{
    "abstractText": "Question Answering over Linked Data (QALD) aims to evaluate a question answering system over structured data, the key objective of which is to translate questions posed using natural language into structured queries. This technique can help common users to directly access open-structured knowledge on the Web and, accordingly, has attracted much attention. To this end, we propose a novel method using first-order logic. We formulate the knowledge for resolving the ambiguities in the main three steps of QALD (phrase detection, phrase-tosemantic-item mapping and semantic item grouping) as first-order logic clauses in a Markov Logic Network. All clauses can then produce interacted effects in a unified framework and can jointly resolve all ambiguities. Moreover, our method adopts a pattern-learning strategy for semantic item grouping. In this way, our method can cover more text expressions and answer more questions than previous methods using manually designed patterns. The experimental results using open benchmarks demonstrate the effectiveness of the proposed method.",
    "authors": [
        {
            "affiliations": [],
            "name": "Shizhu He"
        },
        {
            "affiliations": [],
            "name": "Kang Liu"
        },
        {
            "affiliations": [],
            "name": "Yuanzhe Zhang"
        },
        {
            "affiliations": [],
            "name": "Liheng Xu"
        },
        {
            "affiliations": [],
            "name": "Jun Zhao"
        }
    ],
    "id": "SP:0a9b787d2a3c4c16e99684caa3143aa0acfdd613",
    "references": [
        {
            "authors": [
                "S\u00f6ren Auer",
                "Christian Bizer",
                "Georgi Kobilarov",
                "Jens Lehmann",
                "Richard Cyganiak",
                "Zachary Ives."
            ],
            "title": "Dbpedia: A nucleus for a web of open data",
            "venue": "The semantic web, pages 722\u2013735. Springer.",
            "year": 2007
        },
        {
            "authors": [
                "Junwei Bao",
                "Nan Duan",
                "Ming Zhou",
                "Tiejun Zhao."
            ],
            "title": "Knowledge-based question answering as machine translation",
            "venue": "ACL.",
            "year": 2014
        },
        {
            "authors": [
                "Jonathan Berant",
                "Andrew Chou",
                "Roy Frostig",
                "Percy Liang."
            ],
            "title": "Semantic parsing on freebase from question-answer pairs",
            "venue": "EMNLP.",
            "year": 2013
        },
        {
            "authors": [
                "Christian Bizer",
                "Tom Heath",
                "Tim Berners-Lee."
            ],
            "title": "Linked data-the story so far",
            "venue": "International journal on semantic web and information systems, 5(3):1\u201322.",
            "year": 2009
        },
        {
            "authors": [
                "Kurt Bollacker",
                "Colin Evans",
                "Praveen Paritosh",
                "Tim Sturge",
                "Jamie Taylor."
            ],
            "title": "Freebase: a collaboratively created graph database for structuring human knowledge",
            "venue": "SIGMOD.",
            "year": 2008
        },
        {
            "authors": [
                "Qingqing Cai",
                "Alexander Yates."
            ],
            "title": "Large-scale semantic parsing via schema matching and lexicon extension",
            "venue": "ACL.",
            "year": 2013
        },
        {
            "authors": [
                "Unger Christina",
                "Andr Freitas."
            ],
            "title": "Question answering over linked data: Challenges, approaches, trends",
            "venue": "ESWC.",
            "year": 2014
        },
        {
            "authors": [
                "Dima Corina."
            ],
            "title": "Intui2: A prototype system for question answering over linked data",
            "venue": "Work. Multilingual Question Answering over Linked Data (QALD-3).",
            "year": 2013
        },
        {
            "authors": [
                "Giannone Cristina",
                "Bellomaria Valentina",
                "Basili Roberto."
            ],
            "title": "A hmm-based approach to question answering against linked data",
            "venue": "Work. Multilingual Question Answering over Linked Data (QALD3).",
            "year": 2013
        },
        {
            "authors": [
                "Marie-Catherine De Marneffe",
                "Bill MacCartney",
                "Christopher D Manning"
            ],
            "title": "Generating typed dependency parses from phrase structure parses",
            "year": 2006
        },
        {
            "authors": [
                "Shady Elbassuoni",
                "Roi Blanco."
            ],
            "title": "Keyword search over rdf graphs",
            "venue": "CIKM.",
            "year": 2011
        },
        {
            "authors": [
                "Anthony Fader",
                "Stephen Soderland",
                "Oren Etzioni."
            ],
            "title": "Identifying relations for open information extraction",
            "venue": "EMNLP.",
            "year": 2011
        },
        {
            "authors": [
                "Anthony Fader",
                "Luke Zettlemoyer",
                "Oren Etzioni."
            ],
            "title": "Paraphrase-driven learning for open question answering",
            "venue": "ACL.",
            "year": 2013
        },
        {
            "authors": [
                "Angela Fahrni",
                "Michael Strube."
            ],
            "title": "Jointly disambiguating and clustering concepts and entities with markov logic",
            "venue": "COLING.",
            "year": 2012
        },
        {
            "authors": [
                "Andre Freitas",
                "Edward Curry."
            ],
            "title": "Natural language queries over heterogeneous linked data graphs: A distributional-compositional semantics approach",
            "venue": "IUI.",
            "year": 2014
        },
        {
            "authors": [
                "Bert F Green Jr",
                "Alice K Wolf",
                "Carol Chomsky",
                "Kenneth Laughery."
            ],
            "title": "Baseball: an automatic question-answerer",
            "venue": "Papers presented at the May 9-11, 1961, western joint IRE-AIEE-ACM computer conference, pages 219\u2013224. ACM.",
            "year": 1961
        },
        {
            "authors": [
                "Shizhu He",
                "Shulin Liu",
                "Yubo Chen",
                "Guangyou Zhou",
                "Kang Liu",
                "Jun Zhao."
            ],
            "title": "Casia@qald-3: A question answering system over linked data",
            "venue": "Work. Multilingual Question Answering over Linked Data (QALD-3).",
            "year": 2013
        },
        {
            "authors": [
                "Minlie Huang",
                "Xing Shi",
                "Feng Jin",
                "Xiaoyan Zhu."
            ],
            "title": "Using first-order logic to compress sentences",
            "venue": "AAAI.",
            "year": 2012
        },
        {
            "authors": [
                "Paul. Jaccard."
            ],
            "title": "Nouvelles recherches sur la distribution florale",
            "venue": "Bulletin de la Soci\u00e8te Vaudense des Sciences Naturelles, 44:223\u2013270.",
            "year": 1908
        },
        {
            "authors": [
                "Guyonvarc\u2019H Joris",
                "S\u00e9bastien Ferr\u00e9"
            ],
            "title": "Scalewelis: a scalable query-based faceted search system on top of sparql endpoints. In Work. Multilingual Question Answering over Linked Data (QALD-3)",
            "year": 2013
        },
        {
            "authors": [
                "Jens Lehmann",
                "Tim Furche",
                "Giovanni Grasso",
                "AxelCyrille Ngonga Ngomo",
                "Christian Schallhart",
                "Andrew Sellers",
                "Christina Unger",
                "Lorenz B\u00fchmann",
                "Daniel Gerber",
                "Konrad H\u00f6ffner"
            ],
            "title": "Deqa: deep web extraction for question answering",
            "year": 2012
        },
        {
            "authors": [
                "Percy Liang",
                "Christopher Potts."
            ],
            "title": "Bringing machine learning and compositional semantics together",
            "venue": "Annual Reviews of Linguistics (to appear).",
            "year": 2014
        },
        {
            "authors": [
                "Percy Liang",
                "Michael I Jordan",
                "Dan Klein."
            ],
            "title": "Learning dependency-based compositional semantics",
            "venue": "Computational Linguistics, 39(2):389\u2013446.",
            "year": 2013
        },
        {
            "authors": [
                "Zhao Liu",
                "Xipeng Qiu",
                "Ling Cao",
                "Xuanjing Huang."
            ],
            "title": "Discovering logical knowledge for deep question answering",
            "venue": "CIKM.",
            "year": 2012
        },
        {
            "authors": [
                "Vanessa Lopez",
                "Enrico Motta",
                "Victoria Uren."
            ],
            "title": "Poweraqua: Fishing the semantic web",
            "venue": "The Semantic Web: research and applications, pages 393\u2013410. Springer.",
            "year": 2006
        },
        {
            "authors": [
                "Vanessa Lopez",
                "Victoria Uren",
                "Marta Sabou",
                "Enrico Motta."
            ],
            "title": "Is question answering fit for the semantic web?: a survey",
            "venue": "Semantic Web, 2(2):125\u2013 155.",
            "year": 2011
        },
        {
            "authors": [
                "Ivan Meza-Ruiz",
                "Sebastian Riedel."
            ],
            "title": "Jointly identifying predicates, arguments and senses using markov logic",
            "venue": "NAACL.",
            "year": 2009
        },
        {
            "authors": [
                "Tomas Mikolov",
                "Martin Karafi\u00e1t",
                "Lukas Burget",
                "Jan Cernock\u1ef3",
                "Sanjeev Khudanpur."
            ],
            "title": "Recurrent neural network based language model",
            "venue": "INTERSPEECH, pages 1045\u20131048.",
            "year": 2010
        },
        {
            "authors": [
                "Ndapandula Nakashole",
                "Gerhard Weikum",
                "Fabian Suchanek."
            ],
            "title": "Patty: a taxonomy of relational patterns with semantic types",
            "venue": "EMNLP.",
            "year": 2012
        },
        {
            "authors": [
                "Gonzalo Navarro."
            ],
            "title": "A guided tour to approximate string matching",
            "venue": "ACM Comput. Surv., 33(1):31\u201388.",
            "year": 2001
        },
        {
            "authors": [
                "Jeffrey Pound",
                "Ihab F Ilyas",
                "Grant Weddell."
            ],
            "title": "Expressive and flexible access to web-extracted data: a keyword-based structured query language",
            "venue": "SIGMOD.",
            "year": 2010
        },
        {
            "authors": [
                "C Pradel",
                "G Peyet",
                "O Haemmerl\u00e9",
                "N Hernandez."
            ],
            "title": "Swip at qald-3: results, criticisms and lesson learned (working notes)",
            "venue": "Work. Multilingual Question Answering over Linked Data (QALD-3).",
            "year": 2013
        },
        {
            "authors": [
                "Matthew Richardson",
                "Pedro Domingos."
            ],
            "title": "Markov logic networks",
            "venue": "Machine learning, 62(12):107\u2013136.",
            "year": 2006
        },
        {
            "authors": [
                "Saeedeh Shekarpour",
                "Axel-Cyrille Ngonga Ngomo",
                "S\u00f6ren Auer."
            ],
            "title": "Question answering on interlinked data",
            "venue": "WWW.",
            "year": 2013
        },
        {
            "authors": [
                "Yang Song",
                "Jing Jiang",
                "Wayne Xin Zhao",
                "Sujian Li",
                "Houfeng Wang."
            ],
            "title": "Joint learning for coreference resolution with markov logic",
            "venue": "EMNLP.",
            "year": 2012
        },
        {
            "authors": [
                "Fabian M Suchanek",
                "Gjergji Kasneci",
                "Gerhard Weikum."
            ],
            "title": "Yago: a core of semantic knowledge",
            "venue": "WWW.",
            "year": 2007
        },
        {
            "authors": [
                "Lappoon R. Tang",
                "Raymond J. Mooney."
            ],
            "title": "Using multiple clause constructors in inductive logic programming for semantic parsing",
            "venue": "Proceedings of the 12th European Conference on Machine Learning, pages 466\u2013477.",
            "year": 2001
        },
        {
            "authors": [
                "Christina Unger",
                "Lorenz B\u00fchmann",
                "Jens Lehmann",
                "Axel-Cyrille Ngonga Ngomo",
                "Daniel Gerber",
                "Philipp Cimiano."
            ],
            "title": "Template-based question answering over rdf data",
            "venue": "WWW.",
            "year": 2012
        },
        {
            "authors": [
                "Sebastian Walter",
                "Christina Unger",
                "Philipp Cimiano",
                "Daniel B\u00e4r."
            ],
            "title": "Evaluation of a layered approach to question answering over linked data",
            "venue": "The Semantic Web\u2013ISWC 2012, pages 362\u2013374. Springer.",
            "year": 2012
        },
        {
            "authors": [
                "William A Woods."
            ],
            "title": "Lunar rocks in natural english: Explorations in natural language question answering",
            "venue": "Linguistic structures processing, pages 521\u2013569.",
            "year": 1977
        },
        {
            "authors": [
                "Mohamed Yahya",
                "Klaus Berberich",
                "Shady Elbassuoni",
                "Maya Ramanath",
                "Volker Tresp",
                "Gerhard Weikum."
            ],
            "title": "Natural language questions for the web of data",
            "venue": "EMNLP.",
            "year": 2012
        },
        {
            "authors": [
                "Mohamed Yahya",
                "Klaus Berberich",
                "Shady Elbassuoni",
                "Gerhard Weikum."
            ],
            "title": "Robust question answering over the web of linked data",
            "venue": "CIKM.",
            "year": 2013
        },
        {
            "authors": [
                "Xuchen Yao",
                "Benjamin Van Durme."
            ],
            "title": "Information extraction over structured data: Question answering with freebase",
            "venue": "ACL.",
            "year": 2014
        },
        {
            "authors": [
                "Qi Zhang",
                "Jin Qian",
                "Huan Chen",
                "Jihua Kang",
                "Xuanjing Huang."
            ],
            "title": "Discourse level explanatory relation extraction from product reviews using firstorder logic",
            "venue": "ACL.",
            "year": 2013
        },
        {
            "authors": [
                "Lei Zou",
                "Ruizhe Huang",
                "Haixun WangZou",
                "Jeffrey Xu Yu",
                "Wenqiang He",
                "Dongyan Zhao."
            ],
            "title": "Natural language question answering over rdf \u2014 a graph data driven approach",
            "venue": "SIGMOD.",
            "year": 2014
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1092\u20131103, October 25-29, 2014, Doha, Qatar. c\u00a92014 Association for Computational Linguistics"
        },
        {
            "heading": "1 Introduction",
            "text": "With the rapid development of the Web of Data, many RDF datasets have been published as Linked Data (Bizer et al., 2009), such as DBpedia (Auer et al., 2007), Freebase (Bollacker et al., 2008) and YAGO (Suchanek et al., 2007). The growing amount of Linked Data contains a wealth of knowledge, including entities, classes and relations. Moreover, these linked data usually have\n\u2217Shizhu He and Kang Liu have equal contribution to this work.\ncomplex structures and are highly heterogeneous. As a result, there are gaps for users regarding access. Although a few experts can write queries using structured languages (such as SPARQL) based on their needs, this skill cannot be easily utilized by common users (Christina and Freitas, 2014). Thus, providing user-friendly, simple interfaces to access these linked data becomes increasingly more urgent.\nBecause of this, question answering over linked data (QALD) (Walter et al., 2012) has recently received much interest, and most studies on this topic have focused on translating natural language questions into structured queries (Freitas and Curry, 2014; Yahya et al., 2012; Unger et al., 2012; Shekarpour et al., 2013; Yahya et al., 2013; Bao et al., 2014; Zou et al., 2014). For example, with respect to the question\n\u201cWhich software has been developed by organizations founded in California, USA?\u201d,\nthe aim is to automatically convert this utterance into an SPARQL query that contains the following subject-property-object (SPO) triple format: \u3008?url rdf:type dbo:Software, ?url dbo:developer ?x1, ?x1 rdf:type dbo:Company, ?x1 dbo:foundationPlace dbr:California\u30091.\nTo fulfill this objective, existing systems (Lopez et al., 2006; Unger et al., 2012; Yahya et al., 2012; Zou et al., 2014) usually adopt a pipeline framework that contains four major steps: 1) decomposing the question and detecting phrases, 2) mapping the detected phrases into semantic items of Linked Data, 3) grouping the mapped semantic items into semantic triples, and 4) generating the correct SPARQL query.\nHowever, completing these four steps and constructing such a structured query is not easy. The first three steps mentioned above are subject to the\n1The prefixes in semantic items indicate the source of their vocabularies.\n1092\nproblem of ambiguity, which is the major challenge in QALD. Using the question mentioned above as an example, we can choose California or California, USA when detecting phrases, the phrase California can be mapped to the entity California State or California Film, and the class Software (mapped from the phrase software) can be matched with the first argument of the relation producer or developer (these two relations can be mapped from the phrase developed). Previous methods (Lopez et al., 2006; Lehmann et al., 2012; Freitas and Curry, 2014) have usually performed disambiguation at each step only, and the subsequent step was performed based on the disambiguation results in the previous step(s). However, we argue that the three steps mentioned above have mutual effects. In the previous example, the phrase founded in (verb) can be mapped to the entities (Founding of Rome and Founder (company)), classes (Company and Department) or relations (foundedBy and foundationPlace). If we know that the phrase California can refer to the entity California State, and which can be the second argument of the relation foundationPlace, together with a verb phrase being more likely to be mapped to Relation, we should map the phrase founded in to foundationPlace in this question. Thus, we aim to determine if joint disambiguation is better than individual disambiguation. (Question One)\nIn addition, previous systems usually employed manually designed patterns to extract predicateargument structures that are used to guide the disambiguation process in the three steps mentioned above (Yahya et al., 2012; Unger et al., 2012; Zou et al., 2014). For example, (Yahya et al., 2012) used only three dependency patterns to group the mapped semantic items into semantic triples. Nevertheless, these three manually designed patterns miss many cases because of the diversity of the question expressions. We gathered statistics on 144 questions and found that the macro-average F1 and micro-average F1 of the three patterns2 used in (Yahya et al., 2012) are only 62.8 and 66.2%, respectively. Furthermore, these specially designed patterns may not be valid with variations in domains or languages. Therefore, another important question arises: can we automatically learn rules or patterns to achieve the same ob-\n2They are 1) verbs and their arguments, 2) adjectives and their arguments and 3) propositionally modified tokens and objects of prepositions.\njective? (Question Two) Focusing on the two problems mentioned above, this paper proposes a novel algorithm based on a learning framework, Markov Logic Networks (MLNs) (Richardson and Domingos, 2006), to learn a joint model for constructing structured queries from natural language utterances. MLN is a statistical relational learning framework that combines first-order logic and Markov networks. The appealing property of MLN is that it is readily interpretable by humans and that it is a natural framework for performing joint learning. We formulate the knowledge for resolving the ambiguities in the main three steps of QALD (phrase detection, phrase-to-semantic-item mapping and semantic item grouping) as first-order logic clauses in an MLN. In the framework of MLN, all clauses will produce interacted effects that jointly resolve all problems into a unified process. In this way, the result in each step can be globally optimized. Moreover, in contrast to previous methods, we adopt a learning strategy to automatically learn the patterns for semantic item grouping. We design several meta patterns as opposed to the specific patterns. In addition, these meta patterns are formulated as the first-order logic formulas in the MLN. The specific patterns can be generated by these meta patterns based on the training data. The model will learn the weights of each clause to determine the most effective patterns for semantic triple construction. In this way, with little effort, our approach can cover more semantic expressions and answer more questions than previous methods, which depend on manually designed patterns.\nWe evaluate the proposed method using several benchmarks (QALD-1, QALD-3, QALD-4). The experimental results demonstrate the advantage of the joint disambiguation process mentioned above. They also prove that our approach, employing MLN to automatically learn the patterns of semantic triple grouping, is effective. Our system can answer more questions and obtain better performance than the traditional methods based on manually designed heuristic rules."
        },
        {
            "heading": "2 Background",
            "text": ""
        },
        {
            "heading": "2.1 Linked Data Sources",
            "text": "Linked Data consist of many relational data, which are usually inter-linked as subject-propertyobject (SPO) triple statements (such as using the owl:sameAs relation). In this paper, we mainly use\nDBpedia3 and some classes from Yago4. These knowledge bases (KBs) are composed of many ontological and instance statements, and all statements are expressed by SPO triple facts. Figure 1 shows some triple fact samples from DBpedia.\nEach fact is composed of three semantic items. A semantic item can be an entity (California (State), Oracle Corporation, etc.), a class (Software, Organisation, etc.) or a relation (called a property or predicate in some occasions). Some entities are literals including strings, numbers and dates (118119(xsd:integer), etc.). Relations contain standard Semantic Web relations (subClassOf, type, domain and label) and ontological relations (developer, foundationPlace and numEmployees)."
        },
        {
            "heading": "2.2 Task Statement",
            "text": "Given a knowledge base (KB), our objective is to translate a natural language question qNL into a formal language query qFL that targets the semantic vocabularies given by the KB, and the query qFL should capture the user information needs expressed by qNL.\nFollowing (Yahya et al., 2012), we focus on the factoid questions, and the answers to such questions are an entity or a set of entities. We ignore the questions that need the aggregation5 (max/min, etc.) and negation operations. That is, we generate queries that consist of a plentiful number of triple patterns, which are multiple conjunctions of SPO search conditions."
        },
        {
            "heading": "3 Framework",
            "text": "Figure 2 shows the entire framework of our system for translating a question into a formal SPARQL query. The first three steps address the input question through 1) Phrase Detection (detecting possible phrases), 2) Phrase Mapping (mapping all\n3http://dbpedia.org/ 4http://www.mpi-inf.mpg.de/yago-naga/yago/ 5We can address the count query questions, which will\nbe explained in Section 3.\nphrase candidates to the corresponding semantic items), and 3) Feature Extraction (extracting the linguistic features and semantic item features from the question and the Linked Data, respectively). As a result, a space of candidates is constructed, including possible phrases, mapped semantic items and the possible argument match relations among them. Next, the fourth step (Inference) formulates the joint disambiguation as a generalized inference task. We employ rich features and constraints (including hard and soft constraints) to infer a joint decision through an MLN. Finally, with the inference results, we can construct a semantic item query graph and generate an executable SPARQL query. In the following subsection, we demonstrate each step in detail.\n1) Phrase detection. In this step, we detect phrases (sequences of tokens) that probably indicate semantic items in the KB. We do not use a named entity recognizer (NER) because of its low coverage. We perform testing on two commonly used question corpora, QALD-3 and free9176, using the Stanford NER tool7. The results demonstrate that only 51.5 and 23.8% of the NEs are correctly recognized, respectively. To avoid missing useful phrases, we retain all n-grams as phrase candidates, and then use some rules to filter them. The rules include the following: the span length must be less than 4 (accepting that all contiguous tokens are capitalizations), the POS tag of the start token must be jj, nn, rb and vb, all contiguous capitalization tokens must not be split, etc. For instance, software, developed by, organizations, founded in and California are detected in the example of the first section.\n2) Phrase mapping. After the phrases are detected, each phrase can be mapped to the corresponding semantic item in KB (entity, class and relation). For example, software is mapped to dbo:Software, dbo:developer, etc., and California is mapped to dbr:California, dbr:California (wine), etc. For different types of semantic items, we use different techniques. For mapping phrases to entities, considering that the entities in DBpedia and Wikipedia are consistent, we employ anchor, redirection and disambiguation information from Wikipedia. For mapping phrases to classes, considering that classes have lexical variation, especially synonyms, e.g., dbo:Film can be mapped\n6http://www.cis.temple.edu/\u223cyates/open-semparsing/index.html\n7http://nlp.stanford.edu/software/CRF-NER.shtml\nfrom film, movie and show, we compute the similarity between the phrase and the class in the KB with the word2vec tool8. The word2vec tool computes fixed-length vector representations of words with a recurrent-neural-network based language model (Mikolov et al., 2010). The similarity scoring methods are introduced in Section 4.2. Then, the top-N most similar classes for each phrase are returned. For mapping phrases to relations, we employ the resources from PATTY (Nakashole et al., 2012) and ReVerb (Fader et al., 2011). Specifically, we first compute the associations between the ontological relations in DBpedia and the relation patterns in PATTY and ReVerb through instance alignments as in (Berant et al., 2013). Next, if a detected phrase is matched to some relation pattern, the corresponding ontological relations in DBpedia will be returned as a candidate. This step only generates candidates for every possible mapping, and the decision of the best selection will be performed in the next step.\n3) Feature extraction and joint inference. There exist ambiguities in phrase detection and in mapping phrases to semantic items. This step focuses on addressing these ambiguities and deter-\n8https://code.google.com/p/word2vec/\nmining the argument match relations among the mapped semantic items. This is the core component of our system, and it performs disambiguation in a unified manner. First, feature extraction is performed to prepare a rich number of features from the input question and from the KB. Next, the disambiguation is performed in a joint fashion with a Markov Logic Network. Detailed information will be presented in Section 4.\n4) Semantic item query graph construction. Based on the inference results, we construct a query graph. The vertices contain the following: the detected phrase, the token span indexes of the phrases, the mapped semantic items and their types. The edge indicates the argument match relation between two semantic items. For example, we use 1 2 to indicate that the first argument of an item matches the second argument of another item9. The right bottom in Figure 2 shows an example of this.\n5) Query generation. The SPARQL queries require the grouped triples of semantic items. Thus, in this step, we convert a query graph into multiple joined semantic triples. Three interconnected semantic items, whereby it must\n9The other marks will be introduced in Section 4.2.\nbe ensured that the middle item is a relation, are converted into a semantic triple (multiple joined facts containing variables). For example, the query graph Vdbo:Book[Class] 1 2\u2190\u2192 dbo:author[Relation] 1 1\u2190\u2192 dbr:Danielle Steel[Entity]W is converted into \u3008?x rdf:type dbo:Book, dbr:Danielle dbo:author ?x\u3009, and Vdbo:populationTotal[Relation] 1 2\u2190\u2192 dbo:capital[Relation] 1 1\u2190\u2192 dbr:Australia[Entity]W10 is converted into \u3008?x1 dbo:populationTotal ?answer, ?x1 dbo:capital dbr:Australia\u3009. If the query graph only contains one vertex that indicates a class ClassURI, we generate \u3008?x rdf:type ClassURI\u3009. If the query graph only contains two connected vertexes, we append a variable to bind the missing match argument of the semantic item.\nThe final SPARQL query is constructed by joining the semantic item triples based on the corresponding SPARQL template. We divide the questions into three types: Yes/No, Normal and Number. Yes/No questions use the ASK WHERE template. Normal questions use the SELECT ?url WHERE template. Number questions first use the normal question template, and if they cannot obtain a correct answer (a valid numeric value), we use the SELECT COUNT(?url) WHERE template to generate a query again. For instance, we construct the SPARQL query SELECT(?url) WHERE{ ?url rdf:type dbo:Software. ?url dbo:developer ?x1. ?x1 rdf:type dbo:Company. ?x1 dbo:foundationPlace dbr:California.} for this example."
        },
        {
            "heading": "4 Joint Disambiguation with MLN",
            "text": "In this section, we present our method for question answering over linked data using a Markov Logic Network (MLN). In the following subsections, we first briefly describe the MLN. Then, we present the predicates and the first-order logic formulas used in the model."
        },
        {
            "heading": "4.1 Markov Logic Networks",
            "text": "Markov logic networks combine Markov networks with first-order logic in a probabilistic framework (Richardson and Domingos, 2006). An MLNM consists of several weighted formulas {(\u03c6i, wi)}i, where \u03c6i is a first order formula and wi is the penalty (the formula\u2019s weight). In contrast to the first-order logic, whereby a formula represents a hard constraint, these logic formulas are relaxed and can be violated with penalties in the\n10This corresponds to the question \u201cHow many people live in the capital of Australia?\u201d\nMLN. Each formula \u03c6i consists of a set of firstorder predicates, logical connectors and variables. These weighted formulas define a probability distribution over a possible world. Let y denote a possible world. Then p(y) is defined as follows:\np(y) = 1 Z exp  \u2211 (\u03c6i,wi)\u2208M wi \u2211 c\u2208Cn\u03c6i f\u03c6ic (y)  , where each c is a binding of the free variables in \u03c6i to constants; f \u03c6i c is a binary feature function that returns 1 if the ground formula that we obtain through replacing the free variables in \u03c6i with the constants in c under the given possible world y is true and is 0 otherwise; and Cn\u03c6i is the set of all possible bindings for the free variables in \u03c6i. Z is a normalized constant. The Markov network corresponds to this distribution, where nodes represent ground atoms and factors represent ground formulas."
        },
        {
            "heading": "4.2 Predicates",
            "text": "In the MLN, we design several predicates to resolve the ambiguities in phrase detection, mapping phrases to semantic items and semantic item grouping. Specifically, we design a hidden predicate hasPhrase(i) to indicate that the i-th candidate phrase has been chosen. The predicate hasResource(i,j) indicates that the i-th phrase is mapped to the j-th semantic item. The predicate hasRelation(j,k,rr) indicates that the j-th semantic item and the k-th semantic item should be grouped together with the argument-match-type rr. Note that we define four argument match types between two semantic items: 1 1, 1 2, 2 1 and 2 2. Here, the argument match type t s denotes that the t-th argument of the first semantic item corresponds to the s-th argument of the second semantic item11. The detailed illustration is shown in Table 1.\nMoreover, we define a set of observed predicates to describe the properties of phrases, semantic items, relations between phrases and relations between semantic items. The observed predicates and descriptions are shown in Table 2.\nPrevious methods usually designed some heuristic patterns to group semantic items, which usually employed a human-designed syntactic path between two phrases to determine their relations. In contrast, we collect all the tokens in the dependency path between two phrases as possible patterns. The predicates phraseDepTag and hasMeanWord are designed to indicate the possible patterns. Note that if these tokens only contain POS tags dt|in|wdt|to|cc|ex|pos|wp or stop words, the value of the predicate hasMeanWord is false; otherwise, it is true. In this way, our system is expected to cover more question expressions. Moreover, the SPARQL endpoint is used to verify the type compatibility of two semantic items and if one triple pattern can obtain query results.\nThe predicate hasRelatedness needs to compute the coherence score between two semantic items. Following (Yahya et al., 2012), we use the Jaccard coefficient (Jaccard, 1908) based on the inlinks between two semantic items.\nThe predicate priorMatchScore assigns a prior score when mapping a phrase to a semantic item. We use different methods to compute this score according to different semantic item types. For entities, we use a normalized score based on the frequencies of a phrase referring to an entity. For classes and relations, we use different methods. We first define the following three similarity metrics: a) s1: The Levenshtein distance score (Navarro, 2001) between the labels of the semantic item and the phrase; b) s2: The word embedding (Mikolov et al., 2010) score, which measures the similarity between two phrases and is the maximum cosine value of the words\u2019 word embed-\ndings between two phrases; and c) s3: the instance overlap score, which is computed using the Jaccard coefficient of the instance overlap. All scores are normalized to produce a comparable scores in the interval of (0, 1). The final prior scores for mapping phrases to classes and relations are \u03b3s1 + (1\u2212 \u03b3)s2 and \u03b1s1 + \u03b2s2 + (1\u2212 \u03b1\u2212 \u03b2)s3, respectively. The parameters are set to empirical values12."
        },
        {
            "heading": "4.3 Formulas",
            "text": "According to these predicates, we design several first-order logic formulas for joint disambiguation. As mentioned in the first section, these formulas represent the meta patterns. The concrete patterns can be generated through these meta patterns with training data. Specifically, we use two types of formulas for the joint decisions: Boolean and Weighted formulas. Boolean formulas are hard constraints, which must be satisfied by all of the ground atoms in the final inference results. Weighted formulas are soft constraints, which can be violated with some penalties."
        },
        {
            "heading": "4.3.1 Boolean Formulas (Hard Constraints)",
            "text": "Table 3 lists the Boolean formulas used in this work. The \u201c \u201d notation in the formulas indicates an arbitrary constant. The \u201c|f |\u201d notation expresses the number of true grounded atoms in the formula f . These formulas express the following constraints: hf1: If a phrase is chosen, then it must have a mapped semantic item; hf2: If a semantic item is chosen, then its mapped phrase must be chosen; hf3: A phrase can be mapped to at most one semantic item; hf4: If the phrase is not chosen, then its mapped\n12Set \u03b3 to 0.6 for Class and set \u03b1 and \u03b2 to 0.3 and 0.3 for Relation, respectively.\nsemantic item should not be chosen; hf5: If a semantic item is chosen, then it should have at least one argument match relation with other semantic items; hf6: Two semantic items have at most one argument match relation; hf7: If an argument match relation for two semantic items is chosen, then they must be chosen; hf8: Each of two chosen phrases must not overlap; hf9, hf10, hf11, hf12: The semantic item with type Entity and Class should not have a second argument that matches with others; hf13: The chosen argument match relation for two sematic items must be type compatible."
        },
        {
            "heading": "4.3.2 Weighted Formulas (Soft Constraints)",
            "text": "Table 4 lists the weighted formulas used in this work. The \u201c+\u201d notation in the formulas indicates that each constant of the logic variable should be weighted separately. Those formulas express the following properties in joint decisions: sf1, sf2: The larger the score of the phrase mapping to a semantic item, the more likely the corresponding phrase and semantic item should been chosen; sf3: There are some associations between the POS tags of phase and the types of mapped semantic items; sf4, sf5, sf6: There are some associations between the dependency tags in the dependency pattern path of two phases and the types of argument match relations of two mapped semantic items;\nsh7: The larger the relatedness of two semantic items, the more likely they have an argument match relation; sf8: If the triple pattern has query results, these semantic items should have corresponding argument match relations."
        },
        {
            "heading": "5 Experiments",
            "text": ""
        },
        {
            "heading": "5.1 Dataset & Evaluation Metrics",
            "text": "We use the following three collections of questions from the QALD13 task for question answering over linked data: QALD-1, QALD-3 and QALD4. The generated SPARQL queries are evaluated on Linked Data from DBpedia and YAGO using a Virtuoso engine14. A typical example question from the QALD benchmark is \u201cWhich books written by Kerouac were published by Viking Press?\u201d. As mentioned in Section 2.2, our system is not designed to answer questions that contain numbers, date comparisons and aggregation operations such as group by or order by. Therefore, we remove these types of questions and retain 110 questions from the QALD-4 training set for generating the specific formulas and for training their weights in MLN. We test our system using 37, 75 and 26 questions from the training set of QALD-115, and the testing set of QALD-3 and QALD-4 respectively. We use #T, #Q and #A to indicate the total\n13www.sc.cit-ec.uni-bielefeld.de/qald/ 14https://github.com/openlink/virtuoso-opensource 15We use the training set because we try to make a fair\ncomparison with (Yahya et al., 2012).\nnumber of questions in the testing set, the number of questions we could address and the number of questions answered correct, respectively. We select Precision (P = #A#Q ), Recall (R = #A #T ), and F1-score (F1 = 2\u00b7P \u00b7RP+R ) as the evaluation metrics. To assess the effectiveness of the disambiguation process in the MLN, we computed the overall quality measures by precision and recall with the manually obtained results."
        },
        {
            "heading": "5.2 Experimental Configurations",
            "text": "The Stanford dependency parser (De Marneffe et al., 2006) is used for extracting features from the dependency parse trees. We use the toolkit thebeast16 to learn the weights of the formulas and to perform the MAP inference. The inference algorithm uses a cutting plane approach. In addition, for the parameter learning, we set all initial weights to zero and use an online learning algorithm with MIRA update rules to update the weights of the formulas. The number of iterations for the training and testing are set to 10 and 200, respectively."
        },
        {
            "heading": "5.3 Results and Discussion",
            "text": ""
        },
        {
            "heading": "5.3.1 The Effect of Joint Learning",
            "text": "To demonstrate the advantages of our joint learning, we design a pipeline system for comparison, which independently performs phrase detection, phrase mapping, and semantic item grouping by removing the unrelated formulas in MLN. For example, the formulas17 related to the predicates hasResource and hasRelation are removed when detecting phrases in questions.\nTable 5 shows the results, where Joint denotes the proposed method with joint inference and Pipeline denotes the compared method performing each step independently. We perform a comparison with the question answering results of QALD (QA), and comparisons at each of the following steps: PD (phrase detection), PM (phrase mapping) and MG (mapped semantic items grouping). From the results, we observe that our method answers over half of the questions. Moreover, our joint model based on MLN can obtain better performance in question answering compared to the pipeline system. We also observe that Joint exhibits better performance than Pipeline in most steps, except for MG in QALD-3. We believe this\n16http://code.google.com/p/thebeast 17including entire formulas, excluding hf8 and sf1\nis because the three tasks (phrase detection, phrase mapping, and semantic item grouping) are connected with each other. Each step can provide useful information for the other two tasks. Therefore, performing joint inference can effectively improve the performance. Finally, we observe that the former task usually produces better results than the subsequent tasks (phrase detection exhibits a better performance than phrase mapping, and phrase mapping exhibits a better performance than semantic item grouping). The main reason is that the latter subtask is more complex than the former task. The decisions of the latter subtask strongly rely on the former results even though they have interacted effects."
        },
        {
            "heading": "5.3.2 The Effect of Pattern Learning",
            "text": "Table 6 shows a comparison of our system with DEANNA (Yahya et al., 2012), which is based on a joint disambiguation model but which employs hand-written patterns in its system. Because DEANNA only reports its results of the QALD-1 dataset, we do not show the results for QALD-3 and QALD-4 for equity. From the results, we can see that our system solved more questions and exhibited a better performance than did DEANNA. One of the greatest strengths of our system is that the learning system can address more questions than hand-written pattern rules.\nCompared to the ILP (Integer Linear Programming) used in (Yahya et al., 2012) for joint disambiguation, we argue that there are two major differences to our method. 1) Our method is a datadriven approach that can learn effective patterns or rules for the task. Therefore, it exhibits more robustness and adaptability for various KBs. 2) We design several meta rules in MLN as opposed to specific ones. The specific rules can be generated by these meta rules based on the training data. By contrast, the traditional approach using ILP needs to set specific rules in advance, which requires more intensive labor than our approach.\nTo further illustrate the effectiveness of our pattern-learning strategy, we show the weights of the learned patterns corresponding to formula sf3 in the MLN, as shown in Table 7. From the table,\nwe can see that nn18 is more likely mapped to Entity19 than to Class and Relation, and vb is most likely mapped to Relation. This proves that our model can learn effective and reasonable patterns for QALD."
        },
        {
            "heading": "5.3.3 Comparison to the state of the art",
            "text": "To illustrate the effectiveness of the proposed method, we perform comparisons to the state-ofthe-art methods. Table 8 shows the results using QALD-3 and QALD-4. These systems are the participants in the QALD evaluation campaigns. From the results, we can see that our system outperforms most systems at a competitive performance. They further prove the effectiveness of the proposed method.\n18The POS tag of the head word in the phrase 19The type of semantic item 20Because the QALD-4 conference does not start until after submission, we have no citation for the state-of-"
        },
        {
            "heading": "5.3.4 The Effect of Different Formulas",
            "text": "To determine which formulas are more useful for QALD, we evaluate the performance of the proposed method with different predicate sets. We subtract one weighted formula from the original sets at a time, except retaining the first two formulas sf1 and sf2 for basic inference. Because of space limitations, only the results using QALD-3 testing set are shown in Table 9.\nFrom the results, we can observe that removing some formulas can boost the performance on some single tasks, but employing all formulas can produce the best performance. This illustrates that solely resolving the steps in QALD (phrase detection, phrase mapping, semantic items grouping) can obtain local results, and that making joint inference is necessary and useful."
        },
        {
            "heading": "6 Related Work",
            "text": "Our proposed method is related to two lines of work: Question Answering over Knowledge bases and Markov Logic Networks.\nQuestion answering over knowledge bases has attracted a substantial amount of interest over a long period of time. The initial attempts included BaseBall (Green Jr et al., 1961) and Lunar (Woods, 1977). However, these systems were mostly limited to closed domains due to a lack of knowledge resources. With the rapid development of structured data, such as DBpedia, Freebase and Yago, the need for providing user-friendly interface to these data has become increasingly urgent. Keyword (Elbassuoni and Blanco, 2011) and semantic (Pound et al., 2010) searches are limited to their ability to specify the relations among the different keywords.\nThe open topic progress has also been pushed by the QALD evaluation campaigns (Walter et al., 2012). Lopez et al. (2011) gave a comprehensive survey in this research area. The authors developed the PowerAqua system (Lopez et al., 2006) to\nthe-art systems in QALD-4. The results can be found at http://greententacle.techfak.uni-bielefeld.de/ cunger/qald.\nanswer questions on large, heterogeneous datasets. For questions containing quantifiers, comparatives or superlatives, Unger et al. (2012) translated NL to FL using several SPARQL templates and using a set of heuristic rules mapping phrases to semantic items. The system most similar to ours is DEANNA (Yahya et al., 2012). However, DEANNA extracts predicate-argument structures from the questions using three hand-written patterns. Our system jointly learns these mappings and extractions completely from scratch.\nRecently, the Semantic Parsing (SP) community targeted this problem from limited domains (Tang and Mooney, 2001; Liang et al., 2013) to open domains (Cai and Yates, 2013; Berant et al., 2013). The methods in semantic parsing answer questions by first converting natural language utterances into meaningful representations (e.g., the lambda calculus) and subsequently executing the formal logical forms over KBs. Compared to deriving the complete logical representation, our method aims to parse a question into a limited logic form with the semantic item query, which we believe is more appropriate for answering factoid questions.\nMarkov Logic Networks have been widely used in NLP tasks. Huang (2012) applied MLN to compress sentences by formulating the task as a word/phrase deletion problem. Fahrni and Strube (2012) jointly disambiguated and clustered concepts using MLN. MLN has also been used in coreference resolution (Song et al., 2012). For the task of identifying subjective text segments and of extracting their corresponding explanations from product reviews, Zhang et al. (2013) modeled these segments with MLN. To discover logical knowledge for deep question answering, Liu (2012) used MLN to resolve the inconsistencies of multiple knowledge bases.\nMeza-Ruiz and Riedel (2009) employed MLN for Semantic Role Labeling (SRL). They jointly performed the following tasks for a sentence:\npredicate identification, frame disambiguation, argument identification and argument classification. The semantic analysis of SRL solely rested on the lexical level, but our analysis focuses on the knowledge-base level and aims to obtain an executable query and to support natural language inference."
        },
        {
            "heading": "7 Conclusions and Future Work",
            "text": "For the task of QALD, we present a joint learning framework for phrase detection, phrase mapping and semantic item grouping. The novelty of our method lies in the fact that we perform joint inference and pattern learning for all subtasks in QALD using first-order logic. Our experimental results demonstrate the effectiveness of the proposed method.\nIn the future, we plan to address the following limitations that still exist in the current system: a) numerous hand-labeled data are required for training the MLN, and we could use a latent form of semantic item query graphs (Liang et al., 2013); b) more robust solutions can be developed to find the implicit relations in questions; c) our system can be scaled up to large-scale opendomain knowledge bases (Fader et al., 2013; Yao and Van Durme, 2014); and d) the learning system has the advantage of being easily adapted to new settings, and we plan to extend it to other domains and languages (Liang and Potts, 2014)."
        },
        {
            "heading": "Acknowledgments",
            "text": "The authors are grateful to the anonymous reviewers for their constructive comments. This work was sponsored by the National Basic Research Program of China (No. 2014CB340503) and the National Natural Science Foundation of China (No. 61202329, 61272332), CCF-Tencent Open Fund. This work was also supported in part by Noahs Ark Lab of Huawei Tech. Ltm."
        }
    ],
    "title": "Question Answering over Linked Data Using First-order Logic",
    "year": 2014
}