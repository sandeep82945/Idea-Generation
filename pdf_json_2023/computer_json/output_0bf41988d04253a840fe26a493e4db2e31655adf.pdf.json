{
    "abstractText": "The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks\u2014knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances. Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Vishakh Padmakumar"
        },
        {
            "affiliations": [],
            "name": "Behnam Hedayatnia"
        },
        {
            "affiliations": [],
            "name": "Di Jin"
        },
        {
            "affiliations": [],
            "name": "Patrick Lange"
        },
        {
            "affiliations": [],
            "name": "Seokhwan Kim"
        },
        {
            "affiliations": [],
            "name": "Nanyun Peng"
        },
        {
            "affiliations": [],
            "name": "Yang Liu"
        },
        {
            "affiliations": [],
            "name": "Dilek Hakkani-Tur"
        }
    ],
    "id": "SP:c5794a26e979baf1dd90a3a5ffb19acdaf9f254d",
    "references": [
        {
            "authors": [
                "Daniel Adiwardana",
                "Minh-Thang Luong",
                "David R So",
                "Jamie Hall",
                "Noah Fiedel",
                "Romal Thoppilan",
                "Zi Yang",
                "Apoorv Kulshreshtha",
                "Gaurav Nemade",
                "Yifeng Lu"
            ],
            "title": "Towards a human-like open-domain chatbot",
            "venue": "arXiv preprint arXiv:2001.09977",
            "year": 2020
        },
        {
            "authors": [
                "Laura Banarescu",
                "Claire Bonial",
                "Shu Cai",
                "Madalina Georgescu",
                "Kira Griffitt",
                "Ulf Hermjakob",
                "Kevin Knight",
                "Philipp Koehn",
                "Martha Palmer",
                "Nathan Schneider."
            ],
            "title": "Abstract Meaning Representation for sembanking",
            "venue": "Proceedings of the 7th Linguistic",
            "year": 2013
        },
        {
            "authors": [
                "Siqi Bao",
                "Huang He",
                "Fan Wang",
                "Hua Wu",
                "Haifeng Wang",
                "Wenquan Wu",
                "Zhen Guo",
                "Zhibin Liu",
                "Xinchao Xu."
            ],
            "title": "PLATO-2: Towards building an opendomain chatbot via curriculum learning",
            "venue": "Findings of the Association for Computational Linguis-",
            "year": 2021
        },
        {
            "authors": [
                "Harry Bunt."
            ],
            "title": "Context representation for dialogue management",
            "venue": "Proceedings of the Second International and Interdisciplinary Conference on Modeling and Using Context, CONTEXT \u201999, page 77\u201390, Berlin, Heidelberg. Springer-Verlag.",
            "year": 1999
        },
        {
            "authors": [
                "Emily Dinan",
                "Stephen Roller",
                "Kurt Shuster",
                "Angela Fan",
                "Michael Auli",
                "Jason Weston."
            ],
            "title": "Wizard of wikipedia: Knowledge-powered conversational agents",
            "venue": "arXiv preprint arXiv:1811.01241.",
            "year": 2018
        },
        {
            "authors": [
                "Xiachong Feng",
                "Xiaocheng Feng",
                "Bing Qin."
            ],
            "title": "A survey on dialogue summarization: Recent advances and new frontiers",
            "venue": "arXiv preprint arXiv:2107.03175.",
            "year": 2021
        },
        {
            "authors": [
                "Sarik Ghazarian",
                "Nuan Wen",
                "Aram Galstyan",
                "Nanyun Peng."
            ],
            "title": "DEAM: Dialogue coherence evaluation using AMR-based semantic manipulations",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Vol-",
            "year": 2022
        },
        {
            "authors": [
                "Bogdan Gliwa",
                "Iwona Mochol",
                "Maciej Biesek",
                "Aleksander Wawer."
            ],
            "title": "Samsum corpus: A humanannotated dialogue dataset for abstractive summarization",
            "venue": "arXiv preprint arXiv:1911.12237.",
            "year": 2019
        },
        {
            "authors": [
                "Bogdan Gliwa",
                "Iwona Mochol",
                "Maciej Biesek",
                "Aleksander Wawer."
            ],
            "title": "SAMSum corpus: A humanannotated dialogue dataset for abstractive summarization",
            "venue": "Proceedings of the 2nd Workshop on New Frontiers in Summarization, pages 70\u201379, Hong",
            "year": 2019
        },
        {
            "authors": [
                "Prakhar Gupta",
                "Cathy Jiao",
                "Yi-Ting Yeh",
                "Shikib Mehri",
                "Maxine Eskenazi",
                "Jeffrey P Bigham."
            ],
            "title": "Improving zero and few-shot generalization in dialogue through instruction tuning",
            "venue": "arXiv preprint arXiv:2205.12673.",
            "year": 2022
        },
        {
            "authors": [
                "Prakhar Gupta",
                "Yang Liu",
                "Di Jin",
                "Behnam Hedayatnia",
                "Spandana Gella",
                "Sijia Liu",
                "Patrick Lange",
                "Julia Hirschberg",
                "Dilek Hakkani-Tur."
            ],
            "title": "Dialguide: Aligning dialogue model behavior with developer guidelines",
            "venue": "arXiv preprint arXiv:2212.10557.",
            "year": 2022
        },
        {
            "authors": [
                "Muhammad Khalifa",
                "Miguel Ballesteros",
                "Kathleen McKeown."
            ],
            "title": "A bag of tricks for dialogue summarization",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 8014\u20138022, Online and Punta Cana, Do-",
            "year": 2021
        },
        {
            "authors": [
                "Zekang Li",
                "Jinchao Zhang",
                "Zhengcong Fei",
                "Yang Feng",
                "Jie Zhou."
            ],
            "title": "Conversations are not flat: Modeling the dynamic information flow across dialogue utterances",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "Percy Liang",
                "Rishi Bommasani",
                "Tony Lee",
                "Dimitris Tsipras",
                "Dilara Soylu",
                "Michihiro Yasunaga",
                "Yian Zhang",
                "Deepak Narayanan",
                "Yuhuai Wu",
                "Ananya Kumar"
            ],
            "title": "Holistic evaluation of language models. arXiv preprint arXiv:2211.09110",
            "year": 2022
        },
        {
            "authors": [
                "Vishakh Padmakumar",
                "He He."
            ],
            "title": "Unsupervised extractive summarization using pointwise mutual information",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 2505\u20132512,",
            "year": 2021
        },
        {
            "authors": [
                "Baolin Peng",
                "Michel Galley",
                "Pengcheng He",
                "Chris Brockett",
                "Lars Liden",
                "Elnaz Nouri",
                "Zhou Yu",
                "Bill Dolan",
                "Jianfeng Gao."
            ],
            "title": "Godel: Large-scale pre-training for goal-directed dialog",
            "venue": "arXiv preprint arXiv:2206.11309.",
            "year": 2022
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Stephen Roller",
                "Emily Dinan",
                "Naman Goyal",
                "Da Ju",
                "Mary Williamson",
                "Yinhan Liu",
                "Jing Xu",
                "Myle Ott",
                "Eric Michael Smith",
                "Y-Lan Boureau",
                "Jason Weston."
            ],
            "title": "Recipes for building an open-domain chatbot",
            "venue": "Proceedings of the 16th Conference of",
            "year": 2021
        },
        {
            "authors": [
                "Liu",
                "Bill Dolan"
            ],
            "title": "2019b. Dialogpt: Large-scale",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 538\u2013547 September 11\u201315, 2023. \u00a92023 Association for Computational Linguistics\n538"
        },
        {
            "heading": "1 Introduction",
            "text": "The bulk of existing work in adapting transformer models to open-domain dialogue represents the dialogue context as the concatenated set of turns in natural language (Zhang et al., 2019b; Roller et al., 2021; Shuster et al., 2022). While the selfattention mechanisms of these models are able to capture the context from these flat representations, it remains unclear if this is the best approach (Li et al., 2021). Studying the format of context representation would help improve performance on downstream tasks such as response generation and external knowledge selection and could also potentially inform the pretraining of general-purpose dialogue models. Additionally, as the length of conversations increases (Gopalakrishnan et al., 2019;\n\u2217 Work done during summer internship at Amazon Alexa AI.\nXu, 2021), these are truncated based on the limit imposed by the positional encodings on transformers. We also know that not all of the utterances are equally relevant so succinctly representing the relevant information in the context given the current conversation state and filtering out the noise from prior interactions would help to model provide more coherent responses.\nIn this work, we empirically investigate the dialogue context representation in the text space for using sequence-to-sequence models. To prioritize broad coverage, we vary the the format of the context using both natural language-only formats (e.g., using all recent utterances or summaries) as well as formats that are more structurally different (e.g., extracting knowledge triples from the utterances) (Section 2) and compare these based on downstream task performance.\nWe find that concatenating all recent utterances is a strong baseline. However, in longer dialogues, combining recent utterances with a summary of the past context obtains the best performance. This shows the benefit of the complementary long and short view of dialogue context. We also observe that improving summary quality and introducing external elements about the coherence of the context result in a further gain of downstream performance. This study and related findings can be extended to combine with elements from the broader definition of context (Bunt, 1999), such as social cues and guidelines (Gupta et al., 2022b), which were previously not included in dialogue datasets."
        },
        {
            "heading": "2 Approach",
            "text": "We study the effect of the representation of dialogue context on downstream dialogue tasks\u2014 knowledge selection and response generation. In order to do so, we run a controlled experiment finetuning sequence-to-sequence models on the two tasks verbalised into the text-to-text setup, while varying only the format in which the dialogue con-\ntext is represented. The first broad category of representations consists of directly using the dialogue utterances. We include the concatenated past dialogue utterances, truncated when necessary, as Plaintext representation. This includes all the past turns delineated using a special token when applicable. We also include Windows of recent turns where we only use the most recent n utterances as the context.\nTo test if models require only the knowledge items within the dialogue utterances, we extract (subject, object, relation) Triples from the utterances as the context. To see if models benefit from more structured information, we convert the utterances into AMR graphs (Banarescu et al., 2013).\nFinally, we examine if the information from the context can be distilled using summarization (Feng et al., 2021; Gliwa et al., 2019a; Khalifa et al., 2021). One method is to convert the utterances from both speakers into an abstractive Summary using a separate summarization model.1 And while a summary might contain all the required high-level information from the dialogue context, it loses the local discourse-level information from recent utterances. To mitigate this, we create a hybrid Summary + Utterances format by appending the Summary with Windows of Turns. We also include an extractive summary in the form of Selected Turns from the context using pointwise mutual information, a proxy for relevance, with respect to the most recent turn (Padmakumar and He, 2021).\nWe provide further implementation details about each of the methods in Appendix C and illustrate an example converted to each of them in Figure 1."
        },
        {
            "heading": "3 Experiments",
            "text": ""
        },
        {
            "heading": "3.1 Datasets and Metrics",
            "text": "Knowledge Selection To evaluate performance on knowledge selection, we report results on the Wizard of Wikipedia (WoW) (Dinan et al., 2018) dataset, which consists of dialogue between a wizard (expert) and apprentice (novice) where the wizard selects knowledge items (sentences) to form a response. In the sequence-to-sequence setup, we frame this as a classification task on individual knowledge items as follows. Input: <context> </s> <knowledge item> Output: \u201cRelevant\u201d for the gold knowledge\n1In particular, we use a BART-large model finetuned on SAMSum(Gliwa et al., 2019b).\nitem given that context, and \u201cNot Relevant\u2019 otherwise.\nIn addition to all the context formats from Section 2, we include another baseline called Plaintext with Documents where the gold documents that were used to generate previous wizard turns were appended to the utterances in the dialogue context.\nMetrics: We report accuracy/F1-score of each label in lieu of instance-based classification performance. To report retrieval performance, we score the individual knowledge items for a particular context using the token probabilities assigned to \u201cRelevant\u201d and select the most relevant item. We then evaluate if this matches the checked sentence from the dataset, akin to Recall@1 when this is framed as a retrieval problem. We also report a more relaxed metric that evaluates if this item is from the checked document from the dataset.\nResponse Generation We report results on WoW, Multi-Session Chat (MSC) (Xu et al., 2021) and Topical Chat (TCS) (Gopalakrishnan et al., 2019) where the objective is to generate the gold response given the context. For WoW, the task is a knowledge-grounded dialogue where the responses were formed using the gold knowledge item from the dataset. The task for TCS is also knowledgegrounded response generation, but not all turns are accompanied by relevant knowledge items. For MSC, the task is for the partners to converse about their own interests and discuss information about each others\u2019 interests across multiple sessions. We concatenate utterances from all past sessions with a special token indicating a session break.2 Input: <context> </s> <optional knowledge item> Output: Gold response from the dataset.\nMetrics We report perplexity of the gold utterances w.r.t. the finetuned models and the BertScore (Zhang et al., 2019a) between the generated response and the target utterance."
        },
        {
            "heading": "3.2 Model Training",
            "text": "For each of the datasets, we convert all of the train examples into the different context representations from Section 2 and report finetuned T5 (Raffel et al., 2020) performance. We use the T5-base (220M parameters) and Large (770M parameters) variants. While the models trained in Zhang et al. (2019b); Peng et al. (2022) have examined further\n2For MSC, the Summary baseline(s) use the released summaries for past sessions coupled with a model generated summary for the utterances in the current session.\npretraining on dialogue, this would bias the model to additionally favor the Plaintext baseline. As a result, we choose T5, noting that absolute performance might improve further by adding dialoguespecific pertaining. When tokenizing the context, we allow for up to 1024 tokens and truncate earlier utterances in case of an overflow. We optimize cross-entropy loss on the output tokens in the desired format based on the dataset. We run finetuning for 10 epochs with an early stopping criteria based on validation loss. For each context representation, we select the best learning rate sweeping from 1e\u22123 to 1e\u22126. In the text-to-text setup, we run inference with greedy decoding kept uniform\nacross the representations. Our experiments were run on a p3.8xlarge and a p3.16xlarge EC2 instances containing 4 and 8 Tesla V100 GPUs respectively."
        },
        {
            "heading": "4 Results",
            "text": "Table 1 and Table 2 show the results comparing context representation formats on knowledge selection and response generation respectively.\nPlaintext is a strong baseline, which is outperformed by Summaries+Utterances on longer dialogues From Table 1 and Table 2, we see that the Plaintext representation provides a strong baseline\nfor both knowledge selection and response generation. When we examine the Last Turn and 3-Turn columns, we see the trend that increasing the window size predictably improves performance, but these lag behind Plaintext. This shows that transformers are able to leverage the additional information from more recent utterances in the context. However, we see that Plaintext is outperformed by the Summary + 5-turn method on the longer dialogue datasets, MSC and TCS. This shows that past the limit imposed on current transformer encoders by the positional embeddings, summarizing all available information outperforms a truncated set of recent utterances. Finally, we see that Summary + 5-turn outperforms Summary alone on all the datasets. These findings highlight the complementary Long and Short views of dialogue context from summaries and recent utterances respectively.\nImproving the quality of summaries results in better downstream performance To observe the effect of summary quality, we point out two comparisons. On MSC, we compare the response generation performance using both the gold humanwritten summaries and model-generated summaries (released with the dataset). The perplexity for response generation reduces by using higher quality, human-written summaries (Table 5). Secondly, we\ncan view the Selected Turns baseline as an extractive summary of the dialogue context that consistently outperforms windows of text of the same number of turns (here Selected Turns and 3-turn are comparable). Combined with the observation of the complementary nature of summaries and recent turns, a future direction highlighted through our work is to use downstream task performance as a means to evaluate dialog summarization.\nNatural language-based approaches outperform the more structure-oriented variants We observe that AMR and Triples are consistently outperformed by all the other utterance-based and summary-based variants. This is potentially explained by the higher similarity of the natural language formats to the pretraining data of sequenceto-sequence models.3\nPositive Scaling Trends One of the main advantage of using sequence-to-sequence transformers is that as pretrained models get better, we can expect improved performance in downstream tasks. We observe a simple version of this when comparing results on the different context representation methods with T5-base and T5-large in Table 3 and\n3These methods are at a disadvantage in the text-to-text format and could be improved by different methods of encoding the extracted information.\nTable 4. Performance improves using the scaled up model uniformly for response generation and on retrieval metrics in knowledge selection.\nProviding additional content as part of the context improves performance Augmenting the Plaintext baseline with document level information for WoW results in further improvement in both classification and retrieval scores. In this work, we only considered the utterances in the dialogue itself to be a part of the context. However a broader definition of context for dialogue includes not just the turns but also discourse information, social context, or the relationship between the speakers, and even physical context, or cues from the relative physical positions and actions of the speakers (Bunt, 1999). Our work indicates that a promising future direction of dialogue research could involve collecting and summarizing all this additional rich information to be used by dialogue models.\nWe present additional results in Appendix E and discuss some limitations that inform future directions in Appendix A."
        },
        {
            "heading": "5 Related Work",
            "text": "When adapting transformers to dialogue tasks, the most common approach is to simply concatenate dialogue utterances (Zhang et al., 2019b; Adiwardana et al., 2020; Roller et al., 2021; Bao et al., 2021; Gupta et al., 2022a; Shuster et al., 2022). For longer dialog datasets where the entire conversation cannot be encoded, summaries of past sessions are a helpful way to provide all the relevant information needed to continue the conversation (Xu\net al., 2022). While AMR graphs have been used to perturb individual utterances in order to evaluate coherence in dialogue (Ghazarian et al., 2022), to the best of our knowledge, AMR and Knowledge Triples have not been used to represent the context. We include them for wider coverage. In the dialogue space, retrieval has largely been used to identify relevant knowledge items to be included for response generation (Shuster et al., 2021). Prior work has examined matching candidate responses with multiple utterances for selection, the weighting learned in effect attending to \u2018relevant\u2019 turns (Wu et al., 2016; Zhang et al., 2018), however, we explicitly select turns as a means of representing the dialogue context across both of our open domain dialogue tasks. To our knowledge, ours is the first controlled experiment to evaluate different textual context representation methods for sequence-to-sequence models."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we present an empirical controlled study examining dialogue context representation for transformer models on open-domain dialogue tasks. While concatenating all previous turns, as is often adopted, is a strong baseline, combining summaries of the overarching context with recent utterances yields the best results in longer dialogues. Additionally improving the quality of the summaries being used and introducing further background information into the context further improve performance. This provides us with new directions to work on including dialogue summarization and considering the broader definition of context for use in open-domain dialogue."
        },
        {
            "heading": "A Limitations",
            "text": "Coverage of Context Representations We acknowledge that the list of context representation formats we examine is non-exhaustive and each particular context format could be further optimized. For instance, for AMR we only cover the semantic representations within a single utterance. There are other types of structural aspects in dialogues like discourses, turn-taking, and so on which could be incorporated. We report results comparing these in order to inform subsequent model training/pretraining as well as subsequent analysis of a similar nature.\nUsing Only Verbalized Representations In this work, we only cover context representation formats that are verbalized in natural language. It is unclear if encoding the information either into a specialized dialogue transformer architecture or as a graph would result in improved performance. We choose the verbalized format as it is the most general purpose which can be used to adapt many different language models (Liang et al., 2022).\nAdapting Retrieval Tasks for Text-to-Text Models Adapting language models to retrieval tasks such as knowledge selection can be done either by running inference on individual examples or by combining all candidates along with the input context. Liang et al. (2022) perform a comparison of these variants in the few-shot setting for a large number of tasks and observe no clear winning format so we proceed with separate inference on knowledge items. Here, to isolate the role of the context representation, we fix the format of the task and study the effect of dialogue context on performance\nEvaluation We acknowledge that we report performance using automatic metrics on a single run for both sets of tasks and human evaluation would allow for a more holistic understanding of the capabilities of models, particularly on response generation. Human evaluation and running multiple sets of fine-tuning runs for each of the different formats would be expensive. In this work, we restricted ourselves to the same in order to focus on comparing and identifying trends in performance between a wider range of different context representation formats."
        },
        {
            "heading": "B Potential Risks",
            "text": "Our work discusses ways to adapt sequence-tosequence transformer models for open-domain dialogue. The main associated risk comes from the black-box nature of these models. The text that is generated is pretty heavily influenced by the pretraining data. The models fine-tuned in this paper are open-sourced T5 checkpoints which may contain biases from the C4 (Raffel et al., 2020) corpus. Additionally, the advent of closed-access and limited-access language models such as GPT3 and Anthropic-LM comes with more uncertainty as the pretraining and training processes of these models are not as well documented (Liang et al., 2022)."
        },
        {
            "heading": "C Context Representations",
            "text": "Context Representation Formats We vary the context in the following ways in an attempt to ensure coverage of different formats. The first broad category of representations consists of directly using dialogue utterances.\n\u2022 Plaintext: The simplest, and most widely used, manner in which we can represent the dialogue context is just the concatenated set of past dialogue utterances. This includes all turns from past sessions delineated using a special token when applicable. 4\n\u2022 Windows of Turns: Here we only use the most recent n utterances as the context. As we increase n, we provide more local context about the dialogue.\nAside from including the utterances themselves, to evaluate if models benefit from more structured information we include the following representations:\n\u2022 AMR: We convert each utterance into an AMR graph (Banarescu et al., 2013) and use the verbalised form as the context. The AMR parses the text into a directed acyclic graph, explicitly conveying the relationships as edges between the various concept nodes in the text. We use the model_parse_xfm_bart_large model from amrlib to convert the utterances into the corresponding AMR. We acknowledge that performance in our experiments could be affected by the quality of AMR\n4Dataset specific details are provided in Section 3.1\nconversions. We refer readers to the original library for performance benchmarking of the text-to-AMR model.\n\u2022 Knowledge Triples: To test if models require only the knowledge items within the dialogue context, and not the whole utterance, we extract (subject, object, relation) triples from the utterances as the context. We use OpenIE5 to extract triples and use a simple unigram overlap heuristic to filter out duplicates. If two triples have a unigram overlap of over 0.7, only one is selected.\nFinally, we examine if the information from the dialogue context can be distilled while retaining the natural language format using summarization.\n\u2022 Summary: We summarise all of the dialogue utterances from both speakers abstractively using a finetuned transformer model. In particular, we use a BART-large model finetuned on SAMSum(Gliwa et al., 2019b). As indicated in Section 4, performance depends on the quality of the summarization model. This model was not trained by the authors of this work. We refer readers to the model card on HuggingFace for evaluation of the model itself.\n\u2022 Summary + Utterances: While a summary might contain all the high-level information from the dialogue context, it loses the local discourse-level information from recent utterances which provide cues on how to use the high-level information. We create this hybrid short+long form context representation by appending the Summary with Windows of Turns.\n\u2022 Retrieved Turns: While the aforementioned setups contain abstractive summaries of the dialogue context, we also include an extractive summary generated by selecting relevant turns using pointwise mutual information to the most recent turn (Padmakumar and He, 2021). In order to select relevant turns, we calculate the PMI of all utterances with respect to the Last Turn and combine the 2 most relevant turns, in order to obtain an extractive summary of the context.\nAn example converted to each of the above formats is provided in Figure 1."
        },
        {
            "heading": "D Details for Responsibility Checklist",
            "text": "D.1 License and Usage of Scientific Artifacts\nThe Wizard of Wikipedia (Dinan et al., 2018) and MSC (Xu et al., 2021) datasets made available through ParlAI that is shared under the MIT License which permits usage of the data for research such as our work. Topical Chat (Gopalakrishnan et al., 2019) is shared using the Community Data License Agreement - Sharing, Version 1.0 which also permits the usage of the data in this manner. These datasets are commonly used in the community and are collected while ensuring that it was properly anonymized and does not contain any offensive language. We do not perform additional checks for either of the same. T5 (Raffel et al., 2020), used for all our finetuning experiments, is released under the Apache 2.0 license which permits its use for research. The model used for dialogue summarization and amrlib are both shared under the MIT license which permits such usage as does OpenIE which is shared under the Open IE 5 Software License Agreement. All of the artifacts, both models and datasets, were used as intended by the original authors.\nD.2 Coverage and Statistics of the Data\nAll of the datasets contain only English data, largely collected from American English speakers conversing in a one-on-one conversation. The specifics of the settings where the conversations are collected are well documented and can be referred to in the original works (Dinan et al., 2018; Xu et al., 2021; Gopalakrishnan et al., 2019). Wizard of Wikipedia consists of 18, 430 documents (166, 787 utterances total, 74, 092 of which were wizard turns used in knowledge selection) in the train set. The results were reported on the random split (981 documents, 3, 939 wizard turns) and topic split (967 documents, 3, 927 wizard turns) of the validation data. For MSC, there are 4000 train conversations (spread across multiple sessions) with 161, 440 turns and we report results on the validation set (1001 conversations, 53, 332 turns). In Topical Chat, there are 8628 train conversations consisting of 188378 utterances and we report results on the frequent (539 conversations, 11681 turns) and rare (539 conversations, 11692 turns) splits of the validation data."
        },
        {
            "heading": "E Additional Results",
            "text": "We report a more comprehensive version of the knowledge selection results from Table 1 in Table 7 and response generation from Table 2 in Table 8.\nEffect of Scaling Model Size Table 9 and Table 10 contain the full comparison of results when we switch from T5-Base to T5-Large.\nQuality of Summaries In order to ablate the quality of summaries used, we compared response generation performance on the MSC dataset, comparing the Summary + 5-Turn baseline when the gold, human-written summaries are used as opposed to the model generated summaries released in the original dataset. From Table 5 we observe that the higher quality summaries result in further improvement in performance.\nEffect Of Truncation Here we aim to empirically verify that truncation of context has an adverse effect on model performance. We select those examples in the second session of the MSC dataset when adapted using the Plaintext representation and divide these into whether or not the context was truncated. This particular set of examples was chosen because, out of all the sessions, this was the one which had a relatively large fraction of examples in both of these buckets\u201427.6% of examples were truncated. From Table 6 we clearly see that those examples which suffer from truncation have a drop in performance."
        }
    ],
    "title": "Investigating the Representation of Open Domain Dialogue Context for Transformer Models",
    "year": 2023
}