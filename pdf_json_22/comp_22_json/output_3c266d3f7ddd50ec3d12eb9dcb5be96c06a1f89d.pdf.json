{
    "abstractText": "The submucosal invasion depth predicts prognosis in early colorectal cancer. Although colorectal cancer with shallow submucosal invasion can be treated via endoscopic resection, colorectal cancer with deep submucosal invasion requires surgical colectomy. However, accurately diagnosing the depth of submucosal invasion via endoscopy is difficult. We developed a tool to diagnose the depth of submucosal invasion in early colorectal cancer using artificial intelligence. We reviewed data from 196 patients who had undergone a preoperative colonoscopy at the Osaka University Hospital and Osaka International Cancer Institute between 2011 and 2018 and were diagnosed pathologically as having shallow submucosal invasion or deep submucosal invasion colorectal cancer. A convolutional neural network for predicting invasion depth was constructed using 706 images from 91 patients between 2011 and 2015 as the training dataset. The diagnostic accuracy of the constructed convolutional neural network was evaluated using 394 images from 49 patients between 2016 and 2017 as the validation dataset. We also prospectively tested the tool from 56 patients in 2018 with suspected early-stage colorectal cancer. The sensitivity, specificity, accuracy, and area under the curve of the convolutional neural network for diagnosing deep submucosal invasion colorectal cancer were 87.2% (258/296), 35.7% (35/98), 74.4% (293/394), and 0.758, respectively. The positive predictive value was 84.4% (356/422) and the sensitivity was 75.7% (356/470) in the test set. The diagnostic accuracy of the constructed convolutional neural network seemed to be as high as that of a skilled endoscopist. Thus, endoscopic image recognition by deep learning may be able to predict the submucosal invasion depth in early-stage colorectal cancer in clinical practice.",
    "authors": [
        {
            "affiliations": [],
            "name": "Soichiro Minami"
        },
        {
            "affiliations": [],
            "name": "Norikatsu Miyoshi"
        },
        {
            "affiliations": [],
            "name": "Shiki Fujino"
        },
        {
            "affiliations": [],
            "name": "Shinya Kato"
        },
        {
            "affiliations": [],
            "name": "Yuki Sekido"
        },
        {
            "affiliations": [],
            "name": "Tsuyoshi Hata"
        },
        {
            "affiliations": [],
            "name": "Takayuki Ogino"
        },
        {
            "affiliations": [],
            "name": "Hidekazu Takahashi"
        },
        {
            "affiliations": [],
            "name": "Mamoru Uemura"
        },
        {
            "affiliations": [],
            "name": "Hirofumi Yamamoto"
        },
        {
            "affiliations": [],
            "name": "Yuichiro Doki"
        },
        {
            "affiliations": [],
            "name": "Hidetoshi Eguchi"
        }
    ],
    "id": "SP:427788b9f228f01cbb2e0a2311c8607343a74dfd",
    "references": [
        {
            "authors": [
                "E. Van Cutsem",
                "A. Cervantes",
                "B. Nordlinger",
                "D. Arnold"
            ],
            "title": "Metastatic colorectal cancer: ESMO Clinical Practice Guidelines for diagnosis, treatment and follow-up",
            "venue": "Ann. Oncol",
            "year": 2014
        },
        {
            "authors": [
                "K. El-Shami",
                "K.C. Oeffinger",
                "N.L. Erb",
                "A. Willis",
                "J.K. Bretsch",
                "M.L. Pratt-Chapman",
                "R.S. Cannady",
                "S.L. Wong",
                "J. Rose",
                "A.L Barbour"
            ],
            "title": "American Cancer Society Colorectal Cancer Survivorship Care Guidelines",
            "venue": "CA Cancer J. Clin",
            "year": 2015
        },
        {
            "authors": [
                "T. Watanabe",
                "K. Muro",
                "Y. Ajioka",
                "Y. Hashiguchi",
                "Y. Ito",
                "Y. Saito",
                "T. Hamaguchi",
                "H. Ishida",
                "M. Ishiguro",
                "S Ishihara"
            ],
            "title": "Japanese Society for Cancer of the Colon and Rectum (JSCCR) guidelines 2016 for the treatment of colorectal cancer",
            "venue": "Int. J. Clin. Oncol",
            "year": 2018
        },
        {
            "authors": [
                "T. Sakamoto",
                "Y. Saito",
                "T. Nakajima",
                "T. Matsuda"
            ],
            "title": "Comparison of magnifying chromoendoscopy and narrow-band imaging in estimation of early colorectal cancer invasion depth: A pilot study",
            "venue": "Dig. Endosc",
            "year": 2011
        },
        {
            "authors": [
                "Y. Backes",
                "A. Moss",
                "J.B. Reitsma",
                "P.D. Siersema",
                "L.M. Moons"
            ],
            "title": "Narrow Band Imaging, Magnifying Chromoendoscopy, and Gross Morphological Features for the Optical Diagnosis of T1 Colorectal Cancer and Deep Submucosal Invasion: A Systematic Review and Meta-Analysis",
            "venue": "Am. J. Gastroenterol",
            "year": 2017
        },
        {
            "authors": [
                "Y. Sano",
                "S. Tanaka",
                "S.E. Kudo",
                "S. Saito",
                "T. Matsuda",
                "Y. Wada",
                "T. Fujii",
                "H. Ikematsu",
                "T. Uraoka",
                "N Kobayashi"
            ],
            "title": "Narrowband imaging (NBI) magnifying endoscopic classification of colorectal tumors proposed by the Japan NBI",
            "venue": "Expert Team. Dig. Endosc",
            "year": 2016
        },
        {
            "authors": [
                "Y. Komeda",
                "H. Kashida",
                "T. Sakurai",
                "Y. Asakuma",
                "G. Tribonias",
                "T. Nagai",
                "M. Kono",
                "K. Minaga",
                "M. Takenaka",
                "T Arizumi"
            ],
            "title": "Magnifying Narrow Band Imaging (NBI) for the Diagnosis of Localized Colorectal Lesions Using the Japan NBI Expert Team (JNET) Classification",
            "venue": "Oncology",
            "year": 2017
        },
        {
            "authors": [
                "K.I. Fu",
                "S. Kato",
                "Y. Sano",
                "E.K. Onuma",
                "Y. Saito",
                "T. Matsuda",
                "I. Koba",
                "S. Yoshida",
                "T. Fujii"
            ],
            "title": "Staging of early colorectal cancers: Magnifying colonoscopy versus endoscopic ultrasonography for estimation of depth of invasion",
            "venue": "Dig. Dis. Sci",
            "year": 2008
        },
        {
            "authors": [
                "S. Yanai",
                "S. Nakamura",
                "T. Matsumoto"
            ],
            "title": "Role of magnifying colonoscopy for diagnosis of colorectal neoplasms: From the perspective of Japanese colonoscopists",
            "venue": "Dig. Endosc",
            "year": 2016
        },
        {
            "authors": [
                "M.Y. Su",
                "C.M. Hsu",
                "Y.P. Ho",
                "P.C. Chen",
                "C.J. Lin",
                "C.T. Chiu"
            ],
            "title": "Comparative study of conventional colonoscopy, chromoendoscopy, and narrow-band imaging systems in differential diagnosis of neoplastic and nonneoplastic colonic polyps",
            "venue": "Am. J. Gastroenterol",
            "year": 2006
        },
        {
            "authors": [
                "F.S. Kawaguti",
                "M.C. Franco",
                "B.C. Martins",
                "V. Segateli",
                "C.F.S. Marques",
                "C.S.R. Nahas",
                "R.A. Pinto",
                "A.V. Safatle-Ribeiro",
                "U. RibeiroJunior",
                "S.C Nahas"
            ],
            "title": "Role of Magnification Chromoendoscopy in the Management of Colorectal Neoplastic Lesions Suspicious for Submucosal Invasion",
            "venue": "Dis. Colon. Rectum",
            "year": 2019
        },
        {
            "authors": [
                "N. Pinto",
                "D.D. Cox",
                "J.J. DiCarlo"
            ],
            "title": "Why is real-world visual object recognition hard",
            "venue": "PLoS Comput. Biol",
            "year": 2008
        },
        {
            "authors": [
                "J.E. Bibault",
                "P. Giraud",
                "A. Burgun"
            ],
            "title": "Big Data and machine learning in radiation oncology: State of the art and future prospects",
            "venue": "Cancer Lett. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "A. Krizhevsky",
                "I. Sutskever",
                "G.E. Hinton"
            ],
            "title": "Imagenet classification with deep convolutional neural networks",
            "venue": "Commun. ACM 2017,",
            "year": 2017
        },
        {
            "authors": [
                "K. Fukushima",
                "S. Miyake"
            ],
            "title": "Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position",
            "venue": "Pattern Recognit",
            "year": 1982
        },
        {
            "authors": [
                "A. Esteva",
                "B. Kuprel",
                "R.A. Novoa",
                "J. Ko",
                "S.M. Swetter",
                "H.M. Blau",
                "S. Thrun"
            ],
            "title": "Dermatologist-level classification of skin cancer with deep neural networks",
            "venue": "Nature",
            "year": 2017
        },
        {
            "authors": [
                "V. Gulshan",
                "L. Peng",
                "M. Coram",
                "M.C. Stumpe",
                "D. Wu",
                "A. Narayanaswamy",
                "S. Venugopalan",
                "K. Widner",
                "T. Madams",
                "J Cuadros"
            ],
            "title": "Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs",
            "venue": "JAMA",
            "year": 2016
        },
        {
            "authors": [
                "T. Hirasawa",
                "K. Aoyama",
                "T. Tanimoto",
                "S. Ishihara",
                "S. Shichijo",
                "T. Ozawa",
                "T. Ohnishi",
                "M. Fujishiro",
                "K. Matsuo",
                "J Fujisaki"
            ],
            "title": "Application of artificial intelligence using a convolutional neural network for detecting gastric cancer in endoscopic images",
            "venue": "Gastric Cancer 2018,",
            "year": 2018
        },
        {
            "authors": [
                "N. Miyoshi"
            ],
            "title": "AI application for surgery",
            "venue": "J. Jpn. Soc. Precis. Eng",
            "year": 2022
        },
        {
            "authors": [
                "M.D. Zeiler",
                "R. Fergus"
            ],
            "title": "Visualizing and Understanding Convolutional Networks",
            "venue": "In Proceedings of the European Conference on Computer Vision, Zurich, Switzerland,",
            "year": 2014
        },
        {
            "authors": [
                "H. Machida",
                "Y. Sano",
                "Y. Hamamoto",
                "M. Muto",
                "T. Kozu",
                "H. Tajiri",
                "S. Yoshida"
            ],
            "title": "Narrow-band imaging in the diagnosis of colorectal mucosal lesions: A pilot study",
            "venue": "Endoscopy",
            "year": 2004
        },
        {
            "authors": [
                "D. Apel",
                "R. Jakobs",
                "D. Schilling",
                "U. Weickert",
                "J. Teichmann",
                "M.H. Bohrer",
                "J.F. Riemann"
            ],
            "title": "Accuracy of high-resolution chromoendoscopy in prediction of histologic findings in diminutive lesions of the rectosigmoid",
            "venue": "Gastrointest. Endosc",
            "year": 2006
        },
        {
            "authors": [
                "Y. Xu",
                "Z. Jia",
                "L.B. Wang",
                "Y. Ai",
                "F. Zhang",
                "M. Lai",
                "E.I. Chang"
            ],
            "title": "Large scale tissue histopathology image classification, segmentation, and visualization via deep convolutional activation features",
            "venue": "BMC Bioinform",
            "year": 2017
        },
        {
            "authors": [
                "S. Hattori",
                "M. Iwatate",
                "W. Sano",
                "N. Hasuike",
                "H. Kosaka",
                "T. Ikumoto",
                "M. Kotaka",
                "A. Ichiyanagi",
                "C. Ebisutani",
                "Y Hisano"
            ],
            "title": "Narrow-band imaging observation of colorectal lesions using NICE classification to avoid discarding significant lesions",
            "venue": "World J. Gastrointest. Endosc",
            "year": 2014
        },
        {
            "authors": [
                "T. Kaltenbach",
                "Y. Sano",
                "S. Friedland",
                "R. Soetikno"
            ],
            "title": "American Gastroenterological Association (AGA) Institute technology assessment on image-enhanced endoscopy",
            "venue": "Gastroenterology",
            "year": 2008
        },
        {
            "authors": [
                "S. Kudo",
                "S. Tamura",
                "T. Nakajima",
                "H. Yamano",
                "H. Kusaka",
                "H. Watanabe"
            ],
            "title": "Diagnosis of colorectal tumorous lesions by magnifying endoscopy",
            "venue": "Gastrointest. Endosc",
            "year": 1996
        },
        {
            "authors": [
                "H. Kanao",
                "S. Tanaka",
                "S. Oka",
                "I. Kaneko",
                "S. Yoshida",
                "K. Arihiro",
                "M. Yoshihara",
                "K. Chayama"
            ],
            "title": "Clinical significance of type V(I) pit pattern subclassification in determining the depth of invasion of colorectal neoplasms",
            "venue": "World J. Gastroenterol",
            "year": 2008
        },
        {
            "authors": [
                "S. Sikka",
                "D.A. Ringold",
                "S. Jonnalagadda",
                "B. Banerjee"
            ],
            "title": "Comparison of white light and narrow band high definition images in predicting colon polyp histology, using standard colonoscopes without optical magnification",
            "venue": "Endoscopy",
            "year": 2008
        },
        {
            "authors": [
                "T. Sakamoto",
                "T. Nakajima",
                "T. Matsuda",
                "Y. Murakami",
                "H. Ishikawa",
                "K. Yao",
                "Y. Saito"
            ],
            "title": "Comparison of the diagnostic performance between magnifying chromoendoscopy and magnifying narrow-band imaging for superficial colorectal neoplasms: An online survey",
            "venue": "Gastrointest. Endosc",
            "year": 2018
        },
        {
            "authors": [
                "K. \u0130ncetan",
                "I.O. Celik",
                "A. Obeid",
                "G.I. Gokceler",
                "K.B. Ozyoruk",
                "Y. Almalioglu",
                "R.J. Chen",
                "F. Mahmood",
                "H. Gilbert",
                "N.J Durr"
            ],
            "title": "VR-Caps: A Virtual Environment for Capsule Endoscopy",
            "venue": "Med. Image Anal. 2021,",
            "year": 1019
        },
        {
            "authors": [
                "S. Mathew",
                "S. Nadeem",
                "A. Kaufman"
            ],
            "title": "CLTS-GAN: Color-Lighting-Texture-Specular Reflection Augmentation for Colonoscopy",
            "venue": "In International Conference on Medical Image Computing and Computer-Assisted Intervention; Springer: Cham, Germany,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Miyoshi, N.; Fujino, S.; Kato, S.;\nSekido, Y.; Hata, T.; Ogino, T.;\nTakahashi, H.; Uemura, M.; et al.\nDiagnosis of Depth of Submucosal\nInvasion in Colorectal Cancer with AI\nUsing Deep Learning. Cancers 2022,\n14, 5361. https://doi.org/10.3390/\ncancers14215361\nAcademic Editors: Andreas\nStadlbauer, Anke Meyer-Baese and\nMax Zimmermann\nReceived: 20 September 2022\nAccepted: 24 October 2022\nPublished: 31 October 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: artificial intelligence; colorectal cancer; deep learning; endoscopy; submucosal invasion"
        },
        {
            "heading": "1. Introduction",
            "text": "Colorectal cancer (CRC) has the highest cancer-related morbidity and the third highest mortality worldwide [1\u20133]. The prognosis of CRC varies based on the depth of tumor invasion. Accordingly, treatment is usually determined based on the degree of progression [3].\nCancers 2022, 14, 5361. https://doi.org/10.3390/cancers14215361 https://www.mdpi.com/journal/cancers\nCancers 2022, 14, 5361 2 of 10\nAlmost all cases of early CRC are curable by surgery. Furthermore, endoscopic mucosal resection is possible without a colorectomy, depending on the depth of cancer invasion [4]. The Japanese guidelines divide submucosal (SM) CRC based on the depth of invasion into shallow SM invasion (SM-s; <1000 \u00b5m) and deep SM invasion (SM-d; \u22651000 \u00b5m). SM-s CRC without lymph node metastasis can be treated endoscopically, but SM-d CRC requires surgery with lymph node dissection [4]. Therefore, an incorrect assessment of the depth of invasion can result in the need to perform an additional colorectomy after initial endoscopic treatment. Such measures can lead to complications associated with endoscopic treatment, delayed surgical treatment, and increased cost [3]. Diagnosis of the depth of invasion of early CRC is difficult. The depth of invasion is assessed only by endoscopic findings in most cases. Although narrow-band imaging (NBI), staining, observation of surface and vascular structures with a magnifying endoscope, and the use of endoscopic ultrasonography have improved the accuracy of invasion depth diagnosis, [5\u20139] the accuracy reported by Japanese experts is only between 59% and 84% [10\u201312]. Hence, it is necessary to further improve the accuracy of diagnosis of the invasion depth of CRC using endoscopic findings. Artificial intelligence (AI) has made dramatic progress in various fields in recent years, especially through machine learning (ML) [13\u201316]. Deep learning has also attracted substantial attention in the field of medicine [17\u201319]. To date, several AI diagnostic tools for CRC have been created by AI experts and other special facilities, such as companies and universities, in collaboration with doctors. However, we believe this approach is too inaccessible to contribute to diagnosis in general clinical practice. Therefore, in this study, we developed an AI auxiliary diagnostic support tool requiring only a personal computer and examined whether it could diagnose the depth of invasion as accurately as human experts."
        },
        {
            "heading": "2. Materials and Methods",
            "text": ""
        },
        {
            "heading": "2.1. Patients and Datasets",
            "text": "Patients pathologically diagnosed with SM-s or SM-d CRC after surgical resection (including additional resection after endoscopic resection) were retrospectively selected from 256 patients with early-stage CRC who underwent preoperative colonoscopy at the Osaka University Hospital and Osaka International Cancer Institute between January 2011 and December 2018. Endoscopic images from preoperative colonoscopy performed by a gastroenterologist or gastroenterological surgeon were selected from the electronic medical records at the Osaka University Hospital and Osaka International Cancer Institute, Osaka, Japan. The patient exclusion criteria were head invasion and insufficient pathology or preoperative laboratory data. We collected the following information from the patients\u2019 medical records: age, sex, levels of carcinoembryonic antigen and carbohydrate antigen 19-9, location of the primary tumor, and pathological findings. Clinicopathological factors were classified according to the 9th edition Union for International Cancer Control Tumor\u2013Node\u2013Metastasis classification."
        },
        {
            "heading": "2.2. Colonoscopy and Endoscopic Images",
            "text": "Colonoscopy was performed for screening or preoperative examination, and images were captured using standard endoscopes (CF-HQ290I, CF-H290I, PCF-H290I, CF-Q260AI, CF-H260AI, PCF-Q260AI; Olympus Medical Systems, Co., Ltd., Tokyo, Japan) and standard endoscopic video systems (EVIS LUCERA; Olympus Medical Systems). Images were included if they were taken with standard white light, chromoendoscopy using indigo carmine spraying, crystal violet, and NBI. Images were excluded if they were poor quality resulting from low insufflation of air, bleeding, halation, blur, defocus, or mucus. At least one CRC lesion was present in all the images, and multiple images were prepared for the same lesion to account for differences in angles, distance, and extension of the mucosa. In addition, we prospectively tested the tool with images from 56 patients with suspected early-stage CRC who underwent preoperative colonoscopy at the Osaka University\nCancers 2022, 14, 5361 3 of 10\nHospital and Osaka International Cancer Institute between January and December 2018 as a test set and compared the accuracy with that of preoperative endoscopic diagnosis. The computer diagnosed the images of early CRC as either SM-s or SM-d. The obtained results were not reported to the endoscopists who performed the endoscopic examination to ensure that their diagnosis was not influenced. The colonoscopy image did not include personal information, and only the image of the tumor site was selected."
        },
        {
            "heading": "2.3. Analysis",
            "text": "Deep learning with AI was performed using MATLAB software (MathWorks, R2021a, Natick, MA, USA) by a convolutional neural network (CNN). During the deep learning process, we prevented the network from learning unnecessary information (e.g., backgrounds containing normal mucosa) by clipping the photographs containing the tumors in the form of squares [20]. We used occlusion which explicates the contribution of input images and evaluates an effect on classification results [21]. Differences in clinicopathological factors between the two groups were analyzed using the chi-square test or Fisher\u2019s exact test. Continuous variables with parametric distributions were analyzed using Student\u2019s t-test or analysis of variance. All statistical analyses were performed using JMP software version 16 (SAS Institute Inc., Cary, NC, USA)."
        },
        {
            "heading": "3. Results",
            "text": "After selection, images from 196 of 256 patients were evaluated (Figure 1, Table 1). There were no significant differences between learning and validation sets (Supplementary Table S1). As the training image dataset for the construction of the CNN, 706 images were collected from 91 patients who underwent screening or preoperative examinations at the Osaka University Hospital between January 2011 and December 2015 and were indicated to have pathologically proven CRC (Figure 2, Table 2). To evaluate the diagnostic accuracy of the constructed CNN, an independent validation dataset of 394 images were collected from 49 patients who underwent screening or preoperative examinations at the Osaka University Hospital between January 2016 and December 2017.\nCancers 2022, 14, x FOR PEER REVIEW 3 of 10 indigo carmine spraying, crystal violet, and NBI. Images were excluded if they were poor\nquality resulting from low insufflation of air, bleeding, halation, blur, defocus, or mucus.\nAt least one CRC lesion was present in all the images, and multiple images were prepared\nfor the same lesion to account for differences in angles, distance, and extension of the mu-\ncosa.\nIn addition, we prospectively tested the tool with images from 56 patients with sus-\npected early-stage CRC who underwent preoperative colonoscopy at the Osaka Univer-\nsity Hospital and Osaka International Cancer Institute between January and December\n2018 as a test set and compared the accuracy with that of preoperative endoscopic diag-\nnosis. The computer diagnosed the im ges of early CRC as ither SM-s or SM-d. Th ob-\ntained results were not repor ed to the endoscopists who performed the endos opic ex-\naminati n to ensure that their d agnosis was not influenced. The col noscopy image d d\nnot include p rs nal information, a only the image of the tumor site was selected.\n2.3. Analysis\nDeep learning with AI was performed using MATLAB software (MathWorks,\nR2021a, Natick, MA, USA) by a convolutional neural network (CNN). During the deep\nlearning process, we prevented the network from learning unnecessary information (e.g.,\nbackgrounds containing normal mucosa) by clipping the photographs containing the tu-\nmors in the form of squares. [20]. We used occlusion which explicates the contribution of\ninput images and evaluates an effect on classification results [21]. Differences in clinico-\npathological factors between the two groups were analyzed using the chi-square test or\nFisher\u2019s exact test. Continuous variables with parametric distributions were analyzed us-\ning Student\u2019s t-test or analysis of variance. All statistical analyses were performed using\nJMP software version 16 (SAS Institute Inc., Cary, NC, USA).\n3. Results\nAfter selection, images from 196 of 256 patients were evaluated (Figure 1, Table 1).\nThere wer no significant differences between le rni g and validation sets (Supplemen-\ntary Table S1). As the training image dataset for the construction of the CNN, 706 i ages\nwere collected from 91 patients who underwent screening or preoperative exa inations\nat the Osaka University Hospital between January 2011 and December 2015 and were in-\ndicated to have pathologically proven CRC (Figure 2, Table 2). To evaluate the diagnostic\naccuracy of the constructed CNN, an independent validation dataset of 394 images were\ncollected from 49 patients who underwent screening or preoperative examinations at the\nOsaka University Hospital between January 2016 and December 2017.\nBudding grade (1/2, 3/NA) 54/16/21 37/8/4 * Continuous variables were evaluated. CEA, Carcinoembryonic antigen; CA19-9, Carbohydrate antigen 19-9; tub, Tubular adenocarcinoma; NA, Not applicable.\nCancers 2022, 14, x FOR PEER REVIEW 4 of 10 Figure 1. Study population diagram. Patients were classified into the learning set group, for which\ndata was collected from 2011 to 2015, and the validation set group, for which data was collected\nfrom 2016 to 2017. SM-s: shallow SM invasion (<1000 \u03bcm), SM-d: deep SM invasion (\u22651000 \u03bcm).\nSex (male/female) 59/32 28/21\nBudding grade (1/2, 3/NA) 54/16/21 37/8/4\ntinuous variables w re evaluated. CEA, Carcinoembryonic antigen; CA19-9, Carbohydrate an-\ntigen 19-9; tub, Tubular adenocarcinoma; NA, Not applicable.\nFigure 2. The computer used the 706 images learned by the computer for CNN analysis. The number of SM-s images was 256 and the number of SM-d images was 450.\nTable 2. Clinicopathological features (Learning set 2011\u20132015).\nVariables SM-s\n(n = 22)\nSM-d\n(n = 69) p-Value\nAge, median (years) * 66 (41\u201386) 66 (35\u201384) 0.846\nSex (male/female) 15/7 44/25 0.706\nLocation (C/A/T/D/S/R) a 1/2/1/0/7/11 7/14/7/5/10/26 NA\nDegree of differentiation\n(tub1, 2/others) 22/0 65/4 0.248\nLymphatic invasion (+/\u2212) 4/18 20/49 0.317\nVascular invasion (+/\u2212) 2/20 10/59 0.514\nBudding grade (1/2, 3) ** 13/2 41/14 0.322\ni r . The co puter use the 706 i ages lear t e co t r f r a l i . e n r\nTable 2. Clinicopathological features (Learning set 2011\u20132015).\nVariables SM-s(n = 22) SM-d (n = 69) p-Value\nAge, median (years) * 66 (41\u201386) 66 (35\u201384) 0.846 Sex (male/female) 15/7 44/25 0.706\nLocation (C/A/T/D/S/R) a 1/2/1/0/7/11 7/14/7/5/10/26 NA Degree of differentiation\n(tub1, 2/others) 22/0 65/4 0.248\nLymphatic invasion (+/\u2212) 4/18 20/49 0.317 Vascular invasion (+/\u2212) 2/20 10/59 0.514 Budding grade (1/2, 3) ** 13/2 41/14 0.322\n* Continuous variables were evaluated. ** Not applicable: 7 in SM-s, 14 in SM-d. a Tumor located at cecum (C), ascending (A), transverse (T), descending (D), sigmoid (S), colon or rectum (R) was determined according to the Japanese Classification of Colorectal Carcinoma (9th ed). NA: Not assessed; tub, Tubular adenocarcinoma; SM-d, deep submucosal invasion; SM-s, shallow submucosal invasion.\nOf the 394 images in the validation dataset, 98 images from 11 patients were pathologically proven as SM-s CRC, and 296 images from 38 patients were pathologically proven as SM-d CRC. The CNN identified 321 (87.2%) of the 394 validation set images as SM-d CRC: 63 images from tumors that were pathologically SM-s CRCs and 258 from tumors that were pathologically SM-d CRCs. In the retrospective validation set, the sensitivity of the CNN for diagnosing SM-d CRC compared to SM-s CRC was 87.2% (258/296), the\nCancers 2022, 14, 5361 5 of 10\nspecificity was 35.7% (35/98), the accuracy was 74.4% (293/394), and the area under the curve was 0.758 (Figure 3, Table 3). The percentage of images with incorrect AI diagnosis focused on other areas than the tumor area was 56.2% for SM-s CRC images and 60.5% for SM-d CRC images (Supplementary Table S2).\nCancers 2022, 14, x FOR PEER REVIEW 5 of 10 * Continuous variables were evaluated. ** Not applicable: 7 in SM-s, 14 in SM-d. a Tumor located at cecum (C), ascending (A), transverse (T), descending (D), sigmoid (S), colon or rectum (R) was determined according to the Japanese Classification of Colorectal Carcinoma (9th ed). NA: Not assessed; tub, Tubular adenocarcinoma; SM-d, deep submucosal invasion; SM-s, shallow submucosal invasion. Of the 394 images in the validation dataset, 98 images from 11 patients were patho-\nlogically proven as SM-s CRC, and 296 images from 38 patients were pathologically\nproven as SM-d CRC. The CNN identified 321 (87.2%) of the 394 validation set images as\nSM-d CRC: 63 images from tumors that were pathologically SM-s CRCs and 258 from\ntumors that were pathologically SM-d CRCs. In the retrospective validation set, the sen-\nsitivity of the CNN for diagnosing SM-d CRC compared to SM-s CRC was 87.2% (258/296),\nthe specificity was 35.7% (35/98), the accuracy was 74.4% (293/394), and the area under the\ncurve was 0.758 (Figure 3, Table 3). The percentage of images with incorrect AI diagnosis\nfocused on other areas than the tumor area was 56.2% for SM-s CRC images and 60.5%\nfor SM-d CRC images (Supplementary Table S2).\nn = 38\n296 images\n38 images 258 images\nSensitivity: 87.2% (258/296), positive predictive value: 80.4% (258/321), accuracy: 74.4% (293/394). CNN, convolutional neural network; SM-d, deep submucosal invasion; SM-s, shallow submucosal\ninvasion.\nRe-verification was performed with the prospective test set of images taken from\nclinical practice. For the prospective test set, a total of 560 images were collected from 26\npatients at the Osaka University Hospital and 30 patients at the Osaka International Can-\ncer Institute with early CRC who underwent a preoperative colonoscopy. The sensitivity\nof the CNN was 75.7% (356/470) and positive predictive value was 84.4% (356/422) (Table\n4A,B).\nTable 3. Results of CNN learning from the validation set.\nSensitivity: 87.2% (258/296), positive predictive value: 80.4% (258/321), accur cy: 74.4% (293/394). CNN, convolutional neural network; SM-d, deep submucosal invasion; SM-s, shallow submucosal invasion.\nRe-verification was performed with the prospective test set of images taken from clinical practice. For the prospective test set, a total of 560 images were collected from 26 patients at the Osaka University Hospital and 30 patients at the Osaka International Cancer Institute with early CRC who underwent a preoperative colonoscopy. The sensitivity of the CNN was 75.7% (356/470) and positive predictive value was 84.4% (356/422) (Table 4A,B).\nCancers 2022, 14, 5361 6 of 10\n* Continuous variables were evaluated. a Tumor located at cecum (C), ascending (A), transverse (T), descending (D), sigmoid (S), colon or rectum (R) was determined according to the Japanese Classification of Colorectal Carcinoma (9th ed). Clinical diagnostic sensitivity: 75.7% (356/470), positive predictive value: 84.4% (356/422). AI diagnostic sensitivity: 63.8% (30/47), positive predictive value: 88.2% (30/34). AI, artificial intelligence; SM-d, deep submucosal invasion; SM-s, shallow submucosal invasion. AI, artificial intelligence; CNN, convolutional neural network; tub, Tubular adenocarcinoma; NA, not assessed."
        },
        {
            "heading": "4. Discussion",
            "text": "Most endoscopy techniques use different lights and mucosal stains to diagnose the depth of invasion in early CRC. However, it is difficult to determine the depth of early CRC using endoscopy alone [7,22,23]. An inaccurate preoperative diagnosis can lead to the selection of inappropriate treatment methods, which may affect patient outcomes. If any tumor remains after mucosal resection and intestinal tract resection is not performed, the cancer may spread over time. Therefore, improving the diagnostic accuracy of early CRC invasion depth is necessary to avoid such complications. The recent dramatic advancements in AI have improved its applicability in various fields of science [13,14]. ML is a method in which the computer is trained to find helpful similarities from given data. Deep learning is a type of ML that involves a learning structure of multiple layers to imitate the brain\u2019s neural network, and it enables computers to analyze various training images and extract specific clinical features using a backpropagation algorithm. CNN is a type of deep learning network that enables the recognition of patterns through multilayer learning of image data and automatic extraction of image features [13,14]. Based on the accumulated clinical features, computers can be used to diagnose newly acquired clinical images using CNNs. Various types of neural networks have been developed, and CNNs are known to yield the best performance in the field of image recognition [16\u201319]. In this study, the accuracy of the CNN was 74.4%, equivalent to that of expert endoscopists. In previous studies, the accuracy of the diagnosis of depth of invasion in early CRC by endoscopists was 59\u201384% [10,22]. In our institute, the accuracy of preoperative diagnosis by endoscopists was 76%. In the validation set, the sensitivity and the positive predictive value of the CNN for early CRC were 87.2% and 74.4%, respectively. This shows that the CNN could diagnose the depth of invasion in early CRC as accurately as endoscopy\nCancers 2022, 14, 5361 7 of 10\nexperts. However, AI can only use the information in the image, not the image itself. Hence, it is better to obtain as much information as possible inside the image. The details of the process of CNN deep learning and the part of the image the CNN reads and makes decisions about are not clear [24,25]. In this study, we constructed a program to visualize the part of the image being recognized and diagnosed by AI with a color map [20]. The areas that the AI focused on for diagnosis can be visualized with brighter color on the color map. We found that the AI\u2019s image diagnosis took into account not only the tumor area but also information about the tumor surroundings. We prepared images that included both a close-up image of the tumor and the immediate tumor surroundings so that unnecessary information, such as the image background, would not affect the accuracy of the diagnosis. The created images were then learned by the CNN and a highly accurate diagnostic support tool was developed for endoscopic diagnosis of SM-d early CRC. When using colonoscopic images, close-up NBI images and staining methods such as indigo carmine and crystal violet are preferable for diagnosing the depth of invasion in early CRC compared to using only images captured with white light [7,22,26\u201329]. In this study, white light, NBI, and stained images were all used to assess SM invasion depth. Of the 1690 images in the total dataset, 1245 were white light images, 194 images were obtained from NBI, and 251 images were chromoendoscopy images. Although we tried to improve the accuracy of the deep learning tool using only NBI or stained images, the accuracy was too low. This can be attributed to the fact that there were few NBI and stained images for ML. All tumors had had white light images taken. Therefore, it was possible to obtain a sufficiently accurate diagnosis rate by repeating the learning process with the expanded dataset. Moreover, there was little difference in AI diagnosis when using white light and NBI or chromoendoscopy. Furthermore, we obtained nearly the same diagnostic accuracy as expert endoscopists using auxiliary tools for endoscopic image diagnosis. Hence, differences in diagnostic accuracy among endoscopic diagnostic doctors in clinical practice can be reduced using this tool. Further, it is expected that the accuracy of the CNN will increase as the number of learning cycles increase [15,24]. Therefore, future studies should increase the number of cases and allow the CNN to learn more endoscopic images. However, there are many reports on the usefulness of magnified images such as NBI and stained images compared to white light, and they are utilized in clinical practice. The depth of the lesion was diagnosed based on the macroscopic type of early CRC in this study. From the results of this study, we plan to collect uniform standards for endoscopic images (such as NBI, chromoendoscopy images) to examine diagnostic accuracy [30,31]. Several recent studies have reported the use of CNNs in medical diagnosis with high rates of diagnostic accuracy. However, as most studies are performed in specialized AI institutions with dedicated engineering systems, it takes a considerable amount of time to receive diagnostic results, which is not advantageous in clinical practice. In this study, we developed a cheap, accessible, and user-friendly tool for use in clinical practice to perform diagnosis using a CNN with a short turnaround time that requires only a personal computer. Both retrospective and test sets showed the high accuracy of our CNN approach. Furthermore, we obtained diagnostic accuracy comparable to that of experienced endoscopic diagnostic doctors using this auxiliary tool for endoscopic image diagnosis with the CNN. Hence, this CNN can be used to aid diagnosis in clinical practice. This study has some limitations. One obvious limitation is the small number of SM-s cases in this study. There were twice as many SM-d cases as SM-s cases. As a result, the diagnostic accuracy of the CNN was lower in SM-s cases. On the other hand, it was a high positive predictive rate depending on the data set and a high false-positive rate. This study aimed that the endoscopic images were then analyzed by CNN and a helpful diagnostic tool was developed for endoscopic diagnosis of SM-d CRC. It should be used as supportive information to determine tumor depth preoperatively, because SM-s could be recognized as SM-d which is deeper CRC. Further, it is necessary to conduct an examination at multiple facilities in the future. Second, the color map visualization showed that not only the tumor area but also the tumor periphery was relevant for the AI diagnostic process. Therefore, it is\nCancers 2022, 14, 5361 8 of 10\nnecessary to examine whether the learning of not only endoscopic images of the tumor but also images including the tumor periphery affects the diagnostic accuracy. Finally, it was difficult to classify the gross appearance for colorectal cancer. We suspected that AI could be used to take some shortcut learning and diagnose depth of tumor invasion. However, this is the cohort study, and we collected data retrospectively. We carefully examined the study design regarding how to classify the tumor appearance of colorectal cancer. VR-Caps and CEP are software that can evaluate tissue volume using CT colonoscopy data [32,33]. Using these, we can obtain the best submucosal ground truth depth values and a large number of corresponding real images, and it is possible to construct new practical models. In this study, we evaluated the medical records as a retrospective analysis, and there are preoperative CT data, but not CT-colonography data. If we can handle the CT-colonography data, combining these applications with CT data and software would allow us to construct a practical model. In conclusion, endoscopic image recognition with deep learning using AI may enable a more accurate diagnosis of SM invasion depth in early-stage CRC. It is necessary to examine the features of images that can improve the accuracy of diagnosis by collecting more cases.\nSupplementary Materials: The following supporting information can be downloaded at: https: //www.mdpi.com/article/10.3390/cancers14215361/s1, Table S1: Clinicopathological features and statistical analysis between learning and validation sets; Table S2: The percentage of endoscopic images with incorrect AI diagnosis in the validation set.\nAuthor Contributions: Conceptualization, S.M., N.M. and S.F.; methodology, N.M. and S.F.; software, N.M.; validation, S.M., K.S. and N.M.; formal analysis, S.M., K.S. and N.M.; investigation, S.M., K.S., N.M., S.F., S.K., Y.S., T.H., T.O., H.T., M.U. and H.Y.; resources, S.M., K.S., N.M., S.F., S.K., Y.S., T.H., T.O., H.T., M.U. and H.Y.; data curation, S.M., K.S. and N.M.; writing\u2014original draft preparation, S.M. and N.M.; writing\u2014review and editing, S.M. and N.M.; visualization, S.M. and N.M.; supervision, Y.D. and H.E.; project administration, N.M.; funding acquisition, N.M. All authors have read and agreed to the published version of the manuscript.\nFunding: This research was funded by Council for Science, Technology and Innovation (CSTI), cross-ministerial Strategic Innovation Promotion Program (SIP), \u201cInnovative AI Hospital System\u201d (Funding Agency: National Instisute of Biomedical Innovation, Health and Nutrition (NIBIOHN)).\nInstitutional Review Board Statement: This study was approved by the Research Ethics Committee of Osaka University (Approval number: No. 15144-6, 6 August 2015) and conducted in accordance with the Declaration of Helsinki. Informed consent was obtained from all the study participants.\nInformed Consent Statement: Informed consent was obtained from all subjects involved in the study.\nData Availability Statement: The datasets used and/or analyzed during the current study are available from the corresponding author upon reasonable request.\nAcknowledgments: We thank the staff of our Department of Gastroenterological Surgery, Osaka University for their outstanding engagement and support of the trial. We are grateful to Hiroyuki Hishida and Misa Taguchi from MathWorks Japan for supporting the program development.\nConflicts of Interest: The authors declare no conflict of interest."
        }
    ],
    "title": "Diagnosis of Depth of Submucosal Invasion in Colorectal Cancer with AI Using Deep Learning",
    "year": 2022
}