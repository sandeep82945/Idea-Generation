{
    "abstractText": "We consider the effects of allowing a finite state verifier in an interactive proof system to use a bounded number of private coins, in addition to \u201cpublic\u201d coins whose outcomes are visible to the prover. Although swapping between private and public-coin machines does not change the class of verifiable languages when the verifiers are given reasonably large time and space bounds, this distinction has well known effects for the capabilities of constant space verifiers. We show that a constant private-coin \u201cbudget\u201d (independent of the length of the input) increases the power of public-coin interactive proofs with finite state verifiers considerably, and provide a new characterization of the complexity class P as the set of languages that are verifiable by such machines with arbitrarily small error in expected polynomial time.",
    "authors": [
        {
            "affiliations": [],
            "name": "M. Utkan Gezer"
        },
        {
            "affiliations": [],
            "name": "A. C. Cem Say"
        }
    ],
    "id": "SP:3b598e2ea174703408dd475526eb818040e25e95",
    "references": [
        {
            "authors": [
                "S. Goldwasser",
                "Y.T. Kalai",
                "G.N. Rothblum"
            ],
            "title": "Delegating computation: Interactive proofs for muggles",
            "venue": "J. ACM 62 ",
            "year": 2015
        },
        {
            "authors": [
                "C. Dwork",
                "L. Stockmeyer"
            ],
            "title": "Finite state verifiers I: The power of interaction",
            "venue": "J. ACM 39 ",
            "year": 1992
        },
        {
            "authors": [
                "S. Goldwasser",
                "M. Sipser"
            ],
            "title": "Private coins versus public coins in interactive proof systems",
            "venue": "in: Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing, Association for Computing Machinery",
            "year": 1986
        },
        {
            "authors": [
                "A.C.C. Say",
                "A. Yakary\u0131lmaz"
            ],
            "title": "Finite state verifiers with constant randomness",
            "venue": "Logical Methods in Computer Science 10 ",
            "year": 2014
        },
        {
            "authors": [
                "J. Hartmanis"
            ],
            "title": "On non-determinancy in simple computing devices",
            "venue": "Acta Informatica 1 ",
            "year": 1972
        },
        {
            "authors": [
                "M.U. Gezer",
                "A.C.C. Say"
            ],
            "title": "Constant-space",
            "venue": "constant-randomness verifiers with arbitrarily small error, Information and Computation 288 ",
            "year": 2022
        },
        {
            "authors": [
                "A. Condon"
            ],
            "title": "Computational Models of Games",
            "venue": "MIT Press",
            "year": 1989
        },
        {
            "authors": [
                "L. Fortnow",
                "C. Lund"
            ],
            "title": "Interactive proofs and alternating time-space complexity",
            "venue": "Theoretical Computer Science 113 ",
            "year": 1993
        },
        {
            "authors": [
                "A. Condon",
                "R. Ladner"
            ],
            "title": "Interactive proof systems with polynomially bounded strategies",
            "venue": "Journal of Computer and System Sciences 50 ",
            "year": 1995
        },
        {
            "authors": [
                "J. Kemeny",
                "J. Snell"
            ],
            "title": "Finite Markov Chains",
            "venue": "Van Nostrand",
            "year": 1960
        },
        {
            "authors": [
                "T.H. Cormen",
                "C.E. Leiserson",
                "R.L. Rivest",
                "C. Stein"
            ],
            "title": "Introduction to Algorithms",
            "venue": "3rd ed., MIT Press",
            "year": 2009
        }
    ],
    "sections": [
        {
            "text": "Keywords Interactive proof systems, Delegating computation, Verifiable computing"
        },
        {
            "heading": "1. Introduction",
            "text": "In addition to providing a new perspective on the age-old concept of \u201cproof\u201d and offering possibilities for weak clients to check the correctness of difficult computations that they delegate to powerful servers, interactive proof systems also play an important role in the characterization of computational complexity classes [1]. These systems involve a computationally weak \u201cverifier\u201d (a probabilistic Turing machine with small resource bounds) engaging in a dialogue with a very strong but possibly malicious \u201cprover\u201d, whose aim is to convince the verifier that a common input string is a member of the language under consideration. If the input is a non-member, the prover may well \u201clie\u201d during this exchange to mislead the verifier to acceptance, or to trick it into running forever instead of rejecting. Interestingly, this setup allows the weak machines to be able to verify (that is, to determine the membership status of any given string with low probability of being fooled) a larger class of languages than they can manage to handle in a \u201cstand-alone\u201d fashion, i.e., without engaging with a prover.\nSeveral specializations of the basic model described above have been studied until now. One parameter is whether the prover can \u201csee\u201d the outcomes of the random choices made by the verifier or not. A \u201cprivate-coin\u201d system hides the results of the verifier\u2019s coin flips from the prover, and the verifier only sends information that it deems necessary through a communication channel. \u201cPublic-coin\u201d systems, on the other hand, hide nothing from the prover, who can be assumed to observe the coin flips and deduce the resulting changes to the configuration\n\u22c6\nThis is an extended version of the paper presented in the 24th Italian Conference on Theoretical Computer Science, Palermo, Italy, September 13\u201315, 2023.\n*Corresponding author. $ utkan.gezer@boun.edu.tr (M. U. Gezer); say@boun.edu.tr (A. C. C. Say)\nar X\niv :2\n30 6.\n09 54\n2v 2\n[ cs\n.C C\n] 1\n7 N\nov 2\n02 3\nof the verifier as they unfold. It is known [2] that private-coin systems are more powerful (i.e., can verify more languages) than public-coin ones when the verifiers are restricted to be constant-space machines, but this distinction vanishes when the space restriction is lifted [3].\nIn this paper, we study the capabilities of constant-space verifiers (essentially, two-way probabilistic finite automata) which are allowed to hide some, but not necessarily all, of their coin flips from the prover. We show that allowing these machines to use even only a constant number1 of private coins enlarges the class of verified languages considerably. We adapt several previous results from the literature to this framework and present a new characterization of the complexity class P as the set of languages that can be verified by such machines in polynomial time with arbitrarily small error."
        },
        {
            "heading": "2. Background",
            "text": ""
        },
        {
            "heading": "2.1. Interactive proof systems",
            "text": "We start by providing definitions of interactive proof systems and related language classes that are general enough to cover finite state verifiers with both private and public coins, as well as the more widely studied versions with greater memory bounds [2, 4].\nA verifier in an interactive proof system (IPS) is a 6-tuple (\ud835\udc44,\u03a3,\u03a6,\u0393, \ud835\udeff, \ud835\udc5e0), where\n1. \ud835\udc44 is the finite set of states, such that \ud835\udc44 = \ud835\udc44pri \u222a\ud835\udc44pub \u222a { \ud835\udc5eacc, \ud835\udc5erej } where \u2022 \ud835\udc44pri is the set of states that flip private coins,\n\u2022 \ud835\udc44pub is the set of states that flip public coins, \ud835\udc44pri \u2286 \ud835\udc44pub, and \u2022 \ud835\udc5eacc, \ud835\udc5erej /\u2208 \ud835\udc44pri \u222a\ud835\udc44pub are the accept and reject states, respectively,\n2. \u03a3 is the input alphabet,\n3. \u03a6 is the work tape alphabet, which is guaranteed to include the special blank symbol, ,\n4. \u0393 is the communication alphabet, \u2208 \u0393,\n5. \ud835\udeff is the transition function, described below, and\n6. \ud835\udc5e0 is the initial state, \ud835\udc5e0 \u2208 \ud835\udc44.\nThe computation of a verifier is initialized with \u25b7\ud835\udc64\u25c1 written on its read-only input tape, where \ud835\udc64 \u2208 \u03a3* is the input string, and \u25b7,\u25c1 /\u2208 \u03a3 are the left and right end-markers, respectively. The input head of the verifier is initially on the left end-marker. The read-write work tape is initially filled with blank symbols, with the work tape head positioned at the beginning of the tape. Apart from these two tapes, the verifier also has access to a communication cell, which is a single-cell tape that is initially blank.\nLet \u03a3\u25c1\u25b7 = \u03a3\u222a{\u25b7,\u25c1 }. Let \u2206 = { \u22121, 0,+1 } be the set of possible head movements, where \u22121 means \u201cmove left\u201d, 0 means \u201cstay put\u201d, and +1 means \u201cmove right\u201d.\n1That is, the number of such private coin flips is fixed, regardless of the length of the input.\nThe computation of a verifier evolves by its transition function \ud835\udeff, which is constructed in two parts as follows: For \ud835\udc5e \u2208 \ud835\udc44pri (which implies \ud835\udc5e \u2208 \ud835\udc44pub), \ud835\udeff(\ud835\udc5e, \ud835\udf0e, \ud835\udf11, \ud835\udefe, \ud835\udc4fpri, \ud835\udc4fpub) = (\ud835\udc5e\u2032, \ud835\udf11\u2032, \ud835\udefe\u2032, \ud835\udc51\ud835\udc56, \ud835\udc51\ud835\udc64) dictates that if the machine is originally in state \ud835\udc5e, scanning \ud835\udf0e \u2208 \u03a3\u25c1\u25b7 in the input tape, \ud835\udf11 \u2208 \u03a6 in the work tape, and \ud835\udefe \u2208 \u0393 in the communication cell, and has obtained the \u201cprivate\u201d random bit \ud835\udc4fpri \u2208 { 0, 1 } and the \u201cpublic\u201d random bit \ud835\udc4fpub \u2208 { 0, 1 } as the result of two independent fair coin flips, then it will switch to state \ud835\udc5e\u2032 \u2208 \ud835\udc44, write \ud835\udf11\u2032 \u2208 \u03a6 to the work tape, overwrite the communication cell with \ud835\udefe\u2032, and move the input and work tape heads in the directions \ud835\udc51\ud835\udc56, \ud835\udc51\ud835\udc64 \u2208 \u2206 respectively. For \ud835\udc5e \u2208 \ud835\udc44pub \u2216\ud835\udc44pri, \ud835\udeff(\ud835\udc5e, \ud835\udf0e, \ud835\udf11, \ud835\udefe, \ud835\udc4fpub) = (\ud835\udc5e\u2032, \ud835\udf11\u2032, \ud835\udefe\u2032, \ud835\udc51\ud835\udc56, \ud835\udc51\ud835\udc64) dictates a similar transition in which the outcome of only a single public coin is used.\nThe verifier is paired with another entity, the prover, whose aim is to convince the verifier to accept (or to prevent it from rejecting) its input string. At every step of the verifier\u2019s execution, the outcome of the public coin flip is automatically communicated to the prover. The prover can be modeled as a function that determines the symbol \ud835\udefe \u2208 \u0393 which will be written in the communication cell in between the transitions of the verifier based on the input string, the public coin outcomes, and the sequence of symbols written by the verifier to the communication cell up to that point. Note that the prover does not \u201csee\u201d (and, in the general case, cannot precisely deduce) the configuration of a verifier which uses private coins.\nA verifier halts with acceptance (rejection) when it executes a transition entering \ud835\udc5eacc (\ud835\udc5erej). Any transition that moves the input head beyond an end-marker delimiting the string written on the read-only input tape leads to a rejection, unless that last move enters \ud835\udc5eacc. Note that the verifier may never halt, in which case it is said to be looping.\nWe say a verifier \ud835\udc49 in an IPS verifies a language \ud835\udc3f with error \ud835\udf00 = max(\ud835\udf00+, \ud835\udf00\u2212) if there exist numbers \ud835\udf00+, \ud835\udf00\u2212 < 1/3 where\n\u2022 for all input strings \ud835\udc64 \u2208 \ud835\udc3f, there exists a prover \ud835\udc43 such that \ud835\udc49 halts by accepting with probability at least 1\u2212 \ud835\udf00+ when started on \ud835\udc64 and interacting with \ud835\udc43 , and,\n\u2022 for all input strings \ud835\udc64 /\u2208 \ud835\udc3f and for all provers \ud835\udc43 *, \ud835\udc49 halts by rejecting with probability at least 1\u2212 \ud835\udf00\u2212 when started on \ud835\udc64 and interacting with \ud835\udc43 *.\nThe terms \ud835\udf00+ and \ud835\udf00\u2212 bound the two possible types of error corresponding to failing to accept and reject, respectively. Intuitively, this definition requires \ud835\udc49 (in order for it to keep its error low) to be reasonable enough to accept legitimate arguments that prove that the input is a member of the language in question, yet skeptical enough to reject spurious claims of membership when the input is not in the language, both with high probability, even when it is interacting with the most cunning of all provers.\nIn some of our proofs in Section 3, we will be considering verifiers with multiple input tape heads that the machine can move independently of one another. This type of verifier can be modeled easily by modifying the tuples in the transition function definitions above to accommodate more scanned input symbols and input head directions. Sections 2.2 and 2.3 provide more information on automata with multiple input heads and their relationships with the standard Turing machine model.\nWe will be using the notation IP(resource1, resource2, . . . , resource\ud835\udc58) to denote the class of languages that can be verified with arbitrarily small (but possibly positive) errors by machines that operate within the resource bounds indicated in the parentheses. These may represent\nbudgets for runtime, working memory usage, and number of public and private random bits, given as a function of the length of the input string, in asymptotic terms. We reserve the symbol \ud835\udc5b to denote the length of the input string. The terms con, log, linear, and poly will be used to represent the well-known types of functions to be considered as resource bounds, with \u201ccon\u201d standing for constant functions of the input length, the others being self evident, to form arguments like \u201cpoly-time\u201d or \u201clog-space\u201d. The absence of a specification for a given type of resource (e.g., private coins) shall indicate that that type of resource is simply unavailable to the verifiers of that class.2\nBy default, a given resource budget should be understood as a worst case bound, indicating that it is impossible for the verifier to exceed those bounds. Some of the interactive protocols to be discussed have the property that the verifier has a probability \ud835\udf00 of being fooled to run forever by a malicious prover trying to prevent it from rejecting the input. The designer of the protocol can reduce \ud835\udf00 to any desired small positive value. The denotation \u201c*\u201d will be used to mark that the indicated amount corresponds to such a machine\u2019s expected consumption of a specific resource with the remaining (high) probability 1\u2212 \ud835\udf00. For instance, \u201cpoly*-time\u201d will indicate that the verifier\u2019s expected runtime is polynomially bounded with probability almost, but possibly not exactly, 1."
        },
        {
            "heading": "2.2. Multihead finite automata and finite state verifiers",
            "text": "Our work makes use of an interesting relationship [5] between multihead finite automata and logarithmic-space Turing machines, which will be detailed in Section 2.3. In this subsection, we provide the necessary definitions and establish the link between these machines and probabilistic finite state verifiers.\nA \ud835\udc58-head nondeterministic finite automaton (2nfa(\ud835\udc58)) is a nondeterministic finite-state machine with \ud835\udc58 read-only heads that move on an input string flanked by two end-marker symbols. Each head can be made to stay put or move to an adjacent tape cell in each computational step. Formally, a 2nfa(\ud835\udc58) is a 4-tuple (\ud835\udc44,\u03a3, \ud835\udeff, \ud835\udc5e0), where\n1. \ud835\udc44 is the finite set of internal states, which includes the two halting states \ud835\udc5eacc and \ud835\udc5erej,\n2. \u03a3 is the finite input alphabet, 3. \ud835\udeff:\ud835\udc44 \u00d7 \u03a3\ud835\udc58\u25c1\u25b7 \u2192 \ud835\udcab (\ufe00 \ud835\udc44\u00d7\u2206\ud835\udc58 )\ufe00 is the transition function describing the sets of alternative\nmoves the machine may perform at each execution step, where each move is associated with a state to enter and whether or not to move each head, given the machine\u2019s current state and the list of symbols that are currently being scanned by the \ud835\udc58 input heads, and \u03a3\u25c1\u25b7 and \u2206 are as defined previously in Section 2.1, and\n4. \ud835\udc5e0 \u2208 \ud835\udc44 is the initial state.\nGiven an input string \ud835\udc64 \u2208 \u03a3*, a 2nfa(\ud835\udc58)\ud835\udc40 = (\ud835\udc44,\u03a3, \ud835\udeff, \ud835\udc5e0) begins execution from the state \ud835\udc5e0, with \u25b7\ud835\udc64\u25c1 written on its tape, and all \ud835\udc58 of its heads on the left end-marker. At each step, \ud835\udc40\n2Verifiers that use only some private coins and no public coins can be described in the framework given above by simply specifying their transition functions to be insensitive to the value of the public random bit argument, i.e., \ud835\udeff(\ud835\udc5e, \ud835\udf0e, \ud835\udf11, \ud835\udefe, \ud835\udc4fpri, 0) = \ud835\udeff(\ud835\udc5e, \ud835\udf0e, \ud835\udf11, \ud835\udefe, \ud835\udc4fpri, 1) and \ud835\udeff(\ud835\udc5e, \ud835\udf0e, \ud835\udf11, \ud835\udefe, 0) = \ud835\udeff(\ud835\udc5e, \ud835\udf0e, \ud835\udf11, \ud835\udefe, 1) for all values of \ud835\udc5e, \ud835\udf0e, \ud835\udf11, \ud835\udefe, and \ud835\udc4fpri.\nnondeterministically updates its state and head positions according to the choices dictated by its transition function. Computation halts if one of the states \ud835\udc5eacc or \ud835\udc5erej has been reached, or a head has moved beyond either end-marker. \ud835\udc40 is said to accept \ud835\udc64 if there exists a sequence of nondeterministic choices where it reaches the state \ud835\udc5eacc, given \ud835\udc64 as the input. \ud835\udc40 is said to reject \ud835\udc64 if every sequence of choices either reaches \ud835\udc5erej, ends with a transition whose associated set of choices is \u2205, or by a head moving beyond an end-marker without a final state being entered. \ud835\udc40 might also loop on the input \ud835\udc64, neither accepting nor rejecting it.\nThe language recognized by \ud835\udc40 is the set of strings that it accepts. Let \u2112(2nfa(*)) denote the set of languages that have a 2nfa(\ud835\udc58) recognizer (for some \ud835\udc58 > 0), and \u2112(2nfa(*), linear-time) denote the set of languages that have a 2nfa(\ud835\udc58) recognizer running in linear time.\nOur main result will be making use of a technique introduced by Say and Yakary\u0131lmaz [4] for \u201csimulating\u201d a multihead nondeterministic automaton in an interactive proof system whose verifier is a (single-head) probabilistic finite automaton. This method\u2019s application to the problem studied in this paper will be explained in detail in the proof of Lemma 6 in Section 3."
        },
        {
            "heading": "2.3. Multihead finite automata and logarithmic space Turing machines",
            "text": "The equivalence of multiple input heads and logarithmic amounts of memory was discovered by Hartmanis [5]. The following theorem reiterates this result in detail, and also contains an analysis for the overhead in time incurred during the simulation.\nTheorem 1. Any language recognized by a Turing machine that uses at most \u2308log \ud835\udc5b\u2309 space with a work tape alphabet of size at most 2\ud835\udc50 (for some integer constant \ud835\udc50 > 0) and in \ud835\udc61(\ud835\udc5b) time can also be recognized by a (\ud835\udc50+ 5)-head finite automaton in \ud835\udc61(\ud835\udc5b) \u00b7 (1 + \ud835\udc50+ 2\ud835\udc5b+ 3\ud835\udc50\ud835\udc5b) time.\nProof idea. Assume, for the sake of simplicity, that \ud835\udc5b is a power of 2. A string over the alphabet { 0, 1 } in a work tape of length log \ud835\udc5b can be seen as the digits of a number between 0 and \ud835\udc5b\u22121, inclusive, represented in binary. The index of a head on the input tape can similarly range between 0 (when on \u25b7) and \ud835\udc5b+1 (when on \u25c1). This correspondence enables a multihead finite automaton to store the same information there is on a log \ud835\udc5b symbol string over an alphabet of size 2\ud835\udc50 (which can be viewed as the binary digits of \ud835\udc50 numbers stacked on top of each other), encoded at the indices of \ud835\udc50 input heads.\nThere is a way for a multihead finite automaton to retrieve a single binary digit of a head\u2019s index and also to change it. Four spare input heads are introduced and used to accomplish these functions, with one of them mimicking the position of the simulated work tape head, and the other three helping with the index manipulations for decoding, changing, and then re-encoding. One last input head is the input head of the multihead finite automaton.\nUsing this method, a multihead finite automaton can simulate a \u2308log \ud835\udc5b\u2309-space Turing machine directly.\nThe detailed proof is included in Appendix A.1 due to space constraints."
        },
        {
            "heading": "2.4. Implementing a polynomial-time \u201cclock\u201d in a probabilistic finite automaton",
            "text": "A logarithmic-space Turing machine can \u201cclock\u201d its own execution to satisfy any desired polynomial time bound by counting up till that bound in the logarithmic space available. The constant-space machines we construct in Section 3 will employ a different technique using randomness, which is illustrated in the following lemma, to obtain the same bound on expected runtime.\nLemma 2. For any constant \ud835\udc61 > 0, integer-valued function \ud835\udc53(\ud835\udc5b) \u2208 O (\ufe00 \ud835\udc5b\ud835\udc61 )\ufe00 , and desired \u201cerror\u201d bound \ud835\udf00premature > 0, there exists a probabilistic finite automaton with an expected runtime in O (\ufe00 \ud835\udc5b\ud835\udc61+1 )\ufe00 , such that the probability that this machine halts in fewer than \ud835\udc53(\ud835\udc5b) time-steps is \ud835\udf00premature.\nProof idea. Assume, for the sake of simplicity, that \ud835\udc61 is an integer. We program a probabilistic finite state automaton to make \ud835\udc61 random walks with its input head, each starting from the first symbol on the input and ending at either one of the end-markers. If all the walks have ended on the right end-marker, the machine halts. Otherwise, the process is repeated. The analysis shows that such a machine has all the necessary characteristics in its runtime.\nThe detailed proof is included in Appendix A.2 due to space constraints."
        },
        {
            "heading": "3. Finite state verifiers with constant private randomness",
            "text": "Let us consider the language of palindromes, \ud835\udc3fpal = {\ufe00 \ud835\udc64 \u2208 { 0, 1 }* \u20d2\u20d2 \ud835\udc64 = \ud835\udc64\ud835\udc45 }\ufe00 , where \ud835\udc65\ud835\udc45 is the reverse any string \ud835\udc65. Trivially, \ud835\udc3fpal \u2208 \u2112(2nfa(*), linear-time). We recall the following facts about the power of finite state verifiers at the two extreme ends of the \u201cpublic vs. private\u201d spectrum, which shows us that even a finite amount of private coins gives verifiers an edge that no amount of public coins can compensate:\nFact 3. \ud835\udc3fpal /\u2208 IP(con-space,\u221e-public-coins,\u221e-time) [2].\nFact 4. \u2112(2nfa(*), linear-time) \u2286 IP(con-space, con-private-coins, linear*-time) [6].3\nLet us now examine the effects of allowing finite state verifiers to hide a constant number of their coin flips from the prover. This turns out to provide a new characterization of the complexity class P, corresponding to the collection of languages decidable by deterministic Turing machines in polynomial time and space.\nTheorem 5.\nIP(con-space, con-private-coins,poly*-public-coins,poly*-time) = P.\n3Recall from the definition of our IP complexity class notation in Section 2 that the verifier\u2019s runtime can be infinite with probability at most \ud835\udf00, and its expected runtime is bounded as indicated with the remaining large probability.\nProof. It is known [7, 1] that\nIP(log-space,poly-public-coins, poly-time) = P.\nThe proof follows from this fact and Lemmas 6 and 7.\nLemma 6.\nIP(log-space,poly-public-coins, poly-time) \u2286 IP(con-space, con-private-coins,poly*-public-coins, poly*-time)."
        },
        {
            "heading": "More specifically, for any \ud835\udc61 > 1,",
            "text": "IP(log-space,O (\ufe00 \ud835\udc5b\ud835\udc61 )\ufe00 -public-coins,O (\ufe00 \ud835\udc5b\ud835\udc61 )\ufe00 -time) \u2286\nIP(con-space, con-private-coins,O (\ufe00 \ud835\udc5b\ud835\udc61+2 )\ufe00* -public-coins,O (\ufe00 \ud835\udc5b\ud835\udc61+2 )\ufe00* -time).\nProof. For some \ud835\udc61 > 1, let \ud835\udc491 be a public-coin verifier that uses O(log \ud835\udc5b) space and O (\ufe00 \ud835\udc5b\ud835\udc61 )\ufe00\ntime to verify the language \ud835\udc3f with error \ud835\udf001 > 0. We will assume that the work tape of \ud835\udc491 is exactly \u2308log \ud835\udc5b\u2309 cells long, but with a \u201cmulti-track\u201d alphabet (e.g., as in [5]) to accommodate for the required amount of memory.\nIn the following discussion, let any prover facing \ud835\udc491 be called \ud835\udc431. Since \ud835\udc491 cannot be fooled into accepting a non-member of \ud835\udc3f with high probability no matter what prover it is facing, it is also immune against any such \ud835\udc431 that \u201cknows\u201d \ud835\udc491\u2019s algorithm. Since all coins are public, such a \ud835\udc431 can be assumed to have complete knowledge about \ud835\udc491\u2019s configuration at every step of their interaction. Therefore we will assume that \ud835\udc491 sends no further information through the communication cell without loss of generality.\nLet us consider a constant-space, public-coin, \ud835\udc58-head verifier \ud835\udc492 that can verify \ud835\udc3f by simply executing \ud835\udc491\u2019s program, simulating \ud835\udc491\u2019s logarithmic-length work tape by the means of Theorem 1. Since the simulation is direct and does not involve any additional use of randomness, \ud835\udc492 recognizes \ud835\udc3f with the same probability of error \ud835\udf001. The only time overhead is caused by the simulation of the log-space memory, so, by Theorem 1, \ud835\udc492 will complete its execution in O (\ufe00 \ud835\udc5b\ud835\udc61+1 )\ufe00 time. Just like \ud835\udc491, \ud835\udc492 sends no information to its prover, say, \ud835\udc432, except the outcomes of its public coins. We now describe \ud835\udc493, a constant-space, single-head verifier that uses a constant number of private coins (in addition to the public coins that it flips at every step) to verify \ud835\udc3f. \ud835\udc493 performs the following verification for \ud835\udc5a consecutive rounds: First, \ud835\udc493 flips \ud835\udc5f of its private coins. Thanks to this randomness, it picks the \ud835\udc56th head of \ud835\udc492 with some probability4 \ud835\udc5d\ud835\udc56. \ud835\udc493 then engages in an interaction with its own prover, say, \ud835\udc433, to simulate the execution of \ud835\udc492, including \ud835\udc492\u2019s interaction with \ud835\udc432 about the input string. In this process, \ud835\udc493 traces the selected head of \ud835\udc492 with its own single head, and relies on the messages of \ud835\udc433 to inform it about what the other heads of \ud835\udc492 would be reading at any step of the execution. \ud835\udc493 does not send any information (except, of course, the outcomes of its public coins) to \ud835\udc433. \ud835\udc433, on the other hand, is expected to transmit both\n4We will discuss constraints on these values in the discussion below.\n\u2022 what \ud835\udc432 would be transmitting to \ud835\udc492, and\n\u2022 its claims about the readings of all \ud835\udc58 heads of \ud835\udc492\nat every step of the simulated interaction. \ud835\udc493 verifies the part of these claims regarding the head it had chosen in private, and rejects if it sees any discrepancy. \ud835\udc433 sends a special symbol when it claims that the simulated interaction up to that point has ended with \ud835\udc492 reaching acceptance. If this is consistent with what \ud835\udc493 has been able to validate, and if this was not the \ud835\udc5ath round, \ud835\udc493 proceeds to another round.\nWhile \ud835\udc5d\ud835\udc56 is positive for all \ud835\udc56, the sum \ud835\udc5dsimulation = \u2211\ufe00\ud835\udc58\n\ud835\udc56=1 \ud835\udc5d\ud835\udc56 is very small by design. With the remaining high probability \ud835\udc5dtimer = 1 \u2212 \ud835\udc5dsimulation, \ud835\udc493 passes this round operating as a probabilistic timer that has an expected runtime of O (\ufe00 \ud835\udc5b\ud835\udc61+2 )\ufe00 . This timer is also guaranteed to run longer than \ud835\udc492\u2019s runtime with probability 1\u2212 \ud835\udf00premature, for some positive \ud835\udf00premature that can be set to be arbitrarily close to 0, by the premise of Lemma 2. If \ud835\udc433 claims that \ud835\udc492 has accepted before the timer runs out, then \ud835\udc493 proceeds with another round of verification. Otherwise (if the timer runs out before \ud835\udc433 declares acceptance), \ud835\udc493 rejects.\n\ud835\udc493 accepts if it does not reject for \ud835\udc5a rounds of verification. The total number of private coins used is \ud835\udc5a\ud835\udc5f.\nThe rest of the proof analyzes the error and runtime of \ud835\udc493.\nArbitrarily small verification error. For any input string that is a member of \ud835\udc3f, \ud835\udc433 should tell \ud835\udc493 the truth about what \ud835\udc492 would read with its \ud835\udc58 heads, and emit the messages \ud835\udc432 would send to \ud835\udc492 alongside those readings. Faced with such a truthful \ud835\udc433, \ud835\udc493 may erroneously reject at any given round, either due to the simulated \ud835\udc492 also rejecting,5 or due to a premature timeout of the probabilistic timer. The probability of that is \ud835\udc5dsimulation \u00b7 \ud835\udf001 + \ud835\udc5dtimer \u00b7 \ud835\udf00premature. For \ud835\udc493 to accept such an input string, it should go through \ud835\udc5a consecutive rounds of verification without committing such errors. The probability that \ud835\udc493 will fail to accept a string in \ud835\udc3f is therefore\n\ud835\udf00+3 \u2264 1\u2212 (\ufe00 1\u2212 (\ufe00 \ud835\udc5dsimulation \u00b7 \ud835\udf001 + \ud835\udc5dtimer \u00b7 \ud835\udf00premature )\ufe00)\ufe00\ud835\udc5a .\nFor any input not in \ud835\udc3f, \ud835\udc493 can accept only if \ud835\udc433 claims that \ud835\udc492 accepts in all \ud835\udc5a rounds. Such a claim can either be true, since \ud835\udc492 can genuinely accept such a string with probability at most \ud835\udf001; or false, in which case \ud835\udc433 would be \u201clying\u201d, i.e., providing false information that could be detected when compared against the actual readings of at least one of \ud835\udc492\u2019s heads. Let \ud835\udc5dmin = min \ud835\udc58 \ud835\udc56=1 \ud835\udc5d\ud835\udc56. The probability of \ud835\udc493 failing to catch such a lie in any round is at most 1\u2212 \ud835\udc5dmin. It follows that the probability that \ud835\udc493 accepts a string not in \ud835\udc3f is\n\ud835\udf00\u22123 \u2264 max(\ud835\udf001, (1\u2212 \ud835\udc5dmin)) \ud835\udc5a.\nThe last kind of verification error for \ud835\udc493 is getting tricked into running forever by an evil prover when given a non-member input string. The probabilistic timer function, when in play with probability \ud835\udc5dtimer, will keep \ud835\udc493 from running forever. The probability of \ud835\udc493 looping on the \ud835\udc56th round of its verification is at most max(\ud835\udf001, (1\u2212 \ud835\udc5dmin))\ud835\udc56\u22121 \u00b7 \ud835\udc5dsimulation (since it should pass\n5Our definitions allow \ud835\udc492 to reject members of \ud835\udc3f with some small probability.\nthe first \ud835\udc56\u2212 1 rounds without rejecting in that case). The probability that \ud835\udc493 can be fooled to loop is at most the sum of those probabilities, i.e.,\n\ud835\udf00 loop 3 \u2264 \ud835\udc5dsimulation \u00b7 \u2211\ufe00\ud835\udc5a\u22121 \ud835\udc56=0 max(\ud835\udf001, (1\u2212 \ud835\udc5dmin)) \ud835\udc56.\nThe overall error bound of \ud835\udc493 is the maximum of all three, i.e., \ud835\udf003 = max (\ufe01 \ud835\udf00+3 , \ud835\udf00 \u2212 3 , \ud835\udf00 loop 3 )\ufe01 .\nSince all of these bounds can be lowered arbitrarily to any positive constant (by first increasing \ud835\udc5a to constrain \ud835\udf00\u22123 , and then decreasing \ud835\udc5dsimulation > 0 and \ud835\udf00premature > 0 to constrain the other two), \ud835\udf003 can also be lowered to any desired positive constant.\nPolynomial expected runtime with arbitrarily high probability. With \ud835\udf00loop3 set to a desired small value, \ud835\udc493 will be running for at most \ud835\udc5a rounds with the remaining high probability. At each of those rounds, \ud835\udc493 will either complete \ud835\udc492\u2019s simulation in O (\ufe00 \ud835\udc5b\ud835\udc61+1 )\ufe00 time or will operate\nas the probabilistic timer that has the expected runtime of O (\ufe00 \ud835\udc5b\ud835\udc61+2 )\ufe00 . Thus, it is expected to run\nin O (\ufe00 \ud835\udc5b\ud835\udc61+2 )\ufe00 time with arbitrarily high probability.\nLemma 7.\nIP(con-space, con-private-coins,poly*-public-coins,poly*-time) \u2286 IP(log-space,poly-public-coins,poly-time)."
        },
        {
            "heading": "More specifically, for any integer \ud835\udc61 > 1,",
            "text": "IP(con-space, con-private-coins,O (\ufe00 \ud835\udc5b\ud835\udc61 )\ufe00* -public-coins,O (\ufe00 \ud835\udc5b\ud835\udc61 )\ufe00* -time) \u2286\nIP(log-space,O (\ufe00 \ud835\udc5b\ud835\udc61+1 )\ufe00 -public-coins,O (\ufe00 \ud835\udc5b\ud835\udc61+1 )\ufe00 -time).\nProof. Let \ud835\udc491 be a (single-head) constant space verifier that uses at most \ud835\udc5f private coins and an unlimited budget of public coins to verify a language \ud835\udc3f, for some constant \ud835\udc5f. The three types of errors that \ud835\udc491 may commit are that\n\u2022 it might reject a member of \ud835\udc3f when communicating with an honest prover with some probability \ud835\udf00+1 ,\n\u2022 it might be tricked to accept a non-member of \ud835\udc3f with some probability \ud835\udf00\u22121 ,\n\u2022 it might be tricked to run forever when the input is not a member of \ud835\udc3f with some probability \ud835\udf00loop1 .\nWhen it is not running forever (i.e., with probability 1\u2212 \ud835\udf00loop1 ), \ud835\udc491 is expected to terminate in \ud835\udc531(\ud835\udc5b) \u2208 O (\ufe00 \ud835\udc5b\ud835\udc61 )\ufe00\nsteps where \ud835\udc61 > 1 is an integer. In the following, the prover that \ud835\udc491 interacts with will be named \ud835\udc431.\nA constant space public-coin (2\ud835\udc5f + \ud835\udc61)-head verifier \ud835\udc492 can verify \ud835\udc3f in polynomial time and with an error bound close to that of \ud835\udc491 as follows: \ud835\udc492 will run 2\ud835\udc5f parallel simulations (\u201csims\u201d) of\n\ud835\udc491, where the \ud835\udc56th sim \ud835\udc46\ud835\udc56 (for \ud835\udc56 \u2208 { 0, . . . , 2\ud835\udc5f \u2212 1 }) assumes its private random bits as the bits of the binary representation of the number \ud835\udc56 and uses the (\ud835\udc56+ 1)st head of \ud835\udc492. The prover that \ud835\udc492 interacts with, which we name \ud835\udc432, is supposed to mimic \ud835\udc431 by providing a 2\ud835\udc5f-tuple containing the symbols that \ud835\udc431 would send to each \ud835\udc46\ud835\udc56 at each step. At every step of its interaction, \ud835\udc492 performs the following three tasks:\n\u2022 It checks the communication symbol received from \ud835\udc432 to see if it is consistent with the simulated interaction that took place up to that point between \ud835\udc431 and the sims (as will be detailed below), rejecting otherwise.\n\u2022 It updates the simulated state information and moves the head corresponding to each sim in accordance with \ud835\udc491\u2019s transition function, the latest public coin outcome, the input symbol scanned by the corresponding head and the communication symbol received from \ud835\udc432 addressed to that sim.\n\u2022 It sends \ud835\udc432 a 2\ud835\udc5f-tuple containing the communication symbols emitted by all the sims at the present step.\nThe consistency check mentioned above is necessary for the following reason: Consider two distinct sims which correspond to two probabilistic paths that emit precisely the same sequence of communication symbols up to a certain point during an interaction of \ud835\udc491 with \ud835\udc431. Since \ud835\udc431 is unable to determine which of these two paths it is talking to at that point, it cannot send different communication symbols to these sims. \ud835\udc492 is supposed to check that \ud835\udc432 respects this condition, and never sends different symbols to two sims whose communications have been identical since the beginning of the interaction. \ud835\udc492 can keep track of subsets of such similar-looking sims in its finite memory to implement this control at every step. \ud835\udc492 uses its remaining \ud835\udc61 heads to implement a deterministic clock that runs for \ud835\udc532(\ud835\udc5b) = \ud835\udc50\ud835\udc5b\ud835\udc61 steps (where \ud835\udc50 is a positive integer whose value ensures that \ud835\udc532(\ud835\udc5b) \u226b \ud835\udc531(\ud835\udc5b), and determines the error committed by \ud835\udc492, as will be described below) in the background.6 \ud835\udc492 makes its decision when the clock times out by picking one of the sims at random with equal probability by the result of \ud835\udc5f public coin tosses. It accepts if the chosen sim has accepted on time, and rejects otherwise. \ud835\udc492 is not able to carry out a \u201cperfect\u201d simulation of \ud835\udc491 (with identical acceptance and rejection probabilities) because of the strict bound on its runtime. This causes \ud835\udc492\u2019s decisions to differ from those of \ud835\udc491 in the following two ways:\n1. \ud835\udc491 has a nonzero probability of accepting some inputs after running for more than \ud835\udc532(\ud835\udc5b) steps, whereas \ud835\udc492 rejects in branches of its simulation corresponding to such cases.\n2. \ud835\udc492 rejects and halts on each branch of its simulation corresponding to cases where \ud835\udc491 is tricked to run forever.\nLet \ud835\udf00+2 and \ud835\udf00 \u2212 2 be the counterparts in \ud835\udc492 of the errors \ud835\udf00 + 1 and \ud835\udf00 \u2212 1 , respectively. (\ud835\udc492 can not be fooled into looping, so we do not have to worry about that type of error.) Let us analyze how the two differences described above affect the errors of \ud835\udc492 compared to those of \ud835\udc491.\n6See [6, Lemma 3] for an explanation of how such a clock can be constructed for any desired value of \ud835\udc50.\n\ud835\udf00\u22122 is at most \ud835\udf00 \u2212 1 , since none of the differences between \ud835\udc492 and \ud835\udc491 can cause an increase in\nan acceptance probability. \ud835\udf00+2 is greater than \ud835\udf00 + 1 by the probability that \ud835\udc491 runs longer than \ud835\udc532(\ud835\udc5b) steps and then accepts. By definition, the expected runtime of \ud835\udc491 is \ud835\udc531(\ud835\udc5b) when it is not running forever (i.e., with probability 1\u2212 \ud835\udf00loop1 ). By Markov\u2019s inequality, the probability that \ud835\udc491 runs for more than \ud835\udc532(\ud835\udc5b) steps when it is not running forever is at most \ud835\udc531(\ud835\udc5b)/\ud835\udc532(\ud835\udc5b). This difference can be reduced by increasing \ud835\udc50, thus bringing \ud835\udf00+2 arbitrarily close to \ud835\udf00 + 1 , and proving our claim that the overall error bound of \ud835\udc492 is close to that of \ud835\udc491. We will conclude the proof by demonstrating \ud835\udc493, a standard public coin log-space verifier with a single input head that verifies the same language. The naive way of simulating a multi-head machine by a logarithmic space machine is rather straightforward. Specifically, \ud835\udc493 can keep \ud835\udc492\u2019s head indices in multiple tracks of its work tape in binary format. (To accommodate for 2\ud835\udc5f + \ud835\udc61 tracks in the work tape, \ud835\udc493 should use a work tape alphabet of size 22\n\ud835\udc5f+\ud835\udc61.) In each simulated transition of \ud835\udc492, to decipher what \ud835\udc492 is reading with its 2\ud835\udc5f + \ud835\udc61 heads, \ud835\udc493 will carry out the following steps:\n1. Move the input head to \u25b7. 2. Do the following for all \ud835\udc56 \u2208 { 1, . . . , 2\ud835\udc5f + \ud835\udc61 }: 3. Decrement the index on the \ud835\udc56th track of the work tape and move the input head to the right. Repeat this until the index becomes 0. 4. Register the symbol under the input head as \ud835\udc65\ud835\udc56. 5. Increment the index on the \ud835\udc56th track of the work tape and move the input head to the left.\nRepeat this until the head is reading \u25b7.\nHaving learned the symbols \ud835\udc651, . . . , \ud835\udc652\ud835\udc5f+\ud835\udc61 scanned by the simulated \ud835\udc492\u2019s heads, \ud835\udc493 can use the latest public coin flip and consult the communication cell to complete a simulated transition of \ud835\udc492, updating the work tape contents to reflect the new head positions of \ud835\udc492 by incrementing or decrementing the indices on the respective tracks. Note that the matching prover, \ud835\udc433, which is supposed to send the messages that \ud835\udc432 would be sending for each simulated step, will send \u201cfiller\u201d symbols (all of which will be ignored by \ud835\udc493) through the communication cell while it waits for \ud835\udc493 to complete these walks on its work tape. \ud835\udc493 accepts the input only if it is convinced that \ud835\udc492 accepts the same as a result of this interaction. \ud835\udc493\u2019s runtime is simply the runtime of \ud835\udc492 multiplied by the overhead of simulating multiple input heads within the logarithmic work tape. Counting from 0 to \ud835\udc5b (or down from \ud835\udc5b to 0) in binary takes O(\ud835\udc5b) time for a Turing machine by amortized analysis. Incrementing or decrementing binary numbers with \u2308log \ud835\udc5b\u2309 digits takes O(log \ud835\udc5b) time. As a result, using the naive method of simulation explained above, \ud835\udc493 is expected to run in O (\ufe00 \ud835\udc5b\ud835\udc61+1 )\ufe00 time.\nThe runtime of \ud835\udc493 in Lemma 7 can be improved by introducing 2\ud835\udc5f + \ud835\udc61 logarithmically-long caches in the memory, one for each head of the simulated \ud835\udc492, each containing the slice from the input string where the corresponding head resides at that time. This slightly more advanced way of simulating multiple heads using logarithmic space (which has been previously used and demonstrated in detail in [6]) saves \ud835\udc493 a factor of O(log \ud835\udc5b) in runtime, but we stuck with the naive method for its sufficiency and simplicity.\nTheorem 8. NC \u2286 IP(con-space, con-private-coins,O(\ufe00\ud835\udc5b4)\ufe00*-public-coins,O(\ufe00\ud835\udc5b4)\ufe00*-time). Proof. It is known [8] that NC \u2286 IP(log-space, 0-private-coins,O(\ufe00\ud835\udc5b log2 \ud835\udc5b)\ufe00-public-coins,O(\ufe00\ud835\udc5b log2 \ud835\udc5b)\ufe00-time). Since log2 \ud835\udc5b \u2208 O(\ud835\udc5b) by standard asymptotic analysis, we also have NC \u2286 IP(log-space, 0-private-coins,O(\ufe00\ud835\udc5b2)\ufe00-public-coins,O(\ufe00\ud835\udc5b2)\ufe00-time). The claimed result then follows directly from Lemma 6."
        },
        {
            "heading": "4. Concluding remarks",
            "text": "This line of research can be expanded with various further questions. Although we mentioned the effect of cutting off the usage of public coins completely (Fact 4), we did not consider the results of imposing a tight budget on the number of public coins that the verifier can flip. (The \u201cclock\u201d head\u2019s random walk in Section 2.4 has an expected cost of polynomially many such flips.) It would be interesting, for instance, to ask whether Condon and Ladner\u2019s result stating that logarithmic space verifiers that flip only logarithmically many public coins can not verify any language outside the class LOGCFL [9] has a counterpart for the constant space case or not."
        },
        {
            "heading": "Acknowledgments",
            "text": "The authors thank the anonymous referees for their comments. This research was partially supported by Bo\u011fazi\u00e7i University Research Fund Grant Number 19441. Utkan Gezer\u2019s participation in this work is supported by the Turkish Directorate of Strategy and Budget under the TAM Project number 2007K12-873."
        },
        {
            "heading": "Appendix",
            "text": ""
        },
        {
            "heading": "A.1. Proof of Theorem 1",
            "text": "Proof. Let \ud835\udc40 be any logarithmic space Turing machine as described in the theorem statement, and \ud835\udc3f be its language. Without loss of generality, let the work tape alphabet of \ud835\udc40 be the set of \ud835\udc50-digit binary numbers from 0 to 2\ud835\udc50 \u2212 1 where 0 corresponds to the blank symbol of the alphabet. Each transition of \ud835\udc40 (and any Turing machine in general) consists of two parts:\n1. \u201cSensing\u201d the current configuration; which involves taking account of the internal state of the machine and reading the symbols under all heads.\n2. \u201cActing\u201d on the current configuration; which can involve changing the internal state, the symbols under the work tape heads, and the positions of both the input and work tape heads.\nWe will construct a (\ud835\udc50+ 5)-head finite automaton \ud835\udc45, whose heads will be denoted \u210e1, . . . , \u210e\ud835\udc50, \u210e\ud835\udefc, \u210e\ud835\udefd , \u210e\ud835\udefe , \u210e\ud835\udeff , and \u210e\ud835\udf16. \ud835\udc45 is to recognize \ud835\udc3f by simulating \ud835\udc40 . It will maintain the positions of heads \u210e1 through \u210e\ud835\udc50 on the input tape to match the content of \ud835\udc40 \u2019s work tape, such that taking the \ud835\udc56th bit of each symbol on the work tape and concatenating them in reverse will form the binary number that represents the index (location) of \u210e\ud835\udc56 on the input tape (with the location of the leftmost cell containing \u25b7 denoted 0). \u210e\ud835\udefc will mimic \ud835\udc40 \u2019s input tape head exactly, and \u210e\ud835\udefd will mimic \ud835\udc40 \u2019s work tape head in its position, albeit being on the input tape of \ud835\udc45. The remaining three heads will be used to facilitate the manipulations of the indices of \u210e1 through \u210e\ud835\udc50, necessary to simulate \ud835\udc40 \u2019s memory.\n\ud835\udc45 will simulate each transition of \ud835\udc40 using a sequence of transitions of its own, as described below, and report the same decision as \ud835\udc40 . The rest of the proof describes the \u201csense\u201d and \u201cact\u201d parts of each simulated transition.\nSensing. \ud835\udc45 traces \ud835\udc40 \u2019s current state in its own finite memory and reads its input tape with \u210e\ud835\udefc to obtain the symbol \ud835\udc40 is scanning with its input head.\nObtaining the symbol under \ud835\udc40 \u2019s work tape head requires sophistication. Let \ud835\udc4f denote the index of \u210e\ud835\udefd , which is at the same index as \ud835\udc40 \u2019s work tape head in \ud835\udc40 \u2019s work tape. To decode the symbol under \ud835\udc40 \u2019s work tape head from the positions of heads \u210e1 through \u210e\ud835\udc50, the following routine will be carried out:\n0. (At this point, \u210e\ud835\udefe , \u210e\ud835\udeff , and \u210e\ud835\udf16 are guaranteed to be on \u25b7.) 1. Do the following for \ud835\udc56 = 1, . . . , \ud835\udc50: 2. Walk \u210e\ud835\udc56 to the left so that its index (on the input string) at the end of this walk equals\n\u230a\ud835\udc57/2\ud835\udc4f\u22121\u230b where \ud835\udc57 is the current index of \u210e\ud835\udc56. To achieve this, repeat the following until \u210e\ud835\udefd reads \u25b7:\n3. Move \u210e\ud835\udc56 to the left such that its index is \u201chalved\u201d, i.e., is reduced to \u230a\ud835\udc57/2\u230b from its original value \ud835\udc57.7\n7In detail, move \u210e\ud835\udc56 towards \u25b7 while moving \u210e\ud835\udeff to the right in every second movement of \u210e\ud835\udc56. Then, reidentify \u210e\ud835\udeff as \u210e\ud835\udc56, and vice versa.\n4. Move \u210e\ud835\udefd once to the left. 5. Check the parity of \u210e\ud835\udc56\u2019s index. If it is odd, \u201cread\u201d the \ud835\udc56th bit of the symbol under \ud835\udc40 \u2019s\nsimulated work tape head as 0. Otherwise, read it as 1.8\n6. Move \u210e\ud835\udc56 and \u210e\ud835\udefd back to their locations at the beginning of the procedure.9\nThe reader should note that \u210e1, . . . , \u210e\ud835\udc50, and \u210e\ud835\udefd (after the reidentifications) are located at exactly where they were before the procedure. We will justify the statement at Stage 0 by the end of this proof.\nThe procedure above completes the \u201csense\u201d part of the simulation of an \ud835\udc40 -transition. Sensing the current simulated state and the input symbol can be handled parallelly with the procedure described above, and would incur no additional time cost. \u201cReading\u201d the symbol under the simulated work tape head with the above procedure incurs up to\n\ud835\udc50 \u00b7 (\ud835\udc5b+ \ud835\udc5b/2 + \ud835\udc5b/4 + \u00b7 \u00b7 \u00b7+ 1\u23df \u23de Stages 2 and 5 ) \u2264 \ud835\udc50+ 2\ud835\udc50\ud835\udc5b\nsteps.\nActing. Updating the internal state and head positions of the simulated machine is again straightforward: \ud835\udc45 updates the simulated machine\u2019s state in its own finite memory. It also moves \u210e\ud835\udefc and \u210e\ud835\udefd , which mimic \ud835\udc40 \u2019s input and work tape heads, in the required directions, after simulating the changes in \ud835\udc40 \u2019s work tape contents at that step.\nChanging the work tape contents is accomplished as follows. Once again, let \ud835\udc4f denote the index of \u210e\ud835\udefd . To change \ud835\udc40 \u2019s simulated work tape\u2019s contents, \ud835\udc45 updates the positions of \u210e1 through \u210e\ud835\udc50 by moving each of them either 2\ud835\udc4f cells to the left (if the bit on that track of the simulated work tape symbol at the index \ud835\udc4f needs to be changed from 1 to 0) or to the right (if the change is from 0 to 1), or leave them where they are (if no change is needed at the corresponding bit), by doing the following:\n0. (At this point, \u210e\ud835\udefe , \u210e\ud835\udeff and \u210e\ud835\udf16 are guaranteed to be on \u25b7.) 1. Bring \u210e\ud835\udf16 to the 2\ud835\udc4fth index on the input tape. To do so, move \u210e\ud835\udf16 one step to the right, and\nthen repeat the following until \u210e\ud835\udefd reads \u25b7: 2. Move \u210e\ud835\udf16 to the right such that its index is doubled.10 3. Move \u210e\ud835\udefd once to the left and \u210e\ud835\udefe once to the right. 4. Reidentify \u210e\ud835\udefe as \u210e\ud835\udefd , and vice versa. 5. For all \ud835\udc56 between 1 and \ud835\udc50 where the transition being simulated changes the \ud835\udc56th bit of the\nsymbol under the simulated work tape head, do the following: 6. Move \u210e\ud835\udc56 to the right by 2\ud835\udc4f cells (with the help of \u210e\ud835\udf16)11 if the change is from 0 to 1, and to\nthe left otherwise. 8To do the parity check, move \u210e\ud835\udc56 to \u25b7; the parity is odd if \u210e\ud835\udc56 reaches there in an odd number of steps, and even otherwise. 9To do so, \u210e\ud835\udefe is made to mirror the movements of \u210e\ud835\udefd throughout, and \u210e\ud835\udf16 is made to mirror the movements of \u210e\ud835\udc56 as it is moving towards \u25b7 during the first execution of Stage 3. Finally, the mirror-pairs are reciprocally reidentified in Stage 6. 10In detail, move \u210e\ud835\udf16 to \u25b7 while moving \u210e\ud835\udeff to the right twice as fast. Then, reidentify \u210e\ud835\udeff as \u210e\ud835\udf16, and vice versa. 11In detail, move \u210e\ud835\udf16 to \u25b7 while moving \u210e\ud835\udc56 and \u210e\ud835\udeff to the right. Then, reidentify \u210e\ud835\udeff as \u210e\ud835\udf16, and vice versa.\n7. Move \u210e\ud835\udf16 to \u25b7.12\nOnce again, the reader should note that the head identified as \u210e\ud835\udefd is located at the same place at the start and end of this procedure.\nThe procedure above completes the \u201cact\u201d part of \ud835\udc40 \u2019s transition\u2019s simulation. Changing the simulated current state and the simulated input and work heads\u2019 positions would incur a single step by themselves, and are handled in parallel with the above procedure, thereby incurring no additional time. Finally, changing the symbol under the simulated work tape head with the above procedure incurs up to\n1 + 2 + 4 + 8 + \u00b7 \u00b7 \u00b7+ \ud835\udc5b\u23df \u23de Stage 1 + \ud835\udc50\ud835\udc5b\u23df \u23de Stg. 5 \u2264 1 + 2\ud835\udc5b+ \ud835\udc50\ud835\udc5b\nsteps. The two routines for reading and changing the simulated memory contents are carried out back to back, and they both leave the heads \u210e\ud835\udefe , \u210e\ud835\udeff , and \u210e\ud835\udf16 on the left end-marker as they finish. Moreover, these heads are on the left end-marker also when \ud835\udc45 begins its execution, by definition. The assumptions in Stage 0 of both routines are thus justified.\nThe two parts together take at most 1 + \ud835\udc50 + 2\ud835\udc5b + 3\ud835\udc50\ud835\udc5b steps, which is an upper bound to the multiplicative runtime overhead of \ud835\udc45 simulating \ud835\udc40 . Thus, \ud835\udc45 completes its simulation in \ud835\udc61(\ud835\udc5b) \u00b7 (1 + \ud835\udc50+ 2\ud835\udc5b+ 3\ud835\udc50\ud835\udc5b) steps."
        },
        {
            "heading": "A.2. Proof of Lemma 2",
            "text": "Proof. By the implications of \ud835\udc53(\ud835\udc5b) \u2208 O (\ufe00 \ud835\udc5b\ud835\udc61 )\ufe00 , let \ud835\udc50 > 0 and \ud835\udc5b0 > \ud835\udf00\u22121 be the integer constants large enough to satisfy \ud835\udc53(\ud835\udc5b) \u2264 \ud835\udc50 \u00b7 \ud835\udc5b\ud835\udc61 for all \ud835\udc5b \u2265 \ud835\udc5b0. The extra constraint upon \ud835\udc5b0 to be larger than \ud835\udf00\u22121 will be evident by the end of the proof. Then, let \ud835\udc40\ud835\udc61,\ud835\udc50,\ud835\udc5b0 be a constant-space verifier with the following algorithm:\n\ud835\udc40\ud835\udc61,\ud835\udc50,\ud835\udc5b0 = \u201cOn input \ud835\udc64: 1. If \ud835\udc5b < \ud835\udc5b0,13 pause for max (\ufe00 \ud835\udc53(\ud835\udc5b), \u2308\ufe00 \ud835\udc50 \u00b7 \ud835\udc5b\ud835\udc61+1 \u2309\ufe00)\ufe00 time-steps and halt.\n2. If \ud835\udc61 \u2264 1, move the input head back to \u25b7 while pausing it for \ud835\udc50\u2212 1 time-steps after each movement, then halt. 3. Repeat the following \u2308\ud835\udc61\u2309 times: 4. Move the input head to the beginning of \ud835\udc64. 5. Perform a random walk with the input head (i.e., repeatedly move the input\nhead towards left or right by the flips of a coin) until the input head reaches \u25b7 or \u25c1. Pause for \ud835\udc50\u2212 1 time-steps after each step moving the input head.\n6. If any of the last \u2308\ud835\udc61\u2309 random walks have ended with the input head reaching \u25b7, go back to Stage 3. 7. Halt.\u201d\n12This, in fact, is done by simply not moving \u210e\ud835\udeff and keeping it on \u25b7 as \u210e\ud835\udf16 is moving to \u25b7 during the last time Stage 6 is being performed. 13Note that this check brings the input head to the right end-marker.\nStage 1 initially takes \ud835\udc5b+ 1 steps to check whether \ud835\udc5b < \ud835\udc5b0. If so, \ud835\udc40\ud835\udc61,\ud835\udc50,\ud835\udc5b0 runs for a total of max(\ud835\udc53(\ud835\udc5b), \u2308\ufe00 \ud835\udc50 \u00b7 \ud835\udc5b\ud835\udc61+1 \u2309\ufe00 )+\ud835\udc5b+1 time-steps and then halts, which yields a runtime within desired bounds with certainty. When\ud835\udc5b \u2265 \ud835\udc5b0 and \ud835\udc61 \u2264 1, \ud835\udc40\ud835\udc61,\ud835\udc50,\ud835\udc5b0 halts after running for (\ud835\udc50+ 1)\u00b7(\ud835\udc5b+ 1) steps in Stages 1 and 2 combined, which is again within the expected and minimum time limits, and with certainty. The rest of the proof will examine the claims for \ud835\udc5b \u2265 \ud835\udc5b0 and \ud835\udc61 > 1.\nExpected runtime. Each random walk at Stage 5 is commonly known as the gambler\u2019s ruin, and the probability of each ending at the right-hand side of the input tape is (\ud835\udc5b+ 1)\u22121 by their Markov chain analysis [10, Section 7.1]. Consequently, the probability of having a \u201cterminating batch\u201d (a batch of \u2308\ud835\udc61\u2309 random walks where each of them ends up at the right-hand side of the input tape) is (\ud835\udc5b+ 1)\u2212\u2308\ud835\udc61\u2309.\nThe expected number of independent trials to observe a binomial event is the reciprocal of its occurrence probability [11, Section C.4]. Therefore the expected number of random walks until termination is \u2308\ud835\udc61\u2309 \u00b7 (\ud835\udc5b+ 1)\u2308\ud835\udc61\u2309.\nThe expected runtime of each random walk is \ud835\udc50\ud835\udc5b steps [10, Section 7.1]. The reset in Stage 4 takes exactly \ud835\udc5b+ 2 steps before the first random walk, and it is expected to take another\n(\ud835\udc5b+ 1)\u22121 \u00b7 (\ud835\udc5b+ 2)\u23df \u23de resetting from \u25c1 + (1\u2212 (\ud835\udc5b+ 1)\u22121) \u00b7 1\u23df \u23de resetting from \u25b7 = 2\nsteps before every subsequent one. Taking Stage 1 into account as well, the expected runtime of \ud835\udc40\ud835\udc61,\ud835\udc50,\ud835\udc5b0 is \u2308\ud835\udc61\u2309 \u00b7 (\ud835\udc5b+ 1)\u2308\ud835\udc61\u2309 \u00b7 (\ud835\udc50\ud835\udc5b+ 2) + 2\ud835\udc5b+ 1 \u2208 O (\ufe01 \ud835\udc5b\u2308\ud835\udc61\u2309+1 )\ufe01 .\nMinimum runtime. For simplicity, we note that the probability of a terminating batch occurring, (\ud835\udc5b+ 1)\u2212\u2308\ud835\udc61\u2309, is less than \ud835\udc5b\u2212\ud835\udc61.\nIt is evident that the execution of a terminating batch takes more than \u2308\ud835\udc61\u2309 \u00b7 \ud835\udc5b\ud835\udc50 \u2265 \ud835\udc61\ud835\udc5b\ud835\udc50 timesteps, and thus, in a time frame of \ud835\udc53(\ud835\udc5b) \u2264 \ud835\udc50 \u00b7 \ud835\udc5b\ud835\udc61 steps, there are at most \ud835\udc5b\ud835\udc61\u22121\ud835\udc61 opportunities for terminating batches to occur, which is less than \ud835\udc5b\ud835\udc61\u22121 (given \ud835\udc61 > 1).\nThe probability of an event with an occurrence probability less than \ud835\udc5b\u2212\ud835\udc61 happening at least once given less than \ud835\udc5b\ud835\udc61\u22121 opportunities, is less than\n\ud835\udc54\ud835\udc61(\ud835\udc5b) = 1\u2212 (\ufe00 1\u2212 \ud835\udc5b\u2212\ud835\udc61 )\ufe00\ud835\udc5b\ud835\udc61\u22121 .\nConsider its binomial series:14\n\ud835\udc54\ud835\udc61(\ud835\udc5b) = 1\u2212 (\ufe03 \u221e\u2211\ufe01 \ud835\udc58=0 (\u22121)\ud835\udc58 \u00b7 (\ufe02 \ud835\udc5b\ud835\udc61\u22121 \ud835\udc58 )\ufe02 \u00b7 \ud835\udc5b\u2212\ud835\udc61\ud835\udc58 )\ufe03\n= \ud835\udc5b\ud835\udc61\u22121\n\ud835\udc5b\ud835\udc61 \u2212 \ud835\udc5b\n\ud835\udc61\u22121 \ud835\udc5b\ud835\udc61 \u00b7 \ud835\udc5b \ud835\udc61\u22121 \u2212 1 2\ud835\udc5b\ud835\udc61 + \ud835\udc5b\ud835\udc61\u22121 \ud835\udc5b\ud835\udc61 \u00b7 \ud835\udc5b \ud835\udc61\u22121 \u2212 1 2\ud835\udc5b\ud835\udc61 \u00b7 \ud835\udc5b \ud835\udc61\u22121 \u2212 2 3\ud835\udc5b\ud835\udc61 \u2212 \u00b7 \u00b7 \u00b7\nSince the series is alternating and the magnitudes are decreasing, we have\n\ud835\udc54\ud835\udc61(\ud835\udc5b) < \ud835\udc5b\ud835\udc61\u22121\n\ud835\udc5b\ud835\udc61 = \ud835\udc5b\u22121.\n\ud835\udc54\ud835\udc61(\ud835\udc5b) constitutes an upper bound to the \u201cerror\u201d of \ud835\udc40\ud835\udc61,\ud835\udc50,\ud835\udc5b0 halting sooner than the desired lower bound of \ud835\udc53(\ud835\udc5b) time-steps. Since \ud835\udc54\ud835\udc61(\ud835\udc5b) is monotone decreasing, \ud835\udc54\ud835\udc61(?\u0304?) < \ud835\udf00 follows for all ?\u0304? \u2265 \ud835\udc5b0 (recalling that \ud835\udc5b0 > \ud835\udf00\u22121). With Stage 1 ensuring that \ud835\udc40\ud835\udc61,\ud835\udc50,\ud835\udc5b0 waits long enough for the strings shorter than \ud835\udc5b0 with probability 1, the probability of \ud835\udc40\ud835\udc61,\ud835\udc50,\ud835\udc5b0 halting prematurely will be less than \ud835\udf00 for strings of any length.\n14Thanks to obscurans at math.stackexchange for the walkthrough."
        }
    ],
    "title": "Finite State Verifiers with Both Private and Public Coins",
    "year": 2023
}