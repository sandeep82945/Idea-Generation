{
    "abstractText": "In an online community, new words come and go: today\u2019s haha may be replaced by tomorrow\u2019s lol. Changes in online writing are usually studied as a social process, with innovations diffusing through a network of individuals in a speech community. But unlike other types of innovation, language change is shaped and constrained by the grammatical system in which it takes part. To investigate the role of social and structural factors in language change, we undertake a large-scale analysis of the frequencies of nonstandard words in Reddit. Dissemination across many linguistic contexts is a predictor of success: words that appear in more linguistic contexts grow faster and survive longer. Furthermore, social dissemination plays a less important role in explaining word growth and decline than previously hypothesized.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ian Stewart"
        },
        {
            "affiliations": [],
            "name": "Jacob Eisenstein"
        }
    ],
    "id": "SP:26f8e47b37682b180064da69200fc0b72506ae97",
    "references": [
        {
            "authors": [
                "Eduardo Altmann",
                "Janet Pierrehumbert",
                "Adilson Motter."
            ],
            "title": "Niche as a determinant of word fate in online groups",
            "venue": "PLoS ONE, 6(5):1\u201312.",
            "year": 2011
        },
        {
            "authors": [
                "Jannis Androutsopoulos."
            ],
            "title": "Language change and digital media: a review of conceptions and evidence",
            "venue": "Kristiansen Tore and Nikolas Coupland, editors, Standard Languages and Language Standards in",
            "year": 2011
        },
        {
            "authors": [
                "Joshua D Angrist",
                "Guido W Imbens",
                "Donald B Rubin."
            ],
            "title": "Identification of Causal Effects Using Instrumental Variables",
            "venue": "Source Journal of the American Statistical Association, 91(434):444\u2013455.",
            "year": 1996
        },
        {
            "authors": [
                "Eytan Bakshy",
                "Jake Hofman",
                "Winter Mason",
                "Duncan Watts."
            ],
            "title": "Everyone\u2019s an influencer: quantifying influence on Twitter",
            "venue": "Proceedings of the International Conference on Web Search and Data Mining, pages 65\u201374.",
            "year": 2011
        },
        {
            "authors": [
                "Mary Bucholtz."
            ],
            "title": "Why be normal?\": Language and identity practices in a community of nerd girls",
            "venue": "Language in Society, 28:203\u2013223.",
            "year": 1999
        },
        {
            "authors": [
                "Joan L. Bybee."
            ],
            "title": "From Usage to Grammar: The Mind\u2019s Response to Repetition",
            "venue": "Language, 82(4):711\u2013733.",
            "year": 2006
        },
        {
            "authors": [
                "Rena Torres Cacoullos",
                "James Walker."
            ],
            "title": "The Present of the English Future: Grammatical Variation and Collocations in Discourse",
            "venue": "Language, 85(2):321\u2013354.",
            "year": 2009
        },
        {
            "authors": [
                "Paula Chesley",
                "Harald Baayen."
            ],
            "title": "Predicting new words from newer words: Lexical borrowings in French",
            "venue": "Linguistics, 48(6):1343\u20131374.",
            "year": 2010
        },
        {
            "authors": [
                "Paul Cook."
            ],
            "title": "Exploiting linguistic knowledge to infer properties of neologisms",
            "venue": "Ph.D. thesis, University of Toronto.",
            "year": 2010
        },
        {
            "authors": [
                "Paul Cook",
                "Suzanne Stevenson."
            ],
            "title": "Automatically identifying the source words of lexical blends in English",
            "venue": "Computational Linguistics, 36(1):129\u2013 149.",
            "year": 2010
        },
        {
            "authors": [
                "David Cox."
            ],
            "title": "Regression models and life tables",
            "venue": "Journal of the Royal Statistical Society, 34:187\u2013220.",
            "year": 1972
        },
        {
            "authors": [
                "Cristian Danescu-Niculescu-Mizil",
                "Robert West",
                "Dan Jurafsky",
                "Christopher Potts."
            ],
            "title": "No Country for Old Members: User Lifecycle and Linguistic Change in Online Communities",
            "venue": "Proceedings of the International Conference on World Wide Web, pages",
            "year": 2013
        },
        {
            "authors": [
                "Alexandra D\u2019Arcy",
                "Sali Tagliamonte"
            ],
            "title": "Not always variable: probing the vernacular",
            "venue": "grammar. Language Variation and Change,",
            "year": 2015
        },
        {
            "authors": [
                "Patrick Drouin",
                "Pascaline Dury."
            ],
            "title": "When terms disappear from a specialized lexicon: A semiautomatic investigation into necrology",
            "venue": "Actes de la conf\u00e9rence internationale \u201cLanguage for Special Purposes\u201d.",
            "year": 2009
        },
        {
            "authors": [
                "BK Dumas",
                "Jonathan Lighter"
            ],
            "title": "Is slang a word for linguists? American Speech, 53(1):5\u201317",
            "year": 1978
        },
        {
            "authors": [
                "Leo Egghe."
            ],
            "title": "Untangling Herdan\u2019s law and Heaps\u2019 Law: Mathematical and informetric arguments",
            "venue": "Journal of the American Society for Information Science and Technology, 58(5):702\u2013709.",
            "year": 2007
        },
        {
            "authors": [
                "Devin Gaffney",
                "J. Nathan Matias."
            ],
            "title": "Caveat emptor, computational social science: Large-scale missing data in a widely-published reddit corpus",
            "venue": "PLoS ONE, 13(7).",
            "year": 2018
        },
        {
            "authors": [
                "Matt Garley",
                "Julia Hockenmaier."
            ],
            "title": "Beefmoves: dissemination, diversity, and dynamics of English borrowings in a German hip hop forum",
            "venue": "Proceedings of the Association of Computational Linguistics, pages 135\u2013139.",
            "year": 2012
        },
        {
            "authors": [
                "Eric Gilbert."
            ],
            "title": "Widespread Underprovision on Reddit",
            "venue": "Proceedings of the Conference on Computer-Supported Cooperative Work, pages 803\u2013 808.",
            "year": 2013
        },
        {
            "authors": [
                "Kevin Gimpel",
                "Nathan Schneider",
                "Brendan O\u2019Connor",
                "Dipanjan Das",
                "Daniel Mills",
                "Jacob Eisenstein",
                "Michael Heilman",
                "Dani Yogatama",
                "Jeffrey Flanigan",
                "Noah Smith"
            ],
            "title": "Part-of-speech tagging for Twitter: Annotation, features, and experiments",
            "year": 2011
        },
        {
            "authors": [
                "Jack Grieve."
            ],
            "title": "Natural selection in the modern English Lexicon",
            "venue": "International Conference on Language Evolution, pages 153\u2013157.",
            "year": 2018
        },
        {
            "authors": [
                "Jack Grieve",
                "Andrea Nini",
                "Diansheng Guo."
            ],
            "title": "Analyzing lexical emergence in Modern American English online",
            "venue": "English Language and Linguistics, 20(2):1\u201329.",
            "year": 2016
        },
        {
            "authors": [
                "Jack Hessel",
                "Chenhao Tan",
                "Lillian Lee."
            ],
            "title": "Science, AskScience, and BadScience: On the coexistence of highly related communities",
            "venue": "Proceedings of the International Conference on Social and Web Media, pages 171\u2013180.",
            "year": 2016
        },
        {
            "authors": [
                "Keisuke Hirano",
                "Guido W Imbens."
            ],
            "title": "The propensity score with continuous treatments",
            "venue": "Andrew Gelman and Xiao-Li Meng, editors, Applied Bayesian modeling and causal inference from incomplete-data perspectives, pages 73\u201384. Wiley,",
            "year": 2004
        },
        {
            "authors": [
                "Guido W Imbens."
            ],
            "title": "The role of the propensity score in estimating dose-response functions",
            "venue": "Biometrika, 87(3):706\u2013710.",
            "year": 2000
        },
        {
            "authors": [
                "Rika Ito",
                "Sali Tagliamonte."
            ],
            "title": "Well weird, right dodgy, very strange, really cool: Layering and recycling in English intensifiers",
            "venue": "Language in Society, 32:257\u2013279.",
            "year": 2003
        },
        {
            "authors": [
                "Daniel Kershaw",
                "Matthew Rowe",
                "Patrick Stacey."
            ],
            "title": "Towards Modelling Language Innovation Acceptance in Online Social Networks",
            "venue": "Proceedings of the ACM International Conference on Web Search and Data Mining, pages 553\u2013562.",
            "year": 2016
        },
        {
            "authors": [
                "John Klein",
                "Melvin Moeschberger."
            ],
            "title": "Survival analysis: techniques for censored and truncated data",
            "venue": "Springer Science & Business Media, New York.",
            "year": 2005
        },
        {
            "authors": [
                "Farshad Kooti",
                "Winter A Mason",
                "Krishna P Gummadi",
                "Meeyoung Cha."
            ],
            "title": "Predicting emerging social conventions in online social networks",
            "venue": "Proceedings of the International Conference on Information and Knowledge Management, pages 445\u2013",
            "year": 2012
        },
        {
            "authors": [
                "Anthony S Kroch."
            ],
            "title": "Reflexes of grammar in patterns of language change",
            "venue": "Language Variation and Change, 1(3):199\u2013244.",
            "year": 1989
        },
        {
            "authors": [
                "William Kruskal."
            ],
            "title": "Relative importance by averaging over orderings",
            "venue": "The American Statistician, 41(1):6\u201310.",
            "year": 1987
        },
        {
            "authors": [
                "Vivek Kulkarni",
                "William Yang Wang."
            ],
            "title": "Simple Models for Word Formation in English Slang",
            "venue": "In Proceedings of the North American Association of Computational Linguistics, pages 1424\u20131434.",
            "year": 2018
        },
        {
            "authors": [
                "William Labov."
            ],
            "title": "Transmission and Diffusion",
            "venue": "Language, 83(2):344\u2013387.",
            "year": 2007
        },
        {
            "authors": [
                "Marco Lui",
                "Timothy Baldwin."
            ],
            "title": "langid",
            "venue": "py: An off-the-shelf language identification tool. In Proceedings of the Association of Computational Linguistics, pages 25\u201330.",
            "year": 2012
        },
        {
            "authors": [
                "Brian MacWhinney."
            ],
            "title": "Competition and Lexical Categorization",
            "venue": "Linguistic Categorization, pages 195\u2013242.",
            "year": 1989
        },
        {
            "authors": [
                "Allan Metcalf."
            ],
            "title": "Predicting new words: The secrets of their success",
            "venue": "Houghton Mifflin, New York.",
            "year": 2004
        },
        {
            "authors": [
                "Alan Partington."
            ],
            "title": "Corpus evidence of language change: The case of the intensifier",
            "venue": "Mona Baker, Gill Francis, and Elena Tognini-Bonelli, editors, Text and Technology: In Honour of John Sinclair, pages 177\u2013192. John Benjamins Publishing,",
            "year": 1993
        },
        {
            "authors": [
                "Daniel Romero",
                "Brendan Meeder",
                "Jon Kleinberg."
            ],
            "title": "Differences in the mechanics of information diffusion across topics: idioms, political hashtags, and complex contagion on Twitter",
            "venue": "Proceedings of the International Conference on World Wide Web,",
            "year": 2011
        },
        {
            "authors": [
                "Lauren Squires."
            ],
            "title": "Enregistering internet language",
            "venue": "Language in Society, 39:457\u2013492.",
            "year": 2010
        },
        {
            "authors": [
                "Sali Tagliamonte",
                "Derek Denis."
            ],
            "title": "Linguistic ruin? LOL! Instant messaging and teen language",
            "venue": "American Speech, 83(1):3\u201334.",
            "year": 2008
        },
        {
            "authors": [
                "Chenhao Tan",
                "Lillian Lee."
            ],
            "title": "All who wander: On the prevalence and characteristics of multicommunity engagement",
            "venue": "Proceedings of the International Conference on World Wide Web, pages 1056\u20131066.",
            "year": 2015
        },
        {
            "authors": [
                "Scott Tonidandel",
                "James LeBreton",
                "Jeff Johnson."
            ],
            "title": "Determining the statistical significance of relative weights",
            "venue": "Psychological methods, 14(4):387.",
            "year": 2009
        },
        {
            "authors": [
                "Marco Del Tredici",
                "Raquel Fern\u00e1ndez."
            ],
            "title": "The Road to Success: Assessing the Fate of Linguistic Innovations in Online Communities",
            "venue": "Proceedings of the International Conference on Computational Linguistics, pages 1591\u20131603.",
            "year": 2018
        },
        {
            "authors": [
                "Oren Tsur",
                "Ari Rappoport."
            ],
            "title": "Don\u2019t Let Me Be #Misunderstood: Linguistically Motivated Algorithm for Predicting the Popularity of Textual Memes",
            "venue": "Proceedings of the International Conference on Social and Web Media, pages 426\u2013435.",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4360\u20134370 Brussels, Belgium, October 31 - November 4, 2018. c\u00a92018 Association for Computational Linguistics\n4360"
        },
        {
            "heading": "1 Introduction",
            "text": "Stop trying to make \u201cfetch\u201d happen! It\u2019s not going to happen! \u2013 Regina George (Mean Girls, 2005)\nWith the fast-paced and ephemeral nature of online discourse, language change in online writing is both prevalent (Androutsopoulos, 2011) and noticeable (Squires, 2010). In social media, new words emerge constantly to replace even basic expressions such as laughter: today\u2019s haha is tomorrow\u2019s lol (Tagliamonte and Denis, 2008). Why do some nonstandard words, like lol, succeed and spread to new contexts, while others, like fetch, fail to catch on? Can a word\u2019s growth be predicted from patterns of usage during its early days?\nLanguage change can be treated like other social innovations, such as the spread of hyperlinks (Bakshy et al., 2011) or hashtags (Romero et al., 2011; Tsur and Rappoport, 2015). A key\naspect of the adoption of a new practice is its dissemination: is it used by many people, and in many social contexts? High dissemination enables words to achieve greater exposure among social groups (Altmann et al., 2011), and may signal that the innovation is positively evaluated.\nIn addition to social constraints, language change is also shaped by grammatical constraints (D\u2019Arcy and Tagliamonte, 2015). New words and phrases rarely change the rules of the game but must instead find their place in a competitive ecosystem with finely-differentiated linguistic roles, or \u201cniches\u201d (MacWhinney, 1989). Some words become valid in a broad range of linguistic contexts, while others remain bound to a small number of fixed expressions. We therefore posit a structural analogue to social dissemination, which we call linguistic dissemination.\nWe compare the fates of such words to determine how linguistic and social dissemination each relate to word growth, focusing on the adoption of nonstandard words in the popular online community Reddit. The following hypotheses are evaluated:\n\u2022 H1: Nonstandard words with higher initial social dissemination are more likely to grow. Following the intuition that words require a large social base to succeed, we hypothesize a positive correlation between social dissemination and word growth. \u2022 H2-weak: Nonstandard words with higher\nlinguistic dissemination in the early phase of their history are more likely to grow. This follows from work in corpus linguistics showing that words and grammatical patterns with a higher diversity of collocations are more likely to be adopted (Ito and Tagliamonte, 2003; Partington, 1993).\n\u2022 H2-strong: Nonstandard words with higher linguistic dissemination are more likely to grow, even after controlling for social dissemination. This follows from the intuition that linguistic context and social context contribute differently to word growth.\nTo address H2, we develop a novel metric for characterizing linguistic dissemination, by comparing the observed number of n-gram contexts to the number of contexts that would be predicted based on frequency alone. Our analysis of word growth and decline includes: (1) prediction of frequency change in growth words (as in prior work); (2) causal inference of the influence of dissemination on probability of word growth; (3) binary prediction of future growth versus decline; and (4) survival analysis, to determine the factors that predict when a word\u2019s popularity begins to decline. All tests indicate that linguistic dissemination plays an important role in explaining the growth and decline of nonstandard words."
        },
        {
            "heading": "2 Related Work",
            "text": "Lexical change online Language changes constantly, and one of the most notable forms of change is the adoption of new words (Metcalf, 2004), sometimes referred to as lexical entrenchment (Chesley and Baayen, 2010). New nonstandard words may arise through the mutation of existing forms by processes such as truncation (e.g, favorite to fave; Grieve et al., 2016) and blending (e.g., web+log to weblog to blog; Cook and Stevenson, 2010). The fast pace and interconnected nature of online communication is particularly conducive to innovation, and social media provides a \u201cbirds-eye view\u201d on the process of change (Danescu-Niculescu-Mizil et al., 2013; Kershaw et al., 2016; Tsur and Rappoport, 2015).\nThe most closely related work is a contemporaneous study that explored the role of weak social ties in the dissemination of linguistic innovations on Reddit, which also proposed the task of quantitatively predicting the success or failure of lexical innovations (Tredici and Fern\u00e1ndez, 2018). One distinguishing feature of our work is the emphasis on linguistic (rather than social) context in explaining these successes and failures. In addition to predicting the binary distinction between success and failure, we also take on the more finegrained task of predicting the length of time that each nonstandard word will survive.\nSocial dissemination Language changes as a result of transmission across generations (Labov, 2007) as well as diffusion across individuals and social groups (Bucholtz, 1999). Such diffusion can be quantified with social dissemination, which Altmann et al. (2011) define as the count of social units (e.g., users) who have adopted a word, normalized by the expected count under a null model in which the word is used with equal frequency across the entire population. Altmann et al. (2011) use dissemination of words across forum users and threads to predict the words\u2019 change in frequency in Usenet, finding a positive correlation between frequency change and both kinds of social dissemination. In contrast, Garley and Hockenmaier (2012) use the same metric to predict the growth of English loanwords on German hip-hop forums, and find that social dissemination has less predictive power than expected. We seek to replicate these prior findings, and to extend them to the broader context of Reddit.\nLinguistic dissemination In historical linguistics, the distribution of a new word or construction across lexical contexts can signal future growth (Partington, 1993). Furthermore, grammatical and lexical factors can explain a speaker\u2019s choice of linguistic variant (Ito and Tagliamonte, 2003; Cacoullos and Walker, 2009) and can provide more insight than social factors alone. Our study proposes a generalizable method of measuring the dissemination of a word across lexical contexts with linguistic dissemination and compares social and linguistic dissemination as predictors of language change."
        },
        {
            "heading": "3 Data",
            "text": "Our study examines the adoption of words on social media, and we focus on Reddit as a source of language change. Reddit is a social content sharing site separated into distinct sub-communities or \u201csubreddits\u201d that center around particular topics (Gilbert, 2013). Reddit is a socially diverse and dynamic online platform, making it an ideal environment for research on language change (Kershaw et al., 2016). Furthermore, because Reddit data is publicly available we expect that this study can be more readily replicated than a similar study on other platforms such as Facebook or Twitter, whose data is less easily obtained.\nWe analyze a set of public monthly Reddit comments1 posted between 1 June 2013 and 31 May 2016, totalling T = 36 months of data. This dataset has been analyzed in prior work (Hessel et al., 2016; Tan and Lee, 2015) and has been noted to have some missing data (Gaffney and Matias, 2018), although this issue should not affect our analysis. To reduce noise in the data, we filter all comments generated by known bots and spam users2 and filter all comments created in well-known non-English subreddits.3 The final data collected is summarized in Table 1.\nWe replace all references to subreddits and users (marked by the convention r/subreddit and u/user) with r/SUB and u/USER tokens, and all hyperlinks with a URL token. We also reduce all repeated character sequences to a maximum length of three (e.g., loooool to loool). The final vocabulary includes the top 100,000 words by frequency.4 We replace all OOV words with UNK tokens, which comprise 3.95% of the total tokens."
        },
        {
            "heading": "3.1 Finding growth words",
            "text": "Our work seeks to study the growth of nonstandard words, which we identify manually instead of relying on pre-determined lists (Tredici and Fern\u00e1ndez, 2018).To detect such words, we first compute the Spearman correlation coefficient between the time steps {1...T} and each word w\u2019s frequency time series f (w)(1:T ) (frequency normalized and log-transformed). The Spearman correlation coefficient captures monotonic, gradual growth that characterizes the adoption of nonstan-\n1From http://files.pushshift.io/reddit/ comments/ (Accessed 1 October 2016).\n2The same list used in Tan and Lee (2015): https: //chenhaot.com/data/multi-community/ README.txt (Accessed 1 October 2016).\n3We randomly sampled 100 posts from the top 500 subreddits and labelled a subreddit as non-English if fewer than 90% of its posts were identified by langid.py (Lui and Baldwin, 2012) as English.\n4We restricted the vocabulary because of the qualitative analysis required to identify nonstandard words.\ndard words (Grieve et al., 2016; Kershaw et al., 2016).\nThe first set of words is filtered by a Spearman correlation coefficient above the 85th percentile (N = 15, 017). From this set of words, one of the authors manually identified 1,120 words in set G (\u201cgrowth\u201d) that are neither proper nouns (berniebot, killary, drumpf ) nor standard words (election, voting).5 These words were removed because their growth may be due to exogenous influence. A \u201cstandard\u201d word is one that can plausibly be found in a newspaper article, which follows from the common understanding of newspaper text as a more formal and standard register. Therefore, a \u201cnonstandard\u201d word is one that cannot plausibly be found in a newspaper article, a judgment often used by linguists to determine what counts as slang (Dumas and Lighter, 1978). In ambiguous cases, one of the authors inspected a sample of comments that included the word. We validate this process by having both authors annotate the top 200 growth candidates for standard/proper versus nonstandard (binary), obtaining inter-annotator agreement of \u03ba=0.79."
        },
        {
            "heading": "3.2 Finding decline words",
            "text": "To determine what makes the growth words successful, we need a control group of \u201cdecline\u201d words, which are briefly adopted and later abandoned. Although these words may have been successful before the time period investigated, their decline phase makes them a useful comparison for the growth words. We find such words by fitting two parametric models to the frequency series.\nPiecewise linear fit We fit a two-phase piecewise linear regression on each word\u2019s frequency time series f(1:T ), which splits the time series into f(1:t\u0302) and f(t\u0302+1:T ). The goal is to select a split point t\u0302 to minimize the sum of the squared error between observed frequency f and predicted frequency f\u0302 :\nf\u0302(m1,m2, b, t) = { b+m1t t \u2264 t\u0302 b+m1t\u0302+m2(t\u2212 t\u0302) t > t\u0302, (1) where b is the intercept, m1 is the slope of the first phase, and m2 is the slope of the second phase. Decline words Dp (\u201cpiecewise decline\u201d) display\n5Code and word lists available at: https://github.com/ianbstewart/ nonstandard_word_dissemination.\ngrowth in the first phase (m1 > 0), decline in the second phase (m2 < 0), and a strong fit between observed and predicted data, indicated by R2(f, f\u0302) above the 85th percentile (36.1%); this filtering yields 14,995 candidates.\nLogistic fit To account for smoother growthdecline trajectories, we also fit the growth curve to a logistic distribution, which is a continuous unimodal distribution with support over the nonnegative reals. We identify the set of candidates Dl (\u201clogistic decline\u201d) as words with a strong fit to this distribution, as indicated byR2 above the 99th percentile (82.4%), yielding 998 candidates. The logistic word set partially overlaps with the piecewise set, because some words\u2019 frequency time series show a strong fit to both the piecewise function and the logistic distribution.\nCombined set We combine the sets Dp and Dl to produce a set of decline word candidates (N = 15, 665). Next, we filter this combined set to exclude standard words and proper nouns, yielding a total of 530 decline words in set D. Each word is assigned a split point t\u0302 based on the estimated time of switch between the growth phase and the decline phase, which is the split point t\u0302 for piecewise decline words and the center of the logistic distribution \u00b5\u0302 for the logistic decline words.\nExamples of both growth and decline words are shown in Table 2. The growth words include several acronyms (tbh, \u201cto be honest\u201d; lmao, \u201claughing my ass off\u201d), while the decline words include clippings (atty, \u201catomizer\u201d), respellings (rekd, \u201cwrecked\u201d; wot, \u201cwhat\u201d) and compounds (nparent, \u201cnarcissistic parent\u201d).\nWe also provide a distribution of the words across word generation categories in Table 3, including compounds and clippings in similar proportions to prior work (Kulkarni and Wang, 2018). Because the growth and decline words exhibit similar proportions of category counts, we do not ex-\npect that this will be a significant confound in differentiating growth from decline."
        },
        {
            "heading": "4 Predictors",
            "text": "We now outline the predictors used to measure the degree of social and linguistic dissemination in the growth and decline words."
        },
        {
            "heading": "4.1 Social dissemination",
            "text": "We rely on the dissemination metric proposed by Altmann et al. (2011) to measure the degree to which a word occupies a specific social niche (e.g., low dissemination implies limited niche). To compute user dissemination DU for word w at time t, we first compute the number of individual users who used word w at time t, written U (w)t . We then compare this with the expectation U\u0303 (w)t under a model in which word frequency is identical across all users. The user dissemination is the log ratio,\nlog U\n(w) t U\u0303 (w) t = logU (w) t \u2212 log U\u0303 (w) t . (2)\nFollowing Altmann et al. (2011), the expected count U\u0303 (w)t is computed as,\nU\u0303 (w) t = \u2211 u\u2208Ut (1\u2212 e\u2212f (w) t m (u) t ), (3)\nwhere m(u)t equals the total number of words contributed by user u in month t, and Ut is the set of all users active in month t. This corresponds to a model in which each token from a user has identical likelihood f (w)t of being word w. In this way, we compute dissemination for all users (DU ), subreddits (DS) and threads (DT ) for each month t \u2208 {1...T}."
        },
        {
            "heading": "4.2 Linguistic dissemination",
            "text": "Linguistic dissemination captures the diversity of linguistic contexts in which a word appears, as measured by unique n-gram counts. We compute\nthe log count of unique trigram6 contexts for all words (C3) using all possible trigram positions: in the sentence \u201cthat\u2019s cool af haha\u201d, the term af appears in three unique trigrams, that\u2019s cool af, cool af haha, af haha <END>.\nThe unique log number of trigram contexts is strongly correlated with log word frequency (\u03c1(C3, f) = 0.904), as implied by Heaps\u2019 law (Egghe, 2007). We therefore adjust this statistic by comparing with its expected value C\u03033. At each timestep t, we fit a linear regression between log-frequency and log-unique n-gram counts, and then compute the residual between the observed log count of unique trigrams and its expectation, DL = C3t \u2212 C\u03033t . The residual DL, or linguistic dissemination, identifies words with a higher or lower number of lexical contexts than expected.\nLinguistic dissemination can separate words by grammatical category, as shown in Figure 1 where the mean DL values are computed for words across common part-of-speech categories. Partof-speech tags were computed over the entire corpus using a Twitter-based tagger (Gimpel et al., 2011), and each word type was assigned the most likely POS tag to provide an approximate distribution of tags over the vocabulary. Interjections have a lower medianDL than other word categories due to the tendency of interjections to occur in limited lexical contexts. Conversely, verbs have a higher median DL due to the flexibility of verbs\u2019 arguments (e.g., subject and object may both be openclass nouns)."
        },
        {
            "heading": "5 Results",
            "text": "The hypotheses about social and linguistic dissemination are tested under four analyses: correlation against frequency change in growth words; causal inference on probability of word growth; binary\n6Pilot analysis with bigram contexts gave similar results.\nprediction of word growth; and survival analysis of decline words."
        },
        {
            "heading": "5.1 Correlational analysis",
            "text": "To test the relative importance of the linguistic and social context on word growth, we correlate these metrics with frequency change (\u2206ft = ft \u2212 ft\u2212k) across all growth words. This replicates the methodology in prior work by Altmann et al. (2011) and Garley and Hockenmaier (2012), who analyzed different internet forums. Focusing on long-term change with k = 12 (one year) and k = 24 (two years), we compute the proportion of variance in frequency change explained by the covariates using a relative importance regression (Kruskal, 1987).7\nThe results of the regression are shown in Table 4. All predictors have relative importance greater than zero, according to a bootstrap method to produce confidence intervals (Tonidandel et al., 2009). Frequency is the strongest predictor (ft\u221212, ft\u221224), because words with low initial frequency often show the most frequency change. In both short- and long-term prediction, linguistic dissemination (DLt\u221212, D L t\u221224) has a higher relative importance than each of the social dissemination metrics. The social dissemination metrics have less explanatory power, in comparison with the other predictors and in comparison to the prior results of Garley and Hockenmaier (2012), who found 1.5% of variance explained by DU and 1.9% for DT at k = 24. Our results were robust to the exclusion of the predictor DL, meaning that\n7Relative importance regression implemented in the relaimpo package in R: https://cran.r-project. org/package=relaimpo\na model with only the social dissemination metrics as predictors resulted in a similar proportion of variance explained. The weakness of social dissemination could be due to the fragmented nature of Reddit, compared to more intra-connected forums. Since users and threads are spread across many different subreddits, and users may not visit multiple subreddits, a higher social dissemination for a particular word may not lead to immediate growth."
        },
        {
            "heading": "5.2 Causal analysis",
            "text": "While correlation can help explain the relationship between dissemination and frequency change, it only addresses the weak version of H2: it does not distinguish the causal impact of linguistic and social dissemination. To test the strong version of H2, we turn to a causal analysis, in which the outcome is whether a nonstandard word grows or declines, the treatment is a single dissemination metric such as linguistic dissemination, and the covariates are the remaining dissemination metrics. The goal of this analysis is to test the impact of each dissemination metric, while holding the others constant.\nCausal inference typically uses a binary treatment/control distinction (Angrist et al., 1996), but in this case the treatment is continuous. We therefore turn to an adapted model known as the average dose response function to measure the causal impact of dissemination (Imbens, 2000). To explain the procedure for estimating the average dose response, we adopt the following terminology: Z for treatment variable, X for covariates, Y for outcome.8\n1. A linear model is fit to estimate the treatment from the covariates,\nZi | Xi \u223c N (\u03b2>Xi, \u03c32). (4)\nThe output of this estimation procedure is a vector of weights \u03b2\u0302 and a variance \u03c3\u03022.\n2. The generalized propensity score (GPS) R is the likelihood of observing the treatment given the covariates, P (Zi | Xi). It is computed from the parameters estimated in the\n8Average dose response function implemented in the causaldrf package in R: https://cran.r-project. org/package=causaldrf\nprevious step:\nR\u0302i = 1\u221a\n2\u03c0\u03c3\u03022 exp\n( \u2212(Zi \u2212 \u03b2\u0302 >Xi) 2\n2\u03c3\u03022\n) .\n(5)\n3. A logistic model is fit to predict the outcome Yi using the treatment Zi and the GPS R\u0302i:\nY\u0302i = Logistic(\u03b1\u03020 + \u03b1\u03021Zi + \u03b1\u03022R\u0302i). (6)\nThis involves estimating the parameters {\u03b1\u03020, \u03b1\u03021, \u03b1\u03022.} By incorporating the generalized propensity score R\u0302i into this predictive model over the outcome, it is possible to isolate the causal effect of the treatment from the other covariates (Hirano and Imbens, 2004).\n4. The range of treatments is divided into levels (quantiles). The average dose response for a given treatment level sz is the mean estimated outcome for all instances at that treatment level,\n\u00b5\u0302(sz) = 1 |sz| \u2211 zi\u2208sz Y\u0302i. (7)\nThe average dose response function is then plotted for all treatment levels.\nEach dissemination metric is considered separately as a treatment. We consider all other dissemination metrics and frequency as covariates: e.g., for treatment variable DL, the covariates are set to [f,DU , DS , DT ]. We bootstrap the above process 100 times with different samples to produce confidence intervals. To balance the outcome classes, we sample an equal number of growth and decline words for each bootstrap iteration.\nThe average dose response function curves in Figure 2 show that linguistic dissemination (DL) produces the most dramatic increase in word growth probability. For linguistic dissemination, the lowest treatment quantile (0%-10%) yields a growth probability below 40% (significantly less than chance), as compared to the highest treatment quantile (90-100%), which yields a growth probability nearly at 70% (significantly greater than chance). This supports the strong form of H2, which states that linguistic dissemination is predictive of growth, even after controlling for the frequency and the other dissemination metrics. Subreddit dissemination also shows a mild causal effect on word growth, up to 60% in the highest treatment quantile. The other social dissemination metrics prove to have less effect on word growth."
        },
        {
            "heading": "5.3 Predictive analysis",
            "text": "We now turn to prediction to determine the utility of linguistic and social dissemination: using the first k months of data, can we predict whether a word will grow or decline in popularity? This is similar to previous work in predicting the success of lexical innovations (Kooti et al., 2012), but our goal is to compare the relative predictive power of various dissemination metrics, rather than to maximize accuracy.\nWe use logistic regression with 10-fold cross-validation over four different feature sets: frequency-only (f), frequency plus linguistic dissemination (f+L), frequency plus social dissemination (f+S) and all features (f+L+S). Each fold is balanced for classes so that the baseline accuracy is 50%. Figure 3 shows that linguistic dissemination provides more predictive power than social dissemination: the accuracy is consistently higher for the models with linguistic dissemination than for the frequency-only and social dissemination models. The accuracies\nconverge as the training data size increases, which suggests that frequency is a useful predictor if provided sufficient historical trajectory.\nPart-of-speech robustness check Considering the uneven distribution of linguistic dissemination across part-of-speech groups (Figure 1), the prediction results may be explained by an imbalance of word categories between the growth and decline words. This issue is addressed through two robustness checks: within-group comparison and prediction.\nFirst, we compare the distribution of linguistic dissemination values between growth and decline words, grouped by the most common POS tags (computed in \u00a7 4.2). Each decline word is matched with a growth word based on similar mean frequency in the first k = 12 months, and their mean linguistic dissemination values during that time period are compared, grouped within POS tag groups. The differences in Figure 4 show that across all POS tags, the growth words show a tendency toward higher linguistic dissemination with significant (p < 0.05) differences in the interjections, adjectives and verbs.\nNext, we add POS tags as additional features to the frequency-only model in the binary prediction task. The accuracy of a predictive model with access to frequency and POS features at k = 1 is 54.8%, which is substantially lower than the accuracy of the model with frequency and linguistic dissemination (cf. Figure 3).9 Thus, linguistic dissemination thus contributes predictive power beyond what is contributed by part-of-speech alone."
        },
        {
            "heading": "5.4 Survival analysis",
            "text": "Having investigated what separates growth from decline, we now focus on the factors that precede a decline word\u2019s \u201cdeath\u201d phase (Drouin and Dury, 2009).\nPredicting the time until a word\u2019s decline can be framed as survival analysis (Klein and Moeschberger, 2005), in which a word is said to \u201csurvive\u201d until the beginning of its decline phase at split point t\u0302. In the Cox proportional hazards model (Cox, 1972), the hazard of death \u03bb at each time t is modeled as a linear function of a vector of predictors,\n\u03bbi(t) = \u03bb0(t) exp(\u03b2 \u00b7 xi), (8)\nwhere xi is the vector of predictors for word i, and \u03b2 is the vector of coefficients. Each cell xi,j is set to the mean value of predictor j for word i over the training period t = {1...k} where k = 3.\nFor words which begin to decline in popularity in our dataset, we treat the point of decline as the \u201cdeath\u201d date. The remaining words are viewed as censored instances: they may begin to decline in popularity at some point in the future, but this time is outside our frame of observation. We use frequency, social dissemination and linguistic dissemination as predictors in a Cox regression model.10\nThe estimated coefficients from the regression are shown in Table 5. We find a negative coefficient for linguistic dissemination (\u03b2 = \u22120.330, p < 0.001), which mirrors the results from \u00a7 5.2: higher DL indicates a lower hazard of word death, and therefore a higher likelihood of survival. We also find that higher subreddit dissemination has a weak but insignificant correlation with a lower likelihood of word death (\u03b2 = \u22120.156, p > 0.05). Both of these results\n9Higher k values yield similar results. 10Cox regression implemented in the lifelines package in Python: https://lifelines.readthedocs.io/ en/latest/.\nlend additional support to the strong form of the hypothesis H2.\nThe predictive accuracy of survival analysis can be quantified by a concordance score. A score of 1.0 on heldout data indicates that the model perfectly predicts the order of death times; a score of 0.5 indicates that the predictions are no better than a chance ordering. We perform 10-fold cross-validation of the survival analysis model, and plot the results in Figure 5. The model with access to linguistic dissemination (f+L) consistently achieves higher concordance than the baseline frequency-only model (f), (t = 4.29, p < 0.001), and the model with all predictors f+L+S significantly outperforms the model with access only to frequency and social dissemination f+S (t = 4.64, p < 0.001). The result is reinforced by testing the goodness-of-fit for each model with model deviance, or difference from the null model. The f+L model has lower deviance, i.e. better fit, than the null model (\u03c72 = 93.3, p < 0.01), and the f+L+S does not have a significantly lower deviance than the f+L model (\u03c72 = 4.6, p = 0.80),\nsuggesting that adding social dissemination does not significantly improve model fit."
        },
        {
            "heading": "6 Discussion",
            "text": "All four analyses support H2: linguistic dissemination was the strongest predictor of monthly frequency changes in growth words, the best differentiator of growth and decline words in causal and predictive tasks, and the most effective warning sign that a word is about to decline. Linguistic dissemination can be related to theories such as the FUDGE factors (Chesley and Baayen, 2010; Cook, 2010; Metcalf, 2004), in which a word\u2019s growth depends on frequency (F), unobtrusiveness (U), diversity of users and situations (D), generation of other forms and meanings (G), and endurance (E). Linguistic dissemination provides an example of \u201cdiversity of situation.\u201d\nThe effectiveness of linguistic dissemination is exemplified in pairs of semantically similar growth and decline words. In the first k = 3 months of growth, the growth word kinda has a relatively high ratio of linguistic to frequency (D L\nf = 0.270) as compared with the semantically similar decline word sorta (0.055). This pattern holds for other pairs of semantically similar growth/decline words: fuckwit and fuckboy; lolno and lmao; yup and yas. While not exhaustive, such a trend suggests that the growth words were able to reach a wider range of lexical contexts and therefore succeed where the decline words failed.\nRegarding H1, we generally found a positive role for social dissemination as well, although these results were not consistent across all metrics and tests, particularly in the survival analysis. This matches the conclusion from Garley and Hockenmaier (2012), who argued that social dissemination is less predictive of word adoption than Altmann et al. (2011) originally suggested. One possible explanation is the inclusion of word categories such as proper nouns in the analysis of Altmann et al. (2011); the adoption of such terms may rely on social dynamics more than the adoption of nonstandard terms. The lower predictive power of thread and user dissemination is also interesting and suggests that subreddits are more socially salient in terms of exposing nonstandard words to potential adopters.\nLimitations One limitation in the study was the exclusion of orthographic and morphological features such as affixation, which has been noted\nas a predictor of word growth (Kershaw et al., 2016). Future work should incorporate these features as additional predictors. Our study also omitted borrowings, unlike prior work in word adoption that has focused on borrowings (Chesley and Baayen, 2010; Garley and Hockenmaier, 2012). Our early language-filtering steps eliminated most non-English words from the vocabulary, although it would have been interesting to examine loanword use in English-language posts. Finally, our study was limited by the focus on nonstandard words rather than memetic phrases (e.g., like a boss) which may show a similar correlation between dissemination, growth and decline (Bybee, 2006).\nFuture work We approximate linguistic dissemination using trigram counts, because they are easy to compute and they generalize across word categories. In future work, a more sophisticated approach might estimate linguistic dissemination with syntactic features such as appearance across different phrase heads (Kroch, 1989; Ito and Tagliamonte, 2003) or across nouns of different semantic classes (D\u2019Arcy and Tagliamonte, 2015). Future work should also investigate more semantically-aware definitions of linguistic dissemination. The existence of semantic \u201cneighbors\u201d occurring in similar contexts (e.g., the influence of standard intensifier very on nonstandard intensifier af ) may prevent a new word from reaching widespread popularity (Grieve, 2018)."
        },
        {
            "heading": "Acknowledgments",
            "text": "The authors thank the anonymous reviewers, the audience at NWAV 46 for discussion of an early presentation of this study, and the members of Georgia Tech\u2019s Computational Linguistics Lab for their help throughout the project. This research was supported by NSF award IIS1452443, AFOSR award FA9550-14-1-0379, and NIH award R01-GM112697-03."
        }
    ],
    "title": "Making \u201cfetch\u201d happen: The influence of social and linguistic context on nonstandard word growth and decline",
    "year": 2018
}