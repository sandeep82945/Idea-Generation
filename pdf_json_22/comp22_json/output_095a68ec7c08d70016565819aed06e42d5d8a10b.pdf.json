{
    "abstractText": "Diabetes is currently one of the most common, dangerous, and costly diseases globally caused by increased blood sugar or a decrease in insulin in the body. Diabetes can have detrimental effects on people\u2019s health if diagnosed late. Today, diabetes has become one of the challenges for health and government officials. Prevention is a priority, and taking care of people\u2019s health without compromising their comfort is an essential need. In this study, the ensemble training methodology based on genetic algorithms was used to diagnose and predict the outcomes of diabetes mellitus accurately. This study uses the experimental data, actual data on Indian diabetics on the University of California website. Current developments in ICT, such as the Internet of Things, machine learning, and data mining, allow us to provide health strategies with more intelligent capabilities to accurately predict the outcomes of the disease in daily life and the hospital and prevent the progression of this disease and its many complications. The results show the high performance of the proposed method in diagnosing the disease, which has reached 98.8%, and 99% accuracy in this study.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jafar Abdollahi"
        },
        {
            "affiliations": [],
            "name": "Babak Nouri-Moghaddam"
        }
    ],
    "id": "SP:e8aa1f0a66a7ad02ed51f1127ef69ed3715bbabc",
    "references": [
        {
            "authors": [
                "L. Garcia-Molina",
                "A.M. Lewis-Mikhael",
                "B. Riquelme-Gallego",
                "N. Cano-Ibanez",
                "M.J. Oliveras-Lopez",
                "A. Bueno-Cavanillas"
            ],
            "title": "Improving type 2 diabetes mellitus glycaemic control through lifestyle modification implementing diet intervention: a systematic review and meta-analysis",
            "venue": "Eur. J. Nutr. 59(4), 1313\u20131328",
            "year": 2020
        },
        {
            "authors": [
                "Y.Z. Liang",
                "J.J.H. Li",
                "H.B. Xiao",
                "Y. He",
                "L. Zhang",
                "Y.X. Yan"
            ],
            "title": "Identification of stress-relatedmicroRNAbiomarkers in type 2 diabetes mellitus: a systematic review and meta-analysis",
            "venue": "J. Diabetes 12(9), 633\u2013644",
            "year": 2020
        },
        {
            "authors": [
                "Y. Zhang",
                "X.F. Pan",
                "J. Chen",
                "L. Xia",
                "A. Cao",
                "Y Zhang"
            ],
            "title": "Combined lifestyle factors and risk of incident type 2 diabetes and prognosis among individuals with type 2 diabetes: a systematic review and meta-analysis of prospective cohort studies",
            "venue": "Diabetologia 63(1), 21\u201333",
            "year": 2020
        },
        {
            "authors": [
                "J.J. Wong",
                "A. Addala",
                "H. Abujaradeh",
                "R.N. Adams",
                "R.C. Barley",
                "Hanes",
                "S.J"
            ],
            "title": "Depression in context: Important considerations for youth with type 1 vs type 2 diabetes",
            "venue": "Pediatr. Diabetes 21(1), 135\u2013142",
            "year": 2020
        },
        {
            "authors": [
                "J. Abdollahi",
                "B.N. Moghaddam",
                "M.E. Parvar"
            ],
            "title": "Improving diabetes diagnosis in smart health using genetic-based Ensemble learning algorithm",
            "venue": "Approach to IoT Infrastructure. Future Gen. Distrib. Syst. J. 1, 23\u201330",
            "year": 2019
        },
        {
            "authors": [
                "S. Wang",
                "P. Ma",
                "S. Zhang",
                "S. Song",
                "Z. Wang",
                "Y Ma"
            ],
            "title": "Fasting blood glucose at admission is an independent predictor for 28-daymortality in patientswithCOVID-19without previous diagnosis of diabetes: a multi-centre retrospective study",
            "venue": "Diabetologia",
            "year": 2020
        },
        {
            "authors": [
                "P.P. Debata",
                "P. Mohapatra"
            ],
            "title": "Diagnosis of diabetes in pregnant woman using a Chaotic-Jaya hybridized extreme learning machine model",
            "venue": "J. Integr. Bioinform. 18, 81\u201399",
            "year": 2020
        },
        {
            "authors": [
                "M.S. Hossain",
                "G. Muhammad"
            ],
            "title": "Cloud-assisted industrial internet of things (iiot)\u2013enabled framework for health monitoring",
            "venue": "Comput. Netw. 101, 192\u2013202",
            "year": 2016
        },
        {
            "authors": [
                "A. Temko"
            ],
            "title": "Accurate wearable heart rate monitoring during physical exercises using PPG",
            "venue": "IEEE Trans. Biomed. Eng.",
            "year": 2017
        },
        {
            "authors": [
                "J.H. Abawajy",
                "M.M. Hassan"
            ],
            "title": "Federated internet of things and cloud computing pervasive patient healthmonitoring system",
            "venue": "IEEE Commun. Mag. 55(1), 48\u201353",
            "year": 2017
        },
        {
            "authors": [
                "H.J. La"
            ],
            "title": "A conceptual framework for trajectory-based medical analytics with IoT contexts",
            "venue": "J. Comput. Syst. Sci. 82(4), 610\u2013626",
            "year": 2016
        },
        {
            "authors": [
                "A.M. Rahmani",
                "T.N. Gia",
                "B. Negash",
                "A. Anzanpour",
                "I. Azimi",
                "M. Jiang",
                "P. Liljeberg"
            ],
            "title": "Exploiting smart e-health gateways at the edge of healthcare internet-of-things: a fog computing approach",
            "venue": "Futur. Gener. Comput. Syst. 78, 641\u2013658",
            "year": 2017
        },
        {
            "authors": [
                "P. Verma",
                "S.K. Sood"
            ],
            "title": "Cloud-centric IoT based disease diagnosis healthcare framework",
            "venue": "J Parallel Distrib. Comput. 116, 27\u201338",
            "year": 2018
        },
        {
            "authors": [
                "I.U. Din",
                "M. Guizani",
                "J.J. Rodrigues",
                "S. Hassan",
                "V.V. Korotaev"
            ],
            "title": "Machine learning in the Internet of Things: designed techniques for smart cities",
            "venue": "Futur. Gener. Comput. Syst. 100, 826\u2013843",
            "year": 2019
        },
        {
            "authors": [
                "International Warfarin Pharmacogenetics C",
                "T.E. Klein",
                "R.B. Altman",
                "N. Eriksson",
                "B.F. Gage",
                "Kimmel",
                "S.E"
            ],
            "title": "Estimation of the warfarin dose with clinical and pharmacogenetic data",
            "venue": "N. Engl. J.Med. 360(8), 753\u2013764 (2009).",
            "year": 2908
        },
        {
            "authors": [
                "Y.H. Hu",
                "F. Wu",
                "C.L. Lo",
                "C.T. Tai"
            ],
            "title": "Predicting warfarin dosage from clinical data: a supervised learning approach",
            "venue": "Artif. Intell. Med. 56(1), 27\u201334 (2012)."
        },
        {
            "authors": [
                "Y. Tao",
                "Y.J. Chen",
                "X. Fu",
                "B. Jiang",
                "Y. Zhang"
            ],
            "title": "Evolutionary ensemble learning algorithm to modeling warfarin dose prediction for Chinese",
            "venue": "IEEE J. Biomed. Health Inform. 23(1), 395\u2013406 (2018)."
        },
        {
            "authors": [
                "L. Breiman"
            ],
            "title": "Stacked regressions",
            "venue": "Mach. Learn. 24(1), 49\u201364",
            "year": 1996
        },
        {
            "authors": [
                "S.Q. Wang",
                "J. Yang",
                "K.C. Chou"
            ],
            "title": "Using stacked generalization to predict membrane protein types based on pseudo-amino acid composition",
            "venue": "J. Theor. Biol. 242(4), 941\u2013946 (2006)."
        },
        {
            "authors": [
                "P. Palimkar",
                "R.N. Shaw",
                "A. Ghosh"
            ],
            "title": "Machine learning technique to prognosis diabetes disease: random forest classifier approach",
            "venue": "Advanced Computing and Intelligent Technologies, pp. 219\u2013244. Springer, Singapore",
            "year": 2022
        },
        {
            "authors": [
                "H.F. Ahmad",
                "H. Mukhtar",
                "H. Alaqail",
                "M. Seliaman",
                "A. Alhumam"
            ],
            "title": "Investigating health-related features and their impact on the prediction of diabetes using machine learning",
            "venue": "Appl. Sci. 11(3), 1173",
            "year": 2021
        },
        {
            "authors": [
                "J. Li",
                "P. Yuan",
                "X. Hu",
                "J. Huang",
                "L. Cui",
                "J Cui"
            ],
            "title": "A tongue features fusion approach to predicting prediabetes and diabetes with machine learning",
            "venue": "J. Biomed. Inform. 115, 103693",
            "year": 2021
        },
        {
            "authors": [
                "T.G. Dietterich"
            ],
            "title": "Ensemble learning",
            "venue": "Handb. Brain Theory Neural Netw. 2(1), 110\u2013125",
            "year": 2002
        },
        {
            "authors": [
                "R. Polikar"
            ],
            "title": "Ensemble learning",
            "venue": "Ensemble Machine Learning, pp. 1\u201334. Springer, Boston",
            "year": 2012
        },
        {
            "authors": [
                "Z.H. Zhou"
            ],
            "title": "Ensemble learning",
            "venue": "Machine Learning, pp. 181\u2013210. Springer, Singapore",
            "year": 2021
        },
        {
            "authors": [
                "O. Sagi",
                "L. Rokach"
            ],
            "title": "Ensemble learning: A survey",
            "venue": "Wiley Interdiscip. Rev.: Data Min. Knowl. Discov. 8(4), e1249",
            "year": 2018
        },
        {
            "authors": [
                "M. Fatima",
                "M. Pasha"
            ],
            "title": "Survey of machine learning algorithms for disease diagnostic",
            "venue": "J. Intell. Learn. Syst. Appl. 9(01), 1",
            "year": 2017
        },
        {
            "authors": [
                "B. Ali\u0107",
                "L. Gurbeta",
                "A. Badnjevi\u0107"
            ],
            "title": "Machine learning techniques for classification of diabetes and cardiovascular diseases",
            "venue": "Embedded Computing (MECO), 2017 6th Mediterranean Conference on, pp. 1\u20134. IEEE",
            "year": 2017
        },
        {
            "authors": [
                "A. Kumar",
                "P. Kumar",
                "A. Srivastava",
                "V.A. Kumar",
                "K. Vengatesan",
                "A. Singhal"
            ],
            "title": "Comparative analysis of data mining techniques to predict heart disease for diabetic patients",
            "venue": "International Conference on Advances in Computing and Data Sciences, pp. 507\u2013518. Springer, Singapore",
            "year": 2020
        },
        {
            "authors": [
                "S. Saru",
                "S. Subashree"
            ],
            "title": "Analysis and prediction of diabetes using machine learning",
            "venue": "Int. J. Emerg. Tech. Innov. Eng. 5(4)",
            "year": 2019
        },
        {
            "authors": [
                "S. Subramaniyan",
                "R. Regan",
                "T. Perumal",
                "K. Venkatachalam"
            ],
            "title": "Semi-supervised machine learning algorithm for predicting diabetes using big data analytics",
            "venue": "Business Intelligence for Enterprise Internet of Things, pp. 139\u2013149. Springer, Cham",
            "year": 2020
        },
        {
            "authors": [
                "H. Yang",
                "Y. Luo",
                "X. Ren",
                "M. Wu",
                "X. He",
                "B Peng"
            ],
            "title": "Risk prediction of diabetes: big data mining with fusion of multifarious physical examination indicators",
            "venue": "Inform. Fusion 75, 140\u2013149",
            "year": 2021
        },
        {
            "authors": [
                "J.J. Beunza",
                "E. Puertas",
                "E. Garc\u00eda-Ovejero",
                "G. Villalba",
                "E. Condes",
                "G Koleva"
            ],
            "title": "Comparison of machine learning algorithms for clinical event prediction (risk of coronary heart disease)",
            "venue": "J. Biomed. Inform. 97, 103257",
            "year": 2019
        },
        {
            "authors": [
                "A.M. Zeki",
                "R. Taha",
                "S. Alshakrani"
            ],
            "title": "Developing a predictive model for diabetes using data mining techniques",
            "venue": "2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT), pp. 24\u201328. IEEE",
            "year": 2021
        },
        {
            "authors": [
                "G.D. Kalyankar",
                "S.R. Poojara",
                "N.V. Dharwadkar"
            ],
            "title": "Predictive analysis of diabetic patient data using machine learning and 123 Iran Journal of Computer Science (2022) 5:205\u2013220 219 Hadoop",
            "venue": "2017 international conference on I-SMAC (IoT in social, mobile, analytics and cloud)(I-SMAC), pp. 619\u2013624. IEEE",
            "year": 2017
        },
        {
            "authors": [
                "A. Rghioui",
                "A. Naja",
                "A. Oumnad"
            ],
            "title": "Diabetic patients monitoring and data classification using IoT application",
            "venue": "2020 International Conference on Electrical and Information Technologies (ICEIT), pp. 1\u20136. IEEE",
            "year": 2020
        },
        {
            "authors": [
                "T.N. Joshi",
                "P.P.M. Chawan"
            ],
            "title": "Diabetes prediction using machine learning techniques",
            "venue": "Ijera 8(1), 9\u201313",
            "year": 2018
        },
        {
            "authors": [
                "N. Sikder",
                "M. Masud",
                "A.K. Bairagi",
                "A.S.M. Arif",
                "A.A. Nahid",
                "H.A. Alhumyani"
            ],
            "title": "Severity classification of diabetic retinopathy using an ensemble learning algorithm through analyzing retinal images",
            "venue": "Symmetry 13(4), 670",
            "year": 2021
        },
        {
            "authors": [
                "B. Ihnaini",
                "M.A. Khan",
                "T.A. Khan",
                "S. Abbas",
                "M.S. Daoud",
                "M. Ahmad"
            ],
            "title": "A smart healthcare recommendation system for multidisciplinary diabetes patients with data fusion based on deep ensemble learning.Comput",
            "year": 2021
        },
        {
            "authors": [
                "M. Banchhor",
                "P. Singh"
            ],
            "title": "Comparative study of ensemble learning algorithms on early stage diabetes risk prediction",
            "venue": "2021 2nd International Conference for Emerging Technology (INCET), pp. 1\u20136. IEEE",
            "year": 2021
        },
        {
            "authors": [
                "M.M.H. Sabbir",
                "A. Sayeed",
                "Jamee",
                "M.A.U.Z."
            ],
            "title": "Diabetic retinopathy detection using texture features and ensemble learning",
            "venue": "2020 IEEE Region 10 Symposium (TENSYMP), pp. 178\u2013181. IEEE",
            "year": 2020
        },
        {
            "authors": [
                "L. Kopitar",
                "P. Kocbek",
                "L. Cilar",
                "A. Sheikh",
                "G. Stiglic"
            ],
            "title": "Early detection of type 2 diabetes mellitus using machine learning-based prediction models",
            "venue": "Sci. Rep. 10(1), 1\u201312",
            "year": 2020
        },
        {
            "authors": [
                "L.J. Muhammad",
                "E.A. Algehyne",
                "S.S. Usman"
            ],
            "title": "Predictive supervised machine learning models for diabetes mellitus",
            "venue": "SN Comput. Sci. 1(5), 1\u201310",
            "year": 2020
        },
        {
            "authors": [
                "N. Abdulhadi",
                "A. Al-Mousa"
            ],
            "title": "Diabetes detection using machine learning classification methods",
            "venue": "2021 International Conference on Information Technology (ICIT), pp. 350\u2013354. IEEE",
            "year": 2021
        },
        {
            "authors": [
                "H. Naz",
                "S. Ahuja"
            ],
            "title": "Deep learning approach for diabetes prediction using PIMA Indian dataset",
            "venue": "J. Diabetes Metab. Disord. 19(1), 391\u2013403",
            "year": 2020
        },
        {
            "authors": [
                "A. Al-Zebari",
                "A. Sengur"
            ],
            "title": "Performance comparison of machine learning techniques on diabetes disease detection",
            "venue": "2019 1st international informatics and software engineering conference (UBMYK), pp. 1\u20134. IEEE",
            "year": 2019
        },
        {
            "authors": [
                "V. Rawat",
                "S. Suryakant"
            ],
            "title": "A classification system for diabetic patients with machine learning techniques",
            "venue": "Int. J. Math. Eng. Manage. Sci. 4(3), 729\u2013744",
            "year": 2019
        },
        {
            "authors": [
                "J. Abdollahi",
                "B. Nouri-Moghaddam",
                "M. Ghazanfari"
            ],
            "title": "Deep neural network based ensemble learning algorithms for the healthcare system (diagnosis of chronic diseases)",
            "venue": "arXiv preprint arXiv:2103. 08182",
            "year": 2021
        },
        {
            "authors": [
                "J. Abdollahi",
                "B. Nouri-Moghaddam",
                "M. Ghazanfari"
            ],
            "title": "Deep neural network based ensemble learning algorithms for the healthcare system (diagnosis of chronic diseases) (2021)",
            "year": 2021
        },
        {
            "authors": [
                "N.A. Priyanka",
                "D. Kumar"
            ],
            "title": "Decision tree classifier: a detailed survey",
            "venue": "Int. J. Inf. Decis. Sci. 12(3), 246\u2013269",
            "year": 2020
        },
        {
            "authors": [
                "J.R. Quinlan"
            ],
            "title": "Induction of decision trees",
            "venue": "Mach. Learn. 1(1), 81\u2013106",
            "year": 1986
        },
        {
            "authors": [
                "S.D. Jadhav",
                "H.P. Channe"
            ],
            "title": "Comparative study of K-NN, naive Bayes and decision tree classification techniques",
            "venue": "Int. J. Sci. Res. 5(1), 1842\u20131845",
            "year": 2016
        },
        {
            "authors": [
                "T. Karthikeyan",
                "P. Thangaraju"
            ],
            "title": "PCA-NB algorithm to enhance the predictive accuracy",
            "venue": "Int. J. Eng. Tech 6(1), 381\u2013387",
            "year": 2014
        },
        {
            "authors": [
                "F. Amato",
                "A. L\u00f3pez",
                "E.M. Pe\u00f1a-M\u00e9ndez",
                "P. Va\u0148hara",
                "A. Hampl",
                "J. Havel"
            ],
            "title": "Artificial neural networks in medical diagnosis",
            "venue": "J. Appl. Biomed.",
            "year": 2013
        },
        {
            "authors": [
                "S. Vijayarani",
                "S. Dhayanand",
                "M. Phil"
            ],
            "title": "Kidney disease prediction using SVMandANNalgorithms",
            "venue": "Int. J Comput. Bus. Res. (IJCBR) 6(2), 1\u201312",
            "year": 2015
        },
        {
            "authors": [
                "J.C. Platt"
            ],
            "title": "12 fast training of support vector machines using sequential minimal optimization",
            "venue": "Adv. Kernel Methods 185\u2013208",
            "year": 1999
        },
        {
            "authors": [
                "S. Ruggieri"
            ],
            "title": "Efficient C4.5 [classification algorithm",
            "venue": "IEEE Trans. Knowl. Data Eng. 14(2),",
            "year": 2002
        },
        {
            "authors": [
                "A. Liaw",
                "M. Wiener"
            ],
            "title": "Classification and regression by randomForest",
            "venue": "R News 2(3), 18\u201322",
            "year": 2002
        },
        {
            "authors": [
                "E. Izquierdo-Verdiguier"
            ],
            "title": "Zurita-Milla, R.:An evaluation ofGuided Regularized Random Forest for classification and regression tasks in remote sensing",
            "venue": "Int. J. Appl. Earth Obs. Geoinf",
            "year": 2020
        },
        {
            "authors": [
                "Z. Zhang"
            ],
            "title": "Introduction to machine learning: k-nearest neighbors",
            "venue": "Ann. Transl. Med. 4(11), 218",
            "year": 2016
        },
        {
            "authors": [
                "A. Naimi",
                "L.B. Balzer"
            ],
            "title": "Stacked generalization: an introduction to super learning",
            "venue": "bioRxiv 172395",
            "year": 2017
        },
        {
            "authors": [
                "D.T. Bui",
                "T.C. Ho",
                "B. Pradhan",
                "B.T. Pham",
                "V.H. Nhu",
                "I. Revhaug"
            ],
            "title": "GIS-based modeling of rainfall-induced landslides using data mining-based functional trees classifier with AdaBoost, Bagging, and MultiBoost ensemble frameworks",
            "venue": "Environ. Earth Sci. 75(14), 1101",
            "year": 2016
        },
        {
            "authors": [
                "M.J. Del Jesus",
                "F. Hoffmann",
                "L.J. Navascu\u00e9s",
                "L. S\u00e1nchez"
            ],
            "title": "Induction of fuzzy-rule-based classifiers with evolutionary boosting algorithms",
            "venue": "IEEE Trans. Fuzzy Syst. 12(3), 296\u2013308",
            "year": 2004
        },
        {
            "authors": [
                "M. Kearns"
            ],
            "title": "Boosting theory towards practice: Recent developments in decision tree induction and the weak learning framework",
            "venue": "Proceedings of the National Conference on Artificial Intelligence, pp. 1337\u20131339",
            "year": 1996
        },
        {
            "authors": [
                "S. Choi",
                "Y.J. Kim",
                "S. Briceno",
                "D. Mavris"
            ],
            "title": "Prediction of weatherinduced airline delays based on machine learning algorithms",
            "venue": "2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC), pp. 1\u20136. IEEE",
            "year": 2016
        },
        {
            "authors": [
                "R.E. Schapire"
            ],
            "title": "The boosting approach to machine learning: An overview",
            "venue": "Nonlinear estimation and classification, pp. 149\u2013171. Springer, New York",
            "year": 2003
        },
        {
            "authors": [
                "S. Barik",
                "S. Mohanty",
                "S. Mohanty",
                "D. Singh"
            ],
            "title": "Analysis of prediction accuracy of diabetes using classifier and hybridmachine learning techniques",
            "venue": "Intelligent and Cloud Computing, pp. 399\u2013409. Springer, Singapore",
            "year": 2021
        },
        {
            "authors": [
                "M. Sewell"
            ],
            "title": "Ensemble learning",
            "venue": "RN 11(02), 1\u201334",
            "year": 2008
        },
        {
            "authors": [
                "N. Singh",
                "P. Singh"
            ],
            "title": "A stacked generalization approach for diagnosis and prediction of type 2 diabetes mellitus",
            "venue": "Computational Intelligence in Data Mining, pp. 559\u2013570. Springer, Singapore",
            "year": 2020
        },
        {
            "authors": [
                "N. Singh",
                "P. Singh"
            ],
            "title": "Stacking-based multi-objective evolutionary ensemble framework for prediction of diabetes mellitus",
            "venue": "Biocybern. Biomed. Eng. 40(1), 1\u201322",
            "year": 2020
        },
        {
            "authors": [
                "K.M. Kuo",
                "P. Talley",
                "Y. Kao",
                "C.H. Huang"
            ],
            "title": "A multi-class classification model for supporting the diagnosis of type II diabetes mellitus",
            "venue": "PeerJ 8, e9920",
            "year": 2020
        },
        {
            "authors": [
                "M. Bernardini",
                "M. Morettini",
                "L. Romeo",
                "E. Frontoni",
                "L. Burattini"
            ],
            "title": "Early temporal prediction of type 2 diabetes risk condition from a general practitioner electronic health record: a multiple instance boosting approach",
            "venue": "Artif. Intell. Med. 105, 101847",
            "year": 2020
        },
        {
            "authors": [
                "N. Mahendran",
                "P.D.R. Vincent",
                "K. Srinivasan",
                "V. Sharma",
                "D.K. Jayakody"
            ],
            "title": "Realizing a stacking generalization model to improve the prediction accuracy of major depressive disorder in adults",
            "venue": "IEEE Access 8, 49509\u201349522",
            "year": 2020
        },
        {
            "authors": [
                "F.A. Khan",
                "K. Zeb",
                "M. Alrakhami",
                "A. Derhab",
                "S.A.C. Bukhari"
            ],
            "title": "Detection and prediction of diabetes using data mining: a comprehensive review",
            "venue": "IEEE Access",
            "year": 2021
        },
        {
            "authors": [
                "S. Mirjalili"
            ],
            "title": "Evolutionary Algorithms and Neural Networks",
            "venue": "Studies in Computational Intelligence, vol. 780. Springer, Cham (2019) 123 220 Iran Journal of Computer Science",
            "year": 2022
        },
        {
            "authors": [
                "T.V. Mathew"
            ],
            "title": "Genetic algorithm",
            "venue": "Report submitted at IIT Bombay",
            "year": 2012
        },
        {
            "authors": [
                "J. Abdollahi",
                "A. Keshandehghan",
                "M. Gardaneh",
                "Y. Panahi",
                "M. Gardaneh"
            ],
            "title": "accurate detection of breast cancer metastasis using a hybrid model of artificial intelligence algorithm",
            "venue": "Arch. Breast Cancer",
            "year": 2020
        },
        {
            "authors": [
                "H.G. Zadeh",
                "H. Jamshidi",
                "A. Fayazi",
                "M.H. Gholizadeh",
                "C.A. Toussi",
                "M. Danaeian"
            ],
            "title": "A new model for retinal lesion detection of diabetic retinopathy using hierarchical self-organizing maps",
            "venue": "Iran J. Comput. Sci. 3(2), 93\u2013101",
            "year": 2020
        },
        {
            "authors": [
                "J. Bagherzadeh",
                "H. Asil"
            ],
            "title": "A review of various semi-supervised learning models with a deep learning and memory approach",
            "venue": "Iran J. Comput. Sci. 2(2), 65\u201380",
            "year": 2019
        },
        {
            "authors": [
                "M.S. Iqbal",
                "B. Luo",
                "T. Khan",
                "R. Mehmood",
                "M. Sadiq"
            ],
            "title": "Heterogeneous transfer learning techniques for machine learning",
            "venue": "Iran J. Comput. Sci. 1(1), 31\u201346",
            "year": 2018
        },
        {
            "authors": [
                "P.P. Singh",
                "S. Prasad",
                "B. Das",
                "U. Poddar",
                "D.R. Choudhury"
            ],
            "title": "Classification of diabetic patient data using machine learning techniques",
            "venue": "Ambient Communications and Computer Systems, pp. 427\u2013436. Springer, Singapore",
            "year": 2018
        },
        {
            "authors": [
                "G. Bhuvaneswari",
                "G. Manikandan"
            ],
            "title": "A novel machine learning framework for diagnosing the type 2 diabetics using temporal fuzzy ant miner decision tree classifier with temporal weighted genetic algorithm",
            "venue": "Computing 100(8), 759\u2013772",
            "year": 2018
        },
        {
            "authors": [
                "E.V. Carrera",
                "A. Gonz\u00e1lez",
                "R. Carrera"
            ],
            "title": "Automated detection of diabetic retinopathy using SVM",
            "venue": "2017 IEEE XXIV International Conference on Electronics, Electrical Engineering and Computing (INTERCON), pp. 1\u20134, August 2017. IEEE",
            "year": 2017
        },
        {
            "authors": [
                "P. Sharma",
                "S. Saxena",
                "Y.M. Sharma"
            ],
            "title": "An efficient decision support model based on ensemble framework of data mining features assortment & classification process",
            "venue": "2018 3rd International Conference on Communication and Electronics Systems (ICCES), pp. 487\u2013491. IEEE",
            "year": 2018
        },
        {
            "authors": [
                "R. Leardi"
            ],
            "title": "Application of a genetic algorithm to feature selection under full validation conditions and to outlier detection",
            "venue": "J. Chemom. 8(1), 65\u201379",
            "year": 1994
        }
    ],
    "sections": [
        {
            "text": "Keywords Diabetes \u00b7 Stacked generalization \u00b7 Prediction \u00b7 Internet of Things \u00b7 Ensemble learning"
        },
        {
            "heading": "1 Introduction",
            "text": "Chronic diabetes (CD) is one disease that affects the body\u2019s metabolism and causes structural changes. In 2014, the number of patients increased from 100 to 422 million [1\u20133]. Diabetes is typically divided into type 1, type 2 [4], and gestational diabetes. Type 2 is increasing with a high prevalence worldwide and is one of the leading causes of death. Because regardless of age and gender, it threatens them due to the lack of insulin in the body [5]. Increased blood sugar is associated with the risk of death in the community due to pneumonia, stroke, acute myocardial infarction, etc.\nHowever, its effect is on the vital organs is so harmful that it is considered the mother of all diseases. There is a risk of miscarriage, kidney failure, heart attack, blindness, and other chronic and deadly diseases in diabetic patients. Therefore, it is essential to diagnose diabetes faster [6\u20138].\nB Babak Nouri-Moghaddam babaknouriit85@gmail.com\n1 Department of Computer Engineering, Ardabil Branch, Islamic Azad University, Ardabil, Iran\nThe promising emerging potential of the Internet of Things (IoT) for connected medical devices and sensors plays a vital role in the next-generation healthcare industry for quality patient care. Due to the increasing number of elderly and disabled people, there is an urgent need for real-time health care infrastructure to analyze patient health care data to prevent preventable deaths [9]. Also, in intelligent health, modern wearable devices have gradually increased their capabilities in recent decades. They are equipped with several internal and external sensors to detect many vital signs [10].\nDesigning and implementing a far-off monitors system allows physicians and caregivers to remember peopling health in the least time. Current developments in ICT like the net of Things, Machine learning (ML), and data processing will enable us to produce health strategies with more intelligent capabilities to accurately predict the outcomes of the disease in the way of life, and therefore the hospital.\nBesides, medical advances in recent decades have significantly increased life expectancy while significantly reducing mortality [11]. According to La et al.\u2019 study [12], the benefits of personal health care with IoT requirements are divided\ninto three general categories, such as. First, increase the likelihood of early detection of potential and ongoing diseases without visiting clinics.\nPromote frequent assessments of health conditions and awareness of preventive health care needs. For example, the diagnosis of the disease with a set of measurements for a period can have been effectively accessible through routine examinations in clinics. Because routinely, in clinics and hospitals, doctors first take vital signs, then performmedical tests on the accepted vital signs to diagnose the disease.\nRahmani et al. [13] used IoT technology to offer an objective and structured approach to improving human health. This approach will vary the health sector\u2019s IoTbased devices regarding social benefits, influence, and cost-effectiveness. Due to the character of the IoT calculations, all health institutions (people, equipment, medicine) are often continuously monitored and managed. Therefore, using these technologies within the health industry can improve the standard and costs of medical aid by automating tasks already carried out by humans. Figure 1 shows the overall IoT-based health monitoring system [14, 15].\nAs a result, the prediction accuracy of a model may be high even with optimal parameters. Not surprisingly, the models produced by MLR and carrier support regression with a linear core are not statistically distinct and\nperform significantly better than other methods in the IWPC Ensemble [16]. One way to beat the restrictions of one algorithm is to mix the benefits of several algorithms to exceed the limit of one machine learning algorithm (e.g., the Ensemble method). Recently, the \u201cbagging\u201d Ensemble method has been wont to predict diabetes [17, 18].\nStack generalization is another Ensemble method that uses a higher-level model to combine lower-level models to achieve higher prediction accuracy [19, 20]. Unlike bagging and boosting approaches, which can only combine machine learning algorithms of the same type, stacked generalization can combine different algorithms through a meta-machine learning model to maximize generalization accuracy. The objectives of the study or the research question are as follows.\n\u2022 Using a hybrid machine learning model to diagnose diabetes. \u2022 Significant improvement in a forecast accuracy \u2022 Use several models in combination \u2022 Achieve a high level of reliability in classification. \u2022 Use multiple models to increase the estimate of the final model. \u2022 Improved accuracy and reduced error compared to singlecore models.\nAlso, the contributions of this paper can be summarized as follows:\n\u2022 Machine learning ensemble models for Diabetes (T2D) prediction demonstrated high performance. \u2022 Comparing resultswith themost related researches according to the literature. \u2022 Examining the benefits of ensemble methods proposed recently for prediction. \u2022 Using hybrid stacked generalization (SG) based Metaheuristics approach in the diagnosis of diabetes.\nIn the last several years, the number of persons diagnosed with diabetes has increased exponentially. According to a health report, 347 million individuals globally have diabetes. Diabetes is a disease that affects both the elderly and the y ounger generation [21\u201323]. Diagnosing diabetes in its early stages is also difficult. This diagnosis will aid in the decisionmaking process of the medical system and will help us save lives from diabetes. Therefore, early prediction of diabetes is significant to save a person from diabetes.\nThe type 2 diabetes data set, which contains nine valuable factors and 768 records, and another dataset with 55 useful variables and 100.000 records, was used in this investigation. Tables 2 and 3 lists the variables and their abbreviations. Finding a pattern in a vast data set is all about data analysis. This allows us to draw particular conclusions from the data supplied. Different machine learning methods can be used to perform the analysis. However, investigations have demonstrated that none of the algorithms can adequately solve a problem independently. This paper presents two sets of machine learning algorithms for diabetes prediction. The classification-based algorithm is one, and the ensemble learning algorithm is the other.\nArtificial intelligence (AI) research in healthcare is quickly advancing, with possible applications being proven in a variety of medical fields. We employ ensemble learning deliberately to look for superior prediction performance or classification accuracy [24\u201327]. We use nine classifiers in classification. Random forest classifier, Support Vector Machine, Decision Trees, K-Nearest Neighbors, Gradient Boosting, Multilayer Perception, Extra Tree Classifier, AdaBoost classifier, and basic Gaussian bays are the several types of classification algorithms. We used a learning-based GeneticAlgorithm (GA) for the ensemble learning approach. These ten algorithms were applied and compared to evaluate the accuracy of diabetes prediction for two different approaches to machine learning, and they scored 98% on average, which is higher than previous machine learning algorithms.\nThe rest of the article is as follows: we will review the method in section two and examine the results in section three. Then, we will review the discussion in the fourth\nsection. Finally, in the last section, we will review the conclusions and future work."
        },
        {
            "heading": "2 Related work",
            "text": "The present study deals with an ensemble stacking-based learning methodology for detecting diabetes. This section provides a brief review of the literature on numerous metaheuristic optimization-based and ensemble learning-based prediction methods of diabetes. Measures have been taken to reduce the number of chronic disease diagnostic tests to reduce overall costs. One of the possible solutions is to use machine learning techniques in healthcare data, which are used to find frequent patterns in an extensive database to obtain helpful information.\nMachine learning methods are instrumental in diagnosing diabetes and increasing its efficiency. One of the most important challenges for machine learning researches is accurately diagnosing diabetes. For example, Fatima et al. [28] have studied different machine learning methods to diagnose various diseases such as cardiopathy, diabetes, liver, and hepatitis and have succeeded in diagnosing this disease. Besides, Alic\u0301 et al. [29] have used artificial neural networks and Bayesian networks to diagnose and classify diabetes, aiming to evaluate artificial neural networks and Bayesian networks and their application to classify Type 2 diabetes (T2D) cardiovascular disease. Kumar et al. [30] used three distinct data mining arrangementmethods, e.g., Simple Biz (NB), support vector machine (SVM), and decision tree decision-making approach to potential approaches to predict the likelihood of heart disease for peoplewith diabetes. However, the accuracy of their prediction is dependent on the accuracy of their prediction. Medical bioinformatics analyses were used by Saru et al. to predict diabetes [31].\nSubramaniyan et al. [32] was predictive analytics using machine learning to evaluatemassive data to anticipate future difficulties in diabetic patients. Yang et al. [33] also created a computer method that combined multiple forms of physical examination data to predict the risk of diabetes. Today, ML offered various tools for efficient data analysis. Especially in the last few years, the digital revolution has provided affordable and accessible tools for collecting and saving data. Data collection and examination machines are located in new andmodern hospitals to collect and share data in large information systems. ML technology is very effective for analyzing medical data and has an influential role in solving diagnostic problems. Correct diagnostic data is presented as medical history or report in modern hospitals or their specific information department. These techniques are accustomed to classifying the information set [28, 34].\nTo evaluate the early diagnosis of diabetes, Zeki et al. [35] used three DM methods: Nave Bayes (NB), logistic\nregression (LR), and Random Forest (RF). The findings of the RF test, according to their research, showed that it has the best level of accuracy when compared to other procedures. In addition, according to the Kalyankar et al. study [36], the machine learning technique in the Hadoop MapReduce environment was used to detect missing values and discover trends in the Pima Indian Diabetes dataset. According to the patient\u2019s risk level, this research can forecast the forms of diabetes mellitus, associated future hazards, and the type of therapy supplied.\nPredictive algorithms based on data mining for evaluating diabetes data can aid in the early diagnosis and prediction of the condition and important link events such as hypo/hyperglycemia. Various approaches have been developed to diagnose, forecast, and classify diabetes [14].\nThe Internet of Things (IoT) is increasingly being utilized to implement various applications, particularly as the amount of data available grows. The Internet of Things can be used in various applications, including patient monitoring systems. For example, we can use the Internet of Things to evaluate data and offer it to physicians and paramedics in the health industry. We can identify solutions for longer and healthier lives by analyzing, processing, and exploiting the knowledge and information contained in big data on health issues and illness trends in a specific population. In many ways, extensive data analysis improves healthcare insight [37]."
        },
        {
            "heading": "2.1 Analysis of strengths and weaknesses related work",
            "text": "Each year, several expenditures are associated with treating and diagnosing patients with diabetes. Diagnostic techniques that have been used in the past are time-consuming. As a result, themost significant and urgent concern is precise forecasting and dependable procedures [38]. Machine learning techniques used to healthcare data could be one option. Diabetes can be diagnosed and managed more efficiently using machine learning approaches. Researchers have investigated several machine learning methods for identifying diseases such as cardiopathy, diabetes, liver, and hepatitis and have been successful in doing so.\nMany research suggests that artificial neural networks, random forest networks, and Bayesian networks are the most accurate ways for diagnosing and classifying diabetes when compared to other techniques. However, we offer a paradigm that incorporates artificial neural networks, Bayesian networks, and seven different methods for categorization. Ensemble Learner is the name given to this combination strategy. We proposed our approach for more accurate disease prediction compared to prior models. The experimental research findings also demonstrated that our strategy outperforms artificial neural networks,Bayesian networks, and random forests. Table 1 compares the benefits and\ndrawbacks of the proposed approach for diagnosing diabetes to previous methods."
        },
        {
            "heading": "2.2 Supportedmethodologies",
            "text": "This section discusses all the supported methodologies used in this study. Machine learning techniques have been widely used in many scientific fields. However, this use in the medical literature is limited partly because of technical difficulties [49, 50].\n\u2022 Decision tree: a decision tree is a decision support tool that uses trees to model [51, 52]. \u2022 Naive Bayes Classifier: a ensemble of simple classifiers based on probabilities is based on Bayes\u2019 theorem, assuming the independence of random variables [53, 54]. \u2022 Artificial Neural Network: inspired by how the biological nervous system processes data and information for learning and knowledge creation [55, 56]. \u2022 Support Vector Machine: it is one of the supervised learningmethods used for classification and regression [56, 57]. \u2022 C 4.5: Algorithm C 4.5 is one of the decision tree algorithms, which is very important due to its very high interoperability [58]. \u2022 Random Forest: one combination learning method for categorization is regression, which works supported training time and, therefore, the output of classes (classification) or for the predictions of every tree individually, supported a structure consisting of the many decision trees [59, 60]. \u2022 K-Nearest Neighbors: KNN classifier is to classify unlabeled observations by assigning them to the class of the most similar labeled examples. Characteristics of statements are collected for both training and testing datasets. The suitable choice of k features has a significant impact on the diagnostic performance of the KNN algorithm. An oversized k reduces the effects of variance caused by random error but runs the danger of ignoring small but significant patterns [59, 61, 62].\nThe following figure shows the proposed flowchart [62]. Within the following, we will examine the popular methods of mixing categories.\n\u2022 Bagging: one of the most straightforward and successful combined approaches to improving the classification problem is the Bagging algorithm, commonly used for decision trees. This algorithm is beneficial for bulk data and will work well for unstable learning algorithms, that is, algorithms that change due to changing data. \u2022 Boosting: this algorithm aims to combine several weak classifiers and obtain a strong one to improve performance, in which the predictors are trained continuously.\nTable 1 Advantages and disadvantages of the proposed method in diagnosing diabetes compared to other methods\nAuthors Approach Advantages Disadvantages\nNiloy Sikder et al. [39] Ensemble learning A valuable tool for mass retinal screening to detect DR\nImbalanced dataset\nBaha Ihnaini et al. [40] Deep ensemble learning For multidisciplinary diabetic illness prediction and recommendation, the proposed method is superior\n\u2013\nMrinal Banchhor et al. [41] Ensemble Learning(Random Forest)\nIn tenfold cross-validation, the Random Forest method was determined to have the best test accuracy, with 99.03% and 96.88% accuracy Low of data\nMd. Mahmudul Hasan Sabbir et al. [42]\nensemble learning The ensemble learning approach\u2019s sensitivity, specificity, and accuracy with texture features are higher than any individual learning model, with 97.2% sensitivity, 78.6% specificity, and 92.0% accuracy \u2013\nLeon Kopitar et al. [43] Glmnet, RF, XGBoost, LightGBM\nLightGBM models had the best amount of variable selection stability over time\nOur results showed no clinically relevant benefit when more sophisticated prediction models were deployed\nL. J. Muhammad et al. [44] Random-Forest With an accuracy of 88.76%, the random forest predictive learning-based model appeared to be one of the best-produced models Low accuracy\nNour Abdulhadi et al. [45] Random-Forest The primary goal of this study is to use several machine learning approaches to predict the occurrence of diabetes, particularly in females, at an early stage Low accuracy\nHuma Naz et al. [46] ANN, NB, DT DL DL had the greatest results for diabetes onset on the PIMA dataset, with an accuracy rate of 98.07%\n\u2013\nAdel Al-Zebari et al. [47] Decision Trees (DT), Logistic Regressions (LR), Discriminant Analysis (DA), Support Vector Machines (SVM), k-Nearest Neighbors (k-NN), and ensemble learners\nPerformance comparison of machine learning algorithms for detecting diabetes illness is conducted\nHe had accuracy scores ranging from 65.5 to 77.9% on average. The LR approach produces the best accuracy score of 77.9%, while the Coarse Gaussian SVM methodology produces the worst accuracy score of 65.5%\nVandana Rawat et al. [48] Bagging and AdaBoost The results computed are quite accurate, with bagging and AdaBoost approaches achieving classification accuracy of 81.77% and 79.69%, respectively\n\u2013\n\u2022 Ada Boost: a meta-algorithm is designed to improve the performance and solve the problem of unbalanced categories, which produces a robust and high-quality learner from a combination of three-week learners. This algorithm combines weak learners to produce an accurate classifier [63\u201367].\nThis study provides an intelligent monitoring system for patients and older people with chronic diseases using the collected data for effective diagnosis and prediction in noncritical situations to promote smart health and prevent deaths on IoT infrastructure using the intelligent ensemble learning algorithms. Ensemble methods are learning algorithms that construct an ensemble of classifiers and classify new data points by taking a (weighted) vote of their predictions.\nThe original ensemble method is Bayesian averaging, but newer algorithms include error-correcting output coding, Bagging, and boosting. This article reviews these methods and explains why ensembles often perform better than any classifier."
        },
        {
            "heading": "3 Materials andmethods",
            "text": "Since the use of an intelligent machine learning algorithm in diagnosing and predicting diseases has not been successful in many scenarios and considering the content and challenges mentioned in the background section, there are many challenges to smart health in IoT, need to be addressed; one of which is the accurate diagnosis and prediction of disease outcomes.\nThis paper uses the newmachine learning approach called Ensemble Learning to diagnose and predict chronic diseases described below. The purpose of this article is to improve the accuracy and speed of diagnosis of chronic diseases in\nthe context of the intelligent network by which we want to use ensemble learning approaches and a new meta-learner in stacking learning. Stack generalization is an approach that allows researchers to connect several different prediction algorithms to a combination."
        },
        {
            "heading": "3.1 Data set",
            "text": "In this study, the data set of type 2 diabetes available in (https://archive.ics.uci.edu/ml/datasets/diabetes) has been used, which has nine useful variables and 768 records. These variables and abbreviations are listed in Table 2. 70% of the data is for training, and 30% of the information is for testing.\nIn addition, another dataset has been used to teach algorithms. This data has been prepared to investigate factors associated with readmission yet as other outcomes regarding patients with diabetes. The data set of heart patients is available in (https://archive.ics.uci.edu/ml/datasets/Diabetes+ 130-US+hospitals+for+years+1999-2008) has been used, which has 55 useful variables and 100.000 records. Variables and their abbreviations are listed in Table 3. 80% of the data is for training, and 20% of the information is for testing."
        },
        {
            "heading": "3.2 Data preprocessing",
            "text": "On the analysis of big clinical databases, the Knowledge Discovery in Databases (KDD) methodology appears to be appealing. The preprocessing step (data cleaning and management of missing values) is critical in the KDD process since it determines the quality of the results acquired by data mining processes and takes up roughly 80% of the total project time. Data preprocessing is vital to arrange the diabetes type data and Pima Indians data to accept a machine learning model. Separating the training and testing data sets ensures that themodel learns only from training data and tests\nits performance with the testing data. Therefore, the data set used was divided into training and test data. The training data contain 70% of the data set, and the test and validation data include 15% each. At first, all the data was shuffled."
        },
        {
            "heading": "3.3 Building and training the stacked-generalization model",
            "text": "This article develops a stacking-based evolutionary ensemble learning system, \u201cStacked Generalization basedMetaheuristics,\u201d to predict the onset of Type-2 diabetesmellitus (T2DM) within five years. Before learning, as a data preprocessing step, the missing values and outliers were identified and imputed with the median values. Several machine learning optimization algorithms are utilized for base learner selection, which simultaneously maximizes the classification accuracy and minimizes the ensemble complexity. As for model combination, Bagging, Boosting, and Ada boost are employed as a meta-classifier that combines the predictions of the base learners [68].\nThe comparative results demonstrate that the proposed stacking genetic method outperforms several individual ML and conventional ensemble approaches. Figure 2 depicts the learning process with stacked generalization based on the model selection from 9 (Table 5) base learners and three stacking-based combination methods.\nStackgeneralization is a different technique for combining several different classifiers such as decision tree, artificial neural network, support vector machine, etc., which consists of two stages:\nBasic learners at level zero and stacking model learners at level one; at level zero, several different models are used to learn from the dataset, and the output of each model is used to make a new dataset. For example, Fig. 3 shows the Stacking algorithm [69]."
        },
        {
            "heading": "3.4 Hyperparameter tuning",
            "text": "Algorithms: an overview. Figure 4 shows a flow chart of the algorithms we applied in this study. The stack generalization learning algorithm is shown in Fig. 3. Here, the Pima Indiandiabetes andDiabetes 130-UShospitals for years 1999\u20132008 dataset is considered for testing all the models. The source of this dataset is the UCI repository [70\u201374]. To determine whether ensemble predictors constructed using stacked generalization improve the prediction accuracy for diabetes, we constructed different stacked generalization frameworks using the same parameters in individual algorithms. Of course, we use Feature selection to select the best feature to improve the accuracy suggested method.\nFeature selection reduces the number of attributes while keeping a subset of the original features. Feature selection is frequently used in data preparation to find previously\nunknown features useful to classification tasks and remove unnecessary or redundant features. The goal of feature selection is to boost classification accuracy. GA is used to reduce insignificant features in this study. We defined chromosomes as a mask for characteristics to achieve this goal [75].\nIn thiswork,GA is used to eliminate insignificant features. In order to reach this purpose, we defined chromosomes as a mask for features. To put it another way, each chromosome is a collection of characteristics. The number of characteristics indicating a diabetes patient\u2019s specification is equal to the size of the chromosome (number of genes). As previously stated, a chromosome is represented by a binary string that\nis either 0 or 1. A value of 1 indicates that the related feature is selected, whereas 0 indicates that it is not."
        },
        {
            "heading": "3.5 Genetic algorithm",
            "text": "GA is one of the initial population-based random algorithms proposed in history. Select, cross, and mutant are the most common GA operators [76]. These algorithms use recombinant operators to store crucial information in simple chromosome-like structures that encode a possible solution to a specific problem. Although the wide variety of genetic algorithms is very wide [77], GAs are frequently regarded as performance optimizers. A simple genetic algorithm\u2019s operating concept is depicted in Fig. 5."
        },
        {
            "heading": "3.5.1 Setting the GA parameters",
            "text": "Other parameters exist in GA. Executive parameters such as mutation and elite rates and structural characteristics such as population sizemust bemodified.However,we employed the most frequent values for these factors,which yielded satisfactory results. The significance of the GA parameters utilized in this experiment is shown in Table 4.\nThe conventional GAmethodwas employed in this experiment. There are four significant steps in the GA method: (1) The features were coded as genomes in binary, with \u20191\u2019 denoting selection and \u20190\u2019 denoting non-selection (phenotypes labeled as \u20190\u2019 denote features that were eliminated, whereas phenotypes labeled as \u20191\u2019 denote features that were chosen)). Thus, phenotypes labeled as \u20190\u2019 are referred to as decreased features, whereas phenotypes labeled as \u20191\u2019 are very significant features). Then, based on the concept of phenotypes, each genotype creates a collection of subsets. The proposed approach uses these subsets as training sets.\nThen, (1) each chromosome was evaluated using the fitness function, and the best features were picked; (3) the chromosomes were modified using crossover and mutation to form a new generation of the population; and (4) the new generation continued to (2) until halting criteria were satisfied.\nA population of 50 people was estimated. This ranking was utilized as a part of a selection strategy in which people who scored in the top half of their fitness levels were chosen to have children. The following population was created using a single point crossover with a ratio of 0.6 and a single point jump with a ratio of 0.033. First, the elitist strategy was set at 2, which meant that the two most minor members of the current generation were included in the next population. Then, the number of generations with the best value was set to twenty for the same fitness. The number of generations was finally set to 100. There were 100 GA executions, each with different initial conditions (some data splitting)."
        },
        {
            "heading": "3.5.2 Fitness function",
            "text": "The classifier fit was evaluated using a linear ranking value in this work. A statistical measure of the agreement between expected and actual values is linear ranking. The classifier\u2019s performance is determined by how the training set is generated. Cross-validationwas done using a repeated sub-random sampling technique due to the small data. Data were randomly partitioned into 70% training sets and 30% validation sets before each GA analysis. Because of the linear ranking value, each stage\u2019s performance was recorded. Due to the value of genome fit, the center of the ten linear ranking values was recorded [76, 77]."
        },
        {
            "heading": "3.5.3 Crossover (recombination)",
            "text": "Two-parent solutions are employed in crossovers to care for a toddler. The selection (production) procedure then comes to a close, followed by the event of higher persons. To pair two chromosomes, this study uses a single-point crossover. Two chromosomes are cut once, and the slices are swapped between them."
        },
        {
            "heading": "3.5.4 Mutation",
            "text": "When the crossing procedure is finished, the strings are inserted to perform the mutation process. Small amounts are rotated from 0 to 1 and 1 to 0 in touch mutations [76, 77]."
        },
        {
            "heading": "3.6 Machine learning parameters",
            "text": "Hyperparameters are variables whose values influence the learning process and affect the learning algorithm\u2019s model parameters. As the prefix \u2019 hyper _ \u2019 suggests, they are \u2019toplevel\u2019 parameters that regulate the learning process and the model parameters that come from it, as the prefix \u2019hyper_\u2019 suggests. Before you start training your model, as a machine learning engineer, you choose and establish hyperparameter values that your learning algorithm will employ.\nThis paper investigates many approaches to establish which factors do not affect model performance, a set of parameters that may have an additional impact on model performance and offers appropriate parameters for diabetes research to show the issues involved with identifiability. The purpose of parameter suggestions is to locate the collection of parameter values that reduce your cost function to the smallest possible value.\nFor Machine Learning Algorithms, there are six MustKnow Parameters, such as:\n1. Support Vector Machines have a C parameter. 2. Support Vector Machines\u2019 gamma parameter. 3. Maximum depth for Decision Trees. 4. For Decision Trees, min impurity decrease. 5. Tree count for Random Forest and GBDT. 6. K-Nearest Neighbors has N neighbors.\nWe have the trained model parameters at the end of the learning process, which is effectively what we refer to as the model.\nSupport Vector Machine (SVM): like gradient boosting, the SVM algorithm is viral, very effective, and has many hyperparameters to tweak. The choice of the kernel that will regulate how the input variables are projected is maybe the most significant parameter. This work evaluated the subset of selected genes using an SVM classification model with an RBF kernel. There are numerous to pick from, but linear, polynomial, and RBF are most frequent. The penalty (C), which can take on various values and has a significant impact on the geometry of the resulting areas for each class, is another important parameter.\nRandom Forest (RF): the number of random features to sample at each split point (max features) is the most critical parameter in Random Forest. In this study, a range of integer values, such as 1 to 20, or 1 to half the number of input features, are tested. However, after careful considera-\ntion and testing, we decided to change this number to zero. The number of trees (n estimators) is another key element for the random forest. This should ideally be increased until the model shows no more improvement. However, a log scale from 10 to 1000 could be helpful too. In this paper, Ring was utilized to determine the optimal settings. For this parameter, the best-selected scale is 100.\nK-Nearest Neighbors (KNN): the most important hyperparameter for KNN is the number of neighbors (n neighbors). We tested values ranging from 1 to 21 in this research. In this paper, the best selected for this parameter N neighbors 5 was used. This study also looked at distance measures (metrics) for determining the composition of a neighborhood. For the metric, I used Minkowski after checking.\nMultilayer Perceptron (MLP): a variety of hyperparameters, such as the number of hidden neurons, layers, and iterations, must be tuned in order for MLP to work. Grid search is a method for optimizing model hyperparameters. It would be best to give a dictionary of hyperparameters to evaluate in the param grid argument when creating this class. This is a map containing the model parameter\u2019s name and an array of values to attempt. Grid-search was utilized in this paper to discover the optimal parameter for this technique. Grid-search is configured as follows.\nparameter_space = {\n'hidden_layer_sizes': [(10, 30, 10), (20,)],\n'activation': ['tanh', 'relu'],\n'solver': ['sgd', 'adam'],\n'alpha': [0.0001, 0.05],\n'learning_rate': ['constant','adaptive'],\n}\nDecision tree (DTree): DTree are a great technique to categorize classes because, unlike Random Forests, they are transparent or white box classifiers, which means we can see the logic behind their classification. The function for determining a split\u2019s quality. The criterion \"Gini\" forGini impurity and \"entropy\" for information gain is supported. In this paper, entropy was used as a criterion parameter. The entropy measure is used as the impurity measure, and information gain splits a node to deliver the highest information gain. On the other hand, Gini Impurity examines the divergences between the probability distributions of the target attribute\u2019s values and splits a node so that the least amount of impurity is produced. The strategy used to choose splitter \"best\" the split at each node used.\nAdaBoost: the number of decision trees employed in the ensemble is an essential hyperparameter for the AdaBoost method. For the model to perform successfully, there must be many trees put to it, often hundreds, if not thousands. The \"n estimators\" option can specify the number of trees. This parameter was set at 100 in this study.\nNaive Bayes (NB): classifiers are scalable, with several parameters proportional to the number of variables (features/predictors) in a learning problem. The parameter set for the Naive Bayes classifier is somewhat narrow. Depending on the implementation, the number of classes may be the only parameter we do not influence over in actuality.\nExtra Trees: it is simple to use because it only includes a few key hyperparameters and logical rules for tuning them. The number of decision trees in the ensemble, the number of input features to select and consider for each split point randomly, and the minimum number of samples necessary in a node to establish a new split point are the three significant hyperparameters to tune in the algorithm. The number of decision trees utilized in the ensemble is an essential hyperparameter for the Extra Trees technique. This setting is set to auto default in this paper. The Extra Trees algorithm, like Random Forest, is unaffected by the value utilized, despite being a critical hyperparameter to control. It is set via the max_features argument and defaults to the square root of the number of input features. In this case, for our test dataset, this would be three features.\nGradient boosting (GB): among data scientists, GB is a very popular prediction model. The following are the parameters used in this algorithm.\n\u2022 Learning rate: this influences how much each tree affects the final result. This parameter was set to 0.1 in this study. \u2022 N estimators: this is the number of sequential trees modeled. Even though GBM is fairly resilient when dealing with many trees, it can nonetheless overfit at times. As a result, a CV should modify this for a specific learning rate. \u2022 Loss: the loss function that must be minimized in each split. For classification and regression cases, it can have a variety of values. In most cases, the default settings are sufficient. The term \u2019deviance\u2019 for loss refers to deviance ( logistic regression) for classification with probabilistic outputs, employed in this paper.\nIn Table 5\u2014RF is the Random Forest; KNN\u2014k-Nearest Neighbors algorithm; MLP\u2014multilayer Perceptron; Ada Boost\u2014AdaBoost; D Tree\u2014decision tree algorithm; NB\u2014Naive Bayes; GBC\u2014gradient boosting classifier algorithm; SVM\u2014Support vector machine, Extra Trees\u2014Extremely Randomized Trees Classifier."
        },
        {
            "heading": "3.7 Performancemeasuring attributes",
            "text": "For the study, Jupyter notebook was used for implementation, and Python, the programming language, was used for coding. For the study, Jupyter notebook was used for implementation, and Python, the programming language, was used for coding. Among all models, we selected the model with the most predictive accuracy.\nMLP Hidden layer sizes (100,), activation relu, solver adam, batch size 100, learning rate adaptive, max iter 100\nAda Boost Base estimator Decision Tree Classifier(max depth 1), n estimators 100, learning rate 1, algorithm SAMME.R,n classes 2,\nConfusion matrix Classified as:\nNegative Positive\nActual class\nNegative TN FP\nPositive FN TP\nThis article efficiently used cost\u2013benefit analysis (the disruptionmatrix), ROC curve, and other model selection issues such as accuracy. Performance measurement is used to determine the effectiveness of the classification algorithm so that, in the case of two-dimensional classification problems, one can show the cost of classification with a cost matrix for two types of false positive (FP) and false-negative (FN) errors and two types of classification into the positive true (TN) and negative true (TN) that give different costs and benefits. As shown in Tables 6 and 7 [6, 49, 50, 78]."
        },
        {
            "heading": "4 Results and discussion",
            "text": "Diabetes is a condition in which blood flow is obstructed throughout the body. The retinal blood vessels may leak in this disorder, resulting in retinal edema [79]. Four learning strategies for extracting patterns from data have been described based on data types: supervised, semi-supervised, unsupervised, and reinforced. Labeled data is challenging to access in machine learning, but unlabeled data is frequently collected and accessed quickly. In most initiatives, however, most of the data is unlabeled, but some are [80]. So, in\nSensitivity(Sen) It determines the proportion of true positive samples in total samples and is called as True Positive Rate (TPR) Sn TP/(TP + FN)\nSpecificity(Spe) It identifies the proportion of true negative samples in total samples and is called as False Positive Rate (FPR) Sp TN/(TN + FP)\nmachine learning and data mining, the primary assumption is that the training and future data have the same distribution and properties [81].\nDuring the past years, medical service providers have always manually examined patients\u2019 vital signs and diagnosed and predicted the disease based on patient records and research findings. In this study, intelligent machine-learning algorithms are used to diagnose effectively and accurately predict the outcomes of the disease, in which cases such as age, gender, blood pressure, cholesterol, smoking, etc., are considered in the diagnosis of this disease. Finally, the risk of the disease against the mentioned diseases is determined. Table 8 compares the similar works of others with ours.\nTable 8 shows the results. Our model\u2019s ability to forecast people with diabetes When compared to the findings of other researchers, it is high, with acceptable accuracy. These models can be integrated into an online computer software to assist doctors in predicting the onset of diabetes in patients and offering required preventive measures.\nThe success of an ensemble learning system is based on a variety of classifiers that make it up. If all classifiers present the same output, it is impossible to correct a possible error. So, they are more likely to have different errors on different samples. If each classifier presents another mistake, you can reduce the total error after their strategic combination. So, such a set of classifiers must be diverse. This diversity can be achieved in different ways, as shown in Fig. 6 [86].\n\u2022 Use different training datasets is to train classifiers. \u2022 Usedifferent training parameters is for different classifiers. \u2022 Use different classifiers.\nToday, due to the lack of knowledge about using different data around us, they are neglected by managers. In contrast, if these seemingly insignificant data are purposefully stored and thenmined, it will generate much knowledge and help us make managerial decisions. In this study, the genetic algorithm with logistic regression and random forest is used to select the appropriate feature is based on the correct diagnosis of the desired class, after applying statistical and probabilistic approaches in the data set and also preprocessing to remove redundant and lost data to extract features that have more variance in the complications of diabetes.\nThe genetic algorithm selects a subset of themost essential qualities for classification [87]. Logistic regression algorithm and a random forest to calculate the accuracy and examine the features with more variance in the rapid diagnosis of diabetes. We applied the data set properties as input to both algorithms. Then this algorithm calculated the accuracy of\neach feature. According to the results, logistic regression has a higher performance than the random forest classifier 0.70 times with 93% accuracy and five optimal features (Tables 9 and 10).\nIn the following\u2014Features Selection Diabetes 130-US hospitals for years 1999\u20132008 Data Set for classification model attempts to select a minimally sized subset according to the following criteria: (1) The classification accuracy should increase; (2) the values for the selected features should have to close as a possible to the original class distribution. The feature selection results on the diabetes dataset are shown below.\nIndividual: [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0].\nFeature Subset: [\u2019age\u2019, \u2019discharge_disposition_id\u2019, \u2019time_in_hospital\u2019, \u2019num_lab_procedures\u2019, \u2019num_procedures\u2019, \u2019num_medications\u2019, \u2019diag_2\u2019, \u2019number_diagnoses\u2019]."
        },
        {
            "heading": "4.1 What is lacking in the current knowledge?",
            "text": "We chose ensemble learning in this work since it usually outperforms any trained models [24]. It has been successfully applied to both supervised (Regression, [25] Classification, and Distance learning [26]) and Unsupervised (Density estimation) learning tasks [27]. It has also been used to figure out how much packing fault [38, 69]. Using a series of models instead of a singlemodel is advantageous for various reasons:\n\u2022 Performance: compared to a single model, there is a significant performance improvement. \u2022 Error reduction: predictive errors in machine learning models can be described using bias and variance.\nAs a result, this paper aims to identify the limitations of machine learning algorithms employed by other researchers in the accurate diagnosis of diabetes and compare them to the ensemble learning approach for better outcomes."
        },
        {
            "heading": "4.2 Strengths of the study",
            "text": "Using these findings, this chapter describes the limitations of machine learning models used for diabetes diagnosis using the dataset, with the goal of highlighting critical issues such as data quality, data quantity, explainability, and data privacy while getting quick results. The following are the article\u2019s strengths:\n\u2022 Combining the greatest machine learning architectures for voting.\nPima Indian diabetes datasets Diabetes 130-US hospitals for years 1999\u20132008 data set\n\u2022 Achieve a high level of classification reliability. \u2022 When compared to single-core models, accuracy and error have improved. \u2022 A comparison of the proposed method\u2019s outcomes.\nFuture research could resolve several significant shortcomings in this study. The study\u2019s first goal was to predict diabetes. and similar things:\n\u2022 The sample size. \u2022 Data that is not readily available or is not trustworthy. \u2022 Inadequate access to hospital information."
        },
        {
            "heading": "5 Conclusion and future work",
            "text": "Diabetes has become one of the most important concerns of people and officials due to irreversible complications and its high prevalence. The PID and Diabetes 130-US hospital\u2019s 1999\u20132008 database was used to diagnose diabetes in this study. Data mining methods have been widely used in medicine and health care to diagnose and prevent diseases, choose treatment methods, and predict deaths and treatment costs during the last years. For this purpose, we used an ensemble learning algorithm called stacked generalization based on genetic algorithms to classify diabetic patients based on the observed complications. This study aimed to combine data mining algorithms to show that combining models can improve models. The highest accuracy was obtained using the proposed Stack Generalization algorithm according to the methods used Intelligence."
        },
        {
            "heading": "5.1 Contribution",
            "text": "A recent study has developed many machine learning algorithms for predictingdiabetes. The ensemble learningmethod for the best diabetes prediction is key to this study. Through the site,wehavegatheredpatient information. Followingdata collection, only the relevant features were eliminated from each data set to improve the proposed model\u2019s accuracy and remove unrelated features that slowed down calculation. The ensemble learning approach works more carefully in larger healthcare datasets and gives better outcomes. Finally, we developed a diabetes data gathering and ensemble learning approach for accurate and timely prediction. Our recommended system\u2019s total performance is between 98.8 and 99.9%.As a result, newmedical researchers will benefit from future research and academic practice, particularly for Internet of Things-based prediction systems."
        },
        {
            "heading": "5.2 Future work",
            "text": "In future research, considering the importance of diagnosing the disease, we intend to expand the research in the field of diagnosing diseases such as breast cancer metastasis, lung cancer, Covid-19 by data mining tools and proposed algorithm and also develop and implement the subjects 1\u2014Consumption of drugs and s upplements (drug interaction) and 2\u2014Provide solutions to caregivers and 3\u2014Introduce a specialist related to the disease and 4\u2014Online medical services.\nAuthor contributions JA: Designed and performed experiments, analyzed data. BNM: supervised the findings of this work and co-wrote the paper. All authors discussed the results and contributed to the final manuscript.\nFunding None.\nDeclarations\nConflict of interest The authors declare that they have no conflict of interest."
        }
    ],
    "title": "Hybrid stacked ensemble combined with genetic algorithms for diabetes prediction",
    "year": 2022
}