{
    "abstractText": "This study presents a diverse set of freely available linguistic resources for Turkish natural language processing, including corpora, pretrained models and education material. Although Turkish is spoken by a sizeable population of over 80 million people, Turkish linguistic resources for natural language processing remain scarce. In this study, we provide corpora to allow practitioners to build their own applications and pretrained models that would assist industry researchers in creating quick prototypes. The provided corpora include named entity recognition datasets of diverse genres, including Wikipedia articles and supplement products customer reviews. In addition, crawling e-commerce and movie reviews websites, we compiled several sentiment analysis datasets of different genres. Our linguistic resources for Turkish also include pretrained spaCy language models. To the best of our knowledge, our models are the first spaCy models trained for the Turkish language. Finally, we provide various types of education material, such as video tutorials and code examples, that can support the interested audience on practicing Turkish NLP. The advantages of our linguistic resources are threefold: they are freely available, they are first of their kind, and they are easy to use in a broad range of implementations. Along with a thorough description of the resource creation process, we also explain the position of our resources in the Turkish NLP world.",
    "authors": [
        {
            "affiliations": [],
            "name": "Duygu Altinok"
        }
    ],
    "id": "SP:9016d34856f660f3e44052b7a86c9f6a50fc2290",
    "references": [
        {
            "authors": [
                "Ahmet Af\u015f\u0131n Ak\u0131n",
                "Mehmet D\u00fcndar Ak\u0131n"
            ],
            "title": "Zemberek, an open source NLP framework for Turkic Languages",
            "year": 2007
        },
        {
            "authors": [
                "Adriane Boyd",
                "Vincent D. Warmerdam. Aug"
            ],
            "title": "Floret: lightweight, robust word vectors",
            "venue": "https: //explosion.ai/blog/floret-vectors.",
            "year": 2022
        },
        {
            "authors": [
                "Erkin Demirtas",
                "Mykola Pechenizkiy."
            ],
            "title": "CrossLingual Polarity Detection with Machine Translation",
            "venue": "Proceedings of the Second International Workshop on Issues of Sentiment Discovery and Opinion Mining, WISDOM \u201913, New York, NY, USA. Asso-",
            "year": 2013
        },
        {
            "authors": [
                "Beyza Eken",
                "Ahmet Tantu\u011f."
            ],
            "title": "Recognizing Named Entities in Turkish Tweets",
            "venue": "Computer Science & Information Technology, 5:155\u2013162.",
            "year": 2015
        },
        {
            "authors": [
                "G\u00fcl\u015fen Eryi\u011fit."
            ],
            "title": "ITU Turkish NLP Web Service",
            "venue": "Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 1\u20134. Association for Computational Linguistics.",
            "year": 2014
        },
        {
            "authors": [
                "A. G\u00f6ksel",
                "C. Kerslake."
            ],
            "title": "Turkish: A Comprehensive Grammar",
            "venue": "Comprehensive grammars. Routledge.",
            "year": 2005
        },
        {
            "authors": [
                "Matthew Honnibal. Aug"
            ],
            "title": "Embeddings, Transformers and Transfer Learning",
            "venue": "https://spacy.io/usa ge/embeddings-transformers.",
            "year": 2020
        },
        {
            "authors": [
                "Matthew Honnibal. Feb"
            ],
            "title": "Introducing spaCy",
            "venue": "ht tps://explosion.ai/blog/introducing-spacy.",
            "year": 2015
        },
        {
            "authors": [
                "Matthew Honnibal. Feb"
            ],
            "title": "Models & Languages",
            "venue": "https://spacy.io/usage/models.",
            "year": 2019
        },
        {
            "authors": [
                "Matthew Honnibal. Jul"
            ],
            "title": "Projects",
            "venue": "https://spac y.io/usage/projects.",
            "year": 2020
        },
        {
            "authors": [
                "Matthew Honnibal",
                "Ines Montani."
            ],
            "title": "spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing",
            "venue": "To appear.",
            "year": 2017
        },
        {
            "authors": [
                "Joakim Nivre",
                "Marie-Catherine de Marneffe",
                "Filip Ginter",
                "Jan Haji\u010d",
                "Christopher D. Manning",
                "Sampo Pyysalo",
                "Sebastian Schuster",
                "Francis Tyers",
                "Daniel Zeman."
            ],
            "title": "Universal Dependencies v2: An evergrowing multilingual treebank collection",
            "venue": "In",
            "year": 2020
        },
        {
            "authors": [
                "Gy\u00f6rgy Orosz",
                "Zsolt Sz\u00e1nt\u00f3",
                "P\u00e9ter Berkecz",
                "Gergo Szab\u00f3",
                "Rich\u00e1rd Farkas."
            ],
            "title": "Huspacy: an industrial-strength hungarian natural language processing toolkit",
            "venue": "CoRR, abs/2201.01956.",
            "year": 2022
        },
        {
            "authors": [
                "Xiaoman Pan",
                "Boliang Zhang",
                "Jonathan May",
                "Joel Nothman",
                "Kevin Knight",
                "Heng Ji."
            ],
            "title": "Cross-lingual Name Tagging and Linking for 282 Languages",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1:",
            "year": 2017
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
            "venue": "CoRR, abs/1910.10683.",
            "year": 2019
        },
        {
            "authors": [
                "H. Bahadir Sahin",
                "Caglar Tirkaz",
                "Eray Yildiz",
                "Mustafa Tolga Eren",
                "Ozan Sonmez"
            ],
            "title": "Automatically Annotated Turkish Corpus for Named Entity Recognition and Text Categorization using Large-Scale Gazetteers",
            "year": 2017
        },
        {
            "authors": [
                "Klaus R. Scherer",
                "H G Wallbott."
            ],
            "title": "Evidence for universality and cultural variation of differential emotion response patterning",
            "venue": "Journal of personality and social psychology, 66 2:310\u201328.",
            "year": 1994
        },
        {
            "authors": [
                "Mansur Alp Tocoglu",
                "Adil Alpkocak."
            ],
            "title": "TREMO: A dataset for emotion analysis in Turkish",
            "venue": "Journal of Information Science, 44(6):848\u2013860.",
            "year": 2018
        },
        {
            "authors": [
                "Gokhan Tur",
                "Dilek Hakkani-Tur",
                "Kemal Oflazer."
            ],
            "title": "A statistical information extraction system for Turkish",
            "venue": "Natural Language Engineering, 9:181\u2013210.",
            "year": 2003
        },
        {
            "authors": [
                "Utku T\u00fcrk",
                "Furkan Atmaca",
                "\u015eaziye Bet\u00fcl \u00d6zate\u015f",
                "G\u00f6zde Berk",
                "Seyyit Talha Bedir",
                "Abdullatif K\u00f6ksal",
                "Balk\u0131z \u00d6zt\u00fcrk Ba\u015faran",
                "Tunga G\u00fcng\u00f6r",
                "Arzucan \u00d6zg\u00fcr"
            ],
            "title": "Resources for Turkish Dependency Parsing: Introducing the BOUN Treebank and the BoAT",
            "year": 2020
        },
        {
            "authors": [
                "Reyyan Yeniterzi."
            ],
            "title": "Exploiting Morphology in Turkish Named Entity Recognition System",
            "venue": "Proceedings of the ACL 2011 Student Session, pages 105\u2013110, Portland, OR, USA. Association for Computational Linguistics.",
            "year": 2011
        },
        {
            "authors": [
                "\u00c7a\u011fr\u0131 \u00c7\u00f6ltekin",
                "A. Seza"
            ],
            "title": "Do\u011fru\u00f6z, and \u00d6zlem \u00c7etino\u011flu",
            "year": 2022
        },
        {
            "authors": [
                "G\u00f6khan \u015eeker",
                "G\u00fcl\u015fen Eryi\u011fit."
            ],
            "title": "Extending a CRF-based named entity recognition model for Turkish well formed text and user generated content1",
            "venue": "Semantic Web, 8:1\u201318. 13748",
            "year": 2017
        },
        {
            "authors": [
                "blank. C"
            ],
            "title": "Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? No response. The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics Volume 1: Long Papers, pages 13739\u201313750\nJuly 9-14, 2023 \u00a92023 Association for Computational Linguistics"
        },
        {
            "heading": "1 Introduction",
            "text": "In recent years, with the development of transformers, natural language processing has experienced a dramatic breakthrough. Previously, learning architectures offered state-of-art solutions to many NLP tasks, such as sequence tagging and text classification. Accordingly, data-driven approaches have become the dominant technique used to process language data. This has made availability of large and high-quality language data an essential resource\nfor the development of NLP models. Turkish is spoken by over 80 million people, both in Turkey and across Europe, Cyprus, and Asia1. However, despite this abundance of Turkish speakers, the number of available Turkish linguistic resources does not compare to the corresponding amount of resources available for well-studied languages such as English. Turkish is an agglutinative language with complex morphology (G\u00f6ksel and Kerslake, 2005), and its morphosyntactic characteristics are challenging to handle in NLP applications. Similar challenges arise in creating linguistic resources for Turkish.\nIn this paper, we present a new set of Turkish linguistic resources, including corpora, pretrained spaCy models, and education material. The corpora comprise named entity recognition datasets of diverse genres, including Wikipedia articles and supplement products customer reviews. We also compiled several sentiment analysis datasets of different genres created via crawling e-commerce and movie reviews websites. The key characteristic of our corpora is their availability, as all corpora are easily accessible via their Github repos. With regard to spaCy pretrained models, to the best of our knowledge, our models are the first of their kind. Each spaCy pretrained language model includes a POS tagger, a dependency parser, a lemmatizer, a morphological analyzer, and a named entity recognizer as pipeline components. Although some webbased solutions have previously been provided, our POS taggers and dependency parsers are the first ones implemented in pure Python and are freely accessible. Our resources also include education materials. Specifically, we offer relevant information on the corpora building process, including all necessary details on web scraping, text cleaning, file formatting, and training the spaCy language models. Along with detailed tutorials about using\n1According to https://en.wikipedia.org/wiki/Turk ish_language\n13739\npretrained spaCy models in Python, we also provide tutorials on Turkish linguistics, dataset formats and the general dataset compilation process. All in all, this paper presents a comprehensive collection of resources to the Turkish NLP community."
        },
        {
            "heading": "2 Background",
            "text": "In this section, we review available corpora and pretrained models to better contextualize the contributions of our work."
        },
        {
            "heading": "2.1 Related Turkish corpora",
            "text": "In a recent review of all available Turkish language resources, \u00c7\u00f6ltekin et al. (\u00c7\u00f6ltekin et al., 2022) reviews the few publicly available NER datasets. Some of these datasets, such as Yeniterzi version (Yeniterzi, 2011) of T\u00fcr et al.\u2019s dataset (Tur et al., 2003), can be obtained through email. The aforementioned dataset includes ca. 500K words with 37,189 named entities (16,291 person, 11,715 location, 9,183 organization). Furthermore, the ITU NLP group offers three NER datasets (S\u0327eker and Eryig\u0306it, 2017) with the following three labels: person, organization, and location. These datasets are available from the group\u2019s website2 upon signing a licence agreement; however, the licence forbids any commercial use of the data. Another relevant dataset of 9,358 tweets has recently been presented by Eken and Tantug\u0306 (Eken and Tantug\u0306, 2015); yet, its availability is unclear.\nAs revealed by the brief review above, currently available Turkish NER datasets are rather scarce, and their common limitations include difficulty of access, lack of commercial usability, small size, and minimal annotation. Furthermore, as concerns sentiment analysis datasets, \u00c7\u00f6ltekin et al. (\u00c7\u00f6ltekin et al., 2022) reviews only two publicly available and commercially usable datasets: one containing movie reviews and the other containing product reviews; these two datasets were introduced by Demirtas\u0327 and Pechenizkiy (Demirtas and Pechenizkiy, 2013), respectively. Demirtas\u0327\u2019 movie reviews dataset, which contains 5,331 positive and 5,331 negative sentences, is scraped from a popular Turkish movie review site. Pechenizkiy\u2019s reviews dataset is considerably smaller and contains 700 positive and 700 negative reviews scraped from an online retailer website. These datasets are available on the authors\u2019 website. A third relevant dataset is called TREMO (Tocoglu and Alpkocak,\n2http://tools.nlp.itu.edu.tr/Datasets\n2018). Collected using a procedure similar to the one used to compile the ISEAR corpus (Scherer and Wallbott, 1994), TREMO is available only for non-commercial use. In summary, there are few sentiment corpora in the Turkish, and the available ones are small-sized (10K and 1.4K reviews), which is definitely not enough to train any kind of neural network-based architecture."
        },
        {
            "heading": "2.2 Turkish language processing pipelines",
            "text": "To date, only two NLP pipelines have been implemented \u2013 namely, Zemberek (Ak\u0131n and Ak\u0131n, 2007) and ITU Turkish NLP Web Service (Eryig\u0306it, 2014). Zemberek is an open-source application written in Java for various NLP tasks such as tokenization, sentence boundary detection, morphological analysis and language identification. The other pipeline is ITU Turkish NLP Web Service which, as suggested by its name, is provided as a web service. This pipeline contains a tokenizer, sentence boundary detector, deasciifier, vowelizer, spelling corrector, Turkish text detector, morphological analyzer and disambiguator, named- entity recognizer, and dependency parser components. However, a limitation of ITU Turkish NLP Web Service is that, despite being a full pipeline, it is not easy to use in code; specifically, one needs to require an API token from ITU NLP group and curl the API with input text. Another limitation of this pipeline is that it is not open-source. As suggested by the brief review above, the situation with Turkish NLP pipelines leaves much room for improvement; for a language spoken by 80 million people, there are only two pipelines \u2013 one without syntax components such as POS tagger and dependency parser and the other not easily accessible. This is complicated by the fact that a decent performing POS tagger and a dependency parser for Turkish are hardly available."
        },
        {
            "heading": "3 Corpora",
            "text": "In this section, we present the corpora part of our set of resources. We start with our named entity and span corpora (Section 3.1), followed by sentiment analysis corpora (Section 3.2) and a small corpus of COVID-19 symptoms (Section 3.3)."
        },
        {
            "heading": "3.1 Corpora for named entity and span recognition",
            "text": "This subsection introduces two corpora for named entity and span recognition that we compiled from\ndifferent resources. In what follows, we provide information about the collection process, corpus size, vocabulary size and tagset for each corpus."
        },
        {
            "heading": "3.1.1 Turkish Wiki NER Dataset",
            "text": "Our Turkish Wiki NER Dataset is a generalpurpose named entity dataset. In essence, it is a re-annotation of a subset of the TWNERTC dataset (Sahin et al., 2017), which is a collection of automatically categorized and annotated sentences from Turkish and English Wikipedia for named entity recognition and text categorization. While the first version of TWNERTC contains 4 broad labels for person names, locations, organizations, and other sort of entities, its second version contains over 1,000 fine-grained labels. Since TWNERTC is an automatically annotated dataset, its label accuracy is not sufficient to be usable in industrial-level NER models. For that reason, for our Turkish Wiki NER Dataset, we manually annotated a set of 20,000 sentences from TWNERTC. The dataset has a redistribution and modification allowing licence (CC BY-SA 4.0). We annotated our dataset with the following 19 types of entities: cardinal numbers, dates, important events, important places, geographical places, human languages, famous laws\u2019 names, locations, money amounts, nationalities or religious or political groups, ordinal numbers, organizations, percentages, person names, product names, quantities, time quantities, person titles, and works of art.\nThe explanations and examples of labels can be found in the dataset\u2019s Github repo.3 Our dataset contains 20,000 annotated sentences, around 357K words, with 70K of these words being unique; a total of 57,749 named-entities are labeled, and 101K words are labeled as entities. Distribution of labels in our corpus is shown in Table 1.\nThe data annotation was performed by our data labeling service provider.4 The dataset was annotated by crowd-sourcing; the labeling work\n3https://github.com/turkish-nlp-suite/Turkish -Wiki-NER-Dataset\n4Co-one Istanbul, https://co-one.co/\nwas done by a total of 25 annotators (15 female, 10 male). All annotators were native speakers of Turkish residing in Turkey. The dataset is available in its Github repo with CC BY-SA 4.0 licence."
        },
        {
            "heading": "3.1.2 Vitamins and Supplements NER Dataset",
            "text": "The Vitamins and Supplements NER Dataset is a multi-purpose NLU dataset containing customer reviews, customer review stars, as well as named entity and span annotations. User reviews were collected from a popular supplement products ecommerce website Vitaminler.com. The dataset is presented in the JSON lines format, with each instance of the dataset containing\n\u2022 product name\n\u2022 product\u2019s brand name\n\u2022 average star rating\n\u2022 number of total ratings\n\u2022 a list of customer reviews; each review consisting of a review text, review ID, star rating together with entity and span annotations.\nEach customer review in the Vitamins and Supplements NER Dataset describes a customer\u2019s experience with a supplement product in terms of\nthat product\u2019s effectiveness, side effects, taste and smell, as well as comments on supplement usage frequency and dosage, active ingredients, brand, and similar products by other brands. The reviews also include pointers to customers\u2019 health history and indications how the supplements helped in resolving customers\u2019 health problems. As part of their health history, customers refer to certain health issues such as vitamin deficiencies, hair and skin problems, pain in several body parts (e.g., neck pain, back pain, and joint pain), as well as digestion, weight control and sleep problems. Another aspect of the collected reviews is customer demography, as customers would typically mention who they purchased the product for, including themselves or another family member (e.g., \u201cbought the product for my baby/85-year-old mother/6-year-old daughter\u201d), and such descriptions usually include references to gender and age. Those parts of the reviews provide valuable information about target users of the product and its effectiveness on certain demographic groups. Finally, one more valuable type of information providing meaningful clues about supplement usage habits in the population is related to who initially recommended the product to the customer (e.g., a health professional, a friend or a relative, etc.).\nConsidering the characteristics of the data, our Vitamins and Supplements NER Dataset lies at the intersection of customer review data and healthcare NLP data. Healthcare NLP datasets are conventionally compiled from a variety of genres such as doctor notes, oncology notes, radiology reports, scientific article abstracts, customer reviews for health products and contain various annotations for diag-\nnosis codes, named entities, spans, and topics5. In view of the variety of information and annotation schemes in the healthcare domain, healthcare NLP obviously requires more than only named entity tags. In response to this need, in the Vitamins and Supplements NER Dataset, we introduced spans, which are \u201cfree\u201d sequences of tokens. By \u201cfree\u201d here we mean that sequence of tokens could be any sequence of tokens; that is, a sequence did not have to end/start with or contain certain POS tags (e.g., determiner, noun or verb), nor should the sequence have been a subtree in the dependency tree or provide any syntactic structure. Rather, the sequence was \u201cfree\u201d to start and end with any token in the text, and what matters was the semantics. Since this approach blurred the concept of span boundary, there arose the question about how the annotators should label the data. In our annotation guideline, we asked the annotators to label the sequences that minimally gave the semantics of the corresponding tag, mostly leaving out \u201chelper\u201d words (e.g., determiners and adverbs).\nTo illustrate our labeling process, consider two sample user review sentences provided below in Figure 3:\nHere, labeling only a named entity, i.e. \u201cbiotin\u201d in this case, would provide information only about active ingredients of the supplement, thus resulting in overlooking the effects and side-effects about this ingredient. A notable amount of information\n5A list of popular healthcare NLP datasets can be found at https://guides.lib.berkeley.edu/publichealth/hea lthstatistics/rawdata\nabout the supplement lies in the annotated spans EFFECT and SIDE_EFFECT.\nIn the light of these insights from the dataset, we annotated the following 10 types of named entities: disease/symptom names, biomolecule names, the person/people who used the supplement, names of other supplement products, person/people who recommended the supplement to the customer, dosage/amount, supplement\u2019s brand name, user demographics, ingredient substances, and other brand names mentioned in the review texts. In addition, we also annotated 4 types of spans: effects, side effects, taste and smell, and health history of the customer. The final dataset contains 2,488 instances, ca. 100K words, including 20K unique words, and around 10K entities. The distribution of named entity and span tags is summarized in Table 2.\nRaw data were collected by crawling Vitaminler.com. In the next step, we provided the raw data and annotation guideline to our data labeling service provider Co-one. The dataset was annotated by crowd-sourcing, and the labeling work was performed by a total of 25 annotators (15 female, 10 male). All annotators were native speakers of Turkish residing in Turkey. We also asked annotators to eliminate potentially offensive reviews and reviews containing person names (including those of the influencers). The dataset is available in its Github repo with CC BY-SA 4.0 licence.6 The sig-\n6https://github.com/turkish-nlp-suite/Vitamin s-Supplements-NER-dataset\nnificance of our Vitamins and Supplements NER Dataset for the Turkish NLP world is two-fold: first, to the best of our knowledge, it is the first span recognition dataset for Turkish; second, our dataset is the first public health NLP dataset in this language."
        },
        {
            "heading": "3.2 Corpora for sentiment analysis",
            "text": "This subsection introduces three corpora for sentiment analysis \u2013 Beyazperde Movie Reviews Dataset (Section 3.2.1), Beyazperde Top 300 Movies Dataset (Section 3.2.2) and Vitamins and Supplements Dataset (Section 3.2.3). In what follows, we provide information about the data collection process, corpus size, and vocabulary size for each corpus."
        },
        {
            "heading": "3.2.1 Beyazperde Movie Reviews Dataset",
            "text": "The data for this dataset were collected by crawling popular movie reviews website Beyazperde.com. We collected URLs of 4,500 most popular movies of all times. For each movie, we crawled the movie\u2019s name, a list of the movie\u2019s genres, the description text, as well as the lists of directors, actors, creators, and creators of the movie\u2019s music (i.e., composers and singers). The rating field on this website includes the number of total ratings, the number of reviews, average rating, as well as the values of the best and worst ratings on the 0-5 scale. For the reviews part, we collected all audience reviews, including review texts and review ratings. The final dataset is presented in the JSON format where each movie appears as a dictionary with general info, rating, and review information.\nThe final dataset contains 4,500 movies from 2,519 distinct directors. The total number of reviews is about 45K; the dataset comprises over 2.2M tokens, including 280K unique words. The star rating distribution in the review corpus is summarized in Table 3.\nThe dataset is available in its Github repo7 with CC BY-SA 4.0 licence."
        },
        {
            "heading": "3.2.2 Beyazperde Top 300 Movies Dataset",
            "text": "This dataset was also crawled from the movies website Beyazperde.com; however, this time we collected 300 top-rated movies. The data collection process and format of this dataset are identical to those of the Beyazperde Movie Reviews Dataset, with the only difference being that rating stars in the Beyazperde Top 300 Movies Dataset are highly unbalanced \u2013 namely, the numbers of 0-, 1-, 2-, and 3-star reviews are considerably lower than the corresponding numbers of 4- and 5-star ratings. Accordingly, this dataset imposes a great challenge of \u201cfinding the least/best of the best\u201d among the best movies. The star rating distribution is shown in Table 4.\nThe final dataset contains 300 top-rated movies by 218 distinct directors. The total number of reviews included in the dataset is 54K; the dataset contains over 2.4M tokens, including 50K unique tokens. Vocabulary size of this dataset is considerably smaller than that of the Beyazperde Movie Reviews Dataset. The dataset is available in its Github repo8 with CC BY-SA 4.0 licence.\nTo the best of our knowledge, both of our sentiment analysis datasets are the first of their kind, as no movie reviews of comparable size were collected before. For instance, a similar corpus published by YTU Kemik NLP Group9 contains reviews of mere 105 movies classified in only 3 classes (negative, positive, and neutral). Considering that modern NLP techniques require large corpora, our movie reviews datasets are sufficiently large and can thus be meaningfully used by the\n7https://github.com/turkish-nlp-suite/BeyazPe rde-Movie-Reviews/tree/main/butun-fimler\n8https://github.com/turkish-nlp-suite/BeyazPe rde-Movie-Reviews/tree/main/en-iyi-fimler\n9http://www.kemik.yildiz.edu.tr/\nTurkish NLP community."
        },
        {
            "heading": "3.2.3 Vitamins and Supplements Dataset",
            "text": "The Vitamins and Supplements NER Dataset discussed in Section 3.1.2 is a subset of a larger Vitamins and Supplements Dataset that has named entity and span annotations. The latter dataset was scraped from the supplements and health products e-commerce website Vitaminler.com. The Vitamins and Supplements Dataset includes user reviews and star ratings about supplement products. Each instance of the dataset includes a product name, brand name, average star rating value, number of customer ratings, and a list of customer reviews. A customer review includes a review text and a star rating. The dataset includes 1,052 products of 262 distinct brands with 244K customer reviews. This corpus contains 2.5M tokens, including 150K unique words. During the compilation process, we automatically eliminated potentially offensive reviews and reviews containing person names (including those of influencers). The dataset is available in its Github repo10 with CC BY-SA 4.0 licence."
        },
        {
            "heading": "3.3 Other corpora",
            "text": "Finally, we compiled a small corpus about COVID-19 symptoms from the popular collaborative dictionary Eks\u0327i S\u00f6zl\u00fck,11 one of the largest (over 400,000 registered users) online communities in Turkey.12 In this community, users share information on various topics ranging from scientific subjects to everyday life issues. The data were crawled from 2 headlines \u2013 \u201cCOVID-19 Symptoms\u201d and \u201cDay-by-day Corona Symptoms.\u201d This dataset, named Corona-mini, is presented in the JSON format in its Github repo.13\nCorona-mini includes 180 instances, embracing a total of 25K tokens with 9K unique words. Each instance of the corpus is an user entry on the website. In these entries, contributors describe their experiences with common COVID-19 symptoms, including fever, cough, tiredness, muscle weakness, pain in several body parts, loss of taste and smell, insomnia, and nausea. We mined this dataset with various information extraction techniques to exhibit possible usages of new spaCy Turkish models in\n10https://github.com/turkish-nlp-suite/Vitamin s-Supplements-Reviews\n11https://www.eksisozluk.com 12https://tr.wikipedia.org/wiki/Ek\u00c5\u00a7i_S\u00c3\u0171zl\u00c3k 13https://github.com/turkish-nlp-suite/Coron\na-mini-dataset\nour video tutorial titled \u201cQuick recipes with spaCy Turkish models\u201d. The compilation process of this dataset was also demonstrated in our video tutorial named \u201cHow to compile NLP Datasets\u201d (see Section 5)."
        },
        {
            "heading": "4 Pretrained Models",
            "text": "In this section, we introduce our spaCy Turkish language models. Overall, spaCy is an industrialstrength open-source NLP library offering state-ofthe-art performance with an order of magnitude exceeding other available NLP libraries (Honnibal and Montani, 2017; Honnibal, Feb 2015). spaCy also comes with a well-structured API, detailed documentation, support for issues, and an immense user community. Moreover, along with being easy to install and deploy, spaCy fits well into the Python machine learning ecosystem.\nEach spaCy language model is a pipeline of pretrained components (Honnibal, Feb 2019). Trainable components include a statistical lemmatizer, morphologizer (statistical morphological analyzer), NER, POS tagger, and dependency parser. spaCy offers \u201cspaCy projects\u201d for end-to-end training, packaging and sharing custom pipelines (Honnibal, Jul 2020). Accordingly, we trained our models with spaCy projects; the project template and the configuration files of each component along with the corresponding training hyperparameters are available on our Github page.14\nWe provide the following 3 pretrained models: tr_core_news_trf, tr_core_news_lg and tr_core_news_md. All these models include a vectorizer, lemmatizer, morphologizer, NER, POS tagger, and dependency parser components. The only difference among these models lies in the vectorization: while tr_core_news_lg and tr_core_news_md include static vectors, tr_core_news_trf is a transformer-based pipeline, meaning that word vectors for tokens are calculated and passed to the downstream components by the underlying transformer (Honnibal, Aug 2020). To train tr_core_news_trf,we used the dbmdz Turkish BERT model.15 tr_core_news_lg and tr_core_news_md are packaged with \u201cstatic\u201d word vectors; here, \u201cstatic\u201d means that these vectors are not learned parameters of the statistical models, and spaCy itself does not feature any algorithms\n14https://github.com/turkish-nlp-suite/turkish -spacy-models\n15https://huggingface.co/dbmdz/bert-base-turki sh-cased\nfor learning word vector tables (Honnibal, Aug 2020). In order to be included in the model training, static vectors have to be separately trained and packaged.\nAccordingly, we trained Floret vectors that support a vast number of subwords in a compact way (Boyd and Warmerdam, Aug 2022). For Turkish morphology, representing subwords is a critical issue. For two packages \u2013 namely, tr_core_news_lg and tr_core_news_md \u2013 we prepared two Floret vector packages: one medium-sized and the other large-sized, respectively. Training configuration of these two packages can be found in their Github repos16; the packaged vectors can be found in their Huggingface repo.17\nAll 3 models were trained on the same corpora: Universal Dependencies Turkish BOUN Treebank (T\u00fcrk et al., 2020) was used to train the morphologizer, lemmatizer, POS tagger, and dependency parser components; the NER component was trained using our Turkish Wiki NER dataset (3.1.1) and PanX (Pan et al., 2017). We trained mediumand large- sized Floret vectors which are 300- dimensional. However, vocabulary sizes were different: while medium-sized vectors include 50K keys, large-sized vectors include 200K keys. The Flloret vectors were trained on the MC4 corpus (Raffel et al., 2019). All our spaCy Turkish lan-\n16https://github.com/turkish-nlp-suite/turkish -spacy-models/tree/main/tr_vectors_web_(lg|md)\n17https://huggingface.co/turkish-nlp-suite/tr_ vectors_web_(lg|md)\nguage pipelines are available for download in our Huggingace repo.18"
        },
        {
            "heading": "4.1 Performance and comparison",
            "text": "Performance of the each model on respective testsets is shown in Table 5. Columns specify POS accuracy, morphological analysis accuracy, lemma accuracy, unlabelled attachment score for dependencies, labelled attachment score for dependencies, sentence boundary splitting F1 score, and NER F1 score. spaCy calculates sentence boundaries based on the full dependency parses. In our models, there is no pipeline component for sentence boundary detection, and spaCy library code manipulates the dependency tags during runtime to calculate the sentence boundary.\nTo evaluate statistical quality of our models, we compared their performance with that of pipelines for other languages, including three agglutinative languages (Hungarian (Orosz et al., 2022), Finnish, and Korean) and English (Honnibal, Feb 2019), which has a rather flat morphology. To this end, we used our best performing model, tr_core_news_trf, and compared it with the best performing models of the aforementioned four languages. The results of this comparison are shown in Table 6.\nAs revealed by the results, our pipelines are competent in statistical quality, and the corresponding values appears to be similar to those of the Finnish pipeline."
        },
        {
            "heading": "4.2 Comparison with other Turkish NLP pipelines",
            "text": "As discussed in Section 2, in previous research, there was only one attempt to compile an opensource, end-to-end Turkish NLP pipeline, Zemberek. In this section, we compare our spaCy Turkish pipelines to Zemberek NLP pipeline from the perspective of completeness. Zemberek pipeline does not contain any parsers for syntax, nor does it provide any pretrained NER models. Since Zemberek NLP paper was published in 2007, and the code was last updated 2 years ago, this package is outdated and does not meet the requirements of present-day NLP software. Accordingly, in this paper, we cannot make an accuracy-wise comparison (for a comparison of pipeline components, see Table 7).\nAnother relevant pipeline is ITU Turkish NLP Web Service which, as suggested by its name, is\n18https://huggingface.co/turkish-nlp-suite\nprovided as a web service. Although this pipeline contains both syntactic parsers and morphological analyzers, it is not easy to use in code; one needs to require an API token from the ITU NLP group and curl the API with input text; in addition, this pipeline is not open-source. Due to accessibility issues, a comparison of our spaCy Turkish models with this pipeline has to be omitted."
        },
        {
            "heading": "5 Education Material",
            "text": "Finally, we prepared a number of video and code tutorials to provide relevant information on the dataset collection process and dataset formats, as well as to demonstrate Python and bash scripting for cleaning and manipulating text, show possible use cases of the spaCy Turkish language models, and provide general information about Turkish linguistics. Our video tutorials, with each tutorial coming as a Youtube playlist consisting of several videos, include the following:\n\u2022 How to compile NLP Datasets\n\u2022 Dataset formats\n\u2022 Quick recipes with spaCy Turkish models\n\u2022 How to train your own spaCy language models\n\u2022 All about Turkish linguistics\n\u2022 Quick FAQ chatbot with semantic search and spaCy\nAll playlists are available on our YouTube channel19. The code tutorials are also available in our Github repo20."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we presented a diverse set of opensource linguistic resources for Turkish language processing. Our resources include corpora, pretrained spaCy language models, and education materials such as code and video tutorials. The importance of our resources for the Turkish NLP community is three-fold. The first important aspect of our resources is their accessibility. To the best of our knowledge, our Vitamins and Supplements NER Dataset is the first healthcare NLP dataset available for Turkish, while our two movie reviews datasets\n19https://www.youtube.com/c/NLPwithDuygu 20https://github.com/turkish-nlp-suite\nare the first large-scale movie review datasets of Turkish. The second aspect of our resources is that they are the first of their kind. For instance, our spaCy Turkish language models \u2013 with a tokenizer, sentence boundary detector, vectorizer, lemmatizer, morphologizer, NER, POS tagger, and dependency parser components packaged together \u2013 are the first complete NLP pipelines for Turkish. The third important characteristic of our resources is their ease of implementation. While previous approaches have failed to provide any tools that can be easily used to solve practical text processing problems, our spaCy pipelines build on solid foundations of a multilingual and industrial-strength NLP framework. Accordingly, these pipelines are the very first easily accessible, downloadable, and industrialstrength Turkish NLP pipelines for Turkish.\nLimitations\nOur work reported in this paper has two limitations. First, because of the scarcity of treebanks and NER datasets for Turkish, our pretrained spaCy language models were tested on a limited amount of testsets. Second, we trained our spaCy models on generalpurpose datasets compiled from Wikipedia data and formal written language resources. Accordingly, our models may not be very effective in analyzing social media texts such as Twitter data."
        },
        {
            "heading": "A For every submission:",
            "text": "3 A1. Did you describe the limitations of your work?\nYes, I included a Limitations section just before the References section.\nA2. Did you discuss any potential risks of your work? Not applicable. Not indeed because my paper is about building datasets and pretrained models for Turkish. There\u2019s not much of a risk to discuss.\n3 A3. Do the abstract and introduction summarize the paper\u2019s main claims? Yes. I included the claims in abstract and introduction. Background work, sections 3 and 4 exhibits the evidence to my claims.\n7 A4. Have you used AI writing assistants when working on this paper? Left blank.\nB 3 Did you use or create scientific artifacts? Left blank.\n3 B1. Did you cite the creators of artifacts you used? Yes, in sections 2,3,4 and 5.\n3 B2. Did you discuss the license or terms for use and / or distribution of any artifacts? Yes, in section 3.\n3 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? Yes, sections 3 and 4.\n3 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? Yes, section 3. We eliminated such instances from the dataset.\n3 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? yes, section 3.\n3 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. Yes, section 3 includes all the numbers.\nC 7 Did you run computational experiments? Left blank.\nC1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? No response.\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.\nC2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? No response.\nC3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? No response.\nC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)? No response.\nD 3 Did you use human annotators (e.g., crowdworkers) or research with human participants? Yes. I worked with a commercial company for data annotations and included their name and contact information in Section 3.\n7 D1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.? No, full annotation guideline is longer than 5 pages for both of the 2 datasets I constructed. No way would fit into this article.\nD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants\u2019 demographic (e.g., country of residence)? Not applicable. NA because I didn\u2019t recruit anyone, they\u2019re employees of the commercial company i worked with.\nD3. Did you discuss whether and how consent was obtained from people whose data you\u2019re using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used? Not applicable. NA because crowdsourcers work for a commercial company, hence this is a commercial work.\nD4. Was the data collection protocol approved (or determined exempt) by an ethics review board? Not applicable. NA here because my data is crawled from internet. Before crawling, we checked robots.txt of each website carefully.\n3 D5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? Yes, section 3."
        }
    ],
    "title": "A Diverse Set of Freely Available Linguistic Resources for Turkish",
    "year": 2023
}