{
    "abstractText": "Deep neural networks (DNNs) extract thousands to millions of task-specific features during model training for inference and decision-making. While visualizing these features is critical for comprehending the learning process and improving the performance of the DNNs, existing visualization techniques work only for classification tasks. For regressions, the feature points lie on a high dimensional continuum having an inherently complex shape, making a meaningful visualization of the features intractable. Given that the majority of deep learning applications are regression-oriented, developing a conceptual framework and computational method to reliably visualize the regression features is of great significance. Here, we introduce a manifold discovery and analysis (MDA) method for DNN feature visualization, which involves learning the manifold topology associated with the output and target labels of a DNN. MDA leverages the acquired topological information to preserve the local geometry of the feature space manifold and provides insightful visualizations of the DNN features, highlighting the appropriateness, generalizability, and adversarial robustness of a DNN. The performance and advantages of theMDA approach compared to the existing methods are demonstrated in different deep learning applications.",
    "authors": [
        {
            "affiliations": [],
            "name": "Md Tauhidul Islam"
        },
        {
            "affiliations": [],
            "name": "Zixia Zhou"
        },
        {
            "affiliations": [],
            "name": "Hongyi Ren"
        },
        {
            "affiliations": [],
            "name": "Masoud Badiei Khuzani"
        },
        {
            "affiliations": [],
            "name": "Daniel Kapp"
        },
        {
            "affiliations": [],
            "name": "James Zou"
        },
        {
            "affiliations": [],
            "name": "Lu Tian"
        },
        {
            "affiliations": [],
            "name": "Joseph C. Liao"
        },
        {
            "affiliations": [],
            "name": "Lei Xing"
        }
    ],
    "id": "SP:569f219021b78b2833e9e44ea4e7f9cacb1e53d5",
    "references": [
        {
            "authors": [
                "Wright",
                "L. G"
            ],
            "title": "Deep physical neural networks trained with backpropagation",
            "venue": "Nature 601,",
            "year": 2022
        },
        {
            "authors": [
                "Senior",
                "A. W"
            ],
            "title": "Improved protein structure prediction using potentials from deep learning",
            "venue": "Nature 577,",
            "year": 2020
        },
        {
            "authors": [
                "Elmarakeby",
                "H. A"
            ],
            "title": "Biologically informed deep neural network for prostate cancer discovery",
            "venue": "Nature 598,",
            "year": 2021
        },
        {
            "authors": [
                "I Anishchenko"
            ],
            "title": "De novo protein design by deep network hallucination",
            "venue": "Nature 600,",
            "year": 2021
        },
        {
            "authors": [
                "S. Webb"
            ],
            "title": "Deep learning for biology",
            "venue": "Nature 554,",
            "year": 2018
        },
        {
            "authors": [
                "Y Wu"
            ],
            "title": "Multiview confocal super-resolution microscopy",
            "venue": "Nature 600,",
            "year": 2021
        },
        {
            "authors": [
                "Lu",
                "M. Y"
            ],
            "title": "AI-based pathology predicts origins for cancers of unknown primary",
            "venue": "Nature 594,",
            "year": 2021
        },
        {
            "authors": [
                "D Ouyang"
            ],
            "title": "Video-based AI for beat-to-beat assessment of cardiac function",
            "venue": "Nature 580,",
            "year": 2020
        },
        {
            "authors": [
                "O Perlman"
            ],
            "title": "Quantitative imaging of apoptosis following oncolytic virotherapy by magnetic resonance fingerprinting aided by deep learning",
            "venue": "Nat. Biomed. Eng",
            "year": 2022
        },
        {
            "authors": [
                "X Qian"
            ],
            "title": "Prospective assessment of breast cancer risk from multimodal multiview ultrasound images via clinically applicable deep learning",
            "venue": "Nat. Biomed. Eng",
            "year": 2021
        },
        {
            "authors": [
                "L. Shen",
                "W. Zhao",
                "L. Xing"
            ],
            "title": "Patient-specific reconstruction of volumetric computed tomography images from a single projection view via deep learning",
            "venue": "Nat. Biomed. Eng",
            "year": 2019
        },
        {
            "authors": [
                "A Esteva"
            ],
            "title": "Dermatologist-level classification of skin cancer with deep neural networks",
            "venue": "Nature 542,",
            "year": 2017
        },
        {
            "authors": [
                "V Gulshan"
            ],
            "title": "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs",
            "venue": "JAMA 316,",
            "year": 2016
        },
        {
            "authors": [
                "G Wang"
            ],
            "title": "A deep-learning pipeline for the diagnosis and discrimination of viral, non-viral and COVID-19 pneumonia from chest X-ray images",
            "venue": "Nat. Biomed. Eng",
            "year": 2021
        },
        {
            "authors": [
                "Calin",
                "O. Deep Learning Architectures"
            ],
            "title": "A Mathematical Approach 2nd edn, Vol",
            "venue": "2",
            "year": 2020
        },
        {
            "authors": [
                "I.T. Jolliffe"
            ],
            "title": "Principal Component Analysis. Springer series in statistics 1st edn, Vol. 1 (Springer",
            "year": 2002
        },
        {
            "authors": [
                "L. van der Maaten",
                "G. Hinton"
            ],
            "title": "Visualizing data using t-SNE",
            "venue": "J. Mach. Learn. Res",
            "year": 2008
        },
        {
            "authors": [
                "E Becht"
            ],
            "title": "Dimensionality reduction for visualizing single-cell data using UMAP",
            "venue": "Nat. Biotechnol",
            "year": 2019
        },
        {
            "authors": [
                "T. Hastie",
                "R. Tibshirani",
                "Friedman",
                "J. Linear methods for classification. The Elements of Statistical Learning"
            ],
            "title": "Data Mining, Inference, and Prediction 2nd edn, Vol",
            "venue": "3 (eds Hastie, T., Tibshirani, R. & Friedman, J.) Ch. 101\u2013137",
            "year": 2009
        },
        {
            "authors": [
                "R. Hadsell",
                "S. Chopra",
                "Y. LeCun"
            ],
            "title": "Dimensionality reduction by learning an invariant mapping",
            "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "year": 2006
        },
        {
            "authors": [
                "B. Wang",
                "J. Zhu",
                "E. Pierson",
                "D. Ramazzotti",
                "S. Batzoglou"
            ],
            "title": "Visualization and analysis of single-cell RNA-seq data by kernel-based similarity learning",
            "venue": "Nat. Methods",
            "year": 2017
        },
        {
            "authors": [
                "Moon",
                "K. R"
            ],
            "title": "Visualizing structure and transitions in highdimensional biological data",
            "venue": "Nat. Biotechnol",
            "year": 2019
        },
        {
            "authors": [
                "K. Sohn",
                "H. Lee",
                "X. Yan"
            ],
            "title": "Learning structured output representation using deep conditional generative models",
            "venue": "In Advances in Neural Information Processing Systems (Curran Associates Inc.,",
            "year": 2015
        },
        {
            "authors": [
                "Menze",
                "B. H"
            ],
            "title": "The multimodal Brain Tumor Image Segmentation Benchmark (BRATS)",
            "venue": "IEEE Trans. Med. Imag.34,",
            "year": 2015
        },
        {
            "authors": [
                "J.B. Tenenbaum",
                "V. de Silva",
                "J.C. Langford"
            ],
            "title": "A global geometric framework for nonlinear dimensionality Reduction",
            "venue": "Science 290,",
            "year": 2000
        },
        {
            "authors": [
                "S.T. Roweis",
                "L.K. Saul"
            ],
            "title": "Nonlinear dimensionality reduction by locally linear embedding",
            "venue": "Science 290,",
            "year": 2000
        },
        {
            "authors": [
                "Weinstein",
                "J. N"
            ],
            "title": "The cancer genome atlas pan-cancer analysis project",
            "venue": "Nat. Genet",
            "year": 2013
        },
        {
            "authors": [
                "Subramanian",
                "A. et al. A next generation connectivity map"
            ],
            "title": "L1000 platform and the first 1,000,000 profiles",
            "venue": "Cell 171, 1437\u20131452.e17",
            "year": 2017
        },
        {
            "authors": [
                "J Zhu"
            ],
            "title": "Prediction of drug efficacy from transcriptional profiles with deep learning",
            "venue": "Nat. Biotechnol",
            "year": 2021
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "year": 2015
        },
        {
            "authors": [
                "Chowdhury",
                "M.E. H"
            ],
            "title": "Can AI help in screening viral andCOVID19 pneumonia",
            "venue": "IEEE Access",
            "year": 2020
        },
        {
            "authors": [
                "A. Hyv\u00e4rinen",
                "Oja",
                "E. Independent component analysis"
            ],
            "title": "algorithms and applications",
            "venue": "Neur. Netw. 13, 411\u2013430",
            "year": 2000
        },
        {
            "authors": [
                "M.T. Islam",
                "L. Xing"
            ],
            "title": "A data-driven dimensionality-reduction algorithm for the exploration of patterns in biomedical data",
            "venue": "Nat. Biomed. Eng",
            "year": 2021
        },
        {
            "authors": [
                "Farrell",
                "J. A"
            ],
            "title": "Single-cell reconstruction of developmental trajectories during zebrafish embryogenesis",
            "venue": "Sciencehttps://doi.org/ 10.1126/science.aar3131",
            "year": 2018
        },
        {
            "authors": [
                "Islam",
                "M. T"
            ],
            "title": "Leveraging data-driven self-consistency for highfidelity gene expression recovery",
            "venue": "Nat. Commun",
            "year": 2022
        },
        {
            "authors": [
                "M.T. Islam",
                "L. Xing"
            ],
            "title": "Leveraging cell-cell similarity for highperformance spatial and temporal cellular mappings from gene expression data",
            "venue": "Patterns https://doi.org/10.1016/j.patter.2023",
            "year": 2023
        },
        {
            "authors": [
                "B. O\u2019Neill"
            ],
            "title": "Elementary Differential Geometry",
            "venue": "2nd edn,",
            "year": 2006
        },
        {
            "authors": [
                "I.J. Goodfellow",
                "J. Shlens",
                "C. Szegedy"
            ],
            "title": "Explaining andharnessing adversarial examples",
            "venue": "arXiv https://doi.org/10.48550/arXiv.2210",
            "year": 2015
        },
        {
            "authors": [
                "M.T. Ribeiro",
                "S. Singh",
                "Guestrin",
                "C. \u201cWhy should I trust you?\u201d"
            ],
            "title": "explaining the predictions of any classifier",
            "venue": "arXiv https://doi.org/10. 48550/arXiv.2210.02192",
            "year": 2016
        },
        {
            "authors": [
                "V. Antun",
                "F. Renna",
                "C. Poon",
                "B. Adcock",
                "A.C. Hansen"
            ],
            "title": "On instabilities of deep learning in image reconstruction and the potential costs of AI",
            "venue": "Proc. Natl Acad. Sci. USA https://doi.org/10",
            "year": 2020
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "Brox",
                "T. U-Net"
            ],
            "title": "convolutional networks for biomedical image segmentation",
            "venue": "arXiv https://doi.org/10. 48550/arXiv.2210.02192",
            "year": 2015
        },
        {
            "authors": [
                "V. Papyan",
                "X.Y. Han",
                "D.L. Donoho"
            ],
            "title": "Prevalence of neural collapse during the terminal phase of deep learning training.Proc.Natl",
            "venue": "Acad. Sci.117,",
            "year": 2020
        },
        {
            "authors": [
                "Kothapalli",
                "V. Neural collapse"
            ],
            "title": "A reviewonmodellingprinciples and generalization",
            "venue": "arXiv https://doi.org/10.48550/arXiv.2206. 04041",
            "year": 2023
        },
        {
            "authors": [
                "W. Liu",
                "L. Yu",
                "A. Weller",
                "B. Sch\u00f6lkopf"
            ],
            "title": "Generalizing and decoupling neural collapse via hyperspherical uniformity gap",
            "year": 2023
        },
        {
            "authors": [
                "Zhou",
                "J. et al. Are all losses created equal"
            ],
            "title": "a neural collapse perspective",
            "venue": "arXiv https://doi.org/10.48550/arXiv.2210.02192",
            "year": 2022
        },
        {
            "authors": [
                "Z Zhu"
            ],
            "title": "A geometric analysis of neural collapse with unconstrained features",
            "venue": "arXiv https://doi.org/10.48550/arXiv.2105",
            "year": 2021
        },
        {
            "authors": [
                "M.T. Islam",
                "L. Xing"
            ],
            "title": "Geometry and statistics-preserving manifold embedding for nonlinear dimensionality reduction",
            "venue": "Patter. Recogn.Lett. 151,",
            "year": 2021
        },
        {
            "authors": [
                "M.T. Islam",
                "L. Xing"
            ],
            "title": "Cartography of genomic interactions enables deep analysis of single-cell expression data",
            "venue": "Nat. Commun. 14,",
            "year": 2023
        },
        {
            "authors": [
                "Z. Gong",
                "W. Hu",
                "X. Du",
                "P. Zhong",
                "P. Hu"
            ],
            "title": "Deep manifold embedding for hyperspectral image classification",
            "venue": "IEEE Trans. Cybernet",
            "year": 2022
        },
        {
            "authors": [
                "Zang",
                "Z. et al. DLME"
            ],
            "title": "Deep local-flatness manifold embedding",
            "venue": "Computer Vision\u2014ECCV 2022, Lecture Notes in Computer Science 1st edn, Vol. 2 (eds Avidan, S., Brostow,G., Cisse,M., Farinella, G.M. & Hassner, T.) Ch. 576\u2013592",
            "year": 2022
        },
        {
            "authors": [
                "D.W. Scott"
            ],
            "title": "On optimal and data-based histograms",
            "venue": "Biometrika 66,",
            "year": 1979
        },
        {
            "authors": [
                "M. Girolami",
                "S. Rogers"
            ],
            "title": "Variational Bayesian multinomial probit regression with Gaussian process priors",
            "venue": "Neur. Comput",
            "year": 2006
        },
        {
            "authors": [
                "L. McInnes",
                "J. Healy",
                "Melville",
                "J. UMAP"
            ],
            "title": "Uniform manifold approximation and projection for dimension reduction",
            "venue": "arXiv https://doi.org/10.48550/arXiv.1512.03385",
            "year": 2020
        },
        {
            "authors": [
                "T. Sainburg",
                "L. McInnes",
                "T.Q. Gentner"
            ],
            "title": "Parametric UMAP embeddings for representation and semisupervised learning.Neur",
            "venue": "Comput. 33,",
            "year": 2021
        },
        {
            "authors": [
                "R. Caruana",
                "S. Lawrence",
                "Giles",
                "C. Overfitting in neural nets"
            ],
            "title": "backpropagation, conjugate gradient, and early stopping",
            "venue": "In Advances in Neural Information Processing Systems Vol. 13",
            "year": 2000
        },
        {
            "authors": [
                "P. Tschandl",
                "C. Rosendahl",
                "H. Kittler"
            ],
            "title": "The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions",
            "venue": "Sci. Data",
            "year": 2018
        },
        {
            "authors": [
                "C Ledig"
            ],
            "title": "Photo-realistic single image super-resolution using a generative adversarial network",
            "venue": "arXiv https://doi.org/10.48550/",
            "year": 2017
        },
        {
            "authors": [
                "Macosko",
                "E. Z"
            ],
            "title": "Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets",
            "venue": "Cell 161,",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "Revealing hidden patterns in deep neural network feature space continuum via manifold learning\nMd Tauhidul Islam 1,4, Zixia Zhou 1,4, Hongyi Ren1, Masoud Badiei Khuzani1, Daniel Kapp1, James Zou 2, Lu Tian2, Joseph C. Liao 3 & Lei Xing 1\nDeep neural networks (DNNs) extract thousands to millions of task-specific features during model training for inference and decision-making. While visualizing these features is critical for comprehending the learning process and improving the performance of the DNNs, existing visualization techniques work only for classification tasks. For regressions, the feature points lie on a high dimensional continuum having an inherently complex shape, making a meaningful visualization of the features intractable. Given that the majority of deep learning applications are regression-oriented, developing a conceptual framework and computational method to reliably visualize the regression features is of great significance. Here, we introduce a manifold discovery and analysis (MDA) method for DNN feature visualization, which involves learning the manifold topology associated with the output and target labels of a DNN. MDA leverages the acquired topological information to preserve the local geometry of the feature space manifold and provides insightful visualizations of the DNN features, highlighting the appropriateness, generalizability, and adversarial robustness of a DNN. The performance and advantages of theMDA approach compared to the existing methods are demonstrated in different deep learning applications.\nDeep learning promises to revolutionize scientific discoveries and various technological applications1\u20135. In general, deep learning tasks can be divided into two major categories, classification, and regression. Different from classification tasks in which the outputs take discrete values, deep regression models predict continuous outcomes from the data. While most deep learning applications are regressionoriented6\u201312, physically meaningful visualization of the feature space representation of these models is quite challenging and has yet to be achieved.\nAlgorithmically, a deep neural network (DNN) learns the relationship between themanifolds representing the input data and labels. During training, the DNNs learn the function that transforms an input manifold to an output manifold that is similar to the label/target manifold, making deep learning a manifold mapping problem. For a test sample (i.e., a point on the input manifold), a trained DNN model estimates the location of the corresponding point in the output manifold (Fig. 1(a)). Classification is a special case of the manifold mapping where output manifold is of a single dimension. A series of abstractions are carried out through the layered calculations of DNNs to connect the input and output manifolds. In other words, features at each layer attempt to form a latent representation of the input in highdimensional (HD) space. Unlike in classification tasks, where the features are clustered13\u201315, the features in a regression problem form a continuum in an HD space16. Visualizing the HD features in a low dimension is essential to understand the manifold mapping process and represents an important step toward interpretable AI. For\nReceived: 17 May 2023\nAccepted: 24 November 2023\nCheck for updates\n1Department of Radiation Oncology, Stanford University, Stanford, CA 94305, USA. 2Department of Biomedical Data Science, Stanford University, Stanford, CA 94305, USA. 3Department of Urology, Stanford University, Stanford, CA 94305, USA. 4These authors contributed equally: Md Tauhidul Islam, Zixia Zhou.\ne-mail: jliao@stanford.edu; lei@stanford.edu\nNature Communications | (2023) 14:8506 1\n12 34\n56 78\n9 0 () :,;\n12 34\n56 78\n9 0 () :,;\nmeaningful feature embedding, the spatial distances among the points on the manifold surface should be preserved when projecting them down to a low dimension. Because of the inherent complexity of a manifold surface of DNN features, geodesic distance should beused to relate the HD data points instead of pairwise distance (e.g., Euclidean distance and correlation). It is important to point out that conventional dimensionality reduction and/or visualization techniques with or without supervision17\u201324 are not applicable to visualize the feature space data of regression DNNs as they are designed only for classification problems, in which case the features are characterized by 1D discrete labels and preserving the pairwise distance among the points is all one needs for feature embedding (see Results for examples). This work aims to develop an MDA framework for DNN feature visualization in deep learning problems. ThemotivationbehindMDA is that in multi-layered neural networks, the weights and biases of each layer create a submanifold. As we delve deeper into the network, the manifold space increasingly resembles the output manifold. When the network is well-trained, the output manifold mimics the target manifold. Consequently, visualizing the features of intermediate layers in relation to the target and output manifolds reveals the quality of the latent features of the network. In properly trained networks, the visualization demonstrates a consistent arrangement of data points with respect to the output and target manifolds. However, in poorly trained networks, the visualization lacks information from the target\noutput manifold and use that information to visualize the manifold of extracted DNN features in lower dimension. To this end, MDA first computes distances between the DNN-estimated labels, enabling construction of the outline of the manifold for the estimated labels in HD. This outline provides the basis for grouping the labels based on their distances on the manifold surface. Next, a Bayesian approach is used to embed HD feature points at a specific DNN layer, constrained by the sorted label groups. Finally, a deep learning is employed to transform the projected features to a lower dimension for visualization and analysis. This figure was created with BioRender.com.\nNature Communications | (2023) 14:8506 2\nmanifold, resulting in inconsistent positioning of the feature data points. Computationally, our proposed approach explores the DNN feature spaceunder the guidanceof theoutput and targetmanifoldsof the DNN (Fig. 1b, Supplementary Fig. S1). We construct the manifold outline from the estimated labels as follows: (i) Computing the distances among the network outputs (Supplementary Fig. S1-step 1). (ii) Constructing a layout of the output manifold by finding one end point of the manifold (Supplementary Fig. S1-step 2). (iii) Sorting the distances of the outputs from the end point into K bins using optimal histogrambin count (Supplementary Fig. S1-step 2) (seeMethods). The outline of the target manifold is also computed using the same procedure, which serves as the colormap for MDA visualization (see Methods). A Bayesian approach is used for the projection of the feature data under the condition of the pseudo labels created in the previous step via histogram sorting (Supplementary Fig. S1-step 3). This projection preserves the geodesic distances among the data points locally on the manifolds (see Supplementary Fig. S24 and Methods). The final visualization of the HD features is achieved by using a deep neural network optimized with cross-entropy loss between theprobability of point locations of theBayesiancomponents and a 2D embedding space (Supplementary Fig. S1-step 4). Below, we demonstrate that MDA provides a reliable dimensionality reduction technique for the visualization and exploration of DNN features in various deep learning applications."
        },
        {
            "heading": "Results",
            "text": "The unique capability of MDA in visualizing the DNNs\u2019 features is illustrated via a series of examples, includingmedical image segmentation, gene expression prediction, gene-based survival prediction, medical image superresolution, and classification of COVID-19 radiography dataset. A summary of our experimental setup, datasets, and findings is presented in Table 1. A simple regression problem with MNIST handwritten digits is also studied to shed useful insights into the MDA visualization of deep regression (Supplementary Figs. S9\u2013S11).\nMDA affords feature visualization in segmentation tasks We first explore the feature space of the Dense-UNet segmentation network trained on the BraTS 2018 dataset25. The inputs here are brain MRI images and the outputs are binary images with tumor segmentation. The input andoutput images are located inHDmanifold spaces of 57,600 (number of image pixels) dimensions. The Dense-UNet network connects these two manifold spaces and when trained, finds an optimal function that can transform the input images into output images. The features at each of the 218 intermediate layers form manifolds of dimensions equal to the number of neurons in the layer. Thus, these 218 intermediate feature manifolds collectively create a mapping function between the input and output manifolds. The features from several different convolutional layers at the beginning and end of model training, including the 2nd of the 3rd dense block (B3L2), the 8th of the 4th dense block (B4-L8), the 2nd of the 6th dense block (B6-L2), and the last before thefinaloutput (B7-L8), are displayed in Figs. 2 and 3, and Supplementary Figs. S25, and S26 using t-distributed stochastic neighbor embedding (t-SNE)18, uniform manifold approximation and projection (UMAP)19, Isomap26, locally linear embedding (LLE)27 and MDA. It is seen that, for both training and testing datasets, traditional t-SNE and UMAP show clustered data points and reveal no useful information about the features at the layers. Isomap and LLE also fail to show any meaningful visualizations before and after the network is trained. It is not surprising that the MDA shows similar behavior before training. After the DNN is trained (Fig. 3), the manifolds at different layers approach that defined by the labels, leading to a continuous change in color as seen in the MDA visualizations. In this way, MDA reveals the quality of the DNN features at different layers as well as at different stages of the training (theMDA visualizations at intermediate training epochs are presented in T ab le 1 |S um m ar y o f th e ex p er im en ts an d re su lt s\nEx p er im\nen ts\nD at as\net D N N\nR es\nul ts\nK ey\nco n cl us\nio n\nA na\nly si s o f fe at ur e d at as et s of\nD N N s of\nd iff er en t co m p le xi tie s in d iff er en t b io m ed ic al d is ci p lin\nes B ra TS\n,T C G A ,L\nIN C S\nL1 0 0 0 ,I S IC -2 0 19 , D R ,C O V ID\nD en\nse -U N et ,M\nLP ,V\nA EM LP\n,S R G A N ,\nR es\nN et ,A\nle xN\net ,U\nN et ,m\nC N N (T ab\nle S 6 ),\nfM LP\n(T ab\nle S 5)\nFi g s.\n2\u2013 9 ,S\n9 M D A si g n ifi ca\nnt ly\nou tp er fo rm\ns ex\nis tin\ng d at a an\nal ys is m et ho\nd s su ch as tS N E, U M A P, LL E an d Is om ap .\nR ob\nus tn es\ns te st\nof D N N s ag\nai ns\nt no\nis e\nB ra TS\n,C O V ID\nD en\nse -U N et ,U\n-N et ,R\nes N et ,A\nle xN\net S up\np le m en\nta ry\nFi g s.\nS 4 2\u2013\nS 4 6\nM D A sh\now s th e ro b u st ne\nss of\na D N N to\nno is e th ro ug\nh fe at ur e sp\nac e\nvi su\nal iz at io n.\nG en\ner al iz ab\nili ty\nte st\nof D N N s\nTC G A ,L\nIN C S L1 0 0 0\nM LP\n,V A EM LP\nFi g s.\n4 ,5\nM D A re ve\nal s th e g en\ner al iz ab\nili ty\nof D N N to w ar d s un\nkn ow\nn d at as et s\nm or e ac\ncu ra te ly\nth an\not he\nr m et ho\nd s.\nN eu\nra lc\nol la p se\nin D N N s fo r re g re ss io n ta sk s\nM N IS T,\nTC G A\nm C N N ,f M LP\nS up\np le m en\nta ry\nFi g s.\nS 28\n,S 29\nN ov\nel p he\nno m en\na su\nch as\nne ur al\nco lla\np se\nca n b e d is co\nve re d fr om\nM D A vi su\nal iz at io ns\n,w hi ch\nis no\nt p os\nsi b le\nin re su\nlt s fr om\not he r vi su al iz at io n m et ho d s.\nQ ua\nnt ifi ca\ntio n of\nm an\nifo ld\nst ru ct ur e\nB ra TS\n,M N IS T\nR es\nN et ,m\nC N N\nS up\np le m en\nta ry\nFi g .S\n27 M D A p re se\nrv es\nth e hi g h d im\nen si on\nal m an\nifo ld\nst ru ct ur e in\nlo w\nd im\nen si on\nal re p re se\nnt at io n m or e ac\ncu ra te ly\nth an\nex is tin\ng m et ho\nd s.\nN eu\nra ln\net w or k b eh\nav io r fo r ex\ntr ap\no la tio\nn ta sk\nM N IS T,\nTC G A\nm C N N ,f M LP\nS up\np le m en\nta ry\nFi g s.\nS 34\n\u2013 S 37\nM D A of fe rs\nm ea\nni ng\nfu lv\nis ua\nliz at io n of\nth e D N N s\u2019 fe at ur e sp\nac e in\nex tr ap\nol at io n ta sk s.\nC ha\nng e in\nD N N s\u2019 fe at ur e sp\nac e w ith\nep oc\nh B ra TS\n,C O V ID\nD en\nse -U N et ,R\nes N et\nS up\np le m en\nta ry\nFi g .S\n22 M D A ca\np tu re s th e g ra d ua\nli m p ro ve\nm en\nt of\nm an\nifo ld\np ro p er tie\ns of\nth e D N N fe at ur e sp\nac e ov\ner th e co\nur se\nof th e ep\noc h s.\nNature Communications | (2023) 14:8506 3\nFig. S22). Here, red and violet denote the starting point (0) and ending point (1) in the manifold, respectively, and other colors denote the normalized distance (from the starting point) in the target manifold (see Methods). The quantitative evaluation of the low dimensional representations from different techniques is also presented in (d) of Figs. 2 and 3, which shows clearly the superiority of MDA over other methods. It is worth pointing out that theMDA preserves the geodesic distance better, as indicated by the Pearson correlation coefficients computed between the geodesic distances of the HD features and low dimensional representation from different techniques. Moreover, MDA shows a significantly better Pearson coefficient value for the trained features than the untrained ones. The Pearson correlation values computed from t-SNE and UMAP representation did not show any notable difference before and after the training of the DNN or at different DNN layers. MDA offers an analysis of the DNN feature space in survival prediction We now study a DNN-based survival prediction model (see methods) with the Cancer GenomeAtlas (TCGA)28 database. The dataset consists of bulk RNA expression levels from 10,060 patients afflicted with 33 cancers. Each data point is a patient consisting of 20,531 genes of varying expression. 80% of the data is used formodel training, and the rest is for testing. A multi-layer perceptron (MLP- see methods) was trained to predict the survival days. The features from several different layers, including the 2nd layer of the 3rd fully connected block (B3-L2), the 2nd layer of the 4th fully connected block (B4-L2), the 2nd layer of the 5th fully connected block (B5-L2), and the 2nd layer of the 6th fully connected block (B6-L2), are displayed in Figs. 4 and S17 for different visualization techniques. The survival days are normalized from 0 to 1 for visualization purposes. It is seen that the MDA yields the most\nmalized manifold distance. Source data are provided as a Source Data file.\nNature Communications | (2023) 14:8506 4\nFig. 3 | Visualization and analysis ofDense-UNet features for segmentation task after training the network. Here, B3-L2 denotes the 2nd layer of the 3rd dense block, B4-L8 denotes the 8th layer of the 4th dense block, B6-L2 denotes the 2nd layer of the 6th dense block, and B7-L8 denotes the last layer before the final output. t-SNE, UMAP and MDA results are shown in (a\u2013c) respectively for training\nand testing datasets at different network layers. The colorbar denotes the normalized manifold distance. d Pearson correlations between the geodesic distances among feature data points in HD and low dimensional representation from differentmethods are shown for training and testing data. Source data are provided as a Source Data file.\nNature Communications | (2023) 14:8506 5\ndescriptive representation of survival time. For both training and testing datasets, UMAP shows clustered visualizations, which show little correlation with the continuous ground truth. Although t-SNE performs slightly better in this case, a lot of spurious clusters are seen in its visualization. MDA achieves the highest Pearson correlation values with the ground truth when the low dimensional representations from different techniques are compared quantitatively. Not surprisingly, the Pearson coefficient value increases as the MDA is applied to the deeper layers. Interestingly, the correlation value decreases drastically in the case of the testing dataset (see the last row of Fig. 4), suggesting poor generalizability of the trainedmodel toward the testing dataset. Indeed, the survival prediction DNN performs poorly in testing, with a resultant correlation value of only 0.3526 between predictions and testing labels. This is inferior to that of the training case (0.9312). Similarly, the strong generalizability of DNN toward unseen data will also be reflected in the MDA visualizations, as shown in the next example.\nMDA deciphers the DNN feature space in gene expression prediction Theutility ofMDA is further illustratedby examining a gene expression prediction network. Briefly, a network is designed to predict the change ingene expressionobserved inhumancell lines perturbedwith small molecules from L1000 database29,30. To visualize the intermediate layers of the DNN30 (see Methods), we select the features of the first (L1), second (L2), third (L3), and fourth (L4) MLP layers. The visualizations of these four latent features before/after training are shown in Fig. 5 and Supplementary Fig. S18. Again, the MDA features visualization shows no systematic pattern before training. After training, the features in MDA display show a continuous change in colors for both training and testing datasets. In this case, t-SNE and UMAP fail to show any useful information in both training and testing cases. The quantitative evaluation of low dimensional representations from different techniques also shows the superiority of MDA in visualizing the feature manifold (Fig. 5-d) compared to t-SNE and UMAP.\nMDA affords feature space analysis in super resolution tasks The fourth feature space explored is from a generative adversarial network (SRGAN) applied for super resolution of dermoscopic images. To visualize the intermediate layers of the SRGAN,we select features of (a) output of the first residual block (RB1), (b) output of the third residual block (RB3), (c) output of the fourth residual block (RB4), and (d) output of the up-sampling block (UB) in the generator. The visualizations of four latent features after training of DNN are shown in Fig. 6. As shown in Fig. 6c, after the network training, the MDA visualizations of the training and testing set features show continuous change of colors, which demonstrates the effective learning of the DNN for performing super resolution task. t-SNE and UMAP fail to show any useful information about the feature quality or training status of the network Fig. 6a, b.\nMDA shows superior feature visualization in classification tasks To demonstrate that MDA can also show insightful visualizations of deep learning feature space in classification tasks, we now investigate the feature space of ResNet5031 applied on a public COVID-19 dataset32,33 to classify the data into four categories. The ResNet50 network consists of 4 substructures (see Methods). To visualize the intermediate layers of the ResNet50, we selected features of output of the 4th residual block\u2019s last convolutional layer in substructure 2 (S2B4-L3), the 2nd residual block\u2019s last convolutional layer in substructure 3 (S3-B2-L3), the 6th residual block\u2019s last convolutional layer in substructure 3 (S3-B6-L3), and the 3rd residual block\u2019s last convolutional layer in substructure 4 (S4-B3-L3). The t-SNE, UMAP, and MDA visualizations of these four latent features before/after training are shown in Fig. 7 andSupplementaryFig. S19. Thenetwork achieves an accuracyof\nover 90% after training. Before training, the data points are randomly distributed in MDA visualizations. In contrast, after the training, the feature space becomes well clustered inMDA visualizations, especially in deeper layers. This is understandable as the deeper layers of the DNN extract higher-level features for better classification of the dataset. In this case, although UMAP and t-SNE show some clusters, the quality of these clusters is very poor (see Fig. 7(d)). There are many spurious clusters in the case of t-SNE visualization, making the interpretation of the feature space very difficult. Note that the t-SNE and UMAP in Fig. 7 are unsupervised. We also provide the visualizations of the supervised versions of UMAP and LDA methods in Supplementary Figs. S20 and S21. Again, thesemethods fail to provide any informative results about the training status of the network. The quantitative evaluations of the low dimensional representations from different techniques (Fig. 7(d)) also show the superiority of MDA over other techniques."
        },
        {
            "heading": "Discussion",
            "text": "Dimensionality reduction of HD feature datasets is challenging, especially for deep regression tasks because of the complex inner structures of the feature space data. In this work, an effective MDAmethod is proposed for the visualization and analysis of the DNN feature space data. MDA leverages the information on HD labels in the dimensionality reduction process by using the estimated manifold layout of the DNN outputs. MDA allows us to visualize the extracted features and assess the quality of the features. MDA finds the underlying manifold of the features before data embedding, which is fundamentally different from commonly used data exploration methods such as PCA, ICA34, FEM35, t-SNE, UMAP, andMDS36. All these conventional methods attempt to compute a compressed representation of the data based on someassumptions about the behaviorsof thedata inHDand LD,which maynot be fully satisfied inmost of the practical scenarios.MDA learns the manifold of the feature data and therefore can naturally adapt to the data.\nMDA has a number of unique features that make it ideal for visualizing the latent space information of DNNs. In particular, MDA provides an effective mechanism to take advantage of the training label information during the dimensionality reduction and visualization of the features at a particular layer of the deep network. However, MDA can also be used for unsupervised visualization, where the manifold outline is constructed from the input data (see Fig. 8 for an example analysis of scRNA-seq data of zebrafish embryogenesis37\u201339 by unsupervised MDA). This makes MDA suitable for multiple data exploration tasks such as dimensionality reduction, data continuum analysis, and visualization in the same framework. In addition, MDA uses parallelizable computational steps to save run-time (see our implementation codes), whichmakes it suitable for analyzing DNNs of any depth, structure, and complexity.\nAssessing the structure of a data manifold is complicated due to its inherent complexities in both geometry and topology. Various metrics, however, have emerged to help quantify manifold structures40, including (1) intrinsic dimensionality, which gauges the fewest number of parameters needed to adequately represent the data; (2) curvature, a metric that explores manifold structure through multiple lenses like Gaussian, mean, and sectional curvatures, highlighting \u2018folds\u2019 or \u2018bends\u2019; (3) geodesic Distance, the shortest path between two points on a manifold, offering insights into data point interconnectedness. In Supplementary Section 8, we evaluated all these metrics for high-dimensional feature data and their lowdimensional counterparts, for two datasets. The results indicated that MDA offers better preservation of these metrics as compared to the existing manifold-embedding techniques like LLE (see Tables S3 and S4). Additionally, we furnished thorough qualitative and quantitative analyses\u2014specifically utilizing Pearson correlation between geodesic distances in high and low dimensions\u2014comparing MDA with\nNature Communications | (2023) 14:8506 6\nFig. 4 | Visualization and analysis of MLP features for survival prediction task after training the network. Here, B3-L2 denotes the 2nd layer of the 3rd fully connected block, B4-L2 denotes the 2nd layer of the 4th fully connected block, B5L2 denotes the 2nd layer of the 5th fully connected block, and B6-L2 denotes the 2nd layer of the 6th fully connectedblock. t-SNE, UMAP andMDA results are shown\nin (a\u2013c) respectively for training and testing datasets at different network layers. The colorbar denotes the normalized manifold distance. d Pearson correlations between the geodesic distances among feature data points in HD and low dimensional representation from different methods are shown for training and testing data. Source data are provided as a Source Data file.\nNature Communications | (2023) 14:8506 7\nNature Communications | (2023) 14:8506 8\nFig. 6 | MDA Visualization of SRGAN features for super resolution task after network training.Here, RB1 denotes the first residual block, RB3 denotes the third residual block, RB4 denotes the fourth residual block, and UB denotes the upsampling block. t-SNE, UMAP and MDA results are shown in (a\u2013c) respectively for training and testing datasets at different network layers. The colorbar denotes the\nnormalized manifold distance. d Pearson correlations between the geodesic distances among feature data points in HD and low dimensional representation from differentmethods are shown for training and testingdata. Sourcedata are provided as a Source Data file.\nNature Communications | (2023) 14:8506 9\nFig. 7 | Investigation of the feature space of ResNet50 network applied on a public COVID-19 dataset for classification into four categories. a\u2013c t-SNE, UMAP, andMDA visualizations of the feature spaces at four different layers before/ after training. Here, S2-B4-L3 denotes the 4th residual block\u2019s last convolutional layer in substructure 2, S3-B2-L3 denotes the 2nd residual block\u2019s last convolutional layer in substructure 3, S3-B6-L3 denotes the 6th residual block\u2019s last convolutional layer in substructure 3, and S4-B3-L3 denotes the 3rd residual block\u2019s last\nconvolutional layer in substructure 4. Before training, the data points are randomly distributed in MDA visualizations. However, after the training, the feature space becomeswell clustered inMDAvisualizations, especially indeeper layers. t-SNE and UMAP fail to show any information about the training status of the network. d k-nearest neighbor classification accuracyof the lowdimensional representations from different techniques. Source data are provided as a Source Data file.\nNature Communications | (2023) 14:8506 10\nother established methods like t-SNE, UMAP, LLE, and Isomap across five datasets (see Figs. 2\u20136, Supplementary Fig. S27).\nThe proposed MDA can be used for: (i) finding effect of a particular part of input data on DNN feature space, and (ii) testing the robustness of DNNs. In the first case, the effect of a particular part of input in the training process may provide important clues to find how different input parts are used in the decision process of the deep network. It is shown in Fig. 9 that if a portion of the input is masked or changed, MDA is able to show the effect of the action in the feature domain. This may help us in removing the suspicious input components accordingly. Such a type of MDA-guided analysis may be valuable for a user to assess the roles of particular data in the overall performance of the network. Testing the robustness of an AI model is important before its employment in critical tasks such as disease diagnosis or treatment planning. As noticed in several previous works, deep convolutional networks can be easily \u2018fooled\u2019 to make mistakes by adding perturbations (such as Gaussian noise) in the inputs41\u201343. As demonstrated in Supplementary Fig. S42, MDA provides interactive visualizations of the DNN features after some random Gaussian noises are added to thedata duringmodel training and testing.Morecomplex noise addition or input modification can be performed similarly to model the adversarial attacks in reality to test the robustness of the deep networks. From our analysis, it is found that although DenseUNet can show reasonable results at SNR of 0.3, its performance\n-20 -10 0 10 20 30 tSNE1\n-30\n-20\n-10\n0\n10\n20\ntS N E2\n-5 0 5 UMAP1\n-4\n-2\n0\n2\n4\nU M AP 2\n-8 -6 -4 -2 0 2 4 6 8 10 MDA1\n-10\n-8\n-6\n-4\n-2\n0\n2\n4\n6\n8\nM DA 2\nt-SNE UMAP MDA 0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nD EM\naP\n1\na\nb\nc\nhpf\nFig. 8 | Unsupervised MDA visualization of continuous manifold in scRNA-seq data of zebrafish embryogenesis. a t-SNE and UMAP visualization, (b) unsupervised MDA visualization, and (c) DEMaP index computed from the dimensionality-reduced data using different methods. From (a) t-SNE and UMAP primarily cluster the data and do not effectively represent the cell transitions from one stage to another. In contrast, MDA (b) clearly illustrates cell transitions from\nlower hours postfertilization (hpfs) (red, yellow, green) to higher hpfs (magenta, violet) through intermediate hpfs (cyan, blue). The unsupervised MDA\u2019s ability to better preserve the high-dimensional geodesic distance in low dimensions is also evident in the DEMaP index values (c). Source data are provided as a Source Data file.\nNature Communications | (2023) 14:8506 11\ndegrades substantially when the SNR reaches 0.1. Thus, MDA provides a useful tool to evaluate the robustness of a DNN in specific applications where noise or adversarial attacks are of concern. Moreover, from Supplementary Fig. S42, it is obvious that theMDA visualizations of the robustDense-UNet features showbetter continuousdistribution of colors in comparison to MDA visualizations of features from less robust simple U-Net44 (Supplementary Fig. S43). For quantitative analysis, we have added the Pearson correlation between the distance of data points inMDA visualization and distance among the data labels to show high Pearson correlation value (arc shape) corresponding to better robustness of the network towards noise (Supplementary Fig. S44). For both networks, we used signal to noise ratios (SNR) of \u221e (no noise-original images), 0.1, 0.3 and 0.5. In both cases, MDA visualizations become more arc-shaped and color distribution becomes more ordered with improvements in SNR. These results suggest that increased noise negatively affects the DNNs\u2019 learning process, reducing the quality of the intermediate layer features which is reflected on MDA visualizations. However, at the same SNR level, the MDA visualization of Dense-UNet features is better arc-shaped and color distribution is more ordered than in MDA visualizations of the simple U-Net features. This proves that Dense-UNet is more robust to noise than simple U-Net which is also supported by the Dice scores of these two DNNs (Supplementary Figs. S42 and S43). MDA also reveals the robustness of DNNs to noise for classification tasks through feature space visualization (see Supplementary Figs. S45 and S46).\nMDA serves as a versatile tool for gaining insights into the DNN feature space. First, MDA is employed to elucidate the impact of specific layers on feature behavior. In Supplementary Figs. S30 and S32, the MDA visualizations of RELU, batch normalization, and dropout layers are presented for two different datasets (MNIST and TCGA). It is evident that RELU and batch normalization layers improve the manifold continuity and correct the distance of the data points over the manifold. In other words, these layers help the network learn the relationship between the data and the label. The dropout layer is known to have no impact on the feature space other than making the features sparse. Similar MDA visualizations of the features before and after dropout layers confirm this observation. Existing methods such as t-SNE fail to show such insights (Supplementary Figs. S31 and S33). Second, MDA facilitates the demonstration of network generalizability, as depicted in Figs. 4 and 5. In these figures, it is evident that the colormaps in feature visualization for a generalizable network are consistent with the position on the manifold. Third, MDA allows for a better understanding of the relationship between the feature space and network performance. As examples, in Supplementary Figs. S34 and S36, we provide MDA visualizations for two networks trained with partial labels on TCGA and MNIST datasets. In the former case, we selected TCGA data with patients with survival days ranging from 0 to 7000days. We trained the network with this data and tested it on patient data with survival days ranging from 0 to 10,000days. MDA visualization reveals that the network projects the data of higher survival days (>7000days) mostly between 4000 and 7000days. The network identifies similar patient data in this unknown day range from the training data and projects the data to a similar position as the training data point. Similar insights can be obtained from MDA visualizations for the MNIST dataset, as seen in Supplementary Fig. S36. Such insights are not visible in t-SNE visualizations (Supplementary Figs. S35 and S37). In another experiment, we applied MDA to investigate the feature visualization differences at different epochs of the training for segmentation and classification networks. For segmentation task, we chose the features of the testing datasets at epochs of 1, 3\nFig. 9 | MDA visualization of Dense-UNet training features for segmentation task (see Fig. 3) with varying square mask sizes. (Row 1) Input images (of size 240 \u00d7 240 pixels) are masked by square shapes ranging from 10 \u00d7 10 to 20\u00d7 20 pixels. (Row 2) Input images are masked by square shapes ranging from 30\u00d7 30 to 50\u00d7 50 pixels. (Row 3) Input images are masked by square shapes ranging from 100\u00d7 100 to 120\u00d7 120 pixels. The ground truth segmentation labels and estimated segmentation labels for a randomly selected input are shown in the rightmost\ncolumn for each mask size. MDA visualization for the segmentation model trained with a small mask range results in a structured color distribution and compact shapes. However, when increasing the mask size to 30-50 and 100-120, the visualized feature shapes become less compact, and the color distribution becomes noisier. These observations indicate that as the mask size increases, the DenseUNet\u2019s ability to accurately segment images deteriorates. Source data are provided as a Source Data file.\nNature Communications | (2023) 14:8506 12\nand 10 and visualized themusingMDA inSupplementary Fig. S22a. Our results indicate that the MDA visualization of features at epoch 10 displayed a more organized color arrangement than at epoch 3. Similarly, theMDAvisualization at epoch3hadamore structured color pattern compared to that of epoch 1. This observation indicates that feature visualization by MDA is capable of reflecting the network\u2019s learning status with change in epoch. For classification task, the data points belong to different classes gradually get separated in MDA\u2019s visualization with progress of epochs as seen in Supplementary Fig. S22b.\nMDA can help unveil distinctive phenomena within neural networks. A recent concept, neural collapse, initially applied to classification tasks, signifies the convergence of final-layer features into singular points when the network is further trained after achieving perfect training accuracy45\u201349. While its manifestation in regression scenarios remains unclear, our investigation in Supplementary Section 9, utilizing MDA visualizations, confirms its existence. MDA visualization reveals that the features align on a simplified curve as the features go into neural collapse. This empirical validation cannot be obtained through alternative techniques (as illustrated in Supplementary Figs. S28 and S29). As a future step, we aspire to formalize this collapse theoretically, contributing a cornerstone to the analysis of regression networks.\nMDA also offers novel insights into the feature space of classification DNNs. As demonstrated in the case of the diabetic retinopathy (DR) dataset, clinically similar patient groups are positioned close to each other in MDA visualizations after DNN training (Supplementary Figs. S40 and S41). Feature data of normal and mild DR patients are positioned closely, as are the data of severe and proliferative patient groups. Most notably, the gradual transition from normal to proliferative through mild, moderate and severe stages is clearly visible. Such preservation of clinical information is not evident in t-SNE and UMAP visualizations (as shown in Supplementary Fig. S41).\nMDA is designed to analyze features from the deep learning latent space, elucidating information flow within a DNN and exploring its properties such as appropriateness, generalizability, and adversarial robustness. Many other high-dimensional (HD) data, such as gene expressions, can also be analyzed by MDA in an unsupervised manner (see Fig. 8). It is noteworthy that like many other data analysis techniques such as PCA, FEM, GSE50, CCSF39, t-SNE, and UMAP, interactive relationships of the components inside an HD feature point are not considered explicitly during the MDA embedding process51. For some special applications such as the assessment of image similarity in a low dimensional embedding, DNN-basedmanifold learning techniques like Deep Manifold Embedding Method (DMEM)52 and Deep Local-flatness Manifold Embedding (DLME)53 couldbe used. In this process, however, MDA is also useful as it offers an effective method for analyzing the deep learning features and sheds insights into the embedding process.\nWe have proposed anMDA strategy for DNN feature visualization that is applicable to all kinds of deep learning tasks irrespective of the domains. The approach is applicable in a broad context and enables an understanding of the quality of the DNN features in deep learning tasks.We envision that theMDA strategy will be helpful in interpreting and optimizing the training procedures of DNNs, improving the accuracy and robustness of AI models, and identifying potential confounding factors and biases. Although this work is focused on analyzing DNN features, MDA can be applied to any application requiring dimensionality reduction and visualization."
        },
        {
            "heading": "Methods",
            "text": ""
        },
        {
            "heading": "Motivation behind MDA",
            "text": "Riemannian manifold. A Riemannianmanifold \u00f0M,g\u00de is a real smooth manifold M equipped with the a metric g. Specifically, the metric is defined at each point p 2 M via the bi-linear map gp : TpM\u00d7TpM ! R, whereTpM is the tangent space at point p. Let\nX \u00f0M\u00de denotes the space of time invariant vector fields on themanifold M. For any two vector fields X ,Y 2 X \u00f0M\u00de, the affine connection on manifold M is a bi-linear map (X, Y)\u2192\u2207XY such that for all differentiable functions f 2 C2\u00f0M\u00de, the following two conditions are satisfied\n\u2022 \u2207fXY = f\u2207XY, \u2022 \u2207X(fY) = df(X)Y + f\u2207XY,\nwhere df(X) is the directional derivative of function f in the direction of X. Define a coordinate chart \u00f0U,\u03c6\u00de as \u03c6 : U ! V, where U M is an open set and V Rn. The affine connection on an n-dimensional manifold is completely determined by n3 real valued smooth functions on U, namely the Christoffel symbols of the second kind \u0393kij on local coordinates (u1,\u22ef , un). Let \u2202k denotes the vector field on U . Then, in local coordinates, the affine connection can be characterized in terms of the covariant derivatives of basis vectors\n\u2207\u2202i\u2202j = Xn k = 1 \u0393kij\u2202k ,\nwhere \u0393kij are the Christoffel symbols of the second kind. For the specific case of the Levi-Civita connection, the Christoffel symbols have the following explicit form\n\u0393kij = 1 2 gkr \u2202gir \u2202xj + \u2202gjr \u2202xi \u2202gij \u2202xr\n! :\nGeodesic curves. A geodesic on a smoothmanifoldM equipped with an affine connection\u2207 is defined as a curve \u03b3 : \u00bd0,1 ! M such that the parallel transport along the curve preserves the tangent vector to the curve. Specifically, \u2207 _\u03b3\u00f0t\u00de _\u03b3\u00f0t\u00de=0, at each point along the curve, where _\u03b3\u00f0t\u00de is the derivative with respect to t\u2208 [0, 1]. Alternatively, the geodesics of the Levi-Civita connection can be defined as the locally distance-minimizing paths. Specifically, in a Riemannian manifold M with the metric tensor g, the length of a path \u03b3 : \u00bd0,1 ! M is the following functional,\nL\u00bd\u03b3 = Z 1 0 \u00f0g\u03b3\u00f0t\u00de\u00f0 _\u03b3\u00f0t\u00de, _\u03b3\u00f0t\u00de\u00de\u00de 1 2dt,\nAccordingly, the geodesic distance d(p, q) between two points p,q 2 M is defined as\nd\u00f0p,q\u00de= inffL\u00bd\u03b3 : \u03b3 : \u00bd0,1 ! M,\u03b3\u00f00\u00de=p,\u03b3\u00f01\u00de= q,\u03b3 is piecewise smooth g:\nUsing the Euler-Lagrange equations to minimize the functional L[\u03b3] yields the following set of differential equations for geodesics in local coordinates,\n\u20ac\u03b3i\u00f0t\u00de+ Xn j,k = 1 \u0393ijk _\u03b3j\u00f0s\u00de _\u03b3k\u00f0s\u00de=0,\nwhere i = 1, 2,\u22ef , n.\nManifolds in neural networks. The aim of a given neural network is to approximate a target function g such that y = g(x), where x = \u00f0x1, ,xn\u00de 2 Rn and y 2 M are the input data and target value which is an element of a target manifold M such as the manifold of continuous functions. We note that in practical scenarios, when the target value is a vector y = (y1,\u2026, yn), the manifoldM has a dimension of n. Let by denotes the network\u2019s output parametrized by the weights w = (w1,\u22ef ,wm) andbias bof the network\u03b8= \u00f0w,b\u00de 2 \u0398 Rm \u00d7R. The network output by= f \u00f0x;\u03b8\u00de is an element of the output manifold S. In particular, for a one layer neural network with the sigmoid non-\nNature Communications | (2023) 14:8506 13\nlinearity, we have m = n, and the manifold of outputs is defined as follows\nS = f \u00f0x;\u03b8\u00de= \u03c3 wTx+b ;\u03b8 2 \u0398 : is m + 1 dimensional submanifold of M. Moreover, the tangent space TbyS at the point by 2 S is defined as the span of the set of functions\nTbyS = spanfby\u00f0\u03b8\u00de\u00f01 by\u00f0\u03b8\u00de\u00de,by\u00f0\u03b8\u00de\u00f01 by\u00f0\u03b8\u00de\u00dex1, ,by\u00f0\u03b8\u00de\u00f01 by\u00f0\u03b8\u00de\u00dexng, since\n\u2202 \u2202b \u03c3\u00f0wTx +b\u00de= \u03c3\u00f0wTx +b\u00de\u00f01 \u03c3\u00f0wTx + b\u00de\u00de, \u00f01\u00de\n\u2202 \u2202wi \u03c3\u00f0wTx + b\u00de= \u03c3\u00f0wTx +b\u00de\u00f01 \u03c3\u00f0wTx +b\u00de\u00dexi, i= 1,2, ,n: \u00f02\u00de\nThemanifold S is a submanifold ofM, and as such can be viewed as an (m + 1)-dimensional hyper-surface inside the space of real-valued continuous functionsM= C\u00f0\u00bd0,1 \u00de16. Training the network is equivalent to finding an exact, or approximate value of \u03b8*, for which the distance from target function g to S is minimum, namely\n\u03b8 = argmin \u03b82\u0398\ndist\u00f0g,S\u00de,\nwhere dist \u00f0g,S\u00de denotes the distance of the target function from the output manifold (p. 431 of ref. 16).\nIn neural networks with more than one layer, weights and bias of each of the layers form a submanifold and as we go deeper into the network, the manifold space becomes more and more like the output manifold or the target manifold in the case of well-trained networks. Thus, if we can visualize the features of the intermediate layers of the networkwith respect to the targetmanifold, the resulting visualization should show the quality of the training. For well-trained cases, the visualization should reflect the continuous position of the data points on the target manifold. For ill-trained cases, the visualization should not have any information from the target manifold and thus it should not able to show any continuity in the positions of the feature data points.\nSorting of data labels via optimal histogram bin count Consider a test (out-of-sample) dataset {x1,\u22ef , xm}. Let by1, ,bym denote thepredicted values fromthe trained feed-forwardnetwork, i.e., byi = f \u00f0xi;\u03b8*\u00de, where \u03b8* is the parameters of the neural network after model training. Wedefine thepairwise geodesicdistances among theoutputs as follows dij =d\u00f0byi,byj\u00de, 1\u2264 i<j \u2264m: For simplicity, we order these pairwise distances based on the lexicographic order of their 2-tuple indices, i.e., \u00f0i,j\u00de< \u00f0i0,j0\u00de if i< i0, or i= i0 and j < j0. Subsequently, we assign the single index \u2113\u2208 {1, 2,\u22ef , (m2 \u2212m)/2}. In particular, we let fd\u2018g\u00f0m 2 m\u00de=2 \u2018= 1 denote the sequence of pairwise distances, and define the empirical probability density function associated with these distances as follows\nbpm\u00f0d\u00de= 2m2 m X \u00f0m2 m\u00de=2\n\u2018= 1\n\u03b4d\u2018 \u00f0d\u00de,\nwhere \u03b4d\u2018 \u00f0 \u00de is Dirac\u2019s delta function concentrated at d\u2113. By the strong law of large numbers, the empirical estimator bpm\u00f0d\u00de converges to a\nlimiting density function p(d) asm\u2192\u221e almost surely. In the sequel, we describe an approach to cluster (partition) the test dataset {x1,\u22ef , xm} via an optimal histogram bin count approach that minimizes the integrated mean square error between the histogram estimate value and the limiting distribution p(d).\nPseudo labeling via histogram bin count. Consider a histogram with equally spaced bins. In particular, let tmi 2 R+ denote the bin boundaries, and let hm = tm(i+1) \u2212 tmi denote the bin widths which is uniform across all bins and is thus independent of index i. Associated with this histogram, let epm\u00f0d\u00de denote the histogram estimation for the distance d 2 R+ . The integratedmean squared error is then defined as follows\nIMSE= Z 1 0 E\u00bd\u00f0~pm\u00f0s\u00de p\u00f0s\u00de\u00de2 ds,\nwhere the expectation is taken with respect to the binomial distribution of the number of samples that fall into the same bin as the point s. It is known that IMSE=O\u00f0\u00f0m2 m\u00de 2=3\u00de. To achieve this rate of convergence, we adopt Scott\u2019s optimal binning strategy54. Let Im(d) be the bin interval that contains the point d 2 R+ and let tm(d) denote the left-hand endpoint of the bin Im(d). Integrating the density function over bin Im(d) yields\npm\u00f0d\u00de= Z tm\u00f0d\u00de+hm tm\u00f0d\u00de p\u00f0y\u00dedy:\nUsing Taylor\u2019s expansion for the integrand, p\u00f0y\u00de=p\u00f0d\u00de+p0\u00f0d\u00de\u00f0y d\u00de+ O h2m , yields the following approximation of the integral\npm\u00f0d\u00de= Z tm\u00f0d\u00de+hm tm\u00f0d\u00de p\u00f0d\u00de+p0\u00f0d\u00de\u00f0y d\u00de+O h2m n o dy,\n=hmp\u00f0d\u00de+ 1 2 p0\u00f0d\u00de h2m 2hm d tm\u00f0d\u00de\nh i +O h3m :\nWe denote the count of empirical distance values falling in the bin interval Im(d) by sm(d). Then, sm(d) has a binomial distribution B \u00f0m2 m\u00de=2,pm\u00f0d\u00de\n54. The histogram estimate then is given by a random variable defined as epm\u00f0d\u00de=2sm\u00f0d\u00de= \u00f0m2 m\u00dehm , with expectation\nEfepm\u00f0d\u00deg=pm\u00f0d\u00de=hm, \u00f03\u00de =p\u00f0d\u00de+ 1\n2 hmp\n0\u00f0d\u00de p0\u00f0d\u00de d tm\u00f0d\u00de +O h2m : \u00f04\u00de\nThe bias can be expressed as\nBias=Efepm\u00f0d\u00deg p\u00f0d\u00de= 12hmp0\u00f0d\u00de p0\u00f0d\u00de d tm\u00f0d\u00de +O h2m : The variance of the histogram estimate can be derived as follows\nVar\u00f0~pm\u00f0d\u00de\u00de=2pm\u00f0d\u00de 1 pm\u00f0d\u00de = \u00f0m2 m\u00deh2m , \u00f05\u00de\n= 2hmp\u00f0d\u00de+O h2m n o 1 O hm = \u00f0m2 m\u00deh2m , \u00f06\u00de\n=2p\u00f0d\u00de= \u00f0m2 m\u00dehm +O\u00f01=\u00f0m2 m\u00de\u00de: \u00f07\u00de\nNature Communications | (2023) 14:8506 14\nThe mean squared error between the histogram estimate and the true density value is defined by MSE\u00f0d\u00de=E \u00f0epm\u00f0d\u00de p\u00f0d\u00de\u00de2h i: Using Eqs. (4) and (7), we can thus write\nMSE\u00f0d\u00de=2p\u00f0d\u00de= \u00f0m2 m\u00dehm + 1 4 h2mp 0\u00f0d\u00de2 +p0\u00f0d\u00de2 d tn\u00f0d\u00de 2\nhmp0\u00f0d\u00de2 d tm\u00f0d\u00de +O 2=\u00f0m2 m\u00de+h3m :\n\u00f08\u00de\nIntegration of MSE(d) in eq. (8) results in\nIMSE= Z 1 0 MSE\u00f0s\u00deds = 2= \u00f0m2 m\u00dehm\n+ 1 12 h2m Z 1 0 p0\u00f0s\u00de2ds +O 2=\u00f0m2 m\u00de+h3m :\n\u00f09\u00de\nBy optimizing the first two terms in eq. (9), the optimal choice of bin bandwidth is obtained in54 as follows\nh*m = 6= Z 1 0 p0\u00f0s\u00de2ds 1=3 \u00f0\u00f0m2 m\u00de=2\u00de 1=3: \u00f010\u00de\nwhich, is the optimal choice for hm. We notice that this optimal choice depends on the derivative of the density p(d) which is unknown. This density itself depends on the underlying validationdata-set {x1,\u22ef , xm} as well as the parameters \u03b8* of the trained feed-forward network f( \u22c5 ; \u03b8*). Consider a folded Gaussian distribution with zero mean,\np\u00f0d\u00de= ffiffiffi 2\npffiffiffi \u03c0 p \u03c3 exp\u00f0 d2=2\u03c32\u00de, d \u22650: \u00f011\u00de\nAbove, \u03c3 >0 is the variance. Plugging the folded Gaussian density function in Eq. (11) into Eq. (10) yields\nh m = 12 1=3\u03c01=6\u03c3\u00f0\u00f0m2 m\u00de=2\u00de 1=3: \u00f012\u00de\nIn the sequel, we use the bin width estimate in Eq. (12). As shown in Supplementary Fig. S8, whenm\u2192\u221e, the ratio of the estimate h*m to the optimal value is near one for many heavy tail and bimodal distributions."
        },
        {
            "heading": "Bayesian dimensionality reduction",
            "text": "The feature data should be projected in such a way that the Euclidean distance of the data points in each of the small parts of the manifold (eachof the bins in the last step) is preserved. In turn, it wouldpreserve the manifold curvature or geodesic distance among the data points (locally on the manifold, the geodesic distance can be well approximated with the Euclidean distance16 \u2014see Supplementary Fig. S24). To achieve this, we use a supervised Bayesian projection, with the pseudo labels created in theprevious step. TheBayesianprojection inMDAhas two sets of parameters: (1) the lowdimensional representation that has Gaussian-distributed data values and (2) the prior information matrix from the labels created in the last step. All prior variables in the model are denoted by \u039e = {\u03bb,\u03a6,\u03a8}, where the remaining variables are denoted by \u0398 = {b,Q,T,W,Z} and the hyperparameters (scale variables of Gamma distribution) are denoted by \u03b6 = f\u03b1\u03bb,\u03b2\u03bb,\u03b1\u03d5,\u03b2\u03d5,\u03b1\u03c8,\u03b2\u03c8g. See Supplementary Fig. S2 and Supplementary Tables S1 and S2 for list of the notations and probability distribution functions for each of the variables. The rationale behind choosing the distribution models and parameters are discussed in Supplementary Sections 2 and S12 (Supplementary Figs. S3\u2013S8, S38 and S39).\nThe Bayesian dimensionality reduction is based on the following joint data distribution\np\u00f0ey,\u0398,\u039ejX\u00de=p\u00f0\u03a6\u00dep\u00f0Qj\u03a6\u00dep\u00f0Z jQ,X\u00dep\u00f0\u03bb\u00dep\u00f0bj\u03bb\u00dep\u00f0\u03a8\u00dep\u00f0W j\u03a8\u00dep\u00f0T jb,W ,Z\u00dep\u00f0eyjT \u00de, \u00f013\u00de\nwhere X (of size m \u00d7 n) denotes the input data (DNN features at a specific layer in MDA), and ey is the pseudo label generated via the histogram bin count method of by= f \u00f0x;\u03b8*\u00de. The variational approximation of the posterior distribution is as follows\np\u00f0\u0398,\u039ejX ,ey\u00de\u2248q\u00f0\u0398,\u039e\u00de=q\u00f0\u03a6\u00deq\u00f0Q\u00deq\u00f0Z\u00deq\u00f0\u03bb\u00deq\u00f0\u03a8\u00deq\u00f0b,W \u00deq\u00f0T \u00de, \u00f014\u00de where the factored posterior can be modeled as a product of gamma distributions\nq\u00f0\u03a6\u00de= Ym f = 1 YR s = 1 G \u03d5fs ;\u03b1\u03d5 + 1 2 , 1 \u03b2\u03d5 + qfs 2 2\n0B@ 1CA 10BB@ 1CCA, \u00f015\u00de\nwherem and R denote the dimensionality of the original and reduced data space andG\u00f0 ;\u03b1,\u03b2\u00de denotes the gammadistributionwith the shape parameter \u03b1 and the scale parameter \u03b2. The approximate posterior distribution of the projection matrix is a product of multivariate Gaussian distributions and can be written as\nq\u00f0Q\u00de= YR s = 1 N qs;\u03a3 qs Xezs, diag e\u03d5s +XX> 1 : \u00f016\u00de Here, the small letters are the s-th vector of the corresponding matrix of capital letters (e.g., qs denotes the s-th column vector of Q and zs denotes the s-th row vector of the mean matrix of Z). Here, N \u00f0 ;\u03bc,\u03a3\u00de denotes the normal distribution with the mean vector \u03bc and the covariancematrix \u03a3. The tilde notation denotes the posterior expectation,gf\u00f0\u03c4\u00de= Eq\u00f0\u03c4\u00de\u00bdf \u00f0\u03c4\u00de . The scale parameters are computed using the posterior sufficient statistics of the projectionmatrixQ (of sizem \u00d7 R). The approximate posterior distribution of the projected data samples is computed as a product of multivariate Gaussian distributions\nq\u00f0Z\u00de= Yn i = 1 N zi;\u03a3 zi eQ>xi + eWeti eWb , I+ gWW> 1 : \u00f017\u00de\nHere, the score variables ti is the i-th vector of score matrix T (of size n \u00d7K) and W (of size R \u00d7K) is a matrix of weight parameters. In this supervised learning, we need to learn the bias vector (of size K \u00d7 1) and the weight matrix that has Gaussian distributed data, and the priors whichhaveGammadistribution. The equation for the priors of the bias vector can be written as\nq\u00f0\u03bb\u00de= YK e= 1 G \u03bbe;\u03b1\u03bb + 1 2 , 1 \u03b2\u03bb + f b2e 2\n0@ 1A 1 0B@ 1CA, \u00f018\u00de where K is the number of unique values in ci (discrete labels vector created in theprevious step) and \u03bbdenotes theK \u00d7 1 vector of precision priors over bias parameters. The equation for the priors of the weight matrix can be written as\nq\u00f0\u03a8\u00de= YR s = 1 YK e= 1 G \u03c8se;\u03b1\u03c8 + 1 2 , 1 \u03b2\u03c8 + wse 2 2 ! 10@ 1A, \u00f019\u00de where \u03a8 denotes the R \u00d7K matrix of precision priors over weight parameters. The approximate posterior distribution of the supervised\nNature Communications | (2023) 14:8506 15\nlearning parameters is a product of multivariate normal distributions\nq\u00f0b,W\u00de= YK e= 1 N be we ;\u03a3 be,we 1>eteeZe \" # e\u03bbe +N 1>eZ>eZ1 diag e\u03c8e +fZZ> 24 35 1 1CA: \u00f020\u00de\nThe approximate posterior distribution of the score variables is a product of truncated multivariate normal distributions\nq\u00f0T\u00de= Yn i = 1 T N ti; eW>ezi + eb,I,Y e\u2260 ci I tcii > t e i\n! , \u00f021\u00de\nwhere I\u00f0 \u00de is the indicator function, and the untruncated mean values depend on the posterior expectations of the projected instances and the supervised learning parameters. T N \u00f0 ;\u03bc,\u03a3,\u03c1\u00f0 \u00de\u00de denotes the truncated normal distribution with the mean vector \u03bc, the covariance matrix \u03a3, and the truncation rule \u03c1( \u22c5 ) such that T N \u00f0 ;\u03bc,\u03a3,\u03c1\u00f0 \u00de\u00de / N \u00f0 ;\u03bc,\u03a3\u00de if \u03c1( \u22c5 ) is true and T N \u00f0 ;\u03bc,\u03a3,\u03c1\u00f0 \u00de\u00de =0 if otherwise. We need to compute the posterior expectations of the score variables in order to update the approximate posterior distributions of the projected data values and the supervised learning parameters. We can approximate these expectations using a naive sampling approach55.\nThe term XX\u22a4 which is included in the variance of Q ensures that the variance of the original data and that of the projected matrix remain similar. This is similar to PCA, which also attempts to preserve the maximum variance of data in principal directions. Note that computationally, PCA optimizes the preservation of Euclidean distance among data points in HD space and low dimensional representation. Similarly, Eq. (21) includes the term e\u03c8e +fZZ> which preserves the variance of data points corresponding to different discrete labels representing small parts of the manifold.\nThe Bayesian projection algorithm in MDA is based on a variational lower bound, and can be written as (Supplementary Fig. S2) 1. Initialize q(Q),q(Z), q(b,W), and q(T) randomly\nrepeat 2. Update q(\u03a6) and q(Q) using Eqs. (15) and (16) 3. Update q(Z) using Eq. (17) 4. Update q(\u03bb), q(\u03a8), and q(b,W) using eqs. (18),(19) and (20) 5. Update q(T) using equation\n(21) until convergence 6. return q(Q)\nThe projected data is computed by U =XT\u03bc, where \u03bc=Eq\u00f0Q\u00de\u00bdQ ."
        },
        {
            "heading": "Manifold embedding",
            "text": "In the last step of MDA, a deep neural network trained with uniform manifold approximation and projection (UMAP)19,56 loss function is used to embed the projected matrix U= \u00f0u1, ,un\u00deT 2 Rn\u00d7R into V= \u00f0v1, ,vn\u00deT 2 Rn \u00d7 L. A cross entropy loss functiondefinedbetween distribution of data in the target and embedded spaces57 is optimized during the training. In particular, the technique computes local, onedirectional probabilities \u00f0pijj\u00de1 \u2264 i,j \u2264n between a point and its k-nearest neighbors to determine the probability with which an edge (or simplex) exists. This is based on the assumption that data are uniformly distributed across a manifold in a warped data space. Under this assumption, a local notion of distance is set by the distance to the k th nearest neighbor, and the local probability is scaled by that local notion of distance, which is defined as:\npjji = exp d ui,uj\n\u03c1i =\u03c3i\n: \u00f022\u00de\nHere, d\u00f0ui,uj\u00de represents the distance between the row vectors ui and uj (e.g., Euclidean distance), \u03c3i is the standard deviation for the Gaussian distribution, based on the perplexity parameter, such that one standard deviation of the Gaussian kernel fits a set number of nearest neighbors in U. The local connectivity parameter \u03c1i is set to the distance from xi to its nearest neighbor, and \u03c3i is set to match the local distance around ui upon its k nearest neighbors (where k is a hyperparameter). After computing the one-directional edgeprobabilities for each data point, a global probability is computed as the probability of either of the two local, one-directional probabilities occurring,which is defined as:\npij = pjji +pijj\npjjipijj : \u00f023\u00de\nThe computation of the pairwise probability qij between points in the embedding space V= \u00f0v1, ,vn\u00deT 2 Rn\u00d7 L uses the following function:\nqij = 1 +a vi vj 2b 1, \u00f024\u00de\nwhere a and b are hyperparameters that are set based on a desired minimumdistancebetweenpoints in the embedding space. Tofind the embedded vectors v1,\u22ef , vn, a cross entropy loss function is optimized. In particular, the following loss function is defined\nH\u00f0P,Q\u00de= X i\u2260j pij log pij qij\n! + 1 pij\nlog 1 pij 1 qij\n! , \u00f025\u00de\nwhere P = \u00f0pij\u00de1\u2264 i,j\u2260n, and Q= \u00f0qij\u00de1\u2264 i,j \u2264n. MDA is an optimal blend of global structure-preserving techniques like PCA and multi dimensional scaling (MDS)36, and local structure-preserving methods like t-SNE, UMAP and LLE. Please see Supplementary Section 3 for detailed proof of howMDA preserves the local and global manifold structure."
        },
        {
            "heading": "Experiments",
            "text": "Segmentation. We used Dense-UNet, a deep learning model, to segment brain tumors in magnetic resonance (MR) images. The BraTS 2018 dataset25, which contains multimodality 3D MRI images with tumor segmentation labels annotated by physicians, was used to train and evaluate the model. The dataset includes 484 cases in total, which can be divided into 210 high-grade gliomas (HGG) and 75 low-grade gliomas (LGG) cases. Dense-UNet is a modified version of the U-Net architecture that uses dense connections to increase feature reuse and improve performance. The network consists of seven dense blocks (four in the encoder and three in the decoder), each of which stacks eight convolutional layers. Every two convolutional layers are linked together in a feed-forward mode to maximize feature reuse. In our experiments,we randomly split the dataset into 400 training cases and 84 testing cases. We only used the T1 MRI images as inputs, and we chose the 51st to 100th frame of each 3D volume. This preprocessing resulted in a training set with 20,000MRI images and a testing set with 4,200 MRI images. We trained the model using the binary cross entropy loss function and the Adamoptimizer.We set the batch size to 16 and used the early stop strategy58 with patience parameter of 20 to monitor the validation loss. After training, theDice coefficient between the network\u2019s output and the ground truth of the training and testing sets were 0.7850 and 0.7354, respectively. Examples of the outputs of the trained network are shown in Supplementary Fig. S13.\nSurvival prediction. We established a multi-layer perceptron (MLP) model to predict the survival days of cancer patients from genomics data. We used the Cancer Genome Atlas (TCGA)28 dataset, which contains gene expression (normalized RNA-seq) and patient survival data for 10,956 tumors from 33 cancer types. The survival prediction\nNature Communications | (2023) 14:8506 16\nnetwork had six fully connected blocks in total. Each block contained two fully connected layers with the same dimension and one batch normalization layer. The number of dimensions was reduced from 2048 to 1024, then 512, 256, 128, and 64. After that, a dropout layer with dropout rate of 0.25 and a fully connected layer with 4 channel were adopted. Finally, the 1-dimensional output gave the prediction of the patients\u2019 survival days. Before training, we conducted data preprocessing. We first selected the cases where the information \u201cdays to death\u201dwas available. Then, we standardized the survival days to 0-1 by dividing by the maximum value. Finally, we saved the corresponding gene expression value of each case and processed the data by z-score normalization. After preprocessing, the applicable data included 2,892 cases, each containing the normalized expression value of 20,531 genes and corresponding standardized survival days. All cases were split into train-test subsets with a 4/5:1/5 ratio. During the training process, we selected the mean squared error (MSE) loss function and Adam optimizer. We set the batch size as 32. Additionally, we adopted the early stop strategy to monitor the validation loss with patience parameter of 50. After training, theMSE between the network\u2019s output and the ground truth of the training and testing sets were 0.001227 and 0.007845, respectively.\nGene expression prediction. We established a gene expression prediction network that can effectively estimate the gene expression profiles for different chemical perturbations. The network is from a recent drug discovery researchpaper30, whichfirst encodes the textual string of amolecule into one-hot vectorsbyusing the SMILES grammar toparse the string into aparse tree. Thenetwork thenuses a variational autoencoder (VAE) to embed the one-hot vectors into a continuous latent representation. Finally, the network uses a multilayer perceptron (MLP) to predict the expression profiles of 978 landmark genes.\nDefined the dataset asX, we can sample a value of z from q(z\u2223X) to compute the empirical lower bound (ELBO). The first part of the variational autoencoder loss seeks to minimize the ELBO, which is calculated as:\nL\u00f0\u03d5,\u03b8;X\u00de=Eq\u00f0zjX\u00de\u00bdlogp\u03b8\u00f0X,z\u00de logq\u03d5\u00f0zjX\u00de : \u00f026\u00de\nHere q(z\u2223X) is a Gaussian distribution whose mean and variance parameters are the output of the encoder network, with an isotropic Gaussian prior p\u00f0z\u00de=N \u00f00,I\u00de. \u03d5 and \u03b8 denote the parameters of the encoder and decoder, respectively. The second part of the variational autoencoder loss is binary cross-entropy, which is used to force the VAE to generate the same output as the input. The VAE part of the networkwas implemented using the released version of grammar VAE, which is pretrained with around 2.2M compounds on the ChEMBL dataset. The MLP part of the network contains four fully connected layers in total.\nThe dataset used to train the network was from the LINCS L1000 project29, which contains gene expression profiles for thousands of perturbagens at a variety of time points, doses, and cell lines. We selected Level 3 of the L1000 project, which includes quantilenormalized gene expression profiles of 978 landmark genes, to build our training and testing sets. The training process was conducted in two stages. In the first stage, we froze the encoder of the grammar VAE and only trained the MLP part. In the second stage, we fine-tuned the entire network. The network was trained with mean square error loss function and adadelta optimizer. After training, the Pearson correlation between the predicted gene expression values and the ground truth for the training and testing sets were 0.9755 and 0.9635, respectively. The Pearson correlation coefficient plots for training and testing datasets are shown in Supplementary Fig. S12.\nSuper resolution. In the superresolution task, we used SRGAN to enhance the resolution of dermoscopic images (ISIC-2019)59 from\n32 \u00d7 32 pixels to 64 \u00d7 64 pixels. SRGAN60 is a well-established deep learning model for superresolution. It consists of two parts: a generator and a discriminator. The generator is responsible for upsampling the low-resolution images tohigh-resolution images. It contains 4 residual blocks with shortcut connections, batch normalization, and PReLU activation functions. It also contains 1 upsampling block. The discriminator contains 7 convolutional layers with leaky ReLU activation functions. The loss function of the generator composes of the content loss lcon and the adversarial loss ladv, which are defined as:\nlcon = 1 N XN n= 1 IHRn G\u03b8G\u00f0ILR\u00de , \u00f027\u00de\nladv = XN n = 1 logD\u03b8D \u00f0G\u03b8G \u00f0I LR\u00de\u00de: \u00f028\u00de\nHere N denotes the number of images, ILR and IHR denote the lowresolution input images and real high-resolution images, respectively. G and D represent the generator and discriminator. \u03b8G and \u03b8D are trainable parameters of the generator and discriminator. The discriminator is trained to distinguish the real HR images and the outputs of the generator. The loss function of the discriminator is defined as:\nminGmaxDV \u00f0G,D\u00de= EIHR \u223cptrain\u00f0IHR\u00de + EILR \u223cpG log\u00f01 D\u00f0G\u00f0I LR\u00de\u00de\u00de, \u00f029\u00de\nwhere ptrain and pG are the data distributions of the low-resolution samples and generated images. E( \u22c5 ) represents the expectation calculation.\nThe ISIC-2019 dataset59 consists of 25,331 dermoscopic images, including 4,522 melanomas, 12,875 melanocytic nevi, 3,323 basal cell carcinomas, 867 actinic keratoses, 2,624 benign keratoses, 239 dermatofibromas, 253 vascular lesions, and 628 squamous cell carcinomas. We trained the SRGAN model using the Adam optimizer with an initial learning rate of 10\u22125, a batch size of 4, and a total of 300 epochs. After training, the mean squared error (MSE) between the generated images and the high-resolution ground truth images was 1.44 \u00d7 10\u22124 on the training set and 1.58 \u00d7 10\u22124 on the testing set. Examples of the outputs of the DNN are shown in Supplementary Fig. S15.\nClassification. We used the ResNet50 model31 to classify lung X-ray images. The COVID-19 radiography dataset32,33 contains 21,165 X-ray images in total, including 3616 COVID-19 positive cases, 10,192 normal cases, 6012 lung opacity cases, and 1345 viral pneumonia cases. The ResNet50 model consists of 4 substructures, each of which has 3, 4, 6, and 3 residual blocks, containing 3 convolutional layers each. Shortcut connections are also equipped in all residual blocks to solve the degradation problem. Before training, we split the images into training, testing, and validation subsets with a 2/3:1/6:1/6 ratio. We resized the images to 256 \u00d7 256 pixels, normalized them to a scale of0 to 1, and augmented them by randomly shifting, rotating, shearing, zooming, and flipping. During training, we used the categorical cross-entropy loss function, the Adam optimizer, and set the initial learning rate to 10\u22125 and the weight decay to 10\u22125. We also set the batch size to 32 and used the early stop strategy to monitor the validation accuracy with patience parameter of 20.We saved the bestmodel during the training stage. After training, the accuracy of the model for the training and testing set was 0.9270 and 0.9131, respectively. Confusion matrices of the predicted labels by the DNN are shown in Supplementary Fig. S14.\nUnsupervised MDA analysis of scRNA-seq data of zebrafish embryogenesis. To demonstrate the superiority of unsupervised MDA in analyzing the manifold in scRNA-seq data, we use here a large dataset obtained through profiling 38,731 cells from 694\nNature Communications | (2023) 14:8506 17\nembryos across 12 closely separated stages of early zebrafish development37 using a massively parallel scRNA-seq technology named Drop-seq61. Data were acquired from high blastula stage (3.3 h postfertilization (hpf), moment after transcription starts from zygotic genome) to six-somite stage (12 h after postfertilization, just after the gastrulation). Most cells are pluripotent at high blastula stage, where as many cells have differentiated into specific cell types at six-somite stage."
        },
        {
            "heading": "Implementation and parameter settings",
            "text": "Both Python and Matlab 2020a (MathWorks Inc., Natick, MA, USA) versions of MDA implementation are available. The deep learning models for different tasks were implemented and trained in Python (See Supplementary Fig. S16 for training and validation curves for two tasks). PCA and t-SNE implemented by Matlab have been used to produce the results of these method with default parameters. All the scale parameters (\u03b1\u03bb, \u03b2\u03bb, \u03b1\u03d5, \u03b2\u03d5, \u03b1\u03c8, and \u03b2\u03c8) in Bayesian projection were initialized as 1. The projection dimension was set to R = 16 and the number of maximum iterations to 200. For deep learning embedding, tensorflow package was used for training a network with a single embedding layer. The adam optimizer with a learning rate of 0.001 was used for optimization. The values of a and b were set to 1. The number of nearest neighbor was set to 30. In unsupervised MDA, the manifold outline was created from the input data. To this end, the distances among the input data points were computed and one end point of the manifold was found. The distances of all the data points from the end point was then computed and used for Bayesian projection and deep learning embedding to create the MDA visualizations."
        },
        {
            "heading": "Creation of colors for visualization in MDA",
            "text": "To compute the discrete distance over the target manifold, we follow these steps: (1) Compute the Euclidean distances between all pairs of data labels. (2) Find the endpoint of the target manifold. (3) Discretize the distance vector using the same automatic binning algorithm used in MDA. Use the labels of the bins to color the data labels in MDA visualizations. The colors in the MDA visualizations represent the distance of the data labels from the endpoint of the target manifold."
        },
        {
            "heading": "Ablation study",
            "text": "In ablation experiments, we replaced the deep learning-based embedding of MDA with LDA and t-SNE methods. We visualize the features of the DNNs before and after training for five different tasks in Supplementary Fig. S23. The MDA-LDA method can display a rainbow shape similar to the proposed MDA, and the quality of the features before and after training can be reflected by the color distribution. However, MDA-LDA fails to generate reasonable results in many cases suchas feature visualization for segmentation taskbefore training. The MDA-tSNE method cannot obtain a continuous manifold embedding. The embedded 2D points are very scattered. This is because t-SNE preserves only the local informationandhas poor ability to capture the global information of the data."
        },
        {
            "heading": "Quantitative evaluations",
            "text": "Computation of Pearson correlation: For the regression tasks, first, the geodesic distance26 among the data points is computed from the HD data and low dimensional representations. The Pearson correlation coefficient between the two geodesic distances is then computed. DEMaP index was computed following ref. 23.\nk-nearest neighbor classification accuracy: For the classification tasks, following common practice inmachine learning community, we chose 70% of the data from low dimensional representations for training a k-NN classifier and 30% for testing. The mean performance for 5-fold cross validation is reported."
        },
        {
            "heading": "Statistics and reproducibility",
            "text": "No statistical method was used to predetermine sample size. No data were excluded from the analyses. The experiments were not randomized. There was no blinding. The analyses performed do not involve evaluation of any subjective matters."
        },
        {
            "heading": "Reporting summary",
            "text": "Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article."
        },
        {
            "heading": "Data availability",
            "text": "The datasets generated during and/or analyzed during the current study are in the manuscript and supplementary. The web links for the datasets used in the paper are LINCS L1000, BraTS2018 (https://www. kaggle.com/datasets/sanglequang/brats2018), TCGA (https://www. cancer.gov/ccg/access-data#tcga-amp-continuing-analyses-genomicdata-resources), ISIC-2019 (https://challenge.isic-archive.com/data/# 2019), and COVID-19 radiography dataset (https://www.kaggle.com/ datasets/tawsifurrahman/covid19-radiography-database). All other relevant data supporting the key findings of this study are available within the article and its Supplementary Information files or from the corresponding author upon request. Source data are provided with this paper."
        },
        {
            "heading": "Code availability",
            "text": "MDA implementation is available as a CodeOcean capsule (https://doi. org/10.24433/CO.0076930.v1). Its source codes can be found at https://github.com/xinglab-ai/mda(https://doi.org/10.5281/zenodo. 10140440)62."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was partially supported by NIH (1K99LM01430901 (M.I.), 1R01 CA223667 (L.X.) and R01CA227713 (L.X.)) and a Faculty Research Award from Google Inc. (L.X.)."
        },
        {
            "heading": "Author contributions",
            "text": "L.X. conceived the experiment(s), M.I. and Z.Z. conducted the experiment(s), M.I. and Z.Z. analyzed the results. M.I., Z.Z., H.R., M.K., D.K., J.Z., L.T., J.L., and L.X. wrote the manuscript."
        },
        {
            "heading": "Competing interests",
            "text": "The authors declare no competing interests."
        },
        {
            "heading": "Additional information",
            "text": "Supplementary information The online version contains supplementary material available at https://doi.org/10.1038/s41467-023-43958-w.\nCorrespondence and requests for materials should be addressed to Joseph C. Liao or Lei Xing.\nPeer review information Nature Communications thanks the anonymous reviewer(s) for their contribution to the peer review of this work. A peer review file is available.\nReprints and permissions information is available at http://www.nature.com/reprints\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/ licenses/by/4.0/.\n\u00a9 The Author(s) 2023\nNature Communications | (2023) 14:8506 20"
        }
    ],
    "title": "Revealing hidden patterns in deep neural network feature space continuum via manifold learning",
    "year": 2023
}