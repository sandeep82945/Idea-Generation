{
    "abstractText": "The International Atomic Energy Agency (IAEA) stopping power database is a highly valued public resource compiling most of the experimental measurements published over nearly a century. The database\u2013accessible to the global scientific community\u2013is continuously updated and has been extensively employed in theoretical and experimental research for more than thirty years. This work aims to employ machine learning algorithms on the 2021 IAEA database to predict accurate electronic stopping power cross sections for any ion and target combination in a wide range of incident energies. Unsupervised machine learning methods are applied to clean the database in an automated manner. These techniques purge the data by removing suspicious outliers and old isolated values. A large portion of the remaining data is used to train a deep neural network, while the rest is set aside, constituting the test set. The present work considers collisional systems only with atomic targets. The first version of the espnn (electronic stopping power neural-network code), openly available to users, is shown to yield predicted values in excellent agreement with the experimental results of the test set.",
    "authors": [
        {
            "affiliations": [],
            "name": "F. Bivort Haiek"
        },
        {
            "affiliations": [],
            "name": "A.M.P. Mendez"
        },
        {
            "affiliations": [],
            "name": "C.C. Montanari"
        },
        {
            "affiliations": [],
            "name": "D.M. Mitnik"
        }
    ],
    "id": "SP:35183ddd908e1e06f83b441288e1903fee5eee4e",
    "references": [
        {
            "authors": [
                "Stopping of Swift Point Charges. Springer-Verlag",
                "Berlin",
                "Heidelberg"
            ],
            "title": "10P",
            "venue": "Sigmund, Particle Penetration and Radiation Effects. Vol. 2: Penetration of atomic and",
            "year": 2006
        }
    ],
    "sections": [
        {
            "text": "ESPNN: a novel Electronic Stopping Power neural-network code built on the IAEA stopping power database. I. Atomic targets\nF. Bivort Haiek,1 A.M.P. Mendez,2 C.C. Montanari,2 and D.M. Mitnik2, a) 1)Miner\u0301\u0131a de Datos y Descubrimiento del Conocimiento, Universidad de Buenos Aires, Argentina. 2)Instituto de Astronom\u0131\u0301a y F\u0301\u0131sica del Espacio, CONICET and Universidad de Buenos Aires, Argentina.\n(Dated: 16 December 2022)\nThe International Atomic Energy Agency (IAEA) stopping power database is a highly valued public resource compiling most of the experimental measurements published over nearly a century. The database\u2013accessible to the global scientific community\u2013is continuously updated and has been extensively employed in theoretical and experimental research for more than thirty years. This work aims to employ machine learning algorithms on the 2021 IAEA database to predict accurate electronic stopping power cross sections for any ion and target combination in a wide range of incident energies. Unsupervised machine learning methods are applied to clean the database in an automated manner. These techniques purge the data by removing suspicious outliers and old isolated values. A large portion of the remaining data is used to train a deep neural network, while the rest is set aside, constituting the test set. The present work considers collisional systems only with atomic targets. The first version of the espnn (electronic stopping power neural-network code), openly available to users, is shown to yield predicted values in excellent agreement with the experimental results of the test set.\na)Electronic mail: dmitnik@df.uba.ar\nar X\niv :2\n21 0.\n10 95\n0v 2\n[ ph\nys ic\ns. at\nm -c\nlu s]\n1 4\nD ec\n2 02\n2\nI. INTRODUCTION\nAt the end of 2015, the Nuclear Data Section of the International Atomic Energy Agency1 (IAEA) inherited the monumental work done by Paul2\u20137. He collected about 1000 experimental stopping power measurements made in multiple laboratories worldwide, including publications from as early as 1928. He kick-started his database project in 1990 at the University of Linz, and it has been available to the scientific community since then. The IAEA assumed the responsibility of maintaining, updating, and disseminating this data collection6, which included tables, figures, and comparisons of the published stopping data for ions in atomic targets, compounds, and new materials of technological interest. An overview of the database contents can be found in the review of Montanari and Dimitriou8.\nThe stopping power is the mean energy loss per unit path length of the projectile in many collisional processes. Calculating the electronic stopping power involves determining the target system probabilities of occupying any electronic state different from the initial one due to the transfer of energy from the ion to the target electrons. Several reviews on this subject are available in the literature9\u201311. Different methods and semiempirical codes freely available online are linked and scrutinized on the IAEA stopping power website12. Certainly, the code most widely used is srim. This code is based on a semiempirical method developed by Ziegler13. As reported in their work14, it reproduces 64% of the data with an overall accuracy of 5%. Noteworthy, the latest version of srim includes measurements only up until 2013. Essential differences between the srim predictions and new measurements have been reported since then15\u201318.\nThe present work is the first of a series of publications where we design a robust and general model to accurately calculate the electronic stopping power in different target materials and along an extended energy range. To fulfill this task, we developed a machine learning (ML) model based on a clustering technique and a deep neural-network (NN) method.\nThe IAEA database was built by gathering published articles from diverse authors; hence, it needs to be standardized in its original form. The data are presented in various units and formats. Depending on the ion\u2013target system, the experimental values are given as stopping power per unit length or cross sections per mass or atom. The database contains dozens of thousands of input values only for mono-elemental targets. As a preliminary work, we devoted significant efforts to reorganizing the database, unifying the units, and arranging\nthe data in a standard (csv) format, which enabled easy and quick access to the compiled data. The first task consisted of cleaning the curated data outside the general trend. Purging these data by hand requires considerable amounts of work and is not recommended. Instead, we developed an unsupervised-machine-learning-based method to clean up the database by implementing a filtering algorithm and a cluster analysis. This clustering technique, called dbscan, identifies outlier values and determines which data to keep in the cases of inconsistent overlapping. The cleaning procedure is shown schematically in the left dashedbox of Fig. 1.\nAs illustrated in Fig. 1, the cleaned database becomes the input of the second supervisedmachine-learning method consisting of a deep neural-network. This network has many basic units (neurons) arranged in layers. Each neuron receives input signals from the previous elements, processes it through some weighted non-linear function, and transmits the resulting output to neurons belonging to the next layer. The neural-network contains a known input (projectiles, targets, energies), and a known output (the corresponding experimental stopping power). The training is performed by adjusting the weights, minimizing the differences between the final processed output of the network (predictions) and the experimental results. In that way, the model can accurately reproduce the experimental values and, hopefully, predict new results in the cases not included in the training procedure (the test set). The resulting model and code espnn (electronic stopping power with neural-network) are presented in this work. In this first article, we report the results obtained only for atomic targets. Our results were obtained with excellent accuracy using different error metrics, such as MAPE (Mean Average Percentage Error) or MAE (Mean Absolute Error).\nSection II describes the machine learning (ML) methods employed to depurate the database, showing a few examples of the original data and the remaining final input employed in the network training. In Section III, the deep neural-network architecture is\ndescribed. An overview of the training, validation and test sets is presented; some details concerning the training procedure are also discussed. Section IV presents selected results and the analysis of distinct error metrics, which give a sense of the method\u2019s accuracy. In Appendix B, we provide instructions for installing and using the espnn code."
        },
        {
            "heading": "II. DATABASE CLEANSING",
            "text": ""
        },
        {
            "heading": "A. Database review",
            "text": "The database (updated in December 2021) consists of 60173 experimental measurements, representing stopping power values for 1491 ion\u2013target combinations of 49 projectiles colliding with 283 targets across the energy range 10\u22124 \u2212 104 MeV/amu and ion and target atomic masses from 1 to 240 amu. Concerning only the mono-elemental targets, there are 706 collision cases composed of 44 different projectiles and 73 targets, resulting in 36544 experimental data points. The experimental data summarize 1190 publications covering the period 1928\u20132021. The reorganization of the database allows for performing extensive statistical analysis. This task would indicate, for instance, the lack of data in certain energy regions, over-measured and under-measured systems, which may guide experimental groups regarding the necessity of new findings. A detailed analysis of the database\u2019s current status will be presented in a forthcoming article.\nThe raw data collected come from several publications; the results of the same ion\u2013target collision may show significant discrepancies (much larger than the error of the individual set of experimental data). Cleaning the database is crucial; well-thought criteria must be adopted for selecting the most reliable values, accompanied by careful examination of the outcome. The immense difficulties of scrutinizing such an extensive dataset are resolved by implementing a straightforward ML-based method. First, the dbscan classification algorithm is used to group similar results in clusters and to identify outliers, i.e., values suspected of being erroneous. Then, an algorithm is developed to assess clusters and outliers by introducing different criteria for overlapping and isolated data. In the following, we briefly explain these algorithms.\nB. The dbscan algorithm\nClustering algorithms are attractive for the task of class identification in spatial databases. However, most well-known unsupervised classification algorithms suffer severe drawbacks when applied to large spatial databases. That is, elements in the same cluster may not share enough similarities, or performance may be poor. Also, while partition-based algorithms, such as K-means, may be easy to understand and implement in practice, the algorithm has no notion of outliers; all points are assigned to a cluster, even if they do not belong to any. Moreover, anomalous points draw the cluster\u2019s centroid toward them, making it more difficult to classify them as anomalous points. In contrast, density-based clustering locates regions of high density that are separated by regions of low density (in this context, density is defined as the number of points within a specified radius).\nIn this work, we used the density-based spatial clustering of applications with noise algorithm dbscan19,20. The main idea behind this technique is the following: for a set of points in some space, the algorithm groups together values that are closely packed (points with many nearby neighbors), marking as outlier points that lie alone in low-density regions (whose nearest neighbors are too far away). It requires two input parameters: the radius of the neighborhood, , and the number of reachable points (within a distance ), Nmin, required to form a dense region. All points belonging to an -neighborhood configure a cluster. All points not reachable from any other point are outliers or noise points. dbscan is significantly effective in discovering clusters of arbitrary shapes, which makes it a standard clustering algorithm and one of the most cited in the scientific literature. This method has numerous advantages: it does not require one to specify the number of clusters in the data a priori (as opposed to K-means, for example). dbscan can find arbitrarily shaped clusters; it has a notion of noise, is robust to outliers, and is mainly insensitive to the data order.\nAs examples of the clustering partitions produced by dbscan, we show in Fig. 2 the stopping power cross sections for H in Si (left), and for O in Au (right). In all cases, the cross sections have been scaled to keep both axes of similar size. We found it convenient to set the input parameters as = 0.025 and Nmin = 3. For H in Si, the unsupervised algorithm detected 19 clusters (each one plotted with a different color). The small black dots without Nmin neighboring points inside a circle of a radius are considered noise points. In total, the algorithm labeled 139 outliers. For O in Au, 26 clusters and 181 outliers were identified."
        },
        {
            "heading": "C. Filtering procedure",
            "text": "When the dbscan algorithm is used for data cleansing, the assigned outliers are generally and systematically removed from the dataset. However, the amount of data to be cleaned by following this standard course of action would be significant. Instead, we designed and implemented a three-step sequential filtering algorithm based on the clustering results.\nOnce the clusters and the outliers are identified, the sequential algorithm determines which data points are kept. First, we inspect energy regions with single and multiple publications based on a year-of-publication criterion. For example, in Fig. 2, the data points marked as outliers by dbscan may cover energy regions with no other available values. This context is essential and is considered by our cleaning algorithm: experimental values\nbelonging to an energy region with no other measurements are considered valid data points; diversely, they are examined by the date criterion. In the following step, we examine overlapping (in energy) but isolated (in cross section) data points. Only those fulfilling an ad-hoc criterion are kept; otherwise, they are tagged as true outliers. Finally, we inspect clustering composition, i.e., whether a cluster comprises data from single or many publications. The general structure of this cleaning procedure is described in the following, while a pseudocode scheme resuming the filtering algorithm is presented in Appendix A.\nFor each collisional system, every publication is first assessed according to the energy overlapping with other references. We determine the number of experimental values ni published in the publication Pi, which are spread over an energy range \u2206Ei. If the publication data cover a region with no other measurements, these data are included in the input database. Otherwise, a date criterion is followed; for the remaining publications of the same collisional system, we count the experimental values that: 1) fall inside the energy range \u2206Ei and 2) have been published after Pi. The total energy range covered by these posterior publications is denoted as \u2206Epi . We evaluate what portion of the energy range covered by the publication Pi is also covered by newer publications; i.e.,\nIf \u2206Epi \u2206Ei \u2264 \u03c3\u2206 \u2192 KEEP the publication Pi . (1)\nThe chosen overlap parameter \u03c3\u2206 is close to 0.6 except for the cases in which the number of references addressing the specific collisional system is tiny; in such cases, \u03c3\u2206 \u2248 1. The condition in (1) ensures that if a publication presents results in an unexplored energy range, these values are kept and included in the input of the neural-network, no matter if they belong to a cluster or are classified outliers. An example of this criterion is shown in the right panel of Fig. 2; the experimental low energy values for O in Au are kept in the input database even though dbscan considers them as outliers.\nNext, we deal with the remaining energy-overlapping results. For a given ion\u2013target system, the second filtering step consists of dropping \u201cisolated\u201d results, i.e., data points appearing at the same energy range as others but having different values. In this instance, we count the number of outliers N ioutl detected in Pi and evaluate\nIf N ioutl ni > \u03c3out \u2192 DROP the publication Pi (2)\nwhere \u03c3out \u2248 0.45, except for when the number of publications is small; then, \u03c3out \u2248 1. This criterion implies that if a publication has many results overlapping in energy with newer measurements, but most of their values are considered suspiciously wrong, it is convenient to keep the newer values rather than the outliers.\nFinally, we perform the same test for isolated results, but instead of inspecting the outliers, we look into the clusters. We identify the largest cluster Ci in a particular publication Pi. This cluster has a total of t i data points, including the li values belonging only to Pi. We aim to verify if the biggest cluster of a publication is formed by results obtained from many sources and not just from this unique work. Thus, we evaluate the condition\nIf li\nti > \u03c3clu \u2192 DROP the publication Pi (3)\nwith \u03c3clu \u2248 0.45, except for cases where the number of publications is small; in such cases \u03c3clu \u2248 1.\nThe performance of the cleaning procedure is illustrated with many examples in Figs. 3, 4, 5, and 6. The left panels of all these figures display the complete data set for each collisional system. The central panels illustrate the cleaned data set, i.e., the outcome of implementing the cleaning procedure.\nIn Fig. 4, we show the electronic stopping power cross section of projectiles H (top row), He (middle row), and O (bottom row), colliding with Au. For this target, a large amount of data is available. However, for these collisional systems, significant discrepancies among the various experimental results are evident, stressing the importance of an effective filtering mechanism. For H in Au, the top-center subplot shows that the cleaning algorithm can safely discard only the data produced before 1980. The middle-center subplot indicates that many results have been dropped for He in Au, particularly in the low energy range. The left subplot for O in Au illustrates multiple clusters overlapping in the energy region close to the stopping power cross section maxima. In the bottom-center subplot, we observe that the algorithm chooses to keep the latest experiments, discarding the old data; as a result, a clean and smooth curve is obtained.\nIt is important to stress that the filtering algorithm favors the latest data, but that does not necessarily imply removing the older results. The procedure will not rule out older measurements if they are statistically valid. Of course, the data cleansing procedure can\nbe more severe or relaxed, according to the parameters chosen. It is possible to change the dbscan parameters to modify the size of the clusters and the filtering parameters from Eqs. (1), (2), and (3) for keeping or discarding some publications. Considering the success of the neural-network implementation that will be explored in the following, we assume that the values adopted are satisfactory for general purposes. An example of this feature is given in Fig. 4, where we display the electronic stopping power cross sections of H colliding with Ni (top row), Cu (middle row), and Zn (bottom row). In these cases, the filtering algorithm does not remove the (most) differences near the maxima.\nFig. 5 shows stopping power cross sections of He colliding with Ne (top), Si (middle), and Cu (bottom). In some cases, the filtering procedure (from the left to the center figures) is hardly noticeable; in others, the year-of-publication criterion in the cleaning algorithm plays an important role. Examples of these cases are He in Ne and He in Cu, respectively.\nFor projectiles heavier than He, the amount of experimental data in the database (and generally measured) is scarcer than for H and He. For example, the cases Si in Si, O in C, and C in Al are displayed in Fig. 6. Although these collisional systems have fewer data points, the filtering procedure was performed without further consideration. The outcome in most cases is strongly noticeable, as the center subplots from Fig. 6 illustrate.\nIt was not apparent beforehand how severe the filtering had to be to proceed with the following supervised method. Hard filtering (resulting in clean and smooth data) seems to lead the neural-network to overfit the input values while allowing some \u201cnoise\u201d helps to prevent this problem. The present clustering-based algorithm reduced the original 36000 data points to 28000 values. These filtered measurements constitute the input database and are used to train a deep neural-network, which will be described in Sec. III."
        },
        {
            "heading": "III. STOPPING POWER PREDICTIONS",
            "text": "Calculating the stopping power of an ion when interacting with a target system involves numerous processes and parameters, which makes this a challenging problem. The different theoretical models developed to describe the experimental data accurately have not yet achieved total success. Semiempirical methods are generally needed to fit the known results and provide recommended values for multipurpose simulations and applications. Moreover, the experimental data also suffer from many discrepancies, requiring the introduction of auxiliary methods to classify and select the results. Considering the copious amount of experimental values in the IAEA database, it constitutes an ideal scenario where machine learning methods can help handle the complexities of this multiprocess phenomenon and even discover hidden relations in the data.\nAt the beginning of this project, two different papers following this approach were published. Parfitt and Jackman21 trained a random forest regression algorithm using thousands of measurements collected in Paul\u2019s stopping power database (with data up to 2015). Based on extensive evaluations through k-fold cross-validation against several error metrics, they demonstrated that their model could fit the training data and make low-error predictions on unseen test data. Using the same database, Guo et al.22 trained a deep neural-network to reproduce the experimental results for elementary targets with good accuracy."
        },
        {
            "heading": "A. Model",
            "text": "While designing our neural-network, a thorough analysis was conducted to establish the best hyperparameters to use. This study includes not only the architectural design of the NN but also the definition of the loss function to minimize, the parameters involved in the minimization process, the learning rate, weight decay, and others. We found the best neural-network design consisting of a grid of five fully connected hidden layers, with 10 \u00d7 24\u00d732\u00d724\u00d710 elements, a leaky-ReLu activation function for every layer, and the adaptive moment estimation (Adam) optimizer as the minimization algorithm. The dropout rates are 0.2 for the input and output layers and 0.5 for every hidden layer. The other parameters for the training model are the learning rate \u03b1 = 0.001, the batch size b = 64, and the weight decay \u03bb = 10\u221210. We employed 300 epochs with an early stopping step of 50. The\nre-parametrization trick23 was used to increase the convergence speed.\nIt is worth mentioning the following technical detail. The stopping power must monotonically decrease towards low energies. However, for some collisional systems, an unphysical increase of the predicted values can appear toward small energy values. We tried adding minimal fictitious stopping power values at very low energies, but as expected, the training became extremely unstable due to its MAPE component. The correct behavior is accomplished in the final model by a simple trick: removing the bias parameters from the first linear layer.\nAn additional study focused on allocating the data for the learning process. From the cleaned data (28000 values), we separated 5% (1400 results) for the test set. These data did not participate in the training process. The remaining 95% of the data, called the learning set, was partitioned into five folds. Four folds comprised the training set, while the fifth fold constituted the validation set. Using this design, we trained the neural-network until the loss function successfully converged. Then, the weights of every layer are kept to estimate the stopping power cross sections in a subsequent stage. This procedure is carried out iteratively by rotating the training-validation folds. As a result, we obtain five sets of weights and, therefore, five different estimations for any input entry. The final predictions are attained by averaging the results obtained from the five NN weights, also providing a rough estimation of the uncertainty present in the calculation.\nAs explained in Parfitt and Jackman21, different error metrics can be used to quantify the performance of the model in terms of the predicted values ypred against the true experimental values ytrue. For comparisons with other methods, we use the mean absolute percentage error loss function, or MAPE, given by\nMAPE \u2261 100 n \u2211 \u2223\u2223\u2223\u2223\u2223ytrue \u2212 ypredytrue \u2223\u2223\u2223\u2223\u2223 . (4)\nHowever, for the training process, the loss function is better defined by adding a small contribution of another metric to the MAPE. This prevents the training from featuring instabilities, which can appear at small stopping power values. We defined the loss function as a linear combination of two distinct metrics,\nL \u2261 MAPE + MSE \u03b2 , (5)\nwhere MSE is the mean-squared error defined by\nMSE =\n\u2211 (ytrue \u2212 ypred)2\nn , (6)\nand \u03b2 acts as a scaling factor between different units and is set to 100. Fig. 7 shows the learning curve of four training sets, and we can observe that the learning procedure reaches a global minimum for the loss function. This behavior demonstrates that our NN model does not suffer from bias problems. Also, the fact that the validation set follows the same learning curve indicates that the data are not overfitted, which means that the neural-network parameters have been correctly selected, avoiding variance problems."
        },
        {
            "heading": "B. Features",
            "text": "Another aspect that must be taken into account when designing the NN model concerns the features to be considered from the input data. The network was trained with various sets of input features, and we concluded that it is possible to accurately determine the electronic stopping power of atoms with only five input features: the atomic mass of the incident ion, the atomic mass of the target, the atomic numbers of both the projectile\nand the target, and the incident projectile energy (per unit mass, i.e., keV/amu). The corresponding MAPE values are summarized in Table I. The first improvement is introduced by considering the logarithm of the incident energy in place of the actual value. We also added the first ionization energy of the target, obtaining a further improvement in the MAPE values. Encouraged by this, we tested adding other features, such as the second ionization limit of the target, the ionization energy of the ion, and the electronegativities of both of them, resulting in poorer outcomes with higher error values."
        },
        {
            "heading": "IV. RESULTS",
            "text": "This section presents and examines the results obtained with the espnn model, which has been described in Section III A. The stopping power cross section predictions result from the input forward propagation along the neural-network. In the subplots at the right of Figs. 3, 4, 5, and 6, we show the espnn predictions for the collisional systems examined in Section II C. For these ion\u2013target combinations, the model replicates very well the experimental results. It is noteworthy that although the predictions have been obtained individually for each projectile energy value, the model\u2019s results are given by smooth curves. The stopping power cross sections shown in Fig. 3 for multiple collisional systems with Au as the target tend to follow the trend given by the latest observations. On the contrary, the espnn results illustrated in Fig. 4 for the collisional systems with H as projectiles replicate the shape of the more statistically representing data. The smoothness of the espnn stopping power cross sections can be understood as a consequence of using a reduced number of features in the\ntraining process, which also avoids overfitting and any renormalization of the input variables. Nonetheless, having a result of a soft curve is somewhat remarkable since the experimental input data may present significant spreading in some energy regions.\nTo verify the transferability of the model, we calculated the stopping power cross sections for the experimental data points initially excluded from the training procedure: the test set. Even though these values were not included in the training (or validation) sets, our model can reproduce these results with high accuracy, as shown in Fig. 8.\nWe can further examine the performance of the espnn on the test set by analyzing the\nresiduals given by\nR \u2261 ytrue \u2212 ypred ytrue .\nIn Fig. 9, we show the test set residuals over the experimental energy range (left panel) and the frequency distribution of these values (right panel). We can estimate a mean error value of 5% from this figure. Because the experimental data are scattered over a broad range of uncertainties and discrepancies, the present model\u2019s accuracy can be considered exceptional.\nFor a quantitative comparison of our model with other approaches, we show in Table II the MAPE values reported by srim14, the random forest (RF) algorithm from Parfitt and Jackman21, the deep learning (DL) algorithm from Guo et al.22, and the present espnn calculations. The table does not provide a rigorous comparison between these methods because it displays the values as reported by the respective authors, and different numbers of data points were considered in the final MAPE evaluation. For that reason, we separated the table into two parts, showing on the left the published errors for the training set and, on the right, the MAPE in the test set. However, we can only make a proper comparison with the RF calculations reported by Parfitt and Jackman. Although the size and characteristics of this work\u2019s input and test sets were chosen differently than ours, these authors addressed the training and an unseen test set separately. The MAPE values in Table II provide a clear picture of the various code\u2019s performance. Furthermore, the espnn results on the unseen test set are excellent. A few details are worth mentioning; srim is a semiempirical code that considers all the experimental data published until 2013; therefore, the respective errors do not necessarily correspond to its predictive capability on later measurements. Inversely, RF describes the training data very well but overfits; the high MAPE values for the test set may be an indication of this.\nBecause of the importance and the widespread usage of srim, we devised a detailed experiment to compare our model\u2019s calculations. Attempting to make a fair comparison between our predictions and srim, we conducted the following procedure: we trained the neural-network only with results published before 2013. This means that we applied our dbscan-based heuristic to all the data published up to 2013. The remaining experimental values (published after 2013) were set aside, and left unclean to avoid data leakage. The excluded set (the new test set), was further separated into different groups in an iterative fashion. First, we considered all the experimental results published after 2013, and next, all the publications that appeared after 2015, and successively reduced the test set to include only the most recent publications. Noteworthily, this neural-network was trained only once, with the data collected in the IAEA database until 2013. In this way, we can compare the prediction power of both methods on an equal footing. The results are summarized in Table III. This table shows that the espnn prediction power is consistently better than srim\u2019s, in all the cases. Also, comparing these results with the MAPE values obtained with the complete data training, we observe that the prediction power is improved, as expected, as new values are included in the data set."
        },
        {
            "heading": "V. CONCLUSIONS",
            "text": "In this work, the difficult task of predicting the electronic stopping power cross sections for atomic targets is addressed using two ML methods. First, a clustering-based algorithm was developed to eliminate automatically suspicious or erroneous experimental values. The method implements the dbscan algorithm to detect outliers and clusters with similar data. A multi-step cleaning algorithm analyses these results and implements three specific criteria. The algorithm was prepared to filter about 20% of the 36000 experimental atomic results in the IAEA stopping power database.\nThe filtered data were used to train a deep neural-network, constituting the second ML method. The neural-network was trained to accurately reproduce the training data, producing MAPE results of less than 6%. Considering the widespread of the experimental values, it represents excellent performance. The same MAPE was obtained for the test set, which constituted data not included in the training procedure. These results demonstrate the excellent prediction power of our model.\nMoreover, an open-access espnn code with the forward propagation model has been published in a public repository and is now available. This algorithm allows computing the stopping power cross section of any collisional system effortlessly and quickly. Certainly, the model will be improved in the future with the addition of newer experimental data and stopping cross sections of complex molecules."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "The following institutions of Argentina financially support this research: the CONICET by the PIP11220200102421CO, the ANPCyT, PICT-2020-SERIE A-01931, and the University of Buenos Aires by the project 20020170100727BA.\nDATA AVAILABILITY STATEMENT\nThe data that support the findings of this work are openly available in GitHub at\nhttps://github.com/ale-mendez/ESPNN24 and in PyPI at https://pypi.org/project/ESPNN/25."
        },
        {
            "heading": "Appendix A: Machine Learning Filtering Procedure",
            "text": "1: procedure Clusters and Outliers 2: Input:\n1. (radius of the neighborhood) 2. Nmin (number of reachable points)\n3: Run dbscan to select different clusters and outliers. 4: Output:\n1. Nclust (number of clusters) 2. Noutl (number of noise points)\n5: end procedure clusters and outliers 6: 7: procedure Drop Publications 8: for list of publications Pi do 9:\n10: procedure Check Newer Publications 11: Count ni (number of experimental results Pi) 12: Define \u2206Ei (energy range covered in Pi). 13: for list of publications P nj newer than Pi do\n14: Define \u2206Enji \u2261 \u2206Enj \u22c2 \u2206Ei. 15: end for\n16: Define \u2206Enew \u2261 \u22c3 j \u2206Enji 17: If \u2206E new\n\u2206Ei \u2264 \u03c3\u2206: KEEP publication Pi and BREAK\n18: end procedure check newer publications 19: 20: procedure Isolated Results 21: Count N ioutl (number of outliers in Pi) 22: If N iout ni\n> \u03c3outl: DROP publication Pi 23: end procedure isolated results 24: 25: procedure Test Cluster 26: Identify Ci (biggest cluster in Pi) 27: Count li (number of ni values from Pi \u2208 Ci ) 28: Count ti (total number of results \u2211 nj \u2208 Ci ) 29: If l i\nti > \u03c3clu: DROP publication Pi\n30: end procedure test clusters 31: 32: end for 33: end procedure drop publications\nAppendix B: Instructions for running espnn\nThe code is public and can be used remotely or locally. Detailed instructions can be\nfound at:\nhttps://pypi.org/project/ESPNN/\nFor remote use, the espnn code can run on the Google Colab platform (see the url address\nin the PyPI page). For a local installation, the code can be installed via pip:\npip install ESPNN\nor, by downloading or cloning the repository at:\nhttps://github.com/ale-mendez/ESPNN\nOnce the code is installed, the execution is extremely simple. For example, if the He\n(projectile) and Au (target) collision is required, the user can type from the terminal\npython -m ESPNN He Au\nTo run the code using a Jupyter Notebook, only these two lines are required:\nimport ESPNN ESPNN.run_NN(projectile=\"He\", target=\"Au\")\nThere are other optional arguments that can be modified, such as the minimum and maximum energy values, the number of energy points in the grid, the path to the output file, etc. For information about the options:\npython -m ESPNN -h\nAs an example, we show the results for Ar in Zn. An output file called ArZn prediction.dat is generated. This file has three columns: Energy (MeV/amu), Stopping power (MeV cm2/mg), and variance (MeV cm2/mg). Figure 10 is generated on the notebook.\nREFERENCES\n1https://www-nds.iaea.org/stopping/. 2H. Paul, D. Semrad, and A. Seilinger, Nucl. Instrum. Meth. Phys. Res. B 61, 261 (1991). 3H. Paul and A. Schinner, At. Data. Nucl. Data Tables 85, 377 (2003). 4H. Paul, AIP Conf. Proc. 1525, 295 (2013). 5H. Paul, AIP Conf. Proc.1525, 309 (2013). 6H. Paul, Stopping power for light ions. Available online in: https://www-nds.iaea.org/\nstopping/. Original webpage by H. Paul in http://www.exphys.jku.at/stopping/.\n7For a list of Paul\u2019s publications on stopping power see https://www-nds.iaea.org/\nstopping/stoppingdocu.html.\n8C.C. Montanari and P. Dimitriou, Nucl. Instrum. Meth. Phys. Res. B 408, 50 (2017). 9P. Sigmund, Particle Penetration and Radiation Effects. Vol. 1: General Aspects and\nStopping of Swift Point Charges. Springer-Verlag, Berlin, Heidelberg (2006).\n10P. Sigmund, Particle Penetration and Radiation Effects. Vol. 2: Penetration of atomic and\nmolecular ions. Springer International Publishing, Switzerland (2014).\n11P. Sigmund and A. Schinner, Nucl. Instrum. Meth. Phys. Res. B 382, 15 (2016). 12Stopping Power of Matter for Ions. Computer Programs, https://www-nds.iaea.org/\nstopping/stoppingprog.html.\n13J.F. Ziegler, J.P. Biersack, and U. Littmark, The Stopping and Range of Ions in Solids.\nPergamon Press (1985). http://www.srim.org/.\n14J.F. Ziegler, M.D. Ziegler, and J.P. Biersack, Nucl. Instrum. Meth. Phys. Res. B 268, 1818\n(2010).\n15N.P. Barradas, A. Bergmaier, K. Mizohata, M. Msimanga, J. Ra\u0308isa\u0308nen, T. Sajavaara, and\nA. Simon, Nucl. Instrum. Meth. Phys. Res. B 360, 90 (2015).\n16T. Materna, E. Berthoumieux, Q. Deshayes, D. Dore\u0301, M. Kebbiri, A. Letourneau, L.\nThulliez, Y.H. Kim, U. Ko\u0308ster, and X. Ledoux, Nucl. Instrum. Meth. Phys. Res. B 505 1 (2021).\n17M.V. Moro, P. Bauer, and D. Primetzhofer, Phys. Rev. A 102, 022808 (2020). 18F.F. Selau, H. Trombini, G.G. Marmitt, A.M.H. De Andrade, J. Morais, P.L. Grande, I.\nAlencar, M. Vos, and R. Heller, Phys. Rev. A 102, 032812 (2020).\n19M. Ester, H.P. Kriegel, J. Sander, and Xiaowei Xu, Knowledge Discovery in Databases\n(KDD) 96, 226 (1996).\n20E. Schubert, J. Sander, M. Ester, H.P. Kriegel, and Xiaowei Xu, ACM Trans. Database\nSyst. Vol. 42, No. 3, Article 19 (2017).\n21W.A. Parfitt and R.B. Jackman, Nucl. Instrum. Meth. Phys. Res. B 478, 21 (2020). 22Xun Guo, Hao Wang, Changkai Li, Shijun Zhao, Ke Jin, and Jianming Xue, Chinese Phys.\nB 31, 073402 (2022).\n23T. Salimans and D.P. Kingma, in Advances in Neural Information Processing Systems Vol.\n29, D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett (eds.), Curran Associates Inc. (2016).\n24https://github.com/ale-mendez/ESPNN. 25https://pypi.org/project/ESPNN."
        }
    ],
    "title": "Machine Learning Stopping Power ESPNN: a novel Electronic Stopping Power neural-network code built on the IAEA stopping power database. I. Atomic targets",
    "year": 2022
}