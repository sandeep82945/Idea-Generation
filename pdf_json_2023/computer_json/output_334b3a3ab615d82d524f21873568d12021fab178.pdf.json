{
    "abstractText": "Real-time video streaming relies on rate control mechanisms to adapt video bitrate to network capacity while maintaining high utilization and low delay. However, the current video rate controllers, such as Google Congestion Control (GCC) in WebRTC, are very slow to respond to network changes, leading to link under-utilization and latency spikes. While recent delaybased congestion control algorithms promise high efficiency and rapid adaptation to variable conditions, low-latency video applications have been unable to adopt these schemes due to the intertwined relationship between video encoders and rate control in current systems. This paper introduces Vidaptive, a new rate control mechanism designed for low-latency video applications. Vidaptive decouples packet transmission decisions from encoder output, injecting \u201cdummy\u201d padding traffic as needed to treat video streams akin to backlogged flows controlled by a delay-based congestion controller. Vidaptive then adapts the frame rate, resolution, and target bitrate of the encoder to align the video bitrate with the congestion controller\u2019s sending rate. Our evaluations atop WebRTC show that, across a set of cellular traces, Vidaptive achieves \u223c2\u00d7 higher video bitrate and 1.6 dB higher PSNR, and it reduces 95th-percentile frame latency by 2.7s with a slight increase in median frame latency.",
    "authors": [
        {
            "affiliations": [],
            "name": "Pantea Karimi"
        },
        {
            "affiliations": [],
            "name": "Sadjad Fouladi"
        },
        {
            "affiliations": [],
            "name": "Vibhaalakshmi Sivaraman"
        },
        {
            "affiliations": [],
            "name": "Mohammad Alizadeh"
        }
    ],
    "id": "SP:7fd55d664527fc28284fe3185a7eae53af79690d",
    "references": [
        {
            "authors": [
                "Gaetano Carlucci",
                "Luca De Cicco",
                "Stefan Holmer",
                "Saverio Mascolo"
            ],
            "title": "Analysis and design of the google congestion control for web real-time communication (webrtc)",
            "venue": "In Proceedings of the 7th International Conference on Multimedia Systems,",
            "year": 2016
        },
        {
            "authors": [
                "Venkat Arun",
                "Hari Balakrishnan"
            ],
            "title": "Copa: Practical delay-based congestion control for the internet",
            "venue": "In 15th USENIX Symposium on Networked Systems Design and Implementation (NSDI 18),",
            "year": 2018
        },
        {
            "authors": [
                "Neal Cardwell",
                "Yuchung Cheng",
                "C Stephen Gunn",
                "Soheil Hassas Yeganeh",
                "Van Jacobson"
            ],
            "title": "Bbr: Congestion-based congestion control",
            "year": 2016
        },
        {
            "authors": [
                "Keith Winstein",
                "Anirudh Sivaraman",
                "Hari Balakrishnan"
            ],
            "title": "Stochastic forecasts achieve high throughput and low delay over cellular networks",
            "venue": "In 10th USENIX Symposium on Networked Systems Design and Implementation (NSDI",
            "year": 2013
        },
        {
            "authors": [
                "Yasir Zaki",
                "Thomas P\u00f6tsch",
                "Jay Chen",
                "Lakshminarayanan Subramanian",
                "Carmelita G\u00f6rg"
            ],
            "title": "Adaptive congestion control for unpredictable cellular networks",
            "venue": "In Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication,",
            "year": 2015
        },
        {
            "authors": [
                "Sadjad Fouladi",
                "John Emmons",
                "Emre Orbay",
                "Catherine Wu",
                "Riad S Wahby",
                "Keith Winstein"
            ],
            "title": "Salsify: Lowlatency network video through tighter integration between a video codec and a transport protocol",
            "venue": "In 15th USENIX Symposium on Networked Systems Design and Implementation (NSDI 18),",
            "year": 2018
        },
        {
            "authors": [
                "Ravi Netravali",
                "Anirudh Sivaraman",
                "Somak Das",
                "Ameesh Goyal",
                "Keith Winstein",
                "James Mickens",
                "Hari Balakrishnan"
            ],
            "title": "Mahimahi: Accurate record-and-replay for http",
            "venue": "In Usenix annual technical conference,",
            "year": 2015
        },
        {
            "authors": [
                "Lawrence S. Brakmo",
                "Larry L. Peterson"
            ],
            "title": "Tcp vegas: End to end congestion avoidance on a global internet",
            "venue": "IEEE Journal on selected Areas in communications,",
            "year": 1995
        },
        {
            "authors": [
                "Van Jacobson"
            ],
            "title": "Congestion avoidance and control",
            "venue": "ACM SIGCOMM computer communication review,",
            "year": 1988
        },
        {
            "authors": [
                "Michael Rudow",
                "Francis Y Yan",
                "Abhishek Kumar",
                "Ganesh Ananthanarayanan",
                "Martin Ellis",
                "KV Rashmi"
            ],
            "title": "Tambur: Efficient loss recovery for videoconferencing via streaming codes",
            "venue": "In 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI",
            "year": 2023
        },
        {
            "authors": [
                "Marcin Nagy",
                "Varun Singh",
                "J\u00f6rg Ott",
                "Lars Eggert"
            ],
            "title": "Congestion control using fec for conversational multimedia communication",
            "venue": "In Proceedings of the 5th ACM Multimedia Systems Conference,",
            "year": 2014
        },
        {
            "authors": [
                "Edwin KP Chong",
                "Robert L Givan",
                "Hyeong Soo Chang"
            ],
            "title": "A framework for simulation-based network control via hindsight optimization",
            "venue": "In Proceedings of the 39th IEEE Conference on Decision and Control (Cat. No. 00CH37187),",
            "year": 2000
        },
        {
            "authors": [
                "Jeongyoon Eo",
                "Zhixiong Niu",
                "Wenxue Cheng",
                "Francis Y Yan",
                "Rui Gao",
                "Jorina Kardhashi",
                "Scott Inglis",
                "Michael Revow",
                "Byung-Gon Chun",
                "Peng Cheng"
            ],
            "title": "Opennetlab: Open platform for rl-based congestion control for real-time communications",
            "venue": "Proc. of APNet,",
            "year": 2022
        },
        {
            "authors": [
                "Alain Hore",
                "Djemel Ziou"
            ],
            "title": "Image quality metrics: Psnr vs. ssim",
            "venue": "In 2010 20th international conference on pattern recognition,",
            "year": 2010
        },
        {
            "authors": [
                "Changhyun Lee",
                "Chunjong Park",
                "Keon Jang",
                "Sue B Moon",
                "Dongsu Han"
            ],
            "title": "Accurate latency-based congestion feedback for datacenters",
            "venue": "In USENIX Annual Technical Conference,",
            "year": 2015
        },
        {
            "authors": [
                "Radhika Mittal",
                "Vinh The Lam",
                "Nandita Dukkipati",
                "Emily Blem",
                "Hassan Wassel",
                "Monia Ghobadi",
                "Amin Vahdat",
                "Yaogong Wang",
                "David Wetherall",
                "David Zats"
            ],
            "title": "Timely: Rtt-based congestion control for the datacenter",
            "venue": "ACM SIGCOMM Computer Communication Review,",
            "year": 2015
        },
        {
            "authors": [
                "Cheng Jin",
                "David X Wei",
                "Steven H Low"
            ],
            "title": "Fast tcp: motivation, architecture, algorithms, performance",
            "venue": "In IEEE INFOCOM 2004,",
            "year": 2004
        },
        {
            "authors": [
                "Mo Dong",
                "Qingxi Li",
                "Doron Zarchy",
                "P Brighten Godfrey",
                "Michael Schapira"
            ],
            "title": "PCC: Re-architecting congestion control for consistent high performance",
            "venue": "In 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI",
            "year": 2015
        },
        {
            "authors": [
                "Sea Shalunov",
                "Greg Hazel",
                "Janardhan Iyengar",
                "Mirja"
            ],
            "title": "Kuehlewind. Low extra delay background transport (ledbat)",
            "venue": "Technical report,",
            "year": 2012
        },
        {
            "authors": [
                "Sangtae Ha",
                "Injong Rhee",
                "Lisong Xu"
            ],
            "title": "Cubic: A new tcp-friendly high-speed tcp variant",
            "venue": "SIGOPS Oper. Syst. Rev.,",
            "year": 2008
        },
        {
            "authors": [
                "Sally Floyd",
                "Tom Henderson",
                "Andrei Gurtov"
            ],
            "title": "Rfc3782: The newreno modification to tcp\u2019s fast recovery",
            "year": 2004
        },
        {
            "authors": [
                "Prateesh Goyal",
                "Akshay Narayan",
                "Frank Cangialosi",
                "Srinivas Narayana",
                "Mohammad Alizadeh",
                "Hari Balakrishnan"
            ],
            "title": "Elasticity detection: A building block for internet congestion control",
            "venue": "In Proceedings of the ACM SIGCOMM 2022 Conference,",
            "year": 2022
        },
        {
            "authors": [
                "Gaetano Carlucci",
                "Luca De Cicco",
                "Stefan Holmer",
                "Saverio Mascolo"
            ],
            "title": "Analysis and design of the google congestion control for web real-time communication (webrtc)",
            "venue": "In Proceedings of the 7th International Conference on Multimedia Systems,",
            "year": 2016
        },
        {
            "authors": [
                "Hongzi Mao",
                "Ravi Netravali",
                "Mohammad Alizadeh"
            ],
            "title": "Neural adaptive video streaming with pensieve",
            "venue": "In Proceedings of the conference of the ACM special interest group on data communication,",
            "year": 2017
        },
        {
            "authors": [
                "Te-Yuan Huang",
                "Ramesh Johari",
                "Nick McKeown",
                "Matthew Trunnell",
                "Mark Watson"
            ],
            "title": "A buffer-based approach to rate adaptation: Evidence from a large video streaming service",
            "venue": "In Proceedings of the 2014 ACM conference on SIGCOMM,",
            "year": 2014
        },
        {
            "authors": [
                "Xiaoqi Yin",
                "Abhishek Jindal",
                "Vyas Sekar",
                "Bruno Sinopoli"
            ],
            "title": "A control-theoretic approach for dynamic adaptive video streaming over http",
            "venue": "In Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication,",
            "year": 2015
        },
        {
            "authors": [
                "Kevin Spiteri",
                "Rahul Urgaonkar",
                "Ramesh K Sitaraman"
            ],
            "title": "Bola: Near-optimal bitrate adaptation for online videos",
            "venue": "IEEE/ACM Transactions On Networking,",
            "year": 2020
        },
        {
            "authors": [
                "Francis Y Yan",
                "Hudson Ayers",
                "Chenzhi Zhu",
                "Sadjad Fouladi",
                "James Hong",
                "Keyi Zhang",
                "Philip Alexander Levis",
                "Keith Winstein"
            ],
            "title": "Learning in situ: a randomized experiment in video streaming",
            "venue": "In NSDI,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "This paper introduces Vidaptive, a new rate control mechanism designed for low-latency video applications. Vidaptive decouples packet transmission decisions from encoder output, injecting \u201cdummy\u201d padding traffic as needed to treat video streams akin to backlogged flows controlled by a delay-based congestion controller. Vidaptive then adapts the frame rate, resolution, and target bitrate of the encoder to align the video bitrate with the congestion controller\u2019s sending rate. Our evaluations atop WebRTC show that, across a set of cellular traces, Vidaptive achieves \u223c2\u00d7 higher video bitrate and 1.6 dB higher PSNR, and it reduces 95th-percentile frame latency by 2.7s with a slight increase in median frame latency.\n1 Introduction Real-time video streaming has become an integral part of modern communication systems, enabling a wide range of applications from video conferencing to cloud gaming, live video, and teleoperation. A critical component of these systems is the rate control mechanism, which adapts the video bitrate to the available network capacity. State-of-the-art rate controllers, however, such as the Google Congestion Control (GCC) [1] algorithm used in WebRTC [2] have significant shortcomings. Specifically, GCC is slow to adapt to changes in network conditions, leading to both link under-utilization and latency spikes.\nIn recent years, numerous congestion control algorithms (CCA) have been proposed that achieve high utilization, low delay, and fast convergence [3\u20136]. These algorithms are highly responsive to network variations, adapting within a few roundtrip times (RTTs) while maintaining high utilization and low\ndelay. In contrast, GCC and similar video rate control algorithms lag considerably. When network bandwidth opens up, GCC can take an order of magnitude longer than state-of-theart congestion controllers to increase the video bitrate. This conservative approach can significantly hurt GCC\u2019s utilization and the video quality in variable networks. In our experiments using cellular network traces, GCC under-utilizes the network by 2-3\u00d7 compared to Copa [3].\nThis sluggishness is not merely a limitation of GCC but a symptom of a broader issue: the inherent coupling between video encoders and rate control algorithms [7]. Current systems use an encoder-driven rate controller that adapts the video bitrate by controlling the encoder\u2019s target bitrate. In these systems, the instantaneous data transmission rate is dictated by the size of the video frames produced by the encoder. However, most video encoders are not designed to adjust to rapid fluctuations in network conditions. It generally takes several frames to adapt frame sizes to new target bitrates [7]. Moreover, the frame sizes are variable and only meet the target bitrate on average in a best-effort manner. To maintain low latency despite the vagaries of the encoder output, GCC sets the target bitrate conservatively and increases it slowly. Nevertheless, during times of significant congestion (e.g., due to link outages), the encoder cannot immediately adapt to capacity drops, and GCC experiences significant latency spikes.\nRecently, Salsify [7] addressed this challenge by modifying the encoder to be more adaptive to network variations. Such approaches, however, are challenging to deploy in practice. Changing the encoder usually requires changes to both the sender and receiver sides of the application. With the prevalence of hardware codecs across billions of devices, such drastic changes have become virtually infeasible.\nWe present Vidaptive, a new rate control mechanism for low-latency video applications that significantly improves efficiency and responsiveness to network variability without modifying the encoder. Vidaptive\u2019s design is based on two key concepts.\nThe first is to decouple instantaneous packet transmission decisions from the encoder\u2019s output. Specifically, Vidaptive treats video streams as if they were backlogged flows for the purpose of rate control. It uses an existing delay-based CCA like Copa. If the encoder produces more packets than the\nar X\niv :2\n30 9.\n16 86\n9v 1\n[ cs\n.N I]\n2 8\nSe p\n20 23\nCCA is willing to send, it buffers them at the sender. On the other hand, Vidaptive sends \u201cdummy packets\u201d to fill the gap if the encoder does not produce enough packets to sustain the CCA\u2019s rate. This approach ensures that \u201con the wire\u201d, Vidaptive behaves identically to its adopted CCA running with a backlogged flow. The CCA\u2019s feedback loop can operate without disruption and track available bandwidth quickly.\nNext, Vidaptive matches the video bitrate to the CCA\u2019s sending rate using mechanisms that adapt the frame rate, the encoder\u2019s target bitrate, and the video resolution. To keep frame latency within acceptable bounds when the encoder overshoots the CCA\u2019s rate, Vidaptive skips a frame if the delay at the sender exceeds a threshold (effectively reducing the frame rate to handle sudden latency spikes). Further, Vidaptive uses a novel online optimization algorithm to determine the encoder\u2019s target bitrate based on the CCA\u2019s sending rate and recent frame delay measurements. The optimization procedure provides a principled approach to navigate the tradeoff between video bitrate and frame rate, and importantly, it adapts automatically to the variability in the encoder\u2019s output and the network rate.\nWe implement Vidaptive atop WebRTC and test it using sixteen cellular network traces with significant variability on an emulated network link [8]. Compared to GCC, our key findings are:\n1. Across all traces, Vidaptive improves link utilization by \u223c2.5\u00d7 and video bitrate by \u223c2\u00d7 on average across all traces, resulting in 1.6dB improvement in Peak-Signalto-Noise-Ratio (PSNR) on average. 2. Across all frames in all traces, Vidaptive improves average PSNR by 1.9 dB and P95 PSNR by 2.2 dB. 3. Across all frames in all traces, Vidaptive increases median latency by 47 ms (148 ms \u2192 195 ms), but it reduces 95\ud835\udc61\u210e percentile frame latency by 2687 ms (4120 ms \u2192 1433 ms). On a per-trace basis, Vidaptive improves P95 frame latency by \u223c 2.7 seconds on average but is 45-384 ms worse on some traces. 4. Vidaptive reduces frame rate by \u223c 10% on average per trace.\n2 Motivation and Key Ideas 2.1 The Problem\nStatus Quo for Video Rate Control. To understand how rate control for real-time video works today, we run Google Congestion Control (GCC) [1], the rate control mechanism inside WebRTC, on an emulated link that alternates between 2Mbps and 500Kbps every 40 seconds. The minimum network roundtrip time (RTT) is 50ms, and the buffer size at the bottleneck is large enough that there are no packet drops. In Fig. 1a, GCC is sluggish to increase its rate when the stream begins and when the link capacity rises back to 2Mbps at \ud835\udc61 = 80s. Specifically, GCC takes 18 seconds to go from 500Kbps to 2Mbps, resulting in lower visual quality during that time (Fig. 1b). GCC\u2019s\nconservative nature also results in link under-utilization (85%) in the steady state. GCC is slow to react to capacity drops: in Fig. 1c, when the link rate drops to 500Kbps at \ud835\udc61 = 40s, GCC\u2019s frame latency spikes to over a second and settles only after 12 seconds. This issue is because GCC continues to send at a higher rate even after the drop, causing queue buildup, added delay, and frame loss.\nContrast this behavior with traditional congestion control algorithms [3, 4, 9, 10] operating on backlogged flows: they respond to such network events much faster, typically over few RTTs. For instance, the \u201cBacklogged Copa\u201d lines in Fig. 1a and Fig. 1c show that Copa [3], running on a backlogged flow on the same time-varying link is much more responsive to the network conditions. This wide disparity between GCC on real-time video traffic and Copa on backlogged traffic begs the question: Why does the state-of-the-art video rate control lag so far behind the state-of-the-art congestion control? Encoder-driven Rate Control Loop. GCC has been carefully designed to work within the tight latency bounds of interactive video applications. Its rate control responds to increases or decreases in delay gradients over RTT timescales. It is also conservative in its link utilization to not overwhelm the network and cause delays or packet loss.\nHowever, the real limiting factor is that, in current video congestion controllers like GCC, the instantaneous rate at which data is transmitted on the wire is dictated by the size of the video frames produced by the encoder. GCC controls the video bitrate by adapting the encoder\u2019s target rate, but the encoded frame sizes can be highly variable. The encoder achieves its target bitrate only on average\u2014usually throughout several frames [7]. Moreover, the encoder\u2019s bitrate cannot immediately adapt to changes in the target bitrate. We illustrate this behavior in Fig. 2 where we supply the VP8 encoder with a target bitrate that switches between 2Mbps and 500Kbps every 5s and observe its achieved bitrate. Every time the bitrate goes up from 500Kbps to 2Mbps, the encoder takes nearly 2 seconds to catch up. On the way down from 2Mbps to 500Kbps, it takes about a second to lower the bitrate.\nThe reason for this lag is that the size of an encoded frame is dependent on several factors, including quantization parameters, the encoder\u2019s internal state, and the motion, and is only known accurately after encoding. The encoder tries to rectify its over- and under-shootings by adjusting the quality of subsequent frames. Even once the encoder matches the target bitrate, it exhibits considerable variance around the average on a per-frame basis. Salsify [7] deals with this unpredictability by encoding multiple versions of the same frame and picking the best match after the fact. However, putting aside the extra computational cost, this approach requires radical changes to the codec\u2014at both the sender and the receiver\u2014which hinders its real-world deployability.\nThe unpredictable nature of the encoder leads to two main issues: (1) Since the encoder cannot match the target bitrate on per-frame timescales, GCC cannot immediately reduce the\nbitrate if the capacity suddenly drops. Instead, GCC has to be conservative and leave abundant bitrate headroom at all times (including in the steady state) so that it reduces the risk of congestion during fluctuations. Despite this, GCC still experiences occasional latency spikes (Fig. 1c). (2) GCC is very slow to grab available bandwidth. Whenever GCC increases its target bitrate, the encoder matches it over a few seconds, meaning it also takes several seconds for GCC to get feedback at the higher rate and increase its target bitrate again. This cycle ends up taking 15\u201320 seconds end-to-end (Fig. 1a). What about Probing Mechanisms? A natural question at this point is if probing mechanisms, specifically those already supported within GCC [11], improve GCC\u2019s convergence in such scenarios. While periodic bandwidth probing has proved effective for some CCAs [4], the GCC mechanism is relatively ad-hoc. It fires a periodic timer and sends some bounded extra padding traffic (the frequency can vary but is often in the range of seconds (e.g., every 5 seconds)). Such an infrequent timer does not help on the finer RTT-level timescales required for precise rate control. A five-second timer is, in practice, very similar to a sluggish encoder that responds to the target bitrate over a few seconds. Fig. 3 shows how GCC with probing enabled reacts on a lossless periodic link with an RTT\nof 50ms that alternates between 2Mbps and 500Kbps every 40 seconds. The padding traffic is only sent when GCC reduces the video bitrate significantly (t=40s) but does not help at all with bandwidth discovery (t=80s) when the link opens back up.\n2.2 Our Solution Decoupling the Encoder from the Rate on the Wire. As illustrated in Fig. 1a, a backlogged flow using a state-of-the-art CCA like Copa can adapt to time-varying network capacity on RTT timescales while also controlling network queueing delay. A key reason is that such CCAs have fine-grained control over when to send each packet, e.g., driven via the \u201cACK clock\u201d [12]. Vidaptive makes video streams appear like a backlogged flow to the congestion controller. This allows Vidaptive to leverage existing CCAs optimized for high throughput, low delay, and fast convergence. In Fig. 1, Vidaptive using Copa for congestion control achieves nearly identical throughput and latency as a backlogged Copa flow. Vidaptive quickly increases its bitrate when bandwidth opens up, leading to higher image quality than GCC following each such event (Fig. 1b).\nVidaptive sends packets on the wire as dictated by the congestion controller. Specifically, when the encoder overshoots the available capacity, Vidaptive queues excess video packets\nin a buffer and only sends them out when congestion control allows (e.g., according to the congestion window and inflight packets for window-based CCAs). Conversely, when the encoder undershoots the available capacity, Vidaptive sends \u201cdummy packets\u201d to match the rate requested by the congestion control by padding the encoder output with additional traffic.1 This allows the CCA to operate without disruption (as in a backlogged flow) despite the encoder\u2019s varying frame sizes.\nBy decoupling the congestion control\u2019s decisions from the encoder output, Vidaptive can accurately track time-varying bottleneck rates. However, it is still important to match the actual video bitrate produced by the encoder to the congestion controller\u2019s sending rate. In particular, although buffering packets and sending dummy traffic can handle brief variations in the encoder output bitrate, the quality of experience will suffer if the encoder\u2019s output is persistently higher or lower than the congestion control\u2019s rate. In the former case, end-toend frame latency would grow uncontrollably, and in the latter scenario, dummy packets would waste significant bandwidth.\nVidaptive includes two mechanisms that control the frame rate and encoder\u2019s target bitrate to match the video bitrate to the congestion controller\u2019s sending rate while meeting a delay constraint. First, it uses simple safeguards to ensure that end-to-end frame latency is not significantly affected by delay at the sender. If the delay at the sender exceeds a threshold, Vidaptive skips a frame. During severe latency spikes (e.g., caused by a network outage), Vidaptive drops buffered packets and resets the encoder using a keyframe.\nSecond, Vidaptive selects the encoder\u2019s target bitrate by solving an online optimization that decides how much headroom to leave between the target bitrate and the CCA\u2019s sending rate (CC-Rate). Increasing the target bitrate to near the CC-Rate (lowering headroom) provides a higher video bitrate (and better quality). However, it risks latency increases due to the variability of the encoder\u2019s output frame sizes and future sending rate fluctuations. If these latency increases exceed the video\u2019s delay tolerance, Vidaptive has no choice but to reduce the frame rate. Thus, the choice of the target bitrate (headroom) is effectively about navigating a tradeoff between video bitrate and frame rate. This tradeoff depends on the inherent variability of the system. If the encoder\u2019s output and the bottleneck link rate (and hence CC-Rate) are stable and have low variance, then a small headroom can suffice to ensure low, consistent frame latency and, therefore, a high frame rate. However, the headroom must increase with more variability. Vidaptive\u2019s online optimization uses recent frame delay measurements to adapt to such variability automatically.\n1This dummy traffic could also be repurposed for helpful information such as forward error correction (FEC) packets [13, 14] or keyframes for faster recovery from loss. We leave such enhancements to future work and focus solely on the impact of dummy traffic on video congestion control.\n3 Vidaptive Design 3.1 Overview\nOur goal is to design a system for real-time video applications that responds quickly to any changes in network conditions, and maintains high utilization of available capacity without altering the encoder. Vidaptive achieves this by decoupling the behavior of the transport layer from the unreliable video encoder, and by closely matching the encoder bitrate to the CCA\u2019s sending rate (CC-Rate).\nFig. 4 shows Vidaptive\u2019s overall design. The video encoder encodes frames and sends them to an application-level media queue before sending the packets out into the network. At the transport layer, we add a modified window-based \u201cCongestion Controller\u201d, a \u201cPacer\u201d and a new \u201cDummy Generator\u201d to decouple the rate at which traffic is sent on the wire from the encoder, as described in \u00a73.2. We introduce a new \u201cEncoder Rate Controller\u201d that monitors the delay frames are experiencing to trigger the latency safeguards described in \u00a73.3. The rate controller also uses the discrepancy between the CC-Rate and the video encoder\u2019s current bitrate, along with frame delays to adapt the target bitrate and resolution to efficiently trade off frame rate and frame quality (\u00a73.4).\n3.2 Transport Layer\nCongestion Controller. To build a more responsive transport for real-time video, we start with a congestion controller that is more responsive to the network. A window-based algorithm keeps the amount of video packets in check without allowing them to grow uncontrollably and cause high latency, packet loss, and glitches. Specifically, the congestion window (cwnd) in Vidaptive tracks the maximum number of in-flight bytes between the sender and the receiver. cwnd increases when the queueing delay is lower than what the CCA hopes to impose and decreases otherwise. The sender only sends out new packets when the amount in-flight is less than cwnd. Using delay as the congestion signal prioritizes the end-to-end frame latency and adjusts the window such that most frames are delivered in real time. Vidaptive can be used with any delay-controlling congestion control algorithm. We evaluate Vidaptive with two recently proposed such algorithms, Copa [3] and RoCC [9].\nWe compute the system\u2019s sending rate (CC-Rate) as the cwnd divided by smoothed RTT and use it to configure the Pacer and the encoder target bitrate (\u00a73.4). Pacer. The Pacer receives cwnd and the CC-Rate from the congestion controller and paces out the video packets at CC-Rate. Since the encoder exhibits variance and its output bitrate may instantaneously overshoot the available capacity (\u00a72), the pacer is responsible for avoiding a sudden burst of packets. In Vidaptive, the pacing rate and the congestion window together determine when to send the next packet. Dummy Packets. While the window-based CCA ensures ACK-clocked behavior, and the pacer prevents sudden bursts of video packets, neither ensures fast feedback between video\nframe boundaries. The lack of feedback prevents us from quickly growing our window when bandwidth opens up (\u00a72). To emulate the behavior of a backlogged flow, we place \u201cdummy packets\u201d into the pacer\u2019s queue if the CCA is ready to send a packet but has no available video packets. Note that the dummy packets never stay in the pacer queue as they are only generated when the CCA wants to send a packet, but the pacer queue is empty.\nTo avoid network delay spikes caused by spurious dummy packets when the link rate suddenly drops, we do not send any dummy packets within a few milliseconds (5ms in our implementation) of reading frames from the camera. The intuition behind this mechanism is that if the network is soon to deteriorate, the dummy packets sent a few milliseconds prior to a frame will induce a higher queuing delay in the network and thus increase the frame latency. On the other hand, if the network rate opens up, not sending packets for a few milliseconds will not slow down the congestion controller\u2019s convergence by much.\nLastly, we stop sending dummy packets if the video has reached a maximum bitrate (12Mbps in our experiments). Since the video bitrate cannot increase further, sending extra traffic to discover more available bandwidth is not useful.\n3.3 Safeguarding against Latency Spikes\nTransport design for any real-time video system must ensure low-latency frame delivery. As a result, we place two safeguards within Vidaptive to avoid transmitting frames that are unlikely to be successfully received on time. These safeguards essentially reduce the frame rate during highly congested periods to mitigate latency spikes; we discuss our principled strategy for trading off frame rate with quality in \u00a73.4. Encoder Pause. Vidaptive monitors the time packets spend in the pacer queue before they are sent out. If the time spent by the oldest packet exceeds a pacer queue pause threshold (\ud835\udf0f), we pause encoding and buffer the latest un-encoded frame. If the CC-Rate increases and the pacer queue is drained, we resume\nencoding and send video packets from the latest buffered frame if it is within \u223c 17ms (33ms/2) of that frame being read. Otherwise, we skip this frame altogether and encode the next frame since we are closer in time to reading the next frame. We set \ud835\udf0f = 33ms by default in our implementation, thereby pausing encoding if packets from the previous frame are yet to be sent out. The intuition here is that there is no point in encoding a frame that would have to sit in the Pacer queue, waiting for a previous frame to finish transmission.2 Instead, we always encode and transmit fresh frames when they have a high chance of reaching the receiver with acceptable latency. Encoder Reset. If video packets have been stuck in the pacer for extended periods (> 1s), the network is likely experiencing an outage or extreme congestion. Packets already sent out will likely be lost, making their corresponding frames not decodable. Sending more video packets dependent on those un-decodable frames is wasteful and makes application-level recovery harder. Furthermore, packets from these frames have already incurred a huge latency in the pacer queue, and sending them out would mean very high end-to-end frame latency. Instead, we drain the pacer entirely and reset the encoder by forcing it to send a keyframe. Since video packets received after the congestion event belong to a keyframe, the receiver\u2019s decoder has no errors when decoding them. This reset, similar to pausing, has the impact of controlling worst-case frame latency. It also allows Vidaptive to choose very conservative target bitrates and resolutions (\u00a73.4) in the aftermath of a congestion event that ensures that video packets get through to the receiver and give us fast feedback to help reset the system.\n3.4 Trading off Frame Rate and Quality\nVidaptive skips encoding some frames to reduce latency as described in \u00a73.3. Since this reduces the frame rate and affects\n2A high delay through the Pacer queue reflects congestion at the bottleneck link. If we ignore CC-Rate and transmit the packets stuck in the Pacer queue (as currently implemented in WebRTC), they would still have to wait at the bottleneck link.\nthe smoothness of the video, Vidaptive is set up to reduce the frame bitrate proactively and, consequently, the frame quality in favor of letting more frames get through.\nWe formalize the tradeoff between frame rate and frame quality as a decision problem that picks a target bitrate for the encoder based on how much we prioritize achieving a high frame rate over high video quality. Specifically, we pick \ud835\udefc, the fraction of the CC-Rate to supply as the target bitrate to the encoder. When the frame rate is low, we choose a smaller \ud835\udefc to create smaller frames but let more of them get through. When the frame rate is high, we choose a higher \ud835\udefc to obtain higher quality frames while sacrificing a little on the achieved frame rate. To affect significant and sudden changes in the video bitrate based on network conditions, we update the resolution in addition to setting the target bitrate. Preliminaries. Vidaptive encodes each frame if the frame queueing delay (delay through the pacer queue) for the oldest unsent frame is not more than the pacer queue pause threshold \ud835\udf0f. We define Vidaptive\u2019s frame rate score  to capture how many frames it successfully delivers over a time interval \ud835\udc47 . If there are \ud835\udc41 frames over a time interval \ud835\udc47 that experience delays through the pacer queue denoted by \ud835\udc51\ud835\udc56 for \ud835\udc56\u2208 {1,2, ..,\ud835\udc41}, we define  as the ratio of the number of frames successfully sent (those whose queuing delays do not exceed \ud835\udf0f) to \ud835\udc41 , the total number of frames. In other words,\n = \u2211\ud835\udc41 \ud835\udc56=1\ud835\udfd9[\ud835\udc51\ud835\udc56 \u2264 \ud835\udf0f] \ud835\udc41 , (1)\nwhere \ud835\udfd9[\ud835\udc51\ud835\udc56 \u2264 \ud835\udf0f] = 1 if \ud835\udc51\ud835\udc56 \u2264 \ud835\udf0f and 0 otherwise. At higher  , most frames have \ud835\udc51\ud835\udc56 \u2264 \ud835\udf0f and do not pause the encoder which results in a higher frame rate. \ud835\udc47 =1s by default in our implementation.\nIf the camera\u2019s frame rate is \ud835\udc53\ud835\udc5a\ud835\udc4e\ud835\udc65 (typically 30 FPS), the gap between frames is \u0394 = 1\ud835\udc53\ud835\udc5a\ud835\udc4e\ud835\udc65 (typically 33ms). For maximum efficiency, the frame queueing delay should be close to \u0394, such that the last packet of a frame is transmitted just as the next frame is encoded. Thus, to measure Vidaptive\u2019s efficiency and its impact on frame quality, we define its bitrate score  as,\n = min ( \u2211\ud835\udc41 \ud835\udc56=1 \ud835\udc51\ud835\udc56 \ud835\udc41\u0394 ,1 )\n(2)\nNote that \u2211\ud835\udc41 \ud835\udc56=1 \ud835\udc51\ud835\udc56 \ud835\udc41 is the average frame queueing delay over the \ud835\udc41 samples in the last time interval \ud835\udc47 , and its ratio relative to \u0394 can be viewed as a proxy for utilization. For example, if  = 0.2, the system is sending 20% of the video traffic it can send to the link without causing additional delays. Choosing a Target Bitrate. The frame queueing delay is a function of the estimation of the link rate, CC-Rate, and frame sizes. As a result, it is impacted by fluctuations in both the encoder\u2019s output and in the CC-Rate. These fluctuations are out of our control and can be viewed as a form of exogenous \u201cnoise\u201d impacting frame delays. However, we can influence\nthe expected frame sizes by controlling the encoder\u2019s target bitrate. The crux of our method is to pick the target bitrate in a way that maximizes a weighted linear combination of  and  based on recent per-frame queueing delay measurements. Assume a target bitrate \ud835\udefc \u22c5 CC-Rate is given to the encoder where 0 < \ud835\udefc < 1. Increasing \ud835\udefc increases each frame\u2019s size and its \ud835\udc51\ud835\udc56 (frame size divided by CC-Rate). Since \ud835\udc51\ud835\udc56 depends on \ud835\udefc, we rename it \ud835\udc51\ud835\udc56(\ud835\udefc). Increasing \ud835\udc51\ud835\udc56(\ud835\udefc) increases  but reduces  , i.e. \ud835\udefc induces a tradeoff between the frame rate and the frame quality. Our goal is to find \ud835\udefc\u2217 such that:\nmaximize \ud835\udf06 1\u2212\ud835\udf06  + (3)\ns.t. 0 < \ud835\udefc < 1\nwhere \ud835\udf06 \u2208 (0,1) is a parameter that reflects how much the application favors higher frame rate over better frame quality. When \ud835\udf06 \u223c 1, the application favors a high frame rate; when \ud835\udf06 \u223c 0, the application favors larger frames and higher quality. Solving the Optimization. To choose \ud835\udefc, one would ideally want to solve the above optimization problem over future frames. However, it is hard to model \ud835\udc51\ud835\udc56(\ud835\udefc) for future frames since these can depend on future video content (e.g., the extent of motion) and how CC-Rate changes in the future. Instead, we use hindsight optimization [15] to solve for the best \ud835\udefc we could have picked in hindsight for recent past frames. Estimating the effect \ud835\udefc would have had on the delays of previous frames is simple. Assume we have frame queueing delay measurements \ud835\udc51\ud835\udc56 for \ud835\udc56 \u2208 {1,2, ..,\ud835\udc41} over a time interval \ud835\udc47 , and we encoded these frames with a target bitrate \ud835\udefc\ud835\udc56 \u22c5CC-Rate. Had all these frames been encoded by \ud835\udefc instead, the counterfactual frame queueing delay would have been \ud835\udc51\ud835\udc56(\ud835\udefc) = \ud835\udc51\ud835\udc56\n\ud835\udefc \ud835\udefc\ud835\udc56 . This estimate assumes that frame size is proportional to the target bitrate (and hence proportional to \ud835\udefc), and that changing the target bitrate would not have changed CC-Rate. Using these counterfactual delay estimates, we can now solve the optimization problem in Eq. (3). Fig. 5 shows an example of this counterfactual optimization problem. Fig. 5a shows frame queueing delay samples and\ntheir average (green line). The samples that are less than \ud835\udf0f are colored in blue, and those larger than \ud835\udf0f (which would cause a frame to be skipped) are colored in red. Fig. 5b shows the Objective(\ud835\udefc) versus \ud835\udefc, and its maximizer \ud835\udefc\u2217. Fig. 5c shows the counterfactual frame queueing delay values, \ud835\udc51\ud835\udc56, had \ud835\udefc\u2217 been used to encode them. The scaled-down \ud835\udc51\ud835\udc56 values reduce the number of outliers above \ud835\udf0f (increasing frame rate), but their average is smaller (decreasing frame sizes). As we increase \ud835\udf06 (giving more emphasis to frame rate), the optimal solution will select smaller and smaller values of \ud835\udefc, reducing the number of outliers further. Computing \ud835\udefc\u2217 can be done efficiently by evaluating the objective at only a finite set of \ud835\udefc =min(\ud835\udf0f \u22c5 \ud835\udc51\ud835\udc56\ud835\udefc\ud835\udc56 ,1) for \ud835\udc56 \u2208 {1,2, ...,\ud835\udc41} (see A.1 for details).\nHow does \ud835\udefc work? To demonstrate how \ud835\udefc reacts to link capacity variations, we run Vidaptive on a 1.5Mbps link that experiences 10s of high variability. We repeatedly feed the encoder with a fixed 1280\u00d7720 frame to remove encoder variance. Fig. 6a shows the values of \ud835\udefc and normalized frame rate, the ratio of frame rate and \ud835\udc53\ud835\udc5a\ud835\udc4e\ud835\udc65. Before the fluctuations start at 10s, Vidaptive operates at \ud835\udc53\ud835\udc5a\ud835\udc4e\ud835\udc65 with a very high \ud835\udefc. During the noisy period (10s\u201320s), when the frame rate drops and the frame queueing delay increases, \ud835\udefc decreases to improve frame rate and reduce video bitrate. When the link steadies after the 20s, \ud835\udefc resets to its high value. To demonstrate how \ud835\udefc reacts to encoder variations, we tested Vidaptive on a fixed 1.5Mbps link with a dynamic video [16]. The encoded frame sizes increase during high-motion periods due to large differences from previous frames. Fig. 6b illustrates how \ud835\udefc adapts to the variable output of the encoder, decreasing in the aftermath of a large frame to improve frame rate before increasing again.\nResolution Selection. While tuning the target bitrate effectively adapts the video bitrate over smaller ranges, we change the resolution when more drastic changes are needed. Specifically, we make one of three decisions on every frame: maintain, increase, or decrease the current resolution. We decrease the resolution by one level (e.g., from 1080p to 720p) if the number of frames delivered in the last time interval \ud835\udc47 is below the minimum acceptable frame rate (5 FPS in Vidaptive) because this suggests that frames are too large for the current link capacity. In contrast, if \ud835\udefc is high and the measured video bitrate is far lower than the encoder\u2019s supplied target bitrate, the encoder is having trouble meeting its target bitrate and maintaining high utilization at the current resolution because the frames are too small. So, we increase the resolution by one level (e.g., 720p to 1080p). We simply maintain the resolution if none of the above cases are met. To avoid changing the resolution too frequently and ensure we have sufficient data points to make further changes, we only update the resolution if more than \ud835\udc47 seconds have passed since the latest resolution change. The details of the mechanism are in A.2.\n4 Implementation We implemented our system on top of Google\u2019s implementation of WebRTC [2]. Congestion Controller. We replace GCC within WebRTC with two window-based delay-sensitive algorithms, Copa [3] and RoCC [9]. We reused the logic from the original implementation of Copa [17]. Given \ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5a\ud835\udc56\ud835\udc5b, the minimum observed RTT, RoCC sets the congestion window (cwnd) to a small constant more than the number of bytes received in the last (1 + \ud835\udefe)\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5a\ud835\udc56\ud835\udc5b interval. To achieve high utilization with controlled delays, RoCC aims to maintain a network queueing delay of \ud835\udefe\ud835\udc5f\ud835\udc61\ud835\udc61\ud835\udc5a\ud835\udc56\ud835\udc5b where \ud835\udefe is the delay-sensitiveness parameter. Dummy Generator. We repurpose the padding generator in WebRTC to generate dummy packets that are within the cwnd and no more than 200 bytes each. Dummy packets are ACKed by the receiver but have a special padding to ensure that the payload is ignored. We have implemented safeguards to limit the maximum rate of the dummy traffic to the maximum possible video bitrate (set as 12Mbps). Latency Safeguards. The transport layer sets the encoder target bitrate to zero to signal a pause if the oldest packet\u2019s age in the pacer queue exceeds the pacer queue pause threshold (\ud835\udf0f). We reuse WebRTC\u2019s support for buffering the latest unencoded camera frame. We force an Encoder Reset if the\noldest packet age exceeds 1 second in Vidaptive by draining all the video packets in the pacer queue and signaling the video encoder to send a keyframe via an existing API call in WebRTC. Encoder Rate Controller. Vidaptive has two modules to adapt the encoder to the network: encoder bitrate and resolution selection. We disabled the resolution logic in WebRTC [18] and moved the adaptation logic to occur prior to frame encoding. These modules record \ud835\udefc values and frame queueing delay samples received from the transport layer whenever a frame is sent out from the pacer. Vidaptive picks the next \ud835\udefc\u2217 and frame resolution on a frame-by-frame basis by optimizing over the \ud835\udefc and frame queueing delay values over a sliding window of the last \ud835\udc47 seconds (Algorithm 1). We use \ud835\udc47 = 1s by default. The sliding window ensures gradual changes in \ud835\udefc over time.\nAfter picking \ud835\udefc\u2217, the resolution module chooses whether to decrease, increase, or hold the current resolution on a perframe basis as described in \u00a73.4. The resolution module tracks how many consecutive frames have signaled \u201cincrease\u201d or \u201cdecrease\u2019 and changes the resolution if the number exceeds the threshold for that signal (15 frames for \u201cdecrease\u201d and 30 for \u201cincrease\u201d) 3. It also waits at least \ud835\udc47 seconds before changing the resolution again.\n5 Evaluation We evaluate Vidaptive atop a WebRTC-based implementation on Mahimahi links. We describe our setup in \u00a75.1 and use it to compare existing baselines in \u00a75.2. In \u00a75.3, we delve deeper into Vidaptive\u2019s design components. Trace-level breakdowns of all results can be found in App. C.\n5.1 Setup Testbed. Inspired by OpenNetLab [19], we built a testbed, implemented in C++, on top of WebRTC [20] that enables a headless peer-to-peer video call between two endpoints. The sender reads video frames from an input file and the receiver records the received frames to an output file. To match video frames between the sender and the receiver for visual quality and latency measurements, a unique 2D barcode is placed on each frame [7]. We emulate different network conditions between the sender and receiver by placing the receiver behind a Mahimahi [8] link shell. Vidaptive uses Copa [3] as the default CCA. All experiments are run for 2min on a lossless link with a one-way delay of 25ms. Metrics. Two primary metrics are used to quantify the performance improvements of Vidaptive: frame quality and frame latency. Frame quality is measured by the Peak Signal-to-Noise Ratio (PSNR [21]) between received frames and the corresponding source frames. Vidaptive reports the time between frame read at the sender and frame display at the receiver as frame latency and deems the display time for frames that are not received at the receiver as the presentation time of the\n3Vidaptive prioritizes responding to drops in capacity faster than increases.\nsubsequent displayed frame [7]. We also report the network utilization and frame rate at the receiver. Network Traces. We evaluate each scheme on a set of 16 cellular traces bundled with Mahimahi [8], and also use synthetic traces to illustrate the convergence behavior in 5.3. Videos. We use a 1080p (i.e., 1920\u00d71080) video with a frame rate of 30 FPS YUV video dataset curated from YouTube. Tab. 1 describes the details in the appendix. All the experiments are on the first video of the dataset (Tab. 1) unless stated otherwise. Audio is disabled throughout the experiments. Baselines. We evaluate Google Congestion Control algorithm (GCC), WebRTC\u2019s default transport mechanism. We also evaluate Vidaptive with Copa and RoCC. We use \ud835\udefe = 0.5 (\u00a74) for RoCC and \ud835\udeff = 0.9 (see [3]) for Copa to maintain low-network delay. We choose \ud835\udf06 = 0.5 to weigh frame rate and utilization equally when optimizing the target bitrate in Vidaptive (\u00a73.4). The pacer queue pause threshold is set to \ud835\udf0f = 33\ud835\udc5a\ud835\udc60, and frame queueing delay measurement interval is set to \ud835\udc47 = 1\ud835\udc60 for online optimization of the target bitrate.\n5.2 Overall Comparison\nWe summarize Vidaptive\u2019s performance improvements over WebRTC atop GCC on all Mahimahi cellular traces in Fig. 7. The X axis (symlog [22] format) shows the P95 latency improvement, and the Y axes show the average PSNR and video bitrate improvements of Vidaptive over GCC. On nearly all traces, Vidaptive improves PSNR (1.6 dB on average). Vidaptive also improves P95 latency on 10 out of 16 traces, achieving over 2.7 seconds improvement in P95 frame latency on average across all the traces. Vidaptive has 45-380 ms higher P95 latency on 5 of the traces, although it improves average PSNR by 0.8-3.4 dB on these traces.\nTo better understand per-frame behavior, Fig. 8 shows the CDFs of PSNR and frame latency of all the frames across all the traces. Vidaptive achieves a better PSNR at all the percentiles by sending larger frames when possible. Overall, it improves average PSNR by 1.9 dB and P95 PSNR by 2.2 dB.\nSince Vidaptive generally sends larger frames, its minimum latency is higher than GCC, and it slightly increases the median latency (148 ms for GCC versus 195ms for Vidaptive). However, GCC\u2019s frame latency becomes much worse beyond the 75th percentile. The high percentiles correspond to scenarios with high link rate variability and outages, where Vidaptive\u2019s CCA (Copa) responds faster than GCC. For example, Vidaptive reduces P95 frame latency by 2687ms compared to GCC (4120ms\u2192 1433ms).\nFig. 9 shows the distribution of the normalized improvement of the Vidaptive\u2019s metrics compared to GCC per trace. The whiskers denote P5 and P95 values, the interquartile range shows P25\u2013P75, the horizontal line shows P50 and the dot shows the average. Because Vidaptive\u2019s CCA is more responsive, Vidaptive, on average, achieves more than 2.5\u00d7 of GCC\u2019s link utilization. Vidaptive also achieves a higher video bitrate than GCC on nearly all traces, yielding an average of \u223c2\u00d7 and up to 2.7\u00d7 improvement. Vidaptive improves the P95 latency by up to \u223c2x. In Fig. 7, whenever Vidaptive has a higher P95 latency, it has higher video bitrate and quality. Vidaptive has\n\u223c10% and 30% lower frame rate on average and in the worst case compared to GCC, resulting in frame rates of 27 FPS and 21 FPS respectively. This reduction in frame rate happens during outages when, unlike GCC, Vidaptive\u2019s CCA chooses not to send any frames and avoids further congestion. This caps Vidaptive\u2019s frame rate but achieves better frame latency.\n5.3 Understanding Vidaptive\u2019s Design\nEffect of Dummy Traffic. To quantify the effect of dummy traffic, we disable the changes we made to the target bitrate selection logic and focus on transport layer changes (\u00a73.2). In Fig. 10, we emulate a link that starts with 5Mbps of bandwidth for 40 s, drops to 2Mbps for the next 40 s before jumping back to 5Mbps. We compare the video and padding bitrate for \u201cCopa\u201d to Copa with dummy traffic (\u201cCopa+Dummy\u201d). Copa takes 6 s to match the network capacity, while Copa+Dummy takes 2 s. The dummy traffic is sent only when the video traffic cannot match the link capacity when it suddenly opens up (around 0s and 80s). Copa does not match capacity as fast because its rate on the wire is determined by the slow-reacting encoder (\u00a72). Further, \u201cCopa+Dummy\u201d has a more stable steady-state bitrate than \u201cCopa\u201d because the dummy traffic decouples the CCA\u2019s feedback from the video encoder\u2019s variable output, enabling more accurate link capacity estimation. Ablation Study. To understand the impact of different components in Vidaptive\u2019s design, we incrementally evaluate the benefits of changing the congestion control and adding dummy traffic at the transport layer (\u00a73.2), enabling the latency safeguards (\u00a73.3), and running the encoder bitrate and resolution selection approach described in \u00a73.4. Fig. 11 shows the distribution of the normalized performance improvement compared to GCC on all the traces for different system variations.\nIn \u201cCopa,\u201d we replace GCC with a window-based congestion control algorithm but keep the rest of the modules unchanged. Copa is more aggressive than GCC in bandwidth allocation, improving the average link utilization and video\nbitrate by over 2\u00d7. However, the aggressiveness causes an average increase of 3.1 seconds in the P95 latency. The frame rate also reduces because Copa\u2019s window-based mechanism, unlike GCC, simply stops sending when it detects outages.\nIn \u201cCopa+Dummy,\u201d as the name suggests, we add dummy traffic (\u00a73.2) on top of Copa. Since dummy traffic speeds up bandwidth discovery, the link video bitrate and link utilization improves over \u201cCopa.\u201d However, the P95 frame latency is still very high compared to GCC.\nIn \u201cCopa+Dummy+Latency,\u201d we enable the latency safeguards on top of \u201cCopa+Dummy\u201d but keep the encoder bitrate selection logic unchanged. This reduces the P95 latency (Fig. 11c) compared to GCC, \u201cCopa,\u201d and \u201cCopa+Dummy,\u201d yielding an average reduction of over 2.2 seconds in P95 latency compared to GCC. Since the safeguards pause encoding of frames that increase the latency, the overall frame rate, video bitrate, and utilization decrease compared to \u201cCopa\u201d and \u201cCopa+Dummy.\u201d\nFinally, in \u201cVidaptive\u201d, the system aims to find the right target video bitrate for the encoder by running the optimization described in \u00a73.4. Because this system is trying to balance the frame rate and frame quality, the video bitrate reduces, and the frame rate increases compared to \u201cCopa+Dummy+Latency\u201d. Moreover, the latency further decreases because of the reduction of the video bitrate. The utilization is comparable across all schemes with dummy traffic since it pads any encoder\noutput to match the link rate.\nResolution Distribution. Vidaptive uses a different resolution scheme than WebRTC. Fig. 12 shows the CDF of all the selected resolutions during the experiment across all the traces. More than 80% of the time, Vidaptive chooses a higher resolution than WebRTC, which often translates to higher video quality. When the link capacity is very low or highly variable, Vidaptive chooses to send the lowest resolution, manifesting itself in lower resolution values in low percentiles. In contrast, WebRTC\u2019s resolution mechanism [18] reacts slowly and causes huge latency spikes. Vidaptive currently supports the resolutions shown in Fig. 12.\nUsing a Different Congestion Controller. To show that Vidaptive can work with any delay-sensitive window-based CCA, we replaced Copa with RoCC [9]. Fig. 13a shows the PSNR and P95 latency improvements of Vidaptive (RoCC) compared to GCC. Vidaptive (RoCC) follows similar trends as Vidaptive and improves the average video bitrate on almost all traces while improving the P95 latency for half of them. Fig. 13b shows the distribution of the normalized performance improvements of Vidaptive (RoCC) over GCC on all traces. Like Vidaptive, Vidaptive (RoCC) achieves a higher link utilization and video bitrate on average (more than 3\u00d7 and \u223c 2\u00d7 respectively), while getting an improvement of up to \u223c2\u00d7 in P95 latency and an increment of at most 360ms. Vidaptive (RoCC)\u2019s frame rate is \u223c16% lower on average and 30% lower in the worst case than GCC, resulting in frame rates of 25 FPS and 21 FPS, respectively.\nEvaluation on More Videos. We evaluated Vidaptive on all the videos described in \u00a75.1. Fig. 14 shows the average PSNR improvement against the P95 latency improvement over GCC. Vidaptive improves the average PSNR for \u223c 90% of the settings while increasing the P95 latency by at most 455ms. Since Vidaptive shows similar trends for different videos, we focus on one video and Copa for the remaining experiments.\n10 2\n10 1 0\n10 1\n10 2\n10 3\nP95 Latency Improvement (ms)\n0\n1\n2\n3\n4\nAv g\nPS N\nR\nIm pr\nov em\nen t (\ndB )\nALd2d\nALd2u\nALdd\nALdu\nTLdd\nTLdu TLsdTLsu\nTUdd TUdu\nVEdd\nVEdu\nVLdd\nVLdu\nVLsd\nVLsu\n(a) Average PSNR improvement vs.P95 latency improvement of Vidaptive over WebRTC\n5.4 Effect of Parameter Choices\nEffect of \ud835\udf06. We evaluate the impact of the parameter \ud835\udf06, which trades off video bitrate against frame rate (\u00a73.4). Fig. 15 shows the distribution of the normalized improvement of the metrics relative to GCC on all of the traces with \ud835\udf06 = 0.2,0.5,0.7,0.99. When \ud835\udf06 increases, the optimization framework in \u00a73.4 favors a higher frame rate over the video bitrate, hence video bitrate decreases (Fig. 15b), and average frame rate increases (Fig. 15d). Since Vidaptive uses dummy traffic, changes in the video bitrate do not affect CCA estimations and consequently do not change the overall link utilization. As a result, the overall link utilization (sum of the video and padding bitrates), shown in Fig. 15a, does not change by selecting a different \ud835\udf06. Vidaptive has safeguards to control the maximum latency; hence, changing \ud835\udf06 does not significantly affect the P95 frame latency, as seen in Fig. 15c. Note that during any outages, Vidaptive does not send any frames, which caps Vidaptive\u2019s frame rate. We chose \ud835\udf06 = 0.5 as the default because it maintains a good video bitrate while keeping the P95 latency low with minimal reduction in frame rate (\u223c10%). Pacer Queue Pause Threshold (\ud835\udf0f). Fig. 16 shows how the pacer queue pause threshold \ud835\udf0f (\u00a73.3) affects Vidaptive. We\ntested Vidaptive with \ud835\udf0f = 33, 500, 1000 ms. Changing \ud835\udf0f does not change the network utilization (Fig. 16a) because dummy traffic decouples congestion control from the encoder, padding any encoder output to match the link rate. As \ud835\udf0f increases, the frame rate score increases (Eq. 1), and the encoder bitrate selection logic enforces a higher video bitrate (Fig. 16b). However, these higher-quality frames spend more time in the pacer queue and experience higher P95 latencies (Fig. 16c). At higher \ud835\udf0f, the Encoder Pause threshold is higher, so more frames are encoded, resulting in a higher frame rate (Fig. 16d). Vidaptive selects \ud835\udf0f = 33\ud835\udc5a\ud835\udc60 as it has low P95 latency, relatively high frame rate and video bitrates when compared to GCC. Optimization Time Interval (\ud835\udc47 ). We show the impact of \ud835\udc47 , the interval over which the frame rate and bitrate scores are calculated to strike a balance between them (\u00a73.4). Fig. 17\nshows performance improvements of Vidaptive compared to GCC for \ud835\udc47 = 100,1000,10000 ms. Again, Vidaptive\u2019s link utilization (Fig. 17a) is comparable across all variants because of dummy traffic. A smaller \ud835\udc47 means that Vidaptive reacts to any sudden and local changes in recent frame queueing delay data. \ud835\udc47 = 100 means that the encoder bitrate selection looks at utmost three measurements for a camera with 30 FPS to optimize \ud835\udefc. Any temporary decrease in the few frame queueing delay samples results in a higher encoder target bitrate that affects the slow encoder for a long period of time, resulting in higher video bitrate a lower frame rate and consequently a high latency. On the other hand, a large \ud835\udc47 makes the system insensitive to recent changes in frame queueing delay, and a few large frame queueing delay measurements will result in lower values of \ud835\udefc, which reduces the video bitrate. Further, because the resolution changes at most every \ud835\udc47 , a 10 second \ud835\udc47 does not lower the resolution in time in outages, causing a reduction in the frame rate and severely affecting the latency. We picked \ud835\udc47 = 1000\ud835\udc5a\ud835\udc60 for Vidaptive to ensure the bitrate selection is relatively stable while maintaining sensitivity to the recent frame queueing delay samples.\n6 Related Work Congestion Control. End-to-end congestion control approaches can be broadly categorized into delay-based [1,3,4,6, 10,23\u201325] or buffer-filling schemes [26,27]. Delay-based protocols aim to minimize queuing by adjusting their sending rate based on queuing delay [10,25,28], or delay-gradients [1,6,24].\nBuffer-filling algorithms [26, 29, 30] send as much traffic as possible until loss or congestion is detected. Some approaches like Nimbus [31] switch between delay-based and buffer-filling modes to improve fairness against competing traffic while maintaining high utilization. However, limited attention has been paid to congestion control for applicationlimited flows [32, 33] like video traffic that is generated at fixed intervals determined by the frame rate.\nWebRTC Systems. Many video applications use Web Realtime Communication (WebRTC) [2] to deliver real-time video. GCC [34], WebRTC\u2019s rate control, uses delay gradients to adjust the sending rate. However, GCC\u2019s conservative behavior coupled with the variance in encoder output results in either under-utilization or latency spikes.\nSalsify [7] previously observed a mismatch between video encoder output and available capacity, and rectified it by encoding multiple versions of the same frame and picking the better match. This requires changing the video codec at the sender and the receiver, making it hard to deploy. Vidaptive instead matches encoder output to network capacity without changes to the encoder. Adaptive bitrate algorithms [35\u201339] solve a similar problem for on-demand video using information about available bandwidth, buffer size, and current bitrate to determine the encoder\u2019s target bitrate. A recent proposal called SQP [40] achieves low end-to-end frame delay for interactive video streaming applications but operates in much higher bitrates than Vidaptive is designed for.\n7 Conclusion This paper proposes Vidaptive, a new rate control mechanism for low-latency video applications that is highly efficient and adapts rapidly to changing network conditions without modifications to the video encoder. Vidaptive injects \u201cdummy\u201d traffic to make video traffic appear like a backlogged flow running a delay-based congestion controller. Vidaptive also continuously adapts the frame rate, encoder\u2019s target bitrate, and video resolution to reduce discrepancies between the encoder output bitrate and link rate. We leave to future work an exploration of leveraging dummy traffic for purposes like FEC or keyframes, and the benefits from functional encoders like Salsify [7] in Vidaptive for improved real-time experience.\nReferences [1] Gaetano Carlucci, Luca De Cicco, Stefan Holmer, and\nSaverio Mascolo. Analysis and design of the google congestion control for web real-time communication (webrtc). In Proceedings of the 7th International Conference on Multimedia Systems, pages 1\u201312, 2016.\n[2] WebRTC. https://webrtc.org/.\n[3] Venkat Arun and Hari Balakrishnan. Copa: Practical delay-based congestion control for the internet. In 15th USENIX Symposium on Networked Systems Design and Implementation (NSDI 18), pages 329\u2013342, 2018.\n[4] Neal Cardwell, Yuchung Cheng, C Stephen Gunn, Soheil Hassas Yeganeh, and Van Jacobson. Bbr: Congestion-based congestion control. Queue, 14(5):20\u2013 53, 2016.\n[5] Keith Winstein, Anirudh Sivaraman, and Hari Balakrishnan. Stochastic forecasts achieve high throughput and low delay over cellular networks. In 10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13), pages 459\u2013471, 2013.\n[6] Yasir Zaki, Thomas P\u00f6tsch, Jay Chen, Lakshminarayanan Subramanian, and Carmelita G\u00f6rg. Adaptive congestion control for unpredictable cellular networks. In Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication, pages 509\u2013522, 2015.\n[7] Sadjad Fouladi, John Emmons, Emre Orbay, Catherine Wu, Riad S Wahby, and Keith Winstein. Salsify: Lowlatency network video through tighter integration between a video codec and a transport protocol. In 15th USENIX Symposium on Networked Systems Design and Implementation (NSDI 18), pages 267\u2013282, 2018.\n[8] Ravi Netravali, Anirudh Sivaraman, Somak Das, Ameesh Goyal, Keith Winstein, James Mickens, and Hari Balakrishnan. Mahimahi: Accurate record-and-replay for http. In Usenix annual technical conference, pages 417\u2013429, 2015.\n[9] https://108anup.github.io/assets/papers/CC matic-Hotnets22.pdf.\n[10] Lawrence S. Brakmo and Larry L. Peterson. Tcp vegas: End to end congestion avoidance on a global internet. IEEE Journal on selected Areas in communications, 13(8):1465\u20131480, 1995.\n[11] https://chromium.googlesource.com/external /webrtc/+/3c1e558449309be965815e1bf/webrtc /modules/congestion_controller/probe_contr oller.cc.\n[12] Van Jacobson. Congestion avoidance and control. ACM SIGCOMM computer communication review, 18(4):314\u2013 329, 1988.\n[13] Michael Rudow, Francis Y Yan, Abhishek Kumar, Ganesh Ananthanarayanan, Martin Ellis, and KV Rashmi. Tambur: Efficient loss recovery for videoconferencing via streaming codes. In 20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23), pages 953\u2013971, 2023.\n[14] Marcin Nagy, Varun Singh, J\u00f6rg Ott, and Lars Eggert. Congestion control using fec for conversational multimedia communication. In Proceedings of the 5th ACM Multimedia Systems Conference, pages 191\u2013202, 2014.\n[15] Edwin KP Chong, Robert L Givan, and Hyeong Soo Chang. A framework for simulation-based network control via hindsight optimization. In Proceedings of the 39th IEEE Conference on Decision and Control (Cat. No. 00CH37187), volume 2, pages 1433\u20131438. IEEE, 2000.\n[16] https://www.youtube.com/watch?v=19ikl8vy4z s.\n[17] https://github.com/venkatarun95/genericCC/ blob/master/markoviancc.cc.\n[18] https://chromium.googlesource.com/external /webrtc/+/master/video/g3doc/adaptation.md.\n[19] Jeongyoon Eo, Zhixiong Niu, Wenxue Cheng, Francis Y Yan, Rui Gao, Jorina Kardhashi, Scott Inglis, Michael Revow, Byung-Gon Chun, Peng Cheng, et al. Opennetlab: Open platform for rl-based congestion control for real-time communications. Proc. of APNet, 2022.\n[20] https://webrtc.googlesource.com/src/+/a2f5 d45b81c6ae5632af0c4c45e8988f330af7f1.\n[21] Alain Hore and Djemel Ziou. Image quality metrics: Psnr vs. ssim. In 2010 20th international conference on pattern recognition, pages 2366\u20132369. IEEE, 2010.\n[22] https://matplotlib.org/stable/gallery/scal es/symlog_demo.html.\n[23] Changhyun Lee, Chunjong Park, Keon Jang, Sue B Moon, and Dongsu Han. Accurate latency-based congestion feedback for datacenters. In USENIX Annual Technical Conference, pages 403\u2013415, 2015.\n[24] Radhika Mittal, Vinh The Lam, Nandita Dukkipati, Emily Blem, Hassan Wassel, Monia Ghobadi, Amin Vahdat, Yaogong Wang, David Wetherall, and David Zats. Timely: Rtt-based congestion control for the datacenter. ACM SIGCOMM Computer Communication Review, 45(4):537\u2013550, 2015.\n[25] Cheng Jin, David X Wei, and Steven H Low. Fast tcp: motivation, architecture, algorithms, performance. In IEEE INFOCOM 2004, volume 4, pages 2490\u20132501. IEEE, 2004.\n[26] Mo Dong, Qingxi Li, Doron Zarchy, P Brighten Godfrey, and Michael Schapira. PCC: Re-architecting congestion control for consistent high performance. In 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI 15), pages 395\u2013408, 2015.\n[27] TCP. \"https://datatracker.ietf.org/doc/htm l/rfc793.\n[28] Sea Shalunov, Greg Hazel, Janardhan Iyengar, and Mirja Kuehlewind. Low extra delay background transport (ledbat). Technical report, 2012.\n[29] Sangtae Ha, Injong Rhee, and Lisong Xu. Cubic: A new tcp-friendly high-speed tcp variant. SIGOPS Oper. Syst. Rev., 42(5):64\u201374, jul 2008.\n[30] Sally Floyd, Tom Henderson, and Andrei Gurtov. Rfc3782: The newreno modification to tcp\u2019s fast recovery algorithm, 2004.\n[31] Prateesh Goyal, Akshay Narayan, Frank Cangialosi, Srinivas Narayana, Mohammad Alizadeh, and Hari Balakrishnan. Elasticity detection: A building block for internet congestion control. In Proceedings of the ACM SIGCOMM 2022 Conference, pages 158\u2013176, 2022.\n[32] Updating TCP to Support Rate-Limited Traffic. https: //www.rfc-editor.org/rfc/rfc7661.html.\n[33] Cubic Quiescence: Not So Inactive. https://www.ie tf.org/proceedings/94/slides/slides-94-tcp m-8.pdf.\n[34] Gaetano Carlucci, Luca De Cicco, Stefan Holmer, and Saverio Mascolo. Analysis and design of the google congestion control for web real-time communication (webrtc). In Proceedings of the 7th International Conference on Multimedia Systems, pages 1\u201312, 2016.\n[35] Hongzi Mao, Ravi Netravali, and Mohammad Alizadeh. Neural adaptive video streaming with pensieve. In Proceedings of the conference of the ACM special interest group on data communication, pages 197\u2013210, 2017.\n[36] Te-Yuan Huang, Ramesh Johari, Nick McKeown, Matthew Trunnell, and Mark Watson. A buffer-based approach to rate adaptation: Evidence from a large video streaming service. In Proceedings of the 2014 ACM conference on SIGCOMM, pages 187\u2013198, 2014.\n[37] Xiaoqi Yin, Abhishek Jindal, Vyas Sekar, and Bruno Sinopoli. A control-theoretic approach for dynamic adaptive video streaming over http. In Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication, pages 325\u2013338, 2015.\n[38] Kevin Spiteri, Rahul Urgaonkar, and Ramesh K Sitaraman. Bola: Near-optimal bitrate adaptation for online videos. IEEE/ACM Transactions On Networking, 28(4):1698\u20131711, 2020.\n[39] Francis Y Yan, Hudson Ayers, Chenzhi Zhu, Sadjad Fouladi, James Hong, Keyi Zhang, Philip Alexander Levis, and Keith Winstein. Learning in situ: a randomized experiment in video streaming. In NSDI, volume 20, pages 495\u2013511, 2020.\n[40] Devdeep Ray, Connor Smith, Teng Wei, David Chu, and Srinivasan Seshan. Sqp: Congestion control for low-latency interactive video streaming. arXiv preprint arXiv:2207.11857, 2022.\nA Encoder Bitrate and Resolution Selection Mechanism\nIn this section, we explain the encoder bitrate and resolution selection algorithms in detail.\nA.1 Solving the Optimization Problem Assume we have \ud835\udc41 frame queueing delay measurements \ud835\udc51\ud835\udc56 for \ud835\udc56 \u2208 {1,2, ..,\ud835\udc41} over a time interval \ud835\udc47 , for frames encoded instantaneously with a target bitrate \ud835\udefc\ud835\udc56 \u22c5CC-Rate where CC-Rate was approximated to be constant over the interval. We use hindsight optimization and ask \u201chad we picked a different target bitrate, what would have been the counterfactual values of \ud835\udc51\ud835\udc56?\u201d We use .\u0303 to show counterfactual variables.\nHad all these frames been encoded by \ud835\udefc instead, the counterfactual frame queueing delay would have been \ud835\udc51\ud835\udc56 = \ud835\udefc\n\ud835\udc51\ud835\udc56 \ud835\udefc\ud835\udc56 .\nLet \ud835\udc58\ud835\udc56 = \ud835\udc51\ud835\udc56 \ud835\udefc\ud835\udc56\nfor \ud835\udc56 \u2208 {1,2, ..,\ud835\udc41}. The counterfactual values of  and  as a function of \ud835\udefc are\n\u0303 (\ud835\udefc) =\n\u2211\ud835\udc41 \ud835\udc56=1\ud835\udfd9[\ud835\udefc \u22c5 \ud835\udc51\ud835\udc56 \ud835\udefc\ud835\udc56 \u2264 \ud835\udf0f]\n\ud835\udc41\n= \u2211\ud835\udc41 \ud835\udc56=1\ud835\udfd9[\ud835\udefc \u22c5\ud835\udc58\ud835\udc56 \u2264 \ud835\udf0f] \ud835\udc41\n(4)\n\u0303(\ud835\udefc) = \ud835\udc5a\ud835\udc56\ud835\udc5b (\n\ud835\udc53\ud835\udc5a\ud835\udc4e\ud835\udc65 \u22c5\n\u2211\ud835\udc41 \ud835\udc56=1 \ud835\udefc \u22c5 \ud835\udc51\ud835\udc56 \ud835\udefc\ud835\udc56\n\ud835\udc41 ,1 )\n= \ud835\udc5a\ud835\udc56\ud835\udc5b ( \ud835\udc53\ud835\udc5a\ud835\udc4e\ud835\udc65 \u22c5 \u2211\ud835\udc41 \ud835\udc56=1 \ud835\udefc \u22c5\ud835\udc58\ud835\udc56 \ud835\udc41 ,1 )\n(5)\nWith this definition, we find \ud835\udefc\u2217 such that it maximizes the counterfactual optimization objective, denoted by Objective(\ud835\udefc),\n\ud835\udefc\u2217 = argmax \ud835\udefc Objective(\ud835\udefc)\n= argmax \ud835\udefc \ud835\udf06 1\u2212\ud835\udf06 \u0303 (\ud835\udefc)+ \u0303(\ud835\udefc)\n= argmax \ud835\udefc\n\u23a7\n\u23aa\n\u23a8\n\u23aa\n\u23a9\n\ud835\udf06 1\u2212\ud835\udf06\n\u2211\ud835\udc41 \ud835\udc56=1\ud835\udfd9[\ud835\udefc \u22c5 \ud835\udc51\ud835\udc56 \ud835\udefc\ud835\udc56 \u2264 \ud835\udf0f]\n\ud835\udc41\n+min (\n\ud835\udc53\ud835\udc5a\ud835\udc4e\ud835\udc65 \u22c5\n\u2211\ud835\udc41 \ud835\udc56=1 \ud835\udefc \u22c5 \ud835\udc51\ud835\udc56 \ud835\udefc\ud835\udc56\n\ud835\udc41 ,1 )\n\u23ab\n\u23aa\n\u23ac\n\u23aa\n\u23ad\ns.t. 0 < \ud835\udefc < 1\n(6)\nWithout loss of generality, we assume that the values of \ud835\udc58\ud835\udc56 for \ud835\udc56 \u2208 {1,2, ...,\ud835\udc41} are sorted in increasing order. Let \ud835\udc65\ud835\udc56 =\n\ud835\udf0f \ud835\udc58\ud835\udc56 for \ud835\udc56 \u2208 {1,2, ...,\ud835\udc41}. Note that \ud835\udc65\ud835\udc56 values are in decreasing order. \u0303 (\ud835\udefc) is a discrete monotonically reducing\nfunction relative to \ud835\udefc whose value changes at \ud835\udefc = \ud835\udc5a\ud835\udc56\ud835\udc5b( \ud835\udf0f\ud835\udc58\ud835\udc56 ,1) for \ud835\udc56 \u2208 {1,2, ...,\ud835\udc41}. If \ud835\udc65\ud835\udc56+1 < \ud835\udc65\ud835\udc56 we have \u0303 (\ud835\udc65\ud835\udc56+1) = \u0303 (\ud835\udc65\ud835\udc56)+1 for 0 < \ud835\udc65\ud835\udc56,\ud835\udc65\ud835\udc56+1 < 1. Since \u0303(\ud835\udefc) is a monotonically increasing function of \ud835\udefc, we have \u0303(\ud835\udc65\ud835\udc56+1) < \u0303(\ud835\udc65\ud835\udc56). For any value of \ud835\udc65 such that \ud835\udc65\ud835\udc56+1 < \ud835\udc65 \u2264 \ud835\udc65\ud835\udc56, since \u0303 (\ud835\udc65) = \u0303 (\ud835\udc65\ud835\udc56) and \u0303(\ud835\udc65) \u2264 \u0303(\ud835\udc65\ud835\udc56), Objective(\ud835\udc65) \u2264 Objective(\ud835\udc65\ud835\udc56). As a result, checking Objective(\ud835\udc65\ud835\udc56) and Objective(\ud835\udc65\ud835\udc56+1) is enough to find the maximum in interval (\ud835\udc65\ud835\udc56+1,\ud835\udc65\ud835\udc56]. This means that checking \ud835\udc65\ud835\udc56 values for \ud835\udc56 \u2208 {1,2, ...,\ud835\udc41} is sufficient to find \ud835\udefc\u2217. Algorithm 1 shows the detailed algorithm for solving this optimization problem. In our implementation, if \ud835\udc41 is not large enough, we declare an outage and linearly increase the amount of \ud835\udefc to back off from the congestion. A.2 Resolution Selection Mechanism Vidaptive has an adaptive mechanism to change the resolution in two scenarios. First, when the current frame rate is low, Vidaptive lowers the resolution because the current frame sizes are too big to go through the network. Second, if the output average video bitrate of the encoder is lower than the average target bitrate given to the encoder in the last \ud835\udc47 seconds, despite a high \ud835\udefc\u2217, Vidaptive needs to increase the resolution because the encoder is unable to match the current bitrate at its current resolution. The assumption behind this is that if the chosen resolution for the encoder is correct, the encoder should be able to achieve its target bitrate over long periods of time (e.g. \ud835\udc47 = 1000\ud835\udc5a\ud835\udc60). The resolution selection module sits before the video encoder to choose the resolution on a frame-by-frame basis. It also observes the output of the encoder to measure the video bitrate. It measures the system\u2019s current frame rate and its enc_ratio, the ratio between the encoder\u2019s achieved bitrate and its supplied target bitrate. We define MinFrameRate as the minimum acceptable frame rate of the system, and MinEncRatio as the minimum required value of enc_ratio. The resolution selection module decides on a per-frame basis to emit a \u201cDecrease\u201d, \u201cIncrease\u201d or \u201cHold resolution\u201d signal based on the values of its measurements as described in Algorithm 2.\nIf Vidaptive releases \u201cDecrease Resolution\u201d for ResDownThresh, set to 15 consecutive frames, the frame rate has been consistently low and the resolution is decreased. If Vidaptive releases \u201cIncrease Resolution\u201d for ResUpThresh, set to 30 consecutive frames, the encoder is not keeping up with the target bitrate for a long period and the resolution is increased. We also prevent unwanted resolution oscillations that could adversely affect the quality of experience by making sure we don\u2019t change resolution twice within a time interval of \ud835\udc47 .\nB Video Bitrate Improvements Figures 19a, 19b, and 19c show the corresponding video bitrate vs. latency improvements for experiments shown in Figures 7, 13, and 14.\nAlgorithm 1 Solving Optimization to Find Encoder Target Bitrate Ratio (\ud835\udefc\u2217) Input : D: Vector of frame queuing delays,\nA: Vector of \ud835\udefc values for frames in D, \ud835\udefc\u2032: Current value of \ud835\udefc\nOutput : \ud835\udefc\u2217: encoder bitrate ratio to CC-Rate // Control Parameters \ud835\udc53\ud835\udc5a\ud835\udc4e\ud835\udc65 \u2190 30 ; // max. frame rate of system \ud835\udf06\u2190 0.5 ; // Frame rate sensitivity \ud835\udf0f \u2190 33 ; // Frame Drop Threshold \ud835\udc47 ; // Optimization interval (s) MinFrameRate \u2190 5 ; // Min. frame rate (FPS) \ud835\udefc\ud835\udc5a\ud835\udc56\ud835\udc5b \u2190 0.05 ; // Min. \ud835\udefc value \ud835\udefc\ud835\udc5a\ud835\udc4e\ud835\udc65 \u2190 1.0 ; // Max. \ud835\udefc value\nFunction Objective(\ud835\udc65, \ud835\udc3e): \ud835\udc41 = Size(D)  , = 0,0 for \ud835\udc56\u2190 0 to \ud835\udc41 \u22121 do\n\u2190 + \ud835\udc3e[\ud835\udc56]\ud835\udc41 if \ud835\udc3e[\ud835\udc56] \u2264 \ud835\udf0f then\n \u2190  + 1\ud835\udc41 \u2190min(,1) return \ud835\udf061\u2212\ud835\udf06 +\nFunction FindAlpha (\ud835\udc37, \ud835\udc34, \ud835\udefc\u2032): \ud835\udc41 = Size(D) if \ud835\udc41\ud835\udc47 \u2264 MinFrameRate then\n// Not enough samples, frame rate is small // Frames too big return \ud835\udc5a\ud835\udc4e\ud835\udc65(\ud835\udefc\u2032\u22120.15,\ud835\udefc\ud835\udc5a\ud835\udc56\ud835\udc5b)\n\ud835\udc3e \u2190 empty list for \ud835\udc56\u2190 0 to \ud835\udc41 \u22121 do\n\ud835\udc3e[\ud835\udc56]\u2190 \ud835\udc37[\ud835\udc56]\ud835\udc34[\ud835\udc56] Sort K in ascending order \ud835\udefc\u2217 \u2190 \ud835\udefc\ud835\udc5a\ud835\udc4e\ud835\udc65 max_obj \u2190 Objective (\ud835\udefc\ud835\udc5a\ud835\udc4e\ud835\udc65,K) for \ud835\udc56\u2190 0 to \ud835\udc41 \u22121 do\nif \ud835\udf0f\ud835\udefc\ud835\udc5a\ud835\udc4e\ud835\udc65 < K[\ud835\udc56] \u2264 \ud835\udf0f \ud835\udefc\ud835\udc5a\ud835\udc56\ud835\udc5b then\nx \u2190 \ud835\udf0fK[\ud835\udc56] obj_value \u2190 Objective(x, K) if max_obj < obj_value then\nmax_obj \u2190 obj_value \ud835\udefc\u2217 \u2190 x\nreturn \ud835\udefc\nAlgorithm 2 Adaptive Resolution Control // Control Parameters T \u2190 1 ; // Optimization interval (s) MinEncRatio \u2190 0.9 ; // Min. required encoder ratio MinFrameRate \u2190 5 ; // Min. frame rate (FPS) ResUpThresh \u2190 30 ; // Approx. 1 second ResDownThresh \u2190 15 ; // Approx. 500 ms for outage // Global Parameters PrevSignal \u2190 0 ; // previous res. signal SignalCount \u2190 0 ; // # of consecutive res. signals LastResTime \u2190 0 ; // Last res. change time (s) DecRes \u2190 \u22121 ; // Decrease Resolution HoldRes \u2190 0 ; // Hold Resolution IncRes \u2190 \u22121 ; // Increase Resolution Input : \ud835\udc41 : Number of frame queuing delay samples,\n\ud835\udefc\u2217: Current value of \ud835\udefc, enc_ratio: encoder output to input bitrate ratio, now: Time in s when calling the function\nOutput : res_dir: Direction to change the resolution res_dir \u2190 HoldRes if \ud835\udc41\ud835\udc47 \u2264 MinFrameRate then\nres_signal \u2190 DecRes else if enc_ratio < MinEncRatio and \ud835\udefc\u2217 > 0.9 then\nres_signal \u2190 IncRes if res_signal = PrevSignal and res_signal \u2260 0 then\nSignalCount \u2190 SignalCount+1 else\nSignalCount \u2190 0 PrevSignal \u2190 res_signal if LastResTime < now\u2212\ud835\udc47 then\nif (SignalCount > ResDownThresh and res_signal = DecRes) or (SignalCount > ResUpThresh and res_signal = IncRes) then\nLastResTime \u2190 now_ms SignalCount \u2190 0 res_dir \u2190 res_signal\nelse res_dir \u2190 HoldRes\nreturn res_dir\n10 2\n10 1 0\n10 1\n10 2\n10 3\nP95 Latency Improvement (ms)\n0\n1\n2\n3\n4\nAv g\nVi de\no Bi\ntra te\nIm\npr ov\nem en\nt ( M\nbp s)\nALd2d\nALd2u\nALdd\nALdu\nTLdd\nTLdu\nTLsd\nTLsu\nTUdd TUduVEdd\nVEdu\nVLdd\nVLdu VLsd VLsu\n(a) Average Video Bitrate improvement vs P95 latency improvement of Vidaptive over GCC.\n10 2\n10 1 0\n10 1\n10 2\n10 3\nP95 Latency Improvement (ms)\n0\n1\n2\n3\n4\n5\nAv g\nVi de\no Bi\ntra te\nIm\npr ov\nem en\nt ( M\nbp s)\nALd2d\nALd2u\nALdd\nALdu\nTLdd\nTLdu\nTLsd\nTLsu\nTUddTUduVEdd VEdu\nVLdd\nVLdu VLsd\nVLsu\n(b) Avg. video bitrate improvement vs. P95 latency improvement of Vidaptive (RoCC) over GCC.\n10 2\n10 1\n10 0 0 10 0\n10 1\n10 2\n10 3\n10 4\nP95 Latency Improvement (ms)\n0\n1\n2\n3\n4\n5\nAv g\nVi de\no Bi\ntra te\nIm\npr ov\nem en\nt ( M\nbp s)\n(c) Average video bitrate improvement vs. P95 latency improvement of the Vidaptive over GCC for individual videos in the dataset.\nFigure 19: Corresponding video bitrate vs. latency improvements for experiments in \u00a75.\nC Trace-level Breakdown of Results Overall Results. Fig. 20 shows a detailed comparison of endto-end frame metrics and video bitrate of GCC, Vidaptive, and RoCC+Vidaptive on all the cellular traces. The whiskers denote P5 and P95 values, the interquartile range shows P25\u2013 P75, the horizontal line shows P50 and the dot shows the average. Fig. 20a describes the distribution of frame PSNRs. The average and median PSNR achieved by Copa and RoCC is higher than GCC on nearly all traces. Moreover, the best frames in Vidaptive (P75 and P95) have a much higher quality compared to GCC; e.g., Vidaptive achieves PSNR of more than 44 dB in VLdd.\nOn these highly variable cellular links, Vidaptive spans a wider range of qualities because its adaptive resolution and fast CCA can capture opportunities to send at higher bitrates, increasing the PSNR average and P95 values, while reacting fast to outages by lowering the encoder target bitrate. For example, in TUdd and TUdu, Vidaptive trades off lower bitrate and worse P5 and P25 frame PSNR relative to GCC for better P95 and P75 frame latency (Fig. 20b) by reacting faster during outages.\nHowever, if the link is generally more stable, Vidaptive\u2019s worst frames (P5 and P25) have better or comparable quality than GCC, such as on TLsu. Though Copa and RoCC control network delays differently, their latency values (Fig. 20b) show similar trends because the latency safeguards within Vidaptive are set up to bound latency independent of the congestion control dynamics. The P5 and P95 values of the latency for Vidaptive are generally higher because it prioritizes higher quality frames. Fig. 21a shows that Vidaptive has a higher video bitrate and link utilization (sum of the video and dummy traffic) than GCC. GCC\u2019s lower P5 and P95 latency is also partially attributed to this under-utilization relative to Vidaptive.\nVidaptive generally has a slightly lower frame rate as shown in Fig. 20c because Copa and RoCC do not send the video frames out on wire if the network is congested. In such cases, Vidaptive pauses the encoder to keep the latency bounded. However, Vidaptive still obtains a good frame rate of more than 20 FPS on almost all the traces, which is sufficient for most realtime video applications. On three challenging traces - TUdd, TUdu, VEdd - all the schemes have difficulty maintaining a good frame rate.\nFig. 21b shows the distribution of the instantaneous link utilization measured using Mahimahi logs. The instantaneous utilization is the ratio of the departure rate of the link to the actual link capacity. Vidaptive has a higher average and median instantaneous link utilization than GCC on all the traces with both RoCC and Copa. The reason is that using the dummy traffic enables isolation of the congestion controllers and the video traffic, and the congestion controllers can now freely estimate and utilize the network well.\nFig. 21c breaks down the distribution of in-network delay\nfor the schemes. The difference between network delay and frame latency is that network delay measures the packet delays inside the network, but frame latency measures an end-to-end metric between frame read and frame display time. If the network delay that the video packets experience is high, the frame latency associated with that frame will inevitably be high. Vidaptive\u2019s delay-sensitive algorithms ensure that in nearly all the traces, Vidaptive consistently maintains low network delay. GCC, in contrast, has a higher network delay on most traces because it does not have a mechanism to control queues in the network effectively. This is especially true on TUdd, TUdu, and VEdd, where GCC experiences high network delays and frame latencies. Since Copa slightly outperforms RoCC relative to GCC, we set Copa as the default CCA in Vidaptive. Effect of \ud835\udf06. Fig. 22a shows the distribution of PSNR values for different values of \ud835\udf06. As \ud835\udf06 increases, the optimization in Eq. 3 favors a higher frame rate (Fig. 22c) to a lower video bitrate(Fig. 23a). As \ud835\udf06 increases, Vidaptive becomes more and more conservative by choosing lower values of \ud835\udefc which results in choosing lower resolutions that cap the maximum quality as \ud835\udf06 increases (P95 values of quality decreases). Fig. 18 shows the CDF of the resolutions selected by Vidaptive for all the frames in all the traces. Lower resolution also reduces the average, median, and P25 values of PSNR. As \ud835\udf06 increases, Vidaptive becomes more conservative in selecting higher resolutions. Fig. 22b shows that the latency measurements generally come down by increasing \ud835\udf06. Simultaneously, the video bitrates and resolution become lower.\nFig. 22c shows that the average frame rate increases as \ud835\udf06 increases, exactly as we designed it to. Using dummy traffic decouples the CCA estimations from the underlying video traffic; hence, the distribution of instantaneous link utilization (Fig. 23b) and network queueing delay (Fig. 23c) are agnostic for different values of \ud835\udf06. The sum of the total average video bitrate and dummy traffic (total link utilization) is constant for different values of \ud835\udf06 (Fig. 23a). Ablation Study. Fig. 24 compares the frame statistics of the systems described in the ablation study in \u00a75.3. Adding the dummy traffic to \u201cCopa\u201d, \u201cCopa+Dummy\u201d achieves a slightly higher link utilization (Fig. 25b) because the added dummy traffic enables better estimation of the network by providing traffic when there are no video packets. Having a better network estimation helps increase the average video bitrate (Fig. 25a) and video quality (Fig. 24a) across its entire range. For \u201cCopa\u201d and \u201cCopa+Dummy\u201d, the PSNR values increase (Fig. 24a) and the link utilization (Fig. 25b) increases compared to GCC, and the average video bitrate (Fig. 25a) goes up consequently because Copa is much more aggressive with estimating the link rate and giving the highest possible bitrate (Fig. 25a) to the encoder. However, without Vidaptive latency knobs, \u201cCopa\u201d and \u201cCopa+Dummy\u201d experience very high latency values because there is no mechanism to control the size of the pacer queue when the encoder is producing such\nhigh bitrates and the network is congested, and CCA is not sending.\nTo fix this issue, \u201cCopa+Dummy+Latency\u201d uses the latency mechanisms of Encoder Pause and Encoder Reset that reduce the latency values across its range (Fig. 24b), but lowers the frame rate as a consequence of Encoder Pause. Since \u201cCopa+Dummy+Latency\u201d encodes fewer frames, it has a lower video bitrate (Fig. 25a) and consequently lower quality (Fig. 24a) than the variations without \u201cLatency\u201d. The network delay and instantaneous utilization distributions are almost identical to \u201cCopa+Dummy\u201d since we using dummy traffic. To fix the issue with lower frame rate, Vidaptive adds the optimization mechanism in \u00a73.4. The increase in frame rate and decrease in the video bitrate can be seen in and Fig. 24c Fig. 25a, respectively.\nAll the variations that have Copa as the underlying CCA, keep the network delay bounded (Fig. 25c) on all traces because Copa is delay-sensitive. They also have a similar network delay and instantaneous utilization distribution for each trace. These variations prioritize the network delay and don\u2019t send any traffic during outages, which restricts the frame rate of the systems that use them (Fig. 24c), meaning that the system prefers to skip encoding the frames that much increase the total number of bytes in flight. Details of Effect of Pacer Queue Threshold (\ud835\udf0f). Fig. 26 shows the comparison of quality-of-experience metrics for different values of \ud835\udf0f. Although changing \ud835\udf0f doesn\u2019t affect the network utilization due to dummy traffic, increasing it will result in a higher frame-rate score and, ultimately, a higher video bitrate. As shown in Fig. 26a, this translates to higher frame quality for most of the traces. At the same time, as frame sizes increase, we experience higher latency (Fig. 26b). Since higher values for \ud835\udf0f mean less aggressive pausing of the encoder, we also experience a higher frame rate.\nD Videos Dataset Information Tab. 1 summarizes the information of all the videos that we used in the experiments. The videos are all collected from YouTube and cover a different range of motions and settings.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n34\n36\n38\n40\n42\n44\n46\nPS N\nR (d\nB)\nGCC Vidaptive Vidaptive (RoCC) Average\n(a) Per-frame PSNR statistics comparison of the received video vs. the original video. Vidaptive has better PSNR values compared to GCC on almost all the traces.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n10 2\n10 3\n10 4\nFr am\ne La\nte nc\ny (m\ns)\nGCC Vidaptive Vidaptive (RoCC) Average\n(b) Per-frame latency statistics comparison of the received video vs. the original video. Vidaptive has a comparable (within less than 400ms of GCC) or much lower latency values compared to GCC.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n34\n36\n38\n40\n42\n44\n46\nPS N\nR (d\nB)\n=0.2 =0.5 =0.7 =0.99 Average\n(a) Demonstrating the effect of \ud835\udf06 on the PSNR. When \ud835\udf06 increases, the average PSNR decreases as a result of the reduction in video bitrate.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n10 2\n10 3\n10 4\nFr am\ne La\nte nc\ny (m\ns)\n=0.2 =0.5 =0.7 =0.99 Average\n(b) Demonstrating the effect of \ud835\udf06 on the latency. Vidaptive has safety guards to control the maximum latency; hence, \ud835\udf06 does not significantly affect the P95 frame latency. However, it reduces other latency measurements as Vidaptive gets more conservative.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n0\n2\n4\n6\n8\n10\nAv er\nag e\nBi tra\nte (M\nbp s)\n=0.2 (Video) =0.2 (Dummy)\n=0.5 (Video) =0.5 (Dummy)\n=0.7 (Video) =0.7 (Dummy)\n=0.99 (Video) =0.99 (Dummy)\n(a) Demonstrating the effect of \ud835\udf06 on the Video and Dummy bitrate. When \ud835\udf06 increases, the optimization problem in Eq. 3 favors a higher frame rate over the video bitrate; hence video bitrate decreases. The total sum of dummy and video traffic remains constant.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nN et\nw or\nk U\ntil iz\nat io\nn\n=0.2 =0.5 =0.7 =0.99 Average\n(b) Instantaneous link utilization distribution for different \ud835\udf06. Vidaptive has an almost identical distribution of instant link utilization because of the decoupling of CCA and video.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n34\n36\n38\n40\n42\n44\n46\nPS N\nR (d\nB)\nCopa Copa+Dummy Copa+Dummy+Latency Vidaptive Average\n(a) Per-frame PSNR statistics comparison of the received video vs. the original video for different system variations.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n10 2\n10 3\n10 4\nFr am\ne La\nte nc\ny (m\ns)\nCopa Copa+Dummy Copa+Dummy+Latency Vidaptive Average\n(b) Per-frame latency statistics comparison of the received video vs. the original video for different system variations. Vidaptive has lower latency percentiles because of the smarter mechanism adjusts the encoder bitrate.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n0\n5\n10\n15\n20\n25\nAv g\nFr am\ne R\nat e\n(fp s)\nGCC Copa Copa+Dummy Copa+Dummy+Latency Vidaptive\n(c) Average frame rate comparison across different system variations. Vidaptive achieves a good frame rate while maintaining the latency.\nFigure 24: Comparison of end-to-end frame statistics of quality of experience metrics for different system variations. Vidaptive gets the best trade-off between latency, PSNR, and frame rate compared to GCC across all the variations. The whiskers are P5 and P95, the interquartile range shows P25, P50, and P75, and the dot shows the average.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n0\n2\n4\n6\n8\nAv er\nag e\nBi tra\nte (M\nbp s)\nCopa Copa+Dummy (Video) Copa+Dummy (Dummy)\nCopa+Dummy+Latency (Video) Copa+Dummy+Latency (Dummy)\nVidaptive (Video) Vidaptive (Dummy)\n(a) Average throughput of Video traffic vs. Dummy traffic for different system variations. Vidaptive obtains the best balance between the video bitrate and link utilization among all the variation.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nN et\nw or\nk U\ntil iz\nat io\nn\nCopa Copa+Dummy Copa+Dummy+Latency Vidaptive Average\n(b) Instantaneous link utilization distribution for all the system variations. All the systems with the dummy traffic have similar link utilization distribution. Adding the dummy traffic to \u201cCopa\u201d increases all the percentiles for the link utilization.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n34\n36\n38\n40\n42\n44\n46\nPS N\nR (d\nB)\n=33 =500 =1000 Average\n(a) Per-frame PSNR statistics comparison for different pacer queue thresholds (\ud835\udf0f). Increasing \ud835\udf0f increases \ud835\udefc in Eq. 3, which increases the video bitrate and quality.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n0\n2\n4\n6\n8\n10\nAv er\nag e\nBi tra\nte (M\nbp s)\n=33 (Video) =33 (Dummy)\n=500 (Video) =500 (Dummy)\n=1000 (Video) =1000 (Dummy)\n(a) Average throughput of Video traffic vs. Dummy traffic for different pacer queue thresholds (\ud835\udf0f). A higher pacer queue threshold increases the frame rate score, increasing the \ud835\udefc and consequently the video bitrate.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nN et\nw or\nk U\ntil iz\nat io\nn\n=33 =500 =1000 Average\n(b) Instantaneous link utilization distribution for different pacer queue thresholds (\ud835\udf0f). Using the dummy traffic, the link utilization is agnostic to the underlying video traffic.\nAL d2\nd\nAL d2\nu\nAL dd\nAL du\nTL dd\nTL du\nTL sd\nTL su\nTU dd\nTU du\nVE dd\nVE du\nVL dd\nVL du\nVL sd\nVL su\nTrace\n10 3\n10 1\n10 1\n10 3\nN et\nw or\nk D\nel ay\n(m s)\n=33 =500 =1000 Average\n(c) In-network queueing delay distribution for different pacer queue thresholds (\ud835\udf0f). Using the dummy traffic, the CCA decisions are independent of the video traffic, so the network delay is agnostic to \ud835\udf0f.\nFigure 27: Comparison of network statistics for different values of \ud835\udf0f. Vidaptive has similar network characteristics and simulates the behavior of a backlogged flow from the network\u2019s perspective. The whiskers are P5 and P95, the interquartile range shows P25, P50, and P75, and the dot shows the average."
        }
    ],
    "title": "Vidaptive: Efficient and Responsive Rate Control for Real-Time Video on Variable Networks",
    "year": 2023
}