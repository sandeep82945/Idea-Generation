{
    "abstractText": "Intravascular Ultrasound (IVUS) is a medical imaging modality widely used for the detection and treatment of coronary heart disease. The detection of vascular structures is extremely important for accurate treatment procedures. Manual detection of lumen and calcification is very time-consuming and requires technical experience. Ultrasound imaging suffers from the generation of artifacts which obstructs the clear delineation among structures. Considering, the need, to provide special attention to crucial areas, convolutional block attention modules (CBAM) is integrated into an encoder-decoder-based U-Net architecture along with Atrous Spatial Pyramid Pooling (ASPP) to detect vessel components: lumen, calcification and shadow borders. The attention modules prove effective in dealing with areas of special attention by assigning additional weights to crucial channels and preserving spatial features. The IVUS data of 12 patients undergoing the treatment is taken for this study. The novelty of the model design is such that it is able to detect the lumen area in the presence/absence of calcification and bifurcation artifacts too. Also, the model efficiently detects the calcification area even in case of severely complex lesions with shadows behind them. The main contribution of the work is that IVUS images of varying degrees of calcification till 360\u00b0 are also considered in this work, which is usually neglected in previous studies. The experimental results of 1097 IVUS images of 12 patients resulted in meanIoU (0.7894 \u00b1 0.011), Dice Coefficient (0.8763 \u00b1 0.070), precision (0.8768 \u00b1 0.069) and recall (0.8774 \u00b1 0.071) of the proposed model CADNet which show the model\u2019s effectiveness relative to other state-of-the art methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Akshay Girdhar"
        }
    ],
    "id": "SP:de760a2f6d7afe447b76016992c46d7edf3b0d0b",
    "references": [
        {
            "authors": [
                "H Ritchie",
                "M Roser"
            ],
            "title": "Causes of death",
            "venue": "Published online at https:// www. OurWo rldIn Data",
            "year": 2018
        },
        {
            "authors": [
                "Hahn J",
                "Honda J-y",
                "Fitzgerald PJ (2013) Intravascular ultrasound BT\u2014catheter-based cardiovascular interventions"
            ],
            "title": "a knowledgebased approach",
            "venue": "Springer, Heidelberg, pp 325\u2013348 784 Physical and Engineering Sciences in Medicine",
            "year": 2023
        },
        {
            "authors": [
                "S Bangalore",
                "DL Bhatt"
            ],
            "title": "Coronary intravascular ultrasound. Circulation 127:868\u2013874",
            "venue": "https:// doi. org/",
            "year": 2013
        },
        {
            "authors": [
                "GW Stone",
                "A Maehara",
                "AJ Lansky"
            ],
            "title": "A prospective natural-history study of coronary atherosclerosis",
            "venue": "N Engl J Med 364:226\u2013235. https:// doi. org/",
            "year": 2011
        },
        {
            "authors": [
                "R Vijayvergiya",
                "A Gupta",
                "G Kasinadhuni"
            ],
            "title": "Intravascular ultrasound supported percutaneous coronary intervention of a large diameter right coronary artery",
            "venue": "IHJ Cardiovasc Case Rep (CVCR) 2:106\u2013107. https:// doi. org/",
            "year": 2018
        },
        {
            "authors": [
                "SY Lee",
                "KH Choi",
                "SY Bin"
            ],
            "title": "Use of intravascular ultrasound and long-term cardiac death or myocardial infarction in patients receiving current generation drug-eluting stents",
            "venue": "Sci Rep 12:8237. https:// doi",
            "year": 2022
        },
        {
            "authors": [
                "KC Koskinas",
                "M Nakamura",
                "L R\u00e4ber"
            ],
            "title": "Current use of intracoronary imaging in interventional practice \u2013 Results of a European Association of Percutaneous Cardiovascular Interventions (EAPCI) and Japanese Association of Cardiovascular Interventions and Therapeutics (CVIT) Clinical Practice Survey. EuroIntervention 14:e475\u2013e484",
            "year": 2018
        },
        {
            "authors": [
                "NR Smilowitz",
                "D Mohananey",
                "L Razzouk"
            ],
            "title": "Impact and trends of intravascular imaging in diagnostic coronary angiography and percutaneous coronary intervention in inpatients in the United States",
            "venue": "Catheter Cardiovasc Interv: Off J Soc Cardiac Angiogr Interv 92:E410\u2013E415. https:// doi",
            "year": 2018
        },
        {
            "authors": [
                "M Vavuranakis",
                "K Toutouzas",
                "C Stefanadis"
            ],
            "title": "Stent deployment in calcified lesions: can we overcome calcific restraint with high-pressure balloon inflations? Catheter Cardiovasc Interv: Off J Soc Cardiac Angiogr Interv 52:164\u2013172",
            "venue": "https:// doi. org/",
            "year": 2001
        },
        {
            "authors": [
                "W Liu",
                "Y Zhang",
                "C-M Yu"
            ],
            "title": "Current understanding of coronary artery calcification",
            "venue": "J Geriatr Cardiol 12:668\u2013675. https:// doi. org/",
            "year": 2015
        },
        {
            "authors": [
                "MB Tayel",
                "MA Massoud",
                "YF Shehata"
            ],
            "title": "An automatic segmentation for determination of IV vessel boundaries",
            "venue": "Int J Biosci, Biochem Bioinform 4:218\u2013223. https:// doi. org/",
            "year": 2014
        },
        {
            "authors": [
                "M Xia",
                "W Yan",
                "Y Huang"
            ],
            "title": "IVUS image segmentation using superpixel-wise fuzzy clustering and level set evolution",
            "venue": "Appl Sci (Switzerland) 9:1\u201318. https:// doi. org/ 10. 3390/",
            "year": 2019
        },
        {
            "authors": [
                "M Faraji",
                "I Cheng",
                "I Naudin",
                "A Basu"
            ],
            "title": "Segmentation of arterial walls in intravascular ultrasound cross-sectional images using extremal region selection. Ultrasonics 84:356\u2013365",
            "venue": "https:// doi. org/ 10. 1016/j. ultras. 2017",
            "year": 2018
        },
        {
            "authors": [
                "E Essa",
                "X Xie"
            ],
            "title": "Automatic segmentation of cross-sectional coronary arterial images. Comput Vis Image Underst 165:97\u2013110",
            "venue": "https:// doi. org/ 10. 1016/j. cviu. 2017",
            "year": 2017
        },
        {
            "authors": [
                "JH Lee",
                "YN Hwang",
                "GY Kim",
                "K Sung Min"
            ],
            "title": "Segmentation of the lumen and media-adventitial borders in intravascular ultrasound images using a geometric deformable model",
            "venue": "IET Image Proc 12:1881\u20131891. https:// doi. org/",
            "year": 2018
        },
        {
            "authors": [
                "J Lee",
                "YN Hwang",
                "GY Kim"
            ],
            "title": "Automated classification of dense calcium tissues in gray-scale intravascular ultrasound images using a deep belief network. BMC Med Imaging 19:1\u201313",
            "venue": "https:// doi",
            "year": 2019
        },
        {
            "authors": [
                "EG Mendizabal-Ruiz",
                "M Rivera",
                "IA Kakadiaris"
            ],
            "title": "Segmentation of the luminal border in intravascular ultrasound B-mode images using a probabilistic approach",
            "venue": "Med Image Anal",
            "year": 2013
        },
        {
            "authors": [
                "D China",
                "MK Nag",
                "KM Mandana"
            ],
            "title": "Automated in vivo delineation of lumen wall using intravascular ultrasound imaging. In: 2016 38th Annual international conference of the IEEE engineering in medicine and biology society (EMBC)",
            "year": 2016
        },
        {
            "authors": [
                "M Szarski",
                "S Chauhan"
            ],
            "title": "Improved real-time segmentation of intravascular ultrasound images using coordinate-aware fully convolutional networks",
            "venue": "Comput Med Imaging Gr 91:101955. https:// doi. org/ 10. 1016/j. compm edimag",
            "year": 2021
        },
        {
            "authors": [
                "L Dong",
                "W Jiang",
                "W Lu"
            ],
            "title": "Automatic segmentation of coronary lumen and external elastic membrane in intravascular ultrasound images using 8-layer U-Net",
            "venue": "Biomed Eng Online 20:1\u201311. https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "S Nandamuri",
                "D China",
                "P Mitra",
                "SUMNet Sheet D (2019)"
            ],
            "title": "Fully convolutional model for fast segmentation of anatomical structures in ultrasound volumes",
            "venue": "2019 IEEE 16th International symposium on biomedical imaging",
            "year": 2019
        },
        {
            "authors": [
                "Y Wang",
                "J Sun",
                "X Gao",
                "H Ye"
            ],
            "title": "Segmentation of intravascular ultrasound images based on convex\u2013concave adjustment in extreme regions",
            "venue": "Vis Comput. https:// doi",
            "year": 2022
        },
        {
            "authors": [
                "G Litjens",
                "T Kooi",
                "BE Bejnordi"
            ],
            "title": "A survey on deep learning in medical image analysis",
            "venue": "Med Image Anal 42:60\u201388. https:// doi. org/ 10",
            "year": 2017
        },
        {
            "authors": [
                "L Alzubaidi",
                "J Zhang",
                "AJ Humaidi"
            ],
            "title": "Review of deep learning: concepts, CNN architectures, challenges, applications, future directions",
            "venue": "J Big Data 8:53. https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "S Aslan",
                "G Ciocca",
                "D Mazzini",
                "R Schettini"
            ],
            "title": "Benchmarking algorithms for food localization and semantic segmentation",
            "venue": "Int J Mach Learn Cybern 11:2827\u20132847. https:// doi. org/ 10",
            "year": 2020
        },
        {
            "authors": [
                "E Shelhamer",
                "J Long",
                "T Darrell"
            ],
            "title": "Fully convolutional networks for semantic segmentation",
            "venue": "IEEE Trans Pattern Anal Mach Intell 39:640\u2013651. https:// doi. org/",
            "year": 2017
        },
        {
            "authors": [
                "J Chowdary",
                "P Yogarajah",
                "P Chaurasia",
                "V Guruviah"
            ],
            "title": "A multi-task learning framework for automated segmentation and classification of breast tumors from ultrasound images. Ultrason Imaging 44:3\u201312",
            "venue": "https:// doi",
            "year": 2022
        },
        {
            "authors": [
                "H Polat"
            ],
            "title": "Multi-task semantic segmentation of CT images for COVID-19 infections using DeepLabV3+ based on dilated residual network",
            "venue": "Phys Eng Sci Med 45:443\u2013455. https:// doi. org/ 10",
            "year": 2022
        },
        {
            "authors": [
                "K Li",
                "J Tong",
                "X Zhu",
                "S Xia"
            ],
            "title": "Automatic lumen border detection in IVUS images using deep learning model and handcrafted features. Ultrason Imaging 43:59\u201373",
            "venue": "https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "S Kim",
                "J Yeonggul",
                "J Byunghwan"
            ],
            "title": "Fully automatic segmentation of coronary arteries based on deep neural network in intravascular ultrasound images. Springer Nature Switzerland AG",
            "year": 2018
        },
        {
            "authors": [
                "F Zhu",
                "Z Gao",
                "C Zhao"
            ],
            "title": "A deep learning-based method to extract lumen and media-adventitia in intravascular ultrasound images. Ultrason Imaging 44:191\u2013203",
            "venue": "https:// doi",
            "year": 2022
        },
        {
            "authors": [
                "F Tian",
                "Y Gao",
                "Z Fang",
                "J Gu"
            ],
            "title": "Automatic coronary artery segmentation algorithm based on deep learning and digital image processing",
            "venue": "Appl Intell 51:8881\u20138895. https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "J Yang",
                "M Faraji",
                "A Basu"
            ],
            "title": "Robust segmentation of arterial walls in intravascular ultrasound images using dual path U-Net. Ultrasonics 96:24\u201333",
            "venue": "https:// doi. org/ 10. 1016/j. ultras. 2019",
            "year": 2019
        },
        {
            "authors": [
                "J Yang",
                "L Tong"
            ],
            "title": "IVUS-Net: an intravascular ultrasound segmentation network. In: Basu ABS (ed) Smart multimedia ICSM 2018 lecture notes in computer science",
            "year": 2018
        },
        {
            "authors": [
                "L Bargsten",
                "S Raschka",
                "A Schlaefer"
            ],
            "title": "Capsule networks for segmentation of small intravascular ultrasound image datasets",
            "venue": "Int J Comput Assist Radiol Surg 16:1243\u20131254. https:// doi. org/ 10",
            "year": 2021
        },
        {
            "authors": [
                "ND Cilia",
                "T D\u2019Alessandro",
                "C De Stefano",
                "F Fontanella"
            ],
            "title": "Deep transfer learning algorithms applied to synthetic 785 Physical and Engineering Sciences in Medicine (2023) 46:773\u2013786 1 3 drawing images as a tool for supporting Alzheimer\u2019s disease",
            "venue": "prediction. Mach Vis Appl 33:49. https:// doi",
            "year": 2022
        },
        {
            "authors": [
                "G Arora",
                "AK Dubey",
                "ZA Jaffery",
                "Rocha"
            ],
            "title": "A (2021) Architecture of an effective convolutional deep neural network for segmentation of skin lesion in dermoscopic images",
            "venue": "Expert Syst. https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "E Goceri"
            ],
            "title": "An application for automated diagnosis of facial dermatological diseases",
            "venue": "I\u0307zmir Katip C\u0327elebi U\u0308niversitesi Sag\u0306l\u0131k Bilimleri Faku\u0308ltesi Dergisi",
            "year": 2021
        },
        {
            "authors": [
                "NK Tomar",
                "D Jha",
                "U Bagci",
                "S Ali"
            ],
            "title": "TGANet: text-guided attention for improved polyp segmentation. Medical image computing and computer assisted intervention",
            "year": 2022
        },
        {
            "authors": [
                "Z Quo",
                "L Zhang",
                "L Lu"
            ],
            "title": "Deep LOGISMOS: deep learning graph-based 3D segmentation of pancreatic tumors on CT scans",
            "venue": "Proc Int Symp Biomed Imaging. https:// doi",
            "year": 2018
        },
        {
            "authors": [
                "A Yadav",
                "A Jain",
                "J Morato Lara",
                "D Yadav"
            ],
            "title": "Retinal blood vessel segmentation using convolutional neural networks. In: Proceedings of the 13th International joint conference on knowledge discovery, knowledge engineering and knowledge management",
            "venue": "SCITEPRESS\u2014Science and Technology Publications,",
            "year": 2021
        },
        {
            "authors": [
                "PF Christ",
                "MEA Elshaer",
                "F Ettlinger"
            ],
            "title": "Automatic liver and lesion segmentation in CT using cascaded fully convolutional neural networks and 3D conditional random fields. Lecture notes in computer science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
            "year": 2016
        },
        {
            "authors": [
                "A BenTaieb",
                "J Kawahara",
                "G Hamarneh"
            ],
            "title": "Multi-loss convolutional networks for gland analysis in microscopy",
            "venue": "IEEE 13th International Symposium on Biomedical Imaging (ISBI)",
            "year": 2016
        },
        {
            "authors": [
                "JM Wolterink",
                "T Leiner",
                "MA Viergever",
                "I I\u0161gum"
            ],
            "title": "Dilated convolutional neural networks for cardiovascular MR segmentation in congenital heart disease",
            "year": 2017
        },
        {
            "authors": [
                "H Shinohara",
                "S Kodera",
                "K Ninomiya"
            ],
            "title": "Automatic detection of vessel structure by deep learning using intravascular ultrasound images of the coronary arteries. PLoS ONE 16:1\u201314",
            "venue": "https:// doi. org/",
            "year": 2021
        },
        {
            "authors": [
                "A Hindi",
                "C Peterson",
                "RG Barr"
            ],
            "title": "Artifacts in diagnostic ultrasound. Rep Med Imaging 6:29\u201348",
            "venue": "https:// doi. org/ 10",
            "year": 2013
        },
        {
            "authors": [
                "L-C Chen",
                "G Papandreou",
                "F Schroff",
                "H Adam"
            ],
            "title": "Rethinking atrous convolution for semantic image segmentation",
            "venue": "http:// arxiv. org/ abs/",
            "year": 2017
        },
        {
            "authors": [
                "Y Saito",
                "Y Kobayashi"
            ],
            "title": "Clinical expert consensus document on intravascular ultrasound from the Japanese association of cardiovascular intervention and therapeutics",
            "venue": "https:// doi",
            "year": 2022
        },
        {
            "authors": [
                "O Ronneberger",
                "P Fischer",
                "T Brox"
            ],
            "title": "U-net: convolutional networks for biomedical image segmentation",
            "venue": "Lecture Notes Comput Sci 9351:234\u2013241. https:// doi",
            "year": 2015
        },
        {
            "authors": [
                "J Ba",
                "V Mnih",
                "K Kavukcuoglu"
            ],
            "title": "Multiple object recognition with visual attention",
            "venue": "http:// arxiv. org/ abs/",
            "year": 2014
        },
        {
            "authors": [
                "V Mnih",
                "N Heess",
                "A Graves",
                "K Kavukcuoglu"
            ],
            "title": "Recurrent Models of Visual Attention",
            "venue": "Proceedings of the 27th International Conference on Neural Information Processing Systems",
            "year": 2014
        },
        {
            "authors": [
                "J Hu",
                "L Shen",
                "G Sun"
            ],
            "title": "IEEE/CVF conference on computer vision and pattern recognition",
            "venue": "Squeeze-and-excitation networks",
            "year": 2018
        },
        {
            "authors": [
                "K Xu",
                "J Ba",
                "R Kiros"
            ],
            "title": "Show, attend and tell: neural image caption generation with visual attention",
            "venue": "https:// doi",
            "year": 2015
        },
        {
            "authors": [
                "K He",
                "X Zhang",
                "S Ren",
                "J Sun"
            ],
            "title": "Spatial pyramid pooling in deep convolutional networks for visual recognition",
            "venue": "IEEE Trans Pattern Anal Mach Intell 37:1904\u20131916. https:// doi. org/",
            "year": 2015
        },
        {
            "authors": [
                "L-C Chen",
                "G Papandreou",
                "I Kokkinos"
            ],
            "title": "DeepLab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs",
            "venue": "IEEE Trans Pattern Anal Mach Intell 40:834\u2013848. https:// doi",
            "year": 2018
        },
        {
            "authors": [
                "F Yu",
                "V Koltun"
            ],
            "title": "Multi-scale context aggregation by dilated convolutions",
            "venue": "4th International conference on learning representations, ICLR 2016\u2014Conference Track Proceedings",
            "year": 2016
        },
        {
            "authors": [
                "DS Kim",
                "YH Kim",
                "KR Park"
            ],
            "title": "Semantic segmentation by multi-scale feature extraction based on grouped dilated convolution module. Mathematics 9:947",
            "venue": "https:// doi. org/ 10. 3390/",
            "year": 2021
        },
        {
            "authors": [
                "P Wang",
                "P Chen",
                "Y Yuan"
            ],
            "title": "Understanding convolution for semantic segmentation",
            "venue": "IEEE winter conference on applications of computer vision,",
            "year": 2018
        },
        {
            "authors": [
                "E Goceri"
            ],
            "title": "Image augmentation for deep learning based lesion classification from skin images. In: 2020 IEEE 4th International conference on image processing, applications and systems (IPAS)",
            "year": 2020
        },
        {
            "authors": [
                "DC Cire\u015fan",
                "U Meier",
                "J Masci"
            ],
            "title": "High-performance neural networks for visual object classification",
            "venue": "http:// arxiv. org/ abs/",
            "year": 2011
        },
        {
            "authors": [
                "D Jha",
                "PH Smedsrud",
                "MA Riegler"
            ],
            "title": "ResUNet++: An advanced architecture for medical image segmentation",
            "venue": "IEEE International symposium on multimedia,",
            "year": 2019
        },
        {
            "authors": [
                "L Bargsten",
                "A Schlaefer"
            ],
            "title": "SpeckleGAN: a generative adversarial network with an adaptive speckle layer to augment limited training data for ultrasound image processing",
            "venue": "Int J Comput Assist Radiol Surg 15:1427\u20131436. https:// doi",
            "year": 2020
        },
        {
            "authors": [
                "J Fan",
                "J Lee",
                "Y Lee"
            ],
            "title": "A transfer learning architecture based on a support vector machine for histopathology image classification",
            "venue": "Appl Sci 11:6380. https:// doi. org/",
            "year": 2021
        },
        {
            "authors": [
                "H Chen",
                "Y Wang",
                "J Shi"
            ],
            "title": "Segmentation of lymph nodes in ultrasound images using U-net convolutional neural networks and gabor-based anisotropic diffusion. Journal of Medical and Biological Engineering 41:942\u2013952",
            "venue": "https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "Z Zhou",
                "MMR Siddiquee",
                "N Tajbakhsh",
                "J Liang"
            ],
            "title": "UNet++: A nested U-net architecture for medical image segmentation. In: deep learning in medical image analysis and multimodal learning for clinical decision support: 4th international workshop, DLMIA 2018, and 8th international workshop, ML-CDS 2018, held in conjunction with MICCAI 2018",
            "year": 2018
        },
        {
            "authors": [
                "Oktay O",
                "Schlemper J",
                "Folgoc L Le",
                "et al (2018) Attention U-net"
            ],
            "title": "learning where to look for the pancreas",
            "venue": "http:// arxiv. org/ abs/ 1804. 03999 786 Physical and Engineering Sciences in Medicine",
            "year": 2023
        },
        {
            "authors": [
                "N Ibtehaz",
                "MS Rahman"
            ],
            "title": "MultiResUNet: rethinking the U-net architecture for multimodal biomedical image segmentation",
            "venue": "Neural Netw 121:74\u201387. https:// doi. org/ 10. 1016/j. neunet. 2019",
            "year": 2020
        },
        {
            "authors": [
                "S Ouyang",
                "Y Li"
            ],
            "title": "Combining deep semantic segmentation network and graph convolutional neural network for semantic segmentation of remote sensing imagery. Remote Sensing 13:1\u201322",
            "venue": "https:// doi. org/ 10. 3390/",
            "year": 2021
        },
        {
            "authors": [
                "C Balakrishna",
                "S Dadashzadeh",
                "S Soltaninejad"
            ],
            "title": "Automatic detection of lumen and media in the IVUS images using U-Net with VGG16 Encoder",
            "venue": "arXiv. https:// doi",
            "year": 2018
        },
        {
            "authors": [
                "H Xiao",
                "Z Ran",
                "S Mabu"
            ],
            "title": "SAUNet+ +: an automatic segmentation model of COVID-19 lesion from CT slices",
            "venue": "Vis Comput. https:// doi",
            "year": 2022
        },
        {
            "authors": [
                "M Mosseri",
                "LF Satler",
                "AD Pichard",
                "R Waksman"
            ],
            "title": "Impact of vessel calcification on outcomes after coronary stenting. Cardiovasc Revascularization Med 6:147\u2013153",
            "venue": "https:// doi. org/ 10. 1016/j. carrev",
            "year": 2005
        },
        {
            "authors": [
                "R Kawaguchi",
                "H Tsurugaya",
                "H Hoshizaki"
            ],
            "title": "Impact of lesion calcification on clinical and angiographic outcome after sirolimus-eluting stent implantation in real-world patients. Cardiovasc Revascularization Med 9:2\u20138",
            "venue": "https:// doi. org/ 10. 1016/j. carrev",
            "year": 2008
        },
        {
            "authors": [
                "M Natalia",
                "T Forero",
                "NM Van Mieghem",
                "J Daemen"
            ],
            "title": "Stent underexpansion due to heavy coronary calcification resistant to rotational atherectomy: a case for coronary lithoplasty? Catheter Cardiovasc Interv. https:// doi",
            "year": 2019
        },
        {
            "authors": [
                "E G\u00f6\u00e7eri"
            ],
            "title": "Convolutional neural network based desktop applications to classify dermatological diseases",
            "year": 2020
        },
        {
            "authors": [
                "E G\u00f6\u00e7eri"
            ],
            "title": "Impact of deep learning and smartphone technologies in dermatology: automated diagnosis. In: 2020 tenth international conference on image processing theory, tools and applications (IPTA)",
            "year": 2020
        },
        {
            "authors": [
                "E Goceri"
            ],
            "title": "Automated skin cancer detection: where we are and the way to the future",
            "year": 2021
        },
        {
            "authors": [
                "E Goceri"
            ],
            "title": "CapsNet topology to classify tumours from brain images and comparative evaluation",
            "venue": "IET Image Proc 14:882\u2013889. https:// doi. org/",
            "year": 2020
        },
        {
            "authors": [
                "E Goceri"
            ],
            "title": "Analysis of capsule networks for image classification. International conference on computer graphics, visualization, computer vision and image processing 2021, CGVCVIP 2021, connected smart cities 2021, CSC 2021 and big data analytics, data mining and computational intelligence 2021, BIGDACI 2021\u2014Held at th 53\u201360",
            "venue": "https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "E Goceri"
            ],
            "title": "Capsule neural networks in classification of skin lesions. International conference on computer graphics, visualization, computer vision and image processing 2021, CGVCVIP 2021, connected smart cities 2021, CSC 2021 and big data analytics, data mining and computational intelligence 2021, BIGDACI 2021\u2014Held at th 29\u201336",
            "venue": "https:// doi. org/",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Vol.:(0123456789)\nKeywords Intravascular Ultrasound (IVUS)\u00a0\u00b7 Calcification\u00a0\u00b7 Lumen\u00a0\u00b7 Shadow\u00a0\u00b7 Atrous Spatial Pyramid Pooling (ASPP)\u00a0\u00b7 Image segmentation\u00a0\u00b7 Convolutional Block Attention Module (CBAM)"
        },
        {
            "heading": "Introduction",
            "text": "Cardiovascular disease is the largest cause of death globally, with coronary atherosclerosis being the primary cause [1]. Coronary artery remodelling slows the progression of vascular stenosis brought on by the accumulation of coronary\nplaque in the early stages of atherosclerosis [2]. Intravascular ultrasound (IVUS) is a real-time medical imaging method that helps doctors diagnose and treat coronary heart disease [3]. The detection of vessel components is extremely important for accurate treatment. This study focuses to segment\n* Priyanka Arora arorapriyanka29@gmail.com\nParminder Singh parminder2u@gmail.com\nAkshay Girdhar akshay1975@gmail.com\nRajesh Vijayvergiya vijayvergiya.rajesh@pgimer.edu.in\nPrince Chaudhary p.chaudhary@live.com\n1 IKG Punjab Technical University, Punjab, India 2 Department of\u00a0Computer Science & Engineering, Guru\nNanak Dev Engineering College, Ludhiana, Punjab, India 3 Department of\u00a0Information Technology, Guru Nanak Dev\nEngineering College, Ludhiana, Punjab, India 4 Department of\u00a0Cardiology, Postgraduate Institute of\u00a0Medical\nEducation and\u00a0Research (PGIMER), Chandigarh, India 5 Business Development Manager, Therapy Awareness Group\n(TAG), Boston Scientific India Private Limited, Gurgaon, India\n1 3\nthe vessel components automatically targeting the complex lesions with varying degrees of calcification till 360\u00b0.\nAs per the findings of the Providing Regional Observations to Study Predictors of Events in the Coronary Tree (PROSPECT) study, lesions with a lumen area less than 4\u00a0 mm2, are a major risk for cardiac arrest [4]. The procedure of percutaneous guided intervention (PCI) is used to treat cardiovascular disease. Studies reveal the importance of IVUS-guided PCI in comparison to angiography-guided PCI for treating large diameter right coronary artery, and longterm effects in case of patients who received drug-eluting stents [5, 6]. Therefore, pre-intervention IVUS is beneficial in a clinical environment to analyse the target lesion and determine the best treatment plan. However, it is still not widely used, mainly due to the extensive expertise and experience required to interpret IVUS images [7, 8].\nIn complex lesions, it\u2019s critical to assess the degree of calcification before stent implantation. As a result, monitoring the target lesion\u2019s location and arc of calcification in IVUS images is critical for avoiding PCI problems and optimizing clinical outcomes. Therefore, this study concentrates on the detection of the lumen area and\ncalcification in IVUS images, considering the complex lesions at hand. Also, Class III, IV calcified lesions (i.e. lesions with > 180\u00b0 arc of calcification) are prone to re-stenosis as compared to less calcified lesions [3, 9, 10]. The segmentation of IVUS arterial borders (lumen and mediaadventitia) was presented as a challenge at MICCAI 2011 conference. Since then, it is highly studied in literature with improvements made till now [12\u201321]. Recent studies depict that deep learning and artificial intelligence aid in improving the outcome of the medical imaging [23\u201325]. For identifying complex structures in medical images, pixel-based semantic segmentation is widely preferred. Every pixel in the image is classified using semantic segmentation into one of the specified classes [26]. In the medical field, deep learning-based methods are frequently used in the diagnosis of breast tumors [27], Covid-19 lung infection [28], coronary segmentation [19\u201321, 29\u2013 35], Alzheimer disease prediction [36], skin lesion segmentation [37], dermatological diseases [38] and polyp segmentation [39] to mention a few. Table\u00a01 depicts various areas of medical image segmentation where deep learning is widely used.\n[41] Yadav et\u00a0al. Diabetic retinopathy: Retina Vessel Segmentation Applied CLAHE with CNN and obtained better results with 0.9806 accuracy\n[42] Christ et\u00a0al. Liver and lesion segmentation Applied cascaded CNN at the first stage and refined the segmentation results using the 3D conditional random fields and obtained Dice score of 94.3%\n[43] BenTaieb et\u00a0al. Colon adenocarcinoma glands Applied multi-loss function as a combination of two losses; one from the classification module and another from the segmentation module\n[44] Wolterink et\u00a0al. Whole heart segmentation Applied CNN with dilated convolutions in cardiac MRI images and obtained Dice Score of 0.80\n[45] Shinohara et\u00a0al. Lumen and Media-Adventitia Segmentation in Coronary Arteries\nApplied U-Net as a multiclass semantic segmentation problem and achieved promising results\n[34] Yang et\u00a0al. Lumen and Media-Adventitia Segmentation in Coronary Arteries\nApplied U-Net model with modifications and achieved better Hausdroff distance (HD)\n1 3\nA system that could classify vascular components in IVUS could help the cardiologists and result in optimizing the PCI procedure. Very few studies that categorize vascular components such as calcification are reported in the literature. Furthermore, ultrasound technology suffers from many artifacts throughout the acquisition process due to its inherent properties [46]. The hard calcium deposits cause the ultrasound signal to backscatter and cast a shadow behind. This shadow results in complete information loss behind the calcification arc. In this study, a deep learning-based system called CADNet (convolutional block attention atrous spatial pyramid pooling network) is designed that can detect the complex lesions with narrowed lumen and severe calcification. Also, this system effectively detects the shadow artifact region behind the calcification.\nThe following are the primary contributions of the work:\n\u2013 U-Net is a preferred encoder-decoder based architecture for biomedical applications. The proposed model integrates the dual attention (spatial and channel-wise), convolutional block attention module (CBAM) [47] and atrous spatial pyramid pooling (ASPP) [48], which extracts the features by giving both channel and spatialwise attention, and not only highlight the significant features but also suppresses the irrelevant features. Additionally, the ASPP module collects context information using dilated convolutions at various sampling rates. \u2013 A special augmentation pipeline is designed employing both noise and spatial augmentations that performs realtime augmentation during training to save heavy memory load. \u2013 The dataset prepared is unique in the form with major concentration towards severely calcified complex lesions, with degree of calcification > 180\u00b0. Also, the images used are corrupted with shadows and bifurcation artifacts. Earlier attempts in the field generally use no artifact images. To detect vessel components in artifact corrupted images is itself very challenging and is the main focus of this study."
        },
        {
            "heading": "Methodology",
            "text": ""
        },
        {
            "heading": "Dataset",
            "text": ""
        },
        {
            "heading": "Patients",
            "text": "Retrospective data of 12 patients who underwent IVUS procedures as a part of their treatment plan is taken for this study. The data is acquired from the Department of Cardiology, Postgraduate Institute of Medical Education and Research (PGIMER), Chandigarh with prior approval from the PGIMER\u2019s Institutional Ethics Committee (IEC) with\nApproval No. INT/IEC/2021/SPL-1285 dated 13.09.2021. Because the data are collected retrospectively, informed consent is not required. The IVUS procedure is performed by an expert cardiologist, with more than 25\u00a0years of experience. The inclusion and exclusion criteria taken for the study are thoroughly discussed and approved by the IEC. The inclusion criteria taken is as patients diagnosed with coronary artery disease undergoing IVUS examination. The exclusion criteria are (i) patients who had already undergone stent implantation earlier, (ii) patients with bypass grafting and (iii) poor-quality images."
        },
        {
            "heading": "IVUS image acquisition",
            "text": "The IVUS procedure is carried out using the Boston Scientific Polaris Multi-modality system equipped with OptiCross\u2122 IVUS Catheter of 40\u00a0MHz transducer frequency. The acquisition is done at a pullback speed of 0.5\u00a0mm/s. The output images are in Digital Imaging and Communications in Medicine (DICOM) video format having a pixel size of 512 \u00d7 512."
        },
        {
            "heading": "Preparation of\u00a0IVUS image sets",
            "text": "A typical IVUS pullback generates approximately 1000\u20134000 IVUS frames. The frames are carefully selected by the experts taking into account the variability in the IVUS frames from the four segments, including the ostium, proximal, mid, and distal end of the artery. The experts avoided the adjacent frames as they appear similar to each other and may lead to wrong results. After careful analysis, typically 102 \u00b1 14 frames from each pullback of a patient are selected by the cardiologist for labelling. In the first step, manual labelling is carried out to categorize the vascular components: lumen, calcification and shadows using the non-commercial software LabelMe [49]. Every selected IVUS image is labelled into one of the classes, such that every class has a unique color. The lumen, calcification and shadows are colored yellow, red and green respectively. In the next step, the manual labelling is discussed with two more experts and corrections are made and the consensus is achieved. As a result, the mask images corresponding to these three classes are created for training the deep learning model as shown in Fig.\u00a01. Area enclosed by the luminal border is defined as the lumen area [50]. The calcification area is defined as the bright echo region which causes acoustic shadows [50]. Class III, IV was regarded as a highly calcified region with the calcification arc spanning > 180\u00b0. The areas with no annotation, are considered background. In total, 1097 IVUS images are manually segmented by the experts.\n1 3"
        },
        {
            "heading": "The CADNet model",
            "text": "The popular semantic segmentation model U-Net developed by Ronneberger [51] is employed as a base to construct the CADNet model to distinguish vessel components from IVUS cross-sectional images. The proposed CADNet architecture takes advantage of both the channel and spatial attention blocks and dilated convolutions. The original U-Net employs four encoding and decoding layers with four skip connections to integrate the feature maps [51]. To improve the capability of U-Net, CBAM modules are added to each encoder and decoder blocks to provide special channel and spatial attention to the complex lesions, and dilated convolutions of ASPP modules act as the bridge between encoder and decoder. Table\u00a02 describes the architectural details, Table\u00a03 describes the parameters employed for the CADNet model and the complete architecture is depicted in Fig.\u00a04. The system was trained using Google Colab Pro with a P100 graphics processing unit\nand 25\u00a0GB of RAM. All models used for comparison are trained with the same set of hyperparameters, a batch size of 4, a learning rate of 1e-4, and Adam optimizer. To avoid the model\u2019s overfitting, an early stopping criterion and ReduceLROnPlateau are employed.\nThe model is implemented in the TensorFlow library of Python. The hyperparameters employed are chosen empirically taking into consideration the underfitting and overfitting of the network. The training/test split is done randomly, i.e. the network splits the dataset into separate training and test datasets. The ratio chosen for the split is such that 80% of the images are used for training and 20% of the images in the dataset are used for testing. As the model detects three vessel components: lumen, calcification and shadows, the softmax activation function is used in the network as given by Eq.\u00a01\nFig. 1 Sample raw IVUS images and corresponding masks. Upper Panel images (A) shows Lumen Area with no calcification, (B) shows Lumen Area with no calcification in the presence of bifurcation, (C) shows Lumen with calcification less than 180\u00b0, and (D) shows Lumen Area with severe calcification greater than 180\u00b0 and casting\ndense shadows. Lower Panel Images E\u2013H shows the corresponding manually segmented masks. The yellow, red, green, and black regions show the lumen, calcification, shadows and background areas respectively\nTable 2 Architectural design details of CADNet model employed\nEncoder details Output details Decoder details Output details\nInput 512 \u00d7 512 \u00d7 1 Dec_block_1 64 \u00d7 64 \u00d7 256 Enc_block_1 512 \u00d7 512 \u00d7 32 Dec_block_2 128 \u00d7 128 \u00d7 128 Enc_block_2 256 \u00d7 256 \u00d7 64 Dec_block_3 256 \u00d7 256 \u00d7 64 Enc_block_3 128 \u00d7 128 \u00d7 128 Dec_block_4 512 \u00d7 512 \u00d7 32 Enc_block_4 64 \u00d7 64 \u00d7 256 Output 512 \u00d7 512 \u00d7 4 Bridge (ASPP) 32 \u00d7 32 \u00d7 512\n1 3\nwhere, denotes the softmax function, \ufffd\u20d7x denotes the input vector, exi denotes the standard exponential function for the given input vector, K defines the number of classes in the multi-class problem (K = 4 in this work), and exj denotes the standard exponential function for output vector."
        },
        {
            "heading": "CBAM",
            "text": "The feature map utilization and the importance of the attention mechanism are illustrated in studies [52\u201355]. In addition to directing where to focus, attention enhances the depiction of interests. The Squeeze and Excitation block (SER) [54] enforces channel-wise attention but ignores spatial attention. However, spatial attention also has a substantial impact on the focus areas. The dual attention CBAM module given an intermediate feature map, extracts the features by paying special attention to more important areas both channel and spatial wise. The CBAM module employed in the proposed network utilizes a transitional feature map F \u2208 \u211dC\u00d7H\u00d7W and performs 1D channel attention Ac\u2208 \u211dC\u00d71\u00d71 followed by 2D spatial attention As \u2208 \u211d1\u00d7H\u00d7W . The complete process is shown in Fig.\u00a02.\nThe channel attention module used is implemented by average and max pooling and C \u00d7 1 \u00d7 1 feature map is obtained which is given by Eq.\u00a02\nThe spatial attention module is as given by Eq.\u00a03\nThe complete attention process can be summed up by Eq.\u00a04:\nwhere, denotes the sigmoid function, \u2297 denotes the element-wise multiplication and f 7\u00d77 denotes a convolution operation with a 7 \u00d7 7 filter size.\n(1)\ud835\udf0e \ufffd \ufffd\u20d7x \ufffd i = exi \u2211K\nj=1 exj\n(2)Ac(F) = (MLP(AvgPool(F)) + (MLP(MaxPool(F)))\n(3)As = (f 7\u00d77 ([ AvgPool(F);MaxPool(F) ]) )\n(4)F \ufffd = Ac(F)\u2297 F,F \ufffd\ufffd = As ( F\ufffd ) \u2297 F\ufffd,"
        },
        {
            "heading": "ASPP",
            "text": "The concept of ASPP is inspired by spatial pyramidal pooling, which is effective in resampling features at various scales. In ASPP, the input feature map is subjected to numerous parallel atrous convolutions at varying rates, all of which are fused to capture contextual information at multiple scales. For precisely capturing information on several scales, dilated convolution enables field-of-view control [56, 57]. Convolutional and pooling layers in combination can increase the receptive field of an image without the need for extra parameters, however, pooling operations reduce the size of the image and obliterate its intricacies in the process. Therefore, upsampling cannot fully restore the spatial information [58]. When atrous convolution is utilised, just a portion of the receptive field's pixels is used for convolution, which is the same as creating holes in the convolution kernel. As a result, atrous convolution can regulate the resolution of feature maps and enlarge the receptive field without sacrificing the information [48, 58\u201360]. The ASPP module with varying dilation rates is depicted in Fig.\u00a03.\nThe proposed design of CADNet uses ASPP as a bridge between the encoder and the decoder, as shown in Fig.\u00a04. With its multi-scale information, the ASPP model has demonstrated excellent performance on a number of segmentation tasks. For the purpose of IVUS segmentation in this work, we, therefore, use ASPP to collect the pertinent multiscale data."
        },
        {
            "heading": "Data augmentation",
            "text": "A deep learning model needs a significant amount of data to be trained effectively. Due to the scarcity of a limited amount of annotated data in the case of biomedical imaging, data augmentation is preferred [61]. Various augmentation (operation) types have been investigated in the literature to create fresh training images: When analysing visual documents, elastic distortions are used [62]; other examples include scaling, translation, shearing, flipping, and rotation transformations [19, 20, 27, 39, 51, 63\u201366]. However, not every augmentation operation will be useful in medical settings. In actuality, the application heavily influences the kind of medical image\nFig. 2 The convolutional block attention module (CBAM)\n1 3\naugmentation (transformation). Thus, doing repeated augmentation lengthens training without delivering discernible accuracy gains. As an example, since the catheter is always in the middle of the IVUS images, translating the IVUS frames, for instance, does not sound logical. Therefore, the model will never show an IVUS frame with a catheter, not in the centre. However, most of the studies consider rotation (by varying degrees of 90, 180, 270) and flipping (horizontal and vertical) as the augmentation strategy, which is logical as the catheter is rotated inside the vessel [33]. Also, the augmentation applied in various studies is performed offline which increases disk space requirement. To cater for this scenario, a unique data augmentation pipeline is applied in real-time during the training process on the training set only to save disk space. The augmentation pipeline applies noise augmentation (Gaussian Noise(with sigma = 0.0 to 3.0) OR Salt & Pepper Noise (with sigma = 0.1) OR Speckle Noise (with sigma = 2)) and spatial augmentation (rotation and flipping) at random on a training batch which saves the memory load, thereby enhancing the model\u2019s performance. The probable reason for choosing noise augmentation is that ultrasound images are easily corrupted by noises. The data augmentation pipeline operations applied are depicted in Table\u00a04."
        },
        {
            "heading": "Outcome measures and\u00a0statistics",
            "text": "Metrics like Dice coefficient, Intersection Over Union (IoU), Precision and Recall are calculated in order to assess the model's effectiveness. The main contribution of the model is its\u2019 ability to detect complex areas of calcification and narrowed lumen area in case of severely calcified IVUS images. The metrics used are defined by Eqs.\u00a0(5) and (9)\n(5)DiceCoefficient = 2TP\n2TP + FP + FN\nTP = True Positive, FP = False Positive, TN = True Negative, FN = False Negative.\nThe metrics IoU, Dice coefficient, Precision and Recall are calculated to assess the correlation among the groundtruth images (i.e. the images that are segmented manually) and the predicted images by the system. All the parameters are in the range of 0\u20131. A value close to 1 depicts better segmentation performance."
        },
        {
            "heading": "Results",
            "text": "In this work, a total of 1097 images are manually labelled by expert cardiologists. Out of the total 1097 IVUS images, 877 images are utilized for training while 220 images are used for testing. Figure\u00a05 displays the visual results obtained for the predicted masks using the CADNet model and other state-of-the-art models while Tables\u00a05 and 6 present the results obtained for various performance metrics for the train and the test sets.\nThe meanIoU and Dice Coefficient values obtained for the test set are 0.78941and 0.87633 respectively as given in Table\u00a05. The IoUs obtained for individual vessel\n(6)IoU = TP\nTP + FP + FN\n(7)meanIoU = 1\nn\nn \u2211\ni=1\nIoUi\n(8)Precision = TP\nTP + FP\n(9)Recall = TP\nTP + FN\n1 3\ncomponents lumen, calcification and shadows are 0.93735, 0.80248 and 0.78968 respectively as given in Table\u00a06.\nThe loss functions obtained for the different models are as depicted in Fig.\u00a06."
        },
        {
            "heading": "Ablation study",
            "text": "In order to ensure each component\u2019s efficiency in the proposed model CADNET, multiple experiments are conducted\nTable 4 Data augmentation pipeline\nOnline data augmentation pipeline\nNoise augmentation Gaussian_noise (with sigma = 0.0 to 3.0) OR salt&pepper (with sigma = 0.1) OR speckle (with sigma = 2) Spatial augmentation Rotation (90, 180 or 270) AND\nFlipping (Horizontal or Vertical)\n1 3\non the IVUS dataset. The comparison is made with the baseline U-Net, and additions of modules CBAM and ASPP respectively. The quantitative outcomes of the ablation experiments are given in Table\u00a07 and the visual comparison\nis given in Fig.\u00a07. For the first experiment, the IVUS dataset of 1097 images is tested with the baseline UNET model which has 0.65275 IoU and 0.71559 Dice Coefficient; in the second experiment, the bridge of the baseline is replaced\nFig. 5 Sample predicted masks by various models. (Right to Left) The rightmost column panel shows the input IVUS images followed by ground truth masks predicted for lumen (yellow), calcification (red) and shadow (green) by U-Net, UNet + + , Attention UNet, AttResUnet, MultiResUnet, and the proposed CADNet deep learning-based models The top row (A) image shows the predicted mask of the lumen of a healthy IVUS image, row (B, C) shows the predicted masks in case of calcification and shadow for mild calci-\nfication < 180\u00b0, row (D, E) shows the predicted masks of lumen, calcification and shadow in case of severe calcification casting dense shadows and bifurcations, row (F) shows the predicted masks of lumen, calcification and shadow in case of dense calcification of > 180\u00b0 casting dense shadows and the last row (G) shows the predicted mask for lumen, calcification and shadow in case of 360\u00b0 calcification\n1 3\nwith ASPP module which gives an improvement in the prediction of the mask, but still needs better results. Another third experiment involves the addition of the CBAM to the baseline U-Net model, to give more weight to the important features and suppress the irrelevant ones. By introducing the\nCBAM block, an improvement of 10.2 and 17.17% is seen for IoU and dice coefficient respectively.\nIn the last experiment, the two components CBAM and ASPP are combined with the baseline U-Net model, to give the proposed CADNet model, which gave the highest IoU (0.78941), Dice Coefficient (0.87633), Precision (0.87683) and Recall (0.87743) with an improvement of 21%, 22.5%, 17.43% and 25.38% for IoU, Dice coefficient, precision and recall respectively than the baseline U-Net model."
        },
        {
            "heading": "Discussion",
            "text": "The main findings of this study are (1) the ability to detect lumen in the presence of severe calcification, (2) lumen area predicted by the system shows compatible results with manually segmented images, (3) detect the severely calcified regions, and (4) detecting the shadow area behind the calcification. Earlier works concentrate on the detection of lumen and media borders but in this work, the complex calcification region is also detected along with the most misleading shadow artifact. As it is clear from the results, there is an improvement of 21%, 22.4%, 17.4% and 25.4% in meanIoU, Dice Coefficient, Precision and Recall values by the proposed model CADNet as compared with the base model U-Net. Further, improvement is seen by 7.7% in IoU for the lumen area which is promising considering the complexity of the dataset. Earlier works reported, detect vessel lumen and media regions in the absence of calcification. So, a system should be capable of detecting the vessel components in complex lesions/segments. Many papers in the literature that use deep neural nets for IVUS lumen and media boundary segmentation use datasets without calcification [33, 71]. The dataset used in this study differs from earlier studies in that it contains significant calcified lesions and shadows, i.e. most of the IVUS images are corrupted by the misleading shadow artifact. It has been stated in studies that IVUS images corrupted with artifacts are more difficult to segment than those without artifacts [71]. Considering these circumstances, the obtained IoU of the vessel components is equivalent to other studies.\nThe meanIoU obtained as the average of the IoU over each individual class (vessel component in this case) in the test set is just 0.78941. This occurred due to the low IoU of the shadow region where there occurs complete information loss and the system classifies part of the black shadow region as background only. Although, for detecting complex structures, pixel-based semantic segmentation is preferred nowadays. The U-Net architecture developed, is the first model for biomedical image segmentation. Most of the medical imaging tasks apply encoder-decoder based architectures for the segmentation of complex structures [27, 42, 51, 66, 71, 72]. For detecting the vessel components in IVUS images,\nIoU \u00a0U-Net [51] 0.8154 \u00b1 0.023 0.3025 \u00b1 0.197 0.3672 \u00b1 0.175 \u00a0UNet + + [67] 0.7665 \u00b1 0.028 0.4783 \u00b1 0.100 0.4876 \u00b1 0.057 \u00a0Attention U-Net\n[68] 0.8101 \u00b1 0.038 0.5230 \u00b1 0.101 0.3637 \u00b1 0.069\n\u00a0MultiResUNet [69]\n0.8768 \u00b1 0.0508 0.3965 \u00b1 0.083 0.4515 \u00b1 0.071\n\u00a0AttResUnet [70]\n0.8289 \u00b1 0.036 0.5026 \u00b1 0.165 0.5968 \u00b1 0.098\n\u00a0CADNet (Proposed) 0.87822 \u00b1 0.062 0.6254 \u00b1 0.011 0.7052 \u00b1 0.007\nDice Coefficient \u00a0U-Net [51] 0.8959 \u00b1 0.014 0.3917 \u00b1 0.127 0.4581 \u00b1 0.105 \u00a0UNet + + [67] 0.8678 \u00b1 0.018 0.6471 \u00b1 0.014 0.6555 \u00b1 0.013 \u00a0Attention U-Net\n[68] 0.9335 \u00b1 0.037 0.4942 \u00b1 0.044 0.5290 \u00b1 0.049\n\u00a0MultiResUNet [69]\n0.9324 \u00b1 0.029 0.4739 \u00b1 0.053 0.5189 \u00b1 0.039\n\u00a0AttResUnet [70]\n0.9295 \u00b1 0.031 0.4844 \u00b1 0.055 0.4985 \u00b1 0.038\n\u00a0CADNet (Proposed)\n0.9320 \u00b1 0.036 0.7695 \u00b1 0.003 0.8271 \u00b1 0.007\nPrecision \u00a0U-Net [51] 0.9180 \u00b1 0.018 0.4893 \u00b1 0.018 0.5398 \u00b1 0.005 \u00a0UNet + + [67] 0.8386 \u00b1 0.022 0.7462 \u00b1 0.050 0.8320 \u00b1 0.039 \u00a0Attention U-Net\n[68] 0.9308 \u00b1 0.042 0.5161 \u00b1 0.043 0.5539 \u00b1 0.024\n\u00a0MultiResUNet [69]\n0.9154 \u00b1 0.030 0.5401 \u00b1 0.025 0.5552 \u00b1 0.014\n\u00a0AttResUnet [70]\n0.9235 \u00b1 0.041 0.5132 \u00b1 0.012 0.5479 \u00b1 0.014\n\u00a0CADNet (Proposed)\n0.9269 \u00b1 0.020 0.7392 \u00b1 0.004 0.8683 \u00b1 0.003\nRecall \u00a0U-Net [51] 0.8837 \u00b1 0.012 0.3554 \u00b1 0.026 0.4107 \u00b1 0.014 \u00a0UNet + + [67] 0.8992 \u00b1 0.028 0.5713 \u00b1 0.040 0.5408 \u00b1 0.051 \u00a0Attention U-Net\n[68] 0.9415 \u00b1 0.024 0.4861 \u00b1 0.054 0.5178 \u00b1 0.045\n\u00a0MultiResUNet [69]\n0.9556 \u00b1 0.030 0.4427 \u00b1 0.064 0.5026 \u00b1 0.049\n\u00a0AttResUnet [70]\n0.9417 \u00b1 0.030 0.4758 \u00b1 0.062 0.4685 \u00b1 0.073\n\u00a0CADNet (Proposed)\n0.9373 \u00b1 0.008 0.8025 \u00b1 0.015 0.7897 \u00b1 0.008\n1 3\nFig. 7 Ablation study experiments visual results\n1 3\nwe prefer to enhance the capability of the encoder-decoder based U-Net architecture with additions of a lightweight attention mechanism (to give more focus to crucial areas) and dilated convolutions (to extract multi-scale features with varying dilation rates of {1, 6, 12, 18}). The channel and spatial-wise attention modules are used twice in the case of the decoder, to enhance the attention towards the extracted features and suppress the irrelevant features. The comprehensive comparison among other different cuttingedge models for semantic segmentation such as the base model UNet, UNet + + , Attention UNet, AttResUnet and MultiResUnet shows that the proposed model CADNet is better for detecting the vessel lumen, calcification and shadow areas. The results depicted in Tables\u00a05 and 6 prove the efficacy of the proposed model. The PCI procedure is generally performed on complex lesions with severe calcification. To further prove the efficacy of the model and the components, an ablation study is done, which verifies the effectiveness of each component. Also, the addition of certain pre-processing and post-processing methods could improve the results. However, other object detection models such as YOLO prove effective for the detection of objects but the semantic segmentation approach classifies each object based on the pixels into the respective classes. As per earlier findings, the lesions corrupted with severe calcification possess substantially more chances of restenosis and stent underexpansion in comparison to simple lesions [73\u201375]. Therefore, the system must take the complex lesions into consideration, while detecting lumen or media borders. The ground truth developed in this study is such that, it considers the detection of vessel components in the presence of calcification, shadows and bifurcations. Consequently, the model developed in this study is capable of detecting lumen in the presence of calcification, bifurcations and shadows with an IoU of 0.87. As a result, future IVUS applications may be tailored to facilitate the interpretation of vascular components in complex lesions. In recent years, CNN-based networks have become popular and are used in various tasks [76\u201378]. But they suffer from the disadvantage of losing spatial relationships among features, therefore, in the future capsule networks can be considered for the design of IVUS segmentation and classification tasks [79\u201381].\nHowever, the study has the following limitations which could be addressed in future. First, due to the fact that this was a single-center retrospective study, selection bias cannot be ruled out. Second, the IVUS images taken for consideration are of one frequency only i.e. 40\u00a0MHz. Third, it is time-consuming and laborious to manually segment the vessel components, which limits the availability of a greater number of images. Since, deep learning systems require a large number of images for training, the limited number of IVUS images available along with ground truth should be increased in future. Also, more focus shall be, towards the\ndesign of a more robust system for IVUS images acquired at varied frequencies."
        },
        {
            "heading": "Conclusion",
            "text": "The detection of vessel components in IVUS images has always remained a challenging task. Identifying the lumen and media borders has been a focus of the research community. But most of the studies consider the segmentation of borders in simple lesions i.e. vessels without calcification. However, limited work has been reported for severely calcified lesions. With the application of deep learning in medical images, there has been great improvement in the field. In this study, a deep learning-based system is designed to detect the lumen area in the presence/absence of calcification along with the shadows behind them in close proximity to the manually segmented images. The dataset is prepared such that the complex lesions are given much attention. Therefore, it can be concluded that with the application of deep learning methods, it is possible to detect complex vascular structures. The experimental results obtained as compared to the other methods prove the effectiveness of the proposed method.\nAcknowledgements The authors would like to acknowledge Guru Nanak Dev Engineering College, Ludhiana, Punjab (India) and IKG Punjab Technical University, Kapurthala, Punjab (India) for their support in this research work. Also, the authors sincerely thank PGIMER, Chandigarh (India) for providing the real IVUS dataset. A special thanks to Dr. Debarghya China, Postdoctoral Fellow, Johns Hopkins University, Baltimore (United States) for his expert guidance and timely response in answering our technical queries.\nFunding No funding was received for conducting this study.\nData availability Since the data contains patient information, it is not available publicly. However, the code implementation shall be available to fellow researchers from the corresponding author upon reasonable request."
        },
        {
            "heading": "Declarations",
            "text": "Competing interest The authors declare that they have no conflict of interest.\nInformed consent Since the study was performed on retrospective data of patients so no informed consent was required from participants."
        }
    ],
    "title": "CADNet: an advanced architecture for automatic detection of coronary artery calcification and shadow border in intravascular ultrasound (IVUS) images",
    "year": 2023
}