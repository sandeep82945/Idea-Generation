 Among those, GOP size is a structural factor, which forbid immediate viewportdependent content selection on non-I-frames. Without layered bitstream structure like that in the paper, server will have to wait for next I-frame to respond viewport change and it will cost the time about half of GOP size on average. For example, if GOP size is 10 and FPS (frames per second) is 30, latency caused by GOP size will be 167ms. Although this latency
can be reduced by a separate track with short GOP size (e.g., using GOP size 3 or 5), such track will increase drastically the bitrate and encoding complexity. v. experiments  a. environment setup We extended the AV1 codec of Alliance for Open Media (AOM) to implement this schema and made comparisons with existing approaches for 360-degree videos. While the new coding schema can achieve instant viewport change and much more advanced than existing approaches (as shown in section 3.1), we would like to further evaluate this new coding schema in two aspects: (1) quality with the same bitrate; (2) encoding time/speed. An Intel Xeon E5-8280 CPU and 192GB memories are used to handle 8K and 4K video encoding. Three 30fps 8K and 4K 360-degree video clips (in Table I) are used in experiments; ERP screenshots are presented in Fig. 12. The encoding parameters are set as the following: cpu-used=7, passes=1, threads=20, end-usage=CBR and real-time mode. Each case will be tested three times and the average of all the experimental results are used. b. bitrate and quality In industry, the 360-degree video solution usually includes two or three streams, e.g., one high resolution track with long GOP size for long time view, one low resolution track with long GOP size as background and one high resolution with short GOP size for viewport switch. To make the evaluation meaningful, we compare PSNR of two methods in selected
video clips. For existing solution, the PSNR is the average of two high resolution tracks and the scalable ratio is 2.0x, which means the low quality video is half the width and height of the original video. In Fig. 10 & 11, method A and B are common three-track methods stated as above, and the long GOP size is 30 and the short GOP size is 5 and 3, respectively. The new SVC-based coding schema includes two structures in Fig. 6: enhancement layer refers only one frame and multiple frames of base layer (denoted as “SVC”and “SVC refs”respectively in Fig. 10 & 11). Fig. 10 shows that SVC-based and three-track method can achieve a similar quality per bitrate. Our method is limited better or worse than the other solution in specific scene or video content. Besides, it is worthy to note that PSNR value can be improved by about 0.5-1dB because of the SVC structure in Fig. 6(b). On the other hand, the transport bitrate is also one of the factors we should consider. According to the previous discussion, our scheme can reduce the latency to one-frame time. If the existing method that wants to reduce the latency to one frame as well, it needs to transport the full picture or at least provide enough margin depending on the specified scene like [17]. Here we do not discuss the transmission strategy for specific video scenes, because our approach requires the only about 1/6 of enhanced layers and simplify the adjustment of the strategy accordingly, which means considerable savings in bitstream. c. encoding time We consider the encoding time of each method in different encoding bitrates. The result is recorded from the time command in Linux system and the result equals to the sum of user time and system time. The performance between SVC-based and existing threetrack method is shown in Fig. 11. According to the results, the actual encoding time of new SVC-based coding schema is significantly less (>30%) than three-track method in the same bitrate, which implies using SVC can reduce a considerable encoding cost in multi-rate (or multi-resolution) use cases. vi. conclusions The viewport-dependent streaming becomes necessary for 360-degree videos (and VR content). But the temporal dependency used in modern video codecs makes viewport switch latency correlated to the GOP size - difficult to achieve instant viewport change which is critical for user experiences. In this paper, an SVC-based and tiled-based video coding structure is proposed to resolve the viewport switch challenge and it can reduce interactive latency to one frame time - the best possible time. Secondly, by using tiles in SVC layers, it circumvents the issue of packing the non-adjacent regions, which is a common geometry challenge in non-planar contents, such as 360-degree videos or VR. Furthermore, compared with existing industry approaches, this new coding schema can save encoding cost significantly, while achieving a similar PSNR result in same bitrate. In our experiments, 2x spatial scale factor is used between the base layer and enhanced layer, because SVC usually needs a smaller scale factor for better quality [18]. Depending on video contents, AV1 SVC encoding may present different quality metrics compared with conventional single layer encoding, but the gap (PSNR) is acceptable in our case - even in the worst case, PSNR gap is less than 1dB (typically 0.5dB). This work paves the way for the most efficient viewport-dependent streaming of 360-degree videos, in terms of interactive latency, coding performance, and architecture.