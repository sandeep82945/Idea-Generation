{
    "abstractText": "Failure of facial recognition and authentication system may lead to several unlawful activities. The current facial recognition systems are vulnerable to different biometric attacks. This research focuses on morphing attack detection. The research proposes a robust detection mechanism that can deal with variation in age, illumination, eye and head gears. A deep learning based feature extractor along with a classifier is adopted. Additionally, image enhancement and feature combination are proposed to augment the detection results. A versatile dataset is also developed that contains Morph-2 and Morph-3 images, created by sophisticated tools with manual intervention. Morph-3 images can give more realistic appearance and hence difficult to detect. Moreover, Morph-3 images are not considered in the literature before. Professional morphing software depicts more realistic morph attack scenario as compared to the morphs generated in the previous work from free programs and code scripts. Eight face databases are used for creation of morphs to encompass the variation. These databases are Celebrity2000, Extended Yale, FEI, FGNET, GT-DB, MULTI-PIE, FERET, FRLL. Results are investigated using multiple experimental setups and it is concluded that the proposed methodology gives promising results. INDEX TERMS Morphing attack detection, fraudulent and forged digital identity documents, biometrics, facial recognition, access control.",
    "authors": [
        {
            "affiliations": [],
            "name": "Muhammad Hamza"
        },
        {
            "affiliations": [],
            "name": "Samabia Tehsin"
        },
        {
            "affiliations": [],
            "name": "Hanen Karamti"
        },
        {
            "affiliations": [],
            "name": "Norah Saleh Alghamdi"
        }
    ],
    "id": "SP:7b920268d137fbce25bb9ebf9e31543306b2b0f9",
    "references": [
        {
            "authors": [
                "F. Peng",
                "L.-B. Zhang",
                "M. Long"
            ],
            "title": "Fd-gan: Face de-morphing generative adversarial network for restoring accomplice\u2019s facial image",
            "venue": "IEEE Access, vol. 7, pp. 75122\u201375131, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Ferrara",
                "A. Franco",
                "D. Maltoni"
            ],
            "title": "Face demorphing",
            "venue": "IEEE Transactions on Information Forensics and Security, vol. 13, no. 4, pp. 1008\u20131017, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "U. Scherhag",
                "C. Rathgeb",
                "J. Merkle",
                "R. Breithaupt",
                "C. Busch"
            ],
            "title": "Face recognition systems under morphing attacks: A survey",
            "venue": "IEEE Access, vol. 7, pp. 23012\u2013 23026, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A.W. Yip",
                "P. Sinha"
            ],
            "title": "Contribution of colour to face recognition",
            "venue": "Perception, vol. 31, no. 8, pp. 995\u20131003, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "U. Scherhag",
                "C. Rathgeb",
                "J. Merkle",
                "C. Busch"
            ],
            "title": "Deep face representations for differential morphing attack detection",
            "venue": "IEEE Transactions on Information Forensics and Security, vol. 15, pp. 3625\u2013 3639, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "K. Panetta",
                "Q. Wan",
                "S. Agaian",
                "S. Rajeev",
                "S. Kamath",
                "R. Rajendran",
                "S.P. Rao",
                "A. Kaszowska",
                "H.A. Taylor",
                "A. Samani"
            ],
            "title": "A comprehensive database for benchmarking imaging systems",
            "venue": "IEEE transactions on pattern analysis and machine intelligence, vol. 42, no. 3, pp. 509\u2013520, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "G. Wolberg"
            ],
            "title": "Image morphing: a survey",
            "venue": "The visual computer, vol. 14, no. 8, pp. 360\u2013372, 1998.",
            "year": 1998
        },
        {
            "authors": [
                "D.B. Smythe"
            ],
            "title": "A two-pass mesh warping algorithm for object transformation and image interpolation",
            "venue": "Rapport technique, vol. 1030, p. 31, 1990.",
            "year": 1990
        },
        {
            "authors": [
                "T. Beier",
                "S. Neely"
            ],
            "title": "Feature-based image metamorphosis",
            "venue": "ACM SIGGRAPH computer graphics, vol. 26, no. 2, pp. 35\u201342, 1992.",
            "year": 1992
        },
        {
            "authors": [
                "J. Kannala",
                "E. Rahtu"
            ],
            "title": "Bsif: Binarized statistical image features",
            "venue": "Proceedings of the 21st international conference on pattern recognition (ICPR2012), pp. 1363\u20131366, IEEE, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "D. Ortega-Delcampo",
                "C. Conde",
                "D. Palacios-Alonso",
                "E. Cabello"
            ],
            "title": "Border control morphing attack detection with a convolutional neural This article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2022.3188668 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME XX, 2017 9 network de-morphing approach",
            "venue": "IEEE Access, vol. 8, pp. 92301\u201392313, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C. Seibold",
                "W. Samek",
                "A. Hilsmann",
                "P. Eisert"
            ],
            "title": "Accurate and robust neural networks for face morphing attack detection",
            "venue": "Journal of Information Security and Applications, vol. 53, p. 102526, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "K. Raja",
                "S. Venkatesh",
                "R. Christoph Busch"
            ],
            "title": "Transferable deepcnn features for detecting digital and print-scanned morphed face images",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 10\u201318, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "S. Venkatesh",
                "R. Ramachandra",
                "K. Raja",
                "L. Spreeuwers",
                "R. Veldhuis",
                "C. Busch"
            ],
            "title": "Detecting morphed face attacks using residual noise from deep multi-scale context aggregation network",
            "venue": "Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 280\u2013289, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "R. Raghavendra",
                "K.B. Raja",
                "C. Busch"
            ],
            "title": "Detecting morphed face images",
            "venue": "2016 IEEE 8th International Conference on Biometrics Theory, Applications and Systems (BTAS), pp. 1\u20137, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L. Qin",
                "F. Peng",
                "S. Venkatesh",
                "R. Ramachandra",
                "M. Long",
                "C. Busch"
            ],
            "title": "Low visual distortion and robust morphing attacks based on partial face image manipulation",
            "venue": "IEEE Transactions on Biometrics, Behavior, and Identity Science, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "D. ICAO"
            ],
            "title": "9303-machine readable travel documents-part 9: Deployment of biometric identification and electronic storage of data in emrtds",
            "venue": "International Civil Aviation Organization (ICAO), 2015.",
            "year": 2015
        },
        {
            "authors": [
                "B.-C. Chen",
                "C.-S. Chen",
                "W.H. Hsu"
            ],
            "title": "Face recognition and retrieval using cross-age reference coding with cross-age celebrity dataset",
            "venue": "IEEE Transactions on Multimedia, vol. 17, no. 6, pp. 804\u2013815, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "A.S. Georghiades",
                "P.N. Belhumeur",
                "D.J. Kriegman"
            ],
            "title": "From few to many: Illumination cone models for face recognition under variable lighting and pose",
            "venue": "IEEE transactions on pattern analysis and machine intelligence, vol. 23, no. 6, pp. 643\u2013660, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "E. Kussul",
                "T. Baydyk"
            ],
            "title": "Face recognition using special neural networks",
            "venue": "2015 International Joint Conference on Neural Networks (IJCNN), pp. 1\u20137, IEEE, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "C.E. Thomaz",
                "G.A. Giraldi"
            ],
            "title": "A new ranking method for principal components analysis and its application to face image analysis",
            "venue": "Image and Vision Computing, vol. 28, no. 6, pp. 902\u2013913, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "R.R. Atallah",
                "A. Kamsin",
                "M.A. Ismail",
                "S.A. Abdelrahman",
                "S. Zerdoumi"
            ],
            "title": "Face recognition and age estimation implications of changes in facial features: A critical review study",
            "venue": "IEEE Access, vol. 6, pp. 28290\u2013 28304, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "T. Sim"
            ],
            "title": "S. baker, and m. bsat. the cmu pose, illumination, and expression (pie) database",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 25, no. 12, pp. 1615\u20131618, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "P.J. Phillips",
                "H. Wechsler",
                "J. Huang",
                "P.J. Rauss"
            ],
            "title": "The feret database and evaluation procedure for face-recognition algorithms",
            "venue": "Image and vision computing, vol. 16, no. 5, pp. 295\u2013306, 1998.",
            "year": 1998
        },
        {
            "authors": [
                "P.J. Phillips",
                "H. Moon",
                "S.A. Rizvi",
                "P.J. Rauss"
            ],
            "title": "The feret evaluation methodology for face-recognition algorithms",
            "venue": "IEEE Transactions on pattern analysis and machine intelligence, vol. 22, no. 10, pp. 1090\u20131104, 2000.",
            "year": 2000
        },
        {
            "authors": [
                "L. DeBruine",
                "B. Jones"
            ],
            "title": "Face research lab london set",
            "venue": "May 2017.",
            "year": 2017
        },
        {
            "authors": [
                "N. Burton",
                "M. Burton",
                "D. Rigby",
                "C.A. Sutherland",
                "G. Rhodes"
            ],
            "title": "Best-worst scaling improves measurement of first impressions",
            "venue": "Cognitive research: principles and implications, vol. 4, no. 1, pp. 1\u201310, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "E. Sarkar",
                "P. Korshunov",
                "L. Colbois",
                "S. Marcel"
            ],
            "title": "Vulnerability analysis of face morphing attacks from landmarks and generative adversarial networks",
            "venue": "arXiv preprint, Oct. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Mallick"
            ],
            "title": "Face morph using OpenCV \u2014 c++ / python",
            "venue": "https://learnOpenCV.com/face-morph-using-OpenCV-cpp-python/."
        },
        {
            "authors": [
                "Yaopang"
            ],
            "title": "Face morpher",
            "venue": "https://github.com/yaopang/FaceMorpher/tree/master/FaceMorpher."
        },
        {
            "authors": [
                "S. Hassan"
            ],
            "title": "Face classification using facenet and mtcnn",
            "venue": "https://github.com/saadhaxxan/ Face-Classification-using-FaceNet-and- MTCNN."
        },
        {
            "authors": [
                "A. Rosebrock"
            ],
            "title": "How-to: Python compare two images",
            "venue": "https://www.pyimagesearch.com/2014/09/15/ python-compare-twoimages/.",
            "year": 2014
        },
        {
            "authors": [
                "FooBar167"
            ],
            "title": "Fastest way to increase colour image contrast with OpenCV in python",
            "venue": "https://stackoverflow.com/users/7550928/foobar167."
        },
        {
            "authors": [
                "F. Schroff",
                "D. Kalenichenko",
                "J. Philbin"
            ],
            "title": "Facenet: A unified embedding for face recognition and clustering, in: 2015",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2015
        },
        {
            "authors": [
                "P. Terh\u00f6rst",
                "J.N. Kolf",
                "N. Damer",
                "F. Kirchbuchner",
                "A. Kuijper",
                "Ser fiq"
            ],
            "title": "Unsupervised estimation of face image quality based on stochastic embedding robustness",
            "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2020
        },
        {
            "authors": [
                "P. Terh\u00f6rst",
                "J.N. Kolf",
                "N. Damer",
                "F. Kirchbuchner",
                "A. Kuijper"
            ],
            "title": "Face quality estimation and its correlation to demographic and nondemographic bias in face recognition",
            "venue": "IEEE International Joint Conference on Biometrics (IJCB),",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "VOLUME XX, 2017 1\nactivities. The current facial recognition systems are vulnerable to different biometric attacks. This research focuses on morphing attack detection. The research proposes a robust detection mechanism that can deal with variation in age, illumination, eye and head gears. A deep learning based feature extractor along with a classifier is adopted. Additionally, image enhancement and feature combination are proposed to augment the detection results. A versatile dataset is also developed that contains Morph-2 and Morph-3 images, created by sophisticated tools with manual intervention. Morph-3 images can give more realistic appearance and hence difficult to detect. Moreover, Morph-3 images are not considered in the literature before. Professional morphing software depicts more realistic morph attack scenario as compared to the morphs generated in the previous work from free programs and code scripts. Eight face databases are used for creation of morphs to encompass the variation. These databases are Celebrity2000, Extended Yale, FEI, FGNET, GT-DB, MULTI-PIE, FERET, FRLL. Results are investigated using multiple experimental setups and it is concluded that the proposed methodology gives promising results.\nINDEX TERMS Morphing attack detection, fraudulent and forged digital identity documents, biometrics, facial recognition, access control.\nI. INTRODUCTION The world has become a global village with the introduction of modern technologies. Vast distances have now shrunk due to the availability of fast means of conveyance like airplanes, trains, ships and buses. These abundant conveyance options have given rise to a significant increase in the travelling population. With such a large number of mobile population, manual verification of travelling documents and facial authentication is not possible. Therefore, an automatic border control system is used for authentication and approval of passports [1]. Border control systems are now deployed in more than 180 airports around the world [2]. This automatic system uses face recognition system [1] to compare the live captured images of the traveller with the image of traveller that is stored in the travel agency\u2019s database system or in the form of passport or any other type of machine readable travel\ndocuments (MRTD) [3]. After face recognition system approves that both the live captured image of the traveller and the image on the passport are same, the traveller is granted travelling authorization [3]. In this way an automatic border control system [1] is implemented to deal with enormous travelling population. Availability of image manipulation technology has also enabled the culprits to use this technology for fraudulent activities. In order to gain legal entry permission into foreign countries for unlawful activities many criminals are utilizing a technology called face morphing to trick the face recognition system. Image morphing has been around since 1980s [4] but now with the ease and abundance in availability of software and hardware technology to the general public, creating morphed images for fraudulent activities is easier than ever. In face morphing technology the\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nimage of two or more persons can be combined or merged together in such a way that it resembles the participants of the morphed image and the facial recognition system approves the morphed image as the original image of the applicant [5]. Furthermore, the ratio of merger of different persons in the morphed image is controlled in such a way that human inspection is also extremely difficult. Example of morphed images is shown in Fig. 1 in which two separate morphed images are created from two subjects that are resembling both subjects. By using image morphing a wanted criminal who is barred from travelling can easily morph his facial image with the facial image of an accomplice and successfully acquire travel permission in an unauthorized country [5].\nIn order to alleviate this vulnerability of the face recognition systems several methods have been proposed in the past. These methods are categorized based on their methodology of morph detection. Single image morph attack detection and differential morph detection [5]. This study introduces a general morph attack detection model that would be able to classify a wide variety of images. Images of different types and varying features (age, expression, posture, illumination, gender, race, hair style, facial hair, head gear, eye wear) are used as different type of ID cards have different back ground colours and specifications. Generalized images are considered to broaden the checkpoint locations by including border control checkpoints, train stations, bus stations, hotel check ins, security institutions, police stations and banks. As the quality of the input images vary in different parts of the world based on the technology and infrastructure limitations related to both hardware and software, therefore a generalized robust model is presented that would be able to be deployed in any location irrespective of the local technology and data for producing the best possible accurate results with what is available instead of overall rejection to classify morph images. Presented model\nis designed to be a robust, adaptable, generalized and accurate model that can be deployed for facilitating the process of morph attack detection to ensure that fraudulent activities will not go unchecked. In this study, a unique and diverse morphed database is created manually using professional software. Morphed images created from two and three subjects are included in this work. A modern morph detection model based on deep learning based feature extractor and a machine learning based classifier is adopted to be trained and tested on the created database. Six different types of experiments are performed in this study to analyse the performance of the proposed morph attack detection model on different types of morphed and original images. First experiment is performed by training and testing the model on the created database to analyse the impact of different feature combination techniques. Second experiment is performed to analyse the performance of different types of famous classifiers like SVM, Naive Bayes, Logistic Regression, XG Boost and majority voting. Third experiment is performed to evaluate the performance of the model after applying image enhancement techniques. Different levels of brightness and contrast are used to analyse the impact on the performance of the model in detecting morph attacks. In the fourth experiment, replication of the previous state of the art work [5] has been done to compare the performance of the model created in this study and the state of the art [5]. In the fifth experiment, the vulnerability of the morph detection model to the created diverse and unique database is elaborated by using this database as testing database to illustrate the issues and performance depreciation in training the model on one database created from single morphing tool as proposed in the previous state of the art work [5]. In the sixth experiment, the model is trained on the morphed database that is created in this research and tested on the database from the previous state of the art work [5] to illustrate that the created morphed database yields better results by training the model better as compared to previous work [5] that utilized single database and single morphing tool for creation of training database. The following are the main contributions of this research work:\n\u2022 Proving vulnerability of previous morph attack\ndetection models to morph-3 images.\n\u2022 Simulation of a realistic morph attack scenario by\ncreation of a morph database with extreme variation in features. Creation and inclusion of morph-2 & 3 images in the database using professional morphing\ntool. \u2022 Creation of a robust morph detection model using\ndeep learning. \u2022 Proving impact of image enhancement on morph\ndetection.\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nThe organization of this study is as follows. Section-2 describes the state of the art work that has been done in the field of morph attack generation and detection. Furthermore, techniques of morph attack detection from recent research work are discussed and compared in detail along with imperative analysis. Section-3 describes the steps that are involved in the creation of the morphed databases that have been used in this research work. In Section-4, detailed information about the adopted methodology and utilized modules is discussed. Section-5 contains the presentation of results, advantages, disadvantages and limitations of different techniques. Similarly, comparative analysis of model\u2019s performance on different databases is also elaborated. Section-6 provides the conclusion drawn after the completion of this study."
        },
        {
            "heading": "II. RELATED WORK",
            "text": "The matter of morph attack detection has enticed a significant amount of attention from the research community in the recent years. Different studies have been conducted in this field and different approaches have been applied to effectively detect morph attacks. Variety of face databases are utilized for creation of morph image databases as sufficient morph images are not easily available for research purposes.\nA. IMAGE MORPHING In the late 1980s and 1990s, face image morphing was used for introducing visual effects in movies and animations [4]. In image morphing, features of two face images were compared and spatial relationship between the features was determined for combination. After the alignment of both images through warping, colour interpolation is applied to generate new image. The new image is a mix of both input images [7]. The varying of warping and colour interpolation was referred to as transition control. Different techniques of morphing like mesh warping [8], field morphing [9] and radial basis morphing have been used for creation of morphed faces. In mesh warping, meshes are used to link different landmarks or control points on the images of two subjects. The source image is morphed into the target image by freezing some parts of the image while warping others through control points. In field morphing, a pair of lines were used to map corresponding features between two images. Different points on the images were mapped based on their distance from the respective line. In radial basis functions, the features on the image were considered to be represented by a set of points. Different lines and curves that formulated a mesh on an image were considered as a set of points. Mapping was done from the two surfaces that was considered on both images."
        },
        {
            "heading": "B. METHODS OF MORPH ATTACK DETECTION",
            "text": "There are two basic types of morph attack detection (MAD) methods that are prevalent in the literature."
        },
        {
            "heading": "1) SINGLE IMAGE MAD METHOD",
            "text": "In these types of methods only the morphed image is analysed for presence of morphing attempt. Morphing an image leaves some artifacts in the image that are traced for detection of morph. Texture descriptors like binary statistical image features (BSIF) [10] are utilized for texture classification. Furthermore, ghosting or shading artifacts are also detected in such images. Similarly, deep neural network can also be trained to detect such artifacts as long as the training data contain variety of images [5]."
        },
        {
            "heading": "2) DIFFERENTIAL MAD METHOD",
            "text": "In these types of methods both the potential morph and the live captured images are analysed, compared and processed to detect morphing attempt [5]. Feature vectors from both images are extracted for comparison [1], [5], [11], [12], [13], [14], [15]. Demorphing process is also done in some of these techniques to extract the identity of the accomplice by subtracting the live captured image from the morphed image [1], [2], [11]."
        },
        {
            "heading": "C. STATE OF THE ART RESEARCH WORK",
            "text": "Significant amount of work has been done in the field of morph attack detection. Different tools, preprocessing methods and databases are used for morph image creation. Overview of related literature work is shown in Table 1.\nSeveral research studies in the area of morph attack detection have reported good detection results but these studies are tested on the datasets with limited variations and lack real world scenarios. Features like variation in age, race, facial hair, head gear, eye wear, illumination, expression and posture are underutilized or not utilized at all in many studies [1], [2], [5], [11], [12], [16]. Similarly limited number of databases are utilized for morph attack detection. Furthermore, fixed contribution weights (attacker and accomplice) are used in creation of morphed images instead of random contribution weights from attacker\u2019s and accomplice\u2019s images [5]. Images in which head gear and eye wear are present, resulted in incorrect classification of original images as morph images [5]. The quality of live captured images is very high in previous studies [1], [2], [5], [12], [16], that is not applicable for all checkpoints due to variation of available resources.\nExisting morph detection datasets have another very major problem. These datasets have considered the morph of two persons only (morph-2 images), leading to easy morph detection [1], [2], [5], [12], [16]. Furthermore, low quality programming script based morphing tools like FaceMorpher, OpenCV, FaceFusion [3] are used that generate morphed images automatically and majority of created morphed images are easily detectable through visual inspection by a human. Therefore, these techniques are rarely used by criminals, hence not depicting the real world scenarios. Methods tested on the datasets with the discussed limitations, can give very high detection rates but will not be very\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nsuccessful in real scenarios. Morphs of high quality and high variance are still very difficult to classify properly [5].\nSeveral approaches with different benchmarks are proposed in the literature. Previous work has succeeded in achieving high accuracy but the results were achieved on\ndatabases having limited features. The accuracy of results declined whenever there were some additional features in the database related to facial hair, eye wear, cosmetics, hair style, expression and posture [1], [5].\nTable-1\nOverview of the related literature work on morph attack detection\nPublication Author Name Methodology Results Limitations\nDifferential MAD Methods\nFACE DEMORPHING [2] Matteo Ferrara, Annalisa Franco and\nDavide Maltoni,\nExtraction of accomplice\u2019s image from morphed image through corresponding points. Morphed image acceptance rate by facial recognition system dropped from 66.4 % to\n6.1 %.\nIn advance knowledge about morphing factor must be known to set specific range of demorphing factor to ensure proper extraction of accomplice\u2019 image. Furthermore, manual removal of artifacts was required in many cases. Only morph-2 (merging of two persons only) images were used. Limited morphing tools.\nFD-GAN Face DeMorphing Generative Adversarial Network for Restoring Accomplice\u2019s Facial Image [1] Fei Ping, Le-Bing Zhang and Min Long Extraction of accomplice\u2019s image through dual network architecture along with two levels of restoration losses. Accuracy of restoration increased from 49.82% to 87.5% in simple cases without expression and occlusion. Accuracy increased from 46.91% to 64.9% in case of presence of expression and\nocclusion.\nAccuracy of restoration of images suffered in case of images in which subjects were displaying expression, posture or there was some occlusion in the image. Only morph-2 images were used. Limited morphing tools.\nBorder Control Morphing Attack Detection with a Convolutional Neural Network DeMorphing Approach [11] David OrtegaDecamp, Cristina Conde, Daniel Palacios-Alonso and Enriqu Cabello Convolutional neural network de-morphing approach for morph attack detection. Accuracy of 98.1% to 98.7% was achieved in morph attack detection. D-EER of 0.78 % to 20.7 % was achieved. Expressions, posture, illumination and variety in databases were not considered in this study. Only morph-2 images were used. Limited morphing tools. Deep Face Representations for Differential Morphing Attack Detection [5] Ulrich Scherhag, Christian Rathgeb, Johannes Merkle and Christian Busch. Deep learning neural network was used for feature extraction and machine learning classifier was used for classification of morphed\nimages of varying quality created from four tools.\nD-EER of 1% to 7% was achieved while other techniques achieved D-EER of 2.9% to 51%. Morphs of high quality and morphs that bear high resemblance to live captured images were not properly classified. Similarly, images having variation in facial expression, headgear, eye wear, variations in illumination and focus also contributed to misclassification. Lack of\nrealistic database depicting real world scenario. Only morph-2 images were used. Low quality morphing tools.\nSingle Image MAD Methods\nAccurate and Robust Neural Networks for Face Morphing Attack Detection [12] Clemens Seibold, Wojciech Samak, Anna Hilsmann and Peter Eisert. Four training methods to teach specific data to the network and Layer wise level propagation was used for analyzing and controlling the\ndecision-making process of neural networks.\nD-EER of 2.8% to 3.1% was acquired as compared to DEER of 15% to 31% acquired in previous work. Robustness of morph attack detection increased from 20% to 87%. Training and testing were done only on specific selected images with neutral expression, illumination and pose. Images with variety in pose, illumination and expression were not considered and therefore the acquired accuracy was only for such images. Testing is required for images that exhibit variety in expression, pose, illumination and other features like eye wear, head gear and age. Only morph-2 images were\nused. Limited morphing tools.\nDetecting Morphed Face Images [15] Raghavendra R, Raja KB and Busch C. Features from input image were extracted using BSIF\nfilters and SVM classifier was used to classify the image as morph or bondfide.\nACER (Average classification error rate) dropped from 37.55% to 1.73% as compared to previous work. Uniform pose, illumination and expression were present in all images and therefore the acquired accuracy is only for such images. Testing is required for images that exhibit variety in expression, pose, illumination and other features like head gear and age. Only morph-2 images were\nused. Limited morphing tools.\nTransferrable DeepCNN features for detecting digital and print-scanned morphed face images [13] Raghavendra R, Raja KB, Venkatesh S, and Busch C. Pretrained deep learning models of AlexNet and VGG19 were used for feature extraction from input images and P-CRC classifier was used to classify the images as\nmorph or bonafide.\nResults of proposed model were significantly better than previous BSIF model. D-EER of proposed model was 15.05% as compared to previous DEER of 26.70%. Normal face dataset with neutral pose, expression and illumination were utilized therefore accuracy of the model is not proven on datasets having variety in features. Testing is required for images that exhibit variety in expression, pose, illumination and other features like head gear and age. Only morph-2 images were used. Limited morphing tools.\nDetecting Morphing Face Attacks Using Residual Noise from Deep Multi-Scale Context Aggregation [14] Sushma Venkatesh, Raghavendra Ramachandra, Kiran Raja, Luuk Spreeuwers and Raymond Veldhuis. Detection of morph images by learning from features of residual noise in morph and bonafide images by using deep learning and P-CRC classifier. D-EER of proposed method was 2.6% to 8%, which was significantly better as compared to D-EER of 3.83 % to 42.2 % in previous models. Similarly, at various settings of\nAPCER the BPCER value was also significantly better than conventional model. Computational cost also improved by a factor of 4.\nNormal face datasets with neutral pose, expression and illumination were utilized therefore accuracy of the model is not proven on datasets having variety in features. Testing is required for images that exhibit variety in expression, pose, illumination and other features like head gear and age. Only morph-2 images were used. Limited morphing tools.\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nSimilarly, the age of subjects considered for analysis does not differ more than two years in the previous studies [1], [2], [5], [11], [16], but in reality, the electronic machine readable document (MRTD) is valid for up to ten years as specified in the International Civil Aviation Authority (ICAO) protocols about travel documents [17]. So, the studies should contain subjects having age difference between 5 to 9 years as the person presenting the travel document at the border control system could be incorrectly classified as an attacker if his age difference is not properly taken into consideration by the facial recognition system. To cater these limitations a morph attack detection model is required that is accurate, adaptable and generalized. Moreover, the detection model should be trained and tested on the data with all the variations."
        },
        {
            "heading": "III. MATERIALS AND DATA",
            "text": "For implementing this proposed model, total eight face image database are used in this study and an additional FRGC morph database has been used for evaluation during the concluding experiments. Subsets of these databases are used that are most suitable for this proposed model. Images that exhibit wide variety of features are selected. Databases are divided into different sections for training and testing. Famous morphing tools are used and some of them were also used in the previously done research work [5]. Details and features of the images in all the source databases are represented in Table 2.\nTable-2\nDetails and features of images in all the source databases Databases Total\nimages\nNumber of subjects\nImages per subject\nVariation in features\nCelebrity2000 [18] 163,446 2000 Variable Age (16 \u2013 62),\nillumination, expression, posture, eye wear, head gear, hair style, race, gender, facial hair.\nExtended Yale B [19], [6] 16,128 28 585 64 Illumination conditions with\ngrayscale, posture, expression, race, gender.\nFEI (Faculty of industrial engineering) [20], [21] 2800 200 14 Posture, expression, illumination, eye wear, race, gender. FGNET (Face and gesture recognition working group) [22] 1002 82 Variable Age (0-69), illumination, colour / grayscale, expression, posture, hair\nstyle, eye wear, facial hair, gender.\nGT-DB (Georgia tech face database) [6] 750 50 15 Expression, illumination, posture, eye wear, gender. CMU MULTI-PIE (Carnegie mellon university pose, illumination and expression) [23], [24] 130,000 250 520 19 illumination conditions, gender, race, eye wear, expression, posture. FERET (Face recognition technology) [25], [26] 14,126 1199 Variable Colour / grayscale, illumination, expression, posture, gender, race, facial hair, hair style. FRLL (Face research lab London) [27], [28] 204 102 2 Gender, race, facial hair, hair style."
        },
        {
            "heading": "A. CREATION OF MORPHED DATABASE",
            "text": "A specialized morphed image database has been created for this study by following the proposition of a renowned researcher Andrew Ng from an interview [42]. Andrew Ng proposed that a data centric approach should be adopted to improve the performance of deep learning based models as the architecture of the models is sufficiently tweaked and improved to achieve maximum results. Therefore, in this research the main focus is allocated towards creating a quality database to facilitate the model to learn and perform better. This database has been created manually using different morphing software. In this database, morphed images are created by utilizing the images from the first eight databases that are mentioned in Table 2. Morphs created from FERET, FRGC and FRLL databases are borrowed from other research work and those images were created using programming algorithms of OpenCV and FaceMorpher.\nTwo types of morphed images are created in this research:\n1. Morph-3, Images that are created by mixing facial\nimages of three different persons.\n2. Morph-2, Images that are created by mixing facial\nimages of two persons only.\nThe detailed information about the morphed database is displayed in Table 3.\nTable-3\nDetails and features of images in the morphed database\nSource databases\nQuantity of morph-3 images Quantity of morph-2\nimages\nNormal images\nCelebrity2000 827 148 2777\nExtended Yale\n21 17 97\nFEI 63 23 235 FGNET 34 24 150 GTDB 18 18 90 PIE 82 39 324\nFERET [29] 0 1058 1058 FRLL [29] 0 570 570 FRGC [29] 0 1928 1928\nTotal 1045 3825 7229\nGrand total 12099\nTotal 1045 morph-3 images are created manually using high quality software [3] FantaMorph and 269 morph-2 images are created using FotoMorph. While 570 morph-2 images (borrowed) were created from database FRLL and 1058 morph-2 images (borrowed) were created from FERET using programming algorithms of OpenCV and FaceMorpher. FERET and FRGC databases were also used in the training and testing of model in the previous work [5]. Normal images in the morphed database contain the source images\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nthat were used to create morphed images and normal images also contain live captured images. A portion of normal images is used as original images and the second portion as live captured images during training and testing. Number of live captured images vary for different subjects. Maximum amount of live captured images is used for each subject to introduce variation in the training and testing in order to bring this study as close to a realistic scenario as possible. Databases have different qualities and different types of features therefore images from the same database were used for creating morphed images. Each database has been divided into training and testing sets. Source original images and created morphed images from those source images are placed in their respective training and testing sections. Approximately twenty percent images from each database are used for testing while eighty percent images are used for training of model. In some databases twenty percent source images are used for creation of more than twenty percent morphed images so in that case all the morphed images created from source images are placed in respective test set in order to avoid the appearance of training images in testing set. Mixing of images from different databases for creating morphs has not been done as different features like variation in illumination causes artifacts in morphs and reduces the quality of morphs. Images of subjects having similar facial structure and features yield better resulting morphs, so similar facial images are morphed. The detailed information about the images used in training and testing is displayed in\nTable 4."
        },
        {
            "heading": "B. QUALITY ASSESSMENT OF MORPH-3 IMAGES",
            "text": "Morph-3 image has several advantages over the morph-2 image as morph-3 exhibit a more realistic presentation of a human face because the third image acts as a transitioning supporter for ensuring smooth transition between the images. Colour tone is also properly normalized by combining three images and sharp or abrupt differences and artifacts between different images are reduced significantly. Morph-3 images are better at tricking the human inspector because of their additional realistic and natural look. As morph-3 images are created and introduced in this domain of morph attack etection for the first time therefore research work estimating the quality of morph-3 images is not available. In order to prove scientifically that morph-3 images have superior quality in terms of facial features specially for facial recognition system, a face quality estimation and assessment technique from the state of the art works will be utilized. Research works on estimation of face image quality based on stochastic embedding [39], [40] proposed a technique of SER-FIQ (Stochastic embedding robustness - Face image quality). SER-FIQ is designed for face quality estimation specially for ensuring good performance of facial images during processing in different facial recognition systems. This technique outperformed previously proposed techniques\nin majority of cases [39]. The quality of image is assessed based on the level of variation in the stochastic embedding. High variation in stochastic embedding set indicates a low quality image. To assess and estimate the quality of morph-3 images that are created in this research, SER-FIQ technique will be used to compare the quality of morph-2 and morph-3 images.\nTable-4\nDetails and features of images used in training and testing of\nmodel Databases Morph-\n3 train images\nMorph3 test images Morph2 train images Morph2 test images Qty of normal train\nimages\nQuantity of normal test images\nCelebrity2000 660 167 110 38 3265 836\nExtended Yale\n17 4 15 2 40 6\nFEI 50 13 18 5 114 36 FGNET 27 7 20 4 58 20 GT-DB 14 4 15 3 42 12 MULTI-PIE 66 16 33 6 166 46 FERET 0 0 846 212 1140 286 FRLL 0 0 368 202 166 40\nTotal 834 211 1425 472 4991 1282\nGrand total 9215\nThe implementation of SER FIQ has been borrowed from [41] and it is implemented without any changes. Total 30 morph-3 and 30 morph-2 images are selected. These 30 image sets each contain one morph-2 and one respective morph-3. These sets are randomly selected from the created database. Two source images in both morph-2 and morph-3 sets are same while morph-3 have an additional third source image that further adds to its quality. The source images are those images that were used to create these morphed images. It was observed during the experiment that morph-3 image had higher quality score in 27 out of 30 cases of image sets while comparing between morph-2 and morph-3. In two cases of image sets, morph-2 images had higher quality and in one case of image set, morph-2 and morph-3 had the same quality. Based on the majority of cases, it was concluded that morph-3 images have higher quality in terms of quality of facial features. Based on the higher quality of morph-3 images, they have a higher probability of getting matched with their respective live captured images and hence successfully deceive the facial recognition system which is the main objective of creating a morph. Similarly, in the domain of morphing attack detection, after extensive testing in experiment-5 (Section-5), it was observed that around 50% morphed images were incorrectly classified when the testing database contained 80% morph-3 images. This further illustrates that morph-3 images can easily deceive facial recognition systems that are trained on morph2 images only. It is also important to highlight that the criminals creating the morphed images are not limited by the standard rules to create only morph-2 images only as their\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nmain aim is to deceive the facial recognition system by using any available tools and methods at their disposal."
        },
        {
            "heading": "C. SOFTWARE TOOLS USED",
            "text": "The following software are utilized for creating this morphed database.\n1. FotoMorph [30], This software has been used for\nmanually creating morphed images from two facial images using 20 to 45 landmarks. 2. FantaMorph [31], This software has been used for\nmanually creating morphed images from three facial images using 127 landmarks. 3. OpenCV [32], This software has been used to create\nmorphed images from two facial images automatically through program script code using 68 landmarks. 4. FaceMorpher [33], This software has been used to\ncreate morphed images from two facial images automatically through program script code using 77 landmarks.\nFollowing steps are involved in the creation of morphed image from two subjects in tool FotoMorph:"
        },
        {
            "heading": "1) FOTOMORPH",
            "text": "1. Creating corresponding points (landmarks) as\nshown in Fig. 2.\n2. Assigning similar corresponding points to the\nsimilar regions of face on both images.\n3. Selecting the most suitable frame from the\nanimation.\n4. Morphed images were created to include 50%\ncontribution from both the images. It was ensured that the resulting image looked realistic and had minimum artifacts. 5. If the resulting image was unrealistic or had\nsignificant artifacts then the morphing contribution from images was varied to acquire the best possible morphed image. Resulting final image is shown in Fig. 2.\nFollowing steps are involved in the creation of morphed image from three subjects in tool FantaMorph:"
        },
        {
            "heading": "2) FANTAMORPH",
            "text": "1. Assigning similar corresponding points or face\nregion locators to the similar regions of face on all the three images as shown in Fig. 3. 2. Selecting appropriate contribution of features and\nshape from all three images.\n3. Morphed images were created to include 33%\ncontribution from all the images but it was ensured that the resulting image looked realistic and had minimum artifacts.\n4. If the resulting image was unrealistic or had\nsignificant artifacts then the morphing contribution from images was varied to acquire the best possible morphed image. Resulting final image is shown at the bottom in Fig. 3.\nSamples of morph-3 and morph-2 images created by FantaMorph and FotoMorph respectively, are presented in Fig. 4.\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9"
        },
        {
            "heading": "IV. METHODOLOGY",
            "text": "After extensive analysis of the literature in Section-2, a deep learning based approach was adopted in this research as deep learning based models outperformed the other morph detection models by a significant margin. Therefore, in order to tackle the issue of morph detection, a combination of deep learning based feature extractor and a machine learning based classifier is utilized. Model with the selected combination is essential for developing an accurate and robust morph attack detection system as this type of model is capable to tackle different scenarios of morph attack detection as indicated by the previous state of the art works [5], [13], [14], [15]. Furthermore, most suitable live captured image is automatically selected to combine its features with the potential morph image in order to facilitate the model to only focus on discrepancies between the images. The main morph attack detection model is shown in Fig. 5. Implementations of MTCNN (Multi task cascaded convolutional neural networks) and cosine distance calculation are borrowed from previous work [34]. This model is based on DeepFace model FaceNet (a pre-built deep learning neural network) and it is used for training and testing during this study. Some variations in hyper parameters are made in different experiments and these variations are mentioned in respective experiments. FaceNet has been selected because of its efficient performance in the presence of different poses in the images [38].\nThe following steps are performed in the implementation phase of this study:\n1. Extraction of faces from input images (morph and\nlive captured) using MTCNN. Extracted images are converted to size of 160 x 160 x 3 for FaceNet. 2. Features are extracted from the input images using\nFaceNet.\n3. Features from input live captured and potential\nmorph image are combined using subtraction, addition, or concatenation. Features of potential morph and its respective live captured image are combined after verification from the facial recognition system based on structural similarity index measure (SSIM) [35] and cosine distance. 4. The combined features are forwarded to the\nmachine learning based classifier SVM (support vector machine) for classification of input images as morphed or original images."
        },
        {
            "heading": "A. FEATURE COMBINATION",
            "text": "In order to combine the features of live captured and potential morphed images, the following steps are performed as represented in Fig. 6:\n1. Cosine distance and SSIM score are calculated\nbetween the potential morph and the respective live captured images. 2. Cosine distance utilizes the extracted feature vectors\nfrom the input images for calculating similarity score while SSIM uses the extracted input face images for calculation of similarity score. 3. Both the cosine distance and SSIM scores are\ncombined by averaging.\n4. Features of potential morphed image are combined\nwith the live captured image based on lowest combined cosine and SSIM similarity score.\nThe basic explanation of morph attack detection model has been provided in Algorithm 1."
        },
        {
            "heading": "B. ALGORITHM-1",
            "text": "procedure MORPH ATTACK DETECTION (database)\nExtracted faces = MTCNN (database) model = load (FaceNet, weights) for faces in database do\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nfeatures = model (extract features (Extracted faces))\nend for while potential morph index < total potential morphs: do\nwhile live image index < total live images: do\ncos = cos (features potential morph, features live image) ssim = 1 - ssim (potential morph, live image) score list = ((cos + ssim) / 2)\nend while smallest score = smallest value (score list) index = score list.index (smallest score) combined = (features pot.morph, features live (index)) trainX = normalize (combined, L-2) classifier (trainX, trainY) predictedY = classifier.predict(testX) (Accuracy, DEER) = evaluation metrics (testY, predictedY)\nend while\nend procedure\nFIGURE 6. Feature combination process\nLive captured image with the best possible posture, illumination and other important features is selected for feature combination. If the potential morphed image is actually a morph, then the only distinguishing factor in the morphed image and the live captured image is the evidence of morphing attempt or leftover digital footprint in the morphed image\u2019s feature vector."
        },
        {
            "heading": "C. EVALUATION METRICS",
            "text": "For evaluation of the model all the relevant metrics are adopted. Fewer metrics may lead to ignore various evaluation aspects while highlighting some. Such rigorous evaluation has not been done before. General detection accuracy is reported and metrics for standard biometric systems according to the document ISO IEC 30107-3 [36] like DEER\n(Detection equal error rate), APCER (Proportion of attack presentations incorrectly classified as bona fide presentations), BPCER (Proportion of bonafide presentations incorrectly classified as attack presentations) and ACER (Average classification error rate) are used. The accuracy of the model is reported using the Detection equal error rate (DEER) and it is defined as the decision threshold where APCER is as high as BPCER. Similarly, APCER-10 and BPCER-10 are reported in this study. APCER-10 is defined as the point where BPCER = 10% and BPCER-10 is the point where APCER = 10%."
        },
        {
            "heading": "V. RESULTS",
            "text": "Six different types of experiments are performed in this study to analyse the performance of the proposed morph attack detection model on different types of morphed and original images. The following experiments are performed:"
        },
        {
            "heading": "A. EXPERIMENT-1: PERFORMANCE OF THE MODEL USING DIFFERENT FEATURE COMBINATION TECHNIQUES",
            "text": "In this experiment the first eight databases from Table 3 are utilized excluding the ninth database FRGC. Total 2259\nmorphed images and 4991 source normal images are used for training and 683 morphed, 1282 normal images (original and live) are used for testing. One or more live captured images per subject are a part of 1282 normal images which are used for comparison and authentication of morphed and original images. Quantities of used images during training and testing are mentioned in Table 4. Details about the experiment\u2019s performance on SVM with linear function are represented in\nTable 5 and errors in each database are represented in Table 6. In Table 6, M represents the proportion of incorrectly classified morphed images and O represents proportion of incorrectly classified original images. DEER curves and confusion matrices of the experiment are represented in Fig. 7.\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nFeature combination\nCelebrity Yale FEI FGNET GTDB PIE FERET FRLL\nM O M O M O M O M O M O M O M O\nFeature concatenation\n20.5 3.8 16.7 0.0 16.7 2.8 45.4 5.0 28.6 0.0 22.7 4.3 29.7 1.4 21.3 2.5\nWithout combination\n37.1 5.6 33.3 0.0 16.7 11.1 81.8 0.0 28.6 0.0 22.7 6.5 29.2 8.0 35.1 5.0\nFeature subtraction\n24.9 6.6 0.0 16.7 22.2 8.3 54.5 15.0 42.9 16.7 22.7 8.7 47.6 8.0 34.6 7.5\nFeature addition 69.6 8.4 83.3 0.0 38.9 11.1 72.7 10.0 28.6 0 59.1 8.7 48.6 12.2 56.0 5.0\nIt can be seen from Table 5 that the best results in terms of errors like APCER, BPCER, ACER and DEER are acquired when extracted feature vectors by FaceNet are concatenated. Similarly other metrics like accuracy yielded the best results in feature concatenation strategy. Concatenation of features produced the best results because majority of live captured images are very similar to morphed images and feature addition or subtraction were not able to produce a prominent pattern as compared to feature concatenation. Feature concatenation also preserved the information from morphed and live captured images in its original form and that helped the model to better learn and classify accordingly. Computationally feature concatenation is more intensive as the size of a single feature vector is 256 (dimensions 1 x 256) and in case of feature addition or subtraction the size of feature vector is 128 (dimensions 1 x 128). Without feature combination the results are also better than the addition and subtraction methods. It also provides an additional benefit that it only requires a single morphed or original image for classification as during training and testing this method does not require a live captured image for classification. Furthermore, the model without feature combination has the lowest computational requirements as it skips the facial recognition phase and only learns from input facial images.\nVOLUME XX, 2017 9\nUtilizing both SSIM and cosine, the computational cost is almost doubled but during testing it was observed that the facial recognition phase took different time for images belonging to different databases. More time was required for high quality images but the facial recognition phase did not take more than one second for processing the best quality image. Other modules of the model take the standard default time in the processing of data as intended by the designers. From Table 6 it is evident that almost all the morphed images in each database are classified in an excellent manner except FGNET database where 45.4% images are incorrectly classified. This incorrect classification in FGNET database resulted due to the extreme levels of variations related to range of age (0 to 69 years), colour and illumination as mentioned in Table 2. Images that are present in this database are represented in Fig. 9. Best classification results are acquired in Yale database because all the images of this database are grayscale and external factors like background colour and light sources are almost same in all the images. This absence of external factors allows the model to detect the variation in images that is caused from morphing process and it becomes easier for the model to detect these morphing traces with specific and undivided focus. During experiments it was observed that 164 morphed test images were incorrectly classified and the maximum proportion of incorrectly classified images were created from tool FotoMorph as shown in Table 7. All the morphed images had significant amount of training data ranging from three to four times the test data but the reason for most incorrect classifications related to tool FotoMorph is that the training data of 211 images was spread between six databases and extreme level of variation among the databases was not properly encompassed in the training data related to FotoMorph.\nFurthermore, sufficient training data from each database to ensure maximum learning (weight updation) and correct classification was not provided to the model in case of FotoMorph as evident from Table 4, otherwise the results in case of other morphing tools like FantaMorph, FaceMorpher and OpenCV are significantly better because training data\ncontained considerable quantity from each database to ensure maximum learning (weight updation) and correct classification. This also proves that during training representation of morphed images created from each morphing tool is necessary in order to facilitate the model to efficiently detect the test morphed images created from the same tool. With respect to effect of facial hair, eye wear and head gear on incorrect classification of original images as morphed images, the results indicated that 6 out of 31 original images were incorrectly classified due to the presence of eye wear, 3 out of 188 images due to the presence of facial hair and 0 out of 12 images due to the presence of head gear or caps. These results represent an overall improvement in correct classification of original images as compared to previous work [5]. Accuracy decreased from 87.5% to 64.9% in previous work [1] in the presence of above mentioned variations in images as compared to the accuracy of 89.6% of this research."
        },
        {
            "heading": "B. EXPERIMENT-2: PERFORMANCE OF THE MODEL USING DIFFERENT CLASSIFIERS",
            "text": "Training and testing of proposed model on all the first eight databases are done excluding the ninth database FRGC as shown in Table 3 to analyse the performance of different types of famous classifiers like SVM, naive bayes, logistic regression, XG boost and majority voting. Majority voting is a combination of SVM with linear function, Naive bayes and XG boost. Two out of three classifiers decided the outcome of classification. Tuning of SVM on radial basis function (RBF) has also been done by using different values of hyper parameters like gamma (influence controller) and C (decision margin controller). Details about the experiment\u2019s performance are represented in Table 8 and errors in each database are represented in Table 9. In Table 9, M represents the proportion of incorrectly classified morphed images and O represents proportion of incorrectly classified original images. It is evident from results in Table 8 that the best results are acquired when SVM is equipped with RBF tuned function with gamma set to 0.6 and C is set to 50. While lowest DEER is observed with SVM RBF on default hyper parameters. All the classifiers performed well except naive bayes because it assumes that the features are independent in the data while some of the features in these images are dependent like morphing software leaves different artifacts in different images and the magnitude of these artifacts is dependent on the illumination, quality and light intensity in the respective images. In Table 9 SVM RBF with tuned hyper parameters is able to get the best results in classifying the morphed images in majority of databases and it is even able to achieve only 27.3 % error in classifying FGNET database in which other classifiers lagged behind\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nsignificantly. Naive Bayes also produced the best results in classifying morphed images in databases like GTDB, PIE, FERET and FRLL because in these databases majority of images have small amount of variation as compared to FGNET and features are independent from each other due to the absence of external influences like significant variation in illumination and colour."
        },
        {
            "heading": "C. EXPERIMENT-3: PERFORMANCE OF THE MODEL",
            "text": "USING IMAGE ENHANCEMENT Training and testing of proposed model have been done on all the first eight databases as shown in Table 3 by applying image enhancement techniques like contrast limited adaptive histogram equalization (CLAHE) [37]. Different levels of brightness, contrast and CLAHE clip limit are used to analyse the impact on performance of the model in detecting morph attacks. Details about the experiment\u2019s performance are represented in Table 10 for SVM with linear function and Table 12 for SVM with RBF function. Errors in each database are represented in Table 11 for SVM with linear function and Table 13 for SVM with RBF function. In Table 11, and Table 13 M represents the proportion of incorrectly classified morphed images and O represents proportion of incorrectly\nclassified original images. From results it can be formulated that medium to high level of contrast is causing a negative impact on the correct classification of morphed images while low to medium level of brightness and clip limit produce significantly better results as seen in Table 10. Indepth analysis of enhancement can be done by observing individual database results. It can be seen in Table 11 that image enhancement has different effect on different databases. The classification performance of morphed images in case of databases like Celebrity, FERET, and GTDB is continuously decreasing with the increase in image enhancement parameters because the images in these databases are already well illuminated in majority of scenarios while in databases like Yale and PIE at parameter 1, 1, 3 and in FGNET at parameter 10, 4, 20 and in FRLL at parameter 30, 8, 20 the best results of classification in case of morphed images are acquired because the images in these databases lack proper illumination and colour variance. The histograms of images after image enhancement are spread over all the colour spectrum and colour variance facilitates the model to learn more from each image and classifies them better consequently. At the end, it can be seen in the results that very high values of image enhancement parameters have resulted in very low results of classification in case of morphed images because all the details, information and\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\npatterns in the images are washed out and all the images look similar with values of each pixel reaching their maximum limit. The performance of SVM with RBF function is also presented in Table 12 and Table 13 and almost similar results are produced with some variation in respective databases. Therefore, it can be concluded that these enhancements and contrast settings may vary depending upon the hardware resources."
        },
        {
            "heading": "300, 4, 120 65.2 100.0 0.0 - - 50.0 -",
            "text": ""
        },
        {
            "heading": "150, 4, 70 78.2 51.2 6.2 42.0 45.9 28.7 22.7",
            "text": ""
        },
        {
            "heading": "100, 8, 70 75.8 59.8 5.6 46.0 45.6 32.5 25.5",
            "text": ""
        },
        {
            "heading": "100, 4, 70 79.8 43.2 7.9 39.0 37.5 25.5 21.5",
            "text": ""
        },
        {
            "heading": "100, 4, 50 79.7 43.8 7.7 38.2 37.4 25.7 21.6",
            "text": ""
        },
        {
            "heading": "100, 4, 30 79.4 44.4 7.9 39.9 37.9 26.1 21.4",
            "text": ""
        },
        {
            "heading": "85, 4, 30 80.2 41.6 8.2 37.8 37.9 24.9 20.5",
            "text": ""
        },
        {
            "heading": "30, 1, 30 85.8 32.0 4.7 21.2 24.6 18.4 15.5",
            "text": ""
        },
        {
            "heading": "30, 4, 30 81.4 40.8 6.8 35.3 36.4 23.8 20.5",
            "text": ""
        },
        {
            "heading": "30, 8, 20 77.2 50.7 7.9 44.8 45.2 29.3 22.5",
            "text": ""
        },
        {
            "heading": "30, 4, 20 81.8 40.1 6.5 34.1 35.7 23.3 20.5",
            "text": ""
        },
        {
            "heading": "20, 4, 20 82.0 40.0 6.2 33.8 37.7 23.1 20.7",
            "text": ""
        },
        {
            "heading": "15, 4, 20 81.7 40.2 6.7 62.9 36.0 23.4 20.5",
            "text": ""
        },
        {
            "heading": "10, 4, 20 81.8 39.5 6.8 32.0 35.8 23.2 20.5",
            "text": ""
        },
        {
            "heading": "5, 2, 20 83.0 37.2 6.2 30.4 28.8 21.7 18.6",
            "text": ""
        },
        {
            "heading": "5, 2, 10 83.4 36.4 6.0 28.8 31.0 21.2 17.7",
            "text": ""
        },
        {
            "heading": "5, 2, 3 82.9 35.4 7.2 29.4 27.2 21.3 17.4",
            "text": ""
        },
        {
            "heading": "1, 1, 3 88.2 26.6 3.8 17.3 21.0 15.2 13.3",
            "text": ""
        },
        {
            "heading": "300, 4, 120 100.0 0.0 100.0 0.0 100.0 0.0 100.0 0.0 100.0 0.0 100.0 0.0 100.0 0.0 100.0 0.0",
            "text": ""
        },
        {
            "heading": "150, 4, 70 71.2 2.7 83.3 0.0 22.2 13.9 63.6 15.0 85.7 0.0 72.7 10.9 61.8 8.4 17.3 47.5",
            "text": ""
        },
        {
            "heading": "100, 8, 70 73.2 2.7 100.0 0.0 38.9 25.0 90.9 10.0 100 0.0 90.9 2.2 72.6 7.3 26.7 30.0",
            "text": ""
        },
        {
            "heading": "100, 4, 70 58.0 5.5 66.7 0.0 11.1 16.7 54.5 15.0 42.7 25.0 27.3 19.6 54.2 7.7 19.8 30.0",
            "text": ""
        },
        {
            "heading": "100, 4, 50 59.5 5.4 66.7 0.0 11.1 16.7 54.5 15.0 42.9 25.0 27.3 19.6 55.2 7.3 19.3 30.0",
            "text": ""
        },
        {
            "heading": "100, 4, 30 60.0 6.0 50.0 0.0 11.1 11.1 54.5 15.0 57.1 16.7 27.3 19.6 55.7 7.7 20.3 27.5",
            "text": ""
        },
        {
            "heading": "85, 4, 30 53.7 6.5 50.0 0.0 11.1 11.1 54.5 25.0 42.8 8.3 22.7 22.7 52.4 8.0 21.8 20.0",
            "text": ""
        },
        {
            "heading": "30, 4, 30 41.5 5.5 16.7 0.0 27.8 11.1 45.4 10.0 28.6 16.7 36.4 26.1 59.4 6.6 23.3 5.0",
            "text": ""
        },
        {
            "heading": "30, 8, 20 69.3 3.7 100.0 0.0 22.2 22.2 63.6 15.0 85.7 0.0 68.2 15.2 62.7 10.8 16.3 52.5",
            "text": ""
        },
        {
            "heading": "30, 4, 20 42.4 5.5 16.7 0.0 33.3 11.1 36.4 15.0 28.6 8.3 40.9 21.7 56.1 5.9 22.8 7.5",
            "text": ""
        },
        {
            "heading": "20, 4, 20 40.5 5.0 16.7 0.0 38.9 13.9 36.4 10.0 28.6 8.3 36.4 19.6 59.0 5.9 21.3 10.0",
            "text": ""
        },
        {
            "heading": "15, 4, 20 39.0 5.5 16.7 0 38.9 16.7 36.4 10.0 28.6 8.3 36.5 21.7 59.4 5.9 22.8 10.0",
            "text": ""
        },
        {
            "heading": "5, 2, 20 36.6 5.5 33.3 16.7 27.8 5.5 54.5 15.0 42.9 16.7 40.9 17.4 46.2 5.2 27.7 5",
            "text": ""
        },
        {
            "heading": "5, 2, 10 39.0 5.4 50.0 16.7 33.3 8.3 54.5 15.0 45.8 16.7 31.8 13.0 44.3 5.2 24.7 5.0",
            "text": ""
        },
        {
            "heading": "5, 2, 3 37.1 8.2 33.3 0.0 16.7 5.6 45.4 15.0 42.8 0.0 36.4 6.5 36.3 4.5 33.7 7.5",
            "text": ""
        },
        {
            "heading": "150, 4, 70 79.4 47.9 6.0 39.5 41.2 26.9 21.5",
            "text": ""
        },
        {
            "heading": "100, 8, 70 78.5 50.1 6.3 40.6 43.7 28.2 22.5",
            "text": ""
        },
        {
            "heading": "100, 4, 70 82.5 41.1 4.9 28.7 36.1 23.0 18.6",
            "text": ""
        },
        {
            "heading": "100, 4, 50 82.7 40.5 4.8 28.9 36.4 22.7 19.2",
            "text": ""
        },
        {
            "heading": "100, 4, 30 81.8 43.6 4.6 28.7 38.0 24.1 19.3",
            "text": ""
        },
        {
            "heading": "85, 4, 30 82.4 40.7 5.3 27.7 30.8 23.0 18.5",
            "text": ""
        },
        {
            "heading": "30, 1, 30 86.4 31.6 3.9 18.7 18.7 17.8 13.6",
            "text": ""
        },
        {
            "heading": "30, 4, 30 84.0 37.0 4.8 26.1 28.7 20.9 17.3",
            "text": ""
        },
        {
            "heading": "30, 8, 20 80.5 45.8 5.5 35.3 40.5 25.7 21.5",
            "text": ""
        },
        {
            "heading": "30, 4, 20 83.6 38.6 4.6 26.9 27.1 21.6 16.9",
            "text": ""
        },
        {
            "heading": "20, 4, 20 84.2 37.0 4.4 26.1 28.2 20.7 17.0",
            "text": ""
        },
        {
            "heading": "15, 4, 20 84.1 37.3 4.5 24.9 28.5 20.9 17.0",
            "text": ""
        },
        {
            "heading": "10, 4, 20 84.2 36.6 4.8 24.6 27.7 20.7 16.5",
            "text": ""
        },
        {
            "heading": "5, 2, 20 85.3 34.0 4.4 19.5 18.0 19.2 13.5",
            "text": ""
        },
        {
            "heading": "5, 2, 10 85.8 33.1 4.1 17.7 17.2 18.6 12.8",
            "text": ""
        },
        {
            "heading": "5, 2, 3 85.9 31.2 4.9 20.6 20.9 18.0 13.8",
            "text": ""
        },
        {
            "heading": "1, 1, 3 88.8 27.7 2.4 13.0 12.5 15.0 11.4",
            "text": "VOLUME XX, 2017 9"
        },
        {
            "heading": "D. EXPERIMENT-4: REPLICATION OF THE STATE OF THE ART [5] PREVIOUS WORK",
            "text": "In this experiment the previous work [5] has been replicated and all the work has been done using FaceNet SVM with RBF function and without feature combination. Training of the model has been done on FERET database that contains 529 morphed images created from morphing tool OpenCV and 529 morphed images created from morphing tool FaceMorpher. 1896 original images are used for training and 470 original images are used for testing. From FRGC database, 964 morphed images are used for testing that are created from tool OpenCV and 964 morphed images are used for testing that are created from tool FaceMorpher. Details about the experiment\u2019s performance are represented in Table 14. It can be seen that during replication process there is only 1 to 2% difference in DEER values of this replication and previous work [5]. Similarly, BPCER-10 value also differ not more than 3% and BPCER-10 of this replication work is 0.9% better while the training and testing is done on FaceMorpher. Replication of the previous state of the art\nwork [5] has been done to compare the performance of the model created in this study and the state of the art [5] and it is proven that performance of the models is almost similar. This study is a better representation of a real morph attack detection scenario as compared to previous work [5] because it is based on a highly diverse and unique morph database. This database is created manually using professional high quality tools as compared to automatically generated morphs using low quality tools in the previous work [5]. It contains morph-3 images that are created for the first time in a research study. Morph-3 images are very difficult to detect due to their realistic look and additional complexity as proven in experiment-5. This database contains images with variety in expression, posture, cosmetics, quality, age and illumination that was lacking in previous works. Furthermore, image enhancement techniques have been introduced to address the issues related to low quality images."
        },
        {
            "heading": "E. EXPERIMENT-5: TRAINING THE MODEL ON STATE",
            "text": ""
        },
        {
            "heading": "OF THE ART [5] DATABASES AND TESTING ON THE CREATED MORPHED DATABASE",
            "text": "To prove the unique and diverse nature of the created database as shown in Table 3, the first six databases manually created from morphing tools of FotoMorph and FantaMorph are used as testing databases to illustrate the issues and performance depreciation in training the model on one database (FERET or FRGC from previous work ([5])) created from single morphing tool. The model is trained and tested using all the techniques like feature concatenation, without feature concatenation and multidimensional scaling of difference of feature vectors. Training of the model is done on FERET database that contains 529 morphed images created in OpenCV and 529 morphed images created in FaceMorpher. FERET database contains 1426 normal images that are used for training of the model. For testing of the model 1314 morphed images and 4641 normal images from first six databases in Table 4 are used. While using SVM\nwith RBF function the best results are shown to represent maximum performance of the model on training database. Details about the experiment\u2019s performance are represented in Table 15 for feature concatenation, Table 16 for without feature combination and Table 17 using MDS (multidimensional scaling of the difference of feature vectors to two dimensions) as per the methodology of previous work [5]. As APCER represents the total incorrectly classified morphed images therefore it is the most important evaluation metric for a morph attack detection model. It can be seen from Table 15, Table 16 and Table 17 that APCER is around 50% in case of feature concatenation and without feature concatenation while in case of MDS the APCER is around 86%. All of the APCER values are very high as around 50% to 87% images are incorrectly classified irrespective of the training tool. DEER curves of the experiment are represented in Fig. 8. It is evident from the results that a single database created from a single morphing tool is not sufficient for a practical morph attack detection model. The training database must\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ncontain a vast range and variety of images and morphing tools in order for a morph attack detection model to be able\nto learn distinguishing features from the source database as proven in the next experiment-6."
        },
        {
            "heading": "F. EXPERIMENT-6: TRAINING THE MODEL ON THE CREATED MORPHED DATABASE AND TESTING ON THE STATE OF THE ART [5] DATABASE",
            "text": "In this experiment, the morph attack detection model is trained on the first seven databases from Table 3 and tested on FERET database to illustrate that the created morphed database yields better result as compared to previous work [5] that utilized single database and single morphing tool for creation of training database. Training images contain 2536 morphed images and 4845 normal images and test data contains 529 morphed images created from OpenCV and 529 morphed images created from FaceMorpher and 1426 normal\nimages from FERET database. Results are represented in Table 18 for SVM with linear function and Table 19 for SVM with RBF function. It can be seen that APCER is around 25% in case of SVM with linear function and around 33% in case of SVM with RBF function while in previous experiment-5, the values of APCER were around 50 to 87%. So, it is evident that training the model on a database having vast variation in images and multiple high quality morphing tools yields better result in classification of morphed images.\nVOLUME XX, 2017 9\nTraining on 7 databases Test database (Tool) Accuracy %\nAPCER %\nBPCER %\nAPCER10 %\nBPCER10 %\nACER %\nDEER %\nFaceMorpher FantaMorph FotoMorph\nFERET (FaceMorpher)\n88.9 32.5 1.8 14.2 14.9 17.2 11.5\nFaceMorpher FantaMorph FotoMorph\nFERET (OpenCV)\n89.6 33.6 1.8 15.9 16.5 17.7 13.5\nOpenCV FantaMorph FotoMorph\nFERET (FaceMorpher)\n90.2 31.9 1.6 14.6 14.2 16.8 11.8\nOpenCV FantaMorph FotoMorph\nFERET (OpenCV)\n89.8 33.5 1.6 15.7 15.1 17.5 12.5"
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "In this study, a robust and generalized morph attack detection model and a very diverse morphed database is introduced to better deal with morph attacks in a practical scenario. Different feature combination techniques are analysed and feature concatenation proved to be the best technique for morph detection. Some of the methods like feature concatenation provided better morph attack detection performance but with the increase of computational cost. Similarly, it was observed that manually created morphed images with high quality morphing tools were difficult to detect by the models that were trained on morphed databases that had low variation and were made automatically from low\nquality morphing tools like OpenCV and FaceMorpher using programming scripts. The training of model on manually created morphed databases with high quality tools proved to be helpful in achieving good results and the results achieved by the model on testing data improved significantly. Proposed model gives very encouraging and improved results in case of age, illumination, posture and expression variations. Testing of morphed images was also done using different machine learning based classifiers and SVM produced the best results. Different image enhancement techniques were also applied on image databases and it was observed that databases with low variation in illumination and colour benefited from image enhancement.\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nVOLUME XX, 2017 9\nManually created morph-3 images were very difficult to detect when the model was only trained on morph-2 images created from low quality tools. After training the model on morph-3 images created from high quality tools, the performance of morph-3 detection increased significantly. It\nfurther solidifies the approach to include diverse range of morphs in the training database to improve the robustness of morph detection model. FGNET database proved to be the most difficult database of images in terms of morph detection as it can be seen in Fig. 9 that this database has a vast range of diversity in terms of age, image quality, colour variation and expression. These extreme levels of variations led to the creation of highly complex morphed images that were very difficult to classify by the morph attack detection model.\nFuture work that can be done to improve this model and train it for all possible morph attacks in a real world deployment scenarios will require the acquisition of real morphed images that were submitted to different organizations like airports, identity card issuing authorities, travel agencies, universities and security institutions. The model should then be trained and tested on the real images to ensure better performance. Furthermore, an adaptive morph attack detection model should be designed that automatically adapts to the input images by applying the image enhancements as per requirement. More than three images may also be used for morphing."
        },
        {
            "heading": "ACKNOWLEDGMENT",
            "text": "For MIT-CBCL Database \"Credit is hereby given to the Massachusetts Institute of Technology and to the Center for Biological and Computational Learning for providing the database of facial images.\" Copyright 2003 -2005 Massachusetts Institute of Technology. For Feret Database \"Portions of the research in this paper use the FERET database of facial images collected under the FERET program, sponsored by the DOD Counterdrug Technology Development Program Office.\" The MIT License (MIT) Copyright \u00a9 2022 <copyright holders> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software\nwithout restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
        }
    ],
    "title": "Generation and Detection of Face Morphing Attacks",
    "year": 2022
}