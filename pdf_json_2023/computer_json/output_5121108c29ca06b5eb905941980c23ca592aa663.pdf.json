{
    "abstractText": "Security Information and Event Management (SIEM) technologies play an important role in the architecture of modern cyber protection tools. One of the main scenarios for the use of SIEM is the detection of attacks on protected information infrastructure. Consorting that ISO 27001, NIST SP 800-61, and NIST SP 800-83 standards objectively do not keep up with the evolution of cyber threats, research aimed at forecasting the development of cyber epidemics is relevant. The article proposes a stochastic concept of describing variable small data on the Shannon entropy basis. The core of the concept is the description of small data by linear differential equations with stochastic characteristic parameters. The practical value of the proposed concept is embodied in the method of forecasting the development of a cyber epidemic at an early stage (in conditions of a lack of empirical information). In the context of the research object, the stochastic characteristic parameters of the model are the generation rate, the death rate, and the independent coefficient of variability of the measurement of the initial parameter of the research object. Analytical expressions for estimating the probability distribution densities of these characteristic parameters are proposed. It is assumed that these stochastic parameters of the model are imposed on the intervals, which allows for manipulation of the nature and type of the corresponding functions of the probability distribution densities. The task of finding optimal functions of the probability distribution densities of the characteristic parameters of the model with maximum entropy is formulated. The proposed method allows for generating sets of trajectories of values of characteristic parameters with optimal functions of the probability distribution densities. The example demonstrates both the flexibility and reliability of the proposed concept and method in comparison with the concepts of forecasting numerical series implemented in the base of Matlab functions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Viacheslav Kovtun"
        },
        {
            "affiliations": [],
            "name": "Krzysztof Grochla"
        },
        {
            "affiliations": [],
            "name": "Vyacheslav Kharchenko"
        },
        {
            "affiliations": [],
            "name": "Mohd Anul Haq"
        },
        {
            "affiliations": [],
            "name": "Andriy Semenov"
        }
    ],
    "id": "SP:46aad568fee90c0127e04e32fb3f8e1a2a3e2082",
    "references": [
        {
            "authors": [
                "A. d\u2019Onofrio",
                "P. Manfredi"
            ],
            "title": "Behavioral SIR models with incidence-based social-distancing",
            "venue": "Chaos Solitons Fractals 159,",
            "year": 1120
        },
        {
            "authors": [
                "F.S. Alshammari",
                "M.A. Khan"
            ],
            "title": "Dynamic behaviours of a modified SIR model with nonlinear incidence and recovery rates",
            "venue": "Alex. Eng. J",
            "year": 2021
        },
        {
            "authors": [
                "L. Chang",
                "S. Gao",
                "Z. Wang"
            ],
            "title": "Optimal control of pattern formations for an SIR reaction\u2013diffusion epidemic model",
            "venue": "J. Theor. Biol",
            "year": 2022
        },
        {
            "authors": [
                "A. \u015eim\u015fek"
            ],
            "title": "Lexical sorting centrality to distinguish spreading abilities of nodes in complex networks under the SusceptibleInfectious-Recover ed (SIR) model",
            "venue": "J. King Saud Univ. Comput. Inf. Sci. https:// doi. org/ 10",
            "year": 2021
        },
        {
            "authors": [
                "V. Abhishek",
                "V. Srivastava"
            ],
            "title": "SIR epidemic model under mobility on multi-layer networks. IFAC-PapersOnLine 53(5), 803\u2013806",
            "venue": "https:// doi. org/ 10",
            "year": 2020
        },
        {
            "authors": [
                "M. Umar",
                "Z. Sabir",
                "M.A.Z. Raja",
                "Y.G. S\u00e1nchez"
            ],
            "title": "A stochastic numerical computing heuristic of SIR nonlinear model based on dengue fever",
            "venue": "Results Phys",
            "year": 1016
        },
        {
            "authors": [
                "V. Blavatska",
                "Holovatch",
                "Yu"
            ],
            "title": "Spreading processes in \u2018post-epidemic",
            "venue": "environments. II. Safety patterns on scale-free networks. Phys. A",
            "year": 2021
        },
        {
            "authors": [
                "Huo",
                "H.-F",
                "P. Yang",
                "H. Xiang"
            ],
            "title": "Dynamics for an SIRS epidemic model with infection age and relapse on a scale-free network",
            "venue": "J. Franklin Inst",
            "year": 2019
        },
        {
            "authors": [
                "C. Saxena",
                "M.N. Doja",
                "T. Ahmad"
            ],
            "title": "Entropy based flow transfer for influence dissemination in networks",
            "venue": "Phys. A Stat. Mech. Appl",
            "year": 2020
        },
        {
            "authors": [
                "I. Dronyuk",
                "O. Fedevych"
            ],
            "title": "Traffic flows Ateb-prediction method with fluctuation modeling using dirac functions",
            "venue": "Comput. Netw",
            "year": 2017
        },
        {
            "authors": [
                "N Shahid"
            ],
            "title": "Mathematical analysis and numerical investigation of advection-reaction-diffusion computer virus model",
            "venue": "Results Phys",
            "year": 2021
        },
        {
            "authors": [
                "I. Dronyuk",
                "O. Fedevych",
                "P. Lipinski"
            ],
            "title": "Ateb-prediction simulation of traffic using OMNeT++ modeling tools",
            "venue": "https:// doi. org/",
            "year": 2016
        },
        {
            "authors": [
                "B. Durnyak",
                "B. Havrysh",
                "O. Tymchenko",
                "D. Anastasiya"
            ],
            "title": "Research of image processing methods in publishing output systems",
            "venue": "https:// doi",
            "year": 2018
        },
        {
            "authors": [
                "M. Nazarkevych",
                "Y. Voznyi",
                "V. Hrytsyk",
                "I. Klyujnyk",
                "B. Havrysh",
                "N. Lotoshynska"
            ],
            "title": "Identification of Biometric Images by Machine Learning",
            "venue": "IEEE 12th International Conference on Electronics and Information Technologies (ELIT) (IEEE,",
            "year": 2021
        },
        {
            "authors": [
                "S. Bidari",
                "X. Chen",
                "D. Peters",
                "D. Pittman",
                "P.L. Simon"
            ],
            "title": "Solvability of implicit final size equations for SIR epidemic models",
            "venue": "Math. Biosci",
            "year": 2016
        },
        {
            "authors": [
                "L. Long",
                "K. Zhong",
                "W. Wang"
            ],
            "title": "Malicious viruses spreading on complex networks with heterogeneous recovery rate",
            "venue": "Phys. A Stat. Mech. Appl",
            "year": 2018
        },
        {
            "authors": [
                "Y. Wu",
                "P. Li",
                "Yang",
                "L.-X",
                "X. Yang",
                "Y.Y. Tang"
            ],
            "title": "A theoretical method for assessing disruptive computer viruses",
            "venue": "Phys. A Stat. Mech. Appl",
            "year": 2017
        },
        {
            "authors": [
                "M.R. Machado",
                "S. Pantano"
            ],
            "title": "Fighting viruses with computers, right now",
            "venue": "Curr. Opin. Virol",
            "year": 2021
        },
        {
            "authors": [
                "W. Pan",
                "Z. Jin"
            ],
            "title": "Edge-based modeling of computer virus contagion on a tripartite graph",
            "venue": "Appl. Math. Comput",
            "year": 1016
        },
        {
            "authors": [
                "X. Liang",
                "Y. Pei",
                "Y. Lv"
            ],
            "title": "Modeling the state dependent impulse control for computer virus propagation under media coverage",
            "venue": "Phys. A Stat. Mech. Appl",
            "year": 2018
        },
        {
            "authors": [
                "J. Ren",
                "Y. Xu"
            ],
            "title": "A compartmental model to explore the interplay between virus epidemics and honeynet potency",
            "venue": "Appl. Math. Model",
            "year": 1016
        },
        {
            "authors": [
                "W. Gao",
                "H.M. Baskonus"
            ],
            "title": "Deeper investigation of modified epidemiological computer virus model containing the Caputo operator",
            "venue": "Chaos Solitons Fractals 158,",
            "year": 1120
        },
        {
            "authors": [
                "S. Arra",
                "K. Rekha Devi"
            ],
            "title": "Evaluation, prediction and implementation patterns of network traffic malware using machine learning",
            "venue": "Mater. Today Proc. https:// doi. org/",
            "year": 1016
        },
        {
            "authors": [
                "I. Izonin",
                "R. Tkachenko",
                "N. Shakhovska",
                "Lotoshynska",
                "N. The additive input-doubling method based on the SVR with nonlinear kernels"
            ],
            "title": "Small data approach",
            "venue": "Symmetry 13(4), 612. https:// doi. org/ 10. 3390/ sym13 040612",
            "year": 2021
        },
        {
            "authors": [
                "Izonin",
                "I. et al. Predictive modeling based on small data in clinical medicine"
            ],
            "title": "RBF-based additive input-doubling method",
            "venue": "Math. Biosci. Eng. 18(3), 2599\u20132613. https:// doi. org/ 10. 3934/ mbe. 20211 32",
            "year": 2021
        },
        {
            "authors": [
                "W. Auzinger",
                "K. Obelovska",
                "R. Stolyarchuk"
            ],
            "title": "A revised Gomory\u2013Hu algorithm taking account of physical unavailability of network channels",
            "venue": "Comput. Netw. https:// doi",
            "year": 2020
        },
        {
            "authors": [
                "C.H. Nwokoye",
                "V. Madhusudanan",
                "M.N. Srinivas",
                "N.N. Mbeledogu"
            ],
            "title": "Modeling time delay, external noise and multiple malware infections in wireless sensor networks. Egypt",
            "venue": "Inform. J",
            "year": 1016
        },
        {
            "authors": [
                "C. Gan",
                "Y. Qian",
                "A. Liu",
                "Zhu",
                "Q. Search-driven virus spreading on Social Internet of Things"
            ],
            "title": "A dynamical perspective",
            "venue": "Commun. Nonlinear Sci. Numer. Simul. 114, 106624. https:// doi. org/ 10. 1016/j. cnsns. 2022. 106624",
            "year": 2022
        },
        {
            "authors": [
                "V.P. Dubey",
                "R. Kumar",
                "D. Kumar"
            ],
            "title": "A hybrid analytical scheme for the numerical computation of time fractional computer virus propagation model and its stability analysis",
            "venue": "Chaos Solitons Fractals",
            "year": 1016
        },
        {
            "authors": [
                "A. Coronel",
                "F. Huancas",
                "I. Hess",
                "E. Lozada",
                "F. Novoa-Mu\u00f1oz"
            ],
            "title": "Analysis of a SEIR-KS mathematical model for computer virus propagation in a periodic environment",
            "year": 2020
        },
        {
            "authors": [
                "S. Karageorgiou",
                "V. Karyotis"
            ],
            "title": "Markov-based malware propagation modeling and analysis in multi-layer networks. Network 2(3), 456\u2013478",
            "venue": "https:// doi. org/",
            "year": 2022
        },
        {
            "authors": [
                "S.S.H. Shah",
                "A.R. Ahmad",
                "N. Jamil",
                "A.R. Khan"
            ],
            "title": "Memory forensics-based malware detection using computer vision and machine learning",
            "venue": "https:// doi. org/",
            "year": 2022
        },
        {
            "authors": [
                "H. Liu",
                "G. Yan",
                "Z. Duan",
                "Chen",
                "C. Intelligent modeling strategies for forecasting air quality time series"
            ],
            "title": "A review",
            "venue": "Appl. Soft Comput. 102, 106957. https:// doi. org/ 10. 1016/j. asoc. 2020. 106957",
            "year": 2021
        },
        {
            "authors": [
                "X. Wang",
                "R.J. Hyndman",
                "F. Li",
                "Kang",
                "Y. Forecast combinations"
            ],
            "title": "An over 50-year review",
            "venue": "Int. J. Forecast. https:// doi. org/ 10. 1016/j. ijfor ecast. 2022. 11. 005",
            "year": 2022
        },
        {
            "authors": [
                "G. Liu",
                "K. Zhong",
                "H. Li",
                "T. Chen",
                "Y. Wang"
            ],
            "title": "A state of art review on time series forecasting with machine learning for environmental parameters in agricultural greenhouses",
            "venue": "Inf. Process. Agric. https:// doi. org/",
            "year": 1016
        },
        {
            "authors": [
                "A. Harvey"
            ],
            "title": "Chapter 7 forecasting with unobserved components time series models",
            "venue": "Handb. Econ. Forecast",
            "year": 2006
        },
        {
            "authors": [
                "U. Basellini",
                "C.G. Camarda",
                "Booth",
                "H. Thirty years on"
            ],
            "title": "A review of the Lee-Carter method for forecasting mortality",
            "venue": "Int. J. Forecast.V https:// doi. org/ 10. 1016/j. ijfor ecast. 2022. 11. 002",
            "year": 2022
        },
        {
            "authors": [
                "O. Bisikalo",
                "V. Kharchenko",
                "V. Kovtun",
                "I. Krak",
                "S. Pavlov"
            ],
            "title": "Parameterization of the stochastic model for evaluating variable small data in the Shannon entropy basis. Entropy 25(2), 184",
            "venue": "https:// doi",
            "year": 2023
        },
        {
            "authors": [
                "M.R. Islam",
                "M.E. Hossain"
            ],
            "title": "Monitoring and global optimization",
            "venue": "Drill. Eng",
            "year": 2021
        },
        {
            "authors": [
                "J. Inns"
            ],
            "title": "The evolution and application of SIEM systems",
            "venue": "Netw. Secur",
            "year": 2014
        },
        {
            "authors": [
                "F Menges"
            ],
            "title": "Towards GDPR-compliant data processing in modern SIEM systems",
            "venue": "Comput. Secur",
            "year": 2020
        },
        {
            "authors": [
                "A.R. Muhammad",
                "P. Sukarno",
                "A.A. Wardana"
            ],
            "title": "Integrated security information and event management (SIEM) with intrusion detection system (IDS) for live analysis based on machine learning",
            "venue": "Proced. Comput",
            "year": 1016
        },
        {
            "authors": [
                "A. Dovbysh",
                "V. Liubchak",
                "I. Shelehov",
                "J. Simonovskiy",
                "A. Tenytska"
            ],
            "title": "Information-extreme machine learning of a cyber attack detection system",
            "venue": "Radioelectron. Comput. Syst",
            "year": 2022
        },
        {
            "authors": [
                "K. Bobrovnikova",
                "S. Lysenko",
                "B. Savenko",
                "P. Gaj",
                "O. Savenko"
            ],
            "title": "Technique for IoT malware detection based on control flow graph analysis",
            "venue": "Radioelectron. Comput. Syst",
            "year": 2022
        },
        {
            "authors": [
                "O Bisikalo"
            ],
            "title": "Modeling of operation of information system for critical use in the conditions of influence of a complex certain negative factor",
            "venue": "Int. J. Control Autom. Syst",
            "year": 1904
        },
        {
            "authors": [
                "A. Altameem",
                "M. Al-Maaitah",
                "V. Kovtun",
                "T. Altameem"
            ],
            "title": "A computationally efficient method for assessing the impact of an active viral cyber threat on a high-availability cluster",
            "venue": "Egypt. Inform. J",
            "year": 1016
        },
        {
            "authors": [
                "V. Kharchenko",
                "O. Illiashenko",
                "H. Fesenko",
                "Babeshko",
                "I. AI cybersecurity assurance for autonomous transport systems"
            ],
            "title": "Scenario, model, and IMECA-based analysis",
            "venue": "Commun. Comput. Inf. Sci. 20, 66\u201379. https:// doi. org/ 10. 1007/ 978-3- 031- 20215-5_6",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "1 Vol.:(0123456789) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nwww.nature.com/scientificreports"
        },
        {
            "heading": "Stochastic forecasting of variable",
            "text": "small data as a basis for analyzing an early stage of a cyber epidemic Viacheslav Kovtun 1*, Krzysztof Grochla 1, Vyacheslav Kharchenko 2, Mohd Anul Haq 3 &"
        },
        {
            "heading": "Andriy Semenov 4",
            "text": "Security Information and Event Management (SIEM) technologies play an important role in the architecture of modern cyber protection tools. One of the main scenarios for the use of SIEM is the detection of attacks on protected information infrastructure. Consorting that ISO 27001, NIST SP 800-61, and NIST SP 800-83 standards objectively do not keep up with the evolution of cyber threats, research aimed at forecasting the development of cyber epidemics is relevant. The article proposes a stochastic concept of describing variable small data on the Shannon entropy basis. The core of the concept is the description of small data by linear differential equations with stochastic characteristic parameters. The practical value of the proposed concept is embodied in the method of forecasting the development of a cyber epidemic at an early stage (in conditions of a lack of empirical information). In the context of the research object, the stochastic characteristic parameters of the model are the generation rate, the death rate, and the independent coefficient of variability of the measurement of the initial parameter of the research object. Analytical expressions for estimating the probability distribution densities of these characteristic parameters are proposed. It is assumed that these stochastic parameters of the model are imposed on the intervals, which allows for manipulation of the nature and type of the corresponding functions of the probability distribution densities. The task of finding optimal functions of the probability distribution densities of the characteristic parameters of the model with maximum entropy is formulated. The proposed method allows for generating sets of trajectories of values of characteristic parameters with optimal functions of the probability distribution densities. The example demonstrates both the flexibility and reliability of the proposed concept and method in comparison with the concepts of forecasting numerical series implemented in the base of Matlab functions.\nThe era of computer viruses lasted little more than 40\u00a0 years1\u20135. One of the first viruses was developed for an Apple computer. It happened in 1981, and the name of the \"progenitor\" was Elk Cloner. This virus was not so much harmless as annoying: with each download, the user of the infected computer saw a funny (in the opinion of the cyberbully) poem on the screen, after which the computer worked in normal mode. The first widespread virus for computers running the MS-DOS operating system appeared in 1986 and was called Brain. However, the developers of this virus, Pakistani brothers Farooq Alvi, did not want to harm people: they wrote Brain to protect the medical program they created from unlicensed copying. Computer viruses have come a long way since their inception, and today\u2019s malicious programs are much more subtle than their counterparts from the 80s and 90s and are much more difficult to detect. In this regard, computer viruses are very similar to their biological \"brothers\". Today, users may not notice for years that a program is running on their gadget, which either silently collects information or forces the user\u2019s device to perform certain actions, or masks the actions of other, much more dangerous programs. Each type of pest has its name and is intended for attackers to achieve various selfish goals6\u201310.\nOne of the earliest computer virus epidemics happened as far back as 1988, when the \"big worm\" or the Morris worm, named after its author, Robert Morris, spread over the Arpanet network in the United States. The worm, picking up passwords, filled the computers of network users with its copies and thus managed to infect more than 6\u00a0k computers, causing about 100 million dollars in damages\u2014a colossal amount for those times. Since\nOPEN\n1Present address: Institute of Theoretical and Applied Informatics, Polish Academy of Sciences, Gliwice, Poland. 2National Aerospace University KhAI, Kharkiv, Ukraine. 3College of Computer and Information Sciences, Majmaah University, Al Majma\u2019ah, Saudi Arabia. 4Vinnytsia National Technical University, Vinnytsia, Ukraine. *email: kovtun_v_v@vntu.edu.ua\n2 Vol:.(1234567890) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nthen, cyber epidemics have occurred repeatedly. For example, a real nightmare for bankers was the Carbanak virus, which in 2014 caused losses to American, Swiss, Dutch, Japanese and Ukrainian banks totalling more than 1 billion dollars. Carbanak moved slowly but surely, first gathering data from rank-and-file bank employees it reached through email attachments, then working its way up the ranks and withdrawing large sums of money. It could take from 2 to 4\u00a0months from the penetration into the bank system to a successful transaction. Here is a more recent example. More than 500\u00a0k computer users were affected by the WannaCry blocker, which appeared in May 2017. This extortionist, very common in Ukraine and India, encrypted information on the computer and demanded money for unlocking. Penetration into the system occurs through open TCP ports. The worm itself did not choose its victims based on certain characteristics, so it paralyzed the work of both ordinary users and various institutions. Comprehensive reporting of cyber outbreaks is worthy of a separate review. Besides, every day, the world-renowned Institute AV-TEST registers almost half a million new malicious and potentially unwanted programs: https:// www. av- test. org/ en/ stati stics/ malwa re/ The provided information is enough for us to state that cyber epidemics are a formidable reality that needs the attention of scientists.\nHowever, research is already underway. Unification is one of the pillars of technological society. Not surprisingly, the scientific community uses the same arsenal to describe both biological virus epidemics and computer virus epidemics. The SIR model1,3,11\u201314, which is not mentioned in almost any article on epidemiology, was created almost a century ago. It is simple and elegant, but it is much criticized and much praised, like any entity that is used only in certain conditions and has its limitations that you need to be aware of when using it. This model assumes the division of the population that is prone to an epidemic into three groups: S (susceptible that does not have immunity), I (infected, contagious) and R (recovered, not contagious, immune). However, the nomenclature is not limited to the three mentioned groups. For example, in the SEIR model15, group E (exposedinfected, not contagious) was added to the three mentioned groups. All these models are instances of the family of compartmental epidemiological models16\u201320. The above-mentioned division of the population into groups or compartments is precisely what determines this family name. The complexity of compartmental models is not limited to three or four groups. Such models can take into account different scenarios: introduction of quarantine measures (SIQR, added group Q\u2014quarantine), loss of immunity (SIRS, transition with some probability from group R back to group S), risk groups according to susceptibility (several groups S, each with its probability of infection), different options for the course of infection (several groups I, each with its probability of hitting susceptible members of the population), etc. The only limitation here is the researchers\u2019 imagination. Complex schemes of compartmental models are usually presented in the form of transition graphs21\u201323. The implementation of compartmental models consists of the formalization of transition equations and the subsequent calculation of changes in each compartment during a certain finite period. If we assume that the number of susceptible to infection and infected is a random variable, then the model becomes stochastic. Typically, such a model is created to answer the question: if the number of uninfected members of the population was equal to x in that week, how will the value of this parameter change this week? What is the probability of avoiding infection u ? If we take into account that u depends on the number of infected members of the population, then we get the Reed Frost model24\u201326. If it is assumed that the probability of infection does not depend on the number of infected, then we get the Greenwood model27\u201330. These are more flexible, non-continuous models. They are also called branching models24\u201330. Stochastic models became widespread in the 1970s, are constantly evolving and now generally agree with the results of observations of the course of various biological infections.\nHowever, in the case of describing computer virus epidemics or cyber epidemics, the acquired \"biological\" experience is not inherited. Experience modelling a flu epidemic will not help when simulating the WannaCry cyber epidemic. The main reason for this is the fundamental difference in the spaces in which members of fundamentally different populations live and interact. In this context, the mathematical apparatus of time series analysis is suitable for describing the development of cyber epidemics34\u201338. However, the disadvantage of this approach is the strength of compartmental models\u2014time series analysis models do not take into account the specifics of the development of the cyber epidemic.\nMachine learning is a powerful tool for determining the relationship between input and output data for processes that are difficult to analyze analytically. The use of heuristic approaches for the early detection of epidemiological risks in some cases allows to improve the quality of forecasting. Among the examples of machine learning models in the context of the subject of the article, we note dynamic Bayesian networks31\u201333. This architecture is based on a directed graph, the vertices of which correspond to the parameters of the researched process, and the edges to probabilistic dependencies between these independent parameters are defined in the form of certain distribution laws. After training on both a large and a small amount of initial data, Bayesian networks make it possible to estimate the probability of the occurrence of some event in the context of the studied sequence of phenomena. To predict the development of biological epidemics, a simple form of the hidden Markov model is used, which is based on the idea of comparing each random variable Y(t) (for example, the number of computer network nodes with declared atypical behaviour) with a random unmeasured variable S(t) (for example, the total number of computer network nodes with both recorded virus infection and heuristically determined signs of the latter), which characterizes the conditional distribution Y(t) . Thus, the value Y(t) depends only on the value of the hidden variable S(t) at time t , and the sequence S(t) has the Markov property, that is, the value S(t) depends only on S(t \u2212 1) . The need to fulfil these and several other mandatory conditions limit the applied change of this approach in the context of the phenomenon to which this article is devoted.\nArtificial neural networks32\u201334 are directed weighted graphs, the vertices of which model the functioning of biological neurons or their functionally oriented populations. The training of such models consists of calculating the coefficients of connections between vertices, which determine the strength of the input signals and is performed based on empirical data: infection statistics based on the values of the factors that determine it. For the correct training of such neural networks, a large amount of representative data is needed, which simply cannot be in the case of a new cyber epidemic.\n3 Vol.:(0123456789) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nAny time series of morbidity can be considered as a random process consisting of a signal reflecting the real epidemic situation and high-frequency noise. Noise filtering allows us to refine the prediction and can be performed both during the pre-processing of the raw data and directly in the body of the prediction algorithm. One such approach is wavelet decomposition35,36, in which a short time series is represented by wavelet functions. This approach is usually used in conjunction with other models. One such model is exponential smoothing, which is a special case of the weighted moving average, and the incidence value y(t) at time t is described by the weighted sum of the last observations: by(t)+ (1\u2212 b)y(t \u2212 1) , where b \u2208 (0, 1) is a smoothing factor that provides weight reduction as the data ages, which can be considered as a reflection of the natural learning process. This method of model creation is suitable for series whose behaviour shows a clear trend or seasonality. These conditions for cyber epidemics are fulfilled only in the abstract.\nT. Schelling in 1971 and M. Mitchell in 1993 proposed the theory of cellular automata to model the local characteristics of susceptible populations together with stochastic parameters that reflect the probabilistic nature of the development of a biological epidemic. Cellular automata are considered as a set of square cells united in a rectangular grid, each cell of which takes a state from a finite set. Grid nodes model entities-individuals, each of which has a fixed position in space. This approach allows us to focus on the contribution of the human factor to the process of the development of a cyber epidemic. The description of the process of computer network node infection in terms of probabilistic cellular automata and ordinary differential equations has a perspective and will be investigated by the authors in the following works.\nPatrolla in 2004 proposed an agent-oriented model37,38, which expands the capabilities of cellular automata in the context of tracking the spread of infection, taking into account mutual contacts between individuals united in a certain social group. Such a model is embodied in the scheme of possible contacts as a dynamic or static graph, the vertices of which correspond to objects with a finite, but sufficiently detailed, set of individual properties inherent to individuals or their classes. This is a potentially promising approach in the context of the subject of this article, but it requires the presence of very specific a priori information for its implementation. This fact does not allow the mathematical apparatus of agent-oriented models to claim universality in the contest of the thematics of this research.\nThus, there is no ready universal solution for describing the development of the cyber epidemic. This fact opens up great prospects for scientific research.\nConsidering the merits and limitations of the aforementioned approaches, we shall now outline the essential characteristics or attributes that scientific research should possess.\nThe object of study is the process of the development of a cyber epidemic at an early stage. The subject of study encompasses probability theory and mathematical statistics, information theory, the theory of experiment planning, mathematical programming methods, and numerical methods. Dear reader, for a more complete understanding of the mathematics-rich material in \u201cModels and methods\u201d section, we recommend that you first read the article40, which reveals the theoretical background of the applied research to which this article is devoted.\nThe aim of the study is to formalize the process of finding optimal functions of probability distribution densities of stochastic characteristic parameters of the variable small data description model with maximum entropy in the context of the problem of forecasting the development of a cyber epidemic at an early stage.\nThe objectives of the study are:\n\u2022 to formalize the concept of calculating variable entropy estimation for functions derived from probability distribution densities of characteristic parameters within a stochastic model. This model is used to describe variable small data, which is represented by interval normalized probabilities.; \u2022 to formalize the process of forecasting the development of cyber epidemics in terms of the stochastic-entropy concept of the description of variable small data; \u2022 to justify the adequacy of the proposed mathematical apparatus and demonstrate its functionality with an example.\nThe main contribution. The article proposes a stochastic concept of describing variable small data on the Shannon entropy basis. The core of the concept is the description of small data by linear differential equations with stochastic characteristic parameters. The practical value of the proposed concept is embodied in the method of forecasting the development of a cyber epidemic at an early stage (in conditions of a lack of empirical information). In the context of the research object, the stochastic characteristic parameters of the model are the generation rate, the death rate, and the independent coefficient of variability of the measurement of the initial parameter of the research object. Analytical expressions for estimating the probability distribution densities of these characteristic parameters are proposed. It is assumed that these stochastic parameters of the model are imposed on the intervals, which allows for manipulation of the nature and type of the corresponding functions of the probability distribution densities. The task of finding optimal functions of the probability distribution densities of the characteristic parameters of the model with maximum entropy is formulated. The proposed method allows for generating sets of trajectories of values of characteristic parameters with optimal functions of the probability distribution densities.\nThe highlights of the study are:\n\u2022 the instances of the class of parameterized stochastic models for the description of variable small data, \u2022 the methods of estimating the functions of the probability distribution densities of their parameters, repre-\nsented by interval probabilities,\n4 Vol:.(1234567890) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\n\u2022 an approach to generating trajectories of random vectors of initial parameters of the model and their statistical processing by the Monte Carlo method to determine numerical characteristics with maximum entropy, \u2022 a method of forecasting the development of a cyber epidemic in terms of the stochastic-entropy concept of describing variable small data."
        },
        {
            "heading": "Models and methods",
            "text": ""
        },
        {
            "heading": "Setting of the research",
            "text": "Let\u2019s examine an object with input parameters x(t) = {xi(t)} , output parameters y(t) = { yi(t) }\nand parameters \u03b5(t) = {\u03b5i(t)} that characterize the variability of measurements of output parameters, i = 1, n , t \u2208 Tp = [t0,T] , t0 < T . We describe the object with a dynamic model with input parameters x(t) = {xi(t)} and output parameters f (t) = { fi(t) }\n, i = 1, n , t \u2208 T . We define the censored observation interval for the object and the model as Ttr = [T\u2212, te) \u222a [te , t0) , where Te = [T\u2212, te) is the training data collection interval, and Tt = [te , t0) is the test data collection interval, Te < te < t0 . The parameters of the mentioned dynamic model are stochastic values. Characteristic features of this model will be the probability distribution densities of these stochastic parameters.\nThe optimal evaluation of the desired probability distribution densities can be carried out based on data collected at the interval Te . We will use the data collected at the interval Tt to test the model. On the interval Tp , we will forecast the object-process using the model f (t) \u2192 y(t) . Let us formalize the connection between parameters x(t) and f (t) in the form of a system of linear differential equations:\nat f (T\u2212) = f0 , where f \u2208 Rn , x \u2208 Rm , n \u2265 m ; C(f ) = [ c (f ) ij ] , i, j = 1, n ; C(x) = [ c (x) ik ]\n, i = 1, n , k = 1,m. The resulting output of the model (1) will be described as\nLet\u2019s formulate the following requirements: R1. The matrix C(f ) is formed by stochastic elements of the interval type\nwhere C(f )\u2212 , C (f ) + are the applied matrices, the elements of which can be both stochastic quantities and linear combinations of a finite number of stochastic quantities; R2. The elements of the matrix C(x) are known and fixed; R3. The probability distribution density P(C) exists, \u2200C(f ) \u2208 C; R4. Vectors \u03b5(t) , t \u2208 Te , are formed by independent components of the interval type:\nIf the conditions R1\u2013R4 are fulfilled, then model (1) allows obtaining a set of trajectories (2) for the stochastic parameter f (t) , t \u2208 \u2329 Te ,Tt ,Tp \u232a\n. Let us rewrite expression (1) taking into account the existence of the fundamental matrix of solutions39:\nBased on expression (5), we write:\nIf the measurement of \"input\u2013output\" entities is carried out at discrete moments with a step , then at the interval Te the expression (6) will take the form\nwhere i \u2208 1,Ne , Ne = \u230a (te \u2212 T\u2212) / \ufffd \u230b . Let\u2019s rewrite expression (2) taking into account expression (7):\nwhere i \u2208 [0,Ne] . For compactness, we denote the block vector \u03b5(T\u2212 + i\ufffd) with dimension n\u00d7 (Ne + 1) mentioned in expression (8) as \u03b5(e) = { \u03b5(k) }\n, k = 0,Ne . Taking into account the a priori independence of both vectors \u03b5(e) and their elements, we define the compat-\nible probability distribution density as Q ( \u03b5(e) ) = \u220fNe i=0 Qi ( \u03b5(i) ) = \u220fNe i=0 \u220fn j=1 qij\n(\n\u03b5 (i) j\n)\nwith the definition domain of E(e) = ENe+1.\n(1) df (t)\ndt = C(f )f (t)+ C(x)x(t),\n(2)o(t) = f (t)+ \u03b5(t).\n(3)C = [ C : C (f ) \u2212 \u2264 C (f ) \u2264 C (f ) + ] ,\n(4)E = [\u03b5\u2212 \u2264 \u03b5 \u2264 \u03b5+].\n(5)V ( C(f )|t \u2212 \u03c4 ) = exp ( C(f )(t \u2212 \u03c4) ) .\n(6)f (t) = V ( C(f )|t \u2212 T\u2212 ) f0 +\nt \u222b\nT\u2212\nV ( C(f )|t \u2212 \u03c4 ) C(x)x(\u03c4 )d\u03c4 .\n(7)f (T\u2212 + i\ufffd) = V ( C(f )|i\ufffd ) f0 +\nT\u2212+i\ufffd \u222b\nT\u2212\nV ( C(f )|T\u2212 + i\ufffd\u2212 \u03c4 ) C(x)x(\u03c4 )d\u03c4 ,\n(8)o(T\u2212 + i\ufffd) = f (T\u2212 + i\ufffd)+ \u03b5(T\u2212 + i\ufffd),\n5 Vol.:(0123456789) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nTherefore, with a defined matrix C, which is characterized by the probability distribution density P(C) , and the vector of the variability of the measurements of the output parameters \u03b5(e) , which is characterized by the compatible probability distribution density Q ( \u03b5(e) )\n, expression (8) is the basis for obtaining a set of the desired stochastic trajectories o(T\u2212 + i\ufffd) , i \u2208 [1,Ne].\nStochastic concept of the description of variable small data in Shannon entropy basis We formalize the estimation of the optimal probability distribution densities P\u2217(C) and Q\u2217 ( \u03b5(e) )\nin terms of the stochastic model for variable small data evaluation in the Shannon entropy basis, which the authors presented in40. We define the objective function of the optimization problem as\nWe specify the system of limitations of such an optimization problem. The first limitation is obvious and focused on the normalization of the investigated probability distribution densities:\nThe second limitation is focused on ensuring the adequacy of the model to the studied process and is aimed at maintaining a balance between the output parameter of the object y(t) and the output parameter of the model o(t) . Let\u2019s formulate this balance equation for the discrete form of representation of the corresponding characteristic parameters, that is, for y(T\u2212 + i\ufffd) = y(i) and o(T\u2212 + i\ufffd) = o(i) , i \u2208 [0,Ne]:\nwhere M { o(i) } is the first moment of the parameter o(i) (look at the expression (5) in the author\u2019s work40), and the parameter w(i) is determined by the expression\nand \u222b C w (i)P(C)dC \u2264 0.5 , \u222b E(e) \u03b5 (i)Q ( \u03b5(e) ) d\u03b5(e) \u2264 0.5 and by manipulating the values of w(i) , \u03b5(i) , respectively. The balance Eq.\u00a0(11) is formulated in the context of the independence of the elements of the vector \u03b5(e). The optimization problem with the objective function (9) and limitations (10), (11) can be classified as a global optimization problem41. The theory of global optimization summarizes a grand and constantly expanding pleiad of solution methods, which can be most generally segmented into three classes. The methods of the first class are focused on the configuration of the objective function and the set of admissible solutions. A characteristic representative of this class is the concept of DC minimization, in which the objective function and the limitations functions are represented by the differences between two convex functions. The methods of the second class investigate simple admissible sets and objective functions with a known Lipshitz constant. We will especially note the concept of reducing a n-dimensional problem to a 1-dimensional one using Peano curves41. The third class of methods is based on the Monte Carlo method with various pseudo-intelligent heuristics41,42. In this class of methods, it is necessary to solve the problem of generating uniformly distributed stochastic vectors within the domain of the search space. For this, both numerous modifications of the Hit-and-Run concept41,42, as well as concepts based on Markov chains43 and concepts based on Kullback\u2013Leibner entropy32,41,42 are used. Further analytical constructions will be formulated based on the methods of the third class.\nThe optimization problem with the objective function (9) and limitations (10), (11) belongs to the Lyapunov type because the functional-objective function and the limitations are integral. Let us analytically express the solution to this problem in terms of the concept of Monte Carlo for global optimization. We will get:\nwhere \u03b2 = { \u03b2(i) }\nis the solution vector, i = 0,Ne , the sign \" \u00b7 \" represents the scalar product, and the functions R(\u03b2) and Q(\u03b2) are defined as\nR(\u03b2) = \u222b\nC\nexp\n(\n\u2212 Ne \u2211\ni=0 \u03b2(i) \u00b7 w(i)(C)\n)\ndC,\nQ ( \u03b5(e) ) = \u222b\nE\nexp\n(\n\u2212 Ne \u2211\ni=0 \u03b2(i) \u00b7 \u03b5(i)\n)\ndE,\nrespectively.\n(9)H ( P(C),Q ( \u03b5(e) )) = \u2212\n\u222b\nC\nP(C) ln P(C)dC \u2212\n\u222b\nE(e)\nQ ( \u03b5(e) ) lnQ ( \u03b5(e) ) d\u03b5(e) \u2192 max .\n(10)\n\u222b\nC\nP(C)dC = 0.5,\n\u222b\nE(e)\nQ ( \u03b5(e) ) d\u03b5(e) = 1.\n(11)y (i) = M\n{ o(i) } =\n\u222b\nC\nw(i)P(C)dC +\n\u222b\nE(e)\n\u03b5(i)Q ( \u03b5(e) ) d\u03b5(e),\n(12)\nw(i)(C) = V(C|i\ufffd)f0\n+\nT\u2212+i\ufffd \u222b\nT\u2212\nV(C + i\ufffd\u2212 \u03c4 )C(x)x(\u03c4 )d\u03c4 ,\n(13)\nP\u2217(C) =exp\n(\n\u2212\nNe \u2211\ni=0\n( \u03b2(i) \u00b7 w(i)(C) )\n)/\nR(\u03b2),\nQ\u2217 ( \u03b5(e) ) =exp\n(\n\u2212\nNe \u2211\ni=0\n( \u03b2(i) \u00b7 \u03b5(i) )\n)/\nQ(\u03b2),\n6 Vol:.(1234567890) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nBy substituting expression (13) into expression (12), we express the vectors of Lagrange multipliers:\nThe optimal solution \u03b2\u2217 = { \u03b2\u2217(i) }\n, i = 0,Ne , of the system of Eq.\u00a0(14) coincides with the global extremum of the discrepancy function J(\u03b2\u2217):\nThe achievement of \u03b2\u2217 marks the completion of training of the model (7) with the stochastic composite parameters C , \u03b5(e) and the corresponding functions of probability distribution densities P\u2217(C) and Q ( \u03b5(e) )\n, which are determined by the expressions (13). Parallelepiped-like regions of admissible values of the parameters C and \u03b5(e) are defined by expressions (3) and (4), respectively.\nWe will focus on the application of the trained model of description of variable small data in the Shannon entropy basis for forecasting. Forecasting based on the trained model (7) consists in generating stochastic matrices of parameters C and \u03b5 with functions of the probability distribution densities (13) for the interval Tp . Let\u2019s formalize this process. We move from the matrix to the vector form of the description of the characteristic parameter C . To do this, we will make a serial connection of the rows of the matrix, obtaining a vector \u03b1 of the length m = n2 of independent stochastic elements. The domain for the elements of the stochastic vector \u03b1 will be defined by the m-dimensional parallelepiped A = [\u03b1\u2212 \u2264 \u03b1 \u2264 \u03b1+] , where the vectors \u03b1\u2212 and \u03b1+ are the result of the matrix-to-vector transformation of the described above matrices C(f )\u2212 and C (f ) + , respectively. Let us introduce the vectors q that belong to the positive unit cube Q : Q = { q : 0 \u2264 q \u2264 1 }\n. We connect the vectors \u03b1 and q by an analytic relation of the form \u03b1 = q(\u03b1+ \u2212 \u03b1\u2212)+ \u03b1\u2212.\nBased on the above, the optimal probability distribution density P\u2217(C) undergoes a sequence of transformations of the form\nTo generate stochastic vectors q \u2208 Q with probability distribution density P ( q )\n, it is proposed to use the Acceptance-\u2013ejection method42. This choice is justified by the fact that we assume the rational sufficiency of the procedures for measuring the characteristic parameters of the object at intervals Te , Tt.\nForecasting the development of the cyber epidemic in terms of the stochastic-entropy concept of the description of variable small data Let\u2019s take a high-availability cluster44,45 as an environment for the start and development of a cyber epidemic. Consider the cluster as a closed system. Let\u2019s introduce the parameter E(t) , which characterizes the number of infected cluster nodes at a time t . The change in the number of infected nodes will be characterized by the variable v(t) = dE(t) /\ndt . The dynamics of the change in the value of the parameter v(t) are ensured by the combined influence of the streams of generation and death.\nThe generation flow is characterized by the parameter B (the number of infected cluster nodes per unit of time). Symmetrically, the flow of death is characterized by the parameter M (the number of infected nodes of the cluster that went into a neutral state as a result of the activity of individual defence mechanisms that coped with the cyber infection (hereinafter \"disinfected\") per unit of time). We emphasize the fact that we are focusing on the early stage of the spread of a new cyber infection when a unified mechanism for its neutralization has not yet been created. We will assume that both of these flows depend linearly on the total number of nodes in the cluster. Let\u2019s move on to the relative time dimension of real-time t (this is convenient because information processes in modern cyber-physical systems of high integration are relatively fast):\nIn the time\u2013space defined by expression (17), the development of the cyber epidemic will be determined by a first-order differential equation of the form\nwhere b is the relative generation rate (the number of newly infected nodes per time quantum, relative to the total number of nodes), m is the relative death rate (the number of disinfected nodes per time quantum, relative to the total number of nodes). In current differential models of the development of the cyber epidemic, those coefficients are considered constant at certain time intervals. We argue that it is more realistic to define these parameters as interval ones: Ib = [b\u2212, b+] , Im = [m\u2212,m+] . This approach allows taking into account the a priori uncertainty inherent in these characteristic parameters. This uncertainty prompts us to interpret the entities b and m as stochastic parameters that take on values in the intervals Ib and Im with the compatible function of the probability distribution density P(b,m) and the additive interval variability of the measurements \u03b5 = {\u03b5(i)} , i = 0, , where I the number of heuristic antivirus scanning procedures in the quantum of time . Those independent elements generalized by the stochastic vector \u03b5 are characterized by the probability distribution density Q(\u03b5) which is defined on the set E =\n\u22c3I j=0 Ej , Ej =\n[\n\u03b5 (j) \u2212 , \u03b5 (j) +\n]\n:\n(14)W(\u03b2) = \u222b\nC\nw(i)(C)\nexp\n(\nNe \u2211 i=0 \u03b2(i) \u00b7 w(i)(C)\n)\nR(\u03b2) dC +\n\u222b\nE\n\u03b5(i) exp\n(\nNe \u2211 i=0 \u03b2(i) \u00b7 \u03b5(i)\n)\nQ(\u03b2) dE\u2212 y(i) = 0.\n(15)J ( \u03b2\u2217 ) = \u2225 \u2225W ( \u03b2\u2217 )\u2225 \u2225.\n(16)P\u2217(C) \u2192 P(\u03b1) \u2192 P ( q ) .\n(17)\u03c4 = t / \ufffd.\n(18) dE(\u03c4 )\nd\u03c4 = E\ufffd(b\u2212m),E0 = E\n(\nT\u2212\n\ufffd\n)\n7 Vol.:(0123456789) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nQ(\u03b5) = I \u220f\nj=0 qj ( \u03b5 [ j\ufffd ]) .\nLet us analytically express the solution of Eq.\u00a0(18) for \u03c4 \u2208 T , T = [\u03c4\u2212, \u03c40] , \u03c4\u2212 = \u2212 / \ufffd , \u03c40 = t0 / \ufffd:\nBy analogy with expression (8), we interpret the change in the number of infected nodes v(t) by taking into account expression (19):\nwhere i \u2208 [0, I] , and\nNote that it is a function (21) that causes the individuality of the model (20). For intervals \u2329 Te , Tt , Tp \u232a , represented by corresponding vectors of measurement results of length \u2329 Ne + 1,Nt + 1,Np + 1 \u232a\n, model (20) will take the form.\nwhere the generation rate b and the death rate m are stochastic parameters with the optimal compatible probability distribution density P\u2217(b,m) , determined on the set Ib \u222a Im by expression (13) at i \u2208 [0,Ne] and by expression (16) at i \u2208 [0,Nt], [ 0,Np ]\n; disturbance \u03b5(i\ufffd) is a vector whose elements are stochastically independent quantities with probability distribution density Q(\u03b5) , i = 0, I ; parameters Et(0) , Ep(0) are constant coefficients that are assigned by experts.\nLet\u2019s analyze the functions P\u2217(b,m) , Q\u2217(\u03b5) analytically, based on the material of the previous section. The optimal compatible function of the probability distribution density for the generation coefficient b and\nthe death coefficient m is expressed as\nwhere p\u2217j ( b,m \u2223 \u2223\u03b2j ) = exp ( \u2212\u03b2j\ufffdj(b,m|Ee(0) ) ) and\nThe optimal function of the probability distribution density for the variability of measurements of the output characteristic parameters of the object \u03b5 is expressed as\nwhere q\u2217j ( \u03b5 ( j\ufffd )\u2223 \u2223\u03b2j ) = exp ( \u2212\u03b2j\u03b5 ( j\ufffd )) and\nTo determine the Lagrange multipliers, we express the balance Eq.\u00a0(14) in terms of expressions (25), (26) for i \u2208 [0,Ne]:\nwhere\nLet\u2019s open the second term from expression (27). We will get:\n(19)E(\u03c4 ) = E0 exp (\u03c4 (b\u2212m)).\n(20)v(i\ufffd) = \ufffdi(b,m|E0 )+ \u03b5(i\ufffd),\n(21)\ufffdi(b,m|E0 ) = E0 exp (i\ufffd(b\u2212m))\u2200i \u2208 [0, I].\n(22)v(i\ufffd) = \ufffdi(b,m|Ee (0))+ \u03b5(i\ufffd), i \u2208 [0,Ne],\n(23)v(i\ufffd) = \ufffdi(b,m|Et (0))+ \u03b5(i\ufffd), i \u2208 [0,Nt],\n(24)v(i\ufffd) = \ufffdi ( b,m \u2223 \u2223Ep (0) ) + \u03b5(i\ufffd), i \u2208 [ 0,Np ] ,\n(25)P\u2217(b,m) = Ne \u220f\nj=0\np\u2217j ( b,m \u2223 \u2223\u03b2j )\n/\nR(\u03b2|Ee(0) ),\nR(\u03b2|Ee(0)) =\n\u222b\nIb\u222aIm\nNe \u2210\nj=0\nexp(\u2212\u03b2j\n\u00d7\ufffdj(b,m|Ee(0)))dbdm.\n(26)Q\u2217(\u03b5) = Ne \u220f\nj=0\nq\u2217j ( \u03b5 ( j\ufffd )\u2223 \u2223\u03b2j )\n/\nQ(\u03b2),\nQ(\u03b2) =\nNe \u220f\nj=0\n(\u03b5j)+ \u222b\n(\u03b5\u2212)j\nexp ( \u2212\u03b2j\u03b5 ( j\ufffd )) d\u03b5 ( j\ufffd ) =\nNe \u220f\nj=0\n( exp (\n\u2212\u03b2j(\u03b5\u2212)j\n) \u2212 exp (\n\u2212\u03b2j(\u03b5+)j\n))/\n\u03b2j .\n(27) Ni(\u03b2|Ee(0) )\nR(\u03b2|Ee(0) ) +\n1\nQ(\u03b5) \u00d7\n\u222b\nE\n\u03b5(i\ufffd)\nNe \u220f\nj=0\nexp ( \u2212\u03b2j\u03b5 ( j\ufffd )) d\u03b5 ( j\ufffd ) \u2212 Ee(i\ufffd) = 0,\nNi(\u03b2|Ee(0) ) =\n\u222b\nIb\u222aIm\n\ufffdi(b,m|Ee(0) )\nNe \u220f\nj=0\nexp ( \u2212\u03b2j\ufffdj(b,m|Ee(0) ) ) dbdm.\n8 Vol:.(1234567890) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nTaking into account the expression (28), we present the balance Eq.\u00a0(27) in a compact form i \u2208 [0,Ne]:\nWe obtain the roots of Eqs.\u00a0(29) \u2200i \u2208 [0,Ne] by analogy with expression (15) as a result of minimizing the discrepancy J(\u03b2):\nwhere || || is interpreted as the Euclidean norm. The dimensionality of the optimization problem with the objective function (30) is equal to Ne + 1 . The actual complexity of the function (30) makes further analytical research of its properties impossible."
        },
        {
            "heading": "Results",
            "text": "Experimental studies with the mathematical apparatus proposed in \u201cModels and methods\u201d will begin with the analysis of the focus group of \"consumers\". In the architecture of modern cyber protection tools, SIEM is undoubtedly such a \"consumer\"41\u201343. Classic SIEM is a log collector that collects events from such sources as DLP systems, firewalls, IPS, servers, workstations, routers, etc. and performs their analysis to detect information security incidents. The main scenarios of using SIEM include the detection of attacks in the early stages, automatic mapping of IT infrastructure, real-time monitoring of the state of IT infrastructure, detection and investigation of information security incidents, detection of new types of threats, optimization of the security monitoring model, etc. At the same time, it is important to understand that SIEM is not a means of protection as such. It is a nested logic and statistics-driven integrator tool for, sometimes, unrelated tools and functions, the purpose of which is to automate end-to-end information security processes. It is rational to implement SIEM if:\u2014\u2265 1 k computing devices are accepted in joint organizational activities;\u2014basic means of information protection are implemented and functioning, for example, an antivirus system, UTM and/or IDS\\IPS, DLP, Web proxy, etc.;\u2014there is a need to reduce the intervention of the \"human factor\" in the processes of the information security service;\u2014there is a need to ensure efficiency, reasonableness and integrity of the decision-making process in the field of information security;\u2014it is necessary to ensure compliance of the protected cyberinfrastructure with ISO 27001, NIST SP 800-61 and NIST SP 800-83 standards.\nTherefore, the expediency of applying the theoretical results of this research in SIEM is obvious. However, such an applied orientation becomes problematic when it is necessary to find an open dataset for testing the proposed system. These circumstances force us to resort to simulation modelling, the data for which is a generalization of open information about the spread of the Petya encryption virus. On June 27, 2017, victims of this virus were Ukrainian companies and Ukrainian branches of international companies, including Nova Poshta, Zaporizhzhiaoblenergo, Dniproenergo, Oshchadbank, media holding Lux, Mondel\u0113z International, TESA, Nivea, Mars, mobile operators LifeCell, UkrTeleCom, Kyivstar and many others. In Kyiv, in particular, some ATMs and cash terminals in stores were found to be infected. It was in Ukraine that the first attacks were recorded. The authors summarized the information available on the IT community website https:// habr. com regarding the spread of the Petya virus in the form of a dataset visualized in Fig.\u00a01. The ordinate axis is graduated in thousand c.u. and represents the average number of infected computing devices E . The abscissa axis is graduated in time\n(28) Li(\u03b2i) =\n( exp ( \u2212\u03b2i(\u03b5\u2212)i )( (\u03b5\u2212)i + \u03b2 \u22121 ))( exp ( \u2212\u03b2i(\u03b5\u2212)i ) \u2212 exp ( \u2212\u03b2i(\u03b5+)i ))\u22121\n\u2212 ( \u2212 exp ( \u2212\u03b2i(\u03b5+)i )( (\u03b5+)i + \u03b1 \u22121 )) \u00d7 ( exp ( \u2212\u03b2i(\u03b5\u2212)i ) \u2212 exp ( \u2212\u03b2i(\u03b5+)i ))\u22121 .\n(29)Gi(\u03b2) = Ni(\u03b2|Ee(0) )\nR(\u03b2|Ee(0) ) + Li(\u03b2i)\u2212 Ee(i\ufffd) = 0.\n(30)J(\u03b2) = \ufffdG(\u03b2)\ufffd2 \u2192 min,\n3, 02\n6 3, 35\n8 3, 69\n1 4, 07 4, 44\n9 4, 88\n4 5, 32 5, 72\n4 6, 12\n8 6, 51\n4 6, 91\n6 7, 26 7, 32\n4 7, 64\n4 7, 96\n4 8, 28\n4 8, 92\n4 9, 56\n4 9, 88\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 0\n2\n4\n6\n8\n10\nAV G (E\n(e ,t, p) )\n\u0456\nFigure\u00a01. Dataset E = f (i).\n9 Vol.:(0123456789) Scientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nintervals . For further research, we will select the training, test and forecast samples within the available data: Te \u2208 i = [0, 6] , Tt \u2208 i = [7, 11] , Ttr = Te \u222a Tt , Tp \u2208 [12, 18] . Since variability is characteristic of the E = f (i) measurements, we further take it into account by defining a stochastic vector \u03b5 with independent stochastic interval elements \u03b5(i\ufffd) \u2208 [\u03b5\u2212, \u03b5+] , i = 0, 18.\nWe will carry out further calculations by applying the following three sets of intervals for the generation coefficient b and the death coefficient m:\nThe interval for the limits of variation of the model\u2019s output parameter is set as E = Ej = [\u22120, 5; 0, 5] \u2200j \u2208 [0,Ne] , Ne = 6 . Let\u2019s apply the mathematical apparatus presented in \u201cModels and methods\u201d for the analysis of the output data on the training, test and forecast intervals \u2329 Te ,Tt ,Tp \u232a\n, respectively. The training interval summarizes the data Te \u2208 i = [0, 6] . The residual function (30) contains two integral components that can only be evaluated numerically. For this, a combination of several quadrature formulas, generalized by the Tiled method, implemented in the Matlab engineering software package as a quad2d function, was used. The essence of this method is to divide the area of integration into a set of trapezoidal or rectangular areas. This choice is justified by the fact that the Trust Region method represented in Matlab by the lsqnonlin function was then used to minimize the discrepancy J(\u03b2) . Function lsqnonlin optimized for use with a function of the quadratic norm type. The use of the lsqnonlin function J(\u03b2) = 10\u22123 made it possible to calculate the value of the Lagrange multipliers B = {\n\u03b2 (i) j\n} = f ({\nI (i) b , I (i) m\n})\n, i = 1, 3 , j = 0, 6 \u2208 Te . The results of the calculations are presented in Fig.\u00a02.\nThe known values of the Lagrange multipliers B make it possible to implement the reverse course and calculate the values of the functions P\u2217 = f (Ii , b,m) , i = 1, 3 , and Q\u2217 = f ( \u03b5, j )\n, j = 0,Ne , Ne = 6 , using expressions (25) and (26), respectively. The calculated dependencies are presented in Figs.\u00a03 and 4. Note that the three-dimensional dependence P\u2217 = f (Ii , b,m) for ease of perception is presented in 2D projections for the limit values of the characteristic parameters \u3008b,m\u3009 . Boundary values are the limits of intervals for these variables, summarized by sets Ii , i = 1, 3.\nAfter training the model (18), we will proceed to its testing. The test interval summarizes the data Tt \u2208 i = [7, 11] (see Fig.\u00a01). The output parameter E(t) is calculated according to the expression (23), where b and m are stochastic parameters with a compatible function of the probability distribution density P\u2217(b,m) and \u03b5(i\ufffd) is the stochastic coefficient of variability of the measurements of the output parameter of the object with the functions of the probability distribution density qi(\u03b5(i\ufffd)) \u2208 Q\u2217 , i \u2208 [7, 11] . To generate trajectories of stochastic parameters b , m , \u03b5(i\ufffd) , i \u2208 [7, 11] , a 2D adaptation of the Ulam\u2013Neumann exception method42 with the volume of the generated sample k = 105 was used. Each exponential trajectory is determined by a pair of values of stochastic parameters b , m and the value of the stochastic parameter \u03b5(i\ufffd) is added to the value of each i -th point of this trajectory by its probability distribution density. The resulting trajectory can no longer be classified as exponential. The only deterministic parameter that affects the set of trajectories is the number of infected computing devices at the initial moment i = 0.\nIi = { i = {1, 3} : ( I (i) b , I (i) m )}\n= (1 : (0, 075; 0, 100), (0, 050; 0, 065);\n2 : (0, 075; 0, 125), (0, 050; 0, 090);\n3 : (0, 055; 0, 065), (0, 035; 0, 045)).\n-1 E4\n-0 ,3 54\n1\n-0 ,3 26\n-0 ,4 11\n1 -0 ,0 03\n1\n0, 28\n21\n1, 19\n-1 E4\n-0 ,6 64\n9\n-0 ,8 69\n8\n,0 81\n4 -0 ,6 28\n2 - 0, 11\n48\n1, 2\n-1 E4\n-0 ,3 65\n6\n-0 ,3 64\n2\n-0 ,4 96\n8 -0 ,1 60\n8\n0, 01\n76\n0, 76\n47\n0 1 2 3 4 5 6 -1,5\n-1,0\n-0,5\n0,0\n0,5\n1,0\n1,5\n\u03b21 (j)\nj\n\u03b21(j) \u03b22(j) \u03b23(j)\nFigure\u00a02. Visualization of the dependency {\n\u03b2 (i) j\n} = f ({\nI (i) b , I (i) m\n})\n, i = 1, 3 , j = 0, 6 \u2208 Te.\n10\nVol:.(1234567890)\nScientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nThe test results are presented in Fig.\u00a05 by the family of curves E = f (i) , i \u2208 [7, 11] = Tt . The curve E (t)\n= f (i) is the averaged trajectory as a result of the description of the interval Tt by the trained model (18) at the limit values of the stochastic parameters b and m imposed by the set I2.\nThe curve Eetalon = f (i) is a visualization of the values of the function E(i) , i = 7, 11 , from Fig.\u00a01. The curve EMatlab = f (i) demonstrates the result of describing the dependence E(i) , i = 7, 11 , on the technological capabilities of standard Matlab functions in the manner described on the page https:// uk. mathw orks. com/ help/ ident/ ug/ forec asting- preda tor- prey- popul ations. html for the initial data E(i) , i = 0, 10 , from Fig.\u00a01. Finally, the curves\n0,048 0,050 0,052 0,054 0,056 0,058 0,060 0,062 0,064 0,066 -0,5\n0,0\n0,5\n1,0\n1,5\n2,0\n2,5\n3,0\n3,5\nP* (I1\n)\nm\nP*(b=0,075;m) P*(b=1,000;m)\n0,0 0,2 0,4 0,6 0,8 1,0\n0\n1\n2\n3\n4\n5\n6\nP* (I1\n)\nb\nP*(b;m=0,050) P*(b;m=0,065)\n0,00 0,02 0,04 0,06 0,08 0,10 0,4\n0,6\n0,8\n1,0\n1,2\n1,4\n1,6\nP* (I2\n)\nm\nP*(b=0,75;m) P*(b=0,125;m)\n0,00 0,02 0,04 0,06 0,08 0,10 0,12 0,14 -0,2\n0,0\n0,2\n0,4\n0,6\n0,8\n1,0\n1,2\n1,4\n1,6\n1,8\nP* (I2\n)\nb\nP*(b;m=0,05) P*(b;m=0,09)\n0,034 0,036 0,038 0,040 0,042 0,044 0,046\n10\n12\n14\n16\n18\n20\n22\n24\n26\nP* (I3\n)\nm\nP*(b=0,055;m) P*(b=0,065;m)\n0,054 0,056 0,058 0,060 0,062 0,064 0,066\n5\n10\n15\n20\n25\n30\nP* (I3\n)\nb\nP*(b;m=0,035) P*(b;m=0,045)\nFigure\u00a03. Visualization of the dependency P\u2217 = f (Ii , b,m) , i = 1, 3.\n11\nVol.:(0123456789)\nScientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\n{E+CI ,ECI\u2212} = f (i) represent the limits of the confidence interval of the variance of the values of E(t) = f (i) , i \u2208 Tt , obtained using the trained model (18).\nThe absolute characteristics of the quality of testing are the root mean square deviation \u03b4 and the relative deviation \u03be of the empirical data from the etalon data. We will give analytical expressions adapted to the conditions of the experiment for calculating these characteristics:\nwhere the values E(i\ufffd) are taken from Fig.\u00a01, and the values E(t)(i\ufffd) are generated by the trained model (18). As a result of the generalization of those shown in Fig.\u00a04 empirical results in metric, \u3008\u03b4, \u03be\u3009 we got:\n\u2329 \u03b4(t), \u03be (t) \u232a\n= (1, 2647; 0, 0417), \ufffd\u03b4Matlab, \u03beMatlab\ufffd = (0, 9520; 0, 0321). Finally, we conclude \u201cResults\u201d by applying the trained model (18) directly to forecasting. It should describe the value of the function E = f (i) from Fig.\u00a01, i \u2208 [12, 18] = Tt . Moreover, i = [16, 18] := 2 , i.e., these measurements of the output data were carried out with a twice-extended interval. It is this fact that explains the extended range of changes i in Fig.\u00a06 to i = 21 . The etalon data is for counts i = {12\u00f7 15, 17, 19, 21}.\nThe forecasting results are presented in Fig.\u00a06 by the family of curves E = f (i) , i \u2208 [12, 21] = Tp . The curve E (p)\n= f (i) is the averaged trajectory as a result of the description of the interval Tp by the model (18) trained on the interval Tp at the limit values of the stochastic parameters b and m imposed by the set I2.\n\u03b4 =\n\u221a\n\u221a\n\u221a\n\u221a\n11 \u2211\ni=7\n( E(i\ufffd)\u2212 E(t)(i\ufffd) )2 ,\n\u03be =\u03b4\n/\n\u221a\n\u221a\n\u221a\n\u221a\n11 \u2211\ni=7\n(E(i\ufffd))2+\n\u221a\n\u221a\n\u221a\n\u221a\n11 \u2211\ni=7\n( E(t)(i\ufffd) )2 ,\n-0,4 -0,2 0,0 0,2 0,4 0,6\n0,0\n0,5\n1,0\n1,5\n2,0\n2,5\n3,0\n3,5\nQ *\n\u03b5\nQ*(\u03b5,j=0) Q*(\u03b5,j=1) Q*(\u03b5,j=2) Q*(\u03b5,j=3) Q*(\u03b5,j=4) Q*(\u03b5,j=5) Q*(\u03b5,j=6)\nFigure\u00a04. Visualization of the dependency Q\u2217 = f ( \u03b5, j ) , j = 0,Ne , Ne = 6.\n7 8 9 10 11 5\n6\n7\n8\n9\n10\nE( i)\ni\nAVG(Et) E.etalon E.Matlab Confidence interval + Confidence interval -\nFigure\u00a05. Visualization of a family of curves E = f (i) , i \u2208 [7, 11] = Tt.\n12\nVol:.(1234567890)\nScientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nThe curve Eetalon = f (i) is a visualization of the values of the function E(i) , i = {12\u00f7 15, 17, 19, 21} , from Fig.\u00a01. The curve EMatlab = f (i) demonstrates the result of describing the dependence E(i) , i \u2208 [12, 21] , on the technological capabilities of standard Matlab functions in the manner described on the page https:// uk. mathw orks. com/ help/ ident/ ug/ forec asting- preda tor- prey- popul ations. html for the initial data E(i) , i = 0, 10 , from Fig.\u00a01. The curves {ECI+,ECI\u2212} = f (i) represent the limits of the confidence interval of the variance of the values E(p) = f (i) , i \u2208 Tp , obtained using the trained model (18)."
        },
        {
            "heading": "Discussion",
            "text": "The last decade can without exaggeration be called the \"decade of neural networks\". Bold experiments with architectures of deep neural networks and their ensembles in combination with the use of Big Data for training allowed us to achieve truly impressive results in solving such classical problems of pattern recognition theory as classification and identification. But have neural networks become smarter? Let\u2019s recall the classic flaw of neural networks\u2014overfitting. The essence of this problem is that the neural network model, perceiving only instances from the training sample, adapts to them instead of learning to classify them. Simply put, overfitting is when a neural network in the training process \"remembers\" the training sample instead of \"generalizing\" it. In principle, with an infinitely large training sample, the problem of overfitting disappears. But when we talk about the socalled \"small data\" this postulate does not work. It is when analyzing small data that the problem of overfitting manifests itself in full. When analyzing small data for their classification and identification, one should resort to the methods of machine learning, and not artificial intelligence. This is exactly what the authors did in the context of the task of forecasting the development of a cyber epidemic at an early stage.\nLet\u2019s take a closer look at the training data, represented in the form of a diagram in Fig.\u00a01. Data visualization instead of a tabular form of their presentation was not chosen by the authors by chance. Figure\u00a01 demonstrates the dynamics of the development of the cyber epidemic of the spread of the Petya encryption virus as it was presented to the general public. We see, in fact, the linear dynamics of the development of this process. Frankly, this immediately raised suspicions among the authors, because intuitively it seems that such a process should develop exponentially until the \"cavalry from over the hill\" appears in the form of a specialized defence mechanism, which will mark the break of the exponential. But if we start from direct data, then we see linear dynamics. This is exactly what the standard methods of forecasting numerical series, presented in Matlab, \"saw\" (see curves EMatlab = f (i) in Figs.\u00a05 and 6). And if the volume of the test sample was too small for them, which was reflected in the inaccurate determination of the angle of inclination of the line EMatlab = f (i) relative to the line Eetalon = f (i) in Fig.\u00a05, then on Fig.\u00a06, these lines practically coincided.\nNow let\u2019s look at the functions E(t) = f (i) and E(p) = f (i) presented in Figs.\u00a05 and 6, respectively. The function E (t)\n= f (i) is also linear, which represents the analytical flexibility embedded in the mathematical model (18). At the same time, the values of the function E(t) = f (i) stably prevail over the values of the function Eetalon = f (i) , i = 7, 11 . That is, the model (18) trained on the data of interval Te \"prepares for the worst\". Finally, the difference will appear in Fig.\u00a06. The function E(p) = f (i) shows an increasing nonlinear character. How can such results be explained? There are two explanations. Or the trained model (18) is inadequate for forecasting the data represented in Fig.\u00a01, or these initial data are incomplete or intentionally distorted.\nThe authors can reasonably reject the first option. To do this, we recall that the stochastic characteristic parameters b , m , \u03b5(i\ufffd) take values from the intervals, the limit ranges of which are embodied in the set of sets Ii , i = 1, 3 . Recall that the curves E (t) = f (i) and E(p) = f (i) were obtained under the condition that the values of the parameters b , m , \u03b5(i\ufffd) satisfy the set I2 . Now recall that b and m are stochastic parameters with a compatible function of the probability distribution density P\u2217(b,m) , and \u03b5(i\ufffd) is a stochastic coefficient of variability of measurements of the output parameter of the object with functions of the probability distribution densities qi(\u03b5(i\ufffd)) \u2208 Q\u2217 . Let\u2019s pay attention to the dependencies P\u2217 = f (I2, b,m) shown in Fig.\u00a03. Non-linearity\n12 14 16 18 20 22 5\n10\n15\n20\n25\n30\nE( i)\ni\nAVG(Ep) E.etalon E.Matlab Confidence interval + Confidence interval -\nFigure\u00a06. Visualization of a family of curves.\n13\nVol.:(0123456789)\nScientific Reports | (2023) 13:22810 | https://doi.org/10.1038/s41598-023-49007-2\nis characteristic of this dependence. This is the source of the nonlinearity of the function E(p) = f (i) shown in Fig.\u00a06. The authors did not accidentally define the set I3 . Let\u2019s pay attention to its characteristics in the form of dependencies P\u2217 = f (I3, b,m) from Fig.\u00a03, both of which have a linear character. The authors trained the model (18) taking into account that its characteristic parameters satisfied the conditions of the set I3 . In the qualitative metric \u3008\u03b4, \u03be\u3009 the obtained result is characterized by the values \u2329 \u03b4(t), \u03be (t) \u232a\nI3 = (0, 6676; 0, 0227) , i.e. it prevails\nover the results obtained using standard Matlab methods (recall: \ufffd\u03b4Matlab, \u03beMatlab\ufffd = (0, 9520; 0, 0321) ). Thus, the functionality of model (18) for solving the problem of forecasting variable small data using the example of forecasting the development of a cyber epidemic of the spread of the Petya encryption virus can be considered proven. The publicly available data on the development of this cyber epidemic was incomplete and the trained model (18) responded differently from the overfitted standard model from the Matlab environment.\nIt remains to clarify a few more points regarding the material presented in \u201cResults\u201d. The first point is the definition of the set I1 . If you look at its characteristics in the form of dependencies P\u2217 = f (I1, b,m) from Fig.\u00a03, then it becomes obvious that this set is a compromise between the \"nonlinear\" set I2 and the \"linear\" set I3 . The authors recommend using the set I1 if the initial data is difficult to pre-characterize. The second point is the influence of the stochastic coefficient of variability of measurements \u03b5(i\ufffd) with functions of the probability distribution densities qi(\u03b5(i\ufffd)) \u2208 Q\u2217 , i \u2208 T , on forecasting results. It is impossible to unambiguously answer this question in numerical and parametric form based on the conducted research. This point needs additional investigation in the context of implementing proactive technologies of AI-powered protection of assets against cyberattacks46\u201348. However, these aspects do not affect the functionality and adequacy of the material presented in the article.\nThe essence of the author\u2019s method is the idea of estimating the model parameter\u2019s probability distributions from a small amount of real empirical data, in the representation of which the measurement noise probability distributions are taken into account. The method returns distributions with maximum entropy, which characterize the state of the greatest uncertainty of the studied process. This makes it possible to interpret the resulting forecasts as the most \u201cnegative\u201d ones. This circumstance suggests that the author\u2019s method may be appropriate for determining pessimistic scenarios when analyzing the reliability of critical systems in conditions of incomplete or distorted telemetry data. This direction can be developed taking into account the fact that the authors previously proposed a mathematical apparatus for describing the influence of complex negative factors on an information system for critical use based on the Markov processes theory49\u201351."
        },
        {
            "heading": "Conclusions",
            "text": "Security Information and Event Management technologies play an important role in the architecture of modern cyber protection tools. One of the main scenarios for the use of SIEM is the detection of attacks on protected information infrastructure. Consorting that ISO 27001, NIST SP 800-61, and NIST SP 800-83 standards objectively do not keep up with the evolution of cyber threats, research aimed at forecasting the development of cyber epidemics is relevant.\nThe article proposes a stochastic concept of describing variable small data on the Shannon entropy basis. The core of the concept is the description of small data by linear differential equations with stochastic characteristic parameters. The practical value of the proposed concept is embodied in the method of forecasting the development of a cyber epidemic at an early stage (in conditions of a lack of empirical information). In the context of the research object, the stochastic characteristic parameters of the model are the generation rate, the death rate, and the independent coefficient of variability of the measurement of the initial parameter of the research object. Analytical expressions for estimating the probability distribution densities of these characteristic parameters are proposed. It is assumed that these stochastic parameters of the model are imposed on the intervals, which allows for manipulation of the nature and type of the corresponding functions of the probability distribution densities. The task of finding optimal functions of the probability distribution densities of the characteristic parameters of the model with maximum entropy is formulated. The proposed method allows for generating sets of trajectories of values of characteristic parameters with optimal functions of the probability distribution densities. The example demonstrates both the flexibility and reliability of the proposed concept and method in comparison with the concepts of forecasting numerical series implemented in the base of Matlab functions.\nThe authors see the direction of further research in deepening the understanding of the influence of the variability of measurements of the output parameter of the research object on the results of evaluation and forecasting of small data. This direction could be added by enhancing protection means against AI-powered attacks52,53."
        },
        {
            "heading": "Data availability",
            "text": "Most data is contained within the article. All the data is available on request due to restrictions e.g. privacy or ethics. Prof. Viacheslav Kovtun (kovtun_v_v@vntu.edu.ua) will be glad to answer any questions regarding the data mentioned in the article.\nReceived: 29 June 2023; Accepted: 2 December 2023"
        },
        {
            "heading": "Acknowledgements",
            "text": "The authors are grateful to all colleagues and institutions that contributed to the research and made it possible to publish its results."
        },
        {
            "heading": "Author contributions",
            "text": "V.K.: methodology, software, validation, formal analysis, investigation, resources, data curation, writing\u2014original draft, writing\u2014review and editing, visualization, supervision; K.G.: validation, resources, writing\u2014review and editing; V.K.: validation, resources, writing\u2014review and Editing; M.H.A.: writing\u2014review and editing; writing\u2014review and editing; A.S.: validation, resources, writing\u2014review and editing."
        },
        {
            "heading": "Funding",
            "text": "This research is part of the project No. 2022/45/P/ST7/03450 co-funded by the National Science Centre and the European Union Framework Programme for Research and Innovation Horizon 2020 under the Marie Sk\u0142odowska-Curie grant agreement No. 945339."
        },
        {
            "heading": "Competing interests",
            "text": "The authors declare no competing interests."
        },
        {
            "heading": "Additional information",
            "text": "Correspondence and requests for materials should be addressed to V.K.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n\u00a9 The Author(s) 2023"
        }
    ],
    "title": "Stochastic forecasting of variable small data as a basis for analyzing an early stage of a cyber epidemic",
    "year": 2023
}