{
    "abstractText": "Inverse probability problems whose generative models are given by strictly nonlinear Gaussian random fields show the all-or-nothing behavior: There exists a critical rate at which Bayesian inference exhibits a phase transition. Below this rate, the optimal Bayesian estimator recovers the data perfectly, and above it the recovered data becomes uncorrelated. This study uses the replica method from the theory of spin glasses to show that this critical rate is the channel capacity. This interesting finding has a particular application to the problem of secure transmission: A strictly nonlinear Gaussian random field along with random binning can be used to securely encode a confidential message in a wiretap channel. Our large-system characterization demonstrates that this secure coding scheme asymptotically achieves the secrecy capacity of the Gaussian wiretap channel.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ali Bereyhi"
        },
        {
            "affiliations": [],
            "name": "Bruno Loureiro"
        },
        {
            "affiliations": [],
            "name": "Florent Krzakala"
        },
        {
            "affiliations": [],
            "name": "Ralf R. M\u00fcller"
        }
    ],
    "id": "SP:57e0b50c476f2eb3953b582995e396df9e9dd0ed",
    "references": [
        {
            "authors": [
                "J. Barbier",
                "M. Dia",
                "N. Macris",
                "F. Krzakala"
            ],
            "title": "The mutual information in random linear estimation",
            "venue": "Proc. 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pp. 625\u2013632, September 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Barbier",
                "N. Macris",
                "A. Maillard",
                "F. Krzakala"
            ],
            "title": "The mutual information in random linear estimation beyond iid matrices",
            "venue": "Proc. IEEE International Symposium on Information Theory (ISIT), pp. 1390\u2013 1394, July 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A. Bereyhi",
                "R.R. M\u00fcller",
                "H. Schulz-Baldes"
            ],
            "title": "Statistical mechanics of MAP estimation: General replica ansatz",
            "venue": "IEEE Transations on Information Theory, vol. 65, no. 12, pp. 7896\u20137934, August 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Bereyhi",
                "R.R. M\u00fcller"
            ],
            "title": "Maximum-a-posteriori signal recovery with prior information: Applications to compressive sensing",
            "venue": "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4494\u20134498, April 2018.",
            "year": 2018
        },
        {
            "authors": [
                "J. Barbier",
                "N. Macris",
                "M. Dia",
                "F. Krzakala"
            ],
            "title": "Mutual information and optimality of approximate message-passing in random linear estimation",
            "venue": "IEEE Transactions on Information Theory, vol. 66, no. 7, pp. 4270\u2013 4303, July 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Bereyhi"
            ],
            "title": "Statistical Mechanics of Regularized Least Squares",
            "venue": "Ph.D. Dissertation,",
            "year": 2020
        },
        {
            "authors": [
                "J. Barbier",
                "W.-K. Chen",
                "D. Panchenko",
                "M. S\u00e1enz"
            ],
            "title": "Performance of Bayesian linear regression in a model with mismatch",
            "venue": "arXiv preprint arXiv:2107.06936, November 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S.F. Edwards",
                "P.W. Anderson"
            ],
            "title": "Theory of spin glasses",
            "venue": "Journal of Physics F: Metal Physics, vol. 5, no. 5, p. 965, May 1975.",
            "year": 1975
        },
        {
            "authors": [
                "D. Panchenko"
            ],
            "title": "The Sherrington-Kirkpatrick model",
            "venue": "Springer Science & Business Media,",
            "year": 2013
        },
        {
            "authors": [
                "M. Talagrand"
            ],
            "title": "Free energy of the spherical mean field model",
            "venue": "Probability theory and related fields, vol. 134, no. 3, pp. 339\u2013382, May 2005.",
            "year": 2005
        },
        {
            "authors": [
                "N. Sourlas"
            ],
            "title": "Spin-glass models as error-correcting codes",
            "venue": "Nature, vol. 339, no. 6227, pp. 693\u2013695, June 1989.",
            "year": 1989
        },
        {
            "authors": [
                "Y. Kabashima",
                "D. Saad"
            ],
            "title": "Statistical mechanics of error-correcting codes",
            "venue": "Europhysics Letters (EPL), vol. 45, no. 1, p. 97, January 1999.",
            "year": 1999
        },
        {
            "authors": [
                "Y.V. Fyodorov"
            ],
            "title": "A spin glass model for reconstructing nonlinearly encrypted signals corrupted by noise",
            "venue": "Journal of Statistical Physics, vol. 175, no. 5, pp. 789\u2013818, June 2019.",
            "year": 2019
        },
        {
            "authors": [
                "S. Leung-Yan-Cheong",
                "M. Hellman"
            ],
            "title": "The Gaussian wiretap channel",
            "venue": "IEEE Transactions on Information Theory, vol. 24, no. 4, pp. 451\u2013 456, July 1978.",
            "year": 1978
        },
        {
            "authors": [
                "A. Bereyhi",
                "B. Loureiro",
                "F. Krzakala",
                "R.R. M\u00fcller",
                "H. Schulz- Baldes"
            ],
            "title": "Bayesian inference with nonlinear generative models: Comments on secure learning",
            "venue": "arXiv Preprint, no. arXiv:2201.09986, Available online at https://arxiv.org/abs/2201.09986, January 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A. Wyner"
            ],
            "title": "Recent results in the Shannon theory",
            "venue": "IEEE Transactions on information Theory, vol. 20, no. 1, pp. 2\u201310, January 1974.",
            "year": 1974
        },
        {
            "authors": [
                "J. Barbier",
                "N. Macris",
                "C. Rush"
            ],
            "title": "All-or-nothing statistical and computational phase transitions in sparse spiked matrix estimation",
            "venue": "arXiv Preprint, no. arXiv:2006.07971, Available online at https://arxiv.org/abs /2006.07971, October 2020.",
            "year": 2006
        },
        {
            "authors": [
                "J. Niles-Weed",
                "I. Zadik"
            ],
            "title": "It was \u201call\u201d for \u201cnothing\u201d: Sharp phase transitions for noiseless discrete channels",
            "venue": "arXiv Preprint, no. arXiv:2102.12422, Available online at https://arxiv.org/abs/2102.12422, February 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Maillard",
                "B. Loureiro",
                "F. Krzakala",
                "L. Zdeborov\u00e1"
            ],
            "title": "Phase retrieval in high dimensions: Statistical and computational phase transitions",
            "venue": "Proc. Advances in Neural Information Processing Systems, vol. 33, pp. 11 071\u201311 082, December 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Liang",
                "H.V. Poor",
                "S. Shamai"
            ],
            "title": "Information theoretic security",
            "venue": "Foundations and Trends in Communications and Information Theory, vol. 5, no. 4\u20135, pp. 355\u2013580, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "A.D. Wyner"
            ],
            "title": "The wiretap channel",
            "venue": "Bell system technical journal, vol. 54, no. 8, pp. 1355\u20131387, October 1975.",
            "year": 1975
        },
        {
            "authors": [
                "T. Cover"
            ],
            "title": "A proof of the data compression theorem of Slepian and Wolf for ergodic sources (corresp.)",
            "venue": "IEEE Transactions on Information Theory, vol. 21, no. 2, pp. 226\u2013228, March 1975.",
            "year": 1975
        },
        {
            "authors": [
                "M.H. Yassaee",
                "M.R. Aref",
                "A. Gohari"
            ],
            "title": "Achievability proof via output statistics of random binning",
            "venue": "IEEE Transactions on Information Theory, vol. 60, no. 11, pp. 6760\u20136786, November 2014.",
            "year": 2014
        },
        {
            "authors": [
                "J. Muramatsu",
                "S. Miyake"
            ],
            "title": "Construction of codes for the wiretap channel and the secret key agreement from correlated source outputs based on the hash property",
            "venue": "IEEE Transactions on Information Theory, vol. 58, no. 2, pp. 671\u2013692, February 2012.",
            "year": 2012
        },
        {
            "authors": [
                "N. Sourlas"
            ],
            "title": "Spin glasses, error-correcting codes and finite-temperature decoding",
            "venue": "Europhysics Letters (EPL), vol. 25, no. 3, p. 159, January 1994.",
            "year": 1994
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n20 5.\n08 78\n2v 1\n[ cs\n.I T\n] 1\n8 M\nay 2\n02 2\nSecure Coding via Gaussian Random Fields Ali Bereyhi\u2217, Bruno Loureiro\u2020, Florent Krzakala\u2020, Ralf R. M\u00fcller\u2217, and Hermann Schulz-Baldes\u2021\n\u2217Institute for Digital Communications, Friedrich-Alexander Universit\u00e4t Erlangen-N\u00fcrnberg (FAU) \u2020Information, Learning and Physics Lab, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL)\n\u2021Mathematical Physics and Operator Algebras Group, Department of Mathematics, FAU ali.bereyhi@fau.de, bruno.loureiro@epfl.ch, florent.krzakala@epfl.ch, ralf.r.mueller@fau.de, schuba@mi.uni-erlangen.de\nAbstract\u2013Inverse probability problems whose generative models are given by strictly nonlinear Gaussian random fields show the all-or-nothing behavior: There exists a critical rate at which Bayesian inference exhibits a phase transition. Below this rate, the optimal Bayesian estimator recovers the data perfectly, and above it the recovered data becomes uncorrelated. This study uses the replica method from the theory of spin glasses to show that this critical rate is the channel capacity. This interesting finding has a particular application to the problem of secure transmission: A strictly nonlinear Gaussian random field along with random binning can be used to securely encode a confidential message in a wiretap channel. Our large-system characterization demonstrates that this secure coding scheme asymptotically achieves the secrecy capacity of the Gaussian wiretap channel.\nIndex Terms\u2014Nonlinear Gaussian random fields, informationtheoretic secrecy, replica method, decoupling principle."
        },
        {
            "heading": "I. PRELIMINARIES",
            "text": "Unlike linear models [1]\u2013[7], nonlinear models are sparsely studied in information theory. This follows from the fact that these models are more complex and seemly have a narrower scope of applications. They are however rather popular in physics; for instance, in the theory of spin glasses [8]\u2013[11]. Invoking connections between statistical mechanics and information theory, a few studies establish known nonlinear models in the theory of spin glasses to address informationtheoretic problems, such as channel coding and data encryption [12]\u2013[14]. This study brings light to the secrecy potential of nonlinear models."
        },
        {
            "heading": "A. Contributions and Related Work",
            "text": "The main contribution of this study is as follows: We show that the secrecy capacity of the Gaussian wiretap channel given in [15] is achieved by employing a strictly nonlinear Gaussian random field as the encoder. The motivation comes from a recent work by Fyodorov [14], where a Gaussian random field is used for signal encryption. In particular, Fyodorov shows that encryption via a purely quadratic Gaussian random field shows an asymptotic phase transition at a threshold signal-to-noise ratio (SNR), below which recovery via the method of leastsquares becomes uncorrelated. Our initial investigations in [16, Section V] shows that combining Fyodorov\u2019s encryption with a simple sphere coding technique can achieve a perfect secrecy\nThis work has been accepted for presentation in 2022 IEEE International Symposium on Information Theory (ISIT) in Espoo, Finland. The link to the final version in the Proceedings of ISIT will be available later.\nThis work was supported by the Emerging Talents Initiative (ETI) at FAU.\nrate close to the secret capacity of the wiretap channel. This interesting finding motivates a new coding scheme to achieve reliable and perfectly secure transmission over the Gaussian wiretap channel.\nIntuitively, the proposed encoder can be seen as a combination of Sourlas\u2019 coding [12] with the random linear binning technique [17]. Decoding is performed via a standard Bayesian decoder. Using the replica method, we show that the Bayesian decoder asymptotically exhibits the all-or-noting behavior [18]\u2013[20] when a strictly nonlinear Gaussian random field is used as the encoder. This finding is then used to show that the proposed coding scheme asymptotically achieves the secrecy capacity of the Gaussian wiretap channel."
        },
        {
            "heading": "B. Notation",
            "text": "Scalars, vectors and matrices are represented with non-bold, bold lower-case and bold upper-case letters, respectively. The transposed of A is indicated by AT. The Euclidean norm of x is denoted by \u2016x\u2016. For K-dimensional vectors x and y, we define the normalized inner-product as\n\u3008x;y\u3009 = xTy\nK . (1)\nThe notation log (\u00b7) indicates the natural logarithm, and E {\u00b7} denotes mathematical expectation. The real axis is shown by R. For sake of brevity, {1, . . . , N} and {N0, N0 + 1, . . . , N1} are abbreviated as [N ] and [N0 : N1], respectively. The capacity of a real Gaussian channel with SNR x is denoted by\nC (x) = 1\n2 log (1 + x) . (2)"
        },
        {
            "heading": "C. Gaussian Random Fields",
            "text": "Gaussian random fields are key components in this paper. We hence define them at this point: In a nutshell, a Gaussian random field is a randomized mapping whose output entries are Gaussian. The mapping is not necessarily linear, i.e. a random matrix, and can be of higher orders. It can hence be observed as an extension of Gaussian random matrices. The exact definition is given below.\nDefinition 1: The mapping V (\u00b7) : RK 7\u2192 RN is a Gaussian random field with covariance function \u03a6 (\u00b7) : R 7\u2192 R, if for any pair of vectors s1, s2 \u2208 R K , the entries of\nV (si) = [V1 (si) , . . . ,VN (si)] T , (3)\nfor i \u2208 {1, 2}, are distributed Gaussian and satisfy\nE {Vm (s1)Vn (s2)} = I {m = n}\u03a6 (\u3008s1; s2\u3009) , (4)\nfor n,m \u2208 [N ], with I {m=n} being the indicator function.\nA basic example of a Gaussian random field is the linear field with covariance function \u03a6 (u) = u. The Gaussian field in this example can be represented as V (s) = As, where A \u2208 R\nN\u00d7K is an independent and identically distributed (i.i.d.) Gaussian matrix whose entries are zero-mean with variance 1/K . More examples can be found in [16]."
        },
        {
            "heading": "II. STATEMENT OF MAIN RESULT",
            "text": "Consider a Gaussian wiretap channel in which a transmitter intends to securely send a message of K = NR bits to a legitimate receiver over an additive white Gaussian noise (AWGN) channel by N uses of the channel. An eavesdropper overhears the transmitted signal through an independent AWGN channel.\nLet M \u2208 [ 2NR ]\ndenote the secret message. The transmitter encodes M via a secure encoder fN (\u00b7) : [ 2NR ]\n7\u2192 RN into the codeword x = [x1, . . . , xN ] T, such that\n1\nN\nN \u2211\nn=1\nE { |xn| 2 } \u2264 P, (5)\nfor some average transmit power P . It then transmits the codeword over the AWGN channel using N subsequent transmission time intervals. The legitimate receiver therefore receives\ny = x+wB, (6)\nfor an i.i.d. Gaussian noise vector wB whose entries are zeromean with variance \u03c32B. The legitimate receiver employs the decoder gN (\u00b7) : RN 7\u2192 [ 2NR ]\nto estimate the secret message, i.e., M\u0302 = gN (y).\nThe eavesdropper overhears the transmitted sequence x over an independent AWGN channel and receives\nyE = x+wE, (7)\nfor i.i.d. Gaussian noise wE whose entries are zero-mean with variance \u03c32E. It is further assumed that the encoder and decoder are publicly known to all parties."
        },
        {
            "heading": "A. Reliable and Secure Transmission",
            "text": "The secret message M contains K = NR information bits and is transmitted within N channel uses. It is hence concluded that the transmission rate in this setting is R bits per channel use. We now focus on a sequence of encoder-decoder pairs indexed by N which transmit secret messages with rate R. The transmission is said to be reliable and secure with this encoderdecoder sequence if the following conditions are satisfied [21]:\n\u2022 The recovery error Pr{M 6= M\u0302} tends to zero as the dimension N grows large. \u2022 The information leakage to eavesdropper, i.e.,\nLN = 1\nN I (M ;yE) , (8)\ntends to zero as the dimension N grows large.\nThe secrecy capacity of the wiretap channel is defined as the maximum reliable and secure transmission rate. Using the random binning approach of Wyner [22], the secrecy capacity of this Gaussian wiretap channel is shown to be [15]\nCS =\n[\nC\n(\nP\n\u03c32B\n)\n\u2212 C\n(\nP \u03c32E\n)]+\n, (9)\nwhere [x]+ := max {0, x}."
        },
        {
            "heading": "B. Secure Coding via Gaussian Random Fields",
            "text": "Invoking Gaussian random fields, we now propose a secure coding scheme. Our main result shows that under some heuristic assumptions, this scheme achieves the secrecy capacity. The proposed scheme uses a strictly nonlinear Gaussian random field to securely encode the secret message. The decoder then recovers the message via the optimal Bayesian estimator.\nTo state the proposed coding scheme, let s \u2208 {\u00b11}K be the bipolar representation of the message M , i.e., each information bit of M is shown by \u00b11. For secure encoding, the transmitter follows the following steps:\n1) It generates at random\nK\u0303 =\n\u2308\nN\nlog 2 C\n(\nP \u03c32E\n)\u2309\n(10)\ni.i.d. uniform bipolar symbols, i.e., k = [k1, . . . , kK\u0303 ] T.\n2) It adds k as a prefix to s and finds s\u0303 as s\u0303 = \u03a0 [ kT, sT ]T\n, where \u03a0 is a (K + K\u0303)\u00d7 (K+ K\u0303) random permutation1 whose permuted vector s\u0303 has the following property: Let the \u2113-th bin of s\u0303 with size B = \u23081 +K/K\u0303\u2309 be\n[s\u0303] \u2113 = {s\u0303k : k \u2208 [(\u2113 \u2212 1)B + 1 : \u2113B]} . (11)\nThen, for every choice of \u2113 \u2208 [K\u0303], there exists only one symbol of k in [s\u0303]\n\u2113 .\n3) It determines the codeword as x = V (s\u0303), for a Gaussian field V (\u00b7) : RK+K\u0303 7\u2192 RN whose covariance function is \u03a6 (u) = Pu\u03bb for some \u03bb \u2265 3.\nFor recovery, the legitimate receiver applies minimum mean squared error (MMSE) estimation to recover the message. To this end, the legitimate receiver follows the following steps:\n1) It calculates the sufficient statistic r\u0303 \u2208 RK+K\u0303 from yB as r\u0303 = E {s\u0303|yB,V}. With uniform prior distribution, the MMSE estimator is given by\nr\u0303 = 1\nZ\n\u2211\nu\u2208{\u00b11}K+K\u0303\nu exp\n{\n\u2212 \u2016yB \u2212 V (u)\u2016\n2\n2\u03c32B\n}\n, (12)\nfor normalization Z defined as\nZ = \u2211\nu\u2208{\u00b11}K+K\u0303\nexp\n{\n\u2212 \u2016yB \u2212 V (u)\u2016\n2\n2\u03c32B\n}\n. (13)\n2) It sets r = \u03a0Tr\u0303, finds s\u0302k = sgn ( r K\u0303+k )\nfor k \u2208 [K] with sgn (\u00b7) being the sign operator, and finds M\u0302 from s\u0302.\n1One can see the connection between \u03a0 and the random binning technique [17], [23]; see also [24], [25] and references therein for more details on the random binning technique and its applications."
        },
        {
            "heading": "C. The Main Result",
            "text": "The main result of this study states that the proposed coding scheme achieves the secrecy capacity of the wiretap channel. We present this result explicitly below:\nResult 1: Consider the sequence {(fN , gN ) : N \u2208 Z}, where fN and gN denote the encoder and decoder in Section II-B, respectively. Set K = NCS/ log 2, where CS is the secrecy capacity of the wiretap channel. Then, the transmission via this\nsequence is asymptotically reliable and secure.\nProof. The proof is given in Section V.\nConsidering Result 1, it is worth mentioning few remarks:\n\u2022 We first note the constraint on the covariance of V (\u00b7), i.e., \u03bb \u2265 3. It indicates that the codewords are generated via a mapping whose total number of coefficients grows with the message length at least cubically. In general, using a Gaussian field with covariance function \u03a6 (u) = u\u03bb, the codewords are generated via an order \u03bb polynomial from a set of NK\u03bb coefficients. \u2022 The proposed scheme is randomized, as the mapping V (\u00b7) is generated at random. Nevertheless, unlike the classical random coding which generates all N2K components of the codebook at random, the proposed scheme uses NK\u03bb\nrandom coefficients to specify V (\u00b7). It then constructs the codewords from the messages using V (\u00b7). \u2022 The key property of the proposed scheme which leads to achieving the secrecy capacity of the wiretap channel is the strict non-linearity of the Gaussian field2. In fact, by adding a linear term to the encoding field, one can observe that the information leakage to the eavesdropper does not vanish asymptotically. This is justified by a rather known property of the linear model: Linear models always carry information about the model parameters3."
        },
        {
            "heading": "III. ASYMPTOTICS OF THE CODING SCHEME",
            "text": "The derivation of Result 1 relies on the asymptotic characterization of a class Bayesian algorithms used for unsupervised learning in nonlinear generative models. The detailed derivations are given in the extended manuscript [16]. In the sequel, we state a particular form of the generic result in [16] which describes the asymptotic properties of the decoder when it is employed to decode a message encoded via a Gaussian random field. This result is then utilized to sketch a proof for Result 1."
        },
        {
            "heading": "A. Asymptotic Characterization of the Bayesian Decoder",
            "text": "The statistics of the sufficient statistic r\u0303 are asymptotically described via the results4 of [16]. We illustrate the asymptotic characterization through the following setting: Consider a vector of uniform bipolar symbols s0 \u2208 {\u00b11}\nK which is mapped via a Gaussian random field V (\u00b7) into x0 \u2208 RN . The mapped vector x0 is observed as y0 = x0 + w0 for Gaussian noise w0 whose entries are zero-mean with variance \u03c320 . Let r0 be\n2This becomes clear later on. 3See [16, Section IV] for some discussions in this respect. 4The characterization in [16] invokes the replica method.\nthe optimal MMSE estimation of s0 from the observation y0 with side information V (\u00b7), i.e.,\nr0 = E {s0|y0,V} = \u2211\ns0\u2208{\u00b11} K\ns0p (s0|y0,V) , (14)\nwhere the posterior distribution p (s0|y0,V) is determined for the true prior belief on s0 and the true noise variance \u03c320 . From the asymptotic results of [16], we can derive the following metrics of this setting in the asymptotic regime, i.e., N,K \u2191 \u221e with bounded R = K/N :\n1) The asymptotic information rate which is defined as\nI (\u03c30) = lim N\u2191\u221e\n1\nN I (s0;y0|V) . (15)\n2) The asymptotic joint distribution of an encoded-decoded pair, i.e., (s0k, r0k) for k \u2208 [K].\nThe final expressions for these metrics are given in closed forms in terms of the so-called decoupled setting. In the sequel, we first define the decoupled setting and then give the closed-form expression for the above metrics."
        },
        {
            "heading": "B. Decoupled Setting",
            "text": "Corresponding to the vector-valued setting in Section III-A, we define the decoupled setting as follows: Consider the uniformly distributed s \u2208 {\u00b11}. This symbol is passed through an AWGN channel whose noise variance is controlled by the parameter m \u2208 [0, 1]. Namely, the observation is given by\ny (m) = s+ w \u221a\nE (m) , (16)\nwhere w is zero-mean and unit-variance Gaussian noise, and\nE (m) = \u03a6\u2032 (m)\nR (\u03c320 +\u03a6(1)\u2212 \u03a6 (m)) , (17)\nwith \u03a6 (\u00b7) denoting the covariance function of V (\u00b7). In this setting, the MMSE estimator of s is given by\nr (m) = tanh (E (m) y (m)) . (18)\nThe input-output mutual information, i.e.,\nID (m) = I (s; y (m)) , (19)\nis further given by\nID (m)=E (m)\u2212Ew\n{ log cosh ( E (m)+ \u221a E (m)w )} . (20)\nWe now define a new metric which is controlled by m: The energy function is defined as\nL (m) = RID (m) + CD (m) + (1\u2212m)C \u2032 D (m) , (21)\nfor the function CD (m) which is given by\nCD (m) = C\n(\n\u03a6 (1)\u2212 \u03a6 (m)\n\u03c320\n)\n. (22)\nProposition 1: Let m\u22c6 be the minimizer of the energy function L (m) over [0, 1]. Then, (s0k, r0k) for k \u2208 [K] converges in distribution to the decoupled pair (s, r (m\u22c6)), and the asymptotic information rate is given by I (\u03c30) = L (m \u22c6).\nProof. The proof is directly concluded from Corollary 1 and Proposition 2 in the extended manuscript [16]."
        },
        {
            "heading": "IV. ALL-OR-NOTHING PHENOMENON",
            "text": "The parameter m\u22c6 in Proposition 1 is often referred to as the overlap. This appellation comes from the fact that m\u22c6 gives the expected normalized inner product between s0 and r0: As m\u22c6 is a minimizer of the energy function5, we have L\u2032 (m\u22c6) = 0 as a necessary condition. This leads to\nm\u22c6 = Ew\n{ tanh ( \u221a E (m\u22c6)w + E (m\u22c6) )} , (23a)\n= E {r (m\u22c6) s} (a) = E {\u3008s0; r0\u3009} , (23b)\nwhere (a) follows from Proposition 1 considering the convergence of (s0k, r0k) to (s, r (m)) in distribution. As the result, m\u22c6 bounds the fraction of bipolar symbols in s0 which are correctly decoded after hard-thresholding6 r0.\nProposition 1 gives an interesting finding about the overlap. To illustrate this finding, we focus on the special form of fields used in the proposed coding scheme, i.e., a Gaussian field with covariance function \u03a6 (u) = Pu\u03bb. For these Gaussian fields, we use Proposition 1 to investigate the behavior of m\u22c6 against R. This leads to the following conclusions:\n\u2022 For \u03bb = 1, i.e., linear fields, the overlap starts from m\u22c6 = 1 at small rates, i.e., R \u2193 0, and continuously decreases by growth of R. It however never reaches zero, i.e., m\u22c6 6= 0 for any choice of R. \u2022 For \u03bb = 2, i.e., purely quadratic fields, the overlap starts from m\u22c6 = 1 at small rates, i.e., R \u2193 0, and shows a first-order phase transition at a critical rate R\u22c6 at which the overlap jumps from m\u22c6 = 1 to 0 6= m\u22c6 < 1 discontinuously. It then shows a second-order phase transition at a threshold rate RTh at which m\u22c6 = 0 for R \u2265 RTh. \u2022 For \u03bb \u2265 3, the overlap shows a first-order phase transition at the critical rate R\u22c6 at which the overlap jumps from m\u22c6 = 1 to m\u22c6 = 0 and remains zero for R \u2265 R\u22c6.\nThe detailed proof of the above findings is out of the scope of a conference paper and can be followed in [16, Section IV].\nThe above results lead to this conclusion: For \u03bb \u2265 3, the energy function L (m) has two local minima at m = 0 and m = 1 and a local maximum at some 0 < m0 < 1. For R < R\u22c6, the global minimum is at m = 1, leading to m\u22c6 = 1. This means that for R < R\u22c6, r0 perfectly recovers s0. For R \u2265 R\u22c6, the overlap is zero meaning that r0 and s0 are uncorrelated. This behavior is often called all-or-nothing phenomenon and is observed in various inference problems, e.g., see [18]\u2013[20]."
        },
        {
            "heading": "A. Heuristic Derivation of the Critical Rate R\u22c6",
            "text": "A rigorous derivation of the critical rate faces complications. However, using the all-or-noting phenomenon, the rate can be derived heuristically: Noting that the global minimum occurs at m = 0 or m = 1, one can compare the energy function at these two points.\nAs \u03a6 (0) = \u03a6\u2032 (0) = 0, we have L (0) = C ( P/\u03c320 )\n; however, an explicit calculation of the energy function at m = 1\n5L (m) is in fact the free energy of the corresponding spin glass; see [16]. 6Which is asymptotically tight.\nis not trivial. We hence use the following approximation: For x \u226b 0, we can approximately write log cosh (x) \u2248 x\u2212 log 2.\nNow, let us define random variable w\u0303 = E (1)+ \u221a\nE (1)w. Since w\u0303 is a Gaussian random variable with mean and variance E (1) > 0, the probability of w\u0303 being close to zero or negative is negligible. We hence use the above approximation and write\nEw\u0303 {log cosh (w\u0303)} \u2248 E {w\u0303} \u2212 log 2 = E (1)\u2212 log 2. (24)\nHence L (1) \u2248 R log 2. This leads to the conclusion that\nR\u22c6 = 1\nlog 2 C\n(\nP \u03c320\n)\n. (25)\nThe all-or-nothing phenomenon is further observed in terms of the information rate: At R\u22c6, the information rate changes from I (\u03c30) = R log 2 (at m\u22c6 = 1) to I (\u03c30) = C ( P/\u03c320 )\n(at m\u22c6 = 0). In the former case, the end-to-end channel is noiseless and hence the information rate equals to the entropy rate of the message; however, by the phase transition, the end-to-end channel becomes noisy and the information rate is restricted by the channel capacity. This finding indicates that by using a strictly nonlinear Gaussian field7 as the encoder and an MMSE decoder, the coding scheme shows a sharp phase transition at the channel capacity. This result confirms the earlier findings reported by Sourlas in [12] and [26]."
        },
        {
            "heading": "B. Numerical Validations",
            "text": "To validate our heuristic derivations, we numerically determine the overlap and the asymptotic information rate, given by Proposition 1, and compare them with the derivations in Section IV-A. To this end, we set \u03c320 = 0.1 and P = 1 and plot the overlap and information rate against R for various choices of \u03bb. The results are shown in Figs. 1 and 2. As the figures show, for \u03bb = 3 the first-order phase transition occurs exactly at the heuristically derived rate. By plotting the figures for larger choices of \u03bb, one can observe that the figures are not numerically distinguishable from the one given for \u03bb = 3; see [16]. We hence conjecture that for \u03bb \u2265 3 the overlap jumps at R\u22c6 from exactly being one to exactly being zero. A rigorous proof of this conjecture is however skipped at this point."
        },
        {
            "heading": "V. DERIVATION OF THE MAIN RESULT",
            "text": "We now invoke our asymptotic derivations to sketch a proof for Result 1. To this end, we consider the proposed coding scheme in Section II-B and show that it leads to a reliable and secure transmission, when we set R = K/N = CS/ log 2. For brevity, we focus on scenarios with non-zero secrecy rates, i.e., \u03c32B > \u03c3 2 E. Noting that the proof invokes derivations based on the replica method, it is natural that it contains some heuristics. For brevity, we use the notation Ci=C ( P/\u03c32 i ) for i \u2208 {E,B}.\n7More precisely, a Gaussian random field whose covariance function has a polynomial expansion with cubic and/or larger terms."
        },
        {
            "heading": "A. Proof of Reliability",
            "text": "Noting that M\u0302 is specified by hard-thresholding of the last K symbols of r, we have Pr{M 6= M\u0302} \u2264 Pr {s\u0303 6= sgn (r\u0303)}. We now consider the end-to-end channel from s\u0303 to sgn (r\u0303) and model it as a binary symmetric channel (BSC) whose flipping probability is given by\nf = 1\nK + K\u0303\nK+K\u0303 \u2211\nk=1\nI {s\u0303k 6= sgn (r\u0303k)} , (26)\nwhere I {\u00b7} denotes the indicator function. As we transmit uncoded over this end-to-end channel, the transmission is considered reliable if f = 0. As the derivation of f for a particular realization of the Gaussian field is not trivial, we invoke the averaging trick and find the average of f over all realizations of the Gaussian field used at the encoder. We start the derivation by noting that \u3008s\u0303; sgn (r\u0303)\u3009 = 1\u22122f . On the other hand, we have\n\u3008s\u0303; sgn (r\u0303)\u3009 = 1\nK + K\u0303\nK+K\u0303 \u2211\nk=1\nI {s\u0303k = sgn (r\u0303k)} \u2212 f. (27)\nNoting that |\u0303rk| \u2264 1, we can write\n\u3008s\u0303; sgn (r\u0303)\u3009 \u2265 1\nK + K\u0303\nK+K\u0303 \u2211\nk=1\ns\u0303k r\u0303k \u2212 f = \u3008s\u0303; r\u0303\u3009 \u2212 f. (28)\nThis concludes that f \u2264 1\u2212 \u3008s\u0303; r\u0303\u3009. From Proposition 1, we know that E {\u3008s\u0303; r\u0303\u3009} in the largesystem limit is determined by the overlap8. We hence conclude that in the asymptotic limit, E {f} \u2264 1 \u2212m\u22c6. As the result, m\u22c6 = 1 guarantees the existence of a Gaussian field by which a reliable transmission is possible.\nThe all-or-nothing phenomenon of Gaussian fields with \u03bb \u2265 3 indicates that m\u22c6 = 1 is achievable when R + CE/log 2 \u2264 CB/log 2. This proves the reliability for any R \u2264 CS/ log 2.\n8This is shown at the beginning of Section IV."
        },
        {
            "heading": "B. Proof of Security",
            "text": "We start the security proof by writing9\nI (s;yE|V) = I (s\u0303;yE|V)\u2212 I (k;yE|s,V) . (29)\nSince for R > 0, R+CE/log 2 > CE/log 2, we conclude that\nlim N\u2191\u221e\n1\nN I (s\u0303;yE|V) = CE, (30)\nbased on the all-or-nothing phenomenon. To calculate the second term, we first note that\nI (k;yE|s,V) = I (s\u0303;yE|s,V) . (31)\nThe right hand side is the mutual information in a genie-aided setting in which the eavesdropper recovers s\u0303 while the message s is revealed to it: Let s = v be a particular realization of the message being known to the eavesdropper. We note that after permutation there exists only one unknown bipolar symbol in each bin of s\u0303, i.e., the symbol of k available in the bin. Thus, each bin describes a binary unknown in the inference problem. The effective transmission rate over the channel from s\u0303 to yE in this case is K\u0303/N = CE/ log 2. We hence use Proposition 1 and write10\nlim N\u2191\u221e\n1\nN I (s\u0303;yE|s = v,V) = CE. (32)\nAs the right hand side does not depend on v, we have\nlim N\u2191\u221e\n1\nN I (s\u0303;yE|s,V) = CE. (33)\nThis concludes concludes the security proof.\n9A more precise notation is to also include the random permutation in the condition, e.g., I (s;yE|\u03a0,V); however, we drop it for brevity.\n10More precisely, one needs to employ an extended version of Proposition 1 with a generic input distribution; however, as s\u0303 is discrete, one concludes the validity of the argument using the fact that the information rate only depends on the distribution. More discussions can be found in [16]."
        },
        {
            "heading": "VI. CONCLUSIONS",
            "text": "Bayesian estimation over a channel with AWGN whose generative model is described by a strictly-nonlinear Gaussian random field shows a first-order phase transition at the capacity of the AWGN channel: By setting the rate arbitrarily close to the channel capacity, perfect recovery via MMSE estimation is asymptotically guaranteed; however, by exceeding the channel capacity, the Bayesian estimation becomes uncorrelated. This all-or-nothing phenomenon is used to establish a secure communication in a Gaussian wiretap channel. Our investigations demonstrate that a coding scheme, whose encoder constructs the codewords by passing the message through a Gaussian random field, asymptotically achieves the secrecy capacity of the Gaussian wiretap channel.\nA natural direction for future work is to develop an approximate message passing algorithm for Bayesian decoding. Using such implementation, the performance of the proposed scheme can be further investigated for finite-length transmissions. The work in this direction is currently ongoing."
        }
    ],
    "title": "Secure Coding via Gaussian Random Fields",
    "year": 2022
}