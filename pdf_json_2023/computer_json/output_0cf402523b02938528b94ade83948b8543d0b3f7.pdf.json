{
    "abstractText": "Point cloud analysis faces computational system overhead, limiting its application on mobile or edge devices. Directly employing small models may result in a significant drop in performance since it is difficult for a small model to adequately capture local structure and global shape information simultaneously, which are essential clues for point cloud analysis. This paper explores feature distillation for lightweight point cloud models. To mitigate the semantic gap between the lightweight student and the cumbersome teacher, we propose bidirectional knowledge reconfiguration (BKR) to distill informative contextual knowledge from the teacher to the student. Specifically, a topdown knowledge reconfiguration and a bottom-up knowledge reconfiguration are developed to inherit diverse local structure information and consistent global shape knowledge from the teacher, respectively. However, due to the farthest point sampling in most point cloud models, the intermediate features between teacher and student are misaligned, deteriorating the feature distillation performance. To eliminate it, we propose a feature mover\u2019s distance (FMD) loss based on optimal transportation, which can measure the distance between unordered point cloud features effectively. Extensive experiments conducted on shape classification, part segmentation, and semantic segmentation benchmarks demonstrate the universality and superiority of our method.",
    "authors": [
        {
            "affiliations": [],
            "name": "Peipei Li"
        },
        {
            "affiliations": [],
            "name": "Xing Cui"
        },
        {
            "affiliations": [],
            "name": "Yibo Hu"
        },
        {
            "affiliations": [],
            "name": "Man Zhang"
        },
        {
            "affiliations": [],
            "name": "Ting Yao"
        }
    ],
    "id": "SP:7d51b064c4452d1e2445fc6fce5e9b72a70af62c",
    "references": [
        {
            "authors": [
                "Y. Zhou",
                "O. Tuzel"
            ],
            "title": "Voxelnet: End-to-end learning for point cloud based 3d object detection",
            "venue": "CVPR, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "H. Su",
                "S. Maji",
                "E. Kalogerakis",
                "E. Learned-Miller"
            ],
            "title": "Multi-view convolutional neural networks for 3d shape recognition",
            "venue": "ICCV, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "C.R. Qi",
                "H. Su",
                "K. Mo",
                "L.J. Guibas"
            ],
            "title": "Pointnet: Deep learning on point sets for 3d classification and segmentation",
            "venue": "CVPR, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "L. Li",
                "Z. Li",
                "S. Liu",
                "H. Li"
            ],
            "title": "Frame-level rate control for geometrybased lidar point cloud compression",
            "venue": "TMM, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "C.-H. Wu",
                "C.-F. Hsu",
                "T.-K. Hung",
                "C. Griwodz",
                "W.T. Ooi",
                "C.-H. Hsu"
            ],
            "title": "Quantitative comparison of point cloud compression algorithms with pcc arena",
            "venue": "TMM, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "C.R. Qi",
                "L. Yi",
                "H. Su",
                "L.J. Guibas"
            ],
            "title": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space",
            "venue": "NeurIPS, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "Y. Shen",
                "C. Feng",
                "Y. Yang",
                "D. Tian"
            ],
            "title": "Mining point cloud local structures by kernel correlation and graph pooling",
            "venue": "CVPR, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Liu",
                "B. Fan",
                "G. Meng",
                "J. Lu",
                "S. Xiang",
                "C. Pan"
            ],
            "title": "Densepoint: Learning densely contextual representation for efficient point cloud processing",
            "venue": "ICCV, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Choe",
                "C. Park",
                "F. Rameau",
                "J. Park",
                "I.S. Kweon"
            ],
            "title": "Pointmixer: Mlp-mixer for point cloud understanding",
            "venue": "ECCV, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "W. Wu",
                "Z. Qi",
                "L. Fuxin"
            ],
            "title": "Pointconv: Deep convolutional networks on 3d point clouds",
            "venue": "CVPR, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "S. Qiu",
                "S. Anwar",
                "N. Barnes"
            ],
            "title": "Geometric back-projection network for point cloud classification",
            "venue": "TMM, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "H. Zhao",
                "L. Jiang",
                "J. Jia",
                "P.H. Torr",
                "V. Koltun"
            ],
            "title": "Point transformer",
            "venue": "ICCV, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "X.-F. Han",
                "Y.-F. Jin",
                "H.-X. Cheng",
                "G.-Q. Xiao"
            ],
            "title": "Dual transformer for point cloud analysis",
            "venue": "TMM, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M. Kusner",
                "Y. Sun",
                "N. Kolkin",
                "K. Weinberger"
            ],
            "title": "From word embeddings to document distances",
            "venue": "ICLR, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "C. Chen",
                "S. Qian",
                "Q. Fang",
                "C. Xu"
            ],
            "title": "Hapgn: Hierarchical attentive pooling graph network for point cloud segmentation",
            "venue": "TMM, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "W. Wu",
                "Q. Shan",
                "L. Fuxin"
            ],
            "title": "Pointconvformer: Revenge of the pointbased convolution",
            "venue": "arXiv preprint arXiv:2208.02879, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Q. Hu",
                "B. Yang",
                "L. Xie",
                "S. Rosa",
                "Y. Guo",
                "Z. Wang",
                "N. Trigoni",
                "A. Markham"
            ],
            "title": "Randla-net: Efficient semantic segmentation of largescale point clouds",
            "venue": "CVPR, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Wang",
                "Y. Sun",
                "Z. Liu",
                "S.E. Sarma",
                "M.M. Bronstein",
                "J.M. Solomon"
            ],
            "title": "Dynamic graph cnn for learning on point clouds",
            "venue": "TOG, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "H. Zhou",
                "Y. Feng",
                "M. Fang",
                "M. Wei",
                "J. Qin",
                "T. Lu"
            ],
            "title": "Adaptive graph convolution for point cloud analysis",
            "venue": "ICCV, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "G. Hinton",
                "O. Vinyals",
                "J. Dean"
            ],
            "title": "Distilling the knowledge in a neural network",
            "venue": "NeurIPSW, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "P.K. Sharma",
                "A. Abraham",
                "V.N. Rajendiran"
            ],
            "title": "A generalized zeroshot quantization of deep convolutional neural networks via learned weights statistics",
            "venue": "TMM, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Hao",
                "Y. Luo",
                "Z. Wang",
                "H. Hu",
                "J. An"
            ],
            "title": "Cdfkd-mfs: Collaborative data-free knowledge distillation via multi-level feature sharing",
            "venue": "TMM, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "L. Zhang",
                "D. Du",
                "C. Li",
                "Y. Wu",
                "T. Luo"
            ],
            "title": "Iterative knowledge distillation for automatic check-out",
            "venue": "TMM, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "X. Wu",
                "R. He",
                "Y. Hu",
                "Z. Sun"
            ],
            "title": "Learning an evolutionary embedding via massive knowledge distillation",
            "venue": "IJCV, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. She",
                "Y. Hu",
                "H. Shi",
                "J. Wang",
                "Q. Shen",
                "T. Mei"
            ],
            "title": "Dive into ambiguity: Latent distribution mining and pairwise uncertainty estimation for facial expression recognition",
            "venue": "CVPR, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C. Yang",
                "H. Zhou",
                "Z. An",
                "X. Jiang",
                "Y. Xu",
                "Q. Zhang"
            ],
            "title": "Cross-image relational knowledge distillation for semantic segmentation",
            "venue": "CVPR, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "D. Ji",
                "H. Wang",
                "M. Tao",
                "J. Huang",
                "X.-S. Hua",
                "H. Lu"
            ],
            "title": "Structural and statistical texture knowledge distillation for semantic segmentation",
            "venue": "CVPR, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "X. Qu",
                "C. Ding",
                "X. Li",
                "X. Zhong",
                "D. Tao"
            ],
            "title": "Distillation using oracle queries for transformer-based human-object interaction detection",
            "venue": "CVPR, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "G. Li",
                "X. Li",
                "Y. Wang",
                "S. Zhang",
                "Y. Wu",
                "D. Liang"
            ],
            "title": "Knowledge distillation for object detection via rank mimicking and predictionguided feature imitation",
            "venue": "AAAI, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J. Gou",
                "B. Yu",
                "S.J. Maybank",
                "D. Tao"
            ],
            "title": "Knowledge distillation: A survey",
            "venue": "IJCV, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "B. Zhao",
                "Q. Cui",
                "R. Song",
                "Y. Qiu",
                "J. Liang"
            ],
            "title": "Decoupled knowledge distillation",
            "venue": "CVPR, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A. Romero",
                "N. Ballas",
                "S.E. Kahou",
                "A. Chassang",
                "C. Gatta",
                "Y. Bengio"
            ],
            "title": "Fitnets: Hints for thin deep nets",
            "venue": "ICLR, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "Z. Huang",
                "N. Wang"
            ],
            "title": "Like what you like: Knowledge distill via neuron selectivity transfer",
            "venue": "arXiv preprint arXiv:1707.01219, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "D. Chen",
                "J.-P. Mei",
                "H. Zhang",
                "C. Wang",
                "Y. Feng",
                "C. Chen"
            ],
            "title": "Knowledge distillation with the reused teacher classifier",
            "venue": "CVPR, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Chen",
                "S. Wang",
                "J. Liu",
                "X. Xu",
                "F. de Hoog",
                "Z. Huang"
            ],
            "title": "Improved feature distillation via projector ensemble",
            "venue": "NeurIPS, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Zagoruyko",
                "N. Komodakis"
            ],
            "title": "Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer",
            "venue": "ICLR, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "F. Tung",
                "G. Mori"
            ],
            "title": "Similarity-preserving knowledge distillation",
            "venue": "ICCV, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "P. Chen",
                "S. Liu",
                "H. Zhao",
                "J. Jia"
            ],
            "title": "Distilling knowledge via knowledge review",
            "venue": "CVPR, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "D. Chen",
                "J.-P. Mei",
                "Y. Zhang",
                "C. Wang",
                "Z. Wang",
                "Y. Feng",
                "C. Chen"
            ],
            "title": "Cross-layer distillation with semantic calibration",
            "venue": "AAAI, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Rubner",
                "C. Tomasi",
                "L.J. Guibas"
            ],
            "title": "The earth mover\u2019s distance as a metric for image retrieval",
            "venue": "IJCV, 2000.",
            "year": 2000
        },
        {
            "authors": [
                "M. Cuturi"
            ],
            "title": "Sinkhorn distances: Lightspeed computation of optimal transport",
            "venue": "NeurIPS, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "H. Phan",
                "A. Nguyen"
            ],
            "title": "Deepface-emd: Re-ranking using patch-wise earth mover\u2019s distance improves out-of-distribution face identification",
            "venue": "CVPR, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K.D. Doan",
                "P. Yang",
                "P. Li"
            ],
            "title": "One loss for quantization: Deep hashing with discrete wasserstein distributional matching",
            "venue": "CVPR, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Zhang",
                "Y. Liu",
                "C. Han",
                "H. Shi",
                "T. Guo",
                "B. Zhou"
            ],
            "title": "Petsgan: Rethinking priors for single image generation",
            "venue": "AAAI, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "C. Zhang",
                "Y. Cai",
                "G. Lin",
                "C. Shen"
            ],
            "title": "Deepemd: Few-shot image classification with differentiable earth mover\u2019s distance and structured classifiers",
            "venue": "CVPR, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "P. Mandikal",
                "V.B. Radhakrishnan"
            ],
            "title": "Dense 3d point cloud reconstruction using a deep pyramid network",
            "venue": "WACV, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Chen",
                "Y.P. Liu",
                "R. Peng",
                "A. Ramaswami"
            ],
            "title": "Exponential convergence of sinkhorn under regularization scheduling",
            "venue": "arXiv preprint arXiv:2207.00736, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "N. Bonneel",
                "J. Rabin",
                "G. Peyr\u00e9",
                "H. Pfister"
            ],
            "title": "Sliced and radon wasserstein barycenters of measures",
            "venue": "JMIV, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "K. Nguyen",
                "N. Ho",
                "T. Pham",
                "H. Bui"
            ],
            "title": "Distributional slicedwasserstein and applications to generative modeling",
            "venue": "ICLR, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "K. Fatras",
                "Y. Zine",
                "R. Flamary",
                "R. Gribonval",
                "N. Courty"
            ],
            "title": "Learning with minibatch wasserstein: asymptotic and gradient properties",
            "venue": "arXiv preprint arXiv:1910.04091, 2019.",
            "year": 1910
        },
        {
            "authors": [
                "K. Nguyen",
                "D. Nguyen",
                "Q. Nguyen",
                "T. Pham",
                "H. Bui",
                "D. Phung",
                "T. Le",
                "N. Ho"
            ],
            "title": "On transportation of mini-batches: A hierarchical approach",
            "venue": "ICML, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "N. Kolkin",
                "J. Salavon",
                "G. Shakhnarovich"
            ],
            "title": "Style transfer by relaxed optimal transport and self-similarity",
            "venue": "ICCV, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Yim",
                "D. Joo",
                "J. Bae",
                "J. Kim"
            ],
            "title": "A gift from knowledge distillation: Fast optimization, network minimization and transfer learning",
            "venue": "CVPR, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. Guo",
                "B. Fan",
                "Q. Zhang",
                "S. Xiang",
                "C. Pan"
            ],
            "title": "Augfpn: Improving multi-scale feature learning for object detection",
            "venue": "CVPR, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Liu",
                "L. Qi",
                "H. Qin",
                "J. Shi",
                "J. Jia"
            ],
            "title": "Path aggregation network for instance segmentation",
            "venue": "CVPR, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "X. Li",
                "W. Wang",
                "X. Hu",
                "J. Yang"
            ],
            "title": "Selective kernel networks",
            "venue": "CVPR, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Hu",
                "L. Shen",
                "G. Sun"
            ],
            "title": "Squeeze-and-excitation networks",
            "venue": "CVPR, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "E. Ricci",
                "G. Zen",
                "N. Sebe",
                "S. Messelodi"
            ],
            "title": "A prototype learning framework using emd: Application to complex scenes analysis",
            "venue": "TPAMI, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "J. Wagner",
                "B. Ommer"
            ],
            "title": "Efficient clustering earth mover\u2019s distance",
            "venue": "ACCV, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "I. Lang",
                "A. Manor",
                "S. Avidan"
            ],
            "title": "Samplenet: Differentiable point cloud sampling",
            "venue": "CVPR, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Wu",
                "S. Song",
                "A. Khosla",
                "F. Yu",
                "L. Zhang",
                "X. Tang",
                "J. Xiao"
            ],
            "title": "3d shapenets: A deep representation for volumetric shapes",
            "venue": "CVPR, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "L. Yi",
                "V.G. Kim",
                "D. Ceylan",
                "I.-C. Shen",
                "M. Yan",
                "H. Su",
                "C. Lu",
                "Q. Huang",
                "A. Sheffer",
                "L. Guibas"
            ],
            "title": "A scalable active framework for region annotation in 3d shape collections",
            "venue": "TOG, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "I. Armeni",
                "O. Sener",
                "A.R. Zamir",
                "H. Jiang",
                "I. Brilakis",
                "M. Fischer",
                "S. Savarese"
            ],
            "title": "3d semantic parsing of large-scale indoor spaces",
            "venue": "CVPR, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "B. Heo",
                "J. Kim",
                "S. Yun",
                "H. Park",
                "N. Kwak",
                "J.Y. Choi"
            ],
            "title": "A comprehensive overhaul of feature distillation",
            "venue": "ICCV, 2019. JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 11",
            "year": 2019
        },
        {
            "authors": [
                "M. Ji",
                "B. Heo",
                "S. Park"
            ],
            "title": "Show, attend and distill: Knowledge distillation via attention-based feature matching",
            "venue": "AAAI, 2021.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u20143D Point Cloud Analysis, Feature Distillation, Earth Mover\u2019s Distance.\nI. INTRODUCTION\nW ITH the popularity of 3D sensing devices, 3D data arewidely used in many applications, such as autonomous driving, robotics, and virtual reality. Among all kinds of 3D data forms, point clouds are considered a simple but efficient representation. To process irregular, unordered, and unstructured point clouds, early works transform point clouds into regular voxels [1] or multiview images [2]. However, these methods lose rich geometric structure. Since the success of PointNet [3], processing point clouds directly has been the dominant solution for 3D point cloud analysis [4], [5]. The subsequent methods, e.g., PointNet++ [6], KCNet [7] and DensePoint [8] have achieved significant improvements in point cloud classification and segmentation tasks. These methods can be divided into three categories. 1) MLP-based\nPeipei Li, Xing Cui and Man Zhang are with the School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing 100876, China. (e-mail: lipeipei@bupt.edu.cn; cuixing@bupt.edu.cn; zhangman@bupt.edu.cn).\nTing Yao and Tao Mei are with HiDream.ai, Beijing, China. (e-mail: tingyao.ustc@gmail.com; tmei@live.com).\nCorresponding author: Yibo Hu. (e-mail: huyibo871079699@gmail.com). This work was done during Xing Cui\u2019s internship and Yibo Hu\u2019s working\nin JD AI Research.\nmethods [6], [9] treat each point independently and map points into high-dimensional features. 2) CNN-based methods [10], [11] design convolution kernels to capture geometric topologies. 3) Transformer-based methods [12], [13] take advantage of a transformer to extract long-range information.\nDespite these advancements, there are still some practical challenges. One is the computational overhead of the system. With the need for applications on mobile or edge devices, point cloud analysis with a small model size, light computation cost, and high performance has attracted much attention. However, current point cloud analysis methods often depend on cumbersome models with expensive computations. For example, PointTransformer [12] requires more than 18.6 GFLOPs on the ModelNet40 dataset when 1024 points are sampled as input. Another key challenge is the irregularity of point clouds, making it difficult to represent discriminative semantic features for elusive shapes. Some methods [3], [7] learn directly from irregular point clouds and sacrifice complexity for effectiveness. Other methods [6], [8] attempt to make full use of the contextual information, including both the global shape and the local structure representations.\nTo address the above challenges, in this paper, we investigate lightweight point cloud analysis from the perspective of feature distillation, where the performance of a lightweight student network is improved by transferring informative knowledge from the intermediate features of a cumbersome teacher network. As illustrated in Table II, conventional knowledge distillation algorithms show limited performance in point clouds since the diverse local structure and global shape information of the point cloud are not fully explored during distillation. To solve this problem, we propose a novel bidirectional knowledge reconfiguration (BKR) mechanism for point cloud feature distillation. Specifically, a top-down knowledge reconfiguration and a bottom-up knowledge reconfiguration are designed, where the former is developed for inheriting diverse local structure information from the teacher, and the latter is employed to absorb high-level global shape knowledge from the teacher. In addition, we also design a residual connection to encourage distilling knowledge from the same level. Therefore, BKR mitigates the semantic gap between lightweight students and cumbersome teachers. Additionally, BKR inherits contextual knowledge from the teacher to all the scales of the student. In this way, each semantic level of the student network can simultaneously learn contextual information from the teacher network with both the local structure and the global shape knowledge.\n0000\u20130000/00$00.00 \u00a9 2021 IEEE\nar X\niv :2\n31 0.\n05 12\n5v 1\n[ cs\n.C V\n] 8\nO ct\n2 02\n3\nFurthermore, 3D point clouds are discrete and unordered. Generally, farthest point sampling (FPS) is employed in most point cloud analysis models [6], [10], [12] to reduce the resolution of the point cloud. However, the randomness of FPS results in a misalignment between the intermediate features of the teacher and student, which may further lead to inferior or even destroyed distillation performance. Inspired by optimal transportation theory [14], we propose feature mover\u2019s distance (FMD) to measure the discrepancy between misaligned teacher and student features. Specifically, to exploit the local structure information, we divide the transportation task into several subproblems where each subproblem focuses on a local area. We further propose a distance-based transportation strategy that approximates the least-expensive transportation flow to simplify the solving procedure of the transportation problem. Extensive experiments are conducted on several benchmarks, demonstrating the effectiveness and the universality of the proposed method. To summarize, our contributions are fourfold:\n\u2022 We design a new feature distillation method for lightweight point cloud analysis: a universal knowledge transfer framework for various point cloud models. \u2022 Bidirectional knowledge reconfiguration (BKR) is proposed to transfer both the low-level structure knowledge and the high-level shape information from the teacher to all the semantic levels of the student. \u2022 Since there exists a potential position inconsistency in point cloud features caused by the point sampling operation, the feature mover\u2019s distance (FMD) is designed to align the features between the teacher and student. \u2022 Our method significantly outperforms the previous distillation strategies on point cloud analysis, demonstrating the effectiveness and universality of our framework."
        },
        {
            "heading": "II. RELATED WORK",
            "text": "In this section, we briefly review existing works related to our method, including point-based classification and segmentation, model compression via knowledge distillation and earth mover\u2019s distance."
        },
        {
            "heading": "A. Point-based Classification and Segmentation",
            "text": "Methods on point-based classification and segmentation can be divided into three categories: MLP-based [3], [6], [9], CNN-based [10], [11], [15] and transformer-based [12], [15], [16]. PointNet [3] pioneers MLP-based point cloud classification and segmentation. It utilizes MLP to map points to highdimensional features and aggregates global features through max pooling, thereby extracting permutation invariant features. However, it fails to capture local structures and ignores finegrained patterns. To solve this problem, PointNet++ [6] designs a hierarchical structure to combine features from multiple scales. Although PointNet++ achieves better performance, it still has limitations in information extraction due to the asymmetric structure. To counter this, PointMixer [9] proposes a universal set operator to build a symmetric architecture.\nAnother network, RandLA-Net [17], improves the efficiency of point cloud processing by using random point sampling instead of point selection.\nHowever, those MLP-based methods only process points individually, ignoring the geometry structure information. To counter this, some researchers intend to design convolution operators on point clouds. DGCNN [18] recovers the topological information of the point cloud via a graph and uses EdgeConv to capture features over a long range. PointConv [10] focuses on nonuniform sampling point clouds, a discrete approximation of a continuous convolution. To learn relationships in point clouds, DensePoint [8] employs relation-shape convolution and builds a dense connection structure to extract dense contextual representations. In contrast, AdaptConv [19] explores an adaptive kernel generated from a pair of points.\nMore recently, transformer-based methods have been proposed for effective point cloud feature learning. Point transformer [12] explores how to extract long-distance relationships in large scenes by developing a self-attention layer for point cloud processing. Another network, DTNet [13], aggregates pointwise and channelwise self-attention models simultaneously for better feature representation. Although the above methods show good performance, they all ignore the memory and computational costs."
        },
        {
            "heading": "B. Model Compression via Knowledge Distillation",
            "text": "Knowledge distillation [20] is a model compression technique that has been widely applied in image processing, such as image classification [21]\u2013[23], face analysis [24], [25], semantic segmentation [26], [27] and object detection [28], [29]. Existing KD methods can be categorized into different categories [30]. Based on the number of levels where the distillation occurs, we divide knowledge distillation into singlelevel methods and multi-level methods.\nFor single-level methods, the model distills knowledge only between certain layers of the network. Among them, KD [20] minimizes the KL divergence between the last logit outputs of the teacher and the student networks. Furthermore, DKD [31] improves the flexibility of logit distillation by formulating distillation loss into a target class term and a non-target term. Recently, many works have focused on optimizing the distillation process via intermediate representations. For example, FitNet [32] utilizes intermediate features as hints to train a deeper and thinner student. NST [33] reviews the distributions of neuron selectivity and matches the distribution between the teacher and student. SimKD [34] designs a simple soft target distillation technique and reuses the classifier layer to narrow the performance gap. PEFD [35] observes the positive effect of the projector in feature distillation. Therefore, an ensemble of projectors is introduced to improve the performance.\nFor multi-level methods, knowledge is distilled for multiple layers of the network. AT [36] designs several methods for transferring attention maps between the teacher and student. SP [37] distills knowledge by preserving the pairwise similarities, which utilizes the pairwise activation similarities within each minibatch to supervise the distillation process. Recent works, ReviewKD [38] and SemCKD [39], further utilize the\nintermediate features of the teacher model by exploring multilayer knowledge. Contrary to the aforementioned approaches that are designed for image processing, we introduce knowledge distillation to point cloud analysis aiming at transferring the diverse local structure information and the global shape knowledge from the intermediate point cloud features of a cumbersome teacher to a lightweight student."
        },
        {
            "heading": "C. Earth Mover\u2019s Distance",
            "text": "Earth mover\u2019s distance (EMD) [40] is proposed to measure the distance between two sets of weighted objects or probability distributions. It has the form of an optimal transportation problem and is defined as the transportation cost under the least-expensive transportation flow. Specifically, let Fr = {( F 1r , s1 ) , ..., ( FNr , sN )} be a set of sources consisting of N pairs, where F ir and si denote the i-th source feature and its corresponding weight, respectively. Let Ft = {( F 1t , t1 ) , ..., ( FNt , tN )} be a set of destinations, where F jt and tj denote the j-th target feature and its corresponding weight, respectively. The ground distance between F ir and F j t is denoted by di,j . The goal of the transportation problem is to find the least-expensive flow \u03a0 = (\u03c0ij) \u2208 RN\u00d7N from Fr to Fs. The transportation problem can be formulated as a linear programming problem:\nEMD (Fr, Ft) = min \u03a0\u22650 \u2211 i,j di,j\u03c0i,j ,\nsubject to \u2211 j\n\u03c0i,j = si, i \u2208 [1, N ] ,\u2211 i \u03c0i,j = tj , j \u2208 [1, N ] .\n(1)\nThen, the least-expensive transportation flow can be achieved with the help of linear programming algorithms, such as the Sinkhorn algorithm [41].\nRecently, EMD has been widely used in image processing [42]\u2013[44]. For example, DeepEMD [45] computes the EMD between dense image features to represent the image distance. DeepFace-EMD [42] reranks face identification results with EMD to improve out-of-distribution generalization. DensePCR [46] predicts the low-resolution point cloud via the EMD loss to measure the consistency of two point sets.\nDespite its effectiveness, EMD is a computationally intensive formulation that requires considerable time and memory. To alleviate this problem, EXSinkhorn [47] adds an entropic regularization [41] and adaptively doubles the regularization parameter. SW [48] and its variants [49] characterize high-dimensional probability distributions into onedimensional space to accelerate the calculation. In addition, some works [49]\u2013[51] explore minibatch solutions to reduce the memory and computational cost. BoMb-OT [49] proposes optimal coupling to consider the relationship between minibatches, which approximates the original transportation strategy and constructs a good global mapping. Recently, mPOT [51] utilized partial optimal transportation to solve the misspecified mapping problem.\nHowever, these approaches still need to solve complex linear programming problems to find the optimal transportation\nflow. The computational cost is O ( max (m,n) 3 )\n, which is untenable for the gradient descent-based method. REMD [14], [52] solves this problem by relaxing the optimal transportation problem and removing one of the two constraints:\nRFr (Fr, Ft) = min \u03a0\u22650 \u2211 i,j di,j\u03c0i,j s.t. \u2211 j \u03c0i,j = si, (2)\nRFt (Fr, Ft) = min \u03a0\u22650 \u2211 i,j di,j\u03c0i,j s.t. \u2211 i \u03c0i,j = tj . (3)\nThus, REMD can be formulated as:\nLREMD = REMD (Fr, Ft)\n= max (RFr (Fr, Ft) , RFt (Fr, Ft)) = max( \u2211 i ti min j di,j , \u2211 j sj min i di,j). (4)\nAlthough REMD has shown satisfactory performance in natural language processing [14] and image processing [52], it only considers optimal transportation of feature weights globally, failing to transfer local structure information in sparse point clouds effectively. Therefore, we propose a feature mover\u2019s distance (FMD) to explore the global shape information as well as the rich local structure information."
        },
        {
            "heading": "III. APPROACH",
            "text": ""
        },
        {
            "heading": "A. Preliminary",
            "text": "We denote an input point cloud with N points as X \u2208 RN\u00d7din , where din is the input dimension. The corresponding positions are defined as P \u2208 RN\u00d73. Usually, X only contains normalized 3D coordinates, i.e., X = P , but it can also be combined with additional attributes, such as surface normal and color. Given an input X and a lightweight student network S. The output Ys can be formulated as:\nYs = S (X) = Sc \u25e6 SL \u25e6 ... \u25e6 S2 \u25e6 S1(X), (5)\nwhere S1,S2, ...,SL are the sequential blocks of the student. Sc represents the classifier in the classification task or the decoder in the segmentation task. \u25e6 is a nesting function, where g \u25e6 f (\u00b7) = g (f (\u00b7)). We denote the intermediate features of the student as {Fs,1, Fs,2, ..., Fs,L}. Fs,l is calculated by:\nFs,l = Sl \u25e6 ... \u25e6 S2 \u25e6 S1 (X). (6)\nThe teacher network T shares a similar process. We denote the intermediate features of the teacher as {Ft,1, Ft,2, ...Ft,L}."
        },
        {
            "heading": "B. Overall Framework",
            "text": "In this paper, we propose bidirectional knowledge reconfiguration (BKR), a novel feature distillation mechanism, for lightweight point cloud analysis. The overall framework is illustrated in Fig. 1. BKR consists of top-down knowledge reconfiguration (TDKR), bottom-up knowledge reconfiguration (BUKR) and residual connection (RES), aiming at alleviating\nthe semantic gap between teacher and student, as well as distilling the contextual knowledge from the teacher to all the semantic levels of the student. However, we observe that position inconsistency between the corresponding teacher and student features, caused by the random sampling operation, is one of the main factors affecting the performance of point cloud feature distillation. To solve this problem, we further design a feature mover\u2019s distance (FMD), which can measure the discrepancy between misaligned student features and teacher features effectively."
        },
        {
            "heading": "C. Bidirectional Knowledge Reconfiguration",
            "text": "Multi-level distillation is widely employed in feature distillation and shows satisfactory performance [36], [37], [53], which usually transfers the same-level knowledge between teacher and student. However, in point cloud analysis, neglecting cross-level knowledge may lead to a loss of rich 3D geometric information and is not conducive to grasping the diverse shape information formed by point clouds [8]. Inspired by multiscale feature learning [54], [55], we propose bidirectional knowledge reconfiguration for point cloud feature distillation, imposing multi-level and multiscale contextual knowledge from the teacher to all the semantic levels of the student hierarchically. We divide layers with the same resolution into a group and view them as a level. In each level, the feature of the last layer is employed to distill the knowledge. Specifically, a top-down knowledge reconfiguration is first employed to merge the information from top to bottom of the student so that the low-level structure knowledge of the teacher can be spread to deep student layers. In addition to low-level structure knowledge, features at high levels represent global knowledge, which is essential for perceiving the overall shape of the point cloud. To further inherit the high-level shape knowledge from the teacher, we perform a bottom-up knowledge reconfiguration on the features produced by the top-down knowledge reconfiguration. Finally, the reconfigured\nfeature and the original student feature are fused via a residual connection to better inherent information from the same level.\n1) Top-down Knowledge Reconfiguration (TDKR): As shown in Fig. 1, we denote {TD1, TD2, ..., TDL} as the reconfigured features of TDKR, where TDl is formulated as:\nTDl = { TDKR (TDl+1, Fs,l) , l = 1, ..., L\u2212 1 Conv1\u00d71 (Fs,l), l = L . (7)\nFig. 2(a) presents the building block of TDKR. Taking the l-th level of the student as an example, with the reconfigured feature TDl+1 \u2208 Rn\n\u2032\u00d7d from the (l + 1) -th level, we first upsample the feature resolution to the same size as the corresponding teacher feature. Similar to [6], we obtain the upsampled feature by interpolating feature values of (l+1)-th level points at coordinates of the l-th level points. The output is denoted as TDl+1\u2191 \u2208 Rn\u00d7d:\nTD\u2191l+1 = Upsample (TDl+1) . (8)\nSpecifically, if the feature is global, we simply use repetition as the upsampling operation. Additionally, the original student feature Fs,l \u2208 Rn\u00d7d \u2032 undergoes a 1\u00d7 1 convolution to match the dimension of TD\u2191l+1, which is termed F \u2032 s,l \u2208 Rn\u00d7d:\nF \u2032\ns,l = Conv1\u00d7 1 (Fs,l) . (9)\nInspired by [56], [57], we employ a gate mechanism to control the information flows from different features. Specifically, we concatenate TD\u2191l+1 and F \u2032\ns,l as Ftd,l \u2208 Rn\u00d72d and employ a 1\u00d71 convolution with a sigmoid function to generate the weight w\ntd,l \u2208 Rn\u00d72. Then, the weight is split into two gates\ng1 td,l \u2208 Rn\u00d71 and g2 td,l \u2208 Rn\u00d71. TDKR is calculated as:\nTDKR (TDl+1, Fs,l) = [g 1 td,l\n] \u00b7 F \u2032\ns,l + [g 2 td,l ] \u00b7 TD\u2191l+1, (10)\nwhere [g1 td,l ] \u2208 Rn\u00d7d and [g2 td,l ] \u2208 Rn\u00d7d are the repetitions of g1 td,l and g2 td,l d times, respectively. In this way, the weights\nare generated dynamically based on the input features. Thus, the information flows from different levels that carry diverse knowledge can be reconfigured adaptively.\n2) Bottom-up Knowledge Reconfiguration (BUKR): As illustrated in Fig. 2 (b), the structure of BUKR is similar to that of TDKR but different in detail: BUKR performs downsampling on low-level features for feature fusion, while TDKR performs upsampling on high-level features. We define {BU1, BU2, ..., BUL} as the outputs of BUKR, where BUl is formulated as:\nBUl = { BUKR (BUl\u22121, TDl) , l = 2, ..., L Conv1\u00d71 (TDl) , l = 1 . (11)\nSpecifically, BUl\u22121 is first downsampled to match the resolution, and a 1 \u00d7 1 convolution is performed on TDl to match the dimension:\nBU\u2193l\u22121 = Downsample (BUl\u22121) , (12)\nTD \u2032\nl = Conv1\u00d7 1 (TDl) . (13)\nThen, we calculate the weight w bu,l \u2208 Rn\u00d72 from the concatenation of BU\u2193l\u22121 and TD \u2032\nl in the same way as TDKR. w\nbu,l is further split into g1 bu,l \u2208 Rn\u00d71 and g2 bu,l \u2208 Rn\u00d71 as\ntwo gates. Finally, the output of BUKR can be written as:\nBUKR (BUl\u22121, TDl) = [g 1 bu,l\n] \u00b7TD \u2032\nl +[g 2 bu,l ] \u00b7BU\u2193l\u22121, (14)\nwhere the notations are similar to TDKR.\n3) Residual Connection (RES): TDKR and BUKR can transfer cross-level information, while rich knowledge at the same level might be ignored. To effectively inherit the same level of knowledge from the teacher, a residual connection is employed to obtain the reconfigured feature Fr,l:\nFr,l = BUl + Fs,l. (15)"
        },
        {
            "heading": "D. Feature Mover\u2019s Distance",
            "text": "As shown in Fig. 3, The randomness of farthest point sampling (FPS) makes the position and order of points different between the teacher and the student. Taking the l-th level as an example, after FPS, the point positions of the student Ps,l \u2208 RN\u00d73 are not equal to the point positions of the teacher Pt,l \u2208 RN\u00d73, leading to feature misalignment between the teacher and student. We present more analysis in Section IV-D1 to show the misalignment. To this end, it is essential to align the point positions of the intermediate features before distilling the knowledge from teacher to student.\nInspired by the optimal transportation theory, we propose the feature mover\u2019s distance (FMD) to align the point positions of the features between the teacher and student. Specifically, we first divide the original optimal transportation problem into N subproblems to leverage local structure information. Denote Fr,l = { F 1r,l, ..., F N r,l } as the reconfigured feature of the\nstudent and Ps,l = { P 1s,l, ..., P N s,l } as its corresponding positions. We divide the student feature into N subsets. Therefore, each subset contains one element, i.e., F\u0302 ir,l = { F jr,l | j = i } .\nSimilarly, let Ft,l be the feature of the teacher and Pt,l ={ P 1t,l, ...P N t,l } be its corresponding positions. As transporting products to neighboring destinations is an approximation of the least-expensive transportation strategy [58], [59], we define the teacher feature subset F\u0302 it,l = { F jt,l | j \u2208 N iPs,l (Pt,l) } . N iPs,l (Pt,l) is the index of the k nearest neighbors of student position P is,l in teacher position set Pt,l.\nFinally, we define FMD as the feature discrepancy under a distance-based transportation strategy. Specifically, we propose\na distance-based transportation strategy \u03a0l = ( \u03c0lij ) to approximate the least-expensive transportation strategy. Similar to [60], we determine the transportation strategy based on the ground distance di,j and use the normalized Gaussian radial basis function to calculate the \u03c0li,j of the l-th level features:\n\u03c0li,j = e\u2212d 2 i,j/2\u03c4 2\u2211 h\u2208N\nPi s,l\n(Pt,l) e\u2212d 2 i,h/2\u03c4\n2 , (16)\nwhere di,j = \u2225\u2225\u2225P is,l \u2212 P jt,l\u2225\u2225\u2225\n2 and \u03c4 is a temperature parameter.\nFMD is calculated as follows:\nLlFMD = FMD (Fr,l, Ft,l)\n= N\u2211 i=1 si,l \u2225\u2225\u2225\u2225\u2225\u2225\u2225F ir,l \u2212 \u2211\nj\u2208N Pi s,l (Pt,l)\n\u03c0li,jF j t,l \u2225\u2225\u2225\u2225\u2225\u2225\u2225 2 , (17)\nwhere Fr,l and Ft,l are the reconfigured student feature and the teacher feature of the l-th level, respectively. Compared to REMD in Eq. (4) that only considers the global nearest destination, FMD takes k nearest local neighbors into account, which transfers local structure information of different levels effectively and makes the measurement more robust.\nInspired by average pooling correlation (APC) [42], we formulate si,l as follows:\nsi,l = max(0, \u27e8F ir,l, \u2211N j F j t,l\nN \u27e9). (18)\nDuring the training process, we utilize both the original cross-entropy loss LCE and the FMD loss LlFMD. The total loss function is:\nL = LCE + \u03bb L\u2211 l=1 LlFMD, (19)\nwhere \u03bb is a trade-off hyperparameter."
        },
        {
            "heading": "IV. EXPERIMENTS",
            "text": "We evaluate the effectiveness of our method on ModelNet40 [61] for point cloud classification, ShapeNetPart [62] for object part segmentation and S3DIS [63] for point cloud semantic segmentation. Since there are few studies on point cloud distillation, we select the Feature-L2 (F-L2) as our baseline, which is a classical feature distillation method in image\nprocessing. In F-L2, all the intermediate features of the student are first transformed to match the size of the corresponding teacher features. Then, L2 loss is employed as the distillation objective. We choose widely used distillation methods as competitors, including KD [20], FitNet [32], NST [33], AT [36], SP [37], OFD [64], DKD [31] and PEFD [35]. Four classical models are chosen as the backbones, including the MLP-based model PointNet++ (PN++) [6], graph-based model DGCNN (DGC) [18], CNN-based model PointConv (PConv) [10] and transformer-based model PointTransformer (PT) [12]. We treat the original model as the teacher and reduce the width to 1/8 as the student, which is marked by a prefix of (1/8). Table I lists the number of parameters (Params) and the multiadds (MAdds) of these models.\nFor PointNet++ [6] and PointConv [10], in addition to the point positions, we also employ the surface normals as the additional input. For all the experiments, we set the data augmentations and the training hyperparameters the same as the open source codes1,2,3,4. For the tradeoff parameter \u03bb, we conduct cross-validation on the ModelNet40 dataset and find that \u03bb = 0.1 achieves the best results for classification and \u03bb = 0.01 achieves the best results for segmentation. For the competitors, we also conduct the same cross-validation experiment to choose the tradeoff parameter. In addition, we choose k = 5 as the number of neighbors in FMD. Code is available at https://github.com/cuixing100876/BKR."
        },
        {
            "heading": "A. Shape Classification",
            "text": "1) Data and Metrics: The ModelNet40 dataset [61] consists of 12,311 meshed CAD models from 40 categories, which is split into 9,843 models for training and 2,468 models for testing. We follow the data preparation of [61] and employ the mean accuracy within each category (mAcc) and the overall accuracy (OA) as the evaluation metrics.\n2) Results: As shown in Table II, when dealing with models that involve sampling operations, such as PointNet++, PointConv, and PointTransformer, the utilization of F-L2 may have a negative impact on the performance of student model. This is because directly transferring intermediate feature knowledge without reconfiguration and alignment may\n1https://github.com/yanx27/Pointnet Pointnet2 pytorch 2https://github.com/AnTao97/dgcnn.pytorch 3https://github.com/DylanWusee/pointconv pytorch 4https://github.com/qq456cvb/Point-Transformers\npotentially result in performance degradation. Our method (BKR+FMD) outperforms other distillation methods on all four backbones. Specifically, for the PointNet++ model, our method outperforms DKD by 1.10% and 1.47% in OA and mAcc, respectively. Moreover, our method also outperforms PEFD by large margins, i.e., 1.00% and 1.28% in OA and mAcc, respectively, which demonstrates the effectiveness of BKR and FMD. Besides, our method improves the mACC of the student by 3.94%, 6.68%, 9.78% and 1.67% and the OA by 1.8%, 3.81%, 9.2% and 1.32% with PointNet++, DGCNN, PointConv and PointTransformer, respectively. The improvement demonstrates that the proposed BKR and FMD can benefit the knowledge transfer procedure in various kinds of point cloud models, demonstrating the universality of our method."
        },
        {
            "heading": "B. Object Part Segmentation",
            "text": "1) Data and Metrics: The ShapeNetPart dataset [62] contains 16,880 models from 16 shape classes. There are 14,006 models for training and 2,874 models for testing. Each point is annotated with one label from 50 parts, and the number of parts for each class is 2-6. For a fair comparison, we follow the same testing protocol with [61]. The category mIoU and the instance mIoU are employed for evaluation.\n2) Results: Similar to the experiments on ModelNet40, we compare our method (BKR+FMD) with the competitors on all four backbones for the object part segmentation task. The results are presented in Table III. Our method surpasses PEFD by 1.97% and 1.41% on instance mIoU and category mIoU for PointNet++ [6], respectively. In the case of DGCNN, although all the distillation methods improve the performance of the original student, our method achieves the largest improvement. For PointConv, our method achieves an improvement of 1.27% and 3.4% on instance mIoU and category mIoU, respectively. The success on the object part segmentation task further reveals the applicability of our method."
        },
        {
            "heading": "C. Semantic Segmentation",
            "text": "1) Data and Metrics: The S3DIS dataset [63] contains 271 rooms in 6 indoor areas. There are 273 million 3D RGB points scanned from three different buildings, each of which is assigned a semantic label from 13 classes. We train the models on Areas 1-4 and 6 and test on Area 5, which is unseen during training. The mean classwise intersection over union (mIoU), mAcc and OA are employed as the evaluation metrics.\n2) Results: Similarly, we conduct comparisons between our method and other distillation methods on several backbones. However, due to the more complex scenarios and serious selfobscuring, semantic segmentation is more challenging than object part segmentation, leading to less effectiveness of the distillation. As shown in Table IV, there are performance drops or slight performance improvements with previous distillation methods. With the help of reconfiguration and alignment, our method consistently and significantly improves the semantic segmentation performance, especially on mAcc and mIoU.\n3) Visualization: Fig. 4 presents the visualization results of PointNet++ [6] on S3DIS. The predictions of our method are closer to the ground truth and capture more connected and consistent local details since the bidirectional knowledge reconfiguration has the ability to well inherit the contextual knowledge from the teacher model. Besides, Fig. 4 also shows qualitative comparisons between our method with other competing methods, including F-L2, DKD, OFD and PEFD. As shown in Fig. 4, F-L2 obtains unsatisfactory performance, which even degenerates the performance of the student model.\nThis may be primarily due to its inherent problem of position inconsistency, which results in misaligned knowledge that distracts the distillation procedure. DKD outperforms F-L2 since it transfers the knowledge in logits, effectively mitigating the issue of position inconsistency in the intermediate features. However, the neglect of information within the intermediate features by DKD leads to insufficient transferred knowledge. For example, in the third example, DKD treats \u201cclutter\u201d (black) as \u201cceiling\u201d (green). Meanwhile, the feature distillation methods, i.e., OFD and PEFD, achieve better results by effectively utilizing the rich information in the intermediate features. Compared to these competitors, our method achieves the best performance. As shown in Fig. 4, our method excels in accurately segmenting both global and local semantic areas. For example, it successfully captures the global shape in the fifth example and accurately identifies the local object, such as sofa, in the second example. These results demonstrate the necessity of FMD in solving the position inconsistency problem, as well as the effectiveness of BKR in leveraging diverse knowledge within the intermediate features."
        },
        {
            "heading": "D. Analysis",
            "text": "1) Position Inconsistency in Feature Distillation: To clarify the position inconsistency problem, we simulate the sampling process and visualize the normalized frequency histogram of the distance between point positions sampled by the teacher and the student. In particular, we employ the preprocessed ModelNet40 dataset in which each input contains 1024 points and samples 512 points for the teacher and the student. The sampling process is the same as the first stage of many point cloud analysis models, such as PointNet++ [6] and PointConv [10]. All the training data are used, and the distance between point pairs is calculated by Euclidean distance. We then count and plot the normalized frequency histogram.\nAs shown in Fig. 5, the distance is between 0 \u223c 2 because the input point cloud positions are normalized to \u22121 \u223c 1 during data preprocessing. Obviously, many point pairs have nonnegligible Euclidean distances. Specifically, approximately 26.98% of the point pairs have a Euclidean distance greater than 1, indicating a large inconsistency between the teacher and student. Such inconsistency leads to misaligned intermediate features, which limits feature distillation effectiveness. There are also some point pairs with distances less than 0.25 or even equal to 0. These aligned or near-aligned points account for why other distillation methods can be effective without feature alignment.\nWe further analyze the influence of position inconsistency at different levels in feature distillation. We choose PointNet++ as the backbone and conduct experiments on the S3DIS dataset. Specifically, distillation is performed on the features of each level separately. Two distillation methods are employed. One is our baseline which directly forces the student feature to mimic the teacher feature by L2 loss. The other one replaces the distillation loss in the baseline with the proposed FMD. The results are summarized in Table VI. For L2, when distilling with single-level, it is observed that shallow features are more sensitive to position inconsistency than deep features. This is because the higher the feature level, the larger the perceptual area captured, which is able to represent more global shape information, making less misalignment between features of different positions. However, the performance is getting worse when more levels are added for distillation. This is because the utilization of more distillation levels may potentially lead to the accumulation of misaligned knowledge distillation. Besides, the inconsistency in knowledge transfer across different levels may further disrupt the distillation procedure, ultimately leading to a decline in performance. For FMD, since features are well aligned in FMD, both low-level and high-level knowledge can be well transferred from the\nteacher to the student, obtaining satisfactory results. Besides, as the shallow feature in Level-1 captures more local structure information which is significant in the semantic segmentation task, the better performance of Level-1 can be attributed to the abundant local structure information. Besides, it is worth noting that employing multi-level features in feature distillation outperforms the single-level method, which is consistent with the observation of previous methods [39], [65].\n2) Ablation Study : To further demonstrate the effectiveness of the proposed BKR and FMD, we design an ablation study on the ModelNet40, ShapeNetPart, and S3DIS datasets with PointNet++ as the backbone. F-L2 is our baseline. As shown in Table V, utilizing the proposed FMD can boost the performance. In classification, FMD helps the student model outperform F-L2 by 3.08%. The effectiveness of FMD is more remarkable on semantic segmentation. Specifically, FMD outperforms REMD by 0.45%, 1.02%, and 0.65% on OA, mAcc, and mIoU, respectively. We also combine FMD with other feature distillation methods. As shown in table VII, FMD can consistently improve performance, demonstrating the universality and effectiveness of FMD.\nIn addition, we quantitatively analyze the effectiveness of TDKR, BUKR and BKR. As shown in Table V, although BUKR+FMD improves the performance of FMD marginally, the collaboration effect between TDKR and BUKR is remarkable which is consistent with our conclusion that \u201cboth local structure and global shape information are essential clues for point cloud\u201d. Taking object part segmentation as an example, on the one hand, TDKR+BUKR+FMD outperforms TDKR+FMD by 0.80% on ins. mIoU, indicating the assisting role of BUKR to TDKR. On the other hand, TDKR+BUKR+FMD outperforms FMD by 1.03% and 1.53% on cat. mIoU and ins. mIoU, further proving the necessity of collaboration between TDKR and BUKR. In addition, our framework (BKR+FMD), which combines TDKR, BUKR and residual connection, achieves the best results, showing that residual connections can bring rich information and improve knowledge transfer. Moreover, as shown in Table VII, although the results of other feature distillation methods can be improved by FMD, they are still inferior to our method, i.e., BKR+FMD, further demonstrating the superiority of BKR.\n3) Analysis of Hyperparameters: We analyze the nearest number k in FMD and the tradeoff parameter \u03bb by cross-\nvalidation. Specifically, 20% of the training set is used as the validation set, and the rest is employed to train the model. We vary k in 1, 3, 5, 7, 9 and \u03bb in 0.1, 0.05, 0.01, 0.005, 0.001. Experiments are conducted on ModelNet40 [61] for shape classification and ShapeNetPart [62] for object part segmentation with PointNet++ [6] as the backbone.\nTable VIII and Table IX present the results of varying k and \u03bb, respectively. Our method is more sensitive to the nearest number k than the tradeoff parameter \u03bb. This is because the number of nearest neighbors in FMD controls the receptive scale of the student and further determines the scope of contextual knowledge transferred from the teacher. Within a certain range, a larger k will form a better representation of the local structure. After adding more neighbors, the performance will not increase because only a moderate k can balance the local structure information and global shape knowledge. As shown in Table VIII, we chose k = 5 in our experiments."
        },
        {
            "heading": "V. CONCLUSIONS",
            "text": "In this paper, we design a universal feature distillation strategy for lightweight point cloud analysis. Since both the local structure knowledge and global shape knowledge of the teacher are essential for the student, a bidirectional knowledge reconfiguration (BKR) is presented to inherit the contextual knowledge from the teacher to all the scales of the student using bidirectional reconfiguration. Specifically, a top-down reconfiguration is developed for inheriting diverse local structure information, and a bottom-up reconfiguration is employed to inherit high-level shape knowledge. Since there exists a potential position inconsistency caused by the random point sampling operation in point cloud analysis, a feature mover\u2019s distance (FMD) is proposed to conduct the feature alignment. Experiments on shape classification, part segmentation and semantic segmentation benchmarks with various point cloud analysis networks show the effectiveness and universality of our framework."
        },
        {
            "heading": "VI. ACKNOWLEDGMENTS",
            "text": "This research is sponsored by Beijing Nova Program (Z211100002121106), National Natural Science Foundation of China (Grant No. 62306041, 62276031)."
        }
    ],
    "title": "Bidirectional Knowledge Reconfiguration for Lightweight Point Cloud Analysis",
    "year": 2023
}