{
    "abstractText": "JIA LI, Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, China YANYAN SHEN\u2217, Department of Computer Science and Engineering, Shanghai Jiao Tong University, China LEI CHEN, Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, China CHARLES WANG WAI NG, Department of Civil and Environmental Engineering, The Hong Kong University of Science and Technology, China",
    "authors": [
        {
            "affiliations": [],
            "name": "JIA LI"
        },
        {
            "affiliations": [],
            "name": "YANYAN SHEN"
        },
        {
            "affiliations": [],
            "name": "LEI CHEN"
        },
        {
            "affiliations": [],
            "name": "Jia Li"
        },
        {
            "affiliations": [],
            "name": "Yanyan Shen"
        },
        {
            "affiliations": [],
            "name": "Lei Chen"
        },
        {
            "affiliations": [],
            "name": "Charles Wang"
        },
        {
            "affiliations": [],
            "name": "Wai Ng"
        }
    ],
    "id": "SP:5f7f897fc9acef47f35c94350e36fa7ce33d7bc1",
    "references": [
        {
            "authors": [
                "Gabriel Appleby",
                "Linfeng Liu",
                "Li-Ping Liu"
            ],
            "title": "Kriging convolutional networks",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Alexei Baevski",
                "Wei-Ning Hsu",
                "Qiantong Xu",
                "Arun Babu",
                "Jiatao Gu",
                "Michael Auli"
            ],
            "title": "Data2vec: A general framework for self-supervised learning in speech, vision and language",
            "year": 2022
        },
        {
            "authors": [
                "Feng-Wen Chen",
                "Chen-Wuing Liu"
            ],
            "title": "Estimation of the spatial rainfall distribution using inverse distance weighting (IDW) in the middle of Taiwan",
            "venue": "Paddy and Water Environment 10,",
            "year": 2012
        },
        {
            "authors": [
                "Tianqi Chen",
                "Thierry Moreau",
                "Ziheng Jiang",
                "Lianmin Zheng",
                "Eddie Yan",
                "Haichen Shen",
                "Meghan Cowan",
                "Leyuan Wang",
                "Yuwei Hu",
                "Luis Ceze"
            ],
            "title": "TVM}: An automated {End-to-End} optimizing compiler for deep learning",
            "venue": "In 13th USENIX Symposium on Operating Systems Design and Implementation",
            "year": 2018
        },
        {
            "authors": [
                "Leila De Floriani",
                "Paola Magillo"
            ],
            "title": "Triangulated Irregular Network",
            "year": 2018
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova"
            ],
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "year": 2019
        },
        {
            "authors": [
                "KN Dirks",
                "JE Hay",
                "CD Stow",
                "D Harris"
            ],
            "title": "High-resolution studies of rainfall on Norfolk Island: Part II: Interpolation of rainfall data",
            "venue": "Journal of Hydrology 208,",
            "year": 1998
        },
        {
            "authors": [
                "Liang Gao",
                "Li Min Zhang",
                "RWM Cheung"
            ],
            "title": "Relationships between natural terrain landslide magnitudes and triggering rainfall based on a large landslide inventory in Hong Kong",
            "venue": "Landslides 15,",
            "year": 2018
        },
        {
            "authors": [
                "Huifeng Guo",
                "Ruiming Tang",
                "Yunming Ye",
                "Zhenguo Li",
                "Xiuqiang He"
            ],
            "title": "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction",
            "venue": "In IJCAI",
            "year": 2017
        },
        {
            "authors": [
                "Michael F Hutchinson"
            ],
            "title": "Interpolating mean rainfall using thin plate smoothing splines",
            "venue": "Int. J. Geogr. Inf. Syst. 9,",
            "year": 1995
        },
        {
            "authors": [
                "Sharon A Jewell",
                "Nicolas Gaussiat"
            ],
            "title": "An assessment of kriging-based rain-gauge\u2013radar merging techniques",
            "venue": "Q. J. R. Meteorol. Soc",
            "year": 2015
        },
        {
            "authors": [
                "Guolin Ke",
                "Di He",
                "Tie-Yan Liu"
            ],
            "title": "Rethinking Positional Encoding in Language Pre-training",
            "venue": "In ICLR",
            "year": 2021
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A Method for Stochastic Optimization",
            "venue": "In ICLR",
            "year": 2015
        },
        {
            "authors": [
                "Chunyuan Li",
                "Jianwei Yang",
                "Pengchuan Zhang",
                "Mei Gao",
                "Bin Xiao",
                "Xiyang Dai",
                "Lu Yuan",
                "Jianfeng Gao"
            ],
            "title": "Efficient Self-supervised Vision Transformers for Representation Learning",
            "venue": "In ICLR",
            "year": 2022
        },
        {
            "authors": [
                "Yaguang Li",
                "Rose Yu",
                "Cyrus Shahabi",
                "Yan Liu"
            ],
            "title": "Diffusion Convolutional Recurrent Neural Network: Data- Driven Traffic Forecasting",
            "venue": "In ICLR",
            "year": 2018
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov"
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "year": 2019
        },
        {
            "authors": [
                "Sarann Ly",
                "Catherine Charles",
                "Aurore Degr\u00e9"
            ],
            "title": "Different methods for spatial interpolation of rainfall data for operational hydrology and hydrological modeling at watershed scale: a review",
            "venue": "Environnement",
            "year": 2013
        },
        {
            "authors": [
                "J Eamonn Nash",
                "Jonh V Sutcliffe"
            ],
            "title": "River flow forecasting through conceptual models part I\u2014A discussion of principles",
            "venue": "J. Hydrol",
            "year": 1970
        },
        {
            "authors": [
                "Peter Shaw",
                "Jakob Uszkoreit",
                "Ashish Vaswani"
            ],
            "title": "Self-Attention with Relative Position Representations",
            "year": 2018
        },
        {
            "authors": [
                "IV Sideris",
                "M Gabella",
                "R Erdin",
                "U Germann"
            ],
            "title": "Real-time radar\u2013rain-gauge merging using spatio-temporal co-kriging with external drift in the alpine terrain of Switzerland",
            "venue": "Quarterly Journal of the Royal Meteorological Society 140,",
            "year": 2014
        },
        {
            "authors": [
                "Raymond Sluiter"
            ],
            "title": "Interpolation methods for climate data: literature review",
            "venue": "KNMI, De Bilt",
            "year": 2009
        },
        {
            "authors": [
                "Weiping Song",
                "Chence Shi",
                "Zhiping Xiao",
                "Zhijian Duan",
                "Yewen Xu",
                "Ming Zhang",
                "Jian Tang"
            ],
            "title": "AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks",
            "venue": "In CIKM",
            "year": 2019
        },
        {
            "authors": [
                "Xiu Tang",
                "Sai Wu",
                "Mingli Song",
                "Shanshan Ying",
                "Feifei Li",
                "Gang Chen"
            ],
            "title": "PreQR: Pre-training Representation for SQL Understanding",
            "venue": "In SIGMOD",
            "year": 2022
        },
        {
            "authors": [
                "Immanuel Trummer"
            ],
            "title": "DB-BERT: a Database Tuning Tool that \"Reads the Manual",
            "venue": "In SIGMOD",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "NeurIPS",
            "year": 2017
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is All you Need",
            "venue": "NeurIPS",
            "year": 2017
        },
        {
            "authors": [
                "Hans Wackernagel"
            ],
            "title": "Ordinary Kriging",
            "year": 1995
        },
        {
            "authors": [
                "Hans Wackernagel"
            ],
            "title": "Universal Kriging",
            "year": 1995
        },
        {
            "authors": [
                "Max Welling",
                "Thomas N Kipf"
            ],
            "title": "Semi-supervised classification with graph convolutional networks. In ICLR",
            "year": 2017
        },
        {
            "authors": [
                "Antje Witting",
                "Frederik Brandenstein",
                "Christiane Zarfl",
                "Ana Luc\u00eda"
            ],
            "title": "Impact of Scientific Scrutiny after the 2016",
            "venue": "Braunsbach Flash Flood on Flood-Risk Management in the State of Baden-Wu\u0308rttemberg, Germany. Water 12,",
            "year": 2020
        },
        {
            "authors": [
                "Yuankai Wu",
                "Dingyi Zhuang",
                "Aur\u00e9lie Labbe",
                "Lijun Sun"
            ],
            "title": "Inductive Graph Neural Networks for Spatiotemporal Kriging",
            "year": 2021
        },
        {
            "authors": [
                "Kun Zhou",
                "Hui Wang",
                "Wayne Xin Zhao",
                "Yutao Zhu",
                "Sirui Wang",
                "Fuzheng Zhang",
                "Zhongyuan Wang",
                "Ji-Rong Wen"
            ],
            "title": "S3-rec: Self-supervised learning for sequential recommendation with mutual information maximization",
            "venue": "In CIKM. 1893\u20131902. Received October 2022; revised January",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "176\nSSIN: Self-Supervised Learning for Rainfall Spatial Interpolation JIA LI, Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, China YANYAN SHEN\u2217, Department of Computer Science and Engineering, Shanghai Jiao Tong University, China LEI CHEN, Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, China CHARLES WANG WAI NG, Department of Civil and Environmental Engineering, The Hong Kong University of Science and Technology, China\nThe acquisition of accurate rainfall distribution in space is an important task in hydrological analysis and natural disaster pre-warning. However, it is impossible to install rain gauges on every corner. Spatial interpolation is a common way to infer rainfall distribution based on available raingauge data. However, the existing works rely on some unrealistic pre-settings to capture spatial correlations, which limits their performance in real scenarios. To tackle this issue, we propose the SSIN, which is a novel data-driven self-supervised learning framework for rainfall spatial interpolation by mining latent spatial patterns from historical observation data. Inspired by the Cloze task and BERT, we fully consider the characteristics of spatial interpolation and design the SpaFormer model based on the Transformer architecture as the core of SSIN. Our main idea is: by constructing rich self-supervision signals via random masking, SpaFormer can learn informative embeddings for raw data and then adaptively model spatial correlations based on rainfall spatial context. Extensive experiments on two real-world raingauge datasets show that our method outperforms the state-of-the-art solutions. In addition, we take traffic spatial interpolation as another use case to further explore the performance of our method, and SpaFormer achieves the best performance on one large real-world traffic dataset, which further confirms the effectiveness and generality of our method.\nCCS Concepts: \u2022 Mathematics of computing \u2192 Interpolation; \u2022 Information systems \u2192 Geographic information systems.\nAdditional Key Words and Phrases: spatial interpolation; self-supervised learning; transformer\nACM Reference Format: Jia Li, Yanyan Shen, Lei Chen, and Charles Wang Wai Ng. 2023. SSIN: Self-Supervised Learning for Rainfall Spatial Interpolation. Proc. ACM Manag. Data 1, 2, Article 176 (June 2023), 21 pages. https://doi.org/10.1145/ 3589321\n\u2217The corresponding author.\nAuthors\u2019 addresses: Jia Li, jlidw@cse.ust.hk, Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Yanyan Shen, shenyy@sjtu.edu.cn, Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Lei Chen, leichen@cse.ust.hk, Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Charles Wang Wai Ng, cecwwng@ust.hk, Department of Civil and Environmental Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. 2836-6573/2023/6-ART176 $15.00 https://doi.org/10.1145/3589321\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nar X\niv :2\n31 1.\n15 53\n0v 1\n[ cs\n.L G\n] 2\n7 N\nov 2\n02 3"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Acquiring fine-grained rainfall data in space and time is critical for hydrological studies and early warning of natural disasters. In many areas, automatic stations have been established to deliver rainfall accumulation data with high temporal resolution (e.g., hourly). Considering that only station data provide direct rainfall measurements, researchers rely on spatial interpolation techniques to infer fine-grained rainfall in space from sparse station observations.\nThe goal of performing spatial interpolation is to \u201cpredict\u201d data for any locations with no historical observations based on available station observations. Rainfall spatial interpolation faces the following practical challenges: (1) Complex Spatial Pattern. Rainfall usually shows irregular and non-uniform distribution in space. (2) Dynamic-Changing Spatial Patterns. Rainfall is a dynamic process involving complex spatiotemporal evolution [20], spatial correlations in rainfall between locations can vary significantly over time. (3) Lack of useful auxiliary variables. Due to cost constraints, it is non-trivial to obtain enough other observed variables to characterize rainfall spatial patterns for interpolation. These challenges together make it difficult to implement accurate spatial interpolation for rainfall.\nVarious interpolation methods have been applied to the rainfall spatial interpolation task. Traditional methods [3, 5, 7, 21, 27] formulate spatial interpolation as a linear weighted sum of observed values to estimate the values at unobserved locations, which can be generally classified into two categories: (i) deterministic approaches, such as IDW [3] and TIN [5]; (ii) geostatistical approaches, such as Kriging [27]. Recently, with the development of Graph Neural Networks (GNNs) [29], researchers have proposed GNN-based models to handle spatial interpolation tasks by modeling spatial points as a graph, such as KCN [1] and IGNNK [31]. Although existing techniques are effective to some extent, they still suffer from an intrinsic restriction \u2014 relying on various pre-settings to capture spatial correlations, which will bring two issues: \u2022 First, parameter selections in these pre-settings are highly dependent on the researchers\u2019 modeling experience, and inappropriate parameters may lead to incorrect estimation of spatial correlation, thereby affecting interpolation performance. For example, in Kriging [27], the variogram essentially represents the strength of spatial correlations between data points and an inappropriate variogram model can lead to completely false results; KCN [1] and IGNNK [31] construct the adjacency matrix using a Gaussian kernel based on distance, in which the kernel length is an important parameter that needs tuning for better performance. \u2022 Second, even with the best possible parameters, the spatial correlations explicitly characterized by pre-settings may not be well suited for real-world scenarios. For example, Kriging assumes observation data are from an underlying Gaussian process, which may not hold in real rainfall data. Besides, most methods tend to use distance-based functions to measure spatial correlations: e.g., IDW uses the function of inverse distance to directly measure the correlation between locations; KCN and IGNNK construct their adjacency matrix using a Gaussian function based on distance to denote spatial correlation and guide message passing. However, static geographic distances can hardly reflect complex spatial patterns of various rainfall events. For example, as shown in Figure 1, given eight stations \ud835\udc5d1 \u2212 \ud835\udc5d8 and one location \ud835\udc5d\ud835\udc62 to be inferred: while the distances between locations are fixed, the correlations between them may change in different rainfall events \u2014 in Example 1, all nine locations are in the same rainfall field and there is a correlation between any one station and \ud835\udc5d\ud835\udc62 ; but in a local convective rain event like Example 2, only \ud835\udc5d3, \ud835\udc5d4 and \ud835\udc5d7 have correlations with \ud835\udc5d\ud835\udc62 .1\nHence, the performance of existing methods is still limited by their inflexible and unrealistic pre-settings.\n1The reality may be more complicated, and the strength of correlations may vary.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nIn this study, we aim to develop an effective spatial interpolation solution to overcome the above issues. To address the limitations of pre-settings, one common idea is to adaptively capture the intrinsic correlations from the data itself, which naturally leads us to self-supervised learning. In recent years, self-supervised learning with Transformer [25] has achieved great success in natural language processing (NLP). Especially BERT [6] and its proposed Masked Language Model (MLM) are advancing the development of other domains [2, 14, 23, 24]. MLM is inspired by the Cloze task and its key idea is: randomly mask a proportion of tokens in the input sequence, then train the model to predict the masked tokens based on their context. We observed that rainfall spatial interpolation is essentially a fill-in-the-blank problem in the spatial domain, which is an \u201cextended version\u201d of the Cloze task. Inspired by the success of BERT and MLM, we propose to borrow the idea of self-supervised learning to solve rainfall spatial interpolation: based on large amounts of historical data, we can employ a similar mask-and-recover task to enable the model to capture the latent spatial correlations from rainfall spatial context. However, applying the BERT model directly to spatial interpolation is inappropriate since it is designed for language modeling. To develop a promising solution, differences between tasks should be well considered. As shown in Figure 2, the key distinctions affecting model design are summarized as follows: (A) Unlike language sentences, there is no concept of \u201csequence\u201d in the continuous 2D space.\nHence, the model should be extended to handle spatial data. (B) Different from the discrete language data, the observations and positions in spatial interpola-\ntion are both continuous. A look-up table manner is no longer suitable for data embeddings since there may be infinite values. Therefore, the model needs to employ new embedding methods for continuous inputs. (C) In the Cloze task, given the known token information, the positions of missing tokens are determined. But in spatial interpolation, given the known observation information, locations to be interpolated may change according to actual needs. To output consistent results for a certain location, it should be independent of the information from other unobserved locations.\nIn this work, we propose a Self-supervised learning framework to improve rainfall Spatial INterpolation by mining latent spatial patterns in historical observation data, which is called SSIN. To address the above issues, we design the SpaFormer (Spatial TransFormer) model as the core component of SSIN. Similar to BERT, SpaFormer stacks multiple Transformer encoders [26] to model spatial correlations, fuse spatial rainfall information, and generate effective data representations for target locations. Specifically, three major techniques are employed to extend SpaFormer to be an\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\neffective spatial interpolator: (A) inspired by the relative position embedding (RPE) [19], we propose a natural extension of attention mechanism by incorporating spatial relative position embeddings (SRPE), thus enabling it to handle spatial data; (B) to generate embeddings for the numerical inputs, we propose to utilize the fully connected network (FCN) as a more flexible linear embedding layer; (C) we devise a shielded self-attention mechanism to avoid aggregating information from unobserved locations. By adopting a mask-and-recover task with rich self-supervised signals, SSIN enables the SpaFormer model to be an effective spatial interpolator: given an instance with known rainfall observations, for any location queries, SpaFormer can infer their rainfall values simultaneously. Our main contributions are summarized as follows:\n\u2022 We identify the limitations of pre-settings in existing works for capturing spatial correlations and propose a self-supervised learning framework SSIN to solve rainfall spatial interpolation. \u2022 We design a novel SpaFormer model as the core component of SSIN to overcome the shortcoming of existing methods. SpaFormer can learn informative embeddings for raw data, then adaptively model interactions and aggregate spatial context information for interpolation, instead of relying on any prior knowledge to characterize spatial correlations. \u2022 We conduct extensive experiments on two real-world raingauge datasets, and the results demonstrate the effectiveness of our proposed method: on the HK and BW datasets, the RMSE is reduced by 12.28% and 5.67%, and the MAE is reduced by 6.97% and 6.18%, respectively. \u2022 We take traffic spatial interpolation as another use case and conduct additional experiments, and the results further confirm the effectiveness and generality of our proposed method.\nThe remainder of this paper is organized as follows. Section 2 introduces the related work. In Section 3, we elaborate on our methodology. We analyze the experimental results in Section 4. Finally, we conclude our work in Section 5.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023."
        },
        {
            "heading": "2 RELATEDWORK",
            "text": "Rainfall Spatial Interpolation. Rainfall spatial interpolation is a widely studied task in Environmental Science, Geography, Water Science, and so on. Traditional spatial interpolation algorithms can be divided into two main categories [17, 21]: (1) deterministic methods; (2) geostatistical methods. Deterministic methods are directly based on surrounding measurements or specified formulas, while geostatistical approaches utilize empirical semivariograms to describe spatial correlations. Deterministic methods include Inverse Distance Weighting (IDW) [3], Triangular Irregular Network (TIN) [5], Spline [10] and so on. Kriging is a generic name for a number of geostatistical techniques [11]. Ordinary Kriging (OK) [27] is the basic form, while other variants like Universal Kriging (UK) [28] incorporate additional variables on the basis of OK. In the fields of data mining and machine learning, rainfall spatial interpolation is still under-explored. Recent works mainly focus on developing GNNs-based solutions for spatial interpolation tasks, such as KCN [1] and IGNNK [31]. However, they are not specialized in handling rainfall spatial interpolation and suffer from one or two of the following drawbacks: (1) assume the existence of node attributes; (2) rely on the fixed adjacency matrix and ignore the fact that various rainfall events may have different spatial correlations. Different from these studies, we fully consider the challenges of real-world rainfall interpolation and propose solutions to adaptively capture the intrinsic correlations from the spatial rainfall data itself. Self-Supervised Learning. Self-supervised learning is a popular paradigm with the ability to learn the intrinsic correlations from the data itself. The general process of self-supervised learning is to first construct the training signals directly from the raw data, and then train the model using the predefined optimization objective [32]. Recently, self-supervised learning with Transformer [25] has achieved great success in natural language processing (NLP). The most prominent model BERT [6] and its proposed masked prediction task are advancing the development of other domains, such as computer vision [2, 14], recommender systems [32] and database systems [23, 24]. In this work, we aim to develop the Transformer architecture as a spatial model and utilize self-supervised learning to solve rainfall spatial interpolation."
        },
        {
            "heading": "3 METHODOLOGY",
            "text": "We first give the problem statement, then provide our SSIN framework, and finally introduce the detailed designs of SpaFormer. The frequently-used notations2 in the paper are listed in Table 1.\n2Spatial locations need to be rearranged into a sequence as model input, we may refer to a \u201clocation\u201d as a \u201cnode\u201d when describing it in the model.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023."
        },
        {
            "heading": "3.1 Problem Statement",
            "text": "In this paper, we focus on rainfall spatial interpolation task. Assume there are\ud835\udc5a rainfall monitoring stations, the known spatial rainfall information can be represented as {\u27e8\ud835\udc5d\ud835\udc56 , \ud835\udc65\ud835\udc56\u27e9}\ud835\udc5a\ud835\udc56=1, where \ud835\udc5d\ud835\udc56 denotes a location, \ud835\udc65\ud835\udc56 is the rainfall value of \ud835\udc5d\ud835\udc56 . Given an arbitrary location \ud835\udc5d\ud835\udc58 , rainfall spatial interpolation is to estimate its rainfall value \ud835\udc65\ud835\udc58 according to {\u27e8\ud835\udc5d\ud835\udc56 , \ud835\udc65\ud835\udc56\u27e9}\ud835\udc5a\ud835\udc56=1."
        },
        {
            "heading": "3.2 SSIN Framework",
            "text": "Figure 3 shows an overview of the SSIN framework. Data. In the climate database, each rainfall record usually consists of the station ID, timestamp, and rainfall value; the station information includes ID, longitude, and latitude. Training. SSIN first arranges the stations into a sequence and calculates the relative position information (including distance and azimuth, which will be discussed in Section 3.3.2) of all location pairs. Then SSIN extracts rainfall data based on the station sequence from the database and performs random masking and data standardization to generate the training sequences. Next, SSIN feeds the training sequences and relative position information into the SpaFormer model, and trains the model to accurately recover the rainfall values of masked locations. \u2022 Masking Strategy.We adopt a mask-and-recover training style like Masked Language Model (MLM). During training, we randomly mask a portion of nodes in each sequence and train the model to predict the rainfall values of masked nodes. Different from MLM, no special token (like [\ud835\udc40\ud835\udc34\ud835\udc46\ud835\udc3e]) is used since a separate embedding may negatively impact the embedding learning for continuous rainfall values. Instead, we use the mean value of known nodes in the sequence to replace the input values of masked nodes3. For the spatial interpolation task, the mean value is more informative than zero because it can help masked (or unobserved) nodes directly obtain the average rainfall information. To generate richer training signals, we adopt the dynamic masking strategy proposed in [16] \u2014 the masking pattern is generated every time when each sequence is fed to the model. \u2022 Data Standardization. To accelerate the model convergence, we standardize the input data before feeding them into the model. Considering that spatial rainfall may vary greatly at different time, we implement an instance-wise standardization for rainfall observations: the rainfall values \ud835\udc65\ud835\udc56 at time \ud835\udc61 is standardized using the mean and standard deviation of the known observed values \ud835\udc4b\ud835\udc3f at time \ud835\udc61 . But the spatial position information is static and relative positions between all\n3The same filling strategy is also used in the testing stage, that is, use the mean of observations to replace the input values of unobserved nodes.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nlocations are within a certain range. Hence, we adopt a global standardization for the relative positions; that is, all distances and azimuths are respectively standardized using the statistics of the known locations. \u2022 Optimization.We use mean squared error as the objective function to calculate the loss: L = 1 \ud835\udc41 \u2211\ud835\udc41 \ud835\udc56=1 (\ud835\udc66\ud835\udc56 \u2212 \ud835\udc66\ud835\udc56 )2, where \ud835\udc66\ud835\udc56 is the true label and \ud835\udc66\ud835\udc56 is the predicted label in Prediction Module.\nInstead of reconstructing the whole input, only masked nodes are predicted and used to calculate the loss.\nTesting. Given rainfall data from monitoring stations at an arbitrary time, SSIN can make use of the trained SpaFormer model to infer the rainfall values for any locations without observations."
        },
        {
            "heading": "3.3 SpaFormer Model",
            "text": "SpaFormer includes four modules: Input Embedding Module (IEM), Spatial Relative Position Embedding Module (SRPEM), Interpolation Transformer Module (ITM), and Prediction Module (PM).\n3.3.1 Input Embedding Module (IEM). This module takes the observed value \ud835\udc65\ud835\udc56 as input and generates its embedding vector \ud835\udc86\ud835\udc56 .\nThe input embedding module in language models is implemented by assigning a unique embedding to each token. However, such an embedding strategy is not applicable in our setting, since rainfall observations are recorded in numerical values and it is not feasible to assign each possible value with a unique embedding. The common embedding method for numerical input is to use an embedding vector (i.e., a linear embedding without bias) to map the input value to the latent embedding space [9, 22], as follows:\n\ud835\udc86\ud835\udc56 = \ud835\udc65\ud835\udc56 \u00b7 \ud835\udc88 (1)\nwhere \ud835\udc88 \u2208 R\ud835\udc51 is the learned vector for embedding and \ud835\udc65\ud835\udc56 is a scalar value. However, this simple approach leads to two problems. First, the representation capacity is limited since there is just a linear scaling relationship between all embeddings. Second, a zero input will be mapped to a zero embedding vector which will cause zero interactions in the latter self-attention computation. In the rainfall field, a standardized zero value is valid information to represent the average of current spatial rainfall and should not be ignored.\nTo tackle the above issues, we adopt a more flexible linear transformation to generate embeddings for the numerical inputs. That is, we transform \ud835\udc65\ud835\udc56 into an embedding vector using a two-layer fully connected network (FCN) with hidden units [\ud835\udc51\ud835\udc52 , \ud835\udc51\ud835\udc52 ]:\n\ud835\udc86\ud835\udc56 = ( \ud835\udc65\ud835\udc56\ud835\udc97 (1) \ud835\udc65 + \ud835\udc83 (1)\ud835\udc65 ) \ud835\udc7e (2)\ud835\udc65 + \ud835\udc83 (2)\ud835\udc65 \u2208 R\ud835\udc51\ud835\udc52 (2)\nwhere \ud835\udc97 (\ud835\udc56 )\ud835\udc65 is the learnable vector,\ud835\udc7e (\ud835\udc56 ) \ud835\udc65 the learnable matrix and \ud835\udc83 (\ud835\udc56 ) \ud835\udc65 is the learnable bias vector for the \ud835\udc56-th layer, \ud835\udc51\ud835\udc52 is the hidden dimension. The two-layer FCN introduces more parameters to improve the capacity and expressiveness of representation, and the existence of bias avoids the zero-embedding problem of zero values.\n3.3.2 Spatial Relative Position Embedding Module (SRPEM). This module generates the embedding vector \ud835\udc84\ud835\udc56 \ud835\udc57 for the spatial relative position \ud835\udc93\ud835\udc56 \ud835\udc57 between points \ud835\udc5d\ud835\udc56 and \ud835\udc5d \ud835\udc57 .\nSince the self-attention itself is a position-agnostic operation, how to explicitly encode position information is a crucial step in performing accurate interpolation. The original Transformer adopts absolute position embedding (APE) [26], in which the absolute position information is added to the token embeddings to serve as the model input. However, absolute positions are less informative for our spatial interpolation task since hourly rainfall values have a weak correlation with the static longitudes and latitudes due to large spatiotemporal variations. In fact, the existing work [12] has\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nshown that the addition operation in APE will bring mixed and noisy correlations between two heterogeneous information resources. Recent work [19] proposed relative position embedding (RPE), which incorporates relative position information into the self-attention mechanism. Considering that the key point of spatial interpolation is to capture pair-wise correlations between locations, it is a natural way to employ RPE to encode position information. A look-up mechanism is not suitable to generate relative position embeddings for the spatial interpolation task, since spatial positions are recorded in real numbers and there are infinite possible pairs of relative positions. To tackle this issue, we generate the spatial relative position embeddings (SRPE) by using a similar method to the Input Embedding Module. We noticed that in addition to distance, the direction is also an important factor in describing relative positions between locations in 2D space. Therefore, we use two values, distance and azimuth4, to represent the relative position. As shown in Figure 4, given a pair of locations \ud835\udc5d\ud835\udc56 and \ud835\udc5d \ud835\udc57 , the relative position of \ud835\udc5d \ud835\udc57 to \ud835\udc5d\ud835\udc56 is \ud835\udc93\ud835\udc56 \ud835\udc57 = [\ud835\udc60, \ud835\udf031] while the relative position of \ud835\udc5d\ud835\udc56 to \ud835\udc5d \ud835\udc57 is \ud835\udc93 \ud835\udc57\ud835\udc56 = [\ud835\udc60, \ud835\udf032]. Then, we employ a two-layer FCN with hidden units [\ud835\udc51\ud835\udc52 , \ud835\udc51\ud835\udc52 ] to generate the embedding vector \ud835\udc84\ud835\udc56 \ud835\udc57 :\n\ud835\udc84\ud835\udc56 \ud835\udc57 = ( \ud835\udc93\ud835\udc56 \ud835\udc57\ud835\udc7e (1) \ud835\udc5f + \ud835\udc83 (1)\ud835\udc5f ) \ud835\udc7e (2)\ud835\udc5f + \ud835\udc83 (2)\ud835\udc5f \u2208 R\ud835\udc51\ud835\udc52 (3)\nwhere\ud835\udc7e (\ud835\udc56 )\ud835\udc5f is the learnable matrix and \ud835\udc83 (\ud835\udc56 ) \ud835\udc5f is the learnable bias for the \ud835\udc56-th layer.\n3.3.3 Interpolation Transformer Module (ITM). The Interpolation Transformer Module is composed of a stack of identical layers and each layer has two components: a shielded self-attention with SRPE and a feed-forward network. Similar to the original implementation [26], we employ a residual connection and a layer normalization for the two sub-layers, that is, the output of each sub-layer is \ud835\udc65 = LayerNorm(\ud835\udc65 + Sublayer(\ud835\udc65)).\nShielded Self-attentionwith SRPE. In the self-attention operation, wemake two improvements to fit the spatial interpolation task: (i) use a natural extension method to incorporate the spatial relative position embedding (SRPE) for modeling pairwise relationships; (ii) adopt the shielded mechanism to avoid aggregating information from unobserved nodes. More specifically, let \ud835\udc6c = [\ud835\udc861, .., \ud835\udc86\ud835\udc5b] denote the input embedding matrix for all nodes. Then based on the input embeddings, we can calculate the queries \ud835\udc78 = \ud835\udc6c\ud835\udc7e\ud835\udc44 , keys \ud835\udc72 = \ud835\udc6c\ud835\udc7e\ud835\udc3e , values \ud835\udc7d = \ud835\udc6c\ud835\udc7e\ud835\udc49 by linear transformation, here\ud835\udc7e\ud835\udc44 ,\ud835\udc7e\ud835\udc3e ,\ud835\udc7e\ud835\udc49 are parameter matrices. Let \ud835\udc92\ud835\udc56 , \ud835\udc8c\ud835\udc56 , \ud835\udc97\ud835\udc56 \u2208 R\ud835\udc51\ud835\udc58 denote the query, key, and value embeddings of the \ud835\udc56-th node, i.e., \ud835\udc56-th row of \ud835\udc78 , \ud835\udc72 , \ud835\udc7d . Then in the attention, the output of the \ud835\udc56-th\n4Azimuth denotes the angle between the north direction and the line connecting the two locations.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nnode, \ud835\udc9b\ud835\udc56 is calculated as below:\n\ud835\udc9b\ud835\udc56 = \ud835\udc5b\u2211\ufe01 \ud835\udc57=1 \ud835\udefc\ud835\udc56 \ud835\udc57\ud835\udc97 \ud835\udc57 \u2208 R\ud835\udc51\ud835\udc58 (4) \ud835\udefc\ud835\udc56 \ud835\udc57 = exp(\ud835\udc52\ud835\udc56 \ud835\udc57 )\u2211\ud835\udc5b \ud835\udc58=1 exp(\ud835\udc52\ud835\udc56\ud835\udc58 ) (5)\n\ud835\udc52\ud835\udc56 \ud835\udc57 = sum\n( \ud835\udc92\ud835\udc56 \u2299 \ud835\udc8c \ud835\udc57 \u2299 \ud835\udc84\ud835\udc56 \ud835\udc57 ) \u221a \ud835\udc51\ud835\udc58\n(6)\nwhere \ud835\udefc\ud835\udc56 \ud835\udc57 is the normalized weight by using a softmax function, \ud835\udc52\ud835\udc56 \ud835\udc57 is the attention score from node \ud835\udc57 to \ud835\udc56 . For the calculation of Equation (6), we simply set \ud835\udc51\ud835\udc58 = \ud835\udc51\ud835\udc52 and use the sum over the element-wise product of \ud835\udc92\ud835\udc56 , \ud835\udc8c\ud835\udc56 and \ud835\udc84\ud835\udc56 \ud835\udc57 to insert SRPE into the attention. As shown in Figure 5, such an attention calculation with SRPE is a natural extension of the original attention.\nHere, \ud835\udc9b\ud835\udc56 is a spatial context-aware representation for location \ud835\udc5d\ud835\udc56 , which is calculated by combining observation information and spatial relative position information. To achieve a more flexible way of capturing complex spatial correlations, we adopt multiple heads to create different \ud835\udc78/\ud835\udc72 /\ud835\udc7d and learn distinct interactions separately. Then we concatenate the outputs from different heads and use a projection to generate the final representation \ud835\udc9b\u2217\ud835\udc56 :\n\ud835\udc9b\u2217\ud835\udc56 = ( \ud835\udc9b (1) \ud835\udc56 \u2225...\u2225\ud835\udc9b (\u210e) \ud835\udc56 ) \ud835\udc7e\ud835\udc42 \u2208 R\ud835\udc51\ud835\udc52 (7)\nwhere \ud835\udc9b (\u210e) \ud835\udc56\nis the output of the \u210e-th head,\ud835\udc7e\ud835\udc42 is the parameter matrix. The pre-trained models like BERT simply adopt self-attention for language modelling, which is essentially full self-attention. As shown in Figure 6a, in full self-attention, each node aggregates information from all nodes without distinguishing them. However, such full attention is not suitable to learn informative representations for the spatial interpolation task. One reason is that the locations to be interpolated may vary according to the real needs, aggregating the information from other unobserved locations will make the model produce inconsistent results for a certain location. To tackle this problem, we propose Shielded Attention (as shown in Figure 6b) to cut off the connections between each query node and other unobserved nodes: (1) each observed node\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\naggregates information from all observed nodes; (2) each unobserved node aggregates information from itself and all observed nodes. Here, we give an example to state the motivation and role of the shielded attention. Given a network of rain gauges, at a given time, queries may involve different subsets of locations to be interpolated, e.g., locations {\ud835\udc4e, \ud835\udc4f, \ud835\udc50} and {\ud835\udc50, \ud835\udc51, \ud835\udc52}. If adopting the full self-attention, the interpolated results of location \ud835\udc50 in answering two queries will be inconsistent since they will aggregate information from locations {\ud835\udc4e, \ud835\udc4f} and {\ud835\udc51, \ud835\udc52}, respectively. By using the shielded self-attention, the interpolated results can be prevented from being affected by other unobserved nodes5. Besides, our results in Section 4.2.3 show that the shielded mechanism can also help improve interpolation performance, since avoiding aggregating noisy information of unobserved nodes can learn better spatial context-aware representations6. Since a sparse attention mechanism is not supported in existing deep learning libraries like PyTorch and TensorFlow, a na\u00efve implementation of Shielded Attention is first to calculate the attention scores between all pairs and then mask out the illegal connections. However, this implementation is too time-consuming (the number of connections in attention is \ud835\udc42 (\ud835\udc3f2), \ud835\udc3f is the sequence length). Besides, the implementation with incorporating SRPE (i.e., Equation (6)) requires additional memories in a normal matrix operation due to inconsistent dimensions of matrices that store the queries, keys, and SRPEs. To reduce the time and memory cost , we build a customized CUDA kernel by using TVM [4] to achieve the shielded attention with SRPE. In Section 3.4.2, we will given more details about the time and space complexity analysis.\nFeed-Forward Network. The feed-forward network following the attention mechanism consists of a two-layer FCN with hidden units [\ud835\udc51\ud835\udc53 , \ud835\udc51\ud835\udc52 ], and a non-linear activation function (i.e., ReLU) is\n5It is worth mentioning that in the original Transformer [25], authors adopted the masked self-attention to avoid future information leakage in the decoding phase. Here, the shielded self-attention is proposed to prevent information of unobserved locations from interfering with interpolation results. 6Unobserved locations do not own real rainfall values, their initialized values are likely to be inconsistent with the real rainfall field, hence bringing the noise to other nodes.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nused between two layers: \ud835\udc89\ud835\udc56 = ReLU ( \ud835\udc9b\u2217\ud835\udc56\ud835\udc7e (1) \ud835\udc53 + \ud835\udc83 (1) \ud835\udc53 ) \ud835\udc7e (2) \ud835\udc53 + \ud835\udc83 (2) \ud835\udc53 \u2208 R\ud835\udc51\ud835\udc52 (8)\nwhere\ud835\udc7e (\ud835\udc56 ) \ud835\udc53 is the learnable matrix and \ud835\udc83 (\ud835\udc56 ) \ud835\udc53 is the learnable bias.\n3.3.4 Prediction Module (PM). Based on the node representation \ud835\udc89\ud835\udc56 from the Interpolation Transformer Module, we further derive the final estimated result via a two-layer FCN with hidden units [\ud835\udc51\ud835\udc52 , 1], which is a regression task:\n\ud835\udc66\ud835\udc56 = ( \ud835\udc89\ud835\udc56\ud835\udc7e (1) \ud835\udc5d + \ud835\udc83 (1) \ud835\udc5d ) \ud835\udc7e (2)\ud835\udc5d + \ud835\udc83 (2) \ud835\udc5d \u2208 R (9)\nwhere\ud835\udc7e (\ud835\udc56 )\ud835\udc5d is the learnable matrix and \ud835\udc83 (\ud835\udc56 ) \ud835\udc5d is the learnable bias."
        },
        {
            "heading": "3.4 Discussion",
            "text": "3.4.1 Numerical Embedding. Unlike NLP tasks that assign an individual (learnable) semantic embedding vector to each discrete element, the representation learning in spatial interpolation is depicted by the mapping function from the continuous original space to the continuous embedding space. Specifically, there are two types of data representation to learn: the embedding mapping for numerical observations and the embedding mapping for spatial relative positions. In this study, we adopt FCNs to generate embeddings for observations and spatial relative positions. As a linear embedding mechanism, FCNs can learn consecutive embedding vectors for continuous inputs and the close inputs will be mapped into similar embeddings. Instead of utilizing any pre-settings to capture spatial correlations, SpaFormer can learn the informative embeddings for numerical observations and relative spatial position information from historical data, then adaptively model the interactions of locations, and aggregate information to generate the spatial context-aware representation for target locations, thus estimating the rainfall values accurately.\n3.4.2 Complexity Analysis. As mentioned in Section 3.3.3, we build a customized CUDA kernel based on TVM to implement the shielded self-attention with SRPE. In this section, we mainly analyze the role of such a customized CUDA kernel in reducing time and memory cost. The empirical results about the memory and speed consumption will be shown in Section 4.2.2. Time Complexity. The na\u00efve implementation of shielded attention is essentially full connection, of which the number of Q-K pairs is \ud835\udc42 (\ud835\udc3f2). For the attention operation with incorporating SPRE (i.e., Equation (6)), the computation complexity is \ud835\udc42 (\ud835\udc51\ud835\udc58 ). Hence, the na\u00efve implementation takes time \ud835\udc42 (\ud835\udc3f2\ud835\udc51\ud835\udc58 ). In TVM implementation of shielded attention, each query node has at most\ud835\udc5a + 1 valid connections, where\ud835\udc5a is the number of observed nodes (\ud835\udc5a < \ud835\udc3f); for a sequence of length \ud835\udc3f, the all number of Q-K pairs is less than (\ud835\udc5a + 1)\ud835\udc3f. Hence, the TVM implementation can theoretically achieve a linear complexity \ud835\udc42 (\ud835\udc5a\ud835\udc3f\ud835\udc51\ud835\udc58 ) with regard to the sequence length. Space Complexity. For one batch including \ud835\udc35 sequences (of length \ud835\udc3f) in \ud835\udc3b -head attention, the shape of matrices that store the queries and keys are both [\ud835\udc35,\ud835\udc3b, \ud835\udc3f, \ud835\udc51\ud835\udc58 ]; during the training, all locations are known, all sequences can share one matrix of SRPEs and its shape is [\ud835\udc3f, \ud835\udc3f, \ud835\udc51\ud835\udc58 ]. To calculate the attention with SPRE (i.e, Equation (4)-(6)), the normal matrix operation needs to extend the dimension of queries and keys to be [\ud835\udc35,\ud835\udc3b, \ud835\udc3f, \ud835\udc3f, \ud835\udc51\ud835\udc58 ], so it will take memory\ud835\udc42 (2\ud835\udc35\ud835\udc3b\ud835\udc3f2\ud835\udc51\ud835\udc58 + \ud835\udc3f2\ud835\udc51\ud835\udc58 ). The TVM implementation can perform the calculation directly without dimension extension, so it takes memory \ud835\udc42 (2\ud835\udc35\ud835\udc3b\ud835\udc3f\ud835\udc51\ud835\udc58 + \ud835\udc3f2\ud835\udc51\ud835\udc58 ).\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "4.1 Experiment Setup",
            "text": "4.1.1 Datasets. We evaluate our proposed method on two real-world hourly raingauge datasets from different regions: Hong Kong (HK) in China and Baden-W\u00fcrttemberg (BW) in Germany. Due to the great variability of terrain, these two regions often suffer from regional rainfall-induced natural disasters, e.g., landslides [8] in Hong Kong and flash floods [30] in BW.\n\u2022 HK raingauge data are obtained from the Hong Kong Observatory (HKO)7 and the Geotechnical Engineering Office (GEO)8. 123 rain gauges are available in this area, and data precision is 0.1- mm. The rain hours between 2008 and 2012 are selected to be the final dataset with 3855 valid timestamps. \u2022 BW raingauge data are public data, which can be accessed in the Climate Data Center (CDC)9 of the German Weather Service (DWD). There are 132 rain gauges available in this area and the rainfall data are based on 0.1-mm precision. This dataset spans from 2012 to 2014 and contains 3640 valid rainy hours.\nFor two datasets, we randomly sample 20% rain gauges as the test locations, and the rest serves as the training data. Table 2 shows the dataset details.\n4.1.2 Baselines. We compare SpaFormer with the following baseline methods. (1) Traditional Interpolation Methods.\n\u2022 TIN: Triangular Irregular Network [5], a deterministic method that creates a series of triangles by using all sampled points, then interpolates with a weighted value of the apexes of the triangle. \u2022 IDW: Inverse Distance Weighting [3], a deterministic method that interpolates with a linear weighted sum of available points, the weights are calculated on a function of inverse distance. \u2022 TPS: Thin Plate Spline [10], a deterministic method that is a spline-based technique, in which the smoothing parameter is calculated by minimizing the generalized cross validation. \u2022 OK: Ordinary Kriging [27], a geostatistical interpolation method which assumes the stationarity of data and that the distance between locations reflect the spatial correlations.\n(2) GNN-based Interpolation Methods.\n\u2022 KCN: Kriging Convolutional Network [1]. The method constructs local subgraphs and predicts each center node\u2019s label based on node features and neighboring labels. \u2022 IGNNK: Inductive Graph Neural Network Kriging [31]. The method treats time-series signals as the node features, generates random subgraphs, randomly mask some nodes, and reconstructs these signals.\n7https://www.hko.gov.hk/en/index.html 8https://www.cedd.gov.hk/eng/about-us/organisation/geo/index.html 9https://www.dwd.de/EN/climate_environment/cdc/cdc_node_en.html\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\n4.1.3 Metrics. To evaluate the performance of interpolation methods, we adopt RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), and NSE (Nash\u2013Sutcliffe\u2019s Efficiency coefficient) [18] as evaluation metrics. NSE = 1 \u2212\n\u2211\ud835\udc5b \ud835\udc56=1 [\ud835\udc66\ud835\udc56\u2212?\u0302?\ud835\udc56 ]2\u2211\ud835\udc5b \ud835\udc56=1 [\ud835\udc66\ud835\udc56\u2212\ud835\udc66 ]2\nis a widely used indicator to assess the performance of hydrological models, where \ud835\udc66 is the mean value of all observed values. NSE\u2019s value ranges from \u2212\u221e to 1: the closer to 1, the better.\n4.1.4 Implementation Details. For traditional interpolation methods, we run different settings and report their best performance, where the power parameter of IDW is 2, the variogram model of OK is spherical, and the type of TIN interpolating function is linear; for TPS, there is no parameters need manual tuning. For KCN and IGNNK, we use the public code provided by their authors. To better validate their performance, we search for the best hyperparameters in much larger search space than that in the original papers. The tuning parameters include learning rate, weight decay, dropout rate, hidden dimension, and the kernel length of the adjacency matrix. Table 3 summarizes the value ranges of the hyperparameter search. Other settings of KCN and IGNNK, like optimizer and activation function, are kept the same as original works. For IGNNK, the time dimension is set as 1 to compare with other spatial interpolators.\nWe implement our method with PyTorch. We denote the number of Transformer blocks as\ud835\udc47 , the number of attention heads as \ud835\udc3b , the embedding dimension as \ud835\udc51\ud835\udc52 , the dimension of query/key/value as \ud835\udc51\ud835\udc58 , the hidden dimension of the feed-forward network as \ud835\udc51\ud835\udc53 . In our implementation, \ud835\udc47 = 3, \ud835\udc3b = 2, \ud835\udc51\ud835\udc52 = \ud835\udc51\ud835\udc58 = 16, \ud835\udc51\ud835\udc53 = 256. We use Adam [13] as the optimizer with \ud835\udefd1 = 0.9, \ud835\udefd2 = 0.98, and \ud835\udf16 = 10\u22129. The warmup strategy [26] is adopted to vary the learning rate, and the warmup step is set as 1200. Batch size is set as 64. We train our model for 100 epochs. For each epoch, we randomly mask 10 times for each sequence to generate different spatial patterns to augment the dataset, the mask ratio is set as 20%. All the experiments were run on a CentOS 7.9.2009 server equipped with a 72-core Intel(R) Xeon(R) Gold 6240 CPU and one Tesla V100 GPU."
        },
        {
            "heading": "4.2 Experiment Results",
            "text": "4.2.1 Overall Performance. We evaluate our method and report the results in Table 4. SpaFormer achieves the best performance on two hourly raingauge datasets. Compared with other methods, SpaFormer does not require any prior knowledge to characterize the spatial correlations. By constructing rich masking patterns as the training objective, SpaFormer learns the effective embeddings for numerical observations and spatial position information from historical data, then the spatial correlations are captured via self-attention that adaptively models the interactions of nodes. From the results, we can see that such a purely data-driven method improves the interpolation performance by a large margin: reducing RMSE for the HK and BW datasets by 12.28%, and 5.67%.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nAmong all baselines, traditional interpolation methods even achieve better results than GNNbased solutions. Specifically, TPS is the best baseline on the HK dataset, while TIN obtains the second lowest MAE on the BW dataset. Two GNN-based solutions, KCN and IGNNK, cannot handle the hourly rainfall spatial interpolation well. Even with the best hyperparameters searched in larger space, only KCN achieves slightly lower RMSE and MAE than the simple method IDW. The main reason is that KCN and IGNNK rely on the pre-defined adjacency matrix to capture the spatial correlations and guide the message passing. However, the pre-defined adjacency matrix may not be optimal for rainfall interpolation all the time, thus limiting their performance. Besides, their model architectures are flawed due to the lack of careful consideration of the characteristics of rainfall spatial interpolation. For example, KCN constructs a subgraph with \ud835\udc3e nearest neighbors around each center point and only predicts the value of the central point, which leads to a weak supervision signal; besides, the rainfall field is dynamically changing, and using a fixed-size subgraph may miss important distant neighbors. IGNNK randomly masks some nodes to generate rich training signals; however, no specific design is proposed to prevent information of unobserved locations from interfering with interpolation results, which is verified to be important for accurate interpolation performance (see ablation study about the shielded mechanism in Section 4.2.3).\n4.2.2 Memory and Speed Consumption. We trained the SpaFormer model with\ud835\udc47 = 3 blocks, \ud835\udc3b = 2 heads and the hidden dimension \ud835\udc51\ud835\udc52 = \ud835\udc51\ud835\udc58 = 16. Table 5 shows our model size and running time on two datasets. We can see such a relatively small model can achieve a fast speed: for HK and BW datasets, the average training time on each epoch is 19.5s and 19.2s, and the average inference time on each sequence is 2.6ms and 2.7ms. Next, we show the efficiency of the customized TVM CUDA kernel for the shielded attention with SRPE. Within a city or region, the number of stations is usually limited, which means the\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nlength of training sequences is relatively short. In practical scenarios, researchers may need to interpolate thousands of locations to obtain fine-grained spatial rainfall information for an area. Performing interpolation for a lot of locations in parallel means a long testing sequence, in this case, the efficiency of the interpolation method will be an important issue. In SpaFormer, we build a customized CUDA kernel implemented based on TVM to implement the shielded attention with SPRE. Here, we compare the efficiency of full attention (i.e., the na\u00efve implementation of shielded attention) with the TVM implementation of shielded attention. We take the situation of the HK region (i.e., 123 stations) as an example and show the comparison results. Figure 7 shows the time and memory cost with respect to the sequence length10 \ud835\udc3f. . We can see that the time and memory cost of the TVM implementation can be much smaller than that of full attention, especially for long sequences. When the sequence length reaches 7000 locations, full attention needs 38.6ms and 16.4GB while TVM implementation only requires 9.2ms and 5.2GB. Our optimization with TVM is practical to use in real-world applications.\n4.2.3 Ablation Study. In this part, we conduct an ablation study from two aspects to investigate the effectiveness of design choices in our work: the architecture of SpaFormer and the training strategy. Firstly, we design six variants of our proposed SpaFormer: (1) \u201cemb: pos-l\u201d applies a linear layer without bias to generate embeddings for relative positions. (2) \u201cemb: input-l\u201d \u201d applies a linear layer without bias to generate embeddings for input values. (3) \u201cemb: both-l\u201d applies a linear layer without bias to generate embeddings for both input values and relative positions. (4) \u201cattn: with SAPE\u201d adopts self-attention with spatial absolute position embedding; just like the original Transformer, we employ the addition operation to integrate the absolute position embeddings into the input embeddings as the model input; here, the absolute position embedding is generated from [\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc61\ud835\udc62\ud835\udc51\ud835\udc52, \ud835\udc59\ud835\udc5c\ud835\udc5b\ud835\udc54\ud835\udc56\ud835\udc61\ud835\udc62\ud835\udc51\ud835\udc52] by using a two-layer FCN. (5) \u201cattn: w/o shield\u201d applies the traditional self-attention without the shielded mechanism. (6) \u201cna\u00efve trans\u201d is a na\u00efve version of Transformer architecture which applies a linear layer without bias as the embedding layers, uses self-attention with spatial absolute position embedding, and no shielded mechanism is applied. Secondly, we design two variants to test the effects of the training strategy: (7) \u201cstatic masking\u201d performs random masking for each sequence during data preprocessing and then trains the model using the generated 10The sequence includes observed and unobserved locations, hence the number of locations to be interpolated is \ud835\udc3f \u2212 123.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nmasked data over multiple epochs. (8) \u201czero fill\u201d replaces the input values of masked/test nodes with zeros.\nTable 6 shows the results. First, compared with SpaFormer, \u201cemb: pos-l\u201d reduces performance slightly, followed by \u201cemb: input-l\u201d and finally \u201cemb: both-l\u201d. This verifies that: (1) using two-layer FCNs as the embedding layer is more expressive than a linear layer without bias; (2) without using bias, the zero-embedding issue in input embeddings will affect the normal interactions between nodes and significantly hurt performance. Second, SpaFormer consistently outperforms both \u201cattn: with SAPE\u201d and \u201cattn: w/o shield\u201d, which shows that: (1) relative position embedding is better at capturing the pairwise relationships and is more suitable for spatial interpolation; (2) the shielded mechanism is able to learn better spatial context-aware representations by avoiding aggregating noisy information from masked/unobserved nodes. Third, the poor results of \u201cna\u00efve trans\u201d confirm the effectiveness of the proposed techniques, and a na\u00efve adaptation of the Transformer architecture is limited to perform accurate spatial interpolation due to the lack of careful consideration of the characteristics of spatial interpolation. Finally, the results of \u201cstatic masking\u201d show rich masking patterns can help the model to yield a higher accuracy, the results of \u201czero fill\u201d confirm that the average rainfall values are informative to learn better spatial context-aware representations for accurate interpolation.\n4.2.4 Parameter Sensitivity. We perform a more detailed analysis to evaluate the effects of key hyperparameters in SpaFormer.\nEffect of Network Depth. Since the Interpolation Transformer Module stacks multiple identical layers, we are interested in how the performance changes w.r.t. the number of layers. The results are summarized in Figure 8. We can see that the performance is poor when only one layer is used. As the number of layers increases, the performance of the model increases. When the number of layers reaches three, the performance becomes relatively stable. Considering a deeper model incurs more training overhead, we choose the configuration with three layers (i.e., \ud835\udc47 = 3). Effect of the Number of Attention Heads. Then, we explore the effect of the number of attention heads. The results are shown in Figure 9. On the HK dataset, the performance continuously increases when we increase the number of attention heads. For the BW dataset, the best number of attention heads is 2. In attention, the multi-head mechanism allows the model to jointly attend to information from different representation subspaces at different positions. According to the results, we conjecture that the spatial distribution of HK rainfall data is more complicated than BW, thus requiring more attention heads to fit complex spatial relationships.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nEffect of Mask Ratio. During the training data generation, the mask ratio is also an important hyperparameter. Here, we study the performance w.r.t. mask ratios, where we choose the mask number \ud835\udc59\ud835\udc5a from 10% to 90% of the sequence length, plus with \ud835\udc59\ud835\udc5a = 1 (i.e., the extreme case, only one node is masked). As shown in Figure 10, we can observe that the error generally decreases first and then increases as the mask number increases. The results mean that too few masks are not enough to generate rich training signals, while too many masks make the input information insufficient for reliable training. A mask ratio between 10% and 30% is a good balance.\n4.2.5 Training Data Amount and Model Update. A large amount of rainfall record data implies rich spatial pattern information, thus enlarging the training data size is likely to improve the\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\nperformance of SpaFormer. We use more historical rainfall data to augment the training dataset 11, i.e., the double and triple size of the original data, then compare the performance. the results in Table 7 show that the performance continuously improves when more training data is used.\nOver time, more rainfall data becomes available. However, different from the streaming data, rainfall does not happen all the time. Considering the intermittency of rainfall events, we can collect rainfall data and retrain the model at a low frequency (e.g., year by year) based on all the data. Here, we take the HK region as an example, add new coming rainfall data into the training data and update the model year by year. The evaluation results for the 2014, 2015, and 2016 years are shown in Figure 11, four traditional methods are added as a comparison. Specifically, \u201cSpaFormer\u201d denotes the trained model on 2008-2012 training data, while \u201cSpaFormer Update\u201d is the trained model by adding new data12. From the results, we can see that our proposed method consistently outperforms other baselines. Besides, as more new data are added, the updated SpaFormer model can achieve lower errors than the old one.\n4.2.6 Transferability Study. In this section, we demonstrate the transferability of SpaFormer. We apply the SpaFormer model trained on one dataset to the other dataset: the trained model on the HK dataset is transferred to BW, and the trained model on the BW dataset is transferred to HK. Without fine-tuning, the trained model on the source dataset is directly applied to the test data of the target dataset. The results are shown in Table 8. By comparing Table 8 with Table 4, we can see that the SpaFormer model has good transferability between HK and BW datasets \u2014 the model trained on each other outperform all other baselines except the SpaFormer trained on itself. The transferability of SpaFormer confirms that such self-supervised learning based on spatial context is a promising solution to solving the spatial interpolation task: the transferred model can offer competitive results even when the new dataset is never seen.\n11Considering that very old data may have poor quality control, we mainly selected data after 2000. 12E.g., using the trained model on 2008-2013 training data to evaluate 2014 test data, using the trained model on 2008-2014 training data to evaluate 2015 test data.\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023."
        },
        {
            "heading": "4.3 Other Case - Traffic Spatial Interpolation",
            "text": "Although our solution is proposed for rainfall spatial interpolation, it can be applied to spatial interpolation problems in other domains thanks to its generality. In this section, we take traffic spatial interpolation as a case to further explore the performance of our proposed method. Performing spatial interpolation on traffic data is helpful in inferring traffic conditions at road locations without sensors installed. We employ one commonly used real-world dataset, PEMS-BAY, to evaluate the performance of different methods. PEMS-BAY is a traffic speed dataset in the Bay Area, released by [15]. Specifically, PEMS-BAY is recorded every 5 minutes and contains data from 325 sensors and 52,116 timestamps. Same as the rainfall interpolation, we randomly sample 20% sensors as the test set, and the rest are used as the training data.\nIt is worth noting that the correlation between traffic sensors is usually related to travel distance instead of geographic distance. So here we make a simple modification in SpaFormer, that is, using the travel distance instead of the geographic distance to generate the relative position embedding. Similarly, the inverse distance matrix of IDW, and the adjacency matrix of KCN and IGNNK are also calculated based on travel distances. Due to the methodological limitation, the methods TIN, TPS, and OK cannot make use of the travel distance information, instead, they employ point coordinates as the inputs to fit the local surface by using deterministic polynomial functions or statistical relationships among points.\nAs shown in Table 9, SpaFormer consistently achieves the best performance in all metrics, which indicates the effectiveness and generality of our method. Traditional methods TIN, TPS, and OK perform worst because they cannot make use of the travel distance information, and the better results of IDW also verify the importance of travel distance in traffic data. KCN, a GNN-based method, suffers from the limitation of the model architecture and thus performs poorly. KCN builds a local subgraph around a central point and only predicts the value of the central point, which leads to a weak supervision signal and cannot capture global information on a sparse traffic graph\nProc. ACM Manag. Data, Vol. 1, No. 2, Article 176. Publication date: June 2023.\ndue to a general two-layer design. Instead, IGNNK and our proposed SpaFormer randomly mask multiple nodes and reconstruct their values, thus producing useful supervision signals to guide the node representation learning. Compared with IGNNK, our method can adaptively capture the spatial correlations without pre-settings, thus achieving better results."
        },
        {
            "heading": "5 CONCLUSIONS",
            "text": "In this paper, we study the rainfall spatial interpolation task. We present SSIN, a self-supervised learning framework, to train an effective spatial interpolator from the rich spatial patterns of historical data. Specifically, we propose the SpaFormer model as the core of SSIN, which can accurately infer rainfall values of unobserved locations by learning informative embeddings and adaptively modeling spatial correlations based on spatial context. The empirical study shows that our proposed SpaFormer consistently outperforms state-of-the-art methods in two large reallife raingauge datasets. Besides, SpaFormer demonstrates remarkable transferability in the two raingauge datasets on different regions, which makes it possible to solve other spatial interpolation scenarios without sufficient training data. Furthermore, we take traffic spatial interpolation as another use case and conduct additional experiments. The experimental results show that our solution significantly outperforms other baselines, which verifies its effectiveness and generality."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "Yanyan Shen\u2019s work is supported by the National Key Research and Development Program of China (2022YFE0200500), Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102) and SJTU Global Strategic Partnership Fund (2021 SJTU-HKUST). Lei Chen\u2019s work is supported by National Science Foundation of China (NSFC) under Grant No. U22B2060, the Hong Kong RGC GRF Project 16209519, CRF Project C6030-18G, C2004-21GF, AOE Project AoE/E-603/18, RIF Project R6020-19, Theme-based project TRS T41-603/20R, China NSFC No. 61729201, Guangdong Basic and Applied Basic Research Foundation 2019B151530001, Hong Kong ITC ITF grants MHX/078/21 and PRP/004/22FX, Microsoft Research Asia Collaborative Research Grant, HKUST-Webank joint research lab grant and HKUST Global Strategic Partnership Fund (2021 SJTU-HKUST)."
        }
    ],
    "title": "SSIN: Self-Supervised Learning for Rainfall Spatial Interpolation",
    "year": 2023
}