{
    "abstractText": "Outsourcing a relational database to the cloud offers several benefits, including scalability, availability, and costeffectiveness. However, there are concerns about the confidentiality and security of the outsourced data. A general approach here would be to encrypt the data with a standardized encryption algorithm and then store the data only encrypted in the cloud. The problem with this approach, however, is that with encryption, important properties of the data such as sorting, format or comparability, which are essential for the functioning of database queries, are lost. One solution to this problem is the use of (e.g. order-preserving) encryption algorithms, which also preserve these properties in the encrypted data, thus enabling queries to encrypted data. These algorithms range from simple algorithms like Caesar encryption to secure algorithms like mOPE. In order to be able to use these algorithms as easy as possible, \u201cDiCE\u201d a JDBC driver was developed, that parses SQL queries as a proxy and transparently encrypts and decrypts these queries. This allows to execute many queries on an encrypted database in the cloud with (nearly) the performance as on unencrypted databases. The DiCE driver can be used with any other JDBC driver and therefore supports a variety of databases. The driver can be configured to support different encryption algorithms. To keep track of the operations, the \u201cDice Information Client\u201d has been developed to track the encryption and decryption of the driver. Although the result of the performance analysis shows a certain overhead due to the parsing and encryption of the SQL queries in the Dice driver, this overhead is significantly reduced by other influencing factors such as the network and parallel queries.",
    "authors": [
        {
            "affiliations": [],
            "name": "Johannes Koppenwallner"
        },
        {
            "affiliations": [],
            "name": "Erich Schikuta"
        }
    ],
    "id": "SP:008f7c08e18321d89559e0c14de1bb99f047af31",
    "references": [
        {
            "authors": [
                "S.T. Leutenegger",
                "D. Dias"
            ],
            "title": "A modeling study of the tpc-c benchmark",
            "venue": "ACM Sigmod Record, vol. 22, no. 2, pp. 22\u201331, 1993.",
            "year": 1993
        },
        {
            "authors": [
                "Eperi"
            ],
            "title": "How eperi can help to achieve compliance with strict data residency requirements",
            "venue": "[Online]. Available: https://blog.eperi.co, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "C. Curino",
                "E. Jones",
                "R.A. Popa",
                "N. Malviya",
                "E. Wu",
                "S. Madden",
                "H. Balakrishnan",
                "N. Zeldovich"
            ],
            "title": "Relational Cloud: A Database Service for the Cloud",
            "venue": "5th Biennial Conference on Innovative Data Systems Research, Asilomar, CA, January 2011.",
            "year": 2011
        },
        {
            "authors": [
                "R.A. Popa",
                "C.M.S. Redfield",
                "N. Zeldovich",
                "H. Balakrishnan"
            ],
            "title": "Cryptdb: Protecting confidentiality with encrypted query processing",
            "venue": "Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles, ser. SOSP \u201911. New York, NY, USA: ACM, 2011, pp. 85\u2013 100. [Online]. Available: http://doi.acm.org/10.1145/2043556.2043566",
            "year": 2011
        },
        {
            "authors": [
                "S. Tu",
                "M.F. Kaashoek",
                "S. Madden",
                "N. Zeldovich"
            ],
            "title": "Processing analytical queries over encrypted data",
            "venue": "Proc. VLDB Endow., vol. 6, no. 5, pp. 289\u2013300, Mar. 2013. [Online]. Available: http://dx.doi.org/10.14778/2535573.2488336",
            "year": 2013
        },
        {
            "authors": [
                "H. Hacig\u00fcm\u00fc\u015f",
                "B. Iyer",
                "C. Li",
                "S. Mehrotra"
            ],
            "title": "Executing sql over encrypted data in the database-service-provider model",
            "venue": "Proceedings of the 2002 ACM SIGMOD international conference on Management of data, ser. SIGMOD \u201902. New York, NY, USA: ACM, 2002, pp. 216\u2013 227. [Online]. Available: http://doi.acm.org/10.1145/564691.564717",
            "year": 2002
        },
        {
            "authors": [
                "P. Antonopoulos",
                "A. Arasu",
                "K.D. Singh",
                "K. Eguro",
                "N. Gupta",
                "R. Jain",
                "R. Kaushik",
                "H. Kodavalla",
                "D. Kossmann",
                "N. Ogg"
            ],
            "title": "Azure sql database always encrypted",
            "venue": "Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, 2020, pp. 1511\u20131525.",
            "year": 2020
        },
        {
            "authors": [
                "P. Jagadeeswaraiah",
                "M.P. Kumar"
            ],
            "title": "Securedbaas model for accessing encrypted cloud databases",
            "venue": "Telkomnika Indonesian Journal of Electrical Engineering, vol. 16, no. 2, pp. 333\u2013340, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "E. Schikuta",
                "T. Fuerle",
                "H. Wanek"
            ],
            "title": "Vipios: The vienna parallel input/output system",
            "venue": "Euro-Par98 Parallel Processing: 4th International Euro-Par Conference. Springer, 1998, pp. 953\u2013958.",
            "year": 1998
        },
        {
            "authors": [
                "W. Mach",
                "E. Schikuta"
            ],
            "title": "A generic negotiation and re-negotiation framework for consumer-provider contracting of web services",
            "venue": "Proceedings of the 14th International Conference on Information Integration and Web-based Applications & Services, 2012, pp. 348\u2013351.",
            "year": 2012
        },
        {
            "authors": [
                "E. Schikuta",
                "T. Weish\u00e4upl"
            ],
            "title": "N2grid: neural networks in the grid",
            "venue": "2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No. 04CH37541), vol. 2. IEEE, 2004, pp. 1409\u20131414.",
            "year": 2004
        },
        {
            "authors": [
                "T. Weish\u00e4upl",
                "F. Donno",
                "E. Schikuta",
                "H. Stockinger",
                "H. Wanek"
            ],
            "title": "Business in the grid: The big project",
            "venue": "Grid Economics & Business Models (GECON 2005) of Global Grid Forum, vol. 13, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "T. Weish\u00e4upl",
                "E. Schikuta"
            ],
            "title": "Towards the merger of grid and economy",
            "venue": "Grid and Cooperative Computing - GCC 2004 Workshops, H. Jin, Y. Pan, N. Xiao, and J. Sun, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2004, pp. 563\u2013570.",
            "year": 2004
        },
        {
            "authors": [
                "E. Schikuta",
                "H. Wanek",
                "I. Ul Haq"
            ],
            "title": "Grid workflow optimization regarding dynamically changing resources and conditions",
            "venue": "Concurrency and Computation: Practice and Experience, vol. 20, no. 15, pp. 1837\u2013 1849, 2008.",
            "year": 1837
        },
        {
            "authors": [
                "K. Kofler",
                "I. Ul Haq",
                "E. Schikuta"
            ],
            "title": "A parallel branch and bound algorithm for workflow qos optimization",
            "venue": "2009 International Conference on Parallel Processing. IEEE, 2009, pp. 478\u2013485.",
            "year": 2009
        },
        {
            "authors": [
                "G. Stuermer",
                "J. Mangler",
                "E. Schikuta"
            ],
            "title": "Building a modular service oriented workflow engine",
            "venue": "2009 IEEE international conference on service-oriented computing and applications (SOCA). IEEE, 2009, pp. 1\u20134.",
            "year": 2009
        },
        {
            "authors": [
                "A. Boldyreva",
                "N. Chenette",
                "Y. Lee",
                "A. O\u2019Neill"
            ],
            "title": "Order- Preserving Symmetric Encryption",
            "venue": "Proceedings of the 28th Annual International Conference on Advances in Cryptology: the Theory and Applications of Cryptographic Techniques, ser. EUROCRYPT \u201909. Berlin, Heidelberg: Springer-Verlag, 2009, pp. 224\u2013241. [Online]. Available: http://dx.doi.org/10.1007/978-3-642-01001-9_13",
            "year": 2009
        },
        {
            "authors": [
                "D. Morris"
            ],
            "title": "Recommendation for block cipher modes of operation: methods for formatpreserving encryption",
            "venue": "NIST Special Publication, vol. 800, p. 38G, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "S. Heron"
            ],
            "title": "Advanced encryption standard (aes)",
            "venue": "Network Security, vol. 2009, no. 12, pp. 8\u201312, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "C.J. Hoofnagle",
                "B. Van Der Sloot",
                "F.Z. Borgesius"
            ],
            "title": "The european union general data protection regulation: what it is and what it means",
            "venue": "Information & Communications Technology Law, vol. 28, no. 1, pp. 65\u201398, 2019.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Database systems, Data encryption, Cloud computing\nI. INTRODUCTION\nFor storing and retrieving structured data, the relational data model is still the dominant model. More and more data is collected and stored in databases and they are a critical part in nearly every IT environment. Traditionally these databases are run in house and managed by members of the same organization using it. With the rise of cloud computing this is changing. Databases are outsourced into the cloud and run and managed by the cloud service provider. This leads to serious privacy and security concerns, because not only the members of the organization itself have access to the data, but additionally the administrators of the cloud provider too. Another serious concern is that a database, which was formally only accessible in an internal network, is now accessible over the internet. A solution to this problem is to encrypt the data with proven secure ciphers before putting it into the cloud. This approach does not work with structured data, because important properties of the data are lost during encryption.\nThe result is that the relational model does not work for the encrypted data anymore. The format of the data has changed and queries do not work the way they used to work on the plaintext data. The data model and any application depending on this schema have to be changed. Even then, the result comes with a serious performance penalty by loosing key index properties, which makes this approach often impractical. To avoid this, other solutions are required. A lot would be gained, if ciphers can encrypt the values while still keeping format, order or other query relevant properties. In the optimal case, the data model can be left unchanged, while still providing data confidentially by encryption. Of course, any application depending on such an unchanged data model can be left unchanged too, if encryption and decryption is done transparently.\nThe goal of the DiCE projects aims for a JDBC proxy which can be used as a drop in for any JDBC driver and supports different ciphers and encryption models. The solution is described and all implemented algorithms are shown in detail in this paper. An overview of the design and implementation is given, and the deployment in the cloud (AWS) is shown too. Additional ciphers can be added and configured by a simple user interface. Our approach is evaluated by using cloud based database as a service model. The performance of specific queries and general benchmarks (TPC-C [1]) is evaluated.\nThe structure of the paper is as follows: In the next section we discuss related work with a specific focus on similar systems. This is followed by the presentation of the requirements, design, and implementation of the DiCE system. Our approach is justified and thoroughly evaluated focusing on different aspects of the application domain and infrastructure. The paper closes by a summary and outlook on future work."
        },
        {
            "heading": "II. RELATED WORK",
            "text": "This chapter gives an overview of related work and other existing solution of encrypted data in the cloud. Although some of these solutions are applicable for a much broader range of problems, encrypting the data in relational databases remains here in focus."
        },
        {
            "heading": "A. Eperi Gateway",
            "text": "Eperi Data Protection for Databases1 is an approach to store only encrypted data in the database. For processing,\n1http://eperi.de/produkte/database-encryption/\nar X\niv :2\n31 0.\n05 71\n0v 1\n[ cs\n.C R\n] 9\nO ct\n2 02\n3\nthe data is decrypted by stored procedures so the cleartext is in memory of DB-Server, thus providing no real end-toend encryption. The encryption and decryption is transparent to an application, so the application does not have to be changed. Eperi gateway itself provides a lot more features. It is the central point for accessing and retrieving data from the cloud. It supports transparent encryption/decryption for different types of data and documents. A disadvantage of this central gateway approach is, that as all traffic to the cloud comes and goes through the gateway. Thus, it can be a performance bottleneck and a single point of failure [2]."
        },
        {
            "heading": "B. Relational cloud",
            "text": "Relational cloud2 is a project from MIT to explore and enhance technology of the database as a service (DBaaS) model in cloud computing. The vision of Relational cloud is to provide access to all features of a DBMS without the need to manage hardware, software and privacy. Relational cloud consists of multiple nodes running a single database server. Applications communicate by their standard interfaces like JDBC. A special driver is used to connect to the frontend to ensure data is kept private. A router is consulted by the front end to analyze the queries and it determines the execution nodes [3]."
        },
        {
            "heading": "C. CryptDB",
            "text": "CryptDB [4] is a database management system, which can execute SQL queries over encrypted data. It follows an SQLaware encryption strategy and evaluates the query directly on the server. The client must only decrypt the results and does not need to perform any query processing. The encryption can be completely transparent to an application, as long as the provided client front-end is used. CryptDB uses order preserving and homomorphic encryption.\nThe goal of CryptDB is to be as secure as possible, while still providing practical access to the database. However, CryptDB\u2019s security was analyzed and some successful attacks were revealed:\n\u2022 LP-optimization: Based on combinatorial optimization techniques, this attack targets deterministic encryption schemes. \u2022 Sorting attack: This attack decrypts order preserving encrypted columns. It works on dense sets, where nearly every value exists in the database. \u2022 Cumulative attack: Another attack on order preserving encrypted columns. It works even on low-density columns by using combinatorial optimization techniques.\nAccording to [5], there exist some CryptDB based or at least inspired solutions:\n\u2022 Monomi [5]: It is based on the design of CryptDB but with a focus on analytical queries. It runs queries on encrypted data on top of the PostgreSQL database. For the execution of complex queries, it uses the split client/server approach (similar to [6]), where part of the\n2http://relationalcloud.com\nquery is executed on the encrypted data on the server, and another part of the query is executed on the decrypted data on the client. \u2022 Microsoft\u2019s Always Encrypted SQL Server [7] \u2022 Encrypted Bigquery3: It is a cloud service for analysis\nof large data-sets from Google storage. For queries it uses an SQL dialect. Encrypted BigQuery is an extension to the Bigquery client, which is capable of client-side encryption for a subset of query types. \u2022 Skyhigh Networks4: McAfee Skyhigh Security Cloud is a cloud access security broker (CASB). This software sits between cloud service consumers and cloud service providers to enforce security, compliance, and governance policies for cloud applications. Among tons of other features, it supports encryption schemes for transparent encrypting of data going through the broker into the cloud. The Skyhigh Security Cloud supports, besides regular symmetric encryption schemes, formatpreserving and searchable encryption schemes. Among other schemes, order preserving encryption is supported too."
        },
        {
            "heading": "D. SecureDBaaS",
            "text": "SecureDBaaS [8] differs from other solutions on the application level, that it does not need a proxy to store metadata. Instead all metadata is stored encrypted on the server to avoid scalability issues. Features of SecureDBaaS are\n\u2022 guaranteed confidentiality by allowing concurrent SQL over encrypted data, \u2022 same availability, elasticity and scalability as unencrypted database as a service, \u2022 concurrent access from distributed clients, \u2022 no trusted broker or proxy required, and \u2022 compatible with most relational Databases. It is possible\nto use existing database servers like PostgreSQL or MS SQL Server."
        },
        {
            "heading": "E. CipherCloud",
            "text": "CipherCloud5 works as gateway which intercepts any traffic between a database and its clients. In fact, it uses an enhanced JDBC driver and supports format preserving encryption. It works with Amazon RDS as a database in the cloud [9].\nF. Voltage Secure\nVoltage Secure6 provides another solution for Amazon relational database service. Unlike CipherCloud it provides its service for applications in the elastic cloud although with external key management. Similar to CipherCloud, it is possible with this solution to query over encrypted data [9].\n3https://github.com/google/encrypted-bigquery-client 4https://www.skyhighsecurity.com 5http://www.ciphercloud.com/ 6https://voltage.com"
        },
        {
            "heading": "G. Perspecsys",
            "text": "CloudSOC [10] is a cloud access security broker (CASB). Part of it (Symantec Cloud Data Protection & Security) provides encryption schemes for the data stored in the cloud. Additionally to the standard schemes, it supports different functionality (including order) preserving encryption schemes.\nOur research in this area is based on our experience with large scale data stores [11] and complex applications in Grids and Clouds [12], [13], [14], [15], and strongly motivated by our focus on Web-based workflow optimizations [16], [17] and their respective management [18]."
        },
        {
            "heading": "III. THE DICE SYSTEM",
            "text": "This section presents our solution for encrypting or at least obfuscating data of a database in the cloud. It is called DICE which is the (clumsy) acronym for \u201cDatabase In the Cloud Encrypted\u201d7."
        },
        {
            "heading": "A. Requirements",
            "text": "To achieve the objective of a fully usable encrypted relational database in the cloud, multiple requirements have to be addressed:\n\u2022 Relational Model Requirements. The relational model has some implicit requirements which have to be addressed to be usable. As plain text always satisfies these requirements, ciphertext does often not (at least not out of the box). As these requirements are different for each SQL construct, the specific requirements for data definition and queries are given. \u2022 Ciphers with Properties. Although standard ciphers often do not satisfy the properties required by the relational model, ciphers exist which satisfy some or multiple of these requirements, as format preserving, order preserving, functional and homomorphic encryption. For queries, order preserving is an often needed property. Thus, different order preserving encryption schemes are implemented. \u2022 Requirements for Cloud Computing. Moving data to the cloud requires additional concerns, especially but not only, regarding security. Contradictions between security requirements and other cloud-specific requirements, like scalability or elasticity, have to be addressed."
        },
        {
            "heading": "B. Architecture",
            "text": "With DiCE the data is always encrypted and decrypted in the application layer. In the database as a service scenario, this means that the data is always stored encrypted and never as plaintext in the cloud. To avoid the effort to change each application for each database at least for java applications, DiCE is implemented as a JDBC driver. This makes transparent encryption for the database and the application possible. As DiCE is in fact a proxy for a real JDBC driver, any application accessing a database via JDBC can use DiCE to add transparent encryption.\n7The source is available at https://github.com/dicejk/dice\nAn overview of the architecture of DiCE is shown in Figure 1. As shown, DiCE works as layer between the application and the database. Its main purpose is to transparently encrypt and decrypt data for an application using it as a JDBC driver. Apart from working as a JDBC driver, DiCE also provides the functionality for the configuration, management and traceability of different ciphers and keys."
        },
        {
            "heading": "C. DiCE Components",
            "text": "DiCE consists of four components, where all its classes are residing in their respective Java package.\n\u2022 dice.sql - This package contains the JDBC proxy driver itself. All necessary interfaces for JDBC are implemented, and all queries are parsed and transparently encrypted and decrypted using the ciphers in the package dice.cipher. \u2022 dice.cipher - This package contains the ciphers available for dice. Each cipher provides its own configuration and user interface. \u2022 dice.info - This package contains everything needed to monitor the execution of the encryption and decryption in the driver. A small server receives the messages from the driver. The information can be shown in client application either using a graphical user interface or the command line. \u2022 net.sf.jsqlparser - This external package contains a slightly modified open source implementation of an SQL parser."
        },
        {
            "heading": "D. Supported Ciphers",
            "text": "DiCE supports different kinds of ciphers with different attributes regarding order preserving, format preserving and encryption strength. These are only examples of simple ciphers, but as long as the provided interface is implemented, any other cipher can be used.\n\u2022 Caesar Cipher \u2022 Generic Substitution Cipher \u2022 Order Preserving Encryption OPE [19] (JOPE was used,\na implementation of order-preserving encryption in Java8) \u2022 Format Preserving Encryption FF1 [20] (FPE4J was\nused9) \u2022 Advanced Encryption Standard AES [21] (javax.crypto\nwas used)\nThe first two ciphers are classical ciphers and therefore are not suitable for serious encryption in the cloud. They are only obfuscating the data, which can be a wanted feature. However, they are a nice showcase for interesting properties like order preserving encrypting for data in a database. OPE [19] is one of the modern order preserving ciphers. FF1 [20] is a standard format preserving cipher for numeric values. The last cipher AES [21] is one of the standard symmetric block ciphers, which provides proved strong encryption, but misses important properties for the general use in a database. If order or format preserving properties are not needed it is the best choice from an security view port (ECB mode is possible)."
        },
        {
            "heading": "E. Cloud Deployment",
            "text": "To show the use of DiCE in the cloud, an example configuration of a database setup using Amazon Web Service is given. Amazon offers a service called RDS, which stands for \u201cRelational Database Service\u201d and is a web service implementing the Database-As-a Service scenario in the cloud. Different database engines in many configurations are offered by Amazon, but in this showcase only the smallest configuration using MySQL is chosen."
        },
        {
            "heading": "IV. DICE USER INTERFACE",
            "text": "DiCE has a minimal user interface developed with Swing for configuration and for showing the SQL query transformation including encryption and decryption."
        },
        {
            "heading": "A. Configuration Client",
            "text": "The configuration client is a minimal application to configure DiCE by simply setting properties for the driver and optionally the used cipher. As shown in Figure 2 the class of the used cipher (dice_cipher_class) and an parameter for that cipher (dice_shift) is set.\n8https://github.com/ssavvides/jope 9https://github.com/zone1511/fpe4j"
        },
        {
            "heading": "B. DiCE Information Client",
            "text": "Figure 3 shows the graphical version of the Information Client. After connecting to the Server, all SQL queries are shown in plain text and in ciphertext. Additionally all operations of encryption and decryption are listed."
        },
        {
            "heading": "C. Application Using DiCE As Driver",
            "text": "To show the usage as driver the SQL query tool SQuirreL is used. To connect to the database the DiCE driver has to be selected and the URL of the original JDBC driver has to be prefixed by jdbc:dice (as shown in Figure 4). Other settings are the same as for the original driver. SQuirreL SQL10 was used as SQL client, but any other supporting JDBC would work too.\n10http://squirrel-sql.sourceforge.net/"
        },
        {
            "heading": "D. Performing a query",
            "text": "Figure 5 shows a query using the DiCE driver. As the encryption and decryption of the query is completely transparent to the application, no difference between the original driver and the DiCE driver can be seen."
        },
        {
            "heading": "E. Encrypted Metadata",
            "text": "Table and column names are encrypted by DiCE too. Figure 6 shows the encrypted metadata in SQuirreL."
        },
        {
            "heading": "F. Encrypted Schema and Result",
            "text": "To show the real data and metadata the original driver is used in the Figure 7. This figure shows the encrypted table names and the content after using DiCE with the Caesar cipher."
        },
        {
            "heading": "G. Decrypted Results",
            "text": "Figure 8 shows the same result as above, but now using the DiCE driver, thus transparently decrypting the data."
        },
        {
            "heading": "V. EVALUATION",
            "text": "The performance of DiCE was evaluated in two different ways. First the standard TPC-C benchmark was used, with an implementation based on JDBC. This benchmark was executed local (i.e. not in the cloud). Additional to the standard benchmark the performance of custom analytical queries was analyzed. A common data model for benchmarks was used and the results were measured locally and by running the queries on different databases in the cloud. For the cloud part of the evaluation AWS RDS was used. As the encryption and decryption is performed on the client, DiCE was profiled with the tool VisualVM to show differences between the used ciphers."
        },
        {
            "heading": "A. TPC-C Performance",
            "text": "The TPC-C benchmark simulates a complete business cycle. Multiple business transaction are executed beginning with creation of orders, querying of existing orders, payment by customers and observing stock levels of warehouses. The metric for the TPC-C benchmark is the \u201cMaximum Qualified Throughput\u201d (MQTh). It is the number of orders processed per minute.\nTCJ (TPC-C via JDBC) is an implementation of the TPC-C benchmark in Java. It uses JDBC to connect to the database11. The benchmark was executed with the following parameters:\n\u2022 -w 10 (number of warehouses) \u2022 -r 1 (length of ramp-up phase) \u2022 -m 10 (length of measurement interval)\nIt was executed with the plain JDBC driver and with the DiCE driver using a simple rotating cipher. It is interesting to see that although the results (the throughput) are very similar, the curves look differently. Using the DiCE driver results in a 12% longer run time. High throughput is reached after 120 seconds, whereas the standard driver reaches the high throughput already after 60s. It shows that the overhead of the SQL parsing in the DiCE driver has impact on the response time of every single transaction, but only a small impact on the throughput.\n1) Throughput using the MySQL driver: Using the MySQL JDBC driver a throughput of 127 MQTh was measured. The run time took 750 seconds and the peak throughput was 143 MQTh (see Figure 9).\n2) Throughput using the DiCE driver: Using the DiCE driver with the rotating cipher a throughput of 124 MQTh was measured. The run time took 840 seconds and the peak throughput was 143 MQTh (see Figure 10).\n11http://sourceforge.net/projects/tpcc-jdbc/"
        },
        {
            "heading": "B. Query Evaluation",
            "text": "As sample data model the Dell DVD Store12 was used. The Entity-Relationship diagram is shown in Figure 11.\n1) Selected SQL Queries: As each cipher determines the properties of the ciphertext, we used a selection of SQL queries to show the operations supported on the ciphertext. For example, if a query on the plain text requires the operator \u201c>\u201d, this operator has to be supported on the ciphertext as well to retrieve the correct result. The SQL queries comprised:\n\u2022 Simple Query with Projection\nSELECT C.FIRSTNAME, C.LASTNAME FROM CUSTOMERS C WHERE C.CUSTOMERID = \u2019123456789\u2019\n\u2022 Query with Join\n12https://linux.dell.com/dvdstore/\nSELECT DISTINCT C.FIRSTNAME, C.LASTNAME FROM CUSTOMERS C INNER JOIN ORDERS O ON\nC.CUSTOMERID = O.CUSTOMERID WHERE O.ORDERDATE > \u20192010-12-30\u2019\n\u2022 Query with Order by\nSELECT FIRSTNAME,LASTNAME,AGE FROM CUSTOMERS C ORDER BY C.AGE LIMIT 5\n\u2022 Query with Where clause =, >,<\nSELECT * FROM CUSTOMERS C WHERE C.INCOME < 20001\n\u2022 Query with Between\nSELECT count(*) FROM CUSTOMERS C WHERE C.INCOME BETWEEN 30000 AND 40000\n\u2022 Query with Like\nSELECT * FROM CUSTOMERS C WHERE C.LASTNAME LIKE \u2019%MEI%\u2019\n\u2022 Query with Aggregate (avg,max,sum)\nSELECT MAX(C.INCOME) FROM CUSTOMERS C\n\u2022 Query with Functions\nSELECT * FROM CUSTOMERS C WHERE C.INCOME = C.AGE * 1000\n\u2022 Query with Group by, having\nSELECT SUM(O.QUANITY) FROM ORDERLINES O GROUP BY PROD_ID HAVING ORDERDATE >\n\u201915-12-2017\u2019\n2) Local Evaluation: The evaluation has been performed on a Lenovo Thinkpad T460s running windows 10. The relational database for local queries has been installed on a virtual machine running Linux. All evaluation programs and the DiCE driver itself have been running under Windows directly avoiding the bias of a virtual environment.\na) Database Load: The first test was simple. We inserted the data into the local database. A small database with the size of 100MB was created. The evaluation was executed with the standard JDBC driver (plain text) and the DICE driver with various ciphers. The run time with DiCE is about 2,5x times longer with the use of a dummy cipher and about 3x longer with a real cipher. The overhead of the ciphers is small compared to the overhead of parsing and rewriting the SQL\nstatement (see Figure 12).\nUsing local networking and VisualVM 1.3.9 as profiler for DiCE with Caesar cipher, the following results were retrieved: It shows the significant overhead of DiCE. The PreparedStatement itself is about 1/3 of the run time. The rest is the DiCEPreparedStatement where the cipher itself costs about 16% of the total run time (see Figures 13 and 14 respectively).\nb) SQL Queries: The queries were evaluated comparing plain text and DiCE. The result shows a significant overhead of DiCE. It is interesting to see, that while the queries without DiCE differ large in run time (0,71s - 3,128s), the relative difference of the run time of the queries with DiCE is much smaller, because the parsing overhead and additional processing overhead of the JDBC proxy is nearly constant (see Figure 15).\nThe absolute numbers are shown in Tables I and II respectively.\nc) Naive Implementation vs DICE Caesar: The last local evaluation was to run the queries with DiCE and compare them against a naive implementation, where no properties in the encrypted database are preserved. Even for a small data set the naive implementation is 2 orders of magnitude slower than the order preserving implementation (see Figure 16).\nThe absolute numbers are shown in Tables III.\n3) Multiple local concurrent connections: The last local evaluation shows the impact of using multiple local clients accessing a local database. The run time per client stays constant and does not scale (or only slightly). It seems like 10 clients and the server are enough to utilize the machine to capacity (see Figure 17)."
        },
        {
            "heading": "C. Cloud Evaluation",
            "text": "1) Cloud Service Provider: The evaluation in the cloud was performed using the AWS relational database service. The same select-statements were performed on the plain text and the encrypted data. Additionally to that, \u201cnaive queries\u201d were performed for comparison. These are different queries, because they represent the case where no properties are preserved by the encryption. Thus, the whole data as to be retrieved and decrypted before processing the result. To import the data of the local databases in the cloud databases mysqldump was used. This is much faster than to insert the data with JDBC again.\n2) Plain and DiCE vs Naive: For the first tests the smallest configuration AWS db.t2.micro was used. It features 1 CPU, 1 GB RAM, SSD as storage and was running in region EU (Frankfurt). MySQL 5.6.27 was used as database. All tests where performed multiple times, to get more accurate results. The performance is depicted in Figure 18.\nIt is interesting to see that there is nearly no difference between DiCE and the plain text anymore. The naive approach is clearly inferior, with a run time about 26x slower than the others. CPU utilization of the database was about 60%.\nThe absolute numbers are shown in Tables IV, V, and VI respectively.\n3) Multiple parallel Clients: To get more load on the server we used the same configuration as before. OPE as cipher was used, but this time with multiple clients (all running on the same machine) querying the server simultaneously. This resulted in higher load on the server (80% and more) and showed the same effect as in the TPC-C benchmark: the average run time per client decreased. The load on the client and the network was negligible (see Figure VII).\nAlthough the total run time is longer, the run time per client is decreasing (see Figure VIII):\n4) Different Cloud Configurations: To examine the impact of different RDS configurations 3 configurations were selected:\n\u2022 t2.micro (1 CPU, 1GB RAM) \u2022 t2.large (2 CPU, 8GB RAM) \u2022 m4.large (4 CPU, 16GB RAM)\nTo avoid the network as bottleneck, these tests were executed with a 100 MBiT network connection to the internet. Whereas the more powerful configurations perform the same, the run time of the clients querying the smallest database is halved (see Figure 19).\nTo confirm the assumption, the CPU utilization was monitored, showing nearly 100% CPU workload, as shown in Figure 20."
        },
        {
            "heading": "D. Findings",
            "text": "First of all, the naive approach of selecting all data, decrypting it on the client and filtering it in the program, does simply not work. Even for a tiny data model, these queries take between 26x and 88x longer than by using the order preserving encryption of DiCE. Thus, this is a no viable solution for using an encrypted database in the cloud. However, the results of DiCE are different.\n1) DiCE Performance: DiCE has a nearly constant overhead for parsing each query and passing it to the real JDBC driver. This overhead is significant and has a great impact on the response time of an individual query. The impact is between 4x - 18x depending on the query. This does not sound good, but if multiple queries are executed in parallel, this overhead is reduced to about 2.5x in total. The impact on the throughput measured with TCJ is even smaller. The throughput here is only 3% less than without encryption, while the overall run-time is about 15% longer. This is consistent with the results of the selected queries, which show that the impact on throughput is much smaller than on response time. But beside the parsing and processing of the SQL in the JDBC\nproxy, the following factors also have significant impact on the overall performance.\n\u2022 Used Cipher \u2022 Encrypted Metadata \u2022 Local / Network\na) Impact of used cipher: The ciphers had only a small impact on the overall performance. The difference between them was only about 15%. Only the dummy implementation of a cipher (NullCipher), was about 30% faster than the slowest real cipher. This can be explained by the big influence of the parsing on performance, which reduces the impact of the chosen cipher on the overall performance. These results are only valid for the tested ciphers. Use of a more secure but less efficient cipher can dramatically change these results.\nb) Impact of metadata encryption: The encryption or not encryption of metadata, as encrypting table or attribute names, had no measurable impact on the performance. The reason for this is that metadata is only retrieved once per table, which causes only very few calls compared to calls for encrypting and decrypting the normal data.\nc) Impact of the network (Cloud): The network has a big impact on the overall performance. The penalty is highly dependent on the speed of the network and by the amount of data transferred between the client and the server in the cloud. In the tests performed, the influence on the overall performance was so high, that any run-time differences between DICE and the direct use of the native driver nearly vanished complete.\n2) Using DiCE in the Cloud: The performance results for using an encrypted database with DiCE in the cloud look promising. Yes, there is an overhead, but it is almost negligible compared to deploying the data without encryption in the cloud."
        },
        {
            "heading": "VI. FUTURE WORK AND OUTLOOK",
            "text": "Currently, the supported ciphers for DiCE are AES as an example for a cipher without properties, JOPE as an example of order preserving encryption and FF1 as example for format preserving encryption. Additionally classic algorithms like Caesar\u2019s and generic rotation ciphers exist. This leaves room for more ciphers for test. As of the time of writing, the implementation is limited to string and number types, so the support of other types, like date or decimal, would be interesting. JDBC is supported, but the other common database interface ODBC is not supported. Not all types and SQL statements are supported, it would be interesting in supporting for example LIKE (which requires a searchable encryption scheme) or aggregate functions like SUM (which requires a homomorphic encryption scheme). The user interface is currently the absolute minimum to be usable. In fact it just sets the necessary system properties. Here, a lot of improvements are possible. Another open question touches security. Is there any evidence that in house administrated databases are more secure than outsourced databases? Is the database a service scenario eventually even more secure than the in house alternatives.\nOptimal order preserving encryption is here, but it has to prove itself over the years. As of today, no high quality standard implementation, as for example for AES, exists. This will hopefully change soon.\nThe big elephant in the room is fully homomorphic encryption, and future will show, if it is possible to develop a secure and well performing cipher. If it is possible to achieve this, the impact goes far beyond database encryption, because then it would be possible to directly operate on the encrypted data and move the whole data processing in the cloud, too.\nQuantum computing could be a disruptive technology for many ciphers, which are currently believed to be secure.\nThe adoption of cloud computing is continuing to grow, but as more and more important services rely on it, it seems very likely that more legislative control will be applied to it. Privacy and security in and outside the cloud will be more important than ever, and legislative regulation like GDPR will become more and more relevant."
        },
        {
            "heading": "VII. CONCLUSION",
            "text": "Collecting and storing only the minimal required data seems obvious, but often it is not. The GDPR (General Data Protection Regulation) [22] makes data minimization of personal data a principle and from a security point of view this makes absolute sense. Never collected data does not have to be stored, maintained and protected. But there are enough systems, where sensible data is definitely needed. Here it is crucial to make this classification as sensible data explicit. Without this knowledge, it is impossible to protect it accordingly. Mixing sensitive with non sensitive data is also a bad idea, because then everything has to be handled as sensitive data and this comes with an overhead. Often it is good practice to separate sensitive tables or even systems from non sensitives, but this will work only if considered from start.\nThis paper discussed many ciphers, with different properties and different strength of security. It is recommended to always go for the best matching cipher regarding security requirements and needed functionality, even if that means to use multiple different ciphers. Here, the use of the smallest common denominator is definitely no good idea, as there is no perfect cipher which is best for all use cases. Ciphers with specific properties required for queries on encrypted data are available and usable. Order preserving encryption schemes with best possible security exist, but they are still not as secure as algorithms without additional properties. It is important to know, that these ciphers are relatively new and not analyzed in depth like standard algorithms as AES, for example. Of course often not optimal encryption is better than none, but it is important to know about the weaknesses of these ciphers. As a result, is not recommended to use any non standard encryption schemes for high classified data.\nThe use of these ciphers also does not come for free. There is a certain overhead by embedding the encryption in a JDBC driver compared to using the native JDBC driver of the database directly. The reason for this is that much more processing has to be done before sending the query to\nthe server. The SQL statement has to be parsed, encrypted and sometimes rewritten before it is forwarded to the real driver. The results of a query have to be parsed and decrypted again. The performance results show that the response time is significant higher, but by simulating multiple simultaneous queries the impact on the throughput is not as dramatic. Compared with the naive approach, by not enabling joins or indices on the encrypted data the result is clear: The naive approach is simple not working for anything but toy projects.\nAs DiCE makes it possible to use any database supporting JDBC, it was good to see that MySQL and Microsoft SQLServer worked as expected. Of course, as DiCE uses its own SQL parser it is necessary to use standard SQL, even if the underlying driver would support some specific extensions of the standard. Making the ciphers interchangeable makes it easy to implement and evaluate new ciphers. So DiCE can be also seen as a test bed for some property preserving ciphers. Making this more adaptable for specific columns and multiple ciphers simultaneously would be a good feature, too.\nOf course, it can not repeated more often that security is more than encryption, and a lot more than encrypting the database has to be done to achieve security. Using the database as service solutions from AWS and Azure worked like a charm. It literally takes only 5 minutes and a database is up and running and available for operation.\nSumming up, DICE proved as viable solution for encrypting database data at rest in the Cloud and the additional costs are acceptable."
        }
    ],
    "title": "DiCE - A Data Encryption Proxy for the Cloud",
    "year": 2023
}