{
    "abstractText": "Weather forecasting primarily uses numerical weather prediction models that use weather observation data, including temperature and humidity, to predict future weather. The Korea Meteorological Administration (KMA) has adopted the GloSea6 numerical weather prediction model from the UK for weather forecasting. Besides utilizing these models for real-time weather forecasts, supercomputers are essential for running them for research purposes. However, owing to the limited supercomputer resources, many researchers have faced difficulties running the models. To address this issue, the KMA has developed a low-resolution model called Low GloSea6, which can be run on small and medium-sized servers in research institutions, but Low GloSea6 still uses numerous computer resources, especially in the I/O load. As I/O load can cause performance degradation for models with high data I/O, model I/O optimization is essential, but trial-and-error optimization by users is inefficient. Therefore, this study presents a machine learning-based approach to optimize the hardware and software parameters of the Low GloSea6 research environment. The proposed method comprised two steps. First, performance data were collected using profiling tools to obtain hardware platform parameters and Low GloSea6 internal parameters under various settings. Second, a machine learning model was trained using the collected data to determine the optimal hardware platform parameters and Low GloSea6 internal parameters for new research environments. The machine-learning model successfully predicted the optimal parameter combinations in different research environments, exhibiting a high degree of accuracy compared to the actual parameter combinations. In particular, the predicted model execution time based on the parameter combination showed a significant outcome with an error rate of only 16% compared to the actual execution time. Overall, this optimization method holds the potential to improve the performance of other high-performance computing scientific applications. INDEX TERMS Scientific Application, GloSea6, Machine Learning, I/O Optimization, Profiling",
    "authors": [
        {
            "affiliations": [],
            "name": "Soohyuck Choi"
        },
        {
            "affiliations": [],
            "name": "Eun-Sung Jung"
        }
    ],
    "id": "SP:f9de46576a08df4473a35e53813c8fb66c74dbee",
    "references": [
        {
            "authors": [
                "P. Davis",
                "C. Ruth",
                "A.A. Scaife",
                "J. Kettleborough"
            ],
            "title": "A Large Ensemble Seasonal Forecasting System: GloSea6",
            "venue": "vol. 2020, pp. A192-05, Dec. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "B. Behzad",
                "H.V.T. Luu",
                "J. Huchette",
                "S. Byna",
                "R. Aydt",
                "M.Q. Koziol"
            ],
            "title": "Sniret al., \u201cTaming parallel I/O complexity with auto-tuning",
            "venue": "Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis. ACM,",
            "year": 2013
        },
        {
            "authors": [
                "B. Behzad",
                "S. Byna",
                "Prabhat",
                "M. Snir"
            ],
            "title": "Optimizing I/O performance of HPC applications with autotuning",
            "venue": "ACM Trans. Parallel Comput., vol. 5, no. 4, pp. 1\u201327, Mar. 2019, doi: 10.1145/3309205.",
            "year": 2019
        },
        {
            "authors": [
                "S. Robert",
                "S. Zertal",
                "G. Goret"
            ],
            "title": "Auto-tuning of IO accelerators using black-box optimization",
            "venue": "International Conference on High Performance Computing & Simulation (HPCS),",
            "year": 2019
        },
        {
            "authors": [
                "A. Ba\u011fbaba",
                "X. Wang",
                "C. Niethammer",
                "J. Gracia"
            ],
            "title": "Improving the I/O Performance of Applications with Predictive Modeling based Auto-tuning",
            "venue": "2021 International Conference on Engineering and Emerging Technologies (ICEET), Oct. 2021, pp. 1\u20136. doi: 10.1109/ICEET53442.2021.9659711.",
            "year": 2021
        },
        {
            "authors": [
                "S. Valcke",
                "R. Redler"
            ],
            "title": "The OASIS Coupler",
            "venue": "Earth System Modelling \u2013 vol. 3, Berlin, Heidelberg: Springer Berlin Heidelberg, 2012, pp. 23\u201332. doi: 10.1007/978-3-642-23360-9_4.",
            "year": 2012
        },
        {
            "authors": [
                "P. Carns",
                "R. Latham",
                "R. Ross",
                "K. Iskra",
                "S. Lang",
                "K. Riley"
            ],
            "title": "24/7 characterization of petascale I/O workloads",
            "venue": "Proceedings of 2009 Workshop on Interfaces and Architectures for Scientific Data Storage, September 2009.",
            "year": 2009
        },
        {
            "authors": [
                "R. Ross",
                "D. Nurmi",
                "A. Cheng",
                "M. Zingale"
            ],
            "title": "A case study in application I/O on Linux clusters",
            "venue": "Proceedings of the 2001 ACM/IEEE conference on Supercomputing, New York, NY, USA, Nov. 2001, p. 11. doi: 10.1145/582034.582045.",
            "year": 2001
        },
        {
            "authors": [
                "S. Herbein"
            ],
            "title": "Scalable I/O-aware job scheduling for burst buffer enabled HPC clusters",
            "venue": "Proceedings of the 25th ACM International Symposium on High-Performance Parallel and Distributed Computing, New York, NY, USA, May 2016, pp. 69\u201380. doi: 10.1145/2907294.2907316.",
            "year": 2016
        },
        {
            "authors": [
                "R. Genuer",
                "J.-M. Poggi"
            ],
            "title": "Tuleau, \u201cRandom Forests: some methodological insights.",
            "venue": "arXiv, Nov",
            "year": 2008
        },
        {
            "authors": [
                "T. Hastie",
                "R. Tibshirani",
                "J. Friedman"
            ],
            "title": "The Elements of Statistical Learning. in Springer Series in Statistics",
            "year": 2009
        },
        {
            "authors": [
                "admin"
            ],
            "title": "SSD vs HDD - Comparing Speed, Lifespan, Reliability",
            "venue": "Tekie, Sep. 23, 2022. https://tekie.com/blog/hardware/ssd-vs-hddspeed-lifespan-and-reliability/ (accessed Feb. 15, 2023).",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "VOLUME XX, 2017 1\nINDEX TERMS Scientific Application, GloSea6, Machine Learning, I/O Optimization, Profiling\nI. INTRODUCTION Significant advancements in computing performance have facilitated the emergence of numerical weather prediction (NWP) [1] models that use large-scale numerical computations for weather forecasting. Since 1999, the Korea Meteorological Administration (KMA) has been using a global data assimilation and prediction system based on the global spectral model, which is based on the global spectrum model from the Japan Meteorological Agency. The KMA introduced the global NWP model GloSea6 [2] from the UK Met Office in 2022 and has since used it for weather forecasting.\nGloSea6 comprises two main models: ATMOS and OCEAN. The ATMOS model comprises atmospheric (UM) and land surface (JULES) models, while the OCEAN model comprises ocean (NEMO) and sea ice (CICE) models. Model execution begins after a preprocessing stage, during which the Earth is divided into grids, and initial and auxiliary data called analysis fields are collected for each grid. Subsequently, the analysis fields are used to prepare input fields for the forecast model, after which numerical model calculation begins.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nOwing to its high demand for computing resources, the KMA provides a low-resolution version of GloSea6 called Low GloSea6 for researchers who lack access to supercomputers. However, even Low GloSea6 requires significant computing resources, and as the model has a high data input/output (I/O) nature, I/O optimization is essential. Notably, general users, who are atmospheric science researchers and not computer scientists, may find conducting performance optimization through trial-and-error inefficient. This paper presents a machine learning-based approach to optimize the hardware and software parameters of the Low GloSea6 research environment.\nThis study proposes a new cross-inference optimization method for the NWP model Low GloSea6 using machine learning and benchmark tools. Specifically, the following are detailed:\n\u2022 We defined the entire workflow for performance cross-validation and validated it through experiments. \u2022 Necessary data for cross-inference were categorized into two types: execution hardware platform parameters and internal software parameters of Low GloSea6, and important parameters among them were extracted through model/data validation. \u2022 We used Darshan to collect detailed data on I/O characteristics and verified the final results using runtime data to perform I/O performance crossvalidation. \u2022 This study demonstrates the applicability of various machine-learning techniques to explain the complex interactions between the execution hardware platform parameters and the Low GloSea6 internal software parameters, thereby making it feasible to cross-infer performance on a new execution hardware platform. \u2022 The proposed method has been generalized throughout the workflow, demonstrating that it is a general methodology that is not limited to Low GloSea6, which is the subject of this paper.\nThis paper is structured as follows: Section 2 describes related research, while Section 3 provides a detailed description of GloSea6, a numerical model for weather prediction, and the profiling tool used for performance data collection. Section 4 explains the hardware/software optimization methodology in the research environment, including the dataset and model used. In Section 5, the experiments conducted using the optimization methodology after the model and data verification are described and analyzed. Section 6 presents the conclusion and future plans. II. RELATED RESEARCH\nOptimization studies for applications running in real-world or research environments have been conducted in various fields. One such approach is the modification of I/O library\ncodes to achieve I/O optimization of applications. M. Howison [3] demonstrated performance improvements for highperformance computing (HPC) applications through code modifications and optimizations of HDF5 and MPI-IO libraries, considering the file system characteristics.\nAnother research method is to achieve I/O optimization by deriving optimal file systems and I/O library parameters. In addition, B. Behzad [4]-[5] used a genetic algorithm to optimize the I/O performance of an application. They created a set of parameters by exploring the file system and I/O library parameter space, measured the I/O performance of the benchmark tool using the parameter set, and iteratively optimized the parameter set based on the measurements until the best I/O performance was achieved. S. Robert [6] optimized an I/O accelerator using black-box optimization techniques that find input parameters with maximum and minimum performance metrics without considering internal mechanisms. They optimized three input parameters (I/O throughput, I/O latency, and I/O memory usage) of the Atos Flash Accelerator, an I/O accelerator that accelerates I/O operations of various HPC applications using NAND flash memory technology, and used basic metrics, such as I/O operation processing time, as performance indicators. Finally, they validated that the I/O accelerator performance can be improved by applying black-box optimization. A. Ba\u011fbaba [7] implemented an automated tuning solution for the optimal parameters of Luster parallel file system and MPI-IO ROMIO library, a high-performance implementation of MPI-IO, using I/O monitoring and performance prediction. The solution employed a random forest-based machine-learning algorithm and was validated using two benchmarking tools (IOR-IO and MPI-Tile-IO) and a molecular dynamics model (ls1 Mardyn.\u201d).\nOur research differs from previous studies in two ways. First, our study enables easy optimization, even without prior I/O optimization knowledge. While M. Howison [3] achieved I/O performance optimization by modifying the I/O library code, this approach requires a developer's expertise and is not easily accessible to general users. In contrast, our research focuses on machine learning-based performance optimization that is easily modifiable and accessible by considering the hardware and software parameters of the research environment. Second, our study simultaneously considers hardware platform parameters and internal software parameters. B. Behzad [4]-[5] optimized I/O using adjustable parameters in the parallel I/O stack, specifically related to file systems, HDF5, and MPI-IO libraries. However, the research did not consider benchmark tool parameter optimization. S.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nRobert [6] used the parameters of I/O throughput, I/O latency, and I/O memory usage of the Atos Flash Accelerator I/O accelerator for its optimization. These parameters are internal software parameters mentioned in this paper, and hardware platform parameters were not considered.\nOur research has broad applicability. A. Ba\u011fbaba study [7] focused on the MPI-IO ROMIO library and Luster parallel file system in a single research environment, which limits its generalizability. In contrast, we collected data in two different research environments and conducted validation on different hardware platform environments using Low GloSea6. In addition, we used MPICH, an MPI-IO implementation with high accessibility that can be applied regardless of the specific implementation version of MPICH. To verify this, we conducted experiments in research environments using different versions of MPICH."
        },
        {
            "heading": "III. BACKGROUND",
            "text": ""
        },
        {
            "heading": "A. NUMERICAL WEATHER FORECASTING: GLOSEA",
            "text": "The ATMOS and OCEAN models are coupled using the Ocean Atmosphere Sea Ice Soil 3-Model Coupling Toolkit (OASIS3-MCT) Coupler [8] to share their results. Figure 1 illustrates the collaboration structure of the two models. The Glosea6 model performs simulations in 15-day increments, saving the results to a file and proceeding to the next step. The saved file is used as the initial data for the simulation in the following step. Therefore, the numerical model calculations restart at each step. As shown in Fig. 1, the ATMOS model produces Fieldsfile (ff) [9] data, while the OCEAN model produces data in NetCDF (nc) [10] file format. Forecast (FCST) and Hindcast (HCST) data are generated to predict future and reproduce past situations, respectively. Ensemble probability predictions are generated by comparing the FCST and HCST data using the average of multiple models. The generated ensemble prediction data is verified by comparing it with observation data using various verification metrics. Deterministic verification techniques such as Bias, RMSE, and Correlation are used for data comparison, and probabilistic verification techniques such as Brier Skill Score and Reliability Diagram are used.\nThe operating system of GloSea6 is based on special software implemented with Jinja2 called ROSE and CYLC. ROSE is a tool used to easily create, edit, and execute suites,\nwhich are units that manage one or more consecutive tasks or processes. ROSE can set compile options and computer resources, etc., through the suite configuration files \u201croseapp.conf\u201d and \u201crose-suite.conf.\u201d Figure 2 shows the configuration screen using the ROSE graphical user interface, which allows for easy configuration. CYLC is a workflow engine used to execute suites. The task sequence is set through the \u201csuite.rc\u201d file, and as shown in Fig. 3, workflow visualization and control are possible.\nTable I shows the sequence and content of GloSea6's suite operations, where \u201cgsfc\u201d represents the process of producing Forecast data and \u201cgshc\u201d represents the process of producing Hindcast data. Relevant source codes are obtained through FCM, a scientific application wrapper for SubVersion (SVN), during the 'Compilation step'.\nFIGURE 1. Combined model implementation process.\nFIGURE 3. CYLC Graphical User Interface.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nComplex models like GloSea6 require the use of supercomputers not only for actual weather forecasting but also for research purposes. However, considering the limited resources of supercomputers, many researchers have faced challenges in running the model. To address this issue, the KMA developed a low-resolution model called Low GloSea6, which can be run on small- to medium-sized servers in research institutions.\nLow GloSea6 is a low-resolution coupled model similar to GloSea6 but with a grid size of 60 km extended up to 170 km. Unlike GloSea6, which runs both ROSE and CYLC on a single supercomputer platform, Low GloSea6 uses multiple platforms such as client local PC and computer cluster, as shown in Fig. 4. The suite's working environment and operational settings are configured through ROSE/CYLC, and the suite is then transmitted to the computer cluster using secure shell (SSH).\nThe computer cluster refers to the assigned values in ROSE to proceed with compilation and resource allocation of the received suite, and performs all tasks sequentially or in parallel through CYLC. In addition, the order and content of the suite in Low GloSea6 differ from those in GloSea6. While GloSea6 performs the \u201cModel run step\u201d after the \u201cCompilation step,\u201d according to Table I, Low GloSea6 does not perform \u201cgshc\u201d and \u201cgsfc_redate_cice\u201d tasks because the initial fields are already set."
        },
        {
            "heading": "B. PROFILING TOOL",
            "text": "The ATMOS and OCEAN models of Low GloSea6, which are the performance measurement targets, are HPC applications based on the message passing interface (MPI). We used Darshan [11]-[12], an HPC I/O profiling tool that can measure and analyze the performance of the MPI I/O and POSIX I/O of HPC applications.\nFIGURE 4. The overall composition of Low GloSea6.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nDarshan is an open-source I/O profiling tool used to understand the I/O characteristics of HPC applications. As shown in Fig. 5, Darshan comprises two components: Darshan-runtime, which generates I/O activity logs for HPC applications, and Darshan-util, which analyzes log contents.\nFigure 7 shows the partial Darshan log analysis files for the ATMOS and OCEAN models.\nFor item 1, the filename of the profiled HPC application and the measurement date are recorded. When ATMOS and OCEAN models are executed simultaneously, the measurement is performed concurrently, but the filename is written based on the application name that appears first in the execution command, which is \u201catmos.exe\u201d in this case. For item 2, \u201cnprocs\u201d represents the number of processes used in the application, and runtime indicates the execution time. The\nATMOS and OCEAN models recorded in the PDF file were assigned four processes each, and nprocs is recorded as 8, which is the sum of the process allocation values for both models. The model ran for 1732 seconds, and the amount of data transferred (in MiB) and bandwidth (in MiB/s) through MPI-IO, POSIX, and STDIO I/O functions can be checked in the 'I/O performance estimate. Notably, even though the HPC application is based on MPI, MPI-IO is not observed. For item 3, the X-axis represents the libraries used, and the Y-axis represents the percentage of time spent on reading, writing, metadata I/O, and computation. Most time is spent on computation, and I/O can be seen at the bottom of each chart. The X-axis of item 4 represents specific I/O operations, and the Y-axis shows the number of operations. Notably, POSIX (in red) dominates the I/O workload. We aim to obtain the optimization benefits and I/O performance metrics of the ATMOS and OCEAN models through Darshan logs.\nWe reviewed the values from the Darshan results, which can be used as performance metrics. The fourth graph indicates no MPI I/O operations during the model execution but shows over 180,000 read operations in POSIX, while the third graph reveals that I/O operations account for approximately 6% of the runtime. This study employed \u201cI/O performance estimate\u201d metrics such as POSIX bandwidth and STDIO bandwidth as I/O performance optimization indicators and used runtime as a metric for overall performance optimization, not just for I/O."
        },
        {
            "heading": "IV. PROPOSED OPTIMIZATION METHOD",
            "text": "To optimize I/O in HPC scientific applications, two approaches can generally be used.\nThe first involves direct modification of the program's implementation method, while the second focuses on identifying performance-boosting parameters by changing the hardware platform parameters and software internal parameters of the HPC scientific application. Both methods have limitations. The first method of directly modifying the implementation of HPC scientific applications may not be\nFIGURE 6. Darshan-core process.\nFIGURE 7. Darshan PDF log.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nfeasible for many users who are not developers. The second method involves finding optimal performance parameters by changing the hardware platform and internal software parameters of HPC scientific applications, which may not always be possible due to hardware and software constraints. This may be impractical if the number of parameters is large or if it takes a long time to complete multiple runs of the program to find the optimal parameters.\nIn this paper, we propose a new cross-inference optimization method that considers both the hardware platform and internal parameters of the application program using machine learning and benchmark tools to improve the performance of Low GloSea6. Further details on this approach will be discussed in the following section."
        },
        {
            "heading": "A. HARDWARE/SOFTWARE PARAMETER OPTIMIZATION",
            "text": "The proposed method comprises four steps (Fig. 8). First, we used Darshan to collect performance data of Low GloSea6 and the benchmark tool based on the internal parameters and hardware platform parameter settings. Second, we used machine-learning techniques to find the benchmark parameter set B with the closest relationship between the parameters of Low GloSea6 and the benchmark tools. Third, we used a machine-learning model trained on the relationship between the benchmark parameter set B/hardware platform parameter settings and performance to determine the optimal settings of the benchmark parameter set B using the hardware platform parameters of the production or research environment. Fourth, we used machine-learning techniques to convert the optimal settings of benchmark parameter set B into the optimal internal parameters of Low GloSea6.\nHowever, this study employed a simple method for performance optimization in the 2nd and 3rd steps without using a benchmark tool. Further exploration of utilizing all\nsteps is reserved for future research. Benchmark tools are typically used to extract hardware information for a specific platform quickly, particularly for HPC applications such as GloSea6, which require many computing resources and have long execution times. However, because performance prediction accuracy can decrease, this study proposes a 3-step approach.\nThis study utilized performance data that include the internal parameters of Low GloSea6 and hardware platform parameters, as well as I/O performance estimates and runtime as performance metrics for both parameter sets. Table II summarizes the internal parameters of Low GloSea6.\nFIGURE 8. Schematic for future research: Optimizing parameters using benchmarking tools.\nFIGURE 9. Schematic methods for optimizing software parameters.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nThe \u201cATMOS_NPROCX\u201d and \u201cTMOS_NPROCY\u201d represent the number of CPU cores allocated to the X and Y axes of the ATMOS model, respectively, while \u201cNEMO_NPROCX\u201d and \u201cNEMO_NPROCY\u201d represent the number of CPU cores allocated to the X and Y axes of the OCEAN model. Low GloSea6 assigns CPU cores to each grid point of the Earth, divided into \u201cX x Y\u201d grid units, as global numerical models like Low GloSea6 are designed to perform calculations for predictions at each grid point (Fig. 10). \u201cXIOS_NPROC\u201d represents the number of CPU cores assigned to the XML IO SERVER (XIOS) created to manage the NetCDF output of the OCEAN model. If \u201cXIOS_NPROC\u201d is set to 0, XIOS operates within the OCEAN model without additional CPU core allocation. The CPU cores used in Low GloSea6 must be less than or equal to the CPU cores on the hardware platform, and this can be calculated as in Equation (1). \ud835\udc36\ud835\udc43\ud835\udc48 \ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 = \ud835\udc34\ud835\udc47\ud835\udc40\ud835\udc42\ud835\udc46_\ud835\udc41\ud835\udc43\ud835\udc45\ud835\udc42\ud835\udc36\ud835\udc4b \u2217 \ud835\udc34\ud835\udc47\ud835\udc40\ud835\udc42\ud835\udc46_\ud835\udc41\ud835\udc43\ud835\udc45\ud835\udc42\ud835\udc36\ud835\udc4c + \ud835\udc41\ud835\udc38\ud835\udc40\ud835\udc42_\ud835\udc41\ud835\udc43\ud835\udc45\ud835\udc42\ud835\udc36\ud835\udc4b \u2217 \ud835\udc41\ud835\udc38\ud835\udc40\ud835\udc42_\ud835\udc41\ud835\udc43\ud835\udc45\ud835\udc42\ud835\udc36\ud835\udc4c + \ud835\udc4b\ud835\udc3c\ud835\udc42\ud835\udc46_\ud835\udc41\ud835\udc43\ud835\udc45\ud835\udc42\ud835\udc36 (1)\n\u201cGSFC_PP_REINIT_DAYS\u201d and \u201cGSFC_RESUB_DAYS\u201d are dump files for restart, which means the number of days for the production cycle of weather forecasting data, and these two parameters should be set to the same number of days.\nOwing to diverse hardware platform parameters, considering all of them is challenging. Therefore, we selected parameters that are closely related to computing and I/O performance. This study focused on the hardware platform parameters of node number, file system block size, switch network speed, and disk I/O speed, which have been considered in several studies [13]-[14], aimed at improving\nsystem software to enhance I/O performance in HPC environments. These parameters were named \u201cNode\u201d and \u201cBlock size,\u201d \u201cSwitch data transfer speed,\u201d and \u201cDisk IO speed.\u201d\nTable III summarizes the descriptions and limitations for all parameters and I/O performance metrics. First, we describe the internal parameters of Low GloSea6. The global data used in Low GloSea6 are divided into even grids (Fig. 10), and to efficiently use CPU cores without leaving any idle, the number of CPU cores on the X and Y axes must be divided into even numbers. As the initial field has a larger X-axis than the Yaxis, more CPU cores should be used for X-axis calculations of the ATMOS and OCEAN models. If no spare CPU core exists on the hardware platform, XIOS operates inside the OCEAN model by allocating 0. Conversely, if a surplus exists, it allocates to the ATMOS and OCEAN models and assigns the remaining CPU cores to XIOS. Given that Low GloSea6 currently does not support model restart, \u201cGSFC_PP_REINIT_DAYS\u201d and \u201cGSFC_RESUB_DAYS\u201d produce prediction data once according to the set cycle and then terminate. Therefore, the two parameters in Low GloSea6 are utilized to set the desired weather forecast days, and in this study, we will refer to these two parameters collectively as \u201cDays.\u201d\nThe hardware platform parameter \u201cNode\u201d refers to the total number of nodes in the hardware platform. \u201cBlock size\u201d is the \u201cwsize/rsize\u201d value set through the network file system (NFS), and \u201cSwitch data transfer speed\u201d refers to the network switch speed. \u201cDisk IO speed_write\u201d and \u201cDisk IO speed_read\u201d are the write and read speeds of the hardware platform memory, respectively.\nTABLE \u2161 LOW GLOSEA6 PARAMETER\nNames Descriptions\nATMOS_NPROCX Number of cores assigned to ATMOS X-axis direction ATMOS_NPROCY Number of cores assigned to ATMOS Y-axis direction NEMO_NPROCX Number of cores assigned to OCEAN X-axis direction NEMO_NPROCY Number of cores assigned to OCEAN Y-axis direction XIOS_NPROC Number of cores assigned to XIOS cycle GSFC_RESUB_DAYS Dump file production cycle\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nThis study used several I/O performance metrics, including POSIX Bandwidth (MiB/s) and STDIO Bandwidth (MiB/s) measured with Darshan, as well as runtime (sec). The performance data comprised three datasets, each containing 10 parameters, based on three I/O performance metrics. Each dataset contained 549 data points.\nThe software/hardware parameters in Table III are adjusted to collect performance data on the testbed, which is used to train a machine-learning model. Subsequently, the trained model can predict software/hardware parameter configurations outside the collected performance data."
        },
        {
            "heading": "B. MACHINE LEARNING MODEL",
            "text": "In this section, we describe the machine-learning techniques and models to be used for optimization. We aim to predict the I/O performance metrics of Low GloSea6 operating in a production or research environment using the collected performance data for I/O optimization. This study utilized the R package [15] to build multiple linear regression (MLR) models, as well as decision tree-based random forest and gradient boosting models.\nMLR is a method for predicting the dependent variable through independent variables, assuming a linear relationship between them. Random forest and gradient boosting are\nensemble models based on decision trees. The ensemble is a technique used to compensate for the instability of decision trees by combining weak models to create a strong model (Fig. 11).\nBagging is a model that uses bootstrap samples of the data (Fig. 12) to create weak models, combines them using the average of the predicted values, and performs the final prediction. Random forest is similar to bagging in that it uses bootstrap samples but randomly selects split variables during the formation of weak models.\nThe gradient boosting model combines weak models into strong models using weights and adds a sequential characteristic to the traditional bagging method. As shown in Fig. 13, the first model makes a prediction, and based on that\nTABLE \u2162 LOW GLOSEA6 PERFORMANCE DATA\nTypes Names Cautions\nLow GloSea6 parameter\nDays GSFC_PP_REINIT_DAYS Low GloSea6 does not support restarting, so it allocates the desired forecast date. GSFC_RESUB_DAYS ATMOS_NPROCX, NEMO_NPROCX Depending on the characteristics of the model, set to even, and must be greater than Y-axis. ATMOS_NPROCY, NEMO_NPROCY Depending on the characteristics of the model, it is set to an even number and must be less than X-axis. XIOS_NPROC Assign according to the CPU core margin of the server. When set to 0, it operates inside the OCEAN model.\nHardware platform parameter\nNode The total number of nodes in the hardware platform. Block size In bytes, with the same value set for wsize and rsize configured via NFS. Switch data transfer speed The network switch speed is in bps (bits per second). Disk IO speed Disk IO speed_write The read/write speed of the hardware platform memory in MB/s (megabytes per second). Disk IO speed_read\nPerformance Indicator\nRuntime The Runtime of the ATMOS and OCEAN models was measured by Darshan, in seconds. I/O performance estimate POSIX bandwidth The bandwidth of POSIX and STDIO was measured by Darshan, in MiB/s. STDIO bandwidth\nFIGURE 11. Ensemble.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nprediction, weights are assigned to the data, which then influence the next model.\nThe hyperparameter settings for each model used in this study are as follows: The MLR model lacks hyperparameters, as it is a characteristic of linear regression estimation. The random forest model has a hyperparameter called \u201cmtry,\u201d which determines the number of features used for each tree. Following R. Genuer [16], setting the \u201cmtry\u201d hyperparameter to the value of \u201cthe number of independent variables divided by 3\u201d is expected to result in\nsuperior performance regarding RMSE for lowdimensional regression prediction. Therefore, we set the \u201cmtry\u201d value to 3. This value was obtained by dividing the number of the independent variables we used, which is 10, by 3 and rounding the first decimal place. The \u201cinteraction.depth\u201d of the gradient boosting model is a hyperparameter that controls the depth of each tree. According to T. Hastie [17], values of \u201cinteraction.depth\u201d exceeding 3 are not recommended due to the risk of overfitting. However, if complex relationship modeling is needed, 6 is expected to yield better results. Hence, we tested the range of 1, 2, 3, and 6 for \u201cinteraction.depth.\u201d Default values [18]-[19] were used for the random forest and gradient boosting models for hyperparameters that were not mentioned."
        },
        {
            "heading": "V. EXPERIMENTAL EVALUATION",
            "text": "Setting up a client local PC for the ROSE/CYLC master role and computer cluster system for the ROSE/CYLC slave role is necessary for the community version of Low GloSea6, which is not for supercomputers. We designated Clusters 1, 2, and 3 for the experimental computer cluster. Clusters 1 and 2 were clusters installed at Hongik University, while Cluster 3 was installed at Changwon National University. Table IV lists the detailed hardware specifications of Hongik University. Fig. 14 shows the configured experimental environment, and Cluster 3 will be introduced in detail in the next section. We established SVN within Clusters 1 and 2 to minimize the time required in the compilation phase.\nThe experimental plan involved collecting performance data by varying the hardware platform parameters of Clusters 1 and 2 and the internal parameters of Low GloSea6. Subsequently, the collected performance data and machinelearning techniques were utilized to predict the optimal internal parameter values of Low GloSea6 for the hardware platform parameters of Cluster 3. Finally, the predicted\nFIGURE 12. Bagging\nFIGURE 13. Bagging vs Gradient Boosting.\nTABLE \u2163 COMPUTER CLUSTER AND CLIENT LOCAL PC SPEC\nCluster1 Cluster2\n(NFS Client/Server) Client Local PC NFS Client NFS Server\nOS CentOS Linux release 7.9.2009\nCentOS Linux release 7.9.2009\nCentOS Linux release 7.9.2009\nWindows 10 pro 64bit (10.0, build 19044)\nVirtual OS - - - Ubuntu 21.04 CPU AMD EPYC 7302 16-\nCore Processor (16 Core 32 Thread) * 2\nIntel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz * 2\nAMD Threadripper PRO 3955WX (16cores, 3.9GHz), Liquid-cooled * 1\nIntel\u00ae Core\u2122 i910900X CPU @ 3.70\nGHz\nStorage 4 TB Crucial MX500 SSD\n4 TB HGST Deskstar HDD\n4 TB Samsung 870 SSD\n256GB SK Hynix NVMe SSD\nRAM 132 GB 256 GB 256 GB 32 GB MPICH 3.1.4 3.1.4 4.0.3 3.4.1\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\ninternal parameter values were applied to Low GloSea6 in Cluster 3 to complete the optimization and analyze the results.\nWith this rough outline of the overall experimental plan, we\nwill now describe the experiment's details."
        },
        {
            "heading": "A. EXPERIMENTAL ENVIRONMENT VALIDATION",
            "text": "First, we verified the reliability of the experiment by measuring the overhead of the profiling tool (Darshan) to ensure that it did not significantly affect the experiment. We ran five Low GloSea6 instances with the same parameters before and after applying Darshan and measured the runtime of the \u201cgsfc_model_m1_s01\u201d step, where the ATMOS and OCEAN models are executed. Figure 15 shows the cumulative bar graph for the five measurements, and Table V presents the individual runtimes and their averages. While a significant difference in the cumulative bar graph was unobserved, an overhead of approximately four seconds was observed in the runtime average. Considering that the average runtime was approximately 870 seconds, we confirmed that Darshan's overhead was negligible."
        },
        {
            "heading": "B. OPTIMIZING GLOSEA6/HARDWARE PLATFORM",
            "text": "PARAMETERS\nFIGURE 14. Overall composition of the Low GloSea6 testbed.\nTABLE \u2164 5-ROUND LOW GLOSEA6 RUNTIME MEASUREMENTS\nAND AVERAGE VALUES\nRounds Runtime (sec) NO_Darshan Darshan Round1 871 859 Round2 843 868 Round3 873 878 Round4 876 878 Round5 873 882 Average 867.2 871\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nThe proposed research environment hardware/Low GloSea6 optimization process in this study comprises three steps, which are explained below."
        },
        {
            "heading": "1) STEP1: DATA COLLECTION",
            "text": "Run the model by changing the hardware platform parameters and Low GloSea6 internal parameters on Clusters 1 and 2 and collect performance data using Darshan.\nTable VI summarizes all the parameter settings. As the runtime and I/O amount are linearly proportional to the prediction criterion \u201cDays,\u201d we fixed the prediction criterion to 1 day for quick data collection. With 32 cores in the experimental testbed, the X-axis CPU core for ATMOS and OCEAN models can be 2, 4, or 6, while the Y-axis can be 2 or 4, so we varied the number of cores within these ranges for performance data collection. XIOS_NPROC was set from 0, 1, 2, 3, and 4, considering CPU core resource usage during model execution.\nThe hardware platform parameter \u201cNode\u201d was configured with a maximum of 2, and the \u201cBlock size\u201d was configured with values of 32768 and 65536 bytes, which are typical settings for NFS, as well as the default value of 524288 bytes in our experimental environment. The \u201cSwitch data transfer\nspeed\u201d has settings of 100 Mbps, 1 Gbps, and 10 Gbps due to the configuration limit of the Cisco Nexus 3000 series switch used in our experiment. The \u201cDisk IO speed\u201d was configured using Linux control groups (Cgroups) based on TEKIE's September 2022 survey [20]. The parameter values are the average read/write speed of Data Description (dd) commands measured 100 times on each of the Clusters 1 and 2 hardware platforms, as well as the average read/write speed of TEKIE's SSD and HDD. The write speed of the SSD was set to the speed in the experimental environment because it exceeded the average speed in our research environment."
        },
        {
            "heading": "2) STEP2: VALIDATION AND MODEL LEARNING",
            "text": "The collected performance data were then subjected to validation, followed by model training and validation.\nA primary concern during data validation is multicollinearity, which is a common problem that arises due to a high correlation between independent variables (parameters), leading to distorted analysis results. Referring to Fig. 16, summarizing previous research by Rea, L. M [21], a correlation coefficient of 0.6 or higher indicates a correlation between each parameter. Therefore, we selected four parameters suspected of multicollinearity from the performance data. However, a correlation does not necessarily\nFIGURE 16. Describing Correlation Coefficients.\nTABLE \u2165 LOW GLOSEA6 PERFORMANCE DATA\nTypes Names Set values\nLow GloSea6 parameter\nDays 1 ATMOS_NPROCX, NEMO_NPROCX 2, 4, 6 ATMOS_NPROCY, NEMO_NPROCY 2, 4 XIOS_NPROC 0, 1, 2, 3, 4\nHardware platform parameter\nNode 1, 2 Block size 32768 byte, 65536 byte, 524288 byte Switch data transfer speed 100 Mbps, 1 Gbps, 10 Gbps Disk IO speed_write/read Cluster 1 Write: 13.2 MB/s Read: 699 MB/s\nCluster 2 Write: 444.5 MB/s Read: 541 MB/s SSD Write: 444.5 MB/s Read: 200 MB/s HDD Write: 160 MB/s Read: 80 MB/s\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nimply multicollinearity, as it simply means that each parameter tends to move together.\nTherefore, we calculated the variance inflation factor (VIF) among four parameters. VIF measures the extent to which the variance or standard error of the estimated regression coefficient is distorted by multicollinearity and is calculated using Equation (2). R2 represents the coefficient of determination and can be calculated as the reciprocal of tolerance.\n\ud835\udc49\ud835\udc3c\ud835\udc39! = 1\n1 \u2212 \ud835\udc45!\" = 1 \ud835\udc47\ud835\udc5c\ud835\udc59\ud835\udc52\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc50\ud835\udc52 (2)\nIf the VIF exceeds 10, it is considered multicollinearity [22]. For ease of analysis, we summarized the VIF values of the parameters suspected of multicollinearity in Table VII. As all parameter VIF values are less than 10, we confirmed that the performance data of Low GloSea6 did not exhibit multicollinearity.\nWe then used best subset selection, a technique that fits a regression model for each subset of the parameters and identifies the optimal subset, to identify significant parameters in the performance data. Figures 17\u201319 show the results for each performance data. The black portion of the graph indicates that the corresponding variable on the X-axis was included in the regression model, and the Y-axis represents the model's goodness of fit based on the included variables. The higher the position on the Y-axis, the better the goodness of fit, and the goodness of fit evaluation metric, \u201cadjr2,\u201d is calculated using Equation (3).\n\ud835\udc4e\ud835\udc51\ud835\udc57\ud835\udc5f2 = 1 \u2212 \ud835\udc5b \u2212 1 \ud835\udc5b \u2212 \ud835\udc5d \u2217 (1 \u2212 \ud835\udc45\") (3)\nwhere n represents the sample size, p denotes the number of parameters, and R2 is the coefficient of determination.\nFigures 17\u201319 show the best subset selection results when the dependent variables are runtime, POSIX bandwidth, and STDIO bandwidth, respectively. When runtime was the dependent variable, using all parameters produced the best-fit model, while excluding three parameters (Node, Blocksize, and atmosX [ATMOS_NPROCX]) yielded the best-fit model when POSIX bandwidth was the dependent variable.\nExcluding three parameters (Disk IO speed_write/read, Blocksize) resulted in the best-fit model when STDIO bandwidth was the dependent variable. Based on these results, we trained the model using the most suitable parameter combinations. With this, we completed the validation and adjustment of the data and proceeded with the validation and adjustment of the model.\nFIGURE 17. Best Subset Selection result of Runtime data.\nFIGURE 18. Best Subset Selection result of POSIX bandwidth data.\nFIGURE 19. Best Subset Selection result of STDIO bandwidth data.\nTABLE \u2166 VIF FOR EACH PARAMETER\nParameters VIF\nNode 2.3 Disk IO speed_write 2.3 Disk IO speed_read 2.9 Blocksize 2.1\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nAs the number of performance data used for Low GloSea6 in this study is insufficient for model training, validating the model's effectiveness is imperative. To address this issue, we used leave-one-out cross-validation (LOOCV). LOOCV is a method that sets one of the n data as the test data and the other n\u22121 data as the training data, repeating the process n times and estimating the error by averaging the mean square error (MSE) of each model. In this study, we used RMSE instead of MSE for ease of analysis, and the LOOCV results of each model are shown in Fig. 20. In particular, the gradient boosting and random forest models used hyperparameter settings, with the smallest RMSE measured in Table VIII.\nWe calculated the variability by dividing the RMSE of each model by the mean value of the dependent variable, multiplying it by 100, and using this as an evaluation metric. The average performance data value with runtime as the dependent variable was 2289 sec. When comparing the RMSE of the average value with those of the MLR, random forest, and gradient boosting models, they showed fluctuations of 22%, 10%, and 7%, respectively.\nThe average value of the performance data with the dependent variable of the POSIX bandwidth was 1631 MiB/s. When compared to the average value, the RMSE values of the MLR, random forest, and gradient boosting models showed high variability of 141%, 129%, and 97%, respectively.\nThe average value of the performance data with the dependent variable of the STDIO bandwidth was 3060 MiB/s. When compared to the average value, the RMSE values of the MLR, random forest, and gradient boosting models showed variability of 46%, 35%, and 23%, respectively.\nTABLE \u2167 MEASURING RMSE OF MACHINE LEARNING MODELS ACCORDING TO HYPERPARAMETER SETTINGS\nDependent variables Runtime POSIX bandwidth STDIO bandwidth\nModels Hyperparameters RMSE (sec) Hyperparameters RMSE (MiB/s) Hyperparameters RMSE\n(MiB/s) tree interaction.depth tree interaction.depth tree interaction.depth Random Forest 100 228 100 2116 100 1081\n500 227 500 2107 500 1095 1000 225 1000 2101 1000 1085 5000 227 5000 2110 5000 1087\nGradient Boosting 100 1 466 100 1 2313 100 1 1372 2 188 2 2030 2 1232 3 176 3 1998 3 1094 6 157 6 1999 6 1328\n500 1 414 500 1 2302 500 1 1329 2 175 2 2031 2 1161 3 159 3 2011 3 960 6 149 6 1978 6 985\n1000 1 411 1000 1 2295 1000 1 719 2 173 2 2035 2 1161 3 156 3 2004 3 919 6 148 6 1978 6 876\n5000 1 411 5000 1 1586 5000 1 1328 2 165 2 2026 2 985 3 153 3 1978 3 876 6 149 6 1974 6 764\nThe best RMSE values for each model were bolded.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nFinally, we excluded the MLR model with the highest RMSE across all dependent variables in LOOCV and proceeded to the next step using the random forest and gradient boosting models with simple parameter tuning."
        },
        {
            "heading": "3) STEP3: PARAMETER PREDICTION AND OPTIMIZATION",
            "text": "In the final step, we optimized Low GloSea6, which operates in new industrial and research environments. Specifically, we optimized Low GloSea6 operating on Cluster 3 at Changwon National University. The university's research environment comprised three nodes with 16 cores and an InfiniBand speed of 100 Gbps, as shown in Fig. 21. To optimize the system, we set the hardware platform parameters to the values in Table IX and input them into the machine-learning model.\nThe optimization system implemented in this study considers a 1-day prediction and takes into account the hardware platform parameters, CPU cores, and XIOS_NPROC values to limit the predicted values. Regarding the number of CPU cores, predictions are made for up to 48 cores based on the Cluster 3 hardware platform. Considering the grid size of the ATMOS and OCEAN models, the X-axis CPU core of the model can be 2, 4, 6, or 8, and the Y-axis can\nbe 2, 4, or 6. Thus, parameter combination prediction is performed within this range. XIOS_NPROC is a parameter whose support is determined depending on the Low GloSea6 construction option. Therefore, we also set the XIOS_NPROC parameter value as input. In the case of Changwon University, the XIOS_NPROC prediction value in this study only covers 0 because the university does not support this parameter.\nUsing the input Cluster 3 hardware platform parameters, we predicted the optimal internal parameters of Low GloSea6 based on the dependent variables of runtime, POSIX bandwidth, and STDIO bandwidth. First, the prediction results when the dependent variable is runtime are shown in Fig. 22 and Table X. The graph's Y-axis represents the runtime of Low GloSea6 in seconds, and the X-axis represents the internal parameter settings of Low GloSea6. For example, \u201c12_34\u201d means \u201cATMOS_NPROCX = 1, ATMOS_NPROCY = 2, NEMO_NPROCX = 3, NEMO_NPROCY = 4.\u201d The blue line represents the actual runtime of Changwon National University, while the gray and orange lines represent the predicted runtime using random forest and gradient boosting, respectively, sorted from slowest to fastest on the left side of the graph. In particular, the parameter combination with the fastest/slowest predicted runtime by the random forest model is \u201c64_42'/'22_22,\u201d which is highlighted in bold in Table X, and \u201c64_62'/'22_46\u201d are the parameter combinations with the fastest/slowest predicted runtime by the gradient boosting model. The other parameter combinations were randomly selected from the predicted values.\nThe results were analyzed from two perspectives: error rate, prediction application results, and research environment. We calculated the percentage error between the predicted model runtime using Equation (4) and the actual model runtime to analyze the error rate.\n\ud835\udc43\ud835\udc52\ud835\udc5f\ud835\udc50\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc4e\ud835\udc54\ud835\udc52 \ud835\udc52\ud835\udc5f\ud835\udc5f\ud835\udc5c\ud835\udc5f = |\ud835\udc45\ud835\udc52\ud835\udc4e\ud835\udc59 \u2212 \ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc51\ud835\udc56\ud835\udc50\ud835\udc61|\n\ud835\udc45\ud835\udc52\ud835\udc4e\ud835\udc59 \u2217 100 (4)\nFIGURE 21. Overall composition of Changwon National University Low GloSea6 testbed.\nTABLE \u2168 CHANGWON NATIONAL UNIVERSITY PARAMETER\nParameters Values\nNode 3 Block size 32768 byte Switch data transfer speed 100 Gbps Disk IO speed_write 194 MB/s\nDisk IO speed_read 179 MB/s\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nFigure 22 shows a similar trend between the actual and predicted values. On average, the random forest model's predictions outperformed the other models. However, as the number of CPU cores used increased, the error rate of the gradient boosting model decreased significantly, and for the optimal parameter combinations predicted by each model, the random forest model showed an error rate of 76%, while the gradient boosting model showed an error rate of 16%. While the average error is important, this study primarily aims to obtain the optimal parameter combination; thus, we adopted\nthe gradient boosting model as a suitable model for parameter optimization.\nThe analysis of the application of predictions is as follows: with reference to Fig. 22 graph, we directly applied the parameter combinations with the slowest and fastest runtime predicted by the gradient boosting model, \u201c22_46\u201d and \u201c64_62,\u201d respectively, to the research environment at Changwon National University. We then compared the Darshan profile data, as shown in Fig. 23. The graph summarizes the total I/O operation count of the ATMOS and OCEAN models for each parameter combination. The Y-axis\nFIGURE 22. Runtime's predicted value versus actual value.\nTABLE \u2169 REAL/PREDICTION RUNTIME VALUE ACCORDING TO PARAMETER COMBINATION\nSources Indicators Combination of parameters (\u2018ATMOS_NPROCXY\u2019_\u2019NEMO_NPROCXY\u2019)\n22_64 22_46 22_44 22_22 22_24 24_42 24_24 42_24 64_42 64_82 64_62\nChangwon (Real)\nRuntime (sec)\n3087 3053 3013 3016 2903 1721 1697 1658 678 675 671\nGradient Boosting (Predict)\n1575 1627 1627 1455 1532 946 929 923 799 790 782\nRandom Forest\n(Predict) 2037 1970 1969 2131 2081 1425 1425 1397 1066 1183 1183\nThe worst/best values for each model were bolded.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nrepresents the number of I/O operations, while the X-axis represents the type of I/O operation. A little difference was confirmed in STDIO, but the number of reads, writes, and seek operations in POSIX decreased significantly, indicating that parameter optimization can improve the model's performance and reduce the system I/O load. Additionally, we compared the prediction results of two models using different parameter combinations. Using the same input data, we conducted a 1- day forecast and compared the final prediction outputs. The size of the final prediction output files was identical for both models. To verify the integrity of the data, we utilized NASA's netCDF viewer, Panoply5. The left side of Fig. 24 shows the prediction results and partial data for the \"22_46\" parameter combination, while the right side shows the prediction results and partial data for the \"64_62\" parameter combination. Upon visual inspection, no discernible difference was observed, and the output data were identical, validating that our optimization method does not compromise prediction accuracy.\nThe analysis from the research environment perspective is as follows: the performance of the Changwon National University research environment is generally better than Cluster 1 and lower than Cluster 2. Therefore, Low GloSea6 can be effectively optimized for other research environments with hardware platform parameter values that have not been\ncollected through the collection and learning of performance data collected from both extreme ends.\nFigure 25 and Table XI present the prediction results for the dependent variable of the POSIX bandwidth. The Y-axis in Fig. 25 represents I/O bandwidth (MiB/s), while the X-axis represents the internal parameter settings of Low GloSea6. The values in Table XI overlap considerably as the ATMOS_NPROCX parameter was excluded through best subset selection for models using POSIX bandwidth as the dependent variable. For example, the \u201c24_42\u201d and \u201c64_42\u201d parameter combinations are treated identically in predicting POSIX bandwidth. Due to the significant margin of error and different trends observed in the predicted values for POSIX bandwidth compared to the actual values, extracting information from the graph alone was challenging. Therefore, we present a heatmap in Fig. 26 to identify the correlation between Low GloSea6 internal parameters and POSIX bandwidth. The predicted value heatmap shows that the correlation coefficient between NEMO_NPROCX and POSIX bandwidth is above 0.8, indicating a strong correlation. Therefore, to improve POSIX bandwidth, we could predict that the NEMO_NPROCX parameter must be increased, which was validated by confirming the strong correlation between NEMO_NPROCX and POSIX bandwidth in the actual value heatmap. In summary, unlike the runtime\nFIGURE 24. Analysis of predictive results of parameter combination models\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nprediction results, predicting the optimal parameter combination for the POSIX bandwidth may be challenging. However, the results can provide useful reference data for determining which parameters to prioritize during optimization.\nFurthermore, we present the prediction results for the dependent variable of STDIO bandwidth in Fig. 27 and Table XII. The Y-axis represents the I/O bandwidth (MiB/s), and the X-axis represents the internal parameter settings of Low GloSea6. Unlike the POSIX bandwidth, the STDIO bandwidth uses all internal parameters of Low GloSea6. However, no discernible trend was observed in the graph and heatmap presented in Fig. 27 and Fig. 28, respectively, indicating that optimization through STDIO bandwidth was impossible.\nIn summary, using \u201cI/O performance estimate\u201d metrics, such as POSIX bandwidth and STDIO bandwidth, as performance indicators for I/O performance optimization may help determine the importance of parameters in the initial optimization or as validation metrics after optimization. However, because the I/O bandwidth is an estimated value, it is inappropriate for performance optimization and prediction. Conversely, using runtime as a performance metric for overall performance optimization led to improved performance not only in runtime but also in the I/O aspect. The prediction error rate for runtime based on the optimal parameter combination was 16%, which is a significant result."
        },
        {
            "heading": "VI. CONCLUSIONS AND FUTURE WORK",
            "text": "A machine learning-based approach for optimizing hardware/software parameters of scientific applications was demonstrated in this study. The weather forecast scientific application Low GloSea6 was used as a target, and a dataset containing the application's internal parameters and hardware platform parameters and performance data based on the combination of these two parameters was constructed. Before applying the machine-learning model, the dataset was verified, and the validity of the regression model trained with insufficient data was ensured through the LOOCV technique. The optimal hardware platform parameters and corresponding Low GloSea6 internal parameters were found using the trained machine-learning model in a new research environment and these values agreed with the actual parameter combinations. In particular, the predicted execution time based on the parameter combination showed a 16% error rate compared to the actual execution time, demonstrating a meaningful result in predicting execution time. The proposed optimization method can be applied to improve the performance of other HPC scientific applications. Besides weather and climate modeling, to name a few, there are computational fluid dynamics (CFD) simulations, molecular dynamics (MD) simulations, and quantum chemistry calculations. Frequently, scientists who run such HPC scientific applications used to get help from staff members at supercomputing centers to\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\noptimize their applications, and our optimization method will help this manual performance optimization process expedited.\nTwo directions for future research are outlined in terms of data. First, increasing the absolute amount of data is necessary. In this study, the accurate prediction of execution time was hindered owing to the omission of some hardware platform parameters. Therefore, collecting additional hardware/software parameters and I/O performance indicators would improve model performance. Second, implementing the benchmark-based cross-inference optimization method proposed in this study's initial algorithm would be beneficial. This would accelerate data collection and enable the collection of parameter values not collected in this study through alternative parameters, thereby expanding the model performance improvement and application range."
        },
        {
            "heading": "ACKNOWLEDGMENT",
            "text": "This research was supported by the Korea Meteorological Administration through the project \u201cDevelopment of Application Technology for Climate and Climate Change Monitoring and Prediction Information (KMI-2021-01310).\u201d"
        }
    ],
    "title": "Optimizing Numerical Weather Prediction Model Performance using Machine Learning Techniques",
    "year": 2023
}