{
    "abstractText": "In this paper, we design a new flexible smart softwaredefined radio access network (Soft-RAN) architecture with traffic awareness for sixth generation (6G) wireless networks. In particular, we consider a hierarchical resource allocation model for the proposed smart soft-RAN model where the software-defined network (SDN) controller is the first and foremost layer of the framework. This unit dynamically monitors the network to select a network operation type on the basis of distributed or centralized resource allocation procedures to intelligently perform decisionmaking. In this paper, our aim is to make the network more scalable and more flexible in terms of conflicting performance indicators such as achievable data rate, overhead, and complexity indicators. To this end, we introduce a new metric, i.e, throughputoverhead-complexity (TOC), for the proposed machine learningbased algorithm, which supports a trade-off between these performance indicators. In particular, the decision making based on TOC is solved via deep reinforcement learning (DRL) which determines an appropriate resource allocation policy. Furthermore, for the selected algorithm, we employ the soft actor-critic (SAC) method which is more accurate, scalable, and robust than other learning methods. Simulation results demonstrate that the proposed smart network achieves better performance in terms of TOC compared to fixed centralized or distributed resource management schemes that lack dynamism. Moreover, our proposed algorithm outperforms conventional learning methods employed in recent state-of-the-art network designs.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ali Nouruzi"
        },
        {
            "affiliations": [],
            "name": "Atefeh Rezaei"
        },
        {
            "affiliations": [],
            "name": "Ata Khalili"
        },
        {
            "affiliations": [],
            "name": "Nader Mokari"
        },
        {
            "affiliations": [],
            "name": "Mohammad Reza Javan"
        },
        {
            "affiliations": [],
            "name": "Eduard A. Jorswieck"
        },
        {
            "affiliations": [],
            "name": "Halim Yanikomeroglu"
        }
    ],
    "id": "SP:d8ae98f228b04b0ae381235093fbf8c47d7fbbf8",
    "references": [
        {
            "authors": [
                "W. Lee",
                "O. Jo",
                "M. Kim"
            ],
            "title": "Intelligent resource allocation in wireless communications systems",
            "venue": "IEEE Communications Magazine, vol. 58, no. 1, pp. 100\u2013105, Jan. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C. Sun",
                "X. Wu",
                "X. Li",
                "Q. Fan",
                "J. Wen",
                "V.C. Leung"
            ],
            "title": "Cooperative computation offloading for multi-access edge computing in 6G mobile networks via soft actor critic",
            "venue": "IEEE Transactions on Network Science and Engineering, pp. 1\u20131, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Pagin",
                "T. Zugno",
                "M. Polese",
                "M. Zorzi"
            ],
            "title": "Resource management for 5GNR integrated access and backhaul: A semi-centralized approach",
            "venue": "IEEE Transactions on Wireless Communications, vol. 21, no. 2, pp. 753\u2013 767, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "X. Zhang",
                "M. Peng",
                "S. Yan",
                "Y. Sun"
            ],
            "title": "Deep-reinforcement-learningbased mode selection and resource allocation for cellular V2X communications",
            "venue": "IEEE Internet of Things Journal, vol. 7, no. 7, pp. 6380\u20136391, Jul. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "W. Xia",
                "T.Q.S. Quek",
                "J. Zhang",
                "S. Jin",
                "H. Zhu"
            ],
            "title": "Programmable hierarchical C-RAN: From task scheduling to resource allocation",
            "venue": "IEEE Transactions on Wireless Communications, vol. 18, no. 3, pp. 2003\u20132016, Mar. 2019.",
            "year": 2003
        },
        {
            "authors": [
                "A. Rezaei",
                "P. Azmi",
                "N. Mokari",
                "M.R. Javan",
                "H. Yanikomeroglu"
            ],
            "title": "Robust resource allocation for cooperative MISO-NOMA-based heterogeneous networks",
            "venue": "IEEE Transactions on Communications, vol. 69, no. 6, pp. 3864\u20133878, Jun. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "B. Khorsandi",
                "F. Tonini",
                "C. Rafaelli"
            ],
            "title": "Centralized vs. distributed algorithms for resilient 5G access networks",
            "venue": "Photonic Network Communications, vol. 37, no. 3, pp. 376\u2013387, Jun. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M.J. Kalbasi",
                "S. Valaee"
            ],
            "title": "Centralized and distributed algorithms for energy and spectrum efficient user association in small cell networks",
            "venue": "IEEE Transactions on Green Communications and Networking, vol. 5, no. 4, pp. 1781\u20131790, Dec. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Khalili",
                "E.M. Monfared",
                "S. Zargari",
                "M.R. Javan",
                "N.M. Yamchi",
                "E.A. Jorswieck"
            ],
            "title": "Resource management for transmit power minimization in UAV-assisted RIS HetNets supported by dual connectivity",
            "venue": "IEEE Transactions on Wireless Communications, vol. 21, no. 3, pp. 1806\u20131822, Mar. 2022.",
            "year": 1806
        },
        {
            "authors": [
                "D.P. Kingma",
                "J.L. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "Proc. Int. Conf. Learn. Represent, pp. 1\u201341, 2015.",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "I. INTRODUCTION The evolution from fifth-generation (5G) to sixth-generation (6G) wireless networks is proceeding along two main lines, which consist of developing network architecture and communications technologies. As 5G and beyond networks continue to evolve, it will be possible for network architectures and communication technologies to be dynamically adapted according to the changing demands of the network. In such a flexible architecture, a huge amount of signaling and computational resources are needed to manage the network resources efficiently.\nDue to discrepancies between the mathematical tractability and the exponentially greater complexity of wireless networking, conventional resource allocation approaches are unfortunately ineffective and may not be able to fulfill the precise quality of service (QoS) requirements of emerging applications. Furthermore, 6G networks require to provide performance based on the different conditions, such as traffic changes or the\nThe work of Eduard Jorswieck was supported in part by the Federal Ministry of Education and Research (BMBF, Germany) in the program of \"Souver\u00e4n. Digital. Vernetzt.\" joint project 6G-RIC, project identification number: 16KISK020K and 16KISK031.\nvariety of services requested by users. To tackle these issues, artificial intelligence (AI) has been identified as a promising solution for automatic and autonomous network management. Adopting intelligent resource allocation for wireless networks not only has the potential to replace the manual intermediation needed for current network management tasks, but also presents novel optimization possibilities to ameliorate performance gains online in real-time. Since future dense wireless networks will involve high complexity algorithms, machine learning (ML) has emerged as a key enabler to manage high complexity for real-time implementation. In this regard, reinforcement learning (RL) as a type of ML has been employed to learn from an environment by trial and error, which promotes improvements over time. Also, deep reinforcement learning (DRL) has been investigated for comprehensive inputs as well as more accurate results compared to RL algorithms [1]. Furthermore, to enable a real-time scheduler for stochastic environments, it has been shown that learning via multiple agents can solve complicated stochastic optimization problems [2]. Besides, the soft actorcritic (SAC) algorithm with a maximum entropy objective can be leveraged to provide more accurate and stable solutions for scalable networks in dynamic environments compare to the baselines.\nML algorithms have already been exploited for resource multiple allocation in a wireless communication system to obtain an efficient solution from instantaneous actual channel data. Also, thanks to the capability of ML solutions in adaptation to the environment, they lead to a higher performance in practice. In this regards, there are a plethora of works that considered resource allocation based on ML algorithms [2]-[6]. In [2], a multi-access edge computing technique was considered that reduced the core network congestion. More specifically, cooperative computation offloading policy was designed for mobile edge computing (MEC) technology using the SAC method for both the centralized and distributed offloading. The authors in [3] proposed a matching-based distributed structure to improve the latency and proficiency of a network. In [4], a DRL algorithm for vehicular-to-everything (V2X) communication was proposed that determined resource block allocation and performed power control. The DRL algorithm has the ability to select the transmission mode (i.e., vehicle-to-infrastructure (V2I) or vehicle-to-vehicle (V2V) communications. The authors in [5] performed functional splits of control and data planes ar X\niv :2\n30 2.\n04 65\n5v 1\n[ ee\nss .S\nP] 9\nF eb\nbetween the cloud and edge nodes in C-RAN while taking the fronthaul delay into account. The authors in [6] considered a semi-centralized framework for the resource allocation problem by using matching theory and a successive convex approximation (SCA) approach. The authors in [7] compared both centralized and distributed algorithms regarding the base band unit (BBU) location placement problem in C-RAN, where their proposed solution is based on a distributed heuristic algorithm. Moreover, in [8], the authors compared the energy efficiency of their proposed distributed and centralized user association algorithms by sequentially minimizing the power consumption of the heterogeneous network.\nMotivated by the above discussion, in this paper we propose an intelligent approach for determining an effective resource allocation policy. We consider a network that can switch between centralized and distributed operations for on demand resource management. To the best of our knowledge, a smart network architecture configuration such as this has not been studied yet. Previous works have not considered the changing environmental conditions of networks, and thus they are not appropriate for changes in real scenarios. Besides, the complexity, overhead, and achievable data rate performance metrics are not considered jointly in the other existing works in the literature while it is important to consider them jointly in selecting the proper resource management. The main contributions of this paper are summarized as follows: \u2022 In contrast to the conventional approaches that employ a\nmodel for the resource allocation based on the analytical models, an intelligent approach based on the learning methods is exploited for solving the software-defined network (SDN) decision and resource allocation problems in a centralized or distributed manner. This approach allows a network to adapt to the environment and perform more effectively in real-world scenarios. In particular, we introduce a novel algorithm for the SDN controller that chooses the best resource allocation policy based on the DRL method. In this model, the centralized or distributed modes are selected on the basis of a throughput metric that considers overhead, complexity, and the total data rate. Hence, our proposed smart algorithm decides whether a BBU or each re-configurable radio systems (RRS) is responsible for the resource allocation policy. \u2022 In the centralized scheme, we consider the single-agent SAC algorithm at the centralized unit that designates the appropriate actions based on the collected information. Additionally, in the distributed scheme, we consider that there is no information exchange between agents, and that the BSs (as RRSs) locally perform resource allocation tasks based on a multi-agent actor-critic algorithm. This algorithm can be applied to more complex environments and provides stable solutions for the network compared to the other learning methods. \u2022 Numerical results indicate a performance gain by employing the SAC methods relative to other ML based (i.e., DDPG and DQN approaches). Furthermore, results demonstrate performance gaps between fixed centralized or fixed distributed schemes with the proposed smart algorithm.\nII. SYSTEM MODEL AND PROBLEM STATEMENT\nAs shown in Fig. 1, we consider that the RAN network consists of two major units which we refer to as the access\nnetwork outer (AN-O) and the access network inner (AN-I). The AN-O is the cloud RAN network, and the AN-I includes B RRSs as local units. The RRSs provide signaling and data coverage for the users. As a result of considering an intelligent network, it is necessary to obtain some efficient feedback about the network status to operate in a real-time. Furthermore, it is assumed that the information can be fed back from the BSs to the AN-O through the control links. Also, we assume that all RRSs and users are equipped with single antenna. The AN-O consists of a BBU pool which performs centralized baseband processing, and a centralized SDN controller, which controls the network operation by programming the network\u2019s element functionalities properly. In particular, we consider that the SDN controller saves a stream of data rates that was achieved from the previous time slots, and it stores the flows including the overheads and complexities in its buffer. By monitoring the network, the SDN controller determines whether the network would operate in a centralized or distributed manner."
        },
        {
            "heading": "A. Decision-Making Optimization Problem",
            "text": "We consider a comprehensive framework in which the SDN controller intelligently switches between centralized and distributed network operations by considering the total data rate and the amount of data exchanged in terms of overhead and complexity. We define two binary decision making parameters for the centralized and distributed scenarios as x(t)Cnt and x (t) Dst, respectively, where x(t) = {x(t)Cnt, x (t) Dst}. To make a trade-off between data rate, overhead, and complexity, we introduce a new metric term as TOC to perform mode selection. Consequently, the decision-making structure for the SDN controller is shown at the top of Fig. 1. In this framework, we consider that in each time slot t, only one operation scheme can be selected as follows:\nx (t) Dst + x (t) Cst = 1,\u2200t, x (t) Dst, x (t) Cst \u2208 {0, 1}. (1)\nIn the following, we introduce and model the three components of TOC:\n1) Overhead: As a critical key performance indicator, we address the overhead in the telecommunication networks. The overhead is a function of the number of information bits needed to feed back the channel status, subcarrier indicators, and the transmission power of a specific user over a subcarrier. Also, the total number of RRSs, users, and subcarriers in each RRS and in each time slot can affect the overhead. In the centralized mode, the resource allocation operation is performed at the BBU, and thus the information needs to be transmitted from the RRSs to the centralized unit and it is denoted by \u03c4 tCnt at time slot t. In the distributed mode, by contrast, all operations related to resource allocation are performed independently by the RRSs without any data exchange and it is denoted by \u03c4 b,tDst for each of RRSs. Accordingly, \u03c4 tCnt and \u03c4 b,t Dst are calculated as follows:\n\u03c4 b,tDst = (\u03b2Power + \u03b2CSI + \u03b2Subcarriers) \u00b7 |U t b | \u00b7 |Ktb|, (2) \u03c4 tCnt = \u2211 b\u2208B \u03c4 b,tDst, (3)\nwhere \u03b2Power, \u03b2Subcarriers, and \u03b2CSI represent the number of required bits to describe the power allocation variable matrix, subcarrier allocation variable matrix, and the channel state information (CSI) matrix. In addition, the size of the set of users that are associated with RRS b is denoted by |U tb |. Moreover,\n|Ktb| represents the size of the set of subcarrier for RRS b. Ultimately, the set of total users and subcarriers are denoted by U and K, respectively.\nIt is remarkable that for the decision making procedure in addition to the achieved data rates of the centralized scheme, the distributed data rates in a certain number of previous time slots are fed back and stored in the SDN controller\u2019s memory. Hence, the overhead of decision making procedure originates from exchanging the data rates of remote radio heads (RRH) and SDN controller which is tolerable. Also, to reduce the overhead of signaling in the distributed operation, we consider that the decisions of each specific RRS regarding its allocated powers, subcarriers and the estimated channels are not exchanged with the other distributed RRSs.\n2) Achievable Data Rate: Let binary variable \u03c1t,b,u,k \u2208 {0, 1} denote that subcarrier k in RRS b for user u at time slot t and its transmission power is considered as pt,b,u,k \u2265 0.\nConsequently, for the centralized resource allocation scheme, PtCnt = [ pt,b,u,kCnt ] and \u03c1tCnt = [ \u03c1t,b,u,kCnt ] and for the distributed\nscheme PtDst,b = [ pt,b,u,kDst ] and \u03c1tDst,b = [ \u03c1t,b,u,kDst ] . In addition, the channel gain between user u and RRS b on subcarrier k at time slot t is denoted by ht,b,u,k = ht,b,u,kLarge h t,b,u,k Small which includes small scale fading and large scale fading effects. Accordingly, the total achieved data rate by the centralized method is given by.\nrtCnt = \u2211 b\u2208B \u2211 k\u2208K \u2211 u\u2208U\n( 1 + ht,b,u,kpt,b,u,kCnt \u03c1 t,b,u,k Cnt\n\u03c32 + It,b,u,kCnt\n) ,\u2200t, (4)\nwhere \u03c32 is the noise variance power of AWGN. In addition, It,b,u,kCnt is the inter-cell interference on subcarrier k in RRS b for user u and it is calculated as follows:\nIt,u,kCnt = \u2211\nb\u2032 6=b\u2208B \u2211 u\u2032 6=u\u2208U ht,b \u2032,u,kpt,b \u2032,u\u2032,k Cnt \u03c1 t,b\u2032,u\u2032,k Cnt . (5)\nIn a similar manner, the total achieved data rate by adopting the distributed scheme is denoted by rtDst and is given by.\nrtDst = \u2211 b\u2208B \u2211 k\u2208Kb \u2211 u\u2208Ub\n( 1 + ht,b,u,kpt,b,u,kDst \u03c1 t,b,u,k Dst\n\u03c32 + It,u,kDst\n) ,\u2200t, (6)\nwhere It,u,kDst is the inter-cell interference for user u at time slot t. It can be seen that in the distributed manner the interference only depends on the user location, i.e., the large scale fading as each RRS calculates the large scale fading of the other RRSs to its users based on the locations. Also, in the worst-case scenario, we introduce an upper bound for the interference function which is based on the maximum transmit power that each RRS can allocate. Thus, the inter-cell interference is computed as follows:\nIt,u,kDst = \u2211\nb\u2032 6=b\u2208B \u2211 u\u2032 6=u\u2208U ht,b \u2032,u Large P b\u2032 Equal, (7)\nin which P b \u2032 Equal = pb\n\u2032\nmax\n|U tb\u2032 ||Ktb\u2032 | .\n3) Computational Complexity: The computational complexity of DRL-based methods depends on the number of neurons, layers, the state size, the action space, the number of episodes (E), and the number of samples of random batch (M ) [9]. Accordingly, by considering a DRL network with |N | hidden layers, the total computational complexity for the centralized method, is calculated as follows:\n\u0393tCnt = O\n( E \u00b7M \u00b7 ( lInputCnt,tl1 + N\u22122\u2211 n=1 lnln+1 + lN\u22121l Output Cnt,t )) ,\n(8)\nwhere ln is the number of neurons in the layer n of the deployed neural network, and lInputCnt,t is the number of input layer in the DRL network and it is equal to the state size which is given by lInputCnt,t = |U t| \u00b7 |Kt| \u00b7 |B|. In addition, l Output Cnt,t denotes the number of output layers for the centralized method and it is calculated by\nlOutputCnt,t = |P t Cnt|+ |\u03c1tCnt|. In a similar manner, the computational complexity for the distributed method in RRS b is given by .\n\u0393b,tDst = O\n( E \u00b7M \u00b7 ( lInputDst,b,tl1 + N\u22122\u2211 n=1 lnln+1 + lN\u22121l Output Dst,b,t )) ,\n(9)\nwhere lInputDst,b,t denotes the number of neurons in the input layer of DRL in the RRS b and it is given by lInputDst,b,t = |U tb | \u00d7 |Ktb|. Moreover, lOutputDst,b,t is the number of neurons in the output layer for RRS b and it is given by lOutputDst,b,t = |P t Dst,b|+ |\u03c1tDst,b|.\n4) Main Problem: The SDN controller stores data rates, overhead, and complexities of the D previous time slots as follows: rCnt = {rt\u2212DCnt , ..., r t\u22121 Cnt}, rDst = {r t\u2212D Dst , ..., r t\u22121 Dst}, \u03c4Cnt = {\u03c4 t\u2212DCnt , ..., \u03c4 t\u22121 Cnt}, \u03c4 bDst = {\u03c4 t\u2212D Dst , ..., \u03c4 t\u22121 Dst}, \u0393Cnt = {\u0393t\u2212DCnt , ...,\u0393 t\u22121 Cnt}, \u0393 b Dst = {\u0393t\u2212DDst , ...,\u0393 t\u22121 Dst}. Also, based on the previous stored data, the following TOC metrics are considered:\nTOCtCnt = r t Cnt \u2212 \u03b2\u03c4 tCnt \u2212 \u03b1\u0393tCnt, (10)\nTOCtDst = r t Dst \u2212 \u03b2max{\u03c4 b,t Dst} \u2212 \u03b1max{\u0393 b,t Dst}, (11)\nwhere \u03b1 and \u03b2 are the coefficient factors related to the overhead and computational complexity, which is affected by the number of information updates to solve the allocation problem resources. To have a better representation of the smart process of choosing solution method over the time, we provide the time-based scheme illustrated in Fig. 2."
        },
        {
            "heading": "B. Proposed Solution for the SDN",
            "text": "We employ the DRL framework for the decision-making problem at the SDN controller in which the states, actions, and rewards are described in Fig. 3. In the SDN algorithm, based on the given state S(t)SDN in each time slot, the SDN selects an appropriate action a(t)SDN. As you can see in Fig. 1, we consider a memory of network traffic and users\u2019 channel state information as S(t)SDN. By taking the action at each time slot, the agent gets a reward r(t)SDN that is defined on the basis of the objective function in the main resource allocation problem. After observing S(t+1)SDN , the SDN stores S(t)SDN, a (t) SDN, r (t) SDN, and S (t+1) SDN . Then, it employs a stochastic optimization method like Adam [10] to minimize the loss function and update its decision. The pseudo code of the proposed solution is provided in Algorithm. 1."
        },
        {
            "heading": "C. Resource Allocation Problem",
            "text": "After the decision-making stage, the resource allocation problem (RAP) is solved using one of the two different schemes in terms of centralized or distributed. In particular, we formulate the resource allocation problem to maximize the throughput of\nAlgorithm 1: Smart Resource Allocation Policy Selection Based on SAC\n1 Input: Initial Q value function parameters \u03c6 2 Input: Initial policy parameters \u03b8 3 Set: The memory of transaction B = \u2205; 4 for each iteration do 5 for each environment step do 6 In state S(t)SDN, based on the policy \u03c0 with parameters \u03b8, select action a(t)SDN: 7 a\n(t) SDN \u223c \u03c0\u03b8 ( \u00b7|S(t)SDN ) 8 if x(t)Cnt = 1 then 9 Based on (10), calculate the reward."
        },
        {
            "heading": "10 else",
            "text": "11 Based on (11), calculate the reward network state\nchanges: S(t)SDN \u2190 S (t+1) SDN 12 B \u2190 B \u222a { S\n(t) SDN, a (t) SDN, r\n( S\n(t) SDN, a (t) SDN\n) , S\n(t+1) SDN } 13 for each gradient step do 14 Update parameters \u03b8 and \u03c6 based on the Adam [10]\noptimizer.\nthe network while taking into account the subcarrier allocation and power control based on the downlink OFDMA. To solve the problem, we propose a SAC based resource allocation for the centralized and distributed scenarios. In what follows, we explain how the resource allocation problem can be solved.\n1) Centralized Scheme: In the case where x(t)Cnt = 1, the RAP is solved based on a single agent SAC at the BBU pool for RRS b as shown in Fig. 1. Specifically, in this scheme, RRSs act as RRHs in which the radio frequency tasks and the resource allocation process are performed at the BBU pool. Each RRS collects related information and forwards it to the BBU pool. Based on the received information at time slot t, the agent chooses action aCnt. Then, the actions are sent to the RRSs based on the resource allocated in the BBU pool unit. Moreover, the reward rCnt and new states SCnt are collected and forwarded to the BBU pool through fronthaul links.\n2) Decentralized Scheme: In the distributed scheme i.e., x(t)Dst = 1, resource allocation is performed by the RRSs using an independent multi-agent actor critic method. To reduce the overhead, we consider that RRS b in the distributed mode cannot access the others\u2019 information and just performs the resource allocation tasks by using its own information. The DQNs, are implemented at the RRS and each agent computes the power control and subcarrier allocation locally. As we can see in Fig. 3, each RRS b at time slot t observes state S(t)b and takes the action a(t)b , individually. Also, it receives the results of its own behavior as the reward r(t)b without knowing the actions of the other agents."
        },
        {
            "heading": "III. NUMERICAL RESULTS AND DISCUSSION",
            "text": "We consider a coverage area of radius 500 m with four distributed BSs, each covering a radius of 100 m. The maximum transmit power of the BSs are set to 40 dBm, and the total bandwidth is divided into 32 orthogonal subcarriers. The pathgain between a specific user and a BS for RF communication follows the Rayleigh distribution with distance-based path loss. The noise power at each subcarrier is assumed \u2212174 dBm/Hz.\nFig. 4 illustrates the overhead and complexity of the network based on the different policies (i.e., centralized, distributed, and smart). We assume the set {16, 4, 4} as the number of information bits to transmit channel status, subcarrier indicators, and the transmission power in the feedback process. As we can see, the network overhead and complexity for the centralized structure is too high, which leads to numerous difficulties in the network, such as the high delay and low reliability. The overhead and complexity in the distributed network are lower, which makes the distributed architecture preferable for realtime reliable networks. Fig. 4 also shows that the complexity and overhead of the centralized structure are greater in the ultra-dense networks, which makes the centralized policy inefficient for a dense network. This is due to the fact that in the centralized scheme, the complexity and overhead grow linearly due to resource management being performed over all the transmission nodes of the network with information being exchanged between all nodes. In contrast, the complexity and overhead of the distributed scheme are inferior. This indicates that the complexity gap between the two schemes is much more sensible in dense networks with many users. On the other hand, the overhead and complexity of the smart model closely follow those of the centralized and distributed structures in low and ultra-dense networks, respectively. We remark that although for a single instance the smart decision selects one of the centralized/distributed approaches, as a result of the existence of different channels that are variable over the time, the overhead and complexity of the smart network on average would occur between two different strict centralized or distributed architectures. In Fig. 5, we compare the achievable data rate for the different proposed architectures. As we can see, the achievable data rate of the centralized scheme outperforms the others, because in this scheme the network\u2019s knowledge is collected at the centralize\nunit, which raises the network awareness and efficiency. The smart solution achieves a data rate intermediate between the centralized and distributed schemes. In particular, by increasing the network\u2019s traffic, the smart scheme at first follows the centralized structure and then approaches the distributed case. Further, as Fig. 5 shows, the achievable data rate for a huge number of users in all schemes is saturated due to the limited resources. We remark that since there are different channel gains which are variable over time, the smart algorithm achieves the data rate between the centralized and distributed results. We can also observe in Fig. 5 that the efficiency of the SAC based algorithm is greater than the other methods. This makes sense since the soft actor-critic can be employed for the continuous variables while the DQN needs some discretized variables, that results in some performance loss.\nFig. 6 presents a comparison of Throughput Overhead Complexity (TOC) values for the centralized, distributed, and proposed smart network models. It is assumed that the number of users in the network varies depending on the level of traffic, from low to heavy. As we can see in Fig. 6, the centralized network shows a moderate performance increase in terms of TOC when the traffic status is low while it experiences a sharp decrease in a dense network. In the distributed network, there is a moderate increase of performance in terms of TOC by increasing the load of the network. At |K| = 200, the throughput of the distributed structure exceeds that of the centralized one, and thus the decision-making algorithm here plays a vital role in the network. Another interesting observation in this figure is that the performance gain in terms of the TOC through the learningbased approaches is better than that of the DDPG method. This means that although the achieved data rate through the DDPG is higher than that of the ML solutions, the complexity of the DDPG in the centralized manner is very high, which deteriorates the performance gain in terms of TOC.\nIV. CONCLUSION\nIn this paper, we proposed a hierarchical network management model that adopts the best resource allocation policy in relation to changes in network status. The proposed intelligent model is density aware, which guarantees the network\u2019s per-\nformance on the basis of the DRL algorithm. We investigated three different scenarios (i.e., fixed centralized, fixed distributed, and dynamic) for different levels of network traffic. Simulation results showed that the proposed algorithm not only performs better than conventional learning methods in terms of TOC, but it also outperforms both fixed centralized and distributed resource allocation policies."
        }
    ],
    "title": "Smart Resource Allocation Model via Artificial Intelligence in Software Defined 6G Networks",
    "year": 2023
}