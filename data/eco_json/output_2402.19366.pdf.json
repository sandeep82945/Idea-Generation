{
    "abstractText": "The growing number of cases requiring digital forensic analysis raises concerns about law enforcement\u2019s ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs. In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement entities.",
    "authors": [
        {
            "affiliations": [],
            "name": "Akila Wickramasekara"
        },
        {
            "affiliations": [],
            "name": "Frank Breitinger"
        },
        {
            "affiliations": [],
            "name": "Mark Scanlon"
        }
    ],
    "id": "SP:628f12c9df052c0227aa1642ac4912fbd34aede3",
    "references": [
        {
            "authors": [
                "Francisca Adoma Acheampong",
                "Henry Nunoo-Mensah",
                "Wenyu Chen"
            ],
            "title": "Transformer models for text-based emotion detection: a review of BERT-based approaches",
            "venue": "Artificial Intelligence Review",
            "year": 2021
        },
        {
            "authors": [
                "Arafat Al-Dhaqm",
                "Shukor Abd Razak",
                "Richard Adeyemi Ikuesan",
                "Victor R. Kebande",
                "Kamran Siddique"
            ],
            "title": "A Review of Mobile Forensic Investigation Process Models",
            "venue": "IEEE Access",
            "year": 2020
        },
        {
            "authors": [
                "Rami Al-Rfou",
                "Dokook Choe",
                "Noah Constant",
                "Mandy Guo",
                "Llion Jones"
            ],
            "title": "Character-level language modeling with deeper self-attention",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Jean-Baptiste Alayrac",
                "Jeff Donahue",
                "Pauline Luc",
                "Antoine Miech",
                "Iain Barr"
            ],
            "title": "Flamingo: a Visual Language Model for Few-Shot Learning",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Liaqat Ali"
            ],
            "title": "Cyber crimes-A constant threat for the business sectors and its growth (A study of the online banking sectors in GCC)",
            "venue": "The Journal of Developing Areas 53,",
            "year": 2019
        },
        {
            "authors": [
                "Uri Alon",
                "Roy Sadaka",
                "Omer Levy",
                "Eran Yahav"
            ],
            "title": "Structural Language Models of Code",
            "venue": "In International Conference on Machine Learning. PMLR,",
            "year": 2020
        },
        {
            "authors": [
                "Ian Arawjo",
                "Chelse Swoopes",
                "Priyan Vaithilingam",
                "Martin Wattenberg",
                "Elena Glassman"
            ],
            "title": "ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing",
            "year": 2023
        },
        {
            "authors": [
                "B. Mesk\u00f3"
            ],
            "title": "Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial",
            "venue": "J Med Internet Res",
            "year": 2022
        },
        {
            "authors": [
                "Venansius Baryamureeba",
                "Florence Tushabe"
            ],
            "title": "The enhanced digital investigation process model",
            "venue": "Digital Investigation",
            "year": 2004
        },
        {
            "authors": [
                "Emily M. Bender",
                "Timnit Gebru",
                "Angelina McMillan-Major",
                "Shmargaret Shmitchell"
            ],
            "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big",
            "venue": "In Proceedings of the 2021 ACM Conference on Fairness, Accountability,",
            "year": 2021
        },
        {
            "authors": [
                "Rishi Bommasani",
                "Drew A. Hudson",
                "Ehsan Adeli",
                "Russ Altman",
                "Simran Arora"
            ],
            "title": "On the Opportunities and Risks of Foundation Models",
            "year": 2022
        },
        {
            "authors": [
                "Euan Bonner",
                "Ryan Lege",
                "Erin Frazier"
            ],
            "title": "Large Language Model-Based Artificial Intelligence in the Language Classroom: Practical Ideas for Teaching",
            "venue": "Teaching English with Technology",
            "year": 2023
        },
        {
            "authors": [
                "Andres M Bran",
                "Philippe Schwaller"
            ],
            "title": "Transformers and Large Language Models for Chemistry and Drug Discovery",
            "year": 2023
        },
        {
            "authors": [
                "Frank Breitinger",
                "Jan-Niclas Hilgert",
                "Christopher Hargreaves",
                "John Sheppard",
                "Rebekah Overdorf",
                "Mark Scanlon"
            ],
            "title": "DFRWS EU 10-Year Review and Future Directions in Digital Forensic Research",
            "venue": "Forensic Science International: Digital Investigation",
            "year": 2024
        },
        {
            "authors": [
                "Tom B. Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared Kaplan"
            ],
            "title": "Language Models Are Few-Shot Learners",
            "venue": "In Proceedings of the 34th International Conference on Neural Information Processing Systems (Vancouver, BC, Canada)",
            "year": 2020
        },
        {
            "authors": [
                "Andrew Caines",
                "Luca Benedetto",
                "Shiva Taslimipoor",
                "Christopher Davis",
                "Yuan Gao"
            ],
            "title": "On the Application of Large Language Models for Language Teaching and Assessment Technology",
            "year": 2023
        },
        {
            "authors": [
                "In\u00eas Carvalho",
                "Stanislav Ivanov"
            ],
            "title": "ChatGPT for tourism: applications, benefits and risks",
            "venue": "Tourism Review",
            "year": 2023
        },
        {
            "authors": [
                "Eoghan Casey"
            ],
            "title": "Digital Evidence and Computer Crime: Forensic Science, Computers, and the Internet",
            "year": 2011
        },
        {
            "authors": [
                "Christophe Champod",
                "Alex Biedermann",
                "Jo\u00eblle Vuille",
                "Sheila Willis",
                "Jan De Kinder"
            ],
            "title": "ENFSI guideline for evaluative reporting in forensic science: A primer for legal practitioners",
            "venue": "Criminal Law and Justice Weekly 180,",
            "year": 2016
        },
        {
            "authors": [
                "Bei Chen",
                "Fengji Zhang",
                "Anh Nguyen",
                "Daoguang Zan",
                "Zeqi Lin",
                "Jian-Guang Lou",
                "Weizhu Chen"
            ],
            "title": "CodeT: Code Generation with Generated Tests",
            "venue": "In The Eleventh International Conference on Learning Representations",
            "year": 2023
        },
        {
            "authors": [
                "Chi Chen",
                "Ruoyu Qin",
                "Fuwen Luo",
                "Xiaoyue Mi",
                "Peng Li",
                "Maosong Sun",
                "Yang Liu"
            ],
            "title": "Position-Enhanced Visual Instruction Tuning for Multimodal Large Language Models",
            "year": 2023
        },
        {
            "authors": [
                "Dake Chen",
                "Hanbin Wang",
                "Yunhao Huo",
                "Yuzhao Li",
                "Haoyang Zhang"
            ],
            "title": "GameGPT: Multi-agent Collaborative Framework for Game Development",
            "year": 2023
        },
        {
            "authors": [
                "Cheng-Han Chiang",
                "Hung yi Lee"
            ],
            "title": "Can Large Language Models Be an Alternative to Human Evaluations",
            "year": 2023
        },
        {
            "authors": [
                "Aakanksha Chowdhery",
                "Sharan Narang",
                "Jacob Devlin",
                "Maarten Bosma",
                "Gaurav Mishra"
            ],
            "title": "PaLM: Scaling Language Modeling with Pathways",
            "venue": "Journal of Machine Learning Research 24,",
            "year": 2023
        },
        {
            "authors": [
                "Fenia Christopoulou",
                "Gerasimos Lampouras",
                "Milan Gritta",
                "Guchun Zhang",
                "Yinpeng Guo"
            ],
            "title": "PanGu-Coder: Program Synthesis with Function-Level Language Modeling",
            "year": 2022
        },
        {
            "authors": [
                "Robert Dale"
            ],
            "title": "GPT-3: What\u2019s it good for",
            "venue": "Natural Language Engineering 27,",
            "year": 2021
        },
        {
            "authors": [
                "Erik Derner",
                "Kristina"
            ],
            "title": "Beyond the Safeguards: Exploring the Security Risks of ChatGPT",
            "venue": "Batistic\u030c",
            "year": 2023
        },
        {
            "authors": [
                "Tim Dettmers",
                "Artidoro Pagnoni",
                "Ari Holtzman",
                "Luke Zettlemoyer"
            ],
            "title": "QLoRA: Efficient Finetuning of Quantized LLMs",
            "year": 2023
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova"
            ],
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "venue": "In Proceedings of the",
            "year": 2019
        },
        {
            "authors": [
                "Xiaoyu Du",
                "Nhien-An Le-Khac",
                "Mark Scanlon"
            ],
            "title": "Evaluation of Digital Forensic Process Models with Respect to Digital Forensics as a Service",
            "venue": "In Proceedings of the 16th European Conference on Cyber Warfare and Security (ECCWS 2017). ACPI,",
            "year": 2017
        },
        {
            "authors": [
                "Xiaoyu Du",
                "Mark Scanlon"
            ],
            "title": "Methodology for the Automated Metadata- Based Classification of Incriminating Digital Forensic Artefacts",
            "venue": "Association for Computing Machinery,",
            "year": 2019
        },
        {
            "authors": [
                "Himanshu Dubey",
                "Shobha Bhatt",
                "Lokesh Negi"
            ],
            "title": "Digital Forensics Techniques and Trends: A Review",
            "venue": "The International Arab Journal of Information Technology (IAJIT) 20,",
            "year": 2023
        },
        {
            "authors": [
                "Florin Eggmann",
                "Roland Weiger",
                "Nicola U Zitzmann",
                "Markus B Blatz"
            ],
            "title": "Implications of large language models such as ChatGPT for dental medicine",
            "venue": "Journal of Esthetic and Restorative Dentistry",
            "year": 2023
        },
        {
            "authors": [
                "Lizhou Fan",
                "Lingyao Li",
                "Zihui Ma",
                "Sanggyu Lee",
                "Huizi Yu",
                "Libby Hemphill"
            ],
            "title": "A Bibliometric Review of Large Language Models Research from",
            "year": 2023
        },
        {
            "authors": [
                "Daniel Fried",
                "Armen Aghajanyan",
                "Jessy Lin",
                "Sida Wang",
                "Eric Wallace",
                "Freda Shi",
                "Ruiqi Zhong",
                "Scott Yih",
                "Luke Zettlemoyer",
                "Mike Lewis"
            ],
            "title": "InCoder: A Generative Model for Code Infilling and Synthesis",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Leon Fr\u00f6hling andArkaitz Zubiaga"
            ],
            "title": "Feature-Based Detection of Automated Language Models: Tackling GPT-2, GPT-3, and Grover",
            "venue": "PeerJ Computer Science",
            "year": 2021
        },
        {
            "authors": [
                "David Glukhov",
                "Ilia Shumailov",
                "Yarin Gal",
                "Nicolas Papernot",
                "Vardan Papyan"
            ],
            "title": "LLM Censorship: A Machine Learning Challenge or a Computer Security Problem",
            "year": 2023
        },
        {
            "authors": [
                "Muhammad Usman Hadi",
                "qasem al tashi",
                "Rizwan Qureshi",
                "Abbas Shah",
                "amgad muneer",
                "Muhammad Irfan",
                "Anas Zafar",
                "Muhammad Bilal Shaikh",
                "Naveed Akhtar",
                "Jia Wu",
                "Seyedali Mirjalili"
            ],
            "title": "Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects",
            "year": 2023
        },
        {
            "authors": [
                "Hans Henseler",
                "Harm van Beek"
            ],
            "title": "ChatGPT as a Copilot for Investigating Digital Evidence. In Proceedings of the Third International Workshop on Artificial Intelligence and Intelligent Assistance for Legal Professionals in the Digital Workplace (LegalAIIA 2023) co-located with the 19th International Conference on Artificial Intelligence and Law (ICAIL 2023)",
            "venue": "(CEUR Workshop Proceedings),",
            "year": 2023
        },
        {
            "authors": [
                "Xinying Hou",
                "Yanjie Zhao",
                "Yue Liu",
                "Zhou Yang",
                "Kailong Wang",
                "Li Li",
                "Xiapu Luo",
                "David Lo",
                "John C. Grundy",
                "Haoyu Wang"
            ],
            "title": "Large Language Models for Software Engineering: A Systematic Literature Review",
            "year": 2023
        },
        {
            "authors": [
                "Joshua James",
                "Pavel Gladyshev"
            ],
            "title": "Challenges with Automation in Digital Forensic Investigations",
            "venue": "ArXiv abs/1303.4498",
            "year": 2013
        },
        {
            "authors": [
                "Ezhil Kalaimannan",
                "Jatinder N.D. Gupta",
                "Seong-Moo Yoo"
            ],
            "title": "Maximizing Investigation Effectiveness in Digital Forensic Cases",
            "venue": "In 2013 International Conference on Social Computing",
            "year": 2013
        },
        {
            "authors": [
                "Mert Karabacak",
                "Konstantinos Margetis"
            ],
            "title": "Embracing Large Language Models for Medical Applications: Opportunities and Challenges",
            "venue": "Cureus 15,",
            "year": 2023
        },
        {
            "authors": [
                "Nickson. M. Karie",
                "Victor R. Kebande",
                "H.S. Venter",
                "Kim-Kwang Raymond Choo"
            ],
            "title": "On the Importance of Standardizing the Process of Generating Digital Forensic Reports",
            "venue": "Forensic Science International: Reports",
            "year": 2019
        },
        {
            "authors": [
                "Guolin Ke",
                "Di He",
                "Tie-Yan Liu"
            ],
            "title": "Rethinking Positional Encoding in Language Pre-training",
            "year": 2021
        },
        {
            "authors": [
                "Ryan Kiros",
                "Ruslan Salakhutdinov",
                "Rich Zemel"
            ],
            "title": "Multimodal Neural Language Models",
            "venue": "In Proceedings of the 31st International Conference on Machine Learning (Proceedings of Machine Learning Research),",
            "year": 2014
        },
        {
            "authors": [
                "Barbara Kitchenham"
            ],
            "title": "Procedures for Performing Systematic Reviews",
            "venue": "Keele, UK, Keele University",
            "year": 2004
        },
        {
            "authors": [
                "Jing Yu Koh",
                "Daniel Fried",
                "Russ Salakhutdinov"
            ],
            "title": "Generating Images with Multimodal Language Models",
            "venue": "In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems",
            "year": 2023
        },
        {
            "authors": [
                "Christopher S. Koper",
                "Cynthia Lum",
                "James J. Willis"
            ],
            "title": "Optimizing the Use of Technology in Policing: Results and Implications from a Multi-Site Study of the Social, Organizational, and Behavioural Aspects of Implementing Police Technologies",
            "venue": "Policing: A Journal of Policy and Practice",
            "year": 2014
        },
        {
            "authors": [
                "Siwei Lai",
                "Kang Liu",
                "Shizhu He",
                "Jun Zhao"
            ],
            "title": "How to generate a good word embedding",
            "venue": "IEEE Intelligent Systems 31,",
            "year": 2016
        },
        {
            "authors": [
                "Patrick Lewis",
                "Ethan Perez",
                "Aleksandra Piktus",
                "Fabio Petroni",
                "Vladimir Karpukhin"
            ],
            "title": "Retrieval-Augmented Generation for Knowledge- Intensive NLP Tasks",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Junnan Li",
                "Dongxu Li",
                "Silvio Savarese",
                "Steven Hoi"
            ],
            "title": "BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models",
            "year": 2023
        },
        {
            "authors": [
                "Raymond Li",
                "Loubna Ben Allal",
                "Yangtian Zi",
                "Niklas Muennighoff",
                "Denis Kocetkov"
            ],
            "title": "StarCoder: May the Source Be with You",
            "venue": "Transactions on Machine Learning Research",
            "year": 2023
        },
        {
            "authors": [
                "Yujia Li",
                "David Choi",
                "Junyoung Chung",
                "Nate Kushman",
                "Julian Schrittwieser"
            ],
            "title": "Competition-Level Code Generation with AlphaCode",
            "venue": "Science",
            "year": 2022
        },
        {
            "authors": [
                "Yuanze Li",
                "Haolin Wang",
                "Shihao Yuan",
                "Ming Liu",
                "Debin Zhao",
                "Yiwen Guo",
                "Chen Xu",
                "Guangming Shi",
                "Wangmeng Zuo"
            ],
            "title": "Myriad: Large Multimodal Model by Applying Vision Experts for Industrial Anomaly Detection",
            "year": 2023
        },
        {
            "authors": [
                "Jiaju Lin",
                "Haoran Zhao",
                "Aochi Zhang",
                "Yiting Wu",
                "Huqiuyue Ping",
                "Qin Chen"
            ],
            "title": "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation",
            "year": 2023
        },
        {
            "authors": [
                "Haotian Liu",
                "Chunyuan Li",
                "Yuheng Li",
                "Yong Jae Lee"
            ],
            "title": "Improved Baselines with Visual Instruction Tuning",
            "year": 2023
        },
        {
            "authors": [
                "Haotian Liu",
                "Chunyuan Li",
                "Qingyang Wu",
                "Yong Jae Lee"
            ],
            "title": "Visual Instruction Tuning",
            "venue": "In Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems",
            "year": 2023
        },
        {
            "authors": [
                "Jiawei Liu",
                "Chunqiu Steven Xia",
                "Yuyao Wang",
                "Lingming Zhang"
            ],
            "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation",
            "year": 2023
        },
        {
            "authors": [
                "Zhaoyang Liu",
                "Yinan He",
                "Wenhai Wang",
                "Weiyun Wang",
                "Yi Wang"
            ],
            "title": "InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language",
            "year": 2023
        },
        {
            "authors": [
                "Brady D Lund",
                "Ting Wang"
            ],
            "title": "Chatting About ChatGPT: How AI and GPT May Impact Academia and Libraries",
            "venue": "Library Hi Tech News 40,",
            "year": 2023
        },
        {
            "authors": [
                "Huaishao Luo",
                "Lei Ji",
                "Botian Shi",
                "Haoyang Huang",
                "Nan Duan",
                "Tianrui Li",
                "Xilin Chen",
                "Ming Zhou"
            ],
            "title": "UniViLM: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation",
            "venue": "ArXiv abs/2002.06353",
            "year": 2020
        },
        {
            "authors": [
                "Ziyang Luo",
                "Can Xu",
                "Pu Zhao",
                "Qingfeng Sun",
                "Xiubo Geng",
                "Wenxiang Hu",
                "Chongyang Tao",
                "Jing Ma",
                "Qingwei Lin",
                "Daxin Jiang"
            ],
            "title": "Wizard- Coder: Empowering Code Large Language Models with Evol-Instruct",
            "year": 2024
        },
        {
            "authors": [
                "Raymond Lutui"
            ],
            "title": "A multidisciplinary digital forensic investigation process model",
            "venue": "Business Horizons 59,",
            "year": 2016
        },
        {
            "authors": [
                "Ga\u00ebtan Michelet",
                "Frank Breitinger"
            ],
            "title": "ChatGPT, Llama, can you write my report? An experiment on assisted digital forensics reports written using (Local) Large Language Models",
            "year": 2023
        },
        {
            "authors": [
                "Ga\u00ebtan Michelet",
                "Frank Breitinger",
                "Graeme Horsman"
            ],
            "title": "Automation for Digital Forensics: Towards a definition for the community",
            "venue": "Forensic Science International",
            "year": 2023
        },
        {
            "authors": [
                "Tom\u00e1s Mikolov",
                "Kai Chen",
                "Greg Corrado",
                "Jeffrey Dean"
            ],
            "title": "Efficient Estimation of Word Representations in Vector Space",
            "venue": "In 1st International Conference on Learning Representations,",
            "year": 2013
        },
        {
            "authors": [
                "Sara Sarwar Mir",
                "Umar Shoaib",
                "Muhammad Shahzad Sarfraz"
            ],
            "title": "Analysis of digital forensic investigation models",
            "venue": "Int. J. Comput. Sci. Inform. Secur 14,",
            "year": 2016
        },
        {
            "authors": [
                "Steven Moore",
                "Richard Tong",
                "Anjali Singh",
                "Zitao Liu",
                "Xiangen Hu"
            ],
            "title": "Empowering Education with LLMs: The Next-Gen Interface and Content Generation",
            "venue": "In International Conference on Artificial Intelligence in Education",
            "year": 2023
        },
        {
            "authors": [
                "Shaaswat Mukherjee",
                "Shazia Haque"
            ],
            "title": "Review Paper on Digital Forensics Practices: A Road Map for Building Digital Forensics Capability",
            "venue": "Iconic Research and Engineering Journals 1,",
            "year": 2018
        },
        {
            "authors": [
                "Erik Nijkamp",
                "Bo Pang",
                "Hiroaki Hayashi",
                "Lifu Tu",
                "Huan Wang"
            ],
            "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis",
            "venue": "In The Eleventh International Conference on Learning Representations",
            "year": 2022
        },
        {
            "authors": [
                "Claudio Novelli",
                "Federico Casolari",
                "Antonino Rotolo",
                "Mariarosaria Taddeo",
                "Luciano Floridi"
            ],
            "title": "Taking AI Risks Seriously: A New Assessment Model for the AI Act",
            "venue": "AI & Society",
            "year": 2023
        },
        {
            "authors": [
                "Debora Nozza",
                "Federico Bianchi",
                "Anne Lauscher",
                "Dirk Hovy"
            ],
            "title": "Measuring Harmful Sentence Completion in Language Models for LGBTQIA+ Individuals",
            "venue": "In Proceedings of the Second Workshop on Language Technology for Equality,",
            "year": 2022
        },
        {
            "authors": [
                "Augustus Odena",
                "Charles Sutton",
                "David Martin Dohan",
                "Ellen Jiang",
                "Henryk Michalewski"
            ],
            "title": "Program Synthesis with Large Language Models",
            "year": 2021
        },
        {
            "authors": [
                "Jiao Ou",
                "Junda Lu",
                "Che Liu",
                "Yihong Tang",
                "Fuzheng Zhang",
                "Di Zhang",
                "Zhongyuan Wang",
                "Kun Gai"
            ],
            "title": "DialogBench: Evaluating LLMs as Human-like Dialogue Systems",
            "year": 2023
        },
        {
            "authors": [
                "Guilherme Penedo",
                "Quentin Malartic",
                "Daniel Hesslow",
                "Ruxandra Cojocaru",
                "Hamza Alobeidli"
            ],
            "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data Only",
            "year": 2023
        },
        {
            "authors": [
                "Zhiliang Peng",
                "Wenhui Wang",
                "Li Dong",
                "Yaru Hao",
                "Shaohan Huang",
                "Shuming Ma",
                "Furu Wei"
            ],
            "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World",
            "year": 2023
        },
        {
            "authors": [
                "Maciej P. Polak",
                "Dane Morgan"
            ],
            "title": "Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering - Example of ChatGPT",
            "year": 2023
        },
        {
            "authors": [
                "Yudi Prayudi",
                "Ahmad Ashari",
                "Tri Kuntoro Priyambodo"
            ],
            "title": "The Framework to Support the Digital Evidence Handling: A Case Study of Procedures for the Management of Evidence in Indonesia",
            "venue": "Journal of Cases on Information Technology (JCIT) 22,",
            "year": 2020
        },
        {
            "authors": [
                "Shuhan Qi",
                "Zhengying Cao",
                "Jun Rao",
                "Lei Wang",
                "Jing Xiao",
                "Xuan Wang"
            ],
            "title": "What Is the Limitation of Multimodal LLMs? A Deeper Look into Multimodal LLMs Through Prompt Probing",
            "venue": "Information Processing & Management 60,",
            "year": 2023
        },
        {
            "authors": [
                "Rui Qian",
                "Yeqing Li",
                "Zheng Xu",
                "Ming-Hsuan Yang",
                "Serge Belongie",
                "Yin Cui"
            ],
            "title": "Multimodal Open-Vocabulary Video Classification via Pre-Trained Vision and Language Models",
            "year": 2022
        },
        {
            "authors": [
                "Yujia Qin",
                "Shihao Liang",
                "Yining Ye",
                "Kunlun Zhu",
                "Lan Yan",
                "Yaxi Lu",
                "Yankai Lin",
                "Xin Cong",
                "Xiangru Tang",
                "Bill Qian",
                "Sihan Zhao",
                "Runchu Tian",
                "Ruobing Xie",
                "Jie Zhou",
                "Mark Gerstein",
                "Dahai Li",
                "Zhiyuan Liu",
                "Maosong Sun"
            ],
            "title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs",
            "year": 2024
        },
        {
            "authors": [
                "Alec Radford",
                "Jong Wook Kim",
                "Chris Hallacy",
                "Aditya Ramesh",
                "Gabriel Goh"
            ],
            "title": "Learning Transferable Visual Models From Natural Language Supervision",
            "venue": "In Proceedings of the 38th International Conference on Machine Learning (Proceedings of Machine Learning Research),",
            "year": 2021
        },
        {
            "authors": [
                "Alec Radford",
                "Jong Wook Kim",
                "Chris Hallacy",
                "Aditya Ramesh",
                "Gabriel Goh"
            ],
            "title": "Learning Transferable Visual Models From Natural Language Supervision",
            "venue": "In Proceedings of the 38th International Conference on Machine Learning (Proceedings of Machine Learning Research),",
            "year": 2021
        },
        {
            "authors": [
                "Noorjahan Rahman",
                "Eduardo Santacana"
            ],
            "title": "Beyond Fair Use: Legal Risk Evaluation for Training LLMs on Copyrighted Text",
            "venue": "In ICML Workshop on Generative AI and Law",
            "year": 2023
        },
        {
            "authors": [
                "Nitarshan Rajkumar",
                "Raymond Li",
                "Dzmitry Bahdanau"
            ],
            "title": "Evaluating the Text-to-SQL Capabilities of Large Language Models",
            "year": 2022
        },
        {
            "authors": [
                "Aditya Ramesh",
                "Mikhail Pavlov",
                "Gabriel Goh",
                "Scott Gray",
                "Chelsea Voss"
            ],
            "title": "Zero-Shot Text-to-Image Generation",
            "venue": "In Proceedings of the 38th International Conference on Machine Learning (Proceedings of Machine Learning Research),",
            "year": 2021
        },
        {
            "authors": [
                "Partha Pratim Ray"
            ],
            "title": "ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope",
            "venue": "Internet of Things and Cyber-Physical Systems",
            "year": 2023
        },
        {
            "authors": [
                "Alpa Reshamwala",
                "Dhirendra Mishra",
                "Prajakta Pawar"
            ],
            "title": "Review on natural language processing",
            "venue": "IRACST Engineering Science and Technology: An International Journal (ESTIJ) 3,",
            "year": 2013
        },
        {
            "authors": [
                "Matthias C. Rillig",
                "Marlene \u00c5gerstrand",
                "Mohan Bi",
                "Kenneth A. Gould",
                "Uli Sauerland"
            ],
            "title": "Risks and Benefits of Large Language Models for the Environment",
            "venue": "Environmental Science & Technology 57,",
            "year": 2023
        },
        {
            "authors": [
                "Michael G. Rizzo",
                "Nathan Cai",
                "David Constantinescu"
            ],
            "title": "The performance of ChatGPT on orthopaedic in-service training exams: A comparative study of the GPT-3.5 turbo and GPT-4 models in orthopaedic education",
            "venue": "Journal of Orthopaedics",
            "year": 2024
        },
        {
            "authors": [
                "Baptiste Rozi\u00e8re",
                "Jonas Gehring",
                "Fabian Gloeckle",
                "Sten Sootla",
                "Itai Gat"
            ],
            "title": "Code Llama: Open Foundation Models for Code",
            "year": 2024
        },
        {
            "authors": [
                "Mark Scanlon",
                "Frank Breitinger",
                "Christopher Hargreaves",
                "Jan-Niclas Hilgert",
                "John Sheppard"
            ],
            "title": "ChatGPT for digital forensic investigation: The good, the bad, and the unknown",
            "venue": "Forensic Science International: Digital Investigation",
            "year": 2023
        },
        {
            "authors": [
                "Mark Scanlon",
                "Bruce Nikkel",
                "Zeno Geradts"
            ],
            "title": "Digital forensic investigation in the age of ChatGPT",
            "venue": "Forensic Science International: Digital Investigation",
            "year": 2023
        },
        {
            "authors": [
                "Makhdoom SyedMuhammad Baqir Shah",
                "Shahzad Saleem",
                "Roha Zulqarnain"
            ],
            "title": "Protecting digital evidence integrity and preserving chain of custody",
            "venue": "Journal of Digital Forensics, Security and Law 12,",
            "year": 2017
        },
        {
            "authors": [
                "Bo Shen",
                "Jiaxin Zhang",
                "Taihong Chen",
                "Daoguang Zan",
                "Bing Geng",
                "An Fu",
                "Muhan Zeng",
                "Ailun Yu",
                "Jichuan Ji",
                "Jingyang Zhao",
                "Yuenan Guo",
                "Qianxiang Wang"
            ],
            "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback",
            "year": 2023
        },
        {
            "authors": [
                "Yiqiu Shen",
                "Laura Heacock",
                "Jonathan Elias",
                "Keith D. Hentel",
                "Beatriu Reig",
                "George Shih",
                "Linda Moy"
            ],
            "title": "ChatGPT and Other Large Language Models Are Double-edged Swords",
            "venue": "Radiology 307,",
            "year": 2023
        },
        {
            "authors": [
                "Noah Shinn",
                "Federico Cassano",
                "Ashwin Gopinath",
                "Karthik R Narasimhan",
                "Shunyu Yao"
            ],
            "title": "Reflexion: Language Agents with Verbal Reinforcement Learning",
            "venue": "In Thirty-seventh Conference on Neural Information Processing Systems",
            "year": 2023
        },
        {
            "authors": [
                "Swardiantara Silalahi",
                "Tohari Ahmad",
                "Hudan Studiawan"
            ],
            "title": "Transformerbased Sentiment Analysis for Anomaly Detection on Drone Forensic Timeline",
            "venue": "11th International Symposium on Digital Forensics and Security (ISDFS)",
            "year": 2023
        },
        {
            "authors": [
                "Aarohi Srivastava",
                "Abhinav Rastogi",
                "Abhishek Rao",
                "Abu Awal Md Shoeb",
                "Abubakar Abid"
            ],
            "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
            "venue": "Transactions on Machine Learning Research (2023)",
            "year": 2023
        },
        {
            "authors": [
                "Ruixiang Tang",
                "Yu-Neng Chuang",
                "Xia Hu"
            ],
            "title": "The Science of Detecting LLM-Generated Texts",
            "year": 2023
        },
        {
            "authors": [
                "Yoad Tewel",
                "Yoav Shalev",
                "Idan Schwartz",
                "Lior Wolf"
            ],
            "title": "ZeroCap: Zero- Shot Image-to-Text Generation for Visual-Semantic Arithmetic",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "year": 2022
        },
        {
            "authors": [
                "Surendrabikram Thapa",
                "Usman Naseem",
                "Mehwish Nasim"
            ],
            "title": "From Humans to Machines: Can ChatGPT-like LLMs Effectively Replace Human Annotators in NLP Tasks",
            "venue": "In Workshop Proceedings of the 17th International 11 AAAI Conference on Web and Social Media",
            "year": 2023
        },
        {
            "authors": [
                "Arun James Thirunavukarasu",
                "Darren Shu Jeng Ting",
                "Kabilan Elangovan",
                "Laura Gutierrez",
                "Ting Fang Tan",
                "Daniel Shu Wei Ting"
            ],
            "title": "Large language models in medicine",
            "venue": "Nature Medicine 29,",
            "year": 2023
        },
        {
            "authors": [
                "Romal Thoppilan",
                "Daniel De Freitas",
                "Jamie Hall",
                "Noam M. Shazeer",
                "Apoorv Kulshreshtha"
            ],
            "title": "LaMDA: Language Models for Dialog Applications",
            "year": 2022
        },
        {
            "authors": [
                "Meng-Lin Tsai",
                "ChongWei Ong",
                "Cheng-Liang Chen"
            ],
            "title": "Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT",
            "venue": "Education for Chemical Engineers",
            "year": 2023
        },
        {
            "authors": [
                "Shagun Uppal",
                "Sarthak Bhagat",
                "Devamanyu Hazarika",
                "Navonil Majumder",
                "Soujanya Poria"
            ],
            "title": "Multimodal research in vision and language: A review of current and emerging trends",
            "venue": "Information Fusion",
            "year": 2022
        },
        {
            "authors": [
                "Aleksandar Valjarevi\u0107",
                "Hein Venter",
                "Ranko Petrovi\u0107"
            ],
            "title": "ISO/IEC 27043:2015 \u2014 Role and Application",
            "venue": "In 2016 24th Telecommunications Forum (TELFOR)",
            "year": 2016
        },
        {
            "authors": [
                "R.B. van Baar",
                "H.M.A. van Beek",
                "E.J. van Eijk"
            ],
            "title": "Digital Forensics as a Service: A game changer",
            "venue": "Digital Investigation",
            "year": 2014
        },
        {
            "authors": [
                "H.M.A. van Beek",
                "E.J. van Eijk",
                "R.B. van Baar",
                "M. Ugen",
                "J.N.C. Bodde",
                "A.J"
            ],
            "title": "Digital Forensics as a Service: Game on",
            "venue": "Siemelink",
            "year": 2015
        },
        {
            "authors": [
                "Harm MA van Beek",
                "Jeroen van den Bos",
                "Abdul Boztas",
                "EJ Van Eijk",
                "R Schramp",
                "M Ugen"
            ],
            "title": "Digital forensics as a service: Stepping up the game",
            "venue": "Forensic Science International: Digital Investigation",
            "year": 2020
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is All you Need",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Maxim Vidgof",
                "Stefan Bachhofner",
                "Jan Mendling"
            ],
            "title": "Large Language Models for Business Process Management: Opportunities and Challenges",
            "venue": "In Business Process Management Forum,",
            "year": 2023
        },
        {
            "authors": [
                "Guanzhi Wang",
                "Yuqi Xie",
                "Yunfan Jiang",
                "Ajay Mandlekar",
                "Chaowei Xiao",
                "Yuke Zhu",
                "Linxi Fan",
                "Anima Anandkumar"
            ],
            "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
            "year": 2023
        },
        {
            "authors": [
                "Haohan Wang",
                "Bhiksha Raj",
                "Eric P. Xing"
            ],
            "title": "On the Origin of Deep Learning",
            "venue": "CoRR abs/1702.07800",
            "year": 2017
        },
        {
            "authors": [
                "Lei Wang",
                "Chen Ma",
                "Xueyang Feng",
                "Zeyu Zhang",
                "Hao Yang",
                "Jingsen Zhang",
                "Zhiyuan Chen",
                "Jiakai Tang",
                "Xu Chen",
                "Yankai Lin",
                "Wayne Xin Zhao",
                "Zhewei Wei",
                "Ji-Rong Wen"
            ],
            "title": "A Survey on Large Language Model based Autonomous Agents",
            "year": 2023
        },
        {
            "authors": [
                "Wenhai Wang",
                "Zhe Chen",
                "Xiaokang Chen",
                "JiannanWu",
                "Xizhou Zhu",
                "Gang Zeng",
                "Ping Luo",
                "Tong Lu",
                "Jie Zhou",
                "Yu Qiao",
                "Jifeng Dai"
            ],
            "title": "VisionLLM: Large Language Model Is Also an Open-Ended Decoder for Vision-Centric Tasks",
            "year": 2023
        },
        {
            "authors": [
                "YanchengWang",
                "Ziyan Jiang",
                "Zheng Chen",
                "Fan Yang",
                "Yingxue Zhou",
                "Eunah Cho",
                "Xing Fan",
                "XiaojiangHuang",
                "Yanbin Lu",
                "Yingzhen Yang"
            ],
            "title": "RecMind: Large Language Model Powered Agent For Recommendation",
            "year": 2023
        },
        {
            "authors": [
                "Yue Wang",
                "Hung Le",
                "Akhilesh Gotmare",
                "Nghi Bui",
                "Junnan Li",
                "Steven Hoi"
            ],
            "title": "CodeT5+: Open Code Large LanguageModels for Code Understanding and Generation",
            "year": 2023
        },
        {
            "authors": [
                "Zhenhailong Wang",
                "Manling Li",
                "Ruochen Xu",
                "Luowei Zhou",
                "Jie Lei"
            ],
            "title": "Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Fei Xia"
            ],
            "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2022
        },
        {
            "authors": [
                "Jules White",
                "Quchen Fu",
                "Sam Hays",
                "Michael Sandborn",
                "Carlos Olea",
                "Henry Gilbert",
                "Ashraf Elnashar",
                "Jesse Spencer-Smith",
                "Douglas C. Schmidt"
            ],
            "title": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT",
            "year": 2023
        },
        {
            "authors": [
                "Yotam Wolf",
                "Noam Wies",
                "Oshri Avnery",
                "Yoav Levine",
                "Amnon Shashua"
            ],
            "title": "Fundamental Limitations of Alignment in Large Language Models",
            "year": 2024
        },
        {
            "authors": [
                "Chenfei Wu",
                "Sheng-Kai Yin",
                "Weizhen Qi",
                "Xiaodong Wang",
                "Zecheng Tang",
                "Nan Duan"
            ],
            "title": "Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models",
            "year": 2023
        },
        {
            "authors": [
                "Qingyun Wu",
                "Gagan Bansal",
                "Jieyu Zhang",
                "Yiran Wu",
                "Shaokun Zhang",
                "Erkang (Eric) Zhu",
                "Beibin Li",
                "Li Jiang",
                "Xiaoyun Zhang",
                "Chi Wang"
            ],
            "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi- Agent Conversation",
            "venue": "Technical Report MSR-TR-2023-33. Microsoft. https://www.microsoft.com/en-us/research/publication/autogen-enablingnext-gen-llm-applications-via-multi-agent-conversation-framework/",
            "year": 2023
        },
        {
            "authors": [
                "Tina Wu",
                "Frank Breitinger",
                "Stephen O\u2019Shaughnessy"
            ],
            "title": "Digital forensic tools: Recent advances and enhancing the status quo",
            "venue": "Forensic Science International: Digital Investigation",
            "year": 2020
        },
        {
            "authors": [
                "Frank F. Xu",
                "Uri Alon",
                "Graham Neubig",
                "Vincent Josua Hellendoorn"
            ],
            "title": "A Systematic Evaluation of Large Language Models of Code",
            "venue": "In Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming (San Diego, CA,",
            "year": 2022
        },
        {
            "authors": [
                "Dao Xuan-Quy",
                "Le Ngoc-Bich",
                "Ngo Bac-Bien",
                "Phan Xuan-Dung"
            ],
            "title": "LLMs\u2019 Capabilities at the High School Level in Chemistry: Cases of ChatGPT andMicrosoft Bing Chat",
            "year": 2023
        },
        {
            "authors": [
                "Xianjun Yang",
                "Yan Li",
                "Xinlu Zhang",
                "Haifeng Chen",
                "Wei Cheng"
            ],
            "title": "Exploring the Limits of ChatGPT for Query or Aspect-based Text Summarization",
            "year": 2023
        },
        {
            "authors": [
                "Junjie Ye",
                "Xuanting Chen",
                "Nuo Xu",
                "Can Zu",
                "Zekai Shao",
                "Shichun Liu",
                "Yuhan Cui",
                "Zeyang Zhou",
                "Chao Gong",
                "Yang Shen",
                "Jie Zhou",
                "Siming Chen",
                "Tao Gui",
                "Qi Zhang",
                "Xuanjing Huang"
            ],
            "title": "A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models",
            "year": 2023
        },
        {
            "authors": [
                "Hongxin Zhang",
                "Weihua Du",
                "Jiaming Shan",
                "Qinhong Zhou",
                "Yilun Du",
                "Joshua Tenenbaum",
                "Tianmin Shu",
                "Chuang Gan"
            ],
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models. https://openreview",
            "venue": "net/forum?id=oBQVCTpKXW",
            "year": 2023
        },
        {
            "authors": [
                "Jingyi Zhang",
                "Jiaxing Huang",
                "Sheng Jin",
                "Shijian Lu"
            ],
            "title": "Vision-Language Models for Vision Tasks: A Survey",
            "year": 2023
        },
        {
            "authors": [
                "Shilong Zhang",
                "Peize Sun",
                "Shoufa Chen",
                "Min Xiao",
                "Wenqi Shao",
                "Wenwei Zhang",
                "Kai Chen",
                "Ping Luo"
            ],
            "title": "GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest",
            "year": 2024
        },
        {
            "authors": [
                "Yizhe Zhang",
                "Siqi Sun",
                "Michel Galley",
                "Yen-Chun Chen",
                "Chris Brockett"
            ],
            "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
            "venue": "Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Bo Zhao",
                "Boya Wu",
                "Tiejun Huang"
            ],
            "title": "SVIT: Scaling up Visual Instruction Tuning",
            "year": 2023
        },
        {
            "authors": [
                "Yue Zhao",
                "Ishan Misra",
                "Philipp Kr\u00e4henb\u00fchl",
                "Rohit Girdhar"
            ],
            "title": "Learning Video Representations From Large Language Models",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
            "year": 2023
        },
        {
            "authors": [
                "Qinkai Zheng",
                "Xiao Xia",
                "Xu Zou",
                "Yuxiao Dong",
                "Shan Wang"
            ],
            "title": "CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X",
            "year": 2023
        },
        {
            "authors": [
                "Denny Zhou",
                "Nathanael Sch\u00e4rli",
                "Le Hou",
                "JasonWei",
                "Nathan Scales",
                "XuezhiWang",
                "Dale Schuurmans",
                "Claire Cui",
                "Olivier Bousquet",
                "Quoc V Le"
            ],
            "title": "Least-to- Most Prompting Enables Complex Reasoning in Large Language Models",
            "venue": "In The Eleventh International Conference on Learning Representations",
            "year": 2022
        },
        {
            "authors": [
                "Yongchao Zhou",
                "Andrei Ioan Muresanu",
                "Ziwen Han",
                "Keiran Paster",
                "Silviu Pitis",
                "Harris Chan",
                "Jimmy Ba"
            ],
            "title": "Large Language Models are Human-Level Prompt Engineers",
            "year": 2023
        },
        {
            "authors": [
                "Deyao Zhu",
                "Jun Chen",
                "Xiaoqian Shen",
                "Xiang Li",
                "Mohamed Elhoseiny"
            ],
            "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models",
            "year": 2024
        },
        {
            "authors": [
                "Yutao Zhu",
                "Huaying Yuan",
                "Shuting Wang",
                "Jiongnan Liu",
                "Wenhan Liu",
                "Chenlong Deng",
                "Zhicheng Dou",
                "Ji rong Wen"
            ],
            "title": "Large Language Models for Information Retrieval: A Survey",
            "year": 2023
        },
        {
            "authors": [
                "Daniel M. Ziegler",
                "Nisan Stiennon",
                "Jeffrey Wu",
                "Tom B. Brown",
                "Alec Radford"
            ],
            "title": "Fine-Tuning Language Models from Human Preferences",
            "year": 2020
        },
        {
            "authors": [
                "Andy Zou",
                "Zifan Wang",
                "J. Zico Kolter",
                "Matt Fredrikson"
            ],
            "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "KEYWORDS Digital Forensics, Large Language Models, Investigative Process, Challenges"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "With the pervasive growth of Information and Communication Technology (ICT) and information systems, cybercrimes have witnessed a significant surge in recent years [6]. As a further compounding factor, the number of \u201ctraditional\u201d police investigations including digital evidence is also ever-increasing [35]. Addressing and investigating this volume of cases presents substantial challenges.\nArtificial General Intelligence (AGI) and Large Language Models (LLMs) have become prominent topics of global discussion, prompting researchers to intensify their investigations by leveraging the capabilities of LLMs. The usage of LLMs within the scientific community experienced a rapid surge after 2022, notably with the advent of OpenAI\u2019s ChatGPT platform. In a remarkably short period, this topic has garnered attention from academia, industry, and the research community at large [94]. Simultaneously, researchers are exploring the potential of LLMs across various domains and assessing their impact on the future of science and society. This inquiry also includes an examination of the potential harmfulness associated with the deployment of LLMs [17, 78]. In other words, the use of LLMs in various tasks can be a double-edged sword, necessitating careful consideration depending on the specific situations and contexts.\nGiven the swiftly evolving landscape of LLMs, it is prudent to look into various types and their unique capabilities. A nuanced\nunderstanding of the strengths and characteristics of different LLMs can contribute to more informed and effective applications within the dynamic field of digital forensics (DF).\nThe main objective of this article is to explore the viability of integrating LLMs into the fundamental phases of the modern DF process. This exploration involved a meticulous and systematic review, adhering to the standards set by Kitchenham [51]. The literature selected for this review was exclusively in English, and non-article sources such as books were excluded. The focus of the review encompassed empirical studies, case studies, and literature reviews within the domain of DF investigation methods, models, frameworks, efficiency, and challenges, as well as LLM capabilities, challenges, and architectures. Additionally, the study underscores the utilisation of autonomous agents based on LLMs, emphasising their capabilities and the potential efficiency gains achievable in the field of DF. In light of the fast-paced advancements and recent explosion in LLM-focused research, a substantial influx of LLMfocused research papers has occurred since the launch of ChatGPT in late 2022. Due to this fast pace, a large number of research articles exist solely as preprints on preprint services, e.g., arXiv or OpenReview. To give two examples, the initial papers for GPT-4 [2] and LLaMA [112] are both only published on arXiv, but have garnered thousands of citations each. Despite their preprint status, these papers offer essential insights critical for contemporary research and dialogue within the domain, making their incorporation into this paper necessary to provide the most up-to-date knowledge and perspectives.\nThe paper is structured as follows: Section 2 provides a comprehensive background for the review, delving into existing DF process models, the challenges inherent in DF, and a detailed overview of the current work conducted with the utilisation of LLMs within DF. In Section 3 the paper delves into the realm of Natural Language Processing (NLP), elucidating the working principles of LLMs, their architectural foundations, and the specifics surrounding specially trained LLMs. Section 4 provides an in-depth review focusing on the capabilities and benchmark information of LLMs trained for coding tasks, as well as those tailored for vision assistance. Section 4 explores the synergy between DF and LLMs, detailing how LLMs can be effectively employed in each phase of the DF process model. Finally, in Section 6, the paper summarises the future challenges associated with integrating LLMs with automated agents within the DF domain. It outlines potential avenues for future research and development, shedding light on the path of future DF investigations employing LLMs. The discussion encompasses not only the potential negative impacts but also the practical difficulties and risks in real-world environments. ar X iv :2\n40 2.\n19 36\n6v 1\n[ cs\n.C R\n] 2\n9 Fe\nb 20\n24"
        },
        {
            "heading": "2 BACKGROUND",
            "text": "DF is a process to identify, preserve, analyse, and document digitally recorded data, which originate in electronic devices such as computers, servers, smartphones, and IoT devices [11]. This exercise is required in most criminal cases. Data collected in this process are kept unchanged and safe to present in a court case or to support future investigations conducted by law enforcement agencies [75]."
        },
        {
            "heading": "2.1 Digital Forensic Process Models",
            "text": "DF process models consist of a series of activities that help to standardise the investigative process [34] and outline the phases; collection, preservation of evidence, examination or analysis, and reporting.\nDF encompasses various subdisciplines such as computer forensics, mobile device forensics, memory forensics, network forensics, and cloud forensics, each employing distinct processes reflected in a plethora of models within the literature [99, 134]. These models often share phases but differ in their focus and execution. For instance, Al-Dhaqm et al. [3] proposed a mobile forensic model that adds a preparatory phase and bifurcates the analysis stage into examination and analysis phases. To accommodate the complexities of computer, network, cloud, and smart device forensics, Lutui [69] introduced a multidisciplinary model that necessitates diverse skills for effective investigation, covering incident detection to evidence storage.\nCasey\u2019s model, as shown in Figure 1, includes phases like incident recognition, evidence collection, preservation, and presentation, with the examination phase detailed into recovery, harvesting, reduction, and classification [20]. This model emphasises the critical nature of maintaining evidence integrity and the requirement for expert analysis to extract and interpret pertinent information, culminating in a report suitable for legal scrutiny [20]. Notably, the analysis or examination stage is pivotal in all models, demanding specialised knowledge in the relevant DF area [73, 84].\nThe advent of cloud computing has led to the Digital Forensic as a Service (DFaaS) model by van Baar et al., integrating evidence preservation and analysis into an automated, secure software service, marking a significant evolution in forensic methodologies [34, 118, 119]."
        },
        {
            "heading": "2.2 Existing Challenges in Digital Forensics",
            "text": "DF is an evolving field, yet the literature highlights that it still undergoes changes to address ongoing challenges and advancements. Dubey et al. [36] assert that DF faces key challenges, including the\ncomplexity of data and its volume, a lack of standardisation, inadequacies in the power of existing tools to support investigations and issues related to timelines.\nIn addition to the previouslymentioned challenges, issues such as scope creep in cases due to complexity and vast data, as well as the critical tasks of selecting and prioritising the right set of evidence, and efficiently allocating time and investigators for the chosen evidence, were highlighted [46]. Koper et al. [53] focus on certain issues from the investigator\u2019s perspective, including challenges in adapting to a system, unexpected time-saving negations, and frustrations among officers arising from timelines and the adoption of complex systems.\nAutomating the DF process using existing technology appears to be a promising solution for addressing issues related to time management and effectiveness [71]. However, an ongoing challenge revolves around measuring the accuracy of investigations and ensuring the verification of the automated process. This aspect remains an open area that requires further attention and resolution [45]."
        },
        {
            "heading": "2.3 Existing Work With LLMs in Digital Forensics",
            "text": "Scanlon et al. [99] analysed using ChatGPT for DF. In their assessment, the authors evaluated the programming, incident narration, keyword list creation, and DF teaching abilities of ChatGPT. Their conclusion highlighted that while ChatGPT exhibited some hallucinations in the output results, it still serves as an effective assistant for code generation.\nTimeline reconstruction aids investigators in deducing the behaviour of an event. In line with timeline regeneration, Silalahi et al. [105] proposed a method to detect anomalies in a drone flight by employing sentiment analysis with the assistance of a pre-trained LLM. Their approach successfully discerned differences between normal and abnormal events with an accuracy of 92.5%.\nHansken, a DFaaS platform created by the Netherlands Forensic Institute, is designed to assist investigators in handling evidence and conducting investigations more efficiently [117]. ChatGPT has been utilised as an assistance for the Hansken DFaaS system, contributing to streamlined processes and improved support for investigators [43]. In a successful experiment, evidence traces were provided to ChatGPT, and it was tasked with analysing the case, ultimately providing conclusions. This utilisation of ChatGPT showcases its potential in assisting with the analytical aspects of investigations, highlighting its ability to process and interpret evidence data [43]."
        },
        {
            "heading": "3 LARGE LANGUAGE MODELS",
            "text": "This section explores LLMs, concentrating on three principal aspects. Initially, it explores the architecture of LLMs, detailing their design and function. Next, it assesses the usability of LLMs, underscoring the features and capabilities that render them apt for a wide range of tasks. Finally, it showcases the versatility of LLMs by discussing their application across various fields, demonstrating their wide-reaching impact and the extensive scope of their applications."
        },
        {
            "heading": "3.1 Natural Language Processing",
            "text": "Popular LLMs such as Generative Pre-trained Transformer (GPT) [30], Language Model for Dialogue Applications (LaMDA) [111], Pathways Language Model (PaLM) [28], Bidirectional Encoder Representations from Transformers (BERT) [33], and Large Language Model Meta AI (LLaMA) [112] stem from advancements in Natural Language Processing (NLP). NLP, focusing on language-based tasks, utilises both traditional and deep learning models to enable applications such as language translation, text processing, and speech recognition [95].\nDeep learning, a branch of machine learning, uses complex computational layers and adaptive weights to enhance prediction accuracy, offering a more refined analysis than conventional machine learning [55]. It has excelled in image and speech recognition, and natural language understanding, mimicking the decision-making process of the human brain through artificial neurons. These neurons form networks capable of intricate pattern recognition and data analysis. Central to deep learning are neural networks with multiple hidden layers, which autonomously learn and featureextract from data, bypassing the need for manual variable selection. This automatic feature extraction makes them exceptionally adept at handling complex tasks [123]."
        },
        {
            "heading": "3.2 LLMs",
            "text": "An LLM is a language model employing neural networks with billions of parameters, trained on extensive text data. These models are engineered to comprehend and generate human language. Fundamentally, they rely on multiple neural network architectures, enabling them to recognise the relationships between words and phrases within sentences [38, 103]. These architectures have been a transformative force in the field of natural language processing. Its capability to excel across a diverse array of language-related tasks distinguishes it as a game-changer, in contrast to being tailored for a singular, specific task."
        },
        {
            "heading": "3.3 Architecture of LLMs",
            "text": "LLMs utilise deep learning, particularly neural networks, to process and produce human language. Fundamentally, a language model operates with letters or words, but since machine learning algorithms and neural networks require vector inputs, words are vectorised. Each word in the vocabulary is assigned a unique numerical value for input into neural networks. Through initial random weight assignments and subsequent backpropagation, words acquire numerical positions reflecting their semantic similarity, culminating in a word embedding model [54].\n3.3.1 Word to Vectors. Word embeddings, as introduced byMikolov et al. [72], entail precise and high-dimensional vector representations for words, particularly suited for extensive datasets comprising billions of text entries. The authors exploredmodel architectures for word vectorisation, achieving substantial enhancements in accuracy while requiring lower computational resources and reduced training time [72]. In the realm of LLMs, the primary objective is to generate new text based on the extensive dataset, on which it was trained. For this purpose, Vaswani et al. [120] introduced the transformer model, aided by the word-to-vector model. This\narchitecture incorporates a self-attention mechanism, as well as encoder and decoder processes, enabling the model to rapidly and simultaneously focus on pertinent information.\n3.3.2 Transformer Models. The transformer model initially aimed at machine translation, translating input words into another language, begins with word embedding, where inputs, termed as tokens, are vectorised. Recognising word order is achieved through positional encoding, with two main techniques: absolute and relative. Absolute positional encoding assigns unique vectors to each position, enhancing themodel\u2019s ability to recognise word placement and facilitate position-specific attention [49]. Relative positional encoding, on the other hand, calculates the relative positions of words by introducing a bias term that quantifies distances between positions, improving the model\u2019s capacity to understand word relationships within a sequence [49].\nSelf-attention, a core mechanism within the transformer, calculates the relationship among words in a sentence, allowing the model to assess eachword\u2019s similarity to others and generate unique representations for each [4]. The decoder mirrors the encoder\u2019s steps but uses different weights, starting with positional encoding and computing self-attention values to identify the sentence\u2019s initial translation word.\nThis transformer process, leveraging stacked self-attention and unique positional encoding, has significantly advanced NLP tasks, including machine translation, text generation, and summarisation, by executing these processes in parallel and optimising weights for both encoder and decoder [1, 120]."
        },
        {
            "heading": "3.4 Specifically Trained LLMs",
            "text": "The transformer model and the self-attention mechanism have paved the way for researchers to train language models on trillions of tokens with billions of parameters. Several LLMs have been trained and harnessed, each tailored with specific capabilities for diverse fields such as security, chemistry, engineering, medicine, business, tourism, and language-related applications. These models are employed in tasks ranging from detecting security threats, analysing data, and generating synthetic actions to teaching, code generation, structured query generation, planning, assisting in medical education, clinical decision-making, leveraging clinical settings, clinical validation, understanding general patterns and decisionmaking, bias detection, addressing ethical issues, language translations, question answering, information extraction, and business process automation, among others [14, 15, 18, 19, 22, 37, 41, 44, 47, 74, 79, 92, 110, 113, 121, 130, 136, 149]. The fine-tuning and retraining capabilities of LLMs empower them to be adapted to specific tasks or behaviours in a predefined manner. Fine-tuning involves taking an already trained language model and retraining its existing weights and bias values using a new dataset specific to a particular domain. This process allows the LLM to be customised and refined for tasks beyond its original training, enhancing its applicability in specific contexts [150]. This process results in a new model that is more tailored and focused on the specified domain. In existing literature, it is frequently observed that LLMs are fine-tuned with a particular emphasis on engineering and research-related fields. This targeted fine-tuning ensures that the model is adept at handling\ntasks and generating content specifically relevant to the intricacies of these domains [22]."
        },
        {
            "heading": "4 CAPABILITIES OF LARGE LANGUAGE MODELS",
            "text": "This section focuses on the abilities and capabilities of Language Model Models (LLMs) as outlined in Section 3.4. Additionally, it discusses the currently available fine-tuned LLMs that exhibit potential for application in DF."
        },
        {
            "heading": "4.1 Programming/Coding",
            "text": "The ability to generate source code within a specific context is a crucial proficiency inherent to a language model [8]. Xu et al. [135] conducted a systematic evaluation of six LLMs for code generation across twelve diverse programming languages. The benchmarking process involved the use of the HumanEval benchmark and an evaluation dataset designed to assess the functional correctness of programs generated by an LLM [26]. Initially, the dataset was employed for benchmarking Code, a GPT language model finetuned on publicly available code sourced from GitHub [26]. The Mostly Basic Programming Problems (MBPP) stands as another benchmark, comprising 974 programming tasks. It serves as a frequently employed evaluation dataset for LLMs specialising in coderelated tasks [129]. Several LLMs explicitly trained for code generation include Code LLaMA, CodeGen, StarCoder, PanGu-Coder, PanGu-Coder2, WizardCoder, InCoder 6B, CodeGen-Mono 16B, Code-Davinci-001, Code-Davinci-002, PaLM-Coder-540B, CodeT5+, InstructCodeT5+, GPT-4 with Reflexion, CodeGeeX, AlphaCode, Santa-Coder [7, 17, 23, 28, 29, 39, 58, 59, 68, 76, 98, 102, 104, 127, 138, 145, 146]. A higher value for both HumanEval and MBPP indicates greater accuracy in code generation for a given task. For detailed information, refer to Table 1, which presents the counts for HumanEval and MBPP, along with the trained parameter size for each LLM. Even with the benchmarking rates from HumanEval, Liu et al. [64] raised questions about the accuracy of the functionality of the generated code. To address this concern, they proposed EvalPlus, an automated test generation engine, to verify the functional correctness of LLM-generated code."
        },
        {
            "heading": "4.2 Vision Assistance",
            "text": "Traditional vision assistant systems face limitations in image processing or recognition, as they are typically trained on fixed types of datasets. However, with the emergence of LLMs, this paradigm has shifted towards utilising raw text as the source of supervision [89, 108]. Research on visual recognition language models is experiencing exponential growth, with the number of models surpassing 1,500 in 2023 [140]. Radford et al. [89] introduced a novel method called Contrastive Language-Image Pre-training (CLIP). This method is efficient and capable of performing a wide range of tasks during pre-training. It enables the training of a model to learn a shared representation space for both images and text, facilitating a deeper understanding of the relationships between the two modalities. Ramesh et al. [93] proposes a model for text-to-image\n* Estimated parameter count as value is not officially released [97].\ngeneration, capable of generating images as combinations derived from textual input or sentences. Moreover, with the model named Generating Images with Large Language Models (GILL), it becomes feasible to generate text, retrieve images, generate novel images, and interleave the results into coherent multimodal dialogues [52]. VisionLLM is a framework leveraging LLMs for diverse vision tasks with unified language instruction, demonstrating generality and flexibility [125]. It incorporates a language-guided image tokeniser and an LLM-based task decoder, capable of handling open-ended tasks based on provided language instructions [125].\nVisual instruction tuning leverages language-only models, such as GPT-4, to generate multimodal language-image instruction following data. This data is then utilised to instruction-tune large multimodal models, such as Large Language and Vision Assistant (LLaVA) [2, 62, 63]. The open-source LLaVA project introduces an end-to-end trainedmodel, integrating a vision encoder with an LLM. Notably, LLaVA showcases multimodal chat capabilities. LLaVa exhibits the capability to engage with images, providing detailed descriptions and responding to queries with a reported accuracy of 92.53% [63]. This demonstrates its effectiveness in understanding and generating contextually relevant information about visual content [63]. MiniGPT-4 is an open-source, powerful visual instructiontuned LLM, and it demonstrates versatility by generating stories and poems inspired by provided images and teaching users how to cook based on visual cues from food photos. This showcases its ability to understand and respond creatively to diverse visual stimuli [148].\nPosition-enhanced Visual Instruction Tuning (PVIT) represents an extended version ofMultimodal Large LanguageModels (MLLMs). It facilitates region-level encoding in an image, enabling the model to discern and identify information within specific regions [24]. Like PVIT, GPT-4 Region of Interest (ROI) is an instruction-tuned LLM capable of extracting information such as colour, shape, material, and action from a specified region [141]. This model enables users to interact with both language and drawing bounding boxes to indicate the area of interest within an image [141]. Other MLLMs, such as Visual ChatGPT, InternGPT, Flamingo, BLIP-2, and Kosmos, are noted in the literature for their capacity to assist users in visual-related information [5, 57, 65, 82, 90, 132, 143].\nVideo information is gaining prominence in vision assistance, and Zhao et al. [144] has introduced a novel approach to automatically narrate lengthy videos using LLMs. UniVL is another language pre-trained model designed for both multimodal understanding and generation. It is capable of retrieving a video segment based on text descriptions, generating captions for given video clips, segmenting a video according to a provided text input, and conducting multimodal sentiment analysis of a video segment [67]. VidIL and MOV are additional MLLMswith similar capabilities, demonstrating proficiency in video classification and video-language operations such as video captioning, video question answering, video caption retrieval, and video future event prediction [87, 128].\nThese MLLMs adhere to a shared task set, encompassing visual question answering, visual captioning, visual common-sense reasoning, visual generation, multimodal affective computing, visual retrieval, vision-language navigation, multimodal machine translation, visual question generation, and visual dialoguing, as summarised in Table 2 [50, 114]."
        },
        {
            "heading": "4.3 Conversation",
            "text": "Specific LLMs are trained explicitly for meaningful and coherent dialogues with humans. An example is Dialogue Generative Pretrained Transformer (DialoGPT), a fine-tuned model trained on 174 million conversations from Reddit [142]. DialoGPT exhibits the ability to provide human-like answers in tested conversations [142]. Dettmers et al. [32] introduced a fine-tuning mechanism for LLMs named Quantized Pre-trained Language Model into Low-Rank Adapters (QLoRA). This allows the fine-tuning of large-parameter LLMs with low training costs. They introduced Guanaco, a finetuned LLM with 65 billion parameters, which achieved a performance level of 99.3%. Falcon-180B and Falcon-40B represent another set of open-source LLMs with 180 billion and 40 billion parameters. These models are trained to communicate in multiple languages, allowing users to engage in conversations in languages other than English [81]. To evaluate the accuracy of human-like dialogue systems, Ou et al. [80] proposed a dialogue evaluation benchmark named DialogBench, comprising 12 dialogue tasks to assess the capabilities of LLMs. In their evaluation, they assessed 28 pre-trained and instruction-tuned LLMs, demonstrating that GPT-4, ChatGPT, and KwaiYii-13B-Chat emerged as the top three models for conversations in domains related to daily life and professional knowledge.\nIn DF chat conversations, the significance lies in facilitating nontechnical investigators to elucidate terminologies and areas lacking\nunderstanding. This serves a dual purpose, acting as an interactive teacher to enhance comprehension in discussions [99]."
        },
        {
            "heading": "4.4 Prompt Engineering",
            "text": "Achieving quality outputs from LLMs often relies on providing well-crafted, meaningful, and precise input queries, known as input prompts. However, even human-defined natural language instructions may not consistently yield the best results. Prompt engineering is amethodology that involves carefully defining and instructing LLMs to generate more accurate and desirable outputs. Through thoughtful refinement of input prompts, prompt engineering aims to enhance the performance and effectiveness of LLMs in generating outputs that align more closely with user expectations and requirements [130, 147]. This plays a crucial role in biasing LLMs towards specific domains or topics, enabling a more targeted and nuanced response. By carefully crafting prompts, users can guide LLMs to delve deeper into the nuances of their queries, leading to more accurate and relevant outputs. This approach enhances the model\u2019s responsiveness to specific areas of interest, allowing users to fine-tune and tailor their interactions with the LLM for more precise and meaningful outcomes. Prompt engineering with LLMs is employed across various sectors, including but not limited to medical, engineering, construction, and healthcare [10, 83].\nChainForge is an open-source Graphical User Interface (GUI) tool developed specifically for prompt engineering and hypothesis testing derived from LLMs that can be used in the above-mentioned fields to generate accurate and swift outputs [9]."
        },
        {
            "heading": "4.5 Autonomous Agents",
            "text": "The evolution of LLMs, with their capacity to generate information and communicate in a manner resembling human interaction, has led to the development of autonomous agents. The expectation is that these agents will effectively execute a wide array of tasks, capitalising on the human-like capabilities inherent in LLMs [124]. These autonomous agents follow a four-stage architecture, encompassing profiling, memory, planning, and action. Profiling defines the agent\u2019s role, privileges, domain, and expertise [124]. Memory stores information about tasks and profile data relevant to the environment. Planning involves breaking down given tasks into subtasks and solving them individually. The action stage is the final phase where all decisions and subtasks are translated into actions executed by the agent. Zhang et al. [139] developed a framework designed to facilitate collaboration between AGI agents and humans. This framework enables planning and communication for specific tasks, leveraging the capabilities of LLMs Similarly, AgentSims, ToolBench, GameGPT, ChatDev, Voyager, and RecMind represent a diverse array of autonomous AGI agents developed with distinct goals and objectives [25, 61, 86, 88, 122, 126]. Certainly, AutoGen stands out as a multiagent framework with the capability to autonomously perform tasks or collaborate with human feedback. This flexibility makes it a versatile tool for various applications [133]."
        },
        {
            "heading": "4.6 Limitations and Risks",
            "text": "As explored in the preceding sections, it appears that LLMs possess a vast range of capabilities. However, it is crucial to acknowledge\nthat they are not without limitations and risks. In multimodal LLMs, it is a common issue that they are over-reliant [131]. Hadi et al. [42] highlighted significant drawbacks associated with LLMs, including issues such as bias, explainability challenges, reasoning errors, logical errors, hallucinations, vulnerability to prompt injections, and spelling and grammar errors. These limitations underscore the importance of a cautious and critical approach when utilising LLMs in various applications. Additionally, the literature shows limitations in LLMs, including statistical inconsistency, the absence of emotional attributes in linguistic responses, and challenges related to fact verification [40, 107]. These factors contribute to a comprehensive understanding of the constraints and potential shortcomings when working with LLMs. Thapa et al. [109] contend that while LLMs can indeed diminish the time and costs associated with annotation tasks, they fall short of completely supplanting human annotation. This is because they struggle with intricate linguistic constructions, such as idioms, irony, sarcasm, and metaphor, which can potentially impact the precision of annotations.\nSimilar limitations are associated with MLLMs. Issues such as over-reliance on training data, sensitivity to word order in the input prompts, and vulnerability to prompts containing extra knowledge represent challenges in the capabilities of MLLMs [85]. There are several more concerns associated with LLMs including restricted input and output text lengths, limited comprehension of syntax, ethical considerations with the generated information, constraints with multilingual capabilities, elevated costs associated with training\nand maintenance, inadequate understanding of human behaviours, and limited ability to learn incrementally [27, 42, 137].\nDespite their considerable capabilities, LLMs are not without risks. Bommasani et al. [13], Lund and Wang [66], Rahman and Santacana [91] provide comprehensive overviews of risks linked to LLMs. These include the homogenisation of outcomes, wherein defects or biases from the foundation model are inherited by all downstream models. There is also the risk of a monopoly for the owners of the foundationmodels, leading to increased centralisation of power in a single entity. Ethical and legal concerns are intertwined with privacy and intellectual property issues. Additionally, there are economic and environmental impacts, raising concerns about the potential displacement of human workers. Furthermore, inequity and misuse of LLMs, such as the creation of deepfakes and their application in criminal and unethical activities, pose additional challenges. Given that LLMs do not inherently prioritise the accuracy of information, Bender et al. [12] have underscored the risk of generating social turbulence, especially, when employed on social media platforms. Additionally, the use of LLMs is associated with significant costs, leading to a direct environmental impact due to their substantial energy consumption [96].\nThe risks associated with LLMs are predominantly emphasised within Information Communication and Technology (ICT) and cyberspace. Primary concerns include the disclosure of personal information, the generation of malicious text, and the creation of malicious code [31].\nIn response to the increasing prominence of LLMs and Artificial General Intelligence (AGI), the EU Artificial Intelligence Act (AIA) presently classifies AI systems into four risk categories based on broad fields of application. However, this categorisation approach may result in inaccurate risk estimation and ineffective enforcement. To rectify this issue, the authors advocate for a risk assessment model that aligns the risk categories with specific AI scenarios. This model integrates the AIA with the risk assessment approach employed by the Intergovernmental Panel on Climate Change (IPCC) and relevant literature, facilitating a more precise estimation of the magnitude of AI-related risks [77].\nThe Beyond the Imitation Game benchmark (BIG-bench), serves as an evaluation framework for LLMs. It encompasses 204 distinct language-related tasks, spanning contextual and context-free question-answering, reading comprehension, etc. [106]. It is acknowledged that the challenge of social biases and English language dependency persists across nearly all LLMs."
        },
        {
            "heading": "5 LARGE LANGUAGE MODELS FOR DIGITAL FORENSICS",
            "text": "Section 5 summarises existing work with LLMs in DF, the feasibility of employing them, and potential future directions. As discussed in Sections 3 and 4, despite the widespread use of LLMs in various fields to enhance the efficiency and accuracy of tasks within specific domains, their application in the field of DF is still relatively new.\nConducting a thorough analysis of the utilisation of LLMs in conjunction with the stages of the DF process model, as highlighted in Section 2.1, proves to be a valuable undertaking."
        },
        {
            "heading": "5.1 Incident Recognition Phase",
            "text": "In the initial phase of Casey\u2019s DF process model, which delineates the recognition of an incident, LLMs can serve as a valuable detection mechanism. In cases of cybercrime, the primary artefacts often involve data logs, data dumps and network dumps. Fine-tuning an LLM to monitor text-based logs and related files enables it to discern and identify potential or ongoing incidents within the environment. In network-related activities, anomaly detection plays a pivotal role in initiating an incident response. Various existing anomaly detection techniques are employed in systems for this purpose. Leveraging its capability to identify patterns in a series of text data sets, LLMs exhibit potential as an Intrusion Detection System (IDS) within such systems [60]."
        },
        {
            "heading": "5.2 Collection Phase",
            "text": "While evidence collection or seizure traditionally involves physical tasks requiring human interaction, LLMs can play a role in identifying and listing potential pieces of evidence at a crime scene. For instance, in the examination of photographs or video records from a crime scene, an investigator can enlist the assistance of a MLLM like LLaVa, GPT-4, or VisionLLM. These models are capable of processing information within the images and generating a text-based output, facilitating the interpretation and categorisation of visual data. While this task may seem simple and within the capabilities of a human agent, the efficiency becomes particularly evident, when dealing with a massive-scale investigation involving thousands of collected artefacts and photographs. Utilising an MLLM for initial\nprocessing can significantly save time, with human agents then focusing on the crucial task of verification and validation."
        },
        {
            "heading": "5.3 Preservation/Acquisition Phase",
            "text": "Preserving evidence is centred on maintaining integrity. To achieve this, various tools such as EnCase and FTK Imager have been employed, aiding investigators in streamlining their work processes [101]. In the context of preserving disk evidence, it becomes feasible for an investigator to articulate their requirements in natural language, LLM to generate source code tailored to the specific needs. Indeed, LLMs specialised in code generation, such as StarCoder, Code LLaMA, and others, can be fine-tuned and retrained for specific tasks, including those related to preserving disk evidence through customised code generation. In certain instances, gathering live data for forensic investigations becomes crucial, particularly data collected at the crime scene. For this purpose, investigators may leverage DFaaS platforms like Hansken. Hansken possesses the capability to amalgamate custom extraction APIs for data extractions, and these APIs can be developed using code-generative LLMs [117]. This approach enhances the adaptability and efficiency of the investigative process.\nAs stated in Section 4.5, the automation of code generation and unit testing can be facilitated by autonomous agents that utilise LLMs as their core. AutoGen, being an open-source framework, provides the means to develop AI agents tailored for specific tasks. These AutoGen agents are not only customizable and conversational but can also operate in diverse modes, employing combinations of LLMs, human inputs, and various tools [133]. Positively, automated agents, particularly those developed within frameworks like AutoGen, can be effectively employed in the preservation phase. Their capabilities will enable the automated preservation within this phase, streamlining and enhancing efficiency in the preservation of digital evidence [133]."
        },
        {
            "heading": "5.4 Examination Phase",
            "text": "This phase constitutes a pivotal component of the investigation, playing a crucial role in elucidating the case through activities such as data recovery, collection, reduction, and classification. For each of these components, LLMs fine-tuned for scripting can significantly assist, especially at a larger scale. Within these components, tasks such as keyword search, file recovery, pattern matching, and fragment reassembly can be achievedwithminimal technical knowledge using LLMs. LLMs can provide valuable assistance in these tasks by generating new codes, crafting regular expressions, generating passwords and/or password hash lists for decryption, and creating sample logs or files. LLMs can generate a set of instructions, queries, and Application Programming Interface (API) validations from natural language provided by a human. This opens up the possibility of integrating third-party tools like Scapy, tshark, John the Ripper, and others seamlessly into the investigative process, enhancing the toolkit available for DF investigations and the ability to automate these processes enhances efficiency and effectiveness in the examination phase of the investigation."
        },
        {
            "heading": "5.5 Analysis Phase",
            "text": "The analysis phase involves comprehending the incident and arriving at a conclusive understanding based on the information gathered during the examination phase. As also highlighted in Section 2.3, it has been demonstrated that LLMs are effective in case analysis [43]. The use of MLLMs, which possess the capability to interpret images, broadens the scope for analysing a crime case more comprehensively. LLMs can be specifically fine-tuned for the analysis of various data types, including log files, email contents, chat transcripts, call records, file metadata, hex dumps, memory dumps, and registry hives. Incorporating contents such as event logs, timestamps, and network traffic captures further enables the effective recreation of incidents by correlating each data set with the assistance of LLMs. Also, audio and video-specificMLLMs can assist in analysing the contents within these formats. This specialised capability has the potential to significantly save time for investigators in their analyses of audio and video data during investigations.\nThe use of automated agents can distribute the analysis workload. Simultaneously, leveraging Augmented Large Language Models (ALLM) and Retrieval Augmented Generation (RAG) techniques can enhance real-time knowledge searching, thereby improving the accuracy of analysis and decision-making processes [56]."
        },
        {
            "heading": "5.6 Reporting Phase",
            "text": "The quality and validity of evidence, along with the thoroughness of the analysis, are encapsulated in the final report. The reporting phase holds significant weight, as the entire judgement may hinge on this crucial stage. Notably, DF is experiencing heightened scrutiny with regard to the quality of the reports, emphasising the importance of precision and clarity in this phase [48]. As pointed out by Champod et al. [21], there is no standard framework for evaluating and reporting scientific findings to authorities and stakeholders. To provide assistance and alleviate scrutiny, incorporating LLMs for report creation is a viable solution. While by definition, LLMs do not produce deterministic outputs, they could be retrained using standards such as ISO/IEC 27043:2015, the international standard for the DF investigation process [115]. A first feasibility study has already been released byMichelet and Breitinger [70]. Naturally, LLMs could also help to automate forensic reports and alternative formats (i.e., not MS Word) such as HTML or Latex."
        },
        {
            "heading": "5.7 Other Possibilities",
            "text": "In general, LLMs can be effectively utilised in each phase of the DF process model. By integrating the DF process life cycle with automated agents, it becomes feasible to establish a fully automated DF process throughout an investigation. For instance, if automated agents are assigned specific roles and maintain synchronisation within each agent, employing frameworks such as AutoGen, there is a substantial potential to expedite the completion of one or multiple DF cases compared to relying solely on human agents. This approach enhances efficiency, speed, and consistency in the DF investigative process.\nScanlon et al. [99] highlights that LLMs can play a significant role in DF teaching scenarios. This involvement extends to activities such as storyboarding, synthetic content creation, and synthetic character profiling. Additionally, fine-tuned LLMs prove to\nbe valuable tools for establishing evaluation criteria for DF agents, facilitating the creation of exams, measuring the accuracy and efficiency of investigations through an automated weighing system, and effectively presenting a case to non-technical or non-domain individuals, such as judges."
        },
        {
            "heading": "5.8 Challenges for LLMs in Digital Forensics",
            "text": "To optimise results, LLMs likely need to be trained with specific forensic data (i.e., previous case data) to achieve the best results. Given the complexity and variation of cases, it is questionable how good the training data is and whether there is sufficient data [16]. Biases present in training data can lead to skewed interpretations and unjust outcomes.\nInvestigative findings and drawing conclusions are also heavily based on investigator experience and intuition, which are difficult to replicate using LLMs. Initially, they will only prove effective for certain subtasks within digital forensics, which raises questions about their superiority over deterministic programs in certain contexts. For instance, data may be parsed/converted using a regular piece of software or an LLM. While the former works deterministically, the latter is more general, but requires the practitioners to validate the output. This leads to the fundamental necessity for explainability (i.e., not using blackboxes) for investigations. The explainability of LLM-generated results remains a daunting challenge, as understanding the reasons for their, frequently non-deterministic, results is often elusive [70].\nMaintaining the energy- and resource-intensive infrastructure required to train and deploy LLMs is a significant financial burden, making it impractical for smaller forensic laboratories to utilise such technologies. Centralised systems may be an option but require clear guidelines on how data can/may be shared and exchanged. While LLMs can serve as valuable tools to support forensic investigations, it must be recognised that they currently function best as an aid, not a substitute for human expertise [100]. There is a risk that people may place too much trust in the results generated by LLMs (over-reliance), which could lead to complacency and overlook the need for detailed human expert analysis and validation.\nFinally, ethical and legal considerations must also be discussed. Determining accountability in cases where LLMs produce false information or are compromised by hacking. Clarifying responsibilities between developers, users and regulators is crucial to establish a framework for accountability. If LLM-generated DF results lead to incorrect information, the responsibility may lie with the developers for ensuring the accuracy of the model and with the users for the appropriate interpretation and validation of the results."
        },
        {
            "heading": "5.9 Risks of Integration",
            "text": "The integration of LLMs within the DF process comes with inherent risks \u2013 extra to those general LLM limitations outlined in Section 4.6. Notably, in the examination, analysis, and reporting phases, the utilisation of LLMs introduces the risk of producing inaccurate information, primarily due to the phenomenon of inheritance hallucinations associated with these models [70, 100]. Additionally, the biases and obscurities present in an inheritance model may significantly impact the performance of a DF-focused\nLLM \u2013 potentially leading to the unacceptable generation of biased or inaccurate information within the DF process.\nIt is also crucial to acknowledge that DF LLMs, like any complex models, are susceptible to adversarial manipulation [151]. This vulnerability poses a substantial risk in the context of sensitive domains such as DF, where the integrity of information gained is paramount. Adversarial attacks can compromise the reliability of LLM-generated outputs, potentially influencing the outcomes of various phases within the DF process.\nIndeed, despite incorporating human verification, outputs and reports generated by LLMs within DF applications may encounter challenges regarding acceptance within the legal systems of different countries. This highlights a significant usability risk associated with LLM-based DF applications, but one that can be carefully mitigated by limiting the technology\u2019s deployment as a human-inthe-loop investigative aid as opposed to directly feeding into any investigative/judicial decision-making processes."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "The convergence of LLMs with an array of technologies represents an exciting synergy. Although the utilisation of LLMs in the realm of DF is still in its nascent stages, there is evidence of their substantial potential to significantly augment the efficiency of investigations. The exploration of investment for LLMs across the entire DF process is considered, aiming to enhance the productivity and efficiency of investigations. Additionally, the integration of LLMs into current DF tools is posited to reduce user training times, as these models comprehend natural language input and provide outputs accordingly. In the dynamic landscape of LLM applications within DF, promising avenues for further exploration and advancement unfold.\nWhile the surge in LLM research is promising, it is crucial to balance enthusiasm with an awareness of existing challenges. The propensity for LLMs to produce hallucinations highlights the need for human oversight in critical decision-making processes, underscoring the irreplaceable value of human judgement, intuition and expertise. A notable limitation is the language dependency issue, as most LLMs are predominantly trained on English data, reducing their effectiveness with non-English content. Additionally, the deployment of LLMs in DF involves significant costs related to infrastructure for processing evidence. Questions also arise about the validation of task correctness and quality when automated by LLMs, as well as the legal and professional acceptance of results obtained with limited human intervention.\nIntegrating LLMs with automated agents offers a promising path to automating DF processes, potentially allowing multiple cases to be handled concurrently for more timely and precise outcomes. This integration could significantly streamline investigations. Future research should explore the role of LLMs and AI in DF decisionmaking. It is essential to focus on validating LLM-generated outputs to ensure their scope, accuracy, reliability, and trustworthiness in investigations. Further studies comparing DF outcomes with and without LLM integration are critical, as they could highlight LLMs\u2019 benefits and controlled applicability in DF and similar fields.\nIn essence, while LLMs offer exciting prospects for the future of digital forensics, a balanced approach that integrates their strengths\nwith human oversight is essential for harnessing their full potential. Inevitably, LLM-facilitated DF processes will themselves become the focus of future investigation."
        }
    ],
    "title": "SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency",
    "year": 2024
}