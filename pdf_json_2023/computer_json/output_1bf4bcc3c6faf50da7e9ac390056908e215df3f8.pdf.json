{
    "abstractText": "Despite being the go-to choice for link prediction on knowledge graphs, research on interpretability of knowledge graph embeddings (KGE) has been relatively unexplored. We present KGEx, a novel post-hoc method that explains individual link predictions by drawing inspiration from surrogate models research. Given a target triple to predict, KGEx trains surrogate KGE models that we use to identify important training triples. To gauge the impact of a training triple, we sample random portions of the target triple neighborhood and we train multiple surrogate KGE models on each of them. To ensure faithfulness, each surrogate is trained by distilling knowledge from the original KGE model. We then assess how well surrogates predict the target triple being explained, the intuition being that those leading to faithful predictions have been trained on \u201cimpactful\u201d neighborhood samples. Under this assumption, we then harvest triples that appear frequently across impactful neighborhoods. We conduct extensive experiments on two publicly available datasets, to demonstrate that KGEx is capable of providing explanations faithful to the black-box model.",
    "authors": [
        {
            "affiliations": [],
            "name": "Vasileios Baltatzis"
        },
        {
            "affiliations": [],
            "name": "Luca Costabello"
        }
    ],
    "id": "SP:2b165043d4d7ab7b9b91abae492ab107058d9f33",
    "references": [
        {
            "authors": [
                "Ahmed M Alaa",
                "Mihaela van der Schaar"
            ],
            "title": "Demystifying black-box models with symbolic metamodels",
            "venue": "NeurIPS,",
            "year": 2019
        },
        {
            "authors": [
                "S\u00f6ren Auer",
                "Christian Bizer",
                "Georgi Kobilarov",
                "Jens Lehmann",
                "Richard Cyganiak",
                "Zachary Ives"
            ],
            "title": "Dbpedia: A nucleus for a web of open data",
            "venue": "In The semantic web,",
            "year": 2007
        },
        {
            "authors": [
                "Ivana Bala\u017eevi\u0107",
                "Carl Allen",
                "Timothy M Hospedales"
            ],
            "title": "Tucker: Tensor factorization for knowledge graph completion",
            "venue": "arXiv preprint arXiv:1901.09590,",
            "year": 1901
        },
        {
            "authors": [
                "Federico Bianchi",
                "Gaetano Rossiello",
                "Luca Costabello",
                "Matteo Palmonari",
                "Pasquale Minervini"
            ],
            "title": "Knowledge Graph Embeddings and Explainable AI",
            "venue": "arXiv preprint arXiv:2004.14843,",
            "year": 2020
        },
        {
            "authors": [
                "Antoine Bordes",
                "Nicolas Usunier",
                "Alberto Garcia-Duran",
                "Jason Weston",
                "Oksana Yakhnenko"
            ],
            "title": "Translating embeddings for modeling multi-relational data",
            "venue": "In NIPS, pages 2787\u20132795,",
            "year": 2013
        },
        {
            "authors": [
                "Rajarshi Das",
                "Shehzaad Dhuliawala",
                "Manzil Zaheer",
                "Luke Vilnis",
                "Ishan Durugkar",
                "Akshay Krishnamurthy",
                "Alex Smola",
                "Andrew McCallum"
            ],
            "title": "Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning",
            "venue": "In ICLR,",
            "year": 2018
        },
        {
            "authors": [
                "Tim Dettmers",
                "Pasquale Minervini",
                "Pontus Stenetorp",
                "Sebastian Riedel"
            ],
            "title": "Convolutional 2d knowledge graph embeddings",
            "venue": "In AAAI,",
            "year": 2018
        },
        {
            "authors": [
                "Mikhail Galkin",
                "Jiapeng Wu",
                "Etienne Denis",
                "William L Hamilton"
            ],
            "title": "Nodepiece: Compositional and parameter-efficient representations of large knowledge graphs",
            "venue": "arXiv preprint arXiv:2106.12144,",
            "year": 2021
        },
        {
            "authors": [
                "Geoffrey Hinton",
                "Oriol Vinyals",
                "Jeff Dean"
            ],
            "title": "Distilling the knowledge in a neural network",
            "year": 2015
        },
        {
            "authors": [
                "Bo Kang",
                "Jefrey Lijffijt",
                "Tijl De Bie"
            ],
            "title": "ExplainE: An approach for explaining network embedding-based link predictions",
            "venue": "arXiv preprint arXiv:1904.12694,",
            "year": 1904
        },
        {
            "authors": [
                "Seyed Mehran Kazemi",
                "David Poole"
            ],
            "title": "Simple embedding for link prediction in knowledge graphs",
            "venue": "In Procs. of NeurIPS. 2018",
            "year": 2018
        },
        {
            "authors": [
                "Carolin Lawrence",
                "Timo Sztyler",
                "Mathias Niepert"
            ],
            "title": "Explaining neural matrix factorization with gradient rollback",
            "venue": "In Procs of AAAI,",
            "year": 2021
        },
        {
            "authors": [
                "Pasquale Minervini",
                "Sebastian Riedel",
                "Pontus Stenetorp",
                "Edward Grefenstette",
                "Tim Rockt\u00e4schel"
            ],
            "title": "Learning reasoning strategies in end-to-end differentiable proving",
            "venue": "In ICML,",
            "year": 2020
        },
        {
            "authors": [
                "Yatin Nandwani",
                "Ankesh Gupta",
                "Aman Agrawal",
                "Mayank Singh Chauhan",
                "Parag Singla"
            ],
            "title": "Oxkbc: Outcome explanation for factorization based knowledge base completion",
            "venue": "In AKBC,",
            "year": 2020
        },
        {
            "authors": [
                "Deepak Nathani",
                "Jatin Chauhan",
                "Charu Sharma",
                "Manohar Kaul"
            ],
            "title": "Learning attention-based embeddings for relation prediction in knowledge graphs",
            "venue": "arXiv preprint arXiv:1906.01195,",
            "year": 1906
        },
        {
            "authors": [
                "Dai Quoc Nguyen",
                "Tu Dinh Nguyen",
                "Dat Quoc Nguyen",
                "Dinh Phung"
            ],
            "title": "A novel embedding model for knowledge base completion based on convolutional neural network",
            "venue": "In NAACL,",
            "year": 2018
        },
        {
            "authors": [
                "Maximilian Nickel",
                "Volker Tresp",
                "Hans-Peter Kriegel"
            ],
            "title": "A three-way model for collective learning on multi-relational data",
            "venue": "In ICML,",
            "year": 2011
        },
        {
            "authors": [
                "Maximilian Nickel",
                "Kevin Murphy",
                "Volker Tresp",
                "Evgeniy Gabrilovich"
            ],
            "title": "A review of relational machine learning for knowledge graphs",
            "venue": "Procs of the IEEE,",
            "year": 2016
        },
        {
            "authors": [
                "Wonpyo Park",
                "Dongju Kim",
                "Yan Lu",
                "Minsu Cho"
            ],
            "title": "Relational knowledge distillation",
            "year": 2019
        },
        {
            "authors": [
                "Fabian M Suchanek",
                "Gjergji Kasneci",
                "Gerhard Weikum"
            ],
            "title": "Yago: a core of semantic knowledge",
            "venue": "In Procs of WWW,",
            "year": 2007
        },
        {
            "authors": [
                "Zhiqing Sun",
                "Zhi-Hong Deng",
                "Jian-Yun Nie",
                "Jian Tang"
            ],
            "title": "Rotate: Knowledge graph embedding by relational rotation in complex space",
            "venue": "In ICLR,",
            "year": 2019
        },
        {
            "authors": [
                "Kristina Toutanova",
                "Danqi Chen",
                "Patrick Pantel",
                "Hoifung Poon",
                "Pallavi Choudhury",
                "Michael Gamon"
            ],
            "title": "Representing text for joint embedding of text and knowledge bases",
            "venue": "In Procs of EMNLP,",
            "year": 2015
        },
        {
            "authors": [
                "Th\u00e9o Trouillon",
                "Johannes Welbl",
                "Sebastian Riedel",
                "\u00c9ric Gaussier",
                "Guillaume Bouchard"
            ],
            "title": "Complex embeddings for simple link prediction",
            "venue": "In ICML,",
            "year": 2016
        },
        {
            "authors": [
                "Bishan Yang",
                "Scott Wen-tau Yih",
                "Xiaodong He",
                "Jianfeng Gao",
                "Li Deng"
            ],
            "title": "Embedding entities and relations for learning and inference in knowledge bases",
            "venue": "In ICLR,",
            "year": 2015
        },
        {
            "authors": [
                "Fan Yang",
                "Zhilin Yang",
                "William W Cohen"
            ],
            "title": "Differentiable learning of logical rules for knowledge base reasoning",
            "venue": "In NIPS,",
            "year": 2017
        },
        {
            "authors": [
                "Wen Zhang",
                "Bibek Paudel",
                "Wei Zhang",
                "Abraham Bernstein",
                "Huajun Chen"
            ],
            "title": "Interaction embeddings for prediction and explanation in knowledge graphs",
            "venue": "Procs of the ICWSDM,",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Knowledge graphs are knowledge bases whose facts are labeled, directed edges between entities. Research led to broad-scope graphs such as DBpedia [2], WordNet, and YAGO [21]. Countless domain-specific knowledge graphs have also been published on the web, from bioinformatics to retail [10].\nKnowledge graph embeddings (KGE) are a family of graph representation learning methods that learn vector representations of nodes and edges of a knowledge graph. They are widely used in graph completion, knowledge discovery, entity resolution, and link-based clustering [19].\nDespite achieving excellent trade-off between predictive power and scalability, these neural architectures suffer from poor human interpretability, to the detriment of user trust, troubleshooting, and compliance.\nPrevious work in knowledge graph representation learning aims at designing natively interpretable KGE models or generating post-hoc explanations for existing knowledge graph embedding models. Nevertheless, the field is still in its infancy and recently proposed explanation methods do not scale beyond toy datasets or do not provide thorough empirical evidence of being faithful to the KGE model being explained.\nIn this work, we propose KGEx, a post-hoc, local explanation sub-system for KGE models (Figure 1). KGEx works with any existing KGE model proposed in literature: given a target triple predicted with a KGE model, we return an explanation in the form of a ranked list of relevant triples from the training set. We use a combination of subgraph sampling and knowledge distillation that we refine with Monte Carlo sampling. Our experiments show that KGEx provides faithful explanations that can be used beyond toy knowledge graphs.\nPreprint. Preliminary work.\nar X\niv :2\n31 0.\n01 06\n5v 1\n[ cs\n.A I]\n2 O\nct 2\n02 3"
        },
        {
            "heading": "2 Related Work",
            "text": "Knowledge Graph Embeddings. Knowledge graph embedding models (KGE) are neural architectures designed to predict missing links between entities. TransE [5] is the forerunner of distance-based KGE models, and inspired a number of models commonly referred to as TransX. The symmetric bilinear-diagonal model DistMult [25] paved the way for its asymmetric evolutions in the complex space, ComplEx [24] and RotatE [22]. Some models such as RESCAL [18], TuckER [3], and SimplE [12] rely on different tensor decomposition techniques. Models such as ConvE [7] or ConvKB [17] leverage convolutional layers. Attention is used by [16]. The recent NodePiece uses an anchor-based approach to map entities and relations to a fixed-sized, memory-efficient vocabulary [8]. Recent surveys provide a good coverage of the landscape [4].\nExplanations for KGEs. Recent studies address the problem of making KGE architectures more interpretable. MINERVA [6], NeuralLP [26], CTPs [14] integrate rule-based systems to deliver natively interpretable link prediction methods. Although promising, these works do not scale beyond toy datasets. Other works consist instead of post-hoc approaches (they operate on black-box, pretrained KGE models) and are local methods, i.e. they explain the prediction of a single instance (i.e. a single missing link between two entities). Gradient Rollback [13] returns a ranked list of influential triples for a target prediction. Such list is computed by storing gradient updates during training, to the detriment of memory footprint and training time overhead. OXKBC creates post-hoc explanations by leveraging entity and path similarities that are selected as template by an end-to-end method [15]. Earlier work identifies training triples that, when removed, decrease the predicted probability score. ExplainE is grounded on counterfactual explanations and operates on toy knowledge graphs and low-dimensional embeddings [11]. [27] instead randomly perturbs the neighborhood of the target triple, but its design rationale is geared towards adversarial attacks rather than explainability."
        },
        {
            "heading": "3 Preliminaries",
            "text": "Knowledge Graph. A knowledge graph G = {(s, p, o)} \u2286 E\u00d7R\u00d7E is a set of triples t = (s, p, o) each including a subject s \u2208 E , a predicate p \u2208 R, and an object o \u2208 E . E andR are the sets of all entities and relation types of G.\nKnowledge Graph Embedding Models. KGE encode both entities E and relations R into lowdimensional, continuous vectors \u2208 Rk (i.e, the embeddings). Embeddings are learned by training a neural architecture over a training knowledge graph G: an input layer feeds training triples, and a scoring layer f(t) assigns plausibility scores to each triple. f(t) is designed to assign high scores to positive triples and low scores to negative corruptions. Corruptions are synthetic negative\ntriples generated by a corruption generation layer: we define a corruption of t as t\u2212 = (s, p, o\u2032) or t\u2212 = (s\u2032, p, o) where s\u2032, o\u2032 are respectively subject or object corruptions, i.e. other entities randomly selected from E [5]. Finally, a loss layer LKGE optimizes the embeddings by learning optimal embeddings, such that at inference time the scoring function f(t) assigns high scores to triples likely to be correct and low scores to triples unlikely to be true.\nLink Prediction. The task of predicting unseen triples in knowledge graphs is formalized in literature as a learning to rank problem, where the objective is learning a scoring function f(t = (s, p, o)) : E \u00d7 R \u00d7 E \u2192 R that given an input triple t = (s, p, o) assigns a score f(t) \u2208 R proportional to the likelihood that the fact t is true. Such predictions are ranked against predictions from synthetic corruptions, to gauge how well the model tells positives from negatives.\nKnowledge Distillation (KD). This method has been introduced to alleviate computational costs and allow knowledge to be transferred from large, complex models (teacher) to smaller, compact ones (student) [9]. Let X be the input data distribution, with xi \u223c X distinct samples drawn from that distribution. For brevity, we denote teacher and student representations as gT,i = gT (xi) and gS,i = gS(xi), respectively. Conventional KD can take up the the form of Eq. 1:\nLKD = \u2211 xi\u223cX l(gT,i,gS,i), (1)\nwhere l is a loss function such as the Kullback-Leibler divergence, which tries to match the representations of teacher and student for an individual sample xi.\nRelational KD\u2019s (RKD) [20] purpose is to transfer the relationship between individual samples from the teacher to the student, as described in Eq. 2:\nLRKD = \u2211\n(xi,...,xn)\u223cX\nl\u03b4(\u03d5(gT,i, ...,gT,n), \u03d5(gS,i, ...,gS,n)), (2)\nwhere \u03d5 is a relational potential function and l\u03b4 is the Huber loss, which is defined in Eq. 3:\nl\u03b4(a, b) =\n{ 1 2 (a\u2212 b)\n2 for | a\u2212 b |\u2264 1, | a\u2212 b | \u2212 12 , otherwise.\n(3)\nA particular case of relational potential function is the angle-wise relational potential \u03d5A, which can be applied on a triple of samples and is defined as in Eq. 4:\n\u03d5A(gT,i,gT,j ,gT,k) = \u27e8dij ,djk\u27e9, (4)\nwhere dij = gT,i\u2212gT,j \u2225gT,i\u2212gT,j\u22252 , djk = gT,j\u2212gT,k \u2225gT,j\u2212gT,k\u22252 and \u27e8\u00b7,\u00b7\u27e9 is the dot product."
        },
        {
            "heading": "4 Methods",
            "text": "Given a pre-trained black-box KGE model and the prediction for an unseen target triple, we generate an explanation for such prediction in the form of a list of training triples ranked by their \u2018influence\u2019 on the prediction. Such explanation is generated by KGEx, our proposed explanation subsystem, which consists of three components. The first step samples a subgraphH from the original knowledge graph G in order to limit the search space for possible explanations (section 4.1). To increase the faithfulness of the surrogate model, in the second step we utilize KD to train a new KGE model on the subgraph, while the black-box KGE model we are explaining plays the role of the teacher (section 4.2). Finally, we repeat the second step through a Monte Carlo (MC) process. This is done to rank the triples in the subgraph according to their contribution to the prediction (section 4.3)."
        },
        {
            "heading": "4.1 Subgraph sampling",
            "text": "Our motivation stems from the explainable AI subfield of surrogate models [1]. Concretely, the idea behind surrogate models is to convert a \u201cblack-box\u201d model gT into a more interpretable \u201cwhite-model\u201d gS . The main challenge when trying to design a surrogate model for a KGE model is that KGEs are transductive models and therefore have no inference capabilities, i.e. given a triple t that contains an\n- unseen during training - entity, there is no function gT , so that we can infer an output y = gT (t). Given this limitation we cannot replace gT with an interpretable gS , directly. However, we can find a subgraph that will allow us to train such a surrogate model.\nWe formulate this task as finding the smallest subgraphH \u2282 G, which if used to train a KGE model gS will give a latent space representation to the target triple that is as close as possible to the one assigned by the black-box KGE model gT , which was trained on the whole knowledge graph G. While searching forH, we are facing a trade-off that has to do with the subgraph size: a larger size promotes fidelity (i.e. faithfulness to the original model), while a smaller size reduces cognitive load and therefore favors interpretability.\nThe search for the subgraphH of particular target triple t\u2217 = (s\u2217, p\u2217, o\u2217) can be broken down to two parts. The first part involves retaining the 1-hop neighborhood NG(s\u2217, o\u2217) of the subject s\u2217 and the object o\u2217 of t\u2217. Using the case depicted in Fig. 1, NG(Guy Ritchie, Film Director) would include all triples involving either Guy Ritchie or Film Director. These are the triples that are in the vicinity of the entities of the target triple and therefore will likely play an important role in the representation that the KGE will learn for these entities. As such, the fact that (Guy Ritchie, director, Sherlock Holmes) is important in explaining (Guy Ritchie, profession, Film Director). If we were to retain only this 1-hop neighborhood, we would not be able to incorporate information on any long-range (in terms of hops in the graph) information that might be pivotal for the latent representation of the target triple. Additionally, the 1-hop neighborhood of the subject and the object does not take explicitly into account the predicate p\u2217 of t\u2217, which could lead to not learning a meaningful representation for p\u2217. In the running example, the fact (Madonna, profession, Film Producer) might seem irrelevant at first sight and would not be part of NG(Guy Ritchie, Film Director). However, combined with the fact that (Guy Ritchie, married, Madonna) could again lead to the target triple being predicted as positive. In the second part, to alleviate the issues above, we propose two alternatives:\n\u2022 Random Walk (RW) Sampling Apart from the 1-hop neighborhood, we also add a naive random walk of predefined size measured in numbers of steps, which starts from the target triple (see Algorithm 2 in Appendix A).\n\u2022 Predicate Neighborhood (PN) Sampling To ensure that the predicate p\u2217 of t\u2217 is part of the subgraph we randomly sample from G a predefined number n of triples t\u2217 = (s\u0302, p\u2217, o\u0302), which have the same predicate p\u2217, and include these along with their own 1-hop neighborhoods NG(s\u0302, o\u0302) in the subgraph (Algorithm 1). In our example, that would entail sampling triples that involved the predicate profession."
        },
        {
            "heading": "4.2 Knowledge Distillation",
            "text": "After sampling the subgraph, we train a KGE model gS on that. We need to ensure that this model is a faithful surrogate to the black-box model whose predictions we are trying to explain, through some sort of constraint. For this reason, we propose the use of KD as a way to allow the original model to drive the learning process of the surrogate model. Thus, in KD terms, the black-box model plays the role of the teacher, while the surrogate model that of the student, with functions gT and gS , respectively. The relational aspect of RKD makes it a natural fit for KGEs. Nevertheless, it is important to note that RKD is applied on individual samples. In mini-batch training, for instance, it will be applied on every possible combination of the samples that constitute the mini-batch. In KGEs,\nAlgorithm 1 Subgraph sampling w/ Predicate Neighborhood 1: Input: target triple (s\u2217, p\u2217, o\u2217), number of predicate neighbors n 2: Output: SubgraphH 3: H \u2190 \u2205 4: NG(s\u2217) = {(s, p, o) \u2208 G|s = s\u2217 \u2228 o = s\u2217} 5: NG(o\u2217) = {(s, p, o) \u2208 G|s = o\u2217 \u2228 o = o\u2217} 6: NG(s\u2217, o\u2217) = NG(s\u2217) \u222aNG(o\u2217) \u25b7 1-hop neighborhood of s\u2217, o\u2217 7: H = H \u222aNG(s\u2217, o\u2217) 8: PG(p\u2217) = {(s, p, o) \u2208 G|p = p\u2217} \u25b7 Triples involving p\u2217 9: for i\u2190 0 to n\u2212 1 do 10: Sample a triple (s\u0302, p\u2217, o\u0302) \u223c PG(p\u2217) 11: Get the 1-hop neighborhood NG(s\u0302, o\u0302) 12: H = H \u222aNG(s\u0302, o\u0302)\nhowever, the relational aspect between the embeddings is inherent. Given that the training samples are in the form of triples (s, p, o) \u2208 G, the KGE loss is already affecting their embeddings (s,p,o) in a relational manner. To accommodate the training of the KGE we adapt the RKD loss, so that it is applied only among the entities and the relation of a particular triple at a time, instead of randomly selected samples. We term this adaptation LRKD\u2212KGE and it takes the following form (Eq. 5):\nLRKD\u2212KGE = \u2211\n(s,p,o)\u2208G\nl\u03b4(\u03d5A(sT ,pT ,oT ), \u03d5A(sS ,pS ,oS))\n+ l\u03b4(\u03d5A(pT ,oT , sT ), \u03d5A(pS ,oS , sS))\n+ l\u03b4(\u03d5A(oT , sT ,pT ), \u03d5A(oS , sS ,pS)) (5)\nThe overall loss of the architecture can then be defined as in Eq. 6, with the RKD-KGE part acting as a regularization on the exact embeddings that the KGE part is affecting:\nL = LKGE + \u03bbLRKD\u2212KGE (6)\nIt is important to remind here that the teacher model is pre-trained and its weights are not updated. Instead the teacher representations are only utilized to aid the training of the student. An overview of the student\u2019s training procedure can be found in Fig. 2."
        },
        {
            "heading": "4.3 Monte Carlo process",
            "text": "The explanation produced by KGEx is a list of the triples included in the subgraph, ranked by their contribution to the prediction of the target triple. To generate this list, for each target triple that we want to explain and given a pre-trained KGE model (teacher), we train multiple KGE models (students) with the loss defined in Eq. 6. Each of the students is trained on a subsetHmc \u2282 H and assigns a rank to the target triple. The contribution of each triple t = (s, p, o) \u223c H is analogous to the average rank that was assigned to the target triple on the runs that t was part ofHmc."
        },
        {
            "heading": "5 Experiments",
            "text": "We assess the faithfulness of the explanations returned by KGEx. Experiments show that KGEx surrogates are faithful to the original black-box models being explained.\nDatasets. We experiment with the two standard link prediction benchmark datasets, WN18RR [7] (a subset of Wordnet) and FB15K-237 [23] (a subset of Freebase). We operate with reduced test sets that include 100 triples only. This is to guarantee a reasonable execution time of our experiments, most of which require to retrain a model multiple times as part of the Monte Carlo step, for each triple that we want to explain. We work with two separate test sets: first, to control for the black-box model predictive power, we define T1, that includes 100 test triples that have been ranked at the first place by all the black-box models used in our experiments (see \u2018Evaluation Protocol\u2019 below). Additionally,\nin some experiments we use another test set, Trand, which includes 100 randomly-selected triples, regardless of the assigned rank by the black-box KGE model. Table 1 shows the statistics of all the datasets used.\nEvaluation protocol. We measure the faithfulness of explanations generated by KGEx in terms of predictive power discrepancy between black box predictions and predictions generated with KGEx surrogates. We adopt the standard evaluation protocol described by [5]. We predict whether each triple t = (s, p, o) \u2208 T is true, where T is either T1 or Trand. We cast the problem as a learning-torank task: for each t = (s, p, o) \u2208 T , we generate synthetic negatives t\u2212 \u2208 Nt by corrupting one side of the triple at a time (i.e. either the subject or the object). In the standard evaluation protocol, synthetic negatives Nt are generated from all entities in E . In our experiments, to guarantee a fair comparison between the black-box and the surrogate model, we limit to synthetic negatives created from entities included in the corresponding sampled subgraphH. We predict a score for each t and all its negatives t\u2212 \u2208 Nt. We then rank the only positive t against all the negatives Nt. We report mean rank (MR), mean reciprocal rank (MRR), and Hits at n (where n = 1, 10) by filtering out spurious ground truth positives from the list of generated corruptions (i.e. \u201cfiltered\u201d metrics).\nImplementation Details and Baselines. The KGEx explanation subsystem and the black-box KGE models are implemented using TensorFlow 2.5.2 and Python 3.81. KGE hyperparameter ranges and best combinations are reported in Appendix B. Regarding the KGEx specific hyperparameters, we use Predicate Neighborhood (PN) sampling with 5 neighbors for FB15K-237 and 3 neighbors for WN18RR (see section 5.2), KD coefficient \u03bb = 3 (see section 5.3). Student models have embedding dimensionality k = 50, synthetic negatives ratio \u03b7 = 2 and are trained using the Adam optimizer and a multiclass-NLL baseline loss with learning rate=0.1 for 200 epochs. Depending on the size of the subgraph, an explanation might require from 50 to 200 MC runs. All experiments were run under Ubuntu 16.04 on an Intel Xeon E5-2630, 32 GB, equipped with a Titan XP 12GB."
        },
        {
            "heading": "5.1 Faithfulness: KGE Architectures",
            "text": "The first experiment tests how faithful the KGEx surrogates are to the pre-trained black-box models in terms of predictive performance. We conduct this experiment by leveraging both the T1 test set (which is produced from the ranks of each black-box that we are explaining) and the Trand test set. The results for T1 are shown on Table 2. Naturally, all black-box models have perfect metrics, by definition. By inspecting the performance of the surrogate models, we can see that they retain a respectable level in MRR of around 0.5 (depending on the black-box) for FB15K-237. It is quite interesting to note that the TransE surrogate is the one which manages to achieve the minimum drop in performance from its black-box, across all reported metrics. Turning to WN18RR, we can see even stronger results from the surrogates, and especially from DistMult and ComplEx. DistMult in particular replicates its black-box\u2019s almost perfect performance.\nThe same experiment is conducted on Trand test set and the results are reported on Table 3. TransE again gets the best results for FB15K-237 with 53% drop in MRR from its black-box, but given the added difficulty of the task, DistMult and ComplEx still manage to get a comparable Hits@10. For WN18RR, similar to T1, DistMult and ComplEx retain quite high scores across all the metrics. While TransE is a bit lower compared to the other architectures, we can see that compared to its own black-box, it actually manages to stay on a very competitive level in terms of MRR and Hits@10. We have to mention here that the MRR of the TransE black-box in this case is 35-40% lower than DistMult or ComplEx, which is confirmed by similar numbers reported in recent literature. The\n1We will release code and experiments upon acceptance.\nreason for that is most likely related to the small amount of relations in WN18RR, which might not be properly captured by TransE\u2019s architecture. As a result, this affects the TransE surrogate both in T1 and Trand and therefore is not an issue of the KGEx component but rather the black-box\u2019s."
        },
        {
            "heading": "5.2 Impact of Subgraph Sampling",
            "text": "We evaluate predicate neighborhood (PN) and random walk (RW) sampling. Both methods contain the 1-hop neighborhood of the subject and the object of the target triple. For PN sampling, we conduct experiments with 3, 5 and 10 predicate neighbors for both datasets. For RW sampling, we use 10, 50 and 100 steps for FB15K-237 and 100, 200 and 500 steps for WN18RR. Table 4 shows complete results.\nAcross both datasets PN sampling yields much better results than RW sampling. An interesting finding, is that regardless of method increasing the subgraph size either with more neighbors for PN sampling or with more steps in RW sampling, performance is actually decreasing. This shows that\nwe do not need a very large subgraph to calculate effective embeddings for the target triple, and that including facts likely to be not relevant in the subgraph hurts performance."
        },
        {
            "heading": "5.3 Knowledge Distillation Effect",
            "text": "We assess the effect of knowledge distillation on the KGEx pipeline. As defined in Eq. 6, the KD component acts as regularization in the training process of the student. Its contribution is regulated by the KD coefficient \u03bb and, as we see in Fig. 3, performance across models remains fairly stable across different \u03bb. We chose \u03bb = 3 across experiments, as it consistently gives marginally better results across all models.\nFinally, we look at the enhancement in performance that KD offers in Table 5. It is evident that when KD is used, it improves results across all backbone models, compared to standalone students (i.e. models trained on the subgraph without KD). In detail, ComplEx and DistMult outperform their standalone counterparts across all metrics for both datasets with increase in MRR in the 6-13 % region. The outlier in our observations comes from TransE on WN18RR, which is the only case where the standalone model outperforms the KD-based one (MRR=0.38 against MRR=0.24 on T1). This is not a limitation of KGEx though, but rather something that highlights it is indeed working as intended. Given the characteristics of WN18RR (small number of relations), it looks like a smaller subgraph\nactually favors KGEs, as the standalone model, even though of smaller capacity, outperforms the model trained on the full KG. However, the KD student remains bounded by the knowledge that was distilled by its teacher and therefore remains faithful to the teacher, which is what is desirable. On the other hand, the standalone model leverages to a great extent the favorable topology of the subgraph, but because there is no connection to the teacher through the loss function, it fails completely to capture any of the teacher\u2019s representation abilities, which is what we would expect."
        },
        {
            "heading": "5.4 Example Explanations",
            "text": "We also provide some example explanations in Table 6. These were generated by KGEx for target triples from FB15K-237. Something that can be observed is KGEx\u2019s ability to include triples in the explanation that are beyond the 1-hop neighborhood of the subject and the object of the target triple. Such an example is the explanation triple (Julianne Moore, film, Far from heaven), which explains the target triple (Walk of fame, inductee, Meryl Streep) because Meryl Streep and Julianne Moore have collaborated in movies. When explaining the target triple (Priyanka Chopra, ethnicity, Punjabis), we see that the explanation contains relevant information and not facts about the subject\u2019s professional life as in the previous example. Finally, in other cases, when the context can be really specific, such as the symptoms example, we see that all the explanation triples are sourced based on the predicate. Even in that case though, although jaundice can be a symptom of various diseases, the ones chosen in the explanation (i.e. pancreatic cancer and malaria) are both correlated with hepatitis."
        },
        {
            "heading": "6 Conclusion",
            "text": "KGEx generates post-hoc, local explanations in the form of a ranked list of triples. We show that the interplay of graph sampling and knowledge distillation reduces the explanation search space while guaranteeing faithfulness to the black-box KGE model being explained. Deploying a Monte Carlo process to rank the explanation triples based on their influence on the prediction prioritizes important and relevant facts.\nMoving forward, we will leverage the modular nature of the framework and propose replacement modules, such as a search-based approach instead of the MC process, to reduce computational burden. Future work will also focus on user studies to gauge the perceived quality of KGEx explanations, by measuring how much they assist human experts on the receiving side of KGE predictions."
        },
        {
            "heading": "A Subgraph sampling with random walk",
            "text": "Algorithm 2 Subgraph sampling w/ Random Walk 1: Input: target triple (s\u2217, p\u2217, o\u2217), number of random walk steps n 2: Output: SubgraphH 3: H \u2190 \u2205 4: NG(s\u2217) = {(s, p, o) \u2208 G|s = s\u2217 \u2228 o = s\u2217} 5: NG(o\u2217) = {(s, p, o) \u2208 G|s = o\u2217 \u2228 o = o\u2217} 6: NG(s\u2217, o\u2217) = NG(s\u2217) \u222aNG(o\u2217) \u25b7 1-hop neighborhood of s\u2217, o\u2217 7: H = H \u222aNG(s\u2217, o\u2217) 8: (so, po, oo) = (s\u2217, p\u2217, o\u2217) \u25b7 Initialize random walk origin 9: for i\u2190 0 to n\u2212 1 do 10: Sample a triple (s\u0302, p\u0302, o\u0302) \u223c NG(so, oo) 11: H = H \u222a {(s\u0302, p\u0302, o\u0302)}) 12: (so, po, oo) = (s\u0302, p\u0302, o\u0302) \u25b7 Update origin"
        },
        {
            "heading": "B Hyperparameter search",
            "text": "We experiment with three popular KGE architectures: TransE, DistMult, ComplEx. For each of them we replicated SOTA results by carrying out extensive grid search, over the following ranges of hyperparameter values: embedding dimensionality k = [200 \u2212 500], with a step of 50; baseline losses={negative log-likelihood, multiclass-NLL, self-adversarial}; synthetic negatives ratio \u03b7 = {20, 30, 40, 50}; learning rate= {1e\u22124, 5e\u22125, 1e\u22125}; epochs= [500 \u2212 2000], step of 500; L2 regularizer, with weight \u03b3 = {1e\u22123, 1e\u22124, 1e\u22125}. The best loss for all models was the multiclass-NLL and the best regularization weight \u03b3 = 1e\u22124. The best combinations for the rest of the hyperparameters are shown on Table 7"
        }
    ],
    "title": "KGEx: Explaining Knowledge Graph Embeddings via Subgraph Sampling and Knowledge Distillation",
    "year": 2023
}