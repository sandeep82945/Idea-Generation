{
    "abstractText": "We propose a decoder for the correction of erasures with hypergraph product codes, which form one of the most popular families of quantum LDPC codes. Our numerical simulations show that this decoder provides a close approximation of the maximum likelihood decoder that can be implemented in O(N) bit operations where N is the length of the quantum code. A probabilistic version of this decoder can be implemented in O(N) bit operations.",
    "authors": [
        {
            "affiliations": [],
            "name": "Nicholas Connolly"
        },
        {
            "affiliations": [],
            "name": "Vivien Londe"
        },
        {
            "affiliations": [],
            "name": "Anthony Leverrier"
        },
        {
            "affiliations": [],
            "name": "Nicolas Delfosse"
        }
    ],
    "id": "SP:bf71abaa0b8eee9969f01ea8ffdfbd6de5609c2f",
    "references": [
        {
            "authors": [
                "E. Dennis",
                "A. Kitaev",
                "A. Landahl",
                "J. Preskill"
            ],
            "title": "Journal of Mathematical Physics 43",
            "venue": "4452 ",
            "year": 2002
        },
        {
            "authors": [
                "A.G. Fowler",
                "M. Mariantoni",
                "J.M. Martinis",
                "A.N. Cleland"
            ],
            "title": "Physical Review A 86",
            "venue": "032324 ",
            "year": 2012
        },
        {
            "authors": [
                "R. Gallager"
            ],
            "title": "IRE Transactions on Information Theory 8",
            "venue": "21 ",
            "year": 1962
        },
        {
            "authors": [
                "D.J. MacKay",
                "G. Mitchison",
                "P.L. McFadden"
            ],
            "title": "IEEE Transactions on Information Theory 50",
            "venue": "2315 ",
            "year": 2004
        },
        {
            "authors": [
                "J.-P. Tillich",
                "G. Z\u00e9mor"
            ],
            "title": "IEEE Transactions on Information Theory 60",
            "venue": "1193 ",
            "year": 2013
        },
        {
            "authors": [
                "D. Gottesman"
            ],
            "title": "Quantum Information & Computation 14",
            "venue": "1338 ",
            "year": 2014
        },
        {
            "authors": [
                "O. Fawzi",
                "A. Grospellier"
            ],
            "title": "and A",
            "venue": "Leverrier, in 2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS) ",
            "year": 2018
        },
        {
            "authors": [
                "M.A. Tremblay",
                "N. Delfosse"
            ],
            "title": "and M",
            "venue": "E. Beverland, arXiv preprint arXiv:2109.14609 ",
            "year": 2021
        },
        {
            "authors": [
                "E. Knill",
                "R. Laflamme",
                "G.J. Milburn"
            ],
            "title": "nature 409",
            "venue": "46 ",
            "year": 2001
        },
        {
            "authors": [
                "S. Bartolucci",
                "P. Birchall",
                "H. Bombin",
                "H. Cable",
                "C. Dawson",
                "M. Gimeno-Segovia",
                "E. Johnston",
                "K. Kieling",
                "N. Nickerson"
            ],
            "title": "M",
            "venue": "Pant, et al., arXiv preprint arXiv:2101.09310 ",
            "year": 2021
        },
        {
            "authors": [
                "Y. Wu",
                "S. Kolkowitz",
                "S. Puri"
            ],
            "title": "and J",
            "venue": "D. Thompson, arXiv preprint arXiv:2201.03540 ",
            "year": 2022
        },
        {
            "authors": [
                "S. Kudekar",
                "T. Richardson",
                "R.L. Urbanke"
            ],
            "title": "IEEE Transactions on Information Theory 59",
            "venue": "7761 ",
            "year": 2013
        },
        {
            "authors": [
                "M.G. Luby",
                "M. Mitzenmacher",
                "M.A. Shokrollahi",
                "D.A. Spielman"
            ],
            "title": "IEEE Transactions on Information Theory 47",
            "venue": "569 ",
            "year": 2001
        },
        {
            "authors": [
                "V.V. Zyablov",
                "M.S. Pinsker"
            ],
            "title": "Problemy Peredachi Informatsii 10",
            "venue": "15 ",
            "year": 1974
        },
        {
            "authors": [
                "N. Delfosse",
                "G. Z\u00e9mor"
            ],
            "title": "Physical Review Research 2",
            "venue": "033042 ",
            "year": 2020
        },
        {
            "authors": [
                "S. Lee",
                "M. Mhalla"
            ],
            "title": "and V",
            "venue": "Savin, in 2020 IEEE International Symposium on Information Theory (ISIT) ",
            "year": 2020
        },
        {
            "authors": [
                "A. Steane"
            ],
            "title": "Proceedings of the Royal Society of London",
            "venue": "Series A: Mathematical, Physical and Engineering Sciences 452, 2551 ",
            "year": 1996
        },
        {
            "authors": [
                "A.R. Calderbank",
                "P.W. Shor"
            ],
            "title": "Physical Review A 54",
            "venue": "1098 ",
            "year": 1996
        },
        {
            "authors": [
                "M. Grassl",
                "T. Beth",
                "T. Pellizzari"
            ],
            "title": "Physical Review A 56",
            "venue": "33 ",
            "year": 1997
        },
        {
            "authors": [
                "T.J. Richardson",
                "R.L. Urbanke"
            ],
            "title": "IEEE Transactions on Information Theory 47",
            "venue": "638 ",
            "year": 2001
        },
        {
            "authors": [
                "X.-Y. Hu",
                "E. Eleftheriou",
                "D.-M. Arnold"
            ],
            "title": "in GLOBE- COM\u201901",
            "venue": "IEEE Global Telecommunications Conference (Cat. No.01CH37270), Vol. 2 ",
            "year": 2001
        },
        {
            "authors": [
                "X.-Y. Hu",
                "E. Eleftheriou",
                "D. Arnold"
            ],
            "title": "IEEE Transactions on Information Theory 51",
            "venue": "386 ",
            "year": 2005
        },
        {
            "authors": [
                "T.S. Manu"
            ],
            "title": "Progressive edge growth algorithm for generating LDPC matrices",
            "year": 2014
        },
        {
            "authors": [
                "N. Connolly"
            ],
            "title": "Pruned peeling and vh decoder (2022)",
            "year": 2022
        },
        {
            "authors": [
                "D. Wiedemann"
            ],
            "title": "IEEE Transactions on Information Theory 32",
            "venue": "54 ",
            "year": 1986
        },
        {
            "authors": [
                "E. Kaltofen",
                "B. David Saunders"
            ],
            "title": "in International Symposium on Applied Algebra",
            "venue": "Algebraic Algorithms, and Error-Correcting Codes ",
            "year": 1991
        },
        {
            "authors": [
                "E. Kaltofen"
            ],
            "title": "Mathematics of Computation 64",
            "venue": "777 ",
            "year": 1995
        },
        {
            "authors": [
                "A.A. Kovalev",
                "L.P. Pryadko"
            ],
            "title": "Physical Review A 87",
            "venue": "020304 ",
            "year": 2013
        },
        {
            "authors": [
                "N. Delfosse",
                "V. Londe"
            ],
            "title": "and M",
            "venue": "E. Beverland, IEEE Transactions on Information Theory ",
            "year": 2022
        },
        {
            "authors": [
                "N.P. Breuckmann",
                "J.N. Eberhardt"
            ],
            "title": "IEEE Transactions on Information Theory 67",
            "venue": "6653 ",
            "year": 2021
        },
        {
            "authors": [
                "I. Dinur",
                "M.-H. Hsieh",
                "T.-C. Lin"
            ],
            "title": "and T",
            "venue": "Vidick, arXiv preprint arXiv:2206.07750 ",
            "year": 2022
        },
        {
            "authors": [
                "M. Kang",
                "W.C. Campbell"
            ],
            "title": "and K",
            "venue": "R. Brown, arXiv preprint arXiv:2210.15024 ",
            "year": 2022
        },
        {
            "authors": [
                "A. Kubica",
                "A. Haim",
                "Y. Vaknin",
                "F. Brand\u00e3o"
            ],
            "title": "and A",
            "venue": "Retzker, arXiv preprint arXiv:2208.05461 ",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Fast erasure decoder for a class of quantum LDPC codes\nNicholas Connolly,1 Vivien Londe,2 Anthony Leverrier,1 and Nicolas Delfosse3 1Inria, Paris, France\n2Microsoft, Paris, France 3Microsoft Quantum, Redmond, Washington 98052, USA\n(Dated: March 8, 2023)\nWe propose a decoder for the correction of erasures with hypergraph product codes, which form one of the most popular families of quantum LDPC codes. Our numerical simulations show that this decoder provides a close approximation of the maximum likelihood decoder that can be implemented in O(N2) bit operations where N is the length of the quantum code. A probabilistic version of this decoder can be implemented in O(N1.5) bit operations.\nIntroduction \u2013 Due to the high noise rate of quantum hardware, extensive quantum error correction is necessary to scale quantum devices to the regime of practical applications. The surface code [1, 2] is one of the most popular quantum error correction code for quantum computing architectures but it comes with an enormous qubit overhead because each qubit must be encoded into hundreds or thousands of physical qubits.\nQuantum Low-Density Parity-Check (LDPC) codes [3, 4] such as hypergraph product (HGP) codes [5] promise a significant reduction of this qubit overhead [6, 7]. Numerical simulations with circuit noise show a 15\u00d7 reduction of the qubit count in the large-scale regime [8]. For applications to quantum fault toleance, HGP codes must come with a fast decoder, whose role is to identify which error occurred. In this work, we propose a fast decoder for the correction of erasures or qubit loss. Our numerical simulations show that our decoder achieves a logical error rate close to the maximum likelihood decoder.\nOur motivation for focusing on the decoding of erasures is twofold. First it is practically relevant and it is the dominant source of noise in some quantum platforms such as photonic systems [9, 10] for which a photon loss can be interpreted as an erasure, or neutral atoms [11]. Second, many of the ideas that led to the design of capacityachieving classical LDPC codes over binary symmetric channels were first discovered by studying the correction of erasures [12, 13]. Classical erasure decoders \u2013 A linear code with length n is defined to be the kernel C = kerH of an r\u00d7n binary matrix H called the parity-check matrix. Our goal is to protect a codeword x \u2208 C against erasures. We assume that each bit is erased independently with probability p and erased bits are flipped independently with probability 1/2. The set of erased positions is known and is given by an erasure vector \u03b5 \u2208 Zn2 such that bit bi is erased iff \u03b5i = 1. The initial codeword x is mapped onto a vector y = x + e \u2208 Zn2 where e is the indicator vector of the flipped bits of x. In particular the support of e satisfies supp(e) \u2286 supp(\u03b5). To detect e, we compute the syndrome s = Hy = He \u2208 Zr2. A non-trivial syndrome indicates the presence of bit-flips.\nThe goal of the decoder is to provide an estimation e\u0302 of e given s and \u03b5 and it succeeds if e\u0302 = e. This can be done by solving the linear system He\u0302 = s with the condition supp(e\u0302) \u2286 supp(\u03b5) thanks to Gaussian elimination. This Gaussian decoder runs in O(n3) bit operations which may be too slow in practice for large n.\nAlgorithm 1: Classical peeling decoder input : An erasure vector \u03b5 \u2208 ZN2 and a syndrome s \u2208 Zr2. output: Either failure or e\u0302 \u2208 Zn2 such that He\u0302 = s\nand supp(e\u0302) \u2286 supp(\u03b5). 1 Set e\u0302 = 0. 2 while there exists a dangling check do 3 Select a dangling check ci. 4 Let bj be the dangling bit incident to ci. 5 if si = 1 then 6 Flip bit j of e\u0302. 7 Flip sk for all checks ck incident with bj ."
        },
        {
            "heading": "8 Set \u03b5j = 0.",
            "text": "9 if \u03b5 6= 0 return Failure, else return e\u0302.\nThe classical peeling decoder [14], described in Algorithm 1, provides a fast alternative to the Gaussian decoder. It does not perform as well in general, but it can be implemented in linear time and displays good performance for LDPC codes. To describe this decoder, it is convenient to introduce the Tanner graph, denoted T (H), of the linear code C = kerH. It is the bipartite graph with one vertex c1, . . . , cr for each row of H and one vertex b1, . . . , bn for each column of H such that ci and bj are connected iff Hi,j = 1. We refer to ci as a check node and bj as a bit node. The codewords of C are the bit strings such that the sum of the neighboring bits of a check node is 0 mod 2. Given an erasure vector \u03b5, a check node is said to be a dangling check if it is incident to a single erased bit. We refer to this erased bit as a dangling bit. The basic idea of the peeling decoder is to use dangling checks to recover the values of dangling bits and to repeat until the erasure is fully corrected.\nThe notion of stopping set was introduced in [15] to bound the failure probability of the decoder for classical\nar X\niv :2\n20 8.\n01 00\n2v 2\n[ qu\nan t-\nph ]\n7 M\nar 2\n02 3\n2 LDPC codes. A stopping set for the Tanner graph T (H) is defined to be a subset of bits that contains no dangling bit. If the erasure covers a non-empty stopping set, then Algorithm 1 returns Failure.\nThe peeling decoder was adapted to surface code [16] and color codes [17]. In the rest of this paper, we design a fast erasure decoder inspired by the peeling decoder that applies to a broad class of quantum LDPC codes. Our design process relies on the analysis of stopping sets. At each design iteration, we propose a new version of the decoder, identify its most common stopping sets and modify the decoder to make it capable of correcting these dominant stopping sets. Classical peeling decoder for quantum CSS codes \u2013 A CSS code [18, 19] with length N is defined by commuting N -qubit Pauli operators SX,1, . . . , SX,RX \u2208 {I,X}\u2297N and SZ,1, . . . , SZ,RZ \u2208 {I, Z}\u2297N called the stabilizer generators. We refer to the group they generate as the stabilizer group and its elements are called stabilizers.\nWe can correct X and Z errors independently with the same strategy. Therefore we focus on the correction of X errors, based on the measurement of the Z-type stabilizer generators. This produces a syndrome \u03c3(E) \u2208 ZRZ2 , whose ith component is 1 iff the error E anti-commutes with SZ,i. An error with trivial syndrome is called a logical error and a non-trivial logical error if it is not a stabilizer, up to a phase.\nWe assume that qubits are erased independently with probability p and that an erased qubit suffers from a uniform error I or X [20]. This results in an X-type error E such that supp(E) \u2286 supp(\u03b5). The decoder returns an estimate E\u0302 of E given the erasure vector \u03b5 and the syndrome s of E. It succeeds iff E\u0302E is a stabilizer (up to a phase). The logical error rate of the scheme, denoted Plog(p), is the probability that E\u0302E is a non-trivial logical error.\nBy mapping Pauli operators onto binary strings, one can cast the CSS erasure decoding problem as the decoding problem of a classical code with parity check matrix HZ whose rows correspond to the Z-type stabilizer generators. As a result, one can directly apply the classical Gaussian decoder and the classical peeling decoder to CSS codes. From Lemma 1 of [16], the Gaussian decoder is an optimal decoder, i.e. a Maximum Likelihood (ML) decoder, but its complexity scaling like O(N3) makes it too slow for large codes. The peeling decoder is faster. However, the following lemma proves that, unlike its classical counterpart, it does not perform well for quantum LDPC codes.\nLemma 1 (Stabilizer stopping sets). The support of an X-type stabilizer is a stopping set for the Tanner graph T (HZ).\nProof. This is because an X-type stabilizer commutes with Z-type generators, and therefore its binary representation is a codeword for the classical linear code\nkerHZ .\nAs a consequence, the classical peeling decoder has no threshold for any family of quantum LDPC codes defined by bounded weight stabilizers. Indeed, if each member of the family has at least one X-type stabilizer with weight w, then the logical error rate satisfies Plog(p) \u2265 pw, which is a constant bounded away from zero when N \u2192\u221e.This is in sharp contrast with the classical case for which the probability to encounter a stopping set provably vanishes for carefully designed families of LDPC codes [21]. Pruned peeling decoder \u2013 Since the peeling decoder gets stuck into stopping sets induced by the X-type generators, the idea is to look for such a generator S supported entirely within the erasure and to remove an arbitrary qubit of the support of S from the erasure. We can remove this qubit from the erasure because either the error E or its equivalent error ES (also supported inside \u03b5) acts trivially on this qubit.\nAlgorithm 2: Pruned peeling decoder input : An erasure vector \u03b5 \u2208 ZN2 , a syndrome s \u2208 ZRZ2 , and an integer M . output: Either Failure or an X-type error\nE\u0302 \u2208 {I,X}N such that \u03c3(E\u0302) = s and supp(E\u0302) \u2286 supp(\u03b5).\n1 Set E\u0302 = I. 2 while there exists a dangling generator do 3 Select a dangling generator SZ,i. 4 Let j be the dangling qubit incident to SZ,i. 5 if si = 1 then 6 Replace E\u0302 by E\u0302Xj and s by s+ \u03c3(Xj)."
        },
        {
            "heading": "7 Set \u03b5j = 0.",
            "text": ""
        },
        {
            "heading": "8 if There is no dangling generator and there exists a product S of up to M stabilizer generators",
            "text": "SX,1, . . . , SX,RX such that supp(S) \u2286 supp(\u03b5) then\n9 Select a qubit j \u2208 supp(S) and set \u03b5j = 0.\n10 if \u03b5 6= 0 return Failure, else return E\u0302.\nThis leads to the pruned peeling decoder described in Algorithm 2. To make it easier to follow, we use the terms dangling generator and dangling qubit in place of dangling check and dangling bit. A dangling generator is a Z generator in the context of correcting X errors. In order to keep the complexity of the peeling decoder linear, we look for an X-type stabilizer which is a product of up to up M stabilizer generators where M is a small constant. For low erasure rate, we expect the erased stabilizers to have small weight and therefore a small value ofM should be sufficient.\nFig. 1 shows the performance of HGP codes equipped with the pruned peeling decoder with M = 0, 1, 2. The pruning strategy only slightly improves over the classical peeling decoder and increasing M beyond M = 1 does not significantly affect the performance. To understand why the ML decoder severely outperforms the pruned\n3\npeeling decoder, we analyze its most common stopping sets with HGP codes. Stopping sets of the pruned peeling decoder \u2013 Let us recall the hypergraph product construction from [5]. The HGP code associated with the Tanner graph T (H) = (A \u222a B,EH) of a classical code is a CSS code, denoted HGP(H), defined from the cartesian product of T (H) with itself (see Fig. 2). Qubits are labelled by the pairs (a, a\u2032) \u2208 A \u00d7 A and (b, b\u2032) \u2208 B \u00d7 B. For each (a, b\u2032) \u2208 A \u00d7 B, we define a stabilizer generator acting as X on the qubits (b, b\u2032) such that {a, b} \u2208 EH and the qubits (a, a\u2032) such that {a\u2032, b\u2032} \u2208 EH . For each (b, a\u2032) \u2208 B \u00d7 A, we define a stabilizer generator acting as Z on the qubits (a, a\u2032) such that {a, b} \u2208 EH and the qubits (b, b\u2032) such that {a\u2032, b\u2032} \u2208 EH . If the input graph T (H) is sparse, then HGP(H) is LDPC.\nThe input Tanner graph is generated using the standard progressive edge growth algorithm which is commonly used to produce good classical or quantum LDPC codes [22]. We use the implementation [23, 24] of the progressive edge growth algorithm.\nBy studying the failure configurations of the pruned peeling decoder, we observe that the gap between the pruned peeling decoder and the ML decoder is due to the following stopping sets of HGP codes.\nLemma 2 (Horizontal and vertical stopping sets). If SB is a stopping set for a Tanner graph T (H), then for all b \u2208 B the set {b}\u00d7SB is a stopping set for the Tanner graph T (HZ) of the HGP code HGP(H). If SA is a stopping set for a Tanner graph T (HT ), then for all a\u2032 \u2208 A the set SA \u00d7 {a\u2032} is a stopping set for the Tanner graph T (HZ)\nof the HGP code HGP(H).\nProof. Consider a stopping set SB for T (H). Any Z-type stabilizer generator acting on {b} \u00d7 SB must be indexed by (b, a\u2032) for some a\u2032. Moreover, the restriction of these stabilizers to {b}\u00d7SB are checks for the linear code kerH. Therefore is {b} \u00d7 SB is a stopping set for T (HZ). The second case is similar.\nWe refer to the stopping sets {b}\u00d7SB as vertical stopping sets and SA\u00d7{a\u2032} are horizontal stopping sets. Numerically, we observe that these stopping sets are responsible for vast majority of the failures of the pruned peeling decoder. This is because the quantum Tanner graph T (HZ) contains on the order of \u221a N copies of the type\n{b} \u00d7 SB for each stopping sets SB of T (H) and \u221a N copies of each stopping set of T (HT ). Our idea is to use the Gaussian decoders of the classical codes kerH and kerHT to correct these stopping sets. VH decoder \u2013 The Vertical-Horizontal (VH) decoder is based on the decomposition of the erasure into vertical subsets of the form {b} \u00d7 \u03b5b with b \u2208 B and \u03b5b \u2286 B, and horizontal subsets of the form \u03b5a\u2032 \u00d7{a\u2032} with a\u2032 \u2208 A and \u03b5a\u2032 \u2286 A, that will be decoded using the Gaussian decoder.\nLet Tv (resp. Th) be the subgraph of T (HZ) induced by the vertices of B\u00d7(A\u222aB) (resp. (A\u222aB)\u00d7A). The graph Tv is made with the vertical edges of T (HZ) and Th is made with its horizontal edges. Given an erasure vector \u03b5, denote by V (\u03b5) the set of vertices of T (HZ) that are either erased qubits or check nodes incident to an erased qubit. A vertical cluster (resp. horizontal cluster) is a subset of V (\u03b5) that is a connected component for the graph Tv (resp. Th).\n4 The VH graph of \u03b5 is defined to be the graph whose vertices are the clusters and two clusters are connected iff their intersection is non-empty.\nThe following proposition provides some insights on the structure of the VH graph.\nProposition 1. The VH graph is a bipartite graph where each edge connects a vertical cluster with an horizontal cluster. There is a one-to-one correspondence between the check nodes of T (HZ) that belong to one vertical cluster and one horizontal cluster and the edges of the VH graph.\nProof. Because the graph Tv contains only vertical edges, any vertical cluster must be a subset of {b1} \u00d7 (A \u222a B) for some b1 \u2208 B. Similarly, any horizontal cluster is a subset of (A \u222a B) \u00d7 {a\u20321} for some a\u20321 \u2208 A. As a result, two clusters with the same orientation (horizontal or vertical) cannot intersect and the only possible intersection between a cluster included in {b1} \u00d7 (A \u222aB) and a cluster included in (A\u222aB)\u00d7{a\u20321} is the check node (b1, a\u20321). The bijection between check nodes and edges of the VH graph follows.\nA check node of T (HZ) that belongs to a single cluster is called an internal check, otherwise it is called a connecting check. From Proposition 1, a connecting check must belong to one horizontal and one vertical cluster.\nGiven a cluster \u03ba, let E(\u03ba) be the set of errors supported on the qubits of \u03ba whose syndrome is trivial over the internal checks of \u03ba. Let S(\u03ba) be the set of syndromes of errors E \u2208 E(\u03ba) restricted to the connecting checks of \u03ba. A cluster is said to be isolated if is has no connecting check. Then, it can be corrected independently of the other clusters. A dangling cluster is defined to be a cluster with a single connecting check.\nA cluster \u03ba can have two types of connecting check. If S(\u03ba) contains a weight-one vector supported on an connecting check c, we say that c is a free check. Otherwise, it is a frozen check. If a check is free, the value of the syndrome on this check can be adjusted at the end of the procedure to match s using an error included in the cluster \u03ba.\nTo compute a correction E\u0302 for a syndrome s \u2208 ZRZ2 , we proceed as follows. Denote by s\u03ba the restriction of s to a cluster \u03ba. We initialize E\u0302 = I and we consider three cases.\nCase 1: Isolated cluster. If \u03ba is a isolated cluster, we use Gaussian elimination to find an error E\u0302\u03ba supported on the qubits of \u03ba whose syndrome matches s on the internal checks of \u03ba. Then, we add E\u0302\u03ba to E\u0302, we add \u03c3(E\u0302\u03ba) to s and we remove \u03ba from the erasure \u03b5. This cluster can be corrected independently of the other cluster because it is not connected to any other cluster.\nCase 2: Frozen dangling cluster. If \u03ba is a dangling cluster and its only connecting check is frozen, we proceed exactly as in the case of an isolated cluster. This is\npossible because any correction has the same contribution to the syndrome on the connecting check.\nCase 3: Free dangling cluster. The correction of a dangling cluster \u03ba that contains a free check is delayed until the end of the procedure. We remove \u03ba from the erasure and we remove its free check from the Tanner graph T (HZ). Then, we look for a correction E\u0302\u2032 in the remaining erasure. We add E\u0302\u2032 to E\u0302 and \u03c3(E\u0302\u2032) to s. Once the remaining erasure is corrected and the syndrome is updated, we find a correction E\u0302\u03ba inside \u03ba that satisfies the remaining syndrome s\u03ba in \u03ba. We proceed in that order because the value of the syndrome on a free check can be adjusted at the end of the procedure to match s using an error included in the cluster \u03ba (by definition of free checks).\nAltogether, we obtain the VH decoder (Algorithm 3). Our implementation is available here [25]. It works by correcting all isolated and dangling clusters until the erasure is fully corrected. Otherwise, it returns Failure.\nAlgorithm 3: VH decoder input : An erasure vector \u03b5 \u2208 ZN2 , a syndrome s \u2208 ZRZ2 . output: Either Failure or an X-type error\nE\u0302 \u2208 {I,X}N such that \u03c3(E\u0302) = s and supp(E\u0302) \u2286 supp(\u03b5).\n1 Set E\u0302 = I. 2 Construct an empty stack L = []. 3 while there exists an isolated or a dangling cluster \u03ba\ndo 4 if \u03ba is isolated or frozen then 5 Compute an error E\u0302\u03ba supported on \u03ba whose\nsyndrome matches s on the internal checks of \u03ba in T (HZ).\n6 Replace E\u0302 by E\u0302E\u0302\u03ba and s by s+ \u03c3(E\u0302\u03ba). 7 For all qubits j in \u03ba, set \u03b5j = 0."
        },
        {
            "heading": "8 else",
            "text": "9 Then \u03ba is free.\n10 Remove the free connecting check c of \u03ba from the Tanner graph T (HZ). 11 Add the pair (\u03ba, c) to the stack L. 12 For all qubits j in \u03ba, set \u03b5j = 0.\n13 while the stack L is non-empty do 14 Pop a cluster (\u03ba, c) from the stack L. 15 Add the check node c to the Tanner graph T (HZ). 16 Compute an error E\u0302\u03ba supported on \u03ba whose\nsyndrome matches s on all the checks of \u03ba in T (HZ), including the free check c.\n17 Replace E\u0302 by E\u0302E\u0302\u03ba and s by s+ \u03c3(E\u0302\u03ba).\n18 if \u03b5 6= 0 return Failure, else return E\u0302.\nFor a r \u00d7 n matrix H, the complexity of the VH decoder is dominated by the cost of the Gaussian decoder which grows as O(n3) per cluster and O(n4) including all the clusters (assuming r = O(n)). Therefore the VH decoder can be implemented in O(N2) bit operations where\n5 N = \u0398(n2) is the length of the quantum HGP code. Using a probabilistic implementation of the Gaussian decoder [26\u201329], we can implement the Gaussian decoder in O(n2) operations, reducing the complexity of the VH decoder to O(N1.5).\nAlgorithm 3 fails if the VH-graph of the erasure contains a cycle. However, one can modify the algorithm to eliminate some cycles by removing free checks of all clusters and not only dangling clusters. This may improve further the performance of the VH-decoder.\nIn comparison with our numerical results from Fig. 1, we see that the combination of pruned peeling and VH decoders performs almost as well as the ML decoder at low erasure erasure rates. This is to say that cycles of clusters, which are stopping sets for the VH decoder, are relatively infrequent in the low erasure rate regime. This behavior matches our intuition since errors for LDPC codes tend to be composed of disjoint small weight clusters [30]. Conclusion \u2013 We proposed a practical highperformance decoder for the correction of erasure with HGP codes. Our numerical simulations show that the combination of the pruned peeling decoder with the VH decoder achieves a close-to-optimal performance in complexity O(N2). This decoder can be used as a subroutine of the Union-Find decoder for LDPC codes [31] to speed up this algorithm.\nIn future work, it would be interesting to adapt our decoder to other quantum LDPC codes [32\u201335]. We are also wondering if one can reduce the complexity further to obtain a linear time ML decoder for the correction of erasure.\nFinally, it would be interesting to investigate the resource overhead of quantum computing architectures capable of detecting erasures based on neutral atoms [11], trapped ions [36] or superconducting qubits [37].\nThis research was supported by the MSR-Inria Joint Centre. AL acknowledges support from the Plan France 2030 through the project ANR-22-PETQ-0006.\n[1] E. Dennis, A. Kitaev, A. Landahl, and J. Preskill, Journal of Mathematical Physics 43, 4452 (2002). [2] A. G. Fowler, M. Mariantoni, J. M. Martinis, and A. N. Cleland, Physical Review A 86, 032324 (2012). [3] R. Gallager, IRE Transactions on Information Theory 8, 21 (1962). [4] D. J. MacKay, G. Mitchison, and P. L. McFadden, IEEE Transactions on Information Theory 50, 2315 (2004). [5] J.-P. Tillich and G. Z\u00e9mor, IEEE Transactions on Information Theory 60, 1193 (2013). [6] D. Gottesman, Quantum Information & Computation 14, 1338 (2014). [7] O. Fawzi, A. Grospellier, and A. Leverrier, in 2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS) (IEEE, 2018) pp. 743\u2013754.\n[8] M. A. Tremblay, N. Delfosse, and M. E. Beverland, arXiv preprint arXiv:2109.14609 (2021). [9] E. Knill, R. Laflamme, and G. J. Milburn, nature 409, 46 (2001). [10] S. Bartolucci, P. Birchall, H. Bombin, H. Cable, C. Dawson, M. Gimeno-Segovia, E. Johnston, K. Kieling, N. Nickerson, M. Pant, et al., arXiv preprint arXiv:2101.09310 (2021). [11] Y. Wu, S. Kolkowitz, S. Puri, and J. D. Thompson, arXiv preprint arXiv:2201.03540 (2022). [12] S. Kudekar, T. Richardson, and R. L. Urbanke, IEEE Transactions on Information Theory 59, 7761 (2013). [13] T. Richardson and R. Urbanke, Modern coding theory (Cambridge university press, 2008). [14] M. G. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. A. Spielman, IEEE Transactions on Information Theory 47, 569 (2001). [15] V. V. Zyablov and M. S. Pinsker, Problemy Peredachi Informatsii 10, 15 (1974). [16] N. Delfosse and G. Z\u00e9mor, Physical Review Research 2, 033042 (2020). [17] S. Lee, M. Mhalla, and V. Savin, in 2020 IEEE International Symposium on Information Theory (ISIT) (IEEE, 2020) pp. 1886\u20131890. [18] A. Steane, Proceedings of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences 452, 2551 (1996). [19] A. R. Calderbank and P. W. Shor, Physical Review A 54, 1098 (1996). [20] M. Grassl, T. Beth, and T. Pellizzari, Physical Review A 56, 33 (1997). [21] T. J. Richardson and R. L. Urbanke, IEEE Transactions on Information Theory 47, 638 (2001). [22] X.-Y. Hu, E. Eleftheriou, and D.-M. Arnold, in GLOBECOM\u201901. IEEE Global Telecommunications Conference (Cat. No.01CH37270), Vol. 2 (2001) pp. 995\u20131001 vol.2. [23] X.-Y. Hu, E. Eleftheriou, and D. Arnold, IEEE Transactions on Information Theory 51, 386 (2005). [24] T. S. Manu, Progressive edge growth algorithm for generating LDPC matrices (2014). [25] N. Connolly, Pruned peeling and vh decoder (2022). [26] D. Wiedemann, IEEE Transactions on Information The-\nory 32, 54 (1986). [27] E. Kaltofen and B. David Saunders, in International\nSymposium on Applied Algebra, Algebraic Algorithms, and Error-Correcting Codes (Springer, 1991) pp. 29\u201338. [28] B. A. LaMacchia and A. M. Odlyzko, in Conference on the Theory and Application of Cryptography (Springer, 1990) pp. 109\u2013133. [29] E. Kaltofen, Mathematics of Computation 64, 777 (1995). [30] A. A. Kovalev and L. P. Pryadko, Physical Review A 87, 020304 (2013). [31] N. Delfosse, V. Londe, and M. E. Beverland, IEEE Transactions on Information Theory (2022). [32] N. P. Breuckmann and J. N. Eberhardt, IEEE Transactions on Information Theory 67, 6653 (2021). [33] P. Panteleev and G. Kalachev, in Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing (2022) pp. 375\u2013388. [34] A. Leverrier and G. Z\u00e9mor, arXiv preprint arXiv:2202.13641 (2022). [35] I. Dinur, M.-H. Hsieh, T.-C. Lin, and T. Vidick, arXiv preprint arXiv:2206.07750 (2022).\n6 [36] M. Kang, W. C. Campbell, and K. R. Brown, arXiv preprint arXiv:2210.15024 (2022). [37] A. Kubica, A. Haim, Y. Vaknin, F. Brand\u00e3o, and A. Retzker, arXiv preprint arXiv:2208.05461 (2022)."
        }
    ],
    "title": "Fast erasure decoder for a class of quantum LDPC codes",
    "year": 2023
}