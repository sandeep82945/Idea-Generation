{
    "abstractText": "of Master\u2019s Thesis of Academic Year 2021 Emolleia \u2013 Wearable Kinetic Flower Display for Expressing Emotions",
    "authors": [
        {
            "affiliations": [],
            "name": "Yifan Zhuang"
        },
        {
            "affiliations": [],
            "name": "Kai Kunze"
        },
        {
            "affiliations": [],
            "name": "Junichi Yamaoka"
        },
        {
            "affiliations": [],
            "name": "Kazunori Sugiura"
        }
    ],
    "id": "SP:4b15f8c3e3e7f8369908cfb3277446a15cdc12f1",
    "references": [
        {
            "authors": [
                "Xiao-Ping Gao",
                "John Xin",
                "Tetsuya Sato",
                "Aran Hansuebsai",
                "Marcello Scalzo",
                "Kanji Kajiwara",
                "Shing-Sheng Guan",
                "Josep Valldeperas-Morell",
                "Manuel Lis",
                "Monica Billger"
            ],
            "title": "Analysis of cross-cultural color emotion",
            "venue": "Color Research & Application,",
            "year": 2007
        },
        {
            "authors": [
                "Steven McCornack",
                "Joseph Ortiz"
            ],
            "title": "Loose-Leaf Version for Choices & Connections: An Introduction to Communication",
            "venue": "Macmillan Higher Education,",
            "year": 2019
        },
        {
            "authors": [
                "Philip G Zimbardo",
                "Paul Pilkonis",
                "Robert Norwood"
            ],
            "title": "The silent prison of shyness",
            "venue": "Technical report, STANFORD UNIV CA DEPT OF PSYCHOL- OGY,",
            "year": 1977
        },
        {
            "authors": [
                "Margaret M Bradley",
                "Peter J Lang"
            ],
            "title": "Measuring emotion: the selfassessment manikin and the semantic differential",
            "venue": "Journal of behavior therapy and experimental psychiatry,",
            "year": 1994
        },
        {
            "authors": [
                "Iztok Hrga"
            ],
            "title": "Wearable technologies: Between fashion, art, performance, and science",
            "venue": "(fiction). Tekstilec,",
            "year": 2019
        },
        {
            "authors": [
                "Rosalind W Picard",
                "Jennifer Healey"
            ],
            "title": "Affective wearables",
            "venue": "Personal Technologies,",
            "year": 1997
        },
        {
            "authors": [
                "Vlaho Kostov",
                "Jun Ozawa",
                "Satoshi Matsuura"
            ],
            "title": "Analysis of wearable interface factors for appropriate information notification",
            "venue": "In Eighth International Symposium on Wearable Computers,",
            "year": 2004
        },
        {
            "authors": [
                "Sydney Pratte",
                "Anthony Tang",
                "Lora Oehlberg"
            ],
            "title": "Evoking empathy: A framework for describing empathy tools",
            "venue": "In Proceedings of the Fifteenth International Conference on Tangible, Embedded, and Embodied Interaction,",
            "year": 2021
        },
        {
            "authors": [
                "Soomi Park",
                "Patrick GT Healey",
                "Antonios Kaniadakis"
            ],
            "title": "Should robots blush",
            "venue": "In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Kristin Neidlinger",
                "Khiet P. Truong",
                "Caty Telfair",
                "Loe Feijs",
                "Edwin Dertien",
                "Vanessa Evers"
            ],
            "title": "Awelectric: That gave me goosebumps, did you feel it too",
            "venue": "In Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction,",
            "year": 2017
        },
        {
            "authors": [
                "Nur Al-huda Hamdan",
                "Adrian Wagner",
                "Simon Voelker",
                "J\u00fcrgen Steimle",
                "Jan Borchers"
            ],
            "title": "Springlets: Expressive, flexible and silent on-skin tactile interfaces",
            "venue": "In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Kelsey Vitullo",
                "Margarita Benitez"
            ],
            "title": "A wearable therapy and technology garment for kids: the underlying super hero",
            "venue": "In Proceedings of the 23rd International Symposium on Wearable Computers,",
            "year": 2019
        },
        {
            "authors": [
                "Joanna Berzowska",
                "Marcelo Coelho"
            ],
            "title": "Kukkia and vilkas: Kinetic electronic garments",
            "venue": "In Ninth IEEE International Symposium on Wearable Computers",
            "year": 2005
        },
        {
            "authors": [
                "Yohei Noguchi",
                "Fumihide Tanaka"
            ],
            "title": "Omoy: A handheld robotic gadget that shifts its weight to express emotions and intentions",
            "venue": "In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Rain Ashford"
            ],
            "title": "Responsive and emotive wearables: devices, bodies, data and communication",
            "venue": "In Proceedings of the 2014 ACM International Symposium on Wearable Computers: Adjunct Program,",
            "year": 2014
        },
        {
            "authors": [
                "\u00c7a\u011flar Gen\u00e7",
                "Ashley Colley",
                "Markus L\u00f6chtefeld",
                "Jonna H\u00e4kkil\u00e4"
            ],
            "title": "Face mask design to mitigate facial expression occlusion",
            "venue": "In Proceedings of the 2020 International Symposium on Wearable Computers,",
            "year": 2020
        },
        {
            "authors": [
                "Teddy Seyed",
                "James Devine",
                "Joe Finney",
                "Michal Moskal",
                "Peli de Halleux",
                "Steve Hodges",
                "Thomas Ball",
                "Asta Roseway"
            ],
            "title": "Rethinking the runway: Using avant-garde fashion to design a system for wearables",
            "venue": "In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Ye Tao",
                "Guanyun Wang",
                "Caowei Zhang",
                "Nannan Lu",
                "Xiaolian Zhang",
                "Cheng Yao",
                "Fangtian Ying"
            ],
            "title": "Weavemesh: A low-fidelity and low-cost prototyping approach for 3d models created by flexible assembly",
            "venue": "In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Oussama Metatla",
                "Emanuela Maggioni",
                "Clare Cullen",
                "Marianna Obrist"
            ],
            "title": "popcorn\u201d crossmodal correspondences between scents, 3d shapes and emotions in children",
            "venue": "In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Eldy S Lazaro Vasquez",
                "Katia Vega"
            ],
            "title": "Myco-accessories: sustainable wearables with biodegradable materials",
            "venue": "In Proceedings of the 23rd International Symposium on Wearable Computers,",
            "year": 2019
        },
        {
            "authors": [
                "Esther W Foo",
                "Robert Mt Pettys-Baker",
                "Shawn Sullivan",
                "Lucy E Dunne"
            ],
            "title": "Garment-integrated wetness sensing for leak detection",
            "venue": "In Proceedings of the 2017 ACM International Symposium on Wearable Computers,",
            "year": 2017
        },
        {
            "authors": [
                "Irene Posch",
                "Liza Stark",
                "Geraldine Fitzpatrick"
            ],
            "title": "etextiles: reviewing a practice through its tool/kits",
            "venue": "In Proceedings of the 23rd International Symposium on Wearable Computers,",
            "year": 2019
        },
        {
            "authors": [
                "Aaron Toney",
                "Lucy Dunne",
                "Bruce H Thomas",
                "Susan P Ashdown"
            ],
            "title": "A shoulder pad insert vibrotactile display",
            "venue": "In Seventh IEEE International Symposium on Wearable Computers,",
            "year": 2003
        },
        {
            "authors": [
                "J Walter Lee",
                "Stephanie Wang",
                "Caroline Albers",
                "Lucy E Dunne"
            ],
            "title": "Garment-based emg system for intra-spacesuit biomechanics analysis",
            "venue": "In Proceedings of the 2018 ACM International Symposium on Wearable Computers,",
            "year": 2018
        },
        {
            "authors": [
                "Banu Manav"
            ],
            "title": "Color-emotion associations and color preferences: A case study for residences. Color Research & Application: Endorsed by Inter-Society Color Council, The Colour Group (Great Britain), Canadian Society for Color, Color Science Association of Japan, Dutch Society for the Study of Color, The Swedish Colour Centre Foundation",
            "venue": "Colour Society of Australia, Centre Franc\u0327ais de la Couleur,",
            "year": 2007
        },
        {
            "authors": [
                "Rense Lange",
                "Jason Rentfrow"
            ],
            "title": "Color and personality: Strong\u2019s interest inventory and cattell\u2019s 16pf",
            "venue": "North Am J Psychol,",
            "year": 2007
        },
        {
            "authors": [
                "Miho Saito"
            ],
            "title": "Comparative studies on color preference in japan and other asian regions, with special emphasis on the preference for white",
            "venue": "Color Research & Application,",
            "year": 1996
        },
        {
            "authors": [
                "Cigic Dunja",
                "Vojislava Bugarski Ignjatovi\u0107"
            ],
            "title": "Personality traits and colour preferences. Aktuelnosti iz Neurologije",
            "venue": "Psihijatrije i Granic\u030cnih Podruc\u030cja,",
            "year": 2010
        },
        {
            "authors": [
                "Robert Plutchik"
            ],
            "title": "Emotions and life: Perspectives from psychology, biology, and evolution",
            "venue": "American Psychological Association,",
            "year": 2003
        },
        {
            "authors": [
                "Kazunori Terada",
                "Atsushi Yamauchi",
                "Akira Ito"
            ],
            "title": "Artificial emotion expression for a robot by dynamic color change",
            "venue": "IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication,",
            "year": 2012
        },
        {
            "authors": [
                "Mary Ellen Berglund",
                "Esther Foo",
                "Md Tahmidul Islam Molla",
                "Smitha Muthya Sudheendra",
                "Crystal Compton",
                "Lucy E Dunne"
            ],
            "title": "Make it blue: a controllable, color-changing dynamic costume",
            "venue": "In Proceedings of the 2018 ACM International Symposium on Wearable Computers,",
            "year": 2018
        },
        {
            "authors": [
                "Pradthana Jarusriboonchai",
                "Emmi Harjuniemi",
                "Heiko M\u00fcller",
                "Ashley Colley",
                "Jonna H\u00e4kkil\u00e4. Linn"
            ],
            "title": "dress: enabling a dynamically adjustable neckline",
            "venue": "In Proceedings of the 23rd International Symposium on Wearable Computers,",
            "year": 2019
        },
        {
            "authors": [
                "Pradthana Jarusriboonchai",
                "Hong Li",
                "Emmi Harjuniemi",
                "Heiko M\u00fcller",
                "Jonna H\u00e4kkil\u00e4"
            ],
            "title": "Always with me: Exploring wearable displays as a lightweight intimate communication channel",
            "venue": "In Proceedings of the Fourteenth International Conference on Tangible, Embedded, and Embodied Interaction,",
            "year": 2020
        },
        {
            "authors": [
                "Iztok Hrga"
            ],
            "title": "Wearable Technologies: Between Fashion, Art, Performance, and Science (Fiction). (English) [On the electrodynamics of moving bodies",
            "venue": "APers Ubiquit Comput,",
            "year": 2019
        },
        {
            "authors": [
                "David Dobbelstein",
                "Steffen Herrdum",
                "Enrico Rukzio"
            ],
            "title": "Inscent: A wearable olfactory display as an amplification for mobile notifications",
            "venue": "In Proceedings of the 2017 ACM International Symposium on Wearable Computers,",
            "year": 2017
        },
        {
            "authors": [
                "Benhaz Farahi"
            ],
            "title": "Iridescence: Bio-inspired emotive matter. 2019",
            "year": 2019
        },
        {
            "authors": [
                "Regina Bernhaupt",
                "Andreas Boldt",
                "Thomas Mirlacher",
                "David Wilfinger",
                "Manfred Tscheligi"
            ],
            "title": "Using emotion in games: emotional flowers",
            "venue": "In Proceedings of the international conference on Advances in computer entertainment technology,",
            "year": 2007
        },
        {
            "authors": [
                "Daisuke Uriu",
                "Noriyasu Obushi",
                "Zendai Kashino",
                "Atsushi Hiyama",
                "Masahiko Inami"
            ],
            "title": "Floral tribute ritual in virtual reality: Design and validation of sensevase with virtual memorial",
            "venue": "In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "J.M. Jani",
                "M. Leary",
                "A. Subic",
                "M.A. Gibson"
            ],
            "title": "A review of shape memory alloy research, applications and opportunities. (English) [On the electrodynamics of moving bodies",
            "venue": "APers Ubiquit Comput,",
            "year": 2014
        },
        {
            "authors": [
                "Marcelo Coelho \u2022 Jamie Zigelbaum"
            ],
            "title": "Shape-changing interfaces. (English) [On the electrodynamics of moving bodies",
            "venue": "APers Ubiquit Comput,",
            "year": 2011
        },
        {
            "authors": [
                "Jiale Yong",
                "Feng Chen",
                "Qing Yang",
                "Guangqing Du",
                "Chao Shan",
                "Hao Bian",
                "Umar Farooq",
                "Xun Hou"
            ],
            "title": "Bioinspired transparent underwater superoleophobic and anti-oil surfaces",
            "venue": "J. Mater. Chem. A,",
            "year": 2015
        },
        {
            "authors": [
                "Julian B. Rotter"
            ],
            "title": "Generalized expectancies for internal versus external control of reinforcement",
            "venue": "Psychological Monographs: General and Ap- 51 References plied,",
            "year": 1966
        },
        {
            "authors": [
                "Albert Mehrabian"
            ],
            "title": "Basic dimensions for a general psychological theory implications for personality, social, environmental, and developmental studies",
            "year": 1980
        },
        {
            "authors": [
                "B. Geethanjali",
                "K. Adalarasu",
                "A. Hemapraba",
                "S.P. Kumar",
                "R. Rajasekeran"
            ],
            "title": "Emotion analysis using sam (self-assessment manikin) scale",
            "venue": "Biomedical Research-tokyo,",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Title Emolleia : wearable kinetic flower display for expressing emotions Sub Title Author \u5e84, \u6613\u68b5(Zhuang, Yifan) Kunze, Kai Publisher \u6176\u61c9\u7fa9\u587e\u5927\u5b66\u5927\u5b66\u9662\u30e1\u30c7\u30a3\u30a2\u30c7\u30b6\u30a4\u30f3\u7814\u7a76\u79d1\nPublication year 2021 Jtitle\nJaLC DOI Abstract Notes \u4fee\u58eb\u5b66\u4f4d\u8ad6\u6587. 2021\u5e74\u5ea6\u30e1\u30c7\u30a3\u30a2\u30c7\u30b6\u30a4\u30f3\u5b66 \u7b2c881\u53f7 Genre Thesis or Dissertation URL https://koara.lib.keio.ac.jp/xoonips/modules/xoonips/detail.php?koara_id=KO40001001-00002021-\n0881\n\u6176\u61c9\u7fa9\u587e\u5927\u5b66\u5b66\u8853\u60c5\u5831\u30ea\u30dd\u30b8\u30c8\u30ea(KOARA)\u306b\u63b2\u8f09\u3055\u308c\u3066\u3044\u308b\u30b3\u30f3\u30c6\u30f3\u30c4\u306e\u8457\u4f5c\u6a29\u306f\u3001\u305d\u308c\u305e\u308c\u306e\u8457\u4f5c\u8005\u3001\u5b66\u4f1a\u307e\u305f\u306f\u51fa\u7248\u793e/\u767a\u884c\u8005\u306b\u5e30\u5c5e\u3057\u3001\u305d\u306e\u6a29\u5229\u306f\u8457\u4f5c\u6a29\u6cd5\u306b\u3088\u3063\u3066 \u4fdd\u8b77\u3055\u308c\u3066\u3044\u307e\u3059\u3002\u5f15\u7528\u306b\u3042\u305f\u3063\u3066\u306f\u3001\u8457\u4f5c\u6a29\u6cd5\u3092\u9075\u5b88\u3057\u3066\u3054\u5229\u7528\u304f\u3060\u3055\u3044\u3002\nThe copyrights of content available on the KeiO Associated Repository of Academic resources (KOARA) belong to the respective authors, academic societies, or publishers/issuers, and these rights are protected by the Japanese Copyright Act. When quoting the content, please follow the Japanese copyright act.\nPowered by TCPDF (www.tcpdf.org)\nMaster\u2019s Thesis\nAcademic Year 2021\nEmolleia \u2013 Wearable Kinetic Flower Display for\nExpressing Emotions\nKeio University\nGraduate School of Media Design\nYifan Zhuang\nA Master\u2019s Thesis\nsubmitted to Keio University Graduate School of Media Design\nin partial fulfillment of the requirements for the degree of\nMaster of Media Design\nYifan Zhuang\nMaster\u2019s Thesis Advisory Committee:\nProfessor Kai Kunze (Main Research Supervisor) Senior Assistant Professor Junichi Yamaoka (Sub Research Supervisor)\nMaster\u2019s Thesis Review Committee:\nProfessor Kai Kunze (Chair) Senior Assistant Professor Junichi Yamaoka (Co-Reviewer) Professor Kazunori Sugiura (Co-Reviewer)\nAbstract of Master\u2019s Thesis of Academic Year 2021\nEmolleia \u2013 Wearable Kinetic Flower Display for\nExpressing Emotions\nCategory: Design\nSummary\nWe explore how what we wear (our clothes and wearable accessories) can be more expressive and represent our mood in the moment. In this paper, we present Emolleia, an open, wearable kinetic display in form of three 3D printed flowers that can based on wearer & onlooker\u2019s facial expression, dynamically perform 8 pre-defined animations. Users can define their own animated motions. We describe the prototype design and hardware considerations. We also evaluate the expressiveness of the prototype in user survey (n=50), mapping 8 pre-defined animated motions to the reported, user-perceived valence, arousal and dominance. Several animated motions show significant responses for perceived valence and arousal, presenting evidence that Emolleia can be effective in communicating feelings. By conducting conversation study with Emolleia, we explored how facial tracking technology with wearable computer can be used to enhance social interaction and encourage people express themselves more.\nKeywords:\nwearable display, aethetic wearables, emotion, interactive design, fashion\nKeio University Graduate School of Media Design\nYifan Zhuang\ni\nContents\nAcknowledgements vii"
        },
        {
            "heading": "1 Introduction 1",
            "text": "1.1. Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2. Socialization & Non-verbal Communication . . . . . . . . . . . . . 1 1.3. Proposal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.4. Research Question . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.5. Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.6. Thesis Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4"
        },
        {
            "heading": "2 Related Works 5",
            "text": "2.1. Wearable Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.2. Wearables with emotion expressing . . . . . . . . . . . . . . . . . 5 2.3. Emotion & Color . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2.4. Fashion with technology . . . . . . . . . . . . . . . . . . . . . . . 7 2.5. Flower Design Reflect Emotion . . . . . . . . . . . . . . . . . . . 8"
        },
        {
            "heading": "3 Emolleia 9",
            "text": "3.1. Concept and Final Design . . . . . . . . . . . . . . . . . . . . . . 9 3.2. Design Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n3.2.1 Sketch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3.2.2 Prototyping . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3.2.3 System Description . . . . . . . . . . . . . . . . . . . . . . 17\n3.3. Pre-study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3.3.1 Design Research . . . . . . . . . . . . . . . . . . . . . . . . 21 3.3.2 Pilot Survey . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.3.3 Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\nii\nContents\n3.3.4 Pilot Study . . . . . . . . . . . . . . . . . . . . . . . . . . 24"
        },
        {
            "heading": "4 Evaluation 27",
            "text": "4.1. Study 1: Emotion Elicitation . . . . . . . . . . . . . . . . . . . . 27\n4.1.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 28 4.1.2 Study Protocol . . . . . . . . . . . . . . . . . . . . . . . . 28 4.1.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 4.1.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n4.2. Exhibition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 4.3. User study 2: Conversation Use Case . . . . . . . . . . . . . . . . 38\n4.3.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 38 4.3.2 Study Protocol . . . . . . . . . . . . . . . . . . . . . . . . 38 4.3.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 4.3.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . 42"
        },
        {
            "heading": "5 Conclusion 43",
            "text": "5.1. Finding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 5.2. Limitation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 5.3. Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\nReferences 46\nAppendices 53\nA. Questionnaires . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\niii\nList of Figures\n1.1 Emolleia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n3.1 Model wearing Emolleia around shoulder . . . . . . . . . . . . . 9 3.2 The interpretation sketch of how Emolleia react to surround peo-\nple according to their facial expression . . . . . . . . . . . . . . . 10\n3.3 The soft of user define animation . . . . . . . . . . . . . . . . . 12 3.4 The first Emolleia design sketch . . . . . . . . . . . . . . . . . . 12 3.5 The Emolleia design sketch - profile . . . . . . . . . . . . . . . . 13 3.6 The Emolleia design sketch - front . . . . . . . . . . . . . . . . . 14 3.7 Test prototype & 3D modeling images . . . . . . . . . . . . . . . 14 3.8 Emolleia sketch SMA ver. . . . . . . . . . . . . . . . . . . . . . . 15 3.9 The 3d model of petal . . . . . . . . . . . . . . . . . . . . . . . . 17 3.10 The 3d model of Emolleia support . . . . . . . . . . . . . . . . . 17 3.11 Final prototype of emolleia . . . . . . . . . . . . . . . . . . . . . 18 3.12 System description of M5STACK . . . . . . . . . . . . . . . . . . 19 3.13 Overview of the assembly of Emolleia . . . . . . . . . . . . . . . 20 3.14 A color wheel to help categorize intensities of eight primary emotions-\nanger,fear,sadness,disgust,surprise,curiosity, acceptance and joy [1] 21\n3.15 Beetle color change observing sketch . . . . . . . . . . . . . . . . 22 3.16 Implementation explanation of prototype used in pilot study . . 24 3.17 Pilot study set up 1 . . . . . . . . . . . . . . . . . . . . . . . . . 25 3.18 Pilot study set up 2 . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.1 The-Self-Assessment-Manikin-SAM-Measure-Scales-valence-arousal-\nand-dominance-pole . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.2 The Emolleia motion used in Animation Study . . . . . . . . . . 28 4.3 Replies of where people would like to wear the device . . . . . . 30\niv\nList of Figures\n4.4 Replies of Who would you be willing to use this product under\nthe company? . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n4.5 The mean value of Emolleia\u2019s arousal . . . . . . . . . . . . . . . 32 4.6 The mean value of Emolleia\u2019s valence . . . . . . . . . . . . . . . 32 4.7 Eight Motions mapped to valence-arousal coordinate axes based\non average SAM scores from survey results . . . . . . . . . . . . 33\n4.8 Poster of Emolleia in KMD forum 2021 . . . . . . . . . . . . . . 35 4.9 Description of facial recognition system . . . . . . . . . . . . . . 36 4.10 Emolleia interactive process step interpretation . . . . . . . . . 36 4.11 Exhibition - KMD forum 2021 . . . . . . . . . . . . . . . . . . . 37 4.12 Face recognition process flow diagram . . . . . . . . . . . . . . . 39 4.13 Conversation use case set up . . . . . . . . . . . . . . . . . . . . 40\nv\nList of Tables\n4.1 Descriptive statistics of SAM scores over eight types of motions."
        },
        {
            "heading": "Acknowledgements",
            "text": "I am forever thankful to Professor Kai Kunze for the guidance, advice and interest he shared throughout my two years life in KMD. Your insightful feedback pushed me to sharpen my thinking and brought my work to a higher level.\nI am extremely grateful to my sub-supervisor Professor Yamaoka Junichi for the generous support and brilliant advice. He provided me with countless valuable knowledge on interact material, media art and led me through a proper and more ambitious research path.\nMy special appreciation to Keitaro Tsuchiya and Takuro Nakao, not just for the strongest assistance on making this project - Emolleia happen, but also showing me the right way to research field. I have grown up so much.\nI am forever thankful to my talented fellow friends I met at Keio Media Design, who have always been so supportive, funny, ridiculous (in a good way love you guys) , all the conversations, discussions, laughs we had already became part of my precious memory. Thanks for sharing this splendid journey together.\nAlso, to all my friends I encountered in Japan, thank you for your existence to make my life here much more fun. I couldn\u2019t ask a better experience living in another country.\nLast but not least, I would like to express my endless gratitude to my family, especially my parents for all the support and love they have been given me for the past 24 years. To my beloved grandfather who taught me that learning is an endless journey, I wish he could witness how far I have been. The time I spent at KMD has been the most wonderful time of my life, thank you all again for making this happen.\nvii\nChapter 1\nIntroduction"
        },
        {
            "heading": "1.1. Background",
            "text": "Every morning, after we wake up, part of our morning routine is to pick what clothes and accessories to wear. Sometimes these choices are affected by our mood in the moment; how we feel after getting up, what sound is playing on the radio. Sometimes, we dress to impress, picking our favourite outfit in which we feel confident, relaxed or beautiful, and communicating these feelings to the people we meet.\nClothes and accessories are part of our self-expression, yet usually we can just change how we look and adjust it to our feelings a couple of times a day by putting on different clothing items.\nThere are already quite a few explorations on utilizing garments or accessories to assist self expression, social interaction, or conversation efficiency. Researchers and designers have started realizing instead of a simple decoration, garment can actually be functional as an extension of our body, as an advanced communication method to augment or even perform non-verbal communication as eye contact, facial expressions, gestures, posture, and body language. [2]"
        },
        {
            "heading": "1.2. Socialization & Non-verbal Communication",
            "text": "Take a moment to imagine on this beautiful blue planet, there are roughly 7.6 billion people living together on the same land, connected tightly as an organization which every internal individual has been more or less affected by one and another during million years. We have been constantly interacting with other human being spontaneously or reluctantly under this gigantic social system, by communicating through verbal or non-verbal methods. Socializing, has already\n1\n1. Introduction 1.3. Proposal\nbecome one indispensable part of our daily life.\nAlthough undeniably we are heading to the united society in very high speed, there are still some incredible people were unable to openly express themselves very well under social context or a conversation due to variety reasons.\nSome studies pointed out that non-verbal communication can convey more information than verbal communication. [3] Some scholars state that most people trust forms of nonverbal communication over verbal communication. [2]Ray Birdwhistell concludes that nonverbal communication accounts for 60\u201370 percent of human communication. [4]\nFor example, shy people always find it hard to tell surrounding individuals to keep distance when they prefer to be alone, or let others know they are willing to socialize but lack of courage to ask.\nZimbardo (1977) proposed that there are two types of shy individuals; (1) shy introverts who prefer to be alone and lack social skills and, (2) shy extroverts who desire to interact with others, but lack social skills and experience internal distress and cognitive distortions about social situations. [5]\nThe motivation of this project is to assists people who has difficulty on express-\ning their emotions to show their acceptance and rejection in a gentle way."
        },
        {
            "heading": "1.3. Proposal",
            "text": "In our research, we explore how to create more expressive clothes and accessories that are able to instantaneously reflect our feelings. We work on integrating wearable computing in our clothes to dynamically show mood changes and represent how we feel in the moment. We focus on wearable accessories and clothes that can change and reflect the intentions, moods, and feelings of the wearer. The target user of this device is people who has difficulty to express themselves in social conditions.\nIn this thesis, we present Emolleia, a wearable kinetic display in form of three 3D printed flowers that equipped a facial tracking camera which can detect your presence and recognize your facial expression. As you approach, Emolleia can dynamically perform eight animations at different speeds according to wearer & onlooker\u2019s facial expression. Users can define their own animated motions.\n2\n1. Introduction 1.4. Research Question\nThe kinetic display is the result of several design iterations trying to capture the movements of flower ensembles."
        },
        {
            "heading": "1.4. Research Question",
            "text": "The aim of this study is to explore more possibilities utilizing wearables to assist on emotion expressing, ultimately enhance our conversation efficiency or even social life. Here is three research questions we would like to raise:\nResearch Question 1 Are wearables able to express people\u2019s emotion?\nResearch Question 2 Does affective wearables make participants to be more\naware of other people\u2019s emotions?\nResearch Question 3 Will participants who relatively express their opinions\nless than others be motivated to speak out their thought, and will participants who relatively talk more than others realize that those who talk less have something to say and offer them a chance to speak out?"
        },
        {
            "heading": "1.5. Contribution",
            "text": "The contributions of this paper are as follows:\n1. We present the concept, design and prototype implementation of Emolleia,\na kinetic display consisting of three flowers (the 3D model, components and software will be open-sourced).\n2. We conducted a user survey with 50 participants to elicit potential use and\napplication cases.\n3. In the emotion elicitation study with the same participants, we evaluated\n8 designed animated motions of Emolleia regarding their perceived emotional qualities using the self-assessment Manikin [6].Several animated motions show significant differences for perceived valence and arousal.\n3\n1. Introduction 1.6. Thesis Structure\n4. In the user study 2 conversation use case, we picked and mapped 5 emotion-\ncorrelated animations on Emolleia then conducted an experiment with 6 participants to observe how wearables enhance people social interaction and self expression."
        },
        {
            "heading": "1.6. Thesis Structure",
            "text": "This thesis is divided into 5 chapters. Chapter 1 is an introduction to this project. Chapter 2 presents related works, chapter 3 focused on describing the design concept, process and implementation of Emolleia, chapter 4 explains the two user studies and analyses experiment results, chapter 5 concludes with the findings, limitation and future work.\n4\nChapter 2\nRelated Works\nTo understand the design concept Emollia, we first explore related works in the fields of wearables. Here we specifically focus on emotion expression, emotion & color, fashion and technology, also the flower design with emotion."
        },
        {
            "heading": "2.1. Wearable Devices",
            "text": "According to Susan Elizabeth Ryan, the term \u2018wearable technology\u2019 or WT applies to work that is functional in application and potentially commercial in distribution or experimental and conceptual in nature to aid the awareness of embodiment. [7]\nThere\u2019s a long line of research in wearable computing and in human computer interaction fields targeting the recognition, visualization, and evocation of emotions [8\u201312].\nSpringlets, expressive, non-vibrating mechano-tactile interfaces on the skin. Embedded with shape memory alloy springs,it\u2019s a thin and flexible stickers to be worn on various body location which provided a new interactive experience in tactile social communication, physical guidance, health interfaces, navigation, and virtual reality gaming. [13]"
        },
        {
            "heading": "2.2. Wearables with emotion expressing",
            "text": "Researchers link garments, clothes and accessories to how we are perceiving us and actively use these effects for communication and therapy [14]. Garment is one of the most intimate things that we interact with in our daily lives. Garments are used to hide, reveal, and distort the self that we present to the world. [15] There are several works using wearables to display and communicate emotional\n5\n2. Related Works 2.3. Emotion & Color\nfeedback in with kinetic using tactile sensations [13,16].\nThere are variety of researches which using wearables to assist on self-expressing\nand explore new possibilities on social interacting have been conducted.\nRain Ashford presented one emotive wearables which will reflect wearer\u2019s EEG data on pendant, to show if this person is paying attention or concentrating on what is going on around them, or is relaxed and not focusing or concentrating. [17]\nThe Awe Goosebumps uses the inflatable silicone to externalize and amplify\nfeelings of goosebumps [12]\nUnder COVID-19 pandemic, there are also some works presents a stepping stone towards productizable solutions for smart face masks that potentially increase the acceptability of face mask wear in public which display the emoji on the mask. [18]\nFashion makers and designers are also rethinking their trade and incorporate wearables in their designs [19]. There is an emerging area of 3D printed, computer generated fashion individualized for the user [20]. They utilize often the connections between shapes, forms and emotions [21]. Vasquez et al. present wearable, expressive accessories combining biodegradable materials with electronics [22].These works however are often not dynamic and cannot change while the user is wearing them. Most work in the wearable garment and accessories space focuses on utility and use cases (e.g. detecting wetness) [23\u201326]. Vasquez et al. present wearable, expressive accessories combining biodegradable materials with electronics [22]."
        },
        {
            "heading": "2.3. Emotion & Color",
            "text": "Color is an important design element that can meet a variety of human needs. [27] Color is also an important aspect of our efforts to create personal spaces to our own liking. Moreover, color choices can have important social consequences as our choices are part of our presentation to others, and thus these choices may influence how others perceive us. [28]\nMany studies have shown that cultural background, age, gender, personality do have strong affect on people\u2019s interpretation and choice towards color. [29] Social introversion and neuroticism may be associated with the preference for dark and cold colours (in this case grey, brown, and black). Similarly to these\n6\n2. Related Works 2.4. Fashion with technology\ncolours, introvert personalities tend to withdraw from the external environment. [30] Studies indicate that there is a common preference for white in Asian areas. White with its associative image of being clean, pure, harmonious, refreshing, beautiful, cheer, gentle and natural is preferred in Asian regions. [29]\nMany studies have shown that color is associated with emotional expression. In the Color - Emotion Association case study conducted by Banu Manav shows, Pink and yellow color samples were associated with dynamism, cheerfulness, and enjoyment. Green elicited a high number of responses, including the feelings of excitement, relaxation and vividness, confidence and purity. Blue was associated with calmness, being peaceful and cold. [27]\nIn 1980\u2019s Robert Plutchik [31] divided emotions into eight main categories. Half\nof these emotions are positive emotions, and the other half are negative ones.\nStudies have also been conducted on novel method of expressing emotions for\na robot by dynamically changing the color luminosity of its body. [32]"
        },
        {
            "heading": "2.4. Fashion with technology",
            "text": "Researchers and designers are not satisfied with placing wearables only in Engineering or Human Computer Interaction side. There are quite some experimental fashion garments been created with both aesthetic outlook and ingenious interaction.\nWe are inspired by the following research works and their vision follow closely. Berzowska et al. present first prototypes of kinetic electronic garments focusing on self-expression [15]. Berglund et al. present a controllable, dynamic changing costume and extend this concept towards kinetic dynamics [33]. Jarusriboonchai et al. show a transforming dress that dynamically reveal and conceal areas of skin [34]. They also explore the design space of wearables for intimate communication [35]. The designed artifacts focus on wrist bands, earbuds etc. and are complimentary to the research presented here. We are not aware of any works presenting an open-source, wearable, kinetic display to express feelings.\nINTIMACY 2.0 which created by Daan Roosegaarde, is the dress made of smart fabrics which become clear when electrified by a quickening heartbeat. [36] Smoke dress is the garment being activated by proximity sensors. When someone steps\n7\n2. Related Works 2.5. Flower Design Reflect Emotion\ninto the personal space of the wearer, the dress creates a veil of smoke which can be smell and taste by people around it. [37] [38] Dobbelstein et al. present a wearable olfactory display allowing users to receive multiple computer generated scents related to notifications, reminders or other kinds of digital data [39]\nIridescence is an interactive collar, equipped with a facial tracking camera which will flip the colors and start to make patterns, in response to the movement of onlookers and their facial expressions. [40]\nThe ability to communicate things experienced through our other senses, such\nas smell, taste, and touch, has not been developed until recent years. [12]"
        },
        {
            "heading": "2.5. Flower Design Reflect Emotion",
            "text": "Flowers are also often used as a way to express emotions. Bernhaupt et al. included flowers in a game as a feedback mechanism on how much the user is smiling while playing a game [41]. Urui et al. use flower displays for memorials to express mourning and remembrance [42].\n8\nChapter 3\nEmolleia"
        },
        {
            "heading": "3.1. Concept and Final Design",
            "text": "Emolleia is a 3D printed emotive wearable which will recognize and respond to your facial expression. As you approach, Emolleia will dynamically perform happy, sad, surprise, neutral, disgust five emotions to correspondingly interact with you.\nThree blooming transparent flowers shape garment can be wearing around the shoulder. With a web camera turned on, the onlooker\u2019s facial expression will be detected and categorized, according to the facial expression, the Emolleia will\n9\n10\n3. Emolleia 3.2. Design Process\nperform five pre-definded correlated motion.\nOur initial intention was to design a simple accessory to express wearers mood in a given situation. We sought to explore more possibilities that people can do to express their emotion through not only facial or body language, but also non-verbal language and wearable computer. We especially wanted to target the upper body and shoulder region, as it\u2019s visible also in video calls and so far not so many accessories are worn on the shoulders. After consulting the related works and several focus group discussions, we settled on a flower design.\nThe application ideas from experts ranged from signaling the willingness/reluctance\nfor social interactions, over allowing interest matching in a party setting (flowers would represent the approximate match to the person you are closest to) to using the flowers as a socially acceptable shutter for a video camera (easy to see if it recording or not).\nWe sought to explore more possibilities that people can do to express their emotion through not only facial or body language, but also non-verbal language and wearable devices.\nEach of three flower has been equipped LED light unit inside in order to perform\ncolor change to express emotion.\nWe also provide users a software to let them monitor and customize the flower\u2019s motion and color of connected device (see Figure. 3.3). Users can set the motion triggered either by the groove sensor/buttons or interactive commands via serial communication such as Bluetooth and Wifi. The signal lines for each servo motor and RGB LED (NeoPixel compatible) are connected to the M5stack, and the power supply is 5[V] from an external power source such as a mobile battery. 3.3"
        },
        {
            "heading": "3.2. Design Process",
            "text": "We conducted several pilot studies, first using one flower to seethe animated motions. After expert feedback (2 designers, 4 wear-able computing researchers) we found that the expressiveness of a single flower was limiting and decided to add 2 more to represent movement patterns.\nWe also constructed a soft which allow wearer define there own animations.\nThe soft is still under testing process. 3.3\n11\n3. Emolleia 3.2. Design Process\n12\n3. Emolleia 3.2. Design Process"
        },
        {
            "heading": "3.2.1 Sketch",
            "text": "The sketch of \u2019Emolleia\u2019 was inspired by a poetry \u2019Shy Flower\u2019. \u201dTo the little shy flower hiding beneath brush petals extended smiles pink-white colors for the butterfly she drew\u201d The outlook of garment was designed in a poetic and arty way, the flower design was inspired by Diphylleia Rotans, also known as skeleton flower. The flower has white petals which turn transparent when it makes contact with water. [43]\nAccording to the result we got from previous pilot study, we selected to use\nmultiple flowers as it can be related to social interactions more."
        },
        {
            "heading": "3.2.2 Prototyping",
            "text": "Paper Prototype\n13\n3. Emolleia 3.2. Design Process\n14\n3. Emolleia 3.2. Design Process\nAs the test prototype, goal of this paper prototype is to try out different materials to see which one would work best as the main actuator for flower shape changing motion.\nIn order to perform petal opening and closing motion, a few of methods to actuate this kinetic movement have been considered. For example, using foldable structure like Kirigami, Origami or self-folding material as Shape Memory Alloy , magnetic or polymer swelling. Or inflatable structure by insert gas, normally air, helium, hydrogen or nitrogen.\nAfter few literature review and discussion, we firstly considered to use Nitinol, also known as memory or muscle wire, a shape memory alloy made of nickel and titanium once treated to acquire a specific shape, has the ability to indefinitely remember its geometry. [44] It performs quiet shape changing motion, with light weight would be ideal material for wearing on the body.\nShape memory alloys (SMAs) have been successfully commercialized in the\n15\n3. Emolleia 3.2. Design Process\nbiomedical, electrical, automotive, aerospace, and oil industries Since initially developed in the 1960s,. [45]It is the material that undergo a mechanical deformation under the influence of direct or indirect electrical stimuli. They are by nature dynamic, in addition to the static properties that we find in other conventional polymers or alloys. [46]\nThe idea of utilizing Nitinol wire as actuator to perform shape changing in wearables is not new, however the process is complicated. Before the test, the material needs to be constrained in the desire shape, we firstly fixed the wire as spring shape, continuously heat it up in 500\u00b0C for 30 seconds, then drown the wire into cold water to let it cool down to return the shape. After the shape-set process done, the Nitinol wire with silicon tube wrapping around would be attached on the paper petal surface, when a battery is connected to the ends, the metal gets hot and activated to the shape we formed beforehand. Meanwhile, the Nitinol wire will bring paper petal bend over with shape changing process.\nThe benefit of using SMA was due to SMA\u2019s special quality, unlike other mechanical structure, the whole moving process of the prototype was very quite. The heat up time also gained some special effect on presenting the subtle beautiful feeling of flower blooming. Which matches our design concept, performing the gentleness acceptance and rejection.\nHowever, the limitation was plain as well. As the Figure 3.2 & Figure 3.3 presented, after heaten up, the angle of bending petal was around 30 degree. It was obvious weak for flower open and close motion.\nSilicon Prototype\nIn the second prototype, we replaced paper to silicon as the material of flower, due to it\u2019s high plasticity which allows to attempt different aesthetic outlooks. Also, silicon is able to contact with Nitinol wire directly without necessarily being protected by another layer of tube. After comparison, we chose Silicon Sealant 8060 clear type.\nDuring the model making process, we found that shaped Nitinol wire was difficult to be planted in uncured silicon. The shaped Nitinol wire remained slightly curved spring shape which would penetrate through silicon surface.\nIn general, SMA is a great actuator to use, but considering the difficulty of equipping it in 3d printed model, and the limitation of using Nitinol, especially\n16\n3. Emolleia 3.2. Design Process\nthe degree of bending was slightly weak with 0-15-30 degree angle, we decide to replace it."
        },
        {
            "heading": "3.2.3 System Description",
            "text": "For final prototype, considering the movement\u2019s accuracy and product delicacy, we select 3d printing to develop the prototype.\nFigure 3.9 The 3d model of petal\nThe 3d model of flower petal (length: 43mm, thickness: 2mm, width:30mm), basement case and serve motor case were built in Fusion 360. A petal support (length: 15mm, width: 15mm, height 15mm) has also been built for holding 5 petals together and as the connector between flower itself with basement case.\nThe basement case (length: 42mm, width: 38mm, height:30mm) is created for containing servo motor, motion strings and wheel. The 4 small attached boxes (length:12mm, width, 12mm, height, 3mm) under were designed for placing magnets in order to attach every Emolleia part on the chain. This design was out of fashion consideration, for wearer is able to wear Emolleia in daily life.\nWe chose Form Labs Form 3 and Elastic 50A resin as printing material. Elasticity is the ability of an object or material to resume its normal shape after being stretched or compressed with high transparency. The softness of Elastic 50A allows the prototype has bending over and reform motion freely, the special transparency of this material also matched our designed sketch.\n17\n3. Emolleia 3.2. Design Process\nThe device was constructed by three main parts, flowers, servo motor case and Velcro strap to fix the device on body. The 3d printing flowers are fixed at the stem and consist of five petals with a diameter of 6 [cm] designed with a transparent resin with a hardness of 50 A (Elastic Resin).\nFlowers are connected with servo motor by strings on petals. With strings pulled off by the servo motor, the flower will close up. On the other hand, the blooming motion will be triggered when the servo motor loosen up the strings. These operations are controlled by M5Stack Core. The motor uses SG-90. The specially designed servo horn rotates in the range of 0-180 degree and can pull up a strings to 3.14[cm].\n18\n3. Emolleia 3.2. Design Process\n19\n3. Emolleia 3.2. Design Process\n20\n3. Emolleia 3.3. Pre-study"
        },
        {
            "heading": "3.3. Pre-study",
            "text": ""
        },
        {
            "heading": "3.3.1 Design Research",
            "text": "With billions of years of evolution, creatures have developed almost perfect structures and have exhibited various functions. [47] Poets and artists draw their inspiration from nature, scientist and engineers mimic creatures structure to better assist human construct living life.\nColor and shape changing in response to predators or mating process are not new for animals. The color change often helps animals communicate their mood or regulate body temperature.\nElytron, Seahorses change their color for camouflage or frighten predators, moon jellyfish switches color depending on what they have been eating lately, male reef octopuses, rapidly change from white to red to signal to females that they\u2019re ready to mate. 3.16\n21\n3. Emolleia 3.3. Pre-study\nOur color design followed the color wheel created by Plutchik\u2019s Model [1], the\ndetailed usage will be described in the last user study 2 section. 3.14\nAbout initial concept for shape changing part, the garment was considered to be designed as something representational like bird, butterfly or flower. The whole project is about using a poetic and arty method to convey user\u2019s message, the design of this wearable device should be gentle, beautiful and harmless. It is the garment to help user express their acceptance or rejection in the soft way.\nThe rhythm cuttlefish moves raised out interest. Cuttlefish have a fin fringe running along their sides. By undulating these fins cuttlefish are able to hover, crawl and swim. They can also move by \u2018jet propulsion\u2019, which can be an effective escape mechanism. [48] Inspired by the cuttlefish\u2019s movement, the first sketch came out. ?? However, out of the consideration of time and effort, we decided to move to the design with better notice and smaller size.\nWe also conducted a research on plants in order to find inspirations. Mimosa, well known as the plant represented as Shy, bashful, timid. When touched, Leaves of mimosa fold up, returning to full leaf in a few minutes. The motion of leaves usually being interpreted as \u2018shyness\u2019, which would be used in the garment design\n22\n3. Emolleia 3.3. Pre-study\nas symbol of wearer prefer to stay undisturbed.\nMimosa leaves close up successively gives people a strong image of social rejec-\ntion. This will be described detailed in pilot survey parts."
        },
        {
            "heading": "3.3.2 Pilot Survey",
            "text": "In order to find out which motion and color would be related to what interactive intention. A survey and pilot study have been conducted.\nIn the survey, we divided participants to extrovert and introvert by asking them finish the I-E scale. Through answering how much they feel connected to a statement via a 5-Likert scale (5 = Almost Always 4 = Frequently 3= Occasionally 2 = Rarely 1 = Almost Never 0 = Does not Apply).\nWe also made a questionnaire to find what kind of movement people can relate to social interactions the most and which basic shape they think can be used to describe the introvert and extrovert. The questionnaire was combined by 3 parts, demographic survey, I-E scale and interactive relation survey. In the second part, The I-E scale [49] was used to identify participant\u2019s characteristic into extrovert, introvert or Average. Most of participants were defined as AVERAGE or Like the Typical Member.\nIn the third part, we selected 3 botany movement GIF, the first one is an inflorescence (six flowers on the string in total) blooming successively blooming successively (length: 3 seconds), the second one is one flower open up (length: 5 seconds), the third one is mimosa leaves being touched on the top then close up successively (length: 5 seconds). After each of the GIF, participants were required to assess Which best describe the GIF through a 6-likert scale (1= introvert, 6= extrovert), and How well does this GIF relate to social interactions via a 7-Likert scale (1 = not at all, 7= very much). The purpose of this study is to see based on the introverted and extroverted tendency, how participants defined with different personality interpret these motions"
        },
        {
            "heading": "3.3.3 Result",
            "text": "Among 25 results we received, 96 percent participants consider mimosa close up movement represented introverts, 60 percent of participants related this motion\n23\n3. Emolleia 3.3. Pre-study\nwith social interactions the most.\nMore than 60 percent of participants consider the movement of inflorescence blooming to interpreted as extrovert, also more than 55 percent participants relate this successive movement with social interaction.\nHowever, participants have diverse opinion towards the GIF 2 with one flower\nopen motion.\nHence, for the garment design, we select 3 flowers\u2019 successive motion as main\ninteraction to express wearer\u2019s emotion."
        },
        {
            "heading": "3.3.4 Pilot Study",
            "text": "Participants completed the pilot study in a rented office room to simulate a social environment. The study was conducted in both standing and sitting position, where participants wore the prototype (with a single flower) on there left\n24\n3. Emolleia 3.3. Pre-study\nFigure 3.18 Pilot study set up 2\nshoulder.\nThe purpose of this pilot study is to evaluate how people would decode to the\nprototype\u2019s simple motion, and also the social acceptability of the prototype.\nThe prototype consisted of one 3d printed flower, a LED light performs red and blue light, a servo motor, a micro controller, a switch and portable battery. The initial prototype is able to preform simple open motion with red color and close motion with blue color controlled by wearer using a switch.\nWe simulated a social situation with 20 participants stay in one open room (10 female, aged 23-35), with beverage and food prepared to support the interaction better and more natural. Participants were asked to put mask on the whole session under the consideration of Covid-19. Before the session going, we only notify the wearers the meaning and function of Emolleia. When wearer wanted to be alone, he/she would choose close up the flower with dark blue lights on, in reverse, when he/she prefer interacting with others, they are able to choose the open-up flower motion.\n2 sessions in total have been conducted, each session lasted 30 minutes. In the beginning of every session, the wearer was asked to wear Emolliea around their left shoulder, with a switch hold in hand to control motion and light changing. The wearer was walking around the room and talking with other participants freely until the 30 minutes session over.\nIn the followup interview, we discovered most of participants are able to decode\n25\n3. Emolleia 3.3. Pre-study\nthe motion of flower open-up/ close-up as acceptance and rejection of further social interaction and most of participants are satisfied with wearing flower design wearable as both decoration and functional device. However, some of participants raised concern above color choosing on red as welcoming intention. The red color was interpreted danger sign of showing rejection and they would stay away and suggested to replace red as pink or orange.\nWe used the result in future study and updated final prototype.\n26\nChapter 4\nEvaluation"
        },
        {
            "heading": "4.1. Study 1: Emotion Elicitation",
            "text": "To explore potential use cases, self-expression possibilities and the general perception of the prototype, we conducted a user study.\nThe main purpose of this study was to measure how people perceive Emolleia\u2019s motion in relation to emotional states and gain more insight into what people would like to use this prototype for and estimate prototype\u2019s social acceptability in different contexts. We refer to the PAD model which categorizes emotional states by three dimensional scales: pleasant/valence, arousal and dominance. [50].\nLang et al. later develop a non-verbal pictorial self-assessment also known as\n27\n4. Evaluation 4.1. Study 1: Emotion Elicitation\nSAM (self assessment manikin) [6]. In our user study, we let subjects report their perceptions by SAM using a 5-likert scale (we are mostly interested in the valence and arousal dimensions, yet conducted the self-assessment according to related work) [51]. The study was conducted according to the rules and regulations of blinded for review with approval of the Ethics Committee."
        },
        {
            "heading": "4.1.1 Participants",
            "text": "We collected survey answers from 50 participants aged from 21 to 37 (Male: 26, Female: 19, Diverse: 2, Prefer not to say: 3). Most of the participants (83%) came from Asian countries"
        },
        {
            "heading": "4.1.2 Study Protocol",
            "text": "The survey takes approximately 20 minutes to complete. It consists of four\n28\n4. Evaluation 4.1. Study 1: Emotion Elicitation\nparts: 1) demographic questionnaire 2) personality test by the Introversion-Extroversion Scale (I-E scale) [52] 3) the device utility study 4) the device animation study.\nThe I-E Scale can assess if a participant is more introverted or extroverted by answering how much they feel connected to a statement via a 5-Likert scale (5 = Almost Always 4 = Frequently 3 = Occasionally 2 = Rarely 1 = Almost Never 0 = Doesn\u2019t Apply).\nIn the device utility study, we presented a 3-second video of one of our prototype\u2019s motions \u2013 one flower with simple open-up and close-up. We then asked questions about their general opinion, perceived function, and attitude towards this device. We asked participants willing to use the device to imagine the particular social contexts and under whose company they would like to wear it.\nIn the Animation study procedure, eight pre-recorded videos displaying different prototype on-body motions were shown to participants. Under each of the eight motion, participants were asked to rated the valence/arousal/dominance space of emotion using SAM on a 5-Likert scale where the participants choose one option from valence space (Pleasant, Pleased, Neutral, Unsatisfied, Unpleasant) arousal space (Excited, Wide-awake, Neutral, Dull, Calm) and dominance space (Dependent, Powerlessness, Neutral, Powerful, Independent) for rating three categories (pleasant/unpleasant and neutral) of motions [51].\nThe Animation Study was first planned as an in-person study. Yet, due to the COVID-19 pandemic, we decided to conduct it online. The participants were able to play back the pre-recorded eight prototype motion videos until they choose to move on to the next."
        },
        {
            "heading": "4.1.3 Results",
            "text": "We discover the participants\u2019 personality traits using the I-E scale. Among 50 participants, 27 participants were rated as average, 15 participants were rated as extremely introverted or more introverted than usual, and eight participants were rated as more extroverted than usual or extremely extroverted.\n69% of the participants showed a positive attitude towards wearing the device, one participant stated that \u201dI love wearing wearable devices and hope this helps to track my mood or mind.\u201d Some participants expressed concern towards the size and suggested it might be inconvenient to wear and would like to decide whether\n29\n4. Evaluation 4.1. Study 1: Emotion Elicitation\n30\n4. Evaluation 4.1. Study 1: Emotion Elicitation\nto wear it after knowing more about the functions. For social acceptance, 62% of the participants reported it was acceptable to wear it at home, with the question of accompanying selection, 47% of the participants would wear it under friends\u2019 company. 4.44.3\nTable. 4.1 reports descriptive statistics of reported SAM scores about eight motions. We operated repeated measures of ANOVA with Greenhouse-Geissers correction in SPSS to examine the scores\u2019 difference. There were statistically significant differences for valence ( F(4.84, 237.14) = 13.46, p \u00a1 .001) and arousal ( F(5.45, 267.11) = 38.28, p \u00a1 .001) across eight motion types. However, significant difference did not exist in the reported dominance ( F(4.40, 215.39) = 1.71, p =.14).\nFigure 4.3 and Figure 4.4 reported the valence and arousal mean value of eight motions. The values are mapped in Figure 4.5 for further discussion."
        },
        {
            "heading": "4.1.4 Discussion",
            "text": "We found extrovert showed stronger willingness to wear Emolleia than introvert and average. For other answers, we did not find obvious difference among introvert, average, and extrovert people.\nRegarding to the potential scenarios of wearing Emolleia, answers mainly re-\n31\n4. Evaluation 4.1. Study 1: Emotion Elicitation\nFigure 4.5 The mean value of Emolleia\u2019s arousal\nlates to self expressing (present wearer\u2019s mood, feeling, mental status, emotional arousal, social attitude) and notification purpose (weather or noise display, hygrometer, message notice, daily water drinking reminder, plant hydration levels monitor, fire detection). One participant suggested that \u201dIt could be a really good device for children with special conditions, such as autism, vision or hearing challenge. The children can use the device to show their willingness to talk or other emotional status.\u201d\nAmong all the feedback we received in survey, the most common usage scenario is to utility Emolleia for self expressing or social interaction to build deeper connection with others. For example:\n\u2022 I\u2019d love to know how my family is doing through this. Especially grandparents, as they\u2019re wellness is my strong interest.\n\u2022 Like the tail of a dog, it can be an enjoyable way to use for emotional communication. Also, based on the functionality of communication, seems\nthat the device can be diverted to medical care and counseling using.\n\u2022 can be a implicit inner world reflection to show others and connect with others with extimacy.\nWe also received some interesting answers regarding to utility as:\n\u2022 new type of conveyor belt sushi dish\n\u2022 Grab meat ball...\n32\n4. Evaluation 4.1. Study 1: Emotion Elicitation\n33\n4. Evaluation 4.2. Exhibition\n\u2022 Since I don\u2019t have many chances to see the moment when a flower blooms, a device that analyzes emotional changes caused by seeing the moment when\na flower opens and activates mental stability and brain movement.\nAs for the feasibility to communicate different emotional states, the results of repeated measures ANOVA proves shows the potential of using eight motions to convey different emotions. By mapping the average SAM score of eight motions to the valence-arousal coordinate space, we further have more insights into matching animated motions with emotional feelings (see Figure. 4.7). For example, flowers opening motions (motion a & h) would be perceived as the represent of pleasant, satisfied and serene. Closing motions (motion b & g) was interpreted as unsatisfied, frustrated and relaxed status . In general, the arousal of motion h and motion g which presented flowers opening/ closing together was noticeably stronger than motion a and b which represent the flowers opening/ closing successively. The quivering motions with higher speed (motion c & e) was perceived more pleasant and excited than quivering motions with lower speed (motion d & f)."
        },
        {
            "heading": "4.2. Exhibition",
            "text": "A facial tracking camera which programmed to recognize wearer\u2019s 7 facial expression (\u2019angry\u2019,\u2019disgust\u2019,\u2019fear\u2019,\u2019happy\u2019,\u2019sad\u2019,\u2019surprise\u2019,\u2019neutral\u2019) was placed to trigger three patterns Emolleia motion reaction, 1) correlated 2)in contrary 3) on looker\u2019s facial.\nDue to the results limitation of previous study, only five emotion \u2019happy, sad, surprise, neutral and disgust\u2019 have been selected to correlate with motion a, g, c, d, which related to the emotion defined as pleased, unsatisfied, calm, nervous, neutral five emotions from the previous study result. 4.1\nFor the color choice, we referred the Emotional Wheel created by Robert Plutchik.\n[31] The decided correlated final prototype as follow table.\nThe updated prototype Emolleia was presented in KMD Forum 2021. During the period of two days exhibition, we received many positive feedback from the audience.\n\u2022 \u201c Its beautiful, love the outlook\u201d\n34\n4. Evaluation 4.2. Exhibition\n35\n4. Evaluation 4.2. Exhibition\n36\n4. Evaluation 4.2. Exhibition\n37\n4. Evaluation 4.3. User study 2: Conversation Use Case"
        },
        {
            "heading": "4.3. User study 2: Conversation Use Case",
            "text": "The purpose of this study is to answer research question 3, \u201dWill participants who relatively express their opinions less than others be motivated to speak out their thought, and will participants who relatively talk more than others realize that those who talk less have something to say and offer them a chance to speak out?\u201d"
        },
        {
            "heading": "4.3.1 Participants",
            "text": "Six new participants (4 female, aged 21-28) was recruited. Most of Participants were from Asia countries."
        },
        {
            "heading": "4.3.2 Study Protocol",
            "text": "Before beginning the conversation task, participants were given a brief explanation about the procedure of the user study. The aim of the study was to answer the research question 3: Will participants who relatively express their opinions less than others be motivated to speak out their thought, and will participants who relatively talk more than others realize that those who talk less have something to say and offer them a chance to speak out?\nThe study consisted of 3 conversation sessions, each lasting 5 minutes. There were three conditions in the experiment: condition A - normal interaction (no\n38\n4. Evaluation 4.3. User study 2: Conversation Use Case\n39\n4. Evaluation 4.3. User study 2: Conversation Use Case\n40\n4. Evaluation 4.3. User study 2: Conversation Use Case\nwearable device), condition B \u2013 device present but not switched on and condition C \u2013 device present and switched on. A repeated measures design was used with each pair of participants taking part in each of the three conditions. [?] There was a moderator to observe the test process. After each session, participants rated a set of statements about the Emolleia\u2019 influence on attention and concentration, on natural behavior and on understandability of the emotional state of the wearer, also how much wearer feel wanting to express themselves more (than usual) on a 5 Likert scale (1 = strongly disagree, 5 = strongly agree).\nDuring the conversation sessions, one participant was asked to wear Emolleia, the web camera on the table will be turned toward wearer\u2019s face to recognize wearer\u2019s facial expression. After the facial expression got categorized by M5 stack, Emolleia would perform corresponding motion. 4.13 Every motion lasts 3 seconds long, before the next command received, Emolleia would stay stand-by mode with performing motion d with white color which categorized as expressive of neutral emotion.\nFollowing the conversation sessions, a semi-structured interview was conducted\nto collect qualitative feedback on the Emolleia from the participants."
        },
        {
            "heading": "4.3.3 Results",
            "text": "In the semi-structured interview after conversation test, we received some feedback:\n\u2022 Emolleia is an adorable device, it made me feel like being a flower.\n\u2022 It\u2019s such a nice thing to show how my mood changed through this equipment, I love the technological feeling.\n\u2022 With this device I feel more encouraged to express my emotion, I was literally laughing all the time when I see another person\u2019s reaction of watching\nEmolleia change motion.\n\u2022 It becomes easier for me to notice another person\u2019s emotion.\n41\n4. Evaluation 4.3. User study 2: Conversation Use Case"
        },
        {
            "heading": "4.3.4 Discussion",
            "text": "According to the comment received from participants, most of feedback are positive on both outlook and utility side. Participants who wear the device Emolleia found it decreased their nervous or uncomfortable on having a conversation with stranger. The conversation going better than they thought since they could interact with the device, and motions of Emolleia do assist to improve a more comfortable atmosphere of conversation.\nHowever, the imitation is also mentioned by participants during the semistructured interview. For example, one participant found that the noise of Emolleia performing motions might be a little loud as wearable device. The device is somehow quite distractive for wearer during the conversation.\nNot every participant is able to decode the emotion expression of Emolleia is also a key problem. Participant who doesn\u2019t wear the device sometimes got confused on what the current motion stands for, if the wearer is in happy or sad status.\nAnother concern is toward size of the device, some participant mentioned although Emolleia is a beautiful fashionable piece, it might still be inconvenient as a wearable people could wear in daily life.\n42\nChapter 5\nConclusion"
        },
        {
            "heading": "5.1. Finding",
            "text": "We introduced our novel kinetic wearable device which is able to performs eight pre-defined animated motions \u2013 Emolleia. We conducted a user study with 50 participants to elicit potential usages and social scenarios. We also collected their perceptions about eight animated motions by SAM scale to help us further improve our motion design. Feedback from the participants prove the feasibility of our concept about communicating emotional feelings via Emolleia.\nThen we selected 5 motions to match with facial expression, combined with the strong ground truth, Emolleia is capable of interacting with surroundings. We tested how Emolleia enhance people social interaction and self expression by conducting explorative cases study with 6 participants.\nAlthough using wearable computers to enhance social interaction is not new in HCI field, our study still brought up new sight on exploring how people would define prototype animation with emotion, and how well wearable device would be accepted in daily social context. Further more, it is a attempt on building a bridge between design, engineering, art and science. Wearable computers can be fashionable to wear, and accessory is capable of expressing emotions."
        },
        {
            "heading": "5.2. Limitation",
            "text": "Size: As some of feedback we collected from participants in User Study 1, the reason they have concerns on wearing the device was mainly due to the Emolleia\u2019s size. It might be tiny big for the device to wear in daily life, and wearer might be discreet when they wear it.\nPosition: Although participants didn\u2019t mention they feel uncomfortable wearing\n43\n5. Conclusion 5.3. Future Work\nthe device around shoulder, but we are considering other possibilities wear it more noticeably. Like around neck, wrist, or in front of chest, or probably on the head.\nEmotion trigger: So far we have tested two triggers: 1) proxemics sensor, 2)simple switch, 3) facial expression. Three of them are all categorized as interact in conscious. We are wondering would we get different perspective with unconscious by using bio-sensors to detect wearer\u2019s heart rate, EDA, EEG.\nMaterial: It would be interesting to test other flexible material to see the dif-\nferent movement.\nSystem implementation: we tried to use SMA to perform shape changing in the first prototype, and using strings to pull off & loose to perform flower blooming % closing movement as final method. But for sure there will have many methods to complete the same movement. We will be thrilled to test them out.\nOther than the limitations we mentioned above, although we have defined eight animations to let participants correlate them with emotions, also most of normal expressions can be corresponded to the motion, we still found that two important emotions were missing. There were no motion mapped in the quadrant of unpleasant and excited which represents regular emotion angry and fear. 4.2"
        },
        {
            "heading": "5.3. Future Work",
            "text": "Based on the limitations we found above, the first thing we may need to do is update prototype design, adjust it with smaller size. Then conduct a survey or interview with more participants on where they would like to wear this device on and why. According to the answers, analyse a better place for wearer. It would also be interesting to combine Emolleia with biometric sensors (heart rate/ galvanic skin response), in constant contact with the user as unconscious switch to trigger the motion change. We will also conduct further user studies in real-life social conditions to test the usability of our device.\nTo decrease the noise of servo motor make when Emolleia perform motions, we will try other actuator to perform shape changing. Inflatable material or electrical material would also be interesting to attempt in the future.\nWe made a soft for wearer to definite their own animations to express their emotions. We would like to conduct a user study with this function as well in the\n44\n5. Conclusion 5.3. Future Work\nfuture.\nIf the improvements above are implemented, Emolleia would be ready to wear on everyone in the society everyday. It is possible to see an upcoming wearable computers time when on-body device become one indispensable part of us to express ourselves emotion in daily life. Just like we use cellphone texting, use Emoji, meme or stamps to assist better emotion express.\nIn fact, although the main target of Emolleia are the type of shy introverts who want to interact with others but may lack of social skills, Emolleia can also be used for anyone who wants to interact with surroundings in a fun way or just simply assist wearer express themselves with more encourage.\n45"
        },
        {
            "heading": "A. Questionnaires",
            "text": "53\n6/29/2021 Wearable Emotion Expressing Device Design\nhttps://docs.google.com/forms/d/1QgsgSpDrUlVgYrSL1eHNUQZgeuUtE69MEW4vf-cSo7M/edit 1/8\n1.\n2.\nMark only one oval.\nFemale Male Prefer not to say\n3.\n4.\nMark only one oval.\nOther:\nLess than High School diploma High School Associate Degree Bachelor's Degree Master Degree Phd\nWearable Emotion Expressing Device Design\n*Required\nWhere are you from? *\nwhat's your gender? *\nwhat's your age *\nwhat's your highest educational level *\n6/29/2021 Wearable Emotion Expressing Device Design\nhttps://docs.google.com/forms/d/1QgsgSpDrUlVgYrSL1eHNUQZgeuUtE69MEW4vf-cSo7M/edit 2/8\n5.\nMark only one oval.\nAsian or Pacific Islander Black or African American Hispanic or Latino Native American or Alaskan Native White or Caucasian Multiricial or Biricial A race/ ethnicity not listed here\nThe I-E Scale\nDirections: Respond by indicating the degree to which each statement agrees with the perception you have of yourself. Record numbers 0-5 on the lines provided below, based on the following scale: 5 = Almost Always, 4 = Frequently, 3 = Occasionally, 2 = Rarely, 1 = Almost Never, 0 = Doesn\u2019t Apply\n6.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n7.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\nWhat do you consider your ethnicity to be? *\nA. I show individuality and originality in written reports. *\nB. I dislike test questions in which the information tested is in a different form from that in which it was learned. *\n6/29/2021 Wearable Emotion Expressing Device Design\nhttps://docs.google.com/forms/d/1QgsgSpDrUlVgYrSL1eHNUQZgeuUtE69MEW4vf-cSo7M/edit 3/8\n8.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n9.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n10.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n11.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\nC. I avoid exaggeration when sharing personal experiences. *\nD. I lose control when I get angry. *\nA. I engage in reflective, philosophical thought. *\nB. I prefer to have a theory or principle explained rather than studying it out for myself *\n6/29/2021 Wearable Emotion Expressing Device Design\nhttps://docs.google.com/forms/d/1QgsgSpDrUlVgYrSL1eHNUQZgeuUtE69MEW4vf-cSo7M/edit 4/8\n12.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n13.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n14.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n15.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\nC. I conceal disappointments. *\nD. I shed tears when I hear a sad story. *\nA. I spend leisure time reading poetry, stories, or plays. *\nB. I am uninterested in discussions of The Ideal Society. *\n6/29/2021 Wearable Emotion Expressing Device Design\nhttps://docs.google.com/forms/d/1QgsgSpDrUlVgYrSL1eHNUQZgeuUtE69MEW4vf-cSo7M/edit 5/8\n16.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n17.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\nHow would you relate the following images with social behavior?\nC. When people displease me, I refrain from saying anything. *\nD. I get excited when I argue. *\n6/29/2021 Wearable Emotion Expressing Device Design\nhttps://docs.google.com/forms/d/1QgsgSpDrUlVgYrSL1eHNUQZgeuUtE69MEW4vf-cSo7M/edit 6/8\n18.\nMark only one oval.\nintrovert\n1 2 3 4 5 6\nextrovert\n19.\nMark only one oval.\nnot at all\n1 2 3 4 5 6 7\nvery much\n20.\nMark only one oval.\nintrovert\n1 2 3 4 5 6\nextrovert\nWhich best describes this GIF? *\nHow well does this GIF relate to social interactions? *\nWhich best describes this GIF? *\n6/29/2021 Wearable Emotion Expressing Device Design\nhttps://docs.google.com/forms/d/1QgsgSpDrUlVgYrSL1eHNUQZgeuUtE69MEW4vf-cSo7M/edit 7/8\n21.\nMark only one oval.\nnot at all\n1 2 3 4 5 6 7\nvery much\n22.\nMark only one oval.\nintrovert\n1 2 3 4 5 6\nextrovert\n23.\nMark only one oval.\nnot at all\n1 2 3 4 5 6 7\nvery much\nHow well does this GIF relate to social interactions? *\nWhich best describes this GIF? *\nHow well does this GIF relate to social interactions? *\n6/29/2021 Wearable Emotion Expressing Device Design\nhttps://docs.google.com/forms/d/1QgsgSpDrUlVgYrSL1eHNUQZgeuUtE69MEW4vf-cSo7M/edit 8/8\nThis content is neither created nor endorsed by Google.\n\u00a0Forms\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 1/24\n1.\n2.\nMark only one oval.\nFemale / \u2f25\u6027 Male / \u7537\u6027 Prefer not to say / \u672a\u56de\u7b54\u5e0c\u671b Diverse / \u591a\u69d8\n3.\nwearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7 \u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\n*Required\nWhere are you from? / \u51fa\u8eab\u56fd *\nwhat's your gender? / \u6027\u5225 *\nwhat's your age / \u5e74\u9f62 *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 2/24\n4.\nMark only one oval.\nOther:\nLess than High School diploma / \u4e2d\u5b66\u6821 High School / \u2fbc\u6821 Associate Degree / \u51c6\u5b66\u2f20 Bachelor's Degree / \u2f24\u5b66(\u5b66\u2f20\uff09 Master Degree / \u4fee\u2f20 Phd / \u535a\u2f20\nThe I-E Scale\nDirections: Respond by indicating the degree to which each statement agrees with the perception you have of yourself. Record numbers 0-5 on the lines provided below, based on the following scale: 0 = Doesn\u2019t Apply , 1 = Almost Never , 2 = Rarely , 3 = Occasionally, 4 = Frequently, 5 = Almost Always \u6307\u793a: \u5404\u8cea\u554f\u5185\u5bb9\u306e\u72b6\u6cc1\u306b\u5bfe\u3057\u3066\u3001\u3042\u306a\u305f\u304c\u2f83\u5206\u2f83\u8eab\u306b\u3064\u3044\u3066\u6301\u3063\u3066\u3044\u308b\u8a8d\u8b58\u3068\u2f50\u3079\u3066\u3001\u3069\u306e \u7a0b\u5ea6\u540c\u610f\u3067\u304d\u308b\u304b\u6559\u3048\u3066\u304f\u3060\u3055\u3044\u3002 \u6b21\u306e\u30b9\u30b1\u30fc\u30eb\u306b\u57fa\u3065\u3044\u3066\u30010\u301c5\u756a\u306e\u3044\u305a\u308c\u304b\u3092\u9078\u629e\u3057\u3066\u304f\u3060\u3055\u3044\u3002 0 = \u5f53\u3066\u306f\u307e\u3089\u306a\u3044\u30011 = \u307b\u3068\u3093\u3069\u306a\u3044\u30012 = \u3081\u3063\u305f\u306b\u306a\u3044\u30013 = \u3068\u304d\u3069\u304d\u3042\u308b\u30014 = \u983b\u7e41\u306b\u3042 \u308b\u30015 = \u5e38\u306b\u3042\u308b\n5.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\nwhat's your highest educational level / \u6700\u7d42\u5b66\u6b74 *\nA. I show individuality and originality in written reports. \u30ec\u30dd\u30fc\u30c8\u3092\u66f8\u304f\u969b\u306b\u306f\u2f83\u5206\u306e \u30aa\u30ea\u30b8\u30ca\u30ea\u30c6\u30a3\u3092\u767a\u63ee\u3059\u308b\u3002 *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 3/24\n6.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n7.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n8.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n9.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\nB. I dislike test questions in which the information tested is in a different form from that in which it was learned. / \u30c6\u30b9\u30c8\u306b\u51fa\u984c\u3055\u308c\u305f\u554f\u984c\u304c\u3001\u5b66\u7fd2\u3057\u305f\u7bc4\u56f2\u3068\u9055\u3046\u5f62\u5f0f \u3067\u51fa\u984c\u3055\u308c\u308b\u306e\u304c\u5acc\u3044\u3067\u3042\u308b\u3002 *\nC. I avoid exaggeration when sharing personal experiences. / \u500b\u2f08\u7684\u306a\u7d4c\u9a13\u3092\u5171\u6709\u3059 \u308b\u3068\u304d\u306b\u3001\u8a71\u3092\u8a87\u5f35\u3059\u308b\u3053\u3068\u3092\u907f\u3051\u308b\u3002 *\nD. I lose control when I get angry. / \u6012\u308b\u3068\u2f83\u5236\u2f3c\u3092\u5931\u3063\u3066\u3057\u307e\u3046\u3002 *\nA. I engage in reflective, philosophical thought. / \u79c1\u306f\u719f\u616e\u7684\u3067\u3042\u308a\u3001\u54f2\u5b66\u7684\u306a\u8003\u3048\u3092 \u6301\u3063\u3066\u3044\u307e\u3059\u3002 *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 4/24\n10.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n11.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n12.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n13.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\nB. I prefer to have a theory or principle explained rather than studying it out for myself / \u2f83\u5206\u3067\u52c9\u5f37\u3059\u308b\u3088\u308a\u3082\u3001\u7406\u8ad6\u3084\u539f\u7406\u3092\u8aac\u660e\u3057\u3066\u3082\u3089\u3046\u3053\u3068\u3092\u597d\u3080 *\nC. I conceal disappointments. / \u304c\u3063\u304b\u308a\u3057\u305f\u3053\u3068\u306a\u3069\u3092\u96a0\u3057\u3066\u3057\u307e\u3046\u3002 *\nD. I shed tears when I hear a sad story. / \u60b2\u3057\u3044\u8a71\u3092\u805e\u304f\u3068\u6d99\u304c\u3053\u307c\u308c\u308b\u3002 *\nA. I spend leisure time reading poetry, stories, or plays. / \u79c1\u306f\u6687\u306a\u6642\u306b\u8a69\u3001\u7269\u8a9e\u3092\u8aad \u3093\u3060\u308a\u6f14\u5287\u3092\u2f92\u305f\u308a\u3059\u308b\u3002 *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 5/24\n14.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n15.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\n16.\nMark only one oval.\nDoesn\u2019t Apply\n0 1 2 3 4 5\nAlmost Always\nUtility / \u5b9f\u2f64\u6027\nB. I am uninterested in discussions of The Ideal Society. / \u79c1\u306f\u7406\u60f3\u7684\u306a\u793e\u4f1a\u3078\u306e\u8b70\u8ad6 \u306b\u8208\u5473\u304c\u3042\u308a\u307e\u305b\u3093\u3002 *\nC. When people displease me, I refrain from saying anything. / \u2f08\u306b\u5acc\u308f\u308c\u305f\u3068\u304d \u306f\u3001\u4f55\u3082\u2f94\u308f\u305a\u306b\u96e2\u308c\u308b\u3002 *\nD. I get excited when I argue. / \u2f94\u3044\u4e89\u3044\u306e\u6642\u306b\u30a8\u30ad\u30b5\u30a4\u30c8\u3059\u308b\u3002 *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 6/24\n17.\n18.\nWhat do you think the functionality of the device is? (What does it display?) / \u3053\u306e \u30c7\u30d0\u30a4\u30b9\u306e\u6a5f\u80fd\u306f\u4f55\u3060\u3068\u601d\u3044\u307e\u3059\u304b? \uff08\u4f55\u3092\u8868\u73fe\u3057\u3066\u3044\u308b\u3068\u601d\u3044\u307e\u3059\u304b\uff1f\uff09 *\nCan you imagine a new use for the device? Assuming you can connect the movements of the flowers to any kind of information/ data. / \u3053\u306e\u30c7\u30d0\u30a4\u30b9\u306e\u65b0\u3057\u3044 \u2f64\u9014\u3092\u60f3\u50cf\u3067\u304d\u307e\u3059\u304b? \u82b1\u3073\u3089\u306e\u52d5\u304d\u3092\u3042\u3089\u3086\u308b\u7a2e\u985e\u306e\u60c5\u5831\u30fb\u30c7\u30fc\u30bf\u306b\u7d50\u3073\u3064\u3051\u308b \u3053\u3068\u304c\u3067\u304d\u308b\u3068\u4eee\u5b9a\u3057\u307e\u3059\u3002 *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 7/24\n19.\n20.\nOther:\nTick all that apply.\nhome / \u2f83\u5b85 party /\u30d1\u30fc\u30c6\u30a3 public transportation / \u516c\u5171\u4ea4\u901a\u6a5f\u95a2 work / \u4ed5\u4e8b\u4e2d restaurant / \u30ec\u30b9\u30c8\u30e9\u30f3\n21.\nMark only one oval.\nYes / \u306f\u3044 No / \u3044\u3044\u3048 Maybe / \u591a\u5206\n22.\nWould you use the device? If so for what? / \u3053\u306e\u30c7\u30d0\u30a4\u30b9\u3092\u4f7f\u2f64\u3057\u305f\u3044\u3067\u3059\u304b\uff1f \u3082 \u3057\u305d\u3046\u306a\u3089\u4f55\u306e\u305f\u3081\u306b\u5229\u2f64\u3057\u305f\u3044\u3067\u3059\u304b\uff1f *\nIn which social contexts can you see the device being used? / \u3069\u306e\u72b6\u6cc1\u3067\u30c7\u30d0\u30a4\u30b9 \u304c\u4f7f\u2f64\u3055\u308c\u3066\u3044\u308b\u3068\u601d\u3044\u307e\u3059\u304b? *\nWould you wear the device? / \u3042\u306a\u305f\u306f\u30c7\u30d0\u30a4\u30b9\u3092\u88c5\u7740\u3057\u307e\u3059\u304b\uff1f\nWhy? Why not? / \u306f\u3044\u3001\u3044\u3044\u3048\u305d\u308c\u305e\u308c\u306e\u7406\u7531\u3092\u6559\u3048\u3066\u304f\u3060\u3055\u3044\u3002 *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 8/24\n23.\nOther:\nTick all that apply.\nfriend / \u53cb\u2f08 family / \u5bb6\u65cf partner / \u30d1\u30fc\u30c8\u30ca\u30fc alone / \u2f00\u2f08 colleaguess / \u540c\u50da strangers / \u2f92\u77e5\u3089\u306c\u2f08\nAnimations Pleases select in the range of 1-5 according to what you feel from the GIF.\u2f83\u8eab\u304c\u611f\u3058\u308b \u611f\u60c5\u53ca\u3073\u611f\u899a\u30671-5\u306e\u7bc4\u56f2\u3067\u7b54\u3048\u3066\u304f\u3060\u3055\u3044\u3002\nWho would you be willing to use this product under the company? / \u3053\u306e\u88fd\u54c1\u3092\u4f7f\u2f64 \u3057\u3066\u3044\u308b\u2f08\u304c\u3044\u308b\u3068\u3057\u305f\u3089\u8ab0\u3067\u3059\u304b? *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 9/24\n24.\nMark only one oval.\n1 2 3 4 5\n25.\nMark only one oval.\n1 2 3 4 5\n*\n\u30a8\u30ad\u30b5\u30a4\u30c8 - \u7a4f\u3084\u304b *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 10/24\n26.\nMark only one oval.\n1 2 3 4 5\n\u5916\u90e8\u304b\u3089\u5236\u5fa1\u3055\u308c\u3066\u3044\u308b- \u2f83\u5206\u3067\u5236\u5fa1\u3057\u3066\u3044\u308b *\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 11/24\n27.\nMark only one oval.\n1 2 3 4 5\n28.\nMark only one oval.\n1 2 3 4 5\n*\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 12/24\n29.\nMark only one oval.\n1 2 3 4 5\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 13/24\n30.\nMark only one oval.\n1 2 3 4 5\n31.\nMark only one oval.\n1 2 3 4 5\n*\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 14/24\n32.\nMark only one oval.\n1 2 3 4 5\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 15/24\n33.\nMark only one oval.\n1 2 3 4 5\n34.\nMark only one oval.\n1 2 3 4 5\n*\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 16/24\n35.\nMark only one oval.\n1 2 3 4 5\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 17/24\n36.\nMark only one oval.\n1 2 3 4 5\n37.\nMark only one oval.\n1 2 3 4 5\n*\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 18/24\n38.\nMark only one oval.\n1 2 3 4 5\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 19/24\n39.\nMark only one oval.\n1 2 3 4 5\n40.\nMark only one oval.\n1 2 3 4 5\n*\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 20/24\n41.\nMark only one oval.\n1 2 3 4 5\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 21/24\n42.\nMark only one oval.\n1 2 3 4 5\n43.\nMark only one oval.\n1 2 3 4 5\n*\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 22/24\n44.\nMark only one oval.\n1 2 3 4 5\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 23/24\n45.\nMark only one oval.\n1 2 3 4 5\n46.\nMark only one oval.\n1 2 3 4 5\n*\n*\n6/29/2021 wearable device survey\uff08\u30a6\u30a7\u30a2\u30e9\u30d6\u30eb\u30c7\u30d0\u30a4\u30b9\u306b\u5bfe\u3059\u308b\u8abf\u67fb\uff09\nhttps://docs.google.com/forms/d/1r0ft1GQthIn8EQs087GQGlE_T20wzs7aD7KjjwYpoCw/edit 24/24\n47.\nMark only one oval.\n1 2 3 4 5\nThis content is neither created nor endorsed by Google.\n*\n\u00a0Forms"
        }
    ],
    "title": "Emolleia \u2013 Wearable Kinetic Flower Display for Expressing Emotions",
    "year": 2024
}