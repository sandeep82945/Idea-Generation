"In this work, we propose 3D PGT, an automated fusion framework that contains multiple generative 3D pre-training tasks to obtain an effective pre-trained 2D graph encoder 𝑓𝜃 ∗ (·). 3D PGT focuses on 1. Designing multiple generative pre-training tasks that can benefit downstream tasks where 3D information is not available; 2. Bridging the gap between 3D generative pre-training tasks and downstream property prediction, allowing a wider range of downstream tasks to benefit from pre-training."

"In Section 3.2, we propose a surrogate metric based on total energy to search the adaptive weight of each generative pre-training task. To verify its effectiveness, we design an ablation study by pre-training a variant of average pre-training."

"The experiment we designed proves that the potential geometric prior is not only beneficial to quantum chemical property prediction, but also to the prediction in pharmacology, physical chemistry and biophysics, etc."

"Moreover, 3D PGT outperforms all baselines from top solutions for large-scale molecular prediction in OGB leaderboard."