{
    "abstractText": "In recent years, smart meters have been widely adopted by electricity suppliers to improve the management of the smart grid system. These meters usually collect energy consumption data at a very low frequency (every 30min), enabling utilities to bill customers more accurately. To provide more personalized recommendations, the next step is to detect the appliances owned by customers, which is a challenging problem, due to the very-low meter reading frequency. Even though the appliance detection problem can be cast as a time series classification problem, with many such classifiers having been proposed in the literature, no study has applied and compared them on this specific problem. This paper presents an in-depth evaluation and comparison of state-of-the-art time series classifiers applied to detecting the presence/absence of diverse appliances in very low-frequency smart meter data. We report results with five real datasets. We first study the impact of the detection quality of 13 different appliances using 30min sampled data, and we subsequently propose an analysis of the possible detection performance gain by using a higher meter reading frequency. The results indicate that the performance of current time series classifiers varies significantly. Some of them, namely deep learning-based classifiers, provide promising results in terms of accuracy (especially for certain appliances), even using 30min sampled data, and are scalable to the large smart meter time series collections of energy consumption data currently available to electricity suppliers. This paper appeared in ACM e-Energy 2023.",
    "authors": [
        {
            "affiliations": [],
            "name": "Adrien Petralia"
        },
        {
            "affiliations": [],
            "name": "Philippe Charpentier"
        },
        {
            "affiliations": [],
            "name": "Paul Boniol"
        },
        {
            "affiliations": [],
            "name": "Themis Palpanas"
        }
    ],
    "id": "SP:0aa9251017c04084d2dc42bbba21ade31170f28a",
    "references": [
        {
            "authors": [
                "Adrian Albert",
                "Ram Rajagopal"
            ],
            "title": "Smart Meter Driven Segmentation: What Your Consumption Says About You",
            "venue": "IEEE Transactions on Power Systems 28,",
            "year": 2013
        },
        {
            "authors": [
                "Hunt Allcott"
            ],
            "title": "Social norms and energy conservation",
            "venue": "Journal of Public Economics 95,",
            "year": 2011
        },
        {
            "authors": [
                "Muzaffer Aslan",
                "Ebra Nur Zurel"
            ],
            "title": "An efficient hybridmodel for appliances classification based on time series features",
            "venue": "Energy and Buildings",
            "year": 2022
        },
        {
            "authors": [
                "Anthony Bagnall",
                "Aaron Bostrom",
                "James Large",
                "Jason Lines"
            ],
            "title": "The Great Time Series Classification Bake Off: An Experimental Evaluation of Recently Proposed Algorithms",
            "venue": "Extended Version",
            "year": 2016
        },
        {
            "authors": [
                "Gouri R. Barai",
                "Sridhar Krishnan",
                "Bala Venkatesh"
            ],
            "title": "Smart metering and functionalities of smart meters in smart grid - a review",
            "venue": "IEEE Electrical Power and Energy Conference (EPEC). 138\u2013145",
            "year": 2015
        },
        {
            "authors": [
                "Paul Boniol",
                "Mohammed Meftah",
                "Emmanuel Remy",
                "Themis Palpanas"
            ],
            "title": "DCAM: Dimension-Wise Class Activation Map for Explaining Multivariate Data Series Classification",
            "venue": "In Proceedings of the 2022 International Conference on Management of Data (Philadelphia, PA, USA) (SIGMOD \u201922)",
            "year": 2022
        },
        {
            "authors": [
                "L Breiman"
            ],
            "title": "2001",
            "venue": "Random Forests. Machine Learning 45 ",
            "year": 2001
        },
        {
            "authors": [
                "Deepika R. Chavan",
                "Dagadu S. More",
                "Amruta M. Khot"
            ],
            "title": "IEDL: Indian Energy Dataset with Low frequency for NILM",
            "venue": "Energy Reports",
            "year": 2022
        },
        {
            "authors": [
                "Stanislav Chren",
                "Bruno Rossi",
                "Tom\u00e1\u0161 Pitner"
            ],
            "title": "Smart grids deployments within EU projects: The role of smart meters",
            "venue": "In 2016 Smart Cities Symposium Prague (SCSP)",
            "year": 2016
        },
        {
            "authors": [
                "T. Cover",
                "P. Hart"
            ],
            "title": "1967",
            "venue": "Nearest neighbor pattern classification. IEEE Transactions on Information Theory 13, 1 ",
            "year": 1967
        },
        {
            "authors": [
                "Hoang Anh Dau",
                "Anthony Bagnall",
                "Kaveh Kamgar",
                "Chin-Chia Michael Yeh",
                "Yan Zhu",
                "Shaghayegh Gharghabi",
                "Chotirat Ann Ratanamahatana",
                "Eamonn Keogh"
            ],
            "title": "The UCR Time Series Archive",
            "year": 2018
        },
        {
            "authors": [
                "Angus Dempster",
                "Fran\u00e7ois Petitjean",
                "Geoffrey I. Webb"
            ],
            "title": "ROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels",
            "venue": "CoRR abs/1910.13051 (2019)",
            "year": 2019
        },
        {
            "authors": [
                "Angus Dempster",
                "Daniel F Schmidt",
                "Geoffrey I Webb"
            ],
            "title": "MiniRocket: A Very Fast (Almost) Deterministic Transform for Time Series Classification",
            "venue": "In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. ACM,",
            "year": 2021
        },
        {
            "authors": [
                "Chunyu Deng",
                "KeheWu",
                "BinbinWang"
            ],
            "title": "Residential Appliance Detection Using Attention-based Deep Convolutional Neural Network",
            "venue": "CSEE Journal of Power and Energy Systems 8,",
            "year": 2022
        },
        {
            "authors": [
                "Houtao Deng",
                "George Runger",
                "Eugene Tuv",
                "Martyanov Vladimir"
            ],
            "title": "A Time Series Forest for Classification and Feature Extraction",
            "year": 2013
        },
        {
            "authors": [
                "G\u00fcnther Eibl",
                "Dominik Engel"
            ],
            "title": "Influence of Data Granularity on Smart Meter Privacy",
            "venue": "IEEE Transactions on Smart Grid 6,",
            "year": 2015
        },
        {
            "authors": [
                "Hassan Ismail Fawaz",
                "Benjamin Lucas",
                "Germain Forestier",
                "Charlotte Pelletier",
                "Daniel F. Schmidt",
                "JonathanWeber",
                "Geoffrey I. Webb",
                "Lhassane Idoumghar",
                "Pierre- Alain Muller",
                "Fran\u00e7ois Petitjean"
            ],
            "title": "InceptionTime: Finding AlexNet for time series classification",
            "venue": "Data Mining and Knowledge Discovery 34,",
            "year": 2020
        },
        {
            "authors": [
                "G.W. Hart"
            ],
            "title": "1992",
            "venue": "Nonintrusive appliance load monitoring. Proc. IEEE 80, 12 ",
            "year": 1992
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep Residual Learning for Image Recognition",
            "year": 2015
        },
        {
            "authors": [
                "J. Hills",
                "J. Lines",
                "E. Baranauskas"
            ],
            "title": "et al",
            "venue": "2014. Classification of time series by shapelet transformation. Data Min Knowl Disc 28 ",
            "year": 2014
        },
        {
            "authors": [
                "P.A. Hohne",
                "K. Kusakana",
                "B.P. Numbi"
            ],
            "title": "2019",
            "venue": "A review of water heating technologies: An application to the South African context. Energy Reports 5 ",
            "year": 2019
        },
        {
            "authors": [
                "Patrick Huber",
                "Alberto Calatroni",
                "Andreas Rumsch",
                "Andrew Paice"
            ],
            "title": "Review on Deep Neural Networks Applied to Low-Frequency NILM",
            "venue": "Energies 14,",
            "year": 2021
        },
        {
            "authors": [
                "Sergey Ioffe",
                "Christian Szegedy"
            ],
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "year": 2015
        },
        {
            "authors": [
                "Hassan Ismail Fawaz",
                "Germain Forestier",
                "Jonathan Weber",
                "Lhassane Idoumghar",
                "Pierre-Alain Muller"
            ],
            "title": "Deep Learning for Time Series Classification: A Review",
            "venue": "Data Min. Knowl. Discov. 33,",
            "year": 2019
        },
        {
            "authors": [
                "Matthias Kahl",
                "Daniel Jorde",
                "Hans-Arno Jacobsen"
            ],
            "title": "Representation Learning for Appliance Recognition: A Comparison to Classical Machine Learning",
            "year": 2022
        },
        {
            "authors": [
                "Matthias Kahl",
                "Anwar Ul Haq",
                "Thomas Kriechbaumer",
                "Hans-Arno Jacobsen"
            ],
            "title": "A Comprehensive Feature Study for Appliance Recognition on High Frequency Energy Data. In Proceedings of the Eighth International Conference on Future Energy Systems (Shatin, Hong Kong) (e-Energy \u201917)",
            "venue": "Association for Computing Machinery,",
            "year": 2017
        },
        {
            "authors": [
                "Maria Kaselimi",
                "Eftychios Protopapadakis",
                "Athanasios Voulodimos",
                "Nikolaos Doulamis",
                "Anastasios Doulamis"
            ],
            "title": "Towards Trustworthy Energy Disaggregation: A Review of Challenges, Methods, and Perspectives for Non-Intrusive Load Monitoring",
            "venue": "Sensors",
            "year": 2022
        },
        {
            "authors": [
                "Jack Kelly",
                "William Knottenbelt"
            ],
            "title": "Neural NILM",
            "venue": "In Proceedings of the 2nd ACM International Conference on Embedded Systems for Energy-Efficient Built Environments. ACM",
            "year": 2015
        },
        {
            "authors": [
                "Jack Kelly",
                "William Knottenbelt"
            ],
            "title": "The UK-DALE dataset, domestic appliance-level electricity demand and whole-house demand from five UK homes",
            "venue": "Scientific Data",
            "year": 2015
        },
        {
            "authors": [
                "J. Zico Kolter"
            ],
            "title": "REDD : A Public Data Set for Energy Disaggregation Research",
            "year": 2011
        },
        {
            "authors": [
                "Pauline Laviron",
                "Xueqi Dai",
                "B\u00e9r\u00e9nice Huquet",
                "Themis Palpanas"
            ],
            "title": "Electricity Demand Activation Extraction: From Known to Unknown Signatures, Using Similarity Search",
            "venue": "The Twelfth ACM International Conference on Future Energy Systems, Virtual Event, Torino, Italy,",
            "year": 2021
        },
        {
            "authors": [
                "Jason Lines",
                "Sarah Taylor",
                "Anthony Bagnall"
            ],
            "title": "HIVE-COTE: The Hierarchical Vote Collective of Transformation-Based Ensembles for Time Series Classification",
            "venue": "In 2016 IEEE 16th International Conference on Data Mining (ICDM)",
            "year": 2016
        },
        {
            "authors": [
                "Yu Liu",
                "Congxiao Liu",
                "Yiwen Shen",
                "Xin Zhao",
                "Shan Gao",
                "Xueliang Huang"
            ],
            "title": "Non-intrusive energy estimation using random forest based multi-label classification and integer linear programming",
            "venue": "Energy Reports",
            "year": 2021
        },
        {
            "authors": [
                "Carl H Lubba",
                "Sarab S Sethi",
                "Philip Knaute",
                "Simon R Schultz",
                "Ben D Fulcher",
                "Nick S Jones"
            ],
            "title": "catch22: CAnonical Time-series CHaracteristics",
            "year": 2019
        },
        {
            "authors": [
                "Markus L\u00f6ning",
                "Anthony Bagnall",
                "Sajaysurya Ganesh",
                "Viktor Kazakov",
                "Jason Lines",
                "Franz J. Kir\u00e1ly"
            ],
            "title": "sktime: A Unified Interface for Machine Learning with Time Series",
            "year": 2019
        },
        {
            "authors": [
                "Matthew Middlehurst",
                "James Large",
                "Anthony Bagnall"
            ],
            "title": "The Canonical Interval Forest (CIF) Classifier for Time Series Classification",
            "venue": "IEEE International Conference on Big Data (Big Data)",
            "year": 2020
        },
        {
            "authors": [
                "Matthew Middlehurst",
                "James Large",
                "Anthony J. Bagnall"
            ],
            "title": "The Canonical Interval Forest (CIF) Classifier for Time Series Classification",
            "venue": "CoRR abs/2008.09172 (2020)",
            "year": 2020
        },
        {
            "authors": [
                "Matthew Middlehurst",
                "James Large",
                "Michael Flynn",
                "Jason Lines",
                "Aaron Bostrom",
                "Anthony J. Bagnall"
            ],
            "title": "HIVE-COTE 2.0: a new meta ensemble for time series classification",
            "venue": "CoRR abs/2104.07551",
            "year": 2021
        },
        {
            "authors": [
                "Megan Milam",
                "G. Kumar Venayagamoorthy"
            ],
            "title": "Smart meter deployment: US initiatives",
            "venue": "ISGT",
            "year": 2014
        },
        {
            "authors": [
                "Ayumu Miyasawa",
                "Yu Fujimoto",
                "Yasuhiro Hayashi"
            ],
            "title": "Energy disaggregation based on smart metering data via semi-binary nonnegative matrix factorization",
            "venue": "Energy and Buildings",
            "year": 2019
        },
        {
            "authors": [
                "Keiron O\u2019Shea",
                "Ryan Nash"
            ],
            "title": "An Introduction to Convolutional Neural Networks",
            "venue": "CoRR abs/1511.08458",
            "year": 2015
        },
        {
            "authors": [
                "Francesca Paradiso",
                "Federica Paganelli",
                "Antonio Luchetta",
                "Dino Giuli",
                "Pino Castrogiovanni"
            ],
            "title": "ANN-based appliance recognition from low-frequency energy monitoring data",
            "venue": "IEEE 14th International Symposium on \"A World of Wireless, Mobile and Multimedia Networks\" (WoWMoM)",
            "year": 2013
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga",
                "Alban Desmaison",
                "Andreas K\u00f6pf",
                "Edward Yang",
                "Zach DeVito",
                "Martin Raison",
                "Alykhan Tejani",
                "Sasank Chilamkurthy",
                "Benoit Steiner",
                "Lu Fang",
                "Junjie Bai",
                "Soumith Chintala"
            ],
            "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
            "year": 2019
        },
        {
            "authors": [
                "Leitao Qu",
                "Yaguang Kong",
                "Meng Li",
                "Wei Dong",
                "Fan Zhang",
                "Hongbo Zou"
            ],
            "title": "A residual convolutional neural network with multi-block for appliance recognition in non-intrusive load identification",
            "venue": "Energy and Buildings",
            "year": 2023
        },
        {
            "authors": [
                "Florian Rossier",
                "Philippe Lang",
                "Jean Hennebert"
            ],
            "title": "Near Real-Time Appliance Recognition Using Low FrequencyMonitoring and Active LearningMethods",
            "venue": "Energy Procedia",
            "year": 2017
        },
        {
            "authors": [
                "H. Sakoe",
                "S. Chiba"
            ],
            "title": "1978",
            "venue": "Dynamic programming algorithm optimization for spoken word recognition. IEEE Transactions on Acoustics, Speech, and Signal Processing 26, 1 ",
            "year": 1978
        },
        {
            "authors": [
                "Robert E Schapire"
            ],
            "title": "Explaining adaboost",
            "year": 2013
        },
        {
            "authors": [
                "Patrick Sch\u00e4fer"
            ],
            "title": "The BOSS is concerned with time series classification in the presence of noise. Data Mining and Knowledge Discovery",
            "year": 2015
        },
        {
            "authors": [
                "Patrick Sch\u00e4fer",
                "Mikael H\u00f6gqvist"
            ],
            "title": "SFA: A symbolic fourier approximation and index for similarity search in high dimensional datasets",
            "venue": "ACM International Conference Proceeding Series,",
            "year": 2012
        },
        {
            "authors": [
                "Ahmed Shifaz",
                "Charlotte Pelletier",
                "Fran\u00e7ois Petitjean",
                "Geoffrey I. Webb"
            ],
            "title": "TS-CHIEF: A Scalable and Accurate Forest Algorithm for Time Series Classification",
            "venue": "CoRR abs/1906.10329 (2019)",
            "year": 2019
        },
        {
            "authors": [
                "K Simonyan",
                "A Zisserman"
            ],
            "title": "2015",
            "venue": "Very deep convolutional networks for largescale image recognition. 3rd International Conference on Learning Representations ",
            "year": 2015
        },
        {
            "authors": [
                "Stavros Sykiotis",
                "Maria Kaselimi",
                "Anastasios Doulamis",
                "Nikolaos Doulamis"
            ],
            "title": "ELECTRIcity: An Efficient Transformer for Non-Intrusive Load Monitoring",
            "venue": "Sensors 22,",
            "year": 2022
        },
        {
            "authors": [
                "Christian Szegedy",
                "Wei Liu",
                "Yangqing Jia",
                "Pierre Sermanet",
                "Scott Reed",
                "Dragomir Anguelov",
                "Dumitru Erhan",
                "Vincent Vanhoucke",
                "Andrew Rabinovich"
            ],
            "title": "Going Deeper with Convolutions",
            "year": 2014
        },
        {
            "authors": [
                "Seyed Mostafa Tabatabaei",
                "Scott Dick",
                "Wilsun Xu"
            ],
            "title": "Toward Non- Intrusive Load Monitoring via Multi-Label Classification",
            "venue": "IEEE Transactions on Smart Grid 8,",
            "year": 2017
        },
        {
            "authors": [
                "Zhiguang Wang",
                "Weizhong Yan",
                "Tim Oates"
            ],
            "title": "Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline",
            "year": 2016
        },
        {
            "authors": [
                "Zhenrui Yue",
                "Camilo Requena Witzig",
                "Daniel Jorde",
                "Hans-Arno Jacobsen"
            ],
            "title": "BERT4NILM: A Bidirectional Transformer Model for Non-Intrusive Load Monitoring. In Proceedings of the 5th International Workshop on Non-Intrusive Load Monitoring (Virtual Event, Japan) (NILM\u201920)",
            "venue": "Association for Computing Machinery,",
            "year": 2020
        },
        {
            "authors": [
                "Bochao Zhao",
                "Lina Stankovic",
                "Vladimir Stankovic"
            ],
            "title": "On a Training- Less Solution for Non-Intrusive Appliance Load Monitoring Using Graph Signal Processing",
            "venue": "IEEE Access",
            "year": 2016
        },
        {
            "authors": [
                "Bochao Zhao",
                "Minxiang Ye",
                "Lina Stankovic",
                "Vladimir Stankovic"
            ],
            "title": "Nonintrusive load disaggregation solutions for very low-rate smart meter data",
            "venue": "Applied Energy",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "CCS CONCEPTS \u2022 Computing methodologies\u2192 Learning paradigms.\nKEYWORDS Appliance Detection, Smart Meter Data, Time Series Classification ACM Reference Format: Adrien Petralia, Philippe Charpentier, Paul Boniol, and Themis Palpanas. 2023. Appliance Detection Using Very Low-Frequency Smart Meter Time Series. In The 14th ACM International Conference on Future Energy Systems (e-Energy \u201923), June 20\u201323, 2023, Orlando, FL, USA. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3575813.3595198"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "The energy sector is undergoing significant changes, primarily driven by the need for a more sustainable and secure energy supply.\ne-Energy \u201923, June 20\u201323, 2023, Orlando, FL, USA \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. This is the author\u2019s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in The 14th ACM International Conference on Future Energy Systems (e-Energy \u201923), June 20\u201323, 2023, Orlando, FL, USA, https://doi.org/10.1145/3575813.3595198.\nOne way to better manage our consumption is to understand it better. In the last decade, electricity suppliers have installed millions of smart meters worldwide to improve their ability to manage the electrical grid [10, 42]. These meters record detailed time-stamped data on electricity consumption, allowing both individual customers and businesses to better understand and rationalize their consumption [6]. These data are also valuable for suppliers, as they can help them anticipate energy demand more accurately. Overall, the widespread adoption of smart meters plays a crucial role in transitioning toward a more sustainable and efficient energy system.\nWe note that it has become essential for electricity suppliers to know which electrical appliances their customers own. This knowledge allows suppliers to better segment their customer base [3], and therefore to propose personalized offers and services that increase the customer satisfaction and retention. Furthermore, they can help customers rationalize their electricity consumption, therefore contributing to the energy transition. One way to gather this information is by asking customers directly through a consumption questionnaire. However, this method can be a significant investment in terms of time and resources, which customers may not accept, and is also prone to errors. Therefore, electricity suppliers need to find more efficient and non-intrusive ways of gathering this information, such as using advanced data analytics techniques to detect the appliances directly through the collected smart meters data [20].\nAppliance detection has become a significant area of research, with various techniques employed to detect the presence of devices [36, 48]. This problem is closely related to Non-Intrusive Load Monitoring (NILM), which aims to identify the power consumption, pattern, or on/off state activation of individual appliances using only the total consumption series [29]. While detecting an appliance can be seen as a step in NILM-based methods [4, 27, 28, 33, 45, 47, 57], and diverse approaches have been proposed in the literature [4, 27, 28, 33, 45, 47, 57], they differ from our objective. Indeed,\nar X\niv :2\n30 5.\n10 35\n2v 2\n[ ee\nss .S\nP] 2\n1 M\nay 2\n02 3\nthese studies essentially focus on detecting when a specific appliance is \"ON\" rather than if a household owns a specific appliance, and the presence of a specific appliance is in several cases already known before applying these approaches. Moreover, the majority of the NILM studies rely on data sampled at \u22651Hz, and consequently use signature-based methods [36, 48] that require either knowledge about how each appliance operates, or training on their individual power consumption. Nonetheless, most existing smart meter installations record consumption at a very low sampling frequency: once every 10 to 60 minutes (in some cases at an even lower frequency). This results in signals where the unique appliance pattern information has been smoothed-out, or lost. Figure 1 illustrates this loss of information. We observe that the dishwasher (shown on the left) and washing machine (shown on the right) signatures become increasingly hard to distinguish from one another as the sampling frequency drops. Therefore, it becomes infeasible to accurately detect appliances using signature-based methods for the sampling frequencies actually used in practice.\nIn this paper, we propose a benchmark of diverse state-of-the-art classification methods for the problem of appliance detection in very low-frequency electrical consumption time series. We conduct our experimental evaluation on five real smart meter datasets using different time series classifiers. We first focus on detecting appliances in very low-sampled smart meters data (30min level), as it is nowadays one of the standard sampling rates adopted by electricity suppliers. We then provide an in-depth analysis of the increasing detection quality using higher frequency smart meter readings: 15min, 10min, and 1 min. To our knowledge, this is the first study to perform an exhaustive comparison of 11 state-of-the-art methods on five diverse real datasets with 13 different types of appliances, for multiple sampling frequencies. The experimental evaluation demonstrates that current time series classifiers can accurately detect several appliances, even at the 30min resolution. Specifically, deep learning techniques are the most accurate and scalable when applied to large smart meter datasets. Moreover, we demonstrate that setting the smart meter reading frequency to 1min can greatly enhance appliance detection using time series classifiers.\nOur contributions are summarized as follows. \u2022 We describe a framework for comparing the performance of different time series classification methods for the appliance detection problem, andmake this framework publicly available: https: //github.com/adrienpetralia/ApplianceDetectionBenchmark \u2022 We perform an extensive experimental evaluation using 5 diverse real datasets and 11 time series classifiers, including both traditional machine learning, as well as deep learning methods. \u2022 We report the results of our comparison, which demonstrate that (i) current time series classifiers can only detect certain appliances at the 30min resolution; (ii) deep learning classifiers are the most accurate and scalable solution; and (iii) electricity suppliers should target a minimum smart meter reading frequency of 15min. \u2022 The findings of this study can help electricity suppliers make informed decisions regarding the characteristics of future smart meter deployments. Moreover, these findings point to interesting (and still challenging) open research directions in the context of electricity consumption time series analysis, and appliance detection in particular."
        },
        {
            "heading": "2 BACKGROUND AND RELATEDWORK",
            "text": ""
        },
        {
            "heading": "2.1 Smart Meter Data",
            "text": "An electrical consumption load curve is defined as a univariate time series X = (\ud835\udc991, ..., \ud835\udc99\ud835\udc47 ) of ordered elements \ud835\udc99 \ud835\udc57 \u2208 R1+ following (\ud835\udc561, ..., \ud835\udc56\ud835\udc47 ) time consumption indexes (i.e., timestamps). The sampling frequency is defined as the time difference between two records index \u0394\ud835\udc61 B \ud835\udc56 \ud835\udc57 \u2212 \ud835\udc56 \ud835\udc57\u22121. Each element \ud835\udc99 \ud835\udc57 , usually given in Watt, indicates either the actual power at time \ud835\udc56 \ud835\udc57 or the average electric power called during the interval time \u0394\ud835\udc61 . The value can also be given in Watt-hour. In the literature, the definition of high and low-frequency smart meters data can differ [24]. In this study, we refer to high-frequency data sampled at less than 1 second and lowfrequency data sampled between 1 second and 1min. Data sampled above 1min refers to very low-frequency smart meter data. [Individual appliance load curve] By monitoring electric devices with individual meters, we can obtain the consumption load curve of each individual appliance in a household. However, instrumenting every appliance in the house is prohibitively expensive. [Aggregate load curve] The main consumption power of a house is usually recorded by a smart meter device located on the electrical meter of the household. This aggregate signal is the addition of the power consumption of all individual appliances in the household."
        },
        {
            "heading": "2.2 Non-Intrusive Load Monitoring (NILM) and Appliance Detection",
            "text": "Non-Intrusive Load Monitoring (NILM) [20], also called load disaggregation, relies on identifying the individual power consumption, pattern, or on/off state activation of individual appliances using only the total aggregated load curve [29]. NILM was initially approached as a problem involving linear combinations, with algorithms aiming to estimate the proportion of total power consumption used by distinct active appliances at each time step [29]. Early research on this topic employed combinatorial optimization techniques [29]. Later, Hidden Markov Models became the dominant approach, and in the last few years, deep learning models have been the reference to perform disaggregation [24, 29, 30, 55, 59]. Furthermore, NILM approaches can be divided into supervised and unsupervised learning, depending on whether they usee labeled data for training the models. Supervised learning involves classifying detected events (appliances being switched on or off) by matching extracted features [33, 36, 45, 57]. In contrast, unsupervised NILMmethods detect events by analyzing feature similarities, or correlations without using labeled data [20, 60].\nSince device recognition can be seen as a step of NILM-based methods, different approaches exist in the literature to detect appliances in load curves using high or low-frequency smart meter data [4, 27, 28, 33, 45, 47, 57]. However, numerous studies using pattern recognition at low frequency require knowledge about how each device operates. Few recent research studies [4, 27, 33, 45] used time series features, or deep learning representations, to detect events or appliance activation patterns. Despite the promising results demonstrated by these studies using modern machine learning approaches, we note that they are only applied to high-frequency data (i.e., data sampled at a minimum rate of 1 sample per second).\n2.2.1 Studies on Very Low-Frequency Data. Most NILM studies use high-frequency smart-meter data (seconds level at maximum), and only very few studies have been conducted using very-low sampling rates [17, 43, 61]. In [61], the authors suggested three methods to estimate appliance consumption using hourly smart meter data. The first two methods are unsupervised and require knowledge about manufacturer appliance parameters. The third method is a supervised deep learning approach that requires disaggregate appliance load curves for training. In [17], the authors proposed a data privacy-oriented study to assess the impact of Smart Meters sampling frequency on the detection of certain electrical appliances. They used an event detection approach as a feature extractor to train a classifier that identifies changes in power consumption. However, the experimental evaluation in this study was rather limited: the authors evaluated the classification performance on a single dataset, and used the same house for both training and testing. Overall, the few NILM studies that used low-frequency data focus on estimating the consumed power of each appliance, rather than detecting which appliances are present in the households.\nFew papers in the literature [2, 15] try to tackle the problem of detecting the devices owned by a household using very low-frequency sampled data. In [2], the authors used a Hidden Semi-MarkovModel (HSMM) to extract appliance features from power consumption data. These features are then merged with external variables (such as temperature) and serve to train an AdaBoost classifier [50] to detect the presence of different appliances. In [15], the authors proposed a framework that uses a deep learning approach on subsequences of a long consumption load curve to detect the appliances present in the household. A majority vote gives the final device prediction, based on the individual predictions made on every examined subsequence. The study compares their method to [2], but not to any of the current state-of-the-art time series classifiers. In addition, only one public dataset at one sampling rate was considered."
        },
        {
            "heading": "2.3 Time Series Classification",
            "text": "Time series classification (TSC) [5, 26] is an important analysis task across several domains. Many studies have suggested different approaches to solve the TSC problem, ranging from the computation of similarity measures between time series [11] to the identification of discriminant patterns [22]. In addition, benchmarks, such as the the UCR archive [12], have been proposed, on which exaustive experimental studies have been conducted [5]. We discuss in more detail the current state-of-the-art time series classifiers in Section 3."
        },
        {
            "heading": "3 PROBLEM DEFINITION AND BENCHMARK",
            "text": ""
        },
        {
            "heading": "3.1 Problem Definition",
            "text": "In this work, we treat the appliance detection problem as a supervised binary classification problem. We aim to identify the presence/absence of a specified appliance\u2019s activation signature in a smart meter data series, independently of the number of activations of this appliance. The presence can be simply defined by the fact that the device is switched \"ON\" at least once. Formally, we define the problem as follows:\nDefinition 3.1 (Appliance Detection Problem). Given an aggregate smart meter time series X \u2208 R\ud835\udc47 , an appliance type \ud835\udc4e, we want to\nknow if appliance \ud835\udc4e is activated at least once in X (i.e., was in an \"ON\" state, regardless of the time and number of activations)."
        },
        {
            "heading": "3.2 Overview of Time Series Classifiers",
            "text": "We now provide an overview of the different approaches proposed in the literature to solve the TSC problem (refer to Figure 2). The objective is to compare the performance of these methods when applied to the appliance detection problem. Each classifier takes as input for training the univariate consumption time series (i.e., 1D signal) along with the ground-truth labels.\n3.2.1 Nearest-Neighbor Classifier. \ud835\udc3e-Nearest-Neighbor (\ud835\udc3e-NN) classifiers are the most simple and intuitive classifiers, based on the notion of time series similarity. Following a chosen distance measure, each new instance is classified by getting assigned the same label as the majority label of the \ud835\udc3e closest samples in the training set (\ud835\udc3e = 1 in our experiments, i.e., we use 1-NN classifiers). The most popular distance measure is Euclidean distance, which allows comparing two instances point to point. However, this distance does not consider the possible distortions on the temporal axis. Dynamic Time Warping (DTW) [49] is a distance measure to compute the similarity between two time series, where relevant patterns may evolve at different speeds. DTW suffers from a high computational cost, which makes it challenging to apply on large datasets.\n3.2.2 Tree Based Classifier. Tree-based classifiers, like Random Forest [8], have exhibited promising results in classification tasks. [Time Series Forest] TSF [16] is a random forest-based classifier that uses as input features extracted from randomly sampled intervals of the raw data series. The algorithm first selects a number \ud835\udc5f of intervals with a random start position and length; then, from each interval, three simple features are extracted: the mean, the standard deviation, and the slope. Finally, the 3\ud835\udc5f new features serve to train a classic random forest classifier. The number of intervals is set by default to \u221a \ud835\udc47 , where \ud835\udc47 is the length of the input time series, and the number of estimators for the decision tree is set to 200. [Random Interval Spectral Ensemble] The RISE algorithm [35] is a random forest classifier based on spectral extraction features, rather than simple summary statistics for each interval. It computes the Fast Fourier Transform (FFT) and the Auto Correlation Function (ACF) for several randomly selected intervals. In contrast to TSF, the algorithm extracts only one interval from the raw series for\neach decision tree (set to 500 in our experiments), and the first tree is built using the features extracted from the entire series. [DrCIF] The Diverse Representation Canonical Interval Forest Classifier (DrCIF) algorithm [40] is an extension of the Canonical Interval Forest (CIF) classifier [39], which itself uses the Canonical Time Series Characteristics (Catch22) [37]. Unlike the two previous tree-based methods, this algorithm is an interval-based time series classifier that looks for discriminative subseries before building the decision trees. As for TSF, the number of estimators is set to 200 in our experiments.\n3.2.3 Dictionary Based Classifier. Dictionary-based approaches, also called bag-of-words approaches, transform a time series into a sequence of symbols (letters usually) according to a chosen discretization technique. Using a sliding window of a specific size \ud835\udc59 , it is then possible to count the number of repeated patterns (i.e., symbolic words) to perform classification regarding the repetition frequency of similar patterns. [BOSS] The Bag Of SFA Symbol (BOSS) [51] is a dictionary-based classifier that uses Symbolic-Fourier-Approximation (SFA) [52] as a discretization technique. It first extracts sub-sequences from the raw series using a predefined sliding window of length \ud835\udc59 . Then, each sub-series is discretized in a word of size\ud835\udc64 of \ud835\udefc symbols using SFA and the Multiple Coefficient Binning algorithms [51] (\ud835\udc59 = 10, \ud835\udc64 = 10, and \ud835\udefc = 2 in our experiments). This symbolic sentence (i.e., word arrangement) is then converted into a histogram by counting the frequency occurrence of each word. Finally, classification is performed using the histogram information. [BOSS and cBOSS Ensembles] The BOSS ensemble [51] is a set of individual BOSS classifiers that use different discretization parameters\ud835\udc64 and \ud835\udc59 . The parameter \ud835\udc59 is defined as \ud835\udc59 \u2208 [10,\ud835\udc47 ] (\ud835\udc47 being the time series length), and values of \ud835\udc64 \u2208 {16, 14, 12, 10, 8}. The number of symbols, \ud835\udefc , is set to the default value of 4. The algorithm keeps only individual BOSS classifiers that performed the best according to a validation test. The BOSS ensemble requires building and evaluating a large number of models, making it a time and memory-intensive classifier for large datasets. To address this complexity, a compact version (cBOSS) was introduced, that uses a restricted set of randomly chosen parameters for ensemble creation.\n3.2.4 Deep Learning Based Classifier. The interest in deep learning methods for time series classification has risen significantly in the past few years [26, 58]. These models have shown excellent performance, reaching the top of state-of-the-art. [ConvNet] A Convolutional Neural Network (CNN) [44] is a type of deep learning neural network widely used in image recognition that is specially designed to extract patterns through data with a grid-like structure, such as images, or time series. A CNN uses convolution, where a filter is applied on a sliding window over the time series. The ConvNet architecture proposed in [58] is composed of three stacked Convolutional blocks followed by global average pooling [34], and a Softmax activation function. Each Conv block comprises a convolutional layer followed by a batch normalization layer [25], and a ReLU activation layer. The three block used the following 1D kernel sizes {8, 5, 3}. [ResNet] The Residual Network (ResNet) architecture [21] was introduced to address the gradient vanishing problem encountered in large CNNs [54]. A ResNet is formed by stacking several blocks and\nconnecting them together using residual connections (i.e., identity mapping). For time series classification, a ResNet architecture has been proposed in [58], and has demonstrated a strong classification accuracy [7]. It is the same architecture as the previously described ConvNet model, with adding residual connection between each Convolutional block. [ResNet with Attention Mechanism] In [15], the authors proposed a an extension of the ResNet architecture to perform appliance detection. The model starts by extracting features using six convolution blocks with dilated convolution and residual connections, followed by two encoder/decoder modules that use a dot product attention mechanism. In this model, the dilated convolution (i.e., adding zeroes between the elements of the filter) aims to increase the receptive field of the kernels without increasing the number of parameters. After the feature extraction step, the classification step is performed using a multi-layer perceptron followed by a softmax activation function. [InceptionTime] Inspired by inception-based networks in computer vision [56], an ensemble of five neural networks using Inception modules has been proposed for time series classification [18]. The model consists of five identical networks using residual connections and convolutional layers. One network uses 3 Inception modules that replace the traditional residual blocks that we can find in a ResNet architecture. Each Inception modules consist of a concatenation of convolutional layers using different size of filters. Specifically, each module results in the following layers. In the case of multivariate time series, a 1D convolutional bottleneck layer is used to reduce the number of dimensions of the time series .Then, the output is fed to three different 1D convolutional layers with different kernel sizes (10, 20, and 40) and one Max-Pooling layer with kernel size 3. The last step consists of concatenating the previous four layers along the channel dimension and applying a ReLu activation function to the output, followed by batch normalization. All the convolutional layers used in the module come with 32 filters and a stride parameter of 1.\n3.2.5 Random Convolutional Kernel Features Classifiers. The authors of [13] proposed an approach based on convolution filters without learning any weights. Some variants of this model, based on the same principle, were later proposed in the literature. [ROCKET]The RandOmConvolutional KErnel Transform (ROCKET) algorithm [13] uses 1D convolutional kernels to extract relevant features. Instead of learning proper filter parameters using a gradient descent algorithm to detect relevant patterns, the method generates a large set of \ud835\udc3e kernels with random length, weights, bias, dilation, and padding. After applying them, the maximum and the proportion of positive values are extracted as new features for each time series, resulting in a 2\ud835\udc3e features for each instance. Classification is then performed on these features, using a simple ridge classifier. By default, ROCKET uses 10000 random kernels. [MiniRocket]MINImally RandOm Convolutional KErnel Transform (MiniRocket) [14] is a version of ROCKET that reduces the random sampling space of the filter parameters, and keeps only the proportion of positive values as a new feature for each kernel. These modifications lead to a lower execution time complexity while maintaining similar performances.\n[Arsenal] Arsenal [41] is an ensemble of multiple ROCKET classifiers that uses a restricted number of kernels compared to the original model. This method was proposed to estimate the variance predicted by the classifier without changing the type of classifier.\n3.2.6 Ensemble Models. To reduce the variance in predictions, using a combination of models rather than a single one is a common technique. Ensemble models combining different approaches have been proposed to address the TSC problem. Several ensemble methods have been proposed in the literature, such as TS-CHIEF (Time Series Combination of Heterogeneous and Integrated Embedding Forest) [53] and HIVE-COTE (Hierarchical Vote Collective of Transformation-Based Ensembles) [41]. The first, is and ensemble of tree classifiers. The second is combining 4 different classifiers and use majority voting to provide the final prediction. However, these models suffer from a high execution time and cannot be applied to very long time series such as load curves."
        },
        {
            "heading": "3.3 Energy Consumption Datasets",
            "text": "Numerous energy consumption datasets exist in the literature [9], and some of them have become references to conduct NILM studies [19, 31, 32]. However, these datasets typically provide aggregated and appliance-level load curves for only a few houses at a highsampling frequency. Resampling them at a very low frequency leads to significant data reduction. In order to include a broader range of appliances and to align with existing literature, we include two NILM datasets in our experiments: UK-DALE [31] and REFIT [19]. We also include one public dataset providing 30min sampled aggregate load curves for a large number of households [1]. Moreover, we include two private datasets from EDF (the main french electricity supplier). In total, we consider five real diverse datasets in our experimental evaluation. These datasets are detailed below.\n3.3.1 NILM Datasets. UKDALE and REFIT are two well-known high-frequency Smart Meters datasets used in NILM studies [55, 59]. [UK-DALE]TheUK-DALE dataset [31] contains data from 5 houses in the United Kingdom, and includes appliance-level load curves sampled every 6 seconds, as well as the whole-house aggregate data series sampled at 16kHz. Four houses were recorded for over a year and a half, while the 5th house was recorded for 655 days. [REFIT] The REFIT project (Personalised Retrofit Decision Support Tools for UK Homes using Smart Home Technology) [19] ran between 2013 and 2015. During this period, 20 houses in the United Kingdom were recorded after being monitored with smart meters and multiple sensors. This dataset provides aggregate and individual appliance load curves at 8-second sampling intervals.\n3.3.2 CER Dataset. The Commission for Energy Regulation of Ireland conducted a study to assess the performance of smart meters and their impact on consumer energy consumption [1], recording the aggregate load curve consumption every 30min for over 5000 Irish homes and businesses. Pparticipants filled out a questionnaire on the household composition, the behavior of electricity consumption, and the type and number of appliances present in the home, or business. In this work, we use the residential sub-group of the study, i.e., 4225 households recorded from July 15, 2009, to January 1, 2011, for a total of 4225 series, of length 25728 data points each.\n3.3.3 EDF Datasets. To better understand its customers\u2019 base and electricity consumption behavior, Electricit\u00e9 De France (EDF) conducts surveys on customer samples. These customers consent to EDF to use their data and analyze their consumption behaviors, and only the aggregate power consumption of the house is recorded. Similar to the CER study, customers fill out a questionnaire with information on which appliances are present in their households, and on their consumption habits. Two EDF datasets from two different studies were used in our experiments. [EDF Dataset 1] The first one contains 2611 load curves at 30min sampling frequency of one year of electricity recording consumption. Data were collected between September 2019 and September 2021 from 1553 different clients. The dataset consists of 2611 time series of length 17520 from 1553 different sources. [EDF Dataset 2] The second dataset contains 5354 load curves at a 10min sampling frequency, recorded over a period of six months. Data were collected between January 2012 and January 2015 from 1260 clients. The dataset consists of 5354 time series of length 26208 from 1260 different sources."
        },
        {
            "heading": "4 EXPERIMENTAL SETUP",
            "text": "All experiments are performed on a high-performance computing cluster. The source code is in Python 3.7, and for each classifier we use the default parameters provided by the authors in the original papers. For non-deep-learning approaches, we use the sktime library [38]. We perform each experiment on a server with 2 Intel Xeon Gold 6140 CPUs with 190 Go RAM. For deep-learning based models, we implement all the models using the 1.8.1 version of the PyTorch framework [46], and run experiments on a server with 2 NVidia V100 GPUs with 16Go RAM.\nWe consider all the classifiers presented in Section 3.2. We run each method five-time using different random train/validation/test splits, and we report the average of these runs. Note that the error bars shown in Figure 3, Figure 7, and Figure 8, correspond to the average variability of the classifiers through these five runs. Additionally, we set a 10-hour time limit per job. Only models that finished a run (training + inference) are considered. We note that the ResNet with Attention model was not evaluated using UKDALE and REFIT data due to the residual block\u2019s dilation convolution being incompatible with the small size of the time series of these datasets.\nWe make all code available online: https://github.com/adrienpet ralia/ApplianceDetectionBenchmark"
        },
        {
            "heading": "4.1 Data Preprocessing",
            "text": "Since the datasets we employ in this study have been created using different sampling frequencies, we preprocess them for the experiments as explained below. The left part of Table 1 summarizes, for each dataset, the number of time series and the corresponding length, according to each sampling frequency.\n4.1.1 NILMdataset preprocessing. The REFIT andUKDALE datasets provide appliance level and total consumption load curves for a small number of houses: 5 and 20, respectively. Moreover, the electrical appliances in the houses are likely the same. Inspired by the data processing step in NILM studies [55, 59], we preprocess the\ndatasets by slicing the entire consumption curve of each household into smaller sub-sequences.\nFor each experiment, we first resample the data to a specified sampling rate and fill in with linear interpolation the gaps of less than 1 hour. Then, we process the datasets by splitting each household\u2019s consumption load curve into smaller sub-sequences of one day, and by dropping those with missing values. The choice of the one day for the sub-sequence length provides an overall balance between positive (i.e., containing the device) and negative (i.e., not containing the device) samples. In contrast, slicing the entire consumption curve in weeks leads to very few negative samples for most appliance cases. This is because the appliances in these datasets are devices that are very frequently used (on average, once every two or three days). To assign the positive or negative label (i.e., appliance presence or not) to a sub-sequence, we use the corresponding disaggregated appliance load curve, allowing us to know if the appliance has been switched on at least once for a given day.\nBy preprocessing the UKDALE dataset, we noticed that the fourth house of the study could not be used for the experiments, since a single disaggregated load curve regrouped multiple appliances. Thus, we use only three houses for the training/validation set, whereas the one last house\u2019s sub-sequences are used for the test set. With the REFIT data, we use two randomly selected houses for the test set, while the other houses available are used for the train set.\n4.1.2 CER and EDFs datasets preprocessing. The CER and EDFs datasets provide only the total aggregated load curve of each house. As a consequence, it is impossible to know if an appliance is activated or not for a given day. Therefore, we cannot slice the time series into smaller subsequences as for the NILM datasets, and we provide as inputs to the classifier the full-length load curves. In addition, we process the load curves by linearly interpolating gaps of less than 1 hour and any time series with residual missing values are not retained. The appliance presence label is assigned using the provided questionnaire associated with each dataset. Finally, we do a 70%/10%/20% random split of the houses for the training, validation, and test sets, respectively.\n4.1.3 Appliance Detection Cases. We select different cases of device detection through all the datasets, including small and big appliances. The right part of Table 1 summarizes the selected appliance detection cases for all datasets. The REFIT and UKDALE datasets include mostly small appliances because, in these studies, only plugged devices were recorded. On the other hand, the CER and EDFs datasets provide information about larger appliances, directly connected to the electric meters, such as Water Heaters, Heaters, and Electric Vehicles.\nThe selected cases aim to determine if a specific device is present in a time series using binary detection. However, the \"Convector/Heat Pump\" case involves classifying the types of electric heaters, such as distinguishing between convectors and heat pumps.\nIn order to ensure that the classifiers are not biased during training, we maintain an equal balance of time series labeled with positive and negative samples. However, we note that the test set reflects the actual, imbalanced nature of the data, allowing us to evaluate the classifier\u2019s performance in a realistic scenario.\n\u266fTS is the number of labeled time series used for each case, in which each class are balanced. IB Ratio indicates the imbalance level of the corresponding test sets (i.e., the percentage of positive instances in the number of instances)."
        },
        {
            "heading": "4.2 Evaluation Measures",
            "text": "[Accuracy]When detecting appliance presence/absence, several classification cases may be unbalanced. Indeed, most people own a television or a washing machine but do not have an electric heating system or a swimming pool. However, using a model that only predicts the majority class may appear to perform well in these cases when using the classification accuracy (i.e., the ratio of well classified instances versus the total number of instances). Precision, Recall, and the harmonic average of both, called the F1-Score, are well-known measures, defined as follows:\nF1-score = 2.\ud835\udc43 .\ud835\udc45 \ud835\udc43 + \ud835\udc45 , with: \ud835\udc43 = \ud835\udc47\ud835\udc43 \ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc43 , \ud835\udc45 = \ud835\udc47\ud835\udc43 \ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc41\nwith\ud835\udc47\ud835\udc43 = True Positive,\ud835\udc47\ud835\udc41 = True Negative, \ud835\udc39\ud835\udc43 = False Positive and \ud835\udc39\ud835\udc41 = False Negative. Nevertheless, precision (P), recall (R), and F1-score measures independently indicate the model\u2019s performance can be applied to one class only. In the case of a binary classification problem with data imbalance, these measures are typically applied only to the minority class. In our classification problem, the minority class varies depending on the specific device. Detecting an appliance (i.e., the positive class) could correspond either to the minority or the majority class. Thus, the F1-Score measure is not appropriate in our case. To account for this variability and provide an overall performance measure, we use the Macro F1-score to evaluate the performance of the classifiers. Formally, for \ud835\udc41 class (in our case, \ud835\udc41 = 2), the Macro F1-Score is defined as follows:\nMacro F1-score = 1 \ud835\udc41 \ud835\udc41\u2211\ufe01 \ud835\udc56=1 F1-score\ud835\udc56\n[Time Performance] Considering the computation time of classifiers is crucial for evaluating their effectiveness in real-world scenarios. We measure the time performance of the classifiers, considering the total time required for both training and inference."
        },
        {
            "heading": "5 RESULTS AND DISCUSSION",
            "text": "This section presents the results of our experimental evaluation. First, we normalize the different datasets to the same sampling frequency, i.e., 30min, to obtain overall results on all the cases. Then, we perform an experimental evaluation of the influence of sampling frequency on the detection quality of the classifiers. We also analyze the data size impact on the detection quality. Finally, we provide a discussion of the overall results."
        },
        {
            "heading": "5.1 Accuracy for 30min Sampling Frequency",
            "text": "The appliance detection results of the classifiers for the sampling frequency of 30min are summarized in Table 2. We observe that all classifiers return poor results for the UKDALE dataset. (We discuss and explain these results in detail in Section 5.3.) Furthermore, we note that independently of the dataset, some appliances are easier to detect than others. The following sections provide an analysis of these results according to the type of appliances.\n5.1.1 Tech Appliances. DesktopComputer andTelevision seem to be well detected in the REFIT dataset, with a Macro F1-Score above 0.7 for the best classifiers. The score obtained on Desktop Computer on other datasets is not as good, but is consistent with the number of time series provided. It can be explained by the fact that the pattern is hidden behind other appliance activation signatures in longer smart meters load curves, and thus, is hard for classifiers to detect.\n5.1.2 Kitchen Appliances. First, detectingKettle usage looks pretty challenging, with poor results obtained by all classifiers and aMacro F1-Score \u2243 0.45. Given that a kettle operates for relatively short periods, it is understandable that its activation may not be captured using 30min sampled data. Microwave oven and classic Oven are not well detected in the EDF datasets. However, the detection score obtained on REFIT by the best two classifiers is above 0.7, thanks to the larger amount of data available for this case in REFIT. Finally, the Cooker is well detected on the CER dataset.\n5.1.3 Washer Appliances. Classifiers achieve promising results detecting Dishwasher and Tumble Dryer through CER and EDF 2 datasets. The lower performance obtained with the EDF 1 datast is explained by the lower amount of labeled instances given for these cases. However, the low score results obtained on the three washer appliances for REFIT are not due to the amount of time series data. We believe that this poor detection score can be explained by the\nfact that these three devices are used in combination and have similar activation patterns; therefore, the classifiers cannot easily distinguish among them.\n5.1.4 Heating Appliances. The best detection scores are achieved for Water Heater on the EDF 1 and EDF 2 datasets. In France, water heaters refer mainly to devices that heat water from a hot tank, and usually operate during hours with high consumption power levels [23]. The classifiers can effectively discern this type of pattern, even using 30min sampled data. The lower performance on the CER dataset can be attributed to the use of two types of water heaters in Ireland: instantaneous and tank-pumped. Instantaneous water heaters only operate on demand, resulting in high spikes of short duration. Using the same label for these two devices, which have different activation signatures, significantly impacts the performance of the classifiers. The results on heater detection are satisfying for the EDF datasets, and we assume that the score difference between EDF 1 and EDF 2 is mainly due to the span of the time period used for training the model. By providing a full year of electricity consumption, the model can more easily detect the heater pattern, since it trains with data during the high consumption levels of the winter season. The poor performance on the CER dataset for heater detection can be attributed to the fact that the heater label indicates the presence of a convector electric heater, which is typically used as a supplementary heat source in winter, rather than being the primary heat source for the home.\n5.1.5 Other Appliances. Electric Vehicles are well detected on the EDF 1 dataset considering the restricted number of labeled instances that we have available. The lengthy recharging times of electric vehicles and the high power required, combined with the fact that recharging often occurs mainly during low-consumption night-time hours, can explain the good performance we observe.\n5.1.6 Overall Classifier Results Using 30min data. The overall results, shown in Table 2 and Figure 3, demonstrate that InceptionTime outperforms other classifiers when considering the average score and rank; InceptionTime is followed by ResNet, Arsenal, ConvNet, MiniRocket and Rocket. Since the ResNet model enhanced with the attention mechanism was not evaluated in all the cases, we do not include it in the total average score shown in Figure 3. However, this classifier achieves relatively poor performance compared to the others (refer to Table 2). In light of these results, it is essential to note the difference in performance between the best and worst performing classifiers: convolutional-based classifiers, i.e., InceptionTime, ConvNet and ResNet, are the optimal choice for many detection cases.\nFigure 4 summarizes the average total running time (i.e., training and inference time together) for the 11 classifiers we studied. Taking into consideration the performance of the convolutional-based approaches (deep- and non deep-learning approaches), as well as their running time, we observe that this type of classifier is the most suitable for appliance detection using 30min sampled smart meter data. InceptionTime reaches a sligthly higher detection score, but at the cost of longer execution times. A balance between performance and efficiency is achieved by the ResNet and ConvNet classifiers."
        },
        {
            "heading": "5.2 Influence of Sampling Rate",
            "text": "In this part of the experimental evaluation, we analyze the improvement of the detection score of the different classifiers, as the smart meter sampling rate increases. We used the REFIT and EDF 2 datasets to perform these experiments, since these datasets provide data at a higher frequency than every 30min.\nUsing the REFIT dataset, we performed experiments at four different sampling rates: 1min, 10min, 15min, and 30min. To obtain complementary results on bigger appliances that were not available with REFIT data, we also included appliance detection cases from the EDF 2 dataset. However, since this dataset offers data sampled at 10 min, we could only produce results for sampling rates: 10min, 15min, and 30min.\nAll the results are summarized in Figure 5. For clarity, we only illustrate the scores of the five best classifiers.\nOn average across all cases, the appliance detection accuracy decreases significantly (by almost 0.1) when the sampling rate drops from 1min to 30min. For the best classifier (InceptionTime), the average drop is 0.15.\nHowever, it is interesting to note that not all appliances are significantly better detected using a higher sampling frequency. As expected, appliances that operate only for short periods, i.e., Microwave or Kettle, benefit the most when using higher smart meter frequencies. For example, the results in Figure 5 show that using 1min sampled data can significantly improve the Kettle detection. In this case, the best classifier, ResNet, achieves a 0.2 improvement in the detection score when the sampling rate increases from 30min to 1min. For the Microwave case, it is a 0.1 average gain score for all the classifiers using 1min sampled data.\nOther appliances, such as Dishwasher, Desktop Computer, Television, Washing Machine and Water Heater, which typically operate for long periods, are better detected using higher sampling rates, as well. For example, using 1min level data, the Washing Machine is much more accurately detected than when using 30min data (refer to Figure 5(f))."
        },
        {
            "heading": "5.3 Influence of Data Size",
            "text": "In this last part, we analyze the impact of the number of distinct households on classifier performance. These experiments demonstrate that classifiers cannot effectively learn the patterns of an appliance using only a small number of households when the smart meter data sampling frequency is very low (this explains the poor results presented in Section 5.1 for the UK-DALE dataset). Furthermore, we demonstrate that the number of households is more important for training the machine learning models than the amount of data available for each household.\nWe compared the following two approaches for training: (i) randomly select a subset of the houses and use all the data from these houses to train the models, and (ii) select all houses and use a random subset of the time series from each house. We performed the experiments on the appliance detection cases using the REFIT dataset. Furthermore, in order to account for the impact of the smart meter reading on these results, we performed the experiments using 4 different sampling frequencies: 1min, 10min, 15min, and 30min. Figure 6 summarizes the results of these experiments: the graphs show the average performance of all classifiers1 for each sampling\n1We average the performance of all classifiers listed in Table 2, except for ResNetAtt, which could not be used with the small length of the REFIT time series.\nrate. The black line represents the score value averaged across all sampling rates.\nWe note that for every sampling rate and detection case, it is almost always preferable to use all the available households and a subset of their time series, rather than to use all time series from a subset of the households. Indeed, data from the same house is frequently characterized by the consumption patterns of the residents. Instead, using data from multiple households, enables the classifier to focus on and learn the actual activation patterns of the appliances. Interestingly, using a subset of the households, or a subset of the time series does not seem to significantly affect the detection accuracy for the Washing Machine and the Tumble Dryer. The Tumble Dryer is indeed not well detected in our experiments. However, the detection score of theWashing Machine seems to be more impacted by the sampling frequency rather than by the data size."
        },
        {
            "heading": "6 DISCUSSION",
            "text": "We now summarize the results of our evaluation. Figure 7 shows the average score for each classifier across all the experiments conducted in our study. The results show that the three deep learningbased methods are the most accurate overall. Among them, ResNet and ConvNet perform on average sligthly better than InceptionTime. However, as shown in Figure 8, the average score depends on the time series length. ResNet and ConvNet are better on average when using the short time series (REFIT and UKDALE datasets). InceptionTime is better on average when using long time series (CER and EDF datasets), because of InceptionTime\u2019s ability to capture long-lasting patterns through the use of a combination of\ndifferently-sized kernels. Nevertheless, as the confidence intervals indicate, there is no clear winner among the three deep-learning classifiers. Based on these findings, we recommend using either ResNet or ConvNet, since their time performance is one order of magnitude faster than InceptionTime (see Figure 4).\nOverall, the experiments show that for improving appliance detection, it is beneficial for electricity suppliers to collect data over extended periods of time, and at a finer time step than 30min. Indeed, a 15min step seems to be the minimum target in order to correctly detect a certain number of appliances. Furthermore, this study shows that further work is needed to more accurately detect appliances, even for data with 1min sampling frequency. Nevertheless, the lack of large electricity consumption public datasets that can be used to develop and train new algorithms is an important shortcoming. Having more good-quality data over long time intervals are necessary in order to allow for the development of more robust methods and further advancements in the field."
        },
        {
            "heading": "7 CONCLUSIONS",
            "text": "This paper presents a comprehensive evaluation of state-of-the-art time series classifiers applied to the appliance detection in very low-frequency smart meter data. We develop the first benchmark of time series classifiers for appliance detection using five different real datasets of very low-frequency electricity consumption with varying time series lengths. The results indicate that the performance of current time series classifiers varies significantly; only appliances that operate during long periods of time can be accurately detected using 30min sampled data. However, using 1min sampling data can drastically increase the detection accuracy of small appliances. Furthermore, deep learning-based classifiers have shown promising results in terms of accuracy, particularly for certain appliances. Overall, this study provides a valuable contribution to electricity suppliers, as well as analysts and practitioners, in order to help them choose the appropriate classifier for accurately detecting appliances in very low-frequency smart meter data."
        }
    ],
    "title": "Appliance Detection Using Very Low-Frequency Smart Meter Time Series",
    "year": 2023
}