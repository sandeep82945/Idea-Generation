{
    "abstractText": "We study transformations of automata and games using Muller conditions into equivalent ones using parity or Rabin conditions. We present two transformations, one that turns a deterministic Muller automaton into an equivalent deterministic parity automaton, and another that provides an equivalent history-deterministic Rabin automaton. We show a strong optimality result: the obtained automata are minimal amongst those that can be derived from the original automaton by duplication of states. We introduce the notions of locally bijective morphisms and history-deterministic mappings to formalise the correctness and optimality of these transformations. The proposed transformations are based on a novel structure, called the alternating cycle decomposition, inspired by and extending Zielonka trees. In addition to providing optimal transformations of automata, the alternating cycle decomposition offers fundamental information on their structure. We use this information to give crisp characterisations on the possibility of relabelling automata with different acceptance conditions and to perform a systematic study of a normal form for parity automata. 2012 ACM Subject Classification Theory of computation \u2192 Automata over infinite objects",
    "authors": [
        {
            "affiliations": [],
            "name": "Antonio Casares"
        },
        {
            "affiliations": [],
            "name": "Thomas Colcombet"
        },
        {
            "affiliations": [],
            "name": "Nathana\u00ebl Fijalkow"
        },
        {
            "affiliations": [],
            "name": "Karoliina Lehtinen"
        }
    ],
    "id": "SP:4fc3e7cf333a7069eed7ed23432679a093d83ea5",
    "references": [
        {
            "authors": [
                "Bader Abu Radi",
                "Orna Kupferman"
            ],
            "title": "Minimization and canonization of GFG transition-based automata",
            "venue": "Log. Methods Comput. Sci.,",
            "year": 2022
        },
        {
            "authors": [
                "Tom\u00e1\u0161 Babiak",
                "Franti\u0161ek Blahoudek",
                "Alexandre Duret-Lutz",
                "Joachim Klein",
                "Jan K\u0159et\u00ednsk\u00fd",
                "David M\u00fcller",
                "David Parker",
                "Jan Strej\u010dek"
            ],
            "title": "The Hanoi omega-automata format",
            "venue": "In CAV,",
            "year": 2015
        },
        {
            "authors": [
                "Roderick Bloem",
                "Krishnendu Chatterjee",
                "Barbara Jobstmann"
            ],
            "title": "Graph games and reactive synthesis",
            "venue": "Handbook of Model Checking,",
            "year": 2018
        },
        {
            "authors": [
                "Le\u00f3n Bohn",
                "Christof L\u00f6ding"
            ],
            "title": "Constructing deterministic parity automata from positive and negative examples",
            "venue": "CoRR, abs/2302.11043,",
            "year": 2023
        },
        {
            "authors": [
                "Bernard Boigelot",
                "S\u00e9bastien Jodogne",
                "Pierre Wolper"
            ],
            "title": "On the use of weak automata for deciding linear arithmetic with integer and real variables",
            "venue": "In Automated Reasoning,",
            "year": 2001
        },
        {
            "authors": [
                "Udi Boker"
            ],
            "title": "Why these automata types",
            "venue": "In LPAR,",
            "year": 2018
        },
        {
            "authors": [
                "Udi Boker",
                "Denis Kuperberg",
                "Orna Kupferman",
                "Micha\u0142 Skrzypczak"
            ],
            "title": "Nondeterminism in the presence of a diverse or unknown future",
            "venue": "In ICALP,",
            "year": 2013
        },
        {
            "authors": [
                "Udi Boker",
                "Orna Kupferman",
                "Michal Skrzypczak"
            ],
            "title": "How deterministic are good-for-games automata",
            "venue": "In FSTTCS,",
            "year": 2017
        },
        {
            "authors": [
                "Udi Boker",
                "Orna Kupferman",
                "Avital Steinitz"
            ],
            "title": "Parityizing Rabin and Streett",
            "venue": "In FSTTCS, volume 8 of LIPIcs,",
            "year": 2010
        },
        {
            "authors": [
                "Udi Boker",
                "Karoliina Lehtinen"
            ],
            "title": "Good for Games Automata: From Nondeterminism to Alternation",
            "venue": "In CONCUR,",
            "year": 2019
        },
        {
            "authors": [
                "Udi Boker",
                "Karoliina Lehtinen"
            ],
            "title": "History determinism vs. good for gameness in quantitative automata",
            "venue": "In FSTTCS,",
            "year": 2021
        },
        {
            "authors": [
                "Udi Boker",
                "Karoliina Lehtinen"
            ],
            "title": "When a little nondeterminism goes a long way: An introduction to history-determinism",
            "venue": "ACM SIGLOG News,",
            "year": 2023
        },
        {
            "authors": [
                "Patricia Bouyer",
                "Antonio Casares",
                "Mickael Randour",
                "Pierre Vandenhove"
            ],
            "title": "Half-positional objectives recognized by deterministic B\u00fcchi automata",
            "venue": "In CONCUR,",
            "year": 2022
        },
        {
            "authors": [
                "J. Richard B\u00fcchi"
            ],
            "title": "On a decision method in restricted second order arithmetic",
            "venue": "Proc. Internat. Congr. on Logic, Methodology and Philosophy of Science,",
            "year": 1960
        },
        {
            "authors": [
                "Olivier Carton",
                "Ram\u00f3n Maceiras"
            ],
            "title": "Computing the Rabin index of a parity automaton. RAIRO",
            "year": 1999
        },
        {
            "authors": [
                "Olivier Carton",
                "Max Michel"
            ],
            "title": "Unambiguous B\u00fcchi automata",
            "venue": "Theoretical Computer Science,",
            "year": 2003
        },
        {
            "authors": [
                "Antonio Casares"
            ],
            "title": "On the minimisation of transition-based Rabin automata and the chromatic memory requirements of Muller conditions",
            "venue": "In CSL,",
            "year": 2022
        },
        {
            "authors": [
                "Antonio Casares",
                "Thomas Colcombet",
                "Nathana\u00ebl Fijalkow"
            ],
            "title": "Optimal transformations of games and automata using Muller conditions",
            "venue": "In ICALP,",
            "year": 2021
        },
        {
            "authors": [
                "Antonio Casares",
                "Thomas Colcombet",
                "Karoliina Lehtinen"
            ],
            "title": "On the size of good-for-games Rabin automata and its link with the memory in Muller games",
            "venue": "In ICALP,",
            "year": 2022
        },
        {
            "authors": [
                "Antonio Casares",
                "Alexandre Duret-Lutz",
                "Klara J. Meyer",
                "Florian Renkin",
                "Salomon Sickert"
            ],
            "title": "Practical applications of the Alternating Cycle Decomposition",
            "venue": "In TACAS,",
            "year": 2022
        },
        {
            "authors": [
                "Thomas Colcombet"
            ],
            "title": "The theory of stabilisation monoids and regular cost functions",
            "venue": "In ICALP, pages 139\u2013150,",
            "year": 2009
        },
        {
            "authors": [
                "Thomas Colcombet"
            ],
            "title": "Forms of Determinism for Automata (Invited Talk)",
            "venue": "In STACS,",
            "year": 2012
        },
        {
            "authors": [
                "Thomas Colcombet"
            ],
            "title": "Unambiguity in automata theory",
            "venue": "In DCFS,",
            "year": 2015
        },
        {
            "authors": [
                "Thomas Colcombet",
                "Damian Niwi\u0144ski"
            ],
            "title": "On the positional determinacy of edge-labeled games",
            "venue": "Theor. Comput. Sci.,",
            "year": 2006
        },
        {
            "authors": [
                "Thomas Colcombet",
                "Konrad Zdanowski"
            ],
            "title": "A tight lower bound for determinization of transition labeled B\u00fcchi automata",
            "venue": "In ICALP, pages 151\u2013162,",
            "year": 2009
        },
        {
            "authors": [
                "Antonio Di Stasio",
                "Aniello Murano",
                "Vincenzo Prignano",
                "Loredana Sorrentino"
            ],
            "title": "Improving parity games in practice",
            "venue": "Annals of Mathematics and Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Alexandre Duret-Lutz",
                "Etienne Renault",
                "Maximilien Colange",
                "Florian Renkin",
                "Alexandre Gbaguidi Aisse",
                "Philipp Schlehuber-Caissier",
                "Thomas Medioni",
                "Antoine Martin",
                "J\u00e9r\u00f4me Dubois",
                "Cl\u00e9ment Gillard",
                "Henrich Lauko"
            ],
            "title": "From Spot 2.0 to Spot 2.10: What\u2019s new",
            "venue": "In CAV,",
            "year": 2022
        },
        {
            "authors": [
                "Stefan Dziembowski",
                "Marcin Jurdzi\u0144ski",
                "Igor Walukiewicz"
            ],
            "title": "How much memory is needed to win infinite games",
            "venue": "In LICS,",
            "year": 1997
        },
        {
            "authors": [
                "R\u00fcdiger Ehlers",
                "Sven Schewe"
            ],
            "title": "Natural colors of infinite words",
            "venue": "In FSTTCS,",
            "year": 2022
        },
        {
            "authors": [
                "E. Allen Emerson",
                "Charanjit S. Jutla"
            ],
            "title": "Tree automata, mu-calculus and determinacy (extended abstract)",
            "venue": "In FOCS,",
            "year": 1991
        },
        {
            "authors": [
                "E. Allen Emerson",
                "Charanjit S. Jutla"
            ],
            "title": "The complexity of tree automata and logics of programs",
            "venue": "SIAM J. Comput.,",
            "year": 1999
        },
        {
            "authors": [
                "E. Allen Emerson",
                "Charanjit S. Jutla",
                "A. Prasad Sistla"
            ],
            "title": "On model-checking for fragments of \u03bc-calculus",
            "venue": "In CAV,",
            "year": 1993
        },
        {
            "authors": [
                "Javier Esparza",
                "Jan K\u0159et\u00ednsk\u00fd",
                "Jean-Fran\u00e7ois Raskin",
                "Salomon Sickert"
            ],
            "title": "From LTL and limit-deterministic B\u00fcchi automata to deterministic parity automata",
            "venue": "In TACAS,",
            "year": 2017
        },
        {
            "authors": [
                "Seth Fogarty",
                "Orna Kupferman",
                "Moshe Y. Vardi",
                "Thomas Wilke"
            ],
            "title": "Profile trees for B\u00fcchi word automata, with application to determinization",
            "venue": "Inf. Comput.,",
            "year": 2015
        },
        {
            "authors": [
                "Oliver Friedmann",
                "Martin Lange"
            ],
            "title": "Solving parity games in practice",
            "venue": "In ATVA,",
            "year": 2009
        },
        {
            "authors": [
                "Dimitra Giannakopoulou",
                "Flavio Lerda"
            ],
            "title": "From states to transitions: Improving translation of LTL formulae to B\u00fcchi automata",
            "venue": "In FORTE,",
            "year": 2002
        },
        {
            "authors": [
                "Yuri Gurevich",
                "Leo Harrington"
            ],
            "title": "Trees, automata, and games",
            "venue": "In STOC, pages",
            "year": 1982
        },
        {
            "authors": [
                "Thomas A. Henzinger",
                "Nir Piterman"
            ],
            "title": "Solving games without determinization",
            "venue": "In Computer Science Logic, pages 395\u2013410,",
            "year": 2006
        },
        {
            "authors": [
                "Florian Horn"
            ],
            "title": "Explicit Muller games are PTIME",
            "venue": "In FSTTCS,",
            "year": 2008
        },
        {
            "authors": [
                "Florian Horn"
            ],
            "title": "Random fruits on the Zielonka tree",
            "venue": "In STACS,",
            "year": 2009
        },
        {
            "authors": [
                "Paul Hunter",
                "Anuj Dawar"
            ],
            "title": "Complexity bounds for regular games",
            "venue": "In MFCS, pages 495\u2013506,",
            "year": 2005
        },
        {
            "authors": [
                "Michael Kaminski"
            ],
            "title": "A classification of \u03c9-regular languages",
            "venue": "Theoretical Computer Science,",
            "year": 1985
        },
        {
            "authors": [
                "Nils Klarlund"
            ],
            "title": "Progress measures, immediate determinacy, and a subset construction for tree automata",
            "venue": "Annals of Pure and Applied Logic,",
            "year": 1994
        },
        {
            "authors": [
                "Jan Kret\u00ednsk\u00fd",
                "Tobias Meggendorfer",
                "Salomon Sickert"
            ],
            "title": "Owl: A library for \u03c9-words, automata, and LTL",
            "venue": "In ATVA,",
            "year": 2018
        },
        {
            "authors": [
                "Jan K\u0159et\u00ednsk\u00fd",
                "Tobias Meggendorfer",
                "Clara Waldmann",
                "Maximilian Weininger"
            ],
            "title": "Index appearance record for transforming Rabin automata into parity automata",
            "venue": "In TACAS,",
            "year": 2017
        },
        {
            "authors": [
                "Sriram C. Krishnan",
                "Anuj Puri",
                "Robert K. Brayton"
            ],
            "title": "Deterministic \u03c9-automata vis-a-vis deterministic B\u00fcchi automata",
            "venue": "In ISAAC,",
            "year": 1994
        },
        {
            "authors": [
                "Sriram C. Krishnan",
                "Anuj Puri",
                "Robert K. Brayton"
            ],
            "title": "Structural complexity of omegaautomata",
            "venue": "In STACS, pages 143\u2013156,",
            "year": 1995
        },
        {
            "authors": [
                "Denis Kuperberg",
                "Micha\u0142 Skrzypczak"
            ],
            "title": "On determinisation of good-for-games automata",
            "venue": "In ICALP, pages 299\u2013310,",
            "year": 2015
        },
        {
            "authors": [
                "Orna Kupferman"
            ],
            "title": "Automata theory and model checking",
            "venue": "Handbook of Model Checking,",
            "year": 2018
        },
        {
            "authors": [
                "Orna Kupferman",
                "Gila Morgenstern",
                "Aniello Murano"
            ],
            "title": "Typeness for omega-regular automata",
            "venue": "Int. J. Found. Comput. Sci.,",
            "year": 2006
        },
        {
            "authors": [
                "Jan K\u0159et\u00ednsk\u00fd",
                "Tobias Meggendorfer",
                "Clara Waldmann",
                "Maximilian Weininger"
            ],
            "title": "Index appearance record with preorders",
            "venue": "Acta Informatica,",
            "year": 2021
        },
        {
            "authors": [
                "Oebele Lijzenga",
                "Tom van Dijk"
            ],
            "title": "Symbolic parity game solvers that yield winning strategies",
            "venue": "In GandALF,",
            "year": 2020
        },
        {
            "authors": [
                "Christof L\u00f6ding",
                "Anton Pirogov"
            ],
            "title": "Determinization of B\u00fcchi automata: Unifying the approaches of Safra and Muller-Schupp",
            "venue": "In ICALP,",
            "year": 2019
        },
        {
            "authors": [
                "Michael Luttenberger",
                "Philipp J. Meyer",
                "Salomon Sickert"
            ],
            "title": "Practical synthesis of reactive systems from LTL specifications via parity games",
            "venue": "Acta Informatica,",
            "year": 2020
        },
        {
            "authors": [
                "Christof L\u00f6ding"
            ],
            "title": "Optimal bounds for transformations of \u03c9-automata",
            "venue": "In FSTTCS, page 97\u2013109,",
            "year": 1999
        },
        {
            "authors": [
                "Robert McNaughton"
            ],
            "title": "Testing and generating infinite sequences by a finite automaton",
            "venue": "Information and control,",
            "year": 1966
        },
        {
            "authors": [
                "Robert McNaughton"
            ],
            "title": "Infinite games played on finite graphs",
            "venue": "Annals of Pure and Applied Logic,",
            "year": 1993
        },
        {
            "authors": [
                "Philipp Meyer",
                "Salomon Sickert"
            ],
            "title": "On the optimal and practical conversion of Emerson-Lei automata into parity automata, 2021",
            "venue": "Personal Communication",
            "year": 2021
        },
        {
            "authors": [
                "Thibaud Michaud",
                "Maximilien Colange"
            ],
            "title": "Reactive synthesis from LTL specification with Spot",
            "venue": "In SYNT@CAV, Electronic Proceedings in Theoretical Computer Science,",
            "year": 2018
        },
        {
            "authors": [
                "Andrzej W. Mostowski"
            ],
            "title": "Regular expressions for infinite trees and a standard form of automata",
            "venue": "In SCT,",
            "year": 1984
        },
        {
            "authors": [
                "David M\u00fcller",
                "Salomon Sickert"
            ],
            "title": "LTL to deterministic Emerson-Lei automata",
            "venue": "In GandALF,",
            "year": 2017
        },
        {
            "authors": [
                "David E. Muller"
            ],
            "title": "Infinite sequences and finite machines",
            "venue": "In Symposium on Switching Circuit Theory and Logical Design,",
            "year": 1963
        },
        {
            "authors": [
                "Damian Niwi\u0144ski",
                "Igor Walukiewicz"
            ],
            "title": "Relating hierarchies of word and tree automata",
            "venue": "In STACS, pages 320\u2013331,",
            "year": 1998
        },
        {
            "authors": [
                "Dominique Perrin",
                "Jean-Eric Pin"
            ],
            "title": "Infinite words - automata, semigroups, logic and games, volume 141 of Pure and applied mathematics series",
            "year": 2004
        },
        {
            "authors": [
                "Nir Piterman"
            ],
            "title": "From nondeterministic B\u00fcchi and Streett automata to deterministic parity automata",
            "venue": "In LICS,",
            "year": 2006
        },
        {
            "authors": [
                "Nir Piterman",
                "Amir Pnueli"
            ],
            "title": "Temporal logic and fair discrete systems",
            "venue": "Handbook of Model Checking,",
            "year": 2018
        },
        {
            "authors": [
                "Amir Pnueli",
                "Roni Rosner"
            ],
            "title": "On the synthesis of a reactive module",
            "venue": "In POPL, page 179\u2013190,",
            "year": 1989
        },
        {
            "authors": [
                "Florian Renkin",
                "Alexandre Duret-Lutz",
                "Adrien Pommellet"
            ],
            "title": "Practical \u201cparitizing\u201d of Emerson-Lei automata",
            "venue": "In ATVA,",
            "year": 2020
        },
        {
            "authors": [
                "Schmuel Safra"
            ],
            "title": "On the complexity of \u03c9-automata",
            "venue": "In FOCS, page 319\u2013327,",
            "year": 1988
        },
        {
            "authors": [
                "Sven Schewe"
            ],
            "title": "Tighter bounds for the determinisation of B\u00fcchi automata",
            "venue": "In FoSSaCS, pages 167\u2013181,",
            "year": 2009
        },
        {
            "authors": [
                "Sven Schewe"
            ],
            "title": "Beyond hyper-minimisation\u2014minimising DBAs and DPAs is NP-complete",
            "venue": "In FSTTCS,",
            "year": 2010
        },
        {
            "authors": [
                "Sven Schewe"
            ],
            "title": "Minimising Good-For-Games automata is NP-complete",
            "venue": "In FSTTCS,",
            "year": 2020
        },
        {
            "authors": [
                "Sven Schewe",
                "Thomas Varghese"
            ],
            "title": "Determinising parity automata",
            "venue": "In MFCS, pages 486\u2013498,",
            "year": 2014
        },
        {
            "authors": [
                "Micha\u0142 Skrzypczak"
            ],
            "title": "Topological extension of parity automata",
            "venue": "Information and Computation,",
            "year": 2013
        },
        {
            "authors": [
                "Robert Tarjan"
            ],
            "title": "Depth first search and linear graph algorithms",
            "venue": "Siam Journal On Computing,",
            "year": 1972
        },
        {
            "authors": [
                "Tom van Dijk"
            ],
            "title": "Oink: An implementation and evaluation of modern parity game solvers",
            "venue": "In TACAS,",
            "year": 2018
        },
        {
            "authors": [
                "Klaus Wagner"
            ],
            "title": "On \u03c9-regular sets",
            "venue": "Information and control,",
            "year": 1979
        },
        {
            "authors": [
                "Wies\u0142aw Zielonka"
            ],
            "title": "Infinite games on finitely coloured graphs with applications to automata on infinite trees",
            "venue": "Theoretical Computer Science,",
            "year": 1998
        }
    ],
    "sections": [
        {
            "text": "The proposed transformations are based on a novel structure, called the alternating cycle decomposition, inspired by and extending Zielonka trees. In addition to providing optimal transformations of automata, the alternating cycle decomposition offers fundamental information on their structure. We use this information to give crisp characterisations on the possibility of relabelling automata with different acceptance conditions and to perform a systematic study of a normal form for parity automata.\n2012 ACM Subject Classification Theory of computation \u2192 Automata over infinite objects\nKeywords and phrases Emerson-lei automata, good-for-games, paritizing, omega-regular languages.\nRelated Version Conference version [18]: https://drops.dagstuhl.de/opus/volltexte/2021/14192/ We incorporate results from [19]: https://drops.dagstuhl.de/opus/volltexte/2022/16458/\nFunding Thomas Colcombet: Supported by the European Research Council (ERC) under the European Union\u2019s Horizon 2020 research and innovation programme (grant agreement No.670624) \u2013 DuaLL \u2013 and the DeLTA ANR project (ANR-16-CE40-0007).\nAcknowledgements We want to thank Klara J. Meyer and Salomon Sickert for their comments and for spotting a mistake in a previous version. We also thank Alexandre Duret-Lutz and Florian Renkin for stimulating discussions around the alternating cycle decomposition, and Corto Mascle for his valuable suggestions about the presentation of this paper.\nThis document contains hyperlinks. Each occurrence of a notion is linked to its definition. On an electronic device, the reader can click on words or symbols (or just hover over them on some PDF readers) to see their definition.\nar X\niv :2\n30 5.\n04 32\n3v 1\n[ cs\n.F L\n] 7\nM ay\n2 02\n2 Contents"
        },
        {
            "heading": "1 Introduction 3",
            "text": ""
        },
        {
            "heading": "2 Preliminaries 8",
            "text": "2.1 Transition systems, automata and games . . . . . . . . . . . . . . . . . . . . . 9 2.2 Muller languages, cycles and the parity hierarchy . . . . . . . . . . . . . . . . 14 2.3 Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18"
        },
        {
            "heading": "3 Morphisms as witnesses of transformations 19",
            "text": "3.1 Morphisms of transition systems . . . . . . . . . . . . . . . . . . . . . . . . . 19 3.2 Local properties of morphisms . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 3.3 History-deterministic mappings . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.4 Preservation of semantic properties of automata and games . . . . . . . . . . 26"
        },
        {
            "heading": "4 The Zielonka tree: An optimal approach to Muller languages 29",
            "text": "4.1 The Zielonka tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 4.2 A minimal deterministic parity automaton . . . . . . . . . . . . . . . . . . . . 31\n4.2.1 The Zielonka-tree-parity-automaton . . . . . . . . . . . . . . . . . . . 31 4.2.2 Optimality of the Zielonka-tree-parity-automaton . . . . . . . . . . . . 33\n4.3 A minimal history-deterministic Rabin automaton . . . . . . . . . . . . . . . 44 4.3.1 The Zielonka-tree-HD-Rabin-automaton . . . . . . . . . . . . . . . . . 44 4.3.2 Optimality of the Zielonka-tree-HD-Rabin-automaton . . . . . . . . . 48"
        },
        {
            "heading": "5 The alternating cycle decomposition: An optimal approach to Muller transition systems 49",
            "text": "5.1 The alternating cycle decomposition . . . . . . . . . . . . . . . . . . . . . . . 49 5.2 An optimal transformation to parity transition systems . . . . . . . . . . . . 52 5.3 An optimal history-deterministic transformation to Rabin transition systems 56 5.4 Optimality of the ACD-transforms . . . . . . . . . . . . . . . . . . . . . . . . 59\n5.4.1 Statements of the optimality results . . . . . . . . . . . . . . . . . . . 59 5.4.2 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 5.4.3 Optimality of the parity condition of ACDparity(TS) . . . . . . . . . . . 60 5.4.4 Optimality of the sizes of ACDparity(TS) and ACDRabin(TS) . . . . . . . 63"
        },
        {
            "heading": "6 Corollaries 65",
            "text": "6.1 Typeness results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n6.1.1 Typeness for Muller languages . . . . . . . . . . . . . . . . . . . . . . 65 6.1.2 Typeness for Muller transition systems and deterministic automata . . 66\n6.2 A normal form for parity transition systems . . . . . . . . . . . . . . . . . . . 70 6.3 Minimisation of deterministic parity automata recognising Muller languages . 74"
        },
        {
            "heading": "7 Conclusion 76",
            "text": ""
        },
        {
            "heading": "A Generalised classes of acceptance conditions 82",
            "text": ""
        },
        {
            "heading": "B Transformations for games 85",
            "text": ""
        },
        {
            "heading": "C Simplifications for prefix-independent conditions 88",
            "text": ""
        },
        {
            "heading": "D Simplifying automata with duplicated edges 90",
            "text": "E Proofs for Section 6.1.1 91"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 3",
            "text": "1 Introduction\nContext Games and automata for LTL synthesis. Games and automata over infinite words form the theoretical basis for the verification and synthesis of reactive systems; we refer to chapters 2, 4, and 27 of the recent Handbook of Model Checking [68, 50, 3] for a broad exposition of this research area. A milestone objective is the synthesis of reactive systems with specifications given in Linear Temporal Logic (LTL). The original approach of Pnueli and Rosner [69] using automata and games devised more than four decades ago is still at the heart of the state of the art synthesis tools [33, 55, 61, 63]. The limiting factor in this method is the transformation of the LTL formula to a deterministic parity automaton. This automaton is then used to build a game, and a controller for the reactive system can be obtained from a winning strategy for this game. Most solutions to this problem (including the top-ranked tools in the SyntComp competitions [42], Strix [55, 60] and ltlsynt [61]) first construct a Muller (or Emerson-Lei) automaton, and then transform it into an equivalent parity automaton. The use of an intermediate Muller automaton is also present (although sometimes implicitly) in the most recent improvements in the determinisation of B\u00fcchi automata towards deterministic parity automata [54, 67, 73]. For this reason, understanding transformations of Muller automata and finding efficient procedures for it is of great importance.\nWhich are the simplest acceptance conditions? There exist multiple kinds of acceptance conditions that are commonly employed by \u03c9-automata (B\u00fcchi, Rabin, Muller...). The use of parity conditions for LTL synthesis is justified by both practical and theoretical reasons. Firstly, there exist several high-performing algorithms solving parity games [26, 35, 53, 79], so the last step in the LTL synthesis method described above can be carried out smoothly, once the parity game is obtained. Contrarily, solving Muller games and Rabin games is, respectively, PSPACE-complete [41] and NP-complete [31]. From a theoretical point of view, parity conditions can be considered as the simplest family of conditions that can be used to recognise all \u03c9-regular languages with deterministic automata; it could even be argued that there is a canonical aspect to them:\nFor every \u03c9-regular language L, the minimal number of output colours needed by deterministic Muller automata to recognise L is attained with parity automata (Proposition 6.14). The optimal number of colours needed by a parity automaton to recognise a language L reveals a fundamental information about it, called its parity index. This is a measure of the topological complexity of L [77, 80]. Parity languages are exactly Muller languages corresponding to families F \u2286 2\u0393+ of subsets of colours such that both F and its complement are closed under union (Proposition 6.4). Parity languages are bipositional [30] (in a parity game, both players can play optimally using positional strategies, that is, strategies that use no memory). Moreover, over infinite game graphs, these are the only bipositional languages [24], and over finite game graphs, these are the unique bipositional Muller languages [81]. Solving parity games is both in NP and co-NP [32].\nHowever, these are not the only kind of conditions that deserve our attention. In this work, we further investigate transformations producing automata using a Rabin acceptance condition. Although in practice solvers for Rabin games are not as developed, Rabin languages are a natural choice and interesting from a theoretical point of view: they are exactly the half-positional Muller languages [81], there exists a correspondence between Rabin automata\n4 and memory structures for Muller games [17, 19], and the determinisation of B\u00fcchi automata naturally produces Rabin automata [34, 72, 73].\nTransformations of games and automata. There are various existing techniques to transform Muller automata or games into parity ones. The majority of these methods involve composing the input automaton A with a deterministic parity automaton recognising the acceptance condition used by A. The first such parity automaton was introduced by Gurevich and Harrington in the 1980s [37] and is known as the Latest Appearance Record (LAR). L\u00f6ding proved that the LAR is optimal in the worst case [56]: there exists a family of Muller languages Li for which the LAR is minimal amongst deterministic parity automata recognising Li. However, the LAR is far from being minimal in every case, as it only uses the information about the size of the alphabet. Since its introduction, many refinements of the LAR have been proposed for subclasses of Muller languages [46, 56]. The approach using composition of automata has one significant drawback: it disregards the structure of the original automaton, and only its acceptance condition is taken into account. Some works have explored heuristics to improve this aspect [52, 59, 70]. These refined transformations do still have the following property: each original state q is turned into multiple states of the form (q, x) \u2013 although this is done in a non-uniform way, with each state possibly being copied a different number of times. In this work, we introduce morphisms of transition systems to formalise the idea of transformations of automata and games; if a parity automaton B has been obtained as a transformation of a Muller automaton A, there will be a morphism \u03d5 : B \u2192 A that sends states of the form (q, x) to q. A theory of morphisms of transition systems is developed in Section 3.\nHistory-deterministic automata. For the purposes of LTL synthesis and game transformations, it is imperative to eliminate non-determinism from automata, since non-deterministic automata do not yield correct games. Unfortunately, deterministic automata can be exponentially larger than non-deterministic ones. Recently, an intermediate model of automata, named history-deterministic (also called good-for-games), has received considerable attention. The reason is that history-determinism exactly captures the features of deterministic automata that make them suitable for synthesis purposes, while being a less restrictive model. A natural question that arises is whether history-deterministic automata can be more succinct that deterministic ones, and, in that case, which languages and automata types can benefit from this succinctness. It was not until several years after the introduction of historydeterminism [38, 21] that an example of an \u03c9-regular language for which history-deterministic automata are smaller than deterministic ones was exhibit [49] (and it was even conjectured that such automaton could not exist [22]). History-deterministic automata are the focus of several lines of research (we refer to the survey [12] for a detailed exposition). Despite this, a complete understanding of history-deterministic automata remains elusive, and their scope of applicability is still uncertain. One key aspect that has not yet been addressed is how to design techniques as general as possible for building history-deterministic automata. To the best of our knowledge, the only existing result in this direction is a polynomial-time algorithm to minimise coB\u00fcchi history-deterministic automata [1].\nThe Zielonka tree and the alternating cycle decomposition. The starting point of our work is the notion of Zielonka tree, introduced by Zielonka [81] as an informative representation of Muller languages \u2013 languages that can be described by a boolean combination of atomic propositions of the form \u201cthe letter \u2018a\u2019 appears infinitely often\u201d. The Zielonka tree"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 5",
            "text": "captures many important properties of Muller languages, such as being Rabin or parity [81], and, most importantly, it characterises their exact memory requirements, both in two-player games [28] and stochastic games [40].\nThe contribution at the core of this work is a generalisation of Zielonka trees to general Muller automata recognising any \u03c9-regular language, which we call the alternating cycle decomposition (ACD). The ACD, greatly inspired from Wagner\u2019s work on \u03c9-automata [80], is a data structure that provides an abridged representation of the accepting and rejecting cycles of the automaton, encapsulating the interplay between the structure of the underlying graph and the acceptance condition of a Muller automaton.\nContributions In this work, we carry out an extensive study of transformations of Muller automata and games. We outline next our main contributions.\n1. Minimal automata for Muller languages. The basis on which we build up our work is a study of minimal automata recognising Muller languages. Using the Zielonka tree, we propose a construction of a deterministic parity automaton recognising a Muller language (Section 4.2). This construction implicitly appears in the long version of [28]. We show a strong optimality result: for all Muller language L, the parity automaton obtained from the Zielonka tree is minimal both amongst deterministic and history-deterministic parity automata recognising L (Theorem 4.13)1. Moreover, it uses the optimal number of output colours to recognise L (Theorem 4.12). The optimality result we obtain is much stronger than the worst case optimality result of the LAR transformation [56], since it applies to every Muller language. In particular, our characterisation yields an algorithm to minimise deterministic parity automata recognising Muller languages in polynomial time (Theorem 6.31). In light of our result, we conclude that the use of history-determinism does not yield any gain in the state complexity of parity automata recognising Muller languages. We further propose a construction of a history-deterministic Rabin automaton recognising a Muller language (Section 4.3), and prove that this automaton is minimal amongst history-deterministic Rabin automata (Theorem 4.48). This construction is also based on the Zielonka tree. In essence, our results reinforce the idea that the Zielonka tree precisely captures the fundamental properties of Muller languages.\n2. Introducing morphisms as witnesses of transformations. In order to formalise transformations of games and automata, we develop a theory of morphisms of transition systems (Section 3). Intuitively, a morphism \u03d5 : B \u2192 A witnesses the fact that B has been obtained from A by blowing up each state q \u2208 A to the states in \u03d5\u22121(q). However, this property on its own does not suffice to guarantee the semantic equivalence of A and B. It is for this reason that we introduce different variants of morphisms, offering a range of definitions with varying degrees of restrictiveness. Two kind of morphisms will be of central importance: (1) locally bijective morphisms, which generalise composition by deterministic automata and preserve determinism, and (2) history-deterministic mappings (HD mappings), which generalise composition by history-deterministic automata and are"
        },
        {
            "heading": "1 The optimality of the Zielonka-tree-parity-automaton amongst deterministic automata has also been",
            "text": "obtained in the independent unpublished work [59].\n6 defined using a minimal set of hypothesis guaranteeing the semantic equivalence of A and B."
        },
        {
            "heading": "3. The alternating cycle decomposition and optimal transformations of Muller transition",
            "text": "systems. In order to generalise the fruitful applications of the Zielonka tree to Muller automata and games, we introduce the alternating cycle decomposition (ACD), a data structure that captures the interplay of the underlying graph of these transition systems and their acceptance condition (Section 5). Using the ACD, we describe a construction that transforms a Muller automaton A into an equivalent parity automaton B while preserving the determinism of A (formally, there is a locally bijective morphism \u03d5 : B \u2192 A). This transformation comes with a strong optimality guarantee: for any other parity automaton B\u2032 admitting a locally bijective morphism (or even HD mapping) \u03d5\u2032 : B\u2032 \u2192 A, the automaton B is smaller than B\u2032 and it uses less output colours (Theorems 5.31 and 5.32). An interesting corollary of our result is the following: if B is an HD parity automaton that is strictly smaller than any deterministic parity automaton recognising L(B), then B cannot be derived from a deterministic Muller automaton (Corollary 5.36). This result sheds light on the difficulty to obtain succinct HD automata and their potential applicability. We also provide a transformation that translates a Muller automaton A into a historydeterministic Rabin automaton B in an optimal way: for any other Rabin automaton B\u2032 admitting an HD mapping \u03d5\u2032 : B\u2032 \u2192 A, the automaton B is smaller than B\u2032.\n4. Structural results for Muller transition systems. The ACD does not only provide optimal transformations of games and automata, it also features some of their fundamental structural properties. As an application, we give a set of crisp characterisations for relabelling automata with different classes of acceptance conditions (Section 6.1). For instance, we show that given a Muller automaton A, we can define a Rabin condition over the underlying graph of A obtaining an equivalent automaton if and only if the union of rejecting cycles of A is again a rejecting cycle. Our results unify and extend those from [5, 9, 47, 81]. In Section 6.2, we conduct a comprehensive examination of a normal form for parity automata. This normal form implicitly appears in [15], and has since proven instrumental in proofs about history-deterministic automata [1, 29, 49], positionality of \u03c9-regular languages [13] and learning of \u03c9-automata [4]. Similar normalisation procedures are commonly applied to parity games to speed up algorithms solving them [35]. We use the ACD to provide straightforward proofs of the fundamental properties which make automata in normal form practical in both theoretical proofs and applications.\nOur model: transition systems and acceptance over edges. We want to point out a few technical details about the model used in this paper. First, we work with general transition systems for two reasons: (1) to seamlessly encompass both automata and games models, and (2) to emphasise that the ACD and the transformations we propose do only depend in the underlying graph and the acceptance condition; we can view the input letters of an automaton, or the partition of the vertices in a game, as add-ons that do not affect the core of our approach.\nAlso, we define acceptance conditions over the edges of transitions systems \u2013 instead of over the vertices. This choice has been shown to yield more canonical results in theory, for instance, in the study of strategy complexity for games [13, 17, 24, 81], the determinisation of B\u00fcchi automata [25, 76], or the minimisation of history-deterministic automata [1, 29]. It has also proven to be more applicable in practical scenarios [27, 36]. We believe that the"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 7",
            "text": "present work provides further evidence to this claim, as the minimal automaton obtained from the Zielonka tree, as well as the transformations based on the ACD, substantially rely on the use of edge-based acceptance.\nFinally, we remark that in this work we are concerned with state complexity, that is, the efficiency of a construction is measured based on the number of states of the resulting transition system. We do not focus in the representation of the acceptance conditions; for instance, we will not differentiate between Muller or Emerson-Lei conditions, as they have the same expressive power (see also Remark 2.11).\nRelated versions\nThis paper is based on a preceding conference version [18], and incorporates material from another conference paper [19]. In addition, we have introduced some new content, revised the presentation and simplified various proofs. We outline the provenance of the different results:\nICALP 2021 [18]. Most of the material concerning deterministic automata and locally bijective morphisms comes from [18]. This includes the construction of a parity automaton from the Zielonka tree (Section 4.2.1), the definition of the ACD (Section 5.1) and the construction of a parity automata from it (Section 5.2), as well as the introduction of locally bijective morphisms (Section 3.2) and the typeness results from Section 6.1. However, in [18], the optimality of the Zielonka-tree-parity-automaton and the ACDparity-transform was proven only with respect to deterministic automata and locally bijective morphisms, respectively. Moreover, the proof of the optimality of the ACDparity-transform (Theorem 5.32) has been simplified. ICALP 2022 [19]. The construction of history-deterministic Rabin automata for Muller languages (Section 4.3) and its optimality (Theorem 4.48) come from [19]. Original content. The following content has not appeared in any precedent work: optimality of the Zielonka-tree-parity-automaton with respect to HD automata (Theorem 4.13); the definition of HD mappings, as well as the systematic study of the different kinds of morphisms (Sections 3.3 and 3.4); the ACD-HD-Rabin-transform (Section 5.3) and its optimality (Theorem 5.33); and the introduction of a normal form for parity automata (Section 6.2).\nIn this paper, we have tried to integrate these results to present a coherent and complete exposition of the theory of optimal transformations of Muller automata.\nFollow-up work\nDespite its recent introduction [18], the alternating cycle decomposition has already found applications in both practical and theoretical scenarios. The ACD-parity-transform has been implemented in two open-source tools: Spot 2.10 [27] and Owl 21.0 [45], and it is used in the LTL-synthesis tools ltlsynt [27] and Strix [60]. These implementations were presented in the conference paper [20], where transformations based on the ACD are compared to the state-of-the-art existing paritizing methods.\nThe typeness results steaming from the ACD [18, Section 5] have also been proven instrumental in theoretical applications. They have been used to show a correspondence between Rabin automata and memory structures for games [17], and to provide lower bounds in the size of deterministic Rabin automata [19].\n8 2 Preliminaries\nIn this section we introduce definitions that will be used throughout the paper.\nBasic definitions\nFor a set A we let |A| denote its cardinality, 2A its power set and 2A+ = 2A \\ {\u2205}. For a family of subsets F \u2286 2A and A\u2032 \u2286 A, we write F|A\u2032 = F \u2229 2A\n\u2032 . For natural numbers i \u2264 j, [i, j] stands for {i, i+ 1, . . . , j \u2212 1, j}.\nFor a set \u03a3, a word over \u03a3 is a sequence of elements from \u03a3. An \u03c9-word (or simply an infinite word) is a word of length \u03c9. The sets of finite and infinite words over \u03a3 will be written \u03a3\u2217 and \u03a3\u03c9, respectively, and we let \u03a3\u221e = \u03a3\u2217 \u222a \u03a3\u03c9. Subsets of \u03a3\u2217 and \u03a3\u03c9 will be called languages. For a word w \u2208 \u03a3\u221e we write wi to represent the i-th letter of w. We let \u03b5 denote the empty word, and let \u03a3+ = \u03a3\u2217 \\ {\u03b5}. The concatenation of two words u \u2208 \u03a3\u2217 and v \u2208 \u03a3\u221e is written u \u00b7 v, or simply uv. If u = v \u00b7 w for v \u2208 \u03a3\u2217, u, w \u2208 \u03a3\u221e, we say that v is a prefix of u and we write v v u. For a word w \u2208 \u03a3\u03c9, we let Inf(w) = {a \u2208 \u03a3 | wi = a for infinitely many i \u2208 N}.\nWe say that a language L \u2286 \u03a3\u03c9 is prefix-independent if for all w \u2208 \u03a3\u03c9 and u \u2208 \u03a3\u2217, uw \u2208 L if and only if w \u2208 L.\nGiven a map \u03b1 : A\u2192 B, we will extend \u03b1 to words component-wise, i.e., \u03b1 : A\u221e \u2192 B\u221e will be defined as \u03b1(w0w1w2 . . . ) = \u03b1(w0)\u03b1(w1)\u03b1(w2) . . . . We will use this convention throughout the paper without explicitly mentioning it. If A\u2032 \u2286 A, we note \u03b1|A\u2032 the restriction of \u03b1 to A\u2032. We let IdA be the identity function on A. We write \u03b1 : A \u21c0 B if \u03b1 is a partial mapping (it is defined only over some subset of A).\nA graph2 is a tuple G = (V,E,Source,Target) where V is a set of vertices, E a set of edges and Source : E \u2192 V and Target : E \u2192 V are maps indicating the source and target for each edge. A path is a (finite or infinite) sequence \u03c1 = e0e1... \u2208 E\u221e such that Source(ei) = Target(ei\u22121) for all i > 0. For notational convenience, we write v0 e0\u2212\u2192 v1 \u00b7 \u00b7 \u00b7 en\u22121\u2212\u2212\u2212\u2192 vn to denote a finite path from v0 = Source(e0) to vn = Target(en\u22121) and we let Source(\u03c1) = v0 and Target(\u03c1) = vn. For A \u2286 V , we let PathfinA (G) and PathA(G) denote, respectively, the set of finite and infinite paths on G starting from some v \u2208 A (we omit brackets if A = {v} is a singleton). We let Path\u221eA (G) = Path fin A (G) \u222a PathA(G). For a subset of vertices A \u2286 V we write:\nIn(A) = {e \u2208 E | Target(e) \u2208 A}, Out(A) = {e \u2208 E | Source(e) \u2208 A}.\nAll graphs considered in this paper will be finite. A graph is strongly connected if there is a path connecting each pair of vertices. A subgraph of (V,E,Source,Target) is a graph (V \u2032, E\u2032,Source\u2032,Target\u2032) such that V \u2032 \u2286 V , E\u2032 \u2286 E and Source\u2032 and Target\u2032 are the restrictions of Source and Target to E\u2032, respectively. A strongly connected component (SCC) is a maximal strongly connected subgraph. We say that a SCC is final if there is no edge leaving it. We say that a vertex v is recurrent if it belongs to some SCC, and that it is transient on the contrary.\n2 In this work we will use the term graph to denote what is sometimes called a directed multigraph (edges are directed, and multiple edges between two vertices are allowed)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 9",
            "text": ""
        },
        {
            "heading": "2.1 Transition systems, automata and games",
            "text": "Transition systems. A pointed graph G = (V,E,Source,Target, I) is a graph together with a non-empty subset of initial vertices I \u2286 V . An acceptance condition over G is a tuple Acc = (\u03b3,\u0393,W) where \u0393 is a finite set of colours, \u03b3 : E \u2192 \u0393 \u222a {\u03b5} is an edge-colouring of G and W \u2286 \u0393\u03c9 is a language of infinite words called the acceptance set. We allow uncoloured edges (\u03b5-edges), but we impose the condition that no infinite path of G is eventually composed exclusively of \u03b5-edges (that is, every cycle contains some edge e with \u03b3(e) 6= \u03b5).\nA transition system (abbreviated TS) is a tuple TS = (GTS ,AccTS), where GTS = (V,E,Source,Target, I) is a pointed graph, called the underlying graph of TS, and AccTS = (\u03b3,\u0393,W) is an acceptance condition over GTS . We will also refer to vertices and edges as states and transitions, respectively. We write v c\u2212\u2192 v\u2032 if there is e \u2208 E such that Source(e) = v, Target(e) = v\u2032 and \u03b3(e) = c. We will suppose for technical convenience that transition systems contain no sink, that is, every vertex has at least one outgoing edge . For any non-empty subset of vertices I\u0303 \u2286 V , we let TS I\u0303 be the transition system obtained from TS by setting I\u0303 to be its set of initial vertices. The size of a transition system TS is the cardinality of its set of vertices, written |TS|.\nA run on a transition system TS (or on a pointed graph) is a (finite or infinite) path \u03c1 = e0e1 \u00b7 \u00b7 \u00b7 \u2208 E\u221e starting from an initial vertex, that is, Source(e0) \u2208 I. We let Runfin(TS) and Run(TS) be the set of finite and infinite runs on TS, respectively, and we let Run\u221e(TS) = Runfin(TS) \u222a Run(TS). (We note that Run(TS) = PathI(GTS).)\nThe output of a run \u03c1 \u2208 Run\u221e(TS) is the sequence of colours in \u0393\u221e obtained by removing the occurrences of \u03b5 from \u03b3(\u03c1); which we will also denote by \u03b3(\u03c1) by a small abuse of notation. A run \u03c1 is accepting if \u03b3(\u03c1) \u2208W, and rejecting otherwise (in particular, finite runs will be rejecting). We write \u03c1 = v w v\u2032 to denote a run with Source(\u03c1) = v, Target(\u03c1) = v\u2032 and \u03b3(\u03c1) = w.\nWe say that a vertex v \u2208 V is accessible (or reachable) from a vertex v0 if there exists a finite path from v0 to v. We say that v is accessible if it is accessible from some initial vertex. A set of states B \u2286 V is accessible if every state v \u2208 B is accessible. The accessible part of a transition system is the set of accessible states. We define analogously the accessible part from a vertex v0.\nA labelled graph (G, (lV , LV ), (lE , LE)) is a graph together with labelling functions lV : V \u2192 LV , lE : E \u2192 LE , where LV and LE are sets of labels for vertices and edges, respectively. If only the first (resp. the second) of these labelling functions appears, we will use the terms vertex-labelled (resp. edge-labelled) graphs. A labelled transition system is a transition system with labelled underlying graph.\nI Remark 2.1. We remark that, whenever necessary, we can suppose without loss of generality that in the acceptance condition Acc = (\u03b3,\u0393,W) of a transition system, \u0393 = E is the whole set of edges and \u03b3 is the identity function. Indeed, an equivalent acceptance condition can always be defined by using the acceptance set W\u2032 = {w \u2208 E\u03c9 | \u03b3(w) \u2208W} \u2286 E\u03c9 .\nAutomata. A (non-deterministic) automaton over \u03a3 is an edge-labelled transition system A = (GA,AccA, (l\u03a3,\u03a3)), where \u03a3 is a finite set of input letters. Let A be an automaton with GA = (Q,\u2206,Source,Target, I) as underlying graph and AccA = (\u03b3,\u0393,W) as acceptance condition. We write e = q a:c\u2212\u2212\u2192 q\u2032 to denote that e \u2208 \u2206 satisfies l\u03a3(e) = a and \u03b3(e) = c. We can suppose that \u2206 \u2286 Q\u00d7 \u03a3\u00d7 \u0393\u00d7Q. We define:\n\u03b4(q, a) = {(q\u2032, c) \u2208 Q\u00d7 \u0393 | there is e = q a:c\u2212\u2212\u2192 q\u2032 \u2208 \u2206}.\n10\nWe note that we can now recover the classical representation of an automaton as a tuple A = (Q,\u03a3, I,\u0393, \u03b4,W), (or (Q,\u03a3, I,\u0393,\u2206,W)) which we might use when working exclusively with automata.\nWe say that an automaton A is deterministic if I is a singleton and for every q \u2208 Q and a \u2208 \u03a3, |\u03b4(q, a)| \u2264 1. We say that A is complete if for every q \u2208 Q and a \u2208 \u03a3, |\u03b4(q, a)| \u2265 1. We remark that we can suppose that automata are complete without loss of generality by adding a sink state.\nGiven an automaton A and a word w \u2208 \u03a3\u221e, a run over w in A is a run \u03c1 = e0e1 \u00b7 \u00b7 \u00b7 \u2208 Run\u221e(A) such that l\u03a3(ei) = wi for all i \u2265 0. A word w \u2208 \u03a3\u03c9 is accepted by A if it exists a run over w that is accepting (that is, a run \u03c1 such that \u03b3(\u03c1) \u2208W). The language accepted (or recognised) by an automaton A is the set\nL(A) := {w \u2208 \u03a3\u03c9 | w is accepted by A}.\nTwo automata recognising the same language are said equivalent. We remark that if A is deterministic (resp. complete), there is at most one (resp. at least one) run over w for each w \u2208 \u03a3\u221e. Given a subgraph G\u2032 of the underlying graph of an automaton A and a subset of states I \u2032 in G\u2032, the subautomaton induced by G\u2032 with initial states I \u2032 is the automaton having G\u2032 as underlying graph, I \u2032 as set of initial states, and whose acceptance condition and labelling with input letters are the restrictions of those of A.\nHistory-deterministic automata. Let A be a (non-deterministic) automaton over \u03a3 with \u2206 as set of transitions and I as set of initial states. A resolver for A is a pair (r0, r), consisting of a choice of an initial state3, r0 \u2208 I, and a function r : \u2206\u2217 \u00d7 \u03a3 \u2192 \u2206 such that for all words w = w0w1 \u00b7 \u00b7 \u00b7 \u2208 \u03a3\u03c9, the sequence e0e1 \u00b7 \u00b7 \u00b7 \u2208 \u2206\u03c9, called the run induced by r over w and defined by ei = r(e0 . . . ei\u22121, wi) is actually a run over w in A starting from r0. We say that the resolver is sound if it satisfies that for every w \u2208 L(A), the run induced by r over w is an accepting run. In other words, r should be able to construct an accepting run in A letter-by-letter with only the knowledge of the word so far, for all words in L(A). An automaton A is called history-deterministic (shortened HD, also called good-for-games in the literature) if there is a sound resolver for it. I Remark 2.2. Deterministic automata are history-deterministic, and they admit a unique resolver.\nI Example 2.3. In Figure 1, we show an automaton A over \u03a3 = {a, b, c} that is not deterministic (as it has two b-transitions from q1) but is history-deterministic. Its set of output colours is \u0393 = {1, 2} and its acceptance set isW = {u \u2208 {1, 2}\u03c9 | u contains finitely many 1s} (this is a coB\u00fcchi condition, as introduced in the next section). It is easy to check that A recognises the language:\nL(A) = {w \u2208 \u03a3\u03c9 | Inf(w) \u2286 {a, b} or Inf(w) \u2286 {b, c}}.\nA resolver for A only has to take a decision when the automaton is in the state q1 and letter b is provided. In this case, a sound resolver is obtained by using the following strategy:\n3 Sometimes in the literature [7, 12, 38] the initial state r0 is not required to be specified. This would permit to choose it after the first letter w0 is given. We consider that a resolver constructing a run without guessing the future should pick the initial state before the first letter is revealed, hence the introduction of r0 in the definition of a resolver. The suitability of this choice will be further supported by the generalisation of HD automata to HD mappings (Section 3.3)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 11",
            "text": "if the last letter seen was a, we take the transition leading to state q0; if it was c, we take the transition leading to q2. This strategy ensures that, if eventually only letters in {a, b} (resp. {b, c}) are seen, the run will end up in state q0 (resp. q2) and remain there indefinitely, without producing any colour 1. y\nWe say that an state q is reachable using the resolver (r0, r) if there is a finite run \u03c1 = r0 q such that \u03c1 is the run induced by r over some word w \u2208 \u03a3\u2217.\nNext remark indicates that we can suppose without loss of generality that all states in an HD automaton are reachable using some sound resolver. I Remark 2.4. Let A be an HD automaton, let (r0, r) be a sound resolver for it and let A\u0303 be the subautomaton induced by the set of states reachable using (r0, r), with initial state r0. Then, L(A) = L(A\u0303).\nThe following lemma provides a simplification for automata recognising prefix-independent languages. Its proof can be found in Appendix C. Together with Remark 2.4, it indicates that when dealing with HD automata for this kind of languages, we can suppose that any state of the automaton is the initial one. In particular there will be no need to specify the initial states of subautomata induced by subgraphs of HD automata recognising prefix-independent languages.\nI Lemma 2.5. Let A be a history-deterministic automaton recognising a prefix-independent language and using as acceptance set a prefix-independent language. For any state q of A that is reachable using some sound resolver, it is verified that A recognises the same language if we fix q as initial state, that is, L(A) = L(Aq). Moreover, Aq is also history-deterministic. In particular, if A is deterministic, this is the case for any reachable state q.\nGames. A game is a vertex-labelled transition system G = (GG ,AccG , (lPlayers, {Eve,Adam})), with GG = (V,E,Source,Target, I) a pointed graph, and lPlayers : V \u2192 {Eve,Adam} a vertexlabelling function inducing a partition of V into vertices controlled by two players that we refer to as Eve and Adam. We let VEve = l\u22121Players(Eve) and VAdam = l \u22121 Players(Adam).\nDuring a play, players move a token from one vertex to another for an infinite amount of time. The player who owns the vertex v where the token is placed chooses an edge in Out(v) and the token travels through this edge to its target. In this way, they produce an infinite run \u03c1 on G (that we also call a play). The objective of Eve is to produce an accepting run (a sequence of colours in W), and Adam tries to prevent it.\nA strategy from v \u2208 V for Eve is a (partial) function stratv : Pathfinv (G) \u21c0 E, defined for finite paths from v ending in a vertex in VEve, that tells Eve which move to choose after any possible finite play. We say that a play \u03c1 \u2208 Path\u221ev (G) is consistent with the strategy stratv\n12\nif after each finite prefix \u03c1\u2032 v \u03c1 ending in a vertex controlled by Eve, the next edge in \u03c1 is stratv(\u03c1\u2032). We say that stratv is a winning strategy for Eve if all plays from v consistent with stratv are accepting. We say that Eve wins the game G from v if there is a winning strategy from v for her. Strategies for Adam are defined dually.\nGiven a game G, the winning region of G for Eve, written WEve(G), is the set of initial vertices v \u2208 I such that she wins the game G from v. The full winning region of G for Eve is her winning region in the game GV where all vertices are initial, that is, the set of vertices v \u2208 V such that Eve wins the game G from v.\nIn some proofs, we will need to take a close look into the strategies used in games, for which we need to introduce finite memory strategies. For a set X (usually the set of edges of a game), we define a memory skeleton over X as an edge-labelled pointed graph M = (M,EM ,Source,Target,m0) with a single initial state m0 and labels lM : EM \u2192 X inducing a deterministic structure, that is, satisfying that for each m \u2208M and x \u2208 X there is at most one transition e \u2208 Out(m) labelled x. We denote \u00b5 : M\u00d7X \u21c0M the update function given by \u00b5(m,x) = m\u2032 if m x\u2212\u2192 m\u2032 is the (only) transition from m labelled x. We extend \u00b5 to \u00b5 : M \u00d7X\u2217 \u21c0M by induction (\u00b5(m, \u03b5) = m and \u00b5(m,x1 . . . xn) = \u00b5(\u00b5(m,x1 . . . xn\u22121), xn)). A memory structure (for Eve) for a game G is a memory skeleton over the set E of edges of G together with a next-move function \u03c3 : VEve \u00d7M \u2192 E. We say that(M, \u03c3) implements a strategy stratv : Pathfinv (G) \u21c0 E if for any finite play \u03c1 \u2208 Path fin v (G) ending in VEve, stratv(\u03c1) = \u03c3(Target(\u03c1), \u00b5(m0, \u03c1)). We remark that a memory structure for G implements at most one strategy from a given vertex. We say that stratv is a finite memory strategy if it can be implemented by a finite memory structure.\nComposition of a transition system and an automaton. We now present the construction of the composition (or product) of a transition system with an automaton, which constitutes the standard method for transforming a transition system that uses an acceptance set W1 to another one using a different acceptance set W2. To guarantee the correctness of the resulting transition system (that is, that it has the same semantic properties as the original one), the automaton must be deterministic or history-deterministic (see Propositions 2.6, 2.7, and 2.8).\nLet TS = (GTS ,AccTS) be a transition system, with GTS = (V,E,SourceTS ,TargetTS , ITS) and AccTS = (\u03b3TS ,\u03a3,WTS), and let A = (GA,AccA, (l\u03a3,\u03a3)) be a complete automaton over the alphabet \u03a3, where GA = (Q,\u2206,SourceA,TargetA, IA) and AccA = (\u03b3A,\u0393,WA). The composition of TS and A (also called their product) is the transition system TS nA defined as follows:\nThe set of vertices is the cartesian product V \u00d7Q. The set of initial vertices is ITS \u00d7 IA. The set of edges En contains a transition (v, q) c\u2212\u2192 (v\u2032, q\u2032) if there is a \u2208 \u03a3 and transitions e1 = v a\u2212\u2192 v\u2032 \u2208 E and e2 = q a:c\u2212\u2212\u2192 q\u2032 \u2208 \u2206. It also contains \u03b5-edges (v, q) \u03b5\u2212\u2192 (v\u2032, q) if v \u03b5\u2212\u2192 v\u2032 \u2208 E. Formally,\nEn = {(e1, e2) \u2208 E\u00d7\u2206 | \u03b3TS(e1) = l\u03a3(e2)} \u222a {e1 \u2208 E | \u03b3TS(e1) = \u03b5} \u2286 (E\u00d7\u2206)\u222aE.\nThe acceptance condition is inherited from that of A: the colouring function \u03b3\u2032 : En \u2192 \u0393 is defined as \u03b3\u2032(e1, e2) = \u03b3(e2), and the acceptance set is WA \u2286 \u0393\u03c9.\nWe remark that if TS does not contain an uncoloured cycle, neither does TS nA. Also, TS nA does not contain sinks by completeness of A."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 13",
            "text": "If TS is a labelled transition system, labelled by the functions lV and lE , we consider TSnA as a labelled transition system with the functions lnV (v, q) = lV (v) and l n E(e1, e2) = lE(e1) (resp. lnE(e1) = lE(e1) if e1 is an uncoloured edge). Intuitively, a computation in TS nA happens as follows: we start from a vertex v0 \u2208 ITS in TS and from q0 \u2208 IA. When we are in a position (v, q) \u2208 V \u00d7Q, a transition e between v and v\u2032 takes place in TS, producing a letter a \u2208 \u03a3 as output. Then, the automaton A proceeds using a transition corresponding to a, producing an output in \u0393. In this way, a word in \u0393\u03c9 is generated and we can use the acceptance set WA \u2286 \u0393\u03c9 of the automaton as the acceptance set for TS nA.\nIn particular, we can perform this operation if TS is an automaton. We obtain in this way a new automaton that uses the acceptance condition of A.\nWe could, of course, apply this construction to a game G, obtaining a new game G nA in which the player who makes a move in G also chooses a transition in A corresponding to the letter produced by the selected move. However, in most applications, we intend to obtain an asymmetric form of product game in which one player has full control of the transitions of the automaton (we take the point of view of Eve and want her to choose these transitions). For this reason, we restrain the class of games to which we can apply the product construction by a non-deterministic automaton.\nWe say that a game is suitable for transformations if it satisfies that for every edge e = v \u2212\u2192 v\u2032 such that v \u2208 VAdam, the edge e is uncoloured (\u03b3(e) = \u03b5), v\u2032 \u2208 VEve, and e is the only incoming edge to v\u2032 (In(v\u2032) = {e}). We remark that any game G can be made suitable for transformations with at most a linear blow up on the size by inserting an intermediate Eve-vertex in each edge outgoing from an Adam-vertex. A formal construction, as well as further motivation for this definition, can be found in Appendix B.\nThe following results are well known and constitute the main application of automata composition. They can be seen as corollaries of our results from Section 3.4, which generalise them.\nI Proposition 2.6 (Folklore). Let B be an automaton with acceptance set WB and let A be an automaton recognising L(A) = WB. Then, L(B nA) = L(B). Moreover, if A and B are deterministic (resp. history-deterministic), so is B nA.\nI Proposition 2.7 ([38]). Let G be a game that is suitable for transformations with acceptance set WG, and let A be a history-deterministic automaton recognising L(A) = WG. Then, the winning region of Eve in G is the projection of her winning region in G n A, that is, Eve wins G from an initial vertex v if and only if she wins G nA from (v, q0), for q0 some initial vertex of A.\nProposition 2.7 fails if the automaton is not HD. In fact, this property characterises history-determinism, which is the reason why HD automata are also called good-for-games in the literature. However, it should be noted that history-determinism and good-for-gameness have been generalised to other contexts in which they do not necessarily yield equivalent notions [11, 21].\nI Proposition 2.8 ([38]). Let A be an automaton recognising WG \u2286 \u03a3\u03c9 satisfying that for every game G suitable for transformations with acceptance set WG, Eve wins the game G from an initial vertex v if and only if she wins G nA from (v, q0), for q0 some initial vertex of A. Then, A is history-deterministic.\n14"
        },
        {
            "heading": "2.2 Muller languages, cycles and the parity hierarchy",
            "text": "Languages commonly used as acceptance sets. We now define the main classes of languages used by \u03c9-regular automata as acceptance sets. We let \u0393 stand for a finite set of colours.\nB\u00fcchi. Given a subset B \u2286 \u0393, we define the B\u00fcchi language associated to B as:\nB\u00fcchi\u0393(B) = {w \u2208 \u0393\u03c9 | Inf(w) \u2229B 6= \u2205}.\nWe say that a language L \u2286 \u0393\u03c9 is a B\u00fcchi language if there is a set B \u2286 \u0393 such that L = B\u00fcchi\u0393(B).\ncoB\u00fcchi. Given a subset B \u2286 \u0393, we define the coB\u00fcchi language associated to B as:\ncoB\u00fcchi\u0393(B) = {w \u2208 \u0393\u03c9 | Inf(w) \u2229B = \u2205}.\nWe say that a language L \u2286 \u0393\u03c9 is a coB\u00fcchi language if there is a set B \u2286 \u0393 such that L = coB\u00fcchi\u0393(B). Rabin. A Rabin language is represented by a family R = {(G1, R1), . . . , (Gr, Rr)} of Rabin pairs, where Gj , Rj \u2286 \u0393. The Rabin language associated to R is defined as:\nRabin\u0393(R) = {w \u2208 \u0393\u03c9 | [Inf(w) \u2229Gj 6= \u2205 and Inf(w) \u2229Rj = \u2205] for some index j}.\nIf [Inf(w) \u2229 Gj 6= \u2205 and Inf(w) \u2229 Rj = \u2205], we say that w is accepted by the Rabin pair (Gj , Rj). We say that a language L \u2286 \u0393\u03c9 is a Rabin language if there is a family of Rabin pairs R such that L = Rabin\u0393(R). Streett. The Streett language associated to a family S = {(G1, R1), . . . , (Gr, Rr)} of Rabin pairs is defined as:\nStreett\u0393(S) = {w \u2208 \u0393\u03c9 | [Inf(w) \u2229Gj 6= \u2205 implies Inf(w) \u2229Rj = \u2205] for all indices j}.\nWe say that a language L \u2286 \u0393\u03c9 is a Streett language if there is a family of Rabin pairs S such that L = Streett\u0393(S).\nParity. We define the parity language over the alphabet [dmin, dmax] \u2286 N as:\nparity[dmin,dmax] = {w \u2208 [dmin, dmax] \u03c9 | min Inf(w) is even}.\nWe say that a language L \u2286 \u0393\u03c9 is a [dmin, dmax]-parity language if there is a mapping \u03c6 : \u0393\u2192 [dmin, dmax] such that for all w \u2208 \u0393\u03c9, w \u2208 L if and only if \u03c6(w) \u2208 parity[dmin,dmax]. We say that L is a parity language if there are dmin, dmax \u2208 N such that L is a [dmin, dmax]parity language. Muller. We define the Muller language associated to a family F \u2286 2\u0393+ of non-empty subsets of \u0393 as:\nMuller\u0393(F) = {w \u2208 \u0393\u03c9 | Inf(w) \u2208 F}.\nWe say that a language L \u2286 \u0393\u03c9 is a Muller language if there is a family F \u2286 2\u0393+ such that L = Muller\u0393(F).\nWe drop the subscript \u0393 (resp. [dmin, dmax]) whenever the set of colours is clear from the context. We remark that all languages of the classes above are prefix-independent (for all w \u2208 \u0393\u03c9 and u \u2208 \u0393\u2217, uw \u2208 L if and only if w \u2208 L)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 15",
            "text": "We say that an acceptance condition (resp. transition system, automaton) is an X condition (resp. X transition system, X automaton), for X one of the classes of languages above, if its acceptance set is an X language. In the case of parity transition systems, we will always suppose that the set of colours is a subset of N and \u03c6 is the identity function.\nWe let DPA stand for deterministic parity automaton and DMA for deterministic Muller automaton.\nWe discuss further classes of languages in Appendix A (generalised B\u00fcchi and coB\u00fcchi languages, as well as generalised weak acceptance). We refer to the survey [6] for a more detailed account on different types of acceptance conditions. I Remark 2.9 (Inclusions between classes). We observe that there are many inclusions between the classes of languages that we have introduced. For example, B\u00fcchi languages are exactly [0, 1]-parity languages, and parity languages are Rabin languages [62]. In particular, all classes above are special cases of Muller languages. The relations between these classes of languages are outlined in Figure 2. y\nI Remark 2.10. A language L \u2286 \u0393\u03c9 is a Muller language if and only if it satisfies:\nFor all w,w\u2032 \u2208 \u0393\u03c9, if Inf(w) = Inf(w\u2032), then w \u2208 L \u21d0\u21d2 w\u2032 \u2208 L. y\nI Remark 2.11 (Representation of acceptance conditions). In practice, there exists a variety of ways to represent Muller languages and acceptance conditions of automata: using boolean formulas (Emerson-Lei conditions), as a list of accepting subsets of edges, etc. The complexity and practicality of algorithms manipulating automata and games may greatly differ depending on the representation of their acceptance conditions [39, 41]. However, in this work, we are mostly interested in the expressive power of acceptance conditions, and the results we present will not depend on how they are represented. y\nI Example 2.12. In Figure 3 we show three different types of automata over the alphabet \u03a3 = {a, b} recognising the language\nL = {w \u2208 \u03a3\u03c9 | w = ub\u03c9 or (w = ua\u03c9 and u has an even number of \u2018b\u2019s )}. y\n\u03c9-regular languages. The class of \u03c9-regular languages plays a central role in the theory of formal languages and verification. The significance of \u03c9-regular languages is (partly) due to the robustness of its definition, as they admit multiple equivalent characterisations relating different areas of study.\nI Proposition 2.13 ([62, 64]). Let L \u2286 \u03a3\u03c9 be a language of infinite words. The following properties are equivalent:\nL can be recognised by a non-deterministic B\u00fcchi automaton.\n16\nub\u03c9 or (w = ua\u03c9 and u has an even number of \u2018b\u2019s )}.\nL can be recognised by a deterministic parity automaton. L can be recognised by a non-deterministic Muller automaton.\nA language satisfying the previous conditions is called \u03c9-regular. Many other equivalent definitions exist. Notably, \u03c9-regular languages are exactly the languages that can be defined using monadic second-order logic [14], those that can be described by using \u03c9-regular expressions [57], and those that can be recognised by an \u03c9-semigroup [66, Chapter 2].\nCycles. Let TS be a transition system with V and E as set of vertices and edges, respectively. A cycle of TS is a subset ` \u2286 E such that there is a finite path v0 e0\u2212\u2192 v1 e1\u2212\u2192 v2 \u2212\u2192 . . . vr\ner\u2212\u2192 v0 with ` = {e0, e1, . . . , er}. We remark that we do not require this path to be simple, that is, edges and vertices may appear multiple times. The set of states of the cycle ` is States(`) = {v0, v1, . . . vr}. The set of cycles of a transition system TS is written Cycles(TS). We will consider the set of cycles ordered by inclusion. For a state v \u2208 V , we note Cycles\nv (TS)\nthe subset of cycles of TS containing v. We remark that a vertex v is recurrent if and only if Cycles\nv (TS) 6= \u2205. We note that Cycles v (TS) is closed under union; moreover, the union of two\ncycles `1, `2 \u2208 Cycles(TS) is again a cycle if and only if there is some state v such that both `1 and `2 contain v.\nLet TS be a Muller transition system with acceptance condition (\u03b3,\u0393,Muller\u0393(F)). Given a cycle ` \u2208 Cycles(TS), we say that ` is accepting (resp. rejecting) if \u03b3(`) \u2208 F (resp. \u03b3(`) /\u2208 F). We remark that the maximal cycles of a transition system are exactly the sets of edges of its strongly connected components. In particular, we can apply the adjectives accepting and rejecting similarly to the SCCs of a Muller transition system.\nWe note that, by definition, the acceptance of a run in a Muller transition system only depends on the set of transitions taken infinitely often. For any infinite run \u03c1 \u2208 Run(TS), the set of transitions taken infinitely often forms a cycle, Inf(\u03c1) = `\u03c1 \u2208 Cycles(TS), and \u03c1 is an accepting run if and only if `\u03c1 is an accepting cycle.\nThe deterministic and history-deterministic parity hierarchy. As we have mentioned, every \u03c9-regular language can be recognised by a deterministic parity automaton, but the number of colours required to do so might be arbitrarily large. We can assign to each \u03c9-regular language the optimal number of colours needed to recognise it using a deterministic automaton. We obtain in this way the deterministic parity hierarchy, having its origins in the works of"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 17",
            "text": "Wagner [80], Kaminski [43], and Mostowski [62]. We represented this hierarchy in Figure 4. This hierarchy is strict, that is, for each level of the hierarchy there are languages that do not appear in lower levels [80]. It is known that we can decide in polynomial time the parity index of an \u03c9-regular language represented by a deterministic parity automaton [15], but this problem is NP-complete if the language is given by a deterministic Rabin or Streett automaton [48].\n[0, 0] [1, 1]\nWeak1\n[0, 1] [1, 2]\nWeak2\n[0, 2] [1, 3]\nWeak3\n... ...\n...\nFigure 4 The (history-)deterministic parity hierarchy.\nI Definition 2.14 (Parity index of a language). Let L \u2286 \u03a3\u03c9 be an \u03c9-regular language. We say that L has parity index at least [0, d\u2212 1] (resp. [1, d]) if any DPA recognising L with a parity acceptance condition over the set of colours [dmin, dmax] satisfies that dmax \u2212 dmin \u2265 d\u2212 1, and in case of equality dmin is even (resp. odd). We say that the parity index of L is [0, d\u2212 1] (resp. [1, d]) if, moreover, there is a DPA recognising L with a parity acceptance condition over the set of colours [0, d\u2212 1] (resp. [1, d]).\nWe say that L has parity index at least Weakd if any DPA recognising L with a parity acceptance condition over the set of colours [dmin, dmax] satisfies that dmax \u2212 dmin \u2265 d. We say that the parity index of L is Weakd if, moreover, there are DPAs A1 and A2 recognising L with parity acceptance conditions over the sets of colours [0, d] and [1, d+ 1], respectively. y\nIf follows from the definition that for each \u03c9-regular language L, there is a unique d such that either L has parity index [0, d \u2212 1], [1, d] or Weakd, and these options are mutually exclusive. See also Appendix A for more details about languages of parity index Weakd.\nOne of our contributions is to show that the parity index also applies to Muller automata: any deterministic or HD Muller automaton recognising an \u03c9-regular language of parity index [0, d\u2212 1] uses at least d different colours (Proposition 6.14).\nThe following proposition states that the notion of parity index of a language does not change by using HD automata instead of deterministic ones in the definition. However, for non-deterministic automata, the hierarchy collapses at level [0, 1] (B\u00fcchi automata) [57].\nI Proposition 2.15 ([10, Theorem 19]). Let A be an HD parity automaton recognising a language L, and suppose that the parity index of L is [0, d \u2212 1] (resp. [1, d]). Then, the acceptance condition of A uses at least d output colours, and if it uses exactly d colours, the least of them is even (resp. odd). If the parity index of L is Weakd, then A uses at least d+ 1 output colours.\nWe show next that the parity index of an \u03c9-regular language can be read directly from a deterministic Muller automaton.\n18\nLet TS be a transition system using the Muller acceptance condition (\u03b3,\u0393,Muller\u0393(F)). A d-flower over a state v of TS is a set of d cycles `1, `2, . . . , `d \u2208 Cyclesv(TS) such that `i ) `i+1 and \u03b3(`i) \u2208 F \u21d0\u21d2 \u03b3(`i+1) /\u2208 F . We say that it is a positive flower if \u03b3(`1) \u2208 F and that it is negative otherwise.\nI Lemma 2.16 (Flower Lemma, [65, 80]). Let A be a DMA. If A admits an accessible positive (resp. negative) d-flower, then L(A) has parity index at least [0, d\u2212 1] (resp. [1, d]). If A admits both accessible positive and negative d-flowers, then L(A) has parity index at least Weakd.\nConversely, if an \u03c9-regular language L has parity index at least [0, d\u2212 1] (resp. [1, d]), then any DMA recognising L admits a positive (resp. negative) d-flower."
        },
        {
            "heading": "2.3 Trees",
            "text": "We introduce some technical notations that will be used to define automata based on the Zielonka tree (Sections 4.2 and 4.3) and the transformations based on the ACD (Sections 5.2 and 5.3).\nA tree T = (N, ) is a non-empty finite set of nodes N equipped with an order relation called the ancestor relation (we say that x is an ancestor of y, or that y is below x if x y), such that (1) there is a minimal node for , called the root, and (2) the ancestors of an element are totally ordered by . The converse relation is the descendant relation. Maximal nodes are called leaves, and the set of leaves of T is denoted by Leaves(T ). The minimal strict descendants of a node are called its children. The set of children of n in T is written ChildrenT (n). The depth of a node n is the number of strict ancestors of it. We note it Depth(n). The height of a tree T is the maximal length of a chain for the ancestor relation. A subtree of T = (N, ) is a tree T \u2032 = (N \u2032, \u2032) such that N \u2032 \u2286 N , \u2032 is the restriction of to N \u2032 and ChildrenT \u2032(n\u2032) \u2286 ChildrenT (n\u2032) for all n\u2032 \u2208 N \u2032. Given a node n of a tree T , the subtree of T rooted at n is the subtree of T whose nodes are the nodes of T that have n as ancestor. A branch is a maximal chain of the order .\nAn ordered tree is a tree T = (N, ) together with a total order \u2264n over ChildrenT (n), for each node n \u2208 N that is not a leaf. We remark that a subtree of an ordered tree can be seen as an ordered tree with the restrictions of these total orders to the existing children. These orders induce a total order \u2264T on T (the depth-first order): let n, n\u2032 \u2208 N . If n n\u2032, we let n \u2264T n\u2032. If n and n\u2032 are incomparable for the ancestor relation, let nm be the deepest common ancestor, and let n1, n2 \u2208 ChildrenT (nm) such that n1 n and n2 n\u2032. We let n \u2264T n\u2032 if and only if n1 \u2264nm n2. In the latter case, we say that n is on the left of n\u2032.\nWe will make use of these orders through some auxiliary functions. Let T \u2032 be a subtree of T and n a node of T \u2032 that is not a leaf in T \u2032. For n\u2032 \u2208 ChildrenT (n), we let\nNextT \u2032(n\u2032) = min\u2264n{n \u2032\u2032 \u2208 ChildrenT \u2032(n) | n\u2032 <n n\u2032\u2032} if this set is not empty,\nmin\u2264n{n\u2032\u2032 \u2208 ChildrenT \u2032(n)} otherwise.\nThat is, the function NextT \u2032 maps each child of n to a sibling that is its successor in T \u2032 for the \u2264n-order, in a cyclic way.\nLet T \u2032 = (N \u2032, \u2032) be a subtree of T = (N, ). Let nm \u2208 N \u2032 and no \u2208 N such that nm is a strict ancestor of no (nm \u227a no). If nm is a leaf of T \u2032, we define JumpT \u2032(no, nm) = nm. If not, we define JumpT \u2032(no, nm) = ldest \u2208 Leaves(T \u2032) to be the only node satisfying that there are two children of nm in T , n1, n2 \u2208 ChildrenT (nm) such that:\nn1 no,"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 19",
            "text": "n2 = NextT \u2032(n1) (in particular, n2 \u2208 N \u2032), ldest n2 is the leftmost4 leaf in T \u2032 (minimal for \u2264T \u2032) below n2.\n(We remark that n1 = n2 if n1 is the only child of nm in T \u2032). For nm = no, we define JumpT \u2032(no, nm) to be the leftmost leaf of T \u2032 below no. Intuitively, l = JumpT \u2032(no, nm) if we can reach l by the following procedure: we start at no, we go up the tree T until finding the node nm, we change to the next child of nm in T \u2032 (in a cyclic way) and we re-descend to l in T \u2032 taking the leftmost branch. We drop the subscript T \u2032 if T \u2032 = T .\nAn A-labelled (ordered) tree is an (ordered) tree T together with a labelling function \u03bd : N \u2192 A. A set of trees is called a forest.\nWe refer the reader to Examples 4.5 and 5.5 for illustrations of the notations introduced here.\n3 Morphisms as witnesses of transformations\nAs mentioned in the introduction, all existing transformations of automata follow a common approach: they turn each state q into multiple states of the form (q, x), where x stores some information about the acceptance condition. It is reasonable to put forward this characteristic as the defining trait establishing that an automaton has been obtained as a transformation of another. In this section, we introduce morphisms of transition systems, which formalise this idea: a morphism \u03d5 : B \u2192 A witnesses that each state q \u2208 A has been augmented to \u03d5\u22121(q). To ensure that B is semantically equivalent to A, the morphism has to grant a further guarantee, namely, we need to be able to simulate runs of A in B. We will examine two properties of morphisms that allow to do this: local bijectivity and history-determinism for mappings.\nIn all this section, TS = (G,Acc) and TS \u2032 = (G\u2032,Acc\u2032) will stand for transition systems with underlying graphs G = (V,E,Source,Target, I) and G\u2032 = (V \u2032, E\u2032,Source\u2032,Target\u2032, I \u2032), and acceptance conditions Acc = (\u03b3,\u0393,W) and Acc\u2032 = (\u03b3\u2032,\u0393\u2032,W\u2032)."
        },
        {
            "heading": "3.1 Morphisms of transition systems",
            "text": "I Definition 3.1. A morphism of graphs from G to G\u2032 is a pair of mappings \u03d5 = (\u03d5V : V \u2192 V \u2032, \u03d5E : E \u2192 E\u2032) preserving edges, that is:\nSource\u2032(\u03d5E(e)) = \u03d5V (Source(e)) for every e \u2208 E, Target\u2032(\u03d5E(e)) = \u03d5V (Target(e)) for every e \u2208 E.\nWe say that \u03d5 is a morphism of pointed graphs if, moreover, it preserves initial vertices:\n\u03d5V (v0) \u2208 I \u2032 for every v0 \u2208 I.\nIf (G, (lV , LV ), (lE , LE)) and (G, (l\u2032V , L\u2032V ), (l\u2032E , L\u2032E)) are labelled graphs, we say that \u03d5 is a morphism of labelled graphs if, in addition, LV \u2286 L\u2032V , LE \u2286 L\u2032E and \u03d5 preserves labels:\nl\u2032V (\u03d5V (v)) = lV (v) for every v \u2208 V , l\u2032E(\u03d5E(e)) = lE(e) for every e \u2208 V . y\n4 The choice of the leftmost leaf is arbitrary. In all our uses of the function Jump, it could be replaced by any leaf below n2.\n20\nWe will write \u03d5 : G\u2192 G\u2032 to denote a morphism \u03d5. We will drop the subscript in \u03d5V and \u03d5E whenever it can be deduced from its use. We say that \u03d5 is surjective (resp. injective) if \u03d5V is.\nNote that the mapping \u03d5V does not completely determine a morphism \u03d5, as multiple edges might exist between two given vertices. However, if G has no isolated vertices, the mapping \u03d5E does determine it. It will be convenient nonetheless to also keep the notation for \u03d5V .\nWe remark that the image of a run in G by a morphism of pointed graphs is a run in G\u2032. Therefore, a morphism of pointed graphs \u03d5 : G\u2192 G\u2032 induces a mapping\n\u03d5Runs : Run\u221e(G)\u2192 Run\u221e(G\u2032).\nI Definition 3.2. Let TS and TS \u2032 be two (labelled) transition systems. A weak morphism of (labelled) transition systems \u03d5 : TS \u2192 TS \u2032 is a morphism of (labelled) pointed graphs between their underlying graphs, \u03d5 : G\u2192 G\u2032. We say that it is a morphism of (labelled) transition systems if it preserves the acceptance of runs, that is:\nfor every infinite run \u03c1 \u2208 Run(TS), \u03b3(\u03c1) \u2208W \u21d0\u21d2 \u03b3\u2032(\u03d5Runs (\u03c1)) \u2208W\u2032. y\nA morphism of labelled TS between automata (resp. between games) will be called a morphism of automata (resp. morphism of games).\nWe say that a morphism of TS \u03d5 : TS \u2192 TS \u2032 is an isomorphism if \u03d5V and \u03d5E are bijective and \u03d5\u22121 = (\u03d5\u22121V , \u03d5 \u22121 E ) is a morphism from TS \u2032 to TS. In that case, we say that TS and TS \u2032 are isomorphic."
        },
        {
            "heading": "3.2 Local properties of morphisms",
            "text": "I Definition 3.3. A morphism of pointed graphs \u03d5 : G\u2192 G\u2032 is called:\nLocally surjective if it verifies:\n1. For every v\u20320 \u2208 I \u2032 there exists v0 \u2208 I such that \u03d5(v0) = v\u20320. 2. For every v \u2208 V and every e\u2032 \u2208 Out(\u03d5(v)) there exists e \u2208 Out(v) such that \u03d5(e) = e\u2032.\nLocally injective if it verifies:\n1. For every v\u20320 \u2208 I \u2032, there is at most one v0 \u2208 I such that \u03d5(v0) = v\u20320. 2. For every v \u2208 V and every couple e1, e2 \u2208 Out(v), \u03d5(e1) = \u03d5(e2) implies e1 = e2.\nLocally bijective if it is both locally surjective and locally injective. y\nEquivalently, a morphism of pointed graphs \u03d5 is locally surjective (resp. locally injective) if for every v \u2208 V the restriction of \u03d5E to Out(v) is a surjection onto Out(\u03d5(v)) (resp. an injection into Out(\u03d5(v))), and the restriction of \u03d5V to I is a surjection onto I \u2032 (resp. an injection into I \u2032).\nLet \u03d5 : TS \u2192 TS \u2032 be a (weak) morphism, and let \u03c1\u2032 = v\u20320 e\u20320\u2212\u2192 v\u20321 e\u20321\u2212\u2192 . . . be a run in TS \u2032. If \u03d5 is locally surjective, we can pick an initial vertex v0 in \u03d5\u22121(v\u20320) and build step-by-step a run \u03c1 in TS from v0 that is sent to \u03c1\u2032 under \u03d5. If \u03d5 is moreover locally bijective, the choices of the initial vertex and the edges at each step are unique, so runs in TS \u2032 can be simulated in TS via \u03d5 in a unique way. Said differently, if \u03d5 : TS \u2192 TS \u2032 is a locally bijective morphism, we can see TS as an automaton that processes runs of TS \u2032 in a deterministic fashion (this idea is formalised in Section 5.4.3). This property will allow us to show that a locally bijective morphism witnesses the semantic equivalence of TS and TS \u2032 (see Section 3.4)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 21",
            "text": "We note that the notion of locally bijective morphisms of transition systems almost coincide with the usual concept of bisimulation. The main difference is that locally bijective morphisms treat the acceptance of a run as a whole; we do not impose the output colour of an edge \u03b3(e) to coincide with the colour \u03b3\u2032(\u03d5(e)). This allows us to compare transition systems using different types of acceptance conditions.\nI Remark 3.4. Let \u03d5 be a morphism of pointed graphs.\n1. If \u03d5 is locally surjective, then \u03d5Runs is surjective. 2. If \u03d5 is locally injective, then \u03d5Runs is injective. 3. If \u03d5 is locally bijective, then \u03d5Runs is bijective.\nIn the following, the weak morphisms under consideration will be locally surjective. Next lemma ensures that we can suppose that they are surjective without loss of generality.\nI Lemma 3.5. If \u03d5 : TS \u2192 TS \u2032 is a locally surjective weak morphism, it is onto the accessible part of TS \u2032. That is, for every accessible state v\u2032 \u2208 TS \u2032, there exists some state v \u2208 TS such that \u03d5V (v) = v\u2032. In particular, if every state of TS \u2032 is accessible, \u03d5 is surjective.\nProof. Let v\u2032 be an accessible state of TS \u2032. By definition, there exists a finite run \u03c1\u2032 from an initial vertex of TS \u2032 to v\u2032. By surjectivity of \u03d5Runs , there is a finite run \u03c1 \u2208 Runfin(TS) such that \u03d5Runs (\u03c1) = \u03c1\u2032. As \u03d5 is a morphism of graphs, we have that \u03d5(Target(\u03c1)) = v\u2032. J\nI Example 3.6. In Figure 5 we provide an example of a locally bijective morphism between the two rightmost transition systems from Figure 3 (we have removed input letters for simplicity). We recall that the acceptance set of the rightmost transition system is the Muller language associated to F = {{\u03b1}, {\u03b2}}. The morphism is given by \u03d5V (v1) = \u03d5V (v2) = v\u2032 and \u03d5V (v2) = v\u20322. In this case, the mapping \u03d5V determines a unique morphism; the (uniquely determined) mapping \u03d5E is represented by the colours of the edges in the figure. It is easy to check that this mapping preserves the acceptance of runs and that it is locally bijective."
        },
        {
            "heading": "3.3 History-deterministic mappings",
            "text": "Locally bijective morphisms are a natural generalisation of the composition of a transition system with a deterministic automaton. They guarantee the semantic equivalence of the\n22\ntwo involved transition systems, but at the cost of the use of some strong hypothesis, as the outgoing edges of a vertex v must exactly correspond to the outgoing edges of its image \u03d5(v). We can imagine correct transformations that do not satisfy this requirement. Notably, history-deterministic automata have been introduced as a method to bypass this restriction, with the hope of outperforming transformations that are witnessed by locally bijective morphisms. In general, if A is an HD automaton recognising the acceptance set ot TS, the composition TS nA does not admit a locally bijective morphism to TS, although it shares most semantic properties with it (Proposition 2.7).\nWe introduce next HD mappings, which are weak morphisms with the minimal set of hypothesis ensuring that, if \u03d5 : TS \u2192 TS \u2032 is an HD mapping, we can simulate runs of TS \u2032 in TS via \u03d5 while preserving their acceptance. This will allow us to show that \u03d5 witnesses the semantic equivalence of TS and TS \u2032 (Section 3.4).\nHistory-deterministic mappings\nLet TS and TS \u2032 be transition systems and \u03d5 : TS \u2192 TS \u2032 a weak morphism between them. A resolver simulating \u03d5 consists in a pair of functions rInit : I \u2032 \u2192 I and r : E\u2217 \u00d7 E\u2032 \u2192 E such that:\n1. \u03d5(rInit(v\u20320)) = v\u20320 for all v\u20320 \u2208 I \u2032, 2. \u03d5(r(\u03c1, e\u2032)) = e\u2032, for all \u03c1 \u2208 E\u2217 and e\u2032 \u2208 E\u2032, 3. if e\u20320 \u2208 Out(I \u2032), Source(r(\u03b5, e\u20320)) = rInit(Source(e\u20320)), and 4. if \u03c1 is a finite run in TS ending in v and e\u2032 \u2208 Out(\u03d5(v)), then r(\u03c1, e\u2032) \u2208 Out(v).\nGiven a run \u03c1\u2032 = e\u20320e\u20321 \u00b7 \u00b7 \u00b7 \u2208 Run\u221e(TS \u2032) starting in some v\u20320 \u2208 I \u2032, the run induced by r is the sequence rRuns (\u03c1\u2032) = e0e1e2 \u00b7 \u00b7 \u00b7 \u2208 Run\u221e(TS) defined by ei = r(e0 . . . ei\u22121, e\u2032i), which is indeed a run in TS. We say that the resolver is sound if for every accepting run \u03c1\u2032 \u2208 Run(TS \u2032), the run rRuns (\u03c1\u2032) is accepting in TS. Note that we do not impose rRuns (\u03c1\u2032) to be rejecting if \u03c1\u2032 is.\nI Remark 3.7. Provided that all states of TS \u2032 are accessible, a resolver simulating \u03d5 can only exist if \u03d5 is a locally surjective weak morphism.\nSaid differently, a sound resolver simulating \u03d5 is a winning strategy for the player Duplicator in the following game:"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 23",
            "text": "In round 0, Spoiler picks an initial vertex v\u20320 in TS \u2032. Duplicator responds by picking an initial vertex v0 in TS such that \u03d5(v0) = v\u20320. In round n > 0, Spoiler picks an edge e\u2032n in TS \u2032, and Duplicator responds by picking an edge en in TS such that \u03d5(en) = e\u2032n. Duplicator wins if either e1e2 . . . is an accepting run in TS from v0 or e\u20321e\u20322 . . . is not an accepting run in TS \u2032 from v\u20320 (it is either not a run from v0 or not accepting). Spoiler wins otherwise.\nI Definition 3.8. Let TS and TS \u2032 be (labelled) transition systems. A history-deterministic mapping (HD mapping) of transition systems from TS to TS \u2032 is a pair of mappings \u03d5 = (\u03d5V : V \u2192 V \u2032, \u03d5E : E \u2192 E\u2032) such that:\n\u03d5 is a weak morphism, \u03d5 preserves accepting runs: \u03c1 \u2208 Run(TS) and \u03b3(\u03c1) \u2208W =\u21d2 \u03b3\u2032(\u03d5Runs (\u03c1)) \u2208W\u2032, and there exists a sound resolver simulating \u03d5. y\nEven if a history-deterministic mapping is not necessarily locally bijective (and not even a morphism of transition systems), the existence of a sound resolver allows to define a right inverse to \u03d5Runs preserving the acceptance of runs.\nI Lemma 3.9. Let \u03d5 : TS \u2192 TS \u2032 be an HD mapping and let (rInit, r) be a sound resolver simulating it. The following holds:\n\u03d5Runs \u25e6 rRuns = IdRun\u221e(TS\u2032). rRuns preserves the acceptance of runs in TS \u2032, that is, for every run \u03c1\u2032 \u2208 Run(TS \u2032), \u03c1\u2032 is accepting if and only if rRuns (\u03c1\u2032) is accepting in TS.\nProof. The first item follows from the fact that \u03d5(r(\u03c1, e\u2032)) = e\u2032 for every \u03c1 \u2208 E\u2217 and e\u2032 \u2208 E\u2032. For the second item, the definition of a sound resolver imposes that if \u03c1\u2032 is accepting, so is rRuns (\u03c1\u2032). For the other direction, if rRuns (\u03c1\u2032) is accepting, then \u03d5Runs (rRuns (\u03c1\u2032)) = \u03c1\u2032 has to be accepting, as an HD mapping preserves accepting runs. J\nI Example 3.10. In Figure 7 we give an example of a weak morphism \u03d5 : TS \u2192 TS \u2032 that is a history-deterministic mapping, but which is neither a morphism, nor locally bijective. Transition system TS, on the left of the figure, is a parity TS (more precisely, a coB\u00fcchi TS). Transition system TS \u2032, depicted on the right of the figure, is a Muller TS using as acceptance set the Muller language associated to F = {{\u03b1}, {\u03b1, \u03b2}, {\u03b1, \u03bb}}; that is, a run in TS \u2032 is accepting if and only if it eventually avoids either transition e\u2032 or transition f \u2032. The weak morphism we propose is given by: \u03d5(v0) = \u03d5(v1) = \u03d5(v2) = v\u2032, and \u03d5(u1) = \u03d5(u2) = u\u2032. The image of most edges is uniquely determined, and we use colours to represent them. We have named the only edges whose image is not uniquely determined, and we define \u03d5(e1) = \u03d5(e2) = e\u2032 and \u03d5(f1) = \u03d5(f2) = f \u2032.\nWe remark that \u03d5 does not preserve rejecting runs. Indeed, a run in TS alternating between v0 and u1, taking transition f1 infinitely often, is rejecting, but its image is accepting in TS \u2032. However, \u03d5 preserves accepting runs: a run is accepting in TS if and only if it eventually stays in {v1, u1} or in {v2, u2}. In the first case, the image under \u03d5 avoids transition f \u2032 in TS \u2032, and in the second case, its image avoids transition e\u2032.\nFinally, we describe a sound resolver simulating \u03d5. When simulating a run from TS \u2032 in TS, we have a choice to make only when we are in state v0. If the previous transition in TS \u2032 was e\u2032, we will go up, that is, v\u2032 \u03b1\u2212\u2192 u\u2032 is simulated by v0 1\u2212\u2192 u1 and v\u2032\n\u03b1\u2212\u2192 v\u2032 is simulated by v0\n1\u2212\u2192 v1. If the previous transition in TS \u2032 was f \u2032, we will go down in a symmetric manner. In this way, if transition f \u2032 is eventually not visited by the run in TS \u2032, we ensure to stay in {v1, u1} in TS (and symmetrically, we ensure to stay in {v2, u2} if e\u2032 is avoided in TS \u2032). y\n24\nHistory-deterministic-for-games mappings\nIn the case of games, we need to slightly strengthen the definition of HD mappings to guarantee that, if there is a suitable mapping \u03d5 : G \u2192 G\u2032, then G and G\u2032 have the same winner. In order to show that if Eve wins G\u2032 then she wins G, we need a method to transfer strategies in G\u2032 to G. A regular resolver simulating \u03d5 does not suffice to do this, as it does not take into account the partition into Eve and Adam vertices. We need to be able to simulate a play of G\u2032 in G in a two-players-game fashion, Adam\u2019s moves will be simulated by Adam, and Eve\u2019s moves by Eve. This idea leads to the notion of HD-for-games mapping.\nLet G and G\u2032 be two games, and \u03d5 : G \u2192 G\u2032 be a weak morphism between them admitting a resolver (rInit, r) simulating \u03d5. Given runs \u03c1\u2032 = e\u20320e\u20321 \u00b7 \u00b7 \u00b7 \u2208 Run(G\u2032) and \u03c1 = e0e1 \u00b7 \u00b7 \u00b7 \u2208 Run(G), we say that \u03c1 is consistent with (rInit, r) over \u03c1\u2032 if:\n1. Source(e0) = rInit(Source(e\u20320), 2. \u03d5(ei) = e\u2032i, and 3. for every finite prefix e0e1 . . . en\u22121 v \u03c1 ending in a vertex controlled by Eve, the next\nedge in \u03c1 is en = r(e0 . . . en\u22121, e\u2032n).\nWe remark that there exists at least one run consistent with (rInit, r) over \u03c1\u2032, namely rRuns (\u03c1\u2032). We say that (rInit, r) is sound for G if it verifies that for any accepting run \u03c1\u2032 \u2208 Run(G\u2032), all runs consistent with (rInit, r) over \u03c1\u2032 are accepting in G.\nSaid differently, a resolver sound for G is a winning strategy for Duplicator in the following game:\nIn round 0, Spoiler picks an initial vertex v\u20320 in G\u2032. Duplicator responds by picking an initial vertex v0 in G such that \u03d5(v0) = v\u20320. In round n > 0, Spoiler picks an edge e\u2032n in G\u2032. If vn\u22121 is controlled by Adam, Spoiler chooses an edge en = vn\u22121 \u2212\u2192 vn \u2208 Out(vn\u22121) such that \u03d5(en) = e\u2032n. If vn is controlled by Eve, it is Duplicator who chooses one such en. Duplicator wins if either e1e2 . . . is an accepting run in G from v0 or e\u20321e\u20322 . . . is not an accepting run in G\u2032 from v\u20320. Spoiler wins otherwise."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 25",
            "text": "I Definition 3.11. An HD mapping of games \u03d5 : G \u2192 G\u2032 is called history-deterministic-forgames if it admits a resolver sound for G.\nWhenever we apply the term HD-for-games to a map \u03d5 : TS \u2192 TS \u2032, it will implicitly imply that TS and TS \u2032 are games (that is, they have a fixed vertex-labelling lPlayers : V \u2192 {Eve,Adam}), and that \u03d5 preserves those vertex-labellings).\nIn the next lemma, we prove that HD and HD-for-games mappings are a strict generalisation of locally surjective morphisms (and therefore, also of locally bijective ones). On the other hand, we remark that HD mappings must be locally surjective, but they are not necessarily morphisms (they might not preserve rejecting runs).\nI Lemma 3.12. If \u03d5 : TS \u2192 TS \u2032 is a locally surjective morphism, it is also an HD mapping. If TS and TS \u2032 are games, \u03d5 is moreover HD-for-games.\nProof. We need to define a sound resolver simulating \u03d5. Let rInit : I \u2032 \u2192 I be any function choosing initial vertices satisfying that \u03d5 \u25e6 rInit = IdI\u2032 (which exists by local surjectivity of \u03d5). For each v \u2208 V and edge e\u2032 \u2208 Out(\u03d5(v)) we choose one edge f(v, e\u2032) \u2208 Out(v) such that \u03d5(f(v, e\u2032)) = e\u2032 (which exists by local surjectivity), and we let r be the resolver induced by these choices. Formally, we define r : E\u2217 \u00d7 E\u2032 \u2192 E recursively. For the base case, if e\u20320 \u2208 Out(v\u2032), with v\u2032 \u2208 I \u2032, we define r(\u03b5, e\u20320) = f(rInit(v\u2032), e\u20320). Suppose that r has been defined for runs of length \u2264 n, and let \u03c1 \u2208 E\u2217 be of length n+ 1 and e\u2032 \u2208 E\u2032. If \u03c1 is not a run or e\u2032 /\u2208 Out(Target(\u03d5(\u03c1))), we let r(\u03c1, e\u2032) be any edge in \u03d5\u22121(e\u2032). If not, let v = Target(\u03c1) and we define r(\u03c1, e\u2032) to be the edge f(v, e\u2032).\nIt is straightforward to check that (rInit, r) is indeed a resolver (for every run \u03c1\u2032 \u2208 Run(TS \u2032), the sequence rRuns (\u03c1\u2032) is a run in TS and \u03c1\u2032 is its image under \u03d5). Finally, since \u03d5 is a morphism, for every \u03c1\u2032 \u2208 Run(TS \u2032) and every \u03c1 \u2208 Run(TS) consistent with (rInit, r) over \u03c1\u2032, \u03c1 is accepting in TS if and only if \u03c1\u2032 = \u03d5Runs(\u03c1) is accepting in TS \u2032. We conclude that (rInit, r) is a sound resolver (resp. sound for TS) and therefore \u03d5 is an HD mapping (resp. HD-for-games mapping). J\nRestrictions and extensions of initial sets\nThe following simple lemma states that reducing the number of initial vertices preserves the history-determinism of mappings.\nI Lemma 3.13. Let TS and TS \u2032 be two TS such that there is an HD (resp. HD-for-games) mapping \u03d5 : TS \u2192 TS \u2032. For any non-empty subset I\u0303 \u2286 I \u2032, \u03d5 is also an HD (resp. HD-forgames) mapping between the transition systems TSrInit(I\u0303) and TS \u2032 I\u0303 ; that is, the transitions systems obtained by setting rInit(I\u0303) and I\u0303 as initial vertices, respectively.\nFor arbitrary acceptance conditions, enlarging the set of initial vertices does not preserve history-determinism. However, for transition systems using the acceptance conditions considered in this work, we can enlarge the set of initial vertices without loss of generality. The proof can be found in Appendix C.\nI Lemma 3.14. Let TS and TS \u2032 be two TS such that all their states are accessible, and let \u03d5 : TS \u2192 TS \u2032 be an HD (resp. HD-for-games) mapping between them. If W and W\u2032 are prefix-independent, the mapping \u03d5 is also HD (resp. HD-for-games) when considered between the transition systems TSV and TS \u2032V \u2032 , consisting of the transition systems TS and TS \u2032 where all the states are set to be initial.\n26"
        },
        {
            "heading": "3.4 Preservation of semantic properties of automata and games",
            "text": "We start this section by showing that locally bijective morphisms and HD mappings are a strict generalisation of compositions by deterministic and history-deterministic automata, respectively (Proposition 3.15). Then, we prove that these mappings witness the semantic equivalence of the transition systems under consideration. That is, (1) if \u03d5 : A \u2192 A\u2032 is an HD mapping of automata, then L(A) = L(A\u2032), and if \u03d5 is locally bijective, A is deterministic (or unambiguous) if and only if A\u2032 is (Proposition 3.16)5; and (2) if \u03d5 : G \u2192 G\u2032 is an HD-for-games mapping, G and G\u2032 have the same winner (Proposition 3.18 and Corollary 3.19).\nMorphisms generalise composition by an automaton\nI Proposition 3.15. Let A be a complete automaton accepting the language L(A) = W \u2286 \u03a3\u03c9, and let TS be a (labelled) TS with acceptance set W. Then, there exists a locally surjective weak morphism of (labelled) TS \u03d5 : TS nA \u2192 TS that preserves accepting runs. Moreover:\n1. If A is deterministic, \u03d5 can be chosen to be a locally bijective morphism. 2. If A is HD, then \u03d5 can be chosen to be an HD mapping. 3. If A is HD and TS is a game suitable for transformations, then \u03d5 can be chosen to be an\nHD-for-games mapping.\nProof. We recall that the set of states of TS nA is V \u00d7Q and its set of transitions En is a subset of (E \u00d7\u2206) t E, where V and Q (resp. E and \u2206) are the states (resp. transitions) of TS and A, respectively. We let WA \u2286 \u0393\u03c9 be the acceptance set of A. We define \u03d5V (v, q) = v and \u03d5E(e1, e2) = e1 for (e1, e2) \u2208 E \u00d7\u2206 and \u03d5E(e1) = e1 for e1 \u2208 E. It is immediate to check that \u03d5 is a weak morphism.\nGiven a run \u03c1 = (v0, q0) c0\u2212\u2192 (v1, q1) c1\u2212\u2192 . . . in TS nA, we can consider its projection over TS, \u03d5Runs(\u03c1) = v0 a0\u2212\u2192 v1 a1\u2212\u2192 . . . . We note that there must exist a unique run in A of the form\n\u03d5A(\u03c1) = q0 a0:c0\u2212\u2212\u2212\u2192 q1 a1:c1\u2212\u2212\u2212\u2192 . . . .\n(Formally, some of the letters ai might equal \u03b5, and in this case qi ai:ci\u2212\u2212\u2212\u2192 qi+1 does not appear in the run \u03d5A(\u03c1)). We show that \u03d5 preserves accepting runs. Let \u03c1 be an accepting run in TS nA. In that case, c0c1c2 \u00b7 \u00b7 \u00b7 \u2208WA, and therefore \u03d5A(\u03c1) is an accepting run in A over a0a1a2 . . . , so we conclude that a0a1a2 \u00b7 \u00b7 \u00b7 \u2208W and \u03d5Runs (\u03c1) is an accepting run in TS.\nWe prove next the local surjectivity of \u03d5. Clearly, \u03d5 induces a surjection between the initial vertices of TS n A (which are ITS \u00d7 IA) and those of TS. Let (v, q) \u2208 V \u00d7 Q and e1 = v\na\u2212\u2192 v\u2032 \u2208 E. If a = \u03b5, the edge e1 belongs to En and \u03d5(e1) = e1. If a 6= \u03b5, since A is complete there is a transition e2 = q a\u2212\u2192 q\u2032 \u2208 \u2206 and \u03d5(e1, e2) = e1, so \u03d5 is locally surjective.\n1. Since A has a single initial state q0, \u03d5 induces a bijection between the initial vertices of TS nA (which are ITS \u00d7{q0}) and those of TS. Let Encol \u2286 E\u00d7\u2206 and En\u03b5 \u2286 E such that En = Encol \u222a En\u03b5 . We remark that \u03d5|En\u03b5 is the identity function (so injective) and that\n5 The results in this section do not directly imply that if A is an automaton recognising the acceptance set of another automaton B, then B n A recognises the same language than B, if A is not historydeterministic (Proposition 2.6). In that case, the equality L(B nA) = L(B) follows from the idea that runs in B can be simulated in B nA \u201cguided by the non-deterministic choices of A\u201d, which we do not formalise in this work."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 27",
            "text": "\u03d5(Encol) \u2229 \u03d5(En\u03b5 ) = \u2205 because \u03d5(E n col) are exactly coloured transitions of TS. Finally, let (e1, e2) and (e\u20321, e\u20322) in Out(v, q) \u2229 Encol. Their \u03d5(e1, e2) = \u03d5(e\u20321, e\u20322) if and only if e1 = e\u20321. Let a \u2208 \u03a3 be the colour of e1. Since A is deterministic, there is at most one transition from q labelled by a, that must be e2 = e\u20322. We conclude that (e1, e2) = (e\u20321, e\u20322) and that \u03d5 is locally injective. Let \u03c1 be a rejecting run in TS n A (we use the notations introduced above). In that case, c0c1c2 . . . /\u2208WA, and therefore \u03d5A(\u03c1) is a rejecting run over a0a1a2 . . . . Since A is deterministic, this is the only run over a0a1a2 . . . so we conclude that it does not belong to W. We conclude that \u03d5Runs (\u03c1) is a rejecting run in TS. 2. Let (r0, rA) be a resolver for A. We define a resolver (rInit, r\u03d5) simulating \u03d5. First, we let rInit(v0) = (v0, r0) for all v0 \u2208 ITS . We define r\u03d5 : En\n\u2217 \u00d7 E \u2192 En by induction on the length of the runs. Let e0 = v0\na\u2212\u2192 v1 \u2208 Out(v0) be an edge in TS. If e0 is uncoloured (a = \u03b5), we let r\u03d5(\u03b5, e0) = e0 = (v0, r0)\n\u03b5\u2212\u2192 (v1, r0). If not, we let r\u03d5(\u03b5, e0) = (e0, ea), where ea = r(\u03b5, a). Suppose that r\u03d5 has been defined for sequences of edges of TS nA of length < n and let \u03c1 = e0e1 . . . en\u22121 \u2208 En \u2217 be a sequence length n+ 1 and eTS = vn an\u2212\u2212\u2192 vn+1 be an edge in TS. If \u03c1 is not a run or if it does not end in \u03d5\u22121(vn), we let r\u03d5(\u03c1, eTS) be any edge in \u03d5\u22121(eTS). Suppose that \u03c1 is a run ending in \u03d5\u22121(vn). If an = \u03b5, we define r\u03d5(\u03c1, eTS) = eTS . As noted before, \u03c1 induces a run \u03d5A(\u03c1) = q0 a0:c0\u2212\u2212\u2212\u2192 q1 a1:c1\u2212\u2212\u2212\u2192 . . . \u2212\u2192 qn in A. We let eA = rA(\u03d5A(\u03c1), an) be the transition chosen by the resolver of A after this run, and we define r\u03d5(\u03c1, eTS) = (eTS , eA). It directly follows from this definition that (rInit, r\u03d5) is indeed a resolver. The proof that if \u03c1 \u2208 Run(TS) is an accepting run then r\u03d5,Runs (\u03c1) is accepting follows the same lines than the previous item.\n3. We prove that, if TS is a game suitable for transformations, the resolver (rInit, r\u03d5) defined in the previous item is sound for TS. We claim that if \u03c1 is a run in TS, the only run consistent with (rInit, r\u03d5) over \u03c1 is r\u03d5,Runs (\u03c1). This follows from the fact that if (v, q) is a vertex in TSnA controlled by Adam and e \u2208 Out(v), then there is a unique e\u2032 \u2208 Out(v, q) such that \u03d5(e\u2032) = e. This is indeed the case: as TS is suitable for transformations, if v is an Adam\u2019s vertex, every e \u2208 Out(v) is uncoloured, so by definition of \u03d5 we have that \u03d5(e\u2032) = e =\u21d2 e\u2032 = e. (This can be seen as that \u03d5 is locally bijective in Adam\u2019s vertices). We conclude that if \u03c1 is an accepting run in TS and \u03c1n is a run consistent with (rInit, r\u03d5) over \u03c1, then \u03c1n = r\u03d5,Runs (\u03c1), which is accepting by soundness of the resolver (rInit, r\u03d5). J\nMorphisms witness equivalence of automata\nI Proposition 3.16. Let A, A\u2032 be two automata over the same input alphabet such that there is an HD mapping of automata \u03d5 : A \u2192 A\u2032. Then, L(A) = L(A\u2032), and A is HD if and only if A\u2032 is HD. If \u03d5 is moreover locally bijective and surjective, A is deterministic (resp. complete) if and only if A\u2032 is.\nProof. Since \u03d5 preserves accepting runs, it is clear that L(A) \u2286 L(A\u2032). Since \u03d5 admits a sound resolver (rInit, r), if \u03c1 is an accepting run over w \u2208 \u03a3\u03c9 in A\u2032, then rRuns(\u03c1) is an accepting run over w in A, so L(A\u2032) \u2286 L(A).\nLet (rInit, r\u03d5) be a sound resolver simulating \u03d5. Suppose that A is HD, admitting a resolver (r0, r). A resolver (r\u20320, r\u2032) for A\u2032 can be obtained just by composing r\u03d5 and \u03d5, that is: r\u20320 = \u03d5(r0) and for \u03c1\u2032 \u2208 Runfin(A\u2032) and a \u2208 \u03a3, r\u2032(\u03c1\u2032, a) = \u03d5(r(r\u03d5,Runs(\u03c1\u2032), a))). That is, given a run \u03c1\u2032 in A\u2032, we simulate it in A using r\u03d5, then, we look at what is the continuation proposed by the resolver r when we give the letter a, and we transfer back this choice to A\u2032 using \u03d5. Suppose now that A\u2032 is HD and that (r\u20320, r\u2032) is a resolver for it.\n28\nWe define a resolver (r0, r) for A. We let r0 = rInit(r\u20320), and for \u03c1 \u2208 Runfin(A) and a \u2208 \u03a3, r(\u03c1, a) = r\u03d5((\u03d5Runs (\u03c1), r(\u03d5Runs (\u03c1), a)). That is, given a run \u03c1 in A, we simulate it in A\u2032 using \u03d5, then, we look at what is the continuation proposed by the resolver r\u2032 when we give the letter a, and we transfer back this choice to A using r\u03d5. It is a direct check that the resolvers defined this way witness that A\u2032 and A, respectively, are HD.\nThe proof that A is deterministic (resp. complete) if and only if A\u2032 is deterministic (resp. complete), assuming surjectivity and local bijectivity of \u03d5, follows the same lines. J\nA subclass of automata with a restrictive amount of non-determinism that is widely study is that of unambiguous automata (we refer to [23, 16] for a detailed exposition). An automaton is unambiguous if for every input word w \u2208 \u03a3\u03c9 there is at most one accepting run over w, and it is strongly unambiguous if there is at most one run over w. By Remark 3.4, locally bijective morphisms also preserve (strongly) unambiguity: if \u03d5 : A \u2192 A\u2032 is a locally bijective morphism then A is (strongly) unambiguous if and only if A\u2032 is.\nMorphisms preserve winning regions of games\nI Lemma 3.17. Let G,G\u2032 be two games, such that there is a weak morphism of games \u03d5 : G \u2192 G\u2032 that is locally surjective and preserves accepting runs. If Eve wins the game G from an initial vertex v, then she wins G\u2032 from \u03d5(v).\nProof. Let v\u2032 = \u03d5(v), and let stratv : Pathfinv (G) \u2192 E be a strategy from v for Eve in G. Intuitively, we will define a strategy in G\u2032 as follows: for each finite run \u03c1\u2032 from v\u2032 in G\u2032, we pick a preimage \u03c1 \u2208 \u03d5\u22121(\u03c1\u2032) in G, look at the decision made by stratv at the end of \u03c1 and transfer it back to G\u2032 via \u03d5. In order to define a correct strategy, the choices of the preimages have to be made in a coherent manner. We formalise this idea next.\nWe will make use of a function choicest : Pathfinv\u2032 (G\u2032)\u2192 Path fin v (G) satisfying that for any\n\u03c1\u2032 = e\u20320e\u20321 . . . e\u2032n\u22121e\u2032n \u2208 Path fin v\u2032 (G\u2032):\nThe run choicest(\u03c1\u2032) has length n+ 1. \u03d5Runs (choicest(\u03c1\u2032)) = \u03c1\u2032. Monotonicity: if \u03c1\u0303\u2032 v \u03c1\u2032 then choicest(\u03c1\u0303\u2032) v choicest(\u03c1\u2032). If there exists en \u2208 \u03d5\u22121(e\u2032n) such that choicest(e\u20320e\u20321 . . . e\u2032n\u22121)en is consistent with stratv, then choicest(\u03c1\u2032) is consistent with stratv.\nAssume for now that such a function exists, and define a strategy in G\u2032 as\nstrat\u2032v\u2032(\u03c1\u2032) = \u03d5(stratv(choicest(\u03c1\u2032))), for \u03c1\u2032 \u2208 Path fin v\u2032 (G\u2032).\nWe prove that strat\u2032v\u2032 is winning. Let \u03c1\u2032 = e\u20320e\u20321 \u00b7 \u00b7 \u00b7 \u2208 Run(G\u2032) be an infinite play consistent with strat\u2032v\u2032 . For each finite prefix \u03c1\u0303\u2032 v \u03c1\u2032, choicest(\u03c1\u0303\u2032) is a finite play in G, and by the monotonicity assumption, we can define the limit of these runs as:\n~\u03c1 = e0e1e2 \u00b7 \u00b7 \u00b7 \u2208 Run(G), where e0e1 . . . en = choicest(e\u20320e\u20321 . . . e\u2032n),\nwhich is indeed a run in G. We show that ~\u03c1 is consistent with stratv by induction. Let \u03c1n = e0e1 . . . en\u22121 be the prefix of size n of ~\u03c1, and suppose that it ends in a vertex vn controlled by Eve. We want to show that en = stratv(\u03c1n). By definition of strat\u2032v\u2032 , e\u2032n = \u03d5(stratv(\u03c1n)) = \u03d5(en), and as vn is controlled by Eve, stratv(\u03c1n) is the only continuation of \u03c1n consistent with stratv, so by the last property of choicest, en has to coincide with stratv(\u03c1n), as we wanted. As ~\u03c1 is consistent with the winning strategy stratv, it is an accepting run in G, and since \u03d5 preserves accepting runs, \u03c1\u2032 = \u03d5Runs (~\u03c1) is also an accepting run."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 29",
            "text": "Finally, we show how to build a function choicest : Pathfinv\u2032 (G\u2032)\u2192 Path fin v (G) by induction on the length of the runs. Suppose that choicest has been defined for runs of length \u2264 n, and let e\u20320e\u20321 . . . e\u2032n be a run of length n + 1, with choicest(e\u20320e\u20321 . . . e\u2032n\u22121) = e0e1 . . . en\u22121. If e0e1 . . . en\u22121 is not consistent with stratv, it ends in a vertex vn controlled by Adam, or stratv(e0e1 . . . en\u22121) /\u2208 \u03d5\u22121(en), we let en \u2208 \u03d5\u22121(en) \u2229 Out(vn) be any edge (one such edge exists by local surjectivity). On the contrary, we let en = stratv(e0e1 . . . en\u22121). We define choicest(e\u20320e\u20321 . . . e\u2032n\u22121e\u2032n) = e0e1 . . . en\u22121en. By construction, the obtained function fulfils the 4 requirements. J\nI Proposition 3.18. Let G,G\u2032 be two games such that there is an HD-for-games mapping \u03d5 : G \u2192 G\u2032. Eve\u2019s winning region in G\u2032 is the projection of her winning region in G: WEve(G\u2032) = \u03d5(WEve(G)).\nProof. If Eve wins G from an initial vertex v, Lemma 3.17 guarantees that she wins G\u2032 from \u03d5(v).\nSuppose now that Eve wins G\u2032 from an initial vertex v\u2032 with a strategy strat\u2032v\u2032 : Path fin v\u2032 (G\u2032)\u2192 E\u2032. We need to show that she wins G from some initial vertex in \u03d5\u22121(v\u2032). Let (rInit, r) be a resolver simulating \u03d5 sound for G and let v = rInit(v\u2032). We define\nstratv(\u03c1) = r(\u03c1, strat\u2032v\u2032(\u03d5Runs (\u03c1)), for \u03c1 \u2208 Path fin v (G).\nThat is, stratv is a strategy in G from v that, given a finite run \u03c1, simulates \u03c1 in G\u2032, looks at the move done by the strategy strat\u2032v\u2032 in there, and transfers this choice back to G\u2032 by using the resolver r. We prove that stratv is winning for Eve in G. Let \u03c1 = e0e1 \u00b7 \u00b7 \u00b7 \u2208 Pathv(G) be a play consistent with stratv. We claim that \u03d5(\u03c1) is consistent with strat\u2032v\u2032 and that \u03c1 is consistent with (rInit, r) over \u03d5(\u03c1). This implies the desired result; consistency with strat\u2032v\u2032 implies that \u03d5(\u03c1) is accepting, and since (rInit, r) is sound for G, \u03c1 would be accepting in G.\nWe prove that \u03d5(\u03c1) is consistent with strat\u2032v\u2032 . Let e\u20320e\u20321 . . . e\u2032n\u22121 be a subplay of \u03d5(\u03c1) ending in a vertex vn controlled by Eve. By definition of the strategy stratv, we have that en = r(e0 . . . en\u22121, strat\u2032v\u2032(e\u20320 . . . e\u2032n\u22121)), and by definition of a resolver (item 2), e\u2032n = \u03d5(en) = strat\u2032v\u2032(e\u20320 . . . e\u2032n\u22121)), as we wanted.\nThe fact that \u03c1 is consistent with (rInit, r) over \u03d5(\u03c1) follows directly from the definition of stratv. J\nThe next corollary follows from the previous proposition and Lemma 3.14.\nI Corollary 3.19. Let G,G\u2032 be two games whose states are accessible and such that their acceptance sets WG and WG\u2032 are prefix-independent. If there is an HD-for-games mapping \u03d5 : G \u2192 G\u2032, then Eve\u2019s full winning region in G\u2032 is the projection of her full winning region in G: WEve(G\u2032V \u2032) = \u03d5(WEve(GV )).\n4 The Zielonka tree: An optimal approach to Muller languages\nIn this section, we take a close look into the Zielonka tree, a structure introduced (under the name of split trees) to study Muller languages [81]. We show how to use the Zielonka tree to construct minimal deterministic parity automata and minimal history-deterministic Rabin automata recognising Muller languages. In Section 4.2, we describe the construction of a minimal deterministic parity automaton AparityZF for a given Muller language Muller(F). Theorem 4.13, the main contribution of this section, states the minimality of AparityZF both amongst deterministic and HD parity automata. Theorem 4.12 states the optimality on the number of colours of the acceptance condition of AparityZF , and implies that we can determine\n30\nthe parity index of a Muller language from its Zielonka tree. We will use the optimality of automaton AparityZF to provide a polynomial-time algorithm minimising DPAs recognising Muller languages in Section 6.3.\nIn Section 4.3, we describe the construction of a minimal history-deterministic Rabin automaton ARabinZF for a Muller language Muller(F). Its minimality amongst HD automata is shown in Theorem 4.48, by using the characterisation of the memory requirements of a Muller language in terms of its Zielonka tree [28].\nOn the other hand, it has been shown that finding a minimal deterministic Rabin automaton recognising a given Muller language is NP-complete, if the language is represented by a parity or Rabin automaton, or even by its Zielonka tree [17]. Therefore, unless P = NP, there are Muller languages for which minimal deterministic Rabin automata are strictly larger than minimal HD Rabin automata. Some explicit such languages were shown in [19, Section 4]. A summary of the minimal automata recognising Muller languages appears in Table 1.\nacceptance condition (parity or Rabin) and the form of determinism."
        },
        {
            "heading": "4.1 The Zielonka tree",
            "text": "I Definition 4.1 ([81]). Let F \u2286 2\u03a3+ be a family of non-empty subsets over a finite set \u03a3. A Zielonka tree for F (over \u03a3)6, denoted ZF = (N, , \u03bd : N \u2192 2\u03a3+) is a 2\u03a3+-labelled tree with nodes partitioned into round nodes and square nodes, N = N\u00a9 tN , such that:\nThe root is labelled \u03a3. If a node is labelled X \u2286 \u03a3, with X \u2208 F , then it is a round node, and it has a child for each maximal non-empty subset Y \u2286 X such that Y 6\u2208 F , which is labelled Y . If a node is labelled X \u2286 \u03a3, with X 6\u2208 F , then it is a square node, and it has a child for each maximal non-empty subset Y \u2286 X such that Y \u2208 F , which is labelled Y . y\nI Remark 4.2. We note that for each family of subsets F \u2286 2\u03a3+, there is only one Zielonka tree up to renaming of its nodes, so we will talk of the Zielonka tree of F . y I Remark 4.3. We remark that if n is a node of ZF , then the subtree of ZF rooted at n is the Zielonka tree for the family F|\u03bd(n) over the alphabet \u03bd(n), that is, for the restriction of F to the subsets included in the label of n. y I Remark 4.4. Let n be a node of ZF and let n1 be a child of it. If \u03bd(n1) ( X \u2286 \u03bd(n), then \u03bd(n1) \u2208 F \u21d0\u21d2 X /\u2208 F \u21d0\u21d2 \u03bd(n) /\u2208 F . In particular, if n1, n2 are two different children of n, then \u03bd(n1) \u2208 F \u21d0\u21d2 \u03bd(n2) \u2208 F \u21d0\u21d2 \u03bd(n1) \u222a \u03bd(n2) /\u2208 F . y\n6 The definition of ZF , as well as most subsequent definitions, do not only depend on F but also on the alphabet \u03a3. Although this dependence is important, we do not explicitly include it in the notations in order to lighten them, as most of the times the alphabet will be clear from the context."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 31",
            "text": "We equip Zielonka trees with an order to navigate in them. That is, we equip each set ChildrenZF (n) with a total order, making ZF an ordered tree. The precise order considered will be irrelevant for our purposes. From now on, we will suppose that all Zielonka trees are ordered, without explicitly mentioning it.\nFor a leaf l \u2208 Leaves(ZF ) and a letter a \u2208 \u03a3 we define Supp(l, a) = n to be the deepest ancestor of l (maximal for ) such that a \u2208 \u03bd(n).\nI Example 4.5. We will use the Muller language associated to the following family of subsets as a running example throughout the paper. Let \u03a3 = {a, b, c} and let F be:\nF = {{a, b}, {a, c}, {b}}.\nIn Figure 8 we show the Zielonka tree of F . We use Greek letters (in pink) to name the nodes of the tree. Integers appearing on the right of the tree will be used in next section.\nWe have that Supp(\u03be, c) = \u03bb and Supp(\u03be, b) = \u03b1 . Also, Jump(\u03be, \u03bb) = \u03b6 is the leaf reached by going from \u03be to \u03bb, then changing to the next branch (in a cyclic way) and re-descend by taking the leftmost path. Similarly, Jump(\u03be, \u03b1) = \u03b8.\nThe subtree rooted at \u03bb contains the nodes {\u03bb, \u03be, \u03b6}. We note that this is the Zielonka tree of F|{a,c} = {{a, c}} (over the alphabet {a, c}).\ny"
        },
        {
            "heading": "4.2 A minimal deterministic parity automaton",
            "text": "We present next the Zielonka-tree-parity-automaton, a minimal deterministic parity automaton for a Muller language Muller(F) built from the Zielonka tree ZF . Our construction will furthermore let us determine the parity index of the language Muller(F) from its Zielonka tree."
        },
        {
            "heading": "4.2.1 The Zielonka-tree-parity-automaton",
            "text": "We associate a non-negative integer to each level of a Zielonka tree ZF = (N, , \u03bd). We let pZ : N \u2192 N be the function defined as:\nif \u03a3 \u2208 F , pZ(n) = Depth(n), if \u03a3 /\u2208 F , pZ(n) = Depth(n) + 1.\nWe let minF (resp. maxF ) be the minimum (resp. maximum) value taken by the function pZ . I Remark 4.6. A node n in the Zielonka tree ZF verifies that pZ(n) is even if and only if \u03bd(n) \u2208 F . If \u03a3 \u2208 F , minF = 0 and maxF equals the height of the Zielonka tree minus one. If \u03a3 /\u2208 F , minF = 1 and maxF equals the height of the Zielonka tree. y\n32\nI Example 4.7. The Muller language from Example 4.5 satisfies \u03a3 /\u2208 F . The values taken by the function pZ are represented at the right of the Zielonka tree in Figure 8. We have pZ(\u03b1) = 1, pZ(\u03b2) = pZ(\u03bb) = 2 and pZ(\u03b8) = pZ(\u03be) = pZ(\u03b6) = 3, so minF = 1 and maxF = 3. y\nI Definition 4.8 (Zielonka-tree-parity-automaton). Given a family of non-empty subsets F \u2286 2\u03a3+, we define the ZT-parity-automaton A parity ZF = (Q,\u03a3, q0, [minF ,maxF ], \u03b4, parity) as the deterministic parity automaton given by:\nQ = Leaves(ZF ), q0 is the leftmost leaf of ZF 7, The transition reading a \u2208 \u03a3 from q \u2208 Q goes to Jump(q,Supp(q, a)) and produces pZ(Supp(q, a)) as output, that is,\n\u03b4(q, a) = (Jump(q,Supp(q, a)), pZ(Supp(q, a))) . y\nIntuitively, the transitions of the automaton are determined as follows: if we are in a leaf l and we read a colour a, then we move up in the branch of l until we reach a node n that contains the letter a in its label. Then we pick the child of n just on the right of the branch that we took before (in a cyclic way) and we move to the leftmost leaf below it. The colour produced as output is pZ(n), determined by the depth of n.\nI Example 4.9. In Figure 9 we show the ZT-parity-automaton AparityZF of the family of subsets from Example 4.5. y\nCorrectness of the Zielonka-tree-parity-automaton\nI Proposition 4.10 (Correctness). Let F \u2286 2\u03a3+ be a family of non-empty subsets. Then,\nL(AparityZF ) = Muller\u03a3(F).\nThat is, a word w \u2208 \u03a3\u03c9 is accepted by AparityZF if and only if Inf(w) \u2208 F .\nThe following useful lemma follows directly from the definition of Supp and Jump.\nI Lemma 4.11. Let q be a leaf of ZF and let n be a node above q. Then, Supp(q, a) is a descendant of n if and only if a \u2208 \u03bd(n), and in this case, Jump(q,Supp(q, a)) is a descendant of n too.\n7 Any state can be chosen as initial state (see Lemma 2.5)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 33",
            "text": "Proof of Proposition 4.10. Let w = w0w1w2 \u00b7 \u00b7 \u00b7 \u2208 \u03a3\u03c9 be an infinite word. For i > 0, let qi be the leaf of ZF reached after the (only) run over w0w1 . . . wi\u22121 in AparityZF . For i \u2265 0 let ni = Supp(qi, wi) be the \u201cintermediate node\u201d used to determine the next state and the output colour of each transition, and let ci = pZ(ni) = \u03b3(qi, wi) \u2208 [minF ,maxF ] be that output colour (the output of the run over w being therefore c0c1c2 \u00b7 \u00b7 \u00b7 \u2208 N\u03c9). Let q\u221e be a node appearing infinitely often in the sequence q0q1q2 . . . , and let nw be the deepest ancestor of q\u221e such that Inf(w) \u2286 \u03bd(nw).\nB Claim 4.10.1. There is K \u2208 N such that for all i \u2265 K, qi nw and Supp(qi, wi) nw. In particular, ci \u2265 pZ(nw) for i \u2265 K.\nProof. Let K \u2208 N be a position such that wi \u2208 Inf(w) for all i \u2265 K and qK = q\u221e. The claim follows from Lemma 4.11 and induction. C\nB Claim 4.10.2. Let nw,1, . . . , nw,s be an enumeration of ChildrenZF (nw) from left to right. It is verified that:\n1. Supp(qi, wi) = nw infinitely often. In particular, ci = pZ(nw) for infinitely many i\u2019s. 2. There is no nw,k \u2208 Children(nw) such that Inf(w) \u2286 \u03bd(nw,k).\nProof. We first remark that for all nw,k there are arbitrarily large positions i such that qi is not below nw,k. Suppose by contradiction that this is not the case. Then, for all i sufficiently large we have that Supp(qi, wi) nw,k, and by Lemma 4.11, Inf(w) \u2286 \u03bd(nw,k). In particular, q\u221e is below nw,k, contradicting the fact that nw is the deepest ancestor of q\u221e containing Inf(w).\nLet K be like in the Claim 4.10.1. We show that if i \u2265 K and qi nw,k, then there is j > i such that wj /\u2208 \u03bd(nw,k), Supp(qj , wj) = nw and qj+1 nw,k+1 (by an abuse of notation we let s+ 1 = 1). It suffices to consider the least j \u2265 i such that Supp(qj , wj) nw,k (which exists by the previous remark). Since Inf(w) \u2286 \u03bd(nw) we have that Supp(qj , wj) = nw, so wj /\u2208 \u03bd(nw,j) (by Lemma 4.11) and by definition of the transitions of AparityZF , qj+1 will be a leaf below nw,k+1.\nThe fact that qj+1 nw,k+1 implies that for any child nw,k\u2032 , infinitely many states qi will be below nw,k\u2032 (we go around the children in a round-robin fashion). Therefore, for any k, there are arbitrarily large j such that wj /\u2208 \u03bd(nw,j) and Supp(qj , wj) = nw, implying both items in the claim. C\nCombining both claims, we obtain that the minimum of the colours that are produced as output infinitely often is pZ(nw). By Remark 4.6, pZ(nw) is even if and only if nw is a round node (if \u03bd(nw) \u2208 F). It remains to show that Inf(w) \u2208 F if and only if \u03bd(nw) \u2208 F , which holds by the second item in Claim 4.10.2 and Remark 4.4. J"
        },
        {
            "heading": "4.2.2 Optimality of the Zielonka-tree-parity-automaton",
            "text": "We now state and prove the main results of this section: the optimality of the ZT-parityautomaton in both number of states (Theorem 4.13) and number of colours of the acceptance condition (Theorem 4.12). The minimality of the ZT-parity-automaton comes in two version. A weaker one states its minimality only amongst deterministic automata (Theorem 4.16), and a stronger one states its minimality amongst all history-deterministic automata (Theorem 4.13). Although the weaker version is implied by the stronger one, we find it instructive to provide a proof for this easier case. The proof of the stronger statement is one of the most technical parts of the paper, but the argument used in its proof is just a careful refinement of the ideas appearing in the weaker version.\n34\nStatement of the results\nI Theorem 4.12 (Optimality of the parity condition). The parity index of a Muller language Muller\u03a3(F) is [minF ,maxF ]. That is, the ZT-parity-automaton of Muller\u03a3(F) uses the optimal number of colours to recognise this language.\nI Theorem 4.13 (Minimality of the ZT-parity-automaton). Let A be a history-deterministic parity automaton recognising a Muller language Muller\u03a3(F). Then, |AparityZF | \u2264 |A|.\nI Corollary 4.14. For every Muller language L, a minimal deterministic parity automaton recognising L has the same size than a minimal HD parity automaton recognising L.\nWe remark that, nonetheless, there are non-trivial HD parity automata recognising Muller languages. The automaton provided in Example 2.3 is an HD coB\u00fcchi automaton recognising a Muller language that cannot be made deterministic just by removing transitions. We note that the (deterministic) ZT-parity-automaton for this Muller language has only 2 states.\nWe say that an automaton A is determinisable by prunning if there is a subset \u2206\u2032 \u2286 \u2206 of its transitions and an initial state q0 such that the subautomaton induced by \u2206\u2032 with initial state q0 is deterministic and recognises L(A).\nI Proposition 4.15. There exists an HD parity automaton recognising a Muller language that is not determinisable by prunning.\nOptimality of the parity condition\nProof of Theorem 4.12. Let L = Muller\u03a3(F). The ZT-parity-automaton of L is a parity automaton recognising L using colours in [minF ,maxF ], therefore, the parity index of L is at most [minF ,maxF ].\nTo prove that the parity index is not less than [minF ,maxF ], we use the Flower Lemma 2.16. The language L is trivially recognised by a deterministic Muller automaton AL with just one state q, transitions q\na:a\u2212\u2212\u2192 q for each a \u2208 \u03a3, and acceptance condition given by L itself. Let n1 n2 . . . nd be a branch of maximal length of ZF (that must verify d = maxF \u2212minF , and that the root n1 is a round node if and only if minF is even). If we let `i be the cycle in AL containing exactly the transitions corresponding to letters in \u03bd(ni), we obtain that `1 ) `2 ) \u00b7 \u00b7 \u00b7 ) `d is a d-flower over q, which is positive if and only if n1 is a round node. Lemma 2.16 allows us to conclude. J\nMinimality of the ZT-parity-automaton with respect to deterministic automata\nBefore presenting the proof of Theorem 4.13, we prove a weaker result, namely, that the ZT-parity-automaton is minimal amongst deterministic parity automata recognising a Muller language. We find that a proof of this weaker result might be enlightening for the reader, and it will allow us to introduce the main ingredients used in the proof of the stronger optimality result in a simpler setting.\nI Theorem 4.16 (Minimality of the Zielonka Tree automaton with respect to deterministic automata). Let A be a DPA recognising a Muller language Muller\u03a3(F). Then, |AparityZF | \u2264 |A|.\nWe recall that, by Remark 2.4 and Lemma 2.5, we can suppose that all the states of automata recognising Muller languages are accessible, and that any of them can be chosen to be initial. When considering subautomata of these automata, we will sometimes not mention their initial state."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 35",
            "text": "Let A = (Q,\u03a3, I,\u0393,\u2206,W) be an automaton, and let X \u2286 \u03a3 be a subset of the input alphabet. We say that a subgraph S of the underlying graph of A is X-closed if for every state q in S and every letter a \u2208 X there is some transition q a:c\u2212\u2212\u2192 q\u2032 in S. An X-final strongly connected component (X-FSCC) of A is an X-closed final SCC in the graph obtained by taking the restriction of the underlying graph of A to the edges labelled by letters in X. We remark that a subset S \u2286 Q is the set of states of an X-FSCC if and only if:\nfor any two states q, q\u2032 \u2208 S there is a finite word w \u2208 X\u2217 labelling a finite path from q to q\u2032, and if q \u2208 S and there is a finite path from q to q\u2032 labelled with a word w \u2208 X\u2217, then q\u2032 \u2208 S.\nI Lemma 4.17. Let A be a complete automaton. For every subset X \u2286 \u03a3, A contains an accessible X-FSCC.\nProof. As any graph without sinks contains some final SCC, the accessible part of the restriction of A to edges labelled by letters in X contains one. By completeness of A, one such final SCC has to be an X-closed subgraph, so it is an X-FSCC. J\nI Lemma 4.18. Let A be a DMA recognising a Muller language Muller\u03a3(F), let X \u2286 \u03a3 and let SX be an accessible X-FSCC of A. Then, the automaton induced by SX is a deterministic automaton recognising MullerX(F|X) = {w \u2208 X\u03c9 | Inf(w) \u2208 F}.\nProof. Let A = (Q,\u03a3, q0,\u0393, \u03b4,W) (whereW is a Muller language). Let qS be the state in SX chosen to be initial, and let u0 \u2208 \u03a3\u2217 be a finite word such that the run over u0 from q0 ends in qS . By prefix-independence of Muller languages, a word w \u2208 X\u03c9 belongs to Muller\u03a3(F) if and only if u0w \u2208 Muller\u03a3(F), and therefore, A accepts w if and only if it accepts u0w. Since the run in A over u0w and the run in SX over w have a suffix in common, and by prefix-independence of W, we have that w \u2208 L(SX) if and only if u0w \u2208 L(A) if and only if Inf(w) \u2208 F . J\nNext lemma states that, in a parity automaton, the union of two accepting cycles must be accepting, and similarly for rejecting cycles. In Section 6.1, we will see that this property is actually a characterisation of parity transition systems (Proposition 6.11).\nI Lemma 4.19. Let A be a parity automaton. Let `1, `2 \u2208 Cycles(A) be two cycles with some state in common. If `1 and `2 are both accepting (resp. rejecting), then `1 \u222a `2 is also accepting (resp. rejecting).\nProof. Let \u03b3 : \u2206\u2192 N be the colouring function of A. The cycles `1 and `2 are accepting if and only if di = min \u03b3(`i) is even, for i = 1, 2. In this case, min \u03b3(`1 \u222a `2) = min{d1, d2} is even. The proof is symmetric if `1 and `2 are rejecting. J\nBy a small abuse of notation, we will say that two SCC S1 and S2 are disjoint, and write S1 \u2229 S2 = \u2205, if their sets of states are disjoint.\nI Lemma 4.20. Let F \u2286 2\u03a3+ be a family of subsets with Zielonka tree ZF = (N, , \u03bd), and let A be a DPA recognising Muller\u03a3(F). Let n \u2208 N be a node of the Zielonka tree of F , and let n1, n2 \u2208 ChildrenZF (n) be two different children of n. If S1 and S2 are two accessible \u03bd(n1)-FSCC and \u03bd(n2)-FSCC in A, respectively, then S1 \u2229 S2 = \u2205.\nProof. Without loss of generality, we can suppose that all states in A are accessible, and since the language that A recognises is prefix-independent, we can also suppose that A is complete. Let l\u03a3 : \u2206 \u2192 \u03a3 be the labelling of the transitions of A with input letters. Let\n36\nSi be a \u03bd(ni)-FSCC in A, for i = 1, 2, and let `i be its set of edges, which form a cycle satisfying l\u03a3(`i) = \u03bd(ni). Suppose by contradiction that S1 \u2229 S2 6= \u2205. Then `1 and `2 have some state in common, and their union is also a cycle satisfying l\u03a3(`1 \u222a `2) = \u03bd(n1) \u222a \u03bd(n2). By Lemma 4.19, we must have\n`1 accepting \u21d0\u21d2 `1 \u222a `2 accepting,\ncontradicting the fact that \u03bd(n1) \u2208 F if and only if \u03bd(n1) \u222a \u03bd(n2) /\u2208 F (Remark 4.4). J\nProof of Theorem 4.16. We proceed by induction in the height of ZF . For height 1, the result is trivial, since |AparityZF | = 1. Let A be a DPA recognising Muller\u03a3(F). Let n0 be the root of ZF and n1, n2, . . . , nk be an enumeration of the children of n0 in ZF . By Lemma 4.17, for each i \u2208 {1, . . . , k}, A contains some accessible \u03bd(ni)-FSCC Si, and by Lemma 4.20 these must be pairwise disjoint. By Lemma 4.18, each Si induces a deterministic subautomaton recognising Muller\u03bd(ni)(F|\u03bd(ni)). Let Zi by the subtree of ZF rooted at ni, which we recall that is the Zielonka tree for F|\u03bd(ni). By induction hypothesis, it must be the case that |Leaves(Zi)| \u2264 |Si|, so we can conclude:\n|AparityZF | = |Leaves(ZF )| = k\u2211 i=1 |Leaves(Zi)| \u2264 k\u2211 i=1 |Si| \u2264 |A|. J\nMinimality of the ZT-parity-automaton with respect to HD automata\nWe intend to prove Theorem 4.13, that is, that for any F \u2286 2\u03a3+, the automaton A parity ZF is minimal amongst HD parity automata recognising Muller(F). We will follow the same proof scheme than in the deterministic case, performing an induction over the height of the Zielonka tree. Suppose that A is an HD parity automaton for Muller(F) and that n0 is the root of ZF having n1, . . . , nk as children. For each child ni we want to find an HD subautomaton Ai recognising the language associated to F|\u03bd(ni) in such a way that the automata Ai are pairwise disjoint, which would allow us to carry out the induction and obtain that |A| \u2265 |Leaves(ZF )| = |AparityZF |. Our objective will be therefore to prove:\nI Proposition 4.21. Let n0 be the root of the Zielonka tree of F , and let n1, n2, . . . , nk be an enumeration of the children of n0. If A is an HD automaton recognising Muller\u03a3(F), then, A contains k pairwise disjoint subautomata A1, . . . ,Ak that are history-deterministic and such that L(Ai) = Muller\u03bd(ni)(F|\u03bd(ni)).\nThe non-determinism of A will make this task considerably more laborious than in the previous paragraph, and we will have to thoroughly examine the strategies used by the resolvers for A. By the inherently asymmetric semantics of non-deterministic automata, there are two well-differentiated cases to consider, depending on whether the root of the Zielonka tree is round (\u03a3 \u2208 F) or square (\u03a3 /\u2208 F).\nIn order to simplify the proof, we will suppose that all states are reachable using a sound resolver and that all automata have a single initial state, which can be done without lost of generality since a resolver for an HD automaton fixes such initial state in advance.\nCase 1: The root of the Zielonka tree is a square node: \u03a3 /\u2208 F . LetA = (Q,\u03a3, q0,\u0393,\u2206,W) be a non-deterministic automaton. A memory structure for A is a memory skeleton M over \u2206 together with a function \u03c3 : Q \u00d7M \u00d7 \u03a3 \u2192 \u2206, where M is the set of states of M. We say that (M, \u03c3) implements a resolver (q0, r) if for all a \u2208 \u03a3, r(\u03b5, a) = \u03c3(q0,m0, a) and for all \u03c1 \u2208 \u2206+, r(\u03c1, a) = \u03c3(Target(\u03c1), \u00b5(m0, \u03c1), a), where m0 is the initial state of M and \u00b5 : M \u00d7\u2206\u2217 \u2192M is its update function."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 37",
            "text": "I Lemma 4.22 ([7]). Every HD parity automaton admits a sound resolver implemented by a finite memory structure.\nAs M is a pointed graph labelled with the transitions of A, we could consider the product automaton AnM. We want to furthermore restrict the transitions of this automaton to those that are indicated by the next-move function \u03c3. Given an automaton A and a memory structure (M, \u03c3), we define their composition, which we write A C\u03c3M = (Q \u00d7 M,\u03a3, (q0,m0),\u0393,\u2206\u2032,W) as the automaton having transitions (q,m)\na:c\u2212\u2212\u2192 (q\u2032,m\u2032) if \u03c3(q,m, a) = e = q a:c\u2212\u2212\u2192 q\u2032 and \u00b5(m, e) = m\u2032 (formally, \u2206\u2032 is a subset of \u2206\u00d7 EM, where EM are the edges of the memory skeleton). We note that A C\u03c3M is deterministic, and it is complete if A is.\nThe following lemma follows directly from the definition of soundness of a resolver and the definition of composition of an automaton and a memory structure.\nI Lemma 4.23. Let A be an automaton and (M, \u03c3) a memory structure for A. The resolver implemented by (M, \u03c3) is sound if and only if A and AC\u03c3M recognise the same language.\nFor the rest of the paragraph, we let A = (Q,\u03a3, q0,N,\u2206, parity) be a complete historydeterministic automaton recognising the Muller language MullerF (\u03a3) admitting a sound resolver (q0, r) implemented by a memory structure (M, \u03c3). We let \u03c0A : AC\u03c3M\u2192 A be the morphism of automata given by the projection into the first component: \u03c0A,V (q,m) = q and \u03c0A,E(e1, e2) = e1. I Remark 4.24. If \u03c1 is a path in A C\u03c3M that is labelled by input letters a0a1 \u00b7 \u00b7 \u00b7 \u2208 \u03a3\u221e and producing output c0c1 \u00b7 \u00b7 \u00b7 \u2208 N\u221e, then the \u03c0A-projection of \u03c1 is a path in A labelled by a0a1 \u00b7 \u00b7 \u00b7 \u2208 \u03a3\u221e and producing c0c1 \u00b7 \u00b7 \u00b7 \u2208 N\u221e as output. y\nI Lemma 4.25. Let X \u2286 \u03a3 and let SX be an accessible X-FSCC of AC\u03c3M. Then, \u03c0A(SX) induces an HD subautomaton of A recognising MullerX(F|X) = {w \u2208 X\u03c9 | Inf(w) \u2208 F}.\nProof. Let qS be a state in \u03c0A(SX) chosen to be initial. Let mS be a state in M such that (qS ,mS) \u2208 SX . By Lemma 4.18, SX induces a deterministic subautomaton with initial state (qS ,mS) recognising MullerX(F|X). On the one hand, since \u03c0A(SX) is an accessible subautomaton of A having only transitions labelled by X and by prefix-independence of L(A), we have that\nL(\u03c0A(SX)) \u2286 L(A) \u2229X\u03c9 = MullerX(F \u2223\u2223 X ).\nOn the other hand, the projection of any accepting run in SX provides an accepting run in \u03c0A(SX) (by Remark 4.24), so\nL(SX) = MullerX(F \u2223\u2223 X ) \u2286 L(\u03c0A(SX)).\nMoreover, a sound resolver for \u03c0A(SX) is implemented by (MmS , \u03c3) (the memory structure with initial state set to mS). J\nI Lemma 4.26. Let n \u2208 N be a square node of the Zielonka tree of F (\u03bd(n) /\u2208 F), and let n1, n2 \u2208 ChildrenZF (n) be two different children of n. If S1 and S2 are two accessible \u03bd(n1)-FSCC and \u03bd(n2)-FSCC in AC\u03c3M, respectively, then \u03c0A(S1) \u2229 \u03c0A(S2) = \u2205.\nProof. Suppose by contradiction that there is some state q in \u03c0A(S1) \u2229 \u03c0A(S2), and let m1,m2 \u2208 M be such that (q,m1) and (q,m2) are states in S1 and S2, respectively. For i = 1, 2, let `i \u2208 Cycles(q,mi)(A C\u03c3 M) be the cycle over (q,mi) containing all edges in\n38\nSi. We note that l\u03a3(`i) = \u03bd(ni) and therefore min \u03b3(`i) has to be even (as A C\u03c3M is deterministic), where l\u03a3 and \u03b3 are the labellings of AC\u03c3M with input letters and output colours, respectively. By Remark 4.24, the \u03c0A-projections of `1 and `2 are cycles over q in A labelled with \u03bd(n1) and \u03bd(n2) and in which the minimal colour appearing is even. By alternating these two cycles, we can build an accepting run in A over a word w \u2208 \u03a3\u03c9 with Inf(w) = \u03bd(n1) \u222a \u03bd(n2), contradicting the fact that \u03bd(n1) \u222a \u03bd(n2) /\u2208 F (Remark 4.4). J\nLemmas 4.17, 4.25 and 4.26 imply Proposition 4.21 in the case in which the root of the Zielonka tree is a square node.\nCase 2: The root of the Zielonka tree is a round node: \u03a3 \u2208 F . Before presenting the formal proof, let us discuss why considering these two cases separately is necessary. A first idea to obtain the desired result would be to follow the same steps as in Case 1. However, this approach encounters a major difficulty: the argument used in the proof of Lemma 4.26 is not valid if \u03a3 \u2208 F . Indeed, even if we can find two rejecting cycles `1, `2 such that l\u03a3(`i) = \u03bd(ni), their \u03c0A-projections could a priori have a state in common; this would imply the existence of a rejecting run over the set of letters \u03bd(n1)\u222a \u03bd(n2) \u2208 F , which is not enough to conclude, as the non-determinism of A leaves room for the existence of other accepting runs over this set of letters. To circumvent this difficulty, we need to take a closer look at the strategies used by the resolver. Rather than considering any finite memory strategy resolving the non-determinism of A, we will show that we can choose a very precise resolver for which we will be able to obtain a result analogous to Lemma 4.26. To do this, we first construct the letter game of A, as introduced in [38], which is a Muller game satisfying that a strategy for it yields a resolver for A. The strategy that we will use in this game is the one obtained by applying McNaughton\u2019s algorithm to solve Muller games [58] guided by the Zielonka tree, as presented in [28].\nLet A = (Q,\u03a3, q0, [dmin, dmax],\u2206, parity) be a parity automaton recognising Muller(F), and suppose that \u03a3 \u2229 [dmin, dmax] = \u2205. The letter game for A is the game GA defined as follows:\nThe set of vertices is V = Q t (Q\u00d7 \u03a3). Adam controls vertices in Q, and Eve controls vertices in Q\u00d7 \u03a3. For each letter a \u2208 \u03a3 and each q \u2208 Q, there is an edge q a\u2212\u2192 (q, a). For each position (q, a) \u2208 Q\u00d7 \u03a3, and for each transition q a:c\u2212\u2212\u2192 q\u2032 in A, there is an edge (q, a) c\u2212\u2192 q\u2032. The set of colours is \u0393 = \u03a3 t [dmin, dmax], and the acceptance set is the Muller language associated to\nF \u2192 parity = {C \u2286 \u0393 | [C \u2229 \u03a3 \u2208 F ] =\u21d2 [min(C \u2229 [dmin, dmax]) is even]}.\nThat is, in the letter game, Adam provides input letters one by one, and Eve chooses transitions corresponding to those letters in the automaton A. Eve wins this game if she manages to build an accepting run every time that Adam gives as input an infinite word in the language recognised by A.\nWe remark that a subgraph of GA induces a subautomaton of A via the (partial) mapping autA : GA \u21c0 A that sends states of the form q \u2208 Q to q and edges of the form (q, a)\nc\u2212\u2192 q\u2032 to q a:c\u2212\u2212\u2192 q\u2032.\nI Remark 4.27. A strategy for Eve in GA induces a resolver in A, which is sound if and only if the strategy is winning.\nA. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 39\nI Remark 4.28. If two subsets of vertices of the letter game S1, S2 \u2286 V are disjoint, then autA(S1) \u2229 autA(S2) = \u2205.\nI Remark 4.29. If \u03c1 is a play in GA, labelled a0c0a1c1 \u00b7 \u00b7 \u00b7 \u2208 (\u03a3 \u00b7 [dmin, dmax])\u221e, the autAprojection of \u03c1 is a run in A over a0a1 \u00b7 \u00b7 \u00b7 \u2208 \u03a3\u221e producing c0c1 \u00b7 \u00b7 \u00b7 \u2208 [dmin, dmax]\u221e as output.\nI Lemma 4.30 ([38]). A parity automaton A is HD if and only if Eve wins the letter game from some initial state of A.\nFor a subset X of vertices or edges of a game G, we define Eve\u2019s attractor to X as:\nAttrG(X) = {v \u2208 V | there is a strategy for Eve ensuring to eventually visit X from v}.\nFor a colour c \u2208 \u0393 we note AttrG(c) = AttrG(Ec), where Ec is the set of edges coloured c. For the rest of the paragraph, let A = (Q,\u03a3, q0, [0, d],\u2206, parity) be a complete historydeterministic parity automaton recognising Muller(F). We can suppose without loss of generality that the minimal colour that it uses is 0. We let V and E denote the sets of vertices and edges, respectively, of the letter game and \u0393 = \u03a3 t [0, d] its set of colours. Whenever we use expressions like \u201cthe minimal colour appearing in a play\u201d, it will refer to the restriction of \u0393 to [0, d]. From the prefix-independence of Muller(F) we can moreover suppose that Eve wins the letter game from any vertex (see Lemma 2.5). We let n0 be the root of the Zielonka tree of F (supposed to be round, that is \u03bd(n0) \u2208 F), let n1, . . . , nk be its children, and let \u03a3i = \u03bd(ni) \u2286 \u03a3 (note that \u03a3i /\u2208 F for i \u2265 1).\nLet us examine the condition F \u2192 parity used in the letter game a bit closer. The first levels of its Zielonka tree of this condition are depicted in Figure 11. It is clear that a strategy in GA ensuring to produce colour 0 infinitely often is winning. It might be the case that Adam can prevent Eve from doing this, however, since Eve wins GA, in that case she could ensure to produce infinitely often a set of colours included in some of the round nodes below the root, that is, to either avoid colour 1, or to produce letters included in some \u03a3i. We use this idea to define next attractor decompositions for GA.\nGiven a subset of vertices V \u2032 \u2286 V we write GA(V \u2032) to denote the subgame of GA containing the vertices of V \u2032 and the edges between them.\n40\nLet x be an even integer. For a subgame G\u2032 = GA(V \u2032) of GA with no colour strictly smaller than x, we define an x-attractor decomposition of G\u2032 as a partition of V \u2032 into\nV \u2032 = AttrG\u2032(x) t V1 tA1 t \u00b7 \u00b7 \u00b7 t Vl tAl,\nsatisfying:\nAttrG\u2032(x) is Eve\u2019s attractor to x in G\u2032. For each Vj , either (1) there is some i \u2208 {1, . . . , k} such that no colour of \u03a3 \\ \u03a3i appears in GA(Vj), or (2) Eve has a winning strategy for GA(Vj) (from any vertex) avoiding colour x+ 1; and in both cases, if Adam can leave Vj taking an edge v\na\u2212\u2192 v\u2032 (v \u2208 Vj , v\u2032 /\u2208 Vj), then v\u2032 \u2208 AttrG\u2032(x) t V1 tA1 t . . . Vj\u22121 tAj\u22121. In case (1) we say that Vj is a \u03a3i-region of the attractor decomposition and in case (2) that Vj is an x+ 1-avoiding region. Eve wins GA(Vj) from every vertex for all j. Aj = AttrGj (Vj), where Gj is the subgame induced by the subset of vertices given by V \\ (AttrG\u2032(x) t V1 t . . . t Vj\u22121 tAj\u22121) (we note that this game does not contain edges coloured with x).\nIf Vj is an x + 1-avoiding region, we let G\u2032j be the subgame obtained from GA(Vj) by removing the transitions labelled x+ 1.\nAn x-recursive attractor decomposition of G\u2032 is:\nDG\u2032 = \u3008AttrG\u2032(x), (V1, A1,DG\u20321), (V2, A2,DG\u20322), . . . , (Vl, Al,DG\u2032l )\u3009,\nwhere AttrG\u2032(x) t V1 tA1 t \u00b7 \u00b7 \u00b7 t Vl tAl is an x-attractor decomposition of G\u2032, and, if Vj is an x+ 1-avoiding region, then DG\u2032 j is an x+ 2-recursive attractor decomposition of G\u2032j . (If Vj is an \u03a3i-region, DG\u2032 j can be disregarded).\nA representation of an attractor decomposition appears in Figure 12. We say that a subgame S of G\u2032 is a \u03a3i-region of DG\u2032 if it is a \u03a3i-region of some of the recursively defined attractor decompositions. Similarly, for y > x an odd integer, we say that S is a y-avoiding region of DG\u2032 if it is a y-avoiding region of some of the recursively defined attractor decompositions. We say that the full game G\u2032 is an x\u2212 1-avoiding region (note that x might take the value 0). We remark that for any subset S of vertices of G\u2032 there is one and only one minimal y-avoiding region of DG\u2032 containing S (note that y might equal \u22121). I Remark 4.31. A 0-recursive attractor decomposition DGA of GA induces a partition of the vertices into\nV = S1 t \u00b7 \u00b7 \u00b7 t Sr t A1 t . . . Ar t B1 t \u00b7 \u00b7 \u00b7 tBs,"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 41",
            "text": "part represents a 2-attractor decomposition of the subgame G\u20322 induced by the 1-avoiding region V2. Since no 3-avoiding region appears on it, this is a full attractor decomposition of the game G, inducing a partition into three different kinds of regions. The order over the \u03a3i-regions is given by V1 <D V2,1 <D V2,2 <D V3. Adam can only force to decrease with respect to this order, that is, at each sublevel of the decomposition, Adam cannot force to go to the right.\nsuch that:\nSj is a \u03a3i-region of DGA , for some i \u2208 {1, . . . , k}, Aj = AttrGj (Sj) for some subgame Gj appearing at some level of the decomposition, Bj = AttrG\u2032 j (x) for some even integer x and some x\u2212 1-avoiding region G\u2032j appearing at some level of the decomposition.\nMoreover, such a decomposition induces a total order over the \u03a3i-regions: for two sets St, St\u2032 , we write St <D St\u2032 if there are two regions Vj , Vj\u2032 belonging to the same attractor decomposition in DGA such that j < j\u2032, St \u2286 Vj and St\u2032 \u2286 Vk\u2032 .\nWe call such a partition a full attractor decomposition of GA. We remark that, by definition of an attractor decomposition, Eve wins GA(Sj) from every vertex for every Sj . See Figure 12 for an illustration. y\nThe proof that GA admits a full attractor decomposition uses the ideas appearing in [28, Section 3].\nI Lemma 4.32. Let x be an even integer. If G\u2032 is a subgame of GA with no colour smaller than x and such that Eve can win from every vertex, then it admits an x-attractor decomposition. In particular, GA admits a full attractor decomposition.\nProof. We suppose without loss of generality that x = 0. Suppose that V1, A1, . . . Vj\u22121, Aj\u22121 have already been defined and that they verify the desired properties. Suppose that the game Gj with vertices V \\ (AttrG\u2032(0) t V1 t . . . Vj\u22121 tAj\u22121) is non-empty. First, note that Eve wins Gj from any position. Indeed, Eve wins G\u2032 from any vertex v in Gj (as we suppose that she can win G\u2032 starting anywhere); moreover, since v /\u2208 Aj\u2032 for any j\u2032 < j, Adam has a strategy from v to force to remain in Gj , and Eve has to be able to win against any such strategy.\nWe prove that either (1) there is some i \u2208 {1, . . . , k} and v vertex in Gj such that Eve has a winning strategy from v forcing to produce no colour in \u03a3 \\ \u03a3i, or (2) there is some vertex v in Gj such that Eve has a winning strategy from v avoiding colour 1. Suppose by contradiction that this was not the case. Then, Adam can use the following strategy:\n42\nfirst, he forces to produce colour 1, then, a colour not in \u03a31, followed by a color not in \u03a32, and continues this pattern until a color not in \u03a3l is produced (and this without producing colour 0, since no 0-edge appears in Gj). Afterward, he continue repeating these steps in a round-robin fashion. This allows him to produce a play winning for him (the word produced is in Muller(F) while the minimal number produced is 1), contradicting the fact that Eve wins Gj from v.\nWe suppose that we are in the case (1) (case (2) is identical), so from some vertices Eve can win producing no colour in \u03a3 \\ \u03a3i. We let Vj be the set of such vertices, and for each of them we fix a strategy stratv that is winning in Gj and avoids colours in \u03a3 \\\u03a3i. By definition of Vj , if \u03c1 = v v\u2032 is a finite play consistent with stratv in Gj , then v\u2032 \u2208 Vj (Eve can still win without producing colours in \u03a3 \\ \u03a3i), so Adam cannot force to leave Vj . This proves that:\n1. stratv is winning in GA(Vj) from v, 2. if v \u2208 Vj is controlled by Adam and v \u2212\u2192 v\u2032 is an edge in GA, then v\u2032 \u2208 AttrG\u2032(0) t V1 t\nA1 t . . . Vj\u22121 tAj\u22121 t Vj .\nAlso, if a vertex v controlled by Adam is in Vj , no edge v a/\u2208\u03a3i\u2212\u2212\u2212\u2192 v\u2032 appears in Gj , so no colour of \u03a3 \\ \u03a3i appears in GA(Vj). To finish the proof, we define Aj to be the attractor of Vj in Gj .\nThe existence of a full attractor decomposition for GA follows from the fact that any x+1-avoiding region of an x-attractor decomposition verifies the hypothesis of the lemma. J\nI Lemma 4.33 ([58]). Let G be a game using a Muller acceptance condition such that Eve wins G from every vertex. Then, there is a finite memory structure (M, \u03c3) over G implementing a winning strategy uniformly, that is, for every vertex v of G there is a memory state mv in M such that the memory structure (Mmv , \u03c3) implements a winning strategy from v.\nFor the rest of the paragraph, we fix a 0-recursive attractor decomposition DGA for GA and let S1 <D S2 . . . <D Sr be the \u03a3i-regions of the induced full attractor decomposition. For each region Sj we fix a memory structure (Mj , \u03c3j) uniformly implementing a winning strategy for Eve in GA(Sj) (as given by Lemma 4.33). As in the previous paragraph, we can consider the composition GA(Sj)C\u03c3j Mj consisting of the product game in which the choices for Eve are restricted to those of the form (v,m) c\u2212\u2192 (v\u2032,m\u2032) if \u03c3j(v,m) = e = v\nc\u2212\u2192 v\u2032 and \u00b5j(m, e) = m\u2032. By definition, Eve does not have any choice in GA(Sj) C\u03c3j Mj , and since (Mj , \u03c3j) implements a winning strategy, any infinite path in GA(Sj)C\u03c3j Mj produces a set of colours in F \u2192 parity. We let \u03c0G : GA(Sj)C\u03c3j Mj \u2192 GA(Sj) be the projection into GA(Sj).\nA subgraph Gj of GA(Sj) C\u03c3j Mj is X-closed, for a subset X \u2286 \u03a3, if for every vertex (q,m) controlled by Adam and every a \u2208 X there is a transition (q,m) a\u2212\u2192 ((q, a),m\u2032) in Gj (that is, q a\u2212\u2192 (q, a) \u2208 GA(Sj)). We say that Gj is an X-FSCC if it is an X-closed final SCC of the restriction of GA(Sj) C\u03c3j Mj to the graph where Adam\u2019s choices are restricted to letters in X. We say that a subgraph G of GA is an X-closed subgame (with respect to the attractor decomposition DGA and a family of finite memory strategies) if G = \u03c0G(Gj) for Gj some X-closed SCC of some product GA(Sj)C\u03c3j Mj .\nI Lemma 4.34. Eve wins any X-closed subgame of GA (from any vertex)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 43",
            "text": "Proof. In an X-closed subgame included in a region GA(Sj), Adam\u2019s moves have been restricted; however, all Eve\u2019s moves coming from the strategy implemented by (Mj , \u03c3j) are available. Therefore, this strategy is also winning in such a subgame, since it is winning in the full GA(Sj). J\nPutting this lemma together with Remark 4.27 we obtain:\nI Lemma 4.35. Let X \u2286 \u03a3, and let GX \u2286 GA be an X-closed subgame of GA. The subautomaton of A induced by autA(GX) is HD and recognises MullerX(F|X).\nI Lemma 4.36. If a product GA(Sj)C\u03c3j Mj does not contain any X-closed subgraph, for X \u2286 \u03a3, then from any vertex (q,m) Adam can force to leave Sj while playing only letters in X. That is, there is a path (q,m) (q\u2032,m\u2032) in GA(Sj)C\u03c3j Mj producing exclusively letters in X such that, for some a \u2208 X, the edge q\u2032 a\u2212\u2192 (q\u2032, a) does not belong to GA(Sj).\nProof. If this was not the case, the subgraph of GA(Sj)C\u03c3jMj consisting of the vertices that can be reachable from (q,m) by reading letters in X would form an X-closed subgraph. J\nI Lemma 4.37. For each label \u03a3i of the children of the root of ZF , GA admits some \u03a3i-closed subgame contained in a \u03a3i-region of DGA .\nProof. Suppose that the full attractor decomposition of GA induced by DGA is the following:\nV = S1 t \u00b7 \u00b7 \u00b7 t Sr t A1 t . . . Ar t B1 t \u00b7 \u00b7 \u00b7 tBs,\nWe fix the following strategy strat for Eve in the letter game:\nwhenever the play lands to Bj , where Bj = AttrG\u2032 j (x) for some even colour x, she forces to produce colour x, whenever the play arrives to some Aj , she forces to go to Sj , in regions Sj she uses the strategy (Mj , \u03c3j). More precisely, let mv be the state ofMj such that (Mj,v, \u03c3j) implements a winning strategy for GA(Vj) from (v,mv). Each time that the play arrives to a vertex v in Vj from a different region, Eve uses (Mj,v, \u03c3j).\nB Claim 4.37.1. Let \u03c1 be a play consistent with strat (from any vertex), and let y \u2265 \u22121 be the maximal odd number such that Inf(\u03c1) is contained in a y-avoiding region S of DGA . Then, either \u03c1 eventually stays in a \u03a3i-region Sj contained in S, or the minimal colour produced infinitely often by \u03c1 is y + 1.\nProof. Let AttrS(y + 1) t V1 t A1 t . . . . . . , Vl t Al be the attractor decomposition of S appearing in DGA . By definition of an attractor decomposition, each time that the play leaves a Vj region, the next vertex is in v\u2032 \u2208 AttrS(y + 1) t V1 tA1 t . . . Vj\u22121 tAj\u22121. First, if Vj is a y + 2-avoiding region, \u03c1 cannot stay in it (by maximality of y). Thus, if \u03c1 does not eventually stay in a \u03a3i-region, it leaves regions Vj infinitely often, so it must produce y + 1 infinitely often too. Since S is a y-avoiding region, no colour smaller than y + 1 is produced.\nC\nWe obtain as a consequence that strat is winning for Eve from any initial position: any play staying in a y-avoiding region and producing infinitely many y + 1\u2019s is winning, and if a play eventually stays in a \u03a3i-region Sj , it has to be winning since the strategy implemented by (Mj , \u03c3j) is winning in there.\nWe remark that we can extract a \u03a3i-FSCC from any \u03a3i-closed subgraph of GA(Sj)C\u03c3jMj , that will be contained in the \u03a3i-region Sj , so it suffices to prove the existence of such \u03a3i-closed\n44\nsubgraphs. We also recall that in GA(Sj) C\u03c3j Mj all choices are left to Adam, so he can choose to produce any path in this product whenever the play arrives to a vertex v in Sj .\nSuppose by contradiction that no accessible \u03a3i-closed subgraph exists in any of the products. We consider a play in which Adam does the following:\n(a) the letters that he gives form a word w \u2208 \u03a3\u03c9 such that Inf(w) = \u03a3i, (b) each time that the play arrives to a region Sj , he exists this region in a finite number of\nsteps.\nIndeed, he can ensure to exit regions Sj while only producing letters in \u03a3i by Lemma 4.36. By Claim 4.37.1, the minimal colour produced infinitely often by such a play is even. By Remark 4.29, we can project such a play in the automaton A, obtaining an accepting run over w. This is a contradiction, since w /\u2208 Muller(F) = L(A) (because \u03a3i /\u2208 F). We conclude that some GA(Sj) C\u03c3j Mj admits a \u03a3i-FSCC, and therefore GA admits some \u03a3i-closed subgame. J\nWe can now infer Proposition 4.21 in the case in which the root of ZF is round: from Lemma 4.37, we obtain \u03a3i-closed subgames in GA for each i \u2208 {1, . . . , k} that are moreover contained in \u03a3i-regions. Therefore, their autA-projections are disjoint (Remark 4.28), and each of these projections induces an HD-subautomaton recognising F|\u03a3i (Lemma 4.35)."
        },
        {
            "heading": "4.3 A minimal history-deterministic Rabin automaton",
            "text": "In this section, we present the construction of a history-deterministic Rabin automaton ARabinZF for a Muller language Muller(F) using the Zielonka tree ZF , and prove its minimality (Theorem 4.48). The automaton ARabinZF can be seen as a quotient of the ZT-parity-automaton; that is, ARabinZF is obtained by merging some of the states of A parity ZF . Thus, we replace the complexity in the number of states by complexity in the acceptance condition. The size of the automaton ARabinZF is a well-studied parameter of Zielonka trees: its round-branching width, rbw(ZF ). This parameter was introduced by Dziembowski, Jurdzi\u0144ski and Walukiewicz [28] (under the name of memory of ZF ) and shown to coincide with the memory required by Eve to win in games using Muller(F) as an acceptance condition (see Proposition 4.49 below). In this paper, we are not concerned with the memory of winning conditions, but we will use the result from [28] to obtain the minimality of ARabinZF .\nWe note that this construction is asymmetric, in the sense that we show it for Rabin automata, but not for Streett automata (their dual notion). The reason why we cannot dualize the construction is due to the semantics of non-deterministic automata. However, we could use the same idea to obtain a minimal universal history-deterministic Streett automaton (we refer to [10] for the definition of universal HD automata)."
        },
        {
            "heading": "4.3.1 The Zielonka-tree-HD-Rabin-automaton",
            "text": "I Definition 4.38 ([28]). Let T be a tree with nodes partitioned into round and square nodes, and let T1, . . . , Tk be the subtrees of T rooted at the children of the root of T . We define inductively the round-branching width of T , denoted rbw(T ) as:\nrbw(T ) =  1 if T has exactly one node,\nmax{rbw(T1), . . . , rbw(Tk)} if the root is square, k\u2211 i=1 rbw(Ti) if the root is round. y"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 45",
            "text": "Next lemma directly follows from the definition of rbw(T ).\nI Lemma 4.39. Let T = (N = N\u00a9 t N , ) be a tree with nodes partitioned into round and square nodes. There exists a mapping \u03b7 : Leaves(T )\u2192 {1, 2, . . . , rbw(T )} satisfying:\nIf n \u2208 N is a round node with children n1 6= n2, for any pair of leaves l1 and l2 below n1 and n2, respectively, \u03b7(l1) 6= \u03b7(l2). (?)\nI Example 4.40. Let F = {{a, b}, {a, c}, {b}} be the family of subsets considered in Example 4.5. The round-branching width of ZF is rbw(ZF ) = 2. A labelling \u03b7 : Leaves(ZF )\u2192 {1, 2} satisfying Property ? is given by \u03b7(\u03b8) = \u03b7(\u03be) = 1 and \u03b7(\u03b6) = 2. This labelling is represented in the Zielonka tree ZF on the left of Figure 13.\nI Definition 4.41 (Zielonka-tree-HD-Rabin-automaton). Let F \u2286 2\u03a3+, ZF = (N = N\u00a9 t N , ) its Zielonka tree and \u03b7 : Leaves(ZF ) \u2192 {1, 2, . . . , rbw(ZF )} a mapping satisfying Property (?). We define the ZT-HD-Rabin-automaton ARabinZF = (Q,\u03a3, I,\u0393,\u2206,Rabin\u0393(R)) as a (non-deterministic) automaton using a Rabin acceptance condition, where:\nQ = {1, 2, . . . , rbw(ZF )}, I = Q8, \u0393 = N (the colours of the acceptance condition are the nodes of the Zielonka tree), \u03b4(q, a) = { ( Jump(l,Supp(l, a)),Supp(l, a) ) | l \u2208 Leaves(ZF ) such that \u03b7(l) = q}, R = {(Gn, Rn)}n\u2208N\u00a9 , where Gn and Rn are defined as follow: Let n be a round node and n\u2032 be any node of ZF ,{\nn\u2032 \u2208 Gn if n\u2032 = n, n\u2032 \u2208 Rn if n\u2032 6= n and n is not an ancestor of n\u2032. y\nI Remark 4.42. Although we will usually say that ARabinZF is the ZT-HD-Rabin-automaton of F , the structure of this automaton is not unique, it depends on two choices: the order over the nodes of the Zielonka tree and the mapping \u03b7. y\nThe intuition behind this definition is the following. The automaton ARabinZF has rbw(ZF ) states, and each of them can be associated to a subset of leaves of ZF by \u03b7\u22121(q). The mapping \u03b7 is such that the lowest common ancestor of two leaves in \u03b7\u22121(q) is a square node. As for the ZT-parity-automaton, for each leaf of l \u2208 Leaves(ZF ) and letter a \u2208 \u03a3, we identify the deepest ancestor n = Supp(l, a) containing a in its label, and, using the Jump function, pick a leaf l\u2032 below the next child of n. We add a transition q a:n\u2212\u2212\u2192 q\u2032 if there are leaves l \u2208 \u03b7\u22121(q) and l\u2032 \u2208 \u03b7\u22121(q\u2032) giving such a path. This way, we can identify a run in the automaton ARabinZF with a promenade through the nodes of the Zielonka tree in which jumps between leaves with the same \u03b7-image are allowed. If during this promenade a unique minimal node (for ) is visited infinitely often, it is not difficult to see that the sequence of input colours belongs to F if and only if the label of this minimal node belongs to F (it is a round node). The Rabin condition over the set of nodes of the Zielonka tree is devised so that it accepts exactly these sequences of nodes (see Lemma 4.46 below).\nAnother way of presenting the automaton ARabinZF is as a quotient of the deterministic parity automaton AparityZF . Indeed, the graph structure and the labelling by input letters of ARabinZF is obtained by merging the states of A parity ZF (which are the leaves of ZF ) with the same \u03b7-image, and keeping all the transitions between them. However, a parity acceptance condition over this smaller structure is no longer sufficient to accept Muller(F).\n8 Any non-empty subset of Q can be chosen as the set of initial states.\n46\nI Example 4.43. The ZT-HD-Rabin-automaton ARabinZF of the family F = {{a, b}, {a, c}, {b}} from Example 4.5 is shown on the right of Figure 13. The Zielonka tree ZF appears on the left of the figure, and the labelling \u03b7 : Leaves(ZF ) \u2192 {1, 2} is represented by the numbers below its branches.\nThe Rabin condition of this automaton is given by two Rabin pairs (corresponding to the round nodes of the Zielonka tree):\nG\u03b2 = {\u03b2}, R\u03b2 = {\u03b1, \u03bb, \u03be, \u03b6}, G\u03bb = {\u03bb}, R\u03bb = {\u03b1, \u03b2, \u03b8}.\nRabin-automaton ARabinZF . Blue transitions correspond to those coming from leaf \u03b8, and green ones to those originating from leaf \u03be.\nWe note that the automaton ARabinZF is obtained by merging the states \u03b8 and \u03be from the ZT-parity-automaton AparityZF appearing in Figure 9, and replacing the output colours by\nsuitable nodes from the Zielonka tree. y\nI Remark 4.44. We observe that the automaton from Figure 13 presents duplicated edges, in the sense that there are two transitions q a:x\u2212\u2212\u2192 q\u2032 and q a:y\u2212\u2212\u2192 q\u2032 between the same pair of states and reading the same input letter. We can always avoid this and remove duplicated edges from any automaton. We provide a proof in Appendix D (Proposition D.1). For the language from the previous example, an equivalent automaton is proposed in Figure 18\nCorrectness of the Zielonka-tree-HD-Rabin-automaton\nI Proposition 4.45 (Correctness). Let F \u2286 2\u03a3+ be a family of non-empty subsets. Then,\nL(ARabinZF ) = Muller\u03a3(F).\nMoreover, the automaton ARabinZF is history-deterministic.\nI Lemma 4.46. Let u = n0n1n2 \u00b7 \u00b7 \u00b7 \u2208 N\u03c9 be an infinite sequence of nodes of the Zielonka tree. The word u belongs to RabinN (R), for R = {(Gn, Rn)}n\u2208N\u00a9 the Rabin condition of ARabinZF , if and only if there is a unique minimal node for the ancestor relation in Inf(u) and this minimal node is round (recall that the root is the minimal element for ).\nProof. Suppose that there is a unique minimal node in Inf(u), called n, and that n is round. We claim that u is accepted by the Rabin pair (Gn, Rn). It is clear that Inf(u) \u2229 Gn 6= \u2205, because n \u2208 Gn. It suffices to show that Inf(u) \u2229 Rn = \u2205: By minimality, any other node n\u2032 \u2208 Inf(u) is a descendant of n (equivalently, n is an ancestor of n\u2032), so n\u2032 /\u2208 Rn.\nConversely, suppose that u \u2208 RabinN (R). Then, there is some round node n \u2208 N\u00a9 such that Inf(u) \u2229 Gn 6= \u2205 and Inf(u) \u2229 Rn = \u2205. Since Gn = {n}, we deduce that n \u2208 Inf(u)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 47",
            "text": "Moreover, as Inf(u) \u2229Rn = \u2205, all nodes in Inf(u) are descendants of n. We conclude that n is the unique minimal node in Inf(u), and it is round. J\nI Lemma 4.47. There exists a morphism of automata \u03d5 : AparityZF \u2192 A Rabin ZF .\nProof. We define the morphism \u03d5 as follows:\n\u03d5V (l) = \u03b7(l), for l \u2208 Leaves(AparityZF ), for a transition e = l a:c\u2212\u2212\u2192 l\u2032 in AparityZF , we let \u03d5E(e) = (\u03b7(l), a,Supp(l, a), l \u2032).\nIt is clear that \u03d5 is a weak morphism. We prove that it preserve the acceptance of runs. Let \u03c1 = l0 w0\u2212\u2212\u2192 l1 w1\u2212\u2212\u2192 l2 w2\u2212\u2212\u2192 \u00b7 \u00b7 \u00b7 \u2208 Run(AparityZF ) be an infinite run in A parity ZF (the only run over w0w1w2 \u00b7 \u00b7 \u00b7 \u2208 \u03a3\u03c9), and let ni = Supp(li, wi). By definition of the morphism, the output of the run \u03c1\u2032 = \u03d5Runs (\u03c1) in ARabinZF is \u03b3\n\u2032(\u03c1\u2032) = n0n1n2 \u00b7 \u00b7 \u00b7 \u2208 N\u03c9. In the proof of Proposition 4.10, we proved (Claims 4.10.1 and 4.10.2) that there exists a unique node nw appearing infinitely often in \u03b3\u2032(\u03c1\u2032). Moreover, we proved that \u03c1 is accepting in AparityZF if and only if nw is round. Lemma 4.46 allows us to conclude that \u03d5Runs(\u03c1) is accepting in ARabinZF if and only if \u03c1 is accepting in AparityZF . J\nProof of Proposition 4.45. L(ARabinZF ) \u2286 Muller\u03a3(F): Let w \u2208 L(A Rabin ZF ) and let u \u2208 N \u03c9 be the sequence of nodes produced as output of an accepting run over w in ARabinZF . By Lemma 4.46, there is a unique minimal node n for appearing infinitely often in u and moreover n is round. Let n1, . . . , nk be an enumeration of the children of n (from left to right), with labels \u03bd(ni) \u2286 \u03a3 (we remark that \u03bd(ni) /\u2208 F , for 1 \u2264 i \u2264 k). We will prove that Inf(w) \u2286 \u03bd(n) and Inf(w) * \u03bd(ni) for 1 \u2264 i \u2264 k. By definition of the Zielonka tree, as n is round, this implies that Inf(w) \u2208 F .\nSince eventually all nodes produced as output are descendants of n (by minimality), Inf(w) must be contained in \u03bd(n) (by definition of the transitions of ARabinZF ).\nWe suppose, towards a contradiction, that Inf(w) \u2286 \u03bd(nj) for some 1 \u2264 j \u2264 k. Let Qi = {\u03b7(l) : l is a leaf below ni} be the set of states corresponding to leaves under ni, for 1 \u2264 i \u2264 k. We can suppose that the leaves corresponding to transitions of an accepting run over w are all below n, and therefore, transitions of such a run only visit states in \u22c3k i=1Qi. Indeed, eventually this is going to be the case, because if some of the leaves l, l\u2032 corresponding to a transition (q, a, n\u2032, q\u2032) are not below n, then n\u2032 would not be a descendant of n (since n\u2032 is the least common ancestor of l and l\u2032). Also, by Property (?), we have Qi \u2229Qj = \u2205, for all i 6= j. By definition of the transitions of ARabinZF , if a \u2208 \u03a3 is a letter in \u03bd(n) but not in \u03bd(ni), all transitions from some state in Qi reading the colour a go to Qi+1, for 1 \u2264 i \u2264 k\u2212 1 (and to Q1 if i = k). Also, if a \u2208 \u03bd(ni), transitions from states in Qi reading a stay in Qi. We deduce that a run over w will eventually only visit states in Qj , for some j such that Inf(w) \u2286 \u03bd(nj). However, the only transitions from Qj that would produce n as output are those corresponding to a colour a /\u2208 \u03bd(nj), so the node n is not produced infinitely often, a contradiction.\nMuller\u03a3(F) \u2286 L(ARabinZF ) and history-determinism: The existence of a morphism \u03d5 : AparityZF \u2192 A Rabin ZF (Lemma 4.47) and the correctness of A parity ZF (Proposition 4.10) imply that L(ARabinZF ) = L(A parity ZF ) = Muller(F). Indeed, if \u03c1 is an accepting run over w \u2208 \u03a3\n\u03c9 in AparityZF , then \u03d5Runs(\u03c1) is an accepting run over w in ARabinZF . We can moreover use A parity ZF and \u03d5 to define a sound resolver (r0, r) for ARabinZF : we let r0 = \u03d5(q0) be the image of the initial state of AparityZF . If \u03c1R \u2208 Run fin(ARabinZF ) is the image under \u03d5Runs of some finite run \u03c1P \u2208 Run fin(AparityZF ), we let r(\u03c1R, a) = \u03d5(e), where e is the only a-labelled transition from Target(\u03c1P ). We define r arbitrarily in other case. This way, for every w \u2208 \u03a3\u03c9, the run induced by r over w is the image of a run over w in AparityZF , which must be accepting if w \u2208 Muller(F). J\n48"
        },
        {
            "heading": "4.3.2 Optimality of the Zielonka-tree-HD-Rabin-automaton",
            "text": "We devote this section to the proof of the optimality of ARabinZF .\nI Theorem 4.48 (Optimality of the ZT-HD-Rabin-automaton). Let A be a history-deterministic Rabin automaton accepting a Muller language Muller\u03a3(F). Then, |ARabinZF | \u2264 |A|.\nI Proposition 4.49 ([28]). Let L = Muller\u03a3(F) be a Muller language.\n1. If Eve wins a game with L as acceptance set from a position v, there is a winning strategy from v for her implemented by a memory structure of size rbw(ZF ).\n2. There exists a game G using L as acceptance condition in which Eve can win from a position v, but there is no winning strategy from v for her implemented by a memory structure of size strictly smaller than rbw(ZF ).\nI Lemma 4.50 ([44, 81]). Rabin languages are positionally determined, that is, if Eve wins a game using a Rabin acceptance condition from a position v, there is a winning strategy from v for her implemented by a memory structure of size 1.\nI Corollary 4.51. Let A be a history-deterministic Rabin automaton. Then, if Eve wins a game with W = L(A) as acceptance set from a position v, there is a winning strategy from v for her implemented by a memory structure of size |A|.\nProof. Let G be a game with W = L(A) as acceptance set. In order to be able to take the product by A and obtain an equivalent game, we transform G into a game suitable for transformations. Let G\u0303 be the game obtained from G in the following way: for every edge e = v a\u2212\u2192 v\u2032 in G, we add a position (v, e) controlled by Eve and replace edge e by v \u03b5\u2212\u2192 (v, e) a\u2212\u2192 v\u2032. It is clear that Eve wins G from a vertex v if and only if she wins G\u0303 from that same vertex. By Proposition 2.7, if Eve wins G from a vertex v, she wins G\u0303 nA from a vertex (v, q0), where q0 is an initial vertex of A. Moreover, the game G\u0303 n A uses the acceptance set from A, which is a Rabin language, so, by Lemma 4.50, she can win using a strategy given by a function \u03c3 : V\u0303Eve \u2192 E\u0303, where Q is the set of states of A and V\u0303Eve the vertices controlled by Eve in G\u0303 (a subset of (VEve t (V \u00d7 E)) \u00d7 Q). We build a memory structure (M, \u03c3M) of size |Q| that projects the strategy implemented by \u03c3 onto G:\nits set of states is M = Q, the initial state is q0, the update function \u00b5 : M \u00d7E \u2192M sends \u00b5(q, e) = q\u2032 if \u03c3((v, e), q) = ((v, e), q) \u2212\u2192 (v\u2032, q\u2032) is the move chosen by \u03c3 from vertex ((v, e), q), for v \u2208 VEve, q \u2208M , we let \u03c3M(v, q) = e if e is the move chosen by \u03c3 from (v, q), that is, if \u03c3(v, q) = (v, q) \u2212\u2192 ((v, q), e).\nSince \u03c3 implements a winning strategy in G\u0303 n A from (v, q0), its projection onto G via the memory structure (M, \u03c3M) is a strategy that verifies that any play consistent with it produces as output a word in L(A), so it is winning. J\nTheorem 4.48 is obtained by combining the fact that |ARabinZF | = rbw(ZF ) with Proposition 4.49 (second item) and Corollary 4.51."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 49",
            "text": "5 The alternating cycle decomposition: An optimal approach to Muller transition systems\nIn Section 4, we have provided minimal parity and Rabin automata for Muller languages, using the Zielonka tree. We can use these automata to transform Muller transition systems, by applying the product construction. However, this approach overlooks the structure of the transition system, meaning it does not take into account the relevant interplay between the underlying graph and the acceptance condition.\nIn this section, we present our main contributions: optimal transformations of Muller transition systems into parity and Rabin ones. The key novelty is that they precisely capture the way the transition system interacts with the acceptance condition. This is achieved by generalising Zielonka trees from Muller languages to Muller transition systems; we define the alternating cycle decomposition (ACD), consisting in a collection of Zielonka-tree-like structures subsuming all the structural information of the transition system necessary to determine whether a run is accepting or not. More precisely, the ACD is a succinct representation of the alternating chains of loops of a Muller automaton, in the sense of Wagner [80]. The alternating chains of loops of a DMA are known to determine the parity index of the language it recognises [80], and, as we will show, they also capture the essential information to define optimal transformations of automata.\nWe start with the definition of the alternating cycle decomposition in Section 5.1. In Section 5.2, we describe the ACD-parity-transform, turning a DMA A into an equivalent DPA ACDparity(A). Formally, the validity of this transformation is witnessed by a locally bijective morphism \u03d5 : ACDparity(A)\u2192 A (Proposition 5.18). In Section 5.3, we describe the ACD-HD-Rabin-transform that turns a DMA A into an equivalent history-deterministic Rabin automaton ACDRabin(A). The validity of the transformation is witnessed by an HD mapping \u03d5 : ACDRabin(A)\u2192 A (Proposition 5.25). These constructions grant strong optimality guarantees. The automaton ACDparity(A) (resp. ACDRabin(A)) has a minimal number of states amongst parity (resp. Rabin) automata admitting an HD mapping to A (Theorems 5.32 and 5.33). We note that this implies minimality amongst automata admitting a locally bijective morphism to A. Moreover, the acceptance condition of ACDparity(A) uses an optimal number of colours (Theorem 5.31). The optimality of these constructions is shown in Section 5.4. We are able to prove the optimality of both constructions at the same time, by reducing the problem to an application of the minimality of the ZT-parity-automaton and the ZT-HD-Rabin-automaton.\nIn all this section, we let TS = (GTS ,AccTS) be a Muller transition system with underlying graph GTS = (V,E,Source,Target, I) and using a Muller acceptance condition AccTS = (\u03b3,\u0393,Muller\u0393(F))."
        },
        {
            "heading": "5.1 The alternating cycle decomposition",
            "text": "I Definition 5.1. Let `0 \u2208 Cycles(TS) be a cycle. We define the tree of alternating subcycles of `0, denoted AltTree(`0) = (N, , \u03bd : N \u2192 Cycles(TS)) as a Cycles(TS)-labelled tree with nodes partitioned into round nodes and square nodes, N = N\u00a9 tN , such that:\nThe root is labelled `0. If a node is labelled ` \u2208 Cycles(TS), and ` is an accepting cycle (\u03b3(`) \u2208 F), then it is a round node, and its children are labelled exactly with the maximal subcycles `\u2032 \u2286 ` such that `\u2032 is rejecting (\u03b3(`\u2032) /\u2208 F).\n50\nIf a node is labelled ` \u2208 Cycles(TS), and ` is a rejecting cycle (\u03b3(`) /\u2208 F), then it is a square node, and its children are labelled exactly with the maximal subcycles `\u2032 \u2286 ` such that `\u2032 is accepting (\u03b3(`\u2032) \u2208 F). y\nFor a Cycles(TS)-labelled tree T = (N, , \u03bd : N \u2192 Cycles(TS)) and n \u2208 N , we let \u03bdStates(n) = States(\u03bd(n)) be the set of states of the cycle labelling n. I Remark 5.2. Let n be a node of AltTree(`0) and let n1 be a child of it. If `\u2032 is a cycle such that \u03bd(n1) ( `\u2032 \u2286 \u03bd(n), then \u03bd(n1) is accepting \u21d0\u21d2 `\u2032 is rejecting \u21d0\u21d2 \u03bd(n) is rejecting. y\nI Definition 5.3 (Alternating cycle decomposition). Let TS be a transition system, and let `1, `2, . . . , `k be an enumeration of its maximal cycles (that is, the edges sets of its SCCs). We define the alternating cycle decomposition of TS to be the forest ACDTS = {AltTree(`1), . . . ,AltTree(`k)}.\nWe let N`i be the set of nodes of AltTree(`i), and n`i its root. We will suppose that N`i \u2229N`j = \u2205 if i 6= j. y\nWe define the set of nodes of ACDTS to be Nodes(ACDTS) = \u22c3k i=1N`i , and we let Nodes\u00a9(ACDTS) (resp. Nodes (ACDTS)) be the subset of round (resp. square) nodes. As for Zielonka trees, we equip the trees of ACDTS with an arbitrary order making them ordered trees. From now on, we will suppose that all trees of alternating subcycles are ordered, without explicitly mentioning it.\nWe remark that for a recurrent vertex v of TS, there is one and only one tree AltTree(`i) in ACDTS such that v \u2208 \u03bdStates(n`i). On the other hand, transient vertices do not appear in the trees of ACDTS .\nIf v is a recurrent vertex of TS, we define the local subtree at v, noted Tv, as the subtree of AltTree(`i) containing the nodes Nv = {n \u2208 N`i | v \u2208 \u03bdStates(n)}. If v is a transient vertex, we define Tv to be a tree with a single node.\nFor v recurrent, as Nv is a subset of the nodes of AltTree(`i), the tree Tv inherits the order from AltTree(`i), as well as its partition into round and square nodes, Nv = Nv,\u00a9 tNv, . Also, it inherits the labelling given by the mapping \u03bd, whose restriction to Tv has an image in Cycles\nv (TS).\nI Remark 5.4. Let v \u2208 \u03bdStates(n`i). If n \u2208 Nv and n\u2032 is an ancestor of n in AltTree(`i), then n\u2032 \u2208 Nv. In particular, Tv is indeed a subtree of AltTree(`i). Also, we note that the root of Tv is n`i . y\nFor a node n \u2208 N`i and an edge e \u2208 `i we define Supp(n, e) = n\u2032 to be the deepest ancestor of n such that e \u2208 \u03bd(n\u2032). We remark that if e = v \u2212\u2192 v\u2032, then Supp(n, e) is a node in both Tv and Tv\u2032 .\nI Example 5.5. We will use the transition system TS from Figure 14 as a running example. We have named the edges of TS with letters from a to l, that are also used as the output colours of the acceptance condition. The acceptance set of TS is the Muller language associated to:\nF = {{c, d, e}, {e}, {g, h, i}, {l}, {h, i, j, k}, {j, k}}.\nThe initial vertex of TS, v0, is its only transient vertex, all the others vertices are recurrent. TS has 2 strongly connected components, corresponding to cycles `1 and `2.\nThe alternating cycle decomposition of TS is shown in Figure 15. It consists of two trees, AltTree(`1) and AltTree(`2). We use Greek letters (in pink) to name the nodes of the tree. Inside each node we indicate both its label \u03bd(n) and the set of states of it. For example,\nA. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 51\n\u03bd(\u03ba) = {g, h, i} and \u03bdStates(\u03ba) = {v3, v4}. We have that Supp(\u03c4, g) = \u03ba and Supp(\u03c4, j) = \u03bb. We highlight in bold orange the local subtree at v4, Tv4 . The tree Tv0 , consisting in a single node, does not appear in the figure. The numbering on the right of the trees will be used in next section. y\nI Remark 5.6. Let TS be a Muller TS using as acceptance setW = Muller\u0393(F), and let TS be the TS obtained by replacing W with W = \u0393\u03c9 \\W (which is a Muller language). Then, the ACD of TS coincides with that of TS, with the only difference that the partition into round and square nodes is inverted: Nodes\u00a9(ACDTS) = Nodes (ACDTS) and Nodes (ACDTS) = Nodes\u00a9(ACDTS).\nWe note that if A is a DMA recognising L \u2286 \u03a3\u03c9, the automaton A is a DMA recognising \u03a3\u03c9 \\ L.\nI Remark 5.7. The Zielonka tree can be seen as a special case of the alternating cycle decomposition. Indeed, a Muller language Muller(F)\u03a3 can be trivially recognised by a DMA A with a single state q and self-loops q a:a\u2212\u2212\u2192 q. The ACD of this automaton is exactly the Zielonka tree of F .\n52\nLocal Muller languages. For a recurrent state v of TS, we define the local Muller language of TS at v as the Muller language defined over the alphabet \u0393v = Cyclesv(TS) associated to:\nLocalMullerTS(v) = {C \u2286 Cyclesv(TS) | \u22c3 `\u2208C ` is an accepting cycle}.\nWe note that LocalMullerTS(v) is completely determined by singletons (C \u2208 LocalMullerTS(v) if and only if { \u22c3 `\u2208C `} \u2208 LocalMullerTS(v)). For simplicity, and by a slight abuse of notation, we will work as if LocalMullerTS(v) \u2286 Cyclesv(TS). To lighten notations, we will just write LocalMullerTS(v) to denote Muller(LocalMullerTS(v)) whenever no confusion arises.\nThe following lemma directly follows from the definition of Tv and that of Zielonka tree. It provides insight in the structure of the trees Tv, and it will be a key ingredient in the proof of the optimality of the transformations based on the alternating cycle decomposition.\nI Lemma 5.8. Let v be a recurrent vertex. The tree Tv is the Zielonka tree of the family LocalMullerTS(v)9."
        },
        {
            "heading": "5.2 An optimal transformation to parity transition systems",
            "text": "We now define the ACD-parity-transform, an optimal transformation turning a Muller TS into a parity TS while preserving determinism. In order to obtain the optimality in the number of output colours, we need to pay attention to the parity of the minimal colour used in different SCCs. To incorporate this parameter in the transformation, we define positive and negative ACDs.\nLet TS be a Muller transition system and let ACDTS = {AltTree(`1), . . . ,AltTree(`k)} be its alternating cycle decomposition.\nWe say that a tree AltTree(`i) \u2208 ACDTS is positive if `i is an accepting cycle, and that it is negative otherwise. We say that the alternating cycle decomposition of TS is positive if all the trees of maximal height of ACDTS are positive, that it is negative if all trees of maximal height are negative, and that it is equidistant if there are positive and negative trees of maximal height.\nAs for the Zielonka tree, we associate a non-negative integer to each level of the trees of ACDTS via a function pACD(n) : Nodes(ACDTS)\u2192 N. Let `i be a maximal cycle of TS and n \u2208 N`i .\nIf ACDTS is positive or equidistant: pACD(n) = Depth(n), if `i is accepting, pACD(n) = Depth(n) + 1, if `i is rejecting.\nIf ACDTS is negative: pACD(n) = Depth(n) + 2, if `i is accepting, pACD(n) = Depth(n) + 1, if `i is rejecting.\nWe let minTS (resp. maxTS) be the minimum (resp. maximum) value taken by the function pACD.\n9 Formally, the labelling \u03bd of Tv goes to Cyclesv(TS), and not to 2 Cycles v (TS)\n+ , as required by the definition of the Zielonka tree. To obtain a proper Zielonka tree with a labelling of nodes \u03bd\u2032 : Nv \u2192 2 Cycles v (TS) + , we would have to define \u03bd\u2032(n) = {`\u2032 \u2208 Cycles v (TS) | `\u2032 \u2286 \u03bd(n)}."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 53",
            "text": "I Remark 5.9. A node n in AltTree(`i) verifies that pACD(n) is even if and only if \u03bd(n) is an accepting cycle (that is, if n is a round node). I Remark 5.10. It is satisfied:\nminTS = 0 if ACDTS is positive or equidistant, minTS = 1 if ACDTS is negative.\nI Example 5.11. In the previous Example 5.5, AltTree(`1) is a positive tree and AltTree(`2) is negative. As AltTree(`2) is the tree of maximal height, ACDTS is negative. The function pACD is represented in Figure 15 by the integers on the right of each tree. It takes values 2 and 3 over AltTree(`1) (pACD(\u03b1) = 2 and pACD(\u03b2) = 3), because ACDTS is negative. In this example, minTS = 1 and maxTS = 3. We note that if we had associated integers 0 and 1 to the levels of AltTree(`1), we would have used 4 integers in total, instead of just 3 of them. y\nI Definition 5.12 (ACD-parity-transform). Let TS be a Muller TS with ACDTS = {AltTree(`1), . . . ,AltTree(`k)}. We define the ACD-parity-transform of TS be the parity TS ACDparity(TS) = (G\u2032,Acc\u2032), with G\u2032 = (V \u2032, E\u2032,Source\u2032,Target\u2032, I \u2032), and Acc\u2032 = (\u03b3\u2032, [minTS ,maxTS ], parity) defined as follows.\nVertices. The set of vertices is V \u2032 = \u22c3 v\u2208V ({v} \u00d7 Leaves(Tv)) .\nInitial vertices. I \u2032 = {(v0, n) | v0 \u2208 I and n is the leftmost leaf in Tv0}.\nEdges and output colours. For each (v, n) \u2208 V \u2032 and each edge e = v \u2212\u2192 v\u2032 \u2208 Out(v) in TS we define an edge en = (v, n) \u03b3\u2032(en)\u2212\u2212\u2212\u2212\u2192 (v\u2032, n\u2032). Formally,\nE\u2032 = \u22c3 e\u2208E ( {e} \u00d7 Leaves(TSource(e)) ) .\nIf v and v\u2032 are not in the same SCC, we let n\u2032 be the leftmost leaf in Tv\u2032 and \u03b3\u2032(en) = minTS10. If v and v\u2032 belong to the same SCC, we let: n\u2032 = JumpTv\u2032 (n, Supp(n, e)), \u03b3\u2032(en) = pACD(Supp(n, e)).\nLabellings. If TS is a labelled transition system, with labels lV : V \u2192 LV and lE : E \u2192 LE, we label ACDparity(TS) by l\u2032V \u2032(v, n) = lV (v) and l\u2032E\u2032(en) = lE(e). y\nIntuitively, a run in the transition system ACDparity(TS) follows a run in TS with some extra information, updated in the same manner as it was the case with the ZT-parity-automaton. To define transitions in ACDparity(TS), we move simultaneously in TS and in ACDTS . When we take a transition e in TS that goes from v to v\u2032 , while being in a node n in the ACD , we climb the branch of n searching the lowest node n\u0303 with e and v\u2032 in its label (n\u0303 = Supp(n, e)). We produce as output the colour corresponding to the level reached. If no such node exists in the current tree (this occurs if we change of SCC), we jump to the root of the tree containing v\u2032. After having reached the node n\u0303, we move to its next child in the tree Tv\u2032 (in a cyclic way), and we pick the leftmost leaf under it.\n10The colours associated to transitions changing of SCC are almost arbitrary (we could even leave them uncoloured). We define them to be the minimal colour used so that the obtained transition system is normalised in the sense of Section 6.2.\n54\nI Example 5.13. We show in Figure 16 the ACD-parity-transform ACDparity(TS) of the transition system TS from Figure 14 (Example 5.5). For each vertex v in TS, we make as many copies as leaves of the tree Tv. We note that, as v0 is transient, the tree Tv0 consists of a single node (by definition), that we name \u03b9. Transitions are of the form (e, l), for e a transition from TS and l a leaf of some local subtree; these are denoted el in the figure for the sake of space convenience. These labels simply indicate the names of the edges, they should not be interpreted as input letters (ACDparity(TS) is not an automaton).\nWe observe that there is a locally bijective morphism of transition systems \u03d5 from ACDparity(TS) to TS given by \u03d5V (v, l) = v and \u03d5E(el) = e.\nAnother example can be found in Figure 17. y\nI Remark 5.14. The size of the ACD-parity-transformation of TS is:\n|ACDparity(TS)| = \u2211 v\u2208V |Leaves(Tv)| = \u2211 v\u2208Vrec |Leaves(Tv)|+ |Vtrans|,\nwhere Vrec and Vtrans are the sets of recurrent and transient vertices of TS, respectively. y\nI Remark 5.15. We remark that if TS = (GTS ,AccTS) is already a parity TS, then the underlying graphs of ACDparity(TS) and TS are isomorphic. In fact, by Proposition 5.18, ACDparity(TS) and TS will also be isomorphic as transition systems. In this case, the construction of ACDparity(TS) boils down to the application of the procedure described by Carton and Maceiras [15]. y\nI Remark 5.16. The ACD-parity-transform is oblivious to the labelling \u03b3 of the acceptance condition of TS; the only information taken into account to define the graph of ACDparity(TS) and its output colours is the structure of the trees of ACDTS . That is, the definition of this transformation is independent of the actual representation of the acceptance condition of TS (whether it is Emerson-Lei, Muller, Rabin...), and we only use that any such representation induces a mapping f : Cycles(TS)\u2192 {Accept,Reject}. y\nI Remark 5.17. The ZT-parity-automaton can be seen as a special case of the ACD-paritytransform, as AparityZF coincides with the DPA ACDparity(A), where A is the DMA with a single state recognising Muller(F) (see Remark 5.7). y"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 55",
            "text": "Correctness of the ACD-parity-transform\nI Proposition 5.18 (Correctness of the ACD-parity-transform). Let TS be a (labelled) Muller TS and let ACDparity(TS) be its ACD-parity-transform. There is a locally bijective morphism of (labelled) transition systems \u03d5 : ACDparity(TS)\u2192 TS.\nThe following lemma, analogous to Lemma 4.11 from Section 4.2, follows from the definition of the ACD-parity-transform.\nI Lemma 5.19. Let n be a node of AltTree(`i), let n\u0303 be an ancestor of n and let e = v \u2212\u2192 v\u2032 be an edge in `i. Then, Supp(n, e) is a descendant of n\u0303 if and only if e \u2208 \u03bd(n\u0303), and in this case, if en = (v, n) \u2212\u2192 (v\u2032, n\u2032) is an edge of ACDparity(TS), then n\u2032 is a descendant of n\u0303 too.\nProof of Proposition 5.18. We consider the mapping \u03d5 = (\u03d5V , \u03d5E) naturally defined by \u03d5V (v, n) = v and \u03d5E(en) = e. It is immediate to check that \u03d5 is a weak morphism of transition systems (it preserves initial states and transitions). Also, it is easy to see that it is locally bijective: for each initial state v0 \u2208 I, there is exactly one node in I \u2032 of the form (v0, n): the node where n is the leftmost leaf of Tv; and for each vertex (v, n) and edge e \u2208 Out(v) of TS, we have define exactly one edge outgoing from (v, n) corresponding to e.\nWe prove that \u03d5 preserves the acceptance of runs, following the proof scheme from Proposition 4.10. We can suppose w.l.o.g. (see Remarks 2.1 and 5.16) that the set of output colours used by TS is its set of edges E. Let \u03c1 \u2208 Run(ACDparity(TS)) be an infinite run in ACDparity(TS). Eventually, \u03c1 will remain in one SCC, and Inf(\u03c1) will form a cycle that is accepting if and only if \u03c1 is an accepting run. We will suppose that all the edges in \u03c1 appear infinitely often and belong to this cycle (we can do it by using a similar argument as the one presented in the proof of Proposition 4.10), and we let:\n\u03c1 = (v0, n0) x0\u2212\u2192 (v1, n1) x1\u2212\u2192 (v2, n2) x3\u2212\u2192 . . . .\nThe projection of \u03c1 under \u03d5 is:\n\u03d5Runs (\u03c1) = v0 e0\u2212\u2192 v1 e1\u2212\u2192 v2 e3\u2212\u2192 . . . .\nWe note that the edges {e0, e1, . . . } form a cycle in TS, that we will call `\u03c1. In particular, `\u03c1 is contained in some maximal cycle `max, and all the nodes ni belong to the same tree AltTree(`max) of the ACD. Our objective is to show that `\u03c1 is an accepting cycle in TS if and only if min{x0, x1, x2, . . . } is even. We let n\u0303i = Supp(ni, ei) be the node of ACDTS determining the ith transition of \u03c1, so we have that xi = pACD(n\u0303i). Finally, let n\u03c1 be the deepest ancestor of n0 such that `\u03c1 \u2286 \u03bd(n\u03c1).\nB Claim 5.18.1. For all i \u2265 0, ni n\u03c1 and n\u0303i n\u03c1 (that is, all nodes appearing in \u03c1 are below n\u03c1). In particular, xi \u2265 pACD(n\u03c1).\nProof. The claim follows from Lemma 5.19 and induction. C\nB Claim 5.18.2. Let n\u03c1,1, . . . , n\u03c1,s be an enumeration of ChildrenAltTree(`max)(n\u03c1). It is verified that:\n1. Supp(ni, ei) = n\u03c1 infinitely often. In particular, xi = pACD(n\u03c1) for infinitely many i\u2019s. 2. There is no n\u03c1,k \u2208 Children(n\u03c1) such that `\u03c1 \u2286 \u03bd(n\u03c1,k).\nProof. The proof is identical to that of Claim 4.10.2, from Proposition 4.10. C\nWe conclude that min{x0, x1, x2, . . . } = pACD(n\u03c1), which is even if and only if `\u03c1 is an accepting cycle, by Remarks 5.2 and 5.9. J\n56\nI Remark 5.20. We can give an alternative interpretation of the previous proof. Given a run \u03c1 in TS and a vertex v appearing infinitely often in \u03c1, we can decompose the run into:\n\u03c10 v \u03c11 v \u03c12 v \u03c13 v \u03c14 . . . ,\nwhere the finite runs \u03c1i are cycles over v, for i > 0. Therefore, the sequence of these cycles can be processed by the ZT-parity-automaton corresponding to the local Muller condition LocalMullerTS(v). By Lemma 5.8 and the correctness of the ZT-parity-automaton, the minimal colour produced by a run over this sequence of cycles in AparityZLocalMullerTS (v) coincides with the minimal output colour produced by the run \u03d5\u22121Runs (\u03c1) in the ACD-parity-transform ACDparity(TS) (disregarding the initial path \u03c10). This colour is exactly the one corresponding to the deepest node in Tv above the leftmost leaf containing Inf(\u03c1). y\nThe locally bijective morphism given by Proposition 5.18 witnesses that ACDparity(TS) shares the same semantic properties as TS. The next corollaries follow from Proposition 3.16 and Corollary 3.19 (and the fact that the choice of initial vertices in ACDparity(TS) is arbitrary).\nI Corollary 5.21. Let A be a Muller automaton and let ACDparity(A) be its ACD-paritytransform. Then, L(A) = L(ACDparity(A)), and A is deterministic (resp. history-deterministic) if and only if ACDparity(A) is deterministic (resp. history-deterministic).\nI Corollary 5.22. Let G be a Muller game and let ACDparity(G) be its ACD-parity-transform. Eve wins ACDparity(G) from a vertex of the form (v, n) if and only if she wins G from v."
        },
        {
            "heading": "5.3 An optimal history-deterministic transformation to Rabin transition systems",
            "text": "In this section we describe the ACD-HD-Rabin-transform, an optimal transformation of Muller TS to Rabin TS preserving history-determinism. This construction generalises that from Section 4.3.\nI Definition 5.23 (ACD-HD-Rabin-transform). Let TS be a Muller TS. For each vertex v \u2208 V we let \u03b7v : Leaves(Tv)\u2192 {1, . . . , rbw(Tv)} be a mapping satisfying Property (?) from Lemma 4.39.\nWe define the ACD-HD-Rabin-transform of TS to be Rabin TS ACDRabin(TS) = (G\u2032,Acc\u2032), with G\u2032 = (V \u2032, E\u2032,Source\u2032,Target\u2032, I \u2032), and Acc\u2032 = (\u03b3\u2032,Nodes(ACDTS),Rabin(R)) defined as follows.\nVertices. The set of vertices is V \u2032 = \u22c3 v\u2208V ({v} \u00d7 {1, . . . , rbw(Tv)}) ,\nwhere rbw(Tv) is the round-branching width of Tv.\nInitial vertices. I \u2032 = {(v0, x) | v0 \u2208 I and x \u2208 {1, . . . , rbw(Tv0)}}.\nEdges and output colours. We let E\u2032 = \u22c3 e\u2208E ( {e} \u00d7 Leaves(TSource(e)) ) .\nFor each edge e = v \u2212\u2192 v\u2032 \u2208 E in TS and x \u2208 {1, . . . , rbw(Tv)}, we will place one edge from (v, x) for each leaf l of Tv such that \u03b7v(l) = x. More precisely, we let (v, x)\nn\u2212\u2192 (v\u2032, x\u2032) \u2208 E\u2032 if either"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 57",
            "text": "v and v\u2032 are not in the same SCC (in this case the output colour n is irrelevant), or v and v\u2032 are in the same SCC and there are leaves l and l\u2032 of Tv and Tv\u2032 , respectively, such that: \u03b7v(l) = x, \u03b7v\u2032(l\u2032) = x\u2032, l\u2032 = JumpTv\u2032 (l,Supp(l, e)), n = Supp(l, e).\nRabin condition. R = {(Gn, Rn)}n\u2208Nodes\u00a9(ACDTS), where Gn and Rn are defined as follow: Let n be a round node, and let n\u2032 be any node in Nodes(ACDTS),{\nn\u2032 \u2208 Gn if n\u2032 = n, n\u2032 \u2208 Rn if n\u2032 6= n and n is not an ancestor of n\u2032.\nLabellings. If TS is a labelled transition system, with labels lV : V \u2192 LV and lE : E \u2192 LE, we label ACDRabin(TS) by l\u2032V \u2032(v, x) = lV (v) and l\u2032E\u2032(e\u2032) = lE(e), if e\u2032 \u2208 E\u2032(e). y\nThis construction generalises the ZT-HD-Rabin-automaton in the same way as the ACDparity-transform generalises the ZT-parity-automaton. Intuitively, a run in ACDRabin(TS) can be identified with a promenade through the nodes of the ACD, which are used as the output colours to define the Rabin acceptance condition. I Remark 5.24. The size of the ACD-HD-Rabin-transform of TS is:\n|ACDRabin(TS)| = \u2211 v\u2208V rbw(Tv) = \u2211 v\u2208Vrec rbw(Tv) + |Vtrans|,\nwhere Vrec and Vtrans are the sets of recurrent and transient vertices of TS, respectively.\nCorrectness of the ACD-HD-Rabin-transform\nTo obtain the correctness of the ACD-HD-Rabin-transform, we follow the same steps as in the proof of the correctness of the ZT-HD-Rabin-automaton (Proposition 4.45).\nI Proposition 5.25 (Correctness of the ACD-HD-Rabin-transform). Let TS be a (labelled) Muller TS and let ACDRabin(TS) be its ACD-HD-Rabin-transform. There is an HD mapping of (labelled) transition systems \u03d5 : ACDRabin(TS)\u2192 TS.\nThe proof of next two lemmas are completely analogous to those of Lemmas 4.46 and 4.47.\nI Lemma 5.26. Let u = n0n1n2 \u00b7 \u00b7 \u00b7 \u2208 Nodes(ACDTS)\u03c9 be an infinite sequence of nodes of the ACD of TS. The word u belongs to Rabin(R), for R = {(Gn, Rn)}n\u2208Nodes\u00a9(ACDTS) the Rabin condition of ACDRabin(TS), if and only if there is a unique minimal node for the ancestor relation in Inf(u) and this minimal node is round.\nI Lemma 5.27. There exists a morphism of transition systems \u03d5 : ACDparity(TS)\u2192 ACDRabin(TS).\nUsing these lemmas we can prove Proposition 5.25.\nProof of Proposition 5.25. We define the mapping \u03d5 : ACDRabin(TS) \u2192 TS in the natural way: \u03d5V (v, x) = v and \u03d5E(e, l) = e. It is immediate to check that \u03d5 is a weak morphism. The fact that \u03d5 preserves accepting runs can be proven analogously to the fact that L(ARabinZF ) \u2286 Muller\u03a3(F) in Proposition 4.45 (by using Lemma 5.26).\nDefinition of a sound resolver for \u03d5: In order to show how to simulate runs of TS in ACDRabin(TS), we use the fact that we can see ACDRabin(TS) as a quotient of ACDparity(TS)\n58\n(Lemma 5.27). Let \u03d5\u0303 : ACDparity(TS) \u2192 TS be the locally bijective morphism given by Proposition 5.18, and let \u03d5\u0302 : ACDparity(TS) \u2192 ACDRabin(TS) be the morphism given by Lemma 5.27. Since \u03d5\u0303 is locally bijective, \u03d5\u0303Runs is a bijection between the runs of the transitions systems ACDparity(TS) and TS, admitting an inverse \u03d5\u0303\u22121Runs . Composing this mapping with \u03d5\u0302, we obtain a way to simulate the runs from TS in ACDRabin(TS):\n\u03d5\u0302Runs \u25e6 \u03d5\u0303\u22121Runs : Run\u221e(TS)\u2192 Run\u221e(ACDRabin(TS)).\nThis composition of mappings provides a sound resolver simulating \u03d5. Formally, let (rInit, r) be the resolver defined as follows. The choice of initial vertices rInit : I \u2192 I \u2032 is given by rInit(v0, x) = v0. The function r : E\u2032\u2217 \u00d7 E \u2192 E\u2032 associates to a finite run \u03c1 \u2208 E\u2032\u2217 and e \u2208 E the last edge of the run \u03d5\u0302(\u03d5\u0303\u22121(\u03d5(\u03c1)e)) (subscripts have been omitted for legibility). It is easy to check that (rInit, r) indeed defines a resolver simulating \u03d5. Its soundness follows from the fact that \u03d5\u0303 and \u03d5\u0302 preserve the acceptance of runs. J\nFrom Proposition 3.16 we obtain: I Corollary 5.28. Let A be a Muller automaton and let ACDRabin(A) be its ACD-HD-Rabintransform. Then, L(A) = L(ACDRabin(A)), and A is history-deterministic if and only if ACDRabin(A) is history-deterministic.\nACD-HD-Rabin-transform-for-games\nIn Section 2.1, we discussed some technical difficulties appearing when we wanted to define the composition of a game G and an HD automaton: as the output of such operation, we would like to obtain a game in which Eve always chooses the transitions taken in the automaton, even if it is Adam who makes a move in the game, which is not the case if G is an arbitrary game. Also, in Section 3.3 we had to introduce HD-for-games mappings in order to formalise correct transformations of games. A similar difficulty appears in the context of the ACD-HD-Rabin-transform; we can see the ACD-HD-Rabin-transform of a game G as a game in which, at each moment, first, a move takes place in G, and then a choice is made to update the current node in ACDG . With the current definition of ACDRabin(G), it is the player who makes the move in the game component who chooses how to update the node in ACDG . This is potentially a problem, as in order to obtain an equivalent game we would like that Eve had full control to decide how to update the nodes in ACDG , even when it was Adam who moved in the game component (we note that in Proposition 5.25 we did not claim that there is an HD-for-games mapping \u03d5 : ACDRabin(TS)\u2192 TS). In order to obtain a transformation working for games, we need to slightly modify the definition of the ACD-HD-Rabin-transform.\nFor a Muller game G suitable for transformations, we define its ACD-HD-Rabin-transformfor-games, written ACDgameparity(G). The idea is simply to take from Adam the power to update the ACDG-component of vertices. The update of this information is delayed of one transition, so it is Eve who makes the choice of how to move in the ACD. To do this, we need to introduce some additional vertices controlled by Eve. The formal details of this construction and the proof of correctness can be found in Appendix B. I Proposition 5.29 (Correctness of the ACD-HD-Rabin-transform-for-games). Let G be a Muller game suitable for transformations, and let ACDgameparity(G) be its ACD-HD-Rabin-transform-forgames. There is an HD-for-games mapping \u03d5 : ACDgameparity(G)\u2192 TS. I Corollary 5.30. Let G be a Muller game suitable for transformations, and let ACDgameparity(G) be its ACD-HD-Rabin-transform-for-games. Then, Eve\u2019s full winning region in G is the projection of her full winning region in ACDgameparity(G)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 59",
            "text": ""
        },
        {
            "heading": "5.4 Optimality of the ACD-transforms",
            "text": "We now state and prove the optimality of both the ACD-parity-transform (Theorems 5.31 and 5.32) and the ACD-HD-Rabin-transform (Theorem 5.33). The proofs of these results will use the optimality of the automata based on the Zielonka tree (c.f. Section 4) as a black-box, which will allow us to prove the optimality of both transformations at the same time. The key idea is that if \u03d5 : TS \u2192 TS \u2032 is an HD mapping, we can see TS as an HD automaton recognising the accepting runs of TS \u2032. We can then use local Muller conditions at vertices of TS \u2032 to reduce the problem to automata recognising Muller languages."
        },
        {
            "heading": "5.4.1 Statements of the optimality results",
            "text": "We state the optimality of the transformations based on the ACD. All the results below apply to labelled transition systems too. For technical reasons, we need to suppose that all the states of transition systems under consideration are accessible, hypothesis that can always be made without loss of generality. We recall that HD mappings are in particular locally bijective morphisms and HD-for-games mappings (c.f. Figure 6).\nI Theorem 5.31. Let TS be a Muller TS whose states are accessible and let T\u0303S be a parity TS. If T\u0303S admits an HD mapping \u03d5 : T\u0303S \u2192 TS, then, its acceptance condition uses at least as many colours as that of ACDparity(TS).\nI Theorem 5.32. Let TS be a Muller TS whose states are accessible and let T\u0303S be a parity TS. If T\u0303S admits an HD mapping \u03d5 : T\u0303S \u2192 TS, then, |ACDparity(TS)| \u2264 |T\u0303S|.\nI Theorem 5.33. Let TS be a Muller TS whose states are accessible and let T\u0303S be a Rabin TS. If T\u0303S admits an HD mapping \u03d5 : T\u0303S \u2192 TS, then, |ACDRabin(TS)| \u2264 |T\u0303S|.\nWe obtain an analogous optimality result for the ACD-HD-Rabin-transform-for-games. In this case, the bound is not tight due to the additional vertices that are added to ACDgameparity(G) (see Appendix B for details).\nI Corollary 5.34. Let G be a Muller game suitable for transformations whose states are accessible and let G\u0303 be a Rabin game. If G\u0303 admits an HD-for-games mapping \u03d5 : G\u0303 \u2192 G, then, |ACDgameparity(G)| \u2264 2|G\u0303|."
        },
        {
            "heading": "5.4.2 Discussion",
            "text": "Before presenting the proofs of the optimality theorems, we discuss some consequences and limitations of our results.\nDifficulty of finding succinct history-deterministic automata. As mentioned in the introduction, several years had to pass after the introduction of history-deterministic automata [38] before finding HD automata that were actually smaller than equivalent deterministic ones [49]. As of today, we only know a handful of examples of \u03c9-regular languages admitting succinct HD automata [1, 49, 19], and their applicability in practice has yet to be fully determined. We assert that we can derive from our results some enlightening explanations on the difficulty of finding succinct HD parity automata, and set some limits in their usefulness in practical scenarios such as LTL synthesis.\nFirst, Corollary 4.14 already sets the impossibility of the existence of small HD parity automata recognising Muller languages. Corollary 5.36 states that if an HD parity automaton A has been obtained as a transformation of a DMA B, then A is not strictly smaller than a minimal deterministic parity automaton for L(A).\n60\nI Corollary 5.35. Let TS be a Muller TS. A minimal parity TS admitting an HD mapping to TS has the same size than a minimal parity TS admitting a locally bijective morphism to TS.\nI Corollary 5.36. Let A be a history-deterministic parity automaton. Suppose that there exists a DMA B such that A admits an HD mapping to B. Then, there exists a DPA A\u2032 recognising L(A) such that |A\u2032| \u2264 |A|.\nBoth corollaries follow from an immediate application of Theorem 5.32.\nThe ACD-transform does not preserve minimality. A natural question is whether the ACD-parity-transform preserves minimality of automata, that is, given a DMA A with a minimal number of states for the language it recognises, is ACDparity(A) minimal amongst DPAs recognising L(A)?11 The answer to this question is negative, as we show now.\nI Proposition 5.37. There exists a DMA A that is minimal amongst DMAs recognising L(A), but such that its ACD-parity-transform ACDparity(A) is not a minimal DPA.\nWe consider the alphabet \u03a3 = {a, b, c} and the language\nL = {w \u2208 \u03a3\u03c9 | c \u2208 Inf(w) and w contains infinitely often the factor ab}.\nA minimal DMA for L is depicted in Figure 17a. Its minimality follows simply from the fact that, as L is not a Muller language ((abc)\u03c9 \u2208 L but (bac)\u03c9 /\u2208 L, c.f. Remark 2.10), a DMA with just one state cannot recognise L. In Figure 17 we show its alternating cycle decomposition and its ACD-parity-transform, that has 4 states. However, we can find a DPA with just 3 states recognising L, as shown in Figure 17d.\n5.4.3 Optimality of the parity condition of ACDparity(TS) We show next the proof of Theorem 5.31. To prove this result, we would like to use the Flower Lemma 2.16, however, the statement of Theorem 5.31 does not involve \u03c9-regular languages. In order to set up a context in which apply the Flower Lemma, we show that, whenever we have a morphism \u03d5 : TS \u2192 TS \u2032, TS can be seen as an automaton reading the runs of TS \u2032.\nLet TS = (G,Acc) and TS \u2032 = (G\u2032,Acc\u2032) be transition systems with underlying graphs G = (V,E,Source,Target, I) and G\u2032 = (V \u2032, E\u2032,Source\u2032,Target\u2032, I \u2032), and acceptance conditions Acc = (\u03b3,\u0393,W) and Acc\u2032 = (\u03b3\u2032,\u0393\u2032,W\u2032). A weak morphism of transition systems \u03d5 : TS \u2192 TS \u2032 provides a labelling of the edges of TS by \u03d5E : E \u2192 E\u2032. Therefore, we can see TS as an automaton with input alphabet E\u2032, inheriting the underlying graph and acceptance condition from TS. We say that this is the automaton of morphism \u03d5 and denote it by A\u03d5.\nWe define the language of accepting runs of a transition system TS as:\nLRuns (TS) = {\u03c1 \u2208 E\u03c9 | \u03c1 is an accepting run in TS}.\nI Lemma 5.38. Let TS and TS \u2032 be transition systems with a single initial state, let \u03d5 : TS \u2192 TS \u2032 be a weak morphism of transition systems, and let A\u03d5 be its automaton. Then, \u03d5 is an HD mapping if and only if the automaton A\u03d5 is history-deterministic, and, in this case,\nL(A\u03d5) = LRuns (TS \u2032).\n11This question was left open as a conjecture in the conference version of this paper [18].\nA. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 61\nProof. We first note that a resolver for A\u03d5 (in the sense of HD automata) is a mapping of the form r : E\u2217\u00d7E\u2032 \u2192 E, as E\u2032 is the input alphabet of this automaton. A resolver simulating \u03d5 (in the sense of HD mappings) is a mapping of the same form. It is straightforward to check that (q0, r) is a sound resolver for A\u03d5 if and only if (rInit, r) is a sound resolver simulating \u03d5 (where rInit(q\u20320) = q0 is the only possible choice of initial vertex).\nWe prove that L(A\u03d5) = {\u03c1\u2032 \u2208 Run(TS \u2032) | \u03c1\u2032 is an accepting run}. First, we remark that if \u03c1 is a run in A\u03d5 over \u03c1\u2032 \u2208 Run(TS \u2032), then \u03c1\u2032 = \u03d5Runs (\u03c1), since the labelling of A\u03d5 by input letters is given exactly by \u03d5 itself. Therefore, if \u03c1\u2032 \u2208 L(A\u03d5), there exists an accepting run \u03c1 over \u03c1\u2032, and since \u03d5 preserves accepting runs, \u03c1\u2032 = \u03d5Runs(\u03c1) is accepting in TS \u2032, proving the inclusion from left to right. For the other inclusion, we let (rInit, r) be a sound resolver simulating \u03d5. If \u03c1\u2032 is an accepting run in TS \u2032, then rRuns(\u03c1\u2032) is an accepting run over \u03c1\u2032 in A\u03d5. J\nWe recall that [minTS ,maxTS ] are the colours used by the ACD-parity-transform of TS, which coincides with the maximal height of a tree in ACDTS . We also recall that minTS = 0 if ACDTS is positive or equidistant, and that minTS = 1 if ACDTS is negative.\nI Lemma 5.39. Let TS be a Muller TS, and let AltTree(`) \u2208 ACDTS be a positive (resp. negative) tree of the ACD of TS of height d. Then, TS admits a positive (resp. negative) d-flower.\nProof. We use the same argument than the one used in the proof of Theorem 4.12. Let n1 n2 . . . nd be a branch of length d of AltTree(`) (where n1 is the root and nd is a leaf of the tree). Let v \u2208 \u03bdStates(nd) be a vertex appearing in the leaf. Then, the\n62\nwhole branch is contained in Tv (by Remark 5.4), that is, \u03bd(ni) \u2208 CyclesTS(v). Moreover, \u03bd(n1) ) \u03bd(n2) ) . . . \u03bd(nd) is a chain that alternates accepting and rejecting cycles, so it is a d-flower that is positive if and only if \u03bd(n1) = ` is an accepting cycle, that is, if AltTree(`) is positive. J\nI Lemma 5.40. Let TS be a Muller TS with a single initial vertex and whose vertices are all accessible. Then, the parity index of LRuns (TS) is:\n[minTS ,maxTS ] if ACDTS is positive or negative, WeakmaxTS if ACDTS is equidistant.\nProof. We consider the identity morphism IdTS : TS \u2192 TS and its automaton AIdTS , which is a deterministic automaton trivially recognising LRuns (TS) (that is, we see TS as an automaton reading its own edges as input letters). The result follows from the Flower Lemma 2.16 and the fact that a tree AltTree(`) \u2208 ACDTS of height d provides a d-flower that is positive if ` is accepting and negative if ` is rejecting (Lemma 5.39). These flowers are accessible as we have supposed that all the vertices of TS are accessible. J\nThe previous lemmas allow us to obtain Theorem 5.31 for transition systems with a single initial vertex. We introduce some further notations to deal with the general case.\nFor a Muller TS TS and a vertex v, we letACD(TS,v) be the alternating cycle decomposition of the accessible part of TS from v. We note that the trees of ACD(TS,v) are a subset of the trees of ACDTS : a tree AltTree(`i) \u2208 ACDTS appears in ACD(TS,v) if and only if the cycle `i is accessible from v. Accordingly, for each vertex v of TS we let min(TS,v) (resp. max(TS,v)) be the minimum (resp. maximum) value taken by the function pACD when restricted to the trees of ACD(TS,v).\nI Remark 5.41. For every transition system TS, one of the two following statements holds:\nThere is some vertex v such that [minTS ,maxTS ] = [min(TS,v),max(TS,v)]. There are two vertices v0 and v1 such that min(TS,v0) = 0, max(TS,v0) = maxTS \u2212 1 and min(TS,v1) = 1, max(TS,v1) = maxTS .\nMoreover, if all the states of TS are accessible, we can choose v (resp. v0 and v1) to be an initial vertex. y\nWe can finally deduce Theorem 5.31 from the preceding lemmas.\nProof of Theorem 5.31. We suppose that we are in the first case of Remark 5.41 (a proof for the second case follows easily). First, we show that we can suppose that T\u0303S and TS have a single initial vertex. Let v be an initial vertex of TS such that [minTS ,maxTS ] = [min(TS,v),max(TS,v)]. Let \u03d5 : T\u0303S \u2192 TS be an HD mapping, and let (rInit, r) be a sound resolver simulating it. We let v\u0303 = rInit(v) be the initial vertex in T\u0303S chosen by the resolver. It suffices then to prove the result for the accessible part of T\u0303S from v\u0303, the transition system TSv, and the restriction of \u03d5 to these transition systems.\nFrom now on, we suppose that both T\u0303S and TS have a single initial vertex. By Lemma 5.40 and Proposition 2.15, a parity history-deterministic automaton recognising LRuns(TS) uses at least |[minTS ,maxTS ]| colours. By Lemma 5.38, the automaton A\u03d5 of the morphism \u03d5 is a parity history-deterministic automaton recognising LRuns(TS), and therefore uses at least |[minTS ,maxTS ]| colours. Since the acceptance condition of T\u0303S is exactly the same as that of A\u03d5, we can conclude. J"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 63",
            "text": "5.4.4 Optimality of the sizes of ACDparity(TS) and ACDRabin(TS) We prove now Theorems 5.32 and 5.33.\nSketch of the proof. Let \u03d5 : T\u0303S \u2192 TS be an HD mapping, and let v be a vertex in TS. We can see the set \u03d5\u22121(v) as the states of an HD automaton reading finite runs in TS looping around v. This allows to define an HD automaton having \u03d5\u22121(v) as set of states and recognising LocalMullerTS(v). As the Zielonka tree of LocalMullerTS(v) is the tree Tv, by optimality of the ZT-parity-automaton (resp. the ZT-HD-Rabin-automaton), we deduce that |\u03d5\u22121(v)| \u2265 |Leaves(Tv)| (resp. |\u03d5\u22121(v)| \u2265 rbw(Tv)). J\nI Definition 5.42. Let TS and TS \u2032 be two transition systems, and let (\u03b3,\u0393,Muller\u0393(F)) be the acceptance condition of TS. Let \u03d5 : TS \u2192 TS \u2032 be a weak morphism of transition systems that is locally surjective, and let v\u2032 be an accessible recurrent state of TS \u2032. For each `\u2032 \u2208 Cycles\nv\u2032 (TS \u2032) we let \u03c1`\u2032 be a finite path starting and ending in v\u2032 visiting exactly\nthe edges of `\u2032. We define the cycle-preimage-automaton at v\u2032 to be the Muller automaton A(\u03d5\u22121,v\u2032) = (Qv\u2032 , Cyclesv\u2032(TS \u2032), Qv\u2032 , 2\u0393+, \u03b4,Muller2\u0393+(F\u0303 )) over the input alphabet CyclesTS\u2032(v \u2032) defined as:\nthe set of states is Qv\u2032 = \u03d5\u22121(v\u2032), all the states are initial, the output colours are non-empty subsets of the colours used by TS, (q2, C) \u2208 \u03b4(q1, `\u2032) if there is a finite path \u03c1 \u2208 Pathfinq1 (TS) from q1 to q2 such that \u03d5(\u03c1) = \u03c1`\u2032 producing as output the colours in C \u2286 \u0393, that is \u03b3(\u03c1) = C. If C is empty, this corresponds to an uncoloured edge q1\n`\u2032:\u03b5\u2212\u2212\u2192 q2. We remark that, since \u03d5 is supposed locally surjective, there is at least one such path \u03c1. {C1, . . . , Ck} \u2208 F\u0303 if and only if \u222aki=1Ci \u2208 F . y\nWe remark that a transition e = q1 `\u2032:C\u2212\u2212\u2192 q2 in A(\u03d5\u22121,v\u2032) induces a finite path Unfold(e) = q1 C q2 in TS called the unfolding of e, producing as output the set of colours C and such that \u03d5(Unfold(e)) = `\u2032. In particular, a run \u03c1 in A(\u03d5\u22121,v\u2032) is accepting if and only if Unfold(\u03c1) is accepting.\nI Lemma 5.43. If L = Muller\u0393(F) is a parity (resp. Rabin) language, then, so is the language L\u0303 = Muller2\u0393+(F\u0303 ) used by the acceptance condition of A(\u03d5\u22121,v\u2032).\nProof. Suppose that L is a parity language, that is, there are dmin \u2264 dmax and \u03c6 : \u0393 \u2192 [dmin, dmax] such that for any non-empty subset C \u2286 \u0393, C \u2208 F if and only if min\u03c6(C) is even. We define \u03c6\u0303 : 2\u0393+ \u2192 [dmin, dmax] as: \u03c6\u0303(C) = min\u03c6(C). It is immediate to see that {C1, . . . , Ck} \u2208 F\u0303 if and only if min \u03c6\u0303({C1, . . . , Ck}) is even.\nSuppose now that L is a Rabin language represented by the Rabin pairs {(G1, R1), . . . , (Gr, Rr)}. We define a family of Rabin pairs R\u0303 = {(G\u03031, R\u03031), . . . , (G\u0303r, R\u0303r)} for L\u0303 as: {C1, . . . , Ck} \u2208 G\u0303i (resp. \u2208 R\u0303i) if \u222aki=1Ci \u2208 Gi (resp. \u2208 R\u0303i). It is immediate to see that L\u0303 = Rabin2\u0393+(R\u0303). J\nI Lemma 5.44. Let TS and TS \u2032 be two Muller TS, \u03d5 : TS \u2192 TS \u2032 a weak morphism of TS, and v\u2032 an accessible recurrent state of TS \u2032. If \u03d5 is an HD mapping, then the automaton A(\u03d5\u22121,v\u2032) is history-deterministic and recognises the local Muller condition of TS \u2032 at v\u2032.\nProof. L(A(\u03d5\u22121,v\u2032)) \u2286 LocalMullerv\u2032(TS): Let `\u20321`\u20322 \u00b7 \u00b7 \u00b7 \u2208 Cyclesv(TS) \u03c9 be a sequence of cycles accepted by A(\u03d5\u22121,v\u2032). By prefix-independence of Muller languages we can suppose that all\n64\nthe cycles `\u2032i appear infinitely often. Let \u03c1 = q0 `\u20321:C1\u2212\u2212\u2212\u2192 q1 `\u20322\u2212\u2192 q2 \u2212\u2192 . . . be an accepting run in A(\u03d5\u22121,v\u2032) over `\u20321`\u20322 . . . , and let Unfold(\u03c1) be its unfolding. As \u03c1 is an accepting run, so is Unfold(\u03c1), and since \u03d5 preserves accepting runs, \u03d5(Unfold(\u03c1)) is an accepting run in TS \u2032. The edges visited by \u03d5(Unfold(\u03c1)) form the cycle \u222ai\u22651`\u2032i, which is therefore an accepting cycle, so `\u20321`\u20322 \u00b7 \u00b7 \u00b7 \u2208 LocalMullerv\u2032(TS) by definition of local Muller condition.\nLocalMullerTS\u2032(v\u2032) \u2286 L(A(\u03d5\u22121,v\u2032)) and history-determinism: Let r\u03d5 : E\u2217\u00d7E\u2032 \u2192 E be a sound resolver simulating \u03d5. We will transfer the strategy given by r\u03d5 to define a resolver rA : \u2206\u2217 \u00d7 Cyclesv\u2032(TS\n\u2032)\u2192 \u2206 for A(\u03d5\u22121,v\u2032), where \u2206 is the set of transitions of the automaton. Let \u03c1\u20320 \u2208 Runfin(TS \u2032) be a finite run reaching v\u2032, and let \u03c10 = r\u03d5,Runs(\u03c1\u20320) the preimage given by the resolver, ending in some q0 \u2208 Qv\u2032 that is going to by used as initial state for A(\u03d5\u22121,v\u2032). For a sequence e1e2 . . . ek \u2208 \u2206\u2217 and `\u2032 \u2208 Cyclesv\u2032(TS \u2032), we let\nrA(e1e2 . . . ek, `\u2032) = r\u03d5(\u03c1\u20320\u03c1\u20321 . . . \u03c1\u2032k, \u03c1`\u2032)12,\nwhere \u03c1\u2032j = \u03d5(Unfold(ej)) and v\u2032 \u03c1`\u2032 v\u2032 is the finite run corresponding to `\u2032 fixed in the definition of A(\u03d5\u22121,v\u2032). By definition, the obtained resolver satisfies the following property:\nIf e1e2 \u00b7 \u00b7 \u00b7 \u2208 \u2206\u03c9 is the run induced by rA over `\u20321`\u20322 \u00b7 \u00b7 \u00b7 \u2208 Cyclesv\u2032(TS \u2032)\u03c9, then \u03c10Unfold(e1e2 . . . )) = r\u03d5,Runs (\u03c1\u20320\u03c1\u20321\u03c1\u20322 . . . ).\nThis gives us:\u22c3 Inf(`\u20321, `\u20322, . . . ) is accepting cycle in TS \u2032 \u21d0\u21d2 \u03c1\u20320\u03c1\u20321\u03c1\u20322 . . . is accepting run in TS \u2032 =\u21d2\n=\u21d2 \u03c10Unfold(e1e2 . . . ) accepting run in TS \u21d0\u21d2 e1e2 . . . accepting run in A(\u03d5\u22121,v\u2032).\nWhich allows us to conclude that the A(\u03d5\u22121,v\u2032) recognises LocalMullerv\u2032(TS) and that rA is a sound resolver. J\nI Corollary 5.45. Let TS and T\u0303S be a Muller and a parity transition system, respectively, and let \u03d5 : T\u0303S \u2192 TS be an HD mapping. Let v be an accessible recurrent state of TS. Then,\n|\u03d5\u22121(v)| \u2265 |Leaves(ZLocalMullerTS(v))| = |Leaves(Tv)|.\nProof. By Lemma 5.44, the automaton A(\u03d5\u22121,v) is a history-deterministic automaton recognising LocalMullerv(TS) of size |\u03d5\u22121(v)|, and by Lemma 5.43, it is a parity automaton. The optimality of the ZT-parity-automaton (Theorem 4.13) gives us the first inequality. The second equality follows from the fact that Tv is the Zielonka tree of LocalMullerTS(v) (Lemma 5.8). J\nThe next corollary admits an identical proof, using the optimality of the ZT-HD-Rabinautomaton (Theorem 4.48).\nI Corollary 5.46. Let TS and T\u0303S be a Muller and a Rabin transition system, respectively, and let \u03d5 : T\u0303S \u2192 TS be an HD mapping. Let v be an accessible recurrent state of TS. Then,\n|\u03d5\u22121(v)| \u2265 |rbw(ZLocalMullerTS(v))| = |rbw(Tv)|.\nTheorems 5.32 and 5.33 follow from these two corollaries, the formulas for the size of the ACD-transforms (Remarks 5.14 and 5.24) and the fact that a locally surjective morphism \u03d5 : T\u0303S \u2192 TS is surjective if all vertices of TS are accessible (Lemma 3.5).\n12Here we use a slight abuse of notation, since, formally, r\u03d5 takes as input elements in E\u2217\u00d7E\u2032, but \u03c1`\u2032 \u2208 E\u2032\u2217. We can naturally extend r\u03d5 to E\u2032\u2217 by induction. Equivalently, we can say that rA(e1e2 . . . ek, `\u2032) is a suffix of r\u03d5,Runs (\u03c1\u20320\u03c1\u20321 . . . \u03c1\u2032k\u03c1`\u2032)."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 65",
            "text": "6 Corollaries\nIn this section, we discuss some further applications of the Zielonka tree and the alternating cycle decomposition. In Section 6.1, we use the insights gained from the ACD to conduct a comprehensive study of typeness results for deterministic Muller automata (that is, when can we relabel a DMA with an equivalent and simpler acceptance condition). In Section 6.2 we present a normal form for parity transition systems and prove the main properties exhibited by TS in this form. In Section 6.3, we provide a polynomial-time algorithm minimising DPA recognising Muller languages."
        },
        {
            "heading": "6.1 Typeness results",
            "text": "As we have seen, there are many different types of acceptance conditions for \u03c9-regular automata. An important question is the following:\nQuestion: Given a Muller automaton A, can we define a simpler acceptance condition over the underlying graph of A obtaining an equivalent automaton A\u2032?\nThis question was first studied (in the context of automata using state-based acceptance) by Krishnan, Puri and Brayton [47, 48], who showed how to determine if a DMA can be relabelled with an equivalent B\u00fcchi condition. Their work was generalized to parity automata by Boker, Kupferman and Steinitz [9], and related questions about typeness were studied for non-deterministic automata by Kupferman, Morgenstern and Murano [51], and for history-deterministic automata by Boker, Kupferman and Skrzypczak [8].\nIn this section, we provide new general characterisations of typeness for Muller transition systems. The main contributions of this section appear in Propositions 6.9, 6.10 and 6.11, which characterise when a Muller TS can be relabelled with equivalent parity, Rabin, or Streett conditions in terms of properties of the cycles of the TS. For instance, Proposition 6.9 states that a Muller TS can be relabelled with an equivalent Rabin condition if and only if its rejecting cycles are closed under union. The \u201conly if\u201d part of this results was already known [56], but the fact that this is indeed a characterisation is a novel result, for which the use of the ACD is essential. These characterisations directly imply the results from [9, 47, 48]. We also show how to use the ACD to determine the parity index of the language recognised by a DMA (Proposition 6.13), which can be seen as a simplification of the results from [48, Section 3.2]. Further results concerning generalised B\u00fcchi languages and weak automata can be found in Appendix A."
        },
        {
            "heading": "6.1.1 Typeness for Muller languages",
            "text": "We first present some results proven by Zielonka [81, Section 5] that show how we can use the Zielonka tree to deduce if a Muller language is a Rabin, a Streett or a parity language. These results are generalised to transition systems in the next subsection. A study of further types of Muller languages can be found in Appendix A.\nWe do not include the proofs of the results of this section in the main body of the paper, as they are known results [81, Section 5] and they are special cases of the proofs in Section 6.1.2. Nevertheless, we include them in Appendix E.\nWe first introduce some definitions. The terminology will be justified by the upcoming results.\nI Definition 6.1. Let T be a tree T with nodes partitioned into round nodes and square nodes. We say that T has:\n66\nRabin shape if every round node has at most one child. Streett shape if every square node has at most one child. Parity shape if every node has at most one child.\nI Proposition 6.2. Let F \u2286 2\u0393+ be a family of non-empty subsets. The following conditions are equivalent:\n1. Muller\u0393(F) is a Rabin language. 2. 2\u0393+ \\ F is closed under union: If C1 /\u2208 F and C2 /\u2208 F , then C1 \u222a C2 /\u2208 F . 3. ZF has Rabin shape.\nI Proposition 6.3. Let F \u2286 2\u0393+ be a family of non-empty subsets. The following conditions are equivalent:\n1. Muller\u0393(F) is a Streett language. 2. The family F is closed under union. 3. ZF has Streett shape.\nI Proposition 6.4. Let F \u2286 2\u0393+ be a family of non-empty subsets. The following conditions are equivalent:\n1. Muller\u0393(F) is a parity language. 2. Both F and 2\u0393+ \\ F are closed under union: If C1 \u2208 F \u21d0\u21d2 C2 \u2208 F , then, C1 \u222a C2 \u2208 F \u21d0\u21d2 C1 \u2208 F . 3. ZF has parity shape.\nMoreover, if some of these conditions is satisfied, Muller\u0393(F) is a [minF ,maxF ]-parity language.\nI Corollary 6.5. A Muller language L \u2286 \u0393\u03c9 is a parity language if and only if it is both a Rabin and a Streett language."
        },
        {
            "heading": "6.1.2 Typeness for Muller transition systems and deterministic automata",
            "text": "We start this subsection by introducing the necessary definitions about equivalence of acceptance conditions and typeness. Then, we state and prove our main contributions concerning typeness of transition systems.\nEquivalence of acceptance conditions and typeness\nLet TS1 = (G,Acc1) and TS2 = (G,Acc2) be two transitions systems over the same underlying graph G, with acceptance conditions Acci = (\u03b3i,\u0393i,Wi), for i \u2208 {1, 2}. We say that Acc1 and Acc2 are equivalent over G, written Acc1 'G Acc2, if for all runs \u03c1 \u2208 Run(G), \u03c1 is accepting for TS1 if and only if it is accepting for TS2; that is, \u03b31(\u03c1) \u2208W1 \u21d0\u21d2 \u03b32(\u03c1) \u2208W2.\nWe write TS1 ' TS2 if TS1 and TS2 are isomorphic. We recall that two transition systems are isomorphic if there is a morphism of transition systems \u03d5 : TS1 \u2192 TS2 whose inverse is also a morphism, that is, \u03d5 and \u03d5\u22121 preserve the acceptance of runs. I Remark 6.6. If \u03d5 : TS1 \u2192 TS2 is an isomorphism, then (\u03b32 \u25e6 \u03d5,\u03932,W2) is an acceptance condition over the underlying graph of TS1 that is equivalent to (\u03b31,\u03931,W1) over this graph.\nConversely, if two acceptance conditions Acc1 and Acc2 are equivalent over a same graph G, then the identity function is an isomorphism between TS1 = (G,Acc1) and TS2 = (G,Acc2). y"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 67",
            "text": "For X one of types of languages defined in Section 2.2 (B\u00fcchi, parity, Muller, etc...), we say that a transition system TS is X type if there exists an isomorphic transition system TS \u2032 ' TS using an X acceptance condition. We note that, by the previous remark, in that case an X acceptance condition can be defined directly over the underlying graph of TS.\nWe remark that, given a pointed graph G (whose states are accessible), the equivalence classes of Muller acceptance conditions for the relation ' G are given exactly by the mappings f : Cycles(G)\u2192 {Accept,Reject}.\nThe ACD determines the type of transition systems\nI Definition 6.7. Let TS be a Muller transition system with a set of states V . We say that its alternating cycle decomposition ACDTS is a:\nRabin ACD if for every state v \u2208 V , the tree Tv has Rabin shape. Streett ACD if for every state v \u2208 V , the tree Tv has Streett shape. Parity ACD if for every state v \u2208 V , the tree Tv has parity shape. [0, d\u2212 1]-parity ACD (resp. [1, d]-parity ACD) if it is a parity ACD, trees of ACDTS have height at most d and trees of height d are positive (resp. negative).\nI Remark 6.8. ACDTS is a parity ACD if and only if it is both a Rabin and a Streett ACD.\nI Proposition 6.9. Let TS = (GTS ,AccTS) be a Muller transition system whose states are accessible. The following conditions are equivalent:\n1. TS is Rabin type. 2. For every pair of rejecting cycles `1, `2 \u2208 Cycles(TS) with some state in common, `1 \u222a `2\nis a rejecting cycle. 3. ACDTS is a Rabin ACD.\nProof. (1 \u21d2 2) Let AccR = (\u03b3,\u0393,Rabin(R) be the Rabin acceptance condition equivalent to AccTS , and let R = (G1, R1), . . . , (Gr, Rr) be its Rabin pairs. Let l1 and `2 be two cycles with a state in common, and suppose that `1 \u222a `2 is accepting; we show that either `1 or `2 is accepting. The cycle `1 \u222a `2 is accepted by some Rabin pair (Gj , Rj), so for all edges e \u2208 `1 \u222a `2, \u03b3(e) /\u2208 Rj , and there is some e0 \u2208 `1 \u222a `2 such that \u03b3(e0) \u2208 Gj . If e0 belongs to `1, then `1 is accepted by the Rabin pair (Gj , Rj), and if e0 \u2208 `2, then `2 is accepted by it. (2 \u21d2 3) Let v be a vertex of TS and Tv the local subtree at v. Suppose that there is a round node n \u2208 Tv with two different children n1 and n2. The cycles \u03bd(n1) and \u03bd(n2) are rejecting cycles over v, but their union is an accepting cycle (by Remark 5.2). (3 \u21d2 1) We observe that ACDTS is a Rabin ACD if and only if rbw(Tv) = 1 for all vertices v of TS. In particular, the ACD-HD-Rabin-transform of TS does not add any state to TS. It is immediate to check that the morphism \u03d5 : ACDRabin(TS)\u2192 TS given by \u03d5V (v, x) = v, \u03d5E(e, l) = e defined in the proof of Proposition 5.25 is an isomorphism, and TS uses a Rabin acceptance condition. J\nI Proposition 6.10. Let TS = (GTS ,AccTS) be a Muller transition system. The following conditions are equivalent:\n1. TS is Streett type. 2. For every pair of accepting cycles `1, `2 \u2208 Cycles(TS) with some state in common, `1 \u222a `2\nis an accepting cycle.13 3. ACDTS is a Streett ACD.\n68\nProof. Implications (1\u21d2 2) and (2\u21d2 3) are analogous to those from Proposition 6.9.\n(3 \u21d2 1) We consider the transition system TS obtained by complementing the acceptance set of AccTS . By Remark 5.6, the ACD of TS is obtained from ACDTS by turning round nodes into square nodes and vice-versa. Thus, the ACD of TS is a Rabin ACD, and by applying the previous proposition we can define a Rabin condition AccR = (\u03b3,\u0393,Rabin\u0393(R)) such that the transition system (GTS ,AccR) is isomorphic to TS. Since Streett\u0393(R) is the complement language of Rabin\u0393(R), we obtain that AccS = (\u03b3,\u0393,Streett\u0393(R)) is a Streett acceptance condition equivalent to AccTS over GTS . J\nI Proposition 6.11. Let TS = (GTS ,AccTS) be a Muller transition system. The following conditions are equivalent:\n1. TS is parity type. 2. For every pair of accepting (resp. rejecting) cycles `1, `2 \u2208 Cycles(TS) with some state in\ncommon, `1 \u222a `2 is an accepting (resp. rejecting) cycle. 3. ACDTS is a parity ACD.\nMoreover, if some of the conditions is satisfied, TS is [0, d\u2212 1] (resp. [1, d])-parity type if and only if ACDTS is a [0, d\u2212 1](resp. [1, d])-parity ACD.\nProof. (1 \u21d2 2) Proven in Lemma 4.19. (2 \u21d2 3) Admits an analogous proof to the corresponding implication in Proposition 6.9. (3 \u21d2 1) By definition, ACDTS is a parity ACD if and only if Leaves(Tv) is a singleton for\neach vertex v of TS. In particular, the ACD-parity-transform of TS does not add any state to TS. It is immediate to check that the morphism \u03d5 : ACDparity(TS)\u2192 TS defined in the proof of Proposition 5.18 is an isomorphism. Therefore, TS and ACDparity(TS) are isomorphic transition systems, and the latter uses a parity acceptance condition that is a [0, d\u2212 1] (resp. [1, d])-parity condition if ACDTS is a [0, d\u2212 1] (resp. [1, d])-parity ACD. If ACDTS is not a [0, d\u2212 1](resp. [1, d])-parity ACD, then the number of colours cannot be reduced by the optimality of the number of colours of the ACD-parity-transform (Theorem 5.31). J\nI Corollary 6.12. A Muller transition system is parity type if and only if it is both Rabin and Streett type.\nThe ACD and the parity index of \u03c9-regular languages\nI Proposition 6.13. Let A be a deterministic Muller automaton whose states are accessible. Then, the parity index of L(A) is:\n[0, d\u2212 1] (resp. [1, d]) if and only if:\ntrees of ACDA have height at most d, there is at least one tree of height d, and trees of height d are positive (resp. negative).\nWeakd if and only if:\n13This property was introduced by Le Sa\u00ebc under the name cyclically closed automata [71]. We point out that the \u201cif\u201d direction of the result stated in [71, Theorem 5.2] does not hold. That statement can be rephrased as: If a DMA A is cyclically closed, then the parity index of A is [0, 1]. We refer to Proposition 6.13 for a correct characterisation."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 69",
            "text": "trees of ACDA have height at most d, there is at least one positive tree of height d, and there is at least one negative tree of height d.\nProof. We prove the right-to-left implication for the case Weakd. Suppose that ACDA verifies the previous list of conditions (in particular, it is equidistant). Then, the ACD-paritytransform ACDparity(A) is a DPA recognising L(A) using colours in [0, d]. In order to obtain a DPA for L(A) with colours in [1, d+ 1] we need to introduce a small modification to the function pACD. For `i a maximal cycle of A and n \u2208 N`i we define:\np\u2032ACD(n) = Depth(n) + 2, if `i is accepting, p\u2032ACD(n) = Depth(n) + 1, if `i is rejecting.\nIt is a routine check to see that the version of the ACD-parity-transform using p\u2032ACD is indeed a correct parity automaton using colours in [1, d+ 1].\nTo prove that no DPA recognising L uses less than d colours, it suffices to use the Flower Lemma 2.16 and the fact that a branch of length d in a tree of the ACD induces a d-flower in A, which is positive if and only if the corresponding tree is positive (Lemma 5.39).\nThis is indeed a complete characterisation, since for any ACD there is a minimal d such that ACDA lies in one and only one of the classes specified in the statement of the proposition. J\nI Proposition 6.14. Let L \u2286 \u03a3\u03c9 be an \u03c9-regular language of parity index at least [0, d\u2212 1] (resp. [1, d]). Any history-deterministic Muller automaton recognising L uses an acceptance condition with at least d different output colours.\nProof. We first prove the result for deterministic automata. Let A be a DMA recognising L using the acceptance condition (\u03b3,\u0393,Muller\u0393(F)). By Proposition 6.13, there is a tree AltTree(`i) in the ACD of A of height at least d. We define \u03b3ACD : Nodes(ACDTS) \u2192 \u0393 to be the function that assigns to each node of the ACD the colours appearing in it, that is: \u03b3ACD(n) = \u03b3(\u03bd(n)). We remark that if n\u2032 is a descendant of n then \u03b3ACD(n\u2032) \u2286 \u03b3ACD(n), and that a node n is round if and only if \u03b3ACD(n) \u2208 F . Therefore, by the alternation of round and square nodes, if n\u2032 is a strict descendent of n, \u03b3ACD(n\u2032) ( \u03b3ACD(n). We conclude that the root of AltTree(`i) must contain at least d different colours.\nIn order to obtain the result for history-deterministic automata we use finite-memory resolvers as defined in Section 4.2. If A is a history-deterministic Muller automaton, it admits a sound resolver implemented by a finite memory structure (M, \u03c3) (Lemma 4.22). Then, the composition A C\u03c3M is a DMA using the same number of colours, that has to be at least d. J\nThe following result (which was already known, as it is a consequence of the construction by Carton and Maceiras [15]), is refined and proven in Appendix A (Corollary A.16).\nI Proposition 6.15. Let A be a deterministic parity automaton such that all its states are accessible and the parity index of L(A) is [0, d\u2212 1] (resp. [1, d]). Then, A is [0, d\u2212 1] (resp. [1, d])-parity type.\nThe previous result does not hold for history-deterministic automata, as we could artificially add transitions augmenting the complexity of the structure of the automaton (enlarging the flowers of the automaton) without modifying the language it recognises. Nevertheless, some analogous results applying to HD automata can be obtained. Boker, Kupferman and Skrzypczak proved that any HD parity automaton recognising a language of parity index\n70\n[0, 1] (resp. [1, 2]) admits an equivalent HD subautomaton using a B\u00fcchi (resp. coB\u00fcchi) condition [8, Theorems 10 and 13]. We do not know whether the result holds for languages of arbitrary parity index.\nTypeness for deterministic automata\nTwo automata A1 and A2 such that A1 ' A2 recognise the same language: L(A1) = L(A2). However, the converse only holds for deterministic automata.\nI Lemma 6.16. Let A1 and A2 be two deterministic automata over the same underlying graph and with the same labelling by input letters. Then, L(A1) = L(A2) if and only if A1 ' A2.\nProof. The implication from right to left is trivial. For the other implication, suppose that L(A1) = L(A2), and let \u03c1 \u2208 Run(A1) = Run(A2) be an infinite run over the underlying graph of A1. Let w \u2208 \u03a3\u03c9 be the word over the input alphabet \u03a3 labelling the run \u03c1. Since A1 and A2 are deterministic, \u03c1 is the only run over w, and therefore:\n\u03c1 is accepting for A1 \u21d0\u21d2 w \u2208 L(A1) = L(A2) \u21d0\u21d2 \u03c1 is accepting for A2. J\nI Corollary 6.17 (First proven in [9, Theorem 7]). Let GA be the underlying graph of a deterministic automaton. There are Rabin and Streett conditions AccR and AccS such that L(GA,AccR) = L(GA,AccS), if and only if there is a parity condition Accp such that L(GA,Accp) = L(GA,AccR) = L(GA,AccS).\nWe remark that the hypothesis of determinism in the previous corollary is necessary, as it has been shown that an analogous result does not hold for non-deterministic automata [9].\nI Proposition 6.18 (First proven in [47, Theorem 15]). Let A be a deterministic Rabin (resp. Streett) automaton, and suppose that L(A) can be recognised by a deterministic B\u00fcchi (resp. coB\u00fcchi) automaton; that is, the parity index of L(A) is at most [0, 1] (resp. at most [1, 2]). Then, A is B\u00fcchi type (resp. coB\u00fcchi type).\nProof. We do the proof for the case Rabin-B\u00fcchi. We can suppose that all the states of A are accessible, as we can define a trivial acceptance condition in the part of A that is not accessible. Since L(A) has parity index at most [0, 1], the trees of the ACD of A have height at most 2, and trees of height 2 are positive (the root is a round node), by Proposition 6.13. As A is a Rabin automaton, its ACD has Rabin shape (Proposition 6.9), so round nodes have at most one child. We conclude that the trees of the ACD of A have a single branch, so it is a [0, 1]-parity ACD, and by Proposition 6.11, A is B\u00fcchi type. J"
        },
        {
            "heading": "6.2 A normal form for parity transition systems",
            "text": "In this section, we propose a definition of a normal form of parity automata. This is exactly the form of automata resulting by applying the procedure defined by Carton and Maceiras [15], or, equivalently, of automata resulting from the ACD-parity-transform (Proposition 6.26). These automata satisfy that they are parity-index-tight, that is, their acceptance condition use the minimal possible number of colours. But they offer some further convenient properties, stated in Propositions 6.28 and 6.29, which make them particularly well-suited for reasoning about deterministic parity automata.\nThis normal form, or partial versions of it, have already been used in the literature to prove results about parity automata in different contexts, such as history-deterministic"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 71",
            "text": "coB\u00fcchi automata [1, 29, 49], positionality of languages defined by deterministic B\u00fcchi automata [13] or learning of DPAs [4]. This normal form also facilitates the resolution of parity games in practice [35]. However, the application of this normal form in the literature is limited to specific cases, and no prior studies have provided a formal and systematic analysis of it.\nI Remark 6.19. We remark that if Acc = (\u03b3, [dmin, dmax], parity) is a parity acceptance condition over a pointed graph G, we can always suppose that dmin is 0 or 1. Indeed, define \u03c7 = dmin if dmin is even, and \u03c7 = dmin \u2212 1 if dmin is odd. The parity acceptance condition (\u03b3\u2032, [dmin \u2212 \u03c7, dmax \u2212 \u03c7], parity) defined as \u03b3\u2032(e) = \u03b3(e)\u2212 \u03c7 is equivalent to Acc over G.\nNext definition constitutes a syntactic version of the parity index, defined at the level of parity transition systems. The following results establish the tight relation between the semantic notion of parity index and its syntactic counterpart.\nI Definition 6.20. We say that a parity transition system TS = (GTS ,AccTS) is parity-indextight if any other parity condition Acc\u2032 over GTS such that Acc\u2032 ' GTS AccTS uses at least as many colours as AccTS .\nI Lemma 6.21 ([15]). Any parity transition system admits an equivalent parity acceptance condition making it parity-index-tight. Moreover, such an acceptance condition can be computed in polynomial time.\nJust as in the definition of the ACD-parity-transform we had to define positive and negative ACDs to obtain an accurate optimality result in the number of colours, we need now to take care of a small technical detail so that TS in normal form are parity-index-tight.\nWe say that a transition system TS is negative if ACDTS is negative, that is, if for some d TS contains a negative d-flower but contains no positive d-flower. Intuitively, a parity TS is negative if and only if the minimal colour used by a parity acceptance condition using an optimal number of colours is 1.\nI Definition 6.22 (Normal form). Let TS = (GTS ,AccTS) be a parity transition system using a colouring function \u03b3. If TS is not negative, we say that TS is in normal form if any other parity acceptance condition equivalent to AccTS over GTS using a colouring function \u03b3\u2032 satisfies that for every edge e:\n\u03b3(e) \u2264 \u03b3\u2032(e).\nIf TS is negative, we say that it is in normal form if any other equivalent colouring \u03b3\u2032 not using colour 0 satisfies that for any edge e:\n1 \u2264 \u03b3(e) \u2264 \u03b3\u2032(e).\nIf TS is in normal form, we will also say that its acceptance condition or the colouring function it uses are in normal form. y\nI Example 6.23. Parity transition systems from Figures 3, 9, 16 and 17 are all in normal form. Parity automata appearing in Figures 9 and 16 are negative (the minimal colour used by an optimal acceptance condition is odd), whereas parity automata in Figure 17 are not.\nOn the other hand, the automaton from Figure 1 is not in normal form (even if it uses an optimal number of colours). We can put it in normal form by assigning colour 1 to transitions q1 a,b\u2212\u2212\u2192 q0 and q1 b,c\u2212\u2212\u2192 q2. The automaton obtained in this way recognises the same language.\n72\nI Proposition 6.24. Let TS = (GTS ,AccTS) be a parity transition system with a colouring function \u03b3. There is a unique parity acceptance condition equivalent to AccTS over GTS in normal form. Moreover, this acceptance condition is exactly the parity condition of the ACD-parity-transform of TS.\nBefore showing the proof of Proposition 6.24, we prove a useful technical lemma.\nI Lemma 6.25. Let TS be a parity transition system with colouring function \u03b3. If `1 ) `2 ) \u00b7 \u00b7 \u00b7 ) `k is a positive (resp. negative) k-flower of TS, then min \u03b3(`k) \u2265 k \u2212 1 (resp. min \u03b3(`k) \u2265 k).\nProof. We show the result for negative flowers. Let di = min \u03b3(`i). We show that di \u2265 i by induction. Since `i is an accepting cycle if and only if i is even, we have that di is even if and only if i is even. Clearly, d1 \u2265 1, as 1 is the least odd number. Also, di+1 \u2265 di, since `i+1 \u2286 `i, and the inequality is strict by the alternation of the parity, concluding the proof. J\nProof of Proposition 6.24. We first remark that the uniqueness is directly implied by the definition of normal form.\nWe prove that the acceptance condition of the ACD-parity-transform is in normal form. We note its colouring function by \u03b3ACD. The transitions not belonging to any SCC are coloured 0 if TS is not negative and 1 if TS is negative, as desired. It suffices to prove the result for edges in SCCs.\nWe suppose that TS is not negative and we let S be an accepting SCC of TS (the proof is similar for TS negative and a rejecting SCC). Let e = v \u2212\u2192 v\u2032 be an edge in S, and let Tv be the local subtree at v, which is composed of a single branch (see Proposition 6.11). We let n0 n1 . . . nr be that branch, where n0 is the root and nr the leaf . Let nk be the deepest node of Tv such that e \u2208 \u03bd(nk). By definition of the ACD-parity-transform, \u03b3ACD(e) = pACD(e) = k. Also, \u03bd(n0) \u03bd(n1) . . . \u03bd(nk) is a positive k + 1-flower (by Lemma 5.39). Lemma 6.25 implies then that any equivalent parity condition using a colouring function \u03b3\u2032 verifies \u03b3\u2032(e) \u2265 \u03b3ACD(e) = k. J\nI Corollary 6.26. The ACD-parity-transform ACDparity(TS) of any Muller transition system TS is in normal form.\nWe can deduce that the optimality properties of the colouring of ACDparity(TS) (Theorem 5.31) transfer to parity transition systems in normal form.\nI Corollary 6.27. A parity transition system in normal form is parity-index-tight.\nWe now state what we consider to be the two fundamental properties of parity transition systems in normal form.\nI Proposition 6.28. Let TS be a parity transition system in normal form. If there is a path v v\u2032 producing d as minimal colour, then, either:\nv and v\u2032 are in different SCCs (and in this case d \u2208 {0, 1}), or there is a path v\u2032 v producing no colour strictly smaller than d.\nProof. By Proposition 6.24, we know that the colouring of TS is the one given by its ACDtransform, that we note \u03b3ACD. If v and v\u2032 are in different SCCs the result is trivial. Let v and v\u2032 be in the same SCC, that we suppose to be an accepting SCC without loss of generality. Let \u03c1 = v e1\u2212\u2192 . . . ek\u2212\u2192 v\u2032 be a path from v to v\u2032 producing min \u03b3ACD(\u03c1) = d as"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 73",
            "text": "minimal colour. We remark that, as ACDTS is a parity ACD, each edge e appears in one and only one branch of ACDTS , and that \u03b3ACD(e) equals the depth of the deepest node containing e. In particular, if e \u2208 \u03bd(n) for some node e, \u03b3ACD(e) \u2265 Depth(n). Our objective is to show that a similar result holds for the path \u03c1 as a set of edges:\nB Claim 6.28.1. Let N\u03c1 be the set of nodes of ACDTS containing the edges of the path \u03c1 in their label, that is, N\u03c1 = {n \u2208 Nodes(ACDTS) | {e1, . . . , ek} \u2286 \u03bd(n)}. Then, min(\u03b3ACD(\u03c1)) equals the depth of a node of maximal depth of N\u03c1.14\nThis claim allows us to conclude. Indeed, let n be a node of maximal depth of N\u03c1, verifying Depth(n) = d. Then, \u03bd(n) is a cycle containing the vertices v and v\u2032, and for all the edges e \u2208 \u03bd(n), \u03b3ACD(e) \u2265 Depth(n) = d. This provides the desired path from v\u2032 to v.\nProof of Claim 6.28.1. First, we remark that if `1, `2, . . . , `k are cycles such that `i and `i+1 have some state in common, then \u222aki=1`i is a cycle. Let n be a node of maximal depth in N\u03c1. By the previous remarks, \u03b3ACD(e) \u2265 Depth(n). Suppose by contradiction that \u03b3ACD(\u03c1) > Depth(n). Then, each edge ei of \u03c1 would appear in some strict descendant ni of n (we can suppose that ni is a child of n). Then, \u03bd(n1), . . . , \u03bd(nk) would be cycles such that \u03bd(ni) and \u03bd(ni+1) have some state in common (namely, Target(ei) = Source(ei+1)), so their union is a cycle. However, this is not possible in a parity transition system, as \u03bd(n) is accepting if and only if each of the \u03bd(ni) is rejecting (see Lemma 4.19). C\nJ\nI Proposition 6.29 (Normal flowers do not lack petals). Let v be a state of a parity transition system in normal form belonging to an accepting (resp. rejecting) SCC. Let ` \u2208 Cycles\nv (TS)\nbe a cycle over v and let d` be the minimal colour appearing on it.\nIf TS is not negative, for each x \u2208 [0, d`] (resp. x \u2208 [1, d`]) there is a cycle `x \u2208 Cyclesv(TS) producing x as minimal colour. If TS is negative, for each x \u2208 [2, d`] (resp. x \u2208 [1, d`]) there is a cycle `x \u2208 Cyclesv(TS) producing x as minimal colour.\nProof. We do the proof for the case in which TS is not negative and v belongs to an accepting SCC. By Proposition 6.24, the colouring of TS is the one given by its ACD-transform, noted \u03b3ACD. Consider the local subtree at v, Tv, consisting in a single branch, as it has parity shape (Proposition 6.11). Let n0 . . . nk be that branch, and let ni be the deepest node such that ` \u2286 \u03bd(ni). We remark that, by definition of \u03b3ACD, d` = Depth(ni) = i. The desired cycles are obtained by taking `x = \u03bd(nx), for x \u2208 [0, d`]. J\nParity index from automata in normal form\nA refined version of the following result is proven in Appendix A (Corollary A.15), in which we give a full characterisation by using generalised weak automata.\nI Corollary 6.30. Let A be a deterministic parity automaton in normal form such that all its states are accessible. If A uses colours in [0, d\u2212 1] (resp. [1, d]), then the parity index of L(A) is Weakd\u22121 or [0, d\u2212 1] (resp. Weakd\u22121 or [1, d])."
        },
        {
            "heading": "14 In fact, the nodes of N\u03c1 are totally ordered by the ancestor relation, so there is a unique node of maximal",
            "text": "depth in N\u03c1. This fact is not used in our proof.\n74"
        },
        {
            "heading": "6.3 Minimisation of deterministic parity automata recognising Muller languages",
            "text": "The minimisation of \u03c9-automata is a fundamental problem of an intriguing complexity. In 2010, Schewe showed that the minimisation of deterministic B\u00fcchi and parity automata is NP-complete, if the acceptance condition is defined over the states [74]. However, the reduction of NP-hardness does not generalise to automata with edge-based acceptance. A surprising positive result was obtained in 2019 by Abu Radi and Kupferman: we can minimise in polynomial time HD coB\u00fcchi automata using transition-based acceptance [1]. Schewe showed that the minimisation was again NP-hard for HD automata with state-based acceptance [75]. To the best of our knowledge, the only existing hardness result applying to transition-based automata is Casares\u2019 result about the NP-completeness of the minimisation of deterministic Rabin automata [17]. In fact, in [17] a stronger result is proven: it is NP-hard to minimise deterministic Rabin automata recognising Muller languages.\nIn this section, we provide a polynomial-time algorithm for the minimisation of DPA recognising Muller languages (with acceptance condition over transitions). By Proposition 4.10 and Theorem 4.13, we know that a minimal (history-)deterministic parity automaton recognising a Muller language L = Muller\u03a3(F) can be constructed in linear time from the Zielonka tree ZF . We will therefore provide a polynomial-time algorithm computing this Zielonka tree from a DPA recognising L.\nI Theorem 6.31. Let A be a DPA recognising a Muller language L = Muller\u03a3(F). We can find a minimal deterministic (resp. history-deterministic) parity automaton recognising L in polynomial time in the size of the representation of A.15\nDescription of the algorithm. Let A = (Q,\u03a3, q0,\u0393,\u2206, parity) be a DPA recognising L = Muller\u03a3(F). We outline a recursive algorithm building ZF = (N, , \u03bd) in a top-down fashion; it starts from the root of the tree (which is always labelled \u03a3), and each time that some node is added to N , we compute its children. If we have built ZF up to a node n, we compute the children of n by using the procedure AlternatingSets described in Algorithm 1, which we disclose next.\nWe suppose without loss of generality that n is round, that is, \u03bd(n) \u2208 F . First, we take the restriction of A to transitions labelled with letters in \u03bd(n) and pick a final SCC on it. Such final SCC induces a subautomaton A\u2032 of A recognising Muller\u03bd(n)(F|\u03bd(n)) (see also Lemma 4.18). Our objective is to find the maximal subautomata of A\u2032 using as input letters sets X \u2286 \u03bd(n) such that X /\u2208 F . We will keep all such subsets X in a list altSets. The labels of the children of n will then correspond to the maximal sets appearing in this list, which are returned by the algorithm AlternatingSets (Line 15). In order to find them, we remove the transitions using the minimal colour in A\u2032 (that is even, since \u03bd(n) \u2208 F) and compute a decomposition in strongly connected components of the obtained graph. Let S be a component of this decomposition and let \u03a3S \u2286 \u03bd(n) be the input letters appearing on it. Then, \u03a3S /\u2208 F if and only if the minimal output colour in S is odd (see Lemma 6.32 below). In this case, we add \u03a3S to altSets. On the contrary, we remove the minimal (even) colour from S and we start again finding a decomposition in SCCs of the obtained graph.\n15We can suppose that the representation of A has size polynomial in |Q|+ |\u03a3|, where Q and \u03a3 are the set of states and the input alphabet of. Indeed, as A is deterministic the number of transitions is at most |Q| \u00b7 |\u03a3| and we can suppose that A has no more output colours than transitions."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 75",
            "text": "We include the pseudocode for the procedure AlternatingSets in Algorithm 1. We use the following notations:\nLetters(S) is the set of input letters appearing in S, MinColour(S) is the minimal output colour appearing in S (which determines whether Letters(S) \u2208 F , if S is strongly connected), SCC-Decomposition(A) outputs a list of the strongly connected components of A. If A is empty, it outputs an empty list. MaxInclusion(lst) returns the list of the maximal subsets in lst.\nAlgorithm 1 AlternatingSets(A): Computing the children of a node\n1: Input: A strongly connected automaton A over \u03a3 such that L(A) = Muller(F) 2: Output: The maximal subsets \u03a31, . . . ,\u03a3k \u2286 \u03a3 such that \u03a3i \u2208 F \u21d0\u21d2 \u03a3 /\u2208 F . 3: d\u2190 MinColour(A) 4: A>d \u2190 restriction of A to transitions \u2206>d = {q\na:x\u2212\u2212\u2192 q\u2032 \u2208 \u2206 | x > d} 5: \u3008S1, . . . ,Sr\u3009 \u2190 SCC-Decomposition(A>d) 6: altSets\u2190 {} 7: for i = 1, . . . , r do 8: if MinColour(Si) is odd if and only if d is even then 9: altSets\u2190 altSets \u222a {Letters(Si)} 10: else 11: altSets\u2190 altSets \u222a AlternatingSets(Si) 12: end if 13: end for 14: maxAltSets\u2190 MaxInclusion(altSets) 15: return maxAltSets\nCorrectness of the algorithm. Let n be a node of the Zielonka tree of F labelled with \u03bd(n), and let An be an accessible subautomaton of A over \u03bd(n) recognising Muller\u03bd(n)(F|\u03bd(n)). We prove that AlternatingSets(An) returns a list of sets corresponding to the labels of the children of n in ZF . We suppose without loss of generality that \u03bd(n) \u2208 F and therefore the minimal colour d in An is even.\nFirst, we observe that if X \u2286 \u03a3 is added to altSets during the execution of the procedure AlternatingSets, then X is the set of input letters appearing in a cycle whose minimal colour is odd. Next lemma implies that in this case, X /\u2208 F . In particular, no subset is added if n is a leaf of ZF .\nI Lemma 6.32. Let A be a DPA such that L(A) = Muller\u03a3(F). Let ` \u2208 Cycles(A) be an accessible cycle of A. Let \u03a3` \u2286 \u03a3 be the input letters appearing on `, and let d` be the minimal colour on `. Then, \u03a3` \u2208 F if and only if d` is even.\nProof. Since ` is an accessible cycle, there is a word w \u2208 \u03a3\u03c9 such that Inf(w) = \u03a3` and verifying that the edges visited infinitely infinitely often by the (only) run over w in A are the edges of `. Therefore w \u2208 L(A) if and only if d` is even, and since L(A) is a Muller language, w \u2208 L(A) if and only if Inf(w) = \u03a3` \u2208 F . J\nAs the final output of the algorithm consists solely on the maximal subsets in altSets, and no accepting set is added to this list, it suffices to show that each maximal rejecting subset \u03a3max \u2286 \u03bd(n) is added to altSets at some point.\n76\nLet \u03a3max \u2286 \u03bd(n) be one of the maximal rejecting subsets of \u03bd(n). Let S be a final SCC of the restriction of An to transitions labelled with letters in \u03a3max (by the previous lemma, MinColour(S) is odd). We show that \u03a3max will eventually be considered by the recursive procedure AlternatingSets, and therefore \u03a3max will be added to altSets We use of the following remark:\nB Claim 6.32.1. If S \u2032 is a strongly connected subautomaton of An such that S ( S \u2032 \u2286 An, then the minimal colour in S \u2032 is even.\nProof. Let \u03a3\u2032 be the input letters appearing in S \u2032. As S ( S \u2032 and no transition labelled with a letter in \u03a3max leaves S, we must have \u03a3max ( \u03a3\u2032. The claim follows from Lemma 6.32.\nC\nTherefore, either S is one of the SCCs of A>d (in this case, \u03a3max is added to altSets in Line 9), or it is contained in one SCC of A>d whose minimal colour is even and we can conclude by induction.\nComplexity analysis. We will show that the proposed algorithm works in O(|Q|3|\u03a3|2|\u0393|), where Q, \u03a3 and \u0393 are the states, set of input letters and set of output colours of the automaton, respectively. We remark that, since A is deterministic, |\u2206| \u2264 |Q||\u03a3|.\nFirst, we study the complexity of the procedure AlternatingSets(A). At each recursive call, at least one edge is removed from \u2206, and a decomposition in strongly connected components of the automaton is performed, which can be done in O(|Q||\u03a3|) [78]. Therefore, the children of a node of the Zielonka tree can be computed in O(|Q|2|\u03a3|2).\nWe perform this operation for each node of the Zielonka tree. By the optimality of the ZT-parity-automaton (Theorems 4.12 and 4.13), we know that |Q| \u2265 |Leaves(ZF )| and that the height of ZF is at most |\u0393|. Therefore, |ZF | \u2264 |Q||\u0393|, and the procedure AlternatingSets is called at most |Q||\u0393| times. We conclude that the proposed algorithm works in O(|Q|3|\u03a3|2|\u0393|).\n7 Conclusion\nIn this work, we have carried out an extensive study of transformations of automata and games that use Muller acceptance conditions. We have proposed different types of morphisms to formalise the idea of valid transformations of transition systems, which distil the central features of existing transformations. Our main contribution resides in the introduction of a new structure, the alternating cycle decomposition, which is a succinct representation of the alternating chains of loops of a Muller automaton \u2013 in the sense of Wagner [80] \u2013 and provides the necessary information to understand the interplay between its acceptance condition and its underlying graph.\nOptimal and practical transformations of automata. We have presented a transformation that, given a deterministic Muller automaton, provides an equivalent deterministic parity automaton, and another that provides an equivalent history-deterministic Rabin automaton. These transformations are optimal in a strong sense; the obtained automata have a minimal number of states amongst those which accept a history-deterministic mapping to the original Muller automaton. The first of these transformations has been implemented in the opensource tools Spot 2.10 [27] and Owl 21.0 [45], and it has been shown to perform extremely well in practice [20], as the natural definition of the ACD provides a fairly efficient way to"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 77",
            "text": "compute the transformation, while its optimality guarantees to produce automata as small as possible.\nUnderstanding the limitations of history-deterministic automata. As a corollary of our results, we have obtained that minimal deterministic and history-deterministic parity automata recognising Muller languages have the same size (Corollary 4.14). Moreover, we have shown that HD parity automata that are strictly smaller than equivalent deterministic ones cannot come from a deterministic Muller automaton (Corollary 5.36). This provides a partial explanation on the difficulty to find succinct HD parity automata, as we could argue that a simple way to conceptualise \u03c9-regular languages is through deterministic Muller automata. Maybe most importantly, this sets a limitation in the usefulness of history-determinism in practice, as procedures that use a DMA as an intermediate step \u2013 as the ones from the tools Strix [55] and ltlsynt [61], or automata determinisation [67, 73, 54] \u2013 cannot benefit from the succinctness of HD automata.\nOn the other hand, we have shown that, if our objective is to obtain Rabin automata as output, the ACD-HD-Rabin-transform allows us to benefit from succinct HD automata. In this case, it has been shown that these automata can be exponentially smaller than equivalent deterministic ones [19, Theorem 21].\nDisclosing the structure of \u03c9-automata. As an application of the insights gained from the alternating cycle decomposition, we have derived results concerning typeness of automata. In particular, we have characterised when we can define a parity, Rabin or Streett condition on top of a Muller automaton, obtaining an equivalent automaton (Propositions 6.9, 6.10 and 6.11). These characterisations have already been proven instrumental in works about the memory for games [17], and to obtain lower bounds for \u03c9-automata [19].\nWe have also employed the ACD to present a normal form for parity transition systems and systematically prove the most important properties that make this form a valuable tool for manipulating parity automata. We believe that this normal form will be useful to extend existing results about B\u00fcchi and coB\u00fcchi automata (as the ones in [1, 8, 13]) to parity automata.\nReferences 1 Bader Abu Radi and Orna Kupferman. Minimization and canonization of GFG transition-based\nautomata. Log. Methods Comput. Sci., 18(3), 2022. doi:10.46298/lmcs-18(3:16)2022. 2 Tom\u00e1\u0161 Babiak, Franti\u0161ek Blahoudek, Alexandre Duret-Lutz, Joachim Klein, Jan K\u0159et\u00ednsk\u00fd,\nDavid M\u00fcller, David Parker, and Jan Strej\u010dek. The Hanoi omega-automata format. In CAV, pages 479\u2013486, 2015.\n3 Roderick Bloem, Krishnendu Chatterjee, and Barbara Jobstmann. Graph games and reactive synthesis. In Edmund M. Clarke, Thomas A. Henzinger, Helmut Veith, and Roderick Bloem, editors, Handbook of Model Checking, pages 921\u2013962. Springer International Publishing, 2018. doi:10.1007/978-3-319-10575-8_27.\n4 Le\u00f3n Bohn and Christof L\u00f6ding. Constructing deterministic parity automata from positive and negative examples. CoRR, abs/2302.11043, 2023. doi:10.48550/arXiv.2302.11043.\n5 Bernard Boigelot, S\u00e9bastien Jodogne, and Pierre Wolper. On the use of weak automata for deciding linear arithmetic with integer and real variables. In Automated Reasoning, pages 611\u2013625, 2001.\n6 Udi Boker. Why these automata types? In LPAR, volume 57 of EPiC Series in Computing, pages 143\u2013163, 2018. doi:10.29007/c3bj.\n78\n7 Udi Boker, Denis Kuperberg, Orna Kupferman, and Micha\u0142 Skrzypczak. Nondeterminism in the presence of a diverse or unknown future. In ICALP, pages 89\u2013100, 2013. doi: 10.1007/978-3-642-39212-2\\_11.\n8 Udi Boker, Orna Kupferman, and Michal Skrzypczak. How deterministic are good-for-games automata? In FSTTCS, volume 93, pages 18:1\u201318:14, 2017. doi:10.4230/LIPIcs.FSTTCS. 2017.18.\n9 Udi Boker, Orna Kupferman, and Avital Steinitz. Parityizing Rabin and Streett. In FSTTCS, volume 8 of LIPIcs, pages 412\u2013423, 2010. doi:10.4230/LIPIcs.FSTTCS.2010.412."
        },
        {
            "heading": "10 Udi Boker and Karoliina Lehtinen. Good for Games Automata: From Nondeterminism to",
            "text": "Alternation. In CONCUR, volume 140, pages 19:1\u201319:16, 2019. doi:10.4230/LIPIcs.CONCUR. 2019.19."
        },
        {
            "heading": "11 Udi Boker and Karoliina Lehtinen. History determinism vs. good for gameness in quantitative",
            "text": "automata. In FSTTCS, volume 213, pages 38:1\u201338:20, 2021. URL: https://drops.dagstuhl.de/ opus/volltexte/2021/15549, doi:10.4230/LIPIcs.FSTTCS.2021.38."
        },
        {
            "heading": "12 Udi Boker and Karoliina Lehtinen. When a little nondeterminism goes a long way: An",
            "text": "introduction to history-determinism. ACM SIGLOG News, 10(1):24\u201351, 2023. doi:10.1145/ 3584676.3584682."
        },
        {
            "heading": "13 Patricia Bouyer, Antonio Casares, Mickael Randour, and Pierre Vandenhove. Half-positional",
            "text": "objectives recognized by deterministic B\u00fcchi automata. In CONCUR, volume 243, pages 20:1\u201320:18, 2022. doi:10.4230/LIPIcs.CONCUR.2022.20.\n14 J. Richard B\u00fcchi. On a decision method in restricted second order arithmetic. Proc. Internat. Congr. on Logic, Methodology and Philosophy of Science, pages 1\u201311, 1960."
        },
        {
            "heading": "15 Olivier Carton and Ram\u00f3n Maceiras. Computing the Rabin index of a parity automaton.",
            "text": "RAIRO, pages 495\u2013506, 1999. doi:10.1051/ita:1999129.\n16 Olivier Carton and Max Michel. Unambiguous B\u00fcchi automata. Theoretical Computer Science, 297(1):37 \u2013 81, 2003. doi:10.1016/S0304-3975(02)00618-7."
        },
        {
            "heading": "17 Antonio Casares. On the minimisation of transition-based Rabin automata and the chromatic",
            "text": "memory requirements of Muller conditions. In CSL, volume 216, pages 12:1\u201312:17, 2022. doi:10.4230/LIPIcs.CSL.2022.12."
        },
        {
            "heading": "18 Antonio Casares, Thomas Colcombet, and Nathana\u00ebl Fijalkow. Optimal transformations of",
            "text": "games and automata using Muller conditions. In ICALP, volume 198, pages 123:1\u2013123:14, 2021. doi:10.4230/LIPIcs.ICALP.2021.123."
        },
        {
            "heading": "19 Antonio Casares, Thomas Colcombet, and Karoliina Lehtinen. On the size of good-for-games",
            "text": "Rabin automata and its link with the memory in Muller games. In ICALP, volume 229, pages 117:1\u2013117:20, 2022. doi:10.4230/LIPIcs.ICALP.2022.117."
        },
        {
            "heading": "20 Antonio Casares, Alexandre Duret-Lutz, Klara J. Meyer, Florian Renkin, and Salomon Sickert.",
            "text": "Practical applications of the Alternating Cycle Decomposition. In TACAS, volume 13244 of Lecture Notes in Computer Science, pages 99\u2013117, 2022. doi:10.1007/978-3-030-99527-0_6.\n21 Thomas Colcombet. The theory of stabilisation monoids and regular cost functions. In ICALP, pages 139\u2013150, 2009. doi:10.1007/978-3-642-02930-1\\_12.\n22 Thomas Colcombet. Forms of Determinism for Automata (Invited Talk). In STACS, volume 14, pages 1\u201323, 2012. URL: http://drops.dagstuhl.de/opus/volltexte/2012/3386, doi:10.4230/ LIPIcs.STACS.2012.1.\n23 Thomas Colcombet. Unambiguity in automata theory. In DCFS, volume 9118 of Lecture Notes in Computer Science, pages 3\u201318, 2015. doi:10.1007/978-3-319-19225-3\\_1."
        },
        {
            "heading": "24 Thomas Colcombet and Damian Niwi\u0144ski. On the positional determinacy of edge-labeled",
            "text": "games. Theor. Comput. Sci., 352(1-3):190\u2013196, 2006. doi:10.1016/j.tcs.2005.10.046."
        },
        {
            "heading": "25 Thomas Colcombet and Konrad Zdanowski. A tight lower bound for determinization",
            "text": "of transition labeled B\u00fcchi automata. In ICALP, pages 151\u2013162, 2009. doi:10.1007/ 978-3-642-02930-1\\_13."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 79",
            "text": ""
        },
        {
            "heading": "26 Antonio Di Stasio, Aniello Murano, Vincenzo Prignano, and Loredana Sorrentino. Improving",
            "text": "parity games in practice. Annals of Mathematics and Artificial Intelligence, 2021. doi: 10.1007/s10472-020-09721-3."
        },
        {
            "heading": "27 Alexandre Duret-Lutz, Etienne Renault, Maximilien Colange, Florian Renkin, Alexandre Gbaguidi Aisse, Philipp Schlehuber-Caissier, Thomas Medioni, Antoine Martin, J\u00e9r\u00f4me Dubois, Cl\u00e9ment Gillard, and Henrich Lauko. From Spot 2.0 to Spot 2.10: What\u2019s",
            "text": "new? In CAV, volume 13372 of Lecture Notes in Computer Science, pages 174\u2013187, 2022. doi:10.1007/978-3-031-13188-2_9."
        },
        {
            "heading": "28 Stefan Dziembowski, Marcin Jurdzi\u0144ski, and Igor Walukiewicz. How much memory is needed",
            "text": "to win infinite games? In LICS, pages 99\u2013110, 1997. doi:10.1109/LICS.1997.614939.\n29 R\u00fcdiger Ehlers and Sven Schewe. Natural colors of infinite words. In FSTTCS, volume 250, pages 36:1\u201336:17, 2022. doi:10.4230/LIPIcs.FSTTCS.2022.36."
        },
        {
            "heading": "30 E. Allen Emerson and Charanjit S. Jutla. Tree automata, mu-calculus and determinacy",
            "text": "(extended abstract). In FOCS, pages 368\u2013377, 1991. doi:10.1109/SFCS.1991.185392."
        },
        {
            "heading": "31 E. Allen Emerson and Charanjit S. Jutla. The complexity of tree automata and logics of",
            "text": "programs. SIAM J. Comput., 29(1):132\u2013158, 1999. doi:10.1137/S0097539793304741."
        },
        {
            "heading": "32 E. Allen Emerson, Charanjit S. Jutla, and A. Prasad Sistla. On model-checking for fragments",
            "text": "of \u00b5-calculus. In CAV, volume 697 of Lecture Notes in Computer Science, pages 385\u2013396, 1993. doi:10.1007/3-540-56922-7\\_32."
        },
        {
            "heading": "33 Javier Esparza, Jan K\u0159et\u00ednsk\u00fd, Jean-Fran\u00e7ois Raskin, and Salomon Sickert. From LTL and",
            "text": "limit-deterministic B\u00fcchi automata to deterministic parity automata. In TACAS, pages 426\u2013442, 2017. doi:10.1007/978-3-662-54577-5\\_25."
        },
        {
            "heading": "34 Seth Fogarty, Orna Kupferman, Moshe Y. Vardi, and Thomas Wilke. Profile trees for",
            "text": "B\u00fcchi word automata, with application to determinization. Inf. Comput., 245:136\u2013151, 2015. doi:10.1016/j.ic.2014.12.021.\n35 Oliver Friedmann and Martin Lange. Solving parity games in practice. In ATVA, pages 182\u2013196, 2009."
        },
        {
            "heading": "36 Dimitra Giannakopoulou and Flavio Lerda. From states to transitions: Improving translation",
            "text": "of LTL formulae to B\u00fcchi automata. In FORTE, pages 308\u2013326, 2002.\n37 Yuri Gurevich and Leo Harrington. Trees, automata, and games. In STOC, pages 60\u201365, 1982. doi:10.1145/800070.802177.\n38 Thomas A. Henzinger and Nir Piterman. Solving games without determinization. In Computer Science Logic, pages 395\u2013410, 2006. doi:10.1007/11874683\\_26.\n39 Florian Horn. Explicit Muller games are PTIME. In FSTTCS, pages 235\u2013243, 2008. doi: 10.4230/LIPIcs.FSTTCS.2008.1756.\n40 Florian Horn. Random fruits on the Zielonka tree. In STACS, volume 3, pages 541\u2013552, 2009. doi:10.4230/LIPIcs.STACS.2009.1848.\n41 Paul Hunter and Anuj Dawar. Complexity bounds for regular games. In MFCS, pages 495\u2013506, 2005. doi:10.1007/11549345\\_43."
        },
        {
            "heading": "42 Swen Jacobs, Guillermo A. Perez, Remco Abraham, Veronique Bruyere, Michael Cadilhac,",
            "text": "Maximilien Colange, Charly Delfosse, Tom van Dijk, Alexandre Duret-Lutz, Peter Faymonville, Bernd Finkbeiner, Ayrat Khalimov, Felix Klein, Michael Luttenberger, Klara Meyer, Thibaud Michaud, Adrien Pommellet, Florian Renkin, Philipp Schlehuber-Caissier, Mouhammad Sakr, Salomon Sickert, Gaetan Staquet, Clement Tamines, Leander Tentrup, and Adam Walker. The reactive synthesis competition (SYNTCOMP): 2018-2021, 2022. arXiv:2206.00251.\n43 Michael Kaminski. A classification of \u03c9-regular languages. Theoretical Computer Science, 36:217\u2013229, 1985. URL: https://www.sciencedirect.com/science/article/pii/030439758590043X, doi:https://doi.org/10.1016/0304-3975(85)90043-X."
        },
        {
            "heading": "44 Nils Klarlund. Progress measures, immediate determinacy, and a subset construction for tree",
            "text": "automata. Annals of Pure and Applied Logic, 69(2):243\u2013268, 1994. doi:https://doi.org/10. 1016/0168-0072(94)90086-8.\n80"
        },
        {
            "heading": "45 Jan Kret\u00ednsk\u00fd, Tobias Meggendorfer, and Salomon Sickert. Owl: A library for \u03c9-words,",
            "text": "automata, and LTL. In ATVA, volume 11138 of Lecture Notes in Computer Science, pages 543\u2013550, 2018. doi:10.1007/978-3-030-01090-4_34. 46 Jan K\u0159et\u00ednsk\u00fd, Tobias Meggendorfer, Clara Waldmann, and Maximilian Weininger. Index appearance record for transforming Rabin automata into parity automata. In TACAS, pages 443\u2013460, 2017. doi:10.1007/978-3-662-54577-5\\_26. 47 Sriram C. Krishnan, Anuj Puri, and Robert K. Brayton. Deterministic \u03c9-automata vis-a-vis deterministic B\u00fcchi automata. In ISAAC, volume 834 of Lecture Notes in Computer Science, pages 378\u2013386, 1994. doi:10.1007/3-540-58325-4\\_202. 48 Sriram C. Krishnan, Anuj Puri, and Robert K. Brayton. Structural complexity of omegaautomata. In STACS, pages 143\u2013156, 1995. doi:10.1007/3-540-59042-0\\_69. 49 Denis Kuperberg and Micha\u0142 Skrzypczak. On determinisation of good-for-games automata. In ICALP, pages 299\u2013310, 2015. doi:10.1007/978-3-662-47666-6_24. 50 Orna Kupferman. Automata theory and model checking. In Edmund M. Clarke, Thomas A. Henzinger, Helmut Veith, and Roderick Bloem, editors, Handbook of Model Checking, pages 107\u2013151. Springer International Publishing, 2018. doi:10.1007/978-3-319-10575-8_4. 51 Orna Kupferman, Gila Morgenstern, and Aniello Murano. Typeness for omega-regular automata. Int. J. Found. Comput. Sci., 17(4):869\u2013884, 2006. doi:10.1142/S0129054106004157. 52 Jan K\u0159et\u00ednsk\u00fd, Tobias Meggendorfer, Clara Waldmann, and Maximilian Weininger. Index appearance record with preorders. Acta Informatica, 2021. doi:10.1007/s00236-021-00412-y. 53 Oebele Lijzenga and Tom van Dijk. Symbolic parity game solvers that yield winning strategies. In GandALF, volume 326, pages 18\u201332, 2020. doi:10.4204/EPTCS.326.2. 54 Christof L\u00f6ding and Anton Pirogov. Determinization of B\u00fcchi automata: Unifying the approaches of Safra and Muller-Schupp. In ICALP, pages 120:1\u2013120:13, 2019. doi:10.4230/ LIPIcs.ICALP.2019.120. 55 Michael Luttenberger, Philipp J. Meyer, and Salomon Sickert. Practical synthesis of reactive systems from LTL specifications via parity games. Acta Informatica, pages 3\u201336, 2020. doi:10.1007/s00236-019-00349-3. 56 Christof L\u00f6ding. Optimal bounds for transformations of \u03c9-automata. In FSTTCS, page 97\u2013109, 1999. doi:10.1007/3-540-46691-6\\_8. 57 Robert McNaughton. Testing and generating infinite sequences by a finite automaton. Information and control, 9(5):521\u2013530, 1966. doi:10.1016/S0019-9958(66)80013-X. 58 Robert McNaughton. Infinite games played on finite graphs. Annals of Pure and Applied Logic, 1993. doi:https://doi.org/10.1016/0168-0072(93)90036-D. 59 Philipp Meyer and Salomon Sickert. On the optimal and practical conversion of Emerson-Lei automata into parity automata, 2021. Personal Communication. 60 Philipp J. Meyer and Salomon Sickert. Modernising strix. SYNT Workshop, 2021. URL: https://www7.in.tum.de/~sickert/publications/MeyerS21.pdf. 61 Thibaud Michaud and Maximilien Colange. Reactive synthesis from LTL specification with Spot. In SYNT@CAV, Electronic Proceedings in Theoretical Computer Science, 2018. 62 Andrzej W. Mostowski. Regular expressions for infinite trees and a standard form of automata. In SCT, pages 157\u2013168, 1984. doi:10.1007/3-540-16066-3\\_15. 63 David M\u00fcller and Salomon Sickert. LTL to deterministic Emerson-Lei automata. In GandALF, pages 180\u2013194, 2017. doi:10.4204/EPTCS.256.13. 64 David E. Muller. Infinite sequences and finite machines. In Symposium on Switching Circuit Theory and Logical Design, page 3\u201316, 1963. doi:10.1109/SWCT.1963.8. 65 Damian Niwi\u0144ski and Igor Walukiewicz. Relating hierarchies of word and tree automata. In STACS, pages 320\u2013331, 1998. doi:10.1007/BFb0028571. 66 Dominique Perrin and Jean-Eric Pin. Infinite words - automata, semigroups, logic and games, volume 141 of Pure and applied mathematics series. Elsevier Morgan Kaufmann, 2004. 67 Nir Piterman. From nondeterministic B\u00fcchi and Streett automata to deterministic parity automata. In LICS, pages 255\u2013264, 2006. doi:10.1109/LICS.2006.28."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 81",
            "text": ""
        },
        {
            "heading": "68 Nir Piterman and Amir Pnueli. Temporal logic and fair discrete systems. In Edmund M. Clarke,",
            "text": "Thomas A. Henzinger, Helmut Veith, and Roderick Bloem, editors, Handbook of Model Checking, pages 27\u201373. Springer International Publishing, 2018. doi:10.1007/978-3-319-10575-8_2. 69 Amir Pnueli and Roni Rosner. On the synthesis of a reactive module. In POPL, page 179\u2013190, 1989. doi:10.1145/75277.75293. 70 Florian Renkin, Alexandre Duret-Lutz, and Adrien Pommellet. Practical \u201cparitizing\u201d of Emerson-Lei automata. In ATVA, volume 12302 of Lecture Notes in Computer Science, pages 127\u2013143, 2020. doi:10.1007/978-3-030-59152-6_7. 71 Bertrand Le Sa\u00ebc. Saturating right congruences. RAIRO, 24:545\u2013559, 1990. doi:10.1051/ ita/1990240605451. 72 Schmuel Safra. On the complexity of \u03c9-automata. In FOCS, page 319\u2013327, 1988. doi: 10.1109/SFCS.1988.21948. 73 Sven Schewe. Tighter bounds for the determinisation of B\u00fcchi automata. In FoSSaCS, pages 167\u2013181, 2009. doi:10.1007/978-3-642-00596-1\\_13. 74 Sven Schewe. Beyond hyper-minimisation\u2014minimising DBAs and DPAs is NP-complete. In FSTTCS, volume 8, pages 400\u2013411, 2010. doi:10.4230/LIPIcs.FSTTCS.2010.400. 75 Sven Schewe. Minimising Good-For-Games automata is NP-complete. In FSTTCS, volume 182, pages 56:1\u201356:13, 2020. doi:10.4230/LIPIcs.FSTTCS.2020.56. 76 Sven Schewe and Thomas Varghese. Determinising parity automata. In MFCS, pages 486\u2013498, 2014. doi:10.1007/978-3-662-44522-8\\_41. 77 Micha\u0142 Skrzypczak. Topological extension of parity automata. Information and Computation, 228-229:16\u201327, 2013. doi:https://doi.org/10.1016/j.ic.2013.06.004. 78 Robert Tarjan. Depth first search and linear graph algorithms. Siam Journal On Computing, 1(2), 1972. doi:https://doi.org/10.1137/0201010. 79 Tom van Dijk. Oink: An implementation and evaluation of modern parity game solvers. In TACAS, volume 10805 of Lecture Notes in Computer Science, pages 291\u2013308, 2018. doi: 10.1007/978-3-319-89960-2\\_16. 80 Klaus Wagner. On \u03c9-regular sets. Information and control, 43(2):123\u2013177, 1979. doi: 10.1016/S0019-9958(79)90653-3. 81 Wies\u0142aw Zielonka. Infinite games on finitely coloured graphs with applications to automata on infinite trees. Theoretical Computer Science, 200(1-2):135\u2013183, 1998. doi:10.1016/ S0304-3975(98)00009-7.\n82\nA Generalised classes of acceptance conditions\nFurther acceptance conditions\nGeneralised B\u00fcchi. Given k non-empty subsets B1, . . . , Bk \u2286 \u0393, we define the generalised B\u00fcchi language associated to B = {B1, . . . , Bk} as\ngenB\u00fcchi\u0393(B) = {w \u2208 \u0393\u03c9 | Inf(w) \u2229Bi 6= \u2205 for all i \u2208 {1, . . . , k}}.\nWe say that a language L \u2286 \u0393\u03c9 is a generalised B\u00fcchi language if there is a family of sets B = {B1, . . . , Bk} such that L = genB\u00fcchi\u0393(B). Generalised coB\u00fcchi. Given k non-empty subsets B1, . . . , Bk \u2286 \u0393, we define the generalised coB\u00fcchi language associated to B = {B1, . . . , Bk} as\ngenCoB\u00fcchi\u0393(B) = {w \u2208 \u0393\u03c9 | Inf(w) \u2229Bi = \u2205 for some i \u2208 {1, . . . , k}}.\nWe say that a language L \u2286 \u0393\u03c9 is a generalised coB\u00fcchi language if there is a family of sets B = {B1, . . . , Bk} such that L = genCoB\u00fcchi\u0393(B).\nI Remark A.1. Deterministic generalised B\u00fcchi (resp. generalised coB\u00fcchi) automata have the same expressive power than deterministic B\u00fcchi (resp. coB\u00fcchi) automata: they recognise languages of parity index at most [0, 1] (resp. [1, 2]).\nWe will also define conditions that depend on the structure of the transition system and not only on the set of colours.\nGeneralised weak transition systems. Let TS = (GTS ,AccTS) be a transition system using a parity condition AccTS = (\u03b3, [dmin, dmax], parity). We say that TS is Weakd if in each strongly connected component S \u2286 GTS there are at most d different colours that appear, that is, |\u03b3(ES)| \u2264 d, where ES is the set of edges of S.\nAs for the rest of conditions, we say that a transition system TS is Weakd type if there exists an isomorphic parity transition system TS \u2032 ' TS that is Weakd.\nThe adjective Weak has typically been used to refer to the condition corresponding to a partition of TS into accepting and rejecting SCC. A run will be accepting if the component it finally stays in is accepting. It corresponds to Weak1 with our notation.\nAs we will show (Corollary A.11), the notation is justified by the fact that an \u03c9-regular language of parity index Weakd can be recognised by a deterministic Weakd automaton.\nThe Zielonka tree of generalised acceptance conditions\nI Definition A.2. Let T be a tree T with nodes partitioned into round nodes and square nodes. We say that T has:\nB\u00fcchi shape if it has a single branch, height at most 2, and if it has height 2 its root is round. coB\u00fcchi shape if it has a single branch, height at most 2, and if it has height 2 its root is square. Generalised B\u00fcchi shape if it has height at most 2, and if it has height 2 its root is round. Generalised coB\u00fcchi shape if it has height at most 2, and if it has height 2 its root is square.\nI Proposition A.3. Let F \u2286 2\u0393+ be a family of non-empty subsets. Then Muller\u0393(F) is a B\u00fcchi (resp. coB\u00fcchi) language if and only if ZF has B\u00fcchi (resp. coB\u00fcchi) shape."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 83",
            "text": "Proof. This is just a special case of Proposition 6.4. J\nI Proposition A.4. Let F \u2286 2\u0393+ be a family of non-empty subsets. Then Muller\u0393(F) is a generalised B\u00fcchi (resp. coB\u00fcchi) language if and only if ZF has generalised B\u00fcchi (resp. generalised coB\u00fcchi) shape.\nProof. We do the proof for the case generalised B\u00fcchi (symmetric for generalised coB\u00fcchi). Suppose that Muller\u0393(F) = genB\u00fcchi\u0393(B) for some family B = {B1, . . . , Bk}. Then, \u0393 \u2208 F , as \u0393 \u2229Bi 6= \u2205, so the root of ZF is round. If C \u2286 \u0393 is rejecting, C \u2229Bi = \u2205 for all i, then it the same for any subset C \u2032 \u2286 C, so square nodes of ZF are leaves and ZF has height at most 2.\nConversely, suppose that ZF has height 2 and that its root is round (\u0393 \u2208 F). Let A1, . . . , Ak be the labels of the k leaves of ZF and define Bi = Ai. We claim that Muller\u0393(F) = genB\u00fcchi\u0393(B), for B = {B1, . . . , Bk}. Indeed, if C \u2208 F if and only if C * Ai for any i if and only if C \u2229Bi 6= \u2205 for all i. J\nI Corollary A.5. Let A be a deterministic generalised B\u00fcchi (resp. generalised coB\u00fcchi) automaton recognising a Muller language L = Muller\u03a3(F). There is a deterministicgeneralised B\u00fcchi (resp. generalised coB\u00fcchi) automaton recognising L with just one state, that can be computed in polynomial time in the size of the representation of A.\nProof. We do the proof for the case generalised B\u00fcchi. By Remark A.1, the parity index of L is at most [0, 1], so by Proposition 6.13, the Zielonka tree of F has generalised B\u00fcchi shape. Therefore, by Proposition A.4, L is a generalised B\u00fcchi that can be trivially recognised by a generalised B\u00fcchi automaton with just one state.\nThe acceptance condition of such automaton can be deduced in linear time from the Zielonka tree ZF , as indicated in the proof of Proposition A.4. The Zielonka tree ZF can be computed from the original automaton A using a similar argument than in the proof of Theorem 6.31. Suppose that the generalised B\u00fcchi condition used by A is given by the sets B1, . . . , Bk \u2286 \u0393. Then, for each i \u2208 {1, . . . , k} we compute the restriction of A to the transitions using colours in \u0393 \\Bi, and perform a decomposition in SCCs of the obtained graph. If \u03a3S \u2286 \u03a3 is the set of input letters appearing in one of those SCC, then \u03a3S /\u2208 F . We put all the subsets of letters obtained in that way in a list altSets. The leaves of ZF correspond then to the maximal subsets of altSets. J\nACD and typeness for generalised acceptance conditions\nI Definition A.6. Let TS be a Muller transition system with a set of states V . We say that its alternating cycle decomposition ACDTS is a:\nB\u00fcchi ACD if it is a [0, 1]-parity ACD. coB\u00fcchi ACD if it is a [1, 2]-parity ACD. Generalised B\u00fcchi ACD if for every state v \u2208 V , the tree Tv has generalised B\u00fcchi shape. Generalised coB\u00fcchi ACD if for every state v \u2208 V , the tree Tv has generalised coB\u00fcchi shape. Weakd ACD if it is a parity ACD and trees of ACDTS have height at most d.\nI Remark A.7. ACDTS is a Weakd ACD if and only if it is a [0, d]-parity ACD and a [1, d+ 1]-parity ACD.\nI Proposition A.8. A transition system TS is B\u00fcchi (resp. coB\u00fcchi) type if and only if ACDTS is a B\u00fcchi ACD (resp. coB\u00fcchi ACD).\n84\nProof. This is a special case of Proposition 6.11. J\nI Proposition A.9. A transition system TS is generalised B\u00fcchi (resp. generalised coB\u00fcchi) type if and only if ACDTS is a generalised B\u00fcchi ACD (resp. generalised coB\u00fcchi ACD).\nProof. The result follows by applying the same argument and construction than in Proposition A.4, using as set of output colours the set of edges of TS. J\nI Proposition A.10. A transition system TS is Weakd type if and only if ACDTS is a Weakd ACD.\nProof. Proposition 6.11 already provides that TS is parity type if and only if ACDTS is a parity ACD. As in the proof of the aforementioned proposition, we observe that TS and ACDparity(TS) are isomorphic. If ACDTS is a Weakd ACD, then ACDparity(TS) is Weakd. Conversely, if ACDTS is not a Weakd ACD, then TS contains a (d+ 1)-flower, so the number of colours cannot be reduced (using the same argument as in the proof of Theorem 5.31). J\nI Corollary A.11. If L \u2286 \u03a3\u03c9 is an \u03c9-regular language of parity index Weakd, then L can be recognised by a deterministic Weakd automaton.\nProof. Let L be of parity index Weakd. By definition, L is recognised by parity automaton A using colours in [0, d] (it is also recognised by an automaton using colours in [1, d + 1]; we make an arbitrary choice). We will prove that A is in fact Weakd. We will show that its ACD ACDA is Weakd type, which allows to conclude by Proposition A.10. Suppose that this was not the case, that is, that some tree of ACDA has height at least d+ 1. In this case, A would contain a (d+ 1)-flower (Lemma 5.39), so by the Flower Lemma 2.16, L has parity index at least [0, d] or [1, d+ 1], a contradiction. J\nThe following result generalises [5, Theorem 2].\nI Corollary A.12. A Muller transition system is Weakd type if and only if it is both [0, d] and [1, d+ 1]-parity type.\nDeterministic automata using generalised acceptance conditions\nI Corollary A.13. Let GA be the underlying graph of a deterministic automaton. There are [0, d \u2212 1] and [1, d]-parity conditions Accp,0 and Accp,1 such that L(GA,Accp,0) = L(GA,Accp,1) if and only if there is a Weakp condition AccW such that L(GA,AccW ) = L(GA,Accp,0) = L(GA,Accp,1).\nI Proposition A.14. Let A be a deterministic Muller automaton, and suppose that L(A) can be recognised by a deterministic B\u00fcchi (resp. coB\u00fcchi) automaton; that is, the parity index of L(A) is at most [0, 1] (resp. at most [1, 2]). Then, A is generalised B\u00fcchi type (resp. generalised coB\u00fcchi type).\nProof. We prove the result for the case generalised B\u00fcchi (analogous for coB\u00fcchi). We can suppose that all the states of A are accessible, as we can define a trivial acceptance condition in the part of A that is not accessible. Since L(A) has parity index at most [0, 1], the trees of the ACD of A have height at most 2, and trees of height 2 are positive (the root is a round node), by Proposition 6.13, so it is a generalised B\u00fcchi ACD, and by Proposition A.9, A is generalised B\u00fcchi type. J"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 85",
            "text": "Parity index from automata in normal form\nI Corollary A.15. Let A be a deterministic parity automaton in normal form using colours in [0, d \u2212 1] (resp. [1, d]) such that all its states are accessible. If A is Weakd\u22121, then the parity index of L(A) is Weakd\u22121. If not, the parity index of L(A) is [0, d\u2212 1] (resp. [1, d]).\nProof. We suppose that A uses colours in [0, d\u2212 1] (in particular, it is not negative). If A in not Weakd\u22121, there is a SCC containing all the colours [0, d \u2212 1]. By Proposition 6.29, such SCC contains a positive d-flower, so by the Flower Lemma 2.16, the parity index of L(A) is [0, d\u2212 1].\nSuppose now that A is Weakd\u22121. Let ` be a cycle of A in which the colour d\u2212 1 occurs. By Proposition 6.29, ` contains a negative (d \u2212 1)-flower. As A is not negative, it also contains a positive (d\u2212 1)-flower. By the Flower Lemma 2.16, the parity index of L(A) is Weakd\u22121. J\nI Corollary A.16. Let A be a deterministic parity automaton such that all its states are accessible and the parity index of L(A) is [0, d\u22121] (resp. [1, d] / Weakd). Then, A is [0, d\u22121] (resp. [1, d] / Weakd)-parity type.\nProof. We suppose that L(A) has parity index [0, d\u2212 1] (the other cases are similar). By the Flower Lemma 2.16, A does not contain any negative d-flower. By Proposition 6.13, the trees of the ACD of A have height at most d, and trees of height d are positive. That is, ACDA is a [0, d\u2212 1]-parity ACD and we conclude by applying Proposition 6.11. J\nB Transformations for games\nGames suitable for transformations\nAs we have indicated throughout the paper, defining transformations not preserving determinism in the case of games poses certain formal challenges. This difficulties appear both when such transformations arise as the product G nA of a game G by an non-deterministic automaton A, or when they are witnessed by an HD mapping \u03d5 : G \u2192 G\u2032. The problem comes from the fact that the semantics of non-determinism in automata (or history-determinism of morphisms) are inherently asymmetric, and this asymmetry needs to be made compatible with the semantics of games. The choices we have made to overcome this technical difficulty are:\nRestrict transformations of games to games in a standard form, which we have called games suitable for transformations. Add a restriction to HD mappings in the case of games, introducing the notion of HD-for-games mapping.\nThe main motivation for the standard form of games that we propose comes from viewing games as originating from logical formulas. Indeed, an equivalent model for games can be given as follows: vertices in the game graph are not partitioned into Eve\u2019s and Adam\u2019s nodes, instead, we assign a boolean formula to each transition that determines an interaction between the two players. The outcome of this interaction is (1) the next vertex, and (2) the output colour of the acceptance condition. We can obtain a game of the kind we have defined in this paper by unfolding the boolean formulas of the transitions. There is a natural way to standardize such games: putting the boolean formulas in disjunctive normal form (DNF). Then, the unfolding of a game with formulas in DNF yields a game in which the partition into Eve-Adam nodes induces a bipartite graph with a particular structure: first,\n86\nAdam chooses an uncoloured transition leading to a vertex controlled by Eve (with only one ingoing transition), and then Eve picks a transition producing some output colour.\nWe recall that a game is suitable for transformations if it verifies that for every edge e = v \u2212\u2192 v\u2032, if v is controlled by Adam, then e is uncoloured (\u03b3(e) = \u03b5), v\u2032 \u2208 VEve, and e is the only incoming edge to v\u2032 (In(v\u2032) = {e}).\nGames in this form have an asymmetric structure that makes them suitable for any type of transformation. As any pair of consecutive transitions are of the form v \u03b5\u2212\u2192 v\u0303 c\u2212\u2192 v\u2032, with v\u0303 \u2208 VEve, we can force it so that if a decision needs to be made in a product, Eve is the one who makes it.\nI Lemma B.1. For every game G with vertices V and edges E, there exists a game G\u0303 that is suitable for transformations, of size |G\u0303| = O(|E|), and equivalent to G in the following sense: there is an injective function f : V \u2192 V\u0303 such that Eve wins G from v if and only if she wins G\u0303 from f(v).\nProof. We define G\u0303 as follows. We let its set of vertices be V\u0303 = V \u222a E. Vertices of the form v \u2208 V will correspond to vertices coming from G, and vertices e \u2208 E will be intermediate vertices added to force the suitability for transformations property. We let V\u0303Adam = VAdam and V\u0303Eve = VEve \u222a E. If e = v\nc\u2212\u2192 v\u2032 is an edge in G, we add the edges v \u03b5\u2212\u2192 e and e c\u2212\u2192 v\u2032 to G\u2032. It is clear that G\u0303 is suitable for transformations and that Eve wins G from v if and only if she wins G\u0303 from v. J\nACD-HD-Rabin-transform-for-games\nAs discussed in Section 5.3, the ACD-HD-Rabin-transform of a game G does not always induce an HD-for-games mapping \u03d5 : ACDRabin(G) \u2192 G, and G and ACDRabin(G) do not necessarily have the same winner. This is to be expected, as the ACD-HD-Rabin-transform does not take into account the partition into Eve and Adam nodes. In this paragraph we propose a small modification on the transformation to obtain a correct transformation for games.\nLet G be a game. If there is an edge v \u2212\u2192 v\u2032 with v \u2208 VAdam, we say that v\u2032 is an A-successor. We remark that if G is suitable for transformations, an A-successor is controlled by Eve and has a unique predecessor. We let VA-succ be the set of A-successor of G and Vnormal = V \\ VA-succ. If G is suitable for transformations, for each v \u2208 VA-succ we let pred(v) be its unique predecessor.\nThe idea to define the ACD-HD-Rabin-transform-for-games ACDgameparity(G) is the following: starting from the regular ACD-HD-Rabin-transform ACDRabin(G), we make some local changes to vertices that are A-successors. First, if v \u2208 VAdam, we replace edges of the form (v, x)\nn\u2212\u2192 (v\u2032, x\u2032) in ACDRabin(G) by (v, x)\n\u03b5\u2212\u2192 (v\u2032, x) (we forbid Adam to choose how to update the ACD-component). If such an edge is followed by (v\u2032, x\u2032) n \u2032\n\u2212\u2192 (v\u2032\u2032, x\u2032\u2032) in ACDRabin(G), then we add (v\u2032, x) n\u2212\u2192 (v\u2032\u2032, x\u2032\u2032) to ACDgameparity(G) (we note that v\u2032 \u2208 VEve). That is, Eve chooses retroactively how to update the ACD-components performing two consecutive updates. We note that the node n\u2032 is not output in the new game; this is not a problem, since n must be an ancestor of n\u2032 (we could say that n contains more information regarding the acceptance condition). I Remark B.2. Let G be a game suitable for transformations, let v \u2208 VAdam and v\ne1\u2212\u2192 v\u2032 e2\u2212\u2192 v\u2032\u2032 be a path of size 2 in G from v. It holds:\nIf some cycle ` contains e2, it also contains e1. Tv\u2032 is a subtree of Tv."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 87",
            "text": "Let n1 \u2208 Leaves(Tv) and n2 = JumpTv\u2032 (n1,Supp(n1, e1)). Then, Supp(n2, e2)) is a descendant of Supp(n1, e1)) in Tv\u2032 .\nI Definition B.3 (ACD-HD-Rabin-transform-for-games). Let G be a Muller game suitable for transformations. For each vertex v \u2208 V we let \u03b7v : Leaves(Tv) \u2192 {1, . . . , rbw(Tv)} be a mapping satisfying Property (?) from Lemma 4.39. We define the ACD-HD-Rabin-transformfor-games of G to be the Rabin transition system ACDgameparity(G) defined as follows.\nVertices. The set of vertices is V\u0303 = \u22c3\nv\u2208Vnormal\n{v} \u00d7 [1, rbw(Tv)] \u222a \u22c3\nv\u2208VA-succ\n{v} \u00d7 [1, rbw(Tpred(v))].\nPlayers partition. A vertex (v, x) belongs to Eve if and only if v belongs to Eve in G.\nInitial vertices. I\u0303 = {(v0, x) | v0 \u2208 I and x \u2208 {1, . . . , rbw(Tv0)}}.\nEdges and output colours. Let e = v \u2212\u2192 v\u2032 in G. If v \u2208 VEve \u2229Vnormal, we add (v, x)\nn\u2212\u2192 (v\u2032, x\u2032) to ACDgameparity(G) exactly in the same cases as in the regular ACD-HD-Rabin-transform. If v \u2208 VAdam, we let (v, x)\n\u03b5\u2212\u2192 (v\u2032, x) in E\u0303 for each x \u2208 {1, . . . , rbw(Tv)}. If v \u2208 VA-succ, we add (v, x)\nn\u2212\u2192 (v\u2032, x\u2032) to ACDgameparity(G) if in the regular ACD-HDRabin-transform there is a path of size 2 of the form\n(pred(v), x) n\u2212\u2192 (v, x\u0303) n\u0303\u2212\u2192 (v\u2032, x\u2032).\nFormally, E\u0303 = \u22c3\ne=v\u2212\u2192v\u2032\u2208E v\u2208Vnormal\n{e} \u00d7 Leaves(Tv) \u222a \u22c3\ne=v\u2212\u2192v\u2032\u2208E v\u2208VA-succ\n{e} \u00d7 Leaves(Tpred(v)).\nRabin condition. R = {(Gn, Rn)}n\u2208Nodes\u00a9(ACDTS), where Gn and Rn are defined as follow: Let n be a round node, and let n\u2032 be any node in Nodes(ACDTS),{\nn\u2032 \u2208 Gn if n\u2032 = n, n\u2032 \u2208 Rn if n\u2032 6= n and n is not an ancestor of n\u2032.\ny\nCorrectness of the ACD-HD-Rabin-transform-for-games\nI Proposition 5.29 (Correctness of the ACD-HD-Rabin-transform-for-games). Let G be a Muller game suitable for transformations, and let ACDgameparity(G) be its ACD-HD-Rabin-transform-forgames. There is an HD-for-games mapping \u03d5 : ACDgameparity(G)\u2192 TS.\nProof. The proof is analogous to that of the correctness of the regular ACD-HD-Rabintransform (Proposition 5.25). We define the mapping \u03d5 : ACDgameparity(G)\u2192 G as \u03d5V (v, x) = v and \u03d5E(e, l) = e. It is clear that it is a weak morphism, and it preserve accepting runs by Lemma 5.26 and Remark B.2.\nWe define a resolver (r0, r) simulating \u03d5 in a similar way as in the proof of Proposition 5.25: We use ACDparity(G) to guide the resolver. Let \u03c1 = v0 \u2212\u2192 v1re . . . be a run in G, and let (v0, l0) \u2212\u2192 (v1, l1) \u2212\u2192 . . . be the preimage of this run in ACDparity(G). We simulate \u03c1 in ACDgameparity(G) as follows: We ensure that at every moment i, if vi /\u2208 VA-succ, the current vertex (vi, xi) is such that xi = \u03b7vi(li). There distinguish two cases to simulate the edge ei = vi \u2212\u2192 vi+1:\n88\nIf vi \u2208 VAdam, there is a single outgoing edge from (vi, xi) mapped to the edge vi \u2212\u2192 vi+1 in \u03c1: (vi, xi)\n\u03b5\u2212\u2192 (vi+1, xi). This must be the edge picked by the resolver If vi \u2208 VEve, we pick the edge (vi, xi)\nni\u2212\u2192 (vi+1, xx+1) such that xi+1 = \u03b7li+1 and ni = Supp(li, ei).\nIf vi \u2208 VA-succ, the vertex (vi, xi) will verify xi = xi\u22121 = \u03b7vi(li). In this case, we pick the edge (vi, xi) ni\u2212\u2192 (vi+1, xx+1) such that xi+1 = \u03b7li+1 and ni = Supp(li, ei). This is indeed an edge appearing in ACDgameparity(G), as the path (vi\u22121, xi\u22121) n\u2032i\u22121\u2212\u2212\u2212\u2192 (vi, x\u2032i)\nni\u2212\u2192 (vi+1, xx+1) exists in the regular ACDRabin(G), with x\u2032i = \u03b7vi(li).\nThe resolver obtained in this way is sound for ACDgameparity(G), as there is a unique way to simulate edges issued from Adam vertices, and the rest of the edges are simulated in the same way as the resolver defined for the regular ACD-HD-Rabin-transform, which we proved to be sound. J\nOptimality of the ACD-HD-Rabin-transform-for-games\nI Corollary 5.34. Let G be a Muller game suitable for transformations whose states are accessible and let G\u0303 be a Rabin game. If G\u0303 admits an HD-for-games mapping \u03d5 : G\u0303 \u2192 G, then, |ACDgameparity(G)| \u2264 2|G\u0303|.\nProof. The vertices of ACDgameparity(G) corresponding to vertices in Vnormal are exactly the same that those in ACDRabin(G):\n{(v, x) \u2208 ACDgameparity(G) | v \u2208 Vnormal} = {(v, x) \u2208 ACDRabin(G) | v \u2208 Vnormal}.\nMoreover, for v \u2208 VA-succ, there is one vertex of the form (v, x) for each vertex (pred(v), x), and each v \u2208 VA-succ has exactly one predecessor in Vnormal, so we conclude that:\n|ACDgameparity(G)| \u2264 2 \u00b7 |{(v, x) \u2208 ACD game parity(G) | v \u2208 Vnormal}| \u2264 2 \u00b7 |ACDRabin(G)| \u2264 2 \u00b7 G\u2032,\nwhere the last inequality follows from Theorem 5.33. J\nC Simplifications for prefix-independent conditions\nWe prove in this appendix results applying to automata recognising prefix-independent languages and games using prefix-independent winning conditions. We recall that a language L \u2286 \u03a3\u03c9 is prefix-independent if for all w \u2208 \u03a3\u03c9 and u \u2208 \u03a3\u2217, uw \u2208 L if and only if w \u2208 L.\nI Lemma 2.5. Let A be a history-deterministic automaton recognising a prefix-independent language and using as acceptance set a prefix-independent language. For any state q of A that is reachable using some sound resolver, it is verified that A recognises the same language if we fix q as initial state, that is, L(A) = L(Aq). Moreover, Aq is also history-deterministic. In particular, if A is deterministic, this is the case for any reachable state q.\nProof. Let (r0, r) be a sound resolver for A such that q is reachable using (r0, r) (there is a word w0 \u2208 \u03a3\u2217 and a run \u03c10 = r0 w0 q induced by r over w). We first show that L(Aq) \u2286 L(A). Let w \u2208 \u03a3\u03c9 be a word accepted from q. Then, w0w admits an accepting run from the original initial state (by prefix-independence of the acceptance set), so w0w \u2208 L(A), and by the prefix-independence of L(A), w \u2208 L(A) too.\nFor the converse direction, we define a sound resolver (r\u20320, r\u2032) for Aq. We let r\u20320 = q, and r\u2032(\u03c1, a) = r(\u03c10\u03c1, a) be the strategy that acts as the resolver r assuming that \u03c10 has"
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 89",
            "text": "happened in the past. It is clear that for every word w \u2208 \u03a3\u03c9, the run induced by (r\u20320, r\u2032) over w has a common suffix with the run induced by (r0, r) over w0w. Therefore, by the prefix-independence assumptions:\nw \u2208 L(A) \u21d0\u21d2 w0w is accepted using (r0, r) \u21d0\u21d2 w0w is accepted using (r\u20320, r\u2032). J\nI Lemma 3.14. Let TS and TS \u2032 be two TS such that all their states are accessible, and let \u03d5 : TS \u2192 TS \u2032 be an HD (resp. HD-for-games) mapping between them. If W and W\u2032 are prefix-independent, the mapping \u03d5 is also HD (resp. HD-for-games) when considered between the transition systems TSV and TS \u2032V \u2032 , consisting of the transition systems TS and TS \u2032 where all the states are set to be initial.\nProof. First, \u03d5 : TSV \u2192 TS \u2032V \u2032 is trivially a weak morphism. We claim that it preserves accepting runs. Let v \u2208 V be a state in TS and let \u03c1 = v w be an accepting run from v. Since all the states are reachable, there is some v0 \u2208 I and finite run \u03c1v = v0 u v. Since \u03d5 is a weak morphism we have that \u03d5Runs (\u03c1v\u03c1) = \u03d5(v0) u\u2032 \u03d5(v) w \u2032 . It is verified:\nw \u2208W W pref-indep.=\u21d2 uw \u2208W =\u21d2 u\u2032w\u2032 \u2208W\u2032 W\u2032 pref-indep.=\u21d2 w\u2032 \u2208W\u2032,\nwhere the central implication follows from the fact that \u03d5 preserves accepting runs between TS and TS \u2032. Therefore \u03d5Runs (\u03c1) is also an accepting run.\nIn the rest of the proof we suppose that \u03d5 is an HD-for-games mapping, (which covers the HD case). Let (rInit, r) be a resolver sound for TS simulating \u03d5 : TS \u2192 TS \u2032. We define a resolver (r\u0303Init, r\u0303) for the new mapping. For every state v of TS, we fix a finite run \u03c1v \u2208 PathfinI (TS) ending in v that is consistent with (rInit, r) over some \u03c1\u2032, if such a run exists. We let VReach \u2286 V be the set of vertices for which \u03c1v is well-defined. We note that for each v\u2032 \u2208 V \u2032 there exists at least one v \u2208 \u03d5\u22121(v\u2032) such that v \u2208 VReach; indeed, if \u03c1\u2032v\u2032 is a finite run reaching v\u2032 in TS \u2032, one such v is Target(rRuns (\u03c1\u2032v\u2032)) (that is, the vertex to which we arrive in TS when simulating \u03c1\u2032v\u2032 via the original resolver). We let r\u0303Init(v\u2032) be this vertex. If e\u2032 \u2208 Out(v\u2032) is an edge in TS \u2032, we let r\u0303(\u03b5, e\u2032) = r(\u03c1v, e\u2032), for v = r\u0303Init(v\u2032). For \u03c1 a non-empty finite run starting in v \u2208 VReach and e\u2032 \u2208 E\u2032, we define r\u0303(\u03c1, e\u2032) = r(\u03c1v\u03c1, e\u2032). If \u03c1 starts in v /\u2208 VReach we let r\u0303(\u03c1, e\u2032) be any edge in \u03d5\u22121(e\u2032) (if e\u2032 \u2208 Out(\u03d5(Target(\u03c1))) we pick it in Out(Target(\u03c1))). We check that (r\u0303Init, r\u0303) satisfies the four requirements to be a resolver:\n1. r\u0303Init(v\u2032) has been chosen in \u03d5\u22121(v\u2032). 2. r\u0303(e\u2032) is chosen in \u03d5\u22121(e\u2032). 3. Let e\u2032 \u2208 Out(v\u2032). We have defined r\u0303(\u03b5, e\u2032) = r(\u03c1v, e\u2032), where \u03c1v is a finite run consistent\nwith r ending in v = rInit(v\u2032). By Property 4 of a resolver, r(\u03c1v, e\u2032) \u2208 Out(v). 4. Let \u03c1 = v0 v \u2208 Runfin(TSV ) and e\u2032 \u2208 Out(\u03d5(v)). If v0 /\u2208 VReach, then we have picked\nr\u0303(\u03c1, e\u2032) in Out(v). If v0 \u2208 VReach, then r\u0303(\u03c1, e\u2032) = r(\u03c1v0\u03c1, e\u2032); as \u03c1v0\u03c1 is a run ending in v and r verifies Property 4 of a resolver r(\u03c1v0\u03c1, e\u2032) \u2208 Out(v).\nFinally, we show that (r\u0303Init, r\u0303) is sound for TS. Let \u03c1\u2032 = v\u2032 w\u2032 \u2208 Run(TS \u2032V \u2032) be an accepting run, and let \u03c1 = v w \u2032 be a run consistent with (r\u0303Init, r\u0303) over \u03c1\u2032. In particular, v = r\u0303Init(v\u2032). Let \u03c1v = v0 u v be the chosen run reaching v and let \u03c1\u2032v = v\u20320 u\u2032 v\u2032 be a finite run in Runfin(TS \u2032) such that \u03c1v is consistent with (rInit, r) over \u03c1\u2032v. It is immediate to check that \u03c1v\u03c1 is consistent with (rInit, r) over \u03c1\u2032v\u03c1\u2032. Since \u03c1\u2032 is accepting, we have that w\u2032 \u2208W\u2032, and by prefix-independence of the acceptance sets and the fact that \u03c1v\u03c1 is accepting if \u03c1\u2032v\u03c1\u2032 is, we have:\nw\u2032 \u2208W\u2032 =\u21d2 u\u2032w\u2032 \u2208W\u2032 =\u21d2 uw \u2208W =\u21d2 w \u2208W,\n90\nso we conclude that \u03c1 is accepting in TS, as we wanted to show. J\nD Simplifying automata with duplicated edges\nGiven an automaton A = (Q,\u03a3, I,\u0393, \u03b4,W) we say that it has duplicated edges if there are some pair of states q, q\u2032 \u2208 Q and two different transitions between them labelled with the same input letter: q a:\u03b1\u2212\u2212\u2192 q\u2032, q a:\u03b2\u2212\u2212\u2192 q\u2032.\nAs commented in Remark 4.44, the construction of the ZT-HD-Rabin-automaton we have presented potentially introduces duplicated edges, which can be seen as an undesirable property (even if some automata models such as the HOA format [2] allow them). We show next that we can always derive an equivalent automaton without duplicated edges. Intuitively, in the Rabin case, if we want to merge two transitions having as output letters \u03b1 and \u03b2, we add a fresh letter (\u03b1\u03b2) to label the new transition. For each Rabin pair, this new letter will simulate the best of either \u03b1 or \u03b2 depending upon the situation.\nI Proposition D.1 (Simplification of automata). Let A be a Muller (resp. Rabin) automaton presenting duplicated edges. There exists a Muller (resp. Rabin) automaton A\u2032 on the same set of states without duplicated edges such that L(A) = L(A\u2032). Moreover, if A is history-deterministic, A\u2032 can be chosen history-deterministic. In the Rabin case, the number of Rabin pairs is also preserved.\nProof. For the Rabin case, let A\u2032 be an automaton that is otherwise as A except that instead of the transitions \u2206 of A it only has one a-transition q a:x\u2212\u2212\u2192 q\u2032 \u2208 \u2206\u2032 (with a fresh colour x per transition) per state-pair q, q\u2032 and letter a \u2208 \u03a3. That is, \u2206\u2032 = {(q, a, xj , q\u2032) : (q, a, y, q\u2032) \u2208 \u2206 for some y}. The new Rabin condition {(G\u20321, R\u20321), . . . , (G\u2032r, R\u2032r)} is defined as follows. For each transition q a:x\u2212\u2212\u2192 q\u2032:\nx \u2208 G\u2032i if q a:y\u2212\u2212\u2192 q\u2032 \u2208 \u2206 for some y \u2208 Gi, x \u2208 R\u2032i if for all q a:y\u2212\u2212\u2192 q\u2032 \u2208 \u2206, y \u2208 Ri.\nWe claim that L(A\u2032) = L(A). Indeed, if u \u2208 L(A), as witnessed by some run \u03c1 and a Rabin pair (Gi, Ri), then the corresponding run \u03c1\u2032 in A\u2032 over u is also accepted by the Rabin pair (G\u2032i, R\u2032i): the transitions of Inf(\u03c1) \u2229 Gi induce transitions of Inf(\u03c1\u2032) \u2229 G\u2032i and the fact that Inf(\u03c1) \u2229Ri = \u2205 guarantees that Inf(\u03c1\u2032) \u2229R\u2032i = \u2205.\nConversely, if u \u2208 L(A\u2032) as witnessed by a run \u03c1\u2032 and Rabin pair (G\u2032i, R\u2032i), then there is an accepting run \u03c1 over u in A: such a run can be obtained by choosing for each transition q a:x\u2212\u2212\u2192 q\u2032 of \u03c1\u2032 where x \u2208 G\u2032i a transition q a:y\u2212\u2212\u2192 q\u2032 \u2208 \u2206 such that y \u2208 Gi, which exists by definition of A\u2032, for each transition q a:x\u2212\u2212\u2192 q\u2032 where x /\u2208 Gi \u222a Ri a transition q q,y\u2212\u2212\u2192 q\u2032 \u2208 \u2206 such that y /\u2208 Ri, which also exists by definition of A\u2032, and for other transitions q a:x\u2212\u2212\u2192 q\u2032 (that is, those for which x \u2208 R\u2032i) an arbitrary transition q a:y\u2212\u2212\u2192 q\u2032 \u2208 \u2206. Since \u03c1\u2032 is accepting, we have Inf(\u03c1\u2032) \u2229Gi 6= \u2205 and Inf(\u03c1) \u2229Ri = \u2205, that is, \u03c1 is also accepting. For the Muller case, the argument is even simpler. As above, we consider A\u2032 that is otherwise like A except that instead of the transitions \u2206 of A, it only has one a-transition q\na:x\u2212\u2212\u2192 q\u2032 \u2208 \u2206\u2032 (with a fresh colour per transition) per state-pair q, q\u2032 and the accepting condition is defined as follows. A set of transitions T is accepting if and only if for each t = q a:x\u2212\u2212\u2192 q\u2032 \u2208 T there is a non-empty set St \u2286 {q a:y\u2212\u2212\u2192 q\u2032 \u2208 \u2206} such that \u22c3 t\u2208T St is accepting in A. In other words, a set of transitions in A\u2032 is accepting if for each transition we can choose a non-empty subset of the original transitions in A that form an accepting run in A."
        },
        {
            "heading": "A. Casares, T. Colcombet, N. Fijalkow and K. Lehtinen 91",
            "text": "We claim that L(A\u2032) = L(A). Indeed if u \u2208 L(A), as witnessed by some run \u03c1, the run \u03c1\u2032 that visits the same sequence of states in A\u2032 is accepting as witnessed by the transitions that occur infinitely often in \u03c1.\nConversely, assume u \u2208 L(A\u2032), as witnessed by a run \u03c1\u2032 and a non-empty subset St for each transitions t that occurs infinitely often in \u03c1\u2032 such that \u22c3 t\u2208Inf(\u03c1) St is accepting in A. Then there is an accepting run \u03c1 over u in A that visits the same sequence of states as \u03c1\u2032 and chooses instead of a transition t \u2208 Inf(\u03c1) each transition in St infinitely often, and otherwise takes an arbitrary transition. The set of transitions \u03c1 visits infinitely often is exactly \u22c3 t\u2208Inf(\u03c1) St, and is therefore accepting.\nFinally, observe that in both cases, if A is HD, then the automaton A\u2032 without duplicate edges is also HD since A\u2032 is obtained from A by merging transitions. Indeed, the resolver r of A induces a resolver r\u2032 for A\u2032 by outputting the unique transition with the same letter and state-pair as r. By the same argument as above, the run induced by r\u2032 is accepting if and only if the run induced by r is. J\nI Example D.2. The ZT-HD-Rabin-automaton from Figure 13 has duplicated transitions. In Figure 18 we present an equivalent HD Rabin automaton without duplicates. For this, we have merged the self-loops in state 1 labelled with a and b respectively. We have added the output colours (\u03b1\u03b2) and (\u03b8\u03be). The new Rabin pairs are given by:\nG\u2032\u03b2 = {\u03b2, (\u03b1\u03b2)}, R\u2032\u03b2 = {\u03b1, \u03bb, \u03be, \u03b6}, G\u2032\u03bb = {\u03bb}, R\u2032\u03bb = {\u03b1, \u03b2, (\u03b1\u03b2), \u03b8}.\nE Proofs for Section 6.1.1\nProof of Propositions 6.2 and 6.3. We prove it for the Rabin case, being Streett conditions the dual notion.\nIf all round nodes of ZF = (N = N\u00a9 tN , , \u03bd : N \u2192 2\u0393+) have at most one child, we define a family of Rabin pairs R = {(Gn, Rn) | n \u2208 N\u00a9} such that Rabin(R) = Muller(F) as follows: for each round node n \u2208 N\u00a9, we add a Rabin pair (Gn, Rn). We let Gn = \u0393\\\u03bd(n). In order to define Rn, we observe that n has at most one child n\u2032, and we define Rn = \u03bd(n)\\\u03bd(n\u2032), for n\u2032 the only child of n, if it exists, or Rn = \u03bd(n) if n has no children at all. This is, the pair (Gn, Rn) accepts the sets of colours A \u2286 \u0393 that contain some of the colours that disappear in the step n \u2192 n\u2032 and none of the colours appearing up in the tree. We show that Rabin(R) = Muller(F). Let A be a set of colours. If A \u2208 F , let n be a maximal node (for ) containing A. It is a round node and there is some colour c \u2208 A not appearing in the only child of n. Therefore, c \u2208 Gn and A \u2229Rn = \u2205. Conversely, if A /\u2208 F , then for every round node n with a child n\u2032, either A \u2286 \u03bd(n\u2032) (and therefore A\u2229Gn = \u2205) or A * \u03bd(n) (and in that case A \u2229Rn 6= \u2205).\n92\nWe remark that this construction uses more Rabin pairs than necessary, since we could reuse Rabin pairs for nodes that are in the same level and that are not siblings.\nConversely, suppose that Muller(F) = Rabin(R) for the Rabin language associated to R = {(G1, R1), . . . , (Gr, Rr)}. If n \u2208 ZF is a round node (A = \u03bd(n) \u2208 F), then its label A contains some colours that belongs to Gi1 , . . . , Gik and none belonging to Ri1 , . . . , Rik for some i1, . . . , ik, k \u2265 1. A child of n must not have these colours, so the only maximal subset of A that is not in F is A \\ (Gi1 \u222a \u00b7 \u00b7 \u00b7 \u222aGik ). J\nProof of Proposition 6.4. We suppose \u0393 \u2208 F (minF = 0), the other case is symmetric. Suppose that ZF has a single branch of length maxF +1. We define a mapping \u03c6 : \u0393\u2192 [0,maxF ] as follows: for each colour c \u2208 \u0393 we let nc be the deepest node in ZF containing c, and we define \u03c6(c) = \u03bd(nc). It is easy to check that for all w \u2208 \u0393\u03c9, w \u2208 Muller(F) if and only if \u03c6(w) \u2208 parity.\nConversely, suppose that we can assign colours to the elements of \u0393 by \u03c6 : \u0393 \u2192 [0, d], whose corresponding parity language is Muller(F). We show that any node of the Zielonka tree ZF has at most one child. Indeed, let n \u2208 N and let c \u2208 \u03bd(n) such that \u03c6(c) = min{\u03c6(c) | c \u2208 \u03bd(n)}. We suppose that \u03c6(c) is odd (the proof is symmetric for \u03c6(c) even). Let p = min{\u03c6(c\u2032) | c\u2032 \u2208 \u03bd(n) and \u03c6(c\u2032) even}. In every child of n the elements with a smaller colour than p must disappear, so the set of elements \u03bd(n) \u2229 {c \u2208 \u0393 | \u03c6(c) \u2265 p} is the only maximal subset of \u03bd(n) belonging to F . Moreover, in the label of the child of n there is at least one colour less, so the height of ZF will be at most d+ 1. J"
        }
    ],
    "title": "From Muller to Parity and Rabin Automata: Optimal Transformations Preserving (History-)Determinism ",
    "year": 2023
}