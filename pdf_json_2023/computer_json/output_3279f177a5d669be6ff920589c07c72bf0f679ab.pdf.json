{
    "abstractText": "We propose a hybrid joint source-channel coding (JSCC) scheme, in which the conventional digital communication scheme is complemented with a generative refinement component to improve the perceptual quality of the reconstruction. The input image is decomposed into two components: the first is a coarse compressed version, and is transmitted following the conventional separation based approach. An additional component is obtained through the diffusion process by adding independent Gaussian noise to the input image, and is transmitted using DeepJSCC. The decoder combines the two signals to produce a high quality reconstruction of the source. Experimental results show that the hybrid design provides bandwidth savings and enables graceful performance improvement as the channel quality improves.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xueyan Niu"
        },
        {
            "affiliations": [],
            "name": "Xu Wang"
        },
        {
            "affiliations": [],
            "name": "Deniz G\u00fcnd\u00fcz"
        },
        {
            "affiliations": [],
            "name": "Bo Bai"
        },
        {
            "affiliations": [],
            "name": "Weichao Chen"
        },
        {
            "affiliations": [],
            "name": "Guohua Zhou"
        }
    ],
    "id": "SP:7de976d49dfaa253db39db4206bcd4652d7d31b5",
    "references": [
        {
            "authors": [
                "C.E. Shannon"
            ],
            "title": "A mathematical theory of communication",
            "venue": "The Bell System Technical Journal, vol. 27, no. 3, pp. 379\u2013423, 1948.",
            "year": 1948
        },
        {
            "authors": [
                "A. Goldsmith"
            ],
            "title": "Joint source/channel coding for wireless channels",
            "venue": "IEEE Vehicular Techn. Conf., 1995, pp. 614\u2013618.",
            "year": 1995
        },
        {
            "authors": [
                "S. Vembu",
                "S. Verdu",
                "Y. Steinberg"
            ],
            "title": "The source-channel separation theorem revisited",
            "venue": "IEEE Trans. Inf. Theory, vol. 41, no. 1, 1995.",
            "year": 1995
        },
        {
            "authors": [
                "V. Kostina",
                "S. Verd\u00fa"
            ],
            "title": "Lossy joint source-channel coding in the finite blocklength regime",
            "venue": "IEEE Trans. Inf. Theory, vol. 59, no. 5, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "F. Zhai",
                "Y. Eisenberg",
                "A. Katsaggelos"
            ],
            "title": "Joint Source-Channel Coding for Video Communications",
            "venue": "Elsevier Inc,",
            "year": 2005
        },
        {
            "authors": [
                "D. G\u00fcnd\u00fcz",
                "Z. Qin",
                "I.E. Aguerri",
                "H.S. Dhillon",
                "Z. Yang",
                "A. Yener",
                "K.K. Wong",
                "C.-B. Chae"
            ],
            "title": "Beyond transmitting bits: Context, semantics, and task-oriented communications",
            "venue": "IEEE Journal on Selected Areas in Communications, vol. 41, no. 1, pp. 5\u201341, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "E. Bourtsoulatze",
                "D. Burth Kurka",
                "D. G\u00fcnd\u00fcz"
            ],
            "title": "Deep joint sourcechannel coding for wireless image transmission",
            "venue": "IEEE Trans. on Cognitive Comms. and Netw., vol. 5, no. 3, pp. 567\u2013579, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "D.B. Kurka",
                "D. G\u00fcnd\u00fcz"
            ],
            "title": "Bandwidth-agile image transmission with deep joint source-channel coding",
            "venue": "IEEE Transactions on Wireless Communications, vol. 20, no. 12, pp. 8081\u20138095, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "T.-Y. Tung",
                "D. G\u00fcnd\u00fcz"
            ],
            "title": "DeepWiVe: Deep-learning-aided wireless video transmission",
            "venue": "IEEE Journal on Selected Areas in Communications, vol. 40, no. 9, pp. 2570\u20132583, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M. Wang",
                "Z. Zhang",
                "J. Li",
                "M. Ma",
                "X. Fan"
            ],
            "title": "Deep joint sourcechannel coding for multi-task network",
            "venue": "IEEE Signal Processing Letters, vol. 28, pp. 1973\u20131977, 2021.",
            "year": 1973
        },
        {
            "authors": [
                "M. Yang",
                "C. Bian",
                "H.-S. Kim"
            ],
            "title": "OFDM-guided deep joint source channel coding for wireless multipath fading channels",
            "venue": "IEEE Transactions on Cognitive Communications and Networking, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Shao",
                "D. Gunduz"
            ],
            "title": "Semantic communications with discrete-time analog transmission: A PAPR perspective",
            "venue": "IEEE Wireless Communications Letters, vol. 12, no. 3, pp. 510\u2013514, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "H. Wu",
                "Y. Shao",
                "K. Mikolajczyk",
                "D. G\u00fcnd\u00fcz"
            ],
            "title": "Channel-adaptive wireless image transmission with OFDM",
            "venue": "IEEE Wireless Communications Letters, vol. 11, no. 11, pp. 2400\u20132404, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J. Sohl-Dickstein",
                "E. Weiss",
                "N. Maheswaranathan",
                "S. Ganguli"
            ],
            "title": "Deep unsupervised learning using nonequilibrium thermodynamics",
            "venue": "Int\u2019l Conf. on Machine Learning (ICML), Jul 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J. Ho",
                "A. Jain",
                "P. Abbeel"
            ],
            "title": "Denoising diffusion probabilistic models",
            "venue": "Advances in Neural Info. Proc. Sys. (NeurIPS), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Song",
                "S. Ermon"
            ],
            "title": "Generative modeling by estimating gradients of the data distribution",
            "venue": "Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "Improved techniques for training score-based generative models",
            "venue": "Advances in Neural Inf. Proc. Sys. (NeurIPS), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "P. Dhariwal",
                "A. Nichol"
            ],
            "title": "Diffusion models beat GANs on image synthesis",
            "venue": "Advances in Neural Inf. Proc. Sys. (NeurIPS), 2021, pp. 8780\u20138794.",
            "year": 2021
        },
        {
            "authors": [
                "T. Goblick"
            ],
            "title": "Theoretical limitations on the transmission of data from analog sources",
            "venue": "IEEE Trans. Inf. Theory, vol. 11, no. 4, 1965.",
            "year": 1965
        },
        {
            "authors": [
                "E. Erdemir",
                "T.-Y. Tung",
                "P.L. Dragotti",
                "D. Gunduz"
            ],
            "title": "Generative joint source-channel coding for semantic image transmission",
            "venue": "arXiv, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "venue": "Medical Image Comp. and Computer-Assisted Inter., 2015.",
            "year": 2015
        },
        {
            "authors": [
                "Y. Blau",
                "T. Michaeli"
            ],
            "title": "Rethinking lossy compression: The ratedistortion-perception tradeoff",
            "venue": "Int\u2019l Conf. on Mach. Learning (ICML), Jun 2019, pp. 675\u2013685.",
            "year": 2019
        },
        {
            "authors": [
                "X. Niu",
                "D. G\u00fcnd\u00fcz",
                "B. Bai",
                "W. Han"
            ],
            "title": "Conditional rate-distortionperception trade-off",
            "venue": "2023 IEEE International Symposium on Information Theory (ISIT). IEEE, 2023, pp. 1074\u20131079.",
            "year": 2023
        },
        {
            "authors": [
                "Y. Hamdi",
                "D. G\u00fcnd\u00fcz"
            ],
            "title": "The rate-distortion-perception trade-off with side information",
            "venue": "2023 IEEE International Symposium on Information Theory (ISIT). IEEE, 2023, pp. 1056\u20131061.",
            "year": 2023
        },
        {
            "authors": [
                "J. Liu",
                "S. Shao",
                "W. Zhang",
                "H.V. Poor"
            ],
            "title": "An indirect rate-distortion characterization for semantic sources: General model and the case of gaussian observation",
            "venue": "IEEE Trans. Comms., vol. 70, no. 9, 2022.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Semantic communication, joint source-channel coding, diffusion model, wireless network.\nI. INTRODUCTION\nThe fast increasing demand for wireless transmission of high-resolution image and video signals poses a challenge to current communication systems, as emerging applications such as metaverse, augmented/virtual reality (AR/VR), Internetof-things (IoT), vehicular-to-everything (V2X), require more robust transmission and realistic reconstruction of video in a fast-varying wireless communication environment with limited bandwidth resources. State-of-the-art (SOTA) digital communication systems are designed based on Shannon\u2019s sourcechannel separation theorem [1], which implies that there is no loss of optimality by applying separate source coding followed by channel coding, in the asymptotic infinite block length regime and for ergodic source and channel statistics. In reality, these idealized assumptions are rarely met [2]; and therefore, the separation-based digital communication systems do not operate at the theoretical optimal [3], especially in the finite block-length regime [4]. Moreover, separation-based digital communication suffers from sudden quality drop when the channel (signal-to-noise ratio) SNR drops below a certain threshold, known as the \u201ccliff effect\u201d, which requires operating well below the instantaneous channel capacity over timevarying wireless channels.\nJoint source-channel coding (JSCC) has long been studied as an alternative approach to improve the end-to-end performance in practical systems. Indeed, JSCC predates separation based digital transmission approaches, as analog and frequency modulation (AM/FM) are JSCC schemes based on direct modulation of the continuous-time input signal onto the\ncarrier waveform. Later, also in the discrete-time communication framework, JSCC has been shown to outperform purely separate approaches in image and video transmission tasks, particularly in the limited bandwidth scenarios and to provide more resilience to channel variations [2], [5]. More recently, in the context of semantic communications [6], deep learning based JSCC methods, e.g., DeepJSCC, have shown remarkable results thanks to their ability to learn the mapping directly from the training data (for both source and channel) [7]\u2013 [13]. Unlike the separation-based digital transmission schemes, JSCC-based methods directly map the image pixel values to channel input symbols. Through end-to-end training, the encoder and decoder pair learn to operate under various channel conditions.\nThe hybrid communication scheme proposed in this paper envisions a system that inherits the advantages of both digital and joint encoding schemes. By integrating the JSCC-based communication into the digital communication infrastructure, which has already been widely deployed, this method aims to provide bandwidth savings while delivering content with higher perceptual quality more robustly over unreliable wireless channels. We send a low-resolution digitally compressed version of the input image first by following the conventional separation-based digital communication approach. Then, we send a refinement component obtained through the diffusion process using DeepJSCC [7], to improve the perceptual quality of the reconstructed image. Inspired by the success of a class of image generation techniques known as diffusion models [14], [15], in particular, the score-based diffusion models [16], [17], the refinement information is obtained by slowly adding white noise to the signal such that the source distribution is transformed to a Gaussian shape after the Markov chain of diffusion steps. Compared to other image generation methods, notably generative adversarial networks (GANs), diffusion based image generation exhibits better image sample quality [18]. Moreover, since the diffusion process results in an approximately Gaussian signal, we exploit the optimality of \u2018analog/uncoded\u2019 transmission of Gaussian sources over Gaussian channel [19], and transmit this part using JSCC. Experimental results show that using the same bandwidth and power resources, compared to using only digital transmission, the proposed method achieves performance gain in terms of the reconstruction quality while also providing graceful imar X iv :2 30 8. 08 24 4v 1\n[ cs\n.I T\n] 1\n6 A\nug 2\n02 3\nprovement of the performance as the channel SNR increases, while the quality of the pure digital transmission does not increase once the compression rate is fixed."
        },
        {
            "heading": "II. PROBLEM FORMULATION",
            "text": "We consider image transmission over a wireless channel with limited bandwidth and a transmitter power constraint. Consider images of height H , width W , and C color channels. The input image is represented by a real-valued vector x \u2208 Rn, where n = H \u00b7W \u00b7C. The transmitter maps the input image x into a complex-valued vector v \u2208 Ck to be transmitted over the noisy channel. The ratio \u03c1 = k/n is defined as the bandwidth ratio in the JSCC literature, which indicates the average number of channel symbols available for each source symbol. We use capital letters such as X to denote random variables, lower-case letters such as x to denote corresponding (vector) instances. In practice, an average power constraint is also imposed on the transmitter: 1/kE[V V \u2217] \u2264 1. Let v\u0302 \u2208 Ck denote the channel output corrupted by channel noise. The receiver estimates the input image based on v\u0302. Let x\u0302 \u2208 Rn denote the reconstructed image at the receiver. The quality of the reconstruction is measured by some specified distortion measure between the original image and the reconstruction. The goal of wireless image transmission is to design a system that optimizes the performance of the reconstruction under limited bandwidth and power resources."
        },
        {
            "heading": "A. Separation-Based Digital Transmission",
            "text": "In current digital transmission systems, image compression and channel coding are separately performed. The sourceencoded data is transmitted through the wireless channel after channel coding and modulation. Images are first compressed using established codecs such as JPEG and JEPG2000, which consist of sequentially applying some transform coding to\nthe image pixels, e.g., discrete cosine transform (DCT) or discrete wavelet transform (DWT), followed by quantization and entropy coding. Channel coding follows immediately, as an ideal source coding is not resilient to channel errors. SOTA channel codes include Turbo, low density parity check (LDPC) and polar codes. These codes are known to perform close to the Shannon capacity in the large blocklength regime. The encoded bitstream is then mapped to some discrete input constellation, such as 16-QAM and 64-QAM, which maps the bit sequence to complex-valued channel symbols to be transmitted over the wireless channel.\nThe receiver reverses these procedures by first demodulating and decoding the channel code, trying to mitigate any impact of the channel noise, and the decompressor is applied afterwards to reconstruct the original input image. The demodulator, channel decoder, and decompressor are chosen to match the forward modules in the encoding process. The source and channel coding rates and the modulation scheme are chosen jointly according to the channel condition and the source characteristics to minimize the end-to-end distortion, which is caused by both the errors over the channel and the quantization in source coding."
        },
        {
            "heading": "III. HYBRID TRANSMISSION FRAMEWORK",
            "text": "In this section, we will introduce the proposed hybrid transmission scheme that benefits from both the accuracy of the separation-based digital communication system and the efficiency and robustness of the JSCC scheme."
        },
        {
            "heading": "A. Model Description",
            "text": "A diagram of the system model is shown in Fig. 1. Consider the input signal X with sample space consisting of images (real-valued vectors) in Rn. In the hybrid framework, the signal X is decomposed into the pair (Z,XT ) = f\u03b8(X),\nwhere Z represents a generic compressed version of X such that H(Z) \u226a H(X0), i.e., the number of bits required to represent Z is much smaller than that for X .\nThe coarse compressed component z is transmitted in the conventional digital manner (e.g., LDPC code + 16-QAM) to obtain a complex-valued channel input vd = fd(z) \u2208 Ckd , where kd is the dimension of the channel input for digital transmission.\nThe complementary component XT is obtained by following a forward diffusion process, where X0 = X , and Xt is corrupted from t = 0 to t = T using independent additive Gaussian noise at each step, so that xT \u2208 Rks approximately follows a Gaussian distribution. Moreover, by integrating convolutional layers into the neural network of the diffusion model, the dimension of the data is reduced. This final result of the diffusion process is transmitted directly over the channel, by first pairing the real outputs to form complex channel inputs. We denote the corresponding channel input by vs \u2208 Cks . Overall, the channel input is obtained by the concatenation of the digital and diffusion-based joint encoded components, V = [VdVs], for which the bandwidth ratio is given by \u03c1 = (kd + ks)/n. We also allocate the available power between the two streams Vd and Vs to optimize the performance.\nThrough end-to-end training, the decoder learns a reverse diffusion process that recovers the signal at t = 0 from t = T . So, after receiving (V\u0302d, V\u0302s), the receiver first recovers Z\u0302 and X\u0302T , and then generates a reconstruction Y = g\u03d5(Z\u0302, X\u0302T ), where g\u03d5 is a pre-trained neural network reversing a conditional diffusion process."
        },
        {
            "heading": "B. Decomposition of the Source Signal",
            "text": "In principle, the compression Z can be obtained using an arbitrary compression scheme. Arguably, the most common image compression algorithm is the JPEG standard. When applying the JPEG compression, the input image is first divided into small tiles, then the DCT transform is applied, and the resulting coefficients are quantized with a pre-defined quantization table. The level of quantization can be chosen to achieve different reconstruction qualities. When less number of bits are used, the reconstructed image becomes more blurred. In our setting, Z can be a coarse compression of X with very low number of bits per pixel.\nRecent research shows that the JSCC scheme combined with a generative model for reconstruction can achieve significant\nbandwidth reduction, while significantly improving the perceptual quality of the reconstruction [20]. While a pretrained generative model based on GANs is employed in [20], here we will use a diffusion process, which has shown remarkable generative capability in a series of recent papers [16], [17].\nThe forward diffusion process is undertaken to encode the refinement information with the following Gaussian transition kernel:\npt(xt|xt\u22121) = N (xt; \u221a 1\u2212 \u03b2txt\u22121, \u03b2tI). (1)\nFurthermore, Xt can be sampled directly according to the cumulative kernal [15], such that\nXt = \u221a \u03b1\u0304tX0 + \u221a 1\u2212 \u03b1\u0304t\u03f5, (2)\nwhere \u03b1\u0304t = \u220ft s=1(1\u2212 \u03b2s) and \u03f5 \u223c N (0, I)."
        },
        {
            "heading": "C. Channel Transmission",
            "text": "The additive white Gaussian noise (AWGN) channel is adopted in this work, as it has been widely used to represent realistic wireless channel conditions. The channel input signals are transmitted through the noisy channel with the following transfer function\n\u03b7n(V ) = V + n, (3)\nwhere n is the additive independent and identically distributed (i.i.d.) Gaussian noise signal, n \u223c CN (0, \u03c32I), and \u03c32 is the average noise power. We enforce a total average power constraint such that\n1 n E[VdV \u2217 d + VsV \u2217 s ] \u2264 1. (4)\nThe quality of the communication channel is measured by the average SNR, defined as SNR = 10 log10 1 \u03c32 .\nNotably, since the signal XT approximately follows a Gaussian distribution, it is expected that transmitting it over the AWGN in an \u2018analog/uncoded\u2019 fashion is more efficient, since it is known that the uncoded transmission of i.i.d. Gaussian samples over an AWGN channel achieves the optimal performance despite operating over a finite block lengnth [19]. Here, instead of the channel coding/decoding and channel modulation/demodulation, a pair of joint source-channel encoder and decoder is trained in an end-to-end fashion, treating the AWGN channel as a non-trainable layer represented by the transfer function \u03b7n with a range of SNR values."
        },
        {
            "heading": "D. Neural Network Architecture",
            "text": "As shown in Fig. 2, for the diffusion model, we use the common U-net architecture [21] with adaptations [16], which consists of multiple 2D convolution layers. We use positional embedding to encode the time step t. Each embedder block consists of a goup norm, a sigmoid block, and a linear layer that incorporates t and the conditional information from the digital transmission.\nThe objective of the training is to obtain a high-quality reconstruction y \u223c PY of the realization x0 \u2208 Rn in the same sample space at the decoder\u2019s end. The quality of the reconstruction is traditionally evaluated using distortion measures such as the peak signal-to-noise ratio (PSNR). Other measures, such as the structural similarity index (SSIM), and the learned perceptual image patch similarity (LPIPS) have been shown to better capture the perceptual quality of the construction, which is a major focus of semantic communications [6].\nIn a recently developed theory of the rate-distortionperception trade-off [22]\u2013[24], the perceptual quality is measured by the discrepancy between the probability distributions of the input data and the reconstruction. In addition, the semantic information XT can be viewed as a latent variable, following the line of research in [25]. Therefore, the model is trained to minimize the average distortion between the input X\nand its reconstructions Y as well as the distance between the input distribution PX and the output distribution PY capturing the perceptual quality, i.e.,\nmin \u03b8,\u03d5\n\u03bb1Ep(x,y)[d(X,Y )] + \u03bb2L(PX , PY ), (5)\nwhere d(\u00b7, \u00b7) and L(\u00b7, \u00b7) represent the distortion metric and the perceptual loss. The digital transmission stream ensures a reasonable accuracy of the reconstruction using distortion metrics, while the forward and reverse diffusion processes operates directly on the probability distributions, which improve the perceived visual quality of the reconstruction."
        },
        {
            "heading": "IV. SIMULATION RESULTS",
            "text": "We evaluate the performance of the proposed hybrid digitalsemantic communication framework under difference channel SNRs on the MNIST database, which contains 60,000 training images and 10,000 testing images of hand-written digits. The dimension of the images is N = 28 \u00d7 28 \u00d7 1 (height, width, channels). The first column of Fig. 3 are examples of the original images.\nFor the digital transmission stream, we concatenate the JPEG compression with LDPC codes, QAM modulation, and AWGN channel sequentially. We implemented combinations of 4-QAM, 16-QAM, and 64-QAM modulation schemes and LDPC codes with corresponding rates. Examples of recovered images after compression, channel coding, modulation, and their reversals are shown in the second column of Fig. 3. For fair comparison, we stripped the header information for JPEG when computing the source coding rates.\nFor the semantic transmission stream, we train the model on the AWGN channel with SNR = 10dB. The batchsize during the training is set as 64 and the learning rate is 1e\u22124. The reconstructed images at the receiver combining the digital and semantic datastreams are shown in the third column of Fig. 3.\nWe further test the pre-trained system under different channel conditions with SNR = 10, 20, 30(dB). The results are presented in Fig. 4. At the same bandwidth compression level, the hybrid scheme significantly improves the reconstruction quality in terms of PSNR, SSIM, and LPIPS. In comparison to the digital transmission scheme, when PSNR = 21, the hybrid scheme provides a bandwidth reduction of 33.3%; when SSIM = 0.83, the hybrid scheme provides a bandwidth reduction of 47.2%. Moreover, when testing under different channel SNRs (dashed lines), the performances do not suffer from the \u201ccliff effect\u201d, which indicates an improved robustness of the transmission under channel variation.\nWe note here that the current results are limited to the MNIST dataset mainly due to the difficulty of training the neural network associated with the diffusion model. These should be treated as promising initial results, and more complex datasets using more efficient training techniques is currently under investigation."
        },
        {
            "heading": "V. CONCLUSION AND FUTURE WORK",
            "text": "We propose a novel image transmission scheme that combines the SOTA digital communication with the emerging semantic communication utilizing recent developments in diffusion-based generative modeling. The hybrid scheme provides bandwidth savings while providing graceful performance improvement with channel SNR. There are several interesting directions for future research. First, current hybrid framework is designed for and evaluated on AWGN channels. Future investigations will include extensions to other channel models, including fading channels. Second, the proposed algorithm is designed for image transmission. In principle, other types of data, such as video and audio, can also be transmitted using the same framework. Third, efficient algorithms for power\nallocation between the digital and semantic signals with power division rather than time division shall be investigated."
        }
    ],
    "title": "A Hybrid Wireless Image Transmission Scheme with Diffusion",
    "year": 2023
}