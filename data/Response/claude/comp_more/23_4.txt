 Here are 5 potential future research directions based on the paper:

1. Investigate more effective methods for knowledge reviewing to elicit even more relevant knowledge from PLMs. The current prompting methods show promise but there may be room for improvement. 

2. Explore how to handle incorrect or biased knowledge stored in PLMs. The paper notes knowledge rumination may amplify existing errors, so methods to detect and mitigate this could be valuable.

3. Apply knowledge rumination to more diverse tasks beyond text classification and commonsense reasoning, such as open-domain QA, summarization, translation etc. Further demonstrate its generalizability.  

4. Study how to better integrate elicited knowledge into different model architectures. The paper focuses on injecting into FFN but other approaches like attention mechanisms could be explored.

5. Analyze what types of knowledge are best recalled by different prompting techniques. A detailed understanding could allow more customized prompting. Also analyze what knowledge is still missing to guide further pretraining.