{
    "abstractText": "3D object recognition has successfully become an appealing research topic in the real-world. However, most existing recognition models unreasonably assume that the categories of 3D objects cannot change over time in the real-world. This unrealistic assumption may result in significant performance degradation for them to learn new classes of 3D objects consecutively, due to the catastrophic forgetting on old learned classes. Moreover, they cannot explore which 3D geometric characteristics are essential to alleviate the catastrophic forgetting on old classes of 3D objects. To tackle the above challenges, we develop a novel Incremental 3D Object Recognition Network (i.e., InOR-Net), which could recognize new classes of 3D objects continuously via overcoming the catastrophic forgetting on old classes. Specifically, a category-guided geometric reasoning is proposed to reason local geometric structures with distinctive 3D characteristics of each class by leveraging intrinsic category information. We then propose a novel critic-induced geometric attention mechanism to distinguish which 3D geometric characteristics within each class are beneficial to overcome the catastrophic forgetting on old classes of 3D objects, while preventing the negative influence of useless 3D characteristics. In addition, a dual adaptive fairness compensations strategy is designed to overcome the forgetting brought by class imbalance, by compensating biased weights and predictions of the classifier. Comparison experiments verify the state-of-the-art performance of the proposed InOR-Net model on several public point cloud datasets.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jiahua Dong"
        },
        {
            "affiliations": [],
            "name": "Yang Cong"
        },
        {
            "affiliations": [],
            "name": "Lixu Wang"
        },
        {
            "affiliations": [],
            "name": "Lingjuan Lyu"
        },
        {
            "affiliations": [],
            "name": "Jun Li"
        },
        {
            "affiliations": [],
            "name": "Ender Konukoglu"
        }
    ],
    "id": "SP:aca010fea9ad1641ba15f0b0b39886e05ca4805d",
    "references": [
        {
            "authors": [
                "J. Stria",
                "V. Hlav\u00e1c"
            ],
            "title": "Classification of hanging garments using learned features extracted from 3d point clouds",
            "venue": "2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2018, pp. 5307\u2013 5312.",
            "year": 2018
        },
        {
            "authors": [
                "X. Roynard",
                "J.-E. Deschaud",
                "F. Goulette"
            ],
            "title": "Paris-lille-3d: A point cloud dataset for urban scene segmentation and classification",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, June 2018, pp. 2108\u201321 083.",
            "year": 2018
        },
        {
            "authors": [
                "A. Behl",
                "O. Hosseini Jafari",
                "S. Karthik Mustikovela",
                "H. Abu Alhaija",
                "C. Rother",
                "A. Geiger"
            ],
            "title": "Bounding boxes, segmentations and object coordinates: How important is recognition for 3d scene flow estimation in autonomous driving scenarios?",
            "venue": "The IEEE International Conference on Computer Vision (ICCV),",
            "year": 2017
        },
        {
            "authors": [
                "J. Dong",
                "Y. Cong",
                "G. Sun",
                "B. Zhong",
                "X. Xu"
            ],
            "title": "What can be transferred: Unsupervised domain adaptation for endoscopic lesions segmentation",
            "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020, pp. 4022\u20134031.",
            "year": 2020
        },
        {
            "authors": [
                "C.R. Qi",
                "H. Su",
                "K. Mo",
                "L.J. Guibas"
            ],
            "title": "Pointnet: Deep learning on point sets for 3d classification and segmentation",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017, pp. 77\u201385.",
            "year": 2017
        },
        {
            "authors": [
                "C.R. Qi",
                "L. Yi",
                "H. Su",
                "L.J. Guibas"
            ],
            "title": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space",
            "venue": "Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds. Curran Associates, Inc., 2017, pp. 5099\u20135108.",
            "year": 2017
        },
        {
            "authors": [
                "Y. Li",
                "R. Bu",
                "M. Sun",
                "W. Wu",
                "X. Di",
                "B. Chen"
            ],
            "title": "Pointcnn: Convolution on x-transformed points",
            "venue": "Advances in Neural Information Processing Systems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, Eds. Curran Associates, Inc., 2018, pp. 820\u2013830.",
            "year": 2018
        },
        {
            "authors": [
                "S. Lan",
                "R. Yu",
                "G. Yu",
                "L.S. Davis"
            ],
            "title": "Modeling local geometric structure of 3d point clouds using geo-cnn",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2019, pp. 998\u20131008.",
            "year": 2019
        },
        {
            "authors": [
                "X. Yan",
                "C. Zheng",
                "Z. Li",
                "S. Wang",
                "S. Cui"
            ],
            "title": "Pointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 5589\u20135598.",
            "year": 2020
        },
        {
            "authors": [
                "W. Yu",
                "H. Yu",
                "Y. Huang",
                "L. Wang"
            ],
            "title": "Generalized inter-class loss for gait recognition",
            "venue": "Proceedings of the 28th ACM international conference on multimedia, 2022, pp. 141\u2013150.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Li",
                "D. Hoiem"
            ],
            "title": "Learning without forgetting",
            "venue": "Computer Vision \u2013 ECCV 2016, B. Leibe, J. Matas, N. Sebe, and M. Welling, Eds. Cham: Springer International Publishing, 2016, pp. 614\u2013629.",
            "year": 2016
        },
        {
            "authors": [
                "S.-A. Rebuffi",
                "A. Kolesnikov",
                "G. Sperl",
                "C.H. Lampert"
            ],
            "title": "icarl: Incremental classifier and representation learning",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017, pp. 5533\u20135542.",
            "year": 2017
        },
        {
            "authors": [
                "J. Dong",
                "L. Wang",
                "Z. Fang",
                "G. Sun",
                "S. Xu",
                "X. Wang",
                "Q. Zhu"
            ],
            "title": "Federated class-incremental learning",
            "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2022, pp. 10 164\u201310 173.",
            "year": 2022
        },
        {
            "authors": [
                "K. Wei",
                "C. Deng",
                "X. Yang"
            ],
            "title": "Lifelong zero-shot learning.",
            "venue": "in IJCAI,",
            "year": 2020
        },
        {
            "authors": [
                "F.M. Castro",
                "M.J. Marin-Jimenez",
                "N. Guil",
                "C. Schmid",
                "K. Alahari"
            ],
            "title": "End-to-end incremental learning",
            "venue": "The European Conference on Computer Vision (ECCV), September 2018, pp. 241\u2013257.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Wu",
                "Y. Chen",
                "L. Wang",
                "Y. Ye",
                "Z. Liu",
                "Y. Guo",
                "Y. Fu"
            ],
            "title": "Large scale incremental learning",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2019, pp. 374\u2013382.",
            "year": 2019
        },
        {
            "authors": [
                "Z. Yang",
                "S. Al-Dahidi",
                "P. Baraldi",
                "E. Zio",
                "L. Montelatici"
            ],
            "title": "A novel concept drift detection method for incremental learning in nonstationary environments",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 1, pp. 309\u2013320, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Dong",
                "Y. Cong",
                "G. Sun",
                "B. Ma",
                "L. Wang"
            ],
            "title": "I3dol: Incremental 3d object learning without catastrophic forgetting",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 7, pp. 6066\u2013 6074, May 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Li",
                "B.M. Chen",
                "G. Hee Lee"
            ],
            "title": "So-net: Self-organizing network for point cloud analysis",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018, pp. 9397\u20139406.",
            "year": 2018
        },
        {
            "authors": [
                "O. Ostapenko",
                "M.M. Puscas",
                "T. Klein",
                "P. J\u00e4hnichen",
                "M. Nabi"
            ],
            "title": "Learning to remember: A synaptic plasticity driven framework for continual learning",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2019, p. 11321\u201311329.",
            "year": 2019
        },
        {
            "authors": [
                "K. Wei",
                "C. Deng",
                "X. Yang",
                "M. Li"
            ],
            "title": "Incremental embedding learning via zero-shot translation",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 11, 2021, pp. 10 254\u201310 262.",
            "year": 2021
        },
        {
            "authors": [
                "C. Chen",
                "H. Wang",
                "W. Liu",
                "X. Zhao",
                "T. Hu",
                "G. Chen"
            ],
            "title": "Twostage label embedding via neural factorization machine for multi-label classification",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, no. 01, 2019, pp. 3304\u20133311.",
            "year": 2019
        },
        {
            "authors": [
                "K. Shmelkov",
                "C. Schmid",
                "K. Alahari"
            ],
            "title": "Incremental learning of object detectors without catastrophic forgetting",
            "venue": "The IEEE International Conference on Computer Vision (ICCV), Oct 2017, pp. 3400\u20133409.",
            "year": 2017
        },
        {
            "authors": [
                "H. Yu",
                "H. Peng",
                "Y. Huang",
                "J. Fu",
                "H. Du",
                "L. Wang",
                "H. Ling"
            ],
            "title": "Cyclic differentiable architecture search",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 1, pp. 211\u2013228, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J. Leo",
                "J. Kalita"
            ],
            "title": "Incremental deep neural network learning using classification confidence thresholding",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 33, no. 12, pp. 7706\u20137716, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K. Wei",
                "D. Chen",
                "Y. Li",
                "X. Yang",
                "C. Deng",
                "D. Tao"
            ],
            "title": "Incremental embedding learning with disentangled representation translation",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 1, no. 2, pp. 1\u201313, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "L. Yu",
                "X. Liu",
                "J. van de Weijer"
            ],
            "title": "Self-training for class-incremental semantic segmentation",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 1, no. 1, pp. 1\u201312, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "D.-W. Zhou",
                "Y. Yang",
                "D.-C. Zhan"
            ],
            "title": "Learning to classify with incremental new class",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 33, no. 6, pp. 2429\u20132443, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J. Kirkpatrick",
                "R. Pascanu",
                "N. Rabinowitz",
                "J. Veness",
                "G. Desjardins",
                "A.A. Rusu",
                "K. Milan",
                "J. Quan",
                "T. Ramalho",
                "A. Grabska-Barwinska",
                "D. Hassabis",
                "C. Clopath",
                "D. Kumaran",
                "R. Hadsell"
            ],
            "title": "Overcoming catastrophic forgetting in neural networks",
            "venue": "Proceedings of the National Academy of Sciences, vol. 114, no. 13, pp. 3521\u20133526, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Dong",
                "Y. Cong",
                "G. Sun",
                "Z. Fang",
                "Z. Ding"
            ],
            "title": "Where and how to transfer: Knowledge aggregation-induced transferability perception for unsupervised domain adaptation",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 1\u20131, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C. Wu",
                "L. Herranz",
                "X. Liu",
                "y. wang",
                "J. van de Weijer",
                "B. Raducanu"
            ],
            "title": "Memory replay gans: Learning to generate new categories without forgetting",
            "venue": "Advances in Neural Information Processing Systems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, Eds. Curran Associates, Inc., 2018, pp. 5962\u20135972.",
            "year": 2018
        },
        {
            "authors": [
                "E. Belouadah",
                "A. Popescu"
            ],
            "title": "DeeSIL: deep-shallow incremental learning",
            "venue": "TaskCV Workshop @ ECCV 2018., p. 151\u2013157, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "E. Belouadah",
                "A. Popescu",
                "F.M. Castro"
            ],
            "title": "Il2m: Class incremental learning with dual memory",
            "venue": "2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp. 583\u2013592.",
            "year": 2019
        },
        {
            "authors": [
                "A.A. Rusu",
                "N.C. Rabinowitz",
                "G. Desjardins",
                "H. Soyer",
                "J. Kirkpatrick",
                "K. Kavukcuoglu",
                "R. Pascanu",
                "R. Hadsell"
            ],
            "title": "Progressive neural networks",
            "venue": "arXiv preprint arXiv:1606.04671, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Rajasegaran",
                "M. Hayat",
                "S.H. Khan",
                "F.S. Khan",
                "L. Shao"
            ],
            "title": "Random path selection for continual learning",
            "venue": "Advances in Neural Information Processing Systems 32. Curran Associates, Inc., 2019, pp. 12 669\u2013 12 679.",
            "year": 2019
        },
        {
            "authors": [
                "C. Simon",
                "P. Koniusz",
                "M. Harandi"
            ],
            "title": "On learning the geodesic path for incremental learning",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 1591\u2013 1600.",
            "year": 2021
        },
        {
            "authors": [
                "X. Hu",
                "K. Tang",
                "C. Miao",
                "X.-S. Hua",
                "H. Zhang"
            ],
            "title": "Distilling causal effect of data in class-incremental learning",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2021, pp. 3957\u20133966.",
            "year": 2021
        },
        {
            "authors": [
                "J. Dai",
                "H. Qi",
                "Y. Xiong",
                "Y. Li",
                "G. Zhang",
                "H. Hu",
                "Y. Wei"
            ],
            "title": "Deformable convolutional networks",
            "venue": "arXiv preprint arXiv:1409.7495, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. Qin",
                "H. You",
                "L. Wang",
                "C.-C.J. Kuo",
                "Y. Fu"
            ],
            "title": "Pointdan: A multi-scale 3d domain adaption network for point cloud representation",
            "venue": "Advances in Neural Information Processing Systems 32. Curran Associates, Inc., 2019, pp. 7190\u20137201.",
            "year": 2019
        },
        {
            "authors": [
                "T. Cover",
                "P. Hart"
            ],
            "title": "Nearest neighbor pattern classification",
            "venue": "IEEE Transactions on Information Theory, vol. 13, no. 1, pp. 21\u201327, 1967.",
            "year": 1967
        },
        {
            "authors": [
                "Y. Song",
                "J. Huang",
                "D. Zhou",
                "H. Zha",
                "C.L. Giles"
            ],
            "title": "Iknn: Informative k-nearest neighbor pattern classification",
            "venue": "Knowledge Discovery in Databases: PKDD 2007, 2007, pp. 248\u2013264.",
            "year": 2007
        },
        {
            "authors": [
                "X. Yang",
                "C. Deng",
                "T. Liu",
                "D. Tao"
            ],
            "title": "Heterogeneous graph attention network for unsupervised multiple-target domain adaptation",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 44, no. 4, pp. 1992\u20132003, 2020. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 14, NO. 8, MARCH 2023 13",
            "year": 1992
        },
        {
            "authors": [
                "J. Zhang",
                "C. Chen",
                "B. Li",
                "L. Lyu",
                "S. Wu",
                "J. Xu",
                "S. Ding",
                "C. Wu"
            ],
            "title": "A practical data-free approach to one-shot federated learning with heterogeneity",
            "venue": "arXiv preprint arXiv:2112.12371, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "T. Shen",
                "J. Zhang",
                "X. Jia",
                "F. Zhang",
                "G. Huang",
                "P. Zhou",
                "K. Kuang",
                "F. Wu",
                "C. Wu"
            ],
            "title": "Federated mutual learning",
            "venue": "arXiv preprint arXiv:2006.16765, 2020.",
            "year": 2006
        },
        {
            "authors": [
                "J. Deng",
                "J. Guo",
                "J. Yang",
                "N. Xue",
                "I. Cotsia",
                "S.P. Zafeiriou"
            ],
            "title": "Arcface: Additive angular margin loss for deep face recognition",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 1, no. 1, pp. 4685\u20134694, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "W. Liu",
                "Y. Wen",
                "Z. Yu",
                "M. Li",
                "B. Raj",
                "L. Song"
            ],
            "title": "Sphereface: Deep hypersphere embedding for face recognition",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 212\u2013 220.",
            "year": 2017
        },
        {
            "authors": [
                "J. Fu",
                "J. Liu",
                "H. Tian",
                "Y. Li",
                "Y. Bao",
                "Z. Fang",
                "H. Lu"
            ],
            "title": "Dual attention network for scene segmentation",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 3146\u20133154.",
            "year": 2019
        },
        {
            "authors": [
                "A.X. Chang",
                "T.A. Funkhouser",
                "L.J. Guibas",
                "P. Hanrahan",
                "Q. Huang",
                "Z. Li",
                "S. Savarese",
                "M. Savva",
                "S. Song",
                "H. Su",
                "J. Xiao",
                "L. Yi",
                "F. Yu"
            ],
            "title": "Shapenet: An information-rich 3d model repository",
            "venue": "arXiv preprint arXiv:1512.03012, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "Zhirong Wu",
                "S. Song",
                "A. Khosla",
                "Fisher Yu",
                "Linguang Zhang",
                "Xiaoou Tang",
                "J. Xiao"
            ],
            "title": "3d shapenets: A deep representation for volumetric shapes",
            "venue": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 1912\u20131920.",
            "year": 2015
        },
        {
            "authors": [
                "A. Dai",
                "A.X. Chang",
                "M. Savva",
                "M. Halber",
                "T. Funkhouser",
                "M. Nie\u00dfner"
            ],
            "title": "Scannet: Richly-annotated 3d reconstructions of indoor scenes",
            "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2432\u20132443.",
            "year": 2017
        },
        {
            "authors": [
                "S. Hou",
                "X. Pan",
                "C.C. Loy",
                "Z. Wang",
                "D. Lin"
            ],
            "title": "Learning a unified classifier incrementally via rebalancing",
            "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2019, pp. 831\u2013 839.",
            "year": 2019
        },
        {
            "authors": [
                "S. Ceri",
                "A. Bozzon",
                "M. Brambilla",
                "E. Della Valle",
                "P. Fraternali",
                "S. Quarteroni"
            ],
            "title": "An Introduction to Information Retrieval",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "InOR-Net: Incremental 3D Object Recognition Network for Point Cloud Representation\nJiahua Dong, Yang Cong, Senior Member, IEEE, Gan Sun, Member, IEEE, Lixu Wang, Lingjuan Lyu, Jun Li, and Ender Konukoglu\nAbstract\u20143D object recognition has successfully become an appealing research topic in the real-world. However, most existing recognition models unreasonably assume that the categories of 3D objects cannot change over time in the real-world. This unrealistic assumption may result in significant performance degradation for them to learn new classes of 3D objects consecutively, due to the catastrophic forgetting on old learned classes. Moreover, they cannot explore which 3D geometric characteristics are essential to alleviate the catastrophic forgetting on old classes of 3D objects. To tackle the above challenges, we develop a novel Incremental 3D Object Recognition Network (i.e., InOR-Net), which could recognize new classes of 3D objects continuously via overcoming the catastrophic forgetting on old classes. Specifically, a category-guided geometric reasoning is proposed to reason local geometric structures with distinctive 3D characteristics of each class by leveraging intrinsic category information. We then propose a novel critic-induced geometric attention mechanism to distinguish which 3D geometric characteristics within each class are beneficial to overcome the catastrophic forgetting on old classes of 3D objects, while preventing the negative influence of useless 3D characteristics. In addition, a dual adaptive fairness compensations strategy is designed to overcome the forgetting brought by class imbalance, by compensating biased weights and predictions of the classifier. Comparison experiments verify the state-of-the-art performance of the proposed InOR-Net model on several public point cloud datasets.\nIndex Terms\u20143D object recognition, class-incremental learning, catastrophic forgetting, point cloud representation.\nI. INTRODUCTION\nOBJECT recognition technology in 3D vision has attractedwidespread attention in the various research fields. Until now, it has achieved great successes in many real-world challenging applications including intelligent robotics [1], environmental surveillance [2], autonomous driving [3], medical\nThis work was supported in part by the National Nature Science Foundation of China under Grant 62127807, 62225310, 62273333, 62133005; and in part by the State Key Laboratory of Robotics under Grant 2023-Z13. (Corresponding author: Yang Cong.)\nJiahua Dong is with the State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang 110016, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China (e-mail: dongjiahua1995@gmail.com).\nYang Cong and Gan Sun are with the State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang 110016, China (e-mail: congyang81@gmail.com, sungan1412@gmail.com).\nLixu Wang is with the Computer Science Department, Northwestern University, Evanston, USA (e-mail: lixuwang2025@u.northwestern.edu).\nLingjuan Lyu is with the Sony AI, Tokyo 108-0075, Japan (e-mail: Lingjuan.Lv@sony.com).\nJun Li is with the School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China (e-mail: junli@njust.edu.cn).\nEnder Konukoglu is with the Computer Vision Lab, ETH Zurich, Zu\u0308rich 8092, Switzerland. (e-mail: ender.konukoglu@vision.ee.ethz.ch).\ndiagnosis [4], etc. To better characterize the semantic context of unordered 3D point cloud data collected by the LiDAR system or depth camera, plenty of convolutional neural networks [5], [6] are introduced to capture discriminative 3D geometric properties and explore the task-specific representations. These convolutional architectures [7]\u2013[10] significantly improve the characterization ability on the task of 3D object recognition for point cloud representation, by encoding hierarchical local structures and spatially-local correlations.\nGenerally, the above 3D object recognition methods [5], [6], [9] are modeled in a static impractical scenario, in which the categories of 3D objects are fixed and cannot change over time. However, in the real-world applications where the novel categories of 3D objects are often collected consecutively, these methods without substantial model modifications cannot learn new 3D objects in a streaming manner, thus causing significant performance degradation on old learned 3D objects (i.e., catastrophic forgetting [11]\u2013[14]). To address it, a naive solution is to store all the training data of old and new categories, and retrain the current model again with a long delay. Nevertheless, this solution consumes high computational overhead and large memory occupancy, which is unacceptable in practical applications. For instance, the autonomous driving model [3] trained with some specific recognition scenes cannot perform well in a prior-unknown environment where new 3D objects arrive continuously, due to the lack of continuous learning capacity for new 3D objects. Moreover, some visual navigation systems and intelligent robots [1] working under a fixed application scenario may also suffer from catastrophic forgetting on previous learning experience, when collecting new 3D objects consecutively. The high computational complexity and large memory consumption make the autonomous driving model [3], visual navigation systems and intelligent robots [1] impractical to access all 3D objects of old and new categories, thus resulting in forgetting on old 3D categories.\nWhen tackling the above challenges, another feasible way is to attach a 3D point cloud feature extractor (e.g., PointNet [5], PointNet++ [6]) to existing 2D class-incremental learning models [12], [15]\u2013[17]. Unfortunately, this solution cannot effectively distinguish which 3D geometric characteristics within each class are essential to overcome the forgetting on old categories of 3D objects, due to the irregularity and deformable permutations of point cloud. The trained models fail to accurately recognize these old classes (i.e., catastrophic forgetting [13], [15]) as new 3D categories arrive consecutively, since they capture the noisy characteristics or the common geometric properties among old 3D classes with\nar X\niv :2\n30 2.\n09 88\n6v 1\n[ cs\n.C V\n] 2\n0 Fe\nb 20\n23\nsimilar structures. For instance, the above methods with PointNet [5] or PointNet++ [6] as feature extractor may highlight common structural layout among tables and chairs, but neglect the discriminative local geometric correlations within each class and further forget their characterizations under the classincremental learning settings. Consequently, it is a challenging object recognition task to learn new 3D classes consecutively while alleviating forgetting on old classes.\nTo address the aforementioned issues, we design a novel Incremental 3D Object Recognition Network (i.e., InOR-Net) for point cloud representation. The proposed InOR-Net model could not only learn new classes of 3D objects under a streaming manner, but also prevent the catastrophic forgetting on old 3D classes without using large infrastructures to store their training data. To be specific, we develop a category-guided geometric reasoning strategy, which captures the distinctive 3D characteristics within each class via constructing local geometric structures with category information as reference. Moreover, a novel critic-induced geometric attention mechanism is developed to identify which 3D geometric attributes within each class are important to prevent forgetting on old classes of 3D objects. It consists of a geometric attention network to quantify the contributions of 3D geometric characteristics, and a critical supervision network to feedback the quality of quantified contributions. To alleviate the catastrophic forgetting caused by class imbalance, we propose a dual adaptive fairness compensations strategy, which could correct the biased weights of the classifier via weight fairness compensation, and balance the biased predictions via score fairness compensation.\nThe proposed InOR-Net model achieves superior performance on three point cloud datasets, when compared with other baseline methods. In summary, we present the major contributions of this paper as follows: \u2022 We propose a novel Incremental 3D Object Recognition\nNetwork (i.e., InOR-Net) to recognize new categories of 3D objects continuously, without forgetting on old 3D categories. Our model is the first attempt to address 3D class-incremental learning in 3D object recognition field.\n\u2022 A category-guided geometric reasoning is designed to learn distinctive 3D characteristics within each class, which can be attained via exploring local geometric structures with category information as guidance.\n\u2022 We develop a novel critic-induced geometric attention mechanism to distinguish which 3D geometric characteristics within each class are important to overcome the catastrophic forgetting on old classes, while neglecting the negative influence of useless 3D characteristics.\n\u2022 A dual adaptive fairness compensations mechanism is designed to address the forgetting brought by class imbalance. It corrects the biased weights of the classifier via weight fairness compensation, and balances the biased predictions via score fairness compensation.\nThis work is a significant extension of our previous conference paper [18]. Compared with [18], some main improvements of this paper could be presented below:\n1) We ameliorate the construction manner of local geometric structures. We develop a category-guided geometric\nreasoning to reason distinctive 3D characteristics within each class by leveraging category information over all point cloud data rather than only an object used in [18].\n2) We propose a novel critic-induced geometric attention to identify which 3D geometric characteristics within each class are useful to overcome the catastrophic forgetting on old classes of 3D objects. It could not only quantify their contributions, but also evaluate the quality of contributions to feedback the positive supervision.\n3) A dual adaptive fairness compensations strategy is designed to correct the biased weights of the classifier via weight fairness compensation in the training phase, while balancing the biased predictions on new classes of 3D objects via score fairness compensation in the test phase.\n4) More comparison experiments on representative datasets illustrate the superior recognition performance of our InOR-Net model against other baseline frameworks."
        },
        {
            "heading": "II. RELATED WORK",
            "text": "A. 3D Object Recognition\nThere are many shape descriptors [6], [9] to characterize point cloud representation, but they are usually invariant to different transformations, thus the recognition task on different 3D classes cannot perform well. When Qi et al. propose to apply convolutional neural network (i.e., PointNet [5]) on point cloud data, deep learning based methods have achieved remarkable successes in 3D object recognition. For instance, PointNet++ [6], an extension version of PointNet [5], could encode hierarchical local structures of point clouds with increasing contextual scales. In addition, some permutationrobust networks [7], [19] are proposed to explore the spatiallylocal relations in the orderless point cloud data. Wu et al. [19] develop a point-to-node neighbor search mechanism to encode point cloud. Yan et al. [9] propose to eliminate the effect of outliers via an adaptive sampling. Unfortunately, the above methods suffer from large performance degradation in the real-world where the data of new 3D categories are collected consecutively."
        },
        {
            "heading": "B. Class-Incremental Learning",
            "text": "According to the methods with access to nothing, generated data or original data (i.e., exemplars) from the old classes, we divide the extensive studies about class-incremental learning [11], [16], [20], [21] on 2D image classification [22] into three categories. For example, when the training data of old classes is unavailable, [11], [23] propose the distillation strategy [24] to overcome the catastrophic forgetting on old classes. Yang et al. [17] propose a consecutive updating mechanism for concept drift detection. Leo et al. [25] develop a classification confidence threshold to selectively finetune neural network for anti-forgetting. Wei et al. [26] focus on exploring classdisentangled representations to tackle forgetting on old classes. Yu et al. [27] introduce a self-training strategy to perform continual semantic segmentation tasks with limited forgetting. [28] designs one unified framework to address continual new classes with efficient training of model parameters. Kirkpatrick et al. [29] introduce new regulators to restrict the model\u2019s\noptimization caused by new classes, which maintains its memory for old classes. In addition, different kinds of generative adversarial networks [30] are utilized by [20], [31] to produce synthetic samples for old categories.\nFor the exemplar replay, there are usually a small quantity of exemplars available for each old category [12]. In this case, class imbalance becomes a serious challenge [15], [32]. Belouadah et al. [33] provide a memory with negligible storage cost to store statistical information of old categories. With the training data of new categories arriving, [34] proposes to expand the neural network in a progressive manner. To address the large-scale class-incremental learning, Wu et al. [16] focus on correcting the deviation of new categories within the classifier network. A random path selection strategy is proposed by Rajasegaran et al. [35] to choose optimal information flow for new tasks. Simon et al. [36] ameliorate the knowledge distillation technology, and measure the similarity between previous and current responses via geodesic path. Hu et al. [37] aim to explore the causal effect between the old and new categories. However, due to the noisy permutations, missing structures and irregularity of point cloud, these methods [26]\u2013[28], [36], [37] cannot effectively distinguish which 3D geometric characteristics within each class are beneficial to prevent catastrophic forgetting on old class of 3D objects."
        },
        {
            "heading": "III. THE PROPOSED MODEL",
            "text": ""
        },
        {
            "heading": "A. Problem Definition and Overview",
            "text": "Problem Definition: For the experimental configurations about 3D class-incremental learning, we follow the standard settings widely-used in 2D field [12], [15], [16], [35]\u2013[37]. Specifically, we define the streaming training data including total S incremental states as D = {D1, D2, \u00b7 \u00b7 \u00b7 , DS}. In the s-th (s = 1, 2, \u00b7 \u00b7 \u00b7 , S) incremental state, the training subset Ds = {xsi , ysi } ns i=1 consists of ns point clouds, where xsi \u2208 RU\u00d73 is the i-th point cloud including U sampled three-dimension points, and ysi represents its one-hot category label. The labels {ysi } ns i=1 include Ks new classes in the s-th\nincremental state. They cannot overlap with Kp = \u2211s\u22121 i=1 Ki old classes that are learned in previous s \u2212 1 incremental states. The training subset {Di}Si=1 with different new classes arrives consecutively in this paper. Similar to [12], [15], [16], [35]\u2013[37], we select a small quantity of samples from Kp old classes of 3D objects to construct the exemplar set M . With access to the subset Ds and the selected exemplar set M , the prediction task is to classify both Kp old categories and Ks new categories in the s-th state. The number of exemplars from M is small (i.e., |M |/Kp ns/Ks) in our experiments.\nOverview: The graphical pipeline of our InOR-Net model is depicted in Fig. 1. First, we forward the 3D object from Ds \u222aM into the encoder E(\u00b7) to extract its low-level feature. Subsequently, the extracted feature is fed into the categoryguided geometric reasoning to capture distinctive 3D geometric characterizations within each class under the guidance of category information, and then we obtain its mid-level feature fm via optimizing Lcst. Afterwards, fm is forwarded into the critic-induced geometric attention to evaluate which 3D geometric characteristics are beneficial to overcome catastrophic\nforgetting on old classes of 3D objects, while filtering out the useless geometric information via optimizing Lcri and Lreg. We apply max-pooling function to fp with geometric attention and get a global feature fg , which is then passed into the classifier C(\u00b7) to make predictions via minimizing Lclc. Moreover, the dual adaptive fairness compensations could further compensate biased weights of the classifier and biased score predictions that are brought by class imbalance between old and new categories. Our InOR-Net model could alleviate the forgetting on old classes via remembering their distinctive 3D geometric characterizations."
        },
        {
            "heading": "B. Category-Guided Geometric Reasoning",
            "text": "Generally, each point cloud can be characterized by L local geometric structures, which correspond to L point subsets{ Pl|Pl = {p\u0302l, pl1, pl2, \u00b7 \u00b7 \u00b7 , plm \u2208 R3} }L l=1\nin the point cloud. p\u0302l is the centroid of the l-th local geometric structure Pl, and {pl1, pl2, \u00b7 \u00b7 \u00b7 , plm} are m nearest neighbor points surrounding around p\u0302l. Obviously, p\u0302l determines the location of the l-th local geometric structure Pl and its m nearest neighbor points.\nTo capture local context information, most existing researches [6], [7] utilize the random sampling or farthest point sampling strategy to select the centroids for local geometric structures {Pl}Ll=1. Though these researches guarantee that the selected centroids fully consider the entire point cloud, they cannot cover the local structures with distinctive 3D characteristics (e.g., the tail in airplane, the geometric layout in chair, etc.) that are more effective to characterize the point cloud. Moreover, they aim to explore distinctive 3D characteristics from an object, but cannot make sure that the local structures within each object can capture the discriminative category information. For example, there are many types of chairs in the real-world, which not only share the common structure layout among all kinds of chairs, but also have unique properties for each kind of chairs. However, the existing works [6], [7] focus on exploring the unique properties within each chair, while neglecting the discriminative category information (e.g., common structure layout) to distinguish the chair and other similar categories (e.g., desk, table, etc). Due to the above limitations, the performance of [6], [7] severely suffers from the noisy points (i.e., noisy local structures).\nTo address these limitations, as shown in Fig. 1, we develop the category-guided geometric reasoning, which captures local structures with distinctive 3D characteristics by considering category information over all point cloud data rather than only an object. Intuitively, for 3D class-incremental learning, these distinctive 3D geometric characteristics within each class are essential to alleviate catastrophic forgetting on old classes. To this end, we first present how to adaptively construct L local geometric structures {Pl}Ll=1, and then consider semantic category information as guidance (i.e., category-guided reasoning) to capture distinctive 3D geometric characteristics. \u2022 Local Geometric Structures Construction: [6], [7] ini-\ntialize the locations of L local geometric structures via farthest point sampling, and utilize the fixed centroids of local geometric structures to encode semantic context. Different from them, we adaptively modify the centroids of local structures (i.e., the\ngeometric offset prediction) as the training process. Compared with deformable convolution [38] using semantic features of 2D images for offset prediction, we employ the edge vectors of each local geometric structure as reference to learn geometric offset of the centroid via network itself [18], [39]. To be specific, we first quantify the semantic context of each edge as the contribution weight, and then integrate the weighted edge vectors of local geometric structures together to achieve offset prediction of the centroid. In other words, for each local geometric structure, the voting strategy of surrounding edge vectors with different contributions determines the centroid offset. Thus, given the l-th local geometric structure Pl constructed via farthest point sampling [6], [7], the geometric offset 4p\u0302l of p\u0302l is formulated as:\n4p\u0302l = 1\nm m\u2211 i=1 ( \u0393o((f\u0302l \u2212 fli); \u03b8\u0393o) \u00b7 (p\u0302l \u2212 pli) ) , (1)\nwhere \u0393o(\u00b7) transforms the semantic knowledge of edge vectors to scale contribution weights via a convolution layer, and \u03b8\u0393o denotes its parameters. (p\u0302l \u2212 pli) represents the ith local edge vector. f\u0302l \u2208 Rdp and {fli \u2208 Rdp}mi=1 are the semantic features of p\u0302l and its m nearest neighbors {pli}mi=1, respectively. dp is the feature dimension of {fli}mi=1 that are extracted via the encoder E(\u00b7), as shown in Fig. 1.\nTo update the l-th local geometric structure, we add the offset vector 4p\u0302l in Eq. (1) to the original centroid p\u0302l, and reselect m nearest neighbors {pl1, pl2, \u00b7 \u00b7 \u00b7 , plm} surrounding around the new centroid p\u0302l:\np\u0302l = p\u0302l +4p\u0302l, {pl1, pl2, \u00b7 \u00b7 \u00b7 , plm} = knn(p\u0302l|pj \u2208 R3, j = 1, \u00b7 \u00b7 \u00b7 , U), (2)\nwhere knn(\u00b7) [40], [41] is employed to search m nearest neighbors around the new p\u0302l by traversing the whole point cloud {pj}Uj=1. U is the number of points sampled from a point cloud, and we follow [5] to set U = 1024 in this paper. The semantic representation fsl \u2208 Rds of the l-th local\ngeometric structure can then be determined by encoding the representations of m nearest neighbor points:\nfsl = max i=1,2,\u00b7\u00b7\u00b7 ,m \u0393s(fli; \u03b8\u0393s), (3)\nwhere {fli}mi=1 denote the representations of m nearest neighbor points around the updated p\u0302l. ds is the feature dimension of fsl \u2208 Rds that is encoded via \u0393s(\u00b7). \u0393s(\u00b7) is a convolutional layer encoding the representations of all nearest neighbor points, and its parameters are denoted as \u03b8\u0393s . Thus, the features {fsl \u2208 Rds}Ll=1 of L local geometric structures in each point cloud can be obtained via Eq. (3). Inspired by [6], we concatenate {fsl }Ll=1 of local geometric structures as fm \u2208 RL\u00d7ds , and regard it as the low-level representations over the whole point cloud. \u2022 Category-Guided Reasoning: To further help the lo-\ncal geometric structures capture distinctive 3D characteristics within each class, we employ the global category-wise prototypes as guidance, and perform a self-supervised semantic consistency between local structures and category-wise prototypes for category-guided reasoning. To this end, as shown in Fig. 1, we perform the max-pooling operation on lowlevel representations with geometric attention (i.e., fp), and obtain its global feature fg \u2208 Rds for the whole point cloud. Given a mini-batch TB = {xsi , ysi }Bi=1(B ns) with B point clouds sampled from the s-th incremental state, the estimated category-wise prototype f\u0302kg of the k-th category is formulated as the mean feature of all global representations belonging to the k-th category (k = 1, 2, \u00b7 \u00b7 \u00b7 ,Ks +Kp) in TB :\nf\u0302kg = E(xsi ,ysi )\u2208TB [ 1\nNt B\u2211 i=1 fgi \u00b7 1arg max ysi =k], (4)\nwhere Nt = \u2211B i=1 1arg max ysi =k denotes the number of point clouds belonging to the k-th class. fgi \u2208 Rds is the i-th point cloud\u2019s global representation. To eliminate the sampling\nrandomness of mini-batch, we construct global category-wise prototype fkg for the k-th class via an exponential update:\nfkg = \u03b3f k g + (1\u2212 \u03b3)f\u0302kg , (5)\nwhere \u03b3 = 0.7 is the balanced weight. The local representations {fsl \u2208 Rds}Ll=1 and global category-wise prototypes {fkg \u2208 Rds} Ks+Kp k=1 may have some semantic heterogeneity [42]\u2013[44], so we employ convolutional networks \u0393es(\u00b7) and \u0393eg(\u00b7) to embed them into a semanticshared feature space. When the input point cloud belongs to the k-th class, we enforce the embedded representations {\u0393es(fsl ; \u03b8\u0393es) \u2208 Rdc}Ll=1 of local geometric structures to be closer to the embedded global category-wise prototype \u0393eg(f k g ; \u03b8\u0393eg ) \u2208 Rdc of the k-th class, while maximizing their dissimilarity with other embedded global prototypes {\u0393eg(f ig, \u03b8\u0393eg ) \u2208 Rdc |i 6= k} Ks+Kp i=1 via optimizing Lcst:\nLlcst = log ( 1 + \u2211 i 6=k exp ( \u03c4N (\u0393es(fsl ; \u03b8\u0393es))>N (\u0393eg(f ig; \u03b8\u0393eg ))\n\u2212 \u03c4N (\u0393es(fsl ; \u03b8\u0393es))>N (\u0393eg(fkg ; \u03b8\u0393eg )) )) ,\nLcst = E(xsi ,ysi )\u2208Ds\u222aM \u2211L l=1 Llcst, (6)\nwhere \u03b8\u0393eg and \u03b8\u0393es denote the network parameters. dc is the feature dimension of embedding space. N (x) = x\u2212mean(x)\u2016x\u2016 represents a `2 normalization function, and mean(x) denotes the mean value of x.\nBefore performing a self-supervised semantic consistency metric via Eq. (6), we first normalize the embedded representations \u0393es(fsl ; \u03b8\u0393es) and \u0393eg(f k g ; \u03b8\u0393eg ) via `2 normalization function N (\u00b7), and then utilize a scale value \u03c4 = 64 to re-scale the embedded representations. Existing works [45], [46] have shown the re-scaling strategy could stabilize the training process and make 3D characteristics within each class more discriminative. Intuitively, when minimizing Eq. (6), we enforce local geometric structures to explore unique 3D characteristics within each class, while neglecting the properties common with other classes. These distinctive 3D characteristics are essential to alleviate forgetting on old classes of 3D objects."
        },
        {
            "heading": "C. Critic-Induced Geometric Attention",
            "text": "Although the category-guided geometric reasoning could construct L discriminative local geometric structures to capture distinctive 3D characteristics, these characteristics contributes unequally to address the catastrophic forgetting on old classes. That is to say, some local geometric structures containing more common 3D characteristics may strengthen the forgetting, while the others with more distinctive 3D characteristics would alleviate the forgetting. To address this issue, as presented in Fig. 1, we develop the critic-induced geometric attention to emphasize unique 3D geometric characteristics within each class, while mitigating the forgetting caused by common 3D properties. Specifically, we first use the geometric attention network \u0393a(\u00b7) to calibrate the contributions of local geometric structures {Pl}Ll=1, and further introduce the critical supervision network \u0393c(\u00b7) as guidance to evaluate the quality of the contributions quantified via \u0393a(\u00b7). \u0393c(\u00b7) can provide positive\nsupervision to guide \u0393a(\u00b7) maximize the contribution gain, even though misleading quantification of \u0393a(\u00b7) appears. \u2022 Geometric Attention Network \u0393a(\u00b7): According to the vanilla attention strategy [47] in image understanding, we introduce a residual learning to the geometric attention network \u0393a(\u00b7). It can calibrate the weights of different geometric structures. Therefore, we obtain the final low-level semantic representation fp \u2208 RL\u00d7ds via the attention mechanism:\nfp = Am fm + fm = \u03c8s ( \u0393u(\u03c8r(\u0393d(fm; \u03b8\u0393d)); \u03b8\u0393u) ) fm + fm, (7)\nwhere Am = \u03c8s ( \u0393u(\u03c8r(\u0393d(fm; \u03b8\u0393d)); \u03b8\u0393u) ) \u2208 RL\u00d7ds represents the geometric attention (a.k.a. the contributions of local geometric structures). is the Hadamard product. \u03c8s(\u00b7) and \u03c8r(\u00b7) are the sigmoid and ReLU functions. \u0393u(\u00b7) and \u0393d(\u00b7) denote the channel-upscaling and channel-downscaling layers with the ratio as r = 4. \u03b8\u0393u and \u03b8\u0393d are their weights, which are both denoted as the parameters \u03b8\u0393a of \u0393a(\u00b7) for simplification. As shown in Fig. 1, we then perform maxpooling on fp to extract global feature fg \u2208 Rds , and forward it into C(\u00b7) for object recognition. \u2022 Critical Supervision Network \u0393c(\u00b7): As aforementioned, \u0393c(\u00b7) focuses on maximizing the gain of geometric attention Am over the basic network via a task reward strategy. To this end, as depicted in Fig. 1, the critical supervision network \u0393c(\u00b7) takes both fp and Am as the inputs. It contains two branches, i.e., a state branch with a convolutional block, a flatten operation and two fully-connected layers to extract semantic context from fp; and a policy branch with a convolutional block, a flatten operation and a fully-connected layer to encode quantified contribution Am. Afterwards, the outputs of both state and policy branches are concatenated together, and are fed into a fully-connected layer to obtain a scalar gain Vcri = \u0393c(fp,Am; \u03b8\u0393c), where \u03b8\u0393c is the network weights. Two losses (i.e., the critic loss Lcri and regression loss Lreg) are designed to maximize the gain with positive guidance.\n1. Critic Loss Lcri: For training the geometric attention network \u0393a(\u00b7), the critic loss Lcri is proposed to maximize the scalar gain value Vcri with respect to the geometric attention Am (i.e., minimizing Lcri in Eq. (8)):\nLcri = Efp\u2208Ds\u222aM [\u2212Vcri] = Efp\u2208Ds\u222aM [\u2212\u0393c(fp,Am; \u03b8\u0393c)]. (8)\nIntuitively, Lcri encourages \u0393c(\u00b7) to highlight the local geometric structures with higher contribution scores. It maximizes the positive gain by generating higher gain value Vcri.\n2. Regression Loss Lreg: The regression loss Lreg is designed to guide \u0393c(\u00b7) feedback accurate supervision for \u0393a(\u00b7) via a new reward R. Specifically, R is composed of a classification reward Rc and an amelioration reward Ra, i.e., R = Rc + Ra. Rc measures whether the geometric attention Am learned via \u0393a(\u00b7) leads to correct prediction, which is formulated as follows:\nRc =\n{ 1, if arg maxC(fg; \u03b8C) = arg max y,\n0, otherwise, (9)\nwhere \u03b8C denotes the parameters of classifier C(\u00b7), and C(fg; \u03b8C) is the probability outputs of global feature fg with\nAlgorithm 1 Training Pipeline of Our InOR-Net Model. 1: Input: The subset Ds = {xsi , ysi } ns i=1 including the data\nof new categories, the exemplar set M , and {\u03bb1, \u03bb2}. 2: Initialize: {\u03b8E , \u03b8C , \u03b8\u0393c , \u03b8\u0393a}; 3: While not converged do 4: Construct a mini-batch TB = {xsi , ysi }Bi=1 from Ds\u222aM ; 5: Update {\u03b8E , \u03b8C} via minimizing Lclc + \u03bb2Lcst; 6: Update \u03b8\u0393a via minimizing Lclc + \u03bb1Lcri + \u03bb2Lcst; 7: Update \u03b8\u0393c via minimizing Lreg; 8: End 9: Store statistical information to compensate the biased\npredictions via Eq. (13) in the inference phase; 10: Return {\u03b8E , \u03b8C , \u03b8\u0393c , \u03b8\u0393a};\nthe geometric attention Am. y \u2208 Ds \u222a M is the one-hot groundtruth of the input point cloud. Moreover, the amelioration reward Ra examines whether Am learned via \u0393a(\u00b7) facilitates the positive prediction, where Ra is defined as:\nRa =\n{ 1, if C(fg; \u03b8C) k>C(fg\u2032 ; \u03b8C) k, k = arg max y\n0, otherwise, (10)\nwhere C(fg; \u03b8C)k and C(fg\u2032 ; \u03b8C)k respectively represent the k-th category probability predicted by the classifier C(\u00b7) with geometric attention Am or not. Here, fg\u2032 can be obtained when we directly perform max-pooling operation on fm without using Am. We then develop a reward regression loss Lreg to guide \u0393c(\u00b7) feedback accurate supervision. Lreg aims to minimize the gap between the estimated scalar gain Vcri and defined reward R:\nLreg = Efp\u2208Ds\u222aM [ (Vcri \u2212R)2], (11)\nwhere Vcri = \u0393c(fp,Am; \u03b8\u0393c), and R = Rc +Ra."
        },
        {
            "heading": "D. Dual Adaptive Fairness Compensations",
            "text": "Although the above modules can explore distinctive 3D characteristics within local geometric structures for each class, the classifier C(\u00b7) is easily prone to forget the old classes since there is a severe class imbalance issue between old and new categories of 3D objects (|M | ns). To address this issue, most 2D researches [12], [15], [16], [35] propose to pay more attention on old classes via the knowledge distillation strategy. However, they cannot prevent the fully-connected layers of classifier C(\u00b7) from being highly biased, thus strengthening the forgetting on old classes. The classifier C(\u00b7) often predicts well on new classes with a large number of 3D objects, while performing badly on old classes without abundant data.\nTo overcome above issues, the dual adaptive fairness compensations strategy is designed to correct prediction bias among the old and new categories of 3D objects. It consists of a weight fairness compensation to correct the biased weights of classifier C(\u00b7) in the training phase, and a score fairness compensation to balance the biased predictions on new 3D categories in the test phase. \u2022 Weight Fairness Compensation: Denote the weight W l of the last fully-connected layer in the classifier C(\u00b7) as W l = [W lold,W l new] \u2208 Rdw\u00d7(Kp+Ks), where Kp and\nChair Bed Monitor Bathtub Lamp Table\nKs respectively denote the numbers of old and new categories, and dw is the input feature dimension of last fullyconnected layer in C(\u00b7). The weight matrices W lold and W lnew are defined as W lold = [w1, w2, \u00b7 \u00b7 \u00b7 , wKp ] \u2208 Rdw\u00d7Kp and W lnew = [wKp+1, wKp+2, \u00b7 \u00b7 \u00b7 , wKp+Ks ] \u2208 Rdw\u00d7Ks . The corresponding norms of the weight matrices W lold and W l new are written as Nold = [||w1||, ||w2||, \u00b7 \u00b7 \u00b7 , ||wKp ||] \u2208 RKp and Nnew = [||wKp+1||, ||wKp+2||, \u00b7 \u00b7 \u00b7 , ||wKp+Ks ||] \u2208 RKs . Therefore, the normalized weight matrix W\u0303 lnew for new classes of 3D objects is formulated as W\u0303 lnew = mean(Nold) mean(Nnew)\n\u00b7W lnew. After applying weight fairness compensation, the corrected weight W\u0303 l of the last fully-connected layer is:\nW\u0303 l = [W lold, W\u0303 l new] = [W l old,\nmean(Nold) mean(Nnew) \u00b7W lnew]. (12)\nIntuitively, Eq. (12) encourages the average norm of W lnew from new 3D classes to approximate W lold from old classes. Such design guarantees the prediction fairness among the old and new categories by adaptively adjusting the probabilities of new classes with mean(Nold)mean(Nnew) . Moreover, it can cooperate with the aforementioned critic network \u0393c(\u00b7) together to effectively address the catastrophic forgetting on old classes. \u2022 Score Fairness Compensation: In addition to the biased classifier C(\u00b7) in the training phase, the biased predictions during the inference phase are also non-negligible. To address this concern, we leverage the statistical information of old classes during the training phase to modify the prediction\nscores of new categories in the inference phase [18], [33]. When adequate 3D objects of old classes are available, the predictions for them are more reliable. Thus, we record their initial statistical information for rectification when the old classes are initially learned in each incremental state. Then the rectified probability Cs(fg; \u03b8C)k of the k-th category is written as:\nCs(fg; \u03b8C) k = C(fg; \u03b8C)k \u00b7 \u03c8si(k) \u03c8s(k) \u00b7 \u03c8(s) \u03c8(si) , if new category,\nC(fg; \u03b8C) k, otherwise,\n(13)\nwhere \u03c8si(k) and \u03c8s(k) respectively represent the mean scores classified as the k-th categories in the initial si-th state and the current s-th state. Here, the initial si-th state indicates that all 3D objects of the k-th category are available. \u03c8(si) and \u03c8(s) denote the average scores of new categories in the si-th and s-th incremental states. We need to mention that only if the given 3D objects are initially predicted as the new classes, Eq. (13) applies rectification to their predicted scores. Intuitively, Eq. (13) can guarantee the test fairness among the old and new categories of 3D objects by adaptively adjusting the probabilities of new classes with \u03c8si (k)\u03c8s(k) \u00b7 \u03c8(s) \u03c8(si) in the inference phase.\nE. Implementation Details For the network configuration, as shown in Table I, we\nprovide the detailed architecture description of the proposed InOR-Net model. Specifically, we use PointNet [5] as the encoder E(\u00b7) to extract the low-level representations of point clouds, and employ a four-layer fully-connected network as the classifier C(\u00b7). The channels of C(\u00b7) are set as {1024, 512, 256,number of classes} in this paper. The Adam optimizer with the initial learning rate as 0.001 is utilized to optimize our model, and its weight decay is set as 0.0005. The proposed InOR-Net model is implemented via PyTorch, and we follow the parameter initialization manner1 proposed\n1https://github.com/fxia22/pointnet.pytorch\nin [5] to initialize our model. In Section III-B, we empirically set the number of local geometric structures as L = 64 via conducting the parameter experiments in Section IV-F. The mini-batch size TB is set as 64 for all benchmark datasets. Inspired by [36], we utilize the similar method (i.e., herding strategy) to select the exemplar set M . Overall, the formulation Lobj of our InOR-Net model is written as follows:\nLobj = Lclc + Lreg + \u03bb1Lcri + \u03bb2Lcst, (14) where Lclc =E(xsi ,ysi )\u2208Ds\u222aM [\u2212 \u2211Kp+Ks k=1 (y s i ) klog(C(fg; \u03b8C)\nk)] is the cross-entropy loss for classification. \u03bb1, \u03bb2 \u2265 0 are the balanced weights, which are empirically set as \u03bb1 = 0.01, \u03bb2 = 0.1. We also summarize the optimization procedure of our InOR-Net model, as shown in Algorithm 1.\nInference: For performance evaluation, we directly forward the 3D object into the encoder E(\u00b7) to extract fm via categoryguided geometric reasoning, and obtain fp via geometric attention network \u0393a(\u00b7). After performing max-pooling on fp, we get the global feature fg , and forward it into the classifier C(\u00b7) to compute softmax probabilities that are rectified via Eq. (13) for the final 3D object recognition."
        },
        {
            "heading": "IV. EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "A. Datasets and Evaluation Metric",
            "text": "\u2022 ShapeNet [48] is composed of 35037 CAD samples for training and 5053 CAD samples for validation, which are collected from online repositories. We use 53 categories in the comparison experiments, and select 1000 CAD samples to be stored in the exemplar set M . The total incremental states S is set as 9, and each incremental state has an increment of six classes, except for the last one with five new classes. \u2022ModelNet [49] with 40 different CAD categories contains\n9843 samples for training and 2468 samples for evaluation. All CAD samples are clean models. The exemplar set M stores 800 CAD samples. We define the total incremental states S as 10, and each incremental state will collect four new classes. \u2022 ScanNet [50] consists of 17 different classes collected\nfrom the scanned and reconstructed scenes. When compared\nwith ShapeNet [48] and ModelNet [48], it is a more challenging dataset due to many noisy geometric structures. The training and test sets respectively have 12060 and 3416 samples. We store 600 CAD samples in the exemplar set M , and define total incremental states S = 9, where each incremental state has an increment of two classes, except for the last one with only one incremental class. Moreover, some example samples of three benchmark datasets are visualized in Fig. 2.\nAs for the selection of exemplar set M and incremental states S, we follow the standard settings of class-incremental learning proposed in [12], [15], [16], [35]\u2013[37], and utilize the same experimental settings to compare with other stateof-the-art baseline methods for fair comparisons. Specifically, considering the number of 3D object classes in each incremental state, we select the number of total incremental states to be around 10 for more new categories in each incremental task, while ensuring that the number of incremental states S is as large as possible. Besides, the number of exemplars from M satisfies |M |/Kp ns/Ks, and we empirically set the\nnumber of M as 1000, 800, 600 for ShapeNet [48], ModelNet [49] and ScanNet [50] respectively.\nEvaluation Metric: Following other baseline methods [12], [16], [18], [37], we utilize the top-1 accuracy [52], [53] as the evaluation metric to conduct comparison experiments."
        },
        {
            "heading": "B. Comparison Experiments",
            "text": "The comparison experiments on ShapeNet [48], ModelNet [49], ScanNet [50] are shown in Tables II, III and IV. For a fair comparison, all baseline methods utilize PointNet [5] to obtain local feature of point cloud, and are trained with the same data augmentation mechanism in [5]. According to the results, we observe our InOR-Net model outperforms the conference version I3DOL [18] about 1.7% \u223c 2.1% (average accuracy) on three benchmark datasets. The substantial extensions about exploring 3D geometric characteristics and alleviating catastrophic forgetting promote the object recognition ability of our InOR-Net model against the conference method [18]. Moreover, the average accuracy of Ours significantly outperforms\nother comparison methods [11], [12], [15], [16], [20], [33], [35]\u2013[37] by a large margin about 2.9% \u223c 26.7%. It illustrates that our model has more advantages than 2D methods in addressing 3D class-incremental learning. Specifically, when compared with them, our model is effective to explore distinctive 3D characteristics within each class under the category information as guidance via the category-guided geometric reasoning. Our InOR-Net model also considers different contributions of 3D characteristics to address the forgetting via critic-induced geometric attention. The recognition results of our InOR-Net model are better than knowledge distillation based approaches [12], [15], [16], [35]\u2013[37], since the dual adaptive fairness compensations could effectively alleviate catastrophic forgetting by correcting prediction bias among old and new categories in the training and test stages."
        },
        {
            "heading": "C. Ablation Studies",
            "text": "To demonstrate the necessity of proposed modules in our InOR-Net model, we introduce detailed ablation studies on three benchmark datasets, as shown in Tables II, III and IV. Ours-w/oCGR, Ours-w/oCGA, Ours-w/oWFC and Oursw/oSFC represent the performance of our model without using the category-guided geometric reasoning (CGR), criticinduced geometric attention (CGA), weight fairness compensation (WFC) and score fairness compensation (SFC).\nTables II, III and IV show that the average accuracy degrades 1.2% \u223c 3.9% when any component of our model is absent. It verifies that the proposed modules cooperate well to\naddress 3D class-incremental learning. Specifically, the lack of dual adaptive fairness compensations causes the degradation about 1.2% \u223c 2.2% average accuracy, which validates the effectiveness to alleviate the forgetting via correcting the prediction bias. When removing the category-guided geometric reasoning, the average accuracy of our model decreases 3.5% \u223c 3.9%. The worse performance explains its importance to explore unique 3D characteristics within each class. Oursw/oCGA performs worse than Ours about 2.6% \u223c 3.0%. It validates the effectiveness of critic-induced geometric attention to highlight distinctive 3D characteristics."
        },
        {
            "heading": "D. Qualitative Analysis of Exemplar Set",
            "text": "This section investigates the effect of exemplar set M on model performance. As depicted in Fig. 3, we present comparison experiments on benchmark datasets when setting different sizes of the exemplar set M . Specifically, we set the sample number of M as {800, 1200}, {600, 1000} and {400, 800} for ShapeNet [48], ModelNet [49] and ScanNet [50] datasets respectively. According to Fig. 3, we can observe that our model still outperforms all comparison baselines when setting a small sample number of exemplar set M , which further validates the superiority of our model. This observation also illustrates the effectiveness of our model against other comparison methods, when addressing the forgetting on old classes of 3D objects. Moreover, training our model with more exemplars significantly facilitates to alleviate the catastrophic\nforgetting by exploring distinctive 3D geometric characteristics and addressing the class imbalance."
        },
        {
            "heading": "E. Qualitative Analysis of Incremental States",
            "text": "As depicted in Fig. 4, we introduce the comparison ex-\nperiments between our model and other baseline methods on benchmark datasets, when setting different incremental states S with Tables II, III and IV. From the depicted curves in Fig. 4, we observe that all comparison methods perform worse than Ours, even though each incremental state has more new 3D classes. It validates the generalization of our model to alleviate the catastrophic forgetting under different experimental configurations. Compared with the conference version I3DOL [18], our model could effectively quantify the contributions of distinctive 3D characteristics within each class via the critic-induced geometric attention, and address the forgetting caused by class imbalance via the dual adaptive fairness compensations. These substantial extensions lead to the performance improvements of our model. Besides, the recognition results of our model are significantly better than other 2D baseline approaches [15], [20], [33], [35]\u2013[37], since the category-guided geometric reasoning captures distinctive 3D properties within each class via using category information as learning guidance."
        },
        {
            "heading": "F. Qualitative Analysis of Parameters {\u03bb1, \u03bb2, L}",
            "text": "This subsection presents the parameter experiments about\n\u03bb1, \u03bb2 in Eq. (14) and L in Section III-B on three benchmark\ndatasets, by tuning them in range of {1\u00d7 10\u22124, 1\u00d7 10\u22123, 1\u00d7 10\u22122, 1 \u00d7 10\u22121, 1} and {16, 32, 48, 64, 80}, respectively. As shown in Fig. 5, when we set \u03bb1 = 0.01, \u03bb2 = 0.1, L = 64, our model achieves the optimal average accuracy, and we utilize these parameter values in comparison experiments.\nFig. 5 also shows the performance of our model has great stability even though {\u03bb1, \u03bb2, L} have a wide selection range. Furthermore, when L = 64 and fixing other parameters {\u03bb1, \u03bb2}, our model has the best performance on benchmark datasets. It validates each point cloud could be characterized well by 64 local geometric structures. Besides, the performance of our model degrades when setting an inappropriate value for L. It illustrates that more local geometric structures can bring more noise information, while less local geometric structures may lose some informative knowledge. Our model can capture unique 3D characteristics within each class via the category-guided geometric reasoning (i.e., \u03bb2Lcst). \u03bb1Lcri provides the positive supervision to guide \u0393a(\u00b7) maximize the gain of unique 3D characteristics via tuning the parameter \u03bb1."
        },
        {
            "heading": "G. Convergence Analysis",
            "text": "We introduce the convergence investigation of our InOR-Net model in this subsection, as shown in Fig. 6. From the convergence curves, we can observe that when the number of training epoches is about 140, the accuracy performance of our InORNet model converges to a stable value on three benchmark datasets. Moreover, the stable performances across incremental states verify our model can recognize new categories of 3D\nobjects consecutively while tackling the forgetting on old categories. It also demonstrates that the proposed modules cooperate well to address 3D class-incremental learning."
        },
        {
            "heading": "H. Qualitative Analysis of Time and Memory Complexities",
            "text": "As shown in Table V, we conduct time and computational parameters comparisons between our InOR-Net model and other approaches on ModelNet [49] under the same settings. The training time (h) denotes the averaged model convergence time (hour) across all incremental states, the test time (s) shows the inference time cost (second) of mini-batch data, and the #Parameters (M) represents computational network parameters of the model trained with TITAN XP GPU. As introduced in Table V, we conclude that our proposed InORNet model significantly outperforms [20], [36], [37], [51] by a large margin, and is comparable with [12], [15], [16], [18], [33], [35] in terms of training time, test time and network parameters. Our model sacrifices marginal computational time and parameters, but achieves significant performance improvement (see Tables II, III and IV) than competing approaches, which is acceptable in real-world applications."
        },
        {
            "heading": "I. Qualitative Analysis of Catastrophic Forgetting",
            "text": "In this subsection, we present the comparison experiments on ModelNet [49] dataset in terms of averaged F1 score and Recall across all incremental states to investigate catastrophic forgetting, as shown in Table VI. Our proposed model outperforms other baseline comparison methods [12], [15], [16], [18], [20], [33], [36], [37] about 2.3%\u223c19.7% in terms of averaged F1 score and Recall. This improvement validates the superiority of our InOR-Net model to identify new categories consecutively under a streaming manner. Moreover, it verifies\nour model could perform well across all classes (both old and new classes) rather than only some specific classes, and also illustrates the effectiveness of our model to alleviate catastrophic forgetting on old classes."
        },
        {
            "heading": "J. Qualitative Analysis of Substantial Improvement",
            "text": "In order to show whether the improvement of our INOR-Net model compared with other baseline approaches is significant, we introduce the t-test experiments via five random runs in this subsection. When the p value of t-test is lower than 0.05, we consider the improvement of object recognition ability is significant. As presented in Table VII, the p value of Ours vs I3DOL [18] is much lower than 0.05, which validates that our InOR-Net model has a substantial improvement over the previous conference version I3DOL [18] on three benchmark datasets. In addition, we introduce t-test experiments between Ours and other baselines [16], [20], [33], [35]\u2013[37]. The p values of these comparisons are significantly lower than 0.05, which supports the superior recognition results of our model to tackle catastrophic forgetting on old categories of 3D objects."
        },
        {
            "heading": "V. CONCLUSION AND FUTURE WORK",
            "text": "In this paper, we propose a novel Incremental 3D Object Recognition Network (InOR-Net) to recognize novel categories of 3D objects under a streaming manner, without the catastrophic forgetting on old 3D classes. Specifically, we focus on capturing the distinctive 3D characteristics within each class via a category-guided geometric reasoning, and identifying which 3D geometric characteristics are important to alleviate the forgetting on old classes of 3D objects via a critic-induced geometric attention. A dual adaptive fairness compensations strategy including both weights and prediction scores corrections is designed to tackle the forgetting brought by class imbalance problem. We verify the superior performance of the proposed InOR-Net model via extensive comparison experiments on representative point cloud datasets.\nThe proposed model lacks some theoretical analysis to guarantee the convergence in the theory perspective, and may suffer from recognition performance degradation when the collected point cloud is heavily polluted by noise and loses some core geometric structures. In the future, we will focus on addressing these limitations, and extend our proposed model into several challenging 3D vision fields such as intelligent robotics and scene understanding."
        }
    ],
    "title": "InOR-Net: Incremental 3D Object Recognition Network for Point Cloud Representation",
    "year": 2023
}