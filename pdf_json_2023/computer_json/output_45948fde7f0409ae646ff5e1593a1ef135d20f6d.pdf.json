{
    "abstractText": "As the key to sentiment analysis, sentiment composition considers the classification of a constituent via classifications of its contained sub-constituents and rules operated on them. Such compositionality has been widely studied previously in the form of hierarchical trees including untagged and sentiment ones, which are intrinsically suboptimal in our view. To address this, we propose semantic tree, a new tree form capable of interpreting the sentiment composition in a principled way. Semantic tree is a derivation of a context-free grammar (CFG) describing the specific composition rules on difference semantic roles, which is designed carefully following previous linguistic conclusions. However, semantic tree is a latent variable since there is no its annotation in regular datasets. Thus, in our method, it is marginalized out via inside algorithm and learned to optimize the classification performance. Quantitative and qualitative results demonstrate that our method not only achieves better or competitive results compared to baselines in the setting of regular and domain adaptation classification, and also generates plausible tree explanations1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhongtao Jiang"
        },
        {
            "affiliations": [],
            "name": "Yuanzhe Zhang"
        },
        {
            "affiliations": [],
            "name": "Cao Liu"
        },
        {
            "affiliations": [],
            "name": "Jiansong Chen"
        },
        {
            "affiliations": [],
            "name": "Jun Zhao"
        },
        {
            "affiliations": [],
            "name": "Kang Liu"
        }
    ],
    "id": "SP:82977ff0ee1f3149164cc706ad7d6647b409bc32",
    "references": [
        {
            "authors": [
                "Stefano Baccianella",
                "Andrea Esuli",
                "Fabrizio Sebastiani"
            ],
            "title": "SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining",
            "venue": "In Proceedings of the Seventh International Conference on Language Resources and Evaluation",
            "year": 2010
        },
        {
            "authors": [
                "James K Baker."
            ],
            "title": "Trainable grammars for speech recognition",
            "venue": "The Journal of the Acoustical Society of America, 65(S1):S132\u2013S132.",
            "year": 1979
        },
        {
            "authors": [
                "Jasmijn Bastings",
                "Wilker Aziz",
                "Ivan Titov."
            ],
            "title": "Interpretable neural predictions with differentiable binary variables",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2963\u20132977, Florence, Italy. As-",
            "year": 2019
        },
        {
            "authors": [
                "John Blitzer",
                "Mark Dredze",
                "Fernando Pereira."
            ],
            "title": "Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification",
            "venue": "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages",
            "year": 2007
        },
        {
            "authors": [
                "Hanjie Chen",
                "Guangtao Zheng",
                "Yangfeng Ji."
            ],
            "title": "Generating hierarchical explanations on text classification via feature interaction detection",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
            "year": 2020
        },
        {
            "authors": [
                "Jihun Choi",
                "Kang Min Yoo",
                "Sang-goo Lee."
            ],
            "title": "Learning to compose task-specific tree structures",
            "venue": "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of",
            "year": 2018
        },
        {
            "authors": [
                "Noam Chomsky."
            ],
            "title": "Three models for the description of language",
            "venue": "IRE Transactions on information theory, 2(3):113\u2013124.",
            "year": 1956
        },
        {
            "authors": [
                "Noam Chomsky."
            ],
            "title": "Formal properties of grammars",
            "venue": "Handbook of Math. Psychology, 2:328\u2013418.",
            "year": 1963
        },
        {
            "authors": [
                "Jishnu Ray Chowdhury",
                "Cornelia Caragea."
            ],
            "title": "Modeling hierarchical structures with continuous recursive neural networks",
            "venue": "International Conference on Machine Learning, pages 1975\u20131988. PMLR.",
            "year": 2021
        },
        {
            "authors": [
                "Nhan Cach Dang",
                "Mar\u00eda N Moreno-Garc\u00eda",
                "Fernando De la Prieta."
            ],
            "title": "Sentiment analysis based on deep learning: A comparative study",
            "venue": "Electronics, 9(3):483.",
            "year": 2020
        },
        {
            "authors": [
                "H Younger Daniel."
            ],
            "title": "Recognition and parsing of context-free languages in time n3",
            "venue": "Information and control, 10(2):189\u2013208.",
            "year": 1967
        },
        {
            "authors": [
                "Nicola De Cao",
                "Michael Sejr Schlichtkrull",
                "Wilker Aziz",
                "Ivan Titov."
            ],
            "title": "How do decisions emerge across layers in neural models? interpretation with differentiable masking",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural",
            "year": 2020
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association",
            "year": 2019
        },
        {
            "authors": [
                "Li Dong",
                "Furu Wei",
                "Shujie Liu",
                "Ming Zhou",
                "Ke Xu."
            ],
            "title": "A statistical parsing framework for sentiment classification",
            "venue": "Computational Linguistics, 41(2):265\u2013308.",
            "year": 2015
        },
        {
            "authors": [
                "Greg Durrett",
                "Dan Klein."
            ],
            "title": "Neural CRF parsing",
            "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),",
            "year": 2015
        },
        {
            "authors": [
                "Jason Eisner."
            ],
            "title": "Inside-outside and forwardbackward algorithms are just backprop (tutorial paper)",
            "venue": "Proceedings of the Workshop on Structured Prediction for NLP, pages 1\u201317, Austin, TX. Association for Computational Linguistics.",
            "year": 2016
        },
        {
            "authors": [
                "Jenny Rose Finkel",
                "Alex Kleeman",
                "Christopher D. Manning."
            ],
            "title": "Efficient, feature-based, conditional random field parsing",
            "venue": "Proceedings of ACL-08: HLT, pages 959\u2013967, Columbus, Ohio. Association for Computational Linguistics.",
            "year": 2008
        },
        {
            "authors": [
                "Serhii Havrylov",
                "Germ\u00e1n Kruszewski",
                "Armand Joulin."
            ],
            "title": "Cooperative learning of disjoint syntax and semantics",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2019
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber."
            ],
            "title": "Long short-term memory",
            "venue": "Neural computation, 9(8):1735\u2013 1780. 7473",
            "year": 1997
        },
        {
            "authors": [
                "Tadao Kasami."
            ],
            "title": "An efficient recognition and syntax algorithm for context-free languages",
            "venue": "Technical report, Air Force Cambridge Research Lab.",
            "year": 1965
        },
        {
            "authors": [
                "Alistair Kennedy",
                "Diana Inkpen."
            ],
            "title": "Sentiment classification of movie reviews using contextual valence shifters",
            "venue": "Computational intelligence, 22(2):110\u2013125.",
            "year": 2006
        },
        {
            "authors": [
                "Siwon Kim",
                "Jihun Yi",
                "Eunji Kim",
                "Sungroh Yoon."
            ],
            "title": "Interpretation of NLP models through input marginalization",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3154\u20133167,",
            "year": 2020
        },
        {
            "authors": [
                "Taeuk Kim",
                "Jihun Choi",
                "Daniel Edmiston",
                "Sanghwan Bae",
                "Sang-goo Lee."
            ],
            "title": "Dynamic compositionality in recursive neural networks with structureaware tag representations",
            "venue": "The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI",
            "year": 2019
        },
        {
            "authors": [
                "Nikita Kitaev",
                "Steven Cao",
                "Dan Klein."
            ],
            "title": "Multilingual constituency parsing with self-attention and pre-training",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3499\u20133505, Florence, Italy. As-",
            "year": 2019
        },
        {
            "authors": [
                "Nikita Kitaev",
                "Dan Klein."
            ],
            "title": "Constituency parsing with a self-attentive encoder",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2676\u20132686, Melbourne, Australia. As-",
            "year": 2018
        },
        {
            "authors": [
                "Tao Lei",
                "Regina Barzilay",
                "Tommi Jaakkola."
            ],
            "title": "Rationalizing neural predictions",
            "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 107\u2013117, Austin, Texas. Association for Computational Lin-",
            "year": 2016
        },
        {
            "authors": [
                "Jiwei Li",
                "Will Monroe",
                "Dan Jurafsky."
            ],
            "title": "Understanding neural networks through representation erasure",
            "venue": "ArXiv preprint, abs/1612.08220.",
            "year": 2016
        },
        {
            "authors": [
                "Pengfei Liu",
                "Xipeng Qiu",
                "Xuanjing Huang."
            ],
            "title": "Adaptive semantic compositionality for sentence modelling",
            "venue": "Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI 2017, Melbourne,",
            "year": 2017
        },
        {
            "authors": [
                "Pengfei Liu",
                "Xipeng Qiu",
                "Xuanjing Huang."
            ],
            "title": "Dynamic compositional neural networks over tree structure",
            "venue": "Proceedings of the Twenty-Sixth International Joint Conference",
            "year": 2017
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter."
            ],
            "title": "SGDR: stochastic gradient descent with warm restarts",
            "venue": "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. Open-",
            "year": 2017
        },
        {
            "authors": [
                "Tim Loughran",
                "Bill McDonald."
            ],
            "title": "When is a liability not a liability? textual analysis, dictionaries, and 10-ks",
            "venue": "The Journal of finance, 66(1):35\u201365.",
            "year": 2011
        },
        {
            "authors": [
                "Jean Maillard",
                "Stephen Clark."
            ],
            "title": "Latent tree learning with differentiable parsers: Shift-reduce parsing and chart parsing",
            "venue": "Proceedings of the Workshop on the Relevance of Linguistic Structure in Neural Architectures for NLP, pages 13\u201318, Mel-",
            "year": 2018
        },
        {
            "authors": [
                "Bo Pang",
                "Lillian Lee."
            ],
            "title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
            "venue": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL\u201905), pages 115\u2013",
            "year": 2005
        },
        {
            "authors": [
                "Livia Polanyi",
                "Annie Zaenen."
            ],
            "title": "Contextual valence shifters",
            "venue": "Computing attitude and affect in text: Theory and applications, pages 1\u201310. Springer.",
            "year": 2006
        },
        {
            "authors": [
                "Ning Qian."
            ],
            "title": "On the momentum term in gradient descent learning algorithms",
            "venue": "Neural networks, 12(1):145\u2013151.",
            "year": 1999
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu"
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "J. Mach. Learn. Res.,",
            "year": 2020
        },
        {
            "authors": [
                "Marco T\u00falio Ribeiro",
                "Sameer Singh",
                "Carlos Guestrin."
            ],
            "title": "why should I trust you?\": Explaining the predictions of any classifier",
            "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery",
            "year": 2016
        },
        {
            "authors": [
                "Richard Socher",
                "Brody Huval",
                "Christopher D. Manning",
                "Andrew Y. Ng."
            ],
            "title": "Semantic compositionality through recursive matrix-vector spaces",
            "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing",
            "year": 2012
        },
        {
            "authors": [
                "Richard Socher",
                "Cliff Chiung-Yu Lin",
                "Andrew Y. Ng",
                "Christopher D. Manning."
            ],
            "title": "Parsing natural scenes and natural language with recursive neural networks",
            "venue": "Proceedings of the 28th International Conference on Machine Learning,",
            "year": 2011
        },
        {
            "authors": [
                "Richard Socher",
                "Alex Perelygin",
                "Jean Wu",
                "Jason Chuang",
                "Christopher D. Manning",
                "Andrew Ng",
                "Christopher Potts."
            ],
            "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
            "venue": "Proceedings of the 2013 Conference on",
            "year": 2013
        },
        {
            "authors": [
                "Julia Strout",
                "Ye Zhang",
                "Raymond Mooney."
            ],
            "title": "Do human rationales improve machine explanations? In Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 56\u201362, Florence, Italy",
            "venue": "As-",
            "year": 2019
        },
        {
            "authors": [
                "Maite Taboada",
                "Julian Brooke",
                "Milan Tofiloski",
                "Kimberly Voll",
                "Manfred Stede."
            ],
            "title": "Lexicon-based methods for sentiment analysis",
            "venue": "Computational Linguistics, 37(2):267\u2013307.",
            "year": 2011
        },
        {
            "authors": [
                "Kai Sheng Tai",
                "Richard Socher",
                "Christopher D. Manning."
            ],
            "title": "Improved semantic representations from tree-structured long short-term memory networks",
            "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and",
            "year": 2015
        },
        {
            "authors": [
                "Ann Taylor",
                "Mitchell Marcus",
                "Beatrice Santorini."
            ],
            "title": "The penn treebank: an overview",
            "venue": "Treebanks, pages 5\u201322.",
            "year": 2003
        },
        {
            "authors": [
                "Zhiyang Teng",
                "Yue Zhang."
            ],
            "title": "Head-lexicalized bidirectional tree LSTMs",
            "venue": "Transactions of the Association for Computational Linguistics, 5:163\u2013 177.",
            "year": 2017
        },
        {
            "authors": [
                "Orith Toledo-Ronen",
                "Roy Bar-Haim",
                "Alon Halfon",
                "Charles Jochim",
                "Amir Menczel",
                "Ranit Aharonov",
                "Noam Slonim."
            ],
            "title": "Learning sentiment composition from sentiment lexicons",
            "venue": "Proceedings of the 27th International Conference on Computational",
            "year": 2018
        },
        {
            "authors": [
                "Adina Williams",
                "Andrew Drozdov",
                "Samuel R. Bowman"
            ],
            "title": "Do latent tree learning models identify meaningful structure in sentences? Transactions of the Association for Computational Linguistics, 6:253\u2013267",
            "year": 2018
        },
        {
            "authors": [
                "Theresa Wilson",
                "Janyce Wiebe",
                "Paul Hoffmann."
            ],
            "title": "Recognizing contextual polarity in phrase-level sentiment analysis",
            "venue": "Proceedings",
            "year": 2005
        },
        {
            "authors": [
                "Ashima Yadav",
                "Dinesh Kumar Vishwakarma."
            ],
            "title": "Sentiment analysis using deep learning architectures: a review",
            "venue": "Artificial Intelligence Review, 53(6):4335\u2013 4385.",
            "year": 2020
        },
        {
            "authors": [
                "Dani Yogatama",
                "Phil Blunsom",
                "Chris Dyer",
                "Edward Grefenstette",
                "Wang Ling."
            ],
            "title": "Learning to compose words into sentences with reinforcement learning",
            "venue": "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April",
            "year": 2017
        },
        {
            "authors": [
                "Die Zhang",
                "Huilin Zhou",
                "Xiaoyi Bao",
                "Da Huo",
                "Ruizhao Chen",
                "Xu Cheng",
                "Hao Zhang",
                "Mengyue Wu",
                "Quanshi Zhang"
            ],
            "title": "Interpreting hierarchical linguistic interactions in dnns",
            "year": 2020
        },
        {
            "authors": [
                "Liwen Zhang",
                "Kewei Tu",
                "Yue Zhang."
            ],
            "title": "Latent variable sentiment grammar",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4642\u20134651, Florence, Italy. Association for Computational Linguis-",
            "year": 2019
        },
        {
            "authors": [
                "Yuan Zhang",
                "Yue Zhang."
            ],
            "title": "Tree communication models for sentiment analysis",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3518\u20133527, Florence, Italy. Association for Computational Linguis-",
            "year": 2019
        },
        {
            "authors": [
                "Ruiqi Zhong",
                "Steven Shao",
                "Kathleen McKeown."
            ],
            "title": "Fine-grained sentiment analysis with faithful attention",
            "venue": "ArXiv preprint, abs/1908.06870.",
            "year": 2019
        },
        {
            "authors": [
                "Xiao-Dan Zhu",
                "Parinaz Sobhani",
                "Hongyu Guo."
            ],
            "title": "Long short-term memory over recursive structures",
            "venue": "Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, volume 37 of JMLR",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "Findings of the Association for Computational Linguistics: ACL 2023, pages 7464\u20137478 July 9-14, 2023 \u00a92023 Association for Computational Linguistics"
        },
        {
            "heading": "1 Introduction",
            "text": "Sentiment classification is a task to determine the sentiment polarity of a sentence (Yadav and Vishwakarma, 2020; Dang et al., 2020). Current researches on this task are gradually shifting from improving model performance to interpretability. As the most known stream, feature-based explanation tries to figure out which input feature, say word, has the most influence on the prediction, in the form of the salience score or rationale, and in both self and post-hoc settings (Li et al., 2016; Ribeiro et al., 2016; Kim et al., 2020; Lei et al., 2016; Bastings et al., 2019; De Cao et al., 2020). However, this task requires sentiment composition\n1Data and code implementation is available at https:// github.com/changmenseng/semantic_tree.\n(Polanyi and Zaenen, 2006), which is beyond the ability of these feature-based explanations.\nTo be concrete, sentiment composition considers the classification of a constituent via 1) classifications of its contained sub-constituents and 2) rules operated on them (Moilanen and Pulman, 2007), as shown in Figure 1(c). Thus, the classification of a sentence is decomposed into hierarchical sentiment compositions of its sub-constituents. Such compositionality has been widely studied previously in the form of hierarchical trees including untagged tree and sentiment tree, as shown in Figure 1. Untagged tree is usually modeled as a latent variable and learned via the task objective (Yogatama et al., 2017; Maillard and Clark, 2018; Choi et al., 2018; Havrylov et al., 2019; Chowdhury and Caragea, 2021). Then, a TreeLSTM (Tai et al., 2015; Zhu et al., 2015) is adopted to encode the sentence following the hierarchy for the final prediction. However, untagged tree is limited because it can only explain the hierarchy but not give labels on all nodes. Sentiment tree takes a further step that every node within has a polarity score or label. As the most representative example, Socher et al. (2013) creates Stanford Sentiment Treebank (SST) that has senti-\n7464\nment tree annotation. Sentiment tree also appears as a post-hoc explanation giving hierarchical attribution scores (Chen et al., 2020; Zhang et al., 2020). However, in fact, not every constituent is sentimental, some of which are somewhat more functional. For example, while a negator \u201cnot\" is sentimentally neural, it can functionally flip the sentiment of a constituent. Sentiment labels are therefore not sufficient to explain such phenomenon.\nTo overcome those defects, we propose semantic tree, a new tree form capable of explicitly and principally interpreting the sentiment composition. In the semantic tree, each node is assigned a label in semantic labels including sentimental and functional ones, and each local inverted-V structure reveals the rule composing adjacent constituents, as shown in Figure 1(c). Inspired by Dong et al. (2015), formally, the semantic tree is a derivation of a context-free grammar (CFG) (Chomsky, 1956) defined by non-terminal symbols (semantic labels), terminal symbols (word vocabulary), rules, and root symbols (positive and negative). The challenge of designing such grammar lies in designing semantic labels and rules, which requires linguistic knowledge of sentiment composition. To address this, we follow previous work about sentiment composition (Polanyi and Zaenen, 2006; Moilanen and Pulman, 2007; Taboada et al., 2011) to carefully design 11 semantic labels and 62 rules. We believe the grammar could cover most cases in sentiment analysis, as shown in Table 1.\nWe aim to learn a model capable of extracting the semantic tree using data consisting of only sentence-label pairs, which is challenging because the semantic tree is latent without full annotation. To address this, we first build a semantic tree parser, and then marginalize out the semantic tree to induce a sentiment classifier to conduct supervised training on such data. Fortunately, this marginalization over the exponential tree space is computationally tractable resorting to the inside algorithm (Baker, 1979). This process could be abstracted as a module, namely sentiment composition module (SCM), which computes the compatibility of a prediction in the view of sentiment composition but not only pattern recognition. Accompanying an arbitrary neural text encoder with the proposed SCM, we can build a self-explanatory model that can not only predict the sentiment label but also generate a semantic tree as the explanation. To learn more plausible semantic trees, we further propose two\nextra objectives to guide the preterminals in the semantic tree, and to make the tree structure more syntactically meaningful.\nWe conduct experiments on three datasets including MR (Pang and Lee, 2005), SST2 (Socher et al., 2013) and Amazon (Blitzer et al., 2007) in the setting of regular and cross-domain classification. Quantitative and qualitative results demonstrate that our method not only achieves better or competitive results compared to baselines, and also generates plausible tree explanations."
        },
        {
            "heading": "2 Method",
            "text": ""
        },
        {
            "heading": "2.1 Problem Formalization",
            "text": "The dataset is a collection of tuples {(xn, yn)}Nn=1, each of which contains a sentence x \u2208 V\u2217 and a sentiment label y \u2208 Y , where V is the word vocabulary and Y = {P,N} is the label set consisting of positive (P ) and negative (N ). The task goal is to learn a classifier p(y|x). Since we hope to generate a semantic tree of the input sentence where the sentiment label is its root label, as shown in Figure 1(c), the objective classifier p(y|x) is not directly parameterized by a discriminative model as usual. Instead, we define the classifier as the marginalization of a parser over the latent semantic tree, in which the parser could fulfill this purpose. Concretely, let Tx(y) be the set of all semantic trees rooted y. Naturally, we have:\np(y|x) = \u2211\nt\u2208Tx(y) p(t|x) (1)\nwhere p(t|x) is a semantic tree parser that accepts a sentence and generates a semantic tree. We can conduct supervised learning when the classifier p(y|x) is obtained, where the parser p(t|x) is implicitly learned in this process. After training, the model can do the prediction via the induced classifier p(y|x), and generate the semantic tree to real the sentiment composition process of it.\nThe very first issue before solving the summation in Equation (1) is to formalize the semantic tree. For simplicity, we can assume that the label of a constituent is determined immediately by its sub-constituents, regardless of the surrounding context. Therefore, the semantic tree is viewed as a derivation of a CFG that defines specific semantic labels and composition rules. Now, two challenges remain: 1) How to properly define the CFG behind the semantic tree? 2) How to model\nthe parser p(t|x) and efficiently compute the classifier p(y|x)? We shall elaborate these two problems in Section 2.2 and Section 2.3, respectively."
        },
        {
            "heading": "2.2 Sentiment Composition Grammar",
            "text": "The proposed semantic tree is described by a context-free grammar G consisting a quadruple including the non-terminal symbol set N (semantic label set), the terminal symbol set V (word vocabulary), the composition rule set R and the root symbol set Y (P and N ). While V and Y are obvious, the design of semantic labels (N ) and composition rules (R) requires expert knowledge. Fortunately, previous works have concluded different types of compositions exhaustively (Polanyi and Zaenen, 2006; Moilanen and Pulman, 2007; Taboada et al., 2011), inspiring us to design 11 semantic labels and 62 composition rules. We call the proposed grammar as a sentiment composition grammar (SCG).\nSemantic Labels The defined 11 semantic labels include two types as follows:\nSentimental labels Including negative N , positive P , neutral O.\nFunctional labels Including negator D, irrealis blocker I , priority riser +, priority reducer \u2212, high negative N+, high positive P+, low negative N\u2212, low positive P\u2212.\nWe shall explain these labels together with composition rules later.\nComposition Rules Formally, the composition rule is in the form of \u03b2 \u2192 A (A \u2208 N , \u03b2 \u2208 (N\u222aV)\u2217), which determines the label of a constituent given its sub-constituents2. We include three types of rules.\nThe first one is binary rule in the form of BC \u2192 A (A,B,C \u2208 N ). Binary rules are defined following common binary compositions, which mainly includes four types according to previous works and our observations. We now introduce each composition and its corresponding rules3.\n2In the standard CFG, the rule is in the production form: A \u2192 \u03b2. Since we want to model the sentiment composition, our rule is written in the equivalent converse way.\n3Note that we assume binary rules to commutative, i.e., if we have rule BC \u2192 A, then CB \u2192 A also holds. Thus, we only describe half of these rules in the following. Also, for compactness, we use symbol \"/\" to represent \"or\" operation. For example, B C/D \u2192 A means both BC \u2192 A and BD \u2192 A hold.\nPolarity propagation Propagating the polarity:\nN O/N \u2192 N, P O/P \u2192 P, O O \u2192 O (2)\nNegation Flipping the non-neutral polarity (P/N ) via a negator (D):\nD P \u2192 N,D N \u2192 P (3)\nConflict Resolution Resolving the conflict of nonneutral polarity constituents (P/N ) by ranking their priorities based on priority modifiers (+/\u2212). As a typical example, Figure 1 shows a contrastive conjunction (Socher et al., 2013) structure, which the first and the second half of the sentence have opposite polarities. The connector \u201cbut\u201d is a priority riser (+) that rises the priority of the second half sentence, which dominates the entire sentence priority. Similarly, there also exist priority reducer (\u2212) such as \u201calthough\u201d. Thus, rules related to this composition includes those for priority modification:\n+ P \u2192 P+,\u2212 P \u2192 P\u2212 (4)\nand those for resolution:\nN P+ \u2192 P,N\u2212 P+ \u2192 P (5)\nWe don\u2019t allow the polarity with priority (N+/N\u2212/P+/P\u2212) without a explicit modifier +/\u2212, which a single word with non-neutral polarity can\u2019t have priority. Irrealis blocking Neutralizing the non-neutral polarity (P/N ) by an irrealis blocker (I):\nI P/N \u2192 O (6)\nThe blocker such as modal \u201cwould\u201d or connector \u201cif\u201d can set up a context about possibility of some polarities not necessarily expressed by the author. As a result, a literal polarity is canceled.\nThe full binary rule list is shown in Table 6 in Appendix A4. We also present examples of those\n4Readers might ask that why explicit triggers are involved in some rules, for example, we can just define a general \u201cglue\u201d rule P N \u2192 P/N to handle conflict resolution instead of defining the modifier (+/\u2212) to trigger the priority modification, as done by Dong et al. (2015). This is because when only the root label annotation is available, this general rule is easily abused so that the semantic tree degenerates to the sentiment tree as a consequence. The optimal binary rule should satisfy that the output label is uniquely determined given the input ones, requiring us to attribute each label to the specific composition as detailed as possible.\ncompositions Figure 2. Those compositions appears very commonly. To illustrate this, we randomly sample 100 examples in SST2 and MR and count occurrences of above compositions, where 97 and 98 examples in SST2 and MR can be explained by the above compositions. Thus, we believe our rules can cover most cases.\nThe second type is terminal-unary rule defining the legal preterminals of single words, which is in the form of \u03c9 \u2192 A (A \u2208 Npret = {N,P,O,D, I,+,\u2212}, \u03c9 \u2208 V). As introduced, A can\u2019t be the polarity priority (N+/N\u2212/P+/P\u2212).\nWe further define the preterminal-unary rule as the third type, including rules A \u2192 A (A \u2208 {P,N,O,D, I,+,\u2212}) and D/I/ + /\u2212 \u2192 O. Those rules can only and must appear on the second layer of the semantic tree, which is designed to cancel the function of misrecognized function constituents, leading to better performance in our experiments."
        },
        {
            "heading": "2.3 Sentiment Composition Module",
            "text": "We now answer the second question: How to model the parser p(t|x) and compute the classifier p(y|x). We show that this process naturally lead to the sentiment composition module.\nSemantic Tree Parser First, we represent the semantic tree t of a sentence x = (x0, \u00b7 \u00b7 \u00b7 , xT\u22121) by the set of anchored rules (Eisner, 2016) consisting of a rule and its location indices:\nt = {(BikCkj \u2192 Aij)t|1 \u2264 t \u2264 T \u2212 1} \u222a{(Bi \u2192 Ai)t|1 \u2264 t \u2264 T} \u222a{(xi \u2192 Ai)t|1 \u2264 t \u2264 T}\n(7)\nwhere Aij (0 \u2264 i < j < T ) is an anchored node suggesting a label A covering the constituent ranging from xi to xj\u22121. Ai is short for Ai,i+1 which is an unary anchored node covering the word xi. Thus, BikCkj \u2192 Aij , Bi \u2192 Ai and xi \u2192 Ai represent the binary, preterminal-unary, and terminalunary anchroed rule, respectively.\nThe semantic tree parser p(t|x) is defined by a Gibbs distribution on anchored rules in a tree (Finkel et al., 2008; Durrett and Klein, 2015):\np(t|x) = 1 Z(x)\n\u220f a\u2208t \u03d5(a) = 1 Z(x) exp\n(\u2211\na\u2208t s(a)\n)\n(8) where Z(x) is the log-partition function for normalization. \u03d5(a) > 0 is the potential function of the anchored rule a defined in the exponential form exp(s(a)), where s(a) is the score to rate how comfortable it is for a to appear in the tree. Scores for different types of anchored rules are defined as the sum of a few subscores rating the comfortableness of corresponding substructures.\ns(BikCkj \u2192 Aij) = srule(BC \u2192 A) + slabel(A, xij) + sspan(xij) s(Bi \u2192 Ai) = srule(B \u2192 A) + slabel(A, xi) + sspan(xi) s(xi \u2192 Ai) = srule(xi \u2192 A) (9) Here the scores of binary and pos-unary rules srule(BC \u2192 A) and srule(B \u2192 A) are scalar parameters. Other scores are modeled by neural networks:\nsrule(xi \u2192 A) = wArule \u00b7 h\u2264Li + bArule slabel(A, xij) = w A label \u00b7 hLij + bAlabel\nsspan(xij) = wspan \u00b7 hLij + bspan (10)\nwhere \u00b7 is the vector dot product. w\u00b7\u00b7 and b\u00b7\u00b7 are learning parameters. hlij is the phrase representation of the constituent xij in the l layer, which is\ncomputed by a text encoder m:\nh00, \u00b7 \u00b7 \u00b7 ,h0T\u22121, \u00b7 \u00b7 \u00b7 ,hL\u221210 , \u00b7 \u00b7 \u00b7 ,hL\u22121T\u22121 = m(e0, \u00b7 \u00b7 \u00b7 , eT\u22121)\nhlij =\n\u2211j\u22121 t=i h l t\nj \u2212 i\n(11)\nwhere ei is the word embedding of xi. Note that we compute slabel and sspan using top layer phrase representations, but compute srule using a lower layer one. This is because the recognition of the preterminal is easier than determining if this label is cancelled. Thus the simple phrase representation h\u2264Lij is sufficient for the former, while the more \u201ccontextual\u201d one hLij is in favor by the latter.\nInducing the Classifier from the Parser As shown in Equation (1), the classifier is induced by marginalizing over all the semantic trees of the input sentence, which can be efficient done by the inside algorithm. To illustrate this, we first let Tx(Aij) and Tx(BikCkj \u2192 Aij) be sets of subtrees of sentence x that are covered by the anchored node Aij and rule BikCkj \u2192 Aij , respectively. The inside algorithm defines the inside term \u03b1x(Aij) = \u2211 t\u2208Tx(Aij) \u220f a\u2208t \u03d5(a), which is the sum of the potentials of subtrees covered by Aij . The inside term is computed recursively in a bottom-up manner:\n\u03b1x(Ai) = \u03d5(xi \u2192 Ai) \u2211\nB\u2192A\u2208R \u03d5(Bi \u2192 Ai)\n\u03b1x(Aij) =\u2211\nBC\u2192A\u2208R i<k<j\n\u03d5(BikCkj \u2192 Aij)\u03b1x(Bik)\u03b1x(Ckj)\n(12) where \u03b1x(Ai) is the initial value of this recursion. Obvious, the time complexity of the inside algorithm is O(|R|T 3). It can be shown that the inside term of the root anchored node \u03b1x(A0T ), abbreviated as \u03b1x(A), equals to the unnormalized probability that the root of the semantic tree is y. Thus, we have:\np(y = A|x) = \u03b1x(A)\u2211 B\u2208Y \u03b1x(B)\n= exp(slabel(A, x) + sSCM(A, x))\u2211\nB\u2208Y exp(slabel(B, x) + sSCM(B, x))\nsSCM(A, x) = logsumexp BC\u2192A\u2208R 0<k<T\n(srule(BC \u2192 A)\n+ log\u03b1x(B0k) + log\u03b1x(CkT )) (13)\nAs seen, the logit in the softmax includes an extra score sSCM(A, x) as a complement to the regular one slabel(A, x), where the former and the latter can be understood as the accordance of assigning the label A by means of sentiment composition and pattern recognition, respectively. Thus, we call slabel and sSCM as the recognition module and the sentiment composition module, respectively. While the recognition module is only learned from the data, the sentiment composition module incorporates general and invariant human knowledge in the form of sentiment composition rules, which is more robust for domain adaptation, as we shall see in Section 4.1.\nThe last issue is that the proposed SCM is intractable for long documents due to the cube time complexity over length. So for a document, we first cut it into sentences, and then compute their individual logits. Document logits are aggregated by attention on those sentence logits, where attention weights are computed by sentence representations."
        },
        {
            "heading": "2.4 Training & Testing",
            "text": "Now we\u2019ve obtained the induced classifier, we can apply supervised training by minimizing:\nLcls = \u2212 1\nN\nN\u2211\nn=1\nlog p(yn|xn) (14)\nThis objective might be enough for the classification, but not for a plausible semantic tree explanation. Cases in which a semantic tree can reach a right root label with wrong preterminals and improper structure do exist. For example, if we choose BERT (Devlin et al., 2019) as the encoder, the method might assign non-neutral polarity to [CLS], and recognize any other tokens as neutral polarity, since [CLS] representation is usually treated as the sentence representation. An effective way to improve the plausibility is to learn the explanation via more explicit annotations (Strout et al., 2019; Zhong et al., 2019), even if those annotations are weak or incomplete. Therefore, we additional introduce two objectives to regularize the tree.\nFor the preterminal plausibility, we construct a lexicon to annotate the preterminal sequence of each sentence and conduct weakly-supervised learning on the annotation. As introduced, there are 7 preterminals in the proposed grammar, 3 sentimental and 5 functional. We utilize sentiwordnet (Baccianella et al., 2010) and stopwords in NLTK5\n5https://www.nltk.org/\nand spaCy6 library to annotate non-neutral and neutral sentimental labels, respectively. For functional labels, we manually build a lexicon based on irrealis blockers and priority modifiers from Taboada et al. (2011), and negators in Loughran and McDonald (2011). The functional lexicon is shown in Table 7 in Appendix B. Let on be the annotated preterminal sequence of the sentence xn, and Sn be the set containing the indices of all annotated words. Then, we optimize the following conditional log-likelihood based on the terminal-unary score function in Equation (10):\nLpos = \u2212 1\n\u2211N n |Sn|\n\u2211 i\u2208Sn log q(oni |xn)\nq(oi|x) = exp(srule(xi \u2192 oi))\u2211\nA\u2208Npos exp(srule(xi \u2192 A))\n(15)\nFor the structural plausibility, we annotate the syntactical tree for each sentence through Berkeley parser (Kitaev and Klein, 2018; Kitaev et al., 2019), which is a SOTA parser based on T5 (Raffel et al., 2020) and trained on the Penn Treebank (PTB) (Taylor et al., 2003). We convert the tree to the form of left-branching chomsky normal form (CNF) (Chomsky, 1963), and omit non-terminal labels to obtain the tree skeleton. Our goal is to make the semantic tree structure resemble the annotated PTB tree structure. Given the annotated skeleton kn of the sentence xn, we minimize the conditional likelihood:\nLstr = \u2212 1\nN\nN\u2211\nn=1\nlog r(kn|xn)\nr(k|x) = 1 Z \u2032(x)\n\u220f c\u2208k exp\n(\u2211\nc\u2208k sspan(c)\n) (16)\nwhere c is a span in the skeleton k. As seen, r(k|x) is defined by a Gibbs distribution with span score functions in Equation (10). The normalization term Z \u2032(x) is also computed via the inside algorithm similar to Equation (12).\nThe final objective is the linear combination of the above three objectives7:\nL = \u03c9clsLcls + \u03c9posLpos + \u03c9strLstr (17) 6https://spacy.io/ 7Note that both plausibility objectives are conducted on incomplete annotations of the semantic tree. The principled way is to learn the distribution of these annotations conditioned on the input sentence, which is induced from the parser p(t|x) by marginalizing over all the remained unannotated structures. However, this marginalization is intractable in our case. Thus, here we only approximate the true distribution with the product of the expected counts.\nWhen the model is well-trained, it is able to not only predict the sentiment label but also generate the semantic tree as the explanation:\ny\u22c6 = argmax y\u2208Y p(y|x)\nt\u22c6 = argmax t\u2208Tx(y\u22c6)\np(t|x) (18)\nThe second argmax is to decode the best semantic tree with the maximal conditional probability, which is solved by the CKY algorithm (Kasami, 1965; Daniel, 1967)."
        },
        {
            "heading": "3 Experiments",
            "text": "In this section, we conduct experiments to illustrate that the proposed SCM module is able to improve the accuracy performance."
        },
        {
            "heading": "3.1 Datasets",
            "text": "We adopt MR (Pang and Lee, 2005) and SST2 (Socher et al., 2013) in this experiment. MR contains 10662 movie reviews, half of which are positive/negative. Since it has no train/dev/test splits, we follow the convenience to conduct 10-fold cross validation. SST2 is built from SST by binarizing the 5-class sentiment label. Common settings of\nSST2 include SST2-S which only uses the sentence for training, and SST2-P which uses all labeled non-neutral phrases for training, of which the training size is 6920 and 98794, respectively. In both settings, there are 872/1821 sentences for validation/testing."
        },
        {
            "heading": "3.2 Implementation",
            "text": "We utilize BiLSTM (Hochreiter and Schmidhuber, 1997) and BERT (Devlin et al., 2019) (base version) as backbone encoders for modeling the constituent representations. For both models, we use the first layer representations to compute the terminal-unary scores. We use momentum-based gradient descent (Qian, 1999) (we set the momentum to be 0.9), along with cosine annealing learning rate schedule (Loshchilov and Hutter, 2017) to optimize our models. For detailed hyper-parameter settings, please check the configuration files in our publicly available repository."
        },
        {
            "heading": "3.3 Baselines",
            "text": "Compared models include sequential models and three types of tree models: sentiment tree models, untagged tree models and latent untagged tree models. Both tree models ultilize recursive neural networks (RvNNs) (Socher et al., 2011) for modeling phrases in the sentence following a tree structure. Sentiment tree models have the full sentiment tree supervision, and learned to predict labels of all nodes in the tree. By contrasts, tree structures for untagged tree models are obtained by an external parser, and only the root node label is available for training. Latent untagged tree models learn to generate the tree structure itself, which is implicit supervised by the task objectives."
        },
        {
            "heading": "3.4 Results",
            "text": "We report the accuracy of different models in Table 2, which we can find that: 1) Compared to the original sequential model, we can see that adding the proposed SCM steadily improves the classification accuracy for both BiLSTM and BERT encoder all the datsets and settings, directly reflecting the effectiveness of our method. 2) Armed with the proposed SCM, the sequential BiLSTM achieves better or competitive performance with previous tree models on both datasets and settings. Specially, it outperforms each baselines on SST-2. This might suggest that the hierarchical RvNN is not necessarily the best way to model compositions, which a flat sequential model could do just as well. 3) We\nalso admit that the performance improvement from our method is not that huge, which our BiLSTM model doesn\u2019t surpass all compared models on MR and SST2-P. However, since our motivation is interpretability, we believe that the performance is sufficient."
        },
        {
            "heading": "4 Discussion",
            "text": ""
        },
        {
            "heading": "4.1 Sentiment Domain Adaptation",
            "text": "We conduct experiments in the cross-domain setting. We adopt Amazon in this experiment. Amazon is a widely-used domain adaption dataset collected by Blitzer et al. (2007). It contains review documents from the Amazon website in four domains: Books (B), DvDs (D), Electronics (E) and Kitchen & Housewares (K), where each domain contains 2000 labeled reviews. Following previous works, the model is trained on one domain and tested on the other three domains, yielding 12 crossdomain sentiment classification subtasks. For each subtask, we randomly sample 1600 examples in the source domain for training, and left the other 400 examples for validation.\nWe report the accuracy of different subtask in Table 3. As seen, compared to original sequential models, adding the proposed SCM improves the adaptation accuracy in most cases and on average as well, especially for BiLSTM which is trained from scratch. The improvement originates from the injected domain-invariant human knowledge in the proposed SCM, which helps the model to be less sensitive to the domain. The performance improvement of pretrained model BERT is not that significant because the pretraning process has already given the generalization ability to it."
        },
        {
            "heading": "4.2 Ablation Study",
            "text": "We conduct ablation study on SST2-S to study effects of different components including the grammar and two plausibility objectives. We report the accuracy and the unlabeled tree F1 of the generated semantic tree w.r.t. PTB trees generated by Berkeley parser for each model in Table 4.\nWe find that the grammar doesn\u2019t work out alone when two plausibility objectives are absent, where the accuracy drops compared to the original encoder. We speculate this is due to lack of direct information of function labels, making it easier to mis-recognition on those labels. Such error would accumulated from bottom to up in the tree and pollute other sentences including the same constituent, causing the performance drop.\nThe preterminal plausibility objective Lpos alleviates this issue effectively with an obvious performance improvement for both encoders. For the structure plausibility objective Lstr, though it makes the tree structure more syntactically meaningful with higher unlabeled tree F1, it doesn\u2019t necessarily guarantee the performance improvement. This suggests that the optimal tree structure might not exactly resemble PTB tree structure. On the contrary, the tree structure learned without Lstr, which has little similarity with PTB tree structure, is also suboptimal with mediocre accuracy. To study the optimal tree structure, we alter the balancing factor \u03c9str and obtain models with different unlabeled tree F1 w.r.t. PTB trees and accuracy. Then, we visualize relation between these two metrices in Figure 3. We can see that accuracy roughly shows a trend of first increasing and then decreasing when the tree gets more syntactical meaning-\nful for both encoders (i.e., has higher unlabeled tree F1). This is contrary to that of Williams et al. (2018) which finds that the optimal tree structure of untagged tree methods RL-SPINN (Yogatama et al., 2017) and Gumbel-Tree (Choi et al., 2018) do not resemble PTB tree structure. This might because our method has a specific grammar with syntactical information restraining the tree structure, while untagged tree methods accommodate for any structure."
        },
        {
            "heading": "4.3 Effects of SCG",
            "text": "To show the effectiveness of the proposed SCG, we compare it with the glue grammar (Taboada et al., 2011) whose binary rules are very free and in the form BC \u2192 A (A,B,C \u2208 {P,N,O}). Such rules act like the glue to connect adjacent constituents with any polarities. The results are shown in Table 5, which our proposed SCG is more effective with better accuracy compared to the glue grammar. We think this is because glue grammar rules are too free to carry specific sentiment composition knowledge, which is is helpless for the task."
        },
        {
            "heading": "4.4 Qualitative Study",
            "text": "We qualitatively show a few examples to show our method can handle compound sentiment composi-\ntions in Figure 4. The first case is a sentence with two negative constituents joining by a coordinating conjunction, each of which has an irrealis blocking within. The second case is a sentence with negation under conflict resolution. For both cases, the prediction is not simple since the model is susceptible to the surface and literal meaning in the sentence, which might interfere the correct decision. Taking the sentiment composition explicitly, we can see that our method successfully judge the semantic role of different constituents, and finally compose plausible tree explanations."
        },
        {
            "heading": "5 Related Works",
            "text": "Sentiment composition is one of the key to sentiment analysis, which considers the semantic of a constituent from both recognition and composition views (Polanyi and Zaenen, 2006; Moilanen and Pulman, 2007). That is, it decomposes the classification of a sentence into a hierarchical tree structure explicitly showing how the polarity of the sentence come from the composition of its subconstituents. Early works are mainly based on manual rules and semantic lexicon that is constructed either manually (Wilson et al., 2005; Kennedy and Inkpen, 2006) or automatically (Dong et al., 2015; Toledo-Ronen et al., 2018). Nowadays, represented via different forms of tree, sentiment composition is often learned explicitly or implicitly in the endto-end learning manner of neural network models.\nCommon tree forms include untagged tree and sentiment tree, while the learning paradigm is also varied in literature. To be concrete, untagged tree can either be directly obtained from the external syntactic parser (Socher et al., 2012; Tai et al., 2015; Liu et al., 2017a,b; Kim et al., 2019), or\nserve as a latent variable learned implicitly (Yogatama et al., 2017; Maillard and Clark, 2018; Choi et al., 2018; Havrylov et al., 2019; Chowdhury and Caragea, 2021). Compared to the untagged one, sentiment tree offers more information about sentiment polarity of each constituent in the tree. As the most representative resource in this form, SST (Socher et al., 2013) formalizes sentiment composition as a parsing task, motivating lots of works to learn the tree supervisedly (Teng and Zhang, 2017; Zhang and Zhang, 2019; Zhang et al., 2019). Sentiment tree is also a popular explanation form for post-hoc interprebility since it can provide hierahical attribution scores (Chen et al., 2020; Zhang et al., 2020). While both existing forms are useful, they are suboptimal due to their in-ability to explicitly interpret sentiment composition, which our proposed semantic tree fills this gap."
        },
        {
            "heading": "6 Conclusions",
            "text": "In this paper, we present semantic tree to explicitly interpret sentiment compositions in sentiment classification. we carefully design a grammar under each compositions from the linguistic inspiration, and learn to extract semantic tree explanations without full annotations. Quantitative and qualitative results demonstrate that our method is effective and can generate plausible tree explanations."
        },
        {
            "heading": "7 Limitations & Ethics Statement",
            "text": "Our method is first limited by the proposed grammar that doesn\u2019t cover all the realistic cases. As shown in Table 1, there are still a few cases in the randomly sampled 100 examples that none of the defined rules can explain. Secondly, the time complexity of our method is the cube of the sentence length, limiting its direct applications on long documents. So we have to classify the document based on classification of individual sentences, which might be problematic since the sentiment of different sentences in the document may affect each other.\nAll the experiments in this paper are conducted on public available datasets, which has no data privacy concerns. Meanwhile, this paper doesn\u2019t involve human annotations, so there are no related ethical concerns."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was supported by the National Key R&D Program of China (2022ZD0160503) and\nthe National Natural Science Foundation of China (No.61976211, No.62276264), and the Strategic Priority Research Program of Chinese Academy of Sciences (No.XDA27020100). This research was also supported by Meituan."
        },
        {
            "heading": "A Binary Rules",
            "text": "Table 6 shows all the binary rules contained in the proposed SCG."
        },
        {
            "heading": "B Functional Lexicon",
            "text": "Table 7 lists functional lexicon in the manually constructed lexicon.\nACL 2023 Responsible NLP Checklist"
        },
        {
            "heading": "A For every submission:",
            "text": "3 A1. Did you describe the limitations of your work?\n6\n7 A2. Did you discuss any potential risks of your work? We didn\u2019t see much risks of a sentiment classification work."
        },
        {
            "heading": "3 A3. Do the abstract and introduction summarize the paper\u2019s main claims?",
            "text": "In the Abstract section and section 1.\n7 A4. Have you used AI writing assistants when working on this paper? Left blank.\nB 3 Did you use or create scientific artifacts? 2\n3 B1. Did you cite the creators of artifacts you used? 3\nB2. Did you discuss the license or terms for use and / or distribution of any artifacts? Not applicable. Left blank.\n7 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? Datasets we use are publicly available.\n7 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? Datasets we use are publicly available for years, we don\u2019t see much concerns on this issue.\n7 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? Datasets, along with their documentations are publicly available.\n3 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. 3\nC 3 Did you run computational experiments? 3\n7 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? There are too many parameters, which reporting them makes the paper cumbersome. Please check the config file in our public code repository for details.\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.\n7 C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Please check the config file in our public code repository for details.\n7 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? Experimental results are stable with different seeds, and the time complexity is relatively high."
        },
        {
            "heading": "3 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did",
            "text": "you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)? 2.4\nD 7 Did you use human annotators (e.g., crowdworkers) or research with human participants? Left blank.\nD1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.? No response.\nD2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants\u2019 demographic (e.g., country of residence)? No response.\nD3. Did you discuss whether and how consent was obtained from people whose data you\u2019re using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used? No response.\nD4. Was the data collection protocol approved (or determined exempt) by an ethics review board? No response.\nD5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? No response."
        }
    ],
    "title": "Interpreting Sentiment Composition with Latent Semantic Tree",
    "year": 2023
}