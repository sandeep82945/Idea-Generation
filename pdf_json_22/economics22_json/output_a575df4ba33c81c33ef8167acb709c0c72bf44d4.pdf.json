{
    "abstractText": "Although a large body of literature has examined the effects of open government from a theoretical perspective, evidence on the empirical effects is still limited. This paper analyses parental response to an open government initiative consisting of the publication on a government website of school inspection reports. As an indicator of school quality, school inspection reports allow parents to make well informed school choices for their children. We employ a unique natural experiment in Belgium where schools are randomly selected for inspection, and online school inspection reports are the first and only source of objective quality data publicly available. This results in exogenous information shocks. Our findings indicate that information about school quality strongly affects school choice. After the publication, inspected schools experience higher enrolments, with effects driven by positively evaluated schools and rural schools. No differentiated response is observed by schools' socioeconomic composition. We interpret these findings as evidence that parents made extensive use of the government website on which school inspection reports were published.",
    "authors": [
        {
            "affiliations": [],
            "name": "Silvia Palmaccio"
        },
        {
            "affiliations": [],
            "name": "Kristof De Witte"
        }
    ],
    "id": "SP:ac5f8b5a5289922dda32eaa0be8ce20ae9733ada",
    "references": [
        {
            "authors": [
                "A. Abadie",
                "A. Diamond",
                "J. Hainmueller"
            ],
            "title": "Synthetic control methods for comparative case studies: Estimating the effect of California\u2019s tobacco control program",
            "venue": "Journal of the American Statistical Association,",
            "year": 2010
        },
        {
            "authors": [
                "A. Abdulkadiro\u011flu",
                "P.A. Pathak",
                "J. Schellenberg",
                "C.R. Walters"
            ],
            "title": "Do parents value school effectiveness",
            "venue": "American Economic Review,",
            "year": 2020
        },
        {
            "authors": [
                "T. Aitamurto",
                "K. Chen"
            ],
            "title": "The value of crowdsourcing in public policymaking: Epistemic, democratic and economic value",
            "venue": "The Theory and Practice of Legislation,",
            "year": 2017
        },
        {
            "authors": [
                "T. Aitamurto",
                "H. Landemore"
            ],
            "title": "Crowdsourced deliberation: The case of the law on off-road traffic in Finland",
            "venue": "Policy & Internet,",
            "year": 2016
        },
        {
            "authors": [
                "B.A. Almanza",
                "J. Ismail",
                "J.E. Mills"
            ],
            "title": "The impact of publishing foodservice inspection scores",
            "venue": "Journal of Foodservice Business Research,",
            "year": 2002
        },
        {
            "authors": [
                "T. Andrabi",
                "J. Das",
                "A.I. Khwaja"
            ],
            "title": "Report cards: The impact of providing school and child test scores on educational markets",
            "venue": "American Economic Review,",
            "year": 2017
        },
        {
            "authors": [
                "B. Ansari",
                "M. Barati",
                "E.G. Martin"
            ],
            "title": "Enhancing the usability and usefulness of open government data: A comprehensive review of the state of open government data visualization research",
            "venue": "Government Information Quarterly,",
            "year": 2021
        },
        {
            "authors": [
                "W.J. Armstrong",
                "L. Cardella",
                "N. Sabah"
            ],
            "title": "Information shocks, disagreement, and drift",
            "venue": "Journal of Financial Economics,",
            "year": 2021
        },
        {
            "authors": [
                "J. Attard",
                "F. Orlandi",
                "S. Scerri",
                "S. Auer"
            ],
            "title": "A systematic review of open government data initiatives",
            "venue": "Government Information Quarterly,",
            "year": 2015
        },
        {
            "authors": [
                "D.H. Autor"
            ],
            "title": "Outsourcing at will: The contribution of unjust dismissal doctrine to the growth of employment outsourcing",
            "venue": "Journal of Labor Economics,",
            "year": 2003
        },
        {
            "authors": [
                "D. Avdic",
                "A. Karimi"
            ],
            "title": "Modern family? Paternity leave and marital stability",
            "venue": "American Economic Journal: Applied Economics,",
            "year": 2018
        },
        {
            "authors": [
                "C. Avitabile",
                "R. De Hoyos"
            ],
            "title": "The heterogeneous effect of information on student performance: Evidence from a randomized control trial in Mexico",
            "venue": "Journal of Development Economics,",
            "year": 2018
        },
        {
            "authors": [
                "H. Bae"
            ],
            "title": "Reducing environmental risks by information disclosure: Evidence in residential lead paint disclosure rule",
            "venue": "Journal of Policy Analysis and Management,",
            "year": 2012
        },
        {
            "authors": [
                "K. Balcombe",
                "I. Fraser",
                "S. Di Falco"
            ],
            "title": "Traffic lights and food choice: A choice experiment examining the relationship between nutritional food labels and price",
            "venue": "Food Policy,",
            "year": 2010
        },
        {
            "authors": [
                "L.S. Bennear",
                "S.M. Olmstead"
            ],
            "title": "The impacts of the \u201cright to know\u201d: Information disclosure and the violation of drinking water standards",
            "venue": "Journal of Environmental Economics and Management,",
            "year": 2008
        },
        {
            "authors": [
                "Y. Bernard",
                "L. Bertrandias",
                "L. Elgaaied-Gambier"
            ],
            "title": "Shoppers\u2019 grocery choices in the presence of generalized eco-labelling",
            "venue": "International Journal of Retail & Distribution Management.,",
            "year": 2015
        },
        {
            "authors": [
                "E. Bons\u00f3n",
                "L. Torres",
                "S. Royo",
                "F. Flores"
            ],
            "title": "Local e-government 2.0: Social media and corporate transparency in municipalities",
            "venue": "Government Information Quarterly,",
            "year": 2012
        },
        {
            "authors": [
                "K. Boussauw",
                "M. Van Meeteren",
                "F. Witlox"
            ],
            "title": "Short trips and central places: The home-school distances in the Flemish primary education system (Belgium)",
            "venue": "Applied Geography,",
            "year": 2014
        },
        {
            "authors": [
                "S. Burgess",
                "E. Greaves",
                "A. Vignoles",
                "D. Wilson"
            ],
            "title": "What parents want: School preferences and school choice",
            "venue": "Economic Journal,",
            "year": 2015
        },
        {
            "authors": [
                "L. Bursztyn"
            ],
            "title": "Poverty and the political economy of public education spending: Evidence from Brazil",
            "venue": "Journal of the European Economic Association,",
            "year": 2016
        },
        {
            "authors": [
                "B. Camargo",
                "R. Camelo",
                "S. Firpo",
                "V. Ponczek"
            ],
            "title": "Information, market incentives, and student performance evidence from a regression discontinuity Design in Brazil",
            "venue": "Journal of Human Resources,",
            "year": 2018
        },
        {
            "authors": [
                "F.L. Cook",
                "L.R. Jacobs",
                "D. Kim"
            ],
            "title": "Trusting what you know: Information, knowledge, and confidence in social security",
            "venue": "The Journal of Politics,",
            "year": 2010
        },
        {
            "authors": [
                "A.S. Cordis",
                "P.L. Warren"
            ],
            "title": "Sunshine as disinfectant: The effect of state freedom of information act laws on public corruption",
            "venue": "Journal of Public Economics,",
            "year": 2014
        },
        {
            "authors": [
                "N.F. da Cruz",
                "A.F. Tavares",
                "R.C. Marques",
                "S. Jorge",
                "L. De Sousa"
            ],
            "title": "Measuring local government transparency",
            "venue": "Public Management Review,",
            "year": 2016
        },
        {
            "authors": [
                "M. Cucciniello",
                "G.A. Porumbescu",
                "S. Grimmelikhuijsen"
            ],
            "title": "2017). 25 years of transparency research: Evidence and future directions",
            "venue": "Public Administration Review,",
            "year": 2017
        },
        {
            "authors": [
                "K. De Witte",
                "G. D\u2019Inverno",
                "M. Smet"
            ],
            "title": "The effect of additional resources for schools with disadvantaged students: Evidence from a conditional efficiency model",
            "year": 2018
        },
        {
            "authors": [
                "K. De Witte",
                "D.S. Saal"
            ],
            "title": "Is a little sunshine all we need? On the impact of sunshine regulation on profits, productivity and prices in the Dutch drinking water",
            "venue": "sector. Journal of Regulatory Economics,",
            "year": 2010
        },
        {
            "authors": [
                "K. De Witte",
                "V. Titl",
                "O. Holz",
                "M. Smet"
            ],
            "title": "Financing quality education for all: The funding methods of compulsory and special needs education",
            "year": 2019
        },
        {
            "authors": [
                "M. Delmas",
                "M.J. Montes-Sancho",
                "J.P. Shimshack"
            ],
            "title": "Information disclosure policies: Evidence from the electricity industry",
            "venue": "Economic Inquiry,",
            "year": 2010
        },
        {
            "authors": [
                "G. Duwe",
                "W. Donnay"
            ],
            "title": "The impact of Megan\u2019s law on sex offender recidivism: The Minnesota experience",
            "year": 2008
        },
        {
            "authors": [
                "P. Eichholtz",
                "N. Kok",
                "J.M. Quigley"
            ],
            "title": "Doing well by doing good? Green office buildings",
            "venue": "American Economic Review,",
            "year": 2010
        },
        {
            "authors": [
                "D.N. Figlio",
                "L.S. Getzler"
            ],
            "title": "Accountability, ability and disability: Gaming the system",
            "venue": "Advances in Applied Microeconomics,",
            "year": 2006
        },
        {
            "authors": [
                "D.N. Figlio",
                "M.E. Lucas"
            ],
            "title": "What\u2019s in a grade? School report cards and the housing market",
            "venue": "American Economic Review,",
            "year": 2004
        },
        {
            "authors": [
                "S.G. Grimmelikhuijsen",
                "S.J. Piotrowski",
                "G.G. Van Ryzin"
            ],
            "title": "Latent transparency and trust in government: Unexpected findings from two survey experiments",
            "venue": "Government Information Quarterly,",
            "year": 2020
        },
        {
            "authors": [
                "S. Groenez",
                "J. Surkyn"
            ],
            "title": "Een capaciteitsmonitor voor het leerplichtonderwijs - editie 2018: Meta-analyse",
            "venue": "KU Leuven - HIVA. Available at https://onderwijs.vlaanderen",
            "year": 2018
        },
        {
            "authors": [
                "P. Gunawong"
            ],
            "title": "Open government and social media: A focus on transparency",
            "venue": "Social Science Computer Review,",
            "year": 2015
        },
        {
            "authors": [
                "M. Harakeh"
            ],
            "title": "Dividend policy and corporate investment under information shocks",
            "venue": "Journal of International Financial Markets, Institutions and Money,",
            "year": 2020
        },
        {
            "authors": [
                "J. Hastings",
                "T.J. Kane",
                "D.O. Staiger"
            ],
            "title": "Heterogeneous preferences and the efficacy of public school choice",
            "venue": "NBER Working Paper (pp. 1\u201346)",
            "year": 2009
        },
        {
            "authors": [
                "J.S. Hastings",
                "J.M. Weinstein"
            ],
            "title": "Information, school choice, and academic achievement: Evidence from two experiments",
            "venue": "Quarterly Journal of Economics,",
            "year": 2008
        },
        {
            "authors": [
                "J.B. Holbein",
                "H.F. Ladd"
            ],
            "title": "Accountability pressure: Regression discontinuity estimates of how no child left behind influenced student behavior",
            "venue": "Economics of Education Review,",
            "year": 2017
        },
        {
            "authors": [
                "M. Hung",
                "X. Li",
                "S. Wang"
            ],
            "title": "Post-earnings-announcement drift in global markets: Evidence from an information shock",
            "venue": "The Review of Financial Studies,",
            "year": 2015
        },
        {
            "authors": [
                "I. Hussain"
            ],
            "title": "Subjective performance evaluation in the public sector: Evidence from school inspections",
            "venue": "Journal of Human Resources,",
            "year": 2015
        },
        {
            "authors": [
                "M. Hyland",
                "R.C. Lyons",
                "S. Lyons"
            ],
            "title": "The value of domestic building energy efficiency\u2014Evidence from Ireland",
            "venue": "Energy Economics,",
            "year": 2013
        },
        {
            "authors": [
                "B.A. Jacob"
            ],
            "title": "Accountability, incentives and behavior: The impact of high-stakes testing in the Chicago public schools",
            "venue": "Journal of Public Economics,",
            "year": 2005
        },
        {
            "authors": [
                "B.A. Jacob",
                "S.D. Levitt"
            ],
            "title": "Rotten apples: An investigation of the prevalence and predictors of teacher cheating",
            "venue": "Quarterly Journal of Economics,",
            "year": 2003
        },
        {
            "authors": [
                "M. Janssen",
                "Y. Charalabidis",
                "A. Zuiderwijk"
            ],
            "title": "Benefits, adoption barriers and myths of open data and open government",
            "venue": "Information Systems Management,",
            "year": 2012
        },
        {
            "authors": [
                "M. Jaroci\u0144ski",
                "P. Karadi"
            ],
            "title": "Deconstructing monetary policy surprises\u2014The role of information shocks",
            "venue": "American Economic Journal: Macroeconomics,",
            "year": 2020
        },
        {
            "authors": [
                "G.J. Jiang",
                "K.X. Zhu"
            ],
            "title": "Information shocks and short-term market underreaction",
            "venue": "Journal of Financial Economics,",
            "year": 2017
        },
        {
            "authors": [
                "G.Z. Jin",
                "P. Leslie"
            ],
            "title": "The effect of information on product quality: Evidence from restaurant hygiene grade cards",
            "venue": "The Quarterly Journal of Economics,",
            "year": 2003
        },
        {
            "authors": [
                "M.S. Johnson"
            ],
            "title": "Regulation by shaming: Deterrence effects of publicizing violations of workplace safety and health",
            "venue": "laws. American Economic Review,",
            "year": 2020
        },
        {
            "authors": [
                "B.C. Karkkainen"
            ],
            "title": "Information as environmental regulation: Tri and performance benchmarking, precursor to a new paradigm",
            "venue": "Georgetown Law J.,",
            "year": 2001
        },
        {
            "authors": [
                "D.A. Koehler",
                "J.D. Spengler"
            ],
            "title": "The toxic release inventory: Fact or fiction? A case study of the primary aluminum industry",
            "venue": "Journal of Environmental Management,",
            "year": 2007
        },
        {
            "authors": [
                "P. Koning",
                "K. Van der Wiel"
            ],
            "title": "Ranking the schools: How school-quality information affects school choice in the Netherlands",
            "venue": "Journal of the European Economic Association,",
            "year": 2013
        },
        {
            "authors": [
                "D. de Kool",
                "V. Bekkers"
            ],
            "title": "The perceived impact of open inspection data on the quality of education in Dutch primary schools: A parent perspective",
            "venue": "Social Science Computer Review,",
            "year": 2015
        },
        {
            "authors": [
                "S.Y. Lee",
                "J.M. D\u00edaz-Puente",
                "S. Martin"
            ],
            "title": "The contribution of open government to prosperity of society",
            "venue": "International Journal of Public Administration,",
            "year": 2019
        },
        {
            "authors": [
                "J.S. Levenson",
                "L.P. Cotter"
            ],
            "title": "The effect of Megan\u2019s law on sex offender reintegration",
            "venue": "Journal of Contemporary Criminal Justice,",
            "year": 2005
        },
        {
            "authors": [
                "C. Lindstedt",
                "D. Naurin"
            ],
            "title": "Transparency is not enough: Making transparency effective in reducing corruption",
            "venue": "International Political Science Review,",
            "year": 2010
        },
        {
            "authors": [
                "M.L. Loureiro",
                "J. Lotade"
            ],
            "title": "Do fair trade and eco-labels in coffee wake up the consumer conscience",
            "venue": "Ecological Economics,",
            "year": 2005
        },
        {
            "authors": [
                "S. Machin"
            ],
            "title": "Houses and schools: Valuation of school quality through the housing market",
            "venue": "Labour Economics,",
            "year": 2011
        },
        {
            "authors": [
                "E. Maseh",
                "S. Katuu"
            ],
            "title": "The Kenyan Judiciary\u2019s open government initiative: Prospects and challenges",
            "venue": "Journal of Science and Technology Policy Management,",
            "year": 2017
        },
        {
            "authors": [
                "I. Mergel",
                "A. Kleibrink",
                "J. S\u00f6rvik"
            ],
            "title": "Open data outcomes: US cities between product and process innovation",
            "venue": "Government Information Quarterly,",
            "year": 2018
        },
        {
            "authors": [
                "A. Mizala",
                "M. Urquiola"
            ],
            "title": "School markets: The impact of information approximating schools",
            "venue": "effectiveness. Journal of Development Economics,",
            "year": 2013
        },
        {
            "authors": [
                "L.C. Nunes",
                "A.B. Reis",
                "C. Seabra"
            ],
            "title": "The publication of school rankings: A step toward increased accountability",
            "venue": "Economics of Education Review,",
            "year": 2015
        },
        {
            "authors": [
                "D. Nusche",
                "G. Miron",
                "P. Santiago",
                "R. Teese"
            ],
            "title": "OECD reviews of school resources: Flemish Community of Belgium 2015 (OECD Reviews of School Resources)",
            "year": 2015
        },
        {
            "authors": [
                "S. Park",
                "J.R. Gil-Garcia"
            ],
            "title": "Open data innovation: Visualizations and process redesign as a way to bridge the transparency-accountability gap",
            "venue": "Government Information Quarterly,",
            "year": 2021
        },
        {
            "authors": [
                "M. Penninckx",
                "J. Vanhoof",
                "S. De Maeyer",
                "P. Van Petegem"
            ],
            "title": "Exploring and explaining the effects of being inspected",
            "venue": "Educational Studies,",
            "year": 2014
        },
        {
            "authors": [
                "J.M. Rothstein"
            ],
            "title": "Good principals or good peers? Parental valuation of school characteristics, Tiebout equilibrium, and the incentive effects of competition among jurisdictions",
            "venue": "American Economic Review,",
            "year": 2006
        },
        {
            "authors": [
                "D. Shi",
                "C. Bu",
                "H. Xue"
            ],
            "title": "Deterrence effects of disclosure: The impact of environmental information disclosure on emission reduction of firms",
            "venue": "Energy Economics,",
            "year": 2021
        },
        {
            "authors": [
                "J. Shkabatur"
            ],
            "title": "Transparency with (out) accountability: Open government in the United States",
            "venue": "Yale Law Policy Review,",
            "year": 2013
        },
        {
            "authors": [
                "D. Standaard"
            ],
            "title": "Katholiek onderwijs is het grootste net. https://www.standaard",
            "year": 2014
        },
        {
            "authors": [
                "Tai",
                "K.-T"
            ],
            "title": "Open government research over a decade: A systematic review",
            "venue": "Government Information Quarterly,",
            "year": 2021
        },
        {
            "authors": [
                "M.F. Teisl",
                "B. Roe",
                "R.L. Hicks"
            ],
            "title": "Can eco-labels tune a market? Evidence from dolphin-safe labeling",
            "venue": "Journal of Environmental Economics and Management,",
            "year": 2002
        },
        {
            "authors": [
                "K.C. Vadlamannati",
                "A. Cooray"
            ],
            "title": "Transparency pays? Evaluating the effects of the freedom of information Laws on perceived government corruption",
            "venue": "The Journal of Development Studies,",
            "year": 2017
        },
        {
            "authors": [
                "J. Van Erp"
            ],
            "title": "Naming and shaming in regulatory enforcement",
            "year": 2011
        },
        {
            "authors": [
                "J.N. Variyam"
            ],
            "title": "Do nutrition labels improve dietary outcomes",
            "venue": "Health Economics,",
            "year": 2008
        },
        {
            "authors": [
                "B.W. Wirtz",
                "J.C. Weyerer",
                "M. R\u00f6sch"
            ],
            "title": "Open government and citizen participation: An empirical analysis of citizen expectancy towards open government data",
            "venue": "International Review of Administrative Sciences,",
            "year": 2019
        },
        {
            "authors": [
                "I.F. de Wolf",
                "F.J. Janssens"
            ],
            "title": "Effects and side effects of inspections and accountability in education: An overview of empirical studies",
            "venue": "Oxford Review of Education,",
            "year": 2007
        },
        {
            "authors": [
                "J.M. Wooldridge"
            ],
            "title": "Econometric analysis of cross section and panel data",
            "year": 2002
        },
        {
            "authors": [
                "Y. MA: MIT Press. Xu"
            ],
            "title": "Generalized synthetic control method: Causal inference with interactive",
            "year": 2017
        },
        {
            "authors": [
                "A. Zuiderwijk",
                "M. Janssen"
            ],
            "title": "Barriers and development directions",
            "year": 2014
        },
        {
            "authors": [
                "KU Leuven"
            ],
            "title": "Fritz's research focuses on using data analytics and econometrics to improve education policies. Kristof De Witte is a professor at the Faculty of Economics and Business at KU Leuven, Belgium, and he holds the chair in \u201cEffectiveness and Efficiency of Educational Innovations",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Information shocks and parental response in education. A case study of an open government initiative Citation for published version (APA):\nPalmaccio, S., Schiltz, F., & De Witte, K. (2022). Information shocks and parental response in education. A case study of an open government initiative. Government Information Quarterly, 39(3), Article 101702. https://doi.org/10.1016/j.giq.2022.101702\nDocument status and date: Published: 01/07/2022\nDOI: 10.1016/j.giq.2022.101702\nDocument Version: Publisher's PDF, also known as Version of record\nDocument license: Taverne\nPlease check the document version of this publication:\n\u2022 A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. \u2022 The final author version and the galley proof are versions of the publication after peer review. \u2022 The final published version features the final layout of the paper including the volume, issue and page numbers. Link to publication\nGeneral rights Copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights.\n\u2022 Users may download and print one copy of any publication from the public portal for the purpose of private study or research. \u2022 You may not further distribute the material or use it for any profit-making activity or commercial gain \u2022 You may freely distribute the URL identifying the publication in the public portal.\nIf the publication is distributed under the terms of Article 25fa of the Dutch Copyright Act, indicated by the \u201cTaverne\u201d license above, please follow below link for the End User Agreement: www.umlib.nl/taverne-license\nTake down policy If you believe that this document breaches copyright please contact us at:\nrepository@maastrichtuniversity.nl\nproviding details and we will investigate your claim.\nDownload date: 25 Jan. 2024\nGovernment Information Quarterly 39 (2022) 101702"
        },
        {
            "heading": "Available online 28 April 2022",
            "text": "0740-624X/\u00a9 2022 Elsevier Inc. All rights reserved.\nInformation shocks and parental response in education. A case study of an open government initiative1\nSilvia Palmaccio a,*, Fritz Schiltz a, Kristof De Witte a,b\na Leuven Economics of Education Research, KU Leuven, Naamsestraat 69, 3000 Leuven, Belgium b UNU-MERIT, Maastricht University, Boschstraat 24, 6211 AX, Maastricht, the Netherlands\nA R T I C L E I N F O"
        },
        {
            "heading": "Keywords:",
            "text": "Open government Information shock Transparency School inspection reports School choice Difference-in-differences Generalized synthetic control method\nA B S T R A C T\nAlthough a large body of literature has examined the effects of open government from a theoretical perspective, evidence on the empirical effects is still limited. This paper analyses parental response to an open government initiative consisting of the publication on a government website of school inspection reports. As an indicator of school quality, school inspection reports allow parents to make well informed school choices for their children. We employ a unique natural experiment in Belgium where schools are randomly selected for inspection, and online school inspection reports are the first and only source of objective quality data publicly available. This results in exogenous information shocks. Our findings indicate that information about school quality strongly affects school choice. After the publication, inspected schools experience higher enrolments, with effects driven by positively evaluated schools and rural schools. No differentiated response is observed by schools' socioeconomic composition. We interpret these findings as evidence that parents made extensive use of the government website on which school inspection reports were published."
        },
        {
            "heading": "1. Introduction",
            "text": "Public institutions are increasingly expected to share information about their processes, from national governments to local authorities. Since the Open Government Declaration issued in the US in 2009, an increasing number of countries have adopted open government initiatives, including data portals, social media tools, and government websites (Attard, Orlandi, Scerri, & Auer, 2015; Bonso\u0301n, Torres, Royo, & Flores, 2012; da Cruz, Tavares, Marques, Jorge, & De Sousa, 2016). The intended theoretical effects of these initiatives are several, ranging from government transparency and government accountability to citizens participation (for a review, see Tai, 2021). The availability of government websites in which government data is freely accessible online has endowed citizens with large amounts of data that can be used to monitor government performance (da Cruz et al., 2016). However, publishing\ndata (and particularly open data) may be not enough to promote government accountability, as citizens may lack the proper knowledge to use such data (Janssen, Charalabidis, & Zuiderwijk, 2012), and a \u201cbroken link\u201d may emerge between transparency and accountability (Park & Gil-Garcia, 2021; Shkabatur, 2013). In other words, clear and accessible information on the public sector is a necessary condition to reap the benefits of open government.\nThis paper investigates citizens' (hereafter parents) response to information shocks using the online publication of school inspection reports in Flanders (the Dutch speaking region of Belgium) as case study. In the education market, increased transparency in indicators used to measure quality can help parents to choose a school (Koning & Van der Wiel, 2013), and can even be a tool for regulatory enforcement through the \u201cnaming and shaming\u201d of low performers (De Witte & Saal, 2010; Van Erp, 2011). A number of studies has focused on the direct effects of\n* Corresponding Author. E-mail addresses: silvia.palmaccio@kuleuven.be (S. Palmaccio), fritz.schiltz@kuleuven.be (F. Schiltz), kristof.dewitte@kuleuven.be, k.dewitte@ maastrichtuniversity.nl (K. De Witte). 1 The data for this study are provided by the Education Authority of Belgium. As the data are protected by a confidentiality agreement, we are precluded from sharing the data with others. We would be happy to provide assistance and Stata code to replicate the results of this study. We are grateful to Gerd Van den Eede, Kosuke Imai, Jrn-Steffen Pischke, William Parient, Thomas Wouters, Deni Mazrekaj, Erwin Ooghe, Iris Kesternich, Jill Johnes, Daniel Horn, Maarten Penninckx, Philip Oreopoulos, and participants at seminars and conferences in Brussels, Lisbon (ESEE), Budapest (CERSHAS), Leuven (LEER), Catanzaro (IWAEE) and Louvainla-Neuve (BDLE) for comments and suggestions. The authors acknowledge financial support from KU Leuven (grant 3H180266), FWO (grant G067120N) and Horizon Europe project\u2019DemoTrans' (grant 101059288). The usual disclaimer applies.\nContents lists available at ScienceDirect\nGovernment Information Quarterly\njournal homepage: www.elsevier.com/locate/govinf\nhttps://doi.org/10.1016/j.giq.2022.101702 Received 21 April 2021; Received in revised form 22 March 2022; Accepted 25 March 2022\nGovernment Information Quarterly 39 (2022) 101702\n2\ninformation provision on school choice (Hastings & Weinstein, 2008; Koning & Van der Wiel, 2013; Mizala & Urquiola, 2013; Nunes, Reis, & Seabra, 2015). However, contrary to earlier studies, this paper provides evidence on the impact of information in a context where parents have no access to any other indicator of school quality (e.g. test scores). Importantly, as the information is uniquely released on a government website, the particular setting of our study allows to empirically examine the effects of an open government initiative, namely the online publication of school inspection reports.\nWe label this unprecedented provision of information as \u201cinformation shock\u201d. This terminology is often employed in the economics (e.g. Avdic & Karimi, 2018; Bursztyn, 2016; Jarocin\u0301ski & Karadi, 2020) and finance (e.g. Armstrong, Cardella, & Sabah, 2021; Harakeh, 2020; Hung, Li, & Wang, 2015; Jiang & Zhu, 2017) literature to indicate an exogenous, unanticipated provision of information to individuals, that affects an outcome of interest.2 Our identification strategy exploits a unique natural experiment in Flanders (the Dutch speaking region of Belgium), where primary schools are randomly selected for school inspection. Apart from school inspection reports, no other objective information on school quality is accessible by parents due to the lack of central examinations. That is, apart from the reports, parents can only rely on subjective sources of information such as word of mouth. As a result, the disclosure of information is the first and only source of objective school quality data parents can rely on.3 By defining the publication of inspection reports a \u201cshock\u201d, therefore, we intend to highlight the exogeneity of the event (schools are randomly selected for inspection), its unpredictability (schools do not know in advance whether they are going to be inspected), and the absence of other accountability tools available to parents before the reports are published. This allows us, in the estimations, to employ a difference-in-differences model using inspected schools as our treatment group and non-inspected schools as our control group. By comparing schools before and after the publication of inspection reports, we attempt to single out the causal effect of information shocks.\nWith our study, first, we contribute to the literature examining the empirical effects of open government (e.g. Aitamurto & Chen, 2017; Aitamurto & Landemore, 2016; de Kool & Bekkers, 2015; Grimmelikhuijsen, Piotrowski, & Van Ryzin, 2020; Gunawong, 2015; Lee, D\u00edazPuente, & Martin, 2019; Maseh & Katuu, 2017; Mergel, Kleibrink, & So\u0308rvik, 2018; Z\u030cuffova\u0301, 2020). Within two months after the inspection, inspection reports are released online on a government website. The lack of other objective information on school quality as well as the speed in the circulation of information, creates a setting that allows us to (indirectly) relate parental response to open government. Although a large body of literature has explored the theoretical effects of open government, evidence on its empirical effects is still limited, particularly with regard to the use and attitudes of citizens toward open government (Tai, 2021; Wirtz, Weyerer, & Ro\u0308sch, 2019). In a review of the literature, Tai (2021) identifies only two studies investigating the empirical impacts of open government on individuals (Aitamurto & Landemore, 2016; de Kool & Bekkers, 2015). The first study focuses on the effects of a crowdsourced law reform in Finland (Aitamurto & Landemore, 2016). The second study, closer to ours, investigates the perceived impact of online inspection reports in the Netherlands (de Kool & Bekkers, 2015). The authors find that even though Dutch parents consult the inspection website, they consider the inspection data to be of little use. However, de Kool and Bekkers (2015) use a mixed methodology consisting for one\npart of semi-structured interviews, and for the other part of surveys (that may be prone to response and recall biases). We complement their analysis by offering empirical evidence of parental response using a combination of objective administrative data and public inspection data.\nOur paper also makes a specific contribution to the literature on information provision and school choice (Hastings & Weinstein, 2008; Koning & Van der Wiel, 2013; Mizala & Urquiola, 2013; Nunes et al., 2015), as we examine the important role market dynamics play in shaping the effects of performance information. Specifically, we investigate whether the effects of information shocks might be different according to the degree of urbanization of the municipality where the school is located. We may expect that schools located in city centers experience a higher level of competition as a result of the broader school choice set available to parents, while the opposite may be true for schools located in low dense areas. If urban schools are already at the maximum capacity of enrolments for the academic year when the reports are published, they may not be able to accommodate an immediate rise in demand following the information shock, and no effect would be found. To account for school market dynamics, first, we assess the effect of information shocks distinctively for rural and urban schools. Second, as a robustness test, we explicitly define school local markets as the sets of schools laying within a certain radius of kilometers from the evaluated school.\nOur results provide evidence that parents do respond to information shocks. Primary schools face an increase in demand, measured by a rise in first grade students, after inspection reports are published. The effect grows larger over time and is driven by schools that received a positive evaluation, whereas schools with negative evaluations do not significantly lose students. No change in schools' SES composition emerges, suggesting that both high- and low-SES parents are likely to react to school quality data. Finally, a difference is detected according to the spatial distribution of schools in the local market. Specifically, information shocks are found to positively affect parental school choice in rural areas, while no effect is found in urban areas. We interpret these findings as evidence that parents consulted school inspection reports, thereby using the government website on which the reports were published. Our findings are robust to a battery of tests, including various fixed effects specifications, synthetic control estimates, different specifications of school local markets, and alternative definitions of primary schools depending on the grades offered in the same building."
        },
        {
            "heading": "2. Literature review",
            "text": "This section begins by illustrating earlier literature that has examined the impacts on society of government proactive release of information. Then, we review earlier research on information provision and school choice. Finally, we discuss the determinants of school choice and reflect on how these determinants relate to past research on information provision and school choice. By describing earlier literature, we illustrate the specific contributions of this paper."
        },
        {
            "heading": "2.1. Information provision and public response",
            "text": "Several studies have shown that the proactive release of information to the public by the government is beneficial to society. Information dissemination can be implemented primarily through disclosure regulations, i.e. through policies that require recipients to disclose certain types of information.\nThe objectives and the empirical effects of disclosure regulations are various. Disclosure programs ultimately aimed at improving collective health and safety have been shown to increase firms' compliance with health standards in the drinking water industry (Bennear & Olmstead, 2008), to discourage hazardous behaviors (related to lead paint) in the housing market (Bae, 2012), to reduce work-related accidents (Johnson, 2020), and to lower recidivism among sex offenders (Duwe & Donnay, 2008; Levenson & Cotter, 2005). Disclosure regulations requiring restaurants to disclose health inspection scores have been found to improve restaurants' future inspection scores and to reduce hospitalizations due 2 For instance, the term \u2018information shock\u2019 is used to indicate the disclosure of information on public spending in Bursztyn (2016); on the quality of public companies in Hung et al. (2015); Harakeh (2020); on monetary policy interventions in Jarocin\u0301ski and Karadi (2020); on oil prices in Armstrong et al. (2021); and on partners' matching quality in Avdic and Karimi (2018). 3 The absence of any other source of school quality data allows us to consider school inspection reports as a proxy for school quality in the remainder of this paper. However, and as we further discuss in Section 7, we acknowledge that school inspection reports are only imperfect measures of school quality.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n3\nto food poisoning (Jin & Leslie, 2003).4 Finally, disclosure regulations directed at reducing the environmental footprint of production have been found to abate firms' pollutant emissions (Shi, Bu, & Xue, 2021), to increase firms' green energy supply in the energy industry (Delmas, Montes-Sancho, & Shimshack, 2010), and to be negatively correlated with firms' toxic releases (Karkkainen, 2001; Koehler & Spengler, 2007).\nDisclosure regulations can also be implemented by governments through the enforcement of labelling requirements.5 Earlier literature has shown that these requirements are for the most part effective in influencing the behavior of the public. For instance, energy labels that assign an official certification to energy efficient buildings have been found to affect rental prices in the housing market (Eichholtz, Kok, & Quigley, 2010; Hyland, Lyons, & Lyons, 2013). Nutrition labels that reveal product nutrients were found to influence consumers' dietary habits and to discourage the purchase of unhealthy products (Balcombe, Fraser, & Di Falco, 2010; Variyam, 2008). Finally, eco-labels that disclose product sustainability have been shown to affect consumer preferences and to redirect those preferences toward environmentally friendly products (see e.g. Bernard, Bertrandias, & Elgaaied-Gambier, 2015; Loureiro & Lotade, 2005; Teisl, Roe, & Hicks, 2002).\nThe release of government information by the government may also affect the level of trust society places in government and the level of public corruption. Regarding trust, some studies showed a positive impact of government transparency on public trust (e.g. Cook, Jacobs, & Kim, 2010), while other studies found that this effect is not significant or is even negative (for a review, see Cucciniello, Porumbescu, & Grimmelikhuijsen, 2017). A possible explanation for these findings is provided by Grimmelikhuijsen et al. (2020), who distinguished between latent transparency (i.e. citizens' awareness that they can monitor governmental processes) and manifest transparency (i.e. the possibility to monitor governmental processes), finding that latent transparency is not reflected in increased trust in government. Regarding corruption, earlier research mostly found that the dissemination of government information reduces the level of public corruption (Cordis & Warren, 2014; Lindstedt & Naurin, 2010; conditional on media freedom in Z\u030cuffova\u0301, 2020) but increases the likelihood of uncovering corrupt actions (Cordis & Warren, 2014; Vadlamannati & Cooray, 2017). These two counterbalancing effects may explain other studies' seemingly counterintuitive finding that increased transparency is correlated with higher corruption or higher perception of corruption (Cordis & Warren, 2014).\nWith our study, we contribute to this vast but still growing literature examining the effects of government proactive release of information to the public. Our unique empirical research design allows us to show that public dissemination of accountability indicators is effective in influencing choices in the education market."
        },
        {
            "heading": "2.2. Information provision and school choice",
            "text": "A large body of literature has examined the effects of information provision in the education market. Some studies have focused on indirect outcomes of school quality information, such as changes in property prices (Figlio & Lucas, 2004; Machin, 2011), school fees (Andrabi, Das, & Khwaja, 2017) or student behavior (Avitabile & De Hoyos, 2018; Holbein & Ladd, 2017). Other studies have examined the impact of information disclosure on student test scores and school achievements (Camargo, Camelo, Firpo, & Ponczek, 2018; Hussain, 2015).6 An important strand of the literature, to which our paper is directly related, focused on the explicit effects of school quality information on school choice looking at changes in schools' enrolment and composition\n(Hastings & Weinstein, 2008; Koning & Van der Wiel, 2013; Mizala & Urquiola, 2013; Nunes et al., 2015). These studies, however, could not observe parental response in a setting in which parents had no access to other objective information. Further, while the concept of increased transparency in performance indicators is not novel in the education literature, it is unexplored what the effects of this increased transparency might be if the information is conveyed using Information and Communication Technologies (ICTs). In fact, earlier literature on information provision and school choice could only focus on information disclosed to the public on paper sources.\nHastings and Weinstein (2008) show in two experiments that, when endowed with a simplified three-pages information sheet on school performance, low-income families are more likely to enroll their children in higherscoring schools. While proving that a shift from complex to simplified information significantly affects parental school choice, their setting does not allow to focus on the effects of a shift from no information to complex information (i.e. public data on school outcomes). Koning and Van der Wiel (2013) study how the disclosure of school rankings, released by a national newspaper, impact school choice in the Netherlands. Similarly, Nunes et al. (2015) compare schools before and after the publication of school rankings by a national newspaper in Portugal. The two studies find schools to be significantly affected by the disclosure of school rankings. However, in both settings students are subjects to national central examinations in their final year of education, with the resulting outcomes being publicly available. Consequently, parents can obtain some form of school quality information, aside from the content of school rankings. Also, in both studies, shortly after the rankings were released by the newspapers, other sources - national magazines and public authorities - started to share similar information in parallel (online and on paper), offering parents additional means of information. Finally, Mizala and Urquiola (2013) apply a sharp regression discontinuity design to study the effects on school choice of the publication (by a national newspaper and online) of award-winning schools in Chile, finding no parental response. Again, as an evaluating system already existed prior to the \u2018intervention\u2019, parents could have accessed school quality information before the publication of award winners.\nNote that, in the literature on information provision and school choice, online information was only additional to the main source provided on paper. For instance, parents could consult an online school choice guide in Hastings and Weinstein (2008), could access the national exam scores on a public website in Nunes et al. (2015), could consult alternative online school rankings published by the Minister of Education in Koning and Van der Wiel (2013), or could check on a webpage the same list of award-winning schools published on the national newspaper in Mizala and Urquiola (2013). The presence of multiple sources of school quality information, however, did not allow these studies to investigate with a specific focus the effects of information provision using ICTs, nor it allowed to relate this information to open government."
        },
        {
            "heading": "2.3. The role of school choice determinants and market dynamics",
            "text": "Earlier literature examining parental preferences for school attributes suggest that parents prefer schools with high academic performance, similar socio-economic composition to their own, and close to their residence (Burgess, Greaves, Vignoles, & Wilson, 2015; Hastings, Kane, & Staiger, 2009). Other studies looking at parental preferences for school effectiveness, defined as the capability of schools to generate a causal improvement in students' achievements, have found little evidence that parents reward this school attribute (Abdulkadirog\u0306lu, Pathak, Schellenberg, & Walters, 2020; Rothstein, 2006). Finally, another strand of literature indirectly examined preferences of parents for highperforming schools by looking at co-movements between house prices and measured school quality (Figlio & Lucas, 2004; Machin, 2011). These studies found housing valuations to be higher in areas with better performing schools, suggesting that parents are willing to move residence so that their children can attend good quality schools. 4 Consistent results have been found when the health inspection scores are disclosed by the media in Almanza, Ismail, and Mills (2002). 5 Note that labelling requirements are not always mandatory. For instance, energy labels and ecolabels are voluntary programs. 6 Note that the absence of data on test scores prevents us from examining the effects of information shocks on student achievements in our paper.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n4\nSome of these findings, however, are heterogeneous and might emerge in settings in which parents have unequal or incomplete access to information on school quality. For instance, both Hastings et al. (2009) and Burgess et al. (2015) show that parental preferences for academic performance is driven by high-SES parents. However, it may be that although concerned about the relative quality of schools, lowSES parents are not able to observe it but rather substitute it with other easy-to-determine school attributes. Similarly, parents may not value school effectiveness because they are unable to identify it and rather proxy it with other observable school characteristics such as school composition (Abdulkadirog\u0306lu et al., 2020). It is interesting, then, to understand how the literature on information provision relates to the determinants of school choice.\nIn contrast with findings of Hastings et al. (2009) and Burgess et al. (2015), the literature on information provision and school choice appear to suggest that both high- and low-income parents equally value highperforming schools. Hastings and Weinstein (2008) show that low-SES parents are more likely to choose high-scoring schools when endowed with simplified information on school quality. Mizala and Urquiola (2013) and Koning and Van der Wiel (2013) do not find strong evidence of a differentiated response according to social categories. Further, in line with Hastings et al. (2009); Burgess et al. (2015), this literature appear to confirm that, even when endowed with information on school quality, parents still value proximity to school as a choice determinant. For instance, Hastings and Weinstein (2008) show that parents are more likely to respond to information provision if they live close to a highperforming school. Similarly, Koning and Van der Wiel (2013) reveal that the distance to a school is the most important determinant of school choice also when information on school quality is published through rankings.\nStill unexplored in the literature on information provision and school choice is, however, the role that market dynamics play in shaping the effects of performance indicators. For instance, it may be that parents (and students) continue to value home-school distance because they are not able to enroll their children in the good quality schools as identified by the performance indicators. This might happen if schools are at their maximum capacity of enrollments. With population increasingly moving from rural to city centers (Nusche, Miron, Santiago, & Teese, 2015), urban schools can easily reach their capacity limits and may not be able to physically allocate a potential rise in demand following an inspection. Therefore, the effect of information provision might differ according to the level of competition schools face in the local school market. In particular, if market dynamics play a role in influencing the attended effects of accountability policies such as school inspection reports, we would expect a positive effect of information shocks in rural schools, while no effect in urban schools."
        },
        {
            "heading": "3. Setting",
            "text": ""
        },
        {
            "heading": "3.1. Education system in Flanders",
            "text": "Freedom of education is key in Flanders.7 Students (and their parents) are free to select their preference school, and families are not forced to change neighborhood of residence to attend good-performing schools (i.e. there are no catchment areas).8 To ensure that the choice of school is free for all children regardless of their socioeconomic\nbackground, a series of regulations are in place. First, schools are not allowed to select students. In city centers, where subscriptions exceed the capacity of schools, lottery systems offer students an equal opportunity to enroll in the school of their choice. Second, in an attempt to reduce school segregation, quotas are in place to guarantee a number of positions for low SES students. This number depends on the socioeconomic environment such that the socioeconomic composition of schools reflects the neighborhood - a parish inside the municipality - they are located in. In fact, quota are set for both low- and high-SES students. Different schools located in the same socioeconomic environment will have the same number of positions available for both groups. Therefore, schools with many low SES students will have relatively more positions available for high SES students, and vice versa.\nOn the supply side, every person has the right to establish an educational institution, creating a broad heterogeneity in the Flemish educational landscape. Providers include local community governments, private providers (mostly catholic schools) and a centralized state school system, all operating within overlapping geographic regions. All schools, public and private, are funded by the Ministry of Education of Flanders. The equal entitlement to public funding ensures that schools do not to have to rely on other means (e.g. property taxes) for funding. This promotes school integration as it prevents school offer from depending on families' socioeconomic background or neighborhood's wealthiness.9 Since schools are publicly funded and not allowed to select students, and no tuition fees can be charged to parents in compulsory education, the perceived quality of schools remains the sole means to compete with other schools and attract students.10\nWe identify two categories of education facilities: institutions offering both primary education and preschool, and institutions only offering primary education.11 Despite compulsory education starting at age 6, more than 95% of children attend preschool from the age of 3. We hypothesize that when a child turns six years-old and needs to enroll in the first grade of primary education, parents are more likely to inquire about school quality data if the preschool the child is currently enrolled does not provide primary education. That is, we hypothesize larger responsiveness of parents when they are forced to look for a new institution of primary education. Therefore, to isolate parental response in a context where choice cannot be driven by continuity with preschool, in the remainder of the paper we focus our attention on institutions that only provide primary education.12\n7 In the sample, we also include the schools in the Brussels Region that have Dutch as instruction language, as these schools are funded and inspected in exactly the same way as the schools in the Flemish region.\n8 As a consequence, families in Belgium are not likely to move their residence to attend the preferred school for their children. This contrasts to other settings where changing the neighborhood in which you live can be an expedient to elude the school catchment area. Therefore, we will not focus on the (indirect) effects of school inspection reports on residence choices or house prices.\n9 The absence of property taxes as a means of school funding entails that no perfect correlation can emerge between school quality and neighborhood quality. 10 Before the disclosure of school inspection reports, parents would judge a school's quality based on their perception. This indirect information would come from open school days, school infrastructure, SES-characteristics of the student body and school reputation (among the others). 11 Apart from the grades offered, no structural differences emerge between the two types of education facilities. The decision of having (not having) preschool is exogenously made by the school board while establishing the school, and does not affect school offer. 12 In the sample, the majority (around 70%) of the preschool students enrolled in an institution offering both preschool and primary education attend the same institution when enrolling in primary education. Only around 30% of them switch to a new institution. In Section 6.3, we present a robustness check with the sample enlarged to comprehend also the schools that include preschool, and find no parental response. We further test the hypothesis of no difference in inspection coefficients among the two (original and enlarged) samples, and reject the null for all our significant findings. This confirms our hypothesis that there is a larger parental response when schools only offer primary education.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n5"
        },
        {
            "heading": "3.2. School inspections",
            "text": "In the decentralized Flemish system, there are no central examinations,13 but school inspectorates monitor whether the content and the teaching activities are sufficient to attain the minimal goals and competences set by the government. Goals are centrally imposed and equal for all primary schools. In the absence of central examinations, inspections are the only source of accountability of schools toward the government and parents.\nBy law, schools are selected for inspection in a random manner. Every year, a different sample of schools is randomly sorted for inspection. Once a school is selected for inspection, it will not be exposed to a random treatment for the incoming 10 years following the inspection.14 Announced with at least fourteen days' notice, inspections are carried out by members of the Inspectorate through school visits. During the visit, that lasts from three to four days, inspectors examine schools on multiple aspects. Specifically, every school is examined on its capacity to: satisfy the educational regulations; monitor its own quality; address independently its deficits. Although examined in all three aspects, schools are given an evaluation only with respect to their ability to satisfy the educational regulations set by the government. To this end, inspectors investigate schools' education quality and school infrastructure (i.e. compliance with a number of norms, among which safety and hygiene norms).\nTo assess education quality, the inspectors examine a selection of two to three courses, different from school to school. Among the most recurrently evaluated courses we find Dutch language, introduction to social sciences, mathematics and music, whose frequency of assessment is around 20% each. Other courses, such as French language, physical education or ICT, are less frequently evaluated, and they account jointly for 20% of the assessments.15 In the absence of standardized test scores, inspectors rely for the evaluation only on school processes (Penninckx, Vanhoof, De Maeyer, & Van Petegem, 2014). Hence, they attend lessons, examine school documentations, and engage in discussions about teaching and management quality with teachers, principals and a sample of students and parents. Each course is compulsorily always evaluated through an assessment of the educational offer, the equipment, the evaluation practices and the learning guidance,16 and can receive either a favourable or an unfavourable evaluation.\nAfter the visit, the inspectors redact an audit report where detailed information regarding the inspection visit are disclosed (we show in Appendix B selected and translated parts of an inspection report example). Importantly, every school receives one evaluation on education quality and another one on school infrastructure. Each evaluation can be either positive (\u2018favourable\u2019), \u2018restricted favourable\u2019 or \u2018unfavourable\u2019.17 For educational matters, a school receives a positive evaluation if it passes all evaluated courses. If small shortcomings are found with respect to some courses, schools can still receive a positive\nevaluation contingent on an exemption by the inspectorate for specific classes. Conversely, in case of significant shortcomings on one or more courses, the evaluation given to schools will be \u2018restricted favourable\u2019 or \u2018unfavourable\u2019. In the former case, schools will face a follow-up inspection three years later to determine whether proper adjustments were put in place.18 The latter category is assigned to schools that fail to achieve attainment targets and development goals set by the central government. While in theory these schools will be closed, in practice, schools are offered a second chance to develop a strategy to overcome their structural deficiencies, while being monitored on their progresses by an external agency.\nAs of 2012 inspection reports are published on the inspectorate's website, where all inspected schools are listed and their relative inspection reports (including possible follow-up reports) are published.19 The inspection reports are available only on the inspectorate's website, as schools are not allowed to market these reports to attract students. Prior to 2012, no record of inspection reports was publicly available and schools had no to little incentives to use the inspection reports. Therefore, parents are not expected to be aware of (and react to) prior inspections. In particular, if a school received a positive evaluation prior to 2012, parents would not be aware of it as the evaluation would only be communicated internally to the school. If a school received a negative evaluation prior to 2012, parents would likely be even less informed. The school principal is by law forbidden to spread information from school inspections. Moreover, poor performing schools would hardly attract parents even if they implemented improvements in school practices. Without the knowledge that these schools are urged by the Ministry to tackle their deficiencies, parents would likely rely for schooling decisions on past school characteristics, such as the school's prior (presumably poor) reputation. Therefore, the absence of public reports prior to 2012 entails that schools can be compared before and after the information vacuum was filled by inspection reports.\nOur motivation to focus on primary schools in subsequent analyses is threefold. First, inspection reports of primary schools are published within two months following an inspection. This short time period between school inspection and the publication of the report allows us to specify of a clear cut-off year in our empirical analysis. Second, primary schools have a high degree of homogeneity. They offer the same education, forming children on the same set of subjects, irrespective of the location and the provider of education.20 Third, in primary education, the socioeconomic composition of schools cannot be affected by a school's (financial) policy. Total yearly expenditure that can be charged to parents is limited to a fixed ceiling (i.e., 85 euro per school year). This ceiling is set by the central government to guarantee effective free school choice and it prevents schools from influencing the student (socioeconomic) composition.21\n13 Currently, all education providers have their own tests, which are used by the schools on a voluntary basis. However, these data are not available to the public. 14 Since January 2018, a new approach (Inspectie 2.0) was launched. Among other things, the new approach has shortened the time lapse between one inspection and another, from ten to six years. However, as our data cover until academic year 2016/2017, we refer throughout the paper to the original inspection framework. 15 We group these courses as \u2018other\u2019 in the remainder of this study. More detailed information on subjects' assessments can be found in Table A.3 of Appendix A. 16 Note that, in addition to these mandatory aspects, the school inspectorate might decide to examine further aspects. However, these further aspects are supplementary to the mandatory ones, that are by contrast always included. 17 As almost all schools in our sample score positively with respect to school infrastructure, we focus the analysis on evaluations related to education quality, which offer us enough variance to go by.\n18 Note that the inspectors do not have the legal right to advise schools on how to address their weaknesses. However, schools can rely on the analysis appearing in the inspection report to understand how to improve their strengths and overcome their shortfalls. 19 Reports are accessible at the following government website: https://data-on derwijs.vlaanderen.be/onderwijsaanbod/bao/lijst. The government website is constantly updated with the most recent reports. To better visualize the structure of an inspection report, we show in Appendix B a translated example of the table of contents of an inspection report, a subject assessment, and the final evaluation given to a school. The original inspection report can be consulted at this link: https://app.akov.be. 20 Note that schools using different methods (e.g. Steiner, Freinet) can still differentiate their offering, while teaching the same content. 21 Anecdotal evidence points at strategic decisions of schools (in secondary education) to organise expensive school trips in order to influence the student socioeconomic composition.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n6"
        },
        {
            "heading": "4. Dataset",
            "text": ""
        },
        {
            "heading": "4.1. Data and variables",
            "text": "Our dataset combines administrative data (2001\u20132016) with publicly available inspection data (2012\u20132016).22 Administrative data provides us with information, at student level, about individual school choice and socioeconomic status. Inspection reports indicate, at school level, the overall and subject-specific evaluations for all inspected institutions, covering a range of five academic years. Over this period, 199 schools were examined, i.e. the 38.94% of total schools in our sample. Further analysing the outcome of the inspection (see Table 1), 60.3% of the institutions received a positive (\u2018favourable\u2019) evaluation, whereas 39.7% received a negative (\u2018restricted favourable\u2019) score.23\nOur analysis focuses on two main outcome variables: school size and socioeconomic (SES) composition.24 School size is measured as the total number of students enrolled in first grade of primary education. SES composition is the average socioeconomic composition of the student body characterizing the first grade, and is included to study heterogeneity in parental response, possibly resulting from families' diverse socioeconomic status.25 It ranges from 0 (high socioeconomic status) to 1 (low socioeconomic status), and is constructed first at student level, as a weighted average of five equal opportunities indicators. These indicators are used in Flanders to assign extra funds to schools with a certain percentage of disadvantaged students. Specifically, they take into account whether: the student belongs to the travelling population; the mother of the student does not have a degree of secondary education; the student lives (permanently or temporarily) outside his family; the student does not speak the native language Dutch at home; the student receives one or more school grants (De Witte, Titl, Holz, & Smet, 2019, pp. 164). To each indicator is assigned a weight, and the weighted sum is computed for every student to obtain a measure of his socioeconomic status.26 Then, at school level, the SES composition of a school's student body is obtained by averaging out the socioeconomic\nstatus of all students attending the first grade of that school. To further investigate market dynamics related to information shocks, we consider the geographic localization of schools and divide the sample according to whether schools are located in rural or urban municipalities. By distinguishing between rural and urban municipalities, we implicitly define different markets for schools according to the degree of urbanization of the municipality where the school is located. Specifically, the local market for urban schools is expected to be characterized by a high level of school competition due to the low transportation costs experienced by parents. By contrast, the local market for rural schools is presumably characterized by a low level of school competition as a consequence of the high transportation costs incurred by parents.27 To distinguish between rural and urban schools, we consider an indicator of population density and set the threshold to 750 inhabitants per km2 as the dividing value. Municipalities below such threshold are labeled rural, whereas municipalities above it urban.\nTable A.2 in Appendix A provides summary statistics for several levels of population density. The threshold of 750 inhabitants per km2 allows us to have balanced sub-samples, with around 54% of observations in the rural municipalities, and 46% in the urban municipalities. The Kernel densities (Fig. A.1 in Appendix A) reveal a substantial difference in rural and urban areas, both in school size and in the SES composition. Urban schools tend to have larger first grade school classes, and more dispersion in the socioeconomic composition. Conversely, rural schools are slightly less numerous and present a smaller share of low-SES students."
        },
        {
            "heading": "4.2. Random assessment of education inspectorates",
            "text": "To assure internal validity, schools need to be randomly selected for the inspection such that inspected and non-inspected schools have equal expectations prior to the inspection. In the absence of a random selection, endogeneity issues due to selection bias and unobserved heterogeneity might threaten the validity of results.28\nDespite by law schools are selected for inspection in a random manner, we assess in three ways the random selection of schools. First, we show in Table 2, both for inspected and control schools, means and standard errors of our outcome variables on their values prior to 2012 (i. e. before the start of inspections). Most importantly, we test for the\nNotes: In the period examined, 199 primary schools were inspected. The majority of schools (60.3%) reported a positive (\u2018favourable\u2019) evaluation. The remaining 39.7% can be further disentangled in \u2018restricted favourable\u2019 (39.2%) and \u2018unfavourable\u2019 (0.5%). We group the latter two categories into the same category (negative). The total number of schools in the sample (both inspected and non inspected) is 511.\nNotes: Reported are mean values and standard errors in parenthesis, all prior to 2012 (i.e. the starting of inspections), for uninspected and inspected schools. Variables include outcome variables and the five equal opportunities indicators used to build SES composition. To test for a significant difference in the two groups, we regress each variable on an inspection indicator (equal to 1 if the school has been inspected), and we report the p-values in the last column. Standard errors are clustered at school level.\n22 Every year refers to the beginning of the academic year (e.g., 2001 refers to academic year 2001/2002). 23 Since only 1 school received a negative (\u2018unfavourable\u2019) score, it was dropped out of the sample as not representative of its category. Our subsequent analysis holds irrespective of including this specific school. Moreover, since schools receiving a \u2018restricted favourable\u2019 evaluation still experience it as \u2018unfavourable\u2019 (Penninckx et al., 2014), throughout this paper we refer to a \u2018restricted favourable\u2019 evaluation as negative. 24 We express our dependent variables in levels. However, to ensure that our effects are not driven by the absolute size, we have also estimated the model in logarithms. The results are virtually unchanged. 25 Note that, although schools in Flanders do not select students, high or low SES students might sort into different schools according their preferences. 26 More information on the weighting scheme can be found in De Witte et al. (2019) and De Witte, D'Inverno, and Smet (2018).\n27 In Section 6.3, as an additional robustness test we define the school local markets more explicitly on the basis of school distances. Our results are in line with the findings from the main analysis. 28 For example, endogeneity issues might arise if the school inspectorate specifically targets schools located in certain neighborhoods, schools with high (low) student-teacher ratio, or schools with high (low) percentages of disadvantaged students, among the others.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n7\ndifferences in the two groups by regressing each variable on a treatment indicator, and we report the relative p-values in the third column.29 We find that the mean values of both school size and SES composition do not significantly differ between inspected and non-inspected schools. In the bottom part of the table, we compare the indicators used to build the aggregated SES indicator, and again we mostly detect similarity between inspected and non-inspected schools.30 As second approach, we compare the Kernel distributions of inspected and control schools on school size, share of non-Dutch speaking students, share of low educated mothers, and more generally, average SES composition, all on their 2011 values. We plot the result in Fig. 1. Again, we generally observe a close resemblance among densities, especially with respect to the indicators used to build the aggregated SES indicator. A formal Kolmogorov\u2013Smirnov test for the difference in distributions (Table A.1 in Appendix A), confirms the absence of significant differences in the underlying densities.\nFinally, a direct consequence of random assessment is that both inspected and control schools should follow the same trend before the inspection. Hence, we follow Autor (2003) in testing the Parallel Trend Assumption (PTA), by interacting a dummy variable for inspected schools with a relative time variable. We expect the coefficients of the time periods preceding the year of inspection t0 to be close to zero and not significant. As a result, the difference in trends between inspected and uninspected schools does not statistically diverge from zero, and the\nPTA holds. Table A.4 in Appendix A shows the results for school size and SES composition . We find that the estimates for both dependent variables are in line with our expectations, as no coefficient before t0 is significant, and they are all close to zero .31\nHence, all analyses support our argument that the selection process of schools for inspection is (both by law and in practice) random.32"
        },
        {
            "heading": "5. Empirical strategy",
            "text": "To assess the impact that information shocks, driven by the publication of inspection reports, exert on school enrolment and composition, we use the following model specification:\nYit = \u03b20 + \u03b21Dit + \u03b3i + \u03b4t + \u03b8it+ \u03f5it (1)\nwhere Yit indicates the outcome variable: school size (i.e., number of first grade students) or SES composition, in school i at time t; Dit is the inspection indicator equal to 1 if school i was inspected in period t or\n29 We cluster standard errors at school level to account for autocorrelation of error terms within the same schools over multiple time periods. 30 The only indicator to be statistically different at 5% level is \u201creceivers of school grants\u201d. However, this indicator receives the lowest relative weight in the construction of SES composition.\n31 The PTA test is run including school and year fixed effects, as well as school time trend. 32 Note that negatively evaluated schools will face, after three years, a followup inspection that is not random (anymore). Therefore, relative to these schools, parents will be able to consult the follow-up inspection report as well as the original report. As our data cover academic years 2012\u20132016, this concerns only 38 schools in our sample, namely the 20% of the total inspected schools. We test the robustness of our findings to the second report that a fraction of schools receives by estimating our models on a redefined sample. In this sample, we follow inspected schools up to a maximum of two years following the inspection. In this fashion, we ensure that no follow-up inspection report could be published (yet). The results are virtually unchanged with respect to the findings of our main analysis.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n8\nbefore, and 0 otherwise33; \u03b4t denotes time fixed effects, \u03b3i school fixed effects, and \u03b8it school specific time trends (with \u03b8i denoting the coefficient on the school specific time trend). School fixed effects allow us to control for a series of unobserved characteristics that differ among schools but are invariant over time, such as school district attractiveness, school location, school reputation, principal's management ability. We further include year dummies and school specific time trends to control for schools growing trajectories. Next, as schools are repeatedly observed over time, we would expect unobserved variations in school size and SES composition to be correlated across time within units, being determined by serially correlated error terms. Moreover, we do not expect inspections to affect our outcome variables homogeneously in our sample. Hence, we account for serial autocorrelation and allow for heteroscedasticity in the error terms, by clustering standard errors at the school level.34\nThe interpretation of \u03b21 as a causal parameter relies on the assumption that after conditioning on \u03b3i, \u03b4t and \u03b3i\u03b4t, the post-inspection difference between inspected and uninspected schools can be completely attributed to the effect of information shocks, more formally, E(Y0it|\u03b3i,\u03b4t,\u03b3i\u03b4t,Dit) = E(Y0it|\u03b3i,\u03b4t,\u03b3i\u03b4t). The random selection of schools for inspection and the PTA's satisfaction, as illustrated in Section 4, imply the latter assumption to hold.\nAlthough schools are randomly drawn for inspection, one could argue that it is unrealistic to assume that positive and negative outcomes are allocated randomly. Good (and bad) performing schools might differ from their control group on a series of observed and unobserved characteristics. Specifically, good schools might be located in areas with better economic conditions, less low-educated parents or larger share of Dutch-speaking households. As a result, these schools might have higher probabilities of receiving a positive evaluation than their control group. Similarly, bad performing schools can have higher likelihood of receiving a negative evaluation as a consequence of enduring structural deficiencies. If present, unobserved long-lasting (but time-varying) determinants might invalidate the causal estimates identified by Eq. (1).\nTo account for observed and unobserved heterogeneity and further check the robustness of our results, we follow Xu (2017) in applying the generalized synthetic control (GSC) approach. The GSC approach is an extension of the synthetic control method (SCM) first introduced by Abadie, Diamond, and Hainmueller (2010), and it combines the intuition of the SCM with the estimation of an iterative fixed effect (IFE) model. The GSC estimator is well suited for our analysis for three reasons. First, similarly to other synthetic control estimators, the GSC estimator allows to limit endogeneity issues possibly arising from the omission of unobserved covariates. As mentioned earlier, an issue of assessing the effects of information shocks for positively and negatively evaluated schools relies in that these schools might systematically differ from their control group on a series of observed and unobserved characteristics. In this respect, the GSC estimator allows us to compare positively (negatively) evaluated schools to a \u2018synthetic\u2019 control group of schools that is expressly designed to resemble as close as possible the inspected schools on their pre-inspection outcome variables. The idea is\nthat a combination of control schools will constitute a better comparison group for the inspected schools than the original control schools. In fact, this new synthetic control group will reflect the (observed and unobserved) long-term characteristics of positively (negatively) evaluated schools. Put differently, since the synthetic control group replicates the trajectories of positively (negatively) inspected schools over multiple years prior to the inspection, it will also model the underlying unobserved heterogeneities. As second advantage, the synthetic control is the ideal methodology to be employed in a scenario with few treated and control units observed over multiple years. Particularly, the GSC is well suited for our analysis since it allows to have multiple treated units in multiple time periods. Finally, a last advantage of the GSC estimator is that it allows to derive inference by computing standard errors and confidence intervals through parametric bootstrapping.\nWe specify the functional form as follows35:\nYit = \u03b1itDit + \u03b3i + \u03b4t + \u03bb \u2032 i ft + \u03f5it (2)\nwhere Yit is the outcome for school i at time t, \u03b3i and \u03b4t are school and time fixed effects, \u03b1it is the effect of positive (negative) information shocks, Dit is the positive (negative) inspection indicator equal to 1 if school i received a positive (negative) evaluation in period t or before, and 0 otherwise,36 and \u03bbi'ft is the factor component of the model that allows to capture several forms of unobserved heterogeneity on top of the fixed effects already specified, with ft being a vector of r time-varying unobserved coefficients (latent factors), and \u03bbi a vector of r schoolspecific intercepts (factor loadings).37 According to the value of Dit, we can distinguish the outcome of an inspected school i at time t, Yit(1) = \u03b1it + \u03bbi\u2032ft + \u03b3i + \u03b4t + \u03f5it, from the outcome that would have been observed in the same school i, had it not been subject to the inspection: Yit(0) = \u03bbi\u2032ft + \u03b3i + \u03b4t + \u03f5it. The difference defines the causal effect of the publication of an inspection report, i.e. our information shock:\n\u03b1it = Yit(1) \u2212 Yit(0) (3)\nfor every inspected school i at time t, in all post-inspection periods, i.e. t > t0. We are then interested in the estimate of the parameter \u03b1it to find the effect of the treatment. Since Yit(1) is observed, we are left with the estimation of Yit(0). Hence, we need to build a synthetic control group that mimics as good as possible the evolution of our outcome variable, with respect to inspected schools in each pre-inspection year. To do so, the GSC method requires to construct Y\u0302 it(0) in three steps, in which the factor loadings of every unobserved common factor are estimated to minimize the mean square error of the predicted inspected schools in the pre-inspection periods. In other words, we estimate weights that minimize the distance between the observed and predicted outcomes in the pre-inspection periods. Then, Y\u0302 it(0) is computed accordingly, and a prediction exercise is done to obtain estimates for the post-inspection periods. Finally, such estimates are averaged over all inspected schools in every post-inspection period, and noise is smoothed out. The average treatment effect on the treated (ATT) by period is thus defined as follows:\n33 To assess the impact of a positive evaluation, we set Dit equal to 1 if school i was positively evaluated in period t or before, and equal to 0 otherwise. Vice versa to assess the impact of a negative evaluation. Note that, to estimate the effects of positive and negative school reports, the evaluations given to schools by the inspectorate should reflect schools' long-term characteristics and should not be sensitive to short-term circumstances. As school assessments are made on the basis of school processes and not, for example, on the basis of test scores \u2013 more sensitive to short-term circumstances, we expect the evaluations to mirror these (long-term) characteristics. Moreover, even if in some cases school evaluations would reflect short-term circumstances (e.g. higher absence or conflicts at work in case of a negative evaluation), we might expect this to happen at random, both in case of a positive and a negative evaluation. 34 A test by Wooldridge (2002) rejects the null of no first-order correlation, further endorsing the choice of clustered standard errors.\n35 The functional form is assumed to be the same for inspected and noninspected schools. 36 Similarly to the DiD analysis, to assess the overall effect of information shocks Dit is set to 0 if school i was inspected in period t or before, and 0 otherwise. 37 School and time fixed effects are already a special combination of ft and \u03bbi. They can be obtained by setting f1t = 1, \u03bbi2 = 1, with \u03bbi1 = \u03b3i and f2t = \u03b4t, so that f1t\u03bbi1 + f2t\u03bbi2 = \u03b3i + \u03b4t. Other forms of unobserved heterogeneity include schoolspecific linear time trends, quadratic time trends or autoregressive components. A cross-validation algorithm is implemented to select the appropriate number of factors to be estimated in addition to the school and time fixed effects.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n9\nAT\u0302 Tt = 1\nNtr\n\u2211\ni [Yit(1) \u2212 Y\u0302 it(0) ] = 1 Ntr \u2211 i \u03b1\u0302it (4)\nfor t > t0 and i part of the treatment group. The construction of the counterfactual allows us to overcome the issue of non-parallel trend between positively or negatively evaluated schools and uninspected schools. As previously mentioned, another advantage of the GSC method is that it allows to obtain uncertainty estimates of standard errors and confidence intervals, through parametric bootstrapping. The purpose is to build B series of simulated outcome values for inspected and uninspected schools.38 To do so, residuals are resampled from different distributions according to whether the school belongs to the control or treatment group. For every bootstrapped series of simulated outcomes, the ATT is computed. Finally, the variance of the treatment effect can be computed over all bootstrapped simulated ATTs."
        },
        {
            "heading": "6. Results",
            "text": ""
        },
        {
            "heading": "6.1. Overall results",
            "text": "Table 3 presents the estimated effect of information shocks on school size (column 1) and SES composition (column 3). Our findings indicate a positive and significant effect on school size. The estimates suggest that an inspected school experiences, on average, an increase in first grade enrolments by around 1.8 students. The estimated effect corresponds to an increase in school size of about 5%. However, such higher enrolment rate does not translate into a significantly different socioeconomic composition of the school.\nThe availability and propagation over the years of the information on\nschool quality can have a dual effect. On the one hand, it can contribute to build up a school's reputation, as the passing of time increases the chance to reach a larger audience. On the other hand, it may fade away when too many years have passed since its disclosure, as deemed to be no longer accurate. With available data between 2012 an 2016, we can follow schools up to four years after the information shock. We show the results in columns (2) and (4) of Table 3, with periods ranging from the year of inspection (t0) to four years after the inspection (t+4). The results confirm the pattern observed in the overall specification, with class size strongly responding and SES composition never being statistically different from zero. More specifically, our results point out a durable reputation effect over time, with coefficients raising from 1.7 additional students in t0 (corresponding to a percentage increase in school size of 5%) to around 2.7 additional students in t+3 (corresponding to a percentage increase in school size of 8%). The significance of the effect disappears in t+4. As we control for school specific time trends, we are able to attribute the increase in the number of students primarily to the disclosure of inspection reports. We also detect rising standard errors, but we attribute this higher uncertainty to the reduced number of observations available when more years have passed since the inspection. Having evidence that schools face an average increase in demand following the publication of school reports, we interpret the absence of significance of the socioeconomic composition, both overall and overtime, as a signal that high-SES parents and low-SES parents are equally like to respond to information shocks.\nAs every school is inspected on several courses, information shocks might affect schools differently according to which subjects are being examined. To investigate the heterogeneous effect for different courses, Table A.5 in Appendix A shows the interaction of the inspection dummy D with the courses covered during the inspection. Overall, no significant effects emerge from the interaction terms, both on school size and SES composition. In column (1), significance at 1% level is detected only for the category \u2018other\u2019. However, this category consists of several minor courses - such as French language, physical education, technology or ICT - that are evaluated at a consistent lower frequency, preventing us from deriving causal inference individually. This suggests that when reacting to information shocks, parents do not express preferences on the subjects examined. On the contrary, they most likely use the new information at their disposal to locate inspected schools, irrespective of which courses have been evaluated.\nNext, we examine whether the geographic localization of the schools helps us better understand the effect of information shocks. The DiD estimation reported in Table 4 suggests heterogeneity in the results relating to whether the school is located in a lowly or highly densely populated area, corresponding to municipalities with population density below and above 750 inhabitants per km2.39 We refer to the former as rural and to the latter as urban. The results highlight how the baseline outcomes of Table 3 are mostly driven by schools located in rural areas. In column (1), the overall effect on school size for rural schools is significant at 1% level and higher than what previously reported. The same is true in t0, t+1 and t+2. The effect becomes not significant from t+3 onward, signaling less persistence of the reputation effect. Conversely, our results point out no response to information shocks for urban schools, with the overall effect being close to one and not statistically different from zero.40 Such difference may seem counter-intuitive, as students in city centers should be in the position to easily change\nNotes: The table shows the impact of information shocks on school size and SES composition, overall and according to how many years elapsed since the inspection. School size is measured as the number of students in first year of primary education. SES composition is the average SES composition of the student body in the first year of primary education and is measured as a weighted average of five equality indicators: if the student belongs to the travelling population, if the mother does not have a degree of secondary education, if the student lives (permanently or temporarily) outside his family, if the student does not speak the native language Dutch at home, if the student receives one or more school grants. Robust standard errors, clustered at school level, in parenthesis. * p < 0.05, ** p < 0.01, *** p < 0.001).\n38 In both cases such series are constructed without the treatment effect, i.e. they do not include the inspection effect \u03b1it\n39 The value of 750 inhabitants per km2 as a partitioning limit for the level of population density is confirmed by several robustness checks, each with a different threshold for rural and urban areas. Results are reported and discussed in Table A.6 in Appendix A. 40 When comparing the coefficients of rural and urban schools by means of a test of equality of coefficients, we find that the estimates in urban schools do not statistically differ from the ones of rural schools (p-value = 0.361). Since the estimated coefficients in urban schools are positive and above the unit, this comes as no surprise as it likely that the estimates in rural areas differ more significantly from zero than from the positive (albeit not significant) estimates in urban areas.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n10\nschools, unlike peers living in outer municipalities who potentially need more travelling time. However, it can be explained by the enrolment capacities of urban schools in Flanders. There is evidence that schools located in highly populated municipalities are likely to have reached the maximum capacity of students being able to enroll.41 Therefore, in the first years after the publication of the inspection reports, even if urban schools are faced with higher demand, they are not able to accommodate it as being already at their maximum. No effects are found again with respect to the socioeconomic composition.\nFinally, to further explore the difference between schools located in rural and urban municipalities, we interact the inspection dummy D with population density, which we arrange in five categories. Results are presented in Table A.7 in Appendix A. Again, we find evidence of the distinct response in rural and urban areas. Indeed, the impact on schools in regions with a population density larger than 750 inhabitants per km2 is never significant, whereas there is evidence that below 750 inhabitants per km2 information shocks affect school enrolment. We do not observe any difference in SES composition."
        },
        {
            "heading": "6.2. The effect of positive and negative evaluations",
            "text": "After schools are inspected, they receive either a positive or negative evaluation. Above, we presented the overall response of parents to information shocks. However, it is likely that positively evaluated schools followed, and will follow, a different growth path in terms of school size and composition than negatively evaluated schools. We disentangle such effects and report the results in Table 5. From Table 5 two results\nemerge: first, a clear distinction between the effect of a positive and a negative evaluation on school size; second, the repeated absence of impact on the socioeconomic composition.\nAs for the former, we detect a strong positive response of school size following a favourable evaluation, and no response when the school receives an unfavourable evaluation. Parents, when having to choose a school for their children, are attracted by positively evaluated schools that inevitably see the average number of students enrolled in the first grade increase. The overall effect amounts on average to 2.3 additional registrations, strongly significant at 1% level (and corresponding to a percentage increase in school size of 7%). When further disentangling the time effects, reported in column (2) of Table 5, we observe a positive and long-lasting reaction of school size until t+3. Moreover, as the coefficient increases in magnitude, we find evidence that schools consolidate their reputation through the years. The peak occurs in time t+3, with about 3.6 additional students enrolling, corresponding to an increase of 10% in the first grade of primary schools. On the other hand, no significant effect is detected, neither overall nor over time, when the outcome of the inspection is unfavourable. However, the coefficients (and standard errors) related to a negative evaluation are positive and increasing through the time periods, and are not statistically different from the coefficients of a positive evaluation. A test of equality of coefficients fails to reject the null of equality of coefficients with p-value = 0.500. Hence, schools with an unfavourable evaluation are not able to attract new students, as one can legitimately expect, but they also do not attract less students in the first grade after the publication of the reports. This is likely due to two reasons. First, before the information shocks, parents might already be able to identify schools with poor performances. Their (perceived) judgement is later confirmed by the negative assessments, and no effect is detected. Second, knowing that by law negatively evaluated schools are urged to tackle the deficiencies disclosed by the reports, parents might become more optimistic about the change in school quality of these schools in the near future. Specifically, they might interpret the negative evaluation as a signal of commitment to improve school practices, and would react by not punishing the schools after having received a negative evaluation.\nTurning to the socioeconomic composition, disentangling positive from negative scores does not shed any light on the social group driving the results. We interpret it again as evidence that both high and low-SES\nNotes: The table shows the estimated effect of information shocks on school size and SES composition, for schools located in rural and urban municipalities. Rural (urban) municipalities are defined as having less (more) than 750 inhabitants per km2. Estimates show the effect over all years and disentangled according to how many years elapsed since the inspection. School size is measured as the number of students in first grade and SES composition as the average socioeconomic composition of the student body in first grade. Robust standard errors, clustered at school level, in parenthesis. * p < 0.05, ** p < 0.01, *** p < 0.001).\n41 In their OECD Review of School Resources, Nusche et al. (2015) show how urban schools in Flanders are struggling to face an increased demand for places, whereas rural schools are experiencing lower enrolments. This unequal shifting of demand from rural to urban schools is presented as one of the challenges the Flemish educational system would have to address in the following years. Supplementary evidence from academic year 2014/2015 points to around 2700 students not being able to enroll in community urban schools due to the shortage of school places (De Standaard, 2014). Finally, a technical report on school capacities proves most schools located in urban municipalities to experience capacity constraints (Groenez & Surkyn, 2018).\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n11\nparents are equally like to respond to information shocks. Our results are in line with Koning and Van der Wiel (2013), whose findings indicate a rise (fall) in enrolment after a positive (negative) score obtained by the school in the ranking. In particular, the authors find that when all school tracks are considered, schools with a positive score face an increase in enrolments of 2 additional students, while schools with the most positive score see entries increase of 7 additional students, corresponding to a percentage increase in school size of 3% and 9% respectively. Koning and Van der Wiel (2013) also find no differentiated response according to students' socioeconomic characteristics.42 The consistency of findings is accentuated by the country Koning and Van der Wiel (2013) choose for their analysis, namely the Netherlands, whose condition of public free school choice makes it similar to our setting."
        },
        {
            "heading": "6.3. Robustness checks",
            "text": "To test the robustness of our findings, first, we re-propose the main findings of our study with the sample enlarged to include all schools providing primary education in Flanders. Hence, we now add institutions that jointly provide primary education and preschool. As hypothesized, the results, presented in Table A.8, suggest no significant effect both on school size and on SES composition. We argued before that parents exert school choice primarily for continuity with preschool, as they are already familiar with the institution's environment and their children can attend the same school of their fellow peers. Conversely, when parents are forced to choose the institution as the automated choice is not available, they are more apt to make an informed choice and are influenced by the inspection reports. As a matter of fact, even when we further analyse the effects of a positive and negative evaluation, we do not find significance in any of the dependent variables.\nSecond, as discussed in Section 5, although schools are randomly drawn for inspection, positive and negative evaluations are hardly random. Specifically, good performing schools (and bad performing schools) are likely to differ from the control group on a series of observed\nand unobserved characteristics. Therefore, as second robustness test, we re-estimate the findings by the use of a generalized synthetic control approach.\nFig. 2 plots the synthetic control estimates of the effects of a positive (panel a) and negative (panel b) evaluation on school size. For every panel, two graphs are displayed. On the top, we observe the average number of first grade students both for inspected schools (black line) and synthetic control group (dashed blue line); on the bottom, the difference among the averages, i.e. the causal effect of the inspection, is explicitly plotted in every time period. The horizontal axis indicates the time relative to the year of inspection, with 0 intended as the last pretreatment period; 1 as the year of inspection and so on, until 5 as four years after inspection.\nFindings obtained with the generalized synthetic control approach are in line with the ones obtained from DiD analysis. A positive evaluation results in a large and persistent response in first grade enrolments, with the overall effect strongly significant at 0.1% level and close in size to the DiD estimate. Plotted confidence intervals at 95% level confirm that a favourable evaluation consolidates a school's reputation over time, with estimates consistently rising in size. Increasing standard errors signal again more uncertainty around the estimates due to the fewer number of observations available several years after the inspection. Turning to the negative evaluations in panel (b), we find that analogously to Table 5, an unfavourable evaluation does not change the first grade enrolment. Although the graph shows a mild difference between the treated average and the synthetic counterfactual, such divergence is never statistically significant. Finally, when analysing the effect on the SES composition (shown in Fig. A.2 of Appendix A), we do not find any effect of positive or negative evaluations.\nThe exact coefficients of the aforementioned generalized synthetic control (GCC) estimation are reported in Table A.9. Moreover, we employ the GSC method to test the robustness of our baseline, and of the rural and urban settings (Table A.10). Both Tables A.9 and A.10 additionally report estimates for DiD regressions with different levels of fixed effects: School FE; School FE and school time trend; School FE, school time trend and year FE. These robustness tests provide some further insights. First, GSC estimates are mostly consistent with the distinction, previously highlighted, existing between rural and urban municipalities. With the threshold being set again to 750 people per km2, we have\nNotes: The table reports the estimated effect of positive and negative evaluations on school size and SES composition. Estimates show the effect over all years and disentangled according to how many years elapsed since the inspection. School size is measured as the number of students in first grade and SES composition as the average socioeconomic composition of the student body in first grade. Robust standard errors, clustered at school level, in parenthesis. * p < 0.05, ** p < 0.01, *** p < 0.001).\n42 Out of 40 interaction coefficients for students' characteristics, Koning and Van der Wiel (2013) find only two of them to be significantly different from 0.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n12\nconfirmation that information shocks strongly affect rural areas. As opposed to Table 4, a milder response emerges for highly populated municipalities. However, from the time composition, we observe how such response is determined by time periods t+3 and t+4. We deduce that, similarly to what obtained within the DiD framework, urban schools face capacity constraints in the years immediately following the publication of an inspection report. Those limits might be later overcome to accommodate a rise in demand. Second, Tables A.9 and A.10 show primary schools to be significantly affected in most of regressions, confirming strong parental response also under different levels of fixed effects (FE). However, we sense that these patterns might be overestimating the actual impact of information shocks. Indeed, when looking at regressions under school FE, and especially under school FE and school time trend, there is a tendency for coefficients to be more significant than what obtained in our main specification. We explain such difference as follows. Controlling for only school FE excludes from the analysis both yearly cohorts and schools individual growing trajectories. A school located in areas with positive growing rates may see the level of its students rise not only by means of the information shocks, but also as a result of the mere inflow of persons. More inhabitants implicates more children living in the neighborhood, hence more school subscriptions.43 Furthermore, even when school trends are included,\nwithout year FE coefficients will still be upward biased as we do not account for changes that can affect schools simultaneously, for instance as a result of a governmental policy. Hence, both school individual trend and year cohorts are needed to provide correct inference. Moreover, and as discussed above, our selected specification is additionally supported by the synthetic control analysis.\nAs third robustness test, we further enquire the effects of positive and negative evaluations, however separately for rural and urban municipalities. Findings, reported in Table A.11, are consistent with results from our main specification. In rural areas, a positive evaluation has a positive impact on schools size, whereas no effect is found with respect to a negative evaluation. In urban areas, neither a positive nor a negative evaluation are affecting any of the dependent variables.\nFinally, as last robustness check, we further enquire whether the spatial distribution of schools may affect the results obtained so far. When parents face non-zero transportation costs, the demand for a school might depend not only on the (absolute) quality of that school, but also on how it relates to the quality of other schools in the surrounding neighborhoods. So far, we have indirectly accounted for the spatial distribution of schools through the heterogeneous analysis of rural and urban areas. By distinguishing the effect of information shocks separately for rural and urban schools, we have implicitly defined different local markets for schools according to the level of urbanization of the municipality where they are located. The use of the GSC approach (combined with the rural and urban distinction) has helped us to better define the local markets by modelling the unobserved heterogeneities, and has provided us similar results as in the main analysis.\n43 A similar reasoning applies to the socioeconomic composition, as such inflow may alter students' economic distribution for reasons other than the inspection reports.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n13\nIn this section, we explicitly define school local markets and account for school competition within the market, by extending our main model of Eq. (1) as follows. First, we estimate the discrete indicators for positive and negative evaluations in the same regression.44 By doing so, we estimate the effect of positive and negative evaluations with respect to the control schools that receive no inspection. Second, we add four additional control variables. This set of additional covariates allows to account for the number of competitors in the local market, the relative magnitude of each school within the local market and the relative quality of every school with respect to the other competitors. Specifically, as first variable we include the total number of schools laying in the school local market. As second variable, we control for each school's market share within the local market. To obtain a school's market share, we divide the number of students enrolled in the first grade of that school by the total number of students enrolled in the first grade of all schools laying within the local market. Lastly, we include two discrete indicators for the fraction of positively and negatively evaluated schools in the school local market.\nNext, to determine a school's local market, first, we use schools' geographic coordinates to obtain the exact location of every school in Flanders. Second, we define a school's local market as the set of schools that are located within a certain radius of kilometers from the evaluated school.45 As primary school children in Belgium attend schools located within an average distance of 2 km from home, with standard deviation of approximately 2.5 km (Boussauw, Van Meeteren, & Witlox, 2014), we consider four possible thresholds for the radius: 1, 2.5, 5 and 10 km. The smaller the radius, the more the school local market captures school competition in dense populated municipalities. Conversely, the higher the radius, the more the local school market accounts for school competition also in more dispersed areas. We show our results in Table A.12 below.\nIn Table A.12, we report in columns (1) to (4) the estimated model for school size and in columns (5) to (8) the estimated model for the socioeconomic (SES) composition. Moreover, for every dependent variable we display the school local market defined as the set of schools within a radius of 1, 2.5, 5 and 10 km respectively. Overall, from Table A.12 three results emerge: first, a significant effect of positive evaluations on school size and no effect of negative evaluations; second, an increasing effect of positive evaluations according to the radius of the school local market; third, no effect on the socioeconomic composition. As for the former, our results show that when accounting for local competition, schools that received a positive evaluation see a significant increase of the number of students enrolled. Conversely, schools that received a negative evaluation are not significantly affected. This result holds regardless of the radius of the local market. That is, both when considering competition in the immediate vicinity of the school and when the competition is enlarged to include more distant schools, we obtain that inspection reports significantly affect the number of student enrolled in positively evaluated schools. Secondly, our findings suggest an increasing effect of positive evaluations, both in terms of size and statistical significance, as the school local market is defined more extensively. In particular, the effect of a positive evaluation rises from 1.4 additional students in column (2) to 2.2 additional students in column (4). Our findings are in line with the heterogeneous analysis of rural and urban schools. When the school local market is defined in a small radius, we are mostly controlling for competition in dense populated areas. As we have seen, schools in urban areas are not able to accommodate abrupt rises in enrollments, hence the effect of positive evaluations is expected to be smaller and less significant. By contrast, when the school local market is defined to encompass more distant schools, we are defining a school local market also for schools located in more dispersed areas. Since the competition is not anymore only in the immediate vicinity of the school, the effect is expected to be higher. Finally, no effects are found on the socioeconomic composition, as in all our main specifications.\nTherefore, from all robustness results it becomes evident that not selection bias is driving the effect, but parental responses."
        },
        {
            "heading": "7. Discussion and conclusion",
            "text": "This paper examines parental response to exogenous information shocks, defined as the publication of school inspection reports on a government website in a context of initial, absolute information vacuum. Focusing on the Flemish region of Belgium, we have shown that the selection process of school inspections is random and the resulting information is the only source of objective school quality data available to parents due to the absence of central examinations. As a result, enrolments in the first grade and the SES composition can be compared before and after the information shock using a difference-in-differences framework, with uninspected schools as counterfactual.\nOur findings indicate that parents do respond to information shocks, as the publication of school inspection reports strongly affects primary schools. The effect is driven by positively evaluated schools, where the number of first grade students significantly rises by 2.3 students after the publication of reports (an increase of around 7%). The effect is persistent over time, reaching after three years from the inspection an impact of almost 4 additional students. Conversely, schools with an unfavourable evaluation do not significantly lose students. We also observe that our results are driven by schools located in rural areas, while no significance is found for urban schools. We interpret these findings as evidence of the role that market dynamics play in shaping parental response to the publication of performance indicators. In urban municipalities, where schools face capacity constraints, it is not possible to accommodate abrupt rises in demand, and no impact is found. Finally, we never detect significance in the socioeconomic composition.\nThe effect sizes revealed in this study are in line with earlier literature on information provision and school choice. In particular, our findings are consistent with those of Koning and Van der Wiel (2013) who show, relative to all school tracks, an increase in school size between 3 and 9% for schools with at least a positive score in the ranking. While not extremely large, we believe that our results are suggestive of a sizeable effect given the type of intervention (the information is \u201conly\u201d available on the inspectorate's website). As the average school in our sample has 35 students enrolled in the first year of primary education (which approximately corresponds to two classes of 18 students each), this means that a good-performing school sees entries increase by 1 student per class after the reports are published. Our results are also consistent with Koning and Van der Wiel (2013) (and with Mizala & Urquiola, 2013) in that the effect does not appear to be differenciated according to socioeconomic groups.\nFrom a policy perspective, our paper suggests that introducing more transparency is beneficial for two reasons. First, it helps reducing information asymmetries between parents and schools by providing the former with (a proxy of) school quality information that was not available before and that is largely employed. In particular, our study indirectly speaks to the important role that open government can have in conveying more transparency in the education market. In contrast with de Kool and Bekkers (2015), we find strong evidence of parental response to information provision which suggests that parents largely consulted the government website on which inspection reports were published. Second, introducing more transparency is beneficial as it makes schools accountable of their performances by signaling both contemporaneous school practices and future actions to improve school practices.\nRegarding the external validity, our findings are relevant for all countries that - similar to Belgium before inspection reports - so far have no information on school quality accessible by parents.46 The similarity in effects between our study and the one of Koning & Van der Wiel,\n44 The positive and negative indicators are defined following the same notation as in Equation (1). 45 Note that we define as competitors both schools that offer only primary education and schools that offer primary and pre-primary education jointly.\n46 For instance, Italy, where parents have no access to school quality indicators as the test scores from the INVALSI standardized testing are not available for public consultation.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n14\n(2013), further suggests that parents adhere importance to a value judgement released by authorities (newspaper in the Netherlands, inspectorate in Belgium) on school quality. Therefore, although the inspection data object of our study are not open data in its strictest definition (for instance, they are not machine-readable), we might expect similar parental interest in consulting performance indicators even if the information was released in a different way, e.g., through open data platforms. Given the complexity of open data (for an overview, see Zuiderwijk & Janssen, 2014; Ansari, Barati, & Martin, 2021), however, it would then be essential to have a thorough reflection about how to convey such data while exploiting its full potential.\nThree conclusive remarks must be addressed. First, our study employs a quasi-experimental design, which per se does not produce causal evidence. However, given the context, data and methodologies applied, we believe that our estimates are robust and could be interpreted as causal effects. Second, our results also reveal that parents do not make use of school inspection reports when the institution where their children are enrolled for primary school also offers preschool. This suggests that parents are more likely to attribute importance to school reports when forced by contingency to evaluate alternatives, and has important policy implications as it might hinder some of the attended effects of accountability policies such as school inspection reports. Third, school inspection reports might be only imperfect measures of school quality as they share some of the downsides of other low-stake accountability policies. When students are evaluated on their performance, teachers may have the incentive to act strategically and \u2018teach to the test\u2019 or \u2018teach to the inspection\u2019. For instance, to score higher, teachers may train students on test-specific skills and give little space to less quantifiable, yet important, soft skills (Jacob, 2005). Most worrisome, teachers\nmay help students during their performance (Jacob & Levitt, 2003) or make sure the lowest achieving pupils are not present when the evaluation is carried out (Figlio & Getzler, 2006). Additionally, when conducted at low frequencies, inspection reports may induce positively evaluated schools to \u2018rest on their laurels' (de Wolf & Janssens, 2007).\nAll things considered, like earlier studies using other measures of school quality (e.g. Nunes et al., 2015), we do not aim to question the appropriateness of school inspection reports as evaluation tools. Rather, we stress the complicated relationship between performance indicators and actual school quality. The particular setting of our study allows us to consider school inspection reports as a proxy for quality, as no other objective information on schools' performance is available. Given the discussed possible downsides of school inspection reports as a low-stake accountability policy, however, we emphasize that increased transparency should go hand in hand with high internal validity of the underlying documents. To this end, inspection visits (and reports) should be designed to prevent strategic teacher behavior, and be conducted at reasonable frequencies. With so much at stake, it is incumbent upon the government to ensure that inspection methods are top-notch and that assessments are as accurate as possible. This is particularly important since, as we show in this paper, introducing more transparency has reallife implications on citizens' choices and behavior."
        },
        {
            "heading": "Declaration of Competing Interest",
            "text": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."
        },
        {
            "heading": "Appendix A. Figures and Tables",
            "text": "S. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n15"
        },
        {
            "heading": "Table A.2",
            "text": "Summary statistics for several categories of population density.\nObservations Schools Inspection (%)\nPopulation density Freq. Percent Freq. Percent Positive Negative\n0\u2013250 634 9.87 57 11.15 66.67 33.33 250\u2013500 1943 30.25 153 29.94 67.24 32.76 500\u2013750 862 13.42 66 12.92 57.14 42.86 750\u20131500 1347 20.97 103 20.16 60.87 39.13 >1500 1637 25.49 132 25.83 51.02 48.98 Total 6423 100.00 511 100.00 60.30 39.70\nNotes: The table shows absolute and relative frequencies for increasing levels of population density. The total number of schools observed in the sample is 511.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n\u2019Other\u2019 includes courses evaluated at a lower frequency, not enough to be individual categories (i.e. physical education, ICT, French language, science and technology, and social learning).\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n17"
        },
        {
            "heading": "Table A.6",
            "text": "Effect of information shocks on school size and SES composition with several thresholds defined for rural and urban municipalities.\nPANEL A: rural <250 <500 <750 <1000 <1500\n(1) (2) (3) (4) (5) (6) (7) (8) (9) (10)\nSize SES Size SES Size SES Size SES Size SES Inspection \u2212 1.734 \u2212 0.00640 1.583 \u2212 0.0112 2.416** \u2212 0.00222 2.272** \u2212 0.00448 2.234** \u2212 0.00145 (1.795) (0.0103) (1.075) (0.00575) (0.876) (0.00537) (0.763) (0.00490) (0.702) (0.00474) Constant 25.55*** 0.129*** 30.27*** 0.126*** 32.10*** 0.133*** 33.31*** 0.143*** 33.70*** 0.145*** (0.173) (0.000991) (0.0943) (0.000504) (0.0800) (0.000490) (0.0722) (0.000463) (0.0705) (0.000477) School FE Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Year FE Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes School \u00d7 time trends Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes N 634 634 2577 2577 3503 3503 4315 4315 4786 4786 R2 0.893 0.654 0.896 0.745 0.902 0.784 0.905 0.832 0.903 0.827 PANEL B: urban >250 >500 >750 >1000 >1500\n(1) (2) (3) (4) (5) (6) (7) (8) (9) (10) Size SES Size SES Size SES Size SES Size SES\nInspection 2.190** 0.00174 2.099** 0.00708 1.277 0.00269 1.069 0.00983 0.650 0.00817 (0.664) (0.00505) (0.755) (0.00659) (0.886) (0.00796) (1.106) (0.00985) (1.380) (0.0122) Constant 36.74*** 0.182*** 39.22*** 0.210*** 39.87*** 0.228*** 40.39*** 0.244*** 41.28*** 0.269*** (0.0677) (0.000515) (0.0835) (0.000728) (0.100) (0.000903) (0.128) (0.00114) (0.143) (0.00126) School FE Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes Year FE Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes School \u00d7 time trends Yes Yes Yes Yes Yes Yes Yes Yes Yes Yes N 5789 5789 3846 3846 2920 2920 2108 2108 1637 1637 R2 0.912 0.900 0.916 0.914 0.918 0.918 0.922 0.919 0.929 0.928\nNotes: The table shows the estimated effect of information shocks on school size and SES composition, for different thresholds defining rural and urban municipalities. Panel A shows estimation outcomes for rural municipalities, defined as having less than 250, 500, 750, 1000 and 1500 citizens per km2 respectively (reading the table from left to right entails that the sample is intrinsically less rural). Panel B shows estimation outcomes for urban municipalities, defined as having more than 250, 500, 750, 1000 and 1500 inhabitants per km2 (reading the table from left to right entails that the sample is intrinsically more urban). Estimates from Panel B reveal that information shocks do not significantly affect school size as of column 5, thus suggesting no response of parents in highly dense municipalities. Estimates from Panel A reveal that information shocks significantly affect school size as of column (5), where the sample is enlarged to include low to middle rural areas. As we do not consider realistic to define as rural, zones populated up to 1000 and 1500 people per km2, the limit value of 750 is robust to our checks. No significance is detected with respect to SES composition. Robust standard errors, clustered at school level, in parenthesis. * p < 0.05, ** p < 0.01, *** p < 0.001).\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n18"
        },
        {
            "heading": "Table A.8",
            "text": "Effect of information shocks on school size and SES composition for the expanded sample.\nBaseline Positive Negative\n(1) (2) (3) (4) (5) (6)\nSchool size SES composition School size SES composition School size SES composition\nInspection 0.115 \u2212 0.00339 0.276 \u2212 0.00359 \u2212 0.0549 \u2212 0.00485 (0.204) (0.00212) (0.256) (0.00272) (0.312) (0.00308) Constant 27.87*** 0.193*** 27.73*** 0.189*** 27.78*** 0.193*** (0.0222) (0.000231) (0.0210) (0.000224) (0.0197) (0.000194) School FE Yes Yes Yes Yes Yes Yes Year FE Yes Yes Yes Yes Yes Yes School \u00d7 time trends Yes Yes Yes Yes Yes Yes N 40,666 40,666 32,245 32,245 28,287 28,287 R2 0.900 0.876 0.902 0.866 0.902 0.876\nNotes: The table shows the estimated effect of information shocks on school size and SES composition, when the sample is extended to include schools that jointly offer primary education and preschool. Outcomes in columns (1) and (2) refer to the overall effect; outcomes in columns (3) to (6) refer to the effects of a positive and a negative evaluation. School size is measured as the number of students in first grade and SES composition as the average socioeconomic composition of the student body in first grade. Robust standard errors, clustered at school level, in parenthesis. * p < 0.05, ** p < 0.01, *** p < 0.001).\nS. Palmaccio et al.\nGovernmentInformationQuarterly39(2022)101702\n19\nS. Palm accio et al.\nGovernment Information Quarterly 39 (2022) 101702\n20"
        },
        {
            "heading": "Table A.10",
            "text": "Effect of information shocks on school size and SES composition in the baseline specification and in rural and urban municipalities, with gradually added fixed effects and generalized synthetic control estimates.\nBaseline Rural\nSchool FE School FE School FE Generalized School FE School FE\nSchool\u00d7 time School\u00d7 time Synthetic School\u00d7time\nYear FE Control\n(1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11)\nOutcome: School size D: School Inspection 2.042*** 3.332*** 1.839** 1.854*** 2.382*** 4.015*** (0.431) (0.577) (0.627) (0.486) (0.522) (0.737) D\u00d7t0 1.893*** 2.778*** 1.714** 1.851* 2.308** (0.528) (0.592) (0.626) (0.529) (0.715) D\u00d7t+1 2.121*** 3.454*** 1.969* 1.390* 2.486*** (0.570) (0.705) (0.792) (0.589) (0.735) D\u00d7t+2 2.289*** 4.049*** 2.250* 1.871* 2.575** (0.642) (0.822) (0.972) (0.699) (0.815) D\u00d7t+3 2.282** 4.551*** 2.708* 2.104* 2.241* (0.730) (0.939) (1.182) (0.884) (1.062) D\u00d7t+4 1.247 4.573*** 2.888 2.826* 2.010* (0.744) (1.361) (1.719) (1.393) (0.796) Constant 35.61*** 35.61*** 35.48*** 35.45*** 35.63*** 35.60*** 32.11*** 32.11*** 31.96*** (0.0437) (0.0437) (0.0584) (0.0629) (0.0636) (0.0776) (0.0477) (0.0473) (0.0673) N 6423 6423 6423 6423 6423 6423 6329 6329 3503 3503 3503 R2 0.878 0.878 0.912 0.912 0.914 0.914 0.864 0.864 0.900\nOutcome: SES composition D: School Inspection \u2212 0.0121** 0.0208*** 0.000885 0.0024 \u2212 0.0186*** 0.0173*** (0.00448) (0.00418) (0.00467) (0.00352) (0.00489) (0.00482) D\u00d7t0 \u2212 0.0159** 0.0132** 0.000346 \u2212 0.0012 \u2212 0.0233*** (0.00489) (0.00464) (0.00505) (0.00389) (0.00580) D\u00d7t+1 \u2212 0.0149*** 0.0204*** 0.00259 0.0044 \u2212 0.0222*** (0.00433) (0.00442) (0.00553) (0.00437) (0.00556) D\u00d7t+2 \u2212 0.00975 0.0305*** 0.00298 0.0038 \u2212 0.0114 (0.00711) (0.00729) (0.00856) (0.00561) (0.00752) D\u00d7t+3 \u2212 0.0133 0.0405*** 0.00147 \u2212 0.0009 \u2212 0.0177 (0.0103) (0.0107) (0.0127) (0.00675) (0.00908) D\u00d7t+4 0.0118 0.0743*** 0.0158 0.0126 \u2212 0.00277 (0.00941) (0.0131) (0.0164) (0.01053) (0.0138) Constant 0.178*** 0.178*** 0.174*** 0.174*** 0.176*** 0.176*** 0.135*** 0.135*** 0.132*** (0.000454) (0.000463) (0.000424) (0.000515) (0.000473) (0.000659) (0.000447) (0.000454) (0.000441) N 6423 6423 6423 6423 6423 6423 6329 6329 3503 3503 3503 R2 0.841 0.841 0.891 0.892 0.894 0.894 0.699 0.699 0.776\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n21\nRural Urban\nSchool FE School FE Generalized School FE School FE School FE Generalized\nSchool\u00d7time School\u00d7 time Synthetic School\u00d7 time School\u00d7 time Synthetic\nYear FE Control Year FE Control\n(12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22) (23) (24)\nOutcome: School size 2.416** 1.970** 1.712* 2.608** 1.277 2.402* (0.876) (0.639) (0.680) (0.886) (0.886) (0.832) 3.641*** 2.372* 2.276** 1.444 1.841* 1.009 1.565 (0.849) (0.921) (0.722) (0.779) (0.812) (0.830) (0.815) 4.092*** 2.440* 1.819* 1.745* 2.770* 1.484 1.085 (0.899) (1.038) (0.868) (0.875) (1.087) (1.190) (0.944) 4.681*** 2.762* 2.157* 2.014* 3.382** 1.977 2.250 (1.053) (1.294) (1.007) (0.985) (1.257) (1.440) (1.096) 4.716*** 2.459 1.400 2.295* 4.236** 2.999 3.720* (1.044) (1.414) (1.281) (1.001) (1.472) (1.827) (1.260) 5.076* 3.215 1.603 0.574 3.988* 2.727 6.615** (1.784) (2.266) (1.964) (1.186) (2.006) (2.543) (2.160) 31.94*** 32.10*** 32.09*** 39.82*** 39.82*** 39.72*** 39.68*** 39.87*** 39.81*** (0.0668) (0.0800) (0.0887) (0.0771) (0.0773) (0.100) (0.113) (0.100) (0.133) 3503 3503 3503 3466 3466 2920 2920 2920 2920 2920 2920 2863 2863 0.900 0.902 0.902 0.881 0.881 0.917 0.917 0.918 0.919\nOutcome: SES composition \u2212 0.00222 \u2212 0.0018 \u2212 0.00569 0.0245*** 0.00269 0.0006 (0.00537) (0.00482) (0.00740) (0.00693) (0.00796) (0.00543) 0.00916 \u2212 0.00336 \u2212 0.0027 \u2212 0.00791 0.0176* 0.00291 \u2212 0.0009 (0.00568) (0.00597) (0.00558) (0.00797) (0.00745) (0.00832) (0.00569) 0.0160** \u2212 0.00114 \u2212 0.0028 \u2212 0.00747 0.0250*** 0.00521 0.0050 (0.00510) (0.00612) (0.00671) (0.00656) (0.00726) (0.00950) (0.00703) 0.0313*** 0.00222 0.0025 \u2212 0.00807 0.0300* 0.00244 0.0003 (0.00849) (0.00964) (0.00816) (0.0119) (0.0117) (0.0142) (0.00809) 0.0453*** 0.00789 0.0005 \u2212 0.0100 0.0379* \u2212 0.00463 \u2212 0.0118 (0.0110) (0.0127) (0.01032) (0.0164) (0.0168) (0.0211) (0.00939) 0.0656*** 0.00809 \u2212 0.0104 0.0244* 0.0825*** 0.0206 0.0199 (0.0144) (0.0174) (0.01609) (0.0123) (0.0207) (0.0272) (0.01431) 0.131*** 0.133*** 0.133*** 0.229*** 0.229*** 0.226*** 0.225*** 0.228*** 0.228*** (0.000498) (0.000490) (0.000601) (0.000839) (0.000848) (0.000785) (0.000965) (0.000903) (0.00131) 3503 3503 3503 3466 3466 2920 2920 2920 2920 2920 2920 2863 2863 0.778 0.784 0.784 0.867 0.867 0.915 0.916 0.918 0.918\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n22"
        },
        {
            "heading": "Table A.11",
            "text": "Effect of positive and negative evaluations on school size and SES composition in rural and urban municipalities.\nPANEL A: rural Positive Negative\nSchool size SES composition School size SES composition\n(1) (2) (3) (4) (5) (6) (7) (8)\nD: Inspection 2.590* \u2212 0.00396 2.209 0.00279 (1.059) (0.00561) (1.332) (0.0106) D\u00d7t0 2.234* \u2212 0.00490 2.653 0.000116 (1.130) (0.00657) (1.402) (0.0119) D\u00d7t+1 3.321** \u2212 0.00163 1.000 0.000289 (1.266) (0.00696) (1.531) (0.0103) D\u00d7t+2 2.543 \u2212 0.00296 3.420 0.0129 (1.389) (0.0107) (2.382) (0.0169) D\u00d7t+3 3.107* 0.00120 0.973 0.0258 (1.494) (0.0153) (2.719) (0.0155) D\u00d7t+4 4.113 0.0196 1.147 \u2212 0.0345 (2.744) (0.0188) (2.494) (0.0250) Constant 32.54*** 32.52*** 0.134*** 0.133*** 31.68*** 31.68*** 0.141*** 0.141*** (0.0793) (0.0846) (0.000420) (0.000551) (0.0561) (0.0592) (0.000449) (0.000455) School FE Yes Yes Yes Yes Yes Yes Yes Yes Year FE Yes Yes Yes Yes Yes Yes Yes Yes School \u00d7 time trends Yes Yes Yes Yes Yes Yes Yes Yes N 2898 2898 2898 2898 2443 2443 2443 2443 R2 0.903 0.903 0.785 0.785 0.905 0.905 0.791 0.791\nPANEL B: urban Positive Negative\nSchool size SES composition School size SES composition\n(1) (2) (3) (4) (5) (6) (7) (8)\nD: Inspection 1.912 \u2212 0.00454 0.875 0.00914 (1.113) (0.0103) (1.485) (0.0114) D\u00d7t0 1.592 \u2212 0.00408 0.386 0.00957 (1.026) (0.0105) (1.384) (0.0123) D\u00d7t+1 1.756 \u2212 0.00587 1.362 0.0167 (1.463) (0.0111) (1.895) (0.0133) D\u00d7t+2 2.712 \u2212 0.000676 1.423 0.00165 (1.739) (0.0163) (2.166) (0.0222) D\u00d7t+3 4.169 \u2212 0.00129 1.776 \u2212 0.0144 (2.160) (0.0241) (2.696) (0.0325) D\u00d7t+4 2.902 0.0193 2.361 0.0160 (3.137) (0.0351) (3.327) (0.0321) Constant 40.48*** 40.44*** 0.225*** 0.225*** 41.91*** 41.89*** 0.243*** 0.243*** (0.0926) (0.117) (0.000857) (0.00120) (0.104) (0.123) (0.000793) (0.00104) School FE Yes Yes Yes Yes Yes Yes Yes Yes Year FE Yes Yes Yes Yes Yes Yes Yes Yes School \u00d7 time trends Yes Yes Yes Yes Yes Yes Yes Yes N 2272 2272 2272 2272 2032 2032 2032 2032 R2 0.920 0.920 0.911 0.911 0.921 0.922 0.929 0.929\nNotes: The table shows the estimated effect of positive and negative evaluations on school size and SES composition in rural (PANEL A) and urban (PANEL B) municipalities. Rural (urban) municipalities are defined as having less (more) than 750 inhabitants per km2. Estimates show the effect over all years and disentangled according to how many years elapsed since the inspection. School size is measured as the number of students in first grade and SES composition as the average socioeconomic composition of the student body in first grade. Robust standard errors, clustered at school level, in parenthesis."
        },
        {
            "heading": "Table A.12",
            "text": "Effect of positive and negative evaluations on school size and SES composition for different levels of school local markets.\nSchool size SES composition\nRadius: Radius: Radius: Radius: Radius: Radius: Radius: Radius:\n1 km 2.5 km 5 km 10 km 1 km 2.5 km 5 km 10 km\n(1) (2) (3) (4) (5) (6) (7) (8)\nPositive evaluation 1.515* 1.392* 1.892** 2.166** \u2212 0.00254 \u2212 0.00324 \u2212 0.00593 \u2212 0.00423 (0.631) (0.697) (0.667) (0.724) (0.0057) (0.00608) (0.00674) (0.00648) Negative evaluation 0.863 1.131 1.408 1.816 0.00871 0.00839 0.00316 0.00494 (0.819) (0.903) (0.833) (0.998) (0.00741) (0.00767) (0.00868) (0.00801) Number of competitor schoolsa 2.576*** \u2212 0.268 \u2212 0.260* \u2212 0.0957 \u2212 0.000418 \u2212 0.000511 \u2212 0.000165 0.000238 (0.616) (0.249) (0.119) (0.0657) (0.00494) (0.00152) (0.000987) (0.000471) Fraction of positively evaluated schoolsa 0.00327 0.012 \u2212 0.0119 0.00959 \u2212 0.0000426 0.0000195 0.0000152 \u2212 0.000379 (0.0109) (0.00993) (0.0158) (0.0245) (0.000077) (0.000101) (0.00014) (0.000247) Fraction of negatively evaluated schoolsa \u2212 0.00298 \u2212 0.0132 \u2212 0.000649 \u2212 0.0635 \u2212 0.000049 \u2212 0.0000506 0.000264 0.000826\n(continued on next page)\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n23\nThe table shows the impact of positive and negative evaluations on school size and SES composition, for different levels of the school local market. A school's local market is defined as the set of schools laying within a certain radius of kilometers from the school. We consider four possible radius: 1, 2.5, 5 and 10 km. School size is measured as the number of students in first year of primary education. SES composition is the average SES composition of the student body in the first year of primary education. a Number of competitor schools, fraction of positively evaluated schools, fraction of negatively evaluated schools and market share are adaptively computed according to the radius of the local market considered. Fraction of positively evaluated schools ranges from 0 (no school in the local market receives a positive evaluation) to 100 (all schools in the local market receive a positive evaluation); fraction of negatively evaluated schools ranges from 0 (no school in the local market receives a negative evaluation) to 100 (all schools in the local market receive a negative evaluation); market share ranges from 1 to 100 (the reference school is the only school in the local market). Notes: Robust standard errors, clustered at school level, in parenthesis. * p < 0.05, ** p < 0.01, *** p < 0.001."
        },
        {
            "heading": "Appendix B. Table of contents of an inspection report",
            "text": "PREFACE 1. SUMMARY 2. SCREENING REPORT 2.1. Subjects of the inspection visit 2.2. Process indicators or process variables of the inspection visit 3. DOES THE SCHOOL RESPECT THE EDUCATIONAL REGULATIONS? 3.1. Does the school respect the criteria for approval? 3.1.1. Does the school respect the educational objectives? 3.1.1.1. preschool education: Dutch 3.1.1.2. Preschool education: Social sciences 3.1.1.3. preschool education: Dutch and social sciences 3.1.1.4. Primary education: Dutch 3.1.1.5. Primary education: Social sciences 3.1.1.6. Primary education: ICT 3.1.2. Does the school respect the \u2018habitability, safety and hygiene\u2019 criteria for approval? 3.1.3. Does the school respect the other criteria for approval? 3.2. Does the school respect the other regulations? 4. DOES THE SCHOOL MONITOR ITS OWN QUALITY? 4.1. Learning guidance 4.2. Educational organization 5. GENERAL POLICY OF THE SCHOOL 6. STRENGTHS AND WEAKNESSES OF THE SCHOOL 6.1. What is the school doing well? 6.2. What can the school improve? 6.3. What should the school improve? 7. EVALUATIONS RELATED TO THE CRITERIA FOR APPROVAL 8. FINDINGS RELATED TO OTHER REGULATIONS Primary education: Dutch Satisfactory. The teachers achieve the educational objectives for the subject\u2019Dutch\u2019 at a satisfactory level. The choice to work explicitly in a more result-oriented way has a positive effect on the performance of the students. The teachers plan a wide range of education activities, with specific attention to the active involvement of the students. The relatively close adherence to the educational regulations supports cohesion and development.\n- Educational offer (Planning; reference framework; Balanced and complete; Cohesion; broad harmonic formation; active learning)\nBased on the analysis of the output data, the school team took some measures to work in a more results-oriented way. To this end, the school team is collaborating with the Brussels External Guidance Service and with their own pedagogical and guidance services. This approach is implemented in a\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n24\nfew classes, where the performance of the pupils is clearly improved. The teachers closely follow the educational regulations to plan the language offer and attain the educational objectives. In this way they ensure a sufficiently targeted, gradual and balanced educational offer. To meet the educational needs of the pupils, the teachers focus on the reading and speaking learning areas. In addition to the conventional activities, they plan extra reading activities, reading assignments, and extra speaking activities. In this way, they enrich the vocabulary of the students and improve their reading and speaking abilities. Not all teachers are equally engaged in these activities.\nThe spelling classes are usually offered according to the educational regulations, but in some classes students receive extra lessons. This leads sometimes to an oversupply of the educational offer. The writing classes are offered according to the educational regulations and sometimes integrate social sciences topics or current affairs topics.\nTeachers rarely use heuristics to give classes. The educational guidelines that the kindergarten department aims to develop do not receive a strong follow-up in the primary school department.\n- Educational organization (Class management; Teaching time)\nClass management is in some classes aimed at teaching the students how to to work together cooperatively. In these classes, students are given the opportunity to study and learn in a differentiated way. This creates a stimulating and rich language environment. The teachers' educational approach is supportive and challenging.\nThe teachers plan sufficient time to teach, in accordance with the educational needs of the children. They also often integrate, albeit less intentionally, a variety of linguistic terms pertaining to other subjects.\n- Use of the material: Equipment (Educational resources)\nThe school has only the necessary learning materials to give classes. The budget that the teachers receive to purchase materials does not allow them to invest in additional language stimulating tools. The school team made agreements to coordinate the images used in support of the Dutch classes. In some classes, the students do not have a good view of the board.\nSome classes are too small and overcrowded. In these classes, teachers cannot efficiently find space to form groups and create speaking activities.\n- Guidance: Partnerships (Collaborations with partners)\nThe school is part of a local network whose partners strengthen each other. The many school initiatives have a positive effect on the students' language skills. They take part into cultural activities and are given the opportunity to participate in all kinds of creative-language activities.\n- Evaluation: Evaluation practices. (Balanced and representative. Focused on redirecting. Student monitoring system)\nIn first grade, teachers make systematic use of the opportunity to digitally track the progress of the students. This leads to targeted support and, if necessary, to the adjustment of the educational offer.\nIn other grades, teachers make use of the \u2018method testing\u2019 (methodetoetsen), sometimes supplemented with their own tests. During these years, there is a less targeted support and adjustment of the educational offer. Only a few teachers carry on with a targeted differentiated approach.\nIn addition, standardized tests for speaking and technical reading are in place. It is surprising that a significant group of students is not progressing in the development of reading skills. However, this does not lead to targeted support and increased focus on technical reading.\n- Guidance: Learning Guidance. (Perception. Care)\nDespite the relatively good evaluation practices, the student monitoring system does not provide a clear picture of the language development and the learning path of the students. After discussing with the student, the school team rarely formulates concrete and targeted actions to support the student's language development in the longer term. With respect to weak-abilities students, it is difficult to determine what type of guidance is provided and what the result of any remediation is.\n- Quality control\nThe school team is working on an output oriented policy for Dutch. It analyzes the evolution of the students' results and links them with clear expectations. A positive development is noticeable.\nEVALUATIONS RELATED TO THE CRITERIA FOR APPROVAL In implementation of the decree on the quality of education of 8 May 2009, the evaluation is: FAVOURABLE.\n\u2022 for respecting the \u2018educational objectives' criteria for approval for preschool education. \u2022 for respecting the \u2018habitability, safety and hygiene\u2019 criteria for approval. \u2022 for respecting the other criteria for approval.\nLIMITED FAVOURABLE.\n\u2022 for not respecting the \u2018educational objectives' criteria for approval for primary education \u2022 failure to respect the educational objectives for ICT, social sciences.\nTo monitor these shortages, the Education Inspectorate will carry out another check as of 16-05-2017.\nS. Palmaccio et al.\nGovernment Information Quarterly 39 (2022) 101702\n25"
        }
    ],
    "title": "Information shocks and parental response in education. A case study of an open government initiative 1 1 The data for this study are provided by the Education Authority of Belgium. As the data are protected by a confidentiality agreement, we are precluded from sharing the data with others. We would be happy to provide assistance and Stata code to replicate the results of this study. We are grateful to Gerd Van den Eede, Kosuke Imai, Jrn-Steffen Pischke, William Parient, Thomas Wouters, Deni Mazrekaj, Erwin Ooghe, Iris Kesternich, Jill Johnes, Daniel Horn, Maarten Penninckx, Philip Oreopoulos, and participants at seminars and conferences in Brussels, Lisbon (ESEE), Budapest (CERSHAS), Leuven (LEER), Catanzaro (IWAEE) and Louvain-la-Neuve (BDLE) for comments and suggestions. The authors acknowledge financial support from KU Leuven (grant 3H180266), FWO (grant G067120N ) and Horizon Europe projectA\u0303\u00a2A\u0302A\u0302DemoTrans' (grant 101059288). The usual disclaimer applies",
    "year": 2022
}