{
    "abstractText": "In recent years, Scientific Machine Learning (SciML) methods for solving partial differential equations (PDEs) have gained increasing popularity. Within such a paradigm, Physics-Informed Neural Networks (PINNs) are novel deep learning frameworks for solving initial-boundary value problems involving nonlinear PDEs. Recently, PINNs have shown promising results in several application fields. Motivated by applications to gas filtration problems, here we present and evaluate a PINN-based approach to predict solutions to strongly degenerate parabolic problems with asymptotic structure of Laplacian type. To the best of our knowledge, this is one of the first papers demonstrating the efficacy of the PINN framework for solving such kind of problems. In particular, we estimate an appropriate approximation error for some test problems whose analytical solutions are fortunately known. The numerical experiments discussed include two and three-dimensional spatial domains, emphasizing the effectiveness of this approach in predicting accurate solutions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Pasquale Ambrosio"
        },
        {
            "affiliations": [],
            "name": "Salvatore Cuomo"
        },
        {
            "affiliations": [],
            "name": "Mariapia De Rosa"
        }
    ],
    "id": "SP:d5052b9395a28e32c579f8826ac465039e02b59f",
    "references": [
        {
            "authors": [
                "Z.M. Akhmedov",
                "G.I. Barenblatt",
                "V.M. Entov",
                "A. Kh"
            ],
            "title": "Mirzadzhan-Zade",
            "venue": "Nonlinear effects in gas filtration, Izv. AN SSSR. Mekhanika Zhidkosti i Gaza, Vol. 4, No. 5, pp. 103-109",
            "year": 1969
        },
        {
            "authors": [
                "P. Ambrosio"
            ],
            "title": "Fractional Sobolev regularity for solutions to a strongly degenerate parabolic equation",
            "venue": "Forum Mathematicum ",
            "year": 2023
        },
        {
            "authors": [
                "P. Ambrosio"
            ],
            "title": "A",
            "venue": "Passarelli di Napoli, Regularity results for a class of widely degenerate parabolic equations, Adv. Calc. Var. ",
            "year": 2023
        },
        {
            "authors": [
                "S. Byun",
                "J. Oh",
                "L. Wang"
            ],
            "title": "Global Calder\u00f3n-Zygmund Theory for Asymptotically Regular Nonlinear Elliptic and Parabolic Equations",
            "venue": "International Mathematics Research Notices,",
            "year": 2015
        },
        {
            "authors": [
                "S. Cuomo",
                "M. De Rosa",
                "F. Giampaolo",
                "S. Izzo"
            ],
            "title": "V",
            "venue": "Schiano di Cola, Solving groundwater flow equation using physics-informed neural networks, Computers & Mathematics with Applications, 145 ",
            "year": 2023
        },
        {
            "authors": [
                "S. Cuomo"
            ],
            "title": "V",
            "venue": "Schiano Di Cola, F. Giampaolo, G. Rozza, M. Raissi, F. Piccialli, Scientific machine learning through physics-informed neural networks: Where we are and what\u2019s next, Journal of Scientific Computing, 92, 88 ",
            "year": 2022
        },
        {
            "authors": [
                "C.G. Fraces",
                "H. Tchelepi"
            ],
            "title": "Physics Informed Deep Learning for Flow and Transport in Porous Media",
            "venue": "SPE Reservoir Simulation Conference. SPE",
            "year": 2021
        },
        {
            "authors": [
                "A. Gentile"
            ],
            "title": "A",
            "venue": "Passarelli di Napoli, Higher regularity for weak solutions to degenerate parabolic problems, Calc. Var. 62, 225 ",
            "year": 2023
        },
        {
            "authors": [
                "M.-S. Go",
                "J.H. Lim",
                "S. Lee"
            ],
            "title": "Physics-informed neural network-based surrogate model for a virtual thermal sensor with real-time simulation",
            "venue": "International Journal of Heat and Mass Transfer, 214 ",
            "year": 2023
        },
        {
            "authors": [
                "T. Isernia"
            ],
            "title": "BMO regularity for asymptotic parabolic systems with linear growth",
            "venue": "Differential and Integral Equations, vol. 28, No. 11/12 ",
            "year": 2015
        },
        {
            "authors": [
                "G.E. Karniadakis",
                "I.G. Kevredikis",
                "L. Lu",
                "P. Perdikaris",
                "S. Wang",
                "L. Yang"
            ],
            "title": "Physicsinformed machine learning",
            "venue": "Nature Reviews Physics, vol. 3, no. 6, pp. 422-440",
            "year": 2021
        },
        {
            "authors": [
                "T. Kuusi",
                "G. Mingione"
            ],
            "title": "New perturbation methods for nonlinear parabolic problems",
            "venue": "J. Math. Pures Appl., 98: 4 ",
            "year": 2012
        },
        {
            "authors": [
                "J.-L. Lions"
            ],
            "title": "Quelques m\u00e9thodes de r\u00e9solution des probl\u00e8mes aux limites non lin\u00e9aires",
            "venue": "Gauthier-Villars, Paris",
            "year": 1969
        },
        {
            "authors": [
                "M. Raissi"
            ],
            "title": "Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations",
            "venue": "Journal of Machine Learning Research, vol. 19, no. 1, pp. 932-955",
            "year": 2018
        },
        {
            "authors": [
                "M. Raissi",
                "P. Perdikaris",
                "G.E. Karniadakis"
            ],
            "title": "Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations",
            "venue": "preprint ",
            "year": 2017
        },
        {
            "authors": [
                "M. Raissi",
                "P. Perdikaris",
                "G.E. Karniadakis"
            ],
            "title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "venue": "Journal of Computational Physics, vol. 378, pp. 686-707",
            "year": 2019
        },
        {
            "authors": [
                "M.A. Soriano Jr."
            ],
            "title": "Assessment of groundwater well vulnerability to contamination through physics-informed machine learning, Environ",
            "venue": "Res. Lett",
            "year": 2021
        },
        {
            "authors": [
                "N. Zobeiry",
                "K.D. Humfeld"
            ],
            "title": "A physics-informed machine learning approach for solving heat transfer equation in advanced manufacturing and engineering applications",
            "venue": "Engineering Applications of Artificial Intelligence, 101 ",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Keywords: Physics-informed neural network (PINN); deep learning; gas filtration problem; strongly degenerate parabolic equations."
        },
        {
            "heading": "1 Introduction",
            "text": "In this paper, we aim to exploit a novel Artificial Intelligence (AI) methodology, known as Physics-Informed Neural Networks (PINNs), to predict solutions to Cauchy-Dirichlet problems of the type {\n\u2202tu\u2212 div ( (|\u2207u| \u2212 1)+ \u2207u|\u2207u| ) = f in \u2126T := \u2126\u00d7 (0, T ),\nu = w on \u2202par\u2126T , (1.1)\nwhere \u2126 is a bounded connected open subset of Rn (2 \u2264 n \u2264 3) with Lipschitz boundary, f and w are given real-valued functions defined over \u2126 \u00d7 [0, T ] and \u2202par\u2126T respectively, \u2207u denotes the spatial gradient of an unknown solution u : \u2126 \u00d7 [0, T ) \u2192 R, while ( \u00b7 )+ stands for the positive part.\nA motivation for studying problem (1.1) can be found in gas filtration problems (see [1] and [3]). In order to make the paper self-contained, we provide a brief explanation in Section 1.1 below.\nAs for the parabolic equation (1.1)1, the regularity properties of its weak solutions have been recently studied in [2, 3] and [8]. The main novelty of this PDE is that it exhibits a strong degeneracy, coming from the fact that its modulus of ellipticity vanishes in the region {|\u2207u| \u2264 1},\n1\nar X\niv :2\n31 0.\n00 17\n2v 1\n[ m\nat h.\nN A\n] 2\n9 Se\np 20\n23\nand hence its principal part behaves like a Laplace operator only at infinity. The regularity of solutions to parabolic problems with asymptotic structure of Laplacian type had already been investigated in [10], where a BMO regularity was proved for solutions to asymptotically parabolic systems in the case f = 0 (see also [12], where the local Lipschitz continuity of weak solutions with respect to the spatial variable is established). In addition, we want to mention the results contained in [4], where nonhomogeneous parabolic problems with an asymptotic regularity in divergence form of p-Laplacian type are considered. There, Byun, Oh and Wang establish a global Calder\u00f3n-Zygmund estimate by converting a given asymptotically regular problem to a suitable regular problem.\nConcerning the approach used here, the PINNs are a scientific Machine Learning (ML) technique based on Artificial Neural Networks (ANN) with the feature of adding constraints to make the predicted results more in line with the physical laws of the addressed problem. The concept of Physics-Informed Neural Networks was introduced in [11], [14], [15] and [16] to solve direct and inverse problems of Partial Differential Equations. The PINNs predict the solution to a PDE under prescribed initial-boundary conditions by training a neural network to minimize a cost function, called loss function, which penalizes some suitable terms on a set of admissible functions u (for more information, we refer the interested reader to [6]).\nThe kind of approach we want to propose here can offer effective solutions to real problems such as (1.1) and can be applied in many other different fields: for example, in production and advanced engineering [18], for transportation problems [7], and for virtual thermal sensors using real-time simulations [9]. Additionally, it is employed to solve groundwater flow equations [5] and address petroleum and gas contamination [17].\nAs far as we know, this is one of the first papers demonstrating the effectiveness of the PINN framework for solving strongly degenerate parabolic problems of the type (1.1)."
        },
        {
            "heading": "1.1 Motivation",
            "text": "Before describing the structure of this paper, we wish to motivate our study by pointing out that, in the physical cases n = 2 and n = 3, degenerate equations of the form (1.1)1 may arise in gas filtration problems taking into account the initial pressure gradient.\nThe existence of remarkable deviations from the linear Darcy filtration law has been observed in several systems consisting of a fluid and a porous medium (e.g., the filtration of a gas in argillous rocks). One of the manifestations of this nonlinearity is the existence of a limiting pressure gradient, i.e. the minimum value of the pressure gradient for which fluid motion takes place. In general, fluid motion still occurs for subcritical values of the pressure gradient, but very slowly; when achieving the limiting value of the pressure gradient, there is a marked acceleration of the filtration. Therefore, the limiting-gradient concept provides a good approximation for velocities that are not too low.\nIn accordance with some experimental results (see [1]), under certain physical conditions one can take the gas filtration law in the very simple form{\nv = \u2212 k \u00b5 \u2207p [ 1\u2212 \u03b2|\u2207p2| ] if |\u2207p2| \u2265 \u03b2,\nv = 0 if |\u2207p2| < \u03b2,\nwhere v = v(x, t) is the filtration velocity, k is the rock permeability, \u00b5 is the gas viscosity, p = p(x, t) is the pressure and \u03b2 is a positive constant. Under this assumption we obtain a particularly simple expression for the gas mass velocity (flux) j, which contains only the\ngradient of the pressure squared, exactly as in the usual gas filtration problems:{ j = \u03f1v = \u2212 k\n2\u00b5C [ \u2207p2 \u2212 \u03b2 \u2207p2|\u2207p2| ] if |\u2207p2| > \u03b2,\nj = 0 if |\u2207p2| \u2264 \u03b2, (1.2)\nwhere \u03f1 is the gas density and C is a positive constant. Plugging expression (1.2) into the gas mass-conservation equation, we obtain the basic equation for the pressure:{\n\u2202p \u2202t = k 2m\u00b5 div [ \u2207p2 \u2212 \u03b2 \u2207p2|\u2207p2| ] if |\u2207p2| > \u03b2, \u2202p \u2202t = 0 if |\u2207p2| \u2264 \u03b2, (1.3)\nwhere m is a positive constant. Equation (1.3) implies, first of all, that the steady gas motion is described by the same relations as in the steady motion of an incompressible fluid if we replace the pressure of the incompressible fluid with the square of the gas pressure. In addition, if the gas pressure differs very little from some constant pressure p0, or if the gas pressure differs considerably from a constant value only in regions where the gas motion is nearly steady, then the equation for the gas filtration in the region of motion can be \u201clinearized\u201d following L. S. Leibenson, and thus obtaining (see [1] again){\n\u2202p2\n\u2202t = k p0 m\u00b5 div [ \u2207p2 \u2212 \u03b2 \u2207p2|\u2207p2| ] if |\u2207p2| > \u03b2,\n\u2202p2\n\u2202t = 0 if |\u2207p2| \u2264 \u03b2.\n(1.4)\nSetting u = p2 and performing a suitable scaling, equation (1.4) turns into\n\u2202u \u2202t \u2212 div\n( (|\u2207u| \u2212 1)+\n\u2207u |\u2207u|\n) = 0,\nwhich is nothing but equation (1.1)1 with f \u2261 0. This is why (1.1)1 is sometimes called the Leibenson equation in the literature.\nThe paper is organized as follows. Section 2 is devoted to the preliminaries: after a list of some classic notations, we provide details on the strongly degenerate parabolic problem (1.1). In Section 3, we describe the Physics-Informed Neural Network methodology that was employed. Section 4 presents the results that were obtained. Finally, Section 5 provides the conclusions."
        },
        {
            "heading": "2 Notation and preliminaries",
            "text": "In what follows, the norm we use on Rn will be the standard Euclidean one and it will be denoted by | \u00b7 |. In particular, for the vectors \u03be, \u03b7 \u2208 Rn, we write \u27e8\u03be, \u03b7\u27e9 for the usual inner product and |\u03be| := \u27e8\u03be, \u03be\u27e9 12 for the corresponding Euclidean norm. For points in space-time, we will frequently use abbreviations like z = (x, t) or z0 = (x0, t0), for spatial variables x, x0 \u2208 Rn and times t, t0 \u2208 R. We also denote by B\u03c1(x0) = {x \u2208 Rn : |x\u2212 x0| < \u03c1} the open ball with radius \u03c1 > 0 and center x0 \u2208 Rn. Moreover, we use the notation\nQ\u03c1(z0) := B\u03c1(x0)\u00d7 (t0 \u2212 \u03c12, t0), z0 = (x0, t0) \u2208 Rn \u00d7 R, \u03c1 > 0,\nfor the backward parabolic cylinder with vertex (x0, t0) and width \u03c1. Finally, for a general cylinder Q = A\u00d7 (t1, t2), where A \u2282 Rn and t1 < t2, we denote by\n\u2202parQ := (A\u00d7 {t1}) \u222a (\u2202A\u00d7 (t1, t2))\nthe usual parabolic boundary of Q. To give the definition of a weak solution to problem (1.1), we now introduce the function H : Rn \u2192 Rn defined by\nH(\u03be) :=\n{ (|\u03be| \u2212 1)+ \u03be|\u03be| if \u03be \u2208 R\nn \\ {0}, 0 if \u03be = 0.\nDefinition 2.1. Let f \u2208 L1loc(\u2126T ). A function u \u2208 C0 ((0, T );L2(\u2126)) \u2229 L2 (0, T ;W 1,2(\u2126)) is a weak solution of equation (1.1)1 if and only if for any test function \u03c6 \u2208 C\u221e0 (\u2126T ) the following integral identity holds:\u222b\n\u2126T (u \u00b7 \u2202t \u03c6\u2212 \u27e8H(\u2207u),\u2207\u03c6\u27e9) dz = \u2212 \u222b \u2126T f\u03c6 dz. (2.1)\nDefinition 2.2. Let w \u2208 C0 ([0, T ];L2(\u2126)) \u2229 L2 (0, T ;W 1,2(\u2126)). We identify a function\nu \u2208 C0 ( [0, T ];L2(\u2126) ) \u2229 L2 ( 0, T ;W 1,2(\u2126) ) as a weak solution of the Cauchy-Dirichlet problem (1.1) if and only if (2.1) holds and, moreover, u \u2208 w + L2 ( 0, T ;W 1,20 (\u2126) ) and u(\u00b7, 0) = w(\u00b7, 0) in the L2-sense, that is\nlim t\u2198 0\n\u2225u(\u00b7, t)\u2212 w(\u00b7, 0)\u2225L2(\u2126) = 0. (2.2)\nTherefore, the initial condition u = w on \u2126 \u00d7 {0} has to be understood in the usual L2-sense (2.2), while the condition u = w on the lateral boundary \u2202\u2126 \u00d7 (0, T ) has to be meant in the sense of traces, i.e. (u\u2212 w) (\u00b7, t) \u2208 W 1,20 (\u2126) for almost every t \u2208 (0, T ).\nTaking p = 2 and \u03bd = 1 in [3, Theorem 1.1], we immediately obtain the following spatial Sobolev regularity result:\nTheorem 2.3. Let n \u2265 2, 2n+4 n+4 \u2264 q < \u221e and f \u2208 Lq (0, T ;W 1,q(\u2126)). Moreover, assume that\nu \u2208 C0 ( (0, T );L2(\u2126) ) \u2229 L2 ( 0, T ;W 1,2(\u2126) ) is a weak solution of equation (1.1)1. Then the solution satisfies\nH(\u2207u) \u2208 L2loc ( 0, T ;W 1,2loc (\u2126,R n) ) .\nFurthermore, the following estimate\u222b Q\u03c1/2(z0) |\u2207H(\u2207u)|2 dz \u2264 c ( \u2225\u2207f\u2225Lq(QR0 ) + \u2225\u2207f\u2225 2 Lq(QR0 ) ) + c R2 ( \u2225\u2207u\u22252L2(QR0 ) + 1 ) holds true for any parabolic cylinder Q\u03c1(z0) \u2282 QR(z0) \u2282 QR0(z0) \u22d0 \u2126T and a positive constant c depending on n, q and R0.\nFrom the above result one can easily deduce that u admits a weak time derivative ut, which belongs to the local Lebesgue space Lmin {2, q}loc (\u2126T ). The idea is roughly as follows. Consider equation (1.1)1; since the previous theorem tells us that in a certain pointwise sense the second spatial derivatives of u exist, we may develop the expression under the divergence symbol; this will give us an expression that equals ut, from which we get the desired summability of the time derivative. Such an argument has been made rigorous in [3, Theorem 1.2], from which we can derive the next result.\nTheorem 2.4. Under the assumptions of Theorem 2.3, the time derivative of the solution exists in the weak sense and satisfies\n\u2202tu \u2208 Lmin {2, q}loc (\u2126T ).\nFurthermore, the following estimate(\u222b Q\u03c1/2(z0) |\u2202tu|min {2, q} dz ) 1 min {2, q} \u2264 c \u2225f\u2225Lq(QR0 ) + c ( \u2225\u2207f\u2225Lq(QR0 ) + \u2225\u2207f\u2225 2 Lq(QR0 ) ) 1 2\n+ c\nR\n( \u2225\u2207u\u22252L2(QR0 ) + 1 ) 1 2\nholds true for any parabolic cylinder Q\u03c1(z0) \u2282 QR(z0) \u2282 QR0(z0) \u22d0 \u2126T and a positive constant c depending on n, q and R0.\nNow, let the assumptions of Theorem 2.3 be in force. For \u03b5 \u2208 [0, 1] and a couple of standard, non-negative, radially symmetric mollifiers \u03d51 \u2208 C\u221e0 (B1(0)) and \u03d52 \u2208 C\u221e0 ((\u22121, 1)) we define\nf\u03b5(x, t) := \u222b 1 \u22121 \u222b B1(0) f(x\u2212 \u03b5y, t\u2212 \u03b5s)\u03d51(y)\u03d52(s) dy ds,\nwhere f is meant to be extended by zero outside \u2126T . Observe that f0 = f and f\u03b5 \u2208 C\u221e(\u2126T ) for every \u03b5 \u2208 (0, 1]. Next, we consider a domain in space-time denoted by \u2126\u20321,2 := \u2126\u2032 \u00d7 (t1, t2), where \u2126\u2032 \u2286 \u2126 is a bounded domain with smooth boundary and (t1, t2) \u2286 (0, T ). In the following, we will need the definitions below.\nDefinition 2.5. Let \u03b5 \u2208 (0, 1]. A function u\u03b5 \u2208 C0 ((t1, t2);L2(\u2126\u2032)) \u2229 Lp (t1, t2;W 1,2(\u2126\u2032)) is a weak solution of the equation\n\u2202t u\u03b5 \u2212 div (H(\u2207u\u03b5) + \u03b5\u2207u\u03b5) = f\u03b5 in \u2126\u20321,2 (2.3)\nif and only if for any test function \u03c6 \u2208 C\u221e0 (\u2126\u20321,2) the following integral identity holds:\u222b \u2126\u20321,2 (u\u03b5 \u00b7 \u2202t \u03c6\u2212 \u27e8H(\u2207u\u03b5) + \u03b5\u2207u\u03b5,\u2207\u03c6\u27e9) dz = \u2212 \u222b \u2126\u20321,2 f\u03b5 \u03c6dz. (2.4)\nDefinition 2.6. Let \u03b5 \u2208 (0, 1] and u \u2208 C0 ([t1, t2];L2(\u2126\u2032)) \u2229 L2 (t1, t2;W 1,2(\u2126\u2032)). We identify a function\nu\u03b5 \u2208 C0 ( [t1, t2];L 2(\u2126\u2032) ) \u2229 L2 ( t1, t2;W 1,2(\u2126\u2032) )\nas a weak solution of the Cauchy-Dirichlet problem\n{ \u2202t u\u03b5 \u2212 div (H(\u2207u\u03b5) + \u03b5\u2207u\u03b5) = f\u03b5 in \u2126\u20321,2,\nu\u03b5 = u on \u2202par\u2126 \u2032 1,2,\n(2.5)\nif and only if (2.4) holds and, moreover, u\u03b5 \u2208 u+ L2 ( t1, t2;W 1,2 0 (\u2126 \u2032) ) ,\nu\u03b5(\u00b7, t1) = u(\u00b7, t1) in the usual L2-sense and the condition u\u03b5 = u on the lateral boundary \u2202\u2126\u2032 \u00d7 (t1, t2) holds in the sense of traces, i.e. (u\u03b5 \u2212 u) (\u00b7, t) \u2208 W 1,20 (\u2126\u2032) for almost every t \u2208 (t1, t2).\nDue to the strong degeneracy of equation (1.1)1, in order to prove Theorems 2.3 and 2.4 above, the authors of [3] resort to the family of approximating parabolic problems (2.5). These problems exhibit a milder degeneracy than (1.1) and the advantage of considering them stems from the fact that the existence of a unique energy solution u\u03b5 satisfying the requirements of Definition 2.6 can be ensured by the classic existence theory for parabolic equations (see [13, Chapter 2, Theorem 1.2 and Remark 1.2]).\nMoreover, if \u2126\u20321,2 = QR0(z0) := BR0(x0) \u00d7 (t0 \u2212 R20, t0) \u22d0 \u2126T , then from [3, Formulae (4.22) and (4.24)] one can easily deduce\nsup t\u2208 (t0\u2212R20, t0) \u2225u\u03b5(\u00b7, t)\u2212 u(\u00b7, t)\u22252L2(BR0 (x0)) \u2192 0 as \u03b5 \u2192 0 +, (2.6)\nthat is u\u03b5 \u2192 u in L\u221e(t0 \u2212R20, t0;L2(BR0(x0))) as \u03b5 \u2192 0+.\nHence, we can conclude that there exists a sequence {\u03b5j}j\u2208N such that:\n\u2022 0 < \u03b5j \u2264 1 for every j \u2208 N and \u03b5j \u2198 0 monotonically as j \u2192 +\u221e;\n\u2022 u\u03b5j(x, t) \u2192 u(x, t) almost everywhere in QR0(z0) as j \u2192 +\u221e."
        },
        {
            "heading": "3 Physics-informed methodology",
            "text": "Physics-Informed Neural Networks (PINNs) are a type of scientific Machine Learning approach used in neural networks to solve partial differential equations. Unlike traditional neural networks, PINNs incorporate physics constraints into the model, resulting in predicted outcomes that adhere more closely to the natural laws governing the specific problem being addressed. The general form of the problem involves a PDE along with initial and/or boundary conditions.\nIn particular, we consider a (well-posed) problem of the type{ F(u(x, t), \u03b3) = f if (x, t) \u2208 \u2126T := \u2126\u00d7 (0, T ) B(u(x, t)) = w if (x, t) \u2208 \u2202par\u2126T ,\n(3.1)\nwhere \u2126 is a bounded domain in Rn, F denotes a nonlinear differential operator, \u03b3 is a parameter associated with the physics of the problem, B is an operator defining arbitrary initial-boundary conditions, the functions f and w represent the problem data, while u(x, t) denotes the unknown solution.\nThe objective of Physics-Informed Neural Networks is to predict the solution to (3.1) by training the neural network to minimize a cost function. The neural network\u2019s architecture used for PINNs is typically a FeedForward fully-connected Neural Network (FF-DNN), also known as Multi-Layer Perceptron (MLP). In an FF-DNN, information flows only forward direction, in the sense that the neural network does not form a loop. Furthermore, all neurons are interconnected. Once the number N of hidden layers has been chosen, for any i \u2208 {1, . . . , N} and set z = (x, t) we define\n\u0393i(zi\u22121) := Wi zi\u22121 + bi ,\nwhere Wi is the weights matrix of the links between the layers i\u2212 1 and i, while bi corresponds to the biases vector. Then, a generic layer of the neural network is defined by\nhi(zi\u22121;Wi,bi) := \u03c6i(\u0393i(zi\u22121)), i \u2208 {1, . . . , N},\nfor some nonlinear activation function \u03c6i. The output of the FF-DNN, denoted by u\u0302\u03b8(z), can be expressed as a composition of these layers by\nu\u0302\u03b8(z) := (\u0393N \u25e6 \u03c6 \u25e6 \u0393N\u22121 \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 \u03c6 \u25e6 \u03931)(z) , (3.2)\nwhere we assume that the activation function \u03c6 is the same for all layers. To solve the differential problem (3.1) using PINNs, the PDE is approximated by finding an optimal set \u03b8\u2217 of neural network parameters that minimizes a loss function L. This function consists of two components: the former, denoted by LF, is related to the differential equation, while the latter, here denoted by LB, is connected to the initial-boundary conditions (see Fig. 3.1). In particular, the loss function can be defined as follows\nL := \u222b \u2126T\n[F(u(z), \u03b3)\u2212 f ]2 dz\ufe38 \ufe37\ufe37 \ufe38 =:LF +\n\u222b \u2202par\u2126T\n[B(u(z))\u2212 w]2 dHn\ufe38 \ufe37\ufe37 \ufe38 =:LB . (3.3)\nSome weights (\u03c9F, \u03c9B) are usually applied to balance the importance of each component. Hence, we can write\n\u03b8\u2217 := argmin \u03b8\n( \u03c9F LF(\u03b8) + \u03c9B LB(\u03b8) ) . (3.4)\nThe aim of this approach can be either to approximate the solution of the PDE satisfying the initial-boundary conditions (direct problem) or to estimate parameters based on physics constraints (inverse problem)."
        },
        {
            "heading": "4 Numerical results",
            "text": "In this section we evaluate the accuracy and effectiveness of our predictive method, by testing it with five problems of the type (1.1) whose exact solutions are known. For each problem, we will denote the exact solution by u, and the predicted (or approximate) solution by u\u0302. Sometimes, by abuse of language, for a given time t \u2265 0 we will refer to the partial maps u(\u00b7, t) and u\u0302(\u00b7, t) as the exact solution and the predicted (or approximate) solution respectively. The meaning will be clear from the context every time. We will deal with each test problem separately, so that no confusion can arise. In the first three problems, \u2126 will be a bounded domain of R2, while, in the last two problems, \u2126 will denote the open unit sphere of R3 centered at the origin.\nIn addition, for each of the test problems, we employed the same neural network architecture. This consists of 4 layers, each with 20 neurons. We utilized the hyperbolic tangent function as the activation function for both the input layer and the hidden layers, while a linear function served as the activation function for the output layer. Finally, to train the neural network, we conducted 80000 epochs with a learning rate of 3\u00d7 10\u22123 and employed the ADAM optimizer. The experiments were performed on a NVIDIA GeForce RTX 3080 GPU with AMD Ryzen 9 5950X 16-Core Processor and 128 GB of RAM."
        },
        {
            "heading": "4.1 First test problem",
            "text": "The first test problem that we consider is \u2202tv \u2212 div ( (|\u2207v| \u2212 1)+ \u2207v|\u2207v| ) = 1 in \u2126T , v(x, y, 0) = 1 2 (x2 + y2) if (x, y) \u2208 \u2126,\nv(x, y, t) = 1 2 + t if (x, y) \u2208 \u2202\u2126 \u2227 t \u2208 (0, T ),\n(P1)\nwhere \u2126 = {(x, y) \u2208 R2 : x2 + y2 < 1}. The exact solution of this problem is given by\nu(x, y, t) = 1\n2 (x2 + y2) + t.\nTherefore, for any fixed time t \u2265 0 the graph of the function u(\u00b7, t) is an elliptic paraboloid. As time goes on, this paraboloid slides along an oriented vertical axis at a constant velocity, without deformation, since \u2202tu \u2261 1 over \u2126T (see Fig. 4.1, above).\nTo train the neural network, in each experiment we have initially used 441 points to suitably discretize the domain \u2126 and its boundary \u2202\u2126, and 21 equispaced points in the time interval\n[0, T ]. Once the network has been trained, we have made a prediction of the solution to problem (P1) at different times t (Fig. 4.1, below).\nWhat has been observed is that the plot of the predicted solution u\u0302(\u00b7, t) has precisely the same shape and geometric properties as the graph of the exact solution u(\u00b7, t), for both short and long times t. Moreover, the time evolution of the approximate solution u\u0302 exactly mirrors the behavior described for the known solution u. A further interesting aspect that can be noticed is that the level curves of the approximate solution u\u0302(\u00b7, t) overlap almost perfectly those of u(\u00b7, t), provided that t is not very large (see Fig. 4.2).\nWe have also noted that, at time t = 0, the approximate solution is basically equal to zero in a very tiny region around the origin (0, 0) of the xy-plane. This means that the said region is composed of \u201cnumerical zeros\u201d of the solution predicted at time t = 0, while we know that u(x, y, 0) = 0 if and only if (x, y) = (0, 0). However, this discrepancy is actually negligible, since the order of magnitude of u(x, y, 0) is not greater than 10\u22126 within the above region.\nTo assess the accuracy of our predictive method and the numerical convergence of the solution u\u0302 toward u in a more quanitative way, we now look at the time behavior of the L2-error \u2225u\u0302(\u00b7, t)\u2212 u(\u00b7, t)\u2225L2(\u2126) by considering the natural quantities\nE(T ) := sup t\u2208 (0,T )\n\u2225u\u0302(\u00b7, t)\u2212 u(\u00b7, t)\u22252L2(\u2126) (4.1)\nand\nErel(T ) := E(T )\nsup t\u2208 (0,T )\n\u2225u(\u00b7, t)\u22252L2(\u2126) . (4.2)\nPassing from Cartesian to polar coordinates, one can easily find that\n\u2225u(\u00b7, t)\u22252L2(\u2126) = \u222b\u222b \u2126 [ 1 2 (x2 + y2) + t ]2 dx dy = \u03c0 ( t2 + t 2 + 1 12 ) ,\nand therefore Erel(T ) =\n12 \u00b7 E(T ) \u03c0 (12T 2 + 6T + 1) .\nDuring our numerical experiments, we have estimated both E(T ) and Erel(T ) for\nT \u2208 {1, 10, 100, 200, 300, 400, 500}.\nThe results that we have obtained are shown in Table 1. The estimates of E(1) and E(10) are equal to 2.24 \u00d7 10\u22125 and 4.30 \u00d7 10\u22124 respectively, which is very satisfactory, especially considering that the order of magnitude of Erel(1) and Erel(10) is equal to 10\u22126. In order to get more accurate estimates for larger values of T , for every fixed T \u2265 100 we have used 2.1 \u00d7 T equispaced points (instead of the initial 21) to discretize the time interval [0, T ]. By doing so, we have observed that the variation of the estimate of E(T ) displays a monotonically increasing behavior, in accordance with the definition (4.1). However, even for 100 \u2264 T \u2264 500, the order of magnitude of Erel(T ) remains not greater than 10\u22126. Therefore, for this first test problem, we can conclude that our predictive method is indeed very accurate and efficient, on both a short and long time scale.\nNow, for 0 < \u03b5 \u2264 1 we consider the problem \u2202tv\u03b5 \u2212 div (H(\u2207v\u03b5) + \u03b5\u2207v\u03b5) = 1 in \u2126\u20321,2 := \u2126\u2032 \u00d7 (t1, t2), v\u03b5(x, y, t1) = 1 2 (x2 + y2) + t1 if (x, y) \u2208 \u2126\u2032,\nv\u03b5(x, y, t) = 1 2 (x2 + y2) + t if (x, y) \u2208 \u2202\u2126\u2032 \u2227 t \u2208 (t1, t2),\n(4.3)\nwhich is nothing but the approximating problem (2.5) associated with (P1). In what follows, we will denote the exact solution of (4.3) by u\u03b5, while the predicted solution will be denoted by u\u0302\u03b5. Throughout our tests, for 10\u22129 \u2264 \u03b5 \u2264 10\u22123, for \u2126\u2032 = \u2126 and for (t1, t2) = (0, T ), we have observed that the plot of the predicted solution u\u0302\u03b5(\u00b7, t) has the same shape and geometric properties as the graph of the exact solution u(\u00b7, t), for both short and long times (see, e.g. Figure 4.3). Moreover, we have seen that the time evolution of the approximate solution u\u0302\u03b5 reflects the behavior described for the solution u quite faithfully. In addition, the level curves of u\u0302\u03b5(\u00b7, t) perfectly overlap those of u(\u00b7, t), at least for not very long times t (see Fig. 4.4).\nLet us now assume that\n\u2126\u20321,2 = Q 1 2 (z0) := B 1 2 (0)\u00d7\n( 7\n4 , 2\n) ,\nwhere z0 = (0, 2) = (0, 0, 2). Then, the limit in (2.6) suggests that u\u0302\u03b5 should numerically converge to u as \u03b5 \u2198 0. To obtain a numerical evidence of such convergence, we have chosen \u2126\u2032 = B1/2(0) and (t1, t2) = (74 , 2) into (4.3) and looked at the time behavior of the L\n2-error \u2225u\u0302\u03b5(\u00b7, t)\u2212 u(\u00b7, t)\u2225L2(\u2126\u2032), by considering the quantities\nE\u03b5 := sup t\u2208 ( 7\n4 , 2)\n\u2225u\u0302\u03b5(\u00b7, t)\u2212 u(\u00b7, t)\u22252L2(B1/2(0))\nand Erel \u2261 Erel(\u03b5) :=\nE\u03b5 sup\nt\u2208 ( 7 4 , 2)\n\u2225u(\u00b7, t)\u22252L2(B1/2(0)) .\nSwitching from Cartesian to polar coordinates, one can easily find\n\u2225u(\u00b7, t)\u22252L2(B1/2(0)) = \u222b\u222b\nB 1 2 (0)\n[ 1\n2 (x2 + y2) + t\n]2 dx dy = \u03c0\n4\n( t2 + t\n8 +\n1\n192\n) ,\nfrom which it immediately follows that\nErel = 768E\u03b5 817 \u03c0 .\nDuring our experiments, we have estimated both E\u03b5 and Erel for \u03b5 \u2208 {10\u22129, 10\u22128, . . . , 10\u22123}. The results that we have obtained are shown in Table 2 and reveal that the predicted solution u\u0302\u03b5 seems to converge to u, although not too quickly."
        },
        {
            "heading": "4.2 Second test problem",
            "text": "Let \u03b1 > 0. As a second test problem we consider\n \u2202tv \u2212 div ( (|\u2207v| \u2212 1)+ \u2207v|\u2207v| ) = f in \u2126T , v(x, y, 0) = 0 if (x, y) \u2208 \u2126, v(x, y, t) = t if (x, y) \u2208 \u2202\u2126 \u2227 t \u2208 (0, T ),\n(P2)\nwhere \u2126 = {(x, y) \u2208 R2 : x2 + y2 < 1} again and\nf(x, y, t) :=\n{ (x2 + y2)\u03b1 if 2\u03b1 t (x2 + y2)\u03b1\u2212 1 2 \u2264 1,\n(x2 + y2)\u03b1 \u2212 4\u03b12t (x2 + y2)\u03b1\u22121 + 1\u221a x2+y2\nif 2\u03b1 t (x2 + y2)\u03b1\u2212 1 2 > 1.\nThe exact solution of problem (P2) is given by\nu(x, y, t) \u2261 u\u03b1(x, y, t) := t (x2 + y2)\u03b1.\nAt any fixed time t > 0, the shape and geometric properties of the graph of u(\u00b7, t) strongly depend on the value of the parameter \u03b1.\nIf \u03b1 = 1 2 , then the graph of u(\u00b7, t) is a cone whose vertex coincides with the origin (0, 0, 0) at any given positive time t. As time goes on, the cone in question gets narrower and narrower around the vertical axis. In this case, the plot of the approximate solution u\u0302(\u00b7, t) has the same shape as the graph of the exact solution u(\u00b7, t) for both short and long times t > 0, except\nnear the origin, where the tip of the cone appears to have been smoothed out (see Figure 4.5, center). However, this is not a surprise at all, since we already know that for t > 0 the function\n(x, y) \u2208 \u2126 7\u2192 t (x2 + y2) 1 2\nis not differentiable at the center (0, 0) of \u2126.\nWhen 0 < \u03b1 < 1 2 , the graph of u(\u00b7, t) is cusp-shaped for any fixed time t > 0, the origin now being a cusp for all positive times. In this case, a loss on convexity occurs, which is also observed in the plot of the predicted solution u\u0302(\u00b7, t) for all times t > 0 (see, e.g. Figure 4.5, left).\nLastly, when \u03b1 > 1 2 the graph of u(\u00b7, t) is no longer cusp-shaped and becomes increasingly narrow around the vertical axis as t increases. Furthermore, for any fixed t > 0 the exact solution u(\u00b7, t) is convex again and its graph gets flatter and flatter near the origin when \u03b1 >> 1 (see Figure 4.6).\nIn all three of the above cases, we have observed that the plot of the predicted solution u\u0302(\u00b7, t) has basically the same shape and geometric properties as the graph of the exact solution u(\u00b7, t), for both short and long times t. Moreover, also for problem (P2) we have verified that the time evolution of the approximate solution faithfully reflects the behavior described for the exact solution in all three previous cases. Therefore, we may conclude that \u03b1 = 1\n2 represents a critical value for the global behavior\nof both the exact and the predicted solution.\nLater, we have examined the contour lines of u\u0302\u03b1(\u00b7, t) for \u03b1 \u2208 {0.3, 0.5, 1.3, 5} and for not very large times t > 0. For every fixed \u03b1 \u2208 {0.3, 0.5, 1.3}, the level curves of u\u0302\u03b1(\u00b7, t) overlap quite well those of u\u03b1(\u00b7, t), with some small differences between one case and the other. More precisely, for each \u03b1 \u2208 {0.5, 1.3} the contour lines corresponding to the same level are almost indistinguishable, at least for not very long times t (see, for example, Figure 4.7, where t = 0.5). For \u03b1 = 5 and t > 0, we have also noted that the approximate solution is essentially equal to zero in a fairly large region \u03a3t around the origin (0, 0) of the xy-plane (see Fig. 4.8). As already said for problem (P1), this means that such region consists of numerical zeros of u\u03025(\u00b7, t), while for t > 0 we know that u5(x, y, t) = 0 if and only if (x, y) = (0, 0). However, this discrepancy is reasonably small for short times, since the order of magnitude of u5(x, y, t) does not exceed 10\u22122 within \u03a3t for 0 < t \u2264 10.\nTo evaluate in a more quantitative manner the accuracy of our method in solving problem (P2) and the numerical convergence of the solution u\u0302 toward u, we may now consider again the quantities (4.1) and (4.2). Passing from Cartesian to polar coordinates, we find\n\u2225u\u03b1(\u00b7, t)\u22252L2(\u2126) = t2 \u222b\u222b \u2126 (x2 + y2)2\u03b1 dx dy = \u03c0 t2 2\u03b1 + 1 ,\nso that we now have\nErel(T ) := E(T )\nsup t\u2208 (0,T )\n\u2225u\u03b1(\u00b7, t)\u22252L2(\u2126) =\n2\u03b1 + 1\n\u03c0 T 2 sup t\u2208 (0,T ) \u2225u\u0302\u03b1(\u00b7, t)\u2212 u\u03b1(\u00b7, t)\u22252L2(\u2126).\nDuring our experiments, we have estimated both E(T ) and Erel(T ) for \u03b1 \u2208 {0.3, 0.5, 1.3, 5} and T \u2208 {1, 10, 20, 40, 100}. The results that we have obtained are shown in Tables 3\u22126 and reveal that, for any fixed value of \u03b1, the variation of the estimate of E(T ) displays a monotonically increasing behavior, in accordance with (4.1). Furthermore, by analyzing the orders of magnitude of E(T ) and Erel(T ), we can conclude that our approach provides very accurate predictions, on both a short and long time scale."
        },
        {
            "heading": "4.3 Third test problem",
            "text": "We shall now consider the problem \u2202tv \u2212 div ( (|\u2207v| \u2212 1)+ \u2207v|\u2207v| ) = 1 in \u2126T , v(x, y, 0) = g(x, y) if (x, y) \u2208 \u2126, v(x, y, t) = h(x, y, t) if (x, y) \u2208 \u2202\u2126 \u2227 t \u2208 (0, T ),\n(P3)\nwhere \u2126 = (\u22121, 1)\u00d7 (\u22121, 1),\ng(x, y) :=\n{ 1 if \u2212 1 \u2264 x \u2264 0 \u2227 \u22121 \u2264 y \u2264 1,\n1\u2212 x if 0 < x \u2264 1 \u2227 \u22121 \u2264 y \u2264 1, and\nh(x, y, t) := \n1 + t if \u2212 1 \u2264 x \u2264 0 \u2227 y = \u22121, 1 + t if \u2212 1 \u2264 x \u2264 0 \u2227 y = 1, 1 + t if x = \u22121 \u2227 \u22121 \u2264 y \u2264 1, t if x = 1 \u2227 \u22121 \u2264 y \u2264 1,\n1\u2212 x+ t if 0 < x \u2264 1 \u2227 y = \u22121, 1\u2212 x+ t if 0 < x \u2264 1 \u2227 y = 1.\nThe exact solution of this problem is given by\nu(x, y, t) =\n{ 1 + t if \u2212 1 \u2264 x \u2264 0 \u2227 \u22121 \u2264 y \u2264 1,\n1\u2212 x+ t if 0 < x \u2264 1 \u2227 \u22121 \u2264 y \u2264 1. (4.4)\nTherefore, for any fixed time t \u2265 0, the graph of the function u(\u00b7, t) is given by the union of the horizontal region\nHt := {(x, y, 1 + t) : \u22121 \u2264 x \u2264 0, \u22121 \u2264 y \u2264 1} and the \u201cinclined plane\u201d\nIt := {(x, y, 1\u2212 x+ t) : 0 \u2264 x \u2264 1, \u22121 \u2264 y \u2264 1} . Let us denote by Gt := Ht \u222a It the graph of u(\u00b7, t). Then, as time goes on, the set Gt slides along an oriented vertical axis at a constant velocity, without deformation, since \u2202tu \u2261 1 over \u2126T (see Fig. 4.9, above).\nThe plot of the approximate solution u\u0302(\u00b7, t) roughly resembles that of u(\u00b7, t) for both short and long times t \u2265 0, except near the joining line Ht \u2229 It, where the graph of the solution appears to have been slightly smoothed (see Figure 4.9, below). However, this is not surprising at all, since we already know that, for any fixed t \u2265 0, the function u(\u00b7, t) : \u2126 \u2192 R defined by (4.4) is not differentiable at any point of the open segment S0 := {(x, y) \u2208 \u2126 : x = 0}. This fact also has repercussions in the comparison between the level curves of u(\u00b7, t) and u\u0302(\u00b7, t), whose superposition is far from being perfect on approaching the segment S0 from the right, i.e. for x > 0 (see Fig. 4.10).\nMoreover, also for problem (P3) we have verified that the time evolution of the predicted solution u\u0302 faithfully reflects the behavior described for the exact solution.\nTo assess in a more quantitative way the accuracy of our method in solving problem (P3) and the distance between the solutions u and u\u0302, we resort again to the quantities (4.1) and (4.2). Through an easy calculation, we get\n\u2225u(\u00b7, t)\u22252L2(\u2126) = 4 t2 + 6 t+ 8\n3 ,\nso that we now have\nErel(T ) := E(T )\nsup t\u2208 (0,T )\n\u2225u(\u00b7, t)\u22252L2(\u2126) =\n3\n12T 2 + 18T + 8 sup t\u2208 (0,T ) \u2225u\u0302(\u00b7, t)\u2212 u(\u00b7, t)\u22252L2(\u2126).\nProceeding as for the previous problems, we have estimated E(T ) and Erel(T ) for\nT \u2208 {1, 10, 100, 200, 300}.\nThe results that we have obtained are shown in Table 7 and reveal that the variation of the estimate of E(T ) displays again a monotonically increasing behavior, as expected from (4.1). However, by carefully analyzing the orders of magnitude of both E(T ) and Erel(T ), we can conclude that our method provides accurate results also in this case, in both short and longterm predictions."
        },
        {
            "heading": "4.4 Fourth test problem",
            "text": "We now consider the problem \u2202tv \u2212 div ( (|\u2207v| \u2212 1)+ \u2207v|\u2207v| ) = 1 in \u2126T , v(x, y, z, 0) = 1 2 (x2 + y2 + z2) if (x, y, z) \u2208 \u2126,\nv(x, y, z, t) = 1 2 + t if (x, y, z) \u2208 \u2202\u2126 \u2227 t \u2208 (0, T ),\n(P4)\nwhere \u2126 = {(x, y, z) \u2208 R3 : x2 + y2 + z2 < 1}. This problem is the 3-dimensional version of problem (P1) and its exact solution is given by\nu(x, y, z, t) = 1\n2 (x2 + y2 + z2) + t.\nTo assess the accuracy of our method in solving problem (P4) and the distance between the predicted solution u\u0302 and the exact solution u, we confined ourselves to considering the quantities (4.1) and (4.2). Passing from Cartesian to spherical coordinates, one can easily find that\n\u2225u(\u00b7, t)\u22252L2(\u2126) = \u222b\u222b\u222b\n\u2126\n[ 1\n2 (x2 + y2 + z2) + t\n]2 dx dy dz = \u03c0 ( 4\n3 t2 +\n4 5 t+ 1 7\n) ,\nand therefore\nErel(T ) := E(T )\nsup t\u2208 (0,T )\n\u2225u(\u00b7, t)\u22252L2(\u2126) =\n105\n\u03c0 (140T 2 + 84T + 15) sup t\u2208 (0,T ) \u2225u\u0302(\u00b7, t)\u2212 u(\u00b7, t)\u22252L2(\u2126).\nProceeding as for problem (P1), we have estimated both E(T ) and Erel(T ) for\nT \u2208 {1, 10, 20, 30, 40, 100}.\nThe results that we have obtained are shown in Table 8 and reveal that the variation of the estimate of E(T ) displays a monotonically increasing behavior, in accordance with the definition (4.1). However, for every T \u2264 100 the order of magnitude of Erel(T ) is not greater than 10\u22125. Therefore, we can conclude that our predictive method is very accurate and efficient in this case, on both a short and long time scale."
        },
        {
            "heading": "4.5 Fifth test problem",
            "text": "Let \u03b1 > 0 and \u03c9 = 2\u03b1 (2\u03b1 + 1). The last problem that we consider is\n \u2202tv \u2212 div ( (|\u2207v| \u2212 1)+ \u2207v|\u2207v| ) = f in \u2126T , v(x, y, z, 0) = 0 if (x, y, z) \u2208 \u2126, v(x, y, z, t) = t if (x, y, z) \u2208 \u2202\u2126 \u2227 t \u2208 (0, T ),\n(P5)\nwhere \u2126 = {(x, y, z) \u2208 R3 : x2 + y2 + z2 < 1} and\nf(x, y, z, t) :=\n{ (x2 + y2 + z2)\u03b1 if 2\u03b1 t (x2 + y2 + z2)\u03b1\u2212 1 2 \u2264 1,\n(x2 + y2 + z2)\u03b1\u22121(x2 + y2 + z2 \u2212 \u03c9 t) + 2\u221a x2+y2+z2 if 2\u03b1 t (x2 + y2 + z2)\u03b1\u2212 1 2 > 1.\nThis problem is nothing but the 3-dimensional version of (P2) and its exact solution is given by\nu(x, y, z, t) \u2261 u\u03b1(x, y, z, t) := t (x2 + y2 + z2)\u03b1.\nTo evaluate the accuracy of our method in solving problem (P5) and the distance between the approximate solution u\u0302 and the exact solution u, we limited ourselves to estimating the quantities (4.1) and (4.2). Switching from Cartesian to spherical coordinates, one can easily obtain\n\u2225u\u03b1(\u00b7, t)\u22252L2(\u2126) = t2 \u222b\u222b\u222b\n\u2126\n(x2 + y2 + z2)2\u03b1 dx dy dz = 4\u03c0 t2\n4\u03b1 + 3 ,\nfrom which it immediately follows that\nErel(T ) = 4\u03b1 + 3\n4\u03c0 T 2 sup t\u2208 (0,T ) \u2225u\u0302(\u00b7, t)\u2212 u(\u00b7, t)\u22252L2(\u2126).\nProceeding as for problem (P2), we have estimated E(T ) and Erel(T ) for \u03b1 \u2208 {0.3, 0.5, 1.3, 5} and T \u2208 {1, 10, 20, 40, 100}. The results that have been obtained are shown in Tables 9\u221212 and reveal that, for any fixed value of \u03b1, the variation of the estimate of E(T ) is again monotonically increasing, in accordance with (4.1). However, by carefully analyzing the orders of magnitude of both E(T ) and Erel(T ), we can deduce that our method provides accurate solutions also in this case, in both short and long-term predictions."
        },
        {
            "heading": "5 Conclusions",
            "text": "In this paper, we have explored the ability of PINNs to accurately predict the solutions of some strongly degenerate parabolic problems arising in gas filtration through porous media. Since there are no general methods for finding analytical solutions to such problems, it is\nessential to use efficient and accurate numerical methods. For the test problems discussed here, whose exact solutions are fortunately known, we have compared the plots of the predicted solutions with those of the analytical solutions. Moreover, to evaluate the accuracy of our predictive method in a purely quantitative way, we have also analyzed the error trends over time. The proposed approach provides accurate results in line with expectations, at least in short-term predictions. However, some issues remain open, such as how to obtain fully reliable plots for the predicted solution when the exact (unknown) one is not differentiable somewhere, and how to reduce or eliminate some slight discrepancies between the contour lines of the predicted solution and those of the analytical solution in the case n = 2.\nTo the best of our knowledge, this is one of the first papers demonstrating the effectiveness of the PINN framework for solving strongly degenerate parabolic problems with asymptotic structure of Laplacian type.\nAcknowledgements. This work has been supported by the following projects:\n\u2022 The Programma Operativo Nazionale Ricerca e Innovazione 2014-2020 (CCI2014IT16M2OP005) Dottorati e contratti di ricerche su tematiche dell\u2019innovazione XXXVII Ciclo, code DOT1318347, CUP E65F21003980003.\n\u2022 PNRR Centro Nazionale HPC, Big Data e Quantum Computing, (CN_00000013)(CUP: E63C22000980007), under the NRRP MUR program funded by the NextGenerationEU.\n\u2022 P. Ambrosio has been partially supported by the INdAM\u2212GNAMPA 2023 Project \u201cRisultati di regolarit\u00e0 per PDEs in spazi di funzione non-standard\u201d (CUP_E53C22001930001).\nS. Cuomo also acknowledges GNCS-INdAM and the UMI-TAA, UMI-AI research groups."
        }
    ],
    "title": "A physics-informed deep learning approach for solving strongly degenerate parabolic problems",
    "year": 2023
}