{
    "abstractText": "COPYRIGHT \u00a9 2023 Qiu, Huang, Zhang and Wang. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. A novel multidimensional uncalibration method applied to six-axis manipulators",
    "authors": [
        {
            "affiliations": [],
            "name": "Alois C. Knoll"
        },
        {
            "affiliations": [],
            "name": "Yingbai Hu"
        },
        {
            "affiliations": [],
            "name": "Haitao Qiu"
        },
        {
            "affiliations": [],
            "name": "Dan Huang"
        },
        {
            "affiliations": [],
            "name": "Bo Zhang"
        },
        {
            "affiliations": [],
            "name": "Ming Wang"
        }
    ],
    "id": "SP:f02acc9946f11191d1764e0b6e7717e7a842a6d4",
    "references": [
        {
            "authors": [
                "H. Cao",
                "G. Chen",
                "Z. Li",
                "Q. Feng",
                "J. Lin",
                "A. Knoll"
            ],
            "title": "Efficient grasp detection network with gaussian-based grasp representation for robotic manipulation",
            "venue": "IEEE ASME Trans. Mech. doi: 10.1109/TMECH.2022.3224314",
            "year": 2022
        },
        {
            "authors": [
                "H. Cao",
                "G. Chen",
                "Z. Li",
                "Q. Feng",
                "J. Lin",
                "A. Knoll"
            ],
            "title": "NeuroGrasp: multimodal neural network with euler region regression for neuromorphic vision-based grasp pose estimation",
            "venue": "IEEE Trans. Instrument. Measure",
            "year": 2022
        },
        {
            "authors": [
                "H. Cao",
                "G. Chen",
                "J. Xia",
                "G. Zhuang",
                "A. Knoll"
            ],
            "title": "Fusion-based feature attention gate component for vehicle detection based on event camera",
            "venue": "IEEE Sensors J",
            "year": 2021
        },
        {
            "authors": [
                "Y. Chang",
                "L. Li",
                "Y. Wang",
                "K. You"
            ],
            "title": "Toward fast convergence and calibration-free visual servoing control: a new image based uncalibrated finite time control scheme",
            "venue": "IEEE Access",
            "year": 2020
        },
        {
            "authors": [
                "G. Chen",
                "H. Cao",
                "J. Conradt",
                "H. Tang",
                "F. Rohrbein",
                "A. Knoll"
            ],
            "title": "Event-based neuromorphic vision for autonomous driving: a paradigm shift for bioinspired visual sensing and perception",
            "venue": "IEEE Signal Process. Magazine",
            "year": 2020
        },
        {
            "authors": [
                "N.R. Gans"
            ],
            "title": "Performance tests for visual servo control systems, with application to partitioned approaches to visual servo control",
            "venue": "Int. J. Robot. Res",
            "year": 2003
        },
        {
            "authors": [
                "Q. Gao",
                "W. Xiao"
            ],
            "title": "Research on the Robot Uncalibrated Visual Servo Method Based on the Kalman Filter With Optimized Parameters",
            "year": 2021
        },
        {
            "authors": [
                "J. Gu",
                "W. Wang",
                "M. Zhu",
                "Y. Lv",
                "Q. Huo",
                "Z. Xu"
            ],
            "title": "Research on a technology of automatic assembly based on uncalibrated visual servo system,",
            "venue": "IEEE International Conference on Mechatronics and Automation (ICMA). IEEE",
            "year": 2018
        },
        {
            "authors": [
                "L. Haifeng",
                "L. Jingtai",
                "L. Yan",
                "Xiang L",
                "Lei S"
            ],
            "title": "Visual Servoing With an Uncalibrated Eye-in-Hand Camera. Technical Committee on Control Theory, Chinese Association of Automation (Beihang",
            "year": 2010
        },
        {
            "authors": [
                "M. Hao",
                "Z. Sun"
            ],
            "title": "Uncalibrated eye-in-hand visual servoing using recursive least squares,",
            "venue": "IEEE International Conference on Systems, Man and Cybernetics,",
            "year": 2007
        },
        {
            "authors": [
                "T. Hao",
                "H. Wang",
                "F. Xu",
                "J. Wang",
                "Y. Miao"
            ],
            "title": "Uncalibrated visual servoing for a planar two link rigid-flexible manipulator without joint-space-velocity measurement,",
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems,",
            "year": 2020
        },
        {
            "authors": [
                "K. Hosoda",
                "M. Asada"
            ],
            "title": "Versatile visual servoing without knowledge of true Jacobian. Intelligent robots and system",
            "venue": "Proceedings of the IEEE /RSJ/GI International Conference on IEEE,",
            "year": 1994
        },
        {
            "authors": [
                "H. Huang",
                "X. Bian",
                "F. Cai",
                "J. Li",
                "T. Jiang",
                "Z Zhang"
            ],
            "title": "A review on visual servoing for underwater vehicle manipulation systems automatic control and case study",
            "venue": "Ocean Eng",
            "year": 2022
        },
        {
            "authors": [
                "S. Hutchinson",
                "G.D. Hager",
                "P.I. Corke"
            ],
            "title": "A tutorial on visual servo control",
            "venue": "IEEE Trans. Robot Automat",
            "year": 1996
        },
        {
            "authors": [
                "S. Jianbo"
            ],
            "title": "Uncalibrated Robotic Hand-Eye Coordination of Full Degree-of-Freedoms Based on Fuzzy Neural NetWork",
            "year": 2004
        },
        {
            "authors": [
                "Z. Jingmei",
                "D. Pengfei",
                "Z. Tie"
            ],
            "title": "Positioning and grasping system design of industrial robot based on visual guidance",
            "venue": "Machine Design Res",
            "year": 2014
        },
        {
            "authors": [
                "M. Kang",
                "H. Chen",
                "J. Dong"
            ],
            "title": "Adaptive visual servoing with an uncalibrated camera using extreme learning machine and Q-leaning",
            "venue": "Neurocomputing 402,",
            "year": 2020
        },
        {
            "authors": [
                "Y.X. Li",
                "Z.Y. Mao",
                "L.F. Tian"
            ],
            "title": "Visual servoing of 4DOF using image moments and neural network",
            "venue": "Control Theory Appl",
            "year": 2009
        },
        {
            "authors": [
                "X. Longjiang",
                "S. Bingyu",
                "X. Dingyu",
                "X. Xinhe"
            ],
            "title": "Model independent uncallbration visual servo control",
            "venue": "Robot",
            "year": 2003
        },
        {
            "authors": [
                "E. Malis"
            ],
            "title": "Visual servoing invarant to changes in camera-intrinsic parameters",
            "venue": "IEEE Trans. Robot. Automat",
            "year": 2004
        },
        {
            "authors": [
                "J.A. Piepmeier"
            ],
            "title": "Experimental results for uncalibrated eye-in-hand visual servoing,",
            "year": 2003
        },
        {
            "authors": [
                "J.A. Piepmeier",
                "H. Lipkin"
            ],
            "title": "Uncalibrated eye-in-hand visual servoing",
            "venue": "Int. J. Robot. Res",
            "year": 2003
        },
        {
            "authors": [
                "A.A.I. Samad",
                "M.Z. Haq"
            ],
            "title": "Visual Servoing Using Modular MRAC Architecture",
            "year": 2016
        },
        {
            "authors": [
                "R. Singh",
                "R.M. Voyles",
                "D. Littau",
                "N.P. Papanikolopoulos"
            ],
            "title": "Grasping real objects using virtual images,",
            "year": 1998
        },
        {
            "authors": [
                "W. Wu",
                "H. Su",
                "Z. Gou"
            ],
            "title": "Research on precision motion control of micro-motion platform based on uncalibrated visual servo,",
            "venue": "4th International Conference on Control and Robotics (ICCR), Guangzhou,",
            "year": 2022
        },
        {
            "authors": [
                "B.H. Yoshimi",
                "P.K. Allen"
            ],
            "title": "Alignment using an uncalibrated camera system",
            "venue": "IEEE Trans. Robot. Automat",
            "year": 1995
        },
        {
            "authors": [
                "D. Yuhan",
                "H. Lisha",
                "L. Shunlei"
            ],
            "title": "Research on computer vision enhancement in intelligent robot based on machine learning and deep learning.Neural",
            "year": 2021
        },
        {
            "authors": [
                "Y. Zaien",
                "P. Xueliang",
                "L. Zhengyang",
                "J. Yi",
                "C. Shenglong"
            ],
            "title": "The simulation and reconstruction of the complex robot trajectories based on visual tracking",
            "venue": "Machine Design Res",
            "year": 2014
        },
        {
            "authors": [
                "K. Zhang",
                "X. Yang",
                "J. Wang",
                "S. Song",
                "M.Q.H. Meng"
            ],
            "title": "Eye-in-hand uncalibrated visual servoing of concentric tube robot,",
            "venue": "IEEE International Conference on Real-time Computing and Robotics (RCAR). IEEE",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "TYPE Original Research PUBLISHED 14 July 2023 DOI 10.3389/fnins.2023.1221740"
        },
        {
            "heading": "OPEN ACCESS",
            "text": ""
        },
        {
            "heading": "EDITED BY",
            "text": "Alois C. Knoll, Technical University of Munich, Germany\nREVIEWED BY Yingbai Hu, Technical University of Munich, Germany Wang Juan, South China University of Technology, China\n*CORRESPONDENCE Dan Huang\ndan78huang@163.com\nRECEIVED 12 May 2023 ACCEPTED 20 June 2023 PUBLISHED 14 July 2023"
        },
        {
            "heading": "CITATION",
            "text": "Qiu H, Huang D, Zhang B and Wang M (2023) A novel multidimensional uncalibration method applied to six-axis manipulators. Front. Neurosci. 17:1221740. doi: 10.3389/fnins.2023.1221740"
        },
        {
            "heading": "COPYRIGHT",
            "text": "\u00a9 2023 Qiu, Huang, Zhang and Wang. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\nA novel multidimensional uncalibration method applied to six-axis manipulators\nHaitao Qiu1, Dan Huang2*, Bo Zhang3 and Ming Wang3\n1School of Electric Power Engineering, South China University of Technology, Guangzhou, China, 2School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China, 3School of Mechanical Engineering, Ningxia University, Yinchuan, China\nThis study proposes a multidimensional uncalibrated technique for tracking and grasping dynamic targets by a robotic arm in the eye-in-hand mode. This method avoids complex and cumbersome calibration processes, enabling machine vision tasks to be adaptively applied in a variety of complex environments, which solved the problem of traditional calibration methods being unstable in complex environments. The specific method used in this study is first, in the eye-in-hand mode, the robotic arm moves along the x, y, and z axes in sequence, and images are taken before and after each movement. Thereafter, the image Jacobian matrix is calculated from the three (or more) sets of images collected. Finally, the robotic arm converts the target coordinates in the real-time captured images by the camera into coordinates in the robotic arm coordinate system through the image Jacobian matrix and performs real-time tracking. This study tests the dynamic quasi-Newton method for estimating the Jacobian matrix and optimizes the initialization coupling problem using the orthogonal moving method. This optimization scheme significantly shortens the iteration process, making the uncalibrated technology more fully applied in the field of dynamic object tracking. In addition, this study proposes a servo control algorithm with predictive compensation tomitigate or even eliminate the systematic error caused by time delay in dynamic target tracking in robot visual servo systems.\nKEYWORDS\nimage Jacobianmatrix, machine vision, uncalibrated visual servo, dynamic quasi-Newton algorithm, robot\n1. Introduction\nIn the 1960s, due to the development of robotics and computer technology, people began to study robots with visual functions, and in the 1980s, the concept of robot visual servo was proposed. In the following decades, robot visual servoing underwent rapid development. Visual servo control mainly inputs visual information provided by visual sensors into the control system, enabling the control system to process external information. Traditional robot visual servo systems are mostly implemented based on system model calibration technology (Gans, 2003; Huang et al., 2022), which mainly involves models such as camera models, robot models, and target object models. The camera model refers to the internal and external parameters of the camera; the robot model generally refers to the robot kinematics model; the target model mainly refers to the depth information from the target to the end of the robotic arm, as well as the pose and motion parameters of the target in a fixed coordinate system. In the traditional robot visual servo system, the first step is to complete the calibration of the camera and the calibration between the camera and the robot (Hutchinson et al., 1996) to obtain an accurate conversion matrix between the\nFrontiers inNeuroscience 01 frontiersin.org\nimage coordinate system and the robot coordinate system. Then, based on the calibrated transformation matrix, the coordinates of the target object in the image captured by the visual system are converted to obtain the pose of the robot in the coordinate system. Finally, the robot tracks, locates, and grasps the target object in the camera\u2019s field of view based on the converted coordinate information (Kang et al., 2020). Throughout the entire work process, the accuracy of the transformation matrix between the image coordinate system and the robot coordinate system is heavily dependent (Malis, 2004). The calibration work between the camera and the robot is extremely cumbersome, requiring data such as the internal and external parameters of the camera, the motion model of the robot model, and the position relationship between the camera and the fixed position of the robot. However, in practical applications, replacing the camera or camera lens, or loosening the installation position between the camera and the robot can cause deviation in the calibration results, requiring complex calibration work to be carried out again. The traditional calibration methods for robot visual servo systems make it difficult for them to operate in complex working environments, which is currently a bottleneck limiting the development of robot visual servo systems.\nTo break the bottleneck, researchers have begun to focus on studying the \u201ceye-in-hand\u201d structure visual servo control method for calculating the image Jacobian matrix without knowing system parameters. The robot visual servo system still needs to overcome many technical difficulties to be put into normal use in various complex production environments.\nThe development of uncalibrated technology between cameras and robots without knowing system parameters can be divided into multiple stages: 1. The robot visual servo system achieves precise positioning and grasping of static targets through uncalibrated technology; 2. the robot visual servo system achieves tracking and positioning of dynamic targets through uncalibrated technology; and 3. the robot visual servo system achieves practical production applications with low latency and high accuracy in complex environments.\nThe fundamental goal of implementing a robot visual servo system is to achieve precise positioning and grasping of static targets. Hosoda and Asada first proposed the exponential weighted recursive least squares method to obtain the Jacobian matrix. This method achieves servo tracking and positioning of stationary targets in an uncalibrated state, but there are still shortcomings in terms of system stability and accuracy of image feature extraction (Hosoda and Asada, 1994; Cao et al., 2022a,b). Yoshimi and Allen introduced an additional robotic arm to explore motion and observed corresponding changes in image features during each calculation cycle. Then, they combined the least square method to calculate the Jacobian matrix of the current image, achieving more accurate two-dimensional target tracking. However, this method is too cumbersome and lacks real-time performance, making it difficult to apply in practical work (Yoshimi and Allen, 1995). In addition, many researchers have obtained the image Jacobian matrix by converting the online estimation of the Jacobian matrix into system state observation (Jianbo, 2004) or recursive formula calculation (Longjiang et al.,\n2003) and tested the algorithm from four aspects: initial value, operating range, stability, and robustness. Simulation experiments have been conducted to verify the reliability of the algorithm (Hao and Sun, 2007). At this stage, it is possible to use robot visual servo systems for positioning and grasping static targets in industrial production applications that meet various requirements (Singh et al., 1998). Compared to traditional calibration methods (Jingmei et al., 2014), it avoids the tedious process of repeated calibration.\nWith the development of production technology, the function of only achieving precise positioning and grasping static targets no longer meets the production needs of enterprises. Therefore, Piepmeier proposed the Broyden method to estimate the image Jacobian matrix, thereby achieving tracking and positioning of moving targets. However, when the deviation of image features is large, the performance of the control system will decrease, even leading to control failure (Piepmeier and Lipkin, 2003). When the robot visual servo system tracks irregularlymoving targets (Haifeng et al., 2010), it is necessary to improve the real-time performance of the system (Zaien et al., 2014) and the convergence speed of the image Jacobian matrix (Chang et al., 2020). However, while ensuring the real-time performance of the system, it can also lead to problems such as slow recognition speed and low accuracy of the visual system during high-speed movement. Many researchers have combined BP neural networks and genetic algorithms (Samad and Haq, 2016; Chen et al., 2020; Yuhan et al., 2021;Wu et al., 2022) and applied them to real-time image processing in the visual system, improving the processing speed of the visual system, improving the processing speed of the visual system. In addition, it is necessary to improve the robustness of the robot\u2019s visual servo system (Li et al., 2009; Hao et al., 2020) to adapt to stable operation in various complex environments. For example, in the field of medical equipment, the robot servo system needs to operate absolutely accurately and stably (Piepmeier, 2003; Gu et al., 2018; Zhang et al., 2020), thus improving the robustness and anti-interference of the system is very important (Cao et al., 2021; Gao and Xiao, 2021).\nThis study researches the application background of tracking and trajectory coverage of irregular dynamic targets. First, an online estimation test of the dynamic quasi-Newtonian Jacobian matrix was conducted in the simulation system. After analyzing the simulation test results, the system initialization process was targeted and optimized, significantly improving the convergence speed of Jacobian matrix iteration. In addition, this study also proposes a predictive compensation Jacobian matrix PI control algorithm to solve the lag problem of the visual system in the dynamic tracking process, effectively improving the accuracy of the robot servo system in the dynamic tracking process.\nThe remainder of this article is structured as follows. In Section 2, a detailed introduction is given to the control system. This includes the hardware composition of the control system, theoretical deduction of uncalibrated technology, and an introduction to servo control algorithms. In Section 3, we present the experimental results and discuss them. These results include the iterative process for the proposed uncalibrated visual servo system and the optimized iterative process. In addition, a comparative analysis of the research and experimental data conducted in this study is also presented in Section 4.\nFrontiers inNeuroscience 02 frontiersin.org\nFIGURE 1 Bozhilin 6-axis robotic arm platform.\nFIGURE 2 Schematic diagram of the eye-in-hand model."
        },
        {
            "heading": "2. Control system",
            "text": ""
        },
        {
            "heading": "2.1. Operating platform",
            "text": "The robot uncalibrated servo technology reviewed in this study is based on the application of tracking and coating trajectories to moving targets. The technology analyzed in this study can be applied to different fields such as the application of mobile robots to building cracks and robot welding. The robot platform used in this study is a six-axis industrial robot independently developed by Bozhilin, as shown in Figure 1. A Daheng high-speed industrial camera is installed at the end of the robotic arm to collect image information within the working range of the robotic arm. The camera used needs to have a large field of view, as the target object cannot leave the camera\u2019s field of view during uncalibrated initialization; otherwise, it will cause the Jacobian matrix error to increase. The camera and robot are installed in the eye-in-hand mode, and the model diagram is shown in Figure 2."
        },
        {
            "heading": "2.2. Process of uncalibration",
            "text": "Uncalibration technology, such as traditional calibration techniques, is used to describe the relationship between the speed of robot end effectors and the rate of feature change in the image. Assuming a point P in three-dimensional space, based on the traditional camera pinhole imaging model as shown in Figure 3, it can be concluded that\n{\nxi = f zc xc yi = f zc yc\n(1)\nPc(xc, yc, zc) is the coordinate of point P in the camera coordinate system, Pw(xw, yw, zw) is the Cartesian coordinate of point P in the world coordinate system (robotic arm base coordinate system), PI(xi, yi) is the projection coordinate of point P in the camera plane coordinate system, and (ui, vi) is the pixel coordinate in the pixel plane coordinate system.\nThe relationship between the camera imaging plane coordinate\nPI(xi, yi) and the pixel plane coordinate (ui, vi) is\n{\nui = xi dx\n+ u0 vi = yi dy + v0 (2)\nIn the above equation, u0 and v0 are the pixel coordinates of the penetration point of the camera\u2019s optical axis in the pixel plane, while dx and dy represent the spatial distance represented by a single pixel in theX andY directions in the pixel plane, respectively.\nConvert the above equation into a matrix equation as follows:\nFrontiers inNeuroscience 03 frontiersin.org\nFIGURE 4 Framework diagram of the robot servo system.\nFIGURE 5 Simulation model of Puma560 Robot Arm Servo System.\n\n  ui vi 1\n\n  =\n\n \n1 dx\n0 u0 0 1\ndy v0\n0 0 1\n\n \n\n  xi yi 1\n\n  (3)\nAssuming that the focal length of the camera is f, under the ideal pinhole model of the eye-in-hand system, the conversion relationship between the camera coordinate system and the pixel coordinate system is\n[\nui vi\n]\n= f\nzc\n[\nxc yc\n]\n(4)\nAccording to the motion equation of the robot\u2019s end effector,\nwe have\nPc = c \u2217 Pc + Tc (5)   \n \nxc = zcwy + Tx \u2212 vizc f wz yc = uizc f wz \u2212 zcwx + Ty zc = vizc f wx \u2212 uizc f wy + Tz\n(6)\nConverting the above equation into a matrix equation, we\nobtain as follows:\n[\nu v\n]\n=\n\n\nf zc 0 \u2212 uizc \u2212 uivi f f 2+u2i f \u2212vi 0 \u2212 f zc \u2212 vi zc \u2212 f 2+V2i f uivi f ui\n\n \u00b7\n[\nTc\nc\n]\n(7)\nIn practical applications, it is impossible to obtain the transformation matrix between (ui, vi) and [T c, c]T by measuring\nFrontiers inNeuroscience 04 frontiersin.org\nFIGURE 6 Initial position of the servo system.\nFIGURE 7 Position of the servo system in the end.\neach variable in the above equation. Therefore, the variables in the matrix are considered unknown:\n[\nu v\n]\n=\n[\na11 a12 a13 a14 a15 a16 b11 b12 b13 b14 b15 b16\n]\n\u00b7\n\n       \nTx Ty Tz \u03c9x \u03c9y \u03c9z\n\n       \n(8)\nOn the six-axis robotic arm platform, a single feature pixel does not meet the dimensional requirements, so three feature points are taken and stacked up and down:\n\n        \n. u1 . v1 . u2 . v2 . u3 . v3           =          a11 a12 a13 a14 a15 a16 b11 b12 b13 b14 b15 b16 a21 a22 a23 a24 a25 a26 b21 b22 b23 b24 b25 b26 a31 a32 a33 a34 a35 a36 b31 b32 b33 b34 b35 b36          \u00b7          Tx Ty Tz \u03c9x \u03c9y \u03c9z         \n(9)\nFIGURE 8 Motion trajectory of feature points in the image plane.\nF\u0307 represents the rate of change of image features, J0 represents the Jacobian transformation matrix, and P\u0307 represents the motion vector of the robotic arm end effector. The above equation can be expressed as follows:\n. F = J0 . P (10)\nIn practical applications, we need to convert the two change\nrates . F of image features to obtain the motion vector . P of the robotic arm end effector, so we need to inverse the Jacobian matrix J = J0 \u22121.\n. P = J0 . F (11)\nIn application, two change rates of image features are obtained from two adjacent images, so discretization of equations is also required. In the process of high-frequency camera image retrieval, we assume that the Jacobian matrix of adjacent two frames of images remains approximately unchanged. The discrete equation can be obtained as follows:\nF(n+1) \u2248 F(n) + J(n) \u00b7 1P(n) (12) P(n+1) \u2248 P(n) + J(n) -1 \u00b7 1F(n) (13)\nJ = 1F \u00b7 1P-1 (14)\nDuring the initialization process of the robot visual servo system, there is a coupling relationship between multiple movements of the robot, which can lead to the irreversibility and solvability of the Jacobian matrix. In order to obtain a more accurate Jacobian matrix, this article optimized the initialization process of the robot visual servo system. Therefore, by standardizing the movement direction of the robotic arm during the initialization process, the obtained feature point set is naturally linearly uncorrelated by decomposing the movement of the robotic arm into independent movements of each degree of freedom [\nTx Ty Tz \u03c9x \u03c9y \u03c9z\n]\nduring the initialization\nprocess. When moving in the independent Tx direction, we get\nFrontiers inNeuroscience 05 frontiersin.org\n\n        . u1 . v1 . u2 . v2 . u3 . v3          =          a11 a12 a13 a14 a15 a16 b11 b12 b13 b14 b15 b16 a21 a22 a23 a24 a25 a26 b21 b22 b23 b24 b25 b26 a31 a32 a33 a34 a35 a36 b31 b32 b33 b34 b35 b36          .          Tx 0 0 0 0 0         \n(15) . F = Tx\n\n        a11 b11 a21 b21 a31 b31\n\n        + 0 \u2217\n\n        a12 b12 a22 b22 a32 b32\n\n        + 0 \u2217\n\n        a13 b13 a23 b23 a33 b33\n\n       \nFrontiers inNeuroscience 06 frontiersin.org\n+0 \u2217\n\n        a14 b14 a24 b24 a34 b34\n\n        + 0 \u2217\n\n        a15 b15 a25 b25 a35 b35\n\n        + 0 \u2217\n\n        a16 b16 a26 b26 a36 b36\n\n       \n(16)\nAfter completing the initialization of the image Jacobianmatrix, it is necessary to update and iterate the matrix in real time to ensure accuracy during the robot operation process. In the image plane, the difference between the actual feature and the expected feature is f (\u03b8 , t) = y(\u03b8 , t)\u2212 y\u2217, where \u03b8 is the joint angle and t is time. Taylor expansion is performed on the deviation function f (\u03b8 , t) and the radiation model is defined asm(\u03b8 , t).\nm(\u03b8 , t) = f (\u03b8k, tk)+ J(\u03b8 \u2212 \u03b8k)+ \u2202fk\n\u2202t (t \u2212 tk) (17)\nAt moment k-1, we get\nf (\u03b8k\u22121, tk\u22121) = m(\u03b8k\u22121, tk\u22121) = f (\u03b8k, tk)+ Jk(\u03b8k\u22121 \u2212 \u03b8k)+ \u2202fk \u2202t (tk\u22121 \u2212 tk)\n(18)\nThe iterative equation can be obtained as follows:\nJk = Jk\u22121 + (1fk \u2212 Jk\u221211\u03b8 \u2212\n\u2202fk \u2202t 1t)1\u03b8 t\n1\u03b8 t1\u03b8 (19)"
        },
        {
            "heading": "2.3. Servo control algorithm",
            "text": "The process of running a robot visual servo control system is as follows: first, the visual system captures images and processes them, and then the processed image information inputs into the robot controller to start the robot moving. There is a time delay between the visual system capturing images and the robot starting tomove, which can cause systematic errors in the robot\u2019s tracking of dynamic targets. Therefore, in the process of robot motion control, this study designs a Jacobian matrix PI control algorithm with predictive compensation to reduce systematic errors caused by the time lag.\nAssuming that the expected image feature of the moving target is f \u2217(u\u2217, v\u2217) and the actual feature of the robot pose after the image Jacobian matrix transformation is ft(ut , vt) the actual pose and expected pose feature error of the system are as follows:\ne(t) = f \u2217 \u2212 ft (20)\nIn order to improve the real-time performance of the system and ensure that the target motion speed is fast and can complete effective tracking tasks, a predictive compensation method is introduced into the Jacobian matrix control algorithm on the inverse Jacobian matrix visual servo control algorithm, and a Jacobian matrix PI control algorithm with predictive compensation is designed. We define the system image feature error as follows:\neh(t) = f d \u2212 f ht (21)\nIn the above equation, f ht is the current image feature, and f d is the expected image feature. The predicted compensation amount \u03be is defined as follows:\n\u03be = kVimage (22)\nVimage is the rate of change in image features, and k is the\ncompensation coefficient.\nIn the process of dynamic target tracking, in order to reduce system tracking error, the PI control algorithm is introduced into the inverse Jacobian matrix control algorithm, with a control amount of\nuh(n) = 1f h(n+ 1) = f h(n+ 1)\u2212 f h(n) (23)\nIn order to reduce the impact of system image processing time delay on the system, the compensation amount will be predicted \u03be bringing it into the control algorithm to obtain the final visual servo control algorithm:\nuh(n+ 1) = J(KPeh(n)+ KI\nn \u2211\ni=0\neh(n))+ kVimage (24)\nFrontiers inNeuroscience 07 frontiersin.org\nKP and KI represent the proportional and differential coefficients, while k represents the predictive compensation coefficient of the system, which is related to the rate of change of image features. As shown in Figure 4, the robot control system is combined with the visual system to form a closed-loop robot visual servo system."
        },
        {
            "heading": "3. Experimental results",
            "text": ""
        },
        {
            "heading": "3.1. Simulation test",
            "text": "To verify the correctness of the uncalibrated visual servo algorithm, a robotic arm model, a monocular camera model, and\na target object model were established in the simulation platform MATLAB by simulating real robotic arm servo experiments. A camera robotic arm model with \u201ceyes in hand\u201d was adopted, and the Jacobian online estimation algorithm using the dynamic quasi-Newton method was used for visual feedback. By using a visual controller, the control amount is calculated using image feature deviation to drive the end of the robotic arm to move toward the target. Finally, the effectiveness of the uncalibrated visual servo algorithm was verified through simulation experiments, providing a theoretical basis for practical development work.\nWe established a robotic armmodel, monocular camera model, and target object model in the simulation platform MATLAB. The robotic arm is a six-axis Puma560 robotic arm. The camera has a\nFrontiers inNeuroscience 08 frontiersin.org\nresolution of 1,024 \u2217 1,024, a focal length of 8mm, and is installed at the end of the robotic arm (eye in hand). The target object is three small balls located above the robotic arm.\nAt the initial moment, the end of the robotic arm undergoes six exploratory movements. As shown in Figure 5, it is a simulation model of the servo system. The robotic arm is Puma560, and the camera is installed at the end of the robotic arm in green. The three blue balls in the picture are the target objects. Robot movement generates displacement 1P0 at the end of the robotic arm and the displacement of feature points 1F0 within the image plane. The initial value of the Jacobian matrix is\nJ0 = 1F0 \u00b7 1P0 -1 (25)\nUsing the dynamic quasi-Newton method to update the Jacobian matrix, the update frequency of the robotic arm is set to 0.1\u20130.2mmpermovement until the pixel error of the image reaches the range."
        },
        {
            "heading": "3.2. Experimental results of the dynamic quasi-Newton method",
            "text": "The error of the robotic arm in this experiment after 20 iterations is 0.31. After 35 iterations, the error is 0.011. After 56 iterations, the error was 0.0001, and the final image coordinates of the small ball were 761.999661.999, 761.999412.0, and 212.0661.999, respectively. The initial expected pixel coordinates were 762662, 762412, and 212662.\nThe initial posture of the robotic arm servo system and the pixel coordinates of three small balls are shown in Figure 6. The posture and ball pixel coordinates at the end of the servo are shown in Figure 7. The motion trajectories of the feature points of three small balls in the image plane are shown in Figure 8. The error of the entire process (image error and robotic arm end pose error) varies with the number of cycles, as shown in Figure 9.\nFrontiers inNeuroscience 09 frontiersin.org\nFIGURE 12 Dynamic tracking error comparison."
        },
        {
            "heading": "3.3. Orthogonal initialization method test results",
            "text": "According to the simulation experiment results shown in Table 1, it can be seen that the uncalibrated system requires multiple iterations to achieve the specified accuracy. However, in actual production environments, there is no enough time for iterative optimization. Looking at the simulation results data, it was found that the Jacobian matrix obtained from the uncalibrated initialization of the original scheme had a significant error in conversion. Through analysis, it was found that during the initialization process, images before and after movement were obtained by moving the robotic arm. In this process, there is coupling in the movement of the manipulator, which will lead to an irreversible and unsolvable Jacobian matrix.\nTo make the multiple sets of image feature points obtained after the robotic arm moves linearly uncorrelated, it is necessary to decouple the collected feature point set. This will be an incredibly complex and cumbersome task. Therefore, by standardizing the movement direction of the robotic arm during the initialization process, the obtained feature point set is naturally linearly uncorrelated. The iterative process error data of the uncalibrated system after the decoupling optimization initialization process is shown in Table 2, and the error of the entire process varies with the number of cycles, as shown in Figure 10. In Figure 11, it can be seen that the iterative speed of the Jacobian matrix after decoupling optimization has been significantly improved. Faster iterative convergence speed can effectively improve the\nreal-time performance of robot visual servo systems during dynamic tracking.\nIn Figure 11, the vertical axis represents the error during the robot iteration process, and the horizontal axis represents the number of iterations. The update cycle for each iteration of the robot is not fixed. The iterative process includes camera shooting, image processing, and robot motion. Due to the different amount of information in each cycle, the iteration period will fluctuate between 20 and 30 ms."
        },
        {
            "heading": "3.4. Comparison of experimental results",
            "text": "The above simulation tests have verified the reliability of the dynamic quasi-Newton method and the iterative algorithm after decoupling optimization. Next, the two algorithms mentioned above and the servo control algorithm with predictive compensation will be tested on the robotic arm. During the testing process, the robot dynamically tracks the target ball moving on the conveyor belt. The tracking process error data is recorded by identifying the distance between the centroid position of the target ball in the photos captured by the camera during the tracking process and the laser point position vertically shot by the robot arm. The tracking error curves of the three algorithms are shown in Figure 12.\nFrom the tracking error curve in Figure 12, it can be observed that the iterative algorithm after decoupling optimization and the servo control algorithm with predictive compensation have a faster\nFrontiers inNeuroscience 10 frontiersin.org\nconvergence speed than the dynamic equal Newton method. The servo control algorithm with predictive compensation can further reduce the tracking error in the convergence state."
        },
        {
            "heading": "4. Conclusion",
            "text": "This study investigates the application of the dynamic equal Newton method, the iterative algorithm after decoupling optimization, and the servo control algorithm with predictive compensation in robot uncalibrated visual servo systems. However, due to the dynamic equal Newton method requiring multiple iterations to obtain an accurate Jacobian matrix, a decoupling optimization method for the initialization process was proposed by analyzing the entire process of the uncalibrated robot visual servo system. The iterative algorithm after decoupling optimization can effectively reduce the number of iterations and improve the convergence speed of the Jacobian matrix through simulation testing. Therefore, this algorithm has a high practical value in production applications.\nDue to the time lag that cannot be completely eliminated when moving from the visual system to the robot\u2019s active position information in the eye-in-handmode, this study proposes amethod called the servo control algorithm with predictive compensation to weaken or even eliminate the tracking error caused by the time lag. It showed a very significant effect on the experimental test results."
        },
        {
            "heading": "Data availability statement",
            "text": "The original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author."
        },
        {
            "heading": "Author contributions",
            "text": "HQ conducted theoretical research, algorithm design, and paper writing for the article. DH conducted simulation testing and built the framework of the robot visual servo system. BZ completed the collection and analysis of experimental data. MW has completed the optimization and revision of the paper content. All authors contributed to the article and approved the submitted version."
        },
        {
            "heading": "Funding",
            "text": "The study was supported by the Science and Technology\nPlanning Project of Guangzhou City (Grant No. 2023A04J1691)."
        },
        {
            "heading": "Conflict of interest",
            "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest."
        },
        {
            "heading": "Publisher\u2019s note",
            "text": "All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher."
        }
    ],
    "title": "A novel multidimensional uncalibration method applied to six-axis manipulators",
    "year": 2023
}