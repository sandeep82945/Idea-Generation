{
    "abstractText": "Patients resuscitated from cardiac arrest who enter a coma are at high risk of death. Forecasting neurological outcomes of these patients (i.e., the task of neurological prognostication) could help with treatment decisions: which patients are likely to awaken from their coma and should be kept on life-sustaining therapies, and which are so ill that they would unlikely benefit from treatment? In this paper, we propose, to the best of our knowledge, the first dynamic framework for neurological prognostication of post-cardiac-arrest comatose patients using EEG data: our framework makes predictions for a patient over time as more EEG data become available, and different training patients\u2019 available EEG time series could vary in length. Predictions themselves are phrased in terms of either time-to-event outcomes (time-to-awakening or time-to-death) or as the patient\u2019s probability of awakening or of dying across multiple time horizons (e.g., within the next 24, 48, or 72 hours). Our framework is based on using any dynamic survival analysis model that supports competing risks in the form of estimating patient-level cumulative incidence functions. We consider three competing risks as to what happens first to a patient: awakening, being withdrawn from life-sustaining therapies (and thus deterministically dying), or dying (by other causes). For some patients, we do not know which of these happened first since they were still in a coma when data collection stopped (i.e., their outcome is censored). Competing risks models readily accommodate such patients. We demonstrate our framework by benchmarking three existing dynamic survival analysis models that support competing risks on a real dataset of 922 post-cardiac-arrest coma patients. Our main experimental findings are that: (1) the classical Fine and Gray model which only uses a patient\u2019s static features and summary statistics from the patient\u2019s latest hour\u2019s worth of EEG data is highly competitive, achieving accuracy scores as high as the recently developed Dynamic-DeepHit model that uses substantially more of the patient\u2019s EEG data; and (2) in an ablation study, we show that our choice of modeling three competing risks results in a model that is at least as accurate while learning more information than simpler models (using two competing risks or a standard survival analysis setup with no competing risks). \u00a9 2023 X. Shen, J. Elmer & G.H. Chen. ar X iv :2 30 8. 11 64 5v 2 [ ee ss .S P] 1 D ec 2 02 3 Neurological Prognostication Using Dynamic Survival Analysis",
    "authors": [
        {
            "affiliations": [],
            "name": "Xiaobin Shen"
        },
        {
            "affiliations": [],
            "name": "Jonathan Elmer"
        },
        {
            "affiliations": [],
            "name": "George H. Chen"
        }
    ],
    "id": "SP:da54794178d210f89c1920a3ff06039991a95831",
    "references": [
        {
            "authors": [
                "Nicholas S Abend",
                "Dennis J Dlugos",
                "Cecil D Hahn",
                "Lawrence J Hirsch",
                "Susan T Herman"
            ],
            "title": "Use of EEG monitoring and management of non-convulsive seizures in critically ill patients: a survey of neurologists",
            "venue": "Neurocritical Care,",
            "year": 2010
        },
        {
            "authors": [
                "MM Admiraal",
                "LA Ramos",
                "S Delgado Olabarriaga",
                "HA Marquering",
                "J Horn",
                "AF van Rootselaar"
            ],
            "title": "Quantitative analysis of EEG reactivity for neurological prognostication after cardiac arrest",
            "venue": "Clinical Neurophysiology,",
            "year": 2021
        },
        {
            "authors": [
                "Paul Blanche",
                "Jean-Fran\u00e7ois Dartigues",
                "H\u00e9l\u00e8ne Jacqmin-Gadda"
            ],
            "title": "Estimating and comparing time-dependent areas under receiver operating characteristic curves for censored event times with competing risks",
            "venue": "Statistics in Medicine,",
            "year": 2013
        },
        {
            "authors": [
                "Aziza Byron-Alhassan",
                "Barbara Collins",
                "Marc Bedard",
                "Bonnie Quinlan",
                "Michel Le May",
                "Lloyd Duchesne",
                "Christina Osborne",
                "George Wells",
                "Andra M Smith",
                "Heather E Tulloch"
            ],
            "title": "Cognitive dysfunction after out-of-hospital cardiac arrest: Rate of impairment and clinical",
            "venue": "predictors. Resuscitation,",
            "year": 2021
        },
        {
            "authors": [
                "Maria De-Arteaga",
                "Jieshi Chen",
                "Peter Huggins",
                "Jonathan Elmer",
                "Gilles Clermont",
                "Artur Dubrawski"
            ],
            "title": "Predicting neurological recovery with canonical autocorrelation embeddings",
            "venue": "PLOS One,",
            "year": 2019
        },
        {
            "authors": [
                "Jonathan Elmer",
                "John J Gianakas",
                "Jon C Rittenberger",
                "Maria E Baldwin",
                "John Faro",
                "Cheryl Plummer",
                "Lori A Shutter",
                "Christina L Wassel",
                "Clifton W Callaway",
                "Anthony Fabio"
            ],
            "title": "Group-based trajectory modeling of suppression ratio after cardiac arrest",
            "venue": "Neurocritical Care,",
            "year": 2016
        },
        {
            "authors": [
                "Jason P Fine",
                "Robert J Gray"
            ],
            "title": "A proportional hazards model for the subdistribution of a competing risk",
            "venue": "Journal of the American Statistical Association,",
            "year": 1999
        },
        {
            "authors": [
                "Hans Friberg",
                "Tobias Cronberg",
                "Martin W D\u00fcnser",
                "Jacques Duranteau",
                "Janneke Horn",
                "Mauro Oddo"
            ],
            "title": "Survey on current practices for neurological prognostication after cardiac arrest",
            "year": 2015
        },
        {
            "authors": [
                "Romergryko G Geocadin",
                "Clifton W Callaway",
                "Ericka L Fink",
                "Eyal Golan",
                "David M Greer",
                "Nerissa U Ko",
                "Eddy Lang",
                "Daniel J Licht",
                "Bradley S Marino",
                "Norma D McNair"
            ],
            "title": "Standards for studies of neurological prognostication in comatose survivors of cardiac arrest: a scientific statement from the American Heart Association",
            "venue": "e517\u2013e542,",
            "year": 2019
        },
        {
            "authors": [
                "Hannah C Glass",
                "Courtney J Wusthoff",
                "Ren\u00e9e"
            ],
            "title": "A Shellhaas. Amplitude-integrated electro-encephalography: the child neurologist\u2019s perspective",
            "venue": "Journal of Child Neurology,",
            "year": 2013
        },
        {
            "authors": [
                "Robert J Gray"
            ],
            "title": "A class of K-sample tests for comparing the cumulative incidence of a competing risk",
            "venue": "The Annals of Statistics,",
            "year": 1988
        },
        {
            "authors": [
                "Frank E Harrell",
                "Robert M Califf",
                "David B Pryor",
                "Kerry L Lee",
                "Robert A Rosati"
            ],
            "title": "Evaluating the yield of medical tests",
            "venue": "Journal of the American Medical Association,",
            "year": 1982
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural Computation,",
            "year": 1997
        },
        {
            "authors": [
                "John D. Kalbfleisch",
                "Ross L. Prentice"
            ],
            "title": "The Statistical Analysis of Failure Time Data (2nd ed.)",
            "year": 2002
        },
        {
            "authors": [
                "Adina Najwa Kamarudin",
                "Trevor Cox",
                "Ruwanthi Kolamunnage-Dona"
            ],
            "title": "Time-dependent ROC curve analysis in medical research: current methods and applications",
            "venue": "BMC Medical Research Methodology,",
            "year": 2017
        },
        {
            "authors": [
                "Changhee Lee",
                "William Zame",
                "Jinsung Yoon",
                "Mihaela Van Der Schaar"
            ],
            "title": "DeepHit: A deep learning approach to survival analysis with competing risks",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Changhee Lee",
                "Jinsung Yoon",
                "Mihaela Van Der Schaar"
            ],
            "title": "Dynamic-DeepHit: A deep learning approach for dynamic survival analysis with competing risks based on longitudinal data",
            "venue": "IEEE Transactions on Biomedical Engineering,",
            "year": 2019
        },
        {
            "authors": [
                "Liang Li",
                "Tom Greene",
                "Bo Hu"
            ],
            "title": "A simple method to estimate the time-dependent receiver operating characteristic curve and the area under the curve with right censored data",
            "venue": "Statistical Methods in Medical Research,",
            "year": 2018
        },
        {
            "authors": [
                "EA Matthews",
                "J Magid-Bernstein",
                "A Presciutti",
                "A Rodriguez",
                "David Roh",
                "S Park",
                "J Claassen",
                "S Agarwal"
            ],
            "title": "Categorization of survival and death after cardiac arrest",
            "year": 2017
        },
        {
            "authors": [
                "Intae Moon",
                "Stefan Groha",
                "Alexander Gusev"
            ],
            "title": "SurvLatent ODE: A neural ODE based time-to-event model with competing risks for longitudinal data improves cancer-associated Venous Thromboembolism (VTE) prediction",
            "venue": "In Machine Learning for Healthcare,",
            "year": 2022
        },
        {
            "authors": [
                "Marion Moseby-Knappe",
                "Erik Westhall",
                "Sofia Backman",
                "Niklas Mattsson-Carlgren",
                "Irina Dragancea",
                "Anna Lybeck",
                "Hans Friberg",
                "Pascal Stammet",
                "Gisela Lilja",
                "Janneke Horn"
            ],
            "title": "Performance of a guideline-recommended algorithm for prognostication of poor neurological outcome after cardiac arrest",
            "venue": "Intensive Care Medicine,",
            "year": 2020
        },
        {
            "authors": [
                "Sang Hoon Oh",
                "Kyu Nam Park",
                "Young-Min Shon",
                "Young-Min Kim",
                "Han Joon Kim",
                "Chun Song Youn",
                "Soo Hyun Kim",
                "Seung Pill Choi",
                "Seok Chan Kim"
            ],
            "title": "Continuous amplitude-integrated electroencephalographic monitoring is a useful prognostic tool for hypothermia-treated cardiac arrest",
            "venue": "patients. Circulation,",
            "year": 2015
        },
        {
            "authors": [
                "Jon C Rittenberger",
                "Alexandra Popescu",
                "Richard P Brenner",
                "Francis X Guyette",
                "Clifton W Callaway"
            ],
            "title": "Frequency and timing of nonconvulsive status epilepticus in comatose post-cardiac arrest subjects treated with hypothermia",
            "venue": "Neurocritical Care,",
            "year": 2012
        },
        {
            "authors": [
                "Andrea O Rossetti",
                "Emmanuel Carrera",
                "Mauro Oddo"
            ],
            "title": "Early EEG correlates of neuronal injury after brain",
            "venue": "anoxia. Neurology,",
            "year": 2012
        },
        {
            "authors": [
                "Andrea O Rossetti",
                "Alejandro A Rabinstein",
                "Mauro Oddo"
            ],
            "title": "Neurological prognostication of outcome in patients in coma after cardiac arrest",
            "venue": "The Lancet Neurology,",
            "year": 2016
        },
        {
            "authors": [
                "Shubhranshu Shekhar",
                "Dhivya Eswaran",
                "Bryan Hooi",
                "Jonathan Elmer",
                "Christos Faloutsos",
                "Leman Akoglu"
            ],
            "title": "Benefit-aware early prediction of health outcomes on multivariate EEG time series",
            "venue": "Journal of Biomedical Informatics,",
            "year": 2023
        },
        {
            "authors": [
                "Helle S\u00f8holm",
                "Troels Wesenberg Kj\u00e6r",
                "Jesper Kjaergaard",
                "Tobias Cronberg",
                "John BroJeppesen",
                "Freddy K Lippert",
                "Lars K\u00f8ber",
                "Michael Wanscher",
                "Christian Hassager"
            ],
            "title": "Prognostic value of electroencephalography (EEG) after out-of-hospital cardiac arrest in successfully resuscitated patients",
            "year": 2014
        },
        {
            "authors": [
                "Eyad AL Thenayan",
                "Martin Savard",
                "Michael D Sharpe",
                "Loretta Norton",
                "Bryan Young"
            ],
            "title": "Electroencephalogram for prognosis after cardiac arrest",
            "venue": "Journal of Critical Care,",
            "year": 2010
        },
        {
            "authors": [
                "Niranjan Damera Venkata",
                "Chiranjib Bhattacharyya"
            ],
            "title": "When to intervene: Learning optimal intervention policies for critical events",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Erik Westhall",
                "Andrea O Rossetti",
                "Anne-Fleur van Rootselaar",
                "Troels Wesenberg Kjaer",
                "Janneke Horn",
                "Susann Ull\u00e9n",
                "Hans Friberg",
                "Niklas Nielsen",
                "Ingmar Ros\u00e9n",
                "Anders \u00c5neman"
            ],
            "title": "Standardized EEG interpretation accurately predicts prognosis after cardiac arrest",
            "year": 2016
        }
    ],
    "sections": [
        {
            "text": "\u00a9 2023 X. Shen, J. Elmer & G.H. Chen.\nar X\niv :2\n30 8.\n11 64\n5v 2\n[ ee\nss .S"
        },
        {
            "heading": "1. Introduction",
            "text": "Cardiac arrest is one of the leading causes of death and disability worldwide, resulting in approximately 300,000 to 450,000 deaths annually in the U.S. alone (NIH1, 2022) and a 43% reported rate of suffering from cognitive impairment (Byron-Alhassan et al., 2021). In this paper, we specifically focus on cardiac arrest patients who enter a coma and are admitted to the ICU, where they are placed on life-sustaining therapies (e.g., mechanical ventilation, cardiac support devices). Here, forecasting the neurological outcome of patients (i.e., the task of neurological prognostication) is important: if physicians perceive a patient to have poor neurological prognosis, then they may discontinue life-sustaining therapies for the patient, which deterministically ends the patient\u2019s life. Withdrawal of life-sustaining therapies accounts for 48% of all nonsurvivors, with 31% occurring in medically unstable patients and 17% in medically stable patients (Matthews et al., 2017). This raises the possibility that some patients may have survived if different decisions had been made regarding their care. Neurological prognostication, therefore, is crucial in determining the appropriate treatment plan for each patient.\nIn recent years, a promising direction for neurological prognostication has been to take advantage of brain activity measurements using electroencephalography (EEG) (Abend et al., 2010; Glass et al., 2013; Friberg et al., 2015). A number of recent studies have demonstrated these EEG signals are predictive of patients\u2019 neurological outcomes (e.g., Thenayan et al. 2010; Rittenberger et al. 2012; Rossetti et al. 2012; S\u00f8holm et al. 2014; Oh et al. 2015; Elmer et al. 2016b; Westhall et al. 2016; Shekhar et al. 2023). In this paper, we use both EEG data recorded over time and some patient characteristics collected upon hospital admission.\nWhile prognostication is essential, how it has been modeled in existing literature has some major limitations. First, binary classification has been the most common approach for modeling prognostication for post-cardiac arrest coma patients, where the two classes are poor neurological recovery or death (taken to be the \u201cpositive\u201d class) and favorable neurological recovery with certain levels of consciousness at hospital discharge (the \u201cnegative\u201d class) (e.g., Rossetti et al. 2016; Admiraal et al. 2021; Moseby-Knappe et al. 2020). The goal is to achieve a high true positive rate (TPR) with a false positive rate (FPR) close to 0 (see, for instance, the overview by Geocadin et al. (2019)). However, the existence of patients for whom life-sustaining therapies were withdrawn complicates this binary classification setup: including these particular patients in training data is problematic because we do not know what their neurological outcomes would have been if they had been kept on life-sustaining therapies (i.e., we do not know which of the two classes they belong to). Some existing studies simply exclude such patients (e.g., De-Arteaga et al. 2019). However, by excluding these patients, we ignore potentially useful information: these patients likely have characteristics that led to physicians withdrawing them from life-sustaining therapies.\nAnother major limitation of existing work is ignoring the dynamic nature of both the EEG signals as well as physicians\u2019 decision-making and only focusing on using EEG data of a fixed period of time to make a prediction at a single point in time. For example, De-Arteaga et al. (2019) only use EEG data between hours 34 to 36 after ICU admission to make a single prediction of the chance of favorable recovery for each patient; any patient with missing EEG data between hours 34 to 36 would be excluded, and EEG information outside of\n1. https://www.nhlbi.nih.gov/health/cardiac-arrest\nthis time window would not be used by their prediction model. Meanwhile, Admiraal et al. (2021) make a single prediction using EEG data 24 hours after cardiac arrest. In practice, physicians make decisions regarding treatment plans at different times after the patients have been admitted to the ICU (e.g., adjusting medications such as the dosage of vasopressors over time, or deciding whether to withdraw life-sustaining therapies), potentially using all information collected of the patient up until present time. To the best of our knowledge, no existing method has been developed for neurological prognostication of these coma patients that is truly dynamic, where the training patients\u2019 time series can vary in length, and where we make predictions at any point in time.\nOur main contribution in this paper is to propose a framework for neurological prognostication of post-cardiac-arrest coma patients that addresses both of the above major limitations. In particular, our framework is dynamic and directly models specific outcomes of interest as competing risks in the sense that one outcome happening (e.g., withdrawal from life-sustaining therapies) prevents other outcomes from happening (e.g., awakening, dying of other causes). Moreover, our framework allows for outcomes to be censored, meaning that for some patients, we do not get to see their eventual outcome since they were still in a coma by the time data collection stopped. That they were still alive at the end of data collection could be due to specific patient characteristics that make them more likely to be alive rather than to have been pulled off life-sustaining therapies or to have died of other causes.\nOur framework builds on a class of existing dynamic survival analysis models that support competing risks; we refer to this class of models as dynamic competing risks (DCR) models (we precisely define this class of models in Section 2). An example of such a model is Dynamic-DeepHit (Lee et al., 2019). Roughly, a DCR model predicts, for any test patient with measurements up to time t, the probability of the patient experiencing each of the different competing events at any time after time t.\nEven though we learn a DCR model with three competing risks for the neurological prognostication problem, at prediction time, one of these competing risks is often not of primary interest: whether a patient will be withdrawn from life-sustaining therapies. Even if we did predict who would be withdrawn from life-sustaining therapies, we would effectively be predicting how past decisions were made by physicians and not what the true neurological outcomes of these patients would have been. Ideally, predictions of the latter should be what we use to assist with treatment decisions. For this reason, we show how to derive a binary classifier from the DCR model\u2019s predicted output that aims to predict whether a patient will awaken or die (of causes aside from withdrawal from life-sustaining therapies) within any user-specified time horizon (Section 3.1). Conceptually, whereas some existing work on neurological prognostication excluded patients who were withdrawn from life-sustaining therapy altogether from their analysis (e.g., De-Arteaga et al. 2019), we are including such patients when training a DCR model, and only when using our classifier, we condition on (in a probabilistic sense) the test patient not being withdrawn from life-sustaining therapies in the future. Especially as this classifier is meant to help with decisions such as whether a patient should be withdrawn from life-sustaining therapies, a reasonable assumption is to condition on this event not happening yet. This binary classifier that we derive from the DCR model can classify variable-length input time series using any user-specified time horizon without needing to re-train the DCR model. We further develop a patient-specific heat map visualization for the classifier that is straightforward to interpret (Section 3.2).\nIn experiments on real data (cohort selection and other dataset details are in Section 4), we benchmark three DCR models to compare how accurate they are, and we also conduct an ablation study to show why our choice of modeling the competing risks setting with three competing risks is better than using two or one instead (Section 5). Note that the one competing risk setting reduces to a dynamic survival analysis setup without competing risks.\nGeneralizable Insights about Machine Learning in the Context of Healthcare\nFor neurological prognostication of post-cardiac-arrest coma patients using EEG data, our paper is, to the best of our knowledge, the first to consider a dynamic problem setup. We believe that we have framed this prognostication problem in a manner that is more useful for clinical decision support compared to how it has been framed in existing literature.\nAs our dynamic problem setup and accompanying evaluation metrics have not previously appeared in literature for our specific clinical application, our two main experimental findings are novel: (1) in benchmarking three DCR models, we find that the classical competing risks model by Fine and Gray (1999) that only uses static patient features and the summary information from the last hour of a patient\u2019s EEG data is highly competitive, achieving accuracy scores as high as the recently developed Dynamic-DeepHit model (Lee et al., 2019) that uses substantially more EEG data; and (2) our ablation study shows that our choice of modeling three competing risks results in a model that is at least as accurate while providing more information than a model that uses two competing risks or a dynamic survival analysis model without competing risks. These findings suggest that researchers working on the same clinical application may want to also consider modeling at least the three competing risks we consider (or even finer-grain versions of some of them, such as accounting for more causes of death), and also trying the classical Fine and Gray model as a baseline.\nFrom a technical standpoint, our paper does not introduce a new model. Instead, our paper demonstrates how to effectively use any existing DCR model to address a specific clinical problem. The novelty is thus in the application of existing DCR models and also in our proposal of a classifier (derived from a DCR model) and an accompanying heat map visualization for this classifier. The crucial insight of the classifier that we develop is to condition on a particular event\u2014an action taken by a physician that inevitably ends the patient\u2019s life\u2014not happening in the future of the patient because the output of the classifier is meant to help with deciding on whether to take this action (where a reasonable assumption is that we have not taken the action as doing so has a permanent consequence). We suspect that this same idea would be relevant in various other clinical problems."
        },
        {
            "heading": "2. Background",
            "text": "Our paper builds on a specific class of existing dynamic survival analysis models, which we refer to as dynamic competing risks (DCR) models. We review this class of models in Section 2.1, where we also state the dynamic problem setting that our framework uses. We briefly give a concrete example of a DCR model (Dynamic-DeepHit by Lee et al. (2019)) in Section 2.2. Note that throughout this paper, for any positive integer m, we frequently use the notation [m] := {1, 2, . . . ,m}. We typically use uppercase variables to refer to random variables whereas lowercase variables refer to constants, realized values of random variables, or dummy indices (e.g., training data indices)."
        },
        {
            "heading": "2.1. Dynamic Problem Setup and DCR Models",
            "text": "Training data We assume that we have a training dataset consisting of n patients. For each training patient i \u2208 [n], we observe a times series with a total of Li time steps, where at each time step, we observe d features. Specifically, we observe the feature vectors X (1) i , X (2) i , . . . , X (Li) i \u2208 Rd, where X (\u2113) i \u2208 Rd is the i-th patient\u2019s feature vector at time step \u2113 \u2208 [Li] (time steps are sorted chronologically, so time step Li is the last time step observed for training patient i). Moreover, time step \u2113 \u2208 [Li] happens at a time that is recorded as a real number T\n(\u2113) i \u2208 R, meaning that the amount of time that elapses between time steps \u2113\nand \u2113+ 1 is T (\u2113+1) i \u2212 T (\u2113) i . A common assumption is to set the initial time step\u2019s time to be T (1) i = 0. Note that for the d features that are tracked over time, it is possible that some always stay the same (e.g., age upon hospital admission). For ease of exposition, we do not introduce additional notation that separates static from time-varying features although separating these two types of features could be done in practice.\nAs the above notation suggests, patients\u2019 time series can vary in length (e.g., one patient could have EEG data recorded every second for 6 hours, whereas another could have EEG data recorded every second for 12 hours). For the real data we consider later, the time series are regularly sampled (i.e., the amount of time that elapses between consecutive time steps is the same) but in general, DCR models can handle irregularly sampled time series.\nIn terms of ground truth information, for each training patient i \u2208 [n], we assume that we observe two quantities:\n\u2022 (Event indicator) We observe which of k different competing events happened first to the i-th patient, or alternatively we could also observe that none of the competing events happened by the time training data collection stopped. This information is stored in the event indicator Ki \u2208 {0, 1, 2, . . . , k}. For example, in the neurological prognostication problem, we have k = 3 and the competing events are awakening (Ki = 1), dying of causes aside from withdrawal from life-sustaining therapies (Ki = 2), and withdrawal from life-sustaining therapies (Ki = 3). The special value of Ki = 0 means that by the time data collection stopped, none of the competing events happened. \u2022 (Event time) We also observe the time Yi \u2208 R for when the first competing event happened or, if none of them happened, then Yi is the time when data collection stopped for the i-th patient (i.e., the time of \u201ccensoring\u201d). Note that at any time step\n\u2113 \u2208 [Li], the time until the first competing event or censoring happens is Yi \u2212 T (\u2113)i . In summary, for training patient i \u2208 [n], we observe an event indicator Ki \u2208 {0, 1, . . . , k}, an event time Ti \u2208 R, and an input time series of feature vectors X(1)i , X (2) i , . . . , X (Li) i \u2208 Rd at corresponding times T (1) i , T (2) i , . . . , T (Li) i \u2208 R. As shorthand notation for referring to the\nentire observed time series, we write Zi := ( (X (1) i , X (2) i , . . . , X (Li) i ), (T (1) i , T (2) i , . . . , T (Li) i ) ) .\nWe model the training data (Z1,K1, Y1), . . . , (Zn,Kn, Yn) to be i.i.d. To formally state how each training point is generated, we define a few probability distributions: QT denotes an underlying probability distribution over variable-length time series, QE(Z) denotes an underlying conditional probability distribution over nonnegative time durations across all k competing events given a specific time series Z (i.e., a random sample from QE(Z) yields a vector in Rk where the j-th entry of the vector is a random time duration until competing event j \u2208 [k] happens), and QC(Z) denotes the underlying conditional probability\ndistribution over nonnegative time durations until censoring. Specifically, the i-th training point (Zi,Ki, Yi) is generated as follows:\n1. We sample time series Zi (with Li time steps and last time T (Li) i using our earlier\nnotation) from QT . 2. We sample the true nonnegative time durations (\u039ei,1,\u039ei,2, . . . ,\u039ei,k) from QE(Zi) (so\nthat \u039ei,1 is the time until the 1st competing event happens, \u039ei,2 is the time until the 2nd competing event happens, etc). 3. We sample the true nonnegative time duration \u039ei,0 (time until censoring) from a conditional distribution QC(Zi). 4. We set Ki := argminj=0,1,...,k \u039ei,j , and Yi := T (Li) i + \u039ei,Ki . Note that the competing events are \u201cexhaustive\u201d in the sense that with probability 1, either one of them happens or censoring happens.\nPrediction target We model a test patient\u2019s data using the same distributions that we introduced for training data. However, for the test patient, our goal will never be to predict whether the test patient is censored. In particular, we model a test patient with time series Z, event indicator K (always a value in {1, . . . , k}), and event time Y as follows:\n1. We sample time series Z = ( (X(1), . . . , X(L)), (T (1), . . . , T (L)) ) (using notation similar\nto that of training data) from QT . Note that Z has L time steps. 2. We sample the true nonnegative time durations (\u039e1,\u039e2, . . . ,\u039ek) from QE(Z). 3. We set K := argminj=1,...,k \u039ej , and Y := T (L) + \u039eK .\nEven though time series Z is generated so that it has L time steps, in how we set up the prediction task next, we do not observe all time steps immediately. Instead, we progressively observe more of Z over time, similar to what would happen in a real clinical context. In particular, we state our prediction task to depend on time t \u2208 R and use the random variable Z(\u2264t) to denote time series Z limited to information up until time t. Specifically, we aim to predict the so-called cumulative incidence function (CIF) of event j \u2208 [k], which is the probability of event j happening within time duration \u2206 \u2265 0 starting from time t \u2208 R, given a time series observed up until time t. Formally, we write the CIF as Fj(\u2206 | z, t) := P(Y \u2264 t+\u2206,K = j | Z(\u2264t) = z(\u2264t), Y > t) for \u2206 \u2265 0, (1) where t is the time that we are making a prediction at, and z is any specific realization of random variable Z (again, the superscript \u201c(\u2264t)\u201d restricts time to be up until t).\nNote that we have intentionally stated the CIF in the dynamic setting with variablelength time series, where we can make predictions at different points in time. The classical version of the CIF (Gray, 1988; Fine and Gray, 1999) is stated in the \u201cstatic\u201d setting without time series and can be viewed as a special case of the dynamic setup we have described, where all time series sampled from QT have exactly one time step, the recorded time of this first time step is always just taken to be 0, and we only ever evaluate equation (1) at t = 0. Separately, if the number of competing risks is equal to k = 1, then the entire setup we have described would instead be for dynamic survival analysis without competing risks. In fact, one could show that the static setting with one competing risk simply reduces to the classical right-censored survival analysis setup (e.g., see the random censoring setup described in Section 3.2 of the textbook by Kalbfleisch and Prentice (2002)).\nDynamic competing risks (DCR) models The class of DCR models that our framework for neurological prognostication builds on is any model that can predict CIFs as given in equation (1). For example, Dynamic-DeepHit (Lee et al., 2019) and SurvLatent ODE (Moon et al., 2022) are DCR models. Note that any classical competing risks model (e.g., Fine and Gray 1999) that does not actually handle variable-length time series could be made into a DCR model in a simple manner: simply only use the last time step\u2019s feature vector to predict. Some existing dynamic survival analysis models (such as DDRSA (Venkata and Bhattacharyya, 2022)) that were not originally developed to support competing events could be modified to estimate CIFs as well. To give a sense of how a DCR model works, we review Dynamic-DeepHit next. Note that we specifically review a DCR model that directly models variable-length time series without manual feature engineering or resorting to, for instance, only ever using the last time step of an input time series."
        },
        {
            "heading": "2.2. Example of a DCR Model: Dynamic-DeepHit",
            "text": "We provide an overview of Dynamic-DeepHit (Lee et al., 2019), deferring details to the original paper.2 Importantly, Dynamic-DeepHit discretizes possible values for time duration \u2206 in equation (1) into m unique values \u22061 < \u22062 < \u00b7 \u00b7 \u00b7 < \u2206m. We assume that \u22061 > 0 and that \u2206m is an upper bound on possible durations encountered across all events j \u2208 [k] (i.e., all k events happen within time duration \u2206m). In what follows, we regularly use the variables u, v \u2208 [m] to denote indices of the discretized values of \u2206. Dynamic-DeepHit estimates a probability mass function variant of the CIF for event j \u2208 [k] given by\nOj(\u2206u | z, t) := P(\u2206u\u22121 < Y \u2212 t \u2264 \u2206u,K = j | Z(\u2264t) = z(\u2264t), Y > t) for u \u2208 [m], (2) where we define \u22060 := 0 to handle the case when we plug in u = 1. Before explaining why the above function behaves like a probability mass function, we point out that one can readily verify that the CIF for event j from equation (1) satisfies the equality\nFj(\u2206u | z, t) = u\u2211\nv=1\nOj(\u2206v | z, t) for u \u2208 [m]. (3)\nThus, so long as we can estimate Oj(\u2206u | z, t) in equation (2), then we obtain an estimate of the CIF in equation (1) albeit only along a discrete time grid \u2206 \u2208 {\u22061, . . . ,\u2206m}.\nAs for why Oj(\u2206u | z, t) behaves like a probability mass function, note that k\u2211\nj=1\nm\u2211\nu=1\nOj(\u2206u | z, t) = k\u2211\nj=1\nFj(\u2206m | z, t) = 1, (4)\nwhere we have used equation (3) and the assumption that \u2206m is chosen as an upper bound on possible durations across all k competing events.\nWith this motivation, Dynamic-DeepHit models Oj(\u2206u | z, t) in equation (2) using a neural network. For the i-th training time series Zi := ( (X (1) i , . . . , X (Li) i ), (T (1) i , . . . , T (Li) i ) ) , we specifically estimate Oj(\u2206u | Zi, T (Li)i ) to be equal to Oi,j,u (with i \u2208 [n], j \u2208 [k], u \u2208 [m]), 2. Note that Lee et al. (2019) explicitly keep track of a separate vector per time step indicating which of the\nd features are missing. Instead of introducing notation for such a \u201cmissingness\u201d boolean vector, we can augment our original feature vector to include such missingness indicator variables.\nwhere Oi,j,u is shown on the right side of Figure 1; we collect all the Oi,j,u values specific to the i-th patient in the vector Oi \u2208 Rk\u00b7m. We compute Oi from Zi as follows:\n1. We first feed the input time series Zi into a user-specified RNN (with p output features per time step, where the choice of p is up to the user), where we slightly transform what the input looks like per time step. Specifically at time step \u2113 \u2208 [Li\u2212 1], the input to the RNN is taken to be (X\n(\u2113) i , T (\u2113+1) i \u2212 T (\u2113) i ), i.e., we provide both a feature vector\nand a time duration to get to the next time step. However, the last time step\u2019s feature vector X (Li) i is not used with the RNN (but will be used later). The RNN\u2019s output at time step \u2113 \u2208 [Li \u2212 1] is denoted as H(\u2113)i \u2208 Rp. This first step is shown on the left side of Figure 1.\n2. The second step is uses the variable-length time series (H (1) i , . . . ,H (Li\u22121) i ) and the last\ntime step\u2019s feature vector X (Li) i to compute a fixed-length summary vector Ci \u2208 Rp. To do this, we set Ci = \u2211Li\u22121 \u2113=1 a\u2113H (\u2113) i , where\n  a1 a2 ...\naLi\u22121\n  := softmax     fattention((H (1) i , X (Li) i )) fattention((H (2) i , X (Li) i )) ...\nfattention((H (Li\u22121) i , X (Li) i ))\n    \u2208 [0, 1]Li\u22121,\nand fattention is a user-specified feed-forward neural network, such as a multilayer perceptron (MLP), that outputs a single real number. This second step is shown in the middle of Figure 1. 3. We then combine vector Ci and the last time step\u2019s feature vector X (Li) i as the input\nto k different MLPs (one per competing risk) that each outputs m numbers, and the overall concatenated output is passed through a softmax layer to produce the final output Oi (the softmax enforces the constraint in equation (4)). Note that this third step corresponds to the original DeepHit model (Lee et al., 2018) that is meant for handling input data that are fixed-length feature vectors rather than variable-length time series. This step is shown on the right side of Figure 1.\nThere is one last neural network component that is not shown in Figure 1 as it is not used to compute the output vector Oi: Dynamic-DeepHit also requires that at time step \u2113 \u2208 [Li\u2212 1], the RNN on the left side of Figure 1 can output an estimate X\u0302\n(\u2113+1) i of the next time step\u2019s\nfeature vector X (\u2113+1) i . There are different ways to achieve this. For example, at time step \u2113 \u2208 [Li\u22121], we can feed H(\u2113)i (along with the time duration to get to the next time step) into a user-specified MLP fnext-time-step with d output features to produce the estimate X\u0302 (\u2113+1) i . Alternatively, for the RNN in Figure 1, we could choose it to be a type of RNN that already distinguishes between hidden state vectors and output state vectors (e.g., LSTMs (Hochreiter and Schmidhuber, 1997)), in which case we let the hidden state vectors be what we denoted as the H (\u2113) i variables, and we use the output state vectors to predict the next steps\u2019 feature vectors (the output state vector would need to consist of d entries).\nTraining The final loss used to train a Dynamic-DeepHit model is the sum of three terms, two of which make up the original DeepHit loss (a negative log likelihood term and a ranking\n<latexit sha1_base64=\"+2vVAjyBvdHz8JbbIi9aAIX73Ts=\">AAACFXicbZDLSgMxFIYz9VbrbdSlm2ARWmjLjHhbFty4cFGhN2jHIZNm2tBMZkgyQhn6Em58FTcuFHEruPNtTNtRtPVA4M/3n0Nyfi9iVCrL+jQyS8srq2vZ9dzG5tb2jrm715RhLDBp4JCFou0hSRjlpKGoYqQdCYICj5GWN7yc+K07IiQNeV2NIuIEqM+pTzFSGrlmqe3S26Rw7VJYhnZxXIL1b1Aca/RzK2vTNfNWxZoWXBR2KvIgrZprfnR7IY4DwhVmSMqObUXKSZBQFDMyznVjSSKEh6hPOlpyFBDpJNOtxvBIkx70Q6EPV3BKf08kKJByFHi6M0BqIOe9CfzP68TKv3ASyqNYEY5nD/kxgyqEk4hgjwqCFRtpgbCg+q8QD5BAWOkgczoEe37lRdE8rthnldObk3y1kMaRBQfgEBSADc5BFVyBGmgADO7BI3gGL8aD8WS8Gm+z1oyRzuyDP2W8fwER3puR</latexit>\nloss term), and the last term asks that each next feature vector estimate X\u0302 (\u2113+1) i is close to X (\u2113+1) i (using, for instance, squared Euclidean distance).\nPrediction At test time, we could feed any observed test time series (of arbitrarily nonzero length) as input to the neural network in Figure 1 to produce an estimate of the probability mass function of the CIF in equation (2) that we can then use to estimate the CIF with using equation (3). We could trivially accommodate the setting where we see more of a test time series over time since the neural network accepts a variable-length input time series."
        },
        {
            "heading": "3. Framework for Neurological Prognostication",
            "text": "Any DCR model could be applied to the problem of neurological prognostication for postcardiac-arrest coma patients. As stated in Section 2, we can take the number of competing risks to be k = 3 corresponding to awakening (K = 1), dying (not of withdrawal from life-sustaining therapies) (K = 2), or withdrawal from life-sustaining therapies (and thus dying as a result) (K = 3). A key goal of our framework is to help clinicians interpret the information contained in the CIFs (equation (1)) predicted by a DCR model.\nUsing the three competing risks stated above, we derive a binary probabilistic classifier from an already trained DCR model (Section 3.1). The resulting classifier can then be used to produce a patient-specific prediction heat map visualization that aims to be straightforward for a clinician to interpret (Section 3.2). Separately, standard binary classification evaluation metrics could be used for the derived classifier, which supplement survival analysis evaluation metrics that already exist for DCR models."
        },
        {
            "heading": "3.1. A Derived Binary Classifier",
            "text": "As discussed in Section 1, predicting whether a patient will be withdrawn from life-sustaining therapies is often not of primary interest since this is a human-made decision that deterministically ends a patient\u2019s life, and we do not actually know for sure whether the patient would have instead awakened or died of other causes in the ICU. For any test patient\u2019s time series up to time t, we now derive a binary probabilistic classifier that conditions on the event that the test patient is never withdrawn from life-sustaining therapies (we refer to this event as the \u201cnon-withdrawal event\u201d). As we aim to develop a decision support tool to help\nphysicians decide on whether to withdraw life-sustaining therapies, a reasonable assumption is that the patients are kept on these therapies, especially since withdrawal of these therapies has a permanent effect (in Section 6, we comment on whether this conditioning makes sense).\nAfter conditioning on the non-withdrawal event, we then compute the probabilities of the remaining two competing events happening within a time duration \u2206 > 0. This conditional probability can be computed as follows, reusing notation from Section 2:\nPawaken(\u2206 | z, t) := P(Y \u2264 t+\u2206, awaken\ufe37 \ufe38\ufe38 \ufe37 K = 1 |\nawaken or death (not by withdrawal from\nlife-sustaining therapies)\ufe37 \ufe38\ufe38 \ufe37 K \u2208 {1, 2} , Z(\u2264t) = z(\u2264t), Y > t)\n= P(Y \u2264 t+\u2206,K = 1 | Z(\u2264t) = z(\u2264t), Y > t)\nP(K \u2208 {1, 2} | Z(\u2264t) = z(\u2264t), Y > t)\n= P(Y \u2264 t+\u2206,K = 1 | Z(\u2264t) = z(\u2264t), Y > t)\nP(K = 1 | Z(\u2264t) = z(\u2264t), Y > t) + P(K = 2 | Z(\u2264t) = z(\u2264t), Y > t)\n= F1(\u2206 | z, t)\nF1(\u221e | z, t) + F2(\u221e | z, t) . (5)\nThus, if we have trained a DCR model that has an estimate F\u0302j(\u2206 | z, t) for each CIF Fj(\u2206 | z, t), then we can directly plug in these CIF estimates into the right-hand side above to yield the estimated conditional probability\nP\u0302awaken(\u2206 | z, t) := F\u03021(\u2206 | z, t)\nF\u03021(\u221e | z, t) + F\u03022(\u221e | z, t) . (6)\nWe could similarly estimate the probability for death (not by withdrawal from life-sustaining therapies) by\nP\u0302death (not withdrawal)(\u2206 | z, t) := F\u03022(\u2206 | z, t)\nF\u03021(\u221e | z, t) + F\u03022(\u221e | z, t) . (7)\nWe thus have a binary probabilistic classifier between the two classes \u201cawaken\u201d and \u201cdeath (not by withdrawal from life-sustaining therapies)\u201d defined for a specific time t and time duration \u2206: if the ratio P\u0302death (not withdrawal)(\u2206|z,t)\nP\u0302awaken(\u2206|z,t) is below a threshold value of 1, then we\npredict \u201cawaken\u201d. The threshold of 1 could of course be tuned (e.g., to achieve some desired tradeoff between TPR and FPR on some validation set). Note that it only makes sense to plug in times t that are at least the earliest time encountered in time series z.\nImportantly, the binary classifier we just described was derived using estimated CIFs. Existing DCR models like Dynamic-DeepHit estimate CIFs in a manner that would include patients of all three competing risks as well as those who were censored. In particular, we do not have to, for example, exclude patients who are censored or who were withdrawn from life-sustaining therapies from the analysis. Moreover, this classifier can be constructed for any time t after the earliest time in the observed test time series Z = z and for any choice of user-specified time duration \u2206 > 0, without any re-training of the underlying DCR model.\nTechnical remark The estimated probabilities P\u0302awaken(\u2206 | z, t) in equation (6) and P\u0302death (not withdrawal)(\u2206 | z, t) in equation (7) do not, in general, sum to 1. This is intentional. Again, each probability is derived based on equation (5), where the final denominator is the\nprobability that a patient with time series z up to time t experiences an eventual outcome that is either K = 1 or K = 2. From an interpretation standpoint, an appealing aspect of how P\u0302awaken(\u2206 | z, t) (and similarly P\u0302death (not withdrawal)(\u2206 | z, t)) is defined is as follows. For a fixed time t, consider two time durations \u2206 and \u2206\u2032, where \u2206 < \u2206\u2032 (for example, \u2206 = 24 hours and \u2206\u2032 = 48 hours). Then intuitively it makes sense that the probability of someone awakening within time duration \u2206\u2032 should be larger than the probability of someone awakening within the time duration \u2206, since \u2206\u2032 > \u2206. In other words, we would like P\u0302awaken(\u2206 | z, t) \u2264 P\u0302awaken(\u2206\u2032 | z, t). This property indeed holds for how we have defined equations (6) (and a similar result holds for P\u0302death (not withdrawal)). This property would not be guaranteed to hold if instead we had changed the denominators of equations (6) and (7) to F\u03021(\u2206 | z, t) + F\u03022(\u2206 | z, t), which would ensure that the probabilities sum to 1."
        },
        {
            "heading": "3.2. Patient-Specific Heat Map Visualization",
            "text": "We propose a heat map visualization specific to any patient that shows how the predicted probability of awakening (P\u0302awaken(\u2206 | z, t) in equation (6)) changes for the patient as we observe more of the patient\u2019s time series, as shown in the fourth column plot of each row in Figure 2. The experimental setup that led to this figure is explained in more detail in Section 5. For now, focusing on any one of the fourth-column heat maps of Figure 2, we have the horizontal axis correspond to the prediction time t while the vertical axis is the time duration \u2206. We specifically choose the \u2206\u2019s to be equivalent of the next 24 to 72 hours, which is of interest according to clinician feedback we have received. Using Patient 1 in Figure 2 as an example, we observe a drastic decrease in the probability of awakening starting at t = 9 across all \u2206 values evaluated."
        },
        {
            "heading": "4. Cohort",
            "text": "We examine proprietary hospital data collected in a single medical center from 2010 to 2019 (the specific medical center has been blinded for reviewing purposes). The dataset includes patients who suffered sudden cardiac arrest, were successfully resuscitated, and survived to hospital admission at the medical center. EEG is initiated and monitored for these patients continuously as a routine standard of care for several days after cardiac arrest. As stated in the previous sections, we focus on three outcomes: awakening from the coma, dying (not from withdrawal of life-sustaining therapies, such as from brain death or rearrest) and withdrawal from life-sustaining therapies (due to perceived poor neurological prognosis, leading to death). We remark that there is a fourth outcome that is possible but that we exclude from analysis: patients could be withdrawn from life-sustaining therapies for non-neurological reasons such as a do-not-resuscitate order. As our focus is on neurological prognostication, we ignore this outcome in which a decision is made disregarding neurological prognosis. Note that in this study, we only care about the first occurrence of the event that ceases the coma status of a patient, i.e. if a patient awakened at some point and then still died shortly afterward, we would only consider awakening as the outcome of the patient.\nDataset characteristics After excluding patients whose cause of death is withdrawal for non-neurological reasons, we have a dataset consisting of 922 patients. For the 922 patients, summary statistics of their characteristics and the time-to-event are shown in an appendix\n1 2 3 4 5 6 7 8 9 10 11 12 t\n0\n50\n100\n150\n200 EEG\naEEG Suppression Ratio\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 6\nawake death withdrawal\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 12\nawake death withdrawal\n1 2 3 4 5 6 7 8 9 10 11 12 t\n24 48 72 0. 14 4 0. 29 7\n0. 39\n7\n0. 14 5 0. 29 8 0. 39 8 0. 16 4 0. 33 3 0. 42 8 0. 14 5 0. 30 3 0. 39 3 0. 12 8 0. 28 5 0. 36 5 0. 14 5 0. 28 9 0. 37 5 0. 12 7 0. 27 5 0. 35 0. 08 3 0. 23 6 0. 29 0. 02 3 0. 08 2 0. 11 3 0. 00 5 0. 02 4 0. 04 0. 00 2 0. 01 3 0. 02 4 0. 00 2 0. 01 4 0. 02 5\nPawaken( z, t)\n0.1 0.2 0.3 0.4\n(a) Example Patient 1: died (not from withdrawal of life-sustaining therapies) at hour 17\n1 2 3 4 5 6 7 8 9 10 11 12 t\n0\n50\n100\n150\n200 EEG\naEEG Suppression Ratio\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 6\nawake death withdrawal\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 12\nawake death withdrawal\n1 2 3 4 5 6 7 8 9 10 11 12 t\n24 48 72 0. 00 9 0. 04 9\n0. 1\n0. 00 8 0. 04 5 0. 08 6 0. 01 0. 06 3 0. 10 9 0. 02 6 0. 13 8 0. 19 3 0. 02 5 0. 14 4 0. 19 0. 02 9 0. 12 9 0. 17 5 0. 03 6 0. 14 1 0. 18 7 0. 04 8 0. 16 6 0. 21 4 0. 05 6 0. 16 6 0. 20 7 0. 04 8 0. 15 7 0. 19 7 0. 06 3 0. 17 7 0. 21 6 0. 06 8 0. 18 6 0. 21 7\nPawaken( z, t)\n0.1 0.2 0.3 0.4\n(b) Example Patient 2: was still in a coma at hour 118\n1 2 3 4 5 6 7 8 9 10 11 12 t\n0\n50\n100\n150\n200 EEG\naEEG Suppression Ratio\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 6\nawake death withdrawal\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6 0.8 CIF Estimates at t = 12 awake death withdrawal\n1 2 3 4 5 6 7 8 9 10 11 12 t\n24 48 72 0. 18 1 0. 35 0. 45 4 0. 17 1 0. 33 1 0. 43 0. 16 6 0. 33 2 0. 42 2 0. 17 1 0. 33 6 0. 42 4 0. 15 7 0. 31 5 0. 39 4 0. 18 1 0. 33 5 0. 41 6 0. 20 5 0. 35 6 0. 45 7 0. 20 8 0. 36 1 0. 45 8 0. 23 0. 38 2 0. 48 2 0. 22 3 0. 36 6 0. 45 9 0. 22 1 0. 36 2 0. 45 1 0. 23 1 0. 37 0. 45\nPawaken( z, t)\n0.1 0.2 0.3 0.4\n(c) Example Patient 3: awakened at hour 54\n1 2 3 4 5 6 7 8 9 10 11 12 t\n0\n50\n100\n150\n200 EEG\naEEG Suppression Ratio\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 6\nawake death withdrawal\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 12\nawake death withdrawal\n1 2 3 4 5 6 7 8 9 10 11 12 t\n24 48 72\n0. 0 0. 00\n4 0. 01 5\n0. 0 0. 00\n4 0. 01 3\n0. 0 0. 00\n5 0. 01 5\n0. 00 1 0. 00 7 0. 01 8 0. 00 1 0. 00 9 0. 01 9 0. 00 1 0. 01 3 0. 02 6 0. 00 2 0. 01 3 0. 02 7 0. 00 1 0. 01 2 0. 02 5 0. 00 2 0. 01 1 0. 02 2 0. 00 1 0. 00 9 0. 01 8 0. 00 1 0. 00 8 0. 01 6 0. 00 1 0. 00 8 0. 01 7\nPawaken( z, t)\n0.1 0.2 0.3 0.4\n(d) Example Patient 4: died (not from withdrawal of life-sustaining therapies) at hour 71\nFigure 2: For each example patient (panels (a)-(d)), we show time series of two summary EEG features aEEG and suppression ratio (first column plot), estimated CIFs at hours t = 6 (second column plot) and t = 12 (third column plot), and our proposed heat map visualization (fourth column plot). Note that aEEG values for normal brain activity should be within a certain range (constantly being lower than 5 or higher than 25 is usually considered abnormal), and higher suppression ratio values are a sign of more severe dysfunction or injury.\n(Table A.1). Out of the 922 patients, 271 (29.4%) of them awakened at some point, 189 (20.5%) of them died (not from withdrawal from life-sustaining therapies), 432 (49.6%) of them died from withdrawal of life-sustaining therapies due to poor perceived neurological prognosis, and 30 (3.3%) of them were still in a coma when data collection stopped.\nEEG time series data Raw EEG waveform data, typically recorded at 256Hz from 22 electrodes distributed on the brain according to standard clinical practice, are processed using FDA-approved clinical software (https://www.persyst.com/) to quantify more than 2,500 clinically-understood features every second (e.g., amplitude, frequency decompositions, suppression ratio, etc). For ease of exposition, here we focus on 12 features (see Appendix A for details) that have been proven to be useful in this domain: suppression ratio and\namplitude-integrated EEG (aEEG) (Oh et al., 2015; Elmer et al., 2016a). We preprocess and downsample the raw second-by-second data to have one measurement (per feature) per hour in two steps: (1) For each of the 12 EEG features used in this study, we downsample the data by taking the average value of each consecutive non-overlapping block of 60 seconds to get a single value (i.e., we first downsample the data so that each time step corresponds to one minute). (2) We then further downsample the minute-resolution EEG signals so that each time step corresponds to an hour, and for each of the 12 EEG features, we take 6 summary statistics (minimum, maximum, mean, 25% percentile, median, and 75% percentile) as the final features to be used (i.e., for each time step corresponding to 1 hour, we end up with a total of 12 \u00d7 6 = 72 summary features). We remark that the data after downsampling still captures most of the variation from the raw data and does not have much impact on prediction accuracy. Downsampling is mainly to reduce computation time.\nNote that in how we curated the data, we only use at most 12 hours of EEG data per patient (so that if a patient has more than 12 hours worth of EEG data, we ignore the EEG data after 12 hours). This is a limitation of the dataset curation process that could be changed in future work. From a modeling perspective, DCR models could in principal use arbitrarily long EEG time series, subject to hardware memory constraints in practice.\nStatic features Upon hospital admission, a number of features are collected for the patient that we treat as static features, such as demographic information (e.g. age, gender), characteristics of the patient\u2019s initial cardiac arrest collapse (e.g., arrest location, initial arrest rhythm, category of the cardiac arrest), initial coma status, and medical history. A full list of the 43 static features we use can be found in Appendix A.\nIn summary, accounting for both the time-varying EEG features and the static features, we use a total of d = 72 + 43 = 115 final features per time step when we train a DCR model."
        },
        {
            "heading": "5. Experiments",
            "text": "In this section, we run experiments on the dataset described in the previous section using three DCR models: a classical competing risks model by Fine and Gray (1999) using only the last observed time step of each input time series (details are in Appendix B), DynamicDeepHit (Lee et al., 2019) and DDRSA (Venkata and Bhattacharyya, 2022). Also, note that the original DDRSA model by Venkata and Bhattacharyya (2022) does not support competing risks and we modify its network structure to accommodate competing risks (details are in Appendix C). For simplicity, we refer to the competing-risk-adapted version of DDRSA as DDRSA despite the modification we make. We specifically aim to:\n\u2022 (Section 5.1) examine how accurate these models using the standard survival analysis metric of concordance index (abbreviated c-index; this is a value between 0 and 1 where higher is better) (Harrell et al., 1982) as well as AUROC of binary classifiers derived using our approach in Section 3.1, \u2022 (Section 5.2) provide examples of patient-specific visualizations (time series of two summary EEG signals, estimated CIFs, and the heat map visualization we described in Section 3.2) \u2022 (Section 5.3) show that using a setup with fewer than the three competing risks we consider result in models that are not as good.\nExperimental setup We repeat the following basic experiment five times with different random training/validation/test splits of the data. For each experimental repeat, we randomly select 80% of the 922 patients to be in the training set and the remaining 20% in the testing set. For Dynamic-DeepHit and DDRSA, within the training set, a random 20% of the training points are held out as a validation set for hyperparameter tuning. The random splits are stratified as the preserve the fraction of data experiencing each event indicator value {0, 1, . . . , k}. The hyperparameter grid we use is given in Appendix D. Note that the Fine and Gray model has no hyperparameters."
        },
        {
            "heading": "5.1. Accuracy Benchmark in the Dynamic Problem Setup",
            "text": "Survival analysis accuracy metric To evaluate the accuracy of different competing risks models, we compute c-indices per competing risk at different prediction times t = 6, 12 and different time horizons \u2206 = 24, 48, 72; these are all in units of hours. For example, with the prediction time t = 6 and evaluation time \u2206 = 24, it means at hour 6 after ICU admission, we are comparing the model\u2019s predicted risk of different events occurring in the next 24 hours. The results for the models are shown in Table 1. From this table, we see that in terms of c-indices per event, no model is uniformly the best across all prediction times t and time durations \u2206, while DDRSA appears to have slightly lower accuracy scores compared to the other two models.\nBinary classification accuracy metric By using the binary classifier derived from a DCR model as described in Section 3.1, we can use binary classification evaluation metrics such as the area under the ROC curve (AUROC). After restricting the test set cohort to patients that we either observe awakening or death (not from withdrawal from life-sustaining therapies), we can compute the AUROC scores shown in Table 2. Here, note that the Fine and Gray model achieves mean AUROC scores that are higher than those of DynamicDeepHit across all values of t and \u2206 evaluated. Accounting for the standard deviations of the AUROC scores, the two models do have AUROCs that are quite close. Again, DDRSA seems to perform worse than the other two models in terms of AUROCs.\nWe can also plot the ROC curve at different t and \u2206 values. Specifically, we show the ROC at t = 6 and t = 12 with the estimated ratio of the probability of awakening and probability of death (not from withdrawal) within the next \u2206 = 24 hours in Figure 3, where we plot the x-axis on a log scale to focus on the low FPR regime. For example, we can see that at t = 12,\u2206 = 24, Dynamic-DeepHit reaches an average AUROC of 0.898 and an average TPR of 0.668 with a small FPR of 0.020. The ROC curves for a few other t and \u2206 values can be found in Appendix E."
        },
        {
            "heading": "5.2. Patient-Specific Visualizations",
            "text": "After we train a DCR model, we can easily derive the estimated CIF for different events at different prediction times (e.g., t = 6, 12), and the estimated conditional probability of awakening using equation (6). We focus on using the trained Dynamic-DeepHit to derive all the visualizations in this part as an illustrative example (the same sorts of visualizations could be made for the Fine and Gray model and DDRSA). In Figure 2, we display two summary EEG signals for four example patients, the estimated CIFs, and the heat map visualization we described in Section 3.2; each row/panel in the figure corresponds to one patient. Each entry in the heatmap is the estimated conditional probability of awakening occurring at different times (t = 1, 2, . . . , 12) for the different durations (\u2206 = 24, 48, 72). For the four patients shown:\n\u2022 (Figure 2(a)) Patient 1 died at hour 17 (not from withdrawal of life-sustaining therapies). We observe a drastic change in the patient\u2019s EEG signals before and after t = 6, which is reflected in the two sets of estimated CIFs at t = 6 and t = 12 with a higher estimated CIF of the \u201cawakening\u201d event given the first 6 hours of EEG data but a lower \u201cawakening\u201d CIF curve after the first 12 hours of EEG. \u2022 (Figure 2(b)) Patient 2 is still in a coma at hour 118. From the EEG signals of this patient, we can see that the probability of awakening is increasing gradually in the heat map (fourth column plot) as we go from t = 1 to t = 12. \u2022 (Figure 2(c)) Patient 3 awakened at hour 54, and we do observe good EEG signals (we briefly describe some common patterns considered \u201cgood\u201d or \u201cbad\u201d in the caption of Figure 2). In the heat map visualization, the predicted probability of awakening is high at all times. \u2022 (Figure 2(d)) Patient 4 died (not from withdrawal of life-sustaining therapies) at hour 71, and we did observe very poor EEG signals over the entire 12-hour period. In the heat map, the predicted probability of awakening is low at all entries.\nNote that the estimated CIF for withdrawal from life-sustaining therapies could be viewed as the model\u2019s prediction of how likely a physician (at least according to historical data) would make a decision to withdraw said therapies."
        },
        {
            "heading": "5.3. Ablation Study",
            "text": "We conduct an ablation study to show why including the three competing risks in how we framed the problem is better than had we used fewer competing risks. In particular, we repeat the same experiments as above but with only two competing risks (awakening and dying not by withdrawal from life-sustaining therapies), and a single event (awakening). For the purpose of this ablation study, we only focus on the Fine and Gray model and Dynamic-DeepHit as they achieved noticeably higher accuracy than DDRSA in our earlier experiments.\nIn the case when we only consider two competing risks, a patient with the outcome label of withdrawal from life-sustaining therapies would be viewed as being censored (along with those who stayed in a coma). Similarly, when we only model a single competing risk, patients with all other outcomes are viewed as being censored. The resulting c-indices are shown for the two-competing-risk case in Table 3 and for the one competing risk case in Table 4.\nBy comparing Tables 1 and 3, we see that c-indices for death (not by withdrawal of life-sustaining therapies) stay at a similar level for the Fine and Gray model considering the standard deviation interval when we model only two competing risks, while those of Dynamic-DeepHit are clearly higher when we model all three competing risks. While we do not observe a gain in the c-indices for the event of awakening when we move from the single risk setting to those of two or three competing risks, by incorporating more events, we are able to capture more information without decreasing the model\u2019s accuracy. For example, if we only trained the single competing risk model and if the patient is not likely to awaken from the coma, the model would not help us distinguish between any of the other possible outcomes of the patient.\nWe also derive the binary classifier under two competing risks. The resulting AUROC scores are shown in Table 5 and ROC plots at t = 6, 12,\u2206 = 24 in Figure 4. By comparing Tables 2 and 5, average AUROCs drop for both the Fine and Gray model and DynamicDeepHit when we change from three events to two events, showing that there is a benefit to including the event of withdrawal from life-sustaining therapies. By comparing Figures 3 and 4, focusing on the low FPR regime, we observe the TPRs for Dynamic-DeepHit stay at a similar level under the two event setting while those for the Fine and Gray model\nbecome very unstable, again, suggesting the benefit of including the event of withdrawal. The ROC curves under the two event setting for a few other t and \u2206 values can be found in Appendix G."
        },
        {
            "heading": "6. Discussion",
            "text": "Our paper proposes a dynamic formulation of the neurological prognostication problem for post-cardiac-arrest coma patients. The modeling solution we propose uses any existing DCR model and, using specific structure in clinical outcomes of our clinical application, derives a classifier from the DCR model that aims to be helpful to clinicians for decision support. We believe that our dynamic formulation better models the specific clinical problem we focus on compared to what has been proposed in existing literature.\nWe now discuss an alternative to our conditioning strategy in Section 3.1 that we believe is worth investigating in future work, and we also point out various other limitations.\nAn alternative solution for deriving a binary classifier In how we derived our binary classifier in Section 3.1, we conditioned on the event that the test patient never gets withdrawn from life-sustaining therapies (the \u201cnon-withdrawal event\u201d). Our classifier\nuses the probability of awakening and, separately, of dying both conditioned on the nonwithdrawal event. However, we have found that these conditional probabilities are not entirely straightforward to explain to practitioners. Part of the challenge is that it is unclear how conditioning on the non-withdrawal event should impact the probabilities estimated. Concretely, consider the probability of awakening. Prior to conditioning on the non-withdrawal event vs after conditioning on the event, it is unclear whether the probability of awakening should increase or decrease.\nFundamentally, two technical hurdles make reasoning about the non-withdrawal event difficult. First, we do not know what would have happened to patients withdrawn from life-sustaining therapies had they been kept on these therapies instead. Second, we do not know how \u201cgood\u201d past decisions on withdrawing life-sustaining therapies are. As an extreme example, suppose that 100% of patients who die from non-withdrawal causes are perfectly identified by physicians in advance that they would have no chance of awakening so they are pulled off life-sustaining therapies, and 100% of patients who would awaken are also perfectly identified by physicians so that they are kept on life-sustaining therapies. In this case, if we condition on the non-withdrawal event, then we would always just get that the conditional probability of awakening is 100%, so our binary classifier in Section 3.1 would not be useful. However, an alternative that would still be useful is to compute the probabilities of awakening and of dying (not of withdrawal from life-sustaining therapies) without conditioning on the non-withdrawal event. These probabilities would still be conditional probabilities since we would condition on the test patient\u2019s time series. However, we no longer condition on the non-withdrawal event. We now sketch an approach for computing these probabilities, which in turn leads to a binary classifier different from the one we derived in Section 3.1.\nTo begin with, let\u2019s consider the probability of awakening within time duration \u2206 for a patient with features observed until time t. We write this probability as\nP\u0303awaken(\u2206 | z, t) = P(earliest competing event that happens excluding withdrawal from life-sustaining\ntherapies is awakening, Y \u2264 t+\u2206|Z(\u2264t) = z(\u2264t), Y > t) = P(earliest competing event that happens is awakening, Y \u2264 t+\u2206|Z(\u2264t) = z(\u2264t), Y > t) + P(earliest competing event that happens is withdrawal from life-sustaining\ntherapies followed by awakening, Y \u2264 t+\u2206|Z(\u2264t) = z(\u2264t), Y > t). On the right-hand side above, the first term is just the CIF for awakening (i.e., F1(\u2206 | z, t) using equation (1) and the same notation as in Section 3.1). As for the second term, we now make a major assumption that\nP(earliest competing event that happens is withdrawal from life-sustaining\ntherapies followed by awakening, Y \u2264 t+\u2206|Z(\u2264t) = z(\u2264t), Y > t) = F3(\u2206 | z, t)\u00d7 \u03b1,\nwhere \u03b1 \u2208 [0, 1] is a constant that does not depend on anything else, and as a reminder F3 is the CIF for withdrawal from life-sustaining therapies. The above assumption says that among patients whose earliest competing event is being withdrawn from life-sustaining therapies, each of them has probability \u03b1 (independent of everything else) of having their second earliest competing event be awakening (so that had withdrawal from life-sustaining\ntherapies not been an option, they would have awaken). In practice, we have no way of estimating \u03b1 but we can try different values for it. Putting together the pieces, we have\nP\u0303awaken(\u2206 | z, t) = F1(\u2206 | z, t) + F3(\u2206 | z, t)\u00d7 \u03b1. (8) In Figure 5, we provide the heatmap visualization of the probability of awakening with \u03b1 \u2208 {0, 0.25, 0.5, 0.75, 1} for the same Example Patient 1 as in Figure 2. We can see when \u03b1 increases from zero to one, the estimation becomes more \u201coptimistic\u201d in terms of the probability of awakening being higher across different times t and durations \u2206.\nThe same logic can be used to derive the probability of dying (of causes aside from withdrawal from life-sustaining therapies) within duration \u2206; we can denote this probability as P\u0303death (not withdrawal)(\u2206 | z, t). Then we can derive a binary classifier in the same manner as how we derived the one in Section 3.1: e.g., we threshold on the ratio\nP\u0303death (not withdrawal)(\u2206|z,t) P\u0303awaken(\u2206|z,t)\nto decide on whether to predict between awakening or dying. At present, we do not yet fully understand when our proposed solution in Section 3.1 should be used in practice vs the one stated in this discussion section which makes the major assumption involving the unknown probability \u03b1 of patients withdrawn from lifesustaining therapies who would have awaken. Better understanding the pros and cons of these approaches would be interesting. Relaxing the factorization assumption involving the probability \u03b1 would also be an interesting future research direction.\nOther limitations At a high-level, our paper has proposed a framework in which to think about the neurological prognostication problem that works with any DCR model. However, at this point, we have not proposed a new DCR model and, as far as we know, there have simply not been many DCR models developed (where the model truly is using variable-length time series rather than how we set up the Fine and Gray baseline which actually only uses fixed-length feature vector inputs). Naturally, a future research direction would be the development of DCR models that are even more accurate than the ones we have tested, especially since for the accuracy metrics we use, state-of-the-art neural network DCR models do not appear to be significantly better than the classical Fine and Gray model that only uses the final time step\u2019s features (including static features).\nIn terms of evaluating the binary classifier, we simply use AUROC scores at different t,\u2206 with patients who we either observed awakening or death (not from the withdrawal of life-sustaining therapy), ignoring those who have been withdrawn or censored due to lost of follow-up, which could be biased. There are numerous work in the area of ROC analysis with the occurrence of censoring under time-dependent setting (e.g., Blanche et al. 2013; Kamarudin et al. 2017; Li et al. 2018), each with its own limitations. While it is not the\nfocus of our current work, we encourage future work to probe how to better evaluate the binary classifier.\nAnother limitation of our framework is that we only consider the first \u201chitting time\u201d of competing risks, i.e. the earliest event that happened. In reality, some patients may still experience unfavorable outcomes after awakening, and it could be important to try to predict when this happens. One simple approach would be to split up the \u201cawaken\u201d event into different types of \u201cawaken\u201d events, although perhaps a better modeling framework would be to consider multiple critical events that could happen, one after another, rather than constraining the setting to only be on first hitting times.\nAs for the specific clinical problem we have focused on, there were a number of limitations related to the dataset we curated. First, the EEG data we have is limited to the first 12 hours after ICU admission. If we were to have more complete EEG data, we would potentially be able to provide more accurate prognoses. Second, for ease of computation, we downsample the EEG time series data. From some preliminary analyses, we found that this did not impact the resulting prediction accuracy much. However, more thorough experiments are needed to better understand the impact of our current downsampling procedure on information loss. We remark that our patient heat map visualization can help us also find when our DCR-derived classifier is actually wrong but it is very confident in its wrong answer (we provide some examples of this in Appendix F). In some such cases, from physician feedback, we have learned that the prognostication task even for physicians could be difficult given only EEG data and the static features we use. In particular, by collecting and using additional patient features (e.g., vitals, whether the patient experienced another cardiac arrest), more accurate predictions should be possible.\nUltimately, although we believe that our paper takes a step toward more realistically framing the problem of neurological prognostication of post-cardiac-arrest coma patients compared to existing literature, our work has not yet led to a \u201cdeployment-ready\u201d solution. Moreover, at this point, it is unclear to what extent the patient-specific heat map visualization we proposed actually helps clinical decision support. By continuing to account for physician feedback, we hope that we can produce a decision support system that is practically useful. User studies with clinicians would be required to assess the impact of such a system on clinical decision making."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by NSF CAREER award #2047981. The authors thank the anonymous reviewers for helpful feedback."
        },
        {
            "heading": "Appendix A. Data",
            "text": "Some summary statistics for the dataset corresponding to the cohort described in Section 4 are provided in Table A.1.\nEEG Features After post-cardiac-arrest comatose patients are admitted to the intensive care unit, electroencephalography (EEG) is used to measure brain activity. For the data we use, EEG signals are typically recorded at 256Hz from 22 electrodes adhering to standard positions according to the 10-20 International System of electrode placement. They are then processed via the medical software Persyst (https://www.persyst.com/) to generate 6,037 features at 1Hz, which is the \u201craw\u201d format of the data we start with (note that the actual raw data originally recorded by the EEG electrodes are not available, only this processed version from Persyst). The 6,037 features from Persyst include time, artifact intensity, electrode signal quality, seizure probability, FFT (fast Fourier transform) spectrogram, aEEG, peak envelope (0-25 Hz), rhythmicity spectrogram, asymmetry EASI/REASI, relative asymmetry spectrogram, spikes, and suppression ratio. Out of the above features, for simplicity, we focus on two types of EEG features that have been previously proven to be informative for neurological prognostication (e.g., Oh et al. 2015; Elmer et al. 2016a):\nSuppression ratio is calculated as a 10-second summary and reflects the proportion of the amplitude of the EEG signals in that window that falls below some threshold compared to that which falls above the threshold. More suppressed EEG is a sign of more severe dysfunction or injury. Specifically, we use 2 features: the mean values of all the electrodes in the left and right hemispheres respectively.\nAmplitude-integrated EEG (aEEG) is one way of describing the overall EEG amplitude. Very low amplitude EEGs are a sign of injury or dysfunction. Specifically, we use 10 features: the mean values of all the electrodes in the left and right hemispheres, each with 5 different statistical summaries (max, min, median, 25% percentile, 75% percentile).\nIn summary, we use the below 12 features in our study:\n\u2022 Mean of suppression ratio of all the electrodes in the left hemisphere \u2022 Mean suppression ratio of all the electrodes in the right hemisphere \u2022 Mean of max aEEG values of all the electrodes in the left hemisphere \u2022 Mean of min aEEG values of all the electrodes in the left hemisphere \u2022 Mean of median aEEG values of all the electrodes in the left hemisphere \u2022 Mean of 25% percentile aEEG values of all the electrodes in the left hemisphere \u2022 Mean of 75% percentile aEEG values of all the electrodes in the left hemisphere \u2022 Mean of max aEEG values of all the electrodes in the right hemisphere \u2022 Mean of min aEEG values of all the electrodes in the right hemisphere \u2022 Mean of median aEEG values of all the electrodes in the right hemisphere \u2022 Mean of 25% percentile aEEG values of all the electrodes in the right hemisphere \u2022 Mean of 75% percentile aEEG values of all the electrodes in the right hemisphere\nStatic Features A full list of the static features we use in the study and possible values they could take:\n\u2022 Demographic age: Age female: Female gender\nccidementia: History of dementia ccicva: History of stroke or TIA ccihemi: History of hemiplegia ccichf: History of congestive heart failure ccicvd: History of cerebrovascular disease ccicld: History of chronic lung disease/COPD ccictd: History of connective tissue disease ccipud: History of peptic ulcer disease cciaids: History of AIDS ccickd: History of moderate to severe chronic kidney disease ccielsd: History of chronic liver disease ccidm: History of diabetes ccica: History of solid tumor ccileukemia: History of leukemia ccilymphoma: History of lymphoma"
        },
        {
            "heading": "Appendix B. Training the Subdistribution Hazard Model",
            "text": "Since the subdistribution hazard model by Fine and Gray (1999) does not take vary-length time series data as inputs, we instead only use the static features and the EEG features of the last hour available for each patient in the training set to estimate the parameters of the subdistribution hazard model. After the parameters are estimated, we then plug in the static features and the EEG features at t = 6 to estimate the CIFs and calculate the c-indices corresponding to t = 6 and \u2206 = 24, 48, 72. Similarly, we generate the c-indices corresponding to t = 12 and \u2206 = 24, 48, 72, by using the same static features and EEG features at t = 12. This process is repeated five times with different random splits of training and testing sets to get the average and standard deviation of c-indices as in Table 1. Note that there is no validation set used for hyperparameter tuning as there are no hyperparameters."
        },
        {
            "heading": "Appendix C. Modifying DDRSA to Support Competing Risks",
            "text": "To make DDRSA (Venkata and Bhattacharyya, 2022) support competing risks, we modify the model structure of the original DDRSA, largely inspired by Dynamic-DeepHit (Lee et al., 2019). In the original DDRSA, the encoder RNN module takes in time-varying input features, and the decoder RNN module recurrently produces predicted hazards at different discretized time intervals. To make it support competing events, instead of having only one decoder RNN module, we have multiple decoder RNN modules to generate predictions for each of the competing events respectively. Instead of predicting hazards at different discretized time intervals, we make the model to predict the probability mass function variant of the CIF as in equation (2), where a softmax layer is applied at the end to make sure the constraint in equation (4) is satisfied. We also incorporate the attention mechanism as in Dynamic-DeepHit. The modified DDRSA can be trained in the same fashion as Dynamic-DeepHit."
        },
        {
            "heading": "Appendix D. Hyperparameter Grid",
            "text": "Note that for Dynamic-DeepHit, the loss is of the form:\nLtotal = L1 + \u03b1 \u00b7 L2 + \u03b2 \u00b7 L3 where L1 is the negative log likelihood loss term (this basically encourages first hitting times to be correctly predicted, accounting for censoring), L2 is a ranking loss (especially as the standard survival analysis metric of concordance index is a ranking-based metric, having a ranking loss that correctly orders patients based on their predicted CIFs can be helpful), L3 is the RNN prediction loss (recall that we ask the RNN to try to predict the next time step\u2019s feature vector), and lastly \u03b1 > 0 and \u03b2 > 0 are hyperparameters.\nWe use the following hyperparameter grid for both Dynamic-DeepHit and DDRSA: \u2022 learning rate \u2208 {10\u22124, 5\u00d7 10\u22124, 10\u22123} \u2022 weights of different loss terms: \u03b1 \u2208 {0.5, 1, 5}, \u03b2 \u2208 {0.05, 0.1, 0.5} \u2022 dropout rate \u2208 {0.2, 0.4}\nFor all sets of hyperparameters, we train with the Adam optimizer and a batch size of 32. The maximum number of epochs we train the models is 100 while we stop training if the average concordance index (across all the events with \u2206 = 24, 48, 72) on the validation set does not improve for 10 epochs. The best hyperparameter set is chosen to be the one with the highest average concordance index (across all the events with \u2206 = 24, 48, 72) on the validation set."
        },
        {
            "heading": "Appendix E. Additional ROC Curves",
            "text": "We provide the ROC derived based on the estimated conditional probability of awakening for each patient at t = 6, 12 and \u2206 = 48, 72, as shown in Figure E.1."
        },
        {
            "heading": "Appendix F. Additional Patient-Specific Visualizations",
            "text": "We show visualizations for three patients (Figure F.1) where the predictions are, in some sense, inconsistent with the EEG signals. In particular, for all three patients shown, their EEG signals would be perceived as corresponding to poor neurological activities, while the predictions of awakening are fairly high. While we do not understand what exactly leads to the overly high predicted probabilities of awakening for Patients A and C, we suspect the \u201crareness\u201d of the EEG patterns is the reason for the inaccurate prediction for Patient B. In fact, the suppression ratio for one hemisphere and aEEG values are quite normal but the suppression ratio values for the other hemisphere are very high, indicating abnormal brain activities. This kind of inconsistency among different EEG features is very rare in the dataset that we curated."
        },
        {
            "heading": "Appendix G. Additional ROC in Ablation Study",
            "text": "We provide the ROC when we consider only two competing events, awakening and death not by withdrawal from life-sustaining therapies, at t = 6, 12 and \u2206 = 48, 72, as shown in Figure G.1.\n0.03 0.06 0.10 0.18 0.32 0.56 1.00 False positive rate\n0.00\n0.25\n0.50\n0.75\n1.00\nTr ue\np os\niti ve\nra te\nRandom (AUROC = 0.500 \u00b1 0.000) Fine-Gray (AUROC = 0.903 \u00b1 0.039) Dynamic-DeepHit (AUROC = 0.883 \u00b1 0.030) DDRSA (AUROC = 0.863 \u00b1 0.028)\n(a) t = 6,\u2206 = 48\n0.03 0.06 0.10 0.18 0.32 0.56 1.00 False positive rate\n0.00\n0.25\n0.50\n0.75\n1.00\nTr ue\np os\niti ve\nra te\nRandom (AUROC = 0.500 \u00b1 0.000) Fine-Gray (AUROC = 0.921 \u00b1 0.034) Dynamic-DeepHit (AUROC = 0.891 \u00b1 0.029) DDRSA (AUROC = 0.853 \u00b1 0.019)\n(b) t = 12,\u2206 = 48\n0.03 0.06 0.10 0.18 0.32 0.56 1.00 False positive rate\n0.00\n0.25\n0.50\n0.75\n1.00\nTr ue\np os\niti ve\nra te\nRandom (AUROC = 0.500 \u00b1 0.000) Fine-Gray (AUROC = 0.903 \u00b1 0.039) Dynamic-DeepHit (AUROC = 0.885 \u00b1 0.029) DDRSA (AUROC = 0.849 \u00b1 0.031)\n(c) t = 6,\u2206 = 72\n0.03 0.06 0.10 0.18 0.32 0.56 1.00 False positive rate\n0.00\n0.25\n0.50\n0.75\n1.00\nTr ue\np os\niti ve\nra te\nRandom (AUROC = 0.500 \u00b1 0.000) Fine-Gray (AUROC = 0.920 \u00b1 0.034) Dynamic-DeepHit (AUROC = 0.899 \u00b1 0.025) DDRSA (AUROC = 0.822 \u00b1 0.020)\n(d) t = 12,\u2206 = 72\nFigure E.1: Test set ROC curve (average curve \u00b1 standard deviation intervals across five experimental repeats). The x-axis is on a log scale to emphasize the low FPR regime.\n1 2 3 4 5 6 7 8 9 10 11 12 t\n0\n50\n100\n150\n200 EEG\naEEG Suppression Ratio\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 6\nawake death withdrawal\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 12\nawake death withdrawal\n1 2 3 4 5 6 7 8 9 10 11 12 t\n24 48 72 0. 07 5 0. 22 1\n0. 31\n4\n0. 06 5 0.\n21 0. 28 9\n0. 06 8 0. 22 9 0. 3 0. 07 3 0. 25 0. 30 7 0. 07 7 0. 25 6 0. 31 0. 09 9 0. 25 8 0. 31 1 0. 10 2 0. 26 0. 31 2 0. 09 2 0. 24 6 0. 29 7 0. 10 6 0. 25 0. 29 8 0. 11 1 0. 25 1 0. 29 8 0. 11 6 0. 25 8 0. 30 1 0. 12 7 0. 26 7 0. 30 1\nPawaken( z, t)\n0.1 0.2 0.3 0.4\n(a) Example Patient A: died (not from withdrawal of life-sustaining therapies) at hour 106\n1 2 3 4 5 6 7 8 9 10 11 12 t\n0\n50\n100\n150\n200 EEG\naEEG Suppression Ratio\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 6\nawake death withdrawal\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 12\nawake death withdrawal\n1 2 3 4 5 6 7 8 9 10 11 12 t\n24 48 72 0. 13 1 0. 29 7\n0. 38\n9\n0. 11 4 0. 26 8 0. 35 2 0. 14 1 0. 31 6 0. 39 2 0. 12 3 0. 29 5 0. 36 8 0. 11 3 0. 28 6 0. 35 3 0. 12 2 0. 27 0. 33 4 0. 14 8 0. 31 4 0. 38 1 0. 13 8 0. 28 8 0. 35 3 0. 16 1 0. 31 5 0. 38 1 0. 15 2 0. 28 5 0. 34 6 0. 15 3 0. 28 8 0. 34 3 0. 16 8 0. 30 3 0. 34 3\nPawaken( z, t)\n0.1 0.2 0.3 0.4\n(b) Example Patient B: withdrawn from life-sustaining therapies at hour 101\n1 2 3 4 5 6 7 8 9 10 11 12 t\n0\n50\n100\n150\n200 EEG\naEEG Suppression Ratio\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 6\nawake death withdrawal\n0 20 40 60 80 100 0.0\n0.2\n0.4\n0.6\n0.8 CIF Estimates at t = 12\nawake death withdrawal\n1 2 3 4 5 6 7 8 9 10 11 12 t\n24 48 72 0.\n10 2 0. 23\n9 0. 32 8\n0. 10 6 0. 24 4 0. 33 1 0. 10 6 0. 25 1 0. 33 4 0. 10 8 0. 25 8 0. 33 3 0. 10 9 0. 25 8 0. 33 2 0. 12 0. 25 8 0. 33 1 0. 12 3 0. 25 9 0. 33 0. 12 5 0. 25 9 0. 32 9 0. 13 1 0. 26 2 0. 33 2 0. 14 1 0. 26 5 0. 33 2 0. 14 2 0. 27 0. 33 2 0. 15 3 0. 28 0. 33 2\nPawaken( z, t)\n0.1 0.2 0.3 0.4\n(c) Example Patient C: died (not from withdrawal of life-sustaining therapies) at hour 14\nFigure F.1: For each example patient (panels (a)-(c)), we show time series of two summary EEG features aEEG and suppression ratio (first column plot), estimated CIFs at hours t = 6 (second column plot) and t = 12 (third column plot), and our proposed heat map visualization (fourth column plot). Note that aEEG values for normal brain activity should be within a certain range (constantly being lower than 5 or higher than 25 is usually considered abnormal), and higher suppression ratio values are a sign of more severe dysfunction or injury.\n0.03 0.06 0.10 0.18 0.32 0.56 1.00 False positive rate\n0.00\n0.25\n0.50\n0.75\n1.00\nTr ue\np os\niti ve\nra te\nRandom (AUROC = 0.500 \u00b1 0.000) Fine-Gray (AUROC = 0.892 \u00b1 0.033) Dynamic-DeepHit (AUROC = 0.827 \u00b1 0.034)\n(a) t = 6,\u2206 = 48\n0.03 0.06 0.10 0.18 0.32 0.56 1.00 False positive rate\n0.00\n0.25\n0.50\n0.75\n1.00\nTr ue\np os\niti ve\nra te\nRandom (AUROC = 0.500 \u00b1 0.000) Fine-Gray (AUROC = 0.887 \u00b1 0.038) Dynamic-DeepHit (AUROC = 0.824 \u00b1 0.053)\n(b) t = 12,\u2206 = 48\n0.03 0.06 0.10 0.18 0.32 0.56 1.00 False positive rate\n0.00\n0.25\n0.50\n0.75\n1.00\nTr ue\np os\niti ve\nra te\nRandom (AUROC = 0.500 \u00b1 0.000) Fine-Gray (AUROC = 0.891 \u00b1 0.033) Dynamic-DeepHit (AUROC = 0.832 \u00b1 0.035)\n(c) t = 6,\u2206 = 72\n0.03 0.06 0.10 0.18 0.32 0.56 1.00 False positive rate\n0.00\n0.25\n0.50\n0.75\n1.00\nTr ue\np os\niti ve\nra te\nRandom (AUROC = 0.500 \u00b1 0.000) Fine-Gray (AUROC = 0.886 \u00b1 0.038) Dynamic-DeepHit (AUROC = 0.835 \u00b1 0.057)\n(d) t = 12,\u2206 = 72\nFigure G.1: Test set ROC curve with two events (average curve \u00b1 standard deviation intervals across five experimental repeats). The x-axis is on a log scale to emphasize the low FPR regime."
        }
    ],
    "title": "Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks",
    "year": 2023
}