{
    "abstractText": "One challenging property lurking in medical datasets is the imbalanced data distribution, where the frequency of the samples between the different classes is not balanced. Training a model on an imbalanced dataset can introduce unique challenges to the learning problem where a model is biased towards the highly frequent class. Many methods are proposed to tackle the distributional differences and the imbalanced problem. However, the impact of these approaches on the learned features is not well studied. In this paper, we look deeper into the internal units of neural networks to observe how handling data imbalance affects the learned features. We study several popular cost-sensitive approaches for handling data imbalance and analyze the feature maps of the convolutional neural networks from multiple perspectives: analyzing the alignment of salient features with pathologies and analyzing the pathology-related concepts encoded by the networks. Our study reveals differences and insights regarding the trained models that are not reflected by quantitative metrics such as AUROC and AP and show up only by looking at the models through a lens. 1",
    "authors": [
        {
            "affiliations": [],
            "name": "Ashkan Khakzar"
        },
        {
            "affiliations": [],
            "name": "Yawei Li"
        },
        {
            "affiliations": [],
            "name": "Yang Zhang"
        },
        {
            "affiliations": [],
            "name": "Mirac Sanisoglu"
        },
        {
            "affiliations": [],
            "name": "Seong Tae Kim"
        },
        {
            "affiliations": [],
            "name": "Mina Rezaei"
        },
        {
            "affiliations": [],
            "name": "Bernd Bischl"
        },
        {
            "affiliations": [],
            "name": "Nassir Navab"
        }
    ],
    "id": "SP:8dc409ae5285e3e2cbd98fdafafcd991189daab9",
    "references": [
        {
            "authors": [
                "D. Bau",
                "B. Zhou",
                "A. Khosla",
                "A. Oliva",
                "A. Torralba"
            ],
            "title": "Network dissection: Quantifying interpretability of deep visual representations",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 6541\u20136549",
            "year": 2017
        },
        {
            "authors": [
                "D. Bau",
                "J.Y. Zhu",
                "H. Strobelt",
                "A. Lapedriza",
                "B. Zhou",
                "A. Torralba"
            ],
            "title": "Understanding the role of individual units in a deep neural network",
            "venue": "Proceedings of the National Academy of Sciences 117(48), 30071\u201330078",
            "year": 2020
        },
        {
            "authors": [
                "M. Buda",
                "A. Maki",
                "M.A. Mazurowski"
            ],
            "title": "A systematic study of the class imbalance problem in convolutional neural networks",
            "venue": "Neural Networks 106, 249\u2013259",
            "year": 2018
        },
        {
            "authors": [
                "R. Cong",
                "J. Lei",
                "H. Fu",
                "M.M. Cheng",
                "W. Lin",
                "Q. Huang"
            ],
            "title": "Review of visual saliency detection with comprehensive information",
            "venue": "IEEE Transactions on circuits and Systems for Video Technology 29(10), 2941\u20132959",
            "year": 2018
        },
        {
            "authors": [
                "Y. Cui",
                "M. Jia",
                "T.Y. Lin",
                "Y. Song",
                "S. Belongie"
            ],
            "title": "Class-balanced loss based on effective number of samples",
            "venue": "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 9268\u20139277",
            "year": 2019
        },
        {
            "authors": [
                "H. He",
                "E.A. Garcia"
            ],
            "title": "Learning from imbalanced data",
            "venue": "IEEE Transactions on knowledge and data engineering 21(9), 1263\u20131284",
            "year": 2009
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770\u2013778",
            "year": 2016
        },
        {
            "authors": [
                "S. Hooker",
                "D. Erhan",
                "P.J. Kindermans",
                "B. Kim"
            ],
            "title": "A benchmark for interpretability methods in deep neural networks",
            "venue": "Advances in Neural Information Processing Systems. pp. 9737\u20139748",
            "year": 2019
        },
        {
            "authors": [
                "G. Huang",
                "Z. Liu",
                "L. Van Der Maaten",
                "K.Q. Weinberger"
            ],
            "title": "Densely connected convolutional networks",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 4700\u20134708",
            "year": 2017
        },
        {
            "authors": [
                "A. Kendall",
                "Y. Gal",
                "R. Cipolla"
            ],
            "title": "Multi-task learning using uncertainty to weigh losses for scene geometry and semantics",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 7482\u20137491",
            "year": 2018
        },
        {
            "authors": [
                "A. Khakzar",
                "S. Albarqouni",
                "N. Navab"
            ],
            "title": "Learning interpretable features via adversarially robust optimization",
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention. pp. 793\u2013800. Springer",
            "year": 2019
        },
        {
            "authors": [
                "A. Khakzar",
                "S. Baselizadeh",
                "S. Khanduja",
                "C. Rupprecht",
                "S.T. Kim",
                "N. Navab"
            ],
            "title": "Improving feature attribution through input-specific network pruning",
            "venue": "arXiv preprint arXiv:1911.11081",
            "year": 2019
        },
        {
            "authors": [
                "A. Khakzar",
                "S. Baselizadeh",
                "S. Khanduja",
                "C. Rupprecht",
                "S.T. Kim",
                "N. Navab"
            ],
            "title": "Neural response interpretation through the lens of critical pathways",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 13528\u201313538",
            "year": 2021
        },
        {
            "authors": [
                "A. Khakzar",
                "S. Baselizadeh",
                "N. Navab"
            ],
            "title": "Rethinking positive aggregation and propagation of gradients in gradient-based saliency methods",
            "venue": "arXiv preprint arXiv:2012.00362",
            "year": 2020
        },
        {
            "authors": [
                "A. Khakzar",
                "P. Khorsandi",
                "R. Nobahari",
                "N. Navab"
            ],
            "title": "Do explanations explain? model knows best",
            "venue": "arXiv preprint arXiv:2203.02269",
            "year": 2022
        },
        {
            "authors": [
                "A. Khakzar",
                "S. Musatian",
                "J. Buchberger",
                "I. Valeriano Quiroz",
                "N. Pinger",
                "S. Baselizadeh",
                "S.T. Kim",
                "N. Navab"
            ],
            "title": "Towards semantic interpretation of thoracic disease and covid-19 diagnosis models",
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention. pp. 499\u2013508. Springer",
            "year": 2021
        },
        {
            "authors": [
                "A. Khakzar",
                "Y. Zhang",
                "W. Mansour",
                "Y. Cai",
                "Y. Li",
                "Y. Zhang",
                "S.T. Kim",
                "N. Navab"
            ],
            "title": "Explaining covid-19 and thoracic pathology model predictions by identifying informative input features",
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention. pp. 391\u2013401. Springer",
            "year": 2021
        },
        {
            "authors": [
                "S. Khan",
                "M. Hayat",
                "S.W. Zamir",
                "J. Shen",
                "L. Shao"
            ],
            "title": "Striking the right balance with uncertainty",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 103\u2013112",
            "year": 2019
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "Bengio, Y., LeCun, Y. (eds.) 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings",
            "year": 2015
        },
        {
            "authors": [
                "S. Krishna",
                "T. Han",
                "A. Gu",
                "J. Pombra",
                "S. Jabbari",
                "S. Wu",
                "H. Lakkaraju"
            ],
            "title": "The disagreement problem in explainable machine learning: A practitioner\u2019s perspective",
            "venue": "arXiv preprint arXiv:2202.01602",
            "year": 2022
        },
        {
            "authors": [
                "T.Y. Lin",
                "P. Goyal",
                "R. Girshick",
                "K. He",
                "P. Doll\u00e1r"
            ],
            "title": "Focal loss for dense object detection",
            "venue": "Proceedings of the IEEE international conference on computer vision. pp. 2980\u20132988",
            "year": 2017
        },
        {
            "authors": [
                "S.M. Lundberg",
                "S.I. Lee"
            ],
            "title": "A unified approach to interpreting model predictions",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2017
        },
        {
            "authors": [
                "K.P. Murphy"
            ],
            "title": "Machine learning: a probabilistic perspective",
            "venue": "MIT press",
            "year": 2012
        },
        {
            "authors": [
                "C. Olah",
                "A. Mordvintsev",
                "L. Schubert"
            ],
            "title": "Feature visualization",
            "venue": "Distill",
            "year": 2017
        },
        {
            "authors": [
                "A. Paszke",
                "S. Gross",
                "F. Massa",
                "A. Lerer",
                "J. Bradbury",
                "Chanan"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "venue": "Advances in Neural Information Processing Systems 32, pp. 8024\u20138035. Curran Associates, Inc.",
            "year": 2019
        },
        {
            "authors": [
                "M. Rezaei",
                "H. Yang",
                "C. Meinel"
            ],
            "title": "Generative adversarial framework for learning multiple clinical tasks",
            "venue": "2018 Digital Image Computing: Techniques and Applications (DICTA). pp. 1\u20138. IEEE",
            "year": 2018
        },
        {
            "authors": [
                "T. Ridnik",
                "E. Ben-Baruch",
                "N. Zamir",
                "A. Noy",
                "I. Friedman",
                "M. Protter",
                "L. ZelnikManor"
            ],
            "title": "Asymmetric loss for multi-label classification",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 82\u201391",
            "year": 2021
        },
        {
            "authors": [
                "R.R. Selvaraju",
                "M. Cogswell",
                "A. Das",
                "R. Vedantam",
                "D. Parikh",
                "D. Batra"
            ],
            "title": "Gradcam: Visual explanations from deep networks via gradient-based localization",
            "venue": "Proceedings of the IEEE international conference on computer vision. pp. 618\u2013626",
            "year": 2017
        },
        {
            "authors": [
                "K. Simonyan",
                "A. Vedaldi",
                "A. Zisserman"
            ],
            "title": "Deep inside convolutional networks: Visualising image classification models and saliency maps",
            "venue": "arXiv preprint arXiv:1312.6034",
            "year": 2013
        },
        {
            "authors": [
                "M. Sundararajan",
                "A. Taly",
                "Q. Yan"
            ],
            "title": "Axiomatic attribution for deep networks",
            "venue": "34th International Conference on Machine Learning, ICML 2017",
            "year": 2017
        },
        {
            "authors": [
                "X. Wang",
                "Y. Peng",
                "L. Lu",
                "Z. Lu",
                "M. Bagheri",
                "R.M. Summers"
            ],
            "title": "Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2097\u20132106",
            "year": 2017
        },
        {
            "authors": [
                "Y. Zhang",
                "A. Khakzar",
                "Y. Li",
                "A. Farshad",
                "S.T. Kim",
                "N. Navab"
            ],
            "title": "Fine-grained neural network explanation by identifying input features with predictive information",
            "venue": "Advances in Neural Information Processing Systems 34",
            "year": 2021
        },
        {
            "authors": [
                "B. Zhou",
                "A. Khosla",
                "A. Lapedriza",
                "A. Oliva",
                "A. Torralba"
            ],
            "title": "Learning deep features for discriminative localization",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2921\u20132929",
            "year": 2016
        }
    ],
    "sections": [
        {
            "text": "Keywords: Interpretability \u00b7 Explainability \u00b7 Handling Class Imbalance \u00b7 Cost-sensitive Learning"
        },
        {
            "heading": "1 Introduction",
            "text": "Medical imaging datasets often appear in imbalanced distribution where the frequency of the samples between the different classes of the training dataset is not similar or balanced. The low amount of training samples for infrequent classes or tailed distribution makes it challenging to learn optimal classification boundaries in the representation and can lead to a biased model. Existing methods to tackle class imbalance problem either modify data distribution or learn\n? denotes equal contribution 1 https://github.com/CAMP-eXplain-AI/imba-explain\nar X\niv :2\n20 4.\n01 72\n9v 1\n[ ee\nss .I\nV ]\n4 A\n2 appropriate costs to re-weight class errors. At the data level, the objective is to balance the data distribution through re-sampling techniques which often are prone to over-fitting [18,3,6]. On the other hand, the cost-sensitive approaches modify the learning algorithm to alleviate the bias towards frequent classes or head of distribution [5,26]. The efficacy of these approaches is demonstrated by conventional metrics such as precision and recall and their derivatives. However, the effect of these approaches on the learned features is not well studied. The study of learned features not only improves our understanding of what happens within the models, is specifically insightful when the conventional evaluation metrics do not reflect the effect of applying such cost-sensitive approaches.\nThis study explores what happens to the learned features when it is trained by cost-sensitive approaches to handle the data imbalance. To understand the effect on learned features, we analyze the internal units of neural networks. Specifically, we analyze the feature maps (outputs of convolutional layers) in deep layers by class activation maps and network dissection [1]. First, we optimize models (ResNet [7] and DenseNet [9]) with Binary Cross-Entropy (BCE) [23]. Several recent and popular cost-sensitive losses such as Weighted BCE (WBCE) [25], Focal loss [21], and Class-Balanced Focal loss (CB-Focal) [5] on NIH Chest Xray [31] dataset and report classical metrics: area Under ROC curve (AUROC), average precision (AP) and predicted probabilities. Then, we visually analyze the impact on salient learned features using class activation maps [33,28] and provide quantitative evaluations to validate the visual observation. We then proceed to analyze the learned features using network dissection [1,16] which quantitatively identifies the concepts encoded (learned) by the model. Statement of Contribution By placing models trained with different learning strategies under the lens, we observe that while metrics such as AUROC and AP report equivalent performance, the models trained with cost-sensitive losses encode more pathology-related concepts. Moreover, we observe an increased alignment between salient learned features and pathology-related features."
        },
        {
            "heading": "2 Related Works",
            "text": "Handling Data Imbalance: Much of the recent works on imbalanced learning focused on alleviating this problem using novel objective function. Lin et. al. [21] introduce a Focal loss for dense object detection where class-specific weights were automatically learned. Cui et. al. [5] re-weight the loss by the inverse effective number of examples to learn balanced representations. Similarly, [18] modified the weights according the uncertainty of predictions. Others address this problem by multi-task learning [10,26] that used selective instances for training on imbalanced sets for each task. Interpreting Neural Networks: Two principal neural network interpretation approaches are feature attribution [29,32,13,30,22,17,12] (i.e. saliency methods [4]) and analyzing internal units (e.g. feature visualization [24] and dissection [2,16]). Here, we look into the models from both perspectives. We are interested in both the contribution of input features to the output (i.e., feature attribution) and concepts encoded by the network (via analyzing units).\nEffects of Handling Data Imbalance on Learned Features 3\nThe are many attribution methods, however the identified important features are different for different methods [20,32,15,14]. This is a caveat for researchers using the attribution toolkit. Within the various feature attribution methods, CAM [28] being a classic and intuitive method, it satisfies benchmarks in terms of faithfulness [8,32,15]. Moreover, regardless of its advantages for attribution, the method provides a summary of activation maps in a certain layer by performing a weighted sum of the attributions. We use network dissection [1,16] to identify concepts associated with individual convolutional feature maps."
        },
        {
            "heading": "3 Method",
            "text": "The question we explore in this paper is what happens to the learned features within the model when we apply cost-sensitive approaches to handle the class imbalance during training. Specifically, we study the intra-class data imbalance, i.e. the imbalance between the number of positive and negative samples for each class. We first introduce the cost-sensitive methods (see Section 3.1) that consider the data imbalance between positive and negative samples. Then, we explain our approaches for analyzing the learned features (see Section 3.2)."
        },
        {
            "heading": "3.1 Handling Data Imbalance",
            "text": "Given D = {x(k), y(k)}Kk=1, our goal is to learn the optimal boundary \u03b8\u2217 obtained by empirical loss minimization LD(\u03b8) on the training set D as: \u03b8\u2217 = arg min\u03b8 LD(\u03b8). The class imbalanced problem exists when the frequency of the samples among different categories are extremely mismatched. Therefore \u03b8 learned on D using conventional empirical loss can be biased towards the low frequent classes and significantly different from the ideal boundary \u03b8\u2217. In other words, because of the imbalanced proportion between classes, the optimal boundary is more likely to afford a higher empirical error than an alternative hypothesis based on an empirical loss. This is due to the nature of imbalanced class distribution that forces the classifier to shift \u03b8 closer to low-frequent classes because it reduces empirical error. A principal strategy to handle data imbalance is through the cost-sensitive loss functions [21,5,10,27].\nHere, we study data imbalance problem in multi-label and binary classification. Assume N samples X = {x(i)}Ni=1 from M classes. we denote the corresponding label set as Y = {y(i)}Ni=1 with y(i) \u2208 {1, 2, ...,M}. The probability p (i) m of class m for sample x(i) given by a neural network is defined with multiple outputs as cross entropy error between predicted value and true label using Binary Cross Entropy (BCE) loss. The cost-sensitive losses applied to class can be summarized into a unified framework:\nLCE = \u2212 N\u2211 i=1 [w (i) + y (i) log p(i) + w (i) \u2212 (1\u2212 y(i)) log(1\u2212 p(i))], (1)\nwhere w (i) + and w (i) \u2212 are the positive and negative class weights for sample x (i), respectively. We omit the class index m for simplicity. The four losses considered\n4 in this work can be derived as follows:\nBCE [23]: w (i) + = w (i) \u2212 = 1,\nWBCE [25]: w (i) + = N\u2212 N+ +N\u2212 , and w (i) \u2212 = N+ N+ +N\u2212 ,\nFocal [21]: w (i) + = \u03b1(1\u2212 p(i))\u03b3 , and w (i) \u2212 = (1\u2212 \u03b1)p(i) \u03b3 ,\nCB-Focal [5]: w (i) + = 1\u2212 \u03b2 1\u2212 \u03b2N+ \u00b7 (1\u2212 p(i))\u03b3 , and w(i)\u2212 = 1\u2212 \u03b2 1\u2212 \u03b2N\u2212 \u00b7 p(i) \u03b3 ,\n(2)\nwhere N+, N\u2212 are the number of positive and negative samples of class m, and \u03b1, \u03b3 and \u03b2 are hyper-parameters. As we are discussing intra-class imbalance, each loss is considered individually and we apply the cost-sensitive methods on each loss to strike a balance between positive and negative samples for each class."
        },
        {
            "heading": "3.2 Looking into the Models",
            "text": "The objective is to analyze the features learned by the model in different training scenarios. In this work, we analyze the internal units of the model, specifically the activation pattern of convolutional feature maps in deeper layers. The deep convolutional layers are chosen due to the following two reasons: 1) Final layers in principle encode higher-level concepts and we are interested to know if these concepts align with pathological features. 2) We focus on convolutional layers instead of deeper fully connected layers, since convolutional layers keep the spatial correspondence with input features, and therefore, we can leverage image annotations from experts to study if the activations align with pathology related features. We analyze the internal features maps from two different perspectives:\nClass Activation Maps [33,28] can be deemed as a tool that summarizes the contributions of feature maps of the final convolutional layer in one tensor (for the networks under investigation, GradCAM [28], and CAM [33] are equivalent). The method combines the feature maps using their associated weight (or gradient of output with respect to feature map in GradCAM) of their connections to the output, thus summarizing how feature maps contribute to the final output. The method, in essence, shows which areas are contributing to the output for each sample input. Thus using annotations from experts, we can check whether the salient regions are aligned with the pathologies [31,11].\nAnalyzing Encoded Concepts [1,16]: We use an approach inspired by network dissection [1] which is a tool for individually analyzing the convolutional feature maps of the neural network. In essence, it identifies the concepts associated with each feature map, thus allowing for understanding what concepts are encoded by the network during training. In this work, we use a conceptually similar approach. For a chosen convolutional layer, let Ac denote the activation (feature) map of channel c. Similar to [1], we first apply a threshold \u03c4c with P(AC \u2265 \u03c4c) = q to activation values of each channel c to filter the dataset-wise significant activation values, where q is a pre-defined hyper-parameter. For each image in the annotation dataset we compute the corresponding Ac and apply the threshold \u03c4c. Subsequently, we identify the connected components in the\nEffects of Handling Data Imbalance on Learned Features 5\nthreshold activations. If the connected component overlaps the bounding box region, we consider the connected component as a pathology related concept. Using this approach we can report two values that reflect the concepts encoded in the network quantitatively, which are explained in Sec. 4."
        },
        {
            "heading": "4 Experiments",
            "text": "Experimental Setup In this paper, we examine and perform two different datasets and learning tasks: multi-label classification and binary classification on the NIH Chest X-ray dataset [31]. For binary classification. We define samples with the \u201cNo Finding\u201d label as \u201cHealthy\u201d samples, and samples with other labels as \u201cUnhealthy\u201d samples. Random crop, horizontal flip, and color jitter are used as the augmentations. In the end, the augmented images are resized to 224\u00d7224 before being fed into an image classifier.\nWe use two ImageNet pre-trained classifiers: ResNet50 [7] and DenseNet [9]. The last feature maps of ResNet50 have the size 7 \u00d7 7. In order to have a finegrained analysis on smaller features such as Nodule (for which 7\u00d7 7 is a coarse resolution) we use a truncated version of DenseNet. We discard the last two dense blocks and the associated transition blocks, so that the last feature maps have size 28\u00d7 28. We refer to this truncated variant of DenseNet as T-DenseNet. We adopt the same training configurations for all models. Specifically, we train the classifiers on 4 GPUs (DGX-A100) for 50 epochs using the Adam [19] optimizer with weight decay 10\u22126 and initial learning rate 0.0004. The learning rate is decayed following the cosine-annealing policy. In addition, we set the batch size to 512. For the Focal loss, the \u03b3 and \u03b1 set to 2.0 and 0.25, respectively; for the class-balanced focal loss, we set \u03b3 to 2.0 and \u03b2 to 0.9999.\nFeature Alignment Analysis The objective is to have a metric for measuring the alignment between the contributing features (from CAMs) for a single prediction and the pathologies. This can be achieved by classical object detection metrics IoBB(Intersection over Bounding Box) and IoR(Intersection of detected Region). IoBB and IoR can be considered as the visual counterparts of recall and precision. Computing these metrics requires thresholding the CAMs. In order to reduce the sensitivity of the results to the chosen threshold, we implement soft IoBB and IoR computation. This is performed by normalizing the CAMs to [0, 1] and applying a summation of values within the regions under consideration (intersection, bounding box, detected region).\nAnalysis of Concepts We count the number of concepts within bounding boxes in two ways: Disjoint: Number of concepts detected by a feature map (i.e. connected components overlapping the bounding box) for all feature maps in the chosen layer and all images in the annotation subset and normalize the value by the number of images. This approach considers repeated concepts in a bounding box, as some bounding boxes cover huge regions where multiple concepts occur. Unique: For each feature map, if there is at least one concept detected, we\n6 BCE WBCE Focal CB-Focal\nconsider the feature map as a unique concept detector (similar to [1]). We choose the hyper-parameter q = 0.01 for the T-DenseNet and q = 0.04 for the ResNet50. Different q only changes the absolute number of detected concepts and does not affect comparative analysis. We count the number of unique concept detectors\nEffects of Handling Data Imbalance on Learned Features 7\n0.0 0.5\nUnhealthy Average\nNo Finding Infiltration\nEffusion Atelectasis\nNodule Mass\nConsolidation Pneumothorax\nPleural Thickening Cardiomegaly\nEmphysema Edema Fibrosis\nPneumonia Hernia\nAUROC\n0.0 0.5\nAP\n0.0 0.5\nProbability\n0.0 0.5\nAUROC\n0.0 0.5\nAP\n0.0 0.5\nT-DenseNet ResNet50 Probability\nBCE WBCE Focal CB-Focal\nFig. 2: Performance Analysis. The sub-figures 1 \u223c 3 (from left to right) and 4 \u223c 6 show the results of the T-DenseNet and ResNet50, respectively. In addition to AUROC and AP, sample-wise averaged predicted probabilities are shown. In each sub-figure, \u201cAverage\u201d indicates the class-wise average of the corresponding metric in multi-label classification; \u201cUnhealthy\u201d refers to the positive class in binary classification task. We observe that AUCROC and AP for different learning strategies are similar. Thus these metrics do not tell the entire story.\nfor all images and normalize by the number of images. The provided metrics reflect how individual feature maps are aligned with pathologies."
        },
        {
            "heading": "5 Results and Discussion",
            "text": "Performance Analysis We evaluate the classification performance using AUROC and AP (Fig. 2). The performance differences between BCE and weighted losses (WBCE, Focal, and CB-Focal) are marginal. Therefore the effect of handling data imbalance via losses is not visible via these metrics. We also report the predicted probabilities of different losses. The predicted probabilities of the weighted losses are substantially higher than that of the BCE. This is expected as more weight is given to positive samples. Moreover, as more weight is given to the positive weights, the recall is higher. However, it is not clear if the increased recall is due to model\u2019s inclination towards identifying samples as positive or due to the model having learned and leveraging more predictive features.\nFeature Alignment Analysis In this section, we analyze the models\u2019 internal feature maps to see if the increased recall and probability values are related to predictive features relevant to the pathologies. This is realized by comparing CAMs and the salient features for individual predictions with annotations from radiologists. In Fig. 1 we observe that in models trained with cost-sensitive losses, the additionally activated regions are aligned with the pathologies (bounding boxes). This shows that the increased recall is not due to the models\u2019 propensity towards identifying samples as positive but due to having learned meaningful\npredictive features. Note that metrics such as AUROC and AP are roughly equivalent for all models (Fig. 2). In order to quantify the observed behavior in Fig. 1 we report IoBB and IoR results in Tab. 1. The increased IoBB for models trained with cost-sensitive losses shows that the features cover more areas of bounding boxes (pathologies). We also observe a decrease in IoR, which is also evident in Fig. 1 as falsely positive active regions have also increased.\nAnalysis of Concepts This section analyzes the effect of handling data imbalance on the concepts encoded by the model. This is performed by counting the number of detected pathology-related concepts. In Tab. 2 we observe that the models trained with cost-sensitive losses consistently have more detectors. Thus it can be concluded that the models encode more pathology-related concepts when the data imbalance is considered in the loss."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we study the effect of handling data imbalance using cost-sensitive losses during training on the learned feature maps. The feature maps are analyzed from two perspectives: class activation maps and the concept encoded by each feature map. We observe that although classical metrics such as AUROC and AP report equivalent performance for the studied models, the learned features are different in these models. When data imbalance is handled, the models\nEffects of Handling Data Imbalance on Learned Features 9\nencode more pathology-related concepts. Moreover, we observe that overall increased recall and predicted probability of these models are accompanied by an increased alignment between learned features and pathology-related features.\nAcknowledgment This work has been funded in part by the German Federal Ministry of Education and Research (BMBF) under Grant No.01IS18036A and 01IS18036B, Munich Center for Machine Learning (MCML). A. K., N. N. were supported with funding from the Bundesministerium fur Bildung und Forschung (BMBF). M. R., and B. B. were supported by the German Federal Ministry of Education and Research (BMBF) under Grant No. 01IS18036A. Y. L. is supported by the German Federal Ministry of Health (2520DAT920). S.T. K. is supported by National Research Foundation of Korea(NRF) grant funded by the Korea Government(MSIT) (No. 2021R1G1A1094990)."
        }
    ],
    "title": "Analyzing the Effects of Handling Data Imbalance on Learned Features from Medical Images by Looking Into the Models",
    "year": 2022
}