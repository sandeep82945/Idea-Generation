{
    "abstractText": "We study the advantages of reconfigurable communication interfaces vs fixed communication interfaces in the context of asynchronous automata. We study the extension of asynchronous (Zielonka) automata with reconfigurable communication interfaces. We show that it is possible to capture languages of automata with reconfigurable communication interfaces by automata with fixed communication interfaces. However, this comes at a cost of disseminating communication (and knowledge) to all agents in a system. Thus, the system is no longer behaving as a distributed system. We then show that this is unavoidable by describing a language in which every agent that uses a fixed communication interface either must be aware of all communication or become irrelevant. 2012 ACM Subject Classification Theory of computation Formal languages and automata theory",
    "authors": [
        {
            "affiliations": [],
            "name": "Mathieu Lehaut"
        },
        {
            "affiliations": [],
            "name": "Nir Piterman"
        }
    ],
    "id": "SP:24c87179e33a0b235c4b15eb1aee43d38d66f6a6",
    "references": [
        {
            "authors": [
                "Yehia Abd Alrahman",
                "Rocco De Nicola",
                "Michele Loreti"
            ],
            "title": "A calculus for collective-adaptive systems and its behavioural theory",
            "venue": "Inf. Comput.,",
            "year": 2019
        },
        {
            "authors": [
                "Yehia Abd Alrahman",
                "Nir Piterman"
            ],
            "title": "Modelling and verification of reconfigurable multi-agent systems",
            "venue": "Auton. Agents Multi Agent Syst.,",
            "year": 2021
        },
        {
            "authors": [
                "Marco Carbone",
                "Sergio Maffeis"
            ],
            "title": "On the expressive power of polyadic synchronisation in pi-calculus",
            "venue": "Nord. J. Comput.,",
            "year": 2003
        },
        {
            "authors": [
                "Frank S. de Boer",
                "Catuscia Palamidessi"
            ],
            "title": "Embedding as a tool for language comparison",
            "venue": "Inf. Comput.,",
            "year": 1994
        },
        {
            "authors": [
                "Daniele Gorla"
            ],
            "title": "Towards a unified approach to encodability and separation results for process calculi",
            "venue": "Inf. Comput.,",
            "year": 2010
        },
        {
            "authors": [
                "Mathias John",
                "C\u00e9dric Lhoussaine",
                "Joachim Niehren",
                "Adelinde M. Uhrmacher"
            ],
            "title": "The attributed pi calculus",
            "venue": "In 6th International Conference on Computational Methods in Systems Biology,",
            "year": 2008
        },
        {
            "authors": [
                "Radu Mateescu",
                "Gwen Sala\u00fcn"
            ],
            "title": "Translating pi-calculus into LOTOS NT",
            "venue": "In 8th International Conference on Integrated Formal Methods,",
            "year": 2010
        },
        {
            "authors": [
                "Robin Milner",
                "Joachim Parrow",
                "David Walker"
            ],
            "title": "A calculus of mobile processes, I",
            "venue": "Inf. Comput.,",
            "year": 1992
        },
        {
            "authors": [
                "Robin Milner",
                "Joachim Parrow",
                "David Walker"
            ],
            "title": "A calculus of mobile processes, II",
            "venue": "Inf. Comput.,",
            "year": 1992
        },
        {
            "authors": [
                "Rocco De Nicola",
                "Michele Loreti",
                "Rosario Pugliese",
                "Francesco Tiezzi"
            ],
            "title": "A formal approach to autonomic systems programming: The SCEL language",
            "venue": "ACM Trans. Auton. Adapt. Syst.,",
            "year": 2014
        },
        {
            "authors": [
                "Rob van Glabbeek"
            ],
            "title": "Comparing the expressiveness of the \u03c0-calculus and CCS",
            "venue": "Ilya Sergey, editor, Programming Languages and Systems - 31st European Symposium on Programming,",
            "year": 2022
        },
        {
            "authors": [
                "Wieslaw Zielonka"
            ],
            "title": "Notes on finite asynchronous automata",
            "venue": "RAIRO Theor. Informatics Appl.,",
            "year": 1987
        }
    ],
    "sections": [
        {
            "text": "2012 ACM Subject Classification Theory of computation - Formal languages and automata theory\nKeywords and phrases Zielonka Automata, Reconfigurable Communication\nDigital Object Identifier 10.4230/LIPIcs.CVIT.2016.23\nFunding Supported by the ERC Consolidator grant D-SynMA (No. 772459)\n1 Introduction\nIn recent years, computation has permeated every aspect of our lives. Computation devices have become so widely available that they are now everywhere. They are lighter, cheaper, prevalent, and, ultimately, mobile. Sensor networks, multi-agent systems, and robot teams use mobile and ad-hoc networks. In such networks, participants/agents/elements come and go and change the communication configuration based on need, location, and various restrictions. These systems force us to consider how communication changes when participants are numerous, mobile, and required to collaborate.\nAlready three decades ago, the modeling of mobility prompted Milner, Parrow, and Walker to introduce the \u03c0-calculus [9, 10]. This is a process calculus that allows message contents to include the name of channels. By transferring channels to interested parties, communication configuration can change through the run of the system. The \u03c0-calculus has become a standard for modeling mobility and reconfigurability of communication. Building on the \u03c0-calculus, the concurrency community has considered different means of communication and how they support mobility and recently reconfiguration (e.g., [4, 3, 7, 11, 1]). The study of different communication mechanisms, some of them dynamic and mobile and some of them static, led to the development of a rich theory about comparison of such systems for their expressiveness [5, 6] The standard way is to try to create an encoding of one formalism into another [6]. On the one hand, the encoding should be compositional \u2013 respect the structure of original and target programs. It should also have some operational correspondence \u2013 computations of the original are mapped to computations of the target programs. Using this theory one can show both equivalence of expressive power but also distinction (c.f., the seminal study in [6], or, e.g., [8] or the recent surprising results about well known formalisms in [12]).\n\u00a9 Mathieu Lehaut and Nir Piterman; licensed under Creative Commons License CC-BY 4.0\n42nd Conference on Very Important Topics (CVIT 2016). Editors: John Q. Open and Joan R. Access; Article No. 23; pp. 23:1\u201323:12\nLeibniz International Proceedings in Informatics Schloss Dagstuhl \u2013 Leibniz-Zentrum f\u00fcr Informatik, Dagstuhl Publishing, Germany\nar X\niv :2\n30 5.\n01 42\n5v 1\n[ cs\n.F L\n] 2\nM ay\n2 02\n3\nVan Glabbeek\u2019s result mentioned above is particularly surprising as it shows that a static communication formalism can simulate a dynamic communication formalism [12]. Here we are interested in measuring differences in communication when the two formalisms actually have the same expressive power. Particularly, we are asking ourselves what is the value of reconfiguring communication when a formalism with static communication has the same expressive power. At the same time, we diverge from the common view in studies of concurrency and concentrate on language technology. Hence, we consider a canonical formalism in language theory for considering fixed communication \u2013 asynchronous automata or Zielonka automata. These are a well known model that supports distribution of language recognition under a fixed communication topology. The model is especially interesting due to Zielonka\u2019s seminal result on the ability to distribute languages in this model [13]. Zielonka\u2019s result starts from a given regular language and a target (fixed) distribution of the alphabet. He then shows that if the deterministic automaton for the language satisfies a simple condition about independence of communications then the language can be distributed and accepted by a distributed team of agents.\nWe compare Zielonka automata with a reconfigurable variant inspired by channeled transition systems [2]. Agents comprising a system are extended with the ability to connect and disconnect from channels/letters. A communication can occur on a channel if all the agents that are connected to the channel agree on it. Otherwise, the communication is blocked. This is the exact notion of communication of Zielonka automata, except that agents can connect and disconnect to channels. In order to allow more than mere synchronization on the channel, communications are extended by a data value. To distinguish between Zielonka automata and their extension we still call the latter channeled transition systems, though they are much simpler than those considered originally [2].\nWe then show, as expected, that the two formalisms are equivalent in expressive power. As the structure of both formalisms includes one level of parallel composition, the encoding is almost an isomorphism. We show two different encodings: First, we consider Zielonka automata with global transition relations. We show how to encode them using channeled transitions systems with data. Second, we consider Zielonka automata with local transition relations. Their encoding into channeled transition systems is achieved by dropping the data in the previous encoding. The encoding in the other direction is very similar, however, with an important caveat: the encoding does not distribute the communication. Namely, all communication is shared between all agents of the system. Given that all agents are informed about everything they can autonomously decide which communications to ignore and which communications to act upon.\nAlthough we show the encoding only in the context of language equivalence and not structural equivalence, we find the conclusion that the two formalisms have the same expressive power very unsatisfying. Indeed, this conclusion completely ignores who communicates with who in the distributed system, the information that different participants have, and the potential knowledge that agents have on the computation. This criterion is completely dropped from the notion of equivalence. Indeed, there is a cost in one direction of the encoding that is not evaluated according to current practices.\nFinally, we show that this extra cost is unavoidable. We suggest a language that can be recognized distributively by channeled transition system but not by Zielonka automata. Namely, using reconfigurable communication agents actively connect and disconnect from channels and keep themselves informed only about crucial information. Throughout, agents are connected to a very small number of channels that is independent of system size. However, some (changing) channels are used for coordination of how to connect and disconnect from\nthe other channels. We show that for Zielonka automata to recognize the same language some agents must be connected to the full set of channels and be informed of everything. What\u2019s more, every agent that is not connected to the full set of channels can be made trivial by accepting unconditionally all possible communication on channels that they are connected to. Thus, the only possible translation from reconfigurable communication to fixed communication is by making agents constantly connected to all channels that they might need at some point. We give two versions of this construction with slightly different properties with the essential difference being the distance to \u201ctrivializability\u201d being shorter if we add one more channel for coordination.\nThe rest of the paper is organized as follows. In Section 2 we recall the definition of Zielonka automata and give the definition of the simplified channeled transition systems. In Section 3 we give the translations between the models and show that the data of channeled transition systems correspond to the global transitions of Zielonka automata. We then show that in every translation that removes the reconfigurability all agents either know everything or are trivial, in Section 4. Finally, we conclude and discuss our results in Section 5.\n2 Definitions"
        },
        {
            "heading": "2.1 Fixed communication structure",
            "text": ""
        },
        {
            "heading": "2.1.1 Distributed Alphabets.",
            "text": "We fix a finite set P of processes. Let \u03a3 be a finite alphabet, and dom : \u03a3\u2192 2P a domain function associating each letter with the subset of processes listening to that letter. The pair (\u03a3, dom) is called a distributed alphabet. We let dom\u22121(p) = {a \u2208 \u03a3 | p \u2208 dom(a)}. It induces an independence binary relation I in the following way: (a, b) \u2208 I \u21d4 dom(a) \u2229 dom(b) = \u2205. Two words u = u1 . . . un and v = v1 . . . vn are said to be equivalent, denoted by u \u223c v, if one can start from u, repeatedly switch two consecutive independent letters, and end up with v. Let us denote by [u] the equivalence class of a word u. Let A = (Q,\u03a3, q0,\u2206, F ) be a deterministic automaton over \u03a3. We say that A is I-diamond if for all pairs of independent letters (a, b) \u2208 I and all states q \u2208 Q, we have \u2206(q, ab) = \u2206(q, ba). If A has this property, then a word u is accepted by A if and only if all words in [u] are accepted. Zielonka\u2019s result states that an I-diamond automaton can be distributed to processes who are connected to channels according to dom [13]."
        },
        {
            "heading": "2.1.2 Asynchronous Automata.",
            "text": "An asynchronous automaton (AA) over \u03a3 is a tuple B = ((Sp)p\u2208P, (s0p)p\u2208P, (\u03b4a)a\u2208\u03a3,Acc) such that:\nSp is the set of states for process p, and s0p \u2208 Sp is its initial state, \u03b4a : \u220f p\u2208dom(a) Sp \u2192 \u220f p\u2208dom(a) Sp is a transition function for letter a that only depends on the states of processes in dom(a) and leaves those outside unchanged, Acc \u2286 \u220f p\u2208P Sp is a set of accepting states.\nA run of B is a sequence s0a0s1a1 . . . sn where for all i \u2264 n, si \u2208 \u220f\np\u2208P Sp, ai \u2208 \u03a3, satisfying the following relation:\nsi+1 \u2193dom(a)= \u03b4ai(si \u2193dom(a)) and si+1 \u2193P\\dom(a)= si \u2193P\\dom(a)\nA run is accepting if sn belongs to Acc. The word a0a1 . . . is accepted by B if such an accepting run exists. The language of B, denoted by L(B), is the set of words accepted by\nCVIT 2016\nB. For the rest of this paper, we will drop the Acc component as we focus more on the runs themselves over whether they can reach a certain target. That is, we assume that Acc = \u220f p\u2208P Sp.\nWe also define a weaker version of asynchronous automata, called local asynchronous automata (short: LAA or local AA), in which the transition function is local to each process, and therefore independent with respect to the states of all other processes. To avoid confusion, we sometimes refer to normal asynchronous automata as defined earlier as global asynchronous automata (or global AA), though if not specified then AA refers to global AA."
        },
        {
            "heading": "2.1.3 Local Asynchronous Automata.",
            "text": "A local asynchronous automaton over \u03a3 is a tuple B = ((Sp)p\u2208P, (s0p)p\u2208P, (\u03b4p)p\u2208P) where Sp and s0p are defined as before, and \u03b4p : Sp\u00d7dom\u22121(p)\u2192 Sp is the transition function of process p. A run of B is a sequence s0a0s1a1 . . . sn where for all i \u2264 n, si = (spi )p\u2208P \u2208 \u220f p\u2208P Sp, ai \u2208 \u03a3, satisfying the following relation:\nspi+1 = { \u03b4p(spi , ai) if p \u2208 dom(ai), spi otherwise.\nObserve that a global AA can easily simulate a local AA, whereas the reverse direction does not hold."
        },
        {
            "heading": "2.2 Reconfigurable communication",
            "text": "Let us consider here a model where the communication structure is not fixed, and can be modified dynamically during a run. As before, fix a finite set P of processes, with |P| = n. Let us as well fix a finite set C of channels, with a role similar to the alphabet \u03a3 of the previous section except without an added dom function. Finally, let T be a (possibly infinite) set of message contents."
        },
        {
            "heading": "2.2.1 Channeled Transition Systems.",
            "text": "A Channeled Transition System (CTS) over C is a tuple A = (S, s0,\u2206, L) where:\nS is a set of states, s0 \u2208 S being the initial state, \u2206 \u2286 S\u00d7 (T \u00d7C)\u00d7S is the transition relation, where (s, (t, c), s\u2032) means going from state s to s\u2032 after having a message on channel c with content t, L : S \u2192 2C is a listening function such that c \u2208 L(s) if there is a transition of the form (s, (t, c), s\u2032) \u2208 \u2206, i.e. state s must be listening to channel c if there is some transition from s involving a message on c. A run of A is a sequence s0m0s1m1 . . . starting from the initial state s0 and where for all i \u2208 N,mi \u2208 T \u00d7C and (si,mi, si+1) \u2208 \u2206. The language of A, denoted by L(A), is the set of words over C of the form c0c1 . . . such that there exists a run of the form s0(t0, c0)s1(t1, c1) . . . , i.e. we focus only on the sequence of channels where messages are sent, and drop the states and message contents.\nGiven a sequence of CTS A1, . . . ,An (one for each p \u2208 P) with Ap = (Sp, s0p,\u2206p, Lp), one can define their parallel composition A\u2016P = (S, s0,\u2206, L):\nS = \u220f\np\u2208P Sp and s0 = (s01, . . . , s0n), L(s1, . . . , sn) = \u22c3 p\u2264n Lp(sp), ((s1, . . . , sn), (t, c), (s\u20321, . . . , s\u2032n)) \u2208 \u2206 if the following conditions are met:\n1. \u2203p s.t. c \u2208 Lp(sp), 2. \u2200p s.t. c \u2208 Lp(sp), (sp, (t, c), s\u2032p) \u2208 \u2206p, and 3. \u2200p s.t. c /\u2208 Lp(sp), s\u2032p = sp.\nIn plain words, there is a transition if all processes listening to the corresponding channel have a transition, with at least one process listening to the channel, whereas those that do not listen are left unchanged. Note that if some process listens to that channel but does not implement the transition, then that transition is blocked.\n3 From AA to CTS and Back\nWe now focus on comparing the expressive power of those two formalisms. For the rest of this section, we fix a finite set P of processes."
        },
        {
            "heading": "3.1 AA to CTS",
            "text": "Let (\u03a3, dom) be a distributed alphabet, and let B be an AA over it. One can construct a CTS A\u2016P with \u03a3 as set of channels that recognizes the same language as B."
        },
        {
            "heading": "3.1.1 Intuition.",
            "text": "The listening function of each agent is the same for all states: each process always listens to the channels that have this process in their domain, i.e. Lp(s) = dom\u22121(p) for all s \u2208 Sp. The only part that is not straightforward to emulate is that a transition of an AA depends on the states of all processes in the domain of the corresponding letter. Therefore each process in the CTS needs to share their states via message contents to all others when emulating a transition.\nI Lemma 1. Every language recognized by an AA over (\u03a3, dom) can be recognized by a CTS with set of channels \u03a3.\nProof. Let B = ((Sp)p\u2208P, (s0p)p\u2208P, (\u03b4a)a\u2208\u03a3) be an AA as described earlier. Let Ap = (Sp, s0p,\u2206p, Lp) be a CTS for process p where:\nLp(s) = {a \u2208 \u03a3 | p \u2208 dom(a)} for all s \u2208 Sp, \u2206p =\n{(sp, ((sp\u2032)p\u2032\u2208dom(a), a), s\u2032p) | sp = (sp\u2032)p\u2032\u2208dom(a) \u2193p and s\u2032p = \u03b4a((sp\u2032)p\u2032\u2208dom(a)) \u2193p} i.e. an a-transition is possible if and only if all processes in dom(a) correctly share their own state in the message, and all processes then update their state according to \u03b4a.\nBy construction, one can verify that for each run of B, there is a corresponding run of A\u2016P where at each point, the state of each process p is the same in both runs. It follows that every word in L(B) also belongs to L(A\u2016P) and conversely A\u2016P can only emulate runs of B, showing the reverse inclusion. J\nNote that the size of the constructed CTS lies almost entirely in the size of T , the message contents set, which is \u220f p\u2208P Sp. One could reduce the size of T by allowing processes to share their states one communication at a time, though the state space would grow as each process needs to store the states of others, and the language recognized would become the n-stuttering of the original language.\nFor local AA the translation is even more straightforward, as no message content is required (i.e. T can be reduced to a singleton).\nCVIT 2016\nI Corollary 2. Every language recognized by an LAA over (\u03a3, dom) can be recognized by a CTS with set of channels \u03a3 and where |T | = 1.\nProof. In the case of LAA, the transition \u03b4p does not depend on the states of other processes. Let T = {t}. We replace the transition \u2206p in the proof of Lemma 1 by \u2206p = {sp, (t, a), s\u2032p | \u03b4p(sp, a) = s\u2032p}. J"
        },
        {
            "heading": "3.2 CTS to AA",
            "text": "Let us now focus on the reverse direction. Let (Ap)p\u2208P be a sequence of CTS over P with set of channels C, and let A be their parallel composition. Our goal is to create an AA with alphabet C that recognizes the same language. The question that arises is: what should dom be defined as for the distributed alphabet (C, dom)?\nIf we allow dom to be unrestricted, one could define it as the complete domain function: dom(a) = P for all channels. In that case, it is trivial to build an AA over (C, dom) that emulates A, as each process can simply stutter when they are not supposed to listen to a channel.\nI Lemma 3. Every language recognized by a CTS over set of channels C can be recognized by an AA over C and the complete domain function.\nProof. Consider (Ap)p\u2208P, where Ap = (Sp, sP0 , Ap, Lp), with A = (S, s0,\u2206, L) being their parallel composition. We build B = ((Qp)p\u2208P, (q0p)p\u2208P, (\u03b4c)c\u2208C) as follows:\nfor all p \u2208 P, Qp = Sp, and q0p = s0p For channel c \u2208 C we have \u03b4c defined as follows.\n\u03b4c = ((qp)p\u2208P, (q\u2032p)p\u2208P) \u2223\u2223\u2223\u2223\u2223\u2223 \u2203t \u2208 T, p \u2208 P.c \u2208 Lp(qp) and \u2200p\u2032 \u2208 P. If c \u2208 Lp(qp), (qp\u2032 , (t, c), q\u2032p\u2032) \u2208 \u2206p\u2032 and If c /\u2208 Lp(qp), qp = q\u2032p  Note that having global transitions is necessary to ensure all processes share the same message content t. However if we assume that T is a singleton, then local transitions suffice. J\nI Corollary 4. Every language recognized by a CTS over set of channels C, where |T | = 1 can be recognized by an LAA over C.\nActually, it is not even necessary that all processes listens to all channels. It suffices that at least one process p \u2208 P does (i.e. dom\u22121(p) = C), and implements the transitions as described above. Any other process can listen to any subset of channels and simply allow any transition to happen on those channels. In other words, one process serves as a centralized executor of the simulation, while others simply need to be non-blocking.\nIn the next section we show that the complete domain is required.\n4 Trivializable and Fully Listening\nWe now give an example of a CTS such that the method described above is the only way of accepting the same language. The idea is to allow every possible subset of channels to be either fully independent, that is every one of those channels can be used in parallel, or make them sequentially dependent, that is they can only be used in a certain order. This status can be switched by a communication on a separate channel (that all processes listen to), called the switching channel. Moreover, after enough switches, a different channel will serve as the switching channel. That way, all channels have the opportunity to serve as the switching\nchannel, given enough switches. Notice that our construction does not use messages. Thus, already the weakest form of CTS shows this property. We start with a simpler construction with a single switching channel that can cycle through all possible subsets according to some order. Then we give a more refined construction with two switching channels that allows for a finer control on the dependent subset."
        },
        {
            "heading": "4.1 Single Switching Channel",
            "text": "Let P = {p1, . . . , pn}. We fix C = {c1, . . . , cn, cn+1}, that is, we have one channel per process and one additional channel to be used as switching channel (dynamically).\nFor all sc \u2208 C (sc stands for switching channel), fix <sc an arbitrary total order over 2C\\{sc}, with the only requirement that \u2205 be the minimal element. Intuitively, a set in 2C\\{sc} will represent the set of dependent channels, and a switch will go to the next one with respect to <sc. Let us denote by inc<sc : 2C\\{sc} \u2192 2C\\{sc} \u222a {\u22a5} the function that returns the next set according to <sc or \u22a5 for the maximal element.\nAdditionally, for every subset D \u2286 C, we fix D+ 1 : C \u2192 C a function that cycles through all elements of D and is the identity on C \\D. For convenience we write d D+ 1 for D+ 1(d). We also define D\u2212 1 : D \u2192 D the inverse function and use the same notation. Namely, for every d \u2208 D we have (d D\u2212 1) D+ 1 = d and (d D+ 1) D\u2212 1 = d. We denote by cD \u2208 D an arbitrary element of D.\nFinally, we set T = {t}, and omit the message content component in transitions. We build Ap = (Sp, s0p,\u2206p, Lp) for p = pk as follows: Sp = {(c, sc, D, d) | c, sc \u2208 C,D \u2286 C \\ {sc}, d \u2208 D \u222a {c}}, and s0p = (ck, cn+1, \u2205, ck). The first component is the channel assigned to this process, initially ck for process k, but may change if ck becomes the switching channel. The second component is the current switching channel, initialized to cn+1 for all processes. Component D represents the set of channels that are currently dependent, and d is the next channel that Ak is listening to on which it is expecting communication. All processes listen to the switching channel and their assigned channel, plus all of D if it contains the assigned channel:\nLp(c, sc, D, d) = { {sc, c, c D\u2212 1} if c \u2208 D {sc, c} if c /\u2208 D\nThe transition \u2206p is the union of the sets in Figure 1. The first two kinds of transitions handle the independence of all channels in C \\D and the cycling through the channels of D. If c /\u2208 D then c = c D\u2212 1. In this case, the first two sets simply say that a transition on c is always possible possible. If c \u2208 D, then the process awaits until it gets a message on c D\u2212 1 and then is ready to interact on c. After interaction on c it awaits another interaction on c D\u2212 1. It follows that all the processes owning the channels in D enforce together the cyclic order on the messages in D. This part is further illustrated in Figure 2. The rest or the transitions describe what happens when a switch occurs. Sets three and four describe what happens when the next set according to <sc is defined. In this case, the next set becomes the new set of dependent channels D. Set three handles the case of the process that is in charge of the channel becoming the first channel to communicate on the new set inc<sc(D). This process is ready for communication on this first channel. The fourth set handles the case of all other processes. All other processes are either in charge of channels in D\u2032, in which case they set themselves to await a communication on the previous in D\u2032 or they are in charge of channels not in D\u2032 in which case, c and c D\u2032\u2212 1 = c, and the process is ready\nCVIT 2016\n\u2206p = {((c, sc, D, c), c, (c, sc, D, c D\u2212 1))} \u222a {((c, sc, D, c D\u2212 1), c D\u2212 1, (c, sc, D, c)} \u222a{\n((c, sc, D, d), sc, (c, sc, D\u2032, c)) \u2223\u2223\u2223\u2223 D\u2032 = inc<sc(D) 6= \u22a5and c = cD\u2032 } \u222a{\n((c, sc, D, d), sc, (c, sc, D\u2032, c D\u2032\u2212 1)) \u2223\u2223\u2223\u2223 D\u2032 = inc<sc(D) 6= \u22a5and c 6= cD\u2032 } \u222a{\n((c, sc, D, d), sc, (c, sc C+ 1, \u2205, c)) \u2223\u2223\u2223\u2223 inc<sc(D) = \u22a5 andc 6= sc C+ 1 } \u222a{\n((c, sc, D, d), sc, (sc, sc C+ 1, \u2205, sc)) \u2223\u2223\u2223\u2223 inc<sc(D) = \u22a5 andc = sc C+ 1 }\nLet A be the parallel composition of (Ap). The size of the state space of A is in O((n3.2n)n)."
        },
        {
            "heading": "4.2 Asynchronous Automata Construction",
            "text": "We show that an AA that recognizes the same language as A has the following property: for each process p, either p listens to every channel (dom\u22121(p) = C), or from every reachable state there is a path to a bottom strongly connected component that is complete w.r.t. dom\u22121(p). In the former case, we call p fully-listening. In the latter case, we say that p is trivializable, as once it is in this bottom SCC it can never block communications ever again, thus p becomes irrelevant to the rest of the computation.\nI Lemma 5. Let B be an AA such that L(B) = L(A). Each process in B is either fullylistening or trivializable.\nProof. Let B = ((Sp)p\u2208P, (s0p)p\u2208P, (\u03b4a)a\u2208\u03a3), and let p \u2208 P. Assume that p is not fullylistening, so let Cp = dom\u22121(p) ( C. In particular, let c \u2208 C \\ Cp be a channel that p does not listen to.\nLet sp be a reachable state for p in B. Then there is w a computation in L(B) such that p reaches state sp after w. Consider the same computation in A, and let sc be the current switching channel in A at the end of w. Let sc \u00b7 c1 \u00b7 ... \u00b7 cn\u22121 \u00b7 c be the sequence of channels from sc to c according to the order from C+ 1. Then there is a continuation w\u2032 of w of the form sck0 \u00b7 ck11 \u00b7 ... \u00b7 c kn\u22121 n\u22121 with k0, . . . , kn\u22121 \u2208 N such that:\nww\u2032 \u2208 L(A), c is the current switching channel and the dependent set D is \u2205.\nFrom this, every continuation w\u2032\u2032 \u2208 (C \\ {c})\u2217 is still in L(A) and does not change the switching channel or the dependent set. In particular, every w\u2032\u2032 \u2208 (dom\u22121(p))\u2217 maintains that w \u00b7 w\u2032 \u00b7 w\u2032\u2032 is also in L(A) = L(B). Therefore, from the state reached in B after ww\u2032,\nthere is a path to a strongly connected component that will implement all transitions in dom\u22121(p), i.e. a complete one. J"
        },
        {
            "heading": "4.3 Two Switching Channels",
            "text": "We outline a second construction that allows for a finer control on the set of dependent channels using an additional switching channel. Aside from the two switching channels, there is always one highlighted non-switching channel. The first switching channel, tg (for toggling channel), is used to add the highlighted channel to the dependent set. The second switching channel, hl (for highlighting channel), changes the highlighted channel to the next non-switching channel. With that setup, it is always possible to go from an empty dependent set to any set D in a linear number of steps by iterating on D: switch the highlighted channel to the next one in D, then toggle it, repeat. This takes at most n uses of hl to cycle through all channels and n uses of tg to add them. In the previous construction, it could take up to 2n steps to reach a target set. Finally, after enough uses of hl, the two switching channels change so that every channel can eventually be one of the switching channels, and the dependent set is also reset to the empty set.\nFormally, let us first introduce some useful notations. We let P = {p1, . . . , pn} and C = {c1, . . . , cn+2}. As in the previous construction, for every subset D \u2286 C we fix D+ 1 : C \u2192 C a function that cycles through all elements of D and is the identity on C \\D. For convenience we write d D+ 1 for D+ 1(d). As before we also use D\u2212 1 : D \u2192 D the inverse function and use the same notation. When the two switching channels tg and hl are known,\nCVIT 2016\nwe denote by C\u2217 = C \\ {tg,hl} the set of non-switching channels. Finally, let c1? and c0? be two channels in C\u2217 such that c1? = c0? C\u2217+ 1. Those two are used to check when we have cycled through every non-switching channels.\nNow for p \u2208 P we build Ap = (Sp, s0p,\u2206p, Lp) with its components described as follows: A state is of the form s = (c, tg,hl, h,D, d) \u2208 C4 \u00d7 2C \u00d7 C. As in the first construction, c is the channel currently assigned to p, which may change when the switching channels are replaced. The channels tg and hl are those two switching channels. Channel h is the highlighted non-switching channel. Finally, D is the current dependent set and d the next channel available for a communication for p. The initial state is s0p = (ck, cn+1, cn+2, c1 ?\n, \u2205, ck), where k is the index such that p = pk. All processes listen to both switching channels and their assigned channel, plus, potentially, the previous channel in D if D contains the assigned channel:\nLp(c, tg,hl, h,D, d) = { {tg,hl, c, c D\u2212 1} if c \u2208 D {tg,hl, c} if c /\u2208 D\nThe transition \u2206p is the union of the sets in Figure 4. The first two kinds of transition are similar to the previous construction. The third and fourth kind are the toggling mechanism, which adds the currently highlighted channel h to the dependent set. If the followed channel is not h then update the previous channel according to the set D \u222a {h}. If the followed channel is h then expect the next communication on h. The remaining are the highlighting mechanism. When a communication on hl occurs, the highlighted channel changes to the next one. If the highlighted channel is not maximal then go to the next highlighted channel (5). If we have already cycled through all non-switching channels once (the current highlighted channel is maximal), we may have to update the first component if the channel assigned to this process becomes a switching channel, and the highlighted channel and dependent set are both reset, then new channels assume the roles of toggling and highlighting. That is, either \u201cour channel\u201d is untouched by the change (6), or \u201cour channel\u201d is assigned to tg (7) or to hl (8).\nWithout going into details, one can modify the proof of Lemma 5 to be adapted to this construction: use enough hl communications until hl is a channel that process p does not listen to, which means that p is not able to distinguish between all possible dependent sets from this point onwards and therefore p cannot block communications on a non-switching channel.\nWe note that it is possible to modify the last construction so that only the hl channel is dynamic and the tg channel is fixed. This, however, complicates the notations further.\n{(c, tg,hl, h,D, c), c, (c, tg,hl, h,D, c D\u2212 1)} \u222a {(c, tg,hl, h,D, c D\u2212 1), c D\u2212 1, (c, tg,hl, h,D, c)} \u222a {(c, tg,hl, h,D, d), tg, (c, tg,hl, h, E, c E\u2212 1) | c 6= h \u2227 E = D \u222a {h}}} \u222a {(c, tg,hl, h,D, d), tg, (h, tg,hl, h,D \u222a {h}, h) | c = h} \u222a {(c, tg,hl, h,D, d),hl, (c, tg,hl, h C\u2217+ 1, D, d) | h 6= c0?} \u222a{\n(c, tg,hl, c0? , D, d),hl, (c, tg C+ 1,hl C+ 1, c1? , \u2205, c) \u2223\u2223\u2223\u2223 c /\u2208 { tg C+ 1,hl C+ 1 }} \u222a {(c, tg,hl, c0? , D, d),hl, (tg, tg C+ 1,hl C+ 1, c1? , \u2205, tg) | c = tg C+ 1} \u222a {(c, tg,hl, c0? , D, d),hl, (hl, tg C+ 1,hl C+ 1, c1? , \u2205,hl) | c = hl C+ 1}\nFigure 4 The transitions comprising \u2206p of the two switching channels case.\n5 Conclusion\nWe study the addition of reconfiguration of communication to Zielonka automata. We show that in terms of expressiveness, the addition does not change the power of the model: every language recognized distributively by automata with reconfigurable communication can be recognized essentially by the same automata with fixed communication. The same is (obviously) true in the other direction. However, the cost of conversion is in disseminating widely all the information and leaving it up to the agents whether to use it or not. We also show that this total dissemination cannot be avoided. Agents who do not get access to the full information about the computation become irrelevant and in fact do not participate in the distributed computation.\nThe issues of mobile and reconfigurable communication raise a question regarding \u201chow much\u201d communication is performed in a computation. Given a language recognized by a a Zielonka automaton (distributively), the independence relation between letters is fixed by the language. It follows that two distributed systems in the form of Zielonka automata accepting (distributively) the same language must have the same independence relation between letters. However, this does not mean that they agree on the distribution of the alphabet. In case of two different distributed alphabets, what makes one better than the other? This question becomes even more important with systems with reconfigurable communication interfaces. Particularly, in channeled transition systems, the connectivity changes from state to state, which makes comparison even harder. How does one measure (and later reduce or minimize) the amount of communication in a system while maintaining the same behavior? We note that for the system in Section 4, the maximal number of connections per agent is four regardless of how many channels are in the system. Dually, the Zielonka automaton for the same language requires every agent that participates meaningfully in the interaction to have number of connections equivalent to the parameter n. Is less connectivity better than more connectivity?\nThe issues of who is connected and to with whom information is shared also have implications for security and privacy. Reconfiguration allowed us to share communication only with those who \u201cneed to know\u201d. Fixed topology forced us to disseminate information widely. If we intend to use language models and models of concurrency in applications that involve security and privacy we need a way to reason about dissemination of information and comparing formalisms also based on knowledge and information."
        },
        {
            "heading": "Acknowledgments",
            "text": "We are grateful to Y. Abd Alrahman and L. Di Stefano for fruitful discussions and suggestions.\nCVIT 2016\nReferences 1 Yehia Abd Alrahman, Rocco De Nicola, and Michele Loreti. A calculus for collective-adaptive\nsystems and its behavioural theory. Inf. Comput., 268, 2019. doi:10.1016/j.ic.2019.104457. 2 Yehia Abd Alrahman and Nir Piterman. Modelling and verification of reconfigurable\nmulti-agent systems. Auton. Agents Multi Agent Syst., 35(2):47, 2021. doi:10.1007/ s10458-021-09521-x. 3 Marco Carbone and Sergio Maffeis. On the expressive power of polyadic synchronisation in pi-calculus. Nord. J. Comput., 10(2):70\u201398, 2003. 4 Luca Cardelli and Andrew D. Gordon. Mobile ambients. Theor. Comput. Sci., 240(1):177\u2013213, 2000. doi:10.1016/S0304-3975(99)00231-5. 5 Frank S. de Boer and Catuscia Palamidessi. Embedding as a tool for language comparison. Inf. Comput., 108(1):128\u2013157, 1994. doi:10.1006/inco.1994.1004. 6 Daniele Gorla. Towards a unified approach to encodability and separation results for process calculi. Inf. Comput., 208(9):1031\u20131053, 2010. doi:10.1016/j.ic.2010.05.002. 7 Mathias John, C\u00e9dric Lhoussaine, Joachim Niehren, and Adelinde M. Uhrmacher. The attributed pi calculus. In 6th International Conference on Computational Methods in Systems Biology, volume 5307 of Lecture Notes in Computer Science, pages 83\u2013102. Springer, 2008. doi:10.1007/978-3-540-88562-7\\_10. 8 Radu Mateescu and Gwen Sala\u00fcn. Translating pi-calculus into LOTOS NT. In 8th International Conference on Integrated Formal Methods, volume 6396 of Lecture Notes in Computer Science, pages 229\u2013244. Springer, 2010. doi:10.1007/978-3-642-16265-7\\_17. 9 Robin Milner, Joachim Parrow, and David Walker. A calculus of mobile processes, I. Inf. Comput., 100(1):1\u201340, 1992. doi:10.1016/0890-5401(92)90008-4. 10 Robin Milner, Joachim Parrow, and David Walker. A calculus of mobile processes, II. Inf. Comput., 100(1):41\u201377, 1992. doi:10.1016/0890-5401(92)90009-5. 11 Rocco De Nicola, Michele Loreti, Rosario Pugliese, and Francesco Tiezzi. A formal approach to autonomic systems programming: The SCEL language. ACM Trans. Auton. Adapt. Syst., 9(2):7:1\u20137:29, 2014. doi:10.1145/2619998. 12 Rob van Glabbeek. Comparing the expressiveness of the \u03c0-calculus and CCS. In Ilya Sergey, editor, Programming Languages and Systems - 31st European Symposium on Programming, ESOP 2022, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2022, Munich, Germany, April 2-7, 2022, Proceedings, volume 13240 of Lecture Notes in Computer Science, pages 548\u2013574. Springer, 2022. doi:10.1007/978-3-030-99336-8\\_20. 13 Wieslaw Zielonka. Notes on finite asynchronous automata. RAIRO Theor. Informatics Appl., 21(2):99\u2013135, 1987. doi:10.1051/ita/1987210200991."
        }
    ],
    "title": "Measuring the Gain of Reconfigurable Communication",
    "year": 2023
}