{
    "abstractText": "An explanation method called SurvBeX is proposed to interpret predictions of the machine learning survival black-box models. The main idea behind the method is to use the modified Beran estimator as the surrogate explanation model. Coefficients, incorporated into Beran estimator, can be regarded as values of the feature impacts on the black-box model prediction. Following the well-known LIME method, many points are generated in a local area around an example of interest. For every generated example, the survival function of the black-box model is computed, and the survival function of the surrogate model (the Beran estimator) is constructed as a function of the explanation coefficients. In order to find the explanation coefficients, it is proposed to minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples. Many numerical experiments with synthetic and real survival data demonstrate the SurvBeX efficiency and compare the method with the wellknown method SurvLIME. The method is also compared with the method SurvSHAP. The code implementing SurvBeX is available at: https://github.com/DanilaEremenko/SurvBeX",
    "authors": [
        {
            "affiliations": [],
            "name": "Lev V. Utkin"
        }
    ],
    "id": "SP:dfc7a1dbc2f1f54955d6596a399499762908118e",
    "references": [
        {
            "authors": [
                "D. Hosmer",
                "S. Lemeshow",
                "S. May"
            ],
            "title": "Applied Survival Analysis: Regression Modeling of Time to Event Data",
            "venue": "John Wiley & Sons, New Jersey,",
            "year": 2008
        },
        {
            "authors": [
                "P. Wang",
                "Y. Li",
                "C.K. Reddy"
            ],
            "title": "Machine learning for survival analysis: A survey",
            "venue": "ACM Computing Surveys (CSUR), 51(6):1\u201336,",
            "year": 2019
        },
        {
            "authors": [
                "M.Z. Nezhad",
                "N. Sadati",
                "K. Yang",
                "D. Zhu"
            ],
            "title": "A deep active survival analysis approach for precision treatment recommendations: Application of prostate cancer",
            "venue": "arXiv:1804.03280v1, April",
            "year": 2018
        },
        {
            "authors": [
                "D.R. Cox"
            ],
            "title": "Regression models and life-tables",
            "venue": "Journal of the Royal Statistical Society, Series B (Methodological), 34(2):187\u2013220,",
            "year": 1972
        },
        {
            "authors": [
                "C. Haarburger",
                "P. Weitz",
                "O. Rippel",
                "D. Merhof"
            ],
            "title": "Image-based survival analysis for lung cancer patients using CNNs",
            "venue": "arXiv:1808.09679v1, Aug",
            "year": 2018
        },
        {
            "authors": [
                "J.L. Katzman",
                "U. Shaham",
                "A. Cloninger",
                "J. Bates",
                "T. Jiang",
                "Y. Kluger"
            ],
            "title": "Deepsurv: Personalized treatment recommender system using a Cox proportional hazards deep neural network",
            "venue": "BMC medical research methodology, 18(24):1\u201312,",
            "year": 2018
        },
        {
            "authors": [
                "D.M. Witten",
                "R. Tibshirani"
            ],
            "title": "Survival analysis with high-dimensional covariates",
            "venue": "Statistical Methods in Medical Research, 19(1):29\u201351,",
            "year": 2010
        },
        {
            "authors": [
                "X. Zhu",
                "J. Yao",
                "J. Huang"
            ],
            "title": "Deep convolutional neural network for survival analysis with pathological images",
            "venue": "2016 IEEE International Conference on Bioinformatics and Biomedicine, pages 544\u2013547. IEEE,",
            "year": 2016
        },
        {
            "authors": [
                "F.M. Khan",
                "V.B. Zubek"
            ],
            "title": "Support vector regression for censored data (SVRc): a novel tool for survival analysis",
            "venue": "2008 Eighth IEEE International Conference on Data Mining, pages 863\u2013868. IEEE,",
            "year": 2008
        },
        {
            "authors": [
                "N.A. Ibrahim",
                "A. Kudus",
                "I. Daud",
                "M.R. Abu Bakar"
            ],
            "title": "Decision tree for competing risks survival probability in breast cancer study",
            "venue": "International Journal Of Biological and Medical Research, 3(1):25\u201329,",
            "year": 2008
        },
        {
            "authors": [
                "U.B. Mogensen",
                "H. Ishwaran",
                "T.A. Gerds"
            ],
            "title": "Evaluating random forests for survival analysis using prediction error curves",
            "venue": "Journal of Statistical Software, 50(11):1\u201323,",
            "year": 2012
        },
        {
            "authors": [
                "M. Schmid",
                "M.N. Wright",
                "A. Ziegler"
            ],
            "title": "On the use of harrell\u2019s c for clinical risk prediction via random survival forests",
            "venue": "Expert Systems with Applications, 63:450\u2013459,",
            "year": 2016
        },
        {
            "authors": [
                "H. Wang",
                "L. Zhou"
            ],
            "title": "Random survival forest with space extensions for censored data",
            "venue": "Artificial intelligence in medicine, 79:52\u201361,",
            "year": 2017
        },
        {
            "authors": [
                "M.N. Wright",
                "T. Dankowski",
                "A. Ziegler"
            ],
            "title": "Unbiased split variable selection for random survival forests using maximally selected rank statistics",
            "venue": "Statistics in Medicine, 36(8):1272\u20131284,",
            "year": 2017
        },
        {
            "authors": [
                "S. Wiegrebe",
                "P. Kopper",
                "R. Sonabend",
                "A. Bender"
            ],
            "title": "Deep learning for survival analysis: A review",
            "venue": "arXiv:2305.14961, May",
            "year": 2023
        },
        {
            "authors": [
                "A. Holzinger",
                "G. Langs",
                "H. Denk",
                "K. Zatloukal",
                "H. Muller"
            ],
            "title": "Causability and explainability of artificial intelligence in medicine",
            "venue": "WIREs Data Mining and Knowledge Discovery, 9(4):e1312,",
            "year": 2019
        },
        {
            "authors": [
                "V. Arya",
                "R.K.E. Bellamy",
                "P.-Y. Chen",
                "A. Dhurandhar",
                "M. Hind",
                "S.C. Hoffman",
                "S. Houde",
                "Q.V. Liao",
                "R. Luss",
                "A. Mojsilovic",
                "S. Mourad",
                "P. Pedemonte",
                "R. Raghavendra",
                "J. Richards",
                "P. Sattigeri",
                "K. Shanmugam",
                "M. Singh",
                "K.R. Varshney",
                "D. Wei",
                "Y. Zhang"
            ],
            "title": "One explanation does not fit all: A toolkit and taxonomy of AI explainability techniques",
            "venue": "arXiv:1909.03012, Sep",
            "year": 2019
        },
        {
            "authors": [
                "R. Guidotti",
                "A. Monreale",
                "S. Ruggieri",
                "F. Turini",
                "F. Giannotti",
                "D. Pedreschi"
            ],
            "title": "A survey of methods for explaining black box models",
            "venue": "ACM computing surveys, 51(5):93,",
            "year": 2019
        },
        {
            "authors": [
                "C. Molnar"
            ],
            "title": "Interpretable Machine Learning: A Guide for Making Black Box Models Explainable",
            "venue": "Published online, https://christophm.github.io/interpretable-ml-book/,",
            "year": 2019
        },
        {
            "authors": [
                "W.J. Murdoch",
                "C. Singh",
                "K. Kumbier",
                "R. Abbasi-Asl",
                "B. Yu"
            ],
            "title": "Definitions, methods, and applications in interpretable machine learning",
            "venue": "Proceedings of the National Academy of Sciences, volume 116, pages 22071\u201322080,",
            "year": 2019
        },
        {
            "authors": [
                "M.T. Ribeiro",
                "S. Singh",
                "C. Guestrin"
            ],
            "title": "Why should I trust You?\u201d Explaining the predictions of any classifier",
            "venue": "arXiv:1602.04938v3, Aug",
            "year": 2016
        },
        {
            "authors": [
                "D. Garreau",
                "U. Luxburg"
            ],
            "title": "Explaining the explainer: A first theoretical analysis of lime",
            "venue": "International Conference on Artificial Intelligence and Statistics, pages 1287\u20131296. PMLR,",
            "year": 2020
        },
        {
            "authors": [
                "M.S. Kovalev",
                "L.V. Utkin",
                "E.M. Kasimov"
            ],
            "title": "SurvLIME: A method for explaining machine learning survival models",
            "venue": "Knowledge-Based Systems, 203:106164,",
            "year": 2020
        },
        {
            "authors": [
                "M.S. Kovalev",
                "L.V. Utkin"
            ],
            "title": "A robust algorithm for explaining unreliable machine learning survival models using the Kolmogorov-Smirnov bounds",
            "venue": "Neural Networks, 132:1\u201318,",
            "year": 2020
        },
        {
            "authors": [
                "L.V. Utkin",
                "M.S. Kovalev",
                "E.M. Kasimov"
            ],
            "title": "An explanation method for black-box machine learning survival models using the chebyshev distance",
            "venue": "Artificial Intelligence and Natural Language. AINL 2020, volume 1292 of Communications in Computer and Information Science, pages 62\u201374, Cham,",
            "year": 2020
        },
        {
            "authors": [
                "R. Beran"
            ],
            "title": "Nonparametric regression with randomly censored survival data",
            "venue": "Technical report, University of California, Berkeley,",
            "year": 1981
        },
        {
            "authors": [
                "S.M. Lundberg",
                "S.-I. Lee"
            ],
            "title": "A unified approach to interpreting model predictions",
            "venue": "Advances in Neural Information Processing Systems, pages 4765\u20134774,",
            "year": 2017
        },
        {
            "authors": [
                "E. Strumbelj",
                "I. Kononenko"
            ],
            "title": "An efficient explanation of individual classifications using game theory",
            "venue": "Journal of Machine Learning Research, 11:1\u201318,",
            "year": 2010
        },
        {
            "authors": [
                "M. Krzyzinski",
                "M. Spytek",
                "H. Baniecki",
                "P. Biecek"
            ],
            "title": "SurvSHAP (t): Time-dependent explanations of machine learning survival models",
            "venue": "Knowledge-Based Systems, 262:110234,",
            "year": 2023
        },
        {
            "authors": [
                "S.M. Shankaranarayana",
                "D. Runje"
            ],
            "title": "ALIME: Autoencoder based approach for local interpretability",
            "venue": "arXiv:1909.02437, Sep",
            "year": 2019
        },
        {
            "authors": [
                "I. Ahern",
                "A. Noack",
                "L. Guzman-Nateras",
                "D. Dou",
                "B. Li",
                "J. Huan"
            ],
            "title": "NormLime: A new feature importance metric for explaining deep neural networks",
            "venue": "arXiv:1909.04200, Sep",
            "year": 2019
        },
        {
            "authors": [
                "M.R. Zafar",
                "N.M. Khan"
            ],
            "title": "DLIME: A deterministic local interpretable model-agnostic explanations approach for computer-aided diagnosis systems",
            "venue": "arXiv:1906.10263, Jun",
            "year": 2019
        },
        {
            "authors": [
                "M.T. Ribeiro",
                "S. Singh",
                "C. Guestrin"
            ],
            "title": "Anchors: High-precision model-agnostic explanations",
            "venue": "AAAI Conference on Artificial Intelligence, pages 1527\u20131535,",
            "year": 2018
        },
        {
            "authors": [
                "L. Hu",
                "J. Chen",
                "V.N. Nair",
                "A. Sudjianto"
            ],
            "title": "Locally interpretable models and effects based on supervised partitioning (LIME-SUP)",
            "venue": "arXiv:1806.00663, Jun",
            "year": 2018
        },
        {
            "authors": [
                "J. Rabold",
                "H. Deininger",
                "M. Siebers",
                "U. Schmid"
            ],
            "title": "Enriching visual with verbal explanations for relational concepts: Combining LIME with Aleph",
            "venue": "arXiv:1910.01837v1, October",
            "year": 2019
        },
        {
            "authors": [
                "Q. Huang",
                "M. Yamada",
                "Y. Tian",
                "D. Singh",
                "D. Yin",
                "Y. Chang"
            ],
            "title": "GraphLIME: Local interpretable model explanations for graph neural networks",
            "venue": "arXiv:2001.06216, January",
            "year": 2020
        },
        {
            "authors": [
                "T. Chowdhury",
                "R. Rahimi",
                "J. Allan"
            ],
            "title": "Rank-lime: Local model-agnostic feature attribution for learning to rank",
            "venue": "arXiv:2212.12722, Dec",
            "year": 2022
        },
        {
            "authors": [
                "R. Gaudel",
                "L. Galarraga",
                "J. Delaunay",
                "L. Roze",
                "V. Bhargava"
            ],
            "title": "s-lime: Reconciling locality and fidelity in linear explanations",
            "venue": "arXiv:2208.01510, Aug",
            "year": 2022
        },
        {
            "authors": [
                "Heewoo Jun",
                "A. Nichol"
            ],
            "title": "Shap-e: Generating conditional 3d implicit functions",
            "year": 2023
        },
        {
            "authors": [
                "F. Fumagalli",
                "M. Muschalik",
                "P. Kolpaczki",
                "E. Hullermeier",
                "B. Hammer"
            ],
            "title": "Shap-iq: Unified approximation of any-order shapley interactions",
            "venue": "arXiv:2303.01179, Mar",
            "year": 2023
        },
        {
            "authors": [
                "A. Coletta",
                "S. Vyetrenko",
                "T. Balch"
            ],
            "title": "K-shap: Policy clustering algorithm for anonymous multi-agent state-action pairs",
            "venue": "arXiv:2302.11996, Feb",
            "year": 2023
        },
        {
            "authors": [
                "L. Parcalabescu",
                "A. Frank"
            ],
            "title": "Mm-shap: A performance-agnostic metric for measuring multimodal contributions in vision and language models and tasks",
            "venue": "arXiv:2212.08158, Dec",
            "year": 2022
        },
        {
            "authors": [
                "R. Bitto",
                "A. Malach",
                "A. Meiseles",
                "S. Momiyama",
                "T. Araki",
                "J. Furukawa",
                "Y. Elovici",
                "A. Shabtai"
            ],
            "title": "Latent shap: Toward practical human-interpretable explanations",
            "venue": "arXiv:2211.14797, Nov",
            "year": 2022
        },
        {
            "authors": [
                "L. Bouneder",
                "Y. Leo",
                "A. Lachapelle"
            ],
            "title": "X-SHAP: towards multiplicative explainability of machine learning",
            "venue": "arXiv:2006.04574, June",
            "year": 2020
        },
        {
            "authors": [
                "L.V. Utkin",
                "A.V. Konstantinov"
            ],
            "title": "Ensembles of random shaps",
            "venue": "Algorithms, 15(11):431,",
            "year": 2022
        },
        {
            "authors": [
                "T. Hastie",
                "R. Tibshirani"
            ],
            "title": "Generalized additive models, volume 43",
            "venue": "CRC press,",
            "year": 1990
        },
        {
            "authors": [
                "H. Nori",
                "S. Jenkins",
                "P. Koch",
                "R. Caruana"
            ],
            "title": "InterpretML: A unified framework for machine learning interpretability",
            "venue": "arXiv:1909.09223, September",
            "year": 2019
        },
        {
            "authors": [
                "C.-H. Chang",
                "S. Tan",
                "B. Lengerich",
                "A. Goldenberg",
                "R. Caruana"
            ],
            "title": "How interpretable and trustworthy are gams? arXiv:2006.06466",
            "year": 2020
        },
        {
            "authors": [
                "R. Agarwal",
                "N. Frosst",
                "X. Zhang",
                "R. Caruana",
                "G.E. Hinton"
            ],
            "title": "Neural additive models: Interpretable machine learning with neural nets",
            "venue": "arXiv:2004.13912, April",
            "year": 2020
        },
        {
            "authors": [
                "Z. Yang",
                "A. Zhang",
                "A. Sudjianto"
            ],
            "title": "Gami-net: An explainable neural networkbased on generalized additive models with structured interactions",
            "venue": "arXiv:2003.07132, March",
            "year": 2020
        },
        {
            "authors": [
                "J. Chen",
                "J. Vaughan",
                "V.N. Nair",
                "A. Sudjianto"
            ],
            "title": "Adaptive explainable neural networks (AxNNs)",
            "venue": "arXiv:2004.02353v2, April",
            "year": 2020
        },
        {
            "authors": [
                "A. Adadi",
                "M. Berrada"
            ],
            "title": "Peeking inside the black-box: A survey on explainable artificial intelligence (XAI)",
            "venue": "IEEE Access, 6:52138\u201352160,",
            "year": 2018
        },
        {
            "authors": [
                "A.B. Arrieta",
                "N. Diaz-Rodriguez",
                "J. Del Ser",
                "A. Bennetot",
                "S. Tabik",
                "A. Barbado",
                "S. Garcia",
                "S. Gil- Lopez",
                "D. Molina",
                "R. Benjamins",
                "R. Chatila",
                "F. Herrera"
            ],
            "title": "Explainable artificial intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI",
            "venue": "Information Fusion, 58:82\u2013115,",
            "year": 2020
        },
        {
            "authors": [
                "F. Bodria",
                "F. Giannotti",
                "R. Guidotti",
                "F. Naretto",
                "D. Pedreschi",
                "S. Rinzivillo"
            ],
            "title": "Benchmarking and survey of explanation methods for black box models",
            "venue": "Data Mining and Knowledge Discovery,",
            "year": 2023
        },
        {
            "authors": [
                "N. Burkart",
                "M.F. Huber"
            ],
            "title": "A survey on the explainability of supervised machine learning",
            "venue": "Journal of Artificial Intelligence Research, 70:245\u2013317,",
            "year": 2021
        },
        {
            "authors": [
                "D.V. Carvalho",
                "E.M. Pereira",
                "J.S. Cardoso"
            ],
            "title": "Machine learning interpretability: A survey on methods and metrics",
            "venue": "Electronics, 8(832):1\u201334,",
            "year": 2019
        },
        {
            "authors": [
                "A. Cwiling",
                "V. Perduca",
                "O. Bouaziz"
            ],
            "title": "A comprehensive framework for evaluating time to event predictions using the restricted mean survival time",
            "venue": "arXiv:2306.16075, Jun",
            "year": 2023
        },
        {
            "authors": [
                "C. Rudin"
            ],
            "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
            "venue": "Nature Machine Intelligence, 1:206\u2013215,",
            "year": 2019
        },
        {
            "authors": [
                "S. Bobrowski",
                "Hong Chen",
                "M. Doring",
                "U. Jensen",
                "W. Schinkothe"
            ],
            "title": "Estimation of the lifetime distribution of mechatronic systems in the presence of a covariate: A comparison among parametric, semiparametric and nonparametric models",
            "venue": "Reliability Engineering & System Safety,",
            "year": 2015
        },
        {
            "authors": [
                "K.E. Gneyou"
            ],
            "title": "A strong linear representation for the maximum conditional hazard rate estimator in survival analysis",
            "venue": "Journal of Multivariate Analysis, 128:10\u201318,",
            "year": 2014
        },
        {
            "authors": [
                "R. Pelaez",
                "R. Cao",
                "J.M. Vilar"
            ],
            "title": "Nonparametric estimation of the conditional survival function with double smoothing",
            "venue": "Journal of Nonparametric Statistics,",
            "year": 2022
        },
        {
            "authors": [
                "I. Selingerova",
                "S. Katina",
                "I. Horova"
            ],
            "title": "Comparison of parametric and semiparametric survival regression models with kernel estimation",
            "venue": "Journal of Statistical Computation and Simulation, 91(13):2717\u20132739,",
            "year": 2021
        },
        {
            "authors": [
                "G. Tutz",
                "L. Pritscher"
            ],
            "title": "Nonparametric estimation of discrete hazard functions",
            "venue": "Lifetime Data Analysis, 2(3):291\u2013308,",
            "year": 1996
        },
        {
            "authors": [
                "R. Pelaez",
                "R. Cao",
                "J.M. Vilar"
            ],
            "title": "Probability of default estimation in credit risk using a nonparametric approach",
            "venue": "TEST, 30:383\u2013405,",
            "year": 2021
        },
        {
            "authors": [
                "A. Widodo",
                "B.-S. Yang"
            ],
            "title": "Machine health prognostics using survival probability and support vector machine",
            "venue": "Expert Systems with Applications, 38(7):8430\u20138437,",
            "year": 2011
        },
        {
            "authors": [
                "D. Faraggi",
                "R. Simon"
            ],
            "title": "A neural network model for survival data",
            "venue": "Statistics in medicine, 14(1):73\u201382,",
            "year": 1995
        },
        {
            "authors": [
                "S. Kaneko",
                "A. Hirakawa",
                "C. Hamada"
            ],
            "title": "Enhancing the lasso approach for developing a survival prediction model based on gene expression data",
            "venue": "Computational and Mathematical Methods in Medicine, 2015(Article ID 259474):1\u20137,",
            "year": 2015
        },
        {
            "authors": [
                "N. Ternes",
                "F. Rotolo",
                "S. Michiels"
            ],
            "title": "Empirical extensions of the lasso penalty to reduce the false discovery rate in high-dimensional cox regression models",
            "venue": "Statistics in medicine, 35(15):2561\u2013 2573,",
            "year": 2016
        },
        {
            "authors": [
                "C. Pachon-Garcia",
                "C. Hernandez-Perez",
                "P. Delicado",
                "V. Vilaplana"
            ],
            "title": "SurvLIMEpy: A python package implementing SurvLIME",
            "venue": "arXiv:2302.10571, Feb",
            "year": 2023
        },
        {
            "authors": [
                "L.V. Utkin",
                "E.D. Satyukov",
                "A.V. Konstantinov"
            ],
            "title": "SurvNAM: The machine learning survival model explanation",
            "venue": "Neural Networks, 147:81\u2013102,",
            "year": 2022
        },
        {
            "authors": [
                "M. Peroni",
                "M. Kurban",
                "Sun Young Yang",
                "Young Sun Kim",
                "Hae Yeon Kang",
                "Ji Hyun Song"
            ],
            "title": "Extending the neural additive model for survival analysis with ehr data",
            "year": 2022
        },
        {
            "authors": [
                "Xinxing Wu",
                "Chong Peng",
                "R. Charnigo",
                "Qiang Cheng"
            ],
            "title": "Explainable censored learning: Finding critical features with long term prognostic values for survival",
            "venue": "prediction. arXiv:2209.15450,",
            "year": 2022
        },
        {
            "authors": [
                "A. Moncada-Torres",
                "M.C. van Maaren",
                "M.P. Hendriks",
                "S. Siesling",
                "G. Geleijnse"
            ],
            "title": "Explainable machine learning can outperform cox regression predictions and provide insights in breast cancer survival",
            "venue": "Scientific reports,",
            "year": 2021
        },
        {
            "authors": [
                "F. Harrell",
                "R. Califf",
                "D. Pryor",
                "K. Lee",
                "R. Rosati"
            ],
            "title": "Evaluating the yield of medical tests",
            "venue": "Journal of the American Medical Association, 247:2543\u20132546,",
            "year": 1982
        },
        {
            "authors": [
                "H. Uno",
                "Tianxi Cai",
                "M.J. Pencina",
                "R.B. D\u2019Agostino",
                "Lee-Jen Wei"
            ],
            "title": "On the c-statistics for evaluating overall adequacy of risk prediction procedures with censored survival data",
            "venue": "Statistics in medicine,",
            "year": 2011
        },
        {
            "authors": [
                "C.G. Broyden"
            ],
            "title": "The convergence of a class of double rank minimization algorithms: 2",
            "venue": "the new algorithm. Journal of the Institute of Mathematics and its Applications, 6:222\u2013231,",
            "year": 1970
        },
        {
            "authors": [
                "R. Fletcher"
            ],
            "title": "A new approach to variable metric algorithms",
            "venue": "The Computer Journal, 13:317\u2013322,",
            "year": 1970
        },
        {
            "authors": [
                "D. Goldfarb"
            ],
            "title": "A family of variable metric methods derived by variational means",
            "venue": "Mathematics of Computation, 24:23\u201326,",
            "year": 1970
        },
        {
            "authors": [
                "D.F. Shanno"
            ],
            "title": "Conditioning of quasi-newton methods for function minimization",
            "venue": "Mathematics of Computation, 24:647\u2013650,",
            "year": 1970
        },
        {
            "authors": [
                "R. Bender",
                "T. Augustin",
                "M. Blettner"
            ],
            "title": "Generating survival times to simulate cox proportional hazards models",
            "venue": "Statistics in Medicine, 24(11):1713\u20131723,",
            "year": 2005
        },
        {
            "authors": [
                "J. Kalbfleisch",
                "R. Prentice"
            ],
            "title": "The Statistical Analysis of Failure Time Data",
            "venue": "John Wiley and Sons, New York,",
            "year": 1980
        },
        {
            "authors": [
                "W. Sauerbrei",
                "P. Royston"
            ],
            "title": "Building multivariable prognostic and diagnostic models: transformation of the predictors by using fractional polynomials",
            "venue": "Journal of the Royal Statistics Society Series A, 162(1):71\u201394,",
            "year": 1999
        }
    ],
    "sections": [
        {
            "text": "Keywords: interpretable model, explainable AI, LIME, survival analysis, censored data, the Beran estimator, the Cox model."
        },
        {
            "heading": "1 Introduction",
            "text": "Censored survival data can be met in many applications, including medicine, the system reliability and safety, economics [1, 2]. They consider times to an event of interest as observations. The event might not have happened during the period of study [3]. If the observed survival time is less than or equal to the true survival time, then the corresponding data is censored and called right-censoring data. Machine learning models dealing the survival data are based on applying the framework and concepts of survival analysis and conditionally divided into parametric, nonparametric and semiparametric models [2].\nThere are different methods for constituting machine learning survival models. We consider models which depend on the feature vectors characterizing objects, whose times to an event are studied, for example, patients, the system structures, Many survival models are based on using the Cox proportional hazard method or the Cox model [4], which calculates effects of observed covariates on the risk of an event occurring under condition that a linear combination of the instance covariates is assumed in the model. The success of the Cox model in many applied tasks motivated to generalize\nar X\niv :2\n30 8.\n03 73\n0v 1\n[ cs\n.L G\n] 7\nthe model in order to consider non-linear functions of covariates or several regularization constraints for the model parameters [5, 6, 7, 8]. To improve survival analysis and to enhance the prediction accuracy of the machine learning survival models, other approaches have been developed, including the SVM approach [9], random survival forests (RSF) [10, 11, 12, 13, 14], survival neural networks [5, 6, 15, 8].\nThe most survival models can be regarded as black-box models because details of their functioning are often completely unknown, but their inputs as well as outcomes may be known for users. As a results, it is difficult to explain how a prediction corresponding to a certain input is achieved, which features of the input significantly impact on the prediction. However, the explanation of predictions should be an important component of intelligent systems especially in medicine [16] where a doctor has to understand why the used machine learning diagnostic model states a diagnosis. At present, there are many methods which can explain predictions of black-box models \u2018[17, 18, 19, 20]. According to these methods, the explanation means to assign numbers to features, which quantify the feature impacts on the prediction. The methods can be divided into local and global explanation methods. Local methods produce explanation locally around an explained example whereas global methods explain the black-box model for the whole dataset.\nAn important local explanation method is the Local Interpretable Model-agnostic Explanations (LIME) [21], which explains predictions of a black-box model approximating a model function at a point by the linear model where coefficients of the linear model can be regarded as the quantified representation of the feature impacts on the prediction [22]. According to LIME, the linear model is constructed by generating randomly synthetic examples around the explained example. It should be noted that the idea to approximate the black-box model function at a point by the linear surrogate model is fruitful and can be applied to many classification and regression tasks.\nIn most applications, LIME deals with point-valued predictions. However, predictions of the survival machine learning models are functions, for example, the survival function (SF), the cumulative hazard function (CHF). In other words, explanation methods should explain which features have the significant impact on the form of the SF corresponding to some input object. To take into account peculiarities of the survival models, a series of the LIME modifications dealing with survival data and models and called SurvLIME have been presented in [23, 24, 25]. The main idea behind the SurvLIME is to approximate the black-box model at a point by the Cox model which is based on the linear combination of covariates. Coefficients of the linear combination can be viewed as measures of the covariate impact on the prediction in the form of the SF or the CHF.\nMany numerical experiments have shown that the proposed SurvLIME models provide satisfactory results. However, limitations of the Cox model motivated to search for a more adequate model which could improve the explanation of survival models. One of the interesting model is the Beran estimator [26] which can be regarded as a kernel regression for computing the SF taking into account the data structure. However, the original Beran estimator does not contain linear combinations of covariates, which are needed to develop the linear approximation like the Cox model. Therefore, we proposed to modify the Beran estimator by incorporating a vector whose elements can be viewed as the feature impacts on the prediction. The proposed explanation model using the modified Beran estimator is called SurvBeX (Survival Beran eXplanation). It is similar to SurvLIME, but, in contrast to SurvLIME, it has several specific elements which distinguish SurvBeX from SurvLIME. Moreover, SurvBeX is more flexible because it has many opportunities for modifications. For example, it can be studied with different kernels which are important elements of the Beran estimator.\nOur contributions can be summarized as follows:\n1. A new method for explaining predictions of machine learning survival models based on applying\nthe modification of the Beran estimator is proposed.\n2. An algorithm implementing the method based on solving an unconstrained optimization problem is proposed.\n3. Various numerical experiments compare the method with the well-known survival explanation method called SurvLIME under condition of using different black-box survival models, including the Cox model, the RSF, and the Beran estimator. SurvBeX is also compared with a very interesting method based on the survival extension of the method SHAP [27, 28], which is called SurvSHAP(t) [29]. The corresponding code implementing the proposed method is publicly available at: https://github.com/DanilaEremenko/SurvBeX.\nNumerical results show that SurvBeX provides outperforming results in comparison with SurvLIME and SurvSHAP(t).\nThe paper is organized as follows. Related work can be found in Section 2. A short description of basic concepts of survival analysis and the explanation methods, including the Cox model, the original Beran estimator, LIME, SurvLIME, is given in Section 3. A general idea of SurvBeX is provided in Section 4. The formal derivation of the optimization problem for implementing SurvBeX and its simplification can be found in Section 5. Numerical experiments with synthetic data are provided in Section 6. Similar numerical experiments with real data are given in Section 7. Concluding remarks are provided in Section 8."
        },
        {
            "heading": "2 Related work",
            "text": "Local explanation methods. Due to the importance of explaining and interpreting the machine learning model predictions, many local explanation methods have been developed and studied. First of all, we have to point out the original LIME [21] and its various modifications, including ALIME [30], NormLIME [31], DLIME [32], Anchor LIME [33], LIME-SUP [34], LIME-Aleph [35], GraphLIME [36], Rank-LIME [37], s-LIME [38].\nAlong with LIME, another method of local explanation, called SHAP [28], is also actively used. It is based on applying a game-theoretic approach for optimizing a regression loss function using Shapley values [27]. Due to the strong theoretical justification of SHAP, a lot of its modifications also have been proposed, for example, SHAP-E [39], SHAP-IQ [40], K-SHAP [41], MM-SHAP [42], Latent SHAP [43], X-SHAP [44], Random SHAP [45].\nAnother interesting class of explanation methods is based on using ideas behind the Generalized Additive Model (GAM) [46]. Following this mode, the explainable boosting machine was proposed in [47] and [48]. Another model based on GAM is the Neural Additive Model (NAM) was proposed in [49]. NAM can be viewed as a neural network implementation of GAM where the network consists of a linear combination of \u201csmall\u201d neural subnetworks having single inputs corresponding to each feature, i.e. a single feature is fed to each subnetwork producing a shape function of a feature. Similar approaches using neural networks for implementing GAM and performing shape functions called GAMI-Net and the Adaptive Explainable Neural Networks (AxNNs) were proposed in [50] and [51], respectively,\nCritical and comprehensive surveys devoted to the local explanation methods can be found in [52, 53, 54, 55, 56, 57, 18, 19, 20, 58].\nMachine learning models in survival analysis. Many machine learning models have the survival extension, i.e. they are modified in order to deal with survival data or with censored data.\nA detailed review of survival models is presented in [2]. The survival machine learning models can be divided into three groups. The first group consists of models which are based on the well-known statistical models, including the Cox model, The Kaplan-Meier models, etc. Several models from the first group use the Nadaraya-Watson regression for estimating SFs and other concepts of survival analysis [59, 60, 61, 62, 63]. Kernel-based estimators of SFs in survival analysis are studied in [64]. The second group consists of models which mainly adapt the original machine learning models to survival data. These are the SVM approach [65], the random survival forests [10, 13, 14], survival neural networks [6, 15]. The third group is some combinations of the models from the first and the second groups. Examples of these models are modifications of the Cox model relaxing the linear relationship assumption accepted in the Cox model, including neural networks instead of the linear relationship [66, 5], the Lasso modifications [67, 68, 7].\nMost aforementioned survival models can be viewed as black-box models whose predictions should be explained in many applications. This motivates to develop the explanation methods which deal with survival data.\nExplanation methods in survival analysis. One of the problems encountered the local explanation in survival analysis is to explain the function-valued predictions instead of the point-valued predictions which are explained by many methods. In survival analysis, predictions are usually SFs or CHFs which are functions of time. A new approach to deal with function-valued predictions is SurvLIME [23, 24, 25]. Its modification and the corresponding software is called SurvLIMEpy [69]. An extension to SurvLIME called SurvNAM has been proposed in [70]. SurvNAM can be also viewed as an extension to NAM [49]. An extension of the NAM for survival analysis with EHR Data was presented in [71].\nA novel, easily deployable approach, called EXplainable CEnsored Learning, to iteratively exploit critical variables in the framework of survival analysis was developed in [72]. The authors of this work aim to find critical features with long-term prognostic values. The explainable machine learning, which provides insights in breast cancer survival, is considered in [73]. An interesting extension of the SHAP to its application in survival analysis, called SurvSHAP(t) has been proposed in [29]. The authors of the work introduce the first time-dependent explanation for interpreting machine learning survival models. The important feature of the SurvSHAP(t) method is that it explains the predicted SF."
        },
        {
            "heading": "3 Elements of survival analysis",
            "text": ""
        },
        {
            "heading": "3.1 Basic concepts",
            "text": "An example (object) in survival analysis is usually represented by a triplet (xi, \u03b4i, Ti), where x T i = (xi1, ..., xid) is the vector of the example features; Ti is time to event of interest for the i-th example. If the event of interest is observed, then Ti is the time between a baseline time and the time of event happening. In this case, an uncensored observation takes place and \u03b4i = 1. Another case is when the event of interest is not observed. Then Ti is the time between the baseline time and the end of the observation. In this case, a censored observation takes place and \u03b4i = 0. There are different types of censored observations. We will consider only right-censoring, where the observed survival time is less than or equal to the true survival time [1]. Given a training set A consisting of n triplets (xi, \u03b4i, Ti), i = 1, ..., n, the goal of survival analysis is to estimate the time to the event of interest T for a new example x by using A.\nKey concepts in survival analysis are SFs, hazard functions, and the CHF, which describe prob-\nability distributions of the event times. The SF denoted as S(t|x) is the probability of surviving up to time t, that is S(t|x) = Pr{T > t|x}. The hazard function h(t|x) is the rate of the event at time t given that no event occurred before time t. The hazard function can be expressed through the SF as follows [1]:\nh(t|x) = \u2212 d dt lnS(t|x). (1)\nThe CHF denoted as H(t|x) is defined as the integral of the hazard function h(t|x) and can be interpreted as the probability of the event at time t given survival until time t, that is\nH(t|x) = \u222b t \u2212\u221e h(z|x)dz. (2)\nAn important relationship between the SF and the CHF is\nS(t|x) = exp (\u2212H(t|x)) . (3)\nTo compare survival models, the C-index proposed by Harrell et al. [74] is used. It estimates how good a survival model is at ranking survival times. It estimates the probability that, in a randomly selected pair of examples, the example that fails first had a worst predicted outcome. In fact, this is the probability that the event times of a pair of examples are correctly ranking.\nC-index has different forms. One of the forms is [75]:\nC = \u2211 i,j 1[Ti < Tj ] \u00b7 1[T\u0302i < T\u0302j ] \u00b7 \u03b4i\u2211\ni,j 1[Ti < Tj ] \u00b7 \u03b4i ,\nwhere T\u0302i and T\u0302j are the predicted survival durations."
        },
        {
            "heading": "3.2 The Cox model",
            "text": "The Cox proportional hazards model is used as an important component in SurvLIME. Therefore, we provide some details of the model. According to the Cox model, the hazard function at time t given vector x is defined as [4, 1]:\nh(t|x,b) = h0(t) exp ( bTx ) . (4)\nHere h0(t) is a baseline hazard function which does not depend on the vector x and the vector b; bT = (b1, ..., bm) is an unknown vector of the regression coefficients or the model parameters. The baseline hazard function represents the hazard when all of the covariates are equal to zero.\nThe SF in the framework of the Cox model is S(t|x,b) = exp(\u2212H0(t) exp ( bTx ) ) = (S0(t)) exp(bTx) . (5)\nHere H0(t) is the baseline CHF; S0(t) is the baseline SF which is defined as the survival function for zero feature vector xT = (0, ..., 0). The baseline SF and CHF do not depend on x and b.\nOne of the ways to compute the parameters b is to use the partial likelihood defined as follows [4]:\nL(b) = n\u220f j=1\n[ exp(bTxj)\u2211\ni\u2208Rj exp(b Txi)\n]\u03b4j , (6)\nwhere Rj is the set of objects which are at risk at time tj . The term \u201cat risk at time t\u201d means objects for which the event of interest happens at time t or later. Only uncensored observations are used in the likelihood function."
        },
        {
            "heading": "3.3 The Beran estimator",
            "text": "Given the dataset A, the SF can be estimated by using the Beran estimator [26] as follows:\nSB(t|x,A) = \u220f ti\u2264t\n{ 1\u2212 \u03b1(x,xi)\n1\u2212 \u2211i\u22121\nj=1 \u03b1(x,xj)\n}\u03b4i , (7)\nwhere time moments are ordered; the weight \u03b1(x,xi) conforms with relevance of the i-th example xi to the vector x and can be defined through kernels as\n\u03b1(x,xi) = K(x,xi)\u2211n j=1 K(x,xj) . (8)\nIf we use the Gaussian kernel, then the weights \u03b1(x,xi) are of the form:\n\u03b1(x,xi) = softmax\n( \u2212\u2225x\u2212 xi\u2225 2\n\u03c4\n) , (9)\nwhere \u03c4 is a tuning (temperature) parameter. Below another representation of the Beran estimator will be used:\nSB(t|x,A) = \u220f ti\u2264t\n{ 1\u2212 \u2211i j=1 \u03b1(x,xj)\n1\u2212 \u2211i\u22121\nj=1 \u03b1(x,xj)\n}\u03b4i . (10)\nThe Beran estimator can be regarded as a generalization of the Kaplan-Meier estimator [2] because it is reduced to the Kaplan-Meier estimator if the weights \u03b1(x,xi) take values \u03b1(x,xi) = 1/n for all i = 1, ..., n. The product in (7) takes into account only uncensored observations whereas the weights are normalized by using uncensored as well as censored observations."
        },
        {
            "heading": "3.4 LIME",
            "text": "LIME aims to approximate a black-box model implementing a function q(x) by a linear function g(x) in the vicinity of the explained point x [21]. Generally, the function g(x) may be arbitrary from a set G of explainable functions. LIME proposes to perturb new examples and obtain the corresponding predictions for the examples by means of the black-box model. This set of the examples jointly with the predictions forms a dataset for learning the function g(x). To take into account different distances from x and the generated examples, weights wx are assigned in accordance with the distances by using a kernel function.\nAn explanation (local surrogate) model is trained by solving the following optimization problem:\nargmin g\u2208G L(q, g, wx) + \u03a6(g). (11)\nHere L is a loss function, for example, mean squared error (MSE), which measures how the explanation is close to the prediction of the black-box model; \u03a6(g) is the model complexity.\nIf g(x) is linear, then the corresponding prediction is explained by analyzing values of coefficients of g(x)."
        },
        {
            "heading": "3.5 SurvLIME",
            "text": "SurvLIME is a modification of LIME when the black-box model is survival [23]. In contrast to the original LIME, SurvLIME approximates the black-box model with the Cox model.\nSuppose there is a training set A and a black-box model. The model prediction is represented in the form of the CHF H(t|x) for every new example x. SurvLIME approximates the black-box model prediction by the Cox model prediction with the CHF HCox(t|x,b). Values of parameters b can be regarded as quantitative impacts on the prediction H(t|x). They are unknown and have to be found by means of the approximation of models. Optimal coefficients b make the distance between CHFs H(t|x) and HCox(t|x,b) for the example x as small as possible.\nIn order to implement the approximation at point x, many nearest examples xk are generated in a local area around x. The CHF H(t|xk) predicted by the black-box model is computed for every generated xk. Optimal values of b can be found by minimizing the weighted average distance between every pair of CHFs H(t|xk) and HCox(t|xk,b) over all generated points xk. Weight wk depends on the distance between points xk and x. Smaller distances between xk and x define larger weights of distances between CHFs. The distance metric between CHFs defines the corresponding optimization problem for computing optimal coefficients b. Therefore, SurvLIME [23] uses the l2-norm applied to logarithms of CHFs H(t|xk) and HCox(t|xk,b), which leads to a simple convex optimization problem with variables b.\nOne of the limitations of SurvLIME is caused by the underlying Cox model: even in small neighborhoods in the feature space, the proportional hazards assumption may be violated, leading to an inaccurate surrogate model. Another limitation is the linear relationship of covariates in the Cox model, which may be a reason for the inadequate approximation of black-box models by SurvLIME. In order to overcome the aforementioned SurvLIME drawbacks, it is proposed to replace the Cox model by the Beran estimator for explaining predictions produced by a black-box. In other words, it is proposed to approximate the prediction of the black-box model by means of the Beran estimator."
        },
        {
            "heading": "4 A general idea of SurvBeX",
            "text": "Given a training set A and a black-box model which is explained, for every new example x, the blackbox model produces the corresponding output in the form of the SF S(t|x). A general algorithm of SurvBeX is similar to SurvLIME. Suppose we have a new example x and the black-box produces a prediction in the form of SF S(t|x). Let us incorporate parameters b = (b1, ..., bd) into the Beran estimator (7) as follows:\n\u03b1(x,xi,b) = softmax\n( \u2212\u2225b\u2299 (x\u2212 xi)\u2225 2\n\u03c4\n) . (12)\nHere b\u2299 x is the dot product of two vectors. It can be seen from the above that each element of b can be regarded as the quantitative impact of the corresponding feature on the prediction SB(t|x) which will be denoted as SB(t|x,b) to indicate the dependence of the SF on parameters b. If we approximate the function S(t|x) by the function SB(t|x,b), then coefficients b show which features in x are the most important. Actually, elements of b weigh the difference between features xj and xij of vectors x and xi, respectively. However, it follows from the Beran estimator that the predicted SF SB(t|x) depends on differences of vectors x and xi, but not on the vector x itself. Therefore, we use the above representation for \u03b1(x,xi,b) in (7).\nThe remaining part of the algorithm does not substantially differ from SurvLIME. Suppose that the black-box model has been trained on the dataset A. In order to find vector b in accordance with LIME or SurvLIME, we generate N points z1, ..., zN in a local area around x. Different notations for training and generated examples are used in order to distinguish the corresponding sets of data. In contrast to vectors x1, ...,xn from A, which train the black-box model and the Beran estimator, points zk can be viewed as tested examples for the black-box model and for the Beran estimator. For every point zk, the SF S(t|zk) is determined as a prediction of the black-box model. The SF SB(t|zk,b) is represented by using (7) as a function of the parameter vector b which is unknown at this stage. So, we obtain N SFs S(t|zk) and the same number of SFs SB(t|zk,b). It is important to note that the Beran estimator uses the training dataset A to make predictions for the generated points zk.\nIn order to approximate functions S(t|zk) and SB(t|zk,b) and to compute the vector b, we minimize the average distance between the functions over the vector b. The solution to the optimization problem is the optimal vector bopt which explains the prediction S(t|x) corresponding to the example x. At that, we additionaly assign weights w1, ..., wN to examples z1, ..., zN such that the weight wk is defined by the distance between vectors zk and x. Smaller distances between zk and x produce larger weights of distances between SFs S(t|zk) and SB(t|zk,b). Weights can be calculated by using the standard normalized kernel K\u2217(zk,x). It should distinguish kernels K\n\u2217 and K. The kernel K\u2217 is for computing weights of generated examples, but the kernel K is for computing weights \u03b1(x,xi,b) from the Beran estimator. Weights wk are defined in the same way as in LIME.\nA general scheme of SurvBeX is depicted in Fig. 1. It can be seen from Fig. 1 that two models (the trained black-box survival model and the extended Beran estimator with parameters b) produce SFs corresponding to the generated points z1, ..., zN . Moreover, SFs produced by the Beran estimator can be regarded as a family of functions parametrized by b. They are obtained in the implicit form as functions of b. The objective function for computing bopt is the weighted average distance between SFs S(t|zk) and SB(t|zk,b).\nOnly an idea of SurvBeX is presented above. A formal description of the method which contains details of its implementation is provided in the next section."
        },
        {
            "heading": "5 Formal optimization problem statement",
            "text": "According to the general description of SurvBeX, N examples are randomly generated with weights wj to construct an approximation of the predicted SF by the SF estimated by means of the Beran estimator at point x. If we have the set A of n training examples (xi, \u03b4i, Ti) and the set of N generated feature vectors zj in a local area around the explained example x, then the objective function of the optimization problem for computing optimal vector b is the weighted average distance between N pairs of SFs S(t|zj) and SB(t|zj ,b), with weights wj , j = 1, ..., N , which can be written as follows:\nmin b\n1\nN N\u2211 j=1 wj \u00b7D (S(t|zj), SB(t|zj ,b)) . (13)\nHere D (\u00b7, \u00b7) is a distance between two functions. Since many distance metrics are based on the norms ls, s = 1, ...,\u221e, then we can rewrite the optimization problem for these distance metrics\nmin b\n1\nN N\u2211 j=1 wj \u2225S(t|zj)\u2212 SB(t|zj ,b)\u2225ss , (14)\nwhich in the case of finite s is equivalent to\nmin b N\u2211 j=1 wj \u222b \u221e 0 |S(t|zj)\u2212 SB(t|zj ,b)|s . (15)\nLet t0 < t1 < ... < tn be ordered times to an event of interest from the set {T1, ..., Tn}, where t0 = 0 and tn = maxk=1,...,n Tk. It is assumed that all times are different. The times t0, t1, ..., tn split the interval \u2126 = [t0, tn] into n non-intersecting subintervals \u21261, ...,\u2126n such that \u2126k = [tk\u22121, tk), k = 1, ..., n.\nThe black-box model maps the feature vectors x \u2208 Rd into piecewise constant SF S(t|x) which can be represented as the sum\nS(t|x) = n\u2211\nk=1\nS(k)(x) \u00b7 \u03c7\u2126k(t), (16)\nwhere \u03c7\u2126k(t) is the indicator function taking value 1 if t \u2208 \u2126k, and value 0 if t /\u2208 \u2126k; S(k)(x) is the SF for t \u2208 \u2126k.\nThe same representation can be written for the SF SB(t|x,b) as well as for the difference of the SFs. We also assume that S(t|x) = 0 for t > tn. Then the objective function in the optimization problem for computing b can be formulated as\nN\u2211 j=1 wj \u222b \u2126 |S(t|zj)\u2212 SB(t|zj ,b)|s\n= N\u2211 j=1 wj n\u2211 i=1 \u2223\u2223\u2223S(i)(zj)\u2212 S(i)B (zj ,b)\u2223\u2223\u2223s (ti \u2212 ti\u22121) . (17) Similarly, we can state a problem to minimize the difference between logarithms of SFs in order to simplify the optimization problem. Let us introduce the condition S(i)(x) \u2265 \u03b5 > 0 for all i = 1, ..., n. Then the optimizatin problem can also be formulated through logarithms:\nb = argmin b N\u2211 j=1 wj n\u2211 i=1 \u2223\u2223\u2223lnS(i)(zj)\u2212 lnS(i)B (zj ,b)\u2223\u2223\u2223s (ti \u2212 ti\u22121) , (18) where\nlnS (i) B (zj ,b) = \u2211 tl\u2264ti \u03b4l\n[ ln ( 1\u2212\nl\u2211 k=1 \u03b1(zj ,xk)\n) \u2212 ln ( 1\u2212\nl\u22121\u2211 k=1 \u03b1(zj ,xk)\n)] . (19)\nThe unconstrained optimization problem has been obtained, which can be solved by means of a gradient-based algorithm. The weight is defined as wj = K \u2217(x, zj), where K \u2217(\u00b7, \u00b7) is a kernel function which measures how similar two feature vectors. For example, if to use the Gaussian kernel, then the weight is defined as\nwj = exp ( \u2212\u2225x\u2212 zj\u22252 /\u03c3 ) , (20)\nwhere \u03c3 is the kernel parameter. It should be noted that we use two different kernels. The first one is used for computing weights \u03b1(x,xi) in the Beran estimator. The second kernel is used to find weights wj of the generated points in a local area around the explained example. The kernels also have different parameters.\nAlgorithm 1 The algorithm implementing SurvBeX for computing vector b of the feature importance for point x Require: Training set A; point of interest x; the number of generated points N ; parameters of kernels \u03c4 and \u03c3. Ensure: Vector b of important features of x. 1: Generate N random points zk in a local area around x. 2: Find predictions of SFs S(t|zj), j = 1, ..., N , produced by the black-box survival model. 3: Compute weights wj = K\n\u2217(x, zj) of generated points, j = 1, ..., N , by using (20). 4: Construct the optimization problem (17) by using (19) and (7) with weights \u03b1(x,xi,b) expressed\nthrough (12). 5: Find vector b by solving the optimization problem (17) using the gradient-based algorithm.\nFinally, we write Algorithm 1 implementing the proposed explanation method. If to use the logarithmic representation (18), then the computational difficulties of calculating the logarithm of the SF produced by the Beran estimator can be simplified. The idea behind the simplification is to use the series expansion of the logarithm as ln(1\u2212 x) \u2248 \u2212x\u2212 x2/2. Let us denote \u03b1(x,xj) = \u03b1j for short. By using the series expansion of the logarithm, we can rewrite the i-th term in (19) as follows:\nln 1\u2212 i\u2211 j=1 \u03b1j \u2212 ln 1\u2212 i\u22121\u2211 j=1 \u03b1j  \u2248 \u2212\ni\u2211 j=1 \u03b1j \u2212 1 2  i\u2211 j=1 \u03b1j 2 + i\u22121\u2211 j=1 \u03b1j + 1 2 i\u22121\u2211 j=1 \u03b1j 2\n= \u2212\u03b1i \u2212 1\n2  i\u2211 j=1 \u03b1j \u2212 i\u22121\u2211 j=1 \u03b1j  i\u2211 j=1 \u03b1j + i\u22121\u2211 j=1 \u03b1j  = \u2212\u03b1i \u2212 1\n2 \u03b1i \u03b1i + 2 i\u22121\u2211 j=1 \u03b1j  = \u2212\u03b1i 1\u2212 1 2 \u03b1i + i\u2211 j=1 \u03b1j  . (21) Hence, we obtain\nlnSB(t|x,b) \u2248 \u2212 \u2211\nti\u2264t \u03b4i \u00b7 \u03b1(x,xi)\n\u00d7 1\u2212 1 2 \u03b1(x,xi) + i\u2211 j=1 \u03b1(x,xj)  . (22) At the same time, another problem of using the logarithm of the SF is its extremely small negative values when SB is close to 0. In order to overcome this difficulty, the SF SB should be restricted by some positive small value \u03b5."
        },
        {
            "heading": "6 Numerical experiments with synthetic data",
            "text": "In order to study the proposed explanation algorithm, we generate random survival times to events by using the Cox model estimates to have a groundtruth vector of parameters b. This allows us to compare different explanation methods.\nAs black-box models, we use the Cox model, the RSF [10] and the Beran estimator. The RSF consists of 100 decision survival trees. The number of features selected to build each tree in RSF is\u221a d. The largest depth of each tree is 8. The log-rank splitting rule is used. The Gaussian kernels with the parameter (the width), which is equal to 1/250, is used in the Beran estimator. The main reason for using the Cox model as a black box is to check whether the selected important features explaining the SF at the explained point x coincide with the corresponding features accepted in the Cox model for generating training set. It should be noted that the Cox model as well as the RSF are viewed as black-box models whose predictions (CHFs or survival functions) are explained.\nThe well-known Broyden\u2013Fletcher\u2013Goldfarb\u2013Shanno (BFGS) algorithm [76, 77, 78, 79] is used to solve the optimization problem (17).\nTwo kernels as used in the Beran estimator incorporated into SurvBeX: the standard Gaussian with the parameter \u03c4 taking values 10 or 100 and the kernel of the form:\nK (x,xi) = exp\n( |x\u2212 xi|\n\u03c4\n) ."
        },
        {
            "heading": "6.1 Generation of random covariates, survival times and perturbations",
            "text": "In order to evaluate SurvBeX and to compare it with SurvLIME, we use synthetic data. Two types of generated datasets are studied. The first one contains examples which are concentrated around one center. Each feature of a point x \u2208 Rd is randomly generated from the uniform distribution around the center p with radius R.Random survival times in accordance with the Cox model are generated by applying the method proposed in [80]. According to [80], generated survival times have the Weibull distribution with the scale \u03bb and shape v parameters. The use of the Weibull distribution is justified by the fact that the Weibull distribution supports the assumption of proportional hazards [80]. If we denote the random variable uniformly distributed in interval [0, 1] as U , then the random survival time is generated as follows [80]:\nT =\n( \u2212 ln(U)\n\u03bb exp(btruexT)\n)1/v . (23)\nHere the vector btrue = (btrue1 , ..., b true d ) is the vector of known coefficients that are set in advance to generate data. Numerical experiments are performed under condition of different numbers d of features, which are d = 5, d = 10, and d = 20. Parameters of the generation for every number of features are the following:\n1. d = 5: btrue = (0.5, 0.25, 0.12, 0, 0);\n2. d = 10: btrue = (0.6, 0.3, 0.1, 0, 0, ..., 0);\n3. d = 20: btrue = (0.5, 0.25, 0.12, 0, 0, ..., 0);\nThe vectors btrue are chosen in such a way that the feature importance values differ significantly. This will make it easier to compare the feature importance for different models. Parameters of the Weibull distribution for generating survival times are \u03bb = 10\u22125, v = 2. The number of generated points (xi, \u03b4i, Ti) in the dataset is n = 200. The center of the single cluster is p = (0.5, 0.5, 0.5, 0.5), the radius is R = 0.5.\nThe number of generated points around an explained example z is N = 100. These points are generated in accordance with the normal distribution with the expectation z (the explained example) with the standard deviation 0.4 \u00b7 0.5. Weights wj are assigned to every generated point by using the Gaussian kernel with the parameter \u03c3 = 0.4. An example of the one-cluster data structure generated in accordance with the above parameters by using the t-SNE method is depicted in Fig.2.\nThe second type of generated datasets consists of two clusters with different centers p(1) and p(2) of feature vectors and different vectors of the Cox model coefficients btrue1 and b true 2 . The reason for using such a two-cluster data structure is to try to complicate the Cox model data structure. If examples are distributed according to the Cox model, then it is likely that the Cox explanation model underlying SurvLIME will provide a more accurate explanation than SurvBeX. Therefore, it is proposed to use two data clusters for a correct comparison of the models.\nParameters of the cluster generation also depend on the number of features d. For the numbers of features d = 5, d = 10, and d = 20, they are\n1. d = 5:\n(a) btrue1 = (0.5, 0.25, 0.12, 0, 0); (b) btrue2 = (0, 0, 0.12, 0.25, 0.5);\n2. d = 10:\n(a) btrue1 = (0.6, 0.3, 0.1, 0, 0, ..., 0); (b) btrue2 = (0, 0, ..., 0, 0.1, 0.3, 0.6);\n3. d = 20:\n(a) btrue1 = (0.5, 0.25, 0.12, 0, 0, ..., 0); (b) btrue2 = (0, 0, ..., 0, 0.12, 0.25, 0.5).\nThe following parameters for points of every cluster are used:\n1. cluster 1: center p(1) = (0.25, 0.25, 0.25, 0.25, 0.25); radius R = 0.2; the number of points in the cluster n = 200;\n2. cluster 2: center p(2) = (0.75, 0.75, 0.75, 0.75); radius R = 0.2; the number of points in the cluster n = 200.\nParameters of the Weibull distribution for generating survival times are \u03bb = 10\u22125, v = 2. The total number of generated points (xi, \u03b4i, Ti) in the dataset consisting of two clusters is n = 400. The total number of generated points around an explained example is N = 100. Parameters of the generation are the same as in experiments with one cluster. An example of the two-cluster data structure generated in accordance with the above parameters by using the t-SNE method is depicted in Fig.3."
        },
        {
            "heading": "6.2 Measures for comparison the models",
            "text": "To compare different models (SurvLIME and SurvBeX), we use the following three measures:\nD(bmodel,btrue) = \u2225\u2225bmodel \u2212 btrue\u2225\u22252 ,\nKL(bmodel,btrue) = n\u2211 i=1 btruei ln btruei bmodeli ,\nC(bmodel,btrue) =\n\u2211 i,j 1[b true i < b\ntrue j ] \u00b7 1[bmodeli < bmodelj ]\u2211\ni,j 1[b true i < b true j ]\n.\nThe first measure represents the Euclidean distance between the two vectors bmodel and btrue, where the vector bmodel is obtained by SurvLIME and SurvBeX. The vectors bmodel and btrue are normalized. Therefore, they can be regarded as the probability distributions and the Kullback\u2013Leibler divergence (KL) can be applied to analyze the difference between the vectors, which is used as the second measure. The third measure is the C-index applied to the vectors bmodel and btrue. It estimates the probability that any pair of vectors bmodel and btrue are correctly ranking. It should be noted that the third index is the most informative because it estimates the relationship between elements of two vectors. The Euclidean distance and the KL-divergence show how the vectors are close to each other, but they do not show the relationship between elements of two vectors. Nevertheless, these measures can be also useful when the models are compared.\nIn order to study how SFs predicted by using different methods, including the black-box, SurvLIME, and SurvBeX, are close to each other, we use the following distance measure:\nD(S, SB\u2212B) = n\u2211 i=1 ( S(i)(z)\u2212 S(i)B\u2212B(z) )2 (ti \u2212 ti\u22121) , (24)\nwhere S(i)(z) is the SF predicted by SurvLIME or SurvBeX for the explained point z in the time interval [ti\u22121, ti]; S (i) B\u2212B is the SF predicted by the black-box model in the same time interval.\nWhen M points are used for explanation, then the mean values of the above measures are computed: mean squared distance (MSD), which can be viewed as an analog of the mean squared error (MSE), mean KL-divergence (MKL), mean C-index (MCI), and mean SF distance (MSFD). The above measures are computed similarly, for example, the MSD is determined as\nMSD = 1\nM M\u2211 i=1 D(bmodeli ,b true),\nwhere bmodeli is the vector obtained by solving (18) for the i-th explained point by using SurvLIME or SurvBeX.\nThe greater the value of the MCI and the smaller the MSFD, the MKL, and the MSD, the better results we get."
        },
        {
            "heading": "6.3 One cluster",
            "text": "First, we compare SurvBeX with SurvLIME by generating one cluster as it is shown in Fig.2. The first black-box model is the Cox model which is used in order to be sure that SurvLIME provides correct results. It is important to point out the following observation. If the Cox model uses the same method for computing the baseline SF S0(t) (see the corresponding expression (5)), then SurvLIME provides outperforming results because it actually tries to minimize the distance between SFs which are similar to some extent. In this case, we obtain outperforming results provided by SurvLIME. The outperformance is also supported by the fact that the training set is generated in accordance with probability distributions satisfying the Cox model.\nBoxplots in Fig.4 show differences between MSFD, MSD, MKL, and MCI for SurvLIME and SurvBeX when the black box is the Cox model. It can be seen from Fig.4 that SurvLIME provides better results in comparison with SurvBeX in accordance with all introduced measures. The results justify the above assumption about comparison of SurvLIME and SurvBeX when the black box is the Cox model and training example are generated in accordance with the Cox model.\nFig.5 shows values of the feature importance (the left column) and SFs provided by the black box, SurvLIME and SurvBeX (the right column) under the same conditions. For each number of features in examples of the generated dataset, an explained example is randomly selected from the dataset. Results of the explanation and the corresponding SFs provided by different models are depicted. It can be seen from Fig.5 that SFs produced by the black-box model (depicted by the thicker line) and SurvLIME almost coincide whereas SF produced by SurvBeX differs from the black-box model SF. At the same time, when the number of features is 20, SurvBeX provides results similar to SurvLIME.\nLet us consider the RSF as a black-box model. The corresponding numerical results are shown in Figs.6-7.\nFig.6 shows boxplots of MSFD, MSD, MKL, and MCI for SurvLIME and SurvBeX when the black box is the RSF. It is interesting to note that SurvBeX provides better results in comparison with SurvLIME. It is interesting also to point out that SurvBeX behaves more stable when the number of features increases. It can be also seen from Fig.6 (boxplots of MSFD) that the SurvBeX provides better approximation of the SF because the MSFD measures for SurvBeX are smaller than the same measures for SurvLIME. The same conclusion is supported by Fig.7 where randomly selected\nexplained examples for three cases of the feature numbers are analyzed. It can be seen from Fig.7 that SFs provided by SurvBeX are much closer to the black-box SF in comparison with SFs produced by SurvLIME. The difference between results obtained by different black-box models can be explained by the fact that, in spite of the training set generated by using the Cox model, the RSF produces the SF different from the \u201cideal\u201d SF corresponding to the Cox model and this difference increases with the number of features. The Beran estimator is more sensitive to the changes of SFs and, therefore, SurvBeX provides better results.\nIn order to study different cases of the black-box models, we use the Beran estimator as a black-box model. It is obvious in this case that SurvBeX should provide outperforming results. This assumption is justified by results shown in Fig.8. One can see from Fig.8 that SurvBeX outperforms SurvLIME for all numbers of features. The same can be seen from Fig.9. SFs produced by SurvBeX are closer to the black-box SFs than SFs produced by SurvLIME."
        },
        {
            "heading": "6.4 Two clusters",
            "text": "Let us compare SurvBeX with SurvLIME when two clusters of examples are generated (see Fig.3) such that the clusters are generated in accordance with the Cox model, but they have quite different\nparameters of the model. It is obvious that this data structure entirely violates the homogeneous Cox model data structure. Therefore, it can be assumed in advance that SurvLIME will produce worse results. This is confirmed by the following experiments.\nWe consider the case when the RSF is used as a black box. Fig.10 shows boxplots of MSFD, MSD, MKL, and MCI for SurvLIME and SurvBeX. It can be seen from Fig.10 that SurvBeX provides better results for different numbers of features. At the same time, the outperformance of SurvBeX is reduced with increase of the feature numbers.\nAn important peculiarity of the RSF as a black-box model is that it tries to separate examples from different clusters. As a result, the produced SF for each point strongly depends on a cluster which contains the point. In contrast to the RSF, the Cox model computes the baseline SF S0(t) which is common for all points of clusters. Therefore, the Cox model as a black-box model \u201caverages\u201d the clusters and provides the unsatisfactory prediction results. In particular, C-indices of the Cox blackbox model computed on the training and testing sets of the two-cluster dataset with five features are 0.59 and 0.57, respectively, whereas C-indices of the black-box RSF are 0.95 and 0.91, respectively. We can see that the Cox black-box model is no better than random guessing. Fig.12 shows boxplots of MSFD, MSD, MKL, and MCI for this case. It seems from Fig.12 that SurvBeX is worse than SurvLIME. However, this is not the case. The average distance (MSFD) between SFs is very small, and explanation models simply try to guess the feature importance which is also close to 0.5. Due to\nthe more complex optimization in SurvBeX, the error of its explanation is greater. Table 1 illustrate the relationship between different explanation methods when two clusters are considered, the black-box is the RSF, and the number of features in training examples is 5. We also consider an additional explanation method called SurvSHAP [29]. Mean values and standard deviations of measures MSD, MKL, and MCI are given in Table 1. It can be seen from the table that SurvBeX outperforms other explanation methods. Similar results by 10 features are shown in Table 2."
        },
        {
            "heading": "7 Numerical experiments with real data",
            "text": "To illustrate SurvBeX, we study it on the following well-known real datasets:\n\u2022 The Veterans\u2019 Administration Lung Cancer Study (Veteran) Dataset [81] contains data on 137 males with advanced inoperable lung cancer. The subjects were randomly assigned to either a standard chemotherapy treatment or a test chemotherapy treatment. Several additional vari-\nables were also measured on the subjects. The dataset can be obtained via the \u201csurvival\u201d R package or the Python \u201cscikit-survival\u201d package..\n\u2022 The German Breast Cancer Study Group 2 (GBSG2) Dataset contains observations of 686 women [82]. Every example is characterized by 10 features, including age of the patients in years, menopausal status, tumor size, tumor grade, number of positive nodes, hormonal therapy, progesterone receptor, estrogen receptor, recurrence free survival time, censoring indicator (0 - censored, 1 - event). The dataset can be obtained via the \u201cTH.data\u201d R package or the Python \u201cscikit-survival\u201d package.\n\u2022 The Worcester Heart Attack Study (WHAS500) Dataset [1] describes factors associated with acute myocardial infarction. It considers 500 patients with 14 features. The endpoint is death, which occurred for 215 patients (43.0%). The dataset can be obtained via the \u201csmoothHR\u201d R package or the Python \u201cscikit-survival\u201d package.\u2018\nFig.13(a) shows the data structure of the dataset Veteran by means of the t-SNE method. Fig.13(b) shows SFs predicted by the black-box model, SurvLIME and SurvBeX. It can be seen from Fig.13 that the dataset has a specific structure which does not allows us to construct a proper Cox model in the framework of SurvLIME. As a result, the SF produced by SurvBeX is closer to the SF predicted by the black-box model than the SF produced by SurvLIME. Mean values of the feature importance over all points of the dataset computed by using SurvLIME and SurvBeX are depicted in Fig.13(c). It can be seen from Fig.13(c) that the results provided by SurvLIME and SurvBeX are different. The methods coincide in selection of the most important feature \u201cKarnofsky score\u201d. However, the most important second feature is determined by SurvBeX as \u201cCelltype\u201d whereas SurvLIME determines it as \u201cMonths from diagnosis\u201d. \u201cKarnofsky score\u201d and \u201cCelltype\u201d as the most important features were determined also in [70].\nThe next dataset for studying is GBSG2. The data structure of the dataset GBSG2 depicted by means of the t-SNE method and SFs predicted by the black-box model SurvLIME and SurvBeX are shown in Fig.14(a) and (b), respectively, We again see that the SF produced by SurvBeX is closer to the SF predicted by the black-box model than the SF produced by SurvLIME. Fig.14(c) shows mean\nvalues of the feature importance over all points of the dataset GBSG2 computed by using SurvLIME and SurvBeX.\nThe same results can be seen in Fig.15 where results obtained for the dataset WHAS500 are shown."
        },
        {
            "heading": "8 Conclusion",
            "text": "A new explanation method called SurvBeX, which can be regarded as an alternative to the wellknown method SurvLIME developed for survival data, has been presented in the paper. The main idea behind the method is to use the Beran estimator to approximate a survival black-box model at an explained point. The explanation by means of SurvBeX is reduced to minimization between SFs predicted by the black-box model and the Beran estimator for points generated around the explained point.\nThere is an important difference between SurvLIME and SurvBeX except for the use of the Beran estimator instead of the Cox model. According to SurvLIME, the importance weights b are assigned to features. In SurvBeX, they are assigned to distances between features of the explained example and training examples. This implies that the importance weights in SurvBeX directly depend on the training set whereas the weights in SurvLIME implicitly depend on the training set through the baseline function which may be incorrect when the analyzed dataset has a complex structure.\nAt the same time, we should point out a drawback of SurvBeX. In contrast to SurvLIME, SurvBeX has to solve the complex optimization problem, which leads to increasing the computation time. Nevertheless, various numerical experiments have demonstrated that the optimization problem is successfully solved and SurvBeX provides the outperforming explanation.\nThere are several ways for further research based on the proposed method. First of all, we have considered the minimization of the distances between SFs. In the same way, the cumulative hazard functions can be considered as it has been implemented in SurvLIME. Second, only the Gaussian kernel and its modification have been used to implement SurvBeX. However, it is interesting to consider other types of kernels which may provide outperforming results. Third, another important generalization of the proposed method is to combine SurvLIME and SurvBeX. For example, they can be linearly combined with some parameter such that the SF of the combined explanation model is represented\nas a linear combination of two SFs with the same parameters b. The above problems are directions for further research."
        },
        {
            "heading": "Acknowledgement",
            "text": "The research is partially funded by the Ministry of Science and Higher Education of the Russian Federation as part of state assignments \u201cDevelopment of a Multi-Agent Resource Manager for a Heterogeneous Supercomputer Platform Using Machine Learning and Artificial Intelligence\u201d (topic FSEG-2022-0001)."
        }
    ],
    "title": "SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator",
    "year": 2023
}