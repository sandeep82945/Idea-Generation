{
    "abstractText": "Real-time monitoring and accurate prediction of toxic gas concentration in the future are of great significance for emergency capability assessment and rescue work. At present, the method of gas concentration prediction based on artificial intelligence still has problems of low accuracy, slow convergence speed and equal feature importance. This paper proposes a feature-aware LSTM model to predict pollutant gas concentration. First of all, we design a set of multi-component toxic gas monitoring equipment that applies in pollution environment, which can at the same time monitor CO, NO2, NH3, HCN, H2S and SO2, six common pollutants; To accurate estimate the toxic gas concentration, we combine the collected the gas data and the environmental parameters and regard them as the input features, and thenwe obtain toxic gas data based on the sampling policy and the environmental data as our data-set. Finally, we train a FA-LSTM gas concentration prediction model on these data-set. We test the proposed model and compared with ARIMA, ETS and BP network on the same test set. Experimental results show that the proposed model outperforms traditional concentration prediction model. Also, it is better than other state-of-the-art models in predicting accuracy. INDEX TERMS Pollution emergency decision, toxic gas, air pollution prediction, time series, LSTM.",
    "authors": [
        {
            "affiliations": [],
            "name": "YU CONG"
        },
        {
            "affiliations": [],
            "name": "XIMENG ZHAO"
        },
        {
            "affiliations": [],
            "name": "KE TANG"
        },
        {
            "affiliations": [],
            "name": "GE WANG"
        },
        {
            "affiliations": [],
            "name": "YANFEI HU"
        },
        {
            "affiliations": [],
            "name": "YINGKUI JIAO"
        }
    ],
    "id": "SP:b9d6f92dd4dfefada962ee32e30e7887dfed0fae",
    "references": [
        {
            "authors": [
                "P. Guo",
                "H. Li",
                "G. Zhang"
            ],
            "title": "Contaminated site\u2013induced health risk using Monte Carlo simulation: Evaluation from the brownfield in Beijing, China",
            "venue": "Environ. Sci. Pollut. Res., vol. 28, pp. 25166\u201325178, Jun. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Chen",
                "K. de Hoogh",
                "J. Gulliver",
                "B. Hoffmann"
            ],
            "title": "A comparison of linear regression, regularization, and machine learning algorithms to develop Europe-wide spatial models of fine particles and nitrogen dioxide",
            "venue": "Environ. Int., vol. 130, Sep. 2019, Art. no. 104934.",
            "year": 2019
        },
        {
            "authors": [
                "M. Pontiggia",
                "M. Derudi",
                "M. Alba",
                "M. Scaioni",
                "R. Rota"
            ],
            "title": "Hazardous gas releases in urban areas: Assessment of consequences through CFD modelling",
            "venue": "J. Hazardous Mater., vol. 176, nos. 1\u20133, pp. 589\u2013596, Apr. 2010.",
            "year": 2010
        },
        {
            "authors": [
                "S.R. Hanna",
                "O.R. Hansen",
                "M. Ichard",
                "D. Strimaitis"
            ],
            "title": "CFD model simulation of dispersion from chlorine railcar releases in industrial and urban areas",
            "venue": "Atmos. Environ., vol. 43, no. 2, pp. 262\u2013270, Jan. 2009.",
            "year": 2009
        },
        {
            "authors": [
                "S. Metia",
                "S. Oduro",
                "Q. Ha",
                "H. Duc"
            ],
            "title": "Air pollution prediction using Mat\u00e9rn function based extended fractional Kalman filtering",
            "venue": "Proc. 13th Int. Conf. Control Automat. Robot. Vis. (ICARCV), Dec. 2014, pp. 758\u2013763.",
            "year": 2014
        },
        {
            "authors": [
                "R. Wongsathan",
                "I. Seedadan"
            ],
            "title": "A hybrid ARIMA and neural networks model for PM-10 pollution estimation: The case of Chiang Mai city moat area",
            "venue": "Proc. Comput. Sci., vol. 86, pp. 273\u2013276, Mar. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S. Chattopadhyay",
                "G. Chattopadhyay"
            ],
            "title": "Modeling and prediction of monthly total ozone concentrations by use of an artificial neural network based on principal component analysis",
            "venue": "Pure Appl. Geophys., vol. 169, no. 10, pp. 1891\u20131908, Oct. 2012.",
            "year": 1891
        },
        {
            "authors": [
                "R. Wang",
                "B. Chen",
                "S. Qiu",
                "Z. Zhu",
                "Y. Wang",
                "Y. Wang",
                "X. Qiu"
            ],
            "title": "Comparison of machine learning models for hazardous gas dispersion prediction in field cases",
            "venue": "Int. J. Environ. Res. Public Health, vol. 15, no. 7, p. 1450, Jul. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "D. Ma",
                "Z. Zhang"
            ],
            "title": "Contaminant dispersion prediction and source estimation with integrated Gaussian-machine learning network model for point source emission in atmosphere",
            "venue": "J. Hazardous Mater., vol. 311, pp. 237\u2013245, Jul. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "P. Lauret",
                "F. Heymes",
                "L. Aprin",
                "A. Johannet"
            ],
            "title": "Atmospheric dispersion modeling using artificial neural network based cellular automata",
            "venue": "Environ. Model. Softw., vol. 85, pp. 56\u201369, Nov. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Ouyang",
                "A. Wang"
            ],
            "title": "The application of concentration forecasting of air pollutant based on BP neural network in MATLAB",
            "venue": "Environ. Sci. Manage., to be published."
        },
        {
            "authors": [
                "H.Hewamalage",
                "C. Bergmeir",
                "andK. Bandara"
            ],
            "title": "Recurrent neural networks for time series forecasting: Current status and future directions",
            "venue": "Int. J. Forecasting, vol. 37, no. 1, pp. 388\u2013427, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C. Gulcehre",
                "K. Cho",
                "R. Pascanu",
                "Y. Bengio"
            ],
            "title": "Learned-norm pooling for deep feedforward and recurrent neural networks",
            "venue": "Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases. Berlin, Germany: Springer, 2014, pp. 530\u2013546.",
            "year": 2014
        },
        {
            "authors": [
                "L. Xu",
                "C.-S. Choy",
                "Y.-W. Li"
            ],
            "title": "Deep sparse rectifier neural networks for speech denoising",
            "venue": "Proc. IEEE Int. Workshop Acoustic Signal Enhancement (IWAENC), Sep. 2016, pp. 1\u20135.",
            "year": 2016
        },
        {
            "authors": [
                "N. Srivastava",
                "G. Hinton",
                "A. Krizhevsky",
                "I. Sutskever",
                "R. Salakhutdinov"
            ],
            "title": "Dropout: A simple way to prevent neural networks from overfitting",
            "venue": "J. Mach. Learn. Res., vol. 15, no. 1, pp. 1929\u20131958, 2014.",
            "year": 1929
        },
        {
            "authors": [
                "Y.-Q. Zhang",
                "X.-Y. Wang"
            ],
            "title": "A new image encryption algorithm based on non-adjacent coupled map lattices",
            "venue": "Appl. Soft. Comput., vol. 26, pp. 10\u201320, Jan. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "D.J. Gunn",
                "Z. Liu",
                "R. Dave",
                "X. Yuan",
                "K. Roy"
            ],
            "title": "Touch-based active cloud authentication using traditional machine learning and LSTM on a distributed tensorflow framework",
            "venue": "Int. J. Comput. Intell. Appl., vol. 18, no. 4, Dec. 2019, Art. no. 1950022.",
            "year": 2019
        },
        {
            "authors": [
                "H. Li",
                "X. Mu",
                "Y. Yang",
                "A.J. Mason"
            ],
            "title": "Low power multimode electrochemical gas sensor array system for wearable health and safety monitoring",
            "venue": "IEEE Sensors J., vol. 14, no. 10, pp. 3391\u20133399, Oct. 2014. VOLUME 10, 2022 1601 Y. Cong et al.: FA-LSTM: Novel Toxic Gas Concentration Prediction Model in Pollutant Environment",
            "year": 2014
        },
        {
            "authors": [
                "M. Akhoondzadeh"
            ],
            "title": "AMLP neural network as an investigator of TEC time series to detect seismo-ionospheric anomalies",
            "venue": "Adv. Space Res., vol. 51, no. 11, pp. 2048\u20132057, Jun. 2013.",
            "year": 2013
        },
        {
            "authors": [
                "Y. Su",
                "Y. Zhao",
                "M. Sun",
                "S. Zhang",
                "X. Wen"
            ],
            "title": "Detecting outlier machine instances through Gaussian mixture variational autoencoder with one dimensional CNN",
            "venue": "IEEE Trans. Comput., early access, Mar. 9, 2021, doi: 10.1109/TC.2021.3065073.",
            "year": 2021
        },
        {
            "authors": [
                "X.H. Cao",
                "I. Stojkovic",
                "Z. Obradovic"
            ],
            "title": "A robust data scaling algorithm to improve classification accuracies in biomedical data",
            "venue": "BMC Bioinf., vol. 17, no. 1, p. 359, Sep. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "R. Hemeimat"
            ],
            "title": "Demand forecasting for motor vehicle spare parts",
            "venue": "Amer. J. Oper. Res., pp. 113\u2013120, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "D. Haboudane",
                "J.R.Miller",
                "E. Pattey",
                "P.J. Zarco-Tejada",
                "I.B. Strachan"
            ],
            "title": "Hyperspectral vegetation indices and novel algorithms for predicting green LAI of crop canopies: Modeling and validation in the context of precision agriculture",
            "venue": "Remote Sens. Environ., vol. 90, no. 3, pp. 337\u2013352, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "R. Taylor"
            ],
            "title": "Interpretation of the correlation coefficient: A basic review",
            "venue": "J. Diagnostic Med. Sonogr., vol. 6, no. 1, pp. 35\u201339, 1990.",
            "year": 1990
        },
        {
            "authors": [
                "L.Wang"
            ],
            "title": "Support vector machines: Theory and applications",
            "venue": "inMachine Learning and Its Applications (Advanced Lectures). Springer-Verlag, Jan. 2001.",
            "year": 2001
        },
        {
            "authors": [
                "F.S. Wong"
            ],
            "title": "Time series forecasting using backpropagation neural networks",
            "venue": "Neurocomputing, vol. 2, no. 4, pp. 147\u2013159, Jul. 1991.",
            "year": 1991
        },
        {
            "authors": [
                "A. Mazzoldi",
                "T. Hill",
                "J.J. Colls"
            ],
            "title": "CFD and Gaussian atmospheric dispersion models: A comparison for leak from carbon dioxide transportation and storage facilities",
            "venue": "Atmos. Environ., vol. 42, no. 34, pp. 8046\u20138054, Nov. 2008.",
            "year": 2008
        },
        {
            "authors": [
                "H. Liu",
                "X. Mi",
                "Y. Li"
            ],
            "title": "Smart multi-step deep learning model for wind speed forecasting based on variational mode decomposition, singular spectrum analysis, LSTM network and ELM",
            "venue": "Energy Convers. Manage., vol. 159, pp. 54\u201364, Mar. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "F. Qian",
                "L. Chen",
                "J. Li",
                "C. Ding",
                "X. Chen",
                "J. Wang"
            ],
            "title": "Direct prediction of the toxic gas diffusion rule in a real environment based on LSTM",
            "venue": "Int. J. Environ. Res. Public Health, vol. 16, no. 12, p. 2133, Jun. 2019.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS Pollution emergency decision, toxic gas, air pollution prediction, time series, LSTM.\nI. INTRODUCTION A contaminated site, also known as a \u2018\u2018brownfield,\u2019\u2019 refers to the space environment that carries harmful substances due to accumulation, storage, treatment, disposal or other means (such as migration), causing harm or potential risk to human health and the region [1]. In heavily polluted sites, there are often sudden, hidden and highly lethal chemical asphyxiating gases, such as volatile gases such as carbon monoxide, hydrogen cyanide and hydrogen sulfide. These toxic gases pose a great threat to the personal safety of personnel during the repair operation of polluted sites.\nThe accuracy of toxic gas concentration prediction directly determines the effectiveness of on-site solution implementation. Therefore, it is of great significance for the life and health of repair workers to monitor the toxic gas in the\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Sun-Yuan Hsieh .\npolluted environment in real time and to predict the amount of toxic gas or its development trend in real time, accurately, scientifically and reasonably. Among polluting gas predictions, it is challenging to accurately predict the concentration of polluting gas. First of all, the prediction of gas concentration is closely related to the terrain environment and surrounding temperature or humidity, and different terrain also has different effects on the surrounding wind speed. The coupling of each influencing factor and its strong nonlinear correlation bring great challenges to the analysis for technical personnel. Secondly, the high demand on modelling expert is another challenge in the prediction of pollutant gas composition. Professional technicians are usually better at determining gas content and analyzing which factors are affecting its concentration; The data are then handed over to modelling expert, and the level of these experts further constrains the accuracy or the efficiency on the concentration prediction of polluted gases. The accuracy of the model directly affects the\nVOLUME 10, 2022 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 1591\nsubsequent decision execution, and the low prediction will bring great damage to the safety of personnel or property. Therefore, how to quickly, accurately and conveniently predict the composition of polluting gas is a very urgent need.\nAt present, there are two kinds of gas concentration prediction methods, one is based on mechanism process, and the other is based on historical data. In concentration prediction, mechanism method obtains the results of target variables by analyzing the relationship between various influencing factors and target variables [2]. For scenes with strong nonlinear and coupling, this method has low accuracy and an extremely complex analysis process. The calculation time of the model can reach up to several hours. For emergencies, the emergency response ability of this model cannot effectively offer solutions for field staff [3], [4], and its practicability is low. However, the method based on historical data can extract the hidden relationship between variables by analyzing data, which has high accuracy and practicability. Currently, gas concentration prediction methods based on historical data mainly include traditional modeling methods and artificial intelligence methods. Traditional modeling methods based on historical samples include multiple linear regression method [2], Kalman filter technology [5], timespace series model methods, etc. (existing time-space series models such as autoregressive comprehensive moving average model (ARIMA) [6], seasonal ARIMA [7], Gaussian plume diffusion model [8]). The prediction method based on multiple linear regression approximates the gas diffusion model to a linear model, which reduces the accuracy of prediction [6]. The establishment of a nonlinear model based on space-time series requires experienced personnel to determine parameters and the orders of the equation, which hinders the deployment of the model. In order to simplify the complexity of model building, a series of pollutant prediction models based on machine learning were proposed [9]. However, such methods have the limits of low accuracy, slow training speed [10], [11], or the model is difficult to converge and optimize [12]. The latest concentration predictions avoid the problem of the above methods, however, there are still exists defects of predicting a single gas concentration or regarding multiple influencing factors as the equal. In fact, the influence of various factors on the target object varies frequently, for example, themaximum effect of on concentration in the morning is humidity, and at noon wind speed has bigger influence on the concentration.\nBased on the above analysis, we propose a FA-LSTM model to predict gas concentration in the process of contaminated site treatment. FA-LSTM is short for feature awared LSTM for multi-objective prediction model. Specifically, we use multi-component toxic gas monitoring equipment to monitor six high-risk gas pollutants in the polluted site, which are NH3, CO, NO2, HCN, H2S and SO2. We used the time series of the monitoring concentration data as input feature. In addition, the environmental parameters in this area predicted by the weather forecast are used as the auxiliary feature input to establish the model. In the process of model building,\nwe add attention mechanism to distinguish the importance of each feature. Finally, themodel is used to predict the pollutant concentration in the following moments. We evaluate our proposed model and four other state-of-the-art time series prediction models based on the same test dataset. The evaluation results show that the performance of our proposed model on the pollutant gas concentration prediction is obviously better than other methods.\nIn summary, the contributions of this paper are as follows: (1) We novelly combined the monitoring concentration data collected in the field with environmental parameters to predict multi-gas pollutant concentrations; the effective combination of these features helps improve the accuracy of the model.\n(2) We novelly treat the weights of multiple features differently; the weight difference makes the results of the model more sensitive to the changes of features, and solves the problem that feature weights cannot be distinguished.\n(3) We propose a combined model called FA-LSTM, we evaluate the results of our proposed model and compare it with the state-of-the-art model.\nThe rest of this paper is as follows: the second section introduces the basic theory of the model and designs the LSTM model in this paper; The third section focuses on the implementation process and methods, including the construction of monitoring equipment and a brief description of data acquisition. Firstly, the data is preprocessed to obtain the sampling data set, then the data is loaded in a specific way, trained with the model in this paper, and finally evaluated the performance. In the fourth section, the experimental results are analyzed and discussed. Finally, this paper draws a conclusion.\nII. BASIC OF LSTM ALGORITHM The long-term and short-term memory network is a special recurrent neural network (RNN). Cyclic neural network has the ability to remember and analyze historical data, that is, the output of cyclic neural network does not only depend on the current input layer, but also contains historical data information, so it is very suitable for processing the data of predicting time-series related information. The structure of RNN is shown in Figure 1.\nBengio et al. described that gradient disappearance and gradient explosion would occur in the training process of RNN in practical application [13], which could not process a long input sequence. As a variant of RNN, LSTM model has a unique design structure: controllable self-circulation is skillfully introduced to generate a path that enables the gradient to flow sustainably for a long time, and effectively overcome the gradient disappearance problem caused by the passage of time and the increase of network layers in machine learning of RNN. On the basis of RNN, LSTM adds a memory cell state and three control gates: input gate, forgetting gate and output gate. The input gate determines how much network input is saved to the unit state at the current moment; The forgetfulness gate determines how much of the unit state\n1592 VOLUME 10, 2022\nfrom the previous moment is retained to the current moment; The output gate determines how much output the unit state has to the current output value. These three special gate structures can effectively solve the gradient disappearance problem and have memory function, and are suitable for dealing with long-term dependence problem. Figure 2 shows the structure of duplicate modules and hidden layers of the memory unit LSTM.\nThe general working principle of LSTM can be expressed by Equation (1): it = \u03c3 (Wi \u00b7 [ht\u22121, xt ]+ bi) ft = \u03c3 (Wf \u00b7 [ht\u22121, xt ]+ bf ) Ct = ft \u2217 Ct\u22121 + it \u2217 C\u0303t C\u0303t = tanh(Wi \u00b7 [ht\u22121, xt ]+ bc) ot = \u03c3 (Wo \u00b7 [ht\u22121, xt ]+ bo) ht = ot \u2217 tanh(Ct ) (1)\nwhere it , ft , and ot represent input gate, forgetting gate and output gate respectively, and W ( Wi,Wf ,Wo,Wc ) and\nH ( Hi,Hf ,Ho,Hc ) areweightmatrices; b ( bi, bf , bo, bc ) represents the deviation vector; \u03c3 indicates the sigmoid activation function, and the value range of the function is 0\u223c1; tanh (\u00b7) represents hyperbolic tangent activation function, and the output range is \u22121 to 1; C\u0303t is the candidate value of the state of the memory unit at time t , and Ct represents the state of the current memory unit at time t; ht is the output value at time t .\nIII. MODEL DESIGN The goal of the model is to predict the pollution gas content at a futuremoment based on input historical samples and current environmental characteristics. We need to learn a model that can output the pollutant at the next time according to the input at any time. Therefore, during training, themodel output should meet the following relationship: the loss of square error (MSE) is selected as the loss function during predicted results and actual results is the smallest. The mean model training, and the formula is as follows:\nMSE = 1 n n\u2211 i=1 (yi \u2212 Yi) 2 (2)\nwhere yi represents the predicted value and Yi represents the real value. The square of the difference between the real value and the predicted value is then summed and averaged to represent the training error. The above formula is the objective function optimized during training.\nWhen constructing the network, we choose LSTM network, because it effectively solves the problems of long-term dependence on information and gradient disappearance during deep network training. We designed the following network structure: three-layer hidden layer structure, which enables us to achieve higher model accuracy. The network model is shown in Figure 3. The specific parameters corresponding to each layer are shown in Table 1. Among the hidden layers, the correction linear unit (Relu) function is selected as the activation function. Compared with the\nVOLUME 10, 2022 1593\nTABLE 1. Concrete parameters of each layer of the model.\nclassical Sigmoid activation function, Relu can avoid the occurrence of negative predicted concentration value, and is better than other activation functions in terms of statistical performance and computational cost [14]. The activation function of the output layer is Linear. In addition, in order to improve the generalization ability of deep learning model and avoid overfitting, we use the most commonly used method in deep learning to prevent neural network overfitting, the dropout method. The key idea for Dropout is to randomly delete neurons (and their connections) from the neural network during training to reduce co-adaptive relationships [15]. In this paper, the Dropout was added after the first LSTM layer and the last LSTM layer respectively, and the Dropout rate was set to 0.2. The better weight of the optimization model of Adam optimizer is selected [16]. The learning rate is set too large, and the number of training iterations of the model is too small, which leads to continuous oscillation at the optimal point and failure of normal convergence. The learning rate is too small, and the model is under-fitted. The loss value between 0.01 and 0.0001 of the learning rate declines smoothly and converges. Too few iterations cannot make the model obtain accurate prediction results. Therefore, the trained data sets need to be transmitted in the same neural network for many times. Combined with the complexity of the experiment in this paper, 300 epochs can meet the training accuracy requirements.\nIV. EXPERIMENT EVALUATION A. EXPERIMENTS SETUP The test environment is as follows: the OS is Ubuntu16.04, CPU is 2\u00d7 Intel XeonGold5120CPU, andGPU is 8 \u00d7 32GB\nV100 SXM2 NVLINK GPU. The results are presented in the locale based on Python 3.7 and verified in the toxic gas sampling data set. Based on Python 3.7 language environment, Keras is used as the deep learning framework for training and prediction. Keras encapsulates many components of TensorFlow and Theano, two of the best open source deep learning frameworks [17]. Users can design various kinds of networks only by calling APIs, which is very convenient when optimizing networks.\nThe multi-component toxic gas monitoring equipment based on embedded system technology designed in this paper is shown in Figure 4. The device uses STM32F407VGT6 micro-controller as the controller and six ECM-SMART electrochemical gas sensors to detect the corresponding gas concentration value. The 4G wireless transmission module and MCGS man-machine interactive display are responsible for data uploading and display.\nB. DATA COLLECTION The experimental data in this paper aremainly from themulticomponent toxic gas monitoring equipment at each collection node in the contaminated site. Each acquisition node is a set of embedded system. Using the modular design idea, the toxic gas acquisition node is divided into four modules according to its functions, namely sensor detection module, control unit module, display alarmmodule andwireless transmission module. The data acquisition is mainly completed by the sensor detection module, which is composed of sensor group. The sensor group is composed of six ECM-SMART electrochemical gas sensors. The parameters are shown in Table 2, namely hydrogen cyanide, carbon monoxide,\n1594 VOLUME 10, 2022\nhydrogen sulfide, nitrogen dioxide, ammonia and sulfur dioxide. The sensor has the trait of small volume, low power consumption, high resolution, linearity and good repeatability, and meets the measurement requirements of toxic gas to be measured [18]. The data is detected by the sensor group, and the signal is transmitted to the single chip microcomputer through the UART bus. After calculation and processing, the data are respectively transmitted to 4g DTU and uploaded to the cloud server for storage and display. The alarm module can display the gas concentration on the HMI screen, set the gas concentration alarm threshold, and give an audible and visual alarm according to the set threshold to remind relevant personnel to evacuate as soon as possible. The data acquisition process is shown in Figure 5.\nThe toxic gas sampling data set includes the concentration of six pollutant gases including SO2 NO2 CO H2S HCN NH3. The data set can truly and comprehensively reflect the pollution situation of each toxic gas in the polluted site. The experimental site is a polluted site in Tianjin Dong jiang Port Free Trade Zone (located at 39.02N and 117.44 E), where a warehouse preserving dangerous goods fired and exploded in 2015, and all kinds of toxic gases are still trapped even after relevant treatment. During the experiment, 10 monitoring\ndevices are deployed in different locations of the site for all-round and multi-angle sampling. In order to display the prediction results more clearly, this paper uses 5 months data, and the sampling time is selected from January 15 to June 15, 2021. The sampling interval of concentration data of each group is 5 minutes, and there are 43200 sample for each type of gas. Since the data set is made by sampling in real polluted site, it has certain practical value. Finally, we get the time series of concentration data of six pollution factors through data preprocessing.\nAt present, weather forecasts have reached a level that people can rely on. If the characteristics of weather forecast can be well used for pollution prediction, the accuracy of air pollution forecast can be improved to a certain extent. The environmental features selected in this paper are shown in the following Table 3:\nFinally, we divide the data set into training set and test set. The first 85% of the original data set is used as a training set for the training model, and the last 15% is used as a test set to evaluate the model performance. When the model is trained using training set and saved, its parameters can be read directly to predict the concentration value in the testing process.\nVOLUME 10, 2022 1595\nC. DATA PREPROCESSING The original sampling data set is usually chaotic, and abnormal data cannot be avoided (due to packet loss and other reasons). Therefore, it is necessary to preprocess the data on the premise of data analysis. The abnormal data obtained bymonitoring mainly include outliers, missing values and repeated values. For individual outliers, direct deletion of records has a slight impact on the whole. For a large number of missing values, air quality data is a time series. If all records of missing values are deleted, the characteristics in the time dimension are also deleted accordingly, and an appropriate filling method needs to be selected to fill the missing values. Therefore, this paper proposes to clean themissing data based on z-Score algorithm [19]. Firstly, the abnormal value of the given data is detected based on the Z-score algorithm for deletion, and then the lost value data is filled by the mean filling method. Finally, duplicate data in the data samples were deleted and the duplicate values were removed.\nZi = Xi \u2212 \u00b5 \u03c3 , |Zi| > Zthr (3)\nZ-score is a parameter anomaly detection method in onedimensional or low-dimensional feature space [20]. This technique assumes that the data is Gaussian distribution, and the outliers are the data points at the tail of the distribution, so they are far away from the average value of the data. The distance depends on the set threshold Zthr of the normalized data point Zi calculated using the formula. Zthr values are generally set to 2.5, 3.0 and 3.5. Where Xi is a data point, \u00b5 is the average of all points Xi, \u03b4 Is the standard deviation of all points Xi. Then, after standardization, the abnormal value is also standardized, and its absolute value is greater than Zthr.\nData normalization linearly reduces the data from a value range to a new value range. In this paper, the min max scale method is used to normalize the data [21], so that an original value x is mapped to the value x i of interval\n[0, 1]. The Min-Max Scale normalization can be expressed as Equation (4), where max{xi} and min{xi} represent the maximum and minimum values of the current concentration data respectively\nx \u2032i = xi \u2212 min{xi}\nmax{xi} \u2212 min{xi} (4)\nDue to normalization, the final result must be inverse normalized to restore the original interval. The inverse normalization expression is Equation (5).\nxi = x \u2032i (max{xi} \u2212 min{xi})+ min{xi} (5)\nD. MODEL DATA LOADING The objective of the experiment is to use the multi-layer LSTM network to build a regression prediction model based on the time series data of toxic gas concentration characteristics at the pollution site. The LSTM model consists of three parts: the input layer, the hidden layer and the output layer. The input layer is the concentration characteristics and environmental characteristics of the training set in the toxic gas sampling data set. The training data loaded into the model is shown in Figure 6. The data intercepted by the timewindow each time will be used as the input feature Xfeature of the model, and the next item will be used as the concentration label Ylable of 10 s in the future that needs to be predicted. The number of moves of the time window each time is 1. In this way, the model input sample data required for training will be obtained from the training data set in turn, and these window data will be randomly scrambled into themodel training, so as to make the training more consistent with the real distribution of data, so as to improve the generalization ability of the prediction model.\nE. BASE MODEL In order to evaluate the performance of the proposed method, two common benchmark models are established with the same training set. The first is the prediction method based on statistical time series, which is the auto-regressive comprehensive moving average model (ARIMA) and exponential smoothing model (ETS). Both of these methods are based on historical data and their accuracy depends on the estimated parameter order. The other is the prediction model based on machine learning algorithm, namely BP model and SVM model. The selection of these two types of benchmark models\n1596 VOLUME 10, 2022\ncan enable us to verify the effect of the LSTM model more comprehensively. For each prediction model, we selected the optimal parameters according to a specific method. Table 4 describes the optimal parameters of each model.\nF. EVALUATION METRIC In this paper, the mean absolute error (MAE), root mean square error (RMSE) and correlation coefficient (R) are selected to evaluate the prediction performance of the model. MAE represents the average value of the absolute error between the true value and the predicted value, avoiding the case that the positive and negative cancel each other [22].\nRMSE is the square root of the square of the deviation between predicted value and true value and the ratio of observed number n, which can better reflect the prediction accuracy [23]. MAE = 1 n n\u2211 i=1 |Ci \u2212 C \u2032i | RMSE = \u221a\u221a\u221a\u221a1 n n\u2211 i=1 (|Ci \u2212 C \u2032i |) 2 r = Cov(Ci,C \u2032i )\u221a\nVar(Ci) \u00b7 Var(C \u2032i )\n(6)\nTABLE 4. The most optimized parameters in each model.\nwhere Ci is the monitored concentration, C \u2032i is the predicted concentration, Var is the calculated variance, and Cov is the calculated covariance.\nV. EXPERIMENT RESULTS We used the trained LSTM network model, ARMIA linear model, ETS model, SVM model and BP model to simultaneously predict the concentration of each component monitoring gas in the contaminated site on a certain day. In order to verify that the effect of the model has nothing to do with the specific data distribution (time dimension), we selected the data of five months for verification, and randomly selected one day in each month of the five months to verify the stability of the model. Finally, we give the mean and standard deviation of the five predictions.\nA. COMPARSION WITH STATISTICAL MODELS ETS and ARIMA are widely used statistical models in time series prediction. Here we compare the performance of our methodology with those two models, using our proposed methodology, actual monitoring data and forecast data from ARIMA and ETS, as shown in Figure 7. This model was designed and optimized by the Statsmodels1 package in Python, and the performance evaluation results are shown in Table 5.\nIt is clear from the chart that ETS is superior to ARIMA in the test set of toxic gas sampling data set consisting of six component monitoring gases. This result is due to the fact that ETS can handle both linear and nonlinear modes, while ARIMA can only handle linear modes. However, The LSTM model designed by us has achieved the best results on RMSE, MAE and r, and the prediction effect is far better than RMSE and MAE.\nB. COMPARSION WITH MACHINE LEARNING MODELS In this section, we compare the performance of the proposed methodwith twomachine learning algorithms, support vector machine (SVM) and BP neural network (BP). SVM is a\nVOLUME 10, 2022 1597\nmachine learning method based on statistical learning theory used to solve classification and regression tasks [25].\nThis article is implemented and optimized using Scikit-Learn Package2 in Python; The neural network with hidden layer\n1598 VOLUME 10, 2022\nusing back propagation algorithm is one of the widely used neural network types in time series prediction [26]. The design of BP neural network is realized by using Keras in Python. Figure 8 shows the comparison of actual data and predicted data in our proposed method and machine learning methods including support vector machine and neural network. The performance comparison results are shown in Table 6.\nBP model and LSTM model designed in this paper are obviously superior to SVMmodel in RMSE, MAE and r, and the AVERAGE RMSE, MAE and r of BP model are 52.84%, 34.92% and 20.14% lower than that of this model. However, due to the generalization ability of BP neural network for complex nonlinear problems, it still has certain universality in time series prediction. Compared with the other two models, SVM model has no obvious advantages. The reason for this result may be that the SVM algorithm depends too much on the selection of parameters, and it is difficult to obtain the optimal parameters without external algorithm optimization. However, compared with Figure. 7 and Figure 8, the accuracy of SVM is higher than that of traditional statistical prediction methods. Compared with artificial neural network, SVMwith fewer parameters still has certain advantages in time series prediction.\nFrom the perspective of data and conclusions, this paper introduces the LSTM deep learning model, which has good memory ability for historical information, into the prediction analysis of gas concentration in contaminated sites. The model shows good performance and minimum standard deviation in the prediction results of each month, indicating that the designed LSTM model is better than the traditional statistical theory and classical artificial intelligence algorithm in the prediction accuracy and stability, and has stronger adaptability and generalization ability. Although the gradient\nproblem of RNN has been solved in LSTM network to some extent, it is still very difficult for the sequence of high order. In addition, if the time span of the sequence is very large and the network is very deep, the calculation will be very heavy and time-consuming. In the subsequent work, we will further explore the research direction mentioned above. Future research can also consider using other deep learningmethods, such as the prediction of relevant time series based on the attention mechanism network.\nVI. RELATED WORKS Currently, there are a variety of methods for predicting the composition size of gaseous pollutants. The main methods can be divided into two categories: one is based on mathematical calculation and the other is based on historical samplemodeling.Mathematical calculationmodels mainly include Gaussian diffusion model and computational fluid dynamics (CFD) model. Gaussian plume diffusion model predicts gas diffusion according to wind speed and direction and calculates according to diffusion expression.\nThe expression of calculation formula is relatively simple, and the calculation period is short, but this model is only applicable to gas flow on flat ground, the prediction of gas in complex geographical environment such as polluted sites is unreliable [27]. CFD model is suitable for predicting gas diffusion on complex urban terrain with dense buildings. Because the flexible representation of complex geometry determines the high calculation accuracy of the model, the model has good practicability for different types of urban terrain, but the calculation time of the model can be up to several hours. For emergencies, the emergency response capability of the model cannot effectively develop solutions for staff [3], [4].\nVOLUME 10, 2022 1599\nThe other is based on historical sample modeling methods, including traditional modeling methods and emerging artificial intelligence methods. Traditional modeling methods based on historical samples include multiple linear regression method, Kalman filter technology, time-space series model method, etc. (existing time-space seriesmodels such as ARIMA [6], seasonal ARIMA [7], gaussian plume diffusion model [8]). The prediction method based on multiple linear regression approximates the gas diffusion model to linear model, which reduces the accuracy of prediction. The method based on spatio-temporal sequence mode requires experienced personnel to determine the parameters and order, which hinders the deployment of the model. To simplify the complexity of model building process, a series of pollutant prediction models based on machine learning are proposed [9]. For example, the model combining cellular automata and artificial neural network is used to predict the methane gas diffusion model in two-dimensional environment, which not only maintains a certain accuracy, but also is much better than the CFD model in calculation time [10]. In addition, the\ngas pollution prediction model based on BP neural network has certain nonlinearity and generalization capability [11]. Although this kind of model can get rid of the dependence of the modeling process on experienced personnel, and the artificial neural network has some outstanding ability in gas prediction in the above research, the model has the problems of slow training speed and low prediction accuracy.\nTo solve the problems in machine learning model, Saratha Sathasivam proposed a recurrent neural network (RNN) [12]. RNN folds the hidden layer on the structure and iteratively calculates the data features of time series, so that it has certain memory ability. However, RNN has the problem of gradient disappearance, which makes it difficult for RNN to learn the state characteristics of long-term sequence data. Therefore, Sepp Hochreiter and J\u00fcrgen Schmidhuber proposed a variant of recurrent neural network, long-term and short-term memory neural network (LSTM) [13]. This method adds memory units to the neural units of RNN hidden layer, which effectively solves the problems of long-term dependence and gradient disappearance of information. The LSTMmodel has\n1600 VOLUME 10, 2022\nbeen widely used in the field of environmental science. For example, a more effective and accurate wind speed prediction model was established based on LSTM, and the hourly solar radiation intensity was predicted and the carbon dioxide concentration in the forest environment was monitored according to the weather forecast data set [28]. Qian Fei, Chen Li et al directly applied the LSTM model designed to the gas diffusion problem, conducted experiments with the classical prairie grass project data set and compared the performance of other diffusion models, but this experiment only used the environmental characteristics in the data set as the input, ignoring the continuous influence of gas concentration [29]. Qin et al proposed a prediction scheme of urban PM2.5 pollutant concentration based on convolutional neural network and LSTM. The model used CNN to extract the spatial representation between monitoring stations as the input feature. By learning the features contained in the air pollution concentration under the time series of historical data, LSTM was used to predict the future air pollution concentration. This method only pays attention to the time and space effect of monitoring data, and ignores the effect of wind speed, wind direction, temperature, atmospheric stability and other external factors on gas prediction [30]. For gas prediction in time series, gas concentration at each sampling point and current environmental parameters play a decisive role in the accuracy of prediction. Although work A also collects relevant weather data and distinguishes feature weights, its output is single, while our forecast output is multi-pollutant gas component andwe consider the coupling relationship among each output.\nVII. CONCLUSION In this paper, the LSTM deep learning model is applied to the real contaminated site treatment process, with the purpose of predicting the gas content of each component in the site, and helping the site personnel to make reasonable and scientific decisions. Combined with Dropout regularization technology, we constructed an optimized multi-layer LSTM network model and applied it to gas concentration prediction analysis. The toxic gas sampling data set is constructed based on the detection data of on-site multi-component toxic gas monitoring equipment. In the experiment, we compared the proposed method with some typical time series prediction techniques in the two dimensions of statistics and artificial intelligence. The experimental results show that the proposed method is superior to other methods in prediction accuracy and accuracy, and achieves the best performance in RMSE, MAE and r, followed by BP and SVM, which means that the means of artificial intelligence have strong ability in time series data analysis. In addition, the experimental results show that the performance of traditional statistical methods such as ARIMA and ETS is poor. In view of the strong selflearning ability, good generalization ability and high adjust ability of the model of LSTM network, its model has broad prospects in the prediction of toxic gas concentration with time series characteristics in the process of pollution control and prevention.\nACKNOWLEDGMENT The authors would like to thank the Engineering Research Center for Optoelectronic Devices and Communication Technology,Ministry of Education, Tianjin University of Technology, and the Tianjin Key Laboratory of Control Theory and Applications for Complex Systems for their assistance.\nREFERENCES [1] P. Guo, H. Li, and G. Zhang, \u2018\u2018Contaminated site\u2013induced health risk\nusing Monte Carlo simulation: Evaluation from the brownfield in Beijing, China,\u2019\u2019 Environ. Sci. Pollut. Res., vol. 28, pp. 25166\u201325178, Jun. 2021. [2] J. Chen, K. de Hoogh, J. Gulliver, and B. Hoffmann, \u2018\u2018A comparison of linear regression, regularization, and machine learning algorithms to develop Europe-wide spatial models of fine particles and nitrogen dioxide,\u2019\u2019 Environ. Int., vol. 130, Sep. 2019, Art. no. 104934. [3] M. Pontiggia, M. Derudi, M. Alba, M. Scaioni, and R. Rota, \u2018\u2018Hazardous gas releases in urban areas: Assessment of consequences through CFD modelling,\u2019\u2019 J. Hazardous Mater., vol. 176, nos. 1\u20133, pp. 589\u2013596, Apr. 2010. [4] S. R. Hanna, O. R. Hansen, M. Ichard, and D. Strimaitis, \u2018\u2018CFD model simulation of dispersion from chlorine railcar releases in industrial and urban areas,\u2019\u2019 Atmos. Environ., vol. 43, no. 2, pp. 262\u2013270, Jan. 2009. [5] S. Metia, S. Oduro, Q. Ha, and H. Duc, \u2018\u2018Air pollution prediction using Mat\u00e9rn function based extended fractional Kalman filtering,\u2019\u2019 in Proc. 13th Int. Conf. Control Automat. Robot. Vis. (ICARCV), Dec. 2014, pp. 758\u2013763. [6] R. Wongsathan and I. Seedadan, \u2018\u2018A hybrid ARIMA and neural networks model for PM-10 pollution estimation: The case of Chiang Mai city moat area,\u2019\u2019 Proc. Comput. Sci., vol. 86, pp. 273\u2013276, Mar. 2016. [7] S. Chattopadhyay and G. Chattopadhyay, \u2018\u2018Modeling and prediction of monthly total ozone concentrations by use of an artificial neural network based on principal component analysis,\u2019\u2019 Pure Appl. Geophys., vol. 169, no. 10, pp. 1891\u20131908, Oct. 2012. [8] R. Wang, B. Chen, S. Qiu, Z. Zhu, Y. Wang, Y. Wang, and X. Qiu, \u2018\u2018Comparison of machine learning models for hazardous gas dispersion prediction in field cases,\u2019\u2019 Int. J. Environ. Res. Public Health, vol. 15, no. 7, p. 1450, Jul. 2018. [9] D. Ma and Z. Zhang, \u2018\u2018Contaminant dispersion prediction and source estimation with integrated Gaussian-machine learning network model for point source emission in atmosphere,\u2019\u2019 J. Hazardous Mater., vol. 311, pp. 237\u2013245, Jul. 2016. [10] P. Lauret, F. Heymes, L. Aprin, and A. Johannet, \u2018\u2018Atmospheric dispersion modeling using artificial neural network based cellular automata,\u2019\u2019 Environ. Model. Softw., vol. 85, pp. 56\u201369, Nov. 2016. [11] J. Ouyang and A. Wang, \u2018\u2018The application of concentration forecasting of air pollutant based on BP neural network in MATLAB,\u2019\u2019 Environ. Sci. Manage., to be published. [12] H.Hewamalage, C. Bergmeir, andK. Bandara, \u2018\u2018Recurrent neural networks for time series forecasting: Current status and future directions,\u2019\u2019 Int. J. Forecasting, vol. 37, no. 1, pp. 388\u2013427, 2021. [13] C. Gulcehre, K. Cho, R. Pascanu, and Y. Bengio, \u2018\u2018Learned-norm pooling for deep feedforward and recurrent neural networks,\u2019\u2019 in Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases. Berlin, Germany: Springer, 2014, pp. 530\u2013546. [14] L. Xu, C.-S. Choy, and Y.-W. Li, \u2018\u2018Deep sparse rectifier neural networks for speech denoising,\u2019\u2019 in Proc. IEEE Int. Workshop Acoustic Signal Enhancement (IWAENC), Sep. 2016, pp. 1\u20135. [15] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, \u2018\u2018Dropout: A simple way to prevent neural networks from overfitting,\u2019\u2019 J. Mach. Learn. Res., vol. 15, no. 1, pp. 1929\u20131958, 2014. [16] Y.-Q. Zhang and X.-Y. Wang, \u2018\u2018A new image encryption algorithm based on non-adjacent coupled map lattices,\u2019\u2019 Appl. Soft. Comput., vol. 26, pp. 10\u201320, Jan. 2015. [17] D. J. Gunn, Z. Liu, R. Dave, X. Yuan, and K. Roy, \u2018\u2018Touch-based active cloud authentication using traditional machine learning and LSTM on a distributed tensorflow framework,\u2019\u2019 Int. J. Comput. Intell. Appl., vol. 18, no. 4, Dec. 2019, Art. no. 1950022. [18] H. Li, X. Mu, Y. Yang, and A. J. Mason, \u2018\u2018Low power multimode electrochemical gas sensor array system for wearable health and safety monitoring,\u2019\u2019 IEEE Sensors J., vol. 14, no. 10, pp. 3391\u20133399, Oct. 2014.\nVOLUME 10, 2022 1601\n[19] M. Akhoondzadeh, \u2018\u2018AMLP neural network as an investigator of TEC time series to detect seismo-ionospheric anomalies,\u2019\u2019 Adv. Space Res., vol. 51, no. 11, pp. 2048\u20132057, Jun. 2013. [20] Y. Su, Y. Zhao, M. Sun, S. Zhang, and X. Wen, \u2018\u2018Detecting outlier machine instances through Gaussian mixture variational autoencoder with one dimensional CNN,\u2019\u2019 IEEE Trans. Comput., early access, Mar. 9, 2021, doi: 10.1109/TC.2021.3065073. [21] X. H. Cao, I. Stojkovic, and Z. Obradovic, \u2018\u2018A robust data scaling algorithm to improve classification accuracies in biomedical data,\u2019\u2019 BMC Bioinf., vol. 17, no. 1, p. 359, Sep. 2016. [22] R. Hemeimat, \u2018\u2018Demand forecasting for motor vehicle spare parts,\u2019\u2019 Amer. J. Oper. Res., pp. 113\u2013120, 2016. [23] D. Haboudane, J. R.Miller, E. Pattey, P. J. Zarco-Tejada, and I. B. Strachan, \u2018\u2018Hyperspectral vegetation indices and novel algorithms for predicting green LAI of crop canopies: Modeling and validation in the context of precision agriculture,\u2019\u2019 Remote Sens. Environ., vol. 90, no. 3, pp. 337\u2013352, 2004. [24] R. Taylor, \u2018\u2018Interpretation of the correlation coefficient: A basic review,\u2019\u2019 J. Diagnostic Med. Sonogr., vol. 6, no. 1, pp. 35\u201339, 1990. [25] L.Wang, \u2018\u2018Support vector machines: Theory and applications,\u2019\u2019 inMachine Learning and Its Applications (Advanced Lectures). Springer-Verlag, Jan. 2001. [26] F. S. Wong, \u2018\u2018Time series forecasting using backpropagation neural networks,\u2019\u2019 Neurocomputing, vol. 2, no. 4, pp. 147\u2013159, Jul. 1991. [27] A. Mazzoldi, T. Hill, and J. J. Colls, \u2018\u2018CFD and Gaussian atmospheric dispersion models: A comparison for leak from carbon dioxide transportation and storage facilities,\u2019\u2019 Atmos. Environ., vol. 42, no. 34, pp. 8046\u20138054, Nov. 2008. [28] H. Liu, X. Mi, and Y. Li, \u2018\u2018Smart multi-step deep learning model for wind speed forecasting based on variational mode decomposition, singular spectrum analysis, LSTM network and ELM,\u2019\u2019 Energy Convers. Manage., vol. 159, pp. 54\u201364, Mar. 2018. [29] F. Qian, L. Chen, J. Li, C. Ding, X. Chen, and J. Wang, \u2018\u2018Direct prediction of the toxic gas diffusion rule in a real environment based on LSTM,\u2019\u2019 Int. J. Environ. Res. Public Health, vol. 16, no. 12, p. 2133, Jun. 2019. [30] J. Ni, H. Yang, J. Yao, Z. Li, and P. Qin, \u2018\u2018Toxic gas dispersion prediction for point source emission using deep learning method,\u2019\u2019 Hum. Ecol. Risk Assessment: Int. J., vol. 26, no. 2, pp. 557\u2013570, Jan. 2019.\nYU CONG was born in Tianjin, China, in 1996. He is currently pursuing the degree major in control science and technology with the School of Electrical and Electronic Engineering, Tianjin University of Technology.\nXIMENG ZHAO was born in Jilin, China, in 1987. She received the M.S. degree in national economics, in 2012. She is currently pursuing the Ph.D. degree in international economics with the University of International Business and Economics. After five years working for companies, such as Detecon consulting and Mercedes-Benz.\nKE TANG was born in Henan, China, in 1990. He received the M.S. degree in international business, in 2013. He is currently pursuing the Ph.D. degree in international economics with the University of International Business and Economics.\nGE WANG was born in Shaanxi, China, in 1995. She is currently pursuing the degree major in business administration with the College of Management and Economics, Tianjin University.\nYANFEI HU was born in Henan, China, in 1989. He received the B.S. and M.S. degrees in automation, in 2012 and 2015, respectively. He is currently pursuing the Ph.D. degree major in computer science with the University of Chinese Academy of Science. He had worked as a Software Engineer in a company that develops automotive electronics. His research interest includes explanation in deep learning model.\nYINGKUI JIAO was born in Henan, China, in 1981. He received the B.S. and M.S. degrees in automation, in 2004 and 2015, respectively. He is currently pursuing the Ph.D. degree in precision instruments and machinery with Tianjin University. He had worked as a Software Engineer in a company that develops electronics device.\n1602 VOLUME 10, 2022"
        }
    ],
    "title": "FA-LSTM: A Novel Toxic Gas Concentration Prediction Model in Pollutant Environment",
    "year": 2022
}