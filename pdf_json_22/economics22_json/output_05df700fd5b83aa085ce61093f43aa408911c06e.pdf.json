{
    "abstractText": "Using Random Matrix Theory, we propose a universal and versatile tool to reveal the existence of \u201cfleeting modes\u201d, i.e. portfolios that carry statistically significant excess risk, signalling ex-post a change in the correlation structure in the underlying asset space. Our proposed test is furthermore independent of the \u201ctrue\u201d (but unknown) underlying correlation structure. We show empirically that such fleeting modes exist both in futures markets and in equity markets. We proposed a metric to quantify the alignment between known factors and fleeting modes and identify momentum as a source of excess risk in the equity space. Introduction Managing the risk of large portfolios requires the knowledge of equally large covariance matrices, describing the whole array of pairwise cross-correlation between the assets included in the portfolio. As is well-known by now, the empirical determination of such covariance matrices is difficult \u2013 for at least two different reasons. One is that even in a stationary world, that is, a world described by an unknown underlying stochastic process with time independent parameters, empirical covariance matrices are soiled by a large amount of measurement noise, that only goes to zero as p N/T , where N is the number of assets and T the amount of data points in the time direction \u2013 for a recent review, see [1]. Typical numbers are N = 500 stocks in a portfolio, and T = 1000 days of data (corresponding to 4 years), p N/T \u2248 0.7 which is by no means small! A number of techniques have been proposed over the years to \u201cclean\u201d as efficiently as possible the empirical covariance matrix E such that one approaches as well as possible the \u201ctrue\u201d covariance matrix C [2, 3, 4], and for reviews [5, 6] and refs. therein. Such cleaning schemes, some based on sophisticated Random Matrix Theory techniques, do help in reducing the discrepancy between \u201cout-of-sample\u201d risk (i.e. risk realized in a period outside the training sample) and \u201cin-sample\u201d risk (i.e. risk estimated on the same period as the training sample). However, the assumption of a stationary world is certainly too naive to describe financial markets. For one thing, volatility can strongly fluctuate from one period to the next, so \u201cout-of-sample\u201d risk may be larger or smaller than \u201cin-sample\u201d risk simply due to realized volatility. This is a well-studied issue, which can be partly mitigated by the use of sophisticated volatility models and/or using the forward looking, implied volatility from option 1 ar X iv :2 20 5. 01 01 2v 1 [ qfi n. PM ] 2 M ay 2 02 2 markets. In this study, we are rather concerned about correlation risk. As a striking example, think of the correlation between the daily price changes of the S&P500 index and the US T-Bond. For many years before 1997, it hovered around +0.5, before suddenly switching sign around the so-called Asian crisis. It then remained in negative territory \u2013 in a \u201cflight-tosafety\u201d mode \u2013 for more than 20 years before possibly switching again in 2021/2022, time will say [7]. More generally, one can expect that as macroeconomic conditions evolve, the whole correlation structure between financial assets also evolves. Several ideas to quantify such a genuine evolution of correlations have been discussed in the past [8, 9, 10, 11], in particular the interesting notion of \u201cmarket states\u201d [12, 13]. The main difficulty is to disentangle measurement noise, which leads to an apparent evolution of the empirical covariance matrix between two non overlapping periods, from any possible evolution of the underlying covariance matrix C. In Ref. [14], two of us proposed a non parametric method based on the overlap of the eigenvectors of Ein and those of Eout, where \u201cin\u201d and \u201cout\u201d refer, respectively, to the in-sample and out-of-sample period. Quite interestingly, our proposal did not require the knowledge of C, only that it was time independent. In this note, we want to propose an alternative non parametric test, simpler and more transparent, which again does not rely on the knowledge of C and allows one to diagnose periods of statistically significant excess correlation risk and identify the directions (in asset space) along which such excess risk manifests itself. Theoretical Tools & Analytical Results Let X= X i,t be the return data set, where i is the asset label and t the time label. The in-sample covariance matrix Ein is defined as Ein = 1 Tin \u2211 t\u2208in X i,t X j,t := 1 Tin XinX > in, (1) where Tin is the length of the in-sample period. The out-of-sample covariance matrix Eout is defined similarly, with Tout is the length of the out-sample period. Let us now introduce the matrix D defined as: D := E in EoutE \u22121/2 in , (2) where E in is defined as the symmetric matrix square-root of Ein. The intuitive meaning of D is as follows. By defining Yin := OE \u22121/2 in Xin, where O is an arbitrary rotation matrix, we construct a set of N synthetic assets (or portfolios) that are by construction ortho-normal, i.e. each synthetic asset is of unit risk and uncorrelated (in sample) with all other synthetic assets. Now the out-of-sample covariance matrix of these synthetic assets is given by DO := ODO>, whose eigenvectors specify a new set of uncorrelated synthetic assets, with variance given by the eigenvalues \u03bba (which are independent of O). Since the in-sample risk of the synthetic assets has been normalized to one, the eigenvectors associated with the eigenvalues \u03bba > 1 thus correspond to linear combinations of synthetic assets that over-realize their risk in the out-of-sample period. In the following, we will choose O such that the synthetic assets are simply the principal risk components ~v\u03bc of the in-sample covariance matrix Ein. We will call the directions ~v\u03bc the statistical risk modes. Suppose qin = N/Tin and qout = N/Tout are both very small and the world is stationary, with true covariance matrix C. Then, clearly Ein \u2248 Eout \u2248 C \u2212\u2192 D\u2248 I. (3)",
    "authors": [
        {
            "affiliations": [],
            "name": "Jean-Philippe Bouchaud"
        },
        {
            "affiliations": [],
            "name": "Iacopo Mastromatteo"
        },
        {
            "affiliations": [],
            "name": "Marc Potters"
        },
        {
            "affiliations": [],
            "name": "Konstantin Tikhonov"
        }
    ],
    "id": "SP:a36a89dd611ceb28dcca95b1d43901c81c3abf70",
    "references": [
        {
            "authors": [
                "M. Potters",
                "J.P. Bouchaud"
            ],
            "title": "A First Course in Random Matrix Theory: For Physicists, Engineers and Data Scientists",
            "year": 2020
        },
        {
            "authors": [
                "O. Ledoit",
                "M. Wolf"
            ],
            "title": "Honey, I shrunk the sample covariance matrix",
            "venue": "The Journal of Portfolio Management,",
            "year": 2004
        },
        {
            "authors": [
                "N. El Karoui"
            ],
            "title": "Spectrum estimation for large dimensional covariance matrices using random matrix theory",
            "venue": "The Annals of Statistics,",
            "year": 2008
        },
        {
            "authors": [
                "O. Ledoit",
                "S. P\u00e9ch\u00e9"
            ],
            "title": "Eigenvectors of some large sample covariance matrix ensembles",
            "venue": "Probability Theory and Related Fields,",
            "year": 2011
        },
        {
            "authors": [
                "J. Bun",
                "J.P. Bouchaud",
                "M. Potters"
            ],
            "title": "Cleaning large correlation matrices: tools from random matrix theory",
            "venue": "Physics Reports,",
            "year": 2017
        },
        {
            "authors": [
                "O. Ledoit",
                "M. Wolf"
            ],
            "title": "The power of (non-) linear shrinking: A review and guide to covariance matrix estimation",
            "venue": "Journal of Financial Econometrics,",
            "year": 2022
        },
        {
            "authors": [
                "R. Engle"
            ],
            "title": "Dynamic conditional correlation: A simple class of multivariate generalized autoregressive conditional heteroskedasticity models",
            "venue": "Journal of Business & Economic Statistics,",
            "year": 2002
        },
        {
            "authors": [
                "P.A. Reigneron",
                "R. Allez",
                "J.P. Bouchaud"
            ],
            "title": "Principal regression analysis and the index leverage effect",
            "venue": "Physica A: Statistical Mechanics and its Applications,",
            "year": 2011
        },
        {
            "authors": [
                "R. Allez",
                "J.P. Bouchaud"
            ],
            "title": "Eigenvector dynamics: general theory and some applications",
            "venue": "Physical Review E,",
            "year": 2012
        },
        {
            "authors": [
                "A. Karami",
                "R. Benichou",
                "M. Benzaquen",
                "J.P. Bouchaud"
            ],
            "title": "Conditional Correlations and Principal Regression Analysis for Futures",
            "year": 2021
        },
        {
            "authors": [
                "M.C. M\u00fcnnix",
                "T. Shimada",
                "R. Sch\u00e4fer",
                "F. Leyvraz",
                "T.H. Seligman",
                "T. Guhr",
                "H.E. Stanley"
            ],
            "title": "Identifying states of a financial market",
            "venue": "Scientific reports,",
            "year": 2012
        },
        {
            "authors": [
                "N. Musmeci",
                "T. Aste",
                "T. Di Matteo"
            ],
            "title": "Risk diversification: a study of persistence with a filtered correlation-network approach",
            "venue": "Journal of Network Theory in Finance 1,",
            "year": 2015
        },
        {
            "authors": [
                "J. Bun",
                "J.P. Bouchaud",
                "M. Potters"
            ],
            "title": "Overlaps between eigenvectors of correlated random matrices",
            "venue": "Physical Review E,",
            "year": 2018
        },
        {
            "authors": [
                "V. Volpati",
                "M. Benzaquen",
                "Z. Eisler",
                "I. Mastromatteo",
                "B. T\u00f3th",
                "J.P. Bouchaud"
            ],
            "title": "Zooming in on equity factor crowding",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Introduction Managing the risk of large portfolios requires the knowledge of equally large covariance matrices, describing the whole array of pairwise cross-correlation between the assets included in the portfolio.\nAs is well-known by now, the empirical determination of such covariance matrices is difficult \u2013 for at least two different reasons. One is that even in a stationary world, that is, a world described by an unknown underlying stochastic process with time independent parameters, empirical covariance matrices are soiled by a large amount of measurement noise, that only goes to zero as p\nN/T , where N is the number of assets and T the amount of data points in the time direction \u2013 for a recent review, see [1]. Typical numbers are N = 500 stocks in a portfolio, and T = 1000 days of data (corresponding to 4 years), p\nN/T \u2248 0.7 which is by no means small! A number of techniques have been proposed over the years to \u201cclean\u201d as efficiently as possible the empirical covariance matrix E such that one approaches as well as possible the \u201ctrue\u201d covariance matrix C [2, 3, 4], and for reviews [5, 6] and refs. therein. Such cleaning schemes, some based on sophisticated Random Matrix Theory techniques, do help in reducing the discrepancy between \u201cout-of-sample\u201d risk (i.e. risk realized in a period outside the training sample) and \u201cin-sample\u201d risk (i.e. risk estimated on the same period as the training sample).\nHowever, the assumption of a stationary world is certainly too naive to describe financial markets. For one thing, volatility can strongly fluctuate from one period to the next, so \u201cout-of-sample\u201d risk may be larger or smaller than \u201cin-sample\u201d risk simply due to realized volatility. This is a well-studied issue, which can be partly mitigated by the use of sophisticated volatility models and/or using the forward looking, implied volatility from option\nar X\niv :2\n20 5.\n01 01\n2v 1\n[ q-\nfi n.\nPM ]\n2 M\nmarkets. In this study, we are rather concerned about correlation risk. As a striking example, think of the correlation between the daily price changes of the S&P500 index and the US T-Bond. For many years before 1997, it hovered around +0.5, before suddenly switching sign around the so-called Asian crisis. It then remained in negative territory \u2013 in a \u201cflight-tosafety\u201d mode \u2013 for more than 20 years before possibly switching again in 2021/2022, time will say [7]. More generally, one can expect that as macroeconomic conditions evolve, the whole correlation structure between financial assets also evolves. Several ideas to quantify such a genuine evolution of correlations have been discussed in the past [8, 9, 10, 11], in particular the interesting notion of \u201cmarket states\u201d [12, 13].\nThe main difficulty is to disentangle measurement noise, which leads to an apparent evolution of the empirical covariance matrix between two non overlapping periods, from any possible evolution of the underlying covariance matrix C. In Ref. [14], two of us proposed a non parametric method based on the overlap of the eigenvectors of Ein and those of Eout, where \u201cin\u201d and \u201cout\u201d refer, respectively, to the in-sample and out-of-sample period. Quite interestingly, our proposal did not require the knowledge of C, only that it was time independent. In this note, we want to propose an alternative non parametric test, simpler and more transparent, which again does not rely on the knowledge of C and allows one to diagnose periods of statistically significant excess correlation risk and identify the directions (in asset space) along which such excess risk manifests itself.\nTheoretical Tools & Analytical Results Let X= X i,t be the return data set, where i is the asset label and t the time label. The in-sample covariance matrix Ein is defined as\nEin = 1 Tin \u2211\nt\u2208in\nX i,t X j,t := 1 Tin XinX > in, (1)\nwhere Tin is the length of the in-sample period. The out-of-sample covariance matrix Eout is defined similarly, with Tout is the length of the out-sample period.\nLet us now introduce the matrix D defined as:\nD := E\u22121/2in EoutE \u22121/2 in , (2)\nwhere E1/2in is defined as the symmetric matrix square-root of Ein. The intuitive meaning of D is as follows. By defining Yin := OE \u22121/2 in Xin, where O is an arbitrary rotation matrix, we construct a set of N synthetic assets (or portfolios) that are by construction ortho-normal, i.e. each synthetic asset is of unit risk and uncorrelated (in sample) with all other synthetic assets.\nNow the out-of-sample covariance matrix of these synthetic assets is given by DO := ODO>, whose eigenvectors specify a new set of uncorrelated synthetic assets, with variance given by the eigenvalues \u03bba (which are independent of O). Since the in-sample risk of the synthetic assets has been normalized to one, the eigenvectors associated with the eigenvalues \u03bba > 1 thus correspond to linear combinations of synthetic assets that over-realize their risk in the out-of-sample period. In the following, we will choose O such that the synthetic assets are simply the principal risk components ~v\u00b5 of the in-sample covariance matrix Ein. We will call the directions ~v\u00b5 the statistical risk modes.\nSuppose qin = N/Tin and qout = N/Tout are both very small and the world is stationary, with true covariance matrix C. Then, clearly\nEin \u2248 Eout \u2248 C \u2212\u2192 D\u2248 I. (3)\nHence, in this case, all eigenvalues of D are very close to unity \u2013 no portfolio over-realizes its risk, as expected. In the case where qin and qout take arbitrary values, one first notes that by definition, (white) Wishart matricesW correspond to empirical covariance matrices when C= I. Hence one can write, still assuming stationarity:\nEin = C1/2WinC1/2; Eout = C1/2WoutC1/2. (4)\nNow, since the characteristic polynomial ofD is the same as that ofE\u22121in Eout = C \u22121/2W\u22121in WoutC 1/2, which is turn is the same as that ofW\u22121in Wout, we conclude that the eigenvalues of D are actually independent of C, and equal to those of our theoretical benchmark\nDth. :=W \u22121/2 in WoutW \u22121/2 in , (5)\nwhereWin, Wout are independent Wishart matrices of parameter, respectively, qin and qout. In the following, we will assume qin < 1 , i.e. Tin > N , so thatWin is invertible.\nThe matrix Dth., a close relative of Jacobi random matrices, is the product of a Wishart and inverse-Wishart matrix and its spectrum can easily be computed, see e.g. [1]. Denoting \u03bb its eigenvalues, the probability density function of \u03bb reads:\n\u03c1(\u03bb) = 1\u2212 qin\n2\u03c0\np\n[(\u03bbmax \u2212\u03bb)(\u03bb\u2212\u03bbmin)]+\n\u03bb(qin\u03bb+ qout) +\n1\u2212 q\u22121out + \u03b4(\u03bb) (6)\nwith\n\u03bbmax,min = 1+ qin + qout(1\u2212 qin)\u00b1 2\np\nqin + qout(1\u2212 qin) (1\u2212 qin)2 , (7)\nwhere the symbol []+ denotes the positive part. Note that for qout > 1, a finite fraction of eigenvalues are exactly zero as expressed by the Dirac delta function. This density has mean (1\u2212 qin)\u22121 and variance (1\u2212 qin)\u22123(qin + qout(1\u2212 qin)).\nOur null hypothesis test is thus the following: if the true underlying covariance matrix C is the same in-sample and out-of-sample, the non-zero eigenvalues \u03bb of D should, for large N , all lie within the interval1\n\u03bb \u2208 [\u03bbmin,\u03bbmax] , (8)\nwith a distribution compatible with Eq. (6), see Fig. 1 for a particular illustration and numerical simulations. Several limiting cases are interesting to discuss. One is when the insample and out-of-sample period have the same length, i.e. Tin = Tout = T , or qin = qout = q. One then finds\n\u03bbmax,min = 1+ 2q\u2212 q2 \u00b1 2\np\nq(2\u2212 q) (1\u2212 q)2\n(9)\nWhen both periods are very long compared to N , one has q\u2192 0 and therefore the interval where the eigenvalues of D are expected to be found is\n\u03bb \u2208 1\u2212 2 p 2q, 1+ 2 p 2q , q := N T , (10)\nwhich, as expected, tends to a Dirac mass at \u03bb= 1 for q = 0.\n1For finite N , there are corrections to \u03bbmax,min of order N \u22122/3, with a prefactor that can be large in practice,\nsee Fig. 2.\nNow, look at another interesting regime where Tin Tout > N , i.e. long in-sample period and relatively short out-of-sample period, aiming at detecting abrupt \u201cregime shifts\u201d. In this regime where qin \u2192 0, we recover precisely the Marc\u030cenko-Pastur distribution with parameter q = qout [1], as it should be since in that limitWin \u2261 I and Ein \u2261 C. The non-zero eigenvalues of Dth. satisfy,\n\u03bb \u2208 (1\u2212 p qout) 2, (1+ p qout) 2 , (11)\nwith an additional Dirac mass of weight 1\u2212 q\u22121out when qout > 1.\nEmpirical Analysis for Stocks & Futures In order to quantify by how much real financial returns differ from their stylized counterpart above, we have constructed two data sets consisting of daily returns X = X i,t of two different groups of financial instruments. The first data set comprises a set of N = 98 liquid futures, covering different sectors (stock indices, commodities, FX, yields), expiry dates and geographies (America, Europe, Asia, and a smaller set of developing markets) in a period ranging from 2006-01-01 to 2022-03-01. The second data set consists in N = 300 US stocks in the period 2002-05-27 to 2022-01-21.2 In order to get rid of any spurious volatility fluctuations and only focus on correlations, we normalize each daily returns by its own intraday volatility, constructed using a Garman-Klass estimator based on Close-High-Low-Close data.\nIn both universes, we construct a set of rolling estimators Ein(t) and Eout(t) according to the following prescription. First, for each day after a \u201cburning\u201d period t > Tin + Tout, we consider the (in) interval as the one comprising returns belonging to [t\u2212 Tout\u2212 Tin, t\u2212 Tout[, whereas the (out) interval is built with the returns belonging to [t\u2212Tout, t[. This construction ensures that i) intervals built at time t only use data available at day t ii) the intervals are contiguous but perfectly disjoint iii) all in-sample and out-of-sample intervals have exactly\n2The detailed list of futures contracts and US stocks is available upon request to the authors. Note that we have not detrended daily returns by their means, which are for all purposes here negligible.\nthe same lengths Tin and Tout iv) under the hypothesis of i.i.d. returns, the estimators Ein(t) and Eout(t) are distributed according to the null model described above.\nFor both futures and stocks, we have decided to fix qin = 1 4 and qout = 4, which corresponds to an in-sample period of a year and a half for futures (about five years for stocks) and an out-of-sample interval of approximately one month for futures (slightly less than four months for stocks). We then apply the definition Eq. 1 to both in-sample and out-of-sample intervals, obtaining rolling sets of covariance matrices indexed by t and denoted as Ein(t) and Eout(t).\nFinally, we build risk over-realization matrices D(t) = E\u22121/2in (t)Eout(t)E \u22121/2 in (t), from which we can extract eigenvalues {\u03bba(t)} that can be compared to the ones prescribed by our null hypothesis. The corresponding eigenvectors also contain important information, to be discussed below.\nFig. 2 illustrates the result of such comparison for both futures (left panel) and stocks (right panel), indicating that in both cases we detect significant departures from the null model. However, the average eigenvalue distribution does not distinguish between an intermittent scenario where risk-over realisation is clustered in time, from a uniform scenario where risk is always over-realized. Part of such information is summarized in Fig. 3, where the evolution of the top eigenvalue \u03bb1(t) is displayed for both our data sets, and compared to the value expected under our null model. Departure from the null model are relatively mild in some periods and stronger in others, with clear spikes, notably in the futures space.\nThe directions along which excess out-of-sample risk is large are given by the eigenvectors ~za of DO := Z>diag(\u03bba)Z corresponding to the largest eigenvalues \u03bba. As explained\nabove, because of our choice of O := ~v, these eigenvectors can be interpreted as portfolios of the (in-sample) statistical risk modes ~v\u00b5, \u00b5 = 1, . . . , N . We will call the eigenvectors ~za fleeting modes.\nThe first question one would like to ask is how close is the top fleeting mode ~z1 (corresponding to the top eigenvalue \u03bb1) to the dominant in-sample risk modes ~v\u00b5. We thus define the cumulative squared overlap as \u03c8n := \u2211n \u00b5=1(~z1 \u00b7 ~\u03bd\u00b5)\n2, where ~z1 \u00b7 ~\u03bd\u00b5 is the \u00b5th risk mode component of ~z1. Note that\u03c8N \u2261 1 for n= N , because the set of {~v\u00b5} forms an orthonormal basis. Fig. 4 shows\u03c8n as a function of n, both for futures and for equities, averaged over (a) days where the over-realisation of risk is in the top 10% and (b) days where the over-realisation of risk is in the bottom 90%. We compare these cumulative overlaps with a stationary null model where the true covariance matrix is Ein.3\nThe results are quite striking: whereas in most cases, the null model explains rather well the direction in which risk is over-realised, the top 10% cases are clearly different. For futures, large excess out-of-sample risk is concentrated in the statistical risk modes with the smallest in-sample risk, whereas for stocks, excess risk is in the direction of the statistical modes with the largest in-sample risk (see also the related discussion in [10, 14].)\nFor futures, risk over-realisation tends to come from the sudden divergence of the spread between tightly correlated contracts, for example associated to the delivery of the same underlying at different expiry dates. The spread between those contracts is typically close to zero, but exogenous shocks might lead such a typically quiet direction to generate anomalous risk along the term structure of the contract. As an example, we observe in Fig. 3 a spike around April 21st, 2020 that corresponds to the days in which the price of crude oil futures has been strongly stressed by a COVID-induced demand shock. Our metrics thus identifies\n3A null model with a true covariance matrix equal to the identity I leads to quite different results, very far from empirical data. This result shows that these overlaps are, unsurprisingly, very sensitive to the underlying correlation structure.\nsuch directions as fleeting modes, since in the presence of tiny in-sample risk directions, even a moderate out-of-sample risk leads to a very strong spike in the top eigenvalue of D.\nIn contrast to futures, the absence of strong mechanical correlations between equity instruments leads to a smaller loading of fleeting modes on low risk modes, and a larger loading on high risk modes (industrial sectors and/or equity factors) which tend to overrealize their risk in a systematic fashion. A natural question is whether known factors could be at the origin of such excess risks in equity portfolios. A natural candidate is the momentum factor. Indeed, let us consider the case Tin Tmom, where Tmom is the time-scale used to build the momentum signal. The in-sample risk model is then blind to such a factor, because the directions defined by momentum signal randomly rotate over time and average out when Tin Tmom. Hence, because of the impact of investors trading in and out [15], these factors should over-realize their expected risk provided Tmom \u00a6 Tout.\nIn order to quantify the role of factors (including momentum) in the observed excess risk, we define a metric that measures the alignment of a given factor direction with the subspace spanned by the n largest eigenvectors of D(t). More precisely, we define by the normalized factor loadings zf,i(t) on the real assets i = 1, . . . , N (with \u2016~zf(t)\u20162 = 1) and similarly rotate the fleeting modes ~za(t) back into the real asset basis. We then consider the following overlap\n\u03c6n(t) := n \u2211\na=1\n(~zf(t) \u00b7 ~za(t)) 2 \u2261\nn \u2211\na=1\nN \u2211\ni=1\nzf,i(t) za,i(t)\n2\n. (12)\nNote that 0\u2264 \u03c6n(t)\u2264 1, with \u03c6N (t)\u2261 1, since ~za is a complete ortho-normal basis.\nFig. 5 shows the average value of\u03c6n(t) over the whole period, for n\u2264 30 when the factor f = mom is the momentum factor for stocks4. We compare this result with a null model that has the same projection amplitude on the statistical risk modes ~v\u00b5(t) as momentum, but with randomly scrambled signs. This graph clearly shows that a significant portion of the risk over-realization in the equity space can indeed be explained as an exposure to the momentum factor, which is itself buffeted by the price impact of momentum trader.\nConclusion Using Random Matrix Theory, we have provided a universal and versatile tool to analyse the statistical significance and financial origin of risk over-realisation in large portfolios. The eigenvalues and eigenvectors of an appropriately constructed matrix mixing in-sample and out-of-sample data allows one to identify \u201cfleeting modes\u201d, i.e. portfolios that carry significant excess risk, signalling (ex-post) a change in the correlation structure in the underlying asset space. Our proposed test is furthermore independent of the \u201ctrue\u201d underlying correlation structure, which is obviously unknown to the modeler. We have shown empirically that such fleeting modes exist both in futures markets and in equity markets, and analyzed the directions in which excess risk manifests itself. We have proposed a metric to quantify the alignment between known factors and fleeting modes. As a case in point, momentum exposure clearly appears as a source of excess risk in equity portfolios that is not captured by low frequency correlation matrices.\n4We define momentum as market-neutralized rank-transformed lagged trend signal, with trendt = pt/ewma (pt , halflife= 100D)."
        }
    ],
    "title": "Excess Out-of-Sample Risk and Fleeting Modes",
    "year": 2022
}