{
    "abstractText": "Animesh Ghose ,1 Mikhail Segal ,1 Fanchen Meng ,2 Zhu Liang ,2 Mark S. Hybertsen ,2 Xiaohui Qu ,2 Eli Stavitski ,3 Shinjae Yoo ,1 Deyu Lu ,2,* and Matthew R. Carbone 1,\u2020 1Computational Science Initiative, Brookhaven National Laboratory, Upton, New York 11973, USA 2Center for Functional Nanomaterials, Brookhaven National Laboratory, Upton, New York 11973, USA 3National Synchrotron Light Source II, Brookhaven National Laboratory, Upton, New York 11973, USA",
    "authors": [
        {
            "affiliations": [],
            "name": "Animesh Ghose"
        },
        {
            "affiliations": [],
            "name": "Mikhail Segal"
        },
        {
            "affiliations": [],
            "name": "Fanchen Meng"
        },
        {
            "affiliations": [],
            "name": "Zhu Liang"
        },
        {
            "affiliations": [],
            "name": "Mark S. Hybertsen"
        },
        {
            "affiliations": [],
            "name": "Xiaohui Qu"
        },
        {
            "affiliations": [],
            "name": "Eli Stavitski"
        },
        {
            "affiliations": [],
            "name": "Shinjae Yoo"
        },
        {
            "affiliations": [],
            "name": "Deyu Lu"
        },
        {
            "affiliations": [],
            "name": "Matthew R. Carbone"
        }
    ],
    "id": "SP:27eb113b8d37251481719ae9255b74cb8c9d6abf",
    "references": [
        {
            "authors": [
                "K.T. Butler",
                "D.W. Davies",
                "H. Cartwright",
                "O. Isayev",
                "A. Walsh"
            ],
            "title": "Machine learning for molecular and materials science",
            "venue": "Nature (London) 559, 547 ",
            "year": 2018
        },
        {
            "authors": [
                "G. Carleo",
                "I. Cirac",
                "K. Cranmer",
                "L. Daudet",
                "M. Schuld",
                "N. Tishby",
                "L. Vogt-Maranto",
                "L. Zdeborov\u00e1"
            ],
            "title": "Machine learning and the physical sciences",
            "venue": "Rev. Mod. Phys. 91, 045002 ",
            "year": 2019
        },
        {
            "authors": [
                "J. Behler",
                "M. Parrinello"
            ],
            "title": "Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces",
            "venue": "Phys. Rev. Lett. 98, 146401 ",
            "year": 2007
        },
        {
            "authors": [
                "R. Ramakrishnan",
                "P.O. Dral",
                "M. Rupp",
                "O.A. Von Lilienfeld"
            ],
            "title": "Big data meets quantum chemistry approximations: the \u03b4-machine learning approach",
            "venue": "J. Chem. Theory Comput. 11, 2087 ",
            "year": 2015
        },
        {
            "authors": [
                "Z. Wu",
                "B. Ramsundar",
                "E.N. Feinberg",
                "J. Gomes",
                "C. Geniesse",
                "A.S. Pappu",
                "K. Leswing",
                "V. Pande"
            ],
            "title": "Moleculenet: A benchmark for molecular machine learning",
            "venue": "Chem. Sci. 9, 513 ",
            "year": 2018
        },
        {
            "authors": [
                "R. G\u00f3mez-Bombarelli",
                "J.N. Wei",
                "D. Duvenaud",
                "J.M. Hern\u00e1ndez-Lobato",
                "B. S\u00e1nchez-Lengeling",
                "D. Sheberla",
                "J. Aguilera-Iparraguirre",
                "T.D. Hirzel",
                "R.P. Adams",
                "A. Aspuru-Guzik"
            ],
            "title": "Automatic chemical design using a data-driven continuous representation of molecules",
            "venue": "ACS Cent. Sci. 4, 268 ",
            "year": 2018
        },
        {
            "authors": [
                "Y. Nomura",
                "A.S. Darmawan",
                "Y. Yamaji",
                "M. Imada"
            ],
            "title": "Restricted boltzmann machine learning for solving strongly correlated quantum systems",
            "venue": "Phys. Rev. B 96, 205152 ",
            "year": 2017
        },
        {
            "authors": [
                "L.F. Arsenault",
                "A. Lopez-Bezanilla"
            ],
            "title": "O",
            "venue": "A. von Lilienfeld, and A. J. Millis, Machine learning for many-body physics: The case of the anderson impurity model, Phys. Rev. B 90, 155136 ",
            "year": 2014
        },
        {
            "authors": [
                "D.-L. Deng",
                "X. Li",
                "S. Das Sarma"
            ],
            "title": "Machine learning topological states",
            "venue": "Phys. Rev. B 96, 195145 ",
            "year": 2017
        },
        {
            "authors": [
                "M. Abdar",
                "F. Pourpanah",
                "S. Hussain",
                "D. Rezazadegan",
                "L. Liu",
                "M. Ghavamzadeh",
                "P. Fieguth",
                "X. Cao",
                "A. Khosravi"
            ],
            "title": "U",
            "venue": "R. Acharya et al., A review of uncertainty quantification in deep learning: Techniques, applications and challenges, Inf. Fusion 76, 243 ",
            "year": 2021
        },
        {
            "authors": [
                "C.E. Rasmussen",
                "C.K.I. Williams"
            ],
            "title": "Gaussian Processes for Machine Learning",
            "year": 2006
        },
        {
            "authors": [
                "S. Krishnadasan",
                "R.J.C. Brown",
                "A.J. Demello",
                "J.C. Demello"
            ],
            "title": "Intelligent routes to the controlled synthesis of nanoparticles",
            "venue": "Lab Chip 7, 1434 ",
            "year": 2007
        },
        {
            "authors": [
                "D.E. Fitzpatrick",
                "C. Battilocchio",
                "S.V. Ley"
            ],
            "title": "A novel internet-based reaction monitoring",
            "venue": "control and autonomous self-optimization platform for chemical synthesis, Org. Process Res. Dev. 20, 386 ",
            "year": 2016
        },
        {
            "authors": [
                "R.W. Epps",
                "M.S. Bowen",
                "A.A. Volk",
                "K. Abdel-Latif",
                "S. Han",
                "K.G. Reyes",
                "A. Amassian",
                "M. Abolhasani"
            ],
            "title": "Artificial chemist: an autonomous quantum dot synthesis bot",
            "venue": "Adv. Mater. 32, 2001626 ",
            "year": 2020
        },
        {
            "authors": [
                "A.E. Gongora",
                "B. Xu",
                "W. Perry",
                "C. Okoye",
                "P. Riley",
                "K.G. Reyes",
                "E.F. Morgan",
                "K.A. Brown"
            ],
            "title": "A bayesian experimental autonomous researcher for mechanical design",
            "venue": "Sci. Adv. 6, eaaz1708 ",
            "year": 2020
        },
        {
            "authors": [
                "A.E. Gongora",
                "K.L. Snapp",
                "E. Whiting",
                "P. Riley",
                "K.G. Reyes",
                "E.F. Morgan",
                "K.A. Brown"
            ],
            "title": "Using simulation to accelerate autonomous experimentation: A case study using mechanics",
            "venue": "iScience 24, 102262 ",
            "year": 2021
        },
        {
            "authors": [
                "J. Behler"
            ],
            "title": "Atom-centered symmetry functions for constructing high-dimensional neural network potentials",
            "venue": "J. Chem. Phys. 134, 074106 ",
            "year": 2011
        },
        {
            "authors": [
                "N. Artrith",
                "T. Morawietz",
                "J. Behler"
            ],
            "title": "High-dimensional neural-network potentials for multicomponent systems: Applications to zinc oxide",
            "venue": "Phys. Rev. B 83, 153101 ",
            "year": 2011
        },
        {
            "authors": [
                "N. Artrith",
                "J. Behler"
            ],
            "title": "High-dimensional neural network potentials for metal surfaces: A prototype study for copper",
            "venue": "Phys. Rev. B 85, 045439 ",
            "year": 2012
        },
        {
            "authors": [
                "C. Schran",
                "K. Brezina",
                "O. Marsalek"
            ],
            "title": "Committee neural network potentials control generalization errors and enable active learning",
            "venue": "J. Chem. Phys. 153, 104105 (2020). 013180-18 UNCERTAINTY-AWARE PREDICTIONS OF MOLECULAR ... PHYSICAL REVIEW RESEARCH 5, 013180 ",
            "year": 2023
        },
        {
            "authors": [
                "J. Behler"
            ],
            "title": "Four generations of high-dimensional neural network potentials",
            "venue": "Chem. Rev. 121, 10037 ",
            "year": 2021
        },
        {
            "authors": [
                "P. Friederich",
                "F. H\u00e4se",
                "J. Proppe",
                "A. Aspuru-Guzik"
            ],
            "title": "Machine-learned potentials for next-generation matter simulations",
            "venue": "Nat. Mater. 20, 750 ",
            "year": 2021
        },
        {
            "authors": [
                "E.V. Podryabinkin",
                "A.V. Shapeev"
            ],
            "title": "Active learning of linearly parametrized interatomic potentials",
            "venue": "Comput. Mater. Sci. 140, 171 ",
            "year": 2017
        },
        {
            "authors": [
                "G. Sivaraman",
                "A.N. Krishnamoorthy",
                "M. Baur",
                "C. Holm",
                "M. Stan",
                "G. Cs\u00e1nyi",
                "C. Benmore",
                "\u00c1. V\u00e1zquez-Mayagoitia"
            ],
            "title": "Machine-learned interatomic potentials by active learning: amorphous and liquid hafnium dioxide",
            "venue": "npj Comput. Mater. 6, 104 ",
            "year": 2020
        },
        {
            "authors": [
                "B. Settles"
            ],
            "title": "Active Learning Literature Survey (Computer Science Technical Report 1648",
            "venue": "University of Wisconsin-Madison Department of Computer Sciences,",
            "year": 2009
        },
        {
            "authors": [
                "K. Gubaev",
                "E.V. Podryabinkin",
                "A.V. Shapeev"
            ],
            "title": "Machine learning of molecular properties: Locality and active learning",
            "venue": "J. Chem. Phys. 148, 241727 ",
            "year": 2018
        },
        {
            "authors": [
                "A.L. Ankudinov",
                "J.J. Rehr",
                "J.J. Low",
                "S.R. Bare"
            ],
            "title": "Sensitivity of Pt x-ray absorption near edge structure to the morphology of small Pt clusters",
            "venue": "J. Chem. Phys. 116, 1911 ",
            "year": 2002
        },
        {
            "authors": [
                "A.L. Ankudinov",
                "J.J. Rehr"
            ],
            "title": "Development of xafs theory",
            "venue": "J. Synchrotron Radiat. 10, 366 ",
            "year": 2003
        },
        {
            "authors": [
                "D. Bazin",
                "J.J. Rehr"
            ],
            "title": "Limits and advantages of x-ray absorption near edge structure for nanometer scale metallic clusters",
            "venue": "J. Phys. Chem. B 107, 12398 ",
            "year": 2003
        },
        {
            "authors": [
                "G. Ciatto",
                "A. Di Trolio",
                "E. Fonda",
                "P. Alippi",
                "A.M. Testa",
                "A.A. Bonapasta"
            ],
            "title": "Evidence of Cobalt-Vacancy Complexes in Zn1-xCoxO Dilute Magnetic Semiconductors",
            "venue": "Phys. Rev. Lett. 107, 127206 ",
            "year": 2011
        },
        {
            "authors": [
                "Q. Ma",
                "J.T. Prater",
                "C. Sudakar",
                "R.A. Rosenberg",
                "J. Narayan"
            ],
            "title": "Defects in room-temperature ferromagnetic Cu-doped ZnO films probed by x-ray absorption spectroscopy",
            "venue": "J. Phys.: Condens. Matter 24, 306002 ",
            "year": 2012
        },
        {
            "authors": [
                "A. Kuzmin",
                "J. Chaboy"
            ],
            "title": "Exafs and xanes analysis of oxides at the nanoscale",
            "venue": "IUCrJ 1, 571 ",
            "year": 2014
        },
        {
            "authors": [
                "C.D. Rankine",
                "T.J. Penfold"
            ],
            "title": "Accurate",
            "venue": "affordable, and generalizable machine learning simulations of transition metal x-ray absorption spectra using the xanesnet deep neural network, J. Chem. Phys. 156, 164102 ",
            "year": 2022
        },
        {
            "authors": [
                "R. Ramakrishnan",
                "P.O. Dral",
                "M. Rupp",
                "O.A. Von Lilienfeld"
            ],
            "title": "Quantum chemistry structures and properties of 134 kilo molecules",
            "venue": "Sci. Data 1, 140022 ",
            "year": 2014
        },
        {
            "authors": [
                "T.J. Penfold",
                "C.D. Rankine"
            ],
            "title": "A deep neural network for valence-to-core x-ray emission spectroscopy",
            "venue": "Mol. Phys., e2123406 ",
            "year": 2022
        },
        {
            "authors": [
                "A.Y.-T. Wang",
                "R.J. Murdock",
                "S.K. Kauwe",
                "A.O. Oliynyk",
                "A. Gurlo",
                "J. Brgoch",
                "K.A. Persson",
                "T.D. Sparks"
            ],
            "title": "Machine learning for materials scientists: An introductory guide toward best practices",
            "venue": "Chem. Mater. 32, 4954 ",
            "year": 2020
        },
        {
            "authors": [
                "N. Artrith",
                "K.T. Butler",
                "F.-X. Coudert",
                "S. Han",
                "O. Isayev",
                "A. Jain",
                "A. Walsh"
            ],
            "title": "Best practices in machine learning for chemistry",
            "venue": "Nat. Chem. 13, 505 ",
            "year": 2021
        },
        {
            "authors": [
                "M.R. Carbone",
                "S. Yoo",
                "M. Topsakal",
                "D. Lu"
            ],
            "title": "Classification of local chemical environments from x-ray absorption spectra using supervised machine learning",
            "venue": "Phys. Rev. Mater. 3, 033604 ",
            "year": 2019
        },
        {
            "authors": [
                "M.R. Carbone",
                "M. Topsakal",
                "D. Lu",
                "S. Yoo"
            ],
            "title": "Machine- Learning X-Ray Absorption Spectra to Quantitative Accuracy",
            "venue": "Phys. Rev. Lett. 124, 156401 ",
            "year": 2020
        },
        {
            "authors": [
                "S.B. Torrisi",
                "M.R. Carbone",
                "B.A. Rohr",
                "J.H. Montoya",
                "Y. Ha",
                "J. Yano",
                "S.K. Suram",
                "L. Hung"
            ],
            "title": "Random forest machine learning models for interpretable x-ray absorption near-edge structure spectrum-property relationships",
            "venue": "npj Comput. Mater. 6, 109 ",
            "year": 2020
        },
        {
            "authors": [
                "E.J. Sturm",
                "M.R. Carbone",
                "D. Lu",
                "A. Weichselbaum",
                "R.M. Konik"
            ],
            "title": "Predicting impurity spectral functions using machine learning",
            "venue": "Phys. Rev. B 103, 245118 ",
            "year": 2021
        },
        {
            "authors": [
                "C. Miles",
                "M.R. Carbone",
                "E.J. Sturm",
                "D. Lu",
                "A. Weichselbaum",
                "K. Barros",
                "R.M. Konik"
            ],
            "title": "Machine learning of kondo physics using variational autoencoders and symbolic regression",
            "venue": "Phys. Rev. B 104, 235111 ",
            "year": 2021
        },
        {
            "authors": [
                "E. H\u00fcllermeier",
                "W. Waegeman"
            ],
            "title": "Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods",
            "venue": "Mach. Learn. 110, 457 ",
            "year": 2021
        },
        {
            "authors": [
                "D.A. Nix",
                "A.S. Weigend"
            ],
            "title": "Estimating the mean and variance of the target probability distribution",
            "venue": "Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN\u201994) ",
            "year": 1994
        },
        {
            "authors": [
                "L.V. Jospin",
                "H. Laga",
                "F. Boussaid",
                "W. Buntine",
                "M. Bennamoun"
            ],
            "title": "Hands-on bayesian neural networks-a tutorial for deep learning users",
            "venue": "IEEE Comput. Intell. Mag. 17, 29 ",
            "year": 2022
        },
        {
            "authors": [
                "N. Srivastava",
                "G. Hinton",
                "A. Krizhevsky",
                "I. Sutskever",
                "R. Salakhutdinov"
            ],
            "title": "Dropout: A simple way to prevent neural networks from overfitting",
            "venue": "J. Mach. Learn. Res. 15, 1929 ",
            "year": 2014
        },
        {
            "authors": [
                "R. Hu",
                "Q. Huang",
                "S. Chang",
                "H. Wang",
                "J. He"
            ],
            "title": "The mbpep: A deep ensemble pruning algorithm providing high quality uncertainty prediction",
            "venue": "Appl. Intell. 49, 2942 ",
            "year": 2019
        },
        {
            "authors": [
                "A.G. Wilson",
                "P. Izmailov"
            ],
            "title": "Bayesian deep learning and a probabilistic perspective of generalization",
            "venue": "Adv. Neural Inf. Process. Syst. 33, 4697 ",
            "year": 2020
        },
        {
            "authors": [
                "M. Tschannen",
                "O. Bachem",
                "M. Lucic"
            ],
            "title": "Recent advances in autoencoder-based representation learning",
            "venue": "arXiv:1812.05069 ",
            "year": 2018
        },
        {
            "authors": [
                "Y. Zhu",
                "N. Zabaras",
                "P.-S. Koutsourelakis",
                "P. Perdikaris"
            ],
            "title": "Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data",
            "venue": "J. Comput. Phys. 394, 56 ",
            "year": 2019
        },
        {
            "authors": [
                "X. Luo",
                "B.T. Nadiga",
                "Y. Ren",
                "J.H. Park",
                "W. Xu",
                "S. Yoo"
            ],
            "title": "A bayesian deep learning approach to near-term climate prediction",
            "venue": "J. Adv. Model. Earth Syst. 14, e2022MS003058 ",
            "year": 2022
        },
        {
            "authors": [
                "L. Ruddigkeit",
                "R. Van Deursen",
                "L.C. Blum",
                "J.-L. Reymond"
            ],
            "title": "Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17",
            "venue": "J. Chem. Inf. Model. 52, 2864 ",
            "year": 2012
        },
        {
            "authors": [
                "J.J. Rehr",
                "J.J. Kas",
                "F.D. Vila",
                "M.P. Prange",
                "K. Jorissen"
            ],
            "title": "Parameter-free calculations of x-ray spectra with FEFF9",
            "venue": "Phys. Chem. Chem. Phys. 12, 5503 ",
            "year": 2010
        },
        {
            "authors": [
                "L. Himanen",
                "M.O.J. J\u00e4ger",
                "E.V. Morooka",
                "F. Federici Canova",
                "Y.S. Ranawat",
                "D.Z. Gao",
                "P. Rinke",
                "A.S. Foster"
            ],
            "title": "DScribe: Library of descriptors for machine learning in materials science",
            "venue": "Comput. Phys. Commun. 247, 106949 ",
            "year": 2020
        },
        {
            "authors": [
                "A.P. Bart\u00f3k",
                "R. Kondor",
                "G. Cs\u00e1nyi"
            ],
            "title": "On representing chemical environments",
            "venue": "Phys. Rev. B 87, 184115 (2013). 013180-19 ANIMESH GHOSE et al. PHYSICAL REVIEW RESEARCH 5, 013180 ",
            "year": 2023
        },
        {
            "authors": [
                "H. Huo",
                "M. Rupp"
            ],
            "title": "Unified representation of molecules and crystals for machine learning",
            "venue": "Mach. Learn. Sci. Technol. 3, 045017 ",
            "year": 2022
        },
        {
            "authors": [
                "M. Gastegger",
                "L. Schwiedrzik",
                "M. Bittermann",
                "F. Berzsenyi",
                "P. Marquetand"
            ],
            "title": "wacsf-weighted atom-centered symmetry functions as descriptors in machine learning potentials",
            "venue": "J. Chem. Phys. 148, 241709 ",
            "year": 2018
        },
        {
            "authors": [
                "N. Artrith",
                "A. Urban"
            ],
            "title": "An implementation of artificial neural-network potentials for atomistic materials simulations: Performance for TiO2",
            "venue": "Comput. Mater. Sci. 114, 135 ",
            "year": 2016
        },
        {
            "authors": [
                "A.L. Ankudinov",
                "B. Ravel",
                "J.J. Rehr",
                "S.D. Conradson"
            ],
            "title": "Real-space multiple-scattering calculation and interpretation of x-ray-absorption near-edge structure",
            "venue": "Phys. Rev. B 58, 7565 ",
            "year": 1998
        },
        {
            "authors": [
                "J.J. Rehr",
                "R.C. Albers"
            ],
            "title": "Theoretical approaches to x-ray absorption fine structure",
            "venue": "Rev. Mod. Phys. 72, 621 ",
            "year": 2000
        },
        {
            "authors": [
                "L. Van der Maaten",
                "G. Hinton"
            ],
            "title": "Visualizing data using t-SNE",
            "venue": "J. Mach. Learn. Res",
            "year": 2008
        },
        {
            "authors": [
                "M. Wattenberg",
                "F. Vi\u00e9gas",
                "I. Johnson"
            ],
            "title": "How to use t-SNE effectively",
            "venue": "Distill 1, e2 ",
            "year": 2016
        },
        {
            "authors": [
                "F. Pedregosa",
                "G. Varoquaux",
                "A. Gramfort",
                "V. Michel",
                "B. Thirion",
                "O. Grisel",
                "M. Blondel",
                "P. Prettenhofer",
                "R. Weiss",
                "V. Dubourg",
                "J. Vanderplas",
                "A. Passos",
                "D. Cournapeau",
                "M. Brucher",
                "M. Perrot",
                "E. Duchesnay"
            ],
            "title": "Scikit-learn: Machine learning in Python",
            "venue": "J. Mach. Learn. Res. 12, 2825 ",
            "year": 2011
        },
        {
            "authors": [
                "R.J. Tibshirani",
                "B. Efron"
            ],
            "title": "An Introduction to the Bootstrap",
            "venue": "Monogr. Stat. Appl. Probab. 57, 1 ",
            "year": 1993
        },
        {
            "authors": [
                "B. Bakker",
                "T. Heskes"
            ],
            "title": "Clustering ensembles of neural network models",
            "venue": "Neural Netw. 16, 261 ",
            "year": 2003
        },
        {
            "authors": [
                "I.J. Goodfellow",
                "J. Shlens",
                "C. Szegedy"
            ],
            "title": "Explaining and harnessing adversarial examples",
            "venue": "arXiv:1412.6572 ",
            "year": 2014
        },
        {
            "authors": [
                "M.R. Carbone"
            ],
            "title": "When not to use machine learning: A perspective on potential and limitations",
            "venue": "MRS Bull. 47, 968 ",
            "year": 2022
        },
        {
            "authors": [
                "T. Flynn",
                "S. Yoo"
            ],
            "title": "Change detection with the kernel cumulative sum algorithm",
            "venue": "2019 IEEE 58th Conference on Decision and Control (CDC) ",
            "year": 2019
        },
        {
            "authors": [
                "R.L. McGreevy",
                "L. Pusztai"
            ],
            "title": "Reverse monte carlo simulation: a new technique for the determination of disordered structures",
            "venue": "Mol. Simul. 1, 359 ",
            "year": 1988
        },
        {
            "authors": [
                "R.L. McGreevy"
            ],
            "title": "Reverse monte carlo modelling",
            "venue": "J. Phys.: Condens. Matter 13, R877 ",
            "year": 2001
        },
        {
            "authors": [
                "D. Whitley"
            ],
            "title": "A genetic algorithm tutorial",
            "venue": "Stat. Comput. 4, 65 ",
            "year": 1994
        },
        {
            "authors": [
                "S.P. Ong",
                "W.D. Richards",
                "A. Jain",
                "G. Hautier",
                "M. Kocher",
                "S. Cholia",
                "D. Gunter",
                "V.L. Chevrier",
                "K.A. Persson",
                "G. Ceder"
            ],
            "title": "Python materials genomics (pymatgen): A robust",
            "venue": "open-source python library for materials analysis, Comput. Mater. Sci. 68, 314 ",
            "year": 2013
        },
        {
            "authors": [
                "A.H. Larsen",
                "J.J. Mortensen",
                "J. Blomqvist",
                "I.E. Castelli",
                "R. Christensen",
                "M. Du\u0142ak",
                "J. Friis",
                "M.N. Groves",
                "B. Hammer"
            ],
            "title": "C",
            "venue": "Hargus et al., The atomic simulation environment-a python library for working with atoms, J. Phys.: Condens. Matter 29, 273002 ",
            "year": 2017
        },
        {
            "authors": [
                "A. Paszke",
                "S. Gross",
                "F. Massa",
                "A. Lerer",
                "J. Bradbury",
                "G. Chanan",
                "T. Killeen",
                "Z. Lin",
                "N. Gimelshein",
                "L. Antiga",
                "A. Desmaison",
                "A. Kopf",
                "E. Yang",
                "Z. DeVito",
                "M. Raison",
                "A. Tejani",
                "S. Chilamkurthy",
                "B. Steiner",
                "L. Fang"
            ],
            "title": "J",
            "venue": "Bai et al., Pytorch: An imperative style, high-performance deep learning library, Adv. Neural Inf. Process. Syst. 32, 8026 ",
            "year": 2019
        },
        {
            "authors": [
                "G. Kresse",
                "D. Joubert"
            ],
            "title": "From ultrasoft pseudopotentials to the projector augmented-wave method",
            "venue": "Phys. Rev. B 59, 1758 ",
            "year": 1999
        }
    ],
    "sections": [
        {
            "text": "PHYSICAL REVIEW RESEARCH 5, 013180 (2023)\nUncertainty-aware predictions of molecular x-ray absorption spectra using neural network ensembles\nAnimesh Ghose ,1 Mikhail Segal ,1 Fanchen Meng ,2 Zhu Liang ,2 Mark S. Hybertsen ,2 Xiaohui Qu ,2 Eli Stavitski ,3\nShinjae Yoo ,1 Deyu Lu ,2,* and Matthew R. Carbone 1,\u2020 1Computational Science Initiative, Brookhaven National Laboratory, Upton, New York 11973, USA\n2Center for Functional Nanomaterials, Brookhaven National Laboratory, Upton, New York 11973, USA 3National Synchrotron Light Source II, Brookhaven National Laboratory, Upton, New York 11973, USA\n(Received 28 October 2022; accepted 23 January 2023; published 15 March 2023)\nAs machine learning (ML) methods continue to be applied to a broad scope of problems in the physical sciences, uncertainty quantification is becoming correspondingly more important for their robust application. Uncertainty-aware machine learning methods have been used in select applications, but largely for scalar properties. In this work, we showcase an exemplary study in which neural network ensembles are used to predict the x-ray absorption spectra of small molecules, as well as their pointwise uncertainty, from local atomic environments. The performance of the resulting surrogate clearly demonstrates quantitative correlation between errors relative to ground truth and the predicted uncertainty estimates. Significantly, the model provides an upper bound on the expected error. Specifically, an important quality of this uncertainty-aware model is that it can indicate when the model is predicting on out-of-sample data. This allows for its integration with large-scale sampling of structures together with active learning or other techniques for structure refinement. Additionally, our models can be generalized to larger molecules than those used for training, and also successfully track uncertainty due to random distortions in test molecules. While we demonstrate this workflow on a specific example, ensemble learning is completely general. We believe it could have significant impact on ML-enabled forward modeling of a broad array of molecular and materials properties.\nDOI: 10.1103/PhysRevResearch.5.013180\nI. INTRODUCTION\nRecent years have witnessed the emergence of a thriving research enterprise directed towards the application of data-driven science to condensed matter physics, chemistry, and materials science [1,2]. In particular, machine learning (ML) models such as artificial neural networks, which are universal approximators that in principle can fit any function, have been widely used to model complex relationship among physical quantities. The intersection of ML tools, emerging high-performance computing platforms and a growing number of large open source datasets has made a transformative impact on research in the physical sciences.\nIn the context of first-principles simulations, it has been demonstrated that ML can be used to predict molecular or materials properties from atomistic structure at comparable accuracy to the quantum mechanical theories used to produce their training data, but at only a tiny fraction of their computational cost [1,3\u20135]. As a result, ML has the potential to\n*dlu@bnl.gov \u2020mcarbone@bnl.gov\nPublished by the American Physical Society under the terms of the Creative Commons Attribution 4.0 International license. Further distribution of this work must maintain attribution to the author(s) and the published article\u2019s title, journal citation, and DOI.\ntremendously accelerate computational studies, bridge firstprinciples simulations to a larger time and length scales, and enable efficient materials discovery pipelines [6]. Similarly, ML surrogate models can also be used to bypass the numerical solution [7,8] and to explore the quantum states [9,10] of model Hamiltonians.\nWhile a trained ML model provides a prediction, it usually does not provide a measure of its confidence, despite the crucial importance of model uncertainty for the researchers who apply them. In particular, ML models are designed to make accurate predictions on inputs sampled from the same distribution as the training set. However, they often fail completely when tasked with predicting on data sampled from a different distribution. Importantly, it is not always obvious (or detectable via some heuristic) when a model is performing inference on an out-of-sample input. In order to detect when this happens, one needs methodologies that incorporate uncertainty quantification (UQ). These are broadly classified as predictive methodologies that include accurate estimates of different types of statistical uncertainty. In the domain of ML and surrogate modeling, this often refers to the ability of trained models to provide some measure of confidence in the accuracy of their predictions [11]. In research scenarios where out-of-sample data are likely to be frequently encountered, the ability of ML models to perform UQ becomes crucial.\nUnderstanding model confidence is a key piece of the ML pipeline. Most research work simply evaluates model performance on a testing set, treating that as a proxy for\n2643-1564/2023/5(1)/013180(20) 013180-1 Published by the American Physical Society\nunderstanding on-the-fly model performance. UQ takes this one step further. For example, UQ is a critical component of Gaussian process-based [12] and neural network ensemble (NNE)-based Bayesian optimization, which has been employed for the autonomous design of experiments in many different domains, from the design of nanopaticles via flow reactors [13\u201315] to the optimization of mechanical properties of materials [16,17]. Neural network potentials (NNPs) [3,18\u201323] often utilize UQ to predict where their models are failing, and where they require retraining [24,25] (known as active learning [26]). Other works apply UQ in active learning for data-efficient prediction of molecular properties, such as the enthalpy, atomization energy, polarizability, and HOMO/LUMO energy levels [27]. However, existing uncertainty-aware (UA) models are mostly limited to several specific topics and not broadly applied in ML applications.\nIn this study, we present a NNE method for quantifying the uncertainty of predicted vector targets. Specifically, we use local atomic environment information to predict the x-ray absorption spectra (XAS) of small molecules. From existing literature on UQ implementations in ML models, very little can be discerned about their performance on spectral functions and vector targets in general, as it is unclear how the standard aforementioned applications would generalize from predicting scalars to a much higher dimensional space. We consider this XAS problem as a case study, but note that our approach is completely general. It can be applied in the broader context of any molecular or materials property. We will show that our NNEs are not only capable of making quantitatively accurate predictions of the XAS spectra, but also of making accurate estimates of the pointwise uncertainty of said predictions.\nXAS is a widely used element-specific materials characterization technique that is sensitive to the local chemical environment of the absorbing sites [28\u201333]. However, interpreting XAS data is nontrivial. While some important, physically motivated heuristics are well known, full understanding of the relationship between spectra and underlying atomic-scale structure is mediated by electronic states. In particular, first-principles XAS simulations are playing an essential role in XAS analysis, allowing the interpretation of precise structure-property relationships otherwise much more challenging to resolve experimentally. In an XAS simulation, the spectrum is calculated from the atomic arrangement of the system. Depending on the complexity of the theory and system, the spectral simulation can be prohibitively time consuming. This limits its use for fast structure screening/refinement or spectral feature assignment. As a result, there is a growing interest to develop surrogate models that can predict XAS spectra, and other types of spectral targets, from atomistic structures [34].\nWe focus on the near-edge portion of the x-ray absorption spectrum, known as x-ray absorption near edge structure (XANES). Specifically we consider K-edge XANES, corresponding to excitation from a 1s core orbital electron to empty orbitals or the continuum. We simulate the K-edge XANES spectra of C, N, and O atoms in small molecular systems for a large database of density functional theory (DFT)relaxed molecular structures: QM9 [35]. Taking a divide-andconquer approach, the NNEs are trained only on the local\nenvironments of individual absorbing atoms, and molecular spectra are constructed by averaging the predictions of the individual absorption sites. Errors are interpreted as standard deviations and propagated accordingly. Figure 1 demonstrates the overall workflow. This allows the NNEs to make predictions on molecules larger than what the models were trained on (similar to how neural network potentials can generalize to larger systems if correlations are sufficiently short-range). As such, this approach could have broad implications in the fields of inverse design and generalizable surrogate modeling.\nKey to any UQ methodology is understanding how trained models perform when data are pushed out-of-sample during inference. The addition of UQ to a surrogate model supports its generalized use. In the context of molecular systems specifically, we enumerate four physically motivated classes of generalization in which a UQ methodology can flag adverse effects of the changing local environment on model performance:\n(1) chemical, e.g., including larger molecules relative to the training set,\n(2) configurational, e.g., including structural distortions from equilibrium geometry (such as due to thermal effects),\n(3) electronic, e.g., introducing new chemical motifs (such as aromaticity) that are not necessarily a function of molecular size,\n(4) environmental, e.g., introducing molecule-solvant interaction due to solvation.\nIn principle, UQ methods should be able to detect when out-of-sample data due to any of the above situations occurs. In this work, we directly study how new distributions of testing data due to chemical and configurational changes affect model and UQ performance. Studies of electronic and environmental effects are beyond the scope of the current work.\nAs noted, to date, incorporation of UQ into ML applications for materials science and chemistry has been limited in scope, particularly focusing on scalar target quantities (we highlight a notable exception, in which various UQ-enabled ML methods were used to predict the x-ray emission spectra of transition metal complexes [36]). In the present work, with our focus on spectroscopy, we explore the challenges associated with incorporating UQ into models where the target space is of a substantially higher dimension, corresponding to the vector of spectroscopic intensity versus x-ray photon energy. In particular, this is the first time UQ methods and the requisite analysis have been demonstrated for XAS prediction.\nThe manuscript is organized as follows. In Sec. II, we outline the procedures used for constructing our databases, and describe the featurization and forward modeling. This includes a brief discussion on our choice of local feature embedding and various forms of UQ. Next, in Sec. III, we outline our procedures for analyzing the database using unsupervised and general data-analysis techniques, as well as final data preparations for machine learning. Section IV contains the main results of this work, and demonstrates the ability of our trained models to make accurate predictions and perform UQ on different subsets of small molecules. Section IV B specifically highlights the power of our models to generalize to molecules with more atoms than those used during training. In Section IV C, we also discuss the NNE\u2019s ability to accurately\n013180-2\nquantify uncertainty when tested on structures which are not in their relaxed geometries, a different type of generalization from the training database. Finally, we conclude and discuss the outlook and future plans of this work in Sec. V."
        },
        {
            "heading": "II. THEORY",
            "text": "The general theory of ensemble learning and UQ has a rich history in the ML literature. In this section, we summarize previous work and highlight the key principles and theory behind ensemble learning and UQ. Specifically, we provide an overview of supervised learning (and feed-forward neural networks), UQ, and ensembling in Secs. II A\u2013II C, respectively."
        },
        {
            "heading": "A. Supervised learning and feed-forward neural networks",
            "text": "In supervised learning tasks, a model f\u03b8 is tasked with learning a mapping f\u03b8 : RM \u2192 RM \u2032 , where M is the number of features (or the length of the input vector) and M \u2032 is the number of targets (or the length of the target vector). This mapping can take many forms, including polynomials, random forests, nonparametric models such as Gaussian processes, or deep learning architectures, such as neural networks. For the purposes of this discussion, we focus on parametric models, where a finite number of parameters \u03b8 determine the form of the approximating function f\u03b8. During the training (or fitting) process, parameters \u03b8 are optimized so as to minimize the loss function, which is a measure of difference between the ground truth target values {y(i)} and the model predictions f\u03b8 (x(i) ) = y\u0302(i). The data on which the model is fit is referred to as the training set. Models are fine-tuned on the cross-validation set, and the final model evaluation is performed on data the model\nhas yet to see, usually called the testing set. For an in-depth tutorial on ML techniques and proper use, we refer the reader to Refs. [37,38].\nWe use feed-forward neural networks (FFNN) to perform the supervised learning task in all results to follow. The details of FFNNs are explained in many other works (and especially in the context of spectroscopy prediction and analysis [8,34,39\u201343]), and are thus not explained here. However, one key property of FFNNs is that they are universal approximators, meaning they can, in principle, model any function provided the model has enough trainable parameters and is trained on enough data. This is relevant for constructing ensembles of neural networks, described in Sec. II C. The details of our features and targets are explained in Sec. III D."
        },
        {
            "heading": "B. Uncertainty quantification",
            "text": "Generally, ML models are tasked with modeling inputs to outputs, as described in the previous subsection. However, there are currently significant ongoing efforts to leverage statistical principles to model, or quantify, the uncertainty in these predictions. For example, Gaussian processes (GPs) [12] are nonparametric generalizations of the multivariate normal distribution to the continuum, and are finding widespread use due to their ability to rigorously quantify statistical uncertainty. This uncertainty is derived from assumptions about correlation lengths embedded in a covariance kernel, allowing one to draw samples from the GP consistent with the parameters of the embedded length scales. For the purposes of this work, we henceforth outline ways to quantify uncertainty in parametric models such as FFNNs. We reserve the discussion of ensembling specifically to Sec. II C.\n013180-3\nUncertainty-aware models incorporate UQ in order to address two different types of uncertainty: aleatoric and epistemic [11,44]. Aleatoric uncertainty is also called \u201cirreducible,\u201d as it is due to natural physical processes (such as randomness in nature) or inherent instrument error. Intrinsic broadening processes in spectroscopy or noise in an image are two examples of aleatoric uncertainty. We highlight that error bars corresponding to uncertainty in a physical measurement are also examples of aleatoric uncertainty. Epistemic uncertainty is due to an insufficient model. It is often large when training data in some region of the input space is not adequately sampled. Unlike aleatoric uncertainty, epistemic uncertainty can be improved by using some combination of a more sophisticated model, incorporating more training data or prior information. While it is nontrivial, recent work has demonstrated that both classes of uncertainties can be predicted using ML techniques [45].\nOne method for modeling aleatoric uncertainty in particular is the mean-variance estimation (MVE) [46]. A MVE model will attempt not only to predict the target value, but also an estimation for the uncertainty in that prediction as another output. Concretely, given an input feature dataset X \u2208 RN\u00d7M (where N is the number of training examples) and a target dataset Y \u2208 RN\u00d7M \u2032 , a MVE model will attempt to learn a mapping f : RM \u2192 R2M \u2032 . The output space is doubled in size since for every output prediction, an uncertainty estimate is also predicted. If we consider the scalar output case M \u2032 = 1, we have a single prediction y\u0302 and a single prediction for the estimate of the uncertainty \u03c3\u0302 . The MVE model is trained to minimize a negative Gaussian log-likelihood (NLL) loss function,\nL(y, y\u0302, \u03c3\u0302 ) = 1 2 ln 2\u03c0 + 1 2\nln \u03c3\u0302 2 + (y \u2212 y\u0302) 2\n2\u03c3\u0302 2 . (1)\nThe principle is simple: if the model makes an accurate prediction [i.e., (y \u2212 y\u0302)2 is small], it can \u201cafford\u201d to also predict a low uncertainty \u03c3. However, if the prediction error is large and cannot be improved during training (perhaps due to a significantly noisy observation) the model will compensate by increasing \u03c3\u0302 , despite paying the penalty of the second term in Eq. (1). The fact that a MVE model trained using the NLL loss function has the flexibility to make this tradeoff allows it to estimate the uncertainty in its own predictions, offering considerable utility when modeling irreducible noise.\nIn our work, the simulation of a XANES spectrum from molecular coordinates is deterministic. Hence, we will only be concerned with modeling epistemic uncertainty. There are several uncertainty quantification techniques that can model epistemic uncertainty, such as Bayesian neural networks (BNN) [47], Monte Carlo dropout (MCD) ensembles [48], and neural network ensembles [49,50]. Instead of directly predicting an estimate of uncertainty, BNN\u2019s treat all of their parameters as random variables, allowing one to sample from this distribution during inference, leading to a distribution of predictions. While proven to be extremely effective in certain cases [51\u201353], BNN\u2019s are expensive to train, and it has been argued that they are consistent with simpler, ensemblebased approaches [50]. MCD ensembles work under a similar principle, by randomly disabling neurons during inference, allowing for a sampling over many \u201ceffective models\u201d and thus\nallowing ensemblelike predictions to be obtained. Statistical bootstrapping can also be used to generate model diversity, and has been shown to be superior to MCD in similar applications [36]. In this study, we choose to use NNEs for the reasons explained in detail below. Similar to Ref. [36], we also downsample our training set size in a way similar to bootstrapping, and combine this with ensembling to create even more model diversity than either would produce on its own (and also found that MCD is less effective than our combined downsampling and ensembling method)."
        },
        {
            "heading": "C. Neural network ensembles",
            "text": "NNEs are sets of individual models (or estimators, in the case of this work these are FFNNs) which are usually trained independently but used together during inference (see Fig. 1). The working principle of NNEs is that of the wisdom of the crowd (or \u201cquery-by-committee\u201d [26]): each individual\u2019s prediction is less robust than the aggregate opinion. More rigorously, any two models that produce an accurate result will by definition produce predictions that are similar. However, due to the vast training weight-space of deep learning models, when any two models both fail, they will usually fail in different ways. The training weight-space refers to the complete set of trainable parameters of a neural network. The values of these weights are randomly initialized between different estimators, and since this space can be incredibly high-dimensional (easily >1 million and often many orders of magnitude larger), there are a vast number of possible sets of weights corresponding to local minima in the landscape of the loss function. The ensemble learning approach turns one of the neural network\u2019s greatest weaknesses into a strength. Each estimator (in its own local minimum) will produce roughly the same correct prediction in a well trained neural network and is partly what allows neural networks to be so flexible. However, the differences between these sets is also what leads to different estimator predictions in failure scenarios.\nEmpirically, the average over the entire ensemble not only produces better predictive accuracy, but also allows for UQ by interpreting the spread in the predictions of the individual estimators. Theoretically, an ensemble-averaged prediction can be thought of as an averaging over the space of \u201creasonable\u201d possible functions mapping inputs to outputs given a fixed training set. This space is infinite, of course, and any finite sampling of models is not sufficient to rigorously cover this space. However, it is sufficient to provide useful uncertainty measures. Choosing how many estimators to use remains a highly problem- and model-dependent open research question [26]. This is in stark contrast to a GP, which not only provides an analytic form for the mean and spread of the GP averaged over an infinite number of estimators, the spread itself is rigorously the standard deviation of a Gaussian distribution. A NNE may not adequately approximate the space and the spread is not strictly interpretable as a proper standard deviation (though it can be used in a similar way [21]). We thus highlight a critical pitfall: like almost all ML techniques, especially in deep learning, UQ is hyperparameter-dependent. These methods must be rigorously tested in order to ensure they are of the appropriate quality given the problem at hand.\n013180-4\nTo our knowledge, there is not yet any formal theory for interpreting the distribution of predictions of NNEs.\nIn this study, we choose NNEs for their balance of relative simplicity, predictive power and overall performance. We also highlight that they operate on essentially the same paradigm that any individual estimator does, which makes them straightforward to train, debug and deploy."
        },
        {
            "heading": "III. METHODOLOGY",
            "text": "In this work, we showcase the utility of the NNE method for UQ on molecular structure-XAS pairings. Molecular structures are taken from the QM9 database [35], which is a subset of the GDB-17 chemical universe [54]. QM9 contains roughly 134k DFT-geometry optimized small molecules, each with at most 9 heavy atoms (C, N, O, F). Molecular spectra are computed using the multiple scattering code FEFF9 [55]. We focus on C, N and O K-edge XANES spectra from individual absorbing sites, and as such we partition our database into DA for A = {C, N, O}. For example, DO is a database containing all oxygen site-XANES pairs. In the following subsections, we explain how our features and targets are constructed (Secs. III A and III B, respectively) and analyzed (Sec. III C). Finally in Secs. III D and III E, we describe the procedure for setting up the training and testing sets used in the remainder of the work, and implementing our NNE approach."
        },
        {
            "heading": "A. Feature construction",
            "text": "XANES is sensitive to the local chemical environment of absorbing atoms. We therefore choose a structural descriptor that is local to each absorbing site: atom-centered symmetry functions (ACSFs) [3,18]. We also considered other descriptors (particularly those from the DSCRIBE library [56]) including the smooth overlap of atomic positions [57] and many-body tensor representations [58], but ultimately decided to use ACSF.1 The ACSF feature encodings have been very successful in modeling total energy partitioned into local atomic contributions. ACSFs were first proposed by Behler in 2011 in the context of developing neural network potentials [3,18] (NNPs). The development of NNPs is summarized in a recent review by Behler [22], along with the utility and flexibility offered by ACSFs.\nACSF feature vectors are further described at length in quite a few recent works, including Refs. [34,60], and as such will not be repeated here. In brief, the ACSF feature vectors are atom-resolved representations of the local radial and angular atomic environments of a central atom, which in this work is the absorbing site.\n1We also considered the weighted-ACSF (wACSF) feature encoding [59], which unlike the traditional ACSF, do not scale in size with the number of unique atom types in the considered data. While this type of encoding is particularly useful when there are a significant number of unique atom types (such as when dealing with the vast spaces of materials or materials complexes [36,39]), it is not necessary for our problem, as we only consider five unique atom types (H, C, N, O, and F).\nWe aim to leverage the locality of XANES in the same way local atomic energy contributions are in constructing NNPs. Physically, the argument that XANES is a local probe can be understood through multiple scattering theory, where the absorption coefficient at a given incident photon energy is determined by the interference between the outgoing wave and the back scattering waves from neighboring atoms. In the multiple scattering path expansion, the absorption coefficient decays exponentially with path length [61,62]. Overall, the longer the scattering path length, the smaller the overall contribution to the XANES spectrum. Typical paths that contribute are illustrated in Fig. 2, where r1 and r2 represent two- and three-atom scattering paths, respectively. Of course, a much larger number of paths contribute in principle, but longer paths, mostly those outside of the range rcutoff , do not contribute significantly.\nIn preparing our ACSF features, for every absorbing atom site, we use a radial cutoff of 6 \u00c5, as well as similar parameters to those used in Ref. [60]. H, C, N, O, and F neighbors were considered, and for each absorbing atom site, a feature vector of 155 entries was constructed. The details of our featurization process can be found in Appendix A 1.\nWe explored feature reduction/importance ranking, similar to that done in Ref. [34], in order to reduce the 155- dimensional input vector to a smaller dimension. We found that training was somewhat stabilized (i.e., loss functions decreased monotonically more consistently), but accuracy overall was not noticeably different from training performed using the full ACSF vector. Thus we choose to use the ACSF feature vectors as-is for inputs to our models.\n013180-5"
        },
        {
            "heading": "B. Target construction",
            "text": "As previously mentioned, FEFF9 [55] is used to compute the XANES spectra using multiple scattering theory. Each molecule\u2019s FEFF spectrum is computed individually (atomby-atom), and the details of these calculations are presented in Appendix A 2. In brief, we use a cutoff of 7 \u00c5 for self-consistent potential calculations and 9 \u00c5 for full multiple scattering calculations, which is commensurate with the geometric cutoff of 6 \u00c5 used for the ACSF descriptor construction. The targets are the XANES spectra interpolated using cubic splines onto a common grid, which was chosen to be 200 dimensional, corresponding to a resolution of 0.27 eV.\nIn brief, the spectral target can be represented as a vector \u03bc(i) = [\u03bc(i)1 , \u03bc(i)2 , . . . , \u03bc(i)M ] (2) for training example i, where M = 200 is the number of target values. We consider a spectral range of 50 eV and scale the intensity to unity at the high energy tail, conforming to the standard XANES normalization procedure."
        },
        {
            "heading": "C. Principal component analysis",
            "text": "Prior to performing ML modeling, it is always prudent to explore the data to ensure sensible correlations or patterns exist between features and targets. It also provides the baseline intuition of what to expect from the ML models. Linear dimensionality reduction techniques, such as principal component analysis (PCA), cannot capture the nonlinear relations that a neural network will, but they are still quite useful in identifying overall trends and are largely parameterindependent. More sophisticated nonlinear techniques, such as t-distributed stochastic neighbor embedding (t-SNE) [63], can extract more complicated trends, but are usually highly parameter dependent and thus less robust [64]. We therefore apply PCA on both the ACSF features and spectra targets in order to resolve their relations in a tightly controlled manner.\nPCA extracts the \u201cdirections of principal variance\u201d in a dataset. The PCA decomposition diagonalizes the M \u00d7 M covariance matrix of a dataset X \u2208 RN\u00d7M (N examples each with M features). The most significant eigenvectors and eigenvalues (the eigenvectors which correspond to directions of maximal variance are indicated by the largest eigenvalues) of the covariance matrix are used to project the data into a lowerdimensional space. Formally, the (scaled) eigenvalues w j are the (relative) captured variance \u03c9 j along the direction defined by that eigenvector. For the ith example in the database Xi, and for the jth eigenvector w j ,\nzi j = Xi \u00b7 w j, (3) where \u00b7 is the dot product. For example, zi1 captures the first principal component (in the direction of maximal variance) of example i. We also highlight that given a value zi = [zi1, zi2, . . . , zid ] with d < M, an approximate reconstruction of Xi can be obtained via\nXi \u2248 d\u2211\nj=1 zi jw j . (4)\nUsing the scikit-learn library [65], we apply PCA to the feature (the ACSF vectors) and target (spectra) spaces,"
        },
        {
            "heading": "C 0.61 0.16 0.34 0.29",
            "text": ""
        },
        {
            "heading": "N 0.74 0.09 0.41 0.26",
            "text": ""
        },
        {
            "heading": "O 0.77 0.11 0.60 0.22",
            "text": "independently. Specifically, we perform the dimensionality reduction on the ACSF feature data as RN\u00d7155 \u2192 RN\u00d72 and the spectra target data as RN\u00d7200 \u2192 RN\u00d72. The values of zi1 and zi2 for the ACSF decomposition are plotted in Fig. 3 on the x and y axes, respectively. The color value of the points represents the value of zi1 of the spectra decomposition. Note that scales are not shown here, as they not important for the qualitative analysis to follow. Table I tabulates the relative captured variance of each dimension for both the features and targets, in the first two principal directions.\nAnalysis of Fig. 3 shows clear spatial correlations between the principal values of the ACSF features and spectral targets. Areas of high color density indicate a spectral feature which is strongly correlated to a common structural motif. These regions are indicated by the appropriate labels. For example, while the C atom clustering is the most poorly resolved, cluster (a) appears to correspond to aliphatic carbon chains. For N atoms, (b) clearly corresponds to azides and (c) to primary ketimines. For O atoms, (d), (e), and (f) correspond to esters, alcohols, and ethers, respectively. While the clustering patterns are not definitive on their own, they indicate a high degree of correlation between the XANES spectra and functional group, a result observed in previous work [40]. Not only does this further substantiate the locality of XANES, it also hints that ML techniques will be able to efficiently capture a more complicated nonlinear relationship between XANES spectra and local atomistic geometry."
        },
        {
            "heading": "D. Data splits and preparation",
            "text": "We test two hypotheses using the QM9 dataset, each necessitating different partitionings of the datasets DA. First, the ACSF feature vectors capture sufficient local structural information about absorbing atoms for accurate prediction of sitewise XANES spectra and uncertainty estimations. Testing our first hypothesis involves evaluating the overall effectiveness of a NNE trained using the usual random train/validation/test split. It corresponds to a use case in which the trained NNE is expected to perform on a randomly selected example in the QM9 database. Hence, this first partitioning is referred to as the \u201crandom partitioning\u201d (DRA ). Such a performance measure is perfectly valid if the distribution of molecules in the test set is chemically similar to those found in the QM9 training set.\nThe second hypothesis is that the XANES spectra are sufficiently local such that an ensemble can be trained on data containing molecules with fewer than n heavy atoms, but still perform on molecules with more than n heavy atoms. Furthermore, the individual local signals can then be averaged, with NNE error propagated, to estimate the molecular XANES, and its error. This is indeed a significant challenge.\n013180-6\nIt is known that neural network potentials, which often also use ACSF input vectors with similar parameters, can struggle in systems with long-range correlations. This hypothesis therefore provides a stringent test on both the locality of the XANES spectra and NNE. If nontrivial long-range correlation effects exist in the XANES spectra, our models will suffer due to the intrinsic locality constraint. Similarly, if the chemical environments captured in QM9 are significantly different than those contained in a dataset with larger molecules, the NNE will fail to generalize. As this partitioning will test the ability of the models to generalize, it is henceforth referred to as the \u201cgeneralization test\u201d (DGA ).2\nFor each DRA , a simple random split is employed, where 90% of data are chosen for training and cross-validation, with the rest held-out as the testing set. For DGA , multiple splits are made. The testing sets always contain all of the QM9 molecules with a total of 9 heavy atoms. Training sets are constructed by choosing molecules with anywhere from 5\u20138 heavy atoms. For example, in one training set instance for nitrogen absorbing atoms, we include sites from all molecules containing at least one N atom, but less than, e.g., total 6 heavy atoms in the training (and cross-validation) splits. Evaluation is then consistently performed on atoms originating from molecules with 9 heavy atoms.\nSignificantly, the data partition DGA has a strong impact on the size of the training set. Binned by the total number of heavy atoms per molecule, the total number of molecules increases exponentially in the QM9 database.\nIn Fig. 4, we show the total number of molecules in DA as a function of the number of heavy atoms/molecule. As one can see, the total amount of data for 9 heavy atoms/molecule is roughly an order of magnitude greater than for 8. If the generalization test succeeds, an exponential increase in training data could be avoided.\n2Note that the same data/examples are contained in DA, DRA , and DGA . We distinguish between them to highlight that the train/validation/test splits are different."
        },
        {
            "heading": "E. Machine learning",
            "text": "We train |E | = 30 independent estimators for all experiments in this work. The details of the training procedures are given in Appendix B, and we highlight the following important points. First, each estimator was always trained on a random 90% sampling (without replacement) of the training set [66,67], meaning some data was purposely excluded during training (the dependence on the sampling proportion is analyzed in Appendix D). Second, each estimator used a randomly initialized neural network architecture. Both of these procedures were employed to maximize model diversity, which as previously discussed, has been shown to be of great utility for UQ.\nDuring initial cross-validation studies, we observed that occasionally individual estimators would produce completely unphysical results. Such results include, but are not limited to, spikes in the spectral intensity an order of magnitude larger than the most intense spectrum in our data and \u201cvanishing\u201d spectra with mostly zero intensity. Likely due to a combination of the random model initialization and training set downsampling, these aberrant results do not contribute meaningful information to either the overall accuracy of the prediction or the uncertainty estimate. Therefore, during\n013180-7\ninference, these faulty prediction-estimator pairs are discarded when computing ensemble-averaged quantities. We discuss the details of this procedure in Appendix C."
        },
        {
            "heading": "IV. RESULTS",
            "text": ""
        },
        {
            "heading": "A. Random partitioning",
            "text": "The NNE predictions for spectrum i on spectral grid point j is given by an average over the individual estimators,\n\u03bc\u0302 (i) j =\n1 |E (i)| \u2211\nk\u2208E (i) \u03bc\u0302\n(i,k) j , (5)\nwhere k is the estimator index, and E (i) \u2286 E is the set of estimator indexes corresponding to nonoutlier, physical predictions, for example, i (and |E (i)| is the size of this set and E is the set of all estimators). The ensemble-averaged error is\n\u03b5(i) = 1 M M\u2211 j=1 \u03b5 (i) j , (6)\nwhere\n\u03b5 (i) j = \u2223\u2223\u03bc(i)j \u2212 \u03bc\u0302(i)j \u2223\u2223. (7) We note that the vector representation of the predicted XANES spectrum is given in a similar form to Eq. (2),\n\u03bc\u0302(i) = [\u03bc\u0302(i)1 , \u03bc\u0302(i)2 , . . . , \u03bc\u0302(i)M ]. (8) During inference, we use the ensemble-averaged quantity as the overall ensemble prediction. In order to demonstrate the NNE\u2019s superiority in raw predictive accuracy, we compare the ensemble prediction above to that of the average prediction error of each individual estimator,\n\u03b5 (i) est =\n1 |E |M |E|\u2211 k=1 M\u2211 j=1 \u2223\u2223\u03bc(i)j \u2212 \u03bc\u0302(i,k)j \u2223\u2223. (9) Equation (9) can be best thought of as a rough measure of how any single model would perform on average. To quantify this, we define the average test error on a logarithmic scale over Ntest structure-spectrum pairs,\n\u03b5\u0304 = 1 Ntest \u2211 i log10 \u03b5 (i) (10a)\nand\n\u03b5\u0304est = 1 Ntest \u2211 i log10 \u03b5 (i) est. (10b)\nWe highlight that \u03b5\u0304 (\u22121.45,\u22121.40, and \u22121.55) clearly outperforms \u03b5\u0304est (\u22121.36,\u22121.32, and \u22121.46) for the C, N, and O datasets. The details of the distributions of these errors are discussed in Appendix D (Fig. 11).\nIn order to ground the discussion of overall model performance, we present waterfall plots in Fig. 5 with samples randomly chosen from the worst cases in each decile of the the testing set of DRC. One of the worst performers (bottom figure) clearly originates from a rare, challenging (from the electronic structure perspective) structure: a seven-membered fully conjugated ring containing five heteroatoms. Given the chemical space covered in QM9, it is not unsurprising that\nthe prediction is not accurate. However, it appears that the uncertainty estimate yields the qualitatively correct trend, as the prediction appropriately presents with relatively large error bars. On the other hand, all other predictions are relatively accurate, and present with error bars roughly commensurate with the prediction accuracy. The pointwise NNE spread for spectrum i is defined as\n\u03c3\u0302 (i) j = \u221a\u221a\u221a\u221a 1|E (i)| \u2211\nk\u2208E (i)\n( \u03bc\u0302\n(i) j \u2212 \u03bc\u0302(i,k)j\n)2 , (11)\nfrom which the overall uncertainty of the prediction can be computed,\n\u03c3\u0302 (i) = 1 M M\u2211 j=1 \u03c3\u0302 (i) j . (12)\nSimilar to Eqs. (2) and (8), the vector uncertainty for a single spectrum can be represented as \u03c3\u0302 (i) = [\u03c3\u0302 (i)1 , \u03c3\u0302 (i)2 , . . . , \u03c3\u0302 (i)M ]. (13) It is important to note that Eqs. (11)\u2013(13) are independent of the ground truth predictions. Additionally, we note that unlike, e.g., a GP, the spreads \u03c3 (i)j are not proper standard deviations, since the distribution of estimator outputs is not guaranteed to\n013180-8\nbe Gaussian. They are simply a measure of how different each output is from the others.\nWe present a quantitative analysis of the NNE\u2019s capability of accurately capturing uncertainty measures in Fig. 6 for all three datasets DRA . In (a)\u2013(c), violin plots of log10 \u03b5 (i) j for 5 bins of log10 \u03c3\u0302 (i) j (shown as the background colors of the violin plots) are presented. From left to right, the average uncertainty estimate (spread) increases. As the spread increases, so does the estimate of the error, spanning multiple orders of magnitude on each axis. Critically, the distributions are mostly nonoverlapping, meaning the uncertainty estimate can be used to produce a robust estimate for the actual error of the prediction. A more fine-grained presentation of the same data is presented in (d)\u2013(f). These are error parity plots comparing the NNE spread with that of the actual error. To guide the eye, we show the best linear fit to the log-scaled data (solid), as well as four successive parallel lines offset by a half an order of magnitude (dashed). The majority (>88%) of the points fall below the first of these upper bounds (half an order of magnitude above the best fit line), suggesting that most of the time, the error estimate given by this linear trend is an appropriate representation of the worst case scenario. We also note that even when using 10% of the overall training set, the ability of the NNE to accurately quantify uncertainty is unaffected (see Fig. 13).\nIt is also noteworthy to analyze why roughly 14% of the data fall half an order of magnitude below the best fit line. Even when making accurate predictions, each estimator will still predict slightly different values given the same input. These predictions can be accurate overall, but still produce noticeable values for an uncertainty estimate due to their slightly different predictions. This is a consequence of the way that\nneural networks train and make predictions. Each estimator finds some local minimum in its vast \u201cweight space,\u201d and each produces slightly different estimations even when the estimators and ensemble as a whole is making predictions to suitable accuracy. That said, underconfidence in a prediction is not nearly as problematic as overconfidence, and the amount of underconfidence as a function of \u03c3\u0302 (i)j decreases as uncertainty increases. In summary, our results suggest that the ensembles provide a robust, general upper bound for the error."
        },
        {
            "heading": "B. Generalization test",
            "text": "The ability to generalize to previously unseen data is a key feature of any ML model. Generalization can be understood through the lens of data distributions: while the data used during testing must be unseen, the data used to train some model must, in a distributional sense, \u201clook like\u201d the data it is expected to perform on. A simple way to test whether or not two sets of data are in-sample with respect to each other is to combine them and sample randomly. If a source of truth, e.g., a domain expert, can tell the distribution of origin given some random sample, then it is likely that the deployment case, which hopefully is represented by the testing set, is out-of-sample and will lead to poor performance. This is not a catch-all test (e.g., adversarial examples [68]), but it is a useful thought experiment. For example, the testing sets as constructed randomly in Sec. IV A were on balance, by the above definition, in-sample.\nThere is also a key difference between generalization and extrapolation which is worth noting. No ML models extrapolate beyond the information-theoretic union of the data and prior information they are trained on [69]. Two examples of\n013180-9\n\u201cinformation-theoretic extrapolation\u201d in our work would be (a) predicting on a molecule containing zwitterionic species and (b) predicting on un-relaxed structures. In case (a), the model has not seen any molecules with major charge gradients, and thus it will not understand how to treat those cases. Stated differently, it will neither understand which structural motifs correspond to a zwitterion nor how to treat them once detected. Similarly, in case (b), while it is possible that many structural configurations found in unrelaxed structures are captured in QM9 due to the large diversity of molecules in the dataset, there is no guarantee, since QM9 contains only relaxed geometries.\nIn this section, we push the boundaries of our NNEs to generalize to new data in a specific way, by training on sites from smaller molecules than what we test on. To do this, we train and cross-validate on subsets of the C, N, and O databases in which there are at most 8 heavy atoms per molecule, and then test on sites originating from molecules containing 9 heavy atoms per molecule (see Sec. III D for details). The specifics of the training and evaluation procedures is identical to those presented in Sec. IV A, except for the particular training/validation/testing split used.\nFurthermore, the true test of the ability of the NNEs to generalize is to evaluate performance on molecular spectra, defined as the average of the sitewise spectra [see Eq. (14)] (in Sec. IV A, we only present results on site-spectra). For any DGA , a molecule is given by M \u2208 DGA , and is defined by a collection of sites. We define the subset of theses sites of atom type A as MA \u2282 M. Given these definitions, the pointwise\nground truth molecular XANES spectrum is\n\u03bc (MA ) j =\n1 |MA| \u2211\ni\u2208MA \u03bc\n(i) j , (14)\nwhere |MA| is the number of absorbing sites of type A in the molecule. Furthermore, the pointwise molecular XANES spectrum prediction is the average of each of the ensemble predictions for each site,\n\u03bc\u0302 (MA ) j =\n1 |MA| \u2211\ni\u2208MA \u03bc\u0302\n(i) j . (15)\nThe estimate of the pointwise spread for the molecular XANES prediction can be calculated using propagation of errors,\n\u03c3\u0302 (MA ) j =\n1 |MA| \u221a \u2211\ni\u2208MA\n[ \u03c3\u0302\n(i) j\n]2 , (16)\nwith an analogous vector representation to that of Eq. (13), \u03c3\u0302 (MA ) = [\u03c3\u0302 (MA )1 , \u03c3\u0302 (MA )2 , . . . , \u03c3\u0302 (MA )M ]. (17) Finally, the error of the molecular spectrum is similarly given by a straightforward analog of Eqs. (6) and (7). For brevity, we will often suppress the subscript A where it is clear which atom type/database is being referred to.\nWe present waterfall plots of the ground truth molecular spectra, and the NNE predictions and spreads in Fig. 7 in the DGA databases. To demonstrate the ability of the NNE to\n013180-10\ngeneralize, we train only on absorbing site-spectrum pairs originating from molecules with at most 6 heavy atoms, but the presented testing set results come from absorbing site-spectrum pairs originating from molecules with 9 heavy atoms. This experiment demands an extreme degree of generalization from the NNE: the subsets of QM9 with only 6 heavy atoms is extremely small, containing only \u2248103 total structures, three orders of magnitude less than the testing set in this case (see Fig. 4). The dependence of the testing set error on the maximum number of atoms per molecule used in the training data (along with a similar analysis to that presented in Fig. 6) is explored in Appendix D. The key result is that adding orders of magnitude more data results in only slight improvement in testing set error. For example, using the DGC dataset with up to 5 heavy atoms in the training set includes 437 data points, and produces an error of \u03b5\u0304 \u2248 0.09. training with up to 8 heavy atoms uses a training set of 102 253 data points, three orders of magnitude more data, and produces an error of 0.03 on the same testing set. Using roughly 103 times as much data produces only a factor of 3 improvement in the testing error. Combined with the results in Fig. 7, this indicates that the NNE is already able to generalize to larger molecules at a relatively low training cost, and is incredibly data-efficient. These results are further rigorously quantified in Appendix D (Fig. 12).\nIn particular the results for DGC present with impressive accuracy given that each spectrum is an average over many carbon atoms (as many as 9 in one of the presented cases). Qualitatively, peak heights and locations are predicted to reasonable accuracy. In contrast, the results for DGN and DGO showcases where the NNE struggles to make accurate predictions for the number of absorbing atoms per molecule. This is largely due to there being far fewer training examples in these two cases relative to DGC . Even so, while some peaks are occasionally missed, the spectral trends are still reproduced, and uncertainties are captured."
        },
        {
            "heading": "C. Out-of-equilibrium geometry analysis",
            "text": "To further study how the NNE responds to out-of-sample data, we used the 10 molecules corresponding to sites whose spectra were presented in Fig. 5, and randomly distorted the geometries of the molecules to see how the NNE performs. Our procedure is as follows. First, given a distortion parameter \u03b4, for each coordinate direction and atom in some molecule M, a direction on the unit sphere is chosen at random, scaled by \u03b4, and then used to perturb that atom\u2019s coordinate. For each of the 10 molecules and each value of \u03b4, we sample 50 distorted molecules. Second, FEFF calculations are then run on each of these new geometries. Finally, the trained NNE used in the DRC experiments is then used to predict the XANES spectrum and spread for each of the site-molecule pairs.\nWe use \u03b4 \u2208 {0.01, 0.02, . . . , 0.1} \u00c5, and present averaged results analogous to Eq. (10) in Fig. 8 as a function of \u03b4. Most importantly, as the average error increases across the average of all results for a given \u03b4, so does the uncertainty measure. This trend is significant and covers roughly a half of an order of magnitude. This shows quantitatively that on average, the uncertainty estimate tracks how out-of-sample a dataset is with respect to its training data. However, it does not\nquantify the relative difference between a certain and uncertain prediction. To address this, we sample a single example for each molecule-\u03b4 pair, and plot the ground truth, NNE prediction and spreads in Fig. 9. Appendix F contains more fine-grained details relating to this analysis, including density parity plots of the errors and uncertainty measures (Fig. 15), and a waterfall plot of distorted spectra (Fig. 16).\nWhile it is only a small sample of the dataset of distorted molecules, the results in Fig. 9 clearly show that on average, the NNE is able to detect when distorted geometries are sufficiently out-of-sample to render a prediction inaccurate. Overall accuracy varies visually as the distortion increases, but the uncertainty estimate gets significantly larger after \u03b4 = 0.03. In most cases, this uncertainty stays relatively large compared to e.g. \u03b4 = 0.01, indicating the NNE recognizes that the geometry is likely unseen. We highlight that detecting when a geometry is out-of-sample is not a trivial task, since while the ACSF vectors are human-interpretable, they are not easily so. Defining necessary heuristics to detect an out-of-sample geometry is likely not feasible. The fact that the NNE can perform this task verifies its potential usefulness in situations where detecting, e.g., change points [70] (where the statistical distribution of data changes) is required. This could be of particular use in active learning loops, where new training data are sampled based on the uncertainty measure of the ML model."
        },
        {
            "heading": "V. CONCLUSIONS AND OUTLOOK",
            "text": "In this work, we use NNEs to make quantitatively accurate predictions of molecular XANES spectra from local atomistic geometry, and to accurately quantify the uncertainty of those predictions under a variety of conditions. Simulating XANES spectra of a large number of molecules and clusters at a high level of theory is computationally demanding, and UA surrogate modeling provides an avenue for greatly accelerating the simulations while reliably quantifying model confidence. Often, for comparison with experimental measurements it requires an expensive averaging over a large number of structures, such as when computing a thermal average, which necessitates the use of surrogate model acceleration. We anticipate that the NNE approach, and UA modeling in general, can be particularly useful for large, complex systems, such as the dynamical evolution of protein structures, organic liquids,\n013180-11\nand solvated molecules, allowing users to make predictions efficiently and with confidence.\nAlthough our work falls into the space of ML-driven spectral function prediction, an accurate surrogate also has important implications for the inverse problem, where physical descriptors are extracted from the spectral function. For example, one strategy to solve the inverse problem in XAS is to identify candidate structures that produce results consistent with a target. This is more broadly known as structure refinement. Various sampling methods are widely used for this purpose, such as reverse Monte Carlo [71,72] and genetic algorithms [73]. Combining these sampling methods with an accurate and efficient forward surrogate model opens new avenues to tackle the inverse problem.\nBeyond the problems presented in this manuscript, we believe that the general principles of UQ methods could have broad implications not only for the case of datasets from in silico experiments, but also for laboratory measurements in experimental science. While modeling aleatoric noise in experimental data is required for statistically robust predictions, UQ techniques can also be applied to, e.g., quality assurance and control. For example, the detection and elimination of data that results from a variety of experimental sources such as misalignment and errors in control settings (similar to Appendices C and E). UQ-enabled models could also be useful for predicting experiment-quality data. As long as noise and other\nsources of uncertainty can be accurately modeled, it would mitigate the risk otherwise posed by the immense challenge of modeling experiments with these types of data-driven techniques.\nAs problems become more complicated, and calculations become more expensive (and thus the stakes become higher), ensuring model confidence becomes evermore important. Conveniently, there exists a vast array of UA models and methodologies for quantifying uncertainty, each with their own strengths and weaknesses. In the case of NNEs, the cost of training multiple models is more than worth the payoff. The application of UQ techniques to vector targets, and to a wider variety of problems in the physical sciences is certainly still an open problem in general. However, we have found that one can gain a significant amount of utility through the straightforward use of a NNE: an ensemble of independent estimators. In this case, if you can train one model, you can train a sufficient number of models to produce a reasonable measure of uncertainty with a low overhead.\nIn conclusion, our case study demonstrates the robust performance of a NNE with uncertainty quantification for predicting complex targets (XANES spectra of small molecules) from the descriptors of local chemical and structural information. More generally, this expands the scope of uncertainty-aware machine learning methods to the case of predicting vector quantities in physical modeling, an area that\n013180-12\nis largely unexplored to date. UQ modeling offers compelling advantages over traditional more boilerplate machine learning techniques at an acceptable cost.\nAll software used in this work, as well as all data used in this work, including FEFF spectra input/output files, featured data, and the neural network ensembles, can be found in Ref. [74]."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "M.R.C. would like to thank Nongnuch Artrith and Alexander Urban for helpful discussions regarding active learning. This research is based upon work supported by the U.S. Department of Energy, Office of Science, Office Basic Energy Sciences, under Award No. FWP PS-030. This research also used theory and computational resources of the Center for Functional Nanomaterials, which is a U.S. Department of Energy Office of Science User Facility, and the Scientific Data and Computing Center, a component of the Computational Science Initiative, at Brookhaven National Laboratory under Contract No. DE-SC0012704. This project was supported in part by the U.S. Department of Energy, Office of Science, Office of Workforce Development for Teachers and Scientists (WDTS) under the Science Undergraduate Laboratory Internships Program (SULI)."
        },
        {
            "heading": "APPENDIX A: DATABASE CONSTRUCTION",
            "text": ""
        },
        {
            "heading": "1. ACSF feature vector details",
            "text": "Molecular geometry files were read directly from the QM9 [35] database, which is freely available for download at Ref. [75]. We utilize the PYMATGEN [76], DSCRIBE [56], and ASE [77] libraries to construct our ACSF feature vectors. Zwitterionic molecules, those which contain an equal number of positively and negatively charged motifs, are discarded and not included in the machine learning databases. The initialization of the ACSF object is shown below.\n1 from dscribe.descriptors import ACSF # v 1.2.1\n2 neighbors = [\u2019\u2019H\u2019\u2019, \u2018\u2018C\u2019\u2019, \u2018\u2018O\u2019\u2019, \u2018\u2018N\u2019\u2019, \u2018\u2018F\u2019\u2019]\n3 rcut = 6.0 # Angstroms 4 g2_params = [ 5 [1.0, 0], 6 [0.1, 0], 7 [0.01, 0] 8 ] 9 g4_params=[ 10 [0.001, 1.0, -1.0], 11 [0.001, 2.0, -1.0], 12 [0.001, 4.0, -1.0], 13 [0.01, 1.0, -1.0], 14 [0.01, 2.0, -1.0], 15 [0.01, 4.0, -1.0], 16 [0.1, 1.0, -1.0], 17 [0.1, 2.0, -1.0], 18 [0.1, 3.0, -1.0] 19 ] 20 acsf = ACSF( 21 species=neighbors,\n22 rcut=rcut, 23 g2_params=g2_params, 24 g4_params=g4_params 25 ) We iterate through every possible atom in each molecule, and construct the atom\u2019s ACSF vector if it matches an absorbing atom used in this work (C, N, or O)."
        },
        {
            "heading": "2. Spectra target vector details",
            "text": "Sitewise spectra for each of C, N, and O absorbing atoms were computed using the FEFF9 code [55]. A common preamble to a FEFF calculation is shown below. Particularly, we use a corehole approximation at the random phase approximation (RPA) level of theory, full multiple scattering up to 9 \u00c5, and self-consistency up to 7 \u00c5.\n1 TITLE... 2 3 EDGE K 4 S02 1.0 5 COREHOLE RPA 6 CONTROL 1 1 1 1 1 1 7 8 XANES 4 0.04 0.1 9 10 FMS 9.0 11 EXCHANGE 0 0.0 0.0 2 12 SCF 7.0 1 100 0.2 3 13 RPATH -1 Once the initial spectral databases were constructed, we screen for extreme outliers or unphysical spectra using methods similar to those described in Ref. [39] (though we note that these screening procedures are not entirely robust, see the discussion corresponding to Fig. 14). Spectra are then interpolated onto common grids using cubic splines. The grids for each absorbing atom type are shown below using Python+NumPy.\n1 import numpy as np 2 M = 200 3 grids = 4 \u2018\u2018C\u2019\u2019: np.linspace(275, 329, M), 5 \u2018\u2018N\u2019\u2019: np.linspace(395, 449, M), 6 \u2018\u2018O\u2019\u2019: np.linspace(528, 582, M) 7"
        },
        {
            "heading": "APPENDIX B: TRAINING DETAILS",
            "text": "In this Appendix, we highlight the important details of our training procedures which can be used to reproduce the work presented in this manuscript. All training was performed on Tesla V100 GPUs using Pytorch+PyTorch Lightning, and the summary of the training and software used for our machine learning pipeline are shown in Table II.\nEach estimator, a FFNN, was trained independently. Each estimator in the ensemble was randomly initialized, with a minimum of 4 layers, a maximum of 20 layers, a minimum of 160 neurons/layer, and a maximum of 200 neurons/layers. The Adam optimizer, L1 loss function, Leaky ReLU activations (except the last layer, which is a softplus) and batch\n013180-13\nnormalization (except the last layer) were used for every instance of training.\nDuring training, learning rates were multiplied by a factor of 0.95 after 20 successive epochs in which the validation loss failed to decrease. A maximum of 2000 epochs proved sufficient with early stopping criteria monitoring when the validation loss plateaued during training (with a patience of 100 epochs)."
        },
        {
            "heading": "APPENDIX C: ENSEMBLE PREDICTION DETAILS",
            "text": "In Sec. IV A, we defined the set of estimator indexes to be E, and the set of estimator indexes corresponding to \u201creasonable\u201d predictions to be E (i). We now define precisely how we determine whether or not a prediction is reasonable.\nWe utilize three criteria to screen for unreasonable predictions.\n(1) For a set of predicted spectra (with fixed i) {\u03bc\u0302(i,k)}|E|k=1, we define the estimator spread \u03c3\u0302 (i). Any spectra in which 70% of the total grid points fall outside a region defined by \u03bc\u0302(i) \u00b1 2\u03c3\u0302 (i) are discarded.\n(2) Given a predicted spectrum \u03bc\u0302(i,k), if any point \u03bc\u0302(i,k)j is greater than 20 (a.u.; roughly an order of magnitude greater than the largest spectral intensity in our datasets) that prediction is discarded.\n(3) If more than half of the predictions \u03bc\u0302(i,k)j for a given i, k fall below an intensity of 0.05, that prediction is discarded.\nThese three rules are purely empirical and capture three different kinds of model failure scenarios, each of which is completely independent of the ground truth data. In point 1, we screen for statistical outliers. The spread of the estimator predictions is treated as a Gaussian standard deviation (we note again that this treatment is purely empirical), and any spectra in which a substantial portion of the predicted values fall outside of an \u224895% confidence interval are discarded. Points 2 and 3 screen on physical grounds. We know from experience and quantum mechanical principles that the FEFF code will only output predictions of certain intensities. Model failure situations routinely included single estimators predicting intensities of \u03bc > 100, which are clearly unphysical. Similarly, it is known that the XAS is mostly positive. While model outputs are hard-constrained to be non-negative by the Softplus activation functions, they can be approximately zero. If a sufficient portion of the spectrum is close to zero, we know that prediction is unphysical and hence it is discarded.\nThe set of estimator indexes that correspond to reasonable predictions is thus defined as E (i), and is inherently dependent on the training example. It is worth highlighting that if estimator k is discarded for training example i, it likely will not be discarded, for example, i\u2032 = i."
        },
        {
            "heading": "APPENDIX D: TRAINING SET SIZE DEPENDENCE",
            "text": "OF DRA AND DGA\nA useful sanity check when performing any ML modeling is to ensure that error decreases as the training set size increases. For any single estimator, this is usually tested by downsampling the training set by some proportion p and evaluating on a fixed testing set. The value for p is then scanned and the testing set error as a function of p evaluated. We evaluate this metric for both DRA and DGA , by randomly downsampling and showcasing how testing set error changes as a function of the number of atoms per molecule used during training.\nInstead of training a single estimator, we evaluate these metrics on the ensembles. For the random partitioning datasets DRA , we randomly downsample the fixed training set by proportion p independently for each of the 30 estimators, train them on the pNtrain training examples, and evaluate on the fixed testing set (the same testing set used in the random partitioning dataset, see Sec. IV A). Each ensemble was randomly initialized for each p. Ensemble predictions are made in accordance with the protocol described in Appendix C, and the results averaged over all Ntest testing examples. Similarly, for the generalization test databases DGA , we follow the procedure as outlined in Sec. IV B, and for each instance of the number of atoms per molecule, compute the amount of training data used. All of these results are plotted in Fig. 10.\nImmediately, it is clear that the testing set error trend is decreasing with increasing p and with increasing amounts of training data, exactly as expected. However in Fig. 10(a), the decrease is not monotonic for the N and O datasets, though it is for the C dataset. Given that the C dataset is much larger (see Fig. 4), it is more probable that even small samples of the training dataset capture general trends, even for small p. The N and O datasets are significantly smaller, and hence for small p it is less likely that significant trends are captured on balance. Finally, the relative decrease in the testing error as a function of p is surprisingly small. For example, the percent change in the N results from p = 0.1 to 0.9 is only roughly 12%. While this is a relatively small change (see, e.g., Supplementary Material in Ref. [40]), it is actually an encouraging result. It is likely that failures of individual estimators in certain regions of the input parameter space at small p are compensated for by other estimators in the ensemble, making the overall inference procedure at low p surprisingly robust.\nIn Fig. 10(b), the trend is much more clear because the amount of training data spans multiple orders of magnitude. However, a key takeaway is that the decrease in the error is incredibly small relative to the amount of training data used: roughly a single order of magnitude compared to 3 orders of magnitude increase in the amount of training data. As discussed in the main text, this is a testament to the NNE method\u2019s ability to generalize when trained on absorbing site data, and the diversity of the chemical space of QM9\u2019s molecules containing even \u223c103 heavy atoms per molecule.\nWe present the error histograms for most of the relevant training procedures in this work in Fig. 11. Subfigures (a)\u2013 (c) depict the log10 sitewise testing set error distributions for DRA , both for the ensemble-averaged error (black) and the average single estimator error (red). One can see clearly that the\n013180-14\nensemble predictions are systematically better than any single estimator on average, as expected of ensemble-based models. Subfigures (d)\u2013(f) showcase the log10 molecular testing set error distributions for DGA , as a function of the total number of atoms per molecule used during training (see legend). Figure 12 is the analog of Fig. 6 for the molecular data. It shows the same trends and overall behavior as the aforementioned site-spectrum figure in the main text.\nFinally, we present a qualitative analysis of how the error and standard deviations correlate as a function of training set size pNtrain in Fig. 13. Even for p = 0.1, we see that the correlation between the average errors and standard deviations remains intact. This is an indication that even with limited training data, uncertainty-quantifying models can still accurately gauge when they are out of sample, and provide a reasonable estimate as to their own uncertainty."
        },
        {
            "heading": "APPENDIX E: EXPLANATION OF FIG. 6 OUTLIERS",
            "text": "The C and O results in Fig. 6 present with some interesting outlier behavior (for example, the data above the fourth dashed lines). These patterns clearly indicate something has gone systematically wrong, and as such, as a pedagogical exercise we investigate the cause of such significant underestimation of the errors. As an example, we look at the O results; it turns out that most of the outliers (captured by taking log10 \u03c3\u0302 (i) j < \u22122 and log10 \u03b5\u0302(i)j > \u22121 in Fig. 6) come from a single spectrum. This failure case is plotted in Fig. 14. The significant underestimation of the error is visually obvious by comparing the spread of the predictions (red) with the supposed ground truth (black). However, this ground truth spectrum is actually an outlier with respect to other training data, suggesting the possibility that the ground truth is incorrect. To test this hypothesis, we also plot the closest\n013180-15\nground truth spectrum to the mean of the predicted spectra from the training set (dashed black, \u03bc ). These two spectra are in almost perfect agreement. We then compare the molecular structures of the inputs, which are also shown in Fig. 14. The SMILES string corresponding to the ground truth and best training set example, CCCC1(C)COC=N1 and CCCC1COC=N1, respectively, are chemically almost identical, differing by a single methyl group. Additionally, the top 3 closest spectra to the ensemble-averaged prediction all contain a N=C-O motif contained in a five-membered ring, strongly suggesting that the FEFF calculation used to generate the ground truth spectrum failed to properly converge, and indicating that the NNE prediction, and low uncertainty estimate, are actually correct.\nIn order to confirm this hypothesis, we performed two sanity checks. First, we reran the FEFF calculations to see if the convergence failure was systemic. Second, we double checked that a different computational spectroscopy software (we chose to use the Vienna ab initio simulation package, or VASP [80]), produced similar spectra for these absorbing sites as well. In summary, our original FEFF calculation failed to converge, the rerun produced the expected result (similar to \u03bc in Fig. 14), and the two VASP calculations (VASP calculations were performed using PBE pseudopotentials a 2 \u00d7 2 \u00d7 2 grid for the k-points, and a square supercell volume of 20 \u00d7 20 \u00d7 20; all quantities are in units of angstroms) also produced qualitatively similar spectra, confirming that indeed\nthe O-XANES spectrum of each of these molecules is essentially the same, and that the NNE prediction is correct.\nOf course, for a real world deployment scenario, any piece of ground truth data that ends up being unphysical would be removed from the training datasets. However, in this case, we highlight that the NNE model was robust to these outliers. Future work could be dedicated to exploring how robust NNEs or related methods are for outlier detection in a database in general, especially in cases where it is suspected the source of truth can actually be incorrect."
        },
        {
            "heading": "APPENDIX F: SUPPLEMENTARY ANALYSIS OF OUT-OF-EQUILIBRIUM DISTORTION TESTS",
            "text": "In this Appendix, we present two useful figures for the analysis of the out-of-equilibrium geometry tests. First, in Fig. 15, we present a parity plot of the pointwise log10 errors vs. the log10 uncertainty estimates. The same positive linear trend found in Figs. 6 and 12 is realized here. Additionally, it is subtle, but as the distortion amount increases, so does the overall error and uncertainty estimate, continuing to substantiate the results in Sec. IV C.\n013180-16\nSecond, to provide an idea of what distorted spectra look like, in Fig. 16, we showcase a waterfall plot of random sampling of the database of distorted spectra, resolved once again by values of \u03b4 and molecule (in the same order as the previous related figures). As a result of the geometry distortion, every\nmolecule begins to exhibit significant new spectral trends. Given that these new geometries are necessarily not in their equilibrium state, they will be much more challenging (if not infeasible) for the NNE to predict, and provide a good test for the NNE\u2019s ability to quantify epistemic uncertainty.\n013180-17\n[1] K. T. Butler, D. W. Davies, H. Cartwright, O. Isayev, and A. Walsh, Machine learning for molecular and materials science, Nature (London) 559, 547 (2018).\n[2] G. Carleo, I. Cirac, K. Cranmer, L. Daudet, M. Schuld, N. Tishby, L. Vogt-Maranto, and L. Zdeborov\u00e1, Machine learning and the physical sciences, Rev. Mod. Phys. 91, 045002 (2019).\n[3] J. Behler and M. Parrinello, Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces, Phys. Rev. Lett. 98, 146401 (2007).\n[4] R. Ramakrishnan, P. O. Dral, M. Rupp, and O. A. Von Lilienfeld, Big data meets quantum chemistry approximations: the \u03b4-machine learning approach, J. Chem. Theory Comput. 11, 2087 (2015).\n[5] Z. Wu, B. Ramsundar, E. N. Feinberg, J. Gomes, C. Geniesse, A. S. Pappu, K. Leswing, and V. Pande, Moleculenet: A benchmark for molecular machine learning, Chem. Sci. 9, 513 (2018).\n[6] R. G\u00f3mez-Bombarelli, J. N. Wei, D. Duvenaud, J. M. Hern\u00e1ndez-Lobato, B. S\u00e1nchez-Lengeling, D. Sheberla, J. Aguilera-Iparraguirre, T. D. Hirzel, R. P. Adams, and A. Aspuru-Guzik, Automatic chemical design using a data-driven continuous representation of molecules, ACS Cent. Sci. 4, 268 (2018).\n[7] Y. Nomura, A. S. Darmawan, Y. Yamaji, and M. Imada, Restricted boltzmann machine learning for solving strongly correlated quantum systems, Phys. Rev. B 96, 205152 (2017).\n[8] L. F. Arsenault, A. Lopez-Bezanilla, O. A. von Lilienfeld, and A. J. Millis, Machine learning for many-body physics: The case of the anderson impurity model, Phys. Rev. B 90, 155136 (2014).\n[9] D.-L. Deng, X. Li, and S. Das Sarma, Machine learning topological states, Phys. Rev. B 96, 195145 (2017).\n[10] K. Ch\u2019ng, J. Carrasquilla, R. G. Melko, and E. Khatami, Machine Learning Phases of Strongly Correlated Fermions, Phys. Rev. X 7, 031038 (2017).\n[11] M. Abdar, F. Pourpanah, S. Hussain, D. Rezazadegan, L. Liu, M. Ghavamzadeh, P. Fieguth, X. Cao, A. Khosravi, U. R.\nAcharya et al., A review of uncertainty quantification in deep learning: Techniques, applications and challenges, Inf. Fusion 76, 243 (2021).\n[12] C. E. Rasmussen and C. K. I. Williams, Gaussian Processes for Machine Learning (MIT Press, Cambridge, 2006).\n[13] S. Krishnadasan, R. J. C. Brown, A. J. Demello, and J. C. Demello, Intelligent routes to the controlled synthesis of nanoparticles, Lab Chip 7, 1434 (2007).\n[14] D. E. Fitzpatrick, C. Battilocchio, and S. V. Ley, A novel internet-based reaction monitoring, control and autonomous self-optimization platform for chemical synthesis, Org. Process Res. Dev. 20, 386 (2016).\n[15] R. W. Epps, M. S. Bowen, A. A. Volk, K. Abdel-Latif, S. Han, K. G. Reyes, A. Amassian, and M. Abolhasani, Artificial chemist: an autonomous quantum dot synthesis bot, Adv. Mater. 32, 2001626 (2020).\n[16] A. E. Gongora, B. Xu, W. Perry, C. Okoye, P. Riley, K. G. Reyes, E. F. Morgan, and K. A. Brown, A bayesian experimental autonomous researcher for mechanical design, Sci. Adv. 6, eaaz1708 (2020).\n[17] A. E. Gongora, K. L. Snapp, E. Whiting, P. Riley, K. G. Reyes, E. F. Morgan, and K. A. Brown, Using simulation to accelerate autonomous experimentation: A case study using mechanics, iScience 24, 102262 (2021).\n[18] J. Behler, Atom-centered symmetry functions for constructing high-dimensional neural network potentials, J. Chem. Phys. 134, 074106 (2011).\n[19] N. Artrith, T. Morawietz, and J. Behler, High-dimensional neural-network potentials for multicomponent systems: Applications to zinc oxide, Phys. Rev. B 83, 153101 (2011).\n[20] N. Artrith and J. Behler, High-dimensional neural network potentials for metal surfaces: A prototype study for copper, Phys. Rev. B 85, 045439 (2012).\n[21] C. Schran, K. Brezina, and O. Marsalek, Committee neural network potentials control generalization errors and enable active learning, J. Chem. Phys. 153, 104105 (2020).\n013180-18\n[22] J. Behler, Four generations of high-dimensional neural network potentials, Chem. Rev. 121, 10037 (2021).\n[23] P. Friederich, F. H\u00e4se, J. Proppe, and A. Aspuru-Guzik, Machine-learned potentials for next-generation matter simulations, Nat. Mater. 20, 750 (2021).\n[24] E. V. Podryabinkin and A. V. Shapeev, Active learning of linearly parametrized interatomic potentials, Comput. Mater. Sci. 140, 171 (2017).\n[25] G. Sivaraman, A. N. Krishnamoorthy, M. Baur, C. Holm, M. Stan, G. Cs\u00e1nyi, C. Benmore, and \u00c1. V\u00e1zquez-Mayagoitia, Machine-learned interatomic potentials by active learning: amorphous and liquid hafnium dioxide, npj Comput. Mater. 6, 104 (2020).\n[26] B. Settles, Active Learning Literature Survey (Computer Science Technical Report 1648, University of Wisconsin-Madison Department of Computer Sciences, 2009).\n[27] K. Gubaev, E. V. Podryabinkin, and A. V. Shapeev, Machine learning of molecular properties: Locality and active learning, J. Chem. Phys. 148, 241727 (2018).\n[28] A. L. Ankudinov, J. J. Rehr, J. J. Low, and S. R. Bare, Sensitivity of Pt x-ray absorption near edge structure to the morphology of small Pt clusters, J. Chem. Phys. 116, 1911 (2002).\n[29] A. L. Ankudinov and J. J. Rehr, Development of xafs theory, J. Synchrotron Radiat. 10, 366 (2003).\n[30] D. Bazin and J. J. Rehr, Limits and advantages of x-ray absorption near edge structure for nanometer scale metallic clusters, J. Phys. Chem. B 107, 12398 (2003).\n[31] G. Ciatto, A. Di Trolio, E. Fonda, P. Alippi, A. M. Testa, and A. A. Bonapasta, Evidence of Cobalt-Vacancy Complexes in Zn1-xCoxO Dilute Magnetic Semiconductors, Phys. Rev. Lett. 107, 127206 (2011).\n[32] Q. Ma, J. T. Prater, C. Sudakar, R. A. Rosenberg, and J. Narayan, Defects in room-temperature ferromagnetic Cu-doped ZnO films probed by x-ray absorption spectroscopy, J. Phys.: Condens. Matter 24, 306002 (2012).\n[33] A. Kuzmin and J. Chaboy, Exafs and xanes analysis of oxides at the nanoscale, IUCrJ 1, 571 (2014).\n[34] C. D. Rankine and T. J. Penfold, Accurate, affordable, and generalizable machine learning simulations of transition metal x-ray absorption spectra using the xanesnet deep neural network, J. Chem. Phys. 156, 164102 (2022).\n[35] R. Ramakrishnan, P. O. Dral, M. Rupp, and O. A. Von Lilienfeld, Quantum chemistry structures and properties of 134 kilo molecules, Sci. Data 1, 140022 (2014).\n[36] T. J. Penfold and C. D. Rankine, A deep neural network for valence-to-core x-ray emission spectroscopy, Mol. Phys., e2123406 (2022).\n[37] A. Y.-T. Wang, R. J. Murdock, S. K. Kauwe, A. O. Oliynyk, A. Gurlo, J. Brgoch, K. A. Persson, and T. D. Sparks, Machine learning for materials scientists: An introductory guide toward best practices, Chem. Mater. 32, 4954 (2020).\n[38] N. Artrith, K. T. Butler, F.-X. Coudert, S. Han, O. Isayev, A. Jain, and A. Walsh, Best practices in machine learning for chemistry, Nat. Chem. 13, 505 (2021).\n[39] M. R. Carbone, S. Yoo, M. Topsakal, and D. Lu, Classification of local chemical environments from x-ray absorption spectra using supervised machine learning, Phys. Rev. Mater. 3, 033604 (2019).\n[40] M. R. Carbone, M. Topsakal, D. Lu, and S. Yoo, MachineLearning X-Ray Absorption Spectra to Quantitative Accuracy, Phys. Rev. Lett. 124, 156401 (2020).\n[41] S. B. Torrisi, M. R. Carbone, B. A. Rohr, J. H. Montoya, Y. Ha, J. Yano, S. K. Suram, and L. Hung, Random forest machine learning models for interpretable x-ray absorption near-edge structure spectrum-property relationships, npj Comput. Mater. 6, 109 (2020).\n[42] E. J. Sturm, M. R. Carbone, D. Lu, A. Weichselbaum, and R. M. Konik, Predicting impurity spectral functions using machine learning, Phys. Rev. B 103, 245118 (2021).\n[43] C. Miles, M. R. Carbone, E. J. Sturm, D. Lu, A. Weichselbaum, K. Barros, and R. M. Konik, Machine learning of kondo physics using variational autoencoders and symbolic regression, Phys. Rev. B 104, 235111 (2021).\n[44] E. H\u00fcllermeier and W. Waegeman, Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods, Mach. Learn. 110, 457 (2021).\n[45] R. Egele, R. Maulik, K. Raghavan, P. Balaprakash, and B. Lusch, Autodeuq: Automated deep ensemble with uncertainty quantification, arXiv:2110.13511.\n[46] D. A. Nix and A. S. Weigend, Estimating the mean and variance of the target probability distribution, in Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN\u201994) (IEEE, 1994), Vol. 1, pp. 55\u201360.\n[47] L. V. Jospin, H. Laga, F. Boussaid, W. Buntine, and M. Bennamoun, Hands-on bayesian neural networks-a tutorial for deep learning users, IEEE Comput. Intell. Mag. 17, 29 (2022).\n[48] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, Dropout: A simple way to prevent neural networks from overfitting, J. Mach. Learn. Res. 15, 1929 (2014).\n[49] R. Hu, Q. Huang, S. Chang, H. Wang, and J. He, The mbpep: A deep ensemble pruning algorithm providing high quality uncertainty prediction, Appl. Intell. 49, 2942 (2019).\n[50] A. G. Wilson and P. Izmailov, Bayesian deep learning and a probabilistic perspective of generalization, Adv. Neural Inf. Process. Syst. 33, 4697 (2020).\n[51] M. Tschannen, O. Bachem, and M. Lucic, Recent advances in autoencoder-based representation learning, arXiv:1812.05069 (2018).\n[52] Y. Zhu, N. Zabaras, P.-S. Koutsourelakis, and P. Perdikaris, Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data, J. Comput. Phys. 394, 56 (2019).\n[53] X. Luo, B. T. Nadiga, Y. Ren, J. H. Park, W. Xu, and S. Yoo, A bayesian deep learning approach to near-term climate prediction, J. Adv. Model. Earth Syst. 14, e2022MS003058 (2022).\n[54] L. Ruddigkeit, R. Van Deursen, L. C. Blum, and J.-L. Reymond, Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17, J. Chem. Inf. Model. 52, 2864 (2012).\n[55] J. J. Rehr, J. J. Kas, F. D. Vila, M. P. Prange, and K. Jorissen, Parameter-free calculations of x-ray spectra with FEFF9, Phys. Chem. Chem. Phys. 12, 5503 (2010).\n[56] L. Himanen, M. O. J. J\u00e4ger, E. V. Morooka, F. Federici Canova, Y. S. Ranawat, D. Z. Gao, P. Rinke, and A. S. Foster, DScribe: Library of descriptors for machine learning in materials science, Comput. Phys. Commun. 247, 106949 (2020).\n[57] A. P. Bart\u00f3k, R. Kondor, and G. Cs\u00e1nyi, On representing chemical environments, Phys. Rev. B 87, 184115 (2013).\n013180-19\n[58] H. Huo and M. Rupp, Unified representation of molecules and crystals for machine learning, Mach. Learn. Sci. Technol. 3, 045017 (2022).\n[59] M. Gastegger, L. Schwiedrzik, M. Bittermann, F. Berzsenyi, and P. Marquetand, wacsf-weighted atom-centered symmetry functions as descriptors in machine learning potentials, J. Chem. Phys. 148, 241709 (2018).\n[60] N. Artrith and A. Urban, An implementation of artificial neural-network potentials for atomistic materials simulations: Performance for TiO2, Comput. Mater. Sci. 114, 135 (2016).\n[61] A. L. Ankudinov, B. Ravel, J. J. Rehr, and S. D. Conradson, Real-space multiple-scattering calculation and interpretation of x-ray-absorption near-edge structure, Phys. Rev. B 58, 7565 (1998).\n[62] J. J. Rehr and R. C. Albers, Theoretical approaches to x-ray absorption fine structure, Rev. Mod. Phys. 72, 621 (2000).\n[63] L. Van der Maaten and G. Hinton, Visualizing data using t-SNE, J. Mach. Learn. Res. 9, 2579 (2008).\n[64] M. Wattenberg, F. Vi\u00e9gas, and I. Johnson, How to use t-SNE effectively, Distill 1, e2 (2016).\n[65] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, Scikit-learn: Machine learning in Python, J. Mach. Learn. Res. 12, 2825 (2011).\n[66] R. J. Tibshirani and B. Efron, An Introduction to the Bootstrap, Monogr. Stat. Appl. Probab. 57, 1 (1993).\n[67] B. Bakker and T. Heskes, Clustering ensembles of neural network models, Neural Netw. 16, 261 (2003).\n[68] I. J. Goodfellow, J. Shlens, and C. Szegedy, Explaining and harnessing adversarial examples, arXiv:1412.6572 (2014).\n[69] M. R. Carbone, When not to use machine learning: A perspective on potential and limitations, MRS Bull. 47, 968 (2022).\n[70] T. Flynn and S. Yoo, Change detection with the kernel cumulative sum algorithm, in 2019 IEEE 58th\nConference on Decision and Control (CDC) (IEEE, 2019), pp. 6092\u20136099.\n[71] R. L. McGreevy and L. Pusztai, Reverse monte carlo simulation: a new technique for the determination of disordered structures, Mol. Simul. 1, 359 (1988).\n[72] R. L. McGreevy, Reverse monte carlo modelling, J. Phys.: Condens. Matter 13, R877 (2001). [73] D. Whitley, A genetic algorithm tutorial, Stat. Comput. 4, 65 (1994).\n[74] All software used in this work can be found open source at github.com/AI-multimodal/XAS-NNE. All data used in this work, including FEFF spectra input/output files, featurized data, and the neural network ensembles can be found open access at https://dx.doi.org/10.5281/zenodo.7554888.\n[75] http://quantum-machine.org/datasets/ [76] S. P. Ong, W. D. Richards, A. Jain, G. Hautier, M. Kocher, S.\nCholia, D. Gunter, V. L. Chevrier, K. A. Persson, and G. Ceder, Python materials genomics (pymatgen): A robust, open-source python library for materials analysis, Comput. Mater. Sci. 68, 314 (2013).\n[77] A. H. Larsen, J. J. Mortensen, J. Blomqvist, I. E. Castelli, R. Christensen, M. Du\u0142ak, J. Friis, M. N. Groves, B. Hammer, C. Hargus et al., The atomic simulation environment-a python library for working with atoms, J. Phys.: Condens. Matter 29, 273002 (2017).\n[78] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai et al., Pytorch: An imperative style, high-performance deep learning library, Adv. Neural Inf. Process. Syst. 32, 8026 (2019).\n[79] W. Falcon and The PyTorch Lightning team, PyTorch Lightning (2019), doi: 10.5281/zenodo.3828935.\n[80] G. Kresse and D. Joubert, From ultrasoft pseudopotentials to the projector augmented-wave method, Phys. Rev. B 59, 1758 (1999).\n013180-20"
        }
    ],
    "title": "Uncertainty-aware predictions of molecular x-ray absorption spectra using neural network ensembles",
    "year": 2023
}