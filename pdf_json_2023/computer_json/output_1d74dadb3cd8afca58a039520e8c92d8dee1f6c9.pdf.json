{
    "abstractText": "The traditional combination forecasting model has good forecasting effect, but it needs precise historical data. In fact, many random events are uncertain, and much of the data are imprecise; sometimes, historical data are lacking. We need to study combination forecasting problems by means of uncertainty theory. Uncertain least squares estimation is an important technique of uncertain statistics, an important way to deal with imprecise data, and one of the best methods to solve the unknown parameters of uncertain linear regression equations. On the basis of the traditional combination forecasting method and uncertain least squares estimation, this paper proposes two kinds of uncertain combination forecasting models, which are the unary uncertain linear combination forecasting model and the uncertain relative error combination forecasting model, respectively. We set up several piecewise linear regression models according to the data of different periods and, according to certain weights, These piecewise linear regression models are combined into a unary uncertain linear combination forecasting model with a better forecasting effect. The uncertain relative error combination forecasting model is a new forecasting model that combines the traditional relative error linear forecasting model and the uncertain least squares estimation. Compared with the traditional forecasting model, the model can better deal with the forecasting problem of imprecise data. We verify the feasibility of the uncertain combination forecasting model through a numerical example. According to the data analysis, compared with the existing model, the forecasting effect of the proposed model is better.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jian Zhou"
        },
        {
            "affiliations": [],
            "name": "Ke Wang"
        },
        {
            "affiliations": [],
            "name": "Yuanyuan Liu"
        },
        {
            "affiliations": [],
            "name": "Marek T. Malinowski"
        },
        {
            "affiliations": [],
            "name": "Hongmei Shi"
        },
        {
            "affiliations": [],
            "name": "Lin Wei"
        },
        {
            "affiliations": [],
            "name": "Cui Wang"
        },
        {
            "affiliations": [],
            "name": "Shuai Wang"
        },
        {
            "affiliations": [],
            "name": "Yufu Ning"
        }
    ],
    "id": "SP:d725f827302f7c93c71ccb7ba918dc34b54be3fe",
    "references": [
        {
            "authors": [
                "C. Yao",
                "J. Wang"
            ],
            "title": "A comparative study on forecast models of apple output in China",
            "venue": "J. Fruit Sci. 2007,",
            "year": 2007
        },
        {
            "authors": [
                "Y. Meng",
                "J. Wang",
                "G. Kang",
                "C. Chen"
            ],
            "title": "Analysis of apple production status in China",
            "venue": "China Fruit Trees 2007,",
            "year": 2007
        },
        {
            "authors": [
                "L. Hou",
                "C. Sun"
            ],
            "title": "A neural network forecast model for apple yield",
            "venue": "J. China Agric. Univ. Soc. Sci. Ed",
            "year": 2001
        },
        {
            "authors": [
                "S. Gao",
                "S. Zhang",
                "L. Mei"
            ],
            "title": "Linear combination forecast based on relative error criterion",
            "venue": "J. Syst. Eng. Electron. 2008,",
            "year": 2008
        },
        {
            "authors": [
                "L. Hao",
                "D. Wu"
            ],
            "title": "Linear regression combined forecasting model\u2014Take the prediction of China\u2019s aging population as an example",
            "venue": "J. Shenyang Univ. Soc. Sci. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "B. Liu"
            ],
            "title": "Uncertainty Theory: A Branch of Mathematics for Modeling Human Uncertainty",
            "year": 2010
        },
        {
            "authors": [
                "B. Liu"
            ],
            "title": "Uncertainty Theory, 2nd ed.",
            "year": 2007
        },
        {
            "authors": [
                "B. Liu"
            ],
            "title": "Some research problems in uncertainty theory",
            "venue": "J. Uncertain Syst. 2009,",
            "year": 2009
        },
        {
            "authors": [
                "B. Liu"
            ],
            "title": "Why is there a need for uncertainty theory",
            "venue": "J. Uncertain Syst. 2012,",
            "year": 2012
        },
        {
            "authors": [
                "B. Liu"
            ],
            "title": "Uncertainty Theory, 5th ed.; Springer: Berlin/Heidelberg, Germany, 2021",
            "year": 2021
        },
        {
            "authors": [
                "X. Wang",
                "Y. Ning"
            ],
            "title": "An Uncertain currency model with floating interest rates",
            "venue": "Soft Comput",
            "year": 2017
        },
        {
            "authors": [
                "Y. Ning",
                "N. Pang",
                "X. Wang"
            ],
            "title": "An Uncertain aggregate production planning model considering investment in vegetable preservation technology",
            "year": 2019
        },
        {
            "authors": [
                "H. Guo",
                "X. Wang",
                "Z. Gao"
            ],
            "title": "Uncertain linear regression model and its application",
            "venue": "J. Intell. Manuf",
            "year": 2014
        },
        {
            "authors": [
                "X. Wang",
                "Z. Peng"
            ],
            "title": "Method of moments for estimating uncertainty distributions",
            "venue": "J. Uncertain. Anal. Appl. 2014,",
            "year": 2014
        },
        {
            "authors": [
                "D. Chen"
            ],
            "title": "Tukey\u2019s biweight estimation for uncertain regression model with imprecise observations",
            "venue": "Soft Comput",
            "year": 2020
        },
        {
            "authors": [
                "Y. Song",
                "Z. Fu"
            ],
            "title": "Uncertain multivariable regression model",
            "venue": "Soft Comput",
            "year": 2018
        },
        {
            "authors": [
                "X. Wang",
                "H. Li",
                "H. Guo"
            ],
            "title": "A new Uncertain regression model and its application",
            "venue": "Soft Comput",
            "year": 2020
        },
        {
            "authors": [
                "Z. Liu"
            ],
            "title": "Least absolute deviations estimation for uncertain regression with imprecise observations",
            "venue": "Fuzzy Optim. Decis. Mak",
            "year": 2020
        },
        {
            "authors": [
                "K. Yao",
                "B. Liu"
            ],
            "title": "Uncertain regression analysis: An approach for imprecise observations",
            "venue": "Soft Comput",
            "year": 2018
        },
        {
            "authors": [
                "S. Wang",
                "Y. Ning",
                "H. Shi",
                "X. Chen"
            ],
            "title": "A new uncertain linear regression model based on slope mean",
            "venue": "J. Intell. Fuzzy Syst",
            "year": 2021
        },
        {
            "authors": [
                "S. Wang",
                "Y. Ning",
                "H. Shi"
            ],
            "title": "A new uncertain linear regression model based on equation deformation",
            "venue": "Soft Comput",
            "year": 2021
        },
        {
            "authors": [
                "S. Wang",
                "Y. Ning",
                "H. Huang"
            ],
            "title": "Uncertain least squares estimation model based on relative error",
            "venue": "J. Intell. Fuzzy Syst",
            "year": 2023
        },
        {
            "authors": [
                "H. Shi",
                "X. Sun",
                "S. Wang",
                "Y. Ning"
            ],
            "title": "Total least squares estimation model based on uncertainty theory",
            "venue": "J. Ambient. Intell. Humaniz. Comput",
            "year": 2023
        },
        {
            "authors": [
                "Z. Liu"
            ],
            "title": "Uncertain growth model for the cumulative number of COVID-19 infections in China",
            "venue": "Fuzzy Optim. Decis. Mak",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Citation: Shi, H.; Wei, L.; Wang, C.;\nWang, S.; Ning, Y. Relative Error\nLinear Combination Forecasting\nModel Based on Uncertainty Theory.\nSymmetry 2023, 15, 1379. https://\ndoi.org/10.3390/sym15071379\nAcademic Editors: Jian Zhou,\nKe Wang, Yuanyuan Liu and\nMarek T. Malinowski\nReceived: 7 June 2023\nRevised: 29 June 2023\nAccepted: 4 July 2023\nPublished: 7 July 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: combination forecasting model; relative error; least squares estimation; uncertainty theory; linear regression model"
        },
        {
            "heading": "1. Introduction",
            "text": "Regression analysis is a forecasting method for data analysis based on the causal relationship of changes in things; that is, according to the actual statistical data, through mathematical calculation, the interdependent quantitative relationship between variables is determined, and a reasonable mathematical model is established to calculate the future value of variables. Linear regression is a statistical analysis method that uses regression analysis in mathematical statistics to determine the interdependent quantitative relationship between two or more variables, which is widely used. Linear regression analysis is mainly used to analyze the observed values and fit a reasonable model. When a new value appears, it can be forecast using this model. The least squares method is a mathematical optimization technique, which is one of the most commonly used methods to solve the\nSymmetry 2023, 15, 1379. https://doi.org/10.3390/sym15071379 https://www.mdpi.com/journal/symmetry\nunknown parameters of linear regression. By minimizing the sum of squares of errors, it can find the best-matching data function and obtain a better linear regression fitting equation. The combination forecasting model adopts different single-item forecasting models for the same forecasting object, making full use of the information provided by various single item forecasting methods, and assigning appropriate weighting coefficients to improve the forecasting accuracy. There are many kinds of combination forecasting models, including the linear regression model, exponential model, power function model, logistic model, and neural network. Each model has its own characteristics and application scope. The idea of combining various models to achieve a better forecasting effect is basis of the combination forecasting. Many experts and scholars have conducted in-depth research on the linear combination forecasting model, deduced some forecasting models, achieved good results and carried out practical applications [1\u20135]. We know that precision and imprecision are symmetrical, precise data are relative, and imprecision data are absolute. Many of the observed data are imprecise. In other words, in practice, the obtained observation is often not a definite value, and may even show an approximate range. At this time, the traditional combination forecasting model cannot solve these problems. However, the uncertainty theory proposed by Liu [6] can solve this problem. The relation between certainty and uncertainty is symmetrical, and any random event is uncertain. We need to study these problems by means of uncertainty theory. Liu [7] founded the uncertainty theory and gradually improved it [6,8\u201310]. Uncertainty theory is a branch of mathematics concerned with the analysis of degree of belief. Its main theories include uncertain measure, uncertain variable, uncertain distribution, uncertain inverse operation and expected value. Uncertainty theory has become an important branch of axiomatic mathematics to deal with uncertainty problems in reality. It has been widely used in uncertain planning, uncertain statistics, comprehensive evaluation and production planning [11\u201313], and has achieved fruitful results, which has aroused great attention. In 2010, Liu [6] began his research on uncertainty statistics, which is a methodology for collecting and interpreting expert experience data through uncertainty theory. Uncertainty statistics mainly include uncertain regression equation, uncertain estimation and uncertain hypothesis testing. Based on the keen interest in uncertain regression equations, many uncertain regression models have been proposed by experts and scholars [14\u201318]. Yao and Liu [19] proposed the least squares estimation to solve the unknown parameters of the uncertain regression equation. Wang et al. [20\u201322] proposed two new uncertain linear regression models. Shi et al. [23] proposed total least squares estimation model based on uncertainty theory. Uncertainty statistics also have real applications; when COVID-19 was spreading rapidly in most countries around the world, Liu Z. [24] proposed an uncertain growth model for the cumulative number of COVID-19 infections in China. It is not easy to build a scientific forecasting model, because whether the forecasting model is scientific depends on the accuracy of the forecasting results on the one hand, and on the simplicity of the model itself on the other. However, these two aspects are contradictory: when the model is simple, the forecasting results are often not too accurate; when the forecasting is relatively accurate, the model is not too simple. On the basis of the previous research [3\u20135] and uncertainty theory, this paper puts forward two kinds of uncertain combination forecasting models, which are the unary uncertain linear combination forecasting model and the uncertain relative error combination forecasting model. In general, the newer the data information, the greater the impact of the given data on the model, but the historical data are also a factor affecting the accuracy of the model. According to the principle of minimum error, the unary uncertain linear combination forecasting model combines the piecewise linear regression of the data corresponding to different periods into a prediction model with higher accuracy. The uncertain relative error combination forecasting model is based on the least squares principle and relative error, combined with the uncertainty theory, which can better deal with the regression and forecasting of imprecision data. The two kinds of uncertain linear combination forecasting\nmodels can be used for both imprecise data and precise data, and the forecasting effect of the models is very good. In this paper, we propose the unary uncertain linear combination forecasting model and the uncertain relative error combination forecasting model. Both of these models can solve the regression equation of imprecise observation data better, and the forecasting effect is better. The main organizational structure is as follows: In Section 2, we propose the unary uncertain linear combination forecasting model. This model aims to establish several piecewise linear regression models according to the data of different periods, and combine the piecewise linear regression into an uncertain combination forecasting model. In Section 3, we propose the uncertain relative error combination forecasting model. This model is a new model, which combines relative error and uncertainty theory together and has a good forecasting effect. In the Section 4, the feasibility of the uncertain linear regression combination forecasting model is verified by numerical example. The forecasting effect of the model is good. Finally, we summarize the proposed model and point out the future research direction."
        },
        {
            "heading": "2. Uncertain Regression Model",
            "text": "Certainty and uncertainty are symmetrical, and precision and imprecision are also symmetrical. In order to resolve uncertainty problems such as imprecise data, Liu [7] founded uncertainty theory. The main content of uncertainty theory includes the basic theory of uncertainty variable, uncertainty measure and uncertainty distribution, as well as the calculation methods of uncertainty operational laws and expected value. If you are interested in uncertainty theory and uncertainty statistics, please study Reference [10]. In this section, we mainly introduce the uncertain least squares estimation method of the uncertain regression equation. Assume that (x1, x2, \u00b7 \u00b7 \u00b7 , xn) is an independent variables vector, and y is a dependent variable. If the functional relationship is between (x1, x2, \u00b7 \u00b7 \u00b7 , xn), then y can be expressed by a regression model\ny = f (x1, x2, \u00b7 \u00b7 \u00b7 , xn | \u03b2) + \u03b5, (1)\nwhere \u03b2 is an unknown vector of parameters, \u03b5 is a disturbance term and \u03b5 is an uncertain variable. If the regression equation fits well, its expected value E[\u03b5] should be 0 [10].\nIn particular, Liu [10] call\ny = \u03b20 + \u03b21x1 + \u03b22x2 + \u00b7 \u00b7 \u00b7+ \u03b2nxn + \u03b5 (2)\na linear regression model. Assume that we have a set of imprecisely observed data,\n(x\u0303i1, x\u0303i2, \u00b7 \u00b7 \u00b7 , x\u0303in, y\u0303i), i = 1, 2, \u00b7 \u00b7 \u00b7 , m (3)\nwhere x\u0303i1, x\u0303i2, \u00b7 \u00b7 \u00b7 , x\u0303in, y\u0303i are independent uncertain variables with regular uncertainty distributions \u03a6i1, \u03a6i2, \u00b7 \u00b7 \u00b7 , \u03a6in, \u03a8i, i = 1, 2, \u00b7 \u00b7 \u00b7 , m, respectively. Yao-Liu [19] proposed the least squares estimate of unknown parameter \u03b2 of linear regression model. The parameter \u03b2 is the solution of the following minimization problem\nmin \u03b2\nm\n\u2211 i=1\nE[(y\u0303i \u2212 f (x\u0303i1, x\u0303i2, \u00b7 \u00b7 \u00b7 , x\u0303in | \u03b2))2]. (4)\nIf the minimization solution is \u03b2\u2217, then the fitted regression equation is determined by y = f (x1, x2, \u00b7 \u00b7 \u00b7 , xn | \u03b2\u2217 ). Then, for each index i(i = 1, 2, \u00b7 \u00b7 \u00b7 , m), the term\n\u03b5\u0303i = y\u0303i \u2212 f (x\u0303i1, x\u0303i2, \u00b7 \u00b7 \u00b7 , x\u0303in | \u03b2\u2217) (5)\nis called the ith residual.\nLet the disturbance term \u03b5 is uncertain variable, its expected value and variance can be estimated as\ne\u0302 = 1 n\nm\n\u2211 i=1 E[\u03b5\u0303i], (6)\nand\n\u03c3\u03022 = 1 n\nm\n\u2211 i=1\nE[(\u03b5\u0303i \u2212 e\u0302)2], (7)\nwhere \u03b5\u0303i are the ith residual, i = 1, 2, \u00b7 \u00b7 \u00b7 , m, respectively [25]. Let (x1, x2, \u00b7 \u00b7 \u00b7 , xn) be a new independent variables vector; the forecast uncertain variable of dependent variable y\u0302 is\ny\u0302 = f (x1, x2, \u00b7 \u00b7 \u00b7 , xn | \u03b2\u2217) + \u03b5\u0302, \u03b5\u0302 \u223c N (e\u0302, \u03c3\u0302). (8)\nLio-Liu [25] suggested that the forecast value is defined as the expected value of the uncertain variable y\u0303, i.e.,\nu\u0302 = f (x1, x2, \u00b7 \u00b7 \u00b7 , xn | \u03b2\u2217) + e\u0302. (9)\nTaking \u03b1 (e.g., 95%) as the confidence level, the confidence interval of dependent variable y\u0303 is\nu\u0302\u00b1 \u03c3\u0302 \u221a\n3 \u03c0 ln 1 + \u03b1 1\u2212 \u03b1 . (10)"
        },
        {
            "heading": "3. Unary Uncertain Linear Regression Combination Forecasting Model",
            "text": "In this section, we derive the unary uncertain linear combination forecasting model, which is abbreviated as UULCFM. We all know that timely updated data have a greater effect on the forecasting model, so when establishing the forecasting model scientifically, we should fully consider the changes in time and conditions. The data information of different periods has different influences on the model and recent data information is obviously more valuable than long-term data information. The idea of UULCFM is to establish m regression models by discarding a certain amount of previous historical data according to the existing data, and then assemble m regression models into a forecasting model according to the principle of minimum error. Assume that (x\u0303i, y\u0303i) (i = 1, 2, \u00b7 \u00b7 \u00b7 , n) be a set of imprecise data, where x\u0303i, y\u0303i are independent uncertain variables with regular uncertainty distributions \u03a6i, \u03a8i(i = 1, 2, \u00b7 \u00b7 \u00b7 , n), respectively. We always assumed that there is a linear relationship between x\u0303i and y\u0303i (i = 1, 2, \u00b7 \u00b7 \u00b7 , n), and y can be expressed by an uncertain regression model y = \u03b1 + \u03b2x + \u03b5, where \u03b1, \u03b2 are unknown parameters, and \u03b5 is an uncertain disturbance term.\nThe main steps of the UULCFM are as follows.\nStep 1. For the original n sets of data, we obtained the following unary linear regression model using uncertain least squares estimation.\ny1 = \u03b11 + \u03b21x, (11)\nwhere \u03b11 and \u03b21 are unknown parameters. Step 2. Discarding the first N1 sets of data, we can obtain the following unary linear regres-\nsion model for the remaining n\u2212 N1 sets of data through least squares estimation.\ny2 = \u03b12 + \u03b22x. (12)\nwhere \u03b12 and \u03b22 are unknown parameters, N1 is positive integer and N1 < n. Step 3. Discarding the first N2 sets of data, we can obtain the following unary linear regres-\nsion model for the remaining n\u2212 N2 sets of data through least squares estimation.\ny3 = \u03b13 + \u03b23x. (13)\nwhere \u03b13 and \u03b23 are unknown parameters. Both N1, N2 are positive integers, and N1 < N2 < n.\nBy analogy, we can obtain the mth unary linear regression equation. Step m. Discarding the first Nm\u22121 sets of data, we can obtain the following unary linear\nregression model for the remaining n\u2212 Nm\u22121 sets of data through least squares estimation.\nym = \u03b1m + \u03b2mx. (14)\nwhere \u03b1m and \u03b2m are unknown parameters. Both N1, N2, \u00b7 \u00b7 \u00b7 , Nm\u22121 are positive integers, and N1 < N2 < \u00b7 \u00b7 \u00b7 < Nm\u22121 < n.\nIn this way, m unary linear regression models are obtained as follows,\nyi = \u03b1i + \u03b2ix, i = 1, 2, 3, \u00b7 \u00b7 \u00b7 , m. (15)\nwhere \u03b1i, \u03b2i are unknown parameters. Each regression equation of Equation (5) is fitted to the remaining n\u2212 Nm\u22121 sets of data, and the generated errors are, respectively,\n\u03b5ij = yij \u2212 y\u0303j, i = 1, 2, 3, \u00b7 \u00b7 \u00b7 , m, j = Nm, Nm+1, \u00b7 \u00b7 \u00b7 , n.\n(16)\nSince y\u0303i, i = 1, 2, \u00b7 \u00b7 \u00b7 , n is a set of imprecise data, Equation (6) is deformed into the following form according to the uncertain expected value formula [10].\n\u03b5ij = yij \u2212 E[y\u0303j] = yij \u2212 \u222b 1\n0 \u03a8\u22121j (\u03b1)d\u03b1, i = 1, 2, 3, \u00b7 \u00b7 \u00b7 , m, j = Nm, Nm+1, \u00b7 \u00b7 \u00b7 , n. (17)\nThe purpose of this paper is to find m numbers k1, k2, k3, \u00b7 \u00b7 \u00b7 , km that satisfy k1 + k2 + k3 + \u00b7 \u00b7 \u00b7+ km = 1. Then, we construct the composite model\ny = m\n\u2211 i=1 kiyi. (18)\nThis minimizes the sum of the squares R = n \u2211\nj=Nm \u03b5 j of error \u03b5ij = yij \u2212 E[y\u0303j],\ni = 1, 2, 3, \u00b7 \u00b7 \u00b7 , m, j = Nm, Nm+1, \u00b7 \u00b7 \u00b7 , n. This model is called the linear regression combinatorial model.\nWe know from the above derivation\n\u03b5 j = yj \u2212 E[y\u0303j] = m\n\u2211 i=1\nkiyij \u2212 m\n\u2211 i=1\nkiE[y\u0303j] = m\n\u2211 i=1\nki[yij \u2212 E[y\u0303j]] = m\n\u2211 i=1 ki\u03b5ij\n= [\u03b51j, \u03b52j, \u00b7 \u00b7 \u00b7 , \u03b5mj][k1, k2, k3, \u00b7 \u00b7 \u00b7 , km]T = [k1, k2, k3, \u00b7 \u00b7 \u00b7 , km][\u03b51j, \u03b52j, \u00b7 \u00b7 \u00b7 , \u03b5mj]T . (19)\nSo,\n\u03b52j = [k1, k2, k3, \u00b7 \u00b7 \u00b7 , km][\u03b51j, \u03b52j, \u00b7 \u00b7 \u00b7 , \u03b5mj]T [\u03b51j, \u03b52j, \u00b7 \u00b7 \u00b7 , \u03b5mj][k1, k2, k3, \u00b7 \u00b7 \u00b7 , km]T\n= [k1, k2, k3, \u00b7 \u00b7 \u00b7 , km]  \u03b521j \u03b51j\u03b52j \u00b7 \u00b7 \u00b7 \u03b51j\u03b5mj \u03b51j\u03b52j \u03b5 2 2j \u00b7 \u00b7 \u00b7 \u03b52j\u03b5mj\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u03b51j\u03b5mj \u03b52j\u03b5mj \u00b7 \u00b7 \u00b7 \u03b52mj\n[k1, k2, k3, \u00b7 \u00b7 \u00b7 , km]T . (20)\nTherefore, we obtain\nR = n\n\u2211 i=Nm \u03b52j = [k1, k2, k3, \u00b7 \u00b7 \u00b7 , km] n \u2211 i=Nm \u03b521j n \u2211 i=Nm \u03b51j\u03b52j \u00b7 \u00b7 \u00b7 n \u2211 i=Nm \u03b51j\u03b5mj n \u2211 i=Nm \u03b51j\u03b52j n \u2211 i=Nm \u03b522j \u00b7 \u00b7 \u00b7 n \u2211 i=Nm \u03b52j\u03b5mj\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 n \u2211\ni=Nm \u03b51j\u03b5mj\nn \u2211\ni=Nm \u03b52j\u03b5mj \u00b7 \u00b7 \u00b7\nn \u2211\ni=Nm \u03b52mj  [k1, k2, k3, \u00b7 \u00b7 \u00b7 , km]T .\n(21)\nDenoted as\nK = [k1, k2, k3, \u00b7 \u00b7 \u00b7 , km],\nE = \nn \u2211\ni=Nm \u03b521j\nn \u2211\ni=Nm \u03b51j\u03b52j \u00b7 \u00b7 \u00b7\nn \u2211\ni=Nm \u03b51j\u03b5mj\nn \u2211\ni=Nm \u03b51j\u03b52j\nn \u2211\ni=Nm \u03b522j \u00b7 \u00b7 \u00b7\nn \u2211\ni=Nm \u03b52j\u03b5mj\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 n \u2211\ni=Nm \u03b51j\u03b5mj\nn \u2211\ni=Nm \u03b52j\u03b5mj \u00b7 \u00b7 \u00b7\nn \u2211\ni=Nm \u03b52mj\n .\n(22)\nThere are R = K \u00b7 E \u00b7 KT . (23)\nAssuming that U = [1, 1, \u00b7 \u00b7 \u00b7 , 1]T . (24)\nSo, the linear regression combination model becomes the problem of finding the minimum value of R = K \u00b7 E \u00b7 KT under the constraint condition K \u00b7U = 1. We use the Lagrange multiplier method to solve the conditional extremum. We construct the Lagrange function as follows\nL = K \u00b7 E \u00b7 KT + \u03bb(KU \u2212 1). (25)\nThe Lagrange function L is a binary elementary function and the minimum point is the stagnation point of the function. If we take the first partial derivative of Lw.r.tK, then we obtain\n\u2202L \u2202K = 2E \u00b7 KT + \u03bbU = 0. (26)\nIf we solve the Equation (26), we get\nKT = \u22121 2 \u03bbE\u22121U. (27)\nAccording to constraint K \u00b7U = 1, we can solve Equation (27) and obtain\nKT = E\u22121U\nUTE\u22121U , \u03bb = \u22122 UTE\u22121U . (28)\nFor m numbers m , numbers k1, k2, k3, \u00b7 \u00b7 \u00b7 , km satisfy k1 + k2 + k3 + \u00b7 \u00b7 \u00b7+ km = 1. Thus, the linear regression combination model y = m \u2211\ni=1 kiyi was obtained.\nThe derivation process of the UULCFM involves the matrix inverse and matrix elementary transformation, which requires readers to have a certain matrix foundation and linear algebra foundation."
        },
        {
            "heading": "4. Uncertain Relative Error Linear Combination Forecasting Model",
            "text": "In this section, we derive the uncertain relative error linear combination forecasting model, which is abbreviated as UURELCFM. Suppose that we have a set of imprecise data X = (x1, x2, \u00b7 \u00b7 \u00b7 , xn)T . where x\u03031, x\u03032, \u00b7 \u00b7 \u00b7 , x\u0303n ,y\u0303 are independent uncertain variables with regular uncertainty distributions \u03a61, \u03a62, \u00b7 \u00b7 \u00b7 , \u03a6n, \u03a8, respectively. The basic principles of UURELCFM are as follows. The forecasting result of the ith (i = 1, 2, . . . , m) forecasting method is Xi = (x1i, x2i, \u00b7 \u00b7 \u00b7 , xni)T . The linear combination of the m forecasting result is\nY = (y1, y2, \u00b7 \u00b7 \u00b7 , yn)T = \u03c91X1 + \u03c92X2 + \u00b7 \u00b7 \u00b7+ \u03c9mXm. (29)\nThe relative error between the forecasting value and the original data can be defined as\nE = (e1, e2, \u00b7 \u00b7 \u00b7 , en)T . (30)\nAmong them,\nej = |yj \u2212 x\u0303j| |x\u0303j| =\n| m \u2211\ni=1 \u03c9ixji \u2212 x\u0303j|\n|x\u0303j| = |\nm\n\u2211 i=1 \u03c9i xji x\u0303j \u2212 1|, j = 1, 2, \u00b7 \u00b7 \u00b7 , n. (31)\nSince (x\u03031, x\u03032, \u00b7 \u00b7 \u00b7 , x\u0303n, y\u0303)T nleads toimprecise data, we have to solve Equation (31) by means of uncertain expectations [10].\nej = | m\n\u2211 i=1 \u03c9iE[ xji x\u0303j ]\u2212 1| = | m \u2211 i=1\n\u03c9ixji \u222b 1\n0 1 \u03a6\u22121j (1\u2212 \u03b1) d\u03b1\u2212 1|, j = 1, 2, \u00b7 \u00b7 \u00b7 , n. (32)\nThe uncertain relative error linear combination forecasting model I (URELCFM I) with the minimum sum of squares of relative errors is\nminQ = n\n\u2211 j=1 e2j , (33)\nand the constraint of the model is m\n\u2211 i=1 \u03c9i = 1. (34)\nDenoted as\nYi = (y1i, y2i, \u00b7 \u00b7 \u00b7 , yni)T = (E[ x1i x\u03031 ]\u2212 1, E[ x2i x\u03032 ]\u2212 1, \u00b7 \u00b7 \u00b7 , E[ xni x\u0303n ]\u2212 1)T\n= (x1i \u222b 1\n0 1 \u03a6\u221211 (1\u2212 \u03b1)\nd\u03b1\u2212 1, x2i \u222b 1\n0 1 \u03a6\u221212 (1\u2212 \u03b1) d\u03b1\u2212 1,\n\u00b7 \u00b7 \u00b7 , xni \u222b 1\n0 1 \u03a6\u22121n (1\u2212 \u03b1) d\u03b1\u2212 1)T ,\n(35)\nand R = [1, 1, \u00b7 \u00b7 \u00b7 , 1]T , W = [\u03c91, \u03c92, \u00b7 \u00b7 \u00b7 , \u03c9n]T ,\nY =  YT1 Y1 Y T 1 Y2 Y T 1 Y3 \u00b7 \u00b7 \u00b7 YT1 Ym YT2 Y1 Y T 2 Y2 Y T 2 Y3 \u00b7 \u00b7 \u00b7 YT2 Ym YT3 Y1 Y T 3 Y2 Y T 3 Y3 \u00b7 \u00b7 \u00b7 YT3 Ym\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 YTmY1 YTmY2 YTmY3 \u00b7 \u00b7 \u00b7 YTmYm\n. (36)\nThe sum of squares of relative errors is\nQ = n\n\u2211 j=1\ne2j = n\n\u2211 j=1\n( m\n\u2211 i=1 \u03c9iE[ xji x\u0303j ]\u2212 1)2 = n \u2211 j=1 ( m \u2211 i=1 \u03c9iE[ xji x\u0303j ]\u2212 m \u2211 i=1 \u03c9i) 2\n= n\n\u2211 j=1\n[ m\n\u2211 i=1 \u03c9i(E[ xji x\u0303j ]\u2212 1)]2 = n \u2211 j=1 [ m \u2211 i=1 \u03c9iyji]2 = n \u2211 j=1 [WT(yj1, yj2, \u00b7 \u00b7 \u00b7 , yjm)T ]2\n= n\n\u2211 j=1\nWT(yj1, yj2, \u00b7 \u00b7 \u00b7 , yjm)T(yj1, yj2, \u00b7 \u00b7 \u00b7 , yjm)W = WTYW.\n(37)\nEquation (33) is transformed into\nminQ = WTYW, (38)\nand the constraint is transformed into\nRTW = 1. (39)\nAccording to the Lagrange multiplier method, the optimal coefficient W\u2217 is\nW\u2217 = Y\u22121R\nRTY\u22121R . (40)\nThe solution of model I sometimes has a negative component, which does not achieve the expected effect of the linear combination forecasting model. In order to overcome the limitations of URELCFM I, we put forward an uncertain combination forecasting model with the minimum sum of squares of relative errors of non-negative weights, namely, the uncertain relative error linear combination forecasting model II (URELCFM II)\nminQ = n\n\u2211 j=1 e2j , (41)\nand the constraint of the model is\nm\n\u2211 i=1 \u03c9i = 1, \u03c9i \u2265 0, i = 1, 2, \u00b7 \u00b7 \u00b7 , m. (42)\nAccording to the derivation of URELCFM I, we can obtain\nminQ = WTYW, (43)\nand the constraint is transformed into\nRTW = 1, W \u2265 0. (44)\nURELCFM II belongs to quadratic convex programming and can be solved by the simplex algorithm of quadratic convex programming. This method needs to be solved by the linear programming method of finite number or can also be solved by MATLAB optimization toolbox.\nBoth URELCFM I and URELCFM II require that the sum of the weighting coefficients is 1. In fact, there is no need for this limitation. The weight can also be negative, and the goal is to minimize the sum of squares of the combined forecasting errors. Although it is controversial that the weight is negative, it is also common from a mathematical perspective; for example, multiple regression often has negative coefficients. By removing the limitation of the weighting coefficient, we can obtain the uncertain relative error linear combination forecasting model III (URELCFM III) with the minimum sum of squares of relative errors\nminQ = n\n\u2211 j=1 e2j . (45)\nDefine Zi = (z1i, z2i, \u00b7 \u00b7 \u00b7 , zni)T = (E[\nx1i x\u03031 ], E[ x2i x\u03032 ], \u00b7 \u00b7 \u00b7 , E[ xni x\u0303n ])T\n= (x1i \u222b 1\n0 1 \u03a6\u221211 (1\u2212 \u03b1)\nd\u03b1, x2i \u222b 1\n0 1 \u03a6\u221212 (1\u2212 \u03b1) d\u03b1,\n\u00b7 \u00b7 \u00b7 , xni \u222b 1\n0 1 \u03a6\u22121n (1\u2212 \u03b1) d\u03b1)T , i = 1, 2, \u00b7 \u00b7 \u00b7 , m.\n(46)\nThe sum of squares of relative errors is\nQ = n\n\u2211 j=1\ne2j = n\n\u2211 j=1\n( m\n\u2211 i=1 \u03c9iE[ xji x\u0303j ]\u2212 1)2 = n \u2211 j=1 ( m \u2211 i=1 \u03c9izji \u2212 1)2. (47)\nQ in Equation (47) is an elementary function. In order to solve the minimum value of Q, we take the partial derivative of \u03c9i(i = 1, 2, \u00b7 \u00b7 \u00b7 , m and equal to 0, respectively, to obtain the following equations\n\u03c91\nn\n\u2211 i=1\nZ2i1 + \u03c92 n\n\u2211 i=1\nZi1Zi2 + \u03c93 n\n\u2211 i=1\nZi1Zi3 + \u00b7 \u00b7 \u00b7+ \u03c9m n\n\u2211 i=1\nZi1Zim = n\n\u2211 i=1 Zi1,\n\u03c91\nn\n\u2211 i=1\nZi2Zi1 + \u03c92 n\n\u2211 i=1\nZ2i2 + \u03c93 n\n\u2211 i=1\nZi2Zi3 + \u00b7 \u00b7 \u00b7+ \u03c9m n\n\u2211 i=1\nZi2Zim = n\n\u2211 i=1 Zi2,\n\u03c91\nn\n\u2211 i=1\nZi3Zi1 + \u03c92 n\n\u2211 i=1\nZi3Zi2 + \u03c93 n\n\u2211 i=1\nZ2i3 + \u00b7 \u00b7 \u00b7+ \u03c9m n\n\u2211 i=1\nZi3Zim = n\n\u2211 i=1 Zi3,\n\u00b7 \u00b7 \u00b7\n\u03c91\nn\n\u2211 i=1\nZimZi1 + \u03c92 n\n\u2211 i=1\nZimZi2 + \u03c93 n\n\u2211 i=1\nZimZi3 + \u00b7 \u00b7 \u00b7+ \u03c9m n\n\u2211 i=1\nZ2im = n\n\u2211 i=1 Zim.\n(48)\nDenoted as\nZ =  ZT1 Z1 Z T 1 Y2 Z T 1 Z3 \u00b7 \u00b7 \u00b7 ZT1 Zm ZT2 Z1 Z T 2 Z2 Z T 2 Z3 \u00b7 \u00b7 \u00b7 ZT2 Zm ZT3 Z1 Z T 3 Z2 Z T 3 Z3 \u00b7 \u00b7 \u00b7 ZT3 Zm\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 ZTMZ1 Z T mZ2 ZTmZ3 \u00b7 \u00b7 \u00b7 ZTmZm\n,\nM =  ZT1 R ZT2 R ZT3 R \u00b7 \u00b7 \u00b7\nZTmR\n. (49)\nWe express the above equations by matrix equations, and obtain\nZW = M. (50)\nThe matrix Z is invertible and the solution W is\nW = Z\u22121M. (51)\nURELCFM I has more constraints than URELCFM III, and the accuracy of URELCFM I is lower than that of URELCFM III, while URELCFM II has more constraints than URELCFM I. Therefore, URELCFM III has the highest accuracy, that is, the sum of relative error squares QIII \u2264 QI \u2264 QII."
        },
        {
            "heading": "5. Numerical Example",
            "text": "To verify the feasibility and effectiveness of the model proposed in this paper, we provide a numerical example of imprecise data. Moreover, we followed the numerical analysis method for the disturbance term in Reference [25], calculated the expected values and variance of the disturbance term, and forecasting and solved the confidence interval. The numerical analysis results show that the model proposed in this paper can lead to better forecasting data. Assuming that (x\u0303i, y\u0303i), i = 1, 2, \u00b7 \u00b7 \u00b7 , 8 are imprecise data provided in Table 1, where x\u0303i, y\u0303i, i = 1, 2, \u00b7 \u00b7 \u00b7 , 8 are independent linear uncertain variables with regular uncertainty distributions \u03a6i and \u03a8i, i = 1, 2, \u00b7 \u00b7 \u00b7 , 8, respectively.\nWe carried out linear regression using the uncertain uncertain slope mean method (USMM) [20] and uncertain equation deformation method (UEDM) [21] respectively, and then solved the linear regression equations according to the combination forecasting model proposed in this paper. The results are shown in Table 2.\nIt can be seen from Table 2 that there are some differences in the coefficients of the linear regression equation of USMM and UEDM. The coefficients of the linear regression equation of the model proposed in this paper are almost the same, the stability of the model is strong, and the difference in fitting effect is small, which can be ignored. The estimated expected values and estimated variances of the each model disturbance term are shown in Table 3. As can be seen from Table 3, the estimated expected values of the disturbance terms of the URELCFM I, URELCFM II and URELCFM III are all 0.0000, and the variance is relatively small, indicating that the three models have a better fitting effect and better forecast effect, and URELCFM III has the best performance.\nWe forecast the data according to the URELCFM III and obtained the confidence interval. We assumed that x\u0303 \u223c L (17, 19) is a new imprecise form of data, and we take the confidence level to be \u03b1 = 95%. According to References [25], the forecast value and confidence interval were obtained as shown in Table 4.\nFrom the perspective of numerical examples, all four models proposed in this paper are feasible. From the perspective of data analysis and comparison with existing models, the prediction effect of the four models proposed in this paper is better."
        },
        {
            "heading": "6. Conclusions",
            "text": "Traditional forecasting models all require data to be precise. In fact, statistics can be imprecise. For example, after the college entrance examination, we invited a teacher to estimate the score of a certain candidate. If the teacher believes that the candidate\u2019s score is bound to exceed 500, we would obtain an expert\u2019s experience data (500, 0), if the teacher thinks the candidate\u2019s score is less than 520 is 0.3, we obtain an expert\u2019s experience data (520, 0.3), if the teacher thinks the candidate\u2019s score is less than 550 is 0.6, we obtain an expert\u2019s experience data (550, 0.6), if the teacher thinks the candidate\u2019s score is less than 580 is 0.8, we obtain an expert experience data (580, 0.8), and the teacher believes that the candidate will score no higher than 600, we obtain an expert experience data (600, 1). This gives us five pieces of expert experience data (500, 0), (520, 0.3), (550, 0.6), (580, 0.8), (600, 1), all of which are imprecise data. Based on traditional combination forecasting methods and uncertainty theory, this paper proposes two kinds of uncertain combination forecasting models. The forecasting models proposed in this paper are all aimed at imprecise data, and they rely on uncertainty theory when solving. Univariate uncertain linear combination forecasting model is a relatively basic linear model. It establishes several piecewise linear regression models based on data in different periods and combines them into an uncertain combination forecasting model with high accuracy. The uncertain relative error combination forecasting model is based on the principle of minimizing the sum of squares of relative errors, setting weight restrictions, and obtaining three kinds of uncertain relative error combination forecasting models with good forecasting results. The four models proposed in this paper are all feasible, and the forecasting effect of the models proposed in this paper is better than the existing models obtained through data analysis. The numerical example in this paper is a univariate linear forecasting problem, and the model solution and data analysis are not too complicated. The derivation and calculation of multivariable uncertain linear combination forecasting model are relatively complex, and can only be realized with the help of computer programs or MATLAB programming.\nAuthor Contributions: Conceptualization, Y.N.; methodology, S.W.; validation, C.W.; data curation, L.W.; writing\u2014original draft preparation, H.S.; writing\u2014review and editing, H.S. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received no external funding.\nConflicts of Interest: The authors declare no conflict of interest."
        }
    ],
    "title": "Relative Error Linear Combination Forecasting Model Based on Uncertainty Theory",
    "year": 2023
}