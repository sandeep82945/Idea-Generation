{
    "abstractText": "Affective computing became a prominent research area for modeling empathic Human-Computer Interaction (HCI) to design interfaces that react or respond to their user\u2019s emotions. However, several challenges remain in emotion recognition, adaptive interface intervention, real-world evaluations, or ethical implications before affective and empathic interfaces will be commonplace. In this workshop, we will discuss the current challenges of empathic and affective computing within the HCI community, including sensing, design of emotional adaptivity, and real-world evaluation. By bringing the community together, we envision ideating and creating new research directions in this field that will lead to a new generation of affective and empathic interfaces. This workshop aims to bring together researchers interested in these topics through open discussions, presentations, and an interactive prototyping session.",
    "authors": [
        {
            "affiliations": [],
            "name": "Esther Bosch"
        },
        {
            "affiliations": [],
            "name": "David Bethge"
        },
        {
            "affiliations": [],
            "name": "Thomas Kosch"
        }
    ],
    "id": "SP:07eef248590f318aa4cb7aba0a2c42cb67444303",
    "references": [
        {
            "authors": [
                "Ashwin Belle",
                "Soo-Yeon Ji",
                "Sardar Ansari",
                "Roya Hakimzadeh",
                "Kevin Ward",
                "Kayvan Najarian"
            ],
            "title": "Frustration detection with electrocardiograph signal using wavelet transform",
            "venue": "In 2010 International Conference on Biosciences",
            "year": 2010
        },
        {
            "authors": [
                "David Bethge",
                "Philipp Hallgarten",
                "Tobias Grosse-Puppendahl",
                "Mohamed Kari",
                "Lewis L. Chuang",
                "Ozan \u00d6zdenizci",
                "Albrecht Schmidt"
            ],
            "title": "EEG2Vec: Learning Affective EEG Representations via Variational Autoencoders",
            "year": 2022
        },
        {
            "authors": [
                "David Bethge",
                "Philipp Hallgarten",
                "Tobias Grosse-Puppendahl",
                "Mohamed Kari",
                "Ralf Mikut",
                "Albrecht Schmidt",
                "Ozan \u00d6zdenizci"
            ],
            "title": "Domain-Invariant Representation Learning from EEG with Private Encoders",
            "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
            "year": 2022
        },
        {
            "authors": [
                "David Bethge",
                "Thomas Kosch",
                "Tobias Grosse-Puppendahl",
                "Lewis L. Chuang",
                "Mohamed Kari",
                "Alexander Jagaciak",
                "Albrecht Schmidt"
            ],
            "title": "VEmotion: Using Driving Context for Indirect Emotion Prediction in Real-Time",
            "venue": "In The 34th Annual ACM Symposium on User Interface Software and Technology (Virtual Event,",
            "year": 2021
        },
        {
            "authors": [
                "Anubhav Bhatti",
                "Behnam Behinaein",
                "Paul Hungler",
                "Ali Etemad"
            ],
            "title": "AttX: Attentive Cross-Connections for Fusion of Wearable Signals in Emotion Recognition",
            "year": 2022
        },
        {
            "authors": [
                "Michael Braun",
                "Florian Weber",
                "Florian Alt"
            ],
            "title": "Affective Automotive User Interfaces\u2013Reviewing the State of Driver Affect Research and Emotion Regulation in the Car",
            "venue": "ACM Computing Surveys (CSUR) 54,",
            "year": 2021
        },
        {
            "authors": [
                "Joseph F Grafsgaard",
                "Joseph BWiggins",
                "Kristy Elizabeth Boyer",
                "Eric NWiebe",
                "James C Lester"
            ],
            "title": "Automatically recognizing facial indicators of frustration: 2https://sites.google.com/view/empathic-technologies 3https://arxiv.org a learning-centric analysis",
            "venue": "In 2013 humaine association conference on affective computing and intelligent interaction",
            "year": 2013
        },
        {
            "authors": [
                "Mariam Hassib",
                "Max Pfeiffer",
                "Stefan Schneegass",
                "Michael Rohs",
                "Florian Alt"
            ],
            "title": "Emotion Actuator: Embodied Emotional Feedback through Electroencephalography and Electrical Muscle Stimulation",
            "venue": "In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado,",
            "year": 2017
        },
        {
            "authors": [
                "Mariam Hassib",
                "Stefan Schneegass",
                "Philipp Eiglsperger",
                "Niels Henze",
                "Albrecht Schmidt",
                "Florian Alt"
            ],
            "title": "EngageMeter: A System for Implicit Audience Engagement Sensing Using Electroencephalography",
            "venue": "In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado,",
            "year": 2017
        },
        {
            "authors": [
                "Klas Ihme",
                "Anirudh Unni",
                "Meng Zhang",
                "Jochem W Rieger",
                "Meike Jipp"
            ],
            "title": "Recognizing frustration of drivers from face video recordings and brain activation measurements with functional near-infrared spectroscopy",
            "venue": "Frontiers in human neuroscience",
            "year": 2018
        },
        {
            "authors": [
                "Thomas Kosch",
                "Mariam Hassib",
                "Robin Reutter",
                "Florian Alt"
            ],
            "title": "Emotions on the Go: Mobile Emotion Assessment in Real-Time Using Facial Expressions",
            "venue": "Association for Computing Machinery,",
            "year": 2020
        },
        {
            "authors": [
                "Thomas Kosch",
                "Robin Welsch",
                "Lewis Chuang",
                "Albrecht Schmidt"
            ],
            "title": "The Placebo Effect of Artificial Intelligence in Human-Computer Interaction",
            "venue": "ACM Trans. Comput.-Hum. Interact. (mar",
            "year": 2022
        },
        {
            "authors": [
                "Sandra Kr\u00fcger",
                "Esther Bosch",
                "Klas Ihme",
                "Michael Oehl"
            ],
            "title": "In-Vehicle Frustration Mitigation via Voice-User Interfaces\u2013A Simulator Study",
            "venue": "In International Conference on Human-Computer Interaction",
            "year": 2021
        },
        {
            "authors": [
                "Am\u00e9lie Oksenberg Rorty"
            ],
            "title": "Explaining emotions",
            "venue": "The journal of philosophy 75,",
            "year": 1978
        },
        {
            "authors": [
                "B. Schilit",
                "N. Adams",
                "R. Want"
            ],
            "title": "Context-Aware Computing Applications",
            "venue": "First Workshop on Mobile Computing Systems and Applications",
            "year": 1994
        },
        {
            "authors": [
                "Jianhua Tao",
                "Tieniu Tan"
            ],
            "title": "Affective computing: A review",
            "venue": "In International Conference on Affective computing and intelligent interaction. Springer,",
            "year": 2005
        },
        {
            "authors": [
                "Marjolein D Van Der Zwaag",
                "Chris Dijksterhuis",
                "Dick DeWaard",
                "Ben LJMMulder",
                "Joyce HDM Westerink",
                "Karel A Brookhuis"
            ],
            "title": "The influence of music on mood and performance while driving",
            "venue": "Ergonomics 55,",
            "year": 2012
        },
        {
            "authors": [
                "Sebastian Zepf",
                "Javier Hernandez",
                "Alexander Schmitt",
                "Wolfgang Minker",
                "Rosalind W. Picard"
            ],
            "title": "Driver Emotion Recognition for Intelligent Vehicles: A Survey",
            "venue": "ACM Comput. Surv",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "CCS CONCEPTS \u2022Human-centered computing\u2192Ubiquitous andmobile computing; Empirical studies in HCI ; \u2022 Computing methodologies \u2192 Machine learning.\nKEYWORDS Emotions, Affect, Sensing, Adaptive Interfaces, Communication\nACM Reference Format: Esther Bosch, David Bethge, Marie Klosterkamp, and Thomas Kosch. 2022. Empathic Technologies Shaping Innovative Interaction: Future Directions of Affective Computing. In Adjunct Proceedings of the 2022 Nordic HumanComputer Interaction Conference (NordiCHI Adjunct \u201922), October 8\u201312, 2022, Aarhus, Denmark. ACM, New York, NY, USA, 3 pages. https://doi.org/10. 1145/3547522.3547703\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). NordiCHI Adjunct \u201922, October 8\u201312, 2022, Aarhus, Denmark \u00a9 2022 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-9448-2/22/10. https://doi.org/10.1145/3547522.3547703"
        },
        {
            "heading": "1 INTRODUCTION AND BACKGROUND",
            "text": "Emotions are a communication channel to convey information between humans [14] implicitly. Empathic and affective communication occurs voluntarily and unnoticed through different channels, including spoken words, facial expressions, behavioral patterns, or physiological responses [17]. Such cues can be recognized by other persons, who in turn can react to develop empathy and react to emotions accordingly [15]. In contrast to humans, however, we interact more daily with computing devices. Although these devices are excellent in estimating the user\u2019s context [16], emotion-sensing and empathic applications remain challenging in the scientific community.\nConsequently, the research fields of affective and empathic computing aim to understand and develop emotion-aware systems, for example, in assessing driver emotions to regulate them [4, 6, 19]. Other use cases include the communication of emotional engagement [9] or communication of emotions between partners [8]. Yet, ubiquitous affective and empathic sensing poses a major research challenge. Previous research successfully recognized user emotions using multimodal data collections through cameras, physiological and cortical data [1, 3, 4, 7, 10, 11, 19]. Another stream of research looks at the affect recognition as a general purpose learning scheme, where machine learning algorithms are employed to encode affective input into low-memory latent representation that can be used in multiple purposes and shared easiliy across systems [2, 5]. Although current research results look promising [13, 18], the successful deployment of empathic and affective faces several challenges: (1) sensing affects and emotions are highly persondependent, hence susceptible to individual noise. (2) Next, empathic and affective data must be interpreted on-the-fly to provide user interventions. However, it is unclear how interface interventions must be designed to communicate affective states with the user. (3) Most state-of-the-art research evaluates their sensing techniques in controlled lab settings, neglecting challenging real-world parameters. (4) Finally, emotion-aware systems can induce placebo effects for perceived adaptiveness, letting users perceive a novel system as beneficial [12].\nThe workshop \u201cEmpathic Technologies Shaping Innovative Interaction\u201d lays the foundation for a research field concerning integrating emotion-sensing capabilities in devices. The workshop invites submissions concerning novel emotion-sensing techniques,\nthe presentation of affect-adaptive interfaces, and the demonstration of proof-of-concept prototypes in real-world environments. We connect recent research revolving in this field with the workshop to start, grow, and foster a community around empathic interfaces in human-computer interaction research. This includes presenting, demonstrating, and discussing existing sensing techniques and demonstrators. Consequently, the workshop encourages the presentation and demonstrations of empathic interfaces."
        },
        {
            "heading": "2 WORKSHOP STRUCTURE",
            "text": "We plan a one-day workshop for approximately 20 participants and the following schedule:\n(1) Workshop introduction (15 minutes) (2) Ice breaker activity (15 minutes) (3) Keynote (60 minutes) (4) Coffee break (30 minutes) (5) Pitches Part I (60 minutes) (6) Lunch break (90 minutes) (7) Prototyping and Demo Session (90 minutes) (8) Pitches Part II (60 minutes) (9) Coffee Break (30 minutes) (10) Closing and Feedback Session (15 minutes)"
        },
        {
            "heading": "3 ORGANIZER BIOGRAPHIES",
            "text": "Esther Bosch is pursuing a Ph.D. degree in Human Factors at the German Aerospace Center (DLR) in Braunschweig, Germany. Her particular interest lies in (automated) recognition of a traveler\u2019s state to make innovative mobility solutions attractive to use.\nDavid Bethge is currently a PhD student at the School of Computer Science at Ludwig-Maximilian University Munich. He is currently a visiting researcher at Meta Reality Labs, previously he worked at Porsche as a Machine Learning Engineer. His research interests lie in affective computing and contextual machine learning leveraging ubiquitous sensing technologies. In addition, his expertise in rapid prototyping, in-car empathic car interfaces, signal processing, and machine learning will benefit the workshop..\nMarie Klosterkamp is working on her Ph.D. in the field of mobility research at the University of Kassel. She has a background in Psychology and Human Factors. She is experienced in the use of driving simulators and psychophysiological measurements.\nThomas Kosch is a professor in the Human-Centered Computing Group at Utrecht University and Humboldt University of Berlin. His research focuses on implicit AI-driven physiological interfaces and emotion prediction. In addition, he is experienced in designing user studies, quantitative and qualitativemethods, machine learning, and prototyping. He successfully led research projects within scientific and industrial councils in this context."
        },
        {
            "heading": "4 WEBSITE",
            "text": "We will provide a website describing the scope of the workshop1. The website includes a workshop description, objectives, and possible submission topics. It also hosts the call for participation, a\n1https://sites.google.com/view/empathic-technologies\nlink to the submission system, the workshop schedule, further organizational information, and information about the workshop organizers. Accepted papers will be made publicly available on the website before the conference to maximize the preparation time for the workshop and foster discussions."
        },
        {
            "heading": "5 PRE-WORKSHOP PLANS",
            "text": "We will distribute information and materials on the workshop website. Information includes the intention, motivation, and anticipated outcomes of the workshop. Furthermore, the website serves to advertise and acquire potential workshop participants. Finally, workshop participants will regularly receive updates via email and the website."
        },
        {
            "heading": "6 HYBRID PARTICIPATION",
            "text": "We plan to organize the workshop in hybrid mode. We offer fullvirtual participation, for example, via Zoom, to enable participants to engage in this workshop without attending in person. We plan to stream the in-person workshop via a camera in the virtual Zoom call. Text communication will be organized in a dedicated Slack workspace."
        },
        {
            "heading": "7 ASYNCHRONOUS AND HYBRID ENGAGEMENT",
            "text": "We will offer the presenter slides, papers, video recordings, and results on the website. Participants and interested persons can view the materials after the workshop. Additionally, we will provide a Slack workspace where participants can discuss their research, group work, and feedback about past projects. The Slack workspace will feature one channel per talk and groupwork project, with slides, papers, and results linked to the channels. Additionally, participants can ask questions for each talk on their respective Slack channels."
        },
        {
            "heading": "8 POST-WORKSHOP PLANS",
            "text": "After the workshop, we encourage researchers to rework their research statements and position papers based on the discussions and feedback from the workshop. We will support researchers in submitting their final statements and papers to either arXiv or preprints on our website. Additionally, we will write a workshop position paper based on the participant contributions published on arXiv. Recorded pitches and the keynote will be uploaded on YouTube after seeking the presenter\u2019s permission. Based on the group work and moderated discussion, the organizers plan to distill critical aspects and the workshop\u2019s outcomes into a position paper."
        },
        {
            "heading": "9 CALL FOR PARTICIPATION",
            "text": "We plan to invite key researchers and labs in the affective community via mail forwarding. Furthermore, we advertise this workshop on social media (e.g., Twitter). We will distribute the following call for paper:\nEmotions are a communication channel to convey information between humans implicitly. Empathic and affective communication occurs voluntarily and unnoticed through different channels, including spoken words, facial expressions, behavioral patterns, or physiological responses. Such cues can be recognized by other\npersons, who can react to develop empathy and react to emotions accordingly. In contrast to humans, however, we interact more daily with computing devices. Although these devices are excellent for estimating the user\u2019s context, emotion-sensing, and empathic applications remain challenging in the scientific community. The workshop \u201cEmpathic Technologies Shaping Innovative Interaction\u201d lays the foundation for a research field concerning integrating emotion-sensing capabilities in devices. The workshop invites submissions concerning novel emotion-sensing techniques, the presentation of affect-adaptive interfaces, and the demonstration of proof-of-concept prototypes in real-world environments. We connect recent research revolving in this field with the workshop to start, grow, and foster a community around empathic interfaces in human-computer interaction research. This includes presenting, demonstrating, and discussing existing sensing techniques and demonstrators. Consequently, the workshop encourages the presentation and demonstrations of empathic interfaces.\nSubmissions should follow the ACM two-column format with a maximum page length of three, excluding references. Information about submitting papers can be found on the workshop website2. The talks and presentations will be streamed for virtually attending participants. Participants will be selected based on their contribution to the workshop. We support and encourage authors to make their research available on arXiv3 after the workshop. At least one author of each accepted submission must attend the workshop. All participants must register for the workshop. We solicit the following submissions: position papers, research statements, and interactive demonstrations. As interactive demonstrations, we consider demonstrating an empathic or affective interface that workshop participants can try out during the workshop. The authors of interactive demonstrations are invited to present a prototype in the interactive workshop session."
        }
    ],
    "title": "Empathic Technologies Shaping Innovative Interaction: Future Directions of Affective Computing",
    "year": 2022
}