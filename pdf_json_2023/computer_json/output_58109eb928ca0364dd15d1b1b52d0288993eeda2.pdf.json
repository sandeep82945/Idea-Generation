{
    "abstractText": "The growing ubiquity of machine learning (ML) has led it to enter various areas of computer science, including black-box optimization (BBO). Recent research is particularly concerned with Bayesian optimization (BO). BO-based algorithms are popular in the ML community, as they are used for hyperparameter optimization and more generally for algorithm configuration. However, their efficiency decreases as the dimensionality of the problem and the budget of evaluations increase. Meanwhile, derivative-free optimization methods have evolved independently in the optimization community. Therefore, we urge to understand whether cross-fertilization is possible between the two communities, ML and BBO, i.e., whether algorithms that are heavily used in ML also work well in BBO and vice versa. Comparative experiments often involve rather small benchmarks and show visible problems in the experimental setup, such as poor initialization of baselines, overfitting due to problem-specific setting of hyperparameters, and low statistical significance. With this paper, we update and extend a comparative study presented by Hutter et al. in 2013. We compare BBO tools for ML with more classical heuristics, first on the well-known BBOB benchmark suite from the COCO environment and then on Direct Policy Search for OpenAI Gym, a reinforcement learning benchmark. Our results confirm that BO-based optimizers perform well on both benchmarks when budgets are limited, albeit with a higher computational cost, while they are often outperformed by algorithms from other families when the evaluation budget becomes larger. We also show that some algorithms from the BBO community perform surprisingly well on ML tasks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Elena Raponi"
        },
        {
            "affiliations": [],
            "name": "Nathana\u00ebl Carraz Rakotonirina"
        },
        {
            "affiliations": [],
            "name": "J\u00e9r\u00e9my Rapin"
        },
        {
            "affiliations": [],
            "name": "Carola Doerr"
        },
        {
            "affiliations": [],
            "name": "Olivier Teytaud"
        }
    ],
    "id": "SP:0b3e9a7a6b1c7b9ff08d670b73693cabd8d446c9",
    "references": [
        {
            "authors": [
                "I. Bajaj",
                "A. Arora",
                "M.M.F. Hasan"
            ],
            "title": "Black-Box Optimization: Methods and Applications",
            "venue": "Black Box Optimization, Machine Learning, and No-Free Lunch Theorems, ser. Springer Optimization and Its Applications, P. M. Pardalos, V. Rasskazova, and M. N. Vrahatis, Eds. Cham: Springer International Publishing, 2021, pp. 35\u201365.",
            "year": 2021
        },
        {
            "authors": [
                "I.L. Markov"
            ],
            "title": "The false dawn: Reevaluating Google\u2019s reinforcement learning for chip macro placement",
            "venue": "CoRR, vol. abs/2306.09633,",
            "year": 2023
        },
        {
            "authors": [
                "N. Hansen",
                "A. Auger",
                "R. Ros",
                "O. Mersmann",
                "T. Tu\u0161ar",
                "D. Brockhoff"
            ],
            "title": "COCO: A platform for comparing continuous optimizers in a blackbox setting",
            "venue": "Optimization Methods and Software, vol. 36, no. 1, pp. 114\u2013144, Jan. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "K. Tang",
                "X. Li",
                "P.N. Suganthan",
                "Z. Yang",
                "T. Weise"
            ],
            "title": "Benchmark Functions for the CEC\u20192010 Special Session and Competition on Large- Scale Global Optimization",
            "venue": "University of Science and Technology of China, Tech. Rep., 2010.",
            "year": 2010
        },
        {
            "authors": [
                "J. Rapin",
                "O. Teytaud"
            ],
            "title": "Nevergrad - A gradient-free optimization platform",
            "venue": "https://GitHub.com/FacebookResearch/Nevergrad, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "C. Doerr",
                "H. Wang",
                "F. Ye",
                "S. van Rijn",
                "T. B\u00e4ck"
            ],
            "title": "IOHprofiler: A Benchmarking and Profiling Tool for Iterative Optimization Heuristics",
            "venue": "arXiv e-prints:1810.05281, Oct. 2018. [Online]. Available: https://arxiv.org/abs/1810.05281",
            "year": 1810
        },
        {
            "authors": [
                "J. Rapin",
                "M. Gallagher",
                "P. Kerschke",
                "M. Preuss",
                "O. Teytaud"
            ],
            "title": "Exploring the MLDA benchmark on the nevergrad platform",
            "venue": "Proceedings of the Genetic and Evolutionary Computation Conference Companion, ser. GECCO \u201919. New York, NY, USA: Association for Computing Machinery, Jul. 2019, pp. 1888\u20131896.",
            "year": 2019
        },
        {
            "authors": [
                "B. Bischl",
                "P. Kerschke",
                "L. Kotthoff",
                "M. Lindauer",
                "Y. Malitsky",
                "A. Fr\u00e9chette",
                "H.H. Hoos",
                "F. Hutter",
                "K. Leyton-Brown",
                "K. Tierney",
                "J. Vanschoren"
            ],
            "title": "ASlib: A benchmark library for algorithm selection",
            "venue": "Artif. Intell., vol. 237, pp. 41\u201358, 2016. [Online]. Available: https://doi.org/10.1016/j.artint.2016.04.003 10",
            "year": 2016
        },
        {
            "authors": [
                "F. Hutter",
                "M. L\u00f3pez-Ib\u00e1\u00f1ez",
                "C. Fawcett",
                "M. Lindauer",
                "H.H. Hoos",
                "K. Leyton-Brown",
                "T. St\u00fctzle"
            ],
            "title": "AClib: A benchmark library for algorithm configuration",
            "venue": "Proc. of Learning and Intelligent Optimization (LION\u201914), ser. LNCS, vol. 8426. Springer, 2014, pp. 36\u2013 40. [Online]. Available: https://doi.org/10.1007/978-3-319-09584-4 4",
            "year": 2014
        },
        {
            "authors": [
                "Y. Mehta",
                "C. White",
                "A. Zela",
                "A. Krishnakumar",
                "G. Zabergja",
                "S. Moradian",
                "M. Safari",
                "K. Yu",
                "F. Hutter"
            ],
            "title": "NAS-benchsuite: NAS evaluation is (now) surprisingly easy",
            "venue": "The Tenth International Conference on Learning Representations, ICLR 2022. OpenReview.net, 2022. [Online]. Available: https://openreview.net/ forum?id=0DLwqQLmqV",
            "year": 2022
        },
        {
            "authors": [
                "J A. Zela",
                "Siems",
                "F. Hutter"
            ],
            "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search",
            "venue": "Proc. of 8th International Conference on Learning Representations (ICLR\u201920). OpenReview.net, 2020. [Online]. Available: https://openreview.net/ forum?id=SJx9ngStPH",
            "year": 2020
        },
        {
            "authors": [
                "L. Bliek",
                "A. Guijt",
                "R. Karlsson",
                "S. Verwer",
                "M. de Weerdt"
            ],
            "title": "Expobench: Benchmarking surrogate-based optimisation algorithms on expensive black-box functions",
            "venue": "CoRR, vol. abs/2106.04618, 2021. [Online]. Available: https://arxiv.org/abs/2106.04618",
            "year": 2021
        },
        {
            "authors": [
                "T. Bartz-Beielstein",
                "C. Doerr",
                "J. Bossek",
                "S. Chandrasekaran",
                "T. Eftimov",
                "A. Fischbach",
                "P. Kerschke",
                "M. L\u00f3pez-Ib\u00e1\u00f1ez",
                "K.M. Malan",
                "J.H. Moore",
                "B. Naujoks",
                "P. Orzechowski",
                "V. Volz",
                "M. Wagner",
                "T. Weise"
            ],
            "title": "Benchmarking in optimization: Best practice and open issues",
            "venue": "CoRR, vol. abs/2007.03488, 2020. [Online]. Available: https://arxiv.org/abs/2007.03488",
            "year": 2007
        },
        {
            "authors": [
                "D.R. Jones",
                "M. Schonlau",
                "W.J. Welch"
            ],
            "title": "Efficient Global Optimization of Expensive Black-Box Functions",
            "venue": "Journal of Global Optimization, vol. 13, no. 4, pp. 455\u2013492, Dec. 1998.",
            "year": 1998
        },
        {
            "authors": [
                "A. Nayebi",
                "A. Munteanu",
                "M. Poloczek"
            ],
            "title": "A Framework for Bayesian Optimization in Embedded Subspaces",
            "venue": "Proceedings of the 36th International Conference on Machine Learning. PMLR, May 2019, pp. 4752\u20134761.",
            "year": 2019
        },
        {
            "authors": [
                "Z. Wang",
                "F. Hutter",
                "M. Zoghi",
                "D. Matheson",
                "N. de Freitas"
            ],
            "title": "Bayesian Optimization in a Billion Dimensions via Random Embeddings",
            "venue": "arXiv:1301.1942 [cs, stat], Jan. 2016.",
            "year": 1942
        },
        {
            "authors": [
                "Z. Wang",
                "C. Gehring",
                "P. Kohli",
                "S. Jegelka"
            ],
            "title": "Batched Large-scale Bayesian Optimization in High-dimensional Spaces",
            "venue": "arXiv:1706.01445 [cs, math, stat], May 2018.",
            "year": 2018
        },
        {
            "authors": [
                "L. Wang",
                "R. Fonseca",
                "Y. Tian"
            ],
            "title": "Learning search space partition for black-box optimization using monte carlo tree search",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. [Online]. Available: https://proceedings.neurips.cc/paper/2020/ hash/e2ce14e81dba66dbff9cbc35ecfdb704-Abstract.html",
            "year": 2020
        },
        {
            "authors": [
                "R. Coulom"
            ],
            "title": "Efficient selectivity and backup operators in Monte-Carlo tree search",
            "venue": "Proceedings of the 5th International Conference on Computers and Games, ser. CG\u201906. Berlin, Heidelberg: Springer- Verlag, 2007, pp. 72\u201383.",
            "year": 2007
        },
        {
            "authors": [
                "R. Munos"
            ],
            "title": "Optimistic optimization of a deterministic function without the knowledge of its smoothness",
            "venue": "Proceedings of the 24th International Conference on Neural Information Processing Systems, ser. NIPS\u201911. Red Hook, NY, USA: Curran Associates Inc., 2011, p. 783\u2013791.",
            "year": 2011
        },
        {
            "authors": [
                "R. Turner",
                "D. Eriksson",
                "M. McCourt",
                "J. Kiili",
                "E. Laaksonen",
                "Z. Xu",
                "I. Guyon"
            ],
            "title": "Bayesian optimization is superior to random search for machine learning hyperparameter tuning: Analysis of the black-box optimization challenge 2020",
            "venue": "NeurIPS 2020 Competition and Demonstration Track, vol. 133. PMLR, 2020, pp. 3\u201326. [Online]. Available: http://proceedings.mlr.press/v133/turner21a.html",
            "year": 2020
        },
        {
            "authors": [
                "M.J. Powell"
            ],
            "title": "A Direct Search Optimization Method That Models the Objective and Constraint Functions by Linear Interpolation",
            "year": 1994
        },
        {
            "authors": [
                "C. Cartis",
                "J. Fiala",
                "B. Marteau",
                "L. Roberts"
            ],
            "title": "Improving the flexibility and robustness of model-based derivative-free optimization solvers",
            "venue": "2018.",
            "year": 2018
        },
        {
            "authors": [
                "M.J. Powell"
            ],
            "title": "An efficient method for finding the minimum of a function of several variables without calculating derivatives",
            "venue": "The Computer Journal, vol. 7, no. 2, pp. 155\u2013162, 1964.",
            "year": 1964
        },
        {
            "authors": [
                "H.-G. Beyer"
            ],
            "title": "The Theory of Evolution Strategies, ser",
            "venue": "Natural Computing Series. Springer, Heideberg,",
            "year": 2001
        },
        {
            "authors": [
                "N. Hansen",
                "A. Ostermeier"
            ],
            "title": "Completely derandomized selfadaptation in evolution strategies",
            "venue": "Evolutionary Computation, vol. 11, no. 1, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "A. Auger",
                "M. Schoenauer",
                "O. Teytaud"
            ],
            "title": "Local and global order 3/2 convergence of a surrogate evolutionary algorithm",
            "venue": "Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation, ser. GECCO \u201905. New York, NY, USA: Association for Computing Machinery, Jun. 2005, pp. 857\u2013864.",
            "year": 2005
        },
        {
            "authors": [
                "K. Khowaja",
                "M. Shcherbatyy",
                "W.K. H\u00e4rdle"
            ],
            "title": "Surrogate models for optimization of dynamical systems",
            "venue": "2021.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Luksic",
                "J. Tanevski",
                "S. Dzeroski",
                "L. Todorovski"
            ],
            "title": "Meta-model framework for surrogate-based parameter estimation in dynamical systems",
            "venue": "IEEE Access, vol. 7, pp. 181 829\u2013181 841, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "F. Hutter",
                "H. Hoos",
                "K. Leyton-Brown"
            ],
            "title": "An evaluation of sequential model-based optimization for expensive blackbox functions",
            "venue": "Proceedings of the 15th Annual Conference Companion on Genetic and Evolutionary Computation, ser. GECCO \u201913 Companion. New York, NY, USA: Association for Computing Machinery, 2013, p. 1209\u20131216. [Online]. Available: https://doi.org/10.1145/2464576.2501592",
            "year": 2013
        },
        {
            "authors": [
                "G. Brockman",
                "V. Cheung",
                "L. Pettersson",
                "J. Schneider",
                "J. Schulman",
                "J. Tang",
                "W. Zaremba"
            ],
            "title": "OpenAI Gym",
            "venue": "(arXiv, 2016) Available: https://arxiv.org/pdf/1606.01540",
            "year": 2016
        },
        {
            "authors": [
                "J. Mockus"
            ],
            "title": "Bayesian Approach to Global Optimization: Theory and Applications",
            "year": 2012
        },
        {
            "authors": [
                "T.J. Santner",
                "B.J. Williams",
                "W.I. Notz"
            ],
            "title": "The Design and Analysis of Computer Experiments, ser",
            "year": 2003
        },
        {
            "authors": [
                "C.E. Rasmussen",
                "C.K.I. Williams"
            ],
            "title": "Gaussian Processes for Machine Learning, ser. Adaptive Computation and Machine Learning",
            "year": 2006
        },
        {
            "authors": [
                "A.I.J. Forrester",
                "A. S\u00f3bester",
                "A.J. Keane"
            ],
            "title": "Engineering Design via Surrogate Modelling - A Practical Guide",
            "year": 2008
        },
        {
            "authors": [
                "T.L. Lai",
                "H. Robbins"
            ],
            "title": "Asymptotically efficient adaptive allocation rules",
            "venue": "Advances in applied mathematics, vol. 6, no. 1, pp. 4\u201322, 1985.",
            "year": 1985
        },
        {
            "authors": [
                "N. Srinivas",
                "A. Krause",
                "S.M. Kakade",
                "M. Seeger"
            ],
            "title": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design",
            "venue": "IEEE Transactions on Information Theory, vol. 58, no. 5, pp. 3250\u20133265, May 2012.",
            "year": 2012
        },
        {
            "authors": [
                "D. Silver",
                "A. Huang",
                "C.J. Maddison",
                "A. Guez",
                "L. Sifre",
                "G. van den Driessche",
                "J. Schrittwieser",
                "I. Antonoglou",
                "V. Panneershelvam",
                "M. Lanctot",
                "S. Dieleman",
                "D. Grewe",
                "J. Nham",
                "N. Kalchbrenner",
                "I. Sutskever",
                "T. Lillicrap",
                "M. Leach",
                "K. Kavukcuoglu",
                "T. Graepel",
                "D. Hassabis"
            ],
            "title": "Mastering the game of Go with deep neural networks and tree search",
            "venue": "Nature, vol. 529, no. 7587, pp. 484\u2013489, jan 2016.",
            "year": 2016
        },
        {
            "authors": [
                "D. Silver",
                "T. Hubert",
                "J. Schrittwieser",
                "I. Antonoglou",
                "M. Lai",
                "A. Guez",
                "M. Lanctot",
                "L. Sifre",
                "D. Kumaran",
                "T. Graepel",
                "T.P. Lillicrap",
                "K. Simonyan",
                "D. Hassabis"
            ],
            "title": "Mastering chess and shogi by self-play with a general reinforcement learning algorithm",
            "venue": "CoRR, vol. abs/1712.01815, 2017. [Online]. Available: http://arxiv.org/abs/1712. 01815",
            "year": 1815
        },
        {
            "authors": [
                "R. Munos"
            ],
            "title": "From Bandits to Monte-Carlo Tree Search: The Optimistic Principle Applied to Optimization and Planning",
            "venue": "Tech. Rep., 2014.",
            "year": 2014
        },
        {
            "authors": [
                "J. Snoek",
                "H. Larochelle",
                "R.P. Adams"
            ],
            "title": "Practical Bayesian optimization of machine learning algorithms",
            "venue": "Advances in Neural Information Processing Systems (NIPS), 2012, pp. 2951\u20132959.",
            "year": 2012
        },
        {
            "authors": [
                "F. Nogueira"
            ],
            "title": "Bayesian Optimization: Open source constrained global optimization tool for Python",
            "venue": "2014. [Online]. Available: https://github.com/fmfn/BayesianOptimization",
            "year": 2014
        },
        {
            "authors": [
                "D. Eriksson",
                "M. Pearce",
                "J. Gardner",
                "R.D. Turner",
                "M. Poloczek"
            ],
            "title": "Scalable global optimization via local Bayesian optimization",
            "venue": "Advances in Neural Information Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9- Buc, E. Fox, and R. Garnett, Eds., vol. 32. Curran Associates, Inc., 2019. [Online]. Available: https://proceedings.neurips.cc/paper/ 2019/file/6c990b7aca7bc7058f5e98ea909e924b-Paper.pdf",
            "year": 2019
        },
        {
            "authors": [
                "FacebookResearch"
            ],
            "title": "Ax - adaptive experimentation",
            "venue": "ax.dev, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "F. Hutter",
                "H.H. Hoos",
                "K. Leyton-Brown"
            ],
            "title": "Sequential modelbased optimization for general algorithm configuration.",
            "venue": "LION, ser. Lecture Notes in Computer Science,",
            "year": 2011
        },
        {
            "authors": [
                "J. Bergstra",
                "B. Komer",
                "C. Eliasmith",
                "D. Yamins",
                "D.D. Cox"
            ],
            "title": "Hyperopt: a python library for model selection and hyperparameter optimization",
            "venue": "Computational Science & Discovery, vol. 8, no. 1, p. 014008, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "T. Akiba",
                "S. Sano",
                "T. Yanase",
                "T. Ohta",
                "M. Koyama"
            ],
            "title": "Optuna: A nextgeneration hyperparameter optimization framework",
            "venue": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD 2019. ACM, 2019, pp. 2623\u20132631. [Online]. Available: https://doi.org/10.1145/3292500.3330701 11",
            "year": 2019
        },
        {
            "authors": [
                "J. Kennedy",
                "R. Eberhart"
            ],
            "title": "Particle Swarm Optimization",
            "venue": "Proceedings of IEEE International Conference on Neural Networks. IEEE, 1995, pp. 1942\u20131948. [Online]. Available: doi:10.1109/ICNN.1995.488968",
            "year": 1995
        },
        {
            "authors": [
                "L. Meunier",
                "H. Rakotoarison",
                "P. Wong",
                "B. Rozi\u00e8re",
                "J. Rapin",
                "O. Teytaud",
                "A. Moreau",
                "C. Doerr"
            ],
            "title": "Black-box optimization revisited: Improving algorithm selection wizards through massive benchmarking",
            "venue": "IEEE Trans. Evol. Comput., vol. 26, no. 3, pp. 490\u2013500, 2022. [Online]. Available: https://doi.org/10.1109/TEVC.2021.3108185",
            "year": 2022
        },
        {
            "authors": [
                "N. Hansen",
                "A. Auger",
                "S. Finck",
                "R. Ros"
            ],
            "title": "Real-parameter black-box optimization benchmarking 2009: Experimental setup",
            "venue": "INRIA, France, Tech. Rep. RR-6828, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "M. Thoma"
            ],
            "title": "RL-agents",
            "venue": "https://martin-thoma.com/rl-agents/."
        },
        {
            "authors": [
                "M. Thoma"
            ],
            "title": "Q-Learning",
            "venue": "https://martin-thoma.com/q-learning/."
        },
        {
            "authors": [
                "A. Manukyan",
                "M.A. Olivares-Mendez",
                "M. Geist",
                "H. Voos"
            ],
            "title": "Deep reinforcement learning-based continuous control for multicopter systems",
            "venue": "2019 6th International Conference on Control, Decision and Information Technologies (CoDIT), 2019, pp. 1876\u20131881.",
            "year": 2019
        },
        {
            "authors": [
                "W.C. Lewis-II",
                "M. Moll",
                "L.E. Kavraki"
            ],
            "title": "How much do unstated problem constraints limit deep robotic reinforcement learning?",
            "venue": "CoRR, vol. abs/1909.09282,",
            "year": 2019
        },
        {
            "authors": [
                "R. Henry",
                "D. Ernst"
            ],
            "title": "Gym-ANM: Reinforcement learning environments for active network management tasks in electricity distribution systems",
            "venue": "2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Zubow",
                "S. R\u00f6sler",
                "P. Gaw\u0142owicz",
                "F. Dressler"
            ],
            "title": "GrGym: When GNU Radio Goes to (AI) Gym",
            "venue": "Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications, ser. HotMobile \u201921. New York, NY, USA: Association for Computing Machinery, 2021, p. 8\u201314. [Online]. Available: https://doi.org/10.1145/3446382.3448358",
            "year": 2021
        },
        {
            "authors": [
                "S. Green",
                "C.M. Vineyard",
                "\u00c7.K. Ko\u00e7"
            ],
            "title": "Impacts of Mathematical Optimizations on Reinforcement Learning Policy Performance",
            "venue": "2018 International Joint Conference on Neural Networks (IJCNN), Jul. 2018, pp. 1\u20138.",
            "year": 2018
        },
        {
            "authors": [
                "S. Sinha",
                "H. Bharadhwaj",
                "A. Srinivas",
                "A. Garg"
            ],
            "title": "D2rl: Deep dense architectures in reinforcement learning",
            "venue": "2020.",
            "year": 2020
        },
        {
            "authors": [
                "F. Rezazadeh",
                "H. Chergui",
                "L. Alonso",
                "C. Verikoukis"
            ],
            "title": "Continuous multi-objective zero-touch network slicing via twin delayed ddpg and openai gym",
            "venue": "2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Rapin",
                "O. Teytaud"
            ],
            "title": "Dashboard of results for Nevergrad platform",
            "venue": "https://dl.fbaipublicfiles.com/nevergrad/allxps/list.html, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "N. Hansen",
                "A. Auger",
                "D. Brockhoff",
                "T. Tusar"
            ],
            "title": "Anytime performance assessment in blackbox optimization benchmarking",
            "venue": "IEEE Trans. Evol. Comput., vol. 26, no. 6, pp. 1293\u20131305, 2022. [Online]. Available: https://doi.org/10.1109/TEVC.2022.3210897",
            "year": 2022
        },
        {
            "authors": [
                "E. Raponi",
                "N.R. Carraz",
                "J. Rapin",
                "C. Doerr",
                "O. Teytaud"
            ],
            "title": "Comparison of Low-budget Black-box Optimization Algorithms on BBOB",
            "venue": "Zenodo, Sep. 2023. [Online]. Available: https://doi.org/10.5281/zenodo. 8375417",
            "year": 2023
        },
        {
            "authors": [
                "H. Wang",
                "D. Vermetten",
                "F. Ye",
                "C. Doerr",
                "T. B\u00e4ck"
            ],
            "title": "IOHanalyzer: Detailed Performance Analyses for Iterative Optimization Heuristics",
            "venue": "ACM Transactions on Evolutionary Learning and Optimization, vol. 2, no. 3, pp. 1-\u201329, 2022. [Online]. Available: https://doi.org/10.1145/ 3510426",
            "year": 2022
        },
        {
            "authors": [
                "S. Rahnamayan",
                "H.R. Tizhoosh",
                "M.M.A. Salama"
            ],
            "title": "Quasioppositional differential evolution",
            "venue": "2007 IEEE Congress on Evolutionary Computation, Sep. 2007, pp. 2229\u20132236.",
            "year": 2007
        },
        {
            "authors": [
                "L. Meunier",
                "C. Doerr",
                "J. Rapin",
                "O. Teytaud"
            ],
            "title": "Variance reduction for better sampling in continuous domains",
            "venue": "Parallel Problem Solving from Nature - PPSN XVI - 16th International Conference, PPSN 2020, Leiden, The Netherlands, September 5-9, 2020, Proceedings, Part I, ser. Lecture Notes in Computer Science, vol. 12269. Springer, 2020, pp. 154\u2013168.",
            "year": 2020
        },
        {
            "authors": [
                "M. Cauwet",
                "C. Couprie",
                "J. Dehos",
                "P. Luc",
                "J. Rapin",
                "M. Rivi\u00e8re",
                "F. Teytaud",
                "O. Teytaud",
                "N. Usunier"
            ],
            "title": "Fully parallel hyperparameter search: Reshaped space-filling",
            "venue": "Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, vol. 119. PMLR, 2020, pp. 1338\u20131348. [Online]. Available: http://proceedings.mlr.press/v119/cauwet20a.html",
            "year": 2020
        },
        {
            "authors": [
                "M. L\u00f3pez-Ib\u00e1\u00f1ez",
                "J. Branke",
                "L. Paquete"
            ],
            "title": "Reproducibility in evolutionary computation",
            "venue": "ACM Trans. Evol. Learn. Optim., vol. 1, no. 4, pp. 14:1\u201314:21, 2021. [Online]. Available: https: //doi.org/10.1145/3466624",
            "year": 2021
        },
        {
            "authors": [
                "J.H. Holland"
            ],
            "title": "Adaptation in Natural and Artificial Systems",
            "venue": "University of Michigan Press, 1975.",
            "year": 1975
        },
        {
            "authors": [
                "V. Khalidov",
                "M. Oquab",
                "J. Rapin",
                "O. Teytaud"
            ],
            "title": "Consistent population control: generate plenty of points, but with a bit of resampling",
            "venue": "Proceedings of the 15th ACM/SIGEVO Conference on Foundations of Genetic Algorithms, FOGA 2019, 116\u2013123, Potsdam, Germany, August 27-29, 2019. Available: https://doi.org/10.1145/3299904.3340312",
            "year": 2019
        },
        {
            "authors": [
                "R. Storn",
                "K. Price"
            ],
            "title": "Differential Evolution \u2013 A Simple and Efficient Heuristic for global Optimization over Continuous Spaces",
            "venue": "Journal of Global Optimization, vol. 11, pp. 341-\u2013359. 1997. https://doi.org/10. 1023/A:1008202821328",
            "year": 1997
        },
        {
            "authors": [
                "M.A. Schumer",
                "K. Steiglitz"
            ],
            "title": "Adaptive Step Size Random Search",
            "venue": "IEEE Trans. Automat., vol. AC-13, no. 3, pp. 270\u2013276, 1968.",
            "year": 1968
        }
    ],
    "sections": [
        {
            "text": "With this paper, we update and extend a comparative study presented by Hutter et al. in 2013. We compare BBO tools for ML with more classical heuristics, first on the well-known BBOB benchmark suite from the COCO environment and then on Direct Policy Search for OpenAI Gym, a reinforcement learning benchmark. Our results confirm that BO-based optimizers perform well on both benchmarks when budgets are limited, albeit with a higher computational cost, while they are often outperformed by algorithms from other families when the evaluation budget becomes larger. We also show that some algorithms from the BBO community perform surprisingly well on ML tasks.\nIndex Terms\u2014Benchmarking, Black-box optimization, BBOB, OpenAI Gym, Bayesian Optimization, Reinforcement Learning.\nI. INTRODUCTION\nBlack-Box Optimization (BBO) is an affirmed and rapidly growing field of optimization and a topic of critical importance in many application areas including complex systems engineering, energy and environment, materials design, drug discovery, chemical process synthesis, and computational biology [1]. As in other classical optimization contexts, BBO assumes that we are facing an objective function f for which we aim to provide a solution x with f(x) as good as possible\nE. Raponi (the corresponding author) is with LIACS, Leiden University, Leiden, The Netherlands (e-mail: e.raponi@liacs.leidenuniv.nl). At the time of writing this article, she was initially affiliated with Meta AI Research in Paris, France, and later with the Technical University of Munich in Munich, Germany, and LIP6, CNRS, Sorbonne Universite\u0301 in Paris, France. N. C. Rakotonirina is with Universitat Pompeu Fabra, Barcelona, Spain (email: nathanael.rakotonirina@upf.edu). At the time of writing this article, he was affiliated with LIMA, Universite\u0301 d\u2019Antananarivo, Madagascar. J. Rapin and O. Teytaud are with Meta AI Research, Paris, France (e-mail: jrapin, oteytaud@fb.com). C. Doerr is with LIP6, CNRS, Sorbonne Universite\u0301, Paris, France (e-mail: carola.doerr@lip6.fr).\nusing as little computational effort as possible. The key distinguishing property of BBO is that the algorithms learn about the problem instance f only by querying the quality f(x) of possible solution candidates x. This may be because we indeed lack an explicit representation of f (e.g., if simulations or experiments are required for assessing the quality of a possible solution) or when we lack efficient approaches to make use of the instance information (e.g., many real-world scheduling and routing problems are solved with heuristic approaches). Simplifying the complexity measurement, in BBO we typically only account for the number of function evaluations, and hence aim for identifying high-quality solutions x using as few function evaluations as possible.\nBecause of its high practical relevance, people with many different backgrounds are drawn into BBO, leading to a multitude of approaches in the area, ranging from simple heuristics such as local search to local/global modeling approaches. To understand the strengths and weaknesses of these different methods, fair performance comparisons are needed. Several platforms and benchmark suites (i.e., collections of benchmark problems) address this empirical comparison. Some examples are the Black-Box Optimization Benchmarking (BBOB) collection of the COCO environment [3], Large-Scale Global Optimization (LSGO) [4], Nevergrad [5], Pseudo-Boolean Optimization (PBO) [6], and Machine Learning and Data Analysis (MLDA) [7]. Apart from these more general benchmarking suites, there are also problem collections for evaluating and comparing algorithms for specific BBO tasks such as algorithm configuration and selection [8], [9], neural architecture search [10], [11], and expensive global optimization [12]; see [13, Section 3] for a more exhaustive summary.\nAn approach commonly used for expensive optimization problems (for which the available number of function evaluations can be very small) uses surrogates to approximate the problem instance f , with the idea that the approximation f\u0302 can be used to locate interesting solution candidates without requiring evaluations of the true problem f . Recently, Machine Learning (ML) has gone down this road and proposed several tools for BBO along these lines. In particular, a large field of research is Bayesian Optimization (BO), which is based on the Efficient Global Optimization (EGO) algorithm [14]. Despite its success, BO is stated to be limited to less than 15 parameters [15], [16] and a few thousand evaluations [17] according to the literature. To overcome this issue, recent research started to explore space partitioning and local modeling. In fact, learning a classifier that locates the samples on a promising\nar X\niv :2\n31 0.\n00 07\n7v 3\n[ cs\n.L G\n] 2\nJ an\n2 02\n4\n2 subregion of the domain with high probability might be more effective than learning a regressor on the whole domain. Among other partitioning strategies, the Latent Action Monte Carlo Tree Search (LA-MCTS) [18] recursively learns space partition in a hierarchical manner using Monte Carlo Tree Search (MCTS) [19]. Therefore, in addition to BO, MCTS has also been adapted from control and games to BBO [18], [20]. However, both the BO and MCTS tools for BBO have rarely been compared to existing BBO methods in a systematic and satisfactory manner. For example, the comparisons in the LA-MCTS paper [18] depend heavily on poor initialization of competitors, and the baselines used in the paper are not made available in the provided code, while the comparisons in [21] consider only the simple (1+1) sampling method and not the more sophisticated (and often better performing) BBO methods provided by the Nevergrad platform, although they refer to the comparison as \u2018Nevergrad\u2019. However, we note some efforts to make neutral and comprehensive comparisons. Extensive comparisons in Nevergrad [5] tend to favor more classical methods such as tools from mathematical programming like Cobyla [22] and others [23], [24] or evolution strategies [25] like CMA-ES [26], possibly equipped with surrogate models [27]\u2013[29]. Hutter et al. [30] ran SMAC-BBOB, a wellknown BO framework, on the BBOB benchmark suite and got positive results for BO when the budget of admissible function evaluations is fairly small. However, their investigation on expensive black-box functions only assesses SMAC against CMA-ES, yielding a rather limited benchmarking study.\nOverall, there is widespread utilization of black-box optimization algorithms in the ML field, yet there exists a deficiency in conducting comprehensive comparisons between the algorithms favored in ML domains and those favored by evolutionary computation researchers. Recent papers [2] raised doubts on the reproducibility of some results in the ML community. In this work, we update and extend the comparison made in [30] by adding several state-of-the-art solvers and by comparing not only on the BBOB benchmark suite but also \u2013 as it is closer to ML \u2013 on direct policy search for OpenAI Gym problems [31]. We evaluate the performance of various BBO algorithms, considering solvers commonly associated with the ML community as well as more classical heuristics, and testing over a range of budgets that allow us to draw fair and unbiased conclusions."
        },
        {
            "heading": "II. BLACK-BOX OPTIMIZATION ALGORITHMS",
            "text": "We briefly summarize the algorithms included in our comparison, along with a brief description of two main classes of interest, BO and LA-MCTS."
        },
        {
            "heading": "A. Bayesian Optimization",
            "text": "BO [14], [32] is a sequential design strategy targeting global optimization of black-box functions that do not assume any functional forms. It is particularly advantageous for problems where the objective function is difficult to evaluate, is a black box with some known structure, relies upon less than 20 dimensions, and where no information about sensitivity and derivatives is available. Since the objective function does not\nhave an explicit mathematical formulation, BO treats it as a random function and places a prior over it. A Kriging model, also known as Gaussian Process Regression (GPR), can be used as a prior probability distribution over functions in BO.\nBO starts with sampling an initial Design of Experiments (DoE) of size n0: X = [x(1),x(2), . . . ,x(n0)]\u22a4, where the sample i is denoted as x(i) = (x(i)1 , ..., x (i) D ) \u2208 X \u2282 RD [33]. The corresponding objective function values are denoted as y = (f(x(1)), f(x(2)), . . . , f(x(n0)))\u22a4. Conventionally, a centered Gaussian process prior is assumed on the objective function: f \u223c gp(0,K(\u00b7, \u00b7)), where K : X \u00d7 X \u2192 R is a positive definite function \u2013 also known as kernel function \u2013 which computes the autocovariance of the process.\nOften, a Gaussian likelihood is taken, leading to a conjugate posterior process [34], i.e., f | y \u223c gp(f\u0302(\u00b7),K \u2032(\u00b7, \u00b7)), where f\u0302 and K \u2032 are the posterior mean and covariance function, respectively.\nOn an unknown point x, f\u0302(x) yields the maximum a posteriori estimate of f(x) whereas s\u03022(x) := K \u2032(x,x) quantifies the uncertainty of this estimation. The posterior process is, again, a GPR. Based on the posterior process, promising points are identified via the so-called infill-criterion, i.e., by optimizing an acquisition function that balances f\u0302 with s\u03022 (exploitation vs. exploration). A variety of infillcriteria has been proposed in the literature, e.g., Probability of Improvement [32], [35], Expected Improvement [35], and the Upper Confidence Bound [36], [37]. When a new candidate point is selected by the infill criterion, it is evaluated and added to the BO data set, which is used to update the GPR posterior. This process is repeated until a stopping condition is met, i.e., a good enough result is located or the computational budget is exhausted."
        },
        {
            "heading": "B. Monte Carlo Tree Search",
            "text": "Monte Carlo Tree Search (MCTS) [19] is a solver that migrated from trees of bandits for games and control, including alpha-zero [38], [39], to applications in BBO [18], [40]. Its evolved version, LA-MCTS [18], progressively learns and generalizes promising regions in the problem space by recursively partitioning so that solvers like BO can access these regions to improve their performance. At any iteration t of the algorithm, a training dataset Dt = (X,Y) of all the points evaluated so far is available. A tree node A represents a subregion of the search space \u2126A. Therefore, Dt \u2229 \u2126A is the set of all the samples falling in the subregion \u2126A. MCTS uses the Monte Carlo simulation to accumulate value estimates that lead to highly rewarding trajectories in the search tree. In other words, MCTS pays more attention to promising nodes (i.e., subregions of the search space), in order to avoid the need to brute force all possibilities. This is done by using an Upper Confidence Bound (UCB) policy. More specifically, each node has an associated UCB value and, during selection, the child node with the highest UCB value is considered. The statistics used to compute the UCB are (1) nA, which is the number of samples in Dt \u2229\u2126A, and (2) the node value vA := ( \u2211 xi\u2208Dt \u2229\u2126Af(xi))/nA.\nTherefore, in LA-MCTS, which is the MCTS-based optimizer that we include in the comparisons of this study,\n3 promising regions are found by recursively partitioning the search space based on latent actions. In one iteration, LAMCTS starts building the tree by partitioning and then selects a region based on UCB. Finally, sampling is performed in the selected region using BO. In this way, BO avoids overexploring the search space, and its performance improves, especially for high-dimensional problems."
        },
        {
            "heading": "C. Selection of BO-based Algorithms",
            "text": "From the large collection of existing BO-based solvers, we have selected the following ones for our empirical comparison:\n\u2022 BO: the Bayesian Optimization algorithm [41] implemented in Nevergrad. The python class is a wrapper over the bayes opt package [42]. \u2022 LA-MCTS [18]: as described above, LA-MTCS is an MCTS-based derivative-free meta-solver that recursively learns space partition in a hierarchical manner. Sampling is then performed in the selected region using BO. \u2022 Turbo [43]: a trust-region-inspired algorithm using Thompson sampling rather than the optimization of an acquisition function to find new candidate solutions in each subregion. Turbo20 denotes the multi-trust-regions counterpart of Turbo. \u2022 AX [44]: a modular BO framework that uses BoTorch primitives for optimization over continuous spaces. It automates the selection of optimization routines, reducing the amount of fine-tuning required. \u2022 SMAC [45]: a sequential model-based algorithm for algorithm configuration to optimize the parameters of arbitrary algorithms. It scales well to high dimensions and is particularly suitable for hyperparameter optimization of ML algorithms. The main core consists of BO. SMAC2 refers to SMAC-HPO, i.e., SMAC with hyperparameter optimization. \u2022 HyperOpt [46]: library for serial and parallel hyperparameter optimization, designed to accommodate BO algorithms based on Gaussian processes and regression trees. We use the version based on Parzen estimates. \u2022 Optuna [47]: automatic hyperparameter optimization software framework which uses state-of-the-art algorithms for sampling hyperparameters and pruning unpromising trials. By default, Optuna implements a BO algorithm (Tree-structured Parzen Estimator)."
        },
        {
            "heading": "D. Classical Black-box Optimization Algorithms",
            "text": "As baselines commonly used in the broader BBO context we consider CMA, which stands for CMA-ES, a well-known evolution strategy [26], Cobyla, a tool from mathematical programming [22], particle swarm optimization (PSO [48]), and NGOpt from Nevergrad [5], a wizard that combines many classical algorithms in various ways [49]. In the use cases considered in this work (sequential, low-dimensional, noisefree problems), NGOpt mainly uses CMA, Cobyla, and (1+1)- type sampling equipped with metamodels.\nWe also include DefaultCMA [26], a version of CMA without the BBOB-specific initialization used for the experiments of CMA on BBOB [50]. We do this to show that\nad hoc initialization of CMA-ES does not lead to significant improvement over DefaultCMA."
        },
        {
            "heading": "III. BENCHMARK PROBLEMS",
            "text": "Extensive comparisons have already been proposed in Nevergrad [49], focusing on reproducibility, real-world, and different problem sizes. We propose here additional experiments in the well-known BBOB framework [50], chosen for its simplicity/canonicity, and for OpenAI Gym1, commonly used in the reinforcement learning (RL) environment [51]\u2013[59].\nBBOB: The BBOB collection contains 24 functions, with known difficulty (e.g., non-separability, ill-conditioning, different levels of multimodality, adequate or weak global structure, etc.). Although all functions are defined and can be evaluated over RD, the default search domain is [\u22125, 5]D; that is, in contrast to Nevergrad\u2019s experiments in [5], [60], the BBOB suite has a focus on bounded domains.\nBBOB offers a possibility to randomize both the position of the optimal solution (that is, test functions are randomly shifted in the domain) and the function value of the optimum (test functions are randomly shifted in the co-domain). To reduce bias with respect to problem encoding, we run the algorithms on 15 randomly chosen instances per test function and dimension. We consider six different dimensions (2, 3, 5, 10, 20, and 40).\nAs suggested in [30], we focus on a relatively small budget of 10D or 100D function evaluations (the default setting for BBOB experiments is 1000D). When a method crashes, we rerun it with the remaining budget.\nFor the BBOB experiments, our key performance measure is the empirical cumulative distribution function (ECDF) of the runtimes needed to reach the optimal objective value with a given precision \u2206t, i.e., the runtime depends on a given target function value (ft = fopt +\u2206t) and is computed across all runs of an optimizer on a function, as the total number of function evaluations before reaching ft divided by the number of trials that actually reached ft. Informally, the ECDF shows the proportion of problems solved within a given budget, with the budget indicated on the x-axis.\nOpenAI Gym with Direct Policy Search: Firstly, we work on a multi-deterministic Open AI Gym with tiny neural nets. Indeed, we analyze a small version (small number of neurons, low budget) to fit the low-budget context of the present work. Multi-deterministic here means that for a given algorithm, a different seed is drawn at random for each repetition, and this list of seeds is used for all algorithms. There are different seeds so that we avoid overfitting, and the list of seeds is the same over the different algorithms so that we have statistical pairing. This means that parameters are not tuned based on specific landscapes (e.g., bounded/unbounded domains, prescribed optimal regions, and multimodality of the objective function). This is somewhat analogous to random perturbation of the optimum in classical BBO benchmarks in the sense that the objective function is deterministic but drawn randomly.\n1https://www.gymlibrary.dev/\n4 Within the gym library, we select a few environments to compare algorithms based on (1) average loss (i.e. average negated reward) and (2) average winning rates (i.e., the frequencies at which one method outperforms another): MountainCar-v0 (D = 12), Pendulum-v0 (D = 15), GuessingGame-v0 (D = 24), HotterColer-v0 (D = 24), CartPole-v0 (D = 28). CartPole-v1 (D = 28), NChainv0 (D = 40), and MountainCarContinuous-v0 (D = 8). We chose these problems with D < 50 because they are sufficiently challenging and are not too hard in our context of tiny networks and minimal budget, i.e., not all algorithms perform equally. Here we use a neural factor (i.e., the scaling coefficient used in the benchmarking suite to choose the size of neural networks) of 1. The dimension, i.e., the total number of weights, is a consequence of the number of neurons, which in turn is based on the scaling factor (the number of neurons per hidden layer is the neural factor multiplied by the input dimension).\nIn a second set of experiments we include problems with dimensions D \u2264 264 for larger networks defined by setting the neural factor to 3, which parameterizes the size of the hidden layer. This bound on the dimension and the different neural factor lead to a different subset of OpenAI Gym problems: LunarLanderContinuous-v2, Blackjack-v0, Pendulumv0, HotterColder-v0, MountainCarContinuous-v0, CartPolev0, Acrobot-v1, NChain-v0, GuessingGame-v0, CartPole-v1.\nWinning percentage rates are evaluated at fixed budgets of 25, 50, 100, 200, and 400 function evaluations for both settings (neural factor 1 and 3), while bigger budgets are also considered for the bigger networks (see Sections IV and V in the Supplementary Material)."
        },
        {
            "heading": "IV. RESULTS OF THE EMPIRICAL COMPARISON",
            "text": "Results for BBOB: Figs. 1 and 2 present results with budget equal to 10D and 100D, respectively, in dimension D. The xaxis is the budget divided by the dimension, in logarithmic scale, while the y-axis shows the frequency of problems solved, i.e., the higher, the better. The plots are built by using the COCO/BBOB post-processing tool. It aggregates problems with different target precision values and displays the runtime distributions with simulated restarts [3], [61]. The default target precision values are 51 evenly log-spaced values between 102 and 10\u22128. The complete data set is archived on Zenodo [62] and allows further comparison with other BBOB data sets through the original COCO platform [3] or the IOHanalyzer web-interface [63].\nOur experiments for a budget of 10D reproduce the results in [30], where SMAC outperforms CMA. However, SMAC performance decreases with increasing dimension. Similar to all BO-based algorithms, its computational complexity increases significantly with increasing dimension and with increasing budget.\nAlthough we tested fewer optimizers for the D = 20 and D = 40 cases due to the high computational cost, it is interesting to note that Cobyla, which is simply based on linear interpolation, often performs better than all other solvers. Although there is no tuning for our present results from Cobyla\non BBOB, it outperformed all BO-based algorithms. Cobyla is also the algorithm selected by the NGOpt wizard for the test cases considered, which explains their similar performance.\nFig. 2 shows that both versions of CMA \u2013 defaultcma and cmafmin2 (and NGOpt16, which uses CMA as a component) \u2013 perform better than all other solvers when a larger budget of function evaluations is available.\nWe conclude by remarking that, in the BBOB benchmark with our specific setting using a low budget, there are elements that have a significant impact on the overall result:\n\u2022 The LinearSlope function, which has optima in the corners, is difficult for methods that assume that the optimum is supposed to be inside. \u2022 The precision parameter, ranging from 1e \u2212 8 to 100 by default, has a significant impact on results. Since our budget is much smaller than the default setting, the percentage of the problems that are successfully solved is smaller than the typically reported ones.\nIn an additional set of experiments, we verified that removing LinearSlope or changing the precision parameter does not change the overall picture of our results.\nTable I and Table II list the total execution time in seconds for 15 runs on the 24 BBOB functions for budget 10D and 100D, respectively. Note that NGOpt sometimes, in particular when the budget is sufficiently large compared to the dimension, spends a significant time learning a metamodel and checking in cross-validation whether this metamodel could be applied. NGOpt can hence be unexpectedly more expensive in lower dimensions, which in our experiments leads to the non-monotonic behavior of the running time with respect to the dimension. DefaultCMA, Turbo20, and SMAC2 have comparable execution times to CMAFmin2, Turbo, and SMAC, respectively. AX, BO, LAMCTS, and SMAC showed a total time of more than 20 000 seconds in dimension 10. As their computational cost became unmanageable for dimension 20, we stopped the runs after 3-day wall-clock time. We therefore do not report results for these algorithms for the 20- and 40-dimensional BBOB functions with 10D budget. The same algorithms, with the exception of SMAC, plus Optuna, are excluded from the experiments with a higher total evaluation budget (100D) due to their excessive computational cost for that budget.\nResults for the Direct Policy Search on OpenAI Gym: In Fig. 3, we provide an independent comparison of blackbox solvers applied to the Ng-Full-Gym benchmark, which is Nevergrad\u2019s direct policy search applied to OpenAI Gym. More precisely, is the optimization of a neural network as a controller for OpenAI Gym problems. We plot the unscaled loss, defined as the opposite of the reward the agent accumulates over time. Here, the lower the curve, the better the performance. The non-monotonic trend of the curves with respect to the elapsed budget is due to the fact that, for a given problem and algorithm, we perform new runs each time the total budget of the evaluations is updated. As a consequence, the algorithm may choose a different parametrization depending on the total budget or the ratio between the budget and the dimension of the specific benchmark, leading to a statistically significant difference in performance. In addition,\n5\nTABLE I TOTAL COMPUTATIONAL TIME IN SECONDS FOR THE BBOB BENCHMARK BUDGET = 10D\nDimension 2 3 5 10 20 40 CmaFmin2 30 31 33 38 50 90 AX 32 267 65 044 63 808 291 845 Turbo 116 1 118 3 572 11 535 58 670 48 700 Cobyla 16 24 32 51 86 202 NGOpt 90 204 303 563 167 336 BO 1087 2 129 5 486 23 274 Optuna 48 121 409 1 733 7 388 37 431 Lamcts 389 1 941 9 804 47 218 SMAC 5 978 9 258 26 295 66 733 HyperOpt 34 117 420 1 969 7 716 21 835 PSO 15 20 31 70 183 587\nTABLE II TOTAL COMPUTATIONAL TIME IN SECONDS FOR THE BBOB BENCHMARK BUDGET = 100D\nDimension 2 3 5 10 CmaFmin2 36 41 53 89 Turbo 13 241 22 161 38 903 141 852 Cobyla 197 297 474 845 NGOpt 625 1 254 3 070 333 SMAC 224 031 205 209 351 508 807 572 HyperOpt 1 038 1 655 4 260 17 836 PSO 60 101 179 458\nsince we perform independent runs for different budgets and average over the repetitions, some variability in performance is to be expected.\nWe add the following algorithms to our comparison: QORandomSearch [64], MetaTuneRecentering [65], and MetaRecentering [66] are variants of random search that are fully parallel and reduce redundancies compared to random search. We also add NGOpt16RL and SpecialRL from Nevergrad: NGOpt16RL is Nevergrad\u2019s wizard NGOpt optimized specifically for RL problems; SpecialRL runs the base NGOpt16RL for half of the budget and then uses test-based population size adaptation (TBPSA) [69] in the second half. Moreover, since the OpenAI Gym suite contains problems that are unbounded with optima at a small scale, we add algorithms that can adjust the scale of the search. GeneticDE and RotatedTwoPointsDE, for example, are designed to extrapolate the scale from some variables to others and find the right scale before running the classic DE [70] algorithm. MetaTuneRecentering performs a DoE entirely designed to choose the right scale depending on the relationship between budget and dimension. MultiCMA is a tentative robustification of CMA that runs three copies of CMA. We also consider a (1+1) evolutionary algorithm [71], which is a simple and fast state-of-the-art heuristic for adjusting the scale, Diagonal CMA [26], which uses a diagonal covariance matrix, and its scaled version, Scaled Diagonal CMA [5]. Finally, we add to our portfolio Lamcts-Turbo [18], an improved version of vanilla LA-MCTS coupled with Turbo to draw new samples in the selected node of the Monte\n0 1 log10(# f-evals / dimension)\n0.00\n0.05\n0.10\n0.15\n0.20\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai\nrs\nhyperopt lamcts5 PSO turbo turbo20 optuna cmafmin2 defaultcma BO SMAC SMAC2 ax Cobyla ngopt16\nbbob f1-f24, 2-D 51 targets: 100..1e-08 15 instances\nv2.4.1.1\n(a)\n0 1 log10(# f-evals / dimension)\n0.00\n0.05\n0.10\n0.15\n0.20\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai\nrs\nlamcts5 turbo20 PSO hyperopt optuna cmafmin2 turbo defaultcma SMAC SMAC2 BO ax Cobyla ngopt16\nbbob f1-f24, 3-D 51 targets: 100..1e-08 15 instances\nv2.4.1.1\n(b)\n0 1 log10(# f-evals / dimension)\n0.00\n0.05\n0.10\n0.15\n0.20\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai\nrs\nlamcts5 PSO hyperopt turbo20 optuna SMAC2 SMAC ax cmafmin2 defaultcma turbo BO Cobyla ngopt16\nbbob f1-f24, 5-D 51 targets: 100..1e-08 15 instances\nv2.4.1.1\n(c)\n0 1 log10(# f-evals / dimension)\n0.00\n0.05\n0.10\n0.15\n0.20\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai\nrs\nPSO hyperopt optuna ax lamcts5 SMAC2 SMAC turbo20 cmafmin2 defaultcma turbo BO ngopt16 Cobyla\nbbob f1-f24, 10-D 51 targets: 100..1e-08 15 instances\nv2.4.1.1\n(d)\n0 1 log10(# f-evals / dimension)\n0.00\n0.05\n0.10\n0.15\n0.20\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai\nrs\nPSO hyperopt optuna cmafmin2 defaultcma turbo20 turbo ngopt16 Cobyla\nbbob f1-f24, 20-D 51 targets: 100..1e-08 15 instances\nv2.4.1.1\n(e)\n0 1 log10(# f-evals / dimension)\n0.00\n0.05\n0.10\n0.15\n0.20\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai\nrs\nPSO hyperopt optuna defaultcma cmafmin2 turbo20 turbo Cobyla ngopt16\nbbob f1-f24, 40-D 51 targets: 100..1e-08 11, 15 instances\nv2.4.1.1\n(f) Fig. 1. Illustration of the ECDF of runtimes on the BBOB functions f1\u2013f24, using 51 targets uniformly spaced on a log scale between 1e\u22128 and 100. Plots are shown for dimension D equal to (a) 2, (b) 3, (c) 5, (d) 10, (e) 20, and (f) 40 and budget 10D. X-axis: budget/dimension in log-scale. Y-axis: frequency of solving at the requested precision. Overall, Cobyla and NGOpt16 (which heavily relies on Cobyla) perform best in these examples.\n6 0 1 2 log10(# f-evals / dimension) 0.0 0.1 0.2 0.3 0.4 0.5 Fr ac tio n of fu nc tio n, ta rg et p ai rs PSO hyperopt Cobyla turbo SMAC cmafmin2 defaultcma ngopt16bbob f1-f24, 2-D51 targets: 100..1e-08 15 instances v2.4.1.1\n(a)\n0 1 2 log10(# f-evals / dimension)\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai\nrs\nPSO\nhyperopt\nCobyla\nturbo\nSMAC\ndefaultcma\nngopt16\ncmafmin2bbob f1-f24, 3-D51 targets: 100..1e-08 15 instances\nv2.4.1.1\n(b)\n0 1 2 log10(# f-evals / dimension)\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai\nrs\nPSO\nhyperopt\nturbo\nSMAC\nCobyla\nngopt16\ncmafmin2\ndefaultcmabbob f1-f24, 5-D51 targets: 100..1e-08 15 instances\nv2.4.1.1\n(c)\n0 1 2 log10(# f-evals / dimension)\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nFr ac\ntio n\nof fu\nnc tio\nn, ta\nrg et\np ai rs PSO hyperopt SMAC turbo Cobyla ngopt16 cmafmin2 defaultcmabbob f1-f24, 10-D51 targets: 100..1e-08 15 instances\nv2.4.1.1\n(d)\nFig. 2. As Fig. 1 but with a 100D budget and only for dimensions (a) 2, (b) 3, (c) 5, and (d) 10. Some methods, which are too slow, are removed from the analysis. Overall, CMA algorithms and NGOpt16 perform best here.\nCarlo search tree at each iteration. For a complete list of all algorithms compared, see Section VI in the Supplementary Material.\nAlthough we cannot derive comprehensive recommendations from Fig. 3 because of the high variability of results across different benchmarks and dimensions, some conclusions can be drawn from the observation of similar patterns. First, we note that Fig. 3b, 3c, and 3d corresponding to problems of intermediate dimension (D = 15 and D = 24) show no significant differences in solver performance. On the contrary, for the low-dimensional test cases in Fig. 3a and 3g, we observe a very clear superiority of the BObased solvers (BO and AX), HyperOpt, PSO, and the wizard NgOpt16RL, all consistently belonging to the 5-best group. On the other hand, Fig. 3e, 3f, and 3h show that the quality of the performance of the 5-best group deteriorates as the dimension of the problem increases. Indeed, we observe the lowest loss values at the end of the total evaluation budget for population-based algorithms like DE and CMA, which are known to be powerful heuristics to address difficult black-box problems when a large number of function evaluations are available. However, for lower budgets of up to 100 function evaluations, the best-performing algorithms are still BO, AX, HyperOpt, PSO, and NgOpt16RL. On the contrary, LamctsTurbo consistently performs poorly on OpenAI Gym benchmarks, regardless of problem budget and dimension, in sharp contrast to the results shown in [18], where LA-MCTS was reported to perform well on some OpenAI Gym problems. We suspect that this discrepancy is caused by a poor initialization\nof the competitors in [18]. For an in-depth comparison, we also present aggregate plots based on average winning rates (e.g., Fig. 4), where we observe good results for the BO-based methods: BO is the most powerful solver for the lowest budget, while AX, NGOpt16RL and PSO turn out to be the best algorithms (within the confidence intervals) when aggregating results across all budgets (Fig. 4f). This means that vanilla BO is actually good for fast low-precision approximations on difficult problems, whereas AX, NGOpt16RL and PSO can be recommended when optimizing low-dimensional problems with low to medium budgets. Furthermore, Fig. 4 confirms, on the one hand, the good performance of NGOpt16RL, PSO, and HyperOpt for benchmarks with tiny neural networks, and, on the other hand, the poor search capabilities of Lamcts-Turbo, regardless of the available budget. For higher dimensions,\nFig. 5 shows that BO-based solvers become less competitive, although they still perform among the best for the smallest budgets (25 and 50 evaluations). For larger budgets, we see that CMA and DE start becoming more competitive, which is in line with [49]. However, Fig. 5f shows a supremacy of HyperOpt, which is designed for large-scale optimization for models with hundreds of parameters, and PSO, which performs surprisingly well considering that it is a classical heuristic originating from the BBO field and rarely used in ML applications. It can also be noted that Cobyla does not perform as well as for BBOB, while PSO performs constantly well for intermediate budgets from 50 to 400 total evaluations.\nFig. 1 in the Supplementary Material extends the present\n7 (a) (b)\n(c) (d)\n(e) (f)\n(g) (h)\nFig. 3. Multi-deterministic Open AI Gym with tiny neural net: a random seed is randomly drawn for each optimization run so that overfitting is more difficult. See Fig. 4 for an aggregated view. The legend lists all the compared algorithms with two numbers in parentheses: These are the performance values for the last and second-to-last budgets on the x-axis, respectively. The first number is also used to sort the algorithms by performance.\nresults to budgets 800, 1600, and 3200 for both tiny and big neural nets. Here, as the total budget increases, a smaller set of algorithms are compared: AX is affordable for runs on tiny neural nets up to a budget of 800 evaluations, and BO and Lamcts-Turbo become too expensive when exceeding a total budget of 1600 evaluations for big neural nets. The RL-specific algorithms, SpecialRL, and NGOpt16RL achieve the best performance for the largest budgets, followed by the various CMA and DE versions, leaving PSO and HyperOpt behind.\n8 All in all, our results on OpenAI Gym show the competitiveness of BO-based methods for small dimensions and evaluation budgets (up to 100 evaluations), comparably to other solvers, while solvers from other families perform better as the budget increases. We note that this is different behavior from the BBOB benchmarks, where BO-based methods never rank first and show only average performance."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "Our results provide insight into the comparison between different state-of-the-art BO methods, commonly used in ML, and more classical BBO heuristics. We compared the solvers on the BBOB benchmark suite from the COCO environment, which is well-known in the BBO community, and on OpenAI Gym problems, which are from the RL domain. On the BBOB comparison, we noted that Cobyla and the Nevergrad wizard perform best for any tested dimensionality from 2D to 40D with a total budget of 10D. They were consistently better than SMAC and Turbo, which was highlighted as a strong BO method in [21]. It is worth noting that Turbo and HyperOpt\nhave the advantage of being computationally cheaper than other BO methods. Moreover, HyperOpt performed among the best on OpenAI Gym, with the exception of the largest considered budget for big neural nets. Good performance was also observed for PSO, which is commonly considered a classical heuristic and hardly ever used for ML tasks. For the larger budget of 100D, CMA or the Nevergrad wizard perform best regardless of the considered dimension of the problem.\nIn general, we found that the OpenAI Gym benchmark is very sensitive to variable scaling. While BBOB focuses on translations of optima and might therefore favor algorithms tuned for this setting, direct policy search for OpenAI Gym has an unbounded domain and depends differently on the initialization scaling and the ability of the algorithm to change scaling as needed. We optimized the scaling to Bayesian Optimization methods for obtaining results in Fig. 4, and then we ran the experiments to get the (possibly more neutral) results in Fig. 5 without any change.\nOverall, tools based on heavy use of machine learning are computationally more expensive and perform roughly\n9 (a) Budget 25 (b) Budget 50\n(c) Budget 100 (d) Budget 200\n(e) Budget 400 (f) All budgets\nFig. 5. Same as Fig. 4, but with bigger nets (neural factor 3 in Nevergrad\u2019s benchmark scaling). 11 distinct problems per budget. We truncated at dimension \u2264 264. Dimension ranges from 24 to 264 instead of 8 to 40 in Fig. 4. Due to the computational cost, it was not possible to finish the runs for SMAC. Fig. 1 in the Supplementary Material extends the present results to budgets 800, 1600, and 3200.\nequivalently to mathematical programming or evolutionary techniques. In future work, we plan to compare BO and other methods in discrete settings as well. Our results also indicate a high relevance of initializing the solvers with the right scaling. Identifying suitable methods for a dynamic control policy is therefore another topic that we aim to investigate in future works. Of course, it remains interesting to periodically update our comparisons with new state-of-the-art solvers. Since all our experiments are performed with Nevergrad, such an ongoing benchmarking is largely facilitated: users can simply add their favorite method and compare their results to the ones reported above."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "Our work is supported by ANR, project ANR-22-ERCS0003-01, by the CNRS INS2I emergence project RandSearch, and by the PRIME programme of the German Academic Exchange Service (DAAD) with funds from the German Federal Ministry of Education and Research (BMBF)."
        },
        {
            "heading": "A. Domains",
            "text": "First, working in unbounded domains with a Gaussian distributed optimum (as in some benchmarks in Nevergrad) leads to differences compared to benchmarks on bounded domains such as BBOB, especially for functions with an optimum at the boundary. Both contexts look interesting, but some adaptation of NGOpt was needed to make it tackle optima on the boundary. In addition, we add bounded counterparts of YABBOB termed YABOUNDEDBBOB and YABOXBBOB for facilitating further research with simultaneously the convenience of Nevergrad (see Section C) and the bounded setting of BBOB."
        },
        {
            "heading": "B. Budgets and independence",
            "text": "In BBOB, when specifying a maximum budget of 100D, the results plotted for a lower budget of 10D are obtained as a truncation of the 100D-budget runs. On the contrary, Nevergrad runs each budget separately, which is more expensive from a computational point of view but gives a more complete picture of the different budgets. This can be remedied by launching distinct runs for different budgets for BBOB."
        },
        {
            "heading": "C. Parallelization",
            "text": "Nevergrad was more suitable than BBOB for testing very slow algorithms like AX [44] because it is easy to massively parallelize it on a cluster.\nA strength of BBOB is that the interfacing is quite easy, greatly facilitating reproducibility [67].\n1 % Nevergrad\u2019s NGOpt. 2 % Also SMAC, SMAC2, AX, BO: using Nevergrad\u2019s API. 3 ng.optimizers.NGOpt(ng.p.Array(lower=lbounds, upper=\nubounds, shape=[dim]), num_workers=1, budget= evals).minimize(f)\n4 5 % HyperOpt. 6 fmin(fn=lambda x: f([x[\u2019w\u2019+str(i)] for i in range(\ndim)]), space={\u2019w\u2019+str(i): hp.uniform(\u2019w\u2019 + str( i), -5, 5) for i in range(dim)}, algo=tpe. suggest, max_evals=evals)\n7 8 % Optuna. 9 class OptunaObjective(object):\n10 def __init__(self, problem): 11 self.problem = problem 12 13 def __call__(self, trial): 14 x = [] 15 for i in range(self.problem.dimension): 16 x.append(trial.suggest_float(\"x{}\".\nformat(i), problem.lower_bounds[i], problem. upper_bounds[i]))\n12\n17 return self.problem(x) 18 19 study = optuna.create_study(direction=\"minimize\") 20 study.optimize(OptunaObjective(problem), n_trials= evalsleft()) 21 22 % Turbo. 23 class turbo_function: 24 def __init__(self, dim=len(lbounds)): 25 self.dim = dim 26 self.lb = lbounds 27 self.ub = ubounds 28 29 def __call__(self, x): 30 assert len(x) == self.dim 31 assert x.ndim == 1 32 assert np.all(x <= self.ub) and np.all(x >= self.lb) 33 return f(x) 34 35 my_turbo = Turbo1(f=turbo_function(), lb=lbounds, ub =ubounds, max_evals=evals, n_init=min(evals, 20) ) 36 37 my_turbo.optimize() 38 39 % LA-MCTS. 40 % We tested several successive variants of the code, 41 % without much impact: the version below is the last . 42 % We also tested several values 43 % of ninits, without much change. 44 45 agent = MCTS(lb = f.lb, 46 ub = f.ub, 47 dims = f.dims, 48 ninits = 40, # We tested variants without much change. 49 func = f 50 ) 51 agent.search(iterations = evalsleft())\nOpenAI Gym was recently introduced in Nevergrad. After cloning Nevergrad at https://github.com/facebookresearch/ nevergrad.git, experiments can be launched with the following command line:\n1 python -m nevergrad.benchmark ng_full_gym -- repetitions=10 --plot\nHowever, in order to run a reduced experiment like the one presented in this paper, we changed the definition of the budget, dimension, and scaling (budget 25, 50, 100, 200, 400, 800, scaling-factor 1, and add a limit 40 to the dimension) in the ng full gym experiment in nevergrad/benchmarks/ gymexperiments.py (Line 80) for obtaining the setup as in Section III of the main paper.\nHere, we offer additional details about the configuration employed to produce the results depicted in Fig. 5 in the main manuscript. Bigger neural networks provide a more complete version of the Ng-Full-Gym problem, where the neural factor parameter, which scales the size of the neural networks, is equal to 3. This does not change the optimization methods, only the scale of the problems towards a greater dimension. Dimensions up to 264 are considered. This benchmark is unbounded, the the scale of the algorithms (i.e., the standard deviation of the first samples) is therefore particularly critical and makes a fair comparison difficult.\nWe note that PSO and HyperOpt are still the best or among the best for each considered budget. BO-based methods (BO\nand AX) perform well for limited budgets and algorithms specific for RL tasks (NGOpt16RL and SpecialRL) become always more competitive as the budget increases.\nWhile Figs. 4 and 5 in the main paper present results restricted to budgets of at most 400 function evaluations, Fig. 6 presents results for larger budgets of 800, 1600, and 3200 evaluations applied to multi-deterministic Open AI Gym with both tiny and (for methods which are computationally cheap enough) bigger neural nets. As in [49], CMA or NGOpt get better as the budget grows. We also find that, while most BObased methods weaken, HyperOpt performs satisfactorily.\nTable III contains all algorithms involved in our comparison. They are listed in alphabetical order. For each method, we give the labels used in the plots, the testbeds on which they were tested (BBOB, OpenAI Gym, or both), and a brief description of the algorithm.\n13\n14"
        }
    ],
    "title": "Optimizing with Low Budgets: a Comparison on the Black-box Optimization Benchmarking Suite and OpenAI Gym",
    "year": 2024
}