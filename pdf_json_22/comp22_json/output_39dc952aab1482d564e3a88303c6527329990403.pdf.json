{
    "abstractText": "We study the potential of data-driven deep learning methods for separation of two communication signals from an observation of their mixture. In particular, we assume knowledge on the generation process of one of the signals, dubbed signal of interest (SOI), and no knowledge on the generation process of the second signal, referred to as interference. This form of the single-channel source separation problem is also referred to as interference rejection. We show that capturing high-resolution temporal structures (nonstationarities), which enables accurate synchronization to both the SOI and the interference, leads to substantial performance gains. With this key insight, we propose a domain-informed neural network (NN) design that is able to improve upon both \u201coff-the-shelf\u201d NNs and classical detection and interference rejection methods, as demonstrated in our simulations. Our findings highlight the key role communicationspecific domain knowledge plays in the development of datadriven approaches that hold the promise of unprecedented gains.",
    "authors": [
        {
            "affiliations": [],
            "name": "Alejandro Lancho"
        },
        {
            "affiliations": [],
            "name": "Amir Weiss"
        },
        {
            "affiliations": [],
            "name": "Gary C.F. Lee"
        },
        {
            "affiliations": [],
            "name": "Jennifer Tang"
        },
        {
            "affiliations": [],
            "name": "Yuheng Bu"
        },
        {
            "affiliations": [],
            "name": "Yury Polyanskiy"
        },
        {
            "affiliations": [],
            "name": "Gregory W. Wornell"
        }
    ],
    "id": "SP:86c86545fec5f024859c940bcafed2095a13148d",
    "references": [
        {
            "authors": [
                "M. Hirzallah",
                "W. Afifi",
                "M. Krunz"
            ],
            "title": "Full-duplex-based rate/mode adaptation strategies for Wi-Fi/LTE-U coexistence: A POMDP approach",
            "venue": "IEEE J. Sel. Areas Commun., vol. 35, no. 1, pp. 20\u201329, Nov. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "G. Naik",
                "J.-M. Park",
                "J. Ashdown",
                "W. Lehr"
            ],
            "title": "Next generation Wi-Fi and 5G NR-U in the 6 GHz bands: Opportunities and challenges",
            "venue": "IEEE Access, vol. 8, pp. 153 027\u2013153 056, Aug. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A.A. Nugraha",
                "A. Liutkus",
                "E. Vincent"
            ],
            "title": "Multichannel audio source separation with deep neural networks",
            "venue": "IEEE/ACM Trans. Audio, Speech, Lang. Process., vol. 24, no. 9, pp. 1652\u20131664, Jun. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "Y. Gandelsman",
                "A. Shocher",
                "M. Irani"
            ],
            "title": "Double-DIP\u201d: Unsupervised image decomposition via coupled deep-image-priors",
            "venue": "Proc. of IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2019, pp. 11 026\u201311 035.",
            "year": 2019
        },
        {
            "authors": [
                "P.-S. Huang",
                "M. Kim",
                "M. Hasegawa-Johnson",
                "P. Smaragdis"
            ],
            "title": "Joint optimization of masks and deep recurrent neural networks for monaural source separation",
            "venue": "IEEE/ACM Trans. Audio, Speech, Lang. Process., vol. 23, no. 12, pp. 2136\u20132147, Dec. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "M.G. Amin"
            ],
            "title": "Interference mitigation in spread spectrum communication systems using time-frequency distributions",
            "venue": "IEEE Trans. Signal Process., vol. 45, no. 1, pp. 90\u2013101, Jan. 1997.",
            "year": 1997
        },
        {
            "authors": [
                "P. Comon",
                "C. Jutten"
            ],
            "title": "Handbook of Blind Source Separation: Independent component analysis and applications",
            "venue": "Academic press,",
            "year": 2010
        },
        {
            "authors": [
                "A. Weiss",
                "A. Yeredor"
            ],
            "title": "A maximum likelihood-based minimum mean square error separation and estimation of stationary Gaussian sources from noisy mixtures",
            "venue": "IEEE Trans. Signal Process., vol. 67, no. 19, pp. 5032\u20135045, Jul. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "T. Shilong",
                "C. Shaohe",
                "Z. Hui",
                "W. Jian"
            ],
            "title": "Particle filtering based single-channel blind separation of co-frequency MPSK signals",
            "venue": "IEEE Int. Symp. Intell. Signal Process. and Commun. Syst., Feb. 2007, pp. 582\u2013585.",
            "year": 2007
        },
        {
            "authors": [
                "T. Shilong",
                "Z. Hui",
                "G. Na"
            ],
            "title": "Single-channel blind separation of two QPSK signals using per-survivor processing",
            "venue": "IEEE Asia Pac. Conf. Circuits Syst. (APCCAS), Dec. 2008, pp. 473\u2013476.",
            "year": 2008
        },
        {
            "authors": [
                "T.J. O\u2019shea",
                "N. West"
            ],
            "title": "Radio machine learning dataset generation with GNU radio",
            "venue": "Proc. GNU Radio Conf., vol. 1, no. 1, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "MIT RLE LIDS"
            ],
            "title": "RF Challenge - AI Accelerator",
            "venue": "accessed 2022-08-18. [Online]. Available: https://rfchallenge.mit.edu",
            "year": 2022
        },
        {
            "authors": [
                "A. Napolitano"
            ],
            "title": "Cyclostationarity: New trends and applications",
            "venue": "Signal Process., vol. 120, pp. 385\u2013408, Mar. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "DeepSig Inc."
            ],
            "title": "RF Datasets For Machine Learning",
            "venue": "accessed 2022-08- 18. [Online]. Available: https://www.deepsig.ai/datasets",
            "year": 2022
        },
        {
            "authors": [
                "P. Banelli",
                "S. Cacopardi"
            ],
            "title": "Theoretical analysis and performance of OFDM signals in nonlinear AWGN channels",
            "venue": "IEEE Trans. Commun., vol. 48, no. 3, pp. 430\u2013441, Mar. 2000.",
            "year": 2000
        },
        {
            "authors": [
                "Z. Gao",
                "C. Zhang",
                "Z. Wang"
            ],
            "title": "Robust preamble design for synchronization, signaling transmission, and channel estimation",
            "venue": "IEEE Trans. Broadcast., vol. 61, no. 1, pp. 98\u2013104, Jan. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-Net: Convolutional networks for biomedical image segmentation",
            "venue": "Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer International Publishing, 2015, pp. 234\u2013241.",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Blind synchronization, source separation, interference rejection, deep neural network, supervised learning.\nI. INTRODUCTION\nThe proliferation of wireless devices is leading to an increasingly crowded radio spectrum, and consequently, spectrum sharing will be unavoidable [1], [2]. Thus, different wireless communication systems will coexist in the same frequency bands, thereby generating unintentional interferences among them. In order to maintain high reliability, separation of the overlapping signals from the received mixture will become an essential building block in such communication systems.\nIn the image and audio domains, machine learning techniques have been successfully applied for source separation, e.g., [3]. These methods usually exploit domain knowledge relating to the signals\u2019 structures. For example, color features\nResearch was sponsored by the United States Air Force Research Laboratory and the United States Air Force Artificial Intelligence Accelerator and was accomplished under Cooperative Agreement Number FA8750-19-2-1000. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the United States Air Force or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein. Alejandro Lancho has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 101024432. G. C.F. Lee is supported by the National Science Scholarship from the Agency for Science, Technology and Research (A*STAR). This work is also supported by the National Science Foundation under Grant No CCF2131115. \u2217These authors contributed equally to this work.\nand local dependencies are useful for separating natural images [4], whereas time-frequency spectrogram masking methods are typically adopted for separating audio signals [5].\nFor communication signals, if the sources are separable in time and/or frequency, one can separate them via appropriate masking and classical filtering methods (see, e.g., [6]). The key challenge in this domain is the separation of signals overlapping in both time and frequency when the receiver is equipped with a single antenna, which inherently implies there is no spatial diversity to be exploited. This problem is also referred to as single-channel source separation (SCSS). In this case, standard approaches exploiting spatial diversity for blind source separation, such as [7], [8], are irrelevant.\nVarious methods are available in the literature to perform SCSS of digital communication signals. A common approach is maximum likelihood sequence estimation of the target signal, for which algorithms such as particle filtering [9] and per-surviving processing algorithms [10] can be used. However, such methods require prior knowledge of the signal models, which in practice may not be known or available.\nPerhaps a more realistic approach is to assume that only a dataset of the underlying communication signals is available. This can be obtained, for example, through direct/background recordings, or using high fidelity simulators (e.g., [11]), allowing for a data-driven approach. In this setup, deep neural networks (DNNs) arise as a natural choice. This problem has been recently promoted by the \u201cRF Challenge\u201d [12].\nIn this paper, we study the data-driven SCSS problem where two communication signals overlap in time and frequency, and the receiver is equipped with one single antenna. We consider a signal of interest (SOI) whose generation process is known, and an interference signal with cyclic statistical properties that are unknown a priori\u2014as is the case in standard protocols.1 This problem is also referred to as interference rejection. As a performance measure, we consider the bit error rate (BER).\nContributions: We show that temporal nonstationarities of the signals constitute strong regularities that translate to better separation conditions. In particular, when such temporal structures exist, the notion of (time-)synchronization becomes not only sensible, but advantageous for separation. Based on\n1We only assume the cyclic period is known. In practice, provided a dataset of the respective signal, this parameter can be consistently estimated [13].\nar X\niv :2\n20 9.\n04 87\n1v 1\n[ ee\nss .S\nP] 1\n1 Se\np 20\n22\nour theoretical results that bind synchronization with MMSE optimal separation, we propose a data-driven DNN approach that is BER-superior to the classical methods of demodulation with matched filtering (MF) and interference rejection with linear minimum mean-square error (LMMSE) estimation of the SOI. Our proposed DNNs architectures, which can incorporate explicit synchronization, are inspired by specific domain knowledge, relevant to digital communication signals.\nNotation: We use lowercase letters with standard font and sans-serif font, e.g., x and x, to denote deterministic and random scalars, respectively. Similarly, we use x and x for deterministic and random vectors, respectively; and X and X for deterministic and random matrices, respectively. The uniform distribution over a set S is denoted as Unif(S), and for K \u2208 N, we denote SK , {1, . . . ,K}. For brevity, we refer to the complex normal distribution as Gaussian. We denote Czw , E [ zwH ] \u2208 CNz\u00d7Nw as the covariance matrix of z \u2208 CNz\u00d71 and w \u2208 CNw\u00d71 (specializing to Czz for z = w)."
        },
        {
            "heading": "II. PROBLEM FORMULATION",
            "text": "We consider the single-channel, baseband signal model of a noisy mixture of two sources, given by\ny[n] = s[n\u2212 ks] + \u03c1\u22121/2SIR b[n\u2212 kb] + \u03c1\u22121/2SNR w[n], n \u2208 Z, (1) where s[n], b[n] \u2208 C are assumed to be cyclostationary processes with known fundamental cyclic periods Ks,Kb \u2208 N, respectively; w[n] \u2208 C denotes additive white Gaussian noise, statistically independent of s[n] and b[n]; and \u03c1SIR, \u03c1SNR \u2208 R+. We refer to the signal s[n] as the SOI, and to b[n] as interference. The variables ks, kb \u2208 Z denote unknown (discrete) time-shifts with respect to the start of the cyclic periods of s[n] and b[n], respectively, where the start of the cyclic periods are chosen arbitrarily to be at n = 0 without loss of generality. Hence, we assume that ks \u223c Unif (SKs) and kb \u223c Unif (SKb).\nLet y , [y[1] \u00b7 \u00b7 \u00b7 y[N ]]T, s(ks) , [s[1\u2212 ks] \u00b7 \u00b7 \u00b7 s[N \u2212 ks]]T, b(kb) , [b[1\u2212 kb] \u00b7 \u00b7 \u00b7 b[N \u2212 kb]]T, and w , [w[1] \u00b7 \u00b7 \u00b7w[N ]]T. Then, we may compactly write (1) for N samples as\ny = s(ks) + \u03c1 \u22121/2 SIR b(kb) + \u03c1 \u22121/2 SNR w \u2208 CN\u00d71. (2)\nWe further assume that s(ks) and b(kb) are statistically independent, which is a reasonable assumption in scenarios of unintentional interference, for which each source is not actively jamming or adapting to the other signals present in the environment. For simplicity of the exposition, we assume that s(ks) and b(kb) are zero-mean, unit-average-power, i.e., their (possibly time-varying) variance averages to 1. In this case, the parameters \u03c1SIR, \u03c1SNR represent the signal-to-interference ratio (SIR) and signal-to-noise ratio (SNR) at the receiver, respectively.\nThe goal is to produce an estimate of s(ks) from y, denoted by s\u0302, so that given some metric `, the cost E[`(\u0302s, s(ks))] is minimized. This problem is referred to as SCSS.\nAs mentioned in Section I, we assume we do not have precise knowledge of the underlying distributions of the SOI and the interference. However, we assume the availability\nof a dataset of the signals and their respective time-shifts (s(ks), ks) and (b(kb), kb), allowing for a data-driven approach. Examples of such datasets can be found in [12], [14]."
        },
        {
            "heading": "III. THE GAIN IN SYNCHRONIZATION TO INTERFERENCE",
            "text": "Before we present our approach to the SCSS problem formulated in Section II, we provide an analysis of an asymptotically optimal estimator of s(ks) for the metric `(x, z) , \u2016x \u2212 z\u201622, which will shed light on key aspects in optimal separation and the role of synchronization to interference.\nIn this section, we assume that s[n] and b[n] are Gaussian processes, which is a reasonable assumption to model some communication signals, e.g., [15]. In this case, we define2\nv[n\u2212 kb] , \u03c1\u22121/2SIR b[n\u2212 kb] + \u03c1\u22121/2SNR w[n], n \u2208 Z, (3)\nsuch that v(kb) , [v[1\u2212 kb] \u00b7 \u00b7 \u00b7 v[N \u2212 kb]]T \u2208 CN\u00d71 is the \u201cequivalent noise\u201d, which, given kb, is distributed as CN (0,Cvv). Thus, (2) simplifies to\ny = s(ks) + v(kb) \u2208 CN\u00d71. (4) Note that, generally, the equivalent noise term v(kb) is not temporally white (as opposed to w), and exhibits a potentially informative statistical structure (e.g., in the form of Cvv) that can be exploited for enhanced separation performance."
        },
        {
            "heading": "A. Linear minimum mean-square error (MMSE) Estimation",
            "text": "A computationally attractive approach, which already exploits (some of) the underlying statistics of both of the components of the mixture (4), is optimal linear estimation. The LMMSE estimator [16], given by (assuming det(Cyy) 6= 0)\ns\u0302LMMSE , CsyC \u22121 yy y = Css (Css + Cvv) \u22121 y \u2208 CN\u00d71, (5) is constructed using the statistics of the mixture that inherently takes into account the potentially non-trivial structure of Cvv , i.e., some form of deviation from a scaled identity matrix.\nHowever, while (5) coincides with the MMSE estimator for jointly Gaussian processes, it is generally suboptimal due to the linearity constraint. Specifically, in our case, although the processes s[n], v[n] are jointly Gaussian, s(ks) and v(kb) are not even marginally Gaussian. Indeed, s(ks) and v(kb) are Gaussian mixtures due to the random time-shifts ks, kb. It then follows that (5) is in fact not optimal, as shown next."
        },
        {
            "heading": "B. MMSE Estimation",
            "text": "The optimal estimator in the MMSE sense is known to be the conditional expectation,\ns\u0302MMSE , E[s(ks)|y] \u2208 CN\u00d71, (6) whose mean-squared error (MSE) is an achievable lower bound of the MSE of any estimator of s(ks). However, in most practical cases, (6) is hard to obtain analytically and computationally. In our case, by using the law of total\n2Since w[n] is white (and therefore stationary), w[n \u2212 kb] is also white, hence without loss of generality we may indeed define (3) with the shift kb.\nexpectation in (6), the MMSE estimator is given by the more explicit and convenient form\ns\u0302MMSE = E [E[s(ks)|y, ks, kb]|y] (?) = E [\u0302sLMMSE(ks, kb)|y]\n=\nKs\u2211\nms=1\nKb\u2211\nmb=1\nP[ks = ms, kb = mb|y] s\u0302LMMSE(ms,mb), (7)\nwhere in (?) we have used the fact that, given the time-shifts, s(ks) and y are jointly Gaussian, and where s\u0302LMMSE(ms,mb) , Css(ms) [Css(ms) + Cvv(mb)] \u22121 y, with\nCss(m) , E[ssH|ks = m], Cvv(m) , E[vvH|kb = m]. (8) Put simply, (7) is a weighted average of Ks \u00d7 Kb linear estimators, with the posterior probabilities\u2014which are nonlinear functions of the data y\u2014serving as the normalized weights. Even before taking into account the computation of the posteriors, the sum in (7) scales with the product of possible time-shifts Ks\u00d7Kb, rendering s\u0302MMSE often impractical.\nAs can be seen from (7), synchronization (i.e., knowledge of the time-shifts) already substantially simplifies the computation, since, in that case, only the (conditional) linear estimator s\u0302LMMSE(ms,mb) is required. In other words, eliminating this type of randomness from the mixture y grants us lower computational complexity and a simple form of a linear estimator. Fortunately, a two-step \u201csynchronization-separation\u201d estimator can approach the MMSE estimator, thus enjoying asymptotic optimality at a substantially reduced computational burden.\nTo show this rigorously, for simplicity of the exposition, we assume hereafter (unless stated otherwise) that the receiver is synchronized to the SOI,3 namely, ks = 0 and known. However, the result below can be generalized to the case where the SOI\u2019s time-shift ks is random and unknown. Let\nk\u0302MAPb , arg max m\u2208SKb P[kb = m|y] (9)\nbe the maximum a posteriori (MAP) estimator of ks, and define the (suboptimal) \u201cplug-in\u201d, MAP-based quasi-linear MMSE estimator\ns\u0302MAP-QLMMSE , s\u0302LMMSE(k\u0302 MAP b ) \u2208 CN\u00d71, (10)\nwhere, for brevity, we use s\u0302LMMSE(m) to denote s\u0302LMMSE(0,m). Furthermore, we define the MSEs, as a function of N , as\n\u03b52MMSE(N) , E [ \u2016s\u0302MMSE \u2212 s\u201622 ] \u2208 R+, (11) \u03b52MAP-QLMMSE(N) , E[\u2016s\u0302MAP-QLMMSE \u2212 s\u201622] \u2208 R+. (12) We now introduce a \u201ctemporal-diversity\u201d condition (TDC) under which optimal synchronization is increasingly accurate. Definition 1 (TDC): Let \u03c8N (y, k) , 1N y\nHC\u22121yy (k)y\u22121. The (sufficient) TDC is satisfied if there does not exist k \u2208 SKb\\kb such that limN\u2192\u221e |\u03c8N (y, k)| = 0.\nLemma 1: Under the TDC, for any finite \u03b1 \u2208 R+,\nP [ k\u0302MAPb 6= kb ] = o ( 1\nN\u03b1\n) . (13)\n3This is a reasonable assumption in most communication systems [17].\nProof: See Appendix A. The theorem below shows that the two-step synchronizationseparation approach (10) is asymptotically optimal.\nTheorem 1: Under the TDC, we have\nlim N\u2192\u221e\n\u03b52MMSE(N)\n\u03b52MAP-QLMMSE(N) = 1. (14)\nProof: See Appendix B. In words, Theorem 1 tells us that, when the time-shift can be uniquely detectable, first optimally synchronizing to the interference, and then using a suboptimal, quasi-linear estimator, is asymptotically equivalent to MMSE estimation. Further intuition to this type of behaviour, for maximum-likelihoodbased MMSE estimation, is given in [8, Fig. 1]."
        },
        {
            "heading": "C. Synchronization via convolutional neural networks (CNNs)",
            "text": "Although the estimator (10) is attractive in terms of its MSE performance, it nevertheless requires\u2014both for synchronization and separation\u2014precise knowledge of the underlying statistics, including the SIR and SNR, which can be hard to obtain in practice. In particular, without these statistics, it is impossible to obtain k\u0302MAPb . However, when by measurement or generation, sufficiently large datasets with realizations of s(ks) and b(kb) are available, a data-driven approach can be taken.\nTo this end, we leverage the strong capabilities of CNNs for capturing intricate temporal structures, to train a synchronizer in a data-driven manner. Specifically, we propose the CNNbased architecture depicted in Fig. 1, which is trained in a supervised manner based on a labeled dataset of mixtures and the underlying interference time-shifts, {(y(i), k(i)b ) : i \u2208 SIT }, where IT is the size of the training dataset. We use a sufficiently large kernel size in the convolutional layers, which is proportional to the \u201ceffective correlation length\u201d\u2014denoted as Ncorr in Fig. 1\u2014so as to be able to capture the strongest, most informative temporal structures for estimation. Since the cyclic period Kb is assumed to be known, we train a model using the cross-entropy loss, which receives as its input the mixture y and outputs a vector of probabilities, denoted by p\u0302kb \u2208 [0, 1]Kb\u00d71. At inference time, we synchronize to the interference via k\u0302CNNb , arg maxm\u2208SKb e T mp\u0302kb (cf. k\u0302 MAP b in (9)), where em \u2208 RKb\u00d71 denotes the m-th standard basis vector. In Fig. 2, we show the MSE for s\u0302LMMSE, s\u0302MMSE and\ns\u0302CNN-QLMMSE , s\u0302LMMSE(k\u0302 CNN b ), (15)\nfor the same communication waveforms described in detail in Section V, but considering here Gaussian alphabets instead of the discrete and finite alphabets used in Section V. As seen, the linearity restriction (5) costs a considerable price in terms of the compromised performance relative to the lower bound, given by the MMSE. It is also evident that the MSE of the CNN-based quasilinear MMSE (QLMMSE) estimator s\u0302CNN-QLMMSE coincides with (11), which asymptotically coincides with the MAP-QLMMSE (12) by virtue of Theorem 1.\nAll the above motivates our solution approach, and provides the theoretical foundations (as well as intuition) based on which we develop our system architecture, presented next.\nIV. INTERFERENCE REJECTION VIA DNNS\nWe now present two supervised learning approaches for SCSS, used in this work as interference rejection methods. The first DNN architecture, depicted in Fig. 3, consists of two main building blocks: (i) CNN to perform synchronization to the interference, (ii) DNN (U-Net) to perform SCSS.4 The key motivation to perform explicit synchronization is twofold. First, as explained in Section III-B, due to Theorem 1, explicit consistent synchronization decoupled from separation, although suboptimal, can asymptotically (as N \u2192 \u221e) lead to optimal separation with reduced complexity. Second, although a sufficiently rich DNN might be able to perform the synchronization and separation tasks jointly, for a given architecture, acquiring synchronization knowledge explicitly helps by reducing the complexity of the separation task. In Section V-A, we show that this decoupled approach can indeed lead to performance gains. However, Lemma 1 shows that there exists a realizable synchronization method that becomes increasingly accurate as the input size grows. While this can be exploited for explicit synchronization (e.g., Fig. 3), it could also imply that, under certain conditions, a DNN architecture would be able to \u201cimplicitly synchronize\u201d and separate, namely superior performance would be achieved without explicit synchronization. This is shown in Section V-B.\n4To separate the communication signals used in this paper, other DNNs were implemented, yielding worse performance. Details can be found in the Github repository: https://github.com/RFChallenge/SCSS DNN Comparison.\nThe synchronization block is based on the CNN described in Section III-C (Fig. 1). The DNN for separation is based on the so-called U-Net (see Fig. 4) [18], which has some properties that makes it suitable to the specific informative features of digital communication signals. In particular, its CNN building blocks allow us to input and process long time intervals (e.g., N > 104), which cannot be processed using classical methods. In turn, processing such long signals allows for exploitation of temporal structures on a different scale, which can (and does) lead to substantial performance gains.\nAs shown in Fig. 4, our DNN approach departs from standard implementations intended to deal with images (2D signals). To handle 1D complex-valued, time-series communication signals, we use 1D convolutional layers. Furthermore, differently from standard CNN-based architectures that are designed to deal with images and hence use short kernels of size \u223c 3 in all layers, our U-Net architecture utilizes a sufficiently long kernel in the first convolutional layer (denoted by \u03ba in Fig. 4). This enables to capture the most influential temporal structures of the SOI and interference, which can lead to an order of magnitude gains, as demonstrated below.\nFor training, we input the stacked real and imaginary parts of y as separate channels to both the synchronization-tointerference CNN and the separation U-Net. For separation, if explicit synchronization is performed, we mimic a nonlinear version of (10) by using an instance of the DNN architecture depicted in Fig. 4 for each possible output of the synchronization-to-interference CNN block. In other words, we implement a \u201cconditional separation\u201d block for each possible time-shift of the interference. If explicit synchronizationto-interference is not used, the raw unprocessed mixture is (always) fed into to the same DNN separation block.\nThe training set is processed as such to yield a labeled dataset (mixture y and ground-truth reference signal s). As a loss function, we use the empirical MSE. For full implementation details, see our Github repository.5"
        },
        {
            "heading": "V. NUMERICAL RESULTS",
            "text": "We generate synthetic mixtures y where the SOI bears quaternary phase shift keying (QPSK) symbols using a root-raised cosine pulse-shaping filter with roll-off factor 0.5, spanning 8 QPSK symbols, and with an oversampling factor 16. The interference is an orthogonal frequency-division multiplexing\n5https://github.com/RFChallenge/SCSS Sync\n(OFDM) signal. We generate an OFDM signal with symbols of length 80, bearing 16\u2013quadrature amplitude modulation (QAM) symbols, with a fast Fourier transform (FFT) size of 64, and a cyclic-prefix of length 16. Details on the signals generation process are provided in the Github repository.5"
        },
        {
            "heading": "A. The Potential Gain of Explicit Synchronization with DNNs",
            "text": "We now compare the performance of the DNN approach illustrated in Fig. 3 with the performance achieved by classical methods for detection and interference rejection, i.e., MF and the LMMSE estimator s\u0302LMMSE given in (5), and by our proposed \u201csynchronized\u201d QLMMSE estimator s\u0302CNN-QLMMSE given in (15). For the CNN-based synchronization-to-interference methods (Section III-C), we input 640 samples of the mixture y to the CNN. The input size to the separation U-Net is N = 10240.\nIn Fig. 5, we compare the performance in terms of BER as a function of the SIR in a noiseless setting. Specifically, we depict in gray the MF approach. In blue, we depict the LMMSE (\u0302sLMMSE in (5)) computed using blocks of length 320.6 In red, we depict the CNN\u2013QLMMSE approach (\u0302sCNN-QLMMSE in (15)), also using blocks of length 320. Here, we explicitly synchronize to the interference signal, and exploit this to obtain \u201caligned statistics\u201d (8) for each possible time-shift kb. In green, we depict the performance of the U-Net approach when there is no explicit synchronization, i.e., the \u201cSynchronization CNN\u201d block in Fig. 3 is removed. Finally, we depict in black the DNN approach including both the synchronization and separation blocks, as described in Fig. 3, denoted as CNN\u2013UNet. Every described approach includes a last MF step before hard decoding based on the minimum Euclidean distance rule.\nAs can be observed, by only applying a MF to the received signal y, which is optimal under white Gaussian noise, we do not exploit any temporal structure of the (non-Gaussian) interference. Hence, as expected, we obtain the worst performance. It is also evident that the LMMSE approach\u2014 optimal for Gaussian signals\u2014without explicit alignment of the signal statistics via synchronization, is unable to exploit the underlying temporal nonstationarities, and accordingly yields\n6For non-stationary processes, the required inversion of Cyy is computationally impractical for large N , as it is generally of complexity O(N3).\napproximately the performance obtained by only applying a MF to the received signal y. However, by explicitly synchronizing to the interference signal using the CNN described in Section III-C, we can now use the conditional covariance of the interference for each possible time-shift kb to obtain s\u0302CNN-QLMMSE, which already leads to a significant performance gain. For example, for a BER of 10\u22123, the CNN\u2013QLMMSE approach requires an SIR of \u22126 dB, while the MF and the LMMSE approaches require \u22124 dB. Even though by explicitly synchronizing to the interference we can obtain significant gains, we recall that by using (quasi-)linear processing we can only exploit up to (conditional) second order statistics.\nSince we consider digital communication signals, further gains can be achieved by exploiting high-order statistics and the \u201cdiscrete nature\u201d of these signals. This is precisely achieved by our proposed DNN-based approaches (green and black). First, it is observed that a U-Net without prior explicit synchronization already outperforms the CNN\u2013QLMMSE approach for most of the considered SIR values. The performance of the U-Net is further improved with explicit synchronization, using the block described in Fig. 1, as shown in Fig. 3. In this case, a BER of 10\u22122 is obtained at an SIR level of \u221217 dB, while the U-Net without explicit synchronization requires \u221212 dB, and the CNN\u2013QLMMSE approach requires \u221210.5 dB. Thus, for a given architecture with limited capacity (parametrization power), decoupling synchronization and separation can lead to considerable gains, which enables reliable communication in the presence of strong interference."
        },
        {
            "heading": "B. Gains from Explicit-Synchronization-Free Architecture",
            "text": "As mentioned in Section IV, a plausible interpretation of Lemma 1 is the following. When the input mixtures are sufficiently long, an explicit-synchronization-based architecture may not be required (or even provide superior performance), since the data is \u201cvery informative\u201d with respect to the underlying time-shift. This essentially makes direct separation (i.e., an \u201cimplicit\u201d synchronization approach) potentially preferable. Our best result up to date is achieved by directly inputting mixtures of length N = 40960 to the U-Net depicted in Fig. 4.\nFig. 6 shows the performance of the U-Net scheme described in Fig. 4 (U-Net2) where we input two replicas of the\nmixture y, which provides the first layer with more diversity. We consider three different SNR levels of white Gaussian noise: \u03c1SNR \u2208 {10, 20,\u221e} dB. Specifically, we compare the performance of the DNN solution with the performance of the CNN\u2013QLMMSE approach (computed using blocks of length 320) and the MF approach, which is only plotted for the noiseless case for the sake of clarity. Clearly, for all SNR levels, the U-Net2 approach outperforms the CNN\u2013QLMMSE and MF approaches. However, as expected, the smaller the SNR, the smaller the gap between them. For example, for a BER of 10\u22123, the gain of the U-Net2 approach compared to the CNN\u2013QLMMSE is roughly 7 dB in the noiseless case, 4 dB for an SNR= 20dB, and 1.8 dB for an SNR= 10dB."
        },
        {
            "heading": "VI. CONCLUSIONS AND OUTLOOK",
            "text": "We study the SCSS problem with a focus on its application to interference rejection in digital communication. For Gaussian signals, we prove that a decoupled system architecture of synchronization followed by separation is asymptotically optimal in the MMSE sense. Consequently, since the optimal system can be impractical for implementation purposes, we propose a computationally attractive alternative with negligible performance loss relative to the optimal system. For (non-\nGaussian) signals, we demonstrate in simulations that the proposed DNN-based data-driven approach can exploit the underlying temporal structures of the signals, thus leading to significant gains in terms of BER, and in particular, outperforms classical methods. Extensions of this work should focus on understanding how and when to use explicit synchronization in the context of SCSS with DNNs."
        },
        {
            "heading": "APPENDIX A PROOF OF LEMMA 1",
            "text": "To prove Lemma 1, we shall use the following lemma. Lemma 2: For \u03c8N (y, k), in Definition 1 (TDC), we have,\nE [ e\u03c4\u03c8N (y,kb) ] = ( 1\u2212 \u03c4\nN\n)\u2212N \u00b7 e\u2212\u03c4 , \u2200\u03c4 < N. (16)\nProof of Lemma 2: First, recall y|kb \u223c CN (0,Cyy(kb)), where Cyy(kb) = Css(0) + Cvv(kb). Using the Cholesky decomposition, we write Cyy(kb) , \u0393y(kb)\u0393Hy (kb), where \u0393y(kb) \u2208 CN\u00d7N . Then, conditioned on kb, we have\n\u03c8N (y, kb) + 1 = 1 N yHC\u22121yy (kb)y (17)\n= 1 N yH\u0393\u2212Hy (kb)\u0393 \u22121 y (kb)y (18) = 1\nN ( \u0393\u22121y (kb)y\ufe38 \ufe37\ufe37 \ufe38\n,u(kb)\n)H \u0393\u22121y (kb)y\ufe38 \ufe37\ufe37 \ufe38\n=u(kb)\n(19)\n= 1\nN \u2016u(kb)\u201622, (20)\nwhere u(kb)|kb \u223c CN (0, I) is a white Gaussian vector. Thus,\nE [ e\u03c4\u03c8N (y,kb) ] = E [ E [ e\u03c4\u03c8N (y,kb)|kb ]] (21)\n= E [ E [ e\u03c4( 1 N \u2016u(kb)\u201622\u22121)|kb ]] (22) = E [ E [ e \u03c4 N \u2211N n=1 |un(kb)|2 |kb ]] e\u2212\u03c4 (23)\n= E\n[ N\u220f\nn=1\nE [ e \u03c4 2N | \u221a 2un(kb)|2 |kb ]] e\u2212\u03c4(24)\n\u2200\u03c4<N = E\n[ N\u220f\nn=1\n( 1\u2212 \u03c4\nN\n)\u22121 ] e\u2212\u03c4 (25)\n= ( 1\u2212 \u03c4\nN\n)\u2212N \u00b7 e\u2212\u03c4 , (26)\nwhere we have used the law of total expectation in (21); the conditional statistical independence of the elements of u(kb) (given kb) in (24); the fact that {| \u221a 2un(kb)|2 \u223c \u03c722}Nn=1, namely all the squared absolute-valued elements of u(kb), given kb, are chi-squared random variables with two degrees of freedom; and, accordingly, that the moment generating function of a random variable q \u223c \u03c722 is E[e\u03c4\u0303q] = (1\u22122\u03c4\u0303)\u22121, for all \u03c4\u0303 < 12 , in (25), where in our case \u03c4\u0303 = \u03c4/2N , hence the condition on \u03c4 in (24) Equipped with Lemma 2, we now prove Lemma 1.\nBy definition, the MAP estimator has the lowest error probability. Therefore, to show (13), it is sufficient to show that\nthere exists another estimator of kb, whose error probability is o(N\u2212\u03b1) for any finite \u03b1 \u2208 R+, independent of N . For this, let us consider the estimator,\nk\u0302b , arg min m\u2208SKb\n|\u03c8N (y,m)| . (27)\nIn words, as N \u2192\u221e, the error probability of (27) is governed by how far is |\u03c8N (y, kb)| from zero, since from the TDC, @k \u2208 SKb\\kb : limN\u2192\u221e |\u03c8N (y, k)| = 0, whereas\nlim N\u2192\u221e\n\u03c8N (y, kb) = E [\u03c8N (y, kb)] (28)\n= E [E [\u03c8N (y, kb)|kb]] (29) = 1\nN E [ E [ \u2016u(kb)\u201622|kb ]] \u2212 1 = 0, (30)\nwhere we have used (20), u(kb)|kb \u223c CN (0, I), and (28) follows from the fact that Var(\u03c8N (y, kb)) = 1/N , which can be shown in a similar fashion to (28)\u2013(30).\nFormally, the error probability of this estimator is given by,\nP [ k\u0302b 6= kb ] = P [ |\u03c8N (y, kb)| > min\nm\u2208SKb\\kb |\u03c8N (y,m)|\n] .\n(31) We now show that the probability that \u03c8N (y, kb) is bounded away from zero decreases in the desired rate. Clearly, for any a > 0, we have\nP[|\u03c8N (y, kb)| > a] = P[\u03c8N (y, kb) > a] (32) + P[\u03c8N (y, kb) < \u2212a] . (33)\nUsing the Chernoff bound, we have\nP[\u03c8N (y, kb) > a] \u2264 E [ et\u03c8N (y,kb) ] e\u2212ta , B1(t, a), (34) P[\u03c8N (y, kb) < \u2212a] \u2264 E [ e\u2212t\u03c8N (y,kb) ] e\u2212ta , B2(t, a). (35)\nUsing Lemma 2, it follows that\nB1(t, a) =\n( 1\u2212 t\nN\n)\u2212N \u00b7 e\u2212t(1+a), \u2200t < N, (36)\nB2(t, a) =\n( 1 + t\nN\n)\u2212N \u00b7 et(1\u2212a), \u2200t > \u2212N. (37)\nMinimizing B1(t, a) and B2(t, a) with respect to t and choosing a = N\u2212(0.5\u2212 ) for some 0 < < 0.5, we obtain\nmin t<N\nB1(t,N \u2212(0.5\u2212 )) = ( 1 +\n1\nN (0.5\u2212 )\n)N e\u2212N 0.5+ (38)\n, B\u22171 [N ], (39)\nmin t>\u2212N\nB2(t,N \u2212(0.5\u2212 )) = ( 1\u2212 1\nN (0.5\u2212 )\n)N eN 0.5+\n(40)\n, B\u22172 [N ]. (41)\nFinally, as for any \u03b1 \u2208 R+ and any \u03b4 > 0 independent of N ,\nlim N\u2192\u221e N\u03b1+\u03b4B\u22171 [N ] = lim N\u2192\u221e N\u03b1+\u03b4B\u22172 [N ] = 0, (42)\nit follows that for any \u03b1 \u2208 R+ independent of N ,\nP [ |\u03c8N (y, kb)| >\n1\nN0.5\u2212\n] = o ( 1\nN\u03b1\n) (43)\n=\u21d2 P [ k\u0302b 6= kb ] = o ( 1\nN\u03b1\n) . (44)"
        },
        {
            "heading": "APPENDIX B PROOF OF THEOREM 1",
            "text": "From Lemma 1, we have the following corollary. Corollary 1: Using (13), we have\nE [ P [ k\u0302MAPb 6= kb|y ]] = o ( 1\nN\u03b1\n) , (45)\nE [ P [ k\u0302MAPb = k|y ]] = o ( 1\nN\u03b1\n) , \u2200k \u2208 SKb\\kb. (46)\nThe roadmap for the proof of the theorem is as follows: \u2022 Step 1: Express the optimality gap between the MMSE\nand MAP-based QLMMSE estimators as a function of the error probability of the MAP synchronizer k\u0302MAPb . \u2022 Step 2: Express the MMSE (11) as a sum of the MAPbased QLMMSE (12) and the expected squared norm of the optimality gap, also known as the \u201cregret\u201d. \u2022 Step 3: Show that the regret is upper bounded by terms that decay polynomially fast, for any fixed polynomial rate (using Lemma 1).\nWe now prove Thoerem 1. Let us write the the MMSE estimator (6), explicitly, using (7), in terms of the MAP-based QLMMSE estimator (10), as (recall ks = 0, by assumption),\ns\u0302MMSE = Kb\u2211\nmb=1\nP[kb = mb|y] s\u0302LMMSE(mb)\n=\nKb\u2211\nmb=1\nmb 6=k\u0302MAPb\nP[kb = mb|y] s\u0302LMMSE(mb)\n\ufe38 \ufe37\ufe37 \ufe38 ,\u03b4(y)\n+ P [ kb = k\u0302 MAP b |y ] s\u0302LMMSE(k\u0302 MAP b ).\n(47)\nUsing (47), we define the optimality gap (vector),\n\u2206(y) , s\u0302MMSE \u2212 s\u0302LMMSE(k\u0302MAPb ) = s\u0302MMSE \u2212 s\u0302MAP-QLMMSE (48) = \u03b4(y)\u2212 P [ kb 6= k\u0302MAPb |y ] s\u0302MAP-QLMMSE. (49)\nLet us proceed to the second step of the proof. For shorthand, let eMAP-QLMMSE , s\u0302MAP-QLMMSE \u2212 s, and let us first write the MMSE in terms of the estimation error eMAP-QLMMSE and the optimality gap \u2206(y) as, E [ \u2016s\u0302MMSE \u2212 s\u201622 ] = E [ \u2016s\u0302MMSE \u2212 s\u0302MAP-QLMMSE + s\u0302MAP-QLMMSE \u2212 s\u201622 ]\n(50)\n= \u03b52MAP-QLMMSE(N)\u2212 E [ \u2016\u2206(y)\u201622 ] , (51)\nwhere we have used (48) in (50), and the well-known orthogonality property of the estimation error in MMSE estimation\nto any function of the measurements in (51). Expanding the first term, we have,\nE [ \u2016\u2206(y)\u201622 ] =\nE [ \u2016\u03b4(y)\u201622 ] + E [ P [ kb 6= k\u0302MAPb |y ]2 \u2016s\u0302MAP-QLMMSE\u201622 ]\n\u2212 2< { E [ P [ kb 6= k\u0302MAPb |y ] \u03b4H(y)\u0302sMAP-QLMMSE ]} .\n(52) We now show that (the magnitude of) each of the terms in (52) is bounded. It will then follow that the expected squared norm of the optimality gap, E [ \u2016\u2206(y)\u201622 ] , is also bounded.\nStarting with the first term in (52), we have,\nE [ \u2016\u03b4(y)\u201622 ] = N\u2211\nn=1\nE [ \u03b42n(y) ] = (53)\nN\u2211\nn=1\nE     Kb\u2211\nmb=1\nmb 6=k\u0302MAPb\nP[kb = mb|y] s\u0302LMMSE,n(mb)   2  . (54)\nFocusing on one element of the sum in (54), we have,\nE     Kb\u2211\nmb=1\nmb 6=k\u0302MAPb\nP[kb = mb|y] s\u0302LMMSE,n(mb)   2  \u2264 (55)\nKb\u2211\nm1=1\nm1 6=k\u0302MAPb\nKb\u2211\nm2=1\nm2 6=k\u0302MAPb\nE [ P[kb = m1|y]2 P[kb = m2|y]2 ] 1 2 \u00b7\nE [ s\u03022LMMSE,n(m1)\u0302s 2 LMMSE,n(m2) ] 1 2 \u2264 (56)\nKb\u2211\nm1=1\nm1 6=k\u0302MAPb\nKb\u2211\nm2=1\nm2 6=k\u0302MAPb\nE [ P[kb = m1|y]4 ] 1 4E [ P[kb = m2|y]4 ] 1 4 \u00b7\nE [ s\u03022LMMSE,n(m1)\u0302s 2 LMMSE,n(m2) ] 1 2 \u2264 (57)\nKb\u2211\nm1=1\nm1 6=k\u0302MAPb\nKb\u2211\nm2=1\nm2 6=k\u0302MAPb E [P[kb = m1|y]]\ufe38 \ufe37\ufe37 \ufe38 o( 1 N4\u03b1 ) 1 4E [P[kb = m2|y]]\ufe38 \ufe37\ufe37 \ufe38 o( 1 N4\u03b1 ) 1 4 \u00b7 (58)\nE [ s\u03022LMMSE,n(m1)\u0302s 2 LMMSE,n(m2) ] 1 2 \ufe38 \ufe37\ufe37 \ufe38 O(1) = (59)\no\n( 1\nN\u03b1\n) , (60)\nwhere we have used the Cauchy-Schwarz inequality repeatedly in (55) and (56), the following (almost trivial) observation,\nP[z = z]\u03b2 \u2264 P[z = z] , \u2200\u03b2 \u2265 1, (61)\nin (57), and (46) in (58). Since (54) is a sum of N terms as in (55), we obtain\nE [ \u2016\u03b4(y)\u201622 ] = o\n( 1\nN\u03b1\u22121\n) . (62)\nMoving to the second term in (52), we have,\nE [ P [ kb 6= k\u0302MAPb |y ]2 \u2016s\u0302MAP-QLMMSE\u201622 ] \u2264 (63) E [ P [ kb 6= k\u0302MAPb |y ] \u2016s\u0302MAP-QLMMSE\u201622 ] \u2264 (64) E [ P [ kb 6= k\u0302MAPb |y ]2] 12 E [ \u2016s\u0302MAP-QLMMSE\u201642 ] 1 2 \u2264 (65) E [ P [ kb 6= k\u0302MAPb |y ]] \ufe38 \ufe37\ufe37 \ufe38 o( 1 N2\u03b1 ) 1 2E [ \u2016s\u0302MAP-QLMMSE\u201642 ] \ufe38 \ufe37\ufe37 \ufe38 O(N) 1 2 = o ( 1 N\u03b1\u22121 ) ,\n(66)\nwhere we have used (61) in (63) and (65), the Cauchy-Schwarz inequality in (64), and (45) in (66). As for the magnitude of the last term in (52), we similarly obtain,\n\u2223\u2223\u2223< { E [ P [ kb 6= k\u0302MAPb |y ] \u03b4H(y)\u0302sMAP-QLMMSE ]}\u2223\u2223\u2223 \u2264 (67) \u2223\u2223\u2223E [ P [ kb 6= k\u0302MAPb |y ] \u03b4H(y)\u0302sMAP-QLMMSE ]\u2223\u2223\u2223 \u2264 (68)\nE [ P [ kb 6= k\u0302MAPb |y ]2] 12 E [\u2223\u2223\u03b4H(y)\u0302sMAP-QLMMSE \u2223\u22232 ] 1 2 \u2264 (69) E [ P [ kb 6= k\u0302MAPb |y ]] \ufe38 \ufe37\ufe37 \ufe38 o( 1 N2\u03b1 ) 1 2E [\u2223\u2223\u03b4H(y)\u0302sMAP-QLMMSE \u2223\u22232 ] \ufe38 \ufe37\ufe37 \ufe38 O(N) 1 2 = (70)\no\n( 1\nN\u03b1\u22121\n) , (71)\nwhere we have used, again, the Cauchy-Schwarz inequality in (68), (61) in (69), and (45) in (70). We note in passing that the term on the right in (70) may be bound more tightly, but this is not necessary for the following steps of this proof.\nWe have established upper bounds on the magnitudes of the terms in (52). Hence, using (62), (66) and (71), we now have\nE [ \u2016\u2206(y)\u201622 ] = o\n( 1\nN\u03b1\u22121\n) , (72)\nwhich, together with (51), yields\n\u03b52MMSE(N) = \u03b5 2 MAP-QLMMSE(N) + o\n( 1\nN\u03b1\u22121\n) . (73)\nBy the definition of the MMSE estimator, the (trivial) upper bound\n\u03b52MMSE(N) \u2264 \u03b52MAP-QLMMSE(N) =\u21d2 \u03b52MMSE(N)\n\u03b52MAP-QLMMSE(N) \u2264 1 (74)\nholds for any N \u2208 N+. Therefore, and since (73) hold for any \u03b1 \u2208 R+, we can always choose some \u03b1 to have\n\u03b52MMSE(N)\n\u03b52MAP-QLMMSE(N) = 1\u2212 o\n( 1\nN\u03b1\n) , (75)\nwhere we used \u03b52MAP-QLMMSE(N) = O(N), proving the theorem."
        }
    ],
    "title": "Data-Driven Blind Synchronization and Interference Rejection for Digital Communication Signals",
    "year": 2022
}