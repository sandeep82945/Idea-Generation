{
    "abstractText": "In this paper, a mode decomposition (MD) method for degenerated modes has been studied. Convolution neural network (CNN) has been applied for image training and predicting the mode coefficients. Four-fold degenerated LP11 series has been the target to be decomposed. Multiple images are regarded as an input to decompose the degenerate modes. Total of seven different images, including the full original near-field image, and images after linear polarizers of four directions (0\u25e6, 45\u25e6, 90\u25e6, and 135\u25e6), and images after two circular polarizers (right-handed and left-handed) has been considered for training, validation, and test. The output label of the model has been chosen as the real and imaginary components of the mode coefficient, and the loss function has been selected to be the root-mean-square (RMS) of the labels. The RMS and mean-absolute-error (MAE) of the label, intensity, phase, and field correlation between the actual and predicted values have been selected to be the metrics to evaluate the CNN model. The CNN model has been trained with 100,000 three-dimensional images with depths of three, four, and seven. The performance of the trained model was evaluated via 10,000 test samples with four sets of images images after three linear polarizers (0\u25e6, 45\u25e6, 90\u25e6) and image after right-handed circular polarizer showed 0.0634 of label RMS, 0.0292 of intensity RMS, 0.1867 rad of phase MAE, and 0.9978 of average field correlation. The performance of 4 image sets showed at least 50.68% of performance enhancement compared to models considering only images after linear polarizers.",
    "authors": [
        {
            "affiliations": [],
            "name": "Hyuntai Kim"
        }
    ],
    "id": "SP:a2a45771c38d3ef3a077856a856570ff01492ea0",
    "references": [
        {
            "authors": [
                "G. Agrawal"
            ],
            "title": "Applications of nonlinear fiber optics (Elsevier",
            "year": 2001
        },
        {
            "authors": [
                "B.J. Dixon",
                "R.D. Pollard",
                "S. Iezekiel"
            ],
            "title": "Orthogonal frequency-division multiplexing in wireless communication systems with multimode fiber feeds",
            "venue": "IEEE Transactions on Microw. Theory Tech",
            "year": 2001
        },
        {
            "authors": [
                "N Broderick"
            ],
            "title": "Large mode area fibers for high power applications",
            "venue": "Opt. Fiber Technol",
            "year": 1999
        },
        {
            "authors": [
                "Gray",
                "D. R"
            ],
            "title": "Real-time modal analysis via wavelength-swept spatial and spectral (s2) imaging",
            "venue": "IEEE Photonics Technol. Lett. 28,",
            "year": 2016
        },
        {
            "authors": [
                "M Eftekhar"
            ],
            "title": "Instant and efficient second-harmonic generation and downconversion in unprepared graded-index multimode fibers",
            "venue": "Opt. Lett. 42,",
            "year": 2017
        },
        {
            "authors": [
                "V. Serkin",
                "Belyaeva",
                "T. Nonlinear solitonic analogues of coherent",
                "squeezed states"
            ],
            "title": "Graded-index fiber solitons and breathing spherically symmetric bec clouds",
            "venue": "Optik 176, 38\u201348",
            "year": 2019
        },
        {
            "authors": [
                "F. Wang",
                "M. Xiao",
                "K. Sun",
                "Wei",
                "Q.-H"
            ],
            "title": "Generation of radially and azimuthally polarized light by optical transmission through concentric circular nanoslits in ag films",
            "venue": "Opt. express 18,",
            "year": 2010
        },
        {
            "authors": [
                "H Kim"
            ],
            "title": "Metallic fresnel zone plate implemented on an optical fiber facet for super-variable focusing of light",
            "venue": "Opt. express 25,",
            "year": 2017
        },
        {
            "authors": [
                "W. Chen",
                "W. Han",
                "D.C. Abeysinghe",
                "R.L. Nelson",
                "Q. Zhan"
            ],
            "title": "Generating cylindrical vector beams with subwavelength concentric metallic gratings fabricated on optical fibers",
            "venue": "J. Opt",
            "year": 2010
        },
        {
            "authors": [
                "H. Kim",
                "E.T. Rogers"
            ],
            "title": "Sub-wavelength annular-slit-assisted superoscillatory lens for longitudinally-polarized superresolution focusing",
            "venue": "Sci. Reports 10,",
            "year": 2020
        },
        {
            "authors": [
                "H. Kim"
            ],
            "title": "Numerical analysis of protection method of metallic sub-wavelength concentric arrays for radially polarized light selection and its applications",
            "venue": "Sensors 21,",
            "year": 2021
        },
        {
            "authors": [
                "K. Kitamura",
                "K. Sakai",
                "S. Noda"
            ],
            "title": "Sub-wavelength focal spot with long depth of focus generated by radially polarized, narrow-width annular beam",
            "venue": "Opt. express 18,",
            "year": 2010
        },
        {
            "authors": [
                "F. Tang",
                "Y. Wang",
                "L. Qiu",
                "W. Zhao",
                "Y. Sun"
            ],
            "title": "Super-resolution radially polarized-light pupil-filtering confocal sensing technology",
            "venue": "Appl. optics 53,",
            "year": 2014
        },
        {
            "authors": [
                "J. Demas",
                "S. Ramachandran"
            ],
            "title": "Sub-second mode measurement of fibers using c 2 imaging",
            "venue": "Opt. express 22,",
            "year": 2014
        },
        {
            "authors": [
                "J. Nicholson",
                "A.D. Yablon",
                "S. Ramachandran",
                "S. Ghalmi"
            ],
            "title": "Spatially and spectrally resolved imaging of modal content in large-mode-area fibers",
            "venue": "Opt. express 16,",
            "year": 2008
        },
        {
            "authors": [
                "Y Ma"
            ],
            "title": "Fiber-modes and fiber-anisotropy characterization using low-coherence interferometry",
            "venue": "Appl. Phys. B",
            "year": 2009
        },
        {
            "authors": [
                "B. Kim",
                "J. Na",
                "J. Kim",
                "H. Kim",
                "Y. Jeong"
            ],
            "title": "Modal decomposition of fiber modes based on direct far-field measurements at two different distances with a multi-variable optimization algorithm",
            "venue": "Opt. Express",
            "year": 2021
        },
        {
            "authors": [
                "T. Kaiser",
                "D. Flamm",
                "S. Schr\u00f6ter",
                "M. Duparr\u00e9"
            ],
            "title": "Complete modal decomposition for optical fibers using cgh-based correlation filters",
            "venue": "Opt. express 17,",
            "year": 2009
        },
        {
            "authors": [
                "Shastri",
                "B. J"
            ],
            "title": "Photonics for artificial intelligence and neuromorphic computing",
            "venue": "Nat. Photonics",
            "year": 2021
        },
        {
            "authors": [
                "K. Yao",
                "R. Unni",
                "Zheng",
                "Y. Intelligent nanophotonics"
            ],
            "title": "merging photonics and artificial intelligence at the nanoscale",
            "venue": "Nanophotonics 8, 339\u2013366",
            "year": 2019
        },
        {
            "authors": [
                "Y An"
            ],
            "title": "Deep learning-based real-time mode decomposition for multimode fibers",
            "venue": "IEEE J. Sel. Top. Quantum Electron",
            "year": 2020
        },
        {
            "authors": [
                "X Fan"
            ],
            "title": "Mitigating ambiguity by deep-learning-based modal decomposition method",
            "venue": "Opt. Commun. 471,",
            "year": 2020
        },
        {
            "authors": [
                "B. Yan",
                "J. Zhang",
                "M. Wang",
                "Y. Jiang",
                "S. Mi"
            ],
            "title": "Degenerated mode decomposition with convolutional neural network for few-mode fibers",
            "venue": "Opt. & Laser Technol",
            "year": 2022
        },
        {
            "authors": [
                "F.K. Fatemi",
                "G. Beadie"
            ],
            "title": "Spatially-resolved rayleigh scattering for analysis of vector mode propagation in few-mode fibers",
            "venue": "Opt. Express",
            "year": 2015
        },
        {
            "authors": [
                "Y Jeong"
            ],
            "title": "Multi-kilowatt single-mode ytterbium-doped large-core fiber laser",
            "venue": "J. Opt. Soc. Korea",
            "year": 2009
        }
    ],
    "sections": [
        {
            "text": "In this paper, a mode decomposition (MD) method for degenerated modes has been studied. Convolution neural network (CNN) has been applied for image training and predicting the mode coefficients. Four-fold degenerated LP11 series has been the target to be decomposed. Multiple images are regarded as an input to decompose the degenerate modes. Total of seven different images, including the full original near-field image, and images after linear polarizers of four directions (0\u25e6, 45\u25e6, 90\u25e6, and 135\u25e6), and images after two circular polarizers (right-handed and left-handed) has been considered for training, validation, and test. The output label of the model has been chosen as the real and imaginary components of the mode coefficient, and the loss function has been selected to be the root-mean-square (RMS) of the labels. The RMS and mean-absolute-error (MAE) of the label, intensity, phase, and field correlation between the actual and predicted values have been selected to be the metrics to evaluate the CNN model. The CNN model has been trained with 100,000 three-dimensional images with depths of three, four, and seven. The performance of the trained model was evaluated via 10,000 test samples with four sets of images - images after three linear polarizers (0\u25e6, 45\u25e6, 90\u25e6) and image after right-handed circular polarizer - showed 0.0634 of label RMS, 0.0292 of intensity RMS, 0.1867 rad of phase MAE, and 0.9978 of average field correlation. The performance of 4 image sets showed at least 50.68% of performance enhancement compared to models considering only images after linear polarizers."
        },
        {
            "heading": "1 Introduction",
            "text": "Because of the boost in data traffic and intensity of high-power lasers, the demands for multimode optical waveguides have been increasing1\u20133. multimode waveguides have an advantage not only in communications and high-power transmissions, but also in various application fields such as imaging, nonlinear optics, and quantum physics4\u20136. In specific, multimode waveguide is capable to generate or transmit radially polarized light, which is suitable for optical trapping, machining, and longitudinal focusing7\u201313. To understand the ratio of different modes, modal decomposition (MD) technique is inevitable. MD has been studied intensively, and achieved in various methods, such as cross-correlated imaging, spatially and spectrally resolved imaging, low-coherence interferometry, multi-variable optimization algorithm, and correlation filter14\u201318. Thanks to various algorithms and increase in computing power, artificial intelligence has been explosively studied and applied in various fields, including the optics research field19, 20. Especially, convolution neural network (CNN) technique which is proper for image process has been applied in various fields, including MD21\u201323. [21] has studied MD for one polarization state from near-field image, and [22] has applied far-field images as additional input data. However, these existing studies have not considered degenerated modes. LP01 mode is two-fold degenerated, and LP11 mode is four-fold degenerated, which are T M01,T E01, and two HE21 modes. To obtain the specific mode ratio such as radially polarized mode, the coefficient of each mode is required. These degenerated modes show exactly identical near-field profiles, therefore it is difficult to exactly decompose the degenerated modes by a single near-field image. Recently, [23] has studied MD for degenerated modes using polarization filters. The results were remarkable which showed 99.1% of field correlations. The study used three polarized images, and the LP11 mode is a four-fold degenerated state, therefore three polarized images are the minimum input to examine the weights of four modes. However, as the image shows only the intensity of the complex field, images after LPs are unable to distinguish the rotating direction of circular or elliptical polarized lights. In this paper, images after linear polarizers (LPs) and circular polarizers (CPs) are applied to compare the degenerated modes. Four LP11 groups are considered, and six additional near-field images after LPs and CPs are considered. Four images after LPs of direction with x (0\u25e6), x+ y (45\u25e6), y (90\u25e6), and x\u2212 y (135\u25e6), and two images after right-handed CP (RHCP) and left-handed CP (LHCP) are considered. Among the seven images, three, four, and seven sets of images are chosen to train the CNN model. Eigenmodes have been obtained and reproduced based on numerical simulations, and sample images are also calculated based ar X iv :2 20 7. 03 48\n9v 1\n[ cs\n.C V\n] 8\nJ ul\n2 02\n2\non eigenmodes from numerical results. The images are stacked to form a three-dimensional tensor with a depth of three, four, and seven and are regarded as an input of CNN, and the model is trained by generated images."
        },
        {
            "heading": "2 Principles and Methods",
            "text": ""
        },
        {
            "heading": "2.1 Data preparation",
            "text": "The electric field of waveguide can be decomposed by linear combination of its eigenmodes, such as following equation.\n~Enet(r,\u03b8) = N\n\u2211 n=1 Cn~En(r,\u03b8), (1)\nwhere Cn is the complex coefficient of the eigenmode ~En. The complex coefficient Cn can be expressed as both intensity-phase form and real-imaginary form, such as following equation.\nCn = \u03c1nexp( j\u03c6n) = xn + jyn (2)\nThe modes of interest in this paper are LP11 series, which are T E01,T M01, and two HE21 modes. Each mode can be expressed as the following equations.\n~ET E01(r,\u03b8) = B(r)(\u2212sin\u03b8ax + cos\u03b8ay) ~ET M01(r,\u03b8) = B(r)(cos\u03b8ax + sin\u03b8ay) ~EHE21o(r,\u03b8) = B(r)(\u2212sin\u03b8ax\u2212 cos\u03b8ay) ~EHE21e(r,\u03b8) = B(r)(\u2212cos\u03b8ax + sin\u03b8ay)\n(3)\nwhere B(r) is the radial distribution of LP11, which is generally a Bessel function24. The mode profile of LP11 series has been calculated via finite element method via COMSOL. The multimode waveguide has been selected to be a conventional multimode fiber, FG025LJA (Thorlabs), a step-index multimode fiber with 0.1 of NA, and a core diameter of 25 um. The operation wavelength has been assumed to be 1064 nm, which is a typical value for Yb doped lasers25. Hereinafter, the four modes, T E01,T M01,HE21o, and HE21e are indexed as mode 1, 2, 3, and 4, respectively. The degenerated LP11 series can be expressed by four imaginary coefficients C1,C2,C3, and C4. The net intensity |~E2| is not phase-sensitive, so one could tune one coefficient to be real, or phase to be 0. Hereinafter, the phase is tuned as C1 to be a positive real number, which indicates \u03c61 = 0, xn > 0, and y1 = 0. Now to generate a degenerated sample, four random coefficients are generated. The coefficients are weighed to each eigenmode and the final near-field image is generated. Not only the image without the polarizer, but images after four LPs \u2013 x (0\u25e6), x+ y (45\u25e6), y (90\u25e6), and x\u2212 y (135\u25e6) \u2013 and two CPs with different rotation directions - RHCP and LHCP - are also calculated and generated. The pixel number of the generated image has been chosen to be 121\u00d7121, where the core region has been divided into 100 pieces, and 10% margin on both sides was regarded as the area of interest. However, as discussed previously, the left half of the image has an identical tendency to the right half, so taking half of the image is enough for comparison on degenerated LP11 series MD. Therefore, the tenor size of the final input for training becomes 61\u00d7121\u00d7n, where n is the number of images selected in a single case. Generated seven images for four eigenmodes are shown in Fig. 1. The electric vector field is shown within the unpolarized full image.\nFrom Fig. 1, it seems that the modes are available to be compared only by using three images after three LPs. As the degenerated mode has four unknown coefficients C1 \u223cC4, and the problem is to find the ratio between four variables, three equations are enough to solve the problem. However, the image only shows the absolute value not the exact complex value, three images are not enough for some case. Fig. 2 shows two different mixed modes. The first and second mixed mode is chosen to be sum of T E01 mode and T M01 mode with different phase constant, which can be expressed as ~E1\u2212 i~E2, respectively. As the electric field direction of T E01 mode and T M01 mode are perpendicular in all the regions, the electric field of mixed mode becomes circularly polarized in every positions. Therefore, it is unavailable to distinguish two modes only via LP. In other words, the MD system using LP cannot compare two perpendicular modes have leading phase or retarding phase. It is shown in Fig. 2 that two different modes show exactly the same images after all directions of LPs. In this paper, four sets of images and seven sets of images are considered to be the input. Four images are selected to be the images after LPs of angle with x (0\u25e6), x+ y (45\u25e6) and y (90\u25e6), and an additional image after RHCP. Seven sets are chosen to be all the images depicted in Fig. 1 and Fig. 2. For comparison, case of three LPs are also tested.\n2/8"
        },
        {
            "heading": "2.2 CNN Model",
            "text": "The CNN model has been constructed for MD. The size of the input is selected to be three, four, and seven groups of 61\u00d7121 images, resulting in 61\u00d7121\u00d7n images where n =3,4, and 7. The input image goes through a CNN network, which is composed of four convolution rectified linear unit (ReLU) layers, three max pooling layers, a flatten layer, two fully connected ReLu layers, three dropout layers, and the output target of 7 tanh layer. To avoid overfitting, all layers have 10\u22128 L2 regulation, and the dropout ratio of 5% has been applied. The full system is shown in Fig. 3. Note that the numbers at the convolution block of Fig. 3 represent the filter size of the convolution tensor, and the size of the block represents the shape of the output after the layer. The loss of the model was selected to be root-mean-square (RMS), or mean-squared-error (MSE). In terms of loss function, [22] has used field correlation function. However, the degenerated case shows similar correlation functions, so in this paper, the loss function is assumed to be RMS between the values. It is notable that the phase and intensity are different units, so if coefficient \u03c1 and \u03c6 are used to measure loss such as [21], one must carefully determine the weight of intensity and phase. It is reasonable to assume the loss between the actual coefficient Cn,a and the predicted coefficient Cn,p to be the distance between the two imaginary values. The distance is available to be expressed as \u221a (xn,a\u2212 xn,p)2 +(yn,a\u2212 yn,p)2, so if the output label is determined to be x1,x2,y2,x3,y3,x4, and y4, the RMS or MSE will represent the distance between the answer and predicted value. The labels are normalized, the largest value to become 1. Labels are denoted as zn, where z1,2,4,6 = x1,2,3,4 and y2,3,4 = z3,5,7. Note that the first mode is tuned to be real, so y1 is always 0, which can be removed from the output label. The RMS loss of real and complex components, will be referred to hereinafter as label RMS. The label RMS is shown in the\n3/8\nfollowing equation.\nLabel RMS =\n\u221a \u22114n=1(x2n,a\u2212 x2n,p)+\u22114n=2(y2n,a\u2212 y2n,p)\n7 = \u221a\u221a\u221a\u221a 7\u2211 n=1 (z2n,a\u2212 z2n,p) = \u221a \u2206z2 (4)\nThe optimizer of model has been chosen to be \u201cADAM\u201d, and the batch size was selected as 128. 300 epoch of training was performed with 100,000 training sets and 3,000 validation sets. After training, the mode intensity ratio \u03c1 , phase \u03c6 and reconstructed field images have been calculated from the predicted labels. The metric of the model was evaluated in terms of RMS, mean-absolute-error (MAE) and the field correlation between the actual and seven reconstructed near-field images, which are the original full image and six images after the polarizers.\n4/8"
        },
        {
            "heading": "3 Results",
            "text": "The model is trained with 100,000 generated 61\u00d7121\u00d7n training images with 3000 validation sets, and the RMS loss in terms of epoch is shown in Fig. 4 for three cases, n =3, 4, and 7. RMS of the training set and validation set are depicted, respectively. It is clear that the case of n = 3, which only considers images after LPs, converges slower, and shows higher loss compared to the cases which consider image after CP. Both case of n =4 and 7, which consider images after CP, shows similar converge speed and losses.\nTo evaluate the performance of the model, the model predicted 10,000 new test sets. From the predicted seven labels, obtain four weight coefficients (\u03c11 \u223c \u03c14) and three relative phases(\u03c62 \u223c \u03c64), and the field correlation of seven images are inversely calculated. The label MAE (|\u2206z|), label RMS ( \u221a \u2206z2), MAE and RMS of weight coefficient (|\u2206\u03c1| and \u221a \u2206\u03c12), normalized\naverage difference (MAE) of phase (|\u2206\u03c6 |/2\u03c0), the field correlation of the full unpolarized image (Corr f ull), and the average of seven field correlations (Corr) have been calculated and shown in Table 1. Note the angle difference angle \u2206\u03c1 has been calculated from the angle of Cn,a/Cn,p. It is shown that all the cases of n =4 and 7 which considered images after CP show better performance compared to the case of n = 3 which only considered images after LP. Especially the average correlation of n = 3 is less than 99%. Because the case of n = 3 is unable to compare the direction of circular or Elliptical polarized light, the field correlations of images after RHCP and LHCP are relatively low, which are calculated as 0.9855 and 0.9859. The performance enhancement between the case of n =3 and 4 is also calculated and shown in the last row in Table 1. Note that the loss of correlation has been regarded as 1\u2212Corr. It is shown that all the metrics showed at least 50% of reduced loss, which indicates the case with the CP predicts the degenerated mode with higher accuracy.\n|\u2206z| \u221a \u2206z2 |\u2206\u03c1| \u221a\n\u2206\u03c12 |\u2206\u03c6 |/2\u03c0 Corr f ull Corr n = 3 0.0999 0.0773 0.0516 0.0435 0.0449 0.9949 0.9887 n = 4 0.0634 0.0513 0.0291 0.0247 0.0297 0.9978 0.9963 n = 7 0.0516 0.0417 0.0236 0.0200 0.0244 0.9988 0.9976 n = 3 vs 4 (%) 57.57 50.68 77.32 76.11 51.18 131.82 205.41\nTable 1. Calculated metrics for n =3, 4 and 7.\nThe metrics \u2013 RMS of weight coefficient (\n\u221a\n\u2206\u03c12), MAE of normalized phase (|\u2206\u03c6 |/2\u03c0), and field correlation of the full\nimage (Corr f ull) \u2013 sorted by the label RMS ( \u221a\n\u2206z2), are depicted in Fig. 5 for the case of n =3, 4, and 7. It is shown that low label loss tends to show high field correlation, and low mode weight MAE and phase MAE. However, the metrics are not exactly correlated to the label MAE, where some of the outliers are observed where low label MAE loss has high intensity/phase loss or\n5/8\nlow field correlation. The fact indicates the field correlation is not the best metric to be optimized while training, where similar mode images can be generated from different combinations. One may use the seven field correlations as a metric, however, it would add complexity to the calculation. Comparing the three cases, it is obvious that the case of n = 3 shows the highest loss. The label RMS (green solid line) has a higher value compared to other cases (n = 4,7). The intensity weight and phase difference of n = 3 also show more outliers. For the case of n = 4 and 7, most of intensity and phase losses (red and black dots) are positioned at the bottom line and the field correlation (blue dots) is mostly shown at the top line. From the results, it is clear that the cases which considered the image after CP shows higher performance. The case of n =4 and 7 shows similar performance, so the case of four sets of images is assumed to be proper which requires low memory and calculation time.\nThe comparison of modal weight \u03c1 , phase \u03c6 , and the seven images for the case of n = 4 are shown in Fig. 6. The samples were chosen as the lowest quartile, median, and highest quartile in terms of the label MAE loss \u2013 which has 2500th,5000th, and 7500th smallest label MAE loss. It is clear that the coefficients and the images show relatively good matching between the actual value/image and predicted ones."
        },
        {
            "heading": "4 Discussions",
            "text": "The MD study based on CNN has not been thoroughly studied. The metrics, loss function, and method to verify the model are not standardized. For in case of loss function, the results show that field correlation is not a proper metric to understand the exact ratio of each mode. Using both intensity and phase, the weight function on different dimensions is another hyper-parameter to be optimized. Therefore, the paper proposes the real and imaginary component of the modal coefficient is the best choice to be the label, and MSE or RMS will simply be the loss to train and predict the model. Most of the MD studies used a small number of test sets. Samples for comparisons on coefficients and images are selectively chosen, without any standards or metrics. In this paper, 10,000 test samples evaluated the performance of the trained model, and quartiles based on loss have been selected as an example to be shown. As the labels are not discrete but continuous, numerous samples are required to exactly predict the\n6/8\nMD system. For example, if each label is divided into five levels, - which leads to under 20% of loss - samples of 5n will be required, where n is the number of labels. Four modes need seven labels, which requires 78125 samples. However, as the mode theory is studied intensively, it is available to generate training sets. If the number of modes increases, the required training set for model prediction will exponentially increase. Assuming one linear polarization and using LP series will reduce the label by half. However, the LP based model will fail to examine the ratio of cylindrical vector modes such as T M01 mode or T E01 mode. In addition, if one desires to use two-dimensional input image, connecting multiple images horizontally (or vertically) - which generates 61\u00d7(121*n)\u00d71 image in the case of the paper - will perform similar results. The depth of the CNN layers must be reduced, as the 3D CNN layer calculates the third dimension of the tensors at once."
        },
        {
            "heading": "5 Conclusion",
            "text": "The paper has proposed CNN model for MD on degenerated modes based on four or seven sets of input images from LPs and CPs. The CPs detect the direction of circularly polarized light and enhances the performance of the CNN model. LP11 series has been decomposed from 7 images including the full image and images from four LPs of 0\u25e6, 45\u25e6, 90\u25e6, and 135\u25e6 and two CPs, RHCP and LHCP. Output labels of the model have been chosen to be the real and imaginary parts of mode coefficients. The model was trained via 100,000 training sets, and 10,000 test sets were evaluated. The trained model showed 0.0634 of label RMS, 0.0292 of intensity RMS, 0.1867 rad of phase MAE, and 0.9978 of average field correlation for case of 4 image sets. The performance of 4 image sets showed at least 50.68% of performance enhancement compared to models considering only images after LPs. Quartiles in terms of label RMS have been selected to visualize the performance. The predicted values showed relatively reasonable match compared to the actual value. The study is believed to be applied to obtain the coefficient of cylindrical vector mode. In addition, the proposed methods to decompose degenerate modes, select the loss function, and standards to select examples are expected to assist further CNN based MD studies or related works."
        }
    ],
    "title": "Convolution Neural Network based Mode Decomposition for Degenerated Modes via Multiple Images from Polarizers",
    "year": 2022
}