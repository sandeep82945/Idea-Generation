{
    "abstractText": "This work proposes a transformer architecture for user-level classification of gambling addiction and depression that is trainable end-to-end. As opposed to other methods that operate at the post level, we process a set of social media posts from a particular individual, to make use of the interactions between posts and eliminate label noise at the post level. We exploit the fact that, by not injecting positional encodings, multi-head attention is permutation invariant and we process randomly sampled sets of texts from a user after being encoded with a modern pretrained sentence encoder (RoBERTa / MiniLM). Moreover, our architecture is interpretable with modern feature attribution methods and allows for automatic dataset creation by identifying discriminating posts in a user\u2019s text-set. We perform ablation studies on hyper-parameters and evaluate our method for the eRisk 2022 Lab on early detection of signs of pathological gambling and early risk detection of depression. The method proposed by our team BLUE obtained the best ERDE5 score of 0.015, and the second-best ERDE50 score of 0.009 for pathological gambling detection. For the early detection of depression, we obtained the second-best ERDE50 of 0.027.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ana-Maria Bucur"
        },
        {
            "affiliations": [],
            "name": "Adrian Cosma"
        },
        {
            "affiliations": [],
            "name": "Liviu P. Dinu"
        },
        {
            "affiliations": [],
            "name": "Paolo Rosso"
        }
    ],
    "id": "SP:eef2ec957f20448734b28e15ed43203403229804",
    "references": [
        {
            "authors": [
                "M. De Choudhury",
                "S. De"
            ],
            "title": "Mental health discourse on reddit: Self-disclosure, social support, and anonymity",
            "venue": "in: Eighth international AAAI conference on weblogs and social media,",
            "year": 2014
        },
        {
            "authors": [
                "M.M. Tadesse",
                "H. Lin",
                "B. Xu",
                "L. Yang"
            ],
            "title": "Detection of suicide ideation in social media forums using deep learning, Algorithms",
            "year": 2019
        },
        {
            "authors": [
                "E.A. R\u00edssola",
                "S.A. Bahrainian",
                "F. Crestani"
            ],
            "title": "A dataset for research on depression in social media",
            "venue": "in: Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization,",
            "year": 2020
        },
        {
            "authors": [
                "A.-M. Bucur",
                "A. Cosma",
                "L.P. Dinu"
            ],
            "title": "Early risk detection of pathological gambling, self-harm and depression using bert",
            "venue": "in: CLEF (Working Notes),",
            "year": 2021
        },
        {
            "authors": [
                "M. Sundararajan",
                "A. Taly",
                "Q. Yan"
            ],
            "title": "Axiomatic attribution for deep networks, in: International conference on machine learning, PMLR",
            "year": 2017
        },
        {
            "authors": [
                "J. Parapar",
                "P.M. Rodilla",
                "D.E. Losada",
                "F.A. Crestani"
            ],
            "title": "Overview of erisk 2022: Early risk prediction on the internet, in: Experimental IR Meets Multilinguality, Multimodality, and Interaction",
            "venue": "13th International Conference of the CLEF Association,",
            "year": 2022
        },
        {
            "authors": [
                "K.S. Philander"
            ],
            "title": "Identifying high-risk online gamblers: A comparison of data mining procedures, International Gambling Studies",
            "year": 2014
        },
        {
            "authors": [
                "X. Deng",
                "T. Lesch",
                "L. Clark"
            ],
            "title": "Applying data science to behavioral analysis of online gambling",
            "venue": "Current Addiction Reports",
            "year": 2019
        },
        {
            "authors": [
                "A. Cerasa",
                "D. Lofaro",
                "P. Cavedini",
                "I. Martino",
                "A. Bruni",
                "A. Sarica",
                "D. Mauro",
                "G. Merante",
                "I. Rossomanno",
                "M. Rizzuto"
            ],
            "title": "Personality biomarkers of pathological gambling: A machine learning study",
            "venue": "Journal of neuroscience methods",
            "year": 2018
        },
        {
            "authors": [
                "D. Maupom\u00e9",
                "M.D. Armstrong",
                "F. Rancourt",
                "T. Soulas",
                "M.-J. Meurs"
            ],
            "title": "Early detection of signs of pathological gambling, self-harm and depression through topic extraction and neural networks",
            "venue": "in: CLEF (Working Notes),",
            "year": 2021
        },
        {
            "authors": [
                "S. Rude",
                "E.-M. Gortner",
                "J. Pennebaker"
            ],
            "title": "Language use of depressed and depression-vulnerable college students",
            "venue": "Cognition & Emotion",
            "year": 2004
        },
        {
            "authors": [
                "A.-M. Bucur",
                "I.R. Podin\u0103",
                "L.P. Dinu"
            ],
            "title": "A psychologically informed part-of-speech analysis of depression in social media",
            "venue": "in: Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021),",
            "year": 2021
        },
        {
            "authors": [
                "S. Fekete"
            ],
            "title": "The internet-a new source of data on suicide, depression and anxiety: a preliminary study",
            "venue": "Archives of Suicide Research",
            "year": 2002
        },
        {
            "authors": [
                "D. Smirnova",
                "P. Cumming",
                "E. Sloeva",
                "N. Kuvshinova",
                "G.D. Romanov"
            ],
            "title": "Nosachev, Language patterns discriminate mild depression from normal sadness and euthymic state, Frontiers in psychiatry",
            "year": 2018
        },
        {
            "authors": [
                "J.W. Pennebaker",
                "M.E. Francis",
                "R.J. Booth"
            ],
            "title": "Linguistic inquiry and word count",
            "venue": "Liwc",
            "year": 2001
        },
        {
            "authors": [
                "M. Trotzek",
                "S. Koitka",
                "C.M. Friedrich"
            ],
            "title": "Linguistic metadata augmented classifiers at the clef 2017 task for early detection of depression",
            "venue": "in: CLEF (Working Notes),",
            "year": 2017
        },
        {
            "authors": [
                "D.G. Funez",
                "M.J.G. Ucelay",
                "M.P. Villegas",
                "S. Burdisso",
                "L.C. Cagnina",
                "M. Montes-y G\u00f3mez",
                "M. Errecalde"
            ],
            "title": "Unsl\u2019s participation at erisk 2018 lab",
            "venue": "in: CLEF (Working Notes),",
            "year": 2018
        },
        {
            "authors": [
                "M. Trotzek",
                "S. Koitka",
                "C.M. Friedrich"
            ],
            "title": "Word embeddings and linguistic metadata at the clef 2018 tasks for early detection of depression and anorexia",
            "venue": "in: CLEF (Working Notes),",
            "year": 2018
        },
        {
            "authors": [
                "A. Bucur",
                "L.P. Dinu"
            ],
            "title": "Detecting early onset of depression from social media text using learned confidence scores",
            "venue": "in: Proceedings of the Seventh Italian Conference on Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "M.E. Aragon",
                "A.P. Lopez-Monroy",
                "L.-C.G. Gonzalez-Gurrola",
                "M. Montes"
            ],
            "title": "Detecting mental disorders in social media through emotional patterns-the case of anorexia and depression",
            "venue": "IEEE Transactions on Affective Computing",
            "year": 2021
        },
        {
            "authors": [
                "A.-S. Uban",
                "B. Chulvi",
                "P. Rosso"
            ],
            "title": "An emotion and cognitive based analysis of mental health disorders from social media data, Future Generation",
            "venue": "Computer Systems",
            "year": 2021
        },
        {
            "authors": [
                "J. Gehring",
                "M. Auli",
                "D. Grangier",
                "D. Yarats",
                "Y.N. Dauphin"
            ],
            "title": "Convolutional sequence to sequence learning",
            "venue": "in: International Conference on Machine Learning, PMLR,",
            "year": 2017
        },
        {
            "authors": [
                "J. Lee",
                "Y. Lee",
                "J. Kim",
                "A. Kosiorek",
                "S. Choi",
                "Y.W. Teh"
            ],
            "title": "Set transformer: A framework for attention-based permutation-invariant neural networks",
            "venue": "in: International Conference on Machine Learning, PMLR,",
            "year": 2019
        },
        {
            "authors": [
                "S.M. Kazemi",
                "R. Goel",
                "S. Eghbali",
                "J. Ramanan",
                "J. Sahota",
                "S. Thakur",
                "S. Wu",
                "C. Smyth",
                "P. Poupart",
                "M. Brubaker"
            ],
            "title": "Time2vec: Learning a vector representation of time, arXiv preprint arXiv:1907.05321 (2019)",
            "year": 2019
        },
        {
            "authors": [
                "Y. Liu",
                "M. Ott",
                "N. Goyal",
                "J. Du",
                "M. Joshi",
                "D. Chen",
                "O. Levy",
                "M. Lewis",
                "L. Zettlemoyer",
                "V. Stoyanov",
                "Roberta"
            ],
            "title": "A robustly optimized BERT pretraining approach, CoRR abs/1907.11692 (2019)",
            "venue": "URL: http://arxiv.org/abs/1907.11692. arXiv:1907.11692",
            "year": 1907
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "in: ICLR (Poster),",
            "year": 2015
        },
        {
            "authors": [
                "L.N. Smith"
            ],
            "title": "Cyclical learning rates for training neural networks",
            "venue": "IEEE winter conference on applications of computer vision (WACV),",
            "year": 2017
        },
        {
            "authors": [
                "S.M. Lundberg",
                "S.-I. Lee"
            ],
            "title": "A unified approach to interpreting model predictions, Advances in neural information processing systems",
            "year": 2017
        },
        {
            "authors": [
                "M.T. Ribeiro",
                "S. Singh",
                "C. Guestrin"
            ],
            "title": " why should i trust you?\" explaining the predictions of any classifier",
            "venue": "in: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining,",
            "year": 2016
        },
        {
            "authors": [
                "D.E. Losada",
                "F. Crestani"
            ],
            "title": "A test collection for research on depression and language use, in: International Conference of the Cross-Language Evaluation Forum for",
            "venue": "European Languages,",
            "year": 2016
        },
        {
            "authors": [
                "D.E. Losada",
                "F.A. Crestani",
                "J. Parapar"
            ],
            "title": "Overview of erisk at clef 2019: Early risk prediction on the internet (extended overview)",
            "venue": "in: CLEF (Working Notes),",
            "year": 2019
        },
        {
            "authors": [
                "F. Sadeque",
                "D. Xu",
                "S. Bethard"
            ],
            "title": "Measuring the latency of depression detection in social media",
            "venue": "in: Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining,",
            "year": 2018
        },
        {
            "authors": [
                "E. R\u00edssola",
                "S.A. Bahrainian",
                "F. Crestani"
            ],
            "title": "A dataset for research on depression",
            "venue": "Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization,",
            "year": 2020
        },
        {
            "authors": [
                "A. Qu",
                "J. Niu",
                "S. Mo"
            ],
            "title": "Explore better relative position embeddings from encoding perspective for transformer models",
            "venue": "in: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Keywords set transformer, sentence encoder, gambling disorder detection, depression detection, social media"
        },
        {
            "heading": "1. Introduction",
            "text": "How much can one know about someone from their social media interactions? Billions of people1 use social media sites like Facebook, Instagram, Twitter, and Reddit every day. While some sites like Facebook and Instagram encourage users to use their real names, websites such as Reddit are often praised for enabling users to hide between a pseudonym, offering the illusion of privacy. Under the guise of anonymity, users tend to post more personal information related to their lives and their everyday struggles instead of striving to maintain an image and a persona when their identities are open [1]. Many aspects of a user\u2019s personal life can be uncovered in their posting history. Of course, not one single post can be all-encompassing, but rather the information is scattered across many unrelated comments and posts. For instance, on\nCLEF 2022: Conference and Labs of the Evaluation Forum, September 5\u20138, 2022, Bologna, Italy \" ana-maria.bucur@drd.unibuc.ro (A. Bucur); cosma.i.adrian@gmail.com (A. Cosma); ldinu@fmi.unibuc.ro (L. P. Dinu); prosso@dsic.upv.es (P. Rosso) 0000-0003-2433-8877 (A. Bucur); 0000-0003-0307-2520 (A. Cosma); 0000-0002-7559-6756 (L. P. Dinu); 0000-0002-8922-1242 (P. Rosso)\n\u00a9 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings http://ceur-ws.org ISSN 1613-0073 CEUR Workshop Proceedings (CEUR-WS.org)\n1https://www.statista.com/statistics/272014/global-social-networks-ranked-by-number-of-users/\nar X\niv :2\n20 7.\n00 75\n3v 1\n[ cs\n.C L\n] 2\nJ ul\n2 02\n2\nthe r/relationship_advice2 subreddit a user might reveal their gender and age when discussing intimate relationship struggles, while on r/depression3 a user might provide clues for their internal conflicts and experiences.\nIn the task of mental health disorders detection from social media text, many approaches operate on the post-level [2, 3, 4], considering that, for instance, if a user is depressed, then all their posts might contain some information regarding this issue. However, we posit that this method of post-level classification is unsuitable - many posts are unrelated and uninformative to the particular task. Their interaction, however, might contain clues to the mental well-being of a user.\nAs such, we propose an architecture that performs user-level classification by processing a set of posts from a user. We exploit the fact that the multi-head attention operation in transformers is permutation invariant and inputs multiple texts from a single user into the network, modeling their interaction and classifying the user. This approach has several advantages: (i) it is trainable end-to-end, mitigating the need for hand-crafted construction of global user features (ii) it is robust to label noise, as some posts might be uninformative, the network learns to ignore them in the decision and (iii) it is interpretable, using feature attribution methods [5] we can extract the most important posts for the decision.\nThe Early Risk Prediction on the Internet (eRisk)4 Lab started in 2017 with one pilot task and, since then, tacked the early risk detection of several mental illnesses: depression, self-harm, eating disorders, and pathological gambling. This work showcases team BLUE\u2019s proposed approach for Tasks 1 and 2 of eRisk 2022 Lab [6], of gambling and depression detection, respectively.\nThe paper makes the following contributions:\n1. We propose a set-based transformer architecture for user-level classification, which makes a decision by processing multiple texts of a particular user.\n2. We show that our architecture is robust to label noise and is interpretable with modern feature attribution methods, allowing it to be used as a dataset filtering tool.\n3. We obtained promising results on the eRisk 2022 tasks on early risk detection of pathological gambling (best ERDE55 score of 0.015 and the second-best ERDE50 score of 0.009) and depression detection (second-best ERDE50 of 0.027)."
        },
        {
            "heading": "2. Related Work",
            "text": "Pathological Gambling For the detection of gambling disorder, the eRisk Lab is the first to use social media data for the assessment of gambling risk. Usually, the automated methods use data from behavioral markers [7, 8] or personality biomarkers [9]. In the first iteration of the task for gambling addiction detection, the best-performing systems were developed by Maupom\u00e9 et al. [10] and Loyola et al. [11]. Maupom\u00e9 et al. [10] used a user-level approach based on the similarity distance between the vector of topic probabilities of the users\u2019 texts to be assessed for pathological gambling risk and testimonials or items from a self-evaluation questionnaire for\n2https://www.reddit.com/r/relationship_advice/ 3https://www.reddit.com/r/depression/ 4https://erisk.irlab.org/ 5Early Risk Detection Error, introduced in Section 5.1\ncompulsive gamblers. By using this method, the authors obtain the best ERDE5 of 0.048. Loyola et al. [11] attain the best ERDE50 (0.020) and latency-weighted F1 (0.693) through a post-level rule-based early alert policy on bag-of-words text representation classified with SVM. Depression Depression detection from social media data is an interdisciplinary topic, and efforts have been made by researchers from both NLP and Psychology to detect different markers of depression found in the online discourse of individuals. Some depression cues found in language are: greater use of the first-person singular pronouns \"I\" [12], lesser use of first-person plural \"we\" [13], increased use of negative or absolutist terms (e.g., \"never\", \"forever\") [14], greater use of verbs at past tense [15].\nFor the task of early detection of depression, the best systems from the first iteration of the task (eRisk 2017) used as input linguistic meta information extracted from the texts such as LIWC [16], readability and hand-crafted features [17] obtaining the best ERDE5 (12.70%) or a combination of linguistic information and temporal variation of terms from users\u2019 posts [18] achieving the best ERDE50 (9.68%). The best-performing systems from eRisk 2018 were the ones from Funez et al. [19] and Trotzek et al. [20]. Funez et al. [19] propose a user-level approach using an SVM classifier on semantic representations that take into account the temporal variation of terms between the users\u2019 posts and achieve an ERDE5 of 8.78%. On the other hand, the best ERDE50 (6.44%) is attained by Trotzek et al. [20] using a chunk-level6 approach using an ensemble of logistic regression classifiers on bag-of-words features. The dataset from the depression detection task from the eRisk Lab was an important resource later used in different research articles tackling the detection problem using approaches such as a neural network architecture on topic modeling features [21], SVM or deep learning architectures using fine-grained emotions features [22] or deep learning methods using content, writing style and emotion features [23]."
        },
        {
            "heading": "3. Method",
            "text": "The transformer encoder, as proposed by Vaswani et al. [24], essentially consists of multiple sequential layers of multi-head attention. Scaled dot-product attention of a query \ud835\udc44 relative to a set of values \ud835\udc49 and a set of keys \ud835\udc3e is computed using the following equation (\ud835\udc51\ud835\udc58 is the dimensionality of the query and keys):\nAttention(\ud835\udc44,\ud835\udc3e, \ud835\udc49 ) = softmax( \ud835\udc44\ud835\udc3e\ud835\udc47\u221a\n\ud835\udc51\ud835\udc58 )\ud835\udc49 (1)\nAs such, multi-head attention consists of multiple applications of the attention mechanism to the same input. The multi-head attention is defined as:\nMultiHead(\ud835\udc44,\ud835\udc3e, \ud835\udc49 ) = Concat(head1, head2 . . . head\u210e)\ud835\udc4a\ud835\udc42\nhead\ud835\udc56 = Attention(\ud835\udc44\ud835\udc4a \ud835\udc44 \ud835\udc56 ,\ud835\udc3e\ud835\udc4a \ud835\udc3e \ud835\udc56 , \ud835\udc49 \ud835\udc4a \ud835\udc49 \ud835\udc56 )\n(2)\nIn this formulation, multi-head attention is permutation invariant, and the current way to inject temporal information into the input sequence is by employing positional encodings [25]. This is useful when processing sequential data such as texts. However, by omitting positional\n6in 2018 the test data was released in chunks of posts, not one post at a time as it is the case in this year\u2019s tasks\nencodings, the transformer essentially acts as a set encoder. Lee et al. [26] introduced the Set Transformer, in which they prove that multi-head attention is permutation invariant and that the Set Transformer is a universal approximator of permutation invariant functions. We make use of this fact to perform user-level classification by processing sets of texts (in the form of social media posts) from a particular user. The intuition behind processing a set of texts from a user is that no single social media post is sufficiently informative for a classifier decision, but rather their interaction and the user behavior as a whole. Moreover, through mean pooling, the inevitable noise (in terms of unrelated posts) is dampened, which aids classification in weakly-supervised scenarios, such as ours, in which a user is labeled rather than all of their posts.\nWe consider a user \ud835\udc56 to contain multiple social media posts \ud835\udc48\ud835\udc56. A set of \ud835\udc3e texts \ud835\udc61 are randomly sampled from \ud835\udc48\ud835\udc56, which defines our text-set \ud835\udc46\ud835\udc56 = {\ud835\udc61\ud835\udc57 \u223c \ud835\udc48\ud835\udc56, \ud835\udc57 \u2208 (1 . . .\ud835\udc3e)}. We sample \ud835\udc3e posts from the user\u2019s history, instead of processing all of them due to memory limitations - some individuals have thousands of posts while others have only in the order of tens. Moreover, stochasticity is introduced in the training procedure, which prevents overfitting. As such, for training, an input batch of size \ud835\udc5b is defined by the concatenation of \ud835\udc5b such text-sets: \ud835\udc35 = {\ud835\udc46\ud835\udc4f1 , \ud835\udc46\ud835\udc4f2 , . . . \ud835\udc46\ud835\udc4f\ud835\udc5b}. We do not consider the relative order of the texts for a particular user, and text-sets are fed into the transformer encoder without using positional encoding. Since some users have a total number of texts smaller than \ud835\udc3e , creating a batch of text-sets is impossible without padding and masking. However, to alleviate this problem, we train with an effective batch size of 1 and chose to employ gradient accumulation to simulate a larger batch size.\nFigure 1 showcases our proposed model architecture for user-level classification. Each text in a text-set is embedded into a fixed-size vector using available pretrained sentence encoder models (i.e., RoBERTa / MiniLM). The text embeddings are fed into the transformer encoder network, and after processing, we perform mean pooling and output the decision. We compute binary cross-entropy at the user-level, for a text-set. The pretrained sentence encoder is frozen and not updated during training.\nBaytas et al. [27] proposed to use a T-LSTM to process social media posts sequentially as a time-series. The authors modify the LSTM architecture to include a relative time component. However, in our case it is unclear how to incorporate such a mechanism into the transformer\narchitecture, aside from using a relative positional encoding [28], which ignores long-ranged dependencies between posts. As such, we chose to ignore the temporal order of the posts and process them directly as a set. The main reason for considering the posts as a set is that in a user\u2019s post history, many posts are uninformative to the modeling task, and by processing a set of texts, label noise is reduced naturally as a direct consequence of the attention mechanism, which assigns more importance to informative posts. However, training with a sufficiently large dataset might achieve the same effect, but previous attempts at post-level classification have proven ineffective [4].\nIn order to assess the impact of the sentence representations, we chose two different sentence encoders: RoBERTa [29] and MiniLM [30]. We chose RoBERTa since it is one of the best performing English language models in downstream tasks [29], and MiniLM, a multi-lingual model, since some users have social media posts in languages other than English. Figure 2 showcases the performance gap between the two sentence encoders, averaged across multiple values of\ud835\udc3e . RoBERTa yields a consistently superior performance across training steps. Similarly, to assess the impact of the text-set size \ud835\udc3e , we performed an ablation study, as shown in Figure 3. We kept the sentence encoder fixed to RoBERTa, and vary the number of texts per user \ud835\udc3e \u2208 {4, 8, 16, 32, 64, 128}. The best performance was achieved with \ud835\udc3e = 16 and \ud835\udc3e = 32 for Tasks 1 and 2, respectively.\nIn our final submission, we chose RoBERTa as a sentence encoder and sampled \ud835\udc3e = 16 texts\nper user for Task 1 and \ud835\udc3e = 32 for Task 2. We used the standard formulation of the transformer network [24], with 4 encoder layers, 8 attention heads each and a dimensionality of 256. Both networks were trained for 120 epochs, with AdamW optimizer [31], with a cyclical learning rate [32] ranging from 0.00001 to 0.0001 across 6 epochs and a batch size of 128. To account for class imbalance, we computed balanced class weights with respect to each dataset and adjusted the loss function accordingly. Finally, we opted for a very high threshold when predicting the final decision.\nOur proposed architecture can be easily interpretable using modern explainability methods for feature attribution [33, 34, 5], such as Integrated Gradients [5]. It automatically identifies social media posts containing signs of mental health disorders and filters out uninformative posts."
        },
        {
            "heading": "4. Interpretability",
            "text": "Since our model operates on sets of social media texts from a particular user, we can employ model explainability methods to assess the importance of a piece of text to the model decision. Through this, automatic filtering and selection of the most indicative posts of a user can be made for use in dataset creation. This idea is similar to R\u00edssola et al. [3], which employed a series of heuristics to recognize posts portraying depression symptoms for use in constructing a post-level training set from existing depression datasets annotated at the user level. As such, we use Integrated Gradients [5] to compute attribution scores for a text-set. The integrated gradients method has been used in NLP to explore the contribution of individual words and phrases to a decision made by a classifier. Since we are not operating on words, but rather on whole texts, this method computes the most important text to the classifier decision.\nFigure 4 showcases selected samples ordered by their attribution score from the validation set of each task. All samples belong to the same user for each task, and the attribution scores are\ncomputed within the respective text-set. Posts with a high positive contribution to the decision contain more explicit descriptions of symptoms, while posts with more negative contributions are mainly unrelated to the particular mental illness. We use the integrated gradients method in one of our runs to select the most important posts in the user history. However, we emphasize that the best application of this approach is for automatic dataset creation in scenarios of weak supervision, which we aim to explore in future work."
        },
        {
            "heading": "5. Results",
            "text": ""
        },
        {
            "heading": "5.1. Evaluation",
            "text": "There are two kinds of evaluation used for measuring the performance of the systems, decisionbased and raking-based. The decision-based evaluation is used for quantifying the capacity of a system to perform the binary classification and predicting if a user is from the positive class (i.e., pathological gambling or depression) or the negative one. It is comprised of standard measures for classification (Precision, Recall, F1) and measures for this specific task of early detection that consider the delay and the speed of the decision. The early risk detection error (ERDE) [35] measures the correct predictions considering a late decision penalty (for predictions taken after the 5 or 50 first submissions of a user). To overcome the limitations of this metric [36], the latency-weighted F1 score [37] was also proposed to measure the performance of early risk detection. Latency measures the delay in detecting true positives based on the median number of submissions seen by the system before taking a decision. The speed of a system that correctly predicts true positives from the first submission is equal to 1, while a slow system which decides after processing hundreds of texts. The latency-weighted F1 combines the F1-score with the delay in decision-taking for true positives. A perfect system should achieve a latency-weighted F1 of 1. Besides the binary classification decisions, the participating teams were asked to also submit a score for estimating the risk of users for the ranking-based evaluation. These scores are used to rank users\u2019 risk for pathological gambling or depression. Standard IR metrics (P@10, NDCG@10, and NDCG@100) are used to measure the models\u2019 ranking-based performance after processing 1, 100, 500, or 1000 submissions."
        },
        {
            "heading": "5.2. Task 1: Early Detection of Signs of Pathological Gambling",
            "text": "The first task proposes the detection of gambling addiction from social media data. This being the second edition of this task, the organizers provided the last year\u2019s test data for training the systems. The dataset was collected from Reddit, following the methodology described by Losada and Crestani [35] and contains a chronological sequence of posts from each user. The training dataset was comprised of 164 pathological gamblers, with a total of 54,674 submissions, and 2,184 control users with 1,073,883 submissions. The test dataset contains 81 users with gambling addiction, summing 14,627 posts, and 1,998 control users with a total of 1,014,122 posts. For the testing phase, the submissions of users were released sequentially, the systems proposed by the participating teams received one submission at a time from all the users. We submitted three runs for the early detection of pathological gambling: Run 0 is comprised of the text-set transformer model using the most recent \ud835\udc3e = 16 posts for prediction; the system\nfor Run 1 is the same text-set transformer model using as input the set of \ud835\udc3e = 16 texts that are most important in a user\u2019s history, selected with Integrated Gradients; Run 2 is a baseline run, using the proposed model architecture for predicting at post-level, on one sample at a time.\nTable 1 showcases the performance of the systems measured using the decision-based measures. Regarding ERDE, our first run (Run 0), using the transformer architecture on the most recent texts from each user, manages to achieve the best ERDE5 score of 0.015, and the secondbest ERDE50 score of 0.009, demonstrating that the system could detect early the true positive cases. The perfect scores for latency\ud835\udc47\ud835\udc43 and speed show that our models were successful at detecting the true positive cases after the first writing. As expected, the baseline run using a post-level approach (Run 2) has the lowest performance. Regarding Run 2, we expected it to achieve the best performance from our submitted runs, as this approach is more aggressive in taking decisions by using for classification the most informative posts from users\u2019 history. Furthermore, our best run from this year\u2019s task surpasses all the runs from our participation in the first iteration of the task in 2021 [4], showing that a user-level approach considering a set of texts from each individual is more suitable than a post-level approach. In Table 2 we show the results of the ranking-based evaluation, in which each team had to submit the rankings of users\u2019 risk for pathological gambling. Our team has excellent results for NDCG and P@10 in all the situations (after 1, 100, 1000, 5000 writings)."
        },
        {
            "heading": "5.3. Task 2: Early Detection of Depression",
            "text": "This year marks the third iteration of the early detection of depression task, continuing the 2017 T1 and 2018 T2 tasks. The organizers provided the data from the previous two editions for training the models. Users from the depression class were labeled by their mention of diagnosis on their Reddit posts (e.g., \"I was diagnosed with depression\"). In contrast, users from the control class are users who do not have any mention of diagnosis in their posts [35]. The training dataset comprises 214 users diagnosed with depression with 270,666 submissions and 1493 control users with a total of 2,959,080 submissions. The test set contains 98 users with depression with 35,332 posts, and 1,302 users in the control group with a total of 687,228 posts. The texts for making the predictions for the testing phase were released sequentially, and the systems from the participating teams had to decide on firing a decision for a specific user or waiting for more data. We submitted three runs for the early detection of depression: Run 0 is the text-set transformer model using the most recent \ud835\udc3e = 32 posts for prediction; for Run 1 we employ the same text-set transformer model using as input the set of \ud835\udc3e = 32 texts that are most important in a user\u2019s history, selected with Integrated Gradients; Run 2 is a baseline run, using the proposed model architecture for predicting at post-level, on one sample at a time.\nIn Table 3 we present the performance of the systems using the decision-based metrics. Our best performing run is the transformer architecture using the most recent texts from users (Run 0), followed by the system that considers only the most informative submissions from each user for the model\u2019s decisions (Run 1). The post-level system (Run 2) has the worst performance. Our three submitted runs achieve high Recall at the expense of lower Precision scores. The precision of our models can be improved by incorporating a mechanism for weighting user posts according to the prevalence of signs of depression [38]. As such, a text-set containing few posts with signs of depression will not induce a positive prediction. Regarding the early detection evaluation, our team has the second-best score on the ERDE50 metric (0.027), while our ERDE5 score is close to the best one. Compared to the best metrics from the 2018 edition\nof this task, when the best ERDE5 and ERDE50 were 0.087 and 0.064, respectively, current systems surpass these scores due to more data being available for training the models and the advancements in the field of machine learning in the last few years. Regarding the standard metrics for classification, a slight improvement was made in terms of F1 score, from 0.64 in 2018 to 0.71 in 2022. The ranking-based evaluation performance from Table 4 shows that for 1 and 1000 writings, our systems attain some of the best scores for P@10 and NDCG."
        },
        {
            "heading": "6. Conclusion",
            "text": "In this work, we proposed a transformer architecture that performs user-level classification of gambling addiction and depression detection. For each individual, the transformer processes a set of texts encoded by a pretrained sentence encoder to model the interactions between posts and mitigate noise in the dataset. Our network is interpretable and allows for automatic dataset creation by filtering uninformative posts in a user\u2019s history. Our method is a promising approach, especially for social media text processing, where a user has many texts: some informative and some unrelated to the particular modeling task. However, their interaction is indicative of the mental state of the user. We attained the best ERDE5 score of 0.015, and the second-best ERDE50 score of 0.009 for pathological gambling detection. For the early detection of depression, we obtained the second-best ERDE50 (0.027).\nFor future work, we aim to extend our method and construct a mechanism for encoding the relative order of a user\u2019s posts with a modified version of relative positional embeddings [39]. While we chose an approach that ignores temporal ordering and processes posts as a set, preserving order is a natural way to increase the expressive power in modeling a user\u2019s entire social media interactions, similar to architectures such as the time-aware LSTM [27]."
        },
        {
            "heading": "Acknowledgments",
            "text": "The work of Ana-Maria Bucur was in the framework of the research project NPRP13S-0206200281. The work of Paolo Rosso was in the framework of the research project PROMETEO/2019/121 (DeepPattern) by the Generalitat Valenciana. The authors thank the EU-FEDER Comunitat Valenciana 2014\u20132020 grant IDIFEDER/2018/025."
        }
    ],
    "title": "An End-to-End Set Transformer for User-Level Classification of Depression and Gambling Disorder",
    "year": 2022
}