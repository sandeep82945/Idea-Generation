{
    "authors": [
        {
            "affiliations": [],
            "name": "Kalyan Talluri"
        },
        {
            "affiliations": [],
            "name": "Angelos Tsoukalas"
        }
    ],
    "id": "SP:9295b5378e2e0ad250fd537b3329e5668b768986",
    "references": [
        {
            "authors": [
                "D Adelman"
            ],
            "title": "Dynamic bid prices in revenue management",
            "venue": "Oper. Res",
            "year": 2007
        },
        {
            "authors": [
                "D Adelman",
                "AJ Mersereau"
            ],
            "title": "Dynamic capacity allocation to customers who remember past service",
            "venue": "Management Sci",
            "year": 2013
        },
        {
            "authors": [
                "RN Bolton",
                "KN Lemon",
                "MD Bramlett"
            ],
            "title": "The effect of service experiences over time on a supplier\u2019s retention of business customers",
            "venue": "Management Sci",
            "year": 2006
        },
        {
            "authors": [
                "T Boone"
            ],
            "title": "Learning and knowledgedepreciation in professional services.Management Sci",
            "venue": "GaneshanR,HicksRL",
            "year": 2008
        },
        {
            "authors": [
                "JD Cotterman"
            ],
            "title": "Compensation Plans for Law Firms, 6th ed. (American Bar Association, Chicago)",
            "year": 2016
        },
        {
            "authors": [
                "G DeCroix",
                "X Long",
                "J Tong"
            ],
            "title": "How service quality variability hurts revenue when customers learn: Implications for dynamic personalized pricing",
            "venue": "Oper. Res",
            "year": 2021
        },
        {
            "authors": [
                "PE Gill",
                "W Murray",
                "MA Saunders"
            ],
            "title": "SNOPT: An SQP algorithm for large-scale constrained optimization",
            "year": 2005
        },
        {
            "authors": [
                "R Gilson",
                "R Mnookin"
            ],
            "title": "Sharing among the human capitalists: An economic inquiry into the corporate law firm and how partners split profits",
            "year": 1985
        },
        {
            "authors": [
                "R Horst",
                "H Tuy"
            ],
            "title": "Global Optimization: Deterministic Approaches (Springer, Berlin)",
            "year": 2013
        },
        {
            "authors": [
                "DH Maister"
            ],
            "title": "Balancing the professional services firm",
            "venue": "Sloan Management Rev",
            "year": 1982
        },
        {
            "authors": [
                "DH Maister"
            ],
            "title": "Managing the Professional Service Firm (Simon and Schuster, New York)",
            "year": 2012
        },
        {
            "authors": [
                "A Moreno",
                "C Terwiesch"
            ],
            "title": "Doing business with strangers: Reputation in online service marketplaces",
            "venue": "Inform. Systems Res",
            "year": 2014
        },
        {
            "authors": [
                "H Mudrick"
            ],
            "title": "Partner compensation",
            "venue": "CPA J. Online,",
            "year": 1990
        },
        {
            "authors": [
                "L Nachum"
            ],
            "title": "Winners and losers in professional services: What makes the difference",
            "venue": "Service Indust. J. 16(4):474\u2013490",
            "year": 1996
        },
        {
            "authors": [
                "G Roels",
                "US Karmarkar",
                "S Carr"
            ],
            "title": "Contracting for collaborative services",
            "venue": "Management Sci",
            "year": 2010
        },
        {
            "authors": [
                "AV Roth",
                "LJ Menor"
            ],
            "title": "Insights into service operations management: A research agenda",
            "venue": "Production Oper. Management",
            "year": 2003
        },
        {
            "authors": [
                "P Rusmevichientong",
                "M Sumida",
                "H Topaloglu"
            ],
            "title": "Dynamic assortment optimization for reusable products with random usage durations",
            "venue": "Management Sci",
            "year": 2020
        },
        {
            "authors": [
                "D 403\u2013440. Zhan",
                "AR Ward"
            ],
            "title": "Staffing, routing, and payment to trade off",
            "year": 2019
        },
        {
            "authors": [
                "Talluri",
                "Tsoukalas"
            ],
            "title": "Revenue Management of a PSF Operations Research, Articles in Advance",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Received: June 16, 2020 Revised: April 12, 2022 Accepted: June 21, 2022 Published Online in Articles in Advance:\nArea of Review: Market Analytics and Revenue Management\nhttps://doi.org/10.1287/opre.2022.2351\nCopyright: \u00a9 2022 INFORMS\nSupplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.2351.\nKeywords: professional services \u2022 staffing \u2022 workforce analytics"
        },
        {
            "heading": "1. Introduction",
            "text": "Aprofessional service firm (PSF), such as amanagement consulting firm, has employees of varying skills, backgrounds, qualifications, and experience (Nachum 1996). Clients request a quote for their project, and the probability of winning a bid depends both on the price quoted (for the entire duration of the project) as well as the quality and suitability of the employees assigned to the job. If the firm wins the project, it is committed to executing it at that price and dedicating its resources to it.\nThis operational problem of PSFs, abstracting away specific industry details, can be summarized as a bidding-cum-matching problem where the probability of winning depends on the quality of the employees promised for the job as well as the price quoted in the bid. When the set of employees is specified as part of the bid, we call it the quality-revelation model. This typically happens in high-impact high-profile projects, or when the customer is a new one, or when the PSF is competing with larger rivals and needs to reassure the client on quality. This is the primary model we consider in this paper. We also consider an alternate model, the quality-\nreputation model, where the bid does not name specific employees and the winning probability depends on a quality reputation that is accumulated over past projects. This latter model is more appropriate for lower-end PSFs and for simpler, shorter-term projects with established relationshipswith the client.1\nAlthough many papers in the literature have addressed various concomitant research issues for service firms in general (aswe discuss in Section 1.1), relatively little work has been done specific to this operational and computational problem faced by PSFs. In this paper, we formulate it as a revenue management problem where the area partner (throughout, we assume the PSF is run by partners, as is typical in law or consulting) assesses each project, client, future work, and employees, and evaluates win probabilities and decides on a bid to maximize expected revenue. Although employee salaries are sunk in the short term, their opportunity cost\u2014as the employee will be tied up with the project for a duration\u2014has to be considered in the bid. We model the success of the bid as depending on the bid as well as the quality of the employees assigned\n1\nSeptember 27, 2022\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\nto the project, which is a new dimension for revenue management. As we mentioned, quality comes into the equation either ex ante, revealed along with the bid, or as an accumulated reputation effect.\nWe first resort to a stylized Markov chain model to study the revelation versus reputation effects for a twoemployee, one-project-type case. The analysis yields insights in favor of the transparency of the revelation model, onwhichwe subsequently focus our attention.\nBecause the problem has a temporal dimension with uncertainty about new requests for quotes as well as bid wins, the appropriate framework is stochastic dynamic programming. Unfortunately, the dynamic program is impossible to solve exactly in practice, and we show that it is inapproximable to any constant factor (unless P NP) when projects require greater than two employees, motivating a search for good tractable approximations. Because of the nonlinearity inherent in price optimization, we show that a deterministic math programming formulation does not approximate the dynamic program as well, so we look for more sophisticated value-function approximations. We propose a simple and fast greedy heuristic to calculate bids and use the approximations to bound its revenue performance numerically.\nOur methodology is useful not just for the bid optimization problem, but also for performing workforce analytics and Monte Carlo simulations to determine the number of employees of each skill set to hire and when and the marginal value of each employee type, to guide the firm\u2019s overall resource management.\nWe summarize the main contributions of our work as follows:\n1. On the modeling side, we formulate a stylized one-project, two-employee Markov chain model to gain managerial insights into the PSF\u2019s revenue management problem. In particular, we find that a counterintuitive strategy of bidding higher for lower-quality employees is optimal under the reputation model. We also show that in a hybrid reputation\u2013revelationmodel, where a percentage of customers are perceptive and can infer the quality from the bid, the optimal revenue is lower than in the two pure models that generate identical revenue, thus illustrating the value of transparency. This motivates us to focus on the operational problem of themore transparent revelationmodel.\n2. For the revelation model, we formulate the operational version of the problem as a dynamic program that is flexible enough to allow many modeling variations but, unfortunately, is intractable computationally. The main difficulty is the combinatorial effect of bundling employees to a project and the nonlinearity of the win-probability and revenue functions. We outline below our technical contributions in this regard.\na. We show that the problem for projects requiring more than one employee is inapproximable to any\nconstant factor (assuming P\u2260NP). On the positive side, somewhat surprisingly given the nonlinearity inherent in our problem, the methodology developed in Rusmevichientong et al. (2020) in the context of assortment optimization for reusable resources with fixed prices can be partly extended to our setup: we show that for one-employee projects, the revenue from a greedy algorithm has a guarantee of at least 50% of the maximum expected revenue.\nb. Then, we consider the online single-stage problem and the many technical challenges that even this raises.We showhowone can solve it via a two-step procedure: the first step involves solving a two-constraint knapsack problem, and the second step maximizing a univariate log-concave function.\nc. Next, we obtain a relatively tight bound on the value function of the dynamic program by approximately solving an affine approximation linear program (LP) via constraint generation, in the spirit of Adelman (2007). Our innovation is in the solution of the separation problemwhich, unlike in Adelman (2007), is a difficult nonconvex problem. We solve this problem locally to obtain fast cuts and also develop an algorithm to obtain an upper bound to the global optimum. To that end, we use dual ideas as well as a trick to isolate the nonconvexity of the auxiliary problem to one variable.\nd. Finally, we show how our revenue management formulation and its solution methods can be used to obtain valuable insights on staffing and utilization levels. There are very few analytical tools available for project-bidding and staffing of PSFs, so our framework provides a valuable tool kit for workforce management.\nThe remainder of this paper proceeds as follows. We give a survey of the literature in Section 1.1. In Section 2, we analyze a stylized Markov chain model. In Section 3, we formulate the operational problem, and in Section 4, we give analytical bounds and solution methods. Finally, in Section 5, we give numerical results on the performance of the algorithms as well as their application in workforce analytics. All proofs are relegated to the online appendix. In addition, in Section A of the online appendix, we describe our problem in the larger context of bidding and staffing for a PSF."
        },
        {
            "heading": "1.1. Literature Review",
            "text": "The literature on operations of PSFs is relatively sparse and spread out over many disciplines, including profession-specific areas such as accounting or law practice. Gilson and Mnookin (1985), for instance, provide an early survey specific to the law profession, which draws connections to economic principal\u2013agent theories and remains highly relevant. Two further industry publications, by Cotterman (2016) and Mudrick (1990), describe the operations of law and accounting firms. In contrast, relatively little has been documented for management consulting firms, except for a few older\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\narticles (Maister 1982) and management books such as that by Maister (2012). Of a more academic and insightful nature are papers by Teece (2003) and a survey by Roth andMenor (2003) who bothmention the paucity of research into the operations of a PSF.\nQuality of an employee and reputation of a PSF are of course rather intangible concepts. Nachum (1996) surveys these aspects for large advertising PSFs. Two proxies they use for quality of employees are average salary and productivity of the employee.\nOn the subject of reputation there are many articles in the management science literature. Most empirical studies in this area are based on online customer feedback, either numerical ratings or textual reviews (for instance, Moreno and Terwiesch 2014). Unfortunately there is little of that sort of information for PSFs like large advertising firms or management consulting or law firms. However, both their clients and those in the industry are acutely aware of the reputations of the players, and past performance invariably contributes to such reputation.\nQueueing models with k-identical servers and pricing control have a similar flavor as the problem faced by PSFs. This is usually stated as admission control using state-dependent pricing and no buffers. The well-known square-root staffing rule and the literature surrounding it provide great insight into how staffing grows with load, but the literature generalizing the rule usually does not consider all three elements in our model: matching, quality, and pricing. An exception is a recent article by Zhan and Ward (2019), which studies the problem of staffing where quality is a concern; the pricing part in that paper, however, is distinct from ours, as it is about the payments to the employees. A good recent survey of the area is provided by van Leeuwaarden et al. (2019).\nAs PSFs match employees to jobs dynamically, online bipartite matching is another relevant area. This has been extensively studied in the context of online advertisements with quality of the match being an important modeling element. In this application, web page requests are matched with an inventory of ads to show on the page. The resources are perishable, that is, not released back, so there is no concept of duration of the service. As in our model, decisions are online and irrevocable, and there is also a pricing element in the sense that the advertisers bid to place their ads on the page (real-time bidding model) and the highest bidder wins. Note that the logistic model that we use is a probabilistic version of the max-net-utility or envy-free pricing models used in this stream of literature. This is related to our problem as follows: Each ad corresponds to an employee, with the number of such employees corresponding to the number of ads of that type to be shown. Projects are users visiting the\nsite, and each project has to be matched to at most one ad. The duration of a job is \u221e (so it exhausts the ad inventory). In our PSF model, each job requires a bundle of resources and can have arbitrary durations; hence, we are dealing with a significantly more difficult computational problem.\nThe problem is also related to network revenue management (Talluri and van Ryzin 2004) that is used to model the sale control process for hotels, railways, and airlines. The PSF revenue management problem is a generalization of the standard network revenue management problem\u2014with a pricing and matching component and an underlying bipartite graph structure with qualities as weights on the edges. The difference from PSFs is that there is no matching based on qualities, and the prices are not personalized. Rusmevichientong et al. (2020) study the assortment optimization problem of such reusable resources. Because employees can be considered reusable resources, the computational techniques of Rusmevichientong et al. (2020) are relevant to us, and we discuss and extend them further in this paper. By adapting revenue management solution techniques, our paper brings new tools for use in workforce analytics for PSFs.\nIn the operations management area, there are a few important articles that study reputation for quality for service firms. Specific to PSFs, the papers by Boone et al. (2008) and Roels et al. (2010) are two such papers, but they concentrate on organizational and contracting aspects, respectively, in contrast to our revenue management focus. Adelman and Mersereau (2013) model a situation where customers remember past fill rates, which leads to goodwill that is updated by an exponentially smoothed average, and the firm faces the problem of allocating limited capacity\u2014 roughly corresponding to our quality-reputation regime, but at a personalized level. The customer demand is a function of the accumulated goodwill and an exogenous shock. They analyze the performance of a greedy policy and give an approximate dynamic programming approach. Using numerical studies, they evaluate the dynamics for a two-customer case to gain insights. In contrast, we primarily concentrate on the qualityrevelationmodel.\nThe empirical paper by Bolton et al. (2006) is very relevant to the issues that we study in this paper. They study firms\u2019 contract renewal decisions as a function of the suppliers\u2019 service operation metrics over time. Based on a data set of support service contracts for high-tech systems, they find that a firm with very favorable experiences is more likely to renew that contract after controlling for average service levels. A similar study was performed by Sriram et al. (2015) based on a video-on-demand data set, focusing on the role of service variability in influencing retention.\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nIn a very recent paper, DeCroix et al. (2021) studied quality variability and how it affects personalized dynamic pricing. Their concerns are concordant to ours, but in a different setting. We focus specifically on PSFs and the problem of bidding for projects as well as allocation of resources. Our quality-reputation modeling shares many similarities, however; firms\u2019 reputation for quality follows an exponential-smoothing process, and the purchase decision has a logit probability."
        },
        {
            "heading": "2. Markov Chain Model: Reputation vs. Revelation",
            "text": "When reputation is the driver behind the win probability, a PSF may be tempted to follow the dictum (mentioned to us by a PSF partner), \u201cpromise the best and assign what is available.\u201d This, however, has long-term consequences in terms of reputation and the possibility of winning future bids. To gain insight into the interactions of short-term revenues and long-term reputation, we develop a stylized model of the problem with one project type and two employees. The model leads to tractable near-closed-form solutions in steady state under both the revelation and reputation schemes, and allows us to compare them for insight into the main drivers and effects.\nAssume we have two employees of qualities q1 and q2 (q1 > q2; referred to as high-quality and low-quality, respectively) and a unique project type that arrives with probability \u03bb in each period and requires a single employee for a duration of exactly two periods; thus, an employee assigned at time t is not available in period t+1. Also assume zero employee cost (i.e., it is a sunk cost). We model the probability to win the project as\nw(b,q) 1 1+ e\u03b20\u2212\u03b2qq+\u03b2bb , (1)\nwhere b is the bid, and q is the supplied quality under the revelation scheme. The parameters \u03b2q,\u03b2b are assumed positive, so that the winning probability is increasing in quality and decreasing in bid amount. Equation (1) also yields the win probability under the reputation model, where q now represents the reputation of the firm. The reputation of the firm is taken to be the average over all qualities up to time t.\nThe system will transition between three states (1, 0), (0, 1), and (1, 1), where the elements of the tuple represent the first and second employee respectively, and the value one represents availability for assignment and zero otherwise. For example, (1, 0) represents a state where the higher-quality employee 1 is available and the lower quality employee 2 is on a project and not available. Note that there will always be an employee available (hence, (0, 0) is not a reachable state), as only one project arrives per period, each project lasts exactly two periods, and a maximum of one employee is assigned to a project.\nRemark 1. Under both the reputation and revelation models, we should always greedily assign the highquality employee, if available, over the low-quality employee. Indeed, there are two possibilities at state (1, 1). Either we assign the hiqh-quality employee or the low-quality employee (i.e., we do not have to consider the case of not assigning anyone, as we can always bid high enough to make an assignment profitable). If it is optimal to assign the high-quality employee, the state is identical to (1, 0), as (1, 1) and (1, 0) are indistinguishable in terms of both immediate revenue and transition to the next state. Similarly, if it is optimal to assign the low-quality employee, the state is identical to (0, 1).\nBut under both models, being in the state (1, 0) is preferable to being in state (0, 1); that is, we would prefer to have the high-quality employee available more often, and therefore the state (1, 1) is equivalent to the state (1, 0), whence assigning the high-quality employee is preferable.\nIn view of Remark 1, we collapse the states (1, 0) and (1, 1) into one and consider a two-state model (Figure 1) with the following collapsed states:\n\u2022 A\u2014A high-quality individual is available; \u2022 N\u2014A high-quality individual is not available (which implies a low-quality individual is available). Then, a policy is defined by the bidding strategy (bA, bN) in the revelation model and (bA(q\u0304),bN(q\u0304)) in the reputation model. For a given quality, in both models, there is a one-to-one correspondence between bid amount and winning probability. Therefore, when convenient, we can also define the policies with respect to the winning probabilities (wA,wN) in the revelation model and (wA(q\u0304),wN(q\u0304)) in the reputation model.\nIn the reputation model, if \u03c4t projects have been won up to time t, then if a project is won and assigned to employee i at time t, we will have q\u0304t+1 q\u0304t + 1\u03c4t+1 (qi \u2212 q\u0304t), whereas if the project is not won, we will have q\u0304t+1 q\u0304t. Thus, in all cases there holds\n|q\u0304t+1 \u2212 q\u0304t| \u2264 |q1 \u2212 q2| \u03c4t + 1 :\nBecause of the long-term infinitesimal effect of a single period on reputation, we consider only stationary\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\npolicies, and thus at steady state, we can assume that reputation stabilizes to a time-invariant q\u0304. Indeed, consider a constant winning rate wN at state N. The state N is reached exactly as many times as a highquality individual is assigned to a project and the project is won. For every one of these times, exactly \u03bbwN times a project is won and a low-quality individual is assigned. Therefore, in the limit, the ratio of high-quality individuals to low-quality individuals is 1\n\u03bbwN , and the average reputation converges to q2 +\n1 1+\u03bbwN (q1 \u2212 q2).\nWe thus take as a given a constant q\u0304 in the steady state and constant policies (bA(q\u0304),bN(q\u0304)) for the subsequent analysis. For any fixed such policy, the system can be analyzed as a two-state Markov chain.\nFor the rest of this section, unless explicitly stated, the discussion and equations refer to both the reputation and revelation models. At the steady state, let \u03c0A and \u03c0N be the probabilities of being in the two states, respectively (see Table 1).\nThe transition probabilities given the policy are\n1 \u2212 \u03bbwA \u03bbwA 1 0\n[ ] ,\nand the corresponding steady state probabilities are \u03c0A 11+\u03bbwA and \u03c0N \u03bbwA1+\u03bbwA :\nThe percentage of periods where we win a project and assign the high-quality employee is \u03bb\u03c0AwA, and the percentage of periods where we win a project and assign the low-quality employee is \u03bb\u03c0NwN. Therefore, the average quality, also confirming an earlier statement, is\nq\u0304 \u03bb\u03c0AwAq1 +\u03bb\u03c0NwNq2 \u03bb\u03c0AwA +\u03bb\u03c0NwN \u03bbwAq1 +\u03bb2wAwNq2 \u03bbwA +\u03bb2wAwN\nq1 +\u03bbwNq2 1+\u03bbwN q2 + 1 1+\u03bbwN (q1 \u2212 q2),\nand the average revenue per period extracted by the policy is \u03bb\u03c0AbAwA +\u03bb\u03c0N bNwN:\nWhen a project arrives, the average revenue extracted is bAwA when at state A and bNwN when at state N. In Proposition 1, we show that when operating optimally, the average revenue that can be extracted is the same under both models.\nProposition 1. When operating optimally, the average revenue per period under the revelation model is equal to the average revenue per period under the reputation model.\nWe next show that even though the same revenue can be generated under both models, this is possible in the reputation model only by adopting a counterintuitive policy that bids higher for the lower-quality employee. The revelation model behaves predictably in this respect, as we first show in Proposition 2.\nProposition 2. For the optimal bidding policy (b\u2217A,b\u2217N) under the revelation model, there holds b\u2217A > b\u2217N.\nProposition 3 is somehow counterintuitive. It says that in the reputation model, we should bid higher when supplying the low-quality employee. As we extract value only from our reputation, we can extract equal value from high- and low-quality employees in the current period. Reputation considerations imply that we benefit in the long term from assigning good employees when winning; therefore, we are inclined to ask for higher compensation for assigning a lowquality employee. As dictated by intuition and shown in Lemma 1, in spite of the higher bidding for the lowquality employee, we generate more revenue when the high-quality employee is available.\nLemma 1. For the optimal bidding policy (b\u2217A,b\u2217N) under the reputation model with corresponding win probabilities (w\u2217A,w\u2217N), there holds w\u2217Ab\u2217A \u2265 w\u2217Nb\u2217N. Proposition 3. For the optimal bidding policy (b\u2217A,b\u2217N) under the reputation model, there holds b\u2217N \u2265 b\u2217A.\nWe have seen that the firm gets the same revenue in the reputation and revelation cases. Let us examine the situation from the customer\u2019s point of view. From symmetry, the total fees are equal in the two cases. But what is the utility for the customer with respect to the number of projects assigned for these fees and the distribution of high- and low-quality employees? It follows from the reasoning of the proof of Proposition 1 that the optimal reputation and revelation policies will have the same wA and wN, which also implies an identical quality distribution. What changes is the payment schedule, and we next discuss a couple of things that may make the reputation schedule unattractive."
        },
        {
            "heading": "2.1. Reputation vs. Revelation, and Signaling",
            "text": "One could argue that the bidding \u201cinversion\u201d under the reputation model reflects the absence of signaling effects in the model: if we were to implement the bidding strategy of the reputation model, customers would be likely to infer, at least to some degree, the quality from the bid. If we assume all customers are highly observant and infer the bid-to-quality relationship exactly, then we converge to the revelation model. The\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nreputation model, as studied in this section, is the other extreme, where customers do not learn at all.\nBut what about an in-between zone, where some customers can deduce the quality of the employee from the bid while others cannot and act based on the firm\u2019s reputation? The core of the insight remains relevant: the reputation drop associated with winning using low-quality employees is a force pushing toward biding highwhen supplying such employees. In such a hybrid regime, we face a dilemma. Using \u201crevelation bidding\u201d leads to higher acceptance of low bids and lower acceptance of high bids by na\u00efve customers, lowering our revenues. Using \u201creputation bidding\u201d leads to exploitation by perceptive customers. In Proposition 4, we resolve this dilemma, showing that under a hybrid regime, we cannot achieve the same revenue as in either of the pure cases. Thus, there is value in the clarity of knowing all customers behave in the same way, somethingwe can achieve by revealing quality ex ante.\nProposition 4. Consider a hybrid regime where a fraction 0 < \u03b1 < 1 of the customers can deduce the quality of the employee from the bid and (1\u2212 \u03b1) cannot and decide based on reputation, where the reputation q\u0304 is the average quality of the wins of the na\u00efve customers. The optimal revenue generated when operating under this hybrid regime is strictly less than the optimal revenue of the revelation regime.\nRemark 2. A secondary, somewhat unsatisfying property of reverse bidding is related to employee incentives. Although total revenue for the firm does not change under the two models, the division of billing is different. Even though in both models the hiqh-quality employee brings in more revenue, the difference is higher in the revelation model, as we demonstrate in Proposition 5. Thus, employees may be less incentivized for quality work under the reputation model.\nProposition 5. In both the reputation and revelation models, the high-quality employee brings in more revenue than the low-quality employee. The difference, however, is higher under revelation.\nMotivated by the results of this section, we focus the rest of this paper on studying the PSF problem under the revelation model."
        },
        {
            "heading": "3. An Operational Model Under Quality Revelation",
            "text": "In this section, we consider the PSF revenue management problem with quality revelation under a general setup, allowing for an arbitrary number of employees, multiple project types of varying durations, and employee quality match metrics that may vary by project. We formulate the problem as a dynamic program that unfortunately is computationally difficult to solve: the state space of the dynamic program explodes even for\nsmall problems; so the goal is to obtain \u201cgood\u201d policies via approximations (in Section 4).\nTime is discrete and runs over a horizon from one to T. We assume a set P of project types and a set I of employees i \u2208 I. Each project type p \u2208 P has a fixed requirement of kp individuals for a duration of dp. A project of type p arrives with probability \u03bbpt in period t, with at most one project arrival per period \u2211 p\u2208P\u03bbpt \u2264 1. We assume that \u03bbpt 0 for t > T\u2212 dp. When it is clear from the context, we write a project p instead of a project of type p. We denote by qp the vector of size |I| of quality measures of assigning individuals to project p."
        },
        {
            "heading": "3.1. The State Space",
            "text": "The state s is a vector in Z|I|+ , with the ith element si representing the number of periods after which that individual i becomes free. So if si 0, employee i is currently free and can be assigned immediately, whereas if si > 0, he or she is working on some other project and will become available in si periods.\nWe also use the indicator 1s,i 1 if si 0;0 otherwise {\nto indicate that at state s individual i is available, or 1s in vector notation."
        },
        {
            "heading": "3.2. The Controls",
            "text": "The decision variables are how much to bid and the assignment of individuals to the project. The feasible assignments F ps to project p when at state s are the set of assignments that assign only among available resources, that is,\nF ps {x \u2208 {0,1}|I| | x \u2264 1s, 1Tx kp}: (2) The feasible assignments if all resources are available are F p0."
        },
        {
            "heading": "3.3. The State Dynamics",
            "text": "If a project is won and x is a feasible assignment of employees, then we have st+1 [st \u2212 1+ dpx]+. If no project is won, then no employee is assigned, and we have st+1 [st \u2212 1]+. Remark 3. Additional constraints can be imposed on F ps . For example, one can introduce employee types and enforce that at least klp employees of type l are assigned to the project via imposing constraints \u2211 i\u2208Ilxi \u2265 klp, where Il \u2282 I are the employees of type l. We do not consider such constraints, however, as they affect the difficulty of the combinatorial single-period subproblem that we examine in Section 4.1.3."
        },
        {
            "heading": "3.4. Win Probabilities",
            "text": "Given a feasible assignment x \u2208 F ps and a bid b per person-day, we win the project with a probability that\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nis a function of the bid and the average quality q\u0304Tpx of the assignment where q\u0304p qp kp . Specifically, we assume that the probability of winning project p is given by the logistic function\nwp(b, q\u0304Tpx) 1\n1+ e\u03b2p0+\u03b2pbb\u2212\u03b2pq q\u0304Tp x , (3)\nwith \u03b2pq > 0 and \u03b2 p b > 0, so that the probability to win is increasing as a function of quality and decreasing as a function of the bid.\nIf the project is won, we incur a cost cTpx. If we assume the daily cost to be c, that is, independent of p, then we can set cp dpc. The costs c capture nonsunk costs only, if any. Employee salaries that do not depend on the workload are not part of the dynamic program; however, they play a role in optimal hiring decisions that we investigate in our numerical simulations of Section 5.\nLet Vt(s) be the value function representing optimal expected revenue from a project-bidding and resourceallocation policy. Noting that project p has kpdp workdays, the dynamic program is\nVt(s) \u2211 p\u2208P\n\u03bbpt max xp\u2208F ps bp\u2208R+ [(kpdpbp \u2212 cTpx\n+Vt+1([s\u2212 1+ dpxp]+))wp(bp, q\u0304Tpxp) + (1\u2212wp(bp, q\u0304Tpxp))Vt+1([s\u2212 1]+)] + 1\u2212\u2211 p\u2208P \u03bbpt ( ) Vt+1([s\u2212 1]+): (4)\nThe dynamic program recursion is easy to interpret. We decide on the bids and assignments (as this is quality revelation) to maximize the current period\u2019s expected revenue and the future profits given some of our employees become unavailable.\nWriting Vpdt(s,xp) Vt+1([s\u2212 1]+) \u2212Vt+1([s\u2212 1+ dpxp]+), we have\nVt(s) Vt+1([s\u2212 1]+) + \u2211 p\u2208P\n\u03bbpt max xp\u2208F ps bp\u2208R+\n(kpdpbp\n\u2212 cTpxp \u2212 Vpdt(s,xp))wp(bp, q\u0304Tpxp):\n(5)\nThe problem is difficult as formalized in Proposition 6.\nProposition 6. Assuming P\u2260NP, the bidding-and-matching problem of the PSF cannot be approximated to any constant factor whenmaxp kp \u2265 2."
        },
        {
            "heading": "4. Bounds and Solution Methods",
            "text": "The dynamic program (5) is computationally intractable to solve exactly, as the state space explodes even for a small number of employees. We thus first present a linear approximation to the value function and a greedy policy with respect to the approximation. Based on this approximation, we derive a theoretical upper bound on the optimal expected revenue. We show that when\nprojects require exactly one employee, this approach gives a performance guarantee of being within twice the optimal value (see Proposition 6). Subsequently, we derive two increasingly tighter upper bounds on the dynamic program, the motivation being that the tighter the bounds comparedwith the values from the policy, the greater our confidence that policies derived from the bounds reflect the behavior of an optimal solution. The first bounding technique is based on a nonlinear program (NLP), akin to the deterministic version of the problem, that is an upper bound on the value function. The second bound is obtained via restricting the variables of the linear programming formulation of the dynamic program to linear policieswhile retaining thenonlinearity of the revenue function and calculating it using various optimization techniques. In Section 5, we first investigate how the boundsperformnumerically and thenuse the greedypolicy to study somequestions of interest to a PSF."
        },
        {
            "heading": "4.1. Linear Approximation",
            "text": "A natural strategy for approximating the value function is to replace it with a linear approximation. The terms of the approximation can be interpreted as marginal values of employees, which we can approximate either via a recursive heuristic (Section 4.1.1) or via the solution of an affine approximation linear program (16) (in Section 4.3).\nLet dm be the maximum duration over all projects. Consider the approximation of the value function\nV\u0302t(s) \u03bd\u0302tc + \u2211 i\u2208I \u03bd\u0302ti,si ,\nparameterized by \u03bd\u0302tc, \u03bd\u0302 t i,si for i \u2208 I, t \u2208 {1, : : : ,T}, si \u2208{0, : : : ,dm \u2212 1}. The parameter \u03bd\u0302ti,si denotes the marginal value at time t of employee i if he or she were to be available in si periods.We use the vector notation n\u0302ts to contain the corresponding information \u03bd\u0302ti,si for all individuals.\n4.1.1. Recursive Heuristic. Computing the optimal parameters \u03bd\u0302ti,j is not trivial, and in this section, we propose a fast recursive greedy heuristic as a tractable approximation, similar to the one in (Rusmevichientong et al. 2020) in the context of assortment optimization with fixed prices: Initialization: Set \u03bd\u0302Tc 0 and \u03bd\u0302Ti,j 0 for all i \u2208 I, j \u2208{0, : : : ,dm \u2212 1}. Recursion: For t T \u2212 1, : : : , 1: 1. For every project p with \u03bbpt > 0, compute the optimal allocation x\u0302tp and bidding b\u0302 t p under the assumption that all resources are available:\nx\u0302tp, b\u0302 t p ( ) arg max\nxp\u2208F p0 bp\u2208R+\n( kpdpbp \u2212 cTpxp\n\u2212 1T n\u0302t+10 \u2212 n\u0302t+1[0\u22121+dpxp]+ ( )) wp(bp, q\u0304Tpxp):\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\n2. Once (x\u0302tp, b\u0302 t p) is calculated for every project p, compute, for all j \u2208 {t, : : : t\u2212 dm}, \u03bd\u0302ti,j \u03bd\u0302t+1i,j\u22121 \u2200i \u2208 I, j \u2208 {1, : : : ,dm \u2212 1}, (6)\nn\u0302t0 n\u0302t+10 + \u2211 p\u2208P \u03bbpt ( kpdpb\u0302 t pc t p \u25e6 x\u0302tp \u2212 c \u25e6 x\u0302tp\n\u2212 (n\u0302t+10 \u2212 n\u0302t+1[0\u22121+dpxp]+ ) ) wp ( b\u0302 t p, q\u0304 T p x\u0302 t p ) , (7)\nwhere \u25e6 denotes the Hadamard product (element-wise product), and the condition ctp\nTx\u0302tp 1 holds, with ctp distributing the revenue among the participating individuals.We also set\n\u03bd\u0302tc 1Tn\u0302t0: There is some flexibility in picking the parameter ctp, which leaves space for different variants of the heuristic. However, we should always make a choice that satisfies the following condition to guarantee monotonicity of the marginal values (Lemma 3):\nkpdpb\u0302 t pc t p \u25e6 x\u0302tp \u2212 cp \u25e6 x\u0302tp \u2212 (n\u0302t+10 \u2212 n\u0302t+1[0\u22121+dpxp]+ ) \u2265 0, \u2200p \u2208 P:\n(8)\nLemma 2. There exist ctp \u2265 0 with ctpTx\u0302tp 1 that satisfies condition (8).\nFrom the definition of n\u0302t0 the following is obvious.\nLemma 3. If the choice of ctp satisfies condition (8), then n\u0302t0 \u2265 n\u0302t+10 .\nProposition 7 yields a first upper bound on the optimal value of the dynamic problem.\nProposition 7. If the choice of ctp satisfies condition (8), then V1(0) \u2264 2 \u00b7 1Tn\u030210.\nWe call the right-hand side of the inequality in Proposition 7 the theoretical upper bound. In our numerical simulations, it turns out not to be particularly tight, but it gives us a reference value to compare tighter bounds with.\n4.1.2. Greedy Policy. In this section, we explore a simple greedy policy to calculate the bids and assignments under the quality-revelation model once we fix the marginal values according to the recursive heuristic of the previous section. This gives a lower bound on the value function. In Section 4.3, we will discuss an alternative way to compute the marginal values.\nFor fixed n\u0302ts, the greedy policy with respect to the approximation is given by\n(xtp(s),btp (s)) \u2208 arg max xp\u2208F ps xp\u2208F ps\n( kpdpbp \u2212 cTpxp \u22121tsT ( n\u0302t+10\n\u2212 n\u0302t+1[0\u22121+dpxp]+ )) wp bp, q\u0304Tpxp ( ) , (9)\nwhere the dependence on the state is through F ps , 1 t s.\nProposition 6 shows the problem cannot be approximated to any constant factor even when projects are restricted to a maximum of two employees. We now show that if projects need at most one employee, the greedy policy with respect to the value function approximation V\u0302 is guaranteed to obtain at least 50% of the optimal total profit.\nTheorem 1. If kp 1 for all p \u2208 P, the total expected profit of the greedy policy with respect to the value function approximation V\u0302 is at least 50% of the optimal.\nThe proofs of Proposition 7 and Theorem 1 follow similar lines of argument as lemma 3.3 and theorem 3.2 of Rusmevichientong et al. (2020). Next we examine the single-stage problem that appears in the computation of n\u0302ts and the greedy policy with respect to the approximation.\n4.1.3. Implementing the Single-Stage Problem. We want to solve\nmax b\u2208R+ x\u2208F ps\n(kpdpb \u2212 c\u0303Tx)wp(b, q\u0304Tpx), (10)\nwhere b is the bid and c\u0303 cp + (n\u0302t+10 \u2212 n\u0302t+1[0\u22121+dp1]+ ) is the base cost plus the opportunity cost of the resources.\nIt is convenient to rewrite (10) as\nmax b\u2208R+ x\u2208F ps\n(kpdpb \u2212 C)wp b, Qkp ( ) \u2223\u2223\u2223\u2223\u2223 qTpx Q, c\u0303Tx C { } : (11)\nNote that it is natural to assume integrality for qp, but not for c\u0303 because of the inclusion of the opportunity costs.\nThe function r(b,C,Q) (kpdpb\u2212C) 1= 1+ e\u03b2 p 0+\u03b2pbb\u2212\n\u03b2 p q kp Q\n( )( )\nis log-concave, as can be easily verified. With the feasible assignment set F ps as in (2), we can solve (11) via a twostep procedure:\n1. Solve the two-constraint knapsack problem\nmax x\u2208{0,1}|I| x\u22641s\n{qTpx : c\u0303Tx \u2264 C, 1Tx kp} (12)\nfor every 0 \u2264 C \u2264 1Tc\u0303 producing a Pareto front of (C, Q) pairs.\n2. For each Pareto-optimal (C, Q), maximize the univariate log-concave function r(\u00b7,C,Q) obtaining a corresponding bidding price. Pick the Pareto-optimal (C, Q) and the corresponding bid price that yields the overall maximum.\nIn the online appendix, we illustrate how to produce all Pareto points of Step 1 in one go by utilizing a variation of the dynamic programming algorithm for knapsack problems (Kellerer et al. 2004) after an appropriate transformation. The single-stage problem turns out to be computationally fast in practice.\nRemark 4. For more complex feasible assignment sets, as mentioned in Remark 3, Step 1 of the above procedure\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nwould involve the solution of a series of binary programs to obtain the Pareto front."
        },
        {
            "heading": "4.2. Deterministic Upper Bound",
            "text": "In this section, we develop a compact deterministic upper bound akin to the deterministic linear programming bound of network revenue management (Talluri and van Ryzin 2004), but with a nonlinear objective function. We effectively treat the arrivals and wins of projects to be deterministic and equal to their expectations. Then, Jensen\u2019s inequality shows that we can obtain an upper bound via the solution of a convex nonlinear program. The advantage of this bound is that it can be solvedusing standard nonlinear programming packages. However, as we show in Section 5, the bound is not as tight as the more complicated bound of Section 4.3.\nRecall that project p requires kp individuals and lasts dp intervals. Let us define a 0\u20131 incidence matrix A with |I| \u00d7 |P| \u00d7 T columns and |I| \u00d7 T rows, representing resource usage. The column (i, p, t), corresponding to an assignment of individual i to project p at time t, will have ones in rows (i, t) to (i, t+ dp \u2212 1), corresponding to employee i being occupied from time t up to and including time t+ dp \u2212 1.\nConsider the nonlinear convex deterministic program\nmax w\u2208R|P|\u00b7T z\u2208R|I|\u00b7|P|\u00b7T\n\u2211T t 1 \u2211 p\u2208P kpdp\n[ \u03b2pq\n\u03b2 p b\nq\u0304Tpz t p \u2212\n\u03b2 p 0 \u03b2 p b \u03bbtpw t p\n+ 1 \u03b2 p b \u03bbtpw t plog 1 \u2212 wtp wtp ( )] s:t: Az \u2264 1\n1Tztp kpwtp, ztp \u2264 \u03bbpt1, ztp \u2264 wtp1 \u2200t, p 0 \u2264 z \u2264 1 (DWu)\nwhere the decisions are expressed in terms of the assignment ztp to project p at time t, and the corresponding win probability wtp, rather than the bid btp\u2014a one-to-one relationship. We show that the optimal value of (DWu) yields an upper bound to the optimal value of the dynamic program.\nProposition 8. The optimal value of (DWu) is greater than or equal to V1(0).\nIn practice, we can tighten the above bound by simulating project arrivals and averaging the optimal solutions of the corresponding NLPs. Another advantage of simulation is that theNLPs have smaller sizes, asweonly have to consider the project that actually arrived in every period, counterbalancing the effort of solvingmultipleNLPs.\nTo that end, assume that at a simulation iteration a project p(t) \u2208 P arrived at time t. Now our incidence matrix A has |I| \u00d7 T columns and |I| \u00d7 T rows. The column (i, t), corresponding to an assignment of individual i at time t, will have ones in rows (i, t) to\n(i, t+ dp(t) \u2212 1), corresponding to employee i being occupied from time t up to and including time t+ dp(t) \u2212 1. The corresponding NLP is\nmax w\u2208RT z\u2208R|I|\u00b7T\n\u2211T t 1 kp(t)dp(t) \u03b2p(t)q \u03b2 p(t) b q\u0304Tp(t)z t \u2212wt \u03b2 p 0 \u03b2 p b + 1 \u03b2 p b wtlog 1\u2212w w\n( )[ ]\ns:t: Az \u2264 1, 1Tzt kp(t)wt, zt \u2264 1, zt \u2264 wt1 \u2200t, 0 \u2264 z \u2264 1, (DWup(t))\nwhere p(t) is theproject that arrivedat time t. In the above, to avoid notational complications, we assumed a project arrives in every period. Time periods where no project arrives can be left out of the summation in the objective, and the correspondingvariables can bedropped.\nThe optimal value of (DWup(t)) is a random quantity, as it depends on the random arrivals.\nProposition 9. Let O(DWup(t)) be the optimal value of DWup(t) and O(DW u) be the optimal value of (DWu). Then O(DWu) \u2265 E[O(DWup(t))] \u2265 V1(0): We omit the proof as it is similar to the last step of the proof of Proposition 8."
        },
        {
            "heading": "4.3. Affine Bound via Linear Programming",
            "text": "In this section, we investigate solving for the marginal values in the approximation using linear programming as pioneered in revenue management by Adelman (2007). This bound is in general tighter than the bound of Section 4.2 and gives us confidence that our heuristic algorithms for the bidding and assignment are reasonably close to the optimal solution.\nConsider the linear program\nmin V\u03031(0) s:t: V\u0303t(s) \u2265 V\u0303t+1([s \u2212 1]+)+\n+\u2211 p \u03bbpt ( kpdpbtp \u2212 cTpxtp \u2212 V\u0303pdt(s, xtp) ) wp(btp, q\u0304Tpxtp)\n\u2200t, s, btp, x t p \u2208 F ps ,\n(13) where the decision variables of the LP are the V\u0303t(s)\u2019s.\nSolving (13) yields an optimal solution to the dynamic program, but is intractable because of the exponential number of variables and constraints. We can obtain an upper bound by solving instead the LP corresponding to the approximate dynamic program that reduces the number of variables to something we can handle numerically:\nmin \u03bd\u03031c + 1Tn\u030310 (14) s:t: \u03bd\u0303t+1c \u2212 \u03bd\u0303tc + 1tsT(n\u0303t+10 \u2212 n\u0303t0) + (1 \u2212 1ts)T(n\u0303t+1s\u22121 \u2212 n\u0303ts) +\u2211\np\u2208P \u03bbpt\n( kpdpbtp \u2212 cTpxtp \u2212 1T ( n\u0303t+10 \u2212 n\u0303t+1[0\u22121+dpxp]+ )) \u00d7 wp(btp, q\u0304Tpxtp) \u2264 0, \u2200t, s, btp, xtp \u2208 F ps : (15)\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nTo move from (13) to (14)\u2013(15) we constrain the fully general decision variables V\u0303t(s) to be affine in the state. Thus, the problem (14)\u2013(15) is a restriction of (13) and indeed yields an upper bound. We can further restrict the problem, retaining the bounding property, by adding the constraints n\u0303tj n\u0303t+1j\u22121 for all t, j > 0, which can be interpreted as saying that the marginal value of an employee that is to become available after j > 0 periods at time t is equal to the marginal value of the same employee that is to become available after j \u2013 1 periods at time t + 1. In view of these additional constraints, we can drop the term (1\u22121ts)T(n\u0303t+1s21 \u2212 n\u0303ts) from (15). The constraints now depend on the state s only via the available resources in the definitions of F ps , 1 t s, a fact that will be critical computationally:\nmin \u03bd\u03031c + 1Tn\u030310 (16) s:t: \u03bd\u0303t+1c \u2212 \u03bd\u0303tc +1tsT(n\u0303t+10 -n\u0303t0) +\u2211\np\u2208P \u03bbpt\n( kpdpbtp \u2212 cTpxtp \u2212 1T ( n\u0303t+10 \u2212 n\u0303t+1[0\u22121+dpxp]+ )) \u00d7 wp(btp, q\u0304Tpxtp) \u2264 0, \u2200t,s,btp,xtp \u2208 F ps , (17) n\u0303tj n\u0303t+1j\u22121, \u2200t, j > 0: (18) The LP (16)\u2013(18) has T \u00b7 dm \u00b7 |I| +T variables but an exponential number of constraints. Because now the dependence of (17) on the state is via the available resources, to consider the constraints corresponding to all states, we just need to consider all possible combinations of resource availability. Using y to denote the vector of available resources and X x1, : : : ,x|P|, we can rewrite (17) as\n\u03bd\u0303t+1c \u2212 \u03bd\u0303tc + gn\u0303 ,t(y,X,b) \u2264 0, \u2200b \u2208 R|P|+ , \u2200(y,X) \u2208 Z, (19)\nwhere\ngn\u0303,t(y,X,b) (n\u0303t+10 \u2212 n\u0303t0)Ty+ \u2211 p \u03bbpt ( kpdpbp \u2212 cTpxp\n\u2212 1T ( n\u0303t+10 \u2212 n\u0303t+1[0\u22121+dpxp]+ )) wp(bp, q\u0304Tpxp),\nZ {(y,x1, : : : ,x|P|) | y \u2208 {0,1}|I|,xp \u2208 X p,xp \u2264 y}, X p F p0 {x \u2208 {0,1}|I| | 1Txp kp}:\nIf we relax Xp to its linear relaxation X pR, we are effectively increasing the number of constraints. It follows that the optimal value of the corresponding restricted version of (16)\u2013(18) remains a valid upper bound on the dynamic program.We aim to solve this restricted version of (16)\u2013(18) by constraint generation, generating cuts iteratively by solving for every t the separation problem\nmax{gn\u0303,t(y,X,b)|b \u2208 R|P|+ , y \u2208 {0,1}|I|, xp \u2208 X pR, xp \u2264 y}, (20)\nwhere n\u0303ts are obtained by solving the (master problem) bounding LP with a subset of the constraints.\nProblem (20), however, is nonconvex and hard to solve. We use two procedures, a fast one that provides valid cuts but does not theoretically guarantee an upper bound, and a slower one that needs to be called only once, when the values of the relaxed LP converge, to provide an upper bound certificate.\n4.3.1. Weak Fast Cuts. The cuts are generated separately for every period t. Given n\u0303ts values, we find a local maximum of (20) to obtain a local solution (y\u2217,X\u2217,b\u2217). The cut \u03bd\u0303tc \u2265 \u03bd\u0303t+1c + ( y\u2217 \u2212\u2211\np\u2208P \u03bbptwp(bt\u2217p , q\u0304Tpxt\u2217p )xt\u2217p\n)T n\u0303t+10 \u2212 y\u2217Tn\u0303t0\n+\u2211 p\u2208P \u03bbpt ( kpdpbt\u2217p + ( n\u0303t+1[0\u22121+dpxt\u2217p ]+ \u2212 cp )T xt\u2217p ) wp(bt\u2217p , q\u0304Tp x\u0302t\u2217p ),\nwhere, to simplify the expression, we used 1T ( n\u0303t+10 \u2212 n\u0303t+1[0\u22121+dpxt\u2217p ] ) xt\u2217Tp ( n\u0303t+10 \u2212 n\u0303t+1[0\u22121+dpxt\u2217p ] ) ,\nis valid. Indeed, for any feasible point nc,nts of (16)\u2013(18), we have\n\u03bdt+1c \u2212 \u03bdtc + gn,t(y\u2217,x\u2217,b\u2217) \u2264 \u03bdt+1c \u2212 \u03bdtc +max y,x,b gn,t(y,x,b) \u2264 0:\n4.3.2. Upper Bound Certificate. As should be clear, solving the bounding LP (13) with only a subset of constraints will not lead to an upper bound on the optimal revenue. Here we provide an upper bound certificate using dual ideas. Proposition 10 provides an upper bound certificate for Problem (16)\u2013(18) and thus also for the dynamic program.\nProposition 10. Let n\u0303tj with n\u0303 t j n\u0303t+1j\u22121 for j > 0. If g\u0302t is an upper bound on the optimal value of the separation problem (20), then an upper bound on the optimal value of (16)\u2013(18) is given by 1Tn\u030310 +\u2211T\u22121t 1 g\u0302t: Remark 5. Proposition 10 yields an upper bound for any choice of n\u0303ts satisfying the last constraints of the bounding LP. An unfortunate choice, however, of such n\u0303ts may lead to a weak bound. The generation of fast cuts and the solutions of the relaxed LP are thus used to select n\u0303ts\u2019s that will lead to better bounds.\nRemark 6. The marginal values of n\u0303tj obtained by the upper bounding process can also be used to drive an approximate policy, in place of the n\u0302tj \u2019s of Section 4.1.1.\nTo obtain the upper bounds g\u0302t we will solve the dual of (20) with respect to the constraints xp \u2264 y,\nmin p\u2208RI\u00d7P+ max xp \u2208 XRp y \u2208 {0,1}|I| b \u2208 RP+\ngn\u0303,t(y,X,b) + \u2211 p\u2208P (y\u2212 xp)pp: (21)\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nUsing the definition of gn\u0303,t, the inner problem decomposes and yields subproblems\nmax yi\u2208{0,1} (\u2211 p\u2208P \u03c0ip + (\u03bd\u0303t+10i \u2212 \u03bd\u0303t0i) ) yi, (22)\nmax xtp\u2208[0,1]|I| btp\u2208R+\n\u03bbpt ( kpdpbtp \u2212 cTpxtp \u2212 1T ( n\u0302t+10 \u2212 n\u0302t+1[0\u22121+dpxp]+ ))\n\u00d7 wp(btp, q\u0304Tpxtp) \u2212 pTpxp (23) s:t: 1Txtp kp: Problem (22) is trivially solved by setting yi 1 whenever its coefficient in (22) is positive and to yi 0 otherwise. Although Problem (23) is nonconvex, the nonconvexity can be isolated in one dimension and solved by a one dimensional branch-and-bound search. To that end, let\nF(\u03c1) max\nxtp\u2208[0,1]|I| btp\u2208R+\nlog [ \u03bbpt ( kpdpbtp \u2212 cTxtp \u2212 1T ( n\u0302t+10\n\u2212 n\u0302t+1[0\u22121+dpxp]+ )) wp(btp, q\u0304Tpxtp) ] s:t: 1Txtp kp, pTpxtp \u2264 \u03c1,\nand note that the objective function of the defining problem is concave, because the logistic distribution wp is log-concave. In turn, this implies concativity of F(\u00b7), as a perturbation function of a concave maximization problem with convex constraints.\nProblem (23) can be reformulated as the univariate optimization problem\nmax \u03c1\u2208[0,1Tpp]\n{eF(\u03c1) \u2212 \u03c1}\nwith a nonconvex objective function. Note that evaluating eF(\u03c1) \u2212 \u03c1 at a given \u03c1 is an easy concave problem. To find the optimal \u03c1\u2217 via branch and bound, given an interval [\u03c1l,\u03c1u], we further need a concave overestimator of eF(\u03c1) \u2212 \u03c1 in [\u03c1l,\u03c1u], with the property that as the interval [\u03c1l,\u03c1u] gets smaller, the overestimator becomes arbitrary tight (see Horst and Tuy 2013).\nBy replacing the exponential with its secant in the segment [\u03c1l,\u03c1u], we obtain such a concave overestimator,\neF(\u03c1l) + e F(\u03c1u) \u2212 eF(\u03c1l)\nF(\u03c1u) \u2212 F(\u03c1l) (F(\u03c1) \u2212 F(\u03c1l)) \u2212 \u03c1,\nand we observe that the overestimator is exact at the edges of the interval [\u03c1l, \u03c1u]. In turn, because of continuity, this implies that the overestimator can be made arbitrary tight by shrinking the corresponding interval. We emphasize that although branch and bound is in general an exponential algorithm, in our case, it is efficient, as we have isolated the nonconvexity of the problem in one variable.\nRemark 7. The dual does not have to be solved to optimality. Any p \u2265 0 leads to a valid upper bound. In\nour numerical experiments, we use the subgradient algorithm with a modest number of iterations to calculate p."
        },
        {
            "heading": "5. Numerical Study",
            "text": "In this section, we use our computational procedures to numerically investigate questions of great interest for a PSF, namely, what the right utilization level is and what employee types to hire. Our first experiment, in Section 5.1, however, is technical and focuses on examining the tractability and relative tightness of the different bounds as well as giving some insight on the optimality gap of the greedy policy. In the second experiment, in Section 5.2, we perform simulations based on the approximate solution of the dynamic program to explore the interplay between operational and hiring decisions, and in the third set of experiments, in Section 5.3, we look at optimal hiring. The focus is not so much on the specific insights, as they are dependent on parameters, but on illustrating the potential uses of our tool kit and that the value of our formulation and solution methods extends beyond just the bidding and assignment problem and can be useful in workforce analytics and staffing decisions.\nWe generate instances parameterized by the number of employees |I|, the number of project types |P|, durations dmin and dmax, and k, where k is a proxy for the number of employees per project. In each period, a project p arrives with probability \u03bbp, which is sampled from a uniform [0, 1] distribution and subsequently normalized so that exactly one project arrives in each period, that is, \u2211 p\u2208P\u03bbp 1. The project duration dp is taken to be a random integer between dmin and dmax, and kp k\u0304p , where k\u0304p is sampled from a uniform distributionwith support [0:7k, 1:3k].\nWe assume we have three types of employees, A, B, and C, and each project type belongs to one of three classes, a, b, and c, all with equal probability. We emphasize that there are more than three project types, as a project type, apart from its class, is defined by its duration, its workforce requirements, and its sensitivity to quality and price. The suitability of an employee type to a project class is denoted by Sip and takes values from Table 2. Furthermore, each employee has generic capability Ci, which is an integer between one and five. The overall quality of assigning employee i to project p is qip Ci \u00b7 Sip; it is a combination of the inherent capability of the employee and the suitability to the project\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nand takes values in [1, 15]: We assume all labor costs are sunk and set cp 0.\nThe price sensitivity \u03b2pb and the quality sensitivity \u03b2 p q are sampled uniformly from [0:008, 0:012] and [0:3, 0:5], respectively, whereas we set \u03b2p0 \u2212 1, 000\u03b2pb + 9\u03b2pq with sampled uniformly from [\u22120:5, 0:5]. Figure 2 shows the winning probability as a function of the bid for different average qualities Q\u0304. Note that 0 and the parameters \u03b2pb, \u03b2 p q being at the centers of their corresponding intervals leads to a probability of 50% of winning the project if we bid 1,000 per workday and supply a bundle of employees with an average quality of nine."
        },
        {
            "heading": "5.1. Tightness of Bounds and Computational Performance",
            "text": "For our first experiment, we pick the type of an employee to be A with probability 50%, B with probability 30%, and C with probability 20%. The capabilities are picked randomly, with equal probabilities. The computations are to examine the tractability and relative tightness of the different bounds, as well as to give some insight on the optimality gap of the greedy policy.\nWe run our experiments on a Linux workstation with 10 cores clocked at 2.8 GHz and 64 gigabytes of memory. All LPs are solved via Gurobi (Gurobi Optimization 2022), and all NLPs via SNOPT (Gill et al. 2005).\nWe solve instances for eight project types and 50 periods, and we scale the number of individuals from 15 to 75. Because exactly one project arrives per period, as we increase the number of individuals, we also increase the durations and resource requirements of the project types, in order tomaintain a reasonable balance of workload with demand. In this section, we report on one instance of each size, whereas in the online appendix, we provide an additional four instances for each problem size. We do not observe any qualitative difference in the results of the additional instances.\nIn our implementation of the bound of Section 4.3, we terminate the weak cut generation when the cumulative change in the value of the LP in 10 consecutive iterations is smaller than 0.33%. Subsequently, we compute an upper bounding certificate using 40 iterations of the subgradient algorithm for the outside minimization of (21). We note that these criteria for terminating the generation of cuts and themultiplier searchmay be\nTable 3. Numerical Results for |P| 8 and T 50\nProblem Revenue/employee ($1,000) Performance\n|I| k Duration Simh SimNLP SimAFF UBT UBNLP UBAFF Perf"
        },
        {
            "heading": "15 6 3\u20136 28.4 6 0.21 27.4 6 0.22 28.5 6 0.2 48.8 39.7 33.7 84.6",
            "text": ""
        },
        {
            "heading": "15 7 4\u20137 25.5 6 0.18 24.1 6 0.19 25.4 6 0.18 58.0 42.4 34.5 73.9",
            "text": ""
        },
        {
            "heading": "20 6 4\u20137 24.4 6 0.21 23.6 6 0.18 24.7 6 0.19 40.5 33.4 29.3 84.3",
            "text": ""
        },
        {
            "heading": "20 8 4\u20137 26.3 6 0.2 25.3 6 0.21 26.3 6 0.21 58.2 42.4 33.6 78.3",
            "text": ""
        },
        {
            "heading": "25 7 4\u20137 22.0 6 0.17 21.1 6 0.18 22.1 6 0.16 38.8 31.8 27.1 81.5",
            "text": ""
        },
        {
            "heading": "25 8 5\u20138 26.8 6 0.2 25.8 6 0.19 26.9 6 0.19 53.7 41.6 34.7 77.5",
            "text": ""
        },
        {
            "heading": "30 7 5\u20138 26.0 6 0.19 24.9 6 0.2 26.4 6 0.21 44.6 35.9 31.1 84.9",
            "text": ""
        },
        {
            "heading": "30 9 5\u20138 25.1 6 0.18 24.3 6 0.18 25.7 6 0.18 46.3 36.5 32.5 79.1",
            "text": ""
        },
        {
            "heading": "35 8 5\u20138 31.5 6 0.21 30.5 6 0.22 31.7 6 0.22 52.1 42.3 37.7 84.1",
            "text": ""
        },
        {
            "heading": "35 9 6\u20139 28.2 6 0.2 26.7 6 0.19 28.3 6 0.2 46.1 39.5 34.9 81.1",
            "text": ""
        },
        {
            "heading": "40 8 6\u20139 25.9 6 0.2 23.8 6 0.18 25.8 6 0.22 43.5 36.0 31.5 82.2",
            "text": ""
        },
        {
            "heading": "40 10 6\u20139 28.2 6 0.22 26.9 6 0.2 28.5 6 0.19 48.6 41.9 36.3 78.5",
            "text": ""
        },
        {
            "heading": "45 9 6\u20139 29.1 6 0.18 27.8 6 0.19 29.0 6 0.2 48.9 40.1 36.2 80.4",
            "text": ""
        },
        {
            "heading": "45 10 7\u201310 24.2 6 0.21 22.4 6 0.16 24.6 6 0.21 39.5 33.4 29.0 84.8",
            "text": ""
        },
        {
            "heading": "50 9 7\u201310 25.2 6 0.21 24.5 6 0.19 25.6 6 0.21 38.5 34.3 30.5 83.9",
            "text": ""
        },
        {
            "heading": "50 11 7\u201310 28.5 6 0.2 27.5 6 0.2 28.9 6 0.2 51.0 41.1 36.5 79.2",
            "text": ""
        },
        {
            "heading": "55 10 7\u201310 25.1 6 0.22 23.9 6 0.18 25.5 6 0.2 39.8 35.2 31.2 81.7",
            "text": ""
        },
        {
            "heading": "55 11 8\u201311 24.4 6 0.19 23.6 6 0.17 25.1 6 0.18 43.6 35.6 32.7 76.8",
            "text": ""
        },
        {
            "heading": "60 10 8\u201311 20.5 6 0.19 20.2 6 0.15 21.1 6 0.18 32.7 26.7 24.9 84.7",
            "text": ""
        },
        {
            "heading": "60 12 8\u201311 28.1 6 0.21 26.5 6 0.19 28.4 6 0.2 47.1 39.0 36.8 77.2",
            "text": ""
        },
        {
            "heading": "65 11 8\u201311 28.5 6 0.2 26.4 6 0.16 29.0 6 0.2 46.4 38.8 36.7 79.0",
            "text": ""
        },
        {
            "heading": "65 12 9\u201312 25.9 6 0.2 23.9 6 0.18 26.0 6 0.21 44.9 35.7 33.7 77.2",
            "text": ""
        },
        {
            "heading": "70 11 9\u201312 29.4 6 0.21 27.6 6 0.19 29.4 6 0.24 46.0 38.8 37.3 78.8",
            "text": ""
        },
        {
            "heading": "70 13 9\u201312 27.8 6 0.2 26.6 6 0.17 28.3 6 0.22 51.4 40.4 38.9 72.8",
            "text": ""
        },
        {
            "heading": "75 12 9\u201312 28.2 6 0.21 26.0 6 0.18 28.0 6 0.23 45.5 38.2 36.3 77.7",
            "text": ""
        },
        {
            "heading": "75 13 10\u201313 26.9 6 0.21 25.0 6 0.16 26.8 6 0.24 43.6 36.7 35.0 76.9",
            "text": "Notes. The column UBT shows the theoretical bound of Proposition 7. Column UBNLP shows the upper bound obtained via the deterministic NLP method described in Section 4.2 with the tightening based on simulated arrivals: we simulate arrivals 50 times, and we report the upper end of the 99% confidence interval of E[O(DWup(t))] as an upper bound. Column UBAFF shows the upper bound obtained via the methodology of Section 4.3.\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nchanged for a different trade-off between bound tightness and computation time. We have kept all parameters constant for all instances.\nWe also report 90% confidence intervals for the expected revenue generated by the greedy policy (9) via forward simulation of 500 paths. The confidence interval obtained when using the marginal values n\u0302 from the heuristic of Section 4.1 is given in column Simh of Table 3. In column SimNLP, we give the interval we obtain if we instead substitute the opportunity cost 1ts\nT(n\u0302t+10 \u2212 n\u0302t+1[0\u22121+dpxp]+ ) in (9) with the opportunity cost of assigning xp at time t for duration dp, as estimated via the dual solutions of (DWup(t)), averaged over the 50 runs. Column SimAFF contains the interval corresponding to the marginal values n\u0303 coming from the upper bounding LP of Section 4.3. In the last column, Perf, we define performance as the best of the three policies using the ratio max{SimLP,Simh,SimNLP}min{UBAFF,UBNLP,UBT} : Because in the denominator we substitute the best upper bound in place of the unknown optimal expected revenue, the reported performance metric is a conservative estimate.\nIt is evident that both numerical bounds consistently outperform the theoretical bound of Proposition 7, although the affine bound is consistently tighter than the NLP bound. Furthermore, the policy implied by the affine bound is in general generatingmore revenue, but not via a large margin. As the heuristic is much more efficient, it might become a sensible choice if no upper bound is needed and computational resources are limited. The (classical) policy implied via theNLP is clearly dominated.\nComputational times of all procedures can be found in Table 4. We implemented a parallel version of all procedures in this paper, and we report the impact on computational efficiency of using 10 parallel threads. Parallelizing the forward simulations is straightforward, as we can run the 500 paths in parallel. The same goes for the simulation-based bound of UBNLP, for which we simulate arrivals 50 times. In the computation of UBAFF, we run concurrently per period (a) the local optimization problems (20) in the weak cut generation process and (b) the upper bound certificate process. The only part of the UBAFF that cannot be parallelized is the LP (16)\u2013(18), which we solve repeatedly during the constraint generation process.\nTable 4. Elapsed Times for |P| 8 and T 50\nProblem Elapsed time: 10 threads Elapsed time: 1 thread\n|I| k Duration Sim UBNLP UBAFF Sim UBNLP UBAFF"
        },
        {
            "heading": "15 6 3\u20136 1 21 56 + 6 6 126 239 + 5",
            "text": ""
        },
        {
            "heading": "15 7 4\u20137 1 9 58 + 4 6 58 252 + 4",
            "text": ""
        },
        {
            "heading": "20 6 4\u20137 1 21 62 + 12 7 97 296 + 11",
            "text": ""
        },
        {
            "heading": "20 8 4\u20137 1 34 85 + 15 12 160 407 + 16",
            "text": ""
        },
        {
            "heading": "25 7 4\u20137 2 42 78 + 38 16 379 402 + 34",
            "text": ""
        },
        {
            "heading": "25 8 5\u20138 3 24 83 + 47 17 129 420 + 50",
            "text": ""
        },
        {
            "heading": "30 7 5\u20138 3 33 111 + 89 23 222 540 + 100",
            "text": ""
        },
        {
            "heading": "30 9 5\u20138 3 45 91 + 161 22 240 562 + 156",
            "text": ""
        },
        {
            "heading": "35 8 5\u20138 4 54 150 + 237 30 341 897 + 234",
            "text": ""
        },
        {
            "heading": "35 9 6\u20139 3 94 118 + 220 26 490 745 + 217",
            "text": ""
        },
        {
            "heading": "40 8 6\u20139 4 44 133 + 239 34 411 860 + 233",
            "text": ""
        },
        {
            "heading": "40 10 6\u20139 7 111 146 + 429 47 630 957 + 404",
            "text": ""
        },
        {
            "heading": "45 9 6\u20139 6 99 177 + 652 45 531 1,203 + 645",
            "text": ""
        },
        {
            "heading": "45 10 7\u201310 6 49 132 + 302 47 349 910 + 292",
            "text": ""
        },
        {
            "heading": "50 9 7\u201310 7 200 163 + 498 49 526 1,194 + 511",
            "text": ""
        },
        {
            "heading": "50 11 7\u201310 9 566 175 + 1,136 66 2,579 1,284 + 1,157",
            "text": ""
        },
        {
            "heading": "55 10 7\u201310 11 100 202 + 1,110 76 568 1,570 + 1,110",
            "text": ""
        },
        {
            "heading": "55 11 8\u201311 10 393 182 + 1,349 78 2,519 1,408 + 1,375",
            "text": ""
        },
        {
            "heading": "60 10 8\u201311 10 783 178 + 930 66 5,214 1,428 + 932",
            "text": ""
        },
        {
            "heading": "60 12 8\u201311 15 127 212 + 2,028 108 805 1,688 + 2,038",
            "text": ""
        },
        {
            "heading": "65 11 8\u201311 13 287 246 + 2,195 93 886 1,989 + 2,219",
            "text": ""
        },
        {
            "heading": "65 12 9\u201312 10 197 203 + 2,077 87 907 1,620 + 2,103",
            "text": ""
        },
        {
            "heading": "70 11 9\u201312 17 154 283 + 2,235 124 805 2,316 + 2,256",
            "text": ""
        },
        {
            "heading": "70 13 9\u201312 16 366 259 + 2,781 135 1,886 2,048 + 2,812",
            "text": ""
        },
        {
            "heading": "75 12 9\u201312 17 363 228 + 4,642 129 2,030 1,828 + 4,679",
            "text": ""
        },
        {
            "heading": "75 13 10\u201313 18 386 236 + 4,117 135 1,397 1,936 + 4,168",
            "text": "Notes. In column Sim, we report the elapsed time of the forward simulation based on the heuristic of Section 4.1. Elapsed times of the forward simulation when using marginal values based on the bounding procedures are of similar scale, but the corresponding upper bounds have to be computed first. For the affine bound, the running time in column UBAFF is decomposed into two parts: the (parallelizable) time for the cut generation and bound verification plus the time spent in the LP (which dominates for larger problems).\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nThe (500 paths of the) forward simulation using the heuristic is quite efficient and terminates for all instances in a couple ofminutes, and in the parallel implementation, in less than 20 seconds. The NLP bound is also quite efficient, especially in the parallel version, where for all problems, we can compute it in under 800 seconds. The LP bound is more challenging computationally. Somehow surprisingly, the bottleneck is neither the nonlinear separation problem nor the rather involved verification step, which can be parallelized and take less than 300 seconds in total for all instances. In the latter case, the isolation of the nonconvexity to one variable plays a critical role in keeping the times of the branch-and-bound algorithm low. Rather, the bottleneck is the repetitive solution of the LP itself, which cannot be parallelized, grows in size, and becomes time-consuming to solve. Still, it is evident that the methodology is applicable to moderate-size instances, as all instances can be handledwithin a couple of hours."
        },
        {
            "heading": "5.2. Effect of the Labor Force",
            "text": "As a buildup to Section 5.3 on optimal hiring, we perform experiments to determine various workforce performance measures as a function of employee hiring. We use parameters |P| 8, T 100, dmin 8, dmax 14, and k 6, and vary the number of resources |I| between 15 and 75. The first 15 employees are one of each type of each capability. The rest are generated randomly as described in Section 5.1, and thus the pool includes both high- and low-quality employees. This is in contrast with the next section, where we will be selecting employees (at different costs) to optimize\nprofit. We simulate 500 paths, and we collect statistics on the performance of the greedy policy implied by the heuristic as we add employees. On average, in every period, a demand of D \u2211p\u03bbpkpdp workdays arrives, which, for this particular experiment, is just under 53. We report the workforce as a percentage of D. As we start with 15 employees, one of each type, the minimum workforce size we consider is 1553.\nIn Figure 3, we observe that as the workforce increases, both the bid and the win probability increase. With more employees, we have more flexibility to assign quality bundles, and thus we win projects more often even if we bid higher. A second observation is that although the utilization drops as expected with an increase in workforce, the drop is subproportional. This is due to the increased probability of winning projects as well as the decrease in cases where we do not have enough personnel to staff a project. The latter is a dominating factor when we are low on resources. Of course, if we look at utilization separately for each capability group, the utilization of weak employees drops very fast as stronger employees become available. The revenue per day per employed person initially increases, as a very small pool of employees results in inefficient teams and a high probability of missed opportunities, but relatively early, at a workforce of around 0:55D, it starts to decrease as utilization approaches 70%.\nLet us now assume that the total labor cost \u03c3i per person-day of an employee depends on their capability only, and these costs are $250,$350, $450, $500, and $700, respectively, for employees of capabilities one to five. With these labor costs, the profit and profit per person-day for the random selection (after the first 15) of employees is given in panels (d) and (e) of Figure 3. We observe that the optimal profit is realized for a workforce between 0:65D and 0:8D. Any of these choices is close to optimal (modulo random hiring). The corresponding operational policies are similar in terms of the average bid, where the higher labor cost as we approach 0:8D is compensated via higher competing and project win ratios, due to the increased availability of resources, which also has a secondary effect on assignment quality. Eventually, the increase in revenue cannot counterbalance the increased labor costs, and the profits rapidly drop."
        },
        {
            "heading": "5.3. Hiring Decisions",
            "text": "In Section 5.2, we explored the effect of the labor force on utilization and profit, when employee capability is randomly distributed. Here we explore how we can use our framework tomake informed hiring decisions.\nWe perform a simulation to staff the firm. We keep all parameters identical to those in Section 5.2 (|P| 8, T 100, dmin 8, dmax 14, and k 6). Just like in\nFigure 2. (Color online) Win Probability for \u03b2pb 0:01 and \u03b2pq 0:4 for Different Values of Q\u0304\n600 800 1,000 1,200 1,400\n0.2\n0.4\n0.6\n0.8\nBid($/workday)\nW in\np ro\nb a b il it y\n5 7 9 11 13\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nFigure 4. (Color online) Effect of Increasing Randomly HiredWorkforce According to Hiring Rule (24)\n0.4 0.6 0.8 1 1.2 1.4 0\n20\n40\n60\n80\nWorkforce\n%\nNo Compete Win Utilization\n0.4 0.6 0.8 1 1.2 1.4 400\n600\n800\n1,000\nWorkforce\n$\nBid Revenue(MD) Labor cost(MD)\n0.4 0.6 0.8 1 1.2 0\n0.1\n0.2\n0.3\nWorkforce size\n% of\nw or\nkf or\nce\n1 2 3 4 5\n0.4 0.6 0.8 1 1.2 1.4\n\u2212200\n0\n200\n400\n600\n800\nWorkforce\n$( 1,\n00 0)\nProfit\n0.4 0.6 0.8 1 1.2 1.4\n0\n50\n100\n150\n200\nWorkforce\n$\nProfit per man day\n(a) (b) (c)\n(d) (e)\nNotes. Panel (a) shows the percentage of projects that we did not compete for because of insufficient resources, the winning percentage when competing, and utilization. Panel (b) shows the average bid and revenue per employee per day. Remaining panels show the workforce decomposed by (c) capability level, (d) profit, and (e) profit per man day.\nFigure 3. (Color online) Effect of Increasing Randomly HiredWorkforce\n0.4 0.6 0.8 1 1.2 1.4 0\n20\n40\n60\nWorkforce\n%\nNo Compete Win Utilization\n0.4 0.6 0.8 1 1.2 1.4\n400\n600\n800\nWorkforce\n$\nAverage bid Revenue per man day\n0.4 0.6 0.8 1 1.2 1.4\n20\n40\n60\n80\nWorkforce\nU ti\nliz at\nio n\n5 4 3 2 1\n0.4 0.6 0.8 1 1.2 1.4\n200\n400\n600\nWorkforce\n$( 1,\n00 0)\nProfit\n0.4 0.6 0.8 1 1.2 1.4\n50\n100\n150\n200\nWorkforce\n$\nProfit per man day\n(a) (b) (c)\n(d) (e)\nNotes. Panel (a) shows the percentage of projects the firm did not compete for because of insufficient resources, the winning percentage when competing, and utilization. Panel (b) shows the average bid and revenue per employee per day. Remaining panels show the workforce decomposed by (c) utilization by capability level, (d) profit, and (e) profit per man day.\nD ow\nnl oa\nde d\nfr om\nin fo\nrm s.\nor g\nby [\n80 .5\n7. 15\n.1 43\n] on\n1 4\nO ct\nob er\n2 02\n2, a\nt 0 5:\n56 .\nFo r\npe rs\non al\nu se\no nl\ny, a\nll ri\ngh ts\nr es\ner ve\nd.\nSection 5.2, initially we start with 15 employees, one for each combination of type (A\u2013C) and capability (1\u20135). Then we hire employees, one at a time, as follows:\n1. We estimate the increase in revenue from hiring an extra employee of type j \u2208 (a,b, c) and capability l \u2208 {1, 2, 3, 4, 5} to be R+l,j mini\u2208I{\u03bd\u03020i,0|C(i) l, type(i) j}; that is, if we have multiple employees of the same type/capability, we take the minimum marginal value of those employees to be an estimate for the increase in revenue from hiring one more.\n2. Wemake the hire that maximizes\nR+l,j \u2212 \u03c3l: (24)\nIn Figure 4, we observe that the optimal profit is achieved with a workforce of around 0:75D, with an approximate 20% increase in profit compared with that achieved by random hiring, whereas the corresponding utilization is slightly below 70%.\nInitially, as we increase the workforce up to 0:45D, the utilization does not drop and stays close to 75%. As long as we cannot compete for most of the projects, we can effectively just scale up. The average labor cost, which reflects average workforce capability, stays fairly constant until we reach 0:6D and then starts to increase. This reflects the initial need to increase availability of resources to be able to compete for more projects, when quality is a secondary concern. Once we can compete for close to 80% of projects, quality becomes a primary concern, and we hire employees of higher quality (see Figure 4(c)).\nWe note that even in the early stages, although we do not focus on hiring capable employees, the average bid increases. This is because, in contrast to the initial random selection of employees, we select the type of our hires according to demand, increasing the quality of the matches.\nThe peak profit per employed person is achieved earlier for a workforce of 0:45D. The same goes for the revenue per employed person, which reaches the maximum at around 0:45D and stays fairly constant until 1D, when it starts decreasing. To maintain this revenue per person-day, however, we invest in increasingly more qualified employees, raising the average labor costs from 0:6D onward.\nA point worth discussing is when to stop hiring. We caution that whereas the selection criterion of maximizing Rl,j \u2212 \u03c3l is sensible, a stopping criterion of stopping when this maximal value reaches zero would stop too late. The reason is that the estimate Rl,j is optimistic (see Figure 5)."
        },
        {
            "heading": "6. Conclusions",
            "text": "In this paper, we examined some common workforce analytical and decision problems of a PSF in a revenue management framework. Using a stylized Markov chain model, we first argued that it is in the PSF\u2019s interest to be transparent on the supplied quality rather than wait for its delayed effects on reputation. By formulating the problem rigorously and developing good computational procedures, we are able to analyze a number of interesting questions and gain clear insights on the optimal number and mix of staff skills. For a managing partner of a PSF, our paper gives a tool kit for making bidding and assignment decisions under a qualityrevelation model, which applies to important, largescale projects. We hope that this paper spurs research into the operations of PSFs and brings modern analytical tools to help their management."
        },
        {
            "heading": "Acknowledgments",
            "text": "The authors thank the review team for many constructive comments that improved the paper.\nEndnote 1 We further elaborate on the different settings and their relevance to industry in the online appendix."
        }
    ],
    "title": "Revenue Management of a Professional Services Firm with Quality Revelation",
    "year": 2022
}