{
    "abstractText": "Scientific article summarization poses a challenge because the interpretability of the article depends on the objective, experience of the reader. Editors/Chairs assign experts in the domain as peer reviewers. These experts often write a summary of the article at the beginning of their reviews which offers a summarized view of their understanding (perspectives) on the given paper. Multiperspective summaries can provide multiple related but distinct perspectives of the reviewers rather than being influenced by a single summary. Here in this work, we propose a method to produce abstractive multiperspective summaries of scientific articles leveraging peer reviews. Our proposed method includes performing extractive summarization to identify the essential parts of the paper by extracting contributing sentences. In the subsequent step, we utilize the extracted pertinent information to condition a transformerbased language model comprising of a single encoder followed by multiple decoders that share weights. Our goal is to train the decoder to not only learn from a single reference summary but also to take into account multiple perspectives when generating the summary during the inference stage. Experimental results show that our approach achieves the best average ROUGE F1 Score, ROUGE-2 F1 Score, and ROUGE-L F1 Score with respect to the comparing systems. We make our code public for further research.",
    "authors": [
        {
            "affiliations": [],
            "name": "Sandeep Kumar"
        },
        {
            "affiliations": [],
            "name": "Guneet Singh Kohli"
        },
        {
            "affiliations": [],
            "name": "Tirthankar Ghosal"
        },
        {
            "affiliations": [],
            "name": "Asif Ekbal"
        }
    ],
    "id": "SP:4cb6fd574ef2b65f80498b3493573e300e4a2456",
    "references": [
        {
            "authors": [
                "A. Akkasi"
            ],
            "title": "Multi perspective scientific document summarization with graph attention networks (GATS)",
            "venue": "Proceedings of the Third Workshop on Scholarly Document Processing. pp. 268\u2013272",
            "year": 2022
        },
        {
            "authors": [
                "H. Arora",
                "T. Ghosal",
                "S. Kumar",
                "S. Patwal",
                "P. Gooch"
            ],
            "title": "INNOVATORS at semeval-2021 task-11: A dependency parsing and bert-based model for extracting contribution knowledge from scientific papers",
            "venue": "Palmer, A., Schneider, N., 14 S. Kumar et al. Schluter, N., Emerson, G., Herbelot, A., Zhu, X. (eds.) Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021. pp. 502\u2013510. Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "S. Auer",
                "A. Oelen",
                "M. Haris",
                "M. Stocker",
                "J. D\u2019Souza",
                "K.E. Farfar",
                "L. Vogt",
                "M. Prinz",
                "V. Wiens",
                "M.Y. Jaradeh"
            ],
            "title": "Improving access to scientific literature with knowledge graphs",
            "venue": "Bibliothek Forschung und Praxis 44(3), 516\u2013529",
            "year": 2020
        },
        {
            "authors": [
                "M. Cao"
            ],
            "title": "A survey on neural abstractive summarization methods and factual consistency of summarization",
            "venue": "CoRR abs/2204.09519",
            "year": 2022
        },
        {
            "authors": [
                "Z. Cao",
                "F. Wei",
                "S. Li",
                "W. Li",
                "M. Zhou",
                "H. Wang"
            ],
            "title": "Learning summary prior representation for extractive summarization",
            "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). pp. 829\u2013833. Association for Computational Linguistics, Beijing, China",
            "year": 2015
        },
        {
            "authors": [
                "M.K. Chandrasekaran",
                "G. Feigenblat",
                "E.H. Hovy",
                "A. Ravichander",
                "M. ShmueliScheuer",
                "A. de Waard"
            ],
            "title": "Overview and insights from the shared tasks at scholarly document processing 2020: Cl-scisumm, laysumm and longsumm",
            "venue": "Chandrasekaran, M.K., de Waard, A., Feigenblat, G., Freitag, D., Ghosal, T., Hovy, E.H., Knoth, P., Konopnicki, D., Mayr, P., Patton, R.M., Shmueli-Scheuer, M. (eds.) Proceedings of the First Workshop on Scholarly Document Processing, SDP@EMNLP 2020, Online, November 19, 2020. pp. 214\u2013224. Association for Computational Linguistics",
            "year": 2020
        },
        {
            "authors": [
                "J. Cheng",
                "M. Lapata"
            ],
            "title": "Neural summarization by extracting sentences and words",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). pp. 484\u2013494. Association for Computational Linguistics, Berlin, Germany",
            "year": 2016
        },
        {
            "authors": [
                "J. Chung",
                "\u00c7. G\u00fcl\u00e7ehre",
                "K. Cho",
                "Y. Bengio"
            ],
            "title": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
            "year": 2014
        },
        {
            "authors": [
                "A. Cohan",
                "F. Dernoncourt",
                "D.S. Kim",
                "T. Bui",
                "S. Kim",
                "W. Chang",
                "N. Goharian"
            ],
            "title": "A discourse-aware attention model for abstractive summarization of long documents",
            "venue": "Walker, M.A., Ji, H., Stent, A. (eds.) Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 2 (Short Papers). pp. 615\u2013621. Association for Computational Linguistics",
            "year": 2018
        },
        {
            "authors": [
                "A. Cohan",
                "G. Feigenblat",
                "T. Ghosal",
                "M. Shmueli-Scheuer"
            ],
            "title": "Overview of the first shared task on multi perspective scientific document summarization (mup)",
            "venue": "Proceedings of the Third Workshop on Scholarly Document Processing,",
            "year": 2022
        },
        {
            "authors": [
                "A. Cohan",
                "N. Goharian"
            ],
            "title": "Scientific document summarization via citation contextualization and scientific discourse",
            "venue": "Int. J. Digit. Libr. 19(2-3), 287\u2013303",
            "year": 2018
        },
        {
            "authors": [
                "J. D\u2019Souza",
                "S. Auer",
                "T. Pedersen"
            ],
            "title": "SemEval-2021 task 11: NLPContributionGraph - structuring scholarly NLP contributions for a research knowledge graph",
            "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021). pp. 364\u2013376. Association for Computational Linguistics, Online",
            "year": 2021
        },
        {
            "authors": [
                "A. Elkiss",
                "S. Shen",
                "A. Fader",
                "G. Erkan",
                "D.J. States",
                "D.R. Radev"
            ],
            "title": "Blind men and elephants: What do citation summaries tell us about a research article? J",
            "venue": "Assoc. Inf. Sci. Technol. 59(1), 51\u201362",
            "year": 2008
        },
        {
            "authors": [
                "S. Erera",
                "M. Shmueli-Scheuer",
                "G. Feigenblat",
                "O.P. Nakash",
                "O. Boni",
                "H. Roitman",
                "D. Cohen",
                "B. Weiner",
                "Y. Mass",
                "O. Rivlin",
                "G. Lev",
                "A. Jerbi",
                "J. Herzig",
                "Y. Hou",
                "C. Jochim",
                "M. Gleize",
                "F. Bonin",
                "D. Konopnicki"
            ],
            "title": "A summarization system for scientific documents",
            "venue": "Pad\u00f3, S., Huang, R. (eds.) Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019 - System Demonstrations. pp. 211\u2013216. Association for Computational Linguistics",
            "year": 2019
        },
        {
            "authors": [
                "G. Erkan",
                "D.R. Radev"
            ],
            "title": "Lexrank: Graph-based lexical centrality as salience in text summarization",
            "venue": "CoRR abs/1109.2128",
            "year": 2011
        },
        {
            "authors": [
                "S. Ghosh Roy",
                "N. Pinnaparaju",
                "R. Jain",
                "M. Gupta",
                "V. Varma"
            ],
            "title": "Summaformers @ LaySumm 20, LongSumm 20",
            "venue": "Proceedings of the First Workshop on Scholarly Document Processing. pp. 336\u2013343. Association for Computational Linguistics, Online",
            "year": 2020
        },
        {
            "authors": [
                "A. Gidiotis",
                "S. Stefanidis",
                "G. Tsoumakas"
            ],
            "title": "AUTH @ CLSciSumm 20, LaySumm 20, LongSumm 20",
            "venue": "Proceedings of the First Workshop on Scholarly Document Processing. pp. 251\u2013260. Association for Computational Linguistics, Online",
            "year": 2020
        },
        {
            "authors": [
                "K. Gupta",
                "A. Ahmad",
                "T. Ghosal",
                "A. Ekbal"
            ],
            "title": "Contrisci: A bert-based multitasking deep neural architecture to identify contribution statements from research papers",
            "venue": "International Conference on Asian Digital Libraries. pp. 436\u2013452. Springer",
            "year": 2021
        },
        {
            "authors": [
                "D. Harman",
                "P. Over"
            ],
            "title": "The effects of human variation in DUC summarization evaluation",
            "venue": "Text Summarization Branches Out. pp. 10\u201317",
            "year": 2004
        },
        {
            "authors": [
                "K.M. Hermann",
                "T. Kocisk\u00fd",
                "E. Grefenstette",
                "L. Espeholt",
                "W. Kay",
                "M. Suleyman",
                "P. Blunsom"
            ],
            "title": "Teaching machines to read and comprehend",
            "year": 2015
        },
        {
            "authors": [
                "E. Hirsch",
                "A. Eirew",
                "O. Shapira",
                "A. Caciularu",
                "A. Cattan",
                "O. Ernst",
                "R. Pasunuru",
                "H. Ronen",
                "M. Bansal",
                "I. Dagan"
            ],
            "title": "ifacetsum: Coreference-based interactive faceted summarization for multi-document exploration",
            "venue": "Adel, H., Shi, 16 S. Kumar et al. S. (eds.) Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, EMNLP 2021, Online and Punta Cana, Dominican Republic, 7-11 November, 2021. pp. 283\u2013297. Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "K. Jaidka",
                "M. Kumar Chandrasekaran",
                "S. Rustagi",
                "M.Y. Kan"
            ],
            "title": "Overview of the CL-SciSumm 2016 shared task. In: Proceedings of the Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL)",
            "year": 2016
        },
        {
            "authors": [
                "S. Kim"
            ],
            "title": "Using pre-trained transformer for better lay summarization",
            "venue": "Proceedings of the First Workshop on Scholarly Document Processing. pp. 328\u2013335. Association for Computational Linguistics, Online",
            "year": 2020
        },
        {
            "authors": [
                "S. Kumar",
                "G.S. Kohli",
                "K. Shinde",
                "A. Ekbal"
            ],
            "title": "Team AINLPML @ MuP in SDP 2021: Scientific document summarization by end-to-end extractive and abstractive approach",
            "venue": "Proceedings of the Third Workshop on Scholarly Document Processing. pp. 285\u2013290",
            "year": 2022
        },
        {
            "authors": [
                "J. Lin",
                "J. Ling",
                "Z. Wang",
                "J. Liu",
                "Q. Chen",
                "L. He"
            ],
            "title": "ECNUICA at SemEval-2021 task 11: Rule based information extraction pipeline",
            "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021). pp. 1295\u20131302. Association for Computational Linguistics, Online",
            "year": 2021
        },
        {
            "authors": [
                "H. Liu",
                "M.J. Sarol",
                "H. Kilicoglu"
            ],
            "title": "Uiuc bionlp at semeval-2021 task 11: A cascade of neural models for structuring scholarly NLP contributions",
            "venue": "Palmer, A., Schneider, N., Schluter, N., Emerson, G., Herbelot, A., Zhu, X. (eds.) Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021. pp. 377\u2013386. Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "Y. Liu",
                "A. Ni",
                "L. Nan",
                "B. Deb",
                "C. Zhu",
                "A.H. Awadallah",
                "D.R. Radev"
            ],
            "title": "Leveraging locality in abstractive text summarization",
            "venue": "CoRR abs/2205.12476",
            "year": 2022
        },
        {
            "authors": [
                "E. Lloret",
                "M.T. Rom\u00e1-Ferri",
                "M. Palomar"
            ],
            "title": "COMPENDIUM: A text summarization system for generating abstracts of research papers",
            "venue": "Data Knowl. Eng. 88, 164\u2013175",
            "year": 2013
        },
        {
            "authors": [
                "X. Ma",
                "J. Wang",
                "X. Zhang"
            ],
            "title": "YNU-HPCC at semeval-2021 task 11: Using a BERT model to extract contributions from NLP scholarly articles",
            "venue": "Palmer, A., Schneider, N., Schluter, N., Emerson, G., Herbelot, A., Zhu, X. (eds.) Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021. pp. 478\u2013484. Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "A. Martin",
                "T. Pedersen"
            ],
            "title": "Duluth at semeval-2021 task 11: Applying deberta to contributing sentence selection and dependency parsing for entity extraction",
            "venue": "Palmer, A., Schneider, N., Schluter, N., Emerson, G., Herbelot, A., Zhu, X. (eds.) Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021. pp. 490\u2013501. Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "S.K. Mishra",
                "H. Kundarapu",
                "N. Saini",
                "S. Saha",
                "P. Bhattacharyya"
            ],
            "title": "IITPAI-NLP-ML@ CL-SciSumm 2020, CL-LaySumm 2020, LongSumm 2020",
            "venue": "Proceedings of the First Workshop on Scholarly Document Processing. pp. 270\u2013276. Association for Computational Linguistics, Online",
            "year": 2020
        },
        {
            "authors": [
                "P. Nakov",
                "A.S. Schwartz",
                "M.A. Hearst"
            ],
            "title": "Citances: Citation sentences for semantic analysis of bioscience",
            "year": 2004
        },
        {
            "authors": [
                "R. Nallapati",
                "B. Zhou",
                "C.N. dos Santos",
                "\u00c7. G\u00fcl\u00e7ehre",
                "B. Xiang"
            ],
            "title": "Abstractive text summarization using sequence-to-sequence rnns and beyond",
            "venue": "Goldberg, Y., Riezler, S. (eds.) Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning, CoNLL 2016, Berlin, Germany, August 11-12, 2016. pp. 280\u2013290. ACL",
            "year": 2016
        },
        {
            "authors": [
                "D. Parveen",
                "H.M. Ramsl",
                "M. Strube"
            ],
            "title": "Topical coherence for graph-based extractive summarization",
            "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. pp. 1949\u20131954. Association for Computational Linguistics, Lisbon, Portugal",
            "year": 2015
        },
        {
            "authors": [
                "V. Qazvinian",
                "D.R. Radev",
                "S.M. Mohammad",
                "B.J. Dorr",
                "D.M. Zajic",
                "M. Whidby",
                "T. Moon"
            ],
            "title": "Generating extractive summaries of scientific paradigms",
            "year": 2014
        },
        {
            "authors": [
                "S. Reddy",
                "N. Saini",
                "S. Saha",
                "P. Bhattacharyya"
            ],
            "title": "IIITBH-IITP@CL-SciSumm20, CL-LaySumm20, LongSumm20",
            "venue": "Proceedings of the First Workshop on Scholarly Document Processing. pp. 242\u2013250. Association for Computational Linguistics, Online",
            "year": 2020
        },
        {
            "authors": [
                "S. Shailabh",
                "S. Chaurasia",
                "A. Modi"
            ],
            "title": "Knowgraph@iitk at semeval-2021 task 11: Building knowledge graph for NLP research",
            "venue": "Palmer, A., Schneider, N., Schluter, N., Emerson, G., Herbelot, A., Zhu, X. (eds.) Proceedings of the 15th International Workshop on Semantic Evaluation, SemEval@ACL/IJCNLP 2021, Virtual Event / Bangkok, Thailand, August 5-6, 2021. pp. 467\u2013477. Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "S. Sotudeh",
                "N. Goharian"
            ],
            "title": "Towards generating topicaware multi-perspective summaries for scientific documents",
            "venue": "MuP",
            "year": 2022
        },
        {
            "authors": [
                "S. Subramanian",
                "R. Li",
                "J. Pilault",
                "C.J. Pal"
            ],
            "title": "On extractive and abstractive neural document summarization with transformer language models",
            "venue": "CoRR abs/1909.03186",
            "year": 1909
        },
        {
            "authors": [
                "A. Urlana",
                "N. Surange",
                "M. Shrivastava"
            ],
            "title": "LTRC @MuP 2022: Multi-perspective scientific document summarization using pre-trained generation models",
            "venue": "Proceedings of the Third Workshop on Scholarly Document Processing. pp. 279\u2013284",
            "year": 2022
        },
        {
            "authors": [
                "A. Vaswani",
                "N. Shazeer",
                "N. Parmar",
                "J. Uszkoreit",
                "L. Jones",
                "A.N. Gomez",
                "L. Kaiser",
                "I. Polosukhin"
            ],
            "title": "Attention is all you need",
            "year": 2017
        },
        {
            "authors": [
                "M. Yasunaga",
                "J. Kasai",
                "R. Zhang",
                "A. Fabbri",
                "I. Li",
                "D. Friedman",
                "D. Radev"
            ],
            "title": "ScisummNet: A large annotated corpus and content-impact models for scientific paper summarization with citation networks",
            "venue": "Proceedings of AAAI 2019",
            "year": 2019
        },
        {
            "authors": [
                "K. Zechner"
            ],
            "title": "Fast generation of abstracts from general domain text corpora by extracting relevant sentences",
            "venue": "International Conference on Computational Linguistics, Proceedings of the Conference,",
            "year": 1996
        },
        {
            "authors": [
                "G. Zhang",
                "Y. Su",
                "C. He",
                "L. Lin",
                "C. Sun",
                "L. Shan"
            ],
            "title": "ITNLP at SemEval2021 task 11: Boosting BERT with sampling and adversarial training for knowledge extraction",
            "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021). pp. 485\u2013489. Association for Computational Linguistics, Online",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Keywords: Peer Reviews \u00b7 Summarization \u00b7 Deep Learning \u00b7 Scholarly document"
        },
        {
            "heading": "1 Introduction",
            "text": "Rapid increases in the number of publications in scientific fields motivates the development of automatic summarization tools for scientific articles. A summary\n4 https://github.com/sandeep82945/Muti-percepective-summarization\nof a scientific article is crucial as it provides a condensed overview of the main points and contributions of the research. It enables readers to quickly grasp the key findings and arguments presented in the paper, thus helping them decide whether they want to invest time in reading the full paper. Additionally, it serves as a reference for future research and discussions and aids editors and reviewers in understanding the paper and making an informed decision on its acceptance or rejection. Furthermore, it is useful for other researchers who wish to cite the paper and need to comprehend the content of the paper.\nSummarizing scientific articles is challenging as it requires understanding complex language and technical terms, condensing lengthy and detailed articles and having subject expertise to properly grasp and comprehend them [1, 27]. Also, it involves condensing multiple perspectives and findings on the same research, which may require subject expertise and critical evaluation skills. The standard approach for evaluating automated summary systems is to compare their output with human-written summaries. However, creating large annotated datasets of human-written summaries for scientific articles is challenging due to the time, effort, and expertise required in summarizing such complex and technical content.\nA common, yet underutilized, source of manuscript summaries lies within the peer review process. Peer reviewers, often experts in the field, provide detailed comments and summaries on the manuscripts they review. Each reviewer has a unique interpretation of the manuscript, bringing to light different aspects of the paper and offering a unique perspective. These multiple summaries of a single manuscript not only demonstrate to the editor how each reviewer has interpreted the manuscript, but also reveal significant differences in perspectives among the reviewers. This offers a rich set of data that can be utilized for generating summaries of scientific articles. This paper proposes a method that capitalizes on these multiple perspectives to create more comprehensive and inclusive summaries of scientific articles. The objective of multiperspective scientific summarization is not to be swayed by a single summary, but to incorporate multiple related but distinct perspectives of the reviewers.\nHowever, a limitation of previous research in this area has been the assumption that each document has only a single optimal, reference summary referred to as a \u201dgold summary\u201d. Different readers can have different perspectives when summarizing the same document, which can result in variations among humanwritten summaries [19]. The accuracy of evaluating summarization systems using automated metrics is hindered by the use of only one reference or \u201cgold\u201d summary [19, 44]. The use of only one reference summary, particularly for longer and complex documents, may prevent the model from effectively capturing important information and different perspectives during training [21].\nOur approach consists of two main stages. First, we employ an extractive summarization process to identify the essential parts of the paper by extracting contributing sentences. This step allows us to capture the most important information and perspectives from the paper based on the reviewers\u2019 comments and interpretations. In the second stage, we use this extracted information to\ncondition a transformer-based language model. Our model architecture includes a single encoder followed by multiple decoders that share weights. This design allows us to train the decoder to not only learn from a single reference summary, but to consider multiple perspectives when generating the summary. The goal is to produce abstractive summaries of scientific documents that capture a holistic view of the manuscript as understood by multiple expert reviewers. By leveraging the insights of multiple experts, we aim to produce summaries that offer a comprehensive understanding of the paper, and allow readers to gain a multi-faceted view of the work. This method provides a promising approach for improving the quality and diversity of automatic scientific article summarization, addressing the challenges posed by the complexity and technicality of scientific content, and harnessing the power of multiple perspectives offered by expert peer reviewers.\nWe summarize our contributions below:\n\u2013 We present a novel two-stage method for multi-perspective summarization. The first stage performs extractive summarization to identify the essential parts of the paper, while the second stage employs an abstractive approach to generate comprehensive summaries. \u2013 We introduce a transformer-based model that uses a single encoder and multiple decoders, enabling the generation of summaries from different perspectives. \u2013 We leverage the wealth of peer review data as a source of multiple expertwritten summaries, which have been previously under-utilized in scientific summarization tasks. \u2013 Our experimental results show that our proposed method outperforms other state-of-the-art systems, achieving the highest average ROUGE-1, ROUGE2, and ROUGE-L F1 scores.\nThe rest of this paper is organized as follows: Section 2 describes the related works of contributing sentence classification, types of summarization, and the scientific paper summarization task, and how our work is different from them. In Section 3, we describe our proposed methodology. In Section 4, we provide detailed information about the experimental setup, including the methodology, results, and human evaluation and analysis. Finally, in Section 5, we conclude the paper and discuss future directions."
        },
        {
            "heading": "2 Related Works",
            "text": "In this section, we discuss the contributing sentences and the work related to their classification task. We then turn our attention to the topic of automatic text summarization before narrowing our focus to scientific paper summarization. Finally, we delineate how our work differs from previous studies in the field."
        },
        {
            "heading": "2.1 Contributing Sentence Classification",
            "text": "In the context of classifying contributing sentences in scholarly NLP contributions, a task featured in SemEval-2021, several strategies were observed [12].\nThe objective of identifying the contribution sentences from articles has typically been approached via two strategies: a binary classification or a multi-class classification. The binary classification approach designated sentences as either contributing or not. For instance, Teams YNU-HPCC [29] and INNOVATORS [2] both leveraged BERT as a binary classifier. The KnowGraph@IITK [37] team employed a SciBERT + BiLSTM architecture, while UIUC BioNLP [26] used BERT, also enhancing it with features related to sentence context. Alternatively, some teams employed a multi-class classification strategy, categorizing sentences into one of the 12 IUs or as non-contributing. Team DULUTH [30] used deBERTa [3] for this task, and ECNUICA [25] deployed an ensemble of RoBERTa, SciBERT, and BERT ([30]). They incorporated context features such as surrounding sentences and paragraph sub-titles. Team ITNLP [45] also used BERT for multi-class classification, adding sentence context and paragraph headings as features.\nThese sentences contribute to the overall understanding of the main ideas, key points, and important details contained within the original source. So, we use contributing sentences to support and enhance the performance of our approach."
        },
        {
            "heading": "2.2 Automatic Text Summarization",
            "text": "Automatic text summarization can be categorized into two main strategies: extractive and abstractive. Extractive summarization focuses on selecting crucial segments from the text and presenting them as they appear in the original document. This is typically done by assessing each sentence\u2019s importance in a document and subsequently selecting the sentences to be included in the summary (Erkan and Radev, 2004 [15]; Parveen, Ramsl, and Strube, 2015 [34]). Neural network-based techniques have shown effectiveness in summarizing news articles (Cao et al., 2015 [5]; Cheng and Lapata, 2016 [7]). On the other hand, abstractive summarization aims to rephrase the important information in a new and condensed form. Abstractive summarization is computationally more complex than extractive summarization and requires a deeper understanding of the original content. However, abstractive methods can generate more concise summaries, even shorter than any sentence in the source document [4]. In Nallapati et al. [33], the authors adapt a bidirectional GRU-RNN [8] as the encoder and an uni-directional GRU-RNN with the same hidden layer size as the decoder. Transformer introduced by Vaswani et al. [41], the Transformer model for abstractive text summarization replaced the recurrent layers with self-attention layers. Instead of processing the input sequentially, the Transformer uses a multi-head self-attention mechanism, which allows it to handle long-range dependencies effectively. It significantly outperformed the RNN/CNN-based models for various tasks, including summarization, due to its superior ability to capture the context and semantics of the input text. This study generates abstractive summary of scientific papers."
        },
        {
            "heading": "2.3 Scientific Paper Summarization",
            "text": "Scientific paper summarization refers to the method of extracting and condensing the key elements from a scholarly research article into a brief, concise overview. This enables the significant information of the research, often complex and extensive, to be communicated in a more digestible and accessible format. Scientific paper summarization is a fast-evolving research field. Extractive models perform sentence selection to create summaries( [35]; Cohan and Goharian [11]), while hybrid models identify salient text and summarize it [39]. Cohan et al. [9] proposed the first model for abstractive summarization of single, longer-form documents like research papers.\nCitation-based summarization leverages inter-paper reference relationships to formulate summaries, concentrating on the citation context and associated texts. This approach uses a paper\u2019s references from other works to generate summaries, providing a significant understanding of the paper\u2019s scientific contribution . Citation-based summarization has been an active area of research with the aim of summarizing the contribution of a target paper. Several studies have been conducted in this area [32, 13, 28, 22], which proposed methods for extracting a set of sentences from the citation sentences to summarize the contribution of the target paper. The generated summaries may not fully capture all important aspects of the target paper. To address this issue, Yasunaga et al. [43] proposed the integration of both the target paper\u2019s abstract and its citation sentences. However, citation summarization helps improve a paper\u2019s summary quality but doesn\u2019t aid authors in drafting the summary while writing the paper.\nIBM Science Summarizer [14] is a system for retrieval and summarization of scientific articles in computer science. It summarizing each section of the relevant paper obtained by search and filtering process independently. Lloret et al. [28] suggested two approaches for generating research article abstracts, one is extractive, and the other is based on extractive and abstractive technique.\nLaySumm 2020 shared task [6] introduced a task of summarizing a technical or scientific document in simple, non-technical language that is comprehensible to a lay person (non-expert). Several teams contributed unique strategies for lay summarization in the competition. Gidiotis et al. [17] and Kim [23] used finetuned versions of the PEGASUS model, with Kim also incorporating a BERTbased extractive model. Reddy et al. [36] used an extractive sentence classification method. Roy et al. [16] leveraged the BART encoder in their systems, while Mishra et al. [31] utilized a standard encoder-decoder framework.\nOur approach is novel in its utilization of multiperspective review summaries written by expert reviewers as the basis for scientific article summarization. This method differs from previous works that rely on a single reference summary, as it leverages the power of multiple reference summaries for training. Unlike previous studies on citation-based summarization, our approach extracts the contributing sentences of the scientific document and uses them directly to generate the summary. The lack of annotated datasets for training models to produce abstractive, multiperspective scientific paper summaries presents a major challenge in the field. To address this issue, we make use of the summaries present in peer\nreview texts. Reviewers in various scientific fields often provide an introductory summary of the main points and key contributions of a paper, and each paper typically receives multiple reviews. Our proposed solution is an end-to-end extractive and abstractive architecture that generates a summary from the input scientific paper. During the training of the abstractive model, multiple golden summaries are used to teach the model how to generate multi-perspective summaries."
        },
        {
            "heading": "3 Methodology",
            "text": "Figure 1 shows the overall proposed architecture of our approach. The abstract and extracted contributing sentences from the full text are used to train the Multi-Perspective Framework. We explain each component of the architecture as follows:-"
        },
        {
            "heading": "3.1 Contributing Sentence Extraction",
            "text": "The main difficulty in summarizing scientific papers is their length and complexity. In this part of our architecture, our goal is to assist the next abstractive model by selecting only the salient enriching part of the full text of the paper. We extract the contributing sentences from the full textual document of the paper using an attention-based deep neural model named ContriSci [18]. ContriSci is a deep neural architecture that leverages multi-task learning to identify statements from a given research article that mention a contribution of the study."
        },
        {
            "heading": "3.2 Multi Perspective Framework",
            "text": "Training: Given a set of extractively selected salient sentences, denoted as C, we initially transform them into a sequence of hidden representations, denoted as M , using a consistent encoder for each target summary. To cater to the task of multi-reference summarization, multiple decoder frameworks are utilized to uncover various possible golden summaries. For a single instance of M , there could be multiple, say k, golden summaries. The decoder functions at the word level to predict these summaries, denoted as Y .\nh (k) t = Decoder(M,yt\u22121) (1)\nHere, k represents the kth decoder for kth golden summary. We implement the teacher forcing method on each decoder with each reference summary to train the decoder.\nP (yt|y<t,C)(k) = softmax(Wdht + bd) (2)\nwhere ht is the hidden representation of yt (the t-th word in the target summary).\nWe maximize the conditional log likelihood for a given N observation (C(i), Y (i))Ni=1\nL (k) MLE = \u2212 i=N\u2211 i=1 t=T\u2211 t=1 logP (y (i) t |y (i) <tC (i)) (3)\nWe aggregated the losses using objective function f\nLMuliMLE = Min(L (1) MLE , L (2) MLE , .., L (k) MLE) (4)\nMultiRouge = fmean(Rouge (1), Rouge(2), .., Rouge(k)) (5)\nWe define our proposed two different aggregation objectives :- First among the losses from the multiple reference summary, we choose the minimum loss for training. In particular, the model was trained using the generated summary that had the smallest loss compared to the reference summary. We refer our proposed architecture with this training objective as Multibest.\nAggLoss = LMuliMLE (6)\nNext, we took the weighted mean of the losses between the k generated summaries and the k reference summaries to generalize the shared weights of the decoders.\nfmean = t=k\u2211 t=1 \u03b2i(V t) (7)\n\u03b2i = V i\u2211t=k t=1 V t (8)\nHere, V i represents the loss associated with the t-th generated summary.\nAggLoss = \u03b11LMuliMLE \u2212 \u03b12MultiRouge (9)\nWe refer to our proposed architecture with this training objective asMultimean. Here, Rouge refers to the Rougue-1 F1 score between the predicted summary and the reference (or golden) summary. The objective during training is to minimize LMultiMLE and maximize the MultiRouge score\n5. In particular, we combine the loss from each reference summary while training the models. Hence the prediction model is capable of generating predictions considering the multiple editor\u2019s perspective learned during training. However, if one of the summaries of a paper deviates significantly from highlighting the overall contribution of the paper and that reference is used during training, the predictions are expected to be less accurate and is one of the main reasons for exploring a multi-perspective approach. For the two different objective functions fbest and fmean we name the corresponding architecture as Multibest and Multimean respectively. We call the final loss after aggregation of the multiple losses as AggLoss.\nInference: During training, the decoder\u2019s weights are shared, so the final weights after training have learned to take into account different perspectives. During inference we initialize a decoder with the weights to generate a single output summary as shown in Figure 1 (b). Given the extractively selected salient sentences C, the encoder first transforms C into a sequence of hidden representations M . After that, the decoder predicts Y at the word level for M .\nht = Decoder(M,yt\u22121) (10)\n5 We set the value of \u03b11: 1 and \u03b12: 100 empirically, weighing the importance and normalizing the two losses given their different scales.\nP (yt|y<t,C)(k) = softmax(Wdht + bd) (11) where ht is the hidden representation of yt (the t-th word in the target\nsummary)."
        },
        {
            "heading": "4 Experiments",
            "text": "In this section, we discuss the results of our proposed model and compare it with other state-of-the-art systems. We aim to demonstrate that using multiple references for summary, rather than just one, can improve the performance compared to traditional abstractive and extractive methods. Additionally, we examine the effect of utilizing extractive summarization techniques, specifically the identification of contribution sentences, prior to the application of the abstractive summarization method. We use the BART autoencoder for pre-training sequence-to-sequence models for the encoder and decoder. The encoder part is a bidirectional encoder that corresponds to the structure of BERT [42], and the decoder part is an auto-regressive decoder following the settings of GPT. During the pre-training process, BART receives the corrupted document as input and predicts the original uncorrupted document. In this way, BART can effectively learn contextual representations. When fine-tuned for the summarization task, the bidirectional encoder part encodes the original document, and the decoder part predicts the reference summary. BART obtains excellent performance on the summarization task.\nWe gave the input to BART as follows: Input text: Abstract [SEP ] Contributing sentences\nHere, the input to the BART model is Abstract, and the contributing sentences separated by a token [SEP ]."
        },
        {
            "heading": "4.1 Dataset",
            "text": "We use the dataset collected from OpenReview by the MuP 2022 shared task for our task. This has been used for training while the hidden test set6 is used for final evaluation. The number of papers used for training, validation, and testing in this experiment are 18,934, 3,604, and 4,610 respectively. The brief description of the dataset can be found in [10]."
        },
        {
            "heading": "4.2 Experimental Settings",
            "text": "To train the ContriSci, we use the default hyperparameters with which ContriSci is trained. We use the BART large fine-tuned on CNN/DailyMail dataset [20] to initialize both our encoder and decoder from the hugging face library 7. We use a dynamic learning rate, warm up 1000 iterations, and decay afterwards. We train the model for 10 epochs with the batch size of 4. We train all the models on a single GPU (NVIDIA A100 80GB).\n6 https://github.com/allenai/mup 7 https://huggingface.co/"
        },
        {
            "heading": "4.3 Result and Analysis",
            "text": "Automatic Evaluation: Table 1 shows that our method Multimean outperforms all the other systems for comparison. To evaluate the performance of our system during inference, we employ the same method used by other comparable systems. Specifically, we calculate the ROUGE score between the generated summary and each reference summary in the paper, then take the average of these scores. GATS describes an extractive summarization approach using GATs to rank sentences in discourse facets of a paper, creating a graph for each article. Our proposed method Multimean is abstractive and outperforms GATS by an average ROUGE score of 8.4. The LTRC system divides a paper into sections such as the abstract, introduction, and conclusion. They found that the best results were achieved when training the model on only the introduction of the paper. GUIR implemented a two-step summarization process. The first step involved extracting the most salient sentences from the document by training a classifier. In the second step, these sentences were used to write an abstractive summary. However, Multimean extracts the most important contributing sentences from each section of the paper to train our model, and it outperforms both LTRC and GUIR by 2.2 and 2.0 average ROUGE score, respectively. The AINLPML system uses a two-stage approach for the task, first an extractive summarization step with a contributing sentence identification model, and then a BART model is fine-tuned on the extracted summary generated from the previous step. They, along with other systems, used only one reference summary for training. However, we used multiple references for training and utilized multiple decoders to generate a multi-perspective summary. Our proposed Multimean outperforms AINLPML by 1.6 points.\nAblation Study: We analyze the effectiveness of our model by performing an ablation study in Table 2. First, we trained the model on a single reference summary by randomly choosing one of the golden summaries from all available golden summaries. In the case of utilizing the abstract and full text of the paper as input text, our proposed approach achieved 25.79 avg. ROUGE F score. Next,\nwe took the abstract of the paper, along with a collection of contribution sentences from the remaining portion of the paper. Our proposed approach achieved 26.50 ROUGE F score. The improvement of 0.29 points in ROUGE F score between the previous architecture and this one clearly shows the significance of the contributing sentences in generating these summaries.\nNext, to understand the effectiveness of the multi-perspective training, we trained the previous architecture in the multi-objective training fashion, i.e., Multibest. The slight improvement observed may be attributed to the method\u2019s similarity to a single reference summary, but with the added benefit of utilizing a best reference summary dynamic rather than a random one. However, we observed a surprising improvement of 1.63 points in the ROUGE F score in our Multimean architecture. This may be because the training objective of this architecture is not biased towards any particular reference summary, but rather aims to generalize the model towards all of the reference summaries. As a result, the model learns from each reference summary, taking into account the perspective of each reviewer.\nHuman Evaluation: In order to conduct our study, we asked four domain experts in NLP (experts with 5+ years of experience in the field) to annotate a set of 150 randomly selected papers, along with their results. We provided the experts with access to the paper PDFs and the ground-truth reviews. The randomly selected papers were from the validation set because the ground-truth review for the test set is private and we do not have access to it. We reimplemented the comparison systems and evaluated the set on them. Following [10], we asked experts to rate the generated summaries according to three characteristics: faithfulness, readability, and coverage, on a Likert scale (1-5). To evaluate the multi-perceptiveness of our proposed architecture, we also defined a characteristic called P-Coverage. We asked experts to rate whether the generated summary captures the key points from each of the reference summaries. The results of\nthe human evaluation can be found in Table 3. Consistent with the automated evaluation results, our approach outperforms the rest of the systems in terms of readability and coverage, and is very close to leading in terms of faithfulness. GATS achieves a better faithfulness score than our proposed method since it is an extractive approach. Additionally, a higher P-Coverage compared to other systems indicates that our proposed system effectively captures a diverse range of perspectives.\nCase Study: The following case study helps us understand the efficacy of multiperspective settings compared to a traditional single one. Table 4 shows a comparison of the generated summary using a single reference (Multibest) and a multiperspective summary (Multimean). Our proposed multi-perspective framework captures various details from multiple target summaries, which are lacking when trained on only a single reference summary. We make the following two observations:\n1) Relationship between parameter and function distances in a Hilbert space: The proposed model summary explains the nontrivial relationship and how it affects optimization, while the other does not mention the relationship between the two distances.\n2) Direct application of L distance to optimization: The single setting summary does not mention how the L distance can be applied directly to optimization, while the multiperspective provides this information.\nOne reviewer mentioned (1) in their summary, and the other mentioned (2), due to which both got included in our output. Now in the single reference setting, the model is trained against a single summary, and since it did not include (1) or (2) perspective, it never got included in the final summary. The multi-\nperspective summary gives a more technical overview of the paper\u2019s methods and results, allowing the reader to gain a deeper understanding of the content and make a more informed evaluation. The use of technical terms and definitions also helps readers who need to become familiar with the field. The proposed Multi-Perspective Framework can provide context for different interpretations of summaries and determine what various reviewers consider important in the final summary. We also performed an error analysis to analyze where our model fails. We discovered that in the case of highly technical papers abundant with mathematical symbols, the model tends to generate somewhat incoherent summaries. Additionally, we found that if the paper\u2019s text, formatted using an automatic PDF parser, is not properly structured (e.g., disjointed sentences, unconnected words), the resultant summary tends to lack coherence."
        },
        {
            "heading": "5 Conclusion and Future Work",
            "text": "We addressed an interesting problem of multiperspective summarization of scientific papers by proposing an end-to-end extractive and abstractive architecture. Our results, based on automated and human evaluations, suggest that this architecture performs better than other comparable systems in addressing this task. We found that the extractive summarization technique, which extracts the paper\u2019s contributions, assists in this task. The results of the experiment and analysis indicate that considering the reviewers\u2019 multiperspective views enhances the summary\u2019s quality and results in improved performance compared to utilizing just one perspective. In the future, we plan to identify other features (such as section information) apart from the paper\u2019s contribution to improving the performance."
        },
        {
            "heading": "Acknowledgement",
            "text": "Sandeep Kumar acknowledges the Prime Minister Research Fellowship (PMRF) program of the Govt of India for its support. Asif Ekbal acknowledges the Young Faculty Research Fellowship (YFRF), supported by Visvesvaraya PhD scheme for Electronics and IT, Ministry of Electronics and Information Technology (MeitY), Government of India, being implemented by Digital India Corporation (formerly Media Lab Asia)."
        }
    ],
    "title": "MuP-SciDocSum: Leveraging Multi-Perspective Peer Review Summaries for Scientific Document Summarization",
    "year": 2024
}