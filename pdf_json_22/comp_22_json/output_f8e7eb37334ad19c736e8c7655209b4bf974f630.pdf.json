{
    "abstractText": "Warning: This paper contains examples of language that some people may find offensive or upsetting. In this paper, we describe the system proposed by the MilaNLP team for the Multimedia Automatic Misogyny Identification (MAMI) challenge. We use Perceiver IO as a multimodal late fusion over unimodal streams to address both sub-tasks A and B. We build unimodal embeddings using Vision Transformer (image) and RoBERTa (text transcript). We enrich the input representation using face and demographic recognition, image captioning, and detection of adult content and web entities. To the best of our knowledge, this work is the first to use Perceiver IO combining text and image modalities. The proposed approach outperforms unimodal and multimodal baselines.",
    "authors": [
        {
            "affiliations": [],
            "name": "Giuseppe Attanasio"
        },
        {
            "affiliations": [],
            "name": "Debora Nozza"
        },
        {
            "affiliations": [],
            "name": "Federico Bianchi"
        }
    ],
    "id": "SP:3cd67c6b844e80cfd9d58713575640a6644d6831",
    "references": [
        {
            "authors": [
                "Giuseppe Attanasio",
                "Debora Nozza",
                "Dirk Hovy",
                "Elena Baralis."
            ],
            "title": "Entropy-based attention regularization frees unintended bias mitigation from lists",
            "venue": "Findings of the Association for Computational Linguistics: ACL2022 (Forthcoming). Association for",
            "year": 2022
        },
        {
            "authors": [
                "Giuseppe Attanasio",
                "Debora Nozza",
                "Eliana Pastor",
                "Dirk Hovy."
            ],
            "title": "Benchmarking Post-Hoc Interpretability Approaches for Transformer-based Misogyny Detection",
            "venue": "Proceedings of the First Workshop on Efficient Benchmarking in NLP. Association for",
            "year": 2022
        },
        {
            "authors": [
                "Giuseppe Attanasio",
                "Eliana Pastor."
            ],
            "title": "PoliTeam @ AMI: Improving sentence embedding similarity with misogyny lexicons for automatic misogyny identificationin italian tweets",
            "venue": "Valerio Basile, Danilo Croce, Maria Maro, and Lucia C. Passaro, editors,",
            "year": 2020
        },
        {
            "authors": [
                "Valerio Basile",
                "Cristina Bosco",
                "Elisabetta Fersini",
                "Debora Nozza",
                "Viviana Patti",
                "Francisco Manuel Rangel Pardo",
                "Paolo Rosso",
                "Manuela Sanguinetti"
            ],
            "title": "SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women",
            "year": 2019
        },
        {
            "authors": [
                "Elisa Bassignana",
                "Valerio Basile",
                "Viviana Patti."
            ],
            "title": "Hurtlex: A multilingual lexicon of words to hurt",
            "venue": "5th Italian Conference on Computational Linguistics, CLiC-it 2018, volume 2253, pages 1\u20136. CEUR-WS.",
            "year": 2018
        },
        {
            "authors": [
                "Federico Bianchi",
                "Giuseppe Attanasio",
                "Raphael Pisoni",
                "Silvia Terragni",
                "Gabriele Sarti",
                "Sri Lakshmi."
            ],
            "title": "Contrastive language-image pretraining for the italian language",
            "venue": "arXiv preprint arXiv:2108.08688.",
            "year": 2021
        },
        {
            "authors": [
                "Efrat Blaier",
                "Itzik Malkiel",
                "Lior Wolf."
            ],
            "title": "Caption enriched samples for improving hateful memes detection",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9350\u20139358, Online and Punta Cana, Do-",
            "year": 2021
        },
        {
            "authors": [
                "Jize Cao",
                "Zhe Gan",
                "Yu Cheng",
                "Licheng Yu",
                "Yen-Chun Chen",
                "Jingjing Liu."
            ],
            "title": "Behind the scene: Revealing the secrets of pre-trained vision-and-language models",
            "venue": "Computer Vision \u2013 ECCV 2020, pages 565\u2013580, Cham. Springer International Publishing.",
            "year": 2020
        },
        {
            "authors": [
                "Elisabetta Fersini",
                "Francesca Gasparini",
                "Giulia Rizzi",
                "Aurora Saibene",
                "Berta Chulvi",
                "Paolo Rosso",
                "Alyssa Lees",
                "Jeffrey Sorensen."
            ],
            "title": "SemEval-2022 Task 5: Multimedia automatic misogyny identification",
            "venue": "Proceedings of the 16th International Work-",
            "year": 2022
        },
        {
            "authors": [
                "Elisabetta Fersini",
                "Debora Nozza",
                "Giulia Boifava."
            ],
            "title": "Profiling Italian misogynist: An empirical study",
            "venue": "Proceedings of the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language, pages 9\u201313, Marseille, France. Euro-",
            "year": 2020
        },
        {
            "authors": [
                "Elisabetta Fersini",
                "Debora Nozza",
                "Paolo Rosso."
            ],
            "title": "Overview of the EVALITA 2018 task on automatic misogyny identification (AMI)",
            "venue": "Proceedings of the 6th evaluation campaign of Natural Language Processing and Speech tools for Italian (EVALITA",
            "year": 2018
        },
        {
            "authors": [
                "Elisabetta Fersini",
                "Debora Nozza",
                "Paolo Rosso."
            ],
            "title": "AMI @ EVALITA2020: Automatic misogyny identification",
            "venue": "Proceedings of the 7th evaluation campaign of Natural Language Processing and Speech tools for Italian (EVALITA 2020), Online.",
            "year": 2020
        },
        {
            "authors": [
                "Stella Frank",
                "Emanuele Bugliarello",
                "Desmond Elliott."
            ],
            "title": "Vision-and-language or vision-forlanguage? on cross-modal influence in multimodal transformers",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process-",
            "year": 2021
        },
        {
            "authors": [
                "Raul Gomez",
                "Jaume Gibert",
                "Lluis Gomez",
                "Dimosthenis Karatzas."
            ],
            "title": "Exploring hate speech detection in multimodal publications",
            "venue": "2020 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 1459\u20131467.",
            "year": 2020
        },
        {
            "authors": [
                "Vijayasaradhi Indurthi",
                "Bakhtiyar Syed",
                "Manish Shrivastava",
                "Nikhil Chakravartula",
                "Manish Gupta",
                "Vasudeva Varma"
            ],
            "title": "FERMI at SemEval-2019 task 5: Using sentence embeddings to identify hate speech against immigrants and women",
            "year": 2019
        },
        {
            "authors": [
                "Andrew Jaegle",
                "Felix Gimeno",
                "Andy Brock",
                "Oriol Vinyals",
                "Andrew Zisserman",
                "Joao Carreira."
            ],
            "title": "Perceiver: General perception with iterative attention",
            "venue": "Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings",
            "year": 2021
        },
        {
            "authors": [
                "Kimmo Karkkainen",
                "Jungseock Joo."
            ],
            "title": "Fairface: Face attribute dataset for balanced race, gender, and age for bias measurement and mitigation",
            "venue": "Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 1548\u20131558.",
            "year": 2021
        },
        {
            "authors": [
                "Douwe Kiela",
                "Hamed Firooz",
                "Aravind Mohan",
                "Vedanuj Goswami",
                "Amanpreet Singh",
                "Pratik Ringshia",
                "Davide Testuggine."
            ],
            "title": "The hateful memes challenge: Detecting hate speech in multimodal memes",
            "venue": "Advances in Neural Information Processing Sys-",
            "year": 2020
        },
        {
            "authors": [
                "Roy Ka-Wei Lee",
                "Rui Cao",
                "Ziqing Fan",
                "Jing Jiang",
                "Wen-Haw Chong."
            ],
            "title": "Disentangling Hate in Online Memes, page 5138\u20135147",
            "venue": "Association for Computing Machinery, New York, NY, USA.",
            "year": 2021
        },
        {
            "authors": [
                "Alyssa Lees",
                "Jeffrey Sorensen",
                "Ian Kivlichan."
            ],
            "title": "Jigsaw @ AMI and HaSpeeDe2: Fine-Tuning a PreTrained Comment-Domain BERT Model",
            "venue": "Proceedings of Seventh Evaluation Campaign of Natu661",
            "year": 2020
        },
        {
            "authors": [
                "T. Lin",
                "P. Goyal",
                "R. Girshick",
                "K. He",
                "P. Dollar."
            ],
            "title": "Focal loss for dense object detection",
            "venue": "volume 42, pages 318\u2013327, Los Alamitos, CA, USA. IEEE Computer Society.",
            "year": 2020
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Jiasen Lu",
                "Dhruv Batra",
                "Devi Parikh",
                "Stefan Lee."
            ],
            "title": "Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks",
            "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Pro-",
            "year": 2019
        },
        {
            "authors": [
                "Hala Mulki",
                "Bilal Ghanem."
            ],
            "title": "Working notes of the workshop arabic misogyny identification (armi2021)",
            "venue": "Forum for Information Retrieval Evaluation, FIRE 2021, page 7\u20138, New York, NY, USA. Association for Computing Machinery.",
            "year": 2021
        },
        {
            "authors": [
                "Debora Nozza."
            ],
            "title": "Exposing the limits of zero-shot cross-lingual hate speech detection",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
            "year": 2021
        },
        {
            "authors": [
                "Debora Nozza",
                "Federico Bianchi",
                "Dirk Hovy"
            ],
            "title": "2022a. Pipelines for Social Bias Testing of Large Language Models",
            "venue": "In Proceedings of the First Workshop on Challenges & Perspectives in Creating Large Language",
            "year": 2022
        },
        {
            "authors": [
                "Debora Nozza",
                "Federico Bianchi",
                "Dirk Hovy."
            ],
            "title": "HONEST: Measuring hurtful sentence completion in language models",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2021
        },
        {
            "authors": [
                "Debora Nozza",
                "Federico Bianchi",
                "Anne Lauscher",
                "Dirk Hovy."
            ],
            "title": "Measuring Harmful Sentence Completion in Language Models for LGBTQIA+ Individuals",
            "venue": "Proceedings of the Second Workshop on Language Technology for Equality, Diversity and In-",
            "year": 2022
        },
        {
            "authors": [
                "Debora Nozza",
                "Claudia Volpetti",
                "Elisabetta Fersini."
            ],
            "title": "Unintended bias in misogyny detection",
            "venue": "IEEE/WIC/ACM International Conference on Web Intelligence, WI \u201919, page 149\u2013155, New York, NY, USA. Association for Computing Machinery.",
            "year": 2019
        },
        {
            "authors": [
                "Shraman Pramanick",
                "Shivam Sharma",
                "Dimitar Dimitrov",
                "Md. Shad Akhtar",
                "Preslav Nakov",
                "Tanmoy Chakraborty."
            ],
            "title": "MOMENTA: A multimodal framework for detecting harmful memes and their targets",
            "venue": "Findings of the Association for Computa-",
            "year": 2021
        },
        {
            "authors": [
                "Alec Radford",
                "Jong Wook Kim",
                "Chris Hallacy",
                "Aditya Ramesh",
                "Gabriel Goh",
                "Sandhini Agarwal",
                "Girish Sastry",
                "Amanda Askell",
                "Pamela Mishkin",
                "Jack Clark",
                "Gretchen Krueger",
                "Ilya Sutskever"
            ],
            "title": "Learning transferable visual models from natural language",
            "year": 2021
        },
        {
            "authors": [
                "Victor Sanh",
                "Lysandre Debut",
                "Julien Chaumond",
                "Thomas Wolf."
            ],
            "title": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
            "venue": "arXiv preprint arXiv:1910.01108.",
            "year": 2019
        },
        {
            "authors": [
                "Weijie Su",
                "Xizhou Zhu",
                "Yue Cao",
                "Bin Li",
                "Lewei Lu",
                "Furu Wei",
                "Jifeng Dai."
            ],
            "title": "Vl-bert: Pre-training of generic visual-linguistic representations",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        },
        {
            "authors": [
                "Hao Tan",
                "Mohit Bansal."
            ],
            "title": "LXMERT: Learning cross-modality encoder representations from transformers",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System",
            "year": 2020
        },
        {
            "authors": [
                "Kelvin Xu",
                "Jimmy Lei Ba",
                "Ryan Kiros",
                "Kyunghyun Cho",
                "Aaron Courville",
                "Ruslan Salakhutdinov",
                "Richard S. Zemel",
                "Yoshua Bengio."
            ],
            "title": "Show, attend and tell: Neural image caption generation with visual attention",
            "venue": "Proceedings of the 32nd International",
            "year": 2015
        },
        {
            "authors": [
                "Ron Zhu."
            ],
            "title": "Enhance multimodal transformer with external label and in-domain pretrain: Hateful meme challenge winning solution",
            "venue": "arXiv preprint arXiv:2012.08290. 662",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022), pages 654 - 662 July 14-15, 2022 \u00a92022 Association for Computational Linguistics\nIn this paper, we describe the system proposed by the MilaNLP team for the Multimedia Automatic Misogyny Identification (MAMI) challenge. We use Perceiver IO as a multimodal late fusion over unimodal streams to address both sub-tasks A and B. We build unimodal embeddings using Vision Transformer (image) and RoBERTa (text transcript). We enrich the input representation using face and demographic recognition, image captioning, and detection of adult content and web entities. To the best of our knowledge, this work is the first to use Perceiver IO combining text and image modalities. The proposed approach outperforms unimodal and multimodal baselines."
        },
        {
            "heading": "1 Introduction",
            "text": "Monitoring and detecting hateful content online is of paramount importance to limit the spread of hate, misconception, and prejudice. Content on social media platforms poses several challenges, from fast-paced, large-scale generation requiring automatic solutions, to ever-changing information mediums, like internet memes.\nMisogynous memes are an unfortunately common phenomenon. Based on sexist preconceptions, these memes target and degrade women for humor. This intricate nature makes them hard to detect with classical computational models as hate is conveyed by associating known visual concepts with specific textual wording. In the Multimedia Automatic Misogyny Identification task (Fersini et al., 2022) novel systems are required to detect misogynous memes in English. The task is divided into two sub-tasks. Sub-task A requires solving the sole misogynous meme identification (i.e., a binary task). Sub-task B requires recognizing more specific categories, namely stereotype, shaming,\nobjectification, and violence. Figure 1 (top) shows an example from the dataset.\nWe propose a novel architecture where unimodal1 components extract salient information from the meme. We present all information to a late fusion layer that distills it into a latent representation. We use renowned unimodal encoders networks and Perceiver IO (Jaegle et al., 2022) as the late fusion layer. Notably, while jointly learning from all modalities, Perceiver IO easily extends to multi-task learning. To the best of our knowledge, this work is the first to use Perceiver IO combining text and image modalities. We hence effectively address, with the same architecture, both sub-tasks A and B.\n1We use unimodal whenever a single modality is involved, e.g., when dealing with Image content only. By extension, multimodal refers to a mixture of unimodals, e.g., Image and Text.\n654\nThe proposed system outperforms both unimodal and multimodal baselines. The results show that Perceiver IO is an effective and efficient method to jointly fuse input representations from different modalities in multi-task setups. However, we achieved sub-par performance against other competing solutions. We ranked 25th (13 F1 points worse than the best system) out of 69 competing teams on sub-task A and 15th (4 F1 points worse than the best system) out of 42 competing teams on sub-task B. Our system is not specialized in either of the sub-tasks and hence it under-performs against task-engineered solutions. We report a brief error analysis in Section 5.\nWe release the code to replicate our experiments at https://github.com/MilaNLProc/ milanlp-at-mami."
        },
        {
            "heading": "2 Background",
            "text": "In the last years, the task of hate speech detection has attracted considerable attention from the Natural Language Processing and Computer Vision communities. Among the research work in this area, only a limited number of approaches have focused on the problem of misogyny detection, which is a concrete problem in social media platforms. Nozza (2021) shows that hate speech detection models do not transfer across different hate speech targets, further demonstrating the need for ad-hoc misogyny detection approaches and datasets. Indeed, the corpora made available as part of shared tasks (Fersini et al., 2018, 2020b; Basile et al., 2019; Mulki and Ghanem, 2021) enabled a variety of NLP approaches to the problem of automatic misogyny detection on Twitter posts (Indurthi et al., 2019; Fersini et al., 2020a; Attanasio and Pastor, 2020; Lees et al., 2020, inter alia).\nThe Multimedia Automatic Misogyny Identification task focuses on the problem of misogyny detection with the new perspective of multimodality. The most similar research effort in the direction of hateful memes detection is the Hateful Memes Challenge (Kiela et al., 2020) and the MMHS150K corpus (Gomez et al., 2020).\nOn the other hand, multi-modal models that combine image and text are now becoming incredibly popular in Natural Language Processing (Cao et al., 2020; Lu et al., 2019; Tan and Bansal, 2019; Radford et al., 2021; Bianchi et al., 2021; Su et al., 2020, inter alia) due to their capabilities to solve\nzero-shot tasks.2\nIn this paper, we focus on the use of Perceiver IO (Jaegle et al., 2022) to combine the information coming from different sources such as the meme image, the text, and other features."
        },
        {
            "heading": "3 System overview",
            "text": "Following recent work addressing similar tasks (Pramanick et al., 2021; Zhu, 2020; Lee et al., 2021, inter-alia), we decompose the multimodal learning of hateful memes into two stages. First, we embed with unimodal encoders different input sources. Next, we adopt a multimodal late fusion to jointly learn from different modalities. With this setup, we tackle both sub-tasks A and B with no additional data other than the one provided for the task.\nWe build unimodal streams using pretrained, modality-specific encoder networks. Each encoder contributes an input representation to the subsequent fusion layer. We then use Perceiver IO (Jaegle et al., 2022) as a late fusion approach over the concatenation of modality-specific representations. Perceiver IO produces a structured, multidimensional output. We leverage this ability to jointly learn misogyny and other relevant aspects (e.g., aggressiveness, objectification, etc.) from the input. With that, we effectively solve both subtasks A and B of the challenge using a single model in a multi-task learning setting.\nThe system architecture is shown in Figure 2. To the best of our knowledge, this is the first attempt to use Perceiver IO as a multimodal late fusion layer for multi-task learning.\nIn the following sections, we further describe what type of unimodal source we considered (Section 3.1) and how we adapted Perceiver IO to multimodal, multi-task learning (Section 3.2)."
        },
        {
            "heading": "3.1 Unimodal streams",
            "text": "The provided memes are characterized by two features: the meme image and the transcription of the over-imposed text. Building on ideas from recent work (Blaier et al., 2021; Pramanick et al., 2021), we enrich the meme with semantic information including image caption, face and demographics, detection of adult content, and web entities. We report a sample in Figure 1.\n2See also Frank et al. (2021) for a detailed study and ablation analysis on the capabilities of these models.\nWe derive a different input stream from each of the features of the semantically-augmented meme (Figure 2, bottom).\nImage We encode raw images using a pretrained Vision Transformer (Dosovitskiy et al., 2021) (ViT). In this stream, the input image is divided into patches of 16x16 pixels and fed through a stacked transformer architecture. We use the last hidden token embeddings as the output of the stream.\nText Transcript We encode the text transcript using a pretrained RoBERTa (Liu et al., 2019) and use the last hidden token embeddings as the output of the stream. We choose RoBERTa based on its performance and its hurtful sentence completion (HONEST) score (Nozza et al., 2021, 2022b).\nFace and Demographics Some images contain one or more faces. We use a pretrained FairFace (Karkkainen and Joo, 2021) model to detect faces and demographics. For each face found, we extract three categorical attributes, namely Age3, Gender, and Ethnicity. Figure 1 (bottom, F) reports an example of face and demographics extracted with FairFace from a training sample. We encode face demographics with a simple embedding layer.\n3FairFace produces age ranges, e.g., 60-75, 75+.\nAdult Content We use NudeNet4, a pretrained classification and detection model for nudity detection and censoring, to detect if the image contains adult content. We encode this information with additional embeddings.\nImage caption We include an automatically generated image caption to have a textual description of the meme content. We use a pretrained Show, Attend and Tell model (Xu et al., 2015) to generate the caption for both training and test memes. Figure 1 (bottom, C) reports an example of an automatically generated caption. We encode the caption using a pretrained DistilBERT (Sanh et al., 2019).\nWeb Entities We use Google Cloud Vision API to detect web entities starting from the meme image.5 As a summary of the extracted entities, we use the textual field best guess labels provided by the API. We encode this text using a pretrained DistilBERT. Note that this is a different model than the one used for captions.\n4https://github.com/notAI-tech/NudeNet 5https://cloud.google.com/vision/docs/\ndetecting-web"
        },
        {
            "heading": "3.2 Late fusion with Perceiver IO",
            "text": "We concatenate all the information extracted by unimodal streams into a single input array (Figure 2, top). Ideally, this array contains all the raw unrouted information necessary for the task. We use a Perceiver IO-based late fusion layer for information distillation and multi-task learning.\nPerceiver IO builds on Perceiver (Jaegle et al., 2021) a modality-independent neural architecture with two crucial advantages over unimodal models. First, it is designed not to leverage inductive biases as in modality-specific architectures. Because of that, it effectively learns from the input of any shape and nature. Second, Perceiver distills inputs in a much smaller latent representation for memory efficiency. On top of that, Perceiver IO (Jaegle et al., 2022) adds a decoding step to produce a structured output of arbitrary size and semantics. The output is generated using decoder queries cross-attending the latent representation. The number of queries and their dimension defines the output shape.\nWe use this feature of Perceiver IO to address both sub-tasks A and B at once. Specifically, we define five different task queries, one per characteristic of the misogynous meme identification problem, i.e., misogyny, shaming, aggressiveness, objectification, and violence. In this multi-task setup, we generate logits and extract probability distributions for each of the five aspects."
        },
        {
            "heading": "4 Experimental setup",
            "text": "The provided training set counts 10,000 samples. Class labels are balanced on misogyny (p1 = 0.5) but unbalanced on shaming (p1 = 0.18), stereotype (p1 = 0.28), objectification (p1 = 0.22), and violence (p1 = 0.095). We validated our models and baselines using three-fold cross-validation over the training set. We measure performance with F1 Macro on the binary misogyny detection task.\nFor ViT, RoBERTa, and DistilBERT, we use implementations and checkpoints from the transformers library (Wolf et al., 2020) and HuggingFace Hub. We use monolingual English checkpoints for text models. For Perceiver IO, we use the lucidrains\u2019s PyTorch implementation.6\nUnimodal encoders For ViT, we used the google/vit-base-patch16-224-in21k\n6https://github.com/lucidrains/ perceiver-pytorch\ncheckpoint. We used the standard feature processor which entails 1) resizing to a maximum shape of 224x224 and channel normalization. We also augmented the image using color jitter (hue = 0.1), random horizontal flip (p = 0.5), affine transformations,7 contrast (p = 0.3) and equalization (p = 0.3) variations. We discard the CLS last token embedding and use the sequence of the remaining 196 tokens as the image representation.\nFor RoBERTa, we used the roberta-base checkpoint and its standard tokenizer padding and truncating up to a maximum of 32 tokens. We performed text augmentation via token removal (p = 0.15).\nFor DistilBERT, we used the distilbert-base-uncased checkpoint and its standard tokenizer padding and truncating up to a maximum of 32 tokens. Note that this configuration is duplicated for both the text transcript and web entity streams.\nPerceiver IO We did not use a Perceiver IO pretrained checkpoint. We manually fine-tuned the number of latent variables in {64, 128, 256, 512, 1024}, latent dimension in {128, 256, 512, 1024}, and number of selfattention layers in {6, 12}, and settled on the configuration [265, 512, 6]. Self-attention layers are applied sequentially and do not share weights. We use 5 decoder queries to produce a structured output of shape (5, 2). We project the output using a final linear layer and consider the result as the tasks logits. We also tried to use a different linear projection layer per task but with no measurable improvement in performance.\nTraining setup We trained the entire system endto-end, i.e., we jointly optimized all unimodal encoders and Perceiver IO. Following Bianchi et al. (2021), we tried to freeze the encoders for an arbitrary number of steps and then unfreeze them, with no significant improvement.\nWe manually tuned the learning rate in the range [10\u22125, 10\u22126]. We then used 10\u22125 with linear decay and 10% of total steps as warmup steps. We set weight decay to 10\u22122. We trained the system for four epochs using Focal Loss (Lin et al., 2020) to account for class imbalance. We set alpha to 0.25 and gamma to 2.\n7For the full set of affine transformations please refer to our repository."
        },
        {
            "heading": "5 Results",
            "text": "The provided test set counts 1,000 samples. Target labels are balanced in terms of misogyny but imbalanced for the rest of the categories. Unbalancing is slightly more marked than the training set. We report the prior frequency of the positive class as p1 in Table 3.\nIn the following, we compare the performance of the proposed system which encodes detected faces (F), web entities (W), the image caption (C), and adult content detection (A). We refer to the system as Perceiver IO (FCWA). It achieves an overall F1 (macro) score of 69.9% in sub-task A and an F1 (weighted) score of 69.3% in sub-task B. We rank 31th (13 F1 points worse than the best system) on sub-task A and 18th (4 F1 points worse than the best system) on sub-task B. The system outperforms several baselines provided by the task organizers. On sub-task A, we outperform 1) sentence embeddings from a pretrained Universal Sentence Embedding model, 2) an image classifier fine-tuned from a VGG model, and 3) a classifier based on the concatenation of the first two representations plus a single layer neural network. On sub-task B, we outperform 1) a multi-label model based on the concatenation of deep image and text embeddings and\n2) a hierarchical multi-label model based on text representations. Results are reported in Table 2."
        },
        {
            "heading": "5.1 Quantitative analysis",
            "text": "In the proposed dataset, misogyny characteristics (e.g., shaming or objectification) apply only to misogynous content. Hence, we consider performance on sub-task A (binary misogyny detection) as a proxy for the overall quality of the model configuration. We report performance on our crossvalidation over the training set in Table 1.\nWe compared our system with internal unimodal baselines. For the textual modality, we tested a Bagof-Word (BoW) representation8 extracted from the HurtLex lexicon (Bassignana et al., 2018) fed to a Logistic classifier and RoBERTa. For the visual modality, we tested Vision Transformer. Our system outperforms by a large margin these unimodal baselines.\nFurther, we validated the intuition of semantically enriched memes with input ablation. Results are reported in Table 1. Specifically, we removed all streams but the encoders of the raw image and the transcript (Perceiver IO). Cross-validation results show that our enriched input (Perceiver IO (FWCA)) improves classification performance."
        },
        {
            "heading": "5.2 Error analysis",
            "text": "In the post-evaluation phase of the task, we studied the labels predicted by our system on the 1,000 test memes. Results are reported in Table 3 separately by category.\nThe system effectively learned all categories (F1 is always greater than 65%) but with differences. The misogynous identification task has a 70% F1\n8We use a binary presence matrix, i.e., the rows are the transcript of the meme, the columns each of the terms of the lexicon, and the cell is 1 if the transcript contains the term at least once or 0 otherwise.\nscore composed of a promising 75% in precision and 71% recall. While performance between stereotype and objectification are close, the system underperformed in the shaming category. We think this behavior is due to the broad kind of both visual and textual content that can convey shameful messages and is hence more difficult to learn. Finally, the model performed best in violence, where it is probably simpler to identify visual clues that let intend a violent message.\nWe also manually inspected the errors of our model. We conducted the analysis separately by false positives (Figure 3) and false negatives (Figure 4). In the following, we speculate on the possible causes of these errors.\nWeak Adult Content detection We noticed several wrong annotations extracted by NudeNet in both false positives and false negatives (e.g., all memes in Figure 3 are labeled as NSFW). We believe this might have introduced noise in our training that further propagated in classifying test memes.\nBias towards composite memes Several memes have a composite nature. They contrast some behavior or reaction of two groups (e.g., boys and\ngirls) using a predefined structure. A typical example is achieved by organizing one group on top of another (Figure 3b and 3c).\nWe noticed several composite memes among false positives. We argue this kind of meme has a strong association bias with the positive class (misogynous = 1). Indeed, we believe that, in absence of relevant information, the system leverages the structure of the memes and wrongly produces a positive prediction.\nHard stereotypes Several memes contain nonhateful wording and image content. However, they convey misogynous messages because the combination of image and text leverages a well-known stereotype about women. We argue that the correct classification of these memes must involve either a solution explicitly modeling the stereotype or sufficient training data to become aware of it. We call \u201chard stereotypes\u201d those memes whose stereotypical message is not backed by sufficient training data. We noticed several hard stereotypes in our misclassified memes. Figure 4 shows four examples of those.\nGender Bias We noticed several memes misclassified as false negatives depicting only a man in the\nscene. We believe the system might have learned a spurious bias associating the presence of men in the image with the negative class (misogynous = 0)."
        },
        {
            "heading": "5.3 Further considerations",
            "text": "Quality of generated information In our experiments, automatically generated image captions often describe coherently the content of the image, although we do not expect them to generalize well to complex and diverse concepts.\nInstead, FairFace extracts almost always precise face counts and age, ethnicity, and gender for each face even in crowded images (there are cases of 14 people in a single image). Web entities are often significant but provide coarse-grained information (e.g., \"internet cat meme\").\nUnconditioned prediction During the postevaluation phase, we identified a potential weakness in the proposed architecture.\nDecoding queries in Perceiver IO are independent by design. This behavior enhances the model\u2019s generalization capabilities as it needs to learn internal representations useful for all outputs. However, it also prevents any conditioning between them. In our task, the misogynous aspect influences the remaining ones in the sense that only misogynous memes are characterized by one or more categories for sub-task B. We are not explicitly modeling this condition and hence probably hindering the performance."
        },
        {
            "heading": "6 Conclusion",
            "text": "We addressed both sub-tasks A and B of the Multimedia Automatic Misogyny Identification shared task with a novel Perceiver IO-based system. We take advantage of pretrained encoders and external services to extract and enrich with salient information the input meme. Then, we use Perceiver IO as a multimodal, multi-task late fusion layer of several unimodal streams. To our knowledge, this is the first time Perceiver IO has been used to combine text and image modalities.\nThe proposed system outperforms unimodal and multimodal baselines but underperforms against more specialized, task-specific competitor systems. We ranked 25th out of 69 competing teams on subtask A and 15th out of 42 competing teams on subtask B. In future work, we will explore improved input preprocessing (e.g., for the OCR-based text provided), and model ensembling. Additional effort should be put into identifying and mitigating\nunintended bias that may be present in our multimodal misogyny detection model following approaches proposed for text modality (Nozza et al., 2019; Attanasio et al., 2022a,b). The development of these multi-modal hate speech classifiers can be useful for the automatic evaluation of large pretrained models (Nozza et al., 2022a)."
        },
        {
            "heading": "Acknowledgements",
            "text": "This project has partially received funding from the European Research Council (ERC) under the European Union\u2019s Horizon 2020 research and innovation program (grant agreement No. 949944, INTEGRATOR), and by Fondazione Cariplo (grant No. 2020-4288, MONICA). The authors are members of the MilaNLP group and the Data and Marketing Insights Unit of the Bocconi Institute for Data Science and Analysis. Giuseppe Attanasio did part of the work at the DataBase And Data Mining Group at the Polytechnic University of Turin. Computing resources were provided by the SmartData@PoliTO center on Big Data and Data Science."
        }
    ],
    "title": "MilaNLP at SemEval-2022 Task 5: Using Perceiver IO for Detecting Misogynous Memes with Text and Image Modalities",
    "year": 2022
}