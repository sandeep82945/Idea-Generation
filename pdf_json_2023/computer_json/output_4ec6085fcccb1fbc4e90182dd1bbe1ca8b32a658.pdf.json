{
    "abstractText": "Lyric translation plays a pivotal role in amplifying the global resonance of music, bridging cultural divides, and fostering universal connections. Translating lyrics, unlike conventional translation tasks, requires a delicate balance between singability and semantics. In this paper, we present a computational framework for the quantitative evaluation of singable lyric translation, which seamlessly integrates musical, linguistic, and cultural dimensions of lyrics. Our comprehensive framework consists of four metrics that measure syllable count distance, phoneme repetition similarity, musical structure distance, and semantic similarity. To substantiate the efficacy of our framework, we collected a singable lyrics dataset, which precisely aligns English, Japanese, and Korean lyrics on a line-by-line and sectionby-section basis, and conducted a comparative analysis between singable and non-singable lyrics. Our multidisciplinary approach provides insights into the key components that underlie the art of lyric translation and establishes a solid groundwork for the future of computational lyric translation assessment.",
    "authors": [
        {
            "affiliations": [],
            "name": "Haven Kim"
        },
        {
            "affiliations": [],
            "name": "Kento Watanabe"
        },
        {
            "affiliations": [],
            "name": "Masataka Goto"
        },
        {
            "affiliations": [],
            "name": "Juhan Nam"
        }
    ],
    "id": "SP:742dc28c325ee2c2f2a1c1b4df45750912638b3f",
    "references": [
        {
            "authors": [
                "M. Mateo"
            ],
            "title": "Music and translation",
            "venue": "Handbook of translation studies, vol. 3, pp. 115\u2013121, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "\u015e. Susam-Sarajeva"
            ],
            "title": "Translation and music: Changing perspectives, frameworks and significance",
            "venue": "The Translator, vol. 14, no. 2, pp. 187\u2013200, 2008.",
            "year": 2008
        },
        {
            "authors": [
                "S. Spaeth"
            ],
            "title": "Translating to music",
            "venue": "The Musical Quarterly, vol. 1, no. 2, pp. 291\u2013298, 1915.",
            "year": 1915
        },
        {
            "authors": [
                "P. Low"
            ],
            "title": "Translating songs that rhyme",
            "venue": "Perspectives: Studies in translatology, vol. 16, no. 1-2, pp. 1\u201320, 2008.",
            "year": 2008
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "The pentathlon approach to translating songs",
            "venue": "Song and significance. Brill, 2005, pp. 185\u2013212.",
            "year": 2005
        },
        {
            "authors": [
                "F. Guo",
                "C. Zhang",
                "Z. Zhang",
                "Q. He",
                "K. Zhang",
                "J. Xie",
                "J. Boyd-Graber"
            ],
            "title": "Automatic song translation for tonal languages",
            "venue": "Findings of the Association for Computational Linguistics (ACL). Dublin, Ireland: Association for Computational Linguistics, May 2022, pp. 729\u2013743. [Online]. Available: https: //aclanthology.org/2022.findings-acl.60",
            "year": 2022
        },
        {
            "authors": [
                "L. Ou",
                "X. Ma",
                "M.-Y. Kan",
                "Y. Wang"
            ],
            "title": "Songs across borders: Singable and controllable neural lyric translation",
            "venue": "arXiv preprint arXiv:2305.16816, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "C. Li",
                "K. Fan",
                "J. Bu",
                "B. Chen",
                "Z. Huang",
                "Z. Yu"
            ],
            "title": "Translate the beauty in songs: Jointly learning to align melody and translate lyrics",
            "venue": "arXiv preprint arXiv:2303.15705, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "K. Watanabe",
                "M. Goto"
            ],
            "title": "Lyrics information processing: Analysis, generation, and applications",
            "venue": "Proceedings of the 1st Workshop on NLP for Music and Audio (NLP4MusA), 2020, pp. 6\u201312.",
            "year": 2020
        },
        {
            "authors": [
                "K. Papineni",
                "S. Roukos",
                "T. Ward",
                "W.-J. Zhu"
            ],
            "title": "BLEU: A method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th annual meeting of the Association for Computational Linguistics (ACL), 2002, pp. 311\u2013318.",
            "year": 2002
        },
        {
            "authors": [
                "C.-Y. Lin"
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "Text summarization branches out, 2004, pp. 74\u201381.",
            "year": 2004
        },
        {
            "authors": [
                "S. Banerjee",
                "A. Lavie"
            ],
            "title": "METEOR: An automatic metric for MT evaluation with improved correlation with human judgments",
            "venue": "Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "T. Zhang",
                "V. Kishore",
                "F. Wu",
                "K.Q. Weinberger",
                "Y. Artzi"
            ],
            "title": "BERTScore: Evaluating text generation with bert",
            "venue": "International Conference on Learning Representations (ICLR), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "I. Marc"
            ],
            "title": "Travelling songs: On popular music transfer and translation",
            "venue": "IASPM Journal, vol. 5, no. 2, pp. 3\u201321, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "E.C. Hui-tung"
            ],
            "title": "Translation of songs",
            "venue": "An Encyclopedia of Practical Translation and Interpreting, p. 351, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Yang",
                "Y. Zhang",
                "C. Tar",
                "J. Baldridge"
            ],
            "title": "PAWS- X: A cross-lingual adversarial dataset for paraphrase identification",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019, pp. 3687\u20133692.",
            "year": 2019
        },
        {
            "authors": [
                "H.S. Drinker"
            ],
            "title": "On translating vocal texts",
            "venue": "The Musical Quarterly, vol. 36, no. 2, pp. 225\u2013240, 1950.",
            "year": 1950
        },
        {
            "authors": [
                "J. Franzon"
            ],
            "title": "Three dimensions of singability. An approach to subtitled and sung translations",
            "venue": "Text and Tune. On the Association of Music and Lyrics in Sung Verse. Bern: Peter Lang, pp. 333\u2013346, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J.P.G. Mahedero",
                "A. Mart\u00cdnez",
                "P. Cano",
                "M. Koppenberger",
                "F. Gouyon"
            ],
            "title": "Natural language processing of lyrics",
            "venue": "Proceedings of the 13th Annual ACM International Conference on Multimedia, ser. MULTIMEDIA \u201905. Association for Computing Machinery, 2005, pp. 475\u2013478.",
            "year": 2005
        },
        {
            "authors": [
                "K. Watanabe",
                "M. Goto"
            ],
            "title": "A chorus-section detection method for lyrics text.",
            "venue": "Proceedings of the 21th International Conference on Music Information Retrieval (ISMIR),",
            "year": 2020
        },
        {
            "authors": [
                "R. Apter",
                "M. Herman"
            ],
            "title": "Translating art songs for performance: Rachmaninoff\u2019s six choral songs",
            "venue": "Translation Review, vol. 84, no. 1, pp. 27\u201342, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "A. Bain"
            ],
            "title": "English composition and rhetoric,(2nd american ed.)",
            "venue": "New York: D. Appleton and Company, 1867.",
            "year": 1867
        },
        {
            "authors": [
                "N. Manabe"
            ],
            "title": "Globalization and Japanese creativity: Adaptations of Japanese language to rap",
            "venue": "Ethnomusicology, vol. 50, no. 1, pp. 1\u201336, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "Y.B. Yoon",
                "B.L. Derwing"
            ],
            "title": "A language without a rhyme: Syllable structure experiments in Korean",
            "venue": "Canadian Journal of Linguistics/Revue canadienne de linguistique, vol. 46, no. 3-4, pp. 187\u2013237, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "A.K. Syrdal",
                "H.S. Gopal"
            ],
            "title": "A perceptual model of vowel recognition based on the auditory representation of American English vowels",
            "venue": "The Journal of the Acoustical Society of America, vol. 79, no. 4, pp. 1086\u20131100, 1986.",
            "year": 1986
        },
        {
            "authors": [
                "K. Hanson"
            ],
            "title": "Formal variation in the rhymes of Robert Pinsky\u2019s the inferno of dante",
            "venue": "Language and Literature, vol. 12, no. 4, pp. 309\u2013337, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "C. Ito",
                "Y. Kang",
                "M. Kenstowicz"
            ],
            "title": "The adaptation of Japanese loanwords into Korean",
            "venue": "MIT Working Papers in Linguistics, vol. 52, no. 2006, pp. 65\u2013104, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "S.-E. Chang"
            ],
            "title": "Enhancement effects of clear speech and word-initial position in Korean glides.",
            "venue": "The Journal of the Acoustical Society of America,",
            "year": 2017
        },
        {
            "authors": [
                "J. Li",
                "M. Galley",
                "C. Brockett",
                "J. Gao",
                "W.B. Dolan"
            ],
            "title": "A diversity-promoting objective function for neural conversation models",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics (NACCL) : Human Language Technologies, 2016, pp. 110\u2013119.",
            "year": 2016
        },
        {
            "authors": [
                "W. Wang",
                "F. Wei",
                "L. Dong",
                "H. Bao",
                "N. Yang",
                "M. Zhou"
            ],
            "title": "MiniLM: Deep self-attention distillation for task-agnostic compression of pre-trained transformers",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), vol. 33, pp. 5776\u20135788, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "N. Reimers",
                "I. Gurevych"
            ],
            "title": "Sentence-BERT: Sentence embeddings using Siamese BERT-networks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019, pp. 3982\u20133992.",
            "year": 2019
        },
        {
            "authors": [
                "S. Park",
                "T. Kwon",
                "J. Lee",
                "J. Kim",
                "J. Nam"
            ],
            "title": "A cross-scape plot representation for visualizing symbolic melodic similarity",
            "venue": "Proceedings of the 20th International Conference on Music Information Retrieval (ISMIR), 2019, pp. 423\u2013430.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "1. INTRODUCTION\nTranslating lyrics is a prevailing method of enhancing the global appeal and allure of music across a multitude of genres, such as theatre music, animation music, pop music, etc [1]. Furthermore, recent advancements in media technology have facilitated the exchange of intercultural products and globalized fandom culture, resulting in an increase in the popularity of user-translated lyrics across diverse social media platforms [2].\nDespite its popularity, lyric translation is acknowledged as a challenging field, requiring an interdisciplinary approach [2]. As early as 1915, it was suggested that an ideal lyric translator should possess expertise in both linguistics and music, highlighting the need for a comprehensive understanding of the principles and techniques used in translation studies, coupled with a background in musicology [3].\n\u00a9 H. Kim, K. Watanabe, M. Goto, and J. Nam. Licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0). Attribution: H. Kim, K. Watanabe, M. Goto, and J. Nam, \u201cA Computational Evaluation Framework for Singable Lyric Translation\u201d, in Proc. of the 24th Int. Society for Music Information Retrieval Conf., Milan, Italy, 2023.\nMoreover, it is crucial to understand the cultural context of each language, such as different strategies employed for forming rhymes [4]. Because of these challenges, the systematic analysis and evaluation of lyric translation remain an under-researched topic of study. Thus far, only a few have proposed guidelines for scoring the quality of translated lyrics [4, 5]. While these principled approaches have proven successful, they lack automation. Consequently, despite the growing interest in the development of neural lyric translation, its evaluation has predominantly relied on human evaluation, making the evaluation process timeconsuming, unreliable, and subjective [6\u20138].\nOur study aims to computationally analyze and evaluate lyric translation based on a comprehensive understanding of lyrics that accounts for their musical, linguistic, and cultural elements. Unlike prior research that only proposed rhymescoring guidelines applicable to English [4], our framework is extendable to Japanese and Korean. Though our framework may be limited in its application to specific languages, we strive to provide valuable insights into establishing distinct evaluation rules for phoneme repetition in diverse languages. Our comprehensive framework employs a multifaceted evaluation approach that examines lyric translation from four distinct perspectives: syllable counts, phoneme repetition, musical structure, and semantics. In the remainder of this paper, we explicate the rationale behind our selection of these perspectives by delving into the unique characteristics of lyric translation that differentiate it from general language translation tasks. In addition, we introduce the singable lyrics dataset we collected, which features line-by-line and section-by-section alignment of English, Japanese, and Korean lyrics. Moving forward, we propose robust evaluation metrics for lyric translation and analyze the results of our experiments based on the perspectives mentioned above. Finally, we conclude our paper by reflecting on the profound insights gleaned from our experiment and highlighting possible directions for future research."
        },
        {
            "heading": "2. BACKGROUND",
            "text": "Previous research indicates that linguistic analysis methods designed for standard text may not achieve desired outcomes when used to examine lyrics [9]. Although automated evaluation metrics, such as n-gram-based [10\u201312] or neural approaches [13], have proven valuable and effective in assessing conventional machine translation tasks, they\nar X\niv :2\n30 8.\n13 71\n5v 1\n[ cs\n.C L\n] 2\n6 A\nug 2\n02 3\nfall short in evaluating lyric translation. This is due to the unique characteristics of lyrics that render the translation process subject to many constraints and less direct [14].\nOne of the most significant constraints is the syllable count. This is because the original and translated lyrics must match the same melody lines, while it is a common practice to tweak the melody to accommodate minor changes in syllable count [4, 15]. In fact, conveying the same message in different languages requires vastly different syllable counts. For example, \u201cHappy New Year\u201d in English consists of 4 syllables, whereas 15 and 9 are required for Japanese (\u3042\u3051\u307e\u3057\u3066\u304a\u3081\u3067\u3068\u3046\u3054\u3056\u3044\u307e\u3059) and Korean (\u1109\u1162 \u1112\u1162 \u1107\u1169\u11a8 \u1106\u1161\u11ad\u110b\u1175 \u1107\u1161\u11ae\u110b\u1173\u1109\u1166\u110b\u116d), respectively. For the numerical comparison, we examined PAWS-X, a dataset that contains 23,659 English sentences paired with human-translated sentences in various languages [16]. The average number of syllables per sentence in the dataset is 50.89 for Japanese, whereas 36.18 per English and 40.40 per Korean. With these statistics, it can be deduced that Japanese necessitates approximately 41% more syllables than English and 26% more syllables than Korean to express an equivalent message. This limitation forces translators to often modify the meaning of original lyrics by adding, omitting, or even tweaking the message. However, translated lyrics still aim to capture the theme, mood, and spirit of the original lyrics [17]. Therefore, while original and translated lyrics need not be semantically identical, they still need to be semantically relevant [4, 18].\nIt is also crucial to preserve the frequency of phoneme repetition (e.g., rhyme) in translated lyrics, particularly when the music demands it [17]. For instance, some sections, such as choruses, require a substantial degree of phoneme repetition, while others do not. Moreover, due to the inherent connection between lyrics and music, lyrics must be arranged in a way that complements the music [19]. As a result, musically similar sections should maintain resembling linguistic features, including the choice of phonemes and the frequency of phoneme repetition [20]."
        },
        {
            "heading": "3. DATASET",
            "text": "Although some websites provide user-translated multilingual lyrics, we found that most of them lack singability, as these translations were focused on delivering the meaning of the original lyrics rather than making them performable. While there are a few singable translations available, they are often not aligned on a line-by-line nor section-by-section basis due to the subjective nature of the lyric structure that there is no universal agreement on what to call a line and what to call a section. The absence of alignment makes it difficult to compare the original lyrics with their translated versions. To address this issue, we collected a set of singable lyrics, sourced from either official lyrics of commercial songs or user-translated ones found on YouTube, meticulously aligned on a line-by-line basis in English, Japanese, and Korean. This approach ensures that lyrics on the same line share the same melodies. Moreover, the dataset divides the lyrics into sections, allowing for section-by-section analysis. Alongside the lyrics, it\nprovides essential metadata such as genre, artist, original language, and the official status of lyrics. The dataset consists of 162 songs, each having lyrics in the three languages. It covers a diverse range of genres, including 109 K-pop, 23 animation music (e.g., Disney), 13 J-pop, 10 theatre music, and more. Table 1 shows sample data."
        },
        {
            "heading": "4. EVALUATING SINGABILITY",
            "text": "Our primary goal is to develop an evaluation framework that automatically assesses the quality of translated lyrics. One of the most important factors determining the quality is singability, defined as not only the ability of being sung, but also the suitability (easiness) of being sung [18]. To ensure such singability, we aim to provide metrics from three distinct perspectives by making sure that they i) maintain the song\u2019s melodic integrity, ii) preserve the degree of phoneme repetition, and iii) consider the underlying musical structure.\nTo substantiate the reliability of our evaluation metrics, we conducted a comparative analysis of singable lyrics versus non-singable lyrics based on each proposed evaluation metric. In all our comparative analyses, we utilized our dataset for singable lyrics, where official lyrics served as both source and target lyrics, and unofficial functioned as only target lyrics. For non-singable lyrics, we obtained pairs of original singable (source) and human-translated non-singable (target) lyrics, aligned line-wise and sectionwise, for 3,642 songs from https://lyricstranslate.com/.\nSection English Japanese (English translation) Korean (English translation) pho\nE(A1), J(A1), K(A1) Do you wanna build a snowman? Come on, let\u2019s go and play! I never see you anymore Come out the door It\u2019s like you\u2019ve gone away\n\u96ea\u3060\u308b\u307e\u4f5c\u308d\u3046 (Let\u2019s build a snowman) \u30c9\u30a2\u3092\u958b\u3051\u3066 (Please open the door) \u4e00\u7dd2\u306b\u904a\u307c\u3046 (Let\u2019s play together) \u3069\u3046\u3057\u3066 (Why) \u51fa\u3066\u3053\u306a\u3044\u306e? (don\u2019t you come out?)\n\u1100\u1161\u11c0\u110b\u1175\u1102\u116e\u11ab\u1109\u1161\u1105\u1161\u11b7\u1106\u1161\u11ab\u1103\u1173\u11af\u1105\u1162? (Do you wanna build a snowman?) \u110c\u1166\u1107\u1161\u11af\u110c\u1169\u11b7\u1102\u1161\u110b\u116a\u1107\u116a (Please come out) \u110b\u1165\u11ab\u1102\u1175\u1105\u1173\u11af\u1106\u1161\u11ab\u1102\u1161\u11af\u1109\u116e\u110b\u1165\u11b9\u110b\u1165 (I can\u2019t meet you) \u1100\u1161\u11c0\u110b\u1175\u1102\u1169\u11af\u110c\u1161 (Let\u2019s play together) \u1102\u1161\u1112\u1169\u11ab\u110c\u1161\u1109\u1175\u11b7\u1109\u1175\u11b7\u1112\u1162 (I\u2019m lonely alone) 0.85, 0.73, 0.77\nE(B1), J(B1), K(B1) We used to be best buddies And now we\u2019re not I wish you would tell me why!\n\u524d\u306f\u4ef2\u826f\u304f(We were close before) \u3057\u3066\u305f\u306e\u306b (We used to be) \u306a\u305c\u4f1a\u3048\u306a\u3044\u306e (Why can\u2019t we meet each other?) \u1100\u1173\u1105\u1165\u11c2\u1100\u1166\u110e\u1175\u11ab\u1112\u1162\u11bb\u1102\u1173\u11ab\u1103\u1166 (We were close before) \u110b\u1175\u110c\u1166\u11ab\u110b\u1161\u1102\u1163 (and we\u2019re not) \u1100\u1173\u110b\u1175\u110b\u1172\u1105\u1173\u11af\u110b\u1161\u11af\u1100\u1169\u1111\u1161 (I want to know the reason why)\n0.92, 0.80, 0.91\nE(A2), J(A2), K(A2) Do you wanna build a snowman? Or ride our bike around the halls? I think some company is overdue I\u2019ve started talking to the pictures on the walls! \u96ea\u3060\u308b\u307e\u4f5c\u308d\u3046 (Let\u2019s build a snowman) \u81ea\u8ee2\u8eca\u306b\u4e57\u308d\u3046(Let\u2019s ride a bike) \u305a\u3063\u3068\u4e00\u4eba\u3067\u3044\u308b\u3068 (When I\u2019m alone all the time) \u58c1\u306e\u7d75\u3068\u304a\u3057\u3083\u3079\u308a\u3057\u3061\u3083\u3046 (I\u2019m almost talking to the pictures on the walls) \u1100\u1161\u11c0\u110b\u1175\u1102\u116e\u11ab\u1109\u1161\u1105\u1161\u11b7\u1106\u1161\u11ab\u1103\u1173\u11af\u1105\u1162? (Do you wanna build a snowman?) \u110b\u1161\u1102\u1175\u1106\u1167\u11ab\u110c\u1161\u110c\u1165\u11ab\u1100\u1165\u1110\u1161\u11af\u1105\u1162? (or do you wanna ride a bike?) \u110b\u1175\u110c\u1166\u1102\u1173\u11ab\u1102\u1161\u1103\u1169\u110c\u1175\u110e\u1167\u1100\u1161\u1102\u1161\u1107\u116a (Seems I\u2019m getting tired) \u1107\u1167\u11a8\u110b\u1166\u1103\u1161\u1106\u1161\u11af\u110b\u1173\u11af\u1112\u1161\u1106\u1167\u1102\u1169\u11af\u1100\u1169\u110b\u1175\u11bb\u110c\u1161\u11ad\u110b\u1161 (because I\u2019ve started talking to the walls) 0.79, 0.73, 0.82\nE(B2), J(B2), K(B2) It gets a little lonely All these empty rooms Just watching the hours tick by\n\u3055\u3073\u3057\u3044\u90e8\u5c4b\u3067 (In a lonely room) \u67f1\u6642\u8a08 (the wall clock) \u898b\u3066\u305f\u308a\u3059\u308b\u306e (I look at or something)\n\u1109\u1161\u1109\u1175\u11af\u110b\u1173\u11ab\u110c\u1169\u1100\u1173\u11b7\u110b\u116c\u1105\u1169\u110b\u116f (In fact, I\u2019m a little lonely) \u1110\u1165\u11bc\u1107\u1175\u11ab\u1107\u1161\u11bc\u110b\u1166\u1109\u1165\u11ab (In empty rooms) \u1109\u1175\u1100\u1168\u1109\u1169\u1105\u1175\u1106\u1161\u11ab\u1103\u1173\u11af\u1105\u1167 (All I can hear is the clock\u2019s ticking) 0.90, 0.88, 0.96\nTable 3. Lyric excerpt from \u201cDo You Want to Build a Snowman\u201d from the animation \u201cFrozen,\u201d singable in all languages. Sections A1 and A2 form a musically similar pair, while B1 and B2 are also musically similar to each other. Each section is denoted as E(A1), . . . , E(B2) in English, J(A1), . . . , J(B2) in Japanese, and K(A1), . . . ,K(B2) in Korean."
        },
        {
            "heading": "4.1 Line Syllable Count Distance",
            "text": "It is crucial to preserve the syllable counts between the original and translated lyrics for each line as similar as possible in order to maintain the integrity of a song\u2019s melody [21]. Therefore, it is unsurprising that our evaluation framework incorporates a metric to assess the differences in syllable counts. Let the line syllable counts for a pair of lyrics that consist of n lines, X = {x1, ..., xn} and X\u0303 = {x\u03031, ..., x\u0303n} be denoted as {syl(x1), ..., syl(xn)} and {syl(x\u03031), ..., syl(x\u0303n)} where each element refers to the syllable count of each line. For instance, if the first line of the English lyrics X is \u201cSilent night holy night\u201d and the corresponding line in the Korean lyrics X\u0303 is \u201cGoyohanbam-georukhanbam (\u1100\u1169\u110b\u116d\u1112\u1161\u11ab\u1107\u1161\u11b7\u1100\u1165\u1105\u116e\u11a8\u1112\u1161\u11ab\u1107\u1161\u11b7)\u201d, the value of syl(x1) is 6 and syl(x\u03031) is 8. We define the line syllable count distance between a pair of lyrics X and X\u0303 (Dissyl(X, X\u0303)) in order to evaluate the disparities in syllable counts, as follows. Dissyl(X, X\u0303) = 1 2n \u2211n i=1( |syl(xi)\u2212syl(x\u0303i)| syl(xi) + |syl(xi)\u2212syl(x\u0303i)|syl(x\u0303i) ) (1) We compare the line syllable count distance of singable and non-singable lyrics. As shown in Table 2, non-singable lyrics display a considerably greater Dissyl(X, X\u0303) compared to singable lyrics due to the varying syllable count requirements across languages."
        },
        {
            "heading": "4.2 Phoneme Repetition Similarity",
            "text": "Rhyme, defined as the repetition of a vowel sound and any subsequent sounds [22], has historically been a fundamental element in the realm of poetry, including in Western languages like English. However, the concept of rhyme has not been as prevalent in Japanese or Korean poetry [23]. In fact, traditional Korean poetry did not incorporate this concept [24]. Despite the increasing tendency to adopt the concept of rhyme in Japanese and Korean lyrics due to intercultural exchanges, we observed that lyrics in these languages often rely more on repeating grammatical elements. For example, in section A1 of Table 3, the Japanese pair \u201ctsukurou (\u4f5c\u308d\u3046, Let\u2019s build)\u201d and \u201casobou (\u904a\u307c\u3046, Let\u2019s play)\u201d generates a sense of rhyme because both end\nwith the same conjugation \u201cou\u201d meaning \u201clet\u2019s\u201d. Similarly, in Section A2, the Korean pair \u201cmandeullae (\u1106\u1161\u11ab\u1103\u1173\u11af\u1105\u1162, Do you wanna build)\u201d and \u201ctallae (\u1110\u1161\u11af\u1105\u1162, Do you wanna ride)\u201d creates a sense of repetition because both end with \u201cllae\u201d meaning \u201cDo you wanna\u201d. Another example is the repetition of particles at the end of sentences, such as \u201cyo (\u3088)\u201d and \u201cno (\u306e)\u201d in Japanese and \u201cyo (\u110b\u116d)\u201d and \u201cda (\u1103\u1161)\u201d in Korean, which convey cultural nuances related to formality. We therefore propose that English, Japanese, and Korean share common ground in adopting phoneme repetition for poetic expression. However, as such repetition is not necessarily called rhyme in Japanese and Korean, we will refrain from using the term \u201crhyme\u201d and instead employ the term \u201cphoneme repetition.\u201d\nWe noticed that each section\u2019s degree of phoneme repetition remains consistent across different languages when the lyrics are singable. For example, in Table 3, the first section of the original English lyrics (E(A1)) displays a strong degree of phoneme repetition, with three rhyming pairs: \u201ccome-come\u201d, \u201cplay-away\u201d, and \u201canymore-door\u201d (In this paper, we denote a section as an uppercase with a number and a line as a lower case with a number). Similarly, both the Japanese and Korean translations (J(A1), K(A1)) also exhibit a substantial degree of phoneme repetition, featuring three pairs of repeated phonemes in each: \u201cdoa (\u30c9\u30a2)\u201d-\u201cdou (\u3069\u3046)\u201d, \u201ctsukurou (\u4f5c\u308d\u3046)\u201d-\u201casobou (\u904a\u307c\u3046)\u201d, \u201cakete (\u958b\u3051\u3066)\u201d-\u201cshite (\u3057\u3066)\u201d in Japanese, and \u201cgachi (\u1100\u1161\u11c0\u110b\u1175)\u201d-\u201cgachi (\u1100\u1161\u11c0\u110b\u1175)\u201d, \u201cmandeul (\u1106\u1161\u11ab\u1103\u1173\u11af)\u201d\u201ceonnireul (\u110b\u1165\u11ab\u1102\u1175\u1105\u1173\u11af)\u201d, \u201cmandeullae (\u1106\u1161\u11ab\u1103\u1173\u11af\u1105\u1162)\u201d-\u201csimsimhae (\u1109\u1175\u11b7\u1109\u1175\u11b7\u1112\u1162)\u201d in Korean. However, we realized that it is not fair to directly compare the number of phoneme repetitions when attempting to quantify the degree of phoneme repetition as each language has a different number of vowels and consonants: English has 15 vowels and 24 consonants, whereas Japanese has 5 and 15 and Korean has 21 and 19. Hence, in an attempt to minimize the differences in the number of phonemes, we treated acoustically similar vowels as the same vowel in English, such as \u2018IH\u2019-\u2018IY\u2019, \u2018UH\u2019-\u2018UW\u2019, or \u2018EH\u2019-\u2018AE\u2019(e.g., \u2019mass\u2019 and \u2019mess\u2019) [25] because they can still form slant rhymes [26]. Conversely, we considered \u2018A\u2019-\u2018YA\u2019, \u2018O\u2019-\u2018YO\u2019, and \u2018U\u2019-\u2018YU\u2019 as sep-\narate vowels in Japanese, as they are unlikely to function as the same grammatical components. In Korean, we regarded the perceptually similar vowels (e.g., \u2018AE\u2019-\u2018E\u2019or \u2018OE\u2019-\u2018OI\u2019-\u2018OAE\u2019) as the same vowels [27, 28].\nTo quantitatively represent the degree of phoneme repetition, we utilized the concept of distinct-2, the ratio of the number of distinct bi-grams to the total number of bigrams [29]. While the original concept formed bi-grams using two consecutive words, we used two consecutive phonemes to assess the degree of repetition because lower distinct-2 values indicate higher repetition and vice versa. The phoneme distinct-2 (pho) of a section Xi, is defined as follows:\npho(Xi) = unique bi-gram # in Xi total bi-gram # in Xi . (2)\nFor example, consider a section with a single line \u201ctwinkle twinkle little star\u201d, denoted as X1. First, we decomposed the section into phonemes and added the \u2018<eos>\u2019to each line: \u2018T\u2019, \u2018W\u2019, \u2018IH\u2019, \u2018NG\u2019, \u2018K\u2019, \u2018AH\u2019, . . . , \u2018S\u2019, \u2018T\u2019, \u2018AA\u2019, \u2018R\u2019, and \u2018<eos>\u2019. Next, we grouped each component into bi-grams: \u2018TW\u2019, \u2018WIH\u2019, \u2018IHNG\u2019, \u2018NGK\u2019, \u2018KAH\u2019, \u2018AHL\u2019, . . . , \u2018ST\u2019, \u2018TAA\u2019, \u2018AAR\u2019, \u2018R<eos>\u2019. Finally, we calculated the phoneme distinct-2 of the section (pho(X1)) by dividing the number of unique bi-grams by the total number of bi-grams (17/23 = 0.74). To measure the similarity between two sections in terms of the degree of phoneme repetition, we introduce the phoneme repetition similarity (Simpho). Given two sets of lyrics with m sections, X = {X1, ..., Xm} and X\u0303 = {X\u03031, ..., X\u0303m}, the phoneme repetition similarity between X and X\u0303 is defined as the Spearman correlation between {pho(X1), ..., pho(Xm)} and {pho(X\u03031), ..., pho( \u02dcXm)}, as shown below.\nSimpho(X, X\u0303) = corr({pho(X1), ..., pho(Xm)}, {pho(X\u03031), ..., pho(X\u0303m)}) (3) We present the statistical results for the average phoneme repetition similarity of singable and non-singable lyrics in Table 4. The table clearly exhibits a higher correlation between the original lyrics and singable translated lyrics in terms of the phoneme distinct-2 than non-singable lyrics. This result suggests that singable lyric translation takes into account the degree of phoneme repetition within each section to convey a sense of repetition for that section."
        },
        {
            "heading": "4.3 Musical Structure Distance",
            "text": "Upon examining our section-divided singable lyrics data, we identified two tendencies in lyrics when musical sections\nare repeated (e.g., the repetition of the chorus). First, we observed that musically similar sections tend to share the same phonemes and, as expected, the same phrases. For instance, in Table 3, musically similar sections share the same vowels (e.g., \u201cwhy\u201d in E(B1) and \u201cby\u201d in E(B2)) or identical phrases (e.g., \u201cDo you wanna build a snowman\u201d in E(A1) and E(A2)) in order to create a sense of consistency. As a result, when calculating the phoneme distinct-2 (pho) for two concatenated sections, musically similar sections are likely to have smaller values than musically different sections. For example, pho(E(A1 ++A2)) is 0.70 (\u2018++\u2019 denotes the concatenation of text), whereas pho(E(A1++B1)) is 0.82, where A1 is musically similar to A2 but not to B1. However, a low value of pho does not always imply musical similarity, as a meager pho value in one section could result in a low pho of two concatenated sections despite the musical dissimilarity (e.g., \u201clalalalalalalalalalalalalala\u201d ++ \u201cdo you wanna build a snowman?\u201d). From this case, we derived our second observation that a significant difference in pho for each section could imply musical differences. Accordingly, we also realized that musically similar sections tend to have a similar degree of pho. For instance, in Table 3, both A1 and A2, a set of musically similar sections, exhibit relatively low pho, indicating a strong degree of phoneme repetition (rhyme), with similar values to each other across all languages. Likewise, both B1 and B2, another pair of musically similar sections, demonstrate a higher pho, with similar values to each, in all languages.\nTherefore, to quantify the musical similarity between sections, we examined whether they have 1) a tendency to share the same phoneme by obtaining pho(Xi++Xj), and 2) similar pho values by calculating |pho(Xi)\u2212 pho(Xj)|. Given that higher values represent dissimilarity in both cases, we define the musical dissimilarity between two sections, diss(Xi, Xj), as the sum of these two values, as follows.\ndiss(Xi, Xj) = pho(Xi++Xj) + |pho(Xi)\u2212 pho(Xj)| (4)\nAs shown in Figure 1, self-dissimilarity matrices employing our definition of musical dissimilarity look highly similar across English, Japanese, and Korean, where all are singable, visually representing musical structure.\nFinally, we quantitatively evaluated the distance between matrices. We refer to this distance between matrices as the musical structure distance, as it represents the structural element of lyrics. In summary, the musical structure distance\nbetween lyrics in different languages X and X\u0303, each consisting of m sections, Dismus(X, X\u0303), is defined as follows:\nDismus(X, X\u0303) = 1\nm2 \u221a\u2211m i,j=1 (diss(Xi, Xj)\u2212 diss(X\u0303i, X\u0303j))2\n(5) In Table 5, we provide a summary of the average musical structure distance for singable lyrics, human-translated nonsingable lyrics, and machine-translated non-singable lyrics generated by automatically translating official singable lyrics from 80 English, 162 Japanese, and 161 Korean songs using Google Translator. Our findings show that singable lyrics exhibit the lowest Dismus values, while machine-translated non-singable lyrics display the highest, suggesting that machine-translated ones lack structural coherence the most. As human-translated non-singable lyrics maintain structural coherence in aspects such as word choice and nuances, they demonstrate lower distances than machine-translated counterparts."
        },
        {
            "heading": "5. EVALUATING SEMANTICS",
            "text": "Semantic relatedness to the original lyrics is by no means less fundamental than syllable counts, phoneme repetition, and structural factors [18]. We therefore introduce a fourth metric, semantic similarity, to ensure the semantic relevance of translated lyrics to the original."
        },
        {
            "heading": "5.1 Semantic Similarity",
            "text": "To numerically assess the semantic textual similarity (sts) between a pair of lyrics, we first obtained the contextual embeddings of each text from lyrics using a pre-trained Sentence BERT model 1 [31] and then calculated the cosine similarity between the embeddings. As this model was trained for English, the Japanese and Korean lyrics were automatically translated using Google Translator before obtaining the embeddings.\nWe started by examining hierarchical semantic similarity using cross-scape plots [32], as shown in Figure 2. Given a pair of lyrics X = {x1, . . . , xn} and X\u0303 = {x\u03031, . . . , x\u0303n} with n lines each, the first (leftmost) block of the lowest line represents the semantic textual similarity between x1 and x\u03031 (denoted as sts(x1, x\u03031)) while the last (rightmost) block signifies sts(xn, x\u0303n). The first (leftmost) block of the second-lowest line denotes sts(x1++x2, x\u03031++x\u03032), and the second block corresponds to sts(x2++x3, x\u03032++x\u03033). Lastly,\n1 We used all-MiniLM-L6-v2 [30].\nthe highest block (line) represents the similarity between the entire lyrics, sts(x1 ++ \u00b7 \u00b7 \u00b7++ xn, x\u03031 ++ \u00b7 \u00b7 \u00b7++ x\u0303n).\nIn each plot of Figure 2, there are semantic disparities at lower levels, but similarities increase at higher (broader) levels. We have two explanations for this. First, the number of musical notes within a single lyric line may be adequate to deliver a specific message in one language but insufficient in another language. Therefore, it is common for a message conveyed in one line in one language to span two lines in another language. As an example, we provide Table 6, which presents the semantic textual similarity (sts) between Japanese and English lyrics of the J-pop song \u201cA Thousand Winds (\u5343\u306e\u98a8\u306b\u306a\u3063\u3066)\u201d. As demonstrated in the table, the similarity between Japanese and English at a broader level (sts(x1++x2, x\u03031++x\u03032)) can be higher than at the line level (sts(x1, x\u03031), sts(x2, x\u03032)) because Japanese generally requires more syllables than English and it often takes two lines in Japanese to express a single-line message in English. Second, the semantic similarities at broader levels can be higher because of grammatical/linguistic differences. Each language has its own natural word order patterns. For example, in the phrase \u201cI\u2019m going to travel to find the gold,\u201d it is natural in English to mention \u201cI\u2019m going to travel\u201d before \u201cto find the gold.\u201d However, in Japanese and Korean, expressing \u201cto find the gold (\uf90a\u3092\u63a2\u3057\u306b,\u1100\u1173\u11b7\u110b\u1173\u11af\u110e\u1161\u11bd\u110b\u1173\u1105\u1165)\u201d before \u201cI\u2019m going to travel (\uf983\u306b\u51fa\u308b,\u1104\u1165\u1102\u1161\u11ab\u1103\u1161)\u201d is a more typical and natural construction. Table 7 shows that these differences between languages make line-level semantic assessments insufficient. Since lines 1, 2, and 3 in the English version correspond to lines 3, 1, and 2 respectively in the Japanese version, these pairs exhibit low semantic similarities at the line level (sts(x1, x\u03031), sts(x2, x\u03032), sts(x3, x\u03033)), while demonstrating higher similarity when considered as a whole (sts(x1++x2++x3, x\u03031++x\u03032++x3)).\nConsidering these factors, it becomes evident that\nLine # English\nJapanese (English translation) sts\n1 Dare to try and reach out for h\u0435aven\n\u671b\u3080\u3088\u3046\u306b\u751f\u304d\u308b\u306a\u3089 (If you want to become what you\u2019re meant to be) 0.22\n2 You must become what you\u2019r\u0435 meant to be\n\u661f\u304b\u3089\u306e\uf90a\u3092\u6c42\u3081 (to find the gold from stars) 0.27\n3 And bring the gold of heaven to the world\n\u4e00\u4eba\uf983\u306b\u51fa\u308b\u306e\u3088 (Dare to embark on a solo journey) 0.13\n1-3 Dare to try and reach out for h\u0435aven You must become what you\u2019r\u0435 meant to be And bring the gold of heaven to the world \u671b\u3080\u3088\u3046\u306b\u751f\u304d\u308b\u306a\u3089\u661f\u304b\u3089\u306e \uf90a\u3092\u6c42\u3081\u4e00\u4eba\uf983\u306b\u51fa\u308b\u306e\u3088 (Dare to embark on a solo journey if you want to become what you\u2019re meant to be to find the gold from stars) 0.53\nTable 7. Semantic textual similarity (sts) between English and Japanese versions of \u201cGold von den Sternen\u201d.\nFigure 3. The line-wise (Left) and section-wise (Right) semantic similarity matrices between Japanese and Korean versions of \u201cWie wird man seinen Schatten los?\u201d\nsingable lyric translations do not prioritize line-wise semantic similarity. Rather, we observed that singable translations aim to preserve semantic connections at the section level since the organization of the lyric storyline follows a sectionwise approach. To illustrate this, we present Figure 3, which displays both line-wise and section-wise semantic similarity matrices for the Japanese and Korean versions of \u201cHow do you get rid of your shadow? (Wie wird man seinen Schatten los?)\u201d from the German musical \u201cMozart!\u201d. As shown in the Figure, the section-wise matrix represents the semantic relatedness more clearly than the line-wise matrix.\nTherefore, we propose assessing section-wise semantic relatedness for evaluating singable lyric translation. To achieve this, we define the semantic similarity between a pair of lyrics X = {X1, ..., Xm} and X\u0303 = {X\u03031, ..., X\u0303m}, consisting of m sections and n = n(X1) + \u00b7 \u00b7 \u00b7 + n(Xm) lines, where n(Xi) denotes the number of lines in the i-th section, as follows:\nSimsem(X, X\u0303) = \u2211m i=1( n(Xi) n sts(Xi, X\u0303i)). (6)\nTable 8 compares singable and non-singable lyrics in terms of line-wise semantic similarities ( 1n \u2211n i=1 sts(xi, x\u0303i)) and section-wise similarities, using our proposed metric (Simsem). The table reveals that non-singable translations exhibit high semantic similarity for both line-wise and section-wise measures, with similar values for each. In contrast, singable translations show low line-wise similarity, as expected, since they do not prioritize line-wise semantic similarity. However, when evaluated using section-wise similarity, they display a level of similarity comparable to that between \u201cMachine learning is so easy\u201d and \u201cDeep learning is so straightforward\u201d, which is 0.623 when measured with the same pre-trained model [30]."
        },
        {
            "heading": "6. DISCUSSIONS AND CONCLUSIONS",
            "text": "In this paper, we introduced a computational evaluation framework for singable lyric translation, grounded in the musical, linguistic, and cultural understanding of lyrics, comprised of four evaluation metrics, line syllable count distance (Dissyl), phoneme repetition similarity (Simpho), musical structure distance (Dismus), and semantic similarity (Simsem). These metrics are designed to ensure that the translated lyrics maintain the integrity of melodies, degree of phoneme repetition, structural coherence, and semantics of the original lyrics. Our framework is automated, guaranteeing objectivity and efficiency in terms of time and cost. We showed the efficacy of our evaluation metrics by offering comparative statistics between singable and nonsingable lyrics. In addition, our analysis revealed that the degree of phoneme repetition in the original lyrics is frequently mirrored in the translated lyrics, musically similar sections tend to share the same phonemes and display comparable degrees of phoneme repetition, and section-wise analysis is better suited for evaluating semantic similarity for lyric translation than line-wise analysis.\nNonetheless, there remains room for improvement. Although we have assembled a singable lyrics dataset, aligned across English, Japanese, and Korean, our dataset has some limitations; it lacks musical information and its volume is limited. As a result, we have not been able to incorporate musical notes into our experiment or conduct comparative studies across various genres. We recognize that an ideal lyric translation evaluation system should take into account the relationship between musical notes and phonemes, as well as adapt to different genres. Moreover, although we have endeavored to incorporate cultural understandings of poetry in different languages, we acknowledge the need for deeper cultural considerations. For example, we noticed that cultural similarities might have an impact on the extent of semantic similarities. This is demonstrated in an English translation of \u201cMIC Drop\u201d, a K-pop song by BTS originally written in Korean, made by YouTuber Iris Phuong. The translated singable lyrics do not include a translation of the term \u201chyodo (\u1112\u116d\u1103\u1169, taking care of parents)\u201d as there is no direct equivalent in English, while the Japanese version of the song effortlessly conveys the concept as \u201ckoukou (\u5b5d\ufa08)\u201d. In the future, we aim to expand our dataset to contribute more to lyric translation studies and to further explore the impact of genre and cultural influences on lyric translation."
        },
        {
            "heading": "7. ACKNOWLEDGMENTS",
            "text": "This work was supported in part by JST CREST Grant Number JPMJCR20D4."
        },
        {
            "heading": "8. REFERENCES",
            "text": "[1] M. Mateo, \u201cMusic and translation,\u201d Handbook of translation studies, vol. 3, pp. 115\u2013121, 2012.\n[2] S\u0327. Susam-Sarajeva, \u201cTranslation and music: Changing perspectives, frameworks and significance,\u201d The Translator, vol. 14, no. 2, pp. 187\u2013200, 2008.\n[3] S. Spaeth, \u201cTranslating to music,\u201d The Musical Quarterly, vol. 1, no. 2, pp. 291\u2013298, 1915.\n[4] P. Low, \u201cTranslating songs that rhyme,\u201d Perspectives: Studies in translatology, vol. 16, no. 1-2, pp. 1\u201320, 2008.\n[5] \u2014\u2014, \u201cThe pentathlon approach to translating songs,\u201d in Song and significance. Brill, 2005, pp. 185\u2013212.\n[6] F. Guo, C. Zhang, Z. Zhang, Q. He, K. Zhang, J. Xie, and J. Boyd-Graber, \u201cAutomatic song translation for tonal languages,\u201d in Findings of the Association for Computational Linguistics (ACL). Dublin, Ireland: Association for Computational Linguistics, May 2022, pp. 729\u2013743. [Online]. Available: https: //aclanthology.org/2022.findings-acl.60\n[7] L. Ou, X. Ma, M.-Y. Kan, and Y. Wang, \u201cSongs across borders: Singable and controllable neural lyric translation,\u201d arXiv preprint arXiv:2305.16816, 2023.\n[8] C. Li, K. Fan, J. Bu, B. Chen, Z. Huang, and Z. Yu, \u201cTranslate the beauty in songs: Jointly learning to align melody and translate lyrics,\u201d arXiv preprint arXiv:2303.15705, 2023.\n[9] K. Watanabe and M. Goto, \u201cLyrics information processing: Analysis, generation, and applications,\u201d in Proceedings of the 1st Workshop on NLP for Music and Audio (NLP4MusA), 2020, pp. 6\u201312.\n[10] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, \u201cBLEU: A method for automatic evaluation of machine translation,\u201d in Proceedings of the 40th annual meeting of the Association for Computational Linguistics (ACL), 2002, pp. 311\u2013318.\n[11] C.-Y. Lin, \u201cROUGE: A package for automatic evaluation of summaries,\u201d in Text summarization branches out, 2004, pp. 74\u201381.\n[12] S. Banerjee and A. Lavie, \u201cMETEOR: An automatic metric for MT evaluation with improved correlation with human judgments,\u201d in Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 2005.\n[13] T. Zhang, V. Kishore, F. Wu, K. Q. Weinberger, and Y. Artzi, \u201cBERTScore: Evaluating text generation with bert,\u201d in International Conference on Learning Representations (ICLR), 2019.\n[14] I. Marc, \u201cTravelling songs: On popular music transfer and translation,\u201d IASPM Journal, vol. 5, no. 2, pp. 3\u201321, 2015.\n[15] E. C. Hui-tung, \u201cTranslation of songs,\u201d An Encyclopedia of Practical Translation and Interpreting, p. 351, 2019.\n[16] Y. Yang, Y. Zhang, C. Tar, and J. Baldridge, \u201cPAWSX: A cross-lingual adversarial dataset for paraphrase identification,\u201d in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019, pp. 3687\u20133692.\n[17] H. S. Drinker, \u201cOn translating vocal texts,\u201d The Musical Quarterly, vol. 36, no. 2, pp. 225\u2013240, 1950.\n[18] J. Franzon, \u201cThree dimensions of singability. An approach to subtitled and sung translations,\u201d Text and Tune. On the Association of Music and Lyrics in Sung Verse. Bern: Peter Lang, pp. 333\u2013346, 2015.\n[19] J. P. G. Mahedero, A. Mart\u00cdnez, P. Cano, M. Koppenberger, and F. Gouyon, \u201cNatural language processing of lyrics,\u201d in Proceedings of the 13th Annual ACM International Conference on Multimedia, ser. MULTIMEDIA \u201905. Association for Computing Machinery, 2005, pp. 475\u2013478.\n[20] K. Watanabe and M. Goto, \u201cA chorus-section detection method for lyrics text.\u201d in Proceedings of the 21th International Conference on Music Information Retrieval (ISMIR), 2020, pp. 351\u2013359.\n[21] R. Apter and M. Herman, \u201cTranslating art songs for performance: Rachmaninoff\u2019s six choral songs,\u201d Translation Review, vol. 84, no. 1, pp. 27\u201342, 2012.\n[22] A. Bain, \u201cEnglish composition and rhetoric,(2nd american ed.),\u201d New York: D. Appleton and Company, 1867.\n[23] N. Manabe, \u201cGlobalization and Japanese creativity: Adaptations of Japanese language to rap,\u201d Ethnomusicology, vol. 50, no. 1, pp. 1\u201336, 2006.\n[24] Y. B. Yoon and B. L. Derwing, \u201cA language without a rhyme: Syllable structure experiments in Korean,\u201d Canadian Journal of Linguistics/Revue canadienne de linguistique, vol. 46, no. 3-4, pp. 187\u2013237, 2001.\n[25] A. K. Syrdal and H. S. Gopal, \u201cA perceptual model of vowel recognition based on the auditory representation of American English vowels,\u201d The Journal of the Acoustical Society of America, vol. 79, no. 4, pp. 1086\u20131100, 1986.\n[26] K. Hanson, \u201cFormal variation in the rhymes of Robert Pinsky\u2019s the inferno of dante,\u201d Language and Literature, vol. 12, no. 4, pp. 309\u2013337, 2003.\n[27] C. Ito, Y. Kang, and M. Kenstowicz, \u201cThe adaptation of Japanese loanwords into Korean,\u201d MIT Working Papers in Linguistics, vol. 52, no. 2006, pp. 65\u2013104, 2006.\n[28] S.-E. Chang, \u201cEnhancement effects of clear speech and word-initial position in Korean glides.\u201d The Journal of the Acoustical Society of America, 2017.\n[29] J. Li, M. Galley, C. Brockett, J. Gao, and W. B. Dolan, \u201cA diversity-promoting objective function for neural conversation models,\u201d in Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics (NACCL) : Human Language Technologies, 2016, pp. 110\u2013119.\n[30] W. Wang, F. Wei, L. Dong, H. Bao, N. Yang, and M. Zhou, \u201cMiniLM: Deep self-attention distillation for task-agnostic compression of pre-trained transformers,\u201d Advances in Neural Information Processing Systems (NeurIPS), vol. 33, pp. 5776\u20135788, 2020.\n[31] N. Reimers and I. Gurevych, \u201cSentence-BERT: Sentence embeddings using Siamese BERT-networks,\u201d in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019, pp. 3982\u20133992.\n[32] S. Park, T. Kwon, J. Lee, J. Kim, and J. Nam, \u201cA cross-scape plot representation for visualizing symbolic melodic similarity,\u201d in Proceedings of the 20th International Conference on Music Information Retrieval (ISMIR), 2019, pp. 423\u2013430."
        }
    ],
    "title": "A COMPUTATIONAL EVALUATION FRAMEWORK FOR SINGABLE LYRIC TRANSLATION",
    "year": 2023
}