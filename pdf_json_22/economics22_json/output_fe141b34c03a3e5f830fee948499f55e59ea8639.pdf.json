{
    "abstractText": "We consider the problem of partial identification, the estimation of bounds on the treatment effects from observational data. Although studied using discrete treatment variables or in specific causal graphs (e.g., instrumental variables), partial identification has been recently explored using tools from deep generative modeling. We propose a new method for partial identification of average treatment effects (ATEs) in general causal graphs using implicit generative models comprising continuous and discrete random variables. Since ATE with continuous treatment is generally non-regular, we leverage the partial derivatives of response functions to define a regular approximation of ATE, a quantity we call uniform average treatment derivative (UATD). We prove that our algorithm converges to tight bounds on ATE in linear structural causal models (SCMs). For nonlinear SCMs, we empirically show that using UATD leads to tighter and more stable bounds than methods that directly optimize the ATE. 1",
    "authors": [
        {
            "affiliations": [],
            "name": "Vahid Balazadeh"
        },
        {
            "affiliations": [],
            "name": "Vasilis Syrgkanis"
        },
        {
            "affiliations": [],
            "name": "Rahul G. Krishnan"
        }
    ],
    "id": "SP:0e3aac65d550b4850abc12f685e7f159e6c0d17b",
    "references": [
        {
            "authors": [
                "A. Balke",
                "J. Pearl"
            ],
            "title": "Bounds on treatment effects from studies with imperfect compliance",
            "venue": "Journal of the American Statistical Association,",
            "year": 1997
        },
        {
            "authors": [
                "B. Callaway",
                "A. Goodman-Bacon",
                "P.H. Sant\u2019Anna"
            ],
            "title": "Difference-in-differences with a continuous treatment",
            "venue": "arXiv preprint arXiv:2107.02637,",
            "year": 2021
        },
        {
            "authors": [
                "V. Chernozhukov",
                "W.K. Newey",
                "R. Singh"
            ],
            "title": "Automatic debiased machine learning of causal and structural effects",
            "venue": "arXiv preprint arXiv:1809.05224,",
            "year": 2018
        },
        {
            "authors": [
                "M. Cuturi"
            ],
            "title": "Sinkhorn distances: Lightspeed computation of optimal transport",
            "venue": "Advances in neural information processing systems,",
            "year": 2013
        },
        {
            "authors": [
                "I. D\u00edaz",
                "M.J. van der Laan"
            ],
            "title": "Targeted data adaptive estimation of the causal dose\u2013response curve",
            "venue": "Journal of Causal Inference,",
            "year": 2013
        },
        {
            "authors": [
                "D. Dua",
                "C. Graff"
            ],
            "title": "UCI machine learning repository, 2017",
            "venue": "URL http://archive.ics.uci. edu/ml",
            "year": 2017
        },
        {
            "authors": [
                "G. Duarte",
                "N. Finkelstein",
                "D. Knox",
                "J. Mummolo",
                "I. Shpitser"
            ],
            "title": "An automated approach to causal inference in discrete settings",
            "venue": "CoRR, abs/2109.13471,",
            "year": 2021
        },
        {
            "authors": [
                "A. D\u2019Amour",
                "P. Ding",
                "A. Feller",
                "L. Lei",
                "J. Sekhon"
            ],
            "title": "Overlap in observational studies with high-dimensional covariates",
            "venue": "Journal of Econometrics,",
            "year": 2021
        },
        {
            "authors": [
                "R.J. Evans"
            ],
            "title": "Graphical methods for inequality constraints in marginalized dags",
            "venue": "In IEEE International Workshop on Machine Learning for Signal Processing,",
            "year": 2012
        },
        {
            "authors": [
                "J. Feydy",
                "T. S\u00e9journ\u00e9",
                "F. Vialard",
                "S. Amari",
                "A. Trouv\u00e9",
                "G. Peyr\u00e9"
            ],
            "title": "Interpolating between optimal transport and MMD using sinkhorn divergences",
            "venue": "The 22nd International Conference on Artificial Intelligence and Statistics,",
            "year": 2019
        },
        {
            "authors": [
                "N. Finkelstein",
                "R. Adams",
                "S. Saria",
                "I. Shpitser"
            ],
            "title": "Partial identifiability in discrete data with measurement error",
            "venue": "Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "A. Genevay",
                "G. Peyr\u00e9",
                "M. Cuturi"
            ],
            "title": "Learning generative models with sinkhorn divergences",
            "venue": "In A. J. Storkey and F. Pe\u0301rez-Cruz, editors, International Conference on Artificial Intelligence and Statistics,",
            "year": 2018
        },
        {
            "authors": [
                "I. Goodfellow",
                "J. Pouget-Abadie",
                "M. Mirza",
                "B. Xu",
                "D. Warde-Farley",
                "S. Ozair",
                "A. Courville",
                "Y. Bengio"
            ],
            "title": "Generative adversarial nets",
            "venue": "Advances in neural information processing systems,",
            "year": 2014
        },
        {
            "authors": [
                "O. Goudet",
                "D. Kalainathan",
                "P. Caillou",
                "I. Guyon",
                "D. Lopez-Paz",
                "M. Sebag"
            ],
            "title": "Causal generative neural networks",
            "venue": "arXiv preprint arXiv:1711.08936,",
            "year": 2017
        },
        {
            "authors": [
                "S. Gruber",
                "G. Lefebvre",
                "T. Schuster",
                "A. Pich\u00e9"
            ],
            "title": "Atlantic causal inference conference data challenge, 2019",
            "venue": "URL https://sites.google.com/view/acic2019datachallenge/",
            "year": 2019
        },
        {
            "authors": [
                "F. Gunsilius"
            ],
            "title": "A path-sampling method to partially identify causal effects in instrumental variable models",
            "venue": "arXiv preprint arXiv:1910.09502,",
            "year": 2019
        },
        {
            "authors": [
                "F.F. Gunsilius"
            ],
            "title": "Nontestability of instrument validity under continuous treatments",
            "venue": "Biometrika, 108 (4):989\u2013995,",
            "year": 2020
        },
        {
            "authors": [
                "W. Guo",
                "M. Yin",
                "Y. Wang",
                "M.I. Jordan"
            ],
            "title": "Partial identification with noisy covariates: A robust optimization approach",
            "venue": "arXiv preprint arXiv:2202.10665,",
            "year": 2022
        },
        {
            "authors": [
                "K. Hirano",
                "G.W. Imbens"
            ],
            "title": "The propensity score with continuous treatments",
            "venue": "Applied Bayesian modeling and causal inference from incomplete-data perspectives,",
            "year": 2004
        },
        {
            "authors": [
                "Y. Hu",
                "Y. Wu",
                "L. Zhang",
                "X. Wu"
            ],
            "title": "A generative adversarial framework for bounding confounded causal effects",
            "venue": "In Proceedings of the 35th AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "E.H. Kennedy",
                "Z. Ma",
                "M.D. McHugh",
                "D.S. Small"
            ],
            "title": "Non-parametric methods for doubly robust estimation of continuous treatment effects",
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
            "year": 2017
        },
        {
            "authors": [
                "N. Kilbertus",
                "M.J. Kusner",
                "R. Silva"
            ],
            "title": "A class of algorithms for general instrumental variable models",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "M. Kocaoglu",
                "C. Snyder",
                "A.G. Dimakis",
                "S. Vishwanath"
            ],
            "title": "Causalgan: Learning causal implicit generative models with adversarial training",
            "venue": "In 6th International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "J. Li",
                "S. Huang",
                "A.M.-C. So"
            ],
            "title": "A first-order algorithmic framework for distributionally robust logistic regression",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "M. Makar",
                "F.D. Johansson",
                "J.V. Guttag",
                "D.A. Sontag"
            ],
            "title": "Estimation of bounds on potential outcomes for decision making",
            "venue": "In Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "C.F. Manski"
            ],
            "title": "Nonparametric bounds on treatment effects",
            "venue": "The American Economic Review,",
            "year": 1990
        },
        {
            "authors": [
                "C.F. Manski"
            ],
            "title": "Partial identification of probability distributions, volume",
            "year": 2003
        },
        {
            "authors": [
                "C.H. Miles",
                "P.J. Kanki",
                "S. Meloni",
                "E.J.T. Tchetgen"
            ],
            "title": "On partial identification of the pure direct effect",
            "venue": "arXiv: Methodology,",
            "year": 2015
        },
        {
            "authors": [
                "P. Mohajerin Esfahani",
                "D. Kuhn"
            ],
            "title": "Data-driven distributionally robust optimization using the wasserstein metric: Performance guarantees and tractable reformulations",
            "venue": "Mathematical Programming,",
            "year": 2018
        },
        {
            "authors": [
                "K. Padh",
                "J. Zeitler",
                "D. Watson",
                "M. Kusner",
                "R. Silva",
                "N. Kilbertus"
            ],
            "title": "Stochastic causal programming for bounding treatment effects",
            "venue": "arXiv preprint arXiv:2202.10806,",
            "year": 2022
        },
        {
            "authors": [
                "J. Pearl"
            ],
            "title": "Causality: Models, Reasoning and Inference",
            "year": 2009
        },
        {
            "authors": [
                "J.L. Powell",
                "J.H. Stock",
                "T.M. Stoker"
            ],
            "title": "Semiparametric estimation of index coefficients",
            "venue": "Econometrica: Journal of the Econometric Society,",
            "year": 1989
        },
        {
            "authors": [
                "R.R. Ramsahai"
            ],
            "title": "Causal bounds and observable constraints for non-deterministic models",
            "venue": "J. Mach. Learn. Res., 13(null):829\u2013848,",
            "year": 2012
        },
        {
            "authors": [
                "A. Richardson",
                "M.G. Hudgens",
                "P.B. Gilbert",
                "J.P. Fine"
            ],
            "title": "Nonparametric bounds and sensitivity analysis of treatment effects",
            "venue": "Statistical science: a review journal of the Institute of Mathematical Statistics,",
            "year": 2014
        },
        {
            "authors": [
                "C. Ritz",
                "F. Baty",
                "J.C. Streibig",
                "D. Gerhard"
            ],
            "title": "Dose-response analysis using r",
            "venue": "PloS one,",
            "year": 2015
        },
        {
            "authors": [
                "J.M. Robins"
            ],
            "title": "The analysis of randomized and non-randomized aids treatment trials using a new approach to causal inference in longitudinal studies",
            "venue": "Health service research methodology: a focus on AIDS,",
            "year": 1989
        },
        {
            "authors": [
                "D. Rothenh\u00e4usler",
                "B. Yu"
            ],
            "title": "Incremental causal effects",
            "venue": "arXiv preprint arXiv:1907.13258,",
            "year": 2019
        },
        {
            "authors": [
                "A. Sauer",
                "A. Geiger"
            ],
            "title": "Counterfactual generative networks",
            "venue": "In 9th International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "C. Villani"
            ],
            "title": "Optimal transport: old and new, volume 338",
            "year": 2009
        },
        {
            "authors": [
                "J. Weed",
                "F. Bach"
            ],
            "title": "Sharp asymptotic and finite-sample rates of convergence of empirical measures in wasserstein",
            "venue": "distance. Bernoulli,",
            "year": 2019
        },
        {
            "authors": [
                "E. Wong",
                "F. Schmidt",
                "Z. Kolter"
            ],
            "title": "Wasserstein adversarial examples via projected sinkhorn iterations",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "J.M. Wooldridge"
            ],
            "title": "Unobserved heterogeneity and estimation of average partial effects. Identification and inference for econometric models: Essays in honor of Thomas",
            "year": 2005
        },
        {
            "authors": [
                "K. Xia",
                "K. Lee",
                "Y. Bengio",
                "E. Bareinboim"
            ],
            "title": "The causal-neural connection: Expressiveness",
            "venue": "learnability, and inference. CoRR,",
            "year": 2021
        },
        {
            "authors": [
                "J. Yoon",
                "J. Jordon",
                "M. Van Der Schaar"
            ],
            "title": "Ganite: Estimation of individualized treatment effects using generative adversarial nets",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "J. Zhang",
                "E. Bareinboim"
            ],
            "title": "Bounding causal effects on continuous outcome",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "J. Zhang",
                "E. Bareinboim"
            ],
            "title": "Non-parametric methods for partial identification of causal effects",
            "venue": "Columbia CausalAI Laboratory Technical Report,",
            "year": 2021
        },
        {
            "authors": [
                "J. Zhang",
                "J. Tian",
                "E. Bareinboim"
            ],
            "title": "Partial counterfactual identification from observational and experimental data",
            "venue": "CoRR, abs/2110.05690,",
            "year": 2021
        },
        {
            "authors": [
                "Q. Zhao",
                "T. Hastie"
            ],
            "title": "Causal interpretations of black-box models",
            "venue": "Journal of Business & Economic Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "Duarte"
            ],
            "title": "2021], where the true value of ATE",
            "year": 2021
        },
        {
            "authors": [
                "Duarte"
            ],
            "title": "We use the noncompliance IV dataset",
            "venue": "Binary IV [Duarte et al.,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Estimating average treatment effects (ATEs) is a common task that arises in fields involving decisionmaking, such as healthcare and economics. In the presence of the gold-standard randomized controlled trial (RCT) data, one can compare the outcome variable between treated and control groups to make decisions. But RCTs can be costly to set up and run and are, in many circumstances, infeasible. Consequently, communities are using observational data to assist in decision-making.\nIdentification of treatment effects from observational data is tied to the structure of the causal graph. For example, the treatment T and outcome Y in Figure 1b are confounded by an unobserved random variable, making it impossible to find the causal effect of T on Y only from observational data. On the other hand, Figure 1c is identifiable, and one can adjust for confounders using the Back-door formula [Pearl, 2009]. Even in identifiable settings, non-parametric estimations such as Back-door adjustment formula can point-identify the ATE only with additional assumptions such as positivity, i.e., P (T = t|X) > 0 for all values of covariate X . Observational data is finite, high-dimensional, and consequently can suffer from severe violations of such assumptions [D\u2019Amour et al., 2021].\nIn lieu of the challenges of point-identification, there has been a recognition that decisions can be justified using reliable bounds on the ATE rather than its exact value. For an oncologist treating a cancer patient, knowing that a drug has a significant, positive reduction in the patient\u2019s risk of progression may suffice as a rationale to prescribe that drug. This problem is known as partial identification [Manski, 2003]. Most existing methods for bounding the ATEs are only applicable in discrete/binary treatment variables [Makar et al., 2020, Zhang et al., 2021, Duarte et al., 2021, Guo et al., 2022]. There has been recent interest in continuous treatment settings. However, such\n1Our code is accessible at https://github.com/rgklab/partial_identification\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\nar X\niv :2\n21 0.\n08 13\n9v 1\n[ cs\n.L G\n] 1\n4 O\nct 2\nT X Y\n(a) Leaky mediation\nX T Y\n(b) IV\nX\nYT\n(c) Back-door\nT X Y\n(d) Front-door\nmethods are applicable for special causal graphs such as the instrumental variables (IV) setting [Gunsilius, 2020, Kilbertus et al., 2020] or make parametric assumptions on the family of treatmentresponse functions [Padh et al., 2022]. An exception is the work by Hu et al. [2021] which provides a non-parametric approach for partial identification using generative adversarial networks (GANs). However, they only provide convergence guarantees for the special case of IV causal graphs.\nUsing the framework of structural causal models (SCMs) and causal graphs, one can see partial identification as a constrained optimization problem, where the objective, i.e., maximizing/minimizing the ATE, can be written as a post-intervention function of exogenous noise (a.k.a response function) and the constraint is to match the generated samples with the observational distribution. This naturally leads to using generative neural networks such as neural causal models (NCMs) [Xia et al., 2021]. We find that directly solving the ATE optimization using flexible generative models such as GANs can lead to non-informative and degenerate solutions. The flexibility afforded by generative models such as GANs allows them to deviate significantly from the true response curve in the neighborhood of intervention points to maximize/minimize the ATE while continuing to generate samples akin to the data distribution. Figure 1e (left) showcases a typical solution to the ATE optimization.\nOur insight is that the ATE between any two points can be approximated as an integral over the derivatives of the response function w.r.t. the treatment variable. Rather than directly optimizing the ATE, we optimize the partial derivatives of the response function, a quantity that we refer to as the uniform average treatment derivative (UATD). 2 By optimizing the UATD, the model is required to maximize/minimize the partial derivatives for all points within the treatment support, avoiding extreme local solutions as shown in Figure 1e (right). Our contributions are as follows:\n\u2022 We formally define the partial identification of average treatment effects as a distributionallyconstrained optimization problem, where we choose Wasserstein distance as our constraint metric.\n\u2022 For the class of linear SCMs, we prove that the solution to our optimization problem converges to optimal bounds on the true value of ATE in infinite data for general causal graphs.\n\u2022 We use the solution to partial identification of UATDs to find informative bounds on the value of ATE. We introduce a practical algorithm to solve the distributionally-constrained optimization problem using the Lagrange multiplier formulation with alternating optimization. We empirically\n2Average treatment derivative is also known as average partial effect in the literature [Powell et al., 1989, Wooldridge, 2005, Rothenh\u00e4usler and Yu, 2019].\nshow that our algorithm results in tighter and more stable bounds than methods that directly optimize the ATE."
        },
        {
            "heading": "2 Problem Setup & Background",
            "text": "We introduce the definitions and assumptions we will use throughout the paper. Consider the observed data as (possibly continuous) random variables V = {X1, \u00b7 \u00b7 \u00b7 , Xm, T, Y } \u2208 Rd, where T , Y , and {X1, \u00b7 \u00b7 \u00b7 , Xm} denote the treatment variable, target variable, and covariates, respectively. Data generating model. Our approach will be based on the framework of Structural Causal Models (SCMs). An SCM is a tuple M = (V,U,F , PU), where each observed variable Vi \u2208 V is a deterministic function of a subset of variables pa(Vi) \u2286 V and latent variables UVi \u2286 U, i.e.,\nVi = fVi(pa(Vi),UVi) where fVi \u2208 F , Vi 6\u2208 pa(Vi) (1)\nThe only source of randomness are latent variables U with probability space (\u2126,\u03a3, PU). This induces a probability law over the observed variables PM. We may omit the subscriptM and denote the observational probability distribution by P throughout the text. GivenM, one can construct a graph with nodes V \u222aU and directed edges from nodes in pa(Vi) \u222aUVi to Vi. We call this graph the causal graph corresponding to SCMM and denote it by GM or simply G. We assume G is acyclic and known. Moreover, We will assume each node in the graph is 1-dimensional. For random variable V in the SCMM, let VM(u) be its deterministic value after fixing a realization u of latent variables U. The causal effect of treatment T on target Y is: Definition 1 (Causal Effect). Let YM(T=t)(u) be the value of Y by fixing U = u and changing the function fT to a constant function fT = t inM. Then, we call the random variable YM(T=t) the causal effect of treatment T = t on target Y . We may simplify the notation and write it as Yt if the SCMM and treatment variable T are known from context. Note that YT (u)(u) = Y (u). When T is continuous, then we can view {Yt : t \u2208 supp(T )} as a stochastic function defined on (\u2126,\u03a3, PU). This is referred to as the response function, partial dependence plot, and dose-response curve in the literature [Zhao and Hastie, 2021, Ritz et al., 2015, Chernozhukov et al., 2018].\nAverage treatment effect, average treatment derivative, and partial identification. Our goal is to estimate bounds on the effectiveness of a treatment regime on a population from the observational distribution P and the causal graph G. In the continuous treatment case, where there is no \"on\"/\"off\" notion of treatment, we can compare the average causal effect of an arbitrary treatment (dosage) to the average causal effect at a fixed point T = t0. For example, to indicate the effect relative to not prescribing any treatment, we can choose t0 = 0. This quantity is known as the average treatment effect, average level effect, or average dose effect in the literature on continuous treatment setting [Hirano and Imbens, 2004, Kennedy et al., 2017, Callaway et al., 2021]. Definition 2 (Average Treatment Effect). For SCMM, the average treatment effect (ATE) at T = d w.r.t. a fixed point T = t0 is defined as\nATEM(d) := Eu\u223cPU [YM(T=d)(u)\u2212 YM(T=t0)(u)] (2)\nNote that estimating the ATE and finding bounds on it only depends on the value of the average response function in T = d and T = t0. As pointed in Gunsilius [2020], this quantity can take arbitrary values if we do not make any assumptions on the set of response functions. Here, we assume the partial derivative of the response function w.r.t. the treatment, i.e., \u2202Yt/\u2202t exists and is a bounded continuous function. We then define the average treatment derivative as the following: Definition 3 (Average Treatment Derivative). For the treatment regime fT in SCMM, we define the average treatment derivative (ATD) as\nATDM = Eu\u223cPU [ \u2202YM(T=t)(u)\n\u2202t\n\u2223\u2223\u2223 t=T (u) ] , (3)\nEstimating the ATD can be seen as a proxy for the effectiveness of the prescribed treatment, where we consider the population-level average effect of an infinitesimal increase in the treatment/dosage [Rothenh\u00e4usler and Yu, 2019]. In this work, however, we leverage the regularity of this quantity to achieve smoother solutions to the ATE estimation. We will expand on this in section 4.\nNote that we cannot readily use eq. 2 (or eq. 3) to estimate the ATE (or ATD), as we only have access to the observational distribution P and the causal graph G and not the latent distribution PU. In fact, ATEs are generally non-identifiable, i.e., there exist multiple SCMs with the same causal graph G and generated distribution P that result in different values of ATE. For some graphs, however, one can use non-parametric identification algorithms like do-calculus to identify the causal effect from the observational distribution [Pearl, 2009]. In practice, even for identifiable causal graphs, we cannot pinpoint the true ATE due to the uncertainty caused by sampling variation and finite sample errors. Instead, we are interested in finding a tight set of possible solutions that will contain the true value of ATE (or ATD) with high probability. This is known as the partial identification problem in the literature [Manski, 2003].3 More formally, the partial identification of ATDs/ATEs is defined as: Definition 4 (Partial Identification of ATD/ATE). Partial identification of ATD is the solution to the following optimization problem:\n( min M\u2032\u2208M ATDM\u2032 , maxM\u2032\u2208M ATDM\u2032) s.t. PM\u2032 = P & GM\u2032 = G (4)\nwhere M is the set of all SCMs on random variables V. We denote the solution to the above problem as (ATD,ATD). Similarly, we can define the partial identification of ATEs by replacing ATDM\u2032 with ATEM\u2032(d) in eq. 4. We refer to the solution to the latter problem as (ATE(d),ATE(d)).\nImplicit generative models. To solve the partial identification problem, we use the expressive power of generative models to satisfy the distribution constraint in eq. 4. Choosing distance measures such as Jensen-Shannon divergence or Wasserstein metric results in models such as GANs or Wasserstein GANs (WGANs) [Goodfellow et al., 2014, Arjovsky et al., 2017]. The typical way to implement these models is to solve a minimax game between the generator and a discriminator. However, adding the ATD minimization/maximization term to the minimax loss function will result in unstable training. Instead, in our practical algorithm, we will use Sinkhorn Generative Networks (SGNs) that use Sinkhorn divergence S , a differentiable -approximation of Wasserstein metric, as the distance measure between generated and true samples [Cuturi, 2013, Genevay et al., 2018, Feydy et al., 2019]. Due to the differentiability of Sinkhorn divergence, we will only need to train a generator network enabling us to sidestep much of the unstable minimax training in (W)GANs."
        },
        {
            "heading": "3 Related Work",
            "text": "This work builds upon partial identification and generative causal models.\nPartial identification. Finding informative bounds on treatment effects has been well-studied in the existing literature ([Robins, 1989, Manski, 1990, Evans, 2012, Ramsahai, 2012, Richardson et al., 2014, Miles et al., 2015, Finkelstein et al., 2021, Zhang and Bareinboim, 2021a,b]). Balke and Pearl [1997] find the tightest possible bound for the discrete instrumental variable setting by converting it to a linear programming problem. For the backdoor setting and binary treatments, Makar et al. [2020] provide probabilistic upper/lower bounds on potential outcomes in the finite sample regime. Recently, Zhang et al. [2021] and Duarte et al. [2021] independently describe a polynomial programming approach to solve the partial identification for general causal graphs. They both use the notion of canonical SCMs to map the latent variables to the space of functions from treatment T to outcome Y . Though they show their polynomial programming formulation finds the optimal bound, their approach is only applicable to discrete random variables with small support. In fact, the time complexity of their algorithm grows exponentially with the size of the support set of variables, making their algorithm intractable for continuous settings.\nGunsilius [2019] extends the commonly-used linear programming approach to partial identification of IV graphs with continuous treatments. They use a stochastic process representation of the variables and solve the linear programming via sampling. However, their method suffers from stability issues, as discussed in Kilbertus et al. [2020] and is only applicable for the IV setting. Kilbertus et al. [2020], Padh et al. [2022] parameterize the space of response functions by assuming them as linear combinations of a set of fixed basis functions. Then, they match the first two moments of observed distribution while minimizing/maximizing the ATE. However, they do not provide any theoretical guarantees on the tightness of their derived bounds.\n3In the literature, partial identification is not concerned with sampling uncertainty and is defined populationwise for non-identifiable causal effects. However, in this paper, we abuse the terminology and use partial identification for both non-identifiable quantities and identifiable effects with finite samples.\nMost similar to our work is Hu et al. [2021] who use generative adversarial networks (GANs) to match the observed distribution and search for response functions with maximum/minimum ATEs. They provide convergence guarantees for the instrumental variable causal graph with linear models. Their approach is also based on the minimax game between generator and discriminator, which can result in unstable training. Our work differs in a few important ways. We focus on partial identification of average derivatives and use that to find bounds over the ATE. Using this approach, we show that our derived bounds converge to the optimal bounds for linear SCM with general causal graphs, including both identifiable and non-identifiable settings. We use Sinkhorn divergence, a differentiable approximation of Wasserstein distance, to train our implicit generative models. Empirically, we find that this avoids the unstable training of GANs. Guo et al. [2022] studied the partial identification of ATE with noisy covariates. Their work is similar to our approach in that we both use a similar robust optimization formulation. However, they focus on identifiable causal graphs, where one can use adjustment formulas such as the Back-door formula and make parametric assumptions on the joint distribution of observed variables.\nGenerative causal models. [Goudet et al., 2017, Yoon et al., 2018, Kocaoglu et al., 2018, Sauer and Geiger, 2021] use generative models to capture a causal perspective on evaluating the effect of interventions on high-dimensional data such as images. They do not consider the problem of bounding treatment effects. Xia et al. [2021] introduced Neural Causal Models (NCMs) that leverages the universal approximability of neural networks to learn the SCM. Although it is not generally possible to learn the true SCM by training on the observational data, they prove that NCMs can be used to test the identifiability of causal effects and propose an algorithm to estimate identifiable causal effects. Their work\u2019s theory and empirical instantiation are in the context of discrete random variable datasets. Our work builds upon NCMs for partial identification with both continuous and discrete random variables."
        },
        {
            "heading": "4 Partial Identification using Implicit Generative Models",
            "text": "We explain our method to solve the partial identification problem in Def. 4 using implicit generative models. In subsection 4.1, we describe partial identification of ATDs as a constrained optimization problem using G-constraint generative models [Xia et al., 2021]. Then, in subsection 4.2, we show that the solution to this constrained optimization problem converges to the optimal bounds on the ATD in infinite data samples. We prove our results for linear SCMs with general causal graphs, i.e., both identifiable and non-identifiable settings. Next, we propose our approach to extend the partial identification of ATDs to ATEs. Finally, we describe a practical algorithm to solve our distributionally-constrained optimization problem in subsection 4.3.\n4.1 G-constraint generative models\nTo solve the partial identification problem, we need to search over the set of all possible SCMs M. This is generally not feasible, as there is no constraint on the distribution of the latent variables PU, as well as the function family F . Instead, we parameterize the space of all SCMs that are consistent with causal graph G using neural networks. More specifically, we use G-constraint generative models: Definition 5 (G-constraint Generative Models (Def. 7 in Xia et al. [2021])). For a given causal graph G, a G-constraint generative model is a tupleM\u03b8G = (V, U\u0302,F\u03b8, P\u0302U\u0302), where each Vi \u2208 V is generated from\nVi = f \u03b8 Vi(pa(Vi), U\u0302C) for f \u03b8 Vi \u2208 F \u03b8, (5)\nwhere pa(Vi) is the observed parents of node Vi in G and U\u0302C \u2208 U is the latent noise corresponding to maximalC2-Component C \u2286 V containing node Vi, i.e., each pair of variables in C have common latent parent nodes. In addition, P\u0302U\u0302 \u223c Unif(0, 1) for each U\u0302 \u2208 U\u0302.\nG-constraint generative models make the search over the set M feasible by limiting it to generative models with uniformly distributed latent variables that are consistent with causal graph G. In fact, in their Theorem 3, Xia et al. [2021] show that for any discrete SCMM\u2217 with causal graph G, there exists a G-constrained generative model M\u03b8G that generates the same causal effect, i.e., YM\u2217(T=t) = YM\u03b8G(T=t) a.s. Their proof technique, however, only works for SCMs with discrete variables. Here, we do not prove the expressiveness of G-constrained generative models for continuous\nSCMs. Instead, for simplicity and completeness of our theoretical results in subsection 4.2, we assume that the true SCM is a G-constrained generative model itself. In our experiments, we empirically show that our results hold even for SCMs with different latent distributions, such as Gaussian noise. Assumption 1. The true SCMM is a G-constrained generative model. In other words, there exist \u03b8 such thatM =M\u03b8G .\nUnder Assumption 1, we reformulate the problem in eq. 4 using generative models, i.e.,\n(min \u03b8 ATDM\u03b8G , max\u03b8 ATDM\u03b8G ) s.t. PM\u03b8G = P (6)\nIn practice, we never have access to true distribution P as we only observe a finite number of samples corresponding to the empirical distribution Pn = 1n \u2211n i=1 \u03b4v(i) for a given dataset {v(1), \u00b7 \u00b7 \u00b7 ,v(n)}. Also, the observed variables may be biased due to noisy measurements. Therefore, we reformulate the problem in eq. 6 as a constrained optimization problem. We choose the 1-Wasserstein metric as our distance measure, which naturally results in generative models such as WGANs. We will state our theory in subsection 4.2 based on this metric. However, in subsection 4.3, we will propose a practical algorithm that uses Sinkhorn divergence, a differentiable approximation of 1-Wasserstein distance, for more stable results. Our constrained optimization problem is as follows:(\nmin \u03b8 ATDM\u03b8G ,max\u03b8 ATDM\u03b8G\n) s.t. W1 ( PM\u03b8G , P n ) \u2264 \u03b1n (7)\nwhere \u03b1n is a hyper-parameter that specifies the level of tightness of the bounds. We denote the solution to eq. 7 as ( \u02c6ATD, \u02c6ATD). In the case of noisy measurements, we need domain knowledge of how noisy the data is to determine the value of \u03b1n. Otherwise, we can use the finite-sample convergence rate of empirical Wasserstein distance to choose an appropriate value of \u03b1n [Weed and Bach, 2019]. As our theoretical results are concerned with the infinite-sample case, we will assume that there exist values of \u03b1n such that the true distribution lies within the Wasserstein ball. Assumption 2. For each n \u2208 N, there exist \u03b1n > 0 such that W1(P, Pn) \u2264 \u03b1n."
        },
        {
            "heading": "4.2 Theoretical guarantees and extension to ATEs",
            "text": "Assumptions 1 and 2 ensure that the bound derived by eq. 7 contains the true value of ATD. However, we do not know how informative/tight the derived bounds are. In fact, one can always return (\u2212\u221e,+\u221e) as one solution to partial identification. This part gives theoretical guarantees that our algorithm can result in tight bounds over ATD. In particular, we focus on linear SCMs and show that, under the infinite number of samples, our algorithm converges to the optimal bound (ATD,ATD) for both identifiable and non-identifiable causal graphs. See Appendix A for the proof. Definition 6 (Linear SCMs). SCMM = (V,U,F , PU) is linear, if\nVi = a > Vipa(Vi) + b > ViUVi for vectors aVi ,bVi \u2208 F (8)\nTheorem 1 (Tight Bounds). Assume the dataset {v(1), \u00b7 \u00b7 \u00b7 ,v(n)} is generated from a linear SCM. Then, under assumptions 1, and 2, the solution to the constrained optimization problem in eq. 7 converges to the optimal bound over the ATD in infinite samples, i.e., \u02c6ATD\u2192 ATD and \u02c6ATD\u2192 ATD.\nUp until now, we have only focused on partial identification of ATDs. Here, we discuss how to extend our results to find bounds on ATEs. A naive solution is to replace ATD with ATE in eq. 7 and directly optimize it. However, as demonstrated in the experiments, this approach can result in non-informative bounds. In fact, ATE with continuous treatments is a non-regular quantity [Kennedy et al., 2017].\nInstead, we claim that we can use the same generative model trained for partial identification of ATD to bound the value of ATE. In particular, we define a new objective function by uniform intervention on the treatment, which we call uniform average treatment derivative (UATD), and show that the solution to partial identification of UATD matches the solution to partial identification of ATEs. Definition 7 (UATD). For an SCMM, we define the uniform average treatment derivative (UATD) at interval [t0, d] as\nUATDM[t0, d] := Eu\u223cPU [ Et\u223cUnif[t0,d] [ \u2202Yt(u)\n\u2202t\n]] (9)\nNow, we state our result on using average derivatives to solve partial identification of ATEs: Corollary 1. Let \u03b8\u2217 be the solution to the partial identification of UATD at interval [t0, d]. Then, \u03b8\u2217 is also a solution to the partial identification of ATE(d). If the true SCMM is linear, then the bound is tight, i.e., \u02c6ATE(d)\u2192 ATE(d) and \u02c6ATE(d)\u2192 ATE(d) as n\u2192\u221e.\nThe proof is given in Appendix B.\nRemark. ATD and ATE are generally different quantities and finding bounds on one does not necessarily results in bounds on the other. In fact, ATE is not pathwise differentiable for continuous treatments [D\u00edaz and van der Laan, 2013, Kennedy et al., 2017, Chernozhukov et al., 2018] (See Appendix C). We define UATD as a quantity to relate ATE and ATD. The formal definition of UATD in Def. 7 is the same as ATE up to a scale factor, and one would expect to see similar issues with ATE here as well. Therefore, we approximate UATD with a version that, instead of a uniform distribution of treatment within interval [t0, d] with zero density outside, the treatment distribution has continuous differentiable non-zero density defined over the whole support of T . More concretely,\nATEM\u03b8G (d) \u221d UATDM\u03b8G [t0, d] = Eu\u223cPU\u0302 [\u222b supp(T ) \u2202YM\u03b8G (T = t) \u2202t d\u00b5(t) ]\n\u2248 Eu\u223cPU\u0302 [\u222b supp(T ) \u2202YM\u03b8G (T = t) \u2202t d\u00b5\u0303(t) ] (10)\nwhere \u00b5 is a the uniform measure within interval [t0, d] and \u00b5\u0303 is its approximation with a non-zero density over the full support of T . Choosing \u00b5\u0303 trades off between regularity of the response function and the approximation error. The more \u00b5\u0303 is close to the uniform measure \u00b5, the more irregularity we allow in the response curve and the less informative the bound will be, while the objective function is closer to ATE. Adding more density outside of interval [t0, d] imposes regularity on the response curve (Figure 2). It is important to note that we use the formal definition of UATD (with uniform treatment distribution) in Corollary 1 since, in linear SCMs, it is not possible for the generator model to attain arbitrarily large values in points t0 and d as the derivative of linear functions remains fixed outside of interval [t0, d]. This is why we state our theoretical results based on the uniform intervention."
        },
        {
            "heading": "4.3 Our algorithm",
            "text": "We describe our algorithm to solve the optimization problem in eq. 7. We will focus on finding \u02c6ATD, a similar approach can be taken for \u02c6ATD. A general strategy is to convert the constrained problem to its unconstrained version using the method of Lagrange multiplier:\nmin \u03b8 max \u03bb\u22650 ATDM\u03b8G + \u03bb(W1(PM\u03b8G , P n)\u2212 \u03b1n) (11)\nAs the Wasserstein distance is not differentiable, we cannot directly use gradient descent to solve eq. 11. A common approach is to use the dual formulation of Wasserstein distance W1(PM\u03b8G , P n) = max||q\u03c6||L\u22641 EPn [q\u03c6(v)]\u2212 EPM\u03b8G [q\u03c6(v)] and solve eq. 11 using WGANs, a similar solution used\nin Hu et al. [2021]. However, this min-max-max formulation can result in unstable bounds as we show in our experiments. Instead, we use Sinkhorn divergence, a differentiable approximation to Wasserstein distance, as the measure of distance between distributions and solve the following:\nmin \u03b8 max \u03bb\u22650 ATDM\u03b8G + \u03bb(S (PM\u03b8G , P n)\u2212 \u03b1n) (12)\nTo solve eq. 12, we need to evaluate ATDM\u03b8G and calculate its gradient w.r.t. \u03b8. As we are using G-constrained generative models, we can calculate the value of YM\u03b8G(T=t)(u) by hard intervention T = t, i.e., fixing the output of function f\u03b8T as t and computing Y through a topological order of calculations. Then, we estimate ATDM\u03b8G as follows:\nATDM\u03b8G \u2248 1\nn n\u2211 i=1 1 [ YM\u03b8G(T=t(i)+ )(u (i))\u2212 YM\u03b8G(T=t(i))(u (i)) ]\n(13)\nwhere {t(i)}ni=1 are samples from the treatment variable, and {u(i)}ni=1 are the latent variables generated from a uniform distribution. To choose an appropriate value of \u03b1n, we first train our generator without the ATD term until the Sinkhorn loss converges to some value and use that as our choice of \u03b1n. We then continue our training by adding the ATD term.\nWe note that using algorithms such as projected gradient descent to solve the constrained optimization problem requires us to project the weights of our network into the Wasserstein (Sinkhorn) ball in each step. This can be computationally infeasible, and current methods are mainly focused on special loss functions [Mohajerin Esfahani and Kuhn, 2018, Li et al., 2019, Wong et al., 2019]. Instead, we consider an alternating optimization procedure, in which we alternate between updating the gradients for the ATD and the Sinkhorn loss. The full details of our algorithm, its extension to ATEs, and the alternating optimization are described in Appendix D."
        },
        {
            "heading": "5 Experiments",
            "text": "We run our partial identification algorithms on a variety of simulated settings. We mainly focus on the synthetic data generating processes as the ground truth must be known to evaluate our derived bounds properly. Our primary goal is to show that using uniform average treatment derivatives instead of directly optimizing the average treatment effect will result in tighter and more stable bounds. We first run our algorithm to estimate bounds on the value of ATDs for both identifiable and non-identifiable causal graphs. We show that, as the number of samples increases, our algorithm converges to tight bounds over the true value of ATD (Figure 3). We then focus on partial identification of ATEs and demonstrate that using partial derivatives of the response function leads to more informative bounds, while being valid (Figures 4a, 4b).\nAdditionally, as a sanity check, we consider two binary-treatments datasets where the optimal bounds are known and show that our approach can reach the optimal solution. We also test our method on an ACIC dataset, a case study with real-world covariates, to illustrate the performance of our algorithm on higher-dimensional datasets. We include these additional experiments in Appendix E. Our implementation details, as well as hyper-parameters can be found in Appendix F."
        },
        {
            "heading": "5.1 Datasets and Baseline",
            "text": "Datasets. We consider various data generating processes for different causal graphs, including a linear SCM with three-dimensional covariates and a quadratic SCM with nonlinear interaction between\n\u22126 \u22124 \u22122 0 2 \u221238\n\u22120.5\n37\n\u22126 \u22124 \u22122 0 2 \u221225\n\u22123.5\n18\n\u221215 \u221210 \u22125 0 5 \u221265\n34\n133\n\u22124 \u22122 0 2 \u2212208\n\u221219\n170\nTreatment, T\nTa rg\net ,Y\nE[Yt]\u2212 E[Yt0 ] Our Bounds GAN Bounds Real samples\n(a) GAN baseline. (top left) Nonlinear Back-door, (top right) linear IV, (bottom left) nonlinear IV, and (bottom right) leaky mediation settings. t0 is chosen as the maximum treatment value in each data. Our derived bounds are tighter and more stable than the GAN baseline, which directly optimizes the ATE.\n\u22125 0 5 10\n\u221250\n0\n50\n\u22125 0 5 10\n\u221250\n0\n50\n100\nTreatment, T\nTa rg\net ,Y\nE[Yt]\u2212 E[Yt0 ] Our Bounds Padh et al. Samples\n(b) Padh et al. [2022]. (left) Nonlinear IV, (right) linear IV with strong confounding. t0 is chosen as the minimum treatment value in each data. While resulting in tighter bounds in the linear setting, the baseline leads to invalid bounds in the nonlinear dataset.\nFigure 4: Comparing our results for partial identification of E[Yt]\u2212E[Yt0 ] for 10 different values of treatment.\nthe covariates and treatment for the Back-door causal graph (Figure 1c), as well as a nonlinear SCM for the Front-door setting (Figure 1d). For the IV graph (Figure 1b), we use four different SCMs, two linear and two nonlinear datasets, based on the strength of the instrument variable and the confounding. Finally, we generate a two-dimensional linear dataset for the leaky mediation causal graph (Figure 1a). The full details of our data-generating processes can be found in Appendix G.\nBaselines. Our first baseline is the algorithm in Hu et al. [2021] that directly optimizes the value of ATE using GANs. We use their default hyper-parameters with a tolerance of 0.0001. Similar to their experimental setup, we consider 50 intermediate solutions where the distance is within the tolerance and compute the bounds using the mean and one-sided confidence intervals.\nWe also compare our algorithm with the moment-matching method in Padh et al. [2022]. They parameterize the first two moments of the generated distribution and match them with the observed samples. They choose response functions as linear combinations of a fixed number of basis functions. We consider the neural basis functions for our experiments with their default hyper-parameters. In particular, we train a 3-hidden layer MLP with 64 neurons in each layer to learn the target variable given the treatment. We then use the activation of the kth neuron in the last hidden layer as the kth basis function. Instead of maximizing/minimizing E[YT=t], we consider E[YT=t] \u2212 E[YT=t0 ] as our goal is to bound the ATE between two points. We leave other implementation details untouched."
        },
        {
            "heading": "5.2 Results",
            "text": "Bounding average treatment derivatives. We generate data with sample sizes N = {500, 1000, 2000, 5000} from the nonlinear Front-door and linear Back-door SCMs (identifiable), as well as linear IV with strong confounding and leaky mediation settings (non-identifiable). We run our algorithm with ten different random seeds for each setting/sample size. Then, we choose\nthe five runs with the lowest tolerance parameter \u03b1n and choose the upper (lower) bound as the maximum (minimum) value of the ATD within these five runs. Figure 3 shows our derived bounds. As expected, the algorithm is able to point-identify the value of ATD for identifiable scenarios as the number of samples increases (Figures 3 (a) and (b)). In non-identifiable cases, our algorithm leads to tight bounds containing the true value of ATD by increasing the number of samples as depicted in Figures 3 (c) and (d). This is in line with our results in Theorem 1.\nBounding average treatment effects. Here, we aim to demonstrate the effectiveness of using partial derivatives for bounding the ATE compared to the direct optimization approach. We consider six different settings and run our algorithm for 10 different values of treatment {ti}10i=1 in each setting. We compute the value of ATE w.r.t. a fixed point t0. For each value of T , we generate N = 5,000 samples and run each experiment five times. Then, we select the maximum (minimum) value of ATE within the five runs as the upper (lower) bound. We follow the same procedure for the baselines.\nTo find the bounds on ATE using our approach, we sample from a distribution with uniform density within [t0, ti] and Gaussian tails outside of [t0, ti], and maximize/minimize the partial derivatives. Figure 4a shows the effectiveness of this approach in comparison to the GAN baseline. Our algorithm produces stable and tight bounds containing the true value of ATE, while the GAN baseline, which relies on the direct optimization of ATEs, results in unstable loose bounds that may not include the true value of the treatment effect.\nFigure 4b compares our algorithm with the method in Padh et al. [2022]. First, we find that their method do not contain the actual response curve in the nonlinear IV setting (left). This is not a surprising result; since they consider a fixed set of basis functions, the set of possible response curves is more restricted than ours. If the basis functions are not carefully designed to capture the true form of the response curve, the resulting bounds can be invalid, thus not containing the actual value of ATE even if there are regimes where the approach provides a tighter fit. On the other hand, our approach considers a larger family of response functions, enabling us to both capture shape and variation in the response curve while bounding the effects."
        },
        {
            "heading": "6 Conclusion, Limitations and Future Work",
            "text": "Our work introduces a novel method to estimate bounds on average treatment effects from observational data. Specifically, we propose optimizing the average treatment derivative, which in turn can be used to estimate the average treatment effect in treatment response curves. Empirically we find that the use of our method recovers known bounds on treatment effects in the discrete case and outperforms other methods based on implicit models for partial identification in the continuous case.\nThere remain several limitations of this work. Our work builds on the constrained optimization problem defined by Xia et al. [2021] instantiated in the context of the ATD. Developing new methods for function maximization/minimization approaches under distributional constraints remains an important direction for future work. Our work primarily uses carefully designed synthetic datasets to evaluate our method under different constraints on the data distribution. A larger-scale evaluation of our approach on real-world benchmarks will better help us assess the method\u2019s practicality. Moreover, the theory of our work is restricted to the linear SCM scenario. We have also made regularity assumptions throughout the paper, including Assumption 1, that the true SCM can be modeled using implicit generative models with uniform confounding distribution, as well as the approximation of UATD with regular treatment distributions. Consequently, practitioners must exercise caution when deploying this method when there are nonlinear or irregular structures among the random variables. Finally, we have stated our results (Theorem 1 and Corollary 1) without quantifying the finite-sample estimation uncertainty. One can use the existing theory of finite-sample convergence of empirical Wasserstein distance in Weed and Bach [2019] to extend our results with high-probability bounds."
        },
        {
            "heading": "Acknowledgments",
            "text": "We thank Tom Ginsberg and Michael Cooper for many helpful discussions. We also thank David Alvarez Melis for his suggestion on using Sinkhorn divergence instead of Wasserstein distance. This research was supported by NSERC Discovery Award RGPIN-2022-04546 and a CIFAR AI Chair. Resources used in preparing this research were provided, in part, by the Province of Ontario, the Government of Canada through CIFAR, and companies sponsoring the Vector Institute."
        },
        {
            "heading": "A Proof of Theorem 1",
            "text": "Here, we only focus on the minimization problem, i.e., \u02c6ATD \u2192 ATD. The proof of \u02c6ATD \u2192 ATD will similarly follow.\nAssumptions\nBefore stating our proof, we list the assumptions needed as follows. These are mainly technical assumptions that will simplify the derivations.\n1. In this proof we assume all random variables are one-dimensional. 4\n2. Since the true SCMM is G-constrained (Assumption 1) and linear, we will consider linear G-constrained SCMs as our parameter search space. More concretely, each random variable Vi in an SCMM\u03b8G can be written in the following form:\nVi = \u03b8 > Vipa(Vi) + \u03b8\u0302 > ViU\u0302Ci (14)\nwhere \u03b8Vi \u2208 R|pa(Vi)|, \u03b8\u0302Vi \u2208 R|U\u0302Ci |, and \u03b8 \u2208 \u0398 is the concatenation of all \u03b8Vi , \u03b8\u0302Vi in a topological order of Vis. Note that \u03b8 \u2208 R|E|, where E is the set of edges in the causal graph G, containing edges to both observed and unobserved random variables.\n3. We assume the set of feasible parameters \u0398 is a bounded closed subset of R|E|. In practice, even in non-identifiable cases with infinite bounds, we use regularization to ensure the parameters of the network are bounded.\n4. The induced probability over observed random variables PM\u03b8G , which we will write as P\u03b8, and the true distribution P belong to the Wasserstein space of order p = 1, which we refer to as P1. In other words, \u222b Rd |v0 \u2212 v| dP\u03b8(v) < +\u221e for any arbitrary point v0 \u2208 R\nd. Again, in practice, since the support of all observed random variables is bounded, all probability distributions defined on them belong to the Wasserstein space.\nBefore the main proof, we will state and prove the following useful lemmas. Lemma 1. Let define the set of feasible parameters for n number of samples as \u0398n = {\u03b8 \u2208 \u0398; W1(PM\u03b8G , P n) \u2264 \u03b1n}. Then, PM\u03b8nG \u2192 P weakly for every sequence of \u03b8 n \u2208 \u0398n.\nProof. First, note that the empirical distribution Pn weakly converges to P as n \u2192 \u221e. Since W1 metrizes P1, we have W1(Pn, P )\u2192 0 [Villani, 2009]. Hence, we can choose the sequence of \u03b1n for the distributional constraint, such that W1(P, Pn) \u2264 \u03b1n and \u03b1n \u2192 0 as n\u2192\u221e. For any parameter \u03b8n \u2208 \u0398n, we have W1(PM\u03b8nG , P n) \u2264 \u03b1n}. Therefore, W1(PM\u03b8nG , P n) \u2192 0. Using the triangle inequality, we have\nW1(PM\u03b8nG , P ) \u2264W1(PM\u03b8nG , P n) +W1(P n, P ) (15)\nTherefore, W1(PM\u03b8nG , P )\u2192 0 or equivalently, PM\u03b8nG \u2192 P weakly.\nLemma 2. For any linear G-constrained SCMM\u03b8G , we have\nV\u03b8 = A(\u03b8)U\u0302 (16)\nwhere each element in the matrix A(\u03b8) \u2208 Rd\u00d7|dim(U\u0302)| is a continuous function of \u03b8.\nProof. Consider a topological order of observed variables (V1, \u00b7 \u00b7 \u00b7 , Vd). We prove the result by induction. For V1, from eq. 14, we have\nV1 = 0 + \u03b8\u0302 > V1U\u0302C1 = \u03c6 > V1U\u0302 (17)\n4For high-dimensional variables, if the node-level causal graph is given, i.e., the relation between each dimension of variables, we can convert each multi-dimensional variable to multiple one-dimensional ones and follow the same proof. If the node-level causal graph is unknown and there is no inter-dependence between each dimension, one can follow the same proof technique by assuming Vi as a vector in eq. 14. We leave these extensions as future work.\nwhere the elements of \u03c6V1 matches \u03b8\u0302V1 for U\u0302C1 and equal to zero for U\u0302\\U\u0302C1 . Now, assume all variables V1, \u00b7 \u00b7 \u00b7 , Vd\u22121 can be written as \u03c6>ViU\u0302, where \u03c6Vi is a continuous function of \u03b8. Then, from eq. 14,\nVd = \u03b8 > Vd pa(Vd) + \u03b8\u0302 > Vd U\u0302Cd = \u03b8 > Vd (\u03c6>pa1(Vd)U\u0302, \u00b7 \u00b7 \u00b7 ,\u03c6 > par(Vd) U\u0302)> + \u03b8\u0302>VdU\u0302Cd = \u03c6 > Vd U\u0302 (18)\nwhere \u03c6Vd is a linear function of \u03b8Vd ,\u03c6V1 , \u00b7 \u00b7 \u00b7 ,\u03c6Vd\u22121 , and \u03b8\u0302Vd . Defining matrix A(\u03b8) with rows \u03c6Vi concludes the proof.\nNow, we are ready to prove the main result.\nTheorem 2 (Tight Bounds). Assume the dataset {v(1), \u00b7 \u00b7 \u00b7 ,v(n)} is generated from a linear SCM. Then, under assumptions 1, and 2, the solution to the constrained optimization problem in eq. 7 converges to the optimal bound over the ATD in infinite samples, i.e., ( \u02c6ATD, \u02c6ATD)\u2192 (ATD,ATD).\nProof. The goal is to show the solution to\nmin \u03b8\u2208\u0398 ATDM\u03b8G s.t. W1 ( PM\u03b8G , P n ) \u2264 \u03b1n (19)\nconverges to the solution to min \u03b8\u2208\u0398 ATDM\u03b8G , s.t. PM\u03b8G = P (20)\nas n \u2192 \u221e. We first aim to re-write the value of ATD. Note that, in a linear G-constrained SCM, the partial derivative \u2202YM\u03b8G(T=t) (u)\n\u2202t is only a function of SCM parameters \u03b8. Let define\ng(\u03b8) = \u2202YM\u03b8G(T=t) (u)\n\u2202t . Then, ATDM\u03b8G = \u222b\n\u2126\n\u2202YM\u03b8G(T=t)(u)\n\u2202t\n\u2223\u2223\u2223 t=T (u) dPU\u0302(u) = \u222b \u2126 g(\u03b8) dPU\u0302(u) = g(\u03b8) (21)\nTherefore, we need to show the following to conclude the proof:\nmin \u03b8n\u2208\u0398n g(\u03b8n)\u2192 min \u03b8\u221e\u2208\u0398\u221e\ng(\u03b8\u221e) (22)\nwhere\n\u0398n = {\u03b8 \u2208 \u0398; W1(P\u03b8, Pn) \u2264 \u03b1n} \u0398\u221e = {\u03b8 \u2208 \u0398; P\u03b8 = P} = {\u03b8 \u2208 \u0398; W1(P\u03b8, P ) = 0} (23)\nSince \u0398\u221e \u2286 \u0398n for each n \u2208 N, we know that min \u03b8n\u2208\u0398n g(\u03b8n) \u2264 min \u03b8\u221e\u2208\u0398\u221e g(\u03b8\u221e) (24)\nIt is sufficient to show that, for each > 0, there is n0 such that for all n > n0 we have\nmin \u03b8n\u2208\u0398n g(\u03b8n) \u2265 min \u03b8\u221e\u2208\u0398\u221e\ng(\u03b8\u221e)\u2212 (25)\nSuppose this is not true, i.e., there exists > 0 such that for each n \u2208 N we have min \u03b8n\u2208\u0398n g(\u03b8n) < g(\u03b8\u221e)\u2212 (26)\nfor all \u03b8\u221e \u2208 \u0398\u221e. Let \u03b8n? = arg min\u03b8\u2208\u0398n g(\u03b8). The sequence (\u03b8n? )n\u2208N is a subset of \u0398 and therefore is a bounded sequence in R|E|. Thus, by Bolzano-Weierstrass theorem, there exists a convergent sub-sequence (\u03b8ni? )i\u2208N that converges to some fixed parameter \u03b80. Also, \u03b80 \u2208 \u0398 as \u0398 is closed. Now, since g is continuous, we have\ng(\u03b80) = lim i\u2192\u221e\ng(\u03b8ni? ) \u2264 g(\u03b8\u221e)\u2212 (27)\nfor all \u03b8\u221e \u2208 \u0398\u221e. Hence, \u03b80 6\u2208 \u0398\u221e.\nOn the other hand, using Lemma 2, we have V\u03b8ni? = A(\u03b8 ni ? )U\u0302. Since A(\u03b8 ni ? ) is a continuous function of \u03b8ni? , from the continuous mapping theorem, we have P\u03b8ni? \u2192 P\u03b80 weakly. Also, from Lemma 1, we have P\u03b8ni? \u2192 P . Therefore, P = P\u03b80 . Since \u03b80 \u2208 \u0398, we conclude that \u03b80 \u2208 \u0398\n\u221e, a contradiction.\nRemark. In this proof, we did not separate identifiable and non-identifiable cases. In fact, the notion of identifiability can be seen as a property of the set of feasible parameters \u0398n and \u0398\u221e. For example, in identifiable cases, we expect the set \u0398\u221e to only contain one element while in non-identifiable cases, it consists of multiple possible solutions. Our proof holds as long as \u0398n and \u0398\u221e are bounded subsets of R|E|."
        },
        {
            "heading": "B Proof of Corollary 1",
            "text": "Similar to the proof of Theorem 1, define the set of feasible parameters as \u0398n = {\u03b8 \u2208 \u0398 W1(PM\u03b8G , P n) \u2264 \u03b1n}. Then,\nATEM\u03b8G (d) = Eu\u223cPU\u0302 [ YM\u03b8G(T=d)(u)\u2212 YM\u03b8G(T=t0)(u) ] = Eu\u223cPU\u0302 [\u222b d t0 \u2202YM\u03b8G(T=t) \u2202t dt ]\n= (d\u2212 t0) \u00b7 Eu\u223cPU\u0302 [\u222b d t0 \u2202YM\u03b8G(T=t) \u2202t 1 d\u2212 t0 dt ]\n= (d\u2212 t0) \u00b7 Eu\u223cPU\u0302 [ Et\u223cUnif[t0,d] [ \u2202YM\u03b8G(T=t)\n\u2202t ]] = (d\u2212 t0) \u00b7 UATDM\u03b8G [t0, d] (28)\nTherefore, \u03b8\u2217 = arg min\n\u03b8\u2208\u0398n UATDM\u03b8G [t0, d] = arg min\u03b8\u2208\u0398n (d\u2212 t0) \u00b7 UATDM\u03b8G [t0, d] = arg min\u03b8\u2208\u0398n ATEM\u03b8G (d) (29)\nFor the second part, similar to the proof of Theorem 1, we have \u2202YM\u03b8G(T=t)\n\u2202t = g(\u03b8) for some continuous function g. Then,\nATEM\u03b8G (d) eq. 28 = (d\u2212 t0) \u00b7 Eu\u223cPU\u0302 [ Et\u223cUnif[t0,d] [ \u2202YM\u03b8G(T=t)\n\u2202t\n]] = (d\u2212 t0) \u00b7 g(\u03b8) (30)\nThe rest of the proof can be directly derived from the proof of Theorem 1."
        },
        {
            "heading": "C ATE and ATD",
            "text": "Here, we provide more intuition on the difference between ATE and ATD. Consider a simple setting with only two random variables T and Y , where the causal graph is T \u2192 Y . Here, the average treatment effect is identifiable and can be computed (with infinite samples) using the following formula:\nATEM(d) = EP [Y |T = d]\u2212 EP [Y |T = t0] (31)\nNow, assume we have a finite dataset D = {(t(1), y(1)), \u00b7 \u00b7 \u00b7 , (t(n), y(n))}, where t(i) 6= t0 and t(i) 6= d for all i \u2208 [n]. One way to find a (high probability) upper bound on the value of ATE is to solve the following direct optimization:\nmax \u03b8 ATEM\u03b8G (d) s.t. W1(PM\u03b8G , P n) \u2264 \u03b1n (32)\nWith no assumption on the regularity of the response functions YM\u03b8G(T=t), it is possible to find a solution to eq. 32 that matches all points in D, i.e., W1(PM\u03b8G , P\nn) = 0, while getting arbitrarily values of ATEM\u03b8G (d). See Figure 5 for a demonstration. This shows that ATE, in the continuous treatment setting with finite number of samples, is not well-behaved and it is generally impossible to find informative non-parametric bounds on that (see also Gunsilius [2020]). On the other hand, ATD, which is the average partial derivative of response function w.r.t. the observed treatment distribution is defined globally over the support of T . Therefore, it is not possible to maximize ATD arbitrarily without violating the distributional constraint in this setting."
        },
        {
            "heading": "D Algorithm",
            "text": "Algorithm 1 Partial Identification of Average Treatment Derivatives Input: Dataset D = {X(i), T (i), Y (i)}Ni=1, causal graph G, Sinkhorn approximation parameter , learning rate \u03b3, Lagrange learning rate \u03b3L Output: \u02c6ATD: lower bounds on ATD . The algorithm to find \u02c6ATD is similar Phase 1: Matching Distributions 1: InitializeM\u03b8(0)G and i = 0 2: while S (D\u0302,D) not converged do . Train the model to approximate the observed distribution. 3: D\u0302 \u2190 {X\u0302(j), T\u0302 (j), Y\u0302 (j)}Nj=1 \u223cM\u03b8 (i)\nG . Generate dataset from the trained SCM 4: \u03b8(i+1) \u2190 \u03b8(i) \u2212 \u03b3\u2207\u03b8S (D\u0302,D) 5: i\u2190 i+ 1 6: end while 7: \u03b1\u2190 S (D\u0302,D) . Set the distributional constraint level to the minimum Sinkhorn loss\nPhase 2: Joint Optimization Phase 8: Initialize Lagrange multiplier \u03bb(0) and j = 0 9: while ATDM\u03b8(i+j)G\nnot converged do 10: ATDM\u03b8(i+j)G\n\u2190 calculate ATD using eq. 13 11: # Alternate optimization 12: \u03b8\u0304(i+j) \u2190 \u03b8(i+j) \u2212 \u03b3\u2207\u03b8ATDM\u03b8(i+j)G . Update the parameters to minimize the ATD 13: D\u0302 \u2190 {X\u0302(k), T\u0302 (k), Y\u0302 (k)}Nk=1 \u223cM\u03b8\u0304 (i+j)\nG 14: \u03b8(i+j+1) \u2190 \u03b8\u0304(i+j) \u2212 \u03b3\u2207\u03b8S (D\u0302,D) . Update the parameters to minimize the Sinkhorn loss 15: # Lagrange multiplier update"
        },
        {
            "heading": "16: \u03bb(j+1) \u2190 \u03bb(j) + \u03b3L(S (D\u0302,D)\u2212 \u03b1)",
            "text": "17: j \u2190 j + 1 18: end while 19: return ATDM\u03b8(i+j)G\nExtension of Algorithm 1 to ATEs. We can use a similar method to Algorithm 1 for partial identification of average treatment effects (ATEs). The only difference is that, instead of maximizing/minimizing ATDM\u03b8G , we optimize for the value of UATDM\u03b8G [t0, d]. More concretely, we use the following approximation to estimate UATDM\u03b8G [t0, d]:\nUATDM\u03b8G [t0, d] \u2248 1\nn n\u2211 i=1 1 [ YM\u03b8G(T=t(i)+ )(u (i))\u2212 YM\u03b8G(T=t(i))(u (i)) ]\n(33)\nwhere {t(i)}ni=1 are samples from a uniform distribution within [t0, d] with a Gaussian tail, and {u(i)}ni=1 are the latent variables generated from a uniform distribution. Note that, the only difference between eq. 33 and eq. 13 is the distribution of treatment variables, where in the former we use a uniform distribution with Gaussian tail, while the latter uses the same distribution of treatments in the observed dataset. In our experiments, for the uniform distribution with Gaussian tail, we generate samples from N (\u00b5, \u03c3), where \u00b5 = t0+d2 and \u03c3 = d\u2212t0 2 . Then, for each sample within [t0, d], we generate a new sample from uniform distribution Unif[t0, d]."
        },
        {
            "heading": "E Additional Experiments",
            "text": "E.1 Discrete Setting\nTo showcase the generality of our framework, we study two datasets with binary treatments. We consider the binary IV dataset described in Duarte et al. [2021], where the true value of ATE is not identifiable, but the optimal bound is known. We also use the Front-door binary dataset in Zhang et al. [2021] where the causal effect is identifiable (See Appendix G). Here, the partial derivatives do not exist, so we directly optimize the ATE. Note that, in the discrete setting, the network cannot generate arbitrary large values in the intervention points without violating the distributional constraint. Table 1 shows our derived bounds and compares them to the optimal bounds. In the identifiable Front-door causal graph, we find a tight bound over the true ATE. In the non-identifiable IV setting, our bound includes the optimal bound with a small gap.\nE.2 ACIC Dataset\nTo demonstrate the applicability of our method on datasets with higher-dimensional covariates, we consider the Atlantic Causal Inference Conference (ACIC) 2019 Data Challenge [Gruber et al., 2019]. The dataset is constructed based on the spam detection data from UCI [Dua and Graff, 2017]. The outcome of interest Y is whether an email is marked as spam or not. The treatment variable T is also a binary variable showing if the number of capital letters in an email exceeds a threshold. There are 22 continuous covariates that correspond to certain word frequencies.\nWe follow a similar setup as in Guo et al. [2022]. In particular, we consider the problem of partial identification under noisy measurements. Here, the data-generating causal graph is the Back-door setting, and the causal effect of T on Y is identifiable. However, we assume measurement error on the covariates by imposing synthetic noise on them and aim to estimate bounds on ATE under this uncertainty. Since our algorithm can incorporate uncertainty through the distributional constraint, it will lead to a valid and informative bound by choosing an appropriate value for \u03b1n.\nWe generate a dataset of 2,000 samples using ACIC\u2019s data-generating process. Similar to Guo et al. [2022], we synthetically add five different levels of Gaussian noise with mean \u2208 (0.1, 0.2, 0.3, 0.4, 0.5) and standard deviation \u2208 (0.5, 0.5, 1, 1, 1). We then run our algorithm on these five noisy datasets and the original noiseless one, 10 different trials for each. Figure 6 illustrates our derived bounds and the true ATE for each of the noise levels. The results always include the actual value of ATE, while not being too conservative. As the noise level increases, our derived bounds get naturally less informative. 5\nF Implementation Choices\nWe use similar neural network architectures for each variable in the causal graph. For hyper-parameter tuning, we search over networks with {2, 3, 5} hidden layers, {16, 64, 256} neurons in each layer,\n5We heuristically choose the value of hyper-parameter \u03b1n by multiplying the minimum Sinkhorn divergence by factors of (1.2, 1.3, 1.5, 1.6, 1.7) for the noise levels, respectively.\nlearning rate within {0.001, 0.005, 0.01}, and Lagrange multiplier learning rate {0.5, 1}. The hyperparameters with the lowest Sinkhorn loss are chosen for each causal graph. We run all experiments for 500 epochs and use all samples (N = 5000) in each iteration. To find the level of distribution constraint \u03b1n, we minimize the Sinkhorn loss and check the loss value on a validation set until it does not decrease for 30 epochs. We then choose the minimum value of Sinkhorn loss on the training data as \u03b1n. We use an alternate optimization approach to maximize/minimize the ADE (or ATE). In each step, we first minimize the Sinkhorn loss and then maximize/minimize the value of ADE. We use gradient clipping for the ADE optimizer with the value of 0.2. The learning rate of the ADE optimizer is half the learning rate for the Sinkhorn loss optimizer. To find the upper (lower) bounds on ATD/ATE, we find their maximum (minimum) value within all steps that satisfy the distributional constraint. All implementation is done in PyTorch Lightning using Adam optimizer. To evaluate and calculate gradients of Sinkhorn loss, we use the \"geomloss\" library [Feydy et al., 2019]. 6"
        },
        {
            "heading": "G Data Generating Processes",
            "text": "Linear Back-door.\nX \u223c N (2, 1) T \u223c 0.1X2 \u2212X +N (1, 2) Y \u223c 0.5T 2 \u2212 TX +N (0, 2) (34)\nNonlinear Back-door.\nX1, X2, X3 \u223c N (1, 1) T \u223c X1 \u2212X2 + 2X3 + 2 +N (0, 3) Y \u223c 3X1 +X2 \u2212 0.5X3 + 3T +N (0, 2) (35)\nFront-door.\nU \u223c N (\u22121, 1) T \u223c U +N (2, 2) X \u223c 2T +N (1, 2) Y \u223c 0.25X2 \u2212X + U +N (0, 2) (36)\nLinear IV (weak instrument, strong confounding).\nZ1 \u223c N (\u22121, 1) Z2 \u223c N (0, 1) U \u223c N (0, 1) T \u223c Z1 \u2212 Z2 + 0.5U +N (0, 1) Y \u223c 0.5T \u2212 3U +N (0, 1) (37)\n6https://www.kernel-operations.io/geomloss/\nNonlinear IV (strong instrument, weak confounding).\nZ1 \u223c N (\u22121, 1) Z2 \u223c N (0, 1) U \u223c N (0, 1) T \u223c 3Z1 + 1.5Z2 + 0.5U +N (0, 1) Y \u223c 0.3T 2 \u2212 1.5T + U +N (0, 1) (38)\nLeaky Mediation.\nU1 \u223c N (1, 1) U2 \u223c N (\u22121, 1) C \u223c N (0, 1) T \u223c C +N (0, 1) X1 \u223c T + U1 +N (0, 1) X2 \u223c 2T + U2 +N (0, 1) Y \u223c \u22121.5X1 + 2X2 + U1 + U2 + C +N (0, 1) (39)\nBinary IV [Duarte et al., 2021]. We use the noncompliance IV dataset in Section D.1 from Duarte et al. [2021]. The true value of ATE is \u22120.25 while the optimal bound is [\u22120.55,\u22120.15]. Binary Front-door [Zhang et al., 2021].\nU1 \u223c Unif(0, 1) U2 \u223c N (0, 1) T \u223c Binomial(1, U1)\nW \u223c Binomial(1, 1 1 + exp(\u2212T \u2212 U2) )\nY \u223c Binomial(1, 1 1 + exp(W \u2212 U1) ) (40)\nLinear IV with strong confounding [Padh et al., 2022].\nZ \u223c N (0, 1) U \u223c N (0, 1) T \u223c 0.5Z + 3U +N (0, 1) Y \u223c T \u2212 6U +N (0, 1) (41)\nNonlinear IV with nonlinear interaction between treatment and confounding [Padh et al., 2022].\nZ \u223c N (0, 1) U \u223c N (0, 1) T \u223c 3Z + 0.5U +N (0, 1) Y \u223c 0.3T 2 \u2212 1.5TU +N (0, 1) (42)"
        }
    ],
    "title": "Partial Identification of Treatment Effects with Implicit Generative Models",
    "year": 2022
}