{
    "abstractText": "Fair division provides a rich computational and mathematical framework for the allocation of indivisible goods, which has given rise to numerous fairness concepts and their relaxations. In recent years, much attention has been given to theoretical and computational aspects of various fairness concepts. Nonetheless, the choice of which fairness concept is in practice perceived to be fairer by individuals is not well understood. We consider two conceptually different relaxations of envy-freeness and investigate how individuals perceive the induced allocations as fair. In particular, we examine a well-studied relaxation of envy-freeness up to one good (EF1) which is based on counterfactual thinking that any pairwise envy can be eliminated by the hypothetical removal of a single good from the envied agent\u2019s bundle. In contrast, a recently proposed epistemic notion, namely envy-freeness up to k hidden goods (HEF-k), provides a relaxation by hiding information about a small subset of k goods. Through various crowdsourcing experiments, we empirically demonstrate that allocations achieved by withholding information are perceived to be fairer compared to two variants of EF1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Hadi Hosseini"
        },
        {
            "affiliations": [],
            "name": "Joshua Kavner"
        },
        {
            "affiliations": [],
            "name": "Sujoy Sikdar"
        },
        {
            "affiliations": [],
            "name": "Rohit Vaish"
        },
        {
            "affiliations": [],
            "name": "Lirong Xia"
        }
    ],
    "id": "SP:a590bb7927ab6544889551baf0752c851b88a750",
    "references": [
        {
            "authors": [
                "J Stacy Adams"
            ],
            "title": "Towards an understanding of inequity",
            "venue": "Journal of Psychopathology and Clinical Science,",
            "year": 1963
        },
        {
            "authors": [
                "Georgios Amanatidis",
                "Georgios Birmpas",
                "Aris Filos-Ratsikas",
                "Alexandros A Voudouris"
            ],
            "title": "Fair Division of Indivisible Goods: A Survey",
            "venue": "In Proceedings of the 31st International Joint Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Haris Aziz",
                "Sylvain Bouveret",
                "Ioannis Caragiannis",
                "Ira Giagkousi",
                "J\u00e9r\u00f4me Lang"
            ],
            "title": "Knowledge, Fairness, and Social Constraints",
            "venue": "In Proceedings of the 32nd AAAI Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Haris Aziz",
                "Bo Li",
                "Herve Moulin",
                "Xiaowei Wu"
            ],
            "title": "Algorithmic Fair Allocation of Indivisible Items: A Survey and New Questions",
            "venue": "In ACM SIGecom Exchanges,",
            "year": 2022
        },
        {
            "authors": [
                "Felix Brandt",
                "Vincent Conitzer",
                "Ulle Endriss",
                "J\u00e9r\u00f4me Lang",
                "Ariel D Procaccia"
            ],
            "title": "Handbook of Computational Social Choice",
            "year": 2016
        },
        {
            "authors": [
                "Eric Budish"
            ],
            "title": "The Combinatorial Assignment Problem: Approximate Competitive Equilibrium from Equal Incomes",
            "venue": "Journal of Political Economy,",
            "year": 2011
        },
        {
            "authors": [
                "Tapabrata Chakraborti",
                "Arijit Patra",
                "J Alison Noble"
            ],
            "title": "Contrastive Fairness in Machine Learning",
            "venue": "IEEE Letters of the Computer Society,",
            "year": 2020
        },
        {
            "authors": [
                "Jacob Cohen"
            ],
            "title": "Statistical power analysis",
            "venue": "Current Directions in Psychological Science,",
            "year": 1992
        },
        {
            "authors": [
                "Vincent Conitzer",
                "Rupert Freeman",
                "Nisarg Shah",
                "Jennifer Wortman Vaughan"
            ],
            "title": "Group Fairness for the Allocation of Indivisible Goods",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Harald Cram\u00e9r"
            ],
            "title": "Mathematical Methods of Statistics",
            "year": 1946
        },
        {
            "authors": [
                "Geoffroy de Clippel",
                "Kareen Rozen"
            ],
            "title": "Fairness through the lens of cooperative game theory: An experimental approach",
            "venue": "American Economic Journal: Microeconomics,",
            "year": 2022
        },
        {
            "authors": [
                "Greg d\u2019Eon",
                "Kate Larson"
            ],
            "title": "Testing Axioms against Human Reward Divisions in Cooperative Games",
            "venue": "In Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Duncan Karl Foley"
            ],
            "title": "Resource Allocation and The Public Sector",
            "venue": "Yale University,",
            "year": 1967
        },
        {
            "authors": [
                "John C Harsanyi"
            ],
            "title": "Interpersonal Utility Comparisons",
            "venue": "In Utility and Probability,",
            "year": 1990
        },
        {
            "authors": [
                "Dorothea K Herreiner",
                "Clemens D Puppe"
            ],
            "title": "Envy Freeness in Experimental Fair Division Problems",
            "venue": "Theory and Decision,",
            "year": 2009
        },
        {
            "authors": [
                "Hadi Hosseini",
                "Sujoy Sikdar",
                "Rohit Vaish",
                "Jun Wang",
                "Lirong Xia"
            ],
            "title": "Fair Division through Information Withholding",
            "venue": "In Proceedings of the 34th AAAI Conference on Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Tobias K\u00f6nig",
                "Dorothea K\u00fcbler",
                "Lydia Mechtenberg",
                "Renke Schmacker"
            ],
            "title": "Fair Procedures with Naive Agents: Who Wants the Boston Mechanism? Rationality and Competition Discussion Paper Series 222, Discussion Paper, 2019",
            "venue": "URL https://ideas.repec.org/p/rco/dpaper/222.html",
            "year": 2019
        },
        {
            "authors": [
                "Maria Kyropoulou",
                "Josu\u00e9 Ortega",
                "Erel Segal-Halevi"
            ],
            "title": "Fair Cake-Cutting in Practice",
            "venue": "Games and Economic Behavior,",
            "year": 2022
        },
        {
            "authors": [
                "J\u00e9r\u00f4me Lang",
                "J\u00f6rg Rothe"
            ],
            "title": "Fair Division of Indivisible Goods",
            "venue": "In Economics and Computation,",
            "year": 2016
        },
        {
            "authors": [
                "Min Kyung Lee"
            ],
            "title": "Understanding Perception of Algorithmic Decisions: Fairness, Trust, and Emotion in Response to Algorithmic Management",
            "venue": "Big Data & Society,",
            "year": 2018
        },
        {
            "authors": [
                "Min Kyung Lee",
                "Su Baykal"
            ],
            "title": "Algorithmic Mediation in Group Decisions: Fairness Perceptions of Algorithmically Mediated vs. Discussion-Based Social Division",
            "venue": "In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing,",
            "year": 2017
        },
        {
            "authors": [
                "Min Kyung Lee",
                "Anuraag Jain",
                "Hea Jin Cha",
                "Shashank Ojha",
                "Daniel Kusbit"
            ],
            "title": "Procedural justice in algorithmic fairness: Leveraging transparency and outcome control for fair algorithmic mediation",
            "venue": "Proceedings of the ACM on Human-Computer Interaction,",
            "year": 2019
        },
        {
            "authors": [
                "Richard J Lipton",
                "Evangelos Markakis",
                "Elchanan Mossel",
                "Amin Saberi"
            ],
            "title": "On Approximately Fair Allocations of Indivisible Goods",
            "venue": "In Proceedings of the 5th ACM Conference on Electronic Commerce,",
            "year": 2004
        },
        {
            "authors": [
                "Herv\u00e9 Moulin"
            ],
            "title": "Fair Division in the Internet Age",
            "venue": "Annual Review of Economics,",
            "year": 2019
        },
        {
            "authors": [
                "Michael I Norton",
                "Daniel Mochon",
                "Dan Ariely"
            ],
            "title": "The IKEA Effect: When Labor leads to Love",
            "venue": "Journal of Consumer Psychology,",
            "year": 2012
        },
        {
            "authors": [
                "John Rawls"
            ],
            "title": "A Theory of Justice",
            "venue": "In Ethics,",
            "year": 2004
        },
        {
            "authors": [
                "William Samuelson",
                "Richard Zeckhauser"
            ],
            "title": "Status quo bias in decision making",
            "venue": "Journal of risk and uncertainty,",
            "year": 1988
        },
        {
            "authors": [
                "Nripsuta Ani Saxena",
                "Karen Huang",
                "Evan DeFilippis",
                "Goran Radanovic",
                "David C Parkes",
                "Yang Liu"
            ],
            "title": "How do Fairness Definitions Fare? Examining Public Attitudes Towards Algorithmic Definitions of Fairness",
            "venue": "In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society,",
            "year": 2019
        },
        {
            "authors": [
                "Amartya Sen"
            ],
            "title": "Collective Choice and Social Welfare",
            "year": 2018
        },
        {
            "authors": [
                "Megha Srivastava",
                "Hoda Heidari",
                "Andreas Krause"
            ],
            "title": "Mathematical Notions vs. Human Perception of Fairness: A Descriptive Approach to Fairness for Machine Learning",
            "venue": "In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining,",
            "year": 2019
        },
        {
            "authors": [
                "Amos Tversky",
                "Daniel Kahneman"
            ],
            "title": "The framing of decisions and the psychology of choice",
            "venue": "In Behavioral decision making,",
            "year": 1985
        },
        {
            "authors": [
                "Tom R Tyler",
                "E Allan Lind"
            ],
            "title": "Procedural justice",
            "venue": "In Handbook of justice research in law,",
            "year": 2002
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Fair division plays a vital role in distributing resources or goods among a set of agents who have preferences over bundles of resources. It provides a mathematical framework for investigating axiomatic and computational aspects of fairness and has given rise to numerous studies at the intersection of mathematics, economics, and computer science.\nDespite significant attention to theoretical and algorithmic aspects of fairness Moulin [2019], Aziz et al. [2022], Amanatidis et al. [2022], little has been done to investigate their suitability in the presence of human subjects. The perception of fairness has been recently studied in the context of loan decisions Saxena et al. [2019] and within machine learning Srivastava et al. [2019]. Yet, in the context of fair allocation of resources, it is unclear what fairness concepts (or relaxations thereof) are perceived to be fairer.\nOne of the gold standards of fairness\u2014envy-freeness (EF) Foley [1967]\u2014has been extensively studied from theoretical and algorithmic perspectives; see Lang and Rothe [2016], Brandt et al. [2016] for an overview. EF is compelling since it does not rely on interpersonal utility comparisons1 and eliminates the need for identifying which agent derives the most benefit from (a bundle of) resources. It requires that\n1For a comprehensive discussion on interpersonal utility comparisons and arguments for and against them in the utility theory, see Sen [2018], Harsanyi [1990].\nar X\niv :2\n21 2.\n04 57\n4v 2\n[ cs\n.G T\n] 2\neach agent (weakly) prefers its own bundle to all other bundles only according to its own direct subjective preferences \u2013 hence, each agent lacks envy toward other agents.\nWhen dealing with indivisible resources, EF allocations do not always exist and determining their existence is computationally intractable Lipton et al. [2004]. These factors have motivated a large body of work in search of relaxations of envy-freeness. One of the most appealing and well-studied relaxations is envy-freeness up to one good (EF1), which is based on counterfactual thinking that any pairwise envy can be eliminated by the hypothetical removal of a single good from the envied agent\u2019s bundle Budish [2011]. An EF1 allocation always exists and can be computed in polynomial time Lipton et al. [2004]. However, different pairs of agents may require the (hypothetical) removal of a different good, potentially removing all goods in the worst case and resulting in weak aggregate guarantees Hosseini et al. [2020].\nAnother emerging line of work considers epistemic relaxations of envy-freeness (epistemic EF), and proposes concepts that rely on withholding the information available to the agents by assuming agents have no knowledge about the allocations of others Aziz et al. [2018]. Thus, each agent\u2019s view of the hypothetical allocation of the goods distributed among others could be substantially different from the views of other agents and that of the actual underlying allocation.\nA recently proposed notion called envy-freeness up to k hidden goods (HEF-k) takes a middle-ground approach by hiding the allocation of a subset of k goods while consistent and common information about the remaining goods is made available to all agents Hosseini et al. [2020]. Thus, it strikes a balance between counterfactual removal of goods (as in EF1) and on the hypothetical perspectives of agents due to lack of common information (as in epistemic EF).\nWe seek to investigate the perceived fairness of relaxations of envy-freeness through an experiment with human subjects. At a high level, our work is aligned with a large body of work in distributive justice2 that is concerned with socially fair outcomes (in contrast to procedural justice; see e.g., Tyler and Allan Lind [2002], Rawls [2004], Lee et al. [2019]). Thus, we address the following research question:\nWhich relaxation of envy-freeness among EF1 and HEF-k for allocating indivisible goods is perceived to be fairer by individuals?"
        },
        {
            "heading": "1.1 Our Contributions",
            "text": "We develop a framework to implicitly measure perceptions of fairness in allocations of indivisible goods through an empirical study. Each participant is presented with a series of survey questions in which they take on the perspective of an agent in a fair division instance with an initial allocation. The allocation satisfies one of three envy-freeness relaxation properties per the treatment assigned to the participant: sEF1, EF1, or HEF-k (defined in Section 2). In each survey question, they may either keep their given bundle or swap it with another agent\u2019s bundle, indicating their perceived envy (but not the degree of envy). Participants\u2019 responses are aggregated into a single swap rate, the percentage of survey questions where a swap was chosen, as an implicit measurement of perceived fairness under the treatment.\nWe compare the treatments using the following metrics: (i) perceived envy (measured by swap/no-swap decisions), (ii) the impact of variables such as instance size and balance of allocations (defined in Section 3.1), and (iii) cognitive effort (measured through response time and self-reports of question difficulty). Further, we compare swap rates among survey questions in which it is or is not optimal for participants to swap when considering the values of hidden goods.\nOur results show that allocations under the HEF-k treatment are perceived to be fairer than under the sEF1 and EF1 treatments, even when controlling for size of instances, balance of allocations, and questions in which it is optimal to swap. In particular:\n2We refer the reader to the extensive literature in the theory of social justice, e.g. Adams [1963], Rawls [2004].\n\u2022 There is a statistically significant difference between the swap rates of HEF-k and both sEF1 and EF1 treatments, at a significance level of \u03b1 = 0.001. Our main finding is that participants under the HEF-k treatment displayed the lowest swap rate, followed by sEF1 and EF1 (Section 4.1). Hence, HEF-k is perceived to be the most fair tested relaxation of envy-freeness.\n\u2022 There is a statistically significant difference in the cognitive effort exercised by participants (measured by response time and self-reports of difficulty) between the HEF-k and both sEF1 and EF1 treatments, at a significance level of \u03b1 = 0.001 (Section 4.2). Hence, perceived fairness comes at the cost of increased task complexity."
        },
        {
            "heading": "1.2 Related Work",
            "text": "An emerging line of work in recent years has focused on perceived fairness by individuals in algorithmic decision making. In this vein, Herreiner and Puppe [2009] compared the intra-personal fairness notion of EF with the inter-personal notion of inequality aversion (IA), defined as the tendency of individuals to opt for equal outcomes across participants, in the context of bargaining for good allocations with 2 or 3 agents. They showed that IA is the primary factor for fairness, while EF only comes into play as a secondary factor when economic efficiency (e.g. Pareto optimality) and IA are insufficient criteria. Lee et al. [2019] conducted a study to measure the effect of transparency and outcome control\u2014i.e. the ability to manually adjust prescribed outcomes\u2014on perceived fairness of EF1 allocations prescribed by Spliddit3. They showed that perceived fairness was increased after participants were given an opportunity to modify the allocation (either individually or through group discussions). These studies are substantially different from ours for two primary reasons: (1) there is an impact of \u2018personal image\u2019 and \u2018social pressure\u2019 in bargaining and collective decision-making, which may provide a justification for inequality aversion, and (2) there is a sense of \u2018agency\u2019 within discussions or ability to modify the outcome which may result in higher satisfaction caused by the Ikea Effect cognitive bias, a phenomenon by which people tend to increase their value of products that they helped to create Norton et al. [2012].\nSeparately, Kyropoulou et al. [2022] conducted a study to test the effect of participants\u2019 strategic behavior on total envy in fair division of divisible resources. The fair division procedures used guarantee either EF or proportionality, defined as each participant receiving at least 1/n their total valuation, if all n agents behave non-strategically. The authors found that participants strategize less and incur less total envy, at the end of the procedure, when applying fair procedures (that guarantee EF assuming truthfulness) than otherwise.\nAnother line of research compares decisions proposed by algorithms with those proposed by humans. In a study by Lee and Baykal [2017], participants found allocations prescribed by Spliddit to be less fair than those chosen in a group discussion, one third of the time. The authors explain this distinction as the algorithms excluding the effect of individual participation, interpersonal power, and altruism on fairness, despite being envy-free. Lee [2018] suggested that perceived fairness of algorithms is also dependent on task characteristic. Specifically, the participants in Lee\u2019s study recognized that algorithms produce less fair decisions on tasks that require human skills (e.g., subjective judgement) but equally fair on mechanical tasks (e.g., processing data).\nIn a separate work, Ko\u0308nig et al. [2019] conducted a lab study to measure the suitability of two welladopted matching mechanisms, namely the Boston mechanism and the assortative matching, under the veil of ignorance Rawls [2004] assumption. They concluded that which procedure is preferred depends on how much autonomy subjects have in reporting their preferences.\nOther works have studied the empirical validity of fairness axioms in cooperative games d\u2019Eon and Larson [2020], de Clippel and Rozen [2022] and contrastive fairness in machine learning Chakraborti et al. [2020].\n3www.spliddit.org"
        },
        {
            "heading": "2 Model and Solution Concepts",
            "text": "In this section, we formalize the model of fair division for indivisible goods, define envy-freeness and its relaxations, and exemplify these concepts.\nModel. For any k \u2208 N, we define [k] \u2236= {1, . . . , k}. An instance of the fair division problem is a tuple I = \u27e8N,M,V \u27e9, where N \u2236= [n] is a set of n agents, M \u2236= [m] is a set of m goods, and V \u2236= {v1, . . . , vn} is a valuation profile that specifies for each agent i \u2208 N its preferences over the set of all possible bundles 2M . This valuation function vi \u2236 2M \u2192 N\u222a{0} maps each bundle to a non-negative integer. We write vi,j instead of vi({j}) for a singleton good j \u2208 M . We assume that the valuation functions are additive, meaning that for any i \u2208 N and S \u2286M , vi(S) \u2236= \u2211j\u2208S vi,j , where vi(\u2205) = 0. Allocation. An allocation A \u2236= (A1, . . . ,An) is an n-partition of the set of goods M , where Ai \u2286M is the bundle allocated to agent i \u2208 N . Definition 1 (Envy-freeness). An allocation A is: (i) envy-free (EF) if for every pair of agents h, i \u2208 N , vi(Ai) \u2265 vi(Ah) Foley [1967], (ii) strongly envy-free up to one good (sEF1) if for each agent h \u2208 N such that Ah \u2260 \u2205, there exists a good gh \u2208 Ah such that for every i \u2208 N , vi(Ai) \u2265 vi(Ah \u2216 {gh}) Conitzer et al. [2019], and (iii) envy-free up to one good (EF1) if for each pair of agents h, i \u2208 N , there exists a good gh \u2208 Ah such that vi(Ai) \u2265 vi(Ah \u2216 {gh}) Lipton et al. [2004], Budish [2011]. Definition 2 (Envy-freeness with hidden goods). An allocation A is envy-free up to k hidden goods (HEFk) if there exists a subset S \u2286 M , \u2223S\u2223 \u2264 k, such that for every pair of agents h, i \u2208 N , we have that vi(Ai) \u2265 vi(Ah \u2216 S) Hosseini et al. [2020].\nRecall that sEF1 and EF1 detail goods that may counterfactually be removed to entail envy-freeness, whereas HEF-k details a set S of hidden goods. An allocation is EF if and only if it is HEF-0, and \u2200k \u2265 0, HEF-k entails HEF-(k + 1) Hosseini et al. [2020]. Furthermore, sEF1 entails both EF1 and HEF-n, but other relations may not hold. To remove ambiguity, we write \u201cEF1\u201d to denote allocations that are EF1 but not sEF1. We call an allocation A HEF-k with respect to S if A is not HEF-k\u2032 with respect to any smaller set S\u2032, \u2223S\u2032\u2223 = k\u2032 < k. Finally, since EF1 entails HEF-k for some k, we distinguish these classes throughout this paper by stating that an allocation is either EF1 or HEF-k for a specific k.\nExample 1. Consider the fair division instance shown in Figure 1 with three agents 1,2,3 and six goods g1, . . . , g6. The values vi,j are presented for each agent i \u2208 [3] and good gj , followed by three different allocations of the same instance satisfying sEF1, EF1, and HEF-1, respectively. For each good we denote which bundle it is allocated to; for example, in the EF1 allocation, A1 = {g1, g5}.\nThe bracketed bundles indicate which corresponding goods must be hypothetically removed (or hidden) to eliminate pair-wise envy. For example, in the EF1 allocation, removing g1 and g5 from A1 eliminates envy from agents 3 and 2 respectively, removing g3 from A2 eliminates envy from both other agents, and removing g2 and g6 from A3 eliminates envy from agents 2 and 1 respectively."
        },
        {
            "heading": "3 Experimental Design",
            "text": "We conducted an empirical study to compare the perceived fairness of three relaxations of envy-freeness\u2014 sEF1, EF1, and HEF-k\u2014using a gamified pirate scenario (see Figure 2). For each treatment, participants were offered allocations of twelve fair division instances and asked whether they wanted to keep their given bundle or swap with another agent. We measured participants\u2019 swap rate, the percentage of questions where a swap was chosen, and compared treatments using Chi-square and Fisher\u2019s exact tests. We then compared treatments upon segmenting our data by (i) the number of agents and goods in the instance (instance size), (ii) the distribution of goods across agents (allocation balance), and (iii) whether it is optimal for participants to swap or not (optimal choice). Our study employed 120 mutually exclusive participants for each of the three Human Intelligence Tasks (HIT) in Amazon\u2019s Mechanical Turk platform, totalling 360 participants.\nPirate Scenario. Participants were given scenarios with the role of one of the members of a crew of pirates (representing agents), whose captain (a central authority) wished to divide goods, the spoils of a recent adventure, among the crew (see Figure 2). For each survey question, participants were shown: (i) the subjective monetary value in USD ($) that each good in a marketplace is worth to the participant, and (ii) the bundle of (revealed) goods for each pirate in an allocation determined by the captain. Goods present in the marketplace but not visibly allocated in the HEF-k treatment were said to be either allocated to and hidden by other pirates or lost at sea. The actual reward for every other pirate\u2019s bundle included any hidden goods, although the observed reward may be less.\nGiven this information, the participant may either swap their bundle with that of another pirate in its entirety or keep their initial bundle. Participants were incentivized to select bundles with maximal reward with a bonus payment if the total value of goods they collected surpassed a threshold."
        },
        {
            "heading": "3.1 Data Set",
            "text": "Our data set incorporated 168 survey questions, each consisting of a fair division instance, an allocation partitioning the goods, and an assignment of the participant to one pirate\u2019s perspective, constructed as follows.\nInstances. We generated 28 instances of the fair division problem involving nine or ten goods: 21 small instances with three agents and 7 large instances with five agents. Agents\u2019 subjective (heterogeneous) valuations were sampled uniformly at random from {5,10, . . . ,120} for small instances and from {5,10, . . . ,150}\nfor large instances.\nAllocations. For each instance, we computed three allocations satisfying sEF1, EF1, and HEF-k for a prespecified k \u2208 {0,1,2}, which we call the allocation (and associated survey question)\u2019s type. For example, Figure 1 demonstrates three such allocations for an instance with k = 1. In order to emphasize the difference between EF1 and sEF1, our EF1 allocations require at least two more goods than the number of agents to be hypothetically removed to make them envy-free.\nThere were two levels of balance for allocations. A balanced allocation gives every agent a bundle of equal size, three (respectively, two) goods to each agent in a small (respectively, large) instance. In an unbalanced allocation, agents may have bundles consisting of different number of goods, with bundle sizes (2,4,4) for small instances and either (4,2,2,1,1) or (3,2,2,2,1) for large instances. All allocations from the same instance have the same balance.\nPerspective. Participants were randomly assigned to assume the role of either the first or last (i.e., third or fifth) agent in the instance. This expanded our data set without biasing our results, as valuations were randomly generated and allocations did not depend on the agent\u2019s identity.\nSurvey question properties. Our 28 instances were made with the following combinations: (i) 15 small-balanced: five instances each whose HEF-k allocations have types 0, 1 and 2, (ii) 6 small-unbalanced: two instances each whose HEF-k allocations have types 0, 1 and 2, (iii) 5 large-balanced: two instances each whose HEF-k allocations have types 0 and 1 and one of type 2, and (iv) 2 large-unbalanced whose HEF-k allocations were type 1: one each with bundle sizes (4,2,2,1,1) and (3,2,2,2,1)."
        },
        {
            "heading": "3.2 Survey Outline",
            "text": "Participants undertook the following workflow (see Figure 7 in the Appendix). Participant were first assigned a treatment and randomly determined a perspective. After giving their informed consent to participate in our IRB approved study and completing a short tutorial, they subsequently answered twelve survey questions, two questions soliciting self-reports of survey question difficulty, and two attentiveness check questions. The survey questions were organized into four sections, each consisting of questions of different size and balance that were selected uniformly at random from the appropriate data set, and then randomly permuted within the section. A complete questionnaire therefore consisted of:\n\u2022 Section 1 (Q1\u20133): 3 small-balanced questions (if HEF-k, then k \u2208 {0,1,2} respectively).\n\u2022 Section 2 (Q4\u20137): 3 small-unbalanced questions (if HEF-k, then k \u2208 {0,1,2} respectively); followed by Q7 which is a repeat of Q4.\n\u2022 Difficulty: self-reported rating for small questions.\n\u2022 Section 3 (Q8\u201310): 3 large-balanced questions (if HEF-k, then k \u2208 {0,1,2} respectively).\n\u2022 Section 4 (Q11-12): 2 large-unbalanced questions (if HEF-k, then k = 1), one of each bundle size.\n\u2022 Difficulty: self-reported rating for large questions.\n\u2022 Final page with two attentiveness check questions.\nThe pictures representing each good were randomly permuted for each survey question to avoid any effect of participants\u2019 biases towards the goods.\nTutorials. All participants were required to correctly answer a few tutorial questions prior to the survey questions.\nThe first tutorial taught participants that the reward of a bundle was equal to the sum of values of the goods inside that bundle. Participants were presented with a bundle consisting of three goods, which were highlighted in the marketplace, and were asked to compute the bundle\u2019s reward.\nThe second tutorial taught participants that whether they received a monetary bonus upon completing the survey is dependent on the total reward they collect throughout its course. The participants were presented with three bundles, similar to Figure 2(a), and were asked if they wanted to keep their bundle (left) or swap it with either Pirate 1\u2019s bundle (middle) or Pirate 2\u2019s bundle (right). The bundle with the highest reward was enforced as the correct choice.\nHEF-k treatment participants were provided a third tutorial designed to teach them about goods in the marketplace that were not visibly allocated. Participants were presented with three bundles, similar to Figure 2(b), and were told that the missing goods may be either allocated to and hidden by the other pirates or discarded altogether, lost at sea. Participants were asked about the maximum number of goods that could be found in any one pirate\u2019s bundle, thus requiring them to reason about the location of missing goods.\nSelf-reported difficulty. The groups of seven small and five large questions were each succeeded by a question asking participants to rate the difficulty of the questions on a 5-point Likert scale from Very Easy (1) to Very Hard (5).\nAttentiveness check questions. We incorporated many checks to ensure high quality responses from attentive human participants. Prior to the tutorial, participants answered a simple arithmetic problem to ensure they were human. On the final page, they answered: (1) their favorite good and (2) final comments or questions. We presumed that we could identify inattentive participants giving poor quality data as they would not be able to answer these prompts appropriately. We did not discard any participants\u2019 responses by these measures.\nAdditional details about participant qualifications and the payment structure can be found in the Appendix."
        },
        {
            "heading": "4 Experimental Results",
            "text": "We test the empirical swap rate of each treatment as a measure for perceived envy, and, in turn, perceived fairness, across all questions and while controlling for a handful of variables. We partition the HEF-k treatment into three separate sub-treatments\u2014HEF-0, HEF-1, and HEF-2\u2014and compare swap rates between these sub-treatments and to sEF1. Separately, we compare the effect of treatment and size of instance on participants\u2019 cognitive effort, as measured by response time and self-reports of difficulty, for answering the questions.\nOf particular interest is whether swap rates differ between treatments on questions in which a participant\u2019s optimal (i.e., reward maximizing) choice is to stay or swap bundles. We pose this interest upon making two observations. First, participants may be biased to accept their default bundle and maintain the status quo Samuelson and Zeckhauser [1988] rather than make any adjustments. Second, HEF-k differs from the other two treatments in that participants may not have enough information to distinguish which bundle is optimal. This raises the question of whether swap rates may differ between treatments depending on optimal choice."
        },
        {
            "heading": "4.1 Perceived Fairness",
            "text": "We formalize our research question, as follows: Research Question: For any two treatmentsX,Y \u2208 {sEF1,EF1,HEF-k} or {sEF1,HEF-0,HEF-1,HEF-2}, do swap rates differ between X and Y overall and when adjusted independently for the variables: (i) Optimal Choice: whether the reward maximizing choice is to stay with the initial bundle (stay-is-opt), or to\nswap (swap-is-opt), (ii) Instance Size: small or large, and (iii) Balance: balanced or unbalanced? Null Hypothesis: swap rate is independent of treatment. Alternate Hypothesis: swap rate depends on treatment.\nOur experiments provide statistically significant evidence for rejecting the null hypothesis that swap rates are independent of treatment. We draw this conclusion using the Chi-square (\u03c72) test at a significance level of \u03b1 = 0.001 for nearly all combinations of pairs of treatments and values for the different confounding variables in our study, and at a significance level of \u03b1 = 0.002 for the remaining combinations.\nTable 1 summarizes our findings. For each pair of treatments X and Y , identified by the column named \u2018X,Y \u2019, and for each value of each of the possible confounding variables, given by the rows, we present both the p-value of the \u03c72 statistic and the ratio of swap rates under X and Y .\nOur main finding is that across all questions, (1) the perceived envy of HEF-k is significantly lower than the perceived envy of either sEF1 and EF1, and (2) sEF1 allocations are less likely to be perceived as unfair than EF1 allocations, as we show in Figure 3. This holds true upon adjusting for instance size (small or large) and the allocation balance (balanced or unbalanced), and among questions where swap-is-opt, as we summarize in Table 1. Thus our main takeaway message is that: withholding information through hiding goods promotes perceived fairness among individuals.\nSegmented Data. Upon drawing this conclusion, we segment our data to draw additional insights. In particular, among HEF-k allocations, swap rate increases as the number of hidden goods increases (Table 3 in the Appendix): HEF-0 allocations induce less envy among participants than either HEF-1 or HEF-2. This is perhaps because as more goods are hidden, participants are more cautious, more uncertain about the fairness of the allocation, and spend more time on average to choose bundles (Figure 8 in the Appendix). Further studies may be necessary to explain these results.\nOptimal Choice. We find that participants\u2019 perceived fairness is indeed affected by optimal choice. Specifically, for each treatment (except HEF-0), participants\u2019 swap rates are statistically different between swap-is-opt and stay-is-opt questions (Table 2 in the Appendix).\nWhen swap-is-opt (Figure 9 in the Appendix) participants swap their bundles more often under the sEF1 and EF1 treatments, where it is easy to see that their bundle has lower value than that of another pirate. Under the HEF-k treatment, where the allocation of some goods is hidden, participants perceive significantly lower envy even when they are allocated a lower valued bundle.\nAmong stay-is-opt questions, where the participant\u2019s bundle has the highest reward among the bundles of all pirates, we observe that sEF1 allocations have significantly lower perceived envy than HEF-k allocations, which in turn demonstrate a lower envy than EF1 allocations (see Figure 4).\nParticipants subjected to the sEF1 treatment could verify with certainty that their bundles have the highest value since all goods were visible. It may not be possible to make such determinations under the HEF-1 and HEF-2 treatments, where goods may be hidden to eliminate envy between other pairs of pirates. Indeed, the hidden goods may all be allocated to another pirate, hypothetically raising the value of that pirate\u2019s bundle to be the highest, justifying a swap.\nSurprisingly, HEF-0, which is EF and does not hide any goods, and EF1 are perceived to have higher envy than sEF1 allocations, despite it being equally easy to verify that the participant\u2019s bundle has the highest reward for stay-is-opt questions. The swap rate between either HEF-k and EF1, or HEF-2 and sEF1, is not statistically significant in this case.\nControlling for choice of goods. Our survey questions presented goods related to a pirate\u2019s adventure, such as a map, rum, and a diamond. This gamified pirate scenario stands in for a wider variety of fair division problems. To control for any possible effect of our choices of goods on participants\u2019 decisionmaking, we repeated a survey question and replaced the goods with gems of different colors. The repeated instance and allocation (Q7) were identical to the original (Q4), which is small-unbalanced but of varying types.\nWe find that every null hypothesis that was rejected by comparing responses on all questions is also rejected when the test is performed only on the repeated question (see Table 1). Furthermore, the ratio of swap rates for all of the pairs of treatments remains similar as well. Therefore, our results do not appear to be impacted by the choice of goods."
        },
        {
            "heading": "4.2 Cognitive Effort",
            "text": "In addition to our tests of perceived fairness, we investigate the extent to which treatment and size of instance affects cognitive effort of the participants. Specifically, we measure: \u2022 response time, the time elapsed between the survey question page being made available to the participant\nand the participant submitting their choice, and\n\u2022 question difficulty, using the self-reports of question difficulty solicited immediately after the small and then the large questions.\nFigure 5 illustrates that the average response time per sEF1 question is lowest and HEF-k is highest, while EF1 splits the two. Similarly, participants report that sEF1 questions are easiest, while HEF-k is the most difficult and EF1 lies in between (Figure 6). Here, the blue line in the middle of the box indicates the median value, the upper and lower boundaries of box show the 25th and 75th percentile respectively, and the upper and lower whiskers show the range of recorded values. The mean is indicated by a blue diamond. Outliers beyond the whiskers are excluded.\nThese observations suggests that HEF-k instances cause higher cognitive burden on participants. Indeed, the distinction in time spent per question for HEF-k questions versus either sEF1 or EF1 questions, and conditioning on either small or large questions, is statistically significant using a two-sided Welsh t-test (see Table 4 in the Appendix). This burden also increases as the parameter k increases, i.e., as the HEF-k fairness notion, parameterized by k hidden goods is relaxed further (see Figure 8 in the Appendix)."
        },
        {
            "heading": "4.3 Descriptive Comments from Participants",
            "text": "We identify participants anonymously using a letter S,E, orH corresponding to their treatment (sEF1, EF1, HEF-k).\nParticipants in the EF1 treatment consistently noted that other pirates\u2019 bundles \u201cwere usually more valuable\u201d (E22), so they should \u201cswap with the highest yielding chest\u201d (E17, E8, E15). On the other hand, HEF-k participants noted \u201cit seemed a no brainer to just never swap\u201d (H8, H28). These comments are consistent with our data that swap rates were significantly lower for HEF-k than other treatments.\nA few participants commented about fairness. Participant S57 suggested \u201cit didn\u2019t seem like a fair split\u201d while S63 declared they wouldn\u2019t swap in real life \u201cbecause it would be unfair to the other person.\u201d Despite this hesitation, participant E96 reasoned that because \u201cthere was no defining reason why anyone would get more than others\u201d due to differing effort, they should still select the most valuable treasure. These comments\nresemble Herreiner and Puppe [2009]\u2019s findings that participants care more about inequality aversion than EF to ensure fairness. However, it is unclear whether this behavior is still evident when there are no other human participants. We leave this intriguing question for future work.\nAdditional comments may be found in the Appendix."
        },
        {
            "heading": "4.4 Limitations and Future Work",
            "text": "Our experiments are limited, among other aspects, by the size of our instances, uncontrolled bias, and the notion of fairness that we test. First, our experiment tested two sizes of instances representing a crosssection of the numbers of goods m, agents n, and goods hidden k. In all the settings we tested, m \u2264 10 and k < n. Our experiment was limited by the capacity to provide meaningful information to participants without causing cognitive overload?. Determining how sensitive our results are to larger numbers of goods and hidden goods is an interesting question for future work.\nSecond, we controlled for effects of our gamified pirate scenario and choices of goods by repeating a survey question with identical gems of different colors. However, we may not have accounted for all sources of bias. For example, participants may be affected by the framing effect for their decisions about envy-free allocations (i.e., HEF-0), which appear in the HEF-k treatment context; see, e.g., Tversky and Kahneman [1985]. Future work may consider the sensitivity of our results to problem context, such as task characteristic Lee [2018].\nThird, our experiments tested the perceived fairness of two intra-personal envy-based concepts. Both EF1 and HEF-k presume that people find allocations fair if they are themselves not envious of other agents, and our study measures perceived envy according to this standard. Whether envy-based notions of fairness are more appropriate than comparative forms like inequity aversion is a topic of ongoing debate, as noted by Herreiner and Puppe [2009]. Our experiment advances this discussion by comparing two relaxations of envy-freeness and providing evidence that one is perceived to be fairer. Further investigations into perceptions of the fairness of other notions, such as maximin-share Budish [2011] and proportionality; attitudes towards procedural versus distributive fairness; and whether moral judgements are affected by participants having \u2018skin in the game\u2019 are important and interesting topics for future empirical research."
        },
        {
            "heading": "5 Conclusion",
            "text": "Dividing indivisible resources fairly among many stakeholders is a challenging, yet crucial, problem with applications ranging from splitting rent, allocating work credit on a project, and dividing inheritance. Our work presents an important first step in providing an empirical comparison of human perceptions of the fairness of approximate envy-freeness that are widely studied in the literature on the fair division of indivisible goods.\nWe find that HEF-k, an epistemic envy-freeness notion, is perceived to be more fair than other well-\nstudied notions such as sEF1 and EF1 that rely on counterfactual thinking. This holds as HEF-k allocations\u2014 where participants must actively reason about the location of hidden goods\u2014are more cognitively burdensome to reason about than sEF1 and EF1\u2014where participants have full information\u2014as measured by participant response time and reported difficulty."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the anonymous reviewers for helpful comments. HH acknowledges support from NSF grants #2144413, #2107173, and #2052488. RV acknowledges support from DST INSPIRE grant no. DST/INSPIRE/04/2020/000107. LX acknowledges support from NSF grants #1453542, #2007994, and #2106983, and a Google Research Award."
        },
        {
            "heading": "A Experimental Design: Additional Details",
            "text": "Prior to answering any questions, participants were informed of the study description, benefits, risks, rights, and project manager contact information. Participants gave their informed consent to participate in our IRB approved study.\nThe workflow for a participant in our study is illustrated in Figure 7. Here, we provide details on the measures used in our study to ensure high quality responses from participants recruited from the Amazon Mechanical Turk platform. In addition to screening participants and qualifying responses, we discuss how participants were incentivized to provide high quality responses through our payments structure.\nResponse qualifications. In order to obtain high quality responses, participation in our study was restricted to Mechanical Turk Workers who had (a) at least an 80% approval rate on previous tasks, (b) completed at least 100 tasks, (c) located in either the United States or Canada4, (d) a Master\u2019s qualification5 on the MTurk platform, and (e) had not attempted or taken the survey before. We adjusted the minimum HIT Approval Rate (%) and Number of HITs Approved through the experiment in order to attract Mechanical Turk Workers to participate.\nSpecifically, the minimum (approval rate, number approved) per treatment are as follows: (i) all sEF1 participants had (95%, 1000 approved); (ii) among the EF1 participants, 20 had (95%, 1000 approved), and the other 100 had (80%, 100 approved); (iii) among the HEF-k participants, 20 had (95%, 1000 approved), 42 had (90%, 1000 approved), 14 had (80%, 1000 approved), 21 had (90%, 500 approved), 9 had (90%, 100 approved), and 14 had (80%, 100 approved).\nPayments. Each participant was eligible to receive two payments: (1) a base payment of 50\u00a2 for completing the survey in its entirety, and (2) a bonus payment of 50\u00a2 for accumulating at least $2000 worth of goods\n4We restricted location to ensure language proficiency and prevent any potential issues due to linguistic barriers. 5Workers with Master\u2019s qualification, determined by MTurk, are those who \u201chave consistently demonstrated a high degree of\nsuccess in performing a wide range of HITs across a large number of Requesters.\u201d See https://www.mturk.com/worker/help.\nthrough all survey questions. The bonus threshold was chosen to incentivize participants to choose the most valuable bundle, encourage participants to pay greater attention, and not choose randomly for each survey question. We determined this value by computing the minimum and maximum total reward a participant can obtain on any survey using our data set for each question. We then chose $2000 which falls between between 71% and 84% for these ranges."
        },
        {
            "heading": "B Descriptive Comments from Participants",
            "text": "Participants\u2019 final comments provide some insight into their decision-making. We identify the participants by a letter S, E, or H denoting the treatments sEF1, EF1, or HEF-k respectively that they were subject to, followed by a number to uniquely identify them.\nParticipants in the EF1 treatment consistently noted that other pirates\u2019 bundles \u201cwere usually more valuable\u201d (E22), so they should \u201cswap with the highest yielding chest\u201d (E17, E8, E15). On the other hand, HEF-k participants noted \u201cit seemed a no brainer to just never swap\u201d (H8, H28), either because it was the \u201csafest bet\u201d (H49) or the \u201cgreatest statistical chance of getting higher reward\u201d (H59). These comments are consistent with our data that swap rates were significantly less for the HEF-k treatment than the envy-free up to one good treatments.\nA few participants in the envy-free up to one good treatments noted their caution about allocations\u2019 fairness. Participant S57 suggested \u201cit didn\u2019t seem like a fair split\u201d while S63 declared they wouldn\u2019t swap in real life \u201cbecause it would be unfair to the other person.\u201d Despite this hesitation, participantE96 reasoned that because \u201cthere was no defining reason why anyone would get more than others\u201d due to differing effort, they should still select the most valuable treasure. These comments resemble Herreiner and Puppe [2009]\u2019s findings that participants care more about inequality aversion than envy-freeness to ensure fairness. In contrast to this, our tutorials reinforced participants\u2019 belief that their \u201coverall goal was to get the highest value\u201d they could (S97).\nAlthough participants\u2019 bonuses only depend on goods\u2019 market value each round, some participants were speculative. For example, participant E56 wasn\u2019t sure their bundle of four goods would be worth more in the future than a bundle with \u201ca higher current market value but less goods.\u201d Participant E101 noted that the value of silver \u201ccould fluctuate greatly in value.\u201d"
        },
        {
            "heading": "C Experimental Results: Additional Tables and Figures",
            "text": "Cognitive effort on HEF-k allocations. Figure 8 presents the distribution of time spent per survey question over all HEF-0, HEF-1 and HEF-2 questions. We find that overall, as the number of hidden goods increases, the cognitive effort, measured as the amount of time spent in order to decide which bundle to keep, also increases. Specifically, both the mean and variance of time spent increases as the value of k increases for HEF-k questions. Notice that in an HEF-0 question, the participant already has the highest valued bundle and this is readily verifiable since all goods are visible. However, as k increases, the participant must reason about and form beliefs about how the hidden goods may be allocated to the other pirates. The task of computing and deciding whether it may be worth swapping for another pirate\u2019s bundle therefore becomes increasingly more complex as more goods are hidden.\nPerceived envy on swap-is-opt questions under different treatments. Figure 9 presents the swap rates for swap-is-opt questions, where the participant would envy the bundle of another pirate. Recall that HEF-0 is equivalent to envy-free, so there are no such questions when swap-is-opt. Depending on the treatment, eliminating the participant\u2019s envy requires either the hypothetical removal of an item from the envied pirate in the case of the sEF1 and EF1 treatments, or hiding some goods from the envied pirate\u2019s bundle for the HEF-k treatment.\nAs Figure 9 shows, swap rates are significantly lower under the HEF-k treatment than the sEF1 and EF1 treatments. This supports our overall conclusion that participants desire allocations that are not evidently\nunfair. Since all goods are visible under the sEF1 and EF1 treatments, the participant has clear evidence that their allocated bundle has a lower value than that of another pirate. This is not as evident under the HEF-k treatment, where the participant\u2019s bundle has a higher value than the visible portion of other pirate\u2019s bundles due to some goods being hidden.\nCognitive effort on stay-is-opt questions. As Figure 10 shows for stay-is-opt questions, hiding goods under the HEF-k treatment comes at the cost of an increased cognitive burden on the participants. Here, the participant\u2019s bundle has the highest value. This is evident for the sEF1 and EF1 treatments, but may not be clear under the HEF-k treatment, where goods may need to be hidden in order to eliminate envy between the other pirates.\nPerceived envy of swap-is-opt versus stay-is-opt questions under different treatments. Table 2 depicts the ratio of swap rates for swap-is-opt versus stay-is-opt questions under different treatments. Notably, there is a statistically significant difference between swap-is-opt and stay-is-opt for all treatments (except for HEF-0, for which there are no swap-is-opt questions).\nPerceived envy comparing HEF-k treatments. Table 3 depicts the results of our primary hypothesis test comparing the independence of swap rates and treatments, for the pairwise treatments of HEF-0, HEF-1, and HEF-2, and adjusting for different variables. These results complement Table 1 and demonstrate \u03c72 statistics and associated p-values. Notably, there is a statistically significant difference between HEF-0 and both HEF-1 and HEF-2 for all questions, although there is no significant difference between the treatments conditioning on either stay-is-opt or swap-is-opt. By Figure 3, this suggests HEF-0 (i.e., envy-free) allocations are perceived as more fair than either HEF-1 or HEF-2 allocations.\nStatistical Significance of Cognitive Effort We test whether cognitive effort, measured by participants\u2019 response times per question and reported difficulty, varies by treatment. Specifically, we check whether the mean response time or reported difficulty on a five-point Likard scale is different between pairs of treatments, adjusting for different variables such as (i) Optimal Choice: whether the reward maximizing choice is to stay with the allocated bundle (stay-is-opt) and (ii) Instance Size: small or large. Null Hypothesis: The mean cognitive effort (by response time or reported difficulty) is equal across treatments. Alternate Hypothesis: The mean cognitive effort differs between pairs of treatments.\nOur experiments provide statistically significant evidence to reject the null hypothesis that cognitive effort for HEF-k is the same as either sEF1 or sEF1, using a two-sided Welch t-test at a significance level of \u03b1 = 0.001. Table 4 and Table 5 summarize our findings for response times per question and reported feedback, respectively.\nEffect Size We supplement our results of statistical significance with their effect sizes. Table 6, Table 7, Table 8, Table 9, and Table 10 demonstrate the effect size for each statistically significant test for Table 1, Table 2, Table 3, Table 4, and Table 5 respectively. Effect sizes are measured with Cramer\u2019s V for \u03c72 tests Crame\u0301r [1946] and Cohen\u2019s d for Welch t-tests Cohen [1992]."
        }
    ],
    "title": "Hide, Not Seek: Perceived Fairness in Envy-Free Allocations of Indivisible Goods",
    "year": 2023
}