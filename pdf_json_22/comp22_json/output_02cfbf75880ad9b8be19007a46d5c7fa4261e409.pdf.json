{
    "abstractText": "Fall detection and classification become an imperative problem for healthcare applications particularity with the increasingly ageing population. Currently, most of the fall classification algorithms provide binary fall or no-fall classification. For better healthcare, it is thus not enough to do binary fall classification but to extend it to multiple fall events classification. In this work, we utilize the privacy mitigating human skeleton data for multiple fall events classification. The skeleton features are extracted from the original RGB images to not only mitigate the personal privacy, but also to reduce the impact of the dynamic illuminations. The proposed fall events classification method is divided into two stages. In the first stage, the model is trained to achieve the binary classification to filter out the no-fall events. Then, in the second stage, the deep neural network (DNN) model is trained to further classify the five types of fall events. In order to confirm the efficiency of the proposed method, the experiments on the UP-Fall dataset outperform the state-of-the-art.",
    "authors": [
        {
            "affiliations": [],
            "name": "Leiyu Xie"
        },
        {
            "affiliations": [],
            "name": "Yang Sun"
        },
        {
            "affiliations": [],
            "name": "Jonathon A. Chambers"
        },
        {
            "affiliations": [],
            "name": "Syed Mohsen Naqvi"
        }
    ],
    "id": "SP:54d6107a9f607ea9bbd02d86ca43a33db4c406ff",
    "references": [
        {
            "authors": [
                "M. Yu",
                "L. Gong",
                "S. Kollias"
            ],
            "title": "Computer vision based fall detection by a convolutional neural network",
            "venue": "Proceedings of the 19th ACM International Conference on Multimodal Interaction, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "M. Yu",
                "Y. Yu",
                "A. Rhuma",
                "S.M. Naqvi",
                "L. Wang",
                "J.A. Chambers"
            ],
            "title": "An online one class support vector machine-based person-specific fall detection system for monitoring an elderly individual in a room environment",
            "venue": "IEEE Journal of Biomedical and Health Informatics, vol. 17, no. 6, pp. 1002\u20131014, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "X. Wang",
                "J. Ellul",
                "G. Azzopardi"
            ],
            "title": "Elderly fall detection systems: A literature survey",
            "venue": "Frontiers in Robotics and AI, vol. 7, pp. 71\u201394, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "T.-H. Tsai",
                "C.-W. Hsu"
            ],
            "title": "Implementation of fall detection system based on 3d skeleton for deep learning technique",
            "venue": "IEEE Access, vol. 7, pp. 153049\u2013153059, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Mubashir",
                "L. Shao",
                "L. Seed"
            ],
            "title": "A survey on fall detection: Principles and approaches",
            "venue": "Neurocomputing, vol. 100, pp. 144\u2013152, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "H. Jiang",
                "C. Cai",
                "X. Ma",
                "Y. Yang",
                "J. Liu"
            ],
            "title": "Smart home based on wifi sensing: A survey",
            "venue": "IEEE Access, vol. 6, pp. 13317\u201313325, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A. Abobakr",
                "M. Hossny",
                "S. Nahavandi"
            ],
            "title": "A skeleton-free fall detection system from depth images using random decision forest",
            "venue": "IEEE Systems Journal, vol. 12, no. 3, pp. 2994\u20133005, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Yan",
                "F. Angelini",
                "S.M. Naqvi"
            ],
            "title": "Image segmentation based privacy-preserving human action recognition for anomaly detection",
            "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "F. Angelini",
                "Z. Fu",
                "Y. Long",
                "L. Shao",
                "S.M. Naqvi"
            ],
            "title": "2d pose-based real-time human action recognition with occlusion-handling",
            "venue": "IEEE Transactions on Multimedia, vol. 22, no. 6, pp. 1433\u20131446, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "L. Mart\u0131\u0301nez-Villase\u00f1or",
                "H. Ponce",
                "J. Brieva",
                "E. Moya-Albor",
                "J. N\u00fa\u00f1ez- Mart\u0131\u0301nez",
                "C.Pe\u00f1afort-Asturiano"
            ],
            "title": "Up-fall detection dataset: A multimodal approach",
            "venue": "Sensors, vol. 19, no. 9, pp. 1988\u20132103, 2019.",
            "year": 1988
        },
        {
            "authors": [
                "E. Auvinet",
                "C. Rougier",
                "J.Meunier",
                "A. St-Arnaud",
                "J. Rousseau"
            ],
            "title": "Multiple cameras fall dataset",
            "venue": "2010.",
            "year": 2010
        },
        {
            "authors": [
                "X. Ma",
                "H. Wang",
                "B. Xue",
                "M. Zhou",
                "B. Ji",
                "Y. Li"
            ],
            "title": "Depth-based human fall detection via shape features and improved extreme learning machine",
            "venue": "IEEE journal of biomedical and health informatics, vol. 18, no. 6, pp. 1915\u20131922, 2014.",
            "year": 1915
        },
        {
            "authors": [
                "B. Kwolek",
                "M. Kepski"
            ],
            "title": "Human fall detection on embedded platform using depth maps and wireless accelerometer",
            "venue": "Computer Methods and Programs in Biomedicine, vol. 117, no. 3, pp. 489\u2013501, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "A. N\u00fa\u00f1ez-Marcos",
                "G. Azkune",
                "I. Arganda-Carreras"
            ],
            "title": "Visionbased fall detection with convolutional neural networks",
            "venue": "Wireless Communications and Mobile Computing, vol. 2017, pp. 1\u201316, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "N. Zerrouki",
                "F. Harrou",
                "Y. Sun",
                "A. Houacine"
            ],
            "title": "Vision-based human action classification using adaptive boosting algorithm",
            "venue": "IEEE Sensors Journal, vol. 18, no. 12, pp. 5115\u20135121, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "P.S. Sase",
                "S.H. Bhandari"
            ],
            "title": "Human fall detection using depth videos",
            "venue": "International Conference on Signal Processing and Integrated Networks (SPIN), 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Liu",
                "Y. Deng",
                "C. Jia",
                "Y. Yang",
                "R. Wang",
                "C. Li"
            ],
            "title": "Two-stream graph convolutional networks for 2d skeleton-based fall detection",
            "venue": "International Symposium on Computational Intelligence and Industrial Applications (ISCIIA), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Jeong",
                "S. Kang",
                "I. Chun"
            ],
            "title": "Human-skeleton based fall-detection method using LSTM for manufacturing industries",
            "venue": "International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC), 2019.",
            "year": 2019
        },
        {
            "authors": [
                "H. Ramirez",
                "S.A. Velastin",
                "I. Meza",
                "E. Fabregas",
                "D. Makris",
                "G. Farias"
            ],
            "title": "Fall detection and activity recognition using human skeleton features",
            "venue": "IEEE Access, vol. 9, pp. 33532\u201333542, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "H.-S. Fang",
                "S. Xie",
                "Y.-W. Tai",
                "C. Lu"
            ],
            "title": "RMPE: Regional multiperson pose estimation",
            "venue": "International Conference on Computer Vision, ICCV, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. Northcutt",
                "L. Jiang",
                "I. Chuang"
            ],
            "title": "Confident learning: Estimating uncertainty in dataset labels",
            "venue": "Journal of Artificial Intelligence Research, vol. 70, pp. 1373\u20131411, 2021.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Fall classification, skeleton features, deep neural network, privacy mitigating\nI. INTRODUCTION\nIn recent decades, falls in elderly have become one of the most important problems in the increasingly ageing population [1], [2]. Over 6 million falls occur each year in the world, making it the primary reason leading to the death of elderly people [3], [4]. Different types of fall events lead to different injuries in the human body parts. Thus it is not enough to do the binary fall classification but also multiple fall events classification is needed for better healthcare.\nMany approaches have been used for fall events classification. However, most of them are based on wearable sensors and it is inconvenient for ageing people to wear the sensors all the time, particularly when the dementia problem is also increased in elderly people [5], [6]. In this work, a video sensor will be used for the proposed method. To mitigate the privacy information, only skeleton data are extracted from the original RGB data, which can effectively mitigate the personal information and also reduce the dynamic illumination effect on the performance [7], [8]. Meanwhile, using only the skeleton\ndata extracted from the original RGB data, can also reduce the computational cost because the skeleton data size is much smaller than RGB data to be processed [9]. Moreover, different from other human activities recognition tasks, fall is one kind of dangerous activity for elderly people that seldom occurs in the real living environment. Thus the data in the real life datasets are imbalanced.\nThe dramatic impact of deep learning in recent years has greatly changed the landscape, e.g. improved the performance in many relevant tasks, such as object detection and human activities recognition. In order to mitigate the privacy mitigating and imbalanced data problem mentioned above, we propose a two-stage framework which only requires the human skeleton data for multiple fall events classification. This novel approach takes advantage of the DNN for fall events classification. In the first stage, the model will be trained with binary labels to classify the fall and no-fall. In the second stage, the framework will be applied for the multiple fall events classification based on the prior knowledge of fall from the first stage. We verify the effectiveness of the proposed framework on the UP-Fall dataset [10].\nThe outline of the paper is as follows. Section 2 provides the related work about fall detection and the related datasets. Section 3 presents the proposed two-stage fall classification framework. The detailed experimental settings and framework performance are shown in Section 4. Finally, Section 5 concludes the work."
        },
        {
            "heading": "II. RELATED DATASETS AND WORKS",
            "text": "In this section, recently used public fall datasets and methods are briefly discussed. The Multicam dataset is one of the well-known fall detection datasets which contains 24 different scenarios with 8 cameras in the different field of views in the data recording room [11]. In this dataset, the first 22 scenarios contain both fall and confounding events. The remaining 2 scenarios only contain confounding events.\nar X\niv :2\n20 8.\n12 02\n7v 1\n[ cs\n.C V\n] 2\n5 A\nThe SDU-Fall dataset has 6 different actions with 10 subjects, one of the actions is falling to the ground [12]. UR-Fall is a relatively small scale dataset and recorded by 2 Microsoft Kinect cameras, which has 70 sequences of human activities [13]. The UP-Fall dataset is a large scale dataset in the fall detection area which includes 5 different fall events and 6 human normal activities. In total, 17 subjects are recorded by 2 Microsoft Kinect cameras [10]. Therefore, the UP-Fall dataset is used to do the fall classification in this work.\nIn [4], the researchers use the depth information as the input to do the binary fall detection rather than the multiple fall events classification task. By using the optical flow data, [14] propose a transfer learning method to address the fall detection on UR-Fall and Multicam datasets. In [15], an adaptive AdaBoost classifier is used to detect fall events which occur in the UR-Fall dataset. Then, a fall detection framework based on the depth video is proposed for both SDU-Fall and URFall datasets [16]. A two-stream graph convolutional method, which contains both Cartesian and polar representations is proposed for skeleton data to detect binary fall [17]. By using the feature-extraction methods described in [18], long short term memory (LSTM) is used to improve the accuracy of the fall-detection system. Recently, with the UP-Fall dataset, five widely-used classifiers: K-nearest neighbour (KNN), support vector machine (SVM), multilayer perceptron (MLP), random forest (RF) and Adaboost have been applied for fall detection on skeleton data achieving promising performance [19]. Therefore, the proposed method is compared with [19] in this work."
        },
        {
            "heading": "III. PROPOSED METHOD",
            "text": "Most of the fall detection methods are for binary fall classification. However, there are many kinds of fall events,\nsuch as forward falling, backward falling, which will lead to different types of injuries in human body parts. Therefore, in order to provide better healthcare for elderly people, it is crucial to enable multiple fall events classification rather than conventional binary fall classification. Therefore, we design a two-stage fall events classification framework to address the multiple fall events classification problem with privacy mitigating human skeleton data."
        },
        {
            "heading": "A. First Stage: Binary Fall Classification (BFC)",
            "text": "Due to the imbalanced data problem, the fall events classification performance will be negatively affected when trained with the normal activities data. Hence, in the BFC stage, one DNN model is trained with all available training samples in the dataset. To categorize the events into two types: fall and no-fall, processed binary labels are used as training target. The aim of the BFC is to filter out the no-fall events for eliminating the imbalanced data problem. Fall events can lead to serious danger to the health and life of elderly people, thus it is important for the model trained in the BFC stage that it can find most of the fall events and the recall measure is high.\nMoreover, we compare the recall measure for the trained DNN and the trained RF, because the RF achieves the best performance in [19]. The corresponding results are shown in\nTable 1. The comparison results confirm that the DNN is the better choice to select the inner model of the proposed method.\nSince it is a binary classification in the BFC stage. Therefore we used binary cross entropy shown in equation (1) as the loss function. In order to overcome the information loss in the network layers, we use multiple weighted outputs in different\nMethod No. of FallsDetected / Ground Truth Recall\nDNN 1788 / 1803 0.96 RF [19] 1605 / 1803 0.86\nlayers as sub-outputs to reuse the information.\nlossa = \u2212 3\u2211\ni=1\n\u03c9i(yi \u00b7 log(y\u0302i) + (1\u2212 yi) \u00b7 log(1\u2212 y\u0302i)) (1)\nwhere \u03c9i represents the loss weight of ith sub-output. yi, y\u0302i indicate the ground truth and estimation for samples in the ith sub-output, respectively. lossa represents the loss function for the BFC model. The weight ratio of the sub-outputs is 1:1:2. Moreover, in the the DNN model, Sigmoid is used as the activation function of the output layer."
        },
        {
            "heading": "B. Second Stage: Multiple Fall Events Classification (MFEC)",
            "text": "After the DNN model in the BFC stage is trained, we obtain a subset of training data, which only contains the fall events. Then, the second DNN model is trained with the new training subset. Different from the BFC stage, the labels of the subset are the types of fall events. The second model is specifically trained to address the MFEC problem.\nSince the performance of the proposed method mostly depends on the BFC stage performance. Therefore the errors in the BFC stage would be maximally prevented. In order to reduce the classification errors, two thresholds m and n are\nused for two types of misclassifications, i.e. false positive and false negative.\nlossb = \u2212 3\u2211\ni=1\n\u03c9i(yi \u00b7 log(y\u0302i)) (2)\nThe classification task is for multiple events, therefore the sparse categorical cross entropy loss function is used in the MFEC, as shown in equation (2). Weighted sub-outputs are also applied. Final loss function of MFEC is the combination of the sub-output losses and the weight ratio of the sub-outputs is 1:1:2. Sigmoid will be also used as the activation function of the output layer in the end of the model.\nOnce both models in the proposed method are trained. In the testing stage, the testing sample is fed into the binary model in BFC firstly, if the sample is classified as the fall-event, consequentially, it is fed into the multi-class fall classification model in MFEC to obtain the specific fall event category. The proposed method is presented in Algorithm 1."
        },
        {
            "heading": "IV. EXPERIMENTAL RESULTS",
            "text": ""
        },
        {
            "heading": "A. Dataset and Pre-processing",
            "text": "There are 17 subjects recorded in the UP-Fall dataset and 11 types of human activities are included, which have 5 different types of fall events as shown in Table 2. The remainder of them are normal human activities. In order to enlarge the size of the dataset, each subject\u2019s activities are recorded for 3 trials.\nIn the UP-Fall dataset, there are some blank frames, with no subject. Therefore, those blank frames are removed in the pre-processing step. Then, the AlphaPose is used to extract the human skeleton data from the RGB image data [20]. Each skeleton dataset contains 17 key points for one subject and each key point contains 2D coordinates and confidence score. Since the UP-Fall dataset is recorded in the lab which has one glass wall. The people walking in the corridors and the glass reflection of the subjects are also recorded in the data. These non-experimental subjects\u2019 skeletons can provide negative impact to the model performance. To overcome this problem, we use a distance score to filter the noisy skeleton data. The distance between subject and camera has the positive correlation with the distance score. Only the skeleton data in all frames with the largest distance score is kept and the noisy skeleton data is removed.\nSince the UP-Fall dataset annotations are manual and semiautomatic, we introduce confident learning [21] to achieve the annotation cleaning and remove the samples with high probability being mislabelled. Finally, there are 217,405 groups\nof skeleton data in total. We split the whole dataset into two sub-groups, i.e. the training set and the testing set. There are 152,183 groups in the training set and 65,222 groups in the testing set. In the MFEC stage, for the multiple fall events classification model, there are 4,417 groups for the training set and 1,894 groups for the testing set."
        },
        {
            "heading": "B. Parameters Setting",
            "text": "There are 9 dense layers in the proposed DNN model. The ReLU is used as the model inner activation function and batch normalization is also used. The concatenation is applied in the proposed DNN model. In both stages of the proposed model, Adam is applied as the optimizer for data training.\nIn the training stage, we set the learning rate as 0.0001. The batch size of the BFC model is 1024 and for the second training stage is 32. The training epoch of the BFC model is 300, and for the multiple fall events classification model in the MFEC stage is 600. In order to prevent the error classification results from the BFC stage, which can affect the performance in MFEC stage. We set the threshold m as 0.03 and n as 0.02 for misclassification correction. The experiments are conducted on a work station with 4 GeForce GTX 1080Ti GPUs, and 16GB of RAM."
        },
        {
            "heading": "C. Results and Discussion",
            "text": "In Table 1, we already show that the DNN outperforms RF in terms of the BFC. We only present the results of proposed multiple fall events classification (MFEC) in this section. Moreover, we compare the five classifiers used in [19] for the MFEC in Fig. 2, which show that the RF is the best classifier in terms of the performance.\nFirstly, we compare the single RF with the single DNN in Table 3. It can be observed that the single DNN can achieve better classification performance for BF, SF and SDF. With the proposed two-stage DNN (TS-DNN), the overall multiple events classification performance is further improved. Meanwhile, no thresholds are added into the TS-DNN which is shown in Table 3 (m = 0 and n = 0). However, the hands falling (HF) performance is lower than the single model. We\nassume the reason is the misclassification of the binary fall classification model in the BFC stage. Therefore, two thresholds m and n will be used to re-classify the misclassification of fall and no-fall categories in the BFC stage, which could improve the fall events performance in the MFEC stage.\nAccording to Table 4, it can be observed that after adding the thresholds, the TS-DNN shows better performance than without thresholds shown in Table 3. The proposed TS-DNN with thresholds (m = 0.03 and n = 0.02) further improves the F1-score in terms of HF and KF. It is confirmed that the performance of both HF and KF which include misclassification in the BFC stage are revised and improved.\nIn summary, according to the F1-score, generally, it is confirmed that the proposed two-stage framework can achieve the highest accuracy in multiple fall events classification. After the DNN-based binary classifier is introduced in the BFC stage, the data imbalanced problem is eliminated and the multi-class classifier can be better trained in the MFEC stage. Besides, adding thresholds in the BFC stage could help to improve the classification performance of the MFEC stage."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "In this paper, based on the skeleton data extracted from UP-Fall dataset, we proposed a novel two-stage DNN-based framework to achieve the multiple fall events classification. By using skeleton data, the dynamic illumination and privacy mitigating issues were addressed. Then, in the proposed BFC stage of the proposed method, both the imbalanced classification and binary fall classification are performed. Finally, the multiple fall events classification problem is performed in the MFEC stage. The experimental results confirmed the proposed method could earn higher classification accuracy compared with the state-of-the-art classifiers."
        }
    ],
    "title": "Two-stage Fall Events Classification with Human Skeleton Data",
    "year": 2022
}