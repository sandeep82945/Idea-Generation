{
    "abstractText": "We consider the quantum multiple hypothesis testing problem, focusing on the case of hypothesis represented by pure states. A sequential adaptive algorithm is derived and analyzed first. This strategy exhibits a decay rate in the error probability with respect to the expected value of measurements greater than the optimal decay rate of the fixed-length methods. Amore elaborated scheme is developed next, by serially concatenating multiple implementations of the first scheme. In this case each stage considers as a priori hypothesis probability the a posteriori probability of the previous stage. We show that, by means of a fixed number of concatenations, the expected value of measurements to be performed decreases considerably. We also analyze one strategy based on an asymptotically large concatenation of the initial scheme, demonstrating that the expected number of measurements in this case is upper bounded by a constant, even in the case of zero average error probability. A lower bound for the expected number of measurements in the zero error probability setting is also derived. INDEX TERMS Quantum sensing, quantum hypothesis testing, fixed-length algorithms, adaptive algorithms.",
    "authors": [
        {
            "affiliations": [],
            "name": "JORDI P\u00c9REZ-GUIJARRO"
        }
    ],
    "id": "SP:a40e179eb56d9f478a164635aae0f9c33a6ed4fe",
    "references": [
        {
            "authors": [
                "L.Wang andR. Renner"
            ],
            "title": "One-shot classical-quantum capacity and hypothesis testing",
            "venue": "Phys. Rev. Lett., vol. 108, May 2012, Art. no. 200501.",
            "year": 2012
        },
        {
            "authors": [
                "A. Ac\u00edn",
                "J. Bae",
                "E. Bagan",
                "M. Baig",
                "L. Masanes",
                "R. Mu\u00f1oz-Tapia"
            ],
            "title": "Secrecy properties of quantum channels",
            "venue": "Phys. Rev. A, Gen. Phys., vol. 73, no. 1, Jan. 2006, Art. no. 012327.",
            "year": 2006
        },
        {
            "authors": [
                "K.M.R. Audenaert"
            ],
            "title": "Discriminating states: The quantum Chernoff bound",
            "venue": "Phys. Rev. Lett., vol. 98, Apr. 2007, Art. no. 160501.",
            "year": 2007
        },
        {
            "authors": [
                "M. Nussbaum",
                "A. Szko\u0142a"
            ],
            "title": "The Chernoff lower bound for symmetric quantum hypothesis testing",
            "venue": "Ann. Statist., vol. 37, no. 2, pp. 1040\u20131057, Apr. 2009. 4B(n, p) denotes a binomial distribution with parameters n \u2208 N, and p \u2208 (0, 1). VOLUME 10, 2022 13825 J. P\u00e9rez-Guijarro et al.: Quantum Multiple Hypothesis Testing Based on Sequential Discarding Scheme",
            "year": 2009
        },
        {
            "authors": [
                "H. Chernoff"
            ],
            "title": "A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations",
            "venue": "Ann. Math. Statist., vol. 23, no. 4, pp. 493\u2013507, 1952.",
            "year": 1952
        },
        {
            "authors": [
                "K. Li"
            ],
            "title": "Discriminating quantum states: The multiple chernoff distance",
            "venue": "Ann. Statist., vol. 44, no. 4, pp. 1661\u20131679, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "A. Ac\u00edn",
                "E. Bagan",
                "M. Baig",
                "L. Masanes",
                "R.M. Tapia"
            ],
            "title": "Multiplecopy two-state discrimination with individual measurements",
            "venue": "Phys. Rev. A, Gen. Phys., vol. 71, Mar. 2005, Art. no. 032338.",
            "year": 2005
        },
        {
            "authors": [
                "J. Calsamiglia",
                "J.I. de Vicente",
                "R. Mu\u00f1oz-Tapia",
                "E. Bagan"
            ],
            "title": "Local discrimination ofmixed states,\u2019\u2019Phys",
            "venue": "Rev. Lett., vol. 105,",
            "year": 2010
        },
        {
            "authors": [
                "E. Mart\u00ednez Vargas",
                "C. Hirche",
                "G. Sent\u00eds",
                "M. Skotiniotis",
                "M. Carrizo",
                "R. Mu\u00f1oz-Tapia",
                "J. Calsamiglia"
            ],
            "title": "Quantum sequential hypothesis testing",
            "venue": "Phys. Rev. Lett., vol. 126, no. 18, May 2021, Art. no. 180502.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Li",
                "F. Tan",
                "andM. Tomamichel"
            ],
            "title": "Optimal adaptive strategies for sequential quantum hypothesis testing",
            "venue": "2021, arXiv:2104.14706.",
            "year": 2021
        },
        {
            "authors": [
                "H. Nagaoka"
            ],
            "title": "The converse part of the theorem for quantum Hoeffding bound",
            "venue": "2006, arXiv:quant-ph/0611289.",
            "year": 2006
        },
        {
            "authors": [
                "T. Ogawa",
                "M. Hayashi"
            ],
            "title": "On error exponents in quantum hypothesis testing",
            "venue": "IEEE Trans. Inf. Theory, vol. 50, no. 6, pp. 1368\u20131372, Jun. 2004.",
            "year": 2004
        },
        {
            "authors": [
                "J. Calsamiglia",
                "R. Mu\u00f1oz-Tapia",
                "L. Masanes",
                "A. Acin",
                "E. Bagan"
            ],
            "title": "Quantum Chernoff bound as a measure of distinguishability between density matrices: Application to qubit and Gaussian states",
            "venue": "Phys. Rev. A, Gen. Phys., vol. 77, no. 3, Mar. 2008, Art. no. 032311.",
            "year": 2008
        },
        {
            "authors": [
                "K.M.R. Audenaert",
                "M. Mosonyi"
            ],
            "title": "Upper bounds on the error probabilities and asymptotic error exponents in quantum multiple state discrimination",
            "venue": "J. Math. Phys., vol. 55, no. 10, Oct. 2014, Art. no. 102201.",
            "year": 2014
        },
        {
            "authors": [
                "I.D. Ivanovic"
            ],
            "title": "How to differentiate between non-orthogonal states",
            "venue": "Phys. Rev. A, Gen. Phys., vol. 123, no. 6, pp. 257\u2013259, Jan. 1987.",
            "year": 1987
        },
        {
            "authors": [
                "D. Dieks"
            ],
            "title": "Overlap and distinguishability of quantum states",
            "venue": "Phys. Lett. A, vol. 126, nos. 5\u20136, pp. 303\u2013306, Jan. 1988.",
            "year": 1988
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS Quantum sensing, quantum hypothesis testing, fixed-length algorithms, adaptive algorithms.\nI. INTRODUCTION The task of discriminating between hypothesis is essential in a wide variety of scientific fields. In particular, the quantum hypothesis testing problem has an important role in quantum information theory with applications to quantum communication [1] and cryptography [2]. Existing techniques that solve this testing problem can be classified into fixed-length methods, which measure a predetermined number of copies or samples of the state, and sequential schemes, where the number of copies is variable and depends on a stopping criterion. Moreover, a hypothesis test for quantum states is adaptive when the measurement procedure of a given state copy depends on the outcome of the measurements of the previous samples.\nFixed-lengthmethods are themost extensively studied type of strategies. The optimal method in terms of error probability was presented in the seminal works of Helstrom [3] and Holevo [4] in the late 70s, and makes use of a collective\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Abdullah Iliyasu .\nmeasure of all the state copies. In the binary case with states {\u03c31, \u03c32} and L samples, the probability of error is given by 1 2 ( 1\u2212 \u2225\u2225\u2225\u03c01\u03c3\u2297L1 \u2212 \u03c02\u03c3\u2297L2 \u2225\u2225\u22251), where \u03c0i denotes the a priori probability of hypothesis i [3].\nThe results presented in [5], [6] show that the decay rate associated with this error probability, i.e., the exponent of the error probability as L goes to infinity, is CQ(\u03c31, \u03c32) = \u2212 log ( min0\u2264s\u22641 Tr(\u03c3 s1\u03c3 1\u2212s 2 ) ) , which defines the quantum Chernoff distance between two quantum states. This expression generalizes the classical result where the maximum decay rate is given by C(p1, p2) = \u2212 log ( min0\u2264s\u22641 \u2211 i(p1(i) sp2(i)1\u2212s) ) [7]. More recently, [8] shows that for a fixed-length scheme the maximum decay rate in the discrimination of N quantum states is mini,j:i6=j CQ(\u03c3i, \u03c3j).\nIn general, the maximum decay rate is achieved by means of collective quantum measurements which are difficult to implement. This motivates the quest for techniques that limit themaximum number of states to bemeasured jointly. Specifically, authors in [9] propose a method for binary state dis-\nVOLUME 10, 2022 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 13813\ncrimination that measures each copy individually using an adaptive strategy, and attains the minimum error probability achievable with collective measurements. This result does not hold however for the case of two non-pure states, where the maximum decay rate is strictly lower than the quantum Chernoff distance [10].\nAn alternative strategy to fixed-length procedures are the variable-length or sequential techniques where the number of state copies to be measured depends on a stopping criterion and is typicallymodeled as a random variable. The error probability of sequential schemes is hence assessed in terms of the expected value of the number of copies required. In fact [11], [12] show that, for the binary case, the asymptotic rate of the error probability of sequential techniques might decay faster than for fixed-length methods.\nIn particular, [11] uses an optimal classical method called Sequential Probability Ratio Test where the algorithm stops and decides a hypothesis when the a posteriori probability of the state associated to this hypothesis is above a given threshold. The asymptotic rate of the error probability of first kind, p(H\u03022|H1), and second kind, p(H\u03021|H2), attain the optimal values given by D(\u03c31||\u03c32) and D(\u03c32||\u03c31), where D(\u00b7||\u00b7) is the quantum relative entropy,1 even though not simultaneously. An adaptive sequential strategy is adopted in [12], and the asymptotic rate decays of D(\u03c31||\u03c32) and D(\u03c32||\u03c31) are achieved simultaneously for errors of the first and second kind, respectively. The latter is impossible using fixed-length schemes due to the Quantum Hoeffding Bound [13], [14], which implies that if the decay rate of the first kind error is D(\u03c32||\u03c31) then the rate of the second kind will be 0 (or alternatively decay rate of D(\u03c31||\u03c32) of the second kind error and 0 of the first).\nIn this paper we focus on sequential methods for the multiple hypothesis testing problem and present an adaptive sequential scheme, named Sequential Discarding Method (SDM), that attains an asymptotic decay rate with respect to the expected value of measurements higher than mini,j:i6=j CQ(\u03c3i, \u03c3j). Unlike the techniques in [11], [12], the number of required state copies in the proposed method is random but bounded for any given error probability. It is further shown that by applying the SDM method c times in a serial fashion, the expected value of measurements to be performed decreases from O(ln 1/ ) to O(ln(c) 1/ ), where is the mean error probability and ln(c)(\u00b7) indicates c-times composition of the ln(\u00b7) function. Interestingly, we show that the expected number of samples is bounded even in the case of zero error probability.\nThe paper is organized as follows. In section II we introduce the problem of quantum hypothesis testing, and present the Sequential Discarding Method. Next, in section III the performance of the SDM algorithm is analyzed. Specifically, three aspects are studied, the number ofmeasurements L, ana-\n1 The quantum relative entropy is defined as D(\u03c3 ||\u03c1) := Tr (\u03c3 (log \u03c3 \u2212 log \u03c1)) if supp(\u03c3 ) \u2286 supp(\u03c1), and D(\u03c3 ||\u03c1) := \u221e otherwise, where the support of state \u03c3 is the subspace spanned by the eigenvectors, |\u03c6k \u3009, with associated eigenvalues \u03bbk > 0.\nlyzing its probability mass function and expected value; the average error probability; and the decay rate of the average error probability for large values of LU . In section IV the serial concatenation of SDMalgorithms is presented, yielding new strategies with a significant reduction in the number of measurements. In section V, numerical experiments are performed supporting our theoretical findings. Conclusions are drawn in section VI.\nII. QUANTUM HYPOTHESIS TESTING The problem of quantum hypothesis testing for pure states consists in the discrimination of the true hypothesis among a set {Hs}Ns=1. Hypothesis Hs corresponds to the observation of the pure quantum state2 \u03c3s = |\u03c8s\u3009 \u3008\u03c8s| \u2208 D(H), where D(H) represents the set of density operators acting on the Hilbert spaceH. Each hypothesis occurs with prior probability {\u03c0s}Ns=1. Without loss of generality, the states are assumed sorted by decreasing probability, i.e., \u03c01 \u2265 \u03c02 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03c0N . It is also assumed that an unlimited number of copies of the unknown state can be measured before taking a decision.\nQuantum state measurements are modelled through Positive Operator-Valued Measure (POVM), each of which contains P operators. We then denote the POVM by the set L = {3x}Px=1, the outcome of which is x \u2208 [1 : P]. Recall that the probability that a measurement of state \u03c3 using POVM L gives outcome x is equal to Tr(3x\u03c3 ), where Tr(\u00b7) is the trace operator. When measuring different copies of a given quantum state, xi represents the measurement outcome associated to the ith copy, and vector xm = [x1 x2 . . . xm]T gathers measurements from 1 to m. The decision taken as the true hypothesis is denoted by random variable (r.v.) D, a particular realization of which is expressed as d \u2208 [1 : N ]. The total number of measured copies of the quantum state is denoted by integer L. In fixed-length schemes L is a constant. However, in sequential schemes, e.g. [12] and the one we present in this paper, L is a r.v. and realizations of this r.v. are denoted by l.\nA. BINARY HYPOTHESIS TEST: UNANIMITY VOTE This section describes the unanimity vote method [9], which solves the binary hypothesis test problem for N = 2 pure states, as an introduction to the scheme presented later in Section II-B. The unanimity vote strategy belongs to the set of fixed-length techniques, i.e., it measures a fixed number L of copies of the unknown state and takes a decision about the true hypothesis, d \u2208 {1, 2}, afterwards. The POVM used for the L measurements is L = {31,32} = {|\u03c81\u3009 \u3008\u03c81| , I \u2212 |\u03c81\u3009 \u3008\u03c81|} with \u03c01 \u2265 \u03c02 and where I is the identity operator. Hypothesis H1 (or, equivalently, d = 1) is decided if all measurements are equal to 1, i.e., {xi = 1 ; \u2200i = 1, . . . ,L}; otherwise, H2 is assumed true. Denoting by E the error event, the probability of error of this scheme is\np(E) = \u03c02 | \u3008\u03c81| |\u03c82\u3009 |2L (1) 2We refer to a pure quantum state by |\u03c8\u3009 or \u03c3 = |\u03c8\u3009 \u3008\u03c8 |, indistinctly.\n13814 VOLUME 10, 2022\nwhich has an optimal asymptotic behaviour, since the decay rate associated to the error exponent as L \u2192 \u221e, coincides with the quantum Chernoff distance [9]. This follows from the fact that CQ(\u03c31, \u03c32) = \u2212 log Tr(\u03c31\u03c32) if at least one of the two states is pure [15].\nNote that the number of measurements might be reduced without increasing the error probability by taking a decision as soon as one measurement outcome is equal to 2, so that state |\u03c81\u3009 can be discarded. This means that, in fact, the unanimity vote method can be reformulated as a sequential strategy with a stopping condition given by either measurement xi = 1 is obtained for all i \u2208 [1,L], or any measurement gives xi = 2 and thus the unanimous measurement outcome is not reached.\nB. MULTIPLE HYPOTHESIS TEST: SEQUENTIAL DISCARDING The previous observation motivates the proposed scheme, named sequential discarding method (SDM), which solves the multiple hypothesis testing problem, with N \u2265 2 hypothesis, by discarding states in a sequential manner. The SDM method defines a total of (N \u2212 1) POVM sets, each of which includes only two operators, i.e., P = 2, as\nL(k) = {3(k)1 ,3 (k) 2 }\n= {|\u03c8k \u3009 \u3008\u03c8k | , I \u2212 |\u03c8k \u3009 \u3008\u03c8k |} (2)\nfor k \u2208 [1 : N \u2212 1]. Note that each POVM L(k) is matched to one quantum state |\u03c8k \u3009 and the outcome of the measurements are xi \u2208 {1, 2}. The definition of the POVM in (2) is motivated by the fact that when L(k) is used to measure state |\u03c8k \u3009, the measurement outcome is deterministic and equal to 1. Clearly, state |\u03c8k \u3009 can be discarded if any measurement outcome is different from 1 when L(k) is used.\nThe SDM scheme proceeds as follows. It starts by measuring with POVM L(1) associated with state |\u03c81\u3009. Additional measurements using the same POVM are performed unless either onemeasurement output is different from 1, or outcome 1 is unanimously obtained after LU measurements, where LU \u2208 N is a predefined parameter of themethod. If the second event occurs, decision d = 1 is taken and the method stops. If, on the contrary, one measurement xi = 2 is obtained, state |\u03c81\u3009 is discarded as the true hypothesis, and the algorithm is repeated using POVM L(2). Again, if measurement xi = 1 is obtained LU times, decision d = 2 is taken and the method stops; otherwise, i.e., if one measurement yields xi = 2, state |\u03c82\u3009 is discarded. The procedure is iterated for increasing state indexes up to index (N \u2212 1) until, either the stopping condition is reached, i.e. xi = 1 is obtained LU times with the same POVM, or all states except |\u03c8N \u3009 are discarded, so that the decision becomes d = N . A pseudo-code of the SDM scheme, denoted byMSDM (LU ), is given in Algorithm 1. Interestingly, the SDM scheme falls within the set of adaptive sequential methods but uses the predefined collection of POVMs shown in (2), unlike other adaptive methods that\nAlgorithm 1 SDM SchemeMSDM (LU ) Input: The observed state \u03c3s = |\u03c8s\u3009 \u3008\u03c8s|, parameter LU , and POVMs {L(k)}N\u22121k=1 . Output: Decision d . k = 1 Nrep = 0 while k < N and Nrep < LU do\nMeasure state \u03c3s with L(k) yielding outcome x if x=1 then\nNrep = Nrep + 1 else\nNrep = 0 k = k + 1\nend if end while d = k\nsolve an optimization problem to redesign the POVM at each iteration as, for instance, in [12].\nIII. PERFORMANCE ANALYSIS In this section the performance of the SDM algorithm is analyzed, initially in terms of the required number of measurements and later looking into the average error probability. As in other sequential methods, the number of measurements L is a r.v. so that we study its probability mass function and expected value in the large sample regime, defined as LU \u2192\u221e. Afterwards, the average error probability of SDM is obtained and the decay rate for increasing values of LU is evaluated.\nA. NUMBER OF MEASUREMENTS The number of measurements made by the SDM algorithm is a r.v. that can be expressed as\nL =  LU if d = 1 L1 + \u00b7 \u00b7 \u00b7 + Ld\u22121 + LU if 2 \u2264 d \u2264 N \u2212 1 L1 + \u00b7 \u00b7 \u00b7 + LN\u22121 if d = N (3)\nwhere Lk \u2208 [1 : LU ] is a r.v. that denotes the number of measurements using L(k), if this POVM is used. Therefore, L can be lower and upper bounded as follows\nmin {LU ,N \u2212 1} \u2264 L \u2264 LU (N \u2212 1) (4)\nThe lower bound is the minimum between LU and (N \u2212 1), which are the number of measurements in two different situations: (a) d = 1 because the first LU measurements are equal to 1, i.e. {xi = 1; \u2200i = 1, . . . ,LU }; and (b) states {|\u03c8s\u3009} N\u22121 s=1 are discarded, each after one single measurement, implying {xi = 2; \u2200i = 1, . . . ,N\u22121} and, {Li = 1; \u2200i = 1, . . . ,N\u22121} and therefore d = N . The upper bound in (4) corresponds also to the case when d = N , so that states {|\u03c8s\u3009} N\u22121 s=1 are discarded, but in this case after LU measurements each, i.e., {Li = LU ; \u2200i = 1, . . . ,N \u2212 1}. We are interested in the performance analysis of the SDM scheme in the large sample\nVOLUME 10, 2022 13815\nregime, defined in our case when LU \u2192 \u221e. Assuming a limited number of states N , the upperbound in (4) shows that the SDM method might need an infinite number of copies only when LU \u2192 \u221e. The following theorem assesses the behaviour of the expected value of L, denoted by E[L], in terms of LU in the large sample regime. Theorem 1: The expected value of number of measurements L of the SDM scheme in Algorithm 1 satisfies\nlim LU\u2192\u221e E[L] LU = 1\u2212 \u03c0N (5)\nProof: See Appendix A. This result implies that E[L] in SDM increases proportionally with LU with a factor equal to (1 \u2212 \u03c0N ), where \u03c0N is the minimum among all the a priori state probabilities. Note that if the states had been sorted by increasing probability (instead of decreasing), this factor would be smaller, but then, as we show later in Section III-C, the decay rate of the error probability would also be smaller.\nAs a complementary result, next corollary shows the moments of L in the large sample regime. Corollary 1.1: The wth-order moment of the number of measurements L of the SDM scheme in Algorithm 1 satisfies\nlim LU\u2192\u221e E[Lw] LwU = 1\u2212 \u03c0N (6)\nProof: See Appendix B. For illustrative purposes, Figure 1 shows the normalized histogram of L computed after 10.000 realizations of SDM algorithm with N = 3, \u03c01 = \u03c02 = \u03c03 = 13 , and LU = 100. Clearly, the number of measurements tends to be concentrated in two intervals. This particular shape of the probability mass function of L, denoted by pL(l), is justified by the following theorem. Theorem 2: There exist \u03b1, \u03b2 \u2208 R+ with \u03b2 < 1 such that\npL(l) \u2264 (1\u2212 pD(N ))\u03b1\u03b2 l\u2212LU u(l \u2212 LU )+ pD(N )\u03b1\u03b2 lu(l)\n(7)\nwhere u(a) = 1{a \u2265 0} and pD(N ) is the probability of deciding state N .\nProof: See Appendix C. Note that \u03b1\u03b2 l\u2212ku(l \u2212 k) is an exponentially decaying window in the interval l \u2208 [k, k + 1], where 1 depends on \u03b2. Consequently, expression (7) shows that pL(l) is mostly concentrated in the intervals [1,1] and [LU ,LU +1].\nB. AVERAGE PROBABILITY OF ERROR The average probability of error is given by\np(E) = N\u2211 d=1 pE |D(E |d)pD(d) (8)\nwhere E denotes the error event and D the decision regarding the true hypothesis. Similarly, the conditional error probability pE |D(E |d) can be expressed as\npE |D(E |d) = N\u2211 s=1 pE |D,S (E |d, s)pS|D(s|d)\n= N\u2211 s=1 s6=d pS|D(s|d) (9)\nwhere S is the r.v. that represents the index of the observed state, and the second equality follows by pE |D,S (E |d, s) = 1{d 6= s}. Using Bayes theorem and the fact that in the SDM algorithm pD|S (d |s) = 0 \u2200d > s, (9) becomes\npE |D(E |d) = N\u2211\ns=d+1\npD|S (d |s) pD(d) \u03c0s (10)\nSubstituting (10) in (8), we get\np(E) = N\u22121\u2211 d=1 N\u2211 s=d+1 pD|S (d |s)\u03c0s (11)\nThen, noting that Tr(|\u03c8d \u3009 \u3008\u03c8d | \u03c3s)LU = Tr(\u03c3d\u03c3s)LU is the probability of obtaining outcome xi = 1 LU times when POVM L(d) is used, the conditional probabilities pD|S (d |s) for d \u2208 [1,N \u2212 1] are equal toTr(\u03c31\u03c3s) LU if d = 1 Tr(\u03c3d\u03c3s)LU \u220fd\u22121\nj=1\n( 1\u2212 Tr(\u03c3j\u03c3s)LU ) if d > 1\n(12)\nThe expression of pD|S (d |s) for d > 1 comes from the observation that \u220fd\u22121 j=1 ( 1\u2212 Tr(\u03c3j\u03c3s)LU ) is the probability of discarding the states {|\u03c8i\u3009} d\u22121 i=1 , and Tr(\u03c3d\u03c3s)\nLU is the probability of deciding d once lower indexed states are discarded. Substituting (12) in (11), the probability of error becomes p(E) = N\u2211 s=2 \u03c0sTr(\u03c31\u03c3s)LU + N\u22121\u2211 d=2 N\u2211 s=d+1 \u03c0sTr(\u03c3d\u03c3s)LU\n\u00d7 d\u22121\u220f j=1 ( 1\u2212 Tr(\u03c3j\u03c3s)LU ) (13)\n13816 VOLUME 10, 2022\nSince 0 < Tr(\u03c3d\u03c3s) < 1 for d 6= s, all terms of the sum decrease exponentially with LU and, hence, the average error probability also decreases exponentially with LU . This observation is further supported by the following proposition, to be used in next subsection where the decay rate of error probability is assessed. Proposition 1: The average probability of error p(E) of the SDM algorithm is upper and lower bounded as\nBL max i,j:i6=j Tr(\u03c3i\u03c3j)LU \u2264 p(E) \u2264 BU max i,j:i6=j Tr(\u03c3i\u03c3j)LU (14)\nwhere BL ,BU \u2208 R+ and BL < BU . Proof: See Appendix D.\nC. DECAY RATE OF THE AVERAGE ERROR PROBABILITY The asymptotic decay rate of p(E) as LU tends to infinity is defined as\nlim LU\u2192\u221e \u2212 ln p(E) LU\n(15)\nTo compute this limit we first observe that, using Proposition 1, the ratio can be lower and upper bounded as follows\n\u2212 lnBU LU + min i,j:i6=j\n{ \u2212 ln Tr(\u03c3i\u03c3j) } \u2264 \u2212 ln p(E) LU \u2264 \u2212 lnBL LU + min i,j:i6=j { \u2212 ln Tr(\u03c3i\u03c3j) } (16)\nwhich implies that\nlim LU\u2192\u221e \u2212 ln p(E) LU = min i,j:i6=j\n{ \u2212 ln Tr(\u03c3i\u03c3j) } (17)\nAs the quantum Chernoff distance, in the case that at least one state is pure, can be written as CQ(\u03c31, \u03c32) = \u2212 ln Tr(\u03c31\u03c32) [15], the decay rate with respect to LU becomes\nlim LU\u2192\u221e \u2212 ln p(E) LU = min i,j:i6=j CQ(\u03c3i, \u03c3j) (18)\nWe are also interested in assessing the decay rate of the average error probability with respect to the expected number of samples, defined as\nlim LU\u2192\u221e \u2212 ln p(E) E[L]\n(19)\nApplying the product rule of the limit, (19) can be expressed as\nlim LU\u2192\u221e LU E[L] lim LU\u2192\u221e \u2212 ln p(E) LU\n(20)\nsince both limits are finite. Then, using (5) from Theorem 1 and (18), the final result is obtained\nlim LU\u2192\u221e \u2212 ln p(E) E[L] = mini,j:i6=j CQ(\u03c3i, \u03c3j) 1\u2212 \u03c0N (21)\nThis decay rate differs only in the factor 1/(1 \u2212 \u03c0N ) with respect to the optimal fixed-lengthmethod. Interestingly, since (1\u2212\u03c0N ) < 1, the decay rate with respect to the expected number of measurements of the sequential discarding method\nis greater than the optimal decay rate of the fixed-length strategies.\nIt is worth noting that the decay rate obtained in (21) remains valid even if one of the states is not pure. In this scenario, the index of themixed statemust beN , and therefore no POVM associated with this state needs to be defined.\nIV. SERIAL CONCATENATION OF SDM ALGORITHMS In this section we study how the serial concatenation of sequential discarding methods can be employed to yield a newmeasuring strategy by properly transferring the posterior probabilities of the states. The concatenation operation of two SDM algorithms, namely MSDM (LU ,1) and MSDM (LU ,2), consists of:\n1) Indexing states in increasing order of a priori probability. 2) Executing algorithm MSDM (LU ,1). The number of measurements performed in this stage is denoted l1. 3) Computing the posterior probabilities pS|X l1 (s|x l1 ) and\nreordering them in increasing order. In case any posterior probability is zero, the associated state is discarded and the total number of states is reduced. 4) Executing MSDM (LU ,2) using pS|X l1 (s|x l1 ) as a priori probability for each possible state.\nThis procedure can be iterated to concatenate an arbitrary number of SDM algorithms (see Appendix E details). Our analysis assesses the expected number of measurements in two cases: (i) when a predetermined number of SDM stages are concatenated; and (ii) when the number of concatenated SDM algorithms can be arbitrarily large such that the probability of error can be made equal to zero.\nA. NUMBER OF MEASUREMENTS WITH SERIAL CONCATENATION In this subsection, we first study the expected number of measurements when two SDM algorithms are concatenated. This value is then compared to the expected number of measurements obtained with a single SDM algorithm. Finally, the result is generalized to the case when multiple SDM algorithms are concatenated."
        },
        {
            "heading": "1) NUMBER OF MEASUREMENTS WITH TWO SDMs",
            "text": "Expression (21) implies that, for a sufficiently large value of LU ,1, the expected number of measurements required by MSDM (LU ,1) is\nE[L1] ' 1\u2212maxs\u2208[1:N ] \u03c0s mini,j:i6=j CQ(\u03c3i, \u03c3j) ln ( 1 1 ) , (22)\nwhere \u03c0s for s \u2208 [1 : N ] is the a priori state probability and 1 is the average probability of error of MSDM (LU ,1). Assuming thatMSDM (LU ,1) performs l1 measurements, then the a priori probabilities for MSDM (LU ,2) are given by the posteriors pS|X l1 (s|x\nl1 ). Consequently, the expected total number of measurements required by the concatenation of MSDM (LU ,1) andMSDM (LU ,2), conditioned by the fact that\nVOLUME 10, 2022 13817\nl1 measurements were performed in the first one, is given by E [ L|x l1 ] = E [ L2|x l1 ] + l1\n' 1\u2212maxs pS|X l1 (s|x\nl1 ) mini,j:i6=j CQ(\u03c3i, \u03c3j) ln ( 1 2 ) + l1 (23)\nwhere 2 is the probability of error of MSDM (LU ,2) using a priori state probabilities equal to pS|X l1 (s|x\nl1 ). The expected total number of measurements, E[L], of this two stage concatenation scheme can be computed taking the expected value of (23) with respect to x l1 as follows\nE[L] = EXL1 [ E [ L|x l1 ]] ' EXL1 [ 1\u2212maxs pS|X l1 (s|x l1 ) ]\nmini,j:i6=j CQ(\u03c3i, \u03c3j) ln ( 1 2 ) + EXL1 [l1]\n(24) Note that EXL1 [ 1\u2212maxs pS|X l1 (s|x l1 ) ] is the probability of error of the first SDM algorithmwhen using aMAP criterion. Hence,\nEXL1 [ 1\u2212max\ns pS|X l1 (s|x\nl1 ) ] \u2264 1 (25)\nSubstituting (25) in (24), the expected total number of measurements becomes upper bounded as\nE[L] \u2264 1 mini,j:i6=j CQ(\u03c3i, \u03c3j) ln ( 1 2 ) + EXL1 [l1]\n' 1\nmini,j:i6=j CQ(\u03c3i, \u03c3j)\n( 1 ln ( 1 2 ) + 0 ln ( 1 1 )) (26)\nwhere the approximation follows from (22) denoting 0 := 1\u2212 \u03c0N ."
        },
        {
            "heading": "2) COMPARISON WITH A SINGLE SDM",
            "text": "In order to assess the expected number of measurements required by the concatenation of two SDM algorithms, as compared to a single SDM, we fix the probability of error to a given value . Note that this value corresponds to 2 in the two-stage concatenation scheme since the decision is taken only after the second stage.\nAgain, using (21), for a sufficiently large value of LU the expected number of measurements of one single SDM is\nE[L] ' 0 mini,j:i6=j CQ(\u03c3i, \u03c3j) ln ( 1 ) , (27)\nwhere 0 = 1 \u2212 \u03c0N . Therefore, comparing (27) with (26) and substituting 2 = , the two stage concatenation strategy requires a smaller expected number of measurements if 1 is designed such that\n1 ln ( 1 ) + 0 ln ( 1 1 ) < 0 ln ( 1 ) (28)\nIn general there exist a range of values 1 that fulfill the previous inequality. Specifically, if 1 is set equal to\n\u22171 = argmin 0< 1<1\n( 1 ln ( 1 ) + 0 ln ( 1 1 )) =\n0 ln ( 1 ) (29) then the expected measurement number can be upper bounded as\nE[L] \u2264 0\nmini,j:i6=j CQ(\u03c3i, \u03c3j)\n( 1+ ln ln ( 1 ) + ln ( 1 0 )) \u2264 0\nmini,j:i6=j CQ(\u03c3i, \u03c3j)\n( ln ln ( 1 ) +\n1 0\n) (30)\nwhere the second inequality follows from ln (1/ 0) \u2264 1/ 0\u2212 1. It is important to note that 1 cannot take any arbitrary value since it depends on parameter LU ,1, which must be integer. That is, a value LU ,1 such that 1 takes exactly the optimal value, \u22171 = 0/ ln ( 1 ) , does not exist in general. However, by taking LU ,1 as the smallest natural number that fulfills 1 \u2264 \u22171 , the upper bound of the expected number of measurements grows as O(ln ln 1/ ) as well.\nFor illustrative purposes, Figure 2 plots the normalized histogram of L when one single SDM with LU = 125 is used (upper plot) and when 2 SDM algorithms are concatenated (lower plot). A total of 105 realizations are evaluated and the average error probability is set to = 2.5 \u00b7 10\u22129. The states and prior probabilities are the same as the ones used in Figure 1 i.e., N = 3 and \u03c01 = \u03c02 = \u03c03 = 1/3. Parameters LU ,1 and LU ,2 are computed as the smallest integers such that 1 < 0\nln ( 1 ) and 2 < . The approximated probability mass function p\u0302L(l) for the two stage concatenated strategy is mostly concentrated near the origin where two maxima appear. The first maximum is associated with the scenario whereMSDM (LU ,1) decides d = N . As for the second maximum, it comes from the case where MSDM (LU ,2) discards N\u22121 states and therefore the decision\n13818 VOLUME 10, 2022\nhas a zero probability of error. The difference between both maxima is approximately LU ,1 = 21. Moreover, we can see that exists another region of values of l, around l \u2248 LU ,1+LU ,2, which is probable. This is due to the double band effect shown in Figure 1. Remarkably, the expected number of measurements of the two stage concatenation strategy is reduced by a factor of 1/3 in comparison with the single SDM strategy."
        },
        {
            "heading": "3) NUMBER OF MEASUREMENTS WITH MULTIPLE SDMs",
            "text": "The expression of the expected number of measurements obtained by the concatenation of two sequential discarding methods given in (30) can be generalized by mathematical induction to an arbitrary number of stages. The resulting expected number of measurements is given by\nE[L] \u2264 0 mini,j:i6=j CQ(\u03c3i, \u03c3j) ln(c)\n( 1 ) + O(c) (31)\nwhere is the intended average error bound at the final stage, and ln(c)(\u00b7) indicates c-times composition of the ln(\u00b7) function.\nAt the induction step, a concatenation of c SDM stages is built by adding one SDM block as the first stage to an existing concatenation of c \u2212 1 SDM stages. We assume the expected number of measurements of the c\u22121 concatenation is bounded by\nE[L] \u2264 0 mini,j:i6=j CQ(\u03c3i, \u03c3j) ln(c\u22121)\n( 1 ) + O(c\u2212 1) (32)\nHence, following an analogous procedure to the one shown in (26), the expected number of measurements of the c stage concatenation becomes upper bounded by\nE[L] \u2264 1 mini,j:i6=j CQ(\u03c3i, \u03c3j) ln(c\u22121)\n( 1 ) + 0\nmini,j:i6=j CQ(\u03c3i, \u03c3j) ln ( 1 1 ) + O(c\u22121) (33)\nwhere the optimal probability of error of the additional SDM stage is \u22171 = 0 ln(c\u22121) 1 . Substituting this value in (33), expression (31) is obtained. In a nutshell, comparing (27) to (31) the number of measurements can be reduced from O(ln 1/ ) to O(ln(c) 1/ ) using a concatenation of c SDM algorithms, where denotes the average error probability.\nB. NUMBER OF MEASUREMENTS FOR ZERO ERROR PROBABILITY In this section, we let the number of SDM stages c to be arbitrarily large so that the algorithm only finishes once N \u2212 1 states are discarded, which yields a zero probability of error. Note that in this case inequality (31) cannot be used to study the expected number of measurements since the upper bound tends to infinite.\nThe conducted analysis is summarized in Theorem 3 and 4 which provide an upper and lower bound for the expected number of measurements, respectively.\nTheorem 3: The expected number of measurements, E[L], of an asymptotically large concatenation of SDM stages, all of which use LU ,min \u2264 LU ,i \u2264 LU ,max , is bounded as\nE[L] \u2264 LU ,max(N \u2212 1) (\n1 p+ + 1\n) \u2212 LU ,max (34)\nwhere p+ = 12 (1\u2212maxi,j:i6=j Tr(\u03c3i\u03c3j) LU ,min ).\nProof: Since zero error probability is required, all except one of the possible states must be discarded. This requires at most LU ,max measurements per state yielding a total of at most (N \u2212 1)LU ,max measurements. In addition, all SDM stages MSDM (LU ,i), except the final one, end up with a non-discarding measurement and, therefore, use LU ,i measurements each. The total number of required measurements is then upper bounded by\nL \u2264 LU ,max(N \u2212 1)+ Ce\u22121\u2211 i=1 LU ,i \u2264 LU ,max(N \u2212 2+ Ce)\n(35)\nwhere Ce is a r.v. that denotes the number of stages used. As shown in appendix F, the expected number of required SDM stages E[Ce] satisfies\nE[Ce] \u2264 N \u2212 1 p+\n(36)\nTherefore, E[L] \u2264 LU ,max(N \u2212 1) (\n1 p+ + 1\n) \u2212 LU ,max (37)\nTheorem 4: Any algorithm that decides with certainty the\nobserved hypothesis, Hs, i.e., with p(E) = 0, fulfills that\nE[L] \u2265 N\u2211 s=1 \u03c0s N\u2211 i=1 i6=s 1 1\u2212 | \u3008\u03c8s| |\u03c8i\u3009 |2\n(38)\nif all the POVM used belong to the set {L(k)}Nk=1 given in (2). Proof: The expected value of measurements can be computed as\nE[L] = N\u2211 s=1 \u03c0sE[L|s] (39)\nSince we require p(E) = 0, all states except s must be discarded when the true state is s. Since POVM {L(k)}Nk=1 can discard only one state, E[L|s] satisfies\nE[L|s] \u2265 N\u2211 i=1 i6=s E[Mi|s] (40)\nwhere Mi denotes the number of measurements used to discard state i when POVM L(i) = {|\u03c8i\u3009 \u3008\u03c8i| , I \u2212 |\u03c8i\u3009 \u3008\u03c8i|} is used. The inequality follows since additional non-discarding\nVOLUME 10, 2022 13819\nmeasures can also be performed. The value of E[Mi|s] is given by\nE[Mi|s] = \u221e\u2211\nmi=1\nmi ( 1\u2212 | \u3008\u03c8s| |\u03c8i\u3009 |2 ) | \u3008\u03c8s| |\u03c8i\u3009 | 2(mi\u22121)\n= 1\n1\u2212 | \u3008\u03c8s| |\u03c8i\u3009 |2 (41)\nwhich implies that\nE[L] \u2265 N\u2211 s=1 \u03c0s N\u2211 i=1 i6=s 1 1\u2212 | \u3008\u03c8s| |\u03c8i\u3009 |2\n(42)\nSetting LU ,i equal in all stages, i.e. LU ,min = LU ,max = LU , then the gap between upper and lower bounds in Theorem 3 and 4 is minimized for LU = 1. This result follows since the lower bound does not depend on LU , and the upper bound can be expressed as\n(N \u2212 1) \u00b7 gT \u2217 (LU )+ LU \u00b7 (N \u2212 2) (43)\nwhere T \u2217 = maxi,j:i6=j Tr(\u03c3i\u03c3j), and gT (LU ) is given by\ngT (LU ) = 2LU\n1\u2212 T LU , (44)\nwhich is an increasing function on LU , \u2200T \u2208 [0, 1). Figure 3 shows the empirical average of the number of measurements when the number of SDM stages is arbitrarily large until p(E) = 0, and both the upper and lower bounds obtained in Theorem 3 and 4 for different values of LU . Interestingly, the expected number of measurements of the asymptotically large concatenation strategy only moderately increases with LU . Also, it is clear that the upper bound is not tight for large values of LU .\nC. NUMBER OF MEASUREMENTS WITH MIXED STATES The reduction in the number of expected measurements obtained by the concatenation of multiple SDM stages can also be achieved when quantum states are mixed if certain requirements are met. In particular we can generalize the previous results to the multiple hypothesis testing problem for mixed states, denoted by {\u03c1s}Ns=1, \u03c1s \u2208 D(H), provided 3 supp(\u03c1i) * supp(\u03c1j) \u2200i 6= j, or equivalently, D(\u03c1i||\u03c1j) = \u221e \u2200i 6= j. To show this, we consider the spectral decomposition of\n\u03c1k = \u2211 q \u03bb k q \u2223\u2223\u2223\u03c6kq \u232a \u2329\u03c6kq \u2223\u2223\u2223 and POVM {5k , I\u22125k}, where5k =\u2211 q:\u03bbkq>0\n\u2223\u2223\u2223\u03c6kq \u232a \u2329\u03c6kq \u2223\u2223\u2223 is the projection onto the support of \u03c1k . Proceeding as in Section III, it is not difficult to show that the decay of (21) becomes\nlim LU\u2192\u221e \u2212 ln p(E) E[L] = \u2212 lnmaxi,j:i<j Tr\n( 5i\u03c1j ) 1\u2212 \u03c0N\n(45)\nNote that maxi,j:i<j Tr(5i\u03c1j) < 1 since supp(\u03c1i) * supp(\u03c1j) \u2200i 6= j. Using (45), similar results to the ones presented in Section IV-A and IV-B can be obtained. In particular, the expected number of measurements when c SDM stages are concatenated is upper bounded by\nE[L] \u2264 0 \u2212 lnmaxi,j:i<j Tr ( 5i\u03c1j\n) ln(c) (1 ) + O(c), (46)\nFinally, the expected number of measurements of an asymptotically large concatenation of SDM stages, all of which use LU ,min \u2264 LU ,i \u2264 LU ,max , is bounded by\nE[L] \u2264 LU ,max(N \u2212 1) (\n1 p+ + 1\n) \u2212 LU ,max (47)\nwhere p+ = 12 (1\u2212maxi,j:i<j Tr(5i\u03c1j) LU ,min ).\nV. NUMERICAL EXPERIMENTS This section includes simulations that support our theoretical findings, both of the SDM algorithm and of the serial concatenation of SDM algorithms.\nFigure 4 shows results of the SDM algorithm with N = 3 and states |\u03c8i\u3009 = cos ( \u03b8i 2 ) |0\u3009 + ej\u03c6i sin ( \u03b8i 2 ) |1\u3009, with\n\u03c61 = 5.40 rad, \u03c62 = 0.45 rad, \u03c63 = 5.91 rad\n\u03b81 = 2.63 rad, \u03b82 = 2.21 rad, \u03b83 = 1.91 rad\nThe a priori state probabilities are \u03c01 = \u03c02 = \u03c03 = 13 . Specifically, 104 simulations of the SDM algorithm are run for each value of LU in the interval [1 : 300]. In each simulation, the average probability of error is computed using (13) and the number of measurements L is saved. Using these results, a histogram of L for each value of LU is obtained, and represented using the gray scale on the right of the figure. For comparison, the optimal number of measurements for a fixedlengthmethod, the estimated expected value ofmeasurements of the SDM method, E[L], and its theoretical value on the large sample regime given in (5) are also indicated.\n3 The support of a quantum state \u03c1k is the subspace spanned by its eigenvectors \u2223\u2223\u2223\u03c6kq \u232a with positive associated eigenvalues, i.e. \u03bbkq > 0. 13820 VOLUME 10, 2022\nFigure 4 shows that the expected value of samples is very close to the asymptotic theoretical value. Moreover, the expected value of measurements is significantly smaller than the number of samples used by a fixed-length method for the same average probability of error.\nFigure 5 compares the expected value of measurements of the SDM scheme, the serial concatenation of SDM stages with c \u2208 {2, 3}, and the optimal fixed-length method. The states and their a priori probability are the same as the ones used in the previous example. Clearly, the expected number of measurements for the serial concatenation scheme is significantly smaller than the others.\nFinally, Figure 6 illustrates the quotient between E[L] and the lower bound shown in Theorem 4, when an arbitrarily large concatenation of SDM algorithms is used. This ratio is calculated for different values of prior probabilities {\u03c01, \u03c02, \u03c03}, i.e, for coordinate values inside triangle co({[1, 0, 0], [0, 1, 0], [0, 0, 1]}), where co(\u00b7) denotes the convex hull operator. For each value of the a priori\nprobabilities, the method is run 5000 times to obtain an estimate of E[L]. As shown in Figure 6, for a priori probabilities close to the vertices, the expected number of measurements is approximately equal to the lower bound in Theorem 4, that is, the method is approximately optimal in terms of expected number of measurements. As for less informative prior probabilities, that is, those probability values represented close to the center of the triangle, a moderate increase in the number of measurements is obtained, specifically E[L] is 1.7 times higher than the lower bound in Theorem 4.\nVI. CONCLUSION This article demonstrates that sequential discarding methods for the discrimination of pure states, even when simple binary projective measurements are employed, can yield a sub-logarithmic increase of the expected number of measurements with respect to the error probability. The measuring strategy that achieves this decay rate consists of the concatenation of multiple stages of the SDM algorithm. This result also applies to the discrimination of mixed states under certain restrictions on their respective support subspaces. Moreover, this work also shows that, when a single SDM stage is used, the number of measurements required to reach a given probability of error is similar to the one required by the optimal fixed-length strategy, and smaller on average for sufficiently small error probability. Furthermore, in the case of employing an asymptotically large concatenation of SDM stages, the expected value ofmeasurements remains bounded, even in the case of zero error probability.\nAPPENDIX A EXPECTED VALUE OF L IN THE LARGE SAMPLE REGIME The large sample regime is defined as LU \u2192\u221e and thus we assume LU > (N \u2212 1). The expected value of the number of measurements E[L] can be expressed as\nE[L] := LU (N\u22121)\u2211 l=N\u22121 l pL(l)\nVOLUME 10, 2022 13821\n= LU (N\u22121)\u2211 l=N\u22121 N\u2211 d=1 l pL|D(l|d)pD(d)\n= N\u2211 d=1 pD(d)EL|D[L|d] (48)\nwhere the first equality follows by the law of total probability, and the second by the definition of EL|D[L|d] :=\u2211LU (N\u22121)\nl=N\u22121 l pL|D(l|d), which denotes the average number of measurements when decision d is taken.\nLet us define a r.v. A, which denotes the number of measurements made before POVM L(d) is used and decision d is taken. This r.v. takes values\nA = { 0 if d = 1 L1 + L2 + \u00b7 \u00b7 \u00b7 + Ld\u22121 if 1 < d \u2264 N\n(49)\nSubstituting (49) in (3), the total number of measurements becomes\nL = { A+ LU if 1 \u2264 d < N A if d = N\n(50)\nConsequently, for 1 < d < N :\nEL|D[L|d] = LU (N\u22121)\u2211 l=N\u22121 l pL|D(l|d)\n= (d\u22121)LU\u2211 a=d\u22121 (a+ LU )pA|D(a|d)\n= LU + (d\u22121)LU\u2211 a=d\u22121 a pA|D(a|d) (51)\nIn the second equality we use the fact that, for a given decision d , A can take values between d \u2212 1 and LU (d \u2212 1). That is, A = d \u2212 1 when a single measurement is used to discard each of the d \u2212 1 previous states, and LU (d \u2212 1), when all previous states are discarded after LU measurements. Using (49) pA|D(a|d) becomes\npA|D(a|d) = \u2211\nld\u22121\u2208Ta\npL1|D(l1|d) \u00b7 \u00b7 \u00b7 pLd\u22121|D(ld\u22121|d) (52)\nwhere ld\u22121 := (l1, . . . , ld\u22121) and Ta = {ld\u22121 \u2208 Nd\u22121 : l1+\u00b7 \u00b7 \u00b7+ld\u22121 = a}. Since d \u2264 s \u2264 N , probabilities pLj|D(lj|d) are given by\npLj|D(lj|d) = N\u2211 s=d pLj|S,D(lj|s, d)pS|D(s|d)\n= N\u2211 s=d Tr(\u03c3j\u03c3s)lj\u22121 ( 1\u2212 Tr(\u03c3j\u03c3s) ) pS|D(s|d)\nwhere Tr(\u03c3j\u03c3s) = Tr( \u2223\u2223\u03c8j\u232a \u2329\u03c8j\u2223\u2223 \u03c3s) is the probability of obtaining the outcome x = 1 when POVM L(j) is used, and\npS|D(s|d) is the probability of observing state \u03c3s when d is decided. Substituting this result in (52) gives pA|D(a|d) = \u2211\nld\u22121\u2208Ta\nd\u22121\u220f j=1 N\u2211 s=d Tr(\u03c3j\u03c3s)lj\u22121\n\u00d7 ( 1\u2212 Tr(\u03c3j\u03c3s) ) pS|D(s|d) (53)\nNow the term d\u22121\u220f j=1 N\u2211 s=d Tr(\u03c3j\u03c3s)lj\u22121 ( 1\u2212 Tr(\u03c3j\u03c3s) ) pS|D(s|d) (54)\nwhich incorporates d \u2212 1 factors, can be expressed by the following sum of Nd = (N \u2212 d + 1)d\u22121 terms\nNd\u2211 i=1 ci \u00b7 \u03b2 l1\u22121 1,i \u03b2 l2\u22121 2,i \u00b7 \u00b7 \u00b7\u03b2 ld\u22121\u22121 d\u22121,i (55)\nwhere 0 < ci < 1 gathers the product of d \u2212 1 factors of the form ( 1\u2212 Tr(\u03c3j\u03c3s) ) pS|D(s|d), and 0 < \u03b2j,i < 1 is equal to Tr(\u03c3j\u03c3s). Defining \u03b2\u0302i := maxj \u03b2j,i then expression (55) can be upper bounded by\nNd\u2211 i=1 \u03b2\u0302a\u2212d+1i (56)\nsince l1 + \u00b7 \u00b7 \u00b7 + ld\u22121 = a. Noting that this upper bound does not depend on the element l(d\u22121), pA|D(a|d) in (53) can be then upper bounded by\npA|D(a|d) \u2264 Nd\u2211 i=1 |Ta|\u03b2\u0302a\u2212d+1i (57)\nwhere |Ta| is the cardinality of the set Ta. Substituting (57) in (51), we have\nEL|D[L|d] \u2264 LU + (d\u22121)LU\u2211 a=d\u22121 Nd\u2211 i=1 a|Ta|\u03b2\u0302a\u2212d+1i (58)\nNow, note that |Ta| is the number of solutions of equation a = l1 + l2 + \u00b7 \u00b7 \u00b7 + ld\u22121 for lj \u2208 N. Defining l\u0304j = (lj \u2212 1), we have \u2211d\u22121 j=1 l\u0304j = \u2211d\u22121 j=1 lj\u2212 d + 1 and, therefore, |Ta| also\namounts the number of solutions of \u2211d\u22121\nj=1 l\u0304j = a\u2212 d + 1 for l\u0304j \u2265 0. Then denoting v = a \u2212 d + 1, the cardinality of the set Ta is equal to\n|Ta| = ( v+ d \u2212 2\nv\n) = ( a\u2212 1\na\u2212 d + 1\n) , (59)\nwhere (x y ) = x! y!(y\u2212x)! . Substituting (59) in (58), we have\nEL|D[L|d]\n\u2264 LU + Nd\u2211 i=1 (d\u22121)LU\u2211 a=d\u22121 a ( a\u2212 1 a\u2212 d + 1 ) \u03b2\u0302a\u2212d+1i\n= LU + Nd\u2211 i=1 (d\u22121)LU\u2211 a=d\u22121 a! (a\u2212 d + 1)!(d \u2212 2)! \u03b2\u0302a\u2212d+1i\n13822 VOLUME 10, 2022\n\u2264 LU + Nd\u2211 i=1 1 (d \u2212 2)! \u221e\u2211 a=0 d\u22122\u220f j=0 (a\u2212 j)  \u03b2\u0302a\u2212d+1i where the second inequality follows increasing the range of the summation from [d\u22121, (d\u22121)LU ] to [0,\u221e). Next, using that\ndd\u22121\nd \u03b2\u0302d\u22121i \u221e\u2211 a=0 \u03b2\u0302ai = \u221e\u2211 a=0 d\u22122\u220f j=0 (a\u2212 j)  \u03b2\u0302a\u2212d+1i , (60) and \u2211 \u221e\na=0 u a = 1/(1\u2212 u) if |u| < 1, gives\nEL|D[L|d] \u2264 LU + Nd\u2211 i=1 d \u2212 1 (1\u2212 \u03b2\u0302i)d (61)\nSince L = LU for d = 1, the conditional expected value EL|D[L|d] for 1 \u2264 d < N is lower and upper bounded by\nLU \u2264 EL|D[L|d] \u2264 LU + Nd\u2211 i=1 d \u2212 1 (1\u2212 \u03b2\u0302i)d\nmeaning that\nlim LU\u2192\u221e EL|D[L|d] LU = 1 (62)\nfor d < N . The case d = N can be analyzed similarly, except for the fact that LU does not appear in EL|D[L|d = N ] since the algorithm stops if the other N \u22121 states have been discarded. Thus,\nN \u2212 1 \u2264 EL|D[L|N ] \u2264 NN\u2211 i=1 N \u2212 1 (1\u2212 \u03b2\u0302i)N\nwhich gives\nlim LU\u2192\u221e EL|D[L|N ] LU = 0 (63)\nResults (62) and (63) can be used to compute the limit\nlim LU\u2192\u221e E[L] LU = lim LU\u2192\u221e\n\u2211N d=1 EL|D[L|d]pD(d)\nLU\n= N\u2211 d=1 lim LU\u2192\u221e pD(d) lim LU\u2192\u221e EL|D[L|d] LU\n= N\u22121\u2211 d=1 lim LU\u2192\u221e pD(d) (64)\nUsing (12), it is not difficult to check that limLU\u2192\u221e pD(d) = \u03c0d , giving the final result and completing the proof.\nlim LU\u2192\u221e E[L] LU = N\u22121\u2211 d=1 \u03c0d = 1\u2212 \u03c0N (65)\nAPPENDIX B MOMENTS OF L IN THE LARGE SAMPLE REGIME This annex shows the proof of Collonary III-A. First, let\u2019s analyze, EL|D[Lw|d], when w > 1 and d < N , which can be expressed as EL|D[Lw|d] = LU (N\u22121)\u2211 l=N\u22121 lw pL|D(l|d)\n= (d\u22121)LU\u2211 a=d\u22121 (a+ LU )wpA|D(a|d) = LwU + w\u2211 i=1 Lw\u2212iu (w i ) (d\u22121)LU\u2211 a=d\u22121 ai pA|D(a|d)\n (66)\nwhere the second equality follows from (50), i.e., L = A+LU if d < N , and the third equality is obtained by expanding (a+ LU )w. Following an analogous procedure to the one shown in Appendix A, the following inequality is obtained\n(d\u22121)LU\u2211 a=d\u22121 ai pA|D(a|d) \u2264 qi,d (67)\nwhere qi,d is a positive constant. Therefore,\nLwU \u2264 EL|D[L w |d] \u2264 LwU + w\u2211 i=1 Lw\u2212iu ( w i ) qi,d\n= LwU + Qd (LU ) (68)\nwhere Qd is a polynomial of degree w \u2212 1. The case d = N can be computed using L = A instead of L = A+LU , to yield\nEL|D[Lw|N ] = (d\u22121)LU\u2211 a=d\u22121 awpA|D(a|d) \u2264 qw,N (69)\nHence, combining (68) and (69),\nlim LU\u2192\u221e EL|D[Lw|d] LwU = 1{d 6= N } (70)\nUsing (70), the limit of the ratio E[Lw]/LwU is computed as follows\nlim LU\u2192\u221e E[Lw] LwU = lim LU\u2192\u221e\n\u2211N d=1 EL|D[Lw|d]pD(d)\nLwU\n= N\u2211 d=1 lim LU\u2192\u221e pD(d) lim LU\u2192\u221e EL|D[Lw|d] LwU\n= N\u22121\u2211 d=1 lim LU\u2192\u221e pD(d) = 1\u2212 \u03c0N (71)\nwhere the last equality is obtained since limLU\u2192\u221e pD(d) = \u03c0d .\nVOLUME 10, 2022 13823\nAPPENDIX C BOUND OF THE PROBABILITY MASS FUNCTION OF L In order to prove Theorem 2, we hereafter derive the probability mass function of L, denoted by pL(l). According to (50), the total number of required measurements is given by\nL = { A+ LU if 1 \u2264 d < N A if d = N\n(72)\nThen, the probability mass function of L can be expressed as\npL(l) = N\u2211 d=1 pL|D(l|d)pD(d)\n= N\u22121\u2211 d=1 pA|D(l\u2212LU |d)pD(d)+ pA|D(l|N )pD(N ) (73)\nAs shown in equation (57) of Appendix A, there exist \u03b1, \u03b2 \u2208 R+ with \u03b2 < 1 such that pA|D(a|d) \u2264 \u03b1\u03b2au(a), where u(a) = 1{a \u2265 0}. Substituting this inequality in (73), the probability mass function of L can be upper bounded as follows\npL(l) \u2264 N\u22121\u2211 d=1 \u03b1\u03b2 l\u2212LU u(l \u2212 LU )pD(d)+ \u03b1\u03b2 lu(l)pD(N )\n= (1\u2212 pD(N ))\u03b1\u03b2 l\u2212LU u(l \u2212 LU )+ pD(N )\u03b1\u03b2 lu(l).\n(74)\nAPPENDIX D BOUNDS FOR THE PROBABILITY OF ERROR This appendix derives upper and lower bounds for the average error probability. The upper bound is obtained using equation (13) from section III \u2212 B: p(E) = N\u2211 s=2 \u03c0sTr(\u03c31\u03c3s)LU + N\u22121\u2211 d=2 N\u2211 s=d+1 \u03c0sTr(\u03c3d\u03c3s)LU\n\u00d7 d\u22121\u220f j=1 ( 1\u2212 Tr(\u03c3j\u03c3s)LU ) (75)\nSince \u220fd\u22121\nj=1\n( 1\u2212 Tr(\u03c3j\u03c3s)LU ) \u2264 1, the two sums can be\ncombined to yield an upper bound as\np(E) \u2264 N\u22121\u2211 d=1 N\u2211 s=d+1 \u03c0sTr(\u03c3d\u03c3s)LU (76)\nNow, using Tr(\u03c3d\u03c3s) \u2264 maxi,j:i6=j Tr(\u03c3i\u03c3j),\np(E) \u2264 max i,j:i6=j Tr(\u03c3i\u03c3j)LU N\u22121\u2211 d=1 N\u2211 s=d+1 \u03c0s\n= BU max i,j:i6=j\nTr(\u03c3i\u03c3j)LU (77)\nwhere BU = \u2211N\u22121 d=1 \u2211N\ns=d+1 \u03c0s. Similarly, for the lower bound, starting with the exact\nexpression for the average probability of error p(E) = N\u2211 s=2 \u03c0sTr(\u03c31\u03c3s)LU + N\u22121\u2211 d=2 N\u2211 s=d+1 \u03c0sTr(\u03c3d\u03c3s)LU\n\u00d7 d\u22121\u220f i=1 ( 1\u2212 Tr(\u03c3j\u03c3s)LU ) (78)\nSince all the elements of the sum are positive, the sum is greater or equal than any of its terms, in particular than the term corresponding to maxi,j:i6=j Tr(\u03c3i\u03c3j)LU . Also, as Tr(\u03c3i\u03c3j) < 1, or equivalently 1\u2212Tr(\u03c3i\u03c3j)LU > 1\u2212Tr(\u03c3i\u03c3j), the following bound is obtained\nP(E) \u2265 ( \u03c0j\ni\u22121\u220f l=1 ( 1\u2212 Tr(\u03c3l\u03c3j) )) max i,j:i6=j Tr(\u03c3i\u03c3j)LU (79)\nTherefore,\np(E) \u2265 BL max i,j:i6=j Tr(\u03c3i\u03c3j)LU (80)\nwhere BL = \u03c0j \u220fi\u22121\nl=1\n( 1\u2212 Tr(\u03c3l\u03c3j) ) .\nAPPENDIX E COMPUTATION OF POSTERIORS PROBABILITIES This annex shows the procedure followed to compute the posterior probabilities, pS|X l (s|x\nl). To do this, we rewrite pS|X l (s|x l) in terms of pS|X l\u22121(s|x l\u22121), thus obtaining a recursive expression.\npS|X l (s|x l) =\npS,X l\u22121,Xl (s, x l\u22121, xl)\npX l\u22121 (x l\u22121) pX l\u22121(x l\u22121) pX l (x l)\n= pS,Xl |X l\u22121(s, xl |x\nl\u22121)\npXl |X l\u22121(xl |x l\u22121)\n= pXl |X l\u22121,S (xl |x l\u22121, s)pS|X l\u22121 (s|x l\u22121)\u2211N\ns=1 pXl |X l\u22121,S (xl |x l\u22121, s)pS|X l\u22121(s|x l\u22121) = Tr ( 3xl (x l\u22121)\u03c3s ) pS|X l\u22121 (s|x\nl\u22121)\u2211N s=1 Tr ( 3xl (x l\u22121)\u03c3s ) pS|X l\u22121(s|x l\u22121) (81)\nwhere the first and second equalities follow from the definition of conditional probability, the third equality from the law of total probability, and the last step follows from substituting probabilities pXl |X l\u22121,S (xl |x\nl\u22121, s) by their corresponding values, i.e, Tr ( 3xl (x l\u22121)\u03c3s ) . Matrix3xl (x\nl\u22121) denotes the xl element of POVM L(x l\u22121), which depends on the previous outcomes x l\u22121. Using this recursive expression together with the rules defined by the implemented algorithm to decide the POVMs L(x l) \u2208 {L(k)}Nk=1, the posterior probabilities pS|X l (s|x\nl) can be computed.\nAPPENDIX F UPPER BOUND ON THE EXPECTED NUMBER OF STAGES FOR ZERO ERROR PROBABILITY This section shows that the average number of sequential discarding stages E[Ce] required to attain zero error probability is bounded. Note that we assume that LU ,min \u2264 LU ,i \u2264 LU ,max \u2200i.\n13824 VOLUME 10, 2022\nDenoting by N\u0304c the number of discarded states after the execution of the stages from 1 to c, we have:\nN\u0304c = c\u2211 i=1 n\u0304i = N\u0304c\u22121 + n\u0304c (82)\nwhere n\u0304c denotes the number of discarded states at stage c and N\u03040 := 0. Note that in general 0 \u2264 N\u0304c\u22121 < N \u2212 1 for c \u2264 Ce, since the method stops when N \u2212 1 states are discarded. Let us assume without loss of generality that N\u0304c\u22121 = 0, that is, no states where discarded in the previous stages, and that the state with the lowest probability after execution of state c\u2212 1 is s = 1, i.e., 1 = argmins pS|XLc\u22121 (s|x\nlc\u22121), where x lc\u22121 is the outcome from all measurements performed at stages up to c\u2212 1. Note that this implies\npS|XLc\u22121 (1|x lc\u22121 ) \u2264 1 2\n(83)\nsince the rest of the states must accumulate more probability. Then, the probability that at least one state is discarded at stage c can be expressed as\np(n\u0304c > 0) = p(dc 6= 1) (84)\nwhere dc indicates the decision taken at stage c. The equality follows since if a decision dc 6= 1 is taken, then at least state 1 is discarded. The probability p(n\u0304c > 0), taking into account all measurements completed before stage c, can then be written as\np(n\u0304c > 0) = 1\u2212 N\u2211 s=1 pDc|S (1|s)pS|XLc\u22121 (s|x lc\u22121) (85)\nNow, using pDc|S (1|s) = Tr(\u03c31\u03c3s) LU ,c (85) becomes\n1\u2212 pS|XLc\u22121 (1|x lc\u22121 )\n\u2212 N\u2211 s=2 Tr(\u03c31\u03c3s)LU ,cpS|XLc\u22121 (s|x lc\u22121) (86)\nThis expression is lower bounded by\n1\u2212 pS|XLc\u22121 (1|x lc\u22121 )\n\u2212 max j6=1\nTr(\u03c31\u03c3j)LU ,c (1\u2212 pS|XLc\u22121 (1|x lc\u22121 ))\n= (1\u2212 pS|XLc\u22121 (1|x lc\u22121 ))(1\u2212max j6=1 Tr(\u03c31\u03c3j)LU ,c ) (87)\nNow, combining equation (87) with (83) we can set the following lower bound,\np(n\u0304c > 0) \u2265 1 2\n( 1\u2212max\nj6=1 Tr(\u03c31\u03c3j)LU ,min ) \u2265\n1 2\n( 1\u2212 max\nj,i:j6=i Tr(\u03c3i\u03c3j)LU ,min\n) (88)\nParameter p+ := 12 ( 1\u2212maxj,i:j6=i Tr(\u03c3i\u03c3j)LU ,min ) , is defined as this lower bound. Now,\nE[n\u0304c] \u2265 p(n\u0304c > 0) \u2265 p+ (89)\nLet us now define N\u0302c = N\u0302c\u22121+V , where N\u03020 := 0, andV \u223c Bern(p+). Clearly, r.v. N\u0302c needs on average more steps than N\u0304c to reach the value N \u2212 1. Therefore, the random variable Z \u223c pZ (z), where pZ (z) is the probability that N\u0302z = N\u22121 and N\u0302z\u22121 = N \u2212 2, fulfills\nE[Ce] \u2264 E[Z ] (90)\nTo conclude the proof we only have to compute E[Z ]. Since N\u0302c \u223c B(c, p+) 4 for a fixed value of c, the probability pZ (z) is given by\npZ (z) = ((\nz\u2212 1 N \u2212 2\n) pN\u22122+ (1\u2212 p+) z\u2212N+1 ) p+ (91)\nwhere the first term of the product is p(N\u0302z\u22121 = N \u2212 2), and the second p(v = 1) = p+. Hence, the expected value of Z is\nE[Z ] = \u221e\u2211\nz=N\u22121\nz pZ (z)\n= \u221e\u2211 z=N\u22121 z ( z\u2212 1 N \u2212 2 ) pN\u22121+ (1\u2212 p+) z\u2212N+1 (92)\nSubstituting the binomial coefficient ( z\u22121 N\u22122 ) by (z\u22121)!(N\u22122)!(z\u2212N+1)! and arranging terms, the previous expression becomes\npN\u22121+ (N \u2212 2)! \u221e\u2211 z=N\u22121 N\u22122\u220f j=0 (z\u2212 j)(1\u2212 p+)z\u2212N+1 (93)\nThe sum can be rewritten as a derivative of the geometric series,\n\u2211 \u221e\nz=0(1\u2212 p+) z, this is\npN\u22121+ (N \u2212 2)! (\u22121)N\u22121 dN\u22121\ndpN\u22121+ \u221e\u2211 z=0 (1\u2212 p+)z (94)\nFinally, since \u2211 \u221e\nz=0(1 \u2212 p+) z = 1 p+\nthe expected value of Z can be expressed as\nE[Z ] = N \u2212 1 p+\n(95)\nTherefore, E[Ce] is bounded E[Ce] \u2264 N\u22121p+ .\nREFERENCES [1] L.Wang andR. Renner, \u2018\u2018One-shot classical-quantum capacity and hypoth-\nesis testing,\u2019\u2019 Phys. Rev. Lett., vol. 108, May 2012, Art. no. 200501. [2] A. Ac\u00edn, J. Bae, E. Bagan, M. Baig, L. Masanes, and R. Mu\u00f1oz-Tapia,\n\u2018\u2018Secrecy properties of quantum channels,\u2019\u2019 Phys. Rev. A, Gen. Phys., vol. 73, no. 1, Jan. 2006, Art. no. 012327. [3] C.W. Helstrom,QuantumDetection and Estimation. NewYork, NY, USA: Academic, 1976. [4] A. S. Holevo, Probabilistic and Statistical Aspects of Quantum Theory. Pisa, Italy: Edizioni della Normale, 1979. [5] K. M. R. Audenaert, \u2018\u2018Discriminating states: The quantum Chernoff bound,\u2019\u2019 Phys. Rev. Lett., vol. 98, Apr. 2007, Art. no. 160501. [6] M. Nussbaum and A. Szko\u0142a, \u2018\u2018The Chernoff lower bound for symmetric quantum hypothesis testing,\u2019\u2019 Ann. Statist., vol. 37, no. 2, pp. 1040\u20131057, Apr. 2009.\n4B(n, p) denotes a binomial distribution with parameters n \u2208 N, and p \u2208 (0, 1).\nVOLUME 10, 2022 13825\n[7] H. Chernoff, \u2018\u2018A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations,\u2019\u2019 Ann. Math. Statist., vol. 23, no. 4, pp. 493\u2013507, 1952. [8] K. Li, \u2018\u2018Discriminating quantum states: The multiple chernoff distance,\u2019\u2019 Ann. Statist., vol. 44, no. 4, pp. 1661\u20131679, 2016. [9] A. Ac\u00edn, E. Bagan, M. Baig, L. Masanes, and R. M. Tapia, \u2018\u2018Multiplecopy two-state discrimination with individual measurements,\u2019\u2019 Phys. Rev. A, Gen. Phys., vol. 71, Mar. 2005, Art. no. 032338. [10] J. Calsamiglia, J. I. de Vicente, R. Mu\u00f1oz-Tapia, and E. Bagan, \u2018\u2018Local discrimination ofmixed states,\u2019\u2019Phys. Rev. Lett., vol. 105, no. 8, Aug. 2010, Art. no. 080504. [11] E. Mart\u00ednez Vargas, C. Hirche, G. Sent\u00eds, M. Skotiniotis, M. Carrizo, R. Mu\u00f1oz-Tapia, and J. Calsamiglia, \u2018\u2018Quantum sequential hypothesis testing,\u2019\u2019 Phys. Rev. Lett., vol. 126, no. 18, May 2021, Art. no. 180502. [12] Y. Li, F. Tan, andM. Tomamichel, \u2018\u2018Optimal adaptive strategies for sequential quantum hypothesis testing,\u2019\u2019 2021, arXiv:2104.14706. [13] H. Nagaoka, \u2018\u2018The converse part of the theorem for quantum Hoeffding bound,\u2019\u2019 2006, arXiv:quant-ph/0611289. [14] T. Ogawa and M. Hayashi, \u2018\u2018On error exponents in quantum hypothesis testing,\u2019\u2019 IEEE Trans. Inf. Theory, vol. 50, no. 6, pp. 1368\u20131372, Jun. 2004. [15] J. Calsamiglia, R. Mu\u00f1oz-Tapia, L. Masanes, A. Acin, and E. Bagan, \u2018\u2018Quantum Chernoff bound as a measure of distinguishability between density matrices: Application to qubit and Gaussian states,\u2019\u2019 Phys. Rev. A, Gen. Phys., vol. 77, no. 3, Mar. 2008, Art. no. 032311. [16] K. M. R. Audenaert and M. Mosonyi, \u2018\u2018Upper bounds on the error probabilities and asymptotic error exponents in quantum multiple state discrimination,\u2019\u2019 J. Math. Phys., vol. 55, no. 10, Oct. 2014, Art. no. 102201. [17] I. D. Ivanovic, \u2018\u2018How to differentiate between non-orthogonal states,\u2019\u2019 Phys. Rev. A, Gen. Phys., vol. 123, no. 6, pp. 257\u2013259, Jan. 1987. [18] D. Dieks, \u2018\u2018Overlap and distinguishability of quantum states,\u2019\u2019 Phys. Lett. A, vol. 126, nos. 5\u20136, pp. 303\u2013306, Jan. 1988. [19] A. Peres, \u2018\u2018How to differentiate between non-orthogonal states,\u2019\u2019 Phys. Lett. A, vol. 128, nos. 1\u20132, p. 19, Mar. 1988.\nJORDI P\u00c9REZ-GUIJARRO received the B.S. degree in telecommunications engineering from Miguel Hern\u00e1ndez University, Elche, Spain, in 2018, and the M.S. degree in telecommunications engineering from the Universitat Polit\u00e8cnica de Catalunya, Barcelona, Spain, in 2020, where he is currently pursuing the Ph.D. degree.\nALBA PAG\u00c8S-ZAMORA (SeniorMember, IEEE) received the M.S. and Ph.D. degrees in electrical engineering from the Universitat Polit\u00e8cnica de Catalunya (UPC), Spain, in 1992 and 1996, respectively.\nIn 1992, she joined the Department of Signal Theory and Communications, UPC, and became an Associate Professor, in 2001. Since April 2019, she has been the Vice-Dean of Academic Planning and Quality of the Electrical Engineering School\nETSETB, UPC. She has coauthored one patent, two book chapters, 20 articles in international periodic journals, and about 60 papers in international conferences. She has been UPC\u2019s principal investigator of five national and European research projects, and has participated in 15 more. Her current research interests include signal processing on graphs, ensemble learning, and quantum signal processing.\nDr. Pag\u00e8s-Zamora is a member of the IEEE Signal Processing Theory and Methods Technical Committee. Since February 2018, she has been a member of the Editorial Board of EURASIP Signal Processing journal. From February 2012 to 2015, she served as an Associate Editor for the IEEE TRANSACTIONSON SIGNAL PROCESSING. She regularly participates as an evaluator of research projects for the European Commission and for national and international agencies.\nJAVIER RODR\u00cdGUEZ FONOLLOSA (Senior Member, IEEE) received the Ph.D. degree in electrical and computer engineering fromNortheastern University, Boston, MA, USA, in 1992.\nIn 1993, he joined the Department of Signal Theory and Communications, Universitat Polit\u00e8cnica de Catalunya (UPC), where he became an Associate Professor, in 1996, a Professor, in 2003, and the Department Head, from 2006 to 2010. He was the Head of the Signal Theory and Com-\nmunications Department, UPC, fromOctober 2006 to January 2010. In 1995, he led UPC\u2019s participation in the European Commission funded ACTS Mobile projects TSUNAMI (II) and SUNBEAM that included the analysis of adaptive antennas in 2nd and 3rd generation cellular mobile communication systems. From January 2000 to 2003, he was a Technical and a Project Co-ordinator of the IST projects METRA and I-METRA dedicated to the introduction of multi-antenna terminals in UMTS and Systems beyond 3G. From January 2006 to December 2008, he co-ordinated the Sixth Framework Program IST project SURFACE which evaluated the performance of a generalized air interface with self-configuration capabilities. In November 2006, he initiated the co-ordination of the 5 year Type C-Consolider project Fundamental bounds in Network Information Theory of the National Research Plan of Spain. From December 2008 to December 2014, he was the Co-ordinator of the CONSOLIDER-INGENIO 2010 Foundations and Methodologies for Future Communication and Sensor Networks (COMONSENS), a six year e 3.5 Million effort of 135 researchers belonging to ten universities and research centers in Spain. The project continued under his co-ordination as a research network Red COMONSENS, since December 2015, for seven more years. In 2009, he co-ordinated the ERASMUSMUNDUS 2009\u20132013 Master of Science in Research on Information and Communication Technologies (MERIT) EMMC Joint Master Program. From February 2010 to July 2014, he was a manager of the communications and electronic technologies (TEC) area of the National Research Plan of Spain.\nDr. Fonollosa has been a member of the Editorial Board of the EURASIP Signal Processing journal, since May 2005. In June 1995 and September 2001, he was the Co-Chairperson and an Organizer of the IEEE Signal Processing/ATHOS Workshop on Higher-Order Statistics held in Begur, Girona, Spain, and of the IST Mobile Communications Summit 2001 held in Sitges, Barcelona, Spain. He was elected as a member of the Signal Processing for Communications (SPCOM)Technical Committee of the IEEE Signal Processing Society, in February 1998 and January 1999, respectively.\n13826 VOLUME 10, 2022"
        }
    ],
    "title": "Quantum Multiple Hypothesis Testing Based on a Sequential Discarding Scheme",
    "year": 2022
}