{
    "abstractText": "Quantum key distribution (QKD) has been researched for almost four decades and is currently making its way to commercial applications. However, deployment of the technology at scale is challenging because of the very particular nature of QKD and its physical limitations. Among other issues, QKD is computationally intensive in the post-processing phase, and devices are therefore complex and power hungry, which leads to problems in certain application scenarios. In this work, we study the possibility to offload computationally intensive parts in the QKD post-processing stack in a secure way to untrusted hardware. We show how error correction can be securely offloaded for discrete-variable QKD to a single untrusted server and that the same method cannot be used for longdistance continuous-variable QKD. Furthermore, we analyze possibilities for multi-server protocols to be used for error correction and privacy amplification. Even in cases where it is not possible to offload to an external server, being able to delegate computation to untrusted hardware components on the device itself could improve the cost and certification effort for device manufacturers.",
    "authors": [
        {
            "affiliations": [],
            "name": "Hong-Wei Li"
        },
        {
            "affiliations": [],
            "name": "Jin Dong Wang"
        },
        {
            "affiliations": [],
            "name": "Qin Wang"
        },
        {
            "affiliations": [],
            "name": "Thomas Lor\u00fcnser"
        },
        {
            "affiliations": [],
            "name": "Stephan Krenn"
        },
        {
            "affiliations": [],
            "name": "Christoph Pacher"
        },
        {
            "affiliations": [],
            "name": "Bernhard Schrenk"
        }
    ],
    "id": "SP:53ead61bb28e659843a781260732ac75d774f55f",
    "references": [
        {
            "authors": [
                "J. Martinez-Mateo",
                "C. Pacher",
                "M. Peev",
                "A. Ciurana",
                "V. Martin"
            ],
            "title": "Demystifying the information reconciliation protocol cascade",
            "venue": "Quantum Inf. Comput",
            "year": 2015
        },
        {
            "authors": [
                "T.B. Pedersen",
                "M. Toyran"
            ],
            "title": "High performance information reconciliation for QKD with CASCADE",
            "venue": "Quantum Inf. Comput",
            "year": 2015
        },
        {
            "authors": [
                "H.K. Mao",
                "Y.C. Qiao",
                "Q. Li"
            ],
            "title": "High-Efficient Syndrome-Based LDPC Reconciliation for Quantum Key Distribution",
            "venue": "Entropy 2021,",
            "year": 2021
        },
        {
            "authors": [
                "C. Pacher",
                "A. Abidin",
                "T. Lor\u00fcnser",
                "M. Peev",
                "R. Ursin",
                "A. Zeilinger",
                "J. Larsson"
            ],
            "title": "Attacks on quantum key distribution protocols that employ non-ITS authentication",
            "venue": "Quantum Inf. Process",
            "year": 2016
        },
        {
            "authors": [
                "O. Maurhart",
                "C. Pacher",
                "A. Happe",
                "T. Lor",
                "C. Tamas",
                "A. Poppe",
                "M. Peev"
            ],
            "title": "New release of an open source QKD software: design and implementation of new algorithms, modularization and integration with IPSec",
            "venue": "In Proceedings of the QCRYPT",
            "year": 2013
        },
        {
            "authors": [
                "Y. Li",
                "X. Zhang",
                "B. Xu",
                "L. Ma",
                "J. Yang",
                "W. Huang"
            ],
            "title": "High-throughput GPU layered decoder of quasi-cyclic multi-edge type low density parity check codes in continuous-variable quantum key distribution systems",
            "year": 2020
        },
        {
            "authors": [
                "S.S. Yang",
                "Z.G. Lu",
                "Y.M. Li"
            ],
            "title": "High-Speed Post-Processing in Continuous-Variable Quantum Key Distribution Based on FPGA Implementation",
            "venue": "J. Lightwave Technol",
            "year": 2020
        },
        {
            "authors": [
                "S.S. Yang",
                "J.Q. Liu",
                "Z.G. Lu",
                "Z.L. Bai",
                "X.Y. Wang",
                "Y.M. Li"
            ],
            "title": "An FPGA-Based LDPC Decoder with Ultra-Long Codes for ContinuousVariable Quantum Key Distribution",
            "venue": "IEEE Access 2021,",
            "year": 2021
        },
        {
            "authors": [
                "J. M\u00fcller-Quade",
                "R. Renner"
            ],
            "title": "Composability in quantum cryptography",
            "venue": "New J. Phys",
            "year": 2009
        },
        {
            "authors": [
                "M.N. Wegman",
                "L. Carter"
            ],
            "title": "New Hash Functions and Their Use in Authentication and Set Equality",
            "venue": "J. Comput. Syst. Sci",
            "year": 1981
        },
        {
            "authors": [
                "F. Banfi",
                "U. Maurer",
                "C. Portmann",
                "J. Zhu"
            ],
            "title": "Composable and Finite Computational Security of Quantum Message Transmission",
            "venue": "In Proceedings of the Theory of Cryptography;",
            "year": 2019
        },
        {
            "authors": [
                "N. L\u00fctkenhaus"
            ],
            "title": "Estimates for practical quantum cryptography",
            "venue": "Phys. Rev. A",
            "year": 1999
        },
        {
            "authors": [
                "Z. Yuan",
                "A. Plews",
                "R. Takahashi",
                "K. Doi",
                "W. Tam",
                "A. Sharpe",
                "A. Dixon",
                "E. Lavelle",
                "J. Dynes",
                "A Murakami"
            ],
            "title": "10-Mb/s Quantum Key Distribution",
            "venue": "J. Lightwave Technol",
            "year": 2018
        },
        {
            "authors": [
                "S. Ren",
                "S. Yang",
                "A. Wonfor",
                "I. White",
                "R. Penty"
            ],
            "title": "Demonstration of high-speed and low-complexity continuous variable quantum key distribution system with local local oscillator",
            "year": 2021
        },
        {
            "authors": [
                "A. Neppach",
                "C. Pfaffel-Janser",
                "I. Wimberger",
                "T. Loruenser",
                "M. Meyenburg",
                "A. Szekely",
                "J. Wolkerstorfer"
            ],
            "title": "Key management of quantum generated keys in IPSEC",
            "venue": "In Proceedings of the International Conference on Security and Cryptography SECRYPT",
            "year": 2008
        },
        {
            "authors": [
                "C.H. Bennett",
                "G. Brassard"
            ],
            "title": "Quantum cryptography: Public key distribution and coin tossing",
            "venue": "In Proceedings of the Proceedings of IEEE International Conference on Computers, Systems, and Signal Processing,",
            "year": 1984
        },
        {
            "authors": [
                "F. Gr\u00fcnenfelder",
                "A. Boaron",
                "D. Rusca",
                "A. Martin",
                "H. Zbinden"
            ],
            "title": "Performance and security of 5 GHz repetition rate polarizationbased quantum key distribution",
            "venue": "Appl. Phys. Lett",
            "year": 2020
        },
        {
            "authors": [
                "G. Brassard",
                "L. Salvail"
            ],
            "title": "Secret-Key Reconciliation by Public Discussion",
            "venue": "Proceedings of the Advances in Cryptology\u2014",
            "year": 1993
        },
        {
            "authors": [
                "C. Pacher",
                "P. Grabenweger",
                "J. Martinez-Mateo",
                "V. Martin"
            ],
            "title": "An information reconciliation protocol for secret-key agreement with small leakage",
            "venue": "In Proceedings of the 2015 IEEE International Symposium on Information Theory (ISIT), Hong Kong, China,",
            "year": 2015
        },
        {
            "authors": [
                "D. Elkouss",
                "J. Martinez",
                "D. Lancho",
                "V. Martin"
            ],
            "title": "Rate compatible protocol for information reconciliation: An application to QKD",
            "venue": "In Proceedings of the 2010 IEEE Information Theory Workshop on Information Theory (ITW 2010), Dublin, Ireland,",
            "year": 2010
        },
        {
            "authors": [
                "H. Mani",
                "T. Gehring",
                "P. Grabenweger",
                "B. \u00d6mer",
                "C. Pacher",
                "U.L. Andersen"
            ],
            "title": "Multiedge-type low-density parity-check codes for continuous-variable quantum key distribution",
            "venue": "Phys. Rev. A",
            "year": 2021
        },
        {
            "authors": [
                "D.S. Slepian",
                "J.K. Wolf"
            ],
            "title": "Noiseless coding of correlated information sources",
            "venue": "IEEE Trans. Inf. Theory",
            "year": 1973
        },
        {
            "authors": [
                "A.D. Wyner",
                "J. Ziv"
            ],
            "title": "The rate-distortion function for source coding with side information at the decoder",
            "venue": "IEEE Trans. Inf. Theory",
            "year": 1976
        },
        {
            "authors": [
                "V. Scarani",
                "H. Bechmann-Pasquinucci",
                "N.J. Cerf",
                "M. Dusek",
                "N. L\u00fctkenhaus",
                "M. Peev"
            ],
            "title": "The security of practical quantum key distribution",
            "venue": "Rev. Mod. Phys",
            "year": 2009
        },
        {
            "authors": [
                "U.M. Maurer"
            ],
            "title": "Secret key agreement by public discussion from common information",
            "venue": "IEEE Trans. Inf. Theory",
            "year": 1993
        },
        {
            "authors": [
                "F. Furrer"
            ],
            "title": "Reverse-reconciliation continuous-variable quantum key distribution based on the uncertainty principle",
            "venue": "Phys. Rev. A",
            "year": 2014
        },
        {
            "authors": [
                "A. Leverrier",
                "F. Grosshans",
                "P. Grangier"
            ],
            "title": "Finite-size analysis of a continuous-variable quantum key distribution",
            "venue": "Phys. Rev. A 2010,",
            "year": 2010
        },
        {
            "authors": [
                "M. Ben-Or",
                "S. Goldwasser",
                "A. Wigderson"
            ],
            "title": "Completeness theorems for non-cryptographic fault-tolerant distributed computation",
            "venue": "In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing (STOC \u201988),",
            "year": 1988
        },
        {
            "authors": [
                "D. Chaum",
                "C. Crepeau",
                "I. Damgdr"
            ],
            "title": "Multiparty unconditionally secure protocols",
            "venue": "In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing (STOC \u201988),",
            "year": 1988
        },
        {
            "authors": [
                "A. Shamir"
            ],
            "title": "How to Share a Secret",
            "venue": "Commun. ACM",
            "year": 1979
        },
        {
            "authors": [
                "M.G. Raeini",
                "M. Nojoumian"
            ],
            "title": "Secure error correction using multiparty computation",
            "venue": "In Proceedings of the 2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC 2018),",
            "year": 2018
        },
        {
            "authors": [
                "T.J. Richardson",
                "R.L. Urbanke"
            ],
            "title": "The capacity of low-density parity-check codes under message-passing decoding",
            "venue": "IEEE Trans. Inf. Theory",
            "year": 2001
        },
        {
            "authors": [
                "R.G. Gallager"
            ],
            "title": "Low-Density Parity-Check Codes",
            "year": 1963
        },
        {
            "authors": [
                "T. Lor\u00fcnser",
                "F. Wohner"
            ],
            "title": "Performance Comparison of Two Generic MPC-frameworks with Symmetric Ciphers",
            "venue": "In Proceedings of the 17th International Joint Conference on e-Business and Telecommunications, SCITEPRESS\u2014Science and Technology Publications, Virtual Conference,",
            "year": 2020
        },
        {
            "authors": [
                "J. Feldman",
                "M.J. Wainwright",
                "D.R. Karger"
            ],
            "title": "Using linear programming to decode binary linear codes",
            "venue": "IEEE Trans. Inf. Theory 2005,",
            "year": 2005
        },
        {
            "authors": [
                "J. Feldman"
            ],
            "title": "Decoding Error-Correcting Codes via Linear Programming",
            "venue": "Ph.D. Thesis, Massachusetts Institute of Technology,",
            "year": 2003
        },
        {
            "authors": [
                "T. Toft"
            ],
            "title": "Solving Linear Programs Using Multiparty Computation. In Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
            "year": 2009
        },
        {
            "authors": [
                "T. Lor\u00fcnser",
                "F. Wohner",
                "S. Krenn"
            ],
            "title": "A Verifiable Multiparty Computation Solver for the Assignment Problem and Applications to Air Traffic Management",
            "venue": "arXiv 2022,",
            "year": 2022
        },
        {
            "authors": [
                "D. Milovancev",
                "F. Honz",
                "N. Vokic",
                "F. Laudenbach",
                "H. H\u00fcbel",
                "B. Schrenk"
            ],
            "title": "Ultra-Low Noise Balanced Receiver with >20 dB Quantum-to-Classical Noise Clearance at 1 GHz",
            "venue": "In Proceedings of the European Conference on Optical Communication, (ECOC 2021),",
            "year": 2021
        },
        {
            "authors": [
                "D. Milovan\u010dev",
                "N. Voki\u0107",
                "C. Pacher",
                "I. Khan",
                "C. Marquardt",
                "W. Boxleitner",
                "H. H\u00fcbel",
                "B. Schrenk"
            ],
            "title": "Towards Integrating True Random Number Generation in Coherent Optical Transceivers",
            "venue": "IEEE J. Sel. Top. Quantum Electron",
            "year": 2020
        },
        {
            "authors": [
                "A. Treiber",
                "A. Poppe",
                "M. Hentschel",
                "D. Ferrini",
                "T. Lor\u00fcnser",
                "E. Querasser",
                "T. Matyus",
                "H. H\u00fcbel",
                "A. Zeilinger"
            ],
            "title": "Fully automated entanglement-based quantum cryptography system for telecom fiber networks",
            "venue": "New J. Phys",
            "year": 2009
        },
        {
            "authors": [
                "T. Loruenser",
                "E. Querasser",
                "T. Matyus",
                "M. Peev",
                "J. Wolkerstorfer",
                "M. Hutter",
                "A. Szekely",
                "I. Wimberger",
                "C. Pfaffel-Janser",
                "A. Neppach"
            ],
            "title": "Security processor with quantum key distribution",
            "venue": "In Proceedings of the Application-Specific Systems, Architectures and Processors (ASAP",
            "year": 2008
        }
    ],
    "sections": [
        {
            "text": "Citation: Lor\u00fcnser, T.; Krenn, S.;\nPacher, C.; Schrenk, B. On the\nSecurity of Offloading\nPost-Processing for Quantum Key\nDistribution. Entropy 2023, 25, 226.\nhttps://doi.org/10.3390/e25020226\nAcademic Editors: Hong-Wei Li, Jin\nDong Wang, Qin Wang and Xing-Yu\nZhou\nReceived: 17 October 2022\nRevised: 12 December 2022\nAccepted: 21 January 2023\nPublished: 24 January 2023\nCopyright: \u00a9 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: quantum key distribution; post-processing; secure offloading; secure outsourcing; information reconciliation; privacy amplification"
        },
        {
            "heading": "1. Introduction",
            "text": "Quantum key distribution (QKD) was invented almost 40 years ago and is currently a more vital field of research than ever. With commercial impact on the horizon, application of QKD is gaining substantial momentum, and the technology is expected to be deployed on a large scale in the upcoming years. This is true for both terrestrial as well as spacebased applications. QKD is the only known information-theoretic secure primitive for key exchange and can be considered part of the quantum-safe toolbox to build long-term secure information and communication technology (ICT) which even resists quantum computer threats. However, its wide adoption is still hampered by various challenges which have to be overcome to make QKD practically relevant and facilitate commercial adoption. On the one hand, research is thus continuously improving protocols, optics and electronics to achieve a better bandwidth and distance, as well as co-existence with existing infrastructure. On the other hand, miniaturization and electro-optical integration are important topics to make the technology more reliable and cost-effective. Complementary to these efforts, our work focuses on the possibility to offload (outsource) computationally expensive tasks in the QKD post-processing phase to the external infrastructure without compromising the overall security. Being able to outsource these tasks to external data centers allows for simpler and less power-hungry devices in the field, resulting in more versatile applications for QKD."
        },
        {
            "heading": "1.1. Related Work",
            "text": "Improving the efficiency and throughput of the post-processing phase is still an interesting challenge in the context of QKD. Scientific and industrial research initiatives\nEntropy 2023, 25, 226. https://doi.org/10.3390/e25020226 https://www.mdpi.com/journal/entropy\nEntropy 2023, 25, 226 2 of 18\nare focusing on algorithmic improvements to reduce computational effort (c.f. [1\u20134]) or extending the local computational resources with specialized hardware. They leverage equipment from high-performance computing or graphics processing units [5\u20137] or even develop dedicated hardware designs as co-processing units for local installation [8,9]."
        },
        {
            "heading": "1.2. Contributions",
            "text": "In this work, we contribute to these efforts via a complementary approach by presenting novel methods for offloading (or outsourcing) the most expensive parts of the QKD post-processing stack. For this, we combine our expertise from QKD and cryptography. We will clearly demonstrate the problem, show the benefits of our approach and present new protocols and barriers. More precisely, we present and analyze protocols for outsourcing information reconciliation to external and untrusted environments, therefore facilitating new application scenarios (e.g., usage in low-power access networks). We furthermore discuss possibilities to outsource the privacy amplification step, which could further help to reduce the required processing power in QKD nodes. Additionally, we present possible use cases to undermine the practical relevance of the novel developed methods."
        },
        {
            "heading": "1.3. Outline of the Work",
            "text": "In Section 2, we present and discuss quantum key distribution and the required steps for post-processing, as well as the motivation for offloading computationally expensive tasks. In Section 3, we review information reconciliation in detail and present a new protocol which allows its outsourcing in a secure way as well as an impossibility result. In Section 4, we analyze the potential of outsourcing privacy amplification and propose new methods in this direction. Potential use cases for the proposed solution are then discussed in Section 5, and the concluding remarks are given in Section 6."
        },
        {
            "heading": "2. Quantum Key Distribution",
            "text": "Contrary to most other cryptographic primitives, QKD is a cryptographic key-agreement protocol which derives its security from the physical layer (i.e., it uses a quantum channel to exchange quantum information which cannot be perfectly copied or eavesdropped according to the laws of quantum mechanics). In preparing and measuring the QKD protocols, so-called quantum bits (qubits) are encoded and transmitted over a quantum channel. Typically, the qubits are encoded on photons, and the transmission channels are either fiber optics or free space. Finally, the qubits are measured at the receiver and decoded. From the measurement of quantum bits, classical information is derived, and all of the following steps are carried out in the classical domain. However, due to their interaction with the environment and eavesdroppers, photons are subject to perturbation and absorption. To detect and cope with these modifications in the transmission channel, post-processing steps have to be applied in order to obtain the full key agreement primitive with practical correctness and secrecy guarantees. The outstanding property of QKD is that it is an information-theoretic secure (ITS) and universally composable (UC) key agreement protocol [10], given that its classical communication is performed over an authentic channel (note that all key-agreement protocols are insecure over non-authentic channels). ITS message authentication codes are based on universal hashing [11], which in the first round uses pre-shared keys, and in later rounds, QKD keys from previous rounds are a means to generate an ITS authentic channel [12]. Thus, QKD is a very powerful cryptographic primitive which cannot be realized with non-quantum protocols."
        },
        {
            "heading": "2.1. QKD Post-Processing",
            "text": "QKD comprises two phases to arrive at a key agreement with strong correctness and secrecy guarantees. First, qubits are randomly generated on one side, transmitted over the optical quantum channel, and measured on the other side to generate the so-called raw key.\nEntropy 2023, 25, 226 3 of 18\nIn the second phase, a non-quantum (classical) post-processing protocol is executed to agree on identical keys (correctness) on both ends of the transmission line and to render useless any information a potential attacker could have learned by attacking the transmission phase (secrecy). In detail, the steps to extracting a secure key from the raw data of the transmitted quantum bits are as follows:\n1. Sifting removes non-relevant information from the raw key (e.g., in conjugate coding protocols, events prepared and measured in different bases are deleted). Additionally, events not received by Bob are discarded in discrete-variable protocols (cf. Section 3). 2. Error estimation determines an upper bound on the information leaked to an adversary on the quantum channel and can provide information to optimize the subsequent information reconciliation. Although more advanced methods have been proposed in the literature, this is typically accomplished by cut-and-choose methods. Additionally, the idea of using a confirmation phase to replace error estimation was proposed by L\u00fctkenhaus [13]. 3. Information reconciliation, which often uses methods from forward error correction, aims at correcting all errors in the remaining raw key so that the sender and receiver should obtain identical keys. The classical (non-quantum) messages exchanged in this process must not leak information on the final key. Typically, the leakage is tracked and treated during the privacy amplification step. 4. Confirmation detects non-identical keys (for which information reconciliation has failed) with a probability close to one. If non-identical keys are detected, then the parties either go back to the information reconciliation step or abort the QKD protocol. 5. Finally, privacy amplification eliminates the information leaked during all protocol steps (quantum and classical) from the final key by running a (strong) randomness extraction protocol between the peers.\nAll processing steps together enable Alice and Bob to agree on a final key which is e-close to an ideal key. Various optimizations of the above key agreement process have been proposed in the past, either for efficiency reasons or implementation aspects, but this generic structure is typically followed in one way or another."
        },
        {
            "heading": "2.2. Motivation to Offload Post-Processing",
            "text": "From a computational perspective, information reconciliation is by far the most expensive task computationally in the stack and can limit the throughput in high-speed systems [14,15]. The second-most computationally demanding task is privacy amplification [6]. The rest of the protocol steps are rather simple tasks and can be executed in real time even on embedded platforms. Therefore, we introduce and study the idea of offloading these tasks from devices by outsourcing computation to untrusted or less trusted hardware in an ITS way. The ability to outsource information reconciliation (IR) and potentially privacy amplification (PA) would enable new application scenarios for both access networks and transmission systems. On top of this, satellite-based QKD could become more versatile if processing resources can be shifted around more easily. The two main advantages gained by offloading processing to external hardware are increased efficiency and flexibility in the use of compute resources, also resulting in a higher energy efficiency, and a reduced attack surface by limiting the number of components dealing with secure key material. QKD systems are deployed for long-term security and produce large capital expenditure (CAPEX) spending (i.e., they are used over a long period of time). Putting all the processing power into the devices at build time hinders later updates and prevents the operator benefiting from Moore\u2019s law. If the hardware is outsourced, then it could be updated during the lifetime of the system with new technologies, resulting in further optimized efficiency. Furthermore, if the hardware need not be trustworthy and certified,\nEntropy 2023, 25, 226 4 of 18\nthen cheaper commercial off-the-shelf (COTS) hardware can be used. It would even be possible to completely outsource this to public cloud infrastructures in an extreme case. Additionally, time sharing allows for further improvements in certain use cases. If QKD is used in hybrid encryption protocols to establish session keys [16], then high key rates are not needed, and sharing the computational resources between links can further reduce the CAPEX and also the operational cost (OPEX). Hence, putting the computationally expensive tasks into efficient data centers which do not even need to be trusted is very desirable. This allows for hardware updates and joint management of all QKD workloads in the field with its continuous upgrading probabilities, which is especially favorable for operators of QKD networks. Because the communication overhead is minimal compared with the computational one, a clear advantage in terms of energy efficiency arises, and the gained flexibility in managing tasks is very advantageous. Furthermore, the proposed approach could also be used within a system. Treating parts of the system as untrusted could eventually provide the possibility for system updates without compromising system certification and help to reduce the OPEX cost during the system\u2019s lifetime."
        },
        {
            "heading": "3. Outsourcing Information Reconciliation",
            "text": "As mentioned in Section 2, information reconciliation (IR) is the most demanding task in post-processing of QKD, independent of the protocols being used on the quantum level. Error correction is computationally intense because of high error rates encountered in combination with the constraints on the amount of information disclosed during error correction. The information revealed during the public discussion must be kept as short as possible to maximize the overall system performance. Ideally, IR works close to the Shannon limit. If keys have to be processed in real time, error correction is the bottleneck of postprocessing and can introduce substantial problems in resource constraint environments. On a quantum level, QKD protocols can be divided into two classes\u2014discrete variable (DV) and continuous variable (CV) QKD\u2014which also result in different requirements for information reconciliation. In DV-QKD protocols (e.g., BB84 [17]), qubits are measured by single photon detectors. Due to channel attenuation and non-perfect detectors, the rate of detected photons is typically orders of magnitudes lower than the rate of prepared photons. Consequently, in DV-QKD, IR schemes must typically provide the possibility to operate on the final key rates in the order of kilobits per second [18] up to megabits per second [14]. In CV-QKD systems, signals are only perturbed and not lost through channel effects, resulting in very high raw key rates but also high error rates compared with a discrete variable system. Additionally, two basic types of IR protocols can be distinguished in QKD systems. On the one hand, interactive two-way protocols have been developed for highly efficient correction capabilities near the Shannon limit, with CASCADE [1,19,20] being the most prominent representative. They can achieve smaller leakage than any one-way protocol, but their practical performance is limited due to their interactive nature by the latency of the classical channel. On the other hand, forward error correcting schemes have been adopted and developed further to be used in operational regimes encountered in QKD [21]. One-way IR based on low-density parity check codes (LDPC) is currently the most efficient representative in this category and is used in many prototype systems [22]. One-way schemes have many desirable properties when it comes to realization and can easily be parallelized to increase performance. Therefore, in our work and for the design of our protocols, we assume the use of forward error correction where necessary and, in particular, LDPC-based error correction in case concrete implementations are considered."
        },
        {
            "heading": "3.1. Linear One-Way Information Reconciliation",
            "text": "Before presenting our scheme for offloading, we first explain one-way IR in the context of DV-QKD in more detail and informally define the concept of secure outsourcing for IR. Traditional error-correcting block codes consist of sets of codewords that contain redundant\nEntropy 2023, 25, 226 5 of 18\ninformation. Before sending data over a noisy channel, the data are encoded into codewords. The contained redundancy can then be used by the receiver to correct the introduced errors. One-way reconciliation (i.e., source coding with side information) has been studied since the 1970s [23,24]. While related to error-correcting codes, the idea here is that the data are transmitted over a noisy channel without adding any redundancy. Rather, the source additionally sends a syndrome of the data (computed with a parity check matrix of an error-correcting code) over a noise-free channel. The receiver then uses the syndrome together with the noisy data (side information) to decode the original data. More concretely, after sifting, Bob has obtained a noisy version of Alice\u2019s sifted key (i.e., kB = kA + e, where e denotes the error vector). Alice and Bob then use a linear block code with parity check matrix H. Alice computes the syndrome of her sifted key kA with the help of H by computing\nsA := kAH>.\nAlice sends sA over the noise-free classical channel to Bob. Bob corrects his sifted key by (approximately) solving the problem of finding a vector k\u0302A which, among all vectors with syndrome sA, has the smallest Hamming distance to kB. Searching for this vector is computationally hard and is equivalent to solving the standard syndrome-decoding problem (NP-complete) which, given H and a vector s, requires finding a vector e of a minimal weight satisfying eH> = s. The equivalence can easily be seen considering that in our case, the syndrome decoder is employed for eH> = kBH> \u2212 kAH> = kBH> \u2212 sA."
        },
        {
            "heading": "3.2. Protocol for Offloading Direct Reconciliation",
            "text": "In the context of QKD, if Alice, who sends the qubits, also sends the syndrome to Bob, and Bob corrects erroneous bits to obtain the sifted key of Alice as an agreed key, then the protocol is called direct reconciliation (DR). In DV-QKD, which is considered symmetric [25], the roles of Alice and Bob can also be interchanged during IR, resulting in so-called reverse reconciliation (RR). However, the same is not true for CV-QKD, where the direction of the IR protocol does matter for higher transmission rates, as will be discussed later. We present a simple scheme for remote (outsourced) information reconciliation called REM-IR (remote IR), which allows the computationally intense step of syndrome decoding to be outsourced to an untrusted party in a secure way. The idea is to give the error syndrome (i.e., se = sB \u2212 sA = kBH> \u2212 kAH>) to an external party, which returns the error vector e with a minimal weight satisfying se = eH>. We want to emphasize that searching for eH> = se can be carried out with the very same algorithms and techniques typically used locally by Bob (e.g., efficient variants as in [21] or [26]). The problem is that finding e with a minimum Hamming weight is fully equivalent to the problem of finding a k\u0302B with a minimum Hamming distance to kB which fulfills k\u0302BH = sB, which is due to the linearity of the code. As an example, if LDPC codes are used which are characterized by a sparse H, then all types of decoders can be used in the very same way to find e close to the zero code word as in finding k\u0302B close to kB. The only difference in the two ways error decoding is applied is that in the latter, k\u0302B is directly computed, and in the first case, it is computed by k\u0302B = kB + e. Informally, the protocol is secure because the information leaked by publishing se and e in addition to sA, and thus also sB = sA \u2212 e, does not increase the information of Eve regarding the agreed key string kA. The intuition behind this is that just learning a bit flip vector of a largely unknown key does not increase the information about the key. Put differently, the information leaked about the final key kA by additionally learning e is zero because e is independent of kA and removed from kB in the IR step anyway. The described protocol is also equivalent to interactive error decoding, as introduced in CASCADE [19], which also leaks parity information and error bit locations during the public discussion. A detailed description of the protocol is shown in Figure 1, and the security of the protocols is proven in the following:\nEntropy 2023, 25, 226 6 of 18\nEntropy 2023, 25, 226 6 of 19\nprotocol is also equivalent to interactive error decoding, as introduced in CASCADE [19], which also leaks parity information and error bit locations during the public discussion. A detailed description of the protocol is shown in Figure 1, and the security of the protocols is proven in the following:\nTheorem 1 (Security of REM-IR). REM-IR is a secure scheme for offloading direct reconciliation for DV-QKD and does not leak any additional information about the agreed key by public discussion compared with a local IR (i.e., the mutual information between Eve\u2019s key and the agreed key is the same as with local IR).\nProof. Let KA, KB be n bit random variables representing correlated sifted keys for Alice and Bob, which are used as input to information reconciliation. SA is a random variable representing the syndrome computed by Alice, and E is a random variable for the error introduced on n channel usages. The quantum channel between Alice and Bob is then modeled as a binary symmetric channel BSC(e) with a quantum bit error probability e. Furthermore, let LIRE (K|Q) be the additional information leaked to Eve about the agreed key K during the information reconciliation phase beyond what Eve already gained during the previous steps of the key exchange. Moreover, H(KA) = H(KB) = n is for uniformly random input encoding, and mutual information IAB := I(KA; KB) = n(1\u2212 Hb(e)) is defined by the error probability on the channel. Thus, the amount of information required to be exchanged during public discussion is |Q| \u2265 H(KA|KB) = nHb(e), where we assume an ideal reconciliation algorithm which works at the Shannon limit (i.e, equality holds). Without loss of generality, we assume that Bob will correct his errors and the agreed key will be k = kA. Note here that in the DV-QKD-type protocols, we have IAE = IBE [25], which makes them suitable for direct reconciliation. Now, we show that the information Eve gains about the final key during a protocol run of REM-IR is equal to the information leaked in local IR, where it only sees SA. Concretely, by revealing Se and therefore E and SB in addition to SA, the information Eve learns about the final key (k) can be described as follows:\nLREM-IRE (K|SA, Se) = LREM-IRE (K|KH>, EH>) = LREM-IRE (K|KH>) = LREM-IRE (K|SA) .\nThis is due to the fact that the additional information Eve gains by learning Se, E and therefore SB is only about EH>, which is not correlated to the final key and also removed from kB during the IR step. This can also be seen by looking at Bob\u2019s key KB = KA + E, which is the sum of two independent random variables where the error term is removed by IR and does not contribute in any form to the final key string K. Therefore, the leakage during the protocol run is LREM-IRE (K|SA) = |SA| = nHb(e).\nVariants of REM-IR could be, for example, to let Alice and Bob directly send sA and sB, respectively, to the third party, who then computes se = sB \u2212 sA. This version is equivalent,\nFigure 1. REM-IR protocol.\nTheorem 1 (Security of REM-IR). is a sec re sc e e for offloading direct reconciliation for DV-QKD and does not leak any additional infor ation about the agreed key by public discussion compared with a local IR (i.e., the utual infor ation bet een Eve\u2019s key and the agreed key is the same as with local IR).\nProof. Let KA, KB be n bit random variables representing correlated sifted keys for Alice and Bob, which are used as input to information reconciliation. SA is a random variable representing the syndrome computed by Alice, and E is a random variable for the error introduced on n channel usages. The quantum channel between Alice and Bob is then modeled as a binary symmetric channel BSC(e) with a quantum bit error probability e. Furthermore, let LIRE (K|Q) be the additional information leaked to Eve about the agreed key K during the information reconciliation phase beyond what Eve already gained during the previous steps of the key exchange. Moreover, H(KA) = H(KB) = n is for uniformly random input encoding, and mutual information IAB := I(KA; KB) = n(1\u2212 Hb(e)) is defined by the error probability on the channel. Thus, the amount of information required to be exchanged during public discussion is |Q| \u2265 H(KA|KB) = nHb(e), where we assume an ideal reconciliation algorithm which works at the Shannon limit (i.e, equality holds). Without loss of generality, we assume that Bob will correct his errors and the agreed key will be k = kA. Note here that in the DV-QKD-type protocols, we have IAE = IBE [25], which makes them suitable for direct reconciliation. Now, we show that the information Eve gains about the final key during a protocol run of REM-IR is equal to the information leaked in local IR, where it only sees SA. Concretely, by revealing Se and therefore E and SB in addition to SA, the information Eve learns about the final key (k) can be described as follows:\nLREM-IRE (K|SA, Se) = LREM-IRE (K|KH>, EH>) = LREM-IRE (K|KH>) = LREM-IRE (K|SA) .\nThis is due to the fac that the additional information Eve gains by learning Se, E and therefore SB is only about EH>, which i not correlated to the final key and also removed from kB during the IR step. This ca also be seen by looking at Bob\u2019s key KB = KA + E, which is the sum f two independent rand m vari bles where the error term is r mov d by IR and does not contribute in any form to the final key string K. Therefore, the leakage during the protocol run is LREM-IRE (K|SA) = |SA| = nHb(e).\nVariants of REM-IR could be, f r example, to let Alice and Bob directly send sA and sB, respectively, to the third party, who then computes se = sB \u2212 sA. This version is equivalent, as also in REM-IR, the third party knows all syndromes (i.e., it can compute sB = se + sA from the publicly known se, sA). Furthermore, to increase the reliability and availability of the results, the computation can be delegated and distributed to an arbitrary number of third parties. The security is not jeopardized by any extended protocol involving more external untrusted parties and serves as a general baseline for such scenarios.\nEntropy 2023, 25, 226 7 of 18"
        },
        {
            "heading": "3.3. On Outsourcing Reverse Reconciliation",
            "text": "For continuous-variable QKD (CV-QKD), we have different requirements than for discrete-variable QKD which not only impact the modulation schemes but also the information reconciliation. On the Qbit level, CV-QKD uses homodyne detection, which allows for soft or hard decoding. For simplicity, we will look only at discrete modulated CV-QKD, particularly binary modulation. Therefore, in the following, we treat the CV-QKD system as a hard-input\u2013hard-output channel which operates on classical bit strings. The idea of reverse reconciliation was introduced by Maurer [27] for classical communication and later applied to CV-QKD to overcome the 3 dB loss limit [28]. In essence, reverse reconciliation is based on one-way error correction in a reverse configuration, with Bob sending the syndrome sB to Alice and Alice correcting her bits. The underlying model is based on two channels: one connecting Alice and Bob and the other connecting Alice and Eve. Interestingly, if reverse reconciliation is applied in this scenario, a key can still be distilled even if the channel from Alice to Eve is superior to the one from Alice to Bob. The secret capacity of the channel for reverse reconciliation in [27] was derived as Cs = Hb(e + d\u2212 2ed)\u2212 Hb(e) when Alice and Bob had access to a broadcast channel for public discussion. The bit error probabilities are e and d for the channels from Alice to Bob and Alice to Eve, respectively, and e + d\u2212 2ed for the conceptual channel from Bob to Eve. Hb is the binary entropy function. In the classical model of [27], Shannon entropy is used in the analysis. For the case of CV-QKD, the mutual information between Bob and Eve has to be replaced by the Holevo information, and finite key effects have to be considered [29]. However, both refinements do not affect our treatment based on generic BSC channels. For the secret channel capacity argument to be valid, Alice\u2019s key has to be kept private, thus preventing Eve from correcting the error bits in her key. With this additional requirement, outsourcing information reconciliation directly, as performed in REM-IR, is not possible. If both se and sB are leaked, then sA = se + sB can easily be computed, and the advantage over the conceptual channel is lost because Eve can correct all errors in the string with Alice and remove the uncertainty H(KE|KB). More formally, the following result shows that fully offloading error corrections (i.e., letting a third party perform the entire error correction and simply return e) to an untrusted party cannot be achieved for both classical reverse reconciliation and in the quantum setting:\nTheorem 2 (Impossibility of external syndrome decoding for classical RR). For reverse reconciliation in the classical (non-quantum) setting, full offloading syndrome decoding is not possible with a positive key rate.\nProof. Alice is connected to Bob and Eve over binary symmetric channels (BSCs) with error rates e and d, respectively. She sends out the very same signal kA, which is received as kB and kE. In the case of RR, we further have that Alice sends the signal kA but corrects her key for the error received by Bob (i.e., kB is the final key k). For binary random input encoding, it holds that H(KA) = H(KB) = 1, and the mutual information IAB := I(KA; KB) = 1\u2212 Hb(e) is defined by the error probability on the channel. KA, KB and KE are the binary correlated random variables at Alice, Bob and Eve, respectively. The amount of information required to be exchanged during public discussion for reverse reconciliation per channel use is |Q| \u2265 H(KB|KA) = Hb(e). For the proof, we assume that optimal codes reaching the Shannon limit are used (i.e., equality holds for the syndromes communicated). Thus, for offloading, any external party taking over the syndrome decoding for n bit keys based on a public H needs |se| = nHb(e) amount of information to correct for the errors on the AB channel. Note here that se itself does not carry any information about the key yet still fully defines the error e. We now prove the impossibility in two steps. (1) We calculate the change in mutual information by offloading the computation of e by Alice and therefore publishing the error\nEntropy 2023, 25, 226 8 of 18\nsyndrome se. (2) We then discuss the influence of discussion needed between Alice and Bob to compute the error syndrome se = sA \u2212 sB = kAH> \u2212 kBH> in the first place, which clearly needs contributions from both peers. Furthermore, we know that Eve is not allowed to learn enough information about k to correct all errors through its conceptual channel (i.e., IAB\u2013IEB have to be preserved or at least be larger than zero to leave Alice and Bob with a secure key). In the beginning of the protocol, we have IAB = 1\u2212 Hb(e) and IEB = 1\u2212 Hb(e + d\u2212 2ed). After publishing se and computing e in step (1), the mutual information per bit changes to I(i)AB = 1 and I (i) EB = 1\u2212 Hb(e + d\u2212 2ed) + Hb(e) = I (i) EA, respectively. This means that with knowledge of se and implicitly e, Alice can correct for all errors with Bob, but Eve is left with some remaining uncertainty. Now, to compute se = sA \u2212 sB, another nHb(e) bits have to be communicated in advance between Alice and Bob (2), which further impacts the knowledge of Eve about the keys. However, after exchanging another nHb(e) bits about kB in public to compute the error syndrome, we still have I(ii)AB = 1, but I (ii) EA is also increased to 1 because I (i) EB + Hb(e) = 1\u2212 Hb(e + d\u2212 2ed) + 2Hb(e) > 1. Alice already corrected all errors in step (1), and thus the additional information does not further increase their knowledge. On the contrary, for Eve, the information in step (2) is useful and further increases the mutual information with Bob up to the maximum of one, which means Eve has full knowledge about the agreed key. This is due to the fact that the published information is about the independent random variables KE and KB both contributing to the key agreement individually, where k = kB = kA + e. In summary, Eve either learns the key or, if step (2) is encrypted, leads to a negative key balance for QKD in the region of interest with d \u2264 e.\nCorollary 1 (Impossibility for quantum RR). For reverse reconciliation in the quantum setting, full offloading syndrome decoding is not possible with a positive key rate.\nProof. The quantum case is based on the same assumptions as the classical case and derives by looking at the entropies. Bob and Eve are connected to Alice over a quantum channel, where I(KA; KE) \u2265 I(KA; KB) holds. We also assume a symmetric system with H(KA) = H(KB) = 1, and consequently H(KA|KB) = H(KB|KA) as well as H(KA|KE) = H(KE|KA), due to Bayes\u2019 theorem. We also know from the definition of mutual information that Eve has less uncertainty about the final key (i.e., Bob\u2019s key) than Alice H(KA|KE) \u2264 H(KA|KB). Additionally, because the entropy function is concave, we also know that H(KA|KE) \u2264 H(KB|KE) \u2264 H(KA|KE) + H(KA|KB). Due to Slepian-Wolf\u2019s theorem [23], we require Bob to communicate H(KB|KA) bits (e.g., sB) to enable Alice to compute the error syndrome. Furthermore, we require Alice to eventually publish H(KA|KB) bits (e.g., se) in order to fully outsource error correction, also assuming an optimal code. Contrary to forward reconciliation, both strings published are useful for Eve because the information about the error is independent from the bits revealed about Bob\u2019s key. Thus, with access to this public information, Eve is now able to reduce its uncertainty H(KB|KE) about the key because\nH(KB|KE) \u2264 H(KA|KE) + H(KA|KB) < 2H(KA|KB) ,\nleading to I(KA; KE) = 1. In essence, after seeing se and sB, Eve can calculate sA = sB \u2212 se and remove all uncertainty H(KE|KA) < H(KA|KB) about kA and subsequently the final key k = kB.\nHowever, even with these results in mind, it is unclear if weaker notions of offloading would enable certain levels of partial or assisted secure outsourcing with positive key rates. An impossibility result for partial offloading is hard to formalize, as in an edge case, no meaningful computation would be delegated to the untrusted server, and the entire error reconciliation would be performed as local operations. In the following, we argue that no obvious or natural approaches for reasonable (partial) delegation of computations exist.\nEntropy 2023, 25, 226 9 of 18\nWe have seen that to be left with a secure key after all steps, the outsourced error reconciliation has to hide either se or sB with ITS properties. However, se cannot be encrypted by masking because the nature of the outsourced computation is to find a minimum weight vector which fulfills eH> = se for a given se and a public H, which always requires publishing a target vector e, which is the reference for distance minimization. Therefore, a simple solution is to encrypt sB during transmission with previously acquired secure key material. This requires nHb(e) additional key bits, leading to a reduced capacity of Cs\u2212enc = Hb(e + d\u2212 2ed)\u2212 2Hb(e). Although the protocol is secure and enables offloading of error correction, it does not lead to a positive key rate for the regions of interest where d < e, which is also shown in Figure 2.\nEntropy 2023, 25, 226 9 of 19\nleading to I(KA; KE) = 1. In essence, after seeing se and sB, Eve can calculate sA = sB \u2212 se and remove all uncertainty H(KE|KA) < H(KA|KB) about kA and subsequently the final key k = kB.\nHowever, even with these results in mind, it is unclear if weaker notions of offloading would enable certain levels of partial or assisted secure outsourcing with positive key rates. An impossibility result for partial offloading is hard to formalize, as in an edge case, no meaningful computation would be delegated to the untrusted server, and the entire error reconciliation would be performed as local operations. In the following, we argue that no obvious or natural approaches for reasonable (partial) delegation of computations exist.\nWe have seen that to be left with a secure key after all steps, the outsourced error reconciliation has to hide either se or sB with ITS properties. However, se cannot be encrypted by masking because the nature of the outsourced computation is to find a minimum weight vector which fulfills eH> = se for a given se and a public H, which always requires publishing a target vector e, which is the reference for distance minimizati n. Therefore, a si pl solution i to enc ypt sB during transmission with pr viously acquired secure key material. This requires nHb(e) additional key bits, leading to a reduced capacity of Cs\u2212enc = Hb(e + d\u2212 2ed)\u2212 2Hb(e). Although the protocol is secure and enables offloading of error correction, it does not lead to a positive key rate for the regions of interest where d < e, which is also shown in Figure 2.\nachievable, we review the most relevant and evident techniques to protect the key of Alice or even sA in an ITS sense to prevent Eve from learning Alice\u2019 key or increase I(KA; KE). In order to build an encrypted RR protocol, different techniques could be used, but the parity check matrix H is considered to be publicly known, which limits the application of hiding techniques to the raw key vector. Furthermore, the discussed solutions should not increase the computational effort to correct errors.\nWe start from the syndrome-decoding equation se = sA \u2212 sB = eH> and discuss options to hide sA from Eve or to prevent any increase in IAE by public discussion. In order\nTo give more evidence that an encrypted IR protocol with a positive key balance is not achievable, we review the most relevant and evident techniques to protect the key of Alice or even sA in an ITS sense to prevent Eve from learning Alice\u2019 key or increase I(KA; KE). In order to build an encrypt d RR protoco , different techniques could be used, but the parity check matrix H is considered to be publicly known, which limits the application of hiding techniques to the raw key vector. Furthermore, the discussed solutions should not increase the computational effort to correct errors. We start from the syndrome-decoding equation se = sA \u2212 sB = eH> and discuss options to hide sA from Eve or to prevent any increase in IAE by public discussion. In order to hide the bit flip positions, we discuss the following additional techniques, which are evident approaches toward the security goals for offloading RR but also not providing any positive key rate due to encrypting the raw key by the following means:\n\u2022 A one-time pad (OTP); \u2022 Permutation; \u2022 Padding (i.e., adding dummy (error) bits).\nEncryption. If the goal is to hide sA in an ITS way given that H is public, either se or sB must be one OTP encrypted. sB can be encrypted when transmitted to Bob or already at the key level, therefore ultimately hiding the key s\u2032B = (k + m)H\n>, where m is a random masking value, which must also be securely transmitted from Bob to Alice. However, in the first case, |sB| = nHb(e) bits are optimally required, and in the second case, a number of\nEntropy 2023, 25, 226 10 of 18\nraw key bits |k| is required, which is extremely inefficient. Above, we have already shown that even the first case leads to negative key rates. Unfortunately, encryption of se also cannot be used to hide bit error positions because decoding requires a start vector to explore the vicinity too. Finding a vector close to a random vector with public H leaks the bit flip positions e and therefore also se. Permutation. An alternative method to hide e, se and thus sA would be by permuting the raw key bits before running RR with an unencrypted sB. Using a permuted key k\u2032 = \u03a0(k) for the post-processing would render error correction information useless for Eve, but it has to be random for each block and applied on both peers in secret. Thus, a huge amount of shared key material is required, given that the permutation has to be selected randomly from the n! possible ones, which requires O(n log(n)) bits to represent. In the end, if the selected permutation has to be communicated over the public channel via OTP, the key balance is even worse than with syndrome encryption. Padding. Padding the raw key with dummy bits could be used to hide error bits if combined with permutation. This corresponds to the technique of mixing raw key with dummy key bits. However, in this case as well, the positions and value of the dummy key bits have to be agreed upon secretly by Alice and Bob, which also requires too many bits. Finally, additional errors could be introduced only to Alice. Because the remaining error margin in practical CV-QKD is already very small, this technique can only hide a small amount of information and substantially increases the computational work at the remote instance through the increased error rate. In summary, all natural approaches for partially offloading RR with a positive key rate to a single server in general seem unfeasible."
        },
        {
            "heading": "3.4. Verifiability of Outsourced IR",
            "text": "Aside from the challenge of efficient yet secure outsourcing of information reconciliation, it is also important to have a means to efficiently check the correctness of the solution. This prevents from actively malicious behavior of the remote instance performing the actual work. Fortunately, the problem of error decoding comes with an efficient algorithm to check the result: 1. Check if eH> = se; otherwise, abort the process. 2. Optional: Check if the weight of e is indeed below the threshold of the code or is\nconsistent with the estimated error, and abort otherwise.\nThe first check can be easily computed by conducting the vector matrix multiplication and only requires additions to modulo 2 (XOR) in the order of bits set in H, which is very efficient for LDPC codes. The second check is even faster if it can be performed for the used code. The Hamming weight of e must be smaller than what can be corrected by the code. However, the correction capabilities of a code cannot always be bound, especially for the often-used LDPC, where this is not possible. In such cases, only the estimated error rate can be used to test the hypothesis of a bit flip vector being correct. Nevertheless, there is still the final confirmation phase where an ultimate check is completed to assure the key error probability. However, directly verifying the IR outsourcing step enables attribution of errors to external servers and flexible reaction aside from aborting the whole process. In summary, verifiability immediately follows from the nature of the problem. This makes protection against malicious remote servers possible with minimal effort and does not require a full recomputation by Alice."
        },
        {
            "heading": "3.5. Multiparty Computation-Based Outsourcing",
            "text": "In the previous subsections, we presented an efficient solution for offloading direct reconciliation (DR) to a single server and discussed the problems with RR. Although relying on a single untrusted server seems to be the most desirable use case, it is natural to ask how efficient a multi-server configuration would be in cases where single-server offloading is not possible. If multiple servers are available, then ITS multiparty computation protocols (MPCs) based on secret sharing \u2014as introduced by Ben-Or et al. [30] and Chaum et al. [31]\u2014\nEntropy 2023, 25, 226 11 of 18\ncan be used to obliviously compute arbitrary functions on sensitive data, and thus they can also be used in CV-QKD because the inputs are kept private from the servers. The respective class of MPC protocols with ITS security operates in the honest majority setting (i.e., under the assumption that an adversary corrupts less than half of the MPC-computing nodes). Aside from the non-collusion assumption, the protocols also rely on secure channels, which can be assured by different means, as discussed in Section 5. More concretely, in MPCs, a set of parties can jointly evaluate a function without leaking any information to any of the participating parties beyond what can be derived from their own inputs and the computation result itself. Thus, an MPC provides input secrecy (or input privacy) (i.e., no party learns the input values of any other party) and correctness (i.e., the receiver of the result is ensured that the result is correct). In an honest majority setting with less than half of the servers being corrupt, ITS MPCs are among the most performant approaches for computing with encrypted data and achieve practical performance in many application scenarios. We therefore looked into the problem of MPC-based information reconciliation with ITS security on the basis of secret sharing [32]. If IR is performed in MPCs, the decoding can be accomplished without learning anything about the error syndrome se (private input) or error vector e (private output), but the parity check matrix can still be kept clear. In this model, the peer (Alice for RR) offloading IR is encoding the error syndrome as private input for the MPC system. The MPC system then obliviously computes the bit flip vector by executing a distributed protocol realizing a privacy-preserving LDPC decoder. The result of the computation is secretly shared among the MPC nodes after the protocol run and sent back to the peer (Alice), who can reconstruct it. To demonstrate the feasibility of the solution, we study the practical efficiency of error decoding for low-density parity check (LDPC) codes in an existing MPC framework and estimate the performance that can be achieved. To the best of our knowledge, this is the first time this problem is considered. The only known related work was presented by Raeini and Nojoumian [33], who only considered Berlekamp\u2013Welch decoding for Reed\u2013Solomon codes. In general, we distinguish two main types of message-passing algorithms for LDPC decoding: bit-flipping algorithms and belief propagation [34]. The decoding approach typically used in QKD is from the category of belief propagation (BP) and specifically uses sum-product mechanisms to update beliefs, an approach which works very efficiently on plaintext data. Unfortunately, this approach is not well suited for direct application in MPCs. This is because the algorithm works on floating point numbers and uses trigonometric functions in the belief update part, with both being very inefficient in MPCs. Thus, to initiate the research topic, we focused on bit-flipping (BF) algorithms first in our implementation approach because they seemed to be more promising, although they suffer from inferior performance in terms of information rate. BF algorithms have a very simple structure and work extremely fast (e.g., if implemented in hardware). The bit-flipping algorithm is a non-probabilistic hard-input hard-output decoding algorithm and works on the Tanner graph representation of the code. The messages passing back and forth are all binary. The main structure of the BF algorithm is similar for all variants. In the first step, the variable nodes send their current values to the check nodes. Then, the check nodes compute their values and feed back the results to the adjacent variable nodes, signaling if the check is valid. After each variable node receives the check bits from all connected check nodes, the current guess for the code word is updated. Different approaches exist to update the variable nodes, and to the best of our knowledge, no optimized codes or methods for the particular case of QKD have been studied or analyzed. Therefore, we selected one of the most prominent solutions\u2014Gallager\u2019s algorithm [35]\u2014to demonstrate feasibility and applied it to (non-optimized) codes available for BP algorithms. We developed an MPC version for the bit flip-decoding algorithm which is shown in Figure 1, where [[\u00b7]] denotes variables which are processed in the encrypted domain and are therefore kept confidential. The implementation assures that the code word itself as well as related information is only kept in a secret shared form among the parties and never revealed\nEntropy 2023, 25, 226 12 of 18\nduring computation. On a high level, the algorithm performs message passing in a Tanner graph defined by the parity check matrix H, with binary variables represented by public integers with values zero and one. We encoded the bits on integers because ITS-MPCs work on algebraic circuits, with additions being compared almost for free and multiplications requiring interactions between nodes. This allowed us to quickly count the number of ones in a vector of bits and also enabled exclusivity over vectors by reducing modulo two after summing them up. The algorithm comprises four major steps which are iteratively repeated until a valid code word is found or the maximum number of iterations is reached:\n\u2022 In the first step, the variable nodes pass their values to the check nodes, where they are combined to compute the check value, which is zero when the check is fulfilled and one if not. \u2022 In the second step, the values of the check nodes are passed back to the variable nodes, where they are aggregated (i.e., the number of check nodes not satisfied is counted for each variable node). \u2022 Thirdly, the algorithm terminates if all checknodes are zero. \u2022 Finally, the algorithm computes which variable nodes have to be flipped. Here, we\nused Gallager\u2019s algorithm B [35] in our implementation, which basically compares the counts computed in step two against a threshold value to decide which bits are flipped. Although the threshold value for comparison is public, this comparison has to be carried out obliviously to protect the variable node state as well as the bit flip information.\nFrom a performance point of view, all steps except the last one are extremely fast in MPCs, given that additions are only local operations and do not need any communication among the MPC peers, and the reductions in step one can be performed in parallel. The oblivious comparisons necessary to decide for each bit (if it has to be flipped or not) are the costly operations and limit the throughput in MPC implementation. However, modern highly optimized MPC systems such as MP-SPDZ (https://github.com/data61/MP-SPDZ (accessed on 23 January 2023)) are able to achieve good performance even for this task, as the results in Table 1 show. These results indicate that MPC-based real-time decoding for QKD is possible.\nClearly, to achieve the best performance, optimized codes must be studied and designed in tandem with MPC protocols [36]. In addition, BP-based alternatives to sum-product decoding should be studied to see how fast MPC versions of belief propagation methods can be pushed. Additionally, for CV-QKD, approximation approaches combined with multiedge-type codes [22] seem promising for fast MPC implementation. Nevertheless, our experiment already showed the first results and paves the way for practical rates.\nEntropy 2023, 25, 226 13 of 18\nFinally, optimization-based decoding would also be possible as an alternative to message-passing algorithms (i.e., by leveraging linear programming (LP)). In LP decoding [37,38], the maximum likelihood decoding problem is formulated as a linear program. Thus, it is possible to decode a symbol by solving an associated LP with conventional approaches (e.g. with a simplex algorithm where MPC versions also exist [39]). However, for the QKD use case with block sizes k in the range from 104 to 106 bits and high error rates, the formulation would lead to a relatively large simplex tableau. Very low rates can be expected for this solution approach, given the measured performance for MPC-based LP solving reported in [40].\nAlgorithm 1: MPC version of bit flip decoding with Gallager\u2019s Algorithm B Input: [[c]] being the codeword to correct as list of 0/1 bits [[ci]] stored in secure\ninteger h representing H as adjacency list of a Tanner graph with hi being a index list of ones in row i of H t is a vector containing the number of 1s of each column in H n, k, p as code parameters itermax iteration limit\nResult: [[c]] the corrected codeword after updating iter \u2190 0 while True do\niter \u2190 iter + 1 /* step 1: calculate sum at check nodes */ for row \u2208 h do\n[[vi]]\u2190 \u2211i\u2208row [[ci]] [[vi]]\u2190 [[vi]] (mod 2)\nend /* step 2: count failed checks for every code bit */ [[ f ]]\u2190 [0 . . . 0] for i\u2190 1 to p do\nfor node \u2208 hi do [[ fnode]]\u2190 [[ fnode]] + [[vi]]\nend end /* step 3: if all checknodes are 0 then exit */ [[ fsum]]\u2190 \u2211i\u2208{1,..,n}[[ fi]] if fsum = 0 or iter > itermax then\nbreak while end /* step 4: calculate and apply bit flip vector */ lvl = 1 while True do\nfor j\u2190 1 to n do [[bj]]\u2190 [[ f j]] > b(tj/(lvl + 1))c end [[bsum]] = \u2211[[bi]] if bsum = 0 then lvl \u2190 lvl + 1 else\n[[c]]\u2190 [[c]] + [[b]] break while\nend end\nend\nEntropy 2023, 25, 226 14 of 18"
        },
        {
            "heading": "4. Offload Privacy Amplification",
            "text": "Privacy amplification (PA) is another important step in the post-processing stack (cf. Section 2.1). This also requires a public channel for communication and is typically based on application of a randomly selected hash of a universal hash family, thus achieving information-theoretical secure randomness extraction. PA is used to extract the mutual information between Alice and Bob such that the adversary Eve is left without any information, except for a negligible error that can be made arbitrarily small. Although the underlying matrix-vector multiplication seems rather efficient, because of finite key effects and its influence on the secure key rate, a large block length has to be used [29]. Therefore, this step is also computationally very demanding [6], and solutions to entirely offloading this task from the device, or at least from the trusted area within a device, would be desirable. In a PA protocol, Alice randomly selects a hash from a family of universal hashes with the right compression rate\u2014based on Eve\u2019s potential knowledge on the key\u2014and communicates the selected function publicly to Bob. Both peers then apply the same function on the local reconciled key and arrive at the final shared key. The main property of a universal hash family is that they guarantee a low number of collisions, even if the input is chosen by an adversary. Because the block length in QKD is large, the complexity of the universal hashes is also relevant. One family of strongly universal hashes is given by multiplication of the raw key with a random matrix which would need a lot of randomness. Nevertheless, to reduce the randomness needed, a Toeplitz matrix can also be used for PA, which requires only n + m random bits compared with the n \u00b7m for a random matrix. The use of the Toeplitz matrix also reduces the computational effort for PA because the diagonal structure enables the use of a number theoretical transforms for faster processing of the vector matrix product.\nAssume that k\u2032A = k \u2032 B = k \u2032 is the reconciled key at Alice and Bob with a length n and k represents the final keys of a length m. Then, PA works as follows:\n1. Alice randomly generates a uniform string of a length n + m\u2212 1 defining the Toeplitz matrix T and sends it to Bob. 2. Alice computes k = k\u2032 T as the final key. 3. Bob receives T from Alice and also computes his key as k = k\u2032 T.\nThus, both parties perform the same vector-matrix multiplication to shrink the identical keys from n to m bits, where the ratio n/m for CV-QKD is computed as demonstrated by Leverrier et al. [29] and for DV-QKD as shown by Scarani et al. [25]. If we want to offload PA, we would have to offload the core vector-matrix multiplication, which reduces the n raw key bits to m final bits. The ratio is already known at the beginning of the PA step, but the Toeplitz matrix has to be generated for each block and exchanged clearly, which makes offloading a problem. If T could be kept secret, it would be possible to use a permutation-based approach for PA offloading to a single server, but for a public matrix, this is not possible. However, encrypting T is not an option, as it can be immediately seen that the key balance becomes negative if the encryption key for the matrix is longer than the raw key processed. Thus, hiding the input and output keys while still offloading the computation is not feasible in a single-sever model. However, if multiple servers are available, a very efficient non-interactive multiparty protocol is possible (i.e., without requiring the servers to communicate). The protocol is shown in Figure 3. The peer shares the raw key in n parts with a linear secret sharing scheme\u2014working over F2 or a larger prime field Fp\u2014and sends them to the servers (one share per server). The servers compute the [[k\u2032]] = [[k]]T, where [[\u00b7]] denotes the sharing of a value. Because of the linearity of the secret sharing scheme, the necessary multiplications with public constants and additions can be carried out on the shares without interaction between the servers. The results are then sent back to Alice, who reconstructs the final key. For the case of prime fields, Alice additionally reduces the result vector mod 2.\nEntropy 2023, 25, 226 15 of 18\nEntropy 2023, 25, 226 15 of 19 exchanged clearly, which makes offloading a problem. If T could be kept secret, it would be possible to use a permutation-based approach for PA offloading to a single server, but for a public matrix, this is not possible. However, encrypting T is not an option, as it can be immediately seen that the key balance becomes negative if the encryption key for the matrix is longer than the raw key processed. Thus, hiding the input and output keys while still offloading the computation is not feasible in a single-sever model.\nHowever, if multiple servers are available, a very efficient non-interactive multiparty protocol is possible (i.e., without requiring the servers to communicate). The protocol is shown in Figure 3. The peer shares the raw key in n parts with a linear secret sharing scheme\u2014working over F2 or a larger prime field Fp\u2014and sends them to the servers (one share per server). The servers compute the [[k\u2032]] = [[k]]T, where [[\u00b7]] denotes the sharing of a value. Because of the linearity of the secret sharing scheme, the necessary multiplications with public constants and additions can be carried out on the shares without interaction between the servers. The results are then sent back to Alice, who reconstructs the final key. For the case of prime fields, Alice additionally reduces the result vector mod 2.\nThe security of the protocol against a passive adversary is governed by the security of the underlying secret sharing scheme. Because the parties do not interact with each other but only communicate with the peer, they cannot learn any information about the final key as long as ITS linear secret sharing is used (e.g., additive or Shamir secret sharing [32]). The computational effort of the solution is the same for every server, which would also be the same as for local computation. Unfortunately, the REM-PA protocol does not provide efficient verifiability aside from recomputation or spot checking, and therefore efficient protection against active attackers cannot be easily achieved during the PA phase. However, if the confirmation round is shifted to after PA, then it will detect errors in the keys and prevent from erroneous keys by aborting the protocol. Thus, it can also detect malicious behavior by the external servers but not directly attribute the errors to them. If the confirmation is shifted to after PA, then it is important to encrypt the tag sent because otherwise, the leaked information cannot be removed anymore, as is normally carried out by PA. Additionally, a secure channel is assumed to distribute the shares to the severs, which may prevent from certain use cases. However, contrary to the MPC-based LDPC decoding, no interaction between servers is required.\n5. Use Cases\nTo answer why offloading computationally intensive tasks is interesting at all, we present the expected benefits in general and discuss advantages for certain networking scenarios.\nFigure 3. REM-PA protocol.\nThe security of the protocol agai st a assive a versary is governed by the security of the underlying secret sharing sche e. Because the parties do not interact with each other but only communicate with the peer, they cannot learn any infor ation about the final key as long as ITS linear secret sharing is used (e.g., additive or Shamir secret sharing [32]). The computational effort of the solution is the same for every server, which would also be the same as for local computation. Unfortunately, the REM-PA protocol does not provide efficient verifiability aside from recomputation or spot checking, and therefore efficient protection against active attackers cannot be easily achieved during the PA phase. However, if the confirmation round is shifted to after PA, then it will detect errors in the keys and prevent from erroneous keys by aborting the protocol. Thus, it can also detect malicious behavior by the external servers but not directly attribute the errors to them. If the confirmation is shifted to after PA, then it is important to encrypt the tag sent because otherwise, the leaked information cannot be removed anymore, as is normally carried out by PA. Additionally, a secure channel is assumed to distribute the shares to the severs, which may prevent from certain use cases. However, contrary to the MPC-based LDPC decoding, no interaction between servers is required."
        },
        {
            "heading": "5. Use Cases",
            "text": "To answer why offloading computationally intensive tasks is interesting at all, we present the expected benefits in general and discuss advantages for certain networking scenarios. The overall goal which can be achieved is savings in energy or cost at the device side, beneficially impacting the cost-effectiveness of the end user\u2019s equipment. Therefore, if the devices are simpler and require less computational power, then the cost savings could be substantial (e.g., in cases where the user buys the equipment). Compared with data center environments, the devices are also less energy-efficient for running computation-intensive tasks. If this part can be offloaded to a more efficient data center, then the overall operational cost can also be lowered. Therefore, dedicated cloud solutions which further pool information reconciliation for a larger amount could further help to reduce energy consumption. By regularly updating the external hardware resources, the system can benefit from Moore\u2019s law and the continuous drop in cost of computation resources. They can even be shifted flexibly between different locations and data centers to optimize energy usage and cost if more offerings are available. In general, it would even be possible to leverage public cloud services for REM-IR, which requires no trust assumption at all for the environment. Because of these arguments, we think the ability to offload and relocate computationally intensive tasks also leads to higher energy efficiency for computation resources. Additionally, it could also lead to more flexibility on the QKD level (i.e., QKD as a service). The virtualization of the computationally expensive post-processing tasks could be convenient in the future. Not all optical network units (ONUs) have access to QKD\nEntropy 2023, 25, 226 16 of 18\nfunctionality, but the same hardware may be used for coherent passive optical networks (PONs) and CV-QKD [41,42]. Therefore, we may provide QKD to them by just allocating additional processing resources while also switching their software-defined transceiver into QKD mode. Furthermore, networking equipment is installed for longer times and not updated often. This is even more true for high-cost security-certified equipment, because upgrading security-certified equipment is a cumbersome and costly process which typically requires recertification. Being able to update certain non-critical components without needing to exchange or recertify the core QKD device hardware can greatly simplify the upgrade process. To show how the advantages relate to concrete use cases, we will quickly mention three examples. Access networks. In the case of access networks, we find constraint resources (computing energy), and the network units must be low-cost because they are the driving cost factor, especially since only very low key rates are typically required (AES key refreshing). If computational resources are pooled in such a scenario, costs can be substantially reduced not just in case of a reduced user subscription ratio but also due to time sharing of centralized CPU resources. Furthermore, because the optical part is low energy, the dominant cost and energy factor is when a CPU is partially idle, which should be avoided. Satellite communication. Satellites have a particularly long lifetime (20\u201330 years) and have to be remotely operated and maintained. They also have limited access to energy resources and reducing energy consumption is of paramount interest. This is especially true if low-cost (mobile) earth stations should be supported or even inter-satellite links. Offloading post-processing can make satellite transceivers possible and increase the connectivity for individual satellites. Integrated COTS Hardware. Finally, aside from the evident advantages of outsourcing protocols such as REM-IR to data centers, the concept can also be interesting when applied within the device. QKD devices are complex systems [43] and comprise many different components, which makes security auditing and certification very hard. To achieve strong security guarantees, only trustworthy hardware and software can be used to process key material in plaintext [44]. Furthermore, to prevent from side channel attacks and backdoors, it would be desirable to reduce the number of trusted components and the complexity of the secure environment in a device as well as possible. Therefore, if the components processing sensitive key materials can be reduced, this results in a smaller attack surface, simplifies security analysis and helps in the certification process. The MPC-based protocols presented can be used for this purpose (i.e., to reduce the trusted environment on the device architecture level with all its benefits). Within a device, it is also feasible to realize the secure channels required in the MPC model. Thus, it would allow for the integration of COTS hardware in QKD systems only processing keys in encrypted form."
        },
        {
            "heading": "6. Conclusions",
            "text": "In this work, we introduced the idea of offloading the information reconciliation and privacy amplification steps of QKD post-processing. These are the two computationally intensive tasks in processing raw key measurements to secure a shared key between two QKD peers. We showed that outsourcing information reconciliation is possible and straightforward for DV-QKD, even in a single-server model and against an active adversary. However, for CV-QKD, which leverages reverse reconciliation to overcome the 3 dB transmission bound, the same is not true. We also gave an intuition that it is not possible in general to achieve positive key rates with a single server and analyze potential performance in a multi-server setting. We also looked into privacy amplification, where we propose a protocol for multiple servers. Finally, we laid out the potential benefits and discussed use cases where this approach is relevant. Proving the impossibility of single-server PA offloading as well as weak offloading is left for future work. Additionally, MPC-optimized versions of sum-product decoders are currently under investigation and will be presented in a follow-up work.\nEntropy 2023, 25, 226 17 of 18"
        },
        {
            "heading": "7. Patents",
            "text": "The basic scheme IC-REM from this work was first patented in Austria (AT519476B1) and later in Europe (EP3607446B1) and the US as well (US11128445B2). However, only in this work did we provide the security analysis and additional methods as well as the limitations for the technology.\nAuthor Contributions: Conceptualization, T.L. and B.S.; methodology, T.L, S.K., C.P. and B.S.; validation, T.L., S.K. and C.P.; formal analysis, T.L. and S.K.; investigation, T.L.; writing\u2014original draft preparation, T.L., S.K., and C.P.; writing\u2014review and editing, T.L., S.K, C.P. and B.S. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received funding from the European Union\u2019s Horizon 2020 research and innovation program under grant agreement No. 857156 (OPENQKD) and No. 830929 (CyberSec4Europe).\nInstitutional Review Board Statement: Not applicable.\nData Availability Statement: Not applicable.\nConflicts of Interest: The authors declare no conflict of interest.\nReferences 1. Martinez-Mateo, J.; Pacher, C.; Peev, M.; Ciurana, A.; Martin, V. Demystifying the information reconciliation protocol cascade. Quantum Inf. Comput. 2015, 15, 453\u2013477. [CrossRef] 2. Pedersen, T.B.; Toyran, M. High performance information reconciliation for QKD with CASCADE. Quantum Inf. Comput. 2015, 419\u2013434. [CrossRef] 3. Mao, H.K.; Qiao, Y.C.; Li, Q. High-Efficient Syndrome-Based LDPC Reconciliation for Quantum Key Distribution. Entropy 2021, 23. [CrossRef] [PubMed] 4. Pacher, C.; Abidin, A.; Lor\u00fcnser, T.; Peev, M.; Ursin, R.; Zeilinger, A.; Larsson, J. Attacks on quantum key distribution protocols that employ non-ITS authentication. Quantum Inf. Process. 2016, 15, 327\u2013362. [CrossRef] 5. Maurhart, O.; Pacher, C.; Happe, A.; Lor, T.; Tamas, C.; Poppe, A.; Peev, M. New release of an open source QKD software:\ndesign and implementation of new algorithms, modularization and integration with IPSec. In Proceedings of the QCRYPT 2013, Waterloo, ON, Canada, 5\u20139 August 2013.\n6. Wang, X.; Zhang, Y.; Yu, S.; Guo, H. High-speed implementation of length-compatible privacy amplification in continuous-variable quantum key distribution. IEEE Photonics J. 2018, 10, 1\u201310. [CrossRef] 7. Li, Y.; Zhang, X.; Li, Y.; Xu, B.; Ma, L.; Yang, J.; Huang, W. High-throughput GPU layered decoder of quasi-cyclic multi-edge type low density parity check codes in continuous-variable quantum key distribution systems. Sci. Rep. 2020, 10, 14561. [CrossRef] 8. Yang, S.S.; Lu, Z.G.; Li, Y.M. High-Speed Post-Processing in Continuous-Variable Quantum Key Distribution Based on FPGA Implementation. J. Lightwave Technol. 2020, 38, 3935\u20133941. [CrossRef] 9. Yang, S.S.; Liu, J.Q.; Lu, Z.G.; Bai, Z.L.; Wang, X.Y.; Li, Y.M. An FPGA-Based LDPC Decoder with Ultra-Long Codes for ContinuousVariable Quantum Key Distribution. IEEE Access 2021, 9, 47687\u201347697. [CrossRef] 10. M\u00fcller-Quade, J.; Renner, R. Composability in quantum cryptography. New J. Phys. 2009, 11, 85006. [CrossRef] 11. Wegman, M.N.; Carter, L. New Hash Functions and Their Use in Authentication and Set Equality. J. Comput. Syst. Sci. 1981, 22, 265\u2013279. [CrossRef] 12. Banfi, F.; Maurer, U.; Portmann, C.; Zhu, J. Composable and Finite Computational Security of Quantum Message Transmission. In Proceedings of the Theory of Cryptography; Hofheinz, D., Rosen, A., Eds.; Springer: Cham, Switzerland, 2019; pp. 282\u2013311. 13. L\u00fctkenhaus, N. Estimates for practical quantum cryptography. Phys. Rev. A 1999, 59, 3301\u20133319. [CrossRef] 14. Yuan, Z.; Plews, A.; Takahashi, R.; Doi, K.; Tam, W.; Sharpe, A.; Dixon, A.; Lavelle, E.; Dynes, J.; Murakami, A.; et al. 10-Mb/s Quantum Key Distribution. J. Lightwave Technol. 2018, 36, 3427\u20133433. [CrossRef] 15. Ren, S.; Yang, S.; Wonfor, A.; White, I.; Penty, R. Demonstration of high-speed and low-complexity continuous variable quantum key distribution system with local local oscillator. Sci. Rep. 2021, 11, 9454. [CrossRef] 16. Neppach, A.; Pfaffel-Janser, C.; Wimberger, I.; Loruenser, T.; Meyenburg, M.; Szekely, A.; Wolkerstorfer, J. Key management of\nquantum generated keys in IPSEC. In Proceedings of the International Conference on Security and Cryptography SECRYPT 2008, Porto, Portugal, 26\u201329 July 2008.\n17. Bennett, C.H.; Brassard, G. Quantum cryptography: Public key distribution and coin tossing. In Proceedings of the Proceedings of IEEE International Conference on Computers, Systems, and Signal Processing, Bangalore, India, 9\u201312 December 1984. 18. Gr\u00fcnenfelder, F.; Boaron, A.; Rusca, D.; Martin, A.; Zbinden, H. Performance and security of 5 GHz repetition rate polarizationbased quantum key distribution. Appl. Phys. Lett. 2020, 117, 144003. [CrossRef] 19. Brassard, G.; Salvail, L. Secret-Key Reconciliation by Public Discussion. In Proceedings of the Advances in Cryptology\u2014 EUROCRYPT \u201993, Workshop on the Theory and Application of of Cryptographic Techniques, Lofthus, Norway, 23\u201327 May 1993.\nEntropy 2023, 25, 226 18 of 18\n20. Pacher, C.; Grabenweger, P.; Martinez-Mateo, J.; Martin, V. An information reconciliation protocol for secret-key agreement with small leakage. In Proceedings of the 2015 IEEE International Symposium on Information Theory (ISIT), Hong Kong, China, 14\u201319 June 2015. 21. Elkouss, D.; Martinez, J.; Lancho, D.; Martin, V. Rate compatible protocol for information reconciliation: An application to QKD. In Proceedings of the 2010 IEEE Information Theory Workshop on Information Theory (ITW 2010), Dublin, Ireland, 30 August\u20133 September 2010. 22. Mani, H.; Gehring, T.; Grabenweger, P.; \u00d6mer, B.; Pacher, C.; Andersen, U.L. Multiedge-type low-density parity-check codes for continuous-variable quantum key distribution. Phys. Rev. A 2021, 103, 062419. [CrossRef] 23. Slepian, D.S.; Wolf, J.K. Noiseless coding of correlated information sources. IEEE Trans. Inf. Theory 1973, 19, 471\u2013480. [CrossRef] 24. Wyner, A.D.; Ziv, J. The rate-distortion function for source coding with side information at the decoder. IEEE Trans. Inf. Theory 1976, 22, 1\u201310. [CrossRef] 25. Scarani, V.; Bechmann-Pasquinucci, H.; Cerf, N.J.; Dusek, M.; L\u00fctkenhaus, N.; Peev, M. The security of practical quantum key distribution. Rev. Mod. Phys. 2009, 81, 1301\u20131350. [CrossRef] 26. Martinez-Mateo, J.; Elkouss, D.; Martin, V. Blind Reconciliation. arXiv 2012, arXiv:1205.5729. 27. Maurer, U.M. Secret key agreement by public discussion from common information. IEEE Trans. Inf. Theory 1993, 39, 733\u2013742. [CrossRef] 28. Furrer, F. Reverse-reconciliation continuous-variable quantum key distribution based on the uncertainty principle. Phys. Rev. A 2014, 90, 042325. [CrossRef] 29. Leverrier, A.; Grosshans, F.; Grangier, P. Finite-size analysis of a continuous-variable quantum key distribution. Phys. Rev. A 2010, 81. [CrossRef] 30. Ben-Or, M.; Goldwasser, S.; Wigderson, A. Completeness theorems for non-cryptographic fault-tolerant distributed computation. In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing (STOC \u201988), Chicago, IL, USA, 2\u20134 May 1988. 31. Chaum, D.; Crepeau, C.; Damgdr, I. Multiparty unconditionally secure protocols. In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing (STOC \u201988), Chicago, IL, USA, 2\u20134 May 1988. 32. Shamir, A. How to Share a Secret. Commun. ACM 1979, 22, 612\u2013613. [CrossRef] 33. Raeini, M.G.; Nojoumian, M. Secure error correction using multiparty computation. In Proceedings of the 2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC 2018), Las Vegas, NV, USA, 8\u201310 January 2018. 34. Richardson, T.J.; Urbanke, R.L. The capacity of low-density parity-check codes under message-passing decoding. IEEE Trans. Inf. Theory 2001, 47, 599\u2013618. [CrossRef] 35. Gallager, R.G. Low-Density Parity-Check Codes; MIT Press: Cambridge, MA, USA, 1963. 36. Lor\u00fcnser, T.; Wohner, F. Performance Comparison of Two Generic MPC-frameworks with Symmetric Ciphers. In Proceedings\nof the 17th International Joint Conference on e-Business and Telecommunications, SCITEPRESS\u2014Science and Technology Publications, Virtual Conference, 8\u201310 July 2020.\n37. Feldman, J.; Wainwright, M.J.; Karger, D.R. Using linear programming to decode binary linear codes. IEEE Trans. Inf. Theory 2005, 51. [CrossRef] 38. Feldman, J. Decoding Error-Correcting Codes via Linear Programming. Ph.D. Thesis, Massachusetts Institute of Technology, Cambridge, MA, USA, 2003. 39. Toft, T. Solving Linear Programs Using Multiparty Computation. In Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics); Springer: Berlin/Heidelberg, Germany, 2009; Volume 5628 LNCS, pp. 90\u2013107. [CrossRef] 40. Lor\u00fcnser, T.; Wohner, F.; Krenn, S. A Verifiable Multiparty Computation Solver for the Assignment Problem and Applications to Air Traffic Management. arXiv 2022, arXiv:2205.03048. 41. Milovancev, D.; Honz, F.; Vokic, N.; Laudenbach, F.; H\u00fcbel, H.; Schrenk, B. Ultra-Low Noise Balanced Receiver with >20 dB Quantum-to-Classical Noise Clearance at 1 GHz. In Proceedings of the European Conference on Optical Communication, (ECOC 2021), Bordeaux, France, 13\u201316 September 2021. 42. Milovanc\u030cev, D.; Vokic\u0301, N.; Pacher, C.; Khan, I.; Marquardt, C.; Boxleitner, W.; H\u00fcbel, H.; Schrenk, B. Towards Integrating True Random Number Generation in Coherent Optical Transceivers. IEEE J. Sel. Top. Quantum Electron. 2020, 26, 1\u20138. [CrossRef] 43. Treiber, A.; Poppe, A.; Hentschel, M.; Ferrini, D.; Lor\u00fcnser, T.; Querasser, E.; Matyus, T.; H\u00fcbel, H.; Zeilinger, A. Fully automated entanglement-based quantum cryptography system for telecom fiber networks. New J. Phys. 2009, 11, 20. [CrossRef] 44. Loruenser, T.; Querasser, E.; Matyus, T.; Peev, M.; Wolkerstorfer, J.; Hutter, M.; Szekely, A.; Wimberger, I.; Pfaffel-Janser, C.; Neppach, A. Security processor with quantum key distribution. In Proceedings of the Application-Specific Systems, Architectures and Processors (ASAP 2008), Leuven, Belgium, 2\u20134 July 2008.\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "On the Security of Offloading Post-Processing  for Quantum Key Distribution",
    "year": 2023
}