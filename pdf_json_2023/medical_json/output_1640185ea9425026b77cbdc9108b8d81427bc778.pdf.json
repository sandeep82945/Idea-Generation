{
    "authors": [
        {
            "affiliations": [],
            "name": "Robert Burnham Laverty"
        },
        {
            "affiliations": [],
            "name": "Mustafa T. Khan"
        },
        {
            "affiliations": [],
            "name": "Ronit Patnaik"
        },
        {
            "affiliations": [],
            "name": "Christina Sooyeon Lee"
        },
        {
            "affiliations": [],
            "name": "Mamie C. Stull"
        }
    ],
    "id": "SP:069cd83448e2bbbae4e881e293fa6030da04a9b7",
    "references": [
        {
            "authors": [
                "RE Perez",
                "S. Schwaitzberg"
            ],
            "title": "Robotic surgery: nding value in 2019 and beyond",
            "venue": "Ann Laparosc Endosc Surg. 2019;4:51",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Page 2/13\nMethods: Multi-institutional, prospective study involving medical students (MS) and general surgery residents (PGY1-3). Participants performed an exercise using a biotissue bowel model on the da Vinci Xi robotic console during which they created an enterotomy using electrocautery followed by approximation with interrupted sutures. Participant performance was recorded and then scored by crowd-sourced assessors of technical skill along with three of the authors. Construct validity was determined via difference in Global Evaluative Assessment of Robotic Skills (GEARS) score, time to completion and total number of errors between the two cohorts. Upon completion of the exercise, participants were surveyed on their perception of the exercise and its impact on their robotic training to determine content validity.\nResults: 31 participants were enrolled and separated into two cohorts: MS + PGY1 vs PGY2-3. Time spent on the robotic trainer (0.8 vs 8.13 hours, p=0.002), number of bedside robotic assists (5.7 vs 14.8, p<0.001), and number of robotic cases as primary surgeon (0.3 vs 13.1, p<0.001) were statistically signi cant between the two groups. Differences in GEARS scores (18.5 vs 19.9, p=0.001), time to completion (26.1 vs 14.4 min, p<0.001), and total errors (21.5 vs 11.9, p=0.018) between the groups were statistically signi cant as well. Of the 23 participants that completed the post-exercise survey, 87% and 91.3% reported improvement in robotic surgical ability and con dence, respectively. On a 10-point Likert scale, respondents rated the realism of the exercise 7.5, educational bene t 9.1, and effectiveness in teaching robotic skills 8.7. Controlling for the upfront investment of certain training materials, each exercise iteration cost ~$30.\nConclusions: This study con rmed the content, response process, internal structure and construct validity of a novel, high- delity and cost-effective inanimate tissue exercise which successfully incorporates electrocautery. Consideration should be given to its addition to robotic surgery training programs.\nIntroduction Since the initial FDA approval for its use in 2000, robot-assisted surgery has increased in prevalence, particularly in the eld of general surgery [1]. A majority of the over one million robotic surgeries performed in 2019 were general surgery procedures [2\u20134]. While many surgeons cite the platform\u2019s visual and ergonomic advantages to laparoscopy, high-pro le complications have led to increased public scrutiny regarding proper use of the technology [5, 6]. A particular concern is the extent to which robotic surgeons are trained in the platform\u2019s use. In contrast to laparoscopy, where US general surgeons must\nPage 3/13\ncomplete didactic and skills-based curricula and testing for board certi cation, no such requirements exist for robotic-assisted surgery.\nTo address these de ciencies, academic surgery programs along with the groups behind Fundamentals of Robotic Surgery, Robotic Training Network and Fundamental Skills of Robotic Surgery have developed and implemented formalized robotic training programs that incorporate online training, console simulation, and live operating experience both at the beside and robot console [7\u201315]. However, variations in content and application are broad and there remains no consensus for robotic training standards.\nSimulation such as virtual reality trainers, animal, cadaveric and inanimate tissue platforms plays a critical role in existing training curricula as it provides training in a low-stakes environment while allowing the trainee to improve their psychomotor and basic procedural skills. It remains di cult to discern the optimal training platform. Virtual reality trainers, for example, can cost up to $158,000 and are known to poorly emulate electrocautery [16\u201318]. Animal and cadaveric platforms also can be prohibitively expensive and can present ethical challenges for some programs/surgeons. Inanimate training exercises bridge this gap by utilizing the already procured da Vinci system to provide high delity training in a costeffective manner, particularly those that use biotissue models versus traditional box trainers. A persistent need exists for inanimate tissue model that incorporates electrocautery for standardized robotic training curricula. Currently described cautery simulation platforms are expensive and cheaper high- delity cautery simulations are needed [18].\nWe developed such a model using a double-layered bowel model secured to a moistened household sponge that simulates skills such as tissue handling, camera control, suturing, and electrocautery. We then set out to establish the content, response process, internal structure and construct validity of the exercise using Messick\u2019s validity framework [19].\nMethods This research was approved by the 59th Medical Wing, Joint Base San Antonio and University of Texas Health at San Antonio Institutional Review Boards and determined to be exempt. This was a multiinstitutional, prospective study involving medical students (MS) and general surgery residents (PGY1-3). Participants were recruited via email and provided with informed consent. They were then separated into two cohorts (MS + PGY1 vs PGY2/3).\nAn inanimate tissue model was created using a double-layered hydrogel bowel model produced by LifeLike BioTissue Inc. (London, Ontario, Canada) and assembled by research staff. The base of the bowel model was sutured to a heavy-duty cleaning sponge and then marked with a longitudinal incision line measuring 5cm with ve pairs of dots evenly spaced 1cm from each other and 5mm from the incision line to mark locations for the suture needle to enter and exit the bowel. This was then secured to an electrocautery bovie pad within a robotic abdominal dome trainer. [20]. Participants were then asked to\nPage 4/13\ncreate a longitudinal enterotomy using electrocautery with monopolar scissors followed by closure with interrupted suture using the dots as landmarks on where to enter and exit the model.\nParticipants rst completed a pre-study survey on which they self-reported select demographic information and surgical experience. Prior to performing the exercise, participants were provided with a narrated video of one of the authors (R.L.) performing the exercise, which consisted of creating an enterotomy in the bowel model using the da Vinci Xi robot (Intuitive Surgical Inc, Sunnyvale, CA) followed by an interrupted suture closure along marked, dotted lines.\nParticipant performance was recorded and scored in real time by one of the research staff using a standardized scoring rubric based on errors committed. The video recording was then reviewed by a separate researcher to ensure inter-rater reliability for the error calculations. Errors were de ned as the number of times the following occurred: instrument out of view of the camera, targets missed, torn suture, instrument collision and air knots tied. These errors were then tabulated together for a summative total error score. The amount of suture required to complete each exercise and time to completion \u2013 de ned as initiation of enterotomy to the cutting of the last stitch \u2013 were also annotated.\nSimulation recordings were then assessed using the Global Evaluative Assessment of Robotic Skills (GEARS) rubric, a standardized clinical assessment tool for robotic surgical skills assessment [21, 22]. GEARS assesses 6 separate domains: depth perception, bimanual dexterity, e ciency, autonomy, force sensitivity and robotic control. Each domain is scored using a 5-point Likert-like scale with speci c performance anchors at 1, 3 and 5. The GEARS score is the sum of each of these domains. In this analysis, autonomy was not assessed as participants performed the exercise by themselves in its entirety. Each video was evaluated by at least 30 reviewers using the Crowd-Sourced Assessment of Technical Skills (C-SATS\u2122, Seattle, WA) platform [23\u201326]. Lastly, the participants were asked to ll out a survey evaluating their self-rated robotic surgical skill and con dence before and after the exercise along with its overall educational bene t, realism, and potential for skill transfer (Table\u00a01). Controlling for the upfront investment of certain training materials, each exercise iteration cost ~$30, while each C-SATS evaluation cost ~$200 per video.\nPage 5/13\nTable 1 Post-exercise survey provided to all participants. Response options were based on a 1\u201310 Likert scale.\n\u00a0 Question Prompt:\n1 Before completing the exercise, how would you have rated your robotic surgical skill?\n2 Before completing the exercise, how con dent were you in performing robotic surgery\n3 Following the exercise, how would you rate your robotic surgical ability?\n4 Following the exercise, how con dent do you feel in your robotic surgical skill?\n5 Overall, how would you rate the educational bene t of the exercise?\n6 How effective do you think the inanimate training exercise was in training robotic skill?\n7 How realistic was training on the inanimate model (i.e., appearance and tissue characteristics) in comparison to the operating room?\n8 Training on the inanimate exercise taught useful skills that were transferable to the operating room\nMessick\u2019s validity framework was used to evaluate the model for content, response process, internal structure and construct validity [19, 27]. Content validity is de ned as the extent to which a measurement addresses all skills necessary for a particular domain of content [28]. Response process evidence refers to data integrity and how closely assessment scores re ect the observed performance of the trainee. Internal structure validity corresponds to the reliability and reproducibility of simulator scores between raters; this can be shown by establishing inter-rater reliability [29]. Finally, a simulation contains construct validity if it is able to differentiate between participants of different skill sets [30].\nDifferences between the outcomes amongst the two groups were identi ed two-tailed unpaired T-tests. Statistical analysis was performed using SPSS Statistical Software version 24 (IBM, Armonk, NY). Statistical signi cance was de ned at a p < 0.05.\nResults Thirty-one subjects were recruited to participate in the inanimate tissue model exercise. The subjects ranged from medical students to general surgery residents (PGY1-3) at two different institutions. Exposure to and experience with minimally invasive surgical platforms varied signi cantly between the two cohorts (Table\u00a02). We noted statistically signi cant differences between the two when comparing the hours spent on the da Vinci Skills Simulator (dVSS) trainer (p = 0.003), number of bedside assists performed (p < 0.001), number of laparoscopic cases performed as surgeon junior (p < 0.001) and number of robotic cases performed as surgeon junior (p < 0.001).\nPage 6/13\nPerformance metrics from each cohort were aggregated together and compared. The PGY2/3 group completed the exercise faster (14.4 vs 26.1 min, p < 0.001; Fig.\u00a01a) and committed fewer total errors (11.9 vs 21.5 errors, p = 0.018; Fig.\u00a01b). The types of errors committed by each group is shown in Table\u00a03. Interrater reliability of total error was established with Cronbach\u2019s alpha of 0.998.\nThe PGY2/3 group also received higher GEARS score (19.9 vs 18.5, p = 0.001; Fig.\u00a01c). Components of the GEARS scores are shown in Table\u00a04. Inter-rater reliability was established amongst the crowd-sourced assessors (~ 30\u201340 for each video) with Cronbach\u2019s alpha of 0.717. All participants were able to successfully create the enterotomy with electrocautery as described. The electrocautery had a melting effect on the LifeLike Biotissue double-layered hydrogel bowel model akin to using a monopolar energy\nPage 7/13\ndevice on the \u2018Cut\u2019 setting. The thermal spread was minimal and was limited to tissue contacted by the instrument directly.\nThe post-activity survey was completed by 23 of 31 participants. Based upon survey responses, 87.0% and 91.3% of participants reported improvement in robotic surgical ability and con dence, respectively. Overall, respondents rated the realism of the exercise 7.5/10, education bene ts as 9.1/10 and effectiveness in teaching basic robotic skills 8.7/10 (Fig.\u00a02). Furthermore, participants felt that the skills they learned on the inanimate model would transfer to the operating room.\nDiscussion This prospective, multi-institutional study established the content, response process, internal structure and construct validity of a novel inanimate tissue model that incorporates electrocautery using Messick\u2019s validity framework [19, 27]. The content validity was established through the post-exercise survey which demonstrated that participants found the model to contain a high degree of realism comparable to the operating room. Response process validity was achieved by using blinded raters to provide GEARs ratings for video performances. Internal structure validity was established by using GEARS ratings from crowd sourced assessors who have a published inter-rater reliability (IRR) [31]. Finally, construct validity was shown through the signi cant differences in objective metrics \u2013 GEARS scores, time to completion, and total errors committed \u2013 between the two cohorts of participants.\nMedical simulation enables procedural and psychomotor skill acquisition in a low-stakes environment. Certain simulation platforms, however, contain barriers and limitations of use. While virtual reality trainers have robust validation data supporting their use, costs can be prohibitive. For example, the dVSS system costs $90,00 in addition to the investment needed for the da Vinci console (~$500,000) for the trainer interface, while dV-Trainer costs range up to $158,000 [18]. Trainers like the dVSS system that also\nPage 8/13\nrequire concurrent console usage limiting training availability to time outside normal business hours, which can be problematic given residency work hour restrictions [32]. These systems are also known to poorly emulate electrocautery [17]. Similarly, box trainer exercises like the one developed and validated by the Fundamentals of Robotic Surgery Skills Curriculum group lack realism and tissue delity [14]. Other utilized forms of simulation training include live animal and cadaver laboratories, but concerns surrounding ethics, cost, and accessibility persist [33].\nInanimate tissue models serve as a cost-effective and more accessible means to provide task-speci c simulation training [34]. Tam et al argue that virtual reality trainers are best for gaining familiarity to the platform, while biotissue tissue exercises like the one presented teach critical skills such as tissue handling, suturing, camera control, and electrocautery [35]. They showed face and content validity for an inanimate tissue model using material from LifeLike Biotissue Inc. to train surgical oncology fellows for robotic pancreaticoduodenectomy.\nExamples of similar models in the literature are scarce due to the aforementioned barriers. Marecik et al published a similar robotic suturing exercise using porcine intestine, but the need to harvest and freeze the bowel tissue raises ethical and tissue integrity concerns [36]. Other inanimate robotic training exercises are described in the literature such as a vaginal cuff model constructed from \u201cbeer huggies\u201d and drills designed to replicate the Fundamentals of Laparoscopic Surgery curriculum [22, 37]. This double-layered bowel model provides a more cost-effective and accessible means to conferring similar surgical skills. Single iteration use, after initial investment for reusable training materials, costs as little as $30 [38].\nLimitations of this study include the small, yet signi cant, difference in GEARS scores amongst the two groups, the clinical signi cance of which remains to be seen. Work is ongoing to establish the construct validity of this scoring system in commonly performed robotic general surgery procedures, after which time we will be able to comment more de nitively on the matter.\nNext steps will involve incorporating this model and the assessment tools in a pro ciency-based curriculum and utilizing GEARS scores as a metric for junior resident robotic skill evaluation. A pro ciency-based curriculum utilizes expert derived performance goals as training endpoints [39]. These types of curricula would emphasize deliberate practice to a goal-directed learning experience rather than an arbitrary number of repetitions to ensure uniform skill development among trainees, which have been shown to more reliably confer higher levels of skill [40].\nConclusion Using Messick\u2019s validity framework, this study established the content, response process, internal structure and construct validity of a novel, high- delity and cost-effective inanimate tissue exercise which successfully incorporates electrocautery. This may also provide a means to determine trainee pro ciency through time and error-based as well as crowd-sourced analysis. Consideration should be given to its addition to robotic surgery training curricula.\nPage 9/13\nDeclarations Acknowledgements:\u00a0We would also like to thank the Ruth L Kirschstein NRSA Institutional Research Training Grant.\nStatements and Declarations:\u00a0None of the authors have nancial or other con icts of interest. The views expressed herein are those of the author(s) and do not re ect the o cial policy or position of Brooke Army Medical Center, the U.S. Army Medical Department, the U.S. Army O ce of the Surgeon General, the Department of the Army, the Department of the Air Force, or the Department of Defense, or the U.S. Government.\nReferences 1. Administration FaD. FDA Approves New Robotic Surgery Device. Science Daily2000.\n2. Intuitive Surgical I. Annual Report 2018. 2019.\n3. Intuitive Surgical I. Annual Report 2019. 2020.\n4. Perez RE, Schwaitzberg S. Robotic surgery: nding value in 2019 and beyond. Ann Laparosc Endosc Surg. 2019;4:51. doi: 10.21037/ales.2019.05.02.\n5. Pradarelli JC, Thornton JP, Dimick JB. Who Is Responsible for the Safe Introduction of New Surgical Technology?: An Important Legal Precedent From the da Vinci Surgical System Trials. JAMA Surg. 2017;152(8):717-8. doi: 10.1001/jamasurg.2017.0841.\n. Cooper MA, Ibrahim A, Lyu H, Makary MA. Underreporting of robotic surgery complications. J Healthc Qual. 2015;37(2):133-8. doi: 10.1111/jhq.12036.\n7. Foell K, Finelli A, Yasufuku K, Bernardini MQ, Waddell TK, Pace KT, et al. Robotic surgery basic skills training: Evaluation of a pilot multidisciplinary simulation-based curriculum. Can Urol Assoc J. 2013;7(11-12):430-4. doi: 10.5489/cuaj.222.\n. Connolly M, Seligman J, Kastenmeier A, Goldblatt M, Gould JC. Validation of a virtual reality-based robotic surgical skills curriculum. Surg Endosc. 2014;28(5):1691-4. doi: 10.1007/s00464-013-3373-x.\n9. Green CA, Chern H, O'Sullivan PS. Current robotic curricula for surgery residents: A need for additional cognitive and psychomotor focus. Am J Surg. 2018;215(2):277-81. doi: 10.1016/j.amjsurg.2017.09.040.\n10. Dulan G, Rege RV, Hogg DC, Gilberg-Fisher KM, Arain NA, Tesfay ST, et al. Developing a comprehensive, pro ciency-based training program for robotic surgery. Surgery. 2012;152(3):477-88. doi: 10.1016/j.surg.2012.07.028.\n11. Winder JS, Juza RM, Sasaki J, Rogers AM, Pauli EM, Haluck RS, et al. Implementing a robotics curriculum at an academic general surgery training program: our initial experience. J Robot Surg. 2016;10(3):209-13. doi: 10.1007/s11701-016-0569-9.\n12. Moit H, Dwyer A, De Sutter M, Heinzel S, Crawford D. A Standardized Robotic Training Curriculum in a General Surgery Program. JSLS. 2019;23(4). doi: 10.4293/JSLS.2019.00045.\nPage 10/13\n13. Chen R, Rodrigues Armijo P, Krause C, Siu KC, Oleynikov D, Force SRT. A comprehensive review of robotic surgery curriculum and training for residents, fellows, and postgraduate surgical education. Surg Endosc. 2020;34(1):361-7. doi: 10.1007/s00464-019-06775-1.\n14. Satava RM, Stefanidis D, Levy JS, Smith R, Martin JR, Monfared S, et al. Proving the Effectiveness of the Fundamentals of Robotic Surgery (FRS) Skills Curriculum: A Single-blinded, Multispecialty, Multiinstitutional Randomized Control Trial. Ann Surg. 2020;272(2):384-92. doi: 10.1097/SLA.0000000000003220.\n15. Stegemann AP, Ahmed K, Syed JR, Rehman S, Ghani K, Autorino R, et al. Fundamental skills of robotic surgery: a multi-institutional randomized controlled trial for validation of a simulation-based curriculum. Urology. 2013;81(4):767-74. doi: 10.1016/j.urology.2012.12.033.\n1 . Hung AJ, Zehnder P, Patil MB, Cai J, Ng CK, Aron M, et al. Face, content and construct validity of a novel robotic surgery simulator. J Urol. 2011;186(3):1019-24. doi: 10.1016/j.juro.2011.04.064.\n17. Kelly DC, Margules AC, Kundavaram CR, Narins H, Gomella LG, Trabulsi EJ, et al. Face, content, and construct validation of the da Vinci Skills Simulator. Urology. 2012;79(5):1068-72. doi: 10.1016/j.urology.2012.01.028.\n1 . Moglia A, Ferrari V, Morelli L, Ferrari M, Mosca F, Cuschieri A. A Systematic Review of Virtual Reality Simulators for Robot-assisted Surgery. Eur Urol. 2016;69(6):1065-80. doi: 10.1016/j.eururo.2015.09.021.\n19. Messick S. Test validity: A matter of consequence. Social Indicators Research. 1998;45(1):35-44. doi: 10.1023/A:1006964925094.\n20. Lee CS, Khan MT, Patnaik R, Stull MC, Krell RW, Laverty RB. Model Development of a Novel Robotic Surgery Training Exercise With Electrocautery. Cureus. 2022;14(4):e24531. doi: 10.7759/cureus.24531.\n21. Aghazadeh MA, Jayaratna IS, Hung AJ, Pan MM, Desai MM, Gill IS, et al. External validation of Global Evaluative Assessment of Robotic Skills (GEARS). Surg Endosc. 2015;29(11):3261-6. doi: 10.1007/s00464-015-4070-8.\n22. Kiely DJ, Gotlieb WH, Lau S, Zeng X, Samouelian V, Ramanakumar AV, et al. Virtual reality robotic surgery simulation curriculum to teach robotic suturing: a randomized controlled trial. J Robot Surg. 2015;9(3):179-86. doi: 10.1007/s11701-015-0513-4.\n23. Holst D, Kowalewski TM, White LW, Brand TC, Harper JD, Sorensen MD, et al. Crowd-Sourced Assessment of Technical Skills: Differentiating Animate Surgical Skill Through the Wisdom of Crowds. J Endourol. 2015;29(10):1183-8. doi: 10.1089/end.2015.0104.\n24. Chen C, White L, Kowalewski T, Aggarwal R, Lintott C, Comstock B, et al. Crowd-Sourced Assessment of Technical Skills: a novel method to evaluate surgical performance. J Surg Res. 2014;187(1):65-71. doi: 10.1016/j.jss.2013.09.024.\n25. Lendvay TS, White L, Kowalewski T. Crowdsourcing to Assess Surgical Skill. JAMA Surg. 2015;150(11):1086-7. doi: 10.1001/jamasurg.2015.2405.\nPage 11/13\n2 . Kowalewski TM, Comstock B, Sweet R, Schaffhausen C, Menhadji A, Averch T, et al. Crowd-Sourced Assessment of Technical Skills for Validation of Basic Laparoscopic Urologic Skills Tasks. J Urol. 2016;195(6):1859-65. doi: 10.1016/j.juro.2016.01.005.\n27. Goldenberg M, Lee JY. Surgical education, simulation, and simulators\u2014updating the concept of validity. Current Urology Reports. 2018;19(7):1-5. doi: 10.1007/s11934-018-0799-7.\n2 . Carmines EG, Zeller RA. Reliability and Validity Assessment. SAGE Publications; 1979.\n29. Cook DA, Beckman TJ. Current concepts in validity and reliability for psychometric instruments: theory and application. Am J Med. 2006;119(2):166.e7-16. doi: 10.1016/j.amjmed.2005.10.036.\n30. CRONBACH LJ, MEEHL PE. Construct validity in psychological tests. Psychol Bull. 1955;52(4):281- 302. doi: 10.1037/h0040957.\n31. White LW, Kowalewski TM, Dockter RL, Comstock B, Hannaford B, Lendvay TS. Crowd-Sourced Assessment of Technical Skill: A Valid Method for Discriminating Basic Robotic Surgery Skills. J Endourol. 2015;29(11):1295-301. doi: 10.1089/end.2015.0191.\n32. Awan M, Zagales I, McKenney M, Kinslow K, Elkbuli A. ACGME 2011 Duty Hours Restrictions and Their Effects on Surgical Residency Training and Patients Outcomes: A Systematic Review. J Surg Educ. 2021. doi: 10.1016/j.jsurg.2021.06.001.\n33. Schlottmann F, Herbella FAM, Patti MG. Simulation for Foregut and Bariatric Surgery: Current Status and Future Directions. J Laparoendosc Adv Surg Tech A. 2021;31(5):546-50. doi: 10.1089/lap.2021.0080.\n34. Patnaik R, Khan MT, Yamaguchi S, Fritze DM. Building a Low-Cost and Low-Fidelity Kidney Transplant Model: A Technical Report on the San Antonio Kidney Transplant Model. Cureus. 2022;14(4):e23883. doi: 10.7759/cureus.23883.\n35. Tam V, Zenati M, Novak S, Chen Y, Zureikat AH, Zeh HJ, et al. Robotic Pancreatoduodenectomy Biotissue Curriculum has Validity and Improves Technical Performance for Surgical Oncology Fellows. J Surg Educ. 2017;74(6):1057-65. doi: 10.1016/j.jsurg.2017.05.016.\n3 . Marecik SJ, Prasad LM, Park JJ, Jan A, Chaudhry V. Evaluation of midlevel and upper-level residents performing their rst robotic-sutured intestinal anastomosis. Am J Surg. 2008;195(3):333-7; discussion 7-8. doi: 10.1016/j.amjsurg.2007.12.013.\n37. Hung AJ, Jayaratna IS, Teruya K, Desai MM, Gill IS, Goh AC. Comparative assessment of three standardized robotic surgery training methods. BJU Int. 2013;112(6):864-71. doi: 10.1111/bju.12045.\n3 . Lee C, Khan M, Patnaik R, Krell R, Stull M, Laverty R. Model Development of a Novel Robotic Surgery Training Exercise With Electrocautery. April 27, 2022;14(4):e24531. doi: 10.7759/cureus.24531.\n39. Patnaik R, Stefanidis D. Outcome-Based Training and the Role of Simulation. Comprehensive Healthcare Simulation: Surgery and Surgical Subspecialties. Springer; 2019. p. 69-78.\n40. Willis RE, Richa J, Oppeltz R, Nguyen P, Wagner K, Van Sickle KR, et al. Comparing three pedagogical approaches to psychomotor skills acquisition. Am J Surg. 2012;203(1):8-13. doi: 10.1016/j.amjsurg.2011.07.002.\nPage 12/13\nFigures\nFigure 1\n(a)Average time to completion for each group during the exercise (minutes). Timer started at the initiation of the enterotomy and ended once the last suture was cut. P-value obtained using two-tailed unpaired Ttest. (b) Average total number of errors committed by each group during the exercise. P-value obtained using two-tailed unpaired T-test. (c) Average GEARS scores for each of the groups. P-value obtained using two-tailed unpaired T-test.\nPage 13/13\nResponse to post-exercise survey. All questions were answered according to a 1-10 Likert scale."
        }
    ],
    "title": "Intentional Enterotomies: Validation of a Novel Robotic Surgery Training Exercise",
    "year": 2023
}