{
    "abstractText": "Deep learning has shown impressive results in a variety of time series forecasting tasks, where modeling the conditional distribution of the future given the past is the essence. However, when this conditional distribution is non-stationary, it poses challenges for these models to learn consistently and to predict accurately. In this work, we propose a new method to model non-stationary conditional distributions over time by clearly decoupling stationary conditional distribution modeling from non-stationary dynamics modeling. Our method is based on a Bayesian dynamic model that can adapt to conditional distribution changes and a deep conditional distribution model that handles multivariate time series using a factorized output space. Our experimental results on synthetic and real-world datasets show that our model can adapt to non-stationary time series better than state-of-the-art deep learning solutions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Siqi Liu"
        },
        {
            "affiliations": [],
            "name": "Andreas Lehrmann"
        }
    ],
    "id": "SP:b2ea02b0dadb9d8b6b5eb0d1f29ae17290a2f986",
    "references": [
        {
            "authors": [
                "Alexander Alexandrov",
                "Konstantinos Benidis",
                "Michael Bohlke-Schneider",
                "Valentin Flunkert",
                "Jan Gasthaus",
                "Tim Januschowski",
                "Danielle C. Maddix",
                "Syama Rangapuram",
                "David Salinas",
                "Jasper Schulz",
                "Lorenzo Stella",
                "Ali Caner T\u00fcrkmen",
                "Yuyang Wang"
            ],
            "title": "GluonTS: Probabilistic and Neural Time Series Modeling in Python",
            "venue": "Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Abdul Fatir Ansari",
                "Konstantinos Benidis",
                "Richard Kurle",
                "Ali Caner Turkmen",
                "Harold Soh",
                "Alexander J. Smola",
                "Bernie Wang",
                "Tim Januschowski"
            ],
            "title": "Deep explicit duration switching models for time series",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Shaojie Bai",
                "J. Zico Kolter",
                "Vladlen Koltun"
            ],
            "title": "An empirical evaluation of generic convolutional and recurrent networks for sequence modeling",
            "venue": "arXiv preprint arXiv:1803.01271,",
            "year": 2018
        },
        {
            "authors": [
                "Kasun Bandara",
                "Christoph Bergmeir",
                "Slawek Smyl"
            ],
            "title": "Forecasting across time series databases using recurrent neural networks on groups of similar series: A clustering approach",
            "venue": "Expert Systems with Applications,",
            "year": 2020
        },
        {
            "authors": [
                "Tim Bollerslev"
            ],
            "title": "Generalized autoregressive conditional heteroskedasticity",
            "venue": "Journal of Econometrics,",
            "year": 1986
        },
        {
            "authors": [
                "George EP Box",
                "Gwilym M. Jenkins",
                "Gregory C. Reinsel",
                "Greta M. Ljung"
            ],
            "title": "Time Series Analysis: Forecasting and Control",
            "year": 2015
        },
        {
            "authors": [
                "Robert B. Cleveland",
                "William S. Cleveland",
                "Jean E. McRae",
                "Irma Terpenning"
            ],
            "title": "STL: A seasonal-trend decomposition procedure based on loess",
            "venue": "Journal of Official Statistics,",
            "year": 1990
        },
        {
            "authors": [
                "Giorgio Corani",
                "Alessio Benavoli",
                "Marco Zaffalon"
            ],
            "title": "Time series forecasting with Gaussian Processes needs priors",
            "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,",
            "year": 2021
        },
        {
            "authors": [
                "Emmanuel de B\u00e9zenac",
                "Syama Sundar Rangapuram",
                "Konstantinos Benidis",
                "Michael Bohlke-Schneider",
                "Richard Kurle",
                "Lorenzo Stella",
                "Hilaf Hasson",
                "Patrick Gallinari",
                "Tim Januschowski"
            ],
            "title": "Normalizing Kalman filters for multivariate time series analysis",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Matthias De Lange",
                "Rahaf Aljundi",
                "Marc Masana",
                "Sarah Parisot",
                "Xu Jia",
                "Ales Leonardis",
                "Gregory Slabaugh",
                "Tinne Tuytelaars"
            ],
            "title": "A continual learning survey: Defying forgetting in classification tasks",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "David A. Dickey",
                "Wayne A. Fuller"
            ],
            "title": "Distribution of the estimators for autoregressive time series with a unit root",
            "venue": "Journal of the American Statistical Association,",
            "year": 1979
        },
        {
            "authors": [
                "Arnaud Doucet",
                "Nando de Freitas",
                "Kevin Murphy",
                "Stuart Russell"
            ],
            "title": "Rao-Blackwellised particle filtering for dynamic Bayesian networks",
            "venue": "In Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence,",
            "year": 2000
        },
        {
            "authors": [
                "Robert F. Engle"
            ],
            "title": "Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation",
            "venue": "Econometrica: Journal of the Econometric Society,",
            "year": 1982
        },
        {
            "authors": [
                "Marco Fraccaro",
                "Simon Kamronn",
                "Ulrich Paquet",
                "Ole Winther"
            ],
            "title": "A disentangled recognition and nonlinear dynamics model for unsupervised learning",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Marta Garnelo",
                "Dan Rosenbaum",
                "Christopher Maddison",
                "Tiago Ramalho",
                "David Saxton",
                "Murray Shanahan",
                "Yee Whye Teh",
                "Danilo Rezende",
                "S.M. Ali Eslami"
            ],
            "title": "Conditional neural processes",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Vibhor Gupta",
                "Jyoti Narwariya",
                "Pankaj Malhotra",
                "Lovekesh Vig",
                "Gautam Shroff"
            ],
            "title": "Continual learning for multivariate time series tasks with variable input dimensions",
            "venue": "[cs],",
            "year": 2022
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural Computation,",
            "year": 1997
        },
        {
            "authors": [
                "Charles C. Holt"
            ],
            "title": "Forecasting seasonals and trends by exponentially weighted moving averages",
            "venue": "International Journal of Forecasting,",
            "year": 2004
        },
        {
            "authors": [
                "Re E Kalman"
            ],
            "title": "A new approach to linear filtering and prediction problems",
            "venue": "Transactions of the ASME-Journal of Basic Engineering,",
            "year": 1960
        },
        {
            "authors": [
                "Taesung Kim",
                "Jinhee Kim",
                "Yunwon Tae",
                "Cheonbok Park",
                "Jang-Ho Choi",
                "Jaegul Choo"
            ],
            "title": "Reversible instance normalization for accurate time-series forecasting against distribution shift",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980,",
            "year": 2014
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Max Welling"
            ],
            "title": "Auto-encoding variational bayes",
            "venue": "arXiv preprint arXiv:1312.6114,",
            "year": 2013
        },
        {
            "authors": [
                "James Kirkpatrick",
                "Razvan Pascanu",
                "Neil Rabinowitz",
                "Joel Veness",
                "Guillaume Desjardins",
                "Andrei A. Rusu",
                "Kieran Milan",
                "John Quan",
                "Tiago Ramalho",
                "Agnieszka Grabska-Barwinska",
                "Demis Hassabis",
                "Claudia Clopath",
                "Dharshan Kumaran",
                "Raia Hadsell"
            ],
            "title": "Overcoming catastrophic forgetting in neural networks",
            "venue": "[cs, stat],",
            "year": 2017
        },
        {
            "authors": [
                "Alexej Klushyn",
                "Richard Kurle",
                "Maximilian Soelch",
                "Botond Cseke",
                "Patrick van der Smagt"
            ],
            "title": "Latent matters: Learning deep state-space models",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Richard Kurle",
                "Botond Cseke",
                "Alexej Klushyn",
                "Patrick van der Smagt",
                "Stephan G\u00fcnnemann"
            ],
            "title": "Continual learning with bayesian neural networks for non-stationary data",
            "venue": "In International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "Richard Kurle",
                "Syama Sundar Rangapuram",
                "Emmanuel de B\u00e9zenac",
                "Stephan G\u00fcnnemann",
                "Jan Gasthaus"
            ],
            "title": "Deep Rao-Blackwellised particle filters for time series forecasting",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Denis Kwiatkowski",
                "Peter CB Phillips",
                "Peter Schmidt",
                "Yongcheol Shin"
            ],
            "title": "Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root",
            "venue": "Journal of Econometrics,",
            "year": 1992
        },
        {
            "authors": [
                "Guokun Lai",
                "Wei-Cheng Chang",
                "Yiming Yang",
                "Hanxiao Liu"
            ],
            "title": "Modeling long-and short-term temporal patterns with deep neural networks",
            "venue": "In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval,",
            "year": 2018
        },
        {
            "authors": [
                "Vincent Le Guen",
                "Nicolas Thome"
            ],
            "title": "Probabilistic time series forecasting with shape and temporal diversity",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Bryan Lim",
                "Stefan Zohren"
            ],
            "title": "Time series forecasting with deep learning: A survey",
            "year": 2020
        },
        {
            "authors": [
                "James E. Matheson",
                "Robert L. Winkler"
            ],
            "title": "Scoring rules for continuous probability distributions",
            "venue": "Management Science,",
            "year": 1976
        },
        {
            "authors": [
                "Cuong V. Nguyen",
                "Yingzhen Li",
                "Thang D. Bui",
                "Richard E. Turner"
            ],
            "title": "Variational continual learning",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Nam Nguyen",
                "Brian Quanz"
            ],
            "title": "Temporal latent auto-encoder: A method for probabilistic multivariate time series forecasting",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Boris N. Oreshkin",
                "Dmitri Carpov",
                "Nicolas Chapados",
                "Yoshua Bengio"
            ],
            "title": "N-BEATS: Neural basis expansion analysis for interpretable time series forecasting",
            "year": 2020
        },
        {
            "authors": [
                "German I. Parisi",
                "Ronald Kemker",
                "Jose L. Part",
                "Christopher Kanan",
                "Stefan Wermter"
            ],
            "title": "Continual lifelong learning with neural networks: A review",
            "venue": "Neural Networks,",
            "year": 2019
        },
        {
            "authors": [
                "Syama Sundar Rangapuram",
                "Matthias W. Seeger",
                "Jan Gasthaus",
                "Lorenzo Stella",
                "Yuyang Wang",
                "Tim Januschowski"
            ],
            "title": "Deep state space models for time series forecasting",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2018
        },
        {
            "authors": [
                "Kashif Rasul",
                "Calvin Seward",
                "Ingmar Schuster",
                "Roland Vollgraf"
            ],
            "title": "Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting",
            "venue": "In Proceedings of the 38th International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Kashif Rasul",
                "Abdul-Saboor Sheikh",
                "Ingmar Schuster",
                "Urs M. Bergmann",
                "Roland Vollgraf"
            ],
            "title": "Multivariate probabilistic time series forecasting via conditioned normalizing flows",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "David Salinas",
                "Michael Bohlke-Schneider",
                "Laurent Callot",
                "Roberto Medico",
                "Jan Gasthaus"
            ],
            "title": "Highdimensional multivariate forecasting with low-rank Gaussian Copula Processes",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "David Salinas",
                "Valentin Flunkert",
                "Jan Gasthaus",
                "Tim Januschowski"
            ],
            "title": "DeepAR: Probabilistic forecasting with autoregressive recurrent networks",
            "venue": "International Journal of Forecasting,",
            "year": 2020
        },
        {
            "authors": [
                "Slawek Smyl"
            ],
            "title": "A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting",
            "venue": "International Journal of Forecasting,",
            "year": 2020
        },
        {
            "authors": [
                "Binh Tang",
                "David S Matteson"
            ],
            "title": "Probabilistic transformer for time series analysis",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Gerald Woo",
                "Chenghao Liu",
                "Doyen Sahoo",
                "Akshat Kumar",
                "Steven Hoi"
            ],
            "title": "ETSformer: Exponential Smoothing Transformers for Time-series Forecasting",
            "venue": "arXiv preprint arXiv:2202.01381,",
            "year": 2022
        },
        {
            "authors": [
                "Haixu Wu",
                "Jiehui Xu",
                "Jianmin Wang",
                "Mingsheng Long"
            ],
            "title": "Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Zhongjie Yu",
                "Fabrizio G. Ventola",
                "Kristian Kersting"
            ],
            "title": "Whittle networks: A deep likelihood model for time series",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Deep learning has shown impressive results in a variety of time series forecasting tasks, where modeling the conditional distribution of the future given the past is the essence. However, when this conditional distribution is non-stationary, it poses challenges for these models to learn consistently and to predict accurately. In this work, we propose a new method to model non-stationary conditional distributions over time by clearly decoupling stationary conditional distribution modeling from non-stationary dynamics modeling. Our method is based on a Bayesian dynamic model that can adapt to conditional distribution changes and a deep conditional distribution model that handles multivariate time series using a factorized output space. Our experimental results on synthetic and real-world datasets show that our model can adapt to non-stationary time series better than state-of-the-art deep learning solutions."
        },
        {
            "heading": "1 Introduction",
            "text": "Time series forecasting is a cornerstone of modern machine learning and has applications in a broad range of domains, such as operational processes (Salinas et al., 2020), energy (Lai et al., 2018), and transportation (Salinas et al., 2019). In recent years, models based on deep neural networks have shown particularly impressive results (Rangapuram et al., 2018; Salinas et al., 2019; 2020; Rasul et al., 2021b) and demonstrated the effectiveness of deep feature and latent state representations.\nDespite this exciting progress, current time series forecasting methods often make the implicit assumption that the distribution of the observed time series conditioned on the input and past is time-invariant. In real-world applications this assumption is often violated, which results in non-stationarity and poses serious practical challenges to a model\u2019s robustness and predictive power. The statistics literature describes several related concepts of (non-)stationarity for time series, with weak and strong stationarity being the most widely used ones (Hamilton, 1994; Brockwell & Davis, 2009). Common to these variants of (non-)stationarity is that they are defined in terms of a stochastic process\u2019 joint or marginal distribution. For example, given a univariate time series {yt \u2208 R}t\u2208Z and any subset of time points {t1, t2, . . . , tk}, the time series is strongly stationary if \u2200\u03c4 \u2208 Z : p(yt1 , yt2 , . . . , ytk ) = p(yt1+\u03c4 , yt2+\u03c4 , . . . , ytk+\u03c4 ).\nWhile non-stationarity in a stochastic process\u2019 joint or marginal distribution is important and has been widely studied (Dickey & Fuller, 1979; Kwiatkowski et al., 1992; Hamilton, 1994; Kim et al., 2022), we argue that temporal forecasting relies more heavily on the properties of a time-series\u2019 conditional distribution p(yt|yt\u2212B:t\u22121,xt\u2212B:t), where yt\u2212B:t\u22121 = (yt\u2212B ,yt\u2212B+1, . . . ,yt\u22121), yt is a real vector of the target variable, B \u2208 Z>0 is the lookback window size and can be arbitrarily large, and xt is a real vector containing auxiliary information. Most forecasting methods, from traditional approaches (e.g., Autoregressive Integrated Moving Average (ARIMA; (Box et al., 2015)), Generalized Autoregressive Conditional Heteroskedasticity (GARCH; (Engle, 1982; Bollerslev, 1986)), state-space models (SSMs; (Kalman, 1960))) to more recent models (e.g., recurrent neural networks (RNNs; (Hochreiter & Schmidhuber, 1997; Salinas et al., 2020)), temporal\nar X\niv :2\n20 9.\n08 41\n1v 2\n[ cs\n.L G\n] 1\n3 N\nov 2\n02 3\nconvolutional networks (TCNs; (Bai et al., 2018)), Transformers (Vaswani et al., 2017; Rasul et al., 2021b), Neural Processes (NPs; (Garnelo et al., 2018a;b))), rely on this conditional distribution for predictions, but many of them implicitly assume its stationarity by using time-invariant model parameters. While a model with stationary conditional distribution can still handle non-stationarity in the joint or marginal distribution, such as seasonality and trend, by conditioning on extra features in xt, such as day of the week, the conditional distribution itself may also change due to (1) unobserved causes and/or (2) new causes. For example, the daily number of posts from each user on a social media platform is unlikely to be robustly predictable from historical data, even with input features like day of the week, because (1) user activity is often affected by events that are not reflected in the observable data (e.g., illness); and (2) events that have not been seen before may occur (e.g., a new functionality being added to the platform) and change the functional pattern of the input-output relation between the conditioning and target variables in an unpredictable way. How to deal with these changes in the model\u2019s conditional distribution is the main focus of this work.\nAutoregressive (AR) models, TCNs, and Transformers model p(yt|yt\u2212B:t\u22121,xt\u2212B:t) with time-invariant parameters (e.g., the weights and biases in the neural network) and therefore assume stationarity in p(yt|yt\u2212B:t\u22121,xt\u2212B:t). In contrast, SSMs, RNNs, and NPs model p(yt|y1:t\u22121,x1:t) with time-invariant parameters as well, but they have a growing number of conditioning variables (note the time range 1 : t) and therefore can potentially model different conditional distributions p(yt|yt\u2212B:t\u22121,xt\u2212B:t) at different time points t. However, these models need to achieve two goals using the same time-invariant structure: (1) modeling p(yt|yt\u2212B:t\u22121,xt\u2212B:t); and (2) modeling its changes over time. Because they do not incorporate explicit inductive biases for changes in p(yt|yt\u2212B:t\u22121,xt\u2212B:t), they either cannot learn different (seemingly inconsistent) relations between the conditioning and target variables (if the model capacity is limited) or tend to memorize the training data and are not able to generalize to new changes at test time.\nIn this work, we take a different approach to dealing with non-stationary conditional distributions in time series. The core of our model, called DynaConF, is a clean decoupling of the time-variant (non-stationary) and the time-invariant (stationary) part of the distribution. The time-invariant part models a stationary conditional distribution, given a control variable, while the time-variant part focuses on modeling the changes in this conditional distribution over time through the control variable (Figure 1). Using this separation, we build a flexible model for the conditional distribution of the time series and make efficient inferences about its changes over time. At test time, our model takes both the uncertainty from the conditional distribution itself and non-stationary effects into account when making predictions and can adapt to unseen changes in the conditional distribution over time in an online manner."
        },
        {
            "heading": "2 Related Work",
            "text": "Time series forecasting has a rich history (Hamilton, 1994; Box et al., 2015), with many recent advances due to deep neural networks (Lim & Zohren, 2020). The following paragraphs discuss different approaches to non-stationary time series modeling and their relation to our work.\nNon-Stationary Marginal Distribution. There are three common ways of dealing with non-stationarity in the marginal distribution: (1) Data transformation. In ARIMA models, taking the difference of the time series over time can remove trend and seasonality. More advanced approaches based on exponential smoothing (Holt, 2004) or seasonal-trend decomposition (Cleveland et al., 1990) have also been combined with deep neural networks and achieve promising performance (Smyl, 2020; Bandara et al., 2020). More recently, Kim et al. (2022) propose to use reversible normalization/denormalization on the input/output of the time series model to account for (marginal) distribution shifts over time. (2) Inductive bias. As an alternative to data transformations, the underlying ideas of exponential smoothing and decomposition can also be incorporated into deep learning models as inductive biases, which enables end-to-end handling of seasonality/trend (Lai et al., 2018; Oreshkin et al., 2020; Wu et al., 2021; Woo et al., 2022). Similarly, in models based on Gaussian processes, the inductive biases can be added as specific (e.g., periodic or linear) kernel choices (Corani et al., 2021). (3) Conditioning information. Adding features such as relative time (e.g., day of the week) and absolute time to the model input as conditioning information is commonly used in deep probabilistic forecasting models (Rangapuram et al., 2018; Salinas et al., 2019; 2020; Rasul et al., 2021b;a). In our work, we focus on proper handling of changes in the conditional distribution. To deal with marginal distribution shifts, we simply add conditioning information as in approach (3), although we could potentially utilize approach (1) and (2) as well.\nNon-Stationary Conditional Distribution. State-space models (Fraccaro et al., 2017; Rangapuram et al., 2018; de B\u00e9zenac et al., 2020; Tang & Matteson, 2021; Klushyn et al., 2021) and recurrent neural networks (Salinas et al., 2019; 2020; Rasul et al., 2021b;a) are among the most popular choices to model temporal dependencies in time series. When these models are applied to, and therefore conditioned on, the entire history of the time series, they can theoretically \u201cmemorize\u201d different conditional distributions at different points in time. However, for these models to generalize and adapt to new changes in the future, it is critical to have appropriate inductive biases built into the model. A common approach is to allow state-space models to switch between a discrete set of dynamics, which can be learned from training data (Kurle et al., 2020; Ansari et al., 2021). However, the model cannot adapt to continuous changes or generalize to new changes that have not been observed in the training data. In contrast, our model has explicit inductive biases to account for both continuous and discontinuous changes, and to adapt to new changes.\nObservation Model. The expressivity and flexibility of the observation model is a topic that is especially relevant in case of multivariate time series. Different observation models have been employed in time series models, including low-rank covariance structures (Salinas et al., 2019), auto-encoders (Fraccaro et al., 2017; Nguyen & Quanz, 2021), normalizing flows (de B\u00e9zenac et al., 2020; Rasul et al., 2021b), determinantal point processes (Le Guen & Thome, 2020), denoising diffusion models (Rasul et al., 2021a), and probabilistic circuits (Yu et al., 2021). In this work, we prioritize scalability by assuming a simple conditional independence structure in the output space and consider more expressive observation models as orthogonal to our work.\nOnline Approaches. Continual learning (Kirkpatrick et al., 2017; Nguyen et al., 2018; Kurle et al., 2019; Parisi et al., 2019; De Lange et al., 2021; Gupta et al., 2022) also addresses (conditional) distribution changes in an online manner, but usually in a multi-task supervised learning setting and not in time series. In this work, our focus is on conditional distribution changes in time series, and the conditional distribution can change either continuously or discontinuously in time."
        },
        {
            "heading": "3 Method",
            "text": "We study the problem of modeling and forecasting time series with changes in the conditional distribution p(yt|yt\u2212B:t\u22121,xt\u2212B:t) over time t, where yt \u2208 RDy is a target time series, and xt \u2208 RDx is an input containing contextual information. We make the following assumption:\nAssumption 1 yt only depends on a bounded history of y and x for all t. That is, there exists B \u2208 Z>0 such that for all t, p(yt|y<t,x\u2264t) = p(yt|yt\u2212B:t\u22121,xt\u2212B:t).\nAlthough we assume that yt only depends on the history up to B time steps, its conditional distribution can change over time based on information beyond B steps. Assumption 1 is not particularly restrictive in practice, since we usually have a finite amount of training data while B can be arbitrarily large (although usually not needed). Given historical data {(xt,yt)}Tt=1, our task is to fit a model to the data and use it to forecast {yt}T +Ht=T +1, {yt} T +H+H t=T +H+1, . . ., continually with a horizon and step size H, given {xt} T +H t=T +1, {xt} T +H+H t=T +H+1, . . .. At time T , xt, t \u2264 T , may contain any information known at time t, while xt, t > T , can only contain information known in advance, such as day of the week. We do not distinguish between these two cases in notation for simplicity."
        },
        {
            "heading": "3.1 Decoupled Model",
            "text": "We assume that the distribution p(yt|yt\u2212B:t\u22121,xt\u2212B:t) is from a distribution family parametrizable by \u03b8t \u2208 RD\u03b8 . Concretely, we assume a normal distribution N (\u00b5t, \u03a3t), so \u03b8t := (\u00b5t, \u03a3t). Our decoupled model is not restricted to this assumption, but as we will see in Section 3.5 it allows for more efficient inference. Furthermore, we assume\n\u03b8t = f\u03c8,\u03d5t(yt\u2212B:t\u22121,xt\u2212B:t), (1)\nso f : RB\u00d7Dy \u00d7 R(B+1)\u00d7Dx \u2192 RD\u03b8 models the conditional distribution, with its own static parameters denoted collectively as \u03c8, and is modulated by a dynamic control variable \u03d5t \u2208 RD\u03d5 , which can change over time according to a dynamic process defined in Section 3.3. A property guaranteed in our model is that if \u03d5t stays the same across time, then the conditional distribution p(yt|yt\u2212B:t\u22121,xt\u2212B:t) stays the same as well.\nOur key idea is to separate the time-variant part of the model from the time-invariant part, instead of allowing all components to vary across time. This simplifies probabilistic inference and improves the generalization capabilities of the learned model by allowing the time-invariant part to learn from time-invariant input-output relations with time-variant modulations."
        },
        {
            "heading": "3.2 Conditional Distribution at One Time Point",
            "text": "First we describe how we model the conditional distribution p(yt|yt\u2212B:t\u22121,xt\u2212B:t) at each time point t without accounting for non-stationary effects (Figure 1, left). We use a neural network g to encode the historical and contextual information into a vector ht \u2208 RDh as ht = g(yt\u2212B:t\u22121,xt\u2212B:t). For example, g could be a multi-layer perceptron (MLP) or a recurrent neural network (RNN). The parameters of g are time-invariant and included in \u03c8 (Eq. 1).\nWe note that a key distinction between our model\u2019s use of an RNN and a typical deep time series model using an RNN is that the latter keeps unrolling the RNN over time to model the dynamics of the time series. In contrast, we unroll the RNN for B + 1 steps to summarize (yt\u2212B:t\u22121,xt\u2212B:t) in the exact same way at each time point t, i.e., we apply it in a time-invariant manner.\nWe construct the distribution of yt such that each dimension i of yt, denoted as yt,i, is conditionally independent of the others given ht; this helps the learning and inference algorithms to scale better with the dimensionality of yt. First we transform ht into Dy vectors zt,i \u2208 RE as\nzt,i = tanh(Wz,iht + bz,i), \u2200i = 1, . . . , Dy (2)\nwhere Wz,i \u2208 RE\u00d7Dh and bz,i \u2208 RE , so zt,i corresponds to yt,i. Then, from zt,i, we obtain the distribution parameters \u03b8t,i of yt,i. Specifically, we assume a normal distribution with a diagonal covariance for yt, so yt,i \u223c N (\u00b5t,i, \u03c32t,i) and \u03b8t,i := (\u00b5t,i, \u03c32t,i), with\n\u00b5t,i = wT\u00b5,izt,i + b\u00b5,i, \u03c3t,i = exp(wT\u03c3,izt,i + b\u03c3,i), (3)\nwhere w\u00b5,i \u2208 RE and w\u03c3,i \u2208 RE . We use w\u00b5 \u2208 RE\u00b7Dy and b\u00b5 \u2208 RDy to denote the concatenation of wT\u00b5,i and b\u00b5,i along i, and similarly w\u03c3, b\u03c3, zt, \u00b5t, \u03c3t."
        },
        {
            "heading": "3.3 Conditional Distributions Across Time Points",
            "text": "We have explained how we model the conditional distribution p(yt|yt\u2212B:t\u22121,xt\u2212B:t) at each time point t. To model changes in the conditional distribution over time, we first specify which parameters to include in the control variable \u03d5t \u2208 RD\u03d5 , which changes over time and modulates the conditional distribution (Figure 1, right).\nWe choose \u03d5t := w\u00b5. Recall that w\u00b5 transforms zt into the mean \u00b5t of yt, where zt is a summary of the information in the conditioning variables (yt\u2212B:t\u22121,xt\u2212B:t). By allowing w\u00b5 to be different at each time point t, the conditional mean of yt, E[yt|yt\u2212B:t\u22121,xt\u2212B:t], can change as well. We could allow w\u03c3 to change over time as well, effectively modeling a time-variant conditional variance, but focusing on w\u00b5 reduces the dimensionality of \u03d5t and enables more efficient inference utilizing Rao-Blackwellization (Section 3.5).\nWe propose to decompose \u03d5t into a dynamic stochastic process \u03c7t \u2208 RD\u03d5 and a static vector b\u03d5 \u2208 RD\u03d5 :\n\u03d5t = \u03c7t + b\u03d5. (4)\nThe intuition is that b\u03d5 captures the global information of \u03d5t and acts as a baseline, while \u03c7t captures the time-variant changes of \u03d5t relative to b\u03d5.\nWe assume that \u03c7t follows the generative process\n\u03c0t \u223c B(\u03bb); \u03c7t \u223c N (0, \u03a3\u03c7), if \u03c0t = 0; \u03f5t \u223c N (0, \u03a3\u03f5); \u03c7t = \u03c7t\u22121 + \u03f5t, if \u03c0t = 1.\n(5)\nB and N denote the Bernoulli and normal distributions, respectively. \u03c0t \u2208 {0, 1} is a binary random variable that either generates the current \u03c7t as a new sample drawn from a global distribution N (0, \u03a3\u03c7), or as a continuation from the previous \u03c7t\u22121 following a simple stochastic process in the form of a random walk. The intention is to allow \u03c7t to change both continuously (when \u03c0t = 1) through the random walk and discontinuously (when \u03c0t = 0) through the global distribution, which captures the variety of possible changes of \u03c7t in its parameter \u03a3\u03c7.\nWe assume \u03c7t to start at t = B, since it controls the conditional distribution, whose first observation occurs at t = B + 1. For the initial \u03c7B, we assume generation from N (0, \u03a3\u03c7) as well. Our intention is that N (0, \u03a3\u03c7) should be the distribution to generate new \u03c7t whenever there is a drastic change in the conditional distribution of yt, so at t = B it is natural to use that distribution.\nRecall that \u03c7t \u2208 RD\u03d5 , with D\u03d5 = E \u00b7 Dy. We propose to separate \u03c7t along the dimensions of yt into Dy groups. For each i = 1, . . . , Dy, we define \u03c7t,i \u2208 RE as in Eq. 5. The final \u03c7t is the concatenation of \u03c7t,i for all i. The intuition is to allow the group of components of \u03c7t modulating each dimension of yt to change independently of the others, corresponding to the conditional independence assumption we made in Section 3.2. We can thus sample a subset of dimensions of yt in each iteration during training to scale to high-dimensional time series. Our full model is shown in Figure 2."
        },
        {
            "heading": "3.4 Learning",
            "text": "All parameters of the conditional distribution model and the prior, i.e., {\u03c8, b\u03d5, \u03bb, \u03a3\u03c7, \u03a3\u03f5}, are learned by fitting the model to the historical training data {(yt,xt)}Tt=1. We train our model by maximizing the marginal log-likelihood, where the latent variables \u03c7t are marginalized out. Given a trajectory of \u03c7B:T , the conditional log-likelihood is\nlog p(yB+1:T |y1:B ,x1:T ,\u03c7B:T ) = T\u2211\nt=B+1 log p(yt|yt\u2212B:t\u22121,xt\u2212B:t,\u03c7t). (6)\nMarginalizing out \u03c7t gives the log-likelihood objective log p(yB+1:T |y1:B ,x1:T ) = log \u222b p(yB+1:T |y1:B ,x1:T ,\u03c7B:T )p(\u03c7B:T )d\u03c7B:T . (7)\nSince the integral is intractable, we instead introduce a variational distribution q(\u03c7B:T ) and maximize the following variational lower-bound L of the log-likelihood in Eq. 7:\nL := Eq[log p(yB+1:T |y1:B ,x1:T ,\u03c7B:T )] + Eq [ log p(\u03c7B:T )q(\u03c7B:T ) ] \u2264 log p(yB+1:T |y1:B ,x1:T ). (8)\nBased on the conditional independence structure of the prior process, we construct the variational distribution q(\u03c7B:T ) similar to an autoregressive process, however, we assume a simple normal distribution at each time step for efficient sampling and back-propagation. First, we define q(\u03c7B) as a normal distribution. Then, conditioning on the previous \u03c7t\u22121, we recursively define\nq(\u03c7t|\u03c7t\u22121) = N (at \u2299 \u03c7t\u22121 + (1 \u2212 at) \u2299mt, diag(s2t )), \u2200t = B + 1, . . . , T, (9)\nwhere at, mt, st \u2208 RF are variational parameters. Intuitively, at is a gate that chooses between continuing from the previous \u03c7t\u22121, with noise N (0, diag(s2t )), and using a new distribution N (mt, diag(s2t )).\nWe note that both terms in Eq. 8 factorize over time t = B + 1, . . . , T ,\nL = Eq(\u03c7B:T )\n[ T\u2211\nt=B+1 log p(yt|yt\u2212B:t\u22121,xt\u2212B:t,\u03c7t)\n] + Eq(\u03c7B:T ) [ T\u2211\nt=B log p(\u03c7t|\u03c7t\u22121)q(\u03c7t|\u03c7t\u22121)\n]\n= T\u2211\nt=B+1 Eq(\u03c7t) [log p(yt|yt\u2212B:t\u22121,xt\u2212B:t,\u03c7t)] + T\u2211 t=B Eq(\u03c7t\u22121:t) [ log p(\u03c7t|\u03c7t\u22121)q(\u03c7t|\u03c7t\u22121) ] ,\n(10)\nwhere, to simplify notation, we define p(\u03c7t|\u03c7t\u22121) at t = B to be p(\u03c7B), and similarly for q. The expectations in this equation can be evaluated by Monte-Carlo sampling from q(\u03c7) with the reparameterization trick (Kingma & Welling, 2013) for back-propagation.\nIn practice, sequential sampling in the autoregressive posterior could be inefficient because the sampling cannot be parallelized. We further develop a generalized posterior by replacing the autoregressive chain with multiple moving-average blocks combined with autoregressive dependencies between consecutive blocks, where\nsampling within each block can be carried out in parallel. Specifically, for the i-th time block, t \u2208 (bi, bi+1], where b1 = B, bK+1 = T, bi < bi+1, out of K blocks, we sample\n\u03b4t \u223c N ((1 \u2212 at) \u2299mt, diag(s2t )) (11)\nin parallel across t and compute\n\u03c7t =  \u220f v\u2208(bi,t] av  \u2299 \u03c7bi + \u2211 u\u2208(bi,t]  \u220f v\u2208(u,t] av  \u2299 \u03b4u. (12) This generalizes the autoregressive posterior and is the form used in our experiments.\nUtilizing our modeling assumptions from Section 3.2 and Section 3.3, we develop an SGD-based optimization protocol suitable for large datasets. Specifically, we alternate between optimizing the conditional distribution model and the prior and posterior of the dynamic model with different sampling strategies to accommodate high dimensionality and long time spans. See Appendix A for more details about our optimization process."
        },
        {
            "heading": "3.5 Forecasting",
            "text": "At test time, we are given past observations y1:T as well as input features x1:T +H , including H future steps, to infer the conditional distribution p(yT +1:T +H |y1:T ,x1:T +H). We note again that xT +1:T +H only contains information known ahead, such as day of the week. Based on our modeling assumptions, the conditional distribution can be computed as\np(yT +1:T +H |y1:T ,x1:T +H) = \u222b p(yT +1:T +H |yT +1\u2212B:T ,xT +1\u2212B:T +H ,\u03c7T +1:T +H)p(\u03c7T +1:T +H |y1:T ,x1:T )d\u03c7T +1:T +H . (13)\nThe first factor in the integrand can be computed recursively via step-by-step predictions based on our conditional distribution model given \u03c7T +1:T +H ,\np(yT +1:T +H |yT +1\u2212B:T ,xT +1\u2212B:T +H ,\u03c7T +1:T +H) = T +H\u220f\nt=T +1 p(yt|yt\u2212B:t\u22121,xt\u2212B:t,\u03c7t). (14)\nThe second factor in the integrand can be further factorized into p(\u03c7T +1:T +H |y1:T ,x1:T ) = \u222b p(\u03c7T +1:T +H |\u03c7T )p(\u03c7T |y1:T ,x1:T )d\u03c7T . (15)\nWe use Rao-Blackwellized particle filters (Doucet et al., 2000) to infer p(\u03c7T |y1:T ,x1:T ), so our model can keep adapting to new changes in an online manner, where the Rao-Blackwellization is possible because of our distribution assumptions made in the previous sections. We jointly infer \u03c0t and \u03c7t, with particles representing \u03c0t and closed-form inference of \u03c7t. Once we have obtained the posterior samples of p(\u03c7T |y1:T ,x1:T ), we use the prior model to sample trajectories of \u03c7T +1:T +H conditioned on the samples of \u03c7T . With the sample trajectories of p(\u03c7T +1:T +H |y1:T ,x1:T ), we sample the trajectories of p(yT +1:T +H |yT +1\u2212B:T ,xT +1\u2212B:T +H ,\u03c7T +1:T +H) using the aforementioned step-by-step predictions with our conditional distribution model."
        },
        {
            "heading": "4 Experiments",
            "text": "We compare our approach with 2 univariate and 5 multivariate time series models on synthetic (Section 4.1) and real-world (Section 4.2 and 4.3) datasets; see Table 1 for an overview, including references to the relevant literature and implementations. We note that DeepVAR is also called Vec-LSTM in previous works (Salinas et al., 2019; Rasul et al., 2021b). For our own model we consider two variants: an ablated model without the dynamic updates to the conditional distribution described in Section 3.3 (StatiConF); and our full model including those contributions (DynaConF). In both cases we experiment with different encoder architectures. For synthetic data, we use either a two-layer MLP with 32 hidden units (*\u2013MLP) or a point-wise linear + tanh mapping (*\u2013PP) as the encoder. For real-world data, we use an LSTM as the encoder.\n1https://github.com/awslabs/gluon-ts"
        },
        {
            "heading": "4.1 Experiments on Synthetic Data",
            "text": "Datasets For our experiments on synthetic data we simulate four conditionally non-stationary stochastic processes for T = 2500 time steps, where we use the first 1000 steps as training data, the next 500 steps as validation data, and the remaining 1000 steps as test data: (AR(1)\u2013Flip) We simulate an AR(1) process, yt = wtyt\u22121 + \u03f5t, \u03f5t \u223c N (0, 1), but resample its coefficient wt from a uniform categorical distribution over {\u22120.5, +0.5} every 100 steps to introduce non-stationarity. (AR(1)\u2013Dynamic) We simulate the same process as above but now resample wt from a continuous uniform distribution U(\u22121, 1) every 100 steps. (AR(1)\u2013Sin) We simulate the same process as above but now resample wt according to wt = sin(2\u03c0t/T ). Different from the two processes above, this process has a continuously changing non-stationary conditional distribution with its own time-dependent dynamics. (VAR(1)\u2013Dynamic) This process can be viewed as a multivariate generalization of AR(1)\u2013Dynamic and is used in our comparisons with multivariate baselines. We use a four-dimensional VAR process with an identity noise matrix. Similar to the univariate case, we resample the entries of the coefficient matrix from a continuous uniform distribution U(\u22120.8, 0.8) every 250 steps. In addition, we ensure the stability of the resulting process by computing the eigenvalues of the coefficient matrix and discard it if its largest absolute eigenvalue is greater than 1.\nExperimental Setup For univariate data (AR(1)\u2013Flip/Sin/Dynamic), we compare our approach with the two univariate baselines DeepAR and DeepSSM. For multivariate data (VAR(1)\u2013Dynamic), most baselines are redundant because their focus is on better observation models, while the underlying temporal backbone is similar. Since our synthetic observation distributions are simple, we compare with two model families that differ in their temporal backbone: DeepVAR (RNN backbone) and TransformerMAF (Transformer backbone). We use a context window size of 200 to give the models access to the information needed to infer the current parameter of the true conditional distribution. We tried increasing the window size to 500 on VAR(1)\u2013Dynamic but did not see performance improvements. We also removed the unnecessary default input features of these models to prevent overfitting. Further details about our setup can be found in Appendix B.\nFor evaluation we use a rolling-window approach with a window size of 10 steps. The final evaluation metrics are the aggregated results from all 100 test windows. We report the mean squared error (MSE) and continuous ranked probability score (CRPS) (Matheson & Winkler, 1976), a commonly used score to measure how close the predicted distribution is to the true distribution (see Appendix E for details). Full results including standard deviations can be found in the Appendix F. In all cases lower values indicate better performance.\nResults The results on synthetic data are shown in Table 2. For univariate data, our full model (DynaConF) outperforms its ablated counterpart (StatiConF) consistently across datasets and encoders, validating the importance of our dynamic adaptation to non-stationary effects. DynaConF\u2013PP is also superior to all univariate baselines, with its closest competitor DeepAR\u201310 behind by an average of 5.6% (CRPS). Furthermore, we note that our model with the pointwise encoder tends to outperform the MLP encoder, both for the ablated and full model. For multivariate data we observe similar trends. Here, our full model (DynaConF\u2013PP) performs 24.3% (CRPS) better than the ablated model (StatiConF\u2013PP) and 22.6% (CRPS) better than the best-performing baseline (DeepVAR\u2013160). Since for synthetic data we also have access to\n2https://github.com/zalandoresearch/pytorch-ts\nthe ground-truth models, we include the corresponding scores as references and upper bounds in terms of performance.\nFigure 3 shows qualitative results of our model on AR(1)\u2013Flip/Sin/Dynamic. Note that because the encoder in our model is non-linear, the encoding zt that is combined with \u03d5t is not the same as yt\u22121, so the inferred \u03d5t may not match the sign/scale of wt, although the predictions based on \u03d5t and zt can still stay close to yt = wtyt\u22121 + \u03f5t, e.g., if the signs of zt and yt\u22121 are flipped, and the signs of \u03d5t and wt are also flipped. Nonetheless, we can clearly see how \u03d5t differs qualitatively according to wt: gradual changes (Figure 3b) vs. sudden jumps (Figure 3a and Figure 3c) as well as jumps to previous values (Figure 3a) vs. new values (Figure 3c). Furthermore, since our model only sees data for t < 1000 during training, it is remarkable that it can adapt to unseen changes for t \u2265 1000 (Figure 3b and Figure 3c)."
        },
        {
            "heading": "4.2 Experiments on Real-World Data \u2013 Set 1",
            "text": "Datasets and Setup We evaluate the proposed method on six widely used datasets3 with published results (Lai et al., 2018; Salinas et al., 2019): (Exchange) daily exchange rates of 8 different countries from\n3https://github.com/mbohlkeschneider/gluon-ts/tree/mv_release/datasets\n1990 to 2016; (Solar)4 solar power production in 10-minute intervals of 137 PV plants in 2006; (Electricity)5 hourly electricity consumption of 370 customers from 2012 to 2014; (Traffic)6 hourly occupancy data at 963 sensor locations in the San Francisco Bay area; (Taxi) rides taken in 30-minute intervals at 1214 locations in New York City in January 2015/2016; (Wikipedia) daily page views of 2000 Wikipedia articles. We use the same train/test splits and input features, such as time of the day, as previous works with published code and results (Salinas et al., 2019; Rasul et al., 2021b;a), from which we also retrieved the performance of the baselines. For our method, we first train StatiConF and then reuse its learned encoder in DynaConF, so the optimization of DynaConF is focused on the dynamic model. Our models use a two-layer LSTM with 128 hidden units as the encoder, except for the 8-dimensional Exchange data, where the hidden size is 8. We stress again that, different from DeepVAR or LSTM-MAF, we use LSTM as an encoder of (yt\u2212B:t\u22121,xt\u2212B,t) only, so we actually \u201crestart\u201d it at every time step. More details of our hyperparameters can be found in Appendix C.\nResults The results are shown in Table 3. As we can see, the relative performance of each method differs across datasets and evaluation metrics. This shows that different models may benefit from dataset-specific structure in different ways. However, DynaConF achieves the best or closest-to-the-best performance more often than the baselines. Where it does not outperform, its performance is consistently competitive. We also note that our full model (DynaConF), which adapts to changes in the conditional distribution, performs either similarly or better than our ablated model (StatiConF), which itself differs from the baselines due to its explicit modeling of time-invariant conditional distributions. Full results including standard deviations can be found in Appendix F."
        },
        {
            "heading": "4.3 Experiments on Real-World Data \u2013 Set 2",
            "text": "Datasets and Setup We further evaluate our method against state-of-the-art baselines on two more publicly available datasets: (Walmart)7 weekly sales of 45 Walmart stores from February 2010 to October 2012; (Temperature)8 monthly average temperatures of 1000 cities from January 1980 to September 2020. We use the last 10% of the training time periods as validation sets to tune the hyperparameters for all models. For additional details about the experiment setup we refer to Appendix D.\nResults Our results are shown in Table 4. On these datasets, DynaConF shows a clear advantage over the baselines in terms of both CRPS and MSE. We believe this is mainly due to more significant changes in the conditional distributions of the time series in Set 2, a hypothesis which is also supported by the superior performance of DynaConF compared to the ablated StatiConF model. It is also worth noting that the best-performing baseline models across Set 1 and Set 2 are different, while the proposed model performs\n4http://www.nrel.gov/grid/solar-power-data.html 5https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014 6http://pems.dot.ca.gov 7https://www.kaggle.com/datasets/yasserh/walmart-dataset 8https://www.kaggle.com/datasets/hansukyang/temperature-history-of-1000-cities-1980-to-2020\nmore consistently. Combined with the results in the previous section, we conclude that DynaConF performs competitively if the conditional distribution remains relatively stable but outperforms the baselines if the conditional distribution does undergo dynamic changes, in line with its design and ability to account for such changes."
        },
        {
            "heading": "5 Limitations",
            "text": "Our model currently has the following limitations: (1) Since the variational posterior model complexity scales in O(T ), it could be challenging to train the model on extremely long time series. (2) We used a simple observation distribution family in this work to allow efficient inference, but there are cases where this may impact performance. For future work, it would be interesting to develop new variational posteriors and training algorithms that can scale better and more flexible inference algorithms that can deal with more complex observation distributions."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we addressed the problem of modeling and forecasting time series with non-stationary conditional distributions. We proposed a new model, DynaConF, that explicitly decouples the time-invariant conditional distribution modeling and the time-variant non-stationarity modeling. We designed specific architectures, developed new types of variational posteriors, and employed Rao-Blackwellized particle filters to allow the model to train efficiently on large multivariate time series and adapt to unseen changes at test time. Results on synthetic and real-world data show that our model can learn and adapt to different types of changes (continuous or discontinuous) in the conditional distribution and performs competitively or better than state-of-the-art time series forecasting models."
        },
        {
            "heading": "A Optimization Procedure",
            "text": "In contrast to existing time series models, we utilize a flexible variational posterior with a large number of parameters in the order of O(T ) and a structured prior model to account for conditional distribution changes over time. However, jointly optimizing over these variational parameters and the parameters in the conditional distribution model itself using stochastic gradient descent can be prohibitively demanding on the computational resources, especially GPU memory. Instead, we propose an alternative optimization procedure to learn these parameters.\nSpecifically, instead of optimizing by stochastic gradient descent (SGD) over all parameters in both the conditional distribution model and the prior and variational posterior model, we propose to learn the model by alternating the optimization of the parameters in the conditional distribution model and the prior and variational posterior models. For the former, we condition on the samples from the current posterior model while optimizing the conditional distribution model on randomly sampled sub-sequences from the time series using SGD. For the latter, we fix the conditional distribution model, sample from the variational posterior model over the entire time series either sequentially or in parallel, depending on the variational posterior model we use, and compute the loss using the samples through the conditional distribution, prior, and posterior models. Then we perform an update on the prior and posterior model parameters using the gradient from the loss.\nWhen the time series is high-dimensional and GPU memory becomes a constraint during training, we randomly sample a subset of observation dimensions for each batch, since the loss decomposes over the observation dimensions in our model.\nFor our models, we use Adam (Kingma & Ba, 2014) as the optimizer with the default initial learning rate of 0.001 unless it is chosen using the validation set. The dimension of the latent vector zt,i (see Section 3.2) is set to E = 4 across all the experiments."
        },
        {
            "heading": "B Synthetic Data: Details and Hyperparameters",
            "text": "On synthetic datasets, we use the validation set to early stop and choose the best model for both the baselines and our models. We perform 50 updates per epoch. We use 32 hidden units for our 2-layer MLP encoder. For the baselines, we report their results with different hidden sizes, including the default ones.\nWe keep most baseline hyperparameters to their default values but make the following changes to account for properties of our synthetic data: (1) To reduce overfitting, we remove any unnecessary input features from the models and use only past observations with time lag 1 as input. (2) To allow the models to adapt to changes in the conditional distribution we increase the context window size to 200. This allows the models to see enough observations generated with the latest ground-truth distribution parameters, so the models have the necessary information to adapt to the current distribution. For VAR(1)\u2013Dynamic, we also tried extending it to 500, but it did not improve the performance. (3) DeepSSM allows modeling of trend and seasonality, but since our synthetic data do not have those, we explicitly remove those components from the model specification to avoid overfitting; (4) DeepVAR allows modeling of different covariance structures in the noise, such as diagonal, low-rank, and full-rank. Since our synthetic data follow a diagonal covariance structure in the noise, we explicitly specify it for DeepVAR."
        },
        {
            "heading": "C Real-World Data \u2013 Set 1: Details and Hyperparameters",
            "text": "On real-world datasets with published results, we use the last 10% of the training time period as the validation set and choose the initial learning rate, number of training epochs, and model sizes using the performance on the validation set for StatiConF. After training StatiConF, we reuse its encoders in DynaConF, so it only needs to learn the dynamic model. For DynaConF, we use the same validation set to choose the number of training epochs and use 0.01 as the initial learning rate.\nBecause of the diversity of the real-world datasets, we further apply techniques to stablize training. Specifically, for all datasets, we use the mean and standard deviation to shift and scale each dimension of the time series. For Exchange, we use the mean and standard deviation of the recent past data in a moving context window. For the other datasets, we simply use the global mean and standard deviation of each dimension computed using the whole training set. In all cases, for forecasting, the output from the model is inversely scaled and shifted back for evaluation. These design choices were made based on the performance on the validation sets.\nOn real-world datasets, extreme values or outliers may cause instability during training. We optionally apply Winsorization using the quantiles (0.025 and 0.975) computed from the recent past data in a moving context window on Traffic and Wikipedia. The decisions of whether to apply this transformation were based on the results on the validation sets."
        },
        {
            "heading": "D Real-World Data \u2013 Set 2: Details and Hyperparameters",
            "text": "On the Walmart and Temperature datasets, the experiment setup is the same for all the models. For Walmart, the prediction window size is 4 weeks, and the test set consists of the last 20 weeks. For Temperature, the prediction window size is 3 months, and the test set consists of the last 24 months. We found it helpful to normalize the time series using the means and standard deviations computed from the training set for each dataset for stabilizing training, especially for LSTM-MAF and TransformerMAF. We use the last 10% of the training time period as the validation set to tune the hyperparameters, including the model size (32, 128, 512, 2048) and initial learning rate (0.01, 0.001), and for early stopping for each model we test. For the baseline models, we also use it to choose whether to apply marginal transformation (Salinas et al., 2019) and mean scaling (Salinas et al., 2020). We also tried increasing the context window sizes for all the baseline models but found that in many cases it resulted in worse validation performance compared to using the default size. In the other cases, it resulted in small improvements on the validation set but similar or worse performance on the test set. For consistency, we settled on using the same default context window size for all the models."
        },
        {
            "heading": "E Details on Evaluation",
            "text": "We run all experiments for three different random seeds independently and calculate and report the mean and standard deviation of each evaluation metric for each model. On synthetic datasets, we use 1000 sample paths to empirically estimate the predicted distributions for all models. On real-world datasets, we use 100 sample paths.\nWe use two evaluation metrics: mean squared error (MSE) and continuous ranked probability score (CRPS)(Matheson & Winkler, 1976). Assume that we observe y at time t but a probabilistic forecasting model predicts the distribution of y to be F . MSE is widely used for time series forecasting, and for a probabilistic forecasting model, where the mean of the distribution is used for point prediction, it is defined as\nMSE(F, y) = (Ez\u223cF [z] \u2212 y)2 (16)\nfor a single time point t and averaged over all the time points in the test set.\nCRPS has been used for evaluating how close the predicted probability distribution is to the ground-truth distribution and is defined as CRPS(F, y) = \u222b R (F (z) \u2212 I[y \u2264 z])2dz, (17)\nfor a single time point t and averaged over all the time points in the test set, where I denotes the indicator function. Generally, F (z) can be approximated by the empirical distribution of the samples from the predicted distribution. Both MSE and CRPS can be applied to multivariate time series by computing the metric on each dimension and then averaging over all the dimensions."
        },
        {
            "heading": "F Additional Experiment Results",
            "text": "Table 5, 6, 7, and 8 show the full CRPS and MSE results of the baselines and our models on the univariate and multivariate processes respectively. Table 9 and 10 show the full CRPS and MSE results of our models with means and standard deviations on previous real-world datasets. The results of the baselines on the real-world data \u2013 set 1 are from (Rasul et al., 2021b;a)."
        }
    ],
    "title": "DynaConF: Dynamic Forecasting of Non-Stationary Time-Series",
    "year": 2023
}