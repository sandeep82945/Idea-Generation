{
    "abstractText": "Traditionally, the detection of fraudulent insurance claims relies on business rules and expert judgement which makes it a time-consuming and expensive process (\u00d3skarsd\u00f3ttir et al., 2022). Consequently, researchers have been examining ways to develop efficient and accurate analytic strategies to flag suspicious claims. Feeding learning methods with features engineered from the social network of parties involved in a claim is a particularly promising strategy (see for example \u00d3skarsd\u00f3ttir et al. (2022); Van Vlasselaer et al. (2016); Tumminello et al. (2023)). When developing a fraud detection model, however, we are confronted with several challenges. The uncommon nature of fraud, for example, creates a high class imbalance which complicates the development of well performing analytic classification models. In addition, only a small number of claims are investigated and get a label, which results in a large corpus of unlabeled data. Yet another challenge is the lack of publicly available data. This hinders not only the development of new methods, but also the validation of existing techniques. We therefore design a simulation machine that is engineered to create synthetic data with a network structure and available covariates similar to the real life insurance fraud data set analyzed in \u00d3skarsd\u00f3ttir et al. (2022). Further, the user has control over several data-generating mechanisms. We can specify the total number of policyholders and parties, the desired level of imbalance and the (effect size of the) features in the fraud generating model. As such, the simulation engine enables researchers and practitioners to examine several methodological challenges as well as to test their (development strategy of) insurance fraud detection models in a range of different settings. Moreover, large synthetic data sets can be generated to evaluate the predictive performance of (advanced) machine learning techniques.",
    "authors": [
        {
            "affiliations": [],
            "name": "Bavo D.C. Campo"
        },
        {
            "affiliations": [],
            "name": "Katrien Antonio"
        }
    ],
    "id": "SP:dabd32d0858fb103741e1603a716cfc460b6b56c",
    "references": [
        {
            "authors": [
                "A. Agresti"
            ],
            "title": "Categorical data analysis",
            "venue": "3rd ed. edn. Hoboken: Wiley. Albashrawi,",
            "year": 2013
        },
        {
            "authors": [
                "M.A. Andresen",
                "M. Felson"
            ],
            "title": "The impact of co-offending",
            "venue": "Journal of Data Science",
            "year": 2004
        },
        {
            "authors": [
                "B. Avanzi",
                "G. Taylor",
                "M. Wang",
                "B. Wong"
            ],
            "title": "Synthetic: An individual insurance claim simulator with feature control",
            "venue": "Insurance: Mathematics and Economics",
            "year": 2021
        },
        {
            "authors": [
                "B. Baesens"
            ],
            "title": "Fraud analytics: a research agenda",
            "venue": "Journal of Chinese Economic and Business Studies 21(1), 137\u2013141.",
            "year": 2023
        },
        {
            "authors": [
                "B. Baesens",
                "V. Van Vlasselaer",
                "W. Verbeke"
            ],
            "title": "Fraud analytics using descriptive, predictive, and social network techniques : a guide to data science for fraud detection",
            "venue": "1st edition edn. Hoboken, New Jersey: Wiley.",
            "year": 2015
        },
        {
            "authors": [
                "S. Barman",
                "U. Pal",
                "M.A. Sarfaraj",
                "B. Biswas",
                "A. Mahata",
                "P. Mandal"
            ],
            "title": "A complete literature review on financial fraud detection applying data mining techniques",
            "venue": "International Journal of Trust Management in Computing and Communications 3(4), 336\u2013359.",
            "year": 2016
        },
        {
            "authors": [
                "M. Denuit",
                "J. Dhaene",
                "M. Goovaerts",
                "R. Kaas"
            ],
            "title": "Actuarial theory for dependent risks: measures, orders and models",
            "year": 2005
        },
        {
            "authors": [
                "European Insurance",
                "Occupational Pensions Authority"
            ],
            "title": "Big data analytics in motor and health insurance: a thematic review",
            "venue": "Luxembourg: Publications Office of the European Union.",
            "year": 2019
        },
        {
            "authors": [
                "FBI"
            ],
            "title": "Investigating insurance fraud",
            "venue": "Accessed 2022-07-08. https://www.fbi.gov/statsservices/publications/insurance-fraud.",
            "year": 2022
        },
        {
            "authors": [
                "E. Frees",
                "R. Derrig",
                "G. Meyers"
            ],
            "title": "Predictive modeling applications in actuarial science: volume 1, predictive modeling techniques",
            "venue": "New York: Cambridge University Press.",
            "year": 2014
        },
        {
            "authors": [
                "E.W. Frees",
                "J. Gao",
                "M.A. Rosenberg"
            ],
            "title": "Predicting the frequency and amount of health care expenditures",
            "venue": "North American Actuarial Journal 15(3), 377\u2013392.",
            "year": 2011
        },
        {
            "authors": [
                "A. Gabrielli",
                "M. W\u00fcthrich"
            ],
            "title": "An individual claims history simulation machine",
            "venue": "Risks 6(2).",
            "year": 2018
        },
        {
            "authors": [
                "J. Garrido",
                "C. Genest",
                "J. Schulz"
            ],
            "title": "Generalized linear models for dependent frequency and severity of insurance claims",
            "venue": "Insurance, Mathematics & Economics 70, 205\u2013215.",
            "year": 2016
        },
        {
            "authors": [
                "F. Ghobadi",
                "M. Rohani"
            ],
            "title": "Cost sensitive modeling of credit card fraud using neural network strategy",
            "venue": "\u20182016 2nd International Conference of Signal Processing and Intelligent Systems (ICSPIS)\u2019. IEEE. pp. 1\u20135.",
            "year": 2016
        },
        {
            "authors": [
                "M. Goldburd",
                "A. Khare",
                "D. Tevet",
                "D. Guller"
            ],
            "title": "Generalized linear models for insurance rating",
            "venue": "Casualty Actuarial Society, CAS Monographs Series 5.",
            "year": 2016
        },
        {
            "authors": [
                "C. Gomes",
                "Z. Jin",
                "H. Yang"
            ],
            "title": "Insurance fraud detection with unsupervised deep learning",
            "venue": "The Journal of Risk and Insurance 88(3), 591\u2013624.",
            "year": 2021
        },
        {
            "authors": [
                "J. Hanley",
                "B. McNeil"
            ],
            "title": "The meaning and use of the area under a receiver operating characteristic (roc) curve",
            "venue": "Radiology 143(1), 29\u201336.",
            "year": 1982
        },
        {
            "authors": [
                "X. He",
                "M. Gao",
                "Kan",
                "M.-Y.",
                "D. Wang"
            ],
            "title": "Birank: Towards ranking on bipartite graphs",
            "venue": "IEEE Transactions on Knowledge and Data Engineering 29(1), 57\u201371.",
            "year": 2017
        },
        {
            "authors": [
                "R. Henckaerts",
                "K. Antonio",
                "M. Clijsters",
                "R. Verbelen"
            ],
            "title": "A data driven binning strategy for the construction of insurance tariff classes",
            "venue": "Scandinavian Actuarial Journal 2018(8), 681\u2013705.",
            "year": 2018
        },
        {
            "authors": [
                "W. Hilal",
                "S.A. Gadsden",
                "J. Yawney"
            ],
            "title": "Financial fraud: A review of anomaly detection techniques and recent advances",
            "venue": "Expert Systems with Applications",
            "year": 2022
        },
        {
            "authors": [
                "D. Jensen"
            ],
            "title": "Prospective assessment of ai technologies for fraud detection: A case study",
            "venue": "\u2018AAAI Workshop on AI Approaches to Fraud Detection and Risk Management\u2019. Citeseer. pp. 34\u201338.",
            "year": 1997
        },
        {
            "authors": [
                "J.R.D. Kho",
                "L.A. Vea"
            ],
            "title": "Credit card fraud detection based on transaction behavior",
            "venue": "\u2018TENCON 2017-2017 IEEE Region 10 Conference\u2019. IEEE. pp. 1880\u2013884.",
            "year": 2017
        },
        {
            "authors": [
                "M. Khondoker",
                "R. Dobson",
                "C. Skirrow",
                "A. Simmons",
                "D. Stahl"
            ],
            "title": "A comparison of machine learning methods for classification using simulation with multiple real data examples from mental health studies",
            "venue": "Statistical Methods in Medical Research 25(5), 1804\u20131823. PMID: 24047600.",
            "year": 2016
        },
        {
            "authors": [
                "P. Kumar"
            ],
            "title": "Probability distributions and estimation of ali-mikhail-haq copula",
            "venue": "Applied Mathematical Sciences 4(14), 657\u2013666.",
            "year": 2010
        },
        {
            "authors": [
                "A. Lemmens",
                "C. Croux"
            ],
            "title": "Bagging and boosting classification trees to predict churn",
            "venue": "Journal of Marketing Research 43(2), 276\u2013286.",
            "year": 2006
        },
        {
            "authors": [
                "E.A. Lopez-Rojas",
                "D. Gorton",
                "S. Axelsson"
            ],
            "title": "Using the RetSim simulator for fraud detection research",
            "venue": "International Journal of Simulation and Process Modelling 10(2), 144\u2013155.",
            "year": 2015
        },
        {
            "authors": [
                "A.I. Marques",
                "V. Garcia",
                "J.S. Sanchez"
            ],
            "title": "On the suitability of resampling techniques for the class imbalance problem in credit scoring",
            "venue": "The Journal of the Operational Research Society 64(7), 1060\u20131070.",
            "year": 2013
        },
        {
            "authors": [
                "P. McCullagh",
                "J.A. Nelder"
            ],
            "title": "Generalized linear models",
            "venue": "London: Chapman and Hall.",
            "year": 1999
        },
        {
            "authors": [
                "T.P. Morris",
                "I.R. White",
                "M.J. Crowther"
            ],
            "title": "Using simulation studies to evaluate statistical methods",
            "venue": "Statistics in Medicine 38(11), 2074\u20132102.",
            "year": 2019
        },
        {
            "authors": [
                "M. Newman"
            ],
            "title": "Networks : an introduction",
            "venue": "Oxford: Oxford University Press.",
            "year": 2010
        },
        {
            "authors": [
                "E. Ngai",
                "Y. Hu",
                "Y. Wong",
                "Y. Chen",
                "X. Sun"
            ],
            "title": "The application of data mining techniques in financial fraud detection: A classification framework and an academic review of literature",
            "venue": "Decision Support Systems 50(3), 559\u2013569.",
            "year": 2011
        },
        {
            "authors": [
                "I.M. Nur Prasasti",
                "A. Dhini",
                "E. Laoh"
            ],
            "title": "Automobile insurance fraud detection using supervised classifiers",
            "venue": "\u20182020 International Workshop on Big Data and Information Security (IWBIS)\u2019. IEEE. pp. 47\u201352.",
            "year": 2020
        },
        {
            "authors": [
                "E. Ohlsson",
                "B. Johansson"
            ],
            "title": "Non-Life Insurance Pricing with Generalized Linear Models",
            "venue": "Berlin, Heidelberg: Springer Berlin Heidelberg : Imprint: Springer.",
            "year": 2010
        },
        {
            "authors": [
                "T. Oommen",
                "L.G. Baise",
                "R.M. Vogel"
            ],
            "title": "Sampling bias and class imbalance in maximum-likelihood logistic regression",
            "venue": "Mathematical Geosciences 43(1), 99\u2013120.",
            "year": 2011
        },
        {
            "authors": [
                "M. \u00d3skarsd\u00f3ttir",
                "W. Ahmed",
                "K. Antonio",
                "B. Baesens",
                "R. Dendievel",
                "T. Donas",
                "T. Reynkens"
            ],
            "title": "Social network analytics for supervised fraud detection in insurance",
            "venue": "Risk Analysis 42(8), 1872\u20131890.",
            "year": 2022
        },
        {
            "authors": [
                "L. Page",
                "S. Brin",
                "R. Motwani",
                "T. Winograd"
            ],
            "title": "The PageRank citation ranking: Bringing order to the web",
            "venue": "Technical report. Stanford InfoLab",
            "year": 1999
        },
        {
            "authors": [
                "J. Park",
                "Barab\u00e1si",
                "A.-L."
            ],
            "title": "Distribution of node characteristics in complex networks",
            "venue": "Proceedings of the National Academy of Sciences - PNAS 104(46), 17916\u201317920.",
            "year": 2007
        },
        {
            "authors": [
                "T. Pourhabibi",
                "Ong",
                "K.-L.",
                "B.H. Kam",
                "Y.L. Boo"
            ],
            "title": "Fraud detection: A systematic literature review of graph-based anomaly detection approaches",
            "venue": "Decision Support Systems 133, 113303.",
            "year": 2020
        },
        {
            "authors": [
                "O.A. Quijano Xacur",
                "J. Garrido"
            ],
            "title": "Generalised linear models for aggregate claims: to Tweedie or not",
            "venue": "European Actuarial Journal 5(1), 181\u2013202.",
            "year": 2015
        },
        {
            "authors": [
                "A.J. Reiss"
            ],
            "title": "Co-offending and criminal careers",
            "venue": "Crime and Justice (Chicago, Ill.) 10, 117\u2013 170.",
            "year": 1988
        },
        {
            "authors": [
                "R. Roy",
                "K.T. George"
            ],
            "title": "Detecting insurance claims fraud using machine learning techniques",
            "venue": "\u20182017 International Conference on Circuit ,Power and Computing Technologies (ICCPCT)\u2019. IEEE. pp. 1\u20136.",
            "year": 2017
        },
        {
            "authors": [
                "B. So",
                "Boucher",
                "J.-P.",
                "E.A. Valdez"
            ],
            "title": "Synthetic dataset generation of driver telematics",
            "venue": "Risks 9(4).",
            "year": 2021
        },
        {
            "authors": [
                "A. Srivastava",
                "M. Yadav",
                "S. Basu",
                "S. Salunkhe",
                "M. Shabad"
            ],
            "title": "Credit card fraud detection at merchant side using neural networks",
            "venue": "\u20182016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)\u2019. Bharati Vidyapeeth, New Delhi as the Organizer of INDIACom - 2016. pp. 667\u2013670.",
            "year": 2016
        },
        {
            "authors": [
                "K. Storchmann"
            ],
            "title": "On the depreciation of automobiles: An international comparison",
            "venue": "Transportation (Dordrecht) 31(4), 371\u2013408.",
            "year": 2004
        },
        {
            "authors": [
                "S. Subudhi",
                "S. Panigrahi"
            ],
            "title": "Use of optimized fuzzy c-means clustering and supervised classifiers for automobile insurance fraud detection",
            "venue": "Journal of King Saud University. Computer and Information Sciences 32(5), 568\u2013575.",
            "year": 2020
        },
        {
            "authors": [
                "G.G. Sundarkumar",
                "V. Ravi"
            ],
            "title": "A novel hybrid undersampling method for mining unbalanced datasets in banking and insurance",
            "venue": "Engineering Applications of Artificial Intelligence 37, 368\u2013377.",
            "year": 2015
        },
        {
            "authors": [
                "F. Thabtah",
                "S. Hammoud",
                "F. Kamalov",
                "A. Gonsalves"
            ],
            "title": "Data imbalance in classification: Experimental evaluation",
            "venue": "Information Sciences 513, 429\u2013441.",
            "year": 2020
        },
        {
            "authors": [
                "J.W. Tukey"
            ],
            "title": "Exploratory data analysis",
            "venue": "Reading: Addison-Wesley",
            "year": 1977
        },
        {
            "authors": [
                "M. Tumminello",
                "A. Consiglio",
                "P. Vassallo",
                "R. Cesari",
                "F. Farabullini"
            ],
            "title": "Insurance fraud detection: A statistically validated network approach",
            "venue": "The Journal of Risk and Insurance 90(2), 381\u2013419.",
            "year": 2023
        },
        {
            "authors": [
                "R. van den Goorbergh",
                "M. van Smeden",
                "D. Timmerman",
                "B. Van Calster"
            ],
            "title": "The harm of class imbalance corrections for risk prediction models: illustration and simulation using logistic regression",
            "venue": "Journal of the American Medical Informatics Association",
            "year": 2022
        },
        {
            "authors": [
                "M.V. van Koppen",
                "C.J. de Poot",
                "E.R. Kleemans",
                "P. Nieuwbeerta"
            ],
            "title": "Criminal trajectories in organized crime",
            "venue": "British Journal of Criminology",
            "year": 2010
        },
        {
            "authors": [
                "V. Van Vlasselaer",
                "T. Eliassi-Rad",
                "L. Akoglu",
                "M. Snoeck",
                "B. Baesens"
            ],
            "title": "GOTCHA! network-based fraud detection for social security fraud",
            "venue": "Management Science",
            "year": 2016
        },
        {
            "authors": [
                "A. Vosseler"
            ],
            "title": "Unsupervised insurance fraud prediction based on anomaly detector ensembles",
            "venue": "Risks (Basel) 10(7), 132\u2013.",
            "year": 2022
        },
        {
            "authors": [
                "D.E. Warren",
                "M.E. Schweitzer"
            ],
            "title": "When lying does not pay: How experts detect insurance fraud",
            "venue": "Journal of Business Ethics 150(3), 711\u2013726.",
            "year": 2018
        },
        {
            "authors": [
                "J. West",
                "M. Bhattacharya"
            ],
            "title": "Intelligent financial fraud detection: A comprehensive review",
            "venue": "Computers & Security 57, 47\u201366.",
            "year": 2016
        },
        {
            "authors": [
                "C boundary"
            ],
            "title": "Simulating type of coverage The type of coverage is a nominal variable with three levels. We rely on a multinomial regression model to generate the type of coverage as a function of ValueCar, AgeCar and AgePH. The general form of the multinomial logistic regression model (Agresti",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "Keywords: social network data, simulation machine, insurance fraud detection, class imbalance, unlabeled data"
        },
        {
            "heading": "1 Introduction",
            "text": "Fraudulent activity in the insurance industry causes significant financial losses for both insurance companies and policyholders. In non-life insurance, the total yearly cost of fraudulent claims is estimated to be more than $40 billion in the United States (FBI, 2022). For an average family, this leads to an increased yearly premium of $400 to $700 (FBI, 2022). To detect and mitigate fraud, insurance companies implement various anti-fraud measures. Traditionally, insurance companies rely on a combination of business rules and expert judgment to identify\n1\nar X\niv :2\n30 8.\n11 65\n9v 1\n[ cs\n.L G\n] 2\n1 A\nug 2\nfraudulent claims (O\u0301skarsdo\u0301ttir et al., 2022). The business rules flag suspicious claims, which are then sent to experts who determine whether the claim is fraudulent or not (Warren and Schweitzer, 2018). These in-depth investigations, however, are time-intensive and costly. Researchers have therefore developed insurance fraud detection models combining business rules and analytical techniques to flag the most suspicious claims, which are sent to the experts for further investigation. As such, experts can focus solely on the claims with a high likelihood of fraud and avoid spending precious resources on examining non-fraudulent claims. Insurers predominately rely on analytics to prevent fraud (European Insurance and Occupational Pensions Authority, 2019). Moreover, fraud detection is considered an area for more intense use of big data and analytics in the insurance industry.\nWithin fraud analytics, researchers rely on a wide range of statistical and machine learning techniques (see Ngai et al. (2011) and Albashrawi (2016) for an overview). In the literature, we find examples of both supervised and unsupervised (machine learning) techniques to construct fraud detection models. Vosseler (2022), for example, developed an unsupervised anomaly detection technique to identify fraudulent insurance claims. Nur Prasasti et al. (2020) constructed fraud detection models using neural networks and tree-based machine learning techniques. The accuracy of such models, however, greatly depends on the input. We typically use traditional claim characteristics, such as the claim amount, as features in a fraud detection model (Baesens et al., 2015). These characteristics are static whereas the typical features of fraudsters tend to be dynamic (O\u0301skarsdo\u0301ttir et al., 2022; Gomes et al., 2021; Tumminello et al., 2023). According to Jensen (1997), fraudsters adapt their tactics in response to fraud detection systems and hence, the typical fraudster profile evolves over time.\nOne particularly promising approach to capture the characteristics of fraudsters is through social network analytics (Van Vlasselaer et al., 2016; O\u0301skarsdo\u0301ttir et al., 2022; Tumminello et al., 2023). In an insurance context, social network data captures the relationship between claims on the one hand and policyholders and other involved parties (e.g., garage, broker, expert) on the other hand. By analyzing the social network structure of reported claims, insurers can unravel patterns and relationships among policyholders and claims that are indicative of fraud. Moreover, this approach potentially uncovers organized schemes of collaborating fraudsters who are trying to hide their tracks. Criminals often commit crimes in groups to increase rewards and to decrease the risk of detection (Reiss, 1988; Andresen and Felson, 2009). Furthermore, in organized crime, such as fraud, social connections play a crucial role since these connections are based on trust and provide access to co-offenders and opportunities (van Koppen et al., 2010). As such, social network analytics can assist in identifying enduring relationships between fraudsters even as overt characteristics undergo changes.\nNonetheless, publicly available data on insurance fraud is scarce, in particular data with a social network structure. This makes it difficult for researchers to test, validate and improve existing fraud detection methods. Moreover, the lack of data hinders the reproducibility of research findings and the discovery of novel methodologies (Baesens, 2023). The main reason for the limited availability is the sensitive nature of the data (Lopez-Rojas et al., 2015). Insurance data sets contain confidential information about the insurance company and its policyholders. In consequence, the data used to develop and validate fraud detection methods and models is almost never shared. Researchers in fraud analytics are confronted with several inherent methodological challenges when developing analytic models for fraud detection (Baesens, 2023). Investigating suspicious claims is a time-intensive and expensive process, which results in only few claims being labeled (i.e. whether the claim is fraudulent or non-fraudulent) (Warren and Schweitzer, 2018). In addition, due to fraud being uncommon, data sets are often characterized by a severe class imbalance (see, for example O\u0301skarsdo\u0301ttir et al. (2022); Gomes et al. (2021);\n2\nSubudhi and Panigrahi (2020)). Another challenge is the continuous development of machine learning techniques (Baesens, 2023). To assess whether these perform better or on par with existing techniques, we need to evaluate competing models or techniques in similar conditions. That is, using the same (type of) data set.\nOne way to address the scarcity of publicly available data, is by using a simulation engine to generate synthetic data that mimics the structure of the original data set (Lopez-Rojas et al., 2015). Simulation engines enable researchers to perform benchmark studies to investigate the properties and performance of various statistical and machine learning techniques (Morris et al., 2019; Khondoker et al., 2016). Additionally, synthetic data facilitates the development of new methods and stimulates the reproducibility of research. Recently, simulation engines have gained considerable attention in actuarial science. Gabrielli and Wu\u0308thrich (2018) developed a simulation engine to generate individual claim histories of non-life insurance claims and So et al. (2021) devised an engine to generate synthetic telematics data. However, both engines employ neural networks trained on a single real insurance data set to generate synthetic data that closely mirrors the original data. Conversely, the simulation machine of Avanzi et al. (2021) does not emulate a single data set when generating individual non-life insurance claims. Instead, it allows users to generate a diverse set of scenarios which vary in complexity.\nIn this paper, we design a simulation machine that generates synthetic insurance fraud network data. The simulation engine is inspired by and mimics the structure and properties of the nonlife motor insurance data used in O\u0301skarsdo\u0301ttir et al. (2022), which contains both traditional claim and policy(holders) characteristics as well as social network features. When generating the synthetic data, the user has control over several data-generating mechanisms. Both policyholder, contract-specific and claim characteristics as well as the dependence between them can be adjusted. Further, when simulating the number of claims, the individual claim costs and the claim labels (i.e. fraudulent or non-fraudulent), the user can specify the (effect size of the) features that are used in the data-generating model. Specific characteristics of the social network structure and fraud investigation process can be adjusted as well. In addition, the size of the resulting data set and the required level of class imbalance can be set by the user. Hereby, the simulation engine provides researchers with a powerful and valuable tool for evaluating and improving the performance of fraud detection methods across various scenarios. The simulation engine\u2019s ability to produce large data sets makes it ideal for machine learning techniques that require large amounts of data. Furthermore, researchers and practitioners can use the engine to test their (development strategy of) insurance fraud detection models and to investigate the performance of a wide range of analytic methods in tackling the challenges inherent to fraud data sets, e.g. the severe class imbalance and large number of missing labels. Additionally, by examining a specific method or model in these scenarios, researchers can gain a better understanding of its strengths and limitations.\nThis paper is structured as follows. In Section 2, we discuss the fraud cycle, existing analytic fraud detection strategies and provide a comprehensive overview of social network analytics for fraud detection strategies. Further, we address several challenges that are an integral part of fraud detection research. Section 3 delves into the design of the simulation engine and explains how a synthetic data set is generated. Section 4 showcases the simulation engine\u2019s capabilities by generating and exploring two different types of synthetic data sets. In the first type we introduce a social network effect when simulating the claim labels and in the second type, we omit the social network effect. Additionally, using the artificial data, we provide a practical demonstration of the development and evaluation of a fraud detection model. We conclude the paper with Section 5.\n3"
        },
        {
            "heading": "2 Fighting fraud with data analytics: strategies, techniques and",
            "text": "challenges\nIn this section, we provide an overview of some conventional and emerging approaches to fraud detection. We highlight the role of analytics in uncovering fraudulent activities and discuss the various challenges that researchers and practitioners face in this domain."
        },
        {
            "heading": "2.1 Uncovering fraud: traditional and analytic approaches",
            "text": "In insurance, policyholders file a claim to request a financial compensation for a covered loss. The insurance company retains all relevant information on past and current claims in a database, typically stored in a tabular format. The data set encompasses claim, policyholder, and contractspecific attributes, collectively referred to as traditional claim characteristics. Certain claims, however, are illegitimate and detecting fraudulent claims is essential for insurance companies to prevent financial losses and to protect their policyholders. Hereto, insurers adopt either a traditional, a data-driven or a combined strategy to flag suspicious claims.\nExpert-based fraud detection The traditional approach to detect fraud is expert-based (Baesens et al., 2015). This approach is two-fold. First, the insurance company flags certain claims as suspicious. To flag suspicious claims, companies rely on a set of business rules that are based on insights from previous investigations. Second, once a claim is flagged as suspicious, the claim is passed to an expert, who conducts an in-depth investigation to determine whether the claim is fraudulent or not (Warren and Schweitzer, 2018). Hereafter, newly obtained insights from the investigation are used to adjust the procedure for identifying suspicious claims. This is known as the fraud detection cycle.\nThe expert-based approach, however, has some notable shortcomings (Baesens et al., 2015). It is highly dependent on the manual input and expertise of the expert. In addition, investigating claims is a time-intensive and expensive process. Moreover, the dynamic nature of fraud requires that the rule base to flag suspicious claims needs to be continuously monitored, improved and updated. To address these drawbacks, researchers have developed alternative approaches to detect fraud in a more automated manner (Baesens et al., 2015; Ngai et al., 2011; Albashrawi, 2016; Barman et al., 2016). Notwithstanding, even with the alternative approaches, the inclusion of expert knowledge and input is critical to the success of the fraud detection system.\nFraud analytics The limitations of the expert-based approach prompted researchers to develop data-driven methodologies to detect fraud. In the literature, either supervised or unsupervised learning techniques or a combination of both are employed. Within fraud detection, we use unsupervised learning techniques to identify anomalous behavior (Baesens et al., 2015). There is a plethora of anomaly detection techniques available and Hilal et al. (2022) provides an extensive overview of anomaly detection techniques to detect financial fraud. In our paper, we focus on supervised learning methods which learn from historical, labeled data. There are numerous supervised techniques available that can be utilized to construct a fraud detection model, ranging from logistic regression models to neural networks. A comprehensive literature review of the supervised techniques applied in financial fraud detection can be found in Ngai et al. (2011); Barman et al. (2016); Albashrawi (2016).\nOne way to tackle insurance fraud detection is by treating it as a binary classification problem. Here, our response variable Yi can take on only two values: 0 (non-fraud) or 1 (fraud). Further,\n4\neach claim i has a corresponding covariate vector xi. The values herein correspond to a set of features that provide information on the policyholder, contract, claim, network and any other relevant features that can assist in identifying fraudulent claims. The general equation of a predictive classification model is\nP [Yi = 1|xi] = f(xi) (1)\nwhere P [Yi = 1|xi] denotes the probability that claim i is fraudulent given covariate vector xi and f(xi) denotes the predictive model. Logistic regression is one of the most popular models to estimate (1) (Ngai et al., 2011; Baesens et al., 2015; Barman et al., 2016; Albashrawi, 2016). Other commonly employed techniques include tree-based learners (Kho and Vea, 2017; Roy and George, 2017) and neural networks (Srivastava et al., 2016; Ghobadi and Rohani, 2016).\nTo develop a fraud detection model, we rely on historical, labeled data of past observed fraud behavior (Baesens et al., 2015). This historical data is commonly derived from the expert judgment of previously investigated claims and serves as the foundation for constructing an effective fraud detection model. By training the fraud detection model on labeled claims, we aim to find hidden patterns that allow us to identify new fraudulent claims."
        },
        {
            "heading": "2.2 Enriching traditional claim characteristics with social network data",
            "text": "Both the expert-based and fraud analytics approach commonly rely on traditional claim characteristics stored in a tabular data set. To go beyond this tabular structure, we can rely on social network analytics which extracts information from the relational structure in the data set. As such, we augment the database with supplementary information on the social network structure of the claim and the involved parties. The involved parties are typically the policyholder and the experts involved in the claim (O\u0301skarsdo\u0301ttir et al., 2022). Certain contracts involve the active participation of brokers, hereby incorporating them into the network structure. Further, depending on the type of insurance, other parties may be present as well. In motor insurance, for example, we commonly also have the auto repair shop that repaired the vehicle (hereafter referred to as the garage). In constructing the network structure, O\u0301skarsdo\u0301ttir et al. (2022) take a holistic view by integrating information across multiple lines of business. In this paper, we focus exclusively on the social network structure within one specific insurance product.\nFigure 1(a) depicts a toy example of a social network consisting of seven claims and seven involved parties. In this figure, the edges symbolize the connections between the claims and the parties. The claims and parties are represented by circles and the claims in the network are color-coded. Green claims correspond to non-fraudulent claims and fraudulent claims are colored red. There is a notable cluster of fraudulent claims (i.e. c5, c6 and c7) that are strongly interconnected. Party p7 is connected to all three fraudulent claims and might be the central figure in the criminal network. Via the claims, p7 is connected to the fraudsters p5 and p6. In this example, all fraudsters are connected to each other via one or more fraudulent claims.\nTo obtain a mathematical representation of the network data, we use a bipartite network of nodes C \u222a P and edges E. C denotes the set of all claims and P the set of all parties in the network. E is the set of edges that connect the nodes in C to the nodes in P . The bipartite network G = (C\u222aP,E) is undirected (i.e. there is no direction in the edges). We use ci to denote an individual claim, where i \u2208 (1, . . . , nC) and nC is the total number of nodes in C. pj denotes an individual party. Here, j \u2208 (1, . . . , nP ) where nP is the total number of nodes in P . The network\u2019s edges are represented in a weight matrix W of dimension nP \u00d7 nC . Each individual edge carries a certain weight wij that reflects the strength of the relationship between claim i\n5\nand party j. If wij > 0, claim ci is connected to party pj . We have an unweighted network when all nonzero values in W are equal to one.\nWe refer to the set of nodes, connected to node ci via a path of exactly k edges, as the k th order neighborhood of ci and we denote it as N kci . Hence, the first-order neighborhood of a claim ci consists of all involved parties\nN 1ci = {pj |wij \u0338= 0} (2)\nand the second-order neighborhood of ci\nN 2ci = {ck|pj \u2208 N 1 ck \u2227 wkj \u0338= 0} \\ ci. (3)\nare all the claims connected to the parties in N 1ci . In an unweighted network, we refer to the number of nodes in a node\u2019s first order neighborhood as the degree of the node. For claim ci, we denote this as di and dj refers to the degree of party pj . The degree of all claims is summarized in a nC \u00d7 nC diagonal matrix DC , where (DC)ii = di \u2200 i. Similarly, the nP \u00d7 nP diagonal matrix DP contains the degrees of all parties.\nIn this toy example of a social network, we use an unweighted network. Figure 1(b) represents the corresponding W that captures the connections in the example. The strong interconnectedness between fraudsters and fraudulent claims is also reflected in W . In the lower right corner of W we notice a distinct cluster, which predominantly consists of fraudulent nodes and which reveals a web of fraudsters. We observe another group of connected claims in the upper left corner of W . This cluster consists mostly of legitimate claims. Furthermore, there are only a few links connecting fraudulent and non-fraudulent nodes, indicating limited relationships between the two groups.\nHomophily One of the fundamental concepts in a network-based fraud detection approach is the concept of homophily (Baesens et al., 2015; O\u0301skarsdo\u0301ttir et al., 2022). This refers to the tendency of people to form social connections with individuals that are similar to themselves\n6\nin some way (Newman, 2010). Translated to an insurance context, this means that fraudulent claims are predominantly linked to other fraudulent claims, while non-fraudulent claims tend to be connected to other non-fraudulent claims. Moreover, fraudulent and non-fraudulent claims exhibit a weaker degree of connection with each other.\nTo assess whether there are patterns of homophily present in the network, we compute the dyadicity and heterophilicity of the network (Park and Baraba\u0301si, 2007; Baesens et al., 2015). Dyadicity measures the connectedness between nodes with the same label. The higher the dyadicity, the more densely connected the same-label nodes are, compared to what is expected based on a random network configuration. Conversely, heterophilicity assesses the degree of interconnection between nodes with different labels. Networks exhibit high heterophilicity when nodes with different labels show higher interconnectedness compared to what is expected by chance.\nIn a fraud context, the investigated claims can be labeled as fraudulent (1) or non-fraudulent (0). Claims that are uninvestigated have no label and are referred to as unlabeled. Hence, there are three different labels present in the data set. If our focus is on the identification of dense networks of fraudulent claims, we can adopt a one-versus-all classification strategy and group the unlabeled with the non-fraudulent claims. We denote the total number of fraudulent claims as 1nC and 0nC denotes the total number of non-fraudulent and unlabeled claims. Further, nC = 1nC + 0nC . In this example, we have three types of relationships between claims or socalled dyads. That is: fraudulent claims connected to other fraudulent claims (1 - 1); fraudulent claims linked to non-fraudulent, unlabeled claims (1 - 0) and non-fraudulent, unlabeled claims connected to non-fraudulent, unlabeled claims (0 - 0). We use m11, m10 and m00 to refer to the total number of dyads of each kind present in the network and |E| = m11 +m10 +m00, where |E| denotes the number of edges. \u03c1 denotes the probability that two nodes are connected and is empirically calculated in the network as\n\u03c1 = 2|E|\nnC(nC \u2212 1) . (4)\nIf nodes are randomly connected to other nodes irrespective of their labels, the expected values of m11 and m10 equal (Baesens et al., 2015)\nm11 = 1nC(1nC \u2212 1)\u03c1\n2 and m10 = 1nC(nC \u2212 1nC)\u03c1. (5)\nWe then calculate the dyadicity D and heterophilicity H of the network as\nD = m11 m11 , (6) H = m10 m10 . (7)\nWhen D > 1, the network is dyadic and fraudulent nodes are more densely connected to each other compared to what we expect by chance and D \u2248 1 corresponds to a random network configuration. Here, \u2248 denotes approximately equal to. We have a heterophobic network if H < 1, indicating that fraudulent claims have fewer connections to non-fraudulent claims than what is expected by chance. In a random network configuration, H \u2248 1. In our fictive example depicted in Figure 1, the network is dyadic (D = 2.5) and heterophobic (H = 0.28). Consequently, we can infer that our network exhibits homophily as it displays both dyadicity (D > 1) and heterophobia (H < 1). In this toy example, engineering features from the social network potentially enables us to identify collaborating fraudsters that try to hide their tracks.\n7\nBiRank algorithm In a homophilic network (i.e. where D > 1 and H < 1), we can potentially uncover fraud by inspecting claims that are closer and more densely connected to known fraudulent claims. To evaluate the proximity to fraudulent claims, a suitable metric is needed. One effective approach is to employ the BiRank algorithm (He et al., 2017). This algorithm is an extension of the personalized PageRank algorithm (Page et al., 1999) and is specifically designed for bipartite networks. Using BiRank, we rank claims with respect to their exposure to known fraudulent claims (O\u0301skarsdo\u0301ttir et al., 2022).\nThe scores of nodes ci and pj are calculated iteratively as\nci = nP\u2211 j=1 wijpj and pj = nC\u2211 i=1 wijci\nwhere ci and pj denote the scores of nodes ci and pj , respectively. To ensure convergence and stability, the scores are normalized using\nci = nP\u2211 j=1 wij\u221a di \u221a dj pj and pj = nC\u2211 i=1 wij\u221a di \u221a dj ci. (8)\nThis normalization lessens the contribution of high-degree nodes and gives better quality results (He et al., 2017). To steer the scoring towards fraudulent claims, we incorporate query vectors in the scoring process. These query vectors encode our prior belief on the nodes\u2019 importance. We use c0 and p0 to denote the query vectors for the claims and parties, respectively. Further, c0i and p 0 j represent the individual entries in the vectors c 0 and p0. We adjust (8) to\nci = \u03b1 nP\u2211 j=1 wij\u221a di \u221a dj pj + (1\u2212 \u03b1)c0i and pj = \u03b2 nC\u2211 i=1 wij\u221a di \u221a dj ci + (1\u2212 \u03b2)p0j . (9)\nwhere \u03b1 \u2208 [0, 1] and \u03b2 \u2208 [0, 1] are adjustable parameters. The values for \u03b1 and \u03b2 regulate the relative emphasis given to the network structure and the query vector. We rewrite (9) in matrix form\nc = \u03b1Sp+ (1\u2212 \u03b1)c0 and p = \u03b2ST c+ (1\u2212 \u03b2)p0. (10)\nHere, S = D \u2212 1\n2 C WD\n\u2212 1 2\nP denotes the symmetrically normalized weight matrix. We start the algorithm by randomly initializing the ranking vectors c and p. Hereafter, we iteratively compute the node scores until convergence.\nWe encode information about known fraudulent claims into the query vector c0 to rank the nodes\u2019 scores towards fraudulent claims. When the claim is fraudulent, we set c0i = 1 and c0i = 0 otherwise. We define p\n0 \u2261 0, since only claims can be fraudulent and not parties. We set \u03b2 = 1 since we do not include prior information on the parties. We adjust (10) to\nc = \u03b1Sp+ (1\u2212 \u03b1)c0 and p = ST c.\nThe iterative procedure to compute the fraud scores is summarized in Algorithm 1. The BiRank algorithm stops when the difference between two successive iterations is below a certain threshold or when we exceed the maximum number of iterations.\nNetwork featurization Next, we engineer several social network features from the network structure, the labels and the scores resulting from the BiRank algorithm. These features capture the information that is embedded in the network of the claims and can be integrated into\n8\nAlgorithm 1: BiRank algorithm for computing fraud scores in a network of insurance claims and parties (O\u0301skarsdo\u0301ttir et al., 2022). Adapted from Algorithm 1 in He et al. (2017). We omit the query vector p0 and set \u03b2 = 1.\nInput: Weight matrix W , query vector c0 and hyperparameter \u03b1 = 0.85; Output: Ranking vectors c and p;\n1 Symmetrically normalize W : S = D \u2212 1\n2 P WD\n\u2212 1 2\nC ; 2 Randomly initialize c and p; 3 while stopping criteria is not met do 4 c\u2190 \u03b1Sp+ (1\u2212 \u03b1)c0; 5 p\u2190 ST c ; 6 return c and p;\na tabular dataset alongside the individual characteristics of each claim. The social network features then represent an additional source of information that we can use in our fraud analytics models (see Section 2.1). We divide the network features into two groups, the fraud-score based features and the neighborhood based features (see Table 1). The results from the BiRank algorithm are used to compute the fraud-score based features. Here, we look at the claim\u2019s fraud score and the distribution of the fraud scores in, for instance, its first and second order neighborhood. To summarize these distributions, we can rely on (robust) central tendency measures such as the median or midmean (Tukey, 1977). Further, we engineer neighborhood based features that capture the surrounding network structure of each claim. Here, we can compute the size of a claim\u2019s first and second neighborhood for instance."
        },
        {
            "heading": "2.3 Challenges within fraud analytics",
            "text": "When developing an analytic model for fraud detection, we encounter several challenges that are inherent to research on fraud. One of the main challenges is the infrequent nature of fraud, which leads to highly imbalanced data sets (Baesens et al., 2015; Jensen, 1997; West and Bhattacharya, 2016; Thabtah et al., 2020). This imbalance creates a bias towards the majority class for certain analytic techniques, resulting in compromised fraud detection performance. Within fraud research, we commonly tackle the class imbalance problem by employing resampling techniques such as under- and over-sampling, SMOTE or ROSE (Baesens, 2023; Subudhi and Panigrahi, 2020; Sundarkumar and Ravi, 2015; Van Vlasselaer et al., 2016; O\u0301skarsdo\u0301ttir et al., 2022). A second challenge is the dynamic nature of fraud (Baesens et al., 2015; Baesens, 2023; West and Bhattacharya, 2016). To remain undetected, fraudsters continuously adapt their behavior and tactics. Consequently, it is essential to detect fraud as soon as possible and to tweak or rebuild the fraud detection model when necessary. Hereto related is the computational efficiency of the fraud detection model (Baesens et al., 2015; West and Bhattacharya, 2016) which represents yet another challenge. With the rapid advancement of machine learning, new methods are constantly emerging, adding to the ever-growing repertoire of techniques available. Further, given the high cost of fraud, it is crucial to detect fraudulent activities instantly. Existing analytic methods for fraud detection are predominantly evaluated based on their accuracy, often overlooking the aspect of computational efficiency. For an accurate and reliable comparison of competing methods, it is essential to evaluate their performance on a set of benchmark data sets. Most studies, however, do not share their data sets due to their sensitive nature. The lack of publicly available data hinders the reproducibility of research (Baesens, 2023) and gives rise to a fifth challenge (Pourhabibi et al., 2020; West and Bhattacharya, 2016). The sixth and final challenge arises from the disproportionate misclassification cost and the specific performance criteria to evaluate the model (West and Bhattacharya, 2016; Baesens, 2023). Analytic fraud models are commonly assessed using performance measures that evaluate the predictive performance. Notwithstanding, wrongly classifying claims has financial implications. Depending on the allocated budget for the fraud investigation process, wrongly classifying a fraudulent claim as legitimate can be considerably more expensive than the reverse. Consequently, it might be more appropriate to compare models in terms of their monetary performance (Baesens, 2023)."
        },
        {
            "heading": "3 Simulation engine",
            "text": "Our proposed simulation engine addresses one of the key challenges within fraud research. That is, the limited availability of publicly accessible data. In this section, we provide an in-depth overview of the data generation process and the architecture of the simulation engine. We outline the sequential steps taken to generate a realistic and representative insurance fraud network data set.\nThe resulting synthetic data set is structured in a tabular format, with each row representing a unique claim and its corresponding attributes. The columns in the data set capture items such as policyholder characteristics, traditional claim features, involved parties and social network features. These are the attributes typically used for fraud analytics. Further, for each claim we have two different types of labels. The first is the true label of the claim, indicating if it is fraudulent or not. This label is determined by the fraud generating model. The second type of label is the outcome of the fraud investigation, which can either take on the value fraudulent, non-fraudulent or uninvestigated. This variable is typically the one we have available\n10\nin insurance fraud data sets.\nArchitecture We generate a synthetic, tabular data set in seven consecutive steps (see Figure 2). We start by generating the policyholder characteristics (step 1). Hereafter, we simulate the contract-specific attributes per policyholder (step 2). We use the policyholder and contract-specific features as input for our data-generating claim frequency model and generate the number of claims per contract (step 3). Next, we simulate the individual claim amounts using a data-generating claim severity model (step 4). Similarly to step 3, we use the policyholder and contract-specific characteristics as input for the data-generating model. Subsequently, we combine all simulated claims and their characteristics into a tabular data set and we proceed with the observations that have at least one claim. In step 5, we generate the network structure of the claims by connecting each claim to different types of parties. Next, we engineer the social network features and generate the claim labels which represent the ground truth of the claim (i.e. fraudulent or non-fraudulent). We replicate the fraud investigation process in step 6. Hereby, we generate the label that is commonly available in fraud data sets (see Section 2). This label expresses whether the claim has been investigated for fraud and what the outcome of that investigation was. We conclude the synthetic data generation with step 7 where we merge all simulated data.\nThe simulation engine offers a range of customizable features. In all seven steps, several parameters can be adjusted. Moreover, it allows for dependencies between certain features. For example, we can specify a negative dependence between the age and the value of the car. Consequently, older cars will be characterized by a lower value. By allowing for dependencies between features, the synthetic data captures more realistic and nuanced relationships among variables and more closely mirrors real-world data sets. Following, we discuss the seven consecutive steps in detail. An extensive overview of the default configuration is described in Appendix A."
        },
        {
            "heading": "3.1 Policyholder and contract-specific characteristics",
            "text": "Prior to the synthetic data generation, the user can adjust several parameters that determine the characteristics of the synthetic data (see Appendix A for the default configuration). Hence, the user has full control over the data-generating mechanics. One of the adjustable parameters is the number of policyholders nph, which determines the size of the resulting data set. By default, nph = 10 000. We use i = (1, . . . , nph) as an index for the policyholders. In addition to nph, the user can also specify the total number of experts nexp, garages ngar, brokers nbro and other person(s) involved in the claim nper. These parameter values will govern the size of the social network.\nWe start the synthetic data generation by simulating the policyholder characteristics for nph policyholders (step 1 in Figure 2). Here, we generate features such as the age and gender of the policyholder and the number of contracts. We use NrContractsPHi to denote the number of contracts of policyholder i and use j = (1, . . . , NrContractsPHi) as an index for the contracts. Per policyholder, we also generate the number of years since the inception of the first contract and refer hereto as the exposure wi. By default, we set the average exposure to five years and the maximum to 20 years. Additionally, we simulate the contract-specific exposure wij . In the synthetic data set, we consolidate the multiple years of coverage into a single contract to simplify the data structure and analysis. That is, by default we allow wij > 1. Table 2 gives an overview of the different attributes that are generated. The first column in this table depicts the variable name, the second the variable type and the third column contains the feature description. The last column of Table 2 specifies which generator is used to simulate the feature values. For\n11\n12\n13\ncertain features, the user can specify the range of the feature values. When generating the data, we ensure that all simulated values fall within this prespecified range (see Appendix B). Hereby, we avoid generating implausible or invalid values. For the policyholder\u2019s age, for example, the default range is [18, 80]. Consequently, none of the policyholders will be younger than 18 (the legal driving age in many countries) or older than 80. Once all policyholder characteristics are generated, we proceed to simulate the contract-specific features such as the age of the car and the type of coverage (see Table 2).\nDependence structure The simulation engine allows to specify a dependency between different features. To generate the dependency, we rely on copulas (Denuit et al., 2005). In our simulation engine, we restrict ourselves to the bivariate Ali-Mikhail-Haq (AMH) (Kumar, 2010) and Frank copula (Denuit et al., 2005). We use \u03b8 to denote the parameter that controls the dependence.\nTable 3 presents an overview of the dependencies and the method used to incorporate them. Within insurance, we commonly have variables that are correlated (Goldburd et al., 2016). Consequently, by allowing for dependencies, we can create a more realistic data set. For example, in real life data sets we commonly observe that older cars are worth less compared to newer cars. In our engine, we incorporate this negative dependency between the age of the car and its value by using a Frank copula with \u03b8 = \u221225."
        },
        {
            "heading": "3.2 Claim frequency and claim severity",
            "text": "Next, we proceed to simulating the number of claims Nij for policyholder i on contract j and the individual claim costs Lijk. We use k = (1, . . . , Nij) as an index for the claims. Hereto, we employ the frequency-severity approach (Ohlsson and Johansson, 2010; Frees et al., 2014) where we model the claim frequency and claim severity separately. To simulate the number of claims and the claim costs as a function of the policyholder and contract-specific characteristics, we rely on the generalized linear model (GLM) framework (McCullagh and Nelder, 1999). We use a Poisson GLM with log link as the data-generating model for the number of claims (Ohlsson and Johansson, 2010; Quijano Xacur and Garrido, 2015)\nNij \u223c Poi(wij exp(cfx\u22a4ij\u03b2cf )). (11)\n14\nTo generate Nij , we take a random draw from Poi(wij exp(cfx \u22a4 ij\u03b2cf )), with cfxij the covariate vector and \u03b2cf is the corresponding parameter vector. The exposure wij of the contract is included as an offset term and the subscript cf stands for claim frequency. In our simulation engine, the user can specify which features should be included in cfxij and the features\u2019 effect size can be adjusted via \u03b2cf . As such, the user can control the relation between the Nij \u2019s and the policyholder and contract-specific characteristics (see Appendix D for the default specification of the claim frequency model).\nHereafter, we generate the claim-specific characteristics (see Table 2). For example, we simulate the duration in months since the beginning of the contract until the date of the incident. Hereby, we create the claim-specific information that is typically available in fraud insurance data sets and that is used in fraud detection models (see, for example, O\u0301skarsdo\u0301ttir et al. (2022)).\nNext, we proceed with generating the cost Lijk of claim k under contract j of policyholder i. The data-generating model for the claim amounts Lijk is driven by a gamma GLM with log link\nLijk \u223c G(\u03b1, \u03b1/ exp(x\u22a4ij\u03b2 +Nij\u03b6)) (12)\nwhere G denotes the gamma1 distribution and \u03b1 the shape parameter, which we set to 0.25. The subscript cs stands for claim severity and the parameter \u03b6 controls the dependency between the claim frequency and claim severity (Frees et al., 2011; Garrido et al., 2016). Within the frequency-severity approach, we commonly assume that \u03b6 = 0 (i.e. the claim frequency and claim severity are independent). We specify 50 as a lower limit for Lijk to prevent generating implausible low claim amounts. Consequently, when Lijk < 50 we replace it with a randomly drawn value from U(50, 150) to ensure that a low yet realistic claim amount is generated. As with the data-generating claim frequency model (see equation (11)), we can specify which features are included in csxij as well as their effect size via \u03b2cs (see Appendix D for the default model specification)."
        },
        {
            "heading": "3.3 Constructing the social network structure and simulating fraudulent claims",
            "text": "Our next objective is to generate the social network structure that links claims to parties and to other claims. Within motor insurance each claim is linked to a policyholder and a garage. Other parties involved in the claim may include brokers and persons other than the policyholder. Experts are involved in the process only when the claim amount exceeds a certain threshold (KBC Brussels, n.d.). Insurance companies commonly handle minor losses without the involvement of an expert to inspect the damage or injury. Our goal is to enhance the simulated claims with a network structure similar to the one depicted in Figure 3(a). In this figure, the circles depict claims and the rectangles parties.\nTo accomplish this, we create a set Ap for each party type, such as the set of garages Ag, brokers Ab, experts Ae, and other persons Ao. These sets represent the specific parties of each type within the larger set of all possible parties, denoted as P = Ag \u222a Ab \u222a Ae \u222a Ao. The size of a specific set Ap is determined by the corresponding user-specified parameter (see Section 3.1 and Appendix A). For example, if the number of garages ngar is set to 150, the simulation engine will create a set Ag of 150 unique garages. For each claim, we then randomly select one (or multiple when we connect the claim to other persons, see Table 2) member from Ap to link the claim to a specific party. By repeating this procedure for each type of party, we create a social network\n1For the gamma distribution, we use the parameterization with the density function f(x) = \u03c4\u03b1x\u03b1\u22121 exp(\u2212\u03c4x)/\u0393(\u03b1) where \u03c4i = \u03b1/ exp(x\u22a4ij\u03b2 +Nij\u03b6) and \u0393(\u00b7) denotes the gamma function.\n15\nstructure where every claim is connected to different (types of) parties (see Figure 3(a)). As a rule, we do not link the claim to an expert when Lijk < 250 (KBC Brussels, n.d.).\nNext, we proceed with generating the claim label. The data-generating fraud model is a logistic regression model\nYijk \u223c Bern (\u03c0ijk) and \u03c0ijk = e0\u03b2f+fx\n\u22a4 ijk\u03b2f\n1 + e0\u03b2f+fx \u22a4 ijk\u03b2f\n. (13)\nHere, Bern denotes a Bernoulli distribution and Yijk is a binary variable indicating if the k th claim of the jth contract of policyholder i is fraudulent (Yijk = 1) or not (Yijk = 0). The subscript f stands for fraud and 0\u03b2f is the intercept term. The relation between the fraud label and the features is adjusted via the covariate vector fxijk and the parameter vector \u03b2f (see Appendix E for the default specification).\nWe generate the claim labels in an iterative manner and this process is visualized in Figure 3. In this figure, the label of the claims is color-coded. Gray stands for unlabeled, red for fraudulent and green for non-fraudulent. Panel (a) represents the network at initialization, when all claims are unlabeled. We have no fraud-related information at this point and hence, no values for the social network features that rely on this information (e.g., the ratio of known fraudulent claims in the second order neighborhood). Consequently, at initialization, we remove all fraud-score and neighborhood based features (see Table 1) from fxijk and \u03b2f in (13). Next, we take a random subset, equal in size to 1% for example, of all simulated claims. By deliberately taking a small subset of the data, we ensure that only a limited proportion of the claim labels is generated without effect of the fraud-score and neighborhood based features. In Figure 3(a), this subset consists of claims C1, C2 and C3. To generate the claim labels, we take a random draw from Bern(\u03c0ijk) (see (13)). As such, we generate our first set of labeled claims (see\n16\nFigure 3(b)). This enables us to compute the values for the fraud-score and neighborhood based features. Consequently, from here on out, we include these features in fxijk and \u03b2f . To generate the labels of the remaining claims, we again take a random subset of unlabeled claims. In Figure 3(b), this subset corresponds to claims C5 and C6. The size of this random subset can be set by the user. By default, this is equal to 10% of all simulated claims. We combine this subset with the unlabeled claims in the 2nd order neighborhood of the fraudulent claims in the previous iteration (i.e. C4 in Figure 3(b)). In doing so, we ensure that every subset includes unlabeled claims that are connected to fraudulent claims and that we propagate fraud through the network. We engineer the social network features for all claims in the subset and we take random draws from Bernoulli(\u03c0ijk) to generate the claim labels (Figure 3(c)).\nAlgorithm 2 is a generalization of the process illustrated in Figure 3. We use this iterative algorithm to simulate the claim labels Yijk and each iteration consists of three steps. First, we take a random subset of the unlabeled claims and we combine this subset with all unlabeled claims in the 2nd order neighborhood of the fraudulent claims in the previous iteration. Second, we engineer the social network features for all claims in the subset. Third, we take random draws from Bernoulli(\u03c0ijk) to generate the claim labels (Figure 3(c)). This concludes one iteration and we repeat the algorithm until all claims are labeled.\nAlgorithm 2: Iterative algorithm to simulate the claim labels\nModel: Yijk \u223c Bern(\u03c0ijk) Initialization: Remove fraud-score and neighborhood based features from (fxijk,\u03b2f ) in the first iteration and generate the initial claim labels using (13) repeat\n1 Take a subset of the simulated database: a random sample of unlabeled claims\ncombined with the unlabeled claims in 2nd order neighborhood of fraudulent claims in the previous iteration;\n2 Construct the social network features for the claims in this subset; 3 Generate the claim label using the data-generating logistic regression model in\n(13);\nuntil all claims are labeled ;\nThe user can specify which features are included in fxijk and determine their effect size in \u03b2f . Consequently, the user has the flexibility to activate or deactivate specific feature effects and to control their strength. By including social network features in fxijk and via the specified effect size in \u03b2f , for example, we determine to which extent the network exhibits patterns of homophily. The greater the corresponding effect size in \u03b2f , the more densely connected fraudulent claims will be. Conversely, we can turn off the social network effect by omitting the social network features from fxijk. Further, we can set the desired level of class imbalance. Hereto, our simulation engine determines which value for 0\u03b2f results in the target class imbalance (see Appendix E for detailed information)."
        },
        {
            "heading": "3.4 Replicating the expert-based fraud detection approach",
            "text": "In a real life fraud data set, we typically have historical, labeled data that is the result of an investigation by a fraud expert (see Section 2.1). In our simulation engine, we replicate the two steps of this fraud detection approach to obtain these labels. First, we flag claims as suspicious based on a set of business rules which can be defined by the user. Hence, an alert will be triggered for claims that meet the criteria outlined in the business rules. By default, we flag claim k under\n17\ncontract j of policyholder i as suspicious if it satisfies one of the following criteria: a) the claim is filed within one year of the most recent claim (i.e. ClaimDateijk \u2212 ClaimDateij(k\u22121) \u2a7d 1); b) the individual claim amount Lijk > 75% of ValueCarijk or c) the cumulative claim amount\u2211k\nl=1 Lijl > 200% of ValueCarijk. In reality, these claims are passed to an expert who performs an in-depth investigation. Following the investigation, the expert judgement determines whether the claim is legitimate or not. We simulate the expert judgement in the second step as follows. For a claim that is flagged by the business rules in step one, we first look at its ground truth label Yijk. If Yijk = non-fraudulent, we take a random draw from Y expert ijk \u223c Bern(0.01). Hence, when the claim is legitimate, we have a 99% probability that the expert will label the claim as non-fraudulent. Conversely, if Yijk = fraudulent, we randomly draw from Y expert ijk \u223c Bern(0.99). Thus, for fraudulent claims, there is a 99% probability that the expert will classify them as fraudulent as well. Further, claims that are not flagged by the business rules obtain the label uninvestigated. Hereby, we create all three labels that are typically available in an insurance fraud data set: non-fraudulent, fraudulent or uninvestigated. By following the procedure as outlined above, we acknowledge and reflect the inherent missing information and uncertainties that exist in real-life data. That is, the expert-based approach is not entirely infallible (Baesens et al., 2015). Claims that are judged to be non-fraudulent by the investigation may in reality be fraudulent and vice versa. In addition, we acknowledge and replicate the phenomenon of having a substantial proportion of uninvestigated claims that are unlabeled."
        },
        {
            "heading": "4 Generating synthetic fraud network data: illustrations",
            "text": "In this section, we illustrate the capabilities of our simulation engine. We specifically highlight the impact of social network features on the resulting synthetic data sets. Hereto, we generate and analyze two different types of data sets. One where we include a moderately strong social network effect and one where we exclude it. Additionally, we provide an illustrative example of the construction and evaluation of a fraud detection model using a synthetically generated data set. We explore to which extent the constructed model is able to identify fraudulent claims that are not investigated and labeled by the expert."
        },
        {
            "heading": "4.1 The impact of social network features on the synthetic data",
            "text": "We generate two different types of data sets. In the first type of data set we introduce a moderately strong social network effect in the claim label generation (see Section 3.3). We denote this type of data set as DNetwork. Table 4 depicts the specification of the effect sizes used in the simulation of DNetwork. We include various types of features to generate a realistic and representative synthetic data set. These features encompass the policyholder, claim-specific, and social network characteristics. In order to replicate the social dynamics of fraud, we assign a strong effect size for the social network features n1.size, n2.size and n2.ratioFraud. Hereby, we create a synthetic data set where the network structure exhibits patterns of homophily. Conversely, in the second type of data set DNon\u2212network, we exclude all network-related features from the data-generating fraud model (see Table 4). As such, we create a data set where fraud is not influenced by social interactions or network dynamics. The claim label generation is solely driven by policyholder and claim-specific characteristics. The selected set of policyholder and claim-specific features is identical in DNetwork and DNon\u2212network, as well as the effect sizes of these features (see Table 4).\nFor both types of data sets, the number of policyholders is set to 200 000 and the target class imbalance (i.e. the ratio of the number of fraudulent claims to the total number of claims) to 2%.\n18\nAll other settings remain at their default values (see Appendix A). We generate 100 data sets of each type and analyze the distribution of the claim labels across these simulated data sets. We calculate the frequency and relative frequency for each category of Yijk (i.e., fraudulent and non-fraudulent) and Y\nexpert ijk (i.e., fraudulent, non-fraudulent, and uninvestigated) in\neach data set. The average, minimum, and maximum values for both the frequency and relative frequency are computed and presented in Table 5. In all synthetic data sets, the empirical class imbalance is nearly identical to the target class imbalance. The minimum class imbalance in DNetwork is 1.97% and the maximum 2.06%. In DNon\u2212network, the minimum is 1.98% and the maximum is 2.04%. The class imbalance is also reflected in the expert judgement. Only a small fraction of claims are subjected to investigation (approximately 9%), and among those investigated, only a minority are found to be fraudulent. Further, the empirical distribution of both Yijk and Y expert ijk are similar across all simulated data sets.\nEmpirical distribution of the features Figures 4 and 5 present the empirical distribution of the features included in the data-generating fraud models (see Table 4) of one synthetically generated data set. Figure 4 displays the features\u2019 empirical distribution in a simulated data set DNetwork. Figure 5 shows this in a synthetic data set DNon\u2212network. The empirical distribution of policyholder and claim-specific features is different across fraudulent and non-fraudulent claims in both types of data sets. For example, fraudulent claims are mostly associated with younger policyholders (top left plot on Figures 4 and 5). Further, in DNetwork, the difference in the empirical distribution between fraudulent and non-fraudulent claims is also present for the social network features n1.size, n2.size and n2.ratioFraud. This suggests that the claim labels are linked to these features in DNetwork. In contrast, the empirical distributions of the social network features do not differ in DNon\u2212network, indicating that there is no association between these features and the claim label.\nHomophily Figure 6 illustrates the dyadicity D and heterophilicity H observed in the simulated data sets (see Section 2.2). In DNetwork, the fraudulent claims are more densely connected to each other compared to what we expect by chance (D > 1). In addition, fraudulent claims have fewer connections to non-fraudulent claims relative to what we expect by chance (H < 1). In comparison, we observe no patterns of homophily in DNon\u2212network. Both the dyadicity (D \u2248 1) and heterophilicity (H \u2248 1) correspond to values indicative of a random network configuration.\n20\nEffect size of the features Next, we estimate the coefficient vector \u03b2f in each synthetic data set. We fit the following logistic regression model\nlogit(E[Yijk]) = 0\u03b2f + 1\u03b2fAgePHi + 2\u03b2fNrContractsPHij + 3\u03b2fClaimAmountijk\n+ 4\u03b2fClaimAgeijk + 5\u03b2fn1.sizeijk + 6\u03b2fn2.sizeijk\n+ 7\u03b2fn2.ratioFraudijk.\n(14)\nwhere i refers to the policyholder, j to the contract and k to the claim. This model is the same as the data-generating fraud model (see Table 4). Figure 7 depicts the empirical distribution of the estimated coefficient vector \u03b2\u0302 across the 100 simulated data sets. Panel (a) shows the estimates obtained from DNetwork and panel (b) from DNon\u2212network. In both types of data sets, we observe some minor deviations from the specified effect size for most features, reflecting sampling variability. Further, the variability of the estimates is relatively small. Hence, we are able to accurately replicate the specified effect size for the different features, with only minor deviations due to sampling variability. The deviation from the specified effect size and variability, however, is substantially larger for the social network feature n2.ratioFraud. This feature represents the proportion of fraudulent claims in a claim\u2019s second order neighborhood. The estimated effect size of n2.ratioFraud is lower than its value as specified in \u03b2f . This is most likely attributable to the iterative growth in the number of fraudulent claims (see Algorithm 2), leading to a deviation in the estimated effect size from the originally specified value. In the first iterations, there are only a few instances of fraudulent claims. Hence, most of the unlabeled claims will have similar values for n2.ratioFraud. As the number of iterations increases, there will be a progressive increase in the proportion of fraudulent claims (see Appendix F). Accordingly, there will be more distinct feature values for n2.ratioFraud. Thus, the empirical distribution of n2.ratioFraud alters with each iteration."
        },
        {
            "heading": "4.2 Exploring the capabilities of the simulation engine: evaluating a fraud detection model\u2019s effectiveness",
            "text": "In this section, we illustrate the development and validation of a fraud detection model using a supervised learning technique (see Section 2). We proceed with the 100 synthetic data sets DNetwork. In each simulated data set we construct a fraud detection model by fitting a logistic regression model to the investigated claims (i.e. those that are investigated and labeled by the expert, see Section 3.4). We rely on logistic regression given its robustness to imbalanced class sizes (Oommen et al., 2011; Marques et al., 2013; van den Goorbergh et al., 2022). Table 5 illustrates that said imbalance is present in each synthetic data set. To examine the added value of social network analytics when a network effect is present, we define two distinct model specifications. For model 1, we only include policyholder and claim-specific features\nlogit(E[Yijk]) = 0\u03b2f + 1\u03b2fAgePHi + 2\u03b2fNrContractsPHij + 3\u03b2fClaimAmountijk\n+ 4\u03b2fClaimAgeijk. (15)\nNext, we extend model 1 by incorporating social network features as well, resulting in model 2\nlogit(E[Yijk]) = 0\u03b2f + 1\u03b2fAgePHi + 2\u03b2fNrContractsPHij + 3\u03b2fClaimAmountijk\n+ 4\u03b2fClaimAgeijk + 5\u03b2fn1.sizeijk + 6\u03b2fn2.sizeijk\n+ 7\u03b2fn2.ratioFraudijk.\n(16)\nTo assess the predictive performance of the fraud detection models, we rely on the area under the receiver operating characteristic curve (AUC) (Hanley and McNeil, 1982) and the top decile\n22\nlift (TDL) (Lemmens and Croux, 2006). The AUC measures how well the model differentiates between fraudulent and non-fraudulent claims. An AUC of 0.5 corresponds to a random model and a perfect model has an AUC of 1. The TDL measures the extent to which a model surpasses a random model in detecting fraudulent claims. We calculate the TDL by dividing the proportion of fraudulent claims among the top 10% of claims with the highest predicted probability by the relative frequency of fraudulent claims in the data set. The TDL of a random model is equal 1. The higher the TDL, the better the model performance.\nIn each synthetic data set, we examine the in- and out-of-sample predictive performance of the fitted model. Hereto, we use the model fit to compute the probability of fraud for claims in the\n23\nin- and out-of-sample data set\n\u03c0ijk = e0\u03b2\u0302f+fx\n\u22a4 ijk\u03b2\u0302f\n1 + e0\u03b2\u0302f+fx \u22a4 ijk\u03b2\u0302f\n. (17)\nThe in-sample data set consists of the investigated claims (approximately 9% of all claims are investigated, see Table 5). Here, we use the labels of Y\nexpert ijk as outcome when computing the\nperformance measures. The out-of-sample data set contains all uninvestigated claims. In our synthetic data set, we have the advantage of having access to the ground truth label Yijk of the uninvestigated claims, which is not available in real-life data sets. We calculate the out-ofsample AUC and TDL using Yijk. As such, we evaluate to which extent our model is able to generalize and detect fraud in the unlabeled claims.\nFigure 8 depicts the in- and out-of-sample predictive performance of model 1 and model 2. In terms of AUC and TDL, model 2 consistently outperforms model 1 in both the in- and out-of-sample evaluations. Consequently, by incorporating social network features in addition to the traditional claim characteristics, we enhance the model\u2019s ability to identify fraudulent claims. Furthermore, the TDL of model 1 approaches one in all simulated data sets, indicating that the model performs no better than random chance in identifying fraudulent claims within the top 10% of predicted probabilities. In comparison, the TDL of model 2 is substantially larger than one. Model 2 also retains its predictive performance on the out-of-sample data sets. Hence, by training the model on the investigated claims, we can effectively capture the distinct patterns exhibited by fraudulent claims. One seemingly contradictory finding, however, is that the out-of-sample AUCs are higher than the in-sample AUCs. This discrepancy in performance is likely due to the different labels used for model evaluation. For the in-sample comparison, we rely on the expert judgment labels Y\nexpert ijk . Conversely, for the out-of-sample comparison we\nuse the ground-truth labels Yijk. This variation in label sources may contribute to the observed differences in model performance. In addition, the in-sample data sets are 10 times smaller than the the out-of-sample data sets. Consequently, the in-sample data sets exhibit more variability. Further, a small number of the investigated claims will be false positives or false negatives (see Section 3.4). When we fit the models with the ground truth-label Yijk instead of Y expert ijk , the in-sample performance is higher compared to the out-of-sample performance (see Appendix G)."
        },
        {
            "heading": "5 Discussion",
            "text": "In this paper, we present a powerful and flexible toolbox to generate synthetic insurance fraud network data. The simulation engine consists of seven consecutive steps which enable us to generate a complete and complex data set. The engine generates policyholder characteristics, contract-specific features, the number of claims and individual claim costs, and the claim labels (fraudulent or non-fraudulent). To ensure that the simulated data accurately reflects the realworld scenario, the fraud investigation process is also replicated. The generated data from each step is combined to produce a final synthetic database that can be used for various purposes. In generating the synthetic data, the user has control over various data-generating mechanisms.\nThe simulation engine can produce diverse scenarios to meet different research needs. We showcase this ability by generating two distinct types of data sets, one where the social network effect is present during the claim label generation and one where it is absent. Our results highlight the toolbox\u2019s capability to simulate synthetic data according to the user-defined parameters. Our simulation engine accurately generates the desired class imbalance as well as the specified effect sizes of the covariates (including the social network features). As such, we are able to generate data sets that closely mirror real-life insurance fraud data sets in motor insurance.\n24\nResearchers can utilize our simulation engine to conduct benchmark studies, aimed at addressing (methodological) challenges posed by insurance fraud. For instance, future research can focus on the evaluation of sampling techniques to handle the high class imbalance and the performance of learning methods in combination with said sampling techniques."
        },
        {
            "heading": "Acknowledgments",
            "text": "Katrien Antonio gratefully acknowledges funding from the FWO and Fonds de la Recherche Scientifique - FNRS (F.R.S.-FNRS) under the Excellence of Science (EOS) programme, project ASTeRISK Research Foundation Flanders [grant number 40007517], from the Chaire DIALog by CNP Assurances and the FWO network W001021N. The authors gratefully acknowledge support from the Ageas research chair on insurance analytics at KU Leuven. Additionally, the authors would like to thank Misja Langeler for the assistance provided during the initial stages of the simulation engine."
        },
        {
            "heading": "A Default configuration of the simulation engine",
            "text": "The default settings for the database, policyholder, contract-specific and claim characteristics are given in Table 6. The default data-generating claim frequency and claim severity models are given in Appendix D. In Appendix E, we specify the default data-generating fraud model.\nWe define the level of class imbalance as the ratio of the number of fraudulent claims to the total number of claims. Further, ExcludeParties is a parameter that allows to exclude certain types of parties from the network. We exclude the expert by default.\ni\nii"
        },
        {
            "heading": "B Limiting the range of feature values",
            "text": "The default range for AgePH is [18, 80]. Values generated outside of this range are redistributed among the integer values falling inside the range, proportional to the frequency of the values within this range. Hereafter, we take a random draw from U(0, 1) and add this value to the integer to obtain a numeric value.\nWe specify [0, 20] as the default range for ExpPH. Furthermore, AgePH - ExpPH cannot be smaller than the user-specified minimum for AgePH. This would imply that the contract started before the policyholder is legal age of driving. Hereto, we define MaxExpi = AgePHi - MinAge. For values outside the prespecified range, we redraw a value from U(MinExp, MaxExpi).\nWe define [1, 5] as default range for NrContractsPH. Values outside this range are rounded to the closest boundary."
        },
        {
            "heading": "C Simulating type of coverage",
            "text": "The type of coverage is a nominal variable with three levels. We rely on a multinomial regression model to generate the type of coverage as a function of ValueCar, AgeCar and AgePH. The general form of the multinomial logistic regression model (Agresti, 2013) is\nlog\n( \u03c0j(xi)\n\u03c0J(xi)\n) = x\u22a4i \u03b2j , j = (1, . . . , J \u2212 1),\nwhere \u03c0j(xi) = P (Coveragei = j|xi) denotes the probability that Coveragei equals category j. Coveragei denotes the response variable\u2019s value for observation i and here, we use j = (1, . . . , J) as an index for the categories of the response variable. We use category J as reference category. xi denotes the covariate vector and \u03b2j is the parameter vector for category j. For notational\nsimplicity, we assume that xi is fixed for all categories j = (1, . . . , J\u22121). Further, \u2211J\nj=1 \u03c0j(xi) = 1 \u2200 i \u2208 (1, . . . , N) where N denotes the total number of observations.\nThe category-specific probability for category j = (1, . . . , J \u2212 1) is calculated as\n\u03c0j(xi) = ex\n\u22a4 i \u03b2j 1 + \u2211J\u22121\nh=1 e x\u22a4i \u03b2h\nand we calculate this probability for reference category J as\n\u03c0J(xi) = 1 1 + \u2211J\u22121\nh=1 e x\u22a4i \u03b2h\n.\nIn our simulation engine, Coveragei \u2208 (TPL, PO, FO) and we define\n\u03b2TPL = (log(0.50), log(1.25), log(0.25)),\n\u03b2PO = (log(1.25), log(0.75), log(1.05)), \u03b2FO = (log(1.50), log(0.75), log(1.25)).\n(18)\nThe covariate vector xi consists of the normalized values for the value of the car, age of the car and age of the policyholder. Given a variable a = (a1, . . . , ai, . . . , aN ), we normalize in [\u22121, 1] using\n2 (a\u2212min(a))\nmax(a)\u2212min(a) \u2212 1. (19)\niii\nHereafter, we calculate the probabilities (\u03c0TPL(xi), \u03c0PO(xi), \u03c0FO(xi)) for all observations. We generate values for the type of coverage by taking random draws from Multinomial(1, \u03c0TPL, \u03c0PO, \u03c0FO).\nUsing the default values (see equation (18)), the probability of signing up for a full omnium is larger for expensive, relatively new cars and older policyholders. Similarly, the probability of taking out a partial omnium is higher for expensive, relatively new cars but here the effect of age is less strong. Young policyholders with an inexpensive, older car have a higher probability to take out a policy with only third party liability."
        },
        {
            "heading": "D Claim frequency and claim severity model",
            "text": "Both the claim frequency and claim severity model are based on the results in Henckaerts et al. (2018). In this paper, the authors fit a claim frequency and claim severity model on a motor insurance portfolio from a Belgian insurer. Further, (Henckaerts et al., 2018) used a data-driven method to bin the continuous variables AgePH, AgeCar and BonusMalus into categorical variables. These bins are given in Table 7. We denote these binned versions as AgePHBin, AgeCarBin and BonusMalusBin. By default, we use these binned versions in the data-generating claim frequency and claim severity model (see Table 8)."
        },
        {
            "heading": "E Data generating fraud model and class imbalance",
            "text": "Table 9 depicts the default specification of the data-generating fraud model. The column names indicate which features are included, while the values represent the corresponding value in \u03b2f . Further, in the data-generating model we use the normalized version of the features ClaimAmount, ClaimAge, n1.size, n2.size, AgePH and n2.ratioFraud (see (19)). Hereby, we bring all features to the same scale. This ensures that the features\u2019 effect sizes, as specified in \u03b2f , are comparable. Furthermore, at the end of every iteration in Algorithm 2, we normalize both n2.ratioFraud and n2.ratioNonFraud. We do so since the network grows with every step in the algorithm. By normalizing these features, we aim to mitigate the influence of fluctuating values across iterations (also see Appendix F).\nFurther, the simulation engine allows us to specify the desired level of class imbalance pt. We achieve this by employing the following approach in the third step of Algorithm 2, where we\nv\ngenerate the claim labels\nYijk \u223c Bern (\u03c0ijk) and \u03c0ijk = e0\u03b2f+fx\n\u22a4 ijk\u03b2f\n1 + e0\u03b2f+fx \u22a4 ijk\u03b2f\n. (20)\nBefore generating Yijk, we set a seed for the random number generator to ensure reproducibility. We achieve the desired level of imbalance pt by optimizing\nmin 0\u03b2f |pt \u2212 ap| (21)\nwhere\nap =\n\u2211 i,j,k I(Yijk = fraudulent)\u2211\ni,j,k I(Yijk = fraudulent OR Yijk = non-fraudulent) (22)\ndenotes the actual level of class imbalance in the synthetic data set (using all available claim labels). Here, I(\u00b7) represents the indicator function."
        },
        {
            "heading": "F Distribution values n2.ratioFraud",
            "text": "Figure 9 depicts the features values of n2.ratioFraud across the different iterations of Algorithm 2 when generating the claim labels in a synthetic data set. The horizontal axis depicts the iteration and the vertical axis the feature values. Per iteration, we show the empirical distribution of n2.ratioFraud in the random subset (see Algorithm 2). In the first iterations, we have a small number of fraudulent claims. As a consequence, most observations have similar feature values for n2.ratioFraud. The scarcity of distinct values is evident from the compactness of the violin plots. With each iteration, the number of fraudulent claims grows, resulting in an increase in distinct values for n2.ratioFraud. In Figure 9, this is reflected by the increase in width of the violin plots.\nvi"
        },
        {
            "heading": "G Predictive performance in the synthetic data sets",
            "text": "To obtain insights into the results in Section 4, we first fit the following model to the investigated claims\nlogit(E[Yijk]) = 0\u03b2f + 1\u03b2fAgePHi + 2\u03b2fNrContractsPHij + 3\u03b2fClaimAmountijk\n+ 4\u03b2fClaimAgeijk + 5\u03b2fn1.sizeijk + 6\u03b2fn2.sizeijk\n+ 7\u03b2fn2.ratioFraudijk.\n(23)\nHence, here we use the ground-truth Yijk instead of the expert judgement Y expert ijk as the response variable. Hereafter, we examine the performance on the investigated (i.e. the in-sample data set) and uninvestigated (i.e. the out-of-sample data set) claims. Figure 10 depicts the performance on the in- and out-of-sample data sets. Both the AUC and TDL indicate that the fitted models are substantially better than a random model. In addition, compared to the in-sample data sets, the performance is slightly lower on the out-of-sample data sets. Hence, the model is able to capture the underlying relationships between the predictors and the target variable.\nvii"
        }
    ],
    "title": "An engine to simulate insurance fraud network data",
    "year": 2023
}