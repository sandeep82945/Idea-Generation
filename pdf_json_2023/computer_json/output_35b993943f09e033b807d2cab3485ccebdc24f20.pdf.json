{
    "abstractText": "Department of Computer Science and Engineering, Prasad V Potluri Siddhartha Institute of Technology, Vijayawada, Andhra Pradesh 520007, India Department of Computer Science and Engineering, Dhanekula Institute of Engineering and Technology, Vijayawada, Andhra Pradesh 521139, India Department of Computer Science, College of Computer Sciences and Information Technology, King Faisal University, Al-Ahsa 31982, Saudi Arabia Department of Management Information Systems, College of Business Administration, King Faisal University, Al-Ahsa 31982, Saudi Arabia Department of Information Systems\u2014College of Computer and Information Science, King Saud University, Riyadh, Saudi Arabia",
    "authors": [
        {
            "affiliations": [],
            "name": "Parvathaneni Naga Srinivasu"
        },
        {
            "affiliations": [],
            "name": "Balamurali Krishna"
        },
        {
            "affiliations": [],
            "name": "Shakeel Ahmed"
        },
        {
            "affiliations": [],
            "name": "Naif Almusallam"
        },
        {
            "affiliations": [],
            "name": "Fawaz Khaled Alarfaj"
        },
        {
            "affiliations": [],
            "name": "Nasser Allheeib"
        }
    ],
    "id": "SP:fce51a5247b63c534f0e740952364a9deb2e0965",
    "references": [
        {
            "authors": [
                "R. Vaga",
                "K. Bryant"
            ],
            "title": "Recent advances in x-ray technology",
            "venue": "Proceedings of the 2016 Pan Pacifc Microelectronics Symposium (Pan Pacifc), pp. 1\u201310, Big Island, Kohala Coast, Hawaii, USA, January 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S. Ranga Swamy",
                "S. Phani Praveen",
                "S. Ahmed",
                "P. Naga Srinivasu",
                "A. Alhumam"
            ],
            "title": "Multi-features disease analysis based smart diagnosis for covid-19",
            "venue": "Computer Systems Science and Engineering, vol. 45, no. 1, pp. 869\u2013886, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "M.K.S. Venkatesan",
                "B.M. Jenefer"
            ],
            "title": "Computed tomography scan simulation techniques: a survey",
            "venue": "Proceedings of the 2017 Fourth International Conference on Signal Processing, Communication and Networking (ICSCN), pp. 1\u20135, Chennai, India, March 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Sachdeva",
                "V. Kumar",
                "I. Gupta",
                "N. Khandelwal",
                "C.K. Ahuja"
            ],
            "title": "A novel content-based active contour model for brain tumor segmentation",
            "venue": "Magnetic Resonance Imaging, vol. 30, no. 5, pp. 694\u2013715, 2012. Table 5: Impact of the brain tumor concerning various approaches. Tumor core Whole tumor Enhanced tumor HARIS 2.87221 3.88981 3.011942 CNN 2.77638 3.79623 3.110214 SLNS 2.86786 3.80223 3.082932 SLNS with LSTM 2.89383 3.87081 3.105427 Journal of Healthcare Engineering 15",
            "year": 2012
        },
        {
            "authors": [
                "S.N.S.H. Chittajallu",
                "A. Richhariya",
                "K.M. Tse",
                "V. Chinthapenta"
            ],
            "title": "A review on damage and rupture modelling for soft tissues",
            "venue": "Bioengineering, vol. 9, no. 1, p. 26, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "T Pereiro-Brea",
                "A. Golpe-G\u00f3mez",
                "A.M. Golpe-S\u00e1nchez"
            ],
            "title": "Usefulness of Positron emission tomography in the examination of hilar andmediastinal lymphadenopathies in patients with suspicion of lung cancer",
            "venue": "Canadian Respiratory Journal, vol. 2020, Article ID 7909543, 6 pages, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "B. Han",
                "R. Jhaveri",
                "H. Wang",
                "D. Qiao",
                "J. Du"
            ],
            "title": "Application of robust zero-watermarking scheme based on federated learning for securing the healthcare data",
            "venue": "IEEE Journal of Biomedical and Health Informatics, p. 1, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Dogra",
                "C.K. Ahuja",
                "S. Kumar"
            ],
            "title": "A multi-modality paradigm for CT and MRI fusion with applications of quantum image processing",
            "venue": "Concurrency and Computation: Practice and Experience, vol. 34, no. 20, Article ID e6610, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "B. Goyal",
                "A. Dogra",
                "R. Khoond",
                "F. Al-Turjman"
            ],
            "title": "An efcient medical assistive diagnostic algorithm for visualisation of structural and tissue details in CTand MRI fusion",
            "venue": "Cogn Comput, vol. 13, no. 6, pp. 1471\u20131483, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "K. Abhilasha",
                "S. Swati",
                "M. Kumar"
            ],
            "title": "Brain tumor classifcation using modifed AlexNet network",
            "venue": "Advances in Distributed Computing and Machine Learning. Lecture Notes in Networks and Systems, R. R. Rout, S. K. Ghosh, P. K. Jana, A. K. Tripathy, J. P. Sahoo, and KC. Li, Eds., vol. 427, Singapore, Springer, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Zhu",
                "S. Lu",
                "S.H. Wang",
                "J.M. Gorriz",
                "Y.D. Zhang"
            ],
            "title": "DSNN: a DenseNet-based SNN for explainable brain disease classifcation",
            "venue": "Frontiers in Systems Neuroscience, vol. 16, Article ID 838822, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A. Younis",
                "Li Qiang",
                "C.O. Nyatega",
                "M.J. Adamu",
                "H.B. Kawuwa"
            ],
            "title": "Brain tumor analysis using deep learning and VGG-16 ensembling learning approaches",
            "venue": "Applied Sciences, vol. 12, no. 14, p. 7282, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M.B. Sahaai",
                "G.R. Jothilakshmi",
                "D. Ravikumar",
                "R. Prasath",
                "S. Singh"
            ],
            "title": "ResNet-50 based deep neural network using transfer learning for brain tumor classifcation",
            "venue": "AIP Conference Proceedings, vol. 2463, Article ID 020014, 2022.",
            "year": 2001
        },
        {
            "authors": [
                "T.H. Arfan",
                "M. Hayaty",
                "A. Hadinegoro"
            ],
            "title": "Classifcation of brain tumours types based on MRI images using mobilenet",
            "venue": "Proceedings of the 2021 2nd International Conference on Innovative and Creative Information Technology (ICITech), pp. 69\u201373, Salatiga, Indonesia, September 2021.",
            "year": 2021
        },
        {
            "authors": [
                "I. Mehidi",
                "D.E. Chouaib Belkhiat",
                "D. Jabri"
            ],
            "title": "An improved clusteringmethod based on K-means algorithm forMRI brain tumor segmentation",
            "venue": "Proceedings of the 6th International Conference on Image and Signal Processing and their Applications (ISPA), pp. 1\u20136, Mostaganem, Algeria, November 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Chen",
                "H. Zhang",
                "D. Pi",
                "M. Kantardzic",
                "Q. Yin",
                "X. Liu"
            ],
            "title": "A weight possibilistic fuzzy C-means clustering algorithm",
            "venue": "Scientifc Programming, vol. 2021, Article ID 9965813, 10 pages, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y.K. Dubey",
                "M.M. Mushrif"
            ],
            "title": "FCM clustering algorithms for segmentation of brain MR images",
            "venue": "Advances in Fuzzy Systems, vol. 2016, Article ID 3406406, 14 pages, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "N.B. Bahadure",
                "A.K. Ray",
                "H.P. Tethi"
            ],
            "title": "Comparative approach of MRI-based brain tumor segmentation and classifcation using genetic algorithm",
            "venue": "Journal of Digital Imaging, vol. 31, no. 4, pp. 477\u2013489, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "P. Naga Srinivasu",
                "V.E. Balas",
                "N. Norwawi"
            ],
            "title": "Performance measurement of various hybridized kernels for noise normalization and enhancement in high-resolution MR images",
            "venue": "Bio-inspired Neurocomputing. Studies in Computational Intelligence, A. Bhoi, P. Mallick, CM. Liu, and V. Balas, Eds., vol. 903, Singapore, Springer, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "G.C. Lin",
                "W.J. Wang",
                "C.C. Kang",
                "C.M. Wang"
            ],
            "title": "Multispectral MR images segmentation based on fuzzy knowledge and modifed seeded region growing",
            "venue": "Magnetic Resonance Imaging, vol. 30, no. 2, pp. 230\u2013246, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "A.H. Abdel-Gawad",
                "L.A. Said",
                "A.G. Radwan"
            ],
            "title": "Optimized edge detection technique for brain tumor detection in MR images",
            "venue": "IEEE Access, vol. 8, pp. 136243\u2013136259, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S.P. Naga",
                "T. Rao",
                "V. Balas"
            ],
            "title": "A systematic approach for identifcation of tumor regions in the human brain through HARIS algorithm",
            "venue": "Deep Learning Techniques for Biomedical and Health Informatics, pp. 97\u2013118, Academic Press, Cambridge, MA, USA, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "N. Mathur",
                "S. Mathur",
                "D. Mathur"
            ],
            "title": "A novel approach to improve Sobel Edge detector",
            "venue": "Procedia Computer Science, vol. 93, pp. 431\u2013438, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "Z. Gao",
                "G. Wang",
                "Z. Zhang"
            ],
            "title": "Neural network algorithm MRI images for analysis of infuencing factors for patellar dislocation in exercise",
            "venue": "Scientifc Programming, vol. 2021, Article ID 1348922, 8 pages, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "P. Naga Srinivasu",
                "V.E. Balas"
            ],
            "title": "Self-Learning Networkbased segmentation for real-time brain M.R. images through HARIS",
            "venue": "PeerJ Computer Science, vol. 7, p. e654, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C.C. Benson",
                "V.L. Lajish",
                "K. Rajamani"
            ],
            "title": "Brain tumor extraction from MRI brain images using marker based watershed algorithm",
            "venue": "Proceedings of the International Conference on Advances in Computing, Communications, and Informatics (ICACCI), pp. 318\u2013323, Kochi, India, August 2015.",
            "year": 2015
        },
        {
            "authors": [
                "I Diaz",
                "P. Boulanger"
            ],
            "title": "Atlas to patient registration with brain tumor based on a mesh free method",
            "venue": "Proceedings of the 37th Annual International Conference of the IEEE Engineering in Medicine and Biological Society, Milan, Italy, August 2015.",
            "year": 2015
        },
        {
            "authors": [
                "B. Khagi",
                "G.-R. Kwon"
            ],
            "title": "Pixel-label-based segmentation of cross-sectional brain MRI using simplifed SegNet architecture-based CNN",
            "venue": "Journal of Healthcare Engineering, vol. 2018, Article ID 3640705, 8 pages, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Z. Abbas",
                "M. Rehman",
                "S. Najam",
                "S.M. Danish Rizvi"
            ],
            "title": "An efcient gray-leve lCo-occurrence matrix (GLCM) based approach towards classifcation of skin lesion",
            "venue": "Proceedings of the 2019 Amity International Conference on Artifcial Intelligence (AICAI), pp. 317\u2013320, Dubai, United Arab Emirates, February 2019.",
            "year": 2019
        },
        {
            "authors": [
                "D. AboulDahab",
                "S.A. Ghoniemy",
                "G.M. Selim"
            ],
            "title": "Automated brain tumor detection and identifcation using image processing and probabilistic neural network techniques",
            "venue": "International Journal of Image Processing and Visual Communication ISSN, vol. 1, no. 2, pp. 2319\u20131724, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "A. De",
                "C. Guo"
            ],
            "title": "An adaptive vector quantization approach for image segmentation based on SOM network",
            "venue": "Neurocomputing, vol. 149, pp. 48\u201358, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "A. Chakravarty",
                "J. Sivaswamy"
            ],
            "title": "RACE-net: a recurrent neural network for biomedical image segmentation",
            "venue": "IEEE Journal of Biomedical and Health Informatics, vol. 23, no. 3, pp. 1151\u20131162, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A.S. Parihar"
            ],
            "title": "A study on brain tumor segmentation using convolution neural network",
            "venue": "Proceedings of the International Conference on Inventive Computing and Informatics (ICICI), pp. 198\u2013201, Coimbatore, India, November 2017. 16 Journal of Healthcare Engineering",
            "year": 2017
        },
        {
            "authors": [
                "M. Havaei",
                "A. Davy",
                "D. Warde-Farley"
            ],
            "title": "Brain tumor segmentation with Deep neural networks",
            "venue": "Medical Image Analysis, vol. 35, pp. 18\u201331, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Sachdeva",
                "V. Kumar",
                "I. Gupta",
                "N. Khandelwal",
                "C.K. Ahuja"
            ],
            "title": "A package-SFERCB-\u201cSegmentation, feature extraction, reduction and classifcation analysis by both SVM and ANN for brain tumors",
            "venue": "Applied Soft Computing, vol. 47, pp. 151\u2013167, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "W. Jiang",
                "H. Zhou",
                "Y. Shen",
                "B. Liu",
                "Z. Fu"
            ],
            "title": "Image segmentation with pulse-coupled neural network and Canny operators",
            "venue": "Computers and Electrical Engineering, vol. 46, pp. 528\u2013538, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "P. Shan"
            ],
            "title": "Image segmentation method based on K-mean algorithm",
            "venue": "EURASIP Journal Image and Video Processing, vol. 81, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "P.N. Srinivasu",
                "J.G. SivaSai",
                "M.F. Ijaz",
                "A.K. Bhoi",
                "W. Kim",
                "J.J. Kang"
            ],
            "title": "Classifcation of skin disease using deep learning neural networks with MobileNet V2 and LSTM",
            "venue": "Sensors, vol. 21, no. 8, p. 2852, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "P. Chhajer",
                "M. Shah",
                "A. Kshirsagar"
            ],
            "title": "Te applications of artifcial neural networks, support vector machines, and long\u2013short term memory for stock market prediction",
            "venue": "Decision Analytics Journal, vol. 2, Article ID 100015, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K. Tiruvenkadam",
                "N. Perumal"
            ],
            "title": "Brain tumor segmentation of MRI brain images through FCM clustering and seeded region growing technique",
            "venue": "International Journal of Applied Engineering Research, vol. 10, pp. 427\u2013432, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J.G. SivaSai",
                "P.N. Srinivasu",
                "M.N. Sindhuri",
                "K. Rohitha",
                "S. Deepika"
            ],
            "title": "An automated segmentation of brain MR image through fuzzy recurrent neural network",
            "venue": "Bio-inspired Neurocomputing. Studies in Computational Intelligence, A. Bhoi, P. Mallick, CM. Liu, and V. Balas, Eds., vol. 903, Singapore, Springer, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "H. Fan",
                "X. Xie",
                "Y. Zhang",
                "N. Zou"
            ],
            "title": "Contourlet based image denoising method combined recursive cycle-spinning algorithm",
            "venue": "Machine Learning and Intelligent Communications. MLICOM 2017. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, X. Gu, G. Liu, and B. Li, Eds., Vol. 226, Springer, Salmon Tower Building NY, USA, 2018.",
            "year": 2017
        },
        {
            "authors": [
                "T. Priya",
                "P. Kalavathi"
            ],
            "title": "HSV based histogram thresholding technique for MRI brain tissue segmentation",
            "venue": "Advances in Signal Processing and Intelligent Recognition Systems. SIRS 2018. Communications in Computer and Information Science, S. Tampi, O. Marques, S. Krishnan, KC. Li, D. Ciuonzo, and M. Kolekar, Eds., vol. 968, Singapore, Springer, 2019.",
            "year": 2018
        },
        {
            "authors": [
                "B.H. Menze",
                "A. Jakab",
                "S. Bauer"
            ],
            "title": "Te multimodal brain tumor image segmentation benchmark (BRATS)",
            "venue": "IEEE Transactions on Medical Imaging, vol. 34, no. 10, pp. 1993\u2013 2024, 2015.",
            "year": 1993
        },
        {
            "authors": [
                "P. Ganesan",
                "G. Sajiv"
            ],
            "title": "A comprehensive study of edge detection for image processing applications",
            "venue": "Proceedings of the 2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS), pp. 1\u20136, Coimbatore, India, March 2017.",
            "year": 2017
        },
        {
            "authors": [
                "I. Abd El Kader",
                "G. Xu",
                "Z. Shuai"
            ],
            "title": "Brain tumor detection and classifcation on MR images by a deep wavelet autoencoder model",
            "venue": "Diagnostics, vol. 11, no. 9, p. 1589, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "H. Alsaif",
                "R. Guesmi",
                "B.M. Alshammari"
            ],
            "title": "A novel data augmentation-based brain tumor detection using convolutional neural network,\u201dApplied",
            "venue": "Sciences, vol. 12,",
            "year": 2022
        },
        {
            "authors": [
                "R.K. Hapsari",
                "M. Miswanto",
                "R. Rulaningtyas",
                "H. Suprajitno",
                "G.H. Seng"
            ],
            "title": "Modifed gray-level haralick texture features for early detection of diabetes mellitus and high cholesterol with Iris image",
            "venue": "International Journal of Biomedical Imaging, vol. 2022, Article ID 5336373, 11 pages, 2022. Journal of Healthcare Engineering 17",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "Research Article",
            "text": ""
        },
        {
            "heading": "Variational Autoencoders-BasedSelf-Learning Model for Tumor",
            "text": ""
        },
        {
            "heading": "Identification and Impact Analysis from 2-D MRI Images",
            "text": "Parvathaneni Naga Srinivasu ,1 T. Balamurali Krishna ,2 Shakeel Ahmed ,3 Naif Almusallam ,4 Fawaz Khaled Alarfaj ,4 and Nasser Allheeib 5\n1Department of Computer Science and Engineering, Prasad V Potluri Siddhartha Institute of Technology, Vijayawada, Andhra Pradesh 520007, India 2Department of Computer Science and Engineering, Dhanekula Institute of Engineering and Technology, Vijayawada, Andhra Pradesh 521139, India 3Department of Computer Science, College of Computer Sciences and Information Technology, King Faisal University, Al-Ahsa 31982, Saudi Arabia 4Department of Management Information Systems, College of Business Administration, King Faisal University, Al-Ahsa 31982, Saudi Arabia 5Department of Information Systems\u2014College of Computer and Information Science, King Saud University, Riyadh, Saudi Arabia\nCorrespondence should be addressed to Shakeel Ahmed; shakeel@kfu.edu.sa\nReceived 18 October 2022; Revised 13 December 2022; Accepted 7 January 2023; Published 17 January 2023\nAcademic Editor: Ayush Dogra\nCopyright \u00a9 2023 Parvathaneni Naga Srinivasu et al. Tis is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in anymedium, provided the original work is properly cited.\nOver the past few years, a tremendous change has occurred in computer-aided diagnosis (CAD) technology. Te evolution of numerous medical imaging techniques has enhanced the accuracy of the preliminary analysis of several diseases. Magnetic resonance imaging (MRI) is a prevalent technology extensively used in evaluating the progress of the spread of malignant tissues or abnormalities in the human body.Tis article aims to automate a computationally efcient mechanism that can accurately identify the tumor fromMRI images and can analyze the impact of the tumor.Te proposed model is robust enough to classify the tumors with minimal training data. Te generative variational autoencoder models are efcient in reconstructing the images identical to the original images, which are used in adequately training the model. Te proposed self-learning algorithm can learn from the insights from the autogenerated images and the original images. Incorporating long short-term memory (LSTM) is faster processing of the high dimensional imaging data, making the radiologist\u2019s task and the practitioners more comfortable assessing the tumor\u2019s progress. Self-learning models need comparatively less data for the training, and the models are more resource efcient than the various stateof-art models.Te efciency of the proposedmodel has been assessed using various benchmarkmetrics, and the obtained results have exhibited an accuracy of 89.7%.Te analysis of the progress of tumor growth is presented in the current study.Te obtained accuracy is not pleasing in the healthcare domain, yet the model is reasonably fair in dealing with a smaller size dataset by making use of an image generation mechanism. Te study would outline the role of an autoencoder in self-learning models. Future technologies may include sturdy feature engineering models and optimized activation functions that would yield a better result."
        },
        {
            "heading": "1. Introduction",
            "text": "Identifying the tumors and abnormalities in the human body through medical imaging for investigative analysis has become a regular practice. Various medical imaging technologies are used for diagnosis depending on the type of\ndisease and the body part. Te imaging must be performed for an early and precise abnormality diagnosis. Te technologies include X-ray, which is used in the identifcation of bone fractures or for the identifcation of hard tissues [1], and computer tomography (CT) technology [2], which is widely used in contrasting various soft tissues such as the\nHindawi Journal of Healthcare Engineering Volume 2023, Article ID 1566123, 17 pages https://doi.org/10.1155/2023/1566123\nliver, lung tissues, and fat [3]. MRI technology is widely used in the diagnosis of abnormalities in neurology, cardiology, cancer, and soft tissue damage [4, 5], and a positron emission tomography (PET) scan is widely used in the detection of cancerous cells and malignant tissues [6].\nMRI is most widely used in computer-aided diagnosis because of its low radiation and noninvasive nature. On the one hand, MRI can generate a more detailed report of soft tissues compared to CT scans. On the other hand, MRI technology can capture multiplaner images that can capture multiple angles in diferent planes. Moreover, MRI is capable of producing angiographic images without the use of any contrast material. Te patient can be periodically investigated through MR imaging. Te assessments of CAD models are being analyzed to assess the tumor\u2019s impact, which would assist in deciding the infuence of the drug that acts on the abnormality. Te current study identifes the tumor\u2019s progress as actual, enhanced, and whole tumors [7]. Figure 1 represents various medical imaging technologies that are used in smart diagnosis [8].\nTe existing state of art models that work over the segmentation procedures could only recognize the region of the tumor and they are not efcient in classifying the type of tumor and the progress of the tumor growth [9]. Te other deep learning models like AlexNet [10], DenseNet [11], VGG-16 [12], Resnet-50 [13], and MobileNet [14] need tremendous training for attaining reasonable performance. Tere is a great demand for a model that works with minimal training data, especially to deal with novel diseases. Generally, the action of tumor recognition follows the same procedure as any other neural networkmodel.Te image undergoesmultiple phases in tumor identifcation, including preprocessing the image to normalize the noise and enhancing the image\u2019s contrast for better recognition of the regions in the image. Ten, the image is given as input to the algorithm to identify the features acting as a road map for the segmentation process, which is an interactive process. Te proposed self-learning approach immediately performs image analysis by considering knowledge acquired from previous experimental studies and performs the automated segmentation of the MRI images. Te integrated LSTM component is efcient in retaining parameters such as the learning rate of the model through weights and biases observed in previous epochs.Tereby optimizing the eforts for weight assessment and updating. Te overall contributions of the current study are discussed as follows:\n(i) Te primary goal of the current study is to mechanize a self-learning model that can make a precise assessment of tumor progression with minimal data\n(ii) We discuss various existing tumor progression assessment models based on image segmentation and their limitations\n(iii) Te autoencoders generate numerous images identical to the original MRI images for training\n(iv) Integrating the LSTM component with the selflearning model improves performance by maintaining adequate model parameters\n(v) Using the grey-level co-occurrence matrix for the feature engineering task by the self-learning network model that assesses the number of occurrences of combinations of the pixels found in the input MRI image\n(vi) Analyzing the hyperparameters to determine the efciency of the self-learning model\n(vii) Analyzing the performance of the proposed model against benchmark evaluation metrics like sensitivity, specifcity, accuracy, and F1-score\n(viii) Analyzing the tumor impact throughmeasures like tumor core, enhanced tumor, and whole tumor\nTe paper is structured as follows: the introduction presents the domain of the study and the author\u2019s contributions. Section 2 ofers the related work used in the automated segmentation of the MRI images to assess the tumor\u2019s progress. Section 3 presents the proposed selflearning model. Section 4 focuses on the experimental results and discussion part of the study. Finally, Section 5 ofers the conclusions and future scope."
        },
        {
            "heading": "2. Literature Review",
            "text": "Various image segmentation approaches are available to localize the abnormality from the MRI images. Te Kmeans-based segmentation algorithm is among the approaches that are most extensively used in semiautomated segmentation mechanisms that need the number of segments to be predetermined [15]. Moreover, it is simple to implement and requires less computational efort with limited iterations to segment the image. Unlike other segmentation approaches, it does not need training to perform segmentation. Still, it is limited to over, and undersegmentation of the images as the number of segments is predetermined. Tis approach is hardly used these days to segment medical images.\nFuzzy c-means [16] is the improvised version of the traditional K-means algorithm [17].Te pixels are allotted to the image segments based on the membership value rather than considering the distance measured in the K-means algorithm. However, this approach has a fxed number of segments in the image that fails to identify tiny regions signifcant in tumor identifcation. Moreover, the fuzzy Cmeans algorithm requires a high load for evaluating each pixel\u2019s membership to the corresponding segments. In a comparative analysis of various approaches for brain tumor identifcation from the MRI images [18], instructive fuzzy clustering means to have a misclassifcation error rate of 0.537%.\nTe MRI images are being segmented using fully automated mechanisms such as thresholding [19], region growing [20], and edge-based segmentation [21\u201323]. Te threshold-based segmentation mechanism is suitable for MRI images, and the studies have proven that experimenting with difusion-weighted MRI images has obtained 86% accuracy [24]. However, choosing the optimal threshold is challenging, and an inappropriate approximation may lead\nto poor segmentation. However, the region-growing mechanism has outperformed image segmentation by enhancing the sensitivity and specifcity of recognizing malignant tissues. Nevertheless, the algorithm is susceptible to selecting the initial seed points [13]. In edge-based segmentation, the outputs are reasonably fair [25]. Te image needs to be enhanced, and the edge-related information that needs to be highlighted needs rigorous preprocessing on the image, which requires more computational eforts. Figure 2 represents the radiologist\u2019s various segmentation approaches in recognizing the abnormalities from the medical images.\nTe watershed-based image segmentation model works based on edge-based information that necessitates foreground and background planes as separated fles that require high computational resources for preprocessing the image [26]. Te watershed-based image segmentation model is well-systematized for handling homogeneous and heterogeneous malignant cases [4]. However, the watershed-based model fails to address the high-intensity images and noise. Te atlas-based [27] approach works based on labeling and can efciently handle the deformation model. Still, it is susceptible to the initial seed point, and the accuracy of the outcome depends on the topology.\nTe pixel label-based image segmentation [28] is a robust approach extensively used to segment medical images to recognize the abnormalities from the 2D MR images. Identifying the labeled data set of images would be challenging as the algorithm\u2019s accuracy relies on the machine\u2019s quality and quantity. Moreover, labeling the images for the training is not technically feasible, so the approach is hardly used in segmenting the medical-related images. Pixel labelbased image segmentation has exhibited a mean accuracy of 80% on experimenting with the OASIS cross-sectional MR images, which is too low for sensitive medical data. Contourbased image segmentation [4, 29] is an improvised approach over pixel-labeling-based segmentation. It is among the most predominantly used image segmentation approaches\nto identify the objects and regions in an image. Although, the contour-based image segmentation approach fails to handle high-intensity images. Moreover, the images that have noise, such as the medical MR images, are susceptible to Gaussian and poison noise caused by thermal vibrations from the medical equipment or improper equipment calibration.\nA probabilistic neural network (PNN) [30], in conjunction with learning vector quantization (LVQ), is efcient in segmenting the image in minimal computational time by optimizing the hidden layers. Self-organized Map (SOM) [31] model-based image segmentation is noticeable in differentiating the malignant tissues based on the image\u2019s spatial information. Te SOM model needs excellent training, which is not always possible in unusual cases. Fuzzy recurrent neural network (FR-Net) [4] efciently handles high-dimensional data like MR images. Te FR-Net model works by fne-tuning the weights and biases over the parameters and the feedback loops that will assist in identifying the features that determine the abnormality of the image. FRNN needs an enormous computational efort to process the information, and the model needs tremendous training.\nArtifcial neural networks. (ANN) is a predominantly used segmentation approach for medical imaging technology, motivated by the biological neurons being practically implemented through artifcial neurons controlled by the activation and transfer functions. Based on the underlying ground facts and working principles, the auto-encoders are designed in divergent architectures that can either adhere to the logic of a recurrent neural network (RNN) [32], which has obtained 93.82% on the implementation of 58 images obtained from the UCSB bio-segmentation benchmark dataset, and convolution neural networks (CNN) [33]. Te ANN has the beneft of memorizing the entire network, and they have the competence to do with insufcient knowledge due to missing features for segmentation. Resultantly the ANN approaches are fault-tolerant and share parallel processing compatibility. Te major limitation of the ANN approach is that the structure is determined for processing\nthe data. It needs a tremendous computational efort to process the algorithm, and tracing the error in the network is challenging. Neural networks [1, 18] and model-based classifcation have exhibited better accuracy. Artifcial Neural Networks performing the feature extraction over the dataset of size 428MR images have exhibited a classifcation accuracy between 77\u201391% based on the size of the training set and the feature extraction strategy deployed.\nDeep learning-based image segmentation is among the most widely used image segmentationmodels in recent years that would yield better accuracy in tumor identifcation [34]. Te accuracy is 84% on experimenting over a BRATS-13 leaderboard set and 81% on a four-label test set on the BRATS-14 dataset. Te abovementioned model needs a proportionately high-performance computer concerning the number of intermediate layers for segmentation. A hybrid approach with a combination of the pulse-coded neural network (PCNN) and feed-forward back neural network (FFBNN) [35, 36] technique identifes the preliminary seed points. Te latter approach would setback the points that would stabilize the input, leading to an optimal image segmentation level. But the two algorithms need to be executed simultaneously, which requires more execution time and computational eforts and fails in handling unusual cases. Table 1 presents the various existing approaches for tumor recognition."
        },
        {
            "heading": "3. Self-Learning Model with LSTM",
            "text": "Te proposed SLNS-LSTM technique incorporates several components integrated for performing the automated segmentation and assessing the tumor\u2019s progress. Te images are preprocessed internally to discard the noise, and then the images are segmented based on texture-based information.\nTe information related to the previous experiment is loaded in a temporary memory, namely, the long short-term memory, which is widely used with recurrent neural networks. In image segmentation, feature selection is signifcant in attaining remarkable accuracy.\n3.1. Self-Learning Model with Partial Training. Te selflearning algorithm is technically efcient in addressing the segmentation of novel cases, and the algorithm will train itself to segment every case. Initially, the algorithm is partially trained with the available data set, and every time segmenting an image, the algorithm is self-trained. Te algorithm will have an auxiliary memory to maintain the historical information of previous executions. Te algorithm is sturdy to handle both noisy and noiseless images. Te machine is trained with the noisy image at an acceptable level using the labeling approach [38] through a binary identifer to diferentiate noise from noise-free images. Te algorithm can diferentiate various images while performing the automated segmentation of the images.\nIn automated segmentation for the abnormality diagnosis, it is crucial to distinguish brain tissues from nonbrain tissues. To be normalized, the original MRI image comprises much nonbrain tissue, such as the skull region, brainstem, thalamus, and brain fuid. Te proposed algorithm is a layered approach for discarding all such nonbrain tissues for better statistical image analysis. An explicit algorithm is being executed in all the conventional mechanisms simultaneously to discard the nonbrain tissue that needs additional efort to perform the task. Te self-learning component is among the multiple layers in the proposed algorithm, to which the outcomes of the previous executions are fed as the input.Te progress of tumor growth is assessed by the area of the abnormality that has increased from the\nTa bl\ne 1:\nSu m m ar y of\nva ri ou\ns tu m or\nre co gn\niti on\nte ch ni qu\nes .\nA pp\nro ac h\nO ut co m e\nLi m ita\ntio ns\nK -m\nea ns\n[3 7]\nK -m\nea ns\nfo r cl as sif\nca tio\nn al on\ngs id e av er ag e pr ec isi on\nan d in te rs ec tio n ov er un io n ap pr oa ch es fo ro bj ec tr eo rg an iz at io n in re al -t im ei m ag es an d sp lit tin g up th e ob je ct s in th e im ag e\nT e ap pr oa ch\nis su sc ep tib\nle to\nov er se gm\nen ta tio\nn or\nun de rs eg m en ta tio n as th ek va lu ei sf xe d. A la rg er k va lu ew ou ld re su lt in ov er se gm en ta tio n, an d a sm al le r k va lu e w ou ld re su lt in un de rs eg m en ta tio n\nT re sh ol di ng\n[3 8]\nT e au th or\nha s ex pe ri m en te d w ith\nth e th re sh ol di ng\nap pr oa ch\nov er\ndi fu\nsio nw ei gh\nte d M RI\nim ag es\nfo r le sio\nn id en tif\nca tio\nn us in g G am\nm a\nla w\ntr an sf or m at io n co m pa re d to\nco nt ra st\nst re tc hi ng\nA tm\nos t, ca re\nm us tb\ne ta ke n w hi le pi ck in g th e op\ntim al th re sh ol d va lu e.\nW ro ng\nly ch oo\nsin g th e th re sh ol d va lu e m ay\nle ad\nto in ap pr op\nri at e\nse gm\nen ta tio\nn\nRe gi on\ngr ow\nin g [2 0]\nM ul tis pe ct ra lM\nRI im\nag e se gm\nen ta tio\nn ha s be en\npe rf or m ed\nfo r\nse gm\nen ta tio\nn an d ha se xh\nib ite d be tte\nra cc ur ac y w or ki ng\nw ith\nno isy\nM RI\nim ag es .F\nuz zy\nkn ow\nle dg eba se d re gi on\ngr ow\nin g ha s pe rf or m ed\nbe tte r th an th e tr ad iti on al ar ea gr ow in g al go ri th m\nT e re su lta nt\nou tp ut\nim ag e is su sc ep tib\nle to\nth e in iti al se ed\npo in t. T\ner e\nar e ch an ce s w he re\nth e al go ri th m\nm ig ht\nen d up\nin gl ob\nal m ax im\na or\ngl ob\nal m in im\na\nEd ge -b as ed\nse gm\nen ta tio\nn [2 3,\n25 ]\nT e au th or sh\nav e pr op\nos ed\nw or ki ng\nw ith\nSo be le dg e de te ct io n to\nre ta in\nin fo rm\nat io n th at\nas sis\nts in\nth e ex ac tl oc al iz at io n of\nth e tu m or\nth ro ug h\nla se r th er ap y\nT e im\nag e ha s to\nbe pr ep ro ce ss ed\nri go ro us ly\nso th at\nth e ed ge -r el at ed\nin fo rm\nat io n is el ab or at ed ,w\nhi ch\nw ou\nld in cu r a hi gh\nco m pu\nta tio\nna l\nef or t\nW at er sh ed\n[2 6]\nW at er sh ed -b as ed\nse gm\nen ta tio\nn is pe rf or m ed\nw ith\ndi fe re nt\nco m bi na tio\nns of\nfe at ur es\nth at ca n ef ec tiv\nel y lo ca liz e th e tu m or\nfr om\nth e\nM RI\nC on\nsid er ab le ef or ts m us tb en\nee de d du\nri ng\nth ep\nre pr oc es sin\ng as th ef or e\nre gi on\nis se pa ra te d fr om\nth e ba ck gr ou\nnd re gi on\nPi xe l-l ab el -b as ed\nim ag e se gm\nen ta tio n [2 8]\nPi xe l-l ab el -b as ed\nse gm\nen ta tio\nn th ro ug h en co de ra\nnd de co de r ne tw or ks\nof Se gN\net la ye re d ar ch ite ct ur e fo r im\nag e se gm\nen ta tio\nn. It is ob\nse rv ed\nw ith\nso m e en ha nc em\nen ts .T\ne ou\ntc om\ne is ve ry\nm uc h pl ea sin\ng, lik e na tu ra lo ut do or im ag es\nT e av ai la bi lit y of\nth e la be le d tr ai ni ng\nse tf or\nun us ua lt um\nor ty pe s is\na ch al le ng\nin g ta sk .T\ne se gm\nen ta tio\nn ap pr oa ch\nis no\nts ui ta bl e fo r\nas se ss in g th e pr og re ss\nof th e tu m or\nPr ob\nab ili st ic\nne ur al\nne tw or k [3 0]\nLV Q - ba se d PN\nN sy st em\ncl as sif\nca tio\nn is be tte\nr in\nth e M RI\nim ag e\ncl as sif\nca tio\nn, w ith\na m in im\nal pr oc es sin\ng tim\ne of\n79 %\nle ss\nth an\nco nv\nen tio\nna lP\nN N\nT is ap pr oa ch\nne ed s co ns id er ab le\ntr ai ni ng\nfo r be tte\nr ac cu ra te\nre su lts ,\nw hi ch\nca nn\not be\nus ed\nin un\nus ua lc\nas es\nw ith\nou ts\nuf ci en tt ra in in gse t\nda ta\nFu zz y re cu rr en tn\neu ra ln\net w or ks\n[3 7]\nFR -n et m od\nel is us ed\nto se gm\nen tt he\nhi gh\n-d im\nen sio\nna lM\nRI im\nag es w ith\nan ac cu ra cy\nof 87 .8 % an d co m pa ra tiv\nel y fa st er\nth an\nva ri ou\nss up\ner vi so ry\nm od\nel s\nFR -n et m od\nel ne ed sc on\nsid er ab le co m pu\nta tio\nna le fo\nrt sa nd\ntr em\nen do us tr ai ni ng to ob ta in re as on ab le ac cu ra cy\nA rt if ci al\nne ur al\nne tw or ks\n[3 2,\n33 ]\nRA C Ene ta\nrc hi te ct ur e ef\nci en tly\nad dr es se s ov er ft tin\ng by\nad ju st in g th e\nde pe nd\nen ci es\nan d C N N\nth ro ug h a sm\nal lk\ner ne lt ha ta\nss ist s in\nim pl em\nen tin\ng th e m or e pr of ou\nnd ar ch ite ct ur e th at\nal so\nad dr es se s\nov er ft tin\ng by\nas sig\nni ng\nfe w er\nw ei gh\nts\nA N N ca n be\nef ci en tly\nim pl em\nen te d th ro ug h C N N an d RN\nN .B\nut ei th er\nof th os e ap pr oa ch es\nne ed s tr em\nen do\nus tr ai ni ng\n,w hi ch\nw ou ld sig ni fc an tly im pa ct th e co m pu ta tio na ll at en cy ,a nd a hi gh -p er fo rm\nin g\nm ac hi ne\nis re qu\nir ed\nfo r im\npl em\nen ta tio\nn\nprevious scan for a particular patient. Te texture-based information is being considered in evaluating the progress of the tumor."
        },
        {
            "heading": "3.2. Variational Autoencoder for Image Generation.",
            "text": "Dealing with the self-learning models, the models are desired to work with smaller datasets. On splitting the datasets as the training and testing partitions, the size of the data meant for training may not be adequate, resulting in the underftting of the model. Te variational autoencoders are used in the current study to generate images identical to the training images. Te variational autoencoders consist of two components, namely, the encoder and the decoder. Te encoder maps the original picture to a latent space and reconstructs the information in the latent space back into its initial dimensions performed by the decoder.Te variational autoencoders (VAE) are probabilistic in assessing the process of feature assessment. VAE gives a probabilistic description of an observation in latent space. Tus, rather than developing an encoder that produces a single value to represent each latent state feature, it is preferable to use many values. VAE presents the probabilistic distribution for every attribute in the latent space. Te probabilistic measure is associated with the joint model p\u03b1(m, n) \ufffd p\u03b1(m|n)p\u03b1(n) concerning the parameter \u03b1 and posterior q\u03b2(n|m) concerning the parameter \u03b2.Te prior images are used to sample the latent variable n, i.e., n \u223c p\u03b1(n), while the observation model is used to sample the observation variable m, i.e., m \u223c p\u03b2(m|n). Te optimized probability concerning the original images x is shown in the following equation:\np\u03b1(m|x) \ufffd  n p\u03b1(m | n, x)p(n | x)dn, (1)\np\u03b1(m|n, x) \ufffd p\u03b1(m | n, x)p\u03b1(n | x)\np\u03b1(m | x) . (2)\nEquation (2) corresponds to the posterior of the latent space, and as the variable p\u03b1(m | x) is accessible, the posterior is evaluated using the q\u03b2(n | m, x) \u223c p\u03b1(n | m, x). Te conditional evident lower bound is assessed using Jensen\u2019s inequality, as shown in the following equation:\nL(m, x, \u03b1, \u03b2) \ufffd Rq\u03b2(n | m,x) log p\u03b1(m, n | x)\nq\u03b2(n | m, x)  \u2264 logp\u03b1(m | x). (3)\nTe images generated using the variational autoencoders are used in training the self-learning network. Te apparent loss function of VAEs, comprising a rebuilding component and a regularization element, may be precisely constructed using the statistical approach of variational inference; thus, the name variational autoencoders, is given a basic probabilistic model that represents the data."
        },
        {
            "heading": "3.3. Convolutional Operations in Self-Learning Network.",
            "text": "Long- and short-term memory has signifcantly impacted identifying the tumor from theMRI image. LSTM comprises two classes that are categorized as tumors and nontumor tissues. Whenever the image is fed as the machine\u2019s input, it\nclassifes the tissues based on the antecedent experimental studies [39]. Te proposed mechanism\u2019s LSTM component would be competent for learning abiding dependencies and environmental parameters for the past and future. Each layer in LSTM acquires the input from the frst objective function of HARIS and generates the data for the second objective function by evaluating the feed-forward sequence ff \ufffd\u2192 and feed-backward series that is being denoted by \ufffdfb. Te output sequence generated by the feature vectors is stated through equations (4) and (5). Te block diagram of the LSTM module in the proposed approach is presented in Figure 3, which classifes the tumor tissues from the nontumor tissues associated with the feature set.\nff \ufffd\u2192 \ufffd \u03c3 Wiff \ufffd\ufffd\u2192\npixi + W ff \u2192 ff\n\ufffd\u2192 i\u22121 + bias\nff \u2192 , (4)\n\ufffdfb \ufffd \u03c3 Wi \ufffdfb pixi + W\ufffdfb \ufffdfbi\u22121 + bias\ufffdfb . (5)\nFrom the above equation, the variable \u03c3 represents the sigmoid function, Wi denotes the weighted matrix, bias means the bias for both feed-forward represented by bias\nff \u2192\nin equation (4) and feed-backward represented by bias\ufffdfb in equation (5), and the variable pixt represents the each input pixel sequence represented by pix\ufffd (pix1, pix2,. . .pixi).\nSelf-learning network-based segmentation (SLNS) is a layered approach comprising several convolutional layers that carry out the various crucial tasks in the procedure of automated segmentation that involves the preprocessing for the unwanted noise removal from the image using the adaptive fuzzy contourlet transforms [40]. Ten, the resultant image is fed to the corresponding layers of the network to accomplish the image\u2019s automated segmentation by taking texture-related information into account. In each iteration, the feedback from LSTM is considered in diferentiating the damaged tissues from nondamaged tissues [41].\nSLNS approach-based MRI image segmentation requires partial training from various sources that involves acquiring the data related to the segmentation of the images from the labeled segmentation datasets and the knowledge that the algorithms have learned from the previous experimentation. In the proposed approach, every layer of the network is signifcant, one of the layers performs noise removal through adaptive fuzzy contourlet transforms, and the rest of the sublayers would evaluate the optimal number of segments and appropriate segment centroid, respectively, that are refned for several iterations until it reaches an optimal solution.\nTe original image is being processed by the noise removal layer of the proposed SLNS network using an adaptive fuzzy counter transform mechanism that enriches the image quality from magnitude and anisotropy perspectives [42, 43]. Te idea of the adaptive contourlet transforms on various kernels that involve the Laplacian pyramid kernel and direction kernel over the image by preserving some of the critical information in the image, like edge-related information and minor regions in the medical images. Ten the fuzzy contourlet transformworks on the logic of selective\nenhancement of areas in the image, the Laplacian pyramid that classifes the single as low pass frequencies that are being decomposed that would lead to normalized signal strength and the high-pass frequencies that would enrich the sensitive and crucial points over the original MRI images. On the other hand, the Laplacian flter assesses the variance between the image and the resultant fltered image using a low pass flter that blurs the image to curb the low frequencies. Te direction kernel would rebuild the images by enhancing the edge-related information by using the concept of frequency partitioning through the frst-order derivative among the intensities of the pixels that are part of the same region that can be used in any direction."
        },
        {
            "heading": "3.3.1. Integration of LSTM with SLNS Architecture. Te",
            "text": "LSTM memory module is integrated with the layered architecture of the self-learning network model, which holds the layers like the pooling layer and the convolution layers of the proposed architecture. Te pooling layer\u2019s responsibilities are incorporated with the convolution layer that assists in incrementally decreasing the spatial dimensions for the depiction, minimizing the features needed for a thorough reorganization, and assessing the tumor from the MRI image. Te convolution layer performs in decomposing the image to the maximum possible extent for approximating the tumor by using the properties that are being recognized. Te convolution layer has a signifcant impact on the computation latency and the accuracy of the algorithm. Figure 4 represents the architectural design of the proposed self-learning network model.\nTe technical tradeof over the convolution layer is the down-sampling performed in the striding at the convolution layer. Te more it decomposes, the more the accuracy of the\nclassifcation. Still, there would be a considerable burden on the algorithm that can afect the computational latency of the model. In the proposed model, the LSTM component is integrated with the segmentation component of the proposed model; the LSTM model will maintain the information about the segmentation outcomes of the previous experimental instances. Te LSTM and training set information are used in the classifcation process. Te MRI images are then classifed as tumor and nontumor images for diagnosing the tumor.\nTe self-learning model\u2019s layered approach comprises the convolution layer with the various kernels applied to the input MRI image to recognize the feature maps that will assist in the classifcation process. Ten, the resultant outcome is processed using the kernel through the HARIS algorithm. Te tensors of the second convolution layer are applied with the Max Pooling layer that down-sampling the input data for faster processing. Te LSTM component handles the vanishing gradient problem of dealing with high-dimensional images. Incorporating the LSTM is a recognized dependency among the features in determining the abnormality regions in the segmentation process. Te fully connected layer in the SNLS-LSTM architecture will map the features organized by the nonlinear associations in one layer with the activation unit in the upcoming layer. Te SoftMax layer will assess the probabilistic measure of the image classifed among the tumor and nontumor regions. Figure 5 presents the layered framework of the proposed self-learning model.\n3.4. Noise Normalization. Te noise is predicted using the hybrid kernel to discard unwanted noise. Te equation for noise analysis is as follows:\npix(i, j) \ufffd Gaussianpix int(i, j) \u2212 fz \u00d7 4 \u00d7  2\nx\ufffd\u22122 \n2\ny\ufffd\u22122 \u03c9(m, n)Gaussianpix int\ni \u2212 m 2 , j \u2212 n 2  \n\u23a7\u23aa\u23a8\n\u23aa\u23a9\n\u23ab\u23aa\u23ac \u23aa\u23ad . (6)\nFrom equation (6), the variable Gaussianpix int denotes the corresponding Gaussian kernel coefcient associated with coordinates (i, j), and the function \u03c9(m, n) indicates standard deviation concerning the dimensional coordinates (i, j). Te variable fz is the fuzzier arbitrary value that is determined by the pixel membership following the image segment, whose value is defned as follows:\nfz pixi(  \ufffd 1\n1 + pixi \u2212 timax /ki max  2uimax . (7)\nFrom the above equation, the variable fz(pixi) determines the pixel\u2019s fuzziness concerning the segment. and the variables timax , kimax and uimax are the antecedent augments. pixi is the ith pixel in the input image.\n3.5. Feature Selection for Segmentation. Feature selection is one of the pivotal phases of image segmentation, as the performance of the segmentation algorithm depends on the features through which the image is being segmented. For\nfeature selection, the grey-level co-occurrence matrix (GLCM) is very suitable for identifying the features from the MRI images [3]. GLCM is a statistical texture-based approach that works on how frequently the pixel with the corresponding intensity has occurred in the considered image. For each pixel considered (p, q), the key value represents the frequency of occurrence horizontally adjacent to the corresponding pixel intensity p. If an image of 228 bits is considered, the GLCM matrix would be 228\u00d7 228. Te coefcient of the GCLM for the square size image is approximated through the following equation for an MRI image with \u201cp\u201d rows and \u201cq\u201d columns:\nGCLM(x, y) \ufffd GCLM(x, y)\n p x\ufffd1  q y\ufffd1\nGCLM(x, y). (8)\nBy conducting normalization on the coefcients of GLCM, they are represented by probability instead of frequency of occurrences. Te terms are further divided by the entire list of possible combinations. Te same has been\npresented in the following equation with a displacement vector (dp, dq):\nGCLMn(x, y) \ufffd  m\nx\ufffd1 \nn\ny\ufffd1\n1, if I(x, y) \ufffd 1 ,\nI p + dp, q + dq  \ufffd 0 \u23a7\u23a8 \u23a9 \u23ab\u23ac \u23ad; else 0 otherwise. (9)\n3.6. Pixel Fitness Evaluation. Upon processing the input image to discard the unwanted noise, the image is fed as input to the proposed segmentation mechanisms associate layer concerning the pixels\u2019 intensity with a general assumption that the image would be 23 from the previous experiences. Te ftness of appropriate segments is computed through the following equation:\nf itnessfun \ufffd p \u00d7 Totalimg pix totalseg   + q \u00d7 Totalsp pixseg  . (10)\nIn the above equation, the variables p and q are the arbitrary coefcients associated with the accuracy, and the efciency of the ftness function w, p determines the interclass variance that must be maximally assessed through equation (11). Te variable q determines the intra-class correlation that must be at its maximum, which is assessed using equation (10). Either of those will be the sublayers of the segmentation layer of the proposed model. Te variable Totalimg pix designates the sum of pixels in the entire image, totalseg designates the sum of image segments and Totalsp denotes the sum of seed points in the considered image and pixseg denotes the total number of pixels concerning the segment \u201cseg.\u201dTe interclass variance is assessed as follows:\n\u03c32intercls(\u03b8) \ufffd \u03c3 2total cls\u03b8(  \u2212 \u03c3 2 pint C\u03b8( ), (11)\n\u03c32intercls C\u03b8(  \ufffd  C\u03b8\u22121\ni\ufffd0 p(i) \nmax\u22121\ni\ufffdC\u03b8\np(i) \u03bc1 C\u03b8(  \u2212 \u03bc2 C\u03b8(   2 .\n(12)\nEquation (11) is expanded as equation (12), and the class threshold is denoted by C\u03b8 that is approximated using the concept of the fuzzy entropy-based thresholding (FET) mechanism. Te arbitrary variables \u03bc1, \u03bc2 Te above equation would approximate the average intensities of the pixels in the corresponding segment.\nA fuzzy entropy-based thresholding mechanism would assess the pixel\u2019s correlation concerning a segment in the image that tells to what degree the pixel belongs to the region. Te fuzzy entropy threshold is determined using Shannon\u2019s entropy, whose values would always like within the range of 0 and 255 for any given grayscale image defned in equation (13), the variables \u03bctumorcls, \u03bcnon tumorcls It would denote the evaluated fuzzy membership concerning the image segment corresponding to the tumor and nontumor classes.\n\u03b8 \ufffd  max\ni\ufffd1 \u03bctumorcls(i)log2\u03bctumorcls(i) \u2212 \n255\ni\ufffdmax+1 \u03bcnon tumorcls(i)log2\u03bcnon tumorcls(i). (13)\nTe value assessed for the intraclass correlation, as stated in equation (14), would determine how closely the pixels with the same segment are related to each other. It is desired to have higher values for strongly correlated pixels within the same segment. Te standard deviation assesses the correlation between the pixels and the segment.\nIcorrelation \ufffd \u03c32seg\n\u03c32seg + \u03c3 2 img\n. (14)\nFrom equation (14), the component \u03c3seg denotes the standard deviation among the pixels concerning the corresponding segment computed locally, and the component \u03c3img indicates the standard deviation of the entire image that is calculated globally.\nIn working with Long- and short-term memory, the brain tissues are classifed as tumors. Nontumor tissue classes from the previous execution and the classes are\nassigned weights based on the equations (15) and (16) that are stated below for each sample Ii, which are assessed following the likelihood ratio of either class of tissues identifed from 2D MR images of tumor(i)/nontumor(i).\nWp tumor(i)\nnontumor(i)   \ufffd \nn i\ufffd0 f(i) nontumor(i) nontumor(i) tumor(i)dx, (15)\n n\ni\ufffd0 f(i)tumor(i)dx \ufffd Wq[f(i)]. (16)\n3.7. Data Collection. Te labeled data for the partial training of the self-learning model is obtained from the BRATS 2015 [44] open-source dataset consisting of 220 severely afected patients\u2019 MRI image data and 54 acutely afected patient data. Te dataset consists of T1-weighted, T1c-weighted, T2weighted, and FLAIR-weighted MRI images labeled with the\nground facts associated with the tumor. For partial training of the model, two parts of the dataset are used for training, and eight parts are considered for validation out of ten parts of the overall dataset. Te image samples were downsized to 228\u00d7 228 for the experimental study. We have collected 736 random patches at periodic intervals to check the development of classifcation performance during training, with equal numbers taken from all of the validation images in the dataset. To approximate the real proportion of tumors and healthy tissue, patches are evenly selected from the brain area.Te benchmark dataset is considered over the real-time dataset in the current study, as the benchmark datasets are standardized and formatted to maintain uniformity across the samples, which would yield a better training performance."
        },
        {
            "heading": "4. Localization of the Tumor Region",
            "text": "Te heuristic approach of real-time image segmentation (HARIS) has been incorporated for better performance and accuracy [45]. Te algorithm would segment every consecutive experimentation concerning its previous experiment and the available training data. LSTM would support storing the state information in determining the tumor and non\ntumor regions. Te working procedure of the HARIS algorithm is presented in this section, and the libraries and environment settings used in the real-time implementation of the mechanism are presented.\n4.1. HARIS Algorithm. Te heuristic approach for realtime image segmentation technique is a multiobjective, function-based automated image segmentation algorithm that can automatically segment an image with reasonable computational eforts compared to its counterparts. Te initial object function segments the medical MRI image, and the later objective function refnes the segmented image, which continues for a few iterations until the stopping criteria are reached. Initially, the algorithm approximates the number of segments at the beginning through the elbow approach rather than choosing random segments like any other approach. Te initial count of segments is determined through the following equation:\ninitialseg \ufffd  j\nsegi\ufffd1  pixn\u2208ti\npixn \u2212 centroidi    . (17)\nAs mentioned earlier, equation (15) is executed recurrently until there is no signifcant change in the variable\u2019s value initialseg Based on the ground facts, the value approximates 23 in the beginning iteration. In equation (17), the variable j pertains to the approximated number of segments in the previous iteration, and for the frst iteration, the value of j would be 23.Te variable segi designates the ith a segment of the image whose range of values would be between 1 and the maximum limit denoted by the variable j. Te variable pixn designates the sum of the pixels in the nth\nsegment. Te variable centroidi illustrates the approximated centroid of the ith segment.\n4.2. Identifcation of the Segment Centroid. Te process of choosing the centroid of the segment is pivotal in the process of an optimal level of segmentation of the MRI image, as all the pixels around the centroid would be assigned to the corresponding centroid concerning some criteria that can be either a distance measure or the ftness function for assigning the pixel. Te appropriate segment centroid is approximated through the following equation:\nsegcentroid \ufffd  max\npix\ufffd1 \nn\nsegment\ufffd1 f itpix,segdist xpix, centroidseg . (18)\nFrom the above equation (14), segcentroid designates the recognized latest segment centroid of the segment seg, and the variable fitpix,seg designates the approximated ftness of the pixel pix concerning the segment seg. centroidseg denotes the centroid of the image segment seg, and the variable xpix is the xth pixel of the segment. dist(xpix, centroidseg) designates the distance measured between the pixel and the corresponding image segment. In assessing the distance measure, the Mahalanobis distance measure is used to assess the mean of the feature vector, which is approximated from the mean value of intensities in the corresponding segment. Te Mahalanobis distance d2(int, pixn) is assessed for the pixel pixn with the intensity, int is approximated from the following equation:\nd 2 int, pixn(  \ufffd int \u2212 \u03bc i  intD\u22121x int \u2212 \u03bc i  . (19)\nIn the above equation, intD\u22121x denotes the inverse of the matrix that has been produced from the covariancematrix in the following equation:\nintD\u22121x \ufffd xi \u2212 1( S \u22121 n . (20)\nTe individual in each segment with concern to the segment centroid is determined from the following equation:\nSn \ufffd  max\ni\ufffd1 intmaxi \u2212 \u03bcmax(  int max i \u2212 \u03bcmax(  T . (21)\n4.2.1. Objective Function-I. Te objective function-I performs the image\u2019s task by approximating the random segments through the elbow approach and assigning the pixels to it by evaluating the membership of the pixel to the corresponding segment. Te pixel likelihood to the corresponding segmentation is assessed concerning the centroid of the segment that is evaluated from the following equation:\nCr \ufffd 1/ICr I\n2 1 + I 2 2 + . . . + I 2 max \n1/ICr I1 + I2 + . . . + Imax(  . (22)\nIn the above equation, the corresponding segment centroid is identifed by the variable Cr, and the range of r lies between 1 and max. Te objective function for\nestimating the pixel allotment is evaluated using the following equation:\nf(x) \ufffd \u03b1 \u00d7 totpix pixr   + \u03b2 \u00d7 totcent pixs  . (23)\nIn the above equation, the variables \u03b1, \u03b2 are the two arbitrary variables that decide the accuracy and performance of the HARIS algorithm. Te variable \u03b1 determines the interclass variance, and the variable \u03b2 determines the intraclass correlation of the pixels concerning the centroid of the segment. totpix designates the sum of pixels, pixr denotes the sum of pixels in the region r of the image and totcent designates the sum of segments in the image and pixs designates the number of pixels in the region s. Te values of two arbitrary variables that are illustrated as the deciding factors for the performance of the algorithm are defned through the following equations:\n\u03b1 \ufffd \u03c32i\n\u03c32i + \u03c3 2 e/2 \n, (24)\n\u03b2 \ufffd  max\nCr\ufffd1 \u03c9r(x)\u03c3\n2 r(x). (25)\nIn the above equation (22), the variable \u03b1 determines the intraclass correlation, which fgures out how closely the pixels are close to each other in concern to the centroid of the pixel, and the variable \u03b2 in equation (23) determines how dissimilar the pixels are among the segments were the interclass variance designates that. Te ftness is now being evaluated to decide whether to increase or decrease the number of segments. Te ftness is evaluated through equation (25), and the algorithm for the HARIS algorithm is shown in Table 2.\nf Ci(  \ufffd 1 + abs(f(x)) if the value of f Ci( < 0, a new segment is to be added,\nf Ci(  \ufffd 1\n1 + f(x) if the value of f Ci( > 0, the segment needs to be reduced.\n(26)\n4.2.2. Objective Function-II. Objective function-II is to fnetune the resultant outcome of objective function-I. Te major focus of the current objective function is to identify the optimal segment centroid of the global best solution. All\nthe membership function assigns all the pixels corresponding to the segment centroid based on the objection function and is assessed through the following equation:\nspi \ufffd rand(0, 1) \u00d7 f itness spi\u22121 + rand(0, 1) \u00d7 GBspfitness \u2212 f itnesssspi\u22121 . (27)\nFrom the above equation, spi designates the current evaluation of the ftness of the seed point of the segment, and the variable fitness spi\u22121 designates the ftness of the seed point in the previous iteration. GBspfitness denotes the segment seed point\u2019s ftness value considered the global best in ftness, and the values are assessed iteratively.\n4.3. Specifcations and Environment. Te following is the environment set up for the practical implementation of the algorithm.Te experimentation has been conducted on several input images for a precise assessment of the accuracy of the proposed system. Table 3 specifes the platform and environment where the proposed model has been implemented."
        },
        {
            "heading": "5. Experimental Results and Analysis",
            "text": "Te SLNS-LSTM technique has been executed over the medical MRI images obtained from online repositories. Moreover, the experimentation is performed onMRI images of variable size. It is observed that the algorithm has exhibited better performance for smaller-size images than other algorithms. Te self-learning approach is being\nevaluated through various benchmarks, including sensitivity, specifcity, accuracy, and F1- Score. On the one hand, the experimental values of true positive values determine how well the self-learning approach correctly recognizes the abnormality.\nMoreover, the true negative determines how well the proposed method accurately identifes the nontumor areas in the human brain. Te false-positive rate determines how often the proposed approach fails to recognize the tumor region correctly. Furthermore, the false-negative rate determines how often the proposed method fails to recognize the nontumor region correctly. Based on TP, TN, FP, and FN values are used to assess the values on the experimentation of the proposed approach for several rounds, and the accuracy is assessed accordingly.\nTe proposed self-learning model is initially trained with 20% of the dataset with the labeled data, and the model is designed to learn from the experimental outcome consistently. Te SLNS model would exhibit higher learning factors at initial epochs and lesser at later stages as the model would have gained sufcient knowledge for abnormality identifcation. Te learning rate of the model is presented in Figure 6 over 50 epochs. It can be observed that the model\nhas attained a reasonable learning factor of 0.08 at 38 epochs. However, the learning rate is further reduced later in experimentation by accruing the knowledge from experimental studies.\nTe other hyperparameters, such as the training and validation loss and the training and validation accuracies, determine the model\u2019s performance concerning the underftting and overftting situations in training the model. Underftting happens when a machine does not learn from the data and does not generalize efectively across the validation data. Te training accuracy plot could be fatter or have signifcant loss values, indicating that the model did not learn the training samples. Overftting occurs when a model has learned excessively from the training samples, resulting in unpredictability while evaluating the validation data. Te training loss plot falls as the number of epochs increases, and the validating loss plot drops to a level before rising. Te corresponding graphs of loss and accuracy measures are shown in Figure 7.\nTe experimental outcome of the SLNS-LSTM techniques is compared with its counterparts, and the tabulated values are presented in Table 4. Te performance of the SLNS with the LSTM algorithm is superior to that of the SLNS alone. Furthermore, there is a noticeable improvement in accuracy with almost the same level of training.Te confusion matrix of the current study is presented in Figure 8.\nTe computational latency of the proposed approach is assessed through the execution time.Te proposed approach has better performance when compared to others. However, there is a technical tradeof, such as execution time. Te execution time of the proposed approach is slightly more than that of the HARIS algorithm. Nevertheless, the proposed approach has exhibited better accuracy for MRI images. Te impact of the tumor is assessed at the tumor core, whole tumor, and enhanced tumor to identify the\ntumor\u2019s progress in treating the patients. Consequently, the proposed approach would efectively identify the tumor\u2019s growth and help provide better treatment to the patients. Te enhanced tumor in the tumor region is suspected to be spread compared to the earlier diagnosis of the ailment of the corresponding patient.\nFigure 9 represents the outcomes at each stage of the proposed algorithm\u2019s execution over the Jupiter notebook 5.7 software. Te leftmost image represents the original image. Te second image from the left denotes the segmented image representing the tumor core. Te third image is the approximate whole tumor. Te fourth image denotes the enhanced tumor whose area is larger than the tumor core. Te texture-based information is signifcant in determining the impact of the tumor and the enhanced tumor region from the 2D MRI image.\nTable 5 presents the analysis of the tumor\u2019s impact concerning the texture of the tumor region. Te outcome is also highlighted by applying the colormap to the resultant efect based on the tumor region\u2019s texture values. Tumor\nCore designates the actual tumor region where the impact is signifcantly observed. Te enhanced tumor designates the less impacted region based on texture-based information. Te whole tumor designates the entire tumor region from\nthe MRI image. Te values might have deviated from the ground facts, and the erroneous index has been indicated along with each computed damaged index [48].\nWith the change in food habits and environmental conditions, there are multiple diferent diseases that human beings are undergoing. Consequently, new methods that include artifcial intelligence and robust algorithms can work with minimal training to support medical decision-making. Moreover, approaches such as convolution neural networks and fuzzy recurrent neural networks need tremendous training in the existing cases to attain better accuracy. On the one hand, the proposed method productive can recognize the abnormality with high precision with the knowledge acquired from self-learning from the previous cases. Te algorithm would keep on enriching the performance after that. In the current study, various performance contribution techniques like dropout factor and batch normalization techniques are not performed in the current study. Te hyperparameters fnetuning would also assist in better performance of the model. Te feature selection techniques like gray-level co-occurrence matrix might be used in future models as feature engineering would have a signifcant impact on the performance of the model. Te current models lack the above-discussed performance optimization mechanism that has resulted in an accuracy of 87.9%, which could be further improved by fne-tuning the same.\nOn the other hand, the self-learning algorithm relies on the HARIS algorithm for automated image segmentation over multiple iterations. Moreover, long- and short-term memory is used with the recurrent neural network for handling and preserving the state information of irrational long-term dependencies for predicting the time series data. In this experiment, the proposed approach has outperformed when compared with other existing self-learningbased algorithms. By incorporating the LSTM-based approach, the algorithm would perform much faster in assessing the tumors\u2019 progress and have better accuracy in diferentiating the tumors and nontumor regions compared to its counterparts."
        },
        {
            "heading": "6. Conclusions",
            "text": "Te current research examines the role of long- and shortterm memory in improving the efciency of self-learning network-based classifcation by feeding the network state information from an MRI picture. Te insights from the pictures produced by the variational autoencoder are used as input for the tumor model\u2019s diferential categorization. Furthermore, the self-learning technique can identify tumor progression with less training, resulting in quicker execution than its competitors. Self-learning models use less computer resources since they require minimum training and make\nthe model acceptable for tumor diagnosis. Te experimental results showed a decent accuracy of 89.7%. Te proposed approach has outperformed other machine learning models\u2019 accuracy and execution time. Te current study is confned to a limited number of samples for the training and testing purposes. Te images are generated by the variational autoencoder for the training purpose. Te proposed model has yielded an acceptable performance, but by optimizing the hyperparameters, the accuracy of the model can be further enhanced.\nTe SLNS model\u2019s performance has been greatly improved by including the LSTM module. However, the suggested model\u2019s performance may be improved further by using bi-directional LSTM and self-labeling techniques. Optimizing the class weights at each iteration will result in a promising result that may be explored for future perspectives.Te deep variational autoencoder produces images of comparable quality to the variational autoencoder alone. Te deep variational autoencoder, on the other hand, requires more computer resources than the other standard techniques. Tis future direction would assist in building a robust model that could efciently detect the progress of the brain tumor. Te earlier analysis of the tumor impact would assist in providing the appropriate treatment and decision-making."
        },
        {
            "heading": "Data Availability",
            "text": "No data were provided for the current study."
        },
        {
            "heading": "Conflicts of Interest",
            "text": "Te authors declare that they have no conficts of interest."
        },
        {
            "heading": "Acknowledgments",
            "text": "Tis work was supported by the Deanship of Scientifc Research, Vice Presidency for Graduate Studies and Scientifc Research, King Faisal University, Saudi Arabia. [Grant No. 1929]."
        }
    ],
    "title": "Variational Autoencoders-BasedSelf-Learning Model for Tumor Identification and Impact Analysis from 2-D MRI Images",
    "year": 2023
}