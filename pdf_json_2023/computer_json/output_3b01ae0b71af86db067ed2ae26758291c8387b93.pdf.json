{
    "abstractText": "The WASSA 2023 shared task on predicting empathy, emotion and other personality traits consists of essays, conversations and articles in textual form and participants\u2019 demographic information in numerical form. To address the tasks, our contributions include (1) converting numerical information into meaningful text information using appropriate templates, (2) summarising lengthy articles, and (3) augmenting training data by paraphrasing. To achieve these contributions, we leveraged two separate T5-based pre-trained transformers. We then fine-tuned pre-trained BERT, DistilBERT and ALBERT for predicting empathy and personality traits. We used the Optuna hyperparameter optimisation framework to fine-tune learning rates, batch sizes and weight initialisation. Our proposed system achieved its highest performance \u2013 a Pearson correlation coefficient of 0.750 \u2013 on the conversation-level empathy prediction task1. The system implementation is publicly available at https: //github.com/hasan-rakibul/ WASSA23-empathy-emotion.",
    "authors": [
        {
            "affiliations": [],
            "name": "Md Rakibul Hasan"
        },
        {
            "affiliations": [],
            "name": "Md Zakir Hossain"
        },
        {
            "affiliations": [],
            "name": "Tom Gedeon"
        },
        {
            "affiliations": [],
            "name": "Susannah Soon Shafin Rahman"
        }
    ],
    "id": "SP:cc6744aca3111ae00d626068d90b1792de4e6b56",
    "references": [
        {
            "authors": [
                "Takuya Akiba",
                "Shotaro Sano",
                "Toshihiko Yanase",
                "Takeru Ohta",
                "Masanori Koyama."
            ],
            "title": "Optuna: A nextgeneration hyperparameter optimization framework",
            "venue": "Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data",
            "year": 2019
        },
        {
            "authors": [
                "Karen Aldrup",
                "Bastian Carstensen",
                "Uta Klusmann."
            ],
            "title": "Is empathy the key to effective teaching? a systematic review of its association with teacher-student interactions and student outcomes",
            "venue": "Educational Psychology Review, 34(3):1177\u20131216.",
            "year": 2022
        },
        {
            "authors": [
                "Valentin Barriere",
                "Shabnam Tafreshi",
                "Jo\u00e3o Sedoc",
                "Sawsan Alqahtani."
            ],
            "title": "WASSA 2022 shared task: Predicting empathy, emotion and personality in reaction to news stories",
            "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjec-",
            "year": 2022
        },
        {
            "authors": [
                "Valentin Barriere",
                "Shabnam Tafreshi",
                "Jo\u00e3o Sedoc",
                "Salvatore Giorgi."
            ],
            "title": "WASSA 2023 shared task: Predicting empathy, emotion and personality in interactions and reaction to news stories",
            "venue": "Proceedings of the 13th Workshop on Computational Approaches",
            "year": 2023
        },
        {
            "authors": [
                "Yue Chen",
                "Yingnan Ju",
                "Sandra K\u00fcbler."
            ],
            "title": "IUCL at WASSA 2022 shared task: A text-only approach to empathy and emotion detection",
            "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analy-",
            "year": 2022
        },
        {
            "authors": [
                "Narang",
                "Gaurav Mishra",
                "Adams Yu",
                "Vincent Zhao",
                "Yanping Huang",
                "Andrew Dai",
                "Hongkun Yu",
                "Slav Petrov",
                "Ed H. Chi",
                "Jeff Dean",
                "Jacob Devlin",
                "Adam Roberts",
                "Denny Zhou",
                "Quoc V. Le",
                "Jason Wei"
            ],
            "title": "Scaling instruction-finetuned language models",
            "year": 2022
        },
        {
            "authors": [
                "Jean Decety",
                "Philip L Jackson."
            ],
            "title": "The functional architecture of human empathy",
            "venue": "Behavioral and cognitive neuroscience reviews, 3(2):71\u2013100.",
            "year": 2004
        },
        {
            "authors": [
                "Flor Miriam Del Arco",
                "Jaime Collado-Monta\u00f1ez",
                "L. Alfonso Ure\u00f1a",
                "Mar\u00eda-Teresa Mart\u00edn-Valdivia"
            ],
            "title": "Empathy and distress prediction using transformer multi-output regression and emotion analysis with an ensemble of supervised and zero-shot",
            "year": 2022
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Priyanka Dey",
                "Roxana Girju."
            ],
            "title": "Enriching deep learning with frame semantics for empathy classification in medical narrative essays",
            "venue": "Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI), pages",
            "year": 2022
        },
        {
            "authors": [
                "Jesse Dodge",
                "Gabriel Ilharco",
                "Roy Schwartz",
                "Ali Farhadi",
                "Hannaneh Hajishirzi",
                "Noah Smith."
            ],
            "title": "Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping",
            "venue": "arXiv preprint arXiv:2002.06305.",
            "year": 2020
        },
        {
            "authors": [
                "Soumitra Ghosh",
                "Dhirendra Maurya",
                "Asif Ekbal",
                "Pushpak Bhattacharyya."
            ],
            "title": "Team IITPAINLPML at WASSA 2022: Empathy detection, emotion classification and personality detection",
            "venue": "Proceedings of the 12th Workshop on Computational",
            "year": 2022
        },
        {
            "authors": [
                "Bhanu Prakash Reddy Guda",
                "Aparna Garimella",
                "Niyati Chhaya."
            ],
            "title": "EmpathBERT: A BERT-based framework for demographic-aware empathy prediction",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computa-",
            "year": 2021
        },
        {
            "authors": [
                "Bhautesh Dinesh Jani",
                "David N Blane",
                "Stewart W Mercer."
            ],
            "title": "The role of empathy in therapy and the physician-patient relationship",
            "venue": "Complementary Medicine Research, 19(5):252\u2013257.",
            "year": 2012
        },
        {
            "authors": [
                "Allison Lahnala",
                "Charles Welch",
                "Lucie Flek."
            ],
            "title": "CAISA at WASSA 2022: Adapter-tuning for empathy prediction",
            "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis, pages 280\u2013285,",
            "year": 2022
        },
        {
            "authors": [
                "Damilola Omitaomu",
                "Shabnam Tafreshi",
                "Tingting Liu",
                "Sven Buechel",
                "Chris Callison-Burch",
                "Johannes Eichstaedt",
                "Lyle Ungar",
                "Jo\u00e3o Sedoc."
            ],
            "title": "Empathic conversations: A multi-level dataset of contextualized conversations",
            "venue": "arXiv preprint",
            "year": 2022
        },
        {
            "authors": [
                "Shenbin Qian",
                "Constantin Orasan",
                "Diptesh Kanojia",
                "Hadeel Saadany",
                "F\u00e9lix Do Carmo."
            ],
            "title": "SURREY-CTS-NLP at WASSA2022: An experiment of discourse and sentiment analysis for the prediction of empathy, distress and emotion",
            "venue": "Pro-",
            "year": 2022
        },
        {
            "authors": [
                "Victor Sanh",
                "Lysandre Debut",
                "Julien Chaumond",
                "Thomas Wolf."
            ],
            "title": "DistilBERT, a distilled version of bert: smaller, faster, cheaper and lighter",
            "venue": "arXiv preprint arXiv:1910.01108.",
            "year": 2019
        },
        {
            "authors": [
                "Micol Spitale",
                "Sarah Okamoto",
                "Mahima Gupta",
                "HAO Xi",
                "Maja J Matari\u0107."
            ],
            "title": "Socially assistive robots as storytellers that elicit empathy",
            "venue": "ACM Transactions on Human-Robot Interaction (THRI), 11(4):1\u201329.",
            "year": 2022
        },
        {
            "authors": [
                "Shabnam Tafreshi",
                "Orphee De Clercq",
                "Valentin Barriere",
                "Sven Buechel",
                "Jo\u00e3o Sedoc",
                "Alexandra Balahur."
            ],
            "title": "WASSA 2021 shared task: Predicting empathy and emotion in reaction to news stories",
            "venue": "Proceedings of the Eleventh Workshop on Computational",
            "year": 2021
        },
        {
            "authors": [
                "Himil Vasava",
                "Pramegh Uikey",
                "Gaurav Wasnik",
                "Raksha Sharma."
            ],
            "title": "Transformer-based architecture for empathy prediction and emotion classification",
            "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Thomas Wolf",
                "Lysandre Debut",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Tim Rault",
                "R\u00e9mi Louf",
                "Morgan Funtowicz"
            ],
            "title": "HuggingFace\u2019s transformers: State-ofthe-art natural language processing",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis, pages 536\u2013541 July 14, 2023 \u00a92023 Association for Computational Linguistics\nThe WASSA 2023 shared task on predicting empathy, emotion and other personality traits consists of essays, conversations and articles in textual form and participants\u2019 demographic information in numerical form. To address the tasks, our contributions include (1) converting numerical information into meaningful text information using appropriate templates, (2) summarising lengthy articles, and (3) augmenting training data by paraphrasing. To achieve these contributions, we leveraged two separate T5-based pre-trained transformers. We then fine-tuned pre-trained BERT, DistilBERT and ALBERT for predicting empathy and personality traits. We used the Optuna hyperparameter optimisation framework to fine-tune learning rates, batch sizes and weight initialisation. Our proposed system achieved its highest performance \u2013 a Pearson correlation coefficient of 0.750 \u2013 on the conversation-level empathy prediction task1. The system implementation is publicly available at https: //github.com/hasan-rakibul/ WASSA23-empathy-emotion."
        },
        {
            "heading": "1 Introduction",
            "text": "Empathy refers to an individual\u2019s capacity to comprehend and express appropriate emotions in response to others\u2019 emotions, perspectives and beliefs (Decety and Jackson, 2004). This ability can foster relationships and reduce stress and unhappiness among individuals through interaction. The importance of empathy is evident across a broad range of real-life human interactions, such as patient-doctor (Jani et al., 2012), teacher-student (Aldrup et al., 2022) and human-robot (Spitale et al., 2022) interactions.\nThe Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis\n1At the time of writing this paper, official rankings on any tasks and evaluations of several tasks in which we participated have not been published yet.\n(WASSA) has organised a \u201cShared Task on Empathy Detection, Emotion Classification and Personality Detection in Interactions\u201d in 2023 (Barriere et al., 2023). The challenge involves predicting empathy, emotion and personality traits from two types of datasets: essay and conversation. The essay-level dataset consists of essays written by study participants in response to news articles involving harm to individuals, groups or other entities. The conversation-level dataset includes textual conversations between participants regarding the news articles. In addition to the textual data (essays and conversations), the datasets also provide demographic and personal information in numerical form. We participated in four tracks of the 2023 challenge, which involves predicting (1) empathy, personality and interpersonal reactivity index from the essay-level dataset and (2) empathy and emotion from the conversation-level dataset.\nWASSA 2023 challenge extends from the 2022 challenge (Barriere et al., 2022) that involved predictions from only an essay-level dataset. Participants in 2022 challenge, such as Vasava et al. (2022); Chen et al. (2022); Qian et al. (2022); Del Arco et al. (2022); Lahnala et al. (2022) and Ghosh et al. (2022), employed transformer-based architectures, such as BERT (Devlin et al., 2018). Transformer-based models were also found to be the best-performing model in the WASSA 2021 shared task on empathy prediction (Tafreshi et al., 2021). Apart from WASSA competition, transformer models are also used in predicting empathy in essays written by medical students about simulated patient-doctor interactions (Dey and Girju, 2022).\nTransformer models are deemed highly suitable for undertaking text-based empathy prediction owing to their inherent ability to effectively capture long-range dependencies through attention mechanism (Vaswani et al., 2017). Fine-tuning pretrained transformers harnesses prior knowledge,\n536\nleading to enhanced performance while minimising training time. Qian et al. (2022) reported the best performance by just fine-tuning a BERT-based model in their system for the WASSA 2022 shared task. We, therefore, choose to fine-tune pre-trained transformers to predict empathy and personality traits in this challenge. In our prediction pipeline, we utilise numerical information from the datasets, such as participants\u2019 demographic information and income, because previous research by Guda et al. (2021) showed demographic information is an important cue in text-based empathy prediction.\nOverall, this paper has made the following contributions: (1) we use novel strategies to incorporate numerical demographic and other data in the text-based prediction pipeline, (2) we summarise longer text sequences to fit into the pipeline, and (3) we augment training samples by paraphrasing the textual data."
        },
        {
            "heading": "2 System description",
            "text": "The general prediction system for essay-level tasks is illustrated in Figure 1. In the case of conversation-level tasks, demographic and other personal information are not available in the conversation-level dataset. In that case, our prediction models involve only conversations and summarised articles, followed by paraphrasing to augment the training dataset."
        },
        {
            "heading": "2.1 Number to text mapping",
            "text": "We first discarded data points from the datasets where any component is missing. The data collection process, along with the questionnaires used in the WASSA 2023 datasets, has been detailed in the work of Omitaomu et al. (2022). Based on the reported distribution of demographic information, we have mapped numerical values of gender, education level and race to their corresponding textual information as illustrated in Table 1.\nAll the textual features were concatenated in the order of appearance, and this combined feature is referred to as the demographic feature throughout this paper. We further concatenated the demographic feature with the essay texts to create the demographic_essay feature."
        },
        {
            "heading": "2.2 Article summarisation",
            "text": "The converted article text comprised long sequences with a maximum length of 20,047 characters. In contrast, the demographic_essay feature\nhad a maximum of 956 characters, resulting in 236 tokens. Since the BERT tokeniser we used can process a maximum of 512 tokens, the entire article text cannot be processed in its current form. Consequently, we generated summaries of the articles. We employed flan-t5-base-samsum2, which is a fine-tuned variant of the model proposed by Chung et al. (2022).\nThe maximum length of the summarised articles was 987 characters. Considering that the demographic_essay feature contained 956 characters, resulting in 236 tokens, it seems plausible that incorporating the additional 987 characters of the article summary would be within the limit of BERT\u2019s maximum token length of 512."
        },
        {
            "heading": "2.3 Data augmentation",
            "text": "In order to augment the number of training samples, we utilised the chatgpt_paraphraser_on_T5_base3 to paraphrase the demographic, essay and article texts, effectively doubling the size of the dataset."
        },
        {
            "heading": "2.4 Model and hyperparameter tuning",
            "text": "We experimented with different hyperparameter configurations illustrated in Table 2. Specifically, we fine-tuned three transformer models from Huggingface (Wolf et al., 2019). In fine-tuning BERTbased models, weight initialisation plays a critical role (Dodge et al., 2020). Therefore, we also explored various seed values for CPU and GPU. For conversation-level tasks, the length of the conversation texts was comparatively shorter than that of essay-level tasks. Consequently, we investigated larger batch sizes in the range of 2 to 16.\n2https://huggingface.co/philschmid/ flan-t5-base-samsum\n3https://huggingface.co/humarin/ chatgpt_paraphraser_on_T5_base\nTo tune the hyperparameters, we utilised Optuna (Akiba et al., 2019), with the default treestructured Parzen estimator as the sampler and the median stopping rule as the pruner. The purpose of the pruner is to stop the tuning process on lowperforming hyperparameters early, both to save resources and to enable a greater focus on the bestperforming hyperparameters.\nThe best model, as determined by Optuna, was fine-tuned separately for each of the 14 regression tasks we participated. We employed the Pytorch AdamW optimiser with a default weight decay of 0.01 and betas of 0.9 and 0.999 to optimise the mean-squared-error loss function. To adjust the learning rate, we utilised a linear learning rate scheduler with zero warmup steps. We evaluated the prediction performance of all regression tasks in terms of the official Pearson correlation coefficient metric. We trained all essay-level models for 35 epochs and conversation-level models for 50 epochs. We determined the optimal number of epochs by monitoring the training loss until convergence was reached. We observed that the conversation-level dataset required more epochs for convergence, likely due to its larger size compared to the essay-level dataset."
        },
        {
            "heading": "2.5 Resources",
            "text": "We trained the model on a Tesla V100 32 GB GPU and used the following software packages: Transformers 4.28.1, Datasets 2.12.0, Pytorch 2.0.0, CUDA 11.8, Optuna 3.1.1, Numpy 1.24.3, Pandas 1.5.3, Plotly 5.14.1 with Python 3.10.10."
        },
        {
            "heading": "3 Result & analysis",
            "text": "To determine which feature sets are most effective for predicting empathy, we conducted an experiment in which we combined different features (essay, demographic, demographic_essay and article) and trained a DistilBERT (Sanh et al., 2019) model using 5-fold cross-validation for 10 epochs. Huggingface\u2019s tokeniser allowed us to tokenise pairs of sequences together by automatically concatenating them with a special [SEP] token. We then used these pairs of features and evaluated their performance, as presented in Table 3.\nConversion from the longer version of the article text to its summarised shorter version improved the performance (Table 3). We speculate that the reason for comparatively lower performance\nwith longer articles is the BERT tokeniser\u2019s limitation in accommodating longer texts. The inclusion of demographic and article features with the essay feature improved the model\u2019s overall performance. Therefore, we have incorporated demographic_essay and article features in our final model for the essay-level tasks.\nIt is worthwhile to note that the use of data augmentation techniques such as paraphrasing can introduce very similar samples in the dataset. It may bias the evaluation metrics, especially when similar samples are present in both the training and validation sets. The cross-validated Pearson correlation coefficient reported in Table 3 includes both the training and development sets with data augmentation (paraphrasing). However, in the process of tuning the model hyperparameters, we only used paraphrasing with the training set and not with the development set to prevent any potential bias caused by the duplication of similar samples.\nAmong the pre-trained transformer models we experimented with (BERT, DistilBERT and ALBERT), the BERT base model was the bestperforming model. Accordingly, we used BERT and tuned the other hyperparameters. We conducted 200 and 100 Optuna trials for essay-based empathy and distress prediction models, respectively. As the best set of hyperparameters is always found within the first 50 trials in the essay-level empathy and distress prediction models, 50 trials were run for other essay-level prediction models. In the case of conversation-level tasks, 100 Optuna trails were run. Table 4 presents the best set of hyperparameters found by the Optuna trials.\nWe investigated the relative importance of learning rate, seed and batch size (see Appendix A). Our findings are consistent with prior research by Dodge et al. (2020), which highlighted the impact of seed value on the fine-tuning performance of BERT-based models. However, the relative importance of hyperparameters varied across the prediction tasks, indicating the task-specific nature of finetuning pre-trained transformer models. It guided us to train separate models for separate tasks.\nWe observed that text summarisation and data augmentation (paraphrasing) improved model performance on the development set. On the test dataset, the final model achieved Pearson correlation coefficients of 0.750, 0.683 and 0.573 for conversation-level empathy, emotional polarity and emotional intensity prediction, respectively. For essay-level tasks, we achieved Pearson correlation coefficients of 0.187 and 0.344 for empathy and distress predictions, respectively. The average Pearson correlation coefficient for conversation-level tasks was 0.669, while it was 0.266 for essay-level empathy and distress prediction. The test performance of essay-level personality and interpersonal reactivity index predictions, as well as the official rankings, have not been published at the time of writing this paper. Nevertheless, our system achieved its best performance of a Pearson correlation coefficient of 0.750 in predicting conversation-level empathy."
        },
        {
            "heading": "4 Conclusion",
            "text": "Empathy is a vital human attribute to support and care for others. This paper outlines a comprehensive system for predicting empathy, emotion and other personality traits as part of the WASSA 2023 shared task. To this end, we first map the numerical demographic information into meaningful text since individuals\u2019 demographic information, such as age, sex and race, may affect their empathic capacity. Our system utilises pre-trained transformers to map numerical information into meaningful text, summarise longer text sequences, paraphrase text sequences to augment smaller training datasets and finally predict the degree of empathy and other personality traits."
        },
        {
            "heading": "Acknowledgements",
            "text": "This research was undertaken with the assistance of resources from the National Computational Infrastructure (NCI Australia), an NCRIS-enabled capability supported by the Australian Government."
        }
    ],
    "title": "Curtin OCAI at WASSA 2023 Empathy, Emotion and Personality Shared Task: Demographic-Aware Prediction Using Multiple Transformers",
    "year": 2023
}