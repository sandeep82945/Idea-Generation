{
    "abstractText": "The numbers of persons who can be enrolled by their iris patterns with no identity collisions is studied in relation to the biometric entropy extracted, and the decision operating threshold. The population size at which identity collision becomes likelier than not, given those variables, defines iris \u201ccapacity.\u201d The general solution to this combinatorial problem is derived, in analogy with the well-known \u201cbirthday problem.\u201d Its application to unique biometric identification on national population scales is shown, referencing empirical data from US NIST (National Institute of Standards and Technology) trials involving 1.2 trillion (1.2 \u00d7 10) iris comparisons. The entropy of a given person\u2019s two iris patterns suffices for global identity uniqueness.",
    "authors": [
        {
            "affiliations": [],
            "name": "John Daugman"
        }
    ],
    "id": "SP:8ad3d79da5dbde8947261c65118ce21fe919bbb8",
    "references": [
        {
            "authors": [
                "I. Kemelmacher-Shlizerman",
                "S.M. Seitz",
                "D. Miller"
            ],
            "title": "and E",
            "venue": "Brossard, \u201cThe MegaFace Benchmark: 1 million faces for recognition at scale,\u201d Int\u2019l. Conf. Comp. Vision & Patt. Recog., pp. 4873\u20134882",
            "year": 2016
        },
        {
            "authors": [
                "P. Grother",
                "M. Ngan",
                "K. Hanaoka"
            ],
            "title": "Ongoing Face Recognition Vendor Test (FRVT)",
            "venue": "Part 2: Identification\u201d, NISTIR 8238, National Institute of Standards and Technology (Bethesda)",
            "year": 2018
        },
        {
            "authors": [
                "P.J. Phillips",
                "A. Yates",
                "Y. Hu",
                "C. Hahn",
                "E. Noyes",
                "K. Jackson",
                "J. Cavazos",
                "G. Jeckeln",
                "R. Ranjan",
                "S. Sankaranarayanan",
                "J. Chen",
                "C. Castillo",
                "R. Chellappa"
            ],
            "title": "D",
            "venue": "White, and A.J. O\u2018Toole, \u201cFace recognition accuracy of forensic examiners, superrecognizers, and face recognition algorithms,\u201d Proc. Nat\u2019l. Acad. Sci., vol. 115 (24), pp. 6171\u20136176",
            "year": 2018
        },
        {
            "authors": [
                "S. Aiyar"
            ],
            "title": "AADHAAR: A Biometric History of India\u2019s 12-Digit Revolution",
            "venue": "New Delhi: Westland Publications",
            "year": 2017
        },
        {
            "authors": [
                "T. Cover",
                "J. Thomas"
            ],
            "title": "Elements of Information Theory",
            "venue": "2nd ed. New York: Wiley-Interscience",
            "year": 2006
        },
        {
            "authors": [
                "J. Daugman"
            ],
            "title": "Information Theory and the IrisCode,",
            "venue": "IEEE Trans. Info. Foren. Sec,",
            "year": 2015
        },
        {
            "authors": [
                "J. Daugman",
                "C. Downing"
            ],
            "title": "Radial correlations in iris patterns",
            "venue": "and mutual information within IrisCodes\u201d, IET Biometrics, vol. 8 (3), pp. 185\u2013189",
            "year": 2019
        },
        {
            "authors": [
                "J. Daugman"
            ],
            "title": "The importance of being random: statistical principles of iris recognition,",
            "venue": "Pattern Recognition,",
            "year": 2003
        },
        {
            "authors": [
                "P. Grother",
                "E. Tabassi",
                "G.W. Quinn"
            ],
            "title": "and W",
            "venue": "Salamon, \u201cIREX-I: Performance of Iris Recognition Algorithms on Standard Images.\u201d NIST Interagency Report 7629",
            "year": 2009
        },
        {
            "authors": [
                "P. Grother",
                "G.W. Quinn",
                "J.R. Matey",
                "M. Ngan",
                "W. Salamon",
                "G. Fiumara"
            ],
            "title": "and C",
            "venue": "Watson, \u201cIREX-III: Performance of Iris Identification Algorithms.\u201d NIST Interagency Report 7836, April 6",
            "year": 2012
        },
        {
            "authors": [
                "J. Daugman"
            ],
            "title": "C",
            "venue": "Downing, O.N. Akande, O.C. Abikoye, \u201cEthnicity and biometric uniqueness: iris pattern individuality in a West African database,\u201d IEEE Trans. Biometrics, Behavior, and Identity Science ",
            "year": 2023
        },
        {
            "authors": [
                "R. Snell",
                "M. Lemp"
            ],
            "title": "Clinical Anatomy of the Eye (2nd edition)",
            "venue": "London: Blackwell Science",
            "year": 1998
        },
        {
            "authors": [
                "S. Gong",
                "V.N. Boddeti",
                "A.K. Jain"
            ],
            "title": "On the capacity of face representation,",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "I. INTRODUCTION\nAPPLICANTS for Cambridge University undergraduatestudies in mathematics or computer science are asked sometimes in their College interviews to reason about the \u201cbirthday problem\u201d: how many people, chosen at random, must be assembled until it becomes more likely than not that at least one pair of them have the same birthday? Some students are surprised that the answer is only 23 people. Although arriving at the exact number requires a calculator, the reasoning is that N people make N(N \u2212 1)/2 possible pairings. Given that each pairing has probability 1/365 of sharing their birthday and 364/365 of not, the probability that none of the pairings share a birthday is approximately (364/365)N(N\u22121)/2, which is < 0.5 once N \u2265 23.\nThere is a clear analogy with biometric collision avoidance, which we can formulate as the:\nBiometric birthday problem: if some biometric technology is operating with a verification FMR (\u201cone-to-one\u201d False Match Rate), how many people, chosen at random, must be assembled until it becomes more likely than not that at least one pair of them have a biometric collision (are falsely matched to each other)?\nA good example is face recognition, tested across a broad variety of scenarios and using a wide range of image quality, for which a good performance benchmark corresponds to making just one verification False Match in 1,000 non-mated comparisons [1] [2] [3]. That accuracy standard is better than human (even \u201csuper-recogniser\u201d) performance in some circumstances [3]. Face recognition algorithms have improved greatly in recent years, in terms of Rank-1 identification rates [1] [2] in test protocols in which a correct match does always exist within a search gallery that is populated also with other\n1Dept. of Computer Science and Technology, Cambridge University, UK. www.CL.cam.ac.uk/users/jgd1000/ E-mail: John.Daugman@CL.cam.ac.uk\n\u201cdistractors\u201d. But even in the recent tests, the best algorithms do still make some False Matches to distractor images even when there are only 100 distractors [1] [2] despite the presence of a correct match within the gallery, that should instead actually be returned at Rank-1.\nLet us now consider the \u201cbiometric birthday problem\u201d for a face recognition algorithm performing at FMR = 0.001 when examining a gallery of non-mated faces. How large must this gallery get before False Matches become likelier than not, in all-versus-all comparisons? The answer: just 38. That number creates 38 \u00b7 37/2 = 703 possible pairings to consider, and (1 \u2212 0.001)703 = 0.495 so False Matches are then already likelier than not. When waiting at Passport Control (or some other such queue), it is entertaining to turn around, look at the first 38 persons standing behind oneself, and try to spot the pair of facial doppelga\u0308ngers [4] among them.\nBiometric deployments at a national or even prospectively at the planetary scale face a massively challenging biometric \u201cbirthday problem\u201d if they need to search for any duplicate identities, as was necessary in India when all 1.4 billion citizens were recently enrolled in a national ID programme for welfare distribution, government services, and subsidies (UIDAI: Unique IDentification Authority of India) [5]. Because enrollees had an incentive to acquire multiple identities and thereby issuance of multiple subsidies, every new enrollment had to be compared against all existing enrollments before an Aadhaar would be issued. This amounts to a search for identity collisions, all-versus-all, among an astronomical N(N\u22121)/2 pairings of persons. Obviously any attempt to do this by face recognition would drown in False Matches from the very beginning. There simply is not enough entropy, or randomness, in human face structure; the necessary functional purposes of major facial features (mouth, nose, ocular areas) constrain their possible randomness. The bilateral symmetry normally present in a face further reduces its entropy by half. The key idea, the fundamental factor underlying the power of biometric identification, is entropy [6] [7].\nWeak biometrics may be sufficient to enable \u201cone-to-one\u201d verification; stronger biometrics may enable identification in a search database of size N , \u201cone-to-few\u201d or \u201cone-to-many\u201d depending on N ; but de-duplication applications exemplify the birthday problem in that they are essentially \u201call-versus-all\u201d, and the number of False Match opportunities they must survive grows massively with N . In such deployments on a national scale, falsely detected or undetected identity collisions (even if few in percentage) would lead to reduced public confidence in and acceptance of the system, its impaired functionality, and legal problems caused both by undetected duplicates and\nar X\niv :2\n30 8.\n03 18\n9v 1\n[ cs\n.C R\n] 6\nA ug\n2 02\n3\n2\nfalsely detected ones. Table I presents, for a broad range of FMR levels spanning 15 orders-of-magnitude, how large N can get before collisions become likelier than not. Table I clearly shows that the demands for a minuscule FMR become extremely daunting once the population size N is even that of a small town, let alone a population of national, continental, or of planetary scale."
        },
        {
            "heading": "II. GENERAL SOLUTION FOR POPULATION BOUNDS",
            "text": "The number of pairings possible among N persons is N(N \u2212 1)/2 because each person can be paired with N \u2212 1 others, but half of these are redundant (e.g. Alice and Bob, then also Bob and Alice); hence the halving. If a biometric technology is operating at some verification False Match Rate FMR, then the probability of a given pairing not resulting in a False Match is (1\u2212FMR), and the probability that none of the possible pairings do so is (1\u2212FMR)N(N\u22121)/2. For what value of N does this expression become < 0.5, and therefore a biometric collision becomes likelier than not?\nWe will invoke a property of the base e \u201cnatural logarithm\u201d function loge=2.718...( ), commonly denoted ln( ). We seek:\n(1\u2212 FMR)N(N\u22121)/2 < 0.5 (1) ln ( (1\u2212 FMR)N(N\u22121)/2 ) < ln(0.5) (2)\nN(N \u2212 1) 2 ln(1\u2212 FMR) < \u22120.693 (3)\nNow using the power series expansion\nln(1 + x) = x\u2212 x 2\n2 +\nx3\n3 \u2212 x\n4\n4 + \u00b7 \u00b7 \u00b7 , (4)\nwe have ln(1+x) \u2248 x for small |x|, whether x \u2265 0 or x < 0. Basically this reflects the fact that the logarithm function is linear near where it crosses 0 at log(1), and the slope of this line is 1 if the base of the logarithm is e. Thus for any small FMR (say < 0.01), which also entails that N2 \u226b N , we have\n\u2212N(N \u2212 1) 2 FMR \u2272 \u22120.693 (5)\nN2 \u2273 1.386/FMR (6) N \u2273 \u221a 1.386/FMR (7)\nThis general (but approximated) solution can be confirmed by evaluating (1) exactly, using for N each of the corresponding FMR cases tabulated in Table I, insofar as the available tools of calculation can handle the combinatorial exponents required in (1) when N is large."
        },
        {
            "heading": "III. BIOMETRIC ENTROPY TO THE RESCUE",
            "text": "Entropy measures the complexity and randomness [6] that is present in (and between) random variables. Facial structure has limited capacity for randomness. The major facial features have a canonical standard configuration, usually with bilateral symmetry; the eyes are normally on opposite sides of the nose. Much greater randomness is found in iris patterns, and this is the origin of their legendary resistance to False Matches. Although often there do exist strong radial correlations within an iris, with mutual information as large as 0.3 bits per bit across radius [8], and also IrisCode bits at adjacent or nearby angles but a shared radial coordinate have \u201csticky oscillator\u201d correlations that reduce their entropy as much as 0.5 bits per bit [7], nevertheless the remaining entropy is vast. Fig. 1 illustrates this graphically in the bit streams that constitute the IrisCodes of four different eyes. How IrisCodes are computed has been revealed previously [9]. The two bit values are equiprobable, so when bits in IrisCodes from two different eyes are compared by XOR (Exclusive-OR) to detect whether they agree or disagree, these outcomes again are equiprobable, amounting to the toss of a fair coin.\nThe non-independence among the bits in a given IrisCode reduces their collective entropy from what would have been a maximum of 2,048 bits (if each bit corresponded to an independent \u201cfair coin toss\u201d Bernoulli trial) to only about 245 bits. Modelled as a \u201csticky oscillator\u201d Markov process [7], IrisCode bits exhibit a phase coherence that can persist across several bits. Despite such losses in entropy, enough entropy remains that the collision probability between two IrisCodes from different eyes attenuates by astronomical factors, for small reductions in the tolerated fraction of disagreeing bits.\n3"
        },
        {
            "heading": "IV. DISCUSSION",
            "text": "A good way to understand this effect intuitively is to consider tossing a fair coin in runs of 245 tosses, tallying each run\u2019s fraction of heads. The total number of possible outcome sequences is 2245 and each of these has the same probability, namely pi = 2\u2212245 (including, say, the \u201call heads\u201d sequence). The entropy [6] contained in these possible sequences is:\nH = \u2212 \u2211 i pi log2(pi) (8)\n= \u2212 2245\u2211 i=1 2\u2212245 log2(2 \u2212245) = 245 bits. (9)\nThe vast majority of these sequences will have a nearly equal mix of heads and tails. The fraction of possible sequences that have (say) fewer than 30% heads is less than one-billionth of the total. This combinatorial property when large entropy (245 bits) exists in a random variable is ultimately the reason why, for iris recognition, a match between two IrisCodes can be accepted even when (say) 30% of their bits disagree due to problematic image acquisition. Despite such a lenient criterion being so tolerant of noisy bits, the probability that such an accepted match would actually be a False Match is, indeed, less than 1 in a billion.\nThe huge exponents appearing in (9) (note that 2245 \u2248 1074) are key to understanding why sufficient entropy is the basis for biometric collision avoidance even at a planetary scale. A detailed tabulation of the relevant probability distributions, both densities and their cumulatives [9], with and without selecting for best matches after multiple image rotations to compensate for unknown head and camera tilt, is provided at [10] as a function of Hamming distance HD (fraction of bits that disagree in IrisCodes from two different eyes). This probability table enables us to predict how tolerant we can be of poor image acquisition (how large a fraction HD of disagreeing bits we can tolerate and still declare a match), without resulting in False Matches. The table [10] shows for acceptance criteria HD the resulting False Match probability, and its log10 (last two columns).\nTable II extracts coarser HD increments of 0.01 from [10] (first column), showing the corresponding FMR predictions (second column). By 2003 image databases were only large enough to perform about 10 million iris cross-comparisons [9] but distribution parameters could be estimated, implying 249 bits of entropy (slightly more than 245), predicting FMR performance very similar to what is shown in Table II. No False Matches were observed below roughly the HD = 0.33 criterion, for the small databases available. The predicted FMR values were generally dismissed with incredulity [11], because such FMR performance was unknown in other biometrics. But subsequently, other NIST researchers did actually perform billions [12] and then more than a trillion iris comparisons [13], obtaining FMR values in good agreement with those predictions, as reported in column 3.\nAn important cause of skepticism about the FMR performance levels shown in Table II, before they were eventually confirmed by NIST, was the existence of \u2018ground-truth\u2019 errors in early biometric databases that had created illusory identity\ncollisions. Apart from sloppy and na\u0131\u0308ve data collection, (e.g. incentivising paid student volunteers to change names and thereby enroll multiple times), there is an inherent risk in estimating FMR by intra-dataset cross-comparisons. If even just one of N subjects is enrolled under two different identities, whether deviously or just through an innocent clerical error, the estimated FMR then cannot be better than 2/N2. The measured threshold calibration of FMR such as tabulated in Table II must then approach a floor, corresponding to this illusory FMR, which cannot be reduced by any reasonable change in threshold, and indeed NIST [12] demonstrated this problem for (university-sourced) intra-dataset comparisons.\nNIST overcame this problem by performing inter-dataset comparisons: if two disjoint populations, of sizes (say) N and M in geographically remote places can be biometrically enrolled, then N \u00d7 M inter-comparisons become possible without the contaminating effect of ground-truth errors. NIST [13] acquired enrollment datasets for two populations \u201cvery well separated geographically and occupationally,\u201d one having 3.9 million iris images used as the gallery, and the other having 315,000 iris images used as probes to search against this entire gallery, asserting there was zero likelihood of co-membership. Thereby NIST performed N \u00d7 M = 1.2 trillion IrisCode comparisons, leading to the FMR results shown in Table II column 3 (from [13] p. 61) for various HD threshold criteria. This close confirmation of theory (column 2), manipulating FMR over a larger than million-fold range, is striking."
        },
        {
            "heading": "V. DEMOGRAPHIC SPECIFIC APPLICATION",
            "text": "Iris pattern entropy differs somewhat across ethnic groups [14]. For example, the anterior layer of the iris in persons of Sub-Saharan African descent contains a thick blanket of melanocytes [15] creating a coarser texture of crypts and craters, than the finer fibrous details typically visible in an iris of persons descended from more northern regions. Fig. 2 illustrates these entropy differences in samples from three demographies: West African; Irish-American; and Nordic.\nUsing image databases having particular ethnic demographics, it is possible to estimate quantitatively their characteristic entropies. Such calculations are needed in order to understand how many persons can be enrolled before identity clashes\n4\nin \u201call-versus-all\u201d cross-comparisons (at a given acceptance operating criterion), start to become likely. Fig. 3 illustrates this process for a new West African database of iris images [14] \u201cAFHIRIS\u201d, plotting the distribution of Hamming distances (HD, fraction of bits that disagree) between all possible pairings of IrisCodes for different eyes. The red curve is a\nplot of the following probability distribution prob(HD) for the fraction of Heads (HD) in a run of N tosses of a coin whose probability of Heads is p :\nprob(HD) = N !\nm!(N \u2212m)! pm(1\u2212 p)(N\u2212m) (10)\nwhere in this case N = 228, p = 0.5, and HD = m/N is the outcome fraction of N Bernoulli trials (e.g. observing m Heads within a run of N coin tosses). Measuring the std dev \u03c3 for an empirical distribution of HD scores from independent pairings tells us the equivalent number of tosses of a coin (having probability p of Heads), namely N = p(1 \u2212 p)/\u03c32. The empirical distribution has \u03c3 = 0.0331, with p \u2248 0.5 (mean HD) so each toss adds 1 bit of entropy. Therefore we estimate AFHIRIS biometric entropy as N = 228 bits. The fit in Fig. 3 between the empirical distribution data and the theoretical probability density curve (10) seems excellent.\nComparison of Empirical AFHIRIS and Theoretical Density Distributions\nAs was visible in Fig. 2 and investigated in [14], biometric entropy in iris patterns varies among ethnic groups. The range observed spans from about 225 bits to 265 bits. Those values impact the False Match Rates for any given operating point (with higher entropy reducing the FMR), and therefore they also affect how large a population of persons can be enrolled without identity collisions in all-versus-all cross-comparisons. Such a concept is sometimes called biometric \u201ccapacity\u201d [16] for a given modality and operating point. We can now apply the framework that was introduced at the beginning of this paper, the \u201cbiometric birthday problem,\u201d to calculate iris capacity across this observed range of entropies. For any given estimate of biometric entropy, the FMR at a given operating point can be calculated as described in [9] and tabulated in [10] (for the case of N = 245 bits of entropy). Using (7) we arrive at the numbers of persons who can be enrolled while identity collision still remains unlikely. These numbers are presented in Table III for two different HD operating thresholds and five estimates of entropy, always assuming single eye enrollment, to illustrate the combined effects of these variables.\n5\nA way to estimate the scalability of face recognition systems was proposed by [16]. They defined \u201cface capacity\u201d in terms of packing bounds: the ratio of the total volume in a representation space, to the volume that is required to represent individual faces in it (as separate spheres or ellipsoids). This yields an extreme upper bound estimate of capacity, because there is no way to ensure that the spheres or ellipsoids for different faces do not overlap. Such collisions or overlaps certainly occur for identical twins, and even for unrelated persons who are facial doppelga\u0308ngers (as illustrated in this collage [4] of examples.) Recent tests by NIST [2] show that current face recognition algorithms fail completely to distinguish between identical twins. About 1% of persons have an identical twin, so in any sufficiently broad sample, face representations must suffer identity clashes for at least those 1%. By contrast, it is well-known that the IrisCode produces as much distance between the encoded iris patterns of identical twins (or indeed between the two eyes of any given person) as between unrelated eyes [9]."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "Iris recognition is perhaps unique among biometrics in having clear mathematical foundations, enabling strong predictions about IrisCode collision likelihood as a function of the decision threshold. As shown in Table II, for decision criteria in which no more than about 31% of the IrisCode bits are allowed to disagree when declaring a match (which is a very noise-tolerant criterion), the predicted FMR attenuates by almost a factor of 10 for each additional 1% reduction in the tolerated amount of bit disagreement. This extraordinary fact seems not to be generally understood or appreciated; but it is a direct result of using high-entropy random variables in biometric codes. A critical lesson emerging here is the same as a lesson from cryptography: the great power of randomness, if you can get enough of it.\nAs confirmed independently by NIST in [13], the slope of the IrisCode Decision Error Trade-off curves is so flat that the FMR can be lowered by a factor of 10,000 to 100,000 while not even doubling the False non-Match rate (FnMR). A consequence of this relationship is that only small costs in increased FnMR need be paid, by lowering HD threshold, in order to increase greatly the size of a biometrically enrolled population without suffering collisions. Thus for IrisCodes from any two different eyes, the probability of HD \u2264 0.29 is about 10\u221210. If we also exploit the fact that a person\u2019s two eyes generate IrisCodes that are almost completely independent,\nspecifying 0.29 as a match criterion binocularly would yield a fusion FMR of about 10\u221220. Equation (7) shows us that this is how the planetary human population can survive the \u201cbiometric birthday problem\u201d: it is unlikely that even a single pairing among 12 billion persons (despite the vast numbers of possible pairings) would disagree in \u2264 29% of their IrisCode bits for both pairs of eyes. Thus speaks biometric entropy."
        }
    ],
    "title": "Understanding Biometric Entropy and Iris Capacity: Avoiding Identity Collisions on National Scales",
    "year": 2023
}