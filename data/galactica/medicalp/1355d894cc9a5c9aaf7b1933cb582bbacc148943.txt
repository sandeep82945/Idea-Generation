Macrocyclic peptides are an emerging therapeutic modality, yet computational approaches for accurately sampling their diverse 3D ensembles remain challenging due to their conformational diversity and geometric constraints. Here, we introduce RINGER, a diffusion-based transformer model for sequence-conditioned generation of macrocycle structures based on internal coordinates. RINGER provides fast backbone sampling while respecting key structural invariances of cyclic peptides. Through extensive benchmarking and analysis against gold-standard conformer ensembles of cyclic peptides generated with metadynamics, we demonstrate how RINGER generates both high-quality and diverse geometries at a fraction of the computational cost. Our work lays the foundation for improved sampling of cyclic geometries and the development of geometric learning methods for peptides. 1 conclusions In summary, we present RINGER, a new approach for generating macrocycle conformer ensembles that significantly improves sample quality, diversity, and inference. By leveraging specific benefits of diffusion-based models, we demonstrate how a transformer-based architecture with a cyclic positional encoding results in significant gains over Cartesian-based equivariant models and widely-used distance geometry-based algorithms for both unconditional and conditional structure generation. The present work paves the way for more efficient and accurate computational exploration of conformational
space. We anticipate that this approach will more broadly enable rational macrocycle discovery through further development. 7 code and data availability All code for training, sampling, and evaluation in this study are available at http://www.github.com/Genentech/RINGER. We include the exact training and test data splits and trained model. The CREMP dataset [28] is available for download from https://zenodo.org/record/7931445. Acknowledgments and Disclosure of Funding We thank Ben Sellers and Christian Cunningham for insightful discussions on macrocycles and peptide therapeutics. We also thank members of the Departments of Peptide Therapeutics and Discovery Chemistry for helpful feedback and discussions. This research is sponsored by Genentech, Inc. All authors are employees of Genentech, Inc. and shareholders of Roche. a glossary  b dataset description  c training details We use the discrete-time diffusion model from Wu et al. [44] that formulates the forward transition probability using a wrapped normal distribution,
q (xt | xt−1) = Nwrapped ( xt; √ 1− βtxt−1, βtI )
= 1
βt √ 2π ∑ k∈Zn exp
( − ∥∥xt −√1− βtxt−1 + 2πk∥∥2
2β2t
) (4)
instead of a standard normal distribution [38], where xt represents the noised internal coordinates (bond angle and torsion) at time step t. The diffusion model, pΞ(xt−1 | xt), parameterized by Ξ, reverses the process to denoise a wrapped normal distribution toward the data distribution. In the conditional setting, we further guide the diffusion process by learning pΞ (xt−1 | xt,G) in order to draw samples from the ensemble for a specific macrocycle, G. We use the same cosine variance schedule as Wu et al. [44] and Nichol and Dhariwal [63] for βt ∈ (0, 1)Tt=1, but with significantly fewer time steps (typically, T = 20). pΞ(xt−1 | xt) and pΞ (xt−1 | xt,G) are trained using the simplified objective from Ho et al. [54] to train a neural network, ϵΞ(xt, t), to predict the noise present at a given time step by minimizing a smooth L1 loss [64] wrapped by w(x) = (x+π) mod (2π)−π:
dw = w ( ϵ− ϵΞ ( w (√ ᾱtx0 + √ 1− ᾱtϵ ) , t ))
Lw = 1
N N∑ i=1
{ 0.5
d2w,i βL
if |dw,i| < βL |dw,i| − 0.5βL otherwise
(5)
with βL = 0.1π as the transition point between L1 and L2 regimes [44], αt = 1 − βt, and ᾱt = ∏t s=1 αs. We sample time steps uniformly from t ∼ U(0, T ) during training and shift the bond angles and dihedrals using the element-wise means from the training data. d sampling details We also use the sampling scheme from Wu et al. [44]. During inference, we first sample xT from a wrapped normal distribution and iteratively generate x0 from t = T to t = 1 using
xt−1 = w
( 1
√ αt
( xt −
1− αt√ 1− ᾱt ϵΞ(xt, t)
) + σtx ) (6)
where σt = √ βt(1− ᾱt−1)/(1− ᾱt) is the variance of the reverse process and z = N (0, I) if t > 1 and z = 0 otherwise. e model details and hyperparameters Our model is a BERT transformer [57] with cyclic relative positional encodings described in Equations (1) and (2). The model input is a sequence of internal coordinates (and atom features for the conditional model). We linearly upscale the two-dimensional model input (bond angles and dihedrals) and separately upscale the atom features. Angles and atom features are then concatenated. The time step is embedded using random Fourier embeddings [55] and added to the upscaled input. The combined embeddings are passed through the BERT transformer, the output of which is passed through a two-layer feed-forward network with GELU activation and layer normalization. Relevant hyperparameters are shown in Table 4. To condition on the atom sequence, we encode each atom using features of the atom itself and a Morgan fingerprint representation of the side chain attached to the atom (including the atom itself). The atom features include the atomic number, a chiral tag (L, D, or no chirality), aromaticity, hybridization, degree, valence, number of hydrogens, charge, sizes of rings that the atom is in, and the number of rings that the atom is in. The Morgan fingerprint is a count fingerprint with radius 3 and size 32. F Optimization for Back Conversion to Cartesian Ring Coordinates
To convert from the set of redundant internal coordinates predicted by the model back to Cartesian coordinates, we solve the optimization in Equation (3) to obtain a set of Cartesian coordinates that exactly satisfies the known bond distances in the ring. To demonstrate that this procedure is robust to noise, we repeatedly embed 4-, 5-, and 6-mer backbones in 3D using RDKit distance geometry, extract their (redundant) internal coordinates, and add noise to the dihedral angles at different noise scales (standard deviation of a normal distribution) while ensuring that angles always remain in the [−π, π) range. This creates a set of inconsistent, redundant dihedral angles, i.e., there exists no direct correspondence in Cartesian coordinates. We recover a possible Cartesian configuration using Equation (3) and compute RMSD and TFD for the ring atoms compared to the “true” internal coordinates from the RDKit geometry. Figure 5 shows that even moderate errors (∼0.1 rad) result in very small errors in terms of both RMSD (∼0.1Å) and TFD (∼0.02). Notably, the optimization problem in Equation (3) is non-convex and requires a suitable initial guess to perform well. We assign this initial guess by obtaining a Cartesian geometry using the approach of sequentially setting atom positions according to the sequence of bond distances, angles, and torsions starting from one of the atoms in the ring. The starting atom is selected such that the redundant bond distance most closely matches the true bond distance (obtained from the training data). Improving the initial guess could be another direction for future research. g software All experiments were performed using Python and standard numerical libraries. For cheminformatics analysis, all molecules were processed using either OpenEye Applications and Toolkits [62] or the open-source cheminformatics library RDKit [65]. We implemented all experiments in Python using PyTorch [66] and PyTorch Lightning [67]. Transformers were implemented using BERT models within HuggingFace Transformers [68]. h hardware Each model was trained on a single NVIDIA A100 GPU with 80 GB VRAM using 12 CPUs for data loading and 96 GB of memory. i evaluation To measure both diversity and quality of the generated ensembles, we follow previous work and leverage four RMSD-based metrics [33, 36] with the difference that we only evaluate RMSD on macrocycle atoms. The recall-based Coverage metric measures the percentage of correctly generated conformers at a certain RMSD threshold, δRMSD. For a ground-truth ensemble C and a generated ensemble Ĉ:
RMSD-COV-R(Ĉ, C) = 1 |C| ∣∣∣{c ∈ C : ∃ĉ ∈ Ĉ,RMSD(ĉ, c) ≤ δRMSD}∣∣∣ (7) The recall-based Matching metric measures the average RMSD across the closest-matching (minimum-RMSD) generated conformer for each ground-truth conformer:
RMSD-MAT-R(Ĉ, C) = 1 |C| ∑ c∈C min ĉ∈Ĉ RMSD(ĉ, c) (8)
The other two RMSD-based metrics are precision metrics that are defined identically, except that the ground-truth and generated ensembles are switched, and therefore constitute a measure of how many generated conformers are of high quality. Analogous to the RMSD-based metrics, we define four metrics based on torsion fingerprint deviation (TFD) [19, 61] to measure diversity and quality in terms of the torsional profiles of the generated rings:
TFD-COV-R(Ĉ, C) = 1 |C| ∣∣∣{c ∈ C : ∃ĉ ∈ Ĉ,TFD(ĉ, c) ≤ δTFD}∣∣∣ (9) TFD-MAT-R(Ĉ, C) = 1
|C| ∑ c∈C min ĉ∈Ĉ TFD(ĉ, c) (10)
TFD quantifies how well the macrocycle torsion angles match between two conformers and is given by [19]:
TFD(ĉ, c) = 1
n n∑ i=1 1 π |w (τi(ĉ)− τi(c))| (11)
where τi(c) extracts the i-th macrocycle torsion angle of conformer c and w(·) ensures that the deviation is wrapped correctly around the [−π, π) boundary. Each torsion deviation is normalized by the maximum (absolute) deviation, π, so that TFD lies in [0, 1]. j conformer generation baselines RDKit ETKDGv3 RDKit baselines used ETKDGv3 [18, 19] with macrocycle torsion preferences. We first embedded up to 2K conformers (where K is the number of true conformers) using EmbedMultipleConfs with random coordinate initialization (useRandomCoords=True), which has been shown to be beneficial for generating macrocycle geometries [19]. Conformers were subsequently optimized using MMFF94 [69] as implemented in RDKit and sorted by energy. Finally, the sorted conformers were filtered based on heavy-atom RMSD with a threshold of 0.1Å. OpenEye OMEGA: Macrocycle Mode OMEGA baselines were performed using OpenEye Applications (2022.1.1) with OMEGA (v.4.2.0) [21, 22] in macrocycle mode [23]. Conformational ensembles were generated with the following macrocycle settings: maxconfs=2K, ewindow=20, rms=0.1, dielectric_constant=5.0, where K corresponds to the number of ground truth conformers from the original CREST ensemble in the CREMP dataset. The dielectric constant was set to 5.0 (chloroform) to most closely mimic the implicit chloroform solvation used in CREMP.