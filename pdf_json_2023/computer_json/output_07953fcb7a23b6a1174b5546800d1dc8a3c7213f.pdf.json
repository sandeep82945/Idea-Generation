{
    "abstractText": "COPYRIGHT \u00a9 2023 Wang, Peng, Zha, Han, Deng, Hu and Hu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. Enhancing the conversational agent with an emotional support system for mental health digital therapeutics",
    "authors": [
        {
            "affiliations": [],
            "name": "Rosa M. Ba\u00f1os"
        },
        {
            "affiliations": [],
            "name": "Mohd Anul Haq"
        },
        {
            "affiliations": [],
            "name": "Qing Wang"
        },
        {
            "affiliations": [],
            "name": "Shuyuan Peng"
        },
        {
            "affiliations": [],
            "name": "Zhiyuan Zha"
        },
        {
            "affiliations": [],
            "name": "Xue Han"
        },
        {
            "affiliations": [],
            "name": "Chao Deng"
        },
        {
            "affiliations": [],
            "name": "Lun Hu"
        },
        {
            "affiliations": [],
            "name": "Pengwei Hu"
        }
    ],
    "id": "SP:9716acf8621ee66f63bc474c1ce01c50c66b1f63",
    "references": [
        {
            "authors": [
                "F Burger",
                "MA Neerincx",
                "task Brinkman WP. Using a conversational agent for thought recording as a cognitive therapy"
            ],
            "title": "feasibility, content, and feedback",
            "venue": "Front Digital Health.",
            "year": 2022
        },
        {
            "authors": [
                "Stawarz K",
                "Preist C",
                "Coyle D. Use of smartphone apps",
                "social media",
                "webbased resources to support mental health",
                "well-being"
            ],
            "title": "online survey",
            "venue": "JMIR Mental Health.",
            "year": 2019
        },
        {
            "authors": [
                "F Tong",
                "R Lederman",
                "S D\u2019Alfonso",
                "K Berry",
                "apps Bucci S. Digital therapeutic alliance with fully automated mental health smartphone"
            ],
            "title": "a narrative review",
            "venue": "Front Psychiatry.",
            "year": 2022
        },
        {
            "authors": [
                "H op den Akker",
                "M Cabrita",
                "therapeutics Pnevmatikakis A. Digital"
            ],
            "title": "virtual coaching powered by artificial intelligence on real-world data",
            "venue": "Front Comput Sci.",
            "year": 2021
        },
        {
            "authors": [
                "K Kario",
                "N Harada",
                "hypertension Okura A. Digital therapeutics in"
            ],
            "title": "evidence and perspectives",
            "venue": "Hypertension.",
            "year": 2022
        },
        {
            "authors": [
                "F Sun",
                "J Sun",
                "Q. Zhao"
            ],
            "title": "A deep learning method for predicting metabolitedisease associations via graph neural network. Brief Bioinform",
            "year": 2022
        },
        {
            "authors": [
                "T Wang",
                "J Sun",
                "Q. Zhao"
            ],
            "title": "Investigating cardiotoxicity related with hERG channel blockers using molecular fingerprints and graph attention mechanism",
            "venue": "Comput Biol Med",
            "year": 2022
        },
        {
            "authors": [
                "MA Haq",
                "AK Jilani",
                "P. Prabu"
            ],
            "title": "Deep learning based modeling of groundwater storage change",
            "venue": "doi: 10.32604/cmc.2022.020495 Frontiers in Psychiatry",
            "year": 2021
        },
        {
            "authors": [
                "MA Haq"
            ],
            "title": "CNN based automated weed detection system using UAV imagery",
            "year": 2022
        },
        {
            "authors": [
                "MA Haq",
                "A Ahmed",
                "I Khan",
                "J Gyani",
                "A Mohamed",
                "EA Attia"
            ],
            "title": "Analysis of environmental factors using AI and ML methods",
            "year": 2022
        },
        {
            "authors": [
                "MA Haq",
                "G Rahaman",
                "P Baral",
                "A. Ghosh"
            ],
            "title": "Deep learning based supervised image classification using UAV images for forest areas classification",
            "venue": "J Indian Soc Remote Sens",
            "year": 2021
        },
        {
            "authors": [
                "October Boyles BR MSN"
            ],
            "title": "Digital Therapeutics for Treating Anxiety and Depression",
            "year": 2022
        },
        {
            "authors": [
                "BX Yang",
                "P Chen",
                "XY Li",
                "F Yang",
                "Z Huang",
                "G Fu"
            ],
            "title": "Characteristics of high suicide risk messages from users of a social network\u2013sina weibo \u201ctree hole",
            "venue": "Front Psychiatry",
            "year": 2022
        },
        {
            "authors": [
                "Y Ding",
                "J Liu",
                "X Zhang",
                "Z. Yang"
            ],
            "title": "Dynamic tracking of state anxiety via multi-modal data and machine learning",
            "venue": "Front Psychiatry",
            "year": 2022
        },
        {
            "authors": [
                "ML Tielman",
                "MA Neerincx",
                "WP. Brinkman"
            ],
            "title": "Design and evaluation of personalized motivational messages by a virtual agent that assists in post-traumatic stress disorder therapy",
            "venue": "J Med Internet Res",
            "year": 2017
        },
        {
            "authors": [
                "DC Buitenweg",
                "D Van De Mheen",
                "HA Van Oers",
                "QoL-ME Van Nieuwenhuizen C. Psychometric properties of the"
            ],
            "title": "a visual and personalized quality of life assessment app for people with severe mental health problems",
            "venue": "Front Psychiatry.",
            "year": 2022
        },
        {
            "authors": [
                "Burleson BR. Emotional support skills. In"
            ],
            "title": "Greene JO, Burleson BR, editors",
            "venue": "Handbook of Communication and Social Interaction Skills. Lawrence ErlbaumAssociates Publishers.",
            "year": 2003
        },
        {
            "authors": [
                "H Zhou",
                "M Huang",
                "T Zhang",
                "X Zhu",
                "machine Liu B. Emotional chatting"
            ],
            "title": "Emotional conversation generation with internal and external memory",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 32. AAAI Press",
            "year": 2018
        },
        {
            "authors": [
                "H Rashkin",
                "EM Smith",
                "M Li",
                "models Boureau YL. Towards empathetic opendomain conversation"
            ],
            "title": "A new benchmark and dataset",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence: Association for Computational Linguistics",
            "year": 2019
        },
        {
            "authors": [
                "N Majumder",
                "P Hong",
                "S Peng",
                "J Lu",
                "MIME Poria S."
            ],
            "title": "Mimicking emotions for empathetic response generation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics",
            "year": 2020
        },
        {
            "authors": [
                "P Zhong",
                "C Zhang",
                "H Wang",
                "Y Liu",
                "C. Miao"
            ],
            "title": "Towards persona-based empathetic conversational models",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
            "year": 2020
        },
        {
            "authors": [
                "Zandie R",
                "Mahoor MH. EmpTransfo"
            ],
            "title": "a multi-head transformer architecture for creating empathetic dialog systems",
            "venue": "arXiv:2003.02958 [cs.CL].",
            "year": 2020
        },
        {
            "authors": [
                "C Zheng",
                "Y Liu",
                "W Chen",
                "Y Leng",
                "Comae Huang M."
            ],
            "title": "A multi-factor hierarchical framework for empathetic response generation",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "N Majumder",
                "P Hong",
                "S Peng",
                "J Lu",
                "D Ghosal",
                "A Gelbukh",
                "MIME et al."
            ],
            "title": "MIMicking emotions for empathetic response generation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). Online: Association for Computational Linguistics",
            "year": 2020
        },
        {
            "authors": [
                "Z Lin",
                "P Xu",
                "GI Winata",
                "FB Siddique",
                "Z Liu",
                "J Shin",
                "CAiRE et al."
            ],
            "title": "an empathetic neural chatbot",
            "venue": "arXiv: Computation and Language.",
            "year": 2019
        },
        {
            "authors": [
                "Q Li",
                "H Chen",
                "Z Ren",
                "Z Chen",
                "Z Tu",
                "EmpDG Ma J."
            ],
            "title": "Multi-resolution Interactive Empathetic Dialogue Generation",
            "venue": "ArXiv.",
            "year": 2019
        },
        {
            "authors": [
                "L Medeiros",
                "T. Bosse"
            ],
            "title": "Using crowdsourcing for the development of online emotional support agents. In:Highlights of Practical Applications of Agents, Multi-Agent Systems, and Complexity: The PAAMS Collection: International Workshops of PAAMS 2018",
            "year": 2018
        },
        {
            "authors": [
                "A Sharma",
                "AS Miner",
                "DC Atkins",
                "T. Althoff"
            ],
            "title": "A computational approach to understanding empathy expressed in text-based mental health support",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
            "year": 2020
        },
        {
            "authors": [
                "S Liu",
                "C Zheng",
                "O Demasi",
                "S Sabour",
                "Y Li",
                "Z Yu",
                "In et al. Towards emotional support dialog systems."
            ],
            "title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
            "venue": "Online: Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "Q Tu",
                "Y Li",
                "J Cui",
                "B Wang",
                "JR Wen",
                "MISC Yan R."
            ],
            "title": "a mixed strategy-aware model integrating COMET for emotional support conversation",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Dublin, Ireland: Association for Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "W Peng",
                "Y Hu",
                "L Xing",
                "Y Xie",
                "Y Sun",
                "globally Li Y. Control",
                "locally understand"
            ],
            "title": "a global-to-local hierarchical graph network for emotional support conversation",
            "venue": "arXiv preprint. arXiv:220412749.",
            "year": 2022
        },
        {
            "authors": [
                "D Huang Y SJRXSX Zhai",
                "T. J"
            ],
            "title": "Mental states and personality based on real-time physical activity and facial expression recognition",
            "venue": "Front Psychiatry",
            "year": 1904
        },
        {
            "authors": [
                "J Acha",
                "A Sweetland",
                "D Guerra",
                "K Chalco",
                "H Castillo",
                "tuberculosis Palacios E. Psychosocial support groups for patients with multidrug-resistant"
            ],
            "title": "five years of experience",
            "venue": "Global Public Health.",
            "year": 2007
        },
        {
            "authors": [
                "K Papineni",
                "S Roukos",
                "T Ward",
                "Bleu ZhuWJ."
            ],
            "title": "a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. Philadelphia, PA, USA: Association for Computational Linguistics",
            "year": 2002
        },
        {
            "authors": [
                "Lin CY. ROUGE"
            ],
            "title": "a Package for Automatic Evaluation of Summaries",
            "venue": "Text Summarization Branches Out. Barcelona, Spain: Association for Computational Linguistics",
            "year": 2004
        },
        {
            "authors": [
                "S Roller",
                "E Dinan",
                "N Goyal",
                "D Ju",
                "M Williamson",
                "Y Liu",
                "In et al. Recipes for building an open-domain chatbot."
            ],
            "title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
            "venue": "Online: Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "S Humeau",
                "K Shuster",
                "MA Lachaux",
                "Poly-encoders Weston J."
            ],
            "title": "transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring",
            "venue": "arXiv preprint arXiv:190501969.",
            "year": 2019
        },
        {
            "authors": [
                "Xu Q",
                "Yan J",
                "Cao C. Emotional communication between Chatbots",
                "users"
            ],
            "title": "an empirical study on online customer service system",
            "venue": "H. Degen and S. Ntoa, editors. Artificial Intelligence in HCI. HCII 2022. Lecture Notes in Computer Science, vol 13336. Cham: Springer",
            "year": 2022
        },
        {
            "authors": [
                "R Gupta",
                "H Lee",
                "J Zhao",
                "Y Cao",
                "A Rastogi",
                "Show WuY.",
                "tell don\u2019t"
            ],
            "title": "demonstrations outperform descriptions for schema-guided task-oriented dialogue",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Seattle, United States: Association for Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "A Bosselut",
                "H Rashkin",
                "M Sap",
                "C Malaviya",
                "A Celikyilmaz",
                "COMET Choi Y."
            ],
            "title": "commonsense transformers for automatic knowledge graph construction",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence, Italy: Association for Computational Linguistics",
            "year": 2019
        },
        {
            "authors": [
                "W Peng",
                "Y Hu",
                "L Xing",
                "Y Xie",
                "X Zhang",
                "intention Sun Y. Modeling",
                "emotion",
                "In external world in dialogue systems."
            ],
            "title": "ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
            "venue": "IEEE: Singapore",
            "year": 2022
        },
        {
            "authors": [
                "W Peng",
                "Y Hu",
                "L Xing",
                "Y Xie",
                "J Yu",
                "Y Sun"
            ],
            "title": "Bi-directional cognitive thinking network for machine reading comprehension",
            "venue": "arXiv preprint arXiv:201010286",
            "year": 2020
        },
        {
            "authors": [
                "L Mou",
                "R Men",
                "G Li",
                "Y Xu",
                "L Zhang",
                "R Yan"
            ],
            "title": "Natural language inference by tree-based convolution and heuristic matching",
            "venue": "arXiv preprint",
            "year": 2015
        },
        {
            "authors": [
                "Y Liu",
                "J Zhao",
                "J Hu",
                "R Li",
                "EIN Jin Q. Dialogue"
            ],
            "title": "Emotion interaction network for dialogue affective analysis",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics. Gyeongju: International Committee on Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "Z Lin",
                "A Madotto",
                "J Shin",
                "P Xu",
                "MoEL Fung P."
            ],
            "title": "mixture of empathetic listeners",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Hong Kong, China: Association for Computational Linguistics",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "TYPE Original Research PUBLISHED 17 April 2023 DOI 10.3389/fpsyt.2023.1148534"
        },
        {
            "heading": "OPEN ACCESS",
            "text": ""
        },
        {
            "heading": "EDITED BY",
            "text": "Rosa M. Ba\u00f1os, University of Valencia, Spain"
        },
        {
            "heading": "REVIEWED BY",
            "text": "Mohd Anul Haq, Majmaah University, Saudi Arabia Qicheng Li, Nankai University, China Qi Zhao, University of Science and Technology Liaoning, China Shaolin Liang, Zhilian Research Institute for Innovation and Digital Health, China\n*CORRESPONDENCE Pengwei Hu\nhupengwei@hotmail.com\nChao Deng\ndengchao@chinamobile.com"
        },
        {
            "heading": "SPECIALTY SECTION",
            "text": "This article was submitted to Digital Mental Health, a section of the journal Frontiers in Psychiatry\nRECEIVED 20 January 2023 ACCEPTED 22 March 2023 PUBLISHED 17 April 2023"
        },
        {
            "heading": "CITATION",
            "text": "Wang Q, Peng S, Zha Z, Han X, Deng C, Hu L and Hu P (2023) Enhancing the conversational agent with an emotional support system for mental health digital therapeutics. Front. Psychiatry 14:1148534. doi: 10.3389/fpsyt.2023.1148534"
        },
        {
            "heading": "COPYRIGHT",
            "text": "\u00a9 2023 Wang, Peng, Zha, Han, Deng, Hu and Hu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\nEnhancing the conversational agent with an emotional support system for mental health digital therapeutics\nQing Wang1, Shuyuan Peng1, Zhiyuan Zha2, Xue Han1, Chao Deng1*, Lun Hu3 and Pengwei Hu3*\n1China Mobile Research Institute, Beijing, China, 2School of Information, Renmin University of China, Beijing, China, 3The Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Sciences, Urumqi, China\nAs psychological diseases become more prevalent and are identified as the leading cause of acquired disability, it is essential to assist people in improving their mental health. Digital therapeutics (DTx) has been widely studied to treat psychological diseases with the advantage of cost savings. Among the techniques of DTx, a conversational agent can interact with patients through natural language dialog and has become the most promising one. However, conversational agents\u2019 ability to accurately show emotional support (ES) limits their role in DTx solutions, especially in mental health support. One of the main reasons is that the prediction of emotional support systems does not extract e ective information from historical dialog data and only depends on the data derived from one singleturn interaction with users. To address this issue, we propose a novel emotional support conversation agent called the STEF agent that generates more supportive responses based on a thorough view of past emotions. The proposed STEF agent consists of the emotional fusion mechanism and strategy tendency encoder. The emotional fusion mechanism focuses on capturing the subtle emotional changes throughout a conversation. The strategy tendency encoder aims at foreseeing strategy evolution throughmulti-source interactions and extracting latent strategy semantic embedding. Experimental results on the benchmark dataset ESConv demonstrate the e ectiveness of the STEF agent compared with competitive baselines.\nKEYWORDS\ndigital mental health, digital therapeutics, conversational agent, natural language processing, emotional support conversation\n1. Introduction\nMental disorders have a higher lifetime prevalence and have a greater influence on people\u2019s quality-adjusted life expectancy (1). According to Organization (2), mental health issues such as depression affect more than 350 million people, which has been the leading cause of acquired disability. Without adequate treatment, a person suffering from mental health problems would get increasingly ill with multiple symptoms, such as insomnia and loss of interest. Therefore, it is vitally necessary to assist people in improving their mental health, given the prevalence of psychological diseases (3). While face-to-face psychological counseling is an effective approach to treating a variety of mental health issues, only a small percentage of individuals have access to it. According to Tong et al. (4), the demand for\nFrontiers in Psychiatry 01 frontiersin.org\nprofessional mental health therapists is high, and nearly 60 percent of those with a mental disorder are unable to receive treatment.\nDue to the limited access to treatment and the increasing expenditures on healthcare, it is critical to develop digital health solutions (4, 5). Digital Therapeutics (DTx), a subset of digital health solutions, provides evidence-based therapeutic interventions. To prevent, manage, or treat a medical ailment, DTx leverages state-of-the-art artificial intelligence techniques to replace or enhance a variety of established psychological approaches to therapy (6). Artificial intelligence techniques have been widely employed in a variety of fields and have already been used in combination with drugs or other therapies to improve patient care and health outcomes (7\u201312).\nDTx products are generally delivered via smartphones or computers, which offers patients more convenience and privacy. In particular, DTx products on smartphones can be multilingual. Thus, DTx has the potential to address the inadequacy of psychological treatment access. Patients suffering from major depressive disorder (MDD) frequently struggle to apply what they learn in therapy or losemotivation to dowhat their therapists assign them to do. DTx can help patients with MDD keep practicing their skills and improve their ability to move away from negative thoughts. At the same time, DTx can provide therapists with a wealth of additional information about their patients\u2019 daily lives. With the help of DTx, clinicians can adjust the treatment and communicate with patients online in real time, intervening as needed (13).\nOne of the most promising technologies for these DTx products is conversational agents. Conversational agents utilize natural language processing technologies to provide supplemental treatment or track adherence with patients. The advantages of conversational agents in mental health include giving people who require psychological counseling 24/7 access to treatment resources (13). Conversational agents can also inform patients about common therapeutic issues, remind patients about important therapeutic issues, and notify patients when the monitoring indicator value is out of range (14, 15).\nResearch shows that patients with severe symptoms are more likely to keep having a conversation with the conversational agent if they get emotional messages while they communicate (16, 17). However, because it may not be naturally possible to be able to express empathetically (18), many conversational agents are unable to fully understand the patient\u2019s individual needs, determine how the patient is feeling, and accurately show emotion in conversation. As a result, the role of conversation agents in DTx solutions is limited.\nIntroducing emotion into conversation systems has been widely studied since the early days. The emotional chatting machine (ECM) (19) was a noteworthy work in emotional conversation, capable of generating emotional responses based on pre-specified emotions and accurately expressing emotion in generated responses. Some works (20\u201324) concentrated on empathetic responding, which is good at understanding user emotions and responding appropriately, making responses more empathetic. Other works (25\u201327) learned to statistically predict the user\u2019s emotion using a coarse-grained conversation-level emotion label. However, accurate emotional expression and empathy are\nonly the starting point of useful emotional support. Other skills should also consider other abilities.\nSeveral emotion conversation datasets have also been built based on social context. Medeiros and Bosse (28), collected around 10,000 post-response pairs about stressful situations from Twitter, classified these tweets into different supportive categories, and collected supportive replies to them with crowd-sourcing workers. Based on the data, it was also determined which types of support were used most frequently and why. Sharma et al. (29) built an empathy conversation corpus of 10k (post-response) pairs with supporting evidence provided by the model using a RoBERTabased bi-encoder model to identify empathy in conversations and extract rationales underlying its predictions. However, both prior datasets only contained single-turn conversations, which can only be used to support the exploration of simplified response scenarios with users at a coarse-grained emotion level.\nTo fully focus on the emotional support for conversational agents, the emotional support conversation (ESC) task was defined by Liu et al. (30). They also released the first large-scale multi-turn ESC dataset, ESConv, and designed an ESC framework. The ESC task aims at strategically comforting the user whowants to seek help to improve their bad emotional state; thus, the ESC framework has three stages (Exploration, Comforting, and Action). The first stage requires the supporter (or the conversational agent) to identify the user\u2019s problem, followed by properly selecting a support strategy to comfort the user for the second stage. Finally, the supporter should provide suggestions to evoke a positive mental state.\nThe ESC task, according to Liu et al. (30), has two fundamental problems. One of them is determining how to generate a strategyconstrained response with suitable strategy selection. Another challenge is how to dynamically model the user\u2019s mental state. Prior works on the ESC task mainly detect (31, 32) the interaction between the problem faced by the user and the user\u2019s present mental state. However, the user\u2019s mental state is complex and changes subtly throughout a conversation. An effective ES system should consider all mental states of the whole conversation. Identifying the user\u2019s fine-grained, dynamic mental state is critical in the multiturn ESC scenario (15, 33). Moreover, some earlier works merely considered the dialog history to foresee the strategy and overlooked the past strategies the supporter used. Even though some of the past strategies may not have instantly alleviated users\u2019 distress, the past strategies are critical for having a long-term effect on reducing depression.\nIn this study, we propose the STEF agent, a novel emotional support conversation agent built on the ESC, to address the above issues. Our STEF agent is composed of an emotional fusion mechanism and a strategy tendency encoder. The emotional fusion mechanism focuses on capturing subtle emotional changes by combining the representation of historical and present mental states via a fusion layer. The strategy tendency encoder aims at extracting latent strategy text semantic embedding and discovering strategy tendency. Thereafter, we implement a strategy classifier to foresee the future support strategy. At last, STEF agent can generate more supportive responses with finegrained historical emotional understanding and an appropriate support strategy. In the following sections, we will look into the details.\nFrontiers in Psychiatry 02 frontiersin.org"
        },
        {
            "heading": "2. Methods and materials",
            "text": "In this section, we first introduce the ESC system on the digital therapeutic platform. As shown in Figure 1, the doctor can utilize the user data stored in the cloud service to personalize treatment and track the patient\u2019s compliance on the digital therapeutic platform. The conversation agent with the ability to provide emotional support can further comprehend the patient\u2019s situation and provide a considerate response or accurate medical advice based on the doctor\u2019s configuration and helping skills. Particularly in the mental health area, the conversation agent with this ability enables the agent to accompany the patient and act as a supervisor to avoid self-harm behaviors if necessary. The patient can have daily interactions with the conversation agent, and these interactions will be logged in the database as user feedback. Thereafter, the doctor obtains patients\u2019 feedback from the database to track the patient\u2019s treatment response and adjust therapy timely during the course of treatment. The engineer will employ patients\u2019 feedback to promote the performance of emotional support.\nOur approach focused on promoting the performance of emotional support for conversation agents. We conducted our proposed model of ESC on the ESConv dataset. More details about the dataset are described in the next section Emotional Support. The construction of the ESC system is described in the section STEF agent."
        },
        {
            "heading": "2.1. Emotional support",
            "text": "The purpose of emotional support is to comfort seekers and provide suggestions to resolve the problems they face. Specifically,\nthe emotional support conversation takes place between a seeker and a supporter, with the supporter attempting to gradually relieve the help seeker\u2019s distress and assist them in overcoming the challenges they confront as the conversation progresses. According to Tu et al. (31), it is not intuitive to provide emotional support, so conversational skills are critical for providing more support through dialog. Hence, the selection of a support strategy (conversational helping skills) in the ESC task is a significant challenge. Particularly, based on psychological research (34), choosing a appropriate support strategy is crucial for ensuring treatment adherence and providing effective emotional support. Another critical challenge is mental state modeling. A mental state is complicated, and the user\u2019s emotion intensity will subtly fluctuate during the whole conversation. Thereafter, the support strategy selection will differ depending on different mental states.\nFigure 2 shows a typical emotional support scenario. The supporter first strategically comforts the seeker by caringly enquiring about the problem, then resonating with the seeker\u2019s feelings, and then providing suggestions to evoke positive emotions. Due to the particularity of multi-turn dialog scenarios, the ESC system should further take into account how much the selected strategy will contribute to lessening the user\u2019s emotional suffering over time. Even though some strategies might not immediately contribute to offering emotional support, they are still effective for accomplishing the long-term goal.\nTo validate the performance of the ESC system, Liu et al. (30) also released ESConv, a dataset including 1,053 multi-turn dialogs with 31,410 utterances. ESConv contains eight kinds of support strategies to enhance the effectiveness of emotional support, which are questions, restatements or paraphrasing, reflection of feelings, self-disclosure, affirmations reassurance, and providing\nFrontiers in Psychiatry 03 frontiersin.org\nsuggestions, information, and others, almost uniformly distributed among the whole dataset (30). Each example in the ESCconv dataset consists of the psychological problem of the seeker (situation), the whole process of dialog (utterances), and the skills the helper adopted (strategy).\nHowever, how to evaluate the effectiveness of emotional support remains to be explored. Following Liu et al. (30) and Tu et al. (31), we also exploit automatic evaluation and human evaluation to evaluate our work, as described below."
        },
        {
            "heading": "2.1.1. Automatic evaluation",
            "text": "To measure the diversity of responses in the conversation system and the performance of generated response, we adopted traditional evaluation methods PPL(perplexity), D-2(Distinct-2), BLEU(B-2, B-4) (35), and R-L (ROUGE-L) (36). In addition, we employed an extra metric, ACC (strategy prediction accuracy), mentioned in MISC (31) to indicate the ability to select an accurate strategy."
        },
        {
            "heading": "2.1.2. Human evaluation",
            "text": "We adopted the questionnaire (30) mentioned. Thereafter, volunteers would be asked the following questions: (1) Fluency: Which of the following responses is more fluent and easier to understand? (2) Identification: Which answer is more accurate about your situation andmore helpful in identifying your problem? (3) Comforting:Which answer makes you feel more comfortable? (4) Suggestion: Which answer between the two candidates gives advice that contains specific methods that are more useful to you than the other one? (5)Overall: Generally speaking, which of these two forms of emotional support do you prefer overall?"
        },
        {
            "heading": "2.2. STEF agent",
            "text": "In Figure 3, the STEF agent consists of several primary components. The strategy tendency encoder employs historical strategies, dialog context, and historical mental states to capture the interaction and latent semantic embedding of strategy. The emotion fusion mechanism controls the fusion of the seeker\u2019s\nFrontiers in Psychiatry 04 frontiersin.org\ncurrent mental state and past mental states. The multi-source generator generates a supportive response by considering multiple factors, including latent strategy embedding and the fusion information of the seeker\u2019s mental state."
        },
        {
            "heading": "2.2.1. Preliminary work",
            "text": "Emotional support conversation is a generation task, and we can define this task as below. Given a sequence of utterances in dialog history D = {\n(xi, yi) n\u22121 i=1\n}\n, where xi, yi are spoken by the\nseeker and the supporter, respectively, i denotes the index of round, and n \u2212 1 denotes the round number of history conversation. In addition to D, inputs for the ESC task also include historical strategy sequence S = {s1, s2, . . . , sn\u22121}, the seeker\u2019s last utterance with m words B = { b1, b2, . . . , bm } , and a psychological problem with p words C = { c1, c2, . . . , cp } . Hence, the goal of this task is to generate a supportive response conditioned on the dialog history D, history strategies S, the seeker\u2019s last utterance B, and the seeker\u2019s psychological problem C.\nBlenderbot-small (37) is an open-domain conversation agent pretrained with multiple communication skills and large-scale dialog corpora. Blenderbot-small employs poly-encoder in the standard seq2seq transformer architecture. The poly-encoder utilizes a cross-encoder and multiple representations to encode features (38). Following the previous work (39, 40), we utilize the encoder of blenderbot-small as our common encoder to represent historical strategies. The representation of dialog history can be formulated as follows:\nHD = Enc(CLS, (x1, SEP, y1), SEP, (x2, SEP, y2), . . . ,\n(xn\u22121, SEP, yn\u22121)), (1)\nwhere Enc is the encoder, CLS is the start token, and SEP is the separation token between two utterances.\nIn the ESC task, the supporter chooses a different strategy to comfort the seeker based on the seeker\u2019s different mental conditions, which indicates that the seeker\u2019s mental states are important. We exploit COMET (41) to capture the seeker\u2019s mental states. COMET, a commonsense knowledge generator, utilizes the natural language tuples (event, pre-defined relation) to generate corresponding knowledge. We consider each seeker\u2019s utterances in dialog history as an event and input each of them into COMET to acquire a collection of mental states.\nM = {emo1, emo2, . . . , emon\u22121},\nemoi = COMET ( relxAttr , xi ) , (2)\nwhere M is the sequence of user\u2019s mental states, relxAttr is one of the pre-defined relations in COMET, and ui is the utterance of the seeker. The relation xAttr in COMET denotes how the person might be described in an event (utterances). Note that the outputs of COMET are a series of emotion-related synonyms, and we select the first result as emoi.\nFurthermore, we also use our common encoder to represent the\nsequence of historical mental states obtained from COMET.\nHe = [he1 , he2 , . . . , hen\u22121 ], hei = Enc(emoi), (3)\nwhere He is the representation of historical mental states and hei is the hidden state of the encoder. Similarly, we can feed the seeker\u2019s last utterance to obtain the seeker\u2019s current mental state emoB using COMET. The representationHe B will be obtained using a common encoder. Finally, we have representations of the seeker\u2019s mental state at the dialog and utterance levels.\nAccording to Liu et al. (30), each conversation in ESConv has long turns, and they truncate them into pieces. Hence, the psychological problems of each conversation are critical to enhancing the understanding of conversation pieces. To derive the\nFrontiers in Psychiatry 05 frontiersin.org\npsychological problem\u2019s representation Hg , we continue to employ the common encoder:\nHg = Enc(C). (4)"
        },
        {
            "heading": "2.2.2. Emotional fusion mechanism",
            "text": "Motivated by the study by Peng et al. (42), we propose an emotional fusion mechanism for effectively integrating mental state information from the whole conversation and acquiring the influence of historical emotion. The fusion layer is combined the representation of historical and current mental states. Our fusion kernel simply employs concatenation, addition, and subtraction operations to fuse the two sources. According to Peng et al. (43) andMou et al. (44), it is effective to fuse different representations by utilizing a heuristic matching trick with a difference and elementwise product in the fusion mechanism. Hence, an emotional fusion mechanism can be formulated as\nHe = Fuse(H u e ,H B e )\nFuse ( Hue ,H B e ) = Relu(wTf [H u e ;H B e ;H u e \u25e6 H B e ;H u e +HBe ;H u e \u2212H B e ]+ bf )\n(5)\nwhere Fuse is the fusion kernel, Relu is non-linear transformation, \u25e6 denotes the element-wise product, and the wf , bf are learnable parameters."
        },
        {
            "heading": "2.2.3. Strategy tendency encoder",
            "text": "It is essential that the ESC system chooses an appropriate strategy based on the seeker\u2019s mental states and generates a strategyconstrained response. Inspired by DialogEIN (45), we propose the strategy tendency encoder to capture the tendency of each utterance and the latent strategy information. As shown in Figure 3, the embedding of each category is depicted by the circles with different colors. Given the set of strategy labels T = { t1, t2, . . . , tq } , each strategy embedding can be formulated as\nei = E t(ti), (6)\nwhere Et denotes the strategy embedding lookup table and ei indicates the embedding of the i-th strategy category. We initialize the strategy embedding randomly and tune them during the model training. The dimension of strategy embedding is the same as the representations of dialog history andmental states for exploring the interaction from them. Thereafter, we use the strategy embedding to construct the representation of history strategies, S, denoted as\nEs = [es1 , es2 , . . . , esn\u22121 ], (7)\nwhere esi denotes the history strategy embedding for the i-th utterance.\nTo capture the evolution of a support strategy, a multi-head attention module is applied. Based on DialogEIN, we modify the multi-head attention module as\nHs = MHA(HD,He,Es)+HD, (8)\nwhere MHA stands for the multi-head attention module, HD is the query, He is the key, and Es is the value of the self-attention\nmechanism. Hs indicates the tendency information of strategy explicitly and contains the interaction information of historical strategies and mental states. We add the residual of query HD to Hs to ensure it sustains semantic information.\nThereafter, we train a multi-class classifier to predict the response strategy distribution for fully using strategy tendency information Hs. By combining the distribution and strategy embedding, we derive latent strategy representation H \u2032\ns as follows:\nsp = multi-classifier(Hs),\nH \u2032 s = sp \u2217 [e1, e2, . . . , eq], (9)\nwhere multi-classifier is a multi-layer perceptron, sp is the strategy probability distribution prediction, and [e1, e2, . . . , eq] is the embedding set of the strategy label."
        },
        {
            "heading": "2.2.4. Multi-source generator",
            "text": "For conversational agents, the decoder learns a continuous space representation of a phrase that preserves both the semantic and syntactic structure of the utterance. To generate a supportive response, we fully integrate all kinds of information from the abovementioned source. In MISC (31), the cross-attention module of the blenderbot-small decoder is modified to utilize the strategy representation and mental states. We retain this module and employ multi-source representation in our model to obtain crossattention.\nAd = Cross\u2212 attn(O,HD),\nAs = Cross\u2212 attn(O,H \u2032 s),\nAe = Cross\u2212 attn(O,He),\nAg = Cross\u2212 attn(O,Hg),\n(10)\nwhere O is the hidden states of the decoder and Cross \u2212 attn is the cross-attention module."
        },
        {
            "heading": "2.2.4.1. Loss function",
            "text": "The architecture of ourmodel has two tasks: predict the strategy and generate the response. In this study, we directly adopted the same objective fromMISC to train our model.\nLr = \u2212\nnr \u2211\nt=1\nlog(p(rt|rj<t ,D,M,C, S)),\nLs = \u2212log(p(s \u2032 |D,M,C, S)),\nL = Lr + Ls,\n(11)\nwhere Lr is the loss of generated response, nr is the length of generated response, Ls is the loss of predicting strategy label, s \u2032 is the ground truth of the strategy label, and L is the combined objective to minimize."
        },
        {
            "heading": "2.3. Procedures",
            "text": "Our experiments were conducted on the ESConv dataset, following the MISC division of the ESconv dataset for 9882/1235/1235 samples for the training, validation, and testing of partitions. We fine-tuned STEF agent based on the blender-bot\nFrontiers in Psychiatry 06 frontiersin.org\nsmall with the size of 90M parameters. The maximum length of the input sequence for the common encoder is 512, and the dimension of all hidden embeddings is 512. We set the training batch size and evaluating batch size to 8 and 16, respectively, to fit GPU memory and the dropout rate to 0.1. Following the previous work, we employed linear warm-up in 120 warm-up steps. We also employed AdamW as an optimizer, which builds upon the Adam optimizer and incorporates weight decay to improve the performance of regularization. The number of epochs (10 to 40) and initial learning rate (5e-4 to 5e-6) were also tuned. We evaluated perplexity for each checkpoint on the validation set, finally selecting the one corresponding to the lowest perplexity as the trained model. We used one GPU of the NVIDIA Tesla V100 to train the STEF agent, and the overall training time was 1.5 h. During training, we observed that the STEF agent trained for 20 epochs with a learning rate of 2e-5 showed the best performance based on perplexity.\nAfter training, we evaluated the model on the test dataset through two dimensions: automatic evaluation and human evaluation. In automatic evaluation, our model was compared to the baseline in terms of the accuracy of the predicted strategy and common LM metrics of generated responses. In human evaluation, we recruited 10 annotators and asked them to complete questionnaires. Each questionnaire includes two responses generated by our model and another model separately. The annotator compared the two responses on five aspects (fluency, identification, comforting, suggestion, and overall) and annotated the better one. A total of 64 samples were selected from the test set for response generation, and two other models were compared to ours."
        },
        {
            "heading": "3. Analysis",
            "text": ""
        },
        {
            "heading": "3.1. Experiment results",
            "text": ""
        },
        {
            "heading": "3.1.1. Automatic evaluation",
            "text": "We compared our model with several baseline models: Transformer, MoEL (46), MIME (25), Blenderbot-joint (30), and MISC (31), GLHG (32). The metric of perplexity (PPL)\nmeasures the quality of generated responses from the language model dimension, indicating that it is more capable of producing high-quality responses. Distinct-2 (D-2) measures the ratios of the unique 2 g in the generated response. BLEU-n (B-2, B4) measures the ratios of the common n-gram token number between generated and ground-truth responses to the length of the generated response. Rouge-L (R-L) measures the longest common sub-sequence between the generated and ground-truth responses. In Table 1, the STEF agent has a promising result on D-2 compared with baseline models. This result demonstrates that the response the STEF agent generated is more diverse than other baselines. The conversational agent in the DTx solution focuses on personalization and customization, which means that the agent should generate diverse responses. Hence, the D-2 result can also demonstrate that the STEF agent is appropriate for the DTx solution. In terms of the Rouge-Lmetric, we can see that the RougeL result outperforms most baselines, including Blenderbot-joint and GLHG. The Rouge-L result demonstrates that the STEF agent can mimic a supporter to show understanding and comfort the seekers. By comparing with the SOTA models Blenderbot-Join and MISC, we can see that the STEF agent has the worse performance for the Acc metric and perplexity. However, the support strategy is an alternative, and other strategies may also have an effect; thus, the accuracy (ACC) metric is insufficient to evaluate the strategy. The comparison results demonstrate that the STEF agent has the potential to be applied to the DTx product."
        },
        {
            "heading": "3.1.2. Human evaluation",
            "text": "As above mentioned in the procedure, we recruited 10 volunteers to complete the questionnaire. To assist the volunteer in acting as the support seeker as effectively as possible, each sample in the questionnaire includes information on a mental problem description and dialog history. The volunteer was asked to label the generated response with the \u201cwin\" label when they thought the generated response was superior to the other response. At last, we made a statistical analysis of these questionnaires from three aspects (win, lose, and tie). The human evaluation results in Table 2 show that our model has a substantial advantage in\nFrontiers in Psychiatry 07 frontiersin.org\nBold values indicate that ACC: The strategy prediction accuracy. PPL: Perlexity. PPLmeasures the quality of generated responses from the language model dimension. D-2: Distinct-2 (D-2) measures the ratios of the unique two-grams in the generated response. The format is count (two-gram) / count(word). B-2, B-4: Bleu-2, Bleu-4 from Bleu-n. The bleu-n measures the ratios of the common n-gram token number between generated and ground-truth responses to the length of the generated response. R-L: Rouge-L (R-L) measures the longest common sub-sequence between the generated and ground-truth responses. Win: When the volunteers thought the generated response was superior to the other response, they labeled the sample \u201cWin\u201d. Lose: When the volunteers thought the generated response was inferior to the other response, they labeled the sample \u201cLose\u201d. Tie: When the volunteers thought the generated response was equal to the other response, they labeled the sample \u201cTie\u201d.\nall aspects. Compared to Blenderbot-joint, our model significantly outperforms the comforting and suggestion aspect, which indicates that our model is capable of showing support and providing suggestions better. However, in terms of the fluency aspect, our model does not gain much. Compared to MIME, our model achieves remarkable advancement on all metrics, especially on the fluency and identification aspect, which demonstrates our model\u2019s best ability to provide emotional support.\nThe automatic evaluation result and human evaluation result reveal that the STEF agent has a promising performance of support though the ACC metric of strategy prediction is lower than the competitor baseline. The seeker\u2019s mental states affect the selection of support strategies. Even when faced with a small mental problem, the seeker\u2019s mental state still changed with different support strategies. The support strategy is an alternative in different ESC stages; consequently, the ground truth of the support strategy is not unique. The human evaluation results can demonstrate that the strategy tendency encoder can construct the strategy evolution for the whole conversation and predict the appropriate support strategy to improve the performance."
        },
        {
            "heading": "3.2. Case study",
            "text": "Table 3 presents two cases to illustrate the effectiveness of our model.We can see that the situations in cases 1 and 2 are consistent. The seekers both faced depression caused by COVID-19, which has been prevalent around the world in recent years. In these cases, the conversational agent of DTx product in the mental area has the advantage of identifying the situation seeker encountered timely. Conversational agents with the ability of emotional support could\naccompany the seeker using strategy and provide suggestions to alleviate the mental problem.\nIn Case 1, our model first expresses its understanding of the seeker\u2019s description and then explains the benefits of talking with a friend. The response of our model is better than MISC\u2019s response, as shown in Table 3. The latter part of the response MISC generated just encouraged the seeker neutrally without understanding historical support strategies despite the fact that the MISC\u2019s response also initially demonstrated comprehension. Compared to MISC, our model can appropriately comfort the seeker according to the historical support strategies.\nIn Case 2, our model first affirms that the problem the seeker faces is difficult and provides the seeker with empathetic encouragement. Compared to the response our model generated, the MISC\u2019s response is not reasonable in this scenario, particularly in the DTx area. Users of DTx products are aware the conversational agent will be with them 24/7; hence, the expression will make them feel ridiculous, reducing the reliability of DTX products even further.\nFrontiers in Psychiatry 08 frontiersin.org\nThe two cases above have also been evaluated by annotators, and their feedback demonstrates that our model is able to comprehend the seeker\u2019s mental state, choose an appropriate strategy, and generate a supportive response. Compared to the ground truth, the generated responses of our model have the same effect on the seeker.\nThe cases demonstrate that the STEF agent can show understanding and comfort the users. The STEF agent can be employed in the DTx solution to provide a personalized response based on the various symptoms of patients. The strategy of the STEF agent can be replaced or supplemented with more professional mental counseling skills. Thereafter, the STEF agent in the DTx platform can utilize recorded dialog to be more helpful and professional. Furthermore, the STEF agent can utilize the translation technologies to provide multilingual service for patients from all over the world."
        },
        {
            "heading": "4. Conclusion",
            "text": "This paper proposes a novel conversational agent with a concentration on historical support strategies and the fusion of the seeker\u2019s mental states. We proposed the strategy tendency encoder to obtain the tendency of support strategies and the emotional fusion mechanism to gain the influence of historical mental states. Experiments and analysis demonstrate that the STEF agent achieves promising performance. However, we find that our results tend to include content that commonly appears in many samples (e.g., \u201cI\u2019m sorry to hear that,\u201d \u201cI\u2019m glad to hear that,\u201d \u201cI understand\u201d). The results show a lack of diversity and are unable to show personalization, which is insufficient in ESC. There are other limitations, including those as follows: (1) The available data are inadequate, and the support strategy must be annotated. It is costly to train crowd workers to annotate the vast amount of data. (2) The support strategy should be more alternative in each phase. How to evaluate whether the strategy is appropriate is worth exploring. For future studies, we plan to improve the STEF agent based on the above limitations."
        },
        {
            "heading": "Data availability statement",
            "text": "The original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding authors."
        },
        {
            "heading": "Author contributions",
            "text": "QW developed the conversational agent, conducted the experiment, analyzed the data, created all figures, and wrote the manuscript. SP contributed to the research by providing critical feedback and editing the manuscript. ZZ created all figures and also conducted experiments. XH supervised the entire research process and providing guidance throughout. CD, LH, and PH contributed to the research by providing critical feedback. All authors contributed to the article and approved the submitted version."
        },
        {
            "heading": "Acknowledgments",
            "text": "Wewould like to thank all of our colleagues for their hard work\nand collaboration."
        },
        {
            "heading": "Conflict of interest",
            "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest."
        },
        {
            "heading": "Publisher\u2019s note",
            "text": "All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher."
        }
    ],
    "title": "Enhancing the conversational agent with an emotional support system for mental health digital therapeutics",
    "year": 2023
}