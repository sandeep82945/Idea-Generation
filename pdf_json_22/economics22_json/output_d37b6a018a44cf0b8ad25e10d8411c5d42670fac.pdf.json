{
    "abstractText": "We consider a discrete time stochastic Markovian control problem under model uncertainty. Such uncertainty not only comes from the fact that the true probability law of the underlying stochastic process is unknown, but the parametric family of probability distributions which the true law belongs to is also unknown. We propose a nonparametric adaptive robust control methodology to deal with such problem. Our approach hinges on the following building concepts: first, using the adaptive robust paradigm to incorporate online learning and uncertainty reduction into the robust control problem; second, learning the unknown probability law through the empirical distribution, and representing uncertainty reduction in terms of a sequence of Wasserstein balls around the empirical distribution; third, using Lagrangian duality to convert the optimization over Wasserstein balls to a scalar optimization problem, and adopting a machine learning technique to achieve efficient computation of the optimal control. We illustrate our methodology by considering a utility maximization problem. Numerical comparisons show that the nonparametric adaptive robust control approach is preferable to the traditional robust frameworks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Erhan Bayraktar"
        },
        {
            "affiliations": [],
            "name": "Tao Chen"
        }
    ],
    "id": "SP:b05004e157396c070cdc13746097ae03c2db5b8f",
    "references": [
        {
            "authors": [
                "T. Ba\u015far",
                "P. Bernhard"
            ],
            "title": "H\u221e-optimal control and related minimax design problems",
            "venue": "Systems & Control: Foundations & Applications. Birkh\u00e4user Boston, Inc., Boston, MA, second edition,",
            "year": 1995
        },
        {
            "authors": [
                "T. Bhudisaksang",
                "A. Cartea"
            ],
            "title": "Adaptive robust control in continuous-time",
            "venue": "SIAM Journal on Control and Optimization, 59(5):3912\u20133945",
            "year": 2021
        },
        {
            "authors": [
                "T. Bielecki",
                "T. Chen",
                "I. Cialenco"
            ],
            "title": "Recursive construction of confidence regions",
            "venue": "Electron. J. Statist., 11(2):4674\u20134700",
            "year": 2017
        },
        {
            "authors": [
                "T. Bielecki",
                "T. Chen",
                "I. Cialenco",
                "A. Cousin"
            ],
            "title": "and Jeanblanc M",
            "venue": "Adaptive robust control under model uncertainty. SIAM J. Control Optim., 57(2)",
            "year": 2019
        },
        {
            "authors": [
                "T. Bielecki",
                "T. Chen",
                "I. Cialenco"
            ],
            "title": "Risk-sensitive markov decision problems under model uncertainty: finite time horizon case",
            "venue": "arXiv",
            "year": 2021
        },
        {
            "authors": [
                "E. Bayraktar",
                "A. Cosso",
                "H. Pham"
            ],
            "title": "Robust feedback switching control: Dynamic programming and viscosity solutions",
            "venue": "SIAM Journal on Control and Optimization, 54(5):2594\u20132628",
            "year": 2016
        },
        {
            "authors": [
                "D. Bartl",
                "S. Drapeau",
                "J. Obloj",
                "J. Wiesel"
            ],
            "title": "Sensitivity analysis of wasserstein distributionally robust optimization problems",
            "venue": "Proc. R. Soc. A, 477: 20210176",
            "year": 2021
        },
        {
            "authors": [
                "K. Border"
            ],
            "title": "Fixed Point Theorems with Applications to Economics and Game Theory",
            "venue": "Cambridge University Press, 9 edition",
            "year": 1985
        },
        {
            "authors": [
                "D.P. Bertsekas",
                "S. Shreve"
            ],
            "title": "Stochastic Optimal Control: The Discrete-Time Case",
            "venue": "Academic Press",
            "year": 1978
        },
        {
            "authors": [
                "H.F. Chen",
                "L. Guo"
            ],
            "title": "Identification and stochastic adaptive control",
            "venue": "Systems & Control: Foundations & Applications. Birkh\u00e4user Boston, Inc.",
            "year": 1991
        },
        {
            "authors": [
                "T. Chen",
                "M. Ludkovski"
            ],
            "title": "A machine learning approach to adaptive robust utility maximization and hedging",
            "venue": "SIAM Journal on Financial Mathematics, 3(12):1226\u20131256",
            "year": 2021
        },
        {
            "authors": [
                "T. Chen",
                "J. Myung"
            ],
            "title": "Nonparametric adaptive bayesian stochastic control under model uncertainty",
            "venue": "Preprint",
            "year": 2020
        },
        {
            "authors": [
                "E. Del Barrio",
                "E. Gin\u00e9",
                "C. Matr\u00e1n"
            ],
            "title": "Central limit theorems for the wasserstein distance between the empirical andthe true distributions",
            "venue": "The Annals of Probability, 27(2):1009\u20131071",
            "year": 1999
        },
        {
            "authors": [
                "N. Fournier",
                "A. Guillin"
            ],
            "title": "On the rate of convergence in wasserstein distance of the empirical measure",
            "venue": "Probability Theory and Related Fields, 162:707\u2013738",
            "year": 2015
        },
        {
            "authors": [
                "M.G. Genton"
            ],
            "title": "Classes of kernels for machine learning: a statistics perspective",
            "venue": "The Journal of Machine Learning Research, 2:299\u2013312",
            "year": 2002
        },
        {
            "authors": [
                "I. Gilboa",
                "D. Schmeidler"
            ],
            "title": "Maxmin expected utility with nonunique prior",
            "venue": "J. Math. Econom., 18(2):141\u2013153",
            "year": 1989
        },
        {
            "authors": [
                "P.L. Hansen",
                "T.J. Sargent"
            ],
            "title": "Robustness",
            "venue": "Princeton University Press",
            "year": 2008
        },
        {
            "authors": [
                "L.P. Hansen",
                "G. Sargent",
                "G. Turmuhambetova",
                "N. Williams"
            ],
            "title": "Robust control and model misspecification",
            "venue": "J. Econom. Theory, 128(1):45\u201390",
            "year": 2006
        },
        {
            "authors": [
                "D. Kuhn",
                "P. Esfahani",
                "V. Nguyen",
                "S. Abadeh"
            ],
            "title": "Wasserstein distributionally robust optimization: Theory and applications in machine learning",
            "venue": "INFORMS Tutorials in Operations Research, pages 130\u2013166",
            "year": 2019
        },
        {
            "authors": [
                "P.R. Kumar",
                "P. Varaiya"
            ],
            "title": "Stochastic Systems: Estimation",
            "venue": "Identification, and Adaptive Control. Prentice Hall, Inc.",
            "year": 2015
        },
        {
            "authors": [
                "M. Nutz"
            ],
            "title": "Utility maximization under model uncertainty in discrete time",
            "venue": "Mathematical Finance, 26(2):252\u2013268",
            "year": 2016
        },
        {
            "authors": [
                "J. Obl\u00f3j",
                "J. Wiesel"
            ],
            "title": "Distributionally robust portfolio maximisation and marginal utility pricing in one period financial markets",
            "venue": "Mathematical Finance Special Issue in Memory of Professor Mark H. A. Davis, pages 1454\u20131493",
            "year": 2021
        },
        {
            "authors": [
                "U. Rieder"
            ],
            "title": "Bayesian dynamic programming",
            "venue": "Adv. Appl. Prob., 7:330\u2013348",
            "year": 1975
        },
        {
            "authors": [
                "C.E. Rasmussen",
                "C.K.I. Williams"
            ],
            "title": "Gaussian Processes for Machine Learning",
            "venue": "The MIT Press",
            "year": 2006
        },
        {
            "authors": [
                "M. Sirbu"
            ],
            "title": "A note on the strong formulation of stochastic control problems with model uncertainty",
            "venue": "Electronic Communications in Probability, 19",
            "year": 2014
        }
    ],
    "sections": [
        {
            "text": "Keywords: nonparametric adaptive robust control, model uncertainty, stochastic control, adaptive robust dynamic programming, Wasserstein distance, Markovian control problem, utility maximization. MSC2010: 49L20, 49J55, 93E20, 93E35, 60G15, 65K05, 90C39, 90C40, 91G10, 91G60, 62G05\nContents"
        },
        {
            "heading": "1 Introduction 2",
            "text": ""
        },
        {
            "heading": "2 Nonparametric Stochastic Control Problem Subject to Model Uncertainty 3",
            "text": "2.1 Empirical Distribution and Uncertainty Set . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2 Nonparametric Adaptive Robust Control Problem . . . . . . . . . . . . . . . . . . . 6\n2.3 Solution of Nonparametric Adaptive Robust Control Problem . . . . . . . . . . . . . 9\n2.4 Convergence Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13"
        },
        {
            "heading": "3 Nonparametric Adaptive Robust Utility Maximization 15",
            "text": "3.1 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n3.2 Numerical Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n\u2217E. Bayraktar is partially supported by the National Science Foundation under grant DMS-2106556 and by the Susan M. Smith chair.\nDepartment of Mathematics, University of Michigan, Ann Arbor 530 Church Street, Ann Arbor, MI 48109, USA Email: erhan@umich.edu, URL: https://sites.lsa.umich.edu/erhan/\n\u2020\nEmail: chenta@umich.edu, URL: http://taochen.im\nar X\niv :2\n20 2.\n10 39\n1v 3\n[ m\nat h.\nO C\n] 2\n1 M\nar 2\n02 2"
        },
        {
            "heading": "1 Introduction",
            "text": "In this paper we propose a new methodology for solving a stochastic Markovian control problem in discrete time under model uncertainty. Unlike many works in this area that assume the unknown probability law of the underlying stochastic process belongs to some parametric family of distributions, we avoid making such postulation to prevent model misspecification. When it comes to handling model uncertainty, there are different approaches, parametric and nonparametric, developed in the past decades to incorporate learning into solving control problems with unknown system models (cf. [KV15], [CG91], [Rie75], [CM20]). However, earlier studies show that a pure learning approach without awareness of the model risk is prone to risk caused by estimation error and often leads to overly aggressive controls and system outcomes with high variances. On the other hand, the central idea of robust control goes back to [GS89]. A large body of research have been devoted to this area since then, and produced fruitful resutls which are briefly summarized in Section 2. Robust techniques are extremely successful in dealing with model risk but if the learning phase is lacking in the framework, corresponding controls can be overly conservative and even trivial. Our work aims to address all the issues mentioned above when handling a Markovian control problem by proposing a nonparametric adaptive robust methodology and develop an efficient numerical scheme for implementing such method.\nA robust control problem can be viewed as a game between the controller and the nature. In the traditional setup, the nature chooses the worst case model against the controller at the beginning of the game. To respond, the controller adopts a control law which determines the game strategies at all time steps through the timeline. In a sense, both counterparties\u2019 strategies are pre-committed. Mathematically, the controller takes a set of considered models, solves the optimization problem for every model in such set, and chooses the strategy corresponding to the worst model against the controller. We refer to [HSTW06], [HS08], and [BB95], for more information regarding this setup. More recent works consider a robust control problem as a sequential game: from a fixed set of models, at each time step the nature chooses one that is the worst for the controller, and the controller will apply an optimal control in response (cf. [Sir14], [BCP16]). The main difference between the two approaches mentioned so far is that the worst case model is time independent in the former case and time dependent in the latter. In [Nut16], the author presented a robust framework where the nature chooses models from a time dependent set. In other words, the nature can pick strategies from different sets of available actions at different stages of the game. In [BCC+19], the authors specified the dynamics of such sets via recursive confidence regions of the unknown model parameters. We refer to [BCC17] for the detailed discussion of recursive construction of confidence regions. Such idea is also utilized in this work. The advantage of using confidence regions are twofold. On one hand, as new realization of the random noise in the system is observed between the decision-making time points, the confidence region updates itself and naturally represents the learning of the unknown system model. On the other hand, such sequence of sets is asymptotically shrinking in size which leads to reduction of the model uncertainty. To the best of our knowledge, [BCC+19] is the first work that incorporates the idea of online learning into the robust control paradigm. A follow-up work in [BC21] is an attempt to extend the adaptive robust control to the continuous time setup.\nNote that the methods in [BCC+19] and [BC21] are parametric and the practical usage of such methods relies on the assumption that the family of the unknown probability law of the underlying stochastic process is known to the controller. Some researchers have realized this drawback and adopts nonparametric statistical methods by assuming uncertainty for the family of parametric models. To formulate a robust setup, one will define a set of probability distributions that includes the estimated distribution. For example, in [KENA19] and [OW21], the authors take a Wasserstein\nball around the empirical distribution and use the ball as the set of considered models. However, such setup has only been implemented in one-period control problems so far, and the feasibility of this approach in multi-period setup remains to be investigated. To overcome this obstacle, we develop a nonparametric adaptive robust control methodology in this work to handle multiperiod stochastic control problems where the family of distributions which the true law of the system model belongs to is unknown. Naturally, we use the empirical distribution as the estimate of the distribution of the underlying stochastic process. Another candidate for this purpose is the perturbed empirical distribution when such distribution is known to be continuous. For construction of confidence regions in this setup, we utilize the Wasserstein ball around the empirical distribution. There are several works on the concentration results regarding the empirical distribution and the Wasserstein distance (cf. [DBGM99], [FG15]). Backed by these papers, one obtains a CLT-type of result for the empirical distribution that leads to construction of confidence regions through Wasserstein distance under rather mild assumptions. Practically, numerical search of the worst case model in a set of probability distributions is extremely difficult. Another advantage of using the Wasserstein ball as the confidecnce region is that the aforementioned task of searching for the worst case model in a Wasserstein ball can be converted to a scalar optimization problem. Last but not the least, we implement a machine learning technique via the Gaussian process surrogates [RW06] to build regression models for the relevent value function and the optimal control. The former surrogate enables us to proceed the backward recursion according to the dynamic programming principle, and the latter allows us for fast computation of the optimal control when applying our framework.\nThe rest of the paper is organized as follows. We begin Section 2 with setting up the model and in Section 2.1 we discuss the contruction of confidence region for the unknown true probability law in terms of the Wasserstein ball. Such sets of distributions represent the uncertainty of the system model. Section 2.2 is dedicated to the formulation of the nonparametric adaptive robust control framework. We investigate the solution of the nonparametric adaptive robust control problem and derive the associated Bellman equations in Section 2.3. Also in this section, we prove the Bellman principle of optimality for the problem and show the existence of measurable worst-case model selector as well as the existence of measurable optimal control. In Section 2.4, we discuss the convergence and deviation of the adaptive robust value function to the true value function. Finally, in Section 3 we consider an illustrative example. Namely, the uncertain utility maximization problem where the investor needs to allocate the wealth between the money market account and the risky asset without knowing the true distribution of the risky asset\u2019s return process. We apply the nonparametric adaptive robust control approach to such problem and provide a numerical solver by using machine learning techniques. Numerical results presented in this section show the favorable aspects of the proposed methodology to the traditional robust control framework and the case of knowing the true model."
        },
        {
            "heading": "2 Nonparametric Stochastic Control Problem Subject to Model",
            "text": "Uncertainty\nLet (\u2126,F ) be a measurable space, and T \u2208 N be a fixed time horizon. Let T = {0, 1, 2, . . . , T}, T \u2032 = {0, 1, 2, . . . , T \u2212 1}, and T \u2032\u2032 = {1, 2, . . . , T}. On the space (\u2126,F ) we consider a controlled random process X = {Xt, t \u2208 T } taking values in Rn with dynamics\nXt+1 = S(Xt, \u03d5t, Zt+1), t \u2208 T \u2032, X0 = x0 \u2208 Rn. (2.1)\nThe above Z = {Zt, t \u2208 T } is an i.i.d. real valued random sequence of which the natural filtration is denoted by F = (Ft, t \u2208 T ). The process \u03d5 = {\u03d5t, t \u2208 T \u2032} is F-adapted and takes values in a compact set A. The function S : Rn\u00d7A\u00d7R\u2192 Rn is deterministic and continuous. For every t \u2208 T \u2032, we denote by At the set of all processes that take values in A and are adapted to the filtration Ft := (Fs, t \u2264 s \u2264 T \u2212 1). Each element in At is called an admissible control starting at time t, and we use the convention A = A0. In this work, we assume that the process Z is observable but the distribution F \u2217 of each Zt is unknown. We write P(R) as the set of all distributions on R and PF as the probability measure on (\u2126,F ) corresponds to F \u2208 P(R). The expectation associated to PF is EF , and ` : Rn \u2192 R is the loss function which is continuous. In this work we will formulate and solve a robust optimization problem aiming to minimize the expected loss when taking into consideration that the true distribution F \u2217 of Z is unknown. In order to avoid model misspecification caused by assuming a wrong parametric family of distrubtions, we will conduct online learning of the underlying system in a nonparametric manner via empirical distribution. In the spirit of [BCC+19], we define the sets of model candidates as approximated confidence regions around the empirical distribution. Such sets are Wasserstein balls and their sizes decreases as time goes on in general. Therefore, in our robust framework, the uncertainty is dynamically reduced through online learning and shrinkage of the Wasserstein balls."
        },
        {
            "heading": "2.1 Empirical Distribution and Uncertainty Set",
            "text": "We make a standing postulation that F \u2217 satisfies that\u222b \u221e \u2212\u221e \u221a F \u2217(z)(1\u2212 F \u2217(z))dz <\u221e. (2.2)\nWe note that any distribution that has finite moments with order higher than 2 will satisfy the above assumption. Next, denote by F\u0302t, t \u2208 T \u2032, the empirical distrubtion of Zt+1 given the initial guess F\u03020 of F\n\u2217 and the observations Z1:t := {Zi, i = 1, . . . , t}, where F\u03020 is the empirical distribution of Z1 based on historical data of Z with sample size t0. In other words, F\u0302t is the contructed based Z\u2212t0+1:t. Defined as an average of indicator functions, F\u0302t satisfies the following recursion similarly to any estimated mean:\nF\u0302t+1(z) = (t0 + t)F\u0302t + 1{Zt+1<z}\nt0 + t+ 1 := R(t, F\u0302t, Zt+1), z \u2208 R, t \u2208 T \u2032. (2.3)\nThe map R defined above will be viewed as the dynamics of the process F\u0302 . Regarding other properties of F\u0302 , it is well known that F\u0302 is a consistent estimator of F \u2217:\nlim t\u2192\u221e\nF\u0302t(z) = F \u2217(z), a.s..\nMoreover, by the assumption (2.2) and using the results in [DBGM99], we have that\n\u221a t0 + tdW,1(F\u0302t, F \u2217) = \u221a t0 + t \u222b \u221e \u2212\u221e |F\u0302t(z)\u2212 F \u2217(z)|dz \u2192 \u222b 1 0 |B(s)|dQ\u2217(s), (2.4)\nwhere dW,1 is the Wasserstein distance of order 1, B(s), 0 \u2264 s \u2264 1, and Q\u2217 are the Brownian bridge and the quantile function of F \u2217, respectively, and the convergence is in distribution. We will construct an approximated confidence region for F \u2217 based on (2.4). Since Q\u2217 is unknown, we\nwill approximate it by using Q\u0302t which is the quantile function corresponding to F\u0302t. At time t, the integral \u222b 1 0 |B(s)|dQ\n\u2217(s) is then approximated as\u222b 1 0 |B(s)|dQ\u2217(s) \u2248 t0+t\u22121\u2211 i=1 \u2223\u2223\u2223\u2223B( it0 + t )\u2223\u2223\u2223\u2223 (z(i+1) \u2212 z(i)) =: Ht(F\u0302t),\nwhere z(1):(t0+t) is the order statistics of z\u2212t0+1:t. We define the \u03b1-uncertainty set C\u03b1t , 0 < \u03b1 < 1, which is an approximated confidence region for F \u2217 as\nC\u03b1t (F\u0302t) = { F \u2208 P1(R) : dW,1(F\u0302t, F ) \u2264\nQHt (1\u2212 \u03b1)\u221a t0 + t\n} , (2.5)\nwhere P1(R) is the set of all distributions with finite first moment, and QHt is the quantile function of Ht(F\u0302t). Due to the discussion above, the rational behind (2.5) is that the probability that C\u03b1t (F\u0302t) contains F\n\u2217 is approximately 1\u2212 \u03b1. Note that theoretically we can derive the distribution of \u2211t0+t\u22121\ni=1 |B( i t0+t )|(z(i+1)\u2212z(i)). But since B( it0+t), i = 1, . . . , t0+t\u22121, are not independent, then\nsuch computation will be too tedious. Hence, we will estimate QHt (1 \u2212 \u03b1) via simulation instead. As another way to justify that the radius of the Wasstertein ball being a multiple of 1\u221a\nt0+t is the\ncalculation from [FG15] where they show, under the stronger assumption\u222b R ec1|z| c2 F \u2217(dz) <\u221e, (2.6)\nfor some c1 > 0, and c2 > 1, that for any fixed 0 < \u03b1 < 1, there exists some constants C and c such that\nP ( dW,1(F\u0302t, F \u2217) \u2264 \u221a log(C/\u03b1)\nc(t+ t0)\n) \u2265 1\u2212 \u03b1. (2.7)\nA different formulation of the uncertainty sets can be obtained from (2.7). However, radius of the resulting Wasserstein ball has the same order, namely, 1\u221a\nt0+t as of C\u03b1t .\nNext, by using a different representation of the Wasserstein distance between probability distributions, we have the following technical result for the map defined in (2.3).\nLemma 2.1. For fixed t \u2208 T \u2032, the mapping R(t, \u00b7, \u00b7) : P1(R)\u00d7 R\u2192 P1(R) is continuous.\nProof. Assume that (Fn, zn) \u2192 (F, z) where Fn, F \u2208 P1(R), zn, z \u2208 R, n = 1, 2, , . . .. Then, dW,1(Fn, F ) \u2192 0 and zn \u2192 z. Denote \u00b5Fn,zn = R(t, Fn, zn) and \u00b5F,z = R(t, F, z). For M := {f : |f(x)\u2212 f(y)| \u2264 |x\u2212 y|}, we have that\ndW,1(\u00b5Fn,zn , \u00b5F,z) = sup {\u222b R fd\u00b5Fn,zn \u2212 \u222b R fd\u00b5F,z : f \u2208M } = sup { t0 + t\nt0 + t+ 1 (\u222b R fdFn \u2212 \u222b R fdF ) +\n1\nt0 + t+ 1 (f(zn)\u2212 f(z)) : f \u2208M } \u2264 t0 + t t0 + t+ 1 sup {\u222b R fdFn \u2212 \u222b R fdF : f \u2208M } + 1 t0 + t+ 1 |zn \u2212 z| = t0 + t\nt0 + t+ 1 dW,1(Fn, F ) +\n1\nt0 + t+ 1 |zn \u2212 z|.\nTherefore, we get that dW,1(\u00b5Fn,zn , \u00b5F,z)\u2192 0 and the mapping R(t, \u00b7, \u00b7) is continuous.\nOne property that the set valued function C\u03b1t satisfies is upper hemicontinuity (u.h.c.). That is for any for any F \u2208 P1(R) and any open set E such that C\u03b1t (F ) \u2282 E \u2282 P1(R), there exists a neighbourhood D of F such that for all F \u2032 \u2208 D, C\u03b1t (F \u2032) \u2282 E (cf. [Bor85, Definition 11.3]). To see that C\u03b1t is u.h.c., let \u03b5 = dist(F, \u2202E)\u2212QHt (1\u2212\u03b1)/ \u221a t0 + t where dist(F, \u2202E) is the shortest distance from F to the boundary of E. Then, take D as the ball centered at F with radius \u03b5. It is not hard to see that for any F \u2032 \u2208 D, we have C\u03b1t (F \u2032) \u2282 E. We summarize the result as follows\nLemma 2.2. For every t \u2208 T \u2032, the set valued function C\u03b1t is upper hemicontinuous.\nAs per our discussion above, the proof is straightforward and we omit it here."
        },
        {
            "heading": "2.2 Nonparametric Adaptive Robust Control Problem",
            "text": "Now we proceed to formulate the nonparametric adaptive robust control problem. For the rest of the paper, we will consider P1(R) with the metric dW,1. Since R is separable and complete, then (P1(R), dW,1) is also separable and complete. Hence, P1(R) is a Polish space and thus a Borel space. Define the augumented state process Y = {Yt = (Xt, F\u0302t), t \u2208 T }, and the augumented state space EY = Rn \u00d7 P1(R). For EY we equip the product topology, it is then a Borel space and the Borel \u03c3-algebra EY conicides with the product \u03c3-algebra. The process Y has the following dynamics\nYt+1 = G(t, Yt, \u03d5t, Zt+1) := (S(Xt, \u03d5t, Zt+1), R(t, F\u0302t, Zt+1)), t \u2208 T \u2032. (2.8)\nAccording to the assumption that S is continuous and Lemma 2.1, we get that G is continuous and therefore Borel measurable. Next, given our setup, the process Y is F-adapted and Markovian. The transition probability for the state process Y is defined as follows. For any t \u2208 T \u2032, (y, a) \u2208 EY \u00d7A, and F \u2208 P1(R), Qt is a probability measure on EY such that\nQt(D|y, a, F ) = PF (G(t, y, a, Zt+1) \u2208 D), D \u2208 EY .\nOne important property of the stochastic kernel Qt is that it is in fact Borel measurable which will be proved below. Such property is crucial for showing the existence of measurable optimal controls.\nProposition 2.3. For each t \u2208 T \u2032, the probability Qt( \u00b7 |y, a, F ) is a Borel measurable stochastic kernel on EY given EY \u00d7A\u00d7 P1(R).\nProof. According to [BS78], it is enough to show that for any b1, b2 \u2208 Rn and closed ball D \u2286 P(R) with finite radius, Qt([b1, b2]\u00d7D|y, a, F ) is a measurable function in (y, a, F ), where\n[b1, b2] := X n i=1[b (i) 1 , b (i) 2 ], bj = (b (1) j , . . . , b (n) j ), j = 1, 2.\nWe will prove that Qt([b1, b2] \u00d7 D|y, a, F ) is upper semi-continuous, and then it will be Borel measurable.\nFix any (y0, a0, F0) \u2208 EY \u00d7A\u00d7P1(R), and let {(yn, an, Fn), n > 0} be a sequence that converges to (y0, a0, F0). Note that the set C0 := {z : G(t, y0, a0, z) \u2208 [b1, b2] \u00d7 D} is a closed set since the map G is continuous. We similary define Cn = {z : G(t, yn, an, z) \u2208 [b1, b2]\u00d7D}, n > 0, and they satisfy the same properties.\nWe first prove that \u22c3\u221e i=0Ci is bounded. Assume the union contains at least two points. If the two points z1 < z2 belong to the same Cn, denote by f\u0302n the second component of yn, we have that\ndW,1(\u00b5f\u0302n,z1 , \u00b5f\u0302n,z2) = sup {\u222b R gd\u00b5f\u0302n,z1 \u2212 \u222b R gd\u00b5f\u0302n,z2 : g \u2208M } = sup\n{ g(z1)\u2212 g(z2) t0 + t+ 1 : g \u2208M }\n\u2265 z2 \u2212 z1 t0 + t+ 1 .\nSince D is a bounded set, then z2 must be within a bounded range of z1. Next assume that there are zk \u2208 Ck and zl \u2208 Cl, and zl > zk. Again, we have\ndW,1(\u00b5f\u0302l,zl , \u00b5f\u0302k,zk) = sup {\u222b R gd\u00b5f\u0302l,zl \u2212 \u222b R gd\u00b5f\u0302k,zk : g \u2208M } \u2265 t0 + t t0 + t+ 1 (Ef\u0302l [Zl]\u2212 Ef\u0302k [Zk]) + zl \u2212 zk t0 + t+ 1 .\nSince {yn, n > 0} is a convergent sequence, then the value of the first term on the right hand side of the above inequality is bounded for any k and l. Moreover, the value zl \u2212 zk should be bounded as well. Now we see that \u22c3\u221e i=0Ci is bounded and every single Cn is compact. Next, we show that if C0 = \u2205 then for large enough n the set Cn is also empty. In particular, if the preimage R\u22121(t, f\u03020, D) = \u2205, then for large enough n, R\u22121(t, f\u0302n, D) = \u2205. Otherwise, we can find a subsequence nk, k > 0, such that there exist znk \u2208 R\u22121(t, f\u03020, D) for all k. Without loss of generality, we assume that znk is convergent due to the fact that \u22c3\u221e i=0Ci is compact. Then, R(t, f\u0302nk , znk), k > 0, is a convergent sequence and R(t, f\u0302nk , znk) \u2208 D, k > 0. Because D is closed, the limit R(t, f\u03020, z0) \u2208 D which implies that z0 \u2208 C1. This contradicts to the assumption that R\u22121(t, f\u03020, D) = \u2205, hence for large enough n, R\u22121(t, f\u0302n, D) = \u2205. On the other hand, by using the continuity argument, it is also easy to see that if S(x0, a0, z) /\u2208 [b1, b2] for all z \u2208 R, then for large enough n, S(xn, an, z) /\u2208 [b1, b2] for all z \u2208 R. We have proved that if C0 = \u2205 then for large enough n the set Cn is also empty. In this case,\nlim n\u2192\u221e\nQt([b1, b2]\u00d7D|yn, an, Fn) = Q([b1, b2]\u00d7D|t, y0, a0, F0) = 0,\nand the function Qt([b1, b2]\u00d7D|y, a, F ) is continuous and therefore upper semi-continuous at such (y0, a0, F0).\nFor the rest of the proof, we assume that C0 6= \u2205. Let \u03b5m > 0, m > 0, be a strictly decreasing sequence that converges to 0. For any \u03b5m and z \u2208 R, let Bm(z) be the open ball centered at z with radius \u03b5m. The collection {Bm(z) : z \u2208 C0} is an open cover of the compact C0, and there exists a finite subcover Bm(z(1)), . . . ,Bm(z(km)). Define the set Cm0 = \u22c3km i=1 Bm(z(i)), and we argue that for any m > 0, there exists Nm > 0 such that for any n > Nm, we have Cn \u2286 Cm0 . We prove the above statement by contradiction. Assume that it is not true. Then for any N > 0, there exits n > N such that Cn 6\u2286 Cm0 . Consequently, there exists a sub-sequence nj , j > 0, such that znj \u2208 Cnj but znj /\u2208 Cm0 . From previous discussions we know the sequence znj is bounded, and moreover there exists a z\u2217 that is a limiting point of znj . It is safe to assume\nz\u2217 /\u2208 Cm0 (2.9)\nfor the reason that if z\u2217 is on the boundary of Cm0 , we can replace \u03b5m with a number in the interval (\u03b5m+1, \u03b5m). Let us consider the sequence {G(t, ynj , anj , znj ), j > 0}. Recall that znj \u2208 Cnj , hence G(t, ynj , anj , znj ) \u2208 [b1, b2]\u00d7D for all j > 0. Due to Lemma 2.1, G(t, y0, a0, z\u2217) is a limiting point\nof such sequence. In addition, since [b1, b2]\u00d7D is a closed set, then z\u2217 \u2208 C0 \u2286 Cm0 which contradicts to (2.9). Now we conclude that any m > 0, there exists Nm > 0 such that for any n > Nm, we have Cn \u2286 Cm0 .\nNext, we obtain that\nQt([b1, b2]\u00d7D|yn, an, Fn) = PFn(Cn) \u2264 PFn(Cm0 ). (2.10)\nSince Cm0 is a closed set, and Fn converges weakly to F0, then (2.10) implies that\nlim sup n Qt([b1, b2]\u00d7D|yn, an, Fn) = lim sup n PFn(Cn) \u2264 lim sup n PFn(Cm0 ) \u2264 PF0(Cm0 ).\nFinally, note that one can construct {Cm0 ,m > 0} such that the sequence of sets is decreasing and\u22c2 mC m 0 = C0. We have\nlim m\u2192\u221e\nPF0(Cm0 ) = PF0(C0).\nIt follows immediately that\nlim sup n\nQt(b1, b2]\u00d7D|yn, an, Fn) \u2264 Qt([b1, b2]\u00d7D|y0, a0, F0).\nTo summarize, we obtain that Qt([b1, b2]\u00d7D| \u00b7, \u00b7, \u00b7 ) is upper semi-continuous. Therefore, it is a Borel measurable function.\nIn this work, we are dealing with a closed loop feedback control problem. To this end, a control process \u03d5 is called Markovian if for every t \u2208 T \u2032 (with a slight abuse of notation)\n\u03d5t = \u03d5t(Yt)\nwhere on the right hand side \u03d5t : EY \u2192 A is a measurable mapping. Similarly, A process \u03c8 is called a Markovian model selector if\n\u03c8t = \u03c8t(Yt)\nwhere \u03c8t : EY \u2192 P1(R) is measurable. In the adaptive robust framework, we consider the Markovian control processes and Markovian model selectors such that \u03c8t(y) \u2208 C\u03b1t (y) for any y \u2208 EY . For every t \u2208 T \u2032, any time t state yt \u2208 EY , and control process \u03d5 \u2208 At, we denote\n\u03a8\u03d5yt,t = {\u03c8t:T\u22121, \u03c8s(ys) \u2208 C \u03b1 s (ys), \u2203z \u2208 R, s.t. ys+1 = G(s, ys, \u03d5s(ys), z), t \u2264 s < T \u2212 1} .\nand\n\u03a8yt,t = {\u03c8t:T\u22121, \u03c8s(ys) \u2208 C\u03b1s (ys),\u2203a \u2208 A, z \u2208 R, s.t. ys+1 = G(s, ys, a, z), t \u2264 s < T \u2212 1} .\nNext, for every t \u2208 T \u2032, any yt \u2208 EY , \u03d5 \u2208 At, and \u03c8 \u2208 \u03a8yt,t, we define the probability measure Q \u03d5,\u03c8 yt,t on the concatenated canonical space XTs=t+1EY as\nQ\u03d5,\u03c8yt,t(Bt+1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7BT ) = \u222b Bt+1 \u00b7 \u00b7 \u00b7 \u222b BT T\u22121\u220f u=t Qu(dyu+1|yu, \u03d5u(yu), \u03c8u(yu)).\nCorrespondingly, we define the family of probability measures Q\u03d5yt,t = {Q \u03d5,\u03c8 yt,t , \u03c8 \u2208 \u03a8yt,t}. In particular, we let Q\u03d5y0 = Q \u03d5 y0,0\n. Then, for given y0 \u2208 EY , the nonparametric adaptive robust control problem is formulated as\ninf \u03d5\u2208A sup Q\u2208Q\u03d5y0\nEQ[`(XT )]. (2.11)\nIn a traditional robust setup, one would choose a fixed set P0 in place of C\u03b1t . Due to such reason, we will call it the static robust framework throughout. In comparison, the advantage of (2.11) is that such framework integrates robust control with learning and reducing uncertainty. The learning of the unknown model is carried through via the evolution of the process Y , and reduction of uncertainty is embedded in the construction of Q\u03d5y0 since for any yt \u2208 EY instead of finding the worst case model in the fixed set P0, the selectors take values in the uncertainty sets C\u03b1t (yt) which is a sequence of random sets that shrink in size."
        },
        {
            "heading": "2.3 Solution of Nonparametric Adaptive Robust Control Problem",
            "text": "We will show that solution of the nonparametric adaptive robust control problem is given by solving the following adaptive robust Bellman equations\nVT (y) = `(x), y \u2208 EY ,\nVt(y) = inf a\u2208A sup F\u2208C\u03b1t (y) \u222b EY Vt+1(yt+1)Qt(dyt+1|y, a, F ), y \u2208 EY , t \u2208 T \u2032. (2.12)\nBefore we prove the main theorem in this section, let us first provide the following technical result.\nLemma 2.4. Fix t \u2208 T \u2032, for any F\u0302 \u2208 P1(R), let\nC\u0303\u03b1t (F\u0302 ) = { F \u2208 P1(R) : dW,1(F, F\u0302 ) <\nQHt (1\u2212 \u03b1)\u221a t0 + t\n} .\nThen,\nO\u03b1t := \u22c3 y\u2208EY C\u0303\u03b1t (y)\nis an open set in EY \u00d7 P1(R).\nProof. We prove the statement by contradiction. Assume there exists (y0, F0) \u2208 O\u03b1t , and there exists a sequence (yn, Fn)\u2192 (y0, F0), such that for any n > 0, (yn, Fn) /\u2208 O\u03b1t . Note that F0 \u2208 C\u0303\u03b1t (y0), hence dW,1(F0, f\u03020) < Q H t (1\u2212 \u03b1)/ \u221a t0 + t\u2212 \u03b5 for some \u03b5 > 0, where f\u03020 is the second component of y0. We have\ndW,1(Fn, f\u0302n) \u2264 dW,1(Fn, F0) + dW,1(F0, f\u03020) + dW,1(f\u03020, f\u0302n).\nFor large enough n, we have dW,1(Fn, F0) < \u03b5/4, and dW,1(f\u03020, f\u0302n) < \u03b5/4. Then, for such n, the following equality holds true\ndW,1(Fn, f\u0302n) \u2264 QHt (1\u2212 \u03b1)\u221a t0 + t \u2212 \u03b5 2 ,\nwhich implies that Fn \u2208 C\u0303\u03b1t (yn) and (yn, Fn) \u2208 O\u03b1t . We get the contradiction so the set O\u03b1t is open.\nNext, we have the main result of this section which shows that the optimal control \u03d5 and model selector \u03c8 exist, and they are sequences of measurable functions.\nTheorem 2.5. For every t \u2208 T , the function Vt is lower semicontinuous (l.s.c.) and upper semianalytic (u.s.a.). There exists Borel measurable optimal control \u03d5\u2217t , t \u2208 T \u2032, and universally measurable model selector \u03c8\u2217t , t \u2208 T \u2032.\nProof. Since VT (y) = `(x) which is continuous by assumption, then VT is l.s.c. and u.s.a.. Next, denote\nvT\u22121(y, a, F ) = \u222b EY VT (yT )QT\u22121(dyT |y, a, F ).\nBy using Proposition 2.3, we have that vT\u22121(y, a, F ) is u.s.a.. Let D = \u22c3\n(y,a)\u2208EY \u00d7A C \u03b1 T\u22121(y). Note\nthat C\u03b1T\u22121 is u.h.c. from Lemma 2.2 and closed valued, by adopting the proof of [BCC21] in our setup, we obtain that the graph of C\u03b1t\u22121, which is D, is closed. Hence, the set D is analytic. The (y, a) section of D is C\u03b1T\u22121(y), and according to [BS78], we get that\nv\u0303T\u22121(y, a) := sup F\u2208C\u03b1T\u22121(y) vT\u22121(y, a, F )\nis u.s.c.. Moreover, for any \u03b5 > 0, there exists an analytically measurable function \u03c8\u0303 : EY \u00d7A such that for any (y, a),\nvT\u22121(y, a, \u03c8\u0303(y, a)) \u2265 { v\u0303T\u22121(y, a)\u2212 \u03b5, if v\u0303T\u22121(y, a) <\u221e, 1/\u03b5, if v\u0303T\u22121(y, a) =\u221e.\n(2.13)\nDefine the set I = { (y, a) \u2208 EY \u00d7A : for some F \u2217 \u2208 C\u03b1T\u22121(y), vT\u22121(y, a, F \u2217) = v\u0303T\u22121(y, a) } ,\nand we claim that I = EY \u00d7 A. That is for any (y, a) \u2208 EY \u00d7 A there exists an F \u2217 such that vT\u22121(y, a, F\n\u2217) = v\u0303T\u22121(y, a). To see why this is true, by taking in (2.13) \u03b5 = 1/n, we obtain a sequence \u03c8\u0303n such that\nlim n\u2192\u221e vT\u22121(y, a, \u03c8\u0303n(y, a)) = v\u0303T\u22121(y, a).\nNext, note that C\u03b1T\u22121(y) is weakly compact, so there exists \u03c8\u0303\u2217(y, a) as a limiting point of \u03c8\u0303n(y, a), n > 0, such that vT\u22121(y, a, \u03c8\u0303\n\u2217(y, a)) = v\u0303T\u22121(y, a), and indeed I = EY \u00d7 A. Therefore, by [BS78], there exists a universally measurable function \u03c8\u2217T\u22121 : EY \u00d7A\u2192 C\u03b1T\u22121(y) which satisfies\nvT\u22121(y, a, \u03c8 \u2217 T\u22121(y, a)) = v\u0303T\u22121(y, a).\nNow we prove that the function v\u0303T\u22121(y, a) is l.s.c.. To this end, we write\nvT\u22121(y, a, F ) = \u222b R VT (G(T \u2212 1, y, a, z))dF (z).\nSince VT is l.s.c. and G(T \u2212 1, y, a, z) is continuous in (y, a, z), then VT (G(T \u2212 1, y, a, z)) is l.s.c.. On the other hand, F is clearly a continuous stochastic kernel on R given P1(R). In view of the assumption that ` is bounded below, we know the function vT\u22121(y, a, F ) is l.s.c.. Let us consider the optimization problem\nv\u0302T\u22121(y, a) = sup F\u2208C\u0303\u03b1t (y) vT\u22121(y, a, F ).\nLemma 2.4 shows that the set O\u03b1t is open in EY \u00d7P1(R), so it is also open in D\u2032 := EY \u00d7A\u00d7P1(R). The C\u0303\u03b1t (y) is the (y, a) section of D\u2032. By [BS78], we obtain that v\u0302T\u22121(y, a) is l.s.c.. Note for any y \u2208 EY , the uncertainty set C\u03b1t (y) is the closure of C\u0303\u03b1t (y), it follows immediately that v\u0303T\u22121(y, a) = v\u0302T\u22121(y, a) and the former is therefore l.s.c..\nIt remains to show that\nVT\u22121(y) = inf a\u2208A v\u0303T\u22121(y, a)\nis l.s.c., and there exists a Borel measruable function \u03d5\u2217 : EY \u2192 A such that\nVT\u22121(y) = v\u0303T\u22121(y, \u03d5 \u2217(y)).\nTowards this end, we note that D\u2032\u2032 = EY \u00d7 A is closed, and A by assumption is compact. The y section of D\u2032\u2032 is A for any y \u2208 EY . Thus, by [BS78], the function VT\u22121 is l.s.c., and the Borel measurable optimal control \u03d5\u2217 exists.\nWe shall prove the statement of all t = T \u2212 2, . . . , 0 by backward induction. Recall from Proposition 2.3, the stochastic kernel QT\u22122( \u00b7 |y, a, F ) is Borel measurable. Also, the function VT\u22121 is u.s.a.. Therefore,\nvT\u22122(y, a, F ) = \u222b EY VT\u22121(yT\u22121)QT\u22122(dyT\u22121|y, a, F )\nis u.s.a.. By using a similar argument as above, the function\nvT\u22122(y, a, F ) = \u222b EY VT\u22121(G(T \u2212 2, y, a, z))dF (z)\nis l.s.c.. The rest of the proof follows analogously.\nFinally, we show that the problem (2.11) will be solved by the adaptive robust Bellman equations (2.12). To this end, we introduce the set At = {\u03d5t:T\u22121, t \u2208 T \u2032}, and provide the following technical results for preparation.\nLemma 2.6. For every t \u2208 T \u2032, and any \u03d5 \u2208 At, the function\nsup Q\u2208Q\u03d5yt,t\nEQ[`(XT )]\nis upper semianalytic in yt.\nThe proof for this lemma is a direct modification of Theorem 2.5 and hence we omit it here. Such result ensures that the mentioned function is measurable and can be integrated. Now we are ready to present the solution of the adaptive robust control problem.\nTheorem 2.7. For every t \u2208 T \u2032, and any yt \u2208 EY , we have\nVt(yt) = inf \u03d5\u2208At sup Q\u2208Q\u03d5yt,t\nEQ[`(XT )].\nMoreover, with \u03d5\u2217t and \u03c8 \u2217 t , t \u2208 T \u2032, in Theorem 2.5, we get\ninf \u03d5\u2208At sup Q\u2208A\u03d5yt,t EQ[`(XT )] = E Q \u03d5\u2217 t:T\u22121,\u03c8 \u2217 t:T\u22121 yt,t [`(XT )].\nProof. We prove the result via backward induction in t = T \u2212 1, . . . , 1, 0. First, for t = T \u2212 1 and yT\u22121 \u2208 EY , we have\ninf \u03d5\u2208AT\u22121 sup Q\u2208Q\u03d5yT\u22121,T\u22121 EQ[`(XT )] = inf a\u2208A sup F\u2208C\u03b1T\u22121(yT\u22121) \u222b EY VT (yT )QT\u22121(yT |yT\u22121, a, F ) = VT\u22121(yT\u22121).\nNext, for t = T \u2212 2, . . . , 0 and yt \u2208 EY , by induction\ninf \u03d5\u2208At sup Q\u2208Q\u03d5yt,t EQ[`(XT )] = inf (\u03d5t,\u03d5t+1:T\u22121)\u2208At sup F\u2208C\u03b1t (yt) \u222b EY sup Q\u2208Q \u03d5t+1:T\u22121 yt+1,t+1 EQ[`(XT )]Qt(dyt+1|yt, \u03d5t(yt), F )\n\u2265 inf (\u03d5t,\u03d5t+1:T\u22121)\u2208At sup F\u2208C\u03b1t (yt) \u222b EY Vt+1(yt+1)Qt(dyt+1|yt, \u03d5t(yt), F )\n= inf a\u2208A sup F\u2208C\u03b1t (yt) \u222b EY Vt+1(yt+1)Qt(dyt+1|yt, a, F ) = Vt(yt),\nwhere the inequality is due to that\nsup Q\u2208Q\n\u03d5t+1:T\u22121 yt+1,t+1\nEQ[`(XT )] \u2265 inf \u03d5\u2208At+1 sup Q\u2208Q\u03d5yt+1,t+1 EQ[`(XT )] = Vt+1(yt+1).\nOn the other hand, for any \u03b5 > 0, let \u03d5\u03b5t+1:T\u22121 \u2208 At+1 be an \u03b5-optimal control starting at time t+ 1. We get\nsup\nQ\u2208Q \u03d5\u03b5 t+1:T\u22121 yt+1,t+1\nEQ[`(XT )] \u2264 inf \u03d5\u2208At+1 sup Q\u2208Q\u03d5yt+1,t+1 EQ[`(XT )] = Vt+1(yt+1) + \u03b5.\nIt is followed by\ninf \u03d5\u2208At sup Q\u2208Q\u03d5yt,t EQ[`(XT )] = inf (\u03d5t,\u03d5t+1:T\u22121)\u2208At sup F\u2208C\u03b1t (yt) \u222b EY sup Q\u2208Q \u03d5t+1:T\u22121 yt+1,t+1 EQ[`(XT )]Qt(dyt+1|yt, \u03d5t(yt), F )\n\u2264 inf (\u03d5t,\u03d5t+1:T\u22121)\u2208At sup F\u2208C\u03b1t (yt) \u222b EY\nsup\nQ\u2208Q \u03d5\u03b5 t+1:T\u22121 yt+1,t+1\nEQ[`(XT )]Qt(dyt+1|yt, \u03d5t(yt), F )\n\u2264 inf a\u2208A sup F\u2208C\u03b1t (yt) \u222b EY Vt+1(yt+1)Qt(dyt+1|yt, a, F ) + \u03b5\n= Vt(yt) + \u03b5.\nSince \u03b5 is arbitrary, we obtain\ninf \u03d5\u2208At sup Q\u2208Q\u03d5yt,t\nEQ[`(XT )] \u2264 Vt(yt).\nHence, we have\ninf \u03d5\u2208At sup Q\u2208Q\u03d5yt,t\nEQ[`(XT )] = Vt(yt).\nTo see that \u03d5\u2217 and \u03c8\u2217 in Theorem 2.5 solve the adaptive robust control problem, we just need to note that for every t \u2208 T \u2032\nVt(yt) = \u222b EY Vt+1(yt+1)Qt(dyt+1|yt, \u03d5\u2217t (yt), \u03c8\u2217t (yt))\n= \u222b EY \u222b EY Vt+2(yt+2)Qt+1(dyt+2|yt, \u03d5\u2217t (yt+1), \u03c8\u2217t+1(yt+1))Qt(dyt+1|y, \u03d5\u2217t (yt), \u03c8\u2217t (yt))\n= \u222b EY \u00b7 \u00b7 \u00b7 \u222b EY VT (yT ) T\u22121\u220f s=t Qs+1(dys|ys, \u03d5\u2217s(ys), \u03c8\u2217s(ys)) = E Q \u03d5\u2217 t:T\u22121,\u03c8 \u2217 t:T\u22121\nyt,t\n[`(XT )],\nwhere the above \u03c8\u2217s(ys) = \u03c8 \u2217 s(ys, \u03d5 \u2217 s(ys)), t \u2208 T \u2032, can be viewed as a composition of universally measurable functions and therefore universally measurable."
        },
        {
            "heading": "2.4 Convergence Analysis",
            "text": "A nice property of the combination of Wasserstein metric and adaptive robust control is that convergence analysis can be done in such framework very easily. As shown in Theorem 2.5 and 2.7, to deal with (2.11) one employs the dynamic programming principle and solves the following Bellman equation\nVt(y) = inf a\u2208A sup F\u2208C\u03b1t (y)\nEF [Vt+1(G(t, y, a, Zt+1))], t \u2208 T \u2032.\nAccording to [BDOW21, Theorem 2], by assuming V and S to be differentiable w.r.t. x, and denoting\nV at (y) = sup F\u2208C\u03b1t (y) EF [Vt+1(G(t, y, a, Zt+1))],\nwe get that\nV at (y) = EF\u0302t [Vt+1(G(t, y, a, Zt+1))] + QHt (1\u2212 \u03b1)\u221a\nt0 + t E F\u0302t [\u2223\u2223\u2223\u2223 \u2202\u2202xVt+1(G(t, y, a, Zt+1)) \u2223\u2223\u2223\u2223]+ o( 1\u221at0 + t ) .\n(2.14)\nFor any given state y = (x, f\u0302) \u2208 EY , denote by z\u2212t0+1:0 the historical sample points that generate F\u03020, and let z1:t be the observations of Z such that f\u0302(z) = \u2211t i=\u2212t0+1\n1{zi<z} t0+t\n. The following expectation is computed as\nE F\u0302t\n[Vt+1(G(t, y, a, Zt+1))] = 1\nt0 + t t\u2211 i=\u2212t0+1 Vt+1(G(t, y, a, zi)),\nwhich is the sample mean of the random variable Vt+1(G(t, y, a, Zt+1)) given sample z\u2212t0+1:t. By central limit theorem, we obtain that the convergence speed of E\nF\u0302t [Vt+1(G(t, y, a, Zt+1))] to the\nexpectation EF \u2217 [Vt+1(G(t, y, a, Zt+1))] is asymptotically of order 1\u221at0+t . Thus, as t increases the adaptive robust control problem converges to the control problem without uncertainty and the convergence speed is of order 1\u221a\nt0+t . Moreover, we get by using the Chebyshev inequality that\nP (\u2223\u2223\u2223EF\u0302t [Vt+1(G(t, y, a, Zt+1))]\u2212 \u00b5\u2217V \u2223\u2223\u2223 > \u03b5) \u2264 Var\n( E F\u0302t [Vt+1(G(t, y, a, Zt+1))] )\n(t0 + t)\u03b52 , (2.15)\nwhere \u00b5\u2217V = EF \u2217 [Vt+1(G(t, y, a, Zt+1))]. Inequality (2.15) implies that the first term on the right hand side in (2.14) has a high probability of being close to EF \u2217 [Vt+1(G(t, y, a, Zt+1))]. For example, taking \u03b5 = 1\u221a\nt0+t , then (2.15) implies\nP (\u2223\u2223\u2223EF\u0302t [Vt+1(G(t, y, a, Zt+1))]\u2212 \u00b5\u2217V \u2223\u2223\u2223 > 1\u221at0 + t ) \u2264 Var ( E F\u0302t [Vt+1(G(t, y, a, Zt+1))] ) .\nClearly, the above probability will continue to decrease as t increases. Note that with a further assumption given in the Cramer\u2019s Theorem:\u222b\nR e\u03b8zF \u2217(dz) <\u221e, \u2200\u03b8 \u2208 R, (2.16)\nwe have\nlim t\u2192\u221e\n1\nt+ t0 logP (\u2223\u2223\u2223EF\u0302t [Vt+1(G(t, y, a, Zt+1))]\u2212 \u00b5\u2217V \u2223\u2223\u2223 > \u03b5) = \u2212 sup \u03b8\u2208R ((\u00b5\u2217V + \u03b5)\u03b8 \u2212 logEF \u2217 [e\u03b8Zt+1 ]).\nAs a result, the probability that E F\u0302t [Vt+1(G(t, y, a, Zt+1))] deviates from the true value function for more than \u03b5 has an exponential decay in time with speed \u2212 sup\u03b8\u2208R((\u00b5\u2217V + \u03b5)\u03b8\u2212 logEF \u2217 [e\u03b8Zt+1 ]) which is an obvious improvement over (2.15). In summary, if assuming (2.16) and using C\u03b1t (y) as the uncertainty set, even though the overall convergence speed of Vt is still of order\n1\u221a t0+t , we\nobtain a more accurate value function compared to the true one. Based on (2.14), we can compare the adaptive robust framework to the static robust setup in a qualitative manner. For the latter, the uncertainty set is fixed for all t \u2208 T \u2032, and we denote it by P0. To solve the static robust control problem, one also utilizes the dynamic programming principle and solves\nV\u0303t(y) = inf a\u2208A sup F\u2208P0\nEF [V\u0303t+1(G(t, y, a, Zt+1))], t \u2208 T \u2032,\nwhere V\u0303 is the corresponding value function. We consider the set P0 defined as B\u03b4(F\u03020) which is a Wasserstein ball arond F\u03020 with radius \u03b4. We also define a preference relation between value functions via\nVt(y) V\u0303t(y) \u21d0\u21d2 sup F\u2208C\u03b1t (y) EF [Vt+1(G(t, y, a, Zt+1))] \u2264 sup F\u2208B\u03b4(F\u03020) EF [V\u0303t+1(G(t, y, a, Zt+1))],\nfor any a \u2208 A. Next, suppose that F \u2217 \u2208 Po0 which is the interior of the set P0. For large T and t, we have dW,1(F\u0302t, F \u2217) < dW,1(F \u2217, \u2202P0) with high probability, where dW,1(F \u2217, \u2202P0) is the Wasserstein distance from between F \u2217 and the closest point on the boundary of P0. Consequently, C\u03b1t (Yt) \u2282 P0 with high probability, and loosely speaking we get\nVt(y) V\u0303t(y), (2.17)\nasymptotically. Note that such discussion is rather qualitative since it is not easy to compute P(C\u03b1t (Yt) \u2282 P0) and prove (2.17) rigorously. Nevertheless, we argue that adaptive robust framework is more preferrable than static robust.\nFor a more quantitative analysis, we assume that P0 = C\u03b10 (y0). Similarly to (2.14), we have\nV\u0303 at (x) = EF\u03020 [V\u0303t+1(S(x, a, Zt+1))] + QH0 (1\u2212 \u03b1)\u221a\nt0 E F\u03020 [\u2223\u2223\u2223\u2223 \u2202\u2202xV\u0303t+1(S(x, a, Zt+1)) \u2223\u2223\u2223\u2223]+ o(1).\nIt is obvious that the right hand side of the above equality does not converge with respect to t. As a result, the static robust framework will produce strategies that in general distant from the optimal strategies without uncertainty. Such strategies behave very conservatively while adaptive robust has a better balance between being aggressive and conservative due to the embedded learning feature. In view of such, the adaptive robust methodology is more favorable compared to the static robust framework which offers no convergence to the true optimization problem.\nNote that discussions in this section are possible since we are using the Wasserstein metric to define the uncertainty sets. Similar analysis could be done when utilizing the Kullback-Leibler divergence but stronger assumptions on the considered probability distributions are required."
        },
        {
            "heading": "3 Nonparametric Adaptive Robust Utility Maximization",
            "text": "In this section, we consider a utility maximization problem under model uncertainty and we will solve it under the nonparametric adaptive robust framework. To this end, we take X to be the investor\u2019s wealth process. Any portfolio includes two assets: a banking account with 1-period return 1 + r, where r is the interest rate and fixed throughout, and a stock with i.i.d. log-return Zt, t \u2208 T \u2032\u2032, of which the distribution F \u2217 is unknown. For each t \u2208 T \u2032, denote by \u03d5t the ratio of the wealth invested in the stock. We rule out leverage and short selling, so \u03d5t takes values in A = [0, 1]. Imposing the self-financing strategy, and given X0 = x0 > 0, the dynamics of X is given by\nXt+1 = Xt((1\u2212 \u03d5t)(1 + r) + \u03d5teZt+1), t \u2208 T \u2032.\nTake n = 1, and the function S is defined on R\u00d7A\u00d7R. The prices of the risky asset are observable and thus the return process Z of the risky asset is also observable. We will use the observations of Z to construct the empirical distribution iteratively as in (2.3). Then, we build the \u03b1-uncertainty sets for the distribution F of Z according to (2.5). Next, by taking `(x) = e \u2212\u03b7x\u22121 \u03b7 for some \u03b7 > 0, we formulate the nonparametric adaptive robust utility maximization problem as\ninf \u03d5\u2208A sup Q\u2208Q\u03b1y0\nEQ[`(XT )],\nwhere y0 = (x0, F\u03020) such that F\u03020 is the initial guess of F \u2217. Note that the funtion ` is bounded and we are equivalently dealing with\nsup \u03d5\u2208A inf Q\u2208Q\u03b1y0\nEQ [\n1\u2212 e\u2212\u03b7XT \u03b7\n] (3.1)\nwhich is a maximization problem of the exponential utility function. Due to Theorem 2.7, we will solve the following Bellman equations to get the solution of (3.1).\nVT (y) = 1\u2212 e\u2212\u03b7x\n\u03b7 ,\nVt(y) = sup a\u2208A inf F\u2208C\u03b1t (y) \u222b EY Vt+1(yt+1)Qt(dyt+1|y, a, F ), t \u2208 T \u2032. (3.2)\nMoreover, by applying Theorem 2.5, we get that the optimal trading strategies and worst case models exist which are optimizers of (3.2).\nRemark 3.1. Several types of utility functions satisfy the assumptions in Theorem 2.5 so that the corresponding optimal trading strategies and worst case models exist, and the adaptive robust control problem can be solved by utilizing the dynamic programming principle. Another example of such utility functions is the power utility x\n1\u2212\u03b7\u22121 1\u2212\u03b7 where \u03b7 > 1.\nNote that the loss function `(x) = e \u2212\u03b7x\u22121 \u03b7 is not only bounded from below but actually bounded.\nHere we provide the following technical result regarding the corresponding value functions.\nProposition 3.2. The value function Vt(y) as in (2.12) is lower semicontinuous for every t \u2208 T \u2032.\nProof. The function VT (y) = 1\u2212e\u2212\u03b7x\n\u03b7 is clearly continuous and hence u.s.c.. Because G(T\u22121, y, a, z) is continuous in (y, a, z), VT (G(T \u2212 1, y, a, z)) is l.s.c. in (y, a, z). Moreover,\nvT\u22121(y, a, F ) = \u222b R VT (G(T \u2212 1, y, a, z))dF (z)\nis l.s.c. due to that WT is bounded. Consider the set D = \u22c3 (y,a)\u2208EY \u00d7A C \u03b1 T\u22121(y), and define the function\nv\u030cT\u22121(y, a, F ) = { vT\u22121(y, a, F ) if (y, a, F ) \u2208 D, \u221e otherwise.\nFor any c \u2208 R, we have\n{(y, a, F ) \u2208 EY \u00d7A\u00d7 P1(R) | v\u030cT\u22121(y, a, F ) \u2264 c} = {(y, a, F ) \u2208 EY \u00d7A\u00d7 P1(R) | vT\u22121(y, a, F ) \u2264 c} \u2229D.\nSince vT\u22121 is l.s.c., and D is closed, then the set {(y, a, F ) \u2208 EY \u00d7A\u00d7 P1(R) | v\u030cT\u22121(y, a, F ) \u2264 c} is closed and v\u030cT\u22121(y, a, F ) is l.s.c.. Next, for any c \u2208 R,{\n(y, a) \u2208 EY \u00d7A | inf F\u2208C\u03b1T\u22121(y) vT\u22121(y, a, F ) \u2264 c\n}\n= { (y, a) \u2208 EY \u00d7A | inf\nF\u2208P1(R) v\u030cT\u22121(y, a, F ) \u2264 c\n} .\nFix (y, a) and let {Fn, n > 0} \u2282 P1(R) be such that\nv\u030c(y, a, Fn) \u2193 v\u0303T\u22121(y, a) := inf F\u2208P1(R) v\u030cT\u22121(y, a, F ).\nBy definition of v\u030cT\u22121, we know for large enough n, Fn \u2208 C\u03b1T\u22121(y) which is a weakly compact set. Then, there exists F \u2217 such that v\u030cT\u22121(y, a, F\n\u2217) = v\u0303T\u22121(y, a). Let {(yn, an), n > 0} be a sequence that converges to some (y0, a0). We choose a sequence {Fn, n > 0} \u2282 P(R) such that v\u030cT\u22121(yn, an, Fn) = v\u0303T\u22121(yn, an). Obviously, for each n > 0, Fn \u2208 C\u03b1T\u22121(yn). Due to the fact that {yn, n > 0} converges to y0, the set D\u0303 = \u22c3 n C\u03b1T\u22121(yn) is bounded. Hence, there exists F \u2032 \u2208 D\u0303 and \u03b4 > 0 such that D\u0303 \u2282 B\u03b4(F \u2032) where the latter is a Wasserstein ball around F \u2032 with radius \u03b4. Now we consider the topology consistent with the weak convergence for the argument F in the function v\u030cT\u22121(y, a, F ). In such case, v\u030cT\u22121 is still l.s.c.. There exists a subsequence (ynk , ank , Fnk), k > 0, such that\nlim inf n\u2192\u221e v\u030cT\u22121(yn, an, Fn) = lim k\u2192\u221e v\u030cT\u22121(ynk , ank , Fnk).\nAs B\u03b4(F \u2032) is compact under the Prokhorov metric, there exists F0 that is a limit point of {Fnk , n > 0}. We obtain\nlim inf n\u2192\u221e v\u0303T\u22121(yn, an) = lim inf n\u2192\u221e v\u030cT\u22121(yn, an, Fn) = lim k\u2192\u221e v\u030cT\u22121(ynk , ank , Fnk)\n\u2265 v\u030cT\u22121(y0, a0, F0) \u2265 v\u0303T\u22121(y0, a0).\nThis shows that v\u0303T\u22121(y, a) is l.s.c.. Next, take set O = EY \u00d7 (0, 1) and such set is open. The y section of O is the interval (0, 1). By [BS78]\nV\u0302T\u22121(y) = sup a\u2208(0,1) v\u0303T\u22121(y, a)\nis l.s.c.. Note that A = [0, 1] is the closure of (0, 1), thus\nVT\u22121(y) = sup a\u2208A v\u0303T\u22121(y, a) = sup a\u2208(0,1) v\u0303T\u22121(y, a) = V\u0302T\u22121(y),\nand VT\u22121(y) is l.s.c.. Following the backward induction for t = T \u2212 2, . . . , 0, the proof is complete.\nProposition 3.2 is of great importance for numerical computation of Bellman equations (3.2). As in [KENA19], when Vt+1 is l.s.c., for any fixed (y, a) \u2208 EY \u00d7A, the inner optimization problem can be solved as follows\ninf F\u2208C\u03b1t (y) \u222b EY Vt+1(yt+1)Qt(dyt+1|y, a, F ) = inf F\u2208C\u03b1t (y) \u222b R Vt+1(G(t, y, a, z))dF (z)\n= sup \u03b3\u22650\n{ E F\u0302 [ V \u03b3t+1(G(t, y, a, Zt+1)) ] \u2212 \u03b3Q\nH t (1\u2212 \u03b1)\u221a t0 + t\n} ,\nwhere V \u03b3t+1(G(t, y, a, Zt+1)) = infz\u2208R {Vt+1(G(t, y, a, z)) + \u03b3|z \u2212 Zt+1|}, and y = (x, F\u0302 ). With such results in hand, the Bellman equation (3.2) becomes\nVT (y) = 1\u2212 e\u2212\u03b7x\n\u03b7 ,\nVt(y) = sup a\u2208A,\u03b3\u22650\n{ E F\u0302 [V \u03b3t+1(G(t, y, a, Zt+1))]\u2212 \u03b3QHt (1\u2212 \u03b1)\u221a\nt0 + t\n} , (3.3)\nV \u03b3t+1(G(t, y, a, Zt+1)) = inf z\u2208R {Vt+1(G(t, y, a, z)) + \u03b3|z \u2212 Zt+1|}. (3.4)\nIn the sequel, we will dicuss the challenges in the numerical computation of (3.3) and (3.4) and explain our algorithm for dealing with such problem."
        },
        {
            "heading": "3.1 Algorithm",
            "text": "In this practice, we will mainly follow the idea represented in [CL21] and propose a similar numerical scheme that uses regression Monte Carlo and GP surrogates to solve the Bellman equations (3.3) and (3.4). Then, we analyze the performance of the obtained optimal control on out-of-sample paths by simulating the realized terminal utility and estimating the expected utility.\nTowards this end, we begin with discretizing the state space by choosing yit = (x i t, F\u0302 i t ) \u2208 EY , i = 1, . . . , N , t \u2208 T . These yit\u2019s are called design points. Then, we solve the equation (3.3) for the design points y = yit, i = 1, . . . , N , t = T, T \u2212 1 . . . , 0. One of the main tasks in the numerical algorithm is computing E\nF\u0302 [V \u03b3(G(t, yit, a, Zt+1)] for i = 1, . . . , N , t \u2208 T . In view of F\u0302 it being an\nempirical distribution and assuming that\nF\u0302 it (z) = 1\nt0 + t t\u2211 j=\u2212t0+1 1zij\u2264z ,\nwe have\nE F\u0302 it [V \u03b3t+1(G(t, y i t, a, Zt+1))] =\n1\nt+ t0 t\u2211 j=\u2212t0+1 V \u03b3t+1(G(t, y i t, a, z i j)). (3.5)\nRemark 3.3. In our current setup, F\u03020 is defined to be an empirical distribution constructed from historical data prior to the beginning of the investment, but it does not have to be. For example, there are estimation techniques that produce continuous prior distribution F\u03020 (cf. perturbed empirical distribution), and in such case Monte Carlo method will be needed to compute E F\u0302 [V \u03b3t+1(G(t, y, a, Zt+1))] due to the fact that F\u0302 is no longer a discrete distrubtion anymore.\nSince the value function Vt+1, and in turn V \u03b3 t+1, cannot be computed analytically, we will need a regression model for Vt+1 so that we can estimate the right hand side of (3.5). The general strategy is then, for every t \u2208 T \u2032, we use (yit+1, Vt+1(yit+1)), i = 1, . . . , N , called training points to build a regression model for Vt+1, and use it to evaluate V \u03b3 t+1. Thus, we have an optimize\u2013train\u2013optimize loop in our algorithm. The state component F\u0302 it is a probability distribution which is infinitely dimensional, or can be equivalently replaced by the vector zi\u2212t0+1:t. In both cases, we are dealing with a high dimensional problem and facing the challenge of \u201ccurse of dimensionality\u201d. Due to such reason, the traditional grid-based method for choosing the design points yit, i = 1, . . . , N , t \u2208 T , will be inefficient. To overcome this difficulty, we use the idea of randomized control so that we can focus on the points in the state space that are likely to be visited by the state process Y . In particular, for t \u2208 T \u2032, given the design points yit, . . . , yNt , we will uniformly generate a1, . . . , aN from A and use them to update y1t , . . . , y N t to y 1 t+1, . . . , y N t+1, respectively, according to\nyit+1 = G(t, y i t, a i, Zit+1), i = 1, . . . , N,\nwhere Zit+1 is the simulated random noise. Next, we discuss the choise of regression model for the value function Vt+1 in detail. From above we see that for each t \u2208 T \u2032, Vt+1 can be viewed as a function of (xt+1, z\u2212t0+1:t+1) where z\u2212t0+1:t+1 yields the empirical distribution F\u0302t+1. Therefore, it is natural to regress Vt+1 against (xt+1, z\u2212t0+1:t+1) instead of (xt+1, F\u0302t+1). Such treatment will reduce an infinite dimensional problem to a finite one. However, note that (xt+1, z\u2212t0+1:t+1) has a dimension of t0 + t + 2 and to regress Vt+1 against such high dimensional input requires an enormous amount of training points (xit+1, z i \u2212t0+1:t+1), i = 1, . . . , N , so that we can obtain an accurate regression model for Vt+1. Hence, solely for the regression purpose, we will approximate F\u0302t+1 with its first d moments denote by m1t+1, . . . ,m d t+1, and regress Vt+1 against (xt+1,m 1 t+1, . . . ,m d t+1). By doing so, we effectively approximate a t0 + t+ 2-dimensional function with a d+ 1-dimensional regression model. Since the moments of a distrubtion capture the features of the distribution quite well, our strategy is a sound way to reduce the dimension of the problem that we are facing. To this end, we propose to use the GP surrogate to build regression models for Vt+1, t \u2208 T \u2032. Gaussian process is a popular tool in machine learning that is suitable for dealing with regression problem with mid-range dimensions. It produces nonparametric functional approximations of functions by utilizing the location information of the function input. Namely, for some \u201cusual\u201d function g, if \u2016u1\u2212u2\u2016 is small, then a GP user assumes that \u2016g(u1)\u2212 g(u2)\u2016 should be relatively small as well. Recall that from Theorem 2.5 and Proposition 3.2, we immediately get the following result.\nCorollary 3.4. For every t \u2208 T , and Vt defined in (3.2), Vt is a continuous function on EY .\nHence, GP is the ideal tool for us to build the statistical surrogates for each Vt, t \u2208 T \u2032\u2032, so that we can proceed with the backward iteration and solve the Bellman equations. To be more specific,\nwe approximate each of the design points yit+1, i = 1, . . . , N , by y\u030c i t+1 := (x i t+1,m i,1 t+1, . . . ,m i,d t+1), and denote by V\u030ct+1 the GP surrogate of Vt+1. Then, in the context of GP regression, the values V\u030ct+1(y\u030c i t+1), i = 1, . . . , N , are jointly normal distributed. For any y \u2208 EY , the predicted value V\u030ct+1(y) that approximates Vt+1(y) is then computed as\nV\u030ct+1(y) = (k(y, y\u030c 1 t+1), . . . , k(y, y\u030c N t+1))[K + 2I]\u22121(Vt+1(y\u030c 1 t+1), . . . , Vt+1(y\u030c N t+1)) >,\nwhere I is the N \u00d7 N identity matrix and entries of K has the form Kij = k(y\u030cit+1, y\u030c j t+1), i, j = 1, . . . , N . The function k(\u00b7, \u00b7) is called the kernel function of the GP surrogate and in this project, we choose it from the Matern-5/2 family (cf. [Gen02]). We fit V\u030ct+1 to the training points {(y\u030cit+1, Vt+1(y\u030cit+1)), i = 1, . . . , N} and during this process the hyperparameters inside of k(\u00b7, \u00b7) will be estimated. For a comprehensive discussion of the Gaussian process surrogates, we refer to the book [RW06].\nWe summarize our algorithm for solving (3.3) and (3.4) as follows:\n1. (Assume that Vt+1(\u00b7) and \u03d5\u2217t+1(\u00b7) are computed (estimated) at design points y1t+1, . . . , yNt+1, t \u2208 T \u2032\u2032, and the GP surrogates V\u030ct+1 and \u03d5\u030c\u2217t+1 1 are fitted.)\n2. For time t, any a \u2208 A, \u03b3 > 0, z \u2208 R, and each of the design points {yit, i = 1, . . . , N} \u2282 EY , use the GP surrogate V\u030ct+1 and command scipy.optimize.minimize_scalar in the scipy package for Python to compute\nV\u030c \u03b3t+1(G(t, y i t, a, z)) := inf z\u2032\u2208R {V\u030ct+1(G(t, yit, a, z)) + \u03b3|z\u2032 \u2212 z|)}, i = 1, . . . , N,\nand V\u030c \u03b3t+1 is an approximation of V \u03b3 t+1.\n3. For time t, any a \u2208 A, and each of the design points {yit, i = 1, . . . , N} \u2282 EY , approximate E F\u0302 [V \u03b3t+1(G(t, y i t, a, Zt+1))] as\nE F\u0302 [V \u03b3t+1(G(t, y i t, a, Zt+1))] \u2248\n1\nt+ t0 t\u2211 j=\u2212t0+1 V\u030c \u03b3t+1(G(t, y i t, a, z i j)).\n4. Use the command scipy.optimize.minimize_scalar to compute\nV (1)(yit, a) = \u2212 inf \u03b3\u22650 \u2212 1t+ t0 t\u2211\nj=\u2212t0+1 V\u030c \u03b3t+1(G(t, y i t, a, z i j)) +\n\u03b3QHt (1\u2212 \u03b1)\u221a t0 + t  , i = 1, . . . , N, and\nVt(y i t) = \u2212 inf a\u2208A (\u2212V (1)(yit, a)),\nwhere we also obtain the optimizer \u03d5\u2217t (y i t), i = 1, . . . , N .\n5. Fit the GP surrogate V\u030ct by using (y\u030c i t, Vt(y i t)), i = 1, . . . , N , as the training points. Similarly,\nfit \u03d5\u030c\u2217t by using (y\u030c i t, \u03d5t(y i t)), i = 1, . . . , N .\n6. Goto 1.: start the next recursion for t\u2212 1. 1The GP surrogate \u03d5\u030c\u2217t+1 is the Gaussian process regression model constructed by using the training data\n{(y\u030ci, \u03d5\u2217t+1(yi)), i = 1, . . . , N}.\nTo analyze the performance of the optimal control we obtain from solving the Bellman equations, we generate N \u2032 forward simulated paths by starting with the initial state y0 = (x0, F\u03020) and applying the control \u03d5\u030c\u2217t (y\u030c i t), i = 1, . . . , N \u2032, to obtain the next-step state yit+1 for t \u2208 T \u2032 according to\nyit+1 = G(t, y i t, \u03d5\u030c \u2217 t (y\u030c i t), Z i t+1).\nThe corresponding forward Monte Carlo algorithm is summarized as\n1. Take yi0 \u2261 (x0, F\u03020), i = 1, . . . , N \u2032.\n2. For t = 1, . . . , T , generate Zit , i = 1, . . . , N \u2032.\n3. Approximate yit as y\u030c i t and use the GP surrogates to compute the control a i t = \u03d5\u030ct(y\u030c i t), i =\n1, . . . , N \u2032, t \u2208 T \u2032.\n4. Update the states yit+1 = G(t, y i t, a i t, Z i t+1), i = 1, . . . , N \u2032, t = 0, . . . , T \u2212 1. 5. Compute V\u03020(y0) = 1 N \u2032 \u2211N \u2032 i=1 1\u2212e\u2212\u03b7x i T \u03b7 .\nThe average V\u03020(y0) is then the Monte Carlo estimator of the expected utility. In addition, we are interested in the distribution of the utility\nU\u0302(y0) =\n( 1\u2212 e\u2212\u03b7x1T\n\u03b7 , . . . ,\n1\u2212 e\u2212\u03b7xN \u2032 T\n\u03b7\n)\nand the numerical results will be reported in the sequel."
        },
        {
            "heading": "3.2 Numerical Results",
            "text": "In this section, we apply the machine learning algorithm described above to some specific sets of parameters. We will compare the performance of nonparametric adaptive robust method to that of some other frameworks used to deal with model uncertainty. Theoretically, the optimal control is attained when there is no model uncertainty. We will also analyze the difference in performance between the cases of knowing the true model and having to estimate and learning the dynamics\nof the underlying stochastic process. To this end, we consider three types of investors: the one who knows the true model with terminal utility U\u0302TR(y0) and expected utility V\u0302 TR 0 (y0); the one that applies the nonparametric adaptive robust with terminal utility U\u0302AR(y0) and expected utility V\u0302 AR0 (y0); finally, the one uses the static robust methods, meaning the corresponding uncertainty sets do not change with respect to the state and time. In particular, the static robust investor utilizes the nonparametric setup and builds the uncertainty set as a Wasserstein ball around the empirical distribution generated by historical data with sample size t0. The terminal utility and expected terminal utility of the nonparametic static robust investor are U\u0302SR(y0) and V\u0302 SR 0 (y0), respectively.\nNote that we can easily modify the above algorithm to compute U\u0302TR, V\u0302 TR0 , U\u0302 SR, and V\u0302 SR0 . In fact, by taking C\u03b1t (y) \u2261 B0(F \u2217) which is the Wasserstein ball around F \u2217 with 0 radius, we are able to compute U\u0302TR and V\u0302 TR0 . For U\u0302\nSR and V\u0302 SR0 , we take C\u03b1t (y) \u2261 C\u03b10 (y0). We choose the terminal time to be 1 year with T = 10 time steps which means one unit of time is 0.1 year. The annual insterest rate is 0.02 so that r = 0.02/10 = 0.002. Initial endowment is x0 = 100. Some other parameters are \u03b1 = 0.1, \u03b7 = 0.01, and m = 4. The number of paths is N = 1000 for nonparametric adaptive robust and 200 for other methods. The reason for such choice is that the state space of adaptive robust has dimension m + 1 while the others have dimension 1. For the sampling measure and test measure, we consider a Gaussian mixture model: with 40% probability, Zt \u223c N(0.06/10, 0.42/10), and with 60% probability, Zt \u223c N(0.16/10, 0.252/10). Recall that the parametric static robust investor assumes that Zt \u223c N(\u00b5, \u03c32) and constructs the confidence region for \u00b5 and \u03c32. We will compute and compare the distributions of utlities among the mentioned four frameworks with the above choice of parameters for t0 = 20. We also want to point out that the behavior of the optimal strategies would depend on the simulated QH0 (1 \u2212 \u03b1). In this exercise, we present two cases with QH0 (1\u2212\u03b1) \u2248 0.199165 and QH0 (1\u2212\u03b1) \u2248 0.092942. Note that among 1000 simulated paths, 0.199165 sits very closely to the average value of QH0 (1 \u2212 \u03b1) which is 0.200395, and 0.092942 is below the 1% quantile which is 0.115721. We refer to the left panel of Figure 1 for the histogram of simulated QH0 (1\u2212 \u03b1).\nFor QH0 (1\u2212 \u03b1) \u2248 0.199165, comparison among AR, TR, and SR are reported in Table 1. Since TR knows the true model of the risky asset return, the corresponding strategy will be optimal and V\u0302 TR0 will outperform any other optimal control provided by investors who do not know the true model. Nevertheless, AR does better in three indices of risky management: AR has lower variance, higher 20% quantile, and minimum value of the simulated terminal utilities than TR. AR also beats SR quite significantly in regard to the mean, 90% quantile and maximum value of the\nsimulated terminal utility. In addition, by viewing the Figure 2, we argue that AR produces wealth paths with more favorable distribution than TR. On the other hand, SR generates trivial optimal strategies similarly to the observations made in some earlier work (cf. [BCC+19], [CM20]). By ignoring the numerical instability, the terminal wealth produced by SR is a constant 102.018 which means all the money is invested in the banking account. With no surprises, as such a conservative control method, SR performs well in the department of risk management: it has apparent minimal variance, higher 20% quantile and minimum value of the terminal utility compared to AR and TR.\nFor QH0 (1 \u2212 \u03b1) \u2248 0.092942, comparison of the performance of AR, TR, and SR on the same out-of-sample paths as in the previous case are reported in Table 2. Since that QH0 (1 \u2212 \u03b1) is smaller, the size of C\u03b1t along the simulated paths is in general smaller as a consequence. Hence, we expect more aggressive strategies given by the robust approaches. One needs to be aware that QH0 (1\u2212 \u03b1) \u2248 0.092942 has an extremely low probability. Thus, we expect the value of QH0 (1\u2212 \u03b1), and in turn the radius of C\u03b1t to be oscillating after t = 0. Nevertheless, we see from Table 2 that there is an improvement of AR in this case. Estimated expected utility V\u0302 AR0 and the 90% quantile of U\u0302AR are marginally larger than in the case of QH0 (1\u2212 \u03b1) = 0.199165. Increase in the maximum value of U\u0302AR on the other hand is somewhat significant. An unavoidable trade-off is that, even though only slightly, the strategy becomes more risky as the variance increases and 20% quantile, as well as the minimum value, of U\u0302AR both decrease. In line with our discussion, we also observe\nin Figure 2 that the distribution of U\u0302AR in the right panel has moderately larger tails on both left and right sides compared to that in the left panel. Such change is expected to be more significant if the computation is done for larger t0 and T . To conclude, AR is more aggressive when the size of C\u03b1t is smaller but it is in general stable for our choice of parameters in the computation. Regarding SR, we observe changes following a similar pattern as for AR. However, such changes are so tiny and almost negligible. Consequently, the computed SR strategies are considered as trivial and one needs to further reduce QH0 (1\u2212 \u03b1) in order to obtain a non-trivial SR optimal control.\nThe main argument for why SR being so conservative is that for relatively small historical data size t0, the corresponding confidence region is usually too large. On top of that, there is no shrinkage of the confidence region in static robust. Hence, no matter at which time step, the worst case model in such a large set is strongly against the controller which implies that, in the context of optimal portfolio, the money should only be invested in the banking account. Dynamic reduction of uncertainty is thereby an apparent advantage maintained by AR over SR. In practice, static robust control should only be used when there is sufficient historical data. One still needs be cautious of potential estimation error as, for uncertainty set with small size, the SR optimal control will heavily depend on the initial guess of the unknown distribution. Due to the lack of dynamic learning, SR optimal control in such case will be biased if the initial guess has large distance to the true model. On the contrary, learning is incorporated in adaptive robust and thus the corresponding control will be almost optimal for time steps close to T , and this feature will be carried out to earlier time steps following the dynamic programming principle."
        }
    ],
    "title": "Nonparametric Adaptive Robust Control Under Model Uncertainty",
    "year": 2022
}