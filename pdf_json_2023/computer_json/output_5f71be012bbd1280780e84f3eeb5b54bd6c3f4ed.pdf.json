{
    "abstractText": "One-bit quantization with time-varying sampling thresholds has recently found significant utilization potential in statistical signal processing applications due to its relatively low power consumption and low implementation cost. In addition to such advantages, an attractive feature of one-bit analog-to-digital converters (ADCs) is their superior sampling rates as compared to their conventional multi-bit counterparts. This characteristic endows one-bit signal processing frameworks with what we refer to as sample abundance. On the other hand, many signal recovery and optimization problems are formulated as (possibly non-convex) quadratic programs with linear feasibility constraints in the one-bit sampling regime. We demonstrate, with a particular focus on quadratic compressed sensing, that the sample abundance paradigm allows for the transformation of such quadratic problems to merely a linear feasibility problem by forming a large-scale overdetermined linear system; thus removing the need for costly optimization constraints and objectives. To efficiently tackle the emerging overdetermined linear feasibility problem, we further propose an enhanced randomized Kaczmarz algorithm, called Block SKM. Several numerical results are presented to illustrate the effectiveness of the proposed methodologies.",
    "authors": [
        {
            "affiliations": [],
            "name": "Arian Eamaz"
        },
        {
            "affiliations": [],
            "name": "Farhang Yeganegi"
        },
        {
            "affiliations": [],
            "name": "Mojtaba Soltanalian"
        }
    ],
    "id": "SP:45bd0f4dcb8aa4689ce12f5aaed6691ba3b83c74",
    "references": [
        {
            "authors": [
                "A. Beck",
                "Y. Eldar"
            ],
            "title": "Sparsity constrained nonlinear optimization: Optimality conditions and algorithms",
            "venue": "SIAM Journal on Optimization, vol. 23, no. 3, pp. 1480\u20131509, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "Y. Shechtman",
                "Y. Eldar",
                "A. Szameit",
                "M. Segev"
            ],
            "title": "Sparsity based sub-wavelength imaging with partially incoherent light via quadratic compressed sensing",
            "venue": "Optics express, vol. 19, no. 16, pp. 14 807\u201314 822, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "Y. Shechtman",
                "A. Beck",
                "Y. Eldar"
            ],
            "title": "GESPAR: Efficient phase retrieval of sparse signals",
            "venue": "IEEE Transactions on Signal Processing, vol. 62, no. 4, pp. 928\u2013938, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "K. Jaganathan",
                "Y. Eldar",
                "B. Hassibi"
            ],
            "title": "Phase retrieval: An overview of recent developments",
            "venue": "Optical Compressive Imaging, pp. 279\u2013312, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "K. Jaganathan",
                "S. Oymak",
                "B. Hassibi"
            ],
            "title": "Sparse phase retrieval: Convex algorithms and limitations",
            "venue": "2013 IEEE International Symposium on Information Theory. IEEE, 2013, pp. 1022\u20131026.",
            "year": 2013
        },
        {
            "authors": [
                "E.J. Candes",
                "T. Strohmer",
                "V. Voroninski"
            ],
            "title": "PhaseLift: Exact and stable signal recovery from magnitude measurements via convex programming",
            "venue": "Communications on Pure and Applied Mathematics, vol. 66, no. 8, pp. 1241\u20131274, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "E. Cand\u00e8s",
                "X. Li"
            ],
            "title": "Solving quadratic equations via PhaseLift when there are about as many equations as unknowns",
            "venue": "Foundations of Computational Mathematics, vol. 14, no. 5, pp. 1017\u20131026, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "G. Wang",
                "G. Giannakis",
                "Y. Eldar"
            ],
            "title": "Solving systems of random quadratic equations via truncated amplitude flow",
            "venue": "IEEE Transactions on Information Theory, vol. 64, no. 2, pp. 773\u2013794, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "T. Bendory",
                "Y. Eldar",
                "N. Boumal"
            ],
            "title": "Non-convex phase retrieval from STFT measurements",
            "venue": "IEEE Transactions on Information Theory, vol. 64, no. 1, pp. 467\u2013484, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "E.J. Cand\u00e8s",
                "X. Li",
                "M. Soltanolkotabi"
            ],
            "title": "Phase retrieval via Wirtinger flow: Theory and algorithms",
            "venue": "IEEE Transactions on Information Theory, vol. 61, no. 4, pp. 1985\u20132007, Apr 2015.",
            "year": 1985
        },
        {
            "authors": [
                "I. Waldspurger"
            ],
            "title": "Phase retrieval for wavelet transforms",
            "venue": "IEEE Transactions on Information Theory, vol. 63, no. 5, pp. 2993\u20133009, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A. Eamaz",
                "F. Yeganegi",
                "M. Soltanalian"
            ],
            "title": "Modified arcsine law for one-bit sampled stationary signals with time-varying thresholds",
            "venue": "ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021, pp. 5459\u20135463.",
            "year": 2021
        },
        {
            "authors": [
                "P. Boufounos",
                "R. Baraniuk"
            ],
            "title": "1-bit compressive sensing",
            "venue": "2008 42nd Annual Conference on Information Sciences and Systems. IEEE, 2008, pp. 16\u201321.",
            "year": 2008
        },
        {
            "authors": [
                "E.J. Candes",
                "Y.C. Eldar",
                "T. Strohmer",
                "V. Voroninski"
            ],
            "title": "Phase retrieval via matrix completion",
            "venue": "SIAM review, vol. 57, no. 2, pp. 225\u2013251, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "A. Eamaz",
                "F. Yeganegi",
                "M. Soltanalian"
            ],
            "title": "One-bit phase retrieval: More samples means less complexity?",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2022
        },
        {
            "authors": [
                "A. Mezghani",
                "A.L. Swindlehurst"
            ],
            "title": "Blind estimation of sparse broadband massive MIMO channels with ideal and one-bit ADCs",
            "venue": "IEEE Transactions on Signal Processing, vol. 66, no. 11, pp. 2972\u20132983, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "L. Jacques",
                "J. Laska",
                "P. Boufounos",
                "R. Baraniuk"
            ],
            "title": "Robust 1-bit compressive sensing via binary stable embeddings of sparse vectors",
            "venue": "IEEE Transactions on Information Theory, vol. 59, no. 4, pp. 2082\u20132102, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "P. Boufounos",
                "L. Jacques",
                "F. Krahmer",
                "R. Saab"
            ],
            "title": "Quantization and compressive sensing",
            "venue": "Compressed Sensing and its Applications: MATHEON Workshop 2013. Springer, 2015, pp. 193\u2013237.",
            "year": 2013
        },
        {
            "authors": [
                "A. Eamaz",
                "F. Yeganegi",
                "M. Soltanalian"
            ],
            "title": "Covariance recovery for one-bit sampled stationary signals with time-varying sampling thresholds",
            "venue": "Signal Processing, vol. 206, p. 108899, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "A. Eamaz",
                "K.V. Mishra",
                "F. Yeganegi",
                "M. Soltanalian"
            ],
            "title": "UNO: Unlimited sampling meets one-bit quantization",
            "venue": "arXiv preprint arXiv:2301.10155, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "C. Xu",
                "L. Jacques"
            ],
            "title": "Quantized compressive sensing with RIP matrices: The benefit of dithering",
            "venue": "Information and Inference: A Journal of the IMA, vol. 9, no. 3, pp. 543\u2013586, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J.N. Laska",
                "Z. Wen",
                "W. Yin",
                "R.G. Baraniuk"
            ],
            "title": "Trust, but verify: Fast and accurate signal recovery from 1-bit compressive measurements",
            "venue": "IEEE Transactions on Signal Processing, vol. 59, no. 11, pp. 5289\u20135301, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "S. Kaczmarz"
            ],
            "title": "Angen\u00e4herte aufl\u00f6sung von systemen linearer gleichungen (english translation by Jason Stockmann): Bulletin international de l\u2019acad\u00e9mie polonaise des sciences et des lettres",
            "venue": "1937.",
            "year": 1937
        },
        {
            "authors": [
                "T. Strohmer",
                "R. Vershynin"
            ],
            "title": "A randomized Kaczmarz algorithm with exponential convergence",
            "venue": "Journal of Fourier Analysis and Applications, vol. 15, no. 2, pp. 262\u2013278, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "D. Leventhal",
                "A.S. Lewis"
            ],
            "title": "Randomized methods for linear constraints: convergence rates and conditioning",
            "venue": "Mathematics of Operations Research, vol. 35, no. 3, pp. 641\u2013654, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "D. Needell",
                "J.A. Tropp"
            ],
            "title": "Paved with good intentions: Analysis of a randomized block Kaczmarz method",
            "venue": "Linear Algebra and its Applications, vol. 441, pp. 199\u2013221, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "J. De Loera",
                "J. Haddock",
                "D. Needell"
            ],
            "title": "A sampling Kaczmarz\u2013Motzkin algorithm for linear feasibility",
            "venue": "SIAM Journal on Scientific Computing, vol. 39, no. 5, pp. S66\u2013S87, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "Z.Q. Luo",
                "W.K. Ma",
                "A.M.C. So",
                "Y. Ye",
                "S. Zhang"
            ],
            "title": "Semidefinite relaxation of quadratic optimization problems",
            "venue": "IEEE Signal Processing Magazine, vol. 27, no. 3, pp. 20\u201334, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "M.M. Naghsh",
                "M. Soltanalian",
                "P. Stoica",
                "M. Modarres-Hashemi",
                "A. De Maio",
                "A. Aubry"
            ],
            "title": "A doppler robust design of transmit sequence and receive filter in the presence of signal-dependent interference",
            "venue": "IEEE Transactions on Signal Processing, vol. 62, no. 4, pp. 772\u2013785, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "A. Bhandari",
                "F. Krahmer",
                "R. Raskar"
            ],
            "title": "On unlimited sampling and reconstruction",
            "venue": "IEEE Transactions on Signal Processing, vol. 69, pp. 3827\u20133839, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Ameri",
                "J. Li",
                "M. Soltanalian"
            ],
            "title": "One-bit radar processing and estimation with time-varying sampling thresholds",
            "venue": "2018 IEEE 10th Sensor Array and Multichannel Signal Processing Workshop (SAM). IEEE, 2018, pp. 208\u2013212.",
            "year": 2018
        },
        {
            "authors": [
                "A. Eamaz",
                "F. Yeganegi",
                "M. Soltanalian"
            ],
            "title": "Covariance recovery for one-bit sampled non-stationary signals with time-varying sampling thresholds",
            "venue": "IEEE Transactions on Signal Processing, vol. 70, pp. 5222\u20135236, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Khobahi",
                "M. Soltanalian"
            ],
            "title": "Signal recovery from 1-bit quantized noisy samples via adaptive thresholding",
            "venue": "2018 52nd Asilomar Conference on Signals, Systems, and Computers. IEEE, 2018, pp. 1757\u20131761.",
            "year": 2018
        },
        {
            "authors": [
                "J. Briskman",
                "D. Needell"
            ],
            "title": "Block Kaczmarz method with inequalities",
            "venue": "Journal of Mathematical Imaging and Vision, vol. 52, no. 3, pp. 385\u2013396, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "L. Dai",
                "M. Soltanalian",
                "K. Pelckmans"
            ],
            "title": "On the randomized Kaczmarz algorithm",
            "venue": "IEEE Signal Processing Letters, vol. 21, no. 3, pp. 330\u2013333, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "M. Sarowar Morshed",
                "M. Saiful Islam"
            ],
            "title": "Sampling Kaczmarz Motzkin method for linear feasibility problems: Generalization & acceleration",
            "venue": "arXiv e-prints, pp. arXiv\u20132002, 2020.",
            "year": 2002
        },
        {
            "authors": [
                "T. Elfving"
            ],
            "title": "Block-iterative methods for consistent and inconsistent linear equations",
            "venue": "Numerische Mathematik, vol. 35, no. 1, pp. 1\u201312, 1980.",
            "year": 1980
        },
        {
            "authors": [
                "M. Derezi\u0144ski",
                "E. Rebrova"
            ],
            "title": "Sharp analysis of sketch-and-project methods via a connection to randomized singular value decomposition",
            "venue": "arXiv preprint arXiv:2208.09585, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "E. Rebrova",
                "D. Needell"
            ],
            "title": "On block gaussian sketching for the kaczmarz method",
            "venue": "Numerical Algorithms, vol. 86, pp. 443\u2013473, 2021.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 3.\n09 59\n4v 1\n[ cs\n.I T\n] 1\n6 M\nar 2\nOne-bit quantization with time-varying sampling thresholds has recently found significant utilization potential in statistical signal processing applications due to its relatively low power consumption and low implementation cost. In addition to such advantages, an attractive feature of one-bit analog-to-digital converters (ADCs) is their superior sampling rates as compared to their conventional multi-bit counterparts. This characteristic endows one-bit signal processing frameworks with what we refer to as sample abundance. On the other hand, many signal recovery and optimization problems are formulated as (possibly non-convex) quadratic programs with linear feasibility constraints in the one-bit sampling regime. We demonstrate, with a particular focus on quadratic compressed sensing, that the sample abundance paradigm allows for the transformation of such quadratic problems to merely a linear feasibility problem by forming a large-scale overdetermined linear system; thus removing the need for costly optimization constraints and objectives. To efficiently tackle the emerging overdetermined linear feasibility problem, we further propose an enhanced randomized Kaczmarz algorithm, called Block SKM. Several numerical results are presented to illustrate the effectiveness of the proposed methodologies.\nI. INTRODUCTION\nIn the past two decades, sparsity-based processing methods have been attracting a growing interest in statistical signal\nprocessing applications [1]. Quadratic compressed sensing (QCS) is a widely used formulation in sparse signal recovery;\nexamples include when imaging a sparse object using partially and spatially incoherent illumination [2], or phase retrieval\nfor sparse signals [3].\nTo approach the global optimum, the QCS problem was relaxed as a semidefinite programming (SDP) problem, which involves\nminimizing the rank of a lifted matrix while satisfying both the recovery constraints and the row sparsity constraints on the\nsignal [1, 4]. To retrieve the sparse solution, an iterative thresholding algorithm was proposed that leverages a sequence of SDPs.\nThis approach is similar to the recent developments in the field of phase retrieval, where similar semidefinite programming-based\nideas have been utilized [4\u20137]. Unfortunately, these methods have a high complexity, making them difficult to use for the QCS\nproblem.\nTo overcome the computational challenges posed by convex optimization techniques, non-convex methods have been introduced\nas an alternative approach. These methods tackle the phase retrieval problem as a least-square problem and aim to find a local\nThe first two authors have contributed equally to this work.\noptimum using various optimization techniques [3, 8, 9]. In [3], they proposed the greedy sparse phase retrieval (GESPAR), a\nfast local search method, to efficiently recover the signal from measurements of magnitudes in the QCS problem which is more\naccurate than existing local methods. However, the highly non-convex and non-unique nature of the problem presents a challenge\nin finding an optimal local solution. To enhance the performance of these local methods, various initialization algorithms have\nbeen proposed to improve their outcomes [10, 11].\nSampling the signals of interest at high data rates with high-resolution ADCs would dramatically increase the overall\nimplementation cost and power consumption of the sampling task. In multi-bit sampling scenarios, a very large number of\nquantization levels is necessary in order to represent the original continuous signal with high accuracy, which in practice, leads\nto a considerable reduction in sampling rate [12, 13]. This attribute of multi-bit sampling has served as a key motivator for\nthe proliferation of underdetermined signal processing tools [6, 14, 15]. An alternative solution to such challenges is to deploy\none-bit quantization, which is an extreme sampling scenario, where the signals are merely compared with given threshold levels\nat the ADC, thus producing sign data (\u00b11). This enables signal processing equipment to sample at a very high rate, with a\nconsiderably lower cost and energy consumption, compared to their conventional counterparts that employ multi-bit ADCs [12,\n16\u201318].\nThe use of a fixed threshold in one-bit quantization can result in difficulties in accurately estimating the signal amplitude. To\naddress this issue, recent studies have proposed the use of time-varying thresholds, which have been shown to enhance signal\nrecovery performance [19\u201322].\nIn this paper, we consider the deployment of one-bit sampling with time-varying thresholds on QCS, leading to an increased\nsample size and a highly overdetermined system as a result. Our proposed method can recover the desired sparse signal from\nthe one-bit QCS by (i) generating abundant one-bit measurements, in order to define a large scale overdetermined system where\na finite volume feasible set is created for QCS, and (ii) solving this obtained linear feasibility problem by leveraging one of the\nefficient solver families of overdetermined systems, namely the Kaczmarz algorithms.\nThe Kaczmarz method [23] is an iterative projection algorithm for solving linear systems of equations and inequalities. It\nis usually applied to highly overdetermined systems because of its simplicity. Many variants of this iterative method and their\nconvergence rates have been proposed and studied in recent decades for both consistent and inconsistent systems including the\nrandomized Kaczmarz algorithm, the randomized block Kaczmarz algorithm and most recently, the sampling Kaczmarz-Motzkin\n(SKM) method [24\u201327].\nTo reconstruct the signal of interest from the one-bit sampled QCS, we employ the novel variant of the Kaczmarz algorithm,\nBlock Sampling Kaczmarz-Motzkin (Block SKM) whose theoretical guarantees will be discussed.\nOutline: Section II is dedicated to a review of QCS. In Section III, we will briefly introduce the one-bit sampling via time-\nvarying thresholds and propose the one-bit polyhedron for the QCS, which is a large-scale overdetermined system. An accelerated\nKaczmarz approach is proposed to find the optimal point in the one-bit QCS polyhedron in Section IV. Also, the convergence\nrate of proposed algorithm is investigated. Section V is devoted to numerical results of the proposed Kaczmarz algorithm to\nshow its recovery performance in one-bit. Also, we compare the performance of proposed algorithm to that of the well-known\nhigh-resolution method, GESPAR for the phase retrieval scenario, when the rank of middle matrix is one. Finally, Section VI\nconcludes the paper.\nNotation: We use bold lowercase letters for vectors and bold uppercase letters for matrices. C and R represent the set of complex and real numbers, respectively. (\u00b7)\u22a4 and (\u00b7)H denote the vector/matrix transpose, and the Hermitian transpose, respectively. IN \u2208 RN\u00d7N and 0N1\u00d7N2 are the identity matrix of size N and all-zero matrix of size N1 \u00d7N2. Tr(.) denotes the trace of the matrix argument. The Frobenius norm of a matrix B is defined as \u2016B\u2016F= \u221a \u2211N1 r=1 \u2211N2 s=1 |brs| 2 where {brs} are elements of B. The \u21130-norm of a vector counts the number of its non-zero elements. The Hadamard (element-wise) product of\ntwo matrices B1 and B2 is denoted as B1\u2299B2. The vectorized form of a matrix B is written as vec(B). 1s is the s-dimensional all-one vector. Given a scalar x, we define (x)+ as max {x, 0}. The function sgn(\u00b7) yields the sign of its argument. The floor\noperation is denoted by \u230a\u230b."
        },
        {
            "heading": "II. QUADRATIC COMPRESSED SENSING",
            "text": "In QCS, a sparse high-dimensional signal is to be recovered from a quadratic cost function [1, 3]:\nmin x \u2016x\u20160\ns.t. yj = x HAjx, j \u2208 J = {1, \u00b7 \u00b7 \u00b7 ,m} ,\n(1)\nwhere x \u2208 Cn is the signal to be recovered, {yj} are the measurements, {Aj} \u2208 Rn\u00d7n are the associated sensing matrices, and m is the number of measurements. The convex relaxation of (1) is obtained by the matrix lifting procedure, given by\nyj = x HAjx = Tr\n( Ajxx H ) = Tr (AjX) , (2)\nwhere X = xxH, and Tr (AjX) = vec ( A\u22a4j )\u22a4 vec (X). The sparsity constraint on x can be dealt with by enforcing the rowsparsity of X. If x has k non-zero elements, then X has k rows containing non-zero elements, and each of these rows is also k-sparse. The row-sparsity of X may be promoted by adding a quadratic constraint on X, i.e., \u2211\nr\n(\n\u2211 s |Xrs| 2 )\n1 2\n< \u03b7, where\n\u03b7 is a positive number [2]. Based on (2), the QCS problem can be reformulated as:\nfind X\ns.t. Tr (AjX) = yj,\n\u2211\nr\n(\n\u2211\ns\n|Xrs| 2\n) 1\n2\n< \u03b7,\nrank (X) = 1, X 0.\n(3)\nTo have a convex program similar to [2], the problem (3) may be relaxed as,\nmin X Tr(X)\ns.t. Tr (AjX) = yj ,\n\u2211\nr\n(\n\u2211\ns\n|Xrs| 2\n) 1\n2\n< \u03b7, X 0.\n(4)\nThe above problem is a semi-definite program (SDP). Similar SDP-based ideas were recently utilized in the context of phase\nretrieval [6, 14]. However, the SDP has a high computational complexity; in particular, the semi-definiteness and row-sparsity\nconstraint in the above problem render it computationally demanding [3, 28, 29].\nAn interesting alternative to enforcing the feasible set in problem (4), denoted as FX, emerges when one increases the number of samples m, and solves the overdetermined linear system of equations with m \u226b n. In this sample abundance regimen, the\nlinear constraint Tr (AjX) = yj may actually yield the optimum inside FX. As a result of increasing the number of samples,\nit is possible that the intersection of these hyperplanes will achieve the optimal point without the need to consider other costly\nconstraints. However, this idea may face practical limitations in the case of multi-bit quantization systems since ADCs capable\nof ultra-high rate sampling are difficult and expensive to produce. Moreover, one cannot necessarily expect these constraints to\nintersect with FX in such a way to form a finite-volume space before the optimum is obtained [6, 15].\nIn the next section, by deploying the idea of one-bit sampling with time-varying thresholds, linear equality constraints are\nsuperseded by a massive array of linear inequalities\u2014thus forming a polyhedron that asymptotically coincides with FX."
        },
        {
            "heading": "III. ONE-BIT QCS",
            "text": "In this section, we will briefly introduce the one-bit sampling with time-varying scheme and the signal reconstruction problem\nin the one-bit quantization scheme. We will demonstrate that the utilization of time-varying thresholds in one-bit sampling results\nin a highly over-determined system, represented as a polyhedron. Subsequently, by exploiting the ample of samples in the one-bit\nsampling approach, the one-bit sampled QCS problem will be formulated as a linear feasibility problem."
        },
        {
            "heading": "A. One-Bit Sampling with Time-Varying Thresholds",
            "text": "Consider a bandlimited signal y \u2208 L2, which is to be represented by its samples via the standard sampling formula [30],\n0 < T 6 \u03c0\n\u2126 , y(t) =\nk=+\u221e \u2211\nk=\u2212\u221e\ny(kT) sinc\n(\nt T \u2212 k\n)\n, (5)\nwhere 1/T is the sampling rate and sinc(t) = sin(\u03c0t)(\u03c0t) is an ideal low-pass filter. Suppose yk = y(kT) denotes the uniform samples of y(t) with the sampling rate 1/T. Let rk denote the quantized version of y[k] with the formulation rk = Q(yk), where Q denotes the quantization effect. In one-bit quantization, compared to zero or constant thresholds, time-varying sampling\nthresholds yield a better reconstruction performance [31, 32]. These thresholds may be chosen from any distribution. In this\nwork, to be consistent with state-of-the-art [20, 31, 33], we consider a Gaussian non-zero time-varying threshold vector \u03c4 = [\u03c4k] that follows the distribution \u03c4 \u223c N (d = 1d,\u03a3). In the case of one-bit quantization with such time-varying sampling thresholds,\nthe quantizer is simply written as rk = sgn (yk \u2212 \u03c4k). Let y = [yk] and r = [rk]. Then, the signal feasibility based on the\none-bit measurements takes the form\nr\u2299 (y \u2212 \u03c4) \u2265 0, (6)\nor equivalently\n\u2126y r\u2299 \u03c4, (7)\nwhere \u2126 , diag {r}. Suppose y, \u03c4 \u2208 Rm, and that \u03c4(\u2113) denotes the time-varying sampling threshold in \u2113-th experiment where\n\u2113 \u2208 L = {1, \u00b7 \u00b7 \u00b7 ,m1}. According to (7), for the \u2113-th experiment we have\n\u2126(\u2113)y r(\u2113) \u2299 \u03c4(\u2113), \u2113 \u2208 L, (8)\nwhere \u2126(\u2113) = diag { r(\u2113) }\n. In (8), we have m1 linear system of inequalities which can be put together and expressed as\n\u2126\u0303y vec (R)\u2299 vec (\u0393) , (9)\nwhere R and \u0393 are matrices, with { r(\u2113) } and { \u03c4 (\u2113) } representing their columns, respectively, and \u2126\u0303 is given by\n\u2126\u0303 = [ \u2126(1) \u00b7 \u00b7 \u00b7 \u2126(m) ]\u22a4 , \u2126\u0303 \u2208 Rm1m\u00d7m. (10)\nUtilizing the one-bit quantization technique with multiple time-varying sampling threshold sequences allows for an increase in\nthe number of samples with little extra cost and serves as a gateway to the realm of few-bit sampling. This can be especially\nbeneficial in applications where measurement limitations exist."
        },
        {
            "heading": "B. One-Bit QCS as Linear Feasibility Problem",
            "text": "Hereafter, we will focus on (9) as an overdetermined linear system of inequalities that is associated with the one-bit sampling\nscheme. If we apply one-bit sampling to the QCS (1), referred to as one-bit QCS,\nr (\u2113) j =\n  \n \n+1 Tr (AjX) > \u03c4 (\u2113) j , \u22121 Tr (AjX) < \u03c4 (\u2113) j .\n(11)\nAs a result, by using the linear property of trace function Tr (AjX) = vec ( A\u22a4j )\u22a4 vec (X), the one-bit QCS polyhedron can be written as\nP = {\nX | r (\u2113) j vec ( A\u22a4j )\u22a4 vec (X) \u2265 r (\u2113) j \u03c4 (\u2113) j , \u2113 \u2208 L, j \u2208 J\n}\n, (12)\nwhich is vectorized based on y = V vec (X), where V is a matrix with { vec ( A\u22a4j )} as its rows. The inequality (12) may be recast in the standard polyhedron form as\nP = {X | P vec (X) vec (R)\u2299 vec (\u0393)} , (13)\nwhere P = \u2126\u0303V . By leveraging the sample abundance in the one-bit sampling, the space constrained by (13), shrinks to become\ncontained inside the feasible region. However, this shrinking space always contains the globally optimal solution, with a volume that is decreasing with an increasing number of one-bit samples. We will discuss our approach to find the desired matrix X\u22c6\nbelow."
        },
        {
            "heading": "IV. PROPOSED ALGORITHM",
            "text": "To recover the desired signal within the one-bit QCS polyhedron, we use an accelerated variant of randomized Kaczmarz\nalgorithm (RKA). Many variants of this iterative method and their convergence rates have been proposed and studied in recent\ndecades for both consistent and inconsistent systems, including the original randomized Kaczmarz algorithm, the randomized\nblock Kaczmarz algorithm and most recently, the sampling Kaczmarz-Motzkin (SKM) method [24, 25, 27]. The block-structured\nnature of the one-bit QCS matrix has motivated the development of the SKM method, designed specifically to handle block-\nstructured linear feasibility problems with efficiency. Further, the proposed algorithm will be backed by theoretical guarantees."
        },
        {
            "heading": "A. SKM Method",
            "text": "The SKM is a subconjugate gradient method to solve overdetermined linear systems, i.e., Bx b, where B is a m1m\u00d7 n\nmatrix. The conjugate-gradient methods immediately turn such an inequality to an equality of the following form:\n(Bx\u2212 b)+ = 0, (14)\nand then approach the solution by the same process as used for systems of equations. Given a sample index set J , without loss\nof generality, rewrite (14) as the polyhedron \n \n \ncjx \u2264 bj (j \u2208 I\u2264) , cjx = bj (j \u2208 I=) , (15)\nwhere the disjoint index sets I\u2264 and I= partition J and {cj} are the rows of B. The projection coefficient \u03b2i of the SKM at i iteration is [25, 34, 35]\n\u03b2i =\n  \n \n(cjxi \u2212 bj) + (j \u2208 I\u2264) , cjxi \u2212 bj (j \u2208 I=) . (16)\nThe central contribution of SKM lies in its innovative way of projection plane selection. The hyperplane selection is done\nas follows. At iteration i the SKM algorithm selects a collection of \u03b3 (denoted by the set Ti), uniformly at random out of m1m rows of the constraint matrix B. Then, out of these \u03b3 rows, the row with maximum positive residual is selected. Finally, the solution is updated as [27, 36]: xi+1 = xi \u2212 \u03bbi \u03b2i\n\u2016c j\u22c6 i \u20162 2\ncH j\u22c6 i , where the index j\u22c6i is chosen as the Motzkin sampling, i.e.,\nj\u22c6i = argmax { (cjxi \u2212 bj) + } , j \u2208 Ti at iteration i, and \u03bbi is a relaxation parameter which for consistent systems must satisfy, 0 \u2264 limi\u2192\u221e inf \u03bbi \u2264 limi\u2192\u221e sup\u03bbi < 2, to ensure convergence [24]. The convergence bound for SKM is given by\nE\n{\n\u2016xi \u2212 x\u22c6\u2016 2 2\n}\n\u2264\n(\n1\u2212 2\u03bbi \u2212 \u03bb2i \u03ba2 (B)\n)i\n\u2016x0 \u2212 x\u22c6\u2016 2 2 , (17)\nwith \u03ba (B) = \u2016B\u2016F\u2016B\u2020\u20162 denoting the scaled condition number, and x\u22c6 is the optimal solution."
        },
        {
            "heading": "B. Block SKM Algorithm",
            "text": "The matrix P in (13) has a block structure with the following formulation:\nP = [ V\u22a4\u2126(1) \u00b7 \u00b7 \u00b7 V\u22a4\u2126(m) ]\u22a4 , P \u2208 Rm1m\u00d7n. (18)\nTherefore, it is useful to investigate the accelerated block-based RKA methods to find the desired signal in (13) for further\ncomputational efficiency enhancement. Our proposed algorithm, the Block SKM, is described as follows. Suppose we have a linear feasibility problem Bx b where B = [\nB\u22a41 \u00b7 \u00b7 \u00b7 B \u22a4 m1\n]\u22a4\n, B \u2208 Rm1m\u00d7n, and b = [\nb\u22a41 \u00b7 \u00b7 \u00b7 b \u22a4 m1\n]\u22a4\n. The\nproposed algorithm for sparse signal recovery, i.e., the Block SKM, may be summarized as follows:\n1) Choose a block Bj uniformly at random with the probability Pr{j = k} = \u2016Bk\u2016\n2 F\n\u2016B\u20162 F\n.\n2) Compute e = Bjx\u2212 bj . 3) Let e\u2032 denote the sorted version of e from emax (the maximum element of e) to emin (the minimum element of e). This\nstep is inspired by the idea of the Motzkin sampling, presented in [27], to have an accelerated convergence.\n4) Select the first k\u2032 < n element of e\u2032 and construct the sub-problem B\u2032jx b \u2032 j , where B \u2032 j \u2208 R k\u2032\u00d7n and b\u2032j \u2208 R k\u2032\u00d71. The\nreason behind choosing k\u2032 < n is due to the computation of ( B\u2032jB \u2032\u22a4 j )\u22121 in the next step (Step 5). For k\u2032 > n, the matrix B\u2032jB \u2032\u22a4 j is rank-deficient and its inverse is not available.\n5) Compute the Moore-Penrose of B\u2032j , i.e., B \u2032\u2020 j = B \u2032\u22a4 j\n(\nB\u2032jB \u2032\u22a4 j\n)\u22121 .\n6) Update the solution xi+1 = xi\u2212\u03bbiB \u2032\u2020 j\n(\nB\u2032jx\u2212 b \u2032 j\n)+ . This update process is inspired from the randomized block Kaczmarz\nmethod [26, 37] which takes advantage of the efficient matrix-vector multiplication, thus giving the method a significant\nreduction in computational cost [34].\nParticularly, in the case of the one-bit QCS polyhedron, B = \u2212P, x = vec (X), and b = \u2212 vec (R)\u2299 vec (\u0393)."
        },
        {
            "heading": "C. Convergence Analysis",
            "text": "It is worth pointing out that the Block SKM algorithm can be considered to be a special case of the more general sketch-\nand-project method, defined as [38]:\nxi+1 = argmin x\n\u2016x\u2212 xi\u2016 2 2 subject to S \u22a4Bx S\u22a4b, (19)\nwhere S \u2208 Rm1m\u00d7k \u2032 is the sketch matrix choosing a block uniformly at random from the main matrix as mentioned in step 1. The second step of the proposed algorithm follows the Motzkin sampling where the index j\u22c6i is chosen in i-th iteration as follows:\nj\u22c6i = argmax j\n{\n(\n( S\u22a4B )\nj xi \u2212\n( S\u22a4b )\nj\n)+ }\n, (20)\nwith (\u00b7)i denoting the ith row of the matrix argument.\nIn the Block SKM algorithm, the sketch matrix is given by\nS = [\n0k\u2032\u00d7p Ik\u2032 0k\u2032\u00d7(m1m\u2212k\u2032\u2212p)\n]\u22a4\n, S \u2208 Rm1m\u00d7k \u2032 , (21)\nwhere k\u2032 is the block size and p = k\u2032\u03b1, \u03b1 \u2208 { 1, \u00b7 \u00b7 \u00b7 , \u230a m1m k\u2032 \u230b} . Note that the literature does not offer any theoretical guarantees for the convergence of the Block SKM with the above sketch matrix [39]. To derive our theoretical guarantees for the algorithm\nused to solve the one-bit QCS, we change the sketch matrix to the Gaussian sketch matrix as follows:\nS = [\n0k\u2032\u00d7p G 0k\u2032\u00d7(m1m\u2212k\u2032\u2212p)\n]\u22a4\n, S \u2208 Rm1m\u00d7k \u2032 , (22)\nwhere G is a k\u2032 \u00d7 k\u2032 Gaussian matrix, whose entries are i.i.d. following the distribution N (0, 1). In this framework, we are\nable to provide some theoretical guarantees by taking advantage of the favorable properties of Gaussian random variables.\nAssume that S denotes a non-empty solution set of the polyhedron (13). Owing to the fact that E {\n\u2016xi+1 \u2212 S\u2016 2 2\n}\n\u2264\nE\n{\n\u2016xi+1 \u2212 x\u22c6\u2016 2 2\n} [25], then we proceed to prove the convergence rate by employing E {\n\u2016xi+1 \u2212 x\u22c6\u2016 2 2\n}\n. Using the fact\nthat xi+1 \u2212 x\u22c6 is orthogonal to (STB)j\u22c6 i [39], where j\u22c6i is the index chosen based on the Motzkin sampling for the i-th iteration, we have the following Pythagorean relation [38, 39]:\n\u2016xi+1 \u2212 x\u22c6\u2016 2 2 = \u2016xi \u2212 x\u22c6\u2016 2 2 \u2212\n\u2225 \u2225 \u2225 \u2225 ( ( S\u22a4B )\nj\u22c6 i\nxi \u2212 ( S\u22a4b )\nj\u22c6 i\n)+ \u2225\n\u2225 \u2225 \u2225\n2\n2\n\u2016(S\u22a4B)i\u2016 2 2\n. (23)\nIn the linear inequality system, the Kaczmarz algorithms only updates the solution when S\u22a4Bxi S\u22a4b at i-th iteration. Therefore, one can readily rewrite (23) at iteration i where the condition S\u22a4Bxi S\u22a4b is met:\n\u2016xi+1 \u2212 x\u22c6\u2016 2 2 = \u2016xi \u2212 x\u22c6\u2016 2 2 \u2212\n\u2225 \u2225S\u22a4Bxi \u2212 S\u22a4b \u2225 \u2225 2\n\u221e \u2225 \u2225 \u2225(S\u22a4B)j\u22c6 i \u2225 \u2225 \u2225 2\n2\n. (24)\nBy taking the expectation over the error, we have\nES\n{\n\u2016xi+1 \u2212 x\u22c6\u2016 2 2\n}\n= \u2016xi \u2212 x\u22c6\u2016 2 2 \u2212 ES\n  \n \n\u2225 \u2225S\u22a4Bxi \u2212 S\u22a4b \u2225 \u2225 2\n\u221e \u2225 \u2225 \u2225(S\u22a4B)j\u22c6 i \u2225 \u2225 \u2225 2\n2\n  \n \n. (25)\nIn addition, we have that\nES\n{\n\u2225 \u2225 \u2225 ( S\u22a4B )\nj\u22c6 i\n\u2225 \u2225 \u2225 2\n2\n}\n=\nn \u2211\nk=1\nES\n \n\n(\nm1m \u2211\ni1=1\nSji1Bi1i2\n)2 \n\n\n, (26)\nor equivalently, in terms of G in (22),\nn \u2211\ni2=1\nEG\n  \n \n\n\nk\u2032 \u2211\ni1=1\nG\u22a4ji1Bi1i2\n\n\n2 \n \n \n=\nn \u2211\ni2=1\nk\u2032 \u2211\ni1=1\nEG\n{\n(\nG\u22a4ji1\n)2 }\nB2i1i2 ,\n(27)\nwith EG\n{\n(\nG\u22a4ji1\n)2 }\n= 1, which helps to simplify (27) as\nn \u2211\ni2=1\nk\u2032 \u2211\ni1=1\nB2i1i2 = \u2016B\u0302\u2016 2 F, (28)\nwhere B\u0302 is the k\u2032 \u00d7n submatrix of B. Due to the fact that the second term in the right-hand side of (25) is an expectation over the convex function f(x, y) = x2/y, we can apply Jensen\u2019s inequality as follows:\nES\n  \n \n\u2225 \u2225S\u22a4Bxi \u2212 S \u22a4b \u2225 \u2225 2\n\u221e \u2225 \u2225 \u2225 (S\u22a4B)\nj\u22c6 i\n\u2225 \u2225 \u2225 2\n2\n  \n \n\u2265\n(\nES\n{\u2225 \u2225S\u22a4Bxi \u2212 S \u22a4b \u2225 \u2225\n\u221e\n})2\nES\n{\n\u2225 \u2225 \u2225 (S\u22a4B)\nj\u22c6 i\n\u2225 \u2225 \u2225 2\n2\n} . (29)\nSince S\u22a4Bx\u22c6 S \u22a4b and S\u22a4Bxi S \u22a4b, one can conclude \u2225\n\u2225 \u2225 S \u22a4 Bxi \u2212 S \u22a4 b\n\u2225 \u2225 \u2225 \u221e \u2265 \u2225 \u2225 \u2225 S \u22a4 Bxi \u2212 S \u22a4 Bx\u22c6 \u2225 \u2225 \u2225 \u221e . (30)\nIt follows from the above that\nES\n  \n \n\u2225 \u2225S\u22a4Bxi \u2212 S \u22a4b \u2225 \u2225 2\n\u221e \u2225 \u2225 \u2225 (S\u22a4B)\nj\u22c6 i\n\u2225 \u2225 \u2225 2\n2\n  \n \n\u2265\n(\nES\n{\u2225 \u2225S\u22a4B (xi \u2212 x\u22c6) \u2225 \u2225\n\u221e\n})2\n\u2016B\u0302\u20162F . (31)\nWe can additionally take advantage of the estimate for the maximum of independent normal random variables [39],\nES\n{\u2225\n\u2225 \u2225 S \u22a4 B (xi \u2212 x\u22c6)\n\u2225 \u2225 \u2225\n\u221e\n}\n= ES\n{\nmax t\u2208[k\u2032] \u3008st,B (xi \u2212 x\u22c6)\u3009\n}\n= EG\n{\nmax t\u2208[k\u2032]\n\u2329 st, B\u0302 (xi \u2212 x\u22c6) \u232a\n}\n\u2265 c\u2016B\u0302 (xi \u2212 x\u22c6) \u20162 \u221a log k\u2032,\n(32)\nwhere st is the t-th column of S, [k \u2032] = {1, 2, \u00b7 \u00b7 \u00b7 , k\u2032}, and c is a positive value. By plugging the inequality (32) into (25), and using the inequality, \u2225\n\u2225 \u2225 B\u0302 (xi \u2212 x\u22c6)\n\u2225 \u2225 \u2225 2\n2 \u2265 \u03c32min\n( B\u0302 )\n\u2016xi \u2212 x\u22c6\u2016 2 2 , (33)\nwhere \u03c32min is the minimum singular value. Thus, we obtain\nE { \u2016xi+1 \u2212 x\u22c6\u2016 2 2 } \u2264 \u2016xi \u2212 x\u22c6\u2016 2 2 \u2212\nc\u2016B (x\u22c6 \u2212 xi) \u2016 2 2log k \u2032\n\u2016B\u20162F\n\u2264 \u2016xi \u2212 x\u22c6\u2016 2 2 \u2212\nc\u03c32min(B\u0302) log k \u2032\n\u2016B\u0302\u20162F \u2016xi \u2212 x\u22c6\u2016\n2 2\n\u2264\n(\n1\u2212 c\u03c32min(B\u0302) log k \u2032\n\u2016B\u0302\u20162F\n)\n\u2016xi \u2212 x\u22c6\u2016 2 2 ,\n(34)\nwhich can be recast as the following convergence rate, after K updates:\nE { \u2016xi+1 \u2212 x\u22c6\u2016 2 2 } \u2264\n(\n1\u2212 c\u03c32min(B\u0302) log k \u2032\n\u2016B\u0302\u20162F\n)K\n\u2016x0 \u2212 x\u22c6\u2016 2 2 . (35)"
        },
        {
            "heading": "V. NUMERICAL RESULTS",
            "text": "In this section, at first, we numerically scrutinize the capability of the block SKM in the one-bit QCS problem by evaluating the squared Frobenius norm of the error between the desired matrix X\u22c6 and its estimate X\u0304, normalized by the squared Frobenius norm of the desired matrix:\nNMSE ,\n\u2225 \u2225X\u22c6 \u2212 X\u0304 \u2225 \u2225 2\nF\n\u2016X\u22c6\u20162F . (36)\nThe input signal x \u2208 R64, is considered to be a sparse signal with (i) \u2016x\u20160= 5, and (ii) \u2016x\u20160= 10. To choose the time-varying sampling thresholds, we consider the framework presented in [22], which relies on knowledge of the dynamic range of the measurements y. Assume \u03b2y = \u2016y\u2016\u221e denotes the dynamic range of the measurements. Then, herein we generate the time-varying sampling thresholds as\none-bit QCS polyhedron in (13) via the Block SKM for the number of time-varying sampling threshold sequences m1 \u2208 {10, 50, 100, 150}. Fig. 1 appears to confirm the possibility of recovering the desired matrix X\u22c6 in the one-bit QCS polyhedron (13) by applying Block SKM. As expected, the performance of the recovery will be significantly enhanced as the number of time-varying sampling threshold sequences grows large. The reason behind this observation is the sample abundance condition which has been initially analyzed and proved in [15, Theorem 1] and extended to another sampling scheme in [20]. Note that the results in Fig. 1 are averaged over 15 experiments. To examine the performance of the proposed algorithm for the full rank Aj scenario, we generate a full rank Aj \u2208 R 64\u00d764 where its entries are i.i.d normal random variables. Similarly, we generate time-varying sampling thresholds as { \u03c4 (\u2113) \u223c N ( 0, \u03b22 y\n9 I5000\n)}m1\n\u2113=1\n. Fig. 2 illustrates the\nrecovery performance of the Block SKM in this case while preserving the property of boosting the recovery error as the number of timevarying sampling thresholds grows large. Each data point in Fig. 2 is averaged over 15 experiments. Note that the algorithm proposed employs only low-resolution (one-bit) samples, but capitalizes on their abundance to converge to the global solution with heightened precision as the quantity of one-bit samples increases. Moreover, we numerically compare the RKA [25], SKM [27], and our proposed Block SKM in linear systems of inequalities. We apply one-bit sampling to a system of linear equalities Bx = y, resulting in the creation of its corresponding system of linear inequalities as described in (9). Herein, we consider B \u2208 R100\u00d710 , x \u2208 R10, and y \u2208 R100. Each row of B is generated as bj \u223c N (0, I10). Also, the desired signal x is generated as x \u223c N (0, I10). Accordingly, we generate time-varying sampling thresholds as {\n\u03c4 (\u2113) \u223c N\n(\n0, \u03b22 y\n9 I100\n)}m1\n\u2113=1\nfor m1 = 40. The performance of the RKA, SKM, and Block SKM is illustrated in Fig. 3. The results show\nthat the Block SKM outperforms the other two approaches, delivering a faster recovery and higher accuracy in the recovery of the desired signal x. The normalized mean square error for the signal is defined as NMSE , \u2016x\u22c6\u2212x\u0304\u2016 2 2\n\u2016x\u22c6\u2016 2\n2\n, where x\u22c6 and x\u0304 denote the true discretized signal\nand its recovered version, respectively. The NMSE results in Fig. 3 are averaged over 15 experiments.\nTo further investigate the efficacy of the proposed algorithm in QCS, we compare our proposed approach with the well-known GESPAR approach with the initialization algorithm proposed in [3] in terms of NMSE and CPU time. As presented in Table I, Block SKM outperforms GESPAR in terms of both NMSE and CPU time. The results are obtained for x \u2208 R64 when the optimal number of samples are utilized, and where m\u22c6 = 2n = 128 (high-resolution samples) and m\u22c6 = 5000 (one-bit samples) are considered for the high-resolution method and one-bit QCS, respectively. Herein, the optimality of sample sizes means that the number of samples utilized by algorithms leads to their best performance (up to global phase), i.e. satisfying the criterion \u2016x\u22c6 \u2212 x\u0304\u2016 2 2 \u2264 5 \u00d7 10 \u22125 \u2016x\u22c6\u2016 2 2. By this comparison, we remove the burden of the large number of samples from the GESPAR to fairly compare their optimal shape deploying incomplete measurements with that of the Block SKM. Note that the signal of interest is obtained from X\u0304 = x\u0304x\u0304H, where the signal is the largest eigenvector of the recovered matrix."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "We propose taking advantage of the abundant number of samples available in one-bit sampling with time-varying thresholds to efficiently and globally solve the quadratic compressed sensing problem. In particular, a state-of-the-art randomized Kaczmarz algorithms is proposed to find the desired signal inside the emerging confined feasible regions, named the one-bit polyhedron, with an enhanced convergence rate. The numerical results showcased the effectiveness of the proposed approaches for the quadratic compressed sensing problem."
        }
    ],
    "title": "One-Bit Quadratic Compressed Sensing: From Sample Abundance to Linear Feasibility",
    "year": 2023
}