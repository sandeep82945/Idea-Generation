{
    "abstractText": "From the perspective of historical review, the methodology of economics develops from qualitative to quantitative, from a small sampling of data to a vast amount of data. Because of the superiority in learning inherent law and representative level, deep learning models assist in realizing intelligent decision-making in economics. After presenting some statistical results of relevant researches, this paper systematically investigates deep learning in economics, including a survey of frequently-used deep learning models in economics, several applications of deep learning models used in economics. Then, some critical reviews of deep learning in economics are provided, including models and applications, why and how to implement deep learning in economics, research gap and future challenges, respectively. It is obvious that several deep learning models and their variants have been widely applied in different subfields of economics, e.g., financial economics, macroeconomics and monetary economics, agricultural and natural resource economics, industrial organization, urban, rural, regional, real estate and transportation economics, health, education and welfare, business administration and microeconomics, etc. We are very confident that decision-making in economics will be more intelligent with the development of deep learning, because the research of deep learning in economics has become a hot and important topic recently.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zeshui Xu"
        },
        {
            "affiliations": [],
            "name": "Yuanhang Zheng"
        },
        {
            "affiliations": [],
            "name": "Anran Xiao"
        }
    ],
    "id": "SP:b2a71041ebc76232587eb4ee8d4583996ec1664d",
    "references": [
        {
            "authors": [
                "A Abdalla",
                "HY Cen",
                "L Wan"
            ],
            "title": "Fine-tuning convolutional neural network with transfer learning for semantic segmentation of ground-level oilseed rape images in a field with high weed pressure",
            "venue": "Comput Electron Agric 167:105091",
            "year": 2019
        },
        {
            "authors": [
                "MA Adebowale",
                "KT Lwin",
                "MA Hossain"
            ],
            "title": "Intelligent phishing detection scheme using deep learning algorithms",
            "venue": "J Enterp Inform Manage",
            "year": 2020
        },
        {
            "authors": [
                "A Ajami",
                "M Kuffer",
                "C Persello"
            ],
            "title": "Ahelegbey DF (2016) The econometrics of bayesian graphical models: A review with financial application",
            "venue": "J Netw Theory Finance",
            "year": 2019
        },
        {
            "authors": [
                "A Alsmadi",
                "S AlZu\u2019bi",
                "B Hawashin"
            ],
            "title": "Employing deep learning methods for predicting helpful reviews",
            "venue": "neural decision trees. Appl Sciences-Basel",
            "year": 2020
        },
        {
            "authors": [
                "E Arisoy",
                "A Sethy",
                "B Ramabhadran"
            ],
            "title": "Bidirectional recurrent neural network language models for automatic speech recognition. In 2015 ieee international conference on acoustics, speech, and signal processing (pp. 5421\u20135425)",
            "venue": "New York: Ieee Arkhangelski J, Siano P, Mahamadou AT et al",
            "year": 2015
        },
        {
            "authors": [
                "A Bazan-Krzywoszanska",
                "M Bereta"
            ],
            "title": "The use of urban indicators in forecasting a real estate value with the use of deep neural network",
            "venue": "Rep Geodesy Geoinformatics",
            "year": 2018
        },
        {
            "authors": [
                "R Becerra-Vicario",
                "D Alaminos",
                "E Aranda"
            ],
            "title": "Deep recurrent convolutional neural network for bank",
            "year": 2020
        },
        {
            "authors": [
                "Y Bengio",
                "A Courville",
                "P Vincent"
            ],
            "title": "Representation learning: A review and new perspectives",
            "year": 2013
        },
        {
            "authors": [
                "Y. Bengio",
                "P. Simard",
                "P. Frasconi"
            ],
            "title": "Learning long-term dependencies with gradient descent",
            "venue": "Trans Pattern Anal Mach Intell 35(8):1798\u20131828",
            "year": 1994
        },
        {
            "authors": [
                "D Buongiorno",
                "C Camardella",
                "GD Cascarano"
            ],
            "title": "The methodology of economics",
            "venue": "ficult. IEEE Transactions on Neural Networks,",
            "year": 1981
        },
        {
            "authors": [
                "JA York: Ieee Cerniglia",
                "FJ Fabozzi"
            ],
            "title": "Selecting computational models for asset management: Financial economet",
            "year": 2020
        },
        {
            "authors": [
                "SP Chatzis",
                "V Siakoulis",
                "A Petropoulos"
            ],
            "title": "Forecasting stock market crisis events using deep and",
            "venue": "Conference on Cybernetics and Society,",
            "year": 2018
        },
        {
            "authors": [
                "L Che",
                "XP Yang",
                "L Wang"
            ],
            "title": "Text feature extraction based on stacked variational autoencoder",
            "year": 2020
        },
        {
            "authors": [
                "CT Chen",
                "LK Chiang",
                "YC Huang"
            ],
            "title": "Forecasting interaction of exchange rates between fiat curren",
            "year": 2019
        },
        {
            "authors": [
                "CY Los Alamitos Chen",
                "JS Leu",
                "SW Prakosa"
            ],
            "title": "Using autoencoder to facilitate information retention for data",
            "year": 2018
        },
        {
            "authors": [
                "Ieee",
                "HL New York Chen",
                "S Wang",
                "N Jiang"
            ],
            "title": "Trust-aware generative adversarial network with recurrent neural",
            "year": 2021
        },
        {
            "authors": [
                "ZX Chen",
                "WQ Ma",
                "W Dai"
            ],
            "title": "Conditional restricted boltzmann machine for item recommendation",
            "venue": "Int J Intell Syst 36(2):778\u2013795",
            "year": 2020
        },
        {
            "authors": [
                "D Conte",
                "P Gaucher",
                "C Sansone"
            ],
            "title": "Catfish density estimation by aerial images analysis and deep",
            "year": 2019
        },
        {
            "authors": [
                "S Ding",
                "H Huang",
                "T Zhao"
            ],
            "title": "Estimating socioeconomic status via temporal-spatial mobility analysis",
            "year": 2019
        },
        {
            "authors": [
                "M Ebrahimi",
                "JF Nunamaker",
                "HC Chen"
            ],
            "title": "Semi-supervised cyber threat identification in dark net",
            "year": 2020
        },
        {
            "authors": [
                "JL Elman"
            ],
            "title": "Finding structure in time",
            "year": 1990
        },
        {
            "authors": [
                "O Faust",
                "NR Lei",
                "E Chew"
            ],
            "title": "A smart service platform for cost efficient cardiac health monitoring",
            "year": 2020
        },
        {
            "authors": [
                "UJ Frey",
                "M Klein",
                "M Deissenroth"
            ],
            "title": "Modelling complex investment decisions in germany for renew",
            "venue": "Ieee Access 9:153083\u2013153101",
            "year": 2019
        },
        {
            "authors": [
                "H envsoft.2019.03.006 Fujita",
                "D Cimr"
            ],
            "title": "Computer aided detection for fibrillations and flutters using deep convolutional",
            "year": 2019
        },
        {
            "authors": [
                "TR Gadekallu",
                "DS Rajput",
                "MPK Reddy"
            ],
            "title": "A novel pca-whale optimization-based deep neural network model for classification of tomato plant diseases using gpu",
            "venue": "J Real-Time Image Proc. https://doi",
            "year": 2020
        },
        {
            "authors": [
                "S Galeshchuk"
            ],
            "title": "Technological bias at the exchange rate market",
            "venue": "Intell Syst Acc Finance Manage",
            "year": 2017
        },
        {
            "authors": [
                "S Galeshchuk",
                "Y Demazeau"
            ],
            "title": "Forecasting hungarian forint exchange rate with convolutional neural networks",
            "year": 2017
        },
        {
            "authors": [
                "S Galeshchuk",
                "S Mukherjee"
            ],
            "title": "Deep learning for predictions in emerging currency markets",
            "venue": "Paper presented at the In Proceedings of the 9th International Conference on Agents and Artificial Intelligence",
            "year": 2017
        },
        {
            "authors": [
                "A Gensler",
                "J Henze",
                "B Sick"
            ],
            "title": "Deep learning for solar power forecasting - an approach using autoencoder and lstm neural networks",
            "venue": "In 2016 ieee international conference on systems, man, and cybernetics (pp. 2858\u20132865)",
            "year": 2016
        },
        {
            "authors": [
                "I Goodfellow",
                "Y Bengio",
                "Courville"
            ],
            "title": "A (2016) Deep learning",
            "year": 2016
        },
        {
            "authors": [
                "A Graves",
                "G Wayne"
            ],
            "title": "Eynolds MR et al (2016) Hybrid computing using a neural network with dynamic external memory",
            "venue": "Nature 538(7626):471\u2013",
            "year": 2010
        },
        {
            "authors": [
                "PP Groumpos"
            ],
            "title": "Artificial intelligence: Issues, challenges, opportunities and threats",
            "year": 2019
        },
        {
            "authors": [
                "JX Gu",
                "ZH Wang",
                "J Kuen"
            ],
            "title": "Recent advances in convolutional neural networks",
            "venue": "Pattern Recogn 77:354\u2013377",
            "year": 2018
        },
        {
            "authors": [
                "R Guidotti",
                "A Monreale",
                "S Ruggieri"
            ],
            "title": "A survey of methods for explaining black box models",
            "venue": "ACMCSUR",
            "year": 2019
        },
        {
            "authors": [
                "H Guo",
                "L Tang",
                "Y Peng"
            ],
            "title": "Ensemble deep learning method for short-term load forecasting",
            "venue": "Paper presented at the 2018 14th International Conference on Mobile Ad-Hoc and Sensor Networks",
            "year": 2018
        },
        {
            "authors": [
                "LN Guo"
            ],
            "title": "Cross-border e-commerce platform for commodity automatic pricing model based on deep learning",
            "venue": "Electron Commer Res",
            "year": 2020
        },
        {
            "authors": [
                "Y Guo",
                "H Wang",
                "Q Hu"
            ],
            "title": "Deep learning for 3d point clouds: A survey",
            "venue": "IEEE Trans Pattern Anal Mach Intell",
            "year": 2020
        },
        {
            "authors": [
                "YN Han",
                "YY Ma",
                "JB Wang"
            ],
            "title": "Research on ensemble model of anomaly detection based on autoencoder",
            "year": 2020
        },
        {
            "authors": [
                "S Haytamy",
                "F Omara"
            ],
            "title": "A deep learning based framework for optimizing cloud consumer qos-based service composition",
            "year": 2020
        },
        {
            "authors": [
                "J He"
            ],
            "title": "Application of deep learning model under improved emd in railway transportation investment benefits and national economic attribute analysis",
            "venue": "J Supercomputing",
            "year": 2021
        },
        {
            "authors": [
                "QQ He",
                "CI Pang",
                "YW Si"
            ],
            "title": "Transfer learning for financial time series forecasting.PRICAI: Trends in Artificial Intelligence,24\u201336",
            "year": 2019
        },
        {
            "authors": [
                "X He",
                "YS Chen",
                "ZH Lin"
            ],
            "title": "Spatial-spectral transformer for hyperspectral image classification",
            "venue": "Remote Sens 13(3):21",
            "year": 2021
        },
        {
            "authors": [
                "JB Heaton",
                "NG Polson",
                "JH Witte"
            ],
            "title": "Deep learning for finance: Deep portfolios",
            "venue": "Appl Stoch Models Bus Ind 33(1):3\u201312",
            "year": 2017
        },
        {
            "authors": [
                "G Hinton",
                "L Deng",
                "D Yu"
            ],
            "title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups",
            "venue": "IEEE Signal Process Mag",
            "year": 2012
        },
        {
            "authors": [
                "GE Hinton",
                "S Osindero",
                "YW Teh"
            ],
            "title": "A fast learning algorithm for deep belief nets",
            "venue": "Neural Comput",
            "year": 2006
        },
        {
            "authors": [
                "GE Hinton",
                "RR Salakhutdinov"
            ],
            "title": "Reducing the dimensionality of data with neural networks",
            "venue": "Science",
            "year": 2006
        },
        {
            "authors": [
                "S. Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural Computing,",
            "year": 1997
        },
        {
            "authors": [
                "SH Hong",
                "S Ryu",
                "J Lim"
            ],
            "title": "Molecular generative model based on an adversarially regularized autoencoder",
            "venue": "J Chem Inf Model 60(1):29\u201336",
            "year": 2020
        },
        {
            "authors": [
                "CP Hou",
                "FP Nie",
                "XL Li"
            ],
            "title": "Joint embedding learning and sparse regression: A framework for unsupervised feature selection",
            "venue": "Ieee Trans Cybernetics 44(6):793\u2013804",
            "year": 2014
        },
        {
            "authors": [
                "J Huan",
                "H Hong",
                "X Pan"
            ],
            "title": "Short-term load forecasting of integrated energy systems based on deep learning",
            "venue": "5th Asia Conference on Power and Electrical Engineering (ACPEE). https://doi",
            "year": 2020
        },
        {
            "authors": [
                "J Huang",
                "JY Chai",
                "S Cho"
            ],
            "title": "Deep learning in finance and banking: A literature review and classification",
            "venue": "Front Bus Res China",
            "year": 2020
        },
        {
            "authors": [
                "SC Huang",
                "CF Wu"
            ],
            "title": "Energy commodity price forecasting with deep multiple kernel learning. Energies",
            "year": 2018
        },
        {
            "authors": [
                "S Hugo",
                "B Kathy",
                "H Thomas"
            ],
            "title": "Machine learning in agricultural and applied economics",
            "venue": "Eur Rev Agric Econ",
            "year": 2019
        },
        {
            "authors": [
                "Y. Ji",
                "A.W.C. Liew",
                "L.X. Yang"
            ],
            "title": "A novel improved particle swarm optimization with longshort term memory hybrid model for stock indices forecast",
            "venue": "Ieee Access,",
            "year": 2021
        },
        {
            "authors": [
                "Z.G. Jin",
                "Y. Yang",
                "Y.H. Liu"
            ],
            "title": "Stock closing price prediction based on sentiment analysis and lstm",
            "venue": "Neural Computing & Applications,",
            "year": 2020
        },
        {
            "authors": [
                "M.I. Jordan"
            ],
            "title": "Serial order: A parallel distributed processing approach. Institute for Cognitive Science University of California, San Diego",
            "year": 1986
        },
        {
            "authors": [
                "D. Katayama",
                "Y. Kino",
                "K. Tsuda"
            ],
            "title": "A method of sentiment polarity identification in financial news using deep learning",
            "year": 2019
        },
        {
            "authors": [
                "J.M. Keynes"
            ],
            "title": "The general theory of employment, interest and money",
            "venue": "Foreign affairs,",
            "year": 1936
        },
        {
            "authors": [
                "H. Khatter",
                "A. Ahlawat"
            ],
            "title": "An intelligent personalized web blog searching technique using fuzzybased feedback recurrent neural network",
            "venue": "Soft Computing,",
            "year": 2020
        },
        {
            "authors": [
                "S.R. Kheradpisheh",
                "M. Ganjtabesh",
                "Thorpe",
                "S. J"
            ],
            "title": "Stdp-based spiking deep convolutional neural networks for object recognition",
            "venue": "Neural Networks,",
            "year": 2018
        },
        {
            "authors": [
                "H.G. Kim",
                "G.Y. Kim",
                "J.Y. Kim"
            ],
            "title": "Music recommendation system using human activity recognition from accelerometer data",
            "venue": "Ieee Transactions on Consumer Electronics,",
            "year": 2019
        },
        {
            "authors": [
                "S. Kremsner",
                "A. Steinicke",
                "M. Szlgyenyi"
            ],
            "title": "A deep neural network algorithm for semilinear elliptic pdes with applications in insurance",
            "venue": "mathematics. Risks,",
            "year": 2020
        },
        {
            "authors": [
                "C. Krittanawong",
                "K.W. Johnson",
                "Rosenson",
                "R. S"
            ],
            "title": "Deep learning for cardiovascular medicine: A practical primer",
            "venue": "European Heart Journal,",
            "year": 2019
        },
        {
            "authors": [
                "T. Lan",
                "X.Y. Feng",
                "L Li"
            ],
            "title": "Similar trademark image retrieval based on convolutional neural network and constraint theory",
            "venue": "In 2018 eighth international conference on image processing theory, tools and applications (pp. 205\u2013210)",
            "year": 2018
        },
        {
            "authors": [
                "N. Le Roux",
                "Y. Bengio"
            ],
            "title": "Representational power of restricted boltzmann machines and deep belief networks",
            "venue": "Neural Computation,",
            "year": 2008
        },
        {
            "authors": [
                "Y. LeCun"
            ],
            "title": "Modeles connexionnistes de l\u2019apprentissage",
            "venue": "These De Doctorat Universite Paris,",
            "year": 1987
        },
        {
            "authors": [
                "Y. LeCun",
                "L. Bottou",
                "Y Bengio"
            ],
            "title": "Gradient-based learning applied to document recognition",
            "venue": "Proceedings of the Ieee,",
            "year": 1998
        },
        {
            "authors": [
                "C.F. Lee"
            ],
            "title": "Financial econometrics, mathematics, statistics, and financial technology: An overall view",
            "venue": "Review of Quantitative Finance and Accounting,",
            "year": 2020
        },
        {
            "authors": [
                "H.Y. Li",
                "L.N. Pan",
                "M Chen"
            ],
            "title": "Rbm-based back propagation neural network with bsasa optimization for time series forecasting",
            "year": 2017
        },
        {
            "authors": [
                "X.H. Li",
                "X.L. Wang"
            ],
            "title": "Cv image segmentation model combining convolutional restricted boltzmann machine",
            "venue": "Laser & Optoelectronics Progress,",
            "year": 2020
        },
        {
            "authors": [
                "X.S. Li",
                "J.F. Liu",
                "Li",
                "J. J"
            ],
            "title": "A stacked denoising sparse autoencoder based fault early warning method for feedwater heater performance degradation. Energies",
            "year": 2020
        },
        {
            "authors": [
                "Y. Li",
                "S. Wang",
                "Y. Wei",
                "Q. Zhu"
            ],
            "title": "A new hybrid VMD-ICSS-BiGRU approach for gold futures price forecasting and algorithmic trading",
            "venue": "IEEE Transactions on Computational Social Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Y. Li",
                "Z.S. Xu",
                "Wang",
                "X. X"
            ],
            "title": "A bibliometric analysis on deep learning during 2007\u2013 2019",
            "venue": "International Journal of Machine Learning and Cybernetics,",
            "year": 2020
        },
        {
            "authors": [
                "S.Y. Liao",
                "W. Zhuo",
                "L Yao"
            ],
            "title": "Locational marginal price forecasting using transformer-based deep learning network. Paper presented at the 2021 40th Chinese Control Conference (CCC). Conference Paper retrieved from < Go to ISI>://INSPEC:21225180",
            "year": 2021
        },
        {
            "authors": [
                "I. Lindenlaub",
                "A. Prummer"
            ],
            "title": "Network structure and performance",
            "venue": "Economic Journal,",
            "year": 2021
        },
        {
            "authors": [
                "J.L. Liu",
                "C.M.M. Lin",
                "F. Chao"
            ],
            "title": "Gradient boost with convolution neural network for stock forecast",
            "venue": "Advances in computational intelligence systems (Vol",
            "year": 2020
        },
        {
            "authors": [
                "Y. Liu",
                "Q.G. Zeng",
                "Yang",
                "H. R"
            ],
            "title": "Stock price movement prediction from financial news with deep learning and knowledge graph embedding",
            "year": 2018
        },
        {
            "authors": [
                "Z. Liu",
                "Y. Lin",
                "Y Cao"
            ],
            "title": "Swin transformer: Hierarchical vision transformer using shifted windows. arXiv",
            "year": 2021
        },
        {
            "authors": [
                "J.Y. Long",
                "Z.Z. Sun",
                "C Li"
            ],
            "title": "A novel sparse echo autoencoder network for data-driven fault diagnosis of delta 3-d printers",
            "venue": "Ieee Transactions on Instrumentation and Measurement,",
            "year": 2020
        },
        {
            "authors": [
                "A.A. Lukman",
                "O.O. Ahmed",
                "Lukumon",
                "O. O"
            ],
            "title": "Deep learning model for demolition waste prediction in a circular economy",
            "venue": "Journal of Cleaner Production,",
            "year": 2020
        },
        {
            "authors": [
                "J.Q. Luo",
                "S.S. Huang",
                "R.W. Wang"
            ],
            "title": "A fine-grained sentiment analysis of online guest reviews of economy hotels in china",
            "venue": "Journal of Hospitality Marketing & Management,",
            "year": 2021
        },
        {
            "authors": [
                "S.K. Mahata",
                "D. Das",
                "S. Bandyopadhyay"
            ],
            "title": "Mtil2017: Machine translation using recurrent neural network on statistical machine translation",
            "venue": "Journal of Intelligent Systems,",
            "year": 2019
        },
        {
            "authors": [
                "I. Markou",
                "F. Rodrigues",
                "F.C. Pereira"
            ],
            "title": "Is travel demand actually deep? An application in event areas using semantic information",
            "venue": "Ieee Transactions on Intelligent Transportation Systems,",
            "year": 2020
        },
        {
            "authors": [
                "A. Marshall"
            ],
            "title": "The principles of economics",
            "venue": "History of Economic Thought Books",
            "year": 1992
        },
        {
            "authors": [
                "Q.X. Meng",
                "D. Catchpoole",
                "D Skillicorn"
            ],
            "title": "Relational autoencoder for feature extraction",
            "venue": "In 2017 international joint conference on neural networks (pp. 364\u2013371)",
            "year": 2017
        },
        {
            "authors": [
                "K. Mishev",
                "A. Gjorgjevikj",
                "I Vodenska"
            ],
            "title": "Evaluation of sentiment analysis in finance: From lexicons to transformers",
            "venue": "Ieee Access,",
            "year": 2020
        },
        {
            "authors": [
                "R. Mittelman",
                "B. Kuipers",
                "S Savarese"
            ],
            "title": "Structured recurrent temporal restricted boltzmann machines",
            "venue": "Paper presented at the International Conference on Machine Learning",
            "year": 2014
        },
        {
            "authors": [
                "V. Mnih",
                "K. Kavukcuoglu",
                "D Silver"
            ],
            "title": "Playing atari with deep reinforcement learning",
            "venue": "Computer Science",
            "year": 2013
        },
        {
            "authors": [
                "A. Mosavi",
                "Y. Faghan",
                "P Ghamisi"
            ],
            "title": "Comprehensive review of deep reinforcement learning methods and applications in economics",
            "year": 2020
        },
        {
            "authors": [
                "M. Nikou",
                "G. Mansourfar",
                "J. Bagherzadeh"
            ],
            "title": "Stock price prediction using deep learning algorithm and its comparison with machine learning algorithms",
            "venue": "Intelligent Systems in Accounting Finance & Management,",
            "year": 2019
        },
        {
            "authors": [
                "H.L. Niu",
                "K.L. Xu",
                "W.Q. Wang"
            ],
            "title": "A hybrid stock price index forecasting model based on variational mode decomposition and lstm network",
            "venue": "Applied Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "H.M. Noaman",
                "S.S. Sarhan",
                "M.A.A. Rashwan"
            ],
            "title": "Enhancing recurrent neural network-based language models by word tokenization",
            "venue": "Human-Centric Computing and Information Sciences,",
            "year": 2018
        },
        {
            "authors": [
                "S. Nosratabadi",
                "A. Mosavi",
                "P Duan"
            ],
            "title": "Data science in economics: Comprehensive review of advanced machine learning and deep learning methods",
            "year": 2020
        },
        {
            "authors": [
                "O. Ozgur",
                "U. Akkoc"
            ],
            "title": "Inflation forecasting in an emerging economy: Selecting variables with machine learning algorithms",
            "venue": "International Journal of Emerging Markets",
            "year": 2021
        },
        {
            "authors": [
                "L. Page",
                "R.T. Clemen"
            ],
            "title": "Do prediction markets produce well-calibrated probability forecasts",
            "venue": "Economic Journal,",
            "year": 2013
        },
        {
            "authors": [
                "D.I. Patricio",
                "R. Rieder"
            ],
            "title": "Computer vision and artificial intelligence in precision agriculture for grain crops: A systematic review",
            "venue": "Computers and Electronics in Agriculture,",
            "year": 2018
        },
        {
            "authors": [
                "J. Z",
                "Y.X. Su",
                "Zhang",
                "D. H"
            ],
            "title": "Deep learning in economics: a systematic and critical review",
            "year": 2020
        },
        {
            "authors": [
                "C. Phitthayanon",
                "V. Rungreunganun"
            ],
            "title": "Material cost prediction for jewelry production",
            "year": 2019
        },
        {
            "authors": [
                "D.W. Qiu",
                "Y.J. Ye",
                "D Papadaskalopoulos"
            ],
            "title": "A deep reinforcement learning method for pric",
            "year": 2020
        },
        {
            "authors": [
                "M.H. Rafiei",
                "H. Adeli"
            ],
            "title": "A novel machine learning model for estimation of sale prices of real estate",
            "year": 2016
        },
        {
            "authors": [
                "R.C. Guo",
                "R Moraffah"
            ],
            "title": "Linked causal variational autoencoder for inferring",
            "venue": "units. Journal of Construction Engineering and Management,",
            "year": 2018
        },
        {
            "authors": [
                "N. Ranjan",
                "S. Bhandari",
                "P Khan"
            ],
            "title": "Large-scale road network congestion pattern analysis",
            "year": 2021
        },
        {
            "authors": [
                "T.C.S. Rao",
                "S.S.T. Ram",
                "J.B.V. Subrahmanyam"
            ],
            "title": "Fault signal recognition in power",
            "year": 2020
        },
        {
            "authors": [],
            "title": "Econometrics and arms races - critical-review and some extensions",
            "venue": "European Journal",
            "year": 1976
        },
        {
            "authors": [
                "M.T. Ribeiro",
                "S. Singh",
                "C Guestrin"
            ],
            "title": "Why should i trust you?\u201c Explaining the predictions",
            "venue": "Political Research,",
            "year": 2016
        },
        {
            "authors": [
                "R. Salakhutdinov",
                "Hinton",
                "G.J.N. C"
            ],
            "title": "An efficient learning procedure for deep boltzmann",
            "year": 2012
        },
        {
            "authors": [
                "O. 1967\u20132006. Sattarov",
                "A. Muminov",
                "Lee",
                "C. W"
            ],
            "title": "Recommending cryptocurrency trading points with",
            "year": 2020
        },
        {
            "authors": [
                "L. Sehovac",
                "K. Grolinger"
            ],
            "title": "Deep learning for load forecasting: Sequence to sequence recurrent neural",
            "year": 2020
        },
        {
            "authors": [
                "M. Sharaf",
                "E.E. Hemdan",
                "A El-Sayed"
            ],
            "title": "Stockpred: A framework for stock price prediction",
            "venue": "neural networks. Acm Transactions on Graphics,",
            "year": 2021
        },
        {
            "authors": [
                "T. Shi",
                "F. Mei",
                "Lu",
                "J. X"
            ],
            "title": "Phase space reconstruction algorithm and deep learning-based",
            "venue": "Multimedia Tools and Applications,",
            "year": 2019
        },
        {
            "authors": [
                "H. Sakaji",
                "K Izumi"
            ],
            "title": "An inquiry into the nature and causes of the wealth of nations",
            "venue": "short-term bus load forecasting. Energies,",
            "year": 1976
        },
        {
            "authors": [
                "P. Wu",
                "Zhou",
                "G. H"
            ],
            "title": "Combining residual neural networks and feature pyramid",
            "year": 2020
        },
        {
            "authors": [
                "Y.M. jstars.2020.2968468 Tang",
                "K.Y. Chau",
                "Li",
                "W. Q"
            ],
            "title": "Forecasting economic recession through share price",
            "year": 2020
        },
        {
            "authors": [
                "Z.R. Tao",
                "L. Han",
                "K. Bai"
            ],
            "title": "The economic impact analysis of the 1994 northridge earthquake",
            "year": 2020
        },
        {
            "authors": [
                "X.L. Ag. Tian",
                "Z.S. Xu",
                "J. Gu"
            ],
            "title": "An extended todim based on cumulative prospect theory and its appli",
            "year": 2019
        },
        {
            "authors": [
                "H. Touvron",
                "M. Cord",
                "M Douze"
            ],
            "title": "Training data-efficient image transformers & distillation",
            "year": 2020
        },
        {
            "authors": [
                "N. Tsakas",
                "D. Xefteris",
                "N. Ziros"
            ],
            "title": "Vote trading in power-sharing systems: A laboratory",
            "year": 2021
        },
        {
            "authors": [
                "Y.Y. Zheng et al. Tsutsui",
                "M. Hagiwara"
            ],
            "title": "Analog value associative memory using restricted boltzmann machine",
            "year": 2019
        },
        {
            "authors": [
                "S.A.A. Shah",
                "Al-Khasawneh",
                "M. A"
            ],
            "title": "Optimal policy learning for covid",
            "year": 2020
        },
        {
            "authors": [
                "H. Naeem",
                "S Jabbar"
            ],
            "title": "Cyber security threats detection in internet of things",
            "year": 2019
        },
        {
            "authors": [
                "Long Beach",
                "P. CA. Vincent",
                "H. Larochelle",
                "Y Bengio"
            ],
            "title": "Extracting and composing robust features with denois",
            "venue": "Annual Conference on Neural Information Processing Systems",
            "year": 2008
        },
        {
            "authors": [
                "J. Wang"
            ],
            "title": "Speech recognition in english cultural promotion via recurrent neural network",
            "year": 2020
        },
        {
            "authors": [
                "Q. Wang",
                "L. Chen",
                "J Zhao"
            ],
            "title": "A deep granular network with adaptive unequal-length granula",
            "venue": "Ubiquitous Computing,",
            "year": 2020
        },
        {
            "authors": [
                "Q.Q. Wang",
                "C.B. Li"
            ],
            "title": "Incident detection and classification in renewable energy news",
            "year": 2022
        },
        {
            "authors": [
                "W.H. Wang",
                "W.P. Li"
            ],
            "title": "Research on trend analysis method of multi-series economic data",
            "year": 2020
        },
        {
            "authors": [
                "D.S. Zeng"
            ],
            "title": "Development of sports industry under the influence of covid-19 epidemic",
            "year": 2020
        },
        {
            "authors": [
                "Y.N. You",
                "T.L. Chen"
            ],
            "title": "Ar-stock: Deep augmented relational stock",
            "year": 2021
        },
        {
            "authors": [
                "H. Services. Wu",
                "B. Xiao",
                "N Codella"
            ],
            "title": "Cvt: Introducing convolutions to vision transformers",
            "year": 2021
        },
        {
            "authors": [
                "Q. Wu",
                "Y. Guo",
                "H Chen"
            ],
            "title": "Establishment of a deep learning network based on feature extraction",
            "year": 2019
        },
        {
            "authors": [
                "J. neucom.2017.05.063 Xu",
                "L. Xiang",
                "Liu",
                "Q. S"
            ],
            "title": "Stacked sparse autoencoder (ssae) for nuclei detection on breast",
            "year": 2016
        },
        {
            "authors": [],
            "title": "Risk factor analysis combined with deep learning in the risk assessment of overseas",
            "year": 2020
        },
        {
            "authors": [
                "Y.Y. Xu",
                "Z. Liu",
                "Li",
                "Y. J"
            ],
            "title": "Feature data processing: Making medical data fit deep",
            "venue": "Plos One,",
            "year": 2020
        },
        {
            "authors": [
                "J.B. Zhang",
                "Y Hong"
            ],
            "title": "Mapping fine-scale urban housing prices by fusing remotely",
            "year": 2018
        },
        {
            "authors": [
                "M. tgis.12330 Yasir",
                "M.Y. Durrani",
                "S Afzal"
            ],
            "title": "An intelligent event-sentiment-based daily foreign exchange",
            "year": 2019
        },
        {
            "authors": [
                "C. Yeh",
                "A. Perez",
                "A Driscoll"
            ],
            "title": "Using publicly available satellite imagery and deep",
            "venue": "Sciences-Basel,",
            "year": 2020
        },
        {
            "authors": [
                "B. Yu",
                "Y. Dong",
                "F Chen"
            ],
            "title": "Economy estimation of mainland china at county-level based on landsat images and multi-task deep learning framework",
            "venue": "Photogrammetric Engineering and Remote Sensing,",
            "year": 2020
        },
        {
            "authors": [
                "J. Yu",
                "J. Li",
                "Z Yu"
            ],
            "title": "Multimodal transformer with multi-view visual representation for image captioning",
            "venue": "Ieee Transactions on Circuits and Systems for Video Technology,",
            "year": 2020
        },
        {
            "authors": [
                "F.C. Yuan",
                "C.H. Lee"
            ],
            "title": "Intelligent sales volume forecasting using google search engine data",
            "venue": "Soft Computing,",
            "year": 2020
        },
        {
            "authors": [
                "Z.R. Yue",
                "C.R. Witzig",
                "D Jorde"
            ],
            "title": "Bert4nilm: A bidirectional transformer model for non-intrusive load monitoring. Paper presented at the NILM\u201920: Proceedings of the 5th International Workshop on Non-Intrusive Load Monitoring",
            "year": 2020
        },
        {
            "authors": [
                "L.A. Zadeh"
            ],
            "title": "Concept of a linguistic variable and its application to approximate reasoning .2",
            "venue": "Information Sciences,",
            "year": 1975
        },
        {
            "authors": [
                "C. Zhang",
                "R. Li",
                "H Shi"
            ],
            "title": "Deep learning for day-ahead electricity price forecasting",
            "venue": "Iet Smart Grid,",
            "year": 2020
        },
        {
            "authors": [
                "J.H. Zhang",
                "Z.Y. Xu",
                "Xu",
                "W. S"
            ],
            "title": "Bi-objective dispatch of multi-energy virtual power plant: Deep-learning-based prediction and particle swarm optimization",
            "venue": "Applied Sciences-Basel,",
            "year": 2019
        },
        {
            "authors": [
                "M.G. Zhang",
                "Z.Y. Yang"
            ],
            "title": "Gacoforrec: Session-based graph convolutional neural networks recommendation model",
            "venue": "Ieee Access,",
            "year": 2019
        },
        {
            "authors": [
                "W.X. Zhang",
                "C. Witharana",
                "Liljedahl",
                "A. K"
            ],
            "title": "Deep convolutional neural networks for automated characterization of arctic ice-wedge polygons in very high spatial resolution aerial imagery",
            "venue": "Remote Sensing,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Zhang",
                "Q. Yang"
            ],
            "title": "An overview of multi-task learning",
            "venue": "National Science Review,",
            "year": 2018
        },
        {
            "authors": [
                "Y.F. Zhang",
                "L. Shi",
                "Y Wu"
            ],
            "title": "Gesture recognition based on deep deformable 3d convolutional neural networks",
            "venue": "Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Y.H. Zheng",
                "Z.S. Xu",
                "X.X. Wang"
            ],
            "title": "The fusion of deep learning and fuzzy systems: A state-of-theart survey",
            "venue": "IEEE Transactions on Fuzzy Systems",
            "year": 2021
        },
        {
            "authors": [
                "X. Zhong",
                "D. Enke"
            ],
            "title": "Predicting the daily return direction of the stock market using hybrid machine learning algorithms",
            "venue": "Financial Innovation,",
            "year": 2019
        },
        {
            "authors": [
                "S.Y. Zhou",
                "L. Zhou",
                "Mao",
                "M. X"
            ],
            "title": "An optimized heterogeneous structure lstm network for electricity price forecasting",
            "venue": "Ieee Access,",
            "year": 2019
        },
        {
            "authors": [
                "W. Zhou",
                "M. Liu",
                "Xu",
                "Z. S"
            ],
            "title": "Investment decision making based on the probabilistic hesitant financial data: Model and empirical study",
            "venue": "Economic Research-Ekonomska Istrazivanja. https://doi.org",
            "year": 2020
        },
        {
            "authors": [
                "Y.H. Zhou",
                "B. Zhang",
                "Xu",
                "C. L"
            ],
            "title": "A data-driven method for fast ac optimal power flow solutions via deep reinforcement learning",
            "venue": "Journal of Modern Power Systems and Clean Energy,",
            "year": 2020
        },
        {
            "authors": [
                "X.L. Zhu",
                "K.U. Rehman",
                "B Wang"
            ],
            "title": "Modern soft-sensing modeling methods for fermentation",
            "venue": "processes. Sensors,",
            "year": 2020
        },
        {
            "authors": [
                "F.Z. Zhuang",
                "Z.Y. Qi",
                "Duan",
                "K. Y"
            ],
            "title": "A comprehensive survey on transfer learning",
            "venue": "Proceedings of the Ieee,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Zeshui Xu xuzeshui@263.net\nYuanhang Zheng yuanhang_zheng@foxmail.com\nAnran Xiao xiaoanran_ubby@163.com\n1 College of Computer Science, Sichuan University, 610064 Chengdu, PR China 2 Business School, Sichuan University, 610064 Chengdu, PR China\nKeywords Deep learning \u00b7 Economics \u00b7 Critical review \u00b7 Intelligent decision-making\n1 3\nY. Zheng et al."
        },
        {
            "heading": "1 Introduction",
            "text": "Economics is a significant subject that studies various economic activities and corresponding economic relations of human society, aiming to help people discover economic regulation, instruct economic practice and forecast economic behavior (Marshall, 1992). In order to study the concepts, theories and basic reasoning principle of economics, economic methodology were constructed (Blaug, 1981). The development of economic methodology has gone through the following five stages: (1) Before 1790s, possible economic laws were concluded through complicated history and statistical data of economic and social phenomena, represented by a book \u201cAn Inquiry Into the Nature and Causes of the Wealth of Nations\u201d (Smith, 1976); (2) Between Mid-17th to Mid-19th century, that was the period of classical economics, researchers adopted reasoning mode that takes deduction as the leading actor and induction as the supplementary; (3) From late 19th century to early 20th century, Marshall founded the neoclassical school, which provides economic community with tools such as static method, local analysis and general equilibrium analysis, etc. Then, he began to pay attention to the statistical supplement of economic theory (Marshall, 1992); (4) At 1930, the publication of Keynes\u2019s General Theory broke the neoclassical harmony between individual and social interests, reintroducing moral issues and dynamic changes into economics. So that from 1930 to 1960 s, Positivism and falsificationism disputed each other and this period became the golden age of the development of economic methodology (Keynes, 1936); (5) After 1960s, with the rapid development of econometrics, statistics, econometric methods and tools became the main research weapons adopted by mainstream economics. Positivism dominated the upper hand (Ahelegbey, 2016; Lee, 2020).\nAs far as we know, the methodology of economics develops from qualitative to quantitative, and mathematic models play important roles (Lindenlaub & Prummer, 2021; Page & Clemen, 2013; Tsakas et al., 2021). But it is undeniable that the criticism and reflection on this methodology system has never stopped (Cerniglia and Fabozzi, 2020; Rattinger, 1976). Especially with the emergence of many \u201cblack swan events\u201d such as the financial crisis and epidemic disease, the interpretation and prediction ability of Positivist Economics has been greatly challenged, and the effectiveness of the policy measures proposed by it has been seriously questioned. Without strict premise of hypothesis and mathematic models, machine learning has been adopted to handle a large amount of data or the economic problem cannot be described by mathematic models (Hugo et al., 2019; Ozgur & Akkoc, 2021).\nHowever, if the amount of data in economic field is extremely huge and the information is buried in meaningless features, the feature learning efficiency of machine learning algorithms will largely decrease and its performance will be severely affected. Deep learning aims at mining the relationships and regulations hidden in the data by constructing the representation hierarchy of data, for performing downstream tasks, such as classification and decision-making. Hence, it can also improve the intelligent decision-making in economic fields. Because it can deal with a larger amount of higher dimensional data and mine the potential information and rules in the data, deep learning models usually perform better than traditional machine learning models. Combined with other models, deep learning variants solve many practical problems in economics. Therefore, deep learning has greatly improved the development of economics research. A comprehensive literature review and critical comments on deep learning in economics, not only provide economists with new\n1 3\n9498\nDeep learning in economics: a systematic and critical review\nideas and methods to solve economic problems, but also expand the application scenarios for machine learning community.\nAs special type of machine learning, deep learning models are representation-learning methods with multiple simple but non-linear modules, constructed in the form of multilayer neural network (LeCun et al., 2015). It has strong expression ability and can perform sufficiently complex functions for fitting features. Its concept came into people\u2019s sight when deep belief network (DBN) was proposed by Hinton and Salakhutdinov (2006). Since then, deep learning has become an important driving force for scientific research and application in the field of artificial intelligence. Some several deep learning models, e.g., Deep Neural Network (DNN), Restricted Boltzmann Machine (RBM), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Autoencoder (AE), or hybrid techniques, like Deep Reinforcement Learning (DRL), have been developed rapidly and widely applied in pattern recognition (Salakhutdinov & Hinton, 2012), speech recognition (Arisoy et al., 2015), computer vision (Guo et al., 2020), auto-controlling (Roopaei et al., 2017), mechanical equipment (Wu et al., 2019), medical system (Xu et al., 2020), financial field (Huang et al., 2020) and other fields. The main differences between these deep learning models are discussed in Table 1.\nAlthough the application of deep learning in the economic field started late, it has developed very rapidly. Searched from Web of Science, Scopus and DBLP dataset, the first three published papers about the topic of deep learning and economics were collected at 2014. Then, the number of relevant articles increases every year in the average speed of 222.4% from 2015, until 631 published papers in 2021. Comprehensive review of advanced machine learning and deep learning methods (Nosratabadi et al., 2020) has summarized four data science methods in economics, including deep learning models, hybrid deep learning, hybrid machine learning, and ensemble models. The findings show that the development trends of hybrid models will outperform other learning algorithms. Moreover, a bibliometric analysis on deep learning (Li et al., 2020b) provides researchers with a statistical perspective on the development of the field. A state-of-the-art survey about fusing deep learning and fuzzy systems (Zheng et al., 2021) gives a systematic analysis on the fusion effect of fuzzy technology and deep learning.\nIn this paper, we try to investigate and present answers to the following research questions:\n1) Which deep learning models are preferred (and more successful) in economics? What are the characteristics of different deep learning algorithms in the economic field? 2) What economic application areas are of interest to deep learning community? What are the differences when execute deep learning models against traditional soft computing/ machine learning techniques? 3) What are the drawbacks of the current applications of deep learning in economics? 4) What are the future directions of researches about deep learning in economics?\nTherefore, this paper systematically investigates the frequently used deep learning models in economics and several applications of deep learning in economics, aiming to provide a comprehensive cognition of deep learning in economics and seek a new path or new ideas for its development. The main insights of the paper are in the following aspects: (1) Introducing deep learning into economics community and making a survey of frequently-used deep learning models in economic applications, including DNN, RBM, DBN, CNN, RNN,\n1 3\n9499\nY. Zheng et al.\nAE, Transformer and DRL (The main differences between these deep learning models are shown in Table 1); (2) Exhibiting applications of deep learning in economics, in which the applications are classified based on Journal of Economic Literature (JEL) classification system. It is a standard method of classifying scholarly literature in the field of economics (\u201cJel classification system,\u201c); (3) Providing some critical review of deep learning in economics, and offering some possible trends and opportunities of the further fusion.\nThe rest of the paper is constructed as follows: Sect. 2 presents some statistical results of literature about deep learning in economics. Then, Sect. 3 introduces eight frequently-used deep learning methods and their applications in economics and Sect. 4 analyzes the most common applications of using deep learning in economics. Section 5 offers some critical review of deep learning in economics, including critical review on models and applications, models and applications, why and how to implement deep learning in economics, research gap and future challenges. Finally, the answers to our initially stated research questions and some conclusions are exhibited in Sect. 6."
        },
        {
            "heading": "2 Statistical results",
            "text": "In order to collect as many relevant published documents as possible, broader search strings were initially identified, i.e., Web of Science: TS = (economics OR economy) AND TS = \u201cdeep learning\u201d, and search span is set from 2006 to 2021 (because the concept of deep learning coming into people\u2019s sight was in 2006 when DBN was proposed). Then, till Dec. 31th, 2021, 548 articles matched the constraints. Scopus: (TITLE-ABS-KEY (economics) OR TITLE-ABS-KEY (economy) AND TITLE-ABS-KEY (\u201cdeep learning\u201d)) AND PUBYEAR > 2005 AND PUBYEAR < 2022. Then, till Dec. 31th, 2021, 1,384 articles matched the constraints. DBLP: searching from \u201ceconomy, deep learning\u201d OR \u201ceconomics, deep learning\u201d, 6 articles matched the constraints. After combining all articles searched from different databases and removing duplicates, 1,468 articles are retained for further consideration. To ensure that final search results are as accurate as possible, a total of 1,414 articles are collected after purely peer-reviewed academic journal articles finally. These articles are ranked according to the published time and analyzed from the number of articles by year.\nAs shown in Fig. 1, the earliest three relevant articles published in 2014, after the concept of deep learning emerged (Hinton and Salakhutdinov, 2006). From 2014 to 2015, only some researchers paid attention to this topic. But starting from 2016, the number of articles kept increasing year by year, till 631 articles in 2021. Meanwhile, it is easy to see that more and more scholars have been devoted to the research field of deep learning and economics."
        },
        {
            "heading": "3 Frequently-used deep learning models in economics applications",
            "text": ""
        },
        {
            "heading": "3.1 Deep neural network (DNN) in economics",
            "text": "DNN is one of fundamental models of deep learning (Hinton et al., 2012) and it can be thought of as a neural network with many hidden layers. As we can see in Fig. 2, DNN is made of three types of network layer. The first layer is the input layer, the last layer is the output layer, and the layers in middle are both the hidden layers. Layers to layers are fully\n1 3\n9500\nDeep learning in economics: a systematic and critical review\nRBM a. Be a stochastic generated neural network that can learn probabilistic distribution from an input data set; b. Be the building block of DBN. a. Flexible and efficient computation; b. Easy to reason. a. Only suitable for working on binaryvalued data; b. Model is relatively simple so that expression ability is not good enough. Conditional RBM, Pointwise Gated RBM, Temporal RBM DBN a. Can be regarded as either a generation model or a discriminant model; b. Can be used for both unsupervised and supervised learning.\na. The generation model learns the joint probability density distribution, so it can represent the distribution of data from a statistical point of view and reflect the similarity of similar data; b. The generative model can restore the conditional probability distribution, which is equivalent to the discriminant model. a. The classification accuracy of the generative model is not as high as the discriminant model when it is used for classification problems; b. Because the generation model learns the joint distribution of data, the learning problem is more complex; c. The input data are required to be labeled for training. Convolution DBN\nCNN a. Effectively reduce the dimension of large data images to small data (without affecting the results); b. Can retain the characteristics of the picture, similar to the principle of human vision. a. The weight sharing strategy reduces the parameters that need to be trained, making the generalization ability of the trained model stronger; b. Pooling operation can reduce the spatial resolution of the network, so that the translation invariance of the input data is not required. Depth models are prone to gradient dissipation.\nGoogleNet, VGG, Deep Residual Learning\nRNN a. Long-term information can be effectively retained; b. Select important information to keep, and select \u201cforget\u201d for less important information. The model is a depth model in time dimension, which can model the sequence content. a. There are many parameters that need to be trained, which are prone to gradient dissipation or gradient explosion; b. Without feature learning ability. LSTM, GRU\n1 3\n9501\nY. Zheng et al.\nconnected and each layer performs specific effect of sorting and ordering in a process that some are called as \u201crepresentation hierarchy\u201d.\nAs one of the fundamental methods of deep learning, DNNs have been applied in various research fields of economics, e.g., financial economics, macroeconomics and mone-\nFig. 2 Architecture of DNN model\nFig. 1 The number of articles by year\nTransformer a. Self-attention mechanism; b. Focus on global information. a. Enables to model more long-distance dependencies; b. Parallel computing. a. High program complexity; b. Not Turing complete; c. Compute resource input average. Linear Transformer, Sparse Transformer, Reformer, Set Transformer, Transformer-XL DRL a. Combine deep learning with reinforcement learning; b. End-to-End training.\na. Learn control strategies directly from high-dimensional raw data; b. Large numbers of samples can be produced for supervised study. a. Difficult to achieve continuous motion control; b. Overestimation, that is, the estimated value function is larger than the true value function. QR-DQN, Rainbow DQN\n1 3\n9502\nDeep learning in economics: a systematic and critical review\ntary economics, urban, rural, regional, real estate, and transportation economics, industrial organization, etc. Some of applications are shown in Table 2. Not only single DNN model\n(Zhong & Enke, 2019)\nPredict the daily return direction of the SPDR S&P 500 ETF DNN, ANN\nSingle DNN or single ANN Significantly higher classification accuracy\n(Chatzis et al., 2018)\nForecast stock market crisis events\nMXNET DNN\nLOGIT, CART, RF, SVM, NN, XGBoost Higher discriminatory power and superior predictive accuracy\n(He et al., 2019) Forecast financial time series DNN, LSTM\nFive strategies Outperforms others in MAPE, RMSE, R2\n(Kremsner et al., 2020)\nCompute risk measure\nDNN Classical methods in references Can solve problems with high dimension\n(Alaminos et al., 2019)\nPredict currency crisis event DNN, DNDT\nLOGIT, MLP, SVM, AdaBoost Higher levels of accuracy\n(Galeshchuk & Mukherjee, 2017) Predict exchange rate DNN, LSTM\nShallow neural network\nSignificantly higher predictive accuracy\n(Lukman et al., 2020)\nPredict the amount of salvage and waste materials DNN The component based neural network model Higher and more steady prediction accuracy\n(Bazan-Krzywoszanska & Bereta, 2018) Forecast real estate value DNN Linear regression Perform better in test data according to prediction criteria MAE, MRE (Ding et al., 2019) Estimate socioeconomic status\nS2S models containing DNN and LSTM Random Guess, STL, GBDT Outperform other models in precision, recall, and F1-score\n(Yuan & Lee, 2020) Forecast intelligent sales volume DNN, grey analysis, LSSVR GA-ANN, GALSSVR, and PSO- LSSVR\nSuperior performance in Google Index\n(Feng et al., 2018) Recognize pattern and make classification\nDNN Traditional auction Better performance when the number of SUs exceeds a certain value\n(Frey et al., 2019) Predict for investment decisions DNN, Gradient Boosting, RF GLM Higher prediction accuracy (Tan et al., 2020) Estimate poverty Deep ResNet, FPN\nLinear regression model with night-time light data, linear regression model with both night-time light data and spectral index data Outperform other models with the Pearson correlation coefficient\nNote: ANN (Artificial Neural Network), LOGIT (Logistic Regression), MXNET (Deep Learning Techniques), CART (Classification and Regression Trees), RF (Random Forest), SVM (Support Vector Machine), NN (Neural Network), XGBoost (Extreme Gradient Boosting), DNDT (Deep Neural Decision Tree), MLP (Multilayer Perceptron), LSTM (Long Short-Term Memory), RMSE (Root Mean Square Error), STL (Standard Template Library), GBDT (Gradient Boosting Decision Tree), LSSVR (LeastSquare Support Vector Regression), GA (Genetic Algorithm), PSO (Particle Swarm Optimization), GLM (Generalized Linear Models), FPN (Feature Pyramid Network), ResNet (Residual neural Network)\n1 3\n9503\nY. Zheng et al.\n(Bazan-Krzywoszanska & Bereta, 2018; Feng et al., 2018; Kremsner et al., 2020; Lukman et al., 2020), but also hybrid models (Chatzis et al., 2018; Ding et al., 2019; Frey et al. 2019; Galeshchuk & Mukherjee, 2017; He et al., 2019; Tan et al., 2020; Yuan & Lee, 2020; Zhong & Enke, 2019), often achieve higher classification or prediction accuracy than other benchmark methods."
        },
        {
            "heading": "3.2 Restricted Boltzmann Machine (RBM) in economics",
            "text": "Inspired by energy function of statistical physics, RBM is a randomly generated neural network that can learn probability distributions from input data sets (Le Roux & Bengio, 2008). As a special topology structure of Boltzmann Machine (BM), RBM has two layers: a visible layer and a hidden layer. Unlike convolutional BM (Krefl et al., 2020), there are connections between all units of different layers while there is no connection between units in the same layer in RBM. The architecture of RBM is exhibited in Fig. 3. Because of the advantages of strong representation and easy reasoning, RBM is successfully applied to recommendation system (Chen et al., 2020), image segmentation (Li & Wang, 2020), natural language processing (Tsutsui & Hagiwara, 2019), etc.\nRBM model can better maintain the intrinsic characteristics of the original data because the error of feature reconstruction is lower in the process of feature learning (Mittelman et al., 2014). These intrinsic characteristics enable RBM to learn more reconfigurable features and build a wonderful prediction model. In the field of economics, RBM has been applied in several subfields, like macroeconomics and monetary economics (Galeshchuk, 2017), urban, rural, regional, real estate, and transportation economics (Rafiei & Adeli, 2016), agricultural and natural resource economics (Li et al., 2017; Pei et al., 2020), etc. Please refer to Table 3 for more details. The approaches have also been proven effectively in economic predictions and performed better than the compared method."
        },
        {
            "heading": "3.3 Deep Belief Network (DBN) in economics",
            "text": "DBN is a kind of probabilistic generation model (Hinton et al., 2006), which is used for statistical modeling and representing abstract features or statistical distributions of things. As is shown in Fig. 4, DBN\u2019 s graph structure is composed of multiple nodes. There is no\n1 3\n9504\nDeep learning in economics: a systematic and critical review\ninternal connection between nodes of the same layer, and there are full connections between nodes of two adjacent layers. The lowest layer of the network is the observable variable, and all nodes of other layers are the hidden variables.\nDBN has been utilized for solar power forecasting (Gensler et al., 2016), short-term load forecasting of integrated energy (Huan et al., 2020), and very short-term bus load forecasting (Shi et al., 2019). It is also helpful for fault signal recognition in power distribution sys-\nArticle Aim of study\nSpecific approach\nBenchmark methods for comparison\nSuperiority of the proposed method\n(Galeshchuk, 2017) Predict exchange rate\nRBM, AE Multilayer perceptron, Autoregressive integrated moving average model, Random walk model Higher accuracy\n(Rafiei & Adeli, 2016) Estimate the sale prices of real estate units Deep RBM, nonmating genetic algorithm Standard genetic search, best first, linear forward selection, and correlationbased feature subset The superiority of the new method is substantiated in accuracy of classifier (Pei et al., 2020)\nForecast vehicle velocity\nRBM, bidirectional LSTM RBF-NN, BPNN, EV, 5MC, RBF-WT Performs better in RMSE\n(Li et al., 2017) Time series forecasting RBM, BSASA\nBP, Elman, RBMBP, BSABP, DEBP Superior capability in preventing the search result from falling into the minimum\nTable 3 RBM in economics\nNote: BSASA (Backtracking Search Algorithm with Simulated Annealing), BP (Back Propagation), RBFNN (Radial Basis Function Neural Network), BP-NN (Back Propagation Neural Network), EV (Exponentially Varying prediction method), 5MC (5-stageMarkov chain prediction method), WT (a novel velocity predicted method based on Wavelet Transform), RBMBP (Restricted Boltzmann Machine Back Propagation), BSABP (Backtracking Search Algorithm Back Propagation), DEBP (Differential Evolution Back Propagation)\n1 3\n9505\ntem (Rao et al., 2020) and power plant control (Cui et al., 2020) (For detailed information, please see Table 4). When compared with other machine learning algorithms or benchmark methods, DBN performs better and gets more accurate results. As researchers have found that DBN has excellent nonlinear fitting ability to fit the moving point trajectory and provide prediction of the trajectory (Shi et al., 2019). DBN also can extract abstract high-level features and analyze the correlation of multiple features, so that it can learn better features and improve the forecasting accuracy (Huan et al., 2020). Moreover, DBN is regarded as one of advanced artificial intelligence techniques in the construction of robust methods of computer vision applied to precision agriculture from the results of the systematic review (Patricio & Rieder, 2018)."
        },
        {
            "heading": "3.4 Convolutional neural network (CNN) in economics",
            "text": "Convolutional neural network (CNN) is one of the representative algorithms in deep learning, composed of three types of layers: convolution layer, pooling layer and fully connected layer (Goodfellow et al., 2016; Gu et al., 2018) (Inquire Fig. 5 for its architecture). Compared with other neural network structures, CNN requires relatively few parameters, which enable it to be widely used and obtain higher computation efficiency (Fujita & Cimr, 2019).\nArticle Aim of study\nSpecific approach\nBenchmark methods for comparison Superiority of the proposed method\n(Gensler et al., 2016) Forecast the energy output of solar power plants DBN, AE, LSTM Multilayer perceptrons, physical models Superior forecasting performance (Cui et al., 2020)\nPredictive control for ultrasupercritical power plant DBN, Economic model predictive control Subspace model identification Performs better in terms of economic performance and tracking performance\n(Rao et al., 2020) Detect and classify the fault signal in power distribution system DBN SVM, quadratic SVM, RBF SVM, polynomial SVM, MLP SVM, LMNN, GD-NN Effectively detects and classifies the fault signal (Huan et al., 2020)\nForecast short-term load of integrated energy systems DBN, BP, multitask regression layer SVR, ARIMA, BPNN\nLearns better features and improves the forecasting accuracy\n(Shi et al., 2019) Forecast very shortterm bus load Phase space reconstruction, DBN PSR-NN, DBN, ARIMA, NN, LSTM, PSRDBN (no tuning) Higher prediction accuracy and better adaptability\nNote: LM-NN (LevenbergMarquardt Neural Network), GD-NN (Gradient Descent Neural Network), BPNN (Back Propagation Neural Network), SVR (Support Vector Regression), ARIMA (Autoregressive Integrated Moving Average Model,), PSR-NN (Phase Space Reconstruction Neural Network), PSR-DBN (Phase Space Reconstruction Deep Belief Network)\n1 3\nDeep learning in economics: a systematic and critical review\nDeveloped by LeCun and his team, CNN has successfully solved the handwriting digit classification problem (Lecun et al., 1998), so that it comes into the sights of computer vision researchers rapidly (Abdalla et al., 2019; Kheradpisheh et al., 2018; Selim et al., 2016; Zhang et al., 2020b). In other fields, CNN has been generally applied to natural language processing (Gu et al., 2018), recommendation systems (Zhang & Yang, 2019), remote sensing science (Zhang et al., 2018), etc., which also obtains excellent achievements.\nCNN has been widely applied to solve problems in macroeconomics and monetary economics (Chen et al., 2019; Galeshchuk and Demazeau, 2017; Yasir et al., 2019; Yu et al., 2020a), industrial organization (Adebowale et al., 2020; Guo, 2020; Ullah et al., 2019; Wang & Zeng, 2020), financial economics (Liu et al., 2020; Liu et al., 2018), agricultural and natural resource economics (Conte et al., 2019; Gadekallu et al., 2020), urban, rural, regional, real estate (Ajami et al., 2019; Yao et al., 2018), business administration and business economics (Lan et al., 2018), health, education, and welfare (Yeh et al., 2020). Shown in Table 5, cooperated with other machine learning approaches or deep learning algorithms, CNN and its variants usually perform better or improve the estimation and classification accuracy than baseline methods. Among other deep learning models, CNN is great for financial forecasting and economic assessment because of two main causes: Firstly, noise filters and dimensionality reduction approaches help to select crafted input features (Yasir et al., 2019); Secondly, information mining through visual images provides unique and complementary perspective for higher economic prediction performance (Galeshchuk & Demazeau, 2017)."
        },
        {
            "heading": "3.5 Recurrent neural network (RNN) in economics",
            "text": "Proposed from the idea that the cognition of people towards all things is coming from memory and experience, Recurrent neural network (RNN) is a class of recursive neural networks that takes sequence data as input (Goodfellow et al., 2016). Distinguished from other neural networks, RNN not only considers the input of previous moment, but also endows the network a \u201cmemory\u201d function to handle the situation that the decision of current state is dependent on previous state. Starting from Jordan network in 1986 (Jordan, 1986) and Elman network in 1990 (Elman, 1990), RNN has occupied an important position in deep learning algorithms and been successfully applied to natural language processing, like speech recognition (Wang, 2020), language modeling (Noaman et al., 2018) and machine translation (Mahata et al., 2019), and also been used in various time series forecasting (Waheeb & Ghazali, 2020), music recommendation (Kim et al., 2019), commodity recommendation\n1 3\n9507\nY. Zheng et al.\n(Yasir et al., 2019) Forecast foreign exchange rate CNN Linear regression, SVR Perform better than other methods in prediction accuracy (Chen et al., 2019)\nForecast interaction of exchange rates CNN, fixedlength binary Strings, a binary component A random selection rule method, a trend rule method\nHigher prediction performance\n(Galeshchuk & Demazeau, 2017) Predict exchange rates CNN RW, ARIMA, Shallow neural networks\nOutperform the baseline methods in prediction\n(Yu et al., 2020a)\nEstimate economy CNN Luminosity product Improve the estimation accuracy\n(Guo, 2020) Encode image features and select the image features of commodities CNN, attention mechanism\nAnalyze different impact of different situations with the assistance of CNN Successfully extract the most important image feature corresponding to the decoding time\n(Ullah et al., 2019) Detect cyber security threats\nCNN, DNN GIST-SVM, LBP-SVM, CLGM-SVM\nOutperform when measuring the cybersecurity threats\n(Wang & Zeng, 2020) Select typical economic indicators CNN Deep confidence network, Multilayer trestle automatic coder Improve the classification accuracy and adaptability (Adebowale et al., 2020) Detect intelligent phishing\nCNN, LSTM Single CNN, single LSTM Higher classifier prediction performance and less training time\n(Liu et al., 2020)\nForecast stock price\nCNN, GBoost WSAEs-LSTM More accurate prediction\n(Liu et al., 2018)\nPredict stock price movement from financial news TransE Model, CNN, LSTM T-SVM, J-SVM, C-SVM, C-LSTM, J-LSTM Predict better\n(Conte et al., 2019) Estimate catfish density\nCNN, Aerial images ainalysis - -\n(Gadekallu et al., 2020) Classify tomato plant diseases\nCNN, Whale optimization algorithm DNN without Dimensionality Reduction, DNN with Dimensionality Reduction using PCA Higher accuracy and low rate, lesser time for training and testing of the data\n(Ajami et al., 2019) Predict data-driven index of multiple deprivation CNN Principal component regression model combining hand-crafted and GIS features, ensemble model Outperform than others in terms of R2, RMSE, BIAS (Yao et al., 2018)\nMap fine-scale urban housing prices\nUMCNN and RF CNN (HSR), PCA-CNN (HSR), SD, CNN (HSR & SD), PCA-CNN (HSR & SD), CNN (HSR) & SD, PCA-CNN (HSR) & SD, CNN (SD), CNN (HSR) & CNN (SD) The highest housing price simulation accuracy\n1 3\n9508\nDeep learning in economics: a systematic and critical review\n(Chen et al., 2021), etc. The architecture of RNN and its unfolded framework through time is shown in Fig. 6.\nThen, Hochreiter and Schmidhuber (1997) proposed a RNN variant called Long ShortTerm Memory (LSTM), which can tackle issues mentioned by Bengio et al. (1994) and learn long-term dependency relations. Its structure is exhibited in Fig. 7, composed of special units: blocks and gates.\nRNN can still be seen in industrial organization, macroeconomics and monetary economics, agricultural and natural resource economics, financial economics. Collaborated with other machine learning algorithms such as logistic regression, encoder-decoder and attention\n(Lan et al., 2018)\nExtract features of trademark images CNN, Constraint theory LBP, SIFT, HOG, CNNoriginal, CNN-LBP, CNN-Siamese\nBest comprehensive retrieval ability\n(Yeh et al., 2020)\nPredict asset wealth\nDeep CNN Simpler KNN, scalar NL Meets or exceeds published performance\nNote: RW (Random walk without a drift), GIST (Generalized Search Tree),T-SVM (Tf-idf algorithm feature extraction and SVM prediction model), J-SVM (Joint learning feature extraction and SVM prediction model), C-SVM (CNN feature extraction and SVM prediction model), C-LSTM (CNN feature extraction and LSTM prediction model), J-LSTM (Joint learning and LSTM prediction model), PCA (Principle Component Analysis), GIS (Geographic Information System), UMCNN (Convolutional Neural Network for United Mining), HSR (High Spatial Resolution), PCA (Principal Component Analysis), SD (Spatial Data), LBP (Local Binary Pattern), SIFT (Scale Invariant Feature Transform), HOG (Histogram of Oriented Gradients), KNN (K-Nearest Neighbor), NL (Nighlights)\n1 3\n9509\nY. Zheng et al.\nmechanism, RNN and its variants (Alsmadi et al., 2020; Andrijasa, 2019; Becerra-Vicario et al., 2020; Mishev et al., 2020; Zhang et al., 2020a) show superiority in prediction or evaluation than the compared methods, e.g., SVM, neural network. As one of typical deep learning models, RNN is believed to be more suitable to simulate the sequence dynamical data and capture contextual information than regular feedforward neural networks (Alsmadi et al., 2020; Anbazhagan & Kumarappan, 2013). More importantly, for timeseries like electricity price or exchange rate, they present high periodicity patterns and multiple time steps prediction, so that RNN is acted as an ideal option. (Andrijasa, 2019; Zhang et al., 2020a). As a variant of RNN, the essence of LSTM is to introduce the concept of cellular state. Unlike RNN which only considers the most recent state, the cellular state of LSTM determines which states should be left behind and which states should be forgotten. Hence, LSTM plays an important role in many fields of economic research. In comparison with other benchmark methods, the authors design some measurement indicators and the results show that the proposed methods combining LSTM present high reliability and good capability of forecasting, estimating and detection. Table 6 exhibits some typical applications of RNN in economics."
        },
        {
            "heading": "3.6 Autoencoder (AE) in economics",
            "text": "Proposed by LeCun (1987), AE is a kind of artificial neural network used in semi-supervised learning or unsupervised learning, for representation learning of input information by taking input information as learning target (Bengio et al., 2013; Goodfellow et al., 2016). As shown in Fig. 8, AE is built by encoder and decoder, which is helpful for dimensionality reduction of data (Chen et al., 2018), feature extraction (Meng et al., 2017) and anomaly detection (Han et al., 2020). It also has some variants like undercomplete autoencoder (Buongiorno et al., 2019), regularized autoencoder (Hong et al., 2020) and variational autoencoder (Che et al., 2020).\nIn the economic field, AE is usually employed to automatically learn features from the high dimensional data (Long et al., 2020; Ranjan et al., 2021) and for self-adaptive feature reduction (Li et al., 2020). In order to force AE to learn useful information, noises are often added to the input data (Vincent et al., 2008), and then the network is trained to express the original data without noise. Meanwhile, sparse penalty is added to the encoding layer so that the active neurons of encoding layer are limited and the original data can be replaced with discovery features (Li et al., 2020; Xu et al., 2016). In addition, the merit of AE is the interpretability of the model (Suimon et al., 2020), which is largely superior to most of deep learning models in tackling with economic issues. Shown in Table 7, compared with some prediction technologies and other deep learning models, AE also performs well and gets more accurate prediction results, requiring less trainable parameters and training time."
        },
        {
            "heading": "3.7 Transformer in economics",
            "text": "Transformer model proposed by Google in 2017 is a well-known architecture for deep learning, which performs well on a variety of natural language processing tasks (He et al., 2021). Transformer is based on the self-attention mechanism dispensing with recurrence and convolutions entirely (Vaswani et al., 2017). Moreover, Transformer is composed of two parts, including encoder and decoder (Fan et al., 2022). Encoder codes the input and decoder decodes the encoded information, and finally get the decoded output, its structure is shown\n1 3\n9510\nDeep learning in economics: a systematic and critical review\n(BecerraVicario et al., 2020) Predict bankruptcy\nDRCNN, LOGIT Single DRCNN, single LOGIT, neural network Predict well\n(Ebrahimi et al., 2020) Identify semisupervised cyber threat Transductive SVMs, LSTM\nk-NN, LOGI, RF, SVM, CNN, LSTM, Transductive SVM\nState-of-the-art classification performance\n(Agarwal et al., 2021) Detect Fraudulent resource consumption attack LSTM DTC, RFC, LR, SVM, KNN, ANN Perform best in effectively and accurately detecting FRC attacks (Arkhangelski et al., 2020) Evaluate the economic benefits LSTM MILP, fuzzy logic, or another linear optimization technique More prediction accuracy (Haytamy & Omara, 2020)\nPredict the Cloud QoS provisioned values\nLSTM, PSO MQPM Outperforms the existing MQPM model in terms of RMSE\n(Andrijasa, 2019) Predict exchange currency rates Encoder-decoder RNN - - (Tang et al., 2020)\nForecast economic recession through Share Price LSTM MA, KNN, ARIMA, Prophet LSTM outperforms the other models in prediction\n(Zhang et al., 2020a) Forecast dayahead electricity price DRNN Single SVM, hybrid SVM network\nOutperform in terms of simulating the relationships between external factors and the electricity price\n(Zhang et al., 2019) Promote the accuracy of wind prediction LSTM, multi-objective PSO Grey Model Numeric results demonstrate that LSTM is superior to the traditional grey model in terms of prediction accuracy, robustness, and computational efficiency (Zhou et al., 2019) Forecast electricity price\nLSTM, SMBO SVR, BPNN, GTB, DTR, LSTM series models include shallow LSTM, stacked LSTM, EEMD-LSTM and EEMD-LSTM-SMBO Much better than that of the general LSTM model and traditional models in accuracy and stability\n(AbdelNasser & Mahmoud, 2019) Forecast photovoltaic power LSTM-RNN MLR, BRT, and neural networks Further reduction in the forecasting error (Guo et al., 2018) Forecast shortterm power load Integrating several LSTM networks LSTM, ARIMA, SVR, MLP Improve the forecasting performance\n1 3\n9511\nY. Zheng et al.\n(Mishev et al., 2020) Analyze sentiment in finance RNN, RNN-Attention, CNN, Dense Network SVC, XGB, Dense, CNN, RNN\nBetter performance in several criteria\n(Ji et al., 2021)\nForecast stock indices IPSO and LSTM Support-vector regression, LSTM and PSO-LSTM High reliability and good forecasting capability\n(Jin et al., 2020) Predict stock closing price\nLSTM, sentiment analysis, attention mechanism, empirical modal decomposition LS_RF, S_LSTM, The LSTM model that considers the S_AM_LSTM The highest accuracy, the lowest time offset and the closest predictive value when predicting the stock market\n(Nikou et al., 2019) Predict stock price\nLSTM ANN, RF, SVM Better in prediction of the close price of iShares MSCI United Kingdom than the other methods\n(Niu et al., 2020) Predict stock price index\nVMD-LSTM PNN, ELM, CNN, and LSTM, and the hybrid models EMD-BPNN, EMD-ELM, EMDCNN, EMD-LSTM, VMD-BPNN, VMDELM, and VMD-CNN The hybrid models perform significantly better than the single models\n(Sharaf et al., 2021) Predict stock price\nLSTM, CNN, Stacked-LSTM, and Bidirectional-LSTM\nSVM, Linear Regression, LOGIT, K-Neighbors, Decision Tree, RF Outperform the other models based on several evaluation metrics\n(Katayama et al., 2019) Identify sentiment polarity in financial news LSTM, Convolution model\nCommon polarity dictionary\nCaptures more news sentiment\n(Tao et al., 2020) Evaluate the impact of the Northridge Earthquake\nLSTM, NAR neural network\nSingle LSTM, single NAR Perform better based on some criteria\n(He, 2021) Predict investment benefits and national economic attributes EEMD-LSTM BP model, EEMD-BP model, LSTM model, and ARMA Highest prediction accuracy (Wu et al., 2018)\nEstimate remaining useful life of complex engineered systems Vanilla LSTM RNN, GRU Significance of performance improvement\n1 3\n9512\nDeep learning in economics: a systematic and critical review\nin Fig. 9. Besides natural language processing, it has also been successfully applied to image classification, object detection, and segmentation tasks (Bazi et al., 2021; Yu et al., 2020b). It has some variants like Vision Transformer (ViT) (Fisichella and Garolla, 2021), Data efficient image Transformers (DeiT) (Touvron et al., 2020), Convolutional vision Transformer (CvT) (Wu et al., 2021), and Swin-Transformer (Liu et al., 2021).\nIn the field of economy, Transformer takes advantage of performing well on a variety of natural language processing tasks by treating a sentence as a sequence of words and proposing a self-attentive layer structure (Liao et al., 2021). In addition, Bidirectional Encoder Representation from Transformer (BERT) (Devlin et al., 2018) is used to pre-train deep bidirectional representation (Wang & Li, 2022; Yue et al., 2020), and ViT applied directly to sequences of image patches can perform very well on image classification tasks (Fisichella & Garolla, 2021). Therefore, compared with some prediction technologies and conventional\n(Sehovac & Grolinger, 2020) Forecast electrical load S2S RNN Vanilla RNN, LSTM, and GRU Outperform other models (Li et al., 2021) Predict the price of gold VMD-ICSS-BiGRU SVR, LR, ANN, LSTM\nConsistently reduce the forecasting error and improve the fitting performance effectively\nNote: RCNN (Recurrent Convolutional Neural Network), Bi-LSTM (Bidirectional-LSTM), DRCNN (Deep Recurrent Convolutional Neural Network), DRNN (Deep Recurrent Neural Network), SVC (Support Vector Classifier), XGB (Extreme Gradient Boosting), IPSO (Improved Particle Swarm Optimization), LS_RF (Random Rorest estimates using LSboost), S_LSTM (The LSTM model considering the sentiment index), S_AM_LSTM (The LSTM model that considers the sentiment index and attention mechanism), EMD (Empirical Modal Decomposition), NAR (Nonlinear Autoregressive), DTC (Decision Tree Classifier), RFC (Random Forest Classifier), MINLP (Mixed-Integer Nonlinear Programming), MQPM (Multivariate Quality of service Prediction Model), SMBO (Sequence Model-Based Optimization), GTB (Gradient Boosting Regressor), DTR (Decision tree regressor), EEMD (Ensemble Empirical Mode Decomposition), MLR (Multiple Linear Regression), BRT (Bagged Regression Trees), MA (Moving Average), ARMA (Autoregressive Moving Average), S2S RNN (Sequence to Sequence Recurrent Neural Network), ICSS (Iterated Cumulative Sums of Squares), BiGRU (Bidirectional Gated Recurrent Unit), GRU (Gated Recurrent Unit), LR (Linear Regression)\n1 3\n9513\ndeep learning methods, Transformer performs well on higher accuracy in prediction, more efficient and robust training process, and less accumulation of errors (Shown in Table 8)."
        },
        {
            "heading": "3.8 Deep reinforcement learning (DRL) in economics",
            "text": "DRL is a brand new technique that combines deep learning with reinforcement learning to realize end-to-end learning from perception to action. Although so many people had the same idea, the publication \u201cPlaying Atari with Deep Reinforcement Learning\u201d brought DRL into researcher\u2019s vision (Mnih et al., 2013). Then, DeepMind improved DQN, Hinton, Bengio and Lecun took DRL as one of important development directions of deep learning in the future (LeCun et al., 2015). It is used to describe and solve problems in which agents adopt learning strategy to maximize the return or realize some specific targets in the process of interacting with environment. The architecture of DRL is constructed in Fig. 10.\nArticle Aim of study Specific approach Benchmark methods for comparison\nSuperiority of the proposed method\n(Wang et al., 2020a) Forecast long-term time series in industrial production SSAEN, SAEGN BPNN, DLSTM, GrCbased long-term prediction model Significantly improve the long-term time series prediction accuracy (Long et al., 2020)\nLearn features and recognize fault of Delta 3-D printers SAE, ESN\nESN, SAESoftmax, DBN-ESN\nBest forecasting performance\n(Heaton et al., 2017) Predict and classify financial market Stacked auto-encoders, DL - - (Li et al., 2020a) Detect feedwater heater performance\nSDSAE PCA(T2), PCA(SPE), GA-ELM, PCA-BPNN\nAchieves the best performance according to detection threshold, computation accuracy, Accnormal, Accfault\n(Suimon et al., 2020) Represent the Japanese yield curve AE LSTM, VAR Effective, and interpretable (Ranjan et al., 2021)\nAnalyze and predict large-scale road network congestion Convolutional AE ConvLSTM, PredNet\nMore accurate prediction result, less trainable parameter and training time\nNote: SSAEN (Stacked Sparse Auto-Encoders Network), SAEGN (Sparse Auto-Encoder Granulation Network), DLSTM (Deep Long ShortTerm Memory), SAE (Sparse Autoencoder), ESN (Echo State Network), SDSAE (Sacked Denoising Sparse Autoencoder), SPE (Squared Prediction Error), GA-ELM (Genetic Algorithm based Extreme Learning Machine), VAR (Vector Autoregression), ConvLSTM (Convolution Long Short-Term memory), PredNet (Prediction Network)\n1 3\nDeep learning in economics: a systematic and critical review\nDRL is widely applied in economics to help people make intelligent and reliable decisions (Table 9). Comprehensive review (Mosavi et al., 2020) has discussed the development of DRL methods and applications in economics. For example, in the field of financial economics, Chakole and Kurhekar (2020) proposed an algorithm using deep Q-learning techniques to make trading decisions. In terms of agricultural and natural resource economics, a state-of-the-art proximal policy optimization (PPO) algorithm was adopted to derive alternating current optimal power flow solutions with operational constraints (Zhou et al., 2020b), and a novel DRL method combining deep deterministic policy gradient (DDPG) principles with a prioritized experience replay (PER) strategy was developed to solve the examined electric vehicle pricing problem (Qiu et al., 2020). From the aspect of macroeconomics and monetary economics, health, education, and welfare, deep neural model of DRL, DQN and DDPG are used to recommend cryptocurrency trading points (Sattarov et al., 2020) and learn optimal policy for COVID-19 prevention (Uddin et al., 2020). Furthermore, some comparisons between DRL and other conventional methods present the best performance of the proposed DRL. That is because DRL can not only statistically forecast the change trend direction, but also capture the discrete nature of environmental state, so that it greatly assists human in making rapid and effective decisions.\n1 3\n9515"
        },
        {
            "heading": "4 Applications of deep learning in economics",
            "text": ""
        },
        {
            "heading": "4.1 Financial economics",
            "text": "Financial economics covers studies about issues related to various sub-fields: general financial markets dealing with securities (stocks, bonds, and commodity and other futures), financial institutions and services, and corporate finance and governance (\u201cJel classification system,\u201c). From Table 10, we know that the selected data come from relevant database, websites or references, and time span of data is usually several years. In this field, various deep learning models like AE, RNN, CNN, DNN, LSTM, DRL and their variants, have been utilized to predict and classify financial market, forecast stock price, evaluate and analyze supply chain financial credit level, etc. In particular, many scholars are interested in exploiting different deep learning models to make effective and accurate predictions for stock market (Chatzis et al., 2018; Katayama et al., 2019; Nikou et al., 2019; Sharaf et al., 2021; Tao et al., 2020; Zhong & Enke, 2019). But for different aims or facing different types\nArticle Aim of study\nSpecific approach\nBenchmark methods for comparison\nSuperiority of the proposed method\n(Wang & Li, 2022) Detect renewable energy incidents from news articles containing accidents in various renewable energy systems PTM word2vec, BERT, TCNN, TRNN BERT-TCNNs BERT-TRNNs word2vecTCNNs word2vec-TRNNs TCNNs, TRNNs Effective and robust in detecting renewable energy incidents from largescale textual materials (Liao et al., 2021)\nPredict multistepahead location marginal price Transformer, with seq2seq architecture LSTM, BiLSTM, GRU, Bi-GRU, and TCN Avoid the error accumulation of the results, higher accuracy\n(Yue et al., 2020) Predict accurate energy and classify simultaneous status BERT GRU, LSTM, CNN More stable and precise, higher prediction consistency (Fisichella & Garolla, 2021)\nDevelop a complete trading system with a combination of trading rules on Forex time series data ViT ResNet50 Fewer computational resources to train\nNote: PTM (Pre-Trained Model), BERT (Bidirectional Encoder Representation from Transformer), TRNN (Text Recursive Neural Network), TCNN (Text Convolution Neural Network), seq2seq (sequence to sequence), GRU (Gated Recurrent Unit), BiGRU (Bi-directional Gated Recurrent Unit), TCN (Train Communication Network), Vision Transformer (ViT).\n1 3\nDeep learning in economics: a systematic and critical review\nof data, deep learning models play a variety of roles in the field of financial economics. For example, if we consider the effect of time or long-term information, RNN or LSTM models are popular to forecast the stock price; if image information is involved during the estimation process, CNN may be an ideal option; if we need to make trading decisions or decide the change trend, DRL and its variants stand out."
        },
        {
            "heading": "4.2 Macroeconomics and monetary economics",
            "text": "Macroeconomics and monetary economics mainly include researches about the aggregate performance of an economy: output, employment, prices, and interest rates and their determinants (\u201cJel classification system,\u201c). This field concentrates on the law of economic operation of an economic field with the help of national income, overall economic investment and consumption and other overall statistical concepts. It is easy to find that the data are mainly obtained from bank websites or government office, and most of long-term data, such as more than ten years, are taken into consideration. That is because macroeconomics and monetary economics issues need to be addressed by observing and exploring long-term data. As shown in Table 11, various deep learning models including DNN, LSTM, CNN, RNN, AE and RBM, are utilized to predict currency crisis event (Alaminos et al., 2019), forecast exchange rate (Andrijasa, 2019; Galeshchuk, 2017; Galeshchuk & Mukherjee, 2017; Yasir et al., 2019), or estimate economy condition (Tang et al., 2020; Yu et al., 2020a). Among these deep learning models, DNN seems to be one of the most popular models to handle forecasting problems with large amount of data, CNN is good at reducing dimensionality of high-dimensional data and fusing image information. Similarly, RNN and LSTM are both suitable to deal with short-term or long-term dependencies problems in macroeconomics and monetary economics.\n1 3\n9517"
        },
        {
            "heading": "4.3 Agricultural and natural resource economics",
            "text": "Agricultural and natural resource economics mainly discuss economic issues pertaining to two closely related fields: agriculture and natural resources (\u201cJel classification system,\u201c). Table 12 demonstrates some examples of applying deep learning for agricultural and natural resource economics. In terms of the features of problems and the selected data, CNN is used\nArticle Aim of study Specific approach\nBenchmark methods for comparison Superiority of the proposed method\n(Chakole & Kurhekar, 2020) Make trading decisions Deep Q-learning Decision Tree strategy, Buyand-Hold strategy Outperforms in terms of some economic indicators: Accumulated Return, Maximum Drawdown, Average daily return, average annual return, Skewness, Kurtosis, Sharpe ratio, and Standard Deviation (Zhou et al., 2020b)\nDerive optimal power flow DRL, PPO with IL IL, PPO Perform better in accuracy and running time\n(Qiu et al., 2020)\nPricing electric vehicles PDDPG Q-learning, DQN, DDPG Better performance in standard deviation, learning pace, flexibility and computational time\n(Sattarov et al., 2020) Recommend cryptocurrency trading points Deep Neural Model of DRL Double cross strategy, swing trading, scalping trading Best performance in number of actions and quality of Trading (Uddin et al., 2020)\nEstimate impact of COVID19 on the spread of the infection, personal satisfaction or quality of life, resource use and economy DQN, DDPG Random, Q-Learning, SARSA Perform better in terms of best rewards and best policy\nNote: IL (Imitation Learning), PDDPG (Prioritized Deep Deterministic Policy Gradient), DQN (Deep Q Network), DDPG (Deep Deterministic Policy Gradient), SARSA (StateAction-Reward-State-Action).\n1 3\nDeep learning in economics: a systematic and critical review\nApplication subfield Article Aim of study\nData set Date size Time span Used models\nFinancial market (Heaton et al., 2017) Predict and classify financial market Component stocks of the biotechnology IBB index\nWeekly returns data 2012\u2013 2016 Stacked AE\n(Mishev et al., 2020) Analyze sentiment in finance Financial Phrase-Bank dataset, SemEval-2017 task dataset 4,845 English sentences, 2,510 news headlines - RNN, RNN, Attention, CNN, Dense Network\nStock market\n(Zhong & Enke, 2019) Forecast daily stock return SPDR S&P 500 ETF (ticker symbol: SPY) 60 factors over 2,518 trading days 2003\u2013 2013 DNN, ANN (Chatzis et al., 2018) Forecast crisis events FRED and the SNL More than 5,000 records 1996\u2013 2017 MXNET, DNN (Nikou et al., 2019) Predict stock price iShares MSCI United Kingdom exchange 869 data 2015\u2013 2018 LSTM (Sharaf et al., 2021) Predict stock price Quandl dataset - 2000\u2013 2019 LSTM, CNN, Stacked-LSTM, Bi-LSTM (Tao et al., 2020)\nEvaluate the impact of the Northridge Earthquake http://finance.yahoo.com/ 616 listed companies 1992\u2013 1994 LSTM, NAR neural network\n(Katayama et al., 2019) Identify sentiment polarity in financial news Economy Watchers Survey 234,626 samples\n2000\u2013 2018 LSTM, Convolution model\n(Ji et al., 2021) Forecast stock indices Australian stock market index\n2,523 records\n2010\u2013 2020 LSTM-IPSO\n(Jin et al., 2020) Predict stock closing price Stock of Apple from (https:// stocktwits.com/) 96,903 comments 2013\u2013 2018 LSTM, sentiment analysis, attention mechanism, empirical modal decomposition (Liu et al., 2020) Forecast stock price CSMAR and WIND - 2008\u2013 2016 CNN, Gboost (Xu et al., 2016)\nSelect feature and forecast price Apple, S&P 500 in Yahoo Finance\n6,423 financial news headlines 2011\u2013 2017 TransE Model, CNN, LSTM\n(Niu et al., 2020) Predict stock price index HIS, SPX, FTSE and IXIC - 2010\u2013 2019 VMD-LSTM\nTable 10 Applications of deep learning for financial economics\n1 3\n9519\nY. Zheng et al.\nto find useful learning model from numerous images for catfish density estimation (Conte et al., 2019) and tomato plant diseases classification (Gadekallu et al., 2020), DNN is utilized to help complex investment decisions (Frey et al., 2019), RNN and LSTM is suitable for forecasting short-term power load or energy price (Abdel-Nasser & Mahmoud, 2019; Guo et al., 2018; Zhang et al., 2020a; Zhang et al., 2019; Zhou et al., 2019), DRL can derive optimal power flow (Zhou et al., 2020b) and decide the price of electric vehicles (Qiu et al., 2020). Unlike above two applications, the time period of the invested data covers different lengths. Some of them are as long as thirteen years, while others are as short as two months. And the data are selected from various channels, dataset repository, electricity market, relevant website or references, etc."
        },
        {
            "heading": "4.4 Industrial organization",
            "text": "There are many subcategories in industrial organization that are closely related to those in microeconomics. The studies of industry include two types: manufacturing and services (\u201cJel classification system,\u201c). As shown in Table 13, in the aspect of manufacturing, Phitthayanon and Rungreunganun (2019) used deep learning technique to predict jewelry production material cost for jewelry production, Wang et al. (2020a) adopted a deep granular network with adaptive unequal-length granulation strategy to forecast long term time series for industrial enterprises, Wang and Zeng (2020) utilized multilayer CNN to select feature and estimate the influence of COVID-19 epidemic situation to sports industry. In terms of services, LSTM, CNN and their variants have been widely applied to solve problems in Internet services and restaurant industry, such as economic benefit evaluation (Arkhangelski et al., 2020), security threat detection (Adebowale et al., 2020; Ebrahimi et al., 2020; Guo, 2020; Ullah et al., 2019), reviews and bankruptcy prediction (Alsmadi et al., 2020; Becerra-\nApplication subfield Article Aim of study\nData set Date size Time span Used models\n(Sattarov et al., 2020) Recommend cryptocurrency trading points Bitcoin, Litecoin, and Ethereum\u2014hourly historical data from (https://www. cryptodatadownload.com) - 2019 DRL (Chakole & Kurhekar, 2020) Make trading decisions DJIA, NASDAQ, NIFTY and SENSEX index stocks - 2001\u2013 2018 Deep Q-learning\nInsurance mathematics (Kremsner et al., 2020) Compute risk measure Dataset coming from references\n- - DNN\nNote: IPSO (Improved Particle Swarm Optimization), VMD (Variational Mode Decomposition), S&P 500 (Standard & Poor\u2019s 500 index), FRED (Federal Reserve Economic Database), SNL (S&P Global Market Intelligence), CSMAR (China Stock Market & Accounting Research Database), HIS (Daily closing prices of the Hong Kong Hang Seng Index), SPX (S&P 500 Index), FTSE (London FTSE Index) and IXIC (Nasdaq Index), DJIA (Dow Jones Industrial Average), NASDAQ (National Association of Securities Dealers Automated Quotations)\nTable 10 (continued)\n1 3\n9520\nDeep learning in economics: a systematic and critical review\nApplication sub field Article Aim of study\nData set Data size Time span Models\nInternational monetary system (Alaminos et al., 2019) Predict currency crisis event IMF International Financial Statistics, World Bank Development Indicators, World Economic Outlook, and the World Bank Global Financial Database 7,708 observations 1970\u2013 2017 DNN, decision trees Circular economy\n(Lukman et al., 2020)\nPredict the amount of salvage and waste materials UK Demolition Industry 2,280 building demolition records - DNN\nCost efficient cardiac health monitoring (Faust et al., 2020) Machine classification: signal processing and make decisions https://www.polar.com/uk-en - - DL Economic condition\n(Tang et al., 2020)\nForecast economic recession through Share Price Yahoo Finance Six kinds of stock, and 1232 rows of data for each stock 2015\u2013 2019 LSTM\nCurrency exchange market (Andrijasa, 2019) Predict exchange currency rates Bank Indonesia official websites 4,344 daily data series\n2001\u2013 2018 Encoder-decoder RNN\n(Yasir et al., 2019) Forecast foreign exchange rate Daily data of exchange rate 1,304 observations 2008\u2013 2018 CNN (Galeshchuk, 2017) Predict exchange rate http://www.global-view.com/ forex-trading-tools/forex-history/ index.html\nEach time series contains 1,304 observations 2010\u2013 2014 RBM, AE\n(Galeshchuk & Demazeau, 2017) Forecast ungarian forint exchange rate https://www.bloomberg.com/ markets/currencies\n- 2000\u2013 2017 CNN\n(Galeshchuk & Mukherjee, 2017) Predict exchange rates http://www.globalview.com/ forex-trading-tools/forex-history/ - 2000\u2013 2015 DNN, LSTM\nMacroeconomics and Monetary Economics (Chen et al., 2019) Forecast interaction of exchange rates Poloniex, Kaggle, Dukascopy Bank\u2019s website\n- 2016\u2013 2017 CNN, fixedlength binary Strings, a binary component\nTable 11 Applications of deep learning for macroeconomics and monetary economics\n1 3\n9521\nY. Zheng et al.\nVicario et al., 2020). Meanwhile, we can see that the collected data are coming from a lot of ways: websites, industrial enterprises, references and database, which may be because of the wide coverage features of industrial organization."
        },
        {
            "heading": "4.5 Urban, rural, regional, real estate, and transportation economics",
            "text": "This subfield covers the research of urban, rural, and regional economics, real estate and transportation economics (\u201cJel classification system,\u201c). Shown in Table 14, some data of this subfield are collected from industrial office, and others come from company and websites. In order to identify a slum\u2019s degree and predict data-driven index of multiple deprivation, CNN was utilized to capture features from 1,114 very high-resolution images (Ajami et al., 2019). In the aspect of transportation economics, various deep learning techniques, like DNN, LSTM, deep capsule network or their variants, were applied to predict transportation demand or estimate socioeconomic status (Bazan-Krzywoszanska & Bereta, 2018; Ding et al., 2019; He, 2021; Markou et al., 2020). As for real state economics, DNN was used to forecast a real estate value (Yao et al., 2018) and CNN was used to map fine-scale urban housing prices through images (Rafiei & Adeli, 2016)."
        },
        {
            "heading": "4.6 Health, education, and welfare",
            "text": "Deep learning models have also been applied to address issues related to health, education, and welfare (Table 15). Deep residual neural networks was used to estimate poverty (Tan et al., 2020), deep CNN was applied to predict asset wealth (Yeh et al., 2020), and DRL was adopted to estimate the impact of COVID-19 on the spread of the infection, personal satisfaction or quality of life, resource use and economy (Uddin et al., 2020). We find that not only CNN, but also deep residual neural networks can handle image information. Meanwhile, DRL is still good at deciding the trend or impact."
        },
        {
            "heading": "4.7 Business administration and microeconomics",
            "text": "This part contains studies about business administration: production, personnel, and information technology management, new firms, corporate culture, and international business administration. Microeconomics is a branch of modern economics, mainly taking a single economic unit (a single producer, a single consumer, a single market economic activity) as a subject of analysis. As illustrated in Table 16, the method combining CNN with constraint\nApplication sub field Article Aim of study\nData set Data size Time span Models\nSocialeconomic (Yu et al., 2020a) Estimate economy\nImageNet data set, Landsat image dataset - 2009 CNN\nGovernment bonds\n(Suimon et al., 2020) Represent the Japanese yield curve Several weekly Japanese Government Bond rates with varying maturities - 1992\u2013 2019 AE\nNote: IMF (International Monetary Fund)\nTable 11 (continued)\n1 3\n9522\nDeep learning in economics: a systematic and critical review\nApplication sub field Article Aim of study\nData set Data size Time span Model\nFood economic chain (Conte et al., 2019) Estimate catfish density Aerial Images 300 images - CNN, Aerial Images Analysis\n(Gadekallu et al., 2020) Classify tomato plant diseases Plant-village dataset repository - - DNN, Whale optimization algorithm\nEnergy market (Frey et al., 2019) Predict for Investment decisions Energymap.info 1.4 million solar installations - DNN, gradient boosting, random forests\n(Huang & Wu, 2018) Forecast price 5 crude oil spot prices (WTI, Brent, Forties, Dubai, and Oman), 2 financial prices (the gold prices and the U.S. exchange rate) 435 daily observations 2009\u2013 2010 DMKL, directed deep acyclic graph (Zhang et al., 2020a)\nForecast day-ahead electricity price The New England electricity market, ISO launches Standard Market\n- - DRNN\n(Zhang et al., 2019) Promote the accuracy of wind prediction Wind power from Hongfeng Eco-town\n- 2009\u2013 2017 LSTM, multi-objective particle swarm optimization\n(Zhou et al., 2019) Forecast electricity price The electricity price of the Pennsylvania-New Jersey-Maryland power market - 2018 LSTM, SMBO (AbdelNasser & Mahmoud, 2019) Forecast photovoltaic power Two photovoltaic datasets for locations in Aswan (Dataset1) and Cairo (Dataset2) cities, Egypt - 1 year LSTM-RNN (Guo et al. 2018)\nForecast short-term power load https://www.torontohydro.com, http://climate.weather.gc.ca/ indexe.html - 2002\u2013 2016 Integrating several LSTM networks\n(Zhou et al., 2020b) Derive optimal power flow\nData come from references 17,364 in data set I and 2,000 in data set II on the IEEE 14- bus system. 20,000 in data set I and 5,000 in data set II on the Illinois 200- bus system - DRL\nTable 12 Applications of deep learning for agricultural and natural resource economics\n1 3\n9523\nY. Zheng et al.\ntheory was adopted to extract features of trademark images for commodity economy (Lan et al., 2018), DNN was used to assess risk for overseas investment of enterprises (Xu, 2020) and recognize pattern and make classification for multi-slot spectrum auction (Feng et al., 2018), LSTM was adopted to investigate and learn useful sentiment information from large amount of consumer review records (Luo et al., 2021)."
        },
        {
            "heading": "5 Critical review of deep learning in economics",
            "text": ""
        },
        {
            "heading": "5.1 Critical reviews on deep learning models and applications in economics",
            "text": "Because of the excellent feature learning capability in constructing model, deep learning presents great application values in economic research. The model containing deep learning can not only handle a great amount of data in experiment, but also create an effective way to solve problems of economics. There are some comments about deep learning models and applications in economics:\n1) Critical reviews of deep learning models are in terms of two points: basic models and hybrid techniques. On the one hand, different basic deep learning models play different roles in economic field. DNN, AE and RBM are the general models to construct the learning architecture because of the highly efficient computation ability when dealing with large amount of and high dimensional data. When long-term or short-term action affects the current state, or the economic problem is dynamic over time, RNN, Transformer and their variants are the most suitable options to describe the situation and construct the learning model. CNN and its variants have been widely applied to handle a large number of images in economic research, exchange rate forecast. On the other hand, hybrid deep learning has cooperated with various technologies in handling problems in economics. For example, DRL is a good way to help people make decisions and evaluate economic condition. Decision tree is one of classic decision-making methods, collaborated with DNN, they successfully predicted the currency crisis event (Alaminos et al., 2019). With the assist of attention mechanism, CNN was developed to successfully extract the most important image feature (Guo, 2020). Cooperated with logistic regression, RNN obtained better bankruptcy prediction results than single model (Becerra-Vicario et al., 2020). The combination of LSTM and sentiment analysis developed stock closing price prediction (Jin et al., 2020). Furthermore, deep learning models were successfully cooperated with other optimization technologies, e.g., improved particle swarm optimization (Ji et al., 2021), whale optimization algorithm (Gadekallu et al., 2020), multi-objective particle swarm optimization (Zhang et al., 2019),\nApplication sub field Article Aim of study\nData set Data size Time span Model\nElectric vehicles (Pei et al., 2020) Forecast vehicle velocity Open Street Map - - DBM, bidirectional LSTM\n(Qiu et al., 2020) Pricing electric vehicles Data come from the reference - - DRL\nNote: DMKL (Deep Multiple Kernel Learning), DBM (Deep restricted Boltzmann Machines)\nTable 12 (continued)\n1 3\n9524\nDeep learning in economics: a systematic and critical review\nJewelry Production\n(Phitthayanon & Rungreunganun, 2019) Predict material cost XAUUSD and XAGUSD at London Fixed market. The gold and silver price data were collected and archived by usagold.com. The diamond price data were obtained from the reference - 2000\u2013 2018 NAR model, NARX\nIndustry enterprise\n(Wang et al., 2020a)\nForecast longterm time series in industrial production the Mackey\u2013Glass time-series, the Rossler time series data, the flow of passenger on the Paris metro line 3 and 13, as well as two practical industrial datasets - - SSAEN model, SAEGN model\nSports industry (Wang & Zeng, 2020) Select typical economic indicators Standard economic parameter database and Yale industrial economic database - - Multilayer CNN Mart-community microgrid\n(Arkhangelski et al., 2020) Evaluate the economic benefits\nA real conventional rural grid in France - - LSTM\nIoT (Internet of Things) (Ullah et al., 2019) Detect cyber security threats GCJ - - Deep CNN Online attacks (Adebowale et al., 2020) Detect intelligent phishing A data set containing 1 m URLs - - CNNLSTM E-commerce (Guo, 2020)\nEncode image features and select the image features of commodities MSCOCO-2015 data set\nwith about 160,000 product images for training, and about 80,000 product images for test and verification - CNN, attention mechanism\n(Alsmadi et al., 2020) Predict helpful reviews 2014 version of the Amazon reviews dataset around 83.7 million unique reviews\n1996\u2013 2014 RCNN\nDark net marketplaces\n(Ebrahimi et al., 2020) Identify semisupervised cyber threat https://github. com/mohammadrezaebrahimi/ JMIS-DarkNetMarketData 79k product listings - Transductive SVMLSTM\nCloud services and security (Haytamy & Omara, 2020) Predict the Cloud QoS provisioned values\nData come from references: TimeSynth open source library and Cloud providers\u2019 dataset - 6 months LSTMPSO\n1 3\n9525\nY. Zheng et al.\nsequence model-based optimization (Zhou et al., 2019). To sum up, basic and hybrid deep learning models accelerate the development of economic research. In the future, it is possible to use various types of deep learning models to conduct a better performance in the field of economics, and novel combinations of deep learning models and other technologies are used to tackle economic issues, such as combining deep learning with social network systems to forecast the state of economic development, or developing deep learning in multiagent system for better economic evaluation and intelligent decision-making.\n2) Critical discussions of applications in economics are unfolded from three aspects: application fields, application effects and data resources. At first, deep learning models have been widely used in various subfields of economics, up to the national economics, monetary system, financial market, stock market, down to the clothing, food, housing and transportation, which shows the generalization of deep learning models. In the future, deep learning models and their variants will be extended to other fields of economics according to the JEL classification codes guide, e.g., international economics, public economics, labor and demographic economics, economic development, innovation, technological change, and growth, law and economics, and other special topics. Extending deep learning models to supply chain finance could be interesting and gives more inspiration to scholars of economics and algorithm engineer. Secondly, deep learning models have been developed for different effects in economics, like prediction, classification, decision-making, evaluation and so on. In terms of prediction, stock price is usually the applied scene and various deep learning models have been adopted for prediction, such as DNN, LSTM, RNN, AE, etc. Fortunately, the forecast accuracy of deep learning models is frequently superior to other algorithms. As for classification, deep learning models have also been applied to image classification and text classification. Meanwhile, other deep learning models assist to make some decisions. For example, DRL helps to price electric vehicles (Qiu et al., 2020), recommend cryptocurrency trading points (Sattarov et al., 2020), and derive optimal power flow (Zhou et al., 2020b). Despite the above mentioned effects, deep learning models can be used not only in natural language processing (Khatter & Ahlawat, 2020), but also in automatic control (Zhu et al., 2020), so they can bring more and more effects and make differences in economics. Thirdly, the data of applications often come from websites, datasets, companies, references related to the research topic. To be specific, commonly used datasets of economic research are Financial Phrase-Bank dataset, World Bank Global Financial Database, ImageNet data set. Similarly, commonly used websites of economic research are Google Code Jam, Amazon reviews dataset, Yahoo financial dataset. The collection of data takes a long time, and some of them even more than ten/twenty years. The data cover an extensive range\nRestaurant industry\n(BecerraVicario et al., 2020) Predict bankruptcy\nSABI database 460 solvent and bankrupt companies 2008\u2013 2017 DRCNN, LOGIT\nNote: NARX (Nonlinear Autoregressive neural network with exogenous variables), XAUUSD (Gold Spot US Dollar), XAGUSD (Silver Spot US Dollar), GCJ (Google Code Jam)\n1 3\n9526\nDeep learning in economics: a systematic and critical review\nof areas, like bank, stock market, industrial, transportation, etc. Furthermore, the data could be obtained from some international or national competitions."
        },
        {
            "heading": "5.2 Critical reviews on why and how to implement deep learning in economics",
            "text": "Deep learning plays an important role in economics. Critical comments regarding to why and how to implement deep learning models in economics are necessary, and this will be\nSlums\u2019 degree of deprivation (Ajami et al., 2019) Predict datadriven index of multiple deprivation 1114 households living in 37 notified slums 1,114 households living 2010 CNN Transportation system (He, 2021)\nPredict investment benefits and national economic attributes Railway transportation industry from the National Bureau of Statistics - 2013\u2013 2019 EEMDLSTM\n(Ding et al., 2019) Estimate socioeconomic status Smart card: the dataset contains all the subway records in Shanghai; POI dataset of Shanghai is crawled based on GaoDe Map API Service2; Housing price dataset is crawled from Lianjia.com 3 website - 2015 S2S models containing DNN and LSTM (Markou et al., 2020) Time series forecasting of taxi demand Taxi data are available by the NYC TLC.\naround 600 million taxi trips after data filtering 2013\u2013 2016 A neural network architecture based on FC dense layers and a Deep Gaussian Processes architecture\nReal estate market (BazanKrzywoszanska & Bereta, 2018) Forecast real estate value the city center of Zielona Gora\n163 sale and purchase transactions 2016\u2013 2017 DNN\n(Yao et al., 2018) Map fine-scale urban housing prices Fang.com, Tianditu.cn, several basic geographic and social media datasets - - UMCNN, RF (Rafiei & Adeli, 2016) Estimate the sale prices of real estate units\nTehran, Iran 360 residential condominiums (3\u20139 stories) 1993\u2013 2008 Deep RBM, nonmating genetic algorithm\nNote: EEMD (Ensemble Empirical Mode Decomposition), FC (Fully-Connected), UMCNN (Convolutional Neural Network for United Mining), NYC TLC (New York City Taxi and Limousine Commission)\n1 3\n9527\nY. Zheng et al.\nPoverty (Tan et al., 2020) Estimate poverty Landsat 8 images, spectral index data (NDVI, MNDWI, and NDBI), nighttime light data, and statistical yearbook data 39,145 satellite images 2014\u2013 2017 Deep residual neural networks, feature pyramid networks ttTEconomic well-being\n(Yeh et al., 2020) Predict asset wealth Nationally representative DHS more than 500,000 households living in 19,669 villages across 23 countries in Africa 2009\u2013 2016 Deep CNN\nPolicy learning\n(Uddin et al., 2020) Estimate impact of COVID-19 on the spread of the infection, personal satisfaction or quality of life, resource use and economy Simulation data 100 episodes - DRL\nNote: DHS (Demographic and Health Surveys)\nCommodity economy\n(Lan et al., 2018) Extract features of trademark images Self-built trademark training database 1,141 trademarks - CNN, Constraint Theory\nOverseas investment of enterprises (Xu, 2020)\nAssess risk Countries and regions that have continuity in the Fraser risk assessment learning label the selected training samples include a total of 124 research samples containing 4,284 feature values; the selected test samples include a total of 41 research samples containing 1,426 feature values. 2018\u2013 2019 DNN\nAuction market\n(Feng et al., 2018) Recognize pattern and make classification Simulation data - - DNN\nHotel management (Luo et al., 2021) Investigate the sentiment of hotel guests eLong.com 363,723 reviews 2018 Bidirectional LSTM, conditional random field\n1 3\n9528\nDeep learning in economics: a systematic and critical review\nuseful for economists who are unfamiliar with deep learning but want to use it in their research.\n1) Deep learning models usually perform better than traditional machine learning models. It can deal with a large amount of high dimensional data and mine the potential information and rules in the data. In terms of prediction, deep learning models are frequently superior to other algorithms, such as support vector machine, logistic regression, multilayer perceptron, etc., from the aspects of forecast accuracy, recall, robustness, and computational efficiency. As for classification, deep learning improves not only classification accuracy but also adaptability, because it constructs mechanism of visual perception in imitating organisms and possesses representation learning ability. Superior to conventional reinforcement learning, DRL has multiple learning layers to obtain stability and reliability during training, and get better performance. Meanwhile, deep learning models have successfully promoted the development of mathematical and quantitative methods, which play important roles in economics (Rakesh et al., 2018; Wang et al., 2020b; Wang & Li, 2020).\n2) Combined with other models, deep learning variants solve more practical problems in economics. Deep Q-learning have been investigated that this model is better suited for technology stocks (Chakole & Kurhekar, 2020). The developed deep learning model can be further used to modify the inconsistent statistics during the social and economic development period (Yu et al., 2020a). Galeshchuk (2017) noticed that they wished their research effort would lead to significant improvement of the prediction accuracy in the short-andmedium term exchange rates, so that some updated versions of prediction methods can introduce a new generation of computational trading tools and change the market environment. Moreover, some researchers find that granular computing can improve deep learning model with a more efficient and transparent structure and better representation capabilities (Colace et al., 2019; Pedrycz et al., 2019). Meanwhile, granular computing can handle the interpretability and reasonability of \u201cblack box\u201d model (Pal et al., 2020). Therefore, granular computing can also solve the same problem in economics.\n3) Several requirements should be concerned if deep learning is implemented in economics. On the one hand, the samples need to be accessible and the number of samples need to be large enough. Deep learning can form sufficiently complex functions for automatically extracting and fitting features, and one of conditions is that there are as much sample data as possible. In other words, deep learning has strong expression ability based on accessible and large-scale data. On the other hand, there is a need for discrimination or classification tasks in the process of economics research. That is because deep learning is essentially learning the inherent patterns and hierarchical representation of samples, so as to execute feature extraction and classification."
        },
        {
            "heading": "5.3 Critical reviews on research gap and future challenges",
            "text": "Deep learning, although it is a powerful and useful technique to establish prediction model, it is often criticized as \u201cblack box\u201d due to the difficulty to explain the solved weight coefficient and the internal mechanism of the constructed learning model. It often faces some criticisms that the computation efficiency and the result accuracy are both limited if training data are not enough or algorithm is too much complex, and if poor-quality data or unsuitable parameters tuning lead to biased and unsatisfied prediction results (please see (Groumpos, 2019; Krittanawong et al., 2019) for more criticisms regarding deep learning). In order to\n1 3\n9529\nY. Zheng et al.\ndevelop deep learning in economics, some challenges and future works are provided for further research:\n1) Improve the interpretability of deep learning models in economics. Interpretability is divided into two classifications: global and local interpretability, which are detailed discussed in (Du et al., 2020) and (Guidotti et al., 2019). Global interpretability aims to understand the structure and parameters of a model from the perspective of entity. However, it requires the interpretation model to be faithful to all samples of the black box model, which is impractical (Ribeiro et al., 2016). In contrast, local interpretability only explains why individual predictions are made. The lack of local interpretability in deep learning research in economics needs more concerns, because it is important to clearly explain the reasons such as why stock price goes up or down. When applying deep learning in economics, some scholars have found that traditional machine learning performs better than deep learning in some cases. Freitas et al. (2020) discovered that decision tree performs better than DNN when predicting school dropout in IoT system. While others found some insufficiency of this topic. For example, the LSTM model needs a lot of resources and time to train, which can be a barrier for real-world applications (Ji et al., 2021). On the other hand, it is wellknown that there are plenty of external factors that impact stock volatility, so that more sophisticated models that involve external factors will bring severer challenges. (Ji et al., 2021). Because of inexplicability, DNN and most of deep learning models cannot clearly interpret the theoretical and practical principles of models in economic applications such as financial market (Zhong & Enke, 2019). Similarly, just a few of research works published on behavioral finance adopt deep learning models. This may because it is full of difficulties that quantify the inputs and outputs of behavioral finance research within deep learning models (Ozbayoglu et al., 2020). Fortunately, some scholars have concerned some models or algorithms to interpret the black boxes by implementing model agnostic local interpretation methods (Du et al., 2020; Guidotti et al., 2019; Ribeiro et al., 2016).\n2) Construct novel deep learning models to deal with uncertain or vague information in economics. Uncertain or vague information is quite common in economics so that one of research fields is fuzzy economics (Deng et al., 2019; Tian et al., 2019; Zhou et al., 2020a). As an emerging research direction, fuzzy economics aims to make quantitative analysis of the uncertain factors in economic relation and economic activities based on fuzzy set or fuzzy mathematics (Chang, 1976). Meanwhile, the combination of linguistic variables and economics assists to collect much natural linguistic information and reveal some undiscovered laws of economic motion (Zadeh, 1975). Deep learning can assist to acquire precise learning model from big amount of data, but previous researches about deep learning in economics leave fuzzy information out of consideration. A state-of-the-art survey about fusing deep learning and fuzzy systems (Zheng et al., 2021) have comprehensively and profoundly analyzed the fusion effect of fuzzy technology and deep learning, so it is also a good idea to combine fuzzy systems with deep learning in economics to deal with uncertain or vague information.\n3) Improve the ability of deep learning to handle data issues. There are many private data in the economic field, which should be protected and kept secret. So that it is one of challenges related to data issues in deep learning applied in economics. As far as we know, Federated learning based on deep learning (Federated Machine Learning for Loan Risk Prediction) can not only protect privacy but also ensure the decent performance. The other challenge about data issues is that the data scale is not large enough, or there are not enough\n1 3\n9530\nDeep learning in economics: a systematic and critical review\nlabeled samples or high-quality samples, so it is not suitable to use classical deep learning models. Few-shot learning (learning from limited samples) becomes an important, fundamental and unsolved problem that machine learning community extensively concerns. selfsupervised learning without labels (Wei et al., 2021), multitask learning (Zhang & Yang, 2018), embedding learning (Hou et al., 2014), learning with external memory (Graves et al., 2016) and transfer learning (Zhuang et al., 2021) has more potential to tackle various tasks."
        },
        {
            "heading": "6 Conclusion",
            "text": "This paper makes a comprehensive and critical review of deep learning in economics. Firstly, the research database has been explained and some statistical results have been described. Then, a survey of popular deep learning models in economics has been detailed investigated and several applications of deep learning in economics have been classified according to JEL. Finally, some critical reviews of deep learning in economics are provided, including models and applications, why and how to implement deep learning in economics, research gap and future challenges, respectively. In what follows, we are ready to give answers to our initially stated research questions.\n1) Which deep learning models are preferred (and more successful) in economics? What are the characteristics of different deep learning algorithms in the economic field?\nResponse: DNN, RBM, DBN, CNN, RNN, AE, Transformer, DRL and their variants have been widely applied in economics. Among these, DNN, AE and RBM are the general model to construct the learning architecture due to the highly efficient computation ability. RNN, Transformer and their variants are the most suitable options to handle economic problems affected by long-term or short-term. CNN and its variants have been widely applied to control a large number of images in economic research. DRL is used to make decisions or evaluate economic condition.\n2) What economic application areas are of interest to deep learning community? What are the differences when we execute deep learning models against traditional soft computing/machine learning techniques?\nResponse: Deep learning has been widely applied in financial economics, macroeconomics and monetary economics, agricultural and natural resource economics, industrial organization, urban, rural, regional, real estate and transportation economics, health, education and welfare, business administration and microeconomics. Compared to benchmark methods, deep learning models usually bring more accurate prediction results, better classification performance and stronger model or parameter learning capability.\n3) What are the drawbacks of the current application of deep learning in economics?\nResponse: Sometimes, traditional soft computing or machine learning techniques perform better than certain deep learning models in some situations. Deep learning modes also need a lot of resources and time to train, which can be a barrier for real-world applications. More\n1 3\n9531\nY. Zheng et al.\nimportantly, most of deep learning models cannot clearly interpret the theoretical and practical principles of models in economic applications, and some data issues should be taken seriously.\n4) What are the future directions of researches about deep learning in economics?\nResponse: (i) Improve the interpretability of deep learning models in economics. (ii) Exploit different variants of deep learning models and apply them to solve more practical problems in economics. (iii) Develop the ability of deep learning models in economics to deal with uncertain or vague information. (iv) Improve the ability of deep learning to handle data issues.\nWe believe that with the development of deep learning, decision-making in economics will become more intelligent, and some deeper and widely researches of deep learning in economics will be an important topic for years to come.\nAcknowledgements The work was supported by the National Natural Science Foundation of China (No. 72071135, 72271173)."
        }
    ],
    "title": "Deep learning in economics: a systematic and critical review",
    "year": 2023
}