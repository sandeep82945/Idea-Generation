The low-cost Inertial Measurement Unit (IMU) can provide orientation information and is widely used in our daily life. However, IMUs with bad calibration will provide inaccurate angular velocity and lead to rapid drift of integral orientation in a short time. In this paper, we present the Calib-Net which can achieve the accurate calibration of low-cost IMU via a simple deep convolutional neural network. Following a carefully designed mathematical calibration model, Calib-Net can output compensation components for gyroscope measurements dynamically. Dilation convolution is adopted in Calib-Net for spatiotemporal feature extraction of IMU measurements. We evaluate our proposed system on public datasets quantitively and qualitatively. The experimental results demonstrate that our Calib-Net achieves better calibration performance than other methods, what is more, and the estimated orientation with our Calib-Net is even comparable with the results from visual inertial odometry (VIO) systems. 2 related work In the late 1990s, Nebot and Durrant-Whyte (1999) presented an inertial error model for gyros and accelerometers aiming at the IMU calibration for vehicle applications. Tedaldi et al. (2014) proposed an IMU calibration method without using external equipments, they need to move the IMU device by hand and place it in multiple static positions. Based on a specific sensor error model, Rohac et al. (2015) performed the low-cost inertial sensor calibration to obtain the model parameters using the nonlinear optimization under static conditions. Furgale et al. (2013) present the open-source Kalibr toolbox for the spatial and temporal calibration of multiple sensors (cameras/IMUs). Afterward, Rehder et al. (2016) extended the Kalibr toolbox and enabled precise IMU intrinsic calibration following an inertial noise model. They Rehder and Siegwart (2017) then further improved the calibration method by introducing the displacement of individual accelerometer axes into the mathematical noise
model. Barrau and Bonnabel (2020) recently adopted Lie group for IMU error propagation. These calibration methods usually adopt different inertial model variants and estimate the parameters of these sensor error models. For the calibration methods above, the parameters (scale factors, misalignment errors, offsets, etc.) are usually taken as constant values. Nevertheless, these parameters are always varying as time goes on and the environment changes. Aiming at the visual-inertial navigation system, Qin and Shen (2018) presented an online calibration method to optimize model parameters dynamically, and proposed VINS-mono system (Qin et al., 2018) which is one of the state-of-the-art visual-inertial systems. Yang et al. (2020) studied and discussed the necessity and importance of online IMU intrinsic calibration for visual-inertial navigation systems, and proved that online calibration is helpful for improving fusion performance. They also demonstrated an open-source visual-inertial odometry system called OpenVINS (Geneva et al., 2020). Campos et al. took the IMU measurement uncertainty into account (Campos et al., 2020), and proposed to use maximum a posteriori (MAP) estimation during IMU initialization in the ORB-SLAM3 system (Campos et al., 2021). Most of these methods rely on a mathematical model and need to calibrate every device before use. As to the usage of deep learning in IMU calibration and propagation, Yan et al. (2018) proposed to use the machine learning technology to regress velocity vector with linear accelerations and angular velocities as inputs. Nobre and Heckman (2019) proposed to model the IMU calibration as a Markov Decision Process (MDP) and use reinforcement learning to achieve the regression of calibration parameters. Clark et al. (2017) presented VINet which takes the visual-inertial odometry problem as a sequence-to-sequence learning problem to solve and avoids manual camera/IMU calibration operation. Chen et al. (2018) introduced IONet for inertial odometry using the recurrent neural network. Ionet formulates the odometry as an optimization problem based on the neural network and estimates the trajectories with raw measurements as network input. Afterward, they Chen et al. (2019a) further extended the network and also used it to predict model uncertainty. However, the above learning methods usually adopt neural networks with large weights which will consume lots of computation resources. Esfahani et al. (2019b) presented a recurrent neural network called OriNet for orientation estimation. 3D orientation can be obtained by OriNet with only low-cost IMUmeasurements as the network input. They Esfahani et al. (2019a) also proposed AbolDeepIO which simulates the noise model during training and achieves robust inertial odometry with a novel deep neural network. Instead of using recurrent neural networks, Brossard et al. (2020b) adopted a convolutional neural network to estimate the orientation with an IMU device. They Brossard et al. (2020a) further achieved accurate and robust dead-reckoning with only a commercial IMU. The Kalman filter is introduced and a deep neural network is utilized to predict the dynamic parameters of the filter. Frontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725832 3 methods  3.1 mathematical model for low-cost imu calibration  3.2 architecture overview The overview of our proposed framework is shown in Figure 1. Calib-Net takes sequential gyroscope measurements and acceleration measurements as the input, and outputs the compensation for raw IMU measurements. Dilation convolution is utilized for spatio-temporal feature extraction instead of recurrent neural networks. By designing a mathematical calibration model, the measurements can be dynamically calibrated and corrected with the network output. In this way, accurate orientation can be directly obtained through simple integration. Based on only hundred seconds of labeled data, the hyperparameters of the Calib-Net and the constant model parameters (matrix includes) can be optimized at the same time driven by a carefully designed loss function. For a typical low-cost Inertial Measurement Unit (IMU), it usually consists of a three-axis gyroscope, a three-axis accelerometer, and sometimes a magnetometer. The three-axis gyroscope can provide angular velocity information, the threeaxis accelerometer can provide the linear acceleration information. Considering the noise and bias of the sensor measurements (Rehder et al., 2016), the IMU sensor model can be represented as below:
ω̂t ât [ ] C ωt at [ ] + bωt bat [ ] + nωt nat [ ] (1) Where angular velocity ωt ∈ R3 and linear acceleration at ∈ R3 are the measurements of gyroscope and accelerometer, bωt ∈ R 3 and bat ∈ R 3 are the gyroscope and accelerometer bias, nωt ∈ R 3 and nat ∈ R
3 are additive zero-mean Gaussian noises for gyroscope and accelerometer, angular velocity
ω̂t ∈ R3 and linear acceleration ât ∈ R3 are the calibrated measurements which would be used for integration. The C is the intrinsic calibration matrix (approximate equals to I6) for the IMU model (Rehder et al., 2016), and can be modeled as:
C Cω C× 03×3 Ca [ ] (2) Where Cω contains scale factor and axis misalignment for gyroscope measurements, Ca contains scale factor and axis misalignment for accelerometer measurements, both Cω and Ca are approximately equal to identity matrix I3. C× is the coefficient matrix. It indicates the effect that the linear accelerometer has on the gyroscope, and is approximately equal to 03×3. So the gyroscope measurement (angular velocity) model can be represented as:
ω̂t Cωωt + C×at + bωt + nωt Cωωt + Δωt (3) In the formula above, we abbreviate the compensation component for gyroscope measurements as:
Δωt C×at + bωt + nωt (4) Where the compensation component Δωt is related to both gyroscope measurements and accelerometer measurements. By integrating the corrected angular velocity ω̂t, we can achieve the estimation of 3D rigid rotation follows the equation below:
Rt+ΔT RtExp ω̂tΔT( ) (5) Where Rt ∈ SO(3) and Rt+ΔT ∈ SO(3) are the rotation matrices. t is the timestamp that IMU outputs measurements, and ΔT is the minimal time interval between two consecutive IMU readings. In our case, the IMU runs at 200 Hz, and the ΔT is 5 ms. Exp (·) is the exponential map for SO(3). As indicated in the above formula, incorrect ω̂t will lead to continuous error accumulation as more integrations propagate. Frontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725833 3.3 calib-net for imu measurement correction As shown in Eq. 3 and Figure 1, Cω and Δωt play an important role in IMU calibration and orientation estimation. In most cases, Cω will be taken as a constant matrix, and Δωt is a small timevarying vector affected by many factors. In our proposed calibration system, we use the Caib-Net to estimate the compensation part Δωt for angular velocity measurements. The detailed structure of the Calib-Net is shown in Figure 2. It takes the long temporal sequential gyroscope measurements and accelerometer measurements as the network input, and network can be represented as below:
Δωt F ωt−kΔT, at−kΔT, . . . ,ωt, at( ) (6) Where k is the number of IMU readings used as the input of the proposed Calib-Net. F (·) represents the nonlinear function that the Calib-Net stands for. Dilation convolution is adopted to extract spatio-temporal features of IMU measurements. As shown in Figure 3, by introducing the dilation convolution, the historically temporal measurements are fed into the network and used for feature extraction. Dilation size in dilation convolution indicates the spacing between the convolution kernel points, so with different kernel sizes and dilation sizes, different temporal IMU readings will be taken
accordingly. To be specific, the length of the input depends on the product of kernel size and dilation size. In the presented network shown in Figure 2, the maximum product value is 448 which means the network will take k 448 IMU readings as the network input. The Calib-Net is composed of two dilation convolutional layers, one residual block, and two fully connected layers. The residual block includes two dilation convolutional layers and one shortcut. The detailed configuration of each layer is given in Figure 2. As to the matrixCω, we set it to the trainable variable. In this way, following the mathematical model shown in Figure 1, the parameters of Calib-Net and Δωt can be trained and optimized driven by the carefully designed loss function. 3.4 loss function for regression There are many losses that are widely used for solving the regression problem (Jadon, 2020). The losses include L1 Loss using Mean Square Error (MSE), L2 Loss using Mean Absolute Error (MAE), Huber Loss using Smooth Mean Absolute Error, etc. L1 Loss is robust to outliers. however, its gradient is always the same during the training and is still large even faced with small loss values. In this way, it is hard and inefficient for L1 Loss to find the minima at the end of training. On the contrary, L2 Loss is sensitive to outliers, but it is easier for L2 Loss to find a stable solution. Huber loss combines the advantages of L1 Loss and L2 Loss, it is more robust to outliers than L2 Loss and can decrease the gradient around the minima. In our proposed Calib-Net, we choose to use the log hyperbolic cosine (log-cosh) loss for gyroscope measurement correction regression. Compared with the Huber Loss, it approximately equals (y − y′)2/2 for the small loss and to |y − y′| − log(2) for the large loss, so it has all the advantages of Huber Loss and is twice differentiable for both small loss and large loss. The loss function is defined as below:
L y, y′( ) ∑n i 1 log cosh y − y′( )( ) (7)
FIGURE 3 | The illustration of 1D Dilation Convolution. Dilation size indicates the spacing between the convolution kernel points. Frontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725834
Where y is the label (ground truth) of orientation in our case, and y′ is the estimated orientation using the calibrated gyroscope value (namely angular velocity). We also use multi-scale orientation loss to achieve better calibration performance. The orientation is estimated through the integration of calibrated angular velocity. So we adopt
Frontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725835
different time intervals to compute the loss and perform the backpropagation driven by the loss. The loss used for network training is shown below:
L ∑n i 1 LΔt +∑ n/2 i 1 L2Δt +∑ n/4 i 1 L4Δt +/ + LnΔt (8)
Where n ·Δt is the maximum time interval used for computing the loss, and its value is n 2x. By carefully selecting different Δt and n using the trial and error method, we can adopt the suitable rotation transformation combination to train the calibration parameters. 4 experimental evaluation In this section, we evaluate the performance of our proposed Calib-Net using the public EuROC dataset Burri et al. (2016). Both quantitive and qualitative experiments are performed for comparison. We first compare the orientation estimation performance of our Calib-Net with different deep learning methods. Then we replace the gyroscope measurements used for the OpenVINS system with the calibrated angular velocity
from our Calib-Net, and compare the performance with state-ofthe-art VIO methods. For the training of our Calib-Net, most computers with a normally configured GPU are enough. In our case, we use a desktop equipped with an Intel i7-8700K CPU with 3.7-GHz and an Nvidia GeForce GTX 1060 GPU with 6 GB memory. The framework of Calib-Net is implemented based on PyTorch. We use the ADAM optimizer for the network training, the learning rate is set to 0.01, and the weight decay is 0.1. The consine anneal warm restart scheduler is adopted for network learning. The weight parameter for logcosh loss is 1e6. The IMU runs at 200 Hz, so the ΔT is 5 ms in our case. For loss computing, we set Δt to 80 ms and n to 2 (as illustrated in Eq. 8) which means we use 16 and 32 IMU readings for integration. We training the network for 1,200 epochs and it only takes about 8.5min with the Nvidia GTX 1060 GPU which can be reached easily. For the test procedure, our proposed lightweight Calib-Net can easily reach real-time performance for calibration and orientation estimation (the IMU reading is 200 Hz). 4.1 calibration performance evaluation among learning-based methods We first evaluate the proposed Calib-Net by comparing the orientation estimation performance with other learning-based methods. Absolute Orientation Error (AOE) is adopted as the evaluation metric. We choose the evaluation tool (Zhang and Scaramuzza, 2018) to compute the metric. Except for AOE, we also adopt the yaw error as the metric as achieving the accurate yaw angle estimation is most difficult for IMU. The public EuROC dataset (Burri et al., 2016) is used for the evaluation, and the uncalibrated ADIS16448 IMU is adopted in the dataset. We take MH_01_easy, MH_03_medium, MH_05_difficult, V1_02_medium, V2_01_easy, V2_03_difficult as the training sequences, and take MH_02_easy, MH_04_difficult, V1_01_easy, V1_03_difficult, V2_02_medium as the testing sequences. As shown in Table 1, our proposed Calib-Net outperforms the raw IMU data in terms of the orientation estimation and yaw
Frontiers in Robotics and AI | www.frontiersin.org January 2022 | Volume 8 | Article 7725836
estimation. When comparing with the state-of-the-art learningbased calibration methods, our framework defeats both OriNet (Esfahani et al., 2019b) and GyroNet (Brossard et al., 2020b) on most sequences. What is more, OriNet (Esfahani et al., 2019b) adopts the Long Short-Term Memory (LSTM) component for spatio-temporal feature extraction and needs larger GPU memory. Our framework adopts dilation convolutions and proper loss function which construct an easy (less hyperparameters) but efficient (better feature learning) neural network. We also plot the estimated orientation in Figure 4 to give a more compact demonstration of our system’s performance. The blue line indicates the ground truth of the orientation (roll, yaw, pitch), the red line indicates the estimated orientation with our Calib-Net, the green line indicates the estimated orientation with the GyroNet, and the yellow line indicates estimated orientation from the raw IMU data. All orientations here are got only through the integration of the angular velocity. As shown in the figure, when using the raw IMU data to perform orientation estimation, the errors will be accumulated and the integrated orientation will drift in a short time due to inaccurate calibration. Our Calib-Net (red line) is most close to the ground truth and achieves the best performance among these methods. 4.2 calibration performance evaluation Using VIO Methods In order to further prove the effectiveness of our proposed framework, we also introduce the calibrated angular velocity from our Calib-Net into a well-known VIO system (OpenVINS) which achieves state-of-the-art performance recently. The new VIO system combined with our Calib-Net is called OpenVINS*. We present the quantitative orientation estimation results in Table 2. As shown in the table, OpenVINS* performs better than OpenVINS in most cases, and achieves the best mean results in terms of orientation and yaw estimation.We also plot the trajectories with these methods in Figure 5. The OpenVINS* with carefully calibrated angular velocity achieves better performance in trajectory estimation. This proves that our proposed Calib-Net can accurately correct the angular velocity measurements and the calibrated angular velocity is fruitful for VIO systems. When comparing the estimated orientation of Calib-Net (shown in table I) with that of VIO methods (shown in table II), we can find that our Calib-Net can even compete with VIO methods in terms of orientation estimation. What is more, the average yaw error of our Calib-Net is 0.87°, and it performs better than all VIO methods which include Open-VINS* with 1.11°, Open-VINS with 1.37°, VINS-Mono with 2.14°. This further indicates that a carefully calibrated low-cost IMU can achieve similar (even better in some aspects) performance when comparing with visual-inertial methods. 5 conclusion and future work In this paper, we present a light-weight deep convolutional neural network for low-cost IMU calibration which is called Calib-Net. A mathematical calibration model is introduced to design the training and calibration framework. Dilation convolution is adopted for spatio-temporal feature extraction of IMU measurements. Driven by a carefully designed loss function, the Calib-Net can be optimized to output the compensation for raw gyroscope measurements. Corresponding experimental evaluations are performed to prove the effectiveness of our proposed Calib-Net. The results show that our framework achieves quite good calibration performance and the orientation estimation performance of our Calib-Net can even compete with state-of-the-art VIO methods.