{
    "abstractText": "We consider probabilistic systems with hidden state and unobservable transitions, an extension of Hidden Markov Models (HMMs) that in particular admits unobservable \u03b5-transitions (also called null transitions), allowing state changes of which the observer is unaware. Due to the presence of \u03b5-loops this additional feature complicates the theory and requires to carefully set up the corresponding probability space and random variables. In particular we present an algorithm for determining the most probable explanation given an observation (a generalization of the Viterbi algorithm for HMMs) and a method for parameter learning that adapts the probabilities of a given model based on an observation (a generalization of the Baum-Welch algorithm). The latter algorithm guarantees that the given observation has a higher (or equal) probability after adjustment of the parameters and its correctness can be derived directly from the so-called EM algorithm.",
    "authors": [
        {
            "affiliations": [],
            "name": "Rebecca Bernemann"
        },
        {
            "affiliations": [],
            "name": "Barbara K\u00f6nig"
        },
        {
            "affiliations": [],
            "name": "Matthias Schaffeld"
        },
        {
            "affiliations": [],
            "name": "Torben Weis"
        }
    ],
    "id": "SP:6a9a54638961b5496cebbb20c8f674b644f19302",
    "references": [
        {
            "authors": [
                "Dana Angluin"
            ],
            "title": "Learning regular sets from queries and counter-examples",
            "venue": "Information and Control,",
            "year": 1987
        },
        {
            "authors": [
                "Lalit R. Bahl",
                "Frederick Jelinek",
                "Robert L. Mercer"
            ],
            "title": "A maximum likelihood approach to continuous speech recognition",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,",
            "year": 1983
        },
        {
            "authors": [
                "Leonard E Baum",
                "Ted Petrie",
                "George Soules",
                "Norman Weiss"
            ],
            "title": "A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains",
            "venue": "The annals of mathematical statistics,",
            "year": 1970
        },
        {
            "authors": [
                "Jeff Bilmes"
            ],
            "title": "A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and Hidden Markov Models",
            "venue": "Technical Report TR-97-021,",
            "year": 1997
        },
        {
            "authors": [
                "A.P. Dempster",
                "N.M. Laird",
                "D.B. Rubin"
            ],
            "title": "Maximum likelihood from incomplete data via the EM algorithm",
            "venue": "J. Roy. Stat. Soc.,",
            "year": 1977
        },
        {
            "authors": [
                "Pierre Dupont",
                "Fran\u00e7ois Denis",
                "Yann Esposito"
            ],
            "title": "Links between probabilistic automata and Hidden Markov Models: probability distributions, learning models and induction algorithms",
            "venue": "Pattern Recognit.,",
            "year": 2005
        },
        {
            "authors": [
                "Charles Grinstead",
                "Laurie Snell"
            ],
            "title": "Markov chains. In Introduction to Probability, chapter 11, pages 405\u2013470",
            "venue": "American Mathematical Society, second edition,",
            "year": 1997
        },
        {
            "authors": [
                "Frederick Jelinek"
            ],
            "title": "Statistical methods for speech recognition",
            "venue": "MIT press,",
            "year": 1998
        },
        {
            "authors": [
                "G.D. Forney Jr."
            ],
            "title": "The Viterbi algorithm",
            "venue": "Proceedings of the IEEE,",
            "year": 1973
        },
        {
            "authors": [
                "John Orr",
                "Prasad Tadepalli",
                "Janardhan Doppa",
                "Xiaoli Fern",
                "Thomas Dietterich"
            ],
            "title": "Learning scripts as Hidden Markov Models",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2014
        },
        {
            "authors": [
                "Lawrence R. Rabiner"
            ],
            "title": "A tutorial on Hidden Markov Models and selected applications in speech recognition",
            "venue": "Proceedings of the IEEE,",
            "year": 1989
        },
        {
            "authors": [
                "A. Viterbi"
            ],
            "title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 1967
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n20 5.\n13 87\n1v 1\n[ cs\n.L G\n] 2\n7 M\nay 2"
        },
        {
            "heading": "1 Introduction",
            "text": "There are many practical applications that involve the observation of a probabilistic system with hidden state, where the aim is to infer properties about the state of the system only from the observations that are available.\nIn particular we are motivated by the following scenario: imagine a building equipped with sensors that are triggered when a person walks past. However, these sensors might produce both false positives (nobody walked past, but the sensor sends a signal) and false negatives (somebody was present, but did not trigger the sensor). This can be modelled by a probabilistic transition system which has both observable symbols and \u03b5-transitions (also referred to as null transitions), corresponding to false negatives. Now assume that there are three rooms, the bedroom (B), the corridor (C) and the kitchen (K), all of them connected through C and equipped with sensors. Sensors B, K trigger, but not C. However, in order to reach the kitchen from the bedroom, the person should have passed the corridor! Hence our analysis should tell us that the most likely explanation for the observation is indeed the sequence B, C, K.\nWhile here this reasoning is straightforward, it may become increasingly more complex with additional missing sensor data and multiple possible paths.\nIn order to make matters more concrete, consider the following system depicting our motivational example. The start state is s0 and from each state we\nlabel the transitions with symbols and probabilities. For instance, from s0 there is a probability of 0.1 of going to C with an unobservable \u03b5-transition.\nNow we detect the observation: b,k. What happened? In fact there are several possible paths, the most probable being s0, B, C, K (first transition b, second one \u03b5 and the third k) whose probability is\n\u03b4(s0)(b,B) \u00b7 \u03b4(B)(\u03b5,C) \u00b7 \u03b4(C)(k,K) = 0.4 \u00b7 0.3 \u00b7 0.5 = 0.06\nCB K\ns0\nc 0.7 \u03b5 0.3\nb 0.3 \u03b5 0.1\nk 0.5 \u03b5 0.1\nc 0.8 \u03b5 0.2\nb 0.4 \u03b5 0.05\nk 0.2 \u03b5 0.05c 0.2 \u03b5 0.1\nThe question is how to efficiently determine the most likely path and its probability.\nA second issue is how to learn the probabilities that label the transitions. Assume the basic structure of the system is known, in particular the number of states, but the parameters, i.e., the probabilities are not. Now we observe the system and want to estimate its parameters.\nOf course, such systems have been extensively studied under the name of Hidden Markov Models (HMMs) [11,13]. Unobservable transitions, also known as null transitions or \u03b5-transitions, i.e. HMMs that may change state without the observer being aware of it, have been proposed in the literature, especially in the context of speech recognition [2,8]. However, to the best of our knowledge, there is no theory of systems that allows for \u03b5-loops. Related work only treats specific HMMs, where either loops can not appear altogether (so-called leftto-right HMMs) [10] or \u03b5-loops are forbidden [3,2]. Also [8] does not allow \u03b5loops in the context of learning. It does describe an algorithm to eliminate \u03b5transitions, which can increase the size of the model and alters the system such that probabilities of \u03b5-transitions can not be learned directly.\nOn the other hand \u03b5-loops can occur naturally in applications, e.g., in the application described above that we have in mind, and there are no easy workarounds. We can only speculate why the generalization has not been made, but observe that for systems with \u03b5-loops the theory (in particular for parameter learning) is more complex since the Baum-Welch algorithm has to be fundamentally adapted to deal with this scenario. In particular the usual forward-backward algorithm [11] for parameter estimation can not be used directly, but has to be generalized.\nGiven an observation, we propose to compute the conditional expectation of passing each transition (remember that the state and so the transitions are hidden) and this is turned into a probability function (by normalizing), which is the new parameter estimate. The guarantee provided by this estimate is that the observation sequence becomes more probable given the new parameters. This result can be derived from the so-called expectation-maximization (EM) algorithm that gives us a general framework for such results.\nOur contributions are: \u22b2 We rephrase the theory behind HMMs with \u03b5-transitions, being precise about the used probability space and random variables. \u22b2 We extend the theory to systems with \u03b5-transitions, a very natural extension for such systems and indispensable for our application, which complicates the\nformalization and the algorithms. In particular, we have to handle \u03b5-loops which we deal with by setting up fixpoint equations. \u22b2 We spell out explicitly why parameter learning based on the EM algorithm works in this setting.\nWhile HMMs have been known for some time, we feel that, due to the current large interest in learning approaches (e.g., machine learning or the L* algorithm [1]), it makes sense to revive the theory and close existing gaps in the literature."
        },
        {
            "heading": "2 Preliminaries",
            "text": "Probability theory. We recapitulate the basics of discrete probability theory. A probability space (\u2126,P ) consists of a (countable) sample space \u2126 and a probability function P : \u2126 \u2192 [0, 1] such that \u2211\n\u03c9\u2208\u2126 P (\u03c9) = 1. Given a set \u2126 we denote by D(\u2126) the set of all probability functions on \u2126.\nA random variable for a probability space (\u2126,P ) is a function X : \u2126 \u2192 V . We assume a special random variable Z : \u2126 \u2192 \u2126, which is the identity. For v \u2208 V we denote by P (X = v) = \u2211 X(\u03c9)=v P (\u03c9) the probability that X has value v. Given two random variables Xi : \u2126 \u2192 Vi, i = 1, 2, the conditional probability that X1 takes value v1, under the condition that X2 takes value v2, is\nP (X1 = v1 | X2 = v2) = P (X1 = v1 \u2227X2 = v2)\nP (X2 = v2) ,\nprovided that P (X2 = v2) > 0. For a random variable X : \u2126 \u2192 R (where we might enrich the real numbers with \u2212\u221e), we define its expectation as E[X ] = \u2211\n\u03c9\u2208\u2126X(\u03c9)\u00b7P (\u03c9). Given another random variable Y : \u2126 \u2192 V , conditional expectation is defined, for v \u2208 V , as\nE[X | Y = v] = \u2211\n\u03c9\u2208\u2126\nX(\u03c9) \u00b7 P (Z = \u03c9 | Y = v).\nHidden Markov Models. We are working with HMMs with \u03b5-transitions (also called null transitions in the literature [2,8]). In particular we put observations on the transitions, rather than on the states [11]. This is a standard variant for HMMs and is for instance done in [2,8,6]. Since we use \u03b5-transitions, we need not assume an initial probability function, but instead later fix a start state s0.\nDefinition 2.1 (HMM with \u03b5-transitions). An HMM with \u03b5-transitions is a three-tuple (S,\u03a3, \u03b4), consisting of a finite state space S, an alphabet \u03a3 and a transition function \u03b4 : S \u2192 D((\u03a3 \u222a {\u03b5}) \u00d7 S). The set of transitions is defined as T\u03b4 = {(s, a, s\n\u2032) | s, s\u2032 \u2208 S, a \u2208 \u03a3 \u222a {\u03b5}, \u03b4(s)(a, s\u2032) > 0}. In addition T s\u03b4 = T\u03b4 \u2229 ({s} \u00d7 (\u03a3 \u222a {\u03b5})\u00d7 S)."
        },
        {
            "heading": "3 Probability Space and Random Variables",
            "text": "The probability space of observation sequences contains alternating sequences of states and observation symbols (or \u03b5) and is dependent on n, denoting the\nnumber of observable symbols (from \u03a3). We fix a start state s0 \u2208 S and restrict the possible sequences to those where the second to last element is contained in \u03a3 and is hence observable. This is needed to make sure that the probabilities in fact sum up to 1.\n\u2126ns0 = s0((\u03b5S) \u2217\u03a3S)n\nThe probability for an element from the probability space z\u0303 \u2208 \u2126ns0 can be calculated by multiplying the corresponding transition probabilities. Whenever z\u0303 = s0a1s1a2 . . . amsm \u2208 \u2126 n s0 where si \u2208 S and ai \u2208 \u03a3 \u222a {\u03b5} we define:\nPns0(z\u0303) = \u220fm i=1 \u03b4(si\u22121)(ai, si). Furthermore P 0 s0(s0) = 1.\nNote that due to the presence of \u03b5-transitions we have to take care to set up a probability space where the probabilities add up to 1. An alternative could be to use the solution of [8] and to distinguish a final state, which is however inconvenient for some applications. We continue by showing that the probability space is well-defined under some mild conditions. These conditions have the additional benefit that the fixpoint equations become contractive (after a number of iterations) and hence have unique solutions (for more details see Appendix D).\nProposition 3.1. Assume that for each state s \u2208 S there is an outgoing path of non-zero probability that contains a symbol in \u03a3. Then the probability space is well-defined, in particular\n\u2211 z\u0303\u2208\u2126ns0 Pns0(z\u0303) = 1.\nWe will in the following assume that the requirement of Prop. 3.1 holds. Otherwise there might be states that can never reach an observation symbol, for which the probability of all outgoing paths is 0.\nGiven this probability space, we define some required random variables.\nRandom Variables Z : \u2126ns0 \u2192 \u2126 n s0 Identity on \u2126 n s0 Y : \u2126ns0 \u2192 \u03a3 n Projection to observable symbols (removal of \u03b5\u2019s and states) L : \u2126ns0 \u2192 S Last state of a given observation sequence Xt : \u2126 n s0 \u2192 N0 Number of times a transition t = (s, a, s \u2032) occurs in a sequence\nWe omit the indices n, s0 if they are clear from the context: if we write P (z\u0303) or P (Z = z\u0303) we work in the probability space \u2126ns0 and mean the probability function Pns0 , where n = |Y (z\u0303)| and s0 is the first element of z\u0303. And if we write Ps0(Y = y\u0303), the value n is understood to be |y\u0303|. We do the same for expectations."
        },
        {
            "heading": "4 Finding the Best Explanation for an Observation",
            "text": "As a warmup we will describe a method for finding the best explanation, given an observation sequence. More concretely, an observation sequence y\u0303 \u2208 \u03a3\u2217 is given and it is our aim to compute the most probable sequence of states and its probability. For standard HMMs there is a well-known algorithm for this task: the Viterbi algorithm [12,9,11]. Instead of enumerating all paths and checking which one is most probable, it uses intermediate results, by computing step-bystep the most probable path ending at a given state s, for each prefix of the observation sequence y\u0303.\nWe now adapt the Viterbi algorithm, taking \u03b5-transitions into account. While in the standard case it is straightforward to obtain the likeliest path in the case of a single observation symbol, in our case the path might have taken an arbitrary number of \u03b5-transitions in between. Remember that the probability space is set up in such a way that the last transition in every sequence that we consider is always observable, which is no restriction, since there is always some explanation with maximal probability that satisfies this condition.\nProposition 4.1 (Maximal probability for one observation). Let (S,\u03a3, \u03b4) be an HMM and a \u2208 \u03a3 be an observation. With Eas0,s, for s0, s \u2208 S we denote the probability for the most likely path in \u21261s0 , starting in state s0 and ending in state s, where a is the observation. Then we have:\nEas0,s = max z\u0303\u2208\u21261s0 L(z\u0303)=s\nP (Z = z\u0303 \u2227 Y = a) = max ( \u03b4(s0)(a, s) ,max\ns\u2032\u2208S \u03b4(s0)(\u03b5, s\n\u2032) \u00b7 Eas\u2032,s\n)\nThe equation of Prop. 4.1 has a unique fixpoint due to the requirement that from every state there is a path of non-zero probability that contains an observation. In order to compute Eas0,s one could hence perform fixpoint iteration or use an external solver. In fact, the computation is simplified in this case since among the paths with the highest probability there is always one that does not contain duplicate states (apart from the final state s). By equipping the computation with an extra parameter S0 \u2286 S (the set of states that can still be visited), we can easily ensure termination, even in the presence of \u03b5-loops, and the equation becomes the following, where Eas0,s = E a s0,s(S).\nEas0,s(S0) = max ( \u03b4(s0)(a, s) , max\ns\u2032\u2208S0\\{s0} \u03b4(s0)(\u03b5, s\n\u2032) \u00b7 Eas\u2032,s(S0\\{s0}) )\nWe can now address the task of computing the maximal probability for a longer sequence of observations. For this purpose, we extend the established Viterbi algorithm [12]. Here, the probability for the likeliest path that results in a given observation is computed inductively and is based on Prop. 4.1.\nProposition 4.2 (Maximal probability for observation sequence). Let (S,\u03a3, \u03b4) be an HMM and let y\u0303 = a1 . . . an = y\u03031an be an observation sequence. Then V y\u0303s0,s denotes the maximum probability of observing y\u0303 and ending in state s, more formally\nV y\u0303s0,s = maxz\u0303\u2208\u2126ns0 L(z\u0303)=s P (Z = z\u0303 \u2227 Y = y\u0303)\nFor n = 0 we have V \u03b5s0,s = 1 if s = s0 and 0 otherwise. For n > 0:\nV y\u0303s0,s = maxs\u2032\u2208S V y\u03031s0,s\u2032 \u00b7 E an s\u2032,s\nIn order to obtain the best explanation starting at s0, regardless of its final state, we still have to take the maximum maxs\u2208S V y\u0303 s0,s. If we are instead interested in the conditional probability, i.e., maxz\u0303\u2208\u2126ns0 P (Z = z\u0303 | Y = y\u0303), it can be obtained from this maximum by dividing by Ps0(Y = y\u0303).\nSince the computation of the most likely path is almost identical to the computation of the highest probability, we elaborate on this only in the appendix."
        },
        {
            "heading": "5 Parameter Learning",
            "text": "We now discuss a method for determining the system parameters. We assume that the structure of the system and initial probabilities are given, and those probabilities have to be adjusted through observing output sequences. This core problem for HMMs is traditionally solved by the Baum-Welch algorithm [3], which is based on the forward-backward algorithm, but because of \u03b5-transitions and in particular \u03b5-loops, it is necessary to develop a different approach."
        },
        {
            "heading": "5.1 Conditional Expectation of the Number of Transition Traversals",
            "text": "To adjust the probabilities, we have to solve the following subtask: Given an HMM with initial state s0, an observation sequence y\u0303 and a transition t, determine the expected value of the number of traversals of t, when observing sequence y\u0303, starting from s0. For each state, we determine these values for all outgoing transitions and normalize them to obtain probabilities. This gives us new parameters and we later discuss the guarantees that this approach provides.\nIf there are no \u03b5-loops, it is sufficient to compute the probability of crossing a given transition t while reading the i-th symbol of the observation sequence and to sum up over all i. This is done with the forward-backward algorithm, determining the probability of reaching the source state of t, multiplied with the probability of t and the probability of reading the remaining observation sequence from the target state. In the present setup, this has to be adapted, since we may cross t several times while reading the i-th symbol.\nWe want to determine Es0 [Xt | Y = y\u0303] or, equivalently, Es0 [Xt | Y = y\u0303] \u00b7 Ps0(Y = y\u0303). This is defined if Ps0(Y = y\u0303) > 0, which we assume since the sequence y\u0303 has actually been observed. Note that due to the nature of our probability space, \u03b5-transitions that might be traversed after the last observation do not count. We compute the conditional expectation by setting up a suitable fixpoint equation.\nProposition 5.1. Fix an HMM and an observation sequence y\u0303 = a1 . . . an = a1y\u03031. Let t = (s, a, s \u2032) and define\nC y\u0303s0,t = Es0 [Xt | Y = y\u0303] \u00b7 Ps0 (Y = y\u0303).\nThen C\u03b5s0,t = 0 and the following fixpoint equation holds: whenever a \u2208 \u03a3\nC y\u0303s0,t = \u2211\ns1\u2208S\n\u03b4(s0)(a1, s1) \u00b7 C y\u03031 s1,t +\n\u2211\ns1\u2208S\n\u03b4(s0)(\u03b5, s1) \u00b7 C y\u0303 s1,t +\n[s0 = s \u2227 a1 = a] \u00b7 \u03b4(s)(a, s \u2032) \u00b7 Ps\u2032(Y = y\u03031)\nand whenever a = \u03b5 the last summand has to be replaced by [s0 = s] \u00b7 \u03b4(s)(\u03b5, s \u2032) \u00b7 Ps\u2032(Y = y\u0303). We use the convention that [b] = 1 if b holds and [b] = 0 otherwise.\nSince the equations are contractive after some iterations (cf. Appendix D), they have a unique fixpoint, which can be approximated by (Kleene) iteration or computed via a solver. For this we have to be able to determine Ps0(Y = y\u0303) for y\u0303 = a1y\u03031, which can be done with a similar fixpoint equation (adapt the proof of Prop. 5.1 to the case where Xt is the constant 1-function): Ps0(Y = \u03b5) = 1 and otherwise:\nPs0(Y = y\u0303) = \u2211\ns1\u2208S\n\u03b4(s0)(a1, s1) \u00b7 Ps1 (Y = y\u03031)+ \u2211\ns1\u2208S\n\u03b4(s0)(\u03b5, s1) \u00b7 Ps1(Y = y\u0303).\ns0\n\u03b5 1/2 \u03b1 1/4 \u03b2 1/4\nExample 5.2. Given the following HMM on the right where the states and transitions are known, but the probabilities have to be adjusted by observing the system. The three transitions are named t1 = (s0, \u03b5, s0), t2 = (s0, \u03b1, s0), t3 = (s0, \u03b2, s0) and the observation sequence is y\u0303 = \u03b1. Then:\nC y\u0303s0,t1 = \u03b4(s0)(\u03b1, s0)\ufe38 \ufe37\ufe37 \ufe38 1/4 \u00b7C\u03b5s0,t1\ufe38 \ufe37\ufe37 \ufe38 0 + \u03b4(s0)(\u03b5, s0)\ufe38 \ufe37\ufe37 \ufe38 1/2 \u00b7C y\u0303s0,t1 + 1 \u00b7 \u03b4(s0)(\u03b5, s0)\ufe38 \ufe37\ufe37 \ufe38 1/2 \u00b7 Ps0(Y = y\u0303)\ufe38 \ufe37\ufe37 \ufe38 1/4+1/2\u00b7Ps0(Y=y\u0303)\n\u21d2 C y\u0303s0,t1 = 1/2 = Es0 [Xt1 | Y = y\u0303] \u00b7 Ps0(Y = y\u0303)\ufe38 \ufe37\ufe37 \ufe38\n1/2\n\u21d2 Es0 [Xt1 | Y = y\u0303] = 1\nSimilarly, we compute Es0 [Xt2 | Y = y\u0303] = 1 and Es0 [Xt3 | Y = y\u0303] = 0. The adjusted and normalized probability parameters are:\n\u03b4(s0)(\u03b5, s0) = 1/2 \u03b4(s0)(\u03b1, s0) = 1/2 \u03b4(s0)(\u03b2, s0) = 0"
        },
        {
            "heading": "In practice one will of course make longer or multiple observations before adjusting the parameters.",
            "text": ""
        },
        {
            "heading": "5.2 Using the EM Algorithm",
            "text": "We will now introduce the so-called Expectation Maximization (EM) Algorithm [5], which is commonly used to derive the Baum-Welch algorithm [11,4] for parameter estimation. It explains how to suitably adjust (probabilistic) parameters of a system in such a way that the likelihood of observing the given output of the system increases. We assume that the higher the probability for observed sequences, the closer the parameters are to their actual values. This procedure is divided into two phases: the Expectation and Maximization phase.\nFix an HMM with known (graph structure) and unknown parameters (transition probabilities). The unknown parameters, denoted by \u03b8, can be learned by observing the system. We will use \u03b8 in conditional probabilities or expectations to clarify the parameter dependency. E.g., \u03b4(t | \u03b8) with t = (s, a, s\u2032) stands for \u03b4(s)(a, s\u2032) under the parameter setting \u03b8.\nThe algorithm works iteratively in two phases. \u03b8t always denotes our current best guess of the probabilistic parameters, \u03b8 denotes the new parameters that we wish to learn and improve iteratively given an observation sequence y\u0303. In the first\nphase we calculate Q(\u03b8 | \u03b8t) denoting the expected value of the log likelihood function for \u03b8 with respect to the current conditional probability of Z given an observation and the current estimates of the parameter \u03b8t. More concretely:\nQ(\u03b8 | \u03b8t) = EZ|Y,\u03b8t [logP (Y, Z | \u03b8)],\nwhich denotes the expectation of the random variable z\u0303 7\u2192 logP (Y = y\u0303, Z = z\u0303 | \u03b8) in an updated probability space where the probability function is P \u2032(z\u0303) = P (Z = z\u0303 | Y = y\u0303, \u03b8t). Here it is understood that log 0 = \u2212\u221e and 0 \u00b7 (\u2212\u221e) = 0.\nAfter the first phase follows the Maximization phase, where \u03b8t+1 is determined as argmax\u03b8Q(\u03b8 | \u03b8\nt) and the algorithm subsequently starts again with phase one. This happens iteratively until \u03b8t+1 = \u03b8t or the improvements are below some threshold. In general we will converge to a local optimum, finding the global optimum is typically infeasible. The guarantee of the EM algorithm is that P (Y = y\u0303 | \u03b8) > P (Y = y\u0303 | \u03b8t) whenever Q(\u03b8 | \u03b8t) > Q(\u03b8t | \u03b8t).\nTheorem 5.3. In our setting it holds that\nQ(\u03b8 | \u03b8t) = \u2211\ns\u2208S\n\u2211\nt=(s,a,s\u2032)\u2208T\u03b4\nlog \u03b4(t | \u03b8) \u00b7Es0 [Xt | Y = y\u0303, \u03b8 t].\nThe value Q(\u03b8 | \u03b8t) is maximal when the parameters \u03b8 are as follows: for every transition t we set \u03b4(t | \u03b8) proportional to Es0 [Xt | Y = y\u0303, \u03b8 t].\nNote that there might be states where all outgoing transitions have conditional expectation zero, i.e., such a state can not be reached via the observation sequence. In this case we keep the previous parameters. If we adhere to this, we can always guarantee that the requirement of Lemma 3.1 is maintained, since if an outgoing transition of a state has conditional expectation greater than zero, there must be a path of non-zero probability to an observation."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we considered HMMs that admit unobservable \u03b5-transitions. We presented algorithms for determining the most probable explanation (i.e. a sequence of hidden states) given an observation and a method for parameter learning. For this, we generalized the Viterbi and the Baum-Welch algorithm to consider \u03b5-transitions (including \u03b5-loops) and provided the respective proofs of their soundness. By allowing state changes of which the observer is unaware we can model false negatives, i.e. actions that have taken place but have not been observed by a sensor. This extends the applicability of HMMs as a modeling technique to the domain of sensor-based systems, which always have to consider the probability of sensor errors. For example, we now have the methods to compare observations made by sensors with the computed most likely explanation. When these two drift further apart over time, we can conclude that the real-world system is subject to parameter drift or degrading sensor quality. Furthermore, we plan to use the HMMs to clean data sets by replacing observations with their most probable explanation. Parameter learning will be needed to learn and adapt the model parameters based on recorded observations."
        },
        {
            "heading": "A Proofs for Section 3 (Probability Space and Random Variables)",
            "text": "Proposition 3.1. Assume that for each state s \u2208 S there is an outgoing path of non-zero probability that contains a symbol in \u03a3. Then the probability space is well-defined, in particular\n\u2211 z\u0303\u2208\u2126ns0 Pns0(z\u0303) = 1.\nProof. Given a sequence z\u0303 = s0a1s1a2 . . . amsm = s0a1z\u03031 we observe that\nPns0(z\u0303) = \u03b4(s0)(a1, s1) \u00b7 P n s1(z\u03031) if a1 = \u03b5 Pns0(z\u0303) = \u03b4(s0)(a1, s1) \u00b7 P n\u22121 s1 (z\u03031) if a1 \u2208 \u03a3\nWe abbreviate Sns0 = \u2211\nz\u0303\u2208\u2126ns0 Pns0(z\u0303). Since \u2126 0 s0 = {s0}, it is easy to see that\nS0s0 = 1 and if n \u2265 1:\nSns0 = \u2211\nz\u0303\u2208\u2126ns0\nPns0(z\u0303) = \u2211\ns1\u2208S\n\u2211\nz\u03031\u2208\u2126ns1\n\u03b4(s0)(\u03b5, s1) \u00b7 P n s1(z\u03031)+\n\u2211\na1\u2208\u03a3,s1\u2208S\n\u2211\nz\u03031\u2208\u2126 n\u22121 s1\n\u03b4(s0)(a1, s1) \u00b7 P n\u22121 s1 (z\u03031)\n= \u2211\ns1\u2208S\n\u03b4(s0)(\u03b5, s1) \u00b7 \u2211\nz\u03031\u2208\u2126ns1\nPns1(z\u03031)+\n\u2211\na1\u2208\u03a3,s1\u2208S\n\u03b4(s0)(a1, s1) \u00b7 \u2211\nz\u03031\u2208\u2126 n\u22121 s1\nPn\u22121s1 (z\u03031)\n= \u2211\ns1\u2208S\n\u03b4(s0)(\u03b5, s1) \u00b7 S n s1 +\n\u2211\na1\u2208\u03a3,s1\u2208S\n\u03b4(s0)(a1, s1) \u00b7 S n\u22121 s1\nSince the probabilities of all outgoing transitions of a state sum up to 1, we observe that Sns = 1 for all n, s \u2208 S is a solution to this system of fixpoint equations. Since we assume that each state will eventually reach an observation symbol in \u03a3 with non-zero probability, the corresponding fixpoint function is contractive after some iterations, since the probability to stay with index n is strictly less than 1 after at most |S| steps (for more details see Appendix D).\nThis implies that the fixpoint is unique and hence the statement of the proposition follows."
        },
        {
            "heading": "B Proofs for Section 4 (Finding the Best Explanation for an Observation)",
            "text": "Proposition 4.1 (Maximal probability for one observation). Let (S,\u03a3, \u03b4) be an HMM and a \u2208 \u03a3 be an observation. With Eas0,s, for s0, s \u2208 S we denote the probability for the most likely path in \u21261s0 , starting in state s0 and ending in state s, where a is the observation. Then we have:\nEas0,s = max z\u0303\u2208\u21261s0 L(z\u0303)=s\nP (Z = z\u0303 \u2227 Y = a) = max ( \u03b4(s0)(a, s) ,max\ns\u2032\u2208S \u03b4(s0)(\u03b5, s\n\u2032) \u00b7 Eas\u2032,s\n)\nProof.\nEas0,s = max z\u0303\u2208\u21261s0 L(z\u0303)=s P 1(Z = z\u0303 \u2227 Y = a) = max z\u0303\u2208 s0(\u03b5S) \u2217as P 1(Z = z\u0303 \u2227 Y = a)\n= max ( P 1(Z = s0as \u2227 Y = a)\ufe38 \ufe37\ufe37 \ufe38\n\u03b4(s0)(a,s)\n, max z\u03031\u2208\nS(\u03b5S)\u2217as\nP 1(Z = s0\u03b5z\u03031 \u2227 Y = a) )\n= max ( \u03b4(s0)(a, s) , max\ns\u2032\u2208S max z\u03031\u2208\ns\u2032(\u03b5S)\u2217as\n\u03b4(s0)(\u03b5, s \u2032) \u00b7 P 1(Z = z\u03031 \u2227 Y = a)\n)\n= max ( \u03b4(s0)(a, s) , max\ns\u2032\u2208S \u03b4(s0)(\u03b5, s \u2032) \u00b7 max z\u03031\u2208\ns\u2032(\u03b5S)\u2217as\nP 1(Z = z\u03031 \u2227 Y = a) )\n\ufe38 \ufe37\ufe37 \ufe38 Ea s\u2032,s\n= max ( \u03b4(s0)(a, s) ,max\ns\u2032\u2208S \u03b4(s0)(\u03b5, s\n\u2032) \u00b7 Eas\u2032,s\n)\nProposition 4.2 (Maximal probability for observation sequence). Let (S,\u03a3, \u03b4) be an HMM and let y\u0303 = a1 . . . an = y\u03031an be an observation sequence. Then V y\u0303s0,s denotes the maximum probability of observing y\u0303 and ending in state s, more formally\nV y\u0303s0,s = maxz\u0303\u2208\u2126ns0 L(z\u0303)=s P (Z = z\u0303 \u2227 Y = y\u0303)\nFor n = 0 we have V \u03b5s0,s = 1 if s = s0 and 0 otherwise. For n > 0:\nV y\u0303s0,s = maxs\u2032\u2208S V y\u03031s0,s\u2032 \u00b7 E an s\u2032,s\nProof.\nV y\u0303s0,s = V a1...an s0,s\n= max z\u0303\u2208\u2126ns0 L(z\u0303)=s P (Z = z\u0303 \u2227 Y = a1 . . . an)\n= max s\u2032\u2208S max z\u03031\u2208\u2126\nn\u22121 s0 L(z\u03031)=s \u2032\nmax z\u03032\u2208\u2126 1 s\u2032 L(z\u03032)=s P (Z = z\u03031 \u2227 Y = a1 . . . an\u22121) \u00b7 P (Z = z\u03032 \u2227 Y = an)\n= max s\u2032\u2208S max z\u03031\u2208\u2126\nn\u22121 s0 L(z\u03031)=s \u2032\nP (Z = z\u03031 \u2227 Y = a1 . . . an\u22121)\n\ufe38 \ufe37\ufe37 \ufe38 V a1...an\u22121\ns0,s \u2032\n\u00b7 max z\u03032\u2208\u2126 1 s\u2032\nL(z\u03032)=s\nP (Z = z\u03032 \u2227 Y = an)\n\ufe38 \ufe37\ufe37 \ufe38 Ean s\u2032,s\n= max s\u2032\u2208S\nV a1...an\u22121 s0,s\u2032 \u00b7 Eans\u2032,s = maxs\u2032\u2208S V y\u03031s0,s\u2032 \u00b7 E an s\u2032,s\nIn order to obtain the most likely path resulting in a given observation, we make use of the calculated highest probabilities. We do not only expect a sequence of states as explanation, but also the intermediate symbols or \u03b5\u2019s used when transitioning from state to state. This is necessary because a possible \u03b5transition can implicitly occur in an observation, creating an ambiguity problem when working out which exact transitions where taken at what time in the state sequence.\nBy unravelling the fixpoint equation of Prop. 4.1, we obtain the following construction, where EPathas0,s \u2208 \u2126 1 s0 denotes the likeliest state sequence for a path starting in state s0 and ending in state s that produces the observation a in its last transition. This is feasible whenever Eas0,s > 0.\nEPathas0,s =\n{ s0as if E y s0,s = \u03b4(s0)(a, s)\ns0\u03b5EPath a s\u2032,s otherwise, with s \u2032 = argmaxs\u2032\u2208S \u03b4(s0)(\u03b5, s \u2032) \u00b7 Eys\u2032,s\nNote that in the following the operator \u25e6 denotes concatenation and the tail function T removes the first element of a given input sequence and returns the rest.\nProposition B.1 (Likeliest state sequence for observation sequence). Given an HMM (S,\u03a3, \u03b4) and an observation sequence y\u0303 = a1 . . . an. Whenever V y\u0303s0,s > 0, the term \u03c8 y\u0303 s0,s denotes the likeliest state sequence starting in state s0, ending in s, that explains y\u0303, in particular\n\u03c8y\u0303s0,s = argmax z\u0303\u2208\u2126ns0 L(z\u0303)=s P (Z = z\u0303 \u2227 Y = y\u0303).\nIt holds that \u03c8\u03b5s0,s0 = s0. Furthermore, whenever y\u0303 = y\u03031an:\n\u03c8y\u0303s0,s = \u03c8 y\u03031 s0,s\u2032 \u25e6 T (EPathans\u2032,s),\nwhere s\u2032 = argmaxs\u2032\u2208S V y\u03031 s0,s\u2032 \u00b7 Eans\u2032,s.\nProof.\n\u03c8y\u0303s0,s = \u03c8 a1...an s0,s =\n= argmax z\u0303\u2208\u2126ns0 L(z\u0303)=s P (Z = z\u0303 \u2227 Y = a1 . . . an)\n= argmax z\u03031\u2208\u2126\nn\u22121 s0 L(z\u03031)=s \u2032\nP (Z = z\u03031 \u2227 Y = a1 . . . an\u22121)\n\ufe38 \ufe37\ufe37 \ufe38 \u03c8 a1...an\u22121\ns0,s \u2032\n\u25e6T (argmax z\u03032\u2208\u2126\n1 s\u2032\nL(z\u03032)=s\nP (Z = z\u03032 \u2227 Y = an)\n\ufe38 \ufe37\ufe37 \ufe38 EPathan\ns\u2032,s\n)\n= \u03c8 a1...an\u22121 s0,s\u2032 \u25e6 T (EPathans\u2032,s) = \u03c8 y\u03031 s0,s\u2032 \u25e6 T (EPathans\u2032,s)\nwhere s\u2032 = argmaxs\u2032\u2208S V a1...an\u22121 s0,s\u2032 \u00b7 Eans\u2032,s is the state where the maximum is reached."
        },
        {
            "heading": "C Proofs for Section 5 (Parameter Learning)",
            "text": "Proposition 5.1. Fix an HMM and an observation sequence y\u0303 = a1 . . . an = a1y\u03031. Let t = (s, a, s \u2032) and define\nC y\u0303s0,t = Es0 [Xt | Y = y\u0303] \u00b7 Ps0 (Y = y\u0303).\nThen C\u03b5s0,t = 0 and the following fixpoint equation holds: whenever a \u2208 \u03a3\nC y\u0303s0,t = \u2211\ns1\u2208S\n\u03b4(s0)(a1, s1) \u00b7 C y\u03031 s1,t +\n\u2211\ns1\u2208S\n\u03b4(s0)(\u03b5, s1) \u00b7 C y\u0303 s1,t +\n[s0 = s \u2227 a1 = a] \u00b7 \u03b4(s)(a, s \u2032) \u00b7 Ps\u2032(Y = y\u03031)\nand whenever a = \u03b5 the last summand has to be replaced by [s0 = s] \u00b7 \u03b4(s)(\u03b5, s \u2032) \u00b7 Ps\u2032(Y = y\u0303). We use the convention that [b] = 1 if b holds and [b] = 0 otherwise.\nProof. Note that by assumption Ps0(Y = y\u0303) > 0. We compute\nC y\u0303s0,t = Es0 [Xt | Y = y\u0303] \u00b7 Ps0(Y = y\u0303)\n= \u2211\nz\u0303\u2208\u2126ns0\nXt(z\u0303) \u00b7 P (Z = z\u0303 | Y = y\u0303) \u00b7 Ps0(Y = y\u0303)\n= \u2211\nz\u0303\u2208\u2126ns0\nXt(z\u0303) \u00b7 P (Z = z\u0303 \u2227 Y = y\u0303)\n= \u2211\nz\u0303\u2208\u2126ns0 Y (z\u0303)=y\u0303\nXt(z\u0303) \u00b7 P (Z = z\u0303)\n= \u2211\ns1\u2208S\n\u2211\nz\u03031\u2208\u2126 n\u22121 s1\nY (s0a1z\u03031)=y\u0303\nXt(s0a1z\u03031) \u00b7 P (Z = s0a1z\u03031)+\n\u2211\ns1\u2208S\n\u2211\nz\u03031\u2208\u2126 n s1\nY (s0\u03b5z\u03031)=y\u0303\nXt(s0\u03b5z\u03031) \u00b7 P (Z = s0\u03b5z\u03031)\n= \u2211\ns1\u2208S\n\u2211\nz\u03031\u2208\u2126 n\u22121 s1 Y (z\u03031)=y\u03031\n(Xt(z\u03031) + [s0 = s \u2227 a1 = a \u2227 s1 = s \u2032]) \u00b7\n\u03b4(s0)(a1, s1) \u00b7 P (Z = z\u03031)+\u2211\ns1\u2208S\n\u2211\nz\u03031\u2208\u2126 n s1 Y (z\u03031)=y\u0303\nXt(z\u03031) \u00b7 \u03b4(s0)(\u03b5, s1) \u00b7 P (Z = z\u03031)\n= \u2211\ns1\u2208S\n\u03b4(s0)(a1, s1) \u00b7 \u2211\nz\u03031\u2208\u2126 n\u22121 s1 Y (z\u03031)=y\u03031\nXt(z\u03031) \u00b7 P (Z = z\u03031)+\n\u2211 s1\u2208S \u03b4(s0)(\u03b5, s1) \u00b7 \u2211\nz\u03031\u2208\u2126 n s1 Y (z\u03031)=y\u0303\nXt(z\u03031) \u00b7 P (Z = z\u03031)+\n\u2211\ns1\u2208S\n[s0 = s \u2227 a1 = a \u2227 s1 = s \u2032] \u00b7 \u03b4(s0)(a1, s1) \u00b7\n\u2211\nz\u03031\u2208\u2126 n\u22121 s1 Y (z\u03031)=y\u03031\nP (Z = z\u03031)\n= \u2211\ns1\u2208S\n\u03b4(s0)(a1, s1) \u00b7 C y\u03031 s1,t +\n\u2211\ns1\u2208S\n\u03b4(s0)(\u03b5, s1) \u00b7 C y\u0303 s1,t +\n[s0 = s \u2227 a = a1] \u00b7 \u03b4(s)(a, s \u2032) \u00b7 Ps\u2032(Y = y\u03031).\nTheorem 5.3. In our setting it holds that\nQ(\u03b8 | \u03b8t) = \u2211\ns\u2208S\n\u2211\nt=(s,a,s\u2032)\u2208T\u03b4\nlog \u03b4(t | \u03b8) \u00b7Es0 [Xt | Y = y\u0303, \u03b8 t].\nThe value Q(\u03b8 | \u03b8t) is maximal when the parameters \u03b8 are as follows: for every transition t we set \u03b4(t | \u03b8) proportional to Es0 [Xt | Y = y\u0303, \u03b8 t].\nProof. In this proof we write ti(z\u0303) for the i-th transition of z\u0303, i.e., if z\u0303 = s0a1s1a2 . . . amsm, then ti(z\u0303) = (si\u22121, ai, si). Note that 1 \u2264 i \u2264 (|z\u0303| \u2212 1)/2. Hence P (Z = z\u0303 | \u03b8) = \u220f(|z\u0303| \u2212 1)/2 i=1 \u03b4(ti(z\u0303) | \u03b8).\nFurthermore:\nQ(\u03b8 | \u03b8t) = EZ|Y,\u03b8t [logP (Y, Z | \u03b8)]\n= \u2211\nz\u0303\u2208\u2126ns0\nlogP (Y = y\u0303, Z = z\u0303 | \u03b8) \u00b7 P (Z = z\u0303 | Y = y\u0303, \u03b8t)\n= \u2211\nz\u0303\u2208\u2126ns0 Y (z\u0303)=y\u0303\nlogP (Z = z\u0303 | \u03b8) \u00b7 P (Z = z\u0303 | Y = y\u0303, \u03b8t)\n= \u2211\nz\u0303\u2208\u2126ns0 Y (z\u0303)=y\u0303\nlog\n(|z\u0303| \u2212 1)/2\u220f\ni=1\n\u03b4(ti(z\u0303) | \u03b8) \u00b7 P (Z = z\u0303 | Y = y\u0303, \u03b8 t)\n= \u2211\nz\u0303\u2208\u2126ns0 Y (z\u0303)=y\u0303\n(|z\u0303| \u2212 1)/2\u2211\ni=1\nlog \u03b4(ti(z\u0303) | \u03b8) \u00b7 P (Z = z\u0303 | Y = y\u0303, \u03b8 t)\n= \u2211\nt\u2208T\u03b4\n\u2211\nz\u0303\u2208\u2126ns0 Y (z\u0303)=y\u0303\nXt(z\u0303) \u00b7 log \u03b4(t | \u03b8) \u00b7 P (Z = z\u0303 | Y = y\u0303, \u03b8 t)\n= \u2211\nt\u2208T\u03b4\nlog \u03b4(t | \u03b8) \u00b7 \u2211\nz\u0303\u2208\u2126ns0 Y (z\u0303)=y\u0303\nXt(z\u0303) \u00b7 P (Z = z\u0303 | Y = y\u0303, \u03b8 t)\n\ufe38 \ufe37\ufe37 \ufe38 Es0 [Xt|Y=y\u0303,\u03b8 t]\n= \u2211\ns\u2208S\n\u2211\nt\u2208T s \u03b4\nlog \u03b4(t | \u03b8) \u00b7Es0 [Xt | Y = y\u0303, \u03b8 t]\nThe third-last equality is given by the following computation, where A \u2286 B\u2217 and ai denotes the i-th symbol of a \u2208 B\n\u2217. In this case nested sums can be rewritten as follows, where #b(a) stands for the number of occurrences of b in a:\n\u2211\na\u2208A\n|a|\u2211\ni=1\nTai \u00b7 Sa = \u2211\na\u2208A\nSa \u00b7\n|a|\u2211\ni=1\nTai = \u2211\na\u2208A\nSa \u00b7 \u2211\nb\u2208B\n\u2211\n1\u2264i\u2264|a| ai=b\nTb\ufe37\ufe38\ufe38\ufe37 Tai\n\ufe38 \ufe37\ufe37 \ufe38 #b(a)\u00b7Tb\n= \u2211\nb\u2208B\n\u2211\na\u2208A\n#b(a) \u00b7 Tb \u00b7 Sa\nThe last value in the computation above can be maximized for each s \u2208 S independently and we obtain:\n\u2211\nt\u2208T s \u03b4 log \u03b4(t | \u03b8)\ufe38 \ufe37\ufe37 \ufe38 pi \u00b7Es0 [Xt | Y = y\u0303, \u03b8 t]\ufe38 \ufe37\ufe37 \ufe38 ai\n= \u2211\ni\n(log pi) \u00b7 ai\nThis value is maximal if pi = ai\u2211 i ai , which concludes the proof. This is a consequence of Gibbs\u2019 inequality, which says that, given a probability function p : I \u2192 [0, 1] with I finite, then for every other probability function q : I \u2192 [0, 1], we have that \u2211\ni\u2208I\npi log pi \u2265 \u2211\ni\u2208I\npi log qi.\nIt is also related to the fact that Kullback-Leibler divergence is always nonnegative. Since the result is easy to derive we prove it in Lemma C.1\nLemma C.1. Let ai \u2265 0, i \u2208 {1, . . . ,m}, be fixed. Let pi \u2208 [0, 1] be unknown values such that \u2211m i=1 pi = 1. Then\nm\u2211\ni=1\nai \u00b7 log pi\nis maximal if pi = ai\u2211 m i=1 ai .\nProof. We can assume that log = ln, since logarithms differ only by a constant factor. Furthermore we can see that in order to achieve the maximal value, pi must be strictly larger than 0 whenever ai > 0 and pi = 0 otherwise. (Remember the convention that 0 \u00b7 log 0 = 0 \u00b7 (\u2212\u221e) = 0.) Hence we can assume without loss of generality that ai > 0 for all i.\nSince \u2211m i=1 pi = 1 we can replace pm by 1\u2212 \u2211m\u22121 i=1 pi and obtain\nm\u22121\u2211\ni=1\nai \u00b7 ln pi + am \u00b7 ln ( 1\u2212 m\u22121\u2211\ni=1\npi )\nRemembering that ddx lnx = 1 x , we now compute the partial derivates with respect to pj where j 6= m.\n\u2202\n\u2202pj\n(m\u22121\u2211\ni=1\nai \u00b7 ln pi + am \u00b7 ln ( 1\u2212 m\u22121\u2211\ni=1\npi ))\n= aj pj + am \u00b7 1 1\u2212 \u2211m\u22121 i=1 pi \u00b7 (\u22121) = aj pj \u2212 am pm = aj \u00b7 pm \u2212 pj \u00b7 am pj \u00b7 pm\nThis equals 0 if aj \u00b7 pm \u2212 pj \u00b7 am = 0. We sum up over all indices j and get\n0 = m\u2211\nj=1\n(aj \u00b7 pm \u2212 pj \u00b7 am) = pm \u00b7 m\u2211\nj=1\naj \u2212 am \u00b7 m\u2211\nj=1\npj = pm \u00b7 m\u2211\nj=1\naj \u2212 am\nThis implies\npm = am\u2211 j aj\nand by substitution, we obtain an analogous formula for all pj . We can check that all conditions aj \u00b7 pm \u2212 pj \u00b7 am = 0 are satisfied.\nThe maximum must be reached in the point where all derivatives are zero, from which the statement follows."
        },
        {
            "heading": "D Contractivity",
            "text": "The claims on contractivity made in the paper deserve further elaboration. We first define the notion of a contractive function.\nDefinition D.1 (Contractive function). Let RW be the set of all functions from a set W to R. We use the supremum (or maximum) distance and define dsup(g1, g2) = supW\u2208W |g1(W )\u2212 g2(W )| for g1, g2 : W \u2192 R.\nA function F : RW \u2192 RW is contractive whenever for all g1, g2 \u2208 R W it holds\nthat dsup(F (g1), F (g2)) \u2264 q \u00b7 dsup(g1, g2) for some 0 \u2264 q < 1. We say that F is contractive after k iterations if F k is contractive.\nIt is well-known from the Banach fixpoint theorem that contractive functions over complete metric spaces have unique fixpoints and RW with the sup-metric is complete. Furthermore any sequence (gi)i\u2208N with gi+1 = F (gi) converges to this fixpoint. Now, every fixpoint of F is a fixpoint of F k and vice versa. The latter direction holds, since fixpoint iteration for F from a fixpoint x of F k (with F k(x) = x) clearly converges again to x. Hence a function F that is contractive after k iterations also has a unique fixpoint and enjoys the same convergence property (although with a potentially slower convergence rate).\nWe now argue why the fixpoint functions that we consider are contractive after a certain number of iterations.\nThe fixpoint equation systems set up in Sct. 3 (proof of Prop. 3.1) and Sct. 5.1 are over a set W of variables of the form W y\u0303s , where s \u2208 S and y\u0303 \u2208 \u03a3\n\u2217 is the suffix of a given word y\u0304 \u2208 \u03a3\u2217 with n = |y\u0304|. (Or alternatively the variables are of the form Sns , see the proof of Prop. 3.1, leading to an analogous argument.) We define o(W y\u0303s ) = y\u0303. Note that W is finite, since the state space S is finite.\nThe corresponding fixpoint function is a monotone function F : RW \u2192 RW\nwhere, for g : W \u2192 R:\nF (g)(W ) = \u2211\nW \u2032\u2208W\npW,W \u2032 \u00b7 g(W \u2032) +DW , (1)\nwhere pW,W \u2032 \u2208 [0, 1] such that for each W \u2208 W we have \u2211 W \u2032\u2208W pW,W \u2032 \u2264 1 and DW is a non-negative constant. Furthermore pW,W \u2032 > 0 implies |o(W )| \u2265 |o(W \u2032)|. In addition we can assume that o(W ) = \u03b5 implies pW,W \u2032 = 0 (and hence F (g)(W ) = DW is a constant).\nSuch functions are clearly non-expansive (which means that the contractivity requirement holds for q = 1) but not necessarily contractive.\nHowever, we know that the probabilities pW,W \u2032 are transition probabilities and the length of the observed sequence decreases if one takes a transition that is labelled with an observable symbol. Due to the requirement of Prop. 3.1 we know that each state has a path of non-zero probability that contains such an observation. For each state s \u2208 S we consider the minimum length of such a path and we take the maximum over all these minimums and obtain k. Then we know that the fixpoint equation associated with F k is of the same form as for F above (see (1)) and additionally for each W \u2208 W\n\u2013 there exists W \u2208 W with pW,W > 0 and |o(W )| > |o(W )| (if we take a transition with the next label to observe, reducing the length of the observation sequence) or \u2013 \u2211\nW \u2032\u2208W pW,W \u2032 < 1 (if a state has an outgoing transition with a label that does not match the next observation).\nThis means that either the second condition holds after at most n \u00b7k iterations or we reach the last observation of y\u0304 on a path of non-zero probability of length at most n \u00b7 k. The latter means that the term for Fn\u00b7k(g)(W ) contains \u2013 multiplied with a non-zero probability \u2013 a variableW with o(W ) = \u03b5, for which F (g)(W ) is constant. That is, after m+1 iterations the corresponding fixpoint equation (1) satisfies qW := \u2211 W \u2032\u2208W pW,W \u2032 < 1 for each W \u2208 W . Then we have, given g1, g2 : W \u2192 R:\ndsup(F m+1(g1), F m+1(g2))\n= max W\u2208W\n\u2223\u2223\u2223 ( \u2211\nW \u2032\u2208W\npW,W \u2032 \u00b7 g1(W \u2032) +DW ) \u2212 ( \u2211\nW \u2032\u2208W\npW,W \u2032 \u00b7 g2(W \u2032) +DW )\u2223\u2223\u2223\n\u2264 max W\u2208W\n\u2211\nW \u2032\u2208W\npW,W \u2032 \u00b7 |g1(W \u2032)\u2212 g2(W \u2032)|\n\u2264 max W\u2208W\n( \u2211\nW \u2032\u2208W\npW,W \u2032 )\n\ufe38 \ufe37\ufe37 \ufe38 qW\n\u00b7 max W \u2032\u2208W\n|g1(W \u2032)\u2212 g2(W \u2032)|\n\u2264 ( max W\u2208W qW ) \ufe38 \ufe37\ufe37 \ufe38\nq\n\u00b7 max W \u2032\u2208W\n|g1(W \u2032)\u2212 g2(W \u2032)| = q \u00b7 dsup(g1, g2)\nThe first inequality uses the fact that | \u2211 i\u2208I ai| \u2264 \u2211\ni\u2208I |ai|, while the second inequality holds since \u2211 i\u2208I pi \u00b7 ai \u2264 ( \u2211 i\u2208I pi) \u00b7maxi\u2208I ai.\nSince q < 1 we have contractivity after m+ 1 iterations. In fact, the arguments are similar to the setting of absorbing Markov chains\n[7], where the absorption property is used to guarantee unique solutions."
        }
    ],
    "title": "Probabilistic Systems with Hidden State and Unobservable Transitions",
    "year": 2022
}