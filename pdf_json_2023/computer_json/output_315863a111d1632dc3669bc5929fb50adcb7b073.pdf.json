{
    "abstractText": "Distributed messaging systems (DMSs), which are critical for the timely and reliable data dissemination needs of IoT systems, are typically equipped with a large number of configurable parameters that enable users to define application run-time behaviors and resource distribution rules. However, the resulting high-dimensional configuration space makes it difficult for users to determine the best configuration options that can maximize application throughput given specific latency constraints, which is referred to as the constrained configuration tuning problem. Although many studies have been proposed to fulfill automatic software profiling, they have several limitations. First, they optimize throughput only, which assumes throughput and latency are strictly inversely proportional but this is not true for concurrent systems. Second, although some studies regard the optimization objective as a proportional summation of latency and throughput, the explicit latency limitation may not be consistently guaranteed. Third, existing approaches iteratively search the optimal configuration by discretizing parameter ranges, which may result in local optimum, however, most DMS parameters are continuous. To overcome these challenges, we propose a novel, automatic configuration tuning system called DMSConfig, which combines conventional machine learning methods and popular deep reinforcement learning. DMSConfig explores the configuration space by interacting with a data-driven environment prediction model (a DMS simulator), which eliminates the prohibitive cost of conducting online interactions with the production environment. We develop an emulation-based testbed to accelerate the data collection process when building the DMS simulator. DMSConfig employs the deep deterministic policy gradient (DDPG) method and a custom reward mechanism to learn and make configuration decisions based on predicted DMS states and performance. Since the environment model is decoupled with our optimization objectives, DMSConfig is highly adaptive to serve tuning requests with different latency boundaries.We validated the performance of DMSConfig on a representative DMS (Kafka for this paper) under 9 use cases and 7 latency constraint conditions. Experimental results show that DMSConfig performs significantly better than the default configuration and has better adaptability to CPU and bandwidth-limited environment. We also achieve almost the same throughput as three prevalent parameter tuning tools, but with fewer violations of latency constraints. CCS CONCEPTS \u2022 Software and its engineering\u2192 Software configurationmanagement and version control systems; \u2022 Computing methodologies\u2192 Policy iteration.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhuangwei Kang"
        },
        {
            "affiliations": [],
            "name": "Yogesh D. Barve"
        },
        {
            "affiliations": [],
            "name": "Shunxing Bao"
        },
        {
            "affiliations": [],
            "name": "Abhishek Dubey"
        },
        {
            "affiliations": [],
            "name": "Aniruddha Gokhale"
        }
    ],
    "id": "SP:6377377a312fbf7050eeb6f293cf685b7f13ff4f",
    "references": [
        {
            "authors": [
                "Takuya Akiba",
                "Shotaro Sano",
                "Toshihiko Yanase",
                "Takeru Ohta",
                "Masanori Koyama"
            ],
            "title": "Optuna: A next-generation hyperparameter optimization framework",
            "venue": "In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
            "year": 2019
        },
        {
            "authors": [
                "Sowmya Balasubramanian",
                "Dipak Ghosal",
                "Eric Pouyoul",
                "Alex Sim",
                "Kesheng Wu",
                "Brian Tierney"
            ],
            "title": "Autotuned publisher in a pub/sub system: Design and performance evaluation",
            "venue": "IEEE International Conference on Autonomic Computing (ICAC)",
            "year": 2018
        },
        {
            "authors": [
                "Liang Bao",
                "Xin Liu",
                "Ziheng Xu",
                "Baoyin Fang"
            ],
            "title": "Autoconfig: Automatic configuration tuning for distributed message systems",
            "venue": "In Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering",
            "year": 2018
        },
        {
            "authors": [
                "Zhendong Bei",
                "Zhibin Yu",
                "Huiling Zhang",
                "Wen Xiong",
                "Chengzhong Xu",
                "Lieven Eeckhout",
                "Shengzhong Feng"
            ],
            "title": "RFHOC: a random-Forest approach to auto-tuning Hadoop\u2019s configuration",
            "venue": "IEEE Transactions on Parallel and Distributed Systems 27,",
            "year": 2015
        },
        {
            "authors": [
                "James Bergstra",
                "Dan Yamins",
                "David D Cox"
            ],
            "title": "Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms",
            "venue": "In Proceedings of the 12th Python in science conference,",
            "year": 2013
        },
        {
            "authors": [
                "Hui Dou",
                "Pengfei Chen",
                "Zibin Zheng"
            ],
            "title": "Hdconfigor: Automatically Tuning High Dimensional Configuration Parameters for Log Search Engines",
            "venue": "IEEE Access",
            "year": 2020
        },
        {
            "authors": [
                "Florian Forster",
                "S Harl"
            ],
            "title": "collectd\u2013the system statistics collection daemon",
            "year": 2012
        },
        {
            "authors": [
                "Julien Gascon-Samson",
                "Franz-Philippe Garcia",
                "Bettina Kemme",
                "J\u00f6rg Kienzle"
            ],
            "title": "Dynamoth: A scalable pub/sub middleware for latency-constrained applications in the cloud",
            "venue": "In 2015 IEEE 35th International Conference on Distributed Computing Systems",
            "year": 2015
        },
        {
            "authors": [
                "Julien Gascon-Samson",
                "J\u00f6rg Kienzle",
                "Bettina Kemme"
            ],
            "title": "Multipub: Latency and cost-aware global-scale cloud publish/subscribe",
            "venue": "IEEE 37th International Conference on Distributed Computing Systems (ICDCS)",
            "year": 2017
        },
        {
            "authors": [
                "Yongfeng Gu",
                "Yuntianyi Chen",
                "Xiangyang Jia",
                "Jifeng Xuan"
            ],
            "title": "Multiobjective configuration sampling for performance ranking in configurable systems",
            "venue": "26th Asia-Pacific Software Engineering Conference (APSEC)",
            "year": 2019
        },
        {
            "authors": [
                "Jonathan Hasenburg",
                "Florian Stanek",
                "Florian Tschorsch",
                "David Bermbach"
            ],
            "title": "Managing Latency and Excess Data Dissemination in Fog-Based Publish/Subscribe Systems",
            "venue": "IEEE International Conference on Fog Computing (ICFC)",
            "year": 2020
        },
        {
            "authors": [
                "HerodotosHerodotou",
                "Yuxing Chen",
                "Jiaheng Lu"
            ],
            "title": "A Survey onAutomatic Parameter Tuning for Big Data Processing Systems",
            "venue": "ACM Computing Surveys (CSUR) 53,",
            "year": 2020
        },
        {
            "authors": [
                "Herodotos Herodotou",
                "Fei Dong",
                "Shivnath Babu"
            ],
            "title": "No one (cluster) size fits all: automatic cluster sizing for data-intensive analytics",
            "venue": "In Proceedings of the 2nd ACM Symposium on Cloud Computing",
            "year": 2011
        },
        {
            "authors": [
                "Changwu Huang",
                "Yuanxiang Li",
                "Xin Yao"
            ],
            "title": "A survey of automatic parameter tuning methods for metaheuristics",
            "venue": "IEEE Transactions on Evolutionary Computation 24,",
            "year": 2019
        },
        {
            "authors": [
                "Frank Hutter",
                "Holger H Hoos",
                "Kevin Leyton-Brown"
            ],
            "title": "Sequential modelbased optimization for general algorithm configuration",
            "venue": "In International conference on learning and intelligent optimization",
            "year": 2011
        },
        {
            "authors": [
                "Shweta Khare",
                "Hongyang Sun",
                "Kaiwen Zhang",
                "Julien Gascon-Samson",
                "Aniruddha Gokhale",
                "Xenofon Koutsoukos",
                "Hamzah Abdelaziz"
            ],
            "title": "Scalable edge computing for low latency data dissemination in topic-based publish/subscribe",
            "venue": "IEEE/ACM Symposium on Edge Computing (SEC)",
            "year": 2018
        },
        {
            "authors": [
                "D Kim andM Zarri"
            ],
            "title": "Road to 5G: Introduction and migration",
            "year": 2018
        },
        {
            "authors": [
                "Vijay R Konda",
                "John N Tsitsiklis"
            ],
            "title": "Actor-critic algorithms. In Advances in neural information processing",
            "year": 2000
        },
        {
            "authors": [
                "Palden Lama",
                "Xiaobo Zhou"
            ],
            "title": "Aroma: Automated resource allocation and configuration of mapreduce environment in the cloud",
            "venue": "In Proceedings of the 9th international conference on Autonomic computing",
            "year": 2012
        },
        {
            "authors": [
                "Paul Le Noac\u2019H",
                "Alexandru Costan",
                "Luc Boug\u00e9"
            ],
            "title": "A performance evaluation of Apache Kafka in support of big data streaming applications",
            "venue": "IEEE International Conference on Big Data (Big Data)",
            "year": 2017
        },
        {
            "authors": [
                "Guoliang Li",
                "Xuanhe Zhou",
                "Shifu Li",
                "Bo Gao"
            ],
            "title": "Qtune: A query-aware database tuning system with deep reinforcement learning",
            "venue": "Proceedings of the VLDB Endowment 12,",
            "year": 2019
        },
        {
            "authors": [
                "Andy Liaw",
                "Matthew Wiener"
            ],
            "title": "Classification and regression by randomForest",
            "venue": "R news 2,",
            "year": 2002
        },
        {
            "authors": [
                "Timothy P Lillicrap",
                "Jonathan J Hunt",
                "Alexander Pritzel",
                "Nicolas Heess",
                "Tom Erez",
                "Yuval Tassa",
                "David Silver",
                "Daan Wierstra"
            ],
            "title": "Continuous control with deep reinforcement learning",
            "year": 2015
        },
        {
            "authors": [
                "Ashraf Mahgoub",
                "Paul Wood",
                "Sachandhan Ganesh",
                "Subrata Mitra",
                "Wolfgang Gerlach",
                "Travis Harrison",
                "Folker Meyer",
                "Ananth Grama",
                "Saurabh Bagchi",
                "Somali Chaterji"
            ],
            "title": "Rafiki: a middleware for parameter tuning of nosql datastores for dynamic metagenomics workloads",
            "venue": "In Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference",
            "year": 2017
        },
        {
            "authors": [
                "Daniel Minoli",
                "Benedict Occhiogrosso"
            ],
            "title": "Practical aspects for the integration of 5G networks and IoT applications in smart cities environments",
            "venue": "Wireless Communications and Mobile Computing",
            "year": 2019
        },
        {
            "authors": [
                "Volodymyr Mnih",
                "Koray Kavukcuoglu",
                "David Silver",
                "Alex Graves",
                "Ioannis Antonoglou",
                "Daan Wierstra",
                "Martin Riedmiller"
            ],
            "title": "Playing atari with deep reinforcement learning",
            "year": 2013
        },
        {
            "authors": [
                "Alexandr Murashkin",
                "Micha\u0142 Antkiewicz",
                "Derek Rayside",
                "Krzysztof Czarnecki"
            ],
            "title": "Visualization and exploration of optimal variants in product line engineering",
            "venue": "In Proceedings of the 17th International Software Product Line Conference",
            "year": 2013
        },
        {
            "authors": [
                "Vivek Nair",
                "Tim Menzies",
                "Norbert Siegmund",
                "Sven Apel"
            ],
            "title": "Using bad learners to find good configurations",
            "venue": "In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering",
            "year": 2017
        },
        {
            "authors": [
                "Atri Sarkar",
                "Jianmei Guo",
                "Norbert Siegmund",
                "Sven Apel",
                "Krzysztof Czarnecki"
            ],
            "title": "Cost-efficient sampling for performance prediction of configurable systems (t)",
            "venue": "In 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
            "year": 2015
        },
        {
            "authors": [
                "Tom Schaul",
                "John Quan",
                "Ioannis Antonoglou",
                "David Silver"
            ],
            "title": "Prioritized experience replay",
            "venue": "arXiv preprint arXiv:1511.05952",
            "year": 2015
        },
        {
            "authors": [
                "Jacqueline Stewart",
                "Robert Stewart",
                "Sean Kennedy"
            ],
            "title": "Dynamic iot management system using k-means machine learning for precision agriculture applications",
            "venue": "In Proceedings of the Second International Conference on Internet of things, Data and Cloud Computing",
            "year": 2017
        },
        {
            "authors": [
                "David G Sullivan",
                "Margo I Seltzer",
                "Avi Pfeffer"
            ],
            "title": "Using probabilistic reasoning to automate software tuning",
            "venue": "ACM SIGMETRICS Performance Evaluation Review 32,",
            "year": 2004
        },
        {
            "authors": [
                "Yizhan Sun",
                "Alva Couch"
            ],
            "title": "Complexity of system configuration management",
            "venue": "In Handbook of Network and System Administration",
            "year": 2008
        },
        {
            "authors": [
                "Dana Van Aken",
                "Andrew Pavlo",
                "Geoffrey J Gordon",
                "Bohan Zhang"
            ],
            "title": "Automatic database management system tuning through large-scale machine learning",
            "venue": "In Proceedings of the 2017 ACM International Conference on Management of Data",
            "year": 2017
        },
        {
            "authors": [
                "Luis M Vaquero",
                "F\u00e9lix Cuadrado"
            ],
            "title": "Auto-tuning distributed stream processing systems using reinforcement learning",
            "venue": "arXiv preprint arXiv:1809.05495",
            "year": 2018
        },
        {
            "authors": [
                "Tiantian Wang",
                "Mark Harman",
                "Yue Jia",
                "Jens Krinke"
            ],
            "title": "Searching for better configurations: a rigorous approach to clone evaluation",
            "venue": "In Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering",
            "year": 2013
        },
        {
            "authors": [
                "Zhenghe Wang",
                "Wei Dai",
                "Feng Wang",
                "Hui Deng",
                "Shoulin Wei",
                "Xiaoli Zhang",
                "Bo Liang"
            ],
            "title": "Kafka and its using in high-throughput and reliable message distribution",
            "venue": "In 2015 8th International Conference on Intelligent Networks and Intelligent Systems (ICINIS)",
            "year": 2015
        },
        {
            "authors": [
                "Tianyin Xu",
                "Yuanyuan Zhou"
            ],
            "title": "Systems approaches to tackling configuration errors: A survey",
            "venue": "ACM Computing Surveys (CSUR) 47,",
            "year": 2015
        },
        {
            "authors": [
                "Ji Zhang",
                "Yu Liu",
                "Ke Zhou",
                "Guoliang Li",
                "Zhili Xiao",
                "Bin Cheng",
                "Jiashu Xing",
                "Yangtao Wang",
                "Tianheng Cheng",
                "Li Liu"
            ],
            "title": "An end-to-end automatic cloud database tuning system using deep reinforcement learning",
            "venue": "In Proceedings of the 2019 International Conference on Management of Data",
            "year": 2019
        },
        {
            "authors": [
                "Yuqing Zhu",
                "Jianxun Liu",
                "Mengying Guo",
                "Yungang Bao",
                "Wenlong Ma",
                "Zhuoyue Liu",
                "Kunpeng Song",
                "Yingchun Yang"
            ],
            "title": "Bestconfig: tapping the performance potential of systems via automatic configuration tuning",
            "venue": "In Proceedings of the 2017 Symposium on Cloud Computing",
            "year": 2017
        },
        {
            "authors": [
                "Yuqing Zhu",
                "Jianxun Liu",
                "Mengying Guo",
                "Wenlong Ma",
                "Yungang Bao"
            ],
            "title": "ACTS in need: Automatic configuration tuning with scalability guarantees",
            "venue": "In Proceedings of the 8th Asia-Pacific Workshop on Systems",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "To overcome these challenges, we propose a novel, automatic configuration tuning system called DMSConfig, which combines conventional machine learning methods and popular deep reinforcement learning. DMSConfig explores the configuration space by interacting with a data-driven environment prediction model (a DMS simulator), which eliminates the prohibitive cost of conducting online interactions with the production environment. We develop an emulation-based testbed to accelerate the data collection process when building the DMS simulator. DMSConfig employs the deep deterministic policy gradient (DDPG) method and a custom reward mechanism to learn and make configuration decisions based on predicted DMS states and performance. Since the environment model is decoupled with our optimization objectives, DMSConfig is highly adaptive to serve tuning requests with different latency boundaries.We validated the performance of DMSConfig on a representative DMS (Kafka for this paper) under 9 use cases and 7 latency constraint conditions. Experimental results show that DMSConfig performs significantly better than the default configuration and has better adaptability to CPU and bandwidth-limited environment. We also achieve almost the same throughput as three prevalent parameter tuning tools, but with fewer violations of latency constraints.\nCCS CONCEPTS \u2022 Software and its engineering\u2192 Software configurationmanagement and version control systems; \u2022 Computing methodologies\u2192 Policy iteration.\nKEYWORDS Publish/Subscribe Middleware, System Configuration, Policy-based RL Algorithm"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "With the advancement of bandwidth infrastructures, it has become a trend to migrate Internet of Things(IoT) devices to fast networks (5G)[23, 31], which is conducive to resolving performance degradation arisen by network instability and bandwidth limitations in IoT environments. Nevertheless, to leverage and augment the practical utility of 5G networks, it is vital to ensure the rationality of the design and configurations of IoT software at the application level first. Many IoT application domains, such as smart cities and smart grids, employ distributed message system(DMS) as the middleware for data transmission through which data samples can be produced, disseminated and consumed asynchronously. To ensure flexibility in a wide range of deployment scenarios, system topologies and runtime specifications, industrial-strength DMS provide users with a set of configurable parameters that have different data types (e.g., numeric, boolean, categorical) and value ranges, which consequently constitute a hybrid, multidimensional configuration space. These parameters control application runtime behaviors and resource allocation strategies resulting in different variations of application performance measured across different metrics, such as throughput, latency, CPU utilization, etc. Although DMS software is typically equipped with a default profile for the sake of general applicability, the default profile may not consistently guarantee optimal performance under a wide range of deployment use cases and QoS constraints(justify in section 4). Making prudent configuration decisions requires fine-grained domain knowledge and in-depth understanding of the impact of each parameter on application performance, as well as their unseen interactions, which is challenging even for experts, not to mention common users. Besides, na\u00efve exhaustive search methods are laborious, time-consuming, suboptimal and not scalable. Hence, this paper delves into developing an intelligent and automated configuration recommendation system ar X iv :2 30 2. 09 14 6v 1 [ cs\n.S E\n] 1\n7 Fe\nb 20\nfor DMS that aims to optimize application throughput with specific latency constraints, which meets the demand of practical IoT streaming applications that usually have stringent requirements on both throughput and response time. We formally term the problem as a constrained configuration optimization problem(more details are available in Section 2) and choose Apache Kafka [9] as an example to illustrate our approach as it is one of the most popular DMSs in the last decade. Note that since our approach is not tied to Kafka and its system components are fully decoupled, it is applicable to other DMS implementations as well.\nThe published literature[14, 16, 44] suggest that there are three representative classes of approaches in the state-of-the-art configuration tuning domain:\nSearch-based Methods (SBM), as in [33, 42, 47], iteratively evaluate candidate configurations derived from heuristic rules and historical experience, and gradually narrow the search space based on observed application performance. Such online search algorithms require less tuning time; however, they incur the following limitations: (1) designing a practical heuristic function is challenging, particularly if the objective function is subjected to some conditions; (2) the heuristic algorithms cannot guarantee global optimum; and (3) the entire search process needs to be restarted if the optimization objective or constraint condition is out of date.\nPrediction-based Methods (PBM), like [30, 34, 35, 40], are the most straightforward and general approaches that first build an offline performance prediction model based on a pre-collected training dataset and then couple the learned model with some heuristic searching strategies (e.g., genetic algorithms or recursive random search) to discover the near-optimal configuration. The pretrainedmodel acts as a simulator of the target application during the tuning process through which the search engine can rapidly explore the configuration space. Thus, PBM is more likely to discover the near-optimal configuration. Such data-driven methods also enable the tuner to quickly adapt different optimization objectives and QoS constraints with no need to re-interact with the target application. Despite the above advantages, the most critical barrier in adopting PBM is building an accurate performance prediction model because it needs a large volume of training data, which is hard to collect in production environments.\nRank-basedMethods (RBM), such as [3, 12, 46], cope with the challenges of PBM by reducing information granularity required by the searching stage. Rather than predicting the exact value of performance metrics, RBM builds a machine learning model to estimate the rank order of configurations. Since any two observations can form a training sample, ( \ud835\udc5b2 ) = \ud835\udc5b (\ud835\udc5b\u22121) 2 , the training set is significantly augmented. However, RBM is infeasible in constrained optimization scenarios because such gray-box methods do not capture exact values of performance metrics during the training phase. Also, prior efforts study the continuous configuration space in a discrete manner; nonetheless, deciding the length of sub-intervals for each parameter in every iteration is rather hard since parameters typically have different importance, value range, and nonlinear correlation.\nTo tackle the constrained configuration optimization problem and make up for the gaps in the above-mentioned approaches, we develop a novel DMS configuration recommendation system called\nDMSConfig that combines container-based emulation techniques, conventional machine learning, and the deep deterministic policy gradient (DDPG[29]) reinforcement learning(RL) algorithm. DMSConfig falls in the category of PBM and contains three main stages: data collection, DMS simulator training, and configuration tuning. However, DMSConfig significantly alleviates the limitations in PBM. For instance, in the data collection phase, we leverage container and traffic control techniques to emulate practical DMS production environments in terms of CPU, memory, and bandwidth, which enhance adaptivity of our system in practice. Moreover, owing to the resource isolation fulfilled by container virtualization, we can maximize the resource utilization rate of physical nodes and evaluate multiple configurations in parallel to significantly alleviate the burden of data collection cost. We adopt the random forest (RF) algorithm to train our DMS simulator that takes ten of the most performance-relevant parameters as input and forecasts five Kafka internal state metrics, publisher-side throughput, and latency. DMSConfig uses DDPG to find the near-optimal configuration under the latency constraint for the following reasons: (1) the sequential decision-making(SDM) process in RL coincides with the essence of iterative parameter adjustment; (2) DDPG has been proven a robust approach for settling continuous control problems(continuous configuration in our context); (3) the reward function in RL guides the tuning process by applying revenue or penalty to the agent, which satisfies our demand for throughput and latency simultaneously; (4) driven by the model-based DMS simulator and RL reward mechanism, DMSConfig can rapidly adapt tuning requests that have different latency constraints.\nWe conducted extensive experiments under 5 dimensions of external settings, including message size, producer amount, producer CPU number, and bandwidth. Experimental results show that in 9 experimental use cases, DMSConfig outperforms the default configuration by 12%-538% and guarantees near-optimal throughput performance under scenarios with limited CPU or bandwidth resources. Compared to three state-of-the-arts automated parameter tuning frameworks, DMSConfig provides analogous throughput, but more reliable latency assurance on 7 levels of latency constraints.\nIn summary, this paper makes the following contributions:\n(1) We develop an intelligent and automated configuration recommendation system, which can automatically find the configuration that maximizes the producer-side throughput and meets latency restriction in IoT scenarios despite the presence of a continuous high-dimensional configuration space; (2) We design an effective reward function for DDPG that accelerates the speed of locating high-quality Kafka configurations for latency-aware producers; (3) We create a performance prediction model that can successfully estimate Kafka internal state and performance metrics for a given workload and system topology; and (4) We develop a full-stack, container-based Kafka emulation andmonitoring system that is practical for conducting emulationbased Kafka benchmark tasks.\nThe remainder of the paper is organized as follows: Section 2 formulates the constraint configuration problem for DMS; Section 3 depicts the architecture and workflow of our DMSConfig solution; in Section 4, we present the design of experiments, and compare the\nperformance of DMSConfig, Kafka default configuration and three baseline approaches under multiple IoT use cases; Comparison with related research appears in Section 5; and finally, we summarize this paper and lessons learned in Section 6."
        },
        {
            "heading": "2 MOTIVATION AND PROBLEM FORMULATION",
            "text": "A distributed message system, as shown in Figure 1, is composed of three entity types namely: brokers, producers, and consumers. Brokers are responsible for receiving, persisting, and forwarding events dispatched by producers. The subscribing mechanisms on the consumer-side differ across DMS implementations, which may include pull-based (e.g., Kafka, RocketMQ, etc.) and push-based (e.g., RabbitMQ, ActiveMQ, etc.) subscription patterns. Therefore, to maximize system capacity and develop a general solution to automated configuration, we choose to optimize producer-side throughput, which is the amount of data that brokers can serve per unit time. On the other hand, although throughput and latency are inversely proportional in simple, synchronous applications, their relationship becomes fuzzy for concurrent systems with complex networking topologies as in IoT systems. For instance, in DMS deployed in IoT networks, latency is jointly affected by many factors including system parallelism, message backlog, micro-batching, message retransmission, etc. Hence, there is a need to take bounded latency into account while optimizing producer throughput because the service-level objective is usually multifold for practical streaming workloads rather than only throughput.\nTo this end, this paper delves into the constrained configuration problem for distributed message systems, shortened as the CCDMS problem. Next, we define fundamental components of the CCDMS problem and formulate the problem formally.\nConfiguration Space: The fundamental unit of configuration space \ud835\udc36\ud835\udc43 is an individual parameter \ud835\udc5d , whose value is in a continuous real range (numeric parameters) or in a finite discrete set (boolean and category parameters). We designate boundaries of numeric parameters according to the Kafka manual[20] and practical experience. Also, we index the value of a discrete parameter by its position in the array. Furthermore, we model one configuration as a vector \u00ae\ud835\udc36 of parameters that are deployed when the application is launched and consider it immutable at runtime.\nResource Profile: Resource profile \ud835\udc45 involves information on the number of CPU cores \ud835\udc62, available physical memory\ud835\udc5a, and free disk space \ud835\udc51 assigned to each entity, and the overall bandwidth \ud835\udc4f in the system. Collectively, we model it as a matrix \ud835\udc45 = {\u00ae\ud835\udc62, \u00ae\ud835\udc5a, \u00ae\ud835\udc51, \u00ae\ud835\udc4f}, where columns indicate resource types and rows reflect details of each entity.\nWorkload and Topology: Let \ud835\udc4a = (\ud835\udc53 , \ud835\udc59, \ud835\udc60, \ud835\udc5f ) be the unified workload snapshot for producers, where \ud835\udc53 denotes the number of messages emitted by producers per second, \ud835\udc59 is the length of the messages, \ud835\udc60 indicates the sending mode of messages (synchronous or asynchronous), and \ud835\udc5f refers to the transmission reliability (best effort or reliable). Further, we model application topology \ud835\udc47 as \ud835\udc47 = (\ud835\udc41\ud835\udc5d , \ud835\udc41\ud835\udc4f , \ud835\udc41\ud835\udc50 ), referring to the number of producers (\ud835\udc41\ud835\udc5d ), brokers (\ud835\udc41\ud835\udc4f ), and consumers (\ud835\udc41\ud835\udc50 ) in the application, respectively.\nObjective: The goal of CCDMS is to maximize throughput \ud835\udc47\ud835\udc43 given a latency constraint \ud835\udc3f\ud835\udc50 , where\ud835\udc47\ud835\udc43 denotes overall messages acknowledged by brokers per second, and \ud835\udc3f\ud835\udc50 is the restriction imposed on system latency (average latency of all producers). In summary, we formulate the CCDMS problem as follows:\nmax \ud835\udc36\u2208\ud835\udc36\ud835\udc43 \ud835\udc47\ud835\udc43 (\ud835\udc4a,\ud835\udc47, \ud835\udc45,\ud835\udc36) s.t. \ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc50\ud835\udc66 \u2264 \ud835\udc3f\ud835\udc50 (1)\nSince most DMS parameters are continuous and searching for the optimal configuration in such a space is proven to be NP-hard [39], we cast the problem of CCDMS into an RL task that learns a trajectory approaching the optimal configuration through a trial-anderror strategy. RL is a branch of machine learning that is originally inspired by the behaviorist theory in psychology and has succeeded in many stochastic optimization problems. The theoretical basis for RL are Markov Decision Processes. Specifically, a Markov Decision Process is defined by a four-tuple\ud835\udc40 = {\ud835\udc46,\ud835\udc34, \ud835\udc45,\ud835\udc47 }, where \ud835\udc46 denotes all possible states in the environment and \ud835\udc34 is the action space. The reward function \ud835\udc45 \u223c \ud835\udc5f (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 ) estimates the immediate revenue of taking an action \ud835\udc4e\ud835\udc61 \u2208 \ud835\udc34 under state \ud835\udc60\ud835\udc61 \u2208 \ud835\udc46 at each decision epoch \ud835\udc61 . The transition of agent states is governed by a conditional probabilistic function \ud835\udc47 = \ud835\udc43{\ud835\udc60\ud835\udc61+1 = \ud835\udc60 \u2032 |\ud835\udc60\ud835\udc61 = \ud835\udc60, \ud835\udc4e\ud835\udc61 = \ud835\udc4e}. There might be multiple executable actions with diverse transition probabilities for any state, yielding different subsequent states and long-term returns. By continuously interacting with the environment \ud835\udf16 , the agent aims to find an optimal policy \ud835\udf0b\u2217 by maximizing the expected accumulated discounted rewards over the future through taking effective actions in any state, denoted as \ud835\udf0b\u2217 : \ud835\udc46 \u2192 \ud835\udc34. Therefore, the state value function under policy \ud835\udf0b\u2217 is:\n\ud835\udc49\u2217 (\ud835\udc60) = max \ud835\udf0b \u2208\u03a0 \ud835\udc49\ud835\udf0b (\ud835\udc60)\n= max \ud835\udf0b \u2208\u03a0 \ud835\udc38\ud835\udf0b [ \u221e\u2211\ufe01 \ud835\udc61=0 \ud835\udefe\ud835\udc61\ud835\udc5f (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 ) |\ud835\udc600 = \ud835\udc60 ] ,\u2200\ud835\udc60 \u2208 \ud835\udc46\n(2)\n, where \ud835\udefe is the discount factor in range [0, 1], representing the trade-off between immediate and future rewards. A larger \ud835\udefe indicates the agent is more interested in short-term revenues. Eq. 2 implies that the state value at an arbitrary step is determined only by the instantaneous reward and the consecutive state value, thereby, the optimization criteria of MDP can be recursively represented as follows, known as Bellman Optimality Equation (BOE):\n\ud835\udc49\u2217 (\ud835\udc60) = max \ud835\udc4e\n\ud835\udc38 [ \ud835\udc5f (\ud835\udc60, \ud835\udc4e) + \ud835\udefe\ud835\udc49\u2217 (\ud835\udc60 \u2032)\n\ud835\udc600 = \ud835\udc60],\u2200\ud835\udc60 \u2208 \ud835\udc46 (3) The above equation shows that the original optimization problem is decomposed into seeking the best single-step action. The agent incrementally enhances the likelihood of selecting high-quality actions through trial and error until it can obtain the maximum state value in any state. Meanwhile, the exported optimal policy\ncan navigate the agent by acquiring the maximum accumulated return in the terminal state.\nAccordingly, we need to map the CCDMS problem to MDP context for which we define key components as follows:\n(1) Environment: The environment is the DMS being tuned. In our implementation, we use a pre-trained regression model to simulate a practice DMS environment, which takes a specific configuration as input and generates estimated DMS internal and external states. Note that the environment model is built based on a concrete workload, topology, and resource profile. (2) Agent: An intelligent configuration tuner based on a deep RL model is regarded as the agent. (3) Action: Action is represented as a vector of tunable DMS parameters. (4) State:We use a group of observable DMS internal metrics, represented as a vector, to describe DMS states. (5) Reward: Reward is the amount of throughput increment compared to that of the initial setting and the previous one. Further, we assign a penalty to the reward if the latency constraint is violated. More design details of the reward function are shown in Section 3. (6) Policy: In DMSConfig, we feed the agent state into a deep neural network, which then outputs a deterministic action that the agent should take. The policy network is iteratively updated based on the policy gradient method."
        },
        {
            "heading": "3 DMSCONFIG METHODOLOGY",
            "text": "We have set up the CCDMS problem formally. In this section, we introduce our approach DMSConfig, an automatic configuration optimization tool for distributed message systems. The architecture of DMSConfig is shown as figure 2. In this research on DMSConfig, we make the following assumptions: (1) all producers (or brokers) share the same configuration; (2) application workload and topology remain static when serving a tuning request; (3) all connections in the environment have identical bandwidth; (4) the emulation testbed is equipped with the same hardware as that of the production environment. Next, we introduce the workflow and architecture of DMSConfig."
        },
        {
            "heading": "3.1 Identifying Key Parameters",
            "text": "As mentioned in the first section, the fundamental challenge of the CCDMS problem sprang from its high-dimensional configuration space. Although there are considerable adjustable parameters in Kafka, only a small number of them have noticeable influence on application performance. Therefore, the purpose of this stage is to filter out unimportant parameters, which can help avoid the curse of dimensionality and improve model accuracy in latter steps. We identify vital parameters by the following steps: (1) refer Kafka manual and preceding benchmark results[26, 43] to roughly select some candidates; (2) evaluate the selected parameters using controlled experiments with the desired workload, and then observe performance variation to further prune redundant parameters. In the end, we identified the following list of important Kafka parameters and more details are available in Table 1:\n(1) num.network.threads: controls themaximumnumber of threads in the broker used to listen or respond to network requests. (2) num.io.threads: determines the number of I/O threads in the broker to process network requests. (3) queued.max.requests: protects the broker from being overwhelmed by high-speed producer data-flows by limiting the maximum number of requests per broker. Network threads are blocked once this threshold is triggered. (4) socket.receive.buffer.bytes: indicates the read buffer size of a socket connection, which controls the scale of ingress traffic. (5) socket.send.buffer.bytes: determines the socket write buffer size. A large buffer size helps broker to tolerate bursty egress traffic. (6) socket.request.max.bytes: sets the upper-bound of a single socket request to prevent the broker from beingmonopolized by large requests.\n(7) buffer.memory: restricts the maximum allocatable memory for the producer for buffering. If records are sent faster than they can be transmitted to the server, then this buffer space will be consumed. (8) batch.size: specifies the size of a single message batch. Microbatch is an effective mechanism for improving application throughput where messages are coalesced and sent in small chunks. This parameter enables batch processing to improve latency as it prevents applications from frequent system calls and network stack traversal. The overhead is that increasing the waiting time of messages in memory may degrade latency. (9) linger.ms: designates a delay before a batched request is transmitted. In Kafka, messages are dispatched as long as one of the conditions in linger.ms and batch.size is met. (10) compression.type: This parameter denotes the compaction method used by the producer, which includes four options: uncompressed, gzip, snappy, and lz4."
        },
        {
            "heading": "3.2 Testing Samples Generation",
            "text": "To expose the relationship between parameter combinations and performance as much as possible within a limited operation cost, we need an efficient sampling method to guarantee that the training set covers the configuration space uniformly. The Latin Hypercube Sampling(LHS)[18], as a representative space-filling sampling technique, satisfies our demand in this sense. Specifically, LHS divides the range of each parameter into \ud835\udc41 equally probable intervals, where \ud835\udc41 denotes the number of desired samples. Then, for each parameter, it performs a stochastic sampling within a randomly selected interval. By iteratively performing random sampling without replacement, LHS ensures that values within the same interval at most appear once, thus evenly covering the sampling space."
        },
        {
            "heading": "3.3 Benchmark and Data Collection",
            "text": "Data collection is one of the most critical procedures for data-driven approaches as it is highly-coupled to model accuracy. However, a practical challenge we confront is how to collect data efficiently given the limitations on operational budget and accessible hardware resources. Compared to tasks in monolithic applications, this is harder for distributed systems like DMS because (1) they usually occupy more physical resources; (2) collected data may be noisy due to unpredictable network jitter; (3) the startup and cool-down time is relatively longer. Although LHS can represent the configuration space using much fewer samples than na\u00efve grid or random sampling methods, evaluating 1000 configurations, for instance, still takes 25 hours, assuming we run 90 seconds to observe reliable performance metrics for each trial. If this is multiplied by the number of combinations of workload patterns and application topologies, the data collection phase would take a few weeks, which is certainly unacceptable. However, we argue that this cost can be linearly reduced using a container-based emulation testbed. Specifically, we use container virtualization technology to isolate the resources of physical nodes to parallelize the experimental process. Below we illustrate the feasibility of parallelizing experiments.\nAs claimed in [19], the Kafka server is not compute-intensive, so in most cases, the CPU and memory of physical nodes are not fully\nutilized in such benchmark tasks. To justify this and make reasonable resource allocation decisions for Kafka server, we performed a pressure test for a Kafka server in which it continuously processes high-frequency requests from 10 producers and consumers. As shown in Figure 3, the CPU and memory utilization rate of Kafka server is lower than 10%, and 40% percent, respectively, which inspires us to containerize benchmark applications. Docker container is a lightweight virtualization solution that uses Linux namespace and CGroup to isolate container processes and physical resources (CPU, memory, I/O devices) so that each application can run independently without interference by noisy neighbors. Also, bandwidth contention between applications augments data noise, consequently hindering testing multiple configurations simultaneously. However, these issues can be overcome using a container-based environment where the container engine creates a virtualized network interface for each container; thereby, we can employ some traffic shapers (e.g., Linux TC) to emulate span-node communication locally. As we execute containerized benchmark applications in a distributed manner, another practical problem we encountered is that deploying and managing large-scale short-live containers manually is tedious and laborious. Kubernetes(k8s) comes into our sight under this circumstance, as it is a widely accepted container orchestration platform for distributed applications.\nSpecifically, for each test, DMSConfig first generates configuration files for participating entities on the k8s master node, then copies them to a labeled remote worker using the \"scp\" command. On worker nodes, containers mount required configuration files from the host for future benchmark tasks. We leverage Kubernetes Python API to define container meta information and interact with the Kubernetes cluster. Once the containers are deployed, DMSConfig asynchronously executes the startup commands on each and redirects container I/O to the master node. By then DMSConfig can monitor experiment progress and record logs centrally. Note that each experiment is orchestrated by an independent thread on the master. When the specified experiment time is reached, the thread immediately terminates the containers that it supervises.\nWe capture three categories of data including Kafka server states, container statistics, and producer performance (throughput and latency). The first two types are collectively termed as Kafka internal\nmetrics, and the third is external metrics. Internal metrics reflect Kafka runtime behavior under specified input properties (workload, application topology, and resource distribution), used as states of our intelligent configurator in the configuration tuning phase to infer parameter adjustment decisions. External metrics directly characterize application performance. We leveraged Collectd [8] to collect the system metrics as well as the docker container metrics. Collectd is a popular tool for gathering system and application statistics, and it offers pluggable interfaces for subsequent data storage and visualization. We implemented a custom Collectd plugin called Kafka-Container-Collectd to monitor Kafka metrics running inside the docker containers. In DMSConfig, Collectd daemons are distributed over all physical hardware nodes in our cluster. The Kafka-Container-Collectd plugin periodically probes Kafka server containers on the host and queries the Kafka JMX agent for runtime metrics. Similarly, we used Collectd plugin Container-Collectd which accesses container states through the Docker Python API. Query results are then relayed to an InfluxDB database running on the master node through a Rabbitmq messaging bus. As for external metrics, we redirected outputs of Kafka producer performance test application[21] to log files on the master node and parse them after tests. We uniformly set the sampling frequency to 5 seconds, and select the 90th percentile of each metric as the effective measurement. For cumulative metrics, we calculate and store the difference between two consecutive measurements.\nIn summary, we empirically select 7 internal metrics as shown below to describe Kafka container status.\n(1) container.blkio.io_service_bytes: Indicates the number of bytes read and written by the cgroup. (2) container.cpu.usage_usermode: The amount of time the CPU was used executing tasks in user space. (3) container.cpu.usage_kernelmode: The amount of time the CPU was busy in kernel space. (4) container.memory.usage_total: The total memory the container is using. (5) kafka.produce.request.per_sec: The number of producer requests per second. (6) kafka.produce.request.total_time: Total time (in ms) to serve the specified producer request. (7) kafka.produce.request.temporary_bytes: Temporary memory used for message format conversions and decompression."
        },
        {
            "heading": "3.4 DMS Simulator Training",
            "text": "To build the DMS simulator that predicts the above Kafka internal state and performance metrics according to input configurations, we employ the random forest regression (RFR) algorithm to train the performance prediction model. Random forest is a non-parametric statistical learning technique that utilizes an effective ensemble-learning-based method that essentially performs a bootstrap aggregation (bagging) in which the final assessment decision is determined by the mean regression of a multitude of decision trees [28]. A decision tree is built by splits of nodes to adopt heuristic methods to partition the feature space. When splitting a node during the construction of a random forest, the forest takes a random subset of all features in the current state and chooses an effective slicing point. As each tree of the forest is constructed\nbased on the bootstrap resampling strategy on the original training set and input features, RFR performs well with a small data set and even high-dimensional feature space.\nFor given workload\ud835\udc4a\ud835\udc56 , topology \ud835\udc47\ud835\udc56 , and resource profile \ud835\udc45\ud835\udc56 , we train an independent RFR model whose input is a testing configuration \ud835\udc36\ud835\udc61 , and the output is predicted Kafka metrics \ud835\udc46\ud835\udc61 . Formally, the regression model acts as an implicit function \ud835\udc53 as defined in the equation 4:\n\ud835\udc46\ud835\udc61 \u2190 \ud835\udc53{\ud835\udc4a\ud835\udc56 ,\ud835\udc47\ud835\udc56 ,\ud835\udc45\ud835\udc56 } (\ud835\udc36\ud835\udc61 ) (4) Empirical results reveal that RFR achieves 84%-98% prediction accuracy, as shown in Figure 4, regarding selected Kafka metrics over 9 use cases(see section 4), where 1,000 training samples are used for each scenario. Hence, we demonstrate that the obtained regression models are reliable enough for the DMS simulator."
        },
        {
            "heading": "3.5 Configuration Tuning using DDPG",
            "text": "When solving the parameter optimization problem, most traditional heuristic approaches (such as genetic algorithm, random search, evolutionary algorithm, etc.) make a fundamental assumption that the parameter space is discrete, but this is not always true for DMS. To optimize tuning in continuous space, we train an intelligent configuration tuner leveraging the DDPG algorithm, which takes the continuity of the search space into account and enhances configuration improvement direction deterministically according to the current state. DDPG is an policy-policy deep reinforcement learning algorithm, combining Deep Q learning networks (DQN)[32] and Actor-Critic [24] methods. Specifically, it inherits from DQN and includes: (1) adopting a deep neural network to approximate the Q function, (2) using the Experience Replay mechanism to break the empirical data correlation caused by MDP. Actor-critic methods are Temporal Difference (TD) methods, where the TD approximates the current estimate based on the previously learned estimate. Thus, Actor-critic methods have a separate memory structure to explicitly represent the policy independent of the value function. Actor takes suggestion from Critic and generates a tuning action, environment that deploys the tuning action, and a reward value based on the performance change on the updated configuration. Critic criticizes the actions made by the actor and estimates the state value function. Thanks to the Actor-Critic method, DDPG can learn\nin high-dimensional continuous action spaces because it selects actions based on the policy gradient method instead of examining Q-value for every action as DQN does. Next, we describe more implementation details of DDPG and our design of the reward function.\n3.5.1 DDPG in DMSConfig. DDPG constructs four neural networks in light of the structural features of the Actor-Critic method with the Temporal Difference (TD) estimate principle, where both Actor andCritic have an online (\ud835\udf03\ud835\udc62 , \ud835\udf03\ud835\udc44 ) network and a target(\ud835\udf03\ud835\udf07\u2032, \ud835\udf03\ud835\udc44\u2032 ) network respectively. Each pair of online and target network share identical architectures. DDPG adopts a \"soft update\" approach to slowly blend theweights of online networks to corresponding target networks weights. The policy function \ud835\udc4e\ud835\udc56 = \ud835\udf07 (\ud835\udc60\ud835\udc56 |\ud835\udf03\ud835\udf07 ) is substituted by the actor-network \ud835\udf03\ud835\udf07 , which estimates the action \ud835\udc4e\ud835\udc56 that agent should perform in state \ud835\udc60\ud835\udc56 . To avert falling into the local optimum during training, we add Gaussian noise to action \ud835\udc4e\ud835\udc56 so that agent has opportunities to explore unknown searching areas. While interacting with the environment, the agent records the state transition \ud835\udc47\ud835\udc56 =< \ud835\udc60\ud835\udc56 , \ud835\udc4e\ud835\udc56 , \ud835\udc5f , \ud835\udc60\ud835\udc56+1 > into a fixed size Experience Replay Buffer (\ud835\udc38\ud835\udc45\ud835\udc35). When the Actor and Critic networks need to be updated, DDPG randomly extracts a minibatch \ud835\udc41 = {\ud835\udc471,\ud835\udc472, ...,\ud835\udc47\ud835\udc5b} from \ud835\udc38\ud835\udc45\ud835\udc35. Then for every record \ud835\udc47\ud835\udc56 , the online critic-network \ud835\udf03\ud835\udc44 takes \ud835\udc60\ud835\udc56 and \ud835\udc4e\ud835\udc56 as inputs, and outputs a Q value, \ud835\udc44 (\ud835\udc60\ud835\udc56 , \ud835\udc4e\ud835\udc56 |\ud835\udf03\ud835\udc44 ), indicating the benefit of executing \ud835\udc4e\ud835\udc56 in state \ud835\udc60\ud835\udc56 . Therefore, the actor policy should be updated along the direction instructed by the critic-network to improve Q-values and expose better actions, which is formally representing as equation 5:\n\u2207\ud835\udf03\ud835\udf07 \ud835\udc3d \u2248 1\n\ud835\udc41 \u2211\ufe01 \ud835\udc56 \u2207\ud835\udc4e\ud835\udc44 (\ud835\udc60, \ud835\udc4e |\ud835\udf03\ud835\udc44 ) |\ud835\udc60=\ud835\udc60\ud835\udc56 ,\ud835\udc4e=\ud835\udf07 (\ud835\udc60\ud835\udc56 )\u2207\ud835\udf03\ud835\udf07 \ud835\udf07 (\ud835\udc60 |\ud835\udf03 \ud835\udf07 ) |\ud835\udc60=\ud835\udc60\ud835\udc56 (5)\n, where \ud835\udc3d denotes all possible policies. As for the critic-network, it conducts back-prorogation to update weights of the neural network byminimizing the TD-error. Equation 6 shows the TD-error asmean square error between target Q-value and estimated Q-value:\n\ud835\udc3f(\ud835\udf03\ud835\udc44 ) = 1 \ud835\udc41 \u2211\ufe01 \ud835\udc56 (\ud835\udc66\ud835\udc56 \u2212\ud835\udc44 (\ud835\udc60\ud835\udc56 , \ud835\udc4e\ud835\udc56 |\ud835\udf03\ud835\udc44 )2) (6)\n, where \ud835\udc66\ud835\udc56 = \ud835\udc5f\ud835\udc56 + \ud835\udefe\ud835\udc44 \u2032(\ud835\udc60\ud835\udc56+1, \ud835\udf07 \u2032(\ud835\udc60\ud835\udc56+1 |\ud835\udf03\ud835\udf07 \u2032) |\ud835\udf03\ud835\udc44\u2032), denotes the target-\nQ-value.\nFigure 5: Architecture of DDPG\nThe actor-critic networks of DDPG is defined in Figure 5. Specifically, the actor-network contains two hidden layers with the ReLU activation function, a batch normalization(BN) layer, and an output layer activated by the Sigmoid function. As for the criticalnetwork, state and action vectors are first accepted by two parallel ReLU layers, and then being concatenated with another ReLU layer. Moreover, we replace the \ud835\udc38\ud835\udc45\ud835\udc35 in general DDPG with a prioritized \ud835\udc38\ud835\udc45\ud835\udc35 [36], which is proven effective in accelerating the convergence of actor policy[45]. In short, the prioritized \ud835\udc38\ud835\udc45\ud835\udc35 ranks transition samples from the minibatch based on the magnitude of TD-error, which significantly improves the diversity of samples.\n3.5.2 Reward Function. Eq. 6 and 5 suggest that the reward function is essential for DDPG navigating actor to update policy toward to the correct direction. Recalling Eq. 1, our optimization objective is to maximize throughput under latency constraint; thus, the reward function has three missions: (1) navigate agents to chose actions that have higher throughput than that at the initial state; (2) reward agents when the throughput gets improved compared to the previous step; (3) prevents agents from exceeding latency boundary.\nThe rationality of the reward function mission setup has been proofed in [27, 45] that when the reward function simultaneously compares current throughput with both of the initial state \ud835\udc470 and the previous step \ud835\udc47\ud835\udc61\u22121, the actor policy gains fastest convergence and best performance . Therefore, we inherit the same principle in [27, 45] and extend it to scenarios with strict latency constraints. Formally, let \ud835\udc47\ud835\udc61 and \ud835\udc3f\ud835\udc61 be throughput and latency responded by environment at timestamp \ud835\udc61 , respectively. Since configurations (actions), internal metrics (states) and external metrics(throughput, latency) have been normalized when we train the DMS simulator, we directly compute performance changes as follows: \u0394\ud835\udc47\ud835\udc61,0 = \ud835\udc47\ud835\udc61 \u2212\ud835\udc470 \u0394\ud835\udc47\ud835\udc61,\ud835\udc61\u22121 = \ud835\udc47\ud835\udc61 \u2212\ud835\udc47\ud835\udc61\u22121 \u0394\ud835\udc3f\ud835\udc61,\ud835\udc50 = \ud835\udc3f\ud835\udc61 \u2212 \ud835\udc3f\ud835\udc50\n, where \ud835\udc3f\ud835\udc50 indicates latency constraint constant. The overall reward function is designed as:\n\ud835\udc5f =\n{ (\u22121 \u2212 \u0394\ud835\udc3f\ud835\udc61,\ud835\udc50 ) \u230a \ud835\udc3f\ud835\udc61 \ud835\udc3f\ud835\udc50 \u230b ((1 + \u0394\ud835\udc47\ud835\udc61,0)2 \u2212 1) |1 + \u0394\ud835\udc47\ud835\udc61,\ud835\udc61\u22121 |,\u0394\ud835\udc47\ud835\udc61,0 > 0\n(1 + \u0394\ud835\udc3f\ud835\udc61,\ud835\udc50 ) \u230a \ud835\udc3f\ud835\udc61 \ud835\udc3f\ud835\udc50 \u230b ((1 \u2212 \u0394\ud835\udc47\ud835\udc61,0)2 \u2212 1) |1 \u2212 \u0394\ud835\udc47\ud835\udc61,\ud835\udc61\u22121 |,\u0394\ud835\udc47\ud835\udc61,0 \u2264 0\n(7) In summary, when throughput is better than that at the initial state(throughput of the default configuration) and latency satisfies the constraint, the latency penalty term is omitted; otherwise, the throughput part is shadowed by a negative latency multiplier. The more latency oversteps the boundary, the stronger the penalty. Similarly, if the throughput is worse than that in the initial state, and the latency boundary is crossed, we augment the overall penalty."
        },
        {
            "heading": "4 EVALUATION",
            "text": "In this section, we evaluate DMSConfig under 9 Kafka use cases and compare its performance with three mature configuration optimization tools and the default one provided by Kafka vendor. Besides, we examine 7 different levels of latency constraints for each use case to answer whether DMSConfig can successfully balance latency and throughput and obtain maximum profits meanwhile.\nExperiment Environment Our experiment environment comprises 10 AMDOpteron(tm) Processor 4170 HE nodes with 2.10GHz CPU speed, each with 12 physical cores, and 32GB memory; and their software specifications are as follows: Ubuntu 16.04 OS, Linux 4.4.0-157-generic kernel, JDK V1.8.0, Kubernetes V1.18, and Docker V19.03. All of the bare-metal machines are connected via a highspeed 1Gbps LAN. Moreover, as depicted in Section 3, we perform benchmarking tasks on a Kubernetes cluster, which contains a master node and nine worker nodes that communicate with each other through Flannel CNI.\nBenchmark Application We leverage the official Kafka performance evaluation application[21] to create streaming workloads and capture corresponding throughput and latency. Unless otherwise specified, each containerized Kafka server has 4CPUs and 8GB RAM. The producer is equipped with 2CPUs and 4GB RAM. As for the subscriber, we deploy 1CPU and 4GB RAM. It should be noted that since this paper primarily focus on optimizing throughput for latency-aware producers, we deploy a single broker and one subscriber for all tests. Producers and consumers send and consume messages at unrestricted frequencies, respectively. Additionally, we consider reliable communication only so that the Kafka server is required to acknowledge every message dispatched by producers.\nBaseline Techniques Sequential model-based Bayesian optimization is the mainstream scheme in the field of black-box optimization whose internal implementation is mainly based on (1) a surrogate model for predicting validation loss (2) and a heuristic acquisition function for selecting testing points sequentially. In contrast, we leverage the reward mechanism and policy gradient method of DDPG, rather than a prior-knowledge-base acquisition function, to lead a tuner incrementally improve the quality of selected parameters. Hyperopt[5], Optuna[1], and SMAC[17] are three representative implementations of SMBO. Hence, we use them as baselines and briefly summarize their basic information and working principle as below:\n\u2022 Hyperopt is a powerful hyper-parameter tuning instrument based on Bayesian optimization. We realize this optimizer using its open source Python library1 with Tree Parzen Estimators as the fitting model and expected improvement as the acquisition function.\n1http://hyperopt.github.io/\n\u2022 SMAC is also a Bayesian optimization solver. Likewise, our implementation is based on the SMAC3 2 library with default algorithm settings(Random Forests as the surrogate loss prediction model, logarithm expected improvement as the acquisition function). \u2022 Optuna: Optuna is regarded as the next-generation automatic hyper-parameter optimization software, which uses the same optimizationmethod as that of Hyperopt but equips an additional pruner to discard unpromising trials to improve sampling quality when choosing testing points. We implement experimental codes using their Python API3.\nTo make fair comparisons, we set the reward function, as shown in Eq. 7, as the objective function of all baseline algorithms. In addition, because it is extremely time-consuming to carry out online assessments on the practical testbed directly, we adopt the DMS simulator trained in section 3 to generate DMS external metrics needed for the objective function.\nExperiment Design Based on the previous Kafka benchmark experience[26, 43], we design 9 test cases to simulate various scenarios from the aspects of message size, producer computing capacity, network bandwidth, and producer quantity. We perform controlled experiments using configurations recommended by each tuner under these use cases, and run each for 90 seconds to obtain reliable performance metrics. To understand baseline performance and validate the effectiveness of DMSConfig, we execute the Kafka default configuration, as shown in table 1, with the same design of experiments. Table 2 shows experiment settings where the second is considered as the referential test for studying influences of different variables. In addition, we draw latency boundaries based on the default configuration and compute the latency constraint factor \ud835\udc59\ud835\udc50 \ud835\udc53 as the follow:\n\ud835\udc59\ud835\udc50 \ud835\udc53 = \ud835\udc3f\ud835\udc51\ud835\udc52\ud835\udc53 \ud835\udc4e\ud835\udc62\ud835\udc59\ud835\udc61\n\ud835\udc3f\ud835\udc50\n, where \ud835\udc3f\ud835\udc51\ud835\udc52\ud835\udc53 \ud835\udc4e\ud835\udc62\ud835\udc59\ud835\udc61 refers to the latency earned by the default configuration, and \ud835\udc3f\ud835\udc50 is the latency restriction set for tuners. Particularly, \ud835\udc59\ud835\udc50 \ud835\udc53 = 0 denotes there is no restriction for latency.\nExperiment Results In this section, we demonstrate our experiments results in terms of two evaluation metrics: throughput and latency violations. It is worth mentioning that the throughput mentioned here reflects the number of message bytes delivered successfully by producers, but it does not necessarily match the actual bandwidth usage due to message compression and concurrent communication under some settings. In the multi-producer cases (Test 8, 9), we sum the throughput accomplished by each producer as the overall throughput of the system. In addition, in the bar chart shown in figure 8-11, we texture the bar if a configuration fails to meet the specified latency constraint. In order to thoroughly understand the experiment results, we first analyze the performance of default configuration in different use cases, and then compare it with DMSConfig.\n2https://github.com/automl/SMAC3 3https://github.com/optuna/optuna"
        },
        {
            "heading": "1 16 32 14 26 20 463 32 117 347",
            "text": ""
        },
        {
            "heading": "2 32 16 22 35 12 463 36 108 161",
            "text": ""
        },
        {
            "heading": "4 20 14 12 46 24 536 22 106 229",
            "text": ""
        },
        {
            "heading": "6 12 14 16 42 12 518 32 69 203",
            "text": ""
        },
        {
            "heading": "8 -8 16 16 40 12 481 26 72 184",
            "text": ""
        },
        {
            "heading": "10 24 -24 18 35 16 481 34 68 183",
            "text": "Understand The Default Configuration From the message size tests, see figure 7, 8, we can see that under the single producer setting, when the message size increases from 0.1KB to 1KB, the throughput is doubled (25MB/sec-50MB/sec); however, as the message continues growing to 4KB, the throughput only increases by 4MB/sec (50MB/sec-54MB/sec). This shows that under the default configuration, the 1KB high-speed data stream can almost make Kafka server fully loaded (throughput is about 50MB/sec), which is consistent with the performance evaluation results from Kafka community [20]. As for producer CPU tests, figure 9 suggests the number of CPU may become performance bottleneck, because the producer with single core cannot use multithreading to process I/O requests. Besides, as can be noticed in figure 10, in the low bandwidth environment(0.1Gbps), the performance of the default configuration is significantly cut off. However, in the case of 0.5Gbps, the throughput is equal to that of the referential test 7, which indicates a single-producer will not cause network overload under current settings. However, when we run 10 producers simultaneously, as suggested in figure 11, the overall throughput is approximately equal to the physical bandwidth. (Message compression is disabled in the default configuration, so this statement holds.)\nComparison between DMSConfig and Default By comparing the configuration recommended by DMSConfig with the default one, we mainly answer two questions: 1) whether DMSConfig can suggest a better configuration evenwith latency constraints; 2) whether DMSConfig can make adaptive decisions to ensure optimization objectives when performance bottlenecks arise. We demonstrate comparison results in Table 3, where shaded cells represent the recommended configuration fails to meet the latency constraint. As can be seen from Table 3, DMSConfig achieved 8%-463% and 14%- 463% higher throughput than the default configuration, respectively, over 9 experiments in loose latency constraint conditions (\ud835\udc59\ud835\udc50 \ud835\udc53 = 0, \ud835\udc59\ud835\udc50 \ud835\udc53 = 1). However, as we augment the restriction, latency violation occurs more frequently since the default configuration is designed for optimal latency, as depicted in [6], which is most evident in the case of \ud835\udc59\ud835\udc50 \ud835\udc53 = 10. Overall, DMSConfig achieves 12%-538% throughput improvement over 7 levels of latency restrictions in 79.63% of tests(total 63). Concerning the second question, we focus on Test 4 and 6 as they are situations where the default configuration suffers. By comparing Figures 9 and 10, we can observe that DMSConfig can consistently sustain throughput at 58MB/sec-70MB/sec in CPU or bandwidth-constrained environment, which is almost the same as that of the control group(see Fig. 7). In summary, we claim DMSConfig is an effective approach to locate promising configurations in latency-aware DMS.\nComparison between DMSConfig and Baseline Algorithms In general, the difference in throughput between DMSConfig and the other three Bayasien-based baselines is trivial. Optuna is the most aggressive one in tracing a configuration with higher throughput; however, as can be noticed in Figure 6, it is also more likely to trigger latency constraint. In contrast, DMSConfig is more reliable in fulfilling latency restrictions with 20.37% violation percent, which is lower than other approaches."
        },
        {
            "heading": "5 RELATEDWORK",
            "text": "The fundamental problem in automating the Pub/Sub system configuration is to tackle the high dimensional configuration parameter space and complex combinatorial relationships among configuration knobs, which is similar to other network systems such as database management systems, distributed data analytic platforms, and web servers. To that end we compare prior efforts in configuration management for different systems."
        },
        {
            "heading": "5.1 Configuration Tuning optimization in network systems",
            "text": "Search-based methods solve the network systems configuration problem in a blackbox manner. Herodotou et al. integrated a recursive random search to tune the Hadoop cluster size [15]. Zhu et al. presented BestConfig to improve the system throughput via a divide-and-diverge sampling and a recursive bound-and-search algorithm [46]. Dou et al. employed a modified random embedding Bayesian search based algorithm to solve the configuration optimization problem on a search engine [7]. The search-based method\u2019s rudimentary problem is how to deal with a local search range and sample randomness at each search iteration.\nPrediction based methods establish performance prediction models after collecting different configuration sets. One of the challenges is that only a limited set of samples can be acquired under a given time constraint, especially for real production toolkits. Sarkar et al. enhanced projective sampling by incorporating two heuristics for performance prediction to sampling system cost efficiency [35]. Sullivan et al. employed an influence diagram formalism based method to predict the Berkeley DB performance under a givenworkload [38]. There are a few studies using machine learning to build a prediction model and tune distributed data analytic systems such as random forest [4], support vector machine [25], K-means [37].\nRanked based approaches reduce the training sets by ordering important parameters in discrete configuration space. Bao et al. proposed Autoconfig that first selects top \ud835\udc58 essential elements from a prediction model, then utilizes a weighted Latin Hypercube Sampling and a search algorithm to optimize Kafka system throughput [3]. Van et al. employed a ranked list to select the most impactful configuration parameters with a combination of supervised and unsupervised machine learning pipeline [40]. Nair et al. proposed a rank-based approach that ranks the difference between actual and predicted performance to optimize configurable systems [34]. Mahgoub et al. applied the ANOVA-based analysis to identify the key parameters that impact the throughput performance of several NoSQL databases [30]. In short, obtaining the discrete space from a continuous space is complicated and needs external tuning.\nAs prediction models are constructed, reinforcement learning (RL) is an efficient alternative way to find optimal configurations\ninstead of traditional search algorithms. Vaquero et al. presented an automated approach to recommend the most appropriate configurations for Spark workloads [41]. Their methods include supervised machine learning-based metrics ranking mechanism and Q learning-based RL based on the previous workload. Zhang et al. proposed CDBTune that utilizes the DDPG based deep RL with a reward-feedback mechanism to do online-tuning on the cloud database system\u2019s continuous configuration space. CDBTune is trained with a limited number of samples to avoid collecting massive samples [45]. Similarly, Li et al. extracted rich features of SQL queries, then the authors utilized a Double-State DDPG model that enables the actor-critic networks to tune the database configuration based on both the query vector and database states [27].\nOur work DMSConfig explores a near optimal configuration solution in continuous parameter space without splitting the space in discrete set in Pub/Sub stream processing software, which is the main difference from the above works."
        },
        {
            "heading": "5.2 Latency-aware constrained in Pub/Sub stream processing",
            "text": "The DMSConfig aims to hold the latency constraint in the Kafka platform layer. None of the above works explicitly discussed latency constraint in the software platform layer; instead, we care about the latency constraint QoS awareness. The relationship between latency and throughput is inverse if the message queuing size is fixed. However, with more IoT devices being deployed with 5G, the scalability of legacy stream processing systems is challenged by\nmeeting the tradeoff between throughput and latency. Some recent studies have investigated the pub/sub systems architecture component for latency-constrained distributed applications to reduce average response time and enhance outgoing message throughput.\nGascon-Samson et al. proposed Dynamoth to optimize systemlevel and channel level load-balancing [10]. The balancing enables the Redis Pub/Sub system to scale to arbitrary numbers of publishers, subscribers, and publications in the system level and cross channels in real-time to adapt to the workload. Multipub is a flexible latency-constrained Pub/Aub system [11]. It dynamically reconfigures the message delivery configuration within multiple-brokers to achieve a latency guarantee for the messages and cloud costs. Khare et al. proposed a framework that learns a latency prediction model on an edge broker and uses this model to balance the processing and data-dissemination load to provide the desired QoS for the latencyaware placement of topics on brokers [22]. Balasubramanian et al. employed an additive-increase multiplicative-decrease based control algorithm that auto-tunes the Pub/Sub system batch size and the polling interval to optimize the input message load and solve to broker-side congestion that minimizes the latency [2]. Hasenburg et al. presented the latency and excess data dissemination tradeoff within Pub/Sub systems running in fog environments. The authors implemented a broadcast group that split the set of edge brokers into connected groups that use flooding for intra-group communication and a cloud relay for intergroup communication [13].\nAgain, our work focuses on employing latency constraint to optimize Kafka software\u2019s system configuration, rather than topology configuration, job scheduling, or routing configuration."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "In this paper, we propose DMSConfig, an automated configuration tuning approach for latency-aware IoT message systems. DMSConfig casts the problem of constrained configuration optimization to an RL task and searches the near-optimal configuration leveraging the DDPG algorithm. We construct a regression model using RF to predict performance metrics and internal states of a DMS under specific software configurations. Our well-designed reward function leads the RL agent to learn to make wise configuration decisions in a high-dimensional continuous configuration space by iteratively interacting with the regression model. To overcome the burden of data collection cost, we develop a container-based full-stack emulation testbed to parallel experiments. Extensive experimental results reveal that the configurations identified by DMSConfig achieve 12%-538% throughput improvement, compared with the default one suggested by Kafka manual, under 7 different levels of latency restrictions. In addition, DMSConfig is able to guarantee application performance under resource-constrained environments by making wise configuration recommendations. We also verified that DMSConfig earns analogous throughput performance compared with three SMBO-based state-of-the-art parameter optimization frameworks, but delivers the most reliable latency guarantees.\nIn future work, we plan to (1) employ Generative Adversarial Network(GAN) to alleviate the data collection cost further and improve the accuracy of our environment prediction model; (2) integrate the diversities of DMS workloads, topology, and resource allotments into the environment model to enable RL agent competent dynamic configuration recommendation tasks; (3) explore more RL reward functions for improving quality of suggested configurations."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This work is supported by a funding from Cisco. Any opinions, findings, and conclusions or recommendations expressed in this material are of the author(s) and do not necessarily reflect the views of the sponsors."
        }
    ],
    "title": "DMSConfig: Automated Configuration Tuning for Distributed IoT Message Systems Using Deep Reinforcement Learning",
    "year": 2023
}