{
    "abstractText": "The brain-computer interfaces (BCIs) based on steady-state visual evoked potential (SSVEP) have been extensively explored due to their advantages in terms of high communication speed and smaller calibration time. The visual stimuli in the lowand medium-frequency ranges are adopted in most of the existing studies for eliciting SSVEPs. However, there is a need to further improve the comfort of these systems. The high-frequency visual stimuli have been used to build BCI systems and are generally considered to significantly improve the visual comfort, but their performance is relatively low. The distinguishability of 16-class SSVEPs encoded by the three frequency ranges, i.e., 31-34.75 Hz with an interval of 0.25 Hz, 31-38.5 Hz with an interval of 0.5 Hz, 31-46 Hz with an interval of 1 Hz, is explored in this study. We compare classification accuracy and information transfer rate (ITR) of the corresponding BCI system. According to the optimized frequency range, this study builds an online 16-target high frequency SSVEP-BCI and verifies the feasibility of the proposed system based on 21 healthy subjects. The BCI based on visual stimuli with the narrowest frequency range, i.e., 31-34.5 Hz, have the highest ITR. Therefore, the narrowest frequency range is adopted to build an online BCI system. An averaged ITR obtained from the online experiment is Manuscript received 12 September 2022; revised 2 January 2023 and 29 January 2023; accepted 7 February 2023. Date of publication 13 February 2023; date of current version 15 February 2023. This work was supported in part by the National Key Research and Development Program of China under Grant 2022YFC3602803, in part by the National Natural Science Foundation of China under Grant 62171473 and Grant U2241208, in part by the Tianjin Municipal Science and Technology Plan Project under Grant 21JCYBJC01500, and in part by the Key Research and Development Program of Ningxia under Grant 2022CMG02026. (Corresponding authors: Xiaogang Chen; Ning Li.) This work involved human subjects or animals in its research. Approval of all ethical and experimental procedures and protocols was granted by the Institutional Review Board of Tsinghua University under Application No. 20210032. Xiaogang Chen and Hongyan Cui are with the Institute of Biomedical Engineering, Chinese Academy of Medical Sciences and Peking Union Medical College, Tianjin 300192, China (e-mail: chenxg@bme.cams.cn; cuihy@bme.cams.cn). Bingchuan Liu and Xiaorong Gao are with the Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing 100084, China (e-mail: lbc14@tsinghua.org.cn; gxr-dea@ tsinghua.edu.cn). Yijun Wang is with State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing 100083, China (e-mail: wangyj@semi.ac.cn). Jianwei Dong, Ruijuan Ma, and Ning Li are with the People\u2019s Hospital of Ningxia Hui Autonomous Region, Yinchuan 750002, China (e-mail: jwdong.nx@qq.com; hnsymrj@126.com; ninglitju@163.com). Digital Object Identifier 10.1109/TNSRE.2023.3243786 153.79 \u00b1 6.39 bits/min. These findings contribute to the development of more efficient and comfortable SSVEPbased BCIs.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xiaogang Chen"
        },
        {
            "affiliations": [],
            "name": "Bingchuan Liu"
        },
        {
            "affiliations": [],
            "name": "Yijun Wang"
        },
        {
            "affiliations": [],
            "name": "Hongyan Cui"
        },
        {
            "affiliations": [],
            "name": "Jianwei Dong"
        },
        {
            "affiliations": [],
            "name": "Ruijuan Ma"
        },
        {
            "affiliations": [],
            "name": "Ning Li"
        },
        {
            "affiliations": [],
            "name": "Xiaorong Gao"
        }
    ],
    "id": "SP:c935dadd591ef7301d1e95e0a59218ee61fb719b",
    "references": [
        {
            "authors": [
                "J. Wolpaw",
                "N. Birbaumer",
                "D. McFarland",
                "G. Pfurtscheller",
                "T. Vaughan"
            ],
            "title": "Brain\u2013computer interfaces for communication and control",
            "venue": "Clin. Neurophys., vol. 113, no. 6, pp. 767\u2013791, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "A. Kawala-Sterniuk"
            ],
            "title": "Summary of over fifty years with brain\u2013computer interfaces\u2014A review",
            "venue": "Brain Sci., vol. 11, no. 1, p. 43, Jan. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "D. McFarland",
                "J. Wolpaw"
            ],
            "title": "EEG-based brain\u2013computer interfaces",
            "venue": "Current Opinion Biomed. Eng., vol. 4, pp. 194\u2013200, Jan. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. Jeunet",
                "B. Glize",
                "A. McGonigal",
                "J.-M. Batail",
                "J.-A. Micoulaud-Franchi"
            ],
            "title": "Using EEG-based brain computer interface and neurofeedback targeting sensorimotor rhythms to improve motor skills: Theoretical background, applications and prospects",
            "venue": "Neurophysiologie Clinique, vol. 49, no. 2, pp. 125\u2013136, Apr. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Ahn",
                "M. Lee",
                "J. Choi",
                "S.C. Jun"
            ],
            "title": "A review of brain\u2013computer interface games and an opinion survey from researchers, developers and users",
            "venue": "Sensors, vol. 14, no. 8, pp. 14601\u201314633, Aug. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "H.A. Lamti",
                "M.M.B. Khelifa",
                "V. Hugel"
            ],
            "title": "Mental fatigue level detection based on event related and visual evoked potentials features fusion in virtual indoor environment",
            "venue": "Cognit. Neurodyn., vol. 13, no. 3, pp. 271\u2013285, Jun. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "H. Zhao",
                "Y. Wang",
                "Z. Liu",
                "W. Pei",
                "H. Chen"
            ],
            "title": "Individual identification based on code-modulated visual-evoked potentials",
            "venue": "IEEE Trans. Inf. Forensics Security, vol. 14, no. 12, pp. 3206\u20133216, Dec. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "E.C. Leuthardt",
                "D.W. Moran",
                "T.R. Mullen"
            ],
            "title": "Defining surgical terminology and risk for brain computer interface technologies",
            "venue": "Frontiers Neurosci., vol. 15, Mar. 2021, Art. no. 599549.",
            "year": 2021
        },
        {
            "authors": [
                "X. Gao",
                "Y. Wang",
                "X. Chen",
                "S. Gao"
            ],
            "title": "Interface, interaction, and intelligence in generalized brain\u2013computer interfaces",
            "venue": "Trends Cognit. Sci., vol. 25, no. 8, pp. 671\u2013684, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Rashid"
            ],
            "title": "Current status, challenges, and possible solutions of EEG-based brain\u2013computer interface: A comprehensive review",
            "venue": "Frontiers Neurorobot., vol. 14, p. 25, Jan. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "B. Liu",
                "Y. Wang",
                "X. Gao",
                "X. Chen"
            ],
            "title": "eldBETA: A large eldercareoriented benchmark database of SSVEP-BCI for the aging population",
            "venue": "Sci. Data, vol. 9, no. 1, p. 252, May 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Zhang",
                "X. Gao",
                "X. Chen"
            ],
            "title": "Humanoid robot walking in maze controlled by SSVEP-BCI based on augmented reality stimulus",
            "venue": "Frontiers Hum. Neurosci., vol. 16, Jul. 2022, Art. no. 908050. 1286 IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. 31, 2023",
            "year": 2022
        },
        {
            "authors": [
                "X. Chi",
                "C. Wan",
                "C. Wang",
                "Y. Zhang",
                "X. Chen",
                "H. Cui"
            ],
            "title": "A novel hybrid brain\u2013computer interface combining motor imagery and intermodulation steady-state visual evoked potential",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 30, pp. 1525\u20131535, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Gao",
                "Y. Wang",
                "X. Gao",
                "B. Hong"
            ],
            "title": "Visual and auditory brain\u2013computer interfaces",
            "venue": "IEEE Trans. Biomed. Eng., vol. 61, no. 5, pp. 1436\u20131447, May 2014.",
            "year": 2014
        },
        {
            "authors": [
                "X. Chen",
                "Y. Wang",
                "M. Nakanishi",
                "X. Gao",
                "T.-P. Jung",
                "S. Gao"
            ],
            "title": "Highspeed spelling with a noninvasive brain\u2013computer interface",
            "venue": "Proc. Nat. Acad. Sci. USA, vol. 112, no. 44, pp. E6058\u2013E6067, Nov. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "X. Chen",
                "Y. Wang",
                "S. Gao",
                "T.-P. Jung",
                "X. Gao"
            ],
            "title": "Filter bank canonical correlation analysis for implementing a high-speed SSVEP-based brain\u2013computer interface",
            "venue": "J. Neural Eng., vol. 12, no. 4, Aug. 2015, Art. no. 046008.",
            "year": 2015
        },
        {
            "authors": [
                "M. Nakanishi",
                "Y. Wang",
                "X. Chen",
                "Y. Wang",
                "X. Gao",
                "T.-P. Jung"
            ],
            "title": "Enhancing detection of SSVEPs for a high-speed brain speller using task-related component analysis",
            "venue": "IEEE Trans. Biomed. Eng., vol. 65, no. 1, pp. 104\u2013112, Jan. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "X. Chen",
                "B. Zhao",
                "Y. Wang",
                "X. Gao"
            ],
            "title": "Combination of highfrequency SSVEP-based BCI and computer vision for controlling a robotic arm",
            "venue": "J. Neural Eng., vol. 16, no. 2, Apr. 2019, Art. no. 026012.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Chen",
                "C. Yang",
                "X. Chen",
                "Y. Wang",
                "X. Gao"
            ],
            "title": "A novel training-free recognition method for SSVEP-based BCIs using dynamic window strategy",
            "venue": "J. Neural Eng., vol. 18, no. 3, Mar. 2021, Art. no. 036007.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Chen",
                "C. Yang",
                "X. Ye",
                "X. Chen",
                "Y. Wang",
                "X. Gao"
            ],
            "title": "Implementing a calibration-free SSVEP-based BCI system with 160 targets",
            "venue": "J. Neural Eng., Jun. 2021, Art. no. 046094.",
            "year": 2021
        },
        {
            "authors": [
                "X. Chen",
                "Z. Chen",
                "S. Gao",
                "X. Gao"
            ],
            "title": "A high-ITR SSVEP-based BCI speller",
            "venue": "Brain-Comput. Interfaces, vol. 1, nos. 3\u20134, pp. 181\u2013191, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "X. Chen",
                "B. Zhao",
                "Y. Wang",
                "S. Xu",
                "X. Gao"
            ],
            "title": "Control of a 7-DOF robotic arm system with an SSVEP-based BCI",
            "venue": "Int. J. Neural Syst., vol. 28, no. 8, Oct. 2018, Art. no. 1850018.",
            "year": 2018
        },
        {
            "authors": [
                "X. Chen",
                "X. Huang",
                "Y. Wang",
                "X. Gao"
            ],
            "title": "Combination of augmented reality based Brain- computer interface and computer vision for highlevel control of a robotic arm",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 28, no. 12, pp. 3140\u20133147, Dec. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "X. Chen",
                "N. Hu",
                "Y. Wang",
                "X. Gao"
            ],
            "title": "Validation of a brain\u2013computer interface version of the digit symbol substitution test in healthy subjects",
            "venue": "Comput. Biol. Med., vol. 120, May 2020, Art. no. 103729.",
            "year": 2020
        },
        {
            "authors": [
                "X. Chen",
                "N. Hu",
                "X. Gao"
            ],
            "title": "Development of a brain\u2013computer interface-based symbol digit modalities test and validation in healthy elderly volunteers and stroke patients",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 30, pp. 1433\u20131440, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M. Cheng",
                "X. Gao",
                "S. Gao",
                "D. Xu"
            ],
            "title": "Design and implementation of a brain\u2013computer interface with high transfer rates",
            "venue": "IEEE Trans. Biomed. Eng., vol. 49, no. 10, pp. 1181\u20131186, Oct. 2002.",
            "year": 2002
        },
        {
            "authors": [
                "X. Chen",
                "B. Liu",
                "Y. Wang",
                "X. Gao"
            ],
            "title": "A spectrally-dense encoding method for designing a high-speed SSVEP-BCI with 120 stimuli",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 30, pp. 2764\u20132772, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "B. Liu",
                "X. Chen",
                "N. Shi",
                "Y. Wang",
                "S. Gao",
                "X. Gao"
            ],
            "title": "Improving the performance of individually calibrated SSVEP-BCI by task-discriminant component analysis",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 29, pp. 1998\u20132007, 2021.",
            "year": 1998
        },
        {
            "authors": [
                "Y. Wang",
                "R. Wang",
                "X. Gao",
                "B. Hong",
                "S. Gao"
            ],
            "title": "A practical VEPbased brain\u2013computer interface",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 14, no. 2, pp. 234\u2013239, Feb. 2006.",
            "year": 2006
        },
        {
            "authors": [
                "G. Ming",
                "W. Pei",
                "H. Chen",
                "X. Gao",
                "Y. Wang"
            ],
            "title": "Optimizing spatial properties of a new checkerboard-like visual stimulus for userfriendly SSVEP-based BCIs",
            "venue": "J. Neural Eng., vol. 18, no. 5, Oct. 2021, Art. no. 056046.",
            "year": 2021
        },
        {
            "authors": [
                "P.F. Diez",
                "V.A. Mut",
                "E.M.A. Perona",
                "E.L. Leber"
            ],
            "title": "Asynchronous BCI control using high-frequency SSVEP",
            "venue": "J. Neuroeng. Rehabil., vol. 8, p. 39, Jul. 2011.",
            "year": 2011
        },
        {
            "authors": [
                "A. Chabuda",
                "P. Durka",
                "J. Zygierewicz"
            ],
            "title": "High frequency SSVEP- BCI with hardware stimuli control and phase-synchronized comb filter",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 26, no. 2, pp. 344\u2013352, Feb. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S. Ajami",
                "A. Mahnam",
                "V. Abootalebi"
            ],
            "title": "An adaptive SSVEPbased brain\u2013computer interface to compensate fatigue-induced decline of performance in practical application",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 26, no. 11, pp. 2200\u20132209, Nov. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "X. Mao",
                "W. Li",
                "H. Hu",
                "J. Jin",
                "G. Chen"
            ],
            "title": "Improve the classification efficiency of high-frequency phase-tagged SSVEP by a recursive Bayesian-based approach",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 28, no. 3, pp. 561\u2013572, Mar. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C.C. Hsu"
            ],
            "title": "Extraction of high-frequency SSVEP for BCI control using iterative filtering based empirical mode decomposition",
            "venue": "Biomed. Signal Process. Control, vol. 61, Aug. 2020, Art. no. 102022.",
            "year": 2020
        },
        {
            "authors": [
                "K. Goto"
            ],
            "title": "The effect of stimulus pattern, color combination and flicker frequency on steady-state visual evoked potentials topography",
            "venue": "Int. J. Innov. Comput. Inf. Control, vol. 15, no. 4, pp. 1521\u20131530, Aug. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Duszyk"
            ],
            "title": "Towards an optimization of stimulus parameters for brain\u2013computer interfaces based on steady state visual evoked potentials",
            "venue": "PLoS ONE, vol. 9, no. 11, Nov. 2014, Art. no. e112099.",
            "year": 2014
        },
        {
            "authors": [
                "S. Zhang",
                "X. Chen"
            ],
            "title": "Effect of background luminance of visual stimulus on elicited steady-state visual evoked potentials",
            "venue": "Brain Sci. Adv., vol. 8, no. 1, pp. 50\u201356, May 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K.B. Ng",
                "A.P. Bradley",
                "R. Cunnington"
            ],
            "title": "Stimulus specificity of a steady-state visual-evoked potential-based brain\u2013computer interface",
            "venue": "J. Neural Eng., vol. 9, no. 3, Jun. 2012, Art. no. 036008.",
            "year": 2012
        },
        {
            "authors": [
                "Y.Y. Chien"
            ],
            "title": "Polychromatic SSVEP stimuli with subtle flickering adapted to brain-display interactions",
            "venue": "J. Neural Eng., vol. 14, no. 1, Feb. 2017, Art. no. 016018.",
            "year": 2017
        },
        {
            "authors": [
                "X. Chen",
                "Y. Wang",
                "S. Zhang",
                "S. Xu",
                "X. Gao"
            ],
            "title": "Effects of stimulation frequency and stimulation waveform on steady-state visual evoked potentials using a computer monitor",
            "venue": "J. Neural Eng., vol. 16, no. 6, Oct. 2019, Art. no. 066007.",
            "year": 2019
        },
        {
            "authors": [
                "E.P. Zambalde",
                "L.R. Borges",
                "G. Jablonski",
                "M.B. de Almeida",
                "E.L.M. Naves"
            ],
            "title": "Influence of stimuli spatial proximity on a SSVEPbased BCI performance",
            "venue": "IRBM, vol. 43, no. 6, pp. 621\u2013627, Dec. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J. Chen"
            ],
            "title": "Simultaneous decoding of eccentricity and direction information for a single-flicker SSVEP BCI",
            "venue": "Electronics, vol. 8, p. 155, Dec. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "D.H. Brainard"
            ],
            "title": "The psychophysics toolbox",
            "venue": "Spatial Vis., vol. 10, no. 4, pp. 433\u2013436, 1997.",
            "year": 1997
        },
        {
            "authors": [
                "X. Zhao",
                "Z. Wang",
                "M. Zhang",
                "H. Hu"
            ],
            "title": "A comfortable steady state visual evoked potential stimulation paradigm using peripheral vision",
            "venue": "J. Neural Eng., vol. 18, no. 5, Apr. 2021, Art. no. 056021.",
            "year": 2021
        },
        {
            "authors": [
                "P. Yuan",
                "X. Gao",
                "B. Allison",
                "Y. Wang",
                "G. Bin",
                "S. Gao"
            ],
            "title": "A study of the existing problems of estimating the information transfer rate in online brain\u2013computer interfaces",
            "venue": "J. Neural Eng., vol. 10, no. 2, Apr. 2013, Art. no. 026014.",
            "year": 2013
        },
        {
            "authors": [
                "S. Ladouce",
                "L. Darmet",
                "J.J.T. Tresols",
                "S. Velut",
                "G. Ferraro",
                "F. Dehais"
            ],
            "title": "Improving user experience of SSVEP BCI through low amplitude depth and high frequency stimuli design",
            "venue": "Sci. Rep., vol. 12, no. 1, p. 8865, May 2022.",
            "year": 2022
        },
        {
            "authors": [
                "X. Ye",
                "C. Yang",
                "Y. Chen",
                "Y. Wang",
                "X. Gao",
                "H. Zhang"
            ],
            "title": "Multisymbol time division coding for high-frequency steady-state visual evoked potential-based brain\u2013computer interface",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng., vol. 30, pp. 1693\u20131704, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A.I. Renton",
                "J.B. Mattingley",
                "D.R. Painter"
            ],
            "title": "Optimising noninvasive brain\u2013computer interface systems for free communication between na\u00efve human participants",
            "venue": "Sci. Rep., vol. 9, no. 1, p. 18705, Dec. 2019.",
            "year": 1870
        },
        {
            "authors": [
                "S. Abdelnabi",
                "M.X. Huang",
                "A. Bulling"
            ],
            "title": "Towards high-frequency SSVEP-based target discrimination with an extended alphanumeric keyboard",
            "venue": "Proc. IEEE Int. Conf. Syst., Man Cybern. (SMC), Bari, Italy, Oct. 2019, pp. 4181\u20134186.",
            "year": 2019
        },
        {
            "authors": [
                "L. Liang",
                "C. Yang",
                "Y. Wang",
                "X. Gao"
            ],
            "title": "High-frequency SSVEP stimulation paradigm based on dual frequency modulation",
            "venue": "Proc. 41st Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC), Berlin, Germany, Jul. 2019, pp. 6184\u20136187.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Manuscript received 12 September 2022; revised 2 January 2023 and 29 January 2023; accepted 7 February 2023. Date of publication 13 February 2023; date of current version 15 February 2023. This work was supported in part by the National Key Research and Development Program of China under Grant 2022YFC3602803, in part by the National Natural Science Foundation of China under Grant 62171473 and Grant U2241208, in part by the Tianjin Municipal Science and Technology Plan Project under Grant 21JCYBJC01500, and in part by the Key Research and Development Program of Ningxia under Grant 2022CMG02026. (Corresponding authors: Xiaogang Chen; Ning Li.)\nThis work involved human subjects or animals in its research. Approval of all ethical and experimental procedures and protocols was granted by the Institutional Review Board of Tsinghua University under Application No. 20210032.\nXiaogang Chen and Hongyan Cui are with the Institute of Biomedical Engineering, Chinese Academy of Medical Sciences and Peking Union Medical College, Tianjin 300192, China (e-mail: chenxg@bme.cams.cn; cuihy@bme.cams.cn).\nBingchuan Liu and Xiaorong Gao are with the Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing 100084, China (e-mail: lbc14@tsinghua.org.cn; gxr-dea@ tsinghua.edu.cn).\nYijun Wang is with State Key Laboratory on Integrated Optoelectronics, Institute of Semiconductors, Chinese Academy of Sciences, Beijing 100083, China (e-mail: wangyj@semi.ac.cn).\nJianwei Dong, Ruijuan Ma, and Ning Li are with the People\u2019s Hospital of Ningxia Hui Autonomous Region, Yinchuan 750002, China (e-mail: jwdong.nx@qq.com; hnsymrj@126.com; ninglitju@163.com).\nDigital Object Identifier 10.1109/TNSRE.2023.3243786"
        },
        {
            "heading": "153.79 \u00b1 6.39 bits/min. These findings contribute to the development of more efficient and comfortable SSVEPbased BCIs.",
            "text": "Index Terms\u2014 BCI, electroencephalography, highfrequency visual stimulation, SSVEP.\nI. INTRODUCTION\nBRAIN-COMPUTER interface (BCI) directly connects thebrain with external devices [1], [2]. BCI is a promising technology for the development of systems that assist, repair, or enhance the human sensorimotor or cognitive functions [3], [4]. The applications of BCI have expanded from the medical field to various non-medical fields, such as games and entertainment [5], fatigue monitoring [6], biometrics [7]. Currently, various methods are presented, such as electroencephalography (EEG), magnetoencephalography (MEG), functional magnetic resonance imaging (fMRI), and near infrared spectroscopy (NIRS), to monitor the brain activity and build BCIs [8]. Since EEG has the advantages of high time resolution, non-invasiveness, and cost effectiveness, it is widely adopted for building non-invasive BCIs [9], [10], [11], [12]. Currently, EEG has been used for developing multiple BCI paradigms [9], [13], [14], such as steady-state visual evoked potential (SSVEP)-based BCI, P300-based BCI, and sensorimotor rhythms (SMRs)-based BCI.\nAmong these existing EEG-based BCIs, SSVEP-BCI has been extensively investigated due to its high communication speed and less calibration time [15], [16], [17], [18], [19], [20], [21]. Currently, SSVEP-BCI has been applied in multiple fields, including robot control [12], [18], [22], [23], cognitive evaluation [24], [25], and text speller [15], [17], [20], etc. SSVEPs are periodic brain responses elicited by repeated visual stimuli, manifested by increased brain activities at stimulus frequencies and their harmonics [26]. Furthermore, SSVEPs are phase-locked to the visual stimulation. As a result, phase coding and frequency coding are the two most commonly used methods for realizing multi-target SSVEPBCI. In SSVEP-based BCIs, multiple visual flashing stimuli with different frequencies or phases are presented simultaneously on a screen. The users can select the desired option by focusing on the target stimulus. By analyzing the elicited SSVEPs, it is possible to infer the gaze target. Recently, various encoding approaches inspired by multiple\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\naccess (MA) technologies adopted in telecommunication have succeeded in increasing the number of targets [14]. The number of targets in SSVEP-BCIs has increased to more than 100 [20], [27]. At the same time, advanced EEG signal processing and machine learning approaches have been used to improve the performance of SSVEP detection. More recently, the ensemble task-related component analysis (TRCA)-based method and the task-discriminant component analysis (TDCA) have been used to significantly improve the performance of SSVEP detection [17], [28]. With the development of encoding technology, signal processing, and system implementation, SSVEP-BCIs\u2019 performance has improved significantly in recent years. The information transfer rate (ITR) of SSVEP-BCIs has increased from about 20 bits/min to more than 300 bits/min [17]. Nakanishi et al. realized a 40-target SSVEP-BCI speller with 325.33 bits/min, and subjects performed a target-selection task at 800 ms per character with an average accuracy of 89.83% [17]. Among these high ITR SSVEP-BCI studies, the stimulation frequencies of these systems were usually selected from low- and medium-frequency ranges, i.e., below 30 Hz [15], [16], [17], [20]. Although low- and medium-frequency visual stimuli can evoke larger SSVEP amplitude responses leading to better system performance [29], they are prone to cause visual discomfort and fatigue [30]. Therefore, the comfort of these systems should be further improved. Several studies have attempted to use high-frequency stimuli design, i.e., above 30 Hz, for improving visual comfort [30], [31], [32]. Volosyak et al. reported a mean ITR of 12.10 bits/min and accuracy of 89.16% for a 4-target SSVEP-BCI system using high-frequency flickers, i.e., 34, 36, 38, and 40 Hz [32]. Chabuda et al. built an 8-target SSVEPbased BCI using high-frequency stimuli, i.e., 30-39 Hz, and achieved a mean ITR of 47 bits/min [33]. Ajami et al. used a threshold-based version of the least absolute shrinkage and selection operator (LASSO) to classify SSVEPs induced by five visual stimuli, i.e., 35, 36.2, 37.3, 38.3, and 39.4 Hz [34]. In a 4-target high-frequency SSVEP-BCI, an average ITR of 17 bits/min and accuracy of 97.75% were reported by Chen et al. [18]. Recently, Mao et al. developed a 6-target SSVEP-based BCI by combining one stimulation frequency (30 Hz) and six phases and obtained a mean ITR of 67.2 bits/min in offline analysis [35]. Hsu et al. applied iterative filtering - empirical mode decomposition (IF-EMD) for detecting three high-frequency (i.e., 47, 50, 53 Hz) SSVEPs, and achieved an averaged ITR of 54.94 bits/min [36]. In the past few years BCIs based on high-frequency SSVEPs have made some progress, but the performance of these systems is still relatively low (usually less than 70 bits/min).\nThe previous studies show that stimulus parameters, such as stimulus color [37], stimulus size [38], and stimulus background luminance [39] affect the amplitude of SSVEPs [40], [41], [42]. Goto et al. verified that the amplitude of SSVEP evoked by black-and-white flicker stimuli was higher than that evoked by isoluminant color combination stimuli (red/blue, red/green) [37]. Duszyk et al. reported that larger dimensions of flickering fields led to a significantly stronger SSVEP response [38]. Zhang and Chen reported that the black background luminance induced larger SSVEP amplitude\nand greater signal-to-noise ratio (SNR) as compared with gray background luminance [39]. The high SSVEP amplitude facilitates SSVEP detection [31]. Furthermore, it has been reported that a spatial proximity from 4\u25e6 to 13\u25e6 visual angle leads to a higher SSVEP-BCI performance [43]. Therefore, the performance of BCI systems can be improved by optimizing the stimulus parameters. However, the existing studies mostly optimize the stimulus parameters for low- and mediumfrequency SSVEPs. It is still unclear whether optimizing the stimulation parameters for low- and medium-frequency SSVEP-BCI is applicable for high-frequency SSVEP-BCI. In order to improve the high-frequency SSVEP-BCI performance, this study adopts three frequency ranges to build 16-target SSVEP-based BCI, including: 1) 31-34.75 Hz with an interval of 0.25 Hz; 2) 31-38.5 Hz with an interval of 0.5 Hz; 3) 31-46 Hz with an interval of 1 Hz. Two experiments, i.e., experiment 1 and online experiment, are used to optimize and test the performance of the proposed BCI system. In experiment 1, we initially estimate the optimized frequency range with 16-target SSVEP data recorded from 24 subjects. The performance of the 16-target SSVEP-based BCIs with different frequency ranges is evaluated based on ITR and accuracy. Based on the optimized frequency range, this study builds an online 16-target high-frequency SSVEP-BCI. The online BCI experiment is designed to verify the feasibility of the proposed system based on 21 subjects."
        },
        {
            "heading": "II. METHODS",
            "text": ""
        },
        {
            "heading": "A. Subjects",
            "text": "Twenty-nine healthy subjects (fourteen males), aged 21-30 years with normal or corrected-to-normal vision participate in this study. Twenty-four subjects and twenty-one subjects participated in experiment 1 and online BCI experiment, respectively. Sixteen subjects participated in the two experiments simultaneously. The interval between experiment 1 and online BCI experiment is about 1.5 months. Since eight subjects had graduated, we were unable to recruit them for the online BCI experiment and only five subjects took part in the online BCI experiment. All the subjects submitted written informed consent before participating in the experiment. This study is approved by the Institutional Review Board of Tsinghua University (No. 20210032)."
        },
        {
            "heading": "B. EEG Data Acquisition",
            "text": "A Neuroscan SynAmps2 amplifier is adopted to record EEG signals. The sample rate of the amplifier is set to 1000 Hz. The reference electrode is located between Cz and CPz, and the ground electrode is located between Fz and FPz. The EEG data is recorded using nine parietal-occipital electrodes, i.e., Oz, O1, O2, POz, PO5, PO3, PO4, PO6, and Pz, since these electrodes are usually able to obtain SSVEP with high SNR [20], [44]. Fig. 1 shows the locations of these nine electrodes. The electrode impedances are less than 10 k . In order to remove the power-line interference, a 50 Hz notch filter is enabled during EEG data collection."
        },
        {
            "heading": "C. System Design",
            "text": "In this study, the sampled sinusoidal stimulation method [21] is used to present visual stimuli encoded by the\njoint frequency-phase modulation (JFPM) approach [15] on a computer monitor (SAMSUNG C49HG90DMC, resolution: 3840 \u00d7 1080 pixels, refresh rate: 120 Hz). When visual stimuli are presented using the sampled sinusoidal stimulation method, the stimulus sequence s( f, \u2205, i) with frequency f and phase \u2205 can be obtained by adjusting the luminance of the screen by the following equation:\ns( f, \u2205, i) = 1 2\n{ 1 + sin [ i/R ] + \u2205 } (1)\nwhere, i represents the frame index in the stimulus sequence, R indicates the refresh rate of the screen, and sin() generates a sine wave. The dynamic range of the stimulus sequence is from 0 to 1, where 1 indicates the highest luminance and 0 represents darkness. Fig. 2A shows the user interface of the proposed BCI system. Sixteen targets are aligned in a 4 \u00d7 4 matrix. Each target is presented in a rectangle of 173 \u00d7 129 pixels. The interval between adjacent targets is 100 pixels. In JFPM approach, two adjacent targets are coded with different frequencies and different phases at the same time. Figs. 2B-2D show the frequency and phase values for each target under each condition. Psychophysics Toolbox 3 [45] in MATLAB environment is used to implement the visual stimulus presentation."
        },
        {
            "heading": "D. Experimental Design",
            "text": "The aim of experiment 1 is to investigate the effect of different frequency ranges on the performance of SSVEPbased BCIs. In this study, we adopt three frequency ranges to build 16-target SSVEP-based BCIs. For the first experimental condition, as shown in Fig. 1B, the stimulation frequencies range from 31 Hz to 34.75 Hz with an interval of 0.25 Hz. For the second experimental condition, the stimulation frequencies range from 31 Hz to 38.5 Hz with an interval of 0.5 Hz (see Fig. 2C). In the third experimental condition, the frequency range is chosen from 31 Hz to 46 Hz with an interval of 1 Hz (see Fig. 1D). The initial phase and the phase interval of the three experimental conditions are the same, and are set to 0 and 0.35\u03c0 , respectively [15]. In experiment 1, we record three blocks for each experimental condition. The order of\nthe blocks is balanced. Each block contains 64 trials and each target obtains 4 trials in one block. Therefore, for each experimental condition, 12 trials are obtained per target. Each trial lasts 4 s and begins with the presentation of a visual cue, i.e., a red square, which presents 1 s. Subsequently, all stimuli flicker for 2 s. The subjects are told to gaze at the cued target. After stimulus offset, the user interface is presented for 1 s after stimulus offset. The order of the three experimental conditions in experiment 1 was balanced.\nThe online experiment is based on the frequency range selected from experiment 1. The frequency range that resulted in the highest ITR is adopted in the online experiment. An online experiment is conducted on 21 subjects for assessing the performance of the proposed BCI. The user interface and encoding parameters of the proposed BCI system are shown in Fig. 2A and Fig. 2B, respectively. In the online experiment, one training session and one testing session are performed for each subject. The training session includes 12 blocks, each containing 16 trials. The training session is mainly performed to obtain the training data for each individual without providing any feedback. The test session includes 6 blocks, each comprising 16 trials. Regardless of the training or testing sessions, each target obtains 1 trial in one block, and each trial lasts for 1.1 s, i.e., 0.6 s for stimulus presentation and 0.5 s for attention switching. The visual cue of a red square for the next target would be presented immediately after the visual stimulation is completed, and real-time auditory feedback is provided to the subjects, i.e., an online data analysis program made a short beep after correctly identifying a target."
        },
        {
            "heading": "E. Amplitude Spectrum and SNR of SSVEPs",
            "text": "Based on the 2-s offline data epochs, we calculate the amplitude spectrum and SNR of SSVEPs. The fast Fourier transform (FFT) is adopted to compute the amplitude spectrum. The length of data epochs for FFT is 2 s, thus the frequency resolution is 0.5 Hz. The zero-padding is used to increase the FFT resolution for the first experimental condition of experiment 1, i.e., the length of the data in the time domain is extended by padding with zeros at the tail of the time signal. Then, the length of data is extended to 4 s for the first experimental condition of experiment 1.\nThe SNR is calculated as the ratio of SSVEP amplitude spectrum to the average amplitude spectrum of the 8 adjacent frequencies:\nSN R = 20log10 y ( f )\u22114 k=1 [ y ( f \u2212 0.5 \u00d7 k) + y ( f + 0.5 \u00d7 k) ] (2)\nwhere, y ( f ) is SSVEP amplitude spectrum of stimulation frequency f ."
        },
        {
            "heading": "F. SSVEP Detection Method",
            "text": "The epochs are obtained in [0.14 s 0.14 + d s] from the raw EEG data according to stimulus events generated by the stimulus program, where d represents the data length for EEG analysis. Subsequently, we downsample all the EEG epochs\nto 250 Hz as the ensemble TRCA-based method [17] has shown a dramatic improvement in the performance of SSVEPbased BCI. This method is utilized to detect SSVEPs in this study. In ensemble TRCA, individual calibration data for the n-th visual stimulus is represented as xn \u2208 RNc\u00d7Ns\u00d7Nt , n = 1, 2, \u00b7 \u00b7 \u00b7 , N f . Here, Nc is the number of channels, Ns is the number of sampling points in each trial, Nt is the number of training trials, and N f is the number of targets. In this study, N f and Nc are set to 16 and 9, respectively. For the training stage, the filter bank analysis is first applied to the individual calibration data for decomposing the EEG data into Nk sub-bands (k = 1, 2, \u00b7 \u00b7 \u00b7 , Nk). In this study, Nk is set to 2. The frequency range of the k-th sub-band is from k \u00d7 30 Hz to 90 Hz. Now, the i-th trial of the k-th sub-band component is represented as xkn,i . The TRCA seeks to find a linear coefficient vector wkn \u2208 RNc to maximize the following equation.\nV kn = Nt\u2211 i, j\ni \u0338= j\nCov ((\nwkn )T xkn,i , ( wkn )T xkn, j )\n= ( wkn )T  Nt\u2211 i, j\ni \u0338= j\nCov (\nxkn,i , x k n, j )wkn = ( wkn )T Sknw k n (3)\nIn order to avoid the arbitrarily scaling weights, we consider the following constraint:\nCkn = Nt\u2211 i V ar (( wkn )T xkn,i )\n= ( wkn )T ( Nt\u2211 i Cov ( xkn,i )) wkn\n= ( wkn )T Qknw k n = 1 (4)\nThe constrained optimization problem is mathematically expressed as follows:\nwkn = argmax w wT Sknw wT Qknw\n(5)\nThe optimized coefficient vector is obtained by using the eigenvector of the matrix Q\u22121S. An ensemble spatial filter wk \u2208 RNc\u00d7N f is expressed as follows:\nwk = [ wk1, w k 2, \u00b7 \u00b7 \u00b7 , w k N f ] (6)\nThe individual training template x\u0304kn \u2208 RNc\u00d7Ns is expressed as:\nx\u0304kn = 1 Nt Nt\u2211 i xkn,i (7)\nFor the testing stage, the filter bank analysis is also applied to single-trial testing data x\u0302 \u2208 RNc\u00d7Ns to decompose the\nEEG data into Nk sub-bands. The k-th sub-band component of testing data is represented as x\u0302k \u2208 RNc\u00d7Ns . The correlation coefficient between an individual training template and a single-trial testing data is calculated as follows:\n\u03b3 kn = \u03c1\n(( wk )T x\u0304kn , ( wk )T x\u0302k )\n(8)\nwhere, \u03c1 (x, y) is the Pearson\u2019s correlation analysis between x and y. Finally, the target stimulus can be recognized by the following equation:\n\u03c4 = argmax n Nk\u2211 k=1 ( k\u2212a + b ) \u00b7 \u03b3 kn (9)\nwhere, a and b are determined by a grid search approach in this study. Based on our previous study [16], the range of a is from 0 to 2 with an interval of 0.25 and b ranges from 0 to 1 with an interval of 0.25. These parameters corresponding to the highest ITR are used to build the online system."
        },
        {
            "heading": "G. Simulation of Different Stimulation Phase Value",
            "text": "Based on the stimulation frequency and phase, the data segments with different phase values is obtained by performing different time shifts on the 2 s offline data epochs. For each stimulation frequency, SSVEPs with a zero initial phase is calculated as:\nX\u0304( fk, 0, n) = X( fk, \u2205k, n + (2\u03c0 \u2212 \u2205k) \u00d7 fs\n2\u03c0 \u00d7 fk ) (10)\nwhere, n is the index of data sample and fs is the sampling rate. fk and \u2205k represent the stimulation frequency and phase, respectively. The data segments with different phase values are obtained by performing different time shifts in the zero initial phase epochs:\nX\u0302( fk, \u2205\u0304k, n) = X\u0304( fk, 0, n + \u2205\u0304k \u00d7 fs 2\u03c0 \u00d7 fk ) (11)\nwhere, \u2205\u0304k is the desired phase. Therefore, this method is used to simulate the epochs with different phase interval values in this study."
        },
        {
            "heading": "H. Subjective Assessment of Visual Comfort",
            "text": "During experiment 1, the comfort level of the three experimental conditions, i.e., 31-34.75 Hz with an interval of 0.25 Hz, 31-38.5 Hz with an interval of 0.5 Hz, 31-46 Hz with an interval of 1 Hz, are provided by each subject. The subjective assessment questionnaire is adopted from a previous study [46]. The subjects are required to grade each experimental condition with a 6-point scale ranging from 1 (totally unacceptable) to 6 (have a good experience)."
        },
        {
            "heading": "I. Performance Evaluation",
            "text": "ITR is the most adopted metric to evaluate the performance of BCI [47]. Therefore, ITR is utilized to estimate the performance of BCI in this study. The ITR is calculated using the following equation:\nI T R = (\nlog2 M + P log2 P + (1 \u2212 P) log2 [ 1 \u2212 P M \u2212 1 ]) /T\n(12)\nwhere, M is the number of targets, i.e., 16 in this study, P is the accuracy of target detection, and T is the average time for a selection, including stimulus presentation time and attention switching time. An attention switching time of 0.5 s is utilized to calculate ITR in the experiment 1 and the online experiment. For experiment 1, the performance of BCI is estimated by a leave-one-out cross-validation. A leaveone-out cross-validation procedure is adopted to calculate the ITR and the classification accuracy, i.e., 1 trial is served as the validation and the remaining 11 trials are used as the training data. For the online experiment, the ITR and classification accuracy are calculated based on the results obtained by the online data analysis program during the testing stage."
        },
        {
            "heading": "J. Statistical Analysis",
            "text": "This study adopts the SPSS software to perform the statistical analysis. A repeated measures analysis of variance (ANOVA) is used for multiple comparisons in the offline analysis. The Greenhouse-Geisser correction is performed when the data did not conform to the sphericity assumption by Mauchly\u2019s test of sphericity. The paired t-test with Bonferroni correction is used to perform the post hoc comparisons. The alpha level is set at 0.05."
        },
        {
            "heading": "III. EXPERIMENTAL RESULTS AND ANALYSIS",
            "text": ""
        },
        {
            "heading": "A. Amplitude Spectrum and SNR of SSVEPs",
            "text": "Fig. 3 illustrates the average SNR and amplitude spectrum of SSVEPs at 33 Hz derived from the Oz electrode under the first experimental condition of experiment 1. As illustrated in Fig. 2, both SNR and amplitude spectrum exhibit obvious peaks at 33 Hz and 66 Hz. Fig. 4 shows the mean SNRs and amplitude spectra under different stimulation frequencies and response frequencies. The fundamental frequency and second harmonic can be observed in both amplitude spectra and SNRs. It is noteworthy that, as the stimulation frequency increases, the amplitude spectrum and SNR of the second harmonic decreases. Two main frequency components, including the fundamental and second harmonic, are considered in the subsequent analysis. In addition, it is also found that when the stimulation frequency is higher than 41 Hz, in addition to the fundamental SSVEPs, frequency components of 120 minus 2 times the stimulation frequencies are also evoked for the third experimental condition of experiment 1 (see Fig. 4C and Fig. 4F). A possible reason for this phenomenon is that the screen refresh rate is relatively low to generate stable and reliable stimulation signals for these stimulation frequencies (i.e., above 41 Hz). In order to reduce these interfering components, it is best to increase the screen refresh rate, such as increasing to 240 Hz."
        },
        {
            "heading": "B. Target Identification Performance",
            "text": "As described in Section II, the optimal parameters, i.e., a, b, phase interval value, and data length, are determined by using a grid-search method. These parameters are simultaneously optimized to obtain the highest ITR. For the first and third\nexperimental conditions of the experiment 1, the highest ITR is achieved by a data length of 0.3 s. For the second experimental condition of experiment 1, the peak ITR is obtained by a data length of 0.2 s. The optimal a, b, and phase interval values for the three conditions are slightly different. For first, second, and third conditions, they are (0.75, 0.75, 1.95\u03c0), (1.75, 0.25, 1.95\u03c0), and (1.5, 0, 0.4\u03c0), respectively. Fig. 5 illustrates the ITR corresponding to different a and b for the three conditions with the optimal data length (first condition: 0.3 s, second condition: 0.2 s, third condition: 0.3 s) and phase interval (first condition: 1.95\u03c0 , second condition: 1.95\u03c0 , third condition: 0.4\u03c0) of each condition. Fig. 6 describes the average ITR and classification accuracy as a function of phase interval and data length. The phase interval ranges from 0 to 1.95\u03c0 with a step of 0.05\u03c0 . As described in Fig. 6, the first and third conditions obtain the highest ITR (first condition: 196.40 bits/min, third condition: 162.44 bits/min) for a data length of 0.3 s. The second condition achieves the peak ITR (i.e., 193.31 bits/min) for a data length of 0.2 s. The optimal phase interval values are also not the same (first condition: 1.95\u03c0 , second condition: 1.95\u03c0 , third condition: 0.4\u03c0). Moreover, the present study explores the relationship between data length and BCI performance based on the optimal a, b, and phase interval value for each condition, i.e., first condition: (0.75, 0.75, 1.95\u03c0), second condition: (1.75, 0.25, 1.95\u03c0), third condition: (1.5, 0, 0.4\u03c0). Fig. 7 illustrates the ITR and\nclassification accuracy of the three experimental conditions under different data lengths. For each experimental condition, the classification accuracy increases with data length until a stable state is achieved (see Fig. 7). When the data length is longer than 3 s, the accuracy for the first experimental condition is superior to that of the other experimental conditions. For each experimental condition, there is an inverted U-shaped relationship between ITR and data length. The first and third experimental conditions obtain the highest ITRs (first condition: 196.40 \u00b1 14.59 bits/min, third condition: 162.44 \u00b1 16.32 bits/min) for a data length of 0.3 s. While the second experimental condition obtains the highest ITR (i.e., 193.31 \u00b1 18.81 bits/min) for a data length of 0.2 s. When the data length is longer than 0.3 s, the ITR of the first experimental condition also outperforms that of the other two experimental conditions. For each data length, one-way repeated measures ANOVA reveals a considerable difference between the three conditions on the accuracy or ITR (all p < 0.05).\nMoreover, the subjective visual comfort scores are comparable across the three experimental conditions (first condition:\n4.83 \u00b1 0.23, second condition: 5.42 \u00b1 0.16, third condition: 5.13 \u00b1 0.21) (see Fig. 8). One-way repeated measures ANOVA reveals that there is no obvious difference between the three conditions on the subjective visual comfort score (p > 0.05).\nSince the first experimental condition exhibits good BCI performance, the first experimental condition is adopted to build an online BCI system. The abovementioned optimal a, b, and phase interval values, i.e., 0.75, 0.75, and 1.95\u03c0 , are directly used in the online BCI system. As shown in Fig. 6, the highest ITR of the first condition is obtained when the data length is 0.3 s. However, the corresponding classification\naccuracy is only 79.88 \u00b1 3.66 %. A previous study shows that the reliable communication may be difficult when the classification accuracy is less than 80% [48]. When the data length is 0.6 s, an average accuracy rate of 86.41 \u00b1 3.60 % is obtained. Therefore, a visual stimulation time of 0.6 s is adopted to build the online BCI system. Fig. 9 shows classification accuracy for each stimulation frequency when the data length is 0.6 s. The optimal a, b, and phase interval values for the three conditions are determined according to the results of Fig. 5 and Fig. 6. As shown in Fig. 9, the classification accuracy of each stimulation frequency is significantly higher than the chance level (i.e., 6.25%). For all three experimental conditions, classification accuracy decreased with increasing stimulation frequency. SSVEPs induced by higher frequencies have lower discrimination ability. One-way repeated measures ANOVA reveals significant difference between stimulation frequencies (all p < 0.05 for all the three experimental conditions). These results are consistent with the finding that SSVEPs elicited by higher frequencies have relatively lower amplitudes and SNRs (see Fig. 4). Compared with the second and third experimental conditions, the first experimental condition has a higher classification accuracy.\nBased on the abovementioned optimal a, b, and phase interval values for the first experimental condition, we further investigated the impact of number of training data on BCI performance. The accuracy was calculated with the abovementioned optimal parameters using 0.6-s long SSVEP data. Fig. 10 shows the mean classification accuracy for different numbers of training trials. As shown in Fig. 10, the accuracy increased with increasing the number of training data. And the highest accuracy is obtained when the number of training trials is 11. One-way repeated measures ANOVA reveals significant main effect of the number of training trials (p < 0.05)."
        },
        {
            "heading": "C. Online BCI Performance",
            "text": "According to the highest ITR obtained in the offline analysis, the online BCI system adopts a frequency interval of\n0.25 Hz. Furthermore, a 0.6-s stimulation duration and a 0.5-s attention switching time are used in the online BCI system. Therefore, the time to output one command is 1.1 s. Meanwhile, a, b, and phase interval values are set to 0.75, 0.75, and 1.95\u03c0 , respectively. Table I lists the online BCI performance. As listed in Table I, the average accuracy and ITR are 84.62 \u00b1 1.83 % and 153.79 \u00b1 6.39 bits/min, respectively. The online BCI performance is comparable with the offline results (online: 84.62 \u00b1 1.83 %, offline: 86.41 \u00b1 3.60 %). The minimum ITR and maximum ITR are 97.06 bits/min and 211.41 bits/min, respectively. These experimental results exhibit the feasibility of the proposed 16-target high-frequency SSVEP-based BCI."
        },
        {
            "heading": "IV. DISCUSSION",
            "text": "This work aims to develop a high-ITR BCI based on high-frequency SSVEP. Based on the optimized results of stimulation frequency range, the narrowest frequency range is selected for building an online BCI system. The online BCI system achieved a mean ITR of 153.79 bits/min and an average accuracy of 84.62%.\nCurrently, the majority of the existing SSVEP-BCIs adopt low- and medium-frequency stimuli. Furthermore, the highest performance of SSVEP-based BCIs is realized by means of these frequencies. Although low- and medium-frequency stimuli induce obvious SSVEPs and then improve SSVEP detection, the comfort of these BCI systems should be enhanced. In contrast to low- and medium-frequency stimuli, the high-frequency stimulation is considered less annoying. Please note that high-frequency SSVEP is more suitable for building a comfortable system [30], [48], [49]. According to the comfort questionnaire results (see Fig. 8), all the three experimental conditions obtain high comfort scores. These results suggest that the high frequency stimuli used in this study are acceptable and are helpful for building userfriendly BCIs. Admittedly, there are still few high-frequency SSVEP-BCI related studies due to the weak response of high-frequency SSVEPs. As compared with low- or mediumfrequency SSVEP-BCIs, the performance of high-frequency SSVEP-based BCIs is still low (usually less than 70 bits/min). The BCI performance of the online experiment is listed in\nTable I. The results show that the subject can manipulate the proposed BCI system with an ITR of 153.79 bits/min and an average accuracy of 84.62%. According to Renton et al. [50], accuracy higher than 80% is considered acceptable to achieve effective communication. Therefore, according to the above results, it is suggested that the proposed BCI system is considered suitable for BCI applications related to communication. In this study, the proposed BCI system obtains an average ITR of 153.79 bits/min, which is the highest online ITR reported so far for high-frequency SSVEP-BCIs. As compared with the previous studies, the performance improvement in this study is due to stimulus coding optimization and the use of an efficient target recognition algorithm. This study innovatively estimates the optimized frequency range with 16-target SSVEPBCI data. Based on the optimized frequency range, this study builds an online 16-target high-frequency SSVEP-BCI. On the other hand, although the ensemble TRCA-based method has been used in several low- and medium-frequency SSVEP-BCIs, only few TRCA related works are conducted on high-frequency SSVEPs so far. The high performance of the proposed study reveals that the ensemble TRCAbased method is also suitable for classifying high-frequency SSVEPs.\nAdditionally, this study utilizes three frequency ranges with three frequency intervals to build high-frequency SSVEP-BCIs. The first range is from 31 Hz to 34.75 Hz with an interval of 0.25 Hz; the second range is from 31 Hz to 38.5 Hz with an interval of 0.5 Hz. The final range is from 31 Hz to 46 Hz with an interval of 1 Hz. Based on the offline analysis, we seek to find the optimized frequency range for designing high-ITR BCI system. The results show that the lowest frequency range obtains the highest performance (see Fig. 7). This is in agreement with the results presented by Abdelnabi et al. [51]. Although the frequency range and frequency interval of this work are different from the work\npresented by Abdelnabi et al. [51], both studies verify that a relatively narrower frequency range is preferable. Since the starting stimulus frequency for the three frequency ranges is identical in this study, a relatively narrower frequency range is preferred for building high-speed BCIs. A possible reason for this phenomenon is that the relatively lower stimulation frequencies elicit stronger SSVEPs (see Fig. 4). Additionally, by applying dual frequency modulation to encode more targets [52], the performance of the proposed system can be further improved."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "This work aims to develop a high-ITR BCI system based on high-frequency SSVEP. The joint frequency-phase modulation approach and the ensemble TRCA-based algorithm are used to realize the 16-target high-frequency SSVEP-based BCI. By comparing three stimulation frequency ranges, the smallest frequency interval is selected for implementing the online BCI system. According to the online experimental result, an average ITR of 153.79 bits/min is achieved by the proposed high-frequency BCI system, and the maximum ITR of a single subject is 211.41 bits/min. Furthermore, these results also verify the feasibility of the ensemble TRCA-based method to build a high-frequency SSVEP-BCI. Therefore, these results provide a basis for achieving optimal system performance of high-frequency SSVEP-BCI.\nREFERENCES [1] J. Wolpaw, N. Birbaumer, D. McFarland, G. Pfurtscheller, and\nT. Vaughan, \u201cBrain\u2013computer interfaces for communication and control,\u201d Clin. Neurophys., vol. 113, no. 6, pp. 767\u2013791, 2002. [2] A. Kawala-Sterniuk et al., \u201cSummary of over fifty years with brain\u2013computer interfaces\u2014A review,\u201d Brain Sci., vol. 11, no. 1, p. 43, Jan. 2021. [3] D. McFarland and J. Wolpaw, \u201cEEG-based brain\u2013computer interfaces,\u201d Current Opinion Biomed. Eng., vol. 4, pp. 194\u2013200, Jan. 2017. [4] C. Jeunet, B. Glize, A. McGonigal, J.-M. Batail, and J.-A. Micoulaud-Franchi, \u201cUsing EEG-based brain computer interface and neurofeedback targeting sensorimotor rhythms to improve motor skills: Theoretical background, applications and prospects,\u201d Neurophysiologie Clinique, vol. 49, no. 2, pp. 125\u2013136, Apr. 2019. [5] M. Ahn, M. Lee, J. Choi, and S. C. Jun, \u201cA review of brain\u2013computer interface games and an opinion survey from researchers, developers and users,\u201d Sensors, vol. 14, no. 8, pp. 14601\u201314633, Aug. 2014. [6] H. A. Lamti, M. M. B. Khelifa, and V. Hugel, \u201cMental fatigue level detection based on event related and visual evoked potentials features fusion in virtual indoor environment,\u201d Cognit. Neurodyn., vol. 13, no. 3, pp. 271\u2013285, Jun. 2019. [7] H. Zhao, Y. Wang, Z. Liu, W. Pei, and H. Chen, \u201cIndividual identification based on code-modulated visual-evoked potentials,\u201d IEEE Trans. Inf. Forensics Security, vol. 14, no. 12, pp. 3206\u20133216, Dec. 2019. [8] E. C. Leuthardt, D. W. Moran, and T. R. Mullen, \u201cDefining surgical terminology and risk for brain computer interface technologies,\u201d Frontiers Neurosci., vol. 15, Mar. 2021, Art. no. 599549. [9] X. Gao, Y. Wang, X. Chen, and S. Gao, \u201cInterface, interaction, and intelligence in generalized brain\u2013computer interfaces,\u201d Trends Cognit. Sci., vol. 25, no. 8, pp. 671\u2013684, Aug. 2021. [10] M. Rashid et al., \u201cCurrent status, challenges, and possible solutions of EEG-based brain\u2013computer interface: A comprehensive review,\u201d Frontiers Neurorobot., vol. 14, p. 25, Jan. 2020. [11] B. Liu, Y. Wang, X. Gao, and X. Chen, \u201celdBETA: A large eldercareoriented benchmark database of SSVEP-BCI for the aging population,\u201d Sci. Data, vol. 9, no. 1, p. 252, May 2022. [12] S. Zhang, X. Gao, and X. Chen, \u201cHumanoid robot walking in maze controlled by SSVEP-BCI based on augmented reality stimulus,\u201d Frontiers Hum. Neurosci., vol. 16, Jul. 2022, Art. no. 908050.\n[13] X. Chi, C. Wan, C. Wang, Y. Zhang, X. Chen, and H. Cui, \u201cA novel hybrid brain\u2013computer interface combining motor imagery and intermodulation steady-state visual evoked potential,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 30, pp. 1525\u20131535, 2022. [14] S. Gao, Y. Wang, X. Gao, and B. Hong, \u201cVisual and auditory brain\u2013computer interfaces,\u201d IEEE Trans. Biomed. Eng., vol. 61, no. 5, pp. 1436\u20131447, May 2014. [15] X. Chen, Y. Wang, M. Nakanishi, X. Gao, T.-P. Jung, and S. Gao, \u201cHighspeed spelling with a noninvasive brain\u2013computer interface,\u201d Proc. Nat. Acad. Sci. USA, vol. 112, no. 44, pp. E6058\u2013E6067, Nov. 2015. [16] X. Chen, Y. Wang, S. Gao, T.-P. Jung, and X. Gao, \u201cFilter bank canonical correlation analysis for implementing a high-speed SSVEP-based brain\u2013computer interface,\u201d J. Neural Eng., vol. 12, no. 4, Aug. 2015, Art. no. 046008. [17] M. Nakanishi, Y. Wang, X. Chen, Y. Wang, X. Gao, and T.-P. Jung, \u201cEnhancing detection of SSVEPs for a high-speed brain speller using task-related component analysis,\u201d IEEE Trans. Biomed. Eng., vol. 65, no. 1, pp. 104\u2013112, Jan. 2018. [18] X. Chen, B. Zhao, Y. Wang, and X. Gao, \u201cCombination of highfrequency SSVEP-based BCI and computer vision for controlling a robotic arm,\u201d J. Neural Eng., vol. 16, no. 2, Apr. 2019, Art. no. 026012. [19] Y. Chen, C. Yang, X. Chen, Y. Wang, and X. Gao, \u201cA novel training-free recognition method for SSVEP-based BCIs using dynamic window strategy,\u201d J. Neural Eng., vol. 18, no. 3, Mar. 2021, Art. no. 036007. [20] Y. Chen, C. Yang, X. Ye, X. Chen, Y. Wang, and X. Gao, \u201cImplementing a calibration-free SSVEP-based BCI system with 160 targets,\u201d J. Neural Eng., Jun. 2021, Art. no. 046094. [21] X. Chen, Z. Chen, S. Gao, and X. Gao, \u201cA high-ITR SSVEP-based BCI speller,\u201d Brain-Comput. Interfaces, vol. 1, nos. 3\u20134, pp. 181\u2013191, 2014. [22] X. Chen, B. Zhao, Y. Wang, S. Xu, and X. Gao, \u201cControl of a 7-DOF robotic arm system with an SSVEP-based BCI,\u201d Int. J. Neural Syst., vol. 28, no. 8, Oct. 2018, Art. no. 1850018. [23] X. Chen, X. Huang, Y. Wang, and X. Gao, \u201cCombination of augmented reality based Brain- computer interface and computer vision for highlevel control of a robotic arm,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 28, no. 12, pp. 3140\u20133147, Dec. 2020. [24] X. Chen, N. Hu, Y. Wang, and X. Gao, \u201cValidation of a brain\u2013computer interface version of the digit symbol substitution test in healthy subjects,\u201d Comput. Biol. Med., vol. 120, May 2020, Art. no. 103729. [25] X. Chen, N. Hu, and X. Gao, \u201cDevelopment of a brain\u2013computer interface-based symbol digit modalities test and validation in healthy elderly volunteers and stroke patients,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 30, pp. 1433\u20131440, 2022. [26] M. Cheng, X. Gao, S. Gao, and D. Xu, \u201cDesign and implementation of a brain\u2013computer interface with high transfer rates,\u201d IEEE Trans. Biomed. Eng., vol. 49, no. 10, pp. 1181\u20131186, Oct. 2002. [27] X. Chen, B. Liu, Y. Wang, and X. Gao, \u201cA spectrally-dense encoding method for designing a high-speed SSVEP-BCI with 120 stimuli,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 30, pp. 2764\u20132772, 2022. [28] B. Liu, X. Chen, N. Shi, Y. Wang, S. Gao, and X. Gao, \u201cImproving the performance of individually calibrated SSVEP-BCI by task-discriminant component analysis,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 29, pp. 1998\u20132007, 2021. [29] Y. Wang, R. Wang, X. Gao, B. Hong, and S. Gao, \u201cA practical VEPbased brain\u2013computer interface,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 14, no. 2, pp. 234\u2013239, Feb. 2006. [30] G. Ming, W. Pei, H. Chen, X. Gao, and Y. Wang, \u201cOptimizing spatial properties of a new checkerboard-like visual stimulus for userfriendly SSVEP-based BCIs,\u201d J. Neural Eng., vol. 18, no. 5, Oct. 2021, Art. no. 056046. [31] P. F. Diez, V. A. Mut, E. M. A. Perona, and E. L. Leber, \u201cAsynchronous BCI control using high-frequency SSVEP,\u201d J. Neuroeng. Rehabil., vol. 8, p. 39, Jul. 2011. [32] I. Volosyak, D. Valbuena, T. L\u00fcth, T. Malechka, and A. Gr\u00e4ser, \u201cBCI demographics II: How many (and what kinds of) people can use a high-frequency SSVEP BCI?\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 19, no. 3, pp. 232\u2013239, Jun. 2011. [33] A. Chabuda, P. Durka, and J. Zygierewicz, \u201cHigh frequency SSVEPBCI with hardware stimuli control and phase-synchronized comb filter,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 26, no. 2, pp. 344\u2013352, Feb. 2018. [34] S. Ajami, A. Mahnam, and V. Abootalebi, \u201cAn adaptive SSVEPbased brain\u2013computer interface to compensate fatigue-induced decline of performance in practical application,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 26, no. 11, pp. 2200\u20132209, Nov. 2018. [35] X. Mao, W. Li, H. Hu, J. Jin, and G. Chen, \u201cImprove the classification efficiency of high-frequency phase-tagged SSVEP by a recursive Bayesian-based approach,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 28, no. 3, pp. 561\u2013572, Mar. 2020. [36] C. C. Hsu et al., \u201cExtraction of high-frequency SSVEP for BCI control using iterative filtering based empirical mode decomposition,\u201d Biomed. Signal Process. Control, vol. 61, Aug. 2020, Art. no. 102022. [37] K. Goto et al., \u201cThe effect of stimulus pattern, color combination and flicker frequency on steady-state visual evoked potentials topography,\u201d Int. J. Innov. Comput. Inf. Control, vol. 15, no. 4, pp. 1521\u20131530, Aug. 2019. [38] A. Duszyk et al., \u201cTowards an optimization of stimulus parameters for brain\u2013computer interfaces based on steady state visual evoked potentials,\u201d PLoS ONE, vol. 9, no. 11, Nov. 2014, Art. no. e112099. [39] S. Zhang and X. Chen, \u201cEffect of background luminance of visual stimulus on elicited steady-state visual evoked potentials,\u201d Brain Sci. Adv., vol. 8, no. 1, pp. 50\u201356, May 2022. [40] K. B. Ng, A. P. Bradley, and R. Cunnington, \u201cStimulus specificity of a steady-state visual-evoked potential-based brain\u2013computer interface,\u201d J. Neural Eng., vol. 9, no. 3, Jun. 2012, Art. no. 036008. [41] Y. Y. Chien et al., \u201cPolychromatic SSVEP stimuli with subtle flickering adapted to brain-display interactions,\u201d J. Neural Eng., vol. 14, no. 1, Feb. 2017, Art. no. 016018. [42] X. Chen, Y. Wang, S. Zhang, S. Xu, and X. Gao, \u201cEffects of stimulation frequency and stimulation waveform on steady-state visual evoked potentials using a computer monitor,\u201d J. Neural Eng., vol. 16, no. 6, Oct. 2019, Art. no. 066007. [43] E. P. Zambalde, L. R. Borges, G. Jablonski, M. B. de Almeida, and E. L. M. Naves, \u201cInfluence of stimuli spatial proximity on a SSVEPbased BCI performance,\u201d IRBM, vol. 43, no. 6, pp. 621\u2013627, Dec. 2022. [44] J. Chen et al., \u201cSimultaneous decoding of eccentricity and direction information for a single-flicker SSVEP BCI,\u201d Electronics, vol. 8, p. 155, Dec. 2019. [45] D. H. Brainard, \u201cThe psychophysics toolbox,\u201d Spatial Vis., vol. 10, no. 4, pp. 433\u2013436, 1997. [46] X. Zhao, Z. Wang, M. Zhang, and H. Hu, \u201cA comfortable steady state visual evoked potential stimulation paradigm using peripheral vision,\u201d J. Neural Eng., vol. 18, no. 5, Apr. 2021, Art. no. 056021. [47] P. Yuan, X. Gao, B. Allison, Y. Wang, G. Bin, and S. Gao, \u201cA study of the existing problems of estimating the information transfer rate in online brain\u2013computer interfaces,\u201d J. Neural Eng., vol. 10, no. 2, Apr. 2013, Art. no. 026014. [48] S. Ladouce, L. Darmet, J. J. T. Tresols, S. Velut, G. Ferraro, and F. Dehais, \u201cImproving user experience of SSVEP BCI through low amplitude depth and high frequency stimuli design,\u201d Sci. Rep., vol. 12, no. 1, p. 8865, May 2022. [49] X. Ye, C. Yang, Y. Chen, Y. Wang, X. Gao, and H. Zhang, \u201cMultisymbol time division coding for high-frequency steady-state visual evoked potential-based brain\u2013computer interface,\u201d IEEE Trans. Neural Syst. Rehabil. Eng., vol. 30, pp. 1693\u20131704, 2022. [50] A. I. Renton, J. B. Mattingley, and D. R. Painter, \u201cOptimising noninvasive brain\u2013computer interface systems for free communication between na\u00efve human participants,\u201d Sci. Rep., vol. 9, no. 1, p. 18705, Dec. 2019. [51] S. Abdelnabi, M. X. Huang, and A. Bulling, \u201cTowards high-frequency SSVEP-based target discrimination with an extended alphanumeric keyboard,\u201d in Proc. IEEE Int. Conf. Syst., Man Cybern. (SMC), Bari, Italy, Oct. 2019, pp. 4181\u20134186. [52] L. Liang, C. Yang, Y. Wang, and X. Gao, \u201cHigh-frequency SSVEP stimulation paradigm based on dual frequency modulation,\u201d in Proc. 41st Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC), Berlin, Germany, Jul. 2019, pp. 6184\u20136187."
        }
    ],
    "title": "Optimizing Stimulus Frequency Ranges for Building a High-Rate High Frequency SSVEP-BCI",
    "year": 2023
}