{
    "abstractText": "The Physics-Informed Neural Network (PINN) approach is a new and promising way to solve partial differential equations using deep learning. The L PhysicsInformed Loss is the de-facto standard in training Physics-Informed Neural Networks. In this paper, we challenge this common practice by investigating the relationship between the loss function and the approximation quality of the learned solution. In particular, we leverage the concept of stability in the literature of partial differential equation to study the asymptotic behavior of the learned solution as the loss approaches zero. With this concept, we study an important class of high-dimensional non-linear PDEs in optimal control, the Hamilton-JacobiBellman (HJB) Equation, and prove that for general L Physics-Informed Loss, a wide class of HJB equation is stable only if p is sufficiently large. Therefore, the commonly used L loss is not suitable for training PINN on those equations, while L\u221e loss is a better choice. Based on the theoretical insight, we develop a novel PINN training algorithm to minimize the L\u221e loss for HJB equations which is in a similar spirit to adversarial training. The effectiveness of the proposed algorithm is empirically demonstrated through experiments. Our code is released at https://github.com/LithiumDA/L_inf-PINN.",
    "authors": [
        {
            "affiliations": [],
            "name": "Chuwei Wang"
        },
        {
            "affiliations": [],
            "name": "Shanda Li"
        },
        {
            "affiliations": [],
            "name": "Di He"
        },
        {
            "affiliations": [],
            "name": "Liwei Wang"
        }
    ],
    "id": "SP:979086d3d015b757a6023a90ac08e2f2d1a16d5f",
    "references": [
        {
            "authors": [
                "Christian Beck",
                "Sebastian Becker",
                "Patrick Cheridito",
                "Arnulf Jentzen",
                "Ariel Neufeld"
            ],
            "title": "Deep splitting method for parabolic pdes",
            "venue": "SIAM Journal on Scientific Computing,",
            "year": 2021
        },
        {
            "authors": [
                "Dimitri Bertsekas",
                "Steven E Shreve"
            ],
            "title": "Stochastic optimal control: the discrete-time case, volume 5",
            "venue": "Athena Scientific,",
            "year": 1996
        },
        {
            "authors": [
                "Michael Christ",
                "James Colliander",
                "Terrence Tao"
            ],
            "title": "Asymptotics, frequency modulation, and low regularity ill-posedness for canonical defocusing equations",
            "venue": "American journal of mathematics,",
            "year": 2003
        },
        {
            "authors": [
                "Ashley Davey",
                "Harry Zheng"
            ],
            "title": "Deep learning for constrained utility maximisation",
            "venue": "Methodology and Computing in Applied Probability,",
            "year": 2022
        },
        {
            "authors": [
                "Tim De Ryck",
                "Ameya D Jagtap",
                "Siddhartha Mishra"
            ],
            "title": "Error estimates for physics informed neural networks approximating the navier-stokes equations",
            "venue": "arXiv preprint arXiv:2203.09346,",
            "year": 2022
        },
        {
            "authors": [
                "Yu Deng",
                "Nader Masmoudi"
            ],
            "title": "Long time instability of the couette flow in low gevrey spaces",
            "venue": "arXiv preprint arXiv:1803.01246,",
            "year": 2018
        },
        {
            "authors": [
                "Lawrence C Evans"
            ],
            "title": "Partial differential equations",
            "venue": "Graduate studies in mathematics,",
            "year": 1998
        },
        {
            "authors": [
                "Wendell H Fleming",
                "Raymond W Rishel"
            ],
            "title": "Deterministic and stochastic optimal control, volume 1",
            "venue": "Springer Science & Business Media,",
            "year": 2012
        },
        {
            "authors": [
                "Peter A Forsyth",
                "J Shannon Kennedy",
                "Shu Tong Tse",
                "Heath Windcliff"
            ],
            "title": "Optimal trade execution: a mean quadratic variation approach",
            "venue": "Journal of Economic dynamics and Control,",
            "year": 1971
        },
        {
            "authors": [
                "David Gilbarg",
                "Neil S Trudinger",
                "NS Trudinger"
            ],
            "title": "Elliptic partial differential equations of second order, volume 224",
            "year": 1977
        },
        {
            "authors": [
                "Igor Halperin"
            ],
            "title": "Distributional offline continuous-time reinforcement learning with neural physicsinformed pdes (sciphy rl for doctr-l)",
            "venue": "arXiv preprint arXiv:2104.01040,",
            "year": 2021
        },
        {
            "authors": [
                "Jiequn Han",
                "Arnulf Jentzen",
                "E Weinan"
            ],
            "title": "Solving high-dimensional partial differential equations using deep learning",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2018
        },
        {
            "authors": [
                "Yuehaw Khoo",
                "Jianfeng Lu",
                "Lexing Ying"
            ],
            "title": "Solving parametric pde problems with artificial neural networks",
            "venue": "arXiv preprint arXiv:1707.03351,",
            "year": 2017
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "In ICLR (Poster),",
            "year": 2015
        },
        {
            "authors": [
                "Donald E Kirk"
            ],
            "title": "Optimal control theory: an introduction",
            "venue": "Courier Corporation,",
            "year": 2004
        },
        {
            "authors": [
                "Aditi Krishnapriyan",
                "Amir Gholami",
                "Shandian Zhe",
                "Robert Kirby",
                "Michael W Mahoney"
            ],
            "title": "Characterizing possible failure modes in physics-informed neural networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Weiwei Li",
                "Emanuel Todorov",
                "Dan Liu"
            ],
            "title": "Inverse optimality design for biological movement systems",
            "venue": "IFAC Proceedings Volumes,",
            "year": 2011
        },
        {
            "authors": [
                "Gary M Lieberman"
            ],
            "title": "Second order parabolic differential equations",
            "venue": "World scientific,",
            "year": 1996
        },
        {
            "authors": [
                "Zhiwu Lin",
                "Chongchun Zeng"
            ],
            "title": "Inviscid dynamical structures near couette flow",
            "venue": "Archive for rational mechanics and analysis,",
            "year": 2011
        },
        {
            "authors": [
                "Yiping Lu",
                "Haoxuan Chen",
                "Jianfeng Lu",
                "Lexing Ying",
                "Jose Blanchet"
            ],
            "title": "Machine learning for elliptic pdes: Fast rate generalization bound, neural scaling law and minimax optimality",
            "venue": "arXiv preprint arXiv:2110.06897,",
            "year": 2021
        },
        {
            "authors": [
                "Robert C Merton"
            ],
            "title": "Optimum consumption and portfolio rules in a continuous-time model. In Stochastic optimization models in finance, pages 621\u2013661",
            "year": 1975
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Marcus Pereira",
                "Ziyi Wang",
                "Tianrong Chen",
                "Emily Reed",
                "Evangelos Theodorou"
            ],
            "title": "Feynmankac neural network architectures for stochastic control using second-order fbsde theory",
            "venue": "In Learning for Dynamics and Control,",
            "year": 2020
        },
        {
            "authors": [
                "Marcus Pereira",
                "Ziyi Wang",
                "Ioannis Exarchos",
                "Evangelos A Theodorou"
            ],
            "title": "Learning deep stochastic optimal control policies using forward-backward sdes",
            "year": 1902
        },
        {
            "authors": [
                "Huy\u00ean Pham"
            ],
            "title": "Continuous-time stochastic control and optimization with financial applications, volume 61",
            "venue": "Springer Science & Business Media,",
            "year": 2009
        },
        {
            "authors": [
                "Huyen Pham",
                "Xavier Warin",
                "Maximilien Germain"
            ],
            "title": "Neural networks-based backward scheme for fully nonlinear pdes",
            "venue": "SN Partial Differential Equations and Applications,",
            "year": 2021
        },
        {
            "authors": [
                "Maziar Raissi",
                "Paris Perdikaris",
                "George E Karniadakis"
            ],
            "title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "venue": "Journal of Computational Physics,",
            "year": 2019
        },
        {
            "authors": [
                "Tim De Ryck",
                "Ameya D. Jagtap",
                "Siddhartha Mishra"
            ],
            "title": "Error estimates for physics informed neural networks approximating the navier-stokes",
            "venue": "equations. CoRR,",
            "year": 2022
        },
        {
            "authors": [
                "Alexander Schied",
                "Torsten Sch\u00f6neborn"
            ],
            "title": "Risk aversion and the dynamics of optimal liquidation strategies in illiquid markets",
            "venue": "Finance and Stochastics,",
            "year": 2009
        },
        {
            "authors": [
                "Yeonjong Shin",
                "Zhongqiang Zhang",
                "George Em Karniadakis"
            ],
            "title": "Error estimates of residual minimization using neural networks for linear pdes",
            "venue": "arXiv preprint arXiv:2010.08019,",
            "year": 2020
        },
        {
            "authors": [
                "Stanislaw Sieniutycz"
            ],
            "title": "Hamilton\u2013jacobi\u2013bellman framework for optimal control in multistage energy systems",
            "venue": "Physics Reports,",
            "year": 2000
        },
        {
            "authors": [
                "Justin Sirignano",
                "Konstantinos Spiliopoulos"
            ],
            "title": "Dgm: A deep learning algorithm for solving partial differential equations",
            "venue": "Journal of computational physics,",
            "year": 2018
        },
        {
            "authors": [
                "Sifan Wang",
                "Yujun Teng",
                "Paris Perdikaris"
            ],
            "title": "Understanding and mitigating gradient flow pathologies in physics-informed neural networks",
            "venue": "SIAM Journal on Scientific Computing,",
            "year": 2021
        },
        {
            "authors": [
                "Colby L Wight",
                "Jia Zhao"
            ],
            "title": "Solving allen-cahn and cahn-hilliard equations using the adaptive physics informed neural networks",
            "venue": "arXiv preprint arXiv:2007.04542,",
            "year": 2020
        },
        {
            "authors": [
                "Jan Willems"
            ],
            "title": "Least squares stationary optimal control and the algebraic riccati equation",
            "venue": "IEEE Transactions on automatic control,",
            "year": 1971
        },
        {
            "authors": [
                "William M Wonham"
            ],
            "title": "On a matrix riccati equation of stochastic control",
            "venue": "SIAM Journal on Control,",
            "year": 1968
        },
        {
            "authors": [
                "Jiongmin Yong",
                "Xun Yu Zhou"
            ],
            "title": "Stochastic controls: Hamiltonian systems and HJB equations, volume 43",
            "venue": "Springer Science & Business Media,",
            "year": 1999
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Recently, with the explosive growth of available data and computational resources, there have been growing interests in developing machine learning approaches to solve partial differential equations (PDEs) [14, 13, 33, 28]. One seminal work in this direction is the Physics-Informed Neural Network (PINN) approach [28] which parameterizes the PDE\u2019s solution as a neural network. By defining differentiable loss functionals that measure how well the model fits the PDE and boundary conditions, the network parameters can be efficiently optimized using gradient-based approaches. L2 distance is one of the most popularly used measures, which calculates the L2 norm of the PDE and boundary residual on the domain and boundary, respectively. Previous works demonstrated that PINN could solve a wide range of PDE problems using the L2 Physics-Informed Loss, such as Poisson equation, Burgers\u2019 equation, and Navier-Stokes equation [28, 6].\nAlthough previous works empirically demonstrated promising results using L2 Physics-Informed Loss, we argue the plausibility of using this loss for (high-dimensional) non-linear PDE problems. \u2217Equal contribution. \u2020Correspondence to: Liwei Wang <wanglw@pku.edu.cn> and Di He <dihe@pku.edu.cn>.\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\nar X\niv :2\n20 6.\n02 01\n6v 5\n[ cs\n.L G\n] 3\nWe know the trivial fact that the learned solution will equal the exact solution when its L2 loss equals zero. However, the quality of a learned solution with a small but non-zero loss, which is a more realistic scenario in practice, remains unknown to have any approximation guarantees. In this work, we aim at answering a fundamental question:\nCan we guarantee that a learned solution with a small Physics-Informed Loss always corresponds to a good approximator of the exact solution?\nTo thoroughly investigate the problem, we advocate analyzing the stability of PDE [8] in the PINN framework. Stability characterizes the asymptotic behavior of the distance between the learned solution and the exact solution when the Physics-Informed Loss approaches zero. If the PDE is not stable with respect to certain loss functions, we may not obtain good approximate solutions by minimizing the loss. To show the strength of the theory, we perform a comprehensive study on the stability of an important class of high-dimensional non-linear PDEs in optimal control, the Hamilton-Jacobi-Bellman (HJB) equation, which establishes a necessary and sufficient condition for a control\u2019s optimality with regard to the cost function. Interestingly, we prove that for general Lp Physics-Informed Loss, the HJB equation is stable only if p is sufficiently large. This finding suggests that the most widely used L2 loss may not be suitable for training PINN on HJB equations as the learned solution can be arbitrarily distant from the exact solution. Empirical observation verifies the theoretical results.\nWe further show our theory can serve as a principled way to design loss functions for training PINN. For the high-dimensional HJB equation we target in the paper, the theoretical result suggests that L\u221e loss may be a better choice to learn approximate solutions. Motivated by this insight, we propose a new algorithm for training PINN, which adopts a min-max optimization procedure to minimize the L\u221e loss. Our approach resembles the well-known adversarial training framework. In each iteration, we first fix the network parameters and learn adversarial data points to approximate L\u221e loss, and then optimize the network parameters to minimize the loss. When the training finishes, the learned network will converge to a solution with small L\u221e losses and is close to the exact solution. We conduct experiments to demonstrate the effectiveness of the proposed algorithm. All empirical results show that our method can indeed learn accurate solutions for HJB equations and is much better than several baseline methods.\nThe contribution of the paper is summarized as follows.\n\u2022 We make the first step towards theoretically studying the loss design in PINN, and formally introduce the concept of stability in the literature of PDE to characterize the quality of a learned solution with small but non-zero Physics-Informed Loss.\n\u2022 We provide rigorous investigations on an important class of high-dimensional non-linear PDEs in optimal control, the HJB equation. Our results suggest that the widely used L2 loss is not a suitable choice for training PINN on HJB equations.\n\u2022 Based on the theoretical insight, we develop a novel PINN training algorithm to minimize the L\u221e loss for HJB equations. We empirically demonstrate that the proposed algorithm can significant improve the accuracy of PINN in solving the optimal control problems."
        },
        {
            "heading": "2 Related Works",
            "text": "Physics-Informed Neural Network approaches [33, 28] learn to find parametric solutions to satisfy equations and boundary conditions with gradient descent. There has been a notable scarcity of papers that rigorously justify why PINNs work. Important works include [31], which prove the convergence of PINN for second-order elliptic and parabolic equations. In [21], the authors study the statistical limit of learning a PDE solution from sampled observations for elliptic equations. In [29], the convergence of PINN with L2 loss is established for Navier-Stokes equations. At the same time, several works observed different failure modes for training PINN in other PDE problems. In [17], researchers discover that PINN sometimes fails to learn accurate solutions to a class of convection and reaction equations. Their analysis shows that this may be attributed to the complicated loss landscape. [34] observed PINN failed to learn the Helmholtz equation due to the incommensurability between PDE and boundary losses.\nIn this work, we mainly experiment with the Hamilton-Jacobi-Bellman (HJB) equation in optimal control. Previously, there were several works aiming at solving the HJB equation using deep learning methods [12, 13, 25, 39, 24, 1, 27, 5]. [13] is among the first to leverage neural networks to solve HJB equations. In particular, [13] targets constructing an approximation to a solution value u at T = 0, which is further transformed into a backward stochastic differential equation and learned by neural networks. The main difference between [13] and ours is that [13] only learns the solution on a pre-defined time frame, while with our method, the obtained solution can be evaluated for any time frame. Recently, [12] tackled the offline reinforcement learning problem and developed a soft relaxation of the classical HJB equation, which can be learned using offline behavior data. The main difference between [12] and ours is that no additional data is required in our setting.\nStability is one of the most fundamental concepts in studying the well-posedness of PDE problems. Formally speaking, it characterizes the behavior of the solution to a PDE problem when a small perturbation modifies the operator, initial condition, boundary condition, or force term. We say the equation is stable if the solution of the perturbed PDE converges to the exact solution as the perturbations approach zero [8]. The problem regarding whether a PDE is stable has been intensively studied [8, 19, 11] in literature. There are also some works studying how (regularity) conditions affect stability. [20] and [7] investigate in which topology Couette Flow is asymptotic stable. [4] answers in which Sobolev space defocusing nonlinear Schrodinger equation, real Korteweg-de Vries (KdV), and modified KdV are locally well-posed. Our main focus is akin to the latter works but is settled in the machine learning framework."
        },
        {
            "heading": "3 Preliminary",
            "text": "In this section, we introduce basic background on Physics-Informed Neural Networks and stochastic optimal control problems. Without loss of generality, we formulate any partial differential equation as: {\nLu(x) = \u03d5(x) x \u2208 \u2126 \u2282 Rn Bu(x) = \u03c8(x) x \u2208 \u2202\u2126, (1)\nwhere L is the partial differential operator and B is the boundary condition. We use x to denote the spatiotemporal-dependent variable, and use \u2126 and \u2202\u2126 to denote the domain and boundary.\nPhysics-Informed Neural Networks (PINN) PINN [28] is a popular choice to learn the function u(x) automatically by minimizing the loss function induced by the PDE (1). To be concrete, given p \u2208 (1,+\u221e), we define the Lp Physics-Informed Loss as\n`\u2126,p(u) = \u2016Lu(x)\u2212 \u03d5(x)\u2016pLp(\u2126), (2) `\u2202\u2126,p(u) = \u2016Bu(x)\u2212 \u03c8(x)\u2016pLp(\u2202\u2126). (3)\nThe loss term `\u2126,p(u) in Eq. (2) corresponds to the PDE residual, which evaluates how u(x) fits the partial differential equation on \u2126; and `\u2202\u2126,p(u) in Eq. (3) corresponds to the boundary residual, which measures how well u(x) satisfies the boundary condition on \u2202\u2126. Lp denotes p-norm, where p is usually set to 2, leading to a \u201cmean squared error\u201d interpretation of the loss function [33, 28]. The goal is to find u\u2217 that minimizes a linear combination of the two losses defined above. The function u(x) is usually parameterized by neural network u\u03b8(x) with parameter \u03b8 \u2208 \u0398. To find \u03b8\u2217 efficiently, PINN approaches use gradient-based optimization methods. Note that computing the loss involves integrals over \u2126 and \u2202\u2126. Thus, Monte Carlo methods are commonly used to approximate `\u2126,p(u) and `\u2202\u2126,p(u) in practice.\nStochastic Optimal Control Stochastic control [9, 3] is an important sub-field in optimal control theory. In stochastic control, the state function {Xt}0\u2264t\u2264T is a stochastic process, where T is the time horizon of the control problem. The evolution of the state function is governed by the following stochastic differential equation:{\ndXs = m(s,Xs)ds+ \u03c3dWs s \u2208 [t, T ] Xt = x , (4)\nwhere m : [t, T ]\u00d7Rn \u2192 Rn is the control function and {Ws} is a standard n-dimensional Brownian motion.\nGiven a control function m, its total cost is defined as Jx,t(m) = E \u222b T t r(Xs,m, s)ds + g(XT ), where r : Rn\u00d7Rn\u00d7 [0, T ]\u2192 R measures the cost rate during the process and g : Rn \u2192 R measures the final cost at the terminal state. The expectation is taken over the randomness of the trajectories.\nWe are interested in finding a control function that minimizes the total cost for a given initial state. Formally speaking, we define the value function of the control problem (4) as u(x, t) = min\nm\u2208M Jx,t(m),\nwhereM denotes the set of possible control functions that we take into consideration. It can be obtained that the value function will follow a particular partial differential equation as stated below.\nDefinition 3.1 ([38]). The value function u(x, t) is the unique solution to the following partial differential equation, which is called Hamilton-Jacobi-Bellman Equation:{\n\u2202tu(x, t) + 1 2\u03c3 2\u2206u(x, t) + min m\u2208M [r(x,m(t, x), t) +\u2207u \u00b7mt] = 0 u(x, T ) = g(x). (5)\nHamilton-Jacobi-Bellman (HJB) equation establishes a necessary and sufficient condition for a control\u2019s optimality with regard to the cost functions. It is one of the most important high-dimensional PDEs [16] in optimal control with tremendous applications in physics [32], biology [18], and finance [26]. Many well-known equations, including Riccati equation, Linear\u2013Quadratic\u2013Gaussian control problem [36], Merton\u2019s portfolio problem [22] are special cases of HJB equation [37].\nConventionally, the solution to the HJB equation, i.e., the value function u(x, t), can be computed using dynamic programming [2]. However, the computational complexity of dynamic programming will grow exponentially with the dimension of state function. Considering that the state function in many applications is high-dimensional, solving such HJB equations is notoriously difficult in practice using conventional solvers. As neural networks have shown impressive power in learning high-dimensional functions, it\u2019s natural to resort to neural-network-based approaches for solving high-dimensional HJB equations."
        },
        {
            "heading": "4 Failure Mode of PINN on High-Dimensional Stochastic Optimal Control",
            "text": "Note that u(x) is the exact solution to the PDE (1) if and only if both loss terms `\u2126,p(u) and `\u2202\u2126,p(u) are zero. However, in practice, we usually can only obtain small but non-zero loss values due to the randomness in the optimization procedure or the capacity of the neural network. In such cases, a natural question arises: whether a learned u(x) with a small loss will correspond to a good approximator to the exact solution u\u2217(x)? Such a property is highly related to the concept stability in PDE literature, which can be defined as below in our learning scenario:\nDefinition 4.1. Suppose Z1, Z2, Z3 are three Banach spaces. We say a PDE defined as Eq. (1) is (Z1, Z2, Z3)-stable, if \u2016u\u2217(x) \u2212 u(x)\u2016Z3 = O(\u2016Lu(x) \u2212 \u03d5(x)\u2016Z1 + \u2016Bu(x) \u2212 \u03c8(x)\u2016Z2) as \u2016Lu(x)\u2212 \u03d5(x)\u2016Z1 , \u2016Bu(x)\u2212 \u03c8(x)\u2016Z2 \u2192 0 for any function u.\nBy definition, if a PDE is (L2(\u2126), L2(\u2202\u2126), Z)-stable with a suitable Banach space Z, we can minimize the widely used L2 Physics-Informed Losses \u2016Lu(x)\u2212\u03d5(x)\u20162L2(\u2126) and \u2016Bu(x)\u2212\u03c8(x)\u2016 2 L2(\u2202\u2126), and the learned solution is guaranteed to be close to the exact solution when the loss terms approach zero. However, stability is not always an obvious property for PDEs. There are tremendous equations that are unstable, such as the inverse heat equation. Moreover, even if an equation is stable, it is possible that the equation is not (L2(\u2126), L2(\u2202\u2126), Z)-stable, which suggests that the original L2 Physics-Informed Loss might not be a good choice for solving it. We will show later that for control problems, some practical high-dimensional HJB equations are stable but not (L2(\u2126), L2(\u2202\u2126), Z)stable, and using L2 Physics-Informed Loss will fail to find an approximated solution in practice.\nWe consider a class3 of HJB equations in which the cost rate function is formulated as r(x,m) = a1|m1|\u03b11 + \u00b7 \u00b7 \u00b7+ an|mn|\u03b1n \u2212 \u03d5(x, t). The corresponding Hamilton-Jacobi-Bellman equation can\n3The form of cost function we investigate in the paper is representative in optimal control. For example, in financial markets, we often face power-law trading cost in optimal execution problems [10, 30]. The cost function in Linear\u2013Quadratic\u2013Gaussian control and Merton\u2019s portfolio model (constant relative risk aversion utility function in [22]) is also of this form. Therefore, we believe our theoretical analysis for this class of HJB equation is relevant for practical applications.\nbe reformulated as:LHJBu := \u2202tu(x, t) + 1 2 \u03c32\u2206u(x, t)\u2212 n\u2211 i=1 Ai|\u2202xiu|ci = \u03d5(x, t) (x, t) \u2208 Rn \u00d7 [0, T ]\nBHJBu := u(x, T ) = g(x) x \u2208 Rn , (6)\nwhere Ai = (ai\u03b1i) \u2212 1\u03b1i\u22121 \u2212 ai(ai\u03b1i)\u2212 \u03b1i \u03b1i\u22121 \u2208 (0,+\u221e) and ci = \u03b1i\u03b1i\u22121 \u2208 (1,\u221e). See Appendix B for the detailed derivation. For a function f : X \u2192 R, where X is a measurable space, we denote by suppf the support set of f , i.e. the closure of {x \u2208 X : f(x) 6= 0}. An important concept for analyzing PDEs is the Sobolev space, which is defined as follows: Definition 4.2. For m \u2208 N, p \u2208 [1,+\u221e) and an open set \u2126 \u2282 Rn, the Sobolev space Wm,p(\u2126) is defined as {f(x) \u2208 Lp(\u2126) : D\u03b1f \u2208 Lp(\u2126),\u2200\u03b1 \u2208 Nn, |\u03b1| \u2264 m}. The function space Wm,p(\u2126) is\nequipped with Sobolev norm, which is defined as \u2016f\u2016Wm,p(\u2126) = ( \u2211 |\u03b1|\u2264m \u2016D\u03b1f\u2016pLp(\u2126) ) 1 p .\nThe definition above can be extended to functions defined on a spatiotemporal domain Q \u2286 Rn \u00d7 [0, T ]. With a slight abuse of notation, we define Wm,p(Q) = {f(x, t) \u2208 Lp(Q) : D\u03b1f \u2208 Lp(Q),\u2200\u03b1 \u2208 Nn, |\u03b1| \u2264 m}, where the differential D\u03b1 is only operated over spatial variable x. The norm \u2016 \u00b7 \u2016Wm,p(Q) can also be defined accordingly.\nStability of the HJB Equation We present our main theoretical result which characterizes the stability of the HJB equation (Eq. (6)). In particular, we show that the HJB equation is (Lp(Rn \u00d7 [0, T ]), Lq(Rn),W 1,r(Rn \u00d7 [0, T ]))-stable when p, q and r satisfies certain conditions. We take the Banach space Z3 in Definition 4.1 as W 1,r here because it captures the properties of both the value and the derivatives of a function, but Lp spaces do not. However, as could be seen from Appendix B, for optimal control problems, it is essential to obtain an accurate approximator for both the value and the gradient of the value function u (the solution of (Eq. (6)). Thus, it is appropriate to analyze the quality of the approximate solution in W 1,r space.\nTheorem 4.3. For p, q \u2265 1, let r0 = (n+2)qn+q . Assume the following inequalities hold for p, q and r0: p \u2265 max { 2, ( 1\u2212 1\nc\u0304\n) n } ; q > (c\u0304\u2212 1)n2\n(2\u2212 c\u0304)n+ 2 ;\n1 r0 \u2265 1 p \u2212 1 n , (7)\nwhere c\u0304 = max 1\u2264i\u2264n ci in Eq. (6). Then for any r \u2208 [1, r0) and any bounded open set Q \u2282 Rn \u00d7 [0, T ], Eq. (6) is (Lp(Rn \u00d7 [0, T ]), Lq(Rn),W 1,r(Q))-stable for c\u0304 \u2264 2.\nThe proof of Theorem 4.3 can be found in Appendix C and an improved theorem with relaxed dependency on c\u0304 can be found in Appendix E. Intuitively, Theorem 4.3 states that (Lp, Lq,W 1,r)stability of Eq. (6) can be achieved when p, q = \u2126(n). We further show that this linear dependency on n cannot be relaxed in the following theorem: Theorem 4.4. There exists an instance of Eq. (6), whose exact solution is u\u2217, such that for any \u03b5 > 0, A > 0, r \u2265 1,m \u2208 N and p \u2208 [ 1, n4 ] , there exists a function u \u2208 C\u221e(Rn \u00d7 (0, T ]) which satisfies the following conditions:\n\u2022 \u2016LHJBu\u2212 \u03d5\u2016Lp(Rn\u00d7[0,T ]) < \u03b5, BHJBu = BHJBu\u2217, and supp(u\u2212 u\u2217) is compact, where LHJB and BHJB are defined in Eq. (6).\n\u2022 \u2016u\u2212 u\u2217\u2016Wm,r(Rn\u00d7[0,T ]) > A.\nThe proof of Theorem 4.4 can be found in Appendix D.\nDiscussion. Theorem 4.3 and 4.4 together state that when the dimension of the state function n is large, the HJB equation in Eq. (6) cannot be (Lp, Lq,W 1,r)-stable if p and q are small. Furthermore, since Lr=W 0,r by definition, Theorem 4.4 also implies that Eq. (6) is not even (Lp, Lq, Lr)-stable. Therefore, for high-dimensional HJB problems, if we use classic L2 Physics-Informed Loss for training PINN, the learned solution may be arbitrarily distant from u\u2217 even if the loss is very small. Such theoretical results are verified in our empirical studies in Section 6.\nMore importantly, our theoretical results indicate that the design choice of the Physics-Informed Loss plays a significant role in solving PDEs using PINN. In this work, we shed light upon this problem using HJB equations. We believe the relationship between PDE\u2019s stability and the Physics-Informed Loss should be carefully investigated in the future, especially for high-dimensional non-linear PDEs whose stability are more complicated than low-dimensional and linear ones [8, 11, 19]. Given the above observations, we further propose a new algorithm for training PINN to solve HJB Equations, which will be presented in the subsequent sections."
        },
        {
            "heading": "5 Solving HJB Equations with Adversarial Training",
            "text": "The above results suggest that we should use a large value of p and q in the loss `\u2126,p(u) and `\u2202\u2126,q(u) to guarantee a learned solution u is close to u\u2217 for high-dimensional HJB problems. Note that Lp-norm and L\u221e-norm behave similarly when p is large. We can substitute Lp-norm by L\u221e-norm and directly optimize `\u2126,\u221e(u) and `\u2202\u2126,\u221e(u). Overall, the training objective can be formulated as:\nmin u `\u221e(u) = sup x\u2208\u2126 |Lu(x)\u2212 \u03d5(x)|+ \u03bb sup x\u2208\u2202\u2126 |Bu(x)\u2212 \u03c8(x)|, (8)\nwhere \u03bb > 0 is a hyper-parameter to trade off the two objectives.\nIt is straightforward to obtain that setting p and q to infinity satisfies the conditions in Theorem 4.3, and thus the quality of the learned solution enjoys theoretical guarantee. Furthermore, Eq. (8) can be regarded as a min-max optimization problem. The inner loop is a maximization problem to find data points on \u2126 and \u2202\u2126 where u violates the PDE most, and the outer loop is a minimization problem to find u (i.e., the neural network parameters) that minimizes the loss on those points.\nIn deep learning, such a min-max optimization problem has been intensively studied, and adversarial training is one of the most effective learning approaches in many applications. We leverage adversarial training, and the detailed implementation is described in Algorithm 1. In each training step, the model parameters and data points are iteratively updated. We first fix the model u and randomly sample data points x(1), \u00b7 \u00b7 \u00b7 , x(N1) \u2208 \u2126 and x\u0303(1), \u00b7 \u00b7 \u00b7 , x\u0303(N2) \u2208 \u2202\u2126, serving as a random initialization of the inner loop optimization. Then we perform gradient-based methods to obtain data points with large point-wise Physics-Informed Losses, which leads to the following inner-loop update rule:\nx(k) \u2190 Project\u2126 ( x(k) + \u03b7 sign\u2207x ( Lu\u03b8(x(k))\u2212 \u03d5(x(k)) )2) ; (9)\nx\u0303(k) \u2190 Project\u2202\u2126 ( x\u0303(k) + \u03b7 sign\u2207x ( Bu\u03b8(x\u0303(k))\u2212 \u03c8(x\u0303(k)) )2) , (10)\nAlgorithm 1 L\u221e Training for Physics-Informed Neural Networks Input: Target PDE (Eq. (1)); neural network u\u03b8; initial model parameters \u03b8 Output: Learned PDE solution u\u03b8 Hyper-parameters: Number of total training iterations M ; number of iterations and step size of inner loop K, \u03b7; weight for combining the two loss term \u03bb 1: for i = 1, \u00b7 \u00b7 \u00b7 ,M do 2: Sample x(1), \u00b7 \u00b7 \u00b7 , x(N1) \u2208 \u2126 and x\u0303(1), \u00b7 \u00b7 \u00b7 , x\u0303(N2) \u2208 \u2202\u2126 3: for j = 1, \u00b7 \u00b7 \u00b7 ,K do 4: for k = 1, \u00b7 \u00b7 \u00b7 , N1 do 5: x(k) \u2190 Project\u2126 ( x(k) + \u03b7 sign\u2207x ( Lu\u03b8(x(k))\u2212 \u03d5(x(k))\n)2) 6: for k = 1, \u00b7 \u00b7 \u00b7 , N2 do 7: x\u0303(k) \u2190 Project\u2202\u2126 ( x\u0303(k) + \u03b7 sign\u2207x ( Bu\u03b8(x\u0303(k))\u2212 \u03c8(x\u0303(k))\n)2) 8: g \u2190 \u2207\u03b8 ( 1\nN1 N1\u2211 i=1 ( Lu\u03b8(x(i))\u2212 \u03d5(x(i)) )2 + \u03bb \u00b7 1 N2 N2\u2211 i=1 ( Bu\u03b8(x\u0303(i))\u2212 \u03c8(x\u0303(i)) )2) 9: \u03b8 \u2190 Optimizer (\u03b8, g)\n10: return u\u03b8\nwhere Project\u2126 (\u00b7) and Project\u2202\u2126 (\u00b7) project the updated data points to the domain. When the inner-loop optimization finishes, we fix the generated data points and calculate the gradient g to the model parameter:\ng \u2190 \u2207\u03b8\n( 1\nN1 N1\u2211 i=1 ( Lu\u03b8(x(i))\u2212 \u03d5(x(i)) )2 + \u03bb \u00b7 1 N2 N2\u2211 i=1 ( Bu\u03b8(x\u0303(i))\u2212 \u03c8(x\u0303(i)) )2) , (11)\nthen the model parameter can be updated using any first-order optimization methods. When the training finishes, the learned neural network will converge to a solution with small L\u221e losses and is guaranteed to be close to the exact solution."
        },
        {
            "heading": "6 Experiments",
            "text": "In this section, we conduct experiments to verify the effectiveness of our approach. Ablation studies on the design choices and hyper-parameters are then provided. Our codes are implemented based on PyTorch [23]. All the models are trained on one NVIDIA Tesla V100 GPU with 16GB memory. Due to space limitation, we only showcase our methods on the Linear Quadratic Gaussian control problem in the main body of the paper. More experimental results on other PDE problems can be found in Appendix G."
        },
        {
            "heading": "6.1 High Dimensional Linear Quadratic Gaussian Control Problem",
            "text": "We follow [13] to study the classical linear-quadratic Gaussian (LQG) control problem in n dimensions, a special case of the HJB equation:{\n\u2202tu(x, t) + \u2206u(x, t)\u2212 \u00b5\u2016\u2207xu(x, t)\u20162 = 0 x \u2208 Rn, t \u2208 [0, T ] u(x, T ) = g(x) x \u2208 Rn, (12)\nAs is shown in [13], there is a unique solution to Eq. (12):\nu(x, t) = \u2212 1 \u00b5 ln (\u222b Rn (2\u03c0)\u2212n/2e\u2212\u2016y\u2016 2/2 \u00b7 e\u2212\u00b5g(x\u2212 \u221a 2(T\u2212t)y)dy ) , (13)\nWe set \u00b5 = 1, T = 1, and the terminal cost function g(x) = ln ( 1 + \u2016x\u20162\n2\n) .\nExperimental Design The neural network used for training is a 4-layer MLP with 4096 neurons and tanh activation in each hidden layer. To train the models, we use Adam as the optimizer [15]. The learning rate is set to 7e\u22124 in the beginning and then decays linearly to zero during training. The total number of training iterations is set to 5000/10000 for the 100/250-dimensional problem. In each training iteration, we sample N1 = 100/50 points from the domain Rn \u00d7 [0, T ] and N2 = 100/50 points from the boundary Rn \u00d7 {T} to obtain a mini-batch for the 100/250-dimensional problem. The number of inner-loop iterations K is set to 20, and the inner-loop step size \u03b7 is set to 0.05 unless otherwise specified. Evaluations are performed on a hold-out validation set which is unseen during\ntraining. We use the L1, L2, and W 1,1 relative error in [0, 1]n \u00d7 [0, T ] as evaluation metrics: L1 and L2 relative errors are popular evaluation metrics in literature. We additionally consider W 1,1 relative error since the gradient of the solution to HJB equations plays an important role in applications, and our theory indicates that Eq. (12) is (L\u221e, L\u221e,W 1,r) stable. More detailed descriptions of the experimental setting and evaluation metrics can be found in Appendix F.\nWe compare our method with a few strong baselines: 1) original PINN trained with L2 PhysicsInformed Loss [28]; 2) adaptive time sampling for PINN training proposed in [35]; 3) PINN with the learning rate annealing algorithm proposed in [34]; 4) curriculum PINN regularization proposed in [17]. The training recipes for the baseline methods, including the neural network architecture, the training iterations, the optimizer, and the learning rate, are the same as those of our method described above. It should be noted that although these approaches modifies the data sampler, training algorithms or the loss function, they all keep the L2 norm of the PDE residual and boundary residual unchanged in the training objective.\nExperimental Results The experimental results are summarized in Table 1. It\u2019s clear that the relative error of the model trained using the original PINN does not fit the solution well, e.g., the L1 relative error is larger than 6% when n = 250. This empirical observation aligns well with our theoretical analysis, i.e., minimizing L2 loss cannot guarantee the learned solution to be accurate. Advanced methods, e.g., curriculum PINN regularization [17], can improve the accuracy of the learned solution but with marginal improvement, which suggests that these methods do not address the key limitation of PINN in solving high-dimensional HJB Equations. By contrast, our proposed method significantly outperforms all the baseline methods in terms of both Lp relative error and Sobolev relative error, which indicates that both the values and the gradients of our learned solutions are more accurate than the baselines.\nWe also examine the quality of the learned solution u(x, t) by visualization. As the solution is a high-dimensional function, we visualize its snapshot on a two-dimensional space. Specifically, we consider a bivariate function u(x1, x2, 0, \u00b7 \u00b7 \u00b7 , 0; 0) and use a heatmap to show its function value given different x1 and x2. Figure 1 shows the ground truth u\u2217, the learned solutions u of original PINN and our method, and the point-wise absolute error |u\u2212 u\u2217| for each methods. The two axises correspond x1 and x2, respectively. We can see that the point-wise error of the learned solution using our algorithm is less than 2e\u2212 2 on average. In contrast, the point-wise error of the learned solution using original PINN method with L2 loss is larger than 1.3e\u2212 1 for most areas. Therefore,\nthe visualization of the solutions clearly illustrate that PINN learned more accurate solution using our proposed algorithm.\nFurthermore, we visualize the gradient norm |\u2207xu| of the learned solution of both our method and the original PINN in Figure 2, to illustrate that not only can the learned solution of our method accurately approximate the exact solution, but also the gradient of the learned solution can accurately approximate the gradient of the exact solution. Again, since |\u2207xu| is a high dimensional function, we use a heatmap to show its function value given different x1 and x2, and set the other variables to 0. From the right panel of Figure 2, we can clearly see that the gradient of the learned solution of our method is much more accurate compared with that of the gradient of the learned solution using original PINN. The gradient norm error of the vanilla PINN approach is nearly 1e\u2212 2 in some areas shown in the visualization, while the error of our method is less than 1e \u2212 3 for most data points. This empirical observation aligns well with our theory, which states that Eq. (12) is (L\u221e, L\u221e,W 1,r) stable."
        },
        {
            "heading": "6.2 Ablation studies",
            "text": "We conduct ablation studies on the 100-dimensional LQG control problem (Eq. (12)) to ablate the main designs in our algorithm.\nAdversarial training v.s. Directly optimizing Lp physic-informed loss. Our proposed algorithm introduces a min-max optimization procedure. One may have concerns that such an approach may be unnecessarily complicated, and directly minimizing Lp physic-informed loss with a large p would have the same effect. We use these two methods to solve Eq. (12), and compare their performance in the left panel of Table 2. It can be seen that directly minimizing Lp physic-informed loss does not lead to satisfactory results.\nWe point out that this observation does not contradict our theoretical analysis (Theorem 4.3). Theorem 4.3 focuses on the approximation ability, which indicates that a model with a small Lp loss can approximate the exact solution well. The empirical results in Table 2 demonstrate the optimization difficulty of learning such a model with Lp loss. By comparison, our proposed adversarial training method is more stable and leads to better performance. More detailed discussions are provided in Appendix H.\nAdversarial training should be applied to both the PDE residual and the boundary residual. Our theoretical analysis suggests that we should use a large value of p and q in the loss `\u2126,p(u) and `\u2202\u2126,q(u) to guarantee the quality of the learned solution u. Thus, in the proposed Algorithm 1, both the data points inside the domain and the data points on the boundary are learned in the inner-loop maximization. From the right panel of Table 2, we can see that when adversarial training is applied to one loss term, the performance is slightly improved, but its accuracy is still not satisfactory. When both loss terms use adversarial training, the solution is one order of magnitude more accurate, indicating that applying adversarial training to the whole loss function is essential.\nHyper-parameters K and \u03b7 for the inner loop maximization. Our approach introduces additional hyper-parameters K (the number of inner-loop iterations) and \u03b7 (the inner-loop step size). These two parameters control the accuracy of inner-loop maximization. We conduct ablation studies to examine the effects of different design choices. Specifically, we experiment with K = 5, 10, 20 and \u03b7 = 0.05, 0.1, 0.2, and show the L1 relative error in the right panel of Table 2. Typically we find that setting the product K\u03b7 = 1 achieves the best performance. When K\u03b7 is fixed, our results suggest that using a larger K and a smaller \u03b7, i.e., more inner-loop iterations and smaller step sizes, will lead to better performance while being more time-consuming."
        },
        {
            "heading": "7 Conclusions",
            "text": "In this paper, we theoretically investigate the relationship between the loss function and the approximation quality of the learned solution using the concept of stability in the partial differential equation. We study an important class of high-dimensional non-linear PDEs in optimal control, the Hamilton-Jacobi-Bellman (HJB) equation, and prove that for general Lp Physics-Informed Loss, the HJB equation is stable only if p is sufficiently large. Such a theoretical finding reveals that the widely used L2 loss is not suitable for training PINN on high-dimensional HJB equations, while L\u221e loss is a better choice. The theory also inspires us to develop a novel PINN training algorithm to minimize the L\u221e loss for HJB equations in a similar spirit to adversarial training. One limitation of this work is that we only work on the HJB Equation. Theoretical investigation of other important equations can be an exciting direction for future works. We believe this work provides important insights into the loss design in Physics-Informed deep learning."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank Weinan E, Bin Dong, Yiping Lu, Zhifei Zhang, and Yufan Chen for the helpful discussions.\nThis work is supported by National Science Foundation of China (NSFC62276005), The Major Key Project of PCL (PCL2021A12), Exploratory Research Project of Zhejiang Lab (No. 2022RC0AN02), and Project 2020BD006 supported by PKUBaidu Fund."
        },
        {
            "heading": "A Notation and Auxiliary Results",
            "text": "This section gives an overview of the notations used in the paper and summarizes some basic results in partial differential equation and functional analysis.\nA.1 Basic notations\nFor n \u2208 N, we denote {1, 2, ...n} by [n] for simplicity in the paper. For two Banach spaces X,Y , L (X,Y ) refers to the set of continuous linear operator mapping from X to Y .\nFor a mapping f : X \u2192 Y , and u, v \u2208 X , df(u, v) denotes Gateaux differential of f at u in the direction of v, and f \u2032(u) denotes Fr\u00e9chet derivative of f at u.\nFor r > 0, and x0 \u2208 X , where X is a Banach space equipped with norm \u2016 \u00b7 \u2016X , Br(x0) refers to {x \u2208 X : \u2016x\u2212 x0\u2016X < r}. For a function f : X \u2192 R, where X is a measurable space. We denote by suppf the support set of f , i.e. the closure of {x \u2208 X : f(x) 6= 0}. For a measurable set \u2126 \u2282 Rn, define the parabolic region Qt = Qt(\u2126) as \u2126\u00d7 [0, t]. The parabolic boundary \u2202pQt is then defined as \u2126\u00d7 {0} \u222a \u2202\u2126\u00d7 [0, t]. For R > 0, the parabolic neighborhood of 0 (denoted by Q(R)) is defined as {(x, t) \u2208 Rn \u00d7 R\u22650 : |x| < R, t < R2}. Its parabolic boundary \u2202p(Q(R)) is defined as {(x, t) : |x| < R, t = 0 or |x| = R, t \u2208 [0, R2]}.\nA.2 Multi-index notations\nFor n \u2208 N, we call an n\u2212tuple of non-negative integers \u03b1 \u2208 Nn a multi-index. We use the notation |\u03b1| = \u03a3ni=1\u03b1i, \u03b1! = \u03a0ni=1\u03b1i!. For x = (x1, x2, ...xn) \u2208 Rn, we denote by x\u03b1 = \u03a0ni=1x \u03b1i i the corresponding multinomial. Given two multi-indices \u03b1, \u03b2 \u2208 Nd, we say \u03b1 \u2264 \u03b2 if and only if \u03b1i \u2264 \u03b2i, \u2200i \u2208 [n]. For an open set \u2126 \u2282 Rn, T \u2208 R+ and a function f(x) : \u2126 \u2192 R or f(x, t) : \u2126 \u00d7 [0, T ] \u2192 R, we denote by\nD\u03b1f = \u2202|\u03b1|f\n\u2202x\u03b111 ...\u2202x \u03b1n n\n(14)\nthe classical or weak derivative of f .\nFor k \u2208 Rn, we denote by Dkf (or\u2207kf ) the vector whose components are D\u03b1f for all |\u03b1| = k, and we abbreviate D1f as Df .\nA.3 Norm notations\nLet n \u2208 N\u2217, m \u2208 N, T \u2208 R+, and \u2126 \u2282 Rn, Q \u2282 Rn \u00d7 [0, T ] be open sets.We denote by Lp(\u2126) and Lp(Q) the usual Lebesgue space.\nThe Sobolev space Wm,p(\u2126) is defined as\n{f(x) \u2208 Lp(\u2126) : D\u03b1f \u2208 Lp(\u2126), \u2200\u03b1 \u2208 Nn with |\u03b1| \u2264 m}. (15)\nAnd we define Wm,p(Q) as\n{f(x) \u2208 Lp(Q) : D\u03b1f \u2208 Lp(Q), \u2200\u03b1 \u2208 Nn with |\u03b1| \u2264 m}. (16)\nWe define\n\u2016f\u2016Wm,p(\u2126) :=  \u2211 |\u03b1|\u2264m \u2016D\u03b1f\u2016pLp(\u2126)  1p (17)\nfor 1 \u2264 p <\u221e, and\n\u2016f\u2016Wm,\u221e(\u2126) := max |\u03b1|\u2264m \u2016D\u03b1f\u2016L\u221e(\u2126) (18)\nfor p =\u221e. We define \u2016f\u2016Wm,p(Q) for p \u2208 [1,\u221e] similarly.\nWe will use simplified notations \u2016f\u2016p and \u2016f\u2016m,p for Lp\u2212norm and Wm,p\u2212norm when the domain is whole space (Rn, Rn \u00d7 [0, T ] or Rn \u00d7 R\u22650) or when it is clear to the reader. Wm,p0 (\u2126) is defined as the completion of C \u221e 0 (\u2126) under \u2016 \u00b7 \u2016m,p norm. In the similar way we define Wm,p0 (Qt).\nA.4 Auxiliary results\nIn this section, we list out several fundamental yet important results in the field of PDE and functional analysis.\nTo begin with, we would like to recall three useful inequalities in real analysis.\nLemma A.1 (Young\u2019s convolution inequality). In Rn, we define the convolution of two functions f and g as (f \u2217 g)(x) := \u222b Rn f(y)g(x\u2212 y)dy. Suppose f \u2208 L p(Rn), g \u2208 Lq(Rn), and 1p + 1 q = 1 r + 1 with p, q, r \u2208 [1,\u221e], then\u2016f \u2217 g\u2016r \u2264 \u2016f\u2016p\u2016g\u2016q . Lemma A.2 (Sobolev embedding theorem). Let \u2126 be an open set in Rn, p \u2208 [1,\u221e], and m \u2264 k be a non-negative integer.\n(i) If 1p \u2212 k n > 0, and set q = np n\u2212pk , then W m,p \u2282Wm\u2212k,q and the embedding is continuous, i.e. there exists a constant c > 0 such that \u2016u\u2016m\u2212k,q \u2264 c\u2016u\u2016m,p, \u2200u \u2208Wm,p.\n(ii) If 1p \u2212 k n \u2264 0, then for any q \u2208 [1,\u221e), W m,p \u2282Wm\u2212k,q and the embedding is continuous.\nLemma A.3 (A special case of Gagliardo-Nirenberg inequality). \u2126 is an open set in Rn, Let q \u2208 [1,\u221e] and j, k \u2208 N, and suppose j 6= 0 and\n1 < r <\u221e k \u2212 j \u2212 nr /\u2208 N j k \u2264 \u03b8 < 1.\nIf we set\n1 p = j n + \u03b8\n( 1\nr \u2212 k n\n) +\n1\u2212 \u03b8 q , (19)\nthen there exists a constant C independent of u such that\n\u2016\u2207ju\u2016p \u2264 C\u2016\u2207ku\u2016\u03b8r\u2016u\u20161\u2212\u03b8q , \u2200u \u2208 Lq(\u2126) \u2229W k,r(\u2126). (20)\nNext, we list out several basic results in second order parabolic equations, which will be of great use in Appendix C.\nIn the following lemmas, we denote by L0 the operator \u2202\u2202t \u2212\u2206. Lemma A.4. Suppose \u2126 is bounded, and QT = \u2126\u00d7 [0, T ]. Let u \u2208W 2,2(QT ) be the solution to\n{ L0u = f(x, t), (x, t) \u2208 QT u = 0, (x, t) \u2208 \u2202pQT ,\n(21)\nthen for 2 \u2264 p < \u221e, if f \u2208 Lp(QT ), we have u \u2208 W 2,p(QT ) and there exists a constant C such that \u2016u\u20162,p \u2264 C\u2016f\u2016p.\nProof. Since \u2126 is bounded, we can choose an R0 > 1 such that QT \u2282 Q(R0). Set u\u0302(x, t) = u(x, t)1QT and f\u0302(x, t) = f(x, t)1QT , which are extensions of u and f in Rn \u00d7 R\u22650, respectively. The boundary condition in Eq. (21) implies that u\u0302 \u2208W 2,p(Rn \u00d7 R\u22650). Furthermore, for any R > R0, it holds that,{\nL0u\u0302 = f\u0302(x, t), (x, t) \u2208 Q(R) u\u0302 = 0, (x, t) \u2208 \u2202pQ(R).\nFrom proposition 7.18 in [19], and in light of the fact that both u\u0302 and f\u0302 are supported on QT , we obtain that \u2016D2u\u0302\u2016p \u2264 C(\u2016f\u0302\u2016p + 1R\u2016Du\u0302\u2016p + 1 R2 \u2016u\u0302\u2016p) holds for \u2200R > R0. Additionally, Poincar\u00e9 inequality guarantees that there exists a constant C \u2032 > 0 depending only on \u2126 and n, such that \u2016u\u0302\u20162,p \u2264 C \u2032\u2016D2u\u0302\u2016p. Therefore we have\n1\nC \u2032 \u2016u\u0302\u20162,p \u2264 C\n( \u2016f\u0302\u2016p + 1\nR \u2016u\u0302\u20162,p +\n1\nR2 \u2016u\u0302\u20162,p\n) \u2264 C ( \u2016f\u0302\u2016p + 2\nR \u2016u\u0302\u20162,p ) (22)(\n1 C \u2032 \u2212 2C R\n) \u2016u\u0302\u20162,p \u2264 C\u2016f\u0302\u2016p. (23)\nLet R \u2192 \u221e and we derive \u2016u\u0302\u20162,p \u2264 CC \u2032\u2016f\u0302\u2016p. Since \u2016u\u0302\u2016W 2,p(Rn\u00d7R\u22650) = \u2016u\u2016W 2,p(QT ) and \u2016f\u0302\u2016Lp(Rn\u00d7R\u22650) = \u2016f\u2016Lp(QT ), we completes the proof.\nLemma A.5. Let u be the solution to{ L0u(x, t) = 0, (x, t) \u2208 Rn \u00d7 [0, T ] u(x, 0) = g(x), x \u2208 Rn.\nFor any compact set Q \u2282 Rn \u00d7 [0, T ] and p \u2265 1, let r < (n+2)pn+p , then\n(i) there exists a constant C such that \u2016u\u2016W 1,r(Q) \u2264 C\u2016g\u2016Lp(Rn),\n(ii) there exists a constant C \u2032 such that \u2016u\u2016W 2,r(Q) \u2264 C \u2032\u2016g\u2016W 1,p(Rn).\nProof. u have the explicit form\nu(x, t) = \u222b Rn a t n 2 e\u2212b |x\u2212y|2 t g(y)dy, (24)\nwhere a = (4\u03c0)\u2212 n 2 and b = 14 .\nNote that u is the convolution between heat kernel K(x, t) := a t n 2 e\u2212b\n|x|2 t and g(x), with Lemma\nA.1, we derive\n\u2016u(\u00b7, t)\u2016r0 \u2264 \u2016g\u2016p0\u2016K(\u00b7, t)\u2016q0 (25)\nfor p0, q0, r0 \u2208 [1,\u221e] satisfying 1p0 + 1 q0 = 1r0 + 1.\nDue to the uniform convergence of (24), we have \u2202u\u2202xi = ( \u2202 \u2202xi K(x, t)) \u2217 g(x) for all i \u2208 [n]. Thus we have\n\u2016\u2202u(\u00b7, t) \u2202xi \u2016r\u2032 \u2264 \u2016g\u2016p\u2032\u2016 \u2202 \u2202xi K(x, t)\u2016q\u2032 . (26)\nfor p\u2032, q\u2032, r\u2032 \u2208 [1,\u221e] satisfying 1p\u2032 + 1 q\u2032 = 1 r\u2032 + 1.\nIt is enough to decide appropriate tuples of (p0, q0, r0), (p\u2032, q\u2032, r\u2032).\nFor q \u2265 1,\n\u2016K(\u00b7, t)\u2016qq = aq\nt nq 2 \u222b Rn e\u2212bq \u2016x\u20162 t dx = aq t nq\u2212n 2 \u222b Rn e\u2212bq\u2016y\u2016 2 dy (y = 1\u221a t x). (27)\nThus \u2016K(\u00b7, t)\u2016q = C t nq\u2212n 2q , where C is a constant.\nAs a result, for any p, q, r \u2208 [1,\u221e] satisfying 1p + 1 q = 1 r + 1,\n\u2016u\u2016rLr(Rn\u00d7[0,T ]) = \u222b T\n0\n\u2016u(\u00b7, t)\u2016rrdt \u2264 \u2016g\u2016rp \u222b T\n0\n\u2016K(\u00b7, t)\u2016rqdt = Cr\u2016g\u2016rp \u222b T\n0\ndt\nt nq\u2212n 2q r . (28)\nHere we have \u2016u\u2016r \u2264 C1\u2016g\u2016p for a constant C1 \u21d0\u21d2 the integral in the R.H.S. of Eq. (28) converges \u21d0\u21d2 nq\u2212n2q r < 1. Then we could decide appropriate tuple (p0, q0, r0) for (25): tuples that satisfy nn+2 1 p0 < 1r0 \u2264 1 p0\n. (The second inequality comes from the constraint q0 \u2208 [1,\u221e]. It could be removed when these Lp\u2212norms are calculated in a bounded domain). We handle (p\u2032, q\u2032, r\u2032) in (26) with exactly the same method and find that tuples which satisfy n n+2 1 p\u2032 + 1 n+2 < 1 r\u2032 \u2264 1 p\u2032 gives\n\u2225\u2225\u2225\u2225 \u2202u\u2202xi \u2225\u2225\u2225\u2225 r\u2032 \u2264 C2\u2016g\u2016p\u2032 , (29)\nwhere C2 is a constant.\nFinally, note that for any bounded set \u2126, and 1 \u2264 q < p, there is a constant C such that \u2016v\u2016Lq(\u2126) \u2264 C\u2016v\u2016Lp(\u2126) for all v \u2208 Lp(\u2126). Together with the inequalities (28) and (29), this means that for any compact set Q \u2282 Rn \u00d7 [0, T ], p \u2265 1, and r < (n+2)pn+p ,\n\u2016u\u2016W 1,r(Q) = (\u2016u\u2016rLr(Q) + n\u2211 i=1 \u2016 \u2202u \u2202xi \u2016rLr(Q)) 1 r (30)\n\u2264 (C3\u2016u\u2016rLr0 (Q) + C4 n\u2211 i=1 \u2016 \u2202u \u2202xi \u2016r Lr\u2032 (Q) ) 1 r (31)\n\u2264 (C3\u2016u\u2016rLr0 (Rn\u00d7[0,T ]) + C4 n\u2211 i=1 \u2016 \u2202u \u2202xi \u2016r Lr\u2032 (Rn\u00d7[0,T ])) 1 r (32)\n\u2264 (C5\u2016g\u2016rLp(Rn) + C6 n\u2211 i=1 \u2016g\u2016rLp(Rn)) 1 r (33)\n= C7\u2016g\u2016Lp(Rn), (34)\nwhere r0, r\u2032 \u2208 [p, (n+2)pn+p ) \u2229 [r,+\u221e) and all Ci are constants.\nThis gives the first statement.\nNext, we prove the second statement.\nNote that \u2202 2u\n\u2202xixj = ( \u2202\u2202xiK(x, t)) \u2217 \u2202g(x) \u2202xj , \u2200i, j \u2208 [n].\nWith the same argument for (29), we obtain that for any r\u2032\u2032, p\u2032\u2032 satisfying nn+2 1 p\u2032\u2032 + 1 n+2 < 1 r\u2032\u2032 \u2264 1 p\u2032\u2032 ,\n\u2225\u2225\u2225\u2225 \u22022u\u2202xixj \u2225\u2225\u2225\u2225 Lr\u2032\u2032 (Rn\u00d7[0,T ]) \u2264 C \u2225\u2225\u2225\u2225\u2202g(x)\u2202xj \u2225\u2225\u2225\u2225 Lp\u2032\u2032 (Rn) , \u2200i, j \u2208 [n], (35)\nwhere C is a constant.\nTherefore, for any compact set Q \u2282 Rn \u00d7 [0, T ], p \u2265 1, and r < (n+2)pn+p , \u2016u\u2016W 2,r(Q) (36)\n= \u2016u\u2016rLr(Q) + n\u2211 i=1 \u2225\u2225\u2225\u2225 \u2202u\u2202xi \u2225\u2225\u2225\u2225r Lr(Q) + n\u2211 i,j=1 \u2225\u2225\u2225\u2225 \u22022u\u2202xixj \u2225\u2225\u2225\u2225r Lr(Q)  1r (37) \u2264\nC1\u2016u\u2016rLr0 (Q) + C2 n\u2211 i=1 \u2225\u2225\u2225\u2225 \u2202u\u2202xi \u2225\u2225\u2225\u2225r Lr\u2032 (Q) + C3 n\u2211 i,j=1 \u2225\u2225\u2225\u2225 \u22022u\u2202xixj \u2225\u2225\u2225\u2225r Lr\u2032\u2032 (Q)  1r (38) \u2264\nC1\u2016u\u2016rLr0 (Rn\u00d7[0,T ]) + C2 n\u2211 i=1 \u2225\u2225\u2225\u2225 \u2202u\u2202xi \u2225\u2225\u2225\u2225r Lr\u2032 (Rn\u00d7[0,T ]) + C3 n\u2211 i,j=1 \u2225\u2225\u2225\u2225 \u22022u\u2202xixj \u2225\u2225\u2225\u2225r Lr\u2032\u2032 (Rn\u00d7[0,T ])  1r (39)\n\u2264 C4\u2016g\u2016rLp(Rn) + C5 n\u2211 i=1 \u2016g\u2016rLp(Rn) + C6 n\u2211 i,j=1 \u2225\u2225\u2225\u2225 \u2202g\u2202xj \u2225\u2225\u2225\u2225r Lp(Rn)  1r (40) \u2264C7\u2016g\u2016W 1,p(Rn), (41)\nwhere r0, r\u2032, r\u2032\u2032 \u2208 [p, (n+2)pn+p ) \u2229 [r,+\u221e) and all Ci are constants.\nThis completes the proof.\nAt last, we present it here a well-known result in functional analysis. Lemma A.6 (Inverse function theorem in Banach space). Let X,Y be two Banach spaces, V \u2282 X be an open set, and g \u2208 C1(V, Y ) be a mapping. Assume x0 \u2208 V, y0 = g(x0) and the inverse of the Fr\u00e9chet derivative (g\u2032(x0))\u22121 \u2208 L (Y,X). Then there exists r > 0 and s > 0 such that Br(y0) \u2282 g(V ), Bs(x0) \u2282 V and g : Bs(x0)\u2192 g(Bs(x0)) is a differmorphism."
        },
        {
            "heading": "B Derivation of a Class of Hamilton-Jacobi-Bellman (HJB) Equations",
            "text": "For the sake of completeness of the paper, we give the derivation of a class of Hamilton-JacobiBellman (HJB) Equations as below.\nTo start with, we derive the general form of HJB Equation in stochastic control problem.\nIn stochastic control, the state function {Xt}0\u2264t\u2264T is a stochastic process, where T is the time horizon of the control problem. The evolution of the state function is governed by the following stochastic differential equation:{\ndXs = m(s,Xs)ds+ \u03c3dWs s \u2208 [t, T ] Xt = x , (42)\nwhere m : [t, T ]\u00d7Rn \u2192 Rn is the control function and {Ws} is a standard n-dimensional Brownian motion.\nGiven a control function m = (m1(s, y),m2(s, y), ...mn(s, y)), s \u2208 [t, T ], y \u2208 Rn, its total cost is defined as Jx,t(m) = E \u222b T t r(Xs,m(s,Xs), s)ds + g(XT ), where r : Rn \u00d7 Rn \u00d7 [0, T ] \u2192 R measures the cost rate during the process and g : Rn \u2192 R measures the final cost at the terminal state. The expectation is taken over the randomness of the trajectories.\nWe are interested in finding a control function that minimizes the total cost for a given initial state. Formally speaking, we define the value function of the control problem (42) as u(x, t) = min m\u2208M Jx,t(m), whereM denotes the set of possible control functions that we take into consideration.\nIt is obvious that u satisfies u(x, T ) = g(x). In addition, according to dynamical programming principle, we have\nu(x, t) = min m\u2208M E( \u222b t+h t r(Xs,m(s,Xs), s)ds+ u(Xt+h, t+ h)), (43)\nWith Ito\u2019s formula, we derive\nu(Xt+h, t+ h) = u(x, t) + (\u2202tu+ 1\n2 \u03c32\u2206u)h+\u2207u \u00b7 (m(t, x)h+ \u03c3(Wt+h \u2212Wt)) + o(h) (44)\nAfter taking expectation and some calculation, we derive from (44),\n0 = (\u2202tu+ 1\n2 \u03c32\u2206u)h+ min m\u2208M E( \u222b t+h t r(Xs,m(s,Xs), s)ds+\u2207u \u00b7m(t, x)h) + o(h) (45)\n0 = \u2202tu(x, t) + 1\n2 \u03c32\u2206u(x, t) + min m\u2208M (r(x,m(t, x), t) +\u2207u \u00b7m(t, x)) (46)\nThen we get HJB equation{ \u2202tu(x, t) + 1 2\u03c3\n2\u2206u(x, t) + min m\u2208M (r(x,m(t, x), t) +\u2207u \u00b7m(t, x)) = 0\nu(x, T ) = g(x). (47)\nNext, we further simplify this equation in some special cases.\nIn practice, different components of the state have different meanings, and thus the effects of controlling corresponding components have different significance. Therefore, the cost function\u2019s dependence on each component of mt takes a very different form.\nBased on this argument, we consider the case when r(x, y) takes the form\nr(x, y, t) = n\u2211 i=1 ai|yi|\u03b1i \u2212 \u03d5(x, t) (48)\nfor some appropriate function \u03d5 and ai \u2265 0, \u03b1i > 1 (if \u03b1i \u2264 1, the minimizing term might be \u2212\u221e),\u2200i \u2208 [n].\nDenote m(t, x) = (m1(t, x),m2(t, x), ...mn(t, x)) as y \u2208 Rn, and \u2202u(x,t)\u2202xi as \u2202iu, and suppose that M is so large that it includes the global minimizor of (43), then the third term in HJB equation (47) could be written as\nmin y\u2208Rn (\u2212\u03d5(x, t) + n\u2211 i=1 (ai|yi|\u03b1i + yi\u2202iu)) = \u03d5(x, t) + n\u2211 i=1 min yi\u2208R (ai|yi|\u03b1i + yi\u2202iu). (49)\nWith some simple computation, we get\nmin yi\u2208R\n(ai|yi|\u03b1i + yi\u2202iu) =\n( ai\n(ai\u03b1i) \u03b1i \u03b1i\u22121 \u2212 1 (ai\u03b1i) 1 \u03b1i\u22121\n) |\u2202iu| \u03b1i \u03b1i\u22121 . (50)\nAs a result, HJB equation in this case is{ \u2202tu(x, t) + 1 2\u03c3 2\u2206u(x, t)\u2212 \u03d5(x, t)\u2212 \u2211n i=1Ai|\u2202iu|ci = 0\nu(x, T ) = g(x), (51)\nwhere Ai = (ai\u03b1i) \u2212 1\u03b1i\u22121 \u2212 ai(ai\u03b1i)\u2212 \u03b1i \u03b1i\u22121 \u2208 (0,+\u221e) and ci = \u03b1i\u03b1i\u22121 \u2208 (1,+\u221e). Remark B.1. After taking the transform v(x, t) := u(x, T \u2212 t), the equation above becomes{ \u2202tv(x, t)\u2212 12\u03c3 2\u2206v(x, t) + \u2211n i=1Ai|\u2202iv|ci = \u2212\u03d5(x, T \u2212 t)\nv(x, 0) = g(x). (52)\nWe will study this equation in the rest of the paper instead.\nRemark B.2. The minimizer of (49) is y\u2217i = ( |\u2202iu| ai\u03b1i ) 1\n\u03b1i\u22121 and this gives the i-th component of the optimal control m\u2217. Based on the fact that both the value function u and the optimal control m\u2217 are of interest in applications, it is necessary to study this equation in W 1,p space.\nMoreover, in most cases, only a bounded domain \u2126 \u2282 Rn is taken into consideration in both real applications and numerical experiments. Therefore, we study this equation in the space of W 1,p(\u2126\u00d7 [0, T ]) for a bounded domain \u2126, instead of W 1,p(Rn \u00d7 [0, T ]).\nRemark B.3. The form of cost function (48) we investigate in the paper is a generalization of the widely-used power-law cost (or utility) function, which is representative in optimal control. For example, in financial markets, we often face power-law trading cost in optimal execution problems [10, 30]. The cost function in Linear\u2013Quadratic\u2013Gaussian control and Merton\u2019s portfolio model (constant relative risk aversion utility function in [22]) is also of this form. Therefore, we believe our theoretical analysis for this class of HJB equation is relevant for practical applications."
        },
        {
            "heading": "C Proof of Theorem 4.3",
            "text": "In this section, we give the proof of an equivalent statement of Theorem 4.3.\nIn light of remark B.1, it is equivalent to consider the stability property (as is defined in Definition 4.1) for the following equation:{\n\u2202tu(x, t)\u2212 12\u03c3 2\u2206u(x, t) + \u2211n i=1Ai|\u2202iu|ci = h(x, t) (x, t) \u2208 Rn \u00d7 [0, T ] u(x, 0) = g(x), (53)\nwhere Ai > 0, ci \u2208 (1,\u221e), and h(x, t) corresponds to \u2212\u03d5(x, T \u2212 t) in Eq. (52). Without loss of generality, we assume \u03c3 = \u221a 2 for simplicity in the discussion below.\nWe define operators L0 := \u2202\u2202t \u2212\u2206, L\u0303HJBu := L0u+ \u2211n i=1Ai|\u2202iu|ci and B\u0303HJBu(x, t) := u(x, 0) for clarity. We define c\u0304 as max i\u2208[n] ci.\nWe start with the proof of some auxiliary results. Lemma C.1. For every c > 1, there exist k \u2208 N, {ti}ki=1 satisfying 1 \u2264 t1 < t2 < ... < tk < c, and k power functions f1, ...fk whose orders are strictly less than c and no smaller than 0, such that\n(b+ w)c \u2212 bc \u2212 wc \u2264 k\u2211 i=1 fi(b)w ti , \u2200b, w \u2265 0. (54)\nProof. Obviously, the inequality holds when c \u2208 N because of the binomial expansion. We will only consider the case when c /\u2208 N. Step 1.We prove that for any b, w \u2265 0 such that max{b, x} \u2265 1, Fb,w(c) := (b+ w)c \u2212 bc \u2212 wc is monotone increasing.\nWithout loss of generality, suppose b \u2265 w. Then\nF \u2032(c) = (b+ w)c ln(b+ w)\u2212 bc ln b\u2212 wc lnw (55) = (b+ \u03b7)c\u22121(1 + c ln(b+ \u03b7))w \u2212 wc lnw (56)\nholds for an \u03b7 \u2208 (0, w) (mean value theorem). Thus\nF \u2032(c) \u2265 wc(1 + c ln(b+ \u03b7))\u2212 wc lnw > wc(1 + ln(b+ \u03b7)\u2212 lnw) > wc > 0. (57)\nThe inequalities rely on the assumption b \u2265 1, which means ln(b+ \u03b7) > 0, and the first inequality comes from b \u2265 w. This completes the proof in this step.\nStep 2. We then construct k, {ti}ki=1, {fi}ki=1 stated in the lemma. Set n = dce. By virtue of the increasing property of F (c) when max{b, w} \u2265 1, we get\nFb,w(c) \u2264 Fb,w(n) = n\u22121\u2211 i=1 ( n i ) bn\u2212i \u00b7 wi. (58)\nWhen b, w satisfies max{b, w} < 1,\nFb,w(c) \u2264 (b+ w)c \u2212 bc = c(b+ \u03b7)c\u22121w < c2c\u22121w (59)\nholds for an \u03b7 \u2208 (0, w). The equality is an application of mean value theorem, and the second inequality comes from the fact that \u03b7 \u2208 (0, w).\nTo conclude, (b+ w)c \u2212 bc \u2212 wc \u2264 c2c\u22121w + \u2211n\u22121 i=1 ( n i ) bn\u2212i \u00b7 wi, \u2200b, w \u2265 0. Since c /\u2208 N, which means n\u2212 1 < c, this completes the proof.\nLemma C.2. Suppose u\u2217 is the exact solution to{ L\u0303HJBu = h (x, t) \u2208 Rn \u00d7 [0, T ] B\u0303HJBu = g .\nFix a bounded open set \u2126 \u2282 Rn. Suppose u1 satisfies B\u0303HJBu\u2217 = B\u0303HJBu1 and that supp(u1\u2212u\u2217) \u2282 QT (\u2126). Recall ci are parameters in the operator L\u0303HJB. Let p \u2208 [2,\u221e).\nIf p \u2265 n \u00b7max i\u2208[n] ci\u22121 ci = (1\u2212 c\u0304\u22121)n, then there exists \u03b40 > 0 such that, when \u2016L\u0303HJBu1 \u2212 h\u2016p < \u03b40, we have \u2016u\u2217 \u2212 u1\u20162,p \u2264 C\u2016L\u0303HJBu1 \u2212 h\u2016p for a constant C independent of u1.\nProof. Define w = wu1 := u1 \u2212 u\u2217, then supp(w) is compact and w(x, 0) = 0. We further define f = fu1 := L\u0303HJBu1 \u2212 h. Since u1 = u\u2217 in Rn \u00d7 [0, T ]\\QT (\u2126) and f = L\u0303HJBu1 \u2212 L\u0303HJBu\u2217, we have supp(f) \u2282 QT (\u2126). The Wm,p and Lp norm in the rest of the proof is defined on the domain QT (\u2126).\nCompute\nf = L\u0303HJBu1 \u2212 L\u0303HJBu\u2217 = L0w + n\u2211 i=1 Ai|\u2202i(u\u2217 + w)|ci \u2212Ai|\u2202iu\u2217|ci (60)\nThus, for any (x, t),\n|L0w(x, t)| = |f \u2212 n\u2211 i=1 (Ai|\u2202i(u\u2217 + w)|ci \u2212Ai|\u2202iu\u2217|ci)| \u2223\u2223\u2223\u2223 (x,t)\n(61)\n\u2264 |f(x, t)|+ n\u2211 i=1 Ai\u2016\u2202i(u\u2217 + w)|ci \u2212 |\u2202iu\u2217|ci | \u2223\u2223\u2223\u2223 (x,t)\n(62)\n\u2264 |f(x, t)|+ n\u2211 i=1 Ai((|\u2202iu\u2217|+ |\u2202iw|)ci \u2212 |\u2202iu\u2217|ci) \u2223\u2223\u2223\u2223 (x,t)\n(63)\nwhere the second inequality could be derived from the fact that (a+ b)c \u2212 ac \u2265 ac \u2212 (a\u2212 b)c for a \u2265 b \u2265 0 and c \u2265 1. For i \u2208 [n], apply Lemma C.1 for c = ci and we obtain ki and {tij}kij=1, {fij} ki j=1 satisfying corresponding properties.\nWe have\n|L0w(x, t)| \u2264 |f(x, t)|+ n\u2211 i=1 Ai(|\u2202iw|ci + ki\u2211 j=1 fij(|\u2202iu\u2217|)|\u2202iw|tij ) \u2223\u2223\u2223\u2223 (x,t) . (64)\nWith Lemma A.4 and triangle inequality, we obtain\n\u2016w\u20162,p \u2264 C\u2016L0w\u2016p \u2264 C(\u2016f\u2016p + n\u2211 i=1 Ai(\u2016|\u2202iw|ci\u2016p + ki\u2211 j=1 \u2016fij(|\u2202iu\u2217|)|\u2202iw|tij\u2016p)). (65)\nWe will handle each term respectively.\nUsing Lemma A.2, we have\n\u2016|\u2202iw|ci\u2016p = \u2016\u2202iw\u2016cicip \u2264 \u2016w\u2016 ci 1,cip \u2264 C\u0302i\u2016w\u2016ci2, ncipn+cip . (66)\nfor constants C\u0302i.\nUsing Lemma A.2 and H\u00f6lder inequality, we have\n\u2016|fij(|\u2202iu\u2217|)|\u2202iw|tij\u2016p \u2264 \u2016fij(|\u2202iu\u2217|)\u2016\u221e\u2016|\u2202iw|tij\u2016p (67) = \u2016fij(|\u2202iu\u2217|)\u2016\u221e\u2016\u2202iw\u2016 tij tijp \u2264 C\u0303ij\u2016w\u2016 tij\n2, ntijp\nn+tijp\n. (68)\nfor constants C\u0303ij (Since QT (\u2126) is compact, we can tell that \u2016fij(|\u2202iu\u2217|)\u2016\u221e <\u221e and thus C\u0303ij are well-defined).\nWhen p \u2265 n \u00b7max i\u2208[n] ci\u22121 ci , because of tij < ci, we have ncipn+cip \u2264 p, ntijp n+tijp \u2264 p for all i, j.\nNote that \u2126 is bounded, so for 1 \u2264 q < p,there is a constant C such that \u2016v\u2016Lq(\u2126) \u2264 \u2016v\u2016Lp(\u2126) for all v \u2208 Lp(\u2126). As a consequence, we can derive from Eq. (65,66,68) that M := \u2016w\u20162,p satisfies the inequality\nK0M \u2212 n\u2211 i=1 (KiM ci + \u2211 1\u2264j\u2264ki,tij>1 KijM tij ) \u2264 \u2016f\u2016p, (69)\nwhere all Ki and Kij are positive constants depending only on p, n, u\u2217 and \u2126.\nFor clarity, We define the L.H.S. of (69) as a function F with variable M .\nWith the observations (i)F (0) = 0, (ii) F \u2032(0) > 0, (iii)F \u2032\u2032(M) < 0, (iv)F (+\u221e) = \u2212\u221e, we could tell that F (M) has a unique zero m0 in R+. We could further tell that for any non-negative number C \u2264 max\nM\u2208[0,m0] F (M), solving F (M) \u2264 C (M \u2265 0) derives M \u2208 [0, a]\u2229 [b,\u221e] for some 0 < a < b\ndepending on C and that a\u2192 0, b\u2192 m0 monotonously as C decreases to 0. Note that there exists \u03b4 > 0 such that a \u2264 2K0C for \u2200C \u2208 [0, \u03b4]. In order to prove \u2016w\u20162,p = O(\u2016f\u2016p), it suffices to show that \u2016w\u20162,p (i.e. M in the discussion above) would not fall in the second interval providing C (or \u2016f\u2016p, correspondingly) is sufficiently small. We will prove by contradiction.\nNote that L\u0303HJB is a continuous injection from W 2,p0 (QT (\u2126)) to Lp(QT (\u2126)), and that there exists r\u22170 > 0 such that L\u0303HJB is a differmorphism from Br0(u\u2217) (in W 2,p 0 (QT (\u2126))) to L\u0303HJB(Br0(u\u2217)) \u2283 Br1(h) (in L p(QT (\u2126))) for any r0 \u2208 (0, r\u22170) and any r1 \u2208 (0, r\u22171) with r\u22171 depending on r0 (this comes from an application of Lemma A.6).\nSelect r0 < m02 and determine the corresponding r \u2217 1 . By the property of b, there exists \u03b40 \u2208 (0,min{ r \u2217 1\n2 , \u03b4}) such that for any C < \u03b40, the corresponding b is larger than 3 4m0. If there exists\nw \u2208Wm,p0 (QT (\u2126)) satisfying \u2016f\u2016p = \u2016L\u0303HJB(u\u2217 +w)\u2212 L\u0303HJBu\u2217\u2016p := C < \u03b40 while \u2016w\u20162,p > b (b depends on C), then there will also be a w\u2032 \u2208 Br0(0) such that L\u0303HJB(u\u2217 + w\u2032)\u2212 L\u0303HJBu\u2217 = f . We could tell from the difference between their norm that w 6= w\u2032. This contradicts the property of injection.\nThe proof is completed.\nLemma C.3. Suppose u\u2217 follows Lemma C.2, and \u2126 is a fixed bounded open set in Rn. Suppose u1 satisfies L\u0303HJBu\u2217 = L\u0303HJBu1 and that supp(u1 \u2212 u\u2217) \u2282 QT (\u2126). Let q \u2208 [1,\u221e).\nIf c\u0304 \u2264 2 and q > (c\u0304\u22121)n 2 (2\u2212c\u0304)n+2 , there exists \u03b40 > 0 such that when \u2016B\u0303HJBu1\u2212 B\u0303HJBu \u2217\u2016q < \u03b40, we have \u2016u\u2217 \u2212 u1\u20161,r \u2264 C\u2016B\u0303HJBu1 \u2212 B\u0303HJBu\u2217\u2016q for a constant C independent of u1, where r < (n+2)qn+q .\nProof. Define w = wu1 := u1 \u2212 u\u2217 and f = fu1 := B\u0303HJBu1 \u2212 B\u0303HJBu\u2217. Let w1 be the solution to{ L0u = 0, (x, t) \u2208 Rn \u00d7 [0, T ] B\u0303HJBu = f.\nThe Wm,p and Lp norm in the rest of the proof is defined on the domain QT (\u2126).\nSince the conditions c\u0304 \u2264 2 and q > (c\u0304\u22121)n 2 (2\u2212c\u0304)n+2 hold, we have [(c\u0304\u2212 1)n, (n+2)q n+q ) 6= \u2205. Thus we could choose r\u2032 \u2208 [(c\u0304\u2212 1)n, (n+2)qn+q ) \u2229 [r,\u221e). Since QT (\u2126) is bounded, it suffices to bound \u2016u1 \u2212 u \u2217\u2016r\u2032 .\nTo start with, from Lemma A.5, we have \u2016w1\u20161,r\u2032 \u2264 C\u2016f\u2016q . Then we bound the difference between w1 and w. Define v = w1 \u2212 w, then v satisfies{\nL0v = \u2211n i=1Ai|\u2202i(u\u2217 + w)|ci \u2212Ai|\u2202iu\u2217|ci B\u0303HJBv = 0.\nBy Lemma A.2 and Lemma A.4 , we get \u2016v\u20161,r\u2032 \u2264 C\u2016v\u20162, nr\u2032 n+r\u2032 \u2264 C \u2032\u2016L0v\u2016 nr\u2032 n+r\u2032 .\nTherefore we have \u2016w\u20161,r\u2032 \u2264 \u2016w1\u20161,r\u2032 + \u2016v\u20161,r\u2032 \u2264 C\u2016f\u2016q + C \u2032\u2016L0v\u2016 nr\u2032 n+r\u2032 .\nNext, we give an estimation for \u2016L0v\u2016 nr\u2032 n+r\u2032 .\nFollowing from the proof in Lemma C.2, we obtain {ki}ni=1 \u2282 N, {tij}1\u2264i\u2264n,1\u2264j\u2264ki \u2282 R, and power functions {fij}1\u2264i\u2264n,1\u2264j\u2264ki . With similar computations, we have\n\u2016L0v\u2016 nr\u2032 n+r\u2032 \u2264 n\u2211 i=1 Ai(\u2016|\u2202iw|ci\u2016 nr\u2032 n+r\u2032 + ki\u2211 j=1 \u2016fij(|\u2202iu\u2217|)|\u2202iw|tij\u2016 nr\u2032 n+r\u2032 ) (70)\n\u2264 n\u2211 i=1 Ai(\u2016\u2202iw\u2016cicinr\u2032 n+r\u2032 + ki\u2211 j=1 \u2016fij(|\u2202iu\u2217|)\u2016\u221e\u2016\u2202iw\u2016 tij ntijr \u2032 n+r\u2032 ). (71)\nBecause of r\u2032 \u2265 (c\u0304\u2212 1)n and tij < ci, we have ncir \u2032 n+r\u2032 \u2264 r \u2032, ntijr \u2032 n+r\u2032 \u2264 r \u2032 for all i, j.\nThus, due to the fact that QT (\u2126) is bounded, all \u2016\u2202iw\u2016 cinr\u2032 n+r\u2032 and \u2016\u2202iw\u2016ntijr\u2032 n+r\u2032 could be bounded by Ci,j\u2016w\u20161,r\u2032 , where Ci,j are constants. With similar methods applied in Lemma C.2, we could prove this lemma.\nLemma C.4. We denote by u\u2217 the exact solution to{ L\u0303HJBu(x, t) = h(x, t) (x, t) \u2208 Rn \u00d7 [0, T ], B\u0303HJBu(x, t) = g(x) x \u2208 Rn.\nFix \u2126, which is an arbitrary bounded open set in Rn. For two functions f\u03021(x, t), f\u03022(x), denote by u1 the solution to {\nL\u0303HJBu(x, t) = h(x, t) + f\u03021(x, t), in Rn \u00d7 [0, T ] B\u0303HJBu(x, t) = g(x) + f\u03022(x), in Rn.\nFor p, q \u2265 1, let r0 = (n+2)qn+q . Assume the following inequalities hold for p, q and r0:\np \u2265 max { 2, ( 1\u2212 1\nc\u0304\n) n } ; q > (c\u0304\u2212 1)n2\n(2\u2212 c\u0304)n+ 2 ;\n1 r0 \u2265 1 p \u2212 1 n , (72)\nFurther assume that c\u0304 \u2264 2 and supp(u1 \u2212 u\u2217) \u2282 QT (\u2126).\nThen for \u2200r \u2208 [1, r0), there exists \u03b40 > 0 such that, when \u2016f\u03021\u2016p < \u03b40 and \u2016f\u03022\u2016q < \u03b40, \u2016u1 \u2212 u\u2217\u20161,r \u2264 C(\u2016f\u03021\u2016p + \u2016f\u03022\u2016q) for a constant C independent of u1.\nProof. It is straight-forward to define u2 as the solution to{ L\u0303HJBu(x, t) = h(x, t) + f\u03021(x, t) (x, t) \u2208 Rn \u00d7 [0, T ] B\u0303HJBu(x, t) = g(x) x \u2208 Rn\nand bound \u2016u\u2217 \u2212 u2\u20161,r, \u2016u2 \u2212 u1\u20161,r respectively.\nFrom Lemma C.2, there exists \u03b41 > 0, C1 > 0 such that \u2016f\u03021\u2016p < \u03b41 implies \u2016u\u2217 \u2212 u2\u20162,p \u2264 C1\u2016f\u03021\u2016p. And from Lemma C.3, there exists \u03b42 > 0, C2 > 0 such that \u2016f\u03022\u2016q < \u03b42 implies \u2016u2\u2212 u1\u20161,r \u2264 C2\u2016f\u03022\u2016q. By virtue of the condition 1r > 1 r0 \u2265 1p \u2212 1 n , with Lemma A.2 and the fact that we are considering \u2016u\u2217 \u2212 u2\u20161,r, \u2016u2 \u2212 u1\u20161,r on a compact domain, providing \u2016f\u03021\u2016 < \u03b41 and \u2016f\u03022\u2016 < \u03b42, we derive\n\u2016u\u2217 \u2212 u1\u20161,r \u2264 \u2016u\u2217 \u2212 u2\u20161,r + \u2016u2 \u2212 u1\u20161,r (73) \u2264 C\u2016u\u2217 \u2212 u2\u20162,p + \u2016u2 \u2212 u1\u20161,r (74) \u2264 CC1\u2016f\u03021\u2016p + C2\u2016f\u03022\u2016q, (75)\nwhere C is a constant.\nThis concludes the proof.\nFinally, we give the proof of an equivalent statement of Theorem 4.3.\nTheorem C.5. Let f\u03021, f\u03022, u\u2217 and u1 follow from Lemma C.4. Let p, q, r0 satisfy the conditions in Lemma C.4. Assume c\u0304 \u2264 2. For any bounded open set Q \u2282 Rn \u00d7 [0, T ], it holds that for any r \u2208 [1, r0), there exists \u03b4 > 0 and a constant C independent of u1, f\u03021 and f\u03022, such that max{\u2016f\u03021\u2016Lp(Rn\u00d7[0,T ]), \u2016f\u03022\u2016Lq(Rn)} < \u03b4 implies \u2016u1 \u2212 u\u2217\u2016W 1,r(Q) \u2264 C(\u2016f\u03021\u2016Lp(Rn\u00d7[0,T ]) + \u2016f\u03022\u2016Lq(Rn)).\nProof. Since Q is bounded, there exists R > 0 such that Q \u2282 Q(R). Let u\u03021 be the constraint of u1 in Q(R). Construct an extension v of u\u03021 to Rn \u00d7 R\u22650 such that\n(i) v = u\u2217 in (Rn \u00d7 R\u22650)\\Q(2R),\n(ii) \u2016f\u03031\u2016p \u2264 C \u2032\u2016f\u03021\u2016Lp(Q) and \u2016f\u03032\u2016\u2264C \u2032\u2016f\u03022\u2016Lq(BR(0)) for a constant C \u2032 depending only on n,R, p, q,Q, where f\u03031 := L\u0303HJBv \u2212 f\u03021, f\u03032 := B\u0303HJBv \u2212 f\u03022.\nNote that supp(f\u03031) \u2282 Q(2R) and supp(f\u03032) \u2282 B2R(0), the existence of v is obvious.\nFrom Lemma C.4, there exists C > 0 and \u03b4 > 0 such that \u2016f\u03031\u2016p < \u03b4 and \u2016f\u03032\u2016q < \u03b4 imply \u2016v \u2212 u\u2217\u20161,r \u2264 C(\u2016f\u03031\u2016p + \u2016f\u03032\u2016q). Thus\n\u2016u1 \u2212 u\u2217\u2016W 1,r(Q) = \u2016v \u2212 u\u2217\u2016W 1,r(Q) \u2264 \u2016v \u2212 u\u2217\u20161,r \u2264 C(\u2016f\u03031\u2016p + \u2016f\u03032\u2016q) (76)\n\u2264 CC \u2032(\u2016f\u03021\u2016Lp(Q) + \u2016f\u03022\u2016Lq(BR(0))) \u2264 CC \u2032(\u2016f\u03021\u2016p + \u2016f\u03022\u2016q). (77)\nThe proof is completed."
        },
        {
            "heading": "D Proof of Theorem 4.4",
            "text": "In this section, we give the proof of Theorem 4.4.\nBased on remark B.1, it is equivalent to consider Eq. (53). We will show that the following equation satisfies the properties stated in Theorem 4.4,{\n\u2202tu\u2212\u2206u+ |Du|2 = 0 in Rn \u00d7 [0, T ] u(x, 0) = g(x).\n(78)\nThis equation is a special case for Eq. (53) with Ai = 1, ci = 2, \u2200i \u2208 [n] and h(x, t) \u2261 0.\nDenote by u\u2217 the exact solution to the equation above. The notationsL0, L\u0303HJB, B\u0303HJB in the following discussion have the same meaning as in section C.\nWe prove some auxiliary results first.\nLemma D.1. For p \u2208 [2, 2n), and an open set or a parabolic region A, we denote the function space W 2,p(A) as X and L np 2n\u2212p (A) as Y . For any u \u2208 X , we have \u2016u \u2212 u\u2032\u2016X \u2265\nA \u221a \u2016L\u0303HJBu\u2212 L\u0303HJBu\u2032\u2016Y +B \u2212 C holds for \u2200u\u2032 \u2208 X , where A,B,C are positive constants\ndepending on u.\nProof. We divide the proof into two steps.\nStep 1. We check that L\u0303HJB as an operator mapping from X to Y is Fr\u00e9chet-differentiable.\nFor any u, v \u2208 X, t \u2208 R, since v \u2208 X , which means |Dv|2 \u2208W 1, p 2 \u2282 Y , we have\n\u2016L\u0303HJB(u+ tv)\u2212 L\u0303HJBu\u2212 t \u00b7 (L0v + 2Du \u00b7Dv)\u2016Y = \u2016t2|Dv|2\u2016Y = o(t) (t\u2192 0). (79)\nTherefore, dL\u0303HJB(u, v) = L0v + 2Du \u00b7Dv by definition. Define operator A(u) \u2208 L (X,Y ) as A(u)v = dL(u, v). For u, u\u2032 \u2208 X and any v \u2208 X , note that\n\u2016A(u\u2032)v \u2212A(u)v\u2016Y = 2\u2016D(u\u2032 \u2212 u) \u00b7Dv\u2016Y \u2264 C0\u2016D(u\u2032 \u2212 u) \u00b7Dv\u20161, p2 (80) \u2264 C0\u2016D(u\u2032 \u2212 u)\u20161,p\u2016Dv\u20161,p \u2264 C0\u2016u\u2032 \u2212 u\u2016X\u2016v\u2016X (81)\nfor a constant C0, where the second inequality comes from Cauchy-Schwarz inequality. Thus we have \u2016A(u) \u2212 A(u\u2032)\u2016L (X,Y ) \u2264 C0\u2016u \u2212 u\u2032\u2016X , which means A is continuous with regard to u. As a result, L\u0303HJB is Fr\u00e9chet-differentiable and L\u0303\u2032HJB(u) = A(u). Moreover, we derive \u2016L\u2032(u)\u2016 \u2264 \u2016L\u2032(0)\u2016+ \u2016L\u2032(0)\u2212 L\u2032(u)\u2016 \u2264 C0\u2016u\u2016X + C1.\nStep 2. For any u, u\u2032 \u2208 X , let y = L\u0303HJBu, y\u2032 = L\u0303HJBu\u2032.\nDefine u\u03b7 = (1\u2212 \u03b7)u+ \u03b7u\u2032 and y\u03b7 = L\u0303HJBu\u03b7 for \u03b7 \u2208 [0, 1]. Fix a number m \u2208 N.\nFrom the property proved in step 1, for any \u03b7 \u2208 [0, 1], there exists r\u03b7 \u2208 (0, 1m ) such that\n\u2016L\u0303HJBv \u2212 L\u0303HJBu\u03b7\u2016 \u2264 2\u2016L\u2032(u\u03b7)\u2016 \u00b7 \u2016u\u03b7 \u2212 v\u2016 \u2264 2(C0\u2016u\u03b7\u2016+ C1)\u2016v \u2212 u\u03b7\u2016, \u2200v \u2208 Br\u03b7 (u\u03b7). (82)\nNote that {B r\u03b7 2 (u\u03b7) : \u03b7 \u2208 [0, 1]} is an open cover of {u\u03b7 : \u03b7 \u2208 [0, 1]}. Because of the compactness of {u\u03b7 : \u03b7 \u2208 [0, 1]}, we obtain an increasing finite sequence {\u03b7i}Ni=0 with \u03b70 = 0, \u03b7N = 1 such that either u\u03b7i \u2208 Br\u03b7i\u22121 (u\u03b7i\u22121) or u\u03b7i\u22121 \u2208 Br\u03b7i (u\u03b7i) for \u2200i \u2208 [N ]. This means that\n\u2016y\u03b7i \u2212 y\u03b7i\u22121\u2016 \u2264 2(C0\u2016u\u03b7j\u2016+ C1)\u2016u\u03b7i \u2212 u\u03b7i\u22121\u2016, j \u2208 {i\u2212 1, i} (83)\nholds for \u2200i \u2208 [N ]. Therefore\n\u2016y\u2032 \u2212 y\u2016 \u2264 N\u2211 i=1 \u2016y\u03b7i \u2212 y\u03b7i\u22121\u2016 \u2264 N\u2211 i=1 2(C0\u2016u\u03b7j\u2016+ C1)\u2016u\u03b7i \u2212 u\u03b7i\u22121\u2016 (84)\nNote that this inequality holds for every m. As m\u2192\u221e, R.H.S. of (84) converges to \u2016u\u2212 u\u2032\u2016 \u222b 1\n0\n2(C0\u2016u+ s(u\u2032 \u2212 u)\u2016+ C1)ds. (85)\n=\u2016u\u2212 u\u2032\u2016(C0\u2016u+ \u03b8(u\u2032 \u2212 u)\u2016+ C1), (\u03b8 \u2208 (0, 1)) (86) \u2264\u2016u\u2212 u\u2032\u2016(C0(\u2016u\u2016+ \u2016u\u2032 \u2212 u\u2016) + C1). (87)\nThe equality comes from mean value theorem for integral, and the inequality comes from triangular inequality.\nCombining Eq. (84) and (87) together completes the proof.\nLemma D.2. Let u1 satisfies B\u0303HJBu\u2217 = B\u0303HJBu1 and that supp(u1 \u2212 u\u2217) is compact in Rn \u00d7 R+. Define f(x, t) := L\u0303HJBu1. Let p \u2208 [2,\u221e),m \u2208 N. If p \u2265 n2 then there exists \u03b40 > 0 such that \u2016f\u2016m,p < \u03b40 implies \u2016u\u2217 \u2212 u1\u2016m+2,p = O(\u2016f\u2016m,p).\nProof. When m = 0, this statement is a direct consequence of Lemma C.2.\nWhen m > 0, for every multi-index \u03b1 with |\u03b1| \u2264 m, operate D\u03b1 on both sides of L\u0303HJBu1 = f and L\u0303HJBu\u2217 = 0. We then obtain\nL0D\u03b1u1 +D\u03b1|Du1|2 = D\u03b1f (88) L0D\u03b1u\u2217 +D\u03b1|Du\u2217|2 = 0. (89)\nDefine w := u1 \u2212 u\u2217, and compute the difference between (88) and (89), we get\nL0D\u03b1w = D\u03b1f \u2212 n\u2211 i=1 (2D\u03b1(\u2202iu \u2217\u2202iw) +D \u03b1(\u2202iw) 2). (90)\nWith similar methods used in Lemma C.2, we could bound \u2016D\u03b1w\u20162,p with \u2016D\u03b1f\u2016p, based on which we complete the proof.\nFinally, we show that Eq. (78) satisfies the properties stated in Theorem 4.4, which will conclude the proof for Theorem 4.4. Theorem D.3. For any \u03b5 > 0, A > 0, r \u2265 1,m \u2208 N and p \u2208 [ 1, n4 ] , there exists a function u \u2208 C\u221e(Rn \u00d7 (0, T ]) which satisfies the following conditions:\n\u2022 \u2016L\u0303HJBu\u2016Lp(Rn\u00d7[0,T ]) < \u03b5, B\u0303HJBu = B\u0303HJBu\u2217, and supp(u\u2212 u\u2217) is compact.\n\u2022 \u2016u\u2212 u\u2217\u2016Wm,r(Rn\u00d7[0,T ]) > A.\nProof. Since L1(\u2126) has the weakest topology in function spaces Wm,r(\u2126) when \u2126 is bounded, it is enough to consider the case for r = 1, m = 0.\nSet p0 = 59n, p1 = 11 9 n and p2 = 11 7 n.\nStep 1. We construct two families of functions {va,c}, {Fa,c} as the basis of proof.\nFor any a, c > 0, define fa,c(x) = c|x|\u22120.7, x \u2208 B1(0)\\Ba(0) in Rn. We could extend it to a C\u221e function f\u0303a,c(x) defined on Rn such that (i)\u2016f\u0303a,c\u2016\u221e < \u2016fa,c\u2016\u221e + min{1, c} and (ii)supp(f\u0303a,c) \u2282 B1.1(0).\nWe could further construct a C\u221e function f\u0302a,c(x, t) such that\n(i) supp(f\u0302a,c) \u2282 B1.1(0)\u00d7 (0, T ],\n(ii) f\u0302a,c(x, t) = f\u0303a,c(x),\u2200t \u2208 [T2 , T ],\n(iii) \u2016f\u0302a,c(x, t)\u2016L\u221e(Rn)\u00d7[0,T ] \u2264 \u2016f\u0303a,c\u2016L\u221e(Rn).\nDefine ua,c as the solution to { L\u0303HJBu = f\u0302a,c in Rn \u00d7 [0, T ] B\u0303HJBu = g.\nSelect a function wa,c \u2208 C\u221e(Rn \u00d7 R) with compact support supp(wa,c) \u2282 Rn \u00d7 (0, T ], such that \u2016ua,c \u2212 u\u2217 \u2212 wa,c\u2016 < c in W 3,4p0(Rn \u00d7 [0, T ]),W 2,4p1(Rn \u00d7 [0, T ]) and W 2,4p(Rn \u00d7 [0, T ]), where c is an small value depending on c and is to be decided later.\nWe define va,c = u\u2217 + wa,c and Fa,c = L\u0303HJBva,c.\nStep 2. We show that{va,c} and {Fa,c} have following properties:\n(i) supp(va,c \u2212 u\u2217) is compact in Rn \u00d7 (0, T ].\n(ii) B\u0303HJBva,c = B\u0303HJBu\u2217.\n(iii) supp(Fa,c) is compact in Rn \u00d7 (0, T ].\n(iv) There exists a constant M <\u221e such that \u2016Fa,c\u2016q < cM and \u2016Fa,c\u20161,p0 < cM .\n(v) For any c > 0, \u2016Fa,c\u2016p2 \u2192\u221e as a\u2192 0.\n(i) and (ii) comes directly from the construction of va,c.\nBecause supp(va,c\u2212u\u2217) is close, for any (x, t) \u2208 (Rn\u00d7 [0, T ])\\supp(va,c\u2212u\u2217), there exists r > 0 such that (Br(x, t) \u2229 (Rn \u00d7 [0, T ])) \u2282 (Rn \u00d7 [0, T ])\\supp(va,c \u2212 u\u2217) , which means va,c = u\u2217 in Br(x, t) \u2229 (Rn \u00d7 [0, T ]) and thus L\u0303HJBva,c = L\u0303HJBu\u2217 = 0. This gives (iii).\nDue to the fact that the function |x|\u22120.7 \u2208 Lp(B2(0)) \u2229 W 1,p0(B2(0)), there exists a constant M <\u221e such that \u2016f\u0302a,1\u2016p < M \u2212 1 and \u2016f\u0302a,1\u20161,p0 < M \u2212 1 holds for any a and any construction of f\u0302a,1 based on fa,1. Due to the linearity of norms, we derive \u2016f\u0302a,c\u2016p < c(M \u2212 1) and \u2016f\u0302a,c\u20161,p0 < c(M \u2212 1).\nIt is easy to check that L\u0303HJB is a continuous mapping fromW 3,4p0(\u2126) toW 1,p0(\u2126), fromW 2,4p1(\u2126) to Lp2(\u2126) and from W 2,4p(\u2126) to Lp(\u2126) for any compact set \u2126 \u2282 Rn \u00d7 [0, T ]. Therefore, \u2016Fa,c \u2212 f\u0302a,c\u2016 is small in W 1,p0(Rn \u00d7 [0, T ]), Lp2(Rn \u00d7 [0, T ]), and Lp(Rn \u00d7 [0, T ]).\nSince \u2016|x|\u22120.7\u2016Lp2 (B1(0)) = +\u221e, by the construction of f\u0302a,c we have \u2016f\u0302a,c\u2016p2 \u2192 +\u221e as a\u2192 0.\nAs a result of the continuity of L\u0303HJB, we could guarantee \u2016Fa,c\u2016p < cM , \u2016Fa,c\u20161,p0 < cM and \u2016Fa,c\u2016p2 > 12\u2016f\u0302a,c\u2016p2 by choosing c sufficiently small previously. This gives (iv) and (v).\nStep 3. We give an estimation for \u2016va,c \u2212 u\u2217\u20161, i.e., \u2016wa,c\u20161). We mention at the beginning of this part that all Ci appeared below are positive constants.\nFor any > 0, set c to 12M min{ , \u03b40}, where \u03b40 follows from an application of Lemma D.2 for the case p = p0. Then for any a > 0, \u2016Fa,c\u2016p < and we obtain \u2016wa,c\u20163,p0 \u2264 C0\u2016Fa,c\u20161,p0 .\nIn Lemma A.3, we choose j = 2, k = 3, \u03b8 = n+ 13 11\nn+ 65 , r = p0, q = 1, p =\n11 9 n and derive\n\u2016\u22072wa,c\u2016p1 \u2264 C1\u2016\u22073wa,c\u2016\u03b8p0\u2016wa,c\u2016 1\u2212\u03b8 1 . Since \u2016\u22073wa,c\u2016p0 \u2264 \u2016wa,c\u20163,p0 , we get\n\u2016wa,c\u20161 \u2265 ( \u2016\u22072wa,c\u2016p1 C1\u2016wa,c\u2016\u03b83,p0 ) 1 1\u2212\u03b8 \u2265 C2 ( \u2016\u22072wa,c\u2016p1 \u2016Fa,c\u2016\u03b81,p0 ) 1 1\u2212\u03b8 \u2265 C2 (C3M) 1\u2212\u03b8 \u03b8 \u2016\u22072wa,c\u2016 1 1\u2212\u03b8 p1 , (91)\nwhere the last inequality comes from property (iv) in Step 2.\nBy virtue of property (i) in Step 2, we have \u2016\u22072wa,c\u2016p1 \u2265 C4\u2016wa,c\u20162,p1 , which is an application of Poincar\u00e9 inequality. Together with Lemma D.1,\n\u2016wa,c\u20161 \u2265 C2\n(C3M) 1\u2212\u03b8 \u03b8\n\u2016\u22072wa,c\u2016 1 1\u2212\u03b8 p1 \u2265 C5\u2016wa,c\u2016 1 1\u2212\u03b8 2,p1 \u2265 C5 ( C6 \u221a \u2016Fa,c\u2016p2 \u2212 C7 ) 1 1\u2212\u03b8 . (92)\nSince R.H.S. above goes to +\u221e as a \u2192 0 due to property (v), for any A > 0, there exists a0 > 0 such that \u2016wa0,c\u20161 > A. Setting u = va0,c = u \u2217 + wa0,c completes the proof.\nE Improved Theorem 4.3\nIn this section, we give the stability result for Eq. (53) (Theorem E.3). Different from Theorem C.5, the constraint c\u0304 \u2264 2 is released here. The notations u\u2217, c\u0304, L0, L\u0303HJB, B\u0303HJB in the following discussion come from C. The proof of Theorem E.3 is quite similar to that of Theorem C.5.\nWe begin with some auxiliary results.\nLemma E.1. Suppose \u2126 is a fixed bounded open set in Rn. Suppose u1 satisfies L\u0303HJBu\u2217 = L\u0303HJBu1 and that supp(u1 \u2212 u\u2217) \u2282 QT (\u2126). Let q \u2208 [1,\u221e).\nIf q > (c\u0304\u22121)n 2 n+2c\u0304 , then there exists \u03b40 > 0 such that when \u2016B\u0303HJBu1 \u2212 B\u0303HJBu \u2217\u20161,q < \u03b40, we have \u2016u\u2217 \u2212 u1\u20162,r \u2264 C\u2016B\u0303HJBu1 \u2212 B\u0303HJBu\u2217\u20161,q for a constant C independent of u1, where r < (n+2)qn+q .\nProof. The proof is almost the same as that for Lemma C.3.\nFollowing its proof, we define w, f, w1 and v similarly. And the Wm,p and Lp norm in the rest of the proof will also be defined on the domain QT (\u2126).\nSince q > (c\u0304\u22121)n 2 n+2c\u0304 , we have [(1\u2212 c\u0304 \u22121)n, (n+2)qn+q ) 6= \u2205.\nThus we could choose r\u2032 \u2208 [(1\u2212 c\u0304\u22121)n, (n+2)qn+q ) \u2229 [r,\u221e).\nSince QT (\u2126) is bounded, it suffices to bound \u2016u1 \u2212 u\u2217\u2016r\u2032 . From Lemma A.5, we have \u2016w1\u20162,r\u2032 \u2264 C\u2016f\u20161,q. And from Lemma A.4 , we get \u2016v\u20162,r\u2032 \u2264 C \u2032\u2016L0v\u2016r\u2032 . Therefore we have \u2016w\u20162,r\u2032 \u2264 \u2016w1\u20162,r\u2032 + \u2016v\u20162,r\u2032 \u2264 C\u2016f\u20161,q + C \u2032\u2016L0v\u2016r\u2032 . Next, we give an estimation for \u2016L0v\u2016r\u2032 . Following from the proof in Lemma C.2, we obtain {ki}ni=1 \u2282 N, {tij}1\u2264i\u2264n,1\u2264j\u2264ki \u2282 R, and power functions {fij}1\u2264i\u2264n,1\u2264j\u2264ki . With similar computations, we have\n\u2016L0v\u2016r\u2032 \u2264 n\u2211 i=1 Ai(\u2016|\u2202iw|ci\u2016r\u2032 + ki\u2211 j=1 \u2016fij(|\u2202iu\u2217|)|\u2202iw|tij\u2016r\u2032) (93)\n\u2264 n\u2211 i=1 Ai(\u2016\u2202iw\u2016cicir\u2032 + ki\u2211 j=1 \u2016fij(|\u2202iu\u2217|)\u2016\u221e\u2016\u2202iw\u2016 tij tijr\u2032 ). (94)\nDue to the fact that QT (\u2126) is bounded, all \u2016\u2202iw\u2016cir\u2032 and \u2016\u2202iw\u2016tijr\u2032 could be bounded by Ci,j\u2016w\u20161,c\u0304r\u2032 , where Ci,j are constants.\nMoreover, since r\u2032 \u2265 (1\u2212 c\u0304\u22121)n, we could tell from Lemma A.2 that\n\u2016w\u20161,c\u0304r\u2032 \u2264 C\u0302\u2016w\u20162, nc\u0304r\u2032 n+c\u0304r\u2032 \u2264 C\u0302 \u2032\u2016w\u20162,r\u2032 , (95)\nwhere C\u0302 and C\u0302 \u2032 are constants.\nWith similar methods applied in Lemma C.2, we could prove this lemma.\nLemma E.2. Fix \u2126, which is an arbitrary bounded open set in Rn. For two functions f\u03021(x, t), f\u03022(x), denote by u1 the solution to{\nL\u0303HJBu(x, t) = h(x, t) + f\u03021(x, t), in Rn \u00d7 [0, T ] B\u0303HJBu(x, t) = g(x) + f\u03022(x), in Rn.\nFor p, q \u2265 1, let r0 = (n+2)qn+q . Assume the following inequalities hold for p, q and r0: p \u2265 max { 2, ( 1\u2212 1\nc\u0304\n) n } ; q > (c\u0304\u2212 1)n2\nn+ 2c\u0304 . (96)\nFurther assume supp(u1 \u2212 u\u2217) \u2282 QT (\u2126).\nThen for \u2200r \u2208 [1,min{r0, p}), there exists \u03b40 > 0 such that, when \u2016f\u03021\u2016p < \u03b40 and \u2016f\u03022\u2016q < \u03b40, \u2016u1 \u2212 u\u2217\u20162,r \u2264 C(\u2016f\u03021\u2016p + \u2016f\u03022\u20161,q) for a constant C independent of u1.\nProof. The proof follows as in Lemma C.4 by replacing the use of Lemma C.3 with Lemma E.1.\nTheorem E.3. Let f\u03021, f\u03022 and u1 follow from Lemma E.2. For p, q, r \u2265 1, let r0 = (n+2)qn+q . Assume the following inequalities hold for p, q, r and r0:\np \u2265 max { 2, ( 1\u2212 1\nc\u0304\n) n } ; q > (c\u0304\u2212 1)n2\nn+ 2c\u0304 ;\n1 r >\n1 min{r0, p} \u2212 1 n . (97)\nThen for any bounded open set Q \u2282 Rn \u00d7 [0, T ], there exists \u03b4 > 0 and a constant C independent of u1, f\u03021 and f\u03022, such that max{\u2016f\u03021\u2016Lp(Rn\u00d7[0,T ]), \u2016f\u03022\u2016W 1,q(Rn)} < \u03b4 implies \u2016u1 \u2212 u\u2217\u2016W 1,r(Q) \u2264 C(\u2016f\u03021\u2016Lp(Rn\u00d7[0,T ]) + \u2016f\u03022\u2016W 1,q(Rn)).\nProof. By replacing the use of Lemma C.4 in the proof for Theorem C.5 with Lemma E.2, we can bound \u2016u1 \u2212 u\u2217\u2016W 2,r\u2032 (Q) with \u2016f\u03021\u2016Lp(Rn\u00d7[0,T ]) and \u2016f\u03022\u2016W 1,q(Rn) for any r\u2032 \u2208 [1,min{r0, p}).\nWe could further bound \u2016u1 \u2212 u\u2217\u2016W 1,r(Q) with the help of Lemma A.2. This concludes the proof."
        },
        {
            "heading": "F Experimental Settings",
            "text": "Hyperparameters. The hyperparameters used in our experiment is described in Table 3.\nTraining data. In all the experiments, the training data is sampled online. Specifically, in each iteration, we sample N1 i.i.d. data points, (x(1), t(1)), \u00b7 \u00b7 \u00b7 , (x(N1), t(N1)), from the domain Rn \u00d7 [0, T ], and N2 i.i.d. data points, (x\u0303(1), T ), \u00b7 \u00b7 \u00b7 , (x\u0303(N2), T ), from the boundary Rn \u00d7 {T}, where (x(i), t(i)) \u223c N (0, In)\u00d7 U(0, 1) and x\u0303(j) \u223c N (0, In).\nEvaluation metrics. We use L1, L2, and W 1,1 relative errors to evaluate the quality of the learned solution.\nL1 and L2 relative errors are two popular evaluation metrics, which are defined as\u2211S j=1 |u\u2217(xj)\u2212 u\u03b8(xj)|p\u2211S\nj=1 |u\u2217(xj)|p , p = 1, 2, (98)\nwhere u\u03b8 is the learned approximate solution, u\u2217 is the exact solution and {xj}Sj=1 are S i.i.d. uniform samples from the domain [0, 1]n \u00d7 [0, T ]. Since the gradient of the solution to HJB equations plays an important role in applications, we also evaluate the solution using W 1,1 relative error, which is defined as\u2211S\nj=1(|u\u2217(xj)\u2212 u\u03b8(xj)|+ \u2211n i=1 |\u2202xiu\u2217(xj)\u2212 \u2202xiu\u03b8(xj)|)\u2211S\nj=1(|u\u2217(xj)|+ \u2211n i=1 |\u2202xiu\u2217(xj)|)\n. (99)"
        },
        {
            "heading": "G More experiments and visualizations",
            "text": "G.1 More instance of HJB Equations\nTo demonstrate the power of our method in solving general HJB Equations beyond classical LQG problems, we consider a more complicated HJB Equation as below: \u2202tu(x, t) + \u2206u(x, t)\u2212 1 n n\u2211 i=1 |\u2202xiu|c = \u22122 (x, t) \u2208 Rn \u00d7 [0, T ] u(x, T ) =\nn\u2211 i=1 xi x \u2208 Rn , (100)\nEq. (100) has a unique solution u(x, t) = x1 + \u00b7 \u00b7 \u00b7+ xn + T \u2212 t. We consider to solve Eq. (100) for different valued of c using our method. We choose c = 1.25, 1.5 and 1.75 in the experiment. The neural network used for training is a 5-layer MLP with 4096 neurons and ReLU activation in each\nhidden layer. The training recipe, including the optimizer, learning rate, batch size, and the total iterations are the same as those in Appendix F. The number of inner-loop iterations K is set to 5, and the inner-loop step size \u03b7 is searched from {2e\u2212 1, 2e\u2212 2, 2e\u2212 3}. Again, we examine the quality of the learned solution u(x, t) by visualizing its snapshot on a twodimensional space. Specifically, we consider the bivariate function u(x1, x2, 1, 1, \u00b7 \u00b7 \u00b7 , 1; 0) and use a heatmap to show its function value given different x1 and x2. Figure 3-5 shows the ground truth u\u2217, the learned solutions u of our method, and the point-wise absolute error |u\u2212 u\u2217| given different values of c.\nFrom the above visualization, we can see that our method can solve Eq. (100) for different values of c effectively. Specifically, when c = 1.25 or 1.5, the point-wise absolute error is less than 0.5 for most of the area shown in the figures. When c = 1.75, the point-wise absolute error seems slightly larger, but it\u2019s still negligible compared with the scale of the learned solution. Thus, PINNs trained with our method fit the solution of Eq. (100) well, given different values of c.\nWe also compare our models with other baselines on these equations. The evaluation metric is L1 relative error in the domain [0, 1]n\u00d7 [0, 1]. The results are shown in Table 4. It\u2019s clear that our models outperform all the baselines on all these equations, showing the efficacy of our approach.\nG.2 Tracing loss and error during the training\nTo give a more comprehensive comparison between original PINN and our method, we trace the loss and error during the training.\nIt is clear that for the original PINN approach, the L2 loss drops very quickly during training, while its W 1,1 relative error remains high. This result indicates the optimization is successful in this experiment, and that the stability property of the PDE leads to the high test error. By contrast, our proposed training approach enables the test error goes down steadily during training, which aligns with the theoretical claims."
        },
        {
            "heading": "H Discussions on training with Lp loss",
            "text": "As is shown in the left panel of Table 2, directly optimizing Lp loss with large p fails to achieve a good approximator. This might seem to contradict our theoretical analysis in section 4. However, there is actually no contradiction between our theorems and empirical results. Theorem 4.3 focuses on the approximation ability, which indicates that if we have a model whose Lp loss is small, it will approximate the true solution well. The empirical results in Table 2 demonstrate the optimization difficulty of learning such a model.\nIntuitively, we randomly sample points in each training iteration in the domain/boundary to calculate the loss. When p is large, most sampled points will hardly contribute to the loss, which leads to inefficiency and makes the training hard to converge. In Algorithm 1, we adversarially learn the points with large loss values, making all of them contribute to the model update (Step 8), significantly improving the model training.\nTechnically, directly applying Monte Carlo to compute Lp loss in experiments will lead to large variance estimations. For a function f ,\u222b\n|f |pdx = 1 N N\u2211 i=1 |f(Xi)|p +O\n(\u221a Var|f(X)|p\nN\n) ,\nwhere {Xi}Ni=1 are i.i.d. samplings in the domain.\nThus, ||f ||p suffers from an O((Var|f(X)|p/N)1/2p) error.\nAs p \u2192 \u221e,Var|f(X)|p \u223c ||f ||2p\u221e. Therefore, the errors for estimating both Eq.(2,3) and the Lp norm of the residual are very large when p is large."
        }
    ],
    "title": "Is L Physics-Informed Loss Always Suitable for Training Physics-Informed Neural Network?",
    "year": 2023
}