{
    "abstractText": "A Markov network characterizes the conditional independence structure, or Markov property, among a set of random variables. Existing work focuses on specific families of distributions (e.g., exponential families) and/or certain structures of graphs, and most of them can only handle variables of a single data type (continuous or discrete). In this work, we characterize the conditional independence structure in general distributions for all data types (i.e., continuous, discrete, and mixed-type) with a Generalized Precision Matrix (GPM). Besides, we also allow general functional relations among variables, thus giving rise to a Markov network structure learning algorithm in one of the most general settings. To deal with the computational challenge of the problem, especially for large graphs, we unify all cases under the same umbrella of a regularized score matching framework. We validate the theoretical results and demonstrate the scalability empirically in various settings.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yujia Zheng"
        },
        {
            "affiliations": [],
            "name": "Ignavier Ng"
        },
        {
            "affiliations": [],
            "name": "Yewen Fan"
        },
        {
            "affiliations": [],
            "name": "Kun Zhang"
        },
        {
            "affiliations": [],
            "name": "Mohamed bin Zayed"
        }
    ],
    "id": "SP:fd2f6426260294690189175b459785556f3017f7",
    "references": [
        {
            "authors": [
                "Bryan Andrews",
                "Joseph Ramsey",
                "Gregory F Cooper"
            ],
            "title": "Scoring bayesian networks of mixed variables",
            "venue": "International journal of data science and analytics,",
            "year": 2018
        },
        {
            "authors": [
                "Ricardo Baptista",
                "Youssef Marzouk",
                "Rebecca E Morrison",
                "Olivier Zahm"
            ],
            "title": "Learning non-gaussian graphical models via hessian scores and triangular transport",
            "venue": "arXiv preprint arXiv:2101.03093,",
            "year": 2021
        },
        {
            "authors": [
                "Julian Besag"
            ],
            "title": "Spatial interaction and the statistical analysis of lattice systems",
            "venue": "Journal of the Royal Statistical Society: Series B (Methodological),",
            "year": 1974
        },
        {
            "authors": [
                "Patrick Breheny",
                "Jian Huang"
            ],
            "title": "Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection",
            "venue": "The Annals of Applied Statistics,",
            "year": 2011
        },
        {
            "authors": [
                "D Brook"
            ],
            "title": "On the distinction between the conditional probability and the joint probability approaches in the specification of nearest-neighbour systems",
            "year": 1964
        },
        {
            "authors": [
                "Peter J Carrington",
                "John Scott",
                "Stanley Wasserman"
            ],
            "title": "Models and methods in social network analysis, volume 28",
            "venue": "Cambridge university press,",
            "year": 2005
        },
        {
            "authors": [
                "Jie Cheng",
                "Tianxi Li",
                "Elizaveta Levina",
                "Ji Zhu"
            ],
            "title": "High-dimensional mixed graphical models",
            "venue": "Journal of Computational and Graphical Statistics,",
            "year": 2017
        },
        {
            "authors": [
                "David M. Chickering"
            ],
            "title": "Optimal structure identification with greedy search",
            "venue": "Journal of Machine Learning Research,",
            "year": 2002
        },
        {
            "authors": [
                "Giulio Cimini",
                "Tiziano Squartini",
                "Fabio Saracco",
                "Diego Garlaschelli",
                "Andrea Gabrielli",
                "Guido Caldarelli"
            ],
            "title": "The statistical physics of real-world networks",
            "venue": "Nature Reviews Physics,",
            "year": 2019
        },
        {
            "authors": [
                "Sheel C Dodani",
                "Gert Kiss",
                "Jackson KB Cahn",
                "Ye Su",
                "Vijay S Pande",
                "Frances H Arnold"
            ],
            "title": "Discovery of a regioselectivity switch in nitrating p450s guided by molecular dynamics simulations and markov models",
            "venue": "Nature chemistry,",
            "year": 2016
        },
        {
            "authors": [
                "Mathias Drton",
                "Bernd Sturmfels",
                "Seth Sullivant"
            ],
            "title": "Lectures on algebraic statistics, volume 39",
            "venue": "Springer Science & Business Media,",
            "year": 2008
        },
        {
            "authors": [
                "David Edwards"
            ],
            "title": "Hierarchical interaction models",
            "venue": "Journal of the Royal Statistical Society: Series B (Methodological),",
            "year": 1990
        },
        {
            "authors": [
                "Jianqing Fan",
                "Runze Li"
            ],
            "title": "Variable selection via nonconcave penalized likelihood and its oracle properties",
            "venue": "Journal of the American statistical Association,",
            "year": 2001
        },
        {
            "authors": [
                "Bernd Fellinghauer",
                "Peter B\u00fchlmann",
                "Martin Ryffel",
                "Michael Von Rhein",
                "Jan D Reinhardt"
            ],
            "title": "Stable graphical model estimation with random forests for discrete, continuous, and mixed variables",
            "venue": "Computational Statistics & Data Analysis,",
            "year": 2013
        },
        {
            "authors": [
                "Jerome Friedman",
                "Trevor Hastie",
                "Robert Tibshirani"
            ],
            "title": "Sparse inverse covariance estimation with the graphical lasso",
            "year": 2008
        },
        {
            "authors": [
                "Geoffrey R Grimmett"
            ],
            "title": "A theorem about random fields",
            "venue": "Bulletin of the London Mathematical society,",
            "year": 1973
        },
        {
            "authors": [
                "Naftali Harris",
                "Mathias Drton"
            ],
            "title": "Pc algorithm for nonparanormal graphical models",
            "venue": "Journal of Machine Learning Research,",
            "year": 2013
        },
        {
            "authors": [
                "Biwei Huang",
                "Kun Zhang",
                "Yizhu Lin",
                "Bernhard Sch\u00f6lkopf",
                "Clark Glymour"
            ],
            "title": "Generalized score functions for causal discovery",
            "venue": "In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining,",
            "year": 2018
        },
        {
            "authors": [
                "Junzhou Huang",
                "Tong Zhang"
            ],
            "title": "The benefit of group sparsity",
            "venue": "The Annals of Statistics,",
            "year": 1978
        },
        {
            "authors": [
                "Aapo Hyv\u00e4rinen",
                "Peter Dayan"
            ],
            "title": "Estimation of non-normalized statistical models by score matching",
            "venue": "Journal of Machine Learning Research,",
            "year": 2005
        },
        {
            "authors": [
                "Ariel Jaimovich",
                "Gal Elidan",
                "Hanah Margalit",
                "Nir Friedman"
            ],
            "title": "Towards an integrated protein\u2013 protein interaction network: A relational markov network approach",
            "venue": "Journal of Computational Biology,",
            "year": 2006
        },
        {
            "authors": [
                "Steffen L Lauritzen"
            ],
            "title": "Graphical models, volume 17",
            "year": 1996
        },
        {
            "authors": [
                "Steffen L Lauritzen",
                "Anders Holst Andersen",
                "David Edwards",
                "Karl G J\u00f6reskog",
                "S\u00f8ren Johansen"
            ],
            "title": "Mixed graphical association models [with discussion and reply",
            "venue": "Scandinavian Journal of Statistics,",
            "year": 1989
        },
        {
            "authors": [
                "Jason D Lee",
                "Trevor J Hastie"
            ],
            "title": "Learning the structure of mixed graphical models",
            "venue": "Journal of Computational and Graphical Statistics,",
            "year": 2015
        },
        {
            "authors": [
                "Lina Lin",
                "Mathias Drton",
                "Ali Shojaie"
            ],
            "title": "Estimation of high-dimensional graphical models using regularized score matching",
            "venue": "Electronic journal of statistics,",
            "year": 2016
        },
        {
            "authors": [
                "Han Liu",
                "John Lafferty",
                "Larry Wasserman"
            ],
            "title": "The nonparanormal: Semiparametric estimation of high dimensional undirected graphs",
            "venue": "Journal of Machine Learning Research,",
            "year": 2009
        },
        {
            "authors": [
                "Han Liu",
                "Fang Han",
                "Cun-hui Zhang"
            ],
            "title": "Transelliptical graphical models",
            "venue": "Advances in neural information processing systems,",
            "year": 2012
        },
        {
            "authors": [
                "Po-Ling Loh",
                "Peter B\u00fchlmann"
            ],
            "title": "High-dimensional learning of linear causal networks via inverse covariance estimation",
            "venue": "Journal of Machine Learning Research,",
            "year": 2014
        },
        {
            "authors": [
                "Po-Ling Loh",
                "Martin J Wainwright"
            ],
            "title": "Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2012
        },
        {
            "authors": [
                "Po-Ling Loh",
                "Martin J. Wainwright"
            ],
            "title": "Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses",
            "venue": "The Annals of Statistics,",
            "year": 2013
        },
        {
            "authors": [
                "Po-Ling Loh",
                "Martin J. Wainwright"
            ],
            "title": "Support recovery without incoherence: A case for nonconvex regularization",
            "venue": "The Annals of Statistics,",
            "year": 2017
        },
        {
            "authors": [
                "Siwei Lyu"
            ],
            "title": "Interpretation and generalization of score matching",
            "venue": "arXiv preprint arXiv:1205.2629,",
            "year": 2012
        },
        {
            "authors": [
                "Nicolai Meinshausen",
                "Peter B\u00fchlmann"
            ],
            "title": "High-dimensional graphs and variable selection with the lasso",
            "venue": "The annals of statistics,",
            "year": 2006
        },
        {
            "authors": [
                "Rebecca Morrison",
                "Ricardo Baptista",
                "Youssef Marzouk"
            ],
            "title": "Beyond normality: Learning sparse probabilistic graphical models in the non-gaussian setting",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Ignavier Ng",
                "Yujia Zheng",
                "Jiji Zhang",
                "Kun Zhang"
            ],
            "title": "Reliable causal discovery with improved exact search and weaker assumptions",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Dinh Tuan Pham",
                "Philippe Garat"
            ],
            "title": "Blind separation of mixture of independent sources through a quasi-maximum likelihood approach",
            "venue": "IEEE transactions on Signal Processing,",
            "year": 1997
        },
        {
            "authors": [
                "Garvesh Raskutti",
                "Bin Yu",
                "Martin J Wainwright",
                "Pradeep Ravikumar"
            ],
            "title": "Model selection in gaussian graphical models: High-dimensional consistency of `1-regularized mle",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2008
        },
        {
            "authors": [
                "Pradeep Ravikumar",
                "Garvesh Raskutti",
                "Martin J Wainwright",
                "Bin Yu"
            ],
            "title": "Model selection in Gaussian graphical models: High-dimensional consistency of ell1-regularized MLE",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2008
        },
        {
            "authors": [
                "Pradeep Ravikumar",
                "Martin J Wainwright",
                "John D Lafferty"
            ],
            "title": "High-dimensional ising model selection using `1-regularized logistic regression",
            "venue": "The Annals of Statistics,",
            "year": 2010
        },
        {
            "authors": [
                "Huawei Shen",
                "Xueqi Cheng",
                "Kai Cai",
                "Mao-Bin Hu"
            ],
            "title": "Detect overlapping and hierarchical community structure in networks",
            "venue": "Physica A: Statistical Mechanics and its Applications,",
            "year": 2009
        },
        {
            "authors": [
                "Yang Song",
                "Sahaj Garg",
                "Jiaxin Shi",
                "Stefano Ermon"
            ],
            "title": "Sliced score matching: A scalable approach to density and score estimation",
            "venue": "In Uncertainty in Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Alessio Spantini",
                "Daniele Bigoni",
                "Youssef Marzouk"
            ],
            "title": "Inference via low-dimensional couplings",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2018
        },
        {
            "authors": [
                "Peter Spirtes",
                "Clark Glymour"
            ],
            "title": "An algorithm for fast recovery of sparse causal graphs",
            "venue": "Social Science Computer Review,",
            "year": 1991
        },
        {
            "authors": [
                "Arun Suggala",
                "Mladen Kolar",
                "Pradeep K Ravikumar"
            ],
            "title": "The expxorcist: Nonparametric graphical models via conditional exponential densities",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Robert Tibshirani"
            ],
            "title": "Regression shrinkage and selection via the Lasso",
            "venue": "Journal of the Royal Statistical Society. Series B (Methodological),",
            "year": 1996
        },
        {
            "authors": [
                "Ioannis Tsamardinos",
                "Constantin F Aliferis",
                "Alexander R Statnikov",
                "Er Statnikov"
            ],
            "title": "Algorithms for large scale markov blanket discovery",
            "venue": "In FLAIRS conference,",
            "year": 2003
        },
        {
            "authors": [
                "Martin J. Wainwright"
            ],
            "title": "Sharp thresholds for high-dimensional and noisy sparsity recovery using ell1-constrained quadratic programming (Lasso)",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 2009
        },
        {
            "authors": [
                "Eunho Yang",
                "Pradeep Ravikumar",
                "Genevera I Allen",
                "Zhandong Liu"
            ],
            "title": "Graphical models via univariate exponential family distributions",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2015
        },
        {
            "authors": [
                "Ming Yuan"
            ],
            "title": "High dimensional inverse covariance matrix estimation via linear programming",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2010
        },
        {
            "authors": [
                "Ming Yuan",
                "Yi Lin"
            ],
            "title": "Model selection and estimation in regression with grouped variables",
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
            "year": 2006
        },
        {
            "authors": [
                "Cun-Hui Zhang"
            ],
            "title": "Nearly unbiased variable selection under minimax concave penalty",
            "venue": "The Annals of Statistics,",
            "year": 2010
        },
        {
            "authors": [
                "Kun Zhang",
                "Jonas Peters",
                "Dominik Janzing",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Kernel-based conditional independence test and application in causal discovery",
            "venue": "arXiv preprint arXiv:1202.3775,",
            "year": 2012
        },
        {
            "authors": [
                "Hui Zou"
            ],
            "title": "The adaptive lasso and its oracle properties",
            "venue": "Journal of the American statistical association,",
            "year": 2006
        },
        {
            "authors": [
                "Ng"
            ],
            "title": "large, the search procedure may involve computing the kernel-based conditional independence test or score function many times, which therefore may also increase the running time",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Markov networks (also known as Markov random fields) represent conditional dependencies among random variables. They provide clear semantics in a graphical manner to cope with uncertainty in probability theory, with a wide application in fields including physics (Cimini et al., 2019), chemistry (Dodani et al., 2016), biology (Jaimovich et al., 2006), and sociology (Carrington et al., 2005). The undirected nature of edges also allows cyclic, overlapping, or hierarchical interactions (Shen et al., 2009). To estimate the Markov network from observational data, existing work focuses on certain parametric families of distributions, a majority of which study the Gaussian case. By assuming that the variables are from a multivariate Gaussian distribution, the dependencies can be well represented by the support of the precision, or inverse covariance, matrix according to Hammersley-Clifford theorem (Besag, 1974; Grimmett, 1973). Together with various statistical estimators (e.g., the graphical lasso (Friedman et al., 2008) and neighborhood selection (Meinshausen & B\u00fchlmann, 2006)), this connection between the precision matrix and graphical structure has been well exploited in the Gaussian case in the past decades (Yuan, 2010; Ravikumar et al., 2011). However, methods for Gaussian graphical models fail to correctly capture dependencies among variables deviating from Gaussian or including nonlinearity (Raskutti et al., 2008; Ravikumar et al., 2011).\nWhile non-Gaussianity is more common in real-world data generating process, few results are applicable to Markov network structure learning on non-Gaussian data. In the discrete setting, Ravikumar et al. (2010) showed that a binary Ising model can be recovered by neighborhood selection using `1 penalized logistic regression. Loh & Wainwright (2013) encoded extra structural relations in the proposed generalized covariance matrix to model the dependencies for Markov networks with certain structures (e.g., tree structures or graphs with only singleton separator sets) among variables from exponential families. Several approaches allowed estimation for non-Gaussian continuous variables while most of them assumed parametric assumptions such as the exponential families (Yang et al., 2015; Lin et al., 2016; Suggala et al., 2017) or Gaussian copulas (Liu et al., 2009; 2012; Harris & Drton, 2013). These methods illustrate the possibility of reliable Markov network estimations in several non-Gaussian cases, but still, the models are restricted to specific parametric families of distributions and/or structures of conditional independencies.\nar X\niv :2\n30 5.\n11 37\n9v 1\n[ cs\n.L G\n] 1\n9 M\nay 2\n02 3\nConcerned with describing Markov properties of non-Gaussian data with general continuous distributions, Morrison et al. (2017) used the second-order derivatives to encode the conditional independence structure. Specifically, their approach is based on a theorem that the zero pattern in the Hessian matrix of the log-density determines the conditional independencies between non-Gaussian continuous variables (Spantini et al., 2018). A method based on transport map, i.e., Sparsity Identification in Non-Gaussian distributions (SING) (Baptista et al., 2021), is then designed to estimate the data density from samples, and the structure is derived from the estimated density. This approach achieves consistent Markov network structure recovery in a general non-Gaussian continuous setting. However, methods relying on the Hessian matrix cannot cope with discrete or mixed-type data. In addition, density estimation, especially for non-Gaussian data, can be computationally challenging for large graphs, limiting the scalability of this approach. Kernel-based Conditional Independence test (KCI) (Zhang et al., 2012) and Generalized Score (GS) (Huang et al., 2018) can handle the mixed-type case for structure learning, but as kernel-based methods, they are computationally challenging since the complexity scales cubically in the number of samples.\nTo deal with these remaining obstacles, we explore a Generalized Precision Matrix (GPM) for nonparametric Markov networks learning. Based on the necessary and sufficient conditions for the conditional independence among structures in continuous, discrete, and mixed-type cases, GPM characterizes the Markov network structures with arbitrary data types. Moreover, our work does not constrain the distribution to be of specific families, such as exponential families, or has been normalized. Besides, it is also noteworthy that there are no specific assumptions on the functional relations among variables. To the best of our knowledge, the proposed GPM illustrates the feasibility of Markov network structure learning in one of the most general nonparametric settings.\nFurthermore, we put all these cases under the same umbrella of the estimation framework based on regularized score matching, as an extension of the score matching framework (Hyv\u00e4rinen & Dayan, 2005). Different from the previous approach (SING) that applies a transport map to estimate the data density for general continuous distributions, our framework allows us to only estimate the model score function parameterized by a deep model, from which the characterization matrix of the Markov network structure can be directly calculated. To facilitate the estimation process, we also exploit suitable penalties on the characterization matrix to encourage constantly sparse entries. Besides, we adopt recent advancements on score matching (Song et al., 2020) to further scale up the process. Our method therefore narrows the gap between reliable structure learning and scalable deep learning techniques. We validate the theoretical results experimentally, and the scalability has been illustrated."
        },
        {
            "heading": "2 GENERALIZED PRECISION MATRIX",
            "text": "Suppose that we observe a collection of random variables X = (X1, . . . , Xd). Our goal is to discover the underlying Markov network structure. Specifically, it is an undirected graph G comprising a set of vertices V = {1, . . . , d} and edges E. The edges E encode the conditional independence relations or the global Markov property: for any disjoint subsets A, B, and C in the vertices set V such that C separates A and B, XA and XB are conditionally independent given XC, i.e., XA \u22a5 XB | XC.1 Throughout this paper, we use an uppercase letter to denote a random variable and a lowercase letter with subscripts to denote the value of a random variable (e.g., Xi = xi for the value of Xi). For a discrete variable, say Xi, we denote its support by {xi1, . . . , xiMi}, where Mi is its cardinality. As an alternative characterization of the conditional independence relations encoded by the graph, the pairwise Markov property requires that every pair of non-adjacent variables in the graph is conditionally independent given the remaining variables. That is, for any i 6= j, an edge between Xi and Xj is absent if and only if Xi and Xj are conditionally independent given the remaining variables, i.e., Xi \u22a5 Xj | XV\\{i,j}. The conditioning set consisting of all remaining variables is essential. According to Lauritzen (1996), the pairwise Markov property is equivalent to the global one when the density is strictly positive. In order to estimate nonparametric Markov networks in this setting, we explore generalized characterizations of conditional independence in all types of data (i.e., continuous, discrete, and mixed-type) without distributional constraints. We start from learning conditional independence structures in continuous data with a procedure inspired by Spantini et al. (2018), and then propose new characterizations for discrete and mixed-type data.\n1For any set S \u2282 V, we write XS = {Xi : i \u2208 S}.\nIdeally, we aim to construct a Generalized Precision Matrix \u2126 that satisfies the following desiderata:\na. For any i 6= j, if \u2126i,j = 0, then Xi \u22a5 Xj | XV\\{i,j}; b. The probability measure is not restricted to be from specific families but only needs to be\nstrictly positive; c. The undirected graph G is not restricted to be of certain structures; d. For continuous variables, the density has continuous derivatives up to second order w.r.t. the\nLebesgue measure; e. For discrete variables, the cardinality is not restricted; f. To enable practical estimation procedure, \u2126 is differentiable w.r.t. X.\nProperty (a) is the characterization of the pairwise Markov property. Properties (b) and (c) differentiate our work from most previous works that assumes Gaussianity or/and certain structures of the conditional independence. Properties (d) and (e) further raise the difficulty of our task, because, in addition to not being restricted to a specific family of distributions, our characterization \u2126 has to be available for all data types (i.e., continuous, discrete, and mixed-type) with mild assumptions. For discrete variables, Property (e) removes the limitation of cardinality, thus differentiating our work from those focusing on the binary Ising model. Property (f) allows us to incorporate an `1 regularization term in the estimation procedure and make use of gradient-based optimization."
        },
        {
            "heading": "2.1 CHARACTERIZATION FOR CONTINUOUS DATA",
            "text": "We aim to find the necessary and sufficient conditions for Xi \u22a5 Xj | XV\\{i,j}. By definition, if Xi is conditionally independent of Xj given all remaining variable XV\\{i,j}, we can factor the probability density function (PDF) pX as follows pX(x) = p(xi | xV\\{i,j})p(xj | xV\\{i,j})p(xV\\{i,j}). (1) Together with the assumption that pX has continuous derivatives up to second order w.r.t. the Lebesgue measure, we have\n\u22022 log pX \u2202xi\u2202xj = 0. (2)\nConversely, the solution of Eq. (2) is given by log pX(x) = g(x1:i\u22121, xi+1:d) + h(x1:j\u22121, xj+1:d) for some functions g, h : Rd\u22121 \u2192 R. It thus follows Xi \u22a5 Xj | XV\\{i,j}. This connection between pairwise conditional independence and cross derivatives of the log density has been observed in Spantini et al. (2018). Methods based on this connection have also been proposed recently (Morrison et al., 2017; Baptista et al., 2021). Following Baptista et al. (2021), one can characterize the conditional independence between Xi and Xj in the continuous distribution as\n\u2126 [c] ij := ( EpX [ f [c] i,j(x) 2 ]) 1 2 , (3)\nwhere f [c]i,j(\u00b7) denotes the LHS of Eq. (2) and [c] denotes continuous data as a type label. In practice, pX is the empirical PDF. The group structure of it could help achieve simultaneous sparse approximation (Yuan & Lin, 2006; Huang & Zhang, 2010) when being applied as an `1 regularizer in the estimation, which we will describe in Sec. 3. We also apply the same group structures for both the discrete and mixed-type cases, but we will skip the reintroduction for brevity. The characterization of the Markov property is as follows. Corollary 1. Assume\ni. X = (X1, . . . , Xd) is a set of continuous variable.\nii. The PDFs of X are strictly positive and smooth.\niii. The characterization matrix \u2126[c] is defined according to Eq. (3).\nThen for any i 6= j, \u2126[c]i,j = 0 implies Xi \u22a5 Xj | XV\\{i,j}.\nThe proof is shown in Appx. A.1. It is worth noting that Cor. 1 also covers the Gaussian case, where the cross-derivatives of the log-density correspond to entries in the precision or inverse covariance matrix (Drton et al., 2008), thus generalizing previous work assuming Gaussianity. Hence, the support of \u2126 characterizes conditional independence among continuous variables for general distributions."
        },
        {
            "heading": "2.2 CHARACTERIZATION FOR DISCRETE DATA",
            "text": "Since most of the previous work focuses on the Gaussian setting, and works for non-Gaussian distribution are mostly restricted to the exponential family, the characterization for continuous data discussed in Sec. 2.1 has broadened the scope of reliable Markov network learning. However, the characterization is not applicable to discrete data as the gradient does not exist. In this section, we provide such a characterization of Markov network structure in the discrete case. Similar to the continuous case, a key ingredient of the proposed characterization is the necessary and sufficient conditions of conditional independence for discrete data, which we establish in the following theorem. Theorem 1. Denote V as a set of discrete variables and Xi, Xj \u2208 V. For brevity, denote V\\{Xi, Xj} as Z. Let {xi1, . . . , xiMi} and {xj1, . . . , xjMj} be the support of variables Xi and Xj . Denote z as any value(s) of Z. Then, Xi \u22a5\u22a5 Xj | Z if and only if, for all k \u2208 [Mi] and l \u2208 [Mj ] with k 6= 1 and l 6= 1, we have\n(logm(xi1, xj1, z)\u2212 logm(xik, xj1, z))\u2212 (logm(xi1, xjl, z)\u2212 logm(xik, xjl, z)) = 0. (4)\nProof sketch. For the sufficient condition, we want to show that the general solution to Eq. 4 has no term that takes the values of both Xi and Xj . We first iterate all possible differences w.r.t. Xj to get the discrete score function of Xi, which does not take the value of Xj as the argument. Then we obtain the desired solution by summation over all possible differences w.r.t. Xi. For the necessary condition, we decompose the PMF according to the conditional independence to obtain Eq. 4.\nThe full proof is provided in Appx. A.2. Note that we denote m(xik, xjl, z) as the joint probability mass function (PMF) of {Xi, Xj ,Z}, simplified from mXi,Xj ,Z(xik, xjl, z). Based on Thm. 1, we propose the characterization matrix of conditional independence for discrete data \u2126[d]i,j as follows:\n\u2126 [d] i,j := EmX \u2211 k,l f [d](xi1, xik, xj1, xjl, z) 2  , (5) where f [d](xi1, xik, xj1, xjl, z) denotes the LHS of Eq. (4) and [d] is a type label denoting discrete data. The support of the matrix above satisfies the pairwise Markov property and characterizes the Markov network structure, formally stated below with its proof in Appx. A.3. Corollary 2. Assume\ni. X = (X1, . . . , Xd) is a set of discrete variable.\nii. The PMFs of X are strictly positive.\niii. The characterization matrix \u2126[d] is defined according to Eq. (5).\nThen for any i 6= j, \u2126[d]i,j = 0 implies Xi \u22a5 Xj | XV\\{i,j}.\nTherefore, we have a characterization matrix \u2126[d] to represent the conditional independence structure for discrete data. It is worth noting that, unlike the generalized covariance matrix in Loh & Wainwright (2012) that only applies to certain structures among variables from exponential families, the proposed characterization matrix \u2126[d] encodes the Markov properties for general discrete distributions without any structural constraints. Also, compared with Ravikumar et al. (2010), Thm. 1 can be applied to general graphical models apart from binary Ising models and does not rely on the structural condition. It also does not limit the cardinalities of discrete variables. Hence, Theorem 1 sheds light on characterizing arbitrary conditional independence structures for general discrete distributions."
        },
        {
            "heading": "2.3 CHARACTERIZATION FOR MIXED-TYPE DATA",
            "text": "In the previous sections, we have presented characterizations of conditional independence structures for both general continuous and discrete distribution. However, it is common for real-world datasets to have a mixture of continuous and discrete variables. Unfortunately, most works focus on either continuous or discrete data, and previous results for mixed-type data are mostly based on conditional Gaussian distribution (Lauritzen et al., 1989; Edwards, 1990; Lauritzen, 1996; Fellinghauer et al., 2013; Lee & Hastie, 2015; Cheng et al., 2017). Similar to the continuous and discrete settings,\nin this section, we introduce a novel characterization of the pairwise Markov property for general distributions with mixed data-types. We first provide necessary and sufficient conditions of conditional independence for mixed-type data in the following theorem, with full proof given in Appx. A.4.\nTheorem 2. Denote V as a set of mixed-type variables and Xi, Xj \u2208 V, where Xi is discrete and Xj is continuous. Let {xi1, . . . , xiMi} be the support of variables Xi. For brevity, denote V\\{Xi, Xj} as Z. Denote z as any value(s) of Z and xj as any value of the continuous variable Xj . Then, Xi \u22a5\u22a5 Xj | Z if and only if, for all k \u2208 [Mi] with k 6= 1, we have\n\u2202 log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) \u2202xj \u2212 \u2202 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) \u2202xj = 0. (6)\nProof sketch. Similar to the proof sketch of Thm. 1, we consider Xi and Xj separately to construct the desired general solution of Eq. 6 for the sufficient condition. For the necessary condition, we decompose the density function according to the conditional independence to obtain Eq. 6.\nBased on Thm. 2, we propose to characterize the conditional independence between Xi and Xj given all remaining variables with the GPM \u2126[m], of which the element is defined as\n\u2126 [m] i,j :=  E\u03c0X [ f [c] i,j(x) 2 ]\nif Xi \u2208 Xc, Xj \u2208 Xc E\u03c0X [\u2211 k,l f [d](xi1, xik, xj1, xjl, z) 2 ] if Xi \u2208 Xd, Xj \u2208 Xd\nE\u03c0X [\u2211 k f [m](xi, xj1, xjk, z) 2 ]\nif Xi \u2208 Xc, Xj \u2208 Xd E\u03c0X [\u2211 k f [m](xj , xi1, xik, z) 2 ] if Xi \u2208 Xd, Xj \u2208 Xc,\n(7)\nwhere f [m] denotes LHS of Eq. (6) and \u03c0X is the probability function. The type label [m] denotes mixed-type data. Xc and Xd are sets of continuous and discrete variables, respectively. Its characterization of Markov property is as follows\nCorollary 3. Assume\ni. X = (X1, . . . , Xd) is a set of variables containing both continuous and discrete variables.\nii. For continuous variables, the PDFs are strictly positive and smooth.\niii. For discrete variables, the PMFs are strictly positive.\niv. The characterization matrix \u2126[m] is defined according to Eq. (7).\nThen for any i 6= j, \u2126[m]i,j = 0 implies Xi \u22a5 Xj | XV\\{i,j}.\nThe proof is given in Appx. A.5. The GPM \u2126[m] encodes the pairwise Markov property for mixed-type data. More general than previous works, it does not require specific families of distributions, structures of the underlying graph, or cardinality of discrete variables."
        },
        {
            "heading": "3 SCALABLE ESTIMATION WITH REGULARIZED SCORE MATCHING",
            "text": "In Sec. 2, we provide characterizations of conditional independencies for general distribution in continuous, discrete, and mixed-type settings. Based on the introduced necessary and sufficient conditions, these characterizations generalize previous work and establish one of the foundations for nonparametric estimation of Markov network structures with minimal assumptions.\nIn addition to general characterizations of the Markov property with theoretical guarantees (i.e., GPM), a scalable estimation framework is necessary for reliable and practical structure learning. Ideally, we would like to exploit the advancements on scalable deep learning models. Hence, we introduce a regularized score matching-based framework for all considered settings (i.e., general distributions of continuous, discrete, and mixed-type variables)."
        },
        {
            "heading": "3.1 ESTIMATION FOR CONTINUOUS DATA",
            "text": "We start with the continuous setting. Denote p(x; \u03b8) as a parameterized density model with a parameter vector \u03b8. The goal is to estimate parameter \u03b8 from the observation x. We aim to optimize the following objective function, which is based on Fisher divergence:\nOc(\u03b8) = 1\n2 \u222b x\u2208Rd p(x)\u2016\u2207x log p(x; \u03b8)\u2212\u2207x log p(x)\u20162dx + \u03c1\u03bb(\u2126[c]), (8)\nwhere \u03c1\u03bb(\u00b7) denotes a sparsity penalty function and \u03bb is the penalty parameter with domain [0, 1]. \u2126[c] is defined in Eq. 3 as our characterization of the conditional independence structure for continuous data. If we assume the model is not degenerate, where different values of \u03b8 correspond to different PDFs, the asymptotic consistency of the optimization has been shown in Thm. 2 by Hyv\u00e4rinen & Dayan (2005). We impose a sparsity penalty to encounter for finite-sampling errors in practice.\nAlso with a strategy in Hyv\u00e4rinen & Dayan (2005); Pham & Garat (1997), one can remove the data log-density log pX from Eq. (8) by optimizing the following equation, which is equivalent to Eq. (8):\nOc(\u03b8) = \u222b x\u2208Rd p(x) d\u2211 i=1 [ 1 2 \u2016\u2207xi log p(x; \u03b8)\u20162 +Hxi(log p(x; \u03b8)) ] dx + \u03c1\u03bb(\u2126 [c]), (9)\nwhere H denotes the Hessian. The proof is directly based on Hyv\u00e4rinen & Dayan (2005) and we include it (Lemma 1) in Appx. A.6.1 for completeness. It is worth noting that previous work on Markov network structure learning with general continuous distribution (SING (Morrison et al., 2017; Baptista et al., 2021)) applies a transport map to estimate data density from samples, which can be computationally challenging for non-Gaussian data with a large number of variables. Thus, it may not be scalable as suggested by Fig. 1 and Table 1. To avoid this, the proposed regularized score matching allows us to optimize the objective function by only estimating the model score function. Moreover, the estimated model score function directly leads to the characterization matrix \u2126[c] by taking further derivatives, thus efficiently giving rise to the estimated Markov network structure. After training, the expectation in Equation 3 is computed over the parameterized model p(x; \u03b8)."
        },
        {
            "heading": "3.2 ESTIMATION FOR DISCRETE DATA",
            "text": "For the estimation in the discrete case, one cannot directly apply the method introduced for the continuous case since the gradient, on which the continuous score function is based, is not defined for discrete data. An intuitive solution is to replace the gradient with a general linear operator L (Lyu, 2012). Of course, one also needs to replace integration with summation and PDF with PMF. For instance, Eq. (8) can be reformulated as follows\nOd(\u03b8) = 1\n2 \u2211 x mX(x) \u2225\u2225\u2225\u2225L(m(x; \u03b8))m(x; \u03b8) \u2212 L(mX(x))mX(x) \u2225\u2225\u2225\u22252 + \u03c1\u03bb(\u2126[d]), (10)\nwhere m denotes PMF. In this formulation, L(\u00b7) is a generalized version of the score function for discrete data. As shown in Lyu (2012), Od(\u03b8) keeps the computational advantages of score matching for continuous data, i.e., the normalizing partition is canceled out and the formulation can be transformed to an expectation of functions of the unnormalized model. In order to guarantee the consistency of score matching based on Eq. (10), the linear operator L(\u00b7) needs to be complete according to the following definition.\nDefinition 1 (Completeness (Lyu, 2012)). A linear operator L(\u00b7) is complete if L(p(x))p(x) = L(q(x)) q(x) implies p(x) = q(x) almost everywhere, where p(x) and q(x) are two PMFs.\nAccording to Defn. 1, Lyu (2012) used the marginalization operatorM(\u00b7) : F1 7\u2192 Fd as a choice for L(\u00b7), which is defined as\nM(f(x)) =  ...\nMi(f(x)) ...\n =  ...\u2211 x f(x)\n...\n , (11)\nwhere f \u2208 F1. We can observe thatMi(f(x)) is the marginal density of x\\i, where x\\i denotes the vector x after dropping the i-th element (i.e., marginalization). The completeness ofM(\u00b7) has been shown in Brook (1964), and included as Lemma 3 in Lyu (2012). We have\nOd(\u03b8) = 1\n2 \u2211 x mX(x) \u2225\u2225\u2225\u2225M(m(x; \u03b8))m(x; \u03b8) \u2212 M(mX(x))mX(x) \u2225\u2225\u2225\u22252 + \u03c1\u03bb(\u2126[d]). (12)\nThus, it is plausible for us to replace the gradient withM(\u00b7) for discrete data. However, one key advantage of regularized score matching is that it does not have to explicitly estimate the data density (i.e., pX(x) in Theorem 1). As shown by Lyu (2012), we can also optimize Eq. (12) in a similar way, which is equivalent to optimizing the following equation\nOd(\u03b8) = 1\n2 \u2211 x mX(x) d\u2211 i=1 [( Mi(m(x; \u03b8)) m(x; \u03b8) )2 \u2212 2Mi ( Mi(m(x; \u03b8)) m(x; \u03b8) )] + \u03c1\u03bb(\u2126 [d]). (13)\nThe simplification is directly from results in Lyu (2012), of which the corresponding lemma (Lemma 2) is formalized with its proof in Appx. A.6.2 for completeness. Based on Thm. 1 and Thm. 2, similar to the continuous case, we can estimate Markov network structures for general distributions in the discrete setting under the same umbrella of regularized score matching."
        },
        {
            "heading": "3.3 ESTIMATION FOR MIXED-TYPE DATA",
            "text": "For mixed-type data, we define the objective function as follows\nOm(\u03b8) = E\u03c0X [\u2211 i si(x; \u03b8) ] + \u03c1\u03bb(\u2126 [m]), (14)\nwhere\nsi(x; \u03b8) :=  1 2\u2016\u2207xi log \u03c0(x; \u03b8)\u2016\n2 +Hxi(log \u03c0(x; \u03b8)) Xi \u2208 Xc 1 2 ( Mi(m(x;\u03b8)) m(x;\u03b8) )2 \u2212Mi ( Mi(m(x;\u03b8)) m(x;\u03b8) ) Xi \u2208 Xd,\n(15)\nHere, the density \u03c0 is strictly positive. Basically, Om(\u03b8) is a regularized version of the combination of the objective functions for the continuous and discrete cases. Because \u2126[m] also encodes the dependencies between continuous and discrete variables, we can estimate its support for mixedtype data without assuming group structures of data types. The following corollary guarantees the consistency, where we define O\u2032m(\u03b8) as Om(\u03b8)\u2212 \u03c1\u03bb(\u2126[m]). Corollary 4. Assume\ni. The data density \u03c0X(\u00b7) is equal to \u03c0(\u00b7; \u03b8\u2217) for some \u03b8\u2217.\nii. The data density \u03c0X(\u00b7) and model density \u03c0(\u00b7; \u03b8) are strictly positive. \u03c0X(\u00b7) and \u03c0(\u00b7; \u03b8) is differentiable and twice-differentiable, respectively, w.r.t. continuous variables. For some \u03b8\u2217, \u03c0X(\u00b7) = \u03c0(\u00b7; \u03b8\u2217) and no other parameter value gives a density that is equal to \u03c0(\u00b7; \u03b8\u2217) almost everywhere.\niii. The expectations E\u03c0X [ \u2016 log \u03c0(x; \u03b8)\u20162 ] and E\u03c0X [ \u2016log \u03c0X(x)\u2016 2 ] are finite for any \u03b8, and\n\u03c0X(x) log \u03c0(x; \u03b8) goes to zero for any \u03b8 when \u2016x\u2016 \u2192 \u221e.\nThen O\u2032m(\u03b8) = 0 implies \u03b8 = \u03b8 \u2217.\nCor. 4 follows from Lemma 1 (Hyv\u00e4rinen & Dayan, 2005) and Lemma 2 (Lyu, 2012), which are included in Appx. A.6. Together with Thm. 2, one can estimate Markov network structures for mixed-type data in a general setting."
        },
        {
            "heading": "3.4 SPARSITY REGULARIZATION",
            "text": "By minimizing the objective function O(\u03b8) \u2208 {Oc(\u03b8), Od(\u03b8), Om(\u03b8)}, our goal is to essentially perform a model selection task, i.e., to learn of the support of \u2126 \u2208 {\u2126[c],\u2126[d],\u2126[m]}. Here, using\n`0 penalty may be computationally infeasible because it leads to a discrete optimization problem that is difficult to solve. Following previous works (Tibshirani, 1996), we adopt the `1 regularizer \u03c1\u03bb(\u2126) = \u03bb\u2016\u2126\u20161. In particular, the high-dimensional support recovery of `1 regularizer has been extensively studied in the literature; for instance, see Wainwright (2009) for variable selection and Ravikumar et al. (2008) for Gaussian graphical model selection. Although `1 regularizer induces sparsity, it may lead to bias in the resulting solution and thereby worsen the performance (Fan & Li, 2001; Breheny & Huang, 2011). This is because the `1 norm increases linearly with the absolute value of nonzero entries, which is different from `0 norm that is constant for nonzero entries. Therefore, we experiment with smoothly clipped absolute deviation (SCAD) penalty (Fan & Li, 2001), minimax concave penalty (MCP) (Zhang, 2010), and adaptive `1 penalty (Zou, 2006) in this work, which helps remedy the bias issue of `1 regularization. Specifically, SCAD and MCP penalties may be interpreted as a hybrid of `0 and `1 penalties, while adaptive `1 penalty reweighs the penalty coefficient \u03bb by the initial estimate of \u2126 without regularization. Furthermore, the support recovery of `1 penalty relies on the incoherence condition in various cases (Wainwright, 2009; Ravikumar et al., 2008; 2011), which may be a rather strong assumption in practice, whereas the SCAD and MCP penalties do not (Loh & Wainwright, 2017). Thus, we adopt the SCAD penalty according to experimental results (Fig. 7 in Appx. B). We integrate the SCAD penalties for all cases but only introduced here for brevity."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": "Setup. We conduct experiments on two sets of distributions: (1) Butterfly distributions (Morrison et al., 2017; Baptista et al., 2021) and (2) distributions from random graphs. For Butterfly distribution in the continuous setting, we have r i.i.d. pairs of random variables (Pi, Qi) defined as Pi \u223c N (0, 1) and Qi = WiPi with Wi \u223c N (0, 1) and Wi \u22a5 Pi. We replace the Gaussian distribution with the Multinomial distribution for the discrete case and mix the two different types of pairs for the mixed-type case with uniformly sampled proportion. For distributions from random graphs, we first generate a random decomposable directed acyclic graph. Then, for the continuous case, the data are sampled from nonlinear structural equation models (SEMs) with exogenous noises from an exponential distribution. We employ a multilayer perceptron (MLP) with randomly generated weights as the nonlinear function. For the discrete case, variables are generated via randomly parameterized Multinomial distributions of the variable being simulated and the discrete parents (Andrews et al., 2018). For the mixed-type case, we simulate data with the process described in Andrews et al. (2018), of which the details are included in Appx. B. Finally, we moralize all random decomposable DAGs to obtain the ground-truth Markov network structures. We use the deep kernel exponential family (DKEF) during estimation and optimize the objective function by gradient descent with the Adam optimizer. All experiments are on 12 CPU cores with 24 GB RAM.\nConsidered methods. We consider the following representative methods for comparison: (KCI) We adopt Kernel-based Conditional Independence test (KCI) (Zhang et al., 2012) with the Incremental Association Markov Blanket (IAMB) algorithm (Tsamardinos et al., 2003) to learn the Markov network structure in our settings. (GS) We denote GS as Greedy Equivalence Search (GES) (Chickering, 2002) with Generalized Score (GS). Because this procedure estimates causal structures represented by completed partially DAGs (CPDAGs), we moralize the results to obtain the Markov network structures. (SING) Sparsity Identification in Non-Gaussian distributions (SING) (Morrison et al., 2017; Baptista et al., 2021) is an algorithm designed for the estimation of Markov networks in non-Gaussian continuous distributions. It applies a transport map to estimate the data density. (GLASSO) Graphical Lasso (GLASSO) is a classical sparse penalized estimator for the inverse covariance matrix. (NPN) GLASSO with the nonparanormal transformation (Liu et al., 2009).\nResults. We first conduct comparisons in general distributions for all data types (i.e., discrete, continuous, and mixed-type) with different numbers of variables and a sample size of 1000. Among the considered\nmethods, both KCI and GS are available for the estimation of Markov network structures for general distributions with all data types. SING can only deal with continuous data and is therefore only applied in the continuous setting. We also include (semi)parametric methods (GLASSO and NPN) for baselines in the considered general settings. We use Hamming distance between the estimated graph and the ground truth graph as the metric. All results are from 5 trials with different random seeds. The missing results are either due to timeout (i.e., > 1 day) or OOM.\nFor the Butterfly distributions (Fig. 1), one can observe that KCI, GS, and our method can almost recover the true structures with all data types. At the same time, in the more complex setting (i.e., distributions from random graphs, Fig. 2), it is clear that our method outperforms others in most datasets. This suggests that, compared to baselines, our method may have more obvious advantages in more complicated scenarios. Meanwhile, the running times of KCI, GS, and SING are significantly longer than that of our method (Table. 1). Besides, SING and GS cannot scale with more than 12 and 18 variables, respectively. GLASSO and NPN are remarkably fast but fail to accurately recover the structure in the general setting. NPN performs worse than GLASSO in structure recovery, which may be due to its misaligned hypothesis of the nonparanormal transformation in the general mixed-type setting.\nWe also conduct experiments on large graphs, with {250, 500, . . . , 5000} continuous variables from Butterfly distributions. Other settings are identical to those for smaller graphs. From Fig. 3, we observe that the running time is approximately linear w.r.t. the number of variables. Besides, all experiments are conducted on CPUs while our framework could be easily deployed on GPUs. This suggests the potential of taking advantage of recent advances in computation, especially for deep models, to even further improve the scalability."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "We provide a scalable estimation framework based on regularized score matching for nonparametric Markov network structures. We first introduce necessary and sufficient conditions of conditional independence among variables in general distributions for all data types (i.e., continuous, discrete, and mixed-type) without specific assumptions on functional relations among variables, thus giving rise to the corresponding characterizations of the structure, i.e., Generalized Precision Matrix. Then, we unify all these cases under the same umbrella of the estimation framework based on regularized score matching. Appropriate penalties on the characterization matrix are introduced to promote constantly sparse entries for stable estimation. We validate our theoretical claims experimentally in various settings. Future work includes exploring the connection between Markov networks and causal graphs."
        },
        {
            "heading": "6 ACKNOWLEDGMENT",
            "text": "We thank the anonymous reviewers for their constructive comments. This project was partially supported by the National Institutes of Health (NIH) under Contract R01HL159805, by the NSFConvergence Accelerator Track-D award #2134901, by a grant from Apple Inc., a grant from KDDI Research Inc, and generous gifts from Salesforce Inc., Microsoft Research, and Amazon Research."
        },
        {
            "heading": "Appendix",
            "text": ""
        },
        {
            "heading": "Table of Contents",
            "text": ""
        },
        {
            "heading": "A Proofs 13",
            "text": "A.1 Proof of Corollary 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 A.2 Proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 A.3 Proof of Corollary 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 A.4 Proof of Theorem 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 A.5 Proof of Corollary 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 A.6 Proof of Corollary 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18"
        },
        {
            "heading": "B Experiments 20",
            "text": "B.1 Generating process for mixed-type data . . . . . . . . . . . . . . . . . . . . . . 20 B.2 Influence of the sample size . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 B.3 Influence of different penalty functions . . . . . . . . . . . . . . . . . . . . . . 22"
        },
        {
            "heading": "C Discussion 22",
            "text": "C.1 Towards nonparametric causal discovery . . . . . . . . . . . . . . . . . . . . . 22"
        },
        {
            "heading": "A PROOFS",
            "text": ""
        },
        {
            "heading": "A.1 PROOF OF COROLLARY 1",
            "text": "Corollary 1. Assume\ni. X = (X1, . . . , Xd) is a set of continuous variable.\nii. The PDFs of X are strictly positive and smooth.\niii. The characterization matrix \u2126[c] is defined according to Eq. (3).\nThen for any i 6= j, \u2126[c]i,j = 0 implies Xi \u22a5 Xj | XV\\{i,j}.\nProof. According to Eq. (3), it is clear that when \u2126[c]i,j = 0, we have \u22022 log pX \u2202xi\u2202xj\n= 0, which is a necessary and sufficient condition of xi \u22a5 xj | xV\\{i,j} for strictly positive, smooth, and continuous distributions as shown in Sec. 2.1.\nIt is worth noting that it also applies in the Gaussian case, where X \u223c N (\u00b5,\u03a3) is a Gaussian vector with mean \u00b5 and non-singular covariance \u03a3. In this case, we have\nPX(x) \u221d exp ( \u2212(x\u2212 \u00b5)>\u03a3\u22121(x\u2212 \u00b5)\n2\n) , (16)\nwhich implies \u22022 log pX \u2202xi\u2202xj = (\u03a3\u22121)2i,j , (17)\nwhere (\u03a3\u22121)i,j denotes the corresponding entry of the inverse covariance matrix. This well-known property of Gaussian distribution was also shown in Baptista et al. (2021); Drton et al. (2008). Because the inverse covariance matrix encodes the conditional independence structure when variables are from Gaussian distributions, \u2126[c] characterizes the Markov property for the Gaussian case."
        },
        {
            "heading": "A.2 PROOF OF THEOREM 1",
            "text": "Theorem 1. Denote V as a set of discrete variables and Xi, Xj \u2208 V. For brevity, denote V\\{Xi, Xj} as Z. Let {xi1, . . . , xiMi} and {xj1, . . . , xjMj} be the support of variables Xi and Xj . Denote z as any value(s) of Z. Then, Xi \u22a5\u22a5 Xj | Z if and only if, for all k \u2208 [Mi] and l \u2208 [Mj ] with k 6= 1 and l 6= 1, we have\n(logm(xi1, xj1, z)\u2212 logm(xik, xj1, z))\u2212 (logm(xi1, xjl, z)\u2212 logm(xik, xjl, z)) = 0. (4)\nProof. Sufficient condition. Without loss of generality, let us consider three discrete variables, i.e., {Xi, Xj , Z}. Let {xi1, . . . , xiMi} and {xj1, . . . , xjMj} be the support of variables Xi and Xj , respectively.\nConsider the case that the finite difference of the discrete score function of Xi w.r.t. Xj equals zero.\nWhen Xi = xi1, Xj = xj1, and differences are considered w.r.t. to xik\u2032 and xjl\u2032 , we have\n(logm(xi1, xj1, z)\u2212 logm(xik\u2032 , xj1, z)) \u2212 (logm(xi1, xjl\u2032 , z)\u2212 logm(xik\u2032 , xjl\u2032 , z)) = 0,\n(18)\nwhere m(xi1, xj1, z) is the joint PMF simplified from mXi,Xj ,Z{xi1, xj1, z}. By iterating all possible differences w.r.t. Xj , for all l in {2, . . . ,Mj}, we have\n(logm(xi1, xj1, z)\u2212 logm(xik\u2032 , xj1, z)) \u2212 (logm(xi1, xjl, z)\u2212 logm(xik\u2032 , xjl, z)) = 0.\n(19)\nDefine the discrete score function of Xi as g(xi1, xik\u2032 , \u03b3) = logm(xi1, \u03b3)\u2212 logm(xik\u2032 , \u03b3), where \u03b3 denotes other variables. Eq. 19 means g(xi1, xik\u2032 , \u03b3) doe not take the value of Xj as an argument when the LHS of Eq. 19 equals zero. As a result, Eq. 19 could be formulated as\nlogm(xi1, xj1, z) = logm(xik\u2032 , xj1, z) + g(xi1, xik\u2032 , \u03b3). (20)\nThen by iterating all possible differences w.r.t. Xi, for all k in Ixi = {2, . . . ,Mi}, we have\nlogm(xi1, xj1, z) = logm(xik, xj1, z) + g(xi1, xik, \u03b3). (21)\nBy summation, we have\n(N \u2212 1) logm(xi1, xj1, z) = \u2211 k\u2208Ixi (logm(xik, xj1, z) + g(xi1, xik, \u03b3))\n= \u2211 k\u2208Ixi logm(xik, xj1, z) + \u2211 k\u2208Ixi g(xi1, xik, \u03b3), (22)\nwhich implies that\nMi logm(xi1, xj1, z) = Mi\u2211 k=1 logm(xik, xj1, z) + \u2211 k\u2208Ixi g(xi1, xik, \u03b3),\nlogm(xi1, xj1, z) = 1\nMi Mi\u2211 k=1 logm(xik, xj1, z) + \u2211 k\u2208Ixi g(xi1, xik, \u03b3)  . (23)\nBecause \u2211Mi k=1 logm(xik, xj1, z) covers all possible values of Xi, this term does not depend on the\nspecific value of Xi. Besides, the other term \u2211 k\u2208Ixi\ng(xi1, xik, \u03b3) does not depend on Xj . It is worth noting that Xi1 could be any value of Xi w.o.l.g.. Therefore, we could see that when the finite difference of the discrete score function of Xi w.r.t. to Xj equal to zero (after some aggregation of samples), Xi \u22a5\u22a5 Xj | Z.\nNecessary condition. When Xi \u22a5\u22a5 Xj | Z, we could decompose m(xi, xj , z) as mXi|Z(xi | z)mXj |Z(xj | z)mZ(z). This implies that, for all k in {2, . . . ,Mi} and l in {2, . . . ,Mj}, we have\n(logm(xi1, xj1, z)\u2212 logm(xik, xj1, z)) \u2212 (logm(xi1, xjl, z)\u2212 logm(xik, yjl, z))\n= ( log ( mXi|Z(xi1 | z)mXj |Z(xj1 | z)mZ(z) ) \u2212 log ( mXi|Z(xik | z)mXj |Z(xj1 | z)mZ(z)\n)) \u2212 ( log ( mXi|Z(xi1 | z)mXj |Z(xjl | z)mZ(z)\n) \u2212 log ( mXi|Z(xik | z)mXj |Z(xjl | z)mZ(z)\n)) = (( logmXi|Z(xi1 | z) + logmXj |Z(xj1 | z) + logmZ(z) )\n\u2212 ( logmXi|Z(xik | z) + logmXj |Z(xj1 | z) + logmZ(z) )) \u2212 (( logmXi|Z(xi1 | z) + logmXj |Z(xjl | z) + logmZ(z) )\n\u2212 ( logmXi|Z(xik | z) + logmXj |Z(xjl | z) + logmZ(z) )) = 0.\n(24)\nTherefore, when Xi \u22a5\u22a5 Xj | Z, the finite difference of the discrete score function of Xi w.r.t. to Xj equals zero.\nThe proof is complete."
        },
        {
            "heading": "A.3 PROOF OF COROLLARY 2",
            "text": "Corollary 2. Assume\ni. X = (X1, . . . , Xd) is a set of discrete variable.\nii. The PMFs of X are strictly positive.\niii. The characterization matrix \u2126[d] is defined according to Eq. (5).\nThen for any i 6= j, \u2126[d]i,j = 0 implies Xi \u22a5 Xj | XV\\{i,j}. Proof. According to Eq. (5), we have\n\u2126 [d] i,j := EmX \u2211 k,l f [d](xi1, xik, xj1, xjl, z) 2  , (25) where f [d](xi1, xik, xj1, xjl, z) denotes the LHS of Eq. (4), i.e.,\nf [d](xi1, xik, xj1, xjl, z)\n= (logm(xi1, xj1, z)\u2212 logm(xik, xj1, z)) \u2212 (logm(xi1, xjl, z)\u2212 logm(xik, xjl, z)) .\n(26)\nThus, if \u2126[d]i,j = 0, we must have\n(logm(xi1, xj1, z)\u2212 logm(xik, xj1, z)) \u2212 (logm(xi1, xjl, z)\u2212 logm(xik, xjl, z)) = 0,\n(27)\nfor all k \u2208 [Mi] and l \u2208 [Mj ], where Mi and Mj denote the cardinalities of Xi and Xj , respectively. Based on Theorem. 1, we have Xi \u22a5\u22a5 Xj | Z. The proof is complete."
        },
        {
            "heading": "A.4 PROOF OF THEOREM 2",
            "text": "Theorem 2. Denote V as a set of mixed-type variables and Xi, Xj \u2208 V, where Xi is discrete and Xj is continuous. Let {xi1, . . . , xiMi} be the support of variables Xi. For brevity, denote\nV\\{Xi, Xj} as Z. Denote z as any value(s) of Z and xj as any value of the continuous variable Xj . Then, Xi \u22a5\u22a5 Xj | Z if and only if, for all k \u2208 [Mi] with k 6= 1, we have\n\u2202 log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) \u2202xj \u2212 \u2202 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) \u2202xj = 0. (6)\nProof. Sufficient condition. Without loss of generality, let us consider three variables, i.e., {Xi, Xj , Z}:\nxi \u2208 {xi1, . . . , xiMi} xj \u2208 R,\n(28)\nwhere we set Xi = xi as the discrete variable and Xj = xj as the continuous variable w.l.o.g. Note that we do not constraint the type of Z = z here but set Z as continuous for brevity.\nConsider the case that the finite difference of the score function of Xj w.r.t. Xi equals zero. Also, we define p as the p.d.f. and m as the p.m.f.. We first consider the difference between xi1 and xik\u2032 .\n\u2202 log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) \u2202xj \u2212 \u2202 log ( pXj ,Z|Xi(xj , z | xik\u2032)mXi(xik\u2032) ) \u2202xj = 0. (29)\nBy iterating all possible differences w.r.t. xi, for all k in Ixi = {2, . . . ,M}, we have \u2202 log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) \u2202xj \u2212 \u2202 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) \u2202xj = 0, (30)\nwhich is equivalent to \u2202 log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) \u2202xj = \u2202 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) \u2202xj . (31)\nThen by integrating on both sides w.r.t. Xj , we have log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) = log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) + Ck, (32)\nwhere Ck is a constant. We then apply a summation as follows (Mi \u2212 1) log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) = \u2211 k\u2208Ixi ( log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) + Ck ) , (33)\nwhich implies that log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) = 1\nMi Mi\u2211 k=1 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) + \u2211 k\u2208Ixi Ck  . (34) Because \u2211Mi k=1 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) covers all possible values of k, this term does not depend on the specific value of Xi. Besides, Ck does not depend on Xj . Therefore, by iterating all possible differences of Xi, we could see that when the finite difference of the score function of Xj w.r.t. Xi equals zero (after some aggregation of samples), Xi \u22a5\u22a5 Xj | Z. It is noteworthy that another \u201csymmetric\" case, where the derivative of the discrete score function of Xi w.r.t. Xj equals zero, is as follows\n\u2202 ( log (( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) \u2212 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ))) \u2202xj = 0, (35)\nwhich is equivalent to \u2202 log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) \u2202xj \u2212 \u2202 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) \u2202xj = 0. (36)\nThus, we only need to consider Eq. 36, which is the case that the finite difference of the discrete score function of Xi w.r.t. Xj equals zero.\nNecessary condition. When Xi \u22a5\u22a5 Xj | Z, we could decompose pXj ,Z|Xi(xj , z | xi1)mXi(xi1) as mXi|Z(xi1 | z)pXj |Z(xj | z)pZ(z). This implies that, for all k in {2, . . . ,Mi}, we have\n\u2202 log ( pXj ,Z|Xi(xj , z | xi1)mXi(xi1) ) \u2202xj \u2212 \u2202 log ( pXj ,Z|Xi(xj , z | xik)mXi(xik) ) \u2202xj\n= \u2202 log\n( mXi|Z(xi1 | z)pXj |Z(xj | z)pZ(z) ) \u2202xj\n\u2212 \u2202 log\n( mXi|Z(xik | z)pXj |Z(xj | z)pZ(z) ) \u2202xj\n= \u2202 ( logmXi|Z(xi1 | z) + log pXj |Z(xj | z) + log pZ(z) ) \u2202xj\n\u2212 \u2202 ( logmXi|Z(xik | z) + log pXj |Z(xj | z) + log pZ(z) ) \u2202xj\n= \u2202 log pXj |Z(xj | z) \u2202xj \u2212 \u2202 log pXj |Z(xj | z) \u2202xJ\n=0.\n(37)\nTherefore, when Xi \u22a5\u22a5 Xj | Z, the finite difference of the score function of Xj w.r.t. to Xi equal to zero.\nThe proof is complete."
        },
        {
            "heading": "A.5 PROOF OF COROLLARY 3",
            "text": "Corollary 3. Assume\ni. X = (X1, . . . , Xd) is a set of variables containing both continuous and discrete variables.\nii. For continuous variables, the PDFs are strictly positive and smooth.\niii. For discrete variables, the PMFs are strictly positive.\niv. The characterization matrix \u2126[m] is defined according to Eq. (7).\nThen for any i 6= j, \u2126[m]i,j = 0 implies Xi \u22a5 Xj | XV\\{i,j}. Proof. According to Eq. (7), we have\n\u2126 [m] i,j :=  E\u03c0X [ f [c] i,j(x) 2 ]\nif Xi \u2208 Xc, Xj \u2208 Xc E\u03c0X [\u2211 k,l f [d](xi1, xik, xj1, xjl, z) 2 ] if Xi \u2208 Xd, Xj \u2208 Xd\nE\u03c0X [\u2211 k f [m](xi, xj1, xjk, z) 2 ]\nif Xi \u2208 Xc, Xj \u2208 Xd E\u03c0X [\u2211 k f [m](xj , xi1, xik, z) 2 ] if Xi \u2208 Xd, Xj \u2208 Xc,\n(38)\nwhere Xc and Xd are the sets of continuous and discrete variables, respectively. We have already proved the first two cases (i.e., {Xi \u2208 Xc, Xj \u2208 Xc} and {Xi \u2208 Xd, Xj \u2208 Xd}) in the proofs of Cor. 1 and Cor. 2, respectively. So here we will focus on the other two cases. We start from the third case, where {Xi \u2208 Xc, Xj \u2208 Xd}. We have\nf [m](xi, xj1, xjk, z) = \u2202 log\n( pXi,Z|Xj (xi, z | xj1)mXj (xj1) ) \u2202xi\n\u2212 \u2202 log\n( pXi,Z|Xj (xi, z | xjk)mXj (xjk) ) \u2202xi .\n(39)\nThus, if \u2126[m]i,j = 0 for {Xi \u2208 Xc, Xj \u2208 Xd}, we must have \u2202 log ( pXi,Z|Xj (xi, z | xj1)mXj (xj1) ) \u2202xi\n\u2212 \u2202 log\n( pXi,Z|Xj (xi, z | xjk)mXj (xjk) ) \u2202xi = 0,\n(40)\nfor all k \u2208 [Mj ], where Mj denotes the cardinality of Xj . Thus, according to Theorem 2, we have Xi \u22a5\u22a5 Xj | Z if \u2126[m]i,j = 0 for {Xi \u2208 Xc, Xj \u2208 Xd}.\nThe similar derivation applies for the last case, where {Xi \u2208 Xd, Xj \u2208 Xc}."
        },
        {
            "heading": "A.6 PROOF OF COROLLARY 4",
            "text": "We first introduce the following lemmas and their proofs for completeness."
        },
        {
            "heading": "A.6.1 PROOF OF LEMMA 1",
            "text": "Lemma 1. [directly from Thm. 1 in (Hyv\u00e4rinen & Dayan, 2005)] Assume\ni. X = (X1, . . . , Xd) is a set of continuous variables.\nii. The data PDF pX(x) is differentiable. The model PDF p(x; \u03b8) is twice-differentiable. Both of them are strictly positive.\niii. The expectations Ex { \u2016 log p(x; \u03b8)\u20162 } and Ex { \u2016log pX(x)\u2016 2 } are finite for any \u03b8, and\npX(x) log p(x; \u03b8) goes to zero for any \u03b8 when \u2016x\u2016 \u2192 \u221e.\nThen Eq. (8) is equivalent to\nOc(\u03b8) = \u222b x\u2208Rn pX(x) d\u2211 i=1 [ 1 2 \u2016\u2207xi log p(x; \u03b8)\u20162 +Hxi(log p(x; \u03b8)) ] dx + \u03c1\u03bb(\u2126 [c]). (41)\nProof. Based on Eq. (8), we have\nOc(\u03b8) = 1\n2\n\u222b px(x)|\u2207x log p(x; \u03b8)\u2212\u2207x log px(x)|2dx + \u03c1\u03bb(\u2126[c]), (42)\nwhere \u03c1\u03bb(\u00b7) denotes a sparsity penalty function and \u03bb is the penalty parameter. This is equivalent to\nOc(\u03b8) = 1\n2\n\u222b pX(x) ( \u2016\u2207x log p(x; \u03b8)\u20162 + \u2016\u2207x log pX(x)\u20162\n\u22122 (\u2207x log pX(x))> (\u2207x log p(x; \u03b8)) ) dx + \u03c1\u03bb(\u2126 [c]).\n(43)\nWe first consider the integral for the following part \u2212 \u222b pX(x) (\u2207x log pX(x))> (\u2207x log p(x; \u03b8)) dx, (44)\nby which we could obtain \u2212 \u2211 i \u222b pX(x) (\u2207xi log pX(x)) (\u2207xi log p(x; \u03b8)) dx\n=\u2212 \u2211 i \u222b (\u2207xipX(x)) (\u2207xi log p(x; \u03b8)) dx\n=\u2212 \u2211 i \u222b [\u222b \u2207xipX(x) (\u2207xi log p(x; \u03b8)) dx1 ] d(x1, . . . , xd)\n(?) = \u2212 \u2211 i \u222b [ lim a\u2192\u221e,b\u2192\u2212\u221e [pX (a, x2, . . . , xd)\u2207xi log p(a, x2, . . . , xd, \u03b8)\n\u2212pX (b, x2, . . . , xn)\u2207xi log p(b, x2, . . . , xd, \u03b8)] \u2212 \u222b \u22022 log pX \u2202xi2 pX(x)dx1 ] d(x2, . . . , xd),\n(45)\nwhere Eq. (?) is because if we assume f and g are both differential, we have\n\u2202f(x)g(x)\n\u2202xi = f(x)\n\u2202g(x)\n\u2202x1 + g(x)\n\u2202f(x)\n\u2202x1 . (46)\nFor i 6= 1, the cases follow similarly. Because we assume pX(x) log p(x; \u03b8) goes to zero for any \u03b8 when \u2016x\u2016 \u2192 \u221e, the limit is zero. Thus, we have proven that\n\u2212 \u2211 i \u222b pX(x)\u2207xi log pX(x) (\u2207xi log p(x; \u03b8)) dx = \u2211 i \u222b \u22022 log pX \u2202xi2 pX(x)dx, (47)\nBy injecting it into Eq. (43), we obtain\nOc(\u03b8) = \u222b pX(x) [ 1\n2 \u2016\u2207x log p(x; \u03b8)\u20162 +\n1 2 \u2016\u2207x log pX(x)\u20162 + tr (Hx(log p(x; \u03b8)))\n] dx\n+ \u03c1\u03bb(\u2126 [c]).\n(48)\nBecause 12\u2016\u2207x log pX(x)\u2016 2 does not depend on \u03b8, we could ignore it. Then we have\nOc(\u03b8) = \u222b d\u2211 i=1 [ 1 2 \u2016\u2207xi log p(x; \u03b8)\u20162 +Hxi(log p(x; \u03b8)) ] dx + \u03c1\u03bb(\u2126 [c]). (49)\nThus, the proof is complete."
        },
        {
            "heading": "A.6.2 PROOF OF LEMMA 2",
            "text": "Lemma 2. [directly from (Lyu, 2012)] Assume\ni. X = (X1, . . . , Xd) is a set of discrete variables.\nii. The data PMF mX(x) and the model PMF m(x; \u03b8) are strictly positive.\nThen Eq. (12) is equivalent to\nOd(\u03b8) = \u2211 x mX(x) d\u2211 i=1 [( Mi(m(x; \u03b8)) m(x; \u03b8) )2 \u2212 2Mi ( Mi(m(x; \u03b8)) m(x; \u03b8) )] + \u03c1\u03bb(\u2126 [d]). (50)\nProof. Based on Eq. (12), we have\nOd(\u03b8) = \u2211 x mX(x) \u2225\u2225\u2225\u2225M(m(x; \u03b8))m(x; \u03b8) \u2212 M(mX(x))mX(x) \u2225\u2225\u2225\u22252 + \u03c1\u03bb(\u2126[d]), (51)\nwhich implies\nOd(\u03b8) = \u2211 x mX(x) d\u2211 i=1 \u2225\u2225\u2225\u2225Mi(m(x; \u03b8))m(x; \u03b8) \u2212 Mi(mX(x))mX(x) \u2225\u2225\u2225\u22252 + \u03c1\u03bb(\u2126[d])\n(?) = \u2211 x mX(x) d\u2211 i=1 [( Mi(m(x; \u03b8)) m(x; \u03b8) )2 \u2212 2Mi ( Mi(m(x; \u03b8)) m(x; \u03b8) )] + \u03c1\u03bb(\u2126 [d]),\n(52)\nwhere Eq. (?) is due to the fact that ( Mi(mX(x)) mX(x) )2 does not take \u03b8 as an argument.\nThe proof is complete.\nThen the corollary follows from these lemmas, which is included as follows.\nCorollary 4. Assume\ni. The data density \u03c0X(\u00b7) is equal to \u03c0(\u00b7; \u03b8\u2217) for some \u03b8\u2217.\nii. The data density \u03c0X(\u00b7) and model density \u03c0(\u00b7; \u03b8) are strictly positive. \u03c0X(\u00b7) and \u03c0(\u00b7; \u03b8) is differentiable and twice-differentiable, respectively, w.r.t. continuous variables. For some \u03b8\u2217, \u03c0X(\u00b7) = \u03c0(\u00b7; \u03b8\u2217) and no other parameter value gives a density that is equal to \u03c0(\u00b7; \u03b8\u2217) almost everywhere.\niii. The expectations E\u03c0X [ \u2016 log \u03c0(x; \u03b8)\u20162 ] and E\u03c0X [ \u2016log \u03c0X(x)\u2016 2 ] are finite for any \u03b8, and\n\u03c0X(x) log \u03c0(x; \u03b8) goes to zero for any \u03b8 when \u2016x\u2016 \u2192 \u221e.\nThen O\u2032m(\u03b8) = 0 implies \u03b8 = \u03b8 \u2217. Proof. The O\u2032m(\u03b8) is defined as follows\nO\u2032m(\u03b8) = E\u03c0X [\u2211 i si(x; \u03b8) ] , (53)\nwhere\nsi(x; \u03b8) :=  1 2\u2016\u2207xi log \u03c0(x; \u03b8)\u2016\n2 +Hxi(log \u03c0(x; \u03b8)) Xi \u2208 Xc 1 2 ( Mi(m(x;\u03b8)) m(x;\u03b8) )2 \u2212Mi ( Mi(m(x;\u03b8)) m(x;\u03b8) ) Xi \u2208 Xd,\n(54)\nwhere the probability function \u03c0 is strictly positive. According to Lemma 1 and Lemma 2, both cases of si(\u00b7; \u03b8) in O\u2032m(\u03b8) are equivalent to 12E\u03c0 [\u2225\u2225\u2225 g(\u03c0(\u00b7;\u03b8))\u03c0(\u00b7;\u03b8) \u2212 g(\u03c0(\u00b7))\u03c0(\u00b7) \u2225\u2225\u22252], where g denotes the gradient\noperator for continuous variables or the marginalization operator for discrete variables. IfO\u2032m(\u03b8) = 0, si(x; \u03b8) must equal to zero for any i. Because of Brook\u2019s Lemma (Brook, 1964), which is also included in Lyu (2012) as Lemma 3, the marginalization operatorM is complete (Defn. 1). Thus, for the discrete variables, we could replace the gradient in the continuous score function with the marginalization operator while preserving local consistency as that for the continuous variables, which is shown by Theorem 2 in Hyv\u00e4rinen & Dayan (2005)."
        },
        {
            "heading": "B EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "B.1 GENERATING PROCESS FOR MIXED-TYPE DATA",
            "text": "For the mixed-type case, we simulate data with the process described in Andrews et al. (2018), of which the details are included here for completeness. After generating a random decomposable DAG, we first assign a data type (continuous or discrete) to each variable with equal probability. For variables without parents in the ground-truth graph, we sample their values from Gaussian and Multinomial distributions, respectively. Then for each continuous variable, we create a temporary discretized version by applying equal frequency binning. The number of bins is uniformly chosen between and including 2 and 5. The cardinality of each discrete variable is uniformly chosen between and including 2 and 4. The randomly generated decomposable DAGs are moralized to obtain the ground-truth Markov network structures.\nNext, for variables with parents in the ground-truth graph, we sample the values of them as follows. For continuous variables, we first adopt partitioning according to its discrete variables. Then the values of these continuous variables are generated by randomly parameterizing the coefficients of a regression for each partition. For discrete variables, we generate the values of them by randomly parameterizing Multinomial distributions of the variables of the target variable and its discrete parents (temporary or not). After the simulation, all temporary discretized variables are removed.\nB.2 INFLUENCE OF THE SAMPLE SIZE\nIn this section, we report additional experimental results with a larger sample size. We conduct experiments for all settings (continuous, discrete, and mixed-type) with different numbers of variables (d \u2208 {4, 6, . . . , 20}) and 10000 samples. The results are summarized in Fig. 4, Fig. 5, and Fig. 6. One can observe that both KCI and GS fail in all settings, indicating that they cannot scale well with large sample sizes. It is because the complexities of KCI and GS grow cubically in the number of samples, which is one of the motivations for the development of our method. Besides, SING cannot\nscale with more than 6 variables because of OOM. At the same time, our method works well across all datasets without any scalability issues. Together with the better performance illustrated in Sec. 4 (note that one can even go beyond 5000 variables, e.g., it takes 7725 seconds for 10,000 variables in our setting), we believe the potential of our method is not only theoretically exciting but also empirically clear in both consistency and scalability.\nB.3 INFLUENCE OF DIFFERENT PENALTY FUNCTIONS\nTo explore the effect of different regularization functions, we compare the results of our method with different sparsity penalties, which are shown in Fig. 7. The experiments are conducted on Butterfly distributions with the number of continuous variables ranging from 4 to 20 and a sample size of 1000. One could observe that SCAD and MCP outperform other penalties, while SCAD performs slightly better than MCP in general. Adaptive `1 (Zou, 2006) also illustrates its advantage compared to the original `1 penalty. This suggests the importance of appropriate penalty functions."
        },
        {
            "heading": "C DISCUSSION",
            "text": ""
        },
        {
            "heading": "C.1 TOWARDS NONPARAMETRIC CAUSAL DISCOVERY",
            "text": "In this section, we briefly discuss the implication of our proposed Markov network estimation method in causal discovery, of which the goal is to learn graphical models with causal interpretations.\nThe major classes of approaches for causal discovery are constraint-based approaches that utilize conditional independence tests and score-based approaches that optimize a specific score function. Among them, PC (Spirtes & Glymour, 1991) with kernel-based conditional independence test (Zhang et al., 2012) and GES (Chickering, 2002) with generalized score (Huang et al., 2018) are able to handle nonparametric cases with assumptions such as causal sufficiency. Both of these approaches rely on kernel methods whose computational complexity is cubic w.r.t. the number of samples. Therefore, the running time could be long if the sample size is large. Furthermore, when the number of variables is large, the search procedure may involve computing the kernel-based conditional independence test or score function many times, which therefore may also increase the running time.\nAs shown by Loh & B\u00fchlmann (2014); Ng et al. (2021) in the linear Gaussian case, the Markov network (i.e., the support of the inverse covariance matrix of the distribution) is guaranteed to be the super-structure of the ground truth directed acyclic graph (DAG) under a specific type of faithfulness assumption. That is, the super-structure contains all edges of the true DAG. Using this idea, they showed that the Markov network may be used to restrict the search space of score-based approaches for causal discovery, which improves the scalability. Their works focus only on the linear case and adopt classical methods like graphical Lasso (Friedman et al., 2008) to estimate the Markov network. In this work, the nonparametric Markov network estimated by our proposed procedure could potentially be used as a super-structure to restrict the search space for nonparametric causal discovery methods, i.e., (kernel-based) PC and GES. Similar to (Loh & B\u00fchlmann, 2014; Ng et al., 2021), this may help reduce the running time and improve the scalability of these methods."
        }
    ],
    "year": 2023
}