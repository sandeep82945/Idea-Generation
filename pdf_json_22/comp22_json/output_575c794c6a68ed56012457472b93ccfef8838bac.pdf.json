{
    "abstractText": "Deep Neural Networks (DNN) models have achieved acceptable performance in sentiment prediction of written text. However, the output of these machine learning (ML) models cannot be natively interpreted. In this paper, we study how the sentiment polarity predictions by DNNs can be explained and compare them to humans\u2019 explanations. We crowdsource a corpus of Personal Narratives and ask human judges to annotate them with polarity and select the corresponding token chunks the Emotion Carriers (EC) that convey narrators\u2019 emotions in the text. The interpretations of ML neural models are carried out through Integrated Gradients method and we compare them with human annotators\u2019 interpretations. The results of our comparative analysis indicate that while the ML model mostly focuses on the explicit appearance of emotions-laden words (e.g. happy, frustrated), the human annotator predominantly focuses the attention on the manifestation of emotions through ECs that denote events, persons, and objects which activate narrator\u2019s emotional state.",
    "authors": [
        {
            "affiliations": [],
            "name": "Seyed Mahed Mousavi"
        },
        {
            "affiliations": [],
            "name": "Gabriel Roccabruna"
        },
        {
            "affiliations": [],
            "name": "Aniruddha Tammewar"
        },
        {
            "affiliations": [],
            "name": "Steve Azzolin"
        },
        {
            "affiliations": [],
            "name": "Giuseppe Riccardi"
        }
    ],
    "id": "SP:20f739e55b77ae144481631cee8fb43d49b38667",
    "references": [
        {
            "authors": [
                "Acheampong Francisca Adoma",
                "Nunoo-Mensah Henry",
                "Wenyu Chen"
            ],
            "title": "Comparative analyses of bert, roberta, distilbert, and xlnet for text-based emo",
            "year": 2020
        },
        {
            "authors": [
                "Takuya Akiba",
                "Shotaro Sano",
                "Toshihiko Yanase",
                "Takeru Ohta",
                "Masanori Koyama."
            ],
            "title": "Optuna: A nextgeneration hyperparameter optimization framework",
            "venue": "Proceedings of the 25rd ACM SIGKDD International Conference on Knowledge Discovery and Data",
            "year": 2019
        },
        {
            "authors": [
                "Luca Bacco",
                "Andrea Cimino",
                "Felice Dell\u2019Orletta",
                "Mario Merone"
            ],
            "title": "Extractive summarization for explainable sentiment analysis using transformers",
            "venue": "DeepOntoNLP/X-SENTIMENT@ESWC",
            "year": 2021
        },
        {
            "authors": [
                "Francesco Barbieri",
                "Valerio Basile",
                "Danilo Croce",
                "Malvina Nissim",
                "Nicole Novielli",
                "Viviana Patti."
            ],
            "title": "Overview of the evalita 2016 sentiment polarity classification task",
            "venue": "Proceedings of third Italian conference on computational linguistics (CLiC-it 2016)",
            "year": 2016
        },
        {
            "authors": [
                "Sebastian P. Bayerl",
                "Aniruddha Tammewar",
                "Korbinian Riedhammer",
                "Giuseppe Riccardi."
            ],
            "title": "Detecting emotion carriers by combining acoustic and lexical representations",
            "venue": "IEEE Automatic Speech Recognition and Understanding Workshop, ASRU",
            "year": 2021
        },
        {
            "authors": [
                "Francesco Bodria",
                "Andr\u00e9 Panisson",
                "Alan Perotti",
                "Simone Piaggesi."
            ],
            "title": "Explainability methods for natural language processing: Applications to sentiment analysis",
            "venue": "SEBD.",
            "year": 2020
        },
        {
            "authors": [
                "Laura Ana Maria Bostan",
                "Evgeny Kim",
                "Roman Klinger."
            ],
            "title": "GoodNewsEveryone: A corpus of news headlines annotated with emotions, semantic roles, and reader perception",
            "venue": "Proceedings of the 12th Language Resources and Evaluation Confer-",
            "year": 2020
        },
        {
            "authors": [
                "Harry Bunt",
                "Jan Alexandersson",
                "Jean Carletta",
                "JaeWoong Choe",
                "Alex Chengyu Fang",
                "Koiti Hasida",
                "Kiyong Lee",
                "Volha Petukhova",
                "Andrei Popescu-Belis",
                "Laurent Romary"
            ],
            "title": "Towards an iso standard for dialogue act annotation",
            "year": 2010
        },
        {
            "authors": [
                "Samuel Carton",
                "Qiaozhu Mei",
                "Paul Resnick."
            ],
            "title": "Extractive adversarial networks: High-recall explanations for identifying personal attacks in social media posts",
            "venue": "EMNLP.",
            "year": 2018
        },
        {
            "authors": [
                "Ying Chen",
                "Wenjun Hou",
                "Xiyao Cheng",
                "Shoushan Li."
            ],
            "title": "Joint learning for emotion classification and emotion cause detection",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 646\u2013651.",
            "year": 2018
        },
        {
            "authors": [
                "Marina Danilevsky",
                "Kun Qian",
                "Ranit Aharonov",
                "Yannis Katsis",
                "Ban Kawas",
                "Prithviraj Sen"
            ],
            "title": "A survey of the state of explainable ai for natural language processing",
            "venue": "In Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association",
            "year": 2020
        },
        {
            "authors": [
                "Zixiang Ding",
                "Rui Xia",
                "Jianfei Yu."
            ],
            "title": "Ecpe-2d: emotion-cause pair extraction based on joint twodimensional representation, interaction and prediction",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
            "year": 2020
        },
        {
            "authors": [
                "Markus Eberts",
                "Adrian Ulges."
            ],
            "title": "Span-based joint entity and relation extraction with transformer pre-training",
            "venue": "ECAI 2020, pages 2006\u20132013. IOS Press.",
            "year": 2020
        },
        {
            "authors": [
                "Joseph L Fleiss."
            ],
            "title": "Measuring nominal scale agreement among many raters",
            "venue": "Psychological bulletin, 76(5):378.",
            "year": 1971
        },
        {
            "authors": [
                "Lin Gui",
                "Dongyin Wu",
                "Ruifeng Xu",
                "Qin Lu",
                "Yu Zhou."
            ],
            "title": "Event-driven emotion cause extraction with corpus construction",
            "venue": "EMNLP.",
            "year": 2016
        },
        {
            "authors": [
                "Shirley Hayati",
                "Dongyeop Kang",
                "Lyle Ungar."
            ],
            "title": "Does bert learn as humans perceive? understanding linguistic styles through lexica",
            "venue": "pages 6323\u20136331.",
            "year": 2021
        },
        {
            "authors": [
                "Hohyun Hwang",
                "Younghoon Lee."
            ],
            "title": "Semisupervised learning based on auto-generated lexicon using xai in sentiment analysis",
            "venue": "RANLP.",
            "year": 2021
        },
        {
            "authors": [
                "Narine Kokhlikyan",
                "Vivek Miglani",
                "Miguel Martin",
                "Edward Wang",
                "Bilal Alsallakh",
                "Jonathan Reynolds",
                "Alexander Melnikov",
                "Natalia Kliushkina",
                "Carlos Araya",
                "Siqi Yan",
                "Orion Reblitz-Richardson"
            ],
            "title": "Captum: A unified and generic model interpretability",
            "year": 2020
        },
        {
            "authors": [
                "Taku Kudo",
                "John Richardson."
            ],
            "title": "Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System",
            "year": 2018
        },
        {
            "authors": [
                "Xiangju Li",
                "Wei Gao",
                "Shi Feng",
                "Daling Wang",
                "Shafiq Joty."
            ],
            "title": "Span-level emotion cause analysis by bert-based graph attention network",
            "venue": "Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pages",
            "year": 2021
        },
        {
            "authors": [
                "Xiangju Li",
                "Wei Gao",
                "Shi Feng",
                "Yifei Zhang",
                "Daling Wang."
            ],
            "title": "Boundary detection with bert for span-level emotion cause analysis",
            "venue": "Findings of the Association for Computational Linguistics: ACLIJCNLP 2021, pages 676\u2013682.",
            "year": 2021
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov"
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "year": 2019
        },
        {
            "authors": [
                "Seyed Mahed Mousavi",
                "Alessandra Cervone",
                "Morena Danieli",
                "Giuseppe Riccardi."
            ],
            "title": "Would you like to tell me more? generating a corpus of psychotherapy dialogues",
            "venue": "Proceedings of the Second Workshop on Natural Language Processing for Med-",
            "year": 2021
        },
        {
            "authors": [
                "Laura Ana Maria Oberl\u00e4nder",
                "Roman Klinger."
            ],
            "title": "Token sequence labeling vs",
            "venue": "clause classification for english emotion stimulus detection. In Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics, pages 58\u201370.",
            "year": 2020
        },
        {
            "authors": [
                "Desmond C. Ong",
                "Zhengxuan Wu",
                "Zhi-Xuan Tan",
                "Marianne Reddan",
                "Isabella Kahhale",
                "Alison Mattek",
                "Jamil Zaki."
            ],
            "title": "Modeling emotion in complex stories: The stanford emotional narratives dataset",
            "venue": "IEEE Transactions on Affective Computing, 12(3):579\u2013",
            "year": 2021
        },
        {
            "authors": [
                "Marco Polignano",
                "Pierpaolo Basile",
                "Marco de Gemmis",
                "Giovanni Semeraro",
                "Valerio Basile."
            ],
            "title": "AlBERTo: Italian BERT Language Understanding Model for NLP Challenging Tasks Based on Tweets",
            "venue": "Proceedings of the Sixth Italian Conference on",
            "year": 2019
        },
        {
            "authors": [
                "Sahana Ramnath",
                "Preksha Nema",
                "Deep Sahni",
                "Mitesh M. Khapra."
            ],
            "title": "Towards interpreting BERT for reading comprehension based QA",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages",
            "year": 2020
        },
        {
            "authors": [
                "Eva-Maria Rathner",
                "Yannik Terhorst",
                "Nicholas Cummins",
                "Bj\u00f6rn Schuller",
                "Harald Baumeister."
            ],
            "title": "State of mind: Classification through self-reported affect and word use in speech",
            "venue": "Proc. Interspeech 2018, pages 267\u2013271.",
            "year": 2018
        },
        {
            "authors": [
                "Marco Tulio Ribeiro",
                "Sameer Singh",
                "Carlos Guestrin."
            ],
            "title": "Model-agnostic interpretability of machine learning",
            "venue": "arXiv preprint arXiv:1606.05386.",
            "year": 2016
        },
        {
            "authors": [
                "Gabriel Roccabruna",
                "Alessandra Cervone",
                "Giuseppe Riccardi."
            ],
            "title": "Multifunctional iso standard dialogue act tagging in italian",
            "venue": "Seventh Italian Conference on Computational Linguistics (CLiC-it).",
            "year": 2020
        },
        {
            "authors": [
                "Qian",
                "Zhao Ren",
                "Maximilian Schmitt",
                "Panagiotis Tzirakis",
                "Stefanos Zafeiriou"
            ],
            "title": "The interspeech",
            "year": 2018
        },
        {
            "authors": [
                "Lukas Stappen",
                "Nicholas Cummins",
                "Eva-Maria Me\u00dfner",
                "Harald Baumeister",
                "Judith Dineley",
                "Bj\u00f6rn Schuller."
            ],
            "title": "Context modelling using hierarchical attention networks for sentiment and selfassessed emotion detection in spoken narratives",
            "venue": "In",
            "year": 2019
        },
        {
            "authors": [
                "Mukund Sundararajan",
                "Ankur Taly",
                "Qiqi Yan"
            ],
            "title": "Axiomatic attribution for deep networks",
            "year": 2017
        },
        {
            "authors": [
                "Pyry Takala",
                "Pekka Malo",
                "Ankur Sinha",
                "Oskar Ahlgren."
            ],
            "title": "Gold-standard for topic-specific sentiment analysis of economic texts",
            "venue": "LREC.",
            "year": 2014
        },
        {
            "authors": [
                "Sakirin Tam",
                "Rachid Ben Said",
                "\u00d6 \u00d6zg\u00fcr Tanri\u00f6ver."
            ],
            "title": "A convbilstm deep learning model-based approach for twitter sentiment classification",
            "venue": "IEEE Access, 9:41283\u201341293.",
            "year": 2021
        },
        {
            "authors": [
                "Aniruddha Tammewar",
                "Alessandra Cervone",
                "Eva-Maria Messner",
                "Giuseppe Riccardi."
            ],
            "title": "Modeling User Context for Valence Prediction from Narratives",
            "venue": "Proc. Interspeech 2019, pages 3252\u20133256.",
            "year": 2019
        },
        {
            "authors": [
                "Aniruddha Tammewar",
                "Alessandra Cervone",
                "Eva-Maria Messner",
                "Giuseppe Riccardi."
            ],
            "title": "Annotation of emotion carriers in personal narratives",
            "venue": "Proceedings of the 12th Language Resources and Evaluation Conference, pages 1517\u20131525.",
            "year": 2020
        },
        {
            "authors": [
                "Aniruddha Tammewar",
                "Alessandra Cervone",
                "Giuseppe Riccardi."
            ],
            "title": "Emotion Carrier Recognition from Personal Narratives",
            "venue": "Proc. Interspeech 2021, pages 2501\u20132505.",
            "year": 2021
        },
        {
            "authors": [
                "Tan Thongtan",
                "Tanasanee Phienthrakul."
            ],
            "title": "Sentiment classification using document embeddings trained with cosine similarity",
            "venue": "ACL.",
            "year": 2019
        },
        {
            "authors": [
                "Juan Manuel Mayor Torres",
                "Mirco Ravanelli",
                "Sara E. Medina-DeVilliers",
                "Matthew Daniel Lerner",
                "Giuseppe Riccardi."
            ],
            "title": "Interpretable sincnet-based deep learning for emotion recognition from eeg brain activity",
            "venue": "2021 43rd Annual International Conference",
            "year": 2021
        },
        {
            "authors": [
                "Elsbeth Turcan",
                "Shuai Wang",
                "Rishita Anubhai",
                "Kasturi Bhattacharjee",
                "Yaser Al-Onaizan",
                "Smaranda Muresan."
            ],
            "title": "Multi-task learning and adapted knowledge models for emotion-cause extraction",
            "venue": "arXiv e-prints, pages arXiv\u20132106.",
            "year": 2021
        },
        {
            "authors": [
                "Rui Xia",
                "Zixiang Ding."
            ],
            "title": "Emotion-cause pair extraction: A new task to emotion analysis in texts",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1003\u2013 1012.",
            "year": 2019
        },
        {
            "authors": [
                "Qizhe Xie",
                "Zihang Dai",
                "Eduard Hovy",
                "Thang Luong",
                "Quoc Le."
            ],
            "title": "Unsupervised data augmentation for consistency training",
            "venue": "Advances in Neural Information Processing Systems, 33:6256\u20136268.",
            "year": 2020
        },
        {
            "authors": [
                "Yang Yang",
                "Deyu Zhou",
                "Yulan He",
                "Meng Zhang."
            ],
            "title": "Interpretable relevant emotion ranking with event-driven attention",
            "venue": "EMNLP.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis, pages 62 - 70\nMay 26, 2022 c\u00a92022 Association for Computational Linguistics"
        },
        {
            "heading": "1 Introduction",
            "text": "Neural data-driven models have managed to perform comparably well in various tasks related to natural language processing (Eberts and Ulges, 2020; Adoma et al., 2020). Nevertheless, the definition and the training processes of such models have made their decision non-natively interpretable. Several studies and experiments have been conducted to address this issue and explain the decision outputs of such models in various tasks such as emotion prediction (Yang et al., 2019), question answering (Ramnath et al., 2020), the classification of linguistic styles (Hayati et al., 2021), and lexicon-based sentiment prediction (Hwang and Lee, 2021).\nSentiment analysis is a well-established field of research that aims to extract sentiment and its\naspects in a written text. Its performances have reached acceptable levels in different domains such as product reviews (Xie et al., 2020), movie reviews (Thongtan and Phienthrakul, 2019), social media (Tam et al., 2021), financial news (Takala et al., 2014), and Personal Narratives (PN) which are recollections of real-life events that are experienced by the narrator (Tammewar et al., 2019).\nRecently, a deeper understanding of the expressed sentiment and emotion has gained growing research interest (Tammewar et al., 2020, 2021; Bayerl et al., 2021; Ding et al., 2020). These works focus on a more fine-grained analysis on the expressed sentiment/emotion by identifying the Emotion Carriers (entities or actions that explain, cause or carry the emotion). The concept of Emotion Carriers (EC) was first introduced by Tammewar et al. (2020) for German PNs. In this genre of text, the identification of ECs may help in better understanding the emotional state of the narrator and what has caused distress (Tammewar et al., 2021; Bayerl et al., 2021).\nIn this work, we address the problem of analyzing and comparing the text chunks used by machines and humans when predicting the sentiment polarity of text documents. For this study we have selected the Personal Narrative genre since it is rich with entities and relations which are sparsely distributed. We identify the tokens that contribute to the model\u2019s prediction according to their attributions given by Integrated Gradients (Sundarara-\n62\njan et al., 2017), an Explainable-AI technique, and compare them with the tokens tagged as ECs by the human annotator. Our comparative analysis shows the human annotator identifies the tokens that explain an event or its participants as the carrier of emotions and sentiments, which clearly convey the activation of the emotional state in the narrator, even though they are not explicitly manifesting a sentiment. Meanwhile, the DNN model bases its decision mostly on a limited set of tokens which belong to the category of emotion-laden words (see Figure 1 for an example).\nWe summarize our contribution as follows:\n\u2022 The annotation of a dataset of Personal Narratives to obtain the sentiment polarity, and the Emotion Carriers at the Functional Unit (Bunt et al., 2010) level to take into account the communicative functions. This is in contrast with traditional annotation at the document or sentence level.\n\u2022 The evaluation of the annotation results and training a sentiment prediction model based on the AlBERTo architecture (Polignano et al., 2019) using the annotated data, as well as a baseline architecture for the task of Emotion Carrier Detection.\n\u2022 The study of the tokens contributing to the model\u2019s prediction of sentiment and comparing them with the Emotion Carriers identified by the human annotator, and the contribution of the Emotion Carriers in the prediction of the model by their influence on the output confidence score."
        },
        {
            "heading": "2 Literature Review",
            "text": "AI Explainability There have been several interesting works to address the unexplainability of neural architectures. Danilevsky et al. (2020) conducted a survey study on explainable AI (XAI) in natural language processing, summarizing the various XAI methods used by researchers. Bodria et al. (2020) proposed an attention model to investigate the words that contribute to the sentiment prediction, by adding an additional attention layer on top of the BERT architecture to fuse the token embeddings in one vector used to compute the prediction. Bacco et al. (2021) used the attention weights technique to extract summaries of reviews to explain the sentiment prediction of a Transformer-based\nmodel, by using a simplified model with 2 layers and one attention head per layer. Torres et al. (2021) designed a deep neural network with an interpretable decision process to recognize emotions from the Electroencephalography (EEG) signals.\nWhile the approaches based on attention weights require a change in the architecture of the model, LIME (Local Model-Agnostic Explanations) (Ribeiro et al., 2016) and the Integrated Gradients technique (Sundararajan et al., 2017) can be applied to any model without changing the architecture. Using LIME, Hwang and Lee (2021) extracted a sentiment lexicon used as a weak classifier to categorize unseen examples to augment the initial training set. Similarly, Carton et al. (2018) used LIME and hard-attention to extract spans of text that convey personal attacks. Furthermore, Hayati et al. (2021) used the Integrated Gradients to compare most relevant tokens for the human and the machine in predicting the linguistic style of a text.\nEmotion & Sentiment Analysis An approach to perform fine-grained analysis on the expressed emotion in the text is the task of emotion cause extraction (Chen et al., 2018; Xia and Ding, 2019; Ding et al., 2020; Gui et al., 2016). The aim of this task is to identify the explicit or implicit expressions of emotions in the text, as well as the corresponding causes or triggers of the emotion as a span in the text (Turcan et al., 2021; Li et al., 2021a,b). However, most of the works on this task have focused on datasets of news (Bostan et al., 2020; Gui et al., 2016) and microblogs (Oberl\u00e4nder and Klinger, 2020), which are very different from Personal Narratives.\nUnderstanding of Personal Narratives (PN) is a comparatively new domain and is gaining growing attention in the research community (Stappen et al., 2019; Tammewar et al., 2019; Schuller et al., 2018; Rathner et al., 2018; Ong et al., 2021). Compared to the mentioned genres of text, PNs have a different and more complex structure as they are personal recollection of real-life events and may involve multiple characters, and several sub-events (Mousavi et al., 2021; Tammewar et al., 2019). A stream of works has been carried out on the fine-grained emotion analysis of PNs that tries to capture the semantics of the emotions through Emotion Carriers (EC), including the annotation of ECs (Tammewar et al., 2020) as well as the automatic recognition of the ECs (Tammewar et al., 2021; Bayerl et al.,\n2021). In these works, every PN is associated with a positive or negative emotion and the ECs are defined as the persons, objects or actions that explain the emotion felt by the narrator, after recollecting the event."
        },
        {
            "heading": "3 Data Collection & Annotation",
            "text": "We used an extended version of the dataset of PNs from users receiving Cognitive Behavioural Therapy to handle their distress more effectively, introduced previously by Mousavi et al. (2021). Each PN encompasses a real-life personal event that has activated the narrator\u2019s emotional state, the participants of the event as well as the details about the user\u2019s thought and emotions. During two periods of 3 months, we collected 481 personal narratives written by 45 Italian speaker users, with the average length of 51 tokens per narrative and overall dictionary size of 5875 tokens."
        },
        {
            "heading": "3.1 Annotation of Sentiment & Emotion Carriers",
            "text": "We annotate the obtained dataset of PNs, with the sentiment and the Emotion Carrier tokens for each narrative1. The mentioned studies on identifying ECs (Tammewar et al., 2020; Bayerl et al., 2021) focus on the identification of emotion and the corresponding ECs at the narrative level. However, in this work we conduct a deeper analysis and identify the emotion and the corresponding ECs for each Functional Unit of the PN, making it possible to capture the emotion changes of the narrator throughout the narrative. A Functional Unit (FU) is defined as a minimal contiguous span in the text that represents coherent communicative intention (Bunt et al., 2010). We segment each PN to its FUs, using a RoBERTa-based model2 (Liu et al., 2019), fine-tuned on ISO standard Dialogue Act tagging in Italian (Roccabruna et al., 2020) to jointly perform FU segmentation and Dialogue Act tagging. As the result, we obtained 4273 FUs to be annotated (approximately equal to 9 FUs for each narrative on average).\nWe recruited 3 Italian native speaker annotators from a pool of graduate students based on their research interests and previous experience with data annotation. The annotators were asked to annotate\n1We are currently applying for further funds to anonymize the corpus and publish a version of the corpus that respects users\u2019 privacy and deontological requirements.\n2https://github.com/ musixmatchresearch/umberto\nthe sentiment polarity of the FU using a 5-point bipolar scale from -2 (unpleasant) to 2 (pleasant) with 0 representing neutral. The annotators were asked to adopt the point of view of the narrator. In the cases where the sentiment of the FU was not clear by its content, the annotators were asked to consider the adjacent FUs as context for better understanding.\nFor the FUs with an assigned sentiment polarity of positive or negative, the annotators were further asked to select the ECs that convey and carry the annotated sentiment of the narrator in the corresponding FU. Considering the characteristics of PNs as the recollection of real-life events, we focused on the manifestations of the sentiment in terms of persons, objects, places, organizations or actions that affected the narrator\u2019s emotional state. Therefore, we provided the annotators with a list of noun-chunks and verb-chunks in the FU as EC-candidate spans to select from, and excluded the explicit emotion-laden words such as happy, sad, enjoyed, and overwhelmed, since they directly express certain sentiment polarity. Besides, this approach helped to reduce the cognitive load of the subtask.\nPrior to the annotation, we carried out a training session for the annotators administered by a psychotherapist, followed by two training batches by which a satisfactory Inter-Annotator Agreement (IAA) was achieved (the results of the training batches were manually controlled and few adjustments were made with the annotators and to the guidelines). We then distributed the samples in 10 batches with 20% overlap in each batch annotated by all 3 annotators (to monitor the IAA and ensure the annotation quality) and the remaining 80% annotated by a single annotator."
        },
        {
            "heading": "3.2 Annotation Results Analysis",
            "text": "Using the 481 Personal Narratives, we annotated 4273 functional units3. As the results, the majority of the FUs, 60%, were annotated as neutral, while 13% and 27% of them were labeled as positive and negative respectively. The Inter-Annotator Agreement (IAA), computed with the Fleiss\u2019 \u03ba coefficient (Fleiss, 1971), on the sentiment annotation is 0.67 (Substantial) on the 5-point scale results, and 0.73 (Substantial) on the 3-point scale (obtained by regrouping the values into three groups of positive\n3As example of valence and ECs annotation on a PN at the level of Functional Units: https://gitlab.com/ sislab/PNs_Val-EC_annotation\n{1,2}, negative {-2,-1} and neutral {0}). Furthermore, the IAA on the examples that were labelled with a non-neutral polarity by all annotators is 0.98 (Almost Perfect).\nRegarding the EC selection, out of 4452 ECcandidate spans in the FUs that were labeled with a non-neutral sentiment polarity, 1991 spans (45%) were chosen as EC by the annotators, resulting in 2551 EC tokens (tokens in the EC-span) and the EC dictionary size of 962. The IAA on the EC annotation is 0.4 (Fair), computed by considering each EC-candidate as an example to annotate where the labels are yes if it is an EC, and no otherwise.\nThe statistics regarding the labelled ECs and the sentiment distribution are presented in Table 1. For our experiments, we split the obtained annotated dataset into training (80%), validation (10%) and test (10%) sets, stratified on the polarity distribution and on the lengths of the PN."
        },
        {
            "heading": "3.3 Emotion Carrier Detection Baseline",
            "text": "We trained a baseline model to assess the EC annotation on the PN dataset for the task of EC detection. The approaches used in previous works (Tammewar et al., 2021; Bayerl et al., 2021) do not fit with our case, since the annotators were asked to select the EC from a predefined set of candidates, rather than selecting any token in the text. Thus, in our case the model is tasked to classify each EC-candidate span as EC or non-EC.\nThe first part of the architecture computes the tokens embedding of each FU. Afterwards, we extract the encoded representation of the ECcandidate tokens and perform max-pooling, which takes the maximum value for every dimension of the vector encoding, producing the vector representation of the EC-candidate. The vector representation is then given as input to the classification layer (dense layer + softmax) yielding the probability distribution over the EC and non-EC classes. To compute the embeddings, we experimented with biLSTM with attention and AlBERTo, a pre-trained\nBERT-based model for the Italian language (Polignano et al., 2019). In the experiments with the AlBERTo model, we experimented concatenating the representation of the [CLS] token with the ECcandidate representation, to better consider the context during the classification.\nThe results of these experiments, summarized in Table 2, indicate that the outperforming baseline combination is obtained by using the AlBERTo model for the input representation with the concatenation of the [CLS] token."
        },
        {
            "heading": "3.4 Sentiment Prediction Model",
            "text": "We trained a sentiment prediction model to predict the polarity at the level of functional units. Our model is based on the AlBERTo architecture (Polignano et al., 2019) with a three-heads output layer, instead of the original two-heads fully connected layers, to predict the sentiment polarity of each FU over the 3-label output space of negative, positive and neutral. We split the training set of the SENTIPOLC16 dataset (Barbieri et al., 2016)4 into training and validation sets of 90% and 10%, in a stratified manner. We then used the training set to fine-tune the model in the first step, and the validation set in the next step for hyper-parameter optimization and selecting the best model using the Optuna framework (Akiba et al., 2019). Using the obtained hyper-parameters5, the model was then further fine-tuned on our own collected dataset of annotated functional units extracted from PNs. The results of these experiments are presented in Table 3.\n4SENTIPOLC16 is a dataset of tweets in the Italian language\n5learning_rate=6.599e-05, weight_decay=0.0215, warmup_steps=0.899, num_epochs=11"
        },
        {
            "heading": "4 Prediction Decision Explainability",
            "text": "We investigate the explainability of the automatic sentiment prediction by comparing the tokens influencing the prediction with those selected by the human judge as ECs. In order to detect the tokens crucial to the model\u2019s prediction, we use the attribution assigned to each token by the Integrated Gradients (Sundararajan et al., 2017) technique. Integrated Gradients (IntGrad) is an attribution method for Explainable AI which builds on top of the classic backward gradient analysis. Given our sentiment prediction model f(FU), where FU is the functional unit FU = {w1, w2, .., wn} and wi \u2208 Rd are the token embeddings , the backward gradient is given by:\nBackwardGradj(wi) = \u2202f\n\u2202wij (1)\nmeasuring how much perturbing the input token wi by an infinitesimal amount along dimension j affects the output of function f . The IntGrad method extends this by computing the integral of the derivative along the path connecting a baseline token w\u2032, which is a neutral element, to the input point w:\nIntGradj(wi) = (wij \u2212 w\u2032) \u222b 1 \u03b1=0 \u2202f(w\u2032+\u03b1(wij\u2212w\u2032)) \u2202wij d\u03b1\n(2) where \u03b1 \u2208 [0, 1] draws a linear path, from the baseline token to the input token, along which the gradients are integrated. In our studies, we used a zero vector for the baseline token w\u2032, and the opensource library Captum (Kokhlikyan et al., 2020) for efficient IntGrad computation. In cases that a token is split into several subtokens by the tokenizer of our model (Kudo and Richardson, 2018), we\naverage the Integrated Gradients attributions of the subtokens, to get the attribution of the whole token."
        },
        {
            "heading": "4.1 Token Analysis based on IntGrad Attributions",
            "text": "Using the test set samples for which the model predicts the sentiment polarity correctly, we employ two approaches regarding the explainability analysis. In the first approach, we extract the tokens influential or crucial to the prediction process of the model based on their Integrated Gradients (IntGrad) attributions, and study whether or not they belong to the spans annotated as EC by the human annotator.\nIn order to identify tokens crucial to the model\u2019s prediction we experimented with two different thresholds for the IntGrad attribution:\n\u2022 Greater than 0 (G0): This baseline is based on the fact that each token with a positive IntGrad attribution value has a positive influence on the prediction. Nevertheless, tokens with small IntGrad attributions have a marginal contribution and thus they are noisy for our analysis;\n\u2022 Lower Bound (LB): This threshold is obtained uniquely for each FU and is measured by consecutively masking each token in the FU, with a zero-vector embedding, in a descending order of IntGrad attributions until a change in the polarity prediction is observed. The IntGrad attribution of the last masked out token is then selected as the LB threshold.\nThe results of this analysis using the two mentioned threshold policies are presented in Table 4 and Figure 2. The analysis indicates that although 67.9% of the EC tokens (tokens in ECs selected by human annotators) have a positive contribution to the model\u2019s prediction, more than 60% of the tokens with an attribution above the thresholds do not overlap with the EC tokens. Nevertheless, the majority of EC tokens with an attribution higher than the thresholds are EC-heads, regardless of the threshold policy. Furthermore, the distributions of the Content Words (CW), i.e. nouns, verbs and adjectives, confirm our previous assumption that G0 threshold is noisy since 54% of tokens above this threshold are non-CWs, while this number is smaller than 20% for the tokens with an IntGrad attribution higher than the LB. The CWs in LB and G0 groups are distributed as 52% nouns, 27%\nverbs, 21% adjectives, and 47% nouns, 40% verbs and 13% adjectives, respectively.\nIn the next step, we further analyzed the polarity distribution of CWs by using the OpeNER6 lexiconbased sentiment model. The results, presented in Table 5, show that the percentage of non-neutral CWs in the ECs is less than 5%, while more than 40% of the influential tokens, i.e. tokens with attributions over the LB threshold, represent a positive or negative polarity. This remarks the importance of emotion-laden words, such as anxiety, fear and worry, for the model in predicting the sentiment, and suggests that the model mostly focuses on the tokens that explicitly convey emotions, and the ECs (as the implicit manifestations of emotions) are less significant in its decision process."
        },
        {
            "heading": "4.2 Contribution of ECs to the Model\u2019s Decision",
            "text": "For the second approach, we evaluate the influence of the ECs selected by the human annotators in the decision process of the model. For this purpose, we mask out the EC-span in the Functional Unit\n6https://www.opener-project.eu/, This publicly available lexicon was semi-automatically created starting from 1,000 manually controlled keywords\nwith the highest IntGrad attribution, and measure the drop in the confidence score for the initially predicted polarity. The confidence score represents the probability assigned by the model to a given class, which in our case the classes can be either positive or negative. In the next step, we extend this analysis to the token level and measure the drop in the confidence score caused by masking out the EC-head with the highest IntGrad attribution, as well as all EC-heads present in the corresponding FU.\nThe results, shown in Table 6, present the strong contribution of emotion-laden words that explicitly manifest the sentiment on the model\u2019s decision. Furthermore, the confidence drop caused by masking the EC-span is higher than masking only the head of the corresponding EC, suggesting that all the tokens in the EC-span contribute to the prediction confidence. However, the highest drop is achieved by masking the most influential token (the token with the highest IntGrad attribution) and emotion-laden words, respectively. These results once again support the findings of the previous analysis, suggesting the importance of tokens that explicitly manifest a sentiment in the decision process of the model."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this work we studied whether the sentiment prediction decision of DNN models can be explained by Emotion Carriers, spans of text that convey and carry emotions. We have focused our study on Personal Narratives which encompass real-life events and experiences that activate the emotional state of the narrator. We have collected a dataset of Personal Narratives and conducted an annotation task for sentiment polarity and Emotion Carrier selection at the Functional Unit for each narrative. We have then developed a sentiment prediction model based on AlBERTo architecture (Polignano et al., 2019). We have investigated whether the decision of the model is based on the Emotion Carriers that the human annotator selected to explain the sentiment of the text. Furthermore, we have studied the impact of the Emotion Carriers on the confidence score of the polarity prediction model. Our analysis has shown that the human annotators tend to focus on manifestation of emotions through words describing actions and events that have activated the emotional state of the narrator. However, the model bases its decision on explicit representations of sentiment such as emotion-laden words."
        },
        {
            "heading": "Acknowledgements",
            "text": "The research leading to these results has received funding from the European Union \u2013 H2020 Programme under grant agreement 826266: COADAPT."
        }
    ],
    "title": "Can Emotion Carriers Explain Automatic Sentiment Prediction? A Study on Personal Narratives",
    "year": 2022
}