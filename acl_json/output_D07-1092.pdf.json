{
    "abstractText": "Unknown words are a well-known hindrance to natural language applications. In particular, they drastically impact machine translation quality. An easy way out commercial translation systems usually offer their users is the possibility to add unknown words and their translations into a dedicated lexicon. Recently, Stroppa and Yvon (2005) have shown how analogical learning alone deals nicely with morphology in different languages. In this study we show that analogical learning offers as well an elegant and effective solution to the problem of identifying potential translations of unknown words.",
    "authors": [
        {
            "affiliations": [],
            "name": "Philippe Langlais"
        },
        {
            "affiliations": [],
            "name": "Alexandre Patry"
        }
    ],
    "id": "SP:47b75590198eb54741b550cf573260417358219b",
    "references": [
        {
            "authors": [
                "Yaser Al-Onaizan",
                "Kevin Knight."
            ],
            "title": "Translating named entities using monolingual and bilingual resources",
            "venue": "InProc. of the 40th ACL",
            "year": 2002
        },
        {
            "authors": [
                "Chris Callison-Burch",
                "Philipp Koehn",
                "Miles Osborne."
            ],
            "title": "Improved statistical machine translation using paraphrases",
            "venue": "In",
            "year": 2006
        },
        {
            "authors": [
                "Hsin-Hsi Chen",
                "Sheng-Jie Hueng",
                "Yung-Wei Ding",
                "Shih-Chung Tsai"
            ],
            "title": "Proper name translation in cross-language information retrieval",
            "venue": "Proc. of HLT-NAACL,",
            "year": 1998
        },
        {
            "authors": [
                "\u00e9bec",
                "Canada. Matthias Eck",
                "Chiori Hori"
            ],
            "title": "Overview of the IWSLT 2005 evaluation campaign",
            "year": 2005
        },
        {
            "authors": [
                "Dayne Freitag."
            ],
            "title": "Morphology induction from term clusters",
            "venue": "InProc. of the 9th CoNLL",
            "year": 2005
        },
        {
            "authors": [
                "Ann Arbor",
                "Michigan",
                "USA. Pascale Fung",
                "Lo Yuen Yee"
            ],
            "title": "An IR approach for translating new words from nonparallel, comparable texts",
            "venue": "InProc. of the 36th ACL",
            "year": 1998
        },
        {
            "authors": [
                "Dedre Gentner",
                "Keith J. Holyoak",
                "Boicho N. Konikov."
            ],
            "title": "The Analogical Mind",
            "venue": "The MIT Press, Cambridge, Massachusetts, USA.",
            "year": 2001
        },
        {
            "authors": [
                "Sharon Goldwater",
                "David McClosky."
            ],
            "title": "Improving statistical MT through morphological analysis",
            "venue": "Proc. of HLT-EMNLP, pages 676\u2013683, Vancouver, British Columbia, Canada.",
            "year": 2005
        },
        {
            "authors": [
                "Philipp Koehn",
                "Kevin Knight."
            ],
            "title": "Learning a translation lexicon from monolingual corpora",
            "venue": "Proc. of the ACL Workshop on Unsupervised Lexical Acquisition, pages 9\u201316, Philadelphia, Pennsylvania, USA.",
            "year": 2002
        },
        {
            "authors": [
                "Philipp Koehn",
                "Kevin Knight."
            ],
            "title": "Empirical methods for compound splitting",
            "venue": "In",
            "year": 2003
        },
        {
            "authors": [
                "Philipp Koehn",
                "Christof Monz"
            ],
            "title": "Manual and automatic evaluation of machine translation between european languages",
            "year": 2006
        },
        {
            "authors": [
                "Yves Lepage",
                "Etienne Denoual."
            ],
            "title": "ALEPH: an EBMT system based on the preservation of proportionnal analogies between sentences across languages",
            "venue": "Proc. of IWSLT, Pittsburgh, Pennsylvania, USA.",
            "year": 2005
        },
        {
            "authors": [
                "Yves Lepage."
            ],
            "title": "Solving analogies on words: an algorithm",
            "venue": "InProc. of COLING-ACL, pages 728\u2013734, Montreal, Q\u00faebec, Canada.",
            "year": 1998
        },
        {
            "authors": [
                "\u00e9 Joseph Fourier",
                "Grenoble",
                "France. Vladimir. I. Levenshtein"
            ],
            "title": "Binary codes capable of correcting deletions, insertions and reversals",
            "year": 1966
        },
        {
            "authors": [
                "Sonja Nie\u00dfen."
            ],
            "title": "Improving Statistical Machine Translation using Morpho-syntactic Information",
            "venue": "Ph.D. thesis, RWTH, Aachen, Germany.",
            "year": 2002
        },
        {
            "authors": [
                "Franz-Joseph Och",
                "Hermann Ney."
            ],
            "title": "Improved statistical alignment models",
            "venue": "In",
            "year": 2000
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "BLEU: a method for automatic evaluation of machine translation",
            "venue": "In",
            "year": 2002
        },
        {
            "authors": [
                "Alexandre Patry",
                "Fabrizo Gotti",
                "Philippe Langlais."
            ],
            "title": "Mood at work: Ramses versus Pharaoh",
            "venue": "Proc. of the HLT-NAACL Workshop on Statistical Machine Translation, pages 126\u2013129, New York City, USA.",
            "year": 2006
        },
        {
            "authors": [
                "Maja Popovic",
                "Hermann Ney."
            ],
            "title": "Towards the use of word stems and suffixes for statistical machine translation",
            "venue": "InProc. of the 4th LREC,",
            "year": 2004
        },
        {
            "authors": [
                "Reinhard Rapp."
            ],
            "title": "Automatic identification of word translations from unrelated English and German corpora",
            "venue": "InProc. of the 37th ACL",
            "year": 1999
        },
        {
            "authors": [
                "Park",
                "Maryland",
                "USA. Nicolas Stroppa",
                "Fran\u00e7ois Yvon"
            ],
            "title": "An analogical learner for morphological analysis",
            "year": 2005
        },
        {
            "authors": [
                "Tanaka Takaaki",
                "Yoshihiro Matsuo"
            ],
            "title": "Extraction of translation equivalents from non-parallel",
            "venue": "Proc. of the 9th CoNLL,",
            "year": 1999
        },
        {
            "authors": [
                "Chester",
                "England. Peter D. Turney"
            ],
            "title": "Similarity of semantic relations",
            "venue": "Computational Linguistics",
            "year": 2006
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 877\u2013886, Prague, June 2007. c\u00a92007 Association for Computational Linguistics\nUnknown words are a well-known hindrance to natural language applications. In particular, they drastically impact machine translation quality. An easy way out commercial translation systems usually offer their users is the possibility to add unknown words and their translations into a dedicated lexicon. Recently, Stroppa and Yvon (2005) have shown how analogical learning alone deals nicely with morphology in different languages. In this study we show that analogical learning offers as well an elegant and effective solution to the problem of identifying potential translations of unknown words."
        },
        {
            "heading": "1 Introduction",
            "text": "Analogical reasoning has received some attention in cognitive science and artificial intelligence (Gentner et al., 2001). It has been for a long time a faculty assessed in the so-called SAT Reasoning tests used in the application process to colleges and universities in the United States. Turney (2006) has shown that it is possible to compute relational similarities in a corpus in order to solve 56% of typical analogical tests quizzed in SAT exams. The interested reader can find in (Lepage, 2003) a particularly dense treatment of analogy, including a fascinating chapter on the history of the notion of analogy.\nThe concept ofproportional analogy, denoted [A : B = C : D ], is a relation between four entities which reads: \u201cA is to B as C is to D \u201d. Among proportional analogies, we distinguishformal analogies, that is, ones that arise at the graphical level, such as[fournit : fleurit = fournie : fleurie] in French or[believer : unbelievable = doer : undoable] in English. Formal analogies are\noften good indices for deeper analogies (Stroppa and Yvon, 2005).\nLepage and Denoual (2005) presented the system ALEPH, an intriguing example-based system entirely built on top of an automatic formal analogy solver. This system has achieved state-of-theart performance on the IWSLT task (Eck and Hori, 2005), despite its striking purity. As a matter of fact, ALEPH requires no distances between examples, nor any threshold.1 It does not even rely on a tokenization device. One reason for its success probably lies in the specificity of the BTEC corpus: short and simple sentences of a narrow domain. It is doubtful that ALEPH would still behave adequately on broader tasks, such as translating news articles.\nStroppa and Yvon (2005) propose a very helpful algebraic description of a formal analogy and describe the theoretical foundations ofanalogical learning which we will recap shortly. They show both its elegance and efficiency on two morphological analysis tasks for three different languages.\nRecently, Moreau et al. (2007) showed that formal analogies of a simple kind (those involving suffixation and/or prefixation) offer an effective way to extend queries for improved information retrieval.\nIn this study, we show that analogical learning can be used as an effictive method for translating unknown words or phrases. We found that our approach has the potential to propose a valid translation for 80% of ordinary unknown words, that is, words that are not proper names, compound words, or numerical expressions. Specific solutions have been proposed for those token types (Chen et al., 1998; Al-Onaizan and Knight, 2002; Koehn and Knight, 2003).\nThe paper is organized as follows. We first recall\n1Some heuristics are applied for speeding up the system.\n877\nin Section 2 the principle of analogical learning and describe how it can be applied to the task of enriching a bilingual lexicon. In Section 3, we present the corpora we used in our experiments. We evaluate our approach over two translation tasks in Section 4. We discuss related work in Section 5 and give perspectives of our work in Section 6."
        },
        {
            "heading": "2 Analogical Learning",
            "text": ""
        },
        {
            "heading": "2.1 Principle",
            "text": "Our approach to bilingual lexical enrichment is an instance of analogical learning described in (Stroppa and Yvon, 2005). A learning setL = {L1, . . . , LN} gathersN observations. A set of features computed on an incomplete observationX defines an input space. The inference task consists in predicting the missing features which belong to an output space. We denoteI(X) (resp.O(X)) the projection ofX into the input (resp. output) space. The inference procedure involves three steps:\n1. Building EI(X) = {(A,B, C) \u2208 L3 | [I(A) : I(B) = I(C) : I(X)]}, the set of inputstems2 of X, that is the set of triplets(A,B, C) which form with X an analogical equation.\n2. Building EO(X) = {Y | [O(A) : O(B) = O(C) : Y ] ,\u2200(A,B, C) \u2208 EI(X)} the set of solutions to the analogical equations obtained by projecting the stems ofEI(X) into the output space.\n3. Selecting O(X) among the elements of EO(X).\nThis inference procedure shares similarities with the K-nearest-neighbor (k-NN) approach. In particular, since no model of the training material is being learned, the training corpus needs to be stored in order to be queried. On the contrary to k-NN, however, the search for closest neighbors does not require any distance, but instead relies on relational similarities. This purity has a cost: while in k-NN inference, neighbors can be found in time linear to the training size, in analogical learning, this operation requires a computation time cubic inN , the\n2In Turney\u2019s work (Turney, 2006), a stem designates the first two words of a proportional analogy.\nnumber of observations. In many applications of interest, including the one we tackle here, this is simply impractical and heuristics must be applied.\nThe first and second steps of the inference procedure rely on the existence of an analogical solver, which we sketch in the next section. One important thing to note at this stage, is that an analogical equation may have several solutions, some being legitimate word-forms in a given language, others being not. Thus, it is important to select wisely the generated solutions, therefore Step 3. In practice, the inference procedure involves the computation of many analogical equations, and a statistic as simple as the frequency of a solution often suffices to separate good from spurious solutions."
        },
        {
            "heading": "2.2 Analogical Solver",
            "text": "Lepage (1998) proposed an algorithm for computing the solutions of a formal analogical equation [A : B = C : ? ]. We implemented a variant of this algorithm which requires to compute two editdistance tables, one betweenA andB and one betweenA and C. Since we are looking for subsequences ofB andC not present inA, insertion cost is null. Once this is done, the algorithm synchronizes the alignments defined by the paths of minimum cost in each table. Intuitively, the synchronization of two alignments (one betweenA andB, and one betweenA andC) consists in composing in the correct order subsequences of the stringsB and C that are not inA. We refer the reader to (Lepage, 1998) for the intricacies of this process which is illustrated in Figure 1 for the analogical equation [even : usual = unevenly : ? ]. In this example, there are 681 different paths that aligneven and usual (with a cost of 4), and 1 path which alignseven with unevenly (with a cost of 0). This results in 681 synchronizations which generate 15 different solutions, among which onlyunusually is a legitimate word-form.\nIn practice, since the number of minimum-cost paths may be exponential in the size of the strings being aligned, we consider the synchronization of a maximum ofM best paths in each edit-distance table. The worst-case complexity of our analogical solver isO([|A| \u00d7 (|B| + |C|)] + [M2 \u00d7 (|A| + ins(B,C))]), where the first term corresponds to the computation of the two edit-distance tables,\nand the second one corresponds to the maximum time needed to synchronize them.|X| denotes the length, counted in characters of the stringX, whilst ins(B,C) stands for the number of characters ofB andC not belonging toA. Given the typical length of the strings we consider in this study, our solver is quite efficient.3\nStroppa and Yvon (2005) described a generalization of this algorithm which can solve a formal analogical equation by composing two finite-state transducers."
        },
        {
            "heading": "2.3 Application to Lexical Enrichment",
            "text": "Analogical inference can be applied to the task of extending an existing bilingual lexicon (or transfer table) with new entries. In this study, we focus on a particular enrichment task: the one of translating valid words or phrases that were not encountered at training time.\nA simple example of how our approach translates unknown words is illustrated in Figure 2 for the (un-\n3Several thousands of equations solved within one second.\nknown) French wordfutilite\u0301. In this example, translations is inferred by commuting plural and singular words. The inference process lazily captures the fact that English plural nouns ending in-ies usually correspond to singular nouns ending in-y.\nFormally, we are given a training corpusL = {\u3008S1, T1\u3009, . . . , \u3008SN , TN \u3009} which consists of a collection ofN bilingual lexicon entries\u3008Si, Ti\u3009. The input space is in our case the space of possible source words, while the output space is the set of possible target words. We define:\n\u2200X \u2261 \u3008S , T\u3009, I(X) = S andO(X) = T\nGiven an unknown source word-formS, Step 1 of the inference process consists in identifying source stems which haveS as a solution:4\nEI(S) = {\u3008i, j, k\u3009 \u2208 [1, N ]3 | [Si : Sj = Sk : S]}.\nDuring Step 2a, each source stem belonging to EI(S) is projected form by form into (potentially several) stems in the output space, thanks to an operatorproj that will be defined shortly:\nE\u3008i ,j ,k \u3009(S) = {T | [U : V = W : T ]} where (U, V,W ) \u2208 (projL(Si)\u00d7 projL(Sj)\u00d7 projL(Sk)).\n4All strings in a stem must be different, otherwise, it can be shown that all source words would be considered.\nDuring Step 2b, each solution to those output stems is collected inEO(S) along with its associated frequency:\nEO(S) = \u22c3\n\u3008i ,j ,k \u3009\u2208EI(S) E\u3008i ,j ,k \u3009(S).\nStep 3 selects fromEO(S) one or several solutions. We use frequency as criteria to sort the generated solutions. The projection mechanism we resort to in this study simply is a lexicon look-up:\nprojL(S) = {T | \u3008S, T \u3009 \u2208 L}.\nThere are several situations where this inference procedure will introduce noise. First, both source and target analogical equations can lead to spurious solutions. For instance,[show : showing = eating : ? ] will erroneously produceatinging. Second, an error in the original lexicon may introduce as well erroneous target word-forms. For instance, when translating the German wordproklamierung, by making use of the analogy[formalisiert : formalisierung = proklamiert : proklamierung], the English equation[formalised : formalized = sets : ? ] will be considered if it happens that proklamiert\u2194sets belongs toL; in which case,zets will be erroneously produced.\nWe control noise in several ways. The source word-forms we generate are filtered by imposing that they belong to the input space. We also use a (large) target vocabulary to eliminate spurious target word-forms (see Section 3). More importantly, since we consider many analogical equations when translating a word-form, spurious analogical solutions tend to appear less frequently than ones arising from paradigmatic commutations."
        },
        {
            "heading": "2.4 Practical Considerations",
            "text": "Searching forEI(S) is an operation which requires solving a number of (source) analogical equations cubic in the size of the input space. In many settings of interest, including ours, this is simply not practical. We therefore resort to two strategies to reduce computation time. The first one consists in using the analogical equations in a generative mode. Instead of searching through the set of stems\u3008Si, Sj , Sk\u3009 that have for solution the unknown source wordform S, we search for all pairs(Si, Sj) to the solutions of[Si : Sj = S :?] that are valid word-forms\nof the input space. Note that this is an exact method which follows from the property (Lepage, 1998):\n[A : B = C : D ] \u2261 [B : A = D : C ]\nThis leaves us with a quadratic computation time which is still intractable in our case. Therefore, we apply a second strategy which consists in computing the analogical equations[Si : Sj = S :?] for the only wordsSi and Sj close enough toS. More precisely, we enforce thatSi \u2208 v\u03b4(S) and that Sj \u2208 v\u03b2(Si) for a neighborhood functionv\u03b3(A) of the form:\nv\u03b3(A) = {B | f(B,A) \u2264 \u03b3}\nwheref is a distance; we used the edit-distance in this study (Levenshtein, 1966). Note that the second strategy we apply is only a heuristic."
        },
        {
            "heading": "3 Resources",
            "text": "In this work, we are concerned with one concrete problem a machine translation system must face: the one of translating unknown words. We are further focusing on the shared task of the workshop on Statistical Machine Translation, which took place last year (Koehn and Monz, 2006) and consisted in translating Spanish, German, and French texts from and to English. For some reasons, we restricted ourselves to translating only into English. The training material available is coming from theEuroparl corpus. The test material was divided into two parts.5 The first one (hereafter calledtest-in ) is composed of 2 000 sentences from European parliament debates. The second part (calledt st-out ) gathers 1 064 sentences6 collected from editorials of the Project Syndicate website.7 The main statistics pertinent to our study are summarized in Table 1.\nA rough analysis of the 441 different unknown words encountered in the French test sets reveals that 54 (12%) of them contain at least one digit (years, page numbers, law numbers, etc.), 83 (20%) are proper names, 37 (8%) are compound words, 18 (4%) are foreign words (often Latin or Greek\n5The participants were not aware of this. 6We removed 30 sentences which had encoding problems. 7http://www.project-syndicate.com\nFrench Spanish German test- in out in out in out |unknown| 180 265 233 292 469 599 oov% 0.26 1.22 0.38 1.37 0.84 2.87\nTable 1: Number of different (source) test words not seen at training time, and out-of-vocabulary rate ex-\npressed as a percentage (oov%).\nwords), 7 words are acronyms, and 4 are tokenization problems. The 238 other words (54%) are ordi-\nnary words.\nWe considered different lexicons for testing our\napproach. These lexicons were derived from the\ntraining material of the shared task by training with\nGIZA ++ (Och and Ney, 2000) \u2014default settings\u2014 two transfer tables (source-to-target and the reverse) that we intersected to remove some noise.\nIn order to investigate how sensitive our approach is to the amount of training material available, we varied the size of our lexiconLT by considering different portions of the training corpus (T = 5 000, 10 000, 100 000, 200 000, and 500 000 pairs of sentences). The lexicon trained on the full training material (688 000 pairs of sentences), calledLref hereafter, is used for validation purposes. We kept (at most) the 20 best associations of each source word in these lexicons. In practice, because we intersect two models, the average number of translations kept for each source word is lower (see Table 2).\nLast, we collected from various target texts (English here) we had at our disposal, a vocabulary set V gathering 466 439 words, that we used to filter out spurious word-forms generated by our approach."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Translating Unknown Words",
            "text": "For the three translation directions (from Spanish, German, and French into English), we applied the analogical reasoning to translate the (nonnumerical) source words of the test material, absent fromLT . Examples of translations produced by analogical inference are reported in Figure 3, sorted by decreasing order of times they have been generated.\nanti-agricole (anti-farm,5) (anti-agricultural,3) (anti-rural,3) (anti-farming,3) (anti-farmer,3) fleurie (flourishing,5) (flourished,4) (flourish,1) futilite\u0301 (trivialities,27) (triviality,14) (futile,9) (meaningless,9) (futility,4) (meaninglessness,4) (superfluous,2) (unwieldy,2) (unnecessary,2) (uselessness,2) (trivially,1) (tie,1) (trivial,1) butoir (deadline,42) (deadlines,33) (blows,1) court-circuitant (bypassing,13) (bypass,12) (bypassed,5) (bypasses,1) xviie (xvii,18) (sixteenth,3) (eighteenth,1)\nFigure 3: Candidate translations inferred from L200 000 and their frequency. The candidates reported are those that have been intersected withV. Translations in bold are clearly erroneous."
        },
        {
            "heading": "4.1.1 Baselines",
            "text": "We devised two baselines against which we compared our approach (hereafterANALOG). The first one,BASE1, simply proposes as translations the target words in the lexiconLT which are the most similar (in the sense of the edit-distance) to the unknown source word. Naturally, this approach is only appropriate for pairs of languages that share many cognates (i.e., docteur\u2192 doctor). The second baseline, BASE2, is more sensible and more closely corresponds to our approach. We first collect a set of source words that are close-enough (according to the edit-distance) to the unknown word. Those source words are then projected into the output space by simple bilingual lexicon look-up. So for instance, the French word emandawill be translated into the English wordrequestif the French worddemandeis in LT and thatrequestis one of its sanctioned translations.\nEach of these baselines is tested in two variants. The first one (id), which allows a direct comparison, proposes as many translations asANALOG does. The second one (10) proposes the first 10 translations of each unknown word."
        },
        {
            "heading": "4.1.2 Automatic Evaluation",
            "text": "Evaluating the quality of translations requires to inspect lists of words each time we want to test a variant of our approach. This cumbersome process not only requires to understand the source language,\nbut happens to be in practice a delicate task. We therefore decided to resort to an automatic evaluation procedure which relies onLref , a bilingual lexicon which entries are considered correct.\nWe translated all the words ofLref absent from LT . We evaluated the different approaches by computing responseandprecisionrates. The response rate is measured as the percentage of words for which we do have at least one translation produced (correct or not). The precision is computed in our case as the percentage of words for which at least one translation is sanctioned byLref . Note that this way of measuring response and precision is clearly biased toward translation systems that can hypothesize several candidate translations for each word, as statistical systems usually do. The reason of this choice was however guided by a lack of precision of the reference we anticipated, a point we discuss in Section 4.1.3.\nThe figures for the French-to-English direction are reported in Table 2. We observe that the ratio of unknown words that get a translation byANA - LOG is clearly impacted by the size of the lexicon LT we use for computing analogies: the larger the better. This was expected since the larger a lexicon is, the higher the number of source analogies that\ncan be made and consequently, the higher the number of analogies that can be projected onto the output space. The precision ofANALOG is rather stable across variants and ranges between 50% to 60%.\nThe second observation we make is that the baselines perform worse thanANALOG in all but the L500 000 cases. Since our baselines propose translations to each source word, their response rate is maximum. Their precision, however, is an issue. Expectedly,BASE1 is the worst of the two baselines. If we arbitrarily fix the response rate ofBASE2 to the one of ANALOG, the former approach shows a far ower precision (e.g., 34.4 against 59.4 forL200 000). This not only indicates that analogical learning is handling unknown words better thanBASE2, but as well, that a combination of both approaches could potentially yield further improvements.\nA last observation concerns the fact thatANALOG performs equally well on the out-domain material. This is very important from a practical point of view and contrasts with some related work we discuss in Section 5.\nAt first glance, the fact thatBASE2 outperforms ANALOG on the larger training size is disappointi g. After investigations, we came to the conclusion that this is mainly due to two facts. First, the num-\nber of unknown words on which both systems were tested is rather low in this particular case (e.g., 34 for the in-domain corpus). Second, we noticed a deficiency of the reference lexiconLref for many of those words. After all, this is not surprising since the words unseen in the 500 000 pairs of training sentences, but encountered in the full training corpus (688 000 pairs) are likely to be observed only a few times, therefore weakening the associations automatically acquired for these entries. We evaluate that a third of the reference translations were wrong in this setting, which clearly raises some doubts on our automatic evaluation procedure in this case.\nThe performance ofANALOG across the three language pairs are reported in Table 3. We observe a drop of performance of roughly 10% (both in precision and response) for the German-to-English translation direction. This is likely due to the heuristic procedure we apply during the search for stems, which is not especially well suited for handling compound words that are frequent in German.\nWe observe that for Spanish- and German-to-\nEnglish translation directions, the precision rate\ntends to decrease for larger values ofT . One ex-\nplanation for that is that we consider all analogies\nequally likely in this work, while we clearly noted\nthat some are spurious ones. With larger training material, spurious analogies become more likely.\nFrench Spanish German T p% r% p% r% p% r% 5 51.4 30.7 52.8 30.3 49.3 23.1 10 55.3 44.4 52.0 45.2 47.6 33.3 50 58.8 64.3 54.0 66.5 44.6 53.2 100 58.2 65.1 53.9 69.1 45.8 55.6 200 59.4 65.2 46.4 71.8 43.0 59.2\nWe measured the impact the translations produced by ANALOG have on a state-of-the-art phrase-based translation engine, which is described in (Patry et al., 2006). For that purpose, we extended a phrasetable with the first translation proposed byANALOG or BASE2 for each unknown word of the test material. Results in terms of word-error-rate (WER)\nandBLEU score (Papineni et al., 2002) are reported in Table 4 for those sentences that contain at least one unknown word. Small but consistent improvements are observed for both metrics withANALOG. This was expected, since the original system simply leaves the unknown words untranslated. What is more surprising is that theBASE2 version slightly underperforms the baseline. The reason is that some\nnknown words that should appear unmodified in a translation, often get an erroneous translation by BASE2. Forcing BASE2 to propose a translation for the same words for whichANALOG found one, slightly improves the figures (BASE2id).\nFrench Spanish German WER BLEU WER BLEU WER BLEU\nbase 61.8 22.74 54.0 27.00 69.9 18.15 +BASE2 61.8 22.72 54.2 26.89 70.3 18.05 +BASE2id 61.7 22.81 54.1 27.01 70.1 18.14 +ANALOG 61.6 22.90 53.7 27.27 69.7 18.30 sentences 387 452 814\nTable 4: Translation quality produced by our phrasebased SMT engine (base) with and without the first translation produced byANALOG, BASE2, or BASE2id for each unknown word."
        },
        {
            "heading": "4.1.3 Manual Evaluation",
            "text": "As we already mentioned, the lexicon used as a reference in our automatic evaluation procedure is not perfect, especially for low frequency words. We further noted that several words receive valid translations that are not sanctioned byLref . This is for instance the case of the examples in Figure 4, where circumventing and fellow are arguably legitimate translations of the French wordscontournant and\nconcitoyen, respectively. Note that in the second ex-\nample, the reference translation is in the plural form\nwhile the French word is not.\nTherefore, we conducted a manual evaluation of the translations produced fromL100 000 by ANA - LOG and BASE2 on the 127 French words of the corpus test-in 8 unknown ofLref . Those are the non-numerical unknown words the participating systems in the shared task had to face in the\n8We did not notice important differences betweent st-in andtest-out .\ncontournant (49 candidates) ANALOG (circumventing,55) (undermining,20) (evading,19) (circumvented,17) (overturning,16) (circumvent,15) (circumvention,15) (bypass,13) (evade,13) (skirt,12) Lref skirting , bypassing, by-pass, overcoming concitoyen (24 candidates) ANALOG (citizens,26) (fellow,26) (fellowcitizens,26) (people,26) (citizen,23) (fellowcitizen,21) (fellows,5) (peoples,3) (civils,3) (fellowship,2) Lref fellow-citizens\nin-domain part of the test material. 75 (60%) of those words received at least one valid translation by ANALOG while only 63 (50%) did byBASE2. Among those words that received (at least) one valid translation, 61 (81%) were ranked first byANA - LOG against only 22 (35%) byBASE2. We further observed that among the 52 words that did not receive a valid translation byANALOG, 38 (73%) did not receive a translation at all. Those untranslated words are mainly proper names (bush), foreign words (munere), and compound words (rhe\u0301naniedu-nord-westphalie), for which our approach is not especially well suited.\nWe conclude from this informal evaluation that 80% of ordinary unknown words received a valid translation in our French-to-English experiment, and\nthat roughly the same percentage had a valid trans-\nlation proposed in the first place byANALOG."
        },
        {
            "heading": "4.2 Translating Unknown Phrases",
            "text": "Our approach is not limited to translate solely unknown words, but might serve as well to enrich existing entries in a lexicon. For instance, lowfrequency words, often poorly handled by current statistical methods, could receive useful translations. This is illustrated in Figure 5 where we report the best candidates produced byANALOG for the French word invite\u0301es, which appears 7 times in the 200 000\ninvite\u0301e (61 candidates) ANALOG (invited,135) (requested,92) (called,77) (urged,75) (guest,72) (asked,47) (request,43) (invites,27) (invite,26) (urge,26) L200 000 asked, generate,urged\nFigure 5: 10 best candidates produced byANALOG for the low-frequency French wordinvite\u0301es and its translations inL200 000.\nfirst pairs of the training corpus. Interestingly,ANA - LOG produced the candidateguest which corresponds to a legitimate meaning of the French word\nthat was absent in the training data.\nacter, ANALOG is not bounded to translate only\nwords. As a proof of concept, we applied analogical\nreasoning to translate those source sequences of at\nmost 5 words in the test material that contain an unknown word. Since there are many more sequences than there are words, the input space in this experiment is far larger, and we had to resort to a much more aggressive pruning technique to find the stems of the sequences to be translated.\nexpulsent (expelling,36) (expel,31) (are expelling,23) (are expel,10) focaliserai (focus,10) (focus solely,9) (concentrate all,9) (will focus,9) (will placing,9) de\u0301passeront (will exceed,4) (exceed,3) (will be exceed,3) (we go beyond,2) (will be exceeding,2) non-re\u0301ussite de (lack of success for,4) (lack of success of,4) (lack of success,4) que vous subissez (you are experiencing,2)\nFigure 6: Examples of translations produced by ANALOG where the input (resp. output) space is defined by the set of source (resp. target) word sequences. Words in bold are unknown.\nWe applied the automatic evaluation procedure described in Section 4.1.2 for the French-to-English translation direction, with a reference lexicon being this time the phrase table acquired on the full training material.9 The response rate in this experiment is particularly low since only a tenth of the sequences\n9This model contains 1.5 millions pairs of phrases.\nreceived (at least) a translation byANALOG. Those are short sequences that contain at most three words, which clearly indicates the limitation of our pruning strategy. Among those sequences that received at least one translation, the precision rate is 55%, which is consistent with the rate we measured while translating words.\nExamples of translations are reported in Figure 6. We observe that single words are not contrived anymore to be translated by a single word. This allows to capture1:n relations such asde\u0301passeront\u2194will exceed, where the future tense of the French word is adequately rendered by the modalwi l in English."
        },
        {
            "heading": "5 Related Work",
            "text": "We are not the first to consider the translation of unknown words or phrases. Several authors have for instance proposed approaches for translating proper names and named entities (Chen et al., 1998; AlOnaizan and Knight, 2002). Our approach is complementary to those ones.\nRecently and more closely related to the approach we described, Callison-Burch et al. (2006) proposed to replace an unknown phrase in a source sentence by a paraphrase. Paraphrases in their work are acquired thanks to a word alignment computed over a large external set of bitexts. One important difference between their work and ours is that our approach does not require additional material.10 Indeed, they used a rather idealistic set of large, homogeneous bitexts (European parliament debates) to acquire paraphrases from. Therefore we feel our approach is more suited for translating \u201clow density\u201d languages and languages with a rich morphology.\nSeveral authors considered as well the translation of new words by relying on distributional collocational properties computed from a huge non-parallel corpus (Rapp, 1999; Fung and Yee, 1998; Takaaki and Matsuo, 1999; Koehn and Knight, 2002). Even if admittedly non-parallel corpora are easier to acquire than bitexts, this line of work is still heavily dependent on huge external resources.\nMost of the analogies made at the word level in our study are capturing morphological information.\n10We do use a target vocabulary list to filter out spurious analogies, but we believe we could do without. The frequency with which we generate a string could serve to decide upon its legitimacy.\nThe use of morphological analysis in (statistical) machine translation has been the focus of several studies, (Nie\u00dfen, 2002) among the first. Depending on the pairs of languages considered, gains have been reported when the training material is of mod-\nst size (Lee, 2004; Popovic and Ney, 2004; Goldwater and McClosky, 2005). Our approach does not require any morphological knowledge of the source, the target, or both languages. Admittedly, several unsupervised morphological induction methodologies have been proposed,e.g., the recent approach in Freitag (2005). In any case, as we have shown, ANALOG is not bounded to treat only words, which we believe to be at our advantage."
        },
        {
            "heading": "6 Discussion and Future Work",
            "text": "In this paper, we have investigated the appropriateness of analogical learning to handle unknown words in machine translation. On the contrary to several lines of work, our approach does not rely on massive additional resources but capitalizes instead on an information which is inherently pertaining to the language. We measured that roughly 80% of ordinary unknown French words can receive a valid translation into English with our approach.\nThis work is currently being developed in several directions. First, we are investigating why our approach remains silent for some words or phrases. This will allow us to better characterize the limitations of ANALOG and will hopefully lead us to design a better strategy for identifying the stems of a given word or phrase. Second, we are investigating how a systematic enrichment of a phrase-transfer table will impact a phrase-based statistical machine translation engine. Last, we want to investigate the training of a model that can learn regularities from the analogies we are making. This would relieve us from requiring the training material while translating, and would allow us to compare our approach with other methods proposed for unsupervised morphology acquisition.\nAcknowledgementWe are grateful to the anonymous reviewers for their useful suggestions and to Pierre Poulin for his fruitful comments. This study has been partially funded by NSERC."
        }
    ],
    "title": "Translating Unknown Words by Analogical Learning",
    "year": 2007
}