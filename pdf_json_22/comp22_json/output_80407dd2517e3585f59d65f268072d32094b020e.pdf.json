{
    "abstractText": "Computer-aided X-ray pneumonia lesion recognition is important for accurate diagnosis of pneumonia. With the emergence of deep learning, the identification accuracy of pneumonia has been greatly improved, but there are still some challenges due to the fuzzy appearance of chest X-rays. In this paper, we propose a deep learning framework named Attention-Based Contrastive Learning for Class-Imbalanced XRay Pneumonia Lesion Recognition (denoted as Deep Pneumonia). We adopt self-supervised contrastive learning strategy to pre-train the model without using extra pneumonia data for fully mining the limited available dataset. In order to leverage the location information of the lesion area that the doctor has painstakingly marked, we propose mask-guided hard attention strategy and feature learning with contrastive regulation strategy which are applied on the attention map and the extracted features respectively to guide the model to focus more attention on the lesion area where contains more discriminative features for improving the recognition performance. In addition, we adopt Class-Balanced Loss instead of traditional Cross-Entropy as the loss function of classification to tackle the problem of serious class imbalance between different classes of pneumonia in the dataset. The experimental results show that our proposed framework can be used as a reliable computer-aided pneumonia diagnosis system to assist doctors to better diagnose pneumonia cases accurately.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xinxu Wei"
        },
        {
            "affiliations": [],
            "name": "Xiangke Niu"
        },
        {
            "affiliations": [],
            "name": "Xianshi Zhang"
        },
        {
            "affiliations": [],
            "name": "Yongjie Li"
        }
    ],
    "id": "SP:cfac3e3b3b1a47b4165b5c2fa7bfc53ef0cecbb0",
    "references": [
        {
            "authors": [
                "Pranav Rajpurkar",
                "Jeremy Irvin",
                "Kaylie Zhu",
                "Brandon Yang",
                "Hershel Mehta",
                "Tony Duan",
                "Daisy Ding",
                "Aarti Bagul",
                "Curtis Langlotz",
                "Katie Shpanskaya"
            ],
            "title": "Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning",
            "venue": "arXiv preprint arXiv:1711.05225,",
            "year": 2017
        },
        {
            "authors": [
                "Tatiana Gabruseva",
                "Dmytro Poplavskiy",
                "Alexandr Kalinin"
            ],
            "title": "Deep learning for automatic pneumonia detection",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops,",
            "year": 2020
        },
        {
            "authors": [
                "Amit Kumar Jaiswal",
                "Prayag Tiwari",
                "Sachin Kumar",
                "Deepak Gupta",
                "Ashish Khanna",
                "Joel JPC Rodrigues"
            ],
            "title": "Identifying pneumonia in chest x-rays: a deep learning approach",
            "year": 2019
        },
        {
            "authors": [
                "Sudipto Trivedy",
                "Manish Goyal",
                "Prasanta R Mohapatra",
                "Anirban Mukherjee"
            ],
            "title": "Design and development of smartphone-enabled spirometer with a disease classification system using convolutional neural network",
            "venue": "IEEE Transactions on Instrumentation and Measurement,",
            "year": 2020
        },
        {
            "authors": [
                "Qiaobo Hao",
                "Yu Pei",
                "Rong Zhou",
                "Bin Sun",
                "Jun Sun",
                "Shutao Li",
                "Xudong Kang"
            ],
            "title": "Fusing multiple deep models for in vivo human brain hyperspectral image classification to identify glioblastoma tumor",
            "venue": "IEEE Transactions on Instrumentation and Measurement,",
            "year": 2021
        },
        {
            "authors": [
                "Ross Girshick"
            ],
            "title": "Fast r-cnn",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2015
        },
        {
            "authors": [
                "Qian Xie",
                "Dawei Li",
                "Zhenghao Yu",
                "Jun Zhou",
                "Jun Wang"
            ],
            "title": "Detecting trees in street images via deep learning with attention module",
            "venue": "IEEE Transactions on Instrumentation and Measurement,",
            "year": 2019
        },
        {
            "authors": [
                "Xinxu Wei",
                "Xianshi Zhang",
                "Shisen Wang",
                "Cheng Cheng",
                "Yanlin Huang",
                "Kaifu Yang",
                "Yongjie Li"
            ],
            "title": "Da-drn: Degradation-aware deep retinex network for low-light image enhancement",
            "venue": "arXiv preprint arXiv:2110.01809,",
            "year": 2021
        },
        {
            "authors": [
                "Xinxu Wei",
                "Xianshi Zhang",
                "Shisen Wang",
                "Yanlin Huang",
                "Yongjie Li"
            ],
            "title": "Tsn-ca: A two-stage network with channel attention for low-light image enhancement",
            "venue": "arXiv preprint arXiv:2110.02477,",
            "year": 2021
        },
        {
            "authors": [
                "Xinxu Wei",
                "Xianshi Zhang",
                "Yongjie Li"
            ],
            "title": "Sarn: A lightweight stacked attention residual network for low-light image enhancement",
            "venue": "6th International Conference on Robotics and Automation Engineering (ICRAE),",
            "year": 2021
        },
        {
            "authors": [
                "Rencheng Song",
                "Senle Zhang",
                "Chang Li",
                "Yunfei Zhang",
                "Juan Cheng",
                "Xun Chen"
            ],
            "title": "Heart rate estimation from facial videos using a spatiotemporal representation with convolutional neural networks",
            "venue": "IEEE Transactions on Instrumentation and Measurement,",
            "year": 2020
        },
        {
            "authors": [
                "Mohamed Hammad",
                "Abdullah M Iliyasu",
                "Abdulhamit Subasi",
                "Edmond SL Ho",
                "Ahmed A Abd El-Latif"
            ],
            "title": "A multitier deep learning model for arrhythmia detection",
            "venue": "IEEE Transactions on Instrumentation and Measurement,",
            "year": 2020
        },
        {
            "authors": [
                "Shashwat Jha",
                "Vishvaditya Luhach",
                "Raju Poddar"
            ],
            "title": "Retinal malady classification using ai: A novel vit-svm combination architecture",
            "venue": "In 2022 6th International Conference on Computing Methodologies and Communication (ICCMC),",
            "year": 2022
        },
        {
            "authors": [
                "Qinghua Huang",
                "Zhaoji Miao",
                "Shichong Zhou",
                "Cai Chang",
                "Xuelong Li"
            ],
            "title": "Dense prediction and local fusion of superpixels: A framework for breast anatomy segmentation in ultrasound image with scarce data",
            "venue": "IEEE Transactions on Instrumentation and Measurement,",
            "year": 2021
        },
        {
            "authors": [
                "Enes Ayan",
                "Halil Murat \u00dcnver"
            ],
            "title": "Diagnosis of pneumonia from chest x-ray images using deep learning",
            "venue": "Scientific Meeting on Electrical-Electronics & Biomedical Engineering and Computer Science (EBBT),",
            "year": 2019
        },
        {
            "authors": [
                "Okeke Stephen",
                "Mangal Sain",
                "Uchenna Joseph Maduh",
                "Do-Un Jeong"
            ],
            "title": "An efficient deep learning approach to pneumonia classification in healthcare",
            "venue": "Journal of healthcare engineering,",
            "year": 2019
        },
        {
            "authors": [
                "Shervin Minaee",
                "Rahele Kafieh",
                "Milan Sonka",
                "Shakib Yazdani",
                "Ghazaleh Jamalipour Soufi"
            ],
            "title": "Deep-covid: Predicting covid-19 from chest x-ray images using deep transfer learning",
            "venue": "Medical image analysis,",
            "year": 2020
        },
        {
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ],
            "title": "Focal loss for dense object detection",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2017
        },
        {
            "authors": [
                "Fran\u00e7ois Chollet"
            ],
            "title": "Xception: Deep learning with depthwise separable convolutions",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Karen Simonyan",
                "Andrew Zisserman"
            ],
            "title": "Very deep convolutional networks for large-scale image recognition",
            "venue": "arXiv preprint arXiv:1409.1556,",
            "year": 2014
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Jie Hu",
                "Li Shen",
                "Gang Sun"
            ],
            "title": "Squeeze-and-excitation networks",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Gao Huang",
                "Zhuang Liu",
                "Laurens Van Der Maaten",
                "Kilian Q Weinberger"
            ],
            "title": "Densely connected convolutional networks",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Mathilde Caron",
                "Piotr Bojanowski",
                "Armand Joulin",
                "Matthijs Douze"
            ],
            "title": "Deep clustering for unsupervised learning of visual features",
            "venue": "In Proceedings of the European Conference on Computer Vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Ting Chen",
                "Simon Kornblith",
                "Mohammad Norouzi",
                "Geoffrey Hinton"
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "In International conference on machine learning,",
            "year": 2020
        },
        {
            "authors": [
                "Kaiming He",
                "Haoqi Fan",
                "Yuxin Wu",
                "Saining Xie",
                "Ross Girshick"
            ],
            "title": "Momentum contrast for unsupervised visual representation learning",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Haiyan Wu",
                "Yanyun Qu",
                "Shaohui Lin",
                "Jian Zhou",
                "Ruizhi Qiao",
                "Zhizhong Zhang",
                "Yuan Xie",
                "Lizhuang Ma"
            ],
            "title": "Contrastive learning for compact single image dehazing",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Xinlong Wang",
                "Rufeng Zhang",
                "Chunhua Shen",
                "Tao Kong",
                "Lei Li"
            ],
            "title": "Dense contrastive learning for self-supervised visual pre-training",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Ishan Misra",
                "Laurens van der Maaten"
            ],
            "title": "Self-supervised learning of pretext-invariant representations",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Longlong Jing",
                "Yingli Tian"
            ],
            "title": "Self-supervised visual feature learning with deep neural networks: A survey",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Prannay Khosla",
                "Piotr Teterwak",
                "Chen Wang",
                "Aaron Sarna",
                "Yonglong Tian",
                "Phillip Isola",
                "Aaron Maschinot",
                "Ce Liu",
                "Dilip Krishnan"
            ],
            "title": "Supervised contrastive learning",
            "venue": "arXiv preprint arXiv:2004.11362,",
            "year": 2020
        },
        {
            "authors": [
                "Sanghyun Woo",
                "Jongchan Park",
                "Joon-Young Lee",
                "In So Kweon"
            ],
            "title": "Cbam: Convolutional block attention module",
            "venue": "In Proceedings of the European conference on computer vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Chunfeng Song",
                "Yan Huang",
                "Wanli Ouyang",
                "Liang Wang"
            ],
            "title": "Maskguided contrastive attention model for person re-identification",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Feifan Lv",
                "Yu Li",
                "Feng Lu"
            ],
            "title": "Attention guided low-light image enhancement with a large scale low-light simulation dataset",
            "venue": "International Journal of Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Zhaoyang Niu",
                "Guoqiang Zhong",
                "Hui Yu"
            ],
            "title": "A review on the attention mechanism of deep learning",
            "year": 2021
        },
        {
            "authors": [
                "Zhong-Qiu Zhao",
                "Peng Zheng",
                "Shou-tao Xu",
                "Xindong Wu"
            ],
            "title": "Object detection with deep learning: A review",
            "venue": "IEEE transactions on neural networks and learning systems,",
            "year": 2019
        },
        {
            "authors": [
                "Yin Cui",
                "Menglin Jia",
                "Tsung-Yi Lin",
                "Yang Song",
                "Serge Belongie"
            ],
            "title": "Class-balanced loss based on effective number of samples",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Enze Xie",
                "Jian Ding",
                "Wenhai Wang",
                "Xiaohang Zhan",
                "Hang Xu",
                "Peize Sun",
                "Zhenguo Li",
                "Ping Luo"
            ],
            "title": "Detco: Unsupervised contrastive learning for object detection",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Ramprasaath R Selvaraju",
                "Michael Cogswell",
                "Abhishek Das",
                "Ramakrishna Vedantam",
                "Devi Parikh",
                "Dhruv Batra"
            ],
            "title": "Grad-cam: Visual explanations from deep networks via gradient-based localization",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "1 Deep Pneumonia: Attention-Based Contrastive Learning for Class-Imbalanced Pneumonia Lesion\nRecognition in Chest X-rays Xinxu Wei, Xiangke Niu, Xianshi Zhang\u2217, and Yongjie Li, Senior Member, IEEE\nAbstract\u2014Computer-aided X-ray pneumonia lesion recognition is important for accurate diagnosis of pneumonia. With the emergence of deep learning, the identification accuracy of pneumonia has been greatly improved, but there are still some challenges due to the fuzzy appearance of chest X-rays. In this paper, we propose a deep learning framework named Attention-Based Contrastive Learning for Class-Imbalanced XRay Pneumonia Lesion Recognition (denoted as Deep Pneumonia). We adopt self-supervised contrastive learning strategy to pre-train the model without using extra pneumonia data for fully mining the limited available dataset. In order to leverage the location information of the lesion area that the doctor has painstakingly marked, we propose mask-guided hard attention strategy and feature learning with contrastive regulation strategy which are applied on the attention map and the extracted features respectively to guide the model to focus more attention on the lesion area where contains more discriminative features for improving the recognition performance. In addition, we adopt Class-Balanced Loss instead of traditional Cross-Entropy as the loss function of classification to tackle the problem of serious class imbalance between different classes of pneumonia in the dataset. The experimental results show that our proposed framework can be used as a reliable computer-aided pneumonia diagnosis system to assist doctors to better diagnose pneumonia cases accurately.\nIndex Terms\u2014Pneumonia lesion diagnosis, Contrastive learning, Attention mechanism, Class imbalance data, Deep learning\nI. INTRODUCTION\nPneumonia is usually caused by the viral or bacterial infection. Pneumonia is often diagnosed based on symptoms as well as physical examination. Early diagnosis of pneumonia is very important for effective treatment of pneumonia. Chest X-rays are commonly used as a clinical method to diagnose pneumonia. Chest X-ray radiograph usually requires the examine by highly-trained radiologists, and usually there exists disagreement among these experienced experts [1]. Xray radiographs of chest pneumonia are usually very fuzzy, and there are other kinds of lesions in both lungs, such as lung cancer and excess fluid, which show similar opacities with pneumonia lesion in X-ray images, making it difficult to diagnose pneumonia and locate the area of the pneumonia\nThis work was supported by Guangdong Key R&D Project (#2018B030338001) and Natural Science Foundations of China (#61806041, #62076055). (Corresponding author: Xian-Shi Zhang, email: zhangxianshi@uestc.edu.cn)\nXinxu Wei, Haohan Bai, Xianshi Zhang and Yongjie Li are with the MOE Key Lab for Neuroinformation, University of Electronic Science and Technology of China (UESTC), Chengdu 610054, China. Xiangke Niu is with Department of Radiology, Affiliated Hospital of Chengdu University.\nlesion [2] [3]. Other diagnostic methods can help confirm the diagnosis, such as blood tests, and sputum microbial cultures. But these diagnostic methods are time-consuming and costly. In contrast, diagnostic methods aided by computer systems and artificial intelligence algorithms have the advantages of being fast, convenient and accurate. In recent years, deep learning has achieved breakthrough success in many fields, such as medical image recognition [4] [5], object detection [6] [7] and low-level vision tasks [8] [9] [10]. Deep learning also has many applications [11] [12] in the medical field. Many computer-aided diagnosis systems [13] [14] based on deep learning play an important role in doctors\u2019 clinical diagnosis.\nAt present, some algorithms and systems [1] [15] [16] [3] [17] based on deep learning can achieve good recognition and diagnosis effect of pneumonia, but there are still some challenges and problems. The main problems are as follows: (1) The number of chest X-ray radiograph data of pneumonia is small, because it is time-consuming and laborious for doctors to label them, and the acquisition of images is time-consuming and costly, too. (2) The small amount of the data results in poor generalization and robustness of the trained model, and it is easy to overfit. (3) When training the deep learning model, the data are not fully mined and utilized, and the features extracted by the network are not quite discriminative. (4) The location information of lesions painstakingly marked by doctors is not utilized. (5) Due that the incidence of pneumonia is different, the class is extremely imbalanced, which makes the model overfitted or underfitted in certain classes, and there is a severe information overlapping between different pneumonia data samples. All of these factors have negative affect on the recognition accuracy. In this paper, aimed at solving these problems, we propose a deep learning framework named Attention-Based Contrastive Learning for Class-Imbalanced X-Ray Pneumonia Lesions Recognition (denoted as Deep Pneumonia).\nIn order to solve the above-mentioned problems (1)(2)(3), we pre-train the feature extractor by adopting self-supervised contrastive learning, which can fully mine useful information from existing datasets by leveraging data augmentation and contrastive loss without using extra X-ray data. For tackling the problem (4), we introduce a mask-guided hard attention strategy and feature learning with contrastive regulation which are applied on the attention map and the extracted features respectively to guide the model to focus more attention on the lesion area identified and marked by experiened doctors. To overcome the problem (5), we adopt Class-Balanced Loss\nar X\niv :2\n20 7.\n11 39\n3v 1\n[ cs\n.C V\n] 2\n3 Ju\nl 2 02\n2\n2 (a) Normal (b) Pneumonia 1 (c) Pneumonia 2 (d) Pneumonia 3 (e) Pneumonia 4\nFig. 1. Examples of the five categories of X-ray images in the dataset, the first is a normal chest X-ray image without pneumonia, and the other four are images of four different types of pneumonia. The bounding boxes in the X-ray images are the area of the pneumonia lesions identified and marked by the doctor.\ninstead of traditional Cross Entropy as the loss function of classification, which can measure data overlapping and estimate the effective number of samples, then integrate a re-weighting scheme into the Focal Loss [18] for better classification. re-weighting scheme into the Focal Loss [18] for better classification. re-weighting scheme into the Focal Loss [18] for better classification. re-weighting scheme into the Focal Loss [18] for better classification. re-weighting scheme into the Focal Loss [18] for better classification. re-weighting scheme into the Focal Loss [18] for better classification.\nThe main contributions of this paper are threefold: \u2022 In order to fully mine the existing X-ray dataset, we\nadopt self-supervised contrastive learning to pre-train the feature extractor without extra data;\n\u2022 In order to leverage the location information of the lesions, we propose mask-guided hard attention with contrastive regulation module, which can guide and drive the network to focus more attention on the lesion regions;\n\u2022 In order to tackle the challenge of class-imbalanced dataset, we introduce Class-Balanced Focal Loss instead of Cross Entropy to re-weighting the loss weights during training.\nExperiments show that these new strategies can solve those aforementioned common problems and challenges to certain extent in the field of medical image recognition."
        },
        {
            "heading": "II. RELATED WORKS",
            "text": ""
        },
        {
            "heading": "A. Pneumonia Lesion Recognition",
            "text": "There are many methods for pneumonia identification using deep learning, which have achieved good results. For example, CheXNet [1] develops an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists. Stephen et al. [16] constructs a convolutional neural network model, which is trained from scratch to extract features from given chest X-ray radiographs and classify them to determine whether a person is infected with pneumonia. Jaiswal et al. [3] proposes a deep learning based approach for the identification and localization of pneumonia in Chest X-rays (CXRs) images. [15] adopts Xception [19] and Vgg16 [20] for diagnosing pneumonia with transfer learning and fine-tuning in the training stage. Deep-covid [17] trains four popular convolutional\nneural networks, including ResNet18 [21], ResNet50 [21], SqueezeNet [22], and DenseNet-121 [23], to identify COVID19 disease with transfer learning. Although these methods can achieve good accuracy in pneumonia recognition, they just simply apply some basic classification deep learning models to pneumonia X-ray recognition and do not solve the common problems and challenges that we mentioned above in the field of medical image recognition."
        },
        {
            "heading": "B. Contrastive Learning",
            "text": "In recent years, with the emergence of contrastive learning (CL) methods [24] [25] [26] [27] [28], self-supervised learning [29] [30] [31] [32] has attracted a lot of attention. Self-supervised learning can generate positive and negative samples through data augmentation of the anchor images, and label information can be constructed according to the pair of positive and negative samples during training, which can avoid the use of large amounts of labeled data. Such strategy is helpful to some tasks where label information is difficult to obtain. Contrastive learning generates positive and negative sample pairs of the anchor image through two independent data augmentation, and then applies a sharedweight encoder (usually a feature extraction network, such as VGG, ResNet, etc) to extract the features of the images (encode the images into the feature space). Then the dimension of the extracted features is reduced and represented as a lowdimensional vector through the projector (usually a MultiLayer Perception), in a metric embedding space, these vectors are constrained with contrastive loss in the embedding space. The central idea of contrastive learning is to bring similar instances closer and push away dissimilar instances far from each other by measuring the closeness between the embeddings of two samples [30]."
        },
        {
            "heading": "C. Attention Mechanism",
            "text": "Deep learning allows networks to allocate more attention to the regions of interest (ROIs) by mimicking human attention mechanisms. Visual attention mechanisms have achieved great success in computer vision, such as image recognition [33] [34] [22], pedestrian re-identification [35] and image enhancement [9] [36]. The main challenge of introducing attention mechanisms is what kind of top-down cues can be used and\n3 how to guide the bottom-up processing using these top-down cues [37] [38]."
        },
        {
            "heading": "III. DATASETS",
            "text": "The dataset we employed consists of 20,012 X-ray images of pneumonia. As shown in Fig.1, there are five categories in the dataset, one category is normal X-ray images without pneumonia lesion, and the other four categories are X-ray images with different kinds of pneumonia. The pneumonia lesion areas of these four types of images are marked by highly-trained radiologists through bounding boxes, whose coordinates are available. We divided the pneumonia dataset into the training set and test set, and the rule of division is to randomly select 10% of images of each category to form the test set, and the remaining 90% is used as the training set. Each image is a single-channel chest X-ray with the resolution of 1024x1024. The dataset is available at https://god.yanxishe.com/23?from=god home list.\nAs shown in Fig.2, the distribution of this dataset is skewed, with a long-tail. In this kind of dataset, a few dominant classes have most of the samples (for example, the samples of normal X-ray radiography without pneumonia lesions accounts for the majority of the total X-ray images), while most other classes contain relatively few examples (the incidence of some pneumonia is low, so these kinds of pneumonia are less than any other type of pneumonia in term of number. Compared with normal images without pneumonia lesions, they are even negligible). In general, models trained on such data perform poorly for weakly represented classes (a few types of pneumonia) [39]."
        },
        {
            "heading": "IV. METHODOLOGY",
            "text": ""
        },
        {
            "heading": "A. Framework and Network",
            "text": "As shown in Fig.3, we propose a framework named Attention-Based Contrastive Learning for Class-Imbalanced X-Ray Pneumonia Lesion Recognition (denoted as Deep\nPneumonia). There are two stages in the framework: Selfsupervised contrastive learning based pre-training stage and Attention-based supervised re-training stage.\nIn stage I, we adopt self-supervised contrastive learning strategy to pre-train the ResNet18 [21] as the feature extractor backbone. In this stage, following [25], firstly we apply two individual data augmentation operations to the anchor image to generate the corresponding positive and negative samples. Then we feed the three kinds of samples (anchor, positive and negative samples) into the weight-shared feature extractor backbone (ResNet18 [21]) to extract the features of these three samples. The feature extractor can also be viewed as an encoder. Then we use Multi-Layer Perception (MLP) as the projector to reduce the dimension of encoder\u2019s output features and project these features to the low-dimensional space for representing them as metric embedding vectors. During model training in stage I, the contrastive loss [25] is used to constrain the training process of self-supervision, and the label information of samples can be constructed by the generated positive and negative sample pairs themselves without the need of given label information, so the whole process is self-supervised. After the training of stage I, we save the model and weights of the ResNet feature extractor (encoder) as the pre-trained model, which is used for feature extraction in the next stage.\nIn stage II, we use the pre-trained feature extractor (ResNet18) to extract the features of the X-ray image. In this stage, we discard the MLP and adopt Adaptive Average Pooling to flatten the features into vectors. And then a fullyconnected layer is used for classification. ResNet18 [21] is adopted as our backbone, extracting features with a convolutional layer in the first layer, and then feeding them into the network which is composed of several residual blocks to extract deeper semantic features. There are four groups of residual layers in the network, and each residual layer is composed of one or several residual blocks [21]. The number of residual blocks in each residual layer can be adjusted. After each residual layer, the scale of the image is reduced. In order to leverage the location information of the lesion area marked by doctors, so that the network can focus more attention on the lesion area and improve the classification performance, we feed the features of different scales outputted from each residual layer into the proposed module named Mask-guided Attention with Contrastive Regulation (MGACR), which can guide and drive the network to learn the expected attention map through the guidance of the given masks. In addition, the strategy of contrastive regulation is adopted in both the attention map and the features after attention weight is applied, so that the network can learn in a better way. Previous classification methods [19] [20] [21] [23] based on deep learning generally use Cross-Entropy (CE) as the loss function of classification, but the classes of pneumonia X-ray dataset are extremely imbalanced, therefore, we adopt Class-Balanced Focal Loss [39] to replace the traditional Cross-Entropy as the loss function of classification task.\n4 Conv Block Res Block Res Block Res Block Res Block MLP Data Augmentation\nData Augmentation\nPneumonia 1\nPneumonia 3\nPneumonia 2\nPneumonia 4\nNormal 0\nInfoNCE Loss\nProjectorFeature Extractor (Shared Weights)Data Preprocessing Contrastive Loss\nConv Block\nRes Block\nRes Block\nRes Block\nRes Block\nAvg Pool\nPneumonia 2\nClass Balanced\nLoss\nFlattenPre-Trained Feature ExtractorData Preprocessing Loss\nData Augmentation\nMask-guided Attention with Contrastive Regulation\nPositive Samples\nNegative Samples\nAnchorSelfSupervised Contrastive\nLearning Pre-Train\nAttentionBased Supervised Re-Train\nPre-Trained Weights\nStage I\nStage II\nFig. 3. The framework of the proposed Deep Pneumonia. The whole pipeline includes two stages, namely Self-supervised contrastive learning pre-train stage and Attention-based supervised re-train stage. The detailed schematic of the proposed module Mask-guided Hard Attention and Feature Learning with Contrastive Regulation (MGACR) can be seen in Fig.4."
        },
        {
            "heading": "B. Pre-training with Self-supervised Contrastive Learning",
            "text": "There is small amount of X-ray pneumonia data, and the economic cost and time cost of obtaining the dataset are high, therefore, it is necessary to make full use of the existing dataset. In order to fully mine the existing X-ray pneumonia dataset without using external datasets, in satge I, we adopt Self-supervised Contrastive Learning [25] strategy to pre-train the feature extractor backbone.\nBefore the training, positive and negative samples are generated through two individual data augmentation operations. Based on contrastive learning [25] [29] [26], we apply data augmentation to each image in the dataset. Assuming that we select an image as anchor, samples obtained by this anchor image through data augmentation are regarded as positive samples. Samples obtained through data augmentation of other images are negative samples. Then, we feed these three kinds of samples (anchor, positive and negative samples) to a weightshared feature extractor (encoder) to extract features. We adopt ResNet18 [21] as the backbone of our encoder, then a MultiLayer Perception (MLP) is used as the projector to reduce the dimension of the extracted high-dimensional features, and turn the encoder\u2019s output features into low-dimensional vectors. The features are projected to a metric embedding space. Then InfoNCE Loss [25] (a kind of contrastive loss) is used to constrain the entire training process of contrastive learning. We\nbuild the contrastive loss following the rule of maximizing the disagreement among feature vectors from different categories, minimizing the divergence among those belonging to the same category [25] [40]. The InfoNCE Loss is defined as follow:\nLi,j = \u2212log exp(sim(zi, zj)/\u03c4)\u22112N\nk=1 [k 6= j] exp(sim(zi, zk)/\u03c4) (1)\nwhere \u03c4 = 0.2 is a temperature hyper-parameter. Sim(,) measures the similarity of two normalized vectors by dot production. zi is the vector of anchor sample i, zj is the vector of positive sample j, and zk is the vector of negative sample k. By optimizing this contrastive loss, the model can minimize the distance between views from the same images and maximize the distance between views from different images in the latent feature space.\nAfter the pre-training based on self-supervised contrastive learning, we only need to save the model and weights of the feature extractor backbone, and the MLP projector is discarded. The saved encoder backbone will be directly used as the feature extractor to extract image features in re-training stage."
        },
        {
            "heading": "C. Mask-guided Attention with Contrastive Regulation",
            "text": "Through the pre-training stage, we can obtain a powerful feature extractor that can learn and extract image features\n5 well. The pneumonia X-ray dataset also provides the valuable location information of the lesion areas marked by the doctor. In previous X-ray image recognition methods [1] [16] [3] [17] of pneumonia, the location information of the lesion was not used. Inspired by the idea adopted for the task of pedestrian reidentification [35], we propose a module, namely Mask-guided Attention with Contrastive Regulation (MGACR), which consists of two strategies, i.e., Mask-guided Hard Attention and Features Learning with Contrastive Regulation, to leverage the location information of the lesion areas marked by the doctor as the priori attention information, and we add contrastive regulation on both the learning of the attention map and the features weighted by the corresponding attention map into the training process to guide and drive the network to focus more attention on the lesion regions.\nAs shown in Fig.3, in order to drive the network to focus on the lesion area, we feed the features of different scales outputted from each residual layer into the MGACR module in the re-training stage to constrain these features under the rule of contrastive regulation. We adopt the hard attention approach, that is, using the masks as the prior information to guide the learning of spatial attention and force the network to focus more attention on the discriminative lesion regions.\nAs shown in Fig.5, (a) is an X-ray image with pneumonia lesion, and the pneumonia lesion is marked by doctors through bounding boxes. According to these bounding boxes, we can generate corresponding masks and inverted masks, for example, (b) and (c) in Fig.5. We can guide and drive the network to pay more attention to these regions by constraining the network\u2019s attention map and the weighted features with these masks using contrastive regulation.\nNext, we demonstrate in detail the working mechanism of MGACR module and how to drive the network to focus more attention on the lesion region marked with the bounding boxes by doctors. As shown in Fig.4 and Eq.2, we calculate two independent spatial attention maps for the features of the input X-ray images. Then we regard one of these two attention maps as the positive attention map (map+) and use MSE Loss to constrain it with its corresponding mask (mask+). After normalization, the values of the area containing lesions in the mask are 1 and the values of other areas are 0. The purpose of such processing is to drive the distribution of weights in the positive attention map as similar as possible to the value distribution in the mask. At the same time, we drive the positive attention map to stay away from the inverted mask (mask-) as far as possible. So, as indicated by Eq.2, we also calculate MSE Loss between the the positive attention map and its inverted mask, and then put the loss function on the denominator of the fraction. Similarly, as shown in Eq.3, MSE Loss is used to constrain another attention map and its inverted mask (mask-), and a negative attention map (map-) is obtained. The weights of this attention map are distributed outside the lesion area, which is opposite to map+.\nLatt+ = MSE(map+,mask+)\nMSE(map+,mask\u2212) (2)\nLatt\u2212 =MSE(map\u2212,mask\u2212) (3)\nThe total loss function for mask-guided hard attention with contrastive regulation is as follow:\nLatt cr = Latt+ + Latt\u2212 (4)\nWe also use contrastive regulation to constrain the attentionweighted features. The specific method is as follows:: multiplying the input features with the positive attention map and negative attention map, wihch contain respectively the positive attention weights and negative attention weights, to obtain the features weighted by the positive attention and negative attention maps. According to the rule of contrastive learning [25], we expect that the attention weight distribution of the original input features should be as similar as possible to the features integrated with positive attention weights, and at the same time dissimilar to the features weighted by negative attention.\nIn order to achieve this goal, we construct a loss function as shown in Eq.5. For the anchor features, L1 Loss is used to constrain them and the two features weighted respectively by the positive and negative attention maps. In order to drive the\n6 anchor features as similar as possible to the positive features, we put the calculated loss between the anchor features and the positive features in the numerator of the fraction to learn the positive features, and in order to make the anchor feature as dissimilar as possible from the negative features and far from them, we put the calculated loss between anchor feature and negative feature in the denominator, so that the three kinds of features can form a contrastive constraint.\nLfeat cr = L1(feat, feat \u2217map+) L1(feat, feat \u2217map\u2212)\n(5)\nTherefore, the total loss function for the proposed Maskguided Attention with Contrastive Regulation (MGACR) module is as follow:\nLmgacr = Latt cr + Lfeat cr (6)\nThrough this proposed attention module, the network can learn the latent pattern from the diagnostic experience of the doctors, and focus on the particular regions (the lesion regions) in the X-ray image where the clinician would normally focus. In a word, that is learning to see where the doctors want to see."
        },
        {
            "heading": "D. Class-Balanced Focal Loss",
            "text": "As mentioned before, in the pneumonia X-ray dataset, the images of normal cases without pneumonia account for the majority, while the images of other kinds of pneumonia only account for a small part, and the images of some rare pneumonia types are even negligible. In order to solve this problem of class imbalance among various categories of data in the field of medical image recognition, Class-Balanced Focal Loss [39] has been introduced as the loss function of classification task in the field of computer vision during the re-training stage to replace the traditional Cross-Entropy Loss.\nCE(pt) = \u2212log(pt) (7)\nFL(pt) = \u2212(1\u2212 pt)\u03b3 log(pt) (8)\nAs shown in Eq.7 and Eq.8, Focal Loss (FL) [18] applies a modulating factor (1 \u2212 pt)\u03b3 to the Cross-Entropy (CE) Loss in order to focus more learning on hard examples and down-weight the numerous easy negative samples. Focal Loss can successfully address the problem of class imbalance by reshaping the standard cross entropy loss such that it downweights the loss assigned to well-classified examples.\nCBfocal(pt) = \u2212 1\u2212 \u03b2 1\u2212 \u03b2ny (1\u2212 pt)\u03b3 log(pt) (9)\nAs shown in Eq.9, we adopt Class-Balanced Focal Loss [39] as our loss function of classification in the re-training stage. The original focal loss has an balanced variant, that is (1\u2212pt)\u03b3 . Class-Balanced Focal Loss introduces another factor (1\u2212\u03b2)/(1\u2212\u03b2ny ) to Focal Loss based on the effective number of samples [39].\n(a) Loss in pre-training stage (b) Accuracy in pre-training stage\nFig. 6. The change trend of loss and accuracy in self-supervised contrastive learning pre-training process."
        },
        {
            "heading": "V. EXPERIMENTS",
            "text": "A. Implementation details\nWe used the PyTorch to train our model on an Nvidia TITAN XP GPU. The SGD optimizer was used for the training, the batch-size was set to 16 and the resolution of the image was rescaled from 1024x1024 to 224x224. We adopted ResNet18 as the backbone of our model. The number of the four residual blocks is set to [2, 2, 2, 2], which is a standard setting of ResNet18 according to [21]."
        },
        {
            "heading": "B. Ablation study and analysis",
            "text": "As shown in Fig.6, in the contrastive learning pre-training stage, after about 4 epochs of self-supervised training, the process of contrastive learning pre-training converged and the accuracy reached up to 100\nAs shown in Fig.7, we adopted ResNet18 as the backbone. We conducted ablation experiment, and added four techniques in the training process to observe the change trend of accuracy with the training time. It can be seen that the effect of training a single ResNet18 classifier without adding any techniques is worse than that of training with techniques, but the training costs less computation resources. In contrast, after adopting\n7\nTABLE I THE EXPERIMENTAL RESULTS OF OUR MODEL. WE CONDUCTED THE ABLATION STUDY FOR ALL FOUR TECHNIQUES.\nBackbone Image Size CL Pre-Train Mask-guided Attention Feature Learning with CR CB Focal Loss Accuracy (%) Boost (%) ResNet18 224x224 - - - - 79.10 - ResNet18 224x224 X - - - 80.15 1.05 \u2191 ResNet18 224x224 X X - - 81.10 0.95 \u2191 ResNet18 224x224 X X X - 82.40 1.30 \u2191 ResNet18 224x224 X X X X 83.85 1.45 \u2191\nTABLE II COMPARISON WITH OTHER MACHINE LEARNING AND DEEP LEARNING METHODS.\nMethods KNN Decision Tree AdaBoost Random Forest SVM poly VGG16 ResNet18 ResNet50 Deep Pneumonia Accuracy (%) 75.85 68.90 72.60 79.75 76.58 80.10 79.10 80.95 83.85\nTraining Time (min) 25 136 72 46 360 105 98 186 92\nself-supervised contrastive learning strategy to pre-train the backbone, we found that not only the accuracy was improved, but also the convergence was much faster than that without contrastive learning pre-training. This is because after the selfsupervised pre-training in the first stage, the feature extraction capability of backbone in the second stage is better than that of the backbone directly trained from scratch, so the accuracy is improved, and after the pre-training, the model converges faster during the re-training. The accuracy of the model is also improved after adding Mask-guided Hard Attention and Feature Learning with Contrastive Regulation (CR), because as shown in Fig.9, these two techniques guide and drive the network to pay more attention to the lesion regions, which contains more discriminative features. In terms of convergence speed, compared with that without Mask-guided Hard Attention and Feature Learning with CR, the network with these two techniques converges faster in the training process, because during the training, masks are used as the guidance to guide the correct training direction, and contrastive regulation is used as the constraint, which is equivalent to providing a positive pull force and a driving force for the training. All these factors accelerate the convergence speed\n(a) X-ray image with marked lesion (b) The corresponding attention map\nFig. 9. Visual results of attention map. We used Grad-CAM [41] to visualize the activation heatmap of the model. Note that by visualizing the heat map of attention, we can detect the lesion area indirectly, and help doctors to locate the lesion area for the better diagnosis.\nof network training. After Class-Balanced (CB) Focal Loss was added, although the accuracy was greatly improved, the convergence speed became slower, because CB Focal Loss needs to estimate the effective number of samples during training, and then conduct the re-weighting scheme. Note that Mask-guided Hard Attention and Feature Learning with CR only costs computation resources during the training phase, and the MGACR module can be discarded when the model conducts forward inference, which aims to help the model be better trained, so it costs no computation burden during the testing and inference phases. In general, as shown in Table.I, these four techniques can improve accuracy very well, and the introduced extra computation burden is not too large. These four techniques have solved three common problems and challenges well in medical images and achieve promising performance."
        },
        {
            "heading": "C. Comparison study",
            "text": "As shown in Table.II and Fig.8, we compared our method with several other machine learning and deep learning methods, the machine learning models were trained with a CPU on a high-performance server, and the deep learning models were trained on a GPU. It can be seen that our proposed method achieves good results in the accuracy, and the training time cost is also low, too.\n8 CONCLUSION\nIn this paper, we proposed a framework named AttentionBased Contrastive Learning for Class-Imbalanced X-Ray Pneumonia Lesion Recognition (denoted as Deep Pneumonia). In order to solve the problems of difficult acquisition of medical X-ray image data and small amount of this available data, we adopted self-supervised contrastive learning for pretraining, and fully learned and utilized existing datasets without using additional data to pre-train a powerful feature extractor. We proposed mask-guided hard attention mechanism and feature learning with contrastive regulation strategy to guide and drive the network to focus more attention on the lesion area where contains more discriminative features for solving the problem that the location information of lesions marked by doctors is not effectively utilized in pneumonia recognition. In order to solve the challenge of class-imbalanced dataset in medical image recognition, we adopted Class-Balanced Focal Loss to re-weight the loss weights during training. All in all, we hope this work can provide some heuristic ideas and inspiration to solve the common challenges in medical image recognition and help doctors better diagnose pneumonia in practice."
        }
    ],
    "title": "Deep Pneumonia: Attention-Based Contrastive Learning for Class-Imbalanced Pneumonia Lesion Recognition in Chest X-rays",
    "year": 2022
}