{
    "abstractText": "This study proposes a deep transfer learning method using a deep convolutional neural network pre-trained with ImageNet for transient stability assessment. The procedure of deep transfer learning, incorporating the role and considerations of the transient stability assessment system, is suggested. The transient assessment system learns the relationship between the severity of disturbances and transient stability in the power system through the proposed training method. The severity of a disturbance based on the physical causal relationship of the angle stability is proposed to train and implement the transient stability assessment model. The power system state variables obtained from the phasor measurement unit are converted into the feature map described by the severity of a disturbance, enabling the training of transient stability characteristics of the power system to the deep convolutional neural network. The training dataset is constructed using the time-domain simulation on IEEE 39 and IEEE 118-bus benchmark power system models configured in MATLAB/Simulink. As a result of deep transfer learning, which involves training with freezing some of the convolutional layers of the pre-trained deep network, the most suitable model for transient stability assessment is selected among the pre-trained deep networks. The effectiveness of the proposed method is compared with other approaches using the confusion matrix, and the robustness against noise interference is also investigated. INDEX TERMS Transient stability assessment, Deep transfer learning, Pre-trained deep convolutional neural network, VGG, Power system stability, Deep learning, ImageNet",
    "authors": [
        {
            "affiliations": [],
            "name": "Jongju Kim"
        },
        {
            "affiliations": [],
            "name": "Sungshin Kim"
        },
        {
            "affiliations": [],
            "name": "June Ho Park"
        }
    ],
    "id": "SP:2ce5e62e58d2e978a2a7b79046686c6334a68605",
    "references": [
        {
            "authors": [
                "P. Kundur",
                "J. Paserba",
                "V. Ajjarapu",
                "G. Andersson",
                "A. Bose",
                "C. Canizares",
                "N. Hatziargyriou",
                "D. Hill",
                "A. Stankovic",
                "C. Taylor"
            ],
            "title": "Definition and classification of power system stability IEEE/CIGRE joint task force on stability terms and definitions",
            "venue": "IEEE Transactions on Power Systems, vol. 19, no. 3, pp. 1387-1401, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "N. Hatziargyriou",
                "J. Milanovic",
                "C. Rahmann",
                "V. Ajjarapu",
                "C. Canizares",
                "I. Erlich",
                "D. Hill",
                "I. Hiskens",
                "I. Kamwa",
                "B. Pal"
            ],
            "title": "Definition and classification of power system stability\u2013revisited & extended",
            "venue": "IEEE Transactions on Power Systems, vol. 36, no. 4, pp. 3271-3281, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "A. Fouad",
                "S. Stanton"
            ],
            "title": "Transient stability of a multi-machine power system. Part II: Critical transient energy",
            "venue": "IEEE Transactions on power apparatus and systems, no. 7, pp. 3417-3424, 1981.",
            "year": 1981
        },
        {
            "authors": [
                "A. Fouad",
                "V. Vittal",
                "T.K. Oh"
            ],
            "title": "Critical energy for direct transient stability assessment of a multimachine power system",
            "venue": "IEEE Transactions on power apparatus and systems, no. 8, pp. 2199- 2206, 1984.",
            "year": 1984
        },
        {
            "authors": [
                "H.-D. Chiang",
                "F.F. Wu",
                "P.P. Varaiya"
            ],
            "title": "A BCU method for direct analysis of power system transient stability",
            "venue": "IEEE Transactions on power systems, vol. 9, no. 3, pp. 1194-1208, 1994.",
            "year": 1994
        },
        {
            "authors": [
                "J.H. Chow",
                "A. Chakrabortty",
                "M. Arcak",
                "B. Bhargava",
                "A. Salazar"
            ],
            "title": "Synchronized phasor data based energy function analysis of dominant power transfer paths in large power systems",
            "venue": "IEEE Transactions on Power Systems, vol. 22, no. 2, pp. 727-734, 2007.",
            "year": 2007
        },
        {
            "authors": [
                "P. Bhui",
                "N. Senroy"
            ],
            "title": "Real-time prediction and control of transient stability using transient energy function",
            "venue": "IEEE Transactions on Power Systems, vol. 32, no. 2, pp. 923-934, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Machowski",
                "Z. Lubosny",
                "J.W. Bialek",
                "J. R"
            ],
            "title": "Bumby, Power system dynamics: stability and control",
            "year": 2020
        },
        {
            "authors": [
                "J. Rasmussen",
                "P. Jorgensen"
            ],
            "title": "Synchronized phasor measurements of a power system event in eastern Denmark",
            "venue": "IEEE Transactions on Power Systems, vol. 21, no. 1, pp. 278-284, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "N.I.A. Wahab",
                "A. Mohamed",
                "A. Hussain"
            ],
            "title": "Fast transient stability assessment of large power system using probabilistic neural network with feature reduction techniques",
            "venue": "Expert systems with applications, vol. 38, no. 9, pp. 11112-11119, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "F.R. Gomez",
                "A.D. Rajapakse",
                "U.D. Annakkage",
                "I.T. Fernando"
            ],
            "title": "Support vector machine-based algorithm for post-fault transient stability status prediction using synchronized measurements",
            "venue": "IEEE Transactions on Power Systems, vol. 26, no. 3, pp. 1474-1483, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "D. Huang",
                "X. Yang",
                "S. Chen",
                "T. Meng"
            ],
            "title": "Wide\u2010area measurement system\u2010based model\u2010free approach of post\u2010fault rotor angle trajectory prediction for online transient instability detection",
            "venue": "IET Generation, Transmission & Distribution, vol. 12, no. 10, pp. 2425-2435, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "M. Rahmatian",
                "Y.C. Chen",
                "A. Palizban",
                "A. Moshref",
                "W.G. Dunford"
            ],
            "title": "Transient stability assessment via decision trees and multivariate adaptive regression splines",
            "venue": "Electric power systems research, vol. 142, pp. 320-328, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "D. You",
                "K. Wang",
                "L. Ye",
                "J. Wu",
                "R. Huang"
            ],
            "title": "Transient stability assessment of power system using support vector machine with generator combinatorial trajectories inputs",
            "venue": "International Journal of Electrical Power & Energy Systems, vol. 44, no. 1, pp. 318-325, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "B. Wang",
                "B. Fang",
                "Y. Wang",
                "H. Liu",
                "Y. Liu"
            ],
            "title": "Power system transient stability assessment based on big data and the core vector machine",
            "venue": "IEEE Transactions on Smart Grid, vol. 7, no. 5, pp. 2561- 2570, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "H. Hosseini",
                "S. Naderi",
                "S. Afsharnia"
            ],
            "title": "New approach to transient stability prediction of power systems in wide area measurement systems based on multiple\u2010criteria decision making theory",
            "venue": "IET Generation, Transmission & Distribution, vol. 13, no. 21, pp. 4960- 4967, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A.B. Mosavi",
                "A. Amiri",
                "H. Hosseini"
            ],
            "title": "A learning framework for size and type independent transient stability prediction of power system using twin convolutional support vector machine",
            "venue": "IEEE Access, vol. 6, pp. 69937-69947, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S. Ma",
                "C. Chen",
                "C. Liu",
                "Z. Shen"
            ],
            "title": "A measurement-simulation hybrid method for transient stability assessment and control based on the deviation energy",
            "venue": "International Journal of Electrical Power & Energy Systems, vol. 115, pp. 105422, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Wei",
                "M. Yang",
                "J. Qi",
                "J. Wang",
                "S. Ma",
                "X. Han"
            ],
            "title": "Model-free MLE estimation for online rotor angle stability assessment with PMU data",
            "venue": "IEEE Transactions on Power Systems, vol. 33, no. 3, pp. 2463-2476, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Lv"
            ],
            "title": "Transient stability assessment in large-scale power systems based on the sparse single index model",
            "venue": "Electric Power Systems Research, vol. 184, pp. 106291, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S.M. Ashraf",
                "S. Chakrabarti"
            ],
            "title": "A single machine equivalentbased approach for online tracking of power system transient stability",
            "venue": "IEEE Transactions on Power Systems, vol. 36, no. 3, pp. 1688-1696, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "L. Zhu",
                "D.J. Hill"
            ],
            "title": "Networked time series shapelet learning for power system transient stability assessment",
            "venue": "IEEE Transactions on Power Systems, vol. 37, no. 1, pp. 416-428, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "R. Zhang",
                "Y. Xu",
                "Z.Y. Dong",
                "K.P. Wong"
            ],
            "title": "Post\u2010disturbance transient stability assessment of power systems by a self\u2010adaptive intelligent system",
            "venue": "IET Generation, Transmission & Distribution, vol. 9, no. 3, pp. 296-305, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "M. Mahdi",
                "V.I. Genc"
            ],
            "title": "Post-fault prediction of transient instabilities using stacked sparse autoencoder",
            "venue": "Electric Power Systems Research, vol. 164, pp. 243-252, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S. Jafarzadeh",
                "V.I. Genc"
            ],
            "title": "Real-time transient stability prediction of power systems based on the energy of signals obtained from PMUs",
            "venue": "Electric Power Systems Research, vol. 192, pp. 107005, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Wu",
                "L. Zheng",
                "W. Hu",
                "R. Yu",
                "B. Liu"
            ],
            "title": "Improved deep belief network and model interpretation method for power system transient stability assessment",
            "venue": "Journal of Modern Power Systems and Clean Energy, vol. 8, no. 1, pp. 27-37, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "B.P. Soni",
                "A. Saxena",
                "V. Gupta",
                "S. Surana"
            ],
            "title": "Identification of generator criticality and transient instability by supervising real-time rotor angle trajectories employing RBFNN",
            "venue": "ISA transactions, vol. 83, pp. 66-88, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. LeCun",
                "L. Bottou",
                "Y. Bengio",
                "P. Haffner"
            ],
            "title": "Gradient-based learning applied to document recognition",
            "venue": "Proceedings of the IEEE, vol. 86, no. 11, pp. 2278-2324, 1998.",
            "year": 1998
        },
        {
            "authors": [
                "S. Hochreiter",
                "J. Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural computation, vol. 9, no. 8, pp. 1735-1780, 1997.",
            "year": 1997
        },
        {
            "authors": [
                "J. James",
                "D.J. Hill",
                "A.Y. Lam",
                "J. Gu",
                "V.O. Li"
            ],
            "title": "Intelligent timeadaptive transient stability assessment system",
            "venue": "IEEE Transactions on Power Systems, vol. 33, no. 1, pp. 1049-1058, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A. Gupta",
                "G. Gurrala",
                "P. Sastry"
            ],
            "title": "An online power system stability monitoring system using convolutional neural networks",
            "venue": "IEEE Transactions on Power Systems, vol. 34, no. 2, pp. 864-872, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S.K. Azman",
                "Y.J. Isbeih",
                "M.S. El Moursi",
                "K. Elbassioni"
            ],
            "title": "A unified online deep learning prediction model for small signal and transient stability",
            "venue": "IEEE Transactions on power systems, vol. 35, no. 6, pp. 4585-4598, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Huang",
                "L. Guan",
                "Y. Su",
                "H. Yao",
                "M. Guo",
                "Z. Zhong"
            ],
            "title": "Recurrent graph convolutional network-based multi-task transient stability assessment framework in power system",
            "venue": "IEEE Access, vol. 8, pp. 93283-93296, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Xie",
                "W. Sun"
            ],
            "title": "A transfer and deep learning-based method for online frequency stability assessment and control",
            "venue": "IEEE Access, vol. 9, pp. 75712-75721, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "D.E. Rumelhart",
                "G.E. Hinton",
                "R.J. Williams"
            ],
            "title": "Learning representations by back-propagating errors",
            "venue": "nature, vol. 323, no. 6088, pp. 533-536, 1986.",
            "year": 1986
        },
        {
            "authors": [
                "K.P. Murphy"
            ],
            "title": "Machine learning: a probabilistic perspective",
            "venue": "MIT press,",
            "year": 2012
        },
        {
            "authors": [
                "O. Russakovsky",
                "J. Deng",
                "H Su"
            ],
            "title": "ImageNet Large Scale Visual Recognition Challenge.",
            "venue": "International Journal of Computer Vision (IJCV)",
            "year": 2015
        },
        {
            "authors": [
                "A. Krizhevsky",
                "I. Sutskever",
                "G.E. Hinton"
            ],
            "title": "Imagenet classification with deep convolutional neural networks",
            "venue": "Communications of the ACM, vol. 60, no. 6, pp. 84-90, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "S.J. Pan",
                "Q. Yang"
            ],
            "title": "A survey on transfer learning",
            "venue": "IEEE Transactions on knowledge and data engineering, vol. 22, no. 10, pp. 1345-1359, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "M. Iman",
                "H.R. Arabnia",
                "K. Rasheed"
            ],
            "title": "A review of deep transfer learning and recent advancements",
            "venue": "Technologies, vol. 11, no. 2, pp. 40, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "H. Cui",
                "Q. Wang",
                "Y. Ye",
                "Y. Tang",
                "Z. Lin"
            ],
            "title": "A combinational transfer learning framework for online transient stability prediction",
            "venue": "Sustainable Energy, Grids and Networks, vol. 30, pp. 100674, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K. Simonyan",
                "A. Zisserman"
            ],
            "title": "Very deep convolutional networks for large-scale image recognition",
            "venue": "arXiv preprint arXiv:1409.1556, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "B. Neyshabur",
                "H. Sedghi",
                "C. Zhang"
            ],
            "title": "What is being transferred in transfer learning",
            "venue": "Advances in neural information processing systems, vol. 33, pp. 512-523, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Yosinski",
                "J. Clune",
                "Y. Bengio",
                "H. Lipson"
            ],
            "title": "How transferable are features in deep neural networks",
            "venue": "Advances in neural information processing systems, vol. 27, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "S. Bianco",
                "R. Cadene",
                "L. Celona",
                "P. Napoletano"
            ],
            "title": "Benchmark analysis of representative deep neural network architectures",
            "venue": "IEEE access, vol. 6, pp. 64270-64277, 2018.",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "VOLUME XX, 2017 1\nnetwork pre-trained with ImageNet for transient stability assessment. The procedure of deep transfer learning, incorporating the role and considerations of the transient stability assessment system, is suggested. The transient assessment system learns the relationship between the severity of disturbances and transient stability in the power system through the proposed training method. The severity of a disturbance based on the physical causal relationship of the angle stability is proposed to train and implement the transient stability assessment model. The power system state variables obtained from the phasor measurement unit are converted into the feature map described by the severity of a disturbance, enabling the training of transient stability characteristics of the power system to the deep convolutional neural network. The training dataset is constructed using the time-domain simulation on IEEE 39 and IEEE 118-bus benchmark power system models configured in MATLAB/Simulink. As a result of deep transfer learning, which involves training with freezing some of the convolutional layers of the pre-trained deep network, the most suitable model for transient stability assessment is selected among the pre-trained deep networks. The effectiveness of the proposed method is compared with other approaches using the confusion matrix, and the robustness against noise interference is also investigated.\nINDEX TERMS Transient stability assessment, Deep transfer learning, Pre-trained deep convolutional neural network, VGG, Power system stability, Deep learning, ImageNet\nI. INTRODUCTION\nIn line with the global trend of carbon neutrality, the proportion of renewable power generation in power systems has continuously increased. However, the output fluctuation of renewable power generation dependent on nature adds to difficulties in power generation operation. Additionally, although the continuous increase in the electricity demand causes the need for additional generation reserves, power generation facilities are gradually becoming intensive owing to the difficulty in securing new power generation sites, leading to the concentration of power flow. As changes in the operating environment of power systems accelerate, various uncertainties faced by power systems pose a major threat to stability, and there is a growing need for appropriate countermeasures to overcome the limitations of passive protection and control technologies of existing sequential operations. First of all, real-time\nanalysis of the current state of the power system is required to operate the power system securely. Real-time stability assessment would improve stability by guiding power system operators to perform emergency control and remedial actions at an early stage and resolve inefficiency induced by stability constraints in power system operation. In this regard, although the importance of power system stability assessment has been continuously recognized, the area of real-time assessment remains a great challenge, primarily due to limitations in computing resources.\nA power system is a combination of various types of dynamic systems to seek energy balance against continuous changes and disturbances. Stability is the ability to regain a state of operating equilibrium from various disturbances [1], [2]. So as to assess transient stability, it is necessary to interpret the complex dynamic characteristics of the components in a power system. Until now, the most\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\naccurate method to verify power system stability is to carry out the time-domain simulation on a case-by-case basis for various disturbances. However, given that requiring an accurate model of the power system, including the control system, the parameter of the component, and the network, and solving high-dimensional nonlinear differentialalgebraic equations required considerable computer resources [1], the simulation of all possible disturbances in real-time is unfeasible.\nBased on the energy function, an approach to find the stable region of the power system and assess the stability through the state trajectory of the power system after a disturbance was demonstrated [3]. In this regard, an accurate controlling unstable equilibrium point for disturbance was attained for stability analysis in [4], [5]. State data acquisition using the phasor measurement unit (PMU) was considered [6], and a technique for constructing a lookup table for the real-time application was also suggested [7]. However, when applied to large power systems, energy functions are vulnerable to numerical problems in some areas and are somewhat difficult to use in real-time due to modeling limitations and the unreliability of computational techniques [8].\nDeployment of the PMUs provides very high sampling and accurate dynamic state variables with the power system operation system [9]. As a result, machine learning technology began to be used for transient stability assessment (TSA) in earnest. The stability classifications through the neural network [10], support vector machine (SVM) [11], curve fitting [12], and decision tree [13] were proposed. SVMs have been widely used for classification problems with their excellent learning speed and accuracy. In [14], a performance comparison of SVM classifiers using multiple state variables of the generator was conducted, and Wang et al. utilized a core vector machine that can solve the classification problem with a higher dimension than the SVM for transient stability classification [15]. In addition, methods linking the SVM with the Fuzzy analytical hierarchy process [16] and convolutional neural network (CNN) [17] were also conducted. Although SVMs exhibit excellent performance in a normal-size dataset, the scalability of the classification model in the case of the accumulation of datasets remains somewhat insufficient.\nFurther, Ma et al. suggested a hybrid technique of determining and quantifying stability by comparing with measured values based on simulation results based on the equal area criterion [18]. An approach to predict transient stability based on the maximal Lyapunov exponent estimated by a recursive least squares-based method was proposed [19]. In [20], a nonlinear semiparametric model obtained with the LASSO algorithm was used for transient stability analysis. Besides, Ashraf classified critical machines through one machine infinite bus transformation and carried out rotor angle prediction with the Kalman filter [21], and in [22], stability classification through networked\nshapelet learning based on the inherent spatial-temporal correlations of power systems was carried out.\nSince the perceptron was introduced, approaches using neural networks for the classification problem have been continuously attempted. Research about constructing a model for classifying sequence data by organizing individual classification neural networks in parallel [23], assessing the stability using the stacked sparse autoencoder as a feature extractor [24], a training method of including a dimension of time in the input state variables [25], an assessment model stacked with restricted Boltzmann machines [26], and radial basis function neural networkbased model to determine the criticality level of the generators [27] were suggested.\nCNN [28] and long short-term memory (LSTM) [29] have demonstrated excellent performance in image and sequence data recognition, respectively, creating an opportunity for the widespread use of artificial intelligence technology. Accordingly, CNN and LSTM have been applied to TSA and achieved high accuracy. Notably, a study on determining transient stability with LSTM specialized in processing sequence data and methods of converting state data into an image format to utilize CNN were presented [30]\u2013[32]. In [33]\u2013[35], the performance of classifying transient stability was further enhanced by combining CNN with LSTM.\nThe significance of the approaches suggested so far is clear. Nonetheless, considering the crucial role of TSA in power systems, inconsistent assessment timing and relatively long response time after the fault clearing should be supplemented. To be considered for practical application, improving the accuracy and response time of TSA is crucial to provide sufficient time for emergency control or remedial action immediately after the assessment. Most importantly, as training data accumulates persistently, designing the model with the potential for advancement is necessary.\nGiven that time-domain simulation is the most accurate method to assess transient stability of power systems, a deep neural network-based TSA using the time-domain simulation results can be an alternative to satisfy accuracy, feasibility, and responsiveness. However, in order to learn numerous hyperparameters to use a deep neural network, not only a vast amount of dataset is required, but also an appropriate design of the network structure should be premised so that the gradient of the error can be effectively propagated during the process of learning through the backpropagation algorithm [36].\nIn this study, in order to overcome these limitations and build a high-performance stability assessment system, a pre-trained deep convolutional neural network (PDCNN) is applied to TSA. Deep transfer learning (DTL), which brings the backbone of a neural network model trained with a large-scale dataset and applies it to another field, can overcome the insufficiency of the training dataset and\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nprovide significant usefulness in designing neural networks for TSA.\nThe contributions of this paper are:\n1) As the first attempt at DTL of a deep CNN trained with\nImageNet for power system stability assessment, the method and criterion of exploiting a PDCNN to TSA are proposed. 2) The TSA system is constructed by learning the\nproposed disturbance severity index, which possesses the physical characteristics of angle stability. The disturbance severity index synergizes with the excellent classification competence of the deep CNN, resulting in fast response time and high accuracy in the assessment. 3) In this study, an attempt to apply deep CNN pre-trained\nwith completely different tasks to transient stability assessment through fine-tuning proves that DTL is a way to alleviate the need for vast amounts of the training dataset, which is a prerequisite for training deep neural networks. The remainder of the paper is organized as follows. Section II establishes the primary considerations and proposed approach for constructing the TSA system using the neural network. The background of DTL for TSA is addressed in Section \u2162. Section \u2163 examines the theoretical basis for configuring the training dataset and processing the PMU data. The detailed process of constructing the TSA model through fine-tuning is addressed in Section V. In Section \u2165, the performance of the proposed method is verified and compared with previous studies."
        },
        {
            "heading": "II. CONSIDERATIONS FOR TRANSIENT STABILITY ASSESSMENT USING NEURAL NETWORKS",
            "text": "In previous research, neural networks of various structures have been applied, and in particular, studies using LSTM and CNN constitute the majority. In implementing TSA using artificial intelligence technology, there are essential options that affect performance and feasibility. Because those options are issues that still need to be resolved and cause various difficulties in adopting the neural network-based TSA in an actual power system, the following must be considered to move forward from previous studies."
        },
        {
            "heading": "A. OBSERVATION WINDOW AND STABILITY DECISION THRESHOLD",
            "text": "A compromise about the period of the observation window (OW), which is the temporal range of input data, must be found in the trade-off relationship between the accuracy and the timing of the stability decision. Moreover, the OW determines the size of the input data of the neural network; thus, it is a factor that significantly affects the structure of the neural network.\nThe setting of the stability decision threshold (SDT) influences the performance of the TSA system due to acting as a criterion for assessing stability from the inference result\nof the trained neural network. Notwithstanding these two hyperparameters play a critical role in the neural networkbased stability assessment, the OW and SDT, whose value was experimentally set depending on each case study of the power system model and training data, as shown in Table \u2160, make it challenging to exploit the TSA system to an actual power system."
        },
        {
            "heading": "B. TRADE-OFF BETWEEN ACCURACY AND TIMING",
            "text": "Given that transient stability becomes apparent over time after a power system is affected by a severe disturbance in conformity with the physical nature of synchronous operation between synchronous generators, the temporal feature (the length of the OW) of input data significantly impacts the accuracy and timing of a decision, i.e., tending to be less accurate as it gets shorter. The inference timing, as well as accuracy, is crucial in the TSA system because the prompt assessment can provide sufficient time to perform emergency control in power systems. Previous studies found a compromise between the accuracy and the decision timing through several attempts comparing simulation results. Still, it cannot be asserted that the compromise is an appropriate point that can be used as it is in other data (i.e., other power systems)."
        },
        {
            "heading": "C. NEURAL NETWORK DEPTH AND STRUCTURES",
            "text": "The detailed structure of a network suitable for a specific purpose can only be found by trial and error by referring to various research [37]. Although the general characteristics have been confirmed through a recent study on the correlation of network depth and performance [38], the detailed relationship between hyperparameters of a neural network is like a black box, making it difficult to grasp the exact causal relationship [39]. The TSA systems composed of limited training data in various studies face challenges in clearly elucidating the detailed structural features of neural networks and explaining why they exhibit good performance, as well as in determining which of the proposed models\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\npossesses a more efficient network structure. Moreover, it is very difficult to compare, verify, and select the best network structure that can be generalized because of differences in terms of benchmark models, detailed data acquisition scenarios, and data scales for each research."
        },
        {
            "heading": "D. TRAINING DATA INSUFFICIENCY AND VARIABILITY",
            "text": "In order to build a TSA system with a neural network, a large number of training data consisting of state data of power systems experiencing various disturbances, which is enough to train a neural network, should be prepared. However, in actual power systems, there are few unstable cases due to tightly designed protection systems, reserve allocation, and operational technologies that prevent the blackout; thus, time-domain simulation results for various disturbances are inevitably used for training a neural network. Moreover, as operation data of the power system will have been accumulated in the database and the amount of the data gradually increases, model performance improvement would be required through additional training. As such, the TSA model should be able to fully generalize transient stability characteristics even with limited training datasets and steadily expand the model through additional training against the continuous accumulation of operational data, although these two aspects may be in conflict.\nA neural network model can learn more complex phenomena as it has a large number of hyperparameters, whereas it also requires a large amount of data to be learned sufficiently [37]. In the case of training a simple neural network using the initially obtained small-scale training dataset, the neural network exhibits good performance for the moment, while the performance improvement is inevitably limited when the training dataset is extended. On the other hand, if a deep neural network is indiscriminately used, the neural network cannot be sufficiently trained due to the amount of the training dataset, and thus the expected performance cannot be reached."
        },
        {
            "heading": "E. PROPOSED APPROACHES FOR ADDRESSING ISSUES",
            "text": "The main issues are summarized as follows:\n1) Determination of the OW and the SDT. 2) The compromise between the accuracy and the\ndecision timing of TSA.\n3) Design of a suitable neural network structure: A neural\nnetwork model that can be trained with small-scale data and grow by continuously learning about the increase in the amount of training data.\nThe methods proposed in this paper to cope with the\nconsiderations and issues are as follows: 1) Application of deep CNN through DTL: overcoming\nthe variability of the training dataset and securing a neural network model possessing the finest performance. 2) Construct an adequate training dataset so as to avoid\nsetting experimentally determined hyperparameters such as the OW and the SDT and exert the capability of a deep CNN on TSA."
        },
        {
            "heading": "III. DEEP TRANSFER LEARNING FOR TRANSIENT",
            "text": "STABILITY ASSESSMENT\nAs a neural network structure deepens, tasks to be learned can be hierarchically decomposed, complex problems can be replaced with simpler ones, and the feature information in data is transmitted hierarchically, contributing to efficient learning [37]. As the layer of CNN deepens, the extracted information becomes more abstract, and the object to which neurons respond changes from simple shape to advanced information, which is the basis for the outstanding performance of a deep CNN [40], [41]. Nevertheless, training a deep neural network requires a vast amount of training data and computing resources. Furthermore, the design of a deep neural network is a significantly complicated task, and if it is designed to possess a deep structure, problems such as vanishing gradient and overfitting would frequently occur during the training process. In this way, designing and verifying a deep neural network by considering various aspects, including training availability, training time and performance, efficiency, and the number of hyperparameters, requires much effort. Notwithstanding, through DTL, the deep neural networks that are impossible to be trained with only the moderate-scale training dataset (i.e., used in previous studies [30]\u2013[35]) can be fine-tuned and applied to TSA. DTL can be an excellent alternative when training data is relatively small, such as in a power system, and available computing resources are limited."
        },
        {
            "heading": "A. DEEP TRANSFER LEARNING",
            "text": "The ILSVRC (ImageNet Large-Scale Visual Recognition Challenge) is an image recognition competition that classifies ImageNet [42], comprising 1,200,000 image data (see Fig. 1) in 1000 categories [43]. Because the same data is used to comparatively analyze the overall performance of the models, such as the training speed, the size, parameters, and the top-1 and top-5 accuracy, the best-performing model in the field of image recognition is identified. Since AlexNet [44] won in 2012, CNN-based models have been winning so far, and recently, top-ranked models tend to design the structure of neural networks deeper based on deep learning in earnest.\nTransfer learning is motivated by the fact that people can intelligently apply knowledge learned previously to solve new problems faster or with better solutions [45]. It is a valuable method in AI technology to overcome insufficient training data. This method extracts the knowledge from the source task (i.e., ImageNet classification) and applies it to a target (new) task. Research in which PDCNNs with ImageNet have been successfully deep transfer learned in various fields such as medical image, mechanics, physics, and civil engineering can be found [46]. Still, there has yet to be a case where DTL has been used in power systems.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nAlthough some studies have partially confirmed the applicability [35], [47], it was limited to cases where transfer learning was performed within a larger simulation model for the neural network learned in the study. It is not an attempt to transfer-learn the representative neural networks trained with ImageNet, such as AlexNet, GoogLeNet [48], ResNet [49], and VGG [50], and apply them to the field of power system stability. The structures of CNNs for TSA used in previous studies are mostly 2, 3, and 4 convolution layers, in contrast to having 5\u201381 convolution layers, which are representative deep CNN models (see Table II).\nWhile the depth of the layer cannot be the sole criterion for the classification performance of neural network models, it is evident that deep neural networks, in general, are capable of modeling more complex features [37], [51]. DTL is simultaneously capable of solving the insufficiency of training data and the difficulty of designing an appropriate deep network in applying deep networks to TSA. The expected merits of DTL for TSA are summarized as follows: 1) Accurate and fast response assessment by the excellent\nimage recognition ability of the deep CNN.\n2) Addressing the lack of training dataset, the need for\nlarge-scale computing resources to train deep networks, excessive training time, and concerns about overfitting.\n3) Scalability to improve performance through additional\nlearning when the amount of training data enlarges continuously due to the acquisition of training data in the future. 4) The state-of-the-art high-performance deep CNNs that\nhave consistently been developed in the field of image recognition can be applied to assess transient stability through the process proposed in this paper. There is no need for additional consideration of hyperparameters related to network structure. As the image recognition ability of the deep CNN improves, the performance of TSA is also enhanced."
        },
        {
            "heading": "B. FINE-TUNING",
            "text": "Fine-tuning is re-training a deep neural network pre-\ntrained with a vast dataset (e.g., ImageNet) into a new dataset\nsuitable for other tasks. Given that the PDCNN is used as a\nbackbone and only a few layers are initialized and trained,\nthe SGDM, which generally carries out stable learning, is set\nat a very small learning rate and used for fine-tuning. The\ninitial layers of a trained deep neural network preserve\ngeneral features applicable to other tasks, while the deep\nlayers have features that are more specialized for the target\ntasks [51], [52]. When performing fine-tuning to apply a pre-\ntrained deep network to a new task, these characteristics are\nthe foundation for dividing networks into frozen or learnable\nlayers. As shown in Fig. 2, the depth of the learnable layer of\na neural network to be trained is generally determined by\ncomparing the size of the new training data and its similarity\nto the dataset used for pre-training [53]."
        },
        {
            "heading": "C. PRE-TRAINED DEEP CONVOLUTIONAL NEURAL NETWORK SELECTION FOR TRANSIENT STABILITY ASSESSMENT",
            "text": "The method of constructing the DTL-based TSA is illustrated in Fig. 3. Candidate models are selected from the PDCNNs on ImageNet (or other large-scale datasets), considering the\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nsystem environment to implement the TSA system in realtime (inference time within approximately 5ms). The most crucial consideration for applying the PDCNN to TSA is to select a suitable network that requires little time in the inference process, as transient stability should be determined in real-time from power system state variables. In general, the forward propagation of neural networks takes little time, but most of the deep CNN currently proposed for image recognition and classification have very large hyperparameters along with quite deep and complex structures; thus, consideration of inference time should be preceded in selecting networks. In addition to this, the image classification performance, the complexity of the structure, and the number of hyperparameters are considered. The candidate models that meet the priority criteria for real-time application are fine-tuned using the training dataset, which consists of state variables acquired from the power system model to be implemented, and then the most suitable model is selected through performance comparison. The networks arranged in Table III are selected as candidates for the realtime TSA model, considering inference speed and detailed specifications among various deep networks trained with ImageNet. All selected models are affirmed to achieve realtime performances from the inference time (i.e., response speed).\naAverage per-image inference time over 10 runs reported in [54]; bRelative rank with the top-1 accuracy of ImageNet validation among the models in this table."
        },
        {
            "heading": "IV. PROPOSED TRANSIENT STABILITY ASSESSMENT",
            "text": "SYSTEM\nWith the spread of PMUs, an environment where voltage phasors can be acquired in 1 cycle with an error rate of less than 1% has been established [55]. The PMU provides ease of real-time monitoring and data accumulation of the power system and is a suitable signal for machine learning-based real-time TSA. In this study, only these two types of state variables are considered as inputs of the neural network model, assuming that the PMU can acquire the magnitude and phase of each bus voltage. In a neural network-based model, the training dataset, data property, and pre-processing of the input variable are essential options that determine the performance of the neural network associated with the characteristics of the task and type of the neural network. In this section, the establishment of the training dataset that maximizes the utility of the PDCNN model is proposed."
        },
        {
            "heading": "A. TRAINING DATASET",
            "text": "In supervised learning of a neural network, the composition of input and its label, that is, the training dataset, is a process of determining the expected inference results through the model learned from the dataset and specifying the task of the model. In order to interpret and learn an intricate system in which various systems are organically combined, such as a power system, the training dataset should be constructed circumspectly based on physical relevance in particular. Likewise, given that the performance of the TSA system should be improved through enduringly additional learning from the operation data accumulated from the actual power system and the time-domain simulation, the critical consideration for building the neural network-based TSA system is that the training dataset should be able to be constructed from the state data of the actual power system as well. Considering these aspects, PMU-based state variables that can be easily accumulated and instantaneously acquired with high accuracy from the power system are most appropriate as input data, and the transient stability index can\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nclassify the stability from the input data and label whether stable or not [23].\nTSI = 360\u00b0 \u2212 |\ud835\udeff\ud835\udc5a\ud835\udc4e\ud835\udc65|\n360\u00b0 + |\ud835\udeff\ud835\udc5a\ud835\udc4e\ud835\udc65| \u00d7 100 (1)\nwhere \u03b4max is the maximum phase angle difference between any synchronous generators. Transient stability can be classified (i.e., labeled) as stable in TSI > 0, and its class label is tagged as 1; otherwise, as unstable in TSI \u2264 0, its class label is tagged as -1.\n\ud835\udcb4 = { 1(stable), TSI > 0\n\u22121(unstable), TSI \u2264 0 (2)"
        },
        {
            "heading": "1) POWER SYSTEM TRANSIENT STABILITY",
            "text": "Mathematically, transient stability of a power system is a problem to solve the following nonlinear differential equation [1], [8]\n?\u0307? = \ud835\udc1f(\ud835\udc31, \ud835\udc15, \ud835\udc61) (3)\n0 = \ud835\udc20(\ud835\udc31, \ud835\udc15, \ud835\udc61) (4)\n\ud835\udc31 = {\ud835\udc65\ud835\udc56|\ud835\udc56 = 1,2,\u22ef , \ud835\udc5b} \ud835\udc15 = {\ud835\udc49\ud835\udc4f|\ud835\udc4f = 1,2,\u22ef ,\ud835\udc5a}\n\ud835\udc31(\ud835\udc610) = \ud835\udc310, \ud835\udc49\ud835\udc4f = [|\ud835\udc49\ud835\udc4f| \ud835\udf03\ud835\udc4f] T\nwhere \ud835\udc31 \u2208 \u211d\ud835\udc27 are the state variables, x0 is the initial values of state variables, \ud835\udc61 \u2208 [\ud835\udc610, \ud835\udc47] is time, \ud835\udc15 \u2208 \u211d \ud835\udc26 are the algebraic variables (i.e., bus voltages), f(x) is a nonlinear differential equation, g(x) is a nonlinear algebraic equation, and the number of the generator and bus are n and m, respectively. Transient stability is identified from the maximum phase angle difference, \u03b4max, obtained from the state variable x. This is because the state variable x and the algebraic variable V are obtained through the solution of the nonlinear differential-algebraic equation:\n\ud835\udc31(\ud835\udc610 + \u2206\ud835\udc61) = \ud835\udc310 +\u222b \ud835\udc1f(\ud835\udc31, \ud835\udc15, \ud835\udc61) \ud835\udc610+\u2206\ud835\udc61\n\ud835\udc610\n\ud835\udc51\ud835\udc61 (5)\n0 = \ud835\udc20(\ud835\udc31(\ud835\udc610 + \u2206\ud835\udc61), \ud835\udc15(\ud835\udc610 + \u2206\ud835\udc61), \ud835\udc61) (6)\n|\ud835\udeff\ud835\udc5a\ud835\udc4e\ud835\udc65| = max \ud835\udc610\u2264\ud835\udc61<\ud835\udc47 |\ud835\udeff\ud835\udc56(\ud835\udc61) \u2212 \ud835\udeff\ud835\udc57(\ud835\udc61)| \ud835\udc56, \ud835\udc57 \u2208 \ud835\udc5b (7)\nwhere |\u03b4max| represents the maximum phase angle difference between any two generators. Connecting this behavior with the equal area criterion (see Fig. 4), widely known as a helpful method for an intuitive grasp of transient stability, the imbalance energy (area abcd in Fig. 4) stored during the fault period [tF, tC] appears as an increase in power angle (\u03b4max), i.e., a release of the stored energy (area defg in Fig. 4). On the other hand, if the fault is cleared at tC\u2032, the stability limit is exceeded owing to the energy accumulated during the difference of the fault clearing time (tC\u2032-tC). That is, the imbalance energy stored in the power system during the fault period (i.e., [tF, tC] or [tF, tC\u2032]) appears as a change in the state\nvariable x in the differential algebraic equation, and the trajectory of the algebraic variable V is obtained by solving the nonlinear algebraic equation.\nCollectively, concerning the physical aspect of energy accumulation and dissipation through the equal area criterion and the relationship between V and x of the nonlinear algebraic equation, the training dataset is constructed to model the correlation between the imbalance energy accumulated during the fault period expressed as V and the transient stability. The proposed training dataset is\n\ud835\udcd3\ud835\udc47\ud835\udc46\ud835\udc34 \u225c {(\ud835\udcb3\ud835\udc50\ud835\udc4e\ud835\udc60\ud835\udc52 , \ud835\udcb4\ud835\udc50\ud835\udc4e\ud835\udc60\ud835\udc52)|\ud835\udc50\ud835\udc4e\ud835\udc60\ud835\udc52 = 1,2,\u22ef ,\ud835\udc41\ud835\udc37} { \ud835\udce7 (input): accumulated imbalance energy\n\ud835\udce8 (label): transient stability index\n(8)\nwhere ND is the number of the fault case, \ud835\udcb3\ud835\udc50\ud835\udc4e\ud835\udc60\ud835\udc52 is the input of the training dataset, and \ud835\udcb4\ud835\udc50\ud835\udc4e\ud835\udc60\ud835\udc52 is the classification label of the dataset. In conclusion, through the training dataset for constructing the TSA model that exerts the assessment with input data solely during the fault period, the model learns how severe the disturbance occurs in the power system and the effects on generators (i.e., the angle stability). This model targets to assess transient stability immediately after the fault clearing in the power system, as provided in Fig. 5.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nAs depicted by the blue solid line box in Fig. 5, the size of\nthe observation window proposed in this study varies\ndepending on the duration of the fault. The TSA model is\ntrained using only the state data within the fault period,\nallowing it to assess transient stability immediately after the\nfault clears. In this method, it is possible to secure control\ntime for the power system operator to perform additional\ncountermeasures compared to other approaches due to the\nfast response time being made at TC1 and TC2 for TSA. On the other hand, in other approaches, as summarized in Table\n\u2160, fixed observation windows of 5 to 20 cycles (i.e., the\nyellow solid and dashed lines in Fig. 5) are used, and the\ninference results of the model are delayed until the SDT is\nmet. Other approaches using CNN and LSTM require\ndifferent waiting periods (i.e., observation window) for\neach case to enhance the accuracy of the assessment after\nfault clearing, leading to delays and uncertainty in the\nassessment timing, making it challenging to use the\nassessment result as an initiation trigger for emergency\ncontrol of the power system. Contrary to the response time\nof previous studies (see Table \u2160), the TSA model learned\nwith the proposed dataset is built to infer transient stability\nas soon as the fault clears in all cases and is suitable for\napplication in power system operation."
        },
        {
            "heading": "2) DISTURBANCE SEVERITY INDEX",
            "text": "So as to construct the training dataset, it is necessary to\nquantify the effect of disturbance on transient stability of\nthe power system. Taken together, the disturbance severity\nindex (DSI), which includes the location of faults, the\ndistribution of power flows, acceleration energy, and the\nfault duration, is defined. It can be obtained from time-\nseries status variables from the PMU. In (3) and (4), the\nalgebraic variable V, the voltage phasor acquired in real-\ntime from the PMU, is\n\ud835\udc15(\ud835\udc61\ud835\udc5d) = [|\ud835\udc7d|(\ud835\udc61\ud835\udc5d) \ud835\udf3d(\ud835\udc61\ud835\udc5d)] T (9)\n{\n|\ud835\udc7d|(\ud835\udc61\ud835\udc5d) = {|\ud835\udc49\ud835\udc4f||\ud835\udc4f = 1,2,\u22ef ,\ud835\udc5a}\n\ud835\udf3d(\ud835\udc61\ud835\udc5d) = {\ud835\udf03\ud835\udc4f|\ud835\udc4f = 1,2,\u22ef ,\ud835\udc5a}\n?\u0307?(\ud835\udc61\ud835\udc5d) = {?\u0307?\ud835\udc4f|\ud835\udc4f = 1,2,\u22ef ,\ud835\udc5a}\n?\u0307?\ud835\udc4f(\ud835\udc61\ud835\udc5d) \u225c \ud835\udf03\ud835\udc4f(\ud835\udc61\ud835\udc5d) \u2212 \ud835\udf03\ud835\udc4f(\ud835\udc61\ud835\udc5d \u2212 \u0394\ud835\udc47\ud835\udc46)\n\u0394\ud835\udc47\ud835\udc46\nwhere tp is the sampling time, \u2206TS is the sampling interval, the subscript b is the bus number, m is the total number of\nbuses, |V| is the magnitude of the bus voltage, \u03b8 is the phase\nof the bus voltage, and ?\u0307? is the phase angle change with\nrespect to the sampling interval. Because the voltage\ndistribution of the entire power system during the fault period\nis determined by factors such as the location of the voltage\nsource, line admittance, fault impedance, and fault location, it\ncan be observed that the voltage magnitude of all buses in the\nPMU conveys the information about the fault and network\nproperties. Also, the power flow is the function of voltages\nand phase angles, so the trajectories of voltages, phase angles,\nand derivatives of phase angles during the fault period are\ncaused by unbalanced energy under the influence of the fault;\nthus, these variables stand for the disturbance severity\ninfluencing the transient stability. From (9), the DSI is\ndefined as\n\ud835\udc6b\ud835\udc8a\ud835\udc94\ud835\udc95\ud835\udc96\ud835\udc93\ud835\udc83\ud835\udc82\ud835\udc8f\ud835\udc84\ud835\udc86 \ud835\udc94\ud835\udc86\ud835\udc97\ud835\udc86\ud835\udc93\ud835\udc8a\ud835\udc95\ud835\udc9a \ud835\udc8a\ud835\udc8f\ud835\udc85\ud835\udc86\ud835\udc99: \ud835\udc6b\ud835\udc7a\ud835\udc70 \u225c\n{[|\ud835\udc7d|(\ud835\udc58) \ud835\udf3d(\ud835\udc58) ?\u0307?(\ud835\udc58)] \ud835\udc47 | \ud835\udc58 = \ud835\udc61\ud835\udc39 , \ud835\udc61\ud835\udc39 + \u2206\ud835\udc47\ud835\udc46 , \u22ef , \ud835\udc61\ud835\udc36 \u2212 \u2206\ud835\udc47\ud835\udc46, \ud835\udc61\ud835\udc36}\n(10)\nwhere k is the sampling time, tF is the fault occurrence time, and tC is the fault clearing time. Collectively, as shown in Fig. 5, the DSI is the trajectory of the variables of the fault period, and the temporal range of data varies depending on the fault clearing time."
        },
        {
            "heading": "3) FEATURE MAP GENERATION",
            "text": "The power system time-series data acquired from the PMU should be converted into the appropriate type for the CNNbased model so that the PDCNN effectively recognizes the correlation between the trajectory of power system state data and the transient stability. As shown in Fig. 6, the DSI defined in (10) is three-dimensional time series data sampled only during the fault period, which is instantaneously converted into the feature map after the fault clearing and is imparted to the TSA model. To convert the DSI into the feature map, the state variables defined in (9) are sampled\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nonly during the fault period and assigned to each dimension in the form of a 3-dimensional tensor, as described in (10). The RGB image data format consists of 3-dimensional data with red, green, and blue components. Each dimension is represented by an 8-bit unsigned integer, ranging from 0 to 255, indicating the brightness or intensity of the respective color channel. Therefore, by linearly transforming the data distribution of each dimension in (10) into 8-bit unsigned integers ranging from 0 to 255, the data acquires the same attributes as an RGB image. In MATLAB, to perform the described process, as shown in Fig. 6, each state variable is transformed to have a data scale from 0 to 255 using \"rescale\", and then converted to an 8-bit unsigned integer data class using \"uint8\". These transformed state variables are then combined into a 3-dimensional tensor using \"cat\", and \"imresize\" is used to adjust the size of the input image to fit the CNN based model."
        },
        {
            "heading": "B. FINE-TUNING FOR TRANSIENT STABILITY ASSESSMENT",
            "text": "The PDCNN models are defined as (11).\n\ud835\udc3b\u212c(\ud835\udc7e\u2131 , \ud835\udc9e,\ud835\udcb3\ud835\udc56) = ?\u0302?\ud835\udc56 (11)\n\ud835\udc3b\u212c \u2208 { AlexNet, SqueezeNet, ResNet18, \u2026 , ResNet50,MobileNet, GoogLeNet, \u2026 , VGG16, VGG19, ShuffleNet, DarkNet19 }\n\ud835\udc7e\u2131 \u2208 {10%, 30%, 50%, 70%, 90%}\n\ud835\udc9e = {\ud835\udc46\ud835\udc61\ud835\udc4e\ud835\udc4f\ud835\udc59\ud835\udc52, \ud835\udc48\ud835\udc5b\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc4f\ud835\udc59\ud835\udc52}\n\ud835\udc3b\u212c is the deep CNN model pre-trained with ImageNet to be\nthe backbone, \ud835\udc7e\u2131 is the ratio of layers whose learning rate is set to 0 (i.e., the frozen layer), ?\u0302?\ud835\udc56 is the inference result\nfor input \ud835\udcb3\ud835\udc56 , and \ud835\udc9e is the category (i.e., class labels). The cross-entropy loss function with the regularization term [37]\nfor training the PDCNN (11) is\n\ud835\udc38\ud835\udc3f = \u2212 1\n\ud835\udc41\ud835\udc37 \u2211{\ud835\udcb4\ud835\udc56 ln ?\u0302?\ud835\udc56 + (1 \u2212 \ud835\udcb4\ud835\udc56) ln(1 \u2212 ?\u0302?\ud835\udc56)} + \ud835\udf06\n1 2 \u2016\ud835\udc7e\u2016\n\ud835\udc41\ud835\udc37\n\ud835\udc56=1\n(12)\nwhere \ud835\udc41\ud835\udc37 is the number of samples, the output of the model for input \ud835\udcb3\ud835\udc56 is ?\u0302?\ud835\udc56 (the inference result), the class of input \ud835\udcb3\ud835\udc56 is \ud835\udcb4\ud835\udc56 (the class label), W is the weight vector, and \u03bb is the regularization coefficient to reduce overfitting. The\noptimizer to minimize the loss function (12), the stochastic\ngradient descent with momentum (SGDM) [39], is\n\ud835\udc7e\ud835\udc57+1 = \ud835\udc7e\ud835\udc57 \u2212 \ud835\udefc\ud835\udec1\ud835\udc38\ud835\udc3f(\ud835\udc7e \ud835\udc57) + \ud835\udefe(\ud835\udc7e\ud835\udc57 \u2212\ud835\udc7e\ud835\udc57\u22121) (13)\nwhere j is the iteration number, \u03b1 is the learning rate, W is the weight vector, \ud835\udec1\ud835\udc38\ud835\udc3f(\ud835\udc7e \ud835\udc57) is the gradient of the loss function (12) with respect to \ud835\udc7e at iteration j, and \u03b3 is the\nmomentum which determines the contribution of the\nprevious gradient step to the current iteration. In the\ntraining dataset (8), the feature map converted from the DSI\n(10) and the transient stability (2) for each case are assigned\nto the input \ud835\udcb3\ud835\udc56 and label \ud835\udcb4\ud835\udc56 , respectively. The training dataset is constructed accordingly, as (14).\n\ud835\udcd3\ud835\udc47\ud835\udc46\ud835\udc34 = {(\ud835\udcb3\ud835\udc56 , \ud835\udcb4\ud835\udc56)|\ud835\udc56 = 1,2,\u22ef ,\ud835\udc41\ud835\udc37} (14)\nUsing the training dataset (14), the PDCNNs with 10\u201390% depth of the frozen layer (\ud835\udc7e\u2131) are trained by the SGDM (13) to minimize the loss function (12) and, consequently, form the TSA model."
        },
        {
            "heading": "V. CONSTRUCTING PROPOSED ASSESSMENT",
            "text": "SYSTEM\nTraining and verification datasets are constructed through time-domain simulation in power system models of different scales and characteristics to verify the proposed TSA system. The assessment model is selected by comparing the performance of models trained by varying the depth of the frozen layer. The design of the neural network model, data processing, training, and DTL for assessment model construction are performed using MATLAB R2022b with Deep Learning Toolbox and Image Processing Toolbox. All the tests are fulfilled on a computer with Intel Core i9-7900X 3.30GHz CPU, 16GB RAM, and RTX 3090Ti GPU."
        },
        {
            "heading": "A. TRANSIENT STABILITY ASSESSMENT MODEL",
            "text": "The DTL-based TSA system proposed in this study is illustrated in Fig. 7. The state variables of the power system\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nare measured by PMUs and stored in the database, from which the DSI is reconstructed. Immediately after the fault clearing, the DSI is converted into the feature map (see Fig. 6). The feature map represents the power system state variable during the fault period in the type of image data, which is then fed into the deep CNN model. The TSA model is constructed by fine-tuning PDCNNs, as shown in Fig. 3, using the training dataset obtained from the power system model to be implemented."
        },
        {
            "heading": "B. TRAINING DATA GENERATION",
            "text": ""
        },
        {
            "heading": "1) SIMULATION MODEL",
            "text": "To verify the performance and feasibility of the proposed system, time-domain simulation models of the IEEE 39-bus and the IEEE 118-bus system, which are widely used as the benchmark system, are constructed using MATLAB/Simulink. The parameters and configuration of each model are set up as Tables \u2163 and \u2164."
        },
        {
            "heading": "TABLE \u2163",
            "text": ""
        },
        {
            "heading": "PARAMETERS FOR THE BENCHMARK POWER SYSTEM",
            "text": "Component (model) Parameter Setting range Synchronous generator\n(sixth-order model)\nXd; Xd\u2032\nTdo\u2032; Tdo\u2032\u2032; H\n1\u20132.3; 0.15\u20130.4\n4.5; 0.02\u20130.03; 3.5\u201310\nPrime-mover and governor (tandem\ncompound)\nT2; T3; T4; T5 F2; F3; F4; F5\nKp; Rp; Tsr; Tsm\n0; 10; 3.3; 0.5 0; 0.36; 0.36; 0.28 1; 0.05; 1e-3; 0.15\nExciter (IEEE-Type 1) Ka; Ta; Efmn; Efmx 200; 1e-3; 0; 5\nPower system\nstabilizer (PSS-4B)\nKS; FL; KL\nFI; KI; FH; KH\n1; 0.2; 30\n1.25; 40; 12; 160"
        },
        {
            "heading": "TABLE \u2164",
            "text": ""
        },
        {
            "heading": "CONFIGURATION OF THE BENCHMARK SYSTEM",
            "text": "Benchmark model Machine Load Bus Line\nIEEE 39-bus 10 19 39 46 IEEE 118-bus 54 91 118 177"
        },
        {
            "heading": "2) DATABASE GENERATION",
            "text": "The training dataset of the TSA model is acquired through time-domain simulation for a three-phase short circuit fault in transmission lines and buses, as summarized in Table \u2165. The fault duration is set using a uniform distribution ranging from 200ms to 600ms, and the simulation time is set between 5 and 10 seconds. Case-1 involves conducting fault simulations on all transmission\nlines and buses for various load scenarios on the IEEE 39- bus system, resulting in a sufficient training dataset. On the other hand, case-2 considers only bus faults on the IEEE 118-bus system, which is larger and more complex than case-1. Because of the limited and insufficient fault simulation on the larger benchmark system, case-2 presents a challenging dataset for neural network models. The case studies are composed of two types: one with sufficient training data (case-1), and the other with insufficient training data, referred to as case-2. Case-2 is used to verify the generalization ability of the TSA model within the limitations of the training dataset. In actual power systems, it is impossible to obtain all potential fault cases that may occur, so the capability of generalizing the characteristics of transient stability from the training dataset needs to be verified."
        },
        {
            "heading": "TABLE \u2165",
            "text": ""
        },
        {
            "heading": "CONFIGURATION OF TRAINING DATASET FOR THE CASE STUDY",
            "text": "Condition Details Fault type Three-phase short circuit fault\nData location All buses State variable Voltage phasor Sampling rate 60Hz Fault duration 0.2\u20130.6s (uniform distribution) Case study Case-1 (C1) Case-2 (C2)\nBenchmark system IEEE 39-bus IEEE 118-bus\nFault location Line and bus Bus\nFault case\n(stable/unstable)\n3,528\n(2,801/727)\n2,476\n(1,831/645)\nDataset split ratio (training/validation)\n70% (2,470/1,058)\n70% (1,733/743)\nRemarks\nRelatively small\nbenchmark system\nand sufficient training dataset: easy case\nRelatively largescale benchmark system and\ninsufficient training\ndataset: hard case"
        },
        {
            "heading": "C. PRETRAINED DEEP CONVOLUTIONAL NEURAL NETWORK SELECTION",
            "text": "In order to apply the deep CNN pre-trained with ImageNet to TSA, the PDCNNs (11) listed in Table III are fine-tuned using the optimization parameter in Table \u2166 to compose the best-performing TSA system. The performance comparison is conducted through case studies by varying the depth of the frozen layer to select the most suitable model for TSA."
        },
        {
            "heading": "TABLE \u2166",
            "text": ""
        },
        {
            "heading": "OPTIMIZATION PARAMETERS FOR FINE-TUNING",
            "text": "Training option Setting\nOptimizer SGDMa L2 regularization 1e-4\nBatch normalization statistics population\nGradient threshold infinite Gradient threshold method L2norm\nInitial learning rate 1e-4 (learnable layer)\n1e-3 (fully connected layer) Momentum 0.9\nMaximum epochs 40\nMini batch size 4; 8; 16; 32; 48; 64\nFrozen layer depth(%) 10; 30; 50; 70; 90 aStochastic gradient descent with momentum.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nIn Fig. 8(a), the overall good performance of DTL models is verified. Because the difference between generality and specificity learned by the neural network from the former task depends on the depth of the layer, performance variations are observed for an increase in the frozen layer.\n(a)\n(b)\n(c)\nFIGURE 8. Comparison of the training result for selecting a pre-trained deep convolutional neural network. (a) Training results of the models depending on the depth of the frozen layer. (b) Training results (zoomed in the gray dotted box of (a)). (c) Best performances of each model at the optimal frozen layer depth.\nFig. 8(b) represents a magnified figure expanding the dotted line box in Fig. 8(a). Each model demonstrates its best performance with different depths of the frozen layer due to the property of each model. Comparing the transient stability feature map (i.e., the DSI) and ImageNet from the perspective of Fig. 2, these datasets (see Figs. 1 and 9) are dissimilar visually and differ significantly in scale; thus,\nexcellent performance is observed at the proportion of the frozen layer 10\u201350% due to the low similarity and relatively small training dataset. From the comparison of the accuracy of the trained PDCNN models shown in Fig. 8(c), it is evident that the VGG-19 based model exhibits the best performance for both case-1 and case-2.\nRelatively deeper and more complex models exhibit rather disappointing classification results. This indicates that the training dataset used for TSA in this study is somewhat insufficient to train massive networks. As a result, relatively simple models among candidate networks reveal better performance. While most of the models show excellent performance, VGG-16, of note, proves the best classification competence. In the training process, not only the effect of the mini-batch size but also the depth of the frozen layer on the performance appears to have the slightest difference. As a result, in the case studies of this research, it has been confirmed that VGG-16 is the most suitable model for DTL in TSA, considering the size of the training dataset in this study. As summarized in Table \u2162, VGG-16 can determine transient stability from a feature map within 5.1ms, so it has performance sufficient for real-time application and is relatively small-scale compared to other PDCNNs, which has advantages in terms of saving training time and computing resources. Starting from the next section of this paper, VGG16, which serves as the backbone of the assessment model, is referred to as the DTL model.\nVI. VERIFICATION\nThe performance comparison is conducted between the proposed DTL-based model and other approaches, including CNN-based models [31], [32], GINN-based model [33], LSTM-based model [30], and CNN-LSTM-based model [35]. From this point onward in this paper, these other approach models will be denoted as CNN-1, CNN-2, GINN, LSTM, and CLN model, respectively. To achieve objective\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nperformance comparison, TSA are constructed in an environment where all conditions for composing the model are exactly the same except for the neural network model. Due to the difference in the training datasets in the case studies, some modifications to the structures of the other approach models are necessary. The structural differences between the proposed model and other approach models can be observed in Table \u2167. The training is conducted with the same optimizer settings listed in Table \u2168, and the classification results are summarized as the average value of 10 training results."
        },
        {
            "heading": "TABLE \u2167",
            "text": ""
        },
        {
            "heading": "COMPARISON OF THE STRUCTURE OF ASSESSMENT MODELS",
            "text": "Proposed Other approachesa\nDTL model (VGG-16b)\nCNN-1 model [31]\nCNN-2 model [32]\nGINN model [33]\nInputc Convd-64 Conv-64 Max poole Conv-128 Conv-128 Max pool Conv-256 Conv-256 Conv-256 Max pool Conv-512 Conv-512 Conv-512 Max pool Conv-512 Conv-512 Conv-512 Max pool FC-4096\nFC-4096\nInputc\nConv-32 (64)f Conv-16 (32)\nFC-32\nInputc\nConv-64 Conv-16 Conv-4\nFC-64 (128) f\nInputc\nIncepg-16 Conv-48 Incep-32 Conv-96\nFC-128\nLSTM model\n[30]\nCLN modelh\n[35]\nInputc\nLSTM-256 LSTM-128\nFC-32\nInputc\nConv-64 Conv-16 Max pool\nLSTM-256 LSTM-128\nFC-32\nCommon output layer: FC-2 and softmax aThe models are trained using the case study dataset in this study; bVisual geometry group 16 layers; cAll input source images are identical but resized to fit the network; dConvolution layer; Fully connected layer; eMax pooling; fThe model structure is changed depending on each case study; gInception block(i.e., CNN variant); hThis model is arbitrarily constructed as the network structure is not provided."
        },
        {
            "heading": "TABLE \u2168",
            "text": ""
        },
        {
            "heading": "OPTIMIZATION PARAMETERS FOR TRAINING COMPARISON MODELS",
            "text": "Parameter\nOther approach\nCNN-1; CNN-2;\nGINN model\nLSTM model\nCLN\nmodel\nOptimizer SGDM Adama\nInitial learning rate 1e-2 1e-3\nMomentum 0.9 N/A\nSquared gradient decay factor N/A 0.999\nGradient decay factor N/A 0.9\nEpsilon N/A 1e\u22128\nGradient threshold N/A 1\nMini batch size 16 Maximum epochs 40 L2 regularization 1e-4\nBatch normalization statistics population aAdaptive moment estimation."
        },
        {
            "heading": "A. PERFORMANCE ANALYSIS",
            "text": "All models for comparing the performance assess transient stability using the state variable only during the fault period accompanied by the composition of the training dataset proposed in this study. The performance of the assessment model is evaluated using accuracy (AC), precision (PR), recall (RC), F1-score (F1S), false positive rate (FPR), and false discovery rate (FDR) as the performance index [39].\n{\n\ud835\udc34\ud835\udc36 =\n\ud835\udc47\ud835\udc43 + \ud835\udc47\ud835\udc41\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc43 + \ud835\udc47\ud835\udc41 + \ud835\udc39\ud835\udc41 \ud835\udc43\ud835\udc45 = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc43\n\ud835\udc45\ud835\udc36 = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc47\ud835\udc41\n\ud835\udc391\ud835\udc46 = 2 \u00d7 \ud835\udc43\ud835\udc45 \u00d7 \ud835\udc45\ud835\udc36\n\ud835\udc43\ud835\udc45 + \ud835\udc45\ud835\udc36\n\ud835\udc39\ud835\udc43\ud835\udc45 = \ud835\udc39\ud835\udc43\n\ud835\udc39\ud835\udc43 + \ud835\udc47\ud835\udc41\n\ud835\udc39\ud835\udc37\ud835\udc45 = \ud835\udc39\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc43\n(15)\nAs shown in Table \u2169, TP is true positive, TN is true negative, FP is false positive, and FN represents false negative."
        },
        {
            "heading": "TABLE \u2169",
            "text": ""
        },
        {
            "heading": "CONFUSION MATRIX",
            "text": "True class Predicted class\nStable Unstable\nStable True positive False negative\nUnstable False positive True negative\nA considerable difference in classification ability is\nconfirmed in the performance comparison results (see Fig.\n10), even though all conditions are the same except for the\nneural network model. In the proposed DTL model, the false\nnegative and false positive cases are only 4.75 and 1.25 cases\non the IEEE 39-bus system and 1 and 3 cases on the IEEE\n118-bus system, respectively. The DTL model, moreover,\nshows clear superiority in F1-score, used to validate\nperformance from the imbalanced training dataset, such as\nstable and unstable cases in power systems. The results of the\ntwo case studies can be seen in Fig. 11, where most models\nperform well in case-1. However, a clear performance\ndifference is observed in case-2, where learning about\ntransient stability characteristics is relatively difficult. These\nresults confirm the ability of the proposed DTL model to\nlearn and generalize transient stability in power systems.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nBecause the proposed model has a deep layer structure, it can\nbe inferred that if implemented in an actual power system,\nthe deep neural network model can be upgraded continuously\nusing the training dataset being accumulated from the actual\noperation data and simulation. Notably, through the\nprocedure proposed in this study transfer learning of superior\nneural networks developed for other tasks enables the\ncontinuous improvement of the DTL model itself. The reason\nwhy the performance of other approach models is rather\ninsufficient compared to the results in the original research is\nthe difference in assessment timing between this study and\nthe previous studies. In previous studies, the TSA models\ndelay the response time, i.e., the decision timing, until\nidentifying more apparent clues about transient stability, as\nshown in Table \u2160, so as to obtain an accuracy of 99% or\nhigher. This is because, in general, the classification accuracy\nis upregulated as the response time is delayed owing to the\nphysical characteristics of transient stability becoming\napparent as time progresses after the fault clearing. However,\nin this study, the accuracy of other approaches diminishes as\nthe assessment is set to be taken immediately after the fault\nclearing. The outstanding modeling capabilities of the deep\nCNN used in this study and the classification ability\nremaining in the network pre-learned with over 1 million\nImageNet datasets are able to immediately and accurately\nassess transient stability only using the state variables during\nthe fault period."
        },
        {
            "heading": "B. ROBUSTNESS AGAINST PMU DATA WITH NOISE",
            "text": "Considering the standard for the total vector error and noise filtering capability of the PMU specified in IEEE standard C37.118.1 and the field test results under interference conditions [55]\u2013[57], it is identified that the PMU can be interfered to around 40\u201360dB signal-noise ratio (SNR). It is necessary to investigate the overall effect of the reported noise interference on TSA because the proposed model should be built from the state variable acquired from the PMU and be applied in a real-time assessment system. Additive white Gaussian noise (AWGN) is a widely used noise model in communication systems, where the noise is uniformly distributed across all frequency bands, and its amplitude follows a normal probability distribution. It is especially common in modeling satellite communication channels, such as PMU systems. By incorporating AWGN into TSA, the robustness to noise can be validated. Therefore, the power system state data (10) is reconstructed using an AWGN with SNR ranging from 40 to 60 dB to examine the impact of noise on the TSA system.\nCNN converts a specific area of the input image into a representative value, thereby reducing the influence of slight variations in the input signal on the inference results [37]. In particular, deep CNNs have convolution layers connected in\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9\nseries and perform multiple convolution and pooling operations repeatedly in each layer, which can impart robustness against noise interference in the PMU. As identified in Fig. 12, the CNN-based models generally show good performance deviations against noise, while the LSTMbased model clearly exhibits performance degradation. The DTL model (the dotted gray box in Fig 12) demonstrates the most noise-resistant characteristics in line with the features of the deep network structure. Furthermore, the performance differences among case studies also exhibit the most marginal variances. Table \u216a and \u216b indicate the effects of noise interference on performance."
        },
        {
            "heading": "C. LIMITATION AND POTENTIAL CHALLENGE",
            "text": "The approach to constructing the TSA system through DTL, as proposed in this study, requires a substantial amount of training data, which is an inherent drawback of data-driven AI technologies. In actual power systems, acquiring a sufficient number of unstable cases for training is impossible. Hence, accurate modeling of the power system network, machines, and control systems becomes essential as a prerequisite, necessitating the time-consuming process of modeling and simulating the power system to obtain the necessary training dataset. Additionally, from the perspective of power system operation, defining the role of the TSA system in control and operation systems is crucial. The primary purpose of TSA is to enhance the stability of the power system through effective operation and control strategies. Therefore, validation and application in power system operation systems are necessary to ensure its practical implementation. In particular, for effective integration with remedial action schemes (or emergency control), the TSA system must be designed and evaluated considering various constraints, such as PMU data acquisition communication delay, remedial action communication delay, algorithm operation time, circuit breaker interrupting time, and the operation time of the remedial action decision algorithm. The roles and performance criteria required for TSA in these constrained conditions need to be clearly defined, and a seamless relationship between the TSA system and the remedial action scheme should be established."
        },
        {
            "heading": "VII. CONCLUSION",
            "text": "In this paper, DTL method for composing the TSA system through the excellent learning performance and image classification ability of the deep CNN pre-trained with ImageNet is proposed. The proposed system exhibits high accuracy assessment at the fastest timing, which is challenging to achieve with existing models. Despite utilizing only the state data during the fault period the PDCNN has effectively learned the characteristics of power system transient stability and thus can assess transient stability immediately after the fault clears. Furthermore, it is verified that DTL is a valuable method for overcoming the restriction of acquiring large-scale datasets and training deep neural\nnetworks. Future work will focus on developing the results of this study in connection with power system emergency control to improve power system stability."
        },
        {
            "heading": "TABLE \u216a",
            "text": "PERFORMANCE INDEXES WITH DIFFERENT NOISE LEVELS (CASE-1: IEEE 39-BUS)\nSNR Index Proposed Other approaches (%)\nDTL (%) CNN-1 CNN-2 GINN LSTM CLN\n40dB AC 99.11 97.90 97.50 98.70 95.26 97.79\nF1S 99.44 98.68 98.44 99.18 97.01 98.45 FPR 1.38 5.55 7.8 3.72 10.18 4.77 FDR 0.36 1.44 2.01 0.96 2.66 1.24\n50dB AC 99.30 97.96 97.49 98.45 96.67 97.73\nF1S 99.56 98.72 98.41 99.03 97.90 98.57 FPR 1.19 6.61 4.13 5.78 6.51 5.5 FDR 0.31 1.70 1.08 1.48 1.7 1.43\n60dB AC 99.43 97.62 97.71 98.36 96.86 97.96 F1S 99.64 98.51 98.56 98.97 98.01 98.72\nFPR 0.80 8.17 4.77 6.01 4.95 5.23\nFDR 0.21 2.09 1.24 1.54 1.3 1.36 \u221ea AC 99.43 97.82 97.84 98.43 97.05 98.11\nF1S 99.64 98.63 98.64 99.01 98.13 98.81 FPR 0.57 6.56 3.03 4.31 3.76 3.67 FDR 0.15 1.69 0.79 1.12 0.99 0.96\naInfinite signal-noise ratio.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nVOLUME XX, 2017 9"
        },
        {
            "heading": "TABLE \u216b",
            "text": "PERFORMANCE INDEXES WITH DIFFERENT NOISE LEVELS\n(CASE-2: IEEE 118-BUS)\nSNR Index Proposed Other approaches (%)\nDTL (%) CNN-1 CNN-2 GINN LSTM CLN\n40dB AC 99.14 95.42 94.72 97.71 95.75 96.42 F1S 99.42 96.94 96.47 98.46 97.15 97.59\nFPR 2.68 11.80 13.61 6.39 10.72 8.66\nFDR 0.94 4.08 4.1 2.23 3.72 3.02 50dB AC 99.41 95.09 94.67 97.75 96.04 96.20\nF1S 99.60 96.73 96.44 98.49 97.32 97.43 FPR 1.86 13.87 14.23 6.86 7.53 7.22 FDR 0.65 4.75 4.89 2.38 2.66 2.55\n60dB AC 99.25 95.53 94.83 97.93 96.47 96.64\nF1S 99.49 97.01 96.53 98.61 97.62 97.75 FPR 2.47 11.75 11.75 6.96 7.94 9.69 FDR 0.87 4.06 4.69 2.41 2.78 3.35\n\u221e AC 99.46 94.82 94.56 97.73 96.55 96.72 F1S 99.64 96.52 96.39 98.47 97.67 97.80\nFPR 1.55 12.16 15.67 6.70 7.32 9.59 FDR 0.54 4.23 5.34 2.33 2.57 3.31"
        }
    ],
    "title": "Transient Stability Assessment Using Deep Transfer Learning",
    "year": 2023
}