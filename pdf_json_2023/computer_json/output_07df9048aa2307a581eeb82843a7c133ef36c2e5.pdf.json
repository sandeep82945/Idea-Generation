{
    "abstractText": "While artificial intelligence-based chatbots have demonstrated great potential for writing, little is known about whether and how doctoral students accept the use of ChatGPT in writing. Framed with Technology Acceptance Model, this study investigated doctoral students\u2019 acceptance toward ChatGPT in writing and the factors that influence it. The questionnaire survey revealed a high intention to use ChatGPT in writing among doctoral students in China. The findings further indicated that attitude was a significant predictor of behavioural intention to use ChatGPT in writing and mediated the impacts of perceived usefulness and perceived ease of use on it. Perceived ease of ChatGPT use was in turn influenced by students\u2019 past ChatGPT use experience. This study provides powerful evidence for the applicability of Technology Acceptance Model in the acceptance of ChatGPT in writing. The results have significant implications for leveraging ChatGPT for writing in higher education.",
    "authors": [
        {
            "affiliations": [],
            "name": "Martina Rau"
        }
    ],
    "id": "SP:cbdc2d6ebadba44da9150a89a354ec88a46d6782",
    "references": [
        {
            "authors": [
                "F. Abdullah",
                "R. Ward"
            ],
            "title": "Developing a general extended technology acceptance model for E-learning (GETAMEL) by analysing commonly used external factors",
            "venue": "Comput. Hum. Behav. 56, 238\u2013256. doi: 10.1016/j.chb.2015.11.036",
            "year": 2016
        },
        {
            "authors": [
                "I. Ajzen"
            ],
            "title": "The theory of planned behavior",
            "venue": "Organ. Behav. Hum. Decis. Process. 50, 179\u2013211. doi: 10.1016/0749-5978(91)90020-T",
            "year": 1991
        },
        {
            "authors": [
                "I. Ajzen",
                "M. Fishbein"
            ],
            "title": "Scaling and testing multiplicative combinations in the expectancy\u2013value model of attitudes",
            "venue": "J. Appl. Soc. Psychol. 38, 2222\u20132247. doi:",
            "year": 2008
        },
        {
            "authors": [
                "H.A. Alfadda",
                "H.S. Mahdi"
            ],
            "title": "Measuring students\u2019 use of zoom application in language course based on the technology acceptance model (TAM)",
            "venue": "J. Psycholinguist. Res. 50, 883\u2013900. doi: 10.1007/s10936-020-09752-1",
            "year": 2021
        },
        {
            "authors": [
                "J.S. Barrot"
            ],
            "title": "Using ChatGPT for second language writing: pitfalls and potentials",
            "venue": "Assess. Writ. 57:100745. doi: 10.1016/j.asw.2023.100745",
            "year": 2023
        },
        {
            "authors": [
                "L. Bishop"
            ],
            "title": "A computer wrote this paper: what chatgpt means for education, research, and writing",
            "venue": "SSRN Electron. J. doi: 10.2139/ssrn.4338981",
            "year": 2023
        },
        {
            "authors": [
                "C.T. Chang",
                "J. Hajiyev",
                "C.R. Su"
            ],
            "title": "Examining the students\u2019 behavioral intention to use e-learning in Azerbaijan? The general extended technology acceptance model for e-learning approach",
            "venue": "Comput. Educ. 111, 128\u2013143. doi: 10.1016/j. compedu.2017.04.010",
            "year": 2017
        },
        {
            "authors": [
                "E.W. Cheng"
            ],
            "title": "Choosing between the theory of planned behavior (TPB) and the technology acceptance model (TAM)",
            "venue": "Educ. Technol. Res. Dev. 67, 21\u201337. doi:",
            "year": 2019
        },
        {
            "authors": [
                "F.D. Davis"
            ],
            "title": "Perceived usefulness, perceived ease of use, and user acceptance of information technology",
            "venue": "MIS Q. 13, 319\u2013340. doi: 10.2307/249008",
            "year": 1989
        },
        {
            "authors": [
                "F.D. Davis",
                "R.P. Bagozzi",
                "P.R. Warshaw"
            ],
            "title": "User acceptance of computer technology: a comparison of two theoretical models",
            "venue": "Manag. Sci. 35, 982\u20131003. doi:",
            "year": 1989
        },
        {
            "authors": [
                "F.D. Davis",
                "R.P. Bagozzi",
                "P.R. Warshaw"
            ],
            "title": "Extrinsic and intrinsic motivation to use computers in the workplace",
            "venue": "J. Appl. Soc. Psychol. 22, 1111\u20131132. doi:",
            "year": 1992
        },
        {
            "authors": [
                "I. Dergaa",
                "K. Chamari",
                "P. Zmijewski",
                "H.B. Saad"
            ],
            "title": "From human writing to artificial intelligence generated text: examining the prospects and potential threats of ChatGPT in academic writing",
            "venue": "Biol. Sport 40, 615\u2013622. doi: 10.5114/ biolsport.2023.125623",
            "year": 2023
        },
        {
            "authors": [
                "Y.K. Dwivedi",
                "N. Kshetri",
                "L. Hughes",
                "E.L. Slade",
                "A. Jeyaraj",
                "Kar",
                "A. K"
            ],
            "title": "So what if ChatGPT wrote it?\u201d multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy",
            "venue": "Int. J. Inf. Manag. 71:102642. doi: 10.1016/j",
            "year": 2023
        },
        {
            "authors": [
                "R. Edmunds",
                "M. Thorpe",
                "G. Conole"
            ],
            "title": "Student attitudes towards and use of ICT in course study, work and social activity: a technology acceptance model approach",
            "venue": "Br. J. Educ. Technol. 43, 71\u201384. doi: 10.1111/j.1467-8535. 2010.01142.x",
            "year": 2012
        },
        {
            "authors": [
                "EDUCAUSE."
            ],
            "title": "2023 EDUCAUSE horizon report, teaching and learning edition",
            "venue": "Boulder, Colorado: EDUCAUSE.",
            "year": 2023
        },
        {
            "authors": [
                "R. Estriegana",
                "J.A. Medina-Merodio",
                "R. Barchino"
            ],
            "title": "Student acceptance of virtual laboratory and practical work: an extension of the technology acceptance model",
            "venue": "Comput. Educ. 135, 1\u201314. doi: 10.1016/j.compedu.2019.02.010",
            "year": 2019
        },
        {
            "authors": [
                "M. Farrokhnia",
                "S.K. Banihashem",
                "O. Noroozi",
                "A. Wals"
            ],
            "title": "A SWOT analysis of ChatGPT: implications for educational practice and research",
            "venue": "Innov. Educ. Teach. Int., 1\u201315. doi: 10.1080/14703297.2023.2195846",
            "year": 2023
        },
        {
            "authors": [
                "A. Grani\u0107",
                "N. Maranguni\u0107"
            ],
            "title": "Technology acceptance model in educational context: a systematic literature review",
            "venue": "Br. J. Educ. Technol. 50, 2572\u20132593. doi: 10.1111/ bjet.12864",
            "year": 2019
        },
        {
            "authors": [
                "K. Guo",
                "J. Wang",
                "S.K.W. Chu"
            ],
            "title": "Using chatbots to scaffold EFL students\u2019 argumentative writing",
            "venue": "Assess. Writ. 54:100666. doi: 10.1016/j.asw.2022.100666",
            "year": 2022
        },
        {
            "authors": [
                "L.T. Hu",
                "P.M. Bentler"
            ],
            "title": "Cutoff criteria for fit indexes in covariance structure analysis: conventional criteria versus new alternatives",
            "venue": "Struct. Equ. Model. Multidiscip. J. 6, 1\u201355. doi: 10.1080/10705519909540118",
            "year": 1999
        },
        {
            "authors": [
                "M. Imran",
                "N. Almusharraf"
            ],
            "title": "Analyzing the role of ChatGPT as a writing assistant at higher education level: a systematic review of the literature",
            "venue": "Contemp. Educ. Technol. 15:ep464. doi: 10.30935/cedtech/13605",
            "year": 2023
        },
        {
            "authors": [
                "K.J. Kirkpatrick"
            ],
            "title": "Online doctoral students writing for scholarly publication",
            "venue": "Comput. Compos. 52, 19\u201336. doi: 10.1016/j.compcom.2019.01.012",
            "year": 2019
        },
        {
            "authors": [
                "Y.F. Lee",
                "G.J. Hwang",
                "P.Y. Chen"
            ],
            "title": "Impacts of an AI-based cha bot on college students\u2019 after-class review, academic performance, self-efficacy, learning attitude, and motivation",
            "venue": "Educ. Technol. Res. Dev. 70, 1843\u20131865. doi: 10.1007/ s11423-022-10142-8",
            "year": 2022
        },
        {
            "authors": [
                "D.Y. Lee",
                "M.R. Lehto"
            ],
            "title": "User acceptance of YouTube for procedural learning: an extension of the technology acceptance model",
            "venue": "Comput. Educ. 61, 193\u2013208. doi: 10.1016/j.compedu.2012.10.001",
            "year": 2013
        },
        {
            "authors": [
                "L.P.F. Ma"
            ],
            "title": "Writing in English as an additional language: challenges encountered by doctoral students",
            "venue": "High. Educ. Res. Dev. 40, 1176\u20131190. doi:",
            "year": 2021
        },
        {
            "authors": [
                "S. Mat Roni"
            ],
            "title": "Introduction to SPSS",
            "venue": "Edith Cowan University, SOAR Centre.",
            "year": 2014
        },
        {
            "authors": [
                "D.L. Nelson"
            ],
            "title": "Individual adjustment to information-driven technologies: a critical review",
            "venue": "MIS Q. 14, 79\u201398. doi: 10.2307/249311",
            "year": 1990
        },
        {
            "authors": [
                "OpenAI"
            ],
            "title": "ChatGPT: optimizing language models for dialogue",
            "venue": "Available at: https://openai.com/blog/chatgpt/ (Accessed October 10, 2023).",
            "year": 2023
        },
        {
            "authors": [
                "S.H. Purnomo",
                "Y.H. Lee"
            ],
            "title": "E-learning adoption in the banking workplace in Indonesia: an empirical study",
            "venue": "Inf. Dev. 29, 138\u2013153. doi: 10.1177/0266666912448258",
            "year": 2013
        },
        {
            "authors": [
                "H. Rafique",
                "A.O. Almagrabi",
                "A. Shamim",
                "F. Anwar",
                "A.K. Bashir"
            ],
            "title": "Investigating the acceptance of mobile library applications with an extended technology acceptance model (TAM)",
            "venue": "Comput. Educ. 145:103732. doi: 10.1016/j. compedu.2019.103732",
            "year": 2020
        },
        {
            "authors": [
                "R.M. Ryan",
                "E.L. Deci"
            ],
            "title": "Intrinsic and extrinsic motivations: classic definitions and new directions",
            "venue": "Contemp. Educ. Psychol. 25, 54\u201367. doi: 10.1006/ ceps.1999.1020",
            "year": 2000
        },
        {
            "authors": [
                "W.L. Shiau",
                "P.Y. Chau"
            ],
            "title": "Understanding behavioral intention to use a cloud computing classroom: a multiple model comparison approach",
            "venue": "Inf. Manag. 53, 355\u2013365. doi: 10.1016/j.im.2015.10.004",
            "year": 2016
        },
        {
            "authors": [
                "Y. Su",
                "Y. Lin",
                "C. Lai"
            ],
            "title": "Collaborating with ChatGPT in argumentative writing classrooms",
            "venue": "Assess. Writ. 57:100752. doi: 10.1016/j.asw.2023.100752",
            "year": 2023
        },
        {
            "authors": [
                "V. Taecharungroj"
            ],
            "title": "What can ChatGPT do?\u201d analyzing early reactions to the innovative AI Chatbot on twitter",
            "venue": "Big Data Cogn. Comp. 7:35. doi: 10.3390/bdcc7010035",
            "year": 2023
        },
        {
            "authors": [
                "A. Tlili",
                "B. Shehata",
                "M.A. Adarkwah",
                "A. Bozkurt",
                "D.T. Hickey",
                "R Huang"
            ],
            "title": "What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education",
            "year": 2023
        },
        {
            "authors": [
                "E.A. van Dis",
                "J. Bollen",
                "W. Zuidema",
                "R. van Rooij",
                "C.L. Bockting"
            ],
            "title": "ChatGPT: five priorities for research",
            "venue": "Nature 614,",
            "year": 2023
        },
        {
            "authors": [
                "B. Williamson",
                "F. Macgilchrist",
                "J. Potter"
            ],
            "title": "Re-examining AI, automation and datafication in education",
            "venue": "Learn. Media Technol. 48, 1\u20135. doi: 10.1080/17439884.2023.2167830",
            "year": 2023
        },
        {
            "authors": [
                "D. Yan"
            ],
            "title": "Impact of ChatGPT on learners in a L2 writing practicum: An exploratory investigation",
            "venue": "Education and Information Technologies.",
            "year": 2023
        },
        {
            "authors": [
                "Y. Yang",
                "X. Wang"
            ],
            "title": "Modeling the intention to use machine translation for student translators: an extension of technology acceptance model",
            "venue": "Comput. Educ. 133, 116\u2013126. doi: 10.1016/j.compedu.2019.01.015",
            "year": 2019
        },
        {
            "authors": [
                "R. Zhang",
                "D. Zou",
                "G. Cheng"
            ],
            "title": "Chatbot-based learning of logical fallacies in EFL writing: perceived effectiveness in improving target knowledge and learner motivation",
            "venue": "Interact. Learn. Environ., 1\u201318. doi: 10.1080/10494820.2023.2220374",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "Frontiers in Psychology 01 frontiersin.org\nTo use or not to use? Understanding doctoral students\u2019 acceptance of ChatGPT in writing through technology acceptance model Min\u00a0Zou 1 and Liang\u00a0Huang 2* 1 School of Foreign Languages, Beijing Institute of Technology, Beijing, China, 2 Department of Public Administration, Southeast University, Nanjing, China\nWhile artificial intelligence-based chatbots have demonstrated great potential for writing, little is known about whether and how doctoral students accept the use of ChatGPT in writing. Framed with Technology Acceptance Model, this study investigated doctoral students\u2019 acceptance toward ChatGPT in writing and the factors that influence it. The questionnaire survey revealed a high intention to use ChatGPT in writing among doctoral students in China. The findings further indicated that attitude was a significant predictor of behavioural intention to use ChatGPT in writing and mediated the impacts of perceived usefulness and perceived ease of use on it. Perceived ease of ChatGPT use was in turn influenced by students\u2019 past ChatGPT use experience. This study provides powerful evidence for the applicability of Technology Acceptance Model in the acceptance of ChatGPT in writing. The results have significant implications for leveraging ChatGPT for writing in higher education.\nKEYWORDS\nChatGPT, writing, technology acceptance model, artificial intelligence-based chatbot, doctoral students\n1. Introduction\nArtificial intelligence (AI) technologies play a crucially important role in the increasingly digitalized world (Lee et\u00a0al., 2022; Farrokhnia et\u00a0al., 2023). As a generative AI chatbot, ChatGPT is a large language model that can autonomously learn from data and produce human-like texts (van Dis et\u00a0 al., 2023). It can converse on a wide range of topics and generate human-like responses after training huge quantities of text data (OpenAI, 2023). Ever since its release in November 2022, ChatGPT has sparked debates about its implications for education (Farrokhnia et\u00a0al., 2023; Tlili et\u00a0al., 2023; van Dis et\u00a0al., 2023). While ChatGPT can potentially transform educational practices by providing a baseline knowledge of diverse topics (Tlili et\u00a0al., 2023) and facilitating personalized, complex learning (Farrokhnia et\u00a0al., 2023), it may supply incorrect texts, encourage cheating, and threaten academic integrity (Dwivedi et\u00a0al., 2023; van Dis et\u00a0al., 2023). The controversies have made ChatGPT \u201cthe most high-profile and controversial form of AI to hit education so far\u201d (Williamson et\u00a0al., 2023, p.\u00a02).\nWriting has been one of the most influenced domains in the ChatGPT era (Taecharungroj, 2023; Yan, 2023). While writing plays an important role in higher education (Kirkpatrick, 2019), it has been oftentimes considered challenging for language learners, especially for those who"
        },
        {
            "heading": "OPEN ACCESS",
            "text": ""
        },
        {
            "heading": "EDITED BY",
            "text": ""
        },
        {
            "heading": "Martina Rau, University of Wisconsin-Madison, United\u00a0States",
            "text": ""
        },
        {
            "heading": "REVIEWED BY",
            "text": "Edwin Ramirez-Asis, Lord of Sipan University, Peru Yueh-Min Huang, National Cheng Kung University, Taiwan\n*CORRESPONDENCE Liang Huang eliot_huang@163.com\nRECEIVED 16 July 2023 ACCEPTED 16 October 2023 PUBLISHED 26 October 2023"
        },
        {
            "heading": "CITATION",
            "text": "Zou M and Huang L (2023) To use or not to use? Understanding doctoral students\u2019 acceptance of ChatGPT in writing through technology acceptance model. Front. Psychol. 14:1259531. doi: 10.3389/fpsyg.2023.1259531"
        },
        {
            "heading": "COPYRIGHT",
            "text": "\u00a9 2023 Zou and Huang. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\nTYPE Original Research PUBLISHED 26 October 2023 DOI 10.3389/fpsyg.2023.1259531\nFrontiers in Psychology 02 frontiersin.org\nlearn and use English as an additional language (Ma, 2021). Prior research has suggested that chatbots are effective in addressing this challenge, since they could supply meaningful guidance and substantive feedback to support language learners to write at their own pace in a less anxiety-inducing environment and improve writing quality (Guo et\u00a0al., 2022; Zhang et\u00a0al., 2023). As a chatbot powered by generative AI, ChatGPT has demonstrated improved abilities than earlier chatbots (e.g., ELIZA) to understand natural language, generate appropriate responses, and engage in free-flowing conversations throughout the writing process, hence opening a new avenue for writing practice (Barrot, 2023; Su et\u00a0 al., 2023). As succinctly summarized by Imran and Almusharraf (2023), ChatGPT is \u201ca complete package from generation to final proofreading and editing of writing material\u201d (p.2). Nevertheless, till now, scarce attention has been paid to the acceptance and usage of ChatGPT in English writing\u2014a daunting but critical work facing doctoral students (Kirkpatrick, 2019). Little is known about whether and how doctoral students intend to use ChatGPT in writing and the key determined factors. Informed by Technology Acceptance Model (TAM; Davis, 1989), the present study seeks to fill the void by addressing the following two questions: (1) how is the doctoral students\u2019 acceptance intention to ChatGPT in writing? (2) what factors may influence doctoral students\u2019 acceptance intention to ChatGPT in writing? Such information is important, as the individuals\u2019 intention to adopt and use AI technology is critical to improving teaching and learning of writing (Cheng, 2019; Yan, 2023)."
        },
        {
            "heading": "2. Literature review",
            "text": ""
        },
        {
            "heading": "2.1. The use of ChatGPT in writing",
            "text": "Chatbots, computer programs or AI systems designed to simulate human conversations and interact with users via natural language, have gained considerable attention and increasingly applied in writing in the past decade (Zhang et\u00a0al., 2023). Chatbots have demonstrated great potential as a writing assistant and learning partner in writing classrooms, as they can provide a broad array of language choices and feedback to students\u2019 writing process and make students feel less stressed about their writing performance in the learning process (Guo et\u00a0 al., 2022). ChatGPT was developed in 2022 as a novel chatbot rooted in Generative Pre-training Transformer architecture, and outperforms early chatbots in terms of the capability for understanding and producing human-like texts as well as providing feedback on long texts (Dwivedi et\u00a0al., 2023; Farrokhnia et\u00a0al., 2023; Su et\u00a0al., 2023; Tlili et\u00a0al., 2023). Such affordances make it a powerful writing assistant and writing tool (Barrot, 2023; Dergaa et\u00a0al., 2023; Imran and Almusharraf, 2023). As shown in Taecharungroj\u2019s (2023) analysis of early reactions on Twitter, ChatGPT has been most frequently used for writing, such as essays and articles.\nGiven the close link between ChatGPT and writing, a growing body of research has been undertaken to investigate the benefits and threats associated with the use of ChatGPT in writing. Piloting ChatGPT for academic writing, Bishop\u2019s (2023) user experience demonstrated that ChatGPT is effective in explaining well-known concepts, translating between languages, giving timely and personalized feedback, adjusting the style and tone of texts to imitate different writers, and perfecting the mechanics of writing, thereby enhancing writing efficiency and promoting writing quality. Zooming\ninto the use of ChatGPT in second language writing context, Barrot (2023) and Su et\u00a0 al. (2023) further unpacked the potential of collaborating with ChatGPT in writing classrooms. For them, ChatGPT has taken into consideration various writing constructs, such as pragmatics, coherence and syntax, and could support the structural, dialogical and linguistic aspects of quality writing by assisting students in topic generation, outline preparation, content revision, proofreading and post-writing reflection. Taking stock of the research on ChatGPT in academia, Dergaa et\u00a0al. (2023) and Imran and Almusharraf (2023) highlights the need to leverage ChatGPT as a valuable writing assistant tool to support the writing process and enhance academic writing.\nNotwithstanding the benefits, the use of ChatGPT in writing has also raised concern for inaccurate and unintelligent responses, academic integrity, learning loss and educational inequality (Dwivedi et\u00a0al., 2023; Farrokhnia et\u00a0al., 2023; Tlili et\u00a0al., 2023). As noted by the developer itself (OpenAI, 2023), \u201cChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers.\u201d Such incorrect and biased information can mislead students and be\u00a0further incorporated into their writing, thereby harming knowledge practice and science progress (Tlili et\u00a0al., 2023; van Dis et\u00a0al., 2023). Another limitation of using ChatGPT in writing is associated with its unintelligent responses, typified by its frequent use of irrelevant statements, template rigidity of writing, and insufficiencies in emotional depth in writing (Barrot, 2023). Also, ChatGPT does not always reference sources appropriately and cannot be\u00a0held accountable for their work, which raises pertinent issues concerning plagiarism and academic integrity (Dergaa et\u00a0 al., 2023; van Dis et\u00a0 al., 2023; Williamson et\u00a0al., 2023; Yan, 2023). Additionally, the generative nature of ChatGPT allows students to complete writing assignments simply through unwitting copy-and-paste, and hence results in learning loss, especially when students become too reliant on the AI-powered chatbot for convenience (Barrot, 2023). Likewise, using ChatGPT in writing could lead to educational inequality (Dwivedi et\u00a0al., 2023). Focusing on ChatGPT\u2019s text generation functionality, for example, Yan\u2019s (2023) research showed the undergraduates were much concerned with its impact on educational equity, given that writing teachers may not effectively distinguish texts produced by students from those produced by ChatGPT.\nWhile the above user cases and scholarly discussions are helpful in unpacking the potentials and pitfalls of using ChatGPT in writing, the research into ChatGPT is still at its early stage (Barrot, 2023). Little empirical research has been conducted to examine the socio-technical aspects of using ChatGPT in writing. Since writing is essential to doctoral education (e.g., Kirkpatrick, 2019) and subject to the advances in AI technologies (Yan, 2023), it is necessary to explore and examine doctoral students\u2019 intention toward ChatGPT and the influencing factors. Such information could shed light on doctoral students\u2019 acceptance of ChatGPT in writing, and generate useful insights to leverage ChatGPT and other similar generative AI technologies for the teaching and learning of writing in higher education."
        },
        {
            "heading": "2.2. Technology acceptance model",
            "text": "User acceptance refers to the prospective users\u2019 predisposition toward using technology (Lee and Lehto, 2013). TAM, emerging from the theory of reasoned action, has become an influential\nFrontiers in Psychology 03 frontiersin.org\nsocio-technical model that seeks to identify and explain the end-users\u2019 acceptance of technology (e.g., Cheng, 2019; Grani\u0107 and Maranguni\u0107, 2019). In TAM, individuals\u2019 acceptance of a particular technology is operationalized as their behavioural intentions to use it (Lee and Lehto, 2013). TAM postulates that people\u2019s actual usage of technology is determined by their behavioural intentions. Behavioural intentions, in turn, are jointly determined by people\u2019s attitudes and perceived usefulness (Davis et\u00a0 al., 1989). Attitude towards technology underscores individuals\u2019 affective reactions to and evaluation of the use of the technology (Ajzen, 1991; Lee and Lehto, 2013) and it is closely related to one\u2019s intrinsic motivation (Davis et\u00a0 al., 1992). If people have a more favourable attitude toward the technology, they are more likely to form positive intentions to use it (Davis et\u00a0al., 1989; Estriegana et\u00a0al., 2019). Perceived usefulness is people\u2019s belief about the extent to which using the technology will improve their performance (Davis, 1989). It is a type of extrinsic motivation in determining technology acceptance and technology usage behaviour (Davis, 1989; Lee and Lehto, 2013). That is, if students believe that using the technology will improve their performance in writing, they tend to have a positive inclination to use it. The perceived usefulness is also hypothesized to have a positive influence on attitudes and thus affect behavioural intentions (Davis et\u00a0al., 1989). If the technology is viewed as useful in enhancing writing performance, students are apt to appraise the technological means positively and inclined to use it (Estriegana et\u00a0 al., 2019). Therefore, this study proposes the following hypotheses.\nHypothesis 1: Attitude towards using ChatGPT in writing would significantly and positively influence students\u2019 behavioural intention to use ChatGPT in writing.\nHypothesis 2: Perceived usefulness of using ChatGPT would significantly and positively influence students\u2019 behavioural intention to use ChatGPT in writing.\nHypothesis 3: Perceived usefulness of using ChatGPT would significantly and positively influence students\u2019 attitude towards using ChatGPT in writing.\nHypothesis 4: Attitude towards using GPT would significantly mediate the effects of perceived usefulness on students\u2019 intention to use ChatGPT in writing.\nFurthermore, TAM posits that attitude is jointly determined by perceived usefulness and perceived ease of use which refers to \u201cthe degree to which a person believes that using a particular system would be\u00a0free of effort\u201d (Davis, 1989, p.320). In TAM, perceived ease of use is assumed to have a significant effect on perceived usefulness and attitudes, resulting in increased behavioural intention (Davis et\u00a0al., 1989; Alfadda and Mahdi, 2021). If the technological tool is perceived to be\u00a0easy to use, students tend to consider it helpful and develop a favourable attitude, thereby demonstrating a strong inclination to use it in writing (Alfadda and Mahdi, 2021). Subsequently, the following hypotheses can be\u00a0proposed.\nHypothesis 5: Perceived ease of use would significantly and positively influence students\u2019 perceived usefulness of ChatGPT in writing.\nHypothesis 6: Perceived ease of use would significantly and positively influence students\u2019 attitude towards using ChatGPT in writing.\nHypothesis 7: Attitude towards using GPT would significantly mediate the effects of perceived ease of use on students\u2019 intention to use ChatGPT in writing.\nMeanwhile, a number of studies have revealed a strong and direct association between perceived ease of use and behavioural intention (Grani\u0107 and Maranguni\u0107, 2019). In Yang and Wang\u2019s (2019) study, for instance, the perceived ease of use showed a significant and positive impact on students\u2019 behavioural intention to use machine translation. As argued by Shiau and Chau (2016), when people perceive that using a technological tool does not require much effort, they will be\u00a0more intended to use it. Hence, the following hypothesis is proposed.\nHypothesis 8: Perceived ease of use would significantly and positively influence students\u2019 behavioural intention to use ChatGPT in writing.\nAccording to Davis et\u00a0 al. (1989), perceived usefulness and perceived ease of use are influenced by a range of external variables, among which experience is one best studied external factor (Abdullah and Ward, 2016). The existing literature suggests that experience influences both learners\u2019 perceived usefulness (e.g., Chang et\u00a0al., 2017; Yang and Wang, 2019) and perceived ease of use of educational technologies (e.g., Purnomo and Lee, 2013). For instance, Chang et\u00a0al. (2017) found that students who have more experience in using computers tend to demonstrate more positive perceptions regarding the ease of use and usefulness of e-learning. Hence, this study assumes that students who have experience in using generative AI chatbots are more prone to understand usefulness of ChatGPT and become more proficient in using it in EFL writing. The following hypotheses are accordingly proposed.\nHypothesis 9: Past ChatGPT use experience would significantly and positively influence perceived usefulness of ChatGPT in writing.\nHypothesis 10: Past ChatGPT use experience would significantly and positively influence perceived ease of using ChatGPT in writing.\nTaken together, and in line with the existing literature on TAM, a conceptual model is formulated in the present study (see Figure\u00a01)."
        },
        {
            "heading": "3. Research methodology",
            "text": ""
        },
        {
            "heading": "3.1. Participants",
            "text": "A total number of 242 doctoral students (151 males and 91 females) participated in the study through convenience samplings in one technological university in China. The students, ranging from 24 to 43\u00a0in age, were enrolled in the compulsory course entitled Writing for Academic Success taught by the first author. The course aims to empower doctoral students to improve English for academic writing\nFrontiers in Psychology 04 frontiersin.org\nskills. The participants were from different disciplinary backgrounds, such as computer science, mechanical engineering, materials science, economics, and education."
        },
        {
            "heading": "3.2. Measures",
            "text": "To determine doctoral students\u2019 acceptance of ChatGPT in writing and the factors influencing it, an online survey was administered in March 2023. The survey instrument consisted of two sections subsuming questions pertaining to demographic profiles (gender, major, and past ChatGPT use experience) and those concerning the constructs in TAM. The survey items in the second part were adapted from Davis (1989), Edmunds et\u00a0al. (2012), Lee and Lehto (2013), and Rafique et\u00a0al. (2020), and in light of the usage of ChatGPT in writing. In the second section, the respondents indicated their agreement level on every item by recording their response in a 6-point Likert scale, ranging from \u201c1\u201d (Strongly Disagree) to \u201c6\u201d (Strongly Agree)."
        },
        {
            "heading": "3.2.1. Perceived ease of ChatGPT use in writing",
            "text": "Perceived ease of ChatGPT use in writing was measured based on a five-item scale adapted from Davis (1989). The five items (e.g., \u201cI think ChatGPT is easy to use\u201d) showed high reliability (Cronbach\u2019s \u03b1 = 0.854). In light of Hu and Bentler\u2019s (1999) study, the Confirmatory Factor Analysis (CFA) results suggested good construct validity (\u03c72 = 9.445, df = 5, RMSEA = 0.061, CFI = 0.991, TLI = 0.982), with factor loading ranging from 0.608 to 0.821."
        },
        {
            "heading": "3.2.2. Perceived usefulness of ChatGPT in writing",
            "text": "Perceived usefulness of using ChatGPT in writing was assessed by a five-item scale adapted from Davis (1989) and Rafique et\u00a0al. (2020). The five items (e.g., \u201cUsing ChatGPT would enable me to finish English writing assignments effectively\u201d) demonstrated high reliability (Cronbach\u2019s \u03b1 = 0.841). The CFA results showed good construct validity (\u03c72 = 4.254, df = 5, RMSEA = 0.000, CFI = 1.000, TLI =1.000), with factor loading ranging from 0.637 to 0.785."
        },
        {
            "heading": "3.2.3. Attitude towards using ChatGPT in writing",
            "text": "Attitude towards using ChatGPT in writing was measured on a five-item scale adapted from Edmunds et\u00a0al. (2012). The five items (e.g., \u2018I like using ChatGPT while writing in English\u2019) demonstrated excellent reliability (Cronbach\u2019s \u03b1 = 0.915). As indicated by Hu and Bentler (1999), the CFA results showed good construct validity (\u03c72 = 10.184, df = 5, RMSEA = 0.065, CFI = 0.994, TLI = 0.987), with factor loading ranging from 0.775 to 0.879."
        },
        {
            "heading": "3.2.4. Behavioural intention to use ChatGPT in writing",
            "text": "Behavioural intention to use ChatGPT in writing was measured on a five-item scale adapted from Lee and Lehto (2013) and Rafique et\u00a0al. (2020). The five items (e.g., \u201cI intend to use ChatGPT to improve my English writing ability in the future\u201d) showed high reliability (Cronbach\u2019s \u03b1 = 0.871). According to Hu and Bentler (1999), the CFA results demonstrated good construct validity (\u03c72 = 7.976, df = 5, RMSEA = 0.050, CFI = 0.995, TLI = 0.990), with factor loading ranging from 0.659 to 0.838."
        },
        {
            "heading": "3.2.5. Past ChatGPT use experience",
            "text": "In the present study, students\u2019 past ChatGPT use experience was operationalized as whether the students had used ChatGPT de facto at the time of data collection. It was measured via one item, i.e., \u201cHave you\u00a0ever used ChatGPT before?\u201d The respondents indicated their past experience on a yes-no scale (Yes = 1, No = 0)."
        },
        {
            "heading": "3.3. Data analysis",
            "text": "SPSS 24.0 and Mplus 7.4 Software were used for data analysis. First, the SPSS software was used to conduct descriptive analysis and correlation analysis. Then, the Mplus software was utilized to construct structural equation modelling (SEM), with a view to calculating relationships among focus variables and conduct mediation analysis. For mediation analysis, bias-corrected bootstrapping method with 2000 times of resampling was employed to calculate the point\nFIGURE\u00a01 Conceptual model.\nFrontiers in Psychology 05 frontiersin.org\nestimates of the confidence intervals regarding the mediating effects. In light of Hu and Bentler\u2019s (1999) research, the fit of the model was evaluated by the following cut-off values: Root mean-square error of approximation (RMSEA) < 0.08; Tucker-Lewis index (TLI) > 0.90; and comparative fit index (CFI) > 0.90.\nAdditionally, Harman\u2019s single factor test was conducted by SPSS software to exclude possible common variance bias. The results showed that less than 50% (46.80%) of the total variance of variables were explained after all the items were loaded into one factor, indicating no need to control common variance bias (Mat Roni, 2014)."
        },
        {
            "heading": "4. Results",
            "text": ""
        },
        {
            "heading": "4.1. Preliminary analysis",
            "text": "The descriptive statistics of all variables are presented in Table\u00a01. Except for past ChatGPT use experience, the other four focus variables\u2019 score fall between 3.954 and 4.159, indicating mid-to-high levels on behavioural intentions, attitudes, perceived usefulness and perceived ease of use regarding ChatGPT. Particularly, the students reported the highest score on behavioural intention (M = 4.159), revealing doctoral students\u2019 high intention to use ChatGPT in writing in this study.\nAs suggested by the correlation matrix in Table\u00a01, perceived ease of ChatGPT use (\u03b3 = 0.590, p < 0.001), perceived usefulness of ChatGPT (\u03b3 = 0.632, p < 0.001), and attitude towards using ChatGPT (\u03b3 = 0.784, p < 0.001) were significantly and positively correlated with students\u2019 behavioural intention to use ChatGPT in writing. Besides, both perceived ease of ChatGPT use (\u03b3 = 0.688, p < 0.001) and perceived usefulness of ChatGPT (\u03b3 = 0.701, p < 0.001) were significantly and positively correlated with doctoral students\u2019 attitude towards using ChatGPT in writing. Perceived ease of ChatGPT use was significantly and positively correlated with perceived usefulness of ChatGPT in writing (\u03b3 = 0.660, p < 0.001). Moreover, past ChatGPT use experience was significantly and positively correlated with students\u2019 perceived ease of ChatGPT use (\u03b3 = 0.163, p < 0.05), but it was not significantly correlated with perceived usefulness of ChatGPT in writing (\u03b3 = 0.032, p > 0.05)."
        },
        {
            "heading": "4.2. Structural equation modelling",
            "text": "SEM analysis was conducted to examine the relationships among focus variables with gender being controlled for all the structural relationships. As shown in Figure\u00a02, the model had a high explanation for variance in students\u2019 behavioural intention to use ChatGPT in writing (80.1%), attitude towards using ChatGPT (70.2%), and perceived usefulness of ChatGPT (65.7%), respectively, and a low explanation for variance in perceived ease of ChatGPT use (2.4%). The model fit indices (\u03c72 = 350.545, df = 198, RMSEA = 0.056, CFI = 0.951, TLI = 0.943) indicates a good SEM model fit.\nPerceived attitude towards using ChatGPT in writing had significant and positive impacts on students\u2019 behavioural intention to use ChatGPT in writing (\u03b2 = 0.850, p < 0.001), supporting H1. Perceived usefulness of using ChatGPT had significant total influences on students\u2019 behavioural intention to use ChatGPT (\u03b2 = 0.577, p < 0.001), but did not have significant and direct influences on it (\u03b2 = 0.117, p > 0.05), thus rejecting H2. However, perceived usefulness of ChatGPT had positive and significant influences on students\u2019 attitude towards using ChatGPT in writing (\u03b2 = 0.541, p < 0.001), thus supporting H3. Besides, perceived ease of use had significant and positive effects on students\u2019 perceived usefulness of ChatGPT in writing (\u03b2 = 0.817, p < 0.001), thus supporting H5. Perceived ease of ChatGPT use had positive and significant influences on students\u2019 attitude towards using ChatGPT in writing (\u03b2 = 0.337, p < 0.001), thereby supporting H6. Perceived ease of use had significant total influences on students\u2019 behavioural intention to use ChatGPT (\u03b2 = 0.689, p < 0.001) but had no significant and direct influence on it (\u03b2 = \u22120.069, p > 0.05), rejecting H8. In addition, past ChatGPT use experience had significant and positive influences on students\u2019 perceived ease of using ChatGPT in writing (\u03b2 = 140, p < 0.05) but had no significant influence on perceived usefulness of ChatGPT (\u03b2 = \u22120.065, p > 0.05). Therefore, the results supported H10 but rejected H9.\nAdditionally, results of mediation analysis (Table\u00a02) show that students\u2019 attitude towards using ChatGPT significantly mediated the effects of perceived usefulness of ChatGPT on their behavioural intention to use ChatGPT in writing (\u03b2 = 0.460, p < 0.001, 95% CIs: 0.149 to 0.771), hence supporting H4. It also significantly mediated\nTABLE\u00a01 Results of descriptive statistics and correlation analysis.\n1 2 3 4 5\n1. Behavioural intention to use ChatGPT in writing 1\n2. Attitude towards using ChatGPT in writing 0.784*** 1\n3. Perceived usefulness of ChatGPT in writing 0.632*** 0.701*** 1\n4. Perceived ease of ChatGPT use in writing 0.590*** 0.688*** 0.660*** 1\n5. Past ChatGPT use experience 0.093 0.132* 0.032 0.163* 1\nMean 4.159 3.954 4.106 4.017 0.463\nSD 0.917 0.953 0.930 0.820 0.500\nStandardized coefficients are reported. *p < 0.05; ***p < 0.001.\nFrontiers in Psychology 06 frontiersin.org\nthe influences of perceived ease of ChatGPT use on students\u2019 behavioural intention to use ChatGPT in writing (\u03b2 = 0.287, p < 0.05, 95% CIs: 0.022 to 0.552). Thus, H7 was supported."
        },
        {
            "heading": "5. Discussion",
            "text": "While ChatGPT has ignited debates about its applications in education (e.g., Farrokhnia et\u00a0al., 2023), it remains unknown whether students are willing to use it or not in writing. This research contributes to the existing literature by investigating Chinese doctoral students\u2019 acceptance toward ChatGPT in writing and its major influencing factors. Through the lens of TAM, the present study revealed a strong intention to use ChatGPT in writing among doctoral students, which was affected by their attitudes, perceived usefulness, and perceived ease of use. The findings provide a deeper understanding of doctoral students\u2019 acceptance inclination toward ChatGPT and other generative AI chatbots in writing in higher education.\nAlthough ChatGPT remains new, the doctoral students demonstrated a strong intention to use it in writing. This corroborates Taecharungroj\u2019s (2023) finding that ChatGPT has been mainly used\nin the writing domain. Students\u2019 high behavioural intentions might be\u00a0attributed to the affordances of ChatGPT for writing. As shown in prior research (e.g., Bishop, 2023; Yan, 2023), ChatGPT could help students to brainstorm ideas, obtain timely and personalized feedback, translate language items, and improve written drafts. This makes it a potential mediation tool for doctoral students to write more fluently and effectively in the publish-or-perish system (Kirkpatrick, 2019).\nConsistent with our prediction, doctoral students\u2019 attitude towards using ChatGPT in writing was found to be\u00a0a significant predictor of behavioural intention. While a number of prior studies have removed attitudes from TAM due to its weak role in mediating the effects of perceived usefulness and perceived ease of use on behavioural intention (e.g., Lee and Lehto, 2013; Yang and Wang, 2019), this study found that attitude not only directly influences behavioural intention but also mediates the impacts of perceived usefulness and perceived ease of use on it. The finding lends support to the original TAM (Davis et\u00a0al., 1989). It also supports Ajzen\u2019s (1991) argument that personal attitude towards a behaviour functions as a major determinant of people\u2019s intentions to perform it. In other words, when doctoral students have more positive evaluation of using ChatGPT in writing, they are more willing to perform the behaviour. Also, as suggested by\nFIGURE\u00a02 Modified model for behavioural intentions to use ChatGPT in writing. Standardized coefficients are reported. *p < 0.05, **p < 0.01, ***p < 0.001.\nTABLE\u00a02 Results of mediation analysis.\n\u03b2 S.E. 95% Confidence intervals Perceived usefulness \u2192 behavioural intention to use ChatGPT in writing (Direct effect) 0.117 0.179 [\u22120.233, 0.467]\nPerceived usefulness \u2192 attitude towards using \u2192 behavioural intention to use ChatGPT in writing 0.460** 0.159 [0.149,0.771]\nPerceived ease of use \u2192 behavioural intention to use ChatGPT in writing (Direct effect) \u22120.069 0.137 [\u22120.337, 0.200]\nPerceived ease of use \u2192 attitude towards using \u2192 behavioural intention to use ChatGPT in writing 0.287* 0.135 [0.022, 0.552]\nStandardized coefficients are reported. *p < 0.05; **p < 0.01.\nFrontiers in Psychology 07 frontiersin.org\nthe expectancy-value model of attitudes (Ajzen, 1991; Ajzen and Fishbein, 2008), people\u2019s attitude is further determined by salient beliefs regarding the outcome of performing the behaviour and attributes associated with the behaviour, such as the cost and effort incurred by performing it. In this sense, positively valued outcomes and easier management of the technology could strengthen users\u2019 affective reactions towards the technology and boost their sense of efficacy, hence contributing to their favourable attitude towards it and the resultant increasing behavioural intention (Davis et\u00a0al., 1989). As shown in this study, doctoral students\u2019 attitude towards using ChatGPT in writing, shaped by the perceived usefulness and ease of use, played an important role in mediating their effects on students\u2019 intention to use ChatGPT in writing.\nFurthermore, the results revealed that perceived usefulness and perceived ease of use had significant total influences on students\u2019 behavioural intention to use ChatGPT in writing. This echoes the central role of perceived usefulness and perceived ease of use in the adoption process of technology in prior research examining TAM (Cheng, 2019; Grani\u0107 and Maranguni\u0107, 2019; Alfadda and Mahdi, 2021). Nevertheless, the study found no significant direct influence of them on doctoral students\u2019 behavioural intention. Instead, they only influenced behavioural intention through attitudes. This surprising finding is inconsistent with previous studies on people\u2019 acceptance of educational technology (e.g., Estriegana et\u00a0al., 2019; Yang and Wang, 2019). This might be\u00a0due to the fact that some researchers (Davis, 1989; Lee and Lehto, 2013; Chang et\u00a0al., 2017; Yang and Wang, 2019) did not include the attitude variable in their models and consequently failed to explore its mediating effects. Another plausible explanation might be\u00a0that ChatGPT remains new, and early adopters use ChatGPT mainly because it facilitates inherently enjoyable and interesting experience (Taecharungroj, 2023; Tlili et\u00a0al., 2023). In other words, the use of ChatGPT at this stage is primarily intrinsically motivated (Davis et\u00a0 al., 1992). Accordingly, the expected outcome of using ChatGPT for enhancing writing performance at the extrinsic level and perceived ease of using ChatGPT at the technical level could be\u00a0instrumental, when such beliefs catalyse intrinsic motivations and when using ChatGPT in writing appeals to individuals (Ryan and Deci, 2000).\nAlso, the study found that perceived ease of use was found to be\u00a0 significantly and positively influenced perceived usefulness of ChatGPT in writing. This is analogous to Rafique et\u00a0al.\u2019s (2020) study, in which users\u2019 perceived ease of using mobile library applications had a significant influence on perceived usefulness. By the same token, users\u2019 perceived ease of using ChatGPT in writing could greatly shape the perceived usefulness (Davis et\u00a0 al., 1989). If doctoral students consider it challenging to apply ChatGPT in writing, they are likely to hold that ChatGPT has little effect on their writing. When they perceive ChatGPT easy to use, they tend to regard it as useful and helpful for writing.\nIn addition, this study extends prior research on TAM by including experience as an external factor to enhance the model explanatory power. Doctoral students\u2019 past ChatGPT experience is proved to be\u00a0a significant predictor for perceived ease of use. The more experienced the students are, the more positive they are about the ease of using ChatGPT in EFL writing. This is compatible with Purnomo and Lee\u2019s (2013) study, where prior computer experience had a positive influence on learners\u2019 perceived ease of use an\ne-learning system and such influence was stronger than that on perceived usefulness. The findings also support of argument Nelson\u2019s (1990) that the acceptance of technology relies upon not only the technology itself but also individuals\u2019 expertise in using it. Students with experience in using generative AI chatbots could employ the knowledge and skills obtained from prior experience to writing, develop a better personal control, and accordingly perceive it easier to use it in writing (e.g., Purnomo and Lee, 2013; Chang et\u00a0al., 2017)."
        },
        {
            "heading": "6. Conclusion",
            "text": "Despite the increasing interest in ChatGPT in educational settings, research on its acceptance is still scarce in education. Based on TAM, descriptive statistics, correlation analysis, and SEM were employed to gauge doctoral students\u2019 acceptance of ChatGPT in writing and explore the influencing factors. Data analysis revealed a high-level intention to use ChatGPT in writing, shaped by doctoral students\u2019 attitudes, perceived usefulness, and perceived ease of use. The present study could contribute to ChatGPT research in both theoretical and practical ways. Theoretically, the inclusion of experience in TAM helps to reveal the variables that could influence doctoral students\u2019 adoption of ChatGPT in EFL writing. As our model explained 80.1% of the variance in behavioural intention, this study overall supports and advances the applicability of TAM in ChatGPT, a new technology in writing education.\nPractically, the results of the study could also generate useful implications for technology developers, policy-makers, writing teachers, and doctoral students to leverage ChatGPT for the teaching and learning of writing. Doctoral students\u2019 strong intention to use ChatGPT in writing suggest that ChatGPT may augment its function as an educational tool for writing in higher education. Considering the significant and strong effect of attitude on students\u2019 behavioural intentions to use ChatGPT in writing, it is of necessity for educational institutions, writing teachers, and technology developers to be\u00a0 aware of students\u2019 attitudes and increase their positive evaluation of and affective reactions towards using ChatGPT in writing. For instance, technology developer can make the usage of ChatGPT more innovative, enjoyable and interesting so as to create more positive attitudes and boost learners\u2019 intrinsic motivation to use ChatGPT in writing. Given the increasing concerns for information, ethical and learning risks associated with ChatGPT (e.g., Barrot, 2023; Dwivedi et\u00a0al., 2023) and doctoral students\u2019 strong intention to use ChatGPT for writing, measures must be\u00a0taken to mitigate such negative impacts of ChatGPT on doctoral students. For example, technology developers can strengthen the quality control of generated responses. Similarly, writing teachers need to provide trainings on effective, ethical and responsible use of ChatGPT in writing. Besides, perceived ease of use and perceived usefulness are found to have a significant influence on students\u2019 attitude, which could further exert an effect on students\u2019 intentions to use ChatGPT in writing. The sequential and circular influential relationship among the variables implies a need for technology developers to increase the usefulness and ease of using ChatGPT in writing to make it more functional and user-friendly. For\nFrontiers in Psychology 08 frontiersin.org\nexample, technology developers can keep simplifying and optimizing the operation of ChatGPT based on user feedback and provide comprehensible instructions or use cases regarding how to apply ChatGPT to write more effectively and ethically. Instead of prohibiting the use of ChatGPT in writing, policy makers need to take into consideration the students\u2019 voice and align their educational needs with the AI tool (EDUCAUSE, 2023). For writing teachers and institutional administrators, efforts to integrate ChatGPT in writing courses or training programs are needed to capitalize on ChatGPT\u2019s affordances for writing and improve students\u2019 ability to use ChatGPT as an effective writing assistant tool. Given the significant effect of past ChatGPT experience on perceived ease of ease, instructing doctoral students to increase their use of ChatGPT, and reflect upon and communicate the skills for utilizing ChatGPT to promote writing performance could be\u00a0an effective way to develop their expertise in ChatGPT. Also, doctoral students can experiment with ChatGPT in a conscious manner, and record their hands-on experience to continuously improve the capability for effective and ethical use of ChatGPT for writing.\nRegardless of the contributions, there are several limitations that need to be\u00a0taken into consideration in future research. Firstly, while the study revealed a high intention to use ChatGPT in writing among doctoral students, it was exploratory in nature and only used questionnaires to gauge students\u2019 acceptance of ChatGPT. Future research can thus employ case study research deign or mixed study research design and collect multiple sources of data (e.g., semistructured interviews, user reflections, and screenshots) to obtain an idiosyncratic and in-depth understanding of students\u2019 actual process and outcome of using ChatGPT in writing. Secondly, the present study was based on a sample of doctoral students from a science and technology university in China. The types of writing assignments they face and their needs for using ChatGPT to improve writing could be\u00a0very different from other learner groups like undergraduates (Yan, 2023) and students in other countries, which limits the generalizability of this study. Therefore, future research can expand the sample scope to include students with varied educational levels and backgrounds to increase the generalizability and representativeness. It may also be\u00a0interesting to conduct cross-section research to examine whether the level of use acceptance across different learner groups in the future. Thirdly, our data was collected from participants who interacted with ChatGPT shortly after the release of ChatGPT and who used ChatGPT primarily for its inherently enjoyable and interesting experience (Taecharungroj, 2023; Tlili et\u00a0 al., 2023). Given the increasing ethical, learning and information concerns concerning the use of ChatGPT in writing in academia (Barrot, 2023; Su et\u00a0al., 2023) and students\u2019 growing experience, knowledge and skills regarding ChatGPT, their attitudes, perceptions and intentions of using ChatGPT in writing may alter over time. Longitudinal research can be\u00a0conducted to trace the development of knowledge concerning the use of ChatGPT for writing among doctoral students, and how such knowledge influences their attitudes towards, as well as perceptions and intentions of using ChatGPT in writing. Considering the doctoral students\u2019 high intention to use ChatGPT for writing and the increasing concerns for information, ethical and\nlearning risks associated with ChatGPT (e.g., Barrot, 2023; Dwivedi et\u00a0al., 2023), it is also promising to explore effective ways to integrate ChatGPT in writing instruction and construct writing models to empower students to collaborate with ChatGPT in an effective, ethical and responsible manner."
        },
        {
            "heading": "Data availability statement",
            "text": "The raw data supporting the conclusions of this article will be\u00a0made available by the authors, without undue reservation."
        },
        {
            "heading": "Ethics statement",
            "text": "The studies involving humans were approved by the ethics committee of the School of Foreign Languages, Beijing Institute of Technology. The studies were conducted in accordance with the local legislation and institutional requirements. The participants provided their written informed consent to participate in this study."
        },
        {
            "heading": "Author contributions",
            "text": "MZ: Conceptualization, Funding acquisition, Investigation, Project administration, Writing \u2013 original draft. LH: Conceptualization, Formal analysis, Methodology, Software, Writing \u2013 review & editing."
        },
        {
            "heading": "Funding",
            "text": "The author(s) declare financial support was received for the research, authorship, and/or publication of this article. This work was supported by Beijing Association of Higher Education under Grant MS2022225 and 2023 Beijing Institute of Technology Science and Technology Innovation Program \u201cBIT Think Tank\u201d Advancement Plan Funding Project under Grant 2023CX13030."
        },
        {
            "heading": "Conflict of interest",
            "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be\u00a0construed as a potential conflict of interest."
        },
        {
            "heading": "Publisher\u2019s note",
            "text": "All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\nFrontiers in Psychology 09 frontiersin.org"
        }
    ],
    "title": "To use or not to use? Understanding doctoral students\u2019 acceptance of ChatGPT in writing through technology acceptance model",
    "year": 2023
}