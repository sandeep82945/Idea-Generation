{
    "abstractText": "1 School of Mathematics, Physics and Optoelectronic Engineering, Hubei University of Automotive Technology, Shiyan 442002, China 2 Hubei Key Laboratory of Applied Mathematics, Hubei University, Wuhan 430061, China 3 School of Electrical and Information Engineering, Hubei University of Automotive Technology, Shiyan 442002, China 4 School of Liberal Arts and Humanities, Sichuan Vocational College of Finance and Economics, Chengdu 610101, China * Correspondence: xujinyu_2007@126.com \u2020 These authors contributed equally to this work.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ravi P. Agarwal"
        },
        {
            "affiliations": [],
            "name": "Maria Alessandra Ragusa"
        },
        {
            "affiliations": [],
            "name": "Zelin Zhang"
        },
        {
            "affiliations": [],
            "name": "Jun Wu"
        },
        {
            "affiliations": [],
            "name": "Yufeng Chen"
        },
        {
            "affiliations": [],
            "name": "Ji Wang"
        },
        {
            "affiliations": [],
            "name": "Jinyu Xu"
        }
    ],
    "id": "SP:92622b93a707b5062f3c79d9d872f86f3cd2f349",
    "references": [
        {
            "authors": [
                "S. Sulistiyono",
                "A. Akhiruyanto",
                "N. Primasoni",
                "F. Arjuna",
                "N. Santoso",
                "D. Yudhistira"
            ],
            "title": "The effect of 10 weeks game experience learning (gel) based training on teamwork, respect attitude, skill and physical ability in young football players",
            "venue": "Teori\u0300a\u0302 ta Metod. Fi\u0300zic\u030cnogo Vihovanna\u0302",
            "year": 2021
        },
        {
            "authors": [
                "T. Gao",
                "K. Fadnis",
                "M. Campbell"
            ],
            "title": "Local-to-global Bayesian network structure learning",
            "venue": "In Proceedings of the International Conference on Machine Learning, Sydney, Australia,",
            "year": 2017
        },
        {
            "authors": [
                "N. Friedman",
                "M. Goldszmidt"
            ],
            "title": "Learning Bayesian networks with local structure",
            "venue": "In Learning in Graphical Models; Springer: Berlin/Heidelberg, Germany,",
            "year": 1998
        },
        {
            "authors": [
                "C. Lei",
                "X. Zhu"
            ],
            "title": "Unsupervised feature selection via local structure learning and sparse learning",
            "venue": "Multimed. Tools Appl",
            "year": 2018
        },
        {
            "authors": [
                "J. Li",
                "G. Wen",
                "J. Gan",
                "L. Zhang",
                "S. Zhang"
            ],
            "title": "Sparse nonlinear feature selection algorithm via local structure learning",
            "venue": "Emerg. Sci. J. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "S. Liao",
                "D. Yi",
                "Z. Lei",
                "R. Qin",
                "S.Z. Li"
            ],
            "title": "Heterogeneous face recognition from local structures of normalized appearance",
            "venue": "In Proceedings of the International Conference on Biometrics, Alghero, Italy,",
            "year": 2009
        },
        {
            "authors": [
                "J. Qian",
                "J. Yang",
                "Y. Xu"
            ],
            "title": "Local structure-based image decomposition for feature extraction with applications to face recognition",
            "venue": "IEEE Trans. Image Process",
            "year": 2013
        },
        {
            "authors": [
                "L. Heo",
                "M. Feig"
            ],
            "title": "High-accuracy protein structures by combining machine-learning with physics-based refinement",
            "venue": "Proteins Struct. Funct. Bioinform",
            "year": 2020
        },
        {
            "authors": [
                "L. Zhang",
                "G. Du",
                "F. Liu",
                "H. Tu",
                "X. Shu"
            ],
            "title": "Global-local multiple granularity learning for cross-modality visible-infrared person reidentification",
            "venue": "IEEE Trans. Neural Netw. Learn. Syst",
            "year": 2021
        },
        {
            "authors": [
                "C.E. Shannon"
            ],
            "title": "A mathematical theory of communication, 1948",
            "venue": "Bell Syst. Tech. J. 1948,",
            "year": 1948
        },
        {
            "authors": [
                "J.S. Richman",
                "D.E. Lake",
                "J.R. Moorman"
            ],
            "title": "Sample entropy. In Methods in Enzymology",
            "year": 2004
        },
        {
            "authors": [
                "J.M. Yentes",
                "N. Hunt",
                "K.K. Schmid",
                "J.P. Kaipust",
                "D. McGrath",
                "N. Stergiou"
            ],
            "title": "The appropriate use of approximate entropy and sample entropy with short data sets",
            "venue": "Ann. Biomed. Eng",
            "year": 2013
        },
        {
            "authors": [
                "M. Costa",
                "A.L. Goldberger",
                "C.K. Peng"
            ],
            "title": "Multiscale entropy analysis of biological signals",
            "venue": "Phys. Rev. E 2005,",
            "year": 2190
        },
        {
            "authors": [
                "M.A. Busa",
                "R.E. van Emmerik"
            ],
            "title": "Multiscale entropy: A tool for understanding the complexity of postural control",
            "venue": "J. Sport Health Sci. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "C. Bandt",
                "B. Pompe"
            ],
            "title": "Permutation entropy: A natural complexity measure for time series",
            "venue": "Phys. Rev. Lett",
            "year": 2002
        },
        {
            "authors": [
                "K. Keller",
                "T. Mangold",
                "I. Stolz",
                "J. Werner"
            ],
            "title": "Permutation entropy: New ideas and challenges",
            "venue": "Entropy 2017,",
            "year": 2017
        },
        {
            "authors": [
                "Z. Zhang",
                "Z. Xiang",
                "Y. Chen",
                "J. Xu"
            ],
            "title": "Fuzzy permutation entropy derived from a novel distance between segments of time series",
            "venue": "AIMS Math. 2020,",
            "year": 2020
        },
        {
            "authors": [
                "F.C. Morabito",
                "D. Labate",
                "F. La Foresta",
                "A. Bramanti",
                "G. Morabito",
                "I. Palamara"
            ],
            "title": "Multivariate multi-scale permutation entropy for complexity analysis of Alzheimer\u2019s disease",
            "venue": "EEG. Entropy",
            "year": 2012
        },
        {
            "authors": [
                "S. He",
                "K. Sun",
                "H. Wang"
            ],
            "title": "Multivariate permutation entropy and its application for complexity analysis of chaotic systems",
            "venue": "Phys. A Stat. Mech. Its Appl",
            "year": 2016
        },
        {
            "authors": [
                "E. Romera",
                "\u00c1. Nagy"
            ],
            "title": "Density functional fidelity susceptibility and Kullback\u2013Leibler entropy",
            "venue": "Phys. Lett. A",
            "year": 2013
        },
        {
            "authors": [
                "J. Wang",
                "N. Zheng",
                "B. Chen",
                "P. Chen",
                "S. Chen",
                "Z. Liu",
                "F.Y. Wang",
                "B. Xi"
            ],
            "title": "Multivariate Correlation Entropy and Law Discovery in Large Data Sets",
            "venue": "IEEE Intell. Syst",
            "year": 2018
        },
        {
            "authors": [
                "S. Yu",
                "L.G.S. Giraldo",
                "R. Jenssen",
                "J.C. Principe"
            ],
            "title": "Multivariate Extension of Matrix-Based R\u00e9nyi\u2019s \u03b1-Order Entropy Functional",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 2019
        },
        {
            "authors": [
                "Z. Wang",
                "P. Shang"
            ],
            "title": "Generalized entropy plane based on multiscale weighted multivariate dispersion entropy for financial time series",
            "venue": "Chaos Solitons Fractals",
            "year": 2021
        },
        {
            "authors": [
                "X. Wang",
                "S. Si",
                "Y. Li"
            ],
            "title": "Variational Embedding Multiscale Diversity Entropy for Fault Diagnosis of Large-Scale Machinery",
            "venue": "IEEE Trans. Ind. Electron",
            "year": 2022
        },
        {
            "authors": [
                "Y. Yin",
                "X. Wang",
                "Q. Li",
                "P. Shang"
            ],
            "title": "Generalized multivariate multiscale sample entropy for detecting the complexity in complex systems",
            "venue": "Phys. A Stat. Mech. Its Appl",
            "year": 2020
        },
        {
            "authors": [
                "T.B. Berrett",
                "R.J. Samworth",
                "M. Yuan"
            ],
            "title": "Efficient multivariate entropy estimation via k-nearest neighbour distances",
            "venue": "Ann. Stat",
            "year": 2019
        },
        {
            "authors": [
                "H. Azami",
                "J. Escudero"
            ],
            "title": "Refined composite multivariate generalized multiscale fuzzy entropy: A tool for complexity analysis of multichannel signals",
            "venue": "Phys. A Stat. Mech. Its Appl",
            "year": 2017
        },
        {
            "authors": [
                "Y.F. Han",
                "N.D. Jin",
                "L.S. Zhai",
                "Y.Y. Ren",
                "Y.S. He"
            ],
            "title": "An investigation of oil\u2013water two-phase flow instability using multivariate multi-scale weighted permutation entropy",
            "venue": "Phys. A Stat. Mech. Its Appl",
            "year": 2019
        },
        {
            "authors": [
                "X. Mao",
                "P. Shang",
                "Q. Li"
            ],
            "title": "Multivariate multiscale complexity-entropy causality plane analysis for complex time series",
            "venue": "Nonlinear Dyn",
            "year": 2019
        },
        {
            "authors": [
                "B. Shang",
                "P. Shang"
            ],
            "title": "Complexity analysis of multiscale multivariate time series based on entropy plane via vector visibility graph",
            "venue": "Nonlinear Dyn",
            "year": 2020
        },
        {
            "authors": [
                "A.L. Barab\u00e1si",
                "R. Albert"
            ],
            "title": "Emergence of scaling in random networks",
            "venue": "Science",
            "year": 1999
        },
        {
            "authors": [
                "J. Cong",
                "H. Liu"
            ],
            "title": "Approaching human language with complex networks",
            "venue": "Phys. Life Rev",
            "year": 2014
        },
        {
            "authors": [
                "J. Ruths",
                "D. Ruths"
            ],
            "title": "Control profiles of complex networks",
            "venue": "Science",
            "year": 2014
        },
        {
            "authors": [
                "R. Albert",
                "H. Jeong",
                "A.L. Barab\u00e1si"
            ],
            "title": "Error and attack tolerance of complex networks",
            "venue": "Nature",
            "year": 2000
        },
        {
            "authors": [
                "J.F. Donges",
                "Y. Zou",
                "N. Marwan",
                "J. Kurths"
            ],
            "title": "Complex networks in climate dynamics",
            "venue": "Eur. Phys. J. Spec. Top",
            "year": 2009
        },
        {
            "authors": [
                "S. Mutua",
                "C. Gu",
                "H. Yang"
            ],
            "title": "Visibility graphlet approach to chaotic time series",
            "venue": "Chaos 2016,",
            "year": 2016
        },
        {
            "authors": [
                "N. Marwan",
                "J. Kurths"
            ],
            "title": "Complex network based techniques to identify extreme events and (sudden) transitions in spatio-temporal systems",
            "venue": "Chaos",
            "year": 2015
        },
        {
            "authors": [
                "Z. Zhang",
                "J. Xu",
                "X. Zhou"
            ],
            "title": "Mapping time series into complex networks based on equal probability division",
            "venue": "AIP Adv. 2019,",
            "year": 2019
        },
        {
            "authors": [
                "Y. Zhao",
                "X. Peng",
                "M. Small"
            ],
            "title": "Reciprocal characterization from multivariate time series to multilayer complex networks",
            "venue": "Chaos",
            "year": 2020
        },
        {
            "authors": [
                "M. Small",
                "J. Zhang",
                "X. Xu"
            ],
            "title": "Transforming time series into complex networks",
            "venue": "Lect. Notes Inst. Comput. Sci. Soc. Telecommun. Eng. 2009,",
            "year": 2009
        },
        {
            "authors": [
                "V.F. Silva",
                "M.E. Silva",
                "P. Ribeiro",
                "F. Silva"
            ],
            "title": "Time series analysis via network science: Concepts and algorithms",
            "venue": "Wiley Interdiscip. Rev. Data Min. Knowl. Discov. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "L. Lacasa",
                "B. Luque",
                "F. Ballesteros",
                "J. Luque",
                "J.C. Nuno"
            ],
            "title": "From time series to complex networks: The visibility graph",
            "venue": "Proc. Natl. Acad. Sci. USA",
            "year": 2008
        },
        {
            "authors": [
                "L. Lacasa",
                "W. Just"
            ],
            "title": "Visibility graphs and symbolic dynamics",
            "venue": "Phys. D Nonlinear Phenom",
            "year": 2018
        },
        {
            "authors": [
                "R.V. Donner",
                "M. Small",
                "J.F. Donges",
                "N. Marwan",
                "Y. Zou",
                "R. Xiang",
                "J. Kurths"
            ],
            "title": "Recurrence-based time series analysis by means of complex network methods",
            "venue": "Int. J. Bifurc. Chaos",
            "year": 2011
        },
        {
            "authors": [
                "J.F. Donges",
                "J. Heitzig",
                "R.V. Donner",
                "J. Kurths"
            ],
            "title": "Analytical framework for recurrence network analysis of time series",
            "venue": "Phys. Rev. E",
            "year": 2012
        },
        {
            "authors": [
                "Y. Ruan",
                "R.V. Donner",
                "S. Guan",
                "Y. Zou"
            ],
            "title": "Ordinal partition transition network based complexity measures for inferring coupling direction and delay from time series",
            "venue": "Chaos Interdiscip. J. Nonlinear Sci",
            "year": 2019
        },
        {
            "authors": [
                "H. Guo",
                "J.Y. Zhang",
                "Y. Zou",
                "S.G. Guan"
            ],
            "title": "Cross and joint ordinal partition transition networks for multivariate time series analysis",
            "venue": "Front. Phys. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "R.V. Donner",
                "Y. Zou",
                "J.F. Donges",
                "N. Marwan",
                "J. Kurths"
            ],
            "title": "Recurrence networks\u2014A novel paradigm for nonlinear time series analysis",
            "venue": "New J. Phys",
            "year": 2010
        },
        {
            "authors": [
                "C. Li",
                "G. Chen"
            ],
            "title": "Chaos in the fractional order Chen system and its control",
            "venue": "Chaos Solitons Fractals",
            "year": 2004
        },
        {
            "authors": [
                "W. Zhang",
                "S. Zhou",
                "H. Li",
                "H. Zhu"
            ],
            "title": "Chaos in a fractional-order R\u00f6ssler system",
            "venue": "Chaos Solitons Fractals",
            "year": 2009
        },
        {
            "authors": [
                "W.C. Chen"
            ],
            "title": "Nonlinear dynamics and chaos in a fractional-order financial system",
            "venue": "Chaos Solitons Fractals",
            "year": 2008
        },
        {
            "authors": [
                "I. Podlubny"
            ],
            "title": "An introduction to fractional derivatives, fractional differential equations, to methods of their solution and some of their applications",
            "venue": "Math. Sci. Eng",
            "year": 1999
        },
        {
            "authors": [
                "I. Petr\u00e1\u0161"
            ],
            "title": "Fractional-Order Nonlinear Systems: Modeling, Analysis and Simulation; Springer Science & Business Media",
            "year": 2011
        },
        {
            "authors": [
                "H. Zhivomirov"
            ],
            "title": "A method for colored noise generation",
            "venue": "Rom. J. Acoust. Vib. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "G. Ouyang",
                "J. Li",
                "X. Liu",
                "X. Li"
            ],
            "title": "Dynamic characteristics of absence EEG recordings with multiscale permutation entropy analysis",
            "venue": "Epilepsy Res",
            "year": 2013
        },
        {
            "authors": [
                "S. Mukherjee",
                "P. Zawar-Reza",
                "A. Sturman",
                "A.K. Mittal"
            ],
            "title": "Characterizing atmospheric surface layer turbulence using chaotic return map analysis",
            "venue": "Meteorol. Atmos. Phys",
            "year": 2013
        },
        {
            "authors": [
                "K. Chidori",
                "Y. Yamamoto"
            ],
            "title": "Effects of the lateral amplitude and regularity of upper body fluctuation on step time variability evaluated using return map analysis",
            "venue": "PloS ONE 2017,",
            "year": 2017
        },
        {
            "authors": [
                "V. Rybin",
                "D. Butusov",
                "E. Rodionova",
                "T. Karimov",
                "V. Ostrovskii",
                "A. Tutueva"
            ],
            "title": "Discovering chaos-based communications by recurrence quantification and quantified return map analyses",
            "venue": "Int. J. Bifurc. Chaos 2022,",
            "year": 2022
        },
        {
            "authors": [
                "A. Voznesensky",
                "D. Butusov",
                "V. Rybin",
                "D. Kaplun",
                "T. Karimov",
                "E. Nepomuceno"
            ],
            "title": "Denoising Chaotic Signals using Ensemble Intrinsic Time-Scale Decomposition",
            "venue": "IEEE Access 2022. Available online: https://ieeexplore.ieee.org/abstract/document/9932609 (accessed on",
            "year": 2022
        },
        {
            "authors": [
                "H. Cao",
                "Y. Li"
            ],
            "title": "Unraveling chaotic attractors by complex networks and measurements of stock market complexity",
            "venue": "Chaos Interdiscip. J. Nonlinear Sci",
            "year": 2014
        },
        {
            "authors": [
                "F.M.L. Ribeiro"
            ],
            "title": "MAFAULDA\u2014Machinery Fault Database [Online], 2021",
            "venue": "Available online: http://www02.smt.ufrj.br/~offshore/ mfs/page_01.html (accessed on",
            "year": 2022
        },
        {
            "authors": [
                "Y.Y. Song",
                "L. Ying"
            ],
            "title": "Decision tree methods: Applications for classification and prediction",
            "venue": "Shanghai Arch. Psychiatry 2015,",
            "year": 2015
        },
        {
            "authors": [
                "G. Ren",
                "Y. Wang",
                "J. Ning",
                "Z. Zhang"
            ],
            "title": "Using near-infrared hyperspectral imaging with multiple decision tree methods to delineate black tea quality. Spectrochim",
            "venue": "Acta Part A Mol. Biomol. Spectrosc",
            "year": 2020
        },
        {
            "authors": [
                "Y. Himeur",
                "A. Alsalemi",
                "F. Bensaali",
                "A. Amira"
            ],
            "title": "Robust event-based non-intrusive appliance recognition using multi-scale wavelet packet tree and ensemble bagging",
            "venue": "tree. Appl. Energy",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Citation: Zhang, Z.; Wu, J.; Chen, Y.;\nWang, J.; Xu, J. Distinguish between\nStochastic and Chaotic Signals by a\nLocal Structure-Based Entropy.\nEntropy 2022, 24, 1752. https://\ndoi.org/10.3390/e24121752\nAcademic Editors: Ravi P. Agarwal\nand Maria Alessandra Ragusa\nReceived: 4 November 2022\nAccepted: 27 November 2022\nPublished: 30 November 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: multivariate time series; information entropy; chaotic sequence; random signal; machinery fault diagnose"
        },
        {
            "heading": "1. Introduction",
            "text": "The local structure and its integration are crucial components in defining the vast system as a whole. For instance, the personal abilities of football players on the field and their teamwork play key roles in a competition [1], or the seismic capacities of buildings rely on materials and frame structures [2]. However, people tend to use local structures to identify objects in machine learning work [3,4]. Numerous examples can be found in feature selection [5,6], pattern recognition [7\u20139], and so on. Is it possible that a local structure is enough to accomplish identification? If it is possible, it means that other methods, such as global\u2013local structure-based learning [10], are not necessary. So, no one can deny that it depends on specific issues. People tend to agree that only when local structures contain enough information for judging can the local structure-based strategies take effect. Therefore, finding the amount of information contained in the local structures of samples is important for further exploration. In the time series analysis field, entropies were used to reflect the amount of information contained in observed data. The first one can be traced back to Shannon entropy [11], which is defined as,\nH(X) = \u2212 \u2211 x\u2208X p(x)ln(p(x)) (1)\nwhere X is a random variable and p(x) is its probability density. For a time series, Equation (1) is valid under the assumption of stationarity despite whether X is univariate\nEntropy 2022, 24, 1752. https://doi.org/10.3390/e24121752 https://www.mdpi.com/journal/entropy\nor multivariate. Interested readers can refer to other entropies based on Equation (1) for univariate cases, such as sample entropy [12,13], multiscale entropy [14,15], permutation entropy (PE) [16\u201318], etc. These methods have one thing in common\u2014the observed time series is embedded into a phase space in order to reflect the autocorrelation. However, the abovementioned entropies, except for PE, cannot be directly generalized to multivariate cases. With regard to PE, although it naturally provides a multivariate version [19\u201321], it does not reflect correlations between components. Although the Kullback\u2013Leibler entropy [22] is a classical tool to assess the correlation between two components, it is asymmetrical and cannot be employed on a time series whose dimension is greater than 2. In general, correlations between different components together with autocorrelation in every component, are considered double-edged swords, which provide positive affection where the times series can be predicted, as well as a negative influence, where it is difficult to measure the complexity of a multi-dimensional time series. Researchers managed to introduce other entropies to characterize multivariate sequences, such as matrix-based entropy [23,24], multiscale entropy [25\u201327], and estimation methods [28]. For instance, Azami proposed a refined composite multivariate multiscale fuzzy entropy that demonstrates long-range, within, or cross-channel correlations [29]. Han proposed a multivariate multi-scale weighted permutation entropy to illustrate oil\u2013water two-phase flow instability [30]. Mao constructed a complexity\u2013entropy causality plane based on the normalized Shannon entropy and multivariate permutation entropy, thus characterizing various chaotic systems [31]. With the complex network method, Shang put forward another complexity\u2013entropy causality plane via multiscale entropy and the degree distribution of the vector visual graph to measure the complexity of the stock index [32]. The above-mentioned methods have at least one of the following drawbacks: (1) the observed sample numbers need to be large, otherwise the results are not reliable; (2) the computing times are long, so they cannot satisfy the real-time requirements of the application; (3) focusing on autocorrelation but neglecting relationships between components. To illuminate those shortcomings, we plan to use a complex network-like approach to represent the local structure. In the past decades, we have witnessed the development of complex network science [33\u201335], which is utilized to present complex systems such as climate dynamics [36] and human language [37]. Meanwhile, it is regarded as a newly advanced tool for time series analysis, such as for univariate cases [38\u201340] and multivariate cases [41]. Interested readers can find more information in the review articles [42,43]. These complex networkbased methods can be divided into three classes: visibility graph (VG) [44,45], recurrence net (RN) [46,47], and transition net (TN) [48,49]. For VG, a vertex is obtained by the linear relationship contained in fragments. For TN, a vertex is usually generated by certain coarsegraining strategies. Links between pairs of adjacent vertexes in VG or TN are naturally produced according to the order. However, RN is quite different. Its edges are bridged by the similarities of observed values. The validities of these methods also indicate that local structures together with their combination forms could represent essential characteristics of a complex system. Inspired by the above means, we propose a local structure-based entropy (LSE) for analyzing a multivariate time series. This can be regarded as a multivariate version of the Shannon Entropy defined on a discrete distribution of the local structure; the recurrence of the observed vector is employed to represent local structure information. In fact, RN is constructed by the similarity between all observed data. If we just consider the reappearances of the initial state in the sliding window, then its distribution can be viewed as a manifestation of local structure. The rest of this paper is organized as follows. Section 2 introduces the process of computing LSE; Section 3 tests LSE on the fractional-order chaotic time series; LSE is applied to the stock market index and bearing fault signals; finally, we draw our conclusions in Section 5."
        },
        {
            "heading": "2. Method",
            "text": "In [50], Donner introduced the construction of RN, which takes individual values as vertices and indicators of recurrences as edges. Here, a pair of states whose values are close enough can be regarded as recurrences. Thus, RN represents the reappearance of system states over a long period. It is natural for one to (hope to) use the recurrent numbers of the initial states in sliding windows of different lengths to characterize the complexities of the systems. Let xt = (x1t, x2t, . . . , xmt)Tt\u2264N be an m-dimensional time series. \u03c4 and i are integers with i + \u03c4 \u2212 1 \u2264 N. Extract fragment Yi from xt by\nYi =  x1,i . . . x1,(i+\u03c4\u22121)... ... ... xm,i . . . xm,(i+\u03c4\u22121)  (2) Let j \u2208 {0, 1, 2, . . . , \u03c4 \u2212 1}, yij denotes the (j + 1)th column vector of Yi. Define\ndisj = |yi0, yi1+j| (3)\nwhere |\u00b7, \u00b7| is a distance in Rm (in this paper, we use the Euclidean distance). Given a tolerant threshold r and the number of j, such that disj \u2264 r is called the recurrent number of Yi with the scale \u03c4, and the tolerance r is denoted by #(Yi; \u03c4, r). That is,\n#(Yi; \u03c4, r) = \u2211 j\u2208{1,2,...,\u03c4\u22121} sign(disj \u2264 r) (4)\nwhere sign(\u00b7) is the indicator function. Two examples of the above procedure are demonstrated in Figure 1.\nNow, the LSE of xt under scale \u03c4 and tolerance r is defined as\nLSE(xt; \u03c4, r) = \u2211 g(#(Yi; \u03c4, r))ln(g(#(Yi; \u03c4, r))) (5)\nwhere g(\u00b7) = p(\u00b7)/a\u03c4,r, p(\u00b7) represents the density function, and a\u03c4,r is the average of #(Yi; \u03c4, r). NOTE 1 The value of LSE depends on the selection of \u03c4 and r. When their ranges are given, they can be chosen by the maximal LSE. Namely,\n(\u03c4, r) = argmax \u03c4,r LSE(xt; \u03c4, r) (6)\nIn general, the range of \u03c4 can be decided by the length of the time series, such as 1/100 to 1/10 of the raw data. The range of r can be selected by referring to the standard deviation of the multivariate standard Gaussian series. See Appendix A.1. NOTE 2 Given a set of values for \u03c4 and r, respectively, such as \u03c4 \u2208 {\u03c41, \u03c42, . . . , \u03c4q} and r \u2208 {r1, r2, . . . , rs}, the values of LSE(xt; \u03c4i, rj) form a matrix, which presents the variation of the complexity of xt over different scales and tolerances. Therefore, it could be used to characterize xt. NOTE 3 We adopt two strategies for further exploration. To designate the corresponding LSE values, we utilize the variables LSEA and LSEB. METHOD A: normalize each component of xt and specify a tolerance range as described above, which leads to LSEA being immune to linear transformations; METHOD B: do not normalize xt but set tolerance range by the total of component variances, thus taking into account the extents of various channel volatilities. Broadly speaking, LSEA and LSEB are not equivalent, and they can be seen as two different ways of describing the initial sequence. See Appendix A.2 for more information."
        },
        {
            "heading": "3. Numerical Simulations",
            "text": "In this section, we test LSE on several multivariate deterministic and stochastic signals. At first, we analyze fractional-order chaotic systems and random series and find out ranges of \u03c4 and r in Section 3.1, then we test LSE on integer-order, fractional-order chaotic systems and random sequences in Section 3.2."
        },
        {
            "heading": "3.1. Fractional-Order Chaotic Systems and Random Series",
            "text": "Derivatives and integrals of fractional orders are employed to describe objects with memory properties, such as power law nonlocality or long-range dependence [51] and, thus, can model real-world systems more accurately than the classical integer calculus. Many fractional-order dynamical systems [52\u201354] with total order of less than three can exhibit chaos while continuous nonlinear systems with the total order of less than three cannot under the concept of the usual integer order. In this section, we simulate three multivariate fractional-order dynamical models and three random signals to test LSE. For many classes of functions, the three most well-known fractional-order derivatives (the Gr\u00fcnwald\u2013Letnikov (GL), Riemann\u2013Liouville, and Caputo) are equivalent under some conditions [55]. Here, we use the GL definition, i.e.,\nD\u03b1t f (t) = lim h\u21920 1 h\u03b1\n\u221e\n\u2211 j=0\n(\u22121)j (\n\u03b1 j\n) f (t\u2212 jh) (7)\nThen, for the fractional-order differential equation\naD\u03b1t y(t) = f (y(t), t) (8)\na general numerical solution has the form of [56]\ny(tk) = f (y(tk), tk)h\u03b1 \u2212 k\n\u2211 j=v\nc(\u03b1)j y(tk\u2212j) (9)\nwhere c(\u03b1)0 = 1, c (\u03b1) j = (1\u2212 1 + \u03b1 j )c(\u03b1)j\u22121 (10)\nThen, several different dynamic systems, including the fractional order chaotic system, multivariate vector autoregression moving-average process (VARMA), white Gaussian noise (WGN), and 1/f noise, are generated and then analyzed by LSE to showcase its effectiveness. The method in [56] is adopted to generate numerical solutions of Equations (11) to (13); they are chaotic time series, which are cross-validated with the largest Lyapunov exponent [54]. The simulation timespan is 0:0.005:30. (Start at 0, end at\n30, the step is 0.005). To avoid the influences of the initial values, the first 10% of data are discarded and the sampled series (500\u00d7 3, 500 simulated three-dimensional vectors) start from a random position. Figure 2 displays examples of these signals.\n1. Fractional-order Chen system [52] D\u03b11 x = a(y\u2212 x) D\u03b12 y = dx\u2212 xz + cy D\u03b13 z = xy\u2212 bz\n(11)\n\u03b11 = \u03b12 = \u03b13 = 0.9, a = 35, b = 3, c = 28, d = c \u2212 a = \u22127, initial values (x0, y0, z0) = (\u22129,\u22125, 14).\n2. Fractional-order R\u00f6ssler system [53] D\u03b11 x = y\u2212 z D\u03b12 y = x + ay D\u03b13 z = b + z(x\u2212 c)\n(12)\n\u03b11 = 0.9, \u03b12 = 0.85, \u03b13 = 0.95, a = 0.5, b = 0.2, c = 10, (x0, y0, z0) = (0.5, 1.5, 0.1). 3. Fractional-order financial system [54] D\u03b11 x = z + (y\u2212 a)x D\u03b12 y = 1\u2212 by\u2212 x2 D\u03b13 z = \u2212x\u2212 cz (13)\n\u03b11 = 1, \u03b12 = 0.95, \u03b13 = 0.99, a = 1, b = 0.1, c = 1, (x0, y0, z0) = (2,\u22121, 1). 4. Multivariate vector autoregression moving-average process\nyt = c + p\n\u2211 j=1\n\u03a6jyt\u2212j + q\n\u2211 k=1 \u0398ket\u2212k + et (14)\n\u03a61 = 0.2 \u22120.1 00.1 0.2 0.05 0 0.1 0.3 , \u03a62 = 0.3 0 00.1 0.4 0.1 0 0 0.2 , \u03a63 =  0.4 0.1 \u22120.10.2 \u22120.5 0 0.05 0.05 0.2 , \u03981 =\n0.2 0 00 0.2 0 0 0 0.2 , \u03982 = 0.3 0.2 0.10.2 0.4 0 0.1 0 0.5 , c = (0.05, 0,\u22120.05)T , covariance matrix is the unit matrix, e is a standard Gaussian White noise, and the length equals to the above numerical solutions. This procedure is completed by the ARMA2AR and VARMA function of MATLAB2020b.\n5. White Gaussian noise We use the NORMRND function of MATLAB2020b to simulate WGN (500 \u00d7 3). Its components are independent with zero mean and unit standard deviation. 6. 1/f noise On the basis of the algorithm in [57], the procedure of generating 1/f noise consists of three basic steps: (i) simulating white noise whose length is 1500, we obtain y0; (ii) DFT (discrete Fourier transformation) on y0, multiplied by f\u2212 1 2 and symmetrized\nfor a real function, then IDFT (inverse discrete Fourier transformation), adjust the mean and standard deviations, yielding y1; (iii) resize y0 and y1 to 500\u00d7 3 matrix; finally, the 1/f noise series is composed as [y0(:, 1), y1(:, 2), 12 (y0(:, 3) + y1(:, 3))].\nNow, we set the simulation parameters as follows: \u03c4 \u2208 {5, 6, . . . , 15}, r \u2208 {0.05 : 0.041 : 0.5} \u00d7 \u221a 24 for METHOD A, r \u2208 {0.05 : 0.041 : 0.5} \u00d7 \u03a3 for METHOD B, where \u03a3 = \u22113i=1 \u03c3 4 i and \u03c3i is the standard deviation of ith component. More details can be found in Appendix A.2. LSE values are shown in Figure 3.\nFrom Figure 3, we found both METHOD A and METHOD B can distinguish multivariate chaotic signals from stochastic ones. For a fixed (\u03c4, r), the LSE of random time series is higher than that of a chaotic one. As shown in Figure 3a, WGN has the most complex signals, the 1/f noise and VARMA series appear to have similar trends, and the other three chaotic series lie under 0.1. They keep the same orders for most (\u03c4, r). In Figure 3b, LSE values are significantly different and hardly overlap, except for Chen and R\u00f6ssler systems. The reason these two systems are indistinguishable can be because the range of coefficients of r is rather small. Next, we change the lower and upper bounds to 0.01 and 1. Moreover, the above simulation will be repeated 100 times (100 trajectories for each system) to check the robustness of LSE. In each simulation, we add small disturbances to initial values (Disturbinitial = 0.3\u00d7 e) ). Time series generated from Equations (11) to (13) are still chaos\nwith these disturbances; refer to [56]. Note that the intersections of LSE surfaces and \u03c4 = \u03c4i (or r = ri), other than surfaces themselves, are utilized to verify the validity of our methods. Subjecting to the space, only part of the results are demonstrated, see Figures 4 and 6.\nIn Figure 4, the LSE of random series is higher than that of chaotic ones, thus we believe LSE can be treated as an efficient tool to characterize multivariate time series. When \u03c4 is fixed, LSE values of different dynamics show their own features. In Figure 4a\u2013d, LSE values of chaotic systems show similar trends where LSEchaosA oscillates heavily when r = r1 = 0.01 \u00d7 \u221a 24. Then, LSEchaosA decreases as tolerance increases. For LSE random A , they reach their highest values at r2 and then keep reducing as r increases. However, for METHOD B, all LSE values are decreasing, see Figure 4i\u2013l. When r is fixed, except for the R\u00f6ssler and Financial systems, other series can be distinguished by LSE values over different scales. For instance, in Figure 4e, LSEchenA < 0.08 but LSE random A > 0.1, in Figure 4f, LSEWGNA lie at the highest level, and Figure 4g,h,m,n, LSE 1/ f locate higher than LSEVARMA. Compare METHOD A with METHOD B, when r is small, the later performs better at distinguishing multivariate stochastic series from chaotic ones, as well as more stable LSE values for chaos (basically the same). For instance, all LSEchaos are overlapped and smaller than LSErandom when the coefficient is 0.109 in Figure 4m. However, in Figure 4e,f, LSEChenA is close to LSE random A . Moreover, the former shows better discrimination on chaotic\nsystems. This is because of the standardization process of METHOD A, which weights all components at an equal level. It may amplify the LSE if the system\u2019s variation is caused by only one or a small group of components. Based on the simulation findings mentioned above, the following reference range of parameters can be provided:\n\u2022 5 \u2264 \u03c4 \u2264 15 is acceptable. In Figure 4a\u2013d and in Figure 4i\u2013l, when r is taken appropriately, these curves have essentially the same shape, making it possible to distinguish between different signals. This suggests that the distinction is not dependent on the value of \u03c4, and the corresponding time complexity can be taken into consideration when designing this parameter. \u2022 For METHOD A, 0.5 \u2264 r \u2264 2. For METHOD B, 0.1 \u2264 coe f f icient \u2264 0.4. For example, when r = 0.53399, LSEchaos is less than 0.1 but LSErandom is higher than 0.1. Therefore, the stochastic sequence can be distinguished from chaotic ones. See Figure 4e. If r is too small, LSE has a large standard deviation, as is shown in Figure 4a,i. If r is too large, LSEchaos and LSErandom are overlapped, thus, it is difficult to tell apart various signals. See Figure 4g,o.\nHowever, one problem is that LSErossler and LSE f inancial cannot be distinguished, as they are coincident in Figure 4. The reason for this is that the simulated series of Equations (12) and (13) is short and the time step is too small, thus they cannot reflect the feature of the whole system. So, we change the time step to 0.05 and the time span to [0:0.05:300] for the above two systems in order to verify whether LSE functions or not. Examples of the above six kinds of signals are shown in Figure 5.\nAfter repeating 100 times, similar to what we have done in previous tasks, we perceive that LSE works for many tolerance values and some results are drawn in Figure 6. Here, we just show several LSE-\u03c4 figures for fixed tolerances or coefficients, such as Figure 4e,n, because LSE-r charts appear too similar to disparate different series.\nFrom Figure 6, one can easily distinguish six series. For example, in Figure 6d, LSErosslerA lies at the top, in Figure 6b, the LSE values of the other five series do not intersect, and the order is WGN, 1/f noise, VARMA, Chen, and financial, from the top to the bottom. However, the coefficient should be small, such as it is around 0.4 (Figure 6b,f). Otherwise, LSE curves are overlapped (Figure 6d,h). Moreover, to test the dependence on the distance function, we replace Equation (3) with the distance derived from the l\u221e norm, i.e.,\nCompare Figure 7 to Figure 6, one can see that LSE with the same range of parameters can still effectively distinguish between different signals when using the l\u221e norm-derived distance, as Figure 7a,b,f show. Meanwhile, the range of r should be carefully chosen, or the LSE curve may be overlapped, such as Figure 7d,h.\nTo compare with the multivariate permutation entropy (PE) [17,58], Figure 8 shows PE curves for the above six series.\nChaotic signals can be distinguished from stochastic ones via PE since PEchaos < PErandom for all \u03c4 in Figure 8. However, PE cannot discriminate random series, which have correlations in different degrees. Moreover, it fails in the R\u00f6ssler and financial cases. It means that PE is not sensitive to tiny differences in the complexity of systems. However, LSE can distinguish those systems, which indicates LSE is a more accurate measure of complexity."
        },
        {
            "heading": "3.2. Integer-Order Chaos, Fractional-Order Chaos, and Random Series",
            "text": "In this subsection, we test LSE on the integer-order chaotic systems, fractional-order chaotic systems, and stochastic sequences. For integer-order chaos, we use Chen, R\u00f6ssler, and financial systems. The timespans are 0:0:005:30, 0:0.05:300, and 0:0.05:300, respectively. In each simulation, small disturbances are added to the initial values. See Equations (16) to (18).\n1. Integer-order Chen system [52] x\u0307 = a(y\u2212 x) y\u0307 = dx\u2212 xz + cy z\u0307 = xy\u2212 bz\n(16)\na = 35, b = 3, c = 28, d = c\u2212 a = \u22127, initial values (x0, y0, z0) = (\u22129,\u22125, 14) + e. 2. Integer-order R\u00f6ssler system [53] x\u0307 = y\u2212 z y\u0307 = x + ay z\u0307 = b + z(x\u2212 c) (17)\na = 0.4, b = 2, c = 4, (x0, y0, z0) = (0.5, 1.5, 0.1) + e. 3. Integer-order financial system [54] x\u0307 = z + (y\u2212 a)x y\u0307 = 1\u2212 by\u2212 x2 z\u0307 = \u2212x\u2212 cz\n(18)\na = 1, b = 0.1, c = 1, (x0, y0, z0) = (2,\u22121, 1) + e. With the given parameters, the above three systems produce three-dimensional\nchaotic series. For fractional-order chaos, Equations (11) to (13) are used to generate chaotic time series, such as in Section 3.1. Additionally, we add a small disturbance (Disturb\u03b1 = \u00b10.02\u00d7 e) to parameters (\u03b11, \u03b12, and \u03b13), in each simulation. Moreover, we use the same methods as in Section 3.1 to generate random signals. All the simulated series have the same size (500 \u00d7 3). Since we aim to illustrate the effectiveness of LSE, here, we only employ METHOD A to distinguish between different types of signals. Similar to Section 3.1, we also repeat the simulation procedure 100 times; \u03c4 \u2208 {6, 7, . . . , 14} and r \u2208 [0.5, 1.81]. The results are drawn in Figure 9.\nIn Figure 9, chaotic signals can be distinguished from random ones. For instance, LSErandom is greater than 0.1 but LSEchaos is less than 0.1 in Figure 9a. A similar situation can be seen in the images corresponding to other r values. The return map (RM) can be used to characterize the nonlinear process by the transformation of the local maxima (or minima) of the signal [59\u201362]. We tested RM on the length sequences associated with the above nine multivariate time series and the results are drawn in Figure 10. The difference between the R\u00f6ssler system and the other signals is relatively obvious in both the integer-order and fractional-order cases, as shown in Figure 10a,b. However, it is difficult to distinguish between the Chen system and financial system. In addition, both the Chen and Financial systems are mostly located in [0.5, 1]\u00d7 [0.5, 1], overlapping with the position where random signals are located, see Figure 10c. Thus, Figure 10 shows that several signals are muddled and difficult to differentiate apart. This failure could be related to the time series\u2019 length, since RM commonly calls for a sizable amount of data points.\nThree shortcomings noted in Section 1 have been somewhat mitigated by the LSE method.\n1. Multi-scale entropy and complex networks often necessitate a substantial number of data nodes to obtain useful findings, but LSE can process relatively short time series. The length of the test cases in this section is only 500. 2. According to the calculation process in Section 2, it is simple to know that the time complexity of the LSE method is linear (O(\u03c4n)) and appropriate for handling real-time jobs. 3. LSE is more effective at depicting the short-term autocorrelation and the correlation between various components of multidimensional time series because it takes advantage of the similarity of vectors in sliding windows.\nIn Section 3.1, the time steps for R\u00f6ssler and financial systems are 0.005 and 0.05, and the LSE values vary remarkably. Here, we test LSE on the R\u00f6ssler system with different steps. The results are shown in Figure 11. It can be seen that the increase in the step length causes LSE to increase, but the gap between LSErossler and LSErandom is still clear.\nIn order to assess the robustness of the proposed method, the original signal is supplemented with Gaussian white noise at different levels, and the LSE values are recorded accordingly. The original time series is produced by the chaotic R\u00f6ssler system. The signal-to-noise ratio (SNR) is used to measure the level of background noise, which is defined by\nSNR = 10\u00d7 log10( PS PN ) (19)\nwhere PS is the power of the signal and PN is that of noise. See Figure 12.\nNoise tolerance is present in LSE to some extent. The LSErossler is less than 0.1 when the SNR is higher than 10 dB. As a result, the random signals differ significantly. LSE, however, is unable to properly discriminate between chaotic and random signals as SNR continues to drop. The above analysis indicates that the proposed LSE, based on its variations in different scales for certain tolerances (or coefficients), can be regarded as an efficient tool to identify multivariate time series. In the next section, we attempt to apply LSE to real-world data, such as the financial market index and machinery data."
        },
        {
            "heading": "4. Application on Real-World Data",
            "text": "As we introduced in Section 1, multivariate time series conceal the characters in the autocorrelation of each component, as well as the cross-correlation between some channels, which makes it difficult to extract suitable features for further exploration. Two real-world applications, one for the financial market and another for fault diagnosing, will be discussed below."
        },
        {
            "heading": "4.1. Financial Market Index",
            "text": "Financial time series are typical signals with high complexities. How do we illustrate the discrimination between financial markets in different regions? Here, we use LSE to quantify the complexities of three important indices, S&P500, FTSE100, and Shenzhen Securities Component Index (SZI). Their values can be attained from Yahoo.com [63]. The time period is between 25/06/2017 and 24/06/2022. In this experiment, daily OHLC (open, high, low, close) prices and volume are considered. In order to avoid the result being manipulated by the volume only, METHOD A is employed to explore the complexity of the three indices, because volume values have much higher standard deviations than OHLC prices. For more details, see Table 1. The scales are {5, 6, . . . , 15} and the tolerance is between 0.63 and 3.16. The results are drawn in Figure 13.\nFrom Figure 13, we can see that LSEFTSE100 lies at the top, LSESZI at the bottom, and LSES&P500 is between them when r < 1.8. That is, the European stock market shows higher complexity than the other two markets; maturate financial markets, European, and American stock markets display more complexity and stability than the Chinese stock market, which is in accordance with Cao [64]. Note that LSESZI lies between LSEFTSE100 and LSES&P500 for 1.8 < r < 2.4. It contradicts the above result. The reason for this can be attributed to the value of r. We are aware that the range r is determined by multidimensional WGN, but since the financial market index actually has a significant correlation, the tolerance should be lower than usual."
        },
        {
            "heading": "4.2. Machinery Fault Recognition",
            "text": "In this part, we examine the ability of the LSE to recognize vibration signals produced by normal or faulty mechanical systems. The bearing dataset is from the machinery fault database (MAFAULDA), which is kindly provided by the Signals Multimedia and Telecommunications Laboratory (SMT) of the Federal University of Rio de Janeiro (UFRJ) [65]. MAFAULDA collects multivariate time series recorded by sensors on a SpectraQuest\u2019s machinery fault simulator (MFS) alignment\u2013balance\u2013vibration (ABVT) and comprises six different simulated states. We tested LSE for three states: normal function as well as horizontal and vertical misalignment faults. The data acquisition system is composed of several sensors: one Monarch Instrument MT-190 analog tachometer, three Industrial IMI Sensors accelerometers (Model 601A01), one IMI sensors triaxial accelerometer (model 604b31), and a Shure SM81 microphone. Each sequence has 8 columns sampled at 50 KHz for 5 s, namely a 250,000 \u00d7 8 matrix. We randomly intercept 100 fragments (each has 3000 rows)\nfor every state from the database as the test dataset. Figure 14 shows the distribution of each component of the test data (first 100 rows).\nThen, we employed METHOD A to compute the LSE values. The scale set is {5, 6, . . . , 15} and the tolerance is 0.2457. Moreover, the decision tree method is applied to classify LSE values of different states. A decision support tool known as a decision tree employs a tree-like paradigm to represent options and their outcomes. It consists of nodes, branches, and leaves, each of which displays a property, a rule, or an outcome [66]. In this study, three alternative classification algorithms based on the decision tree theory, fine tree (about 100 leaves make fine distinctions between classes), medium tree (less than 20 leaves with medium flexibility), and coarse tree (less than 4 splits), were used to categorize the vibration signals [67]. In addition, an ensemble bagging tree classifier was added, which is processed by creating numerous decision trees during training and outputs the majority of these tree choices for classification tasks [68]. The ten-fold cross-validation was employed in this test and the confusion matrix was plotted in Figure 15a\u2013d. Nevertheless, if we replace LSE by PE, the accuracy is significantly lower; see Figure 15e\u2013h.\nFrom Figure 15, bagged trees based on LSE had the highest accuracy at 98%, while that of PE was 92.3%. Moreover, the accuracies of the LSE-based fine tree, medium tree, and coarse tree (95.3%, 95.3%, and 88.7%) were higher than those of PE (89.3%, 89.3%, 88%). In short, as the LSE values (as features) contribute higher accuracies than PE, the proposed LSE can be an efficient tool for distinguishing multivariate real-world time series."
        },
        {
            "heading": "5. Conclusions",
            "text": "In this paper, we proposed a local structure-based entropy (LSE), which reflects recurrence conditions in certain scales. It can be regarded as an index of complexity for multivariate time series. Depending on whether or not the components are normalized, we suggest two strategies for using LSE: one shows greater discrimination while the other is more stable but easily ignores the effects of slightly varying components. When the tolerance is small, LSE values of fractional chaotic time series are significantly lower than those of stochastic ones. Moreover, the LSE method also has some resilience to noise. When the SNR is higher than 10 dB, accurate classification is obtained for the task of differentiating chaotic signals from random ones, but the accuracy declines when SNR drops. With suitable tolerance, LSE (in certain scales) can be considered a feature of a dynamical system. Regarding real-world data, it was applied to a financial market index, indicating that European and American financial markets are more complex and stable than Chinese markets. Furthermore, we tested LSE on MAFAULDA; it resulted in a higher accuracy than PE-based classification. The results are sensitive to the parameters (especially for r), but the optimal range is provided by the simulation other than the theoretical calculation. Therefore, a more comprehensive examination of the parameters and LSE values based on basic information, such as dimensionality, correlation, and time series length, is required. A distance function that can eliminate the impact of the correlation can also be utilized to increase the applicability of LSE.\nAuthor Contributions: Conceptualization, methodology, software, writing\u2014original draft preparation, Z.Z.; validation, visualization, Z.Z. and J.W. (Jun Wu); resources, J.X. and J.W. (Ji Wang); writing\u2014review and editing, J.X.; supervision, J.X.; project administration, Y.C.; funding acquisition, Y.C. and J.W. (Jun Wu). All authors have read and agreed to the published version of the manuscript.\nFunding: This work is supported by the Doctoral Fund of Hubei University of Automotive Technology (grant no. BK201703) and the Hubei Key Laboratory of Applied Mathematics (grant no. HBAM202105).\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: MAFAULDA, in Section 4.2, is available at http://www02.smt.ufrj.br/ ~offshore/mfs/page_01.html, and we have accessed on 15 July 2022.\nAcknowledgments: We thank Ivo Petras and Gaoxiang Ouyang for the coding fractional-order chaotic system and PE algorithm, as they kindly shared their works on the MATLAB Central File Exchange.\nConflicts of Interest: The authors declare no conflict of interest."
        },
        {
            "heading": "Appendix A",
            "text": ""
        },
        {
            "heading": "Appendix A.1",
            "text": "In NOTE 1, we suggest that the range of tolerance r can be chosen by referring to the standard normal distribution. In fact, we adopt this strategy in METHOD A. For two n-dimensional random variables whose components are N(0,1) iid, Proposition A1 shows the variance of the square of the Euclidean distance is 8n.\nProposition A1. Assume xi \u223c N(0, 1) and yi \u223c N(0, 1) are iid, let SS = \u03a3ni=1(xi \u2212 yi)2, then D(SS) = 8n.\nProof. Let zi = xi\u2212yi\u221a\n2 , then zi \u223c N(0, 1).\nS = \u03a3ni=1( xi\u2212yi\u221a 2 )2 = \u03a3ni=1(zi) 2 \u223c \u03c72(n), then D(S) = 2n. Since S = 12 SS, we have D(SS) = D(2S) = 8n, thus \u03c3(SS) = 2 \u221a 2n.\nFor METHOD A in Section 3, the scale is \u03c4 \u2208 [5 : 1 : 15]; thus, the set of r, denoted by R, is defined as\nR = [0.05 : 0.5\u2212 0.05\n11 : 0.5]\u00d7\n\u221a 8\u00d7 n (A1)\nR can be regarded as a sequence of threshold values multiplied by a constant. Each element of this sequence ([\u00b7 : \u00b7 : \u00b7] part) is called a coefficient. The standardization is required for METHOD A, but it can shuffle the positions of the observed data. To overcome this drawback, METHOD B is introduced. Instead of standardization, different ranges of r are utilized to fit different time series. These ranges are selected according to the variance of the observed time series. In fact, R is defined as\nR = [0.05 : 0.5\u2212 0.05\n11 : 0.5]\u00d7 \u03a3 (A2)\nwhere \u03a3 is introduced in Proposition A2."
        },
        {
            "heading": "Appendix A.2",
            "text": "Proposition A2. Let x = (xi)i\u2264n, where xi \u223c N(\u00b5i, \u03c32i ), be a n-dimensional random variable and assume its components are independent; x and y are iid. Denote SS = \u2211ni=1(xi \u2212 yi)2, then \u03a3 = D(SS) = 8 \u2211ni=1 \u03c3 4 i .\nProof. Assume X \u223c N(\u00b5, \u03c32). It is easy to know that E(X2) = \u03c32 + \u00b52 and E(X4) = \u00b54 + 6\u00b52\u03c32 + 3\u03c34. Then,\nD(X2) = E[(X2)2]\u2212 [E(X2)]2\n= \u00b54 + 6\u00b52\u03c32 + 3\u03c34 \u2212 (\u03c32 + \u00b52)2\n= 4\u00b52\u03c32 + 2\u03c34 (A3)\nNote that (xi \u2212 yi) \u223c N(0, 2\u03c32i ), by Equation (A3) we have D[(xi \u2212 yi)2] = 8\u03c34i . Then,\nD(SS) = D( n\n\u2211 i=1\n(xi \u2212 yi)2)\n= n\n\u2211 i=1\nD[(xi \u2212 yi)2]\n= 8 n\n\u2211 i=1 \u03c34i\n(A4)"
        }
    ],
    "title": "Distinguish between Stochastic and Chaotic Signals by a Local Structure-Based Entropy",
    "year": 2022
}