{
    "abstractText": "Computational humor detection systems rarely model the subjectivity of humor responses, or consider alternative reactions to humor namely offense. We analyzed a large dataset of humor and offense ratings by male and female annotators of different age groups. We find that women link these two concepts more strongly than men, and they tend to give lower humor ratings and higher offense scores. We also find that the correlation between humor and offense increases with age. Although there were no gender or age differences in humor detection, women and older annotators signalled that they did not understand joke texts more often than men. We discuss implications for computational humor detection and downstream tasks.",
    "authors": [
        {
            "affiliations": [],
            "name": "J.A. Meaney"
        },
        {
            "affiliations": [],
            "name": "Steven R. Wilson"
        },
        {
            "affiliations": [],
            "name": "Luis Chiruzzo"
        },
        {
            "affiliations": [],
            "name": "Walid Magdy"
        }
    ],
    "id": "SP:4fe800b79fae745a2bb0744ae6e97d248a5a8861",
    "references": [
        {
            "authors": [
                "V. Basile",
                "C. Bosco",
                "E. Fersini",
                "D. Nozza",
                "V. Patti",
                "F.M.R. Pardo",
                "P. Rosso",
                "M. Sanguinetti"
            ],
            "title": "Semeval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter",
            "venue": "Proceedings of the 13th international workshop on semantic evaluation. pp. 54\u201363",
            "year": 2019
        },
        {
            "authors": [
                "N.D. Bell"
            ],
            "title": "Responses to incomprehensible humor",
            "venue": "Journal of Pragmatics 57, 176\u2013 189",
            "year": 2013
        },
        {
            "authors": [
                "L. Bischetti",
                "P. Canal",
                "V. Bambini"
            ],
            "title": "Funny but aversive: A large-scale survey of the emotional response to covid-19 humor in the italian population during the lockdown",
            "venue": "Lingua 249, 102963",
            "year": 2021
        },
        {
            "authors": [
                "S. Castro",
                "L. Chiruzzo",
                "A. Ros\u00e1"
            ],
            "title": "Overview of the haha task: Humor analysis based on human annotation at ibereval 2018",
            "venue": "IberEval@ SEPLN. pp. 187\u2013194",
            "year": 2018
        },
        {
            "authors": [
                "L. Chiruzzo",
                "S. Castro",
                "M. Etcheverry",
                "D. Garat",
                "J.J. Prada",
                "A. Ros\u00e1"
            ],
            "title": "Overview of haha at iberlef 2019: Humor analysis based on human annotation",
            "venue": "IberLEF@ SEPLN",
            "year": 2019
        },
        {
            "authors": [
                "E. Excell",
                "N.A. Moubayed"
            ],
            "title": "Towards equal gender representation in the annotations of toxic language detection",
            "venue": "Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing pp. 55\u201365",
            "year": 2021
        },
        {
            "authors": [
                "E.C. Ferstl",
                "L. Israel",
                "L. Putzar"
            ],
            "title": "Humor facilitates text comprehension: Evidence from eye movements",
            "venue": "Discourse Processes 54(4), 259\u2013284",
            "year": 2017
        },
        {
            "authors": [
                "M. Friedman"
            ],
            "title": "The use of ranks to avoid the assumption of normality implicit in the analysis of variance",
            "venue": "Journal of the american statistical association 32(200), 675\u2013701",
            "year": 1937
        },
        {
            "authors": [
                "J. Haidt",
                "G. Lukianoff"
            ],
            "title": "The coddling of the American mind: How good intentions and bad ideas are setting up a generation for failure",
            "venue": "Penguin UK",
            "year": 2018
        },
        {
            "authors": [
                "J. Hofmann",
                "T. Platt",
                "C. Lau",
                "J. Torres-Ma\u0155\u0131n"
            ],
            "title": "Gender differences in humorrelated traits, humor appreciation, production, comprehension,(neural) responses, use, and correlates: A systematic review",
            "venue": "Current Psychology pp. 1\u201314",
            "year": 2020
        },
        {
            "authors": [
                "N. Hossain",
                "J. Krumm",
                "M. Gamon",
                "H. Kautz"
            ],
            "title": "Semeval-2020 task 7: Assessing humor in edited news headlines",
            "venue": "arXiv preprint arXiv:2008.00304",
            "year": 2020
        },
        {
            "authors": [
                "H. Knegtmans",
                "W.W. Van Dijk",
                "M. Mooijman",
                "N. Van Lier",
                "S. Rintjema",
                "A. Wassink"
            ],
            "title": "The impact of social power on the evaluation of offensive jokes",
            "venue": "Humor 31(1), 85\u2013104",
            "year": 2018
        },
        {
            "authors": [
                "G. K\u00f6hler",
                "W. Ruch"
            ],
            "title": "Sources of variance in current sense of humor inventories: How much substance, how much method variance",
            "year": 1996
        },
        {
            "authors": [
                "G. Kuipers"
            ],
            "title": "The Humor Divide: Class, Age and Humor Styles",
            "venue": "Good Humor, Bad Taste, pp. 71\u2013101. De Gruyter Mouton",
            "year": 2015
        },
        {
            "authors": [
                "S. Lockyer",
                "M. Pickering"
            ],
            "title": "Beyond a Joke: The Limits of Humour",
            "venue": "Springer",
            "year": 2005
        },
        {
            "authors": [
                "J. Meaney"
            ],
            "title": "Crossing the Line: Where do Demographic Variables Fit into Humor Detection? In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
            "venue": "pp. 176\u2013181",
            "year": 2020
        },
        {
            "authors": [
                "J. Meaney",
                "S. Wilson",
                "L. Chiruzzo",
                "A. Lopez",
                "W. Magdy"
            ],
            "title": "Semeval 2021 task 7: Hahackathon, detecting and rating humor and offense",
            "venue": "Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021). pp. 105\u2013119",
            "year": 2021
        },
        {
            "authors": [
                "P. Potash",
                "A. Romanov",
                "A. Rumshisky"
            ],
            "title": "Semeval-2017 task 6:# hashtagwars: Learning a sense of humor",
            "venue": "Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017). pp. 49\u201357",
            "year": 2017
        },
        {
            "authors": [
                "V. Prabhakaran",
                "A.M. Davani",
                "M. Diaz"
            ],
            "title": "On releasing annotator-level labels and information in datasets",
            "venue": "Proceedings of the Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR) Workshop pp. 133\u2013138",
            "year": 2021
        },
        {
            "authors": [
                "R.T. Proyer",
                "W. Ruch"
            ],
            "title": "Enjoying and fearing laughter: Personality characteristics of gelotophobes, gelotophiles, and katagelasticists",
            "venue": "Psychological Test and Assessment Modeling 52(2), 148\u2013160",
            "year": 2010
        },
        {
            "authors": [
                "W. Ruch"
            ],
            "title": "The Sense of Humor: Explorations of a Personality Characteristic, vol",
            "venue": "3. Walter de Gruyter",
            "year": 2010
        },
        {
            "authors": [
                "L. Silva",
                "M. Mondal",
                "D. Correa",
                "F. Benevenuto",
                "I. Weber"
            ],
            "title": "Analyzing the Targets of Hate in Online Social Media",
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media. vol. 10",
            "year": 2016
        },
        {
            "authors": [
                "C. Spearman"
            ],
            "title": "American journal of psychology 15",
            "venue": "The Proof and Measurement of Association Between two Things (1), 72\u2013101",
            "year": 1904
        },
        {
            "authors": [
                "S. Svebak",
                "R.A. Martin",
                "J. Holmen"
            ],
            "title": "The prevalence of sense of humor in a large, unselected county population in norway: Relations with age, sex, and some health indicators",
            "year": 2004
        },
        {
            "authors": [
                "R. Vallat"
            ],
            "title": "Pingouin: statistics in python",
            "venue": "Journal of Open Source Software 3(31), 1026",
            "year": 2018
        },
        {
            "authors": [
                "F. Wilcoxon"
            ],
            "title": "Individual comparisons by ranking methods",
            "venue": "biometrics bulletin 1, 6 (1945), 80\u201383. URL http://www. jstor. org/stable/3001968",
            "year": 1945
        },
        {
            "authors": [
                "M. Zampieri",
                "P. Nakov",
                "S. Rosenthal",
                "P. Atanasova",
                "G. Karadzhov",
                "H. Mubarak",
                "L. Derczynski",
                "Z. Pitenis",
                "\u00c7. \u00c7\u00f6ltekin"
            ],
            "title": "Semeval-2020 task 12: Multilingual offensive language identification in social media (offenseval 2020)",
            "venue": "arXiv preprint arXiv:2006.07235",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Keywords: Computational Humor \u00b7 Offense Detection \u00b7 Online Texts \u00b7 Demographics."
        },
        {
            "heading": "1 Introduction",
            "text": "Computational Humor Detection is a fast-growing area of research and has produced at least one humor detection challenge per year since 2017 with Hashtag Wars in SemEval 2017, [18], the Spanish-language HAHA task in Iberlef 2018 [4] and 2019 [5], Assessing Humor in Edited Headlines in 2020 [11] and HaHackathon in 2021 [17]. With participation in these challenges increasing year on year, organisers are beginning to refine their conception of humor, and to incorporate some of the vast, inter-disciplinary findings of the broader humor research community.\nOne vital branch of this research is that humor is known to vary along the lines of demographic characteristics. Factors such as age [14], gender [10], personality [21] and other demographic variables all modulate responses to humor. Humor tasks have struggled to incorporate such demographic awareness into their tasks, and instead tend to average over all humor ratings - which removes nuance and subjectivity from the data [16], as well as possibly decreasing the generalizability of humor detection systems.\nar X\niv :2\n20 8.\n10 89\n8v 1\n[ cs\n.C L\n] 2\n3 A\nA second salient finding from the broader humor literature is that humor is closely linked to offense [15] and indeed, can be used as a mechanism to mask hateful or offensive content. Several competitions have modelled hate speech [1] [27], which is related to offense, but HaHackathon was the first humor detection competition to co-model humor and offense. As the concept of offense is less tangible than humor, it was split in two:\n1. General offense meaning that a text targets a group of people simply because they belonged to that group and/or is likely upsetting to a lot of people.\n2. Personal offense, targeting a group that the reader belongs to or cares about.\nAlthough the annotators of this dataset provided demographic data about their age and gender, this was not released as part of the humor detection task, and this is the first analysis of the impact of these age and gender on the humor and offense ratings in this large dataset. The analysis aims to uncover if humor and offense are as meaningfully linked in big datasets as they are in small-N studies, while validating evidence that there are gendered differences in the distribution of humor ratings [24], as well as tolerance of aggressive humor.\nAs in [10], we are mindful of the use of gender to specify a cultural phenomenon, indicating men and women as socially-defined groups, rather than a biological distinction."
        },
        {
            "heading": "1.1 Related Work",
            "text": "Gender and age differences have been the subject of many studies in the fields of psychology, sociology, education, and management studies. Svebak et al. [24] found that \u201coverall humor scores\u201d were higher for men than they were for women. However, it should be noted that \u201coverall humor\u201d was narrowly assessed, using only three items, with each representing one of the dimensions of the Situational Humor Questionnaire. The same work reported that humor appreciation declines with age: the mean scores for total sense of humor on average declined across the age cohorts from highest score in the 20s to lowest score among those aged 70. More recently, an Italian study of covid-related humor [3] reported that increasing age, as well as being female was related to finding pandemic humor more aversive and less funny.\nIn terms of gender differences, perhaps the most replicated result is that men tolerate aggressive humor more than female respondents do [10]. Proyer and Ruch [20] report that men tended to score higher on kagelaticism - the joy of laughing at others, which suggests that as long as a joke does not target men explicitly, it may be offensive towards other groups, without impacting men\u2019s humor ratings. Interestingly, Knegtmans et al. [12] found that participants whose social power had been manipulated to place them in a high-power state rated jokes which targeted others as less offensive, and gave higher humor ratings. No differences in the appreciation of nonsense humor [13], or neutral jokes [7] were found."
        },
        {
            "heading": "1.2 Research Questions (RQ)",
            "text": "1. Is there a correlation between annotators\u2019 perceptions of humor and offense? Does this vary by age and gender? 2. Are there differences in humor detection and comprehension between groups? 3. Are there differences in the distributions of humor and offense ratings be-\ntween groups?\nUsing a dataset of >120k ratings of humor and offense [17], we find a slight negative correlation between humor and offense, which varies as a function of gender and age. The negative link between humor and offense increases as annotators age. We also find a stronger correlation between general offense and humor for women, but male annotators only linked these concepts when they signalled that they were personally offended. There were no significant differences between groups when it came to correctly identifying texts as jokes (i.e. humor detection), but there were differences when it came to humor comprehension. More women than men indicated that they did not get a joke, and women of all age groups had higher rates of using the label \u201cI don\u2019t get it\u201d than men of all age groups. In terms of the distribution of ratings, women were more likely to use lower humor ratings and higher offense ratings, while men showed the opposite trend. In terms of age groups, the oldest group tended to report that they didn\u2019t get a joke more than any other group, while annotators ages 26-40 were least likely to use this label, and also gave the highest humor ratings overall. Older groups were more likely to use higher ratings of general and personal offense, while younger annotators were less likely to use these."
        },
        {
            "heading": "2 Dataset Description",
            "text": "The dataset features the texts and ratings used in the humor and offense shared task HaHackathon at SemEval 2021 [17]. Including non-humorous texts, this comprises 202,369 ratings of 10,000 texts. Each text has an average of 20.2 ratings, with no text having fewer than 17 votes. There were 1,821 unique annotators (mean age 40.45 years, SD=15.64 years), and each annotator rated an average of 111.13 texts. The highest number of texts rated by one person was 307.\nOf the 10,000 texts in the dataset, 2,000 were sourced from the Kaggle Short Jokes Dataset4. Half of the Kaggle texts were selected because they referred to one of the common targets of online hate speech outlined by Silva et al. [22], e.g. women, members of the LGBT community, religious/racial minorities, and this target was the butt of the joke. These texts were deemed likely to elicit ratings of offense from some annotators. The other half of the Kaggle texts referred to a common hate speech target, but did not make it the butt of the joke.\nThe other 8,000 texts were sourced from Twitter, from a mix of humorous and non-humorous accounts. Amongst the non-humorous accounts, there were\n4 https://github.com/amoudgl/short-jokes-dataset\nseveral which advocate for, or provide information to common targets of hate speech. This ensured that mentions of these targets were not limited to humorous texts only.\nAnnotators were asked up to three sets of questions about each text: one related to humor and two related to offense.\n1. Humor detection/rating: annotators were asked if the intention of the text was to be humorous. This binary response question was aimed at gauging the genre of the text, and annotators were asked not to judge based on whether they found it funny, but whether it contained indicators of the humor genre, e.g. a setup and punchline, puns, absurd content, etc. If the annotator selected \u2018yes\u2019, they were asked to rate how funny they found it from 1-5. There was also the option to select \u2018I don\u2019t get it\u2019 if the text was identified as humorous, but the humor was not understood. If the annotator selected \u2018no\u2019, they were not asked any further questions about this text. 2. General offense detection/rating: If a text had been labelled as humorous, annotators were asked if they thought the text targeted a group simply because they belonged to a group, or if they thought the text would be offensive to a large number of people. In the case of a \u2018yes\u2019 response, they were asked how generally offensive they thought the text was from 1-5. 3. Personal offense: If a text had been labelled as humorous, we asked annotators if they were personally hurt by the text, or were hurt on someone else\u2019s behalf, and if so, to rate how much from 1-5.\nThe pool of annotators comprised 4 age groups: 18-25, 26-40, 41-55, 56- 70. In order to avoid a lack of shared cultural knowledge, all annotators were native English speakers and citizens of the United States. Although we aimed to be inclusive of diverse genders, the dataset included only four annotators who preferred not to disclose their gender. As they rated a total of 384 texts, they were excluded from the gender analysis, for reasons of statistical power.\nAnnotators provided informed consent before beginning the annotation, and the procedure was approved by the Ethics Committee of the corresponding author\u2019s institution. Other demographic data about the annotators, such as gender and personality traits, was also provided as part of the dataset."
        },
        {
            "heading": "3 Methodology",
            "text": "Given that the humor and offense annotations were reported using an ordinal scale, for RQ1, we used the Spearman rank correlation [23] to report the correlations between these variables. The Spearman rank correlation is a generalisation of the Pearson correlation which is used for discrete and ordinal data which captures the strength and direction of the relationship between two variables by ranking the values of each variable, summing the square differences and calculating the covariance of the ranks. This returns a correlation coefficient, \u03c1, ranging from -1 to +1, the magnitude of which indicates the strength of the relationship\nand the sign signifies the direction. It also returns a p-value - the probability that the value of the coefficient could occur under the null hypothesis.\nTo answer RQ2, we calculated the proportion of annotators from each group (i.e., gender or age group) that mislabeled (failed to detect) or misunderstood (failed to comprehend) each text. The resulting distributions were non-normal, so we chose non-parametric tests, which do not assume an underlying distribution. As we have only two values for gender in the dataset, we used a Wilcoxon Signed Rank test [26] to examine the null hypothesis that the samples from male and female annotators came from the same distribution. This is similar to a paired t-test, and it ranks the absolute value of the pairs of differences to calculate the test statistic, w. With this test, we report the Common Language Effect Size (CLES): the proportion of pairs where the values for one group are higher than the other.\nFor more than two groups, i.e., our age variable, which had four bins, we use the Friedman test [8], which is similar to a repeated measures ANOVA. Again values are ranked and the test compares the mean rank of each group for statistical significance. In the case of a significant result, we ran post hoc pairwise Wilcoxon tests. We used the Bonferroni correction to adjust the pvalues for multiple comparisons, reducing the risk of false positive results.\nFor RQ3, we first used the Wilcoxon and Friedman tests to determine if one group tended to give higher or lower ratings than another. We then used a chi-square test of homogeneity to examine how the distributions differed from each other. This test determines if the frequencies of each possible value of the dependent variable are distributed in the same way across the different groups. The test calculates the expected frequencies of each rating by each group by multiplying the number of annotators in each group by the true probability that any annotator would pick each answer. This expected frequency is then compared to the observed frequency."
        },
        {
            "heading": "4 Results",
            "text": ""
        },
        {
            "heading": "4.1 RQ1: Is There a Correlation between Humor and Offense?",
            "text": "For the following analysis, we excluded texts which had been labelled as \u2018not humorous\u2019 by our annotators, and removed outliers (e.g. texts that had fewer than 3 humor ratings). This left 121,622 ratings of 6,918 texts.\nOverall, there was a small negative correlation between humor and general offense (\u03c1 = \u22120.13, p <0.05), and this grew stronger for humor and personal offense (\u03c1 =-0.19, p <0.05), which suggests that offensive content is negatively related to humor appreciation. There was a strong correlation between general and personal offense (\u03c1=0.60, p <0.05), indicating that these concepts are linked, but are not identical.\nCorrelations between ratings by Gender When examining the correlations between ratings split by gender, an interesting trend emerged (Figure 1).\nThere was almost no relationship between humor and general offense for men, however personal offense ratings were negatively correlated with humor ratings. Conversely, for female annotators, both types of offense were more strongly correlated with a reduced humor rating for female annotators.\nCorrelations by Age A second interesting trend emerged in terms of age: the older the annotators were, the stronger the negative link between general and personal offense on humor ratings was (Figure 1). The oldest group had the most prominent negative correlation between humor and both types of offense, as well as the strongest correlation between the two offense metrics.\nCorrelations by Age and Gender Although splitting 20 ratings per text into 8 groups (for four age groups by two gender groups) would cause issues of data sparsity and statistical power, we noted that the trend of an increasingly negative correlation between humor and offense continues when this is broken down by age and gender (Figure 2). Female annotators relate lower humor scores to higher offense scores increasingly with age, and this trend is much less pronounced in male annotators."
        },
        {
            "heading": "4.2 RQ2: Are There Differences in Humor Detection and Comprehension Between Groups?",
            "text": "Humor Detection To investigate differences in annotators\u2019 humor detection, we looked at the proportion of male and female annotators who labelled each text from the Kaggle data as \u2018not humorous\u2019. We confined this analysis to the Kaggle data because all texts in this dataset was intended to be humorous, and should have been labeled as such. A paired Wilcoxon signed rank test showed that there was no significant difference between groups (z = 134201.0, p=0.29).\nWe used a similar procedure to test if there were significant differences between age groups in terms of humor detection. A Friedman test showed that there were no significant differences between groups (\u03c72 = 6.976, p=0.07).\nHumor Comprehension After labeling a text as humorous, one of the options for humor rating was \u2018I don\u2019t get it\u2019. This indicated that the annotator had recognized that the text was intended to be humorous, but that they lacked the knowledge to fully understand the joke. We first looked at the Kaggle dataset, and calculated the number of \u2018I don\u2019t get it\u2019 votes from men and women, as a proportion of the total votes per text from each group. A paired Wilcoxon signed rank test showed that there was a significant difference between groups (z = 214403.0, p <0.05). We used Pingouin [25] to calculate the Common Language Effect Size (CLES), i.e. the proportion of pairs where the proportion of \u2018I don\u2019t get it\u2019 ratings provided by female annotators is greater than the proportion of male annotators who gave that rating. The resulting CLES of 0.5540 indicates that a larger proportion of female annotators indicated that they did not get the joke in 55.45% of pairs. When looking at the data from Twitter, women still admit to not getting the joke more than men (z = 2298680.0, p <0.05), but the effect is less pronounced, CLES = 0.5223.\nWe examined differences between age groups in terms of humor detection. A Friedman test showed that there were no significant differences between groups (\u03c72= 0.0012, p=0.06)."
        },
        {
            "heading": "4.3 RQ3: Are There Differences between Groups in Distributions Humor and Offense Ratings?",
            "text": "When looking at the distribution of ratings across the 6 possible values (1-5 and \u2018I don\u2019t get it\u2019 ) for the entire dataset (both Kaggle and Twitter), a \u03c72 test of homogeneity demonstrated that there were significant differences between the distributions of humor ratings between men and women (\u03c72= 202.25, p < 0.05) and showed that women were more likely to select \u2018I don\u2019t get it\u2019, while men were more likely to use higher ratings. We also explored if this difference translated into different average humor ratings per text and a Wilcoxon signed rank showed that men gave significantly higher ratings than women on humor (z = 9684516.5, p < 0.05) and the CLES score of 0.5333 indicated that men gave higher humor ratings in 53.33% of pairs.\nFor general offense, a \u03c72 test of homogeneity showed significant differences between groups (\u03c72 = 430.85, p < 0.05), and examining the expected versus observed counts showed that the trend seen in the humor ratings was reversed: men were more likely to choose low offense ratings and women were more likely to select higher values. In terms of averaged general offense ratings, group differences were significant (z = 4260050.5, p < 0.05, CLES = 0.4704), with men giving higher offense ratings in 47.04% of pairs.\nSimilarly, for personal offense, a \u03c72 test of was significant (\u03c72 = 1195.94, p < 0.05) with a more pronounced trend showing that women were more likely to select a high personal offense rating, and men systematically under-selected high ratings. This led to significant differences in the average personal offense ratings per text, where men gave higher personal offense scores in only 41.5% of pairs (z = 1234096.5, p <0.05, CLES = 0.4146).\nWhen looking at age groups, a \u03c72 test showed significant differences in humor ratings between age groups (\u03c72 = 239.98, p < 0.05). The oldest group, 56-70, were most likely to report \u2018I don\u2019t get it\u2019, while annotators aged 26-40 were least likely to use this, and most likely to give high ratings. In terms of general offense, there were significant group differences (\u03c72 = 540.936 p < 0.05), and annotators 18-40 were more likely to give lower general offense ratings, while those aged 41-70 used fewer low ratings than expected, and the group ages 56-70 was most likely to give the highest possible offense rating of 5. Group differences were more pronounced in personal offense ratings (\u03c72 = 1387.43, p < 0.05) where the two youngest groups gave consistently lower than expected ratings of personal offense, while the older group gave consistently higher ratings. This resulted in significant differences in the average personal offense scores between groups (\u03c72 = 38.223, p <0.05)."
        },
        {
            "heading": "5 Qualitative Analysis",
            "text": "The negative correlation for female annotators between humor and general offense, which was uncovered in the above analysis, is succinctly illustrated in Figure 3. Texts which are offensive for women tend to earn a lower humor rating, while general offense is more tolerated by men.\nTo examine what type of texts male and female annotators differed on with regard to general offense ratings, we selected the top 40 texts where there was at least a 1.5 point difference between the mean general offense score given by male and female annotators. We labeled the topic or target of the texts and five annotators rated whether the content was aggressive or not. Annotators were instructed that a text should be deemed aggressive if it contained violent content or used racial slurs, and inter-annotator agreement was relatively high (Fleiss\u2019s \u03ba = 0.3815).\nThere was a sizeable overlap of topics, with women finding texts about the LGBT community more offensive than men, while male annotators found texts about religion more generally offensive. The texts that were offensive to women tended to be aggressive, while men were more tolerant of this. Interestingly, men\nselected several texts which were not intended to be jokes (e.g. were drawn from accounts supporting targets of hate speech) as both humorous and offensive.\nWe followed a similar procedure to examine the texts where offense ratings from different age groups differed from each other. We compared the mean general offense rating from each group to the average general offense rating from the other 3 groups combined, and looked at the top 40 texts where there was at least a 1.5 point difference. Several topics predominate, namely race, women, body (e.g. disability, body weight). The texts rated as more generally offensive by younger groups focused on these topics, but as age increased, so did the variety of topics featured. The texts selected by group 1 (the youngest group) featured more which were aggressive in nature, but as age increased, aggression was less linked to offense."
        },
        {
            "heading": "6 Discussion",
            "text": "We used a large dataset of texts rated for humor and offense, along with some demographic information about the annotators to explore differences between age and gender groups. We looked at how the groups link humor and offense, differences in humor detection and comprehension, as well as differences in the distributions of ratings.\nRQ1: We found that female annotators negatively link humor and offense more strongly than men. Male annotators do not link general offense with diminished humor ratings. In fact, they link humor and offense to a lesser extent, and only when personally offended.\nAs regards age groups, the correlation between humor and offense was weakest in the youngest group, and grew steadily with age - as did the link between general and personal offense.\nRQ2: There were no differences in gender or age groups in terms of humor detection. However, when it came to humor comprehension, women selected \u2018I don\u2019t get it\u2019 more often than men.\nRQ3: In terms of the distributions of ratings, women gave lower humor ratings and higher offense ratings, while men showed the opposite trend. Amongst the age groups, annotators 26-40 gave the highest ratings and the fewest reports of \u2018I don\u2019t get it\u2019. In line with findings from RQ1, younger groups gave lower offense ratings and older groups reported higher offense.\nSome of the findings above are well attested in the humor literature, albeit in smaller-N studies. Hofmann et al. [10] report that men\u2019s tolerance of aggressive humor is one of the most consistent findings in the humor field, with seven out of eight studies mentioned replicating this result. Our qualitative work shows that in the texts on which men and women differed most on general offense, aggression featured more prominently for women. Perhaps relatedly, Proyer and Ruch [20] report that men score higher on katagelasticism - the joy of laughing at others. This may be reflected in the fact that general offense does not diminish male annotators\u2019 humor ratings, only personal offense does.\nA more surprising result is the increasingly strong negative correlation between humor and offense as age progressed. This contradicts the oft-touted idea of Generation Snowflake, which contends that those born after 1995 tend to be the most overly reactive to offensive material [9]. The older age groups - 40- 55 and 56-70 - gave higher ratings of offense than their younger counterparts, and our qualitative analysis indicated that the older groups gave higher offense ratings to a wider variety of topics.\nThe finding that women used the \u2018I don\u2019t get it\u2019 label more than men is a result that may benefit from some contextualisation from the humor literature. Bell [2] found that when shown incomprehensible jokes, women tended to explicitly state that they did not get it, while men implicitly signaled it by ask-\ning concept-checking questions. It is not possible to know whether this was the case here, but it is true that the qualitative results uncovered that men were mentioning not humorous texts as both humorous and offensive."
        },
        {
            "heading": "6.1 Implications",
            "text": "Given the gender and age group differences in ratings of humor and offense, it is evident that humor detection systems which average over all annotators\u2019 ratings fail to model the subjectivity that is inherent to this task. These systems may not generalise well on downstream tasks, such as content moderation, and may not be effective at moderating aggressive content if they are tuned to men\u2019s preferences, or alternatively may be more restrictive if tuned to women\u2019s preferences. Furthermore, as sociologists have pointed out [15], the line between humor and offense is continually under revision in most societies, therefore not only are these responses subjective, but they are a moving target. We should focus on incorporating frameworks to include demographic knowledge in our systems, which can constantly be updated to reflect society\u2019s changing definitions of humor and offense."
        },
        {
            "heading": "6.2 Limitations",
            "text": "It is a limitation that the dataset did not afford the opportunity to explore the interaction between age and gender. As each text has approximately 20 annotations per text, splitting these into 8 groups to model age and gender would not have provided sufficient statistical power. Similarly, it is a limitation that there were insufficient annotations from gender non-conforming annotators, as there is a dearth of literature on their reactions to humor and offense. The lack of annotators that self-identify with genders other than female and male has been noticed in the past in different tasks as well [6,19].\nA final constraint is that we are modelling only one half of the humorous interaction - the recipient of the joke. Excluding the teller of the joke can deny the recipient some important context needed to enjoy the joke, and different tellers can mitigate the responses. Future work should include this dimension."
        },
        {
            "heading": "7 Conclusion",
            "text": "We present the first analysis of the demographic data provided with the HaHackathon data - a large dataset used to train systems for computational humor detection. Our findings indicate that women negatively link humor to offense, while men only do so if they are personally offended. Links between humor and offense grew with age. There were no differences in humor detection by gender or age groups, but women and older annotators indicated that they did not understand jokes more than men. Distributions of humor and offense ratings replicated findings from humor research, namely that men gave higher humor ratings and lower offense ratings. We hope that these findings will inform future frameworks for computational humor detection and dataset creation."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was supported in part by the EPSRC Centre for Doctoral Training in Data Science, funded by the UK Engineering and Physical Sciences Research Council (grant EP/L016427/1) and the University of Edinburgh."
        }
    ],
    "title": "Don\u2019t Take it Personally: Analyzing Gender and Age Differences in Ratings of Online Humor",
    "year": 2022
}