"The following are our recommendations to bring clarity to the ETSC area:
• An effort should be made to provide a concrete, testable, falsifiable, and useful definition of early classification of time series. While the current authors have no interest in providing this definition (in any case, a consortium of researchers would be better), we believe that any such definition would, at a minimum, have to consider:
1) The cost of a false positive for the actionable class(es) vs. the cost of a false negative [12], [19]. Even if the only early action taken is to sound an alarm, false alarm fatigue is known to have a high cost [21].
2) The probability that the domain of interest contains prefixes, inclusions, and homophones that resemble the actionable class(es).
3) The prior probability of seeing a member of the actionable class(es).
4) The appropriateness of the normalization assumptions for the domain.
• Anyone proposing an ETSC model needs to carefully explain what the model offers beyond simply classification with trivial awareness that not all datapoints matter (recall Fig. 9).
• It is hard to see how any genuine progress could be made without access to a real-world publicly available dataset(s) that could benefit from the
more concrete definition. The overreliance on the UCR datasets seems to have led the community astray here. Proxy datasets and synthetic datasets do have their place in research, especially in fledging areas. However, we are now two decades and many dozens of papers into this area. It is hard to overemphasize the last point. If no realworld publicly available dataset(s) where some form of ETSC is useful can be obtained, this seems tantamount to saying that there is no problem to solve, and the community should stop publishing on this topic."