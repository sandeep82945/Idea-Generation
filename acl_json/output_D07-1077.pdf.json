{
    "abstractText": "Syntactic reordering approaches are an effective method for handling word-order differences between source and target languages in statistical machine translation (SMT) systems. This paper introduces a reordering approach for translation from Chinese to English. We describe a set of syntactic reordering rules that exploit systematic differences between Chinese and English word order. The resulting system is used as a preprocessor for both training and test sentences, transforming Chinese sentences to be much closer to English in terms of their word order. We evaluated the reordering approach within the MOSES phrase-based SMT system (Koehn et al., 2007). The reordering approach improved the BLEU score for the MOSES system from 28.52 to 30.86 on the NIST 2006 evaluation data. We also conducted a series of experiments to analyze the accuracy and impact of different types of reordering rules.",
    "authors": [
        {
            "affiliations": [],
            "name": "Chao Wang"
        }
    ],
    "id": "SP:a12d51dad286a247e746b34e77dca77a41bc719d",
    "references": [
        {
            "authors": [
                "Adam L. Berger",
                "Stephen A. Della Pietra",
                "Vincent J. Della Pietra"
            ],
            "title": "A maximum entropy approach to natural language processing",
            "year": 1996
        },
        {
            "authors": [
                "Peter F. Brown",
                "Stephen A. Della Pietra",
                "Vincent J. Della Pietra",
                "John D. Lafferty",
                "Robert L. Mercer."
            ],
            "title": "Analysis, statistical transfer, and synthesis in machine translation",
            "venue": "InProceedings of Conference on Theoretical and Methodological Issues in Machine Transla-",
            "year": 1992
        },
        {
            "authors": [
                "David Chiang."
            ],
            "title": "A hierarchical phrase-based model for statistical machine translation",
            "venue": "In",
            "year": 2005
        },
        {
            "authors": [
                "Michael Collins",
                "Philipp Koehn",
                "Ivona Ku\u010derov\u00e1"
            ],
            "title": "Clause restructuring for statistical machine translation",
            "venue": "Proceedings of ACL,",
            "year": 2005
        },
        {
            "authors": [
                "Michael Collins"
            ],
            "title": "Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms",
            "year": 2002
        },
        {
            "authors": [
                "Proceedings of EMNLP. Yuan Ding",
                "Martha Palmer."
            ],
            "title": "Machine translation using probablistic synchronous dependency insertion grammars",
            "venue": "InProceedings of ACL",
            "year": 2005
        },
        {
            "authors": [
                "Liang Huang",
                "Kevin Knight",
                "Aravind Joshi."
            ],
            "title": "Statistical syntax-directed translation with extended domain of locality",
            "venue": "InProceedings of AMTA",
            "year": 2006
        },
        {
            "authors": [
                "Philipp Koehn",
                "Amittai Axelrod",
                "Alexandra Birch Mayne",
                "Chris Callison-Burch."
            ],
            "title": "Edinburgh system description",
            "venue": "InIWSLT Speech Translation Evaluation.",
            "year": 2005
        },
        {
            "authors": [
                "Shankar Kumar",
                "William Byrne."
            ],
            "title": "Local phrase reordering models for statistical machine translation",
            "venue": "Proceedings of HLT-EMNLP",
            "year": 2005
        },
        {
            "authors": [
                "Dekang Lin"
            ],
            "title": "A path-based transfer model for",
            "year": 2004
        },
        {
            "authors": [
                "Daniel Marcu",
                "Wei Wang",
                "Abdessamad Echihabi",
                "Kevin Knight."
            ],
            "title": "SPMT: Statistical machine translation with syntactified target language phrases",
            "venue": "Proceedings of EMNLP",
            "year": 2006
        },
        {
            "authors": [
                "Sonja Niessen",
                "Hermann Ney."
            ],
            "title": "Statistical machine translation with scarce resources using morphosyntactic information",
            "venue": "Computational Linguistics",
            "year": 2004
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu"
            ],
            "title": "BLEU: a method for automatic evaluation of machine translation",
            "year": 2002
        },
        {
            "authors": [
                "Chris Quirk",
                "Arul Menezes",
                "Colin Cherry."
            ],
            "title": "Dependency treelet translation: Syntactically informed phrasal SMT",
            "venue": "InProceedings of ACL",
            "year": 2005
        },
        {
            "authors": [
                "Honglin Sun",
                "Daniel Jurafsky."
            ],
            "title": "Shallow semantic parsing of Chinese",
            "venue": "In",
            "year": 2004
        },
        {
            "authors": [
                "Proceedings of NAACLHLT. Christoph Tillmann."
            ],
            "title": "A block orientation model for statistical machine translation",
            "venue": "In",
            "year": 2004
        },
        {
            "authors": [
                "Fei Xia",
                "Michael McCord."
            ],
            "title": "Improving a statistical MT system with automatically learned rewrite patterns",
            "venue": "InProceedings of COLING",
            "year": 2004
        },
        {
            "authors": [
                "Nianwen Xue",
                "Fei Xia",
                "Fu-Dong Chiou",
                "Martha Palmer"
            ],
            "title": "The Penn Chinese Treebank: Phrase structure annotation of a large corpus",
            "year": 2005
        },
        {
            "authors": [
                "Kenji Yamada",
                "Kevin Knight"
            ],
            "title": "A syntax-based statistical translation model",
            "year": 2001
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 737\u2013745, Prague, June 2007. c\u00a92007 Association for Computational Linguistics\nSyntactic reordering approaches are an effective method for handling word-order differences between source and target languages in statistical machine translation (SMT) systems. This paper introduces a reordering approach for translation from Chinese to English. We describe a set of syntactic reordering rules that exploit systematic differences between Chinese and English word order. The resulting system is used as a preprocessor for both training and test sentences, transforming Chinese sentences to be much closer to English in terms of their word order. We evaluated the reordering approach within the MOSES phrase-based SMT system (Koehn et al., 2007). The reordering approach improved the BLEU score for the MOSES system from 28.52 to 30.86 on the NIST 2006 evaluation data. We also conducted a series of experiments to analyze the accuracy and impact of different types of reordering rules."
        },
        {
            "heading": "1 Introduction",
            "text": "Syntactic reordering approaches are an effective method for handling systematic differences in word order between source and target languages within the context of statistical machine translation (SMT) systems (Xia and McCord, 2004; Collins et al., 2005). In reordering approaches, sentences in the source language are first parsed, for example using a Treebank-trained parser. A series of transformations\nis then applied to the resulting parse tree, with the goal of transforming the source language sentence into a word order that is closer to that of the target language. The reordering process is used to preprocess both the training and test data used within an existing SMT system. Reordering approaches have given significant improvements in performance for translation from French to English (Xia and McCord, 2004) and from German to English (Collins et al., 2005).\nThis paper describes a syntactic reordering approach for translation from Chinese to English. Figure 1 gives an example illustrating some of the differences in word order between the two languages. The example shows a Chinese sentence whose literal translation in English is:\nthis is French delegation at Winter Olympics on achieve DEC best accomplishment\nand where a natural translation would be\nthis is the best accomplishment that the French delegation achieved at the Winter Olympics\nAs exemplified by this sentence, Chinese differs from English in several important respects: for example, relative clauses appearbeforethe noun being modified; prepositional phrases often appearbefore the head they modify; and so on. It can be seen that some significant reordering of the input is required to produce a good English translation. For this example, application of reordering rules leads to a new Chinese string whose word-by-word English paraphrase is:\n737\nthis is best accomplishment DEC French delegation achieve at on Winter Olympics\nThis reordering is relatively easy to express using syntactic transformations\u2014for example, it is simple to move the entire relative clause \u201cFrench delegation at Winter Olympics on achieve DEC\u201d to a position that is after the noun phrase it modifies, namely \u201cbest accomplishment.\u201d Phrase-based systems are quite limited in their ability to perform transformations of this type. More recently developed hierarchical systems (e.g., (Yamada and Knight, 2001; Chiang, 2005; Marcu et al., 2006)) may be better equipped to deal with reordering of this type; however, in this example they would effectively have to first identify the span of the relative clause, and then move it into the correct position, without any explicit representation of the source language syntax.\nIn this paper, we describe a set of syntactic reordering rules that exploit systematic differences between Chinese and English word order. The resulting system is used as a preprocessor for both training and test sentences, transforming Chinese sentences to be much closer to English. We report results for the method on the NIST 2006 evaluation data, using the MOSES phrase-based SMT system (Koehn et al., 2007). The reordering rules give an improvement in accuracy from 28.52 to 30.86 BLEU score. A concern for methods that make use of Chinese\nparsers is that these parsers are typically of relatively low accuracy, particularly given that Chinese requires a word-segmentation step that is not required in languages such as English. Our results show that Chinese parses are useful in SMT in spite of this problem. We report results showing the precision of the reordering rules\u2014essentially testing how often the Chinese sentences are correctly reordered\u2014 to give more insight into this issue. We also report experiments which assess the impact of each type of reordering rule on translation accuracy."
        },
        {
            "heading": "2 Related Work",
            "text": "A number of researchers (Brown et al., 1992; Berger et al., 1996; Niessen and Ney, 2004; Xia and McCord, 2004; Collins et al., 2005) have described approaches that preprocess the source language input in SMT systems. We are not, however, aware of work on this topic for translation from Chinese to English. Brown et al. (1992) describe an analysis component for French which moves phrases around (in addition to other transformations) so the source and target sentences are closer to each other in word order. Berger et al. (1996) describe an approach for French that reorders phrases of the formNOUN1 de NOUN2. Xia and McCord (2004) describe an approach for French, where reordering rules that operate on context-free rule productions are acquired au-\ntomatically. Niessen and Ney (2004) describe an approach for translation from German to English that combines verbs with associated particles, and also reorders questions. Collins et al. (2005) also describe an approach for German, concentrating on reordering German clauses, which have quite different word order from clauses in English. Our approach is most similar to that of Collins et al. (2005).\nMost SMT systems employ some mechanism that allows reordering of the source language during translation (i.e., non-monotonic decoding). The MOSES phrase-based system that we use has a relatively simple reordering model which has a fixed penalty for reordering moves in the decoder. More sophisticated models include reordering parameters that are sensitive to lexical information (Tillmann, 2004; Kumar and Byrne, 2005; Koehn et al., 2005). The model of Chiang (2005) employs a synchronous context-free grammar to allow hierarchical approaches to reordering. The syntaxbased models of Yamada and Knight (2001) and Marcu et al. (2006) build a full parse tree in the target language, again effectively allowing hierarchical reordering based on synchronous grammars. It is worth noting that none of these approaches to reordering make use of explicit syntactic information in the source language\u2014for example, none of the methods make use of an existing source-language parser (the systems of Yamada and Knight (2001) and Marcu et al. (2006) make use of a parser in the target language, i.e., English).\nFinally, note that a number of statistical MT systems make use of source language syntax in transducer-style approaches; see (Lin, 2004; Ding and Palmer, 2005; Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006). In contrast to the preprocessing approach, they attempt to incorporate syntax directly into the decoding stage."
        },
        {
            "heading": "3 Chinese Syntactic Reordering Rules",
            "text": "We used the Penn Chinese Treebank guidelines (Xue et al., 2005) in searching for a suitable set of reordering rules. We examined all phrase types in the Treebank; potentially phrases of any type could be candidates for reordering rules. Table 1 provides a list of Treebank phrase tags for easy reference. We ruled out several phrase types as not requiring reordering\nADJP adjective phrase ADVP adverbial phrase headed byAD (adverb) CLP classifier phrase CP clause headed byC (complementizer) DNP phrase formed by \u201cXP+DEG\u201d DP determiner phrase DVP phrase formed by \u201cXP+DEV\u201d FRAG fragment IP simple clause headed byI (INFL) LCP phrase formed by \u201cXP+LC\u201d LST list marker NP noun phrase PP preposition phrase PRN parenthetical QP quantifier phrase UCP unidentical coordination phrase VP verb phrase\nTable 1: Penn Chinese Treebank phrase tags.\nrules. For example, ChineseADJPs, ADVPs, DPs, QPs, andPPs all have similar internal word ordering to their English counterparts. Also similar are a group of special structures such asLST, FRAG, and PRN.\nWe identified three categories that we considered to be the most prominent candidates for reordering. These phrases includeVPs (verb phrases),NPs (noun phrases), andLCPs (localizer phrases, which frequently map to prepositional phrases in English). In the following, we discuss each of the three main categories in more detail."
        },
        {
            "heading": "3.1 Verb Phrases",
            "text": "In Chinese, verb phrase modifiers typically occur in pre-verbal position.VP modifiers can beADVPs, temporal and spatialNPs, QP, PPs, CPs, IPs, DVPs, andLCPs. TheADVPs are simple adverbs, which can occur both preverbal and postverbal in an English verb phrase, so we do not attempt to move them. Similarly, theCP, IP, and DVP modifiers are typically adverbial phrases, which do not have a fixed position in English verb phrases. In the following, we only consider cases involvingPPs, LCPs, temporal and spatialNPs, andQPs.\nPPs and LCPs Figure 2 shows an example verb phrase with aPP modifier, which translates literally\ninto \u201cat Eastern Division rank 10th.\u201d Recognizing thatPPs in English verb phrases almost always occur after the verb, we use a simpleVP(PP:VP) reordering rule which states that aPP in a parentVP needs to be repositioned after the siblingVP. LCPs are similar toPPs and typically map to prepositional phrases in English. Thus they are handled similarly to PPs, i.e., LCPs in a parentVP are repositioned after the siblingVP.\nNPs Figure 3 gives an example of a verb phrase with a temporalNP modifier, which literally translates into \u201csame day morning issue statement.\u201d In English, temporal phrases such as these almost always occur after the head verb. Conveniently, the Chinese Treebank uses the part of speech (POS) tag NT for temporal nouns. Thus, we use a rule which states that a preverbalNP will be repositioned after the siblingVP if there is at least oneNT in the NP subtree. A similar rule might apply to locative NPS; however, there is no special POS tag in the Treebank marking locations,1 so we do not have a syntax-based reordering rule to handle locativeNPs.\nQPs QP modifiers in verb phrases often correspond to time-related concepts such as duration and frequency. Figure 4 shows an example verb phrase with a QP modifier, literally translating into \u201cmany time injured.\u201d Since temporal phrases almost always occur after the verb in English verb phrases, we han-\n1One can argue thatNR (proper nouns) in that context are likely to be places. However, there also exist many exceptions, and so we decided not to exploit theNR tag.\nVP QP CD \u00f5(many) CLP M g(time)\nVP-A VV \u00c9\u00fa(injured)\ndle such cases by a simple rule which states that the QP in a parentVP will be repositioned after the sibling VP."
        },
        {
            "heading": "3.2 Noun Phrases",
            "text": "Noun phrases in Chinese can take several types of modifiers: for example, phrases of typeQP, DP, ADJP, NP, DNP, andCP. The placement ofQP, DP, andADJP modifiers is somewhat similar to English in that these phrases typically occur before the noun they modify. The case ofNP modifiers inNPs is very limited in the Chinese Treebank, since most noun-noun sequences form compounds in a single NP. Hence we only developed reordering rules to handleDNP and clausal (CP) modifiers.\nDNPs DNPs are formed by \u201cXP+DEG,\u201d whereXP can be a phrase of the typeADJP, QP, PP, LCP, or NP. When theXP is anADJP or aQP, no reordering is needed because the word order is the same as that of English.\nWhen theXP is aPP or anLCP, theDNP essentially corresponds to a prepositional phrase in English, which almost always appears after the noun being modified. Figure 5 shows an example where the XP in the DNP is a PP. The reordering rule to handle these two cases states that, if a parentNP has a child DNP which in turn has a childPP or LCP, then theDNP is repositioned after the last siblingNP.\nFigure 6 shows an example noun phrase for which theXP in theDNP isNP. On the surface, the Chinese \u201cNP1 DEG NP2\u201d sequence is analogous to the English possessive structure of \u201cNP1\u2019s NP2\u201d and does\nNP-A DNP NP DP DT T(this) CLP M (measure word) NPB NN E\u00e2(technique)\nDEG (DEG) NPB NN \u00dd\u00ba(mastery)\nFigure 6: An example ChineseNP phrase with a DNP modifier headed by aNP. The phrase translates into \u201cthe mastery of this technique\u201d in English.\nnot require reordering, for example, \u201c (Sue) (\u2019s)*l(friend)\u201d in Chinese and \u201cSue\u2019s friend\u201d in English. However, the Chinese possessive structure\n\u201cNP1 DEG NP2\u201d can express more sophisticated re-\nlationships which are inappropriate for the \u201cNP1\u2019s\nNP2\u201d expression. For example, the phrase in Fig-\nure 6 can only be translated into \u201cthe mastery of this technique,\u201d but not \u201cthis technique\u2019s mastery.\u201d We decide to reorderDNPs of the \u201cNP+DEG\u201d format, because they often can only map to the \u201cNP2 of NP1\u201d expression in English. Additionally, the \u201cNP2\nof NP1\u201d expression is more general and can replace\n\u201cNP1\u2019s NP2\u201d in many cases. One exception is when\nthe NP is a pronoun (PN), e.g., \u201c (he) (\u2019s) \u00b6i(name),\u201d in which case theDNP acts simply like a\npossessive pronoun. Our reordering rule thus states that, if a parentNP has a childDNPwhich in turn has a childNP that is not aPN, then theDNP is repositioned after the last siblingNP.\nCPs Relative clauses correspond to theCP category in the Treebank. Figure 7 shows an example noun phrase with two nestedCP modifiers. As illustrated in the figure, relative clauses in Chinese also occur before the noun they modify, which makes the word order of this sentence quite different from that of the English translation. Such distortions in the word reordering will be quite difficult for the word or phrase-based alignment model to capture. However, with the application of a reordering rule to reposition the childCP after its siblingNP under a parentNP, and thePP VP reordering rule for VP introduced previously, the sentence can be easily transformed into \u201cFrench delegation participate 8th handicap people Winter Olympics hold at US Salt Lake City,\u201d a sentence whose word order is much closer to that of English. CP is typically formed by \u201cIP+DEC\u201d, in which DEC\u2019s only function is to mark theIP as a relative\nNP CP IP VP VV \u00eb\\ (participate) NP CP IP VP PP P 3 (at)\nNP NR {I(US) NR \u00ed \u00a2 (Salt Lake City) VP VV \u00de1 (hold)\nDEC (DEC) QP OD 1l (8th)\nCLP M 3 (measure word) NPB NN \u00ed;<\n(handicap people) NR \u00c1 \u00ac\n(Winter Olympics) DEC (DEC)\nNPB NR {I (French) NPB NN L\u00e8 (delegation)\nFigure 8: An example Chinese localizer phrase. The phrase translates into \u201cafter the accident happened\u201d in English.\nclause, similar to the function of \u201cthat\u201d in English. We use a rule to bringDEC to the front ofIP under CP, to make it more aligned with the \u201cthat + clause\u201d structure of English."
        },
        {
            "heading": "3.3 Localizers",
            "text": "Figure 8 shows an example phrase of the typeLCP. Localizers (taggedLC in the Treebank) in Chinese can be thought of as a post-phrasal preposition which is often used with temporal and locative phrases or clauses to mark directional information. They function similarly to prepositions and conjunctions in English such as \u201cbefore,\u201d \u201con,\u201d \u201cwhen,\u201d etc. Constituents of typeLCP have a similar function to prepositional phrases. Sometimes they are combined with a pre-phrasal generic preposition \u201c3\u201d (roughly corresponding to \u201cat\u201d in English) to form aPP explicitly. An example is shown in Figure 9.\nWe developed a simple reordering rule which moves anLC node to immediately before its left sibling under a parentLCP node. This will result in a word order that is more similar to that of the English\nprepositional phrase: the example in Figure 8 has the paraphrase \u201cafter accident happen\u201d after the reordering rule is applied. In the case where anLCP is embedded in a parentPP phrase, theLC reordering rule will essentially merge the post-phrasal localizer with the pre-phrasal preposition. For example, the phrase in Figure 9 becomes \u201cat after accident happen\u201d after reordering. The phrase-based SMT system will have little problem in learning that \u201cat after\u201d translates into \u201cafter\u201d in English."
        },
        {
            "heading": "4 Evaluation",
            "text": "Our baseline is a phrase-based MT system trained using the MOSES toolkit (Koehn et al., 2007). The training data consists of nearly 637K pairs of sentences from various parallel news corpora distributed by the Linguistic Data Consortium (LDC).2 For tuning and testing, we use the official NIST MT evaluation data for Chinese from 2002 to 2006, which have four human generated English reference translations for each Chinese input. The evaluation data from 2002 to 2005 were split into two sets of roughly equal sizes: a tuning set of 2347 sentences is used for optimizing various parameters using minimum error training (also using the MOSES toolkit), and a development set of 2320 sentences is used for various analysis experiments. We report results on the NIST 2006 evaluation data.\nA series of processing steps are needed before the reordering rules can be applied, which include segmentation, part-of-speech tagging, and parsing. We trained a Chinese Treebank-style tokenizer and partof-speech tagger, both using a tagging model based on a perceptron learning algorithm (Collins, 2002). We used the Chinese parser described by Sun and Jurafsky (2004), which was adapted from the parser\n2We used 8 corpora for training, including LDC2002E18, LDC2003E07, LDC2003E14, LDC2005E83, LDC2005T06, LDC2006E26, LDC2006E8, and LDC2006G05.\npresented in Collins (1997). We then applied the reordering rules described in the previous section to the parse tree of each input. The reordered sentence is then re-tokenized to be consistent with the baseline system, which uses a different tokenization scheme that is more friendly to the MT system.3\nWe use BLEU scores as the performance measure in our evaluation (Papineni et al., 2002). Table 2 gives results for the baseline and reordered systems on both the development and test sets. As shown in the table, the reordering method is able to improve the BLEU scores by 1.29 points on the development set, and by 2.34 on the NIST 2006 set."
        },
        {
            "heading": "4.1 Frequency and Accuracy of Reordering Rules",
            "text": "We collected statistics to evaluate how often and accurately the reordering rules are applied in the data. The accuracy is measured in terms of the percentage of rule applications that correctly reorder sentences. The vast majority of reordering errors are due to parsing mistakes.\nTable 3 summarizes the count of each rule in the training data, ignoring rules occurring less than 500 times in the training data, and the number of sentences each rule impacts. The most frequent three rules areNP(CP:NP), VP(PP:VP), andDNP(NP):NP, which account for over 76% of all the reordering instances and jointly affect 74% of all the training sentences. This shows the prevalence of systematic word order differences between Chinese and English. Only 122,076 (or 19.2%) sentences remain unchanged after the reordering rules are applied.\nEach of the processing steps in producing the Chiese parse tree is prone to error and could lead to mistakes in the reordering of the Chinese sentence. 3The tokenizer used by the MT system favors smaller word units, and backs off to a character by character scheme for unknown words.\nTable 3: Statistics of various reordering rules in the training data.\nTo assess the accuracy of reordering rules, we con-\nducted human evaluations on a set of 200 sentences\nrandomly selected from the development set. Within\nthis set, there were in total 155 sentences containing at least one reordering rule, with 339 rules in total. A bilingual speaker was presented with the Chinese parse tree, the sentence before and after the reordering, and the particular reordering rules applied to the sentence. The bilingual rater determined the correctness of each rule by first identifying the scope of the rule and comparing the string before and after reordering, referencing the corresponding parse structure if necessary. Table 4 summarizes the accuracy (precision) for each type of rule. Notice that our human evaluation of the reordering rules does not take into account missed reordering.\nOverall, there are a lot of reordering errors caused by incorrect parses. On a sentence level, only 57 out of the 155 reordered sentences (36.8%) are error free. Nevertheless, syntactic reordering seems to be helpful in improving the translation quality, despite noise introduced into the data due to the errors."
        },
        {
            "heading": "4.2 Impact of Individual Reordering Rules",
            "text": "In order to assess the relative effectiveness of the reordering rules, we conducted an experiment in which we trained and tested systems using data that were reordered using different subsets of the reordering rules. Table 5 summarizes the BLEU scores of the reordered system for each rule type.\nCount Accuracy\nVP rules 108 65.7% NP rules 209 54.6% LC rules 76 77.6% All rules 393 62.1%\nBLEU Gain\nBaseline 31.57 - VP rules 32.71 +1.14 NP rules 32.23 +0.66 LC rules 31.59 +0.02 All rules 32.86 +1.29\nAs shown in the table, theVP rules are more effective than theNP rules, even though theNP rules are more frequent than theVP rules in the data. This is perhaps because the reordering ofVP modifiers achieves a slightly higher accuracy than that of the NP modifiers. We are a bit surprised by the lack of performance gains with theLC rules only. More analysis is needed to explain this behavior."
        },
        {
            "heading": "4.3 Better Alignment?",
            "text": "There could be two reasons why the syntactic reordering approach improves over the baseline phrase-based SMT system. One obvious benefit is that the word order of the transformed source sentence is much closer to that of the target sentence, which reduces the reliance on the distortion model to perform reordering during decoding. Another potential benefit is that the alignment between the two sides will be of higher quality because of fewer \u201cdistortions\u201d between the source and the target, so that the resulting phrase table of the reordered system would be better. However, a counter argument is that he reordering is very error prone, so that the added noise in the reordered data would actually hurt the alignments and hence the phrase table.\nLacking a good way to measure the quality of\nOriginal Dev Reordered Dev\nBaseline 31.57 32.19 Reorder 30.67 32.86\nthe phrase table directly, we conducted an experiment in which we tested the baseline and reordered systems with both the original and reordered development data. The idea is to compare the two systems given the same type of input: if the reordered system learned a better phrase table, then it might outperform the baseline system on un-reordered inputs despite the mismatch; on the other hand, if the baseline system learned a better phrase table, then it might outperform the reordered system on reordered inputs despite the mismatch. However, the results in Table 6 did not settle our question: the reordered system performed worse than the baseline on unreordered data, while the baseline system performed worse than the reordered system on reordered data, both of which can be explained by the mismatched conditions between training and testing. Perhaps more interesting is the performance gap of the baseline system on the reordered data vs. on the original data: it achieved 0.62 BLEU score gain despite the mismatch in training and testing conditions."
        },
        {
            "heading": "5 Discussion and Future Work",
            "text": "In this paper, we described a set of syntactic reordering rules that exploit systematic differences between Chinese and English word order to transform Chinese sentences to be much closer to English in terms of their word order. We evaluated the reordering approach within the MOSES phrase-based SMT system (Koehn et al., 2007). The reordering approach improved the BLEU score for the MOSES system from 28.52 to 30.86 on the NIST 2006 evaluation data. Our manual evaluation of the reordering accuracy indicated that the reordering approach is helpful at improving the translation quality despite relatively frequent reordering errors. The reordering approach even achieved a 0.62 gain in BLEU score when only the test data are reordered.\nAn important category we examined but did not reorder was clauses of typeIP, which generally corresponds to declarative sentences in Chinese. Sentences of this form have quite similar top-level\nconstituent ordering to English: both follow SVO\n(subject-verb-object) order. There are several spe-\ncial cases in which English and Chinese differ, the\nmost notable being the topicalization of objects or\ntemporal and locative noun phrases (which function as adverbial phrases). We did not try to restore them to the canonical order for several reasons. First, topicalization of temporal and locative phrases happens in English as well. For example, \u201cIn Israel yesterday, an explosion killed one person and injured twelve\u201d is a perfectly acceptable English sentence. Second, the parser\u2019s performance on special constructions is likely to be poor, resulting in frequent reordering errors. Third, special constructions that do not occur often in the data are less likely to have a significant impact on the translation performance. Thus our strategy has been to find reordering rules for syntactic categories that are common in the data and systematically different between the two languages.\nIn our experiments, the phrase-based MT system uses an un-lexicalized reordering model, which might make the effects of the syntactic reordering method more pronounced. However, in an early experiment4 submitted to the official NIST 2006 MT evaluation, the reordered system also improved the BLEU score substantially (by 1.34 on NIST 2006 data) over a phrase-based MT system with lexicalized reordering models (Koehn et al., 2005). The same set of reordering rules in the experimental setting in the current paper achieve a 1.82 BLEU improvement on the same data set, which is comparable to the 1.34 gain for the lexicalized system.\nWe plan to output reordered lattices in the future, so that the approach would be more robust to errors made during parsing/reordering."
        },
        {
            "heading": "Acknowledgements",
            "text": "We would like to thank Brooke Cowan, Stephanie Seneff, and the three anonymous reviewers for their valuable comments. Thanks to Yushi Xu for evaluating the accuracy of the reordering rules. This work\n4This experiment made use of a subset of the reordering rules we have presented here.\nwas supported under the GALE program of the Defense Advanced Research Projects Agency, Contract No. HR0011-06-C-0022."
        }
    ],
    "title": "Chinese Syntactic Reordering for Statistical Machine Translation",
    "year": 2007
}