{
    "abstractText": "Secure relative timestamping and secure append-only logs are two historically mostly independent lines of research, which we show to be sides of the same coin \u2014 the authentication of prefix relations. From this more general viewpoint, we derive several complexity criteria not yet considered in previous literature. We define transitive prefix authentication graphs, a graph class that captures all hash-based timestamping and log designs we know of. We survey existing schemes by expressing them as transitive prefix authentication graphs, which yields more compact definitions and more complete evaluations than in the existing literature.",
    "authors": [
        {
            "affiliations": [],
            "name": "Aljoscha Meyer"
        }
    ],
    "id": "SP:7136d643d17c41a654ec1db9ddd76b4aae0712c8",
    "references": [
        {
            "authors": [
                "Mustafa Al-Bassam",
                "Sarah Meiklejohn"
            ],
            "title": "Contour: A practical system for binary transparency. In Data Privacy Management, Cryptocurrencies and Blockchain Technology, pages 94\u2013110",
            "year": 2018
        },
        {
            "authors": [
                "David Basin",
                "Cas Cremers",
                "Tiffany Hyun-Jin Kim",
                "Adrian Perrig",
                "Ralf Sasse",
                "Pawel Szalachowski"
            ],
            "title": "Arpki: Attack resilient public-key infrastructure",
            "venue": "In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security,",
            "year": 2014
        },
        {
            "authors": [
                "Dave Bayer",
                "Stuart Haber",
                "W Scott Stornetta"
            ],
            "title": "Improving the efficiency and reliability of digital time-stamping",
            "venue": "In Sequences Ii,",
            "year": 1993
        },
        {
            "authors": [
                "Kaouthar Blibech",
                "Alban Gabillon"
            ],
            "title": "A new timestamping scheme based on skip lists",
            "venue": "In Computational Science and Its Applications-ICCSA 2006: International Conference,",
            "year": 2006
        },
        {
            "authors": [
                "Ahto Buldas",
                "Peeter Laud"
            ],
            "title": "New linking schemes for digital time-stamping",
            "venue": "In ICISC,",
            "year": 1998
        },
        {
            "authors": [
                "Ahto Buldas",
                "Peeter Laud",
                "Helger Lipmaa"
            ],
            "title": "Eliminating counterevidence with applications to accountable certificate management",
            "venue": "Journal of Computer Security,",
            "year": 2002
        },
        {
            "authors": [
                "Ahto Buldas",
                "Peeter Laud",
                "Helger Lipmaa",
                "Jan Villemson"
            ],
            "title": "Time-stamping with binary linking schemes",
            "venue": "Annual International Cryptology Conference,",
            "year": 1998
        },
        {
            "authors": [
                "Ahto Buldas",
                "Helger Lipmaa",
                "Berry Schoenmakers"
            ],
            "title": "Optimally efficient accountable time-stamping",
            "venue": "In International workshop on public key cryptography,",
            "year": 2000
        },
        {
            "authors": [
                "Melissa Chase",
                "Sarah Meiklejohn"
            ],
            "title": "Transparency overlays and applications",
            "venue": "In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pages 168\u2013179,",
            "year": 2016
        },
        {
            "authors": [
                "Laurent Chuat",
                "Pawel Szalachowski",
                "Adrian Perrig",
                "Ben Laurie",
                "Eran Messeri"
            ],
            "title": "Efficient gossip protocols for verifying the consistency of certificate logs",
            "venue": "In 2015 IEEE Conference on Communications and Network Security (CNS),",
            "year": 2015
        },
        {
            "authors": [
                "Scott A Crosby",
                "Dan S Wallach"
            ],
            "title": "Efficient data structures for tamper-evident logging",
            "venue": "In USENIX security symposium,",
            "year": 2009
        },
        {
            "authors": [
                "Alan Demers",
                "Dan Greene",
                "Carl Hauser",
                "Wes Irish",
                "John Larson",
                "Scott Shenker",
                "Howard Sturgis",
                "Dan Swinehart",
                "Doug Terry"
            ],
            "title": "Epidemic algorithms for replicated database maintenance",
            "venue": "In Proceedings of the sixth annual ACM Symposium on Principles of distributed computing,",
            "year": 1987
        },
        {
            "authors": [
                "Benjamin Dowling",
                "Felix G\u00fcnther",
                "Udyani Herath",
                "Douglas Stebila"
            ],
            "title": "Secure logging schemes and certificate transparency",
            "venue": "In European Symposium on Research in Computer Security,",
            "year": 2016
        },
        {
            "authors": [
                "Adam Eijdenberg",
                "Ben Laurie",
                "Al Cutter"
            ],
            "title": "Verifiable data structures",
            "venue": "Google Research, Tech. Rep,",
            "year": 2015
        },
        {
            "authors": [
                "Sascha Fahl",
                "Sergej Dechand",
                "Henning Perl",
                "Felix Fischer",
                "Jaromir Smrcek",
                "Matthew Smith"
            ],
            "title": "Hey, nsa: Stay away from my market! future proofing app markets against powerful attackers",
            "venue": "In proceedings of the 2014 ACM SIGSAC conference on computer and communications security,",
            "year": 2014
        },
        {
            "authors": [
                "Michael T Goodrich",
                "Roberto Tamassia"
            ],
            "title": "Efficient authenticated dictionaries with skip lists and commutative hashing",
            "venue": "Technical report,",
            "year": 2000
        },
        {
            "authors": [
                "Stuart Haber",
                "W Scott Stornetta"
            ],
            "title": "How to time-stamp a digital document",
            "venue": "In Conference on the Theory and Application of Cryptography,",
            "year": 1990
        },
        {
            "authors": [
                "Tiffany Hyun-Jin Kim",
                "Lin-Shung Huang",
                "Adrian Perrig",
                "Collin Jackson",
                "Virgil Gligor"
            ],
            "title": "Accountable key infrastructure (aki) a proposal for a public-key validation infrastructure",
            "venue": "In Proceedings of the 22nd international conference on World Wide Web,",
            "year": 2013
        },
        {
            "authors": [
                "Murat Yasin Kubilay",
                "Mehmet Sabir Kiraz",
                "Hac\u0131 Ali Mantar"
            ],
            "title": "Certledger: A new pki model with certificate transparency based on blockchain",
            "venue": "Computers & Security,",
            "year": 2019
        },
        {
            "authors": [
                "Ben Laurie"
            ],
            "title": "Certificate transparency: Public, verifiable, append-only",
            "venue": "logs. Queue,",
            "year": 2014
        },
        {
            "authors": [
                "Ben Laurie",
                "Emilia Kasper"
            ],
            "title": "Revocation transparency",
            "venue": "Google Research, September,",
            "year": 2012
        },
        {
            "authors": [
                "Ben Laurie",
                "Adam Langley",
                "Emilia Kasper",
                "Eran Messeri",
                "Rob Stradling"
            ],
            "title": "Certificate Transparency Version 2.0",
            "venue": "RFC 9162,",
            "year": 2021
        },
        {
            "authors": [
                "Hemi Leibowitz",
                "Haitham Ghalwash",
                "Ewa Syta",
                "Amir Herzberg"
            ],
            "title": "Ctng: Secure certificate and revocation transparency",
            "venue": "Cryptology ePrint Archive,",
            "year": 2021
        },
        {
            "authors": [
                "Jinyuan Li",
                "Maxwell N Krohn",
                "David Mazieres",
                "Dennis E Shasha"
            ],
            "title": "Secure untrusted data repository (sundr)",
            "venue": "In Osdi,",
            "year": 2004
        },
        {
            "authors": [
                "DSV Madala",
                "Mahabir Prasad Jhanwar",
                "Anupam Chattopadhyay"
            ],
            "title": "Certificate transparency using blockchain",
            "venue": "IEEE International Conference on Data Mining Workshops (ICDMW),",
            "year": 2018
        },
        {
            "authors": [
                "Marcela S Melara",
                "Aaron Blankstein",
                "Joseph Bonneau",
                "Edward W Felten",
                "Michael J Freedman"
            ],
            "title": "CONIKS}: Bringing key transparency to end users",
            "venue": "In 24th USENIX Security Symposium (USENIX Security",
            "year": 2015
        },
        {
            "authors": [
                "Alfred J Menezes",
                "Paul C Van Oorschot",
                "Scott A Vanstone"
            ],
            "title": "http: //labit501.upct.es/~fburrull/docencia/ SeguridadEnRedes/old/teoria/bibliography/ HandbookOfAppliedCryptography_AMenezes.pdf",
            "venue": "Handbook of applied cryptography. CRC press,",
            "year": 2018
        },
        {
            "authors": [
                "Ralph C Merkle"
            ],
            "title": "A certified digital signature",
            "venue": "In Conference on the Theory and Application of Cryptology,",
            "year": 1989
        },
        {
            "authors": [
                "Moni Naor",
                "Kobbi Nissim"
            ],
            "title": "Certificate revocation and certificate update",
            "venue": "IEEE Journal on selected areas in communications,",
            "year": 2000
        },
        {
            "authors": [
                "Kirill Nikitin",
                "Eleftherios Kokoris-Kogias",
                "Philipp Jovanovic",
                "Nicolas Gailly",
                "Linus Gasser",
                "Ismail Khoffi",
                "Justin Cappos",
                "Bryan Ford"
            ],
            "title": "CHAINIAC}: Proactive {Software-Update} transparency via collectively signed skipchains and verified builds",
            "venue": "In 26th USENIX Security Symposium (USENIX Security",
            "year": 2017
        },
        {
            "authors": [
                "Linus Nordberg",
                "Daniel Kahn Gillmor",
                "Tom Ritter"
            ],
            "title": "Gossiping in CT. Internet-Draft draft-ietftrans-gossip-05, Internet Engineering Task Force, January 2018",
            "venue": "https://datatracker.ietf.org/doc/ draft-ietf-trans-gossip/05/",
            "year": 2018
        },
        {
            "authors": [
                "Maxwell Ogden",
                "Karissa McKelvey",
                "Mathias Buus Madsen"
            ],
            "title": "Dat \u2014 distributed dataset synchronization and versioning",
            "venue": "Open Science Framework,",
            "year": 2017
        },
        {
            "authors": [
                "Charalampos Papamanthou",
                "Roberto Tamassia",
                "Nikos Triandopoulos"
            ],
            "title": "Authenticated hash tables",
            "venue": "In Proceedings of the 15th ACM conference on Computer and communications security,",
            "year": 2008
        },
        {
            "authors": [
                "William Pugh"
            ],
            "title": "Skip lists: a probabilistic alternative to balanced trees",
            "venue": "Communications of the ACM,",
            "year": 1990
        },
        {
            "authors": [
                "Tobias Pulls",
                "Roel Peeters"
            ],
            "title": "Balloon: A forwardsecure append-only persistent authenticated data structure",
            "venue": "In European Symposium on Research in Computer Security,",
            "year": 2015
        },
        {
            "authors": [
                "Tobias Pulls",
                "Roel Peeters",
                "Karel Wouters"
            ],
            "title": "Distributed privacy-preserving transparency logging",
            "venue": "In Proceedings of the 12th ACM workshop on Workshop on privacy in the electronic society,",
            "year": 2013
        },
        {
            "authors": [
                "Mark D Ryan"
            ],
            "title": "Enhanced certificate transparency and end-to-end encrypted mail",
            "venue": "Cryptology ePrint Archive,",
            "year": 2013
        },
        {
            "authors": [
                "Bruce Schneier",
                "John Kelsey"
            ],
            "title": "Secure audit logs to support computer forensics",
            "venue": "ACM Transactions on Information and System Security (TISSEC),",
            "year": 1999
        },
        {
            "authors": [
                "Abhishek Singh",
                "Binanda Sengupta",
                "Sushmita Ruj"
            ],
            "title": "Certificate transparency with enhancements and short proofs. In Information Security and Privacy: 22nd Australasian Conference, ACISP 2017",
            "venue": "Proceedings, Part II",
            "year": 2017
        },
        {
            "authors": [
                "Ewa Syta",
                "Iulia Tamas",
                "Dylan Visher",
                "David Isaac Wolinsky",
                "Philipp Jovanovic",
                "Linus Gasser",
                "Nicolas Gailly",
                "Ismail Khoffi",
                "Bryan Ford"
            ],
            "title": "Keeping authorities\" honest or bust\" with decentralized witness cosigning",
            "venue": "IEEE Symposium on Security and Privacy (SP),",
            "year": 2016
        },
        {
            "authors": [
                "Roberto Tamassia"
            ],
            "title": "Authenticated data structures",
            "venue": "In European symposium on algorithms,",
            "year": 2003
        },
        {
            "authors": [
                "Dominic Tarr",
                "Erick Lavoie",
                "Aljoscha Meyer",
                "Christian Tschudin"
            ],
            "title": "Secure scuttlebutt: An identity-centric protocol for subjective and decentralized applications",
            "venue": "In Proceedings of the 6th ACM conference on informationcentric networking,",
            "year": 2019
        },
        {
            "authors": [
                "Alin Tomescu",
                "Vivek Bhupatiraju",
                "Dimitrios Papadopoulos",
                "Charalampos Papamanthou",
                "Nikos Triandopoulos",
                "Srinivas Devadas"
            ],
            "title": "Transparency logs via append-only authenticated dictionaries",
            "venue": "In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security,",
            "year": 2019
        },
        {
            "authors": [
                "Alin Tomescu",
                "Srinivas Devadas"
            ],
            "title": "Catena: Efficient non-equivocation via bitcoin",
            "venue": "IEEE Symposium on Security and Privacy (SP),",
            "year": 2017
        },
        {
            "authors": [
                "Ze Wang",
                "Jingqiang Lin",
                "Quanwei Cai",
                "Qiongxiao Wang",
                "Daren Zha",
                "Jiwu Jing"
            ],
            "title": "Blockchain-based certificate transparency and revocation transparency",
            "venue": "IEEE Transactions on Dependable and Secure Computing,",
            "year": 2020
        },
        {
            "authors": [
                "Douglas Brent West"
            ],
            "title": "Introduction to graph theory, volume 2. Prentice hall",
            "venue": "Upper Saddle River,",
            "year": 2001
        },
        {
            "authors": [
                "Jiangshan Yu",
                "Vincent Cheval",
                "Mark Ryan"
            ],
            "title": "Dtki: A new formalized pki with verifiable trusted parties",
            "venue": "The Computer Journal,",
            "year": 2016
        },
        {
            "authors": [
                "Aydan R Yumerefendi",
                "Jeffrey S Chase"
            ],
            "title": "Strong accountability for network storage",
            "venue": "ACM Transactions on Storage (TOS),",
            "year": 2007
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Consider the problem of mapping any finite sequence to a small digest, such that for any pair of a sequence and one of its prefixes, their digests together with a small certificate unforgeably certify that one is a prefix of the other. In other words, consider the problem of finding an authenticated data structure for the prefix relation on strings.\nWhile we are not aware of any prior work that explicitly takes this abstract viewpoint of the problem, there are several publications that tackle it through the lens of a specific use-case: secure logging [39] [11] [37], accountable shared storage [25] [49], certificate transparency [20] [21] [23], or data replication [33] [43].\nSome fifteen years before most of these publications, investigation into secure relative timestamping \u2013 given two events, give an unforgeable certificate that one happened before the other \u2013 has yielded linking schemes [7] as a class of efficient timestamping solutions, with several specific schemes being proposed [17] [5] [8]. While solutions to relative timestamping need not necessarily yield solutions to prefix authentication in general, every linking scheme does provide prefix authentication.\nSo there are quite a few disjoint publications working on essentially the same problem, but with sparse interreferencing and the independent invention of various metaphorically\nwheel-shaped devices. All these techniques are based on the observation that if some object contains a secure hash of another object, the prior must have been created after the latter. Linking schemes are a well-defined class of such solutions, other approaches only have ad-hoc descriptions and proofs of correctness. Different publications also considered different efficiency criteria, making it difficult to objectively compare several approaches.\nWe provide systemization on several levels. First, we give a precise definition of prefix authentication, and systematically derive a set of efficiency criteria from this definition (section 4). Second, we define a class of digraphs which generalizes the linking schemes, can be used for prefix authentication, and includes all hash-based prefix authentication schemes that we are aware of (section 5). And third, we survey those prior schemes, expressing them in our formalism and evaluating them by our complexity criteria, yielding the most complete comparison of such schemes so far (section 6), and revealing some flaws in the current state of the art.\nWe round out our presentation with an overview of related work (section 2), some mathematical preliminaries (section 3), and a conclusion (section 7)."
        },
        {
            "heading": "2 Related Work",
            "text": "Authenticated data structures [42] are data structures which allow to supplement query results with a small certificate of the result\u2019s validity; a verifier with access to only a small digest of the current state of the data structure can check whether the query was answered truthfully based on the certificate.\nSecure (relative) timestamping asks for authenticated data structures for a happened-before relation; given two events, it should be possible to prove which occurred first (as opposed to both happening concurrently). Haber and Stornetta\u2019s foundational work [17] arranges events in a linked list, using secure hashes as references. The path from an event to a prior one certifies their happened-before relation.\nA straightforward optimization is batching multiple events into a single round by storing all events within a round in\nar X\niv :2\n30 8.\n13 83\n6v 1\n[ cs\n.C R\n] 2\n6 A\nug 2\na Merkle tree, and linearly linking the roots of each round rather than individual events [3]. This is fully analogous to the blocks of a blockchain. Certificate sizes do not decrease asymptotically however.\nBuldas, Laud, Lipmaa, and Villemson provide the first asymptotic improvement by adding additional hashes such that there exist paths of logarithmic length between any pair of events [7]. After Buldas and Laud finding the solution with the shortest certificates in this class [5], Buldas, Lipmaa, and Schoenmakers provide threaded authentication trees [8], an even more efficient construction in the class of acyclic graphs where the vertex for every event is reachable from all later events. This is the class we refer to as linking schemes, and upon which our generalization builds.\nTheir presentation and optimality proofs rely on a notion of time-stamping rounds, the maximum number of events in a single round features in their complexity analyses. We take on a more general setting, the notion of rounds corresponds to prefix authentication for sequences of bound length. Hence, their lower bounds do not apply to our setting.\nLaurie, Langley, Kasper, Messeri, and Stradling introduce certificate transparency (CT) [20] [21] [23], a proposed Internet standard for publicly logging information about the activities of certificate authorities (CAs). Rather than detailing the extensive background of public-key infrastructure into which CT embeds itself, we refer to [24] Section 2. We shall further abstract over optimization details of CT such as signed certificate timestamps (SCTs) or maximum merge delays. What remains is a so-called1 append-only log with the dual-purpose of certifying both a prefix relation and set membership. The CT data structure achieves the same certificate sizes as the threaded authentication trees, but is not a linking scheme, which prompts our generalization.\nVarious publications propose alternatives to the original CT design, reasons include adding support for certificate revocation, strengthening the trust model, or mitigating privacy concerns [22] [38] [18] [27] [2] [48] [24]. Other publications extend the concept of logging objects for accountability reasons to application binaries [15] [31] [1] or arbitrary data [14] [36]. None of them improve the underlying prefix authentication scheme.\nSeveral publications generalize (and formalize) the requirements behind CT as the combination of authenticating an append-only property and supporting authenticated membership queries: the logging scheme [13], the dynamic list com-\n1These logs are, quite simply, not append-only logs. A log maintainer cannot be prevented from creating several branches, this can merely be detected after the fact. Upon detection, a log consumer must somehow deal with the misbehavior, for example, by invalidating the log. But at that point, the log has turned into an \u201cappend-only-until-a-full-deletion\u201d log, which is strictly more powerful than an append-only log. No matter how forks are handled, the data structure is too powerful. Calling a data structure an append-only log even though it is not is careless at best and misleading at worst, especially in a security context. Hence, we exclusively talk about prefix authentication from this point on.\nmitment [9], or the append-only authenticated dictionary [44] fall in this category. We are effectively \u201cfactoring out\u201d the prefix authentication; the other \u201cfactor\u201d being authenticated set data structures, which have already received extensive treatment [30] [16] [6] [34] on their own. Usually so, our definition requires neither a specific append operation nor \u201cappend-only proofs\u201d; the general notion of prefixes suffices.\nSecure scuttlebutt [43] and hypercore [33] rely on authenticated prefix relations for efficient event replication. Secure scuttlebutt uses a linked list, hypercore has its own solution which is almost identical to the log of CT.\nSome approaches to tamper-evident logging also rely on linked lists [39] [37]. In this context, Crosby and Wallach [11] designed the first non-linking scheme approach to prefix authentication that we know of. Their scheme precedes the CT design by five years, but it is strictly more complex and inefficient.\nWork on secure networked memory has also made use of linked lists for prefix authentication [25] [49]. They speak of fork-consistency: because forks (creation of strings neither of which is a prefix of the other) cannot be authenticated, a malicious author must consistently feed updates from the same forks to the same data consumers to avoid detection.\nSince a malicious data source can easily present such different views to several consumers, data consumers should exchange information amongst each other to protect against such split world attacks. Epidemic protocols [12] can be used to this end [10] [32]. A complementary approach is to enforce (efficient) cosigning, where a data source must present its updates to a large number of other participants for approval [41].\nVarious authors argue that such reactive detection mechanism are insufficient, and propose a proactive approach based on enforcing global consensus by moving events onto a blockchain [45] [31] [1] [26] [19] [46]. Why an adversary with enough power to perpetually prevent communication between nodes that received incomparable views would be unable keep those nodes in distinct bubbles that each produce separate extensions of the blockchain is beyond us, but who are we to argue against the magic powers of the blockchain?\nWhile we restrict our attention to prefix authentication schemes that exclusively rely on secure hashing, there also exist approaches based on cryptographic accumulators [40]."
        },
        {
            "heading": "3 Preliminaries",
            "text": "We write N0 for the natural numbers, and N for the natural numbers without 0. Let N \u2286 N0, and n \u2208 N0, then N\u2264n := {m \u2208 N : m \u2264 n} and N\u2265n := {m \u2208 N : m \u2265 n}. We denote by bits(n) the unique set of natural numbers such that \u2211k\u2208bits(n) 2k = n.\nWe assume basic understanding of cryptographic hash functions [28], and a basic background in graph theory [47]. In the following, u,v always denote vertices, U,X always denote sets of vertices, G always denotes a graph on vertices V with\nedges E. As we talk about directed graphs exclusively, all graph terminology (graph, path, etc.) refers to directed concepts. We only consider graphs without loops. Whenever we apply a concept that is defined on sets of vertices to an individual vertex, we mean the concept applied to the singleton set containing that vertex.\nA directed acyclic graph (DAG) is a graph without cycles. The (open) out-neighborhood of U in a graph G is N+G (U) := {v \u2208 V \\U : there is u \u2208U such that (u,v) \u2208 E}. A sink is a vertex with an empty out-neighborhood, sinksG denotes the sinks of G. reachG(v) denotes the set of all vertices u \u2208 V(G) such that there is a path from v to u in G, and reachG(U) :=\u22c3\nu\u2208U reachG(u). We use sequence and string synonymously and assume both to always be finite. \u201c\u00b7\u201d denotes concatenation, \u2aaf denotes the prefix relation, for s \u2aaf t, we call s a prefix of t and t an extension of s. \u03b5 denotes the empty sequences. For a sequence s, si denotes the i-th sequence item, with indexing startig at 1."
        },
        {
            "heading": "4 Prefix Authentication Schemes",
            "text": "We can now state what it means to authenticate a prefix relation.\nDefinition 1 (Prefix Authentication Scheme). A prefix authentication scheme (PAS) for sequences over some universe U is a triplet of algorithms digest, certify, and verify:\n\u2022 digest : U\u2217 \u2192{0,1}\u2217 maps any sequence s to some bitstring digest(s), the digest of s.\n\u2022 certify : U\u2217\u00d7U\u2217 \u21c0 {0,1}\u2217 maps any pair of sequences s \u2aaf t to some bitstring certify(s, t), the prefix certificate of s and t.\n\u2022 verify takes bitstrings ds, ds and p and two natural numbers lens and lent , and returns true if there exist sequences s \u2aaf t of length lens and lent respectively such that ds = digest(s), ds = digest(t), and p = certify(s, t). Furthermore, it must be computationally infeasible to find inputs for verify that result in true otherwise.\nFrom this definition, we can systematically derive the efficiency criteria by which to judge a PAS. Straightforward criteria are the time and space complexity of the three functions, as well as the sizes of digests and prefix certificates. Previous work often ignores some of these, especially when they are obvious in the context of that work. In comparing several different prefix authentication approaches from fully independent work, we consider it important to make all these basic criteria explicit.\nA less obvious pair of criteria derives from the question of which portions of their input the algorithms actually utilize. Both digest and certify receive full sequences as input. In practice however, we are interested in schemes that compute\nthem from only a sublinear amount of information about the sequence, say, in a peer-to-peer system where storing full sequences would impose prohibitive storage overhead.\nThe first such criterium asks which information is required to indefinitely keep appending items to a sequence and compute the digests of all these extensions. We require a function iterative_digest : I \u00d7U \u2192{0,1}\u2217\u00d7 I that maps information (of some type I) about a sequence s and a new item u to the digest of s \u00b7u and the information (again of type I) about s \u00b7u. Repeatedly calling this function allows computing the digest for any sequence. Besides the computational complexity of iterative_digest, we are interested in the size of the information for sequences of length n.\nFor prefix certificate computation, we wish to map any sequence to some (small) piece of information such that the prefix certificate for any two sequences can be computed from their two pieces of information. Again we are interested in the cost of these computations, and the size of the information depending on the length of the sequence. This generalizes the notion of a time certificate [8], which is the primary focus of the timestamping literature, whereas this criterium is rarely analyzed in the discussion of logs. We call the piece of information about each sequence its positional certificate."
        },
        {
            "heading": "5 A Class of Solutions",
            "text": "We now develop a family of prefix authentication schemes that generalizes over all hash-based secure timestamping and logging schemes that we are aware of.\nWhen some object contains a secure hash of another object, any change to the latter would invalidate the prior. A classic data structure to leverage this property is the Merkle tree [29], a rooted tree which labels leaves with a secure hash of their contained value, and which labels inner vertices with a secure hash of the concatenation of the child labels.\nWe generalize the idea behind Merkle trees to arbitrary DAGs. We label sinks via some function l : sinks(V ) \u2192 {0,1}k. For all non-sink vertices, we aggregate the labels of their out-neighbors via some hash function h. In order to deterministically apply h to sets (of out-neighbors of a vertex), we assume there is some arbitrary but fixed total order \u2264 on V , and define how to convert any vertex set U into a unique sequence seq(U) via seq( /0) := \u03b5, seq(U) := min\u2264(U) \u00b7 (U \\min\u2264(U)). We then define\nlabell,h(v) := { l(v) if v \u2208 sinks(V ), h(seq(N+G (v))) otherwise.\nFor binary out-trees, this yields exactly the Merkle tree construction. We call a pair (G = (V,E), labell,h) a Merkle DAG. If every maximal path from v intersects U , then labell,h(v) can be computed from the labels of the vertices in U ; we say that U label-determines v. If U label-determines every x \u2208 X ,\nwe say that U label-determines X . Given U and v such that U label-determines v, and some U-labeling p : U \u2192{0,1}k, we denote the expected label of v that can be computed from U and p by labelph(v). Observe that functions p are practically unique for any fixed labelph(v):\nProposition 1. Let (G = (V,E), labell,h) be a Merkle DAG, let v\u2208V , and U \u2286V such that U label-determines v. Then it is computationally infeasible to find a labeling p : U \u2192{0,1}k such that labelph(v) = labell,h(v) and p \u0338= labell,h|dom(p).\nProof. Assume it was feasible to find p \u0338= labell,h|dom(p) with labelph(v) = labell,h(v). Then there must have existed a vertex w with labelph(w) = labell,h(w) having an out-neighbor x with labelph(x) \u0338= labell,h(x). Hence two distinct inputs to h yielded the same hash, contradicting the collision resistance of h.\nOur prefix authentication schemes will use Merkle DAGs whose sinks we each label with a secure hash of a sequence item. We say a vertex set U is a commitment to a vertex set X if X \u2286 reach(U). Changing the label of any vertex in X changes the label of at least one vertex in U . The digests of our schemes will be the labels of singleton commitments to vertices labeled by hashes of sequence items.\nWe say a vertex set U is a tight commitment to a vertex set X if U is a commitment to X and X label-determines U .\nOur prefix certificates generalize the set membership proofs of classic Merkle trees. Merkle trees offer compact set membership proofs by reconstructing the label of the root vertex from the labels of the out-neighborhood of a path to a leaf. The out-neighborhood of a union of such paths certifies membership of several leaves at once. We can generalize this to arbitrary Merkle DAGs (see fig. 1 for an example):\nDefinition 2 (Subgraph Proof). Let (G = (V,E), labell,h) be a Merkle DAG, let U \u2286 V , and let v \u2208 V such that U \u2286 reachG(v). Let P be a family of paths starting in v such that U \u2286 N+G (P), and let p : N + G (P) \u2192 {0,1}k, where {0,1}k is the codomain of h. We then call (labell,h(v), p) a potential subgraph proof of U for v. Observe that N+G (P) label-determines v. We say (labelh(v), p) is a (verified) subgraph proof if label p h(v) = labell,h(v), and a refuted subgraph proof otherwise.\nProposition 2. Let (G = (V,E), labell,h) be a Merkle DAG, and let v \u2208 V . Then, by proposition 1, it is computationally infeasible to find U and p such that (labell,h(v), p) is a verified subgraph proof of U for v with p \u0338= labell,h|dom(p).\nCorollary 1. Let (G = (V,E), labell,h) be a Merkle DAG, let v \u2208V , let U \u2286V , and let (labell,h(v), p) be a subgraph proof of U for v. If h is secure, then N+G (dom(p)) is a subgraph of G. In particular, G[U ] is a subgraph of G, and U \u2286 reachG(v)."
        },
        {
            "heading": "5.1 Linking Schemes",
            "text": "We now have the terminology to define the linking schemes, a class of prefix authentication schemes based on Merkle DAGs. We use secure hashes of sequence items to label the sinks of some Merkle DAG in which the set of the sinks that correspond to any prefix of the sequence has a common ancestor vertex; the labels of the common ancestors serve as digests, and subgraph proofs between the digest vertices serve as prefix certificates.\nFirst, we formalize the notion of mapping sequence items to sinks:\nDefinition 3 (Sequence Graph). Let G be an acyclic graph with sinks(G)\u2287N, and let s be a sequence of length lens.\nThe sequence graph of s and G is the Merkle DAG (G, labells,h) with\nls(sv) := { h(v) if v \u2208N<lens , h(\u03b5) otherwise.\nNext, we can describe the class of graphs that allows for prefix authentication:\nDefinition 4 (Linking Scheme Graph). A graph G = (V,E) is a linking scheme graph if G is acyclic, sinks(G) \u2287 N, and there exist functions digest_vertex : N \u2192 V , and certificate_vertices : N\u00d7N \u2192 P (V ) such that for all lens, lent \u2208N with lens < lent :\n\u2022 digest_vertex(lens) is a tight commitment toN\u2264lens , and\n\u2022 certificate_vertices(lens, lent) is a path starting in digest_vertex(lent) such that digest_vertex(lens) \u2208 N+G (certificate_vertices(lens, lent)).\n1 2 3 4 5 6 7 8 9 10 11\np1 p2 p3 p4 p5 p6 p7 p8 p9 p10 p11\nFigure 2: An example linking scheme, together with a certificate for lens := 3 and lent := 7. p3 and p7 are the digest vertices for 3 and 7 respectively. The path (p7, p4) is a (shortest) path from p7 whose out-neighborhood contains p3, and its out-neighborhood yields the prefix certificate.\nUsing a linking scheme graph as the underlying graph of a Merkle DAG yields a prefix authentication scheme (fig. 2 gives an example):\nDefinition 5 (Linking Scheme). Let G = (V,E) be a linking scheme graph, and let h be a secure hash function.\nG and h define a linking scheme (digest,commit,certify) using the following functions:\nFor strings s of length lens, let (G, labells,h) be the sequence graph of s and G. We then define digest(s) := labells,h(digest_vertex(lens)). Observe that this can be computed from s alone as N\u2264lens label-determines digest_vertex(lens).\nFor strings s \u2aaf t of length lens and lent respectively, let (G, labellt ,h) be the sequence graph of t and G. We then define certify(s, t) as the bitstring obtained by sorting N+G (certificate_vertices(lens, lent)) according to \u2264 and concatenating the labels (in (G, labellt ,h)) of these vertices. Finally, we define verify(ds,dt , p, lens, lent) to first parse p into a labeling p\u2032 of N+G (certificate_vertices(lens, lent)) and then return whether (dt , p\u2032) is a verified subgraph proof of digest_vertex(lens) for digest_vertex(lent).\nProposition 3. Every linking scheme is a prefix authentication scheme.\nProof. All functions have the required signatures. Let s \u2aaf t be sequences of length lens and lent respectively, then verify(digest(s),digest(t),certify(s, t), lens, lent) returns true by construction; and returning true for these inputs implies s \u2aaf t by corollary 1. Any other inputs that yield true witness a hash collision by proposition 2.\nThis definition of linking schemes is adapted from Buldas et al. [8] and captures the linear linking scheme [17], antimonotone schemes [7] [5], and the threaded authentication trees [8]. This class of schemes does not however include Crosby and Wallach\u2019s secure logging scheme [11], transparency logs [20], or hypercore [33], prompting our search for a further generalization."
        },
        {
            "heading": "5.2 Transitive Prefix Authentication Schemes",
            "text": "The generalization to include these other schemes is simple2: rather than giving subgraph proofs that some digest vertex is reachable from another, we give subgraph proofs that some set that label-determines a digest vertex is reachable from another digest vertex.\nDefinition 6 (Transitive Prefix Authentication Graph). A graph G = (V,E) is a transitive prefix authentication graph (TPAG) if G is acyclic, sinks(G) \u2287 N, and there exist functions digest_vertex : N \u2192 V , commit : N \u2192 P (V ), and certificate_vertices : N\u00d7N \u2192 P (V ) such that for all lens, lent \u2208N with lens < lent :\n\u2022 digest_vertex(lens) is a tight commitment toN\u2264lens ,\n\u2022 commit(lens) label-determines digest_vertex(lens), and\n\u2022 certificate_vertices(lens, lent) is a union of paths, each starting in digest_vertex(lent), such that commit(lens)\u2286 N+G (certificate_vertices(lens, lent)).\nUsing a TPAG as the underlying graph of a Merkle DAG yields a prefix authentication scheme (fig. 3 gives an example). Because the definition is similar to that of linking schemes, we have typeset the differences in a bold font.\nDefinition 7 (Transitive Prefix Authentication Scheme). Let G = (V,E) be a TPAG, and let h be a secure hash function.\nG and h define a transitive prefix authentication scheme (TPAS) (digest,commit,certify) using the following functions:\nFor strings s of length lens, let (G, labells,h) be the sequence graph of s and G. We then define digest(s) := labells,h(digest_vertex(lens)). Observe that this can be computed from s alone as N\u2264lens label-determines digest_vertex(lens).\nFor strings s \u2aaf t of length lens and lent respectively, let (G, labellt ,h) be the sequence graph of t and G. We then define certify(s, t) as the bitstring obtained by sorting N+G (certificate_vertices(lens, lent)) according to \u2264 and concatenating the labels (in (G, labellt ,h)) of these vertices. Finally, we define verify(ds,dt , p, lens, lent) to first parse p into a labeling p\u2032 of N+G (certificate_vertices(lens, lent)) and then return whether (dt , p\u2032) is a verified subgraph proof of digest_vertex(lens) for digest_vertex(lent) and whether labelp \u2032\nh (digest_vertex(lens)) = ds.\nProposition 4. Every TPAS is a prefix authentication scheme.\nProof. All functions have the required signatures. Let s \u2aaf t be sequences of length lens and lent respectively, then verify(digest(s),digest(t),certify(s, t), lens, lent)\n2Simple, that is, when starting from a characterization of linking schemes that was specifically crafted to allow for this generalization.\n1 2 3 4 5 6 7 8 9 10\np1 p2 p3 p4 p5 p6 p7 p8 p9 p10\nq2 q4 q6 q8 q10\nFigure 3: A TPAS, together with a certificate for lens := 4 and lent := 7. q4 and p7 are the digest vertices for 4 and 7 respectively. The path (p7, p5) is a (family of exactly one) path from p7 whose out-neighborhood contains p3 and p4, who together label-determine q4. Its out-neighborhood yields the prefix certificate.\nreturns true by construction; and returning true for these inputs implies s \u2aaf t by corollary 1. Any other inputs that yield true witness a hash collision by proposition 2 (when verifying the subgraph proof) or by proposition 1 (when checking that labelp \u2032\nh (digest_vertex(lens)) = ds)."
        },
        {
            "heading": "5.3 Efficiency Criteria",
            "text": "Because every TPAS stems from a TPAG, we can reason about prefix authentication schemes while remaining solely in the realm of unlabeled digraphs; the labelings are a deterministic afterthought. Given the length k of each individual hash, we can also reason about the complexity criteria of section 4 by solely considering graph properties.\nSince digests are labels of individual vertices, the digest size of any sequence is k.\nWorst-case and average prefix certificate sizes correspond directly to the sizes of the out-neighborhood of certificate_vertices(lens, lent): the prefix certificate is labell,h|N+G (certificate_vertices(lens,lent )), which can be encoded by fixing an ordering on V(G) in advance and simply listing the labels of N+G (certificate_vertices(lens, lent)) according to that ordering. The space requirement is hence |N+G (certificate_vertices(lens, lent))| \u2217 k.\nComputing verify consists of reconstructing digest(lens) from commit(lens) and digest(lent) from certify(lens, lent). Reconstructing digest(lens) from commit(lens) requires time proportional to the number of distinct edges on all paths from digest(lens) to any vertices from commit(lens). Reconstructing digest(lent) from certify(lens, lent) requires time proportional to the number of edges in the graph induced by the closed neighborhood of certificate_vertices(lens, lent).\nThe complexity of computing digest(lens) and certify(lens, lent) is less straightforward. Because digest_vertex(lens) is a common ancestor of all i \u2264 lens, computing its label requires at least O(lens) time. In a\nrealistic setting, one would instead precompute and store the labels of all all digest vertices, turning the computation into a simple look-up. The additional storage cost of O(lens) space does not exceed the cost for storing lens sequence items in the first place. But when also precomputing the labels for all vertices that can appear in any prefix certificate, the overall space complexity might exceed O(lens).\nWe simplify the analysis by looking at the storage cost for precomputing the labels of all vertices. Intuitively, we expect efficient schemes to not have redundant vertices, so this simplification should only be an overapproximation for schemes that are of little practical interest to begin with.\nIn order to classify the storage cost per sequence item, we define the graph G[lens] := \u22c3 i\u2264lens reach(digest_vertex(i)) of all vertices that are required to work with a sequence of length lens. The number of labels that need to be precomputed and stored because of the lens-th sequence item is then given by |V(G[lens])\\V(G[lens \u22121])|. We are both interested in the worst-case for any lens and in the amortized case of averaging over the first lens sequence items.\nFor iterative computation of digests, we require a function digest_pool : N\u2192 V(G) such that digest_pool(lens \u2212 1)\u222a {lens} label-determines both digest(lens) and all vertices in digest_pool(lens). Intuitively, the digest pool for some lens consists of all the vertices in G[lens] whose label impacts the label of any future vertex, i.e., every vertice in N+(G[lent ]\u2212G[lens])\u2229G[lens] for any lent > lens. The labels of digest_pool(lens) then allow for indefinitely appending new items to a sequence of length lens by adding any newly created vertices whose labels will be used in the future; we are interested in functions that minimize |digest_pool(lens)|.\nFor computing prefix certificates from only parts of full sequences, we consider functions certificate_pool : N \u2192 V(G) such that N+G (certificate_pool(lens)) \u222a N + G (certificate_pool(lent)) label-determines N+G (certificate_vertices(lens, lent)). This allows for computing certify(lens, lent) from the (out-neighborhoods of the) certificate pools of lens and lent . We are then interested in functions that minimize |N+G (certificate_pool(lens))|."
        },
        {
            "heading": "5.4 Secure Timestamping",
            "text": "Secure timestamping [17] asks to cryptographically certify the happened-before relation on some totally-ordered set of events. Prefix authentication does not immediately imply secure timestamping, but the problems are related: if event number s happened before event number t, we can certify that the sequence of the first s events is a prefix of the sequence of the first t events. This only relates the digests of the event sequences however, not the events themselves.\nWe can extend every TPAS to provide time stamping. We define the identifier of the i\u2212 th item in some sequence as a\n(deterministically selected) subgraph proof of its vertex for digest_vertex(i). We call it an identifier because it identifies a particular item as occuring at a particular position in a particular sequence (and its extensions).\nLet s be the sequence of the first lens events, and let t be the sequence of the first lent events, with s \u2aaf t. To certify that event number lens happened before event number lent , simply provide certify(s, t) together with the identifiers of lens and lent . certify(s, t) certifies the happened-before relation of the digests, and the identifiers tie the digests to the actual items. Verification consists of verifying the certificate as well as the two identifiers.\nHence, the worst-case and average size of the identifier for any item at position n becomes another complexity parameter of interest. Its exact value is k (the size of an individual digest) times the number of vertices in the subgraph proof of {i} for digest_vertex(i)."
        },
        {
            "heading": "6 Prior Schemes",
            "text": "We now give definitions of timestamping and logging schemes from the literature, expressed as TPASs. This serves as a demonstration of the generality and applicability of TPASs, it provides a survey of existing approaches, and it allows us to apply our efficiency criteria to previous work.\nOur definition of Merkle DAGs automatically incorporates the notion of computing the labels along a path from a prefix certificate rather than directly using those labels as the certificate, an optimization introduced by Buldas, Lipmaa, and Schoenmakers. [8] after several prior schemes had already been published. The improvement that their section 5.2 gives over the antimonotone linking schemes [7] [5] is inherent to our formulations of all approaches.\nOur presentation of timestamping schemes differs significantly from their original presentation in that we do not consider a setting of timestamping rounds. Working with timestamping rounds effectively amounts to solving prefix authentication for strings of bounded length. Once the maximal string length is reached, the round concludes and a new round begins for the next subsequence of bounded length.\nFor authentication across rounds, the rounds must themselves be maintained in a prefix-authenticating data structure. This requires an awkward nesting of prefix authentication schemes that is overall less efficient than authenticating the full string without subdividing it into rounds.\nPrefix authentication for strings of bounded length is an easier problem than prefix authentication for strings of arbitrary length. Hence, we need to adapt the timestamping schemes to the more general setting, and this adaptation results in worse positional certificate sizes than the original publications report. The original publications do not account for the cost of inter-round authentication, which is why we do our own complexity analyses and arrive at worse bounds.\nThis adaptation also means that the proofs of optimality in the timestamping literature do not apply to our setting. While we believe our adaptations are faithful, more efficient solutions for round-less authentication can exist."
        },
        {
            "heading": "6.1 Trivial Schemes",
            "text": "The simplemost linking scheme is the linear scheme of [17]. Its underlying graph is a \u201cMerkle linked-list\u201d Glin:\nVlin := {pn : n \u2208N}\u222aN, Elin := {(pn+1, pn) : n \u2208N}\u222a{(pn,n) : n \u2208N}, Glin := (Vlin,Elin).\nTo use this graph as a linking scheme, define digest_vertex(n) := pn, and define certificate_vertices(lens, lent) as the shortest path from digest_vertex(lent) to digest_vertex(lens) (see fig. 4 for a depiction). We use the same definitions of digest_vertex and certificate_vertices for all linking schemes in this section, unless specified otherwise.\nPrefix certificates are of linear size in lent \u2212 lens. Certificate pools are of linear size in lens, as they must contain the full path from digest_vertex(lens) to digest_vertex(1): certificate_pool(lens) := Glin[lens]. On the plus side, digest pools are of constant size, with digest_pool(lens) := digest_vertex(lens).\nThe full linking scheme is the other trivial scheme, with an edge from p j to pi for all i < j; the quadratic number of edges makes it unsuitable for any practical use."
        },
        {
            "heading": "6.2 Skip List Schemes",
            "text": "A simple but suboptimal way of interpolating between the two trivial schemes is to use a (contracted) deterministic skip list [35]. In addition to the edges of Glin, also add an edge from pn to pn\u2212k if n is divisible by k. The certificate pool of n is the out-neighborhood of the shortest path from 2\u2308log2(n)\u2309 to n and from n to 1. The digest pool is the out-neighborhood of the shortest path from n to 1. Figure 5 visualizes the construction.\nThis scheme is used by CHAINIAC [31], but it has prefix certificates of superlogarithmic size. Consider the vertex n := 2k. It has k out-neighbors, all of which must occur in certificate_vertices(1,2k). The second vertex of the shortest\n1 2 3 4 5 6 7 8 9 10\np1 p2 p3 p4 p5 p6 p7 p8 p9 p10 p12 p16\nFigure 5: The CHAINIAC scheme, highlighting certificate_pool(5) and its out-neighborhood.\npath from 2k to 1 is 2k\u22121, whose out-neighborhood contains k\u22121 vertices. Iterating this argument yields a certificate size of \u03a3i\u2264ki \u2208 O(k2) = O(log(n)2). While certificate pools have logarithmic size, their out-neighborhoods do not.\nBlibech and Gabillon [4] also propose a scheme based on skip lists, but their construction relies on the notion of timestamping rounds: unlike the timestamping schemes we generalize next, their scheme gives dedicated treatment to the last vertex of each timestamping round, and it can only provide prefix certificates for items whose timestamping rounds have been concluded. Hence, it is not a prefix authentication scheme according to our definition, as it is not applicable to authenticating sequences of unbounded length."
        },
        {
            "heading": "6.3 Antimonotone Binary Schemes",
            "text": "The simple antimonotone binary linking scheme [7] achieves logarithmic certificate pools by augmenting the linear scheme with only one additional outgoing edge per vertex. The additional edge for vertex pn goes to p f2(n), with f2(n) defined as follows:\nf2(n) := { n\u2212 (2k\u22121 +1) if n = 2k \u22121,k \u2208N n\u22122g(n) otherwise\ng(n) := { k if n = 2k \u22121,k \u2208N g(n\u2212 (2k\u22121 \u22121)) if 2k\u22121 \u22121 < n < 2k \u22121,k \u2208N.\nObserve that for all n < m we have that f2(n) \u2265 f2(m), hence the antimonotone in the name.\nWe denote the resulting graph as Gls2 := (Vlin,Elin \u222a {(pn, p f2(n)) : n \u2208 N\n\u22652}), fig. 6 shows an excerpt. For any n, we say it belongs to generation \u230alog2(n)\u230b. We say p2t+1\u22121 is the vertebra of generation t, and \u22c3 k\u2264t{p2k+1\u22121} is the spine of generation t. Let n a number of generation t. Then, the union of the shortest paths from the vertebra of t to pn, from pn to the vertebra of t \u22121, and from that vertebra to p1 (the latter two paths together form the shortest path from pn to p1) is a certificate pool for n [7]. We proceed with a proof sketch for the size of the corresponding positional certificates.\np1\n1\np2\n2\np3\n3 p4\n4\np5\n5\np6\n6\np7\n7\np8\n8\np9\n9\np10\n10 p11\n11\np12\n12\np13\n13\np14\n14\np15\n15\np16\n16\np17\n17\np18\n18 p19\n19\np20\n20\np21\n21\np22\n22\np23\n23\np24\n24\np25\n25 p26\n26\np27\n27\np28\n28\np29\n29\np30\n30\np31\n31\nFigure 6: The simple antimonotone binary linking scheme, highlighting certificate_pool(9), which consists of the paths from the next vertebra to p9, from p9 to the previous vertebra, and from the previous vertebra to p1.\nObserve the recursive structure of Gls2: the graph of the first t+1 generations consist of two copies of the graph of the first t generations \u2014 with the outgoing edges of the spine of the copy being replaced with edges to the (original) vertebra of generation t \u2014 and a new vertebra p2(t+1)+1\u22121. This recursive structure enables convenient inductive reasoning based on the generation of a vertex.\nFurther observe that every vertex is either a vertebra vertex for some generation t, or a (transitive) copy of a vertebra vertex for some generation t. In both cases, we say that the vertex is of order t.\nFor n of generation t, the shortest path from the vertebra of t to the vertebra of t \u2212 1 via pn is of maximal size if pn is of order 0. The path consists of vertices of decrementing order from the vertebra of t to pn, followed by vertices of incrementing order up to the vertebra of t \u22121. Consequently, all order 0 vertices of the same generation yield certficate pools of the same size: 2t \u22121. A proper proof would perform induction on t: removing the vertebrae of t and t \u22121 from the path yields a path isomorphic to that of n\u22122t \u22121, which is of generation t \u22121.\nThe out-neighborhood of this path has at least the same size, because every pn has an edge to n. More tricky are the edges to other pm; we need to count the number of such edges that lead outside the path. The edges corresponding to f2 never do so, this would immediately contradict antimonotonicity. It remains to consider the edges of the form (pn, pn\u22121).\nFor vertices of generation at most 2, all these edges are part of the path. For vertices of any other generation t +1, there are t \u22122 such edges leading outside the path, as can be seen inductively: if the successor of vertex p2t\u22123 on the path is not its numeric predecessor, the number of predecessor edges outside the path increases by one compared to the path for the previous generation. If the successor of vertex p2t\u22123 on the path is its numeric predecessor, then p f2(2t\u22123) is part of the path but its predecessor is not, again contributing exactly one additional edge to a path of the previous generation (see\nfig. 7). For the full positional certificate of n of generation t, it remains to add the size of the out-neighborhood of the shortest path from the vertebra of t \u2212 1 to p1. This path has t vertices, each contributing two vertices to the out-neighborhood (pm\u22121 and m), except for p1, which has only a single outneighbor. Adding everything up (and accounting for the double-counting of pt\u22121) yields the positional certificate size of (5 \u00b7 \u230alog2(n)\u230b\u22123) \u00b7 k, where k is the size of an individual hash.\nThe shortest path from pn to p1 is of logarithmic size and it can serve as a digest pool (in fact, antimonotonicity implies that this shortest path is a digest pool for every antimonotone scheme). The observation that the graph has no edge which jumps over any vertebra can be used to further shrink the digest pool to the shortest path from pn to the vertebra of the previous generation.\nThe optimal antimonotone binary linking scheme [5] extends the linear scheme with a slightly different, antimonotone function f3(n), to obtain the graph Gls3 := (Vlin,Elin \u222a {(pn, p(n)) : n \u2208 N\u22652}) (fig. 8):\nf3(n) := { n\u2212 (3k\u22121 +1) if n = 3k\u221212 ,k \u2208N n\u2212 ( 3h(n)\u221212 +1) otherwise\nh(n) :=\n{ k if n = 3\nk\u22121 2 ,k \u2208N\nh(n\u2212 3k\u22121\u221212 ) if 3k\u22121\u22121 2 < n < 3k\u22121 2 ,k \u2208N\nCertificate pools (and their analysis) take the same shape as those of the simple antimonotone scheme, but with different generations and vertebra: the generation of n in the optimal scheme is \u230alog3(2n)\u230b, the vertebra of generation t is 3 t+1\u22121 2 .\nFor n of generation t, inductive arguments analogous to to those of the simple antimonotone scheme yield a maximal size of 3t + 1 for the path from the vertebra of t to the vertebra of t \u2212 1 via pn, and 2t \u2212 3 additional vertices for the outneighborhood. The shortest path from the vertebra of t \u2212 1 to p1 contributes another 2t \u2212 1 vertices to the positional certificate, yielding the total size of (7 \u00b7 \u230alog3(2n)\u230b\u2212 4) \u00b7 k (again accounting for the double-counting of pt\u22121). This is more efficient than the simple antimonotone scheme; for all n \u2265 128 we have (7 \u00b7 \u230alog3(2n)\u230b\u22124) \u00b7k < (5 \u00b7 \u230alog2(n)\u230b\u22123) \u00b7 k.\nThe shortest path from pn to the vertebra of the previous generation can again serve as a digest pool. In the optimal antimonotone scheme, this path contains redundancies however. For example, consider p24 in fig. 8: none of the labels of p23, p22, or p17 are directly involved in the computation of the label of any greater vertex. For the digest pool of n, it suffices to take the pm with maximal m of each order (with m \u2264 n and for a maximal order of the generation of n).\nWe would like to point the interested reader to the elegant characterization of all antimonotone binary graphs [5] that forms the basis of the optimality proof for the optimal antimonotone scheme amongst all antimonotone binary schemes in the setting of prefix authentication for strings of bounded length. All antimonotone binary graphs can be constructed from a graph product operation \u2297, starting from the trivial graph G1. The antimotone product is an efficient way of thinking about the antimonotone schemes; the rather intimidating functions of natural numbers to describe the two schemes we presented turn into neat, immediately related one-liners: Gi+1simple := G i simple\u2297Gisimple\u2297G1 and Gi+1opt := Giopt \u2297Giopt \u2297Giopt \u2297G1."
        },
        {
            "heading": "6.4 Merkle Trees",
            "text": "Whereas the schemes we considered so far are extensions of Glin, the remaining schemes utilize Merkle trees. To unify their presentation, we first define the infinite Merkle tree Gtree on which they build (fig. 9) in isolation:\nVtree := { (n,k) : n \u2208N,k \u2208N0 and 2k | n } ,\nEtree := {( (n0,k+1),(n1,k) ) : n0 = n1 or n0 = n1 +2k }\n\u222a {( (i,0), i ) : i \u2208N } ,\nGtree := (Vtree,Etree).\nWe can unify parts of the complexity analysis of the remaining schemes by analyzing Gtree. We first define the forest that corresponds to the first n numbers: Gtree[n] := Gtree[Vtree\u2264n \u222a {(i,k) : i \u2264 n}]. Gtree[n] has at most 3n vertices for every n, but Gtree[n]\u2212Gtree[n\u22121] can have up to \u2308log2(n)\u2309 vertices. Unlike the schemes we have seen so far, all schemes based on Gtree thus require a non-constant amount of information for a single sequence item in the worst case.\nWe further define next_root(n) := (2\u2308log2(n)\u2309,\u2308log2(n)\u2309), the root of the smallest complete subtree to contain both 1 and n, and next_power(n) := (2\u2308log2(n)\u2309,0).\nThe complexity analysis of several schemes depends on the number of roots in Gtree[n]. Observe that the number of leaves of every tree in Gtree[n] is a power of two, and observe further that the trees in Gtree[n] all have different, strictly decreasing sizes. Every power of two less than n occurs either once or not at all. In other words, the trees of Gtree[n] correspond directly to the binary representation of n."
        },
        {
            "heading": "6.5 Threaded Authentication Trees",
            "text": "We now turn to the first construction to use Merkle trees, the threaded authentication trees [8]. Threaded authentication trees start from Gtree and then add edges from every (n,0) to the roots of the trees of Gtree[n], yielding a linking scheme\np31\np31\np67\n67\np121\n121\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n(1, 0) (2, 0) (3, 0) (4, 0) (5, 0) (6, 0) (7, 0) (8, 0) (9, 0) (10, 0) (11, 0) (12, 0) (13, 0) (14, 0) (15, 0) (16, 0)\n(2, 1) (4, 1) (6, 1) (8, 1) (10, 1) (12, 1) (14, 1) (16, 1)\n(4, 2) (8, 2) (12, 2) (16, 2)\n(8, 3) (16, 3)\n(16, 4)\nFigure 9: The start of the infinite Merkle tree Gtree.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n(1, 0) (2, 0) (3, 0) (4, 0) (5, 0) (6, 0) (7, 0) (8, 0) (9, 0) (10, 0) (11, 0) (12, 0) (13, 0) (14, 0) (15, 0) (16, 0)\n(2, 1) (4, 1) (6, 1) (8, 1) (10, 1) (12, 1) (14, 1) (16, 1)\n(4, 2) (8, 2) (12, 2) (16, 2)\n(8, 3) (16, 3)\n(16, 4)\nFigure 10: A threaded authentication tree, highlighting certificate_pool(6), which consists of the paths from next_root(6) to (6,0) and from next_root(6) to (1,0), and its out-neighborhood.\nwith digest_vertex(n) := (n,0). The certificate pool of n is the union of the shortest path from next_root(n) to (n,0) and the shortest path from next_root(n) to (1,0). See fig. 10 for an example.\nThis definition of certificate pools yields positional certificates of size 2 \u00b7 \u2308log2(n)\u2309 \u00b7 k, where k is the size of a single hash. This is almost twice as much as in the setting\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n(1, 0) (2, 0) (3, 0) (4, 0) (5, 0) (6, 0) (7, 0) (8, 0) (9, 0) (10, 0) (11, 0) (12, 0) (13, 0) (14, 0) (15, 0) (16, 0)\n(2, 1) (4, 1) (6, 1) (8, 1) (10, 1) (12, 1) (14, 1) (16, 1)\n(4, 2) (8, 2) (12, 2) (16, 2)\n(8, 3) (16, 3)\n(16, 4)\nd3\nd5 d6 d7\nd9 d10 d11 d12 d13 d14 d15\nFigure 11: A hypercore, highlighting certificate_pool(6), which consists of the paths from next_root(6) to (6,0) and from next_root(6) to (1,0), and its out-neighborhood.\nwith rounds of known size, but it still outperforms the antimonotone schemes and is optimal among all schemes we survey. But unlike the antimonotone schemes, the underlying graph is of super-linear size, Gtat [n] has O(n log(n)) edges in the worst case:\nAssume that n = 2k. Remember that (i,0) has an outgoing edge for every 1 in the binary representation of i. The numbers from 2k\u22121 to 2k (exclusively) are exactly the n2 k-bit numbers. The total number of 1 bits amongst them \u2014 that is, the number of outgoing edges of the vertices ( n2 ,0),( n 2 +1,0), \u00b7 \u00b7 \u00b7 ,(n\u2212 1,0) \u2014 is n2 \u00b7 k 2 \u2208 O(n \u00b7 k) = O(n log(n)).\nAs a consequence, checking a prefix certificate for two sequences of lengths lenn < lent can take time in O(log(lent) \u00b7 log(log(lent))), despite the size of the certificate being in O(log(lent)). This is asymptotically slower than checking certificates for antimonotone schemes. The original presentation of threaded authentication trees focuses on certificate size only and does not mention this flaw.\nAs the outgoing edges of any vertex (n,h) go to a root of a tree in Gtree[n], these roots give a digest pool for n. Since these roots correspond to binary digits, the size of the digest pool of n is at most log2(n)."
        },
        {
            "heading": "6.6 Hypercore",
            "text": "Whereas threaded authentication trees turn Gtree into a linking scheme, we now turn to approaches that turn Gtree into more general TPASs. All these approaches share the insight that when Gtree[n] has a single root, that root can serve as a digest vertex for a sequence of n items. But Gtree has no possible digest vertices for sequences of any other length.\nHypercore [33] takes a direct approach to augmenting Gtree so that there is a digest vertex for every n. For every n that is not a power of two, add a vertex dn with an outgoing edge to every root of Gtree[n] to obtain Ghyper (fig. 11).\nThen define digest_vertex(n) as dn, or the root of Gtree[n] if\nn is a power of two. commit(n) is then simply the set of roots of Ghyper[n], a set which label-determines digest_vertex(n) by construction. Using these definitions of digest_vertex and commit leaves exactly one valid choice for defining certificate_vertices(lens, lent): the unique family of paths that start in digest_vertex(lent) and end \u201cjust before\u201d commit(lent).\nThe certificate pool of n consists of the union of the path from next_root(n) to (n,0) and the path from next_root(n) to (1,0), just like with threaded authentication trees. Despite the different underlying graphs, the out-neighborhoods (and hence the sizes of positional certificates) are identical for threaded authentication trees and hypercores.\nTo see why the two paths yield valid certificate pools for hypercores, first observe that the out-neighborhood of the path from digest_vertex(n) to (n,0) is a subset of the outneighborhood of the path from next_root(n) to (n,0).\nNow consider any two numbers lens < lent . If next_root(lens) \u0338= next_root(lent), then the path from next_root(lent) to (1,0) contains next_root(lens). And the out-neighborhood of the path from next_root(lens) to (lens,0) contains commit(lens), so together they contain certificate_vertices(lens, lent).\nIn the other case of next_root(lens) = next_root(lent), both lens and lent lie in the complete subtree that contains the leaves 2\u2308log2(lens)\u2309\u22121 + 1 to 2\u2308log2(lens)\u2309. This tree is isomorphic to the tree with the first 2\u2308log2(lens)\u2309\u22121 leaves, so certificate_pool(lens, lent) is a valid certificate pool exactly if certificate_pool(lens \u22122\u2308log2(lens)\u2309\u22121, lent \u22122\u2308log2(lens)\u2309\u22121) is a valid certificate pool. Hence, validity follows by induction \u2014 the base case is lens = 1 and lent = 2, for which the union of the certificate paths does contain certificate_vertices(1,2).\nThe roots of Ghyper[n] are a digest pool for n; The labels of the roots of Ghyper[n+1] can be computed from the labels of the roots of Ghyper[n] together with sequence item n+1.\nLike threaded authentication trees, hypercores are of superlinear size: Ghyper[n] has O(n \u00b7 log(n)) edges. But the number of edges within a prefix certificate is linear in the size of the certificate, so certificate validation lies in O(log(n)).\nStill, the super-linear size means that creating a sequence of length n step-by-step takes O(n log(n)) time, whereas the antimonotone schemes only need O(n) time. Furthermore, hypercores have identifiers of up to logarithmic size, unlike the constant-sized identifiers of antimonotone schemes or threaded authentication trees."
        },
        {
            "heading": "6.7 Transparency Logs",
            "text": "The transparency log construction [20] creates digest vertices for every n by iteratively adding a parent vertex to the roots of the two smallest trees in Gtree[n] until there is a single root (fig. 12). This root then serves as the digest of n.\nNotice that contracting the newly created vertices for the same n yields exactly the underlying graph of the hypercore\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n(1, 0) (2, 0) (3, 0) (4, 0) (5, 0) (6, 0) (7, 0) (8, 0) (9, 0) (10, 0) (11, 0) (12, 0) (13, 0) (14, 0) (15, 0) (16, 0)\n(2, 1) (4, 1) (6, 1) (8, 1) (10, 1) (12, 1) (14, 1) (16, 1)\n(4, 2) (8, 2) (12, 2) (16, 2)\n(8, 3) (16, 3)\n(16, 4)\n(3, 1)\n(5, 2) (6, 2)\n(7, 1)\n(7, 2) (9, 1) (10, 1)\n(11, 1) (12, 1) (13, 1) (14, 1)\n(15, 1)\nFigure 12: A certificate transparency log, highlighting certificate_pool(6), which consists of the paths from next_root(6) to (6,0) and from next_root(6) to (1,0), and its out-neighborhood.\nscheme. The certificate transparency scheme is ultimately a deterministic (but essentially arbitrary) way of subdividing the digest vertices of hypercore until every vertex has at most two outgoing edges. Consequently, commit(n) is identical to that of hypercore, and certificate_vertices(lens, lent) is again the unique family of paths that start in digest_vertex(lent) and end \u201cjust before\u201d commit(lent).\nUnlike hypercore, vertices in the certificate transparency scheme have a constant-bounded out-degree (two). The price is a super-linear number of vertices and the hashing of twice as many bits during certificate validation as hypercore. Otherwise, the same complexity analyses apply to both schemes.\nIn the context of certificate transparency, we want to point out that identifier sizes can matter outside timestamping. After submitting an entry to a certificate transparency log, the log operator replies3 with the new signed tree head (digest in our terminology) and an inclusion proof (an identifier in our terminology). Using a scheme with constant-sized identifiers would be an asymptotic improvement over the certificate transparency scheme for this operation.\nFive years prior to the publication of the certificate transparency scheme, Crosby and Wallach [11] presented a highly similar scheme: whereas certificate transparency creates the smallest possible binary trees that contain all trees of Gtree[n], Crosby and Wallach\u2019s scheme also ensures that the vertices corresponding to sequence items all have the same height in the tree.\nThis makes the resulting graphs slightly larger supergraphs of the certificate transparency graphs, without any actual advantages. In hindsight, we can hence recommend to disregard Crosby and Wallach\u2019s scheme, while still appreciating that theirs is the first published non-linking scheme to solve prefix authentication.\n3Setting aside CT-specific optimization details such as deliberate merge delays."
        },
        {
            "heading": "6.8 Summary",
            "text": "Prior presentation of all the schemes we surveyed has focused exclusively on prefix or positional certificate sizes. From this limited perspective, threaded authentication trees, hypercores and certificate transparency logs are equivalent, and antimonotone schemes are inferior.\nThe picture drastically changes when taking into account the other complexity metrics of prefix authentication schemes. All three schemes with minimal certificates have a superlinear total size. Threaded authentication trees have smaller identifiers than hypercore and transparency logs, but suffer from super-logarithmic verification times. The scheme of Blibech and Gabillon [4] does achieve the same certificate sizes with a linearly-sized underlying graph, but it does not generalize to the setting of unbounded sequence lengths.\nTable 1 summarizes the results of our complexity analyses of the presented schemes."
        },
        {
            "heading": "7 Conclusion",
            "text": "Generalizing from secure time stamping and logging to prefix authentication has allowed us to transfer knowledge between results that have not been connected so far. The class of transitive prefix authentication schemes serves as a tool to compactly and efficiently present and analyze prior results. The nuanced analysis shows that no existing approach is strictly superior to any other. We hope that future system designs will take into account all complexity criteria of prefix authentication schemes rather than latching on the first scheme with sub-linear prefix certificates that they lay eyes upon.\nThe main questions we leave open are questions of optimality. While threaded authentication trees have provably minimal positional certificates amongst linking schemes in a timestamping setting with rounds of known length, we did not transfer the optimality result to the setting of prefix authentication without rounds. Similarly, we do not know whether the optimal antimonotone scheme for rounds of bounded length remains optimal amongst antimonotone schemes for prefix authentication without rounds.\nAnother open question is whether the optimal positional certificate sizes amongst linking schemes are optimal amongst all transitive prefix authentication schemes.\nOur complexity analyses further surface a natural design challenge: that of finding a transitive prefix authentication scheme that achieves positional certificates of size 2 \u00b7 \u2308log2(n)\u2309 \u00b7 k while having an underlying graph of linear size. Such a scheme would strictly outperform threaded authentication trees, hypercore, and certificate transparency logs.\nFinally, we would like to emphasize again some of the limitations of prefix authentication schemes. First, the byzanthine fault-tolerant distributed \u201cappend-only log\u201d does not exist, as reacting to forks adds more expressivity to the abstract data type than just an append-operation. And second, \u201cproac-\ntive\u201d fork detection by placing logs onto a blockchain only shifts the problem to that of detecting forks in the blockchain, which might remain undetected for just as long as forks in a log when dealing with an equally powerful adversary (as it is literally the exact same problem).\nThe universe is cold and dark when it comes to distributed systems, but pretending otherwise always does more harm than good."
        }
    ],
    "title": "SoK: Authenticated Prefix Relations \u2014 A Unified Perspective On Relative Time-Stamping and Append-Only Logs",
    "year": 2023
}