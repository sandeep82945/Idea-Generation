{
    "abstractText": "Human or time resources can sometimes fall short in medical image diagnostics, and analyzing images in full detail can be a challenging task. With recent advances in artificial intelligence, an increasing number of systems have been developed to assist clinicians in their work. In this study, the objective was to train a model that can distinguish between various fracture types on different levels of hierarchical taxonomy and detect them on 2D-image representations of volumetric postmortem computed tomography (PMCT) data. We used a deep learning model based on the ResNet50 architecture that was pretrained on ImageNet data, and we used transfer learning to fine-tune it to our specific task. We trained our model to distinguish between \u201cdisplaced,\u201d \u201cnondisplaced,\u201d \u201cad latus,\u201d \u201cad longitudinem cum contractione,\u201d and \u201cad longitudinem cum distractione\u201d fractures. Radiographs with no fractures were correctly predicted in 95\u201399% of cases. Nondisplaced fractures were correctly predicted in 80\u201386% of cases. Displaced fractures of the \u201cad latus\u201d type were correctly predicted in 17\u201318% of cases. The other two displaced types of fractures, \u201cad longitudinem cum contractione\u201d and \u201cad longitudinem cum distractione,\u201d were correctly predicted in 70\u201375% and 64\u201375% of cases, respectively. The model achieved the best performance when the level of hierarchical taxonomy was high, while it had more difficulties when the level of hierarchical taxonomy was lower. Overall, deep learning techniques constitute a reliable solution for forensic pathologists and medical practitioners seeking to reduce workload.",
    "authors": [],
    "id": "SP:b8bc23252c6f08ab7f544ee90c35184d3860782e",
    "references": [
        {
            "authors": [
                "Ziegler DW",
                "Agarwal NN"
            ],
            "title": "The morbidity and mortality of rib fractures",
            "venue": "J Trauma",
            "year": 1994
        },
        {
            "authors": [
                "M Sirmali",
                "H Turut",
                "S Topcu"
            ],
            "title": "A comprehensive analysis of traumatic rib fractures: Morbidity, mortality and management",
            "venue": "Eur J Cardiothorac Surg",
            "year": 2003
        },
        {
            "authors": [
                "J Crandall",
                "R Kent",
                "J Patrie"
            ],
            "title": "Rib fracture patterns and radiologic detection\u2013a restraint-based comparison",
            "venue": "Annu Proc Assoc Adv Automot Med",
            "year": 2000
        },
        {
            "authors": [
                "V Pedersen",
                "A Lampart",
                "R Bingisser"
            ],
            "title": "Accuracy of plain radiography in detecting fractures in older individuals after lowenergy falls: Current evidence",
            "venue": "Trauma Surg Acute Care Open",
            "year": 2020
        },
        {
            "authors": [
                "M Chardoli",
                "T Hasan-Ghaliaee",
                "H Akbari"
            ],
            "title": "Accuracy of chest radiography versus chest computed tomography in hemodynamically stable patients with blunt chest trauma",
            "venue": "Chin J Traumatol",
            "year": 2013
        },
        {
            "authors": [
                "R Smith-Bindman",
                "J Lipson",
                "R Marcus"
            ],
            "title": "Radiation dose associated with common computed tomography examinations and the associated lifetime attributable risk of cancer",
            "venue": "Arch Intern Med",
            "year": 2078
        },
        {
            "authors": [
                "Bolliger SA",
                "Thali MJ"
            ],
            "title": "Imaging and virtual autopsy: Looking back and forward",
            "venue": "Philos Trans R Soc Lond B Biol",
            "year": 2015
        },
        {
            "authors": [
                "R Lindsey",
                "A Daluiski",
                "S Chopra"
            ],
            "title": "Deep neural network improves fracture detection by clinicians",
            "venue": "Proc Natl Acad Sci U S A",
            "year": 2018
        },
        {
            "authors": [
                "C Bluthgen",
                "AS Becker",
                "I Vittoria de Martini"
            ],
            "title": "Detection and localization of distal radius fractures: Deep learning system versus radiologists",
            "venue": "Eur J Radiol",
            "year": 2020
        },
        {
            "authors": [
                "G Kitamura",
                "CY Chung",
                "BE Moore"
            ],
            "title": "2nd. Ankle fracture detection utilizing a convolutional neural network ensemble implemented with a small sample, de novo training, and multiview incorporation",
            "venue": "J Digit Imaging",
            "year": 2019
        },
        {
            "authors": [
                "JE Burns",
                "JH Yao",
                "H Munoz"
            ],
            "title": "Automated detection, localization, and classification of traumatic vertebral body fractures in the thoracic and lumbar spine at CT",
            "year": 2016
        },
        {
            "authors": [
                "T Weikert",
                "LA Noordtzij",
                "J Bremerich"
            ],
            "title": "Assessment of a deep learning algorithm for the detection of rib fractures on whole-body trauma computed tomography",
            "venue": "Korean J Radiol",
            "year": 2020
        },
        {
            "authors": [
                "J Choi",
                "S Edamadaka",
                "D. Brown"
            ],
            "title": "Deep learning to automate identification and characterization of rib fractures on chest computed tomography scans. Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition",
            "venue": "Final report;",
            "year": 2022
        },
        {
            "authors": [
                "O Ronneberger",
                "P Fischer",
                "T Brox"
            ],
            "title": "U-Net: Convolutional networks for biomedical image segmentation",
            "venue": "MICCAI",
            "year": 2015
        },
        {
            "authors": [
                "X Wang",
                "Y. Wang"
            ],
            "title": "Composite attention residual U-Net for rib fracture detection",
            "venue": "Entropy (Basel)",
            "year": 2023
        },
        {
            "authors": [
                "J Wu",
                "N Liu",
                "X Li"
            ],
            "title": "Convolutional neural network for detecting rib fractures on chest radiographs: A feasibility study",
            "venue": "BMC Med Imaging",
            "year": 2023
        },
        {
            "authors": [
                "C Egger",
                "P Vaucher",
                "F Doenz"
            ],
            "title": "Development and validation of a postmortem radiological alteration index: The RA-index",
            "venue": "Int J Legal Med",
            "year": 2012
        },
        {
            "authors": [
                "PM Flach",
                "D Gascho",
                "W Schweitzer"
            ],
            "title": "Imaging in forensic radiology: An illustrated guide for postmortem computed tomography technique and protocols",
            "venue": "Forensic Sci Med Pathol",
            "year": 2014
        },
        {
            "authors": [
                "H Ringl",
                "M Lazar",
                "M Topker"
            ],
            "title": "The ribs unfolded - a CT visualization algorithm for fast detection of rib fractures: Effect on sensitivity and specificity in trauma patients",
            "venue": "Eur Radiol",
            "year": 2015
        },
        {
            "authors": [
                "K He",
                "X Zhang",
                "S Ren"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "IEEE Conf Comput Vis Pattern Recognit (CVPR)",
            "year": 2016
        },
        {
            "authors": [
                "M Abadi",
                "P Barham",
                "J Chen",
                "Z Chen",
                "A Davis",
                "J Dean"
            ],
            "title": "TensorFlow: A system for large-scale machine learning",
            "venue": "Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation. USENIX Association;",
            "year": 2016
        },
        {
            "authors": [
                "V Ibanez",
                "S Gunz",
                "S Erne"
            ],
            "title": "RiFNet: Automated rib fracture detection in postmortem computed tomography",
            "venue": "Forensic Sci Med Pathol",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Vol.:(0123456789)\nKeywords Deep learning\u00a0\u00b7 Forensic sciences\u00a0\u00b7 Rib fracture classification\u00a0\u00b7 Postmortem computed tomography"
        },
        {
            "heading": "Introduction",
            "text": "Rib fractures are a common type of injury. They can result from blunt trauma in an accident, chest compression during cardiopulmonary resuscitation, or a pathological fracture in malignant disease. They are often associated with other injuries, such as hemo- or pneumothorax and lung\ncontusions [1]. Depending on the displacement, type, and extent, rib fractures can result in an unstable chest (flail chest) and\u2014in combination with associated injuries\u2014can significantly influence morbidity and mortality [1, 2]. Depending on trauma severity or case circumstances, conventional radiography is the primary technique used to look for rib fractures because of its general availability, low radiation dose, and affordable costs. However, the sensitivity of conventional radiographs for the detection of rib fractures (especially nondisplaced ones) is considered relatively low [3, 4]. In contrast, computed tomography (CT) shows much higher sensitivity in detecting rib fractures, providing more detailed two-dimensional images that might also be viewed in three dimensions [5]. However, CT scans might not be available everywhere. In addition, they are more expensive, and they expose the patient to a higher radiation dose than conventional radiography [6]. In forensic medicine, concerns regarding radiation dose can obviously be ignored, and postmortem computed tomography (PMCT) has already gained great acceptance worldwide as a valuable adjunct and Sabine Franckenberg and Akos Dobay shared last authorship. * Akos Dobay akos.dobay@uzh.ch 1 Forensic Machine Learning Technology Center, Zurich Institute of\u00a0Forensic Medicine, University of\u00a0Zurich, Winterthurerstrasse 190/52, CH-8057\u00a0Zurich, Switzerland 2 Diagnostic and\u00a0Interventional Radiology, University Hospital Zurich, R\u00e4mistrasse 100, 8091\u00a0Zurich, Switzerland\n3 Zurich Institute of\u00a0Forensic Medicine, 3D Centre Zurich, University of\u00a0Zurich, Winterthurerstrasse 190/52, CH-8057\u00a0Zurich, Switzerland\n1 3\nsometimes even a replacement for conventional autopsies [7].\nSeveral recent studies have employed deep learning and image processing to automate rib fracture detection, adding to previous literature in which different groups proposed solutions for automating the detection of rib fractures on CT scans and radiographs [8\u201312]. For example, one recent study focused on detecting rib fractures on CT scans and classifying them into six categories, including displaced versus nondisplaced, buckle, and segmental fractures [13]. The authors trained a U-Net-based network using the RibFrac challenge dataset [14]. The model proposed by Choi et\u00a0al. can also determine the position of a fracture. In another study by Wang and Wang, the authors developed a modified U-Net architecture, combined with an attention module and a modified dilated convolution, to detect and segment rib fractures on CT scans [15]. The authors relied on the same RibFrac challenge dataset to train their architecture. In a third study, Wu et\u00a0al. utilized chest radiographs and employed a YOLOv3-based convolutional neural network (CNN) for rib fracture detection [16].\nIn our study, we developed a model to automatically detect rib fractures and classify whether they are displaced or nondisplaced using two-dimensional planar views of the rib cage reconstructed from PMCT volumetric data."
        },
        {
            "heading": "Materials and\u00a0methods",
            "text": ""
        },
        {
            "heading": "Ethics",
            "text": "The data used in this retrospective cohort study are in accordance with Swiss laws and ethical standards. The ethics approval for this study was waived by the Ethics Committee of the Canton of Zurich (KEK ZH-No. 15\u20130686)."
        },
        {
            "heading": "Case selection",
            "text": "A total of 340 consecutive autopsy cases were retrospectively retrieved from July 2017 to April 2018 from the archives of the Institute of Forensic Medicine, University of Zurich, Switzerland. We excluded cases with signs of advanced decomposition (using the RA-index defined by Egger et\u00a0al. [17]), corpses that had undergone organ explantation, cases of severe trauma with extensive damage to the corpse (e.g., amputation or exenteration), cases without whole-body PMCT, cases where rib fractures were not visible in the rib unfolding tool or located in the cartilaginous part of the rib, and cases that were still under investigation during this period. After these exclusion criteria were applied, a total of 195 cases remained (55 females, median age 64\u00a0years; 140 males, median age 54\u00a0years). Of the 195 cases, 85 showed acute rib fractures, 84 had no rib fractures,\nand 26 presented subacute and chronic fractures either in combination with acute fractures or independently. Both complete and incomplete rib fractures were included, independent of their location. They were classified as either \u201cdisplaced,\u201d \u201cnondisplaced,\u201d \u201cad latus\u201d (sideways), \u201cad axim\u201d (with angulation), \u201cad longitudinem cum contractione\u201d (in long axis compressed fracture), and \u201cad longitudinem cum distractione\u201d (in long axis with gap between the fragments) fractures.\nPostmortem computed tomography data\nWhole-body imaging was performed on a 128-slice dual source CT scanner (SOMATOM Flash Definition, Siemens, Forchheim, Germany) using automated dose modulation software (CARE Dose4D\u2122, Siemens, Forchheim, Germany); the slice thickness was 1 mm, and the increment was 0.5 mm. The images were reconstructed with both soft and hard kernels. A complete overview of the technical parameters used to acquire the CT scans can be found in Flach et\u00a0al. [18]."
        },
        {
            "heading": "Image treatment prior to\u00a0classification",
            "text": "The rib fracture images were reconstructed from volumetric CT data using Syngo.via rib unfolding tool CT Bone Reading (Siemens Healthineers GmbH, Erlangen, Germany) with standard bone window setting (center 450, width 1500) (see Fig.\u00a01 for more details). The tool used for this conversion was developed by Ringl et\u00a0al. [19]."
        },
        {
            "heading": "Data mining",
            "text": "To extract data containing fractures, we used 270 images of unfolded rib cages with fractures. Two readers, one who was a medical student under supervision and one who was a board-certified forensic pathologist and radiologist, classified each fracture type as either \u201cdisplaced\u201d or \u201cnondisplaced.\u201d The \u201cdisplaced\u201d fractures were further divided into \u201cad latus\u201d (sideways), \u201cad axim\u201d (with angulation), \u201cad longitudinem cum contractione\u201d (in long axis compressed fracture), and \u201cad longitudinem cum distractione\u201d (in long axis with gap between the fragments). Due to the very small number of \u201cad axim\u201d fractures, we excluded them from further analysis. First, we cropped the images to 500 \u00d7 1000 pixels to eliminate the background and then upscaled the images to 300% of the original size with the INTER_AREA interpolation method from OpenCV, resulting in large images measuring\u00a01500 \u00d7 3000. With this preprocessing step, we wanted to achieve an optimal size for dividing the image into sufficient image patches but still capturing all fractures. All fractures were marked using their respective x- and y-coordinates on the large image. For each\n1 3\nlarge image containing one or more fractures, we applied data augmentation by shifting the sliding window from the centered x- and y-coordinates in all four cardinal directions (up, down, right, and left) in steps of 10 pixels. This resulted in a total of 16 additional samples next to the original sample (centered around the fracture). For each fracture, we then manually removed the sample images where the data augmentation resulted in a loss of information (e.g., the fracture was no longer visible). The sample curation led to 11,759 \u201cdisplaced\u201d (\u201cad latus\u201d 1785, \u201clongitudinem cum contractione\u201d 6801, and \u201clongitudinem cum distractione\u201d 3173) and 18,462 \u201cnondisplaced\u201d samples, for a total of 30,251 \u201cfracture\u201d images.\nTo extract samples with the label \u201cno fracture,\u201d we used 231 images of unfolded rib cages without any fractures. As for the images with fractures, we applied the same preprocessing steps (cropping and resizing) to images without fractures. Employing a sliding window of size 99 \u00d7 99 pixels and shifting it 25 pixels in each direction along both the x - and\ny-axes, we obtained 231,926 small images, each of which was 99 \u00d7 99 pixels in size. From these images, we randomly selected 30,251 \u201cno fracture\u201d images, resulting in a balanced dataset of 60,472 samples in total."
        },
        {
            "heading": "Training, validation, and\u00a0testing",
            "text": "For our study, we used a Windows workstation (Windows 10, Nvidia GeForce GTX 1660 SUPER, 64\u00a0 GB CPU RAM). We split our data into ~ 70% training and ~ 30% test data. Representations from the same fracture were kept together in each partition to prevent data leakage into the test set; thus, the partitions varied slightly in size. We then ran a 5-fold cross-validation on the training dataset with different hyperparameters. We selected the best hyperparameters (see Section \u201cModel architecture and hyperparameters\u201d) by assessing the epochs with the highest validation score (F1 score). Finally, we trained our model with the best selection of hyperparameters on\nnondisplaced displaced latus\nlong. c. cont.long. c. dist.\nno fracture fracture\nS lid\nin g w in do\nw an d ra nd om se le ct io n\nx,y-coordinates and data augm entation\nFig. 1 Workflow of the automated rib fracture classification pipeline. Each volumetric PMCT scan of the rib cage was transformed into a corresponding 2D representation. If the representation did not display any fracture (\u201cno fracture\u201d), we collected a series of sample images (each measuring 99 \u00d7 99 pixels) using a sliding window. Then, we randomly drew from a subset of those samples. If the representation displayed rib fractures, we collected a sample at the exact position of the fracture with an additional set of 16 samples. The additional set was obtained using data augmentation by sliding the 99 \u00d7 99-pixel window in each of the four cardinal directions in 10-pixel steps. The samples from the four fracture types and the \u201cno fracture\u201d samples\nwere fed into a ResNet50 architecture for training and testing. We validated the performance of our model on three levels of hierarchical taxonomy: (1) a high-level task where the model distinguished between \u201cfracture\u201d and \u201cno fracture,\u201d (2) a mid-level task to assess how well the model could classify \u201cnondisplaced\u201d and \u201cdisplaced\u201d fractures, and (3) a low-level task to validate the performance of the model in classifying the three different types of displaced fractures \u201cad latus\u201d (sideways), \u201cad longitudinem cum contractione\u201d (in long axis compressed fracture), or \u201cad longitudinem cum distractione\u201d (in long axis with gap between the fragments)\n1 3\nthe full training dataset and validated the trained model on the test set. We assessed three levels of hierarchical taxonomy (see Fig.\u00a01 for more details):\n1. Performance of the model on the balanced binary task when classifying \u201cno fracture\u201d and \u201cfracture\u201d and reported with the accuracy score (high-level task). 2. Performance of the model on the imbalanced binary task when classifying \u201cdisplaced\u201d and \u201cnondisplaced\u201d with the F1, precision, and recall scores (mid-level task). 3. Performance of the model on the imbalanced multiclass task with the displaced classes \u201cad latus,\u201d \u201cad longitudinem cum contractione,\u201d and \u201cad longitudinem cum distractione\u201d with the F1, precision, and recall scores (low-level task).\nAdditionally, we defined two types of assessment:\n1. Performance measurement on the fracture representations (referred to as \u201cstandard\u201d assessment), as in simple image classification tasks. 2. Aggregation of the prediction values from multiple representations of the same fracture into a single prediction value. The aggregation procedure starts by running a custom-made function Y on the predicted values. The function Y is defined as\nwhere the variable y\u0302i stands for the label value predicted by the model for the representation i . The variable y\u0302i can take any integer value from 0 to c , where c represents the number of classes. Hence, the function Y = 0 if at least one of the representations i was classified into the class 0 (classified as \u201cno fracture\u201d). Otherwise, the function Y = 1 if at least one of the representations i was classified into a nonzero class (classified as \u201cfracture\u201d). Then, we used the maximum operator to determine the fracture type k when Y = 1:\nwhere the logitc i stands for the model output value for the class c before entering the Softmax function. In other words, the aggregated prediction value corresponding to a single fracture is the type of fracture (class) that has the highest weight over all its representations. This would ensure us that we have detected a fracture even with the weakest signal. We referred to this type of assessment as \u201caggregated.\u201d\nY = \u23a7 \u23aa\u23a8\u23aa\u23a9 0, if n\u2211 i=1 y\u0302i = 0 1, otherwise\nk = max c\n( 1\nn n\u2211 i=1 logitc i )"
        },
        {
            "heading": "Model architecture and\u00a0hyperparameters",
            "text": "We used the ResNet50 architecture [20] pretrained on the ImageNet database combined with two additional dense layers, each with 198 neurons, and with a dropout layer whose dropout rate was 0.5. Additionally, we included the EarlyStopping function to stop the training when the value of the validation loss function was minimal (patience = 15). We also used the ReduceLROnPlateau function to downscale the learning rate when the validation loss value was not improving (patience = 2) [21]. The batch size was set to 16, and we used the categorical cross-entropy loss function with the Adam optimizer. We first froze the layers of the pretrained network and trained on our data for several epochs (max = 100 epochs, depending on early stopping) with a learning rate of 0.0001. Then, we unfroze the layers and fine-tuned the network for another few epochs (max = 100 epochs, depending on early stopping) with a learning rate of 8e \u2212 05."
        },
        {
            "heading": "Results",
            "text": "We assessed the performance of our model in two different ways. First, we showed the metrics for the predictions on all representations in the test set (\u201cstandard\u201d assessment). Second, we aggregated the predictions of all representations on the test set to the fracture level and reported the metrics (\u201caggregated\u201d assessment). Figure\u00a02 shows the confusion matrices for all classes in terms of absolute and relative values and for each of the assessments. Most of the confusions occurred within the fracture classes, while fewer occurred in the class \u201cno fracture.\u201d While \u201cnondisplaced\u201d was correctly predicted in 80\u201386% of cases (depending on the assessment), \u201cad latus\u201d (sideways) was correctly predicted in only 17\u201318% of cases. The other two \u201cdisplaced\u201d subclasses, \u201cad longitudinem cum contractione\u201d\u00a0(in long axis compressed fracture)\u00a0and \u201cad longitudinem cum distractione,\u201d (in long axis with gap between the fragments) were correctly predicted in 70\u201375% and 64\u201375% of cases, respectively.\nTable\u00a01 gives an overview of the performance of our model. In the balanced binary classification task with the classes \u201cno fracture\u201d and \u201cfracture,\u201d our model achieved an accuracy score of 0.945 (0 worst score, 1 best score) on the \u201cstandard\u201d assessment and an accuracy score of 0.993 on the \u201caggregated\u201d assessment. When evaluating the models\u2019 performance on the imbalanced binary task with the classes \u201cdisplaced\u201d and \u201cnondisplaced,\u201d we found an F1 score of 0.845, a precision score of 0.845, and a recall score of 0.846. When data were aggregated at the fracture level, the model achieved an F1 score of 0.856, a precision score of 0.857, and a recall score of 0.855.\n1 3\nThe third task was an imbalanced multiclass task of the different \u201cdisplaced\u201d classes \u201cad latus\u201d (sideways), \u201cad longitudinem cum contractione\u201d (in long axis compressed fracture), and \u201cad longitudinem cum distractione\u201d (in long axis with gap between the fragments). There, we found an F1 score of 0.661, a precision score of 0.736, and a recall score of 0.603 for the \u201cstandard\u201d assessment and an F1 score of 0.707, a precision score of 0.769, and a recall score of 0.662 for the \u201caggregated\u201d assessment."
        },
        {
            "heading": "Discussion",
            "text": "The aim of this study was to train a deep learning model able to detect and classify different types of rib fractures using a two-dimensional representation of the rib cage reconstructed from three-dimensional PMCT images. By applying our model, we investigated two types of assessment (\u201cstandard\u201d and \u201caggregated\u201d) on three different hierarchical taxonomy levels (\u201cfracture\u201d versus \u201cno\nTable 1 Performance assessment overview. We assessed three different hierarchical taxonomy levels: (1) \u201cfracture\u201d vs. no \u201cfracture,\u201d (2) fractures separated into \u201cdisplaced\u201d and \u201cnondisplaced,\u201d and (3) displaced fractures separated into three subclasses. The three levels are assessed in two ways; \u201cstandard\u201d (all images) and \u201caggregated\u201d (e.g.,\nall representations of a fracture aggregated into a single datapoint). For each case, we calculated the F1, precision, recall, and accuracy score, depending on whether the dataset is balanced (accuracy) or imbalanced (F1, recall, and precision)\nStandard Aggregated\nF1 Precision Recall Accuracy F1 Precision Recall Accuracy\n\u201cFracture\u201d or \u201cno fracture\u201d - - - 0.945 - - - 0.993 \u201cDisplaced\u201d or \u201cnondisplaced\u201d 0.845 0.845 0.846 - 0.856 0.857 0.855 - Displaced subclasses 0.661 0.736 0.603 - 0.707 0.769 0.662 -\n1 3\nfracture,\u201d \u201cdisplaced\u201d versus \u201cnondisplaced,\u201d and \u201cdisplaced subclasses\u201d) with different scores. Our results show that the trained model can distinguish between \u201cfracture\u201d and \u201cno fracture\u201d samples to a large extent and with a high accuracy (94.5%). When data were aggregated at the fracture level, only three out of 591 fractures were classified as \u201cno fracture.\u201d The model also performed reliably in distinguishing \u201cdisplaced\u201d from \u201cnondisplaced\u201d fractures, although to a slightly lesser extent. When classifying \u201cdisplaced\u201d from \u201cnondisplaced\u201d fractures, we noted that the trained model performed slightly better in classifying \u201cnondisplaced\u201d than \u201cdisplaced\u201d fractures. This could be due to either the smaller sample size or the possibility that the features of \u201cdisplaced\u201d fractures were more difficult for the model to capture. Finally, the most difficult task was distinguishing \u201cdisplaced\u201d subclasses. In particular, the model performed worst for the subclass \u201cad latus\u201d (sideways), which was often confused with \u201cad longitudinem cum contractione\u201d (in long axis compressed fracture) or \u201cnondisplaced.\u201d The scores for the aggregated assessment were generally higher than those for the standard assessment, which reflects our choice of metric design. We defined a single correct fracture prediction from all possible representations as sufficient to qualify as a \u201cfracture\u201d and be classified accordingly.\nAs we mentioned in the introduction, three recent studies used deep learning techniques to automatically detect rib fractures either on CT scans or radiographs. These studies used different datasets which makes it difficult to compare their performance with our model. However, we went one step further by identifying four different subclasses of \u201cdisplaced\u201d fractures. We also developed a method to display the position of each fracture. If multiple fractures are present on the same CT scans, they are labeled separately (see Fig.\u00a01)."
        },
        {
            "heading": "Conclusion",
            "text": "The analysis of two-dimensional representations of the rib cage instead of volumetric data already enables clinicians to make a quick and easy assessment for potential rib fractures. Building upon our previous work [22], we have shown how deep learning techniques can be used as an automation step to reliably locate and classify relevant fracture types on such large two-dimensional PMCT images and thus further simplify and support clinicians\u2019 work."
        },
        {
            "heading": "Key points",
            "text": "1. Our model achieved an accuracy score of 0.945 on a balanced binary classification task with the classes \u201cno fracture\u201d and \u201cfracture.\u201d\n2. The F1 score on the imbalanced binary task with the classes \u201cdisplaced\u201d and \u201cnondisplaced\u201d reached 0.845. 3. Classifying \u201cdisplaced\u201d subclasses remains challenging, especially the subclass \u201cad latus.\u201d\nAuthor contribution D.J. and S.F. annotated the images. S.F. checked all annotated images. V.I. developed, trained, and optimized the model. V.I., S.F., and A.D. wrote the manuscript. A.D. supervised the study. L.E. reviewed the manuscript. All authors read and approved the manuscript.\nFunding Open access funding provided by University of Zurich This study was funded by the Emma Louis Kessler Foundation. S.B. was partially funded by the development career program \u201cFilling the Gap\u201d at the University of Zurich to secure protected research time.\nData availability The datasets analyzed during the current study are not publicly available due to data privacy. The code and the trained models are available on reasonable request."
        },
        {
            "heading": "Declarations",
            "text": "Ethics approval This retrospective study does not fall within the scope of the Human Research Act (HRA). The Cantonal Ethics Board of the Canton of Zurich has waived the need for an authorization (waiver document KEK ZH-No. 15\u20130686).\nCompeting interests The authors declare no competing interests.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/."
        }
    ],
    "title": "Classification of rib fracture types from postmortem computed tomography images using deep learning",
    "year": 2023
}