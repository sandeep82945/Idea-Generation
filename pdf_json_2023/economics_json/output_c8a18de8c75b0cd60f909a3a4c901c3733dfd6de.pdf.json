{
    "abstractText": "Stock investment has undergone a significant transformation driven by the development of computer technology, with high-frequency trading data emerging into prominence. Order flow data, the finest granularity of high-frequency data, made up of the order book and transaction data at the tick level, is crucial for market microstructure analysis as it provides traders with valuable insights to make informed decisions. However, extracting and utilizing order flow data is challenging due to the large volume of data and the limitations of traditional factor mining techniques, which are designed for coarser-level stock data. To address these challenges, we propose a novel framework to effectively extract important features from order flow data that can be applied at various temporal granularities. Our method consists of a Context Encoder and an Informative Factor Extractor. The Context Encoder learns an embedding for the current order flow data segment\u2019s context by considering both the expected and actual market state. Meanwhile, the Informative Factor Extractor uses unsupervised learning methods to select such important signals that are most distinct from the majority within the given context. After that, the relevant factors extracted from these signals are utilized in downstream tasks. In empirical studies, we verify our method on an entire year of stock order flow data across diverse scenarios, thus providing a wider range of potential applications in comparison to existing tick-level approaches that have only been evaluated on small datasets spanning a few days of stock data. We demonstrate that our method extracts superior factors from order flow data, enabling significant improvement for stock trend prediction and order execution tasks at the second and minute level. ACM Reference Format: Xianfeng Jiao, Zizhong Li, Chang Xu, Yang Liu, Weiqing Liu, and Jiang Bian. 2023. Microstructure-Empowered Stock Factor Extraction and Utilization. \u2217Both authors contributed equally to this research. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201932nd, October 2023, University of Birmingham and Eastside Rooms, UK \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn In Proceedings of CIKM (Conference\u201932nd). , 10 pages. https://doi.org/10.1145/ nnnnnnn.nnnnnnn",
    "authors": [
        {
            "affiliations": [],
            "name": "Xianfeng Jiao"
        },
        {
            "affiliations": [],
            "name": "Zizhong Li"
        },
        {
            "affiliations": [],
            "name": "Chang Xu"
        },
        {
            "affiliations": [],
            "name": "Yang Liu"
        },
        {
            "affiliations": [],
            "name": "Weiqing Liu"
        },
        {
            "affiliations": [],
            "name": "Jiang Bian"
        }
    ],
    "id": "SP:db4d57e14fbd92ffdf0ef5c100e27d6835366a98",
    "references": [
        {
            "authors": [
                "Marco Avellaneda",
                "Sasha Stoikov"
            ],
            "title": "High-frequency trading in a limit order book",
            "venue": "Quantitative Finance 8,",
            "year": 2008
        },
        {
            "authors": [
                "Brad M Barber",
                "Terrance Odean"
            ],
            "title": "The behavior of individual investors",
            "venue": "In Handbook of the Economics of Finance",
            "year": 2013
        },
        {
            "authors": [
                "Zineb Bousbaa",
                "Javier Sanchez-Medina",
                "Omar Bencharef"
            ],
            "title": "Financial Time Series Forecasting: A Data Stream Mining-Based System",
            "venue": "Electronics 12,",
            "year": 2023
        },
        {
            "authors": [
                "Rodolfo C Cavalcante",
                "Rodrigo C Brasileiro",
                "Victor LF Souza",
                "Jarley P Nobrega",
                "Adriano LI Oliveira"
            ],
            "title": "Computational intelligence and financial markets: A survey and future directions",
            "venue": "Expert Systems with Applications",
            "year": 2016
        },
        {
            "authors": [
                "Chi Chen",
                "Li Zhao",
                "Jiang Bian",
                "Chunxiao Xing",
                "Tie-Yan Liu"
            ],
            "title": "Investment behaviors can tell what inside: Exploring stock intrinsic properties for stock trend prediction",
            "venue": "In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
            "year": 2019
        },
        {
            "authors": [
                "Tarun Chordia",
                "Avanidhar Subrahmanyam"
            ],
            "title": "Order imbalance and individual stock returns: Theory and evidence",
            "venue": "Journal of Financial Economics 72,",
            "year": 2004
        },
        {
            "authors": [
                "Qianggang Ding",
                "Sifan Wu",
                "Hao Sun",
                "Jiadong Guo",
                "Jian Guo"
            ],
            "title": "Hierarchical Multi-Scale Gaussian Transformer for Stock Movement Prediction",
            "venue": "In IJCAI",
            "year": 2020
        },
        {
            "authors": [
                "Yuchen Fang",
                "Kan Ren",
                "Weiqing Liu",
                "Dong Zhou",
                "Weinan Zhang",
                "Jiang Bian",
                "Yong Yu",
                "Tie-Yan Liu"
            ],
            "title": "Universal Trading for Order Execution with Oracle Policy Distillation",
            "venue": "Research Papers in Economics",
            "year": 2021
        },
        {
            "authors": [
                "Fuli Feng",
                "Huimin Chen",
                "Xiangnan He",
                "Ji Ding",
                "Maosong Sun",
                "Tat-Seng Chua"
            ],
            "title": "Enhancing stock movement prediction with adversarial training",
            "year": 2018
        },
        {
            "authors": [
                "Martin D Gould",
                "Mason A Porter",
                "Stacy Williams",
                "Mark McDonald",
                "Daniel J Fenn",
                "Sam D Howison"
            ],
            "title": "Limit order books",
            "venue": "Quantitative Finance 13,",
            "year": 2013
        },
        {
            "authors": [
                "Fabien Guilbaud",
                "Huyen Pham"
            ],
            "title": "Optimal high-frequency trading with limit and market orders",
            "venue": "Quantitative Finance 13,",
            "year": 2013
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber"
            ],
            "title": "Long short-termmemory",
            "venue": "Neural computation 9,",
            "year": 1997
        },
        {
            "authors": [
                "Vivien Lespagnol",
                "Juliette Rouchier"
            ],
            "title": "Trading volume and price distortion: an agent-based model with heterogenous knowledge of fundamentals",
            "venue": "Computational Economics 51,",
            "year": 2018
        },
        {
            "authors": [
                "Wei Li",
                "Ruihan Bao",
                "Keiko Harimoto",
                "Deli Chen",
                "Jingjing Xu",
                "Qi Su"
            ],
            "title": "Modeling the stock relation with graph network for overnight stock movement prediction",
            "venue": "In Proceedings of the twenty-ninth international conference on international joint conferences on artificial intelligence",
            "year": 2021
        },
        {
            "authors": [
                "Qianqiao Liang",
                "Mengying Zhu",
                "Xiaolin Zheng",
                "YanWang"
            ],
            "title": "An Adaptive News-Driven Method for CVaR-sensitive Online Portfolio Selection in Non- Stationary Financial Markets",
            "venue": "In IJCAI",
            "year": 2021
        },
        {
            "authors": [
                "Guang Liu",
                "Yuzhao Mao",
                "Qi Sun",
                "Hailong Huang",
                "Weiguo Gao",
                "Xuan Li",
                "Jianping Shen",
                "Ruifan Li",
                "Xiaojie Wang"
            ],
            "title": "Multi-scale Two-way Deep Neural Network for Stock Trend Prediction",
            "venue": "In IJCAI",
            "year": 2020
        },
        {
            "authors": [
                "Costis Maglaras",
                "Ciamac C Moallemi",
                "Muye Wang"
            ],
            "title": "A deep learning approach to estimating fill probabilities in a limit order book",
            "venue": "Quantitative Finance 22,",
            "year": 2022
        },
        {
            "authors": [
                "Martin Magris",
                "Mostafa Shabani",
                "Alexandros Iosifidis"
            ],
            "title": "Bayesian Bilinear Neural Network for Predicting the Mid-price Dynamics in Limit-Order Book Markets",
            "venue": "arXiv preprint",
            "year": 2022
        },
        {
            "authors": [
                "Frank McGroarty",
                "Ash Booth",
                "Enrico Gerding",
                "VL Chinthalapati"
            ],
            "title": "High frequency trading strategies, market fragility and price spikes: an agent based model perspective",
            "venue": "Annals of Operations Research 282,",
            "year": 2019
        },
        {
            "authors": [
                "Ciamac C Moallemi",
                "Muye Wang"
            ],
            "title": "A reinforcement learning approach to optimal execution",
            "venue": "Quantitative Finance 22,",
            "year": 2022
        },
        {
            "authors": [
                "Somenath Mukherjee",
                "Bikash Sadhukhan",
                "Nairita Sarkar",
                "Debajyoti Roy",
                "Soumil De"
            ],
            "title": "Stock market prediction using deep learning algorithms",
            "venue": "CAAI Transactions on Intelligence Technology",
            "year": 2023
        },
        {
            "authors": [
                "Noella Nazareth",
                "Yeruva Yenkata Ramana Reddy"
            ],
            "title": "Financial applications of machine learning: a literature review",
            "venue": "Expert Systems with Applications",
            "year": 2023
        },
        {
            "authors": [
                "Anna A Obizhaeva",
                "Jiang Wang"
            ],
            "title": "Optimal trading strategy and supply/demand dynamics",
            "venue": "Journal of Financial Markets 16,",
            "year": 2013
        },
        {
            "authors": [
                "Gustavo Magno Lopes Pereira",
                "Eduardo Camilo-da Silva"
            ],
            "title": "Trading Imbalance, Liquidity and Stock Returns: Evidence from Brazil",
            "venue": "Latin American Business Review 21,",
            "year": 2020
        },
        {
            "authors": [
                "Lukas Ruff",
                "Robert Vandermeulen",
                "Nico Goernitz",
                "Lucas Deecke",
                "Shoaib Ahmed Siddiqui",
                "Alexander Binder",
                "Emmanuel M\u00fcller",
                "Marius Kloft"
            ],
            "title": "Deep one-class classification",
            "venue": "In International conference on machine learning",
            "year": 2018
        },
        {
            "authors": [
                "Matthias Schnaubelt"
            ],
            "title": "Deep reinforcement learning for the optimal placement of cryptocurrency limit orders",
            "venue": "European Journal of Operational Research 296,",
            "year": 2022
        },
        {
            "authors": [
                "Claude E Shannon"
            ],
            "title": "A mathematical theory of communication",
            "venue": "The Bell system technical journal 27,",
            "year": 1948
        },
        {
            "authors": [
                "Darryl Shen"
            ],
            "title": "Order imbalance based strategy in high frequency trading",
            "venue": "Ph. D. Dissertation. oxford university",
            "year": 2015
        },
        {
            "authors": [
                "Zijian Shi",
                "John Cartlidge"
            ],
            "title": "2022. State Dependent Parallel Neural Hawkes Process for Limit Order Book Event Stream Prediction and Simulation",
            "venue": "In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining",
            "year": 2022
        },
        {
            "authors": [
                "Zijian Shi",
                "Yu Chen",
                "John Cartlidge"
            ],
            "title": "The LOB recreation model: Predicting the limit order book from TAQ history using an ordinary differential equation recurrent neural network",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Justin A Sirignano"
            ],
            "title": "Deep learning for limit order books",
            "venue": "Quantitative Finance 19,",
            "year": 2019
        },
        {
            "authors": [
                "Ankit Thakkar",
                "Kinjal Chaudhari"
            ],
            "title": "Fusion in stock market prediction: a decade survey on the necessity, recent developments, and potential future directions",
            "venue": "Information Fusion",
            "year": 2021
        },
        {
            "authors": [
                "Avraam Tsantekidis",
                "Nikolaos Passalis",
                "Anastasios Tefas",
                "Juho Kanniainen",
                "Moncef Gabbouj",
                "Alexandros Iosifidis"
            ],
            "title": "Forecasting stock prices from the limit order book using convolutional neural networks",
            "venue": "IEEE 19th conference on business informatics (CBI),",
            "year": 2017
        },
        {
            "authors": [
                "Heyuan Wang",
                "Shun Li",
                "Tengjiao Wang",
                "Jiayi Zheng"
            ],
            "title": "Hierarchical Adaptive Temporal-Relational Modeling for Stock Trend Prediction",
            "venue": "In IJCAI",
            "year": 2021
        },
        {
            "authors": [
                "Heyuan Wang",
                "Tengjiao Wang",
                "Shun Li",
                "Jiayi Zheng",
                "Shijie Guan",
                "Wei Chen"
            ],
            "title": "Adaptive Long-Short Pattern Transformer for Stock Investment Selection",
            "year": 2022
        },
        {
            "authors": [
                "Haoran Wei",
                "Yuanbo Wang",
                "Lidia Mangu",
                "Keith Decker"
            ],
            "title": "Model-based reinforcement learning for predictions and control for limit order books",
            "year": 2019
        },
        {
            "authors": [
                "Borui Xu",
                "Tong Zhang",
                "Weiguo Liu"
            ],
            "title": "A Multi-scale Convolution and Gated Recurrent Unit Based Network for Limit Order Book Prediction",
            "venue": "In International Conference on Knowledge Science, Engineering and Management",
            "year": 2022
        },
        {
            "authors": [
                "Zihao Zhang",
                "Stefan Zohren",
                "Stephen Roberts"
            ],
            "title": "Deeplob: Deep convolutional neural networks for limit order books",
            "venue": "IEEE Transactions on Signal Processing 67,",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "ACM Reference Format: Xianfeng Jiao, Zizhong Li, Chang Xu, Yang Liu, Weiqing Liu, and Jiang Bian. 2023. Microstructure-Empowered Stock Factor Extraction and Utilization.\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference\u201932nd, October 2023, University of Birmingham and Eastside Rooms, UK \u00a9 2023 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn\nIn Proceedings of CIKM (Conference\u201932nd). , 10 pages. https://doi.org/10.1145/ nnnnnnn.nnnnnnn"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "The stock market holds a pivotal position in the financial industry, with quantitative analysis of stocks emerging as a highly significant research field within the realm of FinTech. In recent years, there have been remarkable advancements in stock investment facilitated by rapid progress in computer technology and the availability of high-frequency data [3, 4, 23, 34]. This abundance of high-frequency data, which is updated at a remarkably fast rate, ranging from every second to milliseconds, has opened up avenues for sophisticated analysis of financial markets. Consequently, it enables a deeper understanding of market microstructure and dynamics, thereby offering more accurate and real-time market intelligence.\nIn high-frequency data, order flow data is the most detailed and raw data available for market microstructure analysis. More specifically, it is a chronological sequence of orders at the tick level submitted to trading systems, including information such as the order type, price, volume, and the time of orders. By recording real-time trading records, order flow data allows for the capture of subtle market changes such as trader sentiment and strategy that may be difficult to detect using market trading data at a coarser temporal granularity. For example, as shown in Figure 1, order flow data can encompass the process of traders\u2019 ask and bid positions, capturing their order placement and transaction activities. It can dynamically depict the contrast of forces between buyers and sellers in real-time, providing a more immediate and detailed view of market dynamics. Specifically, the volume of sell orders is significantly higher than that of buy orders, indicating a large sell pressure. This imbalance in trading activity suggests a potential future drop in price, as larger selling pressure often leads to downward price movements. Order flow data is in contrast to widely used candlestick charts, which can only represent lagging trading results. Therefore, order flow data can provide valuable insights and more precise market condition for traders to make more informed and instant trading decisions.\nDespite the potential benefits, extracting and utilizing order flow data at granular levels remains challenging. For instance, the sheer volume of data with a single stock having upwards of 90,000 orders 1 traded in a single day. Since processing and analyzing such a\n1Information obtained from the transactions of the Ping An Bank Co., Ltd. (000001.SZ) in 2020, see more in Yahoo Finance.\nar X\niv :2\n30 8.\n08 13\n5v 1\n[ q-\nfi n.\nST ]\n1 6\nA ug\n2 02\nhuge amount of data is very difficult, traditional deep learningbased factor mining techniques typically operate at coarser time granularities, such as daily and hourly frequencies [5, 9, 15, 16, 36\u2013 38]. This means that these methods may not be able to capture microstructural market features, such as the relative strength of buyers and sellers and trader sentiment and strategy, which are valuable in stock analysis.\nFurthermore, extractingmicrostructural factors fromfine-grained data is only the initial step. Another key challenge lies in developing methods that offer adaptability across various downstream tasks and temporal granularities. Previous research has examined leveraging order flow data to enhance downstream tasks, such as forecasting future instantaneous stockmovement trends [17, 22, 40], and short-term order book reconstruction [31, 32]. However, these studies primarily aim to extract microstructural information in the short term and may not directly address broader analysis over longer time periods. There is still a need for a method that provides greater adaptability across a wide range of downstream tasks.\nIn this paper, we aim to design microstructure factor extraction and utilization methods guided by the following principles: (1) Microstructure market modeling: Focusing on modeling the microstructure market rather than adopting a macro perspective to extract meaningful signals of trading details from extensive order flow data. (2) Generalizability across downstream tasks: Being generalizable across different types of downstream tasks, like return prediction and order executions at different coarser granularity (i.e. the daily-level and minute-level problems). To handle the large volume of order flow level data, we divide the whole order sequence into small segments, such as at the second level, and perform signal extraction on each segment separately. Despite this segmentation, the number of segments for a broader time frame, such as daily intervals, remains significantly challenging to handle. Under these circumstances, we propose to extract only the most important signals from these segments. Based on the principles of Information Theory [29], the segments that contain the most unique information are likely to be the most informative. In addition, to preserve the market state information of these segments, we encode both the expected\nand real market state as context. Subsequently, we generate each segment\u2019s representation and employ unsupervised methods [27] to select segments that exhibit the greatest dissimilarity from the majority given the context. Then, the informative microstructure factors are extracted from these divided segments to serve different granularities of downstream tasks.\nMore specifically, our model comprises the following two essential components: Context Encoder and Factor Extractor. For the Context Encoder, we utilize historical segments\u2019 order flow data to derive accumulated sell/buy orders as input. Then, we employ separate generators for bid and ask orders, while incorporating shared information to generate future orders. This enables us to generate a predicted order book for the next order segment, serving as a snapshot of the future market. To assess the market state and its deviation from expectations, we introduce an expectation-reality comparison method. By comparing the predicted order book with the actual order book, we gain valuable insights into the market dynamics and the extent to which it aligns with expectations. The representation of the predicted and real order books for the next order segment are concatenated and used as the context information, indicating market state.\nGiven the context information, the Factor Extractor utilizes transaction data, derived from order flow data, to extract vital features for the current segment. This data provides valuable insights into the dominant forces of both the buying and selling sides. We design conditional attention mechanism to compress the information from transaction data while considering the current market state. This is essential because the interpretation of the same transaction data stream can vary across different market states. For instance, in a scenario of significant upward price movement, a large volume of active sell orders often indicates profit-taking, whereas in a period of stable price sequences, it may suggest a bearish market sentiment leading to panic selling. Subsequently, we use unsupervised learning to select the most distinctive signals from the extracted feature generated by Factor Extractor. Finally, we extract feature factors based on specific tasks and concatenate the selected important trading signals from the chosen time segment range. These concatenated factors are then utilized in various coarse-grained downstream tasks.\nIn empirical studies, we verify our method on real-world order flow data spanning up to one year across diverse scenarios, greatly exceeding the data range currently available for order flow work [17, 32, 40]. Also, it achieves superior performance compared to other microstructure-based factor mining methods in both daily return prediction and order execution downstream tasks.\nIn summary, our main contributions are as follows:\n1) We proposed a method that leverages a substantial amount of orders to model and extract vital trading details, thereby improving the analysis of stock trends. To the best of our knowledge, this study is one of the pioneering efforts in exploring the modeling of trading data from amicrostructure market perspective instead of a macro view. 2) We develop an innovative framework for extracting stock factor empowered by microstructure analysis, which utilizes historical order flow data to capture contextual information"
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": "In this section, we first review previous research in related areas, including stock factor extraction and utilization of microstructure market data. Then, we introduce order flow data and two types of data derived from order flow data: Limit Order Book (LOB) and transaction data, which are employed in our framework. For clarification and ease of understanding, Table 1 provides the list of notations used in our framework."
        },
        {
            "heading": "2.1 Related Work",
            "text": "Stock factor extraction involves identifying and analyzing patterns and trends in financial data to predict future stock performance, which can be applied in a variety of contexts, including portfolio construction, risk management, and trading strategy development. There are various methods and approaches to stock factor extraction, including statistical and machine learning techniques. Statistical methods [1, 11, 24, 26] often rely on domain expertise and may not be able to generalize to dynamic stock markets. In recent research, deep neural networks have been proposed for learning stock factors. However, previous work [5, 9, 15, 16, 36\u201338] has primarily focused on data at a coarse time granularity (e.g. daily) and has paid little attention to microstructure stock data. For example, these methods tend to model correlations between trading days rather than subtle patterns within intraday and order-level data.\nThe utilization of microstructure market data has been explored in a limited number of studies. Some of these works [1, 11, 24, 26] have designed hand-crafted features to infer the instantaneous market state, such as the ratio of instant buy orders to buy orders[14]. Other studies [17, 19, 33, 35, 41] have applied deep learning techniques to tasks at the order or tick level, such as predicting instant stock prices[7, 17, 40] or performing order-level market simulations [18, 20, 21, 28, 39]. While these methods can capture instantaneous microstructure features, they may not be as effective as traditional stock factor extraction methods for tasks at daily or minutely time granularities."
        },
        {
            "heading": "2.2 Order Flow Data",
            "text": "Order flow data is a key component of the microstructure of a market. In this work, we adopt a definition of orders consistent with previous research [10, 32]. Specifically, an order \ud835\udc65 = (\ud835\udc5d\ud835\udc65 ,\ud835\udc64\ud835\udc65 , \ud835\udc61\ud835\udc65 )\nsubmitted at time \ud835\udc61\ud835\udc65 with price \ud835\udc5d\ud835\udc65 and size \ud835\udc64\ud835\udc65 > 0 (respectively, \ud835\udc64\ud835\udc65 < 0) represents a commitment to sell (respectively, buy) up to |\ud835\udc64\ud835\udc65 | units of the traded asset at a price no less than (respectively, no greater than) \ud835\udc5d\ud835\udc65 . 2 The order flow is then defined as the ordered sequence of orders, i.e., the order flow \ud835\udc4b = {\ud835\udc651, \ud835\udc652, . . . , \ud835\udc65\ud835\udc47 }, where \ud835\udc61\ud835\udc651 \u2264 \ud835\udc61\ud835\udc652 \u2264 \u00b7 \u00b7 \u00b7 \u2264 \ud835\udc61\ud835\udc65\ud835\udc47 . Order flow data represents the most granular and raw form of microstructure market data, and the limit order book data and transaction data derived from it are the types of data we specifically utilize in this work. Figure 2 illustrates the process of deriving transaction data and order book data from order flow data. Transaction Data Transaction data consists of records of completed trades in a market and typically includes information such as the price, size, and time of each trade. By analyzing transaction data, we can gain insights into various aspects of market microstructure, including the activity and intensity of the market and the behavior of large players participating in the market. A single matching record at time \ud835\udc61\ud835\udc65 can be described as \ud835\udc67 = (\ud835\udc5d\ud835\udc67 ,\ud835\udc64\ud835\udc67 , \ud835\udc61\ud835\udc67) with price \ud835\udc5d\ud835\udc67 and size \ud835\udc64\ud835\udc67 > 0 (respectively, \ud835\udc64\ud835\udc67 < 0) represents the active sell (respectively, buy) orders. Transaction data is a chronological sequence of orders, written as \ud835\udc4d = {\ud835\udc671, \ud835\udc672, . . . , \ud835\udc67\ud835\udc3f}. Limit Order Book Data The Limit Order Book (LOB) data provides a snapshot of the supply and demand for a given asset at a specific point in time. It can be used to infer the sentiment and intentions of market participants. The LOB consists of two main components: the bid side and the ask side, representing the highest prices at which buyers are willing to purchase the asset and the lowest prices at which sellers are willing to sell the asset, respectively. The LOB data typically includes the price, size, and time of each order placed. Formally, we denote order books at time \ud835\udc61 as \ud835\udc42\ud835\udc61 = (\ud835\udc42\ud835\udc4f\ud835\udc61 ,\ud835\udc42\ud835\udc60\ud835\udc61 ), where \ud835\udc42\ud835\udc4f\ud835\udc61 and \ud835\udc42\ud835\udc60\ud835\udc61 represent buy order books and sell order books. Buy order book at time \ud835\udc61 is represented as \ud835\udc42\ud835\udc4f\ud835\udc61 = {(\ud835\udc5d\ud835\udc4f0\ud835\udc61 , \ud835\udc63\ud835\udc4f0\ud835\udc61 ), (\ud835\udc5d\ud835\udc4f1\ud835\udc61 , \ud835\udc63\ud835\udc4f1\ud835\udc61 ), . . . , (\ud835\udc5d\ud835\udc4f\ud835\udc3e\ud835\udc61 , \ud835\udc63\ud835\udc4f\ud835\udc3e\ud835\udc61 )}, where \ud835\udc5d\ud835\udc4f 0 \ud835\udc61 > \ud835\udc5d\ud835\udc4f 1 \ud835\udc61 > \u00b7 \u00b7 \u00b7 > \ud835\udc5d\ud835\udc4f\ud835\udc3e\ud835\udc61 . (\ud835\udc5d\ud835\udc4f\ud835\udc58\ud835\udc61 , \ud835\udc63\ud835\udc4f\ud835\udc58\ud835\udc61 ) represents that the volume of buy orders at price \ud835\udc5d\ud835\udc4f\ud835\udc58\ud835\udc61 is \ud835\udc63\ud835\udc4f \ud835\udc58 \ud835\udc61 . Similarly, we can get the sell order book\ud835\udc42\ud835\udc60\ud835\udc61 = {(\ud835\udc5d\ud835\udc60 0\ud835\udc61 , \ud835\udc63\ud835\udc60 0\ud835\udc61 ), (\ud835\udc5d\ud835\udc60 1\ud835\udc61 , \ud835\udc63\ud835\udc60 1\ud835\udc61 ), . . . , (\ud835\udc5d\ud835\udc60\ud835\udc3e\ud835\udc61 , \ud835\udc63\ud835\udc60\ud835\udc3e\ud835\udc61 )}, where \ud835\udc5d\ud835\udc60 0\ud835\udc61 < \ud835\udc5d\ud835\udc60\n1 \ud835\udc61 < \u00b7 \u00b7 \u00b7 < \ud835\udc5d\ud835\udc60\ud835\udc3e\ud835\udc61 . To simplify notation and analysis, we assume that the order book is updated instantaneously when a new order \ud835\udc65\ud835\udc61+1 is received. We use the operator \u2297 to denote the process of generating order book using previous order book and current order flow data, i.e.,\n\ud835\udc42\ud835\udc61+1 = \ud835\udc42\ud835\udc61 \u2297 \ud835\udc65\ud835\udc61+1 . (1) At \ud835\udc61 = 0, the initial order book, represented by \ud835\udc420, is empty, with a volume of zero at every price level. (i) If the new order cannot be matched with the current orders on the order book, it will be added to the existing order book. For instance, if \ud835\udc64\ud835\udc65\ud835\udc61+1 < 0 (i.e., a buy order) and \ud835\udc5d\ud835\udc65\ud835\udc61+1 < \ud835\udc5d0\ud835\udc60 (i.e., cannot match), the order book is updated such that \ud835\udc63\ud835\udc4f\ud835\udc58\ud835\udc61+1 = \ud835\udc63\ud835\udc4f \ud835\udc58 \ud835\udc61 +|\ud835\udc64\ud835\udc65\ud835\udc61+1 | for the price level \ud835\udc58 satisfying \ud835\udc5d\ud835\udc65\ud835\udc61+1 = \ud835\udc5d\ud835\udc4f \ud835\udc58 \ud835\udc61 . (ii) If the new order can be matched with the current orders on the order book, it will consume them. For example, if\ud835\udc64\ud835\udc65\ud835\udc61+1 < 0 and \ud835\udc5d\ud835\udc65\ud835\udc61+1 \u2265 \ud835\udc5d0\ud835\udc60 , the order book is updated such that \ud835\udc63\ud835\udc60\ud835\udc58\ud835\udc61+1 = max(\ud835\udc63\ud835\udc60\ud835\udc58\ud835\udc61 \u2212 (|\ud835\udc64\ud835\udc65\ud835\udc61+1 | \u2212 \u2211\ud835\udc58\u22121 \ud835\udc56=0 \ud835\udc63\ud835\udc60 \ud835\udc56 \ud835\udc61 ), 0) for the price level \ud835\udc58 satisfying \ud835\udc5d\ud835\udc65\ud835\udc61+1 = \ud835\udc5d\ud835\udc60 \ud835\udc58 \ud835\udc61 . (In cases of a partial match, we split the original order\n2During preprocessing, we also convert market orders to their equivalent limit order form and filter out canceled orders.\ninto two equivalent orders: a fully matched order and a remainder order that cannot be matched.) At the same time, a corresponding transaction record is generated as \ud835\udc67 = (\ud835\udc5d\ud835\udc67 ,\ud835\udc64\ud835\udc67 , \ud835\udc61\ud835\udc67), where\ud835\udc64\ud835\udc67 = \ud835\udc64\ud835\udc65 . \ud835\udc5d\ud835\udc67 = ( \u2211\ud835\udc58\u22121 \ud835\udc56=0 \ud835\udc5d\ud835\udc60 \ud835\udc56 \ud835\udc61\ud835\udc63\ud835\udc60 \ud835\udc56 \ud835\udc61 + \ud835\udc5d\ud835\udc60\ud835\udc58\ud835\udc61 (\ud835\udc63\ud835\udc60\ud835\udc58\ud835\udc61 \u2212 (|\ud835\udc64\ud835\udc65\ud835\udc61+1 | \u2212 \u2211\ud835\udc58\u22121 \ud835\udc56=0 \ud835\udc63\ud835\udc60 \ud835\udc56 \ud835\udc61 )))/|\ud835\udc64\ud835\udc65 | represents the actual transaction price. (iii) If an order is canceled, the update corresponding to that order will be reversed and the order book will revert back to its previous state."
        },
        {
            "heading": "3 METHOD",
            "text": "In this section, we will provide a detailed description of our approach for extracting microstructure factors from large-scale order flow data and demonstrate their utilization in downstream tasks. To handle the substantial volume of order flow-level data, we divide it into smaller segments and extract features from segments. In addition, we propose to consider the context of each segment during feature extraction. In Section 3.1, we introduce how to encode historical information as market condition information by Context Encoder. Section 3.2 presents our Factor Extractor module. To extract general factors applicable to diverse downstream tasks, we adopt unsupervised methods that do not rely on task-specific label information during feature extraction. Moreover, to apply the extracted information from the segments to tasks at coarser time granularity, we employ a selection mechanism that identifies the most influential subset of segments based on their deviations from the majority within the given context. We will now delve into a more comprehensive explanation of our proposed model."
        },
        {
            "heading": "3.1 Context Encoder",
            "text": "We first divide one day\u2019s order flow into \ud835\udc41 segments of small time span \u0394\ud835\udc61 , where the time span of the n-th segment is represented as [\ud835\udc610+(\ud835\udc5b\u22121)\u0394\ud835\udc61, \ud835\udc610+\ud835\udc5b\u0394\ud835\udc61]. We define \ud835\udc610 as the start time of each trading day. To provide effective context information for the n-th segment, we leverage its previous M segments that have correlations in the information they cover.\nOur approach is motivated by the concept that the order book, which captures the pending orders at a specific time, serves as a snapshot of themarket, providing insights into traders\u2019 expectations regarding future market conditions [25]. Using historical data, we aim to predict the order book information for the n-th segment. By comparing the predicted order book with the actual one, we can infer the impact of historical information on the current state and use it as an important context for the n-th segment. For instance, if the predicted and actual order books are similar, we can conclude that the current state can be inferred from historical information, indicating the information from the n-th segment is less critical. So we can encode market state information and the extent to which it aligns with expectations as context. We will provide a detailed explanation of the components that make up the Context Encoder. Order Book Generator In the stock market, there is often continuity or consistency in the trading behavior of the same direction (buy/sell)[2, 13]. For instance, if a stock is consistently sold by sellers, it is likely to continue to be sold by sellers in the future. So, in order to model the behavior of buyers and sellers in financial markets, we train separate order book generators for buyers and sellers using historical order book and order flow information to predict the information of the n-th segment\u2019s order book. Specifically, for the\norder flow segment\ud835\udc4b\ud835\udc56 of time period [\ud835\udc610+(\ud835\udc56\u22121)\u0394\ud835\udc61, \ud835\udc610+\ud835\udc56\u0394\ud835\udc61], we first split it into buyer and seller order flows \ud835\udc4b\ud835\udc4f\ud835\udc56 and \ud835\udc4b\ud835\udc60\ud835\udc56 , respectively. We then calculate the accumulated volume of buy and sell orders at each price level in the \u0394\ud835\udc61 time range, referred to as the accumulated orders of the i-th segment, represented by \u0394\ud835\udc42\ud835\udc4f\ud835\udc56 = \ud835\udc420 \u2297 \ud835\udc4b\ud835\udc4f\ud835\udc56 and \u0394\ud835\udc42\ud835\udc60\ud835\udc56 = \ud835\udc420 \u2297 \ud835\udc4b\ud835\udc60\ud835\udc56 , where \ud835\udc420 represents the original empty order book, and \u2297 is the operation of generating new order books as defined in Equation (1).\nWe encode historical M segments of accumulated buy/sell orders using sequential neural models such as RNN/LSTM. For the segments \ud835\udc56 = \ud835\udc5b \u2212 \ud835\udc40, . . . , \ud835\udc5b \u2212 1, we define the hidden state of the sell/buy order generator as:\n\u210e\ud835\udc4f,\ud835\udc56 =\ud835\udc45\ud835\udc41\ud835\udc41\ud835\udc4f (\u210e\ud835\udc4f,\ud835\udc56\u22121,\u0394\ud835\udc42\ud835\udc4f\ud835\udc56 ) \u210e\ud835\udc60,\ud835\udc56 =\ud835\udc45\ud835\udc41\ud835\udc41\ud835\udc60 (\u210e\ud835\udc60,\ud835\udc56\u22121,\u0394\ud835\udc42\ud835\udc60\ud835\udc56 ).\n(2)\nWe use \ud835\udc3a\ud835\udc4f /\ud835\udc3a\ud835\udc60 to notate buy/sell orders generator. Since in real markets, the decision-making process of placing buy/sell orders often considers the actions of the opposing side, we incorporate information interaction in the buy/sell orders generator by sharing their hidden states. The generated accumulated buy/sell orders of segment n are given by\n\u0394\ud835\udc42\ud835\udc4f\ud835\udc5b = \ud835\udc3a\ud835\udc4f (\u210e\ud835\udc4f,\ud835\udc5b, \u210e\ud835\udc60,\ud835\udc5b) \u0394\ud835\udc42\ud835\udc60\ud835\udc5b = \ud835\udc3a\ud835\udc60 (\u210e\ud835\udc60,\ud835\udc5b, \u210e\ud835\udc4f,\ud835\udc5b).\n(3)\nTherefore, the predicted order book of the n-th segment is given by\n?\u0302?\ud835\udc5b = \ud835\udc42\ud835\udc5b\u22121 \u2295 \u0394\ud835\udc42\ud835\udc4f\ud835\udc5b \u2295 \u0394\ud835\udc42\ud835\udc60\ud835\udc5b, (4) where \u2295 represents the operation of combining two order books by summing volumes of each order book at corresponding price levels to obtain a new order book. Expectation-Reality ComparisonWe define the difference between two order books as the total distance in volume at the same\nprice levels. Here, we choose to use Euclidean distance. Therefore, for the n-th period, the measure of the difference between expected and actual order books is defined as:\n\ud835\udefe (\ud835\udc42\ud835\udc5b, ?\u0302?\ud835\udc5b) = \ud835\udc3e\u2211\ufe01 \ud835\udc58=1 | |\ud835\udc63\ud835\udc58\ud835\udc5b \u2212 \ud835\udc63\ud835\udc58\ud835\udc5b | |2, (5)\nwhere \ud835\udc3e represents the number of price levels in the order book, and \ud835\udc63\ud835\udc58\ud835\udc5b denotes the volume of orders at the \ud835\udc58-th price level in the nth period. The value of \ud835\udefe indicates the level of discrepancy between the expected and real order books. As our goal is to accurately model the behavior of buyers and sellers, we aim to optimize \ud835\udc3a\ud835\udc4f and \ud835\udc3a\ud835\udc60 by making the predicted order book as close as possible to the actual order book. The training objective of buy and sell generators is defined as\n\ud835\udc3f\ud835\udc54\ud835\udc52\ud835\udc5b = 1 \ud835\udc41 \ud835\udc41\u2211\ufe01 \ud835\udc5b=1 | |\ud835\udefe (\ud835\udc42\ud835\udc5b, ?\u0302?\ud835\udc5b ) | |2 . (6)\nContext Representation We concatenate expected and actual order books, along with the measure of their difference, as context for the n-th segment given previous\ud835\udc40 segments, denoted as \ud835\udc39\ud835\udc40\ud835\udc5b = \ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc50\ud835\udc4e\ud835\udc61 (\ud835\udc42\ud835\udc5b, ?\u0302?\ud835\udc5b, \ud835\udefe (\ud835\udc42\ud835\udc5b, ?\u0302?\ud835\udc5b)), where \ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc50\ud835\udc4e\ud835\udc61 is the concatenation operation."
        },
        {
            "heading": "3.2 Factor Extractor",
            "text": "In this section, we introduce a method for encoding important information in the n-th segment by considering the context of \ud835\udc39\ud835\udc40\ud835\udc5b . Additionally, we aim to identify the most crucial segments among the N segments. Transaction data, which captures every trade that takes place, provides a detailed and precise overview of market activity and allows for the analysis of market microstructure. In our\nstudy, we utilize transaction information from the n-th segment to extract relevant features.\nTransaction data consists of trades triggered by both active buy and active sell orders. An active buy order is placed by a trader who intends to purchase at the ask price, which is the price at which the seller is willing to sell the asset. This means that the trader is willing to pay a higher price for the asset. Conversely, an active sell order is an order filled at the bid price. Transaction data can provide insight into market sentiment and trader behavior. For example, a high ratio of active buy orders to active sell orders can indicate a bullish market sentiment, while a high ratio of active sell orders to active buy orders can indicate a bearish market sentiment.\nWe simplify notation by omitting the segment index \ud835\udc5b when it is clear from the context. For the n-th transaction order sequence \ud835\udc4d = {\ud835\udc671, \ud835\udc672, . . . , \ud835\udc67\ud835\udc3f}, we can get the active buy sequence \ud835\udc4d\ud835\udc4f = {\ud835\udc67\ud835\udc56 },\u2200\ud835\udc63\ud835\udc67\ud835\udc56 < 0 and the active sell sequence \ud835\udc4d\ud835\udc60 = {\ud835\udc67\ud835\udc56 },\u2200\ud835\udc63\ud835\udc67\ud835\udc56 > 0, where \ud835\udc3f is the length of order sequence. We then pass \ud835\udc4d through the feature encoding function \ud835\udc52\ud835\udc5b\ud835\udc50 (\u00b7), obtaining the transaction feature \ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60 = \ud835\udc52\ud835\udc5b\ud835\udc50 (\ud835\udc4d ) \u2208 R\ud835\udc3f\u00d7\ud835\udc51\ud835\udc52 , where \ud835\udc51\ud835\udc52 is the dimension of the feature encoding. This feature sequence is then input into a contextbased multi-head attention module to extract a feature vector for the segment. Conditional Attention Mechanism We propose an improved version of the traditional multi-head attention mechanism that is conditioned on the context representation \ud835\udc5f\ud835\udc40\ud835\udc5b = \ud835\udc52\ud835\udc5b\ud835\udc50 (\ud835\udc39\ud835\udc40\ud835\udc5b ), \ud835\udc5f\ud835\udc40\ud835\udc5b \u2208 R\ud835\udc51\ud835\udc52 ,where \ud835\udc52\ud835\udc5b\ud835\udc50 (\u00b7) is a d-dimensional encoding function. The attention function maps a query and a set of key-value pairs to an output. Queries, keys, and values are represented by matrices \ud835\udc44 , \ud835\udc3e , and \ud835\udc49 , respectively, defined as:\n\ud835\udc44\ud835\udc56 = \ud835\udc4b\ud835\udc4a \ud835\udc44\n\ud835\udc56 , \ud835\udc3e\ud835\udc56 = \ud835\udc4b\ud835\udc4a \ud835\udc3e \ud835\udc56 , \ud835\udc49\ud835\udc56 = \ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60\ud835\udc4a \ud835\udc49 \ud835\udc56 , (7)\nwhere\ud835\udc4a\ud835\udc44 \ud835\udc56 ,\ud835\udc4a\ud835\udc3e \ud835\udc56 \u2208 R2\ud835\udc51\ud835\udc52\u00d7\ud835\udc51\ud835\udc3e ,\ud835\udc4a\ud835\udc49 \ud835\udc56 \u2208 R\ud835\udc51\ud835\udc52\u00d7\ud835\udc51\ud835\udc49 are weight matrices, \ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60 \u2208 R\ud835\udc3f\u00d7\ud835\udc51\ud835\udc52 is the feature sequence of the transaction data, and \ud835\udc4b \u2208 R\ud835\udc3f\u00d72\ud835\udc51\ud835\udc52 represents the feature combined with context, defined as \ud835\udc4b = \ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc50\ud835\udc4e\ud835\udc61 (\ud835\udc38\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc60 , (1\ud835\udc51\ud835\udc52 )\ud835\udc47 \ud835\udc5f\ud835\udc40\ud835\udc5b ), where 1\ud835\udc51\ud835\udc52 is a \ud835\udc51\ud835\udc52 -dimensional vector whose elements are all 1. By utilizing this approach, we incorporate the context information into the query \ud835\udc44 and key \ud835\udc3e , thereby enabling the consideration of context information during the attention computation. Weighted Masked MatrixWe design a weighted masked matrix \ud835\udc40\ud835\udc4e\ud835\udc61 to avoid future information leakage and distinguish the role of transactions of the same type from those of different types.\ud835\udc40\ud835\udc4e\ud835\udc61 is formulated as\n\ud835\udc40\ud835\udc4e\ud835\udc61\ud835\udc56, \ud835\udc57 =  0, when \ud835\udc61\ud835\udc67\ud835\udc56 \u2264 \ud835\udc61\ud835\udc67 \ud835\udc57 \ud835\udc64, when \ud835\udc61\ud835\udc67\ud835\udc56 > \ud835\udc61\ud835\udc67 \ud835\udc57 and \ud835\udc63\ud835\udc67\ud835\udc56 \ud835\udc63\ud835\udc67 \ud835\udc57 > 0 1 \u2212\ud835\udc64, when \ud835\udc61\ud835\udc67\ud835\udc56 > \ud835\udc61\ud835\udc67 \ud835\udc57 and \ud835\udc63\ud835\udc67\ud835\udc56 \ud835\udc63\ud835\udc67 \ud835\udc57 < 0\n(8)\nFor the i-th head, the attention score matrix is defined as\nai = \ud835\udc60\ud835\udc5c \ud835\udc53 \ud835\udc61\ud835\udc5a\ud835\udc4e\ud835\udc65 ( \ud835\udc44\ud835\udc56\ud835\udc3e \ud835\udc47 \ud835\udc56\u221a \ud835\udc51\ud835\udc52 \u00b7\ud835\udc40\ud835\udc4e\ud835\udc61). (9)\nIn practice, we often observe that the influence between transactions of different types is more significant than that between transactions of the same type. To account for this, we assign a weight\ud835\udc64 < 0.5 in the masked matrix, indicating a higher influence between different types of transactions.\nTo reduce the number of values for \ud835\udc3f transactions, we apply a filtering process to retain only the most significant ones in each dimension. The output of each conditional attention head is calculated as \u210e\ud835\udc56 =\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc5d\ud835\udc5c\ud835\udc5c\ud835\udc59 (ai\ud835\udc49\ud835\udc56 ), (10) where\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc5d\ud835\udc5c\ud835\udc5c\ud835\udc59 (\u00b7) represents the max pooling operation, and \u210e\ud835\udc56 \u2208 R\ud835\udc51\ud835\udc3e is the resulting vector. The final extracted feature from\ud835\udc3b heads for segment \ud835\udc5b is defined as\n\ud835\udc39 \ud835\udc60\ud835\udc52\ud835\udc54 \ud835\udc5b = \ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc50\ud835\udc4e\ud835\udc61 (\u210e1, . . . , \u210e\ud835\udc3b )\ud835\udc4a\ud835\udc3b , (11)\nwhere\ud835\udc4a\ud835\udc3b \u2208 R\ud835\udc51\ud835\udc49 \u00d7\ud835\udc51\ud835\udc52 is a weight matrix. Optimization and Factor Utilization In order to obtain general factors for various downstream tasks, we set the loss function as an unsupervised objective to discover the most distinct and valuable stock information. We adopt DeepSVDD [27], one of the most effective unsupervised learning methods for identifying outliers in data streams. Figure 4 illustrates the optimization and utilization processes in our method. Specifically, we train a neural network as the kernel to map input space to a high-dimensional hypersphere (i.e. the output space). This hypersphere is defined by a radius \ud835\udc45 > 0 and a center \ud835\udc50 , allowing it to differentiate between normal data and outliers effectively. Given the context representation \ud835\udc39\ud835\udc40\n\ud835\udc56 and\nthe corresponding i-th transaction order sequence \ud835\udc4d\ud835\udc56 , the feature representation \ud835\udc39\ud835\udc60\ud835\udc52\ud835\udc54\n\ud835\udc56 can be generalized as:\n\ud835\udc39 \ud835\udc60\ud835\udc52\ud835\udc54 \ud835\udc56 = \ud835\udc53 (\ud835\udc4d\ud835\udc56 |\ud835\udc39\ud835\udc40\ud835\udc56 ;\ud835\udf03 ) (12)\nwhere \ud835\udf03 is the parameters of our microstructure-empowered stock factor extractor. Thus, given the sequence of input feature representations \ud835\udc6d = {\ud835\udc39\ud835\udc60\ud835\udc52\ud835\udc541 , \ud835\udc39 \ud835\udc60\ud835\udc52\ud835\udc54 2 , ..., \ud835\udc39 \ud835\udc60\ud835\udc52\ud835\udc54 \ud835\udc41 }, the optimizing objective is defined as\nmin \ud835\udc45,\ud835\udf03 \ud835\udc452 + 1 \ud835\udf07\ud835\udc41 \ud835\udc41\u2211\ufe01 \ud835\udc56=1 max{0, | |\ud835\udc39\ud835\udc60\ud835\udc52\ud835\udc54 \ud835\udc56 \u2212 \ud835\udc50 | |2 \u2212 \ud835\udc452} + \ud835\udf06 2 | |\ud835\udf03 | |2 (13)\nwhere hyperparameter \ud835\udf07 \u2208 (0, 1] controls the trade-off between the size of hypersphere and violations of its boundary, \ud835\udc50 is determined by random initialization. When applied to various downstream tasks, we utilize the parameter \ud835\udf07 to control the filtering proportions of significant signals. Minimizing \ud835\udc452 minimizes the volume of the hypersphere. The second term is a penalty term for points lying outside the sphere after being passed through the network (i.e. its\ndistance to the center | |\ud835\udc39\ud835\udc60\ud835\udc52\ud835\udc54 \ud835\udc56 \u2212 \ud835\udc50 | | is greater than radius \ud835\udc45), and the last term is a weight decay regularizer on the network parameters \ud835\udf03 with hyperparameter \ud835\udf06 > 0.\nDetermined by the design of our optimization objectives, segments exhibiting the most significant differences in group properties are assigned a relatively larger distance \ud835\udc51\ud835\udc56 = | |\ud835\udc39\ud835\udc60\ud835\udc52\ud835\udc54\ud835\udc56 \u2212 \ud835\udc50 | | from the center \ud835\udc50 of the hypersphere. Hence, the distance \ud835\udc51\ud835\udc56 can be used as the uniqueness indicator for identifying and selecting segments that are highly distinct from large amounts of order flow data. Based on the uniqueness indicator, we flexibly filter the number of signals (i.e., the selected features from order segment) by controlling the proportion coefficient \ud835\udf07, thereby applying them to different granularity levels of downstream tasks."
        },
        {
            "heading": "4 EXPERIMENT SETUPS",
            "text": "In this section, we give a brief introduction of our experiment setting, the order flow dataset collected from the microstructure stock market, and two downstream tasks we use these order flow features to assist: Daily Return Prediction and Order Execution (at the minute frequency). Generally, we first train the microstructureempowered stock factor extractor that excels in selecting important trading signals. Then, we apply this trained upstream model to the practical implementation of downstream tasks with different levels of granularity."
        },
        {
            "heading": "4.1 Dataset",
            "text": "We evaluate our model on real-world stock data. Our dataset consists of two parts: candlestick (at the daily frequency) as baseline daily factor extractor dataset, and high-frequency (10-ms) order flow data as our intra-day micro-factor extractor dataset. Our dataset is collected from the 10 most active stocks of CSI3003. The dataset ranges from Jan.02,2020 to Dec.31,2020, and we split the dataset according to the ratio of 7/1/4 to form the train/validation/test dataset.\nFor the daily candlesticks, we leverage 6 commonly used statistics attributes as daily features (i.e the highest price, the opening price, the lowest price, the closing price, the volume-weighted average 3CSI 300 is one of the major stock indices in the Chinese stock market, see more in CSI 300 Index.\nprice, and trading volume). For order flow data, we use a 4-second fixed time window and split approximately 4.56/0.67/2.64 million segments separately. We use price, size, and time (if applicable) as order flow features. All of the features are normalized by the Z-Score method to train our upstream and downstream models.\nOur dataset consists of a whole year of ten representative stock order flow data instead of a few days of a handful of stocks, which are commonly used in the existing works based on the microstructure market[17, 32, 40]. Therefore, performing validation experiments or conducting practical applications on our dataset is able to provide a more reliable and comprehensive assessment on the focused microstructure stock market."
        },
        {
            "heading": "4.2 Downstream Tasks",
            "text": "In this work, we propose a novel upstream model for feature extraction and we showcase its effectiveness through two distinct downstream tasks: Daily Return Prediction and Order Execution (at the minute frequency).\nIn the Daily Return Prediction task, we aim to predict the daily return of a stock, which is \ud835\udc66 = \ud835\udc5d\ud835\udc47+2/\ud835\udc5d\ud835\udc47+1 \u2212 1, where \ud835\udc5d\ud835\udc61 represents the close price of the stock at day \ud835\udc61 . For all of our comparison methods except the original daily prediction comparison method LSTM, we use order flow data to extract the intra-day factor as the micro supplementary information, concatenating with the daily factor generated by the LSTM baseline using candlesticks to make the daily prediction.\nIn the Order Execution task, we set the problem definition following the problem definition in [8], so our objective is to sell one unit of stock within a predetermined period and obtain the maximum profit. We use order flow factors to extract minute-frequency factors as additional input for the OPD teacher model. It will help the teacher model in training, and subsequently guide the training of the OPD student model."
        },
        {
            "heading": "4.3 Baselines",
            "text": "In our prediction tasks, we evaluate the performance of our model by comparing it with several competitive baselines. These are grouped into three distinctive groups:\nGroup 1: Base Models This group comprises the foundational models upon which our prediction tasks are based.\n\u2022 LSTM [12]: The original LSTMmodel uses only daily-frequency representations and no intra-day features. \u2022 Oracle Policy Distillation(OPD) [8]: OPD is a method for training deep reinforcement learning agents that aim to reduce execution costs for trading.\nGroup 2: Feature Extraction Methods The second group includes various methods for extracting intra-day features from stock transaction records. These extracted features serve as auxiliary information to be fed into the base models to improve their predictive performance.\n\u2022 Random Sample: Randomly extracted intra-day feature within single-day transaction record of stock. \u2022 Uniform Sample: Timed uniformly extracted intra-day feature within single-day transaction record of stock. \u2022 High-Freq LOB Feature [20]: Intra-day feature vectors of a stock can be extracted directly from LOB, including time-insensitive feature vectors and time-sensitive feature vectors. \u2022 Price-Based Transaction Factor: Extracted intra-day feature based on the maximum and minimum trade price within a single-day transaction record of stock. \u2022 Volume-Based Transaction Factor: Extracted intra-day feature based on the maximum and minimum trade volume within a single-day transaction record of stock. \u2022 Order Imbalance Factor [14]: A classical method to measure the imbalance of order by computing the log difference of the five best bids/ask level depth from the current depth of the best asks/bids. \u2022 Time-Sensitive Order Imbalance Factor [6, 30]: TimeSensitive order imbalance measures the difference between time-based limit ask and bid orders sequence using different level depth\u2019s volume, which is an important signal in market trading.\nGroup 3: Our Proposed Method and its Variants This group consists of our novel feature extraction model and its variants. They also extract features to be inputted into the base models to verify their effectiveness.\n\u2022 OurMethod (w/o CE, CAM): This variant removes the Context Encoder and Conditional Attention Mechanismmodules from our proposed method. \u2022 Our Method (w/o CE): This variant removes the Context Encoder and uses current real order book data as the context feature for the Conditional Attention Mechanism module. \u2022 Our Method (w/o Mat): This variant removes the Weighted Masked Matrix from our proposed method.\nThe features extracted by the methods in Groups 2 and 3 are added to the base models of Group 1 to assess their effectiveness."
        },
        {
            "heading": "4.4 Implementation Details",
            "text": "In this subsection, we introduce the practical implementation settings used in our upstream model and downstream tasks. Context Encoder For the Context Encoder, we set \ud835\udc40 = 100. The \ud835\udc45\ud835\udc41\ud835\udc41\ud835\udc60 and \ud835\udc45\ud835\udc41\ud835\udc41\ud835\udc4f are implemented as LSTM models, with hidden size of 64. \ud835\udc3a\ud835\udc60 and \ud835\udc3a\ud835\udc4f are implemented as MLP with hidden size 64.\nFactor Extractor For the Factor Extractor, we use a 1-layer Conditional Attention Mechanism with a hidden size of 16. The number of attention heads is set to 4. For the optimization objective expressed in Equation (13), we set \ud835\udf07 to 0.02 for the ratio of anomaly data and set \ud835\udf06 to 0.1 for the coefficient of \ud835\udc3f2 regularization.\nFor both components, the time step \u0394\ud835\udc61 is set to 4s, the learning rate is set to 1 \u00d7 10\u22123, and the Adam optimizer is used. All computations were performed on a Nvidia A100 GPU. Daily Return Prediction Settings To evaluate the performance of our prediction task, we use the top 2% of trading/order sequences as representative intra-day micro supplementary information and select related factors (i.e. price, volume, time, factor) from these sequences. These sequences are then processed by an MLP layer to generate a daily micro-mining frequency representation.\nWe use the Information Coefficient (IC, also known as the Pearson Correlation Coefficient), Rank Information Coefficient (Rank IC, also known as the Spearman Correlation Coefficient), and Rank Information Ratio (Rank IR) to evaluate the accuracy of daily return prediction. In particular, Rank IR is a measure of the consistency and robustness of the predictions.\n\ud835\udc45\ud835\udc4e\ud835\udc5b\ud835\udc58\ud835\udc3c\ud835\udc45 = Mean(\ud835\udc45\ud835\udc4e\ud835\udc5b\ud835\udc58\ud835\udc3c\ud835\udc36) Std(\ud835\udc45\ud835\udc4e\ud835\udc5b\ud835\udc58\ud835\udc3c\ud835\udc36) (14)\nOrder Execution Settings To evaluate the performance of our execution task, we extract the mean, median, maximum, minimum, variance, and range of the order flow factors at a minute frequency as supplementary features for the OPD teacher model, which then guides the training of the OPD student model.\nWe use the Price Advantage (PA), and Gain-Loss Ratio (GLR) as in [8] and compared their performance. PA and GLR are represented by the following equations, where \ud835\udc43\ud835\udc58\ud835\udc60\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc54\ud835\udc66 is the corresponding average execution price that our strategy has achieved on order \ud835\udc58 . \ud835\udc43\ud835\udc58 is the average market price of the instrument on the specific trading day. |\ud835\udc37 | is the size of the dataset.\n\ud835\udc43\ud835\udc34 = 104\n|\ud835\udc37 | |\ud835\udc37 |\u2211\ufe01 \ud835\udc58=1 ( \ud835\udc43 \ud835\udc58 \ud835\udc60\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc54\ud835\udc66 \ud835\udc43\ud835\udc58 \u2212 1) (15)\n\ud835\udc3a\ud835\udc3f\ud835\udc45 = \ud835\udc38 [\ud835\udc43\ud835\udc34 |\ud835\udc43\ud835\udc34 > 0] \ud835\udc38 [\ud835\udc43\ud835\udc34 |\ud835\udc43\ud835\udc34 < 0] (16)"
        },
        {
            "heading": "5 RESULTS",
            "text": "In this section, we demonstrate the validity of our model on realworld stock markets dataset. In order to validate that the factors extracted using our proposed framework can provide valuable information for stock trend prediction and support tasks at different granularity levels, we compare ourmethodwith a range of advanced baselines for both daily return prediction and order execution tasks. Our method shows promising results in extracting the most informative trading moments of the day from microsecond-frequency trading data, and it can be used for both two downstream tasks with daily and minute frequencies. Moreover, we conduct a series of ablation experiments, proving that our designed modules, namely the Content Encoder, Conditional Attention Mechanism andWeighted Masked Matrix, toward enhancing the overall performance of our method. Furthermore, in order to gain a deeper understanding of the model\u2019s performance, we conducted a case study within a specific trading segment of individual stocks. Our observations revealed a\nstrong alignment between the significant trading information segments extracted by our model and instances of imbalances within the order book, showing our model\u2019s ability to capture and reflect relevant financial phenomena."
        },
        {
            "heading": "5.1 Comparison with Baselines",
            "text": "Daily Return Prediction The performance of our method and other baselines of the daily return prediction downstream task are shown in Table 2. Comparing the simple feature extraction methods (i.e., Random Sample and Uniform Sample) to other rule-based methods in Group2, we can observe that incorporating intra-day features selected through reasonable rules rather than random selection from stock transaction records can enhance the performance of the model in predicting daily return. Specifically, compared to Random Sample and Uniform Sample, the other rule-based baselines in Group2 exhibits a noticeable improvement in all three metrics, which means selecting inter-day features with certain distinct characteristics in stocks is indeed important and can assist the model in predicting stock trends.\nBuilding upon this foundation, our proposed model achieves even better performance compared to the best-performing rulebased baseline (i.e., High-Freq LOB Feature), consistently achieving the best results across all evaluation metrics. Specifically, our approach outshines the best performing baseline method by 81% in IC, 91% in Rank IC, and 69% in Rank IR. These substantial improvements affirm the robustness and superior performance of our method in capturing the intricate dynamics of daily return predictions. In contrast to other baselines that rely on rigid rule-based factor extraction, our method demonstrates greater flexibility and adaptability to the ever-changing nature of stocks. Order Execution Unlike daily return prediction, which operates at a daily frequency, order execution is performed at a more granular level, specifically in minutes. The performance of our method and other baselines for order execution is shown in Table 3. Compare to the original OPDmodel, incorporating all of the rule-based methods from Group2 to extract intra-day features and integrating them into OPD leads to an enhancement in model performance.\nFurthermore, compare to Time-Sensitive Order Imbalance baseline, the rule-based model which shows the best performance in extracting intra-day features to support OPD, our proposed machine learning-based method exhibits an improvement of 38.64% in PA, and an improvement 3% in GLR, demonstrating our method\u2019s effectiveness in optimizing the order execution task."
        },
        {
            "heading": "5.2 Ablation Study",
            "text": "Table 2 and 3 present the results of the ablation study on the proposed method. Our method(w/o CE, CAM) refers to removing the Context Encoder and Conditional Attention Mechanism modules. Our method(w/o CE) refers to removing the Context Encoder and using current real order book data as the context feature for the Conditional Attention Mechanism module. Our method(w/o Mat) refers to removing the Weighted Masked Matrix.\nThe results indicate that our method(w/o CE, CAM) outperforms all other baselines on the two downstream tasks, however it falls short of the performance of our method(w/o CE). Furthermore, our\nmethod demonstrates superior performance over these two variants. This suggests that historical order books can provide effective contextual information for modeling transaction data segments and supports the effectiveness of our Context Encoder in extracting market expectation information on the current state. Additionally, the performance of our method(w/o Mat) was also evaluated and resulted in a decline in performance. This further verifies that the Weighted Masked Matrix module is reasonable for modeling the dynamic interactions between buyers and sellers in transaction data and brings performance improvement."
        },
        {
            "heading": "5.3 Case Study",
            "text": "To get a deeper understanding of how our method works, we randomly sample a trading day and visualized the uniqueness indicators captured by our approach. In Figure 5, \"Volume of bid side in LOB\" refers to the volume of buy orders at the top 5 levels of the order book. \"Ratio of inflow volume size\" 5 refers to the proportion of larger and smaller orders.\nThe price trend in themarket is influenced by the ongoing competition between long and short positions, and identifying the turning points in this competition is crucial. As shown in Figure 5, our method identifies a concentrated accumulation of uniqueness indicators (i.e., red triangles) in interval B (11:18-13:03). We can discern that the B interval aligns with the turning point of the trend, which demonstrates the effectiveness of our method in capturing stock trend information through uniqueness indicators.\nFrom a deeper perspective of stock trading, by comparing the order flow data in interval B to the fluctuating interval A (11:00- 11:10), we observe a significant imbalance of orders in interval B. For instance, at point \ud835\udc56 (11:19:28), we observe a dramatic increase in the proportion of large inflow volume size, from 38.4% to 54.5%, indicating institutional intervention in the market and the initiation\n4On November 30, 2020, we selected stock 000568.SZ from the China stock market as our target for analysis. 5The division rules of larger(XL/L) order and smaller(M/S) order can be seen in Ratio of inflow volume size.\nof upward price movement by the main force. At point \ud835\udc57 (11:25:36), buyers have already established dominance as evidenced by a 33.0% (54.2% to 87.2%) increase in the proportion of bid volume, and this is followed by a sustained upward trend in stock prices. This illustrates that our model successfully captures the predictive signals preceding the upward price movement, which holds significant implications for investment decision-making."
        },
        {
            "heading": "6 CONCLUSIONS",
            "text": "In this paper, we introduce a method that utilizes order flow data to model and extract important trading details to enhance stock trend analysis. We propose a framework for extracting stock factors that leverages historical order flow data to capture contextual information and extract informative factors from the microstructure market. Moreover, we demonstrate the effectiveness of our method in two downstream tasks with varying temporal granularities by using a comprehensive year-long dataset from the real-world."
        }
    ],
    "title": "Microstructure-Empowered Stock Factor Extraction and Utilization",
    "year": 2023
}