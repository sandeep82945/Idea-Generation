{
    "abstractText": "Human beings are highly familiar over-learnt social targets, with similar physical facial morphology between perceiver and target. But does experience with or similarity to a social target determine whether we can accurately infer emotions from their facial displays? Here, we test this question across two studies by having human participants infer emotions from facial displays of: dogs, a highly experienced social target but with relatively dissimilar facial morphology; panins (chimpanzees/ bonobos), inexperienced social targets, but close genetic relatives with a more similar facial morphology; and humans. We find that people are more accurate inferring emotions from facial displays of dogs compared to panins, though they are most accurate for human faces. However, we also find an effect of emotion, such that people vary in their ability to infer different emotional states from different species\u2019 facial displays, with anger more accurately inferred than happiness across species, perhaps hinting at an evolutionary bias towards detecting threat. These results not only compare emotion inferences from human and animal faces but provide initial evidence that experience with a non-human animal affects inferring emotion from facial displays.",
    "authors": [
        {
            "affiliations": [],
            "name": "S. Kezia Sullivan"
        },
        {
            "affiliations": [],
            "name": "Ahyoung Kim"
        },
        {
            "affiliations": [],
            "name": "Lucio Vinicius Castilho"
        },
        {
            "affiliations": [],
            "name": "Lasana T. Harris"
        }
    ],
    "id": "SP:b102199e6e58f4ee1470273735fe176bd70652b4",
    "references": [
        {
            "authors": [
                "V.S. Kwan",
                "S.T. Fiske"
            ],
            "title": "Missing links in social cognition: The continuum from nonhuman agents to dehumanized humans",
            "venue": "Soc. Cog",
            "year": 2008
        },
        {
            "authors": [
                "A. Gopnik",
                "A.N. Meltzoff"
            ],
            "title": "Words, Thoughts, and Theories",
            "year": 1997
        },
        {
            "authors": [
                "A. Gopnik",
                "H.M. Wellman"
            ],
            "title": "Why the child\u2019s theory of mind really is a theory",
            "venue": "Mind Lang. 7(1\u20132),",
            "year": 1992
        },
        {
            "authors": [
                "R.M. Gordon"
            ],
            "title": "Folk psychology as simulation",
            "venue": "Mind Lang. 1(2),",
            "year": 1986
        },
        {
            "authors": [
                "J. Heal"
            ],
            "title": "Simulation, Theory, and Content. In Theories of Theories of Mind (eds Carruthers, P",
            "year": 1996
        },
        {
            "authors": [
                "F. De Vignemont",
                "T. Singer"
            ],
            "title": "The empathic brain: how, when and why",
            "venue": "Trends Cog. Sci. 10(10),",
            "year": 2006
        },
        {
            "authors": [
                "V. Gallese"
            ],
            "title": "The shared manifold hypothesis: From mirror neurons to empathy",
            "venue": "J. Consci. Stud. 8(5\u20136),",
            "year": 2001
        },
        {
            "authors": [
                "R.J. Britten"
            ],
            "title": "Divergence between samples of chimpanzee and human DNA sequences is 5%, counting indels",
            "venue": "Proc. Nat. Aca. Sci",
            "year": 2002
        },
        {
            "authors": [
                "A.M. Burrows",
                "B.M. Waller",
                "L.A. Parr",
                "C.J. Bonar"
            ],
            "title": "Muscles of facial expression in the chimpanzee (Pan troglodytes): Descriptive, comparative and phylogenetic contexts",
            "venue": "J. Anat. 208(2),",
            "year": 2006
        },
        {
            "authors": [
                "B. Hare",
                "M. Tomasello"
            ],
            "title": "Human-like social skills in dogs",
            "venue": "Trends Cog. Sci. 9(9),",
            "year": 2005
        },
        {
            "authors": [
                "J.W. Bradshaw",
                "H.M. Nott"
            ],
            "title": "Social and Communication Behaviour of Companion Dogs",
            "year": 1995
        },
        {
            "authors": [
                "S.J. Lycett",
                "M. Collard",
                "W.C. McGrew"
            ],
            "title": "Cladistic analyses of behavioural variation in wild Pan troglodytes: Exploring the chimpanzee culture hypothesis",
            "venue": "J. Human Evo",
            "year": 2009
        },
        {
            "authors": [
                "M. Bekoff"
            ],
            "title": "The Emotional Lives of Animals: A Leading Scientist Explores Animal Joy, Sorrow, and Empathy\u2014and why",
            "venue": "They Matter (New World Library,",
            "year": 2007
        },
        {
            "authors": [
                "K. Guo",
                "D. Tunnicliffe",
                "H. Roebuck"
            ],
            "title": "Human spontaneous gaze patterns in viewing of faces of different species",
            "venue": "Perception 39(4),",
            "year": 2010
        },
        {
            "authors": [
                "N. Kanwisher",
                "D. Stanley",
                "A. Harris"
            ],
            "title": "The fusiform face area is selective for faces not animals",
            "venue": "NeuroReport 10(1),",
            "year": 1999
        },
        {
            "authors": [
                "M. Wan",
                "N. Bolger",
                "F.A. Champagne"
            ],
            "title": "Human perception of fear in dogs varies according to experience with dogs",
            "venue": "PLoS ONE 7(12),",
            "year": 2012
        },
        {
            "authors": [
                "N Albuquerque"
            ],
            "title": "Dogs recognize dog and human emotions",
            "venue": "Bio. Lett. 12(1),",
            "year": 2016
        },
        {
            "authors": [
                "J. Kaminski",
                "B.M. Waller",
                "R. Diogo",
                "A. Hartstone-Rose",
                "A.M. Burrows"
            ],
            "title": "Evolution of facial muscle anatomy in dogs",
            "venue": "Proc. Nat. Aca. Sci",
            "year": 2019
        },
        {
            "authors": [
                "F. Amici",
                "J. Waterman",
                "C.M. Kellermann",
                "K. Karimullah",
                "J. Br\u00e4uer"
            ],
            "title": "The ability to recognize dog emotions depends on the cultural milieu in which we grow",
            "venue": "up. Sci. Rep. 9(1),",
            "year": 2019
        },
        {
            "authors": [
                "Van Hooff",
                "J.A.R.A. M"
            ],
            "title": "The Facial Displays of the Catarrhine Monkeys and Apes",
            "venue": "In Primate Ethology (ed. Morris,",
            "year": 1967
        },
        {
            "authors": [
                "W.D. Hopkins",
                "J.P. Taglialatela",
                "D.A. Leavens"
            ],
            "title": "Do Chimpanzees have Voluntary Control of Their Facial Expressions and Vocalizations",
            "year": 2011
        },
        {
            "authors": [
                "L.A. Parr",
                "S. Preuschoft",
                "F.B. de Waal"
            ],
            "title": "Afterword: Research on Facial Emotion in Chimpanzees, 75 years Since Kohts",
            "venue": "In Infant Chimpanzee and Human Child (eds Ladygina-Kohts,",
            "year": 2002
        },
        {
            "authors": [
                "P. Ekman"
            ],
            "title": "Cross-cultural Studies of Facial Expression",
            "venue": "In Darwin and Facial Expression: A Century of Research in Review (ed. Ekman,",
            "year": 1973
        },
        {
            "authors": [
                "J.P. Gulledge",
                "S. Fern\u00e1ndez-Carriba",
                "D.M. Rumbaugh",
                "D.A. Washburn"
            ],
            "title": "Judgments of monkey\u2019s (Macaca mulatta) facial expressions by humans: Does housing condition \u201caffect",
            "venue": "countenance?. Psych. Rec. 65(1),",
            "year": 2015
        },
        {
            "authors": [
                "J. Panksepp"
            ],
            "title": "Affective consciousness: Core emotional feelings in animals and humans",
            "venue": "Consci. Cog",
            "year": 2005
        },
        {
            "authors": [
                "P. Pongr\u00e1cz",
                "C. Moln\u00e1r",
                "A. Mikl\u00f3si",
                "V. Cs\u00e1nyi"
            ],
            "title": "Human listeners are able to classify dog (Canis familiaris) barks recorded in different situations",
            "venue": "J. Comp. Psych. 119(2),",
            "year": 2005
        },
        {
            "authors": [
                "D. D\u00f6ring",
                "A. Roscher",
                "F. Scheipl",
                "H. K\u00fcchenhoff",
                "M.H. Erhard"
            ],
            "title": "Fear-related behaviour of dogs in veterinary practice",
            "venue": "Vet. J. 182(1),",
            "year": 2009
        },
        {
            "authors": [
                "C. Boesch"
            ],
            "title": "Hunting Strategies of Gombe and Tai chimpanzees",
            "venue": "In Chimpanzee Cultures (eds Wrangham, R. et al.)",
            "year": 1994
        },
        {
            "authors": [
                "W.A. Mason",
                "S.V. Saxon",
                "L.G. Sharpe"
            ],
            "title": "Preferential responses of young chimpanzees to food and social rewards",
            "venue": "Psych. Rec. 13(3),",
            "year": 1963
        },
        {
            "authors": [
                "V. Trezza",
                "P.J. Baarendse",
                "L.J. Vanderschuren"
            ],
            "title": "The pleasures of play: Pharmacological insights into social reward mechanisms",
            "venue": "Trends Pharm. Sci",
            "year": 2010
        },
        {
            "authors": [
                "M. Bekoff"
            ],
            "title": "Wild justice and fair play: Cooperation, forgiveness, and morality in animals",
            "venue": "Bio. Phil",
            "year": 2004
        },
        {
            "authors": [
                "F. Range",
                "C. Ritter",
                "Z. Vir\u00e1nyi"
            ],
            "title": "Testing the myth: Tolerant dogs and aggressive wolves",
            "venue": "Proc. Royal Soc. B: Bio. Sci",
            "year": 2015
        },
        {
            "authors": [
                "R.M. Wittig",
                "C. Boesch"
            ],
            "title": "Decision-making in conflicts of wild chimpanzees: An extension of the relational model",
            "venue": "Beh. Eco. and Sociobio",
            "year": 2003
        },
        {
            "authors": [
                "M. Reimers",
                "F. Schwarzenberger",
                "S. Preuschoft"
            ],
            "title": "Rehabilitation of research chimpanzees: Stress and coping after long-term isolation",
            "venue": "Horm. Beh. 51(3),",
            "year": 2007
        },
        {
            "authors": [
                "S. Schwartz"
            ],
            "title": "Separation anxiety syndrome in dogs and cats",
            "venue": "J. Am. Vet. Med. Assoc. 222(11),",
            "year": 2003
        },
        {
            "authors": [
                "J.E. Steiner",
                "D. Glaser",
                "M.E. Hawilo",
                "K.C. Berridge"
            ],
            "title": "Comparative expression of hedonic impact: Affective reactions to taste by human infants and other primates",
            "venue": "Neuro. Biobeh. Rev. 25(1),",
            "year": 2001
        },
        {
            "authors": [
                "D. Alderton"
            ],
            "title": "Animal Grief: How Animals",
            "venue": "Mourn (Veloce Publishing,",
            "year": 2011
        },
        {
            "authors": [
                "E Hydbring-Sandberg"
            ],
            "title": "Physiological reactions to fear provocation in dogs",
            "venue": "J. Endocrin",
            "year": 2004
        },
        {
            "authors": [
                "T. Bloom",
                "H. Friedman"
            ],
            "title": "Classifying dogs\u2019 (Canis familiaris) facial expressions from photographs",
            "venue": "Behav. Process. 96,",
            "year": 2013
        },
        {
            "authors": [
                "L.A. Parr",
                "B.M. Waller",
                "S.J. Vick",
                "K.A. Bard"
            ],
            "title": "Classifying chimpanzee facial expressions using muscle action",
            "venue": "Emotion 7(1),",
            "year": 2007
        },
        {
            "authors": [
                "B.M. Waller",
                "J. Micheletta"
            ],
            "title": "Facial expression in nonhuman animals",
            "venue": "Emot. Rev. 5(1),",
            "year": 2013
        },
        {
            "authors": [
                "B.M. Waller",
                "J. Whitehouse",
                "J. Micheletta"
            ],
            "title": "Rethinking primate facial expression: A predictive framework",
            "venue": "Neuro. Biobeh. Rev",
            "year": 2022
        },
        {
            "authors": [
                "L.F. Barrett",
                "R. Adolphs",
                "S. Marsella",
                "A.M. Martinez",
                "S.D. Pollak"
            ],
            "title": "Emotional expressions reconsidered: Challenges to inferring emotion from human facial movements",
            "venue": "Psych. Sci. Pub. Interest",
            "year": 2019
        },
        {
            "authors": [
                "V. Sevillano",
                "S.T. Fiske"
            ],
            "title": "Animals as social objects",
            "venue": "Euro. Psych. 21(3),",
            "year": 2016
        },
        {
            "authors": [
                "V. Gallese",
                "A. Goldman"
            ],
            "title": "Mirror neurons and the simulation theory of mind-reading",
            "venue": "Trends Cog. Sci",
            "year": 1998
        },
        {
            "authors": [
                "L. Carr",
                "M. Iacoboni",
                "M.C. Dubeau",
                "J.C. Mazziotta",
                "G.L. Lenzi"
            ],
            "title": "Neural mechanisms of empathy in humans: a relay from neural systems for imitation to limbic areas",
            "venue": "Proc. Nat. Aca. Sci",
            "year": 2003
        },
        {
            "authors": [
                "H.A. Elfenbein",
                "N. Ambady"
            ],
            "title": "When familiarity breeds accuracy: Cultural exposure and facial emotion recognition",
            "venue": "J. Pers. Soc. Psych. 85(2),",
            "year": 2003
        },
        {
            "authors": [
                "N. Ambady",
                "R. Rosenthal"
            ],
            "title": "Nonverbal communication. Encyc",
            "venue": "Mental Health",
            "year": 1998
        },
        {
            "authors": [
                "K.R. Scherer"
            ],
            "title": "Vocal communication of emotion: A review of research paradigms",
            "venue": "Speech Commun. 40(1\u20132),",
            "year": 2003
        },
        {
            "authors": [
                "C. Correia-Caeiro",
                "K. Guo",
                "D. Mills"
            ],
            "title": "Bodily emotional expressions are a primary source of information for dogs, but not for humans",
            "venue": "Anim. Cog",
            "year": 2021
        },
        {
            "authors": [
                "O Langner"
            ],
            "title": "Presentation and validation of the Radboud faces database",
            "venue": "Cog. Emot",
            "year": 2010
        },
        {
            "authors": [
                "S.J. Vick",
                "B.M. Waller",
                "L.A. Parr",
                "M.C. Smith Pasqualini",
                "K.A. Bard"
            ],
            "title": "A cross-species comparison of facial morphology and movement in humans and chimpanzees using the facial action coding system (FACS)",
            "venue": "J. Nonverb. Beh. 31(1),",
            "year": 2007
        },
        {
            "authors": [
                "L.A. Parr"
            ],
            "title": "The discrimination of faces and their emotional content by chimpanzees (Pan troglodytes)",
            "venue": "Ann. N.Y. Aca. Sci. 1000(1),",
            "year": 2003
        },
        {
            "authors": [
                "J.J. Carrasco",
                "D. Georgevsky",
                "M. Valenzuela",
                "P.D. McGreevy"
            ],
            "title": "A pilot study of sexual dimorphism in the head morphology of domestic dogs",
            "venue": "J. Vet. Beh.: Clin. App. Res",
            "year": 2014
        },
        {
            "authors": [
                "E.M. Weston",
                "A.E. Friday",
                "R.A. Johnstone",
                "F. Schrenk"
            ],
            "title": "Wide faces or large canines? The attractive versus the aggressive primate",
            "venue": "Proc. R. Soc. London B Bio. Sci. 271(6),",
            "year": 2004
        },
        {
            "authors": [
                "D. Lantos",
                "L.T. Harris"
            ],
            "title": "The humanity inventory: Developing and validating an individual difference measure of dehumanization propensity",
            "venue": "J. Theor. Soc. Psych",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "1 Vol.:(0123456789) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\nwww.nature.com/scientificreports"
        },
        {
            "heading": "Comparing emotion inferences",
            "text": "from dogs (Canis familiaris), panins (Pan troglodytes/Pan paniscus), and humans (Homo sapiens) facial displays S. Kezia Sullivan1, Ahyoung Kim1, Lucio Vinicius Castilho2,3 & Lasana T. Harris1*\nHuman beings are highly familiar over-learnt social targets, with similar physical facial morphology between perceiver and target. But does experience with or similarity to a social target determine whether we can accurately infer emotions from their facial displays? Here, we test this question across two studies by having human participants infer emotions from facial displays of: dogs, a highly experienced social target but with relatively dissimilar facial morphology; panins (chimpanzees/ bonobos), inexperienced social targets, but close genetic relatives with a more similar facial morphology; and humans. We find that people are more accurate inferring emotions from facial displays of dogs compared to panins, though they are most accurate for human faces. However, we also find an effect of emotion, such that people vary in their ability to infer different emotional states from different species\u2019 facial displays, with anger more accurately inferred than happiness across species, perhaps hinting at an evolutionary bias towards detecting threat. These results not only compare emotion inferences from human and animal faces but provide initial evidence that experience with a non-human animal affects inferring emotion from facial displays.\nThe human ability to infer other species\u2019 (hereafter \u2018animals\u2019) mind is well documented1. When humans infer other human minds, they can integrate statistical information about the context, target, and prior experiences (first-person or vicarious) to test models or hypotheses about how the target might think or feel2,3. Alternatively, they can simulate what the other is thinking or feeling and use such self-generated interoceptive information to guide the inference4,5. These accounts of social cognition hold implications for the inference of emotions from facial displays; either recognition through learned or experienced associations with contextual information6, or automatic recognition through covert imitation and mirror neuron activity7 due to perceived similarity of the perceiver with the target. However, the question remains whether either strategy is used when inferring the minds of agents beyond humans such as animals. Here, we test whether inferring emotions from facial displays depends on experience with or similarity to an animal target.\nWe compare emotion inferences from dogs (Canis familiaris), bonobos/chimpanzees (Pan paniscus/Pan troglodytes, hereafter referred to as panins), and humans (Homo sapiens) facial displays. We employ dogs and panins as animal targets due to the shared genetic ancestry and facial morphology in the case of the latter8,9, and shared environment in the case of the former10, to differentiate between the roles of morphological similarities and experience when inferring emotions from facial display. Both species have complex social lives11,12, with rules that must be obeyed if an individual is to be accepted\u00a0by a group. As such, it is expected that they will communicate internal states with facial displays during social interactions13. Moreover, people\u2019s gaze patterns when viewing animal and human faces are similar; particular attention is paid to the eye and mouth areas, the moving parts of the face14. Further, although the fusiform face area in the medial temporal lobe of the brain is most strongly activated by human faces, it also responds to animal faces15.\nDogs are often considered human\u2019s closest animal companion; humans have interacted with wolves from as early as the Middle Pleistocene period and tamed these wolf pups, who later became the precursors of\nOPEN\n1Department of Experimental Psychology, University College London, London, England. 2Department of Anthropology, University College London, London, England. 3Department of Anthropology, University of Z\u00fcrich, Z\u00fcrich, Switzerland. *email: lasana.harris@ucl.ac.uk\n2 Vol:.(1234567890) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\ndomesticated dogs11. Further, many people live with dogs, and therefore have extensive experience with dog\u2019s emotional responses and corresponding facial displays. This makes dogs a highly experienced animal. There is a wealth of research demonstrating ways that the symbiotic relationship between dogs and humans may have led to adaptations in the social functioning of both species; Humans can accurately categorise the facial displays of dogs16, and dogs can accurately categorise both the facial displays of dogs and humans17. Domestication affected dogs\u2019 facial muscle anatomy to facilitate communication with humans18. Experience with dogs also has an effect; dog professionals are more accurate at inferring emotions from dog facial displays and behaviour16, and people with personal or cultural experiences with dogs accurately infer emotions from their facial displays earlier in life19.\nIn contrast, panins are closely genetically related to humans, and share similar facial morphology and social hierarchies9 making them a highly similar animal to humans. Although panins have similar facial muscles to humans, they do not express emotion in facial displays the same way humans do. For instance, bare teeth in humans (i.e., smile) may indicate happiness, but to panins, it is a signal of safety20. Panins also have a measure of voluntary control over their facial displays21\u2014differentiating them from other mammals such as dogs that cannot control their facial displays, highlighting the similarity between chimpanzee and human emotion regulation. Panins use facial displays to communicate with each other and maintain social bonds22. However, humans rarely encounter panins, instead viewing them from a distance, if at all. Naive human participants cannot reliably infer the emotion displayed by a chimpanzee, though they can perform at levels above chance23. Moreover, humans distinguish between happy (kept in social housing) macaque monkeys (genetically more closely related to humans than dogs, but with a less recent shared ancestor as panins) and unhappy macaques (kept in isolation), despite lacking the experience to support the inference from facial displays and having fewer facial and genetic similarities compared to panins24.\nCore emotional circuits are common amongst mammals, including fear, rage, and play, and certain generalizable situations cause neurological patterns that are likely to correspond approximately to physiological patterns in all mammals, even humans25. Therefore, emotions are situationally determined where self-report is not available, such as in animals (see26, for a similar approach). For example, dogs display a fear response to veterinary treatment27, whilst panins often demonstrate fear of or submissive aversion to other, more dominant apes28. Both humans and panins find affiliative social contact positively reinforcing, eliciting joy or pleasure29,30, and play evokes pleasure in both panins and dogs31,32. Combat and conflict promote anger responses in the animal species33,34, and they have also been shown to dislike isolation35,36.\nFor this study, we chose emotions with the most robust scientific support for their analogous presence in dogs and panins; specifically, happiness or pleasure33,37, sadness or displeasure36,38, fear28,39, and anger40,41. The secondary rationale for choosing these facial displays is that they each have clearly defined emotional antecedents or contextual determinants. Finally, previous research has explored human inferences of emotion from facial displays in both species of animals19,40,41. Therefore, when considering the emotions of animals, it is reasonable to accept situationally defined approximations of well-established emotional responses. We do however acknowledge that animal facial displays may be indices of future behaviour rather than emotional experience42,43, and even human facial displays may not underlie true emotional experience44.\nLastly, inferring emotions from animals may engage anthropomorphism. Since humans perceive dogs as protective, high in warmth and competence, while chimpanzees as threatening, high in competence but low in warmth45, dogs and panins may be differently anthropomorphised.\nHere, we directly test whether experience with or similarity to an animal matters for inferring emotion from their facial displays. Across two studies, participants perform an emotion categorisation task where they must select the correct emotion that corresponds to a facial display from humans, dogs, and panins. The presence of imitative brain systems: motor facilitation in the same muscles used by the person being observed46 and; similar activation patterns during observation and expression47 may allow for higher accuracy when inferring emotion from panin than dog facial displays. Conversely, recent exposure to members of a culture improved both the speed and accuracy of emotion inference of Chinese participants who lived in either China or the USA, regardless of participant\u2019s own cultural background48. This suggests experience impacts inferring emotion from facial displays, which may allow for higher accuracy when inferring emotions from dog than panin facial displays. Further, we focus on animals\u2019 differentiable facial displays in different contexts or when engaged in different behaviours. As such, we define accuracy as inference of the emotion of the animal consistent with the context or behaviour.\nStudy 1: results Accuracy. We found a significant main effect of species, Wald \u03c72 (2) = 4319.42, p < .001, such that participants were most accurate for human faces (M = 0.95, SE = 0.01) compared to panin (M = 0.46, SE = 0.01; LSD Mdiff = 0.49, SEdiff = 0.02, p < .001, 95% CI [0.47, 0.50]) and dog faces (M = 0.60, SE = 0.01; LSD Mdiff = 0.35, SEdiff = 0.02, p < .001, 95% CI [0.33, 0.36]). However, participants were significantly more accurate for dog than panin faces; LSD Mdiff = 0.14, SEdiff = 0.02, p < .001, 95% CI [0.13, 0.16].\nWe also found a significant main effect of emotion, Wald \u03c72(3) = 271.39, p < .001, such that participants were most accurate for happy (M = 0.76, SE = 0.01) and neutral faces (M = 0.77, SE = 0.01) relative to sad (M = 0.56, SE = 0.01) and fearful inferences from faces (M = 0.60, SE = 0.01). Specifically, we failed to find a significant difference between accuracy for happy and neutral inference from faces; LSD Mdiff = 0.01, SEdiff = 0.02, p = .431, 95% CI [\u2212 0.02, 0.04], and fear and sad inferences from faces; LSD Mdiff = 0.05, SEdiff = 0.02, p = .002, 95% CI [0.02, 0.08]. All other inferences from faces differed significantly on accuracy (all p\u2019s < .001).\nBoth main effects were qualified by a significant species X emotion interaction, Wald \u03c72(6) = 471.63, p < .001 (see Fig.\u00a01). To unpack this interaction, we consider comparisons that were not significant within species (see Table\u00a01 for all simple effect\u00a0results). Happy, sad, and fearful inferences from human faces (happy-sad LSD\n3 Vol.:(0123456789) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\nMdiff = 0.01 SE = 0.01, p = .203, 95% CI [\u2212 0.01, 0.03]; happy-fearful LSD Mdiff = 0.02 SE = 0.01, p = .074, 95% CI [\u2212 0.00, 0.04]; sad-fearful LSD, Mdiff = 0.01, SE = 0.01, p = .387, 95% CI [\u2212 0.01, 0.02]), did not differ in accuracy from each other, but all differed from neutral inferences from human faces, suggesting that participants performed equally well inferring emotion from human facial displays, but were less accurate inferring neutral from facial displays.\nSad and fearful inferences from dog faces (LSD Mdiff = 0.05, SE = 0.03, p = .145, 95% CI [\u2212 0.22, 0.11]), and happy and neutral inferences from dog faces (LSD Mdiff = 0.07, SE = 0.03, p = .005, 95% CI [0.02, 0.12]) did not differ in accuracy, but participants were significantly better at inferring happy and neutral from dog faces from the two avoidant negative emotions. This suggests that participants struggled to infer negative avoidant emotions from facial displays in dog faces.\nFor panin faces, we found that participants were best at inferring neutral, then happy, then fearful, then sad from facial displays (all p\u2019s < .001).\nWhen further considering the emotion \u00d7 species interaction, there is a consistent pattern of highest accuracy for inferences of emotion from human, then dog, then panin faces across all facial displays (all p\u2019s < .001), except for neutral inferences from dog and panin faces which did not differ; LSD Mdiff = 0.04, SEdiff = 0.02, p = .038, 95% CI [0.002, 0.09].\nReaction time. We found no significant main effects or interactions when exploring categorisation speed, suggesting participants may have found the task equally challenging across all conditions.\nConfidence. We found a significant species main effect, F (2, 292) = 229.62, p < .001, \u03b7p2 = 0.61, \u03a9 = 1.00. Follow-up pairwise comparisons revealed a significant difference between humans and dogs (Mdiff = 23.41, SE = 1.90, p < .001, 95% CI [19.66, 27.16]), humans and panins (Mdiff = 41.71, SE = 2.02, p < .001, 95% CI [37.71, 45.72]), and dogs and panins (Mdiff = 18.31, SE = 1.93, p < .001, 95% CI [14.49, 22.12]). This suggests that participants were most confident inferring human facial displays, and least confident inferring panin facial displays, with dogs in the middle.\nCorrelations. We found a significant correlation between experience and confidence for inferences of emotion from dog facial displays, r (143) = 0.29, p < .001, such that more experience was related to increased confidence. We did not observe a significant correlation for panins, r (143) = 0.11, p = .181.\nWe also found a significant correlation between dog experience and reaction time, r (143) = 0.38, p < .001 such that participants more experienced with dogs took longer to infer emotions from their facial displays. We did not observe a significant correlation for panins, r (143) = 0.01, p = .905. This perhaps is an artefact of the circumstances participants encounter the animals, with dog\u2013human interactions likely to occur in domestic contexts, while panin-human interactions likely to occur in captive contexts.\nWe also found a significant correlation between dog, r (131) = 0.19, p = .032 and panin experience and accuracy, r (143) = 0.27, p = .001, such that participants more experienced with both species were more accurate at inferring emotion from their facial displays. This is consistent with both theorising and previous literature.\nFinally, we also found a significant correlation between confidence in inferring human facial displays and reaction time, r (145) = \u2212 0.22, p = .006, such that people who were more confident were faster to categorise human facial displays. We did not find significant correlations for confidence and reaction time for any other species (all p\u2019s > .050). We also did not find significant correlations between confidence and accuracy for any species (all p\u2019s > .050). This suggest that a meta-cognitive evaluation was only relevant for human faces, the species participants felt most confident categorising.\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n1\nSad Fear Happy Neutral\nDog Panin Human\nA cc\nur ac y (p ro po rt io n of c or\nre ct\nin fe\nre nc\ne)"
        },
        {
            "heading": "Emotion Display",
            "text": "Figure\u00a01. Proportion of accurate emotion inferences from facial displays in Study 1. Error bars represent standard error. All bars within emotion category are significantly different.\n4 Vol:.(1234567890) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\nTable 1. Main effects and interaction on accuracy of emotion inferences across species and emotions in Study 1. *significant at Bonferroni corrected p < .0013; (^) marginally significant.\n(I) (J) Mean diff. (I\u2013J) Std. error Sig.\n95% wald confidence interval for difference\nLower Upper\nEmotion main effect\nHappy Sad .199* .013 > .001 .173 .225\nHappy Fear .153* .017 > .001 .119 .186\nFear Sad .046^ .015 .002 .017 .075\nNeutral Happy .012 .016 .431 \u2212 .018 .043\nNeutral Sad .211* .018 > .001 .177 .246\nNeutral Fear .165* .015 > .001 .136 .194\nSpecies main effect\nDog Bonobo/chimp .143* .009 > .001 .126 .160\nHuman Dog .346* .008 > .001 .330 .362\nHuman Bonobo/chimp .489* .008 > .001 .474 .504\nEmotion \u00d7 Species interaction\n\u00a0Dog comparisons across emotions\nHappy Sad .360* .024 > .001 .312 .407\nHappy Fear .314* .031 > .001 .255 .373\nHappy Neutral .070^ .025 .005 .021 .119\nFear Sad .046 .031 .145 \u2212 .016 .107\nNeutral Sad .290* .030 > .001 .231 .348\nNeutral Fear .244* .027 > .001 .192 .296\n\u00a0Bonobo/chimpanzee comparisons across emotions\nHappy Sad .226* .025 > .001 .177 .275\nHappy Fear .018 .010 .074 \u2212 .002 .037\nFear Sad .101* .021 > .001 .060 .141\nNeutral Happy .169* .029 > .001 .112 .225\nNeutral Sad .395* .027 > .001 .342 .448\nNeutral Fear .295* .021 > .001 .253 .336\n\u00a0Human comparisons across emotions\nHappy Sad .010 .008 .203 \u2212 .005 .026\nHappy Fear .018 .010 .074 \u2212 .002 .037\nHappy Neutral .062* .011 > .001 .041 .083\nSad Fear .008 .009 .387 \u2212 .010 .025\nSad Neutral .052* .012 > .001 .029 .074\nFear Neutral .044* .012 > .001 .021 .067\n\u00a0Happy comparisons across species\nHuman Dog .182* .017 > .001 .149 .216\nHuman Bonobo/chimp .465* .020 > .001 .427 .503\nDog Bonobo/chimp .283* .022 > .001 .239 .327\n\u00a0Sad comparisons across species\nHuman Dog .532* .020 > .001 .493 .572\nHuman Bonobo/chimp .682* .156 > .001 .651 .712\nDog Bonobo/chimp .149* .020 > .001 .110 .189\n\u00a0Fear comparisons across species\nHuman Dog .479* .020 > .001 .440 .518\nHuman Bonobo/chimp .573* .015 > .001 .544 .603\nDog Bonobo/chimp .095* .019 > .001 .057 .132\n\u00a0Neutral comparisons across species\nHuman Dog .191* .019 > .001 .154 .227\nHuman Bonobo/chimp .235* .019 > .001 .197 .273\nDog Bonobo/chimp .044^ .021 .038 .002 .085\n5 Vol.:(0123456789) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\nStudy 2 We followed Study 1 with a second study aimed at replicating the findings and broadening the emotion inferences. The most substantiative difference reduced the number of emotions to three, replacing fear and sadness with anger. Though anger is also a negatively valenced emotion, it is an approach emotion, and a conspecific with a facial display of anger and directed gaze is a threat, unlike one displaying sadness or fear. We kept most other aspects of the study the same (see the Methods Section for other minor differences)."
        },
        {
            "heading": "Results",
            "text": "Accuracy scores. We found a significant main effect of species, Wald \u03c72 (2) = 529.85, p < .001, such that participants were most accurate for human faces (M = 0.79, SE = 0.02) compared to panin (M = 0.48, SE = 0.01; LSD Mdiff = 0.30, SEdiff = 0.01, p < .001, 95% CI [0.28, 0.33]) and dog faces (M = 0.61, SE = 0.02; LSD Mdiff = 0.18, SEdiff = 0.01, p < .001, 95% CI [0.15, 0.21]). However, participants were significantly more accurate for dog than panin faces, LSD Mdiff = 0.12, SEdiff = 0.02, p < .001, 95% CI [0.09, 0.15], replicating Study 1.\nWe also found a significant main effect of emotion, Wald \u03c72(2) = 29.59, p < .001, such that participants were more accurate inferring anger (M = 0.70, SE = 0.02) than happiness (M = 0.61, SE = 0.02) and neutral from facial displays (M = 0.57, SE = 0.02). We failed to find a significant difference between accuracy for happy and neutral inferences from faces; LSD Mdiff = 0.03, SEdiff = 0.03, p = .197, 95% CI [\u2212 0.02, 0.09]. However, participants were more accurate inferring angry than happy (LSD Mdiff = 0.09, SEdiff = 0.03, p = .001, 95% CI [0.04, 0.14] and neutral from faces (LSD Mdiff = 0.13, SEdiff = 0.02, p < .001, 95% CI [0.08, 0.17]).\nBoth main effects were qualified by a significant species \u00d7 emotion interaction, Wald \u03c72(4) = 83.77, p < 0.001 (see Fig.\u00a02). To unpack this interaction, we consider comparisons that were not significant within species (see Table\u00a02 for all simple effect results). Accuracy rates for happy and angry inferences from human\u00a0faces were not different (LSD Mdiff = 0.04 SE = 0.02, p = .051, 95% CI [0.00, 0.07]), but neutral inferences from human faces were significantly less accurate than both. This suggests that participants performed equally well when inferring emotions from human facial displays, but were less accurate when inferring neutral from facial displays, replicating the finding from Study 1.\nInferences of happy and neutral from dog faces did not\u00a0significantly differ in accuracy (LSD Mdiff = 0.04, SE = 0.04, p = .285, 95% CI [\u2212 0.03, 0.11]), but participants were significantly more accurate inferring angry than happy or neutral from dog faces. This suggests that participants did not struggle to infer negative approach emotions from facial displays in dogs. Coupled with the results of Study 1, it suggests that positive approach emotions are better inferred from dog faces, though there seems to be a boost for anger\u2014a negative approach emotion\u2014potentially as a threat signal.\nFor panin faces, we found that accuracy did not differ when participants inferred angry and neutral, LSD Mdiff = 0.02, SE = 0.04, p = 0.666, 95% CI [\u2212 0.05, 0.08], nor happy and neutral from faces, LSD Mdiff = 0.08, SE = 0.04, p = 0.064, 95% CI [0.00, 0.16]. nor anger and happy from faces, LSD Mdiff = 0.09, SE = 0.04, p = .031, 95% CI [0.01, 0.17].\nWhen further considering the species \u00d7 emotion interaction, there is a consistent pattern with participants showing the highest accuracy when inferring emotions from human, then dog, then panin faces across all facial displays (all p\u2019s < .0021), except for neutral inferences from dog and panin faces, LSD Mdiff = 0.06, SE = 0.03, p = .036, 95% CI [0.004, 0.11], again replicating Study 1.\nReaction times (RT). There were no significant main effects or interactions for the reaction time measure, replicating the results of Study 1.\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n1\nAngry Happy Neutral\nDog Panin Human\nA cc\nur ac y (p ro po rt io n of c or re ct\nin fe\nre nc\nes )"
        },
        {
            "heading": "Emotion Display",
            "text": "Figure\u00a02. Proportion of accurate emotion inferences from facial displays in Study 2. Error bars represent standard error. All bars within emotion category are significantly different.\n6 Vol:.(1234567890) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\nConfidence. We found a significant species main effect, F (2, 262) = 13.59, p < .001, \u03b7p2 = 0.09, \u03a9 = 1.00. Follow-up pairwise comparisons revealed a significant difference between confidence ratings when inferring emotions\u00a0 from humans and dogs (Mdiff = 5.87, SE = 1.70, p = 0.001, 95% CI [2.50, 9.24]), humans and panins (Mdiff = 8.33, SE = 2.00, p < .001, 95% CI [4.46, 12.20]), and dogs and panins (Mdiff = 2.46, SE = 1.17, p = .037, 95% CI [0.15, 4.76]). This suggests that participants were most confident inferring emotion from human facial displays followed by dog facial displays, and least confident inferring emotion from panin facial displays. These results replicate the findings in Study 1.\nCorrelations. We found a significant correlation between dummy coded experience and confidence ratings for emotion inferences from panin faces, r (130) = 0.19, p = .027, as well as for dog faces, r (130) = 0.32, p < .001, such that more experience was related to increased confidence.\nWe found a significant correlation between dummy coded experience and reaction time when inferring emotion from dog facial displays, r (130) = 0.20, p = .020 such that participants who were more experienced with dogs took longer to infer emotion from their facial displays. The time experience variable did not significantly correlate with any other measures for dogs or panins, and we did not find a significant correlation between dummy coded experience and accuracy, reaction time, or confidence for emotion inferences from panin facial displays (all p\u2019s > .050).\nTable 2. Main effects and interaction on accuracy of emotion inferences across species and emotions in Study 2. *significant at Bonferroni corrected p < .0021; (^) marginally significant.\n(I) (J) Mean diff. (I\u2013J) Std. error Sig.\n95% wald confidence interval for difference\nLower Upper\nEmotion main effect\nAngry Happy .092* .027 .001 .039 .145\nHappy Neutral .034 .026 .197 \u2212 .018 .086\nAngry Neutral .126* .024 > .001 .080 .172\nSpecies main effect\nDog Bonobo/chimp .123* .015 > .001 .093 .153\nHuman Dog .181* .013 > .001 .155 .207\nHuman Bonobo/chimp .304* .014 > .001 .277 .331\nEmotion \u00d7 species interaction\n\u00a0Dog comparisons across emotions\nAngry Happy .222* .045 > .001 .137 .308\nAngry Neutral .182* .032 > .001 .120 .244\nNeutral Happy .040 .038 .285 \u2212 .034 .114\n\u00a0Bonobo/chimpanzee comparisons across emotions\nAngry Happy .091^ .042 .031 .008 .173\nNeutral Happy .076 .041 .064 \u2212 .004 .156\nAngry Neutral .015 .041 .666 \u2212 .054 .084\n\u00a0Human comparisons across emotions\nHappy Angry .037 .019 .051 \u2212 .0001 .073\nHappy Neutral .218* .027 > .001 .166 .271\nAngry Neutral .182* .028 > .001 .127 .237\n\u00a0Happy comparisons across species\nHuman Dog .354* .031 > .001 .294 .413\nHuman Bonobo/chimp .444* .027 > .001 .391 .498\nDog Bonobo/chimp .091* .028 .001 .037 .145\n\u00a0Angry comparisons across species\nHuman Dog .095* .028 .001 .041 .149\nHuman Bonobo/chimp .317* .029 > .001 .260 .374\nDog Bonobo/chimp .222* .027 > .001 .169 .276\n\u00a0Neutral comparisons across species\nHuman Dog .095* .023 > .001 .049 .141\nHuman Bonobo/chimp .150* .025 > .001 .100 .200\nDog Bonobo/chimp .056^ .026 .036 .004 .107\n7 Vol.:(0123456789) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\nWe also found a significant correlation between confidence in inferring dog facial displays and reaction time, r (130) = 0.32, p < .001, such that participants who were more confident of their inference also took longer. No other correlation between experience and accuracy reached significance when inferring emotion from dog facial displays, and there was no significant correlation between confidence and accuracy or reaction time (all p\u2019s > .050) when inferring emotion from human facial displays."
        },
        {
            "heading": "Discussion",
            "text": "The primary aim of this study was to investigate whether experience or similarity best explain inferring emotions from facial displays of non-human animals. To test this, we pitted a domesticated and experienced species with very different facial morphology to humans (dogs) against species\u00a0with a more similar facial morphology but much less likely to be encountered by our participants (panins). We found\u00a0evidence that participants were more accurate inferring dog than panin facial displays. Correlational evidence suggests that higher experience with either animal is associated with increased accuracy inferring emotion from that animals\u2019 facial displays. This suggests that people are using their past experiences with the animal to infer emotions from facial displays.\nWe also explored emotion inference from human faces. In addition to better accuracy for human than animal faces, interestingly, we found that participants had more difficulty inferring neutral from human facial displays than the more emotional inferences; a difficulty they did not suffer with the animal inferences. This suggests a difference between how people infer emotions from human and animal faces, perhaps relying on more emotionspecific or mimicry mechanisms for human faces and learning mechanisms for animals. There may also be a predisposition towards inferring emotions from human facial displays that is not present for animals.\nThe pattern of results for the second study replicates the first as participants were more accurate inferring emotions from dog than panin facial displays. In addition, we found that there was no species advantage for inferring anger displays, consistent with an evolutionary preserved mechanism to detect threat. These results provide further support for the role of experience in inferring emotion from facial displays, though with the important caveat that when emotion inference is in service of threat perception, neither experience nor similarity modulate the effect.\nOur findings replicate evidence in the literature demonstrating that humans can accurately categorise dog facial displays of emotion, perhaps because of experience with dogs, or changes in dogs\u2019 facial morphology to facilitate communication with humans16,18. We find that participants inferred emotions from dogs faces with varying degrees of accuracy. Angry inferences were most accurate, and participants performed significantly better than for happy inferences from dogs. However, happy inferences were significantly more accurate than sad and fear inferences; both latter inferences were also significantly more\u00a0accurate than\u00a0neutral inferences. This suggests a bias towards inferring the face as a threat (angry) or safety (happy) stimulus, over emotional inferences related to the negative well-being of the animal (fear, sad).\nWe find that emotion inferences for panins were also comfortably above-chance levels, along with dogs and humans, with only sad inferences in Study 1 just above chance. Also in Study 1, we find evidence consistent with the literature showing that humans more accurately infer happy than sad from macaque faces24. This suggests a bias towards accurate inferences from the face as a safety signal. However, Study 2 showed no difference between any of the emotions, urging caution when interpreting the results for panins.\nCaution interpreting panin results relative to dogs is also needed\u00a0when examining the meta-cognitive confidence ratings from participants. They felt most confident in their human inferences, followed by dogs, then panins. Moreover, confidence was correlated with experience for dogs across both studies, and panins only in Study 2, suggesting that more familiarity with the species boosted meta-cognitive self-perceptions of performance. Confidence was also correlated negatively with human inference reaction time in Study 1, and positively correlated with dog inference reaction time in Study 2, suggesting different impacts of confidence on performance across the two species.\nAcross both studies we found support for an effect of experience on emotion inference; we found significant correlations between experience and accuracy for dog faces in both studies, and panins in Study 1. Experience also correlated with reaction time for dogs across both studies, but not panins, suggesting that experience impacts performance primarily for the domesticated animal.\nWe found that angry\u00a0facial displays were recognized regardless of species, providing evidence for an evolutionarily preserved threat detection mechanisms regardless of similarity or experience. Interestingly we found that angry\u00a0displays were marginally more accurate than neutral displays for panins, and all emotions were inferred less accurately relative to neutral displays for panins. This suggests that perhaps participants used their mirror system to simulate panin facial displays, reducing accuracy for the faces in emotional situations since these displays use different facial muscles than humans.\nThere are several limitations with our studies, beyond the debate regarding whether animals experience emotions. It is commonly known that dogs use other parts of the body, such as wagging their tail, to express their emotions11, and humans can even recognise the emotions of dogs by just listening to their barks26, suggesting that dog faces may not be the most prominent cue for emotion recognition. Indeed, though humans also rely on human\u00a0body posture49 and prosody to convey\u00a0and infer emotions50, dogs rely on body language to a greater extent than humans do51. Therefore, dog facial displays may not be the most prominent cue for emotion inference. We also did not design our study to test for participant gender differences, therefore we collected unequal samples of men and women in both studies.\nIn addition, facial displays in panins rely on different muscle configurations to communicate emotions than similar human emotional displays, despite the similar facial morphology41. Nonetheless, humans were better at recognising the emotions of dogs by merely looking at their faces. This clearly shows how experiences, like the amount of exposure to non-conspecific animals, override biological roots like homology of facial muscles when\n8 Vol:.(1234567890) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\nhumans infer\u00a0emotions in non-human animals. Additionally, we did not include all emotions in one study, so we cannot compare anger inferences with sad or fear. Finally, Study 1 is more complex than Study 2 because we include four emotion options rather than three.\nWe also conflated two types of experience in our study\u2014experience with a domesticated versus captive animal. Participants in our sample were more likely to encounter domesticated dogs, and captive panins, adding a confound to our results. Finally, our participants read stories about dogs and chimpanzees before completing the emotion inference task, and rated them on several characteristics, which could have influenced their performance on the emotion inference task. However, this exploratory variable did not interact with any of our reported main effects or interactions, suggesting that this exploratory task did not differentially impact our participants.\nFuture research could investigate the role of species domesticity in our understanding of animal facial displays, as well as other factors which affect whether anthropomorphic thinking manifests as increased or decreased accuracy of judgements regarding animal behaviours. Future research could also explicitly manipulate the experience or similarity of an animal, and test whether these variables enhance emotion recognition from facial displays."
        },
        {
            "heading": "Method",
            "text": "Participants. Study 1. We recruited participants using an opportunity sample via social media advertisements and a psychology subject pool. Those who were recruited from the subject pool were awarded course credits for participation. There were no differences based on the source of participants. In total, 147 United Kingdom participants completed the study, comprised of 113 female and 31 male participants, as well as 3 participants who identified as other, between the ages of 18 and 71, Mage = 32.40\u00a0years, SDage = 13.60. Post-hoc power analyses revealed that we had sufficient power to detect a medium effect size, 1\u2212\u03b2 = 0.79. All participants were informed that they could leave the study at any time without consequence and gave their full informed consent before beginning the study. The study was approved by the University College London Ethics Committee; all experimental protocols were approved by this body, and all methods were carried out in accordance with relevant guidelines and regulations.\nStudy 2. We collected data from 132 United States participants via Amazon Mechanical Turk; 36 females and 96 males (Mage = 32.02\u00a0years, SDage = 8.14, age range: 22\u201361\u00a0years); 51 White participants, 52 Asian participants, 16 Hispanic participants, and 13 Black other ethnicities participants. Post-hoc power analyses revealed that we had sufficient power to detect a medium effect size, 1\u2212\u03b2 = 0.80. Participants were paid $1USD. We obtained ethical approval from the University College London Ethics Committee; all experimental protocols were approved by this body, and all methods were carried out in accordance with relevant guidelines and regulations.\nMaterials and procedure. Across two studies, participants viewed facial displays associated with emotional situations or contexts and inferred the correct facial display to the associated emotion derived in that context. We used 8 images of each facial display for each species-emotion combination, for a total of 96 images in Study 1, and 6 images of each combination in Study 2, for a total of 54 images. We used equal numbers of males and females for human faces.\nStudy 1. We used Qualtrics to build the experiment. Participants viewed facial displays of three species (human, dog, panin), displaying emotions in four situations likely to evoke emotions (happy, sad, scared, neutral). There were 8 photographs for each category, so participants viewed 96 photos in total. The background of the photo was not visible; they were cropped so that only the face was visible to participants to avoid contextual information from the photo being used for emotion inference.\nThe photos of humans were used with permission from the Radboud database52. Only photos of people of phenotypically European descent were used (there was no race or ethnic diversity), and gender was balanced for each emotional category. The photographs of dogs were obtained with permission from a professional pet photographer (www. thedo gphot ograp her. co. uk, 2018), and from Shutterstock Images (https:// www. shutt ersto ck. com, 2018), and showed a variety of breeds. Dog breeds in which head shape has been heavily selected, such as pugs, were avoided; instead, the photos were primarily of gundogs and mongrels. The number of dogs with erect and non-erect ears within each emotional category were balanced to prevent ear shape affecting the perception of the participants. Previous research depicted dogs in\u00a0situations proven to evoke specific emotional responses, such as fear provoked by the presence of nail clippers40; therefore, the photos used in this study depicted a range of situations known to evoke specific emotions in most dogs to support the probable presence of the emotion (see Table\u00a03).\nThis situation-emotion matching approach was also used when selecting photographs of panins (see Table\u00a01). Expert evolutionary anthropologists have developed a facial coding system for chimpanzees (ChimpFACS53;) and they can discriminate between facial displays of chimpanzees54. One such experienced researcher provided photographs of bonobos and chimpanzees, and kindly categorized them into facial displays based on extensive experience of panin behaviour. These facial displays were then matched to likely emotions based on background information from the photo or photo source. No distinction was drawn between bonobos and chimpanzees (Pan paniscus and Pan troglodytes), and photos were not gender balanced for panins or dogs, as their facial sexual dimorphism, whilst present55,56, is not clearly visible to most humans.\nParticipants first read an anthropomorphic or mechanistic short story regarding a dog and a chimpanzee. Then, on seven-point Likert scale from \u2018not at all\u2019 to \u2018very\u2019, they rated chimpanzees on being organised, neat, careful, in control of its actions, and sensitive in the anthropomorphism condition, and strong, easily hurt, large, dark coloured, and disciplined in the mechanistic condition, while they rated dogs on disciplined, lazy, thoughtful, easily hurt, and loyal in the anthropomorphism condition, and big, in control of its actions, furry, carnivorous, and\n9 Vol.:(0123456789) Scientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2\nsensitive in the mechanistic condition. Those data were collected for exploratory reasons and will not be discussed further. Nonetheless, we tested whether this exploratory variable affected responses on the main dependent variable, and found no significant main effects of interactions (all p\u2019s > .108 across both studies).\nParticipants clicked the link to the study to be directed to the website to begin. After reading an information sheet and filling in a consent form, they read the anthropomorphic or mechanistic short story followed by the rating questions.\nThey then saw the photos of the faces in a random order and indicated via mouse clicks which of the four emotions (happy, sad, fearful, neutral) best described the facial display in a forced choice format. There was no time limit. They then indicated their experience with dogs and chimpanzees by describing this experience (e.g. owned a dog for 4 years). We dummy coded these responses for analyses. Next, they rated their overall confidence in categorizing the faces from the three species on a Likert scale from 0 (no confidence) to 100 (very confident). They then completed an individual difference measure of flexible social cognition57 for exploratory purposes; we do not report the results of this measure. Finally, they provided demographic information, were debriefed, and thanked.\nStudy 2. We followed up the initial study with a second study that aimed to replicate these findings in a different sample. We used the same materials and followed the same procedure in Study 2 as Study 1 with a few exceptions. First, we reduced the number of emotions to three by eliminating sad and fearful and replacing them with anger: a negatively valenced approach emotion that serves as a threat signal when inferred in another. This allows us to determine whether all negatively valenced emotions are inferred the same way. Moreover, directed gazes displaying anger suggest that the entity with the face is a threat to the perceiver and therefore should trigger evolutionarily preserved threat-detection mechanisms.\nSecond, participants pressed a key to indicate their emotion choice rather than clicking the corresponding label on the screen. This change in response style facilitated more efficient and perhaps rapid responses. It also allows us to determine whether the null effects for reaction time are due to the response style or replicate across response style.\nThird, we built the experiment with Gorilla experiment builder rather than Qualtrics, changing software platforms to rule out that the effect only occurred on a single online survey building platform.\nFourth, we asked about experience with the non-human animals by first having participants indicate the type of experience they had (dogs; dog owner, looked after dog, petted other people\u2019s dog, other; chimpanzees; seen them in a zoo, watched them on TV, other) before indicating the amount of time they had this experience. We dummy coded types of experience as in Study 1 (dummy coded experience) and treated it as a separate variable from the amount of time (time experience). This change allowed us to get two experience dependent variables.\nFifth, we reduced the number of images per stimulus type from 8 to 6, resulting in a total of 54 images to shorten the length of the experiment. Finally, we asked participants to indicate which part of the face they paid most attention to when completing the task for each of the three species\u00a0for exploratory reasons. All other procedures and materials remained the same. We kept all other elements of the design the same except where just noted.\nData analysis strategy. The data analysis strategy remained the same across both studies. We used SPSS (V27) to analyse the data. The data were checked for normality using Box\u2019s Test of Equality of Covariances of Means, and the reaction time data were transformed by Log10, therefore no outliers were removed from the reaction time or accuracy data. We converted accuracy to a proportion, such that 1.00 reflected perfect accuracy. We aggregated the data by averaging over the 8 trials in each of the 12\u00a0(Study 1) or 9 (Study 2)\u00a0types of stimuli. To test the hypothesis that species affect categorisation accuracy, we completed Wald chi-square tests. This analysis deviated from our pre-registration of Study 2 where we stated we would perform parametric analyses. We computed a repeated measures ANOVA to investigate the effect of facial display of emotion and species on reaction time, and a second repeated measures ANOVA to determine whether participants expressed different levels of confidence in their ability to categorise the species. We corrected for multiple comparisons on the above inferential statistics with Bonferroni correction where appropriate. We used both Bonferroni corrected significance level and whether the confidence interval range included zero as criteria to determine statistical significance in our simple effect tests. Finally, we correlated experience, confidence, reaction time, and accuracy within species.\nTable 3. Contextual instantiation of emotion in non-human facial displays.\nSpecies Emotion Situation Relevant literature\nDogs\nHappy Playing with other dog/on a walk Bekoff31\nSad Left tethered alone/stray in poor condition Schwartz36\nScared Handled by a vet D\u00f6ring et\u00a0al.27\nBonobos/Chimpanzees\nHappy Showing affiliative behaviour or play face Steiner et\u00a0al.37\nSad Isolated/in poor condition due to recent rescue Alderton38\nScared Moving away from confrontation/scream face Boesch28\n10\nVol:.(1234567890)\nScientific Reports | (2022) 12:13171 | https://doi.org/10.1038/s41598-022-16098-2"
        },
        {
            "heading": "Data availability",
            "text": "The data is available at https:// osf. io/ n9z5q/. Study 2 is preregistered at https:// aspre dicted. org/ MWX_ SC1.\nReceived: 15 March 2022; Accepted: 4 July 2022"
        },
        {
            "heading": "Acknowledgements",
            "text": "We would like to thank Dr. Lisa Parr and Del Waghorn for providing, and relevant expertise about the stimuli used in the experiments."
        },
        {
            "heading": "Author contributions",
            "text": "S.K.S., L.V.C. and L.T.H. designed the study. S.K.S. and A.K. built the experiment and collected the data. S.K.S., A.K., and L.T.H. analysed the data. All authors wrote the manuscript. S.K.S. and L.T.H. created the tables, and L.T.H. created the figures."
        },
        {
            "heading": "Funding",
            "text": "This research was funded by the Division of Psychology and Language Sciences, University College London."
        },
        {
            "heading": "Competing interests",
            "text": "The authors declare no competing interests."
        },
        {
            "heading": "Additional information",
            "text": "Correspondence and requests for materials should be addressed to L.T.H.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n\u00a9 The Author(s) 2022"
        }
    ],
    "title": "Comparing emotion inferences from dogs (Canis familiaris), panins (Pan troglodytes/Pan paniscus), and humans (Homo sapiens) facial displays",
    "year": 2022
}