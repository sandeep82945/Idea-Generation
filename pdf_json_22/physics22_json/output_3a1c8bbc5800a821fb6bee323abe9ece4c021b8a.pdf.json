{
    "abstractText": "By a symmetry argument, a synethic aperture radar collection along a linear path does not collect threedimensional information about the scene. However, it is known that vertical curvature can be used to derive some vertical position information. This paper approaches the problem from a monopulse perspective, resulting in a non-iterative computation that commutes with efficient image formation algorithms. 1",
    "authors": [
        {
            "affiliations": [],
            "name": "Mark Story"
        }
    ],
    "id": "SP:46b0e77f11de670e4d22894380d4d3dda0faf6d5",
    "references": [
        {
            "authors": [
                "C.V.J. Jakowatz",
                "D.E. Wahl",
                "P.H. Eichel",
                "D.C. Ghiglia",
                "P.A. Thompson"
            ],
            "title": "Spotlightmode synthetic aperture radar: a signal processing approach",
            "venue": "Springer Science & Business Media,",
            "year": 1996
        },
        {
            "authors": [
                "A.W. Doerry",
                "D.L. Bickel"
            ],
            "title": "Synthetic aperture radar height of focus",
            "venue": "tech. rep., Sandia National Lab. (SNL-NM), Albuquerque, NM (United States), 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A.W. Doerry",
                "D.L. Bickel"
            ],
            "title": "Impact of radar flightpath on synthetic aperture radar image height of focus",
            "venue": "Radar Sensor Technology XXVI (K. I. Ranney and A. M. Raynal, eds.), vol. 12108, p. 121080V, International Society for Optics and Photonics, SPIE, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "W.N. Barnes",
                "T.H. Gauss"
            ],
            "title": "Improved height above target (hat) measurement algorithm",
            "venue": "Nov. 3 1998. US Patent 6,831,563.",
            "year": 1998
        },
        {
            "authors": [
                "K. Knaell"
            ],
            "title": "Three-dimensional SAR from curvilinear apertures",
            "venue": "Algorithms for Synthetic Aperture Radar Imagery (D. A. Giglio, ed.), vol. 2230, pp. 120 \u2013 134, International Society for Optics and Photonics, SPIE, 1994.",
            "year": 1994
        },
        {
            "authors": [
                "K. Knaell",
                "G. Cardillo"
            ],
            "title": "Radar tomography for the generation of three-dimensional images",
            "venue": "IEE Proceedings-Radar, Sonar and Navigation, vol. 142, no. 2, pp. 54\u201360, 1995.",
            "year": 1995
        },
        {
            "authors": [
                "K. Knaell"
            ],
            "title": "Three-dimensional SAR from practical apertures",
            "venue": "Radar/Ladar Processing and Applications, vol. 2562, pp. 31\u201341, International Society for Optics and Photonics, 1995.",
            "year": 1995
        },
        {
            "authors": [
                "C.D. Austin",
                "R.L. Moses"
            ],
            "title": "Wide-angle sparse 3D synthetic aerture radar imaging for nonlinear flight paths",
            "venue": "2008 IEEE National Aerospace and Electronics Conference, pp. 330\u2013 336, 2008.",
            "year": 2008
        },
        {
            "authors": [
                "J.A. Jackson",
                "R.L. Moses"
            ],
            "title": "Synthetic aperture radar 3D feature extraction for arbitrary flight paths",
            "venue": "IEEE Transactions on Aerospace and Electronic Systems, vol. 48, no. 3, pp. 2065\u2013 2084, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "D. Andr\u00e9"
            ],
            "title": "An analysis of 3D SAR from single pass nonlinear radar platform trajectories",
            "venue": "Algorithms for Synthetic Aperture Radar Imagery XVII, vol. 7699, pp. 71\u201382, SPIE, 2010.",
            "year": 2010
        },
        {
            "authors": [
                "T. Henderson"
            ],
            "title": "Matched beam theory for unambiguous broadband direction finding",
            "venue": "The Journal of the Acoustical Society of America, vol. 78, no. 2, pp. 563\u2013574, 1985.",
            "year": 1985
        },
        {
            "authors": [
                "T.L. Henderson",
                "T.J. Brudner"
            ],
            "title": "A space\u2013 time filtered gradient method for detecting directions of echoes and transient sounds",
            "venue": "The Journal of the Acoustical Society of America, vol. 118, no. 2, pp. 679\u2013695, 2005. 8",
            "year": 2005
        }
    ],
    "sections": [
        {
            "text": "By a symmetry argument, a synethic aperture radar collection along a linear path does not collect threedimensional information about the scene. However, it is known that vertical curvature can be used to derive some vertical position information. This paper approaches the problem from a monopulse perspective, resulting in a non-iterative computation that commutes with efficient image formation algorithms. 1"
        },
        {
            "heading": "1 Introduction",
            "text": "Synthetic Aperture Radar (SAR) depicts radar reflectivity as a two-dimensional image in range and azimuth relative to the aperture traced out by the path of the platform. A three-dimensional point cloud can be created from two or more appropriately matched SAR images, using interferometric SAR or radargrammetric stereo (as in, for example, [1]). But for a SAR image from a linear aperture, no information is present about the position of a scatterer along a the circle centered on a line through that aperture and lying on a plane perindicular to it. This follows from simple symmetry arguments.\nHowever, when the aperture is not linear, the symmetry is broken. Formation of a sharply-focused two-\n1Research sponsored by Oak Ridge National Laboratory, managed by UT-Battelle, LLC, for the U. S. Department of Energy.\ndimensional image requires compensating for out-ofplane motion using assumed height of scatterers, typically on the ground plane [1]. Conversely, objects in an image with height differing from the assumed ground plane may appear to be out of focus.\nThis depth of focus issue for curvilinear apertures, together with its implication for height estimation, has been most recently studied by [2], [3]. The use of quadratic phase errors for this purpose appears in [4], for a particular maneuver. More recent approaches include \u201cCLEAN\u201d [5], [6], [7]; Basis Pursuit Denoising [8]; and `1-regularized sparse reconstruction followed by an iterative model and subtract (IMAS) step [9]. These use computationally-intensive iterative algorithms that rely on strong implicit or explicit assumptions that the radar reflections are caused by a few discrete or canonical scatterers. In [10], 3D backprojection imaging is applied to discrete scatterers.\nIn this paper, we instead approach a curvilinear aperture as a phased-array monopulse antenna, using techniques related to [11] and [12]. We derive the curvilinear aperture monopulse (CLAM) computations for vertical offset in Section 2, under the assumption that there is a single scatterer near a focus point, we compute its offset in the vertical dimension. The technique commutes with efficient image formation algorithms as monopulse commutes with beamforming. Section 3 demonstrates the computation for an aperture with a simple third-order polynomial vertical component and a monotonic horizontal\nar X\niv :2\n21 1.\n17 12\n7v 1\n[ ee\nss .S\nP] 3\ncomponent. A restriction analogous to focus arises in the context of interference in Section 3.3. Section 4 summarizes conclusions."
        },
        {
            "heading": "2 Derivation",
            "text": "This section develops CLAM equations for a curvilinear aperture, in a single-frequency setting. Of course, practical radar pulses have finite bandwidth to permit range discrimination. But many radar applications are sufficiently narrowband that within a compressed pulse envelope (perhaps with time-delay focusing), the single-frequency approximation is valid."
        },
        {
            "heading": "2.1 Single frequency signal model",
            "text": "A receiver moves along an aperture defined by\nx = x0 + x\u03c4 + \u2206x\ny = y0 + \u2206y\nz = z0 + z\u03c4 + \u2206z,\n(1)\nwhere x0, y0, z0 are known fixed offsets, and where x\u03c4 , z\u03c4 describe the aperture as \u03c4 varies. We require that x\u03c4 and z\u03c4 have three derivatives. \u2206x,\u2206y,\u2206z are unknown fixed offsets that we intend to measure, and we are particularly interested in \u2206z. (Of course, the radar directly measures \u2206y, but \u2206y is needed in the computation for reasons that appear in Section 3.2.) Nonlinear z\u03c4 specifies a curvilinear aperture. Nonlinear x\u03c4 does not significantly complicate the following derivation, but our main interest is on the case of monotonic or linear x\u03c4 . To simplify this derivation, y does not vary with \u03c4 .\nAlong this aperture, we measure a single-frequency radiating scalar field given by\nE = Aejk( 1 p ct\u2212R\u03c4 ), (2)\nwhere R\u03c4 = \u221a x2 + y2 + z2 is the range from x = y = z to the origin. Here, E is the horizontal or vertical polarization of the electric or magnetic field, t is \u201cfast time\u201d, and \u03c4 is \u201cslow time\u201d. Coupling between t and \u03c4 is ignored, and we assume the platform does not move during the travel time of the radar pulse. Choose p = 1 if the transmitter is stationary or p = 2\nif the transmitter moves along the aperture with the receiver.\nFor typical SAR applications, the variation in x\u03c4 and z\u03c4 is large enough relative to y that the plane wave approximation is not valid. However, the first order taylor approximation \u221a 1 + u \u2248 1 + 12u is often sufficient, leading to\n2yR\u03c4 \u2248 2y2 + x2 + z2. (3)\nFrom here forward, we accept (3) as sufficient and drop the approximation symbol."
        },
        {
            "heading": "2.2 System of equations",
            "text": "From (2), the derivative of E with respect to \u03c4 is\nE\u2032 = \u2212jkR\u2032\u03c4E. (4)\n(The \u201cprime\u201d symbol will be used throughout do denote differentiation with respect to \u03c4 .) Taking the derivative of (3) with respect to \u03c4 and expanding using (1),\n(y0 + \u2206y)R \u2032 \u03c4 = x \u2032 \u03c4 (x0 +x\u03c4 + \u2206x) + z \u2032 \u03c4 (z0 + z\u03c4 + \u2206z). (5) Define Q\u03c4 as the value of R\u03c4 if the unknown \u2206x,\u2206y,\u2206z are set to zero, and then\ny0Q \u2032 \u03c4 = x \u2032 \u03c4 (x0 + x\u03c4 ) + z \u2032 \u03c4 (z0 + z\u03c4 ). (6)\nSubstituting (6) into (5),\n(y0 + \u2206y)R \u2032 \u03c4 = x \u2032 \u03c4\u2206x+ z \u2032 \u03c4\u2206z + y0Q \u2032 \u03c4 , (7)\nand with (4),\n(y0 + \u2206y)E \u2032 = \u2212jkE(x\u2032\u03c4\u2206x+ z\u2032\u03c4\u2206z + y0Q\u2032\u03c4 ), (8)\nwhich is linear in \u2206x, \u2206y, and \u2206z:\ny0(E \u2032 + jkQ\u2032\u03c4E) =\n\u2212jkEx\u2032\u03c4\u2206x\u2212 E\u2032\u2206y \u2212 jkEz\u2032\u03c4\u2206z. (9)\nDifferentiating (9),\ny0(E \u2032\u2032 + jk(Q\u2032\u03c4E) \u2032) =\n\u2212jk(Ex\u2032\u03c4 )\u2032\u2206x\u2212 E\u2032\u2032\u2206y \u2212 jk(Ez\u2032\u03c4 )\u2032\u2206z, (10)\nand differentiating (10),\ny0(E \u2032\u2032\u2032 + jk(Q\u2032\u03c4E) \u2032\u2032) =\n\u2212jk(Ex\u2032\u03c4 )\u2032\u2032\u2206x\u2212 E\u2032\u2032\u2032\u2206y \u2212 jk(Ez\u2032\u03c4 )\u2032\u2032\u2206z. (11)\nNow (9), (10), and (11) are a system of three linear equations in \u2206x, \u2206y, and \u2206z. If we know the aperture, then y0, as well as x\u03c4 , z\u03c4 , Q\u03c4 , and their derivatives are known. It remains to compute or measure E\u2032, E\u2032\u2032, and E\u2032\u2032\u2032."
        },
        {
            "heading": "2.3 Scalar field derivatives",
            "text": "Direct measurement of the first three derivatives of the scalar field is unreasonable in many settings. But we can estimate the derivative across the aperture as follows.\nLet w be a finite-length discrete window function with support over the slow-time aperture. Let h be the single-frequency backprojection function for a hypothesized scatterer at (x0, y0, z0):\nh(\u03c4) = e\u2212jkQ\u03c4 . (12)\nIn the azimuthal direction, backprojection image formation of a pixel at (x0, y0, z0), with a window, is given by the integral\u222b T\n\u2212T w(\u03c4)h(\u03c4)Ed\u03c4,\nwhere \u00b1T are the values of \u03c4 specifying the beginning and end of the aperture.\nFor convenience, we will write hw(\u03c4) = w(\u03c4)h(\u03c4). Using integration by parts, if w(\u03c4) is zero except on [\u2212T, T ], and if its derivative exists everywhere, then\u222b T\n\u2212T hw(\u03c4)E \u2032d\u03c4 = \u2212 \u222b T \u2212T\nh\u2032w(\u03c4)Ed\u03c4\u222b T \u2212T hw(\u03c4)E \u2032\u2032d\u03c4 = + \u222b T \u2212T\nh\u2032\u2032w(\u03c4)Ed\u03c4\u222b T \u2212T hw(\u03c4)E \u2032\u2032\u2032d\u03c4 = \u2212 \u222b T \u2212T h\u2032\u2032\u2032w (\u03c4)Ed\u03c4.\n(13)\nFollowing [12], if w is chosen to have the form\nw(\u03c4) = wbase(\u03c4) \u2217 (\u03b4\u2212 12 s + \u03b4 12 s)\n(where \u03b4u is the dirac delta shifted to u), then for small s, its derivative is approximated by\nw1(\u03c4) = wbase(\u03c4) \u2217 1\ns (\u03b4\u2212 12 s \u2212 \u03b4 12 s).\nApplying this approximation multiple times, if\nw0(\u03c4) = wbase(\u03c4) \u2217 (\u03b4\u2212 32 s + 3\u03b4\u2212 12 s + 3\u03b4 12 s + \u03b4 32 s) w1(\u03c4) = wbase(\u03c4) \u2217 1\ns (\u03b4\u2212 32 s + \u03b4\u2212 1 2 s \u2212 \u03b4 1 2 s \u2212 \u03b4 3 2 s )\nw2(\u03c4) = wbase(\u03c4) \u2217 1\ns2 (\u03b4\u2212 32 s \u2212 \u03b4\u2212 12 s \u2212 \u03b4 12 s + \u03b4 32 s)\nw3(\u03c4) = wbase(\u03c4) \u2217 1\ns3 (\u03b4\u2212 32 s \u2212 3\u03b4\u2212 12 s + 3\u03b4 12 s \u2212 \u03b4 32 s)\n(14) (where \u2217 denotes convolution), then the ith derivative of w is approximated by wi for small s, for i = 0, 1, 2, 3. Turning attention to derivatives of the narrowband backprojection function,\nh\u2032(\u03c4) = \u2212jkQ\u2032\u03c4h(\u03c4) h\u2032\u2032(\u03c4) = ((jkQ\u2032\u03c4 )\n2 \u2212 jkQ\u2032\u2032\u03c4 )h(\u03c4) h\u2032\u2032\u2032(\u03c4) = (\u2212(jkQ\u2032\u03c4 )3 + 3(jk)2Q\u2032\u03c4Q\u2032\u2032\u03c4 \u2212 jkQ\u2032\u2032\u2032\u03c4 )h(\u03c4)\n(15) and inserting the approximations in (14),\nh\u2032w(\u03c4) \u2248 w1(\u03c4)h(\u03c4) + w0(\u03c4)h\u2032(\u03c4) h\u2032\u2032w(\u03c4) \u2248 w2(\u03c4)h(\u03c4) + 2w1(\u03c4)h\u2032(\u03c4) + w0(\u03c4)h\u2032\u2032(\u03c4) h\u2032\u2032\u2032w (\u03c4) \u2248 w3(\u03c4)h(\u03c4) + 3w2(\u03c4)h\u2032(\u03c4)\n+ 3w1(\u03c4)h \u2032\u2032(\u03c4) + w0(\u03c4)h \u2032\u2032\u2032(\u03c4). (16)\nWe can then compute integrals of each side of (9), (10), and (11), and\nM\u2206r = M00 M01 M02M10 M11 M12 M20 M21 M22 \u2206x\u2206y \u2206z  = b0b1 b2  = b, (17)\nwhere\nM00 = \u2212jk \u222b T \u2212T hw(\u03c4)x \u2032 \u03c4Ed\u03c4,\nM01 = \u2212 \u222b T \u2212T h\u2032w(\u03c4)Ed\u03c4,\nM02 = \u2212jk \u222b T \u2212T hw(\u03c4)z \u2032 \u03c4Ed\u03c4,\nM10 = \u2212jk \u222b T \u2212T h\u2032w(\u03c4))x \u2032 \u03c4Ed\u03c4,\nM11 = \u2212 \u222b T \u2212T h\u2032\u2032w(\u03c4)Ed\u03c4,\nM12 = \u2212jk \u222b T \u2212T h\u2032w(\u03c4))z \u2032 \u03c4Ed\u03c4,\nM20 = \u2212jk \u222b T \u2212T h\u2032\u2032w(\u03c4)x \u2032 \u03c4Ed\u03c4,\nM21 = \u2212 \u222b T \u2212T h\u2032\u2032\u2032w (\u03c4)Ed\u03c4,\nM22 = \u2212jk \u222b T \u2212T h\u2032\u2032w(\u03c4)z \u2032 \u03c4Ed\u03c4,\nb0 = y0 \u222b T \u2212T (h\u2032w(\u03c4)) \u2032 + jkhw(\u03c4)Q \u2032 \u03c4 )Ed\u03c4,\nb1 = y0 \u222b T \u2212T (h\u2032\u2032w(\u03c4)) \u2032\u2032 + jkh\u2032w(\u03c4)Q \u2032 \u03c4 )Ed\u03c4,\nb2 = y0 \u222b T \u2212T (h\u2032\u2032\u2032w (\u03c4) + jkh \u2032\u2032 w(\u03c4)Q \u2032 \u03c4 )Ed\u03c4.\nFor apertures critically sampled uniformly in \u03c4 at a sample rate of s, the integrals above can be computed as sums. When M is invertible, \u2206r = M\u22121b. Our objective, \u2206z, is the third element of \u2206r."
        },
        {
            "heading": "2.4 Computation using efficient image formation algorithms",
            "text": "The integral in each Mij term and each bi term in (17), together with h, is the azimuth portion of a backprojection image computation, for a single pixel, for the scalar field E, under some window function. For example, forM00, the window is\u2212jkw0(\u03c4)x\u2032\u03c4 . An efficient image formation technique like Polar Format Algorithm commutes with the operations above, and is a good approximation for backprojection. So in principle, M and b can be computed for all pixels in a scene, by performing an image formation operation for each Mij and each bi. We will see in Section 3.3 that interference can corrupt pixels that are not notably brighter than their neighbors.\nFor sufficiently large images, the approximation of (3) may become invalid for large x or z. In this case, it may be necessary to vary x0 and z0 to keep the approximation valid. Handling this situation, while leveraging an efficient image formation technique, is beyond the scope of this paper."
        },
        {
            "heading": "3 Examples",
            "text": ""
        },
        {
            "heading": "3.1 Asymmetric third-order polynomial aperture",
            "text": "Consider the third-order polynomial aperture pictured in Fig. 1. Its length is 55.5m, and its height is 0.5m. Assume a center frequency of 9 GHz, and a range of 1km. A linear aperture of this length would have a horizontal resolution of 0.3m. Choose a hann window for wbase(\u03c4). Using a single-frequency pointscatterer simulation, setting \u2206x = \u2206y = 0, the computed vertical position matches the correct position with \u2206z out to and somewhat beyond the dashed lines at \u00b116.7m, which are the edges of vertical resolution of a hypothetical rectangular aperture circumscribing the curve. Noise was added to each time sample, at an amplitude of 10% of that of the signal. Varying \u2206x over the horizontal resolution of a linear aperture of this length (\u00b10.15m), and varying \u2206y over the same amount (as might be expected for a SAR system), the error in computed \u2206z is shown in Fig. 3. So the approximations we have introduced are capable of measuring \u2206z to a high degree of accuracy in this setting, varying \u2206x,\u2206y over the space of a SAR pixel, for a single scatterer, with a small amount of noise."
        },
        {
            "heading": "3.2 Parabolas aperture ambiguities",
            "text": "For a symmetric second-order polynomial aperture, either a height offset or a small range offset causes similar wavefronts to reach the aperture. For the full computation of (17), the ambiguity causes an illconditioned matrix. But if we make the assumption that \u2206y is zero, we can modify (17) to remove both\n\u2206y and (11), leaving[ M00 M02 M10 M12 ] [ \u2206x \u2206z ] = [ b0 b1 ] . (18)\nA symmetric second-order polynomial aperture is shown in Fig. 4. The aperture height and length are the same as that of Fig. 1. Using (18), measured \u2206z varies with small range offsets, as shown in Fig. (5). So the impact of dropping \u2206y is that the vertical position estimate varies with small range offsets. The full CLAM computation using the aperture of Fig. (1) is immune to this ambiguity, as shown in (6). In certain applications and for certain apertures, the advantage of using a parabolic aperture may outweigh the impact of this ambiguity. In the case pictured, the vertical error is comparable to the size of the azimuthal resolution, which is typically comparable to the azimuthal resolution. But for some applications, this may be acceptible. Larger vertical apertures yield smaller ambiguities, for the same horizontal aperture. See Fig. (7) for results varying \u2206x,\u2206y as in Fig. (3) The size of the errors are comparable for these parameters."
        },
        {
            "heading": "3.3 Interference and glint",
            "text": "The computation for \u2206x,\u2206y,\u2206z in (17) is nonlinear in the scalar field E, because E is present in all terms of M and b in (17). For this reason, if multiple scatterers contribute to E, the computed values of \u2206x,\u2206y,\u2206z are not a linear combination of the values that would be computed in the single-scatterer case. Nor are they guaranteed to be between or even near the correct values. This phenomenon is known as \u201cglint\u201d in the context of monopulse [12].\nConsider a scatterer at \u2206x = 0,\u2206y = 0,\u2206z = 0. If a \u201cconfuser\u201d scatter is placed at the same \u2206z = 0, but at some other \u2206x,\u2206y, then the measured \u2206z is not necessarily near 0. For the aperture of Fig. (1), the size of the error is shown in Fig. 8. \u2206y is varied over half of a wavelength, because the phenomenon appears to be caused by the phase difference of the confuser. The horizontal resolution width is marked by dashed lines. The error is small for most phases, for most confuser scatterers within the resolution width. So a confuser scatterer in the same pixel is likely to result in the correct measurement. For confuser scatterers several resolution widths away, the directional effects of the backprojection function h(\u03c4) rejects the energy from the confuser, and the measurement is approximately correct. However, for confuser scatterers only a few resolution widths away, the error can be quite large. This is because the beampatterns of many of the terms in (17) are wider than a resolution cell. Information from adjacent resolution cells are needed to make the measurement correctly. As a result of this, these computations will only be valid for scatterers that are particularly bright relative to their immediate surroundings in azimuth. SAR images often have pixels that are notably brighter than their neighbors, and this assumption is the basis of determining whether an image is in focus.\nIn a sensing context, it may be difficult to guarantee that only a single scatterer is represented in a location. We need a method to detect when a measurement is corrupted by \u201cglint\u201d from other scatterers. The determinant from the left side of (17) is shown in Fig. 9. Where this determinant is large, the glint error in Fig. 8 is small. This suggests that small determinants may be used to detect measure-\nments corrupted by interference from other scatterers."
        },
        {
            "heading": "4 Conclusion",
            "text": "Using computations given in this paper, with a curvilinear aperture, one can compute elevation of a single scatterer, provided the matrix M from (17) is invertible. The monopulse-based computations are non-iterative, and commute with efficient image formation algorithms. A nearby confuser scatterer of similar amplitude can corrupt the measurement, so elevation will only be available for pixels that are notably brighter than their neighbors. This is analogous to the focus assumption in other work on curvilinear apertures, in that the concept of \u201cfocus\u201d implies that for the correct image, certain pixels are notably brighter than their neighbors. For a pixel subject to this corruption, the determinant of M is small, serving as a warning."
        }
    ],
    "title": "Curvilinear Aperture Monopulse",
    "year": 2022
}