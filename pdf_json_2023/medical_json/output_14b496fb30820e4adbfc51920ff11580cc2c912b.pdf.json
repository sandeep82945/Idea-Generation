{
    "abstractText": "The precipitation and deposition of asphaltene on solid surfaces present a significant challenge throughout all stages of petroleum recovery, from hydrocarbon reservoirs in porous media to wellbore and transfer pipelines. A comprehensive understanding of asphaltene aggregation phenomena is crucial for controlling deposition issues. In addition to experimental studies, accurate prediction of asphaltene aggregation kinetics, which has received less attention in previous research, is essential. This study proposes an artificial intelligence\u2010based framework for precisely predicting asphaltene particle aggregation kinetics. Different techniques were utilized to predict the asphaltene aggregate diameter as a function of pressure, temperature, oil specific gravity, and oil asphaltene content. These methods included the adaptive neuro\u2010fuzzy interference system (ANFIS), radial basis function (RBF) neural network optimized with the Grey Wolf Optimizer (GWO) algorithm, extreme learning machine (ELM), and multi\u2010layer perceptron (MLP) coupled with Bayesian Regularization (BR), Levenberg\u2013 Marquardt (LM), and Scaled Conjugate Gradient (SCG) algorithms. The models were constructed using a series of published data. The results indicate the excellent correlation between predicted and experimental values using various models. However, the GWO\u2010RBF modeling strategy demonstrated the highest accuracy among the developed models, with a determination coefficient, average absolute relative deviation percent, and root mean square error (RMSE) of 0.9993, 1.1326%, and 0.0537, respectively, for the total data.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ali Sharifzadegan"
        },
        {
            "affiliations": [],
            "name": "Abolfazl Dehghan Monfared"
        }
    ],
    "id": "SP:abc01cd08cf19dea447cef538c2a57c0591ae00c",
    "references": [
        {
            "authors": [
                "M. Fazeli",
                "M. Escrochi",
                "Z.S. Hosseini",
                "B. Vaferi"
            ],
            "title": "Experimental analyzing the effect of n-heptane concentration and angular frequency on the viscoelastic behavior of crude oil containing asphaltene",
            "venue": "Sci. Rep",
            "year": 2207
        },
        {
            "authors": [
                "Bahmaninia",
                "H. et al. Toward mechanistic understanding of asphaltene adsorption onto quartz surface"
            ],
            "title": "The roles of size, concentration, and hydrophobicity of quartz, asphaltene composition, flow condition, and aqueous phase",
            "venue": "J. Pet. Sci. Eng. 205, 108820. https:// doi. org/ 10. 1016/j. petrol. 2021. 108820",
            "year": 2021
        },
        {
            "authors": [
                "A. Ahooei",
                "S. Norouzi-Apourvari",
                "A. Hemmati-Sarapardeh",
                "Schaffie",
                "M. Experimental study",
                "modeling of asphaltene deposition on metal surfaces via electrodeposition process"
            ],
            "title": "The role of ultrasonic radiation, asphaltene concentration and structure",
            "venue": "J. Pet. Sci. Eng. 195, 107734. https:// doi. org/ 10. 1016/j. petrol. 2020. 107734",
            "year": 2020
        },
        {
            "authors": [
                "A Hemmati-Sarapardeh"
            ],
            "title": "Modeling asphaltene precipitation during natural depletion of reservoirs and evaluating screening criteria for stability of crude oils",
            "venue": "J. Pet. Sci. Eng",
            "year": 2019
        },
        {
            "authors": [
                "A Hemmati-Sarapardeh"
            ],
            "title": "Effect of asphaltene structure on its aggregation behavior in toluene-normal alkane mixtures",
            "venue": "J. Mol. Struct",
            "year": 2020
        },
        {
            "authors": [
                "A. Daryasafar",
                "M. Masoudi",
                "S. Kord",
                "Madani",
                "M. Evaluation of different thermodynamic models in predicting asphaltene precipitation"
            ],
            "title": "A comparative study",
            "venue": "Fluid Phase Equilibria 54, 112557",
            "year": 2020
        },
        {
            "authors": [
                "M.M. Shadman",
                "M.H. Badizad",
                "M. Dehghanizadeh",
                "A.H.S. Dehaghani"
            ],
            "title": "Developing a novel colloidal model for predicting asphaltene precipitation from crude oil by alkane dilution",
            "venue": "J. Mol. Liquids",
            "year": 1016
        },
        {
            "authors": [
                "H. Dashti",
                "P. Zanganeh",
                "S. Kord",
                "S. Ayatollahi",
                "Amiri",
                "A. Mechanistic study to investigate the effects of different gas injection scenarios on the rate of asphaltene deposition"
            ],
            "title": "An experimental approach",
            "venue": "Fuel 262, 116615. https:// doi. org/ 10. 1016/j. fuel. 2019. 116615",
            "year": 2020
        },
        {
            "authors": [
                "S. Kord",
                "A. Soleymanzadeh",
                "R. Miri"
            ],
            "title": "A generalized scaling equation to predict asphaltene precipitation during precipitant dilution, natural depletion, water injection and gas injection",
            "venue": "J. Pet. Sci. Eng",
            "year": 1016
        },
        {
            "authors": [
                "Z. Rashid",
                "C.D. Wilfred",
                "N. Gnanasundaram",
                "A. Arunagiri",
                "T. Murugesan"
            ],
            "title": "A comprehensive review on the recent advances on the petroleum asphaltene aggregation",
            "venue": "J. Pet. Sci. Eng",
            "year": 1016
        },
        {
            "authors": [
                "I Mohammed"
            ],
            "title": "Impact of asphaltene precipitation and deposition on wettability and permeability",
            "venue": "ACS Omega",
            "year": 2021
        },
        {
            "authors": [
                "M. Salehzadeh",
                "M.M. Husein",
                "C. Ghotbi",
                "V. Taghikhani",
                "B. Dabir"
            ],
            "title": "Investigating the role of asphaltenes structure on their aggregation and adsorption/deposition behavior",
            "venue": "Geoenergy Sci. Eng. 230,",
            "year": 2023
        },
        {
            "authors": [
                "J Meng"
            ],
            "title": "Size distribution of primary submicron particles and larger aggregates in solvent induced asphaltene precipitation",
            "venue": "Preprint at https:// arXiv. org/ quant-",
            "year": 2022
        },
        {
            "authors": [
                "J. Meng",
                "J.B. You",
                "H. Hao",
                "X. Tan",
                "X. Zhang"
            ],
            "title": "Primary submicron particles from early stage asphaltene precipitation revealed in situ by total internal reflection fluorescence microscopy in a model oil system",
            "venue": "Fuel 296,",
            "year": 1205
        },
        {
            "authors": [
                "J. Mirwald",
                "B. Hofko",
                "G. Pipintakos",
                "J. Blom",
                "H. Soenen"
            ],
            "title": "Comparison of microscopic techniques to study the diversity of the bitumen microstructure",
            "venue": "Micron 159,",
            "year": 2022
        },
        {
            "authors": [
                "Q Zhang"
            ],
            "title": "The study on interactions between stabilizers and asphaltenes",
            "venue": "J. Dispers. Sci. Technol",
            "year": 2022
        },
        {
            "authors": [
                "Hammond",
                "C.B. et al. Mesoscale aggregation of sulfur-rich asphaltenes"
            ],
            "title": "In situ microscopy and coarse-grained molecular simulation",
            "venue": "Langmuir 38, 6896\u20136910",
            "year": 2022
        },
        {
            "authors": [
                "J. Jennings",
                "D. Growney",
                "H. Brice",
                "O. Mykhaylyk",
                "S. Armes"
            ],
            "title": "Application of scattering and diffraction techniques for the morphological characterization of asphaltenes",
            "venue": "Fuel 327,",
            "year": 2022
        },
        {
            "authors": [
                "S. Moradi",
                "E.H. Mahvelati",
                "F. Ameli",
                "B. Dabir",
                "D. Rashtchian"
            ],
            "title": "Application of population balance equation in modeling of asphaltene particle size distribution and characterization of aggregation mechanisms under miscible gas Injection",
            "venue": "J. Mol. Liquids 232,",
            "year": 2017
        },
        {
            "authors": [
                "J. Duran",
                "F. Schoeggl",
                "H. Yarranton"
            ],
            "title": "Kinetics of asphaltene precipitation/aggregation from diluted crude oil",
            "venue": "Fuel 255,",
            "year": 2019
        },
        {
            "authors": [
                "B.S. Soulgani",
                "F. Reisi",
                "F. Norouzi"
            ],
            "title": "Investigation into mechanisms and kinetics of asphaltene aggregation in toluene/n-hexane mixtures",
            "venue": "Pet. Sci",
            "year": 2020
        },
        {
            "authors": [
                "A. Poozesh",
                "M. Sharifi",
                "J. Fahimpour"
            ],
            "title": "Modeling of asphaltene deposition kinetics",
            "venue": "Energy Fuels",
            "year": 2020
        },
        {
            "authors": [
                "Hosseini-Moghadam",
                "S.M.-A",
                "A. Zahedi-Nejad",
                "M. Bahrami",
                "M. Torkaman",
                "Ghayyem",
                "M.-A"
            ],
            "title": "Experimental and modeling investigations of temperature effect on chemical inhibitors of asphaltene aggregation",
            "venue": "J. Pet. Sci. Eng. 205,",
            "year": 2021
        },
        {
            "authors": [
                "D.R. Handwerk",
                "P.D. Shipman",
                "S. \u00d6zkar",
                "Finke",
                "R.G. Dust effects on Ir(0)n nanoparticle formation nucleation",
                "growth kinetics",
                "particle size-distributions"
            ],
            "title": "Analysis by and insights from mechanism-enabled population balance modeling",
            "venue": "Langmuir 36, 1496\u20131506. https:// doi. org/ 10. 1021/ acs. langm uir. 9b031 93",
            "year": 2020
        },
        {
            "authors": [
                "Elduayen-Echave",
                "B. et al. Inclusion of shear rate effects in the kinetics of a discretized population balance model"
            ],
            "title": "Application to struvite precipitation",
            "venue": "Water Res. 200, 117242. https:// doi. org/ 10. 1016/j. watres. 2021. 117242",
            "year": 2021
        },
        {
            "authors": [
                "A. Tirjoo",
                "B. Bayati",
                "H. Rezaei",
                "M. Rahmati"
            ],
            "title": "Molecular dynamics simulations of asphaltene aggregation under different conditions",
            "venue": "J. Pet. Sci. Eng",
            "year": 2019
        },
        {
            "authors": [
                "Rahmati",
                "M. Effects of heteroatom",
                "aliphatic chains of asphaltene molecules on their aggregation properties in aromatics Solvents"
            ],
            "title": "A molecular dynamics simulation study",
            "venue": "Chem. Phys. Lett. 779, 138847. https:// doi. org/ 10. 1016/j. cplett. 2021. 138847",
            "year": 2021
        },
        {
            "authors": [
                "M. Ghorbani",
                "G. Zargar",
                "H. Jazayeri-Rad"
            ],
            "title": "Prediction of asphaltene precipitation using support vector regression tuned with genetic algorithms",
            "venue": "Petroleum 2,",
            "year": 2016
        },
        {
            "authors": [
                "M. Sadi",
                "A. Shahrabadi"
            ],
            "title": "Evolving robust intelligent model based on group method of data handling technique optimized by genetic algorithm to predict asphaltene precipitation",
            "venue": "J. Pet. Sci. Eng. 171,",
            "year": 2018
        },
        {
            "authors": [
                "M.N. Kardani",
                "A. Baghban",
                "M.E. Hamzehie",
                "M. Baghban"
            ],
            "title": "Phase behavior modeling of asphaltene precipitation utilizing RBFANN approach",
            "venue": "Pet. Sci. Technol",
            "year": 2019
        },
        {
            "authors": [
                "M. Behnamnia",
                "N. Mozafari",
                "Dehghan Monfared",
                "A. Rigorous hybrid machine learning approaches for interfacial tension modeling in brine-hydrogen/cushion gas systems"
            ],
            "title": "Implication for hydrogen geo-storage in the presence of cushion gas",
            "venue": "J. Energy Storage 73, 108995. https:// doi. org/ 10. 1016/j. est. 2023. 108995",
            "year": 2023
        },
        {
            "authors": [
                "Jang",
                "J.-S. ANFIS"
            ],
            "title": "Adaptive-network-based fuzzy inference system",
            "venue": "IEEE Trans. Syst. Man Cybern. 23, 665\u2013685",
            "year": 1993
        },
        {
            "authors": [
                "M. Babanezhad",
                "I. Behroyan",
                "A.T. Nakhjiri",
                "A. Marjani",
                "S. Shirazian"
            ],
            "title": "Performance and application analysis of ANFIS artificial intelligence for pressure prediction of nanofluid convective flow in a heated pipe",
            "venue": "Sci. Rep",
            "year": 2021
        },
        {
            "authors": [
                "A. Mustafa",
                "Z. Tariq",
                "M. Mahmoud",
                "A. Abdulraheem"
            ],
            "title": "Machine learning accelerated approach to infer nuclear magnetic resonance porosity for a middle eastern carbonate",
            "venue": "reservoir. Sci. Rep",
            "year": 2023
        },
        {
            "authors": [
                "M. Sugeno",
                "G. Kang"
            ],
            "title": "Structure identification of fuzzy model",
            "venue": "Fuzzy Sets Syst",
            "year": 1988
        },
        {
            "authors": [
                "T. Takagi",
                "M. Sugeno"
            ],
            "title": "Fuzzy identification of systems and its applications to modeling and control",
            "venue": "IEEE Trans. Syst. Man Cybern. SMC-15,",
            "year": 1985
        },
        {
            "authors": [
                "P. Werbos"
            ],
            "title": "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences",
            "venue": "(Harvard University,",
            "year": 1974
        },
        {
            "authors": [
                "D. Filev",
                "R.R. Yager"
            ],
            "title": "On the issue of obtaining OWA operator weights",
            "venue": "Fuzzy Sets Syst",
            "year": 1998
        },
        {
            "authors": [
                "A. Baghban",
                "M. Bahadori",
                "Z. Ahmad",
                "T. Kashiwao",
                "A. Bahadori"
            ],
            "title": "Modeling of true vapor pressure of petroleum products using ANFIS algorithm",
            "venue": "Pet. Sci. Technol",
            "year": 2016
        },
        {
            "authors": [
                "B. Horst",
                "K. Abraham"
            ],
            "title": "Neuro\u2010Fuzzy Pattern Recognition",
            "venue": "Vol. 41 (World Scientific,",
            "year": 2000
        },
        {
            "authors": [
                "S. Akbari",
                "S.M. Mahmood",
                "I.M. Tan",
                "H. Hematpour"
            ],
            "title": "Comparison of neuro-fuzzy network and response surface methodology pertaining to the viscosity of polymer solutions",
            "venue": "J. Pet. Explor. Prod. Technol",
            "year": 2017
        },
        {
            "authors": [
                "D. Broomhead",
                "D. Lowe"
            ],
            "title": "Radial basis functions, multi-variable functional interpolation and adaptive networks. ROYAL SIGNALS AND RADAR ESTABLISHMENT MALVERN (UNITED KINGDOM",
            "year": 1988
        },
        {
            "authors": [
                "A. Tatar",
                "A. Barati",
                "A. Najafi",
                "A.H. Mohammadi"
            ],
            "title": "Radial basis function (RBF) network for modeling gasoline properties",
            "venue": "Pet. Sci. Technol",
            "year": 2019
        },
        {
            "authors": [
                "J. Abdi",
                "M. Hadipoor",
                "S.H. Esmaeili-Faraj",
                "B. Vaferi"
            ],
            "title": "A modeling approach for estimating hydrogen sulfide solubility in fifteen different imidazole-based ionic liquids",
            "venue": "Sci. Rep",
            "year": 2022
        },
        {
            "authors": [
                "A. Hemmati-Sarapardeh",
                "A. Varamesh",
                "M.M. Husein",
                "Karan",
                "K. On the evaluation of the viscosity of nanofluid systems"
            ],
            "title": "Modeling and data assessment",
            "venue": "Renew. Sustain. Energy Rev. 81, 313\u2013329. https:// doi. org/ 10. 1016/j. rser. 2017. 07. 049",
            "year": 2018
        },
        {
            "authors": [
                "M. Mahdaviara",
                "N.A. Menad",
                "M.H. Ghazanfari",
                "Hemmati-Sarapardeh",
                "A. Modeling relative permeability of gas condensate reservoirs"
            ],
            "title": "Advanced computational frameworks",
            "venue": "J. Pet. Sci. Eng. 189, 106929. https:// doi. org/ 10. 1016/j. petrol. 2020. 106929",
            "year": 2020
        },
        {
            "authors": [
                "Li",
                "Z.-C",
                "Fan",
                "C.-L"
            ],
            "title": "A novel method to identify the flow pattern of oil\u2013water two-phase flow",
            "venue": "J. Pet. Explor. Prod. Technol",
            "year": 2020
        },
        {
            "authors": [
                "H. Vo Thanh",
                "Y. Sugai",
                "K. Sasaki"
            ],
            "title": "Application of artificial neural network for predicting the performance of CO2 enhanced oil recovery and storage in residual oil",
            "venue": "zones. Sci. Rep",
            "year": 2020
        },
        {
            "authors": [
                "M. Nait Amar",
                "M.A. Ghriga",
                "H. Ouaer"
            ],
            "title": "On the evaluation of solubility of hydrogen sulfide in ionic liquids using advanced committee machine intelligent systems",
            "venue": "J. Taiwan Inst. Chem. Eng",
            "year": 1016
        },
        {
            "authors": [
                "K. Shaygan",
                "S. Jamshidi"
            ],
            "title": "Prediction of rate of penetration in directional drilling using data mining techniques",
            "venue": "Geoenergy Sci. Eng",
            "year": 2023
        },
        {
            "authors": [
                "S Chopra"
            ],
            "title": "Taxonomy of adaptive neuro-fuzzy inference system in modern engineering sciences",
            "venue": "Computat. Intell. Neurosci. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "G. Ciaburro",
                "B. Venkateswaran"
            ],
            "title": "Neural Networks with R: Smart Models Using CNN, RNN, Deep Learning, and Artificial Intel\u2010 ligence Principles (Packt Publishing Ltd, 2017)",
            "year": 2017
        },
        {
            "authors": [
                "B. Akkaya",
                "N. \u00c7olako\u011flu"
            ],
            "title": "Comparison of multi-class classification algorithms on early diagnosis of heart diseases",
            "year": 2019
        },
        {
            "authors": [
                "M. Behnamnia",
                "A. Dehghan Monfared",
                "M. Sarmadivaleh"
            ],
            "title": "Hybrid artificial intelligence paradigms for modeling of water-gas (pure/mixture) interfacial tension",
            "venue": "J. Natural Gas Sci. Eng",
            "year": 1016
        },
        {
            "authors": [
                "Le",
                "V. T"
            ],
            "title": "A multidisciplinary approach for evaluating spatial and temporal variations in water quality",
            "venue": "Water 11,",
            "year": 2019
        },
        {
            "authors": [
                "Huang",
                "G.-B.",
                "D.H. Wang",
                "Lan",
                "Y. Extreme learning machines"
            ],
            "title": "A survey",
            "venue": "Int. J. Mach. Learn. Cybern. 2, 107\u2013122 (2011). 15 Vol.:(0123456789) Scientific Reports |",
            "year": 2023
        },
        {
            "authors": [
                "C.S.W. Ng",
                "H. Djema",
                "M. Nait Amar",
                "Jahanbani Ghahfarokhi",
                "A. Modeling interfacial tension of the hydrogen-brine system using robust machine learning techniques"
            ],
            "title": "Implication for underground hydrogen storage",
            "venue": "Int. J. Hydrogen Energy 47, 39595\u201339605. https:// doi. org/ 10. 1016/j. ijhyd ene. 2022. 09. 120",
            "year": 2022
        },
        {
            "authors": [
                "O. Kisi",
                "E. Uncuo\u011flu"
            ],
            "title": "Comparison of three back-propagation training algorithms for two case studies",
            "venue": "Indian J. Eng. Mater. Sci",
            "year": 2005
        },
        {
            "authors": [
                "M.T. Hagan",
                "M.B. Menhaj"
            ],
            "title": "Training feedforward networks with the Marquardt algorithm",
            "venue": "IEEE Trans. Neural Netw",
            "year": 1994
        },
        {
            "authors": [
                "H. Mehrjoo",
                "M. Riazi",
                "M. Nait Amar",
                "A. Hemmati-Sarapardeh"
            ],
            "title": "Modeling interfacial tension of methane-brine systems at high pressure and high salinity conditions",
            "venue": "J. Taiwan Inst. Chem. Eng",
            "year": 1016
        },
        {
            "authors": [
                "M. Nait Amar",
                "H. Ouaer",
                "M. Abdelfetah Ghriga"
            ],
            "title": "Robust smart schemes for modeling carbon dioxide uptake in metal\u2014Organic frameworks",
            "venue": "Fuel 311,",
            "year": 2022
        },
        {
            "authors": [
                "M.F. M\u00f8ller"
            ],
            "title": "A scaled conjugate gradient algorithm for fast supervised learning",
            "venue": "Neural Netw",
            "year": 1993
        },
        {
            "authors": [
                "H. Faris",
                "I. Aljarah",
                "M.A. Al-Betar",
                "Mirjalili",
                "S. Grey wolf optimizer"
            ],
            "title": "A review of recent variants and applications",
            "venue": "Neural Comput. Appl. 30, 413\u2013435. https:// doi. org/ 10. 1007/ s00521- 017- 3272-5",
            "year": 2018
        },
        {
            "authors": [
                "S. Mirjalili",
                "S.M. Mirjalili",
                "A. Lewis"
            ],
            "title": "Grey wolf optimizer",
            "venue": "Adv Eng. Softw",
            "year": 2013
        },
        {
            "authors": [
                "S. Mohammadi",
                "F. Rashidi",
                "Ghazanfari",
                "M.-H",
                "S.A. Mousavi-Dehghani"
            ],
            "title": "Kinetics of asphaltene aggregation phenomena in live oils",
            "venue": "J. Mol. Liquids 222,",
            "year": 2016
        },
        {
            "authors": [
                "D.A.M. Matthew",
                "A. Jahanbani Ghahfarokhi",
                "C.S.W. Ng",
                "M. Nait Amar"
            ],
            "title": "Proxy model development for the optimization of water alternating CO2 gas for enhanced oil recovery",
            "venue": "Energies 16,",
            "year": 2023
        },
        {
            "authors": [
                "M. Zandieh",
                "A. Kazemi",
                "M. Ahmadi"
            ],
            "title": "A comprehensive insight into the application of machine learning approaches in predicting the separation efficiency of hydrocyclones",
            "venue": "Desalination Water Treat. 236,",
            "year": 2021
        },
        {
            "authors": [
                "R. Wardoyo",
                "N.L. Afifa"
            ],
            "title": "Computing the time complexity of ANFIS algorithm",
            "venue": "Int. J. Adv. Res. Comput. Eng. Technol. (IJARCET)",
            "year": 2018
        },
        {
            "authors": [
                "N.A. Gumerov",
                "R. Duraiswami"
            ],
            "title": "Fast radial basis function interpolation via preconditioned Krylov iteration",
            "venue": "SIAM J. Sci. Comput",
            "year": 2007
        }
    ],
    "sections": [
        {
            "text": "1 Vol.:(0123456789) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nwww.nature.com/scientificreports\nArtificial intelligence\u2011based framework for precise prediction of asphaltene particle aggregation kinetics in petroleum recovery"
        },
        {
            "heading": "Ali Sharifzadegan , Mohammad Behnamnia & Abolfazl Dehghan Monfared *",
            "text": "The precipitation and deposition of asphaltene on solid surfaces present a significant challenge throughout all stages of petroleum recovery, from hydrocarbon reservoirs in porous media to wellbore and transfer pipelines. A comprehensive understanding of asphaltene aggregation phenomena is crucial for controlling deposition issues. In addition to experimental studies, accurate prediction of asphaltene aggregation kinetics, which has received less attention in previous research, is essential. This study proposes an artificial intelligence\u2011based framework for precisely predicting asphaltene particle aggregation kinetics. Different techniques were utilized to predict the asphaltene aggregate diameter as a function of pressure, temperature, oil specific gravity, and oil asphaltene content. These methods included the adaptive neuro\u2011fuzzy interference system (ANFIS), radial basis function (RBF) neural network optimized with the Grey Wolf Optimizer (GWO) algorithm, extreme learning machine (ELM), and multi\u2011layer perceptron (MLP) coupled with Bayesian Regularization (BR), Levenberg\u2013 Marquardt (LM), and Scaled Conjugate Gradient (SCG) algorithms. The models were constructed using a series of published data. The results indicate the excellent correlation between predicted and experimental values using various models. However, the GWO\u2011RBF modeling strategy demonstrated the highest accuracy among the developed models, with a determination coefficient, average absolute relative deviation percent, and root mean square error (RMSE) of 0.9993, 1.1326%, and 0.0537, respectively, for the total data.\nPetroleum industries, either downstream or upstream, can be adversely influenced by the least understood and the most problematic portion of crude oil, known as asphaltene, as oil is being explored, produced, processed, and transported1\u20134. Asphaltenes are referred to as oil constituents that can be solved in aromatic solvents like benzene or toluene while insoluble in saturated hydrocarbons, including n-heptane or n-pentane5,6. As any change in the thermodynamic parameters (such as temperature, pressure, or fluid composition) occurs, small tiny-particle-based asphaltenes may develop larger and become macro particles and accordingly deposit on the solid surface7,8. With this in mind, precipitation and subsequent deposition of asphaltenes throughout either enhanced oil recovery techniques or natural depletion lead to severe operational and/or economic issues for oil production9,10. Some of the most critical consequences of asphaltene formation include adverse wettability alteration of reservoir rock, the decline in well inflow capacity, formation damage, production facilities clogging, and equipment fouling11,12.\nModeling and experimental research into temperature/pressure kinetics concerning asphaltene aggregation phenomena can assist in precisely predicting and/or controlling asphaltene-related issues in all stages of petroleum processing/production. In this regard, numerous laboratory studies using several experimental techniques, including the centrifugation method, small-angle X-ray and small-angle neutron scattering, confocal laser-scanning and fluorescence microscopy, optical and confocal microscopy, and particle-size analyzer were performed for analyzing asphaltene aggregation and aggregation size13\u201320. In addition to experimental studies, there have been efforts to investigate asphaltene aggregation/precipitation behavior from a theoretical perspective.\nMoradi et\u00a0al. studied asphaltene aggregation size distribution through miscible gas injection, which enhanced the optimum extent for collision parameter, and then employed population balance for modeling aggregation kinetic. Conclusions indicated that during natural production, cluster aggregation plays a dominant role near the\nOPEN"
        },
        {
            "heading": "Department of Petroleum Engineering, Faculty of Petroleum, Gas and Petrochemical Engineering, Persian Gulf",
            "text": "University, Bushehr 75169-13817, Iran. *email: dehghan@pgu.ac.ir\n2 Vol:.(1234567890) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nbubble point pressure of crude oil. In addition, nitrogen injection significantly affects the incremental content and size of asphaltene flocs21.\nDuran et\u00a0al. investigated asphaltene aggregation size and precipitation in diluted crude oil with n-heptane using the population balance method. Results showed that collision efficiency has less impacts on precipitation aggregation22. Soltani Soulgani et\u00a0al. showed that asphaltene collision intensity relates to particle size distribution and density of the mixture. Results indicated that increasing n-hexane concentration in asphaltene-toluene solution leads to more asphaltene aggregation. It was observed that large aggregates, due to Brownian motion, are stable in the solution for less than 200 min. In addition, the aggregation rate in the reaction-limited aggregation process was found to be quicker than that of the diffusion-limited aggregation process. Also, the average size of asphaltene aggregation decreases in the asphaltene settling region23. Hemmati-Sarapardeh et\u00a0al. studied two main effective parameters, such as various asphaltene concentrations and normal alkane-to-toluene ratios on asphaltene aggregation. According to their findings, increasing asphaltene concentration would lead to an increase in aggregation size toward more than 100 microns, while increasing n-alkanes length leads to a decrease in the aggregation size. It was also observed that heteroatoms play a significant role in the average size of asphaltene. The asphaltene with the smallest polarity and aromaticity made a more stable solution with the lowest aggregation size6.\nPoozesh et\u00a0al. modeled asphaltene deposition in the pipeline and showed the effectiveness of medium stability and viscosity using different oil compositions. It was observed that the lower the viscosity, the greater the aggregation size and, hence, the greater the deposition rate24. Hosseini-Moghadam et\u00a0al. used different types of chemical inhibitors of asphaltene aggregation in an undiluted dead oil. Among various types of inhibitors, dodecylbenzene sulfonic acid has the highest efficiency in reducing the aggregation size of asphaltene at all performed temperatures due to efficient acid\u2013base interactions. Additionally, the population balance approach was utilized for modeling and analyzing aggregation size and its kinetic behavior. Their results indicated that collision efficiency is reduced with decreasing temperature and inhibitor efficiency25.\nDespite considerable experimental and theoretical/mechanistic investigation focused on exploring the different aspects contributing to the kinetics of asphaltene aggregation behavior, some limited efforts have been made in the modeling stage of this phenomenon. In this way, the use of population balance modeling, as a widely accepted approach in the field of colloidal systems26,27, has been reported by some researchers22,25. The application of fractal theory and molecular dynamic simulation was also rarely addressed in this area23,28,29. In addition, the experimental measurements of asphaltene aggregation kinetics are inherently time-consuming and require interpretation procedures alongside expensive laboratory equipment. Therefore, developing a simple and efficient modeling strategy for predicting asphaltene kinetic behavior is especially important since experimental results under different conditions are scarcely found in the previously published research. To the best of our knowledge, given the importance of the availability of data for asphaltene particle aggregation, it comes as a surprise that there has been no attempt to introduce simple, efficient, and simple-to-use models to date. In this regard, the application of artificial intelligence-based approaches seems interesting.\nThe growing use of artificial intelligence methods is gaining significant attention, as they offer a promising means to predict established phenomena with exceptional accuracy. Artificial intelligence leverages advanced computer algorithms and machine learning models to analyze complex data patterns, excelling at managing large datasets and uncovering intricate relationships, particularly in diverse domains. In the context of predicting issues related to asphaltene deposition using various artificial intelligence methods, some instances have been discussed in the literature.\nIn their research, Ghorbani et\u00a0al. employed a combination of a genetic algorithm (GA) and support vector regression to predict asphaltene precipitation (expressed as an amount in percentage) in terms of temperature, molecular weight, and dilution ratio30. Their study involved comparing the obtained results with the outcomes of two scaling equations, confirming the superior performance of their proposed approach. Hemmati-Sarapardeh and colleagues have also been involved in predicting asphaltene precipitation amount during natural depletion. They applied the Radial Basis Function (RBF) and Multilayer Perceptron (MLP) neural networks, optimized with various optimization algorithm5. Their analysis revealed that the most effective performance was achieved with the RBF-Particle Swarm Optimization (PSO) and MLP-Bayesian Regularization (BR) intelligent techniques. Sadi and Shahrabadi introduced a modeling scheme that integrates genetic algorithms (GA) and the group method of data handling to forecast the weight percentage of asphaltene precipitation. They assessed the accuracy of their developed approach by comparing it to the results obtained from the least squares support vector machine and scaling equations31.\nKardani et\u00a0al. presented an RBF-ANN modeling approach aimed at estimating the weight percentage of precipitated asphaltene. Their results provided validation for the predictive capability of the developed model when compared to several previously proposed correlations32.\nAs can be inferred, most research efforts in the realm of asphaltene applications involving artificial intelligence have concentrated on predicting the amount of asphaltene precipitation. Notably, there is an apparent gap in the literature regarding investigations into the domain of aggregation kinetics.\nTherefore, the main focus of the current work is to propose a new efficient, and precise framework for precise predictions of aggregation kinetics of asphaltene particles. In this regard, artificial intelligence approaches, including adaptive neuro-fuzzy interference system (ANFIS), Multi-layer Perceptron (MLP), radial basis function neural network (RBF-NN), and extreme learning machine (ELM), were employed to interrelate the average diameter of asphaltene aggregates (as output) to the input parameters: temperature, pressure, time, oil specific gravity and oil asphaltene content. The Grey Wolf Optimizer (GWO) is employed to optimize and facilitate learning in RBF-NN, while MLP modeling approach parameters are regulated using Bayesian Regularization (BR), Levenberg\u2013Marquardt (LM), and Scaled Conjugate Gradient (SCG) algorithms. Subsequently, comparative\n3 Vol.:(0123456789) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\ngraphical and statistical analysis is used to assess the effectiveness of the developed models in terms of goodness of fit and prediction capability."
        },
        {
            "heading": "Model development",
            "text": "In essence, the effectiveness of a machine learning technique is contingent on various factors, encompassing the foundational theoretical framework and the architecture of the model (for instance, tree structures or neural networks), and the unique characteristics of the problem being addressed33. Additionally, the incorporation of different optimization algorithms (such as evolutionary and gradient-based) into machine learning approaches improves the tuning phase of modeling, ultimately leading to improved model performance. Moreover, the process of evaluating and comparing them plays a pivotal role in determining the most fitting modeling approach for the particular problem under consideration. Therefore, we have used these models with different theoretical bases and structures to explore the most optimized approach(s) in tackling the aggregation kinetics of asphaltene particles."
        },
        {
            "heading": "Modeling strategies",
            "text": ""
        },
        {
            "heading": "Adaptive neuro\u2011fuzzy interference system (ANFIS)",
            "text": "Adaptive Neuro-Fuzzy Inference System (ANFIS) developed by R. Jang34,35 is an intelligent algorithm based upon a hybrid neural network and fuzzy inference systems to lower the deficiencies associated with each algorithm36,37; in such approach, backpropagation (BP) and hybrid methods are training techniques based on data collection process that is used for training the initial FIS.\nANFIS structure is systematically similar to the fuzzy inference system developed by Takagi\u2013Sugeno-Kang38,39. Gradient descent backpropagation, which is the primary learning rule in ANFIS, computes the derivative of the squared error of each output node (which is known as error rates) recursively from output to input nodes40. This implies a mixed learning technique combining gradient descent and least-squares computational techniques. In the forward stage, output nodes (functional signals) are processed on the way to layer 4, and consequence parameters are achieved by least squares41. The gradient descent then renews the premise parameters in the backward step42.\nThe adaptive network structure is composed of 5 five network layers of 1 to 5 with nodes and connections illustrated in Fig.\u00a01. It is believed that one output (f) and at least two inputs (which we call x and y) are considered within the fuzzy inference system (FIS).\nTo introduce the ANFIS architecture, two fuzzy if\u2013then rules based upon a first-order Sugeno FIS are presented here43,44:\nThe two layers of this structure are defined as follows: Layer 1 defines the fuzzification process; in this layer, each node produces the membership grades of an input variable with the functions of the node explicated as follows:"
        },
        {
            "heading": "If x is A1 and y is B1 , then f1 = p1x + q1y + r1.",
            "text": "If x is A2 and y is B2 , then f2 = p2x+ q2y+ r2.\n(1)O1,i = \u00b5Ai(x), i = 1, 2.\n(2)O1,i = \u00b5Bi\u22122 ( y ) , i = 3, 4.\nFigure\u00a01. Schematic representation of ANFIS modeling approach.\n4 Vol:.(1234567890) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nIn which O1,i is the output of the node i in layer l, and subscript i denotes the membership grade of a fuzzy set that is (A1, B1, A2, B2).\nThe entire incoming signals are produced by the output node situated in layer 2, in accordance with:\nThe calculation for the ratio of a rule\u2019s firing strength, divided by the sum of all the rule\u2019s firing strengths, is as follows:\nAll nodes in layer 4 are the adaptive nodes with a node output:\nwhere qi, pi, and ri are named the consequent parameters.wi is called normalized firing strength. In the end, the ultimate output, which is the sum of all incoming signals, is computed in layer 5:\nRadial basis function (RBF) neural network The feed-forward network known as the radial basis function neural network, which was introduced by Broomhead and Lowe45, is commonly used for classification and regression tasks33. This method is based on the theory of function estimation, and during the training process, it transforms data into a multi-dimensional space in order to search for an optimal surface45,46.\nRBF-NN comprises only three fixed layers: the input layer, the hidden layer, and the output layer47. The intermediate layer in RBF-NN, which is considered the most significant component, connects the input and output layers. The intermediate layer, which plays a crucial role, links the input and output layers. Each neuron in this layer is located at a specific position with an assigned radius, and the distance between the input vector and the center is then calculated48. The Euclidian distance is used for measuring input vectors and centers interval, which is shown in Eq.\u00a0(7). Also, a simplified illustration of an RBF-NN model is shown in Fig.\u00a02.\nIn which rj and cij are the radius and center. Among all RBFs in this study, the Gaussian function was selected to transmit Euclidian distance from the\nhidden layer to the output. The Gaussian function is defined as follows:\nThe spreading coefficient, \u03c3 , is a significant parameter that deals with the smoothness of RBF and should be quantified carefully. By using the Gaussian function as an activation function in RBF-NN, the final formulation will be obtained as follows:\n(3)O2,i = wi = \u00b5Ai(x) \u00d7 \u00b5Bi ( y ) , i = 1, 2.\n(4)O3,i = wi = wi\nw1 +w2 , i = 1, 2.\n(5)O4,i = wifi = wi ( pix + qiy + ri ) , i = 1, 2.\n(6)O5,i = 2 \u2211\ni=1\nwifi = w1f1 + w2f2\nw1 + w2 .\n(7)rj =\n\u221a\n\u221a\n\u221a\n\u221a\nm \u2211\ni=1\n(xi \u2212 cij) 2j = 1, 2, . . . , J .\n(8)\u03d5(r) = exp ( \u2212 r2\n2\u03c3 2\n)\n.\nFigure\u00a02. The employed RBF neural network\u2019s specific structure.\n5 Vol.:(0123456789) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nThe RBF-NN employs weight ( w ), the number of nodes in the hidden layer ( J ), and the number of data points ( m ). The Euclidean distance is represented by \ufffdxi \u2212 cj\ufffd , as previously mentioned. To optimize the performance of RBF-NN, it is crucial to consider the two regularization parameters, namely, the spread coefficient of the Gaussian function and the number of nodes in the hidden layer, and optimize them simultaneously."
        },
        {
            "heading": "Extreme learning machine (ELM)",
            "text": "An extreme learning machine (ELM) is a single hidden layer feed-forward neural network (SLFN) in which input weights are selected randomly, and output weights are determined analytically in this approach. Many advantages of this method, such as high learning speed, a few adjustable parameters, proper for different nonlinear problems, and generally high performance, make the algorithm more efficient49.\nConsidering m as the number of data points in (xi .yi) form and n as the number of neurons in the hidden layer, this method formulation could be written as follows:\nIn which \u03c1i , f , bi , and \u03c9i are output weights, activation function, biases, and input weights for i-th neuron, respectively. The formulation, as mentioned earlier, could be written in another way as follows:\nwhere H is the hidden layer output matrix, which could be defined as follows:\nwhere, \u03c1 = (\u03c11 . . . \u03c1n)T and Y = (Y1 . . .Ym)T50. The main regularization parameter in this approach is the number of neurons in the hidden layer, which is obtained empirically."
        },
        {
            "heading": "Multi\u2011layer perceptron (MLP)",
            "text": "The most well-known classes in computational intelligence are artificial neural networks (ANNs)51,52. ANNs designed based on the biological nervous system of the human brain can be used in figuring out the relationships between the inputs and outputs of a system. There are two different components in each ANN, known as neurons or nods (processing element), that process information and interconnections that connect neurons. MLP and RBF are the most common ANNs. An MLP neural network has three layers: the input layer, which is related to the input data; the intermediate layer, which is called the hidden layer and plays a role between the input and output information, and finally, the output layer, which is related to the output data. In a model, the internal appearance of the relationship between the input and output is controlled by the hidden layers53. The number of neurons in the input layer corresponds to the number of input variables, whereas the number of neurons in the output layer typically represents the output property. It is essential to determine the number of neurons in each layer, including the number of hidden layers. Each neuron in the hidden layer is connected to all other neurons in the preceding and succeeding layers, and its value is the sum of the products of the values of each preceding neuron, a specific weight factor, and a bias term. The resulting value is then passed through activation functions, which can be applied to both hidden and output layers.\nGeneral characteristics of the applied AI modeling techniques ANFIS leverages the strengths of both neural networks and fuzzy logic, making it well-suited for handling complex and non-linear systems. It exhibits flexibility in accommodating various types of data and problem domains. However, the selection of appropriate membership functions can pose a challenge, and it tends to have a slower convergence rate compared to using neural networks alone54. MLP exhibits remarkable proficiency in tackling intricate non-linear challenges through its utilization of multi-layer networks for modeling complex problems. Furthermore, it excels in handling substantial input data and delivering swift predictions post-training. Nevertheless, it is worth noting that MLP can be computationally demanding, and the quality of training data can significantly influence the model\u2019s function55,56. Like MLP, RBF can also handle nonlinear problems. The main difference between RBF and MLP lies in their structure. RBF has a simpler architecture with three layers57. The RBF network excels in efficient localized learning and accuracy in interpolation. However, it presents challenges in selecting the appropriate basis functions and determining the optimal number of functions. Additionally, the training phase of RBF networks tends to be computationally intensive, and they are sensitive to noisy data and high-dimensional datasets58. ELM offers key benefits, such as a reduced number of hyper-parameters, rapid training speed, and the ability to perform reasonably well with large datasets. Nevertheless, the main drawback of this method is limited accuracy in certain systems, as it suffers from the lack of fine-tuning for hidden layer weights57,59.\n(9)yi = J \u2211\nj=1\nwj\u03d5ij ( \ufffdxi \u2212 cj\ufffd ) j = 1, 2, . . . , J and i = 1, 2, . . . ,m.\n(10)yj = n \u2211\ni=1\n\u03c1i f ( \u03c9ixj + bi ) , j = 1, 2, 3, . . .m.\n(11)H\u03c1 = Y ,\n(12)H =\n\n\n f (\u03c91x1 + b1) \u00b7 \u00b7 \u00b7 f (\u03c9nx1 + bn) ... . . . ...\nf (\u03c91xm + b1) \u00b7 \u00b7 \u00b7 f (\u03c9nxm + bn)\n\n  ,\n6 Vol:.(1234567890) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0"
        },
        {
            "heading": "Optimization algorithms",
            "text": "Levenberg\u2013Marquardt The Levenberg\u2013Marquardt (LM) algorithm is an effective optimization technique that is commonly utilized in numerous applications where nonlinear least-squares problems need to be solved. Its wide usage in fields such as computer vision, machine learning, and physics is due to its capability to handle complex and noisy problems60. Additionally, the LM algorithm is a popular choice for optimizing biases and weights in multilayer perceptron neural networks. Notably, calculating the Hessian matrix in the LM algorithm is not required; instead, it is approximated using the equation provided below61,62:\nThe Hessian matrix and Jacobian matrix are denoted by Hm and Jm , respectively. In the MLP modeling approach, the Jacobian matrix is defined based on the weights and biases:\nThe vector e represents the errors in the network, and the equation below can be used to calculate the gradient:\nAfter obtaining the gradient, the algorithm employs a Newton-like equation to update and determine the solution for the next steps, which is expressed as follows:\nThe variable \u03c9 represents the connection weight, and \u03b4 is a constant that can be adjusted during network training based on the outcome of each step. Specifically, if a step is successful, \u03b4 is decreased, whereas if a step is unsuccessful, \u03b4 is increased. Typically, the cost function decreases with each step57,63."
        },
        {
            "heading": "Bayesian regularization",
            "text": "The Bayesian regularization (BR) algorithm is another commonly used method in machine learning and statistical modeling that helps prevent overfitting and improve model performance. By adding a prior distribution, typically a Gaussian with zero mean and a hyper-parameter variance, to the model\u2019s parameters, the algorithm aims to identify optimal parameter values that increase the posterior probability of the model given the input data. This technique is beneficial when dealing with noisy or limited data and enables the estimation of prediction uncertainty64. The objective function for this algorithm is defined as:\nThe objective function ( fobj ) is created by adding the sum of squared network weights ( \u03c3W ) and the sum of network errors ( \u03c3E ), with a and b denoting objective function parameters determined via Bayes\u2019 theorem. The BR algorithm endeavors to build a suitable network by minimizing the sum of weights and squared errors, as indicated in equation65. Once the optimal values for a and b have been determined, the algorithm employs algebraic manipulation to utilize the LM algorithm to minimize the objective function57,63."
        },
        {
            "heading": "Scaled conjugate gradient",
            "text": "The Scaled Conjugate Gradient (SCG) algorithm is a widely used numerical optimization method for optimizing machine learning model parameters, particularly in artificial neural networks. Its development aimed to create a more efficient and robust optimization technique than other commonly used methods, such as gradient descent and conjugate gradient. SCG combines conjugate gradient and line search techniques to minimize the objective function, and it incorporates a scaling procedure to adjust the step size based on the objective function\u2019s curvature.\nThe scaled conjugate gradient algorithm employs the conjugate direction for faster convergence instead of abrupt descent. The initial descent direction ( \u2212i0 ) and the search direction ( S0 ), which is also referred to as the conjugate direction, are related and can be mathematically represented61:\nTo identify the most suitable distance to move along the current search direction in this algorithm, a search line technique is employed. The technique can be described as follows:\nThe calculation of the subsequent search direction in this algorithm depends on the previous conjugate direction. The formula utilized to determine the next search direction is as follows:\n(13)Hm = JTmJm.\n(14)J(\u03b1) =\n\n\n\n\n\u2202e1(\u03b1) \u2202\u03b11 \u00b7 \u00b7 \u00b7 \u2202e1(\u03b1) \u2202\u03b1n\n... . . . ... \u2202eN (\u03b1) \u2202\u03b11 \u00b7 \u00b7 \u00b7 \u2202eN (\u03b1) \u2202\u03b1n\n\n\n\n\n.\n(15)g = JT e.\n(16)\u03c9i+1 = \u03c9i \u2212 (JT J \u2212 \u03b4I)\u22121JT e.\n(17)fobj = a\u03c3W + b\u03c3E .\n(18)S0 = \u2212i0.\n(19)uj+1 = uj + ajij .\n(20)Sj = \u2212ij + bjSj\u22121.\n7 Vol.:(0123456789) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nNotably, the SCG algorithm merges the conjugate gradient algorithm with the trust region approach, given that the line search method utilized to determine the step size may incur significant computational costs. Additionally, the latter is not the only approach used to determine the step size in the SCG algorithm57,66."
        },
        {
            "heading": "Grey wolf optimizer (GWO)",
            "text": "In this study, a meta-heuristic algorithm, namely Grey Wolf Optimizer, was utilized to optimize the RBF-NN parameters and gain more precise results. The grey wolf prefers to spend its life in the pack. The leaders are a female and a male, called alphas. The alpha is primarily responsible for decisions about hunting, sleep place, time to wake up, and so on. Beta is the second level in a gray wolf \u2019s hierarchy. The betas are obedient wolves that help the alpha in decision-making or other activities in the pack. Omega is the lowest rank of gray wolves. The omega wolf function as a submissive figure, consistently yielding to other dominant wolves. It is often referred to as a scapegoat. If a wolf does not hold the alpha, beta, or omega position, it is considered a subordinate or delta, according to some sources. Delta wolves are subordinate to the alpha and beta but dominate over the omega. The hunting behavior of grey wolves can be divided into several key stages:\n\u2022 Tracking, pursuit, and approach to prey. \u2022 Chasing, circling, and harassing the prey until it stops moving. \u2022 Attack at the prey.\nIn this optimization algorithm, all of the above cases have been implemented. Additionally, the search agents have been divided into four categories: alpha, beta, delta, and omega. In this optimization algorithm, alpha represents the best solution in the current iteration. Grey wolves have a way of identifying prey\u2019s location and encircling them. Usually the alpha is in charge of hunting. Occasionally the beta and deltas would play an essential part in a hunt. Nevertheless, in the abstract search space, the best (prey) location is unknown. Mathematically modeling grey wolf hunting behavior involves assuming that the alpha, beta, and delta have superior knowledge about the potential location of prey. As a result, we save the top three best solutions gathered thus far and compel the other search agents, including the omega, to adjust their positions based on the best search agent\u2019s position67,68."
        },
        {
            "heading": "Data gathering",
            "text": "The development of an accurate modeling strategy is strongly associated with the quality of the utilized dataset. The experimental measurements applied in the present work were collected from the literature69. They measured the average diameter of asphaltene aggregates for two different crude oil samples (Samples A and B) at different pressure, temperature, and time values. This dataset comprises 423 data points, of which 70% and the rest were exploited as the train, test (15%), and validation (15%) samples, respectively. The diameter of asphaltene aggregates depends on different variables such as pressure, temperature, time, characteristics of the crude oil, type of asphaltene (basic structure of asphaltene), and asphaltene content, etc. In the current study, temperature, pressure, time, oil specific gravity (as a representative of crude oil characteristics), and oil asphaltene content were considered as the input variables. The output variable is the average diameter of asphaltene aggregates. The statistical criteria of the gathered dataset are shown in Table\u00a01.\nAccording to Table\u00a01, each parameter has a specific range, which can decrease training process performance and, subsequently, model accuracy. Therefore, as a pre-process step the parameters mentioned above are mapped to a new range between \u2212\u00a01 and 1 using the equation below."
        },
        {
            "heading": "Results and discussion",
            "text": ""
        },
        {
            "heading": "Model development",
            "text": "In this study, four intelligent models, namely ANFIS, RBF-NN, MLP, and ELM, are proposed to accurately calculate the average diameter of asphaltene aggregates based on various factors such as time, pressure, temperature, crude oil specific gravity, and asphaltene content. To conduct our research, we utilized a comprehensive data bank that covers a wide range of laboratory conditions.\n(21)xm = 2 (x \u2212 xmin)\n(xmax \u2212 xmin) \u2212 1.\n8 Vol:.(1234567890) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nThe dataset was randomly divided into three groups, namely, the train set, the test set, and the validation set. The training set included 70% of the dataset used for training the model. The 15% of the whole dataset was selected for a test set that is utilized to evaluate the prediction capability and generality of the developed model. Also, the remaining 15% was selected as the validation set to find the optimum parameters for each model and overcome the over-fitting issues. To assess the developed models with different characteristics, some statistical parameters were calculated and subsequently compared with each other to find the most accurate one.\nThe optimal values of the hyper-parameters (regularization parameters) were obtained through trial and error, except for RBF-NN, where the Grey Wolf Optimization algorithm was used to find the optimal hyper-parameter values. This process was repeated multiple times to achieve the best possible results. The GWO algorithm optimized RBF-NN\u2019s regularization parameters by 15 iterations, and the population size contains 50 search agents. The optimized values for RBF-NN, the \u201cnumber of neurons\u201d in the hidden layer and \u201cspread coefficient,\u201d are 99 and 0.5803, respectively. There are two popular structure types for the ANFIS modeling approach: Takagi\u2013Sugeno-Kang (TSK) and Mamdani. In this research, the ANFIS approach was implemented using the TSK structure.\nFurthermore, the FIS was generated using the Fuzzy C-Means (FCM) technique, with the parameters \u2019number of clusters\u2019 set to 18 and \u2019exponent\u2019 configured at 2.3. The exponent serves as a tuning parameter in the ANFIS algorithm, regulating the level of fuzziness, and it is conventionally assigned a value greater than 1. In the ELM modeling approach, the number of neurons has been established at 104. In the case of the MLP modeling approach, the number of neurons in the hidden layer is set to 21, and the activation functions for the hidden and output layers are Tansig. Table\u00a02 provides a concise overview of the regularization parameter values used in the intelligent models."
        },
        {
            "heading": "Statistical error evaluation",
            "text": "Statistical analysis of error parameters is an essential component of any modeling approach. To assess the reliability and performance of the developed models, several statistical indicators are commonly used. In this study, we employed three such indicators: average absolute relative deviation percentage (AARD%), determination coefficient ( R2 ), and root mean square error (RMSE)70. These parameters are defined as follows, respectively:\nDexp and Dpred denote experientially measured and predicted values of asphaltene aggregate average diameter, respectively, and N is the number of data points.\nThe statistical parameters for the proposed models are presented in Table\u00a03. The accuracy of the models was heavily influenced by the optimization of their regularization parameters. In this study, we compared the implemented paradigms based on the AARD% value, as it is not affected by the scale of the data."
        },
        {
            "heading": "Graphical error evaluation",
            "text": "Statistical plots such as Cumulative frequency versus absolute relative error plot, cross plot, average absolute relative deviation percent plot, Relative error versus experimental data points plot, and error distribution plot\n(22)AARD% =\n(\n1\nN\nN \u2211\ni=1\n(\u2223\n\u2223\n\u2223\n\u2223\n\u2223\nDexp \u2212 Dpred\nDexp\n\u2223\n\u2223\n\u2223\n\u2223\n\u2223\n))\n\u00d7 100\n(23) R2=1-\n\u2211N i=1\n( Dexp \u2212 Dpred )2\n\u2211N i=1\n(\nDexp\u2212 \u2212 D\n)2\n(24)RMSE =\n\u221a\n\u221a\n\u221a\n\u221a\n1\nN\nN \u2211\ni=1\n( Dexp\u2212Dpred )2\n9 Vol.:(0123456789) Scientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nare practical tools to evaluate the performance of the developed models visually. Figure\u00a03 illustrates the average absolute relative deviation percent ( AARD% ) for train, validation, test, and total sets.\nBased on the AARD% values presented in Table\u00a03 and Fig.\u00a03, all models in this study exhibit satisfactory performance. However, it is evident that the GWO-RBF model provides the best results in terms of statistical parameters, while the MLP-SCG approach demonstrates the lowest prediction capability. Figure\u00a04 displays crossplots of predicted and experimental data points for the train, validation, and test sets. The one-slope line that emerged from the data points for each model confirms their accuracy.\nFigure\u00a05 illustrates the relative error percent (RE %) versus the experimental average diameter. It is worth noting that the accumulation of data points around the zero error line indicates the model\u2019s superiority. Figure\u00a05 illustrates that all proposed approaches exhibit a satisfactory clustering of data points around the zero error line. However, certain data points with low average diameter may not provide as accurate predictions as others. Among the models tested, GWO-RBF displays the most pronounced concentration around the zero error line.\nAdditionally, Fig.\u00a06 depicts the cumulative frequency versus absolute relative error for all paradigms investigated in this study. As shown in this figure, for ELM, ANFIS, MLP-BR, and MLP-SCG models, 90.31%, 91.73%, 93.38% and 76.83% of the whole data have an absolute relative error of less than 4%, respectively. In the same condition, this figure indicates more than 94% for the GWO-RBF and MLP-LM paradigms. Also, it should be noted that the maximum value of absolute relative errors for GWO-RBF, ANFIS, ELM, MLP-BR, MLP-LM, and MLP-SCG are 12.50%, 17.31%, 16.03%, 16.02%, 16.99%, and 21.36%, respectively. Therefore, based on previous explanations, GWO-RBF can be selected as the best model in this study, and all of the paradigms can be ranked as follows:\nGWO \u2212 RBF > MLP \u2212 LM > MLP \u2212 BR > ANFIS > ELM > MLP \u2212 SCG\nTable 3. Different statistical parameters for proposed paradigms.\nModel Statistical parameter Training data Validation data Testing data Total data\nANFIS\nAARD% 1.4998 1.5395 1.9146 1.5674\nR2 0.9993 0.9985 0.9982 0.9992\nRMSE 0.0578 0.0536 0.0766 0.0604\nGWO-RBF\nAARD% 1.0742 1.265 1.2759 1.1326\nR2 0.9996 0.9988 0.9990 0.9993\nRMSE 0.0409 0.0834 0.0675 0.0537\nMLP-LM\nAARD% 1.1015 1.3800 1.3312 1.1772\nR2 0.9997 0.9981 0.9974 0.9993\nRMSE 0.0415 0.0519 0.0967 0.0548\nMLP-BR\nAARD% 1.1535 1.5675 1.5953 1.281\nR2 0.9997 0.9978 0.9985 0.9992\nRMSE 0.0349 0.0961 0.0853 0.0575\nMLP-SCG\nAARD% 2.6824 3.0387 3.1918 2.8113\nR2 0.9977 0.9947 0.9977 0.9972\nRMSE 0.0941 0.1559 0.1219 0.1098\nELM\nAARD% 1.7356 \u2013 2.7408 2.0374\nR2 0.9996 \u2013 0.9946 0.9980\nRMSE 0.0385 \u2013 0.1611 0.0940\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\nANFIS GWO-RBF MLP-LM MLP-BR MLP-SCG ELM\nA A R D %\nTrain Validation Test Total\nFigure\u00a03. AARD% value for train, validation, test, and total set.\n10\nVol:.(1234567890)\nScientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nFigure\u00a07 further confirms the robustness of the best-developed model. This figure illustrates the relative error percent (RE%) between the predicted and experimental values of the GWO-RBF model. As shown in the plot, the majority of predicted results by the best-developed model have relative error values within the range of \u2212\u00a03% to + 3% for the entire dataset. This indicates the high accuracy of the presented model.\nIn addition to accuracy comparison, the machine learning approaches employed can also be compared based on their computational effort. In this regard, the models were evaluated in terms of their CPU time consumption. It is important to mention that the model codes were executed on a computer system equipped with a Core i7-4910MQ processor, running at a base frequency of 2.90 GHz.\nFigure\u00a08 provides a comparison of different methods based on CPU time. As shown, the GWO-RBF (which performed the best based on the AARD%) exhibited the highest CPU time among the applied techniques. The reason for the increased CPU time for the GWO-RBF method, compared to other methods, is its utilization of a metaheuristic optimization algorithm to find optimal solutions for two hyper-parameters within this model. This metaheuristic algorithm requires more time to converge to optimal values as it operates on a population-based approach. However, it is worth noting that such algorithms tend to achieve high-quality solutions.\nIn contrast, MLP-SCG showed the shortest CPU time. This can be attributed to the SCG algorithm, which operates based on gradients, enabling it to converge more rapidly than the GWO algorithm, which relies on a population-based meta-heuristic approach. However, it is worth noting that gradient-based algorithms are more susceptible to becoming trapped in local optima when compared to meta-heuristic methods.\nOverall, in scenarios where computational resources are limited, lightweight and efficient models (e.g., MLP and ELM) can be applied with an acceptable degree of prediction error. Conversely, when computational resources are more abundant, and a strong emphasis is placed on achieving high accuracy, it becomes viable to utilize models that offer higher accuracy at the expense of increased resource consumption, such as GWO-RBF."
        },
        {
            "heading": "Computational complexity of models",
            "text": "Assessing the computational complexity of different machine learning models can be a laborious task. This is because it hinges on several factors, including the way the model is structured, the size of the dataset, the optimization methods employed, and so on. In this way, big O notation is used to explain the worst-case behavior for an algorithm complexity. Furthermore, the big O notation typically considers all feature inputs collectively, while the number of samples may fluctuate throughout the analysis71. Although the exact determination of big O for the models applied here is very challenging, we try to provide a rough estimate and qualitative comparison.\n0\n5\n10\n15\n20\n0 5 10 15 20P re\nd .\nA v\ner ag\ne D\nia m\net er\n( m\nic ro\nn s)\nExp. Average Diameter (microns)\nANFIS\nTrain\nValidation\nTest\nY = X 0\n5\n10\n15\n20\n0 5 10 15 20P re\nd .\nA v\ner ag\ne D\nia m\net er\n( m\nic ro\nn s)\nExp. Average Diameter (microns)\nELM\nTrain\nTest\nY = X\n0\n5\n10\n15\n20\n0 5 10 15 20\nP re\nd .\nA v\ner ag\ne D\nia m\net er\n( m\nic ro\nn s)\nExp. Average Diameter (microns)\nGWO-RBF\nTrain\nValidation\nTest\nY = X 0\n5\n10\n15\n20\n0 5 10 15 20\nP re\nd .\nA v\ner ag\ne D\nia m\net er\n( m\nic ro\nn s)\nExp. Average Diameter (microns)\nMLP-BR\nTrain\nValidation\nTest\nY = X\n0\n5\n10\n15\n20\n0 5 10 15 20\nP re\nd .\nA v\ner ag\ne D\nia m\net er\n( m\nic ro\nn s)\nExp. Average Diameter (microns)\nMLP-LM\nTrain\nValidation\nTest\nY = X 0\n5\n10\n15\n20\n0 5 10 15 20P re\nd .\nA v\ner ag\ne D\nia m\net er\n( m\nic ro\nn s)\nExp. Average Diameter (microns)\nMLP-SCG\nTrain\nValidation\nTest\nY = X\nFigure\u00a04. Predicted versus experimental values of average asphaltene aggregate diameter.\n11\nVol.:(0123456789)\nScientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nIn the case of ELM, the computational complexity is relatively lower than other applied techniques. It usually depends on the number of neurons (Nn) and data dimension (Dd). In this regard, the computational complexity of approximately O (Nn \u00d7 Dd) may be assumed. The computational complexity of ANFIS is influenced by a combination of factors, including the number of fuzzy rules, the selected training method, the complexity of membership functions, and the quantity of input variables. In general, ANFIS models tend to have a moderate level of computational complexity.\nNevertheless, it is essential to recognize that the exact complexity can vary considerably based on the specific configuration and the nature of the problem under consideration72. Therefore, assigning a big O is very challenging. Like ANFIS, The computational complexity of MLP can range from moderate to high, depending on their specific configurations.\n-20\n-10\n0\n10\n20\n0 5 10 15 20\nR el\nat iv\ne Er\nro r\n(% )\nExp. Average Diameter (microns)\nANFIS\nTrain Validation Test Y = 0 -20 -10\n0\n10\n20\n0 5 10 15 20\nR el\nat iv\ne Er\nro r\n(% )\nExp. Average Diameter (microns)\nELM\nTrain\nTest\nY = 0\n-20\n-10\n0\n10\n20\n0 5 10 15 20\nR el\nat iv\ne Er\nro r\n(% )\nExp. Average Diameter (microns)\nGWO-RBF\nTrain Validation Test Y = 0 -20 -10\n0\n10\n20\n0 5 10 15 20\nR el\nat iv\ne Er\nro r\n(% )\nExp. Average Diameter (microns)\nMLP-BR\nTrain\nValidation\nTest\nY = 0\n-20\n-10\n0\n10\n20\n0 5 10 15 20\nR el\nat iv\ne Er\nro r\n(% )\nExp. Average Diameter (microns)\nMLP-LM\nTrain Validation Test Y = 0\n-30\n-20\n-10\n0\n10\n20\n0 5 10 15 20\nR el\nat iv\ne Er\nro r\n(% )\nExp. Average Diameter (microns)\nMLP-SCG\nTrain\nValidation\nTest\nY = 0\nFigure\u00a05. Relative error versus experimental average diameter.\n0\n0.2\n0.4\n0.6\n0.8\n1\n0 2 4 6 8 10\nC um\nul at\niv e\nFr eq\nue nc\ny\nAbsolute Relative Error (%)\nANFIS\nELM\nGWO-RBF\nMLP-BR\nMLP-LM\nMLP-SCG\nFigure\u00a06. Cumulative frequency versus absolute relative error.\n12\nVol:.(1234567890)\nScientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0\nThe computational complexity could be approximately on the order of O (Ke \u00d7 Nn \u00d7 Dd), with K representing the count of training epochs. The computational complexity of an RBF network is influenced by factors like the number of RBF units, the dimensionality of the input data, and the training procedure. In the training phase, an overall computational complexity of approximately O (M \u00d7 N \u00d7 Dd \u00d7 I) is assumed, where M refers to the training sample size, N represents the number of RBF units, and I indicates the number of iterations necessary for reaching convergence. However, some references state the RBF complexity simply as O(N2)73."
        },
        {
            "heading": "Model trend estimation",
            "text": "Trend estimation is a crucial step in post-evaluating a modeling strategy and verifying a model\u2019s ability to track the variations in experimental measurements. To validate the robustness of the best-proposed model, we assessed the GWO-RBF approach\u2019s trend-prediction capability under different conditions, as shown in Fig.\u00a09. The figure presents a comparison between the predicted and experimental average diameter of asphaltene aggregates over time for oil samples A and B under varying pressure and temperature conditions. The figure demonstrates that the GWO-RBF model accurately predicts the asphaltene aggregate diameter and the process trend under different states.\nThis study offers an AI-based predictive framework for accurately predicting the kinetics of asphaltene particle aggregation, addressing a critical concern in different phases of production from petroleum reservoirs. Its effectiveness lies in the accuracy of predictions obtained through the utilization of diverse AI methodologies and the thorough examination of significant variables. In addition, the proposed strategies have the potential to be integrated with the available simulator to consider the asphaltene precipitation phenomena more accurately. This integration could result in mitigating the uncertainties and improving prediction capability. Nonetheless, the AI-based paradigms are usually restricted by their reliance on available data and potential challenges in generalizing to a wide range of conditions. In other words, the extent of practical applicability of the developed models could be improved as more data is available for their training.\n-15 -12 -9 -6 -3 0 3 6 9 12 15 Relative Error(%)\n0\n20\n40\n60\n80\n100\n120\n140\nFr eq\nue nc\ny\nTrain Validation Test\nFigure\u00a07. Comparison of data frequency versus relative error percent for all data points for GWO-RBF.\n1\n10\n100\n1000\n10000\nGWO-RBF ANFIS ELM MLP-BR MLP-LM MLP-SCG\nC PU\nT im\ne (s\nec on\nds )\nFigure\u00a08. CPU time for applied machine learning schemes.\n13\nVol.:(0123456789)\nScientific Reports | (2023) 13:18525 | https://doi.org/10.1038/s41598-023-45685-0"
        },
        {
            "heading": "Conclusions",
            "text": "In the current research, reliable models based on GWO-RBF, MLP-LM, MLP-BR, MLP-SCG ANFIS, and ELM were constructed to estimate the asphaltene aggregate diameter versus time in terms of pressure, temperature, oil asphaltene content, and oil specific gravity. A series of experimental data was acquired based on the published literature to construct the model. A terrific match was obtained in terms of statistical parameters between the experimental and predicted values of asphaltene aggregate diameter using the developed models. However, the proposed GWO-RBF model exhibits higher accuracy compared to the other models for which the resulted coefficient of determination, average absolute relative deviation percent, and root mean square error were 0.9993, 1.1326%, and 0.0537, respectively. The obtained results show the strong generalization ability and high prediction capability of the introduced models."
        },
        {
            "heading": "Data availability",
            "text": "The datasets generated during and/or analyzed during the current study are available from the corresponding author on reasonable request.\nReceived: 9 June 2023; Accepted: 23 October 2023"
        },
        {
            "heading": "Author contributions",
            "text": "A.S.: conceptualization, methodology, software, investigation, data collection and curation, writing\u2014original draft preparation. M.B.: writing\u2014original draft preparation, software, validation, data analysis. A.D.M.: conceptualization, methodology, data curation, investigation, supervision, visualization, writing\u2014original draft preparation, reviewing and editing. All authors reviewed the manuscript."
        },
        {
            "heading": "Competing interests",
            "text": "The authors declare no competing interests."
        },
        {
            "heading": "Additional information",
            "text": "Correspondence and requests for materials should be addressed to A.D.M.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n\u00a9 The Author(s) 2023"
        }
    ],
    "title": "Artificial intelligence\u2010based framework for precise prediction of asphaltene particle aggregation kinetics in petroleum recovery",
    "year": 2023
}