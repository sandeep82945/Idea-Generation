{
    "abstractText": "This Special Section of the journal Computers & Graphics is evoted to the selected best papers submitted to the 31st edition f the Spanish Conference on Computer Graphics (CEIG) 2022. his edition was held in Vic (Spain) during July 5\u20138th. This nnual conference is sponsored by the Spanish Section of the urographics Association and the main goal is to promote disussion between computer graphics researchers and practitioners n Spain, as well as to disseminate recent advances in the field nd present ongoing works. The conference traditionally includes egular paper sessions, invited talks presenting high-quality reently published works, short papers, poster presentations, and eynote talks from internationally renowned speakers in all areas f computer graphics and visual computing. This year five of the papers submitted to the conference were elected based on their high quality and after a rigorous, complete wo-cycle peer-review by no less than three experts in the field, re published in this Special Section. The selected papers cover iverse topics. Bernal et al. [1] present in their work a novel aliency prediction model for 360 videos based on spherical conolutions and recurrent neural networks to extract the relevant patio-temporal features. This model outperforms various statef-the-art works in predicting human visual attention when exloring dynamic 360 content. The work presented by Etxezarreta t al. [2] addresses the problem of predicting contact areas for rasping complex geometries by robotic grippers. Existing aproaches typically simplify either the gripper or the shape of he object. Instead, this work integrates a fast collision detection ystem to the grasping process that can approximate contact suraces between arbitrarily complex grippers and grasped objects in eal-time. Experimental results are shown with extensive simulaions for multiple shapes and resolutions. L\u00f3pez et al. [3] present a ethod for the generation of hyperspectral point clouds. Existing olutions use LiDAR and hyperspectral sensors integrated into the ame acquisition system which can lead to errors derived from nertial measurements for data fusion and the limited resolution f the LiDAR. This work provides a solution for generating, comressing and rendering 3D hyperspectral point clouds from input ata composed of push-broom hyperspectral and 3D point clouds. u\u00f1oz-Pandiella et al. [4] introduce an automatic algorithm to inimize RGB color differences among a collection of registered anoramic HDR images captured with Terrestrial Lidar Scanners. ypically, these collected images are used to colorize the accomanying point clouds, however, due to existing color differences etween the different panoramas, this can lead to artifacts. After pplying the proposed method, the processed panoramas can e used to colorize point clouds consistently. Finally, in their ork Royo et al. [5] introduce a set of subpath sampling techiques targeting transient light transport simulation in occluded",
    "authors": [],
    "id": "SP:25e43b7c37bf24b19d4c3d231477b6f64a38ea70",
    "references": [
        {
            "authors": [
                "E Bernal",
                "D Martin",
                "D Gutierrez",
                "B. Masia"
            ],
            "title": "SST-Sal: A spherical spatiotemporal approach for saliency prediction in 360 videos. Comput Graph 2022;106:200\u20139",
            "year": 2022
        },
        {
            "authors": [
                "A Etxezarreta-Arruti",
                "M. Sagardia"
            ],
            "title": "Real time contact surface prediction for grasping with complex geometries. Comput Graph 2022;107:66\u201372",
            "year": 2022
        },
        {
            "authors": [
                "A L\u00f3pez",
                "JM Jurado",
                "JR Jim\u00e9nez",
                "FR. Feito"
            ],
            "title": "Generation of hyperspectral point clouds: Mapping, compression and rendering",
            "venue": "Comput Graph",
            "year": 2022
        },
        {
            "authors": [
                "I Mu\u00f1oz-Pandiella",
                "M Comino",
                "C Andujar",
                "O Argudo",
                "C Bosch",
                "A Chica"
            ],
            "title": "Gain compensation across LIDAR scans",
            "venue": "Comput Graph 2022;106:174\u201386",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "d o T a E c i a r c k o\ns t a d s v s o p e g p t s f r t m s s i o p d M m p T p b a b w n\nh 0\nContents lists available at ScienceDirect\nComputers & Graphics\njournal homepage: www.elsevier.com/locate/cag\nEditorial\nForeword to the Special Section on CEIG 2022\nThis Special Section of the journal Computers & Graphics is evoted to the selected best papers submitted to the 31st edition f the Spanish Conference on Computer Graphics (CEIG) 2022. his edition was held in Vic (Spain) during July 5\u20138th. This nnual conference is sponsored by the Spanish Section of the urographics Association and the main goal is to promote disussion between computer graphics researchers and practitioners n Spain, as well as to disseminate recent advances in the field nd present ongoing works. The conference traditionally includes egular paper sessions, invited talks presenting high-quality reently published works, short papers, poster presentations, and eynote talks from internationally renowned speakers in all areas f computer graphics and visual computing. This year five of the papers submitted to the conference were elected based on their high quality and after a rigorous, complete wo-cycle peer-review by no less than three experts in the field, re published in this Special Section. The selected papers cover iverse topics. Bernal et al. [1] present in their work a novel aliency prediction model for 360\u25e6 videos based on spherical conolutions and recurrent neural networks to extract the relevant patio-temporal features. This model outperforms various statef-the-art works in predicting human visual attention when exloring dynamic 360\u25e6 content. The work presented by Etxezarreta t al. [2] addresses the problem of predicting contact areas for rasping complex geometries by robotic grippers. Existing aproaches typically simplify either the gripper or the shape of he object. Instead, this work integrates a fast collision detection ystem to the grasping process that can approximate contact suraces between arbitrarily complex grippers and grasped objects in eal-time. Experimental results are shown with extensive simulaions for multiple shapes and resolutions. L\u00f3pez et al. [3] present a ethod for the generation of hyperspectral point clouds. Existing olutions use LiDAR and hyperspectral sensors integrated into the ame acquisition system which can lead to errors derived from nertial measurements for data fusion and the limited resolution f the LiDAR. This work provides a solution for generating, comressing and rendering 3D hyperspectral point clouds from input ata composed of push-broom hyperspectral and 3D point clouds. u\u00f1oz-Pandiella et al. [4] introduce an automatic algorithm to inimize RGB color differences among a collection of registered anoramic HDR images captured with Terrestrial Lidar Scanners. ypically, these collected images are used to colorize the accomanying point clouds, however, due to existing color differences etween the different panoramas, this can lead to artifacts. After pplying the proposed method, the processed panoramas can e used to colorize point clouds consistently. Finally, in their ork Royo et al. [5] introduce a set of subpath sampling techiques targeting transient light transport simulation in occluded\nttps://doi.org/10.1016/j.cag.2022.08.009 097-8493/\u00a9 2022 The Author(s). Published by Elsevier Ltd. This is an open access a\nnc-nd/4.0/).\nscenes. These techniques are implemented in a modified version of Mitsuba 2 that supports transient light transport, therefore the implementation also supports parallelization, polarization and differentiable rendering.\nWe would like to thank the Keynote speakers, Prof. Yiorgos Chrysanthou (CYENS Centre of Excellence - University of Cyprus), Dr. Duygu Ceylan (Adobe Research), and Dr. Oscar Argudo (Universitat Polit\u00e8cnica de Catalunya) for participating in this edition and delivering very exciting talks about a diversity of topics. We would also like to thank the program committee for their valuable reviews and feedback on the submitted articles. Finally, we thank the members of the executive board of the Eurographics Spanish Section for inviting us to serve as Program Chairs for this year\u2019s CEIG, as well as the Computers & Graphics Editor-in-Chief and the Elsevier staff for their help in making this Special Section a success."
        },
        {
            "heading": "Declaration of competing interest",
            "text": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."
        }
    ],
    "year": 2022
}