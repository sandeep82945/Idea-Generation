{
    "abstractText": "We consider a safe optimization problem with bandit feedback in which an agent sequentially chooses actions and observes responses from the environment, with the goal of maximizing an arbitrary function of the response while respecting stage-wise constraints. We propose an algorithm for this problem, and study how the geometric properties of the constraint set impact the regret of the algorithm. In order to do so, we introduce the notion of the sharpness of a particular constraint set, which characterizes the difficulty of performing learning within the constraint set in an uncertain setting. This concept of sharpness allows us to identify the class of constraint sets for which the proposed algorithm is guaranteed to enjoy sublinear regret. Simulation results for this algorithm support the sublinear regret bound and provide empirical evidence that the sharpness of the constraint set impacts the performance of the algorithm.",
    "authors": [
        {
            "affiliations": [],
            "name": "Spencer Hutchinson"
        },
        {
            "affiliations": [],
            "name": "Berkay Turan"
        },
        {
            "affiliations": [],
            "name": "Mahnoosh Alizadeh"
        }
    ],
    "id": "SP:41ebe3dff738447ab22c59d11d47172ac1a6acc5",
    "references": [
        {
            "authors": [
                "Yasin Abbasi-Yadkori",
                "D\u00e1vid P\u00e1l",
                "Csaba Szepesv\u00e1ri"
            ],
            "title": "Improved algorithms for linear stochastic bandits",
            "venue": "Advances in neural information processing systems,",
            "year": 2011
        },
        {
            "authors": [
                "Sanae Amani",
                "Mahnoosh Alizadeh",
                "Christos Thrampoulidis"
            ],
            "title": "Linear stochastic bandits under safety constraints",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Xiaoqing Bai",
                "Hua Wei",
                "Katsuki Fujisawa",
                "Yong Wang"
            ],
            "title": "Semidefinite programming for optimal power flow problems",
            "venue": "International Journal of Electrical Power & Energy Systems,",
            "year": 2008
        },
        {
            "authors": [
                "Felix Berkenkamp",
                "Andreas Krause",
                "Angela P Schoellig"
            ],
            "title": "Bayesian optimization with safety constraints: safe and automatic parameter tuning in robotics",
            "venue": "Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Sapana Chaudhary",
                "Dileep Kalathil"
            ],
            "title": "Safe online convex optimization with unknown linear safety constraints",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Shaoru Chen",
                "Ning-Yuan Li",
                "Victor M Preciado",
                "Nikolai Matni"
            ],
            "title": "Robust model predictive control of time-delay systems through system level synthesis",
            "venue": "arXiv preprint arXiv:2209.11841,",
            "year": 2022
        },
        {
            "authors": [
                "Varsha Dani",
                "Thomas P Hayes",
                "Sham M Kakade"
            ],
            "title": "Stochastic linear optimization under bandit feedback",
            "year": 2008
        },
        {
            "authors": [
                "Masoud Farivar",
                "Steven H Low"
            ],
            "title": "Branch flow model: Relaxations and convexification\u2014part",
            "venue": "i. IEEE Transactions on Power Systems,",
            "year": 2013
        },
        {
            "authors": [
                "Mohammad Fereydounian",
                "Zebang Shen",
                "Aryan Mokhtari",
                "Amin Karbasi",
                "Hamed Hassani"
            ],
            "title": "Safe learning under uncertain objectives and constraints",
            "venue": "arXiv preprint arXiv:2006.13326,",
            "year": 2020
        },
        {
            "authors": [
                "Javier Garc\u0131a",
                "Fernando Fern\u00e1ndez"
            ],
            "title": "A comprehensive survey on safe reinforcement learning",
            "venue": "Journal of Machine Learning Research,",
            "year": 2015
        },
        {
            "authors": [
                "Lukas Hewing",
                "Kim P Wabersich",
                "Marcel Menner",
                "Melanie N Zeilinger"
            ],
            "title": "Learning-based model predictive control: Toward safe learning in control",
            "venue": "Annual Review of Control, Robotics, and Autonomous Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Spencer Hutchinson",
                "Berkay Turan",
                "Mahnoosh Alizadeh"
            ],
            "title": "A safe pricing mechanism for distributed resource allocation with bandit feedback",
            "venue": "IEEE 61st Conference on Decision and Control (CDC),",
            "year": 2022
        },
        {
            "authors": [
                "Sebastian Junges",
                "Nils Jansen",
                "Christian Dehnert",
                "Ufuk Topcu",
                "Joost-Pieter Katoen"
            ],
            "title": "Safetyconstrained reinforcement learning for mdps. In International conference on tools and algorithms for the construction and analysis of systems, pages 130\u2013146",
            "year": 2016
        },
        {
            "authors": [
                "Abbas Kazerouni",
                "Mohammad Ghavamzadeh",
                "Yasin Abbasi Yadkori",
                "Benjamin Van Roy"
            ],
            "title": "Conservative contextual linear bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Torsten Koller",
                "Felix Berkenkamp",
                "Matteo Turchetta",
                "Andreas Krause"
            ],
            "title": "Learning-based model predictive control for safe exploration",
            "venue": "IEEE conference on decision and control (CDC),",
            "year": 2018
        },
        {
            "authors": [
                "Daniel K Molzahn",
                "Florian D\u00f6rfler",
                "Henrik Sandberg",
                "Steven H Low",
                "Sambuddha Chakrabarti",
                "Ross Baldick",
                "Javad Lavaei"
            ],
            "title": "A survey of distributed optimization and control algorithms for electric power systems",
            "venue": "IEEE Transactions on Smart Grid,",
            "year": 2017
        },
        {
            "authors": [
                "Ahmadreza Moradipari",
                "Christos Thrampoulidis",
                "Mahnoosh Alizadeh"
            ],
            "title": "Stage-wise conservative linear bandits",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Ahmadreza Moradipari",
                "Sanae Amani",
                "Mahnoosh Alizadeh",
                "Christos Thrampoulidis"
            ],
            "title": "Safe linear thompson sampling with side information",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Aldo Pacchiano",
                "Mohammad Ghavamzadeh",
                "Peter Bartlett",
                "Heinrich Jiang"
            ],
            "title": "Stochastic bandits with linear constraints",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "Rolf Schneider"
            ],
            "title": "Convex bodies: the Brunn\u2013Minkowski theory",
            "venue": "Number 151. Cambridge university press,",
            "year": 2014
        },
        {
            "authors": [
                "Yanan Sui",
                "Joel W Burdick"
            ],
            "title": "Correlational dueling bandits with application to clinical treatment in large decision spaces",
            "venue": "In Proceedings of the 26th International Joint Conference on Artificial Intelligence,",
            "year": 2017
        },
        {
            "authors": [
                "Yanan Sui",
                "Alkis Gotovos",
                "Joel Burdick",
                "Andreas Krause"
            ],
            "title": "Safe exploration for optimization with gaussian processes",
            "venue": "In International conference on machine learning,",
            "year": 2015
        },
        {
            "authors": [
                "Yanan Sui",
                "Vincent Zhuang",
                "Joel Burdick",
                "Yisong Yue"
            ],
            "title": "Stagewise safe bayesian optimization with gaussian processes",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Ilnura Usmanova",
                "Andreas Krause",
                "Maryam Kamgarpour"
            ],
            "title": "Safe convex learning under uncertain constraints",
            "venue": "In The 22nd International Conference on Artificial Intelligence and Statistics,",
            "year": 2019
        },
        {
            "authors": [
                "Ilnura Usmanova",
                "Andreas Krause",
                "Maryam Kamgarpour"
            ],
            "title": "Safe non-smooth black-box optimization with application to policy search",
            "venue": "In Learning for Dynamics and Control,",
            "year": 2020
        },
        {
            "authors": [
                "Zhenlin Wang",
                "Andrew J Wagenmaker",
                "Kevin Jamieson"
            ],
            "title": "Best arm identification with safety constraints",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2022
        },
        {
            "authors": [
                "Abbasi-Yadkori"
            ],
            "title": "The statement of the lemma immediately follows. B.2. Term II First, we need a lemma from Abbasi-Yadkori et al",
            "year": 2011
        }
    ],
    "sections": [
        {
            "heading": "1. Introduction",
            "text": "As contemporary learning and control paradigms expand into domains with stringent safety requirements, the need for control mechanisms that can provide such safety guarantees has grown significantly. This has resulted in a plethora of novel safe learning problems in the literature through the lens of model predictive control Koller et al. (2018); Hewing et al. (2020); Chen et al. (2022), reinforcement learning Junges et al. (2016); Garc\u0131a and Ferna\u0301ndez (2015), optimization Usmanova et al. (2019); Fereydounian et al. (2020), bandits Sui et al. (2015), and many others. Such problems are well suited for applications in which the control algorithm interacts with humans, which introduces uncertainties that need to be considered to ensure safety (e.g., clinical trials Sui and Burdick (2017), robotic systems Berkenkamp et al. (2021), and resource allocation in societal infrastructure through pricing Hutchinson et al. (2022)).\nIn this work, we are interested in a sequential decision making problem, where the decisions must be within an arbitrary and unknown compact safety set. We consider a safe optimization framework with bandit feedback, where the reward and the constraint set are known non-linear functions of the matrix multiplication of the action with an unknown parameter. Compared to the existing literature, this problem is uniquely challenging because (1) both the decisions and the feedback from the environment are vectors, (2) the reward is an arbitrary function of the decision vector, and (3) the safety constraint on the decision vector is an arbitrary compact set. These challenges are\n\u00a9 2023 S. Hutchinson, B. Turan & M. Alizadeh.\nar X\niv :2\n30 5.\n00 88\n9v 1\n[ cs\n.L G\n] 1\nM ay\nhowever warranted, given that problems of this form appear in many real-world applications. For example, power flow constraints are nonlinear and nonconvex in general (Molzahn et al. (2017)) and often solved with (nonlinear) convex relaxations (e.g. Bai et al. (2008); Farivar and Low (2013)).\nWe handle the challenge general safety sets present by introducing a geometric property of a set, which we call sharpness, that is related to how difficult it is to perform learning within a particular safety set. This allows us to characterize the performance of our learning algorithm, measured in terms of regret, as a function of the sharpness of the safety set. Accordingly, we identify the class of safety sets (that includes all convex sets) for which we can establish a sublinear regret bound.\nRelated work: Sequential decision making under uncertainty with safety constraints has been an increasingly popular area of research among scholars. In particular, there have been various works that study optimization problems with uncertain constraint functions. Depending on the specific problem setting, the constraint function is assumed to be linear Usmanova et al. (2019); Chaudhary and Kalathil (2022); Fereydounian et al. (2020), have a Gaussian process prior Sui et al. (2015, 2018); Berkenkamp et al. (2021) or be generally Lipschitz Usmanova et al. (2020). In all of these works, the constraint is specified as requiring that the output of the (unknown) function is in the nonpositive orthant (i.e. g(x) \u2264 0), whereas we model the constraint as requiring that the output of the unknown function is in some arbitrary set (i.e. g(x) \u2208 E for some arbitrary E). This model warrants a unique analysis approach where we study how the geometry of this arbitrary constraint set impacts the performance of our algorithm.\nUncertain constraints have also been studied in the stochastic linear bandit setting. In the conventional stochastic linear bandit setting (without uncertain constraints), an agent chooses an action vector at each time step and then receives a reward that is linear in expectation with respect to the action, with the aim of maximizing her cumulative reward (see e.g. Dani et al. (2008); Abbasi-Yadkori et al. (2011)). One type of stochastic linear bandit problem with uncertain constraints is so-called conservative linear bandits Kazerouni et al. (2017); Moradipari et al. (2020), where the expected reward at each round needs to be close to a baseline reward. Others consider a setting where there is an auxiliary constraint function. Specifically, in Amani et al. (2019) the constraint function depends on the (linearly transformed) reward parameter, while in Pacchiano et al. (2021); Moradipari et al. (2021); Wang et al. (2022) the constraint function is unrelated to the reward parameter and the learner receives noisy feedback of it. Similar to stochastic linear bandits, we consider a problem where the expected response from the environment is a linear function of the action. However, we take the response from the environment to be a vector rather than a scalar, consider the reward to be an arbitrary function of the expected response, and require the expected response from the environment to be within an arbitrary set. The main novelty of this problem is the arbitrary constraint set, which necessitates new analysis techniques that might find broader applicability.\nNotation: For a vector v \u2208 Rd and positive definite matrix A \u2208 Rd\u00d7d, we denote the weighted 2-norm as \u2016v\u2016A = \u221a v>Av. The minimum and maximum eigenvalues of a square matrix M are denoted \u03bbmin(M) and \u03bbmax(M), respectively. We denote the closed and open ball with radius r and norm \u2016\u00b7\u2016 as B\u0304\u2016\u00b7\u2016(r) and B\u2016\u00b7\u2016(r), which are centered at the origin. The condition number of a matrix M is denoted as \u03ba(M). For a setD and matrixM , we use the notationMD = {Mx : x \u2208 D}. The set {1, 2, ..., n} is denoted [n]. We use O\u0303 to refer to big-O notation that ignores logarithmic factors. We use the notation ei to refer to a vector with 1 as the ith position and 0 everywhere else. For a vector norm \u2016 \u00b7 \u2016, the dual norm is denoted \u2016 \u00b7 \u2016?. The induced matrix p-norm is denoted \u2016M\u2016p for some matrix M , such that \u2016M\u2016p = sup\u2016x\u2016p=1 \u2016Ax\u2016p. The Frobenius norm is denoted \u2016M\u2016F for some matrix M ."
        },
        {
            "heading": "2. Problem Setup",
            "text": "We study a sequential decision-making problem where, in each round, an agent chooses an action and then the environment chooses a response according to the action taken. Similar to stochastic linear bandits, we assume that the response from the environment is an unknown linear function of the action and that the agent observes the output of this linear function plus some noise. However, our problem differs from stochastic linear bandits in that the response is multi-dimensional and the agent\u2019s goal is to accumulate reward, which is an arbitrary known function of the response. In our problem, the agent also needs to ensure that the response from the environment lies within a safety set every round.\nThe details of the problem are described as follows. In each round t \u2208 [T ], an agent chooses an action xt from the compact action setA \u2282 Rd and then observes the noisy response yt := \u0398\u2217xt+ t. The matrix \u0398\u2217 \u2208 Rn\u00d7d is an unknown parameter that is full rank, t \u2208 Rn is random noise, and we have that n \u2264 d. Upon choosing an action, the agent earns the reward f(\u0398\u2217xt), where the reward function f : Rn \u2192 R is known. The agent needs to ensure that when it chooses actions, the response \u0398\u2217xt lies within the known compact safety set E \u2282 Rn that has nonempty interior, or equivalently, that xt is in the unknown feasible action set X := {x \u2208 A : \u0398\u2217x \u2208 E}.\nWith the actions that it chooses, the agent aims to maximize the cumulative reward that it achieves while ensuring that the safety constraint is satisfied for all rounds. Therefore, the performance of the agent can be measured with the cumulative regret,RT := \u2211T t=1 (f(\u0398\u2217x\u2217)\u2212 f(\u0398\u2217xt)) where x\u2217 \u2208 arg maxx\u2208X f(\u0398\u2217x). In the following two assumptions, we assume that the unknown parameter and feasible actions are bounded, and that the noise is subgaussian. These assumptions are standard in related literature (e.g. Abbasi-Yadkori et al. (2011); Pacchiano et al. (2021)).\nAssumption 1 For all x in A, there exists a constant L such that \u2016x\u20162 \u2264 L. Additionally, there exists constant S such that \u2016\u03b8i\u2217\u20162 \u2264 S for all i \u2208 [n], where \u03b8i\u2217 is the ith row of \u0398\u2217. The constants S and L are known to the agent.\nAssumption 2 For all t \u2208 [T ], the noise t is element-wise conditionally R-subgaussian, such that given the history Ft = \u03c3(x1, x2, ..., xt+1, 1, 2, ..., t) and denoting the ith element of t as it, it holds for all i \u2208 [n] that E[ it|Ft\u22121] = 0 and E[e\u03bb i t |Ft\u22121] \u2264 exp(\u03bb 2R2\n2 ),\u2200\u03bb \u2208 R. The constant R is known to the agent.\nWe additionally assume that the reward function is Lipschitz.\nAssumption 3 f is M -Lipschitz on E such that |f(x)\u2212 f(y)| \u2264M\u2016x\u2212 y\u20162 for all x, y in E .\nLastly, we make an assumption which ensures that the knowledge provided to the agent by Assumption 1 is enough to choose initial actions that are safe. Since it is known that \u0398\u2217 is in C0 = {[\u03b81 \u03b82 ... \u03b8n]> \u2208 Rn\u00d7d : \u2016\u03b8i\u20162 \u2264 S, \u2200i \u2208 [n]} due to Assumption 1, then it is also known that G0 := {x \u2208 A : \u0398x \u2208 E , \u2200\u0398 \u2208 C0} is a subset of X . Therefore, we ensure that the agent can initially choose safe actions by assuming that the interior of G0 is nonempty.\nAssumption 4 The initial feasible set G0 has a nonempty interior.\nWe provide an algorithm for the stated problem in the next section.\nAlgorithm 1 Input: A, E , f, L, S // Pure Exploration\n1 for t = 1 to T \u2032 do 2 Choose xt by randomly sampling G0, and observe response yt. 3 end 4 Construct CT \u2032 and GT \u2032 with (1) and (2) respectively. // Exploration-Exploitation 5 for t = T \u2032 + 1 to T do 6 Choose some (xt, \u0398\u0303t) \u2208 arg max(x,\u0398)\u2208Gt\u22121\u00d7Ct\u22121 f(\u0398x), and observe response yt. 7 Update Ct and Gt with (1) and (2) respectively. 8 end"
        },
        {
            "heading": "3. Proposed Algorithm",
            "text": "We propose an algorithm to address the stated problem that operates by first performing pure exploration for an appropriate duration T \u2032, as specified in the analysis, and then performing explorationexploitation for the remaining rounds. The algorithm is given in Algorithm 1.\nThe pure exploration phase proceeds by randomly sampling actions from G0 such that \u03bb\u2212 := \u03bbmin ( E [ xtx > t ]) > 0 for t \u2208 [T \u2032]. Such a scheme is possible given that G0 has a nonempty interior, although we leave the specific choice of sampling scheme as a design decision.1\nEach round in the exploration-exploitation phase, t \u2208 (T \u2032, T ], consists of first identifying the set of actions which will ensure safety given the current knowledge, and then choosing the optimistic action within this safe action set. In order to both identify which actions are safe and to choose actions optimistically, we use confidence sets in which the parameter \u0398\u2217 lies with high probability. Let \u03b8i\u2217 be the ith row of \u0398\u2217, such that \u0398\u2217 = [\u03b8 1 \u2217 \u03b8 2 \u2217 ... \u03b8 n \u2217 ] >, and let yit be the ith element of yt, such that yt = [y1t y 2 t ... y n t ] >. Then the regularized least-squares estimator of each \u03b8i\u2217 is given by\n\u03b8\u0302it = [Vt] \u22121\u2211t s=1 xsy i s at round t, where the gram matrix is Vt = \u03bdI + \u2211t s=1 xs [xs]\n>. Using the regularized least-squares estimator for each row of \u0398\u2217, we define the confidence set in the following theorem from Abbasi-Yadkori et al. (2011).\nTheorem 1 (Theorem 2 in Abbasi-Yadkori et al. (2011)) Let Assumptions 1 and 2 hold. Then if xt is in A for all t, we have with probability at least 1\u2212 \u03b4 that \u0398\u2217 lies in the set\nCt = { [\u03b81 \u03b82 ... \u03b8n]> \u2208 Rn\u00d7d : \u2225\u2225\u2225\u03b8i \u2212 \u03b8\u0302it\u2225\u2225\u2225 Vt \u2264 \u221a \u03b2t,\u2200i \u2208 [n] } (1)\nfor all t \u2265 0, where \u221a \u03b2t = R \u221a d log (1 + tL2/\u03bd \u03b4/n ) + \u221a \u03bdS.\n1. We give an example of a sampling scheme with \u03bb\u2212 > 0. Since G0 has a nonempty interior, there exists v \u2208 Rd and r > 0 such that the open ball v+B2(r) is a subset of G0. It follows that the closed ball v+ B\u03042(r/2) is a subset of G0. Therefore, one possible sampling scheme is to uniformly sample ut from the unit sphere i.i.d. such that E[utu>t ] = 1 d I , and then play xt = v + r2ut. Therefore, E[xtx > t ] = E[vv>] + r2E[vu > t + utv >] + r 2 4 E[utu>t ] = vv> + r 2 4d I\ngiven that v is fixed, and it follows that \u03bb\u2212 = r 2\n4d > 0.\nUsing this set, we define a conservative inner approximation of the feasible action set (X ) as\nGt := {x \u2208 A : \u0398x \u2208 E ,\u2200\u0398 \u2208 Ct}. (2)\nNote that the sets Ct and Gt are updated at the end of each round such that the agent has access to Ct\u22121 and Gt\u22121 in round t. From the definition of Gt, we can see that for any \u0398 \u2208 Ct and x \u2208 Gt, it is guaranteed that \u0398x is in the safety set E . Theorem 1 states that \u0398\u2217 is in Ct for all rounds with high probability, so if the algorithm chooses xt from Gt\u22121, the responses from the environment {\u0398\u2217xt}\u2200t\u2208(T \u2032,T ] will all be in E with high probability, and as such, they would ensure safety.\nIn order to choose these actions from the conservative action sets {Gt\u22121}\u2200t\u2208(T \u2032,T ] such that the regret is favorable, the algorithm behaves optimistically. That is, the algorithm chooses the best action in Gt\u22121 assuming that the true parameter \u0398\u2217 is as favorable as possible given available information. Since the agent knows that \u0398\u2217 is highly likely to be in the confidence set Ct\u22121 in round t, the algorithm behaves optimistically by finding an action in Gt\u22121 and parameter in Ct\u22121 that maximize the possible reward. Accordingly, the algorithm chooses the action as\n(xt, \u0398\u0303t) \u2208 arg max (x,\u0398)\u2208Gt\u22121\u00d7Ct\u22121 f(\u0398x), (3)\nfor every round t \u2208 (T \u2032, T ]. It is important to recognize that, because Gt\u22121 is a conservative inner approximation of X , the optimal action x\u2217 may not be in Gt\u22121. Hence, how well Gt\u22121 approximates X has an impact on how far xt is from the optimal action x\u2217, and hence how large the gap is between f(\u0398\u2217x\u2217) and f(\u0398\u2217xt) (given the Lipschitz assumption on f ). The tightness with which Gt approximates X is evidently impacted by the size of Ct, but as we show in the following section, the geometric properties of the safety constraint E and the action set A play a significant role as well."
        },
        {
            "heading": "4. Regret Analysis",
            "text": "In this section, we prove an upper bound on the cumulative regret of Algorithm 1. A key aspect of the problem that impacts the regret is the geometric properties of the safety set and the action set. As of now, we have not made any assumptions on these set. However, we will show that the geometric properties of these sets will determine whether we can prove that the algorithm has sublinear regret. To aid in this analysis, we introduce a geometric property of sets that we refer to as sharpness, which plays a key role in the regret bound of the proposed algorithm."
        },
        {
            "heading": "4.1. Geometric Properties of Safety Sets",
            "text": "When the agent chooses an action, there is uncertainty as to what the response will be, necessitating the use of a conservative inner approximation of the set of safe actions. Choosing actions from this inner approximation maintains safety because it ensures that every reasonably possible response to the chosen action (i.e. every \u0398xt for \u0398 \u2208 Ct\u22121) satisfies the safety constraint. In essence, this ensures that some region around the expected response lies within the safety constraint. One can imagine that this region will not \u201cfit\u201d well in to any \u201csharp\u201d corners that the safety set may have, and hence the inner approximation will be looser for safety sets with \u201csharp\u201d corners, resulting in less favorable regret. We formalize this notion of sharpness in the following series of definitions. The proofs from this section are given in Appendix A.\nIn order to study the impact that a safety set\u2019s geometry has on the tightness of the conservative inner approximation, we first present a more general type of inner approximation that we call the shrunk version of a set. Similar to how the conservative inner approximation ensures that the set of all reasonably possible responses are within the safety constraint, the shrunk version of a set ensures that a closed ball at each point is within the original set. This is formally defined in the following definition, which uses the closed ball, B\u0304\u2016\u00b7\u2016(r) := {x \u2208 Rm : \u2016x\u2016 \u2264 r}, where r is the radius and the particular norm is \u2016 \u00b7 \u2016.\nDefinition 2 For a compact set D \u2282 Rm, a norm \u2016 \u00b7 \u2016, and a nonnegative scalar \u2206, we define the shrunk version of D as D\u2016\u00b7\u2016\u2206 := {x \u2208 D : x+ v \u2208 D,\u2200v \u2208 B\u0304\u2016\u00b7\u2016(\u2206)}.2\nGiven the above definition of the shrunk version of a set, one can consider the maximum shrinkage that a set can withstand while still being nonempty. We introduce the maximum shrinkage of a set in the following definition.\nDefinition 3 For a compact set D \u2282 Rm and a norm \u2016 \u00b7 \u2016, we define the maximum shrinkage of D, as H\u2016\u00b7\u2016D := sup{\u2206 : D \u2016\u00b7\u2016 \u2206 6= \u2205}.\nWe can now formally define the sharpness of a set as the maximum distance from any point in a set to the nearest point in the shrunk version of that set.\nDefinition 4 For a compact set D \u2282 Rm and norm \u2016 \u00b7 \u2016, we define the sharpness of D as\nSharp \u2016\u00b7\u2016 D (\u2206) := sup\nx\u2208D inf y\u2208D\u2016\u00b7\u2016\u2206 \u2016y \u2212 x\u20162 ,\nfor all non-negative \u2206 such that D\u2016\u00b7\u2016\u2206 is nonempty.3\nSharpness is applicable to the analysis of safe learning algorithms because it upper bounds how far an optimal point within the safe set (e.g. some set D) is from a conservative inner approximation of that safe set (e.g. D\u2016\u00b7\u2016\u2206 or a superset of D \u2016\u00b7\u2016 \u2206 ). To demonstrate how the geometry of a set impacts its sharpness, the sharpness of several different sets in R2 is plotted in Figure 1. One can see that sets with \u201csharper\u201d corners have greater sharpness for the same value of \u2206. Also note that we use Dp\u2206, HpD and Sharp p D(\u2206) to refer to the shrunk set, maximum shrinkage and sharpness of some set D with respect to the p-norm. We now show some simple properties related to when the shrunk version of a set is nonempty and therefore when the sharpness is defined. First, we have that the shrunk version of a compact set is nonempty for some positive shrinkage precisely when the set has a nonempty interior.\nProposition 5 For a compact set D \u2282 Rm, there exists a \u2206 > 0 such that D\u2016\u00b7\u2016\u2206 is nonempty if and only if D has a nonempty interior.\n2. We can equivalently define D\u2016\u00b7\u2016\u2206 using Minkowski subtraction. The Minkowski subtraction of sets A,B \u2286 R m is\ndefined as A B := {a \u2212 b : a \u2208 A, b \u2208 B}, or equivalently, A B = {x \u2208 Rm : x + B \u2286 A} (Schneider (2014)). Therefore, we can write that D\u2016\u00b7\u2016\u2206 = D B\u2016\u00b7\u2016(\u2206) for \u2206 \u2265 0. 3. Sharpness can also be define with the Hausdorff metric between sets (see Schneider (2014) Sec. 1.8) such that Sharp\n\u2016\u00b7\u2016 D (\u2206) = dH(D,D \u2016\u00b7\u2016 \u2206 ).\nNext, we show that the shrunk version of a compact set with nonempty interior is nonempty for all shrinkage less than or equal to the maximum shrinkage of the set. This indicates that sharpness is defined on the closed interval from zero to the maximum shrinkage.\nProposition 6 For a compact set D \u2282 Rm with nonempty interior, we have that D\u2016\u00b7\u2016\u2206 is nonempty for all \u2206 \u2208 [0, H\u2016\u00b7\u2016D ].\nFor the remainder of this section, we will study the sharpness of different types of compact sets with nonempty interiors. The first type of set that we study is the polytope, which is the convex hull of a finite set of points, or equivalently, the bounded intersection of a finite number of closed half-spaces. Polytopes capture a wide variety of constraints in the real world and are frequently used for safety sets in safe learning (e.g., Chaudhary and Kalathil (2022); Fereydounian et al. (2020); Usmanova et al. (2019)). We use the polyhedron representation of a polytope, D = {x \u2208 Rm : Ax \u2264 b} with A \u2208 Rp\u00d7m and b \u2208 Rp, where there are no redundant constraints. We define aj \u2208 Rm as the jth row of A such that A = [a1 a2 ... ap]\n> and bj \u2208 R as the jth element of b such that b = [b1 b2 ... bp]>. We also use IA to refer to the collection of all sets of m indices such that for each {i1, i2, ..., im} \u2208 IA the vectors\nai1 , ai2 , ..., aim are linearly independent. For each ` \u2208 IA where ` = {i1, i2, ..., im}, we write A` = [ai1 ai2 ... aim ]\n> and denote its condition number by \u03ba(A`). Using this notation, the following proposition shows that the sharpness of a polytope is bounded by a function that is linear in shrinkage.\nProposition 7 For a polytope D = {x \u2208 Rm : Ax \u2264 b} with nonempty interior, we have that Sharp\n\u2016\u00b7\u2016 D (\u2206) \u2264 \u221a mC\u2016\u00b7\u2016KD\u2206, where KD := max`\u2208IA \u03ba(A `) and C\u2016\u00b7\u2016 := max\u2016y\u2016=1 \u2016y\u20162.\nThe sharpness bound in Proposition 7 is proportional to the constant KD, which is the maximum condition number of all sets of m linearly independent constraints. Since there are m linearly independent constraints that are active at each vertex, KD upper bounds the condition number of the active constraints at each vertex. This is an intuitive measure of the sharpness of a polytope, given that the condition number of the constraints indicate how close to parallel they are. Also, note that the term C\u2016\u00b7\u2016 in Proposition 7 may depend on the dimension. For example, when the infinity-norm is used, C\u2016\u00b7\u2016\u221e = \u221a m, and when the 1-norm is used, C\u2016\u00b7\u20161 = 1.\nUsing the sharpness bound that we developed for polytopes, we can study more general sets. The key intuition that we use to study more general sets is that we can define subsets of the original set which, with appropriate construction, bound the original set in terms of sharpness. In particular, we construct polytopic subsets of the original set in order to provide sharpness bounds that are linear with respect to shrinkage. Being able establish linear bounds on the sharpness is important because it allows us to establish sublinear regret bounds on the proposed algorithm, which we discuss in\nthe next section. In order to develop a bound that uses polytopic subsets, we define the families of polytopes that can be used to bound the sharpness of a given set.\nDefinition 8 For a point x in the compact set D \u2282 Rm, we define FD(x) as the family of polytopes with nonempty interior that contain x and are subsets of D. From this, we define the class of sets for which we can use polytopic subsets to bound the sharpness.\nDefinition 9 A compact set D \u2282 Rm is referred to as polytope-sharp if FD(x) is nonempty for all x \u2208 D. We can see that the class of polytope-sharp sets are those for which a collection of polytopes can be constructed to contain each point in the set while still being subsets of the original set. Examples of sets that meet this criterion and sets that do not meet this criterion are illustrated in Figure 2. With this definition, we can then present the following proposition, which provides a linear sharpness bound on sets that are polytope-sharp.\nProposition 10 Let D \u2282 Rm be a compact set that is polytope-sharp, and choose some arbitrary Fx \u2208 FD(x) for each x \u2208 D. Then, we have that\nSharp \u2016\u00b7\u2016 D (\u2206) \u2264 \u221a mC\u0304\u2016\u00b7\u2016\u0393D\u2206,\nwhere, C\u0304\u2016\u00b7\u2016 = max(C\u2016\u00b7\u2016, 1) and\n\u0393D := max { K\u0304F , rD\nH\u0304 \u2016\u00b7\u2016 F\n} ,\nwith K\u0304F := maxx\u2208DKFx , H\u0304 \u2016\u00b7\u2016 F := minx\u2208DH \u2016\u00b7\u2016 Fx and rD := maxx,y\u2208D \u2016x\u2212 y\u20162.\nIn addition to providing a linear sharpness bound on polytope-sharp sets, Proposition 10 also indicates that, when the polytopes are small, i.e. H\u0304\u2016\u00b7\u2016F is small, or the polytopes are sharp, i.e. K\u0304F is large, then the sharpness bound is larger and therefore less favorable. From Proposition 10, we can also immediately show that every compact, convex set with nonempty interior is linearly sharp.\nCorollary 11 If a compact setD \u2282 Rm with nonempty interior is convex, then it is polytope-sharp and it holds that Sharp\u2016\u00b7\u2016D (\u2206) \u2264 \u221a mC\u0304\u2016\u00b7\u2016\u0393D\u2206.\nIt is important to note that although all compact convex sets are polytope-sharp, there are also nonconvex sets that are polytope-sharp."
        },
        {
            "heading": "4.2. Regret Bound",
            "text": "We will now use the work in the previous section to establish a sublinear bound on the cumulative regret of Algorithm 1. In order to do so, we define the set of feasible responses as Y := \u0398\u2217A \u2229 E , where we use the notation \u0398\u2217A = {\u0398\u2217x : x \u2208 A}. The set Y reflects the set of responses that are possible given the action set A and the safety set E . The sharpness of Y is used in the regret bound for Algorithm 1, as shown in Theorem 12. Although one might expect that the sharpness of E would be in the regret bound (instead of the sharpness of Y), the set A can impact the distance from the optimal action x\u2217 to the set Gt\u22121 and hence it is insufficient to solely use the sharpness of E in the regret analysis. Therefore, we use the sharpness of Y to capture both the sharpness of E and any unfavorable effects due to the specific A in a particular problem setting.\nTheorem 12 Let Assumptions 1\u20134 hold. With probability at least 1 \u2212 2\u03b4, we have that the regret of Algorithm 1 is bounded as\nRT \u2264 2M \u221a nLST \u2032 +M(T \u2212 T \u2032)Sharp\u221eY\n( 2 \u221a\n2\u03b2TL\u221a 2\u03bd + \u03bb\u2212T \u2032\n)\n+M max(H\u221eY , 1) \u221a n8\u03b2T (T \u2212 T \u2032)d log ( 1 + TL2\nd\u03bd\n) .\nfor any T \u2032 \u2265 max(t\u03b4, th) where t\u03b4 := 8L 2 \u03bb\u2212 log(d\u03b4 ) and th := 8\u03b2TL 2 \u03bb\u2212(H\u221eY ) 2 \u2212 2\u03bd\u03bb\u2212 .\nCorollary 13 Assume the same as Theorem 12. If Y is polytope-sharp, then the regret of Algorithm 1 satisfies\nRT \u2264 2M \u221a nLST \u2032 +\n2n \u221a\n2\u03b2T\u0393YLM(T \u2212 T \u2032)\u221a 2\u03bd + \u03bb\u2212T \u2032\n+M max(H\u221eY , 1) \u221a n8\u03b2T (T \u2212 T \u2032)d log ( 1 + TL2\nd\u03bd ) with probability at least 1\u22122\u03b4 when T \u2032 \u2265 max(t\u03b4, th). In particular, choosing T \u2032 = max(T 2/3, t\u03b4, th) ensures that RT = O\u0303 ( T 2/3 ) .\nWe can see that the regret bound depends on the sharpness of Y , and as shown in Corollary 13, is O\u0303 ( T 2/3 ) when Y is polytope-sharp. Note that the agent needs to know the maximum shrinkage of Y , or a lower bound of it, in order to appropriately choose T \u2032. If there is a known subset of Y or it is known that E is a subset of \u0398\u2217A then the agent can calculate a lower bound on the maximum shrinkage of Y . Otherwise, there might be application specific information that provides a conservative estimate of the maximum shrinkage of Y .\nThe complete proof of Theorem 12 is given in Appendix B. This proof utilizes a decomposition of the instantaneous regret given by\nrt := f(\u0398\u2217x\u2217)\u2212 f(\u0398\u2217xt) = f(\u0398\u2217x\u2217)\u2212 f(\u0398\u0303txt)\ufe38 \ufe37\ufe37 \ufe38 Term I + f(\u0398\u0303txt)\u2212 f(\u0398\u2217xt)\ufe38 \ufe37\ufe37 \ufe38 Term II . (4)\nTerm I captures the suboptimality of the optimistic pair (xt, \u0398\u0303t) from (3), while Term II captures the shrinkage of the confidence set Ct. The pair (xt, \u0398\u0303t) may be suboptimal due to the fact that Gt is a strict subset of X , which is necessary to ensure safety. Although the analysis of Term II can be handled with conventional bandit analysis, the analysis of Term I requires novel techniques, including sharpness, as we discuss in the following paragraph.\nThe bound on Term I is given in the following lemma.\nLemma 14 Let Assumptions 1\u20134 hold. For t \u2208 (T \u2032, T ], Term I is bounded as\nTerm I := f(\u0398\u2217x\u2217)\u2212 f(\u0398\u0303txt) \u2264MSharp\u221eY\n( 2 \u221a\n2\u03b2TL\u221a 2\u03bd + \u03bb\u2212T \u2032 ) when T \u2032 \u2265 max(t\u03b4, th) with probability at least 1\u2212 2\u03b4. The proof of Lemma 14 is given in Appendix B.1 and considers a shrunk version of Y such that every possible y in the shrunk version of Y can be given by \u0398x with some \u0398 \u2208 Ct and some x \u2208 Gt. This implies that f(\u0398\u0303xt) is greater than or equal to f(y) for every y in the shrunk version of Y and hence we can bound Term I with the difference between the optimal reward (f(y\u2217), where y\u2217 = \u0398\u2217x\u2217) and the reward from some y in the shrunk version of Y . With the Lipschitz assumption on f , this can be bounded with the difference between y\u2217 and some y in the shrunk version Y . By choosing y to be the point in the shrunk version of Y that is closest to y\u2217, we can ultimately bound the regret with the sharpness of Y as given in Lemma 14.\n5. Numerical Experiments\nWe simulated the results of the algorithm with three different polytopic safety sets of different sharpness in a problem setting where n = 3 and d = 3. The cumulative sum of the instantaneous regret in the exploration-exploitation phase of the algorithm is shown in Figure 3 for each polytopic safety set. The solid line is an average of six trials and the shaded region indicates the 95% confidence interval over the trials. For each safety set, the plot shows its K constant, as defined in Proposition 7. Each simulation has a different realization of the noise { t}t\u2208[T ]. Otherwise, the problem and algorithm parameters are the same for every sim-\nulation, and all the polytopic safety sets have the same maximum shrinkage. Also, note that the action set A is chosen to be non-restrictive, such that Y = E . Figure 3 provides some empirical support for the sublinear regret bound in Theorem 12 and also indicates that the sharpness of the safe set impacts the regret of the algorithm. The details of the simulation are given in Appendix C."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by NSF grant #1847096."
        },
        {
            "heading": "Appendix A. Proofs from Section 4.1",
            "text": ""
        },
        {
            "heading": "A.1. Proof of Proposition 5",
            "text": "Proof First we show the \u201cif\u201d direction. By definition, D has a nonempty interior if and only if there exists a point x \u2208 D such that x+B2( ) \u2286 D for some > 0 where B2( ) = {x \u2208 Rm : \u2016x\u20162 < } is the open ball of radius . Since D is closed, this is equivalent to the condition x + B\u03042( ) \u2286 D, where B\u03042( ) = {x \u2208 Rm : \u2016x\u20162 \u2264 }. Norms on finite-dimensional vector spaces are equivalent, so for some norm \u2016\u00b7\u2016, there exists positive constant C such that for all y \u2208 B\u2016\u00b7\u2016(\u0303), C\u2016y\u20162 \u2264 \u2016y\u2016 \u2264 \u0303. We can choose \u0303 = C such that B\u2016\u00b7\u2016(\u0303) \u2286 B2( ), ensuring that x + B\u2016\u00b7\u2016(\u0303) \u2286 D. Therefore, we know that x+ v \u2208 D,\u2200v \u2208 B\u2016\u00b7\u2016(\u2206) for \u2206 = \u0303 > 0 and hence that D\u2016\u00b7\u2016\u2206 is nonempty.\nNext, we show the \u201conly if\u201d direction. There exists a \u2206 > 0 such that D\u2016\u00b7\u2016\u2206 is nonempty, if and only if there exists a point x \u2208 D\u2016\u00b7\u2016\u2206 . The point x must satisfy x+ v \u2208 D,\u2200v \u2208 B\u0304\u2016\u00b7\u2016(\u2206). It follows that x + B\u0304\u2016\u00b7\u2016(\u2206) \u2286 D. From the equivalence of norms discussed previously, it follows that there is some > 0 such that B\u03042( ) \u2286 B\u0304\u2016\u00b7\u2016(\u2206) and therefore that x + B\u03042( ) \u2286 D. This implies that x+ B2( ) \u2286 D because B2( ) \u2282 B\u03042( ). Therefore, D has a nonempty interior."
        },
        {
            "heading": "A.2. Proof of Proposition 6",
            "text": "Proof Let E := {\u2206 \u2265 0 : D\u2016\u00b7\u2016\u2206 6= \u2205} and note that H \u2016\u00b7\u2016 D = supE by definition. First, we show that supE does in fact exist by showing that E is nonempty and is bounded above. We know that E is nonempty because D has a nonempty interior and Proposition 5 tells us that for such sets, there exists a \u2206 > 0 such that D\u2016\u00b7\u2016\u2206 is nonempty and therefore E is nonempty. Also, note that E is bounded above because D is bounded (i.e. there exists finite r such that \u2016x \u2212 y\u20162 \u2264 r for all x, y \u2208 D). To see this, first note that for any \u2206 \u2208 E (i.e \u2206 such that D\u2016\u00b7\u2016\u2206 6= \u2205) there exists x \u2208 D such that x+ v \u2286 D for all v \u2208 B\u0304\u2016\u00b7\u2016(\u2206) and due to equivalence of norms, it holds that x+ v\u0303 \u2286 D for all v\u0303 \u2208 B\u03042(C\u2206) for some finite C > 0. Choosing v\u0303 = e1C\u2206, we have that x and x + e1C\u2206 are in D and hence \u2016x \u2212 (x + e1C\u2206)\u20162 = C\u2206 \u2264 r. Therefore, E is bounded above. Since E is nonempty and bounded above, supE exists.\nNext, we show that H := H\u2016\u00b7\u2016D = supE is in E. Due to the properties of the supremum, there necessarily exists a \u2206\u0303 \u2208 E such that \u2206\u0303 > H \u2212 for every > 0. Therefore, for every \u2208 (0, H] it holds that B\u0304\u2016\u00b7\u2016(\u2206\u0303 ) \u2283 B\u0304\u2016\u00b7\u2016(H \u2212 ) and there is some x such that x + B\u0304\u2016\u00b7\u2016(\u2206\u0303 ) \u2286 D. It follows that x+ B\u0304\u2016\u00b7\u2016(H \u2212 ) \u2282 D for every \u2208 (0, H]. We claim that this implies that x+ B\u2016\u00b7\u2016(H) \u2282 D. Suppose the contrary, i.e. x+B\u2016\u00b7\u2016(H) 6\u2282 D. This would imply that there exists y such that \u2016y\u2016 < H and x+ y 6\u2208 D. Since x+ y 6\u2208 D and x+ B\u0304\u2016\u00b7\u2016(H \u2212 ) \u2282 D for every \u2208 (0, H], it follows that y cannot be in B\u0304\u2016\u00b7\u2016(H\u2212 ) and therefore \u2016y\u2016 6\u2264 H\u2212 or equivalently, \u2016y\u2016 > H\u2212 . Therefore, it must be that H \u2212 < \u2016y\u2016 < H for every \u2208 (0, H]. Rearranging, it must be that > H \u2212 \u2016y\u2016 > 0 for every \u2208 (0, H], so we can choose = H \u2212\u2016y\u2016 > 0 to break the previous statement. Therefore, it holds that x+B\u2016\u00b7\u2016(H) \u2282 D. SinceD is closed, it is also the superset of x+ B\u0304\u2016\u00b7\u2016(H) and therefore, H is in E.\nLastly, we show that all \u2206 \u2208 [0, H] are in E. Since there exists x \u2208 D such that x+ B\u0304\u2016\u00b7\u2016(H) \u2286 D and B\u0304\u2016\u00b7\u2016(\u2206) \u2286 B\u0304\u2016\u00b7\u2016(H) for all \u2206 \u2208 [0, H], it also holds that x+ B\u0304\u2016\u00b7\u2016(\u2206) \u2286 D."
        },
        {
            "heading": "A.3. Proof of Proposition 7",
            "text": "Proof First we show that D\u2016\u00b7\u2016\u2206 is a polytope within D. To do so, we define the halfspace due to the jth constraint as Dj = {x \u2208 Rm : a>j x \u2264 bj} such that D = \u22c2 j\u2208[p]Dj . With some slight abuse of notation, let\nD\u2016\u00b7\u2016j,\u2206 := {x \u2208 Rm : a>j (x+ v) \u2264 bj ,\u2200v \u2208 B\u0304\u2016\u00b7\u2016(\u2206)} = {x \u2208 Rm : max\nv\u2208B\u0304\u2016\u00b7\u2016(\u2206) a>j (x+ v) \u2264 bj}\n= {x \u2208 Rm : a>j x+ \u2206\u2016aj\u2016? \u2264 bj} = {x \u2208 Rm : a>j x \u2264 bj \u2212\u2206\u2016aj\u2016?},\nwhere \u2016 \u00b7 \u2016? is the dual norm of \u2016 \u00b7 \u2016. Therefore, D\u2016\u00b7\u2016\u2206 = \u22c2 j\u2208[p]D \u2016\u00b7\u2016 j,\u2206 is a polytope such that each of its constituent constraints are parallel to a corresponding constraint of D, i.e. D\u2016\u00b7\u2016j,\u2206 is parallel to Dj for all j \u2208 [p]. However, it is important to note that some of the constraints D\u2016\u00b7\u2016j,\u2206 may be redundant. Let E be the set of such constraints that are not redundant, i.e. the smallest set E \u2286 [p] such that D\u2016\u00b7\u2016\u2206 = \u22c2 j\u2208E D \u2016\u00b7\u2016 j,\u2206. In order to study the sharpness of D, we will use the polytope D\u0303 := \u22c2 j\u2208E Dj . The polytope D\u0303 is useful because for each non-redundant constraint of D\u0303, there is a parallel nonredundant constraint of D\u2016\u00b7\u2016\u2206 . We also know that D \u2286 D\u0303 since\nD = \u22c2 j\u2208[p] Dj = \u22c2 j\u2208E Dj  \u2229  \u22c2 j\u2208[p]\\E Dj  \u2286 \u22c2 j\u2208E Dj = D\u0303.\nTherefore, it holds that\nSharp \u2016\u00b7\u2016 D (\u2206) = maxx\u2208D\nmin y\u2208D\u2016\u00b7\u2016\u2206 \u2016x\u2212 y\u20162 \u2264 max x\u2208D\u0303 min y\u2208D\u2016\u00b7\u2016\u2206 \u2016x\u2212 y\u20162.\nHence, we study a point in D\u0303 that has the greatest projection distance, i.e.\nu \u2208 arg max x\u2208D\u0303 min y\u2208D\u2016\u00b7\u2016\u2206 \u2016y \u2212 x\u20162\ufe38 \ufe37\ufe37 \ufe38 g(x) .\nSince \u2016y \u2212 x\u20162 is convex in (x, y), we know that g(x) is convex (Boyd et al. (2004) Sec. 3.2.5). The maximizer of a convex function over a polytope is at a vertex,4 and hence u is at some vertex of D\u0303.\nNow, we bound the distance between u, and the vertex in D\u2016\u00b7\u2016\u2206 with the same active constraints as u. To do so, we first recall the notation from the main text and introduce some new notation. The notation IA refers to a collection of sets of length m such that for each ` = {i1, i2, ..., im} \u2208 IA the vectors ai1 , ai2 , ..., aim are linearly independent. We also use the notation A ` = [ai1 ai2 ... aim ] >\n4. Each point in a polytope can be described as x = \u2211 i\u2208[n] \u03bbivi where vi are the vertices and \u03bbi \u2265 0 with \u2211 i\u2208[n] \u03bbi =\n1. By Jensen\u2019s inequality, it follows that f(x) = f( \u2211 i\u2208[n] \u03bbivi) \u2264 \u2211\ni=[n] \u03bbif(vi) \u2264 maxi\u2208[n] f(vi). Since all vi are in the polytope, the set of maxima must include at least one of them.\nand b` = [bi1 bi2 ... bim ] >. Note that, for each vertex of a polytope without redundant constraints, there are m linearly independent constraints that are active at that vertex, and they form an element of IA. Accordingly, for a vertex v, we use the notation Av = [ai1 ai2 ... aim ]> and bv = [bi1 bi2 ... bim ]\n> where `v = {i1, i2, ..., im} is the set of m linearly independent active constraints at that vertex. We now proceed to bound the distance between u and the vertex v \u2208 D\u2016\u00b7\u2016\u2206 with the same active constraints as u. Since the same constraints are tight at both u and v, we have that Avu = bv and Avv = bv \u2212\u2206\u03b1v, where \u03b1v := [\u2016ai1\u2016? ... \u2016aim\u2016?]>. Therefore, we have that u = (Av)\u22121bv and v = (Av)\u22121 (bv \u2212\u2206\u03b1v). It follows that\n\u2016u\u2212 v\u20162 = \u2016(Av)\u22121bv \u2212 (Av)\u22121 (bv \u2212\u2206\u03b1v) \u20162 = \u2206\u2016(Av)\u22121\u03b1v\u20162 \u2264 \u2206\u2016(Av)\u22121\u20162\u2016\u03b1v\u20162\n= \u2206\n\u221a\u2211 i\u2208`v \u2016ai\u20162?\n\u03c3min(Av)\nNow, consider the numerator of the above:\u221a\u2211 i\u2208`v \u2016ai\u20162? \u2264 C\u2016\u00b7\u2016 \u221a\u2211 i\u2208`v \u2016ai\u201622 = C\u2016\u00b7\u2016\u2016Av\u2016F \u2264 \u221a mC\u2016\u00b7\u2016\u2016Av\u20162 = \u221a mC\u2016\u00b7\u2016\u03c3max(A v)\nwhere C\u2016\u00b7\u2016 = max\u2016x\u20162=1 \u2016x\u2016? such that \u2016x\u2016? \u2264 C\u2016\u00b7\u2016\u2016x\u20162 for all x \u2208 Rm. Therefore, we have that\n\u2016u\u2212 v\u20162 \u2264 \u2206\n\u221a\u2211 i\u2208`v \u2016ai\u20162?\n\u03c3min(Av) \u2264 \u221amC\u2016\u00b7\u2016 \u03c3max(A v) \u03c3min(Av) \u2206 = \u221a mC\u2016\u00b7\u2016\u03ba(A v)\u2206,\nwhere \u03ba(Av) is the condition number of Av. Since v is in D\u2016\u00b7\u2016\u2206 , we have that\nSharp \u2016\u00b7\u2016 D (\u2206) \u2264 min y\u2208D\u2016\u00b7\u2016\u2206 \u2016y \u2212 u\u20162 \u2264 \u2016v \u2212 u\u20162 \u2264\n\u221a mC\u2016\u00b7\u2016K\u2206\nwhere K = max`\u2208IA \u03ba(A `). We further characterize C\u2016\u00b7\u2016 as\nC\u2016\u00b7\u2016 = max \u2016x\u20162=1 \u2016x\u2016? = max \u2016x\u20162=1 max \u2016y\u2016=1 y>x = max \u2016y\u2016=1 max \u2016x\u20162=1 y>x = max \u2016y\u2016=1 \u2016y\u20162.\nNote that \u2016x\u20162 \u2264 C\u2016\u00b7\u2016\u2016x\u2016 for all x \u2208 Rm."
        },
        {
            "heading": "A.4. Proof of Proposition 10",
            "text": "First, we have a lemma that we will need for the proof.\nLemma 15 For compact sets A,D \u2282 Rm that have nonempty interior and satisfyA \u2286 D, it holds that min\ny\u2208D\u2016\u00b7\u2016\u2206 \u2016y \u2212 x\u20162 \u2264 miny\u2208A\u2016\u00b7\u2016\u2206 \u2016y \u2212 x\u20162 for all x \u2208 D.\nProof First, we show that A\u2016\u00b7\u2016\u2206 \u2286 D \u2016\u00b7\u2016 \u2206 . For any a \u2208 A\u2206, it holds that a + B\u0304\u2016\u00b7\u2016(\u2206) \u2286 A. Since A \u2286 D, it follows that a + B\u0304\u2016\u00b7\u2016(\u2206) \u2286 D and hence a \u2208 D\u2016\u00b7\u2016\u2206 . Therefore, A \u2016\u00b7\u2016 \u2206 \u2286 D \u2016\u00b7\u2016 \u2206 and hence min y\u2208D\u2016\u00b7\u2016\u2206 \u2016y \u2212 x\u20162 \u2264 miny\u2208A\u2016\u00b7\u2016\u2206 \u2016y \u2212 x\u20162 for all x \u2208 D.\nThen, we have the proof of Proposition 10. Proof In order to bound the sharpness, we choose some arbitrary Fx \u2208 FD(x) for each x \u2208 D and use Lemma 15 as\nSharp \u2016\u00b7\u2016 D (\u2206) = maxx\u2208D\nmin y\u2208D\u2016\u00b7\u2016\u2206\n\u2016y \u2212 x\u20162\n\u2264 max x\u2208D min y\u2208F\u2016\u00b7\u2016x,\u2206 \u2016y \u2212 x\u20162 \u2264 max x\u2208D max z\u2208Fx\nmin y\u2208F\u2016\u00b7\u2016x,\u2206\n\u2016y \u2212 z\u20162\n= max x\u2208D\nSharp \u2016\u00b7\u2016 Fx(\u2206)\n\u2264 \u2206\u221amC\u2016\u00b7\u2016max x\u2208D KFx\nwhich is valid for \u2206 \u2208 [0, H\u0304\u2016\u00b7\u2016F ], where H\u0304 \u2016\u00b7\u2016 F := minx\u2208DH \u2016\u00b7\u2016 Fx > 0 given that every Fx has nonempty interior by definition and Proposition 5. We use the notation K\u0304F = maxx\u2208DKFx . We can then use the boundedness of D to establish a linear bound for the remainder of the domain of the sharpness, i.e. for \u2206 \u2208 (H\u0304\u2016\u00b7\u2016F , H \u2016\u00b7\u2016 D ]. From the boundedness of D, we have that the diameter rD = supx,y\u2208D \u2016x \u2212 y\u20162 is finite and hence we have the trivial sharpness bound Sharp\n\u2016\u00b7\u2016 D (\u2206) \u2264 rD. This gives the linear bound Sharp \u2016\u00b7\u2016 D (\u2206) \u2264 rDH\u0304\u2016\u00b7\u2016F \u2206 for all \u2206 \u2208 (H\u0304\u2016\u00b7\u2016F , H \u2016\u00b7\u2016 D ].\nTherefore, we have that\nSharp \u2016\u00b7\u2016 D (\u2206) \u2264 max { \u221a mC\u2016\u00b7\u2016K\u0304F , rD\nH\u0304 \u2016\u00b7\u2016 F\n} \u2206 \u2264 \u221amC\u0304\u2016\u00b7\u2016max { K\u0304F , rD\nH\u0304 \u2016\u00b7\u2016 F\n} \u2206,\nwhere C\u0304\u2016\u00b7\u2016 = max(C\u2016\u00b7\u2016, 1)."
        },
        {
            "heading": "A.5. Proof of Corollary 11",
            "text": "Proof Given Proposition 10, it is sufficient to show that a polytope with nonempty interior can be constructed to contain each point in D while being a subset of D. Since D has a nonempty interior, we can construct a polytope A with nonempty interior in D (e.g. a hypercube). Then, from the convexity of D, we can see that the polytope A\u0304 = conv(A, x) contains x and lies in D for each x \u2208 D. Therefore, a convex set D is polytope-sharp and the result in Proposition 10 applies."
        },
        {
            "heading": "A.6. Additional Properties",
            "text": "Proposition 16 For compact sets A,D \u2282 Rm with nonempty interiors, where A \u2286 D, we have that H\u2016\u00b7\u2016A \u2264 H \u2016\u00b7\u2016 D .\nProof Consider any \u2206 \u2208 [0, H\u2016\u00b7\u2016A ]. From Prop. 6 and the definition of a shrunk set, there exists x \u2208 A\u2016\u00b7\u2016\u2206 such that x+B\u2016\u00b7\u2016(\u2206) \u2286 A. SinceA \u2286 D, we have that x+B\u2016\u00b7\u2016(\u2206) \u2286 D and henceD \u2016\u00b7\u2016 \u2206 is nonempty and \u2206 \u2264 H\u2016\u00b7\u2016D . Since this applies for all \u2206 \u2208 [0, H \u2016\u00b7\u2016 A ], it follows that H \u2016\u00b7\u2016 A \u2264 H \u2016\u00b7\u2016 D ."
        },
        {
            "heading": "Appendix B. Proof of Theorem 12",
            "text": "We use the decomposition of the instantaneous regret specified in (4). Accordingly, we discuss Term I in Section B.1, Term II in Section B.2 and the complete regret bound in Section B.3."
        },
        {
            "heading": "B.1. Term I (Proof of Lemma 14)",
            "text": "Before getting to the proof of Lemma 14, we need a lemma from Amani et al. (2019).\nLemma 17 (Lemma 1 in Amani et al. (2019)) We have with probability at least 1\u2212 \u03b4 that\n\u03bbmin(VT \u2032) \u2265 \u03bd + \u03bb\u2212T\n\u2032\n2 , (5)\nfor T \u2032 \u2265 t\u03b4 := 8L 2 \u03bb\u2212 log(d\u03b4 ).\nWe also need to show that the sharpness of Y is well defined, for which we need the following lemma.\nLemma 18 For a set D \u2282 Rd with nonempty interior and full rank matrix N \u2208 Rn\u00d7d with n \u2264 d, the setH = ND has a nonempty interior.\nProof Consider a point x0 in the interior of D. By definition, there exists an open ball of radius > 0 that is centered at x0 and lies within D. We can choose n + 1 points within that ball, x0, x1, ..., xn, which defines the polytope conv(x0, x1, ..., xn) \u2282 D. The image of these points under N is defined as vi = Nxi for all i \u2208 {0, 1, ..., n}, such that conv(v0, v1, ..., vn) \u2282 H. If the vectors v0\u2212v1, v0\u2212v2, ..., v0\u2212vn can be chosen to be linearly independent, then conv(v0, v1, ..., vn) has nonempty interior and henceH has nonempty interior. To see that this is possible, first note for all i \u2208 {1, 2, ..., n} we can choose xi such that x0 \u2212 xi = 2wi for any unit vector wi of dimension d. It follows that zi = v0 \u2212 vi = N(x0 \u2212 xi) = 2Nwi for all i \u2208 {1, 2, ..., n}. Since the rank of N is n, the dimension of the image space of N is n and hence there exists a w1, w2, ..., wn such that z1, z2, ..., zn are linearly independent (i.e. a basis for the image space).\nFrom Assumption 4, we also have that G0 has nonempty interior which implies thatX has nonempty interior as X \u2283 G0. Since we can write Y = \u0398\u2217X and X has nonempty interior, then by Lemma 18, we know that Y has nonempty interior. We also know that Y is compact because A and E are compact and a finite dimensional linear operator preserves compactness. Since Y is compact and has nonempty interior, the sharpness of Y is well defined.\nWe can then give the proof of Lemma 14. Proof Without further reference to it, we take \u0398\u2217 to be in Ct for all t \u2208 [T ], which holds with probability at least 1 \u2212 \u03b4 by Theorem 1. Similarly, we take \u03bbmin(VT \u2032) \u2265 \u03bd + \u03bb\u2212T \u2032 2 , which holds\nwith probability at least 1 \u2212 \u03b4 given Lemma 17 and that T \u2032 \u2265 t\u03b4. By the union bound, both \u0398\u2217 \u2208 Ct, \u2200t \u2208 [T ] and \u03bbmin(VT \u2032) \u2265 \u03bd + \u03bb\u2212T \u2032\n2 jointly hold with probability at least 1\u2212 2\u03b4. First, we define an expanded version of the confidence set for the unknown parameter,\nC\u0303t := { [\u03b81 \u03b82 ... \u03b8n]> \u2208 Rn\u00d7d : \u2225\u2225\u03b8i \u2212 \u03b8i\u2217\u2225\u2225Vt \u2264 2\u221a\u03b2t, \u2200i \u2208 [n]} \u2287 Ct.\nThis holds because for all \u0398 in Ct, we have for all i \u2208 [n] that\u2225\u2225\u03b8i \u2212 \u03b8i\u2217\u2225\u2225Vt = \u2225\u2225\u2225\u03b8i \u2212 \u03b8\u0302it + \u03b8\u0302it \u2212 \u03b8i\u2217\u2225\u2225\u2225Vt \u2264 \u2225\u2225\u2225\u03b8i \u2212 \u03b8\u0302it\u2225\u2225\u2225 Vt + \u2225\u2225\u2225\u03b8\u0302it \u2212 \u03b8i\u2217\u2225\u2225\u2225 Vt \u2264 2 \u221a \u03b2t.\nWe use this to the define a shrunk safe action set:\nG\u0303t := {x \u2208 A : \u0398x \u2208 E , \u2200\u0398 \u2208 C\u0303t} \u2286 Gt (6)\nWe then use Lemma 17 to define a further shrunk safe price set, such that for t \u2265 T \u2032, we have that\nG\u0304 = {x \u2208 A : \u0398\u2217x+ v \u2208 E ,\u2200v \u2208 B\u0304\u221e(`)} \u2286 G\u0303t, (7)\nwhere ` := 2 \u221a\n2\u03b2TL\u221a 2\u03bd+\u03bb\u2212T \u2032 . To see that (7) holds, note that for any x and \u0398 \u2208 C\u0303t we have for all i \u2208 [n] that\nx>\u03b8i \u2208 [ x>\u03b8i\u2217 \u2212 2 \u221a \u03b2t\u2016x\u2016V \u22121t , x >\u03b8i\u2217 + 2 \u221a \u03b2t\u2016x\u2016V \u22121t ] \u2286 [ x>\u03b8i\u2217 \u2212 2 \u221a \u03b2TL\u221a\n\u03bbmin(Vt) , x>\u03b8i\u2217 +\n2 \u221a \u03b2TL\u221a\n\u03bbmin(Vt)\n]\n\u2286 [ x>\u03b8i\u2217 \u2212 2 \u221a\n2\u03b2TL\u221a 2\u03bd + \u03bb\u2212T \u2032 , x>\u03b8i\u2217 + 2 \u221a 2\u03b2TL\u221a 2\u03bd + \u03bb\u2212T \u2032 ] = [ x>\u03b8i\u2217 \u2212 `, x>\u03b8i\u2217 + ` ] .\nTherefore any x such that \u0398\u2217x+ v is in E for all v \u2208 B\u0304\u221e(`) will also ensures that \u0398x is in E for all \u0398 \u2208 C\u0303t and hence G\u0304 \u2286 G\u0303t. Then we have,\nY\u0304 := {\u0398\u2217x : x \u2208 G\u0304} = {\u0398\u2217x : x \u2208 A} \u2229 {y : y + v \u2208 E , \u2200v \u2208 B\u0304\u221e(`)} = {\u0398\u2217x : x \u2208 A} \u2229 E\u221e` \u2287 Y\u221e` ,\nwhere Y := {\u0398\u2217x : x \u2208 A} \u2229 E . We will also need the definition Y\u0303t := {\u0398x : x \u2208 Gt,\u0398 \u2208 Ct}. Note that Y\u0303t \u2287 Y\u0304 \u2287 Y\u221e` for t \u2265 T \u2032.\nIn order to project on to Y\u221e` , we need that it is nonempty. It is nonempty if the safe exploration phase is long enough such that ` \u2264 H\u221eY . We can therefore ensure that T \u2032 is sufficiently large as follows.\n` = 2 \u221a 2\u03b2TL\u221a 2\u03bd + \u03bb\u2212T \u2032 \u2264 H\u221eY\nT \u2032 \u2265 8\u03b2TL 2 \u03bb\u2212 ( H\u221eY )2 \u2212 2\u03bd\u03bb\u2212 =: th\nTogether with Lemma 17, we need that T \u2032 \u2265 max(t\u03b4, th). We can now prove the statement of the lemma directly. Since (3) is optimistic over all y in Y\u0303t and Y\u0303t \u2287 Y\u221e` , we have that f(y\u0303t) \u2265 f(y\u0304), where y\u0303t := \u0398\u0303txt, y\u2217 = \u0398\u2217x\u2217 and y\u0304 \u2208 arg miny\u2208Y\u221e` \u2016y\u2217 \u2212 y\u20162. This yields\nTerm I := f(y\u2217)\u2212 f(y\u0303t) \u2264 f(y\u2217)\u2212 f(y\u0304) \u2264 |f(y\u2217)\u2212 f(y\u0304)| \u2264M\u2016y\u2217 \u2212 y\u0304\u2016 \u2264MSharp\u221eY (`)\n= MSharp\u221eY\n( 2 \u221a\n2\u03b2TL\u221a 2\u03bd + \u03bb\u2212T \u2032 ) The statement of the lemma immediately follows."
        },
        {
            "heading": "B.2. Term II",
            "text": "First, we need a lemma from Abbasi-Yadkori et al. (2011). Lemma 19 (Lemma 11 in Abbasi-Yadkori et al. (2011)) For {xt}\u221et=1 with \u03bd > 0 and Vt = \u03bdI +\u2211t s=1 xs [xs] >, we have that\nT\u2211 t=1 min(\u2016xt\u20162[Vt\u22121]\u22121 , 1) \u2264 2(d log((trace(\u03bdI) + TL 2)/d)\u2212 log det(\u03bdI))\nwhen \u2016xt\u20162 \u2264 L for all t \u2208 [T ].\nWe then bound Term II with the following lemma.\nLemma 20 Let Assumptions 1\u20134 hold. For T > T \u2032 \u2265 max(th, t\u03b4), Term II is bounded as T\u2211\nt=T \u2032+1\nTerm II \u2264M max(LS, 1) \u221a n8\u03b2T (T \u2212 T \u2032)d log(1 + TL2/(d\u03bd)).\nwith probability at least 1\u2212 \u03b4.\nProof As in the proof of Lemma 14, we take \u0398\u2217 \u2208 Ct,\u2200t \u2208 [T ] and \u03bbmin(VT \u2032) \u2265 \u03bd + \u03bb\u2212T \u2032\n2 , which jointly holds with probability at least 1\u2212 2\u03b4.\nUsing Assumption 3, we have for t > T \u2032 that\nTerm II :=f(\u0398\u0303txt)\u2212 f(\u0398\u2217xt) \u2264|f(\u0398\u0303txt)\u2212 f(\u0398\u2217xt)| \u2264M\u2016\u0398\u0303txt \u2212\u0398\u2217xt\u20162 \u2264M\u221anmax\ni\u2208[n]\n( x>t \u03b8\u0303 i t \u2212 x>t \u03b8i\u2217 )\nLet r\u0304IIt := x > t \u03b8\u0303 i t \u2212 x>t \u03b8i\u2217 such that\nr\u0304IIt :=x > t \u03b8\u0303 i t \u2212 x>t \u03b8i\u2217 \u2264\u2016xt\u2016[Vt\u22121]\u22121 \u2225\u2225\u2225\u03b8\u0303it \u2212 \u03b8i\u2217\u2225\u2225\u2225\nVt\u22121 \u2264\u2016xt\u2016[Vt\u22121]\u22121 \u2225\u2225\u2225\u03b8\u0303it \u2212 \u03b8\u0302it + \u03b8\u0302it \u2212 \u03b8i\u2217\u2225\u2225\u2225\nVt\u22121 \u22642 \u221a \u03b2t \u2016xt\u2016[Vt\u22121]\u22121 .\nDue to the pure exploration phase, we have that\n2 \u221a \u03b2t \u2016xt\u2016[Vt\u22121]\u22121 \u2264 2 \u221a \u03b2TL\u221a\n\u03bbmin(Vt\u22121) \u2264 2\n\u221a 2\u03b2TL\u221a\n2\u03bd + \u03bb\u2212T \u2032 \u2264 H\u221eY .\nTherefore, the following bound applies when T is large enough such that \u03b2T \u2265 1.\nr\u0304IIt \u2264min ( H\u221eY , 2 \u221a \u03b2t \u2016xt\u2016[Vt\u22121]\u22121 ) \u22642 \u221a \u03b2T max(H \u221e Y , 1) min ( 1, \u2016xt\u2016[Vt\u22121]\u22121\n) We can then use Lemma 19 as\nT\u2211 t=T \u2032+1 [r\u0304IIt ] 2 =4\u03b2T max((H \u221e Y ) 2, 1) T\u2211 t=T \u2032+1 min ( 1, \u2016xt\u20162[Vt\u22121]\u22121 )\n\u22644\u03b2T max((H\u221eY )2, 1) T\u2211 t=1 min ( 1, \u2016xt\u20162[Vt\u22121]\u22121 ) \u22648\u03b2T max((H\u221eY )2, 1)(d log((trace(\u03bdI) + TL2)/d)\u2212 log det(\u03bdI)) =8\u03b2T max((H \u221e Y )\n2, 1)(d log((d\u03bd + TL2)/d)\u2212 d log(\u03bd)) =8\u03b2T max((H \u221e Y ) 2, 1)d log(1 + TL2/(d\u03bd)).\nTherefore, applying Cauchy-Schwarz yields\nT\u2211 t=T \u2032+1 r\u0304IIt \u2264 \u221a\u221a\u221a\u221a(T \u2212 T \u2032) T\u2211 t=T \u2032+1 [rIIt,i ] 2\n\u2264max(H\u221eY , 1) \u221a 8\u03b2T (T \u2212 T \u2032)d log(1 + TL2/(d\u03bd)).\nWe then have that\nT\u2211 t=T \u2032+1 Term II \u2264M max(H\u221eY , 1) \u221a nd8\u03b2T (T \u2212 T \u2032) log(1 + TL2/(d\u03bd))."
        },
        {
            "heading": "B.3. Complete Regret Bound",
            "text": "Finally, we can prove Theorem 12. Proof First, we have the trivial bound on the instantaneous regret as\nrt := f(\u0398\u2217x\u2217)\u2212 f(\u0398\u2217xt) \u2264M\u2016\u0398\u2217x\u2217 \u2212\u0398\u2217xt\u20162 \u2264M \u221a nmax i\u2208[n]\n( x>\u2217 \u03b8 i \u2217 \u2212 x>t \u03b8i\u2217 ) \u2264 2M\u221anLS\nWe use this trivial bound for the first T \u2032 time steps. Therefore, we can decompose the regret with respect to time and use Lemma 14 and Lemma 20 to get\nRT = T \u2032\u2211 t=1 rt + T\u2211 t=T \u2032+1 (Term I) + T\u2211 t=T \u2032+1 (Term II)\n= 2M \u221a nLST \u2032 +M max(H\u221eY , 1) \u221a n8\u03b2T (T \u2212 T \u2032)d log(1 + TL2/(d\u03bd))\n+M(T \u2212 T \u2032)Sharp\u221eY\n( 2 \u221a\n2\u03b2TL\u221a 2\u03bd + \u03bb\u2212T \u2032\n)"
        },
        {
            "heading": "Appendix C. Numerical Experiments",
            "text": "The numerical experiments were performed in a setting of action dimension d = 3 and response dimension n = 3. The reward function is linear, i.e. f(y) = a>y for some a \u2208 Rn. To methodically study the impact of sharpness, we use safety sets of the form Eb = {y \u2208 Rn : \u2016diag(b)y\u20161 \u2264 1} for some b \u2208 Rn. By appropriately choosing b, we can modify the sharpness of the set without changing the maximum shrinkage. The action set A is chosen to be non-restrictive such that Y = X .\nThe three safety sets that we study are Eb1 , Eb2 and Eb3 , where b1 = [0.1, 0.1, 0.1], b2 = [0.1/2, 0.1, 0.1] and b3 = [0.1/3, 0.1, 0.1]. Note that Eb1 , Eb2 and Eb3 all have a 2-norm maximum shrinkage of 10. To isolate the impact of sharpness, we ensure that the optimal response y\u2217 = \u03b8\u2217x\u2217 is in the \u201csharpest\u201d corner of the polytope by choosing a = e1. The parameter \u0398 is sampled randomly by choosing each element \u0398i,j \u223c U [\u22121, 1] for all i \u2208 [n] and j \u2208 [d]. Each element of the noise t is sampled it \u223c N(\u03c32) for all i \u2208 [n], where \u03c3 = 10\u22123. Also, we choose T = 103. Additionally, S = \u2016\u0398\u2217\u20162 + 0.1 and L = maxb\u2208{b1,b2,b3}maxx\u2208Eb \u2016x\u20162 + 0.1. The algorithm parameters are \u03bd = 0.1, T \u2032 = T 2/3 = 102, and \u03b4 = 0.01.\nAt each time step, the optimistic action in (3) is calculated using the `1 confidence set that is an outer approximation of Ct as used in Dani et al. (2008) and Amani et al. (2019). Specifically, we use the method detailed in Amani et al. (2019) which we summarize as follows. Since f is linear, (3) can be solved by enumerating the vertices of `1 confidence set and optimizing the reward given the parameter at each vertex. The optimal reward is then the maximum of the rewards at each vertex and the optimistic action is the maximizing action for this reward."
        }
    ],
    "title": "The Impact of the Geometric Properties of the Constraint Set in Safe Optimization with Bandit Feedback",
    "year": 2023
}