{
    "abstractText": "Natural language (NL) toolkits enable visualization developers, who may not have a background in natural language processing (NLP), to create natural language interfaces (NLIs) for end-users to flexibly specify and interact with visualizations. However, these toolkits currently only support one-off utterances, with minimal capability to facilitate a multi-turn dialog between the user and the system. Developing NLIs with such conversational interaction capabilities remains a challenging task, requiring implementations of low-level NLP techniques to process a new query as an intent to follow-up on an older query. We extend an existing Python-based toolkit, NL4DV, that processes an NL query about a tabular dataset and returns an analytic specification containing data attributes, analytic tasks, and relevant visualizations, modeled as a JSON object. Specifically, NL4DV now enables developers to facilitate multiple simultaneous conversations about a dataset and resolve associated ambiguities, augmenting new conversational information into the output JSON object. We demonstrate these capabilities through three examples: (1) an NLI to learn aspects of the Vega-Lite grammar, (2) a mind mapping application to create free-flowing conversations, and (3) a chatbot to answer questions and resolve ambiguities.",
    "authors": [
        {
            "affiliations": [],
            "name": "Rishab Mitra\u03c0"
        },
        {
            "affiliations": [],
            "name": "Arpit Narechania\u03c0"
        },
        {
            "affiliations": [],
            "name": "Alex Endert"
        },
        {
            "affiliations": [],
            "name": "John Stasko"
        }
    ],
    "id": "SP:1073e49310c098a63f35225cb99fd7db24a7690c",
    "references": [
        {
            "authors": [
                "G. Aisch"
            ],
            "title": "The Clubs That Connect The World Cup",
            "venue": "https: //www.nytimes.com/interactive/2014/06/20/sports/ worldcup/how-world-cup-players-are-connected.html,",
            "year": 2014
        },
        {
            "authors": [
                "R. Amar",
                "J. Eagan",
                "J. Stasko"
            ],
            "title": "Low-level Components of Analytic Activity in Information Visualization",
            "venue": "In IEEE Symposium on Information Visualization,",
            "year": 2005
        },
        {
            "authors": [
                "L. Blunschi",
                "C. Jossen",
                "D. Kossmann",
                "M. Mori",
                "K. Stockinger"
            ],
            "title": "SODA: Generating SQL for Business Users",
            "venue": "Proceedings of the VLDB Endowment,",
            "year": 2012
        },
        {
            "authors": [
                "M. Bostock",
                "V. Ogievetsky",
                "J. Heer"
            ],
            "title": "D3: Data-Driven Documents",
            "venue": "IEEE TVCG,",
            "year": 2011
        },
        {
            "authors": [
                "D. De Cock. Ames"
            ],
            "title": "Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project",
            "venue": "Journal of Statistics Education,",
            "year": 2011
        },
        {
            "authors": [
                "S. Fu",
                "K. Xiong",
                "X. Ge",
                "S. Tang",
                "W. Chen",
                "Y. Wu"
            ],
            "title": "Quda: Natural Language Queries for Visual Data Analytics",
            "venue": "arXiv preprint arXiv:2005.03257,",
            "year": 2020
        },
        {
            "authors": [
                "T. Gao",
                "M. Dontcheva",
                "E. Adar",
                "Z. Liu",
                "K.G. Karahalios"
            ],
            "title": "Data- Tone: Managing Ambiguity in Natural Language Interfaces for Data Visualization",
            "venue": "In ACM UIST,",
            "year": 2015
        },
        {
            "authors": [
                "M. Haugh"
            ],
            "title": "Conversational Interaction",
            "venue": "The Cambridge handbook of pragmatics,",
            "year": 2012
        },
        {
            "authors": [
                "P. He",
                "Y. Mao",
                "K. Chakrabarti",
                "W. Chen"
            ],
            "title": "X-SQL: Reinforce Schema Representation with Context",
            "venue": "arXiv preprint arXiv.1908.08113,",
            "year": 2019
        },
        {
            "authors": [
                "J. Herzig",
                "P.K. Nowak",
                "T. M\u00fcller",
                "F. Piccinno",
                "J.M. Eisenschlos"
            ],
            "title": "TAPAS: Weakly Supervised Table Parsing via Pre-training",
            "venue": "arXiv preprint arXiv:2004.02349,",
            "year": 2020
        },
        {
            "authors": [
                "M. Honnibal",
                "I. Montani"
            ],
            "title": "spacy 2: Natural Language Understanding with Bloom Embeddings",
            "venue": "Convolutional Neural Networks and Incremental Parsing,",
            "year": 2017
        },
        {
            "authors": [
                "E. Hoque",
                "V. Setlur",
                "M. Tory",
                "I. Dykeman"
            ],
            "title": "Applying Pragmatics Principles for Interaction with Visual Analytics",
            "venue": "IEEE TVCG,",
            "year": 2018
        },
        {
            "authors": [
                "J.-F. Kassel",
                "M. Rohs"
            ],
            "title": "Valletto: A Multimodal Interface for Ubiquitous Visual Analytics",
            "venue": "In ACM CHI Extended Abstracts,",
            "year": 2018
        },
        {
            "authors": [
                "D.H. Kim",
                "E. Hoque",
                "M. Agrawala"
            ],
            "title": "Answering Questions about Charts and Generating Visual Explanations",
            "venue": "In ACM CHI,",
            "year": 2020
        },
        {
            "authors": [
                "A. Kumar",
                "J. Aurisano",
                "B. Di Eugenio",
                "A. Johnson",
                "A. Gonzalez",
                "J. Leigh"
            ],
            "title": "Towards a Dialog System that Supports Rich Visualizations of Data",
            "venue": "In SIGDIAL,",
            "year": 2016
        },
        {
            "authors": [
                "F. Li",
                "H.V. Jagadish"
            ],
            "title": "NaLIR: an interactive natural language interface for querying relational databases",
            "venue": "In ACM SIGMOD,",
            "year": 2014
        },
        {
            "authors": [
                "C. Liu",
                "Y. Han",
                "R. Jiang",
                "X. Yuan"
            ],
            "title": "ADVISor: Automatic Visualization Answer for Natural-Language Question on Tabular Data",
            "venue": "In IEEE PacificVis,",
            "year": 2021
        },
        {
            "authors": [
                "E. Loper",
                "S. Bird"
            ],
            "title": "NLTK: The natural language toolkit",
            "venue": "arXiv preprint cs/0205028,",
            "year": 2002
        },
        {
            "authors": [
                "Y. Luo",
                "N. Tang",
                "G. Li",
                "C. Chai",
                "W. Li",
                "X. Qin"
            ],
            "title": "Synthesizing Natural Language to Visualization (NL2VIS) Benchmarks from NL2SQL Benchmarks",
            "venue": "In ACM SIGMOD,",
            "year": 2021
        },
        {
            "authors": [
                "Y. Luo",
                "N. Tang",
                "G. Li",
                "J. Tang",
                "C. Chai",
                "X. Qin"
            ],
            "title": "Natural Language to Visualization by Neural Machine Translation",
            "venue": "IEEE TVCG,",
            "year": 2021
        },
        {
            "authors": [
                "J. Mackinlay",
                "P. Hanrahan",
                "C. Stolte"
            ],
            "title": "Show Me: Automatic Presentation for Visual Analysis",
            "venue": "IEEE TVCG,",
            "year": 2007
        },
        {
            "authors": [
                "A. Narechania",
                "A. Fourney",
                "B. Lee",
                "G. Ramos"
            ],
            "title": "DIY: Assessing the Correctness of Natural Language to SQL Systems",
            "venue": "In ACM IUI,",
            "year": 2021
        },
        {
            "authors": [
                "A. Narechania",
                "A. Srinivasan",
                "J. Stasko"
            ],
            "title": "NL4DV: A Toolkit for Generating Analytic Specifications for Data Visualization from Natural Language Queries",
            "venue": "IEEE TVCG,",
            "year": 2021
        },
        {
            "authors": [
                "P. Pasupat",
                "P. Liang"
            ],
            "title": "Compositional Semantic Parsing on Semi- Structured Tables",
            "venue": "In ACL IJCNLP,",
            "year": 2015
        },
        {
            "authors": [
                "A. Satyanarayan",
                "D. Moritz",
                "K. Wongsuphasawat",
                "J. Heer"
            ],
            "title": "Vega- Lite: A Grammar of Interactive Graphics",
            "venue": "IEEE TVCG,",
            "year": 2016
        },
        {
            "authors": [
                "V. Setlur",
                "S.E. Battersby",
                "M. Tory",
                "R. Gossweiler",
                "A.X. Chang"
            ],
            "title": "Eviza: A Natural Language Interface for Visual Analysis",
            "venue": "In ACM UIST,",
            "year": 2016
        },
        {
            "authors": [
                "V. Setlur",
                "M. Tory",
                "A. Djalali"
            ],
            "title": "Inferencing Underspecified Natural Language Utterances in Visual Analysis",
            "venue": "In ACM IUI,",
            "year": 2019
        },
        {
            "authors": [
                "A. Srinivasan",
                "B. Lee",
                "N.H. Riche",
                "S.M. Drucker",
                "K. Hinckley"
            ],
            "title": "InChorus: Designing Consistent Multimodal Interactions for Data Visualization on Tablet Devices",
            "venue": "In ACM CHI,",
            "year": 2020
        },
        {
            "authors": [
                "A. Srinivasan",
                "B. Lee",
                "J.T. Stasko"
            ],
            "title": "Interweaving Multimodal Interaction with Flexible Unit Visualizations for Data Exploration",
            "venue": "IEEE TVCG,",
            "year": 2020
        },
        {
            "authors": [
                "A. Srinivasan",
                "N. Nyapathy",
                "B. Lee",
                "S.M. Drucker",
                "J. Stasko"
            ],
            "title": "Collecting and Characterizing Natural Language Utterances for Specifying Data Visualizations",
            "venue": "In ACM CHI,",
            "year": 2021
        },
        {
            "authors": [
                "A. Srinivasan",
                "V. Setlur"
            ],
            "title": "Snowy: Recommending Utterances for Conversational Visual Analysis",
            "venue": "In ACM UIST,",
            "year": 2021
        },
        {
            "authors": [
                "A. Srinivasan",
                "J. Stasko"
            ],
            "title": "Orko: Facilitating Multimodal Interaction for Visual Exploration and Analysis of Networks",
            "venue": "IEEE TVCG,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Sun",
                "J. Leigh",
                "A. Johnson",
                "S. Lee"
            ],
            "title": "Articulate: A Semi-automated Model for Translating Natural Language Queries into Meaningful Visualizations",
            "venue": "In Proceedings of the International Symposium on Smart Graphics,",
            "year": 2010
        },
        {
            "authors": [
                "C. Wang",
                "K. Tatwawadi",
                "M. Brockschmidt",
                "P.-S. Huang",
                "Y. Mao",
                "O. Polozov",
                "R. Singh"
            ],
            "title": "Robust Text-to-SQL Generation with Execution-Guided Decoding",
            "venue": "arXiv preprint arXiv:1807.03100,",
            "year": 2018
        },
        {
            "authors": [
                "K. Wongsuphasawat",
                "D. Moritz",
                "A. Anand",
                "J. Mackinlay",
                "B. Howe",
                "J. Heer"
            ],
            "title": "Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations",
            "venue": "IEEE TVCG,",
            "year": 2015
        },
        {
            "authors": [
                "K. Wongsuphasawat",
                "Z. Qu",
                "D. Moritz",
                "R. Chang",
                "F. Ouk",
                "A. Anand",
                "J. Mackinlay",
                "B. Howe",
                "J. Heer"
            ],
            "title": "Voyager 2: Augmenting Visual Analysis with Partial View Specifications",
            "venue": "In ACM CHI,",
            "year": 2017
        },
        {
            "authors": [
                "B. Yu",
                "C.T. Silva"
            ],
            "title": "FlowSense: A Natural Language Interface for Visual Data Exploration within a Dataflow System",
            "venue": "IEEE TVCG,",
            "year": 2020
        },
        {
            "authors": [
                "T. Yu",
                "R. Zhang",
                "H.Y. Er",
                "S. Li",
                "E. Xue",
                "B. Pang",
                "X.V. Lin",
                "Y.C. Tan",
                "T. Shi",
                "Z. Li"
            ],
            "title": "CoSQL: A Conversational Text-to-SQL Challenge 5 \u00a9 2022 IEEE. This is the author\u2019s version of the article that has been published in the proceedings of IEEE Visualization conference. The final version of this record is available at: xx.xxxx/TVCG.201x.xxxxxxx/ Towards Cross-Domain Natural Language Interfaces to Databases",
            "venue": "ACL EMNLP-IJCNLP,",
            "year": 2019
        },
        {
            "authors": [
                "V. Zhong",
                "C. Xiong",
                "R. Socher"
            ],
            "title": "Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning",
            "venue": "arXiv preprint arXiv:1709.00103,",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Index Terms: Human-centered computing\u2014Visualization\u2014Visualization systems and tools\u2014Visualization toolkits; Human-centered computing\u2014Human computer interaction (HCI)\u2014Interaction techniques\u2014Text input"
        },
        {
            "heading": "1 INTRODUCTION AND BACKGROUND",
            "text": "Natural language interfaces (NLIs) for databases [5,13,14,21,28,31, 44, 49] and visualizations [4, 10, 16, 18\u201320, 27, 29, 35\u201338, 41\u201343, 47] have shown great promise, democratizing access to data through the querying power and expressivity of natural language (NL). Given a dataset (e.g., movies), an NLI for visualization receives an NL query (e.g., \u201cShow the distribution of budget\u201d) as input, extracts data attributes (Production Budget) and analytic tasks (Distribution), and recommends one or more relevant visualizations (Histogram). Many of these NLIs also help resolve ambiguities that may occur during query interpretation. For example, DataTone [10] presents ambiguities through interactive GUI-based widgets (e.g., dropdowns) for disambiguation. Implementing such NLIs, however, requires experience with natural language processing (NLP) techniques and toolkits (e.g., NLTK [23], spaCy [15]) as well as GUI and visualization design tools (e.g., D3.js [6], Vega-Lite [33]), making it challenging for developers without the necessary skillset.\nRecently, NL toolkits [9, 22, 25, 29] have enabled visualization developers, who may not have a background in NLP, to create new\n*e-mail: rmitra34@gatech.edu \u2020e-mail: arpitnarechania4@gatech.edu \u2021e-mail: endert@gatech.edu \u00a7e-mail: stasko@cc.gatech.edu\n\u03c0 authors contributed equally\nvisualization NLIs or incorporate NL input within their existing systems. For example, given a tabular dataset and an NL query about the dataset, NL4DV generates an analytic specification comprising data attributes, analytic tasks (based on [2]), and visualizations (as Vega-Lite specifications [33]) modeled as a JSON object. However, these toolkits currently support one-off utterances (singleton queries) only, with minimal capability to facilitate a multi-turn dialog between the end-user and the system, e.g., by following-up on a previous query. Because of this, end-users would have to specify longer NL queries (e.g., \u201cShow the relationship between budget and rating for Action and Adventure movies that grossed over 100M\u201d) to accomplish more complex tasks. These types of queries may also have a greater chance of failing (e.g., attribute detection can fail; filter operators may be incorrect), eventually warranting several paraphrasing attempts. We believe specifying multiple short queries in a natural sequence can enable end-users to incrementally accomplish a complex task, fix minor errors, and also make debugging easier, as in [3, 11, 16, 35, 38, 40]. This is called conversational interaction \u2013 \u201cface-to-face or technology-mediated forms of interaction that use language, encompassing a wide range of different types of talk\u201d [12].\nDeveloping NLIs with such conversational interaction capabilities remains a challenging task, however, requiring implementations of low-level NLP techniques to process a new query as an intent to follow-up on an older query, e.g., replacing an existing attribute with a new one. To the best of our knowledge, no NL toolkit facilitates conversational interaction, yet. Hence, in this work, we extend a Python-based toolkit, NL4DV [29], in order to enable visualization developers to facilitate multiple simultaneous conversations (through manual specification as well as automatic detection of intents to follow-up) and resolve associated ambiguities through an easy-to-use application programming interface (API). As a result, NL4DV also augments additional conversational information into the output JSON. We demonstrate these capabilities through three examples: (1) an NLI to learn aspects of Vega-Lite \u2013 an implementation of a grammar for interactive graphics [33], (2) a mind mapping application to create free-flowing conversations about a dataset, and (3) a chatbot to answer questions and resolve ambiguities in collaboration with the enduser. To support development of future systems, we open-source NL4DV and the described applications at https://nl4dv.github.io/nl4dv/."
        },
        {
            "heading": "2 CONVERSATIONAL INTERACTION WITH NL4DV",
            "text": "Listing 1 illustrates the basic Python code for developers to enable conversational interaction in their own applications using NL4DV. Given a tabular dataset on Houses (adapted from [7]; accessible at [17]) and a query string specified by the end-user, \u201cShow average prices for different home types over the years\u201d, with a single function call analyze query(query) (lines 1-3), NL4DV first determines it as a standalone query (as it is the very first query), extracts data attributes and analytic tasks, recommends visualizations, and then assigns new objects that identify that conversation (dialogId=\u201c0\u201d) and the corresponding query (queryId=\u201c0\u201d) as part of the output JSON (lines 4-5). After observing the output visualization, if the enduser wants a bar chart instead of a line chart, they may ask, \u201cAs a bar chart\u201d with a new parameter, dialog=\u201cauto\u201d. NL4DV automatically\nar X\niv :2\n20 7.\n00 18\n9v 3\n[ cs\n.H C\n] 1\n2 A\nug 2\n02 2\n1 from nl4dv import NL4DV"
        },
        {
            "heading": "2 nl4dv_instance = NL4DV(data_url=\"housing.csv\")",
            "text": ""
        },
        {
            "heading": "3 resp_1 = nl4dv_instance.analyze_query(\"Show average prices for different home types over the years.\")\u21aa\u2192",
            "text": ""
        },
        {
            "heading": "4 print(resp_1)",
            "text": "5 # a new dialogId and a queryId get created.\n{\n\"dialogId\": \"0\",\n\"queryId\": \"0\",\n...\n}"
        },
        {
            "heading": "6 # this query is automatically inferred as a follow-up.",
            "text": "7 resp_2 = nl4dv_instance.analyze_query(\"As a bar chart.\",\ndialog=\"auto\")\u21aa\u2192\n8 print(resp_2)\n{\n\"dialogId\": \"0\",\n\"queryId\": \"1\",\n\"followUpConfidence\":\n\"high\", ...\n}"
        },
        {
            "heading": "9 # this query is a new, standalone query.",
            "text": "10 resp_3 = nl4dv_instance.analyze_query(\"Correlate Price and\nLot Area.\", dialog=False)\u21aa\u2192\n11 print(resp_3)\n{\n\"dialogId\": \"1\",\n\"queryId\": \"0\",\n...\n}\n12 # this query follows up a specific, older query.\n13 resp_4 = nl4dv_instance.analyze_query(\"Just show condos and\nduplexes.\", dialog=True, dialog_id=\"0\", query_id=\"1\")\u21aa\u2192\n14 print(resp_4)\n{\n\"dialogId\": \"0\",\n\"queryId\": \"2\",\n...\n}\nListing 1: Python code illustrating how developers can enable conversational interaction in their applications using NL4DV.\ndetermines this as a follow-up to the previous query (with a heuristically determined followUpConfidence=\u201chigh\u201d) and directly modifies its analytic specification, retaining the dialogId=\u201c0\u201d but generating a new, now incremented queryId=\u201c1\u201d as the second query in the conversation (lines 6-8). If the end-user is suddenly curious about how house prices compare with area, they may ask, \u201cCorrelate price and area\u201d, explicitly specifying the query as standalone (dialog=False). This time, NL4DV increments dialogId=\u201c1\u201d and resets queryId=\u201c0\u201d since this is now the first query of a new, second conversation (lines 9-11). If the end-user wants to resume their original conversation and only focus on certain home types, they may ask, \u201cJust show condos and duplexes\u201d, this time explicitly specifying the query as a follow-up (dialog=True) with additional parameters: dialog id=\u201c0\u201d, query id=\u201c1\u201d, that correspond to the first conversation (lines 12-14). As expected, the resultant dialogId=\u201c0\u201d and queryId=\u201c2\u201d, along with the filtered bar chart.\nTo achieve this kind of conversational interaction, we extended NL4DV [29]; Figure 1 illustrates the modified technical architecture. The existing Query Processor module parses the input NL query using NLP techniques such as tokenizing and parts of speech tagging (Query Parser), extracts data attributes through semantic and syntactic similarity matching (Attribute Identifier) and analytic tasks through dependency parsing (Tasks Identifier), and recommends relevant visualizations based on heuristics used in prior systems [26, 45, 46] (Visualization Specification Generator), that are"
        },
        {
            "heading": "1 all_dialogs = {",
            "text": ""
        },
        {
            "heading": "2 \"0\": [{\"query\":\"show the distribution of salaries as a",
            "text": "boxplot\",...}, {\"query\":\"How about goals instead?\",..}],\u21aa\u2192"
        },
        {
            "heading": "3 \"1\": [{\"query\": \"Show average goals per country\",...},",
            "text": "{\"query\": \"now group by foot\",...}],\u21aa\u2192"
        },
        {
            "heading": "4 \"2\": [{\"query\": \"correlate age and salary\",...}, {\"query\": \"now show only defenders\",...}],\u21aa\u2192",
            "text": ""
        },
        {
            "heading": "5 \"2.0.0\": [{\"query\": \"correlate age and salary\",...},",
            "text": "{\"query\": \"what about only goalkeepers?\",...}] #\nfollow-up to query with dialog_id=\"2\" and index=0\n\u21aa\u2192\n\u21aa\u2192\n6 }\nListing 2: Data structure to store multiple conversations, including branches (multiple follow-ups to the same query).\ncombined into an Output JSON. The new Conversation Manager module enables developers to automatically determine or manually specify a query as a follow-up (or not). This module also determines the type of follow-up (e.g., add or remove attributes), managing all operations on the internal data structures. Also new, the Query Resolver module facilitates resolving NL ambiguities (e.g., by \u201cmedals\u201d did the end-user mean \u201c{Total | Gold | Silver | Bronze} Medals\u201d?)."
        },
        {
            "heading": "2.1 Facilitating Multiple Simultaneous Conversations",
            "text": "Following the dialog shown in Listing 1, whenever the end-user asks a new, standalone query, the dialog id is also incremented by \u201c1\u201d and the query id is re-initialized to \u201c0\u201d (identifiers are stringified after incrementing for efficient handling of data), creating a new dialog instance that is uniquely identifiable by dialogId and queryId. Subsequently, developers can explicitly follow up on specific queries by passing the follow-up query string along with additional input parameters: dialog (a boolean flag expressing an explicit intent to follow-up), dialog id, and query id to analyze query(query).\nThis design also enables end-users to ask multiple unrelated follow-ups to the same query. To create such conversational branches, developers can provide the same dialog id and query id in repeated calls to analyze query(query). Internally, NL4DV creates the desired branch point and outputs a new, unique dialogId with the format: \u201c{dialog id}.{query id}.{branch id}\u201d (similar to the semantic versioning format [34]), where {branch id} is the index of the branch stemming from the input parameters: {dialog id} and {query id}. This naming convention effectively represents the hierarchy of all entities involved in the conversation. Listing 2 shows how NL4DV stores these conversations in a Python dictionary of lists with dialog ids as the keys and query ids as the indexes of the corresponding list of queries. This data structure enables efficient retrieve, append, modify, and delete operations. Note that calling analyze query(query, dialog=True), without dialog id or query id, will make NL4DV follow up on the most recent dialogId and queryId; if these too do not exist (e.g., it is the very first conversation), then an error is thrown."
        },
        {
            "heading": "2.2 Detecting, Classifying and Processing Follow-ups",
            "text": "To supply dialog, dialog id and query id parameters to analyze query(query), developers have to provide GUI affordances for end-users, e.g., a checkbox to specify if dialog=True or not (and which conversation to follow-up on), which can be an unnatural end-user experience. To alleviate this, NL4DV offers a dialog=\u201cauto\u201d setting (overloading the otherwise boolean input data type) that automatically determines if the query is a follow-up or not and outputs a followUpConfidence rating: {\u201chigh\u201d, \u201clow\u201d, \u201cnone\u201d} reflecting NL4DV\u2019s confidence in making the inference. This rating is heuristically determined based on the previous query, an explicit followup keywords map \u2013 keywords that convey natural conversational intents to follow-up (e.g., \u201cadd\u201d, \u201creplace\u201d), and an implicit followup keywords map \u2013 keywords that implicitly convey an intent to follow-up (e.g., \u201cinstead of\u201d, \u201conly\u201d). The implicit followup keywords are further classified as non-ambiguous \u2013 keywords that always convey an intent to follow-up (e.g. \u201cinstead of\u201d, \u201crather than\u201d) and ambiguous \u2013 keywords that can occur in a follow-up as well as standalone context (e.g., \u201conly\u201d). NL4DV assigns queries containing explicit keywords or implicit non-ambiguous keywords with a high followUpConfidence rating and implicit ambiguous keywords with a low followUpConfidence rating. For queries with no matching keywords, NL4DV compares the attributes, tasks, and visualizations of the current and the previous query and based on a heuristics and rule-based decision tree, assigns either a low or none followUpConfidence rating, the latter corresponding to a new, standalone query. For example, a query \u201cShow the average now.\u201d is a compatible follow-up to its predecessor, \u201cShow maximum price across different home types.\u201d; the desired change from \u201cmaximum\u201d to \u201caverage\u201d in the absence of any other follow-up keywords or attributes makes them compatible. Developers can override these default maps by supplying custom explicit followup keywords and implicit followup keywords objects through the NL4DV() constructor during initialization.\nNext, the explicit followup keywords map classifies the followup query as one of three types: add, remove, or replace (inspired by Evizeon\u2019s continue, retain, shift transitional states [16]) and maps it to one or more components of an analytic specification: data attributes, analytic tasks, and visualizations. Note that the resultant combinations (e.g., replace + data attribute) are not always mutually exclusive, e.g., replacing an attribute can sometimes also modify the task(s) and/or the visualization(s). Lastly, NL4DV references the parent query\u2019s (the query being followed upon) analytic specification and makes necessary associations (e.g., creating new conversational branches) and modifications (e.g., dropping an existing attribute), eventually generating a new specification as a JSON object.\nBy configuring the keyword maps and supplying methods with appropriate parameters, end-users can add, remove, or replace data attributes, either explicitly, e.g., \u201cReplace budget with gross\u201d\u2013which makes a direct reference to the data attributes and the follow-up task; or implicitly, e.g., \u201cNow show only budget\u201d\u2013which indirectly suggests to remove all other attributes except \u201cProduction Budget\u201d. Unlike attributes, following up on tasks is different because endusers are unaware of the associated technical jargon, e.g. \u201cAdd Find Extremum to Worldwide Gross\u201d is not a natural query an end-user would ask; they would rather say, \u201cShow me the highest grossing movie\u201d, which would then infer the Find Extremum task [2] (through \u2018highest\u2019). Thus, most queries that follow-up on tasks are implicit in nature. NL4DV currently supports sort (e.g., \u201cSort by budget in an ascending order\u201d), find extremum (e.g., \u201cWhich of these genres has the smallest budget?\u201d), filter (e.g., \u201cNow show only action movies\u201d), and derived value (e.g., \u201cReplace average with sum\u201d) tasks [2]. A follow-up to add (or remove) a visualization is meaningless as there will (or must) always be some recommended chart. Replace is the only meaningful task and it can be explicit (e.g., \u201cReplace this line\n1 from nl4dv import NL4DV"
        },
        {
            "heading": "2 nl4dv_instance = NL4DV(data_url=\"olympic_medals.csv\")",
            "text": ""
        },
        {
            "heading": "3 init_response = nl4dv_instance.analyze_query(\"Show medals in hockey and skating by country.\")\u21aa\u2192",
            "text": ""
        },
        {
            "heading": "4 # Multiple ambiguities are detected from the query.",
            "text": ""
        },
        {
            "heading": "5 print(init_response)",
            "text": "{ \"dialogId\": \"0\", \"queryId\": \"0\",\n\"ambiguities\": {\n\"attribute\": {\n\"medals\": { \"options\": [\"Bronze Medal\",\"Gold\nMedal\",\"Silver Medal\", \"Total Medal\"],\u21aa\u2192\n\"selected\": null}},\n\"value\": {\n\"skating\": { \"options\": [\"Figure Skating\", \"Short Speed\nSkating\", \"Speed Skating\"],\u21aa\u2192\n\"selected\": null},\n\"hockey\": { \"options\": [\"Hockey\", \"Ice Hockey\"],\n\"selected\": null}}\n}, ... }"
        },
        {
            "heading": "6 resolved_response = nl4dv_instance.update_query({\"attribute\":",
            "text": "{ \"medals\": \"Total Medal\" }, \"value\": {\"skating\": \"Speed\nSkating\", \"hockey\": \"Ice Hockey\"}})\n\u21aa\u2192\n\u21aa\u2192"
        },
        {
            "heading": "7 print(resolved_response)",
            "text": "8 # The \"selected\" property is updated in the response.\n{\"dialogId\":\"0\",\"queryId\":\"0\",\"ambiguities\":{...}, ...}\nListing 3: Python code illustrating how NL4DV helps resolve ambiguities via update query(obj) (line 6).\nchart with a bar chart\u201d) or implicit (e.g., \u201cAs a bar chart instead\u201d)."
        },
        {
            "heading": "2.3 Resolving Ambiguities during Query Interpretation",
            "text": "Natural language (NL) is often ambiguous and underspecified, e.g., consider the query, \u201cShow medals in hockey and skating by country\u201d regarding a dataset on Olympic Medals (adapted from [32]; accessible at [30]). Here, \u201cmedals\u201d (attribute) could be mapped to either of [\u201cTotal Medals\u201d, \u201cGold Medals\u201d, \u201cSilver Medals\u201d, \u201cBronze Medals\u201d], \u201chockey\u201d (value) could be mapped to either of [\u201cIce Hockey\u201d, \u201cHockey\u201d], and \u201cskating\u201d could be mapped to either of [\u201cFigure Skating\u201d, \u201cSpeed Skating\u201d, \u201cShort Speed Skating\u201d].\nThese ambiguities can cause problems while processing ambiguous follow-up queries (e.g., \u201cSort by medals\u201d\u2013Which type of \u201cmedals\u201d?), and hence must be resolved a priori. NL4DV detects these attribute-level and value-level ambiguities and makes them accessible in the output JSON under a new key, ambiguities. In addition, NL4DV now provides a new function update query(obj), to help developers design experiences that resolve ambiguities directly through the toolkit, also enabling accurate processing of subsequent follow-up queries. Listing 3 illustrates how update query(obj) (line 6) takes a Python dictionary as input, that includes the types of ambiguities (\u201cattribute\u201d and \u201cvalue\u201d), the corresponding keywords in the query (\u201cmedals\u201d, \u201chockey\u201d, and \u201cskating\u201d), and the corresponding entities selected by the end-user for resolution. NL4DV then updates the selected entities under ambiguities as well as the attributeMap and the taskMap, recommending a new visList (visualizations). Note that developers may not always provide end-users with affordances to resolve such ambiguities. In these cases, NL4DV automatically resolves ambiguities by itself, selecting the entities that have the highest string-based similarity score with the corresponding query keyword, and calling update query(obj). In case of ties, entities that were detected first are selected."
        },
        {
            "heading": "3 CREATING VISUALIZATION SYSTEMS WITH NL4DV",
            "text": ""
        },
        {
            "heading": "3.1 NL-Driven Vega-Lite Learner",
            "text": "The NL-Driven Vega-Lite Editor in NL4DV [29] demonstrated how NL can be used to create, edit, and hence learn the Vega-Lite [33] grammar. However, end-users of this system need to be proficient with the Vega-Lite syntax (e.g., properties and operators) to be able\nto successfully edit the specifications output by NL4DV. Figure 2 illustrates the user interface of a similar NL-Driven Vega-Lite Learner that demonstrates how conversational interaction can help users learn this grammar better by sequentially processing short, specific NL intents and incrementally building the Vega-Lite specification, helping users learn the syntax changes required to achieve the corresponding intents. Users ask a series of short NL queries and observe the resultant Vega-Lite specifications. These queries are chained together, forming a conversation. Users can see the diff (i.e., added and removed entities) between the Vega-Lite specifications of the selected query and its predecessor through code highlights (green implies addition; red implies deletion). For example, a follow-up query to apply a filter, \u201cNow show only Action movies\u201d generates a Vega-Lite specification that differs from the previous query\u2019s specification in terms of the transform property, helping the user learn how Vega-Lite filters are specified. To develop this interface, developers can sequentially call analyze query(query, dialog=True) and then focus on computing the diffs between the Vega-Lite specifications of the query and its predecessor and programming the layout, styling, and interactivity aspects using HTML, CSS, JavaScript."
        },
        {
            "heading": "3.2 Mind Mapping Conversations about a Dataset",
            "text": "In this second use-case, we demonstrate how the input parameters: dialog, dialog id and query id in analyze query(query) can help end-users engage in multiple simultaneous conversations, unlike the NL-Driven Vega-Lite Learner, that supports only one conversation at-a-time. Figure 3 illustrates the user interface of a mind mapping application that helps users engage in free-flowing conversations regarding a European soccer players dataset (adapted from [1]; accessible at [8]). Listing 2 shows the corresponding data structure maintained by NL4DV. Through speech or text input, users can ask standalone queries (e.g., \u201cCorrelate age and salary\u201d) as well as follow-up queries (e.g., \u201cNow show only defenders\u201d) by clicking\nthe plus icon, enabled by hovering on the corresponding mind map node (the rectangular block). Users can also follow-up on already followed-up queries, forming new conversational branches (e.g., \u201cWhat about only goalkeepers?\u201d). To develop this interface, developers can call analyze query(query, dialog, dialog id, query id), supplying the dialog and query identifiers based on the corresponding query that is to be followed-upon. Then, based on the newly generated dialogId and queryId, a new node is created and appended to the corresponding predecessor query node."
        },
        {
            "heading": "3.3 Collaboratively Resolve Ambiguities in a ChatBot",
            "text": "In this third use-case, we demonstrate how NL4DV\u2019s Query Resolver can help resolve ambiguities that often occur in natural language. Figure 4 illustrates a standard chatbot user interface that presents DataTone-like [10] \u201cambiguity widgets\u201d\u2013dropdowns and buttons. End-users can disambiguate by interacting with the widgets, notifying NL4DV through a function call to update query(obj). After all ambiguities are resolved, the system renders the nowunambiguous visualization. To develop this interface, developers can loop through the ambiguities object in the output JSON and present corresponding options to the end-user, e.g., as options in a select dropdown. As the end-user makes their choices, a function call to update query(obj) will resolve the ambiguity, updating the selected properties in the output JSON. Listing 3 illustrates this data exchange between the user interface and NL4DV."
        },
        {
            "heading": "4 CONCLUSION, LIMITATIONS, AND FUTURE WORK",
            "text": "In this work, we extend an existing natural language (NL) for data visualization toolkit, NL4DV, to enable developers to integrate conversational interaction capabilities within natural language interfaces. We demonstrate NL4DV\u2019s capabilities through three examples and open-source the toolkit at https://nl4dv.github.io/nl4dv/.\nWhile testing, we noted certain conversational ambiguities, e.g., if a query, \u201cShow only Action movies\u201d is followed-up with \u201cWhat about R-rated movies?\u201d does the user mean to augment the previous filter or replace it with the new one? Consider another query, \u201cVisualize budget distribution as a histogram instead of a boxplot\u201d; here, the user means to ask a standalone query, but the presence of \u201cinstead of\u201d (an implicit follow-up keyword) will make NL4DV wrongly treat it as a follow-up. We will address these ambiguities and translation errors in future releases. We also plan a formal performance evaluation of the toolkit. However, unlike conversational text-to-SQL dataset benchmarks (e.g., CoSQL [48]), there are currently no such benchmarks for visualization tasks. An area of future work, thus, for current text-to-visualization datasets [9, 24, 39], that focus on singleton utterances, is to include multi-turn utterances."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This work was supported in part by an NSF Grant IIS-1717111. We thank Arjun Srinivasan and the Georgia Tech Visualization Lab."
        }
    ],
    "title": "Facilitating Conversational Interaction in Natural Language Interfaces for Visualization",
    "year": 2022
}