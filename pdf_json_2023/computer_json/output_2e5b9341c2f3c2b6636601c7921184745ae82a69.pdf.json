{
    "abstractText": "The use of language is innately political and often a vehicle of cultural identity as well as the basis for nation building. Here, we examine language choice and tweeting activity of Ukrainian citizens based on more than 4 million geo-tagged tweets from over 62,000 users before and during the Russian-Ukrainian War, from January 2020 to October 2022. Using statistical models, we disentangle sample effects, arising from the inand outflux of users on Twitter, from behavioural effects, arising from behavioural changes of the users. We observe a steady shift from the Russian language towards the Ukrainian language already before the war, which drastically speeds up with its outbreak. We attribute these shifts in large part to users\u2019 behavioural changes. Notably, we find that more than half of the Russian-tweeting users shift towards Ukrainian as a result of the war.",
    "authors": [
        {
            "affiliations": [],
            "name": "Daniel Racek"
        },
        {
            "affiliations": [],
            "name": "Brittany I. Davidson"
        },
        {
            "affiliations": [],
            "name": "Paul W. Thurner"
        },
        {
            "affiliations": [],
            "name": "Xiao Xiang Zhu"
        },
        {
            "affiliations": [],
            "name": "G\u00f6ran Kauermann"
        }
    ],
    "id": "SP:009c45dcce55ed6d60fa4dfea32472282d484310",
    "references": [
        {
            "authors": [
                "H. Allcott",
                "M. Gentzkow"
            ],
            "title": "Social media and fake news in the 2016 election",
            "venue": "Journal of economic perspectives",
            "year": 2017
        },
        {
            "authors": [
                "F. Barbieri",
                "L.E. Anke",
                "J. Camacho-Collados"
            ],
            "title": "Xlm-t: Multilingual language models in twitter for sentiment analysis and beyond",
            "venue": "in: Proceedings of the Thirteenth Language Resources and Evaluation Conference,",
            "year": 2022
        },
        {
            "authors": [
                "M.M. Bigg"
            ],
            "title": "Russia invaded ukraine more than 200 days ago. here is one key development from every month of the war",
            "venue": "URL: https://www.nytimes.com/article/ ukraine-russia-war-timeline.html",
            "year": 2022
        },
        {
            "authors": [
                "T.W. Christiansen"
            ],
            "title": "The rise of english as the global lingua franca. is the world heading towards greater monolingualism or new forms of plurilingualism",
            "year": 2015
        },
        {
            "authors": [
                "L. Dabbish",
                "R. Farzan",
                "R. Kraut",
                "T. Postmes"
            ],
            "title": "Fresh faces in the crowd: turnover, identity, and commitment in online groups",
            "venue": "in: Proceedings of the ACM 2012 conference on computer supported cooperative work,",
            "year": 2012
        },
        {
            "authors": [
                "B.I. Davidson",
                "S.L. Jones",
                "A.N. Joinson",
                "J. Hinds"
            ],
            "title": "The evolution of online ideological communities",
            "venue": "PloS one 14,",
            "year": 2019
        },
        {
            "authors": [
                "C. Dowd",
                "P. Justino",
                "R. Kishi",
                "G. Marchais"
            ],
            "title": "Comparing \u2018new\u2019and \u2018old\u2019media for violence monitoring and crisis response: evidence from kenya",
            "venue": "Research & Politics",
            "year": 2020
        },
        {
            "authors": [
                "L. Dwarakanath",
                "A. Kamsin",
                "R.A. Rasheed",
                "A. Anandhan",
                "L. Shuib"
            ],
            "title": "Automated machine learning approaches for emergency response and coordination via social media in the aftermath of a disaster: A review",
            "venue": "IEEE Access",
            "year": 2021
        },
        {
            "authors": [
                "Y.K. Dwivedi",
                "E. Ismagilova",
                "N.P. Rana",
                "R. Raman"
            ],
            "title": "Social media adoption, usage and impact in business-to-business (b2b) context: A state-of-the-art literature review",
            "venue": "Information Systems",
            "year": 2021
        },
        {
            "authors": [
                "F. Dzogang",
                "T. Lansdall-Welfare",
                "N. Cristianini"
            ],
            "title": "Seasonal fluctuations in collective mood",
            "year": 2016
        },
        {
            "authors": [
                "J.C. Eichstaedt",
                "A.C. Weidman"
            ],
            "title": "Tracking fluctuations in psychological states using social",
            "venue": "Data Mining Workshops (ICDMW),",
            "year": 2020
        },
        {
            "authors": [
                "J. Flamino",
                "A. Galeazzi",
                "S. Feldman",
                "M.W. Macy",
                "B. Cross",
                "Z. Zhou",
                "M. Serafino",
                "A. Bovet",
                "H.A. Makse",
                "B.K. Szymanski"
            ],
            "title": "Political polarization of news media and influencers on twitter in the 2016 and 2020 us presidential elections",
            "venue": "Nature Human Behaviour ,",
            "year": 2023
        },
        {
            "authors": [
                "L. Harding"
            ],
            "title": "a generational shift\u2019: war prompts ukrainians to embrace their language. The Guardian URL: https://www.theguardian.com/world/2023/mar/06/ russia-ukrainians-embrace-language-war",
            "year": 2023
        },
        {
            "authors": [
                "M. Jurgens",
                "I. Helsloot"
            ],
            "title": "The effect of social media on the dynamics of (self) resilience during disasters: A literature review",
            "venue": "Journal of Contingencies and Crisis Management",
            "year": 2018
        },
        {
            "authors": [
                "M.A. Kaufhold",
                "N. Rupp",
                "C. Reuter",
                "M. Habdank"
            ],
            "title": "Mitigating information overload in social media during conflicts and crises: design and evaluation of a cross-platform alerting system",
            "venue": "Behaviour & Information Technology",
            "year": 2020
        },
        {
            "authors": [
                "V. Kulyk"
            ],
            "title": "Shedding russianness, recasting ukrainianness: The post-euromaidan dynamics of ethnonational identifications in ukraine",
            "venue": "Post-Soviet Affairs",
            "year": 2018
        },
        {
            "authors": [
                "D.D. Laitin"
            ],
            "title": "Language conflict and violence: the straw that strengthens the camel\u2019s back",
            "venue": "European Journal of Sociology/Archives Europe\u0301ennes de Sociologie",
            "year": 2000
        },
        {
            "authors": [
                "W. Lamb"
            ],
            "title": "Rebuilding Ukraine will cost at least $349 billion, a new report estimates. The New York Times URL: https://www.nytimes.com/live/2022/09/10/world/ukraine-russia-war# rebuilding-ukraine-349-billion-dollars",
            "year": 2022
        },
        {
            "authors": [
                "J.H. Lee",
                "A.T. Nguyen"
            ],
            "title": "How music fans shape commercial music services: A case study of bts and army",
            "venue": "in: ISMIR,",
            "year": 2020
        },
        {
            "authors": [
                "M. M\u00e4kinen",
                "M. Wangu Kuira"
            ],
            "title": "Social media and postelection crisis in kenya",
            "venue": "The international journal of press/politics",
            "year": 2008
        },
        {
            "authors": [
                "D.R. Marples"
            ],
            "title": "The War in Ukraine\u2019s Donbas: Origins, Contexts, and the Future",
            "year": 2021
        },
        {
            "authors": [
                "C.A. Marshall"
            ],
            "title": "Post-soviet language policy and the language utilization patterns of kyivan youth",
            "venue": "Language Policy",
            "year": 2002
        },
        {
            "authors": [
                "F. Moreno-Fern\u00e1ndez",
                "H.\u00c1. Mella"
            ],
            "title": "Reexamining the international importance of languages",
            "venue": "HCIAS Working Papers on Ibero-America",
            "year": 2022
        },
        {
            "authors": [
                "E. Morozov"
            ],
            "title": "The net delusion: The dark side of Internet freedom. PublicAffairs",
            "year": 2012
        },
        {
            "authors": [
                "M. Mosleh",
                "G. Pennycook",
                "A.A. Arechar",
                "D.G. Rand"
            ],
            "title": "Cognitive reflection correlates with behavior on twitter",
            "venue": "Nature communications",
            "year": 2021
        },
        {
            "authors": [
                "E. 2023-04-26. Panek",
                "C. Hollenbach",
                "J. Yang",
                "T. Rhodes"
            ],
            "title": "The effects of group size and time on",
            "year": 2018
        },
        {
            "authors": [
                "C. Reuter",
                "A.L. Hughes",
                "M.A. Kaufhold"
            ],
            "title": "Social media in crisis management: An evaluation",
            "venue": "Thunderbird International Business Review",
            "year": 2018
        },
        {
            "authors": [
                "V. Sacco",
                "D. Bossio"
            ],
            "title": "Using social media in the news reportage of war & conflict: Opportu",
            "year": 2015
        },
        {
            "authors": [
                "A.M",
                "S. Hasan",
                "S.V. Ukkusuri",
                "M. Cebrian"
            ],
            "title": "Crisis communication patterns in social",
            "venue": "nities and challenges. The journal of media innovations",
            "year": 2018
        },
        {
            "authors": [
                "A. Saroj",
                "S. Pal"
            ],
            "title": "media during hurricane sandy. Transportation research record",
            "year": 2020
        },
        {
            "authors": [
                "I. Stebelsky"
            ],
            "title": "Ethnic self-identification in ukraine, 1989\u20132001: why more ukrainians and fewer",
            "year": 2009
        },
        {
            "authors": [
                "I. Ali"
            ],
            "title": "Pentagon says it continues to see unusual Russian military",
            "venue": "dynamics. The Journal of Politics",
            "year": 2021
        },
        {
            "authors": [
                "A. Wong",
                "S. Ho",
                "O. Olusanya",
                "M.V. Antonini",
                "D. Lyness"
            ],
            "title": "The use of social media and online communications in times of pandemic covid-19",
            "venue": "Journal of the Intensive Care Society",
            "year": 2021
        },
        {
            "authors": [
                "S.N. Wood"
            ],
            "title": "Generalized additive models: an introduction with R. CRC press",
            "year": 2017
        },
        {
            "authors": [
                "S. Wright"
            ],
            "title": "Language policy, the nation and nationalism",
            "venue": "Cambridge University Press. Cambridge Handbooks in Language and Linguistics,",
            "year": 2012
        },
        {
            "authors": [
                "K.C. Yang",
                "O. Varol",
                "P.M. Hui",
                "F. Menczer"
            ],
            "title": "Scalable and generalizable social bot detection through data selection",
            "venue": "in: Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "E. Zhuravskaya",
                "M. Petrova",
                "R. Enikolopov"
            ],
            "title": "Political effects of the internet and social media",
            "venue": "Annual review of economics",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Social media is critically important in today\u2019s society (Saroj and Pal, 2020; Dwivedi et al., 2021; Wong et al., 2021). In recent years, it has played a key role in a number of political shifts and crises (M\u00e4kinen and Wangu Kuira, 2008; Sadri et al., 2018). While social media has been found to amplify all manners of misinformation, propaganda, populism, and xenophobia (Morozov, 2012; Zhuravskaya et al., 2020; Flamino et al., 2023), it can also serve as a mechanism to call for aid and as a source for live updates of major events unfolding (Sacco and Bossio, 2015; Rogstadius et al., 2013; Allcott and Gentzkow, 2017; Kaufhold et al., 2020).\nIn this article, we analyse language use of Ukrainian citizens on social media before and during the Russian invasion of Ukraine (subsequently referred to as war), where after years of tensions and open aggression between Russia and Ukraine (Marples, 2021), on 24th February 2022, Russian forces began to invade and occupy parts of Ukraine (Bigg, 2022). At the time of writing, it has been estimated that the war has led to over 23,000 civilian casualties (OHCHR, 2023) and hundreds of billions of dollars worth of damage (Lamb, 2022; World Bank, 2023). This has caused worldwide unrest, alongside 8.2 million Ukrainian refugees recorded across Europe and 5 million registered for\n\u2217Corresponding author: Daniel Racek, daniel.racek@stat.uni-muenchen.de\nar X\niv :2\n30 5.\n02 77\n0v 3\n[ cs\n.C Y\n] 6\nJ un\ntemporary protection (UNHCR, 2023; Ratten, 2022).\nThe war in Ukraine is also taking place in the digital era, with social media coverage documenting the horrific events in up to real-time. This provides a unique digital trace of many first-hand accounts of the war, as citizens are communicating among each other and to the public. This is generally known as crisis informatics, whereby social media data are utilized before, during, or after emergency events for use cases such as disaster monitoring, management, and prevention (Sacco and Bossio, 2015; Reuter et al., 2018; Jurgens and Helsloot, 2018; Kaufhold et al., 2020; Dwarakanath et al., 2021). Recent studies have demonstrated that tweets can capture events of political violence (Dowd et al., 2020) and can help in monitoring and understanding intra-country conflicts (SteinertThrelkeld et al., 2022).\nIn our work, the language of a tweet is of particular interest. Notably, the use of language is inherently political. Languages can be the cause of conflict (Laitin, 2000) and they are often incorporated in cultural and ethnic identity definition and are the basis for nation building and political change (Smagulova, 2006; Wright, 2012). After the dissolution of the USSR, most post-soviet countries implemented new language laws in order to assert their original native language and build a new nation (Smagulova, 2006; Pavlenko, 2008). In Ukraine, after independence, many people were considering themselves Russians by nationality or Ukrainian with Russian as their main language. With the Law on Languages (1989) and a 10-year plan for a gradual transition back to Ukrainian (1991), the government aimed to reverse those effects, but was only moderately successful in achieving this goal, as census results show (Marshall, 2002; Stebelsky, 2009; Kulyk, 2018). Only more recently, with the Euromaidan protests and the Russian military intervention in Crimea and the Donbas, surveys between 2012 and 2017 show a consistent and substantial shift away from Russian ethnic and linguistic identification towards Ukrainian practice (Kulyk, 2018). Respondents note an increasing engagement with the Ukrainian language and are more supportive of Ukraine as a direct result of the military intervention.\nWe investigate language choice and tweeting activity on Ukrainian social media from January 2020 to November 2022 using over 4 million geo-tagged tweets from more than 62,000 different users. In doing this, we study how Ukrainian citizens (and non-citizens living there) respond to their country being aggressively attacked and invaded by its direct neighbour they share a long history and language with, and how the use of language evolved before and during this war. Our study allows us to follow the same set of users and observe their (change in) behaviour over both the short- and longer-term as the war breaks out and continues to unfold on an individual level. Hence, we are able to comment on recent news articles outlining shifts in language use from Russian to Ukrainian as a direct result of the war (Harding, 2023; Warner, 2022). Moreover, we are able to monitor long-term language trends even before the war without the necessity of relying on small-scale surveys nor the infrequent censuses, of which the last one was conducted in 2001.\nMore specifically, we study overall trends in the number of tweets in the three main languages (Ukrainian, Russian, English) over time. Second, we investigate how these trends translate to users\u2019 individual tweeting activity and if changes result from the in- and outflux of users, common in online communities (Dabbish et al., 2012; Panek et al., 2018; Ransbotham and Kane, 2011), or if they result from users changing their behaviour over time (Davidson et al., 2019; Eichstaedt and Weidman, 2020; Dzogang et al., 2016). We quantify the magnitude of both effects respectively. Third, we study if changes in users\u2019 tweeting activity originate from shifts between languages and quantify the magnitude of these shifts. Fourth and finally, we take a closer look at those users that switch from predominately tweeting in Russian to predominately tweeting in Ukrainian with the outbreak of the war."
        },
        {
            "heading": "2 Results",
            "text": ""
        },
        {
            "heading": "2.1 Data Collection, Cleaning & Processing",
            "text": "We collected tweets from 9th January 2020 to 12th October 2022 using the 1% real-time stream of the Twitter Sample API (Pfeffer et al., 2022). During collection, we filtered the data such that we only gathered tweets containing geo-information using the Filter API. We then manually filtered the dataset to only retain tweets from Ukraine (denoted by the \"UA\" country tag), as common in the literature (Hu and Wang, 2020), and exclude any retweets. Our subsequently conducted sensitivity analysis shows that through this two-stage filtering process, we were able to recover almost geo-tagged tweets from Ukraine during this time period (see section 4.2).\nWe conducted an extensive spam filtering scheme, in which we 1) removed any duplicate tweets, 2) identified and removed potential spam bots by training a bot detection model following Yang et al. (2020), 3) removed users with >100 tweets per day, 4) only kept tweets coming from official Twitter clients or Instagram, and 5) applied additional filtering rules specific to our dataset. This reduced our dataset from originally 4,453,341 tweets (62,712 users) down to 2,845,670 tweets (41,696 users). For an extensive description and rationale see section 4.3.\nUnsurprisingly, social media is popular in Ukraine, particularly among the younger generation, with almost all citizens aged 18-39 in 2021 reporting that they use social media. For Twitter, user statistics are as follows: 18-29 (13% usage), 30-39 (8%), 40-49 (7%), 50+ (1%) (Statista, 2022b). Hence, our subsequent findings are not necessarily applicable to the entire population. However, they still provide valuable insights into the language use of Ukrainians aged 18-49."
        },
        {
            "heading": "2.2 Descriptive Findings",
            "text": "To determine the language of a tweet, in accordance with the literature (Mosleh et al., 2021; Barbieri et al., 2022), we utilize the language field provided by the Twitter API. Ukrainian (35.8%) and Russian (35.4%) tweets are most prevalent in our dataset, followed by English (11.5%). A large proportion of tweets (11.1%) is labeled as \"undefined\", which among others consists of tweets that are too short, contain only hashtags, or only have media links. All other languages have shares of 1.2% or less. For the subsequent analysis we focus on tweets coming from the three main languages (English, Russian, Ukrainian) and discard all remaining tweets. A full breakdown of the language distribution is reported in section 5.1.\nIn our dataset, there are clear trends in the aggregate over time (Figure 1). In the beginning of 2020, we can see that Russian is the predominant language being used on Twitter in Ukraine, however, over time, this number gradually declines. The number of Ukrainian and English tweets on the other hand remains more or less constant over this initial time period. In the figure, we mark two key dates. On 11th November 2021, the United States officially report a mobilization of Russian troops along the Ukrainian border for the first time (Stewart and Ali, 2021; Euronews, 2021; NDTV, 2022). We will subsequently call this the first signs of aggression. 24th February 2022 marks the begin of the Russian invasion of Ukraine (subsequently referred to as outbreak of the war). As we approach this outbreak, there is a clear spike in tweets across all three languages, with a larger spike in both English and Ukrainian. Afterwards, English and Russian remain mostly constant, although the former on a much higher level than before. For Ukrainian, there is a clear upward trend in the daily number of tweets after the outbreak of the war.\nGiven these remarkable shifts in the number of tweets in the three considered languages, we want to investigate the underlying factors contributing to these changes. Note, that from the\naggregate trends, we can not distinguish whether the observed patterns are due to large in- and outfluxes of users, which are common in online communities (Dabbish et al., 2012; Panek et al., 2018; Ransbotham and Kane, 2011), or whether the actively tweeting users change their behaviour over time (Davidson et al., 2019; Eichstaedt and Weidman, 2020; Dzogang et al., 2016). The disentanglement of this question is the aim of the rest of this article."
        },
        {
            "heading": "2.3 User Activity",
            "text": "In order to address this question, we restructure our dataset by aggregating the number of tweets made by each user in English (EN), Ukrainian (UA), and Russian (RU) in each week. (Note, that we employ the Ukrainian country code \"UA\" instead of the official Ukrainian language tag \"UK\" in order to avoid confusion.) This allows us to study users\u2019 individual behaviour over time. To obtain reliable results, we restrict the further analysis to users, who have tweeted in total at least ten times in any of the three languages. Furthermore, we choose weeks instead of days, as we are interested in general shifts and overall changes in behaviour over time, which are captured sufficiently well on a weekly basis. Through this weekly definition, we can dramatically reduce the size of our dataset, hence more complex modelling approaches become computationally feasible. We drop the first and last week in our dataset as these are incomplete (less than 7 days) and aggregate the remaining tweets on a weekly basis for each user and language. Finally within this, we are only considering weeks in which users are \"active\" (we define this as any week in which a user is tweeting at least once, as well as up to two weeks after), in order to account for the times in which users may be inactive for several weeks at a time or abandon their accounts. Thus, our new sample ranges from 13th January 2020 to 10th October 2022 and consists of 143 analysis weeks, 13,643 users and 1,045,245 observations.\nUsing this definition of user activity, we can visualize the total amount of active users as well as turnover rates (switch from active to inactive and vice versa) over time (Figure 2). In the beginning of 2020, we have around 2,800 active users per week. This number gradually decreases\nto roughly 1,800 until we approach the outbreak of the war. Afterwards, the number of active users starts increasing again. Note the drop and subsequent spike in activity shortly before and with the outbreak of the war. Looking at the turnover rates, we find that there is a constant stream of \u223c 250 (potentially different) users per week that switch from active to inactive and vice versa. The aforementioned spikes are also evident in these turnover rates. Finally, we find that there are roughly 50 users per week that join our sample for the first time and about the same amount that leave it altogether. Both of these numbers almost double after the outbreak of the war."
        },
        {
            "heading": "2.4 Tweeting Activity",
            "text": "To obtain a better understanding on how the average active Ukrainian Twitter user changes over time, we visualize the average number of published tweets by a user in each language in Figure 3a. We smooth this average to highlight general trends. From the figure, we can clearly see that there are substantial shifts. Overall, the average number of RU tweets per user decreases constantly over time (from 4.8 to 2.2), the outbreak of the war being no exception. The average number of EN tweets decreases slightly until the war, where we notice a sudden uptick (from 0.5 to 1.9) followed by a steady decline. Meanwhile, the number of UA tweets slowly but steadily rises (from 2.4 to 3.0), with steeper increases after the first signs of aggression in November 2021 and no appearance of slowing down (5.3 at the end).\nBy combining these findings with Figure 2, we can at least partially explain the aggregate trends evident in Figure 1. While the active user sample is shrinking over time, those users that stay (and join) the sample are tweeting more in UA. Hence, there is no decrease in the overall amount of\nUA tweets. We find the exact opposite for RU tweets. As the number of active users is declining, the users that stay active are tweeting less in RU, resulting in the visible decrease of aggregate RU tweets over time. Notably, so far, we do not know, if those changes in the average amount of tweets per user are simply driven by shifts in our active user sample (i.e., are those users that initially tweet a lot in RU leaving over time and this is why we see this decrease in the average?), or, if these changes are (at least partially) driven by behavioural changes in those users that remain active on Twitter (i.e., are the same users tweeting less in RU over time?).\n(a) Average number of tweets. The graphs report a smoothed average of the published number of tweets per user in each week in each language. The shaded area depicts the 95% confidence interval of the smooth fit. The non-smoothed version of the plot is available in supplementary material S.2.\n(b) Sample effects. The graphs report a smoothed average of the random effects of the active users in each week in each language. The shaded area depicts the 95% confidence interval of the smooth fit. The non-smoothed version of the plot is available in supplementary material S.3.\n(c) Behavioural effects. The graphs report the fitted global trend over all users in each week in each language. The shaded area depicts the 95% confidence interval of the fitted effect.\nFigure 3: Changes in the number of tweets per user. (a) visualizes the average number of tweets over time, (b) how sample changes affected the number of tweets, (c) how behavioural changes affected this number. The first vertical line denotes the mobilization of the Russian troops along the Ukrainian border (11th November 2021). The second line denotes the outbreak of the war (24th February 2022).\nWe address this through our tweet model described in section 4.4. We fit a generalized additive\nmixed model (GAMM) to predict the number of tweets made by each user in each language in each week, assuming a Poisson distribution. By incorporating both a smooth global time trend for each language, as well as user-specific random effects for each of the languages, we disentangle sample shifts (random effects) from behavioural changes (global trend). Note, as on most other social media platforms, users have the option to create new accounts, which we cannot match to their prior ones. Hence, some of the behavioural effects might be underestimated and instead accounted for as sample effects.\nFigure 3b visualizes the fitted average sample effects, i.e. the graphs depict how the average time-constant tweeting intensity in our active user sample changes over time due to user turnover. The figure shows, that the average RU tweeting intensity is mostly constant over time until November 2021, where aggression starts. From that point onward, in the span of only a few months, we see a decline of 22% in RU tweets from November 2021 to October 2022 (end of study period), solely attributed to changes in the user sample during that period. For EN, we find somewhat of an opposite effect. Similarly, there are only minor fluctuations until November 2021. But afterwards, there is a sharp increase of 104%. Taking a look at UA, we find a long-term increase of about 37% before the aggression starts. This increase comes to a hold shortly before the war, and significantly speeds up in the weeks after (+97%). All (relative) effect sizes calculated between the most relevant dates in our analysis period (start of study period, first signs of aggression, outbreak of war, end of study period) are reported in Table 1.\nNext, we will investigate behavioural changes using Figure 3c. The graphs depict how the tweeting behaviour of the active users changes throughout the study period, when controlling for the user turnover (sample effects). Starting with RU, we notice that users are tweeting less and less over time. From January 2020 to November 2021, users tweet 51% less in RU due to behavioural changes. Subsequently, we see a small rise with the outbreak of the war (+5%), followed up by an even steeper decline (-24%). In contrast, UA is reasonably consistent in its use up until the start of aggression. From there, we observe a surge (+36%) until the outbreak of the war, followed by a gentler increase (+15%) after. Finally, looking more closely at EN tweeting behaviour, we can observe a general downward trend (-37%) until November 2021. Once the aggression starts, there is a huge spike (+130%), as users are tweeting a lot more in EN. After the outbreak of the war, this somewhat reverses (-40%), however, without dropping back down to pre-aggression levels. A full breakdown of all changes is reported in Table 1.\nOverall, we can conclude that there are only minor sample shifts pre-dating aggression that affected tweeting activity, but major shifts thereafter. In terms of behaviour, we can already see steady changes early on, which significantly intensify with the war. However, as of yet, we cannot exactly pinpoint where those changes come from. Are users that already tweet in UA simply tweeting more with the outbreak of the war, or is it possible that users are actively switching the language they are tweeting in?"
        },
        {
            "heading": "2.5 Choice of Language",
            "text": "We analyze the choice of language more closely in the following. As we are interested in shifts between the individual languages, we look at the pairwise probability to tweet in one language over another over time. Hence, the probability reports how likely it is that a user tweets in language one (e.g. UA) over language two (e.g. EN). With three languages, this pairwise evaluation gives us a total of three different language pairs (UA over RU, UA over EN, RU over EN), where the order in which we specify each pair is irrelevant. Figure 4a visualizes how these pairwise probabilities evolved for an average user over time. For RU over EN the probability is mostly constant (80% to tweet in RU) until aggression starts, from where it continuously drops down to 55%. For UA over EN we see small increases over time (68% to 74%). With the mobilization of the Russian troops, we see a drop (63%), followed by a rise back to pre-aggression levels months into the war. Finally, for UA over RU we see a completely different pattern. Initially, the probability to tweet in UA is low (33%), from where it continues to rise consistently. In the weeks leading up to the war, there is a significant speed up in this shift, resulting in a probability of 77% to tweet in UA over RU towards the end of the analysis period in October 2022.\nSimilarly to before, we can disentangle sample shifts from behavioural changes through statistical modelling. In summary, we fit a GAMM to model users\u2019 pairwise language probability to tweet over time, assuming a binomial distribution. As before, we include a smooth global time trend and user-specific random effects into the model. We fit such a model, for all three aforementioned language-pairs. A full description is provided in section 4.5.\nFigure 4b visualizes the fitted average sample effects across all three models, i.e. the graphs depict how the average time-constant tweeting probabilities in the active user sample change over time. As we are working with coefficients of a logistic regression, changes must be interpreted with respect to changes in the odds. The figure shows that for RU over EN, initially, there are no relevant sample shifts (on average). However, as we approach the outbreak of the war, we can report a large drop in the odds, as users are 64% less likely to tweet in RU over EN than before, with further decreases thereafter (-24%). For UA over EN, we find a small to moderate increase until aggression (+29%) due to sample shifts, followed by a large drop until war outbreak (-58%), which is recovered in the months after (+64%). Finally, for UA over RU, there is a constant increase in the odds over time (+50%), which significantly speeds up once aggression starts (+101% until October 2022). Table 2 details all changes.\nCombining this with the results from the previous section, we can conclude that the user turnover in the first 1.5 years shifts the sample such that users are more likely to tweet in UA (than RU or EN), but not at the expense of either of the two other languages, as tweet levels are (mostly) steady for both. As we approach the outbreak of the war, this drastically changes. Then, the user sample clearly shifts away from RU, as users are instead tweeting more in EN (initially) and UA (long-term). Upon further investigation (supplementary material S.4 and S.5), we find that users tweeting in RU start leaving around November 2021 (start of aggression), with EN users joining. The former continue to leave as the war unfolds, with some of the latter also slowly leaving the sample again over time. This is also reflected in the increase of the UA odds over time (UA over\n(a) Average language probability. The graphs report a smoothed average of the probability to tweet in language one over language two per user in each week for the tree language pairs. The shaded area depicts the 95% confidence interval of the smooth fit. The non-smoothed version of the plot is available in supplementary material S.2.\n(b) Sample effects. The graphs report a smoothed average of the random effects of the active users in each week for all three language pairs (hence for all three language GAMMs). The shaded area depicts the 95% confidence interval of the smooth fit. The non-smoothed version of the plot is available in supplementary material S.3.\n(c) Behavioural effects. The graphs report the fitted global trend over all users in each week for all three language pairs (hence for all three language GAMMs). The shaded area depicts the 95% confidence interval of the fitted effect.\nFigure 4: Changes in the choice of language per user. (a) visualizes the average probability to tweet in one language over another, (b) how sample changes affected the probability, (c) how behavioural changes affected the probability. The first vertical line denotes the mobilization of the Russian troops along the Ukrainian border (11th November 2021). The second line denotes the outbreak of the war (24th February 2022).\nRU consistently, UA over EN as war continues).\nFigure 4c reports behavioural language changes across all three language pairs, when controlling for the user turnover. For RU over EN we see a constant decline in the odds over time (-33% to tweet in RU), which further speeds up once aggression starts (-55%). For UA over EN we see the exact opposite, as over time users are more likely to tweet in UA (+81% in odds). This change reverses with the start of aggression and the outbreak of the war (-40%), but subsequently reaches pre-aggression levels as the war unfolds. Finally, we can see a clear shift from UA to RU even early on (+129%). This switch becomes even more striking with the outbreak of the war, as users are\nactively changing their behaviour such that average user is 250% more likely to tweet in UA over RU in the span of a single year. Table 2 reports all relevant changes.\nConnecting these language shifts with the results on tweeting activity, we find that the initial decline in EN and RU tweeting activity is not limited to monolingual users. Instead, users are actively shifting towards UA, by reducing their amount of RU and EN tweets (with a stronger shift from RU than EN respectively). Similarly, the temporary increase in EN tweeting behaviour leading up to the war can be linked to both UA and RU users. Finally and most importantly, the decline of RU and the rise of UA tweeting behaviour that manifests with the war is strongly driven by a major language shift (2.5x) from RU to UA.\nWe visualize and demonstrate this substantial behavioural language shift from UA to RU in Figure 5. Figure 5a plots the language proportion of each user (UA to RU; from 0 to 1) that tweet in either language before (y-axis) and after the war (x-axis). Hence, along the straight black line through the origin we have users that do not switch language (top right UA, bottom left RU), users above the line switch to RU, below the line to UA, with users switching completely from one language to the other being located in either the top left (all tweets in UA to all in RU) or bottom right corner. Statistically significant (p < 0.05) language shifts from before to after war outbreak for each user are marked. From the figure it becomes evident that there are many users that do not switch language (in both UA and RU), as well as many users clearly switching from RU to UA at various levels, whereas there are only very few switching from UA to RU.\nIn this sample of users who tweet in either RU or UA both before and after the outbreak of the war (3237 users), we have 1363 users who predominately tweet in RU (>80% of tweets) before the war. Of those, 839 (61.6%) tweet more in UA after the war, with 566 (41.5%) reporting a significant behavioural change (p < 0.05). Out of those 850 users, 341 (25%) even switch to predominately tweeting in UA (>80% of tweets), i.e. perform a \"hard-switch\", with 296 (21.7%) statistically significant hard-switches (p < 0.05). We pick those 296 users and plot their weekly language proportion over time in Figure 5b. Red points denote 100% of the tweets being phrased in RU, blue points denote the same in UA. From the figure, we can clearly see a substantial break and change in behaviour around the time the war breaks out (second black line), as most of the users switch from RU to UA around this mark.\nOn Ukrainian side, we have 1172 users who predominately tweet in UA (>80% of tweets) before the war. Of those, 471 (40.2%) tweet more in RU after the war, with only 83 (7.1%) reporting a sig-\n(a) Scatterplot of users\u2019 language proportions before and after the outbreak of the war. We are only considering users who tweet in either RU or UA (or both) before and after (n = 3237). The points are colored with respect to each user\u2019s shift in language (1 denotes a complete shift to UA, -1 a complete shift to RU, 0 no shift). The straight line through the origin covers all points without a shift. Significant shifts (p<0.05) are denoted through full (non-empty) points. Significance was calculated by individually comparing each user\u2019s language proportion through a two-sided z-test before and after war outbreak (24th February 2022). n = 1808 (821 significant) shifts towards Ukrainian, n = 818 (106 significant) shifts towards Russian.\n(b) Scatterplot of users\u2019 language proportion in each week over time. Each row (on the y-axis) denotes one of the n = 295 users with a statistically significant hard-switch from RU to UA. The points are colored with respect to each user\u2019s language proportion in the respective week (145 total weeks). Missing points indicate that a user was not tweeting in the respective week. The first vertical line denotes the mobilization of the Russian troops along the Ukrainian border (11th November 2021). The second line denotes the outbreak of the war (24th February 2022).\nFigure 5: Language proportion scatterplots of users. The language proportion ranges from [0, 1], with 0 being defined as 100% of a user\u2019s tweets being in RU, and 1 as 100% of tweets in UA. Only RU and UA tweets of each user are considered.\nnificant behavioural change (p < 0.05). More importantly, we only observe 35 (3%) hard-switches, out of which 20 (1.7%) are significant (p < 0.05). Hence, there are only very few UA tweeting users for which we can report a significant switch towards RU after the war.\nFinally, we analyze potential differences in those RU users that perform a hard-switch to UA from those that do not. We find that there are significant differences (p < 0.05) in the median in various user characteristics between the two groups. Users switching have more followers (+54.5%), a higher tweet frequency (+47.7%) as well as a higher like frequency (+48.9%) and published more Ukraine geo-tagged tweets during the study period (+49.1%), whereas there are only small nonsignificant differences in account age (+9.7%; p = 0.13) and followings (+13.8%; p = 0.15). For more information and a full breakdown see section 5.2."
        },
        {
            "heading": "3 Discussion",
            "text": "We collected geo-tagged tweets from Ukraine and analyzed tweeting activity and language choice before and during the Russian-Ukrainian War from 9th January 2020 to 12th October 2022. Due to the nature of our longitudinal dataset, in which we observe the same set of users across the study period, we were able to disentangle shifts in the user sample, arising from user turnover, from behavioural changes of the actively tweeting users.\nWe find there is a steady long-term shift away from Russian towards Ukrainian already before the war, as the Ukrainian tweet probability rises substantially (vs. Russian; 33% to 47%). This shift can be largely attributed to behavioural changes. The actively tweeting users reduce their number of Russian tweets in favour of Ukrainian over time. This finding is in line with trends observed over a 20-year period between the 1989 and the last conducted census in 2001 (Stebelsky, 2009) and more recently across surveys (Kulyk, 2018), where the share of people reporting Ukrainian as their native language perpetually rose over time. Notably, with the Euromaidan protests and the subsequent Russian military intervention in 2014, this shift seems to have sped up, as citizens ethnonational identification and everyday language use is substantially shifting towards Ukrainian.\nThe pattern we observe on Ukrainian Twitter is relatively similar. We find a gradual but substantial language shift already pre-war, which drastically accelerates with the start of the Russian aggression in November 2021 and the subsequent outbreak of the war. In the span of a few months, Ukrainian tweet probability rises from 47% to a remarkable 76%. While some of this increase can be explained by Russian tweeting users leaving and Ukrainian users joining (+101% in odds to tweet in Ukrainian), the major factor is a behavioural change (+249% in odds to tweet in Ukrainian), with a rise in Ukrainian (+56%) and a decrease in Russian tweeting activity (-20%). Notably, we show that out of those users predominately tweeting in Russian before the war, roughly half of them tweet more in Ukrainian after. Strikingly, around a quarter of them switch to predominately tweeting in Ukrainian, i.e. performs a hard-switch. It is worth noting, that we do not observe more than a handful of switches in the other direction. This shift from Ukrainian to Russian is in line with recent reports and small-scale surveys outlining the war as the cause for the recent shifts in language use across Ukraine (Harding, 2023; Warner, 2022). Our work confirms these findings on a large-scale on social-media and pinpoints this substantial change exactly to the outbreak of the war.\nRussian users that perform a hard-switch to Ukrainian seem to be more active on Twitter and have a larger follower base, despite the overall number of followers being fairly low (median of 119 vs. 77). Nonetheless, we find these differences to be statistically significant. While these would not be deemed as influencer accounts, their behaviour could be attributed to a form of signalling to their user-base of their opposition to the war.\nFurthermore, we find a long-term behavioural shift away from English tweeting activity up until November 2021. This could be interpreted as a reduction in talking to a broader international audience during that time (Smith, 2015; Christiansen, 2015; Moreno-Fern\u00e1ndez and Mella, 2022), due to the fact that English is the most widely understood language on the internet by far (Statista, 2022a). However, not surprisingly, with the mobilization of the Russian troops along the Ukrainian border and specifically in the weeks leading up to the war, with a spike during outbreak, we observe a substantial shift towards English, as we hypothesize users wanted to let the world know what was happening and called for aid. While we record a large influx of English speaking users during that time, we can also observe a substantial behavioural shift. Already active users tweet substantially more in English, independent of the language they were normally tweeting in. As the war continues to unfold, this somewhat reverses, with some of the newly joined English users leaving and behaviour reverting, although not to pre-aggression levels. With the world being more aware of the situation, and the international community supporting Ukraine in various ways (European Commission, 2023; White House, 2023), we hypothesize users have less reasons to continue tweeting in English. Instead, they return back to intra-national discussions and thus their native language(s).\nWe recognize that our study provides a foundation towards a better understanding on how the Ukrainian population reacted to the Russian invasion both on- and offline. Future work could potentially take a closer look on content and sentiment of tweets through multilingual topic modelling and sentiment analyses. This could be augmented through the use of media objects attached to tweets such as images and videos. An investigation of retweet and follower networks could provide additional information on user characteristics as well as interactions in order to find differences between the users that are shifting language compared to those that are not. Naturally, any analysis could be extended to other social media platforms.\nIn summary, our work investigated tweeting activity and language choice on Ukrainian Twitter before and during the Russian-Ukrainian War through a large-scale longitudinal study. We observe a substantial shift away from the Russian language to Ukrainian, with more than half of the predominately Russian-tweeting users shifting towards Ukrainian, and a quarter of them even performing a hard-switch to Ukrainian, as the war broke out. We may interpret this as citizens\u2019 increasing opposition to Russia and a return to the country\u2019s linguistic roots as well as a push towards a conscious self-definition of being Ukrainian. We deem this a powerful political message to send to a global audience."
        },
        {
            "heading": "4 Methods",
            "text": "This study was ethically approved by the ethics commission of the faculty of mathematics, computer science and statistics at Ludwig-Maximilians-Universit\u00e4t (LMU) M\u00fcnchen, Germany. The reference identifier is EK-MIS-2022-127."
        },
        {
            "heading": "4.1 Data Collection",
            "text": "The original Twitter dataset obtained from the 1% stream consisted of 4,102,982 tweets (see section 2.1 for details). As we began cleaning, we noticed gaps with missing tweets, most likely due to server and internet outages during the real-time data collection process. Hence, we retrospectively identified and filled all gaps. To do this, we first identified all time windows > 10 min without any tweet and added them to our download queue. Days with more than two of such time windows were added to the queue as a whole. We then queried the Twitter Research API 2.0 using the tweets/search/all endpoint to obtain tweets with Ukrainian geoinformation for all time windows in\nthis queue and added the newly obtained tweets to our original dataset. Finally, we repeated this process for the 15 days with the least amount of tweets in our dataset. After removing all duplicates, this meant we added a total of 350,359 additional tweets to our dataset this way. We perform our sensitivity analysis (see section 4.2) after this step. We clean this dataset by removing spam as well as potential spam bots and accounts, as described in section 4.3."
        },
        {
            "heading": "4.2 Sensitivity Analysis",
            "text": "After the collection of tweets as described in section 4.1, we evaluate the completeness of the dataset, i.e. if we were able to recover most of the tweets published in Ukraine during that time, using the following strategy. We draw a random subset of 29 days from our analysis period and draw tweets from the Twitter Research API 2.0 using the tweets/search/all endpoint, which returns all historic tweets that have not been deleted since. We report a coverage of 98.24% (SD: 3.09%). More importantly, in the opposite direction we are only able to report a coverage of 77.67% (SD: 9.55%). Hence, employing our strategy using the real-time stream offers substantially more tweets, which have been deleted since (for more information on tweet deletion and its effects see Pfeffer et al. (2022)). Moreover, this suggests we were able to recover most of the geo-tagged tweets from Ukraine using our strategy."
        },
        {
            "heading": "4.3 Data Cleaning & Pre-processing",
            "text": "For cleaning our dataset, we first train a Twitter bot detection model using a random forest (RF), as described in Yang et al. (2020). We use the exact same model as described in the authors\u2019 work (except for removing the attribute profile_use_background_image, which is no longer available from the Twitter API), using the training datasets botometer-feedback, celebrity, political-bots, as well as 100 manually labelled Twitter accounts from our dataset. To evaluate performance, we first set up a nested cross validation (CV) routine, with both a 5-fold CV in the inner and outer loop. The inner CV is used for hyperparameter tuning, tuning both the number of trees as well as the minimum node size of the RF, whereas the outer loop is used for evaluating model performance. This results in an average area under the receicer operator characteristics curve (AUROC) of 0.9837 and an average area under the precision-recall curve (AUPRC) of 0.7707. For our final model, we replicate this procedure, by setting up a 5-fold CV on the entire dataset to find the best performing hyperparameters. We then train our RF on the entire dataset and use this model to identify bots and spam accounts in our dataset.\nAs we are only interested in removing the most prevalent spam, we opt for a conservative removal strategy to not falsely remove too many real and non-spam users. Hence, we only remove users with a predicted bot probability > 50% and more than 10 tweets since account creation as well as users with a predicted bot probability > 30% and more than 10,000 tweets. While thresholds of 50% and 30% respectively might not seem conservative, in the given setting, in which the bot class is heavily underrepresented (3.7% of observations in training dataset), an F1-optimizing threshold on the training dataset would lie far below that. We are somewhat less conservative with users that published over 10000 tweets, as in most cases they are spam accounts (e.g. related to bitcoins or NFTs). We do to not remove users with less than 11 tweets, as even for a human it becomes incredibly difficult to determine if a user is a bot with such limited amount of information to draw from. At the same time, we noticed a large influx of new users after the outbreak of the war who exclusively called for help in a short span of time, a behaviour which can easily be mistaken for a bot. Notably, we do not tune the optimal classification threshold, as the outbreak of the war in Ukraine represents an unprecedented event, with an unusual amount of new users joining (see section 2.3). Hence, we expect the distribution between the target label (bot or human) and our features to be different between the bot training dataset and our Ukrainian dataset. Unfortunately,\nan extensive manual labelling strategy and more elaborate bot detection is beyond the scope of this work and would warrant its own paper. In summary, with this strategy we remove a total of 2021 users and their tweets from our dataset.\nTo further identify and remove potential spam accounts, we identify all accounts with more than 100 tweets on a single day (the mean is \u223c 4.4 and the median = 2), and remove those 257 users from the dataset. We also noticed an unusual amount of Tweets containing the word \"BTS\" (45,579; referring to the Korean K-Pop band, see Lee and Nguyen (2020) for more information) with spikes on specific days, which we subsequently filter out. Next, we identify and remove any tweets published by the same user that contain the exact same text as their previous tweet if both tweets were published within a one minute window. Fifth and finally, we filter out any tweets with the source attribute not being equal to Instagram or Twitter. That way, we discard any tweets automatically published by social media schedulers such as dlvr, which are often used by news agencies or other companies."
        },
        {
            "heading": "4.4 Tweet Modelling",
            "text": "We define the number of tweets Yt,u,l made in week t by user u in language l. As tweets are count data, we model the Yt,u,l to follow a Poisson distribution with intensity \u03bbt,u,l, where\n\u03bbt,u,l = exp(\u00b5+ sl(t) +Wu,l).\nHere, \u00b5 is a general time-constant intercept, which captures the average tweet intensity over all users, languages and weeks. The Wu,l are language-specific time-constant random intercepts for each user u, assumed to be normally distributed. They capture by how much the average tweeting behaviour (more or less tweets) of each user in each language differs from the general mean \u00b5. Finally, sl(t) denotes a smooth global time trend for each language l (Ukrainian, Russian, English) and captures changes in the tweeting behaviour over all users over time. Hence, with the latter, we can measure behavioural changes of the users over time (e.g. are users tweeting more with the outbreak of the war?), whereas the random intercepts measure changes in the user sample over time (e.g. are users that enter the platform after the war tweeting more on average?). We fit the model with the R package mgcv v1.8.41 (Wood, 2017) using the GAM implementation for very large datasets bam. To speed up the estimation, we use the discrete option, which discretizes covariates to ease storage and increase efficiency. For fitting sl(t), we employ thin plate regression splines. Our estimation sample consists of y = 1,045,245 observations, with t = 143 weeks, l = 3 languages and u = 13,643 users. For our fitted model, we report an explained deviance of 71.3%.\nThe effect sizes in the main text are calculated as follows. For the behavioural effects we derive the change in sl(t) between two respective dates t1 and t2 and take the exp(.), i.e. exp(sl(t2)\u2212sl(t1)) for each language l. The result is the change in expected tweeting activity due to behavioural changes, when controlling for the in- and outflux of users. The sample effects are derived by averaging the random effects of the active users at the two respective dates and taking the exp(.), i.e. exp(W t2,l \u2212W t1,l). We define W t,l as the average random effect in language l over all users u active at time point t. This captures the averaged change in expected tweeting activity due to a change in average tweeting intensity of the active users, when controlling for behavioural changes."
        },
        {
            "heading": "4.5 Language Modelling",
            "text": "To model users\u2019 pairwise language probability, we refrain from a multinomial modelling strategy, as even with a weekly setup our dataset is particularly large. (To the best of our knowledge, a package with a parallel estimation routine for large datasets that can fit a GAMM for a multinomial distribution does not exist.) Instead, we model each pairwise probability separately through a\nbinomial distribution. Our pairwise evaluation gives us a total of three different language pairs (UA over RU, UA over EN, RU over EN), for which we model the probability \u03c0 to tweet in language one (subsequently l1) over language two (subsequently l2). The order in which we specify these pairs is irrelevant, as the probability to tweet in l2 over l1 is simply 1\u2212 \u03c0. More specifically, we define Xt,u as the number of tweets made in week t by user u in l1. We assume Xt,u \u223c Binomial(nt,u, \u03c0t,u), where nt,u denotes the total number of tweets made by user u in week t (sum of tweets in l1 and l2) and \u03c0t,u corresponds to the probability to tweet in l1 over l2. We assume that nt,u is known and instead model \u03c0t,u by setting\n\u03c0t,u = f(\u00b5+ s(t) +Wu),\nwhere f(.) is defined as the logistic function. Similarly to before, \u00b5 is a general time-constant intercept, which captures the average mean probability over all users and weeks to tweet in l1 over l2. Again, the Wu are time-constant random intercepts for each user u that capture by how much the average probability differs from the general mean \u00b5, and are assumed to be normally distributed. The smooth global time trend s(t) captures changes in the probability over all users over time. Hence, as before, we can measure behavioural changes of the users over time with the latter (are users actively changing the language they are tweeting in?), whereas the random intercepts measure changes in the sample over time (how does the language probability of users entering/leaving the platform evolve?). We estimate this model specification for all three aforementioned languagepairs with the R package mgcv v1.8.41 (Wood, 2017) using the GAM implementation for very large datasets bam. To speed up the estimation, we use the discrete option, which discretizes covariates to ease storage and increase efficiency. For fitting s(t), we employ thin plate regression splines. Users not tweeting in either of the two languages of the respective language pair, need to be discarded by definition. Hence, for UA over RU our estimation sample consists of of x = 194,178 observations, with t = 143 weeks and u = 10,531 users. For UA over EN: x = 146,984, t = 143, u = 9,133. For RU over EN: x = 170,853, t = 143, u = 10777. For our fitted models, we report explained deviances of: 85.8% (UA over RU), 90.5% (UA over EN) and 90% (RU over EN).\nThe coefficients of a logistic regression, as employed here, must be interpreted with respect to changes in the odds (also known as odds ratio). The odds ratio is defined as odds = p/(1 \u2212 p). Hence, it describes how likely an event is going to happen compared to not happen. In this setting, it describes how likely it is to tweet in language 1 over language 2.\nThe effect sizes in the main text are calculated as follows. For the behavioural effects we derive the change in s(t) between two respective dates t1 and t2 and take the exp(.), i.e. exp(s(t2)\u2212s(t1)) for each of the three models. The result is the change in odds to tweet in l1 over l2 due to behavioural changes, when controlling for the in- and outflux of users. The sample effects are derived by averaging the random effects of the active users at the two respective dates and taking the exp(.), i.e. exp(W t2 \u2212W t1) for each of the three models. We define W t as the average random effect over all users u active at time point t. This captures the averaged change in odds due to a change in average tweeting probability of the active users, when controlling for behavioural changes."
        },
        {
            "heading": "5 Extended Data",
            "text": ""
        },
        {
            "heading": "5.1 Language Distribution",
            "text": ""
        },
        {
            "heading": "5.2 Differences in User Characteristics for Russian Users",
            "text": "We evaluate differences in user characteristics between the 1,363 user who predominately tweet in Russian (>80% of tweets) with respect to their language shift with the outbreak of the war in Table 3. Column 2 reports the median of the respective user characteristic for those 1067 Russian users that do not perform a statistically significant (p < 0.05) hard-switch to Ukrainian (>80% of tweets) with the outbreak of the war, column 3 for the 296 users that do. To determine significance, we employ a two-sided z-test on each user\u2019s language proportion (% tweets in UA) before and after the outbreak of the war. Column 4 reports the relative difference from the switch group to the no switch group, with bold values indicating significant differences between the two groups (p < 0.05). Column 5 reports the p-value of the two-sided statistical significance test on the difference in median between the two groups using a chi-squared test. Column 6 the chi-squared statistic.\nFunding Statement\nThis work is supported by the Helmholtz Association under the joint research school \u201cMunich School for Data Science - MUDS\u201d. This work is also supported by the European Research Council (ERC) under the European Union\u2019s Horizon 2020 research and innovation programme (grant agreement No. [ERC-2016-StG-714087], Acronym: So2Sat)"
        }
    ],
    "title": "The Politics of Language Choice: How the Russian-Ukrainian War Influences Ukrainians\u2019 Language Use on Twitter",
    "year": 2023
}