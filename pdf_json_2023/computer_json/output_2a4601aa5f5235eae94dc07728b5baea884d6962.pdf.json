{
    "abstractText": "DAIRUI LIU, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Ireland DEREK GREENE, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Ireland IRENE LI, Information Technology Center, University of Tokyo, Japan XUEFEI JIANG, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Ireland RUIHAI DONG, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Ireland",
    "authors": [
        {
            "affiliations": [],
            "name": "DAIRUI LIU"
        },
        {
            "affiliations": [],
            "name": "IRENE LI"
        },
        {
            "affiliations": [],
            "name": "XUEFEI JIANG"
        },
        {
            "affiliations": [],
            "name": "RUIHAI DONG"
        }
    ],
    "id": "SP:d9f523a8bfe1b24ca6aed3b022917208df47c996",
    "references": [
        {
            "authors": [
                "Gediminas Adomavicius",
                "Alexander Tuzhilin"
            ],
            "title": "Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions",
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "year": 2005
        },
        {
            "authors": [
                "Mingxiao An",
                "Fangzhao Wu",
                "Chuhan Wu",
                "Kun Zhang",
                "Zheng Liu",
                "Xing Xie"
            ],
            "title": "Neural News Recommendation with Long- and Short-term User Representations",
            "year": 2019
        },
        {
            "authors": [
                "Dzmitry Bahdanau",
                "Kyunghyun Cho",
                "Yoshua Bengio"
            ],
            "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
            "year": 2015
        },
        {
            "authors": [
                "David M Blei",
                "Andrew Y Ng",
                "Michael I Jordan"
            ],
            "title": "Latent dirichlet allocation",
            "venue": "The Journal of machine Learning research",
            "year": 2003
        },
        {
            "authors": [
                "Gerlof Bouma"
            ],
            "title": "Normalized (pointwise) mutual information in collocation extraction",
            "year": 2009
        },
        {
            "authors": [
                "Chong Chen",
                "Min Zhang",
                "Yiqun Liu",
                "Shaoping Ma"
            ],
            "title": "Neural Attentional Rating Regression with Review-level Explanations",
            "venue": "In Proceedings of the 2018 World Wide Web Conference on World Wide Web, WWW 2018",
            "year": 2018
        },
        {
            "authors": [
                "Kyunghyun Cho",
                "Bart van Merrienboer",
                "\u00c7aglar G\u00fcl\u00e7ehre",
                "Dzmitry Bahdanau",
                "Fethi Bougares",
                "Holger Schwenk",
                "Yoshua Bengio"
            ],
            "title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation",
            "venue": "In Conference on Empirical Methods in Natural Language Processing",
            "year": 2014
        },
        {
            "authors": [
                "Abhinandan S. Das",
                "Mayur Datar",
                "Ashutosh Garg",
                "Shyam Rajaram"
            ],
            "title": "Google news personalization: scalable online collaborative filtering",
            "venue": "In Proceedings of the 16th international conference on World Wide Web",
            "year": 2007
        },
        {
            "authors": [
                "Emma de Koning",
                "Frederik Hogenboom",
                "Flavius Frasincar"
            ],
            "title": "News Recommendation with CF-IDF+",
            "venue": "In CAiSE",
            "year": 2018
        },
        {
            "authors": [
                "Frank Goossen",
                "Wouter IJntema",
                "Flavius Frasincar",
                "Frederik Hogenboom",
                "Uzay Kaymak"
            ],
            "title": "News personalization using the CF-IDF semantic recommender",
            "venue": "In Proceedings of the International Conference on Web Intelligence, Mining and Semantics",
            "year": 2011
        },
        {
            "authors": [
                "Zhiqiang Guo",
                "Guohui Li",
                "Jianjun Li",
                "Huaicong Chen"
            ],
            "title": "TopicVAE: Topic-aware Disentanglement Representation Learning for Enhanced Recommendation",
            "venue": "In MM \u201922: The 30th ACM International Conference on Multimedia",
            "year": 2022
        },
        {
            "authors": [
                "Po-Sen Huang",
                "Xiaodong He",
                "Jianfeng Gao",
                "Li Deng",
                "Alex Acero",
                "Larry Heck"
            ],
            "title": "Learning deep structured semantic models for web search using clickthrough data",
            "venue": "In Conference on Information and Knowledge Management",
            "year": 2013
        },
        {
            "authors": [
                "Alon Jacovi",
                "Yoav Goldberg"
            ],
            "title": "Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness",
            "year": 2020
        },
        {
            "authors": [
                "Sarthak Jain",
                "Byron C. Wallace"
            ],
            "title": "Attention is not Explanation",
            "venue": "Association for Computational Linguistics,",
            "year": 2019
        },
        {
            "authors": [
                "Guoliang Ji",
                "Shizhu He",
                "Liheng Xu",
                "Kang Liu",
                "Jun Zhao"
            ],
            "title": "Knowledge Graph Embedding via Dynamic Mapping Matrix. In Proceedings of the 53rd annual meeting of the association for computational linguistics and the 7th international joint conference on natural language processing (volume 1: Long papers)",
            "year": 2015
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A Method for Stochastic Optimization",
            "venue": "CoRR abs/1412.6980",
            "year": 2014
        },
        {
            "authors": [
                "Vineet Kumar",
                "Dhruv Khattar",
                "Shashank Gupta",
                "Manish Gupta",
                "Vasudeva Varma"
            ],
            "title": "Deep Neural Architecture for News Recommendation",
            "venue": "In CLEF (Working Notes)",
            "year": 2017
        },
        {
            "authors": [
                "Vaibhav Kumar",
                "Dhruv Khattar",
                "Shashank Gupta",
                "Vasudeva Varma"
            ],
            "title": "Word Semantics Based 3-D Convolutional Neural Networks for News Recommendation",
            "venue": "In IEEE International Conference on Data Mining Workshops (ICDMW)",
            "year": 2017
        },
        {
            "authors": [
                "Xuan Nhat Lam",
                "Thuc Vu",
                "Trong Duc Le",
                "Anh Duc Duong"
            ],
            "title": "Addressing cold-start problem in recommendation systems",
            "venue": "In Proceedings of the 2nd international conference on Ubiquitous information management and communication",
            "year": 2008
        },
        {
            "authors": [
                "Jey Han Lau",
                "David Newman",
                "Timothy Baldwin"
            ],
            "title": "Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality",
            "venue": "In Conference of the European Chapter of the Association for Computational Linguistics. Topic-Centric Explanations for News Recommendation",
            "year": 2014
        },
        {
            "authors": [
                "Dairui Liu",
                "Derek Greene",
                "Ruihai Dong"
            ],
            "title": "A Novel Perspective to Look At Attention: Bi-level Attention-based Explainable Topic Modeling for News Classification. In Findings of the Association for Computational Linguistics: ACL 2022",
            "year": 2022
        },
        {
            "authors": [
                "Danyang Liu",
                "Jianxun Lian",
                "Zheng Liu",
                "Xiting Wang",
                "Guang zhong Sun",
                "Xing Xie"
            ],
            "title": "Reinforced Anchor Knowledge Graph Generation for News Recommendation Reasoning",
            "venue": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining",
            "year": 2021
        },
        {
            "authors": [
                "Danyang Liu",
                "Jianxun Lian",
                "Shiyin Wang",
                "Ying Qiao",
                "Jiun-Hung Chen",
                "Guangzhong Sun",
                "Xing Xie"
            ],
            "title": "KRED: Knowledge-Aware Document Representation for News Recommendations",
            "venue": "arXiv: Information Retrieval",
            "year": 2019
        },
        {
            "authors": [
                "Yichao Lu",
                "Ruihai Dong",
                "Barry Smyth"
            ],
            "title": "Coevolutionary Recommendation Model: Mutual Learning between Ratings and Reviews",
            "venue": "In Proceedings of the 2018 World Wide Web Conference on World Wide Web, WWW 2018",
            "year": 2018
        },
        {
            "authors": [
                "Julian J. McAuley",
                "Jure Leskovec"
            ],
            "title": "Hidden factors and hidden topics: understanding rating dimensions with review text",
            "venue": "In Proceedings of the 7th ACM conference on Recommender systems,",
            "year": 2013
        },
        {
            "authors": [
                "Derek O\u2019Callaghan",
                "Derek Greene",
                "Joe Carthy",
                "P\u00e1draig Cunningham"
            ],
            "title": "An analysis of the coherence of descriptors in topic modeling",
            "venue": "Expert Systems with Applications",
            "year": 2015
        },
        {
            "authors": [
                "Shumpei Okura",
                "Yukihiro Tagami",
                "Shingo Ono",
                "Akira Tajima"
            ],
            "title": "Embedding-based News Recommendation for Millions of Users",
            "venue": "In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining",
            "year": 2017
        },
        {
            "authors": [
                "Madhur Panwar",
                "Shashank Shailabh",
                "Milan Aggarwal",
                "Balaji Krishnamurthy"
            ],
            "title": "TAN-NTM: Topic Attention Networks for Neural Topic Modeling",
            "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021,",
            "year": 2021
        },
        {
            "authors": [
                "Jeffrey Pennington",
                "Richard Socher",
                "Christopher Manning"
            ],
            "title": "GloVe: Global Vectors for Word Representation",
            "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics,",
            "year": 2014
        },
        {
            "authors": [
                "Tao Qi",
                "Fangzhao Wu",
                "Chuhan Wu",
                "Yongfeng Huang",
                "Xing Xie"
            ],
            "title": "Privacy-Preserving News Recommendation Model Learning",
            "venue": "arXiv: Information Retrieval",
            "year": 2020
        },
        {
            "authors": [
                "Shaina Raza",
                "Chen Ding"
            ],
            "title": "News recommender system: a review of recent progress, challenges, and opportunities",
            "venue": "Artificial Intelligence Review",
            "year": 2021
        },
        {
            "authors": [
                "Gerard Salton",
                "Anita Wong",
                "Chung-Shu Yang"
            ],
            "title": "A vector space model for automatic indexing",
            "venue": "Commun. ACM 18,",
            "year": 1975
        },
        {
            "authors": [
                "Sungyong Seo",
                "Jing Huang",
                "Hao Yang",
                "Yan Liu"
            ],
            "title": "Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction",
            "venue": "In Proceedings of the Eleventh ACM Conference on Recommender Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Nitish Srivastava",
                "Geoffrey E. Hinton",
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Ruslan Salakhutdinov"
            ],
            "title": "Dropout: a simple way to prevent neural networks from overfitting",
            "venue": "J. Mach. Learn. Res",
            "year": 2014
        },
        {
            "authors": [
                "Maartje ter Hoeve",
                "Anne Schuth",
                "Daan Odijk",
                "M. de Rijke"
            ],
            "title": "Faithfully Explaining Rankings in a News Recommender System",
            "year": 2018
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "In Advances in neural information processing systems",
            "year": 2017
        },
        {
            "authors": [
                "Hongwei Wang",
                "Fuzheng Zhang",
                "Xing Xie",
                "Minyi Guo"
            ],
            "title": "DKN: Deep Knowledge-Aware Network for News Recommendation",
            "venue": "Proceedings of the 2018 World Wide Web Conference",
            "year": 2018
        },
        {
            "authors": [
                "Chuhan Wu",
                "Fangzhao Wu",
                "Mingxiao An",
                "Jianqiang Huang",
                "Yongfeng Huang",
                "Xing Xie"
            ],
            "title": "Neural News Recommendation with Attentive Multi-View Learning",
            "venue": "arXiv: Computation and Language",
            "year": 2019
        },
        {
            "authors": [
                "Chuhan Wu",
                "Fangzhao Wu",
                "Mingxiao An",
                "Jianqiang Huang",
                "Yongfeng Huang",
                "Xing Xie"
            ],
            "title": "NPA: Neural News Recommendation with Personalized Attention",
            "venue": "In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining",
            "year": 2019
        },
        {
            "authors": [
                "Chuhan Wu",
                "Fangzhao Wu",
                "Suyu Ge",
                "Tao Qi",
                "Yongfeng Huang",
                "Xing Xie"
            ],
            "title": "Neural News Recommendation with Multi-Head Self-Attention. In Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)",
            "year": 2019
        },
        {
            "authors": [
                "Chuhan Wu",
                "Fangzhao Wu",
                "Yongfeng Huang"
            ],
            "title": "Personalized News Recommendation: A Survey",
            "venue": "ArXiv abs/2106.08934",
            "year": 2021
        },
        {
            "authors": [
                "Fangzhao Wu",
                "Ying Qiao",
                "Jiun-Hung Chen",
                "Chuhan Wu",
                "Tao Qi",
                "Jianxun Lian",
                "Danyang Liu",
                "Xing Xie",
                "Jianfeng Gao",
                "Winnie Wu",
                "Ming Zhou"
            ],
            "title": "MIND: A Large-scale Dataset for News Recommendation",
            "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Libing Wu",
                "Cong Quan",
                "Chenliang Li",
                "Qian Wang",
                "Bolong Zheng",
                "Xiangyang Luo"
            ],
            "title": "A Context-Aware User-Item Representation Learning for Item Recommendation",
            "venue": "ACM Trans. Inf. Syst. 37,",
            "year": 2019
        },
        {
            "authors": [
                "Yao Wu",
                "Martin Ester"
            ],
            "title": "FLAME: A Probabilistic Model Combining Aspect Based Opinion Mining and Collaborative Filtering",
            "venue": "In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,",
            "year": 2015
        },
        {
            "authors": [
                "Mingwei Zhang",
                "Guiping Wang",
                "Lanlan Ren",
                "Jianxin Li",
                "Ke Deng",
                "Bin Zhang"
            ],
            "title": "METoNR: A meta explanation triplet oriented news recommendation model",
            "venue": "Knowl. Based Syst",
            "year": 2022
        },
        {
            "authors": [
                "Yongfeng Zhang",
                "Xu Chen"
            ],
            "title": "Explainable Recommendation: A Survey and New Perspectives",
            "venue": "Found. Trends Inf. Retr",
            "year": 2020
        },
        {
            "authors": [
                "Kaiqi Zhao",
                "Gao Cong",
                "Quan Yuan",
                "Kenny Q. Zhu"
            ],
            "title": "SAR: A sentiment-aspect-region model for user preference analysis in geo-tagged reviews",
            "venue": "In 31st IEEE International Conference on Data Engineering,",
            "year": 2015
        },
        {
            "authors": [
                "Qiannan Zhu",
                "Xiaofei Zhou",
                "Zeliang Song",
                "Jianlong Tan",
                "Li Guo"
            ],
            "title": "DAN: Deep Attention Neural Network for News Recommendation",
            "venue": "In National Conference on Artificial Intelligence",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Topic-Centric Explanations for News Recommendation\nDAIRUI LIU, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Ireland\nDEREK GREENE, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Ireland\nIRENE LI, Information Technology Center, University of Tokyo, Japan\nXUEFEI JIANG, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Ireland\nRUIHAI DONG, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Ireland\nNews recommender systems (NRS) have been widely applied for online news websites to help users find relevant articles based on their interests. Recent methods have demonstrated considerable success in terms of recommendation performance. However, the lack of explanation for these recommendations can lead to mistrust among users and lack of acceptance of recommendations. To address this issue, we propose a new explainable news model to construct a topic-aware explainable recommendation approach that can both accurately identify relevant articles and explain why they have been recommended, using information from associated topics. Additionally, our model incorporates two coherence metrics applied to assess topic quality, providing measure of the interpretability of these explanations. The results of our experiments on the MIND dataset indicate that the proposed explainable NRS outperforms several other baseline systems, while it is also capable of producing interpretable topics compared to those generated by a classical LDA topic model. Furthermore, we present a case study through a real-world example showcasing the usefulness of our NRS for generating explanations.\nCCS Concepts: \u2022 Information systems \u2192 Recommender systems; Document topic models.\nAdditional Key Words and Phrases: News Recommender Systems, Topic-Centric Explanations"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "With the development of online news services, such as Google News, millions of users can acquire news information from convenient platforms, rather than directly from traditional media sources. However, it can be difficult for users to browse all available sources in order to find relevant articles which match their specific interests. This has motivated the development of personalized news recommender systems (NRS), which aim to identify relevant news articles based on the personal interests of a given user. These recommendations can improve users\u2019 experience and save time when finding interesting news. This has led to considerable work [2, 30, 40\u201343, 51] focused specifically on improving the recommendation performance of these systems. However, the provision of explanations for news recommendations has rarely been considered by researchers. This deficiency can lead to many problems [49]: 1) users may not trust results provided by the system for poor recommendations, since they are not aware of recommendation reasons; 2) the system may be less effective in persuading users to accept results; 3) this may further decrease the system\u2019s trustworthiness. Thus, providing explanation is critical in helping users to understand why corresponding news items have been presented to them by a NRS. Providing explanation can also be helpful for the system designer, allowing them to understand situations where the news recommendation process fails. The faithfulness of the generated explanations is particularly important in this context [15, 38]. In summary, an effectively explainable NRS, which is generally based on a standard NRS, should accurately recommend news and explain those recommendations simultaneously.\nAuthors\u2019 addresses: Dairui Liu, dairui.liu@ucdconnect.ie, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Dublin, Ireland; Derek Greene, derek.greene@ucd.ie, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Dublin, Ireland; Irene Li, ireneli@ds.itc.u-tokyo.ac.jp, Information Technology Center, University of Tokyo, Tokyo, Japan; Xuefei Jiang, xuefei.jiang@ucdconnect.ie, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Dublin, Ireland; Ruihai Dong, ruihai.dong@ucd.ie, Insight Centre for Data Analytics, School of Computer Science, University College Dublin, Dublin, Ireland.\n1\nar X\niv :2\n30 6.\n07 50\n6v 2\n[ cs\n.I R\n] 6\nO ct\n2 02\n3\nThe workflow of a standard personalized NRS involves several key steps [44]. The first step is to recall a small set of candidate articles from a large-scale news pool when a user visits the news platform. The recommender will then rank these candidate articles according to the user\u2019s interests, as encoded in their individual profile. Subsequently, the system will display the top-\ud835\udc58 ranked articles to the user and records their behavior at last, which can be used for future recommendations. The NRS usually has no explicit user interest data (e.g. rating scores), so only implicit feedback (e.g. clicks) will be available to the system. Among these steps, the recommender is the core component of a standard NRS (see Fig. 1). This involves encoding the textual content of news and the corresponding user profile (e.g. history of clicked news) separately. News content modeling is important when attempting to build a high-performance NRS because clicked news articles usually reflect a user\u2019s interests. The predictions are generated through the collaborative contribution of user embedding and news embedding. However, the operation of the prediction process with a standard recommender is difficult to understand because the factors affecting the prediction are unclear. Thus, an intuitive approach to solve the problem is to identify the most critical factors determining whether the user will click on an article, which can lead to several benefits: 1) it can help the system designer to understand the underlying reasons behind the user\u2019s behavior, thereby allowing them to improve the recommendation process; 2) by presenting a transparent recommendation result to users, it can increase their trust and encourage them to accept the recommended news articles; 3) a more explainable system can lead to a better user experience, which helps build a trustworthy system.\nIt is worth noting that news articles usually contain rich textual metadata, such as title, abstract, and body content, which can be leveraged as a valuable resource for providing explanations. In this work, we not only process news articles for recommendations, but also extract topics from them to interpret generated news embedding as shown in Fig 1 to build an explainable NRS. In Fig 2, we see an example of the clicked news history from a random user from the real-world MIND dataset [45], which demonstrates the latent topics of the user\u2019s interests. The category is marked by the row color, while the topic indicators are highlighted by the font color. The selected user appears to have a broad range of interests, but is perhaps most interested in travel news. Thus, the user has a high probability of clicking on an article from the \"travel\" category. However, explaining recommendations using fixed category information might lack nuance and flexibility since a high-level news category will generally consist of many sub-topics which might evolve over time. Thus, discovering topics in the news corpus and employing them as explanations is a core objective of our explainable NRS.\nNews content can be accurately encoded with the help of existing methods, such as the multi-head self-attention mechanism [43] or convolutional neural networks [2]. However, these methods are not explainable. Therefore we\npropose to embed an explainable news model [23] that can extract explainable topics when encoding news content. Specifically, we aim to provide explanations generated in a topic-centric manner, which differs from general explanations of recommendations [49]. Compared to previous studies [24, 38, 48] on NRS explainability research, we generate explanations from a large news corpus with specific topic indicators, instead of simply providing a high-level category name. The key aspects of our work are as follows:\n\u2022 Most existing news recommendation system studies [2, 41\u201343] focus on improving recommendation performance, while ignoring the interpretability of models and explanations about recommendations. Therefore, we propose to use an interpretable news encoding model\u2013Bi-level Attention-based Topical Model(BATM) [23] to learn an explainable news representation. Thus, we extract attention weights from multiple attention networks during the news modeling and user modeling procedure to generate topic-aware explanations. We achieve state-of-the-art performance on recommendation when compared with selected baselines, while also discovering interpretable topics from the news corpus. \u2022 Although some researchers have presented visual explanations for recommendations to support model transparency, such work did not measure the interpretability of the model [41, 42]. In other words, some case studies were provided to show interpretability, but missing quantitative evaluation metrics were not considered by the authors. Thus, we propose to use quantitative topic coherence metrics [22, 29] to evaluate the quality of topics extracted by our model, which reflects the interpretability of these explanations. Although our primary goal is around explanation rather than topic modeling, our experimental results show that we can often generate high-quality topics comparable to those generated by a standard LDA topic model [4].\nThe remainder of this paper is organized into three parts: related work, methodology, and experimental results. Due to the lack of previous work around explainable NRS, we mainly concentrate on reviewing news recommendation methods in general in Section 2.1, with a short review of explainable methods in Section 2.2. We compare the recommendation performance of our explainable NRS with several baselines in Section 4.3. In addition to evaluating recommendation performance, we use two topic coherence metrics to assess the extracted topics and compare them with a standard topic model in Section 4.4. Finally, in Section 4.5 we present a case study showing the kinds of explanations generated by our approach for real recommendations. The source code associated with this work will be made available online1.\n1https://github.com/Ruixinhua/ExplainedNRS"
        },
        {
            "heading": "2 RELATEDWORK",
            "text": "News recommendation, based on the personal interests of each user, is an active research area. Most researchers focus on the improvement of the performance of news recommendation systems, while few works consider recommendation explanations. In this section, we first introduce several popular approaches for news recommendation in Section 2.1. We then discuss explainable methods for the recommendation task involving text data in Section 2.2."
        },
        {
            "heading": "2.1 News Recommendation Methods",
            "text": "Recommendation methods can be categorized into three broad branches: collaborative filtering (CF), content-based filtering (CBF), and hybrid methods [1]. The CF approach makes predictions primarily based on the interaction between users and news, without knowing the news features in advance. However, this method often suffers from a severe cold start problem [21]. CBF methods can address this problem by introducing the content associated with users and news, which is our primary research focus. Since it is often easier for researchers to solve a problem in news recommendations using CBF methods, they have become particularly popular in recent years. Many researchers have demonstrated that CBF is usually more effective than a pure CF method [34]. Deep learning (DL) models have gradually become predominant in this area because of their performance when dealing with content-based news recommendation [34]. Thus, with the success of DL-based CBF, we have looked at research works that share a similar technical paradigm [44], including news modeling, user modeling, and news ranking procedures. Most recent studies [2, 40\u201343] have proven the effectiveness of the recommendation paradigm for modeling news and user representation separately. Next, we discuss successful methods for modeling news and user representation, some of which will provide baselines for our experiments.\n2.1.1 News Modeling. The main goal of news modeling is to comprehend the characteristics and content of news, which is the core problem of the news recommender system. Due to the short lifespan of news items, the performance of CF methods [9] which only represent news articles by their IDs, is usually sub-optimal compared to CBF methods. Thus, we only focus on CBF news modeling methods, incorporating content features to represent news. These methods have traditionally extracted content-based features from the text of articles to construct a vector space model (VSM) representation [35]. Some approaches use handcrafted features, such as the concept frequency-inverse document frequency (CF-IDF) [12] and CF-IDF+ [10] models which extend standard TF-IDF term weighting schemes. However, these manually-designed methods usually require much effort and domain knowledge, which is also not optimal in understanding the semantic information among news texts.\nTo better encode the semantic meaning of news article content, dense embedding-based representations have been proposed as an alternative to sparse VSM models [28]. Such modern models in natural language processing (NLP) can be helpful when encoding news content for recommendations. For instance, researchers have proposed an embedding-based news recommendation (EBNR) method [30], based on a variant of a de-noising autoencoder to learn representations from article texts. Other embedding-based methods, such as the deep structured semantic model (DSSM) [14], have applied a deep neural network (DNN) on existing embeddings to learn hidden news representations. However, most recent studies use the popular word2vec embedding method [28] for constructing dense vectors to represent the words appearing in news articles. These embedding-based models use simple DNNs to model news text, but can sometimes fail to capture contextual information accurately. Thus, some researchers have employed more complex neural networks, like a 3-D convolutional neural network (CNN) [20] or a knowledge-aware CNN (KCNN) [40], to mine deep semantic relationship. For instance, DKN [40] attempts to discover latent knowledge-level connections from news article titles by\nusing a word-entity-aligned KCNN to learn a knowledge-enhanced news representation. This method also incorporates a knowledge graph (KG) to encode entities using KG embedding algorithms such as TransD [17]. Similarly, other methods also enhance news modeling by involving more CNNs, such as DAN [51], which adopts a combination of two parallel CNNs, built from news titles and named entities, respectively.\nWhile these CNN-based methods can effectively learn contextual representations for news items, they are often not good at capturing and highlighting informative words because of the difference in news content informativeness. Thus, some authors have introduced attention mechanisms [3, 39] to address the problem. For example, NPA [42] uses a personalized word-level attention-based CNN to learn attentive news representations. Similar to NPA, LSTUR [2] and NAML [41] both learn a combined representation of multiple news-related metadata, including titles, categories, subcategories, and news body content through CNNs and attention networks. Here category and subcategory embeddings provide multi-view information to provide a better understanding of news content. Further studies employ advanced attention models like NRMS [43] and FedRec [33] because of the effectiveness of attention mechanisms. NRMS [43] uses a multi-head self-attention (MHSA) network to capture word-level relations and applies another additive attention network to learn informative news representations. FedRec [33] utilizes a news encoder with a combination of CNN, MHSA, and additive attention network to form a comprehensive representation of article titles.\n2.1.2 User Modeling. During the recommendation task, it is also essential to understand a user\u2019s interests from their profile, which usually consists of the history of their click behavior. Thus, user modeling is typically determined by modeling interactions, such as by inferring a user\u2019s interests from the sequence of their clicks. For example, EBNR [30] considers a variant of the recurrent neural network (RNN)\u2013gated recurrent unit (GRU) network, to generate user representations with history sequences. Similarly, RA-DSSM [19] adopts an attention-based bi-directional long shortterm memory (Bi-LSTM, another variant of RNN) network to capture changing and diverse user interests. Moreover, LSTUR [2] applies a GRU network and ID embeddings for short-term and long-term user interest modeling respectively.\nIn contrast, other methods like NAML [41] and KRED [25] only deal with the click sequences using a news-level attention network, which does not significantly affect the performance of recommendations. Similarly, DKN [40] uses a candidate-aware attention network to form user representation by the relevance of clicked news and candidate news. And NPA [42] considers using a personalized attention network with ID embeddings involved for user representation learning. Also, DAN [51] employs the combination of attentive LSTM and candidate-aware attention network for user interest modeling. Moreover, NRMS [43] uses a more complex attention model, which is composed of a multi-head self-attention network and an additive attention network to learn contextual user representations."
        },
        {
            "heading": "2.2 Explainable Methods",
            "text": "Explainable recommenders aim to provide explanations for the recommendations they produce to indicate why a particular news item is being suggested to a user [49]. In recent years, with the success of deep learning, some models (i.e., NAML) have achieved impressive performance on news recommendations. However, these models are normally considered as a black box [2, 30, 40\u201343, 51], making their outputs difficult to understand. Thus, we focus on explainable methods from the perspective of models themselves when making recommendations using text data.\nOne intuitive way to provide explanations is to look at attention scores. For example, the work by Seo et al. [36] applies a CNN to model review texts, and this method can show which part of the given review is more important for the output, based on attention scores. Similarly, some studies [26, 46] also consider the attention score over review words to explain recommendations. Chen et al. [6] propose an approach to select relevant user reviews as explanations\nin their rating prediction model. They use an attention mechanism to analyze both user and item reviews, allowing them to identify high-quality reviews that can be used as explanations. Specifically, the attention module is applied to determine the usefulness of reviews, ensuring that only the most relevant and informative reviews are selected as explanations. Lu et al. [26] integrate matrix factorization and an attentional GRU network on user-item rating data and customer reviews. The resulting user attention network is able to provide explanations by highlighting keywords and phrases based on attention scores. While the attention mechanism seems to be a straightforward method to help explainability, Jain and Wallace [16] argue that such a method may not be able to provide \u2018meaningful\u2019 explanations.\nIn addition to the methods described above, researchers have also leveraged ideas from topic modeling to help improve explainable recommendations. The Latent Dirichlet Allocation (LDA) topic modeling [4] has been widely applied to investigate user preferences, which are often visualized using topic word clouds [27]. Other probabilistic graphic models are also studied for explainable recommendations. Wu and Ester [47] propose the Factorized Latent Aspect ModEl model (FLAME) that learns personalized preferences using item reviews. A word cloud is generated on the hotel aspect for hotel recommendations on the TripAdvisor corpus. Similarly, Zhao et al. [50] utilize a probabilistic graphic model that leverages sentiment, aspect, and region information for point-of-interest (POI) recommendation, making it possible to provide personalized topical-aspect explanations.\nMore recently, neural topic modeling [11] has been demonstrated to generate more useful topics when working with large, heavy-tailed vocabularies. Panwar et al. [31] propose the Topic Attention Networks for Neural Topic Modeling (TAN-NTM) framework. It first encodes a document using an LSTM module, and then a topic-aware module is applied to produce the outputs. A novel attention mechanism is used to learn topic-word distribution as well as the correlation of relevant words and the corresponding topic. This model shows promising results in both document classification and topic-guided keyphrase generation. To better align user preference and content information, Guo et al. [13] propose the Topic-aware Disentangled Variational AutoEncoder (TopicVAE) model. This method first extracts topic-level item representations using an attention-based module and then adopts a variational autoencoder to model topic-level disentangled user representation. Experiments show that this model outperforms other selected baselines on recommendations, as well providing interpretability on disentangled representations. In this paper we also focus on generating explanations using a similar attention mechanism to extract topics for the news recommendation task."
        },
        {
            "heading": "3 METHODOLOGY",
            "text": "This section describes our proposed news modeling method [23] and its application in the context of a general personalized news recommendations framework. We first formulate the recommendation problem and describe the process to generate explanations for the news recommendation scenario."
        },
        {
            "heading": "3.1 Problem Formulation",
            "text": "Given a user \ud835\udc62, let the browsing history (a set of news article documents) be denoted byH , and the candidate news document set by C. The history set consists of all their historical clicked news documentsH = {\ud835\udc411, \ud835\udc412, . . . , \ud835\udc41\ud835\udc56 , . . . , \ud835\udc41\ud835\udc3b }, where\ud835\udc3b is the maximum recorded history length (i.e., we only keep the first\ud835\udc3b news articles). The candidate set contains several news documents and their corresponding binary labels C = {\ud835\udc411-\ud835\udc591, \ud835\udc412-\ud835\udc592, . . . , \ud835\udc41\ud835\udc56 -\ud835\udc59\ud835\udc56 , . . . , \ud835\udc41\ud835\udc36 -\ud835\udc59\ud835\udc36 }, where \ud835\udc36 is the number of the candidate documents for the current impression (\ud835\udc36 may be variant for different impressions) and \ud835\udc59\ud835\udc56 reveals whether the user \ud835\udc62 will click this news. We then calculate relevance scores S = {\ud835\udc601, \ud835\udc602, . . . , \ud835\udc60\ud835\udc56 , . . . , \ud835\udc60\ud835\udc36 } for \ud835\udc62 and recommend the top-ranked news based on these scores. In this setting, the first problem (RQ1) is how to acquire an\naccurate ranked list of candidate documents to match the click preference of \ud835\udc62. The second associated problem (RQ2) is how best to explain the ranking based on the information available."
        },
        {
            "heading": "3.2 News Recommendations",
            "text": "We now introduce the proposed news recommendation workflow and its key components, as illustrated in Fig 3. We first describe the encoder used for news modeling and then take the output of the news encoder to model the user representation. At the same time, the news encoder also generates candidate news representations, which provide the input for the ranking module, along with the user representation. Finally, we outline the training strategy and loss function used to train the recommendation system.\n3.2.1 News Modeling. This task aims to learn semantic news representations from documents using a shared news encoder module. Our proposed encoder, the Bi-level Attention-based Topical Model (BATM) [23], contains an embedding layer and two attention layers, which can generate news embeddings for recommendations and extract meaningful topics for explanations. For a given input document \ud835\udc41\ud835\udc56 , we first tokenize the document into a set of tokens \ud835\udc47\ud835\udc56 = {\ud835\udc611, \ud835\udc612, . . . , \ud835\udc61\ud835\udc5b, . . . , \ud835\udc61\ud835\udc41 }, where \ud835\udc41 is the maximum length of the tokenized set. Then we convert tokens \ud835\udc47\ud835\udc56 to embedding vectors \ud835\udc38\ud835\udc56 = {\ud835\udc521, \ud835\udc522, . . . , \ud835\udc52\ud835\udc5b, . . . , \ud835\udc52\ud835\udc41 } in the embedding layer, where the embedding \ud835\udc52\ud835\udc5b represents word vector of the token \ud835\udc61\ud835\udc5b . We use pre-trained word embedding vectors to enhance the semantic meanings accordingly, improving recommendations\u2019 performance and topics\u2019 quality.\nAfter the embedding layer, we pass word vectors \ud835\udc38\ud835\udc56 into two attention layers. The first one utilizes a multiple-topic attention mechanism to allow the model to focus on different positions in the document from different representation\nsubspaces. We employ \ud835\udc3e attention heads to capture \ud835\udc3e topics among news corpus by topic-term weights A, and here is the procedure of this layer: 1). we compute attention values \ud835\udc54\ud835\udc58 through feed-forward neural networks as shown in Eq. 1; 2) then use the softmax function to get the distribution of the normalized weights; 3) finally, we calculate the weighted sum of word embedding vectors using the attention weights to acquire the topic vector \u210e\ud835\udc58 :\ng\ud835\udc58\ud835\udc57 = \ud835\udc63 \ud835\udc47 \ud835\udc58 tanh ( W\ud835\udc3e\ud835\udc52 \ud835\udc57 + \ud835\udc4f\ud835\udc58 ) (1)\n\ud835\udefc\ud835\udc58\ud835\udc57 = exp(g\ud835\udc58 \ud835\udc57 )\u2211\ud835\udc41\n\ud835\udc5b exp(g\ud835\udc58\ud835\udc5b) (2)\n\u210e\ud835\udc58 = \ud835\udc41\u2211\ufe01 \ud835\udc57 \ud835\udefc\ud835\udc58\ud835\udc57 \ud835\udc52 \ud835\udc57 (3)\nIn the above the learnable parameters are \ud835\udc63\ud835\udc58 \u2208 R\ud835\udc37\ud835\udc3e , W\ud835\udc3e \u2208 R\ud835\udc37\ud835\udc38\u00d7\ud835\udc37\ud835\udc3e , and \ud835\udc4f\ud835\udc58 \u2208 R\ud835\udc37\ud835\udc3e , where \ud835\udc37\ud835\udc3e is the projected dimension of each attention in the middle and \ud835\udc37\ud835\udc38 is the embedding dimension of word vectors. We extract normalized attention weights A = {\ud835\udefc1, \ud835\udefc2, . . . , \ud835\udefc\ud835\udc58 , . . . , \ud835\udefc\ud835\udc3e } as topic-term weight distribution, where \ud835\udefc\ud835\udc58 \u2208 R\ud835\udc41 . The output topic vectors are {\u210e1, \u210e2, . . . , \u210e\ud835\udc58 , . . . , \u210e\ud835\udc3e }, where \u210e\ud835\udc58 \u2208 R\ud835\udc37\ud835\udc3b and \ud835\udc37\ud835\udc3b is the dimension of the topic vectors and document representations.\nFinally, we feed the topic vectors into the additive attention layer, which generates the document-topic distribution B and the document representation \ud835\udc51\ud835\udc56 . This is achieved as follows: 1) we compute document topic attention values \ud835\udf07\ud835\udc58 by Eq. 4; 2) we normalize attention weights by softmax function to get document-topic weights; 3) we acquire the document vector \ud835\udc51\ud835\udc56 through weighted sum up topic vectors according to normalized weights:\n\ud835\udf07\ud835\udc58 = \ud835\udc49 \ud835\udc47 \ud835\udc3c tanh (W\ud835\udc3c\u210e\ud835\udc58 + \ud835\udc4f\ud835\udc3c ) (4)\n\ud835\udefd\ud835\udc58 = exp(\ud835\udf07\ud835\udc58 )\u2211\ud835\udc3e \ud835\udc58 exp(\ud835\udf07\ud835\udc58 )\n(5)\n\ud835\udc51\ud835\udc56 = \ud835\udc3e\u2211\ufe01 \ud835\udc58 \ud835\udefd\ud835\udc58\u210e\ud835\udc58 (6)\nThe trained parameters here are \ud835\udc49\ud835\udc3c \u2208 R\ud835\udc37\ud835\udc3c ,W\ud835\udc3c \u2208 R\ud835\udc37\ud835\udc38\u00d7\ud835\udc37\ud835\udc3c , and \ud835\udc4f\ud835\udc3c \u2208 R\ud835\udc37\ud835\udc3c , where \ud835\udc37\ud835\udc3c is projected dimension of additive attention. Document-topic weights B\ud835\udc56 = {\ud835\udefd1, \ud835\udefd2, . . . , \ud835\udefd\ud835\udc58 , . . . , \ud835\udefd\ud835\udc3e } reflects importance of each topic to the specific news \ud835\udc41\ud835\udc56 . The news representation \ud835\udc51\ud835\udc56 \u2208 R\ud835\udc37\ud835\udc3b is the final output of the news encoder, where the users\u2019 history news representations are used to form the user representation.\n3.2.2 User Modeling. This aspect is another core component of learning a user representation from the browsing history newsH = {\ud835\udc511, \ud835\udc512, . . . , \ud835\udc51\ud835\udc56 , . . . , \ud835\udc51\ud835\udc3b }. Inspired by previous studies [41\u201343], we use an additive attention network to encode news history. The procedure for acquiring a user representation is similar to Eqs.4 to 6. Specifically, we calculate user-news attention weights \ud835\udefe by normalizing attention values \ud835\udf03\ud835\udc56 with a softmax function. Then the user vector \ud835\udc62 is calculated as the weighted sum of the user\u2019s history news representations using user-news attention weights.\n\ud835\udf03\ud835\udc56 = \ud835\udc49 \ud835\udc47 \ud835\udc48 tanh (W\ud835\udc48\ud835\udc51\ud835\udc56 + \ud835\udc4f\ud835\udc48 ) (7)\n\ud835\udefe\ud835\udc56 = exp(\ud835\udf03\ud835\udc56 )\u2211\ud835\udc3b \ud835\udc57 exp(\ud835\udf03 \ud835\udc57 )\n(8)\n\ud835\udc62 = \ud835\udc3b\u2211\ufe01 \ud835\udc56 \ud835\udefe\ud835\udc56\ud835\udc51\ud835\udc56 (9)\nHere \ud835\udc49\ud835\udc47 \ud835\udc48 \u2208 R\ud835\udc37\ud835\udc48 ,\ud835\udc4a\ud835\udc48 \u2208 R\ud835\udc37\ud835\udc3b \u00d7\ud835\udc37\ud835\udc48 , and \ud835\udc4f\ud835\udc48 \u2208 R\ud835\udc37\ud835\udc48 are trainable parameters, and \ud835\udc37\ud835\udc48 is the dimension of the projection layer. We determine the significance of the news item \ud835\udc41\ud835\udc56 via the user-news weight \ud835\udefe\ud835\udc56 , which is also used to select the most relevant news articles for the recommendations task.\nIn addition to attentive methods, sequential methods, such as Gated Recurrent Unit (GRU) networks [7], can also be effective in modeling a user\u2019s interest [2, 30]. Thus, we further consider the impact of using a GRU network as the user model, where the user vector is computed as follow [8]:\n\ud835\udc5f\ud835\udc61 = \ud835\udf0e (\ud835\udc4a\ud835\udc56\ud835\udc5f\ud835\udc51\ud835\udc61 +\ud835\udc4a\u210e\ud835\udc5f\ud835\udc5c\ud835\udc61\u22121 + \ud835\udc4f\ud835\udc5f ) (10)\n\ud835\udc67\ud835\udc61 = \ud835\udf0e (\ud835\udc4a\ud835\udc56\ud835\udc67\ud835\udc51\ud835\udc61 +\ud835\udc4a\u210e\ud835\udc67\ud835\udc5c\ud835\udc61\u22121 + \ud835\udc4f\ud835\udc67) (11)\n\ud835\udc5b\ud835\udc61 = tanh (\ud835\udc4a\ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc61 + \ud835\udc4f\ud835\udc56\ud835\udc5b + \ud835\udc5f\ud835\udc61 \u2217 (\ud835\udc4a\u210e\ud835\udc5b\ud835\udc5c\ud835\udc61\u22121 + \ud835\udc4f\u210e\ud835\udc5b)) (12)\n\ud835\udc5c\ud835\udc61 = (1 \u2212 \ud835\udc67\ud835\udc61 ) \u2217 \ud835\udc5b\ud835\udc61 + \ud835\udc67\ud835\udc61 \u2217 \ud835\udc5c\ud835\udc61\u22121 (13)\nAccordingly,\ud835\udc4a\ud835\udc56\ud835\udc5f ,\ud835\udc4a\u210e\ud835\udc5f ,\ud835\udc4a\ud835\udc56\ud835\udc67 ,\ud835\udc4a\u210e\ud835\udc67 ,\ud835\udc4a\ud835\udc56\ud835\udc5b,\ud835\udc4a\u210e\ud835\udc5b \u2208 R\ud835\udc37\ud835\udc3b \u00d7\ud835\udc37\ud835\udc3b and \ud835\udc4f\ud835\udc5f , \ud835\udc4f\ud835\udc67 , \ud835\udc4f\ud835\udc56\ud835\udc5b, \ud835\udc4f\u210e\ud835\udc5b \u2208 R\ud835\udc37\ud835\udc3b are learnable hidden weights and biases. We represent the input news representation at time \ud835\udc61 with \ud835\udc51\ud835\udc61 , the hidden states at time \ud835\udc61 \u2212 1 and \ud835\udc61 with \ud835\udc5c\ud835\udc61\u22121 and \ud835\udc5c\ud835\udc61 , respectively, and the reset, update, and new gates at time \ud835\udc61 with \ud835\udc5f\ud835\udc61 , \ud835\udc67\ud835\udc61 , and \ud835\udc5b\ud835\udc61 , respectively. \ud835\udf0e and \u2217 are the sigmoid function and the Hadamard product.\nWe denote the first strategy that uses additive methods as the \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 model, and the second strategy incorporating the GRU network as the \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc3a\ud835\udc45\ud835\udc48 model. The output user representation \ud835\udc62 \u2208 R\ud835\udc37\ud835\udc3b reflects a user\u2019s interest, which will be employed to determine the click probabilities of corresponding groups of candidate news articles.\n3.2.3 Click Predictor and Training Strategy. By obtaining the user representation \ud835\udc62 and the set of candidate news representations \ud835\udc37 = {\ud835\udc511, \ud835\udc512, . . . , \ud835\udc51\ud835\udc56 , . . . , \ud835\udc51\ud835\udc36 }, we can employ the simple inner product to calculate the news click probability score, which is inspired by recent research [2, 41\u201343]. The probability score \ud835\udc60\ud835\udc56 of the news \ud835\udc41\ud835\udc56 is computed as \ud835\udc60\ud835\udc56 = \ud835\udc62\ud835\udc47\ud835\udc51\ud835\udc56 , which determines the recommendation rank among the candidate news items. For the model training procedure, we use the negative sampling strategy [14, 43] to train our ranking model using the NCE loss. We treat each clicked news item as a positive sample of the candidate news set, and randomly select\ud835\udc40 non-clicked news items from the same impression as negative samples. Then we jointly calculate scores of positive and negative to acquire the NCE loss. Finally, the loss L\ud835\udc41\ud835\udc36\ud835\udc38 is given by the negative log-likelihood of all positive samples of this impression:\nL\ud835\udc41\ud835\udc36\ud835\udc38 = \u2212 \ud835\udc43\u2211\ufe01 \ud835\udc5d log exp(\ud835\udc60+\ud835\udc5d ) exp(\ud835\udc60+\ud835\udc5d ) + \u2211\ud835\udc40 \ud835\udc5a exp(\ud835\udc60\u2212\ud835\udc5a)\n(14)\nwhere \ud835\udc43 represents the number of positive training samples in the impression and \ud835\udc60\u2212\ud835\udc5a denotes the\ud835\udc5ath negative sample in the same session linked to the \ud835\udc5dth positive sample."
        },
        {
            "heading": "3.3 Recommendation Explanations",
            "text": "After training the proposed recommendation system, we analyze the attention weights extracted from the trained \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 only to generate explanations because the \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc3a\ud835\udc45\ud835\udc48 model is not fully explainable. An explanation is provided to clarify why the model recommends such news items, and we usually only care about the several foremost recommended news items. The core aspect of our explanations are the extracted topics used to reveal the relatedness\nbetween the user\u2019s browsing history news and the ranked candidate news. Thus, we propose to use the quantitative topic coherence metrics [22, 29] to globally evaluate the quality of topics extracted by the \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 model in Section 4.4, which can reflect the trustworthy of these explanations. Later in Section 4.5 we present a case study to further motivate the idea of using topics to validate the relevance of related news articles in a real-world example.\nThe generation of explanations consists of two steps, as shown in Fig. 4. Here we revisit the recommendation example previously discussed in Section 3.1. The first phase involves the global topic distribution from the multiple-topic attention layer, as calculated by Eq. 1 and Eq. 2 using embedded word vectors as inputs. Assume that there are \ud835\udc3e global topics in total and \ud835\udc49 words in the corpus, so the resulting topic distribution T is a \ud835\udc3e \u00d7\ud835\udc49 weight matrix. Moreover, we extract the \ud835\udc61\ud835\udc5c\ud835\udc5d-\ud835\udc40 most important words from the global topic distribution T for each topic and view them as being the topic\u2019s descriptors, which are used for the topic\u2019s quality evaluation. The next phase involves identifying the news contribution among the browsing history H for the candidate set C. Here we can recognize the news contribution by using user-news attention weights \ud835\udefe as calculated by Eq. 7 and Eq. 8. A news article fromH should correlate highly with the clicked candidate news articles when they focus on similar topics. We select the most relevant topics according to the document-topic distributions B for each news article. To verify the topic relevance among the most contributed history clicked news articles and recommended news articles, we highlight the highest-scoring words from a subset topic distribution T , which takes the form of a \ud835\udc3e \u00d7 \ud835\udc41 matrix where \ud835\udc41 is the length of the corresponding news article. Thus, we can validate the relevance of the history H and candidate C from the semantic meaning of those highlighted words."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": "We now provide details of experimental evaluations, including a description of the news dataset, baseline models, and experimental settings for the news recommendation task. We also provide an evaluation of the global topics generated by our approach using topic coherence metrics, together with a case study in Section 4.5."
        },
        {
            "heading": "4.1 Data",
            "text": "We evaluated our proposed model on a news classification task [23] and a news recommendation task on a realworld news recommendation dataset, MIcrosoft News Dataset (MIND) [45]. MIND is a large-scale English news recommendation collection that consists of 1 million anonymized users and more than 160k English news articles, retrieved during 6 weeks from October 12 to November 22, 2019. In addition to the articles themselves, over 15 million\nimpression logs were collected during this time period, involving more than 24 million user clicks. Each impression log represents a one-time recommendation that includes the IDs of news shown to a user when the user browses the news platform during a specific time slot, along with the click behaviors on these news articles. The content related to each news article includes its title, abstract, category, and URL. Based on the original news dataset, we add further information by including news body content for our experiments.\nThe final publicly-released MIND dataset only contains two weeks\u2019 impression logs from November 9 to November 22, 2019, where only the first week\u2019s logs are labeled. MIND released two versions of the dataset from the first week\u2019s data, named MIND-LARGE and MIND-SMALL respectively. The larger dataset contains all behaviors from the first week, while the smaller one only includes the impression logs for a subset of the users. We list details of the official MIND version and publicly available version in Table 1.\nIn our evaluations, we take the MIND-LARGE dataset for the news classification (NC) task and randomly divide the data into training/validation/test sets. As for the news recommendation (NR) task, we randomly split the first week\u2019s log into three sets for both MIND-SMALL and MIND-LARGE versions: training set (from November 9 to November 14), validation set (November 15), and test set (November 15). We select the best hyperparameters for different models based on the validation set, and compare their relative performance on the test set."
        },
        {
            "heading": "4.2 Baseline Models and Experimental Settings",
            "text": "For the purpose of assessing recommendations performance, we compare our model with several popular deep neural models designed for news recommendation:\n\u2022 DKN [40] applies a word-entity-aligned KCNN on news representations learning and a candidate-aware attention network for recommendations2. \u2022 NAML [41] leverages two separate CNN to encode news title and body text while using linear layers to encode category and subcategory. The news representations are learned from a multi-view of text, category, and subcategory representations. And modeling user behavior using another attention network. \u2022 NRMS [43] uses multi-head self-attentions for both news and user modeling. \u2022 LSTUR [2] involves an attention-based CNN on news representations learning and a GRU network to model\nshort-term user interest along with user id for long-term user interest. \u2022 NPA [42] uses a personalized word-level attention-based CNN to learn news representations, while another\npersonalized attention network is employed to learn user representations.\n2We use dot product instead of a linear neural network to predict click probability for a fair comparison.\nWe divide experimental configurations into two categories: general system settings and model hyperparameter settings. Consistent with previous studies [2, 40\u201343], we maintain the same system settings across all experiments to ensure fairness. To account for GPU memory limitations, we set the maximum number of clicked news items for user representation learning to 50 and the maximum length of a news article to 100 tokens, with a maximum length of 30 for the news title and 70 for the news body, respectively. Thus, we randomly sampled at most 50 browsed articles from a user\u2019s history. The batch size was set to 64 and the negative sampling ratio \ud835\udc40 was set to 4 during training, so that each positive sample is paired with 4 negative samples. We employed Adam [18] as the model optimization technique during gradient descent. The learning rate was set to 1e-3, and we reduced the learning rate by half each epoch. To mitigate overfitting, we added a dropout layer [37] to each layer for all models in comparison and set the dropout rate to 20%. We initialized the embedding layer with pre-trained Glove embedding [32] and set the embedding dimension \ud835\udc37\ud835\udc38 to 300. Following previous work [45], we consider four ranking metrics in our experiments to evaluate the performance of news recommendations: AUC, MRR, nDCG@5, and nDCG@10. We repeat each experiment independently 5 times and select the model hyperparameters with the highest average AUC score on the validation set across those 5 runs. The performance scores on the test set are reported in Section 4.3."
        },
        {
            "heading": "4.3 News Recommendations Performance",
            "text": "The overall performance of all baselines and two variants of our model are summarized in Table 2. All the numbers in the table are percentage numbers with \u2018%\u2019 omitted. The overall best and previous best results are boldfaced and underlined respectively.\nFrom the results, we can make a number of important observations. First, all deep neural models achieved similar performances based on the experimental setting in Section 4.2. This is because we used the same pre-trained embedding parameters (Glove) to initialize the embedding layer, which means the number of trainable parameters of models is close3. Another reason is that we applied a similar architecture which contains a news encoder and a user encoder and makes predictions using the results of dot-product between news representations and user representations. Thus, the difference in results is due to news modeling and user modeling design.\nSecondly, the performances of all models in the MIND-LARGE set are significantly better compared to the results in the MIND-SMALL set. NAML model generally achieved the best results among the selected baselines, except in some cases (e.g., the AUC metric) where LSTUR model performs slightly better than the NAML model, as it can obtain information from news text, category, and subcategory to form informative representations. LSTUR model is also\n3The number of embedding layer\u2019s parameters usually counts 90% of the model in total\ncompetitive, as it uses a sequence model (GRU) for user modeling, effectively capturing user interests, which is also the reason we tried a GRU variant of our model.\nFinally, our models \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 and \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc3a\ud835\udc45\ud835\udc48 outperform all baselines on the MIND-SMALL set and the MINDLARGE set for almost all metrics. We can observe that NAML model presents a comparable performance compared to our models, though our models are slightly better overall. The encoding of category and subcategory in NAML model may fuse explicit topic information into the final news representations, which is very similar to our topic modeling module. However, our model can extract latent topics from the news texts and acquire topic representation from texts instead of categories and subcategories. Overall, these experiments demonstrate the effectiveness of our proposed models for news recommendation."
        },
        {
            "heading": "4.4 Evaluation of Global Topics",
            "text": "In addition to performance on the news classification (NC) and news recommendation (NR) tasks, we also evaluate the usefulness of the explanations generated by our methods. As our explanations are based on extracted topics, we quantitatively assess usefulness here by considering the popular idea of topic coherence, corresponding to the semantic interpretability of the top terms typically used to describe the topics identified by a topic modeling algorithm [29]. We use this to compare the quality of topics from our trained model with those produced by a classical topic model LDA [4]. Specifically, the trained model here is \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 model, where the news corpus S\ud835\udc59\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52 for the training of \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40 model [23] on the NC task. The LDA model is generated on the MIND-LARGE corpus, as described in Section 4.1. We also train the \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 for NR task on the MIND-SMALL dataset and compare it with the model on NC task and the LDA model regarding topic quality. The news corpus S\ud835\udc59\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52 is also used as the reference corpus for the remaining assessments when calculating topic coherence scores.\nAfter training the model, we calculate the topic coherence scores using two different metrics from the topic modeling literature: \ud835\udc41\ud835\udc43\ud835\udc40\ud835\udc3c [5, 22] and\ud835\udc4a 2\ud835\udc49 [29]. These are used to determine whether the extracted topic descriptors have an intuitive meaning. The reason for using these two metrics is that the topic coherence metric \ud835\udc41\ud835\udc43\ud835\udc40\ud835\udc3c is regarded as positively correlated with human intuition [22], while\ud835\udc4a 2\ud835\udc49 similarity is designed for embedding-based methods. We select the \ud835\udc61\ud835\udc5c\ud835\udc5d-\ud835\udc40 highest scoring words as topic descriptors and calculate \ud835\udc41\ud835\udc43\ud835\udc40\ud835\udc3c scores and\ud835\udc4a\ud835\udc5c\ud835\udc5f\ud835\udc512\ud835\udc49\ud835\udc52\ud835\udc50(\ud835\udc4a 2\ud835\udc49 ) similarity scores of them. For a given topic \ud835\udc58 , suppose we obtain a topic descriptor set\ud835\udc47\ud835\udc58 = {\ud835\udc61\ud835\udc581 , \ud835\udc61 \ud835\udc58 2 , . . . , \ud835\udc61 \ud835\udc58 \ud835\udc5b , . . . , \ud835\udc61 \ud835\udc58 \ud835\udc41 }, so we compute the \ud835\udc41\ud835\udc43\ud835\udc40\ud835\udc3c scores and\ud835\udc4a 2\ud835\udc49 similarity scores as follow:\n\ud835\udc41\ud835\udc43\ud835\udc40\ud835\udc3c (\ud835\udc47\ud835\udc58 ) = 1(\ud835\udc40 2 ) \ud835\udc41\u2211\ufe01 \ud835\udc57=2 \ud835\udc57\u22121\u2211\ufe01 \ud835\udc56=1 log \ud835\udc43\n( \ud835\udc61\ud835\udc58 \ud835\udc57 ,\ud835\udc61\ud835\udc58 \ud835\udc56 ) +\ud835\udf16\n\ud835\udc43 (\ud835\udc61\ud835\udc58\ud835\udc56 )\ud835\udc43 ( \ud835\udc61\ud835\udc58 \ud835\udc57 ) \u2212 log \ud835\udc43 ( \ud835\udc61\ud835\udc58 \ud835\udc56 , \ud835\udc61\ud835\udc58 \ud835\udc57 ) + \ud835\udf16\n(15)\n\ud835\udc4a 2\ud835\udc49 (\ud835\udc47\ud835\udc58 ) = 1(\ud835\udc40 2 ) \ud835\udc41\u2211\ufe01 \ud835\udc57=2 \ud835\udc57\u22121\u2211\ufe01 \ud835\udc56=1 \ud835\udc60\ud835\udc56\ud835\udc5a\ud835\udc56\ud835\udc59\ud835\udc4e\ud835\udc5f\ud835\udc56\ud835\udc61\ud835\udc66 (\ud835\udc52\ud835\udc58\ud835\udc57 , \ud835\udc52 \ud835\udc58 \ud835\udc56 ) (16)\nHere \ud835\udc52\ud835\udc58 \ud835\udc57 and \ud835\udc52\ud835\udc58 \ud835\udc56 in Eq. 16 are the word vectors of tokens \ud835\udc61\ud835\udc58 \ud835\udc57 and \ud835\udc61\ud835\udc58 \ud835\udc56 from the trained model. We set \ud835\udc40 = 10 for each topic and take the average values of all topics. The word co-occurrence probabilities of \ud835\udc61\ud835\udc58 \ud835\udc57 and \ud835\udc61\ud835\udc58 \ud835\udc56 are counted from the reference corpus S\ud835\udc59\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc52 . Corpus preprocessing can influence the resulting downstream topic descriptors and can further affect topic evaluation metrics. The processing pipeline of a topic model mainly involves three steps: 1) filter out stopwords using the default\nspaCy English stopword list4; 2) remove tokens that appear in more than 90% of documents; 3) remove tokens that appear in fewer than \ud835\udc41 documents. We use the pipeline as preprocessing procedure to train an LDA model and evaluate it with the same processing pipeline. However, the preprocessing pipeline of our deep models is quite different as we keep most tokens (e.g., stopwords remained) for training to retain semantic information. Thus, we apply the same pipeline as the LDA model after the training process of NC and NR tasks. As it is performed after training, we name it post-processing (denoted as \ud835\udc43\ud835\udc43-\ud835\udc41 , such as \ud835\udc43\ud835\udc43-10) for our \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 model. For the model evaluated on the original training dataset, we denote it as\ud835\udc4a\ud835\udc56\ud835\udc61\u210e\ud835\udc5c\ud835\udc62\ud835\udc61 \ud835\udc43\ud835\udc43 .\nIn Fig. 5 we see the distributions of \ud835\udc41\ud835\udc43\ud835\udc40\ud835\udc3c scores and\ud835\udc4a 2\ud835\udc49 similarity scores computed from our \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 model, where each point in a plot represents a one-time evaluation of topic descriptors. Here the number of topics ranges between 10-500. We can make several observations from the box plots. Firstly, post-processing slightly improves scores and decreases the number of poor topics. This is because our model is not highly dependent on the processing pipeline and can robustly deal with non-informative words like stopwords that usually will not appear in the topic descriptors generated by our models. However, the classical LDA model relies on strict preprocessing procedures to avoid including non-informative words in descriptors. Secondly, the LDA model is significantly better than our \ud835\udc35\ud835\udc34\ud835\udc47\ud835\udc40-\ud835\udc34\ud835\udc47\ud835\udc47 model in extracting coherent topics in terms of the \ud835\udc41\ud835\udc43\ud835\udc40\ud835\udc3c metric, but our model achieves comparable results on the\ud835\udc4a 2\ud835\udc49 metric. This is reasonable because our aim here is to generate explanations, rather than focusing on constructing complete topic models for corpus exploration. Finally, our model can often generate coherent topics comparable to the LDA model, where more than 10% of the topics have a \ud835\udc41\ud835\udc43\ud835\udc40\ud835\udc3c score above 0.2 and a\ud835\udc4a 2\ud835\udc49 similarity score over 0.4 as well. This inspires us to compare average scores of only the top-10% topics as we normally only care about several most important topics and generate explanations based on these topics. According to Fig. 6, the trend of top-10% average NPMI scores and\ud835\udc4a 2\ud835\udc49 similarity scores is \ud835\udc3f\ud835\udc37\ud835\udc34 > \ud835\udc41\ud835\udc36 > \ud835\udc41\ud835\udc45. Since the complexity of the NR task requires user modeling based on the news modeling, which may be negative in finding meaningful topics because of the involvement of unsure factors, 4https://github.com/explosion/spaCy/blob/v3.0.5/spacy/lang/en/stop_words.py\nthe extracted topics are not as good as the LDA model. However, those topics are enough to explain recommendation behaviors as we only require some of them in a real case. These results validate the effectiveness of our BATM-ATT model in generating high-quality topics,"
        },
        {
            "heading": "4.5 Case Study",
            "text": "We conduct a case study to present how our BATM-ATT model generates explanations of a real-world example using the method of Section 3.3 as shown in Fig. 7. A case involves the user browsed articlesH and the ranked candidate news articles C shown to the user. We highlight those descriptor words from three of the most important topics for each news article, where each topic is highlighted with a unique color.\nFirstly, we notice that the topic in red \ud835\udc47\ud835\udc5f\ud835\udc52\ud835\udc51 is activated across nearly all articles. The exact meaning of the topic \ud835\udc47\ud835\udc5f\ud835\udc52\ud835\udc51 is hard to summarize, as it is always highly related to the specific article itself. For example, it focuses on words such as \"interview\", \"family\", \"living\", and \"life\" for the article N60340, which are about daily life. However, for a financial news article N62124, the highlighted words now include \"interest\", \"believe\", \"lending\", and \"federal\", which are often used in the financial domain. We also observe that news articles under the same category usually discuss similar topics, and we observed that the example case also reflects this nature. Take the category \"lifestyle\" as an example, except for the general topic \ud835\udc47\ud835\udc5f\ud835\udc52\ud835\udc51 , there are four more topics that concern words related to lifestyle for all four news articles. Among these four topics, the topic in green \ud835\udc47\ud835\udc54\ud835\udc5f\ud835\udc52\ud835\udc52\ud835\udc5b and the topic in purple \ud835\udc47\ud835\udc5d\ud835\udc62\ud835\udc5f\ud835\udc5d\ud835\udc59\ud835\udc52 only appear in the articles on lifestyle. Thus, the last observation is that some topics are closely related to a specific subject, such as the topic in orange \ud835\udc47\ud835\udc5c\ud835\udc5f\ud835\udc4e\ud835\udc5b\ud835\udc54\ud835\udc52 , which is highly related to the political economy topic, and attends to words like \"signals\", \"monetary\" and \"policy\". For further examples of topics generated by our approach, see the Appendix."
        },
        {
            "heading": "5 CONCLUSION AND FUTUREWORK",
            "text": "In this paper, we presented a novel recommender architecture that harnesses a bi-level attention framework to decouple the news recommendations process as topic capturing, topic importance recognition, and decision-making process to\nbenefit explainability. We conducted experiments on a real-world news recommendation dataset where we compared our approach to several state-of-the-art alternatives. Results indicate that our model can achieve better performance while also successfully capturing intuitive meanings in the form of topical features, thus improving its explainability and transparency. Furthermore, we applied two topic coherence metrics to quantitatively evaluate the quality of the topics generated by our model, in the context of both news classification and recommendation tasks, thereby validating the interpretability of our model. For future work, we suggest three distinct directions. First, we intend to explore the use of topic features to improve news recommendation performance. Second, we plan to add constraints to our model to extract more interpretable topics. Finally, we intend to conduct a user study to determine how well our explainable recommender works in a real-world setting."
        },
        {
            "heading": "6 APPENDICES",
            "text": ""
        },
        {
            "heading": "6.1 Experimental Environment",
            "text": "Our experiments were conducted on a High Performance Computing cluster running the Linux operating system. We used PyTorch 1.8.0 as the backend. The GPU type is Nvidia Tesla V100 and A100 with 32GB and 40GB GPU memory respectively. We ran each experiment 5 times with fixed random seeds, each in a single thread."
        },
        {
            "heading": "6.2 Additional Case Study",
            "text": "In Fig. 8 below we show another typical example of a recommendation case sampled from the MIND test set."
        },
        {
            "heading": "6.3 Global Topic Examples",
            "text": ""
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This research was supported by Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289_P2."
        }
    ],
    "title": "Topic-Centric Explanations for News Recommendation",
    "year": 2023
}