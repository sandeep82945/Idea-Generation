{
    "abstractText": "In this paper we propose a method to generate suitably refined finite element meshes using neural networks. As a model problem we consider a linear elasticity problem on a planar domain (possibly with holes) having a polygonal boundary. We impose boundary conditions by fixing the position of a part of the boundary and applying a force on another part of the boundary. The resulting displacement and distribution of stresses depend on the geometry of the domain and on the boundary conditions. When applying a standard Galerkin discretization using quadrilateral finite elements, one usually has to perform adaptive refinement to properly resolve maxima of the stress distribution. Such an adaptive scheme requires a local error estimator and a corresponding local refinement strategy. The overall costs of such a strategy are high. We propose to reduce the costs of obtaining a suitable discretization by training a neural network whose evaluation replaces this adaptive refinement procedure. We set up a single network for a large class of possible domains and boundary conditions and not on a single domain of interest. The computational domain and boundary conditions are interpreted as images, which are suitable inputs for convolution neural networks. In our approach we use the U-net architecture and we devise training strategies by dividing the possible inputs into different categories based on their overall geometric complexity. Thus, we compare different training strategies based on varying geometric complexity. One of the advantages of the proposed approach is the interpretation of input and output as images, which do not depend on the underlying discretization scheme. Another is the generalizability and geometric flexibility. The network can be applied to previously unseen geometries, even with different topology and level of detail. Thus, training can easily be extended to other classes of geometries.",
    "authors": [],
    "id": "SP:58f3016c70707278b7907ee99835fc37662d0d22",
    "references": [
        {
            "authors": [
                "X Liang",
                "Y Zhang"
            ],
            "title": "Matching interior and exterior allquadrilateral meshes with guaranteed angle bounds",
            "year": 2012
        },
        {
            "authors": [
                "S Tang",
                "G Zhang",
                "H Yang",
                "Y Li",
                "WK Liu",
                "X Guo"
            ],
            "title": "Map123: A data-driven approach to use 1D data for 3D nonlinear elastic materials modeling",
            "year": 2019
        },
        {
            "authors": [
                "H Li",
                "OL Kafka",
                "J Gao",
                "C Yu",
                "Y Nie",
                "L Zhang",
                "M Tajdari",
                "S Tang",
                "X Guo",
                "G Li",
                "G Cheng",
                "W Kam Liu"
            ],
            "title": "Clustering discretization methods for generation of material performance databases in machine learning and design optimization",
            "year": 2019
        },
        {
            "authors": [
                "GF Barros",
                "M Grave",
                "A Viguerie",
                "A Reali",
                "refinement Coutinho AL (2021) Dynamic mode decomposition in adaptive mesh",
                "arXiv coarsening simulations. arXiv preprint"
            ],
            "title": "2104",
            "venue": "14034 4652 Engineering with Computers",
            "year": 2022
        },
        {
            "authors": [
                "Z Han",
                "S De"
            ],
            "title": "A deep learning-based hybrid approach for the solution of multiphysics problems in electrosurgery",
            "venue": "Comput Methods Appl Mech Eng",
            "year": 2019
        },
        {
            "authors": [
                "D Finol",
                "Y Lu",
                "V Mahadevan",
                "Srivastava"
            ],
            "title": "A (2019) Deep convolutional neural networks for eigenvalue problems in mechanics",
            "venue": "Int J Numer Meth Eng",
            "year": 2019
        },
        {
            "authors": [
                "A Li",
                "R Chen",
                "AB Farimani",
                "YJ Zhang"
            ],
            "title": "Reaction diffusion system prediction based on convolutional neural network",
            "year": 2020
        },
        {
            "authors": [
                "P Grohs",
                "F Hornung",
                "A Jentzen",
                "P Zimmermann"
            ],
            "title": "Spacetime error estimates for deep neural network approximations for differential equations",
            "venue": "arXiv preprint arXiv:",
            "year": 2019
        },
        {
            "authors": [
                "J He",
                "J Xu"
            ],
            "title": "MgNet: A unified framework of multigrid and convolutional neural network",
            "venue": "Sci China Math 1\u201324",
            "year": 2019
        },
        {
            "authors": [
                "J He",
                "L Li",
                "J Xu",
                "C Zheng"
            ],
            "title": "ReLu deep neural networks and linear finite elements",
            "venue": "J Comput Math 38(3):502\u2013527",
            "year": 2020
        },
        {
            "authors": [
                "S Panghal",
                "M Kumar"
            ],
            "title": "Optimization free neural network approach for solving ordinary and partial differential equations",
            "year": 2021
        },
        {
            "authors": [
                "Z Chi",
                "Z Jiang",
                "M Kamruzzaman",
                "BA Hafshejani",
                "M Safarpour"
            ],
            "title": "Adaptive momentum-based optimization to train deep neural network for simulating the static stability of the composite structure",
            "year": 2021
        },
        {
            "authors": [
                "J Sirignano",
                "K Spiliopoulos"
            ],
            "title": "DGM: A deep learning algorithm for solving partial differential equations",
            "venue": "J Comput Phys 375:1339\u20131364",
            "year": 2018
        },
        {
            "authors": [
                "A Oishi",
                "G Yagawa"
            ],
            "title": "Computational mechanics enhanced by deep learning",
            "venue": "Comput Methods Appl Mech Eng",
            "year": 2017
        },
        {
            "authors": [
                "J Tompson",
                "K Schlachter",
                "P Sprechmann",
                "K Perlin"
            ],
            "title": "Accelerating Eulerian fluid simulation with convolutional networks",
            "venue": "Proceedings of the 34th International Conference on Machine Learning - Volume 70,",
            "year": 2017
        },
        {
            "authors": [
                "S Alfonzetti"
            ],
            "title": "A finite element mesh generator based on an adaptive neural network",
            "venue": "IEEE Trans Magn",
            "year": 1998
        },
        {
            "authors": [
                "L Manevitz",
                "A Bitar",
                "D Givoli"
            ],
            "title": "Neural network time series forecasting of finite-element mesh adaptation",
            "year": 2005
        },
        {
            "authors": [
                "NNE Emam",
                "RA Shaheed"
            ],
            "title": "Computing an adaptive mesh in fluid problems using neural network and genetic algorithm with adaptive relaxation",
            "venue": "Int J Artif Intell Tools",
            "year": 2008
        },
        {
            "authors": [
                "D Pfl\u00fcger",
                "B Peherstorfer",
                "H-J Bungartz"
            ],
            "title": "Spatially adaptive sparse grids for high-dimensional data-driven problems",
            "venue": "J Complex",
            "year": 2010
        },
        {
            "authors": [
                "X Chen",
                "J Liu",
                "Y Pang",
                "J Chen",
                "L Chi",
                "C Gong"
            ],
            "title": "Developing a new mesh quality evaluation method based on convolutional neural network",
            "year": 2020
        },
        {
            "authors": [
                "TJR Hughes",
                "JA Cottrell",
                "Y Bazilevs"
            ],
            "title": "Isogeometric analysis: CAD, finite elements, NURBS, exact geometry and mesh refinement",
            "venue": "Comput Methods Appl Mech Eng",
            "year": 2005
        },
        {
            "authors": [
                "YJ Zhang"
            ],
            "title": "Geometric modeling and mesh generation from scanned images",
            "year": 2018
        },
        {
            "authors": [
                "Y Zhang",
                "C Bajaj"
            ],
            "title": "Adaptive and quality quadrilateral/hexahedral meshing from volumetric data",
            "venue": "Comput Methods Appl Mech Eng",
            "year": 2006
        },
        {
            "authors": [
                "MM Bronstein",
                "J Bruna",
                "Y LeCun",
                "A Szlam",
                "P Vandergheynst"
            ],
            "title": "Geometric deep learning: going beyond euclidean data",
            "venue": "IEEE Signal Process Mag",
            "year": 2017
        },
        {
            "authors": [
                "Y Wang",
                "Y Sun",
                "Z Liu",
                "SE Sarma",
                "MM Bronstein",
                "JM Solomon"
            ],
            "title": "Dynamic graph CNN for learning on point clouds",
            "venue": "ACM Trans. Graph",
            "year": 2019
        },
        {
            "authors": [
                "Z Zhang",
                "Y Wang",
                "PK Jimack",
                "H Wang"
            ],
            "title": "MeshingNet: A new mesh generation method based on deep learning",
            "venue": "In: International Conference on Computational Science,",
            "year": 2020
        },
        {
            "authors": [
                "Z Zhang",
                "PK Jimack",
                "H Wang"
            ],
            "title": "Efficient generation of adapted tetrahedral meshes for computational mechanics",
            "venue": "Adv Eng Softw",
            "year": 2021
        },
        {
            "authors": [
                "O Ronneberger",
                "P Fischer",
                "T Brox"
            ],
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "venue": "In: International Conference on Medical image computing and computer-assisted intervention,",
            "year": 2015
        },
        {
            "authors": [
                "I Goodfellow",
                "Y Bengio",
                "Courville"
            ],
            "title": "A (2016) Deep Learning. MIT Press. http:// www. deepl earni ngbook",
            "year": 2016
        },
        {
            "authors": [
                "N Sukumar",
                "D Srolovitz"
            ],
            "title": "Finite element-based model for crack propagation in polycrystalline materials",
            "venue": "Comput Appl Math 23(2\u20133):363\u2013380",
            "year": 2004
        },
        {
            "authors": [
                "C Giannelli",
                "B J\u00fcttler",
                "H Speleers"
            ],
            "title": "THB-splines: the truncated basis for hierarchical splines",
            "venue": "Comput Aided Geom Des",
            "year": 2012
        },
        {
            "authors": [
                "TW Sederberg",
                "J Zheng",
                "A Bakenov",
                "Nasri"
            ],
            "title": "A (2003) T-splines and T-NURCCs",
            "venue": "ACM Trans Graph",
            "year": 2003
        },
        {
            "authors": [
                "H Casquero",
                "X Wei",
                "D Toshniwal",
                "A Li",
                "TJ Hughes",
                "J Kiendl",
                "YJ Zhang"
            ],
            "title": "Seamless integration of design and KirchhoffLove shell analysis using analysis-suitable unstructured T-splines",
            "year": 2020
        },
        {
            "authors": [
                "M Pauley",
                "D-M Nguyen",
                "D Mayer",
                "J \u0160peh",
                "O Weeger",
                "B J\u00fcttler"
            ],
            "title": "The isogeometric segmentation pipeline",
            "year": 2015
        },
        {
            "authors": [
                "A Li",
                "AB Farimani",
                "YJ Zhang"
            ],
            "title": "Deep learning of material transport in complex neurite",
            "year": 2021
        },
        {
            "authors": [
                "M Fey",
                "JE Lenssen",
                "F Weichert",
                "H M\u00fcller"
            ],
            "title": "SplineCNN: Fast geometric deep learning with continuous B-spline kernels. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 869\u2013877 Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Vol.:(0123456789)\nKeywords Finite element method\u00a0\u00b7 Local refinement\u00a0\u00b7 Artificial neural network\u00a0\u00b7 Linear elasticity"
        },
        {
            "heading": "1 Introduction",
            "text": "In this work, we consider the problem of finding an optimal discretization for a linear elasticity problem for a given planar domain and boundary conditions. Previously, this problem has often been solved by adaptive refinement, which means that the partial differential equation (PDE) is first solved on an initial mesh, then the error is estimated using a local error estimator, and the mesh is subsequently refined in the regions of the domain where the error is large. This process is repeated until the obtained uniform error is below a given tolerance. Adaptive refinement is computationally costly, since at each step, a new mesh is generated and progressively larger linear systems need to be assembled and solved. The objective of this study is therefore to find an optimal mesh a priori without needing to first solve the PDE, thereby avoiding the computational costs involved in iterative mesh refinements. Felix Scholz and Thomas Takacs contributed equally to this work. * Chiu Ling Chan chiu_ling.chan@jku.at Felix Scholz felix.scholz@tafsm.org Thomas Takacs thomas.takacs@ricam.oeaw.ac.at 1 Institute of\u00a0Applied Geometry, Johannes Kepler University Linz, Altenberger Str. 69, 4040\u00a0Linz, Austria 2 Waseda Research Institute for\u00a0Science and\u00a0Engineering, Waseda University, 3-4-1 Okubo, Shinjuku, Tokyo\u00a0169-8555, Japan\n3 Johann Radon Institute for\u00a0Computational and\u00a0Applied Mathematics, Austrian Academy of\u00a0Sciences, Altenberger Str. 69, 4040\u00a0Linz, Austria\n1 3\nFor this purpose, we train a neural network that takes as input the geometry and boundary conditions, and predicts a relative mesh size field for linear elasticity problems. It is well known that for a complex geometry, certain areas need to be refined more to obtain acceptable accuracy, e.g. around re-entrant corners or near to the areas where fixed boundary conditions are prescribed. Using a machine learning approach for the prediction of mesh refinement has several advantages. First, one can avoid an iterative refinement scheme by obtaining a suitable initial guess directly from the initial model. Furthermore, neural networks (especially convolutional neural networks) allow training on several classes of simple configurations, while they can be evaluated on more complex domains. Based on the output from the neural network, we construct a quadrilateral mesh with local refinement properties. Quadrilateral meshes are adopted because of their superior performance in engineering applications. Moreover, we intend to extend the method to isogeometric discretizations based on (curvilinear) quadrilateral patches. There is a rich literature on this topic, for example automatic generation of high quality quadrilateral meshes from given planar curves [1]. The method emphasizes matching interior and exterior boundaries and avoids distorted quads by introducing angle bounds.\nMachine learning and especially artificial neural networks (ANN) have been employed recently to geometric problems as well as to problems that arise when solving PDEs. For instance, machine learning techniques are employed in model order reduction\u00a0[2, 3], and dynamic model decomposition [4]. Specifically, convolutional neural networks (CNN) are often applied in computational problems\u00a0[5\u20137]. The combination of techniques from computational mathematics and ANN has resulted in interesting contributions for both fields, since the theoretical results from classical approximation theory can be used to derive results on the approximation properties of ANN\u00a0[8\u201312].\nA straight-forward application of deep learning to the solution of PDEs consists of training a neural network to represent the solution of a single boundary value problem\u00a0[13]. Especially for very high-dimensional problems, this approach results in efficient methods, compared to classical Galerkin methods. But ANN cannot only be used to describe the discretization spaces for solutions of a PDE, machine learning techniques have also been used in several ways to facilitate the efficient and accurate solution of PDEs using classical methods, such as FEM. Deep learning has been used for the system matrix assembly in Galerkin methods\u00a0[14] as well as for accelerating the solution process of the resulting system\u00a0[15].\nAnother very promising application of ANN in this context is mesh generation. To ensure an efficient approximation, a locally refined discretization space is often needed. So far, the efforts in this direction have focused on generating\npolygonal/polyhedral meshes for finite element discretizations\u00a0[16\u201319]. In [20] an ANN is trained to predict the mesh quality of a given finite element mesh. In our approach, we train an ANN to predict the optimal local mesh density for a given polygonal geometry that can have holes, and given boundary conditions in the form of one traction boundary and one fixed boundary. Moreover, we study in this paper the dependence of the output of our neural network on the complexity of both the computational domain and different training strategies. We represent all input data, i.e. the domain as well as the boundary conditions, as images, and we employ a convolutional neural network (CNN) that maps to a pixel-wise estimate for the optimal mesh density.\nThe use of images and convolutional neural networks has several advantages: CNNs are able to detect local features in the data, which is especially well-suited to the problem of local refinement. Moreover, it is possible to rescale the models to apply them to different input sizes. Finally, the use of images as our input data makes the method completely independent of the employed scheme for numerically approximating the solution to the PDE. This means that the training data for our model can be produced by using finite elements based on different polygons as well as using isogeometric analysis\u00a0[21]. Moreover, image-based engineering and science is a growing research area. Generating meshes from scanned images has wide applications in computation biology, medicine and materials science [22]. As an example, the construction of quadrilateral and hexahedral meshes from volumetric image data is discussed in [23].\nIn recent works, the concept of CNN has been generalized from planar image data to discrete manifolds and graphs\u00a0[24, 25], resulting in geometric deep learning. This makes it possible to train and evaluate neural networks on data sets that consist of discrete surfaces. These techniques might allow a future generalization of our method to the problem of local refinement on surfaces. However for the processing of planar domains, as we do in the present paper, as well as of volumetric domains, image data and CNNs are more suitable. In particular, the representation of the geometry as an image is more flexible and does not depend on a specific parameterization.\nThe approach we present in this paper is similar to\u00a0[26, 27], where a neural network is used to facilitate the generation of locally refined finite element meshes. The network predicts the distribution of the a posteriori error for a given set of geometry, material properties and boundary conditions, which demonstrates the feasibility of neural networks for generating locally refined meshes. We want to highlight here that the network architecture and the structure of input and output are important factors when generalizing the approach. The approach developed in\u00a0[26, 27] is based on a fully connected neural network with a fixed structure, which encodes the geometry. Thus, the possible geometries are taken from a parameterized family of\n1 3\npossible geometries. In our approach, we consider the domain and input parameters to be images and employ CNNs. Using this setup, we can extend the network to other geometries by incorporating them in the training process, while keeping the network structure fixed. We believe that this facilitates the extension to more complex domains.\nThe remainder of this paper is organized as follows: In Sect.\u00a02, we describe the model problem and objective which we consider throughout the paper. In Sect.\u00a03, we analyze and classify different measures for geometric complexity that occur in the problems that we consider. We describe our methods for generating the training data in Sect.\u00a04 and present the architecture of our neural network in Sect.\u00a05. Finally, we present numerical experiments in Sect.\u00a06, discuss directions for further research on the use of artificial neural networks for generating locally refined meshes in Sect.\u00a07 and conclude the paper in Sect.\u00a08."
        },
        {
            "heading": "2 Problem formulation",
            "text": "Given a computational domain and corresponding boundary conditions, we want to obtain a quadrilateral mesh over which we can define a finite element space to represent the solution of a linear elasticity problem. The goal is to find a mesh that yields a numerical solution of high quality without comprising the computational complexity, i.e., the uniform error should be below a given tolerance and the number of elements should be as small as possible. To do this, we train a neural network that takes as an input the geometry, the Dirichlet and Neumann boundary conditions and whose output predicts the relative local mesh resolution."
        },
        {
            "heading": "2.1 The PDE model problem",
            "text": "As a model problem, we consider the problem of linear elasticity on a planar domain \u03a9 \u2282 \u211d2 with polygonal boundary \u03a9 . The segments \u0393\nD \u2282 \ud835\udf15\u03a9 and \u0393 N \u2282 \ud835\udf15\u03a9 are the Dirichlet\nand Neumann boundaries, respectively, where \u0393 D \u2229 \u0393 N = \ufffd . The governing equations are the equilibrium equation\u00a0(1a), strain-displacement relation\u00a0(1b), and the constitutive law\u00a0(1c):\nIn the governing equations, and denote the stress and the strain tensors respectively, while u \u2236 \u03a9 \u2192 \u211d2 is the displacement field and f \u2236 \u03a9 \u2192 \u211d2 is the body force. The constants and are the Lam\u00e9 parameters that satisfy\n(1a)\u2212\ud835\udec1 \u22c5 = f ,\n(1b) = 1\n2 ( u + uT ),\n(1c) = 2 + ( \u22c5 u)I.\nwhere E is Young\u2019s modulus and is Poisson\u2019s ratio. We moreover consider boundary conditions of the form\nwhere u0 are the prescribed displacements, t is the prescribed traction, and n is the outer unit normal vector to \u0393N . Then, after combining the equations in (1), multiplying by a test function v and applying Green\u2019s theorem, we can derive the weak form of (1) as: Find u \u2208 U such that\nfor v \u2208 V . Here,\nwhere H1 is the space of functions with square integrable derivatives.\nIn this study, we consider two-dimensional problems with fixed isotropic materials under plane stress conditions, with E = 103 and = 0.3 . The body force is set to f = 0 . Moreover, we consider fixed boundary conditions u\n0 = 0\nand pressure loading where t = 10n . Due to the linearity of the problem, different material properties or load magnitudes will still result in similar refinement patterns. We believe that the approach presented in this paper has the potential to be extended to a larger class of PDEs."
        },
        {
            "heading": "2.2 The optimization problem",
            "text": "The aim of our method is to find the optimal mesh density for a given geometry, Dirichlet and Neumann boundaries. This means that the mesh density produced by our method should ideally result in a discretization that achieves an optimal accuracy with a minimum number of degrees of freedom. To formulate this objective in a mathematically precise way is a difficult undertaking, as there is no well-defined notion of optimality for the mesh density. Our proposed method can be regarded as an instance of operator learning. We therefore opt to describe the operator that we want to approximate by referring to a standard adaptive algorithm.\nAs described in the previous section, the input of our method consists of a geometry \u03a9 as well as information\n= E\n(1 + )(1 \u2212 2 ) ,\n= E\n2(1 + ) ,\nu = u0 on \u0393D \u2282 \ud835\udf15\u03a9,\nn = t on \u0393N \u2282 \ud835\udf15\u03a9,\n\u222b\u03a9 2 ( u + uT ) \u22c5 ( v + vT ) d\u03a9 + \u222b\u03a9 ( \u22c5 u)( \u22c5 v) d\u03a9\n= \u222b\u03a9 v \u22c5 f d\u03a9 + \u222b\u0393N v \u22c5 t d\u0393\nU = {u \u2208 (H1)2 \u2236 u = u 0 on \u0393D} and\nV = {v \u2208 (H1)2 \u2236 v = 0 on \u0393D},\n1 3\non the fixed boundary \u0393 D \u2282 \ud835\udf15\u03a9 and the traction boundary \u0393 N \u2282 \ud835\udf15\u03a9 . We denote the set of possible input data as X, where each element\nconsists of a geometry and the Dirichlet and Neumann boundaries.\nThe operator that we want to approximate is therefore of the form\nwhere\nand an element dx \u2208 Dx is a function dx \u2236 \u03a9 \u2192 [0, 1] that represents a relative local mesh density.\nThe precise definition of the operator F depends on the chosen method for generating the locally refined mesh. For a data point x \u2208 X , we denote by Wx the set of possible discretizations for solving the PDE using our chosen computational method. In our examples, Wx is the set of quadrilateral meshes that exactly represent the boundary \u03a9.\nWe write\nand we denote by\nan algorithm for generating a discretization for the given input data. For example, A can be a classical adaptive method based on solving the PDE, marking, and refining the elements iteratively until a stopping criterion is reached. The operator F is therefore defined as\nwhere\nmaps a discretization to its local relative mesh density. Since it is fully deterministic, the operator F can be easily evaluated by applying the refinement algorithm A. However, since the evaluation of A typically consists of solving the PDE multiple times on meshes with increasing mesh density, this can be prohibitively computationally complex. Therefore, we want to find a way to evaluate (or approximate) F in an efficient way. Since it is a highly non-linear operator that is impossible to evaluate directly, we opt to approximate F with an artificial neural network FNN.\nTo be able to use neural networks based on convolution, we consider as a discretized input a discrete approximation\nx = (\u03a9,\u0393D,\u0393N) \u2208 X\n(2)F \u2236 X \u2192 D,\nD = \u22c3 x\u2208X Dx\nW = \u22c3 x\u2208X Wx\n(3)A \u2236 X \u2192 W\nF(x) = D\u25e6A(x),\nD \u2236 W \u2192 D\nof x = (\u03a9,\u0393D,\u0393N) at a fixed grid of points ( 1,\u2026 , N) \u2208 \u03a9 , i.e., an image. Likewise, we regard the mesh density as a discrete function at the same set of points. Therefore, for an input x \u2208 X and target mesh density dx , the loss function can be defined as:\nDuring the training, we try to find the optimal approximation FNN by optimizing the network parameters. Since we select the data points i as uniformly spaced, we investigate the use of image-based convolutional networks such as U-net, which are described in detail in Sect.\u00a05."
        },
        {
            "heading": "3 Training strategy and\u00a0data representation",
            "text": "As shown in Sect.\u00a02.2, the problem of finding an optimal mesh density is complicated and largely depends on the domain \u03a9 as well as the boundary conditions. The basic idea of our training strategy is to train the network with simple geometries, for which one can more easily obtain target discretizations. The trained network can then be applied to more complex domains. In this section, we give an overview of several measures of geometric complexity, the training strategy and the data representation."
        },
        {
            "heading": "3.1 Measures of\u00a0complexity",
            "text": "Since in our model problem we restrict ourselves to constant coefficients and zero body forces, the complexity of the mesh generation problem depends largely on the complexity of the domain. While there is no way to objectively quantify the complexity of a geometry in this context, we aim to categorize possible input geometries by a number of measures corresponding to different aspects of geometric complexity.\nOne important advantage of using neural networks for this problem is their potential to generalize knowledge obtained from training on data from a number of simple data classes to complex unseen data. We consider computational domains whose geometric complexity is measured using the following criteria:\n\u2022 Convexity: Domains with only convex boundaries and domains with non-convex boundaries. \u2022 Genus: Simply connected domains and domains with a number of k holes. \u2022 Smoothness of Boundary: Domains with polygonal boundaries and domains whose boundaries are piecewise polynomial curves of degree d \u2265 2.\n(4)L = N\u2211 i=1 ( FNN(x)( i) \u2212 dx( i) )2 .\n1 3\nFor each of the geometric complexity criteria we consider a few simple cases, which are listed as follows:\nWe then obtain geometric complexity classes, which we can denote with triples\nwhere e.g., (0,\u00a00,\u00a00) represents convex, simply-connected, polygonal domains, (1,\u00a02,\u00a00) represents non-convex polygonal domains with holes or (0,\u00a00,\u00a01) represents convex, simply-connected, spline domains. We randomly generated 10,000 sets of data each for the geometric complexity classes (0,\u00a00,\u00a00) and (1,\u00a00,\u00a00). While for the classes (0,\u00a0k,\u00a00) and (1,\u00a0k,\u00a00), which have higher geometric complexity, we generated 20,000 sets of data each. We then train and validate the neural networks by a random 90% - 10% split between the training and testing data.\nWhile we restrict ourselves to these criteria in this paper, the method can be extended arbitrarily by adding more criteria of complexity. Possible generalizations are discussed in more detail in Sect.\u00a07. Furthermore, when applying the method in practice, using real-world training data, the choice of geometric complexity classes does not need to be a conscious decision, as the network can learn from any data in the available data set."
        },
        {
            "heading": "3.2 Training strategy",
            "text": "In this study, we aim to train the neural networks such that they recognize the following refinement rules:\n\u2022 The refinement should be concentrated at points where the stress values are expected to be high, such as the reentrant corners and at the endpoints of the Dirichlet boundary. \u2022 The refinement level depends on the position of the corner relative to the Dirichlet and Neumann boundaries. \u2022 The strength of the refinement also depends on the length of the support and traction boundaries and on their relative position.\nInstead of trying to implement these rules directly, we consider a more general data driven approach. A data set that contains domains of all possible geometric complexity classes, i.e., combinations of cases of complexity criteria listed in Sect.\u00a03.1, would need to be unfeasibly large and\n\u201cConvexity\u201d =\n{ 0 if the outer boundary is convex,\n1 if the outer boundary is non-convex,\n\u201cGenus\u201d = k \u2208 {0, 1, 2}, where k = number of holes,\n\u201cSmoothness of boundary\u201d =\n{ 0 if all boundaries are polygonal,\n1 if at least one boundary curve is a spline.\n(\u201cConvexity\u201d, \u201cGenus\u201d, \u201cSmoothness of boundary\u201d),\ntherefore difficult to generate and process. In this study, we exploit the neural network\u2019s potential for generalization to\nunseen data to handle complicated domains that are complex in more than one of these classes.\nWe train the neural network on a data set that consists of domains that are simple in all but one of the different classes of geometric complexity. When evaluating the network on a domain that is complex in more than one of the listed classes, the network is able to apply the knowledge learned from this training data also to this case. An example is given in Sect.\u00a06.5, where the training data set contains convex polygonal domains with one hole as well as nonconvex polygonal domains without holes (i.e., the classes (0,\u00a01,\u00a00) and (1,\u00a00,\u00a00), respectively). When evaluating the network on a domain that is non-convex and has several holes, e.g. from the class (1,\u00a02,\u00a00), the network can give a good prediction, although it has never seen such a domain."
        },
        {
            "heading": "3.3 Data representation",
            "text": "In our method, we represent the input as well as the output of the neural network as pixel-based images. This choice leads to two significant advantages: On the one hand, we can employ powerful deep learning techniques that have been developed for image processing in the recent years. In particular, we can use convolutional neural networks and related network structures. On the other hand, using only image data makes our method completely independent from the representation of the geometry and from the discretization spaces that are used for solving the partial differential equation numerically.\nFor example, training data for our method can be obtained using a finite element method, isogeometric analysis, or any other adaptive method for solving PDEs. Likewise, the trained neural network has the potential to guide the generation of locally refined meshes for any of these numerical methods. What has to be taken into account is the interpretation of the output data and translation into a locally refined mesh. Since we train our method with bilinear finite elements over quadrilaterals, the local mesh grading needs to be adapted for higher order or isogeometric elements.\nThe input of our neural network consists of three grayscale images of the same resolution: One image contains the geometry of the computational domain \u03a9 . The other two images contain only the Dirichlet boundary \u0393D and the\n1 3\nNeumann boundary \u0393N , respectively. See Fig.\u00a01a\u2013c for an example input data. The output of the network consists of a single grayscale image of the same size as the input data. The scalar value assigned to each pixel represents the network\u2019s prediction of the local mesh-size at that point of the input image representing the computational domain, see Fig.\u00a01d."
        },
        {
            "heading": "4 Data generation and\u00a0adaptive refinement",
            "text": "In this section we explain how the training data sets, that is, the input geometry and the target mesh density, are generated."
        },
        {
            "heading": "4.1 Generating the\u00a0geometry",
            "text": "We have two generators which generate the data for geometry classes with varying Convexity and Genus (as discussed in Sect.\u00a0 3.1), i.e., for classes {(i1, i2, 0), i1 \u2208 {0, 1}, i2 \u2208 {0, 1, 2}} . In the following, we describe the procedures that we use to generate geometries for different geometric complexity classes. More precisely,\nwe produce random convex polygonal domains, non-convex domains as well as domains with voids.\nTo create a domain with a convex boundary, we first generate n sample points distributed randomly within the unit square. In our implementation we use n = 30 for all training data sets. The domain is then given by the convex hull of the point set, see Fig.\u00a02a, where the blue dots are the sampled points and the black line represents the boundary of the convex hull. The blue dots that lie on the black line are the vertices of the convex hull. They are used to construct a quadrilateral mesh in Gmsh, as shown in Fig.\u00a02b.\nIn Fig.\u00a03a, we illustrate the creation of a non-convex domain as a union of two convex domains. Two rectangles that intersect and lie within the unit square are first created. Then, as described above, a convex domain is created for each rectangle as the convex hull (represented by the red polygon) of random sample points. The non-convex domain is then given as the union of the two convex sub-domains; the corresponding mesh is shown in Fig.\u00a03b. If the resulting domain is not simply connected and non-convex, it is discarded.\nCreating a domain of non-zero genus is illustrated in Fig.\u00a04. First, a random convex or non-convex domain is\n1 3\ngenerated, which is then divided into two or more subdomains. In Fig.\u00a04a, a convex domain (blue polygon) is divided into two sub-domains by the dashed lines. The division lines are created by randomly selecting points that lie on the boundary of the unit square (marked by stars) and connecting them to the center of the polygon (marked by the blue dot). Then, for each sub-domain, a small convex domain is created (represented by the red polygon), again as the convex hull of random sample points (with n = 10 ). These small domains are then cut out from the main polygon, forming the voids. Figure\u00a04b shows the resulting mesh.\nThe boundary conditions are generated by randomly selecting two edges from the domain. Here we only consider the outer boundary of the domain. The restriction that we make is that the two boundaries should not be adjacent to each other. One of the selected boundaries is set as the Dirichlet boundary, while the other is set as the Neumann boundary. The domain as well as the edges selected to impose boundary conditions are converted to images which are used as input for the considered data set, cf. Figure\u00a01.\nOnce the domain is constructed and the boundary conditions are fixed, we create an initial mesh over the domain\nand perform a numerical simulation for the linear elasticity problem (see Sect.\u00a02.1 for more details) using a finite element solver. This is explained in more detail in the following subsection."
        },
        {
            "heading": "4.2 Generating the\u00a0target mesh density",
            "text": "For each domain, the sampled points that lie on the boundary are selected and used to construct an initial mesh using Gmsh1. Gmsh is an open-source program written in C++ with an extensive Python interface. It produces unstructured triangular and quad (or mixed) meshes based on a given boundary representation. In our experiments, an all-quad mesh is constructed from a triangle mesh by subdivision.\nFor the numerical analysis we use SolidsPy2 which is written in Python/NumPy. It is an educational software which is easy to use and modify. SolidsPy supports triangle and quad meshes. In addition, it performs stress averaging\nFig. 4 Example of generating a domain with voids (of class (0,\u00a02,\u00a00))\n1 https:// gitlab. onelab. info/ gmsh/ gmsh/-/ blob/ master/ api/ gmsh. py 2 https:// github. com/ Appli edMec hanics- EAFIT/ Solid sPy\n1 3\nfor plotting continuous stress fields. For the given mesh and boundary conditions, information such as displacement, stress and strain can be obtained. The von Mises stress can be computed from the xx , yy and xy stress fields.\nTo obtain an adaptively refined mesh, we use a uniformly refined fine mesh M\u2217 for a heuristic error estimation. Consider a mesh M at level . The von Mises stress is computed on the mesh M and on M\u2217 . By using the error between the fine and coarse solution measured at every vertex of M , we generate a mesh size field B as follows:\nIn (5), and avg represent the maximum edge length and average von Mises error on each element, while max denotes the global maximum von Mises error in the mesh. We refer to the Gmsh tutorial3 for using the estimated mesh size field B to create an updated mesh M\n+1 . An example of adaptive refinement obtained using the method as described above is shown in Fig.\u00a05, where the meshes are adaptively refined from Fig.\u00a05a\u2013d. In the figures, the Dirichlet and Neumann boundary are highlighted in green and red respectively, while the red arrows indicate the traction direction. We choose this heuristic refinement approach to reduce the influence of the initial mesh and of the refinement procedure that is usually present for adaptive schemes based on marking elements."
        },
        {
            "heading": "5 Network architecture",
            "text": "In the following we discuss the structure of the neural network architecture that we use in this paper. Usually, neural networks are built up of layers sequentially. The network receives an input which is transformed through a series of hidden layers followed by an output layer. The hidden layers\n(5)B = ( 1 \u2212 avg\n2 max\n) ,\nand the output layer are made up of neurons associated with weights and biases. Each neuron takes as input the outputs of the neurons of the previous layer. The output of the neuron is given as the composition of an affine linear combination of the input values (taking the weights as coefficients and adding/subtracting the bias), composed with an activation function. The composition of several such layers yields a non-linear function if the activation function is non-linear. In case of a fully connected neural network, each neuron takes as input all neurons from the previous layer (with possibly non-zero weights).\nThe weights and biases of all the neurons are the degrees of freedom which are trained, i.e., for which one optimizes. The entire network is then trained based on a given set of input and target data, and the weights and biases are optimized with respect to a given objective. The objective is described in terms of a scalar-valued loss function. The aim of the training is to find the parameters (weights and biases) which minimize the loss function by using gradient descent type methods. Computing the gradients is accomplished by reverse-mode differentiation (back-propagation).\nWhile fully connected neural networks are useful for solving many optimization problems, when handling higher dimensional data, they tend to result in a huge number of parameters and can lead to overfitting. Therefore, when the data possesses some local structure which is of relevance for the output of the network, one can use neural networks based on convolution."
        },
        {
            "heading": "5.1 Convolutional neural networks",
            "text": "Convolutional neural networks (CNN) are explicitly used for working with 2D or 3D data such as images. CNNs are commonly used for image classification. Spatially coherent features such as corners and lines in the images are identified and combined to predict an associated label or category. Similarly to fully connected neural networks, they are formed by sequences of layers. An example of a CNN is illustrated in Fig.\u00a06. It contains an input (green block), a\n3 https:// gitlab. onelab. info/ gmsh/ gmsh/-/ blob/ master/ tutor ials/ python/ t10. py\n1 3\nconvolution layer (blue block), and an output (red block). In the convolution layer, the filter is formed by neurons arranged in three dimensions. The filter \u201cslides\u201d over the input, performing element-wise multiplication with the current part of the input (highlighted with dark green in Fig.\u00a06), and resulting in a local output (highlighted with dark red in Fig.\u00a06).\nThe output size is determined by several factors including the filter size, input size, padding and stride. Padding refers to adding additional boundary data surrounding the image. It is commonly used for reducing border effects. Stride is defined as the number of steps the filter moves in the convolution. Suppose the input size is given by WI \u00d7 HI \u00d7 DI , convoluted with a WF \u00d7 HF \u00d7 DF filter, P padding, and S stride will produces output of size [(WI \u2212WF + 2P)\u2215S + 1] \u00d7 [(HI \u2212 HF + 2P)\u2215S + 1] \u00d7 DF . Meanwhile, techniques such as pooling and regularization can be added to the network for deep learning enhancement."
        },
        {
            "heading": "5.2 The U\u2011net architecture",
            "text": "In this study, we develop a network to learn the mesh density operator by using the U-net architecture\u00a0[28]. The network consists of two parts: contracting and expanding. The first part is formed by encoder blocks which downsample the data, while the second part contains decoder blocks which upsample the data. Each block consists of convolution layers (transposed convolutions for the decoder block), and batch normalization. The two parts are connected by a bottleneck block which has a max pooling layer followed by convolution, and batch normalization. The U-net for training the data is illustrated in Fig.\u00a07. We adopt U-net architecture because it is capable of capturing the contents and enables precise localization. The contracting part of the U-net is the same as a general CNN which extract features such as reentrant corners, and the relative location of the Dirichlet and Neumann boundaries from the inputs. The network then up-samples its hidden layers to create a gray scale image. The gray\nscale image will have intensity values ranging from 0 to 1, which indicate the relative mesh resolution. This architecture allows the network to combine features from different spatial regions of the images and to localize more precisely the mesh resolution at the region of interest.\nThe main difference between the U-net architecture as in\u00a0[28] and the U-net architecture used in this study is that, in our case, there is only one max pooling layer located at the bottleneck block. The low-level feature map from the convolution layers and the precise position of the features in the inputs are important for meshing which is sensitive to geometry. For this reason, we limit the use of pooling having the effect of making the representation become approximately invariant to small translations of the input [29].\nWe control the down-sampling through padding and striding in the convolution. We apply 2 strides which reduce the size of the convolution output by half, therefore, reducing the image size as the algorithm is moving downward in the contracting path. At the end of the contracting path, the size is reduced to 4 \u00d7 4 . Max-pooling is then used to further down-sample to 3 \u00d7 3 followed by de-convolution, which is the reverse of convolution in terms of dimensions change at each layer in the expanding path. For the decoder block, the filter size, padding and stride are selected such that the tensor size matches with the contracting path in reverse order. Concatenation is used to add the tensors of matching size between contracting path to expanding path. The final output is a 60 \u00d7 60 image with a single channel. We set the depth of the filter at the first encoder block to DF = 32 . It is doubled from one block to the next in the contracting part. At the max pool block, the depth is increased to DF = 512 . The depth is then decreased by half until DF = 32 at the last decoder block. Output samples from the U-net are given in Fig.\u00a08. Each encoder, decoder and max pool block provides\n1 3\na group of outputs. The image resolution and the number of layers are different after each block. For example, the resolution decreases and the depth is increasing from one encoder block to another. For each group, we show a representative layer (slice through the depth) and label the actual size."
        },
        {
            "heading": "5.3 Model evaluation",
            "text": "In this study, we seek for the operator that maps given geometry and boundary conditions to an optimal (adaptive) mesh density. The inputs and outputs are stored as grayscale images which can be converted to matrices of a fixed size corresponding to the image resolution. The mean square error is used as the regression loss function. It is defined by\nwhere x refers to the intensity value at pixel i, and n is the number of pixels."
        },
        {
            "heading": "6 Numerical examples",
            "text": "We conduct some experiments for testing the proposed mesh density estimation method. By using the U-net as discussed in Sect.\u00a05.2, we train six models. The first four models are Model(0,\u00a00,\u00a00), Model(0,\u00a0k,\u00a00), Model(0,\u00a0k,\u00a00), and Model(1,\u00a0k,\u00a00), k \u2208 {1, 2} , where the associated triplets (introduced in Sect.\u00a03.1) indicate the geometry complexity classes used for training. Since each of these models are trained with data restricted to simple geometries or\n(6)MSE = \u2211n i=1 (xi \u2212 x p i )2\nn ,\ngroups of highly related geometries, they are expected to yield more accurate results. However, this choice requires that the underlying complexity class of the example must be known beforehand. Thus, it is more reasonable to have models trained for all possible geometric complexity classes. Here we examine two extended models which are referred to as Model with Reduced Training (Model RT) and Model with Complete Training (Model CT). They are trained using combinations of classes as listed below:\n\u2022 Model RT: (0,\u00a00,\u00a00), (1,\u00a00,\u00a00) and (0, k, 0), k \u2208 {1, 2} \u2022 Model CT: (0,\u00a00,\u00a00), (1,\u00a00,\u00a00), (0, k, 0), k \u2208 {1, 2} and\n(1, k, 0), k \u2208 {1, 2}\nWhile Model CT covers all possible cases, model Model RT is easier to train, as no training data of high complexity (1,\u00a0k,\u00a00), k \u2208 {1, 2} , needs to be constructed. Nonetheless it may be applied to examples of high complexity.\nA comparison of ground truth and output for all the models are given in Sect.\u00a06.2. In Sects. 6.3 and 6.4 show the results of Model(0,\u00a00,\u00a00) and Model(1,\u00a00,\u00a00) handing simple geometric domain. The different effect of Model(1,\u00a0k,\u00a00), Model RT and Model CT on a complex geometry domain is given in Sect.\u00a06.5. Meanwhile, an example with smooth boundary is shown in Sect.\u00a07.1.1, which demonstrates the generalization properties of the corresponding Model(0,\u00a0k,\u00a00). Finally, the overall performances are quantified by using histograms in Sect.\u00a06.6. We also show the plot of the loss function vs. training epochs for the models at the end of this section. In the following section we introduce the error measures that we consider.\n1 3"
        },
        {
            "heading": "6.1 Error measures",
            "text": "We used relative error for evaluation of predicted output. Let IG and IP be the np \u00d7 np matrices representing the ground truth and predicted output images respectively, where np is the number of pixels in each space direction. Here IG\nij \u2208 [0, 1]\nand IP ij \u2208 (0, 1] denote the value of the mesh size for the subdomain covered by the pixel with index ij. We separate the image into two disjoint subdomains \u03a9I and \u03a9O , where \u03a9I denotes the pixels which are (at least partially) in the computational domain and \u03a9O denotes the pixels which are completely outside the domain. Furthermore, we set IG\nij = 1\nfor the pixels which belong to \u03a9O , whereas IG ij < 1 for pixels \u03a9I . For a given domain and set of boundary conditions, the accuracy of predictive mesh size is evaluated by using relative error ( rel ) between the ground truth and the preprocessed output ( \u0303IP ) defined by:\nwhere I\u0303P is obtained by setting IP ij within \u03a9O to be 1 and || \u22c5 || denotes the L2 norm. I\u0303P is adopted for calculating rel such that only the computational domain of interest is considered when computing the error.\nFor validation of the linear elasticity solution, we calculate the error in the relative energy norm of the finite element solution [30]. It is defined in terms of exact stress , computed stress h , and coefficient matrix D written in Voigt notation as:\nand"
        },
        {
            "heading": "6.2 Comparison of\u00a0relative error",
            "text": "As mentioned previously, the idea of the proposed method is to provide the geometry and boundary conditions as input (in the form of images) to the network and receive a gray scale image (the predicted mesh size density) as output. Here, we compare of relative error between the predicted output and ground truth from the different models. Figure\u00a09 shows the average relative error computed on the test data set for geometric complexity classes as labeled on left side of figure.\n(7)\ud835\udf00rel = \u2016\u2016IG \u2212 I\u0303P\u2016\u2016 \u2016\u2016IG\u2016\u2016\n(8)erel =\n\u221a 1\n2 \u222b \u03a9 ( \u2212 h)TD\u22121( \u2212 h)d\u03a9\n\u221a 1\n2 \u222b \u03a9 TD\u22121 d\u03a9\nD = E\n1 \u2212 2 \u23a1\u23a2\u23a2\u23a3 1 0 1 0 0 0 0.5(1 \u2212 ) \u23a4\u23a5\u23a5\u23a6 .\nThe blue bars in the chart are the results from models trained with the respective data sets, i.e. Model (0,\u00a00,\u00a00), Model (1,\u00a00,\u00a00), Model (0,\u00a0k,\u00a00), and Model (1,\u00a0k,\u00a00). They always have the smallest average relative error. The green bars are the results from Model RT. Model RT results in higher relative error for test data sets (1,\u00a00,\u00a00) and (1,\u00a0k,\u00a00). This is because there are fewer data with non-convex boundaries used for training this model. The red bars are the results from Model CT. Although this model is trained with data from all possible geometry complexity classes, it results in higher relative error. The reason is that the network learns better when the training data is consistent. Nonetheless, Model CT could be useful for prediction of mesh size density when there is no information given on the geometry complexity class."
        },
        {
            "heading": "6.3 Example for\u00a0geometric complexity class (0,0,0)",
            "text": "In the following, we examine the mesh discretization constructed based on the predicted output. We will start with showing the result from Model(0,\u00a00,\u00a00) which is trained with a simple geometry complexity class. The adaptive mesh, the mesh constructed from the predicted output, and the uniform refinement mesh are shown in the first row of Fig.\u00a010. The meshes are constructed such that they have approximately the same number of elements. The boundary marked with green color represents the Dirichlet boundary. The Neumann boundary is highlighted with red and the arrows denote the traction direction. The figures below each mesh show the corresponding von Mises stress. The relative error between the ground truth and predicted output is rel = 0.019728.\nIt is shown in Figs.\u00a010a and 10b that the predicted output has very similar mesh density distribution to the adaptive mesh (finer mesh size around the Dirichlet boundary and at the end points of the Neumann boundary). However, it does not capture the high stress around the end points of the Dirichlet boundary well (See Fig.\u00a010f). On the other hand, the uniform mesh in Fig.\u00a010d shows a higher stress at\n1 3\nthe corresponding areas (See Fig.\u00a010f). The reason is that for certain geometries, the uniform mesh contains smaller quads around the corner for better shape approximation. Therefore it is able to capture the high stress if it occurs at those corners. Nonetheless, we can improve the predicted mesh by post-processing the network output. The output is scaled using a piecewise linear function such that for intensity values lower than 0.02, we scale the value by a factor of 0.25. The post-processed result is shown in Fig.\u00a010c. It is shown in the corresponding von Mises stress distribution (Fig.\u00a010g) that the mesh better resolves the high stress region near the Dirichlet boundary. Meanwhile, this locally increased refinement also results in fewer and coarser elements in other areas, as a result of imposing a constraint on the number of elements. The comparison of number of elements and relative error in energy norm ( erel ) are given in Table\u00a01. Note that the error is mostly concentrated in the region with high stresses near the fixed boundary."
        },
        {
            "heading": "6.4 Example for\u00a0geometric complexity class (1,0,0)",
            "text": "In this example shows the result from Model(1,\u00a00,\u00a00). The comparison of adaptive, predicted and fine uniform meshes and their von Mises stress are given in Fig.\u00a011. For this example, the relative error between predicted output and ground truth is given by rel = 0.009530 . The predicted and\nadaptive meshes match fairly well in the domain especially around the Dirichlet boundary. The relative errors in energy norm for the adaptive, predicted, and uniform meshes as listed in Table\u00a02 also demonstrate the capability of proposed method for mesh density prediction."
        },
        {
            "heading": "6.5 Example for\u00a0geometric complexity class (1,2,0)",
            "text": "Here we show an example with complex geometry. It is a non-convex domain with two voids. The comparison of adaptive mesh, uniform mesh and predicted output from Model(1,\u00a0k,\u00a00) are shown in the first row of Fig.\u00a012. The figures below the meshes are the corresponding von Mises\nstresses. In this example, we also compare predicted outputs from Model RT and Model CT. The resulting meshes and von Mises stress are shown in Fig.\u00a012g\u2013j. The predicted output from Model (1,\u00a0k,\u00a00) has the relative error rel = 0.014139 . Model CT results in a slightly lower relative error rel = 0.012991 . An interesting observation is that the results from Model RT ( rel = 0.014128 ) are very close to Model(1,\u00a0k,\u00a00). Geometric complexity class (1,\u00a02,\u00a00) is not included in the training data set for Model RT, but the Unet is able to approximately resemble the higher mesh density around the holes. This demonstrates the generalization capability of the network, which is an advantage of the proposed data-driven mesh density prediction method.\nThe number of elements and relative errors in energy norm for all the meshes are listed in Table\u00a03. We can observe that when the input has complex geometry, the complete training model (Model CT) can indeed provide a better discretization results."
        },
        {
            "heading": "6.6 Evaluation of\u00a0models",
            "text": "For a given predicted output, we construct a uniform mesh with approximately the same number of degrees of freedom, such that: \u2016DOFs\nU\u2212DOFsP\u2016 DOFsP\n<0.05 where DOFsU and DOFsP represent the degrees of freedom of the uniform\nand predicted meshes. We then quantify the solution computed on the predicted mesh over the uniform mesh by using the ratio of errors in the energy norm as follows:\nwhere eU rel and eP rel refer to the relative error in the energy norm (8) of the uniform and predicted mesh, respectively. The rational functions RU is interpreted as:\n\u2022 RU \u2248 1 : both meshes have similar analysis accuracy. \u2022 RU < 1 : the uniform mesh possesses better analysis accu-\nracy. \u2022 RU > 1 : the predicted mesh has better analysis accuracy.\n(9)RU = eU rel\neP rel\n1 3\nThe distributions of RU for Model(0,\u00a00,\u00a00), Model(1,\u00a00,\u00a00), Model(0,\u00a0k,\u00a00), and Model(1,\u00a0k,\u00a00) are shown in Fig.\u00a013. Each histogram shows the results of RU computed on 100 sets randomly selected test data from the corresponding geometric complexity classes. There are some cases where both meshes have similar accuracy, or the uniform mesh has better accuracy. However, the right-skewed distribution indicate that the predicted mesh performed better in most of the cases.\nFinally, the training log for all the models that we discussed above is given in Fig.\u00a014. In the figures, the red line and blue dashes represent the training log and validation log respectively. Note that we used the U-net architecture as discussed in Sect.\u00a05.2 to train different group of data (i.e. different geometry complexity classes). To avoid overfitting, the training process is terminated when validation loss started to increase. It is shown in the figure that all the training and validation losses converge at very similar rates. A likely cause for this effect is the homogeneity of data, in the sense that cases of equal difficulty are included in the testing and training sets. Although the data sets are randomly generated, they belong to the same or very similar geometric complexity classes."
        },
        {
            "heading": "6.7 Comparison with\u00a0MeshingNet on\u00a0a\u00a0test geometry",
            "text": "In the following, we demonstrate the proposed method\u2019s capabilities for handling geometries obtained from image data. We compare our approach with the approach presented in\u00a0[26]. We present the results of our method in Figs.\u00a015 and\u00a016, which are both obtained from the image of the domain given in Fig.\u00a07 of\u00a0[26]. Note that the linear elasticity problems in\u00a0[26] are set in such a way that the Dirichlet boundary is formed by two edges and the Neumann boundary is formed by one edge. Since our models are trained with one edge for each of the Dirichlet and Neumann boundaries, we set the boundary conditions in the following examples to be compatible with the trained models.\nFigs.\u00a0 15 and 16 show two examples where each is assigned one of the Dirichlet edges given in [26]; whereas the Neumann boundary is set at the same position. In the two figures, the Dirichlet and Neumann boundaries are highlighted with green and red, respectively. We can observe that both predicted meshes (Figs.\u00a015b and 16b) are finer around the Dirichlet boundary. The locations where stress values are expected to be high can be predicted accordingly and the analysis results from the output meshes have lower relative energy norms compared to uniform meshes. Tables\u00a04 and 5 show the comparison of the number of elements for each mesh and the relative energy norm computed by using the adaptive mesh as the reference solution. We point out that the predicted mesh might not match perfectly with the adaptive refinement mesh. This is because the latter is computed using exact geometry, while the predicted local refinement is based on coarse resolution images.\nThis study and [26] both introduce machine learning approaches for meshing problems. However, we focus on different aspects. In [26], the domain is restricted to be a polygon with 6-8 edges. In addition, the Dirichlet boundaries are fixed at the 4th and 5th edge, while the 1st edge is always set as the Neumann boundary. But, the model has the option of setting different (homogeneous) material properties and traction with random amplitude up to 1000. Since the underlying problem is linear, we assume that these inputs do not significantly affect the relative mesh density. However, the optimal mesh grading may be affected. Thus, to improve the results we also discuss extensions using varying PDE parameters in Sect.\u00a07. Our method emphasizes handling a larger variety of geometries ranging from convex to nonconvex and domains with voids. We restrict our model to impose boundary conditions only on non-adjacent edges to avoid the singularity formed at the points where the Dirichlet and Neumann boundaries join. Nonetheless, the proposed method can also be extended to work with other boundary conditions by simply adding new data in the training process.\n1 3\n1 3"
        },
        {
            "heading": "7 Discussion and\u00a0future work",
            "text": "A key strength of our method is that it can be extended in a vast number of possible directions. These include the application to more complicated model problems as well as the use of different discretization techniques for solving partial differential equations.\nThere are two possible ways of extending our approach: Either, we generate training data for more general cases or we modify the network architecture itself, summarized in Sects.\u00a07.1 and\u00a07.2, respectively."
        },
        {
            "heading": "7.1 Extension by\u00a0adding training data",
            "text": "The measures of geometric complexity that we consider in Sect.\u00a03.1 can be extended in many ways by generating more training data sets. For example, in Sect.\u00a04.1 we restricted our data set to contain only problems where the fixed and the traction boundary are not adjacent. However, this restriction may be dropped by properly extending the training data set. Similarly, one may train with several edges marked as fixed and/or several edges marked as traction boundary."
        },
        {
            "heading": "7.1.1 Extension to\u00a0curved boundaries",
            "text": "Another possible extension is the application to domains with curved boundaries. To visualize, we present an example for geometric complexity class (0,1,1). We use a wellknown benchmark problem (the square plate with circular hole) to demonstrate this generalization of the proposed data driven method. As mentioned in Sect.\u00a04.1, the data used for training are defined by polygons. Smooth boundaries such as circular voids are \u2019new\u2019 to the trained model. We observe that the model predicts a larger mesh size for such a type of geometry that it has not encountered before; this leads to a higher relative error rel = 0.08481937 . The mesh constructed using the predicted output has very similar mesh size distribution pattern as the adaptive mesh (i.e. a finer mesh around the hole). While the relative error in the energy norm from the predicted mesh and uniform mesh are very close (see Table\u00a06); it is shown in Fig.\u00a017h that the predicted output mesh has better von Mises stress approximation around the hole compared to a uniform mesh (see Fig.\u00a017i).\n1 3\nRefinement Number of elements Relative error in the energy norm\nMaximum value of von Mises stress\nAdaptive 3153 \u2013 829.819385 Predicted 3147 0.067127 570.675438 Uniform 3138 0.090880 539.449472\n1 3\nOn this example one can see that the network can be applied to unseen data, such as curved boundaries, and that the output mesh density is suitable, but not necessarily as good as an adaptive fit. Visually, the output density distribution is similar to the adaptive mesh used as training data, but more uniform. This effect may be reduced by post-processing the output image. Moreover, including domains with curved boundaries also in the training data for the network will most likely improve the result."
        },
        {
            "heading": "7.1.2 Beyond finite element methods",
            "text": "Most importantly, we intend to extend our method to discretization techniques beyond finite element methods, such as isogeometric analysis, which was introduced in\u00a0[21]. While the network can be trained on data generated from any kind of adaptive numerical method, it can then be applied to any space of locally refinable discretizations, such as linear finite elements, multi-patch splines, THB-splines\u00a0[31] or (unstructured) T-splines\u00a0[32, 33]. Since B-splines (and derived concepts) rely on a patch structure, where each patch is tensor-product, refinement becomes more involved. Each patch may be refined in a tensor-product fashion or using e.g. hierarchical B-splines or T-splines. While the latter two are more flexible, a fully tensor-product refinement for each\npatch is significantly easier to generate. Moreover, the subsequent assembly and solution of the resulting linear system is also faster. Thus, the multi-patch segmentation should be selected a-priori such that a tensor-product refinement is as efficient (with respect to the number of degrees of freedom) as a local refinement scheme using e.g. THB-splines. Hence, it may be of interest to encode not only the local mesh size, but to also obtain information on the mesh anisotropy. If in a region of the domain the local refinement direction is clear, one may fit a patch such that its parameter lines correspond to that direction. Such a segmentation may be performed using classical methods\u00a0[34, 35] or using machine learning as well."
        },
        {
            "heading": "7.1.3 Improved training strategies",
            "text": "The framework of our approach is given in such a way that, once the family of PDE problems (including material parameters, possible boundary conditions etc.) is set up and the image dimensions are chosen, the neural network can be trained based on the requirements of the users. We envision a continuous training strategy, always improving the network by including additional model geometries (or families of geometries) based on user experience and user demand. This\n1 3\nway, the network architecture does not need to change when new types of input data are considered.\nAnother way to continuously improve the output of the network is by generating training data obtained from improved adaptive refinement schemes. Currently, we use a heuristic scheme, presented in Sect.\u00a04.2, which may be replaced by a (quasi-)optimal local refinement scheme."
        },
        {
            "heading": "7.2 Generalizations that\u00a0require a\u00a0modified network structure",
            "text": "In the following we discuss possible generalizations that require a new network structure, increasing the number of input/output layers or the changing their dimensions. In some cases, the previously trained networks may be modified, in other cases a new network may need to be set up."
        },
        {
            "heading": "7.2.1 More general model problems",
            "text": "In this paper we restrict ourselves to linear elasticity on a planar domain without body forces and constant boundary conditions along the traction boundary and fixed boundary. While this is already a challenging problem, our method is by no means restricted to this case.\nSince we focus on a representation of the domain as an image, it is possible to encode varying parameters of the PDE or of the boundary conditions as color (or grayscale) images. Similarly, body forces can be included. Besides the variations in geometric complexity, it is then also of interest to vary the complexity of the PDE. As with the geometric models, one can define suitable complexity classes by hand, such as vanishing or non-vanishing body forces, constant or varying parameters etc. Alternatively, one may use a library of problems with known (or desired) solutions as a guide."
        },
        {
            "heading": "7.2.2 Pre\u2011 and\u00a0post\u2011processing of\u00a0input and\u00a0output",
            "text": "In the following we also want to highlight how the algorithm may be improved by properly processing the input and output. Since the network is set up such that both input and output are images, pre- and post-processing steps from image processing may be used to improve the results. Note that the network allows any image of the correct size as an input. Thus, the geometry does not need to be from one of the considered classes. This property can be used to train the network also with segments/cutouts of larger images, which may be split into appropriately sized parts. Moreover,\n1 3\nimage segments of different resolution may be considered and appropriately merged.\nThe output of the network may be smoothened to obtain meshes with improved mesh grading. Similarly, one may\nuse edge/highlight detection algorithms to find features in the output image that need to be refined more. This approach is also proposed in Sect.\u00a06.3 and tested, see e.g. Table\u00a01. Since we consider images, it may also be feasible to train the network with noisy data to make the output more robust. However, such modifications must be performed carefully and studied more deeply, as small details in the geometry have a significant effect on the expected local mesh size."
        },
        {
            "heading": "7.2.3 Higher dimensions",
            "text": "The proposed method can be generalized to problems of higher dimensions such as solving PDE on volumetric domains or solving time dependent problems such as\n1 3\nparabolic PDE using space-time methods. While the method can be set up for problems on volumetric domains in a straight-forward way, an extension to surface domains or space-time problems can be more difficult. The extension to space-time domains leads to 3D or multi-channel images, instead of just grayscale. Note that for time-dependent PDEs, other types of networks like recurrent neural networks or LSTM might be more suitable.\nMulti-channel images may also be used to generalize the approach to surface data when the surface can be parameterized over a planar quadrilateral domain. In this case, the differential equation on the parameterized surface can be pulled back to the parametric domain, resulting in a PDE with varying coefficients that can be encoded as separate channels of the image data. A typical example for this case are single-patch B-spline surfaces that are employed in isogeometric analysis.\nTo process surface data with more complicated methods from geometric deep learning\u00a0[24] may be used for surface data. These methods generalize the notion of image CNN to data that is represented by graphs or discrete manifolds. The challenge is here to define operators that act on these data types and that perform similarly to the convolution operator of matrices. CNN for discrete for discrete surface data are an active field of research [25, 36] and it would be an interesting direction for future work to employ these techniques to generate locally refined surface parameterizations."
        },
        {
            "heading": "8 Conclusions",
            "text": "In this paper we developed a local refinement method for PDEs using machine learning. The geometry of the domain as well as the boundary data of the PDE are encoded as images. These images are then used as input data for a neural network based on the U-net architecture. The output of the network is another image which encodes the local mesh size of a finite element mesh. From this information we then construct a mesh over the domain using Gmsh. The quality of the locally refined mesh can then be measured by computing the discretization error of the resulting finite element solution.\nWe compare the quality of the output for different training strategies. To do so, we categorize possible input data sets using different geometric complexity classes. One can then pursue different training strategies. It is expected that the resulting output yields best results, if the network is trained exactly with those training data sets from the same complexity class as the input. This may however be quite expensive, since it means that one has to generate training data for a wide range of geometric complexities. We could show that it suffices to train the network with data sets which are complex only with respect to one dimension and simple with\nrespect to other dimensions of complexity. For instance, if the network is trained for L-shaped domains without holes as well as domains with a convex boundary and a hole, it can produce a suitable output for an L-shaped domain with a hole, even though it has never seen such a domain. This means that one does not necessarily need to train for all possible geometric complexity classes but can restrict to a subset for which training data is easier to produce.\nIn the future we want to extend the approach to other types of PDEs and to a larger class of possible domains and data of the PDE. Most importantly, the approach can, in principle, also be extended to 3D. However, the classification of possible domains and the generation of training data becomes more involved. In addition, we want to extend the method also to generating multi-patch isogeometric discretizations with curved boundaries, which take into account the estimated mesh density.\nAcknowledgements The authors were supported by the Linz Institute of Technology (LIT) and the government of Upper Austria through the project LIT-2019-8-SEE-116 entitled \u201cPARTITION \u2013 PDE-aware isogeometric discretization based on neural networks\u201d. This support is gratefully acknowledged. F.\u00a0Scholz additionally acknowledges the support by the JST CREST Grant no. JPMJCR1911.\nFunding Open access funding provided by Johannes Kepler University Linz.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/."
        }
    ],
    "title": "Locally refined quad meshing for linear elasticity problems based on convolutional neural networks",
    "year": 2022
}