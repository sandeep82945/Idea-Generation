{
    "abstractText": "With the continuous increase of users and items, conventional recommender systems trained on static datasets can hardly adapt to changing environments. The high-throughput data requires the model to be updated in a timely manner for capturing the user interest dynamics, which leads to the emergence of streaming recommender systems. Due to the prevalence of deep learning-based recommender systems, the embedding layer is widely adopted to represent the characteristics of users, items, and other features in low-dimensional vectors. However, it has been proved that setting an identical and static embedding size is sub-optimal in terms of recommendation performance and memory cost, especially for streaming recommendations. To tackle this problem, we first rethink the streaming model update process and model the dynamic embedding size search as a bandit problem. Then, we analyze and quantify the factors that influence the optimal embedding sizes from the statistics perspective. Based on this, we propose the Dynamic Embedding Size Search (DESS) method to minimize the embedding size selection regret on both user and item sides in a non-stationary manner. Theoretically, we obtain a sublinear regret upper bound superior to previous methods. Empirical results across two recommendation tasks on four public datasets also demonstrate that our approach can achieve better streaming recommendation performance with lower memory cost and higher time efficiency.",
    "authors": [
        {
            "affiliations": [],
            "name": "Bowei He"
        },
        {
            "affiliations": [],
            "name": "Xu He"
        },
        {
            "affiliations": [],
            "name": "Renrui Zhang"
        },
        {
            "affiliations": [],
            "name": "Yingxue Zhang"
        },
        {
            "affiliations": [],
            "name": "Ruiming Tang"
        },
        {
            "affiliations": [],
            "name": "Chen Ma"
        }
    ],
    "id": "SP:47703c10bc2239c74b2905d3077ee9edcdd58140",
    "references": [
        {
            "authors": [
                "Bilge Acun",
                "Matthew Murphy",
                "Xiaodong Wang",
                "Jade Nie",
                "Carole-Jean Wu",
                "Kim Hazelwood"
            ],
            "title": "Understanding training efficiency of deep learning recommendation models at scale",
            "venue": "IEEE International Symposium on High- Performance Computer Architecture (HPCA)",
            "year": 2021
        },
        {
            "authors": [
                "Samuele Battaglino",
                "Erdem Koyuncu"
            ],
            "title": "A generalization of principal component analysis",
            "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
            "year": 2020
        },
        {
            "authors": [
                "Omar Besbes",
                "Yonatan Gur",
                "Assaf Zeevi"
            ],
            "title": "Stochastic multi-armed-bandit problem with non-stationary rewards. Advances in neural information processing systems",
            "year": 2014
        },
        {
            "authors": [
                "Andrew Brock",
                "Theodore Lim",
                "James M Ritchie",
                "Nick Weston"
            ],
            "title": "Smash: one-shot model architecture search through hypernetworks",
            "year": 2017
        },
        {
            "authors": [
                "Badrish Chandramouli",
                "Justin J Levandoski",
                "Ahmed Eldawy",
                "Mohamed F Mokbel"
            ],
            "title": "Streamrec: a real-time recommender system",
            "venue": "In Proceedings of the 2011 ACM SIGMOD International Conference on Management of data",
            "year": 2011
        },
        {
            "authors": [
                "Shiyu Chang",
                "Yang Zhang",
                "Jiliang Tang",
                "Dawei Yin",
                "Yi Chang",
                "Mark A Hasegawa- Johnson",
                "Thomas S Huang"
            ],
            "title": "Streaming recommender systems",
            "venue": "In Proceedings of the 26th international conference on world wide web",
            "year": 2017
        },
        {
            "authors": [
                "Chen Chen",
                "Hongzhi Yin",
                "Junjie Yao",
                "Bin Cui"
            ],
            "title": "Terec: A temporal recommender system over tweet stream",
            "venue": "Proceedings of the VLDB Endowment 6,",
            "year": 2013
        },
        {
            "authors": [
                "Xiong-Hui Chen",
                "Bowei He",
                "Yang Yu",
                "Qingyang Li",
                "Zhiwei Qin",
                "Wenjie Shang",
                "Jieping Ye",
                "Chen Ma"
            ],
            "title": "Sim2Rec: A Simulator-based Decision-making Approach to Optimize Real-World Long-term User Engagement in Sequential Recommender Systems",
            "year": 2023
        },
        {
            "authors": [
                "Weiyu Cheng",
                "Yanyan Shen",
                "Linpeng Huang"
            ],
            "title": "Differentiable neural input search for recommender systems",
            "venue": "arXiv preprint arXiv:2006.04466",
            "year": 2020
        },
        {
            "authors": [
                "Paul Covington",
                "Jay Adams",
                "Emre Sargin"
            ],
            "title": "Deep neural networks for youtube recommendations",
            "venue": "In Proceedings of the 10th ACM conference on recommender systems",
            "year": 2016
        },
        {
            "authors": [
                "Abhinandan S Das",
                "Mayur Datar",
                "Ashutosh Garg",
                "Shyam Rajaram"
            ],
            "title": "Google news personalization: scalable online collaborative filtering",
            "venue": "In Proceedings of the 16th international conference on World Wide Web",
            "year": 2007
        },
        {
            "authors": [
                "Robin Devooght",
                "Nicolas Kourtellis",
                "Amin Mantrach"
            ],
            "title": "Dynamic matrix factorization with priors on unknown values",
            "venue": "In Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining",
            "year": 2015
        },
        {
            "authors": [
                "Ernesto Diaz-Aviles",
                "Lucas Drumond",
                "Lars Schmidt-Thieme",
                "Wolfgang Nejdl"
            ],
            "title": "Real-time top-n recommendation in social streams",
            "venue": "In Proceedings of the sixth ACM conference on Recommender systems",
            "year": 2012
        },
        {
            "authors": [
                "AA Ginart",
                "Maxim Naumov",
                "Dheevatsa Mudigere",
                "Jiyan Yang",
                "James Zou"
            ],
            "title": "Mixed dimension embeddings with application to memory-efficient recommendation systems",
            "venue": "IEEE International Symposium on Information Theory (ISIT)",
            "year": 2021
        },
        {
            "authors": [
                "F Maxwell Harper",
                "Joseph A Konstan"
            ],
            "title": "The movielens datasets: History and context",
            "venue": "Acm transactions on interactive intelligent systems (tiis)",
            "year": 2015
        },
        {
            "authors": [
                "Bowei He",
                "Xu He",
                "Yingxue Zhang",
                "Ruiming Tang",
                "Chen Ma"
            ],
            "title": "Dynamically Expandable Graph Convolution for Streaming Recommendation",
            "venue": "In Proceedings of the ACM Web Conference",
            "year": 2023
        },
        {
            "authors": [
                "Ruining He",
                "Julian McAuley"
            ],
            "title": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering",
            "venue": "In proceedings of the 25th international conference on world wide web",
            "year": 2016
        },
        {
            "authors": [
                "Xiangnan He",
                "Lizi Liao",
                "Hanwang Zhang",
                "Liqiang Nie",
                "Xia Hu",
                "Tat-Seng Chua"
            ],
            "title": "Neural collaborative filtering",
            "venue": "In Proceedings of the 26th international conference on world wide web",
            "year": 2017
        },
        {
            "authors": [
                "Cheng-Kang Hsieh",
                "Longqi Yang",
                "Yin Cui",
                "Tsung-Yi Lin",
                "Serge Belongie",
                "Deborah Estrin"
            ],
            "title": "Collaborative metric learning",
            "venue": "In Proceedings of the 26th international conference on world wide web",
            "year": 2017
        },
        {
            "authors": [
                "Frank Hutter",
                "Holger H Hoos",
                "Kevin Leyton-Brown"
            ],
            "title": "Sequential modelbased optimization for general algorithm configuration",
            "venue": "In International conference on learning and intelligent optimization",
            "year": 2011
        },
        {
            "authors": [
                "Arun Jambulapati",
                "Jerry Li",
                "Kevin Tian"
            ],
            "title": "Robust sub-gaussian principal component analysis and width-independent schatten packing",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "Manas R Joglekar",
                "Cong Li",
                "Mei Chen",
                "Taibai Xu",
                "Xiaoming Wang",
                "Jay K Adams",
                "Pranav Khaitan",
                "Jiahui Liu",
                "Quoc V Le"
            ],
            "title": "Neural input search for large scale recommendation models",
            "venue": "In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
            "year": 2020
        },
        {
            "authors": [
                "Wang-Cheng Kang",
                "Derek Zhiyuan Cheng",
                "Ting Chen",
                "Xinyang Yi",
                "Dong Lin",
                "Lichan Hong",
                "Ed H Chi"
            ],
            "title": "Learning multi-granular quantized embeddings for large-vocab categorical features in recommender systems",
            "venue": "In Companion Proceedings of the Web Conference",
            "year": 2020
        },
        {
            "authors": [
                "Baekjin Kim",
                "Ambuj Tewari"
            ],
            "title": "Randomized exploration for non-stationary stochastic linear bandits",
            "venue": "In Conference on Uncertainty in Artificial Intelligence. PMLR,",
            "year": 2020
        },
        {
            "authors": [
                "Yehuda Koren",
                "Robert Bell",
                "Chris Volinsky"
            ],
            "title": "Matrix factorization techniques for recommender systems",
            "venue": "Computer 42,",
            "year": 2009
        },
        {
            "authors": [
                "Tor Lattimore",
                "Csaba Szepesv\u00e1ri"
            ],
            "title": "Bandit algorithms. Cambridge University Press. Dynamic Embedding Size Search with Minimum Regret for Streaming Recommender System CIKM \u201923",
            "venue": "October 21\u201325,",
            "year": 2020
        },
        {
            "authors": [
                "Haochen Liu",
                "Xiangyu Zhao",
                "Chong Wang",
                "Xiaobing Liu",
                "Jiliang Tang"
            ],
            "title": "Automated embedding size search in deep recommender systems",
            "venue": "In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "year": 2020
        },
        {
            "authors": [
                "Siyi Liu",
                "Chen Gao",
                "Yihong Chen",
                "Depeng Jin",
                "Yong Li"
            ],
            "title": "Learnable embedding sizes for recommender systems",
            "venue": "arXiv preprint",
            "year": 2021
        },
        {
            "authors": [
                "Siyi Liu",
                "Chen Gao",
                "Yihong Chen",
                "Depeng Jin",
                "Yong Li"
            ],
            "title": "Learnable Embedding sizes for Recommender Systems",
            "venue": "In ICLR. OpenReview.net",
            "year": 2021
        },
        {
            "authors": [
                "Renqian Luo",
                "Fei Tian",
                "Tao Qin",
                "Enhong Chen",
                "Tie-Yan Liu"
            ],
            "title": "Neural architecture optimization. Advances in neural information processing systems",
            "year": 2018
        },
        {
            "authors": [
                "Fuyuan Lyu",
                "Xing Tang",
                "Hong Zhu",
                "Huifeng Guo",
                "Yingxue Zhang",
                "Ruiming Tang",
                "Xue Liu"
            ],
            "title": "OptEmbed: Learning Optimal Embedding Table for Clickthrough Rate Prediction",
            "venue": "In Proceedings of the 31st ACM International Conference on Information & Knowledge Management",
            "year": 2022
        },
        {
            "authors": [
                "Chen Ma",
                "Liheng Ma",
                "Yingxue Zhang",
                "Ruiming Tang",
                "Xue Liu",
                "Mark Coates"
            ],
            "title": "Probabilistic metric learning with adaptive margin for top-k recommendation",
            "venue": "In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
            "year": 2020
        },
        {
            "authors": [
                "Donald W Marquardt",
                "Ronald D Snee"
            ],
            "title": "Ridge regression in practice",
            "venue": "The American Statistician 29,",
            "year": 1975
        },
        {
            "authors": [
                "Hieu Pham",
                "Melody Guan",
                "Barret Zoph",
                "Quoc Le",
                "Jeff Dean"
            ],
            "title": "Efficient neural architecture search via parameters sharing",
            "venue": "In International conference on machine learning",
            "year": 2018
        },
        {
            "authors": [
                "Yoan Russac",
                "Claire Vernade",
                "Olivier Capp\u00e9"
            ],
            "title": "Weighted linear bandits for non-stationary environments",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "Yang Song",
                "Ziming Zhuang",
                "Huajing Li",
                "Qiankun Zhao",
                "Jia Li",
                "Wang-Chien Lee",
                "C Lee Giles"
            ],
            "title": "Real-time automatic tag recommendation",
            "venue": "In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval",
            "year": 2008
        },
        {
            "authors": [
                "Karthik Subbian",
                "Charu Aggarwal",
                "Kshiteesh Hegde"
            ],
            "title": "Recommendations for streaming data",
            "venue": "In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management",
            "year": 2016
        },
        {
            "authors": [
                "Jianing Sun",
                "Zhaoyue Cheng",
                "Saba Zuberi",
                "Felipe P\u00e9rez",
                "Maksims Volkovs"
            ],
            "title": "Hgcf: Hyperbolic graph convolution networks for collaborative filtering",
            "venue": "In Proceedings of the Web Conference",
            "year": 2021
        },
        {
            "authors": [
                "Bruno Veloso",
                "Luciano Caroprese",
                "Matthias K\u00f6nig",
                "S\u00f3nia Teixeira",
                "Giuseppe Manco",
                "Holger H Hoos",
                "Jo\u00e3o Gama"
            ],
            "title": "Hyper-parameter Optimization for Latent Spaces",
            "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases",
            "year": 2021
        },
        {
            "authors": [
                "Junshan Wang",
                "Guojie Song",
                "Yi Wu",
                "Liang Wang"
            ],
            "title": "Streaming graph neural networks via continual learning",
            "venue": "In Proceedings of the 29th ACM International Conference on Information & Knowledge Management",
            "year": 2020
        },
        {
            "authors": [
                "Junshan Wang",
                "Wenhao Zhu",
                "Guojie Song",
                "Liang Wang"
            ],
            "title": "Streaming Graph Neural Networks with Generative Replay",
            "venue": "In KDD \u201922: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,",
            "year": 2022
        },
        {
            "authors": [
                "Weiqing Wang",
                "Hongzhi Yin",
                "Zi Huang",
                "Qinyong Wang",
                "Xingzhong Du",
                "Quoc Viet Hung Nguyen"
            ],
            "title": "Streaming ranking based recommender systems",
            "venue": "In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval",
            "year": 2018
        },
        {
            "authors": [
                "Xiang Wang",
                "Xiangnan He",
                "Meng Wang",
                "Fuli Feng",
                "Tat-Seng Chua"
            ],
            "title": "Neural graph collaborative filtering",
            "venue": "In Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval",
            "year": 2019
        },
        {
            "authors": [
                "Ronald J Williams"
            ],
            "title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning. Reinforcement learning",
            "year": 1992
        },
        {
            "authors": [
                "Qingyun Wu",
                "Naveen Iyer",
                "Hongning Wang"
            ],
            "title": "Learning contextual bandits in a non-stationary environment",
            "venue": "In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval",
            "year": 2018
        },
        {
            "authors": [
                "Sirui Xie",
                "Hehui Zheng",
                "Chunxiao Liu",
                "Liang Lin"
            ],
            "title": "SNAS: stochastic neural architecture search",
            "venue": "arXiv preprint arXiv:1812.09926",
            "year": 2018
        },
        {
            "authors": [
                "Fuzheng Zhang",
                "Nicholas Jing Yuan",
                "Defu Lian",
                "Xing Xie",
                "Wei-Ying Ma"
            ],
            "title": "Collaborative knowledge base embedding for recommender systems",
            "venue": "In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining",
            "year": 2016
        },
        {
            "authors": [
                "Peng Zhao",
                "Lijun Zhang",
                "Yuan Jiang",
                "Zhi-Hua Zhou"
            ],
            "title": "A simple approach for non-stationary linear bandits",
            "venue": "In International Conference on Artificial Intelligence and Statistics. PMLR,",
            "year": 2020
        },
        {
            "authors": [
                "Xiangyu Zhao",
                "Haochen Liu",
                "Wenqi Fan",
                "Hui Liu",
                "Jiliang Tang",
                "Chong Wang",
                "Ming Chen",
                "Xudong Zheng",
                "Xiaobing Liu",
                "Xiwang Yang"
            ],
            "title": "Autoemb: Automated embedding dimensionality search in streaming recommendations",
            "venue": "IEEE International Conference on Data Mining (ICDM)",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "CCS CONCEPTS \u2022 Information systems\u2192 Recommender systems.\nKEYWORDS Streaming recommender system; Embedding size search; Contextual bandit; Automated machine learning\n\u2217Corresponding author\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CIKM \u201923, October 21\u201325, 2023, Birmingham, United Kingdom \u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0124-5/23/10. . . $15.00 https://doi.org/10.1145/3583780.3615135"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Recommender systems (RS) have been widely adopted to reduce information overload and satisfy users\u2019 diverse needs. Considering the ever-increasing users and items, as well as users\u2019 continuous interest shift, conventional static RS, however, can hardly adapt to the evolving environment. To tackle such challenges, streaming recommender systems (SRS), whose recommendation strategy updates in a dynamic manner, was proposed in the last decade along with the rapid accumulation of massive data from online applications like Google and Twitter [5, 7, 11, 13, 17, 38]. Recently, deep learning-based recommender systems [19, 49] make a breakthrough in improving the recommendation performance, which provides a new direction for the evolution of streaming recommender systems.\nTo enable the success of deep RS, embedding learning plays a central role in representing users, items, and other features in low-dimensional vectors. Due to the inherent characteristics of different users and items, the conventional design that assigns an identical embedding size to each user or item limits the model performance and brings huge memory costs. To solve this problem, embedding size search is introduced in [23] accompanied by the rapid development of the automated neural network structure design in computer vision and natural language processing tasks [4, 28, 32, 36, 48]. Recently, embedding size search has received widespread attention [15, 23, 24, 30], and various methods have been proposed to search for ID-specific embedding sizes. Most of them adopt an external controller or the differential search to decide the embedding sizes from a discrete or continuous candidate space [9, 23, 29, 31, 33, 52]. Due to the broad application of streaming recommender systems, it has also been noticed that assigning a constant embedding size for users or items along the timeline will lead to unsatisfactory performance. Correspondingly, the dynamic embedding size search problem has also been gradually investigated and several methods [28, 29, 41, 51] have been proposed to search the best time-varying embedding sizes.\nAlthough the aforementioned approaches are effective and insightful, there are still several avenues for improvement. First, previous embedding size search methods [28, 29, 41, 52] with neural network-based or reinforcement learning-based controllers require large amounts of interaction data to converge, which drags down their effectiveness in the early stages of the recommendation stream. Moreover, the neural network-based method can hardly balance the exploration and exploitation during the online embedding size\nar X\niv :2\n30 8.\n07 76\n0v 1\n[ cs\n.I R\n] 1\n5 A\nug 2\nsearch. Second, existing methods [23, 28, 29, 41, 52] only consider the browsing frequency throughout the whole historical record when deciding the appropriate embedding sizes. Nevertheless, this is far from reflecting users\u2019 recent browsing behavior characteristics. In fact, the optimal embedding size is mainly associated with the information amount of users\u2019 browsing records, which should be determined by both the frequency and diversity of browsing records. Third, in previous works [28, 29, 41, 52], the model update process still follows the conventional update pattern of static models, which optimizes the model on the training set until convergence and then evaluating it on the untimely test set. However, in a real SRS like Twitter, the system needs to recommend content to users according to their real-time interests when they post tweets, which means training and testing should alternate over time. Therefore, the optimization objective of dynamic embedding size search should consider the model\u2019s performance at each timestep throughout the whole timeline. Moreover, existing methods often suffer from huge memory costs and low time efficiency which make it difficult to put them into practical use.\nTo address these issues, we rethink the streaming recommendation model update process, and first model the dynamic optimal embedding size search as a cumulative regret minimization bandit problem. Then, we justify the change of the embedding size by analyzing and quantifying the user behavior characteristics via two indicators proposed in this paper. On this basis, we propose the non-stationary LinUCB bandit-based Dynamic Embedding Size Search (DESS) algorithm to minimize the performance regret. In the method design, the weighted forgetting mechanism is adopted to reduce interference from outdated data and help the search policy pay more attention to recent user behaviors. We provide a sublinear dynamic regret upper bound which guarantees the effectiveness of our method. To help validate the superiorities of our approach, we design an embedding size adaptive neural network based on Neural Collaborative Filtering [45], whose embedding input part can be shared among different base recommendation models. Following previous works [28, 29, 51], we conduct the top-\ud835\udc58 recommendation and rating score prediction tasks on four public recommendation datasets. The experimental results demonstrate the effectiveness of our method with lower memory cost and higher time efficiency.\nTo summarize, the main contributions of this work are as follows:\n\u2022 We model the dynamic embedding size search as the cumulative regretminimization bandit and propose a non-stationary LinUCBbased algorithm DESS with a sublinear regret upper bound. \u2022 We provide two effective indicators \ud835\udc3c\ud835\udc41\ud835\udc37 and \ud835\udc43\ud835\udc42\ud835\udc37 reflecting user behavior characteristics that can guide the search for appropriate embedding sizes from a statistical perspective. \u2022 Experiments on four real-world datasets show that DESS outperforms the state-of-the-art methods in dynamic embedding size search for streaming recommender systems."
        },
        {
            "heading": "2 RELATEDWORK",
            "text": "Streaming Recommender System. SRS is a kind of newly developed recommender system in coping with the high -throughput user data and their incremental properties [6, 7, 11, 12, 17, 38, 44].Different from the conventional recommender systems [8, 19,\n49], SRS needs to update its recommendation strategy in a dynamic manner to catch the user interest temporal dynamics. Early works [5, 39], known as memory-based methods, leverage similarity relationships in aggregated historical data to predict ratings. Some more advanced works [6, 12, 13]propose to extend popular static recommender models like collaborative filtering and matrix factorization to the streaming fashion. However, most previous methods suffer from a common drawback: dividing the entire data stream into two segments, training on the former segment until convergence, and then testing on the latter segment, which is far from the real SRS scenario. In this work, we split the data of each time slice to two parts, train on the first part and test on the second part alternatively along the timeline, in such way to better fit the real streaming recommendation task.\nEmbedding Size Search. The embedding size search problem gradually attracts much attention because of the large models\u2019 increasing memory cost [1, 10] and the rapid development of neural architecture search techniques [4, 28, 32, 36, 48]. Some initial works focus on embedding size search on static recommender systems [15, 23, 24, 30, 33]. These approaches break the long-standing uniform-size embedding structure design. However, once determined, these embedding sizes can no longer be dynamically adjusted. As streaming recommender systems are more and more adopted, some recent works [29, 41, 51, 52, 52] start to investigate the corresponding dynamic embedding size problem which means the embedding size for each ID is no more fixed. Generally speaking, previousmethods can be divided into twomainstream schemes: softselection and hard-selection. In the soft-selection scheme [28, 51, 52], the input of following representation learning layers is actually the weighted summation of transformed vectors corresponding to each embedding size. However, this category of methods suffer from the cold-start problem and the excessive memory cost. In the hard-selection scheme [29, 41], only one size of embedding is selected at each time step. Nevertheless, previous works are still not reasonable enough for modeling the SRS update process. In addition, the algorithm performance lacks theoretical guarantee and needs to be improved if applied to the practical application. In this work, we follow the hard-selection scheme and provide a more efficient dynamic embedding size search method.\nBase Recommendation Model. To make effective recommendations, a number of models have been proposed [34], including matrix factorization (MF)-based models, distance-based models, and multi-layer perceptron-based models. Matrix factorization [26] is a representative and widely-used recommendation method which applies an inner product between the user and item embeddings to capture the interactions between users and items. Distance-based models, generally, compute the Euclidean distance between users and items for capturing fine-grained user preference [20]. On the other hand, Neural Collaborative Filtering (NCF) [19], a type of multi-layer perceptron-based method, models user-item interactions through neural network architectures, so that high-level nonlinearities within the user-item interaction can be learned. Following the settings in previous works [23, 29, 51, 52], we also choose NCF as the base recommendation model. Furthermore, we modify its architecture to fit the dynamic embedding size setting, which is detailed in Section 4.5. MF-based models and distance-based models are also explored to prove the wide applicability of our method."
        },
        {
            "heading": "3 PRELIMINARIES",
            "text": "In this section, we first formalize the streaming recommendation problem. Then we derive the dynamic embedding size search task from the streaming model update process."
        },
        {
            "heading": "3.1 Streaming Recommendation",
            "text": "One prominent advantage of SRS is that they can update and respond instantaneously for catching users\u2019 intentions and demands [5, 6]. Due to the high volume of online data, previous works [17, 29, 42, 43, 51] split the user-item interaction stream into short-term segments. Following this setting, we split the whole data stream of length \ud835\udc3f into \ud835\udc47 consecutive segments \ud835\udc371, ..., \ud835\udc37\ud835\udc61 , ..., \ud835\udc37\ud835\udc47 with the same length |\ud835\udc37\ud835\udc61 | (\ud835\udc3f = |\ud835\udc37\ud835\udc61 | \u00d7\ud835\udc47 ). Each segment \ud835\udc37\ud835\udc61 is then divided into the training part \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc61 and test part \ud835\udc37 \ud835\udc61\ud835\udc52 \ud835\udc61 . On this basis, the streaming recommendation task is formulated as: given \ud835\udc37\ud835\udc61\ud835\udc5f1 , \ud835\udc37 \ud835\udc61\ud835\udc5f 2 , ..., \ud835\udc37 \ud835\udc61\ud835\udc5f \ud835\udc61 , ..., \ud835\udc37 \ud835\udc61\ud835\udc5f \ud835\udc47 , it is supposed to train a model\ud835\udc40 to predict the user preference in \ud835\udc37\ud835\udc61\ud835\udc521 , \ud835\udc37 \ud835\udc61\ud835\udc52 2 , ..., \ud835\udc37 \ud835\udc61\ud835\udc52 \ud835\udc61 , ..., \ud835\udc37 \ud835\udc61\ud835\udc52 \ud835\udc47 , where \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc61 \u222a \ud835\udc37\ud835\udc61\ud835\udc52\ud835\udc61 = \ud835\udc37\ud835\udc61 and \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc61 \u2229\ud835\udc37\ud835\udc61\ud835\udc52\ud835\udc61 = \u2205. The overall performance is evaluated by the average recommendation accuracy over the entire timeline."
        },
        {
            "heading": "3.2 Dynamic Embedding Size Search",
            "text": "With the wide use of deep recommendation models, embeddings are largely investigated to represent users, items, and other auxiliary features. However, the conventional design of setting identical and static embedding sizes suffers from the unsatisfying model prediction performance and the unacceptablememory cost. To solve these problems, many works [21, 23, 29, 41, 52] are proposed for the embedding size search. To make the search fit into the streaming scenario, a streaming update process should be first introduced: the model \ud835\udc40 inherits the parameters from the previous moment \ud835\udc40\ud835\udc61\u22121 and updates itself to \ud835\udc40\ud835\udc61 with the current training data \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc61 . Following these, the dynamic embedding size search task can be further formulated: optimizing embedding size search policies \ud835\udf0b\ud835\udc62\n\ud835\udc46\ud835\udc38\nand \ud835\udf0b\ud835\udc56 \ud835\udc46\ud835\udc38 which accordingly control user and item embedding sizes of recommendation model\ud835\udc40 at each timestep, so that the overall model performance can be satisfying (see Figure 1). For the ease of illustration, \ud835\udf0b\ud835\udc46\ud835\udc38 refers to both \ud835\udf0b\ud835\udc62\ud835\udc46\ud835\udc38 and \ud835\udf0b \ud835\udc56 \ud835\udc46\ud835\udc38 ."
        },
        {
            "heading": "4 METHODOLOGY",
            "text": "In this section, we introduce our approach for dynamic embedding size search in streaming recommender systems. First, we model the embedding size search as a bandit problem and formalize the objective. Then we analyze and quantify the characteristics that can determine optimal embedding sizes from a statistical perspective. Next, we elaborate the non-stationary LinUCB-based DESS method (shown in Algorithm 1) to conduct the dynamic embedding size search, and provide the corresponding theoretical guarantee analysis. Finally, we introduce the structure of our streaming recommendation model\u2014an embedding size adaptive neural network."
        },
        {
            "heading": "4.1 Embedding Size Search as Bandits",
            "text": "The target of the embedding size search in streaming scenarios is to optimize the average/cumulative model performance by selecting appropriate embedding sizes at different timesteps. From the temporal view, the search process is, in nature, a sequence of size\nvalue decisions according to data characteristics. To solve this sequential decision-making problem, Multi-armed Bandits (MAB) are a promising approach where a fixed limited set of resources must be allocated between competing choices in a way that maximizes the sum of rewards earned through a sequence of lever pulls [27]. Therefore, to consider the model\u2019s recommendation performance at each timestep, we model the dynamic embedding size search as a bandit problem, and the objective of the search policy \ud835\udf0b\ud835\udc46\ud835\udc38 is to minimize the expected dynamic pseudo-regret defined as:\n\ud835\udc45\ud835\udc47 = \ud835\udc5a\ud835\udc4e\ud835\udc65 \ud835\udf0b :\ud835\udc36\u21921,...,\ud835\udc3e E[ \ud835\udc47\u2211\ufe01 \ud835\udc61=1 L\ud835\udc61\ud835\udc52\ud835\udc61 (\ud835\udf0b\ud835\udc46\ud835\udc38 ) \u2212 \ud835\udc47\u2211\ufe01 \ud835\udc61=1 L\ud835\udc61\ud835\udc52\ud835\udc61 (\ud835\udf0b)], (1)\nwhere L\ud835\udc61\ud835\udc52\ud835\udc61 (\ud835\udf0b\ud835\udc46\ud835\udc38 ) is the batch loss of\ud835\udc40 with embedding sizes determined by search policy \ud835\udf0b\ud835\udc46\ud835\udc38 on test data \ud835\udc37\ud835\udc61\ud835\udc52\ud835\udc61 . L\ud835\udc61\ud835\udc52\ud835\udc61 (\ud835\udf0b) is the model test loss received from pulling the arm that an arbitrary policy \ud835\udf0b recommends at the current state. \ud835\udc36 is the set of context information that can help the policy \ud835\udf0b select the best arm from the arm candidates 1, ..., \ud835\udc3e at different timesteps. Note that the ideal \ud835\udc45\ud835\udc47 is obtained when \ud835\udf0b is the optimal one. Thus, the pseudo regret for \ud835\udf0b\ud835\udc46\ud835\udc38 is the difference between the actual loss it incurs and the loss incurred by the best possible embedding size search policy [27].\nSince the test data is actually inaccessible in the training phase, we utilize the validation data to interact with the bandit directly and update the search policy. Especially, in the streaming recommendation scenario, the union of training data and test data at the last timestep \ud835\udc61 \u2212 1 (\ud835\udc37\ud835\udc61\u22121) can be regarded as the validation data for timestep \ud835\udc61 [29, 51]. Then, the corresponding dynamic regret is:\n\ud835\udc45\ud835\udc47 = \ud835\udc5a\ud835\udc4e\ud835\udc65 \ud835\udf0b :\ud835\udc36\u21921,...,\ud835\udc3e \ud835\udc47\u2211\ufe01 \ud835\udc61=1 |\ud835\udc37\ud835\udc61\u22121 |\u2211\ufe01 \ud835\udc57=1 \ud835\udc5f \ud835\udc63\ud835\udc4e\ud835\udc61,\ud835\udc57 (\ud835\udf0b (x)) \u2212 \ud835\udc47\u2211\ufe01 \ud835\udc61=1 |\ud835\udc37\ud835\udc61\u22121 |\u2211\ufe01 \ud835\udc57=1 \ud835\udc5f \ud835\udc63\ud835\udc4e\ud835\udc61,\ud835\udc57 (\ud835\udf0b\ud835\udc46\ud835\udc38 (x)), (2)\nwhere \ud835\udc5f \ud835\udc63\ud835\udc4e \ud835\udc61,\ud835\udc57 (\ud835\udf0b (x)) is the reward received from pulling the arm that the \ud835\udf0b recommends in the validation phase. \ud835\udc5f \ud835\udc63\ud835\udc4e\n\ud835\udc61,\ud835\udc57 (\ud835\udf0b\ud835\udc46\ud835\udc38 (x)) is the re-\nward actually received by our \ud835\udf0b\ud835\udc46\ud835\udc38 on validation data. The x indicates the context as the input of the bandit model, whose details will be provided in Section 4.2. Here, we further explain the reward \ud835\udc5f\ud835\udc61, \ud835\udc57 , noted as \ud835\udc5f\ud835\udc59 (\ud835\udc59 = (\ud835\udc61 \u2212 1) \u00d7 |\ud835\udc37\ud835\udc61 | + \ud835\udc57, 1 \u2264 \ud835\udc59 \u2264 \ud835\udc3f) and the arm \ud835\udc4e.\nReward. The reward \ud835\udc5f\ud835\udc59 is defined based on the performance L\ud835\udc5b\ud835\udc52\ud835\udc64 \ud835\udc59\nof the temporarily updated embedding structure by \ud835\udf0b\ud835\udc46\ud835\udc38 and the previous structure\u2019s performanceL\ud835\udc5c\ud835\udc59\ud835\udc51\n\ud835\udc59 on \ud835\udc59-th interaction of the\nvalidation data stream. To fairly compare the effectiveness of such two embedding structures with different sizes, we temporarily tune their parameters with the \ud835\udc59-th interaction. \ud835\udc5f\ud835\udc59 here is designed as a binary variable and can only be 0 or 1. The formula is following:\n\ud835\udc5f\ud835\udc59 =\n{ 1, \ud835\udc56 \ud835\udc53 L\ud835\udc5c\ud835\udc59\ud835\udc51\n\ud835\udc59 \u2212 L\ud835\udc5b\ud835\udc52\ud835\udc64 \ud835\udc59 > \ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e\ud835\udc5c\ud835\udc59\ud835\udc51\n0, \ud835\udc56 \ud835\udc53 L\ud835\udc5c\ud835\udc59\ud835\udc51 \ud835\udc59 \u2212 L\ud835\udc5b\ud835\udc52\ud835\udc64 \ud835\udc59\n< \ud835\udc61\u210e\ud835\udc5f\ud835\udc52\ud835\udc60\u210e\ud835\udc5c\ud835\udc59\ud835\udc51 (3)\nIn the real-world application, \ud835\udc5f\ud835\udc59 can be designed as a continuous real number L\ud835\udc5c\ud835\udc59\ud835\udc51\n\ud835\udc59 \u2212 L\ud835\udc5b\ud835\udc52\ud835\udc64 \ud835\udc59 for performance optimization.\nArm. The arms \ud835\udc4e here are actually different embedding size candidates or other embedding size adjustment operations, like increasing or decreasing embedding sizes."
        },
        {
            "heading": "4.2 Embedding Size Indicator",
            "text": "To effectively determine the sizes of embeddings, the indicator to increase or decrease embedding sizes is worth exploring because only\nbrowsing frequency is not sufficient to prompt the search policy to make the correct decision. According to [2, 14, 22], a larger data dispersion degree indicates a greater amount of information the data contains. Thus, when the data dispersion degree is large, the size of the embedding should be large to represent the whole historical information. Motivated by this, we follow a similar fashion to quantify the amount of information in historical data by leveraging the explicit item features independent of the user-item interactions. Assume we have a set of raw feature vectors F1, F2, .., F\ud835\udc41 corresponding to each item. Till \ud835\udc59-th interaction of the data stream, let user \ud835\udc62 have rated a subset of the items indexed by \ud835\udc561, \ud835\udc562, ..., \ud835\udc56\ud835\udc3b , then the interest diversity of user \ud835\udc62 can be formulated by the centroid diameter distance:\n\ud835\udc3c\ud835\udc41\ud835\udc37\ud835\udc62 \ud835\udc59 = 1 \ud835\udc3b \ud835\udc3b\u2211\ufe01 \u210e=1 \u221a\ufe03 (F\ud835\udc56\u210e \u2212 Q\ud835\udc62\ud835\udc59 ) (F\ud835\udc56\u210e \u2212 Q \ud835\udc62 \ud835\udc59 )\u22a4, (4)\nwhere Q\ud835\udc62 \ud835\udc59 is the mean vector of F\ud835\udc561 , F\ud835\udc562 , ..., F\ud835\udc56\ud835\udc3b and represents the user \ud835\udc62\u2019s mean interest. For item \ud835\udc56 , assume it has been rated by users \ud835\udc621, \ud835\udc622, .., \ud835\udc62\ud835\udc3b till \ud835\udc59-th interaction, the diversity of its property is:\n\ud835\udc43\ud835\udc42\ud835\udc37\ud835\udc56 \ud835\udc59 = 1 \ud835\udc3b \ud835\udc3b\u2211\ufe01 \u210e=1 \u221a\ufe03 (Q\ud835\udc62\u210e \ud835\udc59 \u2212 P\ud835\udc56 \ud835\udc59 ) (Q\ud835\udc62\u210e \ud835\udc59 \u2212 P\ud835\udc56 \ud835\udc59 )\u22a4, (5)\nwhere P\ud835\udc56 \ud835\udc59 is the mean vector ofQ\ud835\udc621 \ud835\udc59 ,Q\ud835\udc622 \ud835\udc59 , ...,Q\ud835\udc62\ud835\udc3b \ud835\udc59 and represents item \ud835\udc56\u2019s mean property. In this way, we define the context x\ud835\udc59 for the user embedding size search policy \ud835\udf0b\ud835\udc62\n\ud835\udc46\ud835\udc38 as the combination of frequency\nand information diversity (\ud835\udc39\ud835\udc45\ud835\udc38\ud835\udc62 \ud835\udc59 , \ud835\udc3c\ud835\udc41\ud835\udc37\ud835\udc62 \ud835\udc59 ), where \ud835\udc39\ud835\udc45\ud835\udc38\ud835\udc62 \ud835\udc59 is the occurrence number of user \ud835\udc62 in historical data. The context for the item embedding size search policy \ud835\udf0b\ud835\udc56\n\ud835\udc46\ud835\udc38 is defined as (\ud835\udc39\ud835\udc45\ud835\udc38\ud835\udc56 \ud835\udc59 , \ud835\udc43\ud835\udc42\ud835\udc37\ud835\udc56 \ud835\udc59 )\nsimilarly, where \ud835\udc39\ud835\udc45\ud835\udc38\ud835\udc56 \ud835\udc59 is the occurrence of item \ud835\udc56 in historical data."
        },
        {
            "heading": "4.3 Non-stationary LinUCB-based Search Policy",
            "text": "Despite the effectiveness of linear MAB, some recent works [25, 37, 47, 50] focus on a more general setting: the constraint that requires fixed optimal regression parameters \ud835\udf3d \u2217 is relaxed, which is\nmore suitable for our scenario. To better balance the exploration and exploitation in such a setting, we design our non-stationary LinUCB-based DESS algorithm for dynamic embedding size search. Its effectiveness on memory cost and time efficiency will be elaborated in Section 5. Due to the fact that the accumulated historical data for each user and item can only become richer and richer as data streams in, we simplify the embedding size search as a binary selection problem, where \ud835\udf0b\ud835\udc46\ud835\udc38 only needs to decide if increasing the embedding size to the subsequent larger size candidate.\nThe algorithm details are described in Algorithm 1. Generally, the whole algorithm is separated to two parts: Updating Non-stationary LinUCB-based Search Policy \ud835\udf0b\ud835\udc46\ud835\udc38 and Updating recommendation model, which are executed one after the other at each timestep \ud835\udc61 . Different arms \ud835\udc4e in our method share the common context information \ud835\udc65\ud835\udc59 about the frequency and interest/property diversity: x\ud835\udc59,1 = x\ud835\udc59,2 = ... = x\ud835\udc59,\ud835\udc3e = x\ud835\udc59 . Based on the assumption that the expected payoff \ud835\udc5f\ud835\udc59 is linear to its context x\ud835\udc59 \u2208 R\ud835\udc51 , we set disjoint linear reward models \ud835\udf3d1, \ud835\udf3d2, ..., \ud835\udf3d\ud835\udc3e for corresponding arms 1, 2..., \ud835\udc3e to estimate rewards when selecting different arms. Note that in this paper, \ud835\udf3d\ud835\udc59,\ud835\udc4e indicates the parameter of \ud835\udf3d\ud835\udc4e at the \ud835\udc59-th user-item interaction. For such disjoint linear models, we use ridge regression [35] to solve them. And the objective is to minimize the regularized weighted residual sum of squares, thus the \ud835\udf3d\ud835\udc59,\ud835\udc4e is defined as follows:\n\ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc5a\ud835\udc56\ud835\udc5b \ud835\udf3d \u2208R\ud835\udc51 ( \ud835\udc59\u2211\ufe01 \ud835\udc60=1 1(\ud835\udc4e\ud835\udc60 = \ud835\udc4e)\ud835\udefe\ud835\udc59\u2212\ud835\udc60 (\ud835\udc5f\ud835\udc60 \u2212 \u27e8x\ud835\udc60,\ud835\udc4e, \ud835\udf3d \u27e9)2 + \ud835\udf06\u2225\ud835\udf3d \u222522), (6)\nwhere \u27e8, \u27e9 indicates the inner product operation, and \ud835\udc4e\ud835\udc60 is the arm selected by the \ud835\udf0b\ud835\udc46\ud835\udc38 at \ud835\udc60-th interaction (1 \u2264 \ud835\udc60 \u2264 \ud835\udc59). Eq. 6 is actually the regularized weighted least-squared estimator of \ud835\udf3d \u2217\ud835\udc4e at \ud835\udc59-th interaction. The conduct of the weighted forgetting mechanism (discount factor \ud835\udefe ) is to reduce the interference from the outdated data [3, 37, 47] and help \ud835\udf0b\ud835\udc46\ud835\udc38 pay more attention to the recent\nuser/item behaviors. Furthermore, we have the solution for Eq. 6:\n\ud835\udf3d\ud835\udc59,\ud835\udc4e = V \u22121 \ud835\udc59,\ud835\udc4e \ud835\udc59\u2211\ufe01 \ud835\udc60=1 1(\ud835\udc4e\ud835\udc60 = \ud835\udc4e)\ud835\udefe\ud835\udc59\u2212\ud835\udc60x\ud835\udc60,\ud835\udc4e\ud835\udc5f\ud835\udc60 ,\n\ud835\udc64\u210e\ud835\udc52\ud835\udc5f\ud835\udc52 V\ud835\udc59,\ud835\udc4e = \ud835\udc59\u2211\ufe01 \ud835\udc60=1 1(\ud835\udc4e\ud835\udc60 = \ud835\udc4e)\ud835\udefe\ud835\udc59\u2212\ud835\udc60x\ud835\udc60,\ud835\udc4ex\u22a4\ud835\udc60,\ud835\udc4e + \ud835\udf06I\ud835\udc51 ,\n(7)\nand I\ud835\udc51 denotes the \ud835\udc51-dimensional identity matrix. Here, similar to V\u22121\n\ud835\udc59,\ud835\udc4e , we define a matrix V\u0303\ud835\udc59,\ud835\udc4e as an intermediate variable in our\nalgorithm to help obtain the confidence ellipsoid:\nV\u0303\ud835\udc59,\ud835\udc4e = \ud835\udc59\u2211\ufe01 \ud835\udc60=1 1(\ud835\udc4e\ud835\udc60 = \ud835\udc4e)\ud835\udefe2(\ud835\udc59\u2212\ud835\udc60 )x\ud835\udc60,\ud835\udc4ex\u22a4\ud835\udc60,\ud835\udc4e + \ud835\udf06I\ud835\udc51 , (8)\nwhich is strongly connected to the variance of the estimator \ud835\udf3d\ud835\udc59,\ud835\udc4e . Applying the online version of ridge regression [25, 37, 50], the update formulations of V\ud835\udc4e\ud835\udc59 , V\u0303\ud835\udc4e\ud835\udc59 , \ud835\udf3d\ud835\udc4e\ud835\udc59 are shown as follows:\nV\ud835\udc4e\ud835\udc59 = \ud835\udefeV\ud835\udc4e\ud835\udc59 + x\ud835\udc59,\ud835\udc4e\ud835\udc59 x \u22a4 \ud835\udc59,\ud835\udc4e\ud835\udc59 + (1 \u2212 \ud835\udefe)\ud835\udf06I\ud835\udc51 , V\u0303\ud835\udc4e\ud835\udc59 = \ud835\udefe 2V\u0303\ud835\udc4e\ud835\udc59 + x\ud835\udc59,\ud835\udc4e\ud835\udc59 x \u22a4 \ud835\udc59,\ud835\udc4e\ud835\udc59 + (1 \u2212 \ud835\udefe2)\ud835\udf06I\ud835\udc51 , b\ud835\udc4e\ud835\udc59 = \ud835\udefeb\ud835\udc4e\ud835\udc59 + \ud835\udc5f\ud835\udc59x\ud835\udc59,\ud835\udc4e\ud835\udc59 , \ud835\udf3d\ud835\udc4e\ud835\udc59 = V \u22121 \ud835\udc4e\ud835\udc59 b\ud835\udc4e\ud835\udc59 ,\n(9)\nwhere b is an intermediate variable to help compute \ud835\udf3d . The initialization of V\ud835\udc4e, V\u0303\ud835\udc4e, \ud835\udf3d\ud835\udc4e for each arm \ud835\udc4e is provided in the Initialize part of Algorithm 1. During the algorithm execution, we use Eq. 9 to update such variables for the selected arm at each interaction.\nFinally, we introduce how our non-stationary LinUCB-based policy \ud835\udf0b\ud835\udc46\ud835\udc38 selects themost promising arm. Following relatedworks [25, 37, 47, 50], we first obtain the confidence value \ud835\udefd\ud835\udc59 (coefficient of confidence ellipsoid) which controls the exploration level:\n\ud835\udefd\ud835\udc59 = \u221a \ud835\udf06\ud835\udc46 + \ud835\udf0e \u221a\ufe04 2 log( 1\n\ud835\udeff ) + \ud835\udc51 log(1 + \ud835\udc48 2 (1 \u2212 \ud835\udefe2\ud835\udc59 ) \ud835\udf06\ud835\udc51 (1 \u2212 \ud835\udefe2) ), (10)\nwhere \ud835\udc46 is the upper bound for parameters (\u2200\ud835\udc59, \ud835\udc4e, \u2225\ud835\udf3d \u2217 \ud835\udc59,\ud835\udc4e \u22252 \u2264 \ud835\udc46),\ud835\udc48 is the upper bound for contexts (\u2200\ud835\udc59, \ud835\udc4e, \u2225x\ud835\udc59,\ud835\udc4e \u22252 \u2264 \ud835\udc48 ), \ud835\udf0e is the subgaussian constant, and \ud835\udeff is a pre-designated probability. Based on this, we can derive the upper confidence bound (UCB) which considers both the estimated reward and the uncertainty (confidence ellipsoid) of the reward estimation, in such a way to better balance the exploration and exploitation for arm selection:\n\ud835\udc48\ud835\udc36\ud835\udc35(\ud835\udc4e) = x\u22a4 \ud835\udc59,\ud835\udc4e \ud835\udf3d\ud835\udc4e + \ud835\udefd\ud835\udc59 \u221a\ufe03 x\u22a4 \ud835\udc59,\ud835\udc4e V\u22121\ud835\udc4e V\u0303\ud835\udc4eV\u22121\ud835\udc4e x\ud835\udc59,\ud835\udc4e . (11)\nAfter computing\ud835\udc48\ud835\udc36\ud835\udc35(\ud835\udc4e) for each arm, \ud835\udf0b\ud835\udc46\ud835\udc38 will select the arm with the highest UCB score as the embedding size control command."
        },
        {
            "heading": "4.4 Theoretical Analysis",
            "text": "We provide the upper regret bound analysis for DESS in this section. As far as we know, this is the first theoretical regret bound for the non-stationary contextual linear bandit with disjoint armassociated parameter vectors \ud835\udf3d\ud835\udc4e .\nDefinition 1. Parameter Variation Budget. For the search policy, the true oracle parameters {\ud835\udf3d \u2217\n\ud835\udc59,\ud835\udc4e }\ud835\udc3f \ud835\udc59=1 are actually unknown.\nAnd their shifts can be quantified by the variation budget which\nAlgorithm 1 Dynamic Embedding Size Search (DESS) Input: \ud835\udf02 (learning rate for recommender model), probability \ud835\udeff , subgaussianity constant \ud835\udf0e , context dimension \ud835\udc51 , regularization \ud835\udf06, upper bound for contexts\ud835\udc48 , upper bound for parameters \ud835\udc46 , discount factor \ud835\udefe Initialize: initial recommender model\ud835\udc400, b\ud835\udc4e = 0R\ud835\udc51 ,V\ud835\udc4e = \ud835\udf06I\ud835\udc51 , V\u0303\ud835\udc4e = \ud835\udf06I\ud835\udc51 , \ud835\udf3d\ud835\udc4e = 0R\ud835\udc51 for each arm \ud835\udc4e, user-item interaction data stream {(\ud835\udc37\ud835\udc61\ud835\udc5f1 , \ud835\udc37 \ud835\udc61\ud835\udc52 1 ), ..., (\ud835\udc37 \ud835\udc61\ud835\udc5f \ud835\udc47 , \ud835\udc37\ud835\udc61\ud835\udc52 \ud835\udc47 )} which contains \ud835\udc47 segments of data in chronological order Process: 1: for each \ud835\udc61 = 1,2,...,\ud835\udc47 do 2: /\u2217 Update Non-stationary LinUCB-based Policy \ud835\udf0b\ud835\udc46\ud835\udc38 \u2217/ 3: Collect the last segment of data (\ud835\udc37\ud835\udc61\ud835\udc5f\n\ud835\udc61\u22121, \ud835\udc37 \ud835\udc61\ud835\udc52 \ud835\udc61\u22121)\n4: for each interaction in (\ud835\udc37\ud835\udc61\ud835\udc5f \ud835\udc61\u22121 \u222a \ud835\udc37 \ud835\udc61\ud835\udc52 \ud835\udc61\u22121) do 5: Receive context x\ud835\udc59,\ud835\udc4e for each arm \ud835\udc4e 6: \ud835\udefd\ud835\udc59 = \u221a \ud835\udf06\ud835\udc46 + \ud835\udf0e \u221a\ufe02 2 log( 1 \ud835\udeff ) + \ud835\udc51 log(1 + \ud835\udc48 2 (1\u2212\ud835\udefe2\ud835\udc59 ) \ud835\udf06\ud835\udc51 (1\u2212\ud835\udefe2 ) )\n7: \ud835\udc48\ud835\udc36\ud835\udc35(\ud835\udc4e) = x\u22a4 \ud835\udc59,\ud835\udc4e \ud835\udf3d\ud835\udc4e + \ud835\udefd\ud835\udc59 \u221a\ufe03 x\u22a4 \ud835\udc59,\ud835\udc4e V\u22121\ud835\udc4e V\u0303\ud835\udc4eV\u22121\ud835\udc4e x\ud835\udc59,\ud835\udc4e for each \ud835\udc4e\n8: \ud835\udc4e\ud835\udc59 = \ud835\udc4e\ud835\udc5f\ud835\udc54\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc4e\u2208A (\ud835\udc48\ud835\udc36\ud835\udc35(\ud835\udc4e)) 9: Temporarily change embedding sizes according to \ud835\udc4e\ud835\udc59 10: Temporarily tune embedding parameters 11: Input interaction into\ud835\udc40\ud835\udc61\u22121 and receive reward \ud835\udc5f\ud835\udc59 12: Updating: V\ud835\udc4e\ud835\udc59 = \ud835\udefeV\ud835\udc4e\ud835\udc59 + x\ud835\udc59,\ud835\udc4e\ud835\udc59 x \u22a4 \ud835\udc59,\ud835\udc4e\ud835\udc59\n+ (1 \u2212 \ud835\udefe)\ud835\udf06I\ud835\udc51 , V\u0303\ud835\udc4e\ud835\udc59 = \ud835\udefe2V\u0303\ud835\udc4e\ud835\udc59 +x\ud835\udc59,\ud835\udc4e\ud835\udc59 x \u22a4 \ud835\udc59,\ud835\udc4e\ud835\udc59 +(1\u2212\ud835\udefe2)\ud835\udf06I\ud835\udc51 , b\ud835\udc4e\ud835\udc59 = \ud835\udefeb\ud835\udc4e\ud835\udc59 +\ud835\udc5f\ud835\udc59x\ud835\udc59,\ud835\udc4e\ud835\udc59 , \ud835\udf3d\ud835\udc4e\ud835\udc59 = V \u22121 \ud835\udc4e\ud835\udc59\nb\ud835\udc4e\ud835\udc59 13: end for 14: 15: /\u2217 Update Recommendation Model\ud835\udc40 \u2217/ 16: Collect the current segment of data (\ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc61 , \ud835\udc37\ud835\udc61\ud835\udc52\ud835\udc61 ) 17: Output actions \ud835\udc4e\ud835\udc61 from \ud835\udf0b\ud835\udc46\ud835\udc38 18: Permanently change the embedding sizes for user-item\npairs in \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc61 according to \ud835\udc4e\ud835\udc61 19: Input \ud835\udc37\ud835\udc61\ud835\udc5f\ud835\udc61 to\ud835\udc40\ud835\udc61\u22121 and update the model to\ud835\udc40\ud835\udc61 20: Report the accuracy and test loss of\ud835\udc40\ud835\udc61 on test data \ud835\udc37\ud835\udc61\ud835\udc52\ud835\udc61 21: end for\nmeasures the magnitude of non-stationarity in the dynamical data stream. This can be defined as:\n\ud835\udc35\u2217\ud835\udc3f := \ud835\udc3f\u22121\u2211\ufe01 \ud835\udc59=1 \ud835\udc5a\ud835\udc4e\ud835\udc65 \ud835\udc4e \u2225\ud835\udf3d \u2217 \ud835\udc59+1,\ud835\udc4e \u2212 \ud835\udf3d \u2217 \ud835\udc59,\ud835\udc4e \u22252 . (12)\nAssumption 1. Variation Budget Upper Bound We assume that the variation budget is bounded by a known quantity \ud835\udc35\ud835\udc3f similar to the previous literature [3, 25, 37, 50], that is \ud835\udc35\u2217\ud835\udc3f \u2264 \ud835\udc35\ud835\udc3f .\nAssumption 2. Bounded Reward We assume that the reward \ud835\udc5f\ud835\udc59 is bounded by the subgaussianity constant 2\ud835\udf0e , 0 \u2264 \ud835\udc5f\ud835\udc59 \u2264 2\ud835\udf0e which can be easily satisfied. For example, in the above algorithm description part, the \ud835\udf0e can be set as 0.5.\nLemma 1. Let prediction error\ud835\udc38\ud835\udc5f (x\ud835\udc59,\ud835\udc4e, \ud835\udf3d\ud835\udc59,\ud835\udc4e) = |\u27e8x\ud835\udc59,\ud835\udc4e, \ud835\udf3d \u2217\ud835\udc59,\ud835\udc4e\u27e9\u2212\u27e8x\ud835\udc59,\ud835\udc4e, \ud835\udf3d\ud835\udc59,\ud835\udc4e\u27e9|, \ud835\udc58 = \ud835\udc60\ud835\udc62\ud835\udc5d\nx,\ud835\udf3d \u27e8x, \ud835\udf3d \u27e9, \ud835\udc50 = \ud835\udc56\ud835\udc5b\ud835\udc53 x,\ud835\udf3d \u27e8x, \ud835\udf3d \u27e9, and \ud835\udc37 \u2208 N\u2217. With probability at least\n1 \u2212 \ud835\udeff : for all \ud835\udc4e \u2265 1, the following holds:\n\ud835\udc38\ud835\udc5f (x\ud835\udc59,\ud835\udc4e, \ud835\udf3d\ud835\udc59,\ud835\udc4e) \u2264 2\ud835\udc58\ud835\udc50 \ud835\udefd\ud835\udc59 \u2225x\ud835\udc59,\ud835\udc4e \u2225V\u22121 \ud835\udc59,\ud835\udc4e + 2\ud835\udc58\ud835\udc48\ud835\udc50 \u221a\ufe03 1 + \ud835\udc3f2 \ud835\udf06 (1\u2212\ud835\udefe ) ( 2\ud835\udc58\ud835\udc46\ud835\udc48 2 \ud835\udf06 \ud835\udefe\ud835\udc37 1\u2212\ud835\udefe +\n\ud835\udc58\n\u221a\ufe03 \ud835\udc51 \ud835\udf06 (1\u2212\ud835\udefe ) \u2211\ud835\udc59\u22121 \ud835\udc60=\ud835\udc59\u2212\ud835\udc37 \u2225\ud835\udf3d \u2217 \ud835\udc60,\ud835\udc4e \u2212 \ud835\udf3d \u2217\ud835\udc60+1,\ud835\udc4e \u22252).\nLemma 2. Similar to [37], let {x\ud835\udc60,\ud835\udc4e\u2217 \ud835\udc59 }\ud835\udc59 \ud835\udc60=1 a sequence in R \ud835\udc51 such that \u2225x\ud835\udc60,\ud835\udc4e\u2217\n\ud835\udc59 \u22252 \u2264 \ud835\udc48 for all \ud835\udc60 \u2208 N\u2217. \ud835\udc4e\u2217\ud835\udc59 is the optimal arm that \ud835\udf0b\ud835\udc46\ud835\udc38\nshould select at \ud835\udc59-th interaction. For \ud835\udc59 \u2265 1, define\ud835\udc49\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 := \u2211\ud835\udc59 \ud835\udc60=1 1(\ud835\udc4e\ud835\udc60 = \ud835\udc4e\u2217 \ud835\udc59 )\ud835\udefe\ud835\udc59\u2212\ud835\udc60x\ud835\udc60,\ud835\udc4e\u2217 \ud835\udc59 x\u22a4 \ud835\udc60,\ud835\udc4e\u2217\n\ud835\udc59 + \ud835\udf06I\ud835\udc51 . Given \ud835\udf06 \u2265 0, the following inequality holds:\u2211\ud835\udc3f \ud835\udc59=1 \u2225x\ud835\udc59,\ud835\udc4e\u2217\ud835\udc59 \u2225V\u22121\ud835\udc59,\ud835\udc4e\u2217\n\ud835\udc59\n\u2264 2 max(1, \ud835\udc3f2/\ud835\udf06) (\ud835\udc51\ud835\udc3f log( 1\ud835\udefe )+\ud835\udc51 log(1+ \ud835\udc48 2 (1\u2212\ud835\udefe\ud835\udc3f ) \ud835\udf06\ud835\udc51 (1\u2212\ud835\udefe ) )).\nTheorem 1. Under the assumptions above, the regret of the DESS algorithm is bounded for all \ud835\udefe \u2208 (0, 1) and integer \ud835\udc37 \u2265 1, with the probability at least 1 \u2212 \ud835\udeff , by\n\ud835\udc45\ud835\udc3f \u2264 \u221a\ufe01 32 max(1,\ud835\udc48 2/\ud835\udf06) \ud835\udc58\ud835\udc50 \ud835\udefd\ud835\udc3f \u221a \ud835\udc51\ud835\udc3f \u221a\ufe02 \ud835\udc3f log( 1\ud835\udefe ) + log(1 + \ud835\udc48 2 (1\u2212\ud835\udefe\ud835\udc3f ) \ud835\udf06\ud835\udc51 (1\u2212\ud835\udefe ) ) + 8\ud835\udc582\ud835\udc46\ud835\udc48 3\ud835\udefe\ud835\udc37 \ud835\udc50\ud835\udf06 (1\u2212\ud835\udefe ) \ud835\udc3f + 8\ud835\udc582\ud835\udc46\ud835\udc48 4\ud835\udefe\ud835\udc37\n\ud835\udc50\ud835\udf06 3 2 (1\u2212\ud835\udefe ) 3 2 \ud835\udc3f + 4\ud835\udc582\ud835\udc48\ud835\udc37 \ud835\udc50 \u221a \ud835\udf06\n\u221a\ufe03 \ud835\udc51\n1\u2212\ud835\udefe \ud835\udc35\ud835\udc3f + 4\ud835\udc582\ud835\udc48 2\ud835\udc37 \ud835\udc50\ud835\udf06\n\u221a \ud835\udc51 1\u2212\ud835\udefe \ud835\udc35\ud835\udc3f .\nCorollary 1. By choosing discount factor\ud835\udefe = 1\u2212(\ud835\udc35\ud835\udc3f/( \u221a \ud835\udc51\ud835\udc3f))2/5, the regret of DESS algorithm is asymptotically upper bounded with high probability by a term O(\ud835\udc519/10\ud835\udc351/5\n\ud835\udc3f \ud835\udc3f4/5) when \ud835\udc3f \u2192 \u221e.\nThe detailed proofs of theorem 1 and corollary 1 are provided in Appendix B.1 and B.2, respectively."
        },
        {
            "heading": "4.5 Embedding Size Adaptive Neural Network",
            "text": "4.5.1 Model Inference. As mentioned in Section 2, based on the NCFmodel [19, 23, 29], we design an embedding size adaptive neural network shown in Figure 2 as the streaming recommendation model \ud835\udc40 in Algorithm 1. Different from the conventional design that assigns one or a set of embedding sizes for each user or item in advance [19, 28, 29, 45, 49], the embedding size of each user or item can be selected flexibly from a group of size candidates at each timestep in our proposed structure. Suppose that the embedding size group for users and items are both \ud835\udc60\ud835\udc56\ud835\udc67\ud835\udc52 = [\ud835\udc600, \ud835\udc601, .., \ud835\udc60\ud835\udc5b] (\ud835\udc600 < \ud835\udc601 ... < \ud835\udc60\ud835\udc5b) for simplicity. Actually, the candidates for each user or item can be different. The initial size for each ID is set as the minimum value \ud835\udc600 of the candidate group. {W01, b0,W12, b1, ...,W\ud835\udc5b\u22121\ud835\udc5b, b\ud835\udc5b} is a sequence of linear transformation parameters that will unify the embedding size to \ud835\udc60\ud835\udc5b before inputting it to the representation learning part. Assume that the current embedding size for user \ud835\udc62 is \ud835\udc60\ud835\udc56 and the embedding vector is E\ud835\udc62\n\ud835\udc56 , the forward propagation process in embed-\nding input part is: E\u0302\ud835\udc62 \ud835\udc56+1 = W\ud835\udc56\ud835\udc56+1E \ud835\udc62 \ud835\udc56 + b\ud835\udc56 , .., E\u0302\ud835\udc62\ud835\udc5b = W\ud835\udc5b\u22121\ud835\udc5bE\u0302\ud835\udc62\ud835\udc5b\u22121 + b\ud835\udc5b\u22121. The embedding vector will be transformed into the \ud835\udc60\ud835\udc5b-dimensional space R\ud835\udc60\ud835\udc5b . Then, an additional batch normalization with Tanh activation is necessary to tackle the magnitude differences between inner-batch transformed embeddings E\u0302\ud835\udc62\ud835\udc5b if processing a mini-\nbatch:\u0302E\ud835\udc62\ud835\udc5b = \ud835\udc61\ud835\udc4e\ud835\udc5b\u210e ( E\u0302\ud835\udc62\ud835\udc5b\u2212\ud835\udf07\ud835\udc35\u221a\ufe03 (\ud835\udf0e2\n\ud835\udc35 )2+\ud835\udf16\n) , where \ud835\udf07\ud835\udc35 is the mini-batch mean and\n\ud835\udf0e2 \ud835\udc35 is the mini-batch variance. The batch size can be set as 1 when inferring a single sample. After executing a similar transformation on item \ud835\udc56 , we obtain the transformed user embedding E\u0302\ud835\udc62\ud835\udc5b and item embedding E\u0302\ud835\udc56\ud835\udc5b with the same dimension \ud835\udc60\ud835\udc5b . The following representation learning part is a sequence of BatchNorm, Linear,\nand Tanh activation layers: h1 = \ud835\udc35\ud835\udc4e\ud835\udc61\ud835\udc50\u210e\ud835\udc41\ud835\udc5c\ud835\udc5f\ud835\udc5a(\ud835\udc50\ud835\udc4e\ud835\udc61 (E\u0302\ud835\udc62\ud835\udc5b, E\u0302\ud835\udc56\ud835\udc5b)), h2 = \ud835\udc35\ud835\udc4e\ud835\udc61\ud835\udc50\u210e\ud835\udc41\ud835\udc5c\ud835\udc5f\ud835\udc5a(\ud835\udc3f\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f (h1)), y\u0302\ud835\udc62\ud835\udc56 = \ud835\udc3f\ud835\udc56\ud835\udc5b\ud835\udc52\ud835\udc4e\ud835\udc5f (\ud835\udc47\ud835\udc4e\ud835\udc5b\u210e(h2)) .\n4.5.2 Embedding Warm Initialization. When receiving the increasing embedding size command from \ud835\udf0b\ud835\udc46\ud835\udc38 , there are two intuitive ways to initialize the embedding vector with the new embedding size: 1) zero initialization/random initialization, and 2) initialization with the information from previous embedding vectors. We take the second type of initialization and name it as embedding warm initialization (EWI). We perform a linear transformation sharing the parameters with above on the previous embedding E\ud835\udc56 \u2208 R\ud835\udc60\ud835\udc56 and obtain E\ud835\udc56+1 in the \ud835\udc60\ud835\udc56+1-dimensional space R\ud835\udc60\ud835\udc56+1 : E\ud835\udc56+1 = W\ud835\udc56\ud835\udc56+1E\ud835\udc56 +b\ud835\udc56 .\nAfter the embedding warm initialization, the model inference starts from E\ud835\udc56+1 and follows the forward propagation introduced in Section 4.5.1."
        },
        {
            "heading": "5 EXPERIMENTS",
            "text": "In this section, to comprehensively demonstrate the effectiveness of our method, we mainly focus on the following questions: \u2022 RQ1: Does our method achieve better recommendation accuracy than the state-of-art methods along the timeline? \u2022 RQ2: Does our method get sublinear regret on selecting embedding sizes, outperforming previous methods? \u2022 RQ3: Whether our method consumes less computer memory compared with baseline methods? \u2022 RQ4: Whether our method is more time-efficient than baselines for streaming recommendation? \u2022 RQ5: Whether our method is applicable to different base recommendation models, like matrix factorization-based model and distance-based model? \u2022 RQ6: Whether Embedding Warm Initialization technique contributes to the model performance improvement?"
        },
        {
            "heading": "5.1 Experiment Setting",
            "text": "5.1.1 Datasets. We evaluate our method on four public recommender system datasets. The data and code will be released soon. \u2022 ml-20m [16]: This dataset describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 20,000,263 ratings created by 138,493 users over 27,278 movies between January 09, 1995 and March 31, 2015. \u2022 ml-latest [16]: This is a recently released dataset from MovieLens and contains 27,753,444 ratings by 283,228 users over 58,098 movies between January 09, 1995 and September 26, 2018. \u2022 Amazon-Books [18]: This dataset contains book reviews from Amazon, including 22,507,154 ratings spanning May 1996 - July 2014. We download the ratings-only dataset and preprocess it like [40]. In the filtered dataset, each user has reviewed at least 20 books and each book has been reviewed by at least 20 users. \u2022 Amazon-CDs [18]: This is a CD review dataset also from the website above, including 3,749,003 ratings covering the same time span. A similar preprocessing operation is executed and the filtering threshold is set as 10.\n5.1.2 Tasks. We adopt the top-\ud835\udc58 recommendation and rating score prediction tasks to evaluate the effectiveness of our method. \u2022 Top-\ud835\udc58 Recommendation: This is one of the most common recommendation tasks to evaluate the model\u2019s ability on inferring\nUser Embedding Input\nusers\u2019 intentions. In detail, the model needs to recommend a list of items with the length \ud835\udc58 to each user according to their historical interaction records. The accuracy is measured with metrics Recall@\ud835\udc58 and NDCG@\ud835\udc58 . Recall@\ud835\udc58 indicates what percentage of a user\u2019s rated items can emerge in the list. NDCG@\ud835\udc58 is the normalized discounted cumulative gain at \ud835\udc58 , which takes the position of correctly recommended items into consideration. Here, we take \ud835\udc58 to be 10. \u2022 Rating Score Prediction: Similar to previous works [28, 29, 51], we also utilize the following two rating score prediction subtasks as the benchmark: binary classification andmulticlass classification. The former can be understood as predicting if a user likes an item. And the latter can be used to estimate the discretized interest degree of users. For binary classification task, when preprocessing the raw data, we set the rating scores greater than the threshold 3.5 to 1.0 and others to 0.0. The model performance is measured with classification accuracy and mean-squared-error loss [29, 51]. For multiclass classification task, we regard the 5-star rating scores as 5 classes. The model performance is measured with classification accuracy and cross-entropy loss [29, 51].\n5.1.3 Baselines. Following methods serve as the baselines:\n\u2022 Fixed: The base Neural Collaborative Filtering [19] model, where the embedding sizes for users and items are both identical and fixed. To fairly compare experimental results, , we set the embedding sizes to 128 and 222, regarding the two versions Fixed-128 and Fixed-222 of the model, respectively. \u2022 DARTS [28]: A type of soft-selection algorithm developed from the neural architecture search. The weight vectors regarding embedding sizes are trained directly with gradient backpropagation.\n\u2022 AutoEmb [51]: Another type of soft-selection algorithm similar to DARTS. However, the weight vectors are the outputs of controller neural networks independent of the recommendation model. \u2022 ESAPN [29]: A type of hard-selection algorithm using the REINFORCE algorithm [46] as the controller to dynamically choose the suitable embedding size for corresponding users and items.\nDue to the fact that Amazon datasets cannot provide the raw item feature vectors, we run both DESS-CV (with (\ud835\udc39\ud835\udc45\ud835\udc38\ud835\udc62\n\ud835\udc59 , \ud835\udc3c\ud835\udc41\ud835\udc37\ud835\udc62 \ud835\udc59 ) and\n(\ud835\udc39\ud835\udc45\ud835\udc38\ud835\udc56 \ud835\udc59 , \ud835\udc43\ud835\udc42\ud835\udc37\ud835\udc56 \ud835\udc59 ) as embedding size search policies input) and DESSFRE (with only historical frequency as search policies input) on ml-20m and ml-latest datasets while only DESS-FRE on AmazonBooks and Amazon-CDs datasets. The comparison between DESSCV and DESS-FRE can be regarded as the ablation study to the embedding size indicators proposed in Section 4.2. All the results below are the average of five trials with different random seeds."
        },
        {
            "heading": "5.2 Results and Analysis",
            "text": "5.2.1 Recommendation Accuracy (RQ1). In Tables 1, 2 and 3, we report the average performance of recommendation models on test data sequence {\ud835\udc37\ud835\udc61\ud835\udc521 , ..., \ud835\udc37 \ud835\udc61\ud835\udc52 \ud835\udc47 } of each task. First, we observe that DESS performs significantly better than the fixed methods and the soft-selection methods. This proves that hard-selection, generally speaking, is a more effective way to search embedding sizes. Second, we notice that our DESS-FRE and DESS-CV achieve better results compared with the state-of-the-art hard-selection algorithm ESAPN on all tasks and datasets. This demonstrates the effectiveness of DESS algorithm in improving the streaming recommendation. Third, by comparing the results of DESS-FRE with ESAPN and\nDESS-CV with DESS-FRE, respectively, we can find that the nonstationary LinUCB-based search policy \ud835\udf0b\ud835\udc46\ud835\udc38 and the two indicators (\ud835\udc3c\ud835\udc41\ud835\udc37 and \ud835\udc43\ud835\udc42\ud835\udc37) both contribute to the performance gains.\n5.2.2 Embedding Size Selection Regret (RQ2). We report the regret in terms of users due to the space limitation. The item side has a similar trend. Fixed embedding size methods and soft-selection methods have no regret because they actually use the embeddings of all sizes at the same time. We illustrate the regret curves of two rating score prediction tasks on each dataset in Figure 3. First, the observed decline in regret connects the aforementioned improvement in accuracy, justifying the advantage of modeling the\ndynamic embedding size search as bandits. Second, the regret can be reduced several times to dozens of times compared with ESAPN. The regret of DESS-CV is a bit lower than that of DESS-FRE. These demonstrate the effectiveness of \ud835\udf0b\ud835\udc46\ud835\udc38 and also the two indicators. Third, from the regret curves, we observe the sublinear increase phenomena of DESS-FRE and DESS-CV, which is also in line with the regret upper bound guarantee given in Section 4.4.\n5.2.3 Model Memory Cost (RQ3). In Figure 4, we calculate the average number of embedding parameters for each algorithm on each task. From this figure, we observe that the embedding parameter quantity of DESS-FRE is much less than that of other\nfour methods. As for ml-20m, the memory consumption of Fixed128 and two soft selection approaches are 1.93 times, 3.35 times, and 3.45 times of DESS-FRE. In the recommendation tasks on mllatest dataset, our method only consumes 50.2%, 28.9%, 28.9% and 28.2% memory compared with the Fixed-128, Fixed-222, DARTS, and AutoEmb, respectively. Moreover, the embedding memory cost brought by DESS-CV is even less than that of DESS-FRE. Similar memory overhead savings can also be observed on Amazon datasets. These all certify that our proposed methods can reduce the memory cost effectively and contribute to the more efficient algorithm DESS.\n5.2.4 Time Efficiency Analysis (RQ4). Time efficiency is also of great significance when deploying streaming recommendation models in real world. In the experiments, we count the average training time and average inference time of our method and embedding size-changeable baselines for the above two classification tasks on ml-latest and ml-20m datasets. The results are shown in Figure 5. From the figure, we can observe that the average training time of ourDESS algorithms is much less that of other soft-selection and hard-selection methods. More precisely, the training time of DESS-FRE is no more than 20% \u223c 30% of Darts and is even no more than 10% of AutoEmb. We can also observe a similar trend in average inference time histogram. Thus, we can speculate that our\nDESS algorithm holds obvious time efficiency advantage compared with previous methods. This is actually because that the bandit inherently has more lighter model and faster decision-making process compared with deep neural work-based and reinforcement learning-based embedding size selection policies. Besides, we can find that both the average training time and average inference time of DESS-FRE are less than DESS-CV to some extent. This is due to the lower input dimension and the smaller linear matrix in the bandit\u2019s reward model, which finally lead to much faster computation.\n5.2.5 Method Applicability Analysis (RQ5). We also explore the effects of our method when choosing the matrix factorizationbased model and distance-based model as the base streaming recommendation models, respectively. Different dynamic embedding size search methods are evaluated with the rating score binary classification task on ml-20m and ml-latest datasets. From the accuracy reported in Table 4, it can be first noticed that the recommendation models with fixed embedding sizes (Fixed-128 and Fixed-222) are much worse than that with dynamic embedding sizes. This also confirms the necessity of the dynamic embedding size search in the streaming recommendation. Second, we observe that DESS-CV\noutperforms all the baselines regardless of datasets and recommendation models. Even the DESS-FRE without the support from \ud835\udc3c\ud835\udc41\ud835\udc37 and \ud835\udc43\ud835\udc42\ud835\udc37 is still superior to all the previous methods in most cases. Such experimental results demonstrate that our algorithm can be a general approach towards more effective dynamic embedding size search in streaming recommendation.\n5.2.6 Ablation Study (RQ6). To validate the effectiveness of Embedding Warm Initialization technique proposed in Section 4.5, we also conduct the experiments of DESS-FRE (w/o EWI) and DESS-CV (w/o EWI) on four datasets, whose results are shown in Tables 1, 2, and 3. We can observe that, DESS-FRE and DESS-CV both achieve stable performance gain over DESS-FRE (w/o EWI) and DESS-CV (w/o EWI), respectively, especially onml-20m andml-latest datasets. The limited improvement on Amazon datasets may be due to the bottleneck of the base recommender model itself. These results demonstrate that initializing the embeddings with previous information via a simple linear transformation can effectively benefit the recommendation performance along the timeline."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "In this work, we first rethink the streaming model update process and then model the dynamic embedding size as a bandit problem. Based on the embedding size indicator analysis, we provide the DESS algorithm and obtain a sublinear dynamic regret upper bound as the theoretical guarantee. The results of recommendation accuracy, memory cost, and time consumption across various recommendation tasks on four open datasets demonstrate the effectiveness of our method. In the future, we plan to explore the automated tuning methods of other hyperparameters like learning rate in the streaming machine learning."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This work was supported by the Start-up Grant (No. 9610564) and the Strategic Research Grant (No. 7005847) of City University of Hong Kong."
        },
        {
            "heading": "A NOTATIONS",
            "text": "We summarize the main notations used in this paper in Table 5.\nTable 5: Major notations.\n\ud835\udc3e The number of arms (embedding size candidates) \ud835\udc47 The total number of time steps \ud835\udc3f The length of the whole data stream \ud835\udc36 The set of contexts for non-stationary LinUCB \ud835\udc48 The upper bound of contexts for non-stationary LinUCB \ud835\udc46 The upper bound of parameters in reward models of bandit \ud835\udefe The discount factor in non-stationary LinUCB bandit \ud835\udc51 The dimension of context vectors for bandit \ud835\udf0b\ud835\udc62 \ud835\udc46\ud835\udc38\nThe dynamic embedding size search policy for users \ud835\udf0b\ud835\udc56 \ud835\udc46\ud835\udc38\nThe dynamic embedding size search policy for items \ud835\udc5f\ud835\udc59 The reward received at \ud835\udc59-th user-item interaction (\ud835\udc59 \u2264 \ud835\udc3f) \ud835\udf3d\ud835\udc59,\ud835\udc4e The updated parameter of the reward model for arm \ud835\udc4e at \ud835\udc59-th user-item interaction\n\ud835\udf3d \u2217 \ud835\udc59,\ud835\udc4e The parameter of the oracle reward model for arm \ud835\udc4e at \ud835\udc59-th user-item interaction \ud835\udc40\ud835\udc61 The updated recommendation model at time step \ud835\udc61 (\ud835\udc61 \u2264 \ud835\udc47 ) F\ud835\udc56 The raw feature vector for item \ud835\udc56"
        },
        {
            "heading": "B THEOREM PROOF B.1 Proof of Theorem 1",
            "text": "Proof. First recall that \ud835\udc4e\u2217 \ud835\udc59 = arg\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc4e\u2208A \u27e8x\ud835\udc59 , \ud835\udf3d \u2217\ud835\udc59,\ud835\udc4e\u27e9 and x\ud835\udc59,1 =\nx\ud835\udc59,2 = ... = x\ud835\udc59,\ud835\udc3e = x\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 = x\ud835\udc59 = x(\ud835\udc61, \ud835\udc57 ) (\ud835\udc59 = \ud835\udc61 \u00d7 |\ud835\udc37\ud835\udc61 | + \ud835\udc57),\n\ud835\udc45\ud835\udc3f = \ud835\udc47\u2211\ufe01 \ud835\udc61=1 |\ud835\udc37\ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc61 |\u2211\ufe01 \ud835\udc57=1 \u27e8x(\ud835\udc61, \ud835\udc57 ) , \ud835\udf3d \u2217(\ud835\udc61, \ud835\udc57 ),\ud835\udc4e\u2217(\ud835\udc61,\ud835\udc57 ) \u27e9 \u2212 \u27e8x(\ud835\udc61, \ud835\udc57 ) , \ud835\udf3d \u2217(\ud835\udc61, \ud835\udc57 ),\ud835\udc4e (\ud835\udc61,\ud835\udc57 ) \u27e9\n= \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \u27e8x\ud835\udc59 , \ud835\udf3d \u2217\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 \u27e9 \u2212 \u27e8x\ud835\udc59 , \ud835\udf3d \u2217\ud835\udc59,\ud835\udc4e\ud835\udc59 \u27e9\n= \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \u27e8x\ud835\udc59 , \ud835\udf3d \u2217\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 \u27e9 \u2212 \u27e8x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 \u27e9 + \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \u27e8x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 \u27e9 \u2212 \u27e8x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\ud835\udc59 \u27e9\n+ \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \u27e8x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\ud835\udc59 \u27e9 \u2212 \u27e8x\ud835\udc59 , \ud835\udf3d \u2217 \ud835\udc59,\ud835\udc4e\ud835\udc59 \u27e9\n= \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \u27e8x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 \u27e9 \u2212 \u27e8x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\ud835\udc59 \u27e9 + \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \u27e8x\ud835\udc59 , \ud835\udf3d \u2217\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 \u27e9 \u2212 \u27e8x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 \u27e9\n+ \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \u27e8x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\ud835\udc59 \u27e9 \u2212 \u27e8x\ud835\udc59 , \ud835\udf3d \u2217 \ud835\udc59,\ud835\udc4e\ud835\udc59 \u27e9\n\u2264 2\ud835\udc58 \ud835\udc50 \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \ud835\udefd\ud835\udc61 [\u2225x\ud835\udc59 \u2225\ud835\udc49 \u22121 \ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 \u2212 \u2225x\ud835\udc59 \u2225\ud835\udc49 \u22121 \ud835\udc59,\ud835\udc4e\ud835\udc59 ] + \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \ud835\udc38\ud835\udc5f (x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 )\n+ \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \ud835\udc38\ud835\udc5f (x\ud835\udc59 , \ud835\udf3d\ud835\udc59,\ud835\udc4e\ud835\udc59 ).\n(13)\nThanks to Lemma 1 and Lemma 2:\n\ud835\udc45\ud835\udc3f \u2264 \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 4\ud835\udc58 \ud835\udc50 \ud835\udefd\ud835\udc59 \u2225x\ud835\udc59 \u2225\ud835\udc49 \u22121\n\ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59\ufe38 \ufe37\ufe37 \ufe38\n\ud835\udc451 \ud835\udc3f\n+ \ud835\udc47\u2211\ufe01 \ud835\udc59=1 4\ud835\udc58\ud835\udc48 \ud835\udc50\n\u221a\ufe04 1 + \ud835\udc48 2\n\ud835\udf06(1 \u2212 \ud835\udefe) 2\ud835\udc58\ud835\udc46\ud835\udc48 2 \ud835\udf06 \ud835\udefe\ud835\udc37\n1 \u2212 \ud835\udefe\ufe38 \ufe37\ufe37 \ufe38 \ud835\udc452 \ud835\udc3f\n+ \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 4\ud835\udc58\ud835\udc48 \ud835\udc50\n\u221a\ufe04 1 + \ud835\udc48 2\n\ud835\udf06(1 \u2212 \ud835\udefe) \ud835\udc59\u22121\u2211\ufe01 \ud835\udc60=\ud835\udc59\u2212\ud835\udc37 \ud835\udc58\n\u221a\ufe04 \ud835\udc51\n\ud835\udf06(1 \u2212 \ud835\udefe)\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc4e \u2225\ud835\udf3d \u2217 \ud835\udc60,\ud835\udc4e \u2212 \ud835\udf3d \u2217\ud835\udc60+1,\ud835\udc4e \u2225)\ufe38 \ufe37\ufe37 \ufe38\n\ud835\udc453 \ud835\udc3f\n.\n(14)\n\ud835\udc451\ud835\udc3f \u2264 \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 4\ud835\udc58 \ud835\udc50 \ud835\udefd\ud835\udc3f \u2225x\ud835\udc59 \u2225\ud835\udc49 \u22121 \ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59\n\u2264 4\ud835\udc58 \ud835\udc50 \ud835\udefd\ud835\udc3f \u221a \ud835\udc3f \u221a\u221a \ud835\udc3f\u2211\ufe01 \ud835\udc59=1 \u2225x\ud835\udc59 \u2225\ud835\udc49 \u22121 \ud835\udc59,\ud835\udc4e\u2217 \ud835\udc59 (\ud835\udc36\ud835\udc4e\ud835\udc62\ud835\udc61\u210e\ud835\udc66 \u2212 \ud835\udc46\ud835\udc50\u210e\ud835\udc64\ud835\udc4e\ud835\udc5f\ud835\udc67)\n\u2264 4\ud835\udc58 \ud835\udc50 \ud835\udefd\ud835\udc3f\n\u221a\ufe02 2\ud835\udc51\ud835\udc3fmax(1, \ud835\udc48 2\n\ud835\udf06 )\n\u221a\ufe04 \ud835\udc3f log( 1\n\ud835\udefe ) + log(1 + \ud835\udc48 2 (1 \u2212 \ud835\udefe\ud835\udc3f) \ud835\udf06\ud835\udc51 (1 \u2212 \ud835\udefe) ) (\ud835\udc3f\ud835\udc52\ud835\udc5a\ud835\udc5a\ud835\udc4e 2) .\n(15) Because \u221a\ufe03 1 + \ud835\udc48 2\n\ud835\udf06 (1\u2212\ud835\udf06) can be upper bounded by 1 + \ud835\udc48\u221a \ud835\udf06 (1\u2212\ud835\udf06) :\n\ud835\udc452\ud835\udc3f \u2264 8\ud835\udc582\ud835\udc46\ud835\udc48 3\ud835\udefe\ud835\udc37 \ud835\udc50\ud835\udf06(1 \u2212 \ud835\udefe) \ud835\udc3f + 8\ud835\udc582\ud835\udc46\ud835\udc48 4\ud835\udefe\ud835\udc37\n\ud835\udc50\ud835\udf06 3 2 (1 \u2212 \ud835\udefe) 3 2 \ud835\udc3f\n\ud835\udc453\ud835\udc3f \u2264 4\ud835\udc582\ud835\udc48\ud835\udc37 \ud835\udc50 \u221a \ud835\udf06\n\u221a\ufe04 \ud835\udc51\n1 \u2212 \ud835\udefe \ud835\udc35\ud835\udc3f + 4\ud835\udc582\ud835\udc48 2\ud835\udc37 \ud835\udc50\ud835\udf06\n\u221a \ud835\udc51 1 \u2212 \ud835\udefe \ud835\udc35\ud835\udc3f . (16)\nAdd such three components together, we have:\n\ud835\udc45\ud835\udc3f \u2264 \ud835\udc451\ud835\udc3f + \ud835\udc45 2 \ud835\udc3f + \ud835\udc45 3 \ud835\udc3f\n\u2264 \u221a\ufe01\n32 max(1,\ud835\udc48 2/\ud835\udf06)\ud835\udc58 \ud835\udc50 \ud835\udefd\ud835\udc3f\n\u221a \ud835\udc51\ud835\udc3f \u221a\ufe04 \ud835\udc3f log( 1\n\ud835\udefe ) + log(1 + \ud835\udc48 2 (1 \u2212 \ud835\udefe\ud835\udc3f) \ud835\udf06\ud835\udc51 (1 \u2212 \ud835\udefe) )+\n8\ud835\udc582\ud835\udc46\ud835\udc48 3\ud835\udefe\ud835\udc37 \ud835\udc50\ud835\udf06(1 \u2212 \ud835\udefe) \ud835\udc3f + 8\ud835\udc582\ud835\udc46\ud835\udc48 4\ud835\udefe\ud835\udc37\n\ud835\udc50\ud835\udf06 3 2 (1 \u2212 \ud835\udefe) 3 2 \ud835\udc3f + 4\ud835\udc58\n2\ud835\udc48\ud835\udc37\n\ud835\udc50 \u221a \ud835\udf06\n\u221a\ufe04 \ud835\udc51\n1 \u2212 \ud835\udefe \ud835\udc35\ud835\udc3f + 4\ud835\udc582\ud835\udc48 2\ud835\udc37 \ud835\udc50\ud835\udf06\n\u221a \ud835\udc51\n1 \u2212 \ud835\udefe \ud835\udc35\ud835\udc3f .\n(17) Thus, the theorem 1 is proved. \u25a1\nB.2 Proof of Corollary 1 Proof. By neglecting the logarithmic term,\n\ud835\udefd\ud835\udc3f \u221a \ud835\udc51\ud835\udc3f \u221a\ufe01 \ud835\udc3f log(1/\ud835\udefe) \u223c \ud835\udc51\ud835\udc3f \ud835\udc35 1/5 \ud835\udc3f \ud835\udc51\u22121/10 \ud835\udc3f1/5 = \ud835\udc519/10\ud835\udc351/5 \ud835\udc3f \ud835\udc3f4/5\n\ud835\udefe\ud835\udc37\ud835\udc3f/(1 \u2212 \ud835\udefe)3/2 \u223c \ud835\udc52\u2212 log\ud835\udc3f\ud835\udc3f( \ud835\udc511/5\ud835\udc3f2/5 \ud835\udc35\n2/5 \ud835\udc3f\n)3/2 = \ud835\udc513/10\ud835\udc35\u22123/5 \ud835\udc3f \ud835\udc3f3/5\n\u221a \ud835\udc51\n1\u2212\ud835\udefe \ud835\udc37\ud835\udc35\ud835\udc3f \u223c \ud835\udc51 1/2\ud835\udc35\ud835\udc3f ( \ud835\udc51\n1/5\ud835\udc3f2/5 \ud835\udc35 2/5 \ud835\udc3f )2 = \ud835\udc519/10\ud835\udc351/5 \ud835\udc3f \ud835\udc3f4/5.\nThus, with high probability, we have:\n\ud835\udc45\ud835\udc3f = O\ud835\udc3f\u2192\u221e (\ud835\udc519/10\ud835\udc351/5\ud835\udc3f \ud835\udc3f 4/5).\n\u25a1\nC IMPLEMENTATION DETAILS For the fair comparison, we set the embedding size candidates of the last three methods and our DESS as {2, 4, 8, 16, 64, 128}, which is also consistent with previous related researches [28, 29, 51]. All the methods share the embedding size adaptive neural network designed in 4.5 as the streaming recommendation model. We use the Adam optimizer with an initial learning rate as 0.001 and a regularization parameter as 0.001. The hidden layer size of the recommendation model is set to 512. The min-batch size is set as 500. The discount factor \ud835\udefe is set as 0.99. The subguassian constant \ud835\udf0e is set as 3.0. Without specifications, the hyper-parameters are set same as the original paper. We implement our algorithm with PyTorch and test it on the NVIDIA Titan-RTX GPU with 24 GB memory."
        }
    ],
    "title": "Dynamic Embedding Size Search with Minimum Regret for Streaming Recommender System",
    "year": 2023
}