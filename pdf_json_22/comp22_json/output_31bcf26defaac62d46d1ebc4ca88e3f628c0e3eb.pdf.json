{
    "abstractText": "In machine learning, training data often capture the behaviour of multiple subgroups of some underlying human population. This behaviour can often be modelled as observations of an unknown dynamical system with an unobserved state. When the training data for the subgroups are not controlled carefully, however, under-representation bias arises. To counter under-representation bias, we introduce two natural notions of fairness in timeseries forecasting problems: subgroup fairness and instantaneous fairness. These notion extend predictive parity to the learning of dynamical systems. We also show globally convergent methods for the fairness-constrained learning problems using hierarchies of convexifications of non-commutative polynomial optimisation problems. We also show that by exploiting sparsity in the convexifications, we can reduce the run time of our methods considerably. Our empirical results on a biased data set motivated by insurance applications and the well-known COMPAS data set demonstrate the efficacy of our methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Quan Zhou"
        },
        {
            "affiliations": [],
            "name": "Robert Shorten"
        }
    ],
    "id": "SP:975cd34d10776ddbf677cdfce6e646ba88417878",
    "references": [
        {
            "authors": [
                "\u00c5str\u00f6m",
                "K.-J",
                "B. Torsten"
            ],
            "title": "Numerical identification of linear dynamic systems from normal operating records",
            "venue": "IFAC Proceedings Volumes,",
            "year": 1965
        },
        {
            "authors": [
                "D.S. Abdou"
            ],
            "title": "Gender-based price discrimination: The cost of being a woman",
            "venue": "Proceedings of Business and Economic Studies, 2 (5).",
            "year": 2019
        },
        {
            "authors": [
                "S. Agarwal"
            ],
            "title": "Trade-offs between fairness and interpretability in machine learning",
            "venue": "IJCAI 2021 Workshop on AI for Social Good.",
            "year": 2021
        },
        {
            "authors": [
                "S. Aghaei",
                "M.J. Azizi",
                "P. Vayanos"
            ],
            "title": "Learning optimal and fair decision trees for non-discriminative decision-making",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "A. Amini",
                "A.P. Soleimany",
                "W. Schwarting",
                "S.N. Bhatia",
                "D. Rus"
            ],
            "title": "Uncovering and mitigating algorithmic bias through learned latent structure",
            "venue": "In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society,",
            "year": 2019
        },
        {
            "authors": [
                "O. Anava",
                "E. Hazan",
                "S. Mannor",
                "O. Shamir"
            ],
            "title": "Online learning for time series prediction",
            "venue": "In COLT 2013 - The 26th Annual Conference on Learning Theory, June 12-14,",
            "year": 2013
        },
        {
            "authors": [
                "R.B. Avery",
                "K.P. Brevoort",
                "G. Canner"
            ],
            "title": "Does credit scoring produce a disparate impact",
            "venue": "Real Estate Economics,",
            "year": 2012
        },
        {
            "authors": [
                "P. Awasthi",
                "C. Cortes",
                "Y. Mansour",
                "M. Mohri"
            ],
            "title": "Beyond individual and group fairness. CoRR, abs/2008.09490",
            "year": 2020
        },
        {
            "authors": [
                "S. Barocas",
                "M. Hardt",
                "A. Narayanan"
            ],
            "title": "Fairness and Machine Learning. fairmlbook.org, http://www.fairmlbook.org",
            "year": 2019
        },
        {
            "authors": [
                "C. Belitz",
                "L. Jiang",
                "N. Bosch"
            ],
            "title": "Automating procedurally fair feature selection in machine learning",
            "venue": "In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society,",
            "year": 2021
        },
        {
            "authors": [
                "P. Bertail",
                "S. Cl\u00e9men\u00e7on",
                "Y. Guyonvarch",
                "N. Noiry"
            ],
            "title": "Learning from biased data: A semi-parametric approach",
            "venue": "Proceedings of the 38th International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "A. Blum",
                "K. Stangl"
            ],
            "title": "Recovering from biased data: Can fairness constraints improve accuracy",
            "venue": "arXiv preprint arXiv:1912.01094,",
            "year": 2019
        },
        {
            "authors": [
                "S. Burgdorf",
                "I. Klep",
                "J. Povh"
            ],
            "title": "Optimization of polynomials in non-commuting",
            "year": 2016
        },
        {
            "authors": [
                "B.J. Calder",
                "E.C. Malthouse",
                "U. Schaedel"
            ],
            "title": "An experimental study of the relationship between online engagement and advertising effectiveness",
            "venue": "Journal of interactive marketing,",
            "year": 2009
        },
        {
            "authors": [
                "S. Caton",
                "S. Malisetty",
                "C. Haas"
            ],
            "title": "Impact of imputation strategies on fairness in machine learning",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2022
        },
        {
            "authors": [
                "M. Chakraborty",
                "E. Segal-Halevi",
                "W. Suksompong"
            ],
            "title": "Weighted fairness notions for indivisible items revisited",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "H. Chang",
                "R. Shokri"
            ],
            "title": "On the privacy risks of algorithmic fairness",
            "venue": "IEEE European Symposium on Security and Privacy (EuroS&P),",
            "year": 2021
        },
        {
            "authors": [
                "N.V. Chawla"
            ],
            "title": "C4.5 and imbalanced data sets: investigating the effect of sampling method, probabilistic estimate, and decision tree structure",
            "venue": "In Proceedings of the ICML,",
            "year": 2003
        },
        {
            "authors": [
                "N.V. Chawla",
                "K.W. Bowyer",
                "L.O. Hall",
                "W.P. Kegelmeyer"
            ],
            "title": "Smote: synthetic minority over-sampling technique",
            "venue": "Journal of artificial intelligence research,",
            "year": 2002
        },
        {
            "authors": [
                "N.V. Chawla",
                "D.A. Cieslak",
                "L.O. Hall",
                "A. Joshi"
            ],
            "title": "Automatically countering imbalance and its empirical relationship to cost",
            "venue": "Data Mining and Knowledge Discovery,",
            "year": 2008
        },
        {
            "authors": [
                "S. Chiappa"
            ],
            "title": "Path-specific counterfactual fairness",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33, pp. 7801\u20137808.",
            "year": 2019
        },
        {
            "authors": [
                "A. Chouldechova"
            ],
            "title": "Fair prediction with disparate impact: A study of bias in recidivism prediction instruments",
            "venue": "Big data, 5 (2), 153\u2013163.",
            "year": 2017
        },
        {
            "authors": [
                "A. Chouldechova",
                "A. Roth"
            ],
            "title": "A snapshot of the frontiers of fairness in machine learning",
            "venue": "Communications of the ACM,",
            "year": 2020
        },
        {
            "authors": [
                "D.A. Cieslak",
                "N.V. Chawla"
            ],
            "title": "Learning decision trees for unbalanced data",
            "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,",
            "year": 2008
        },
        {
            "authors": [
                "R. Cummings",
                "V. Gupta",
                "D. Kimpara",
                "J. Morgenstern"
            ],
            "title": "On the compatibility of privacy and fairness",
            "venue": "In Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization,",
            "year": 2019
        },
        {
            "authors": [
                "A. D\u2019Amour",
                "H. Srinivasan",
                "J. Atwood",
                "P. Baljekar",
                "D. Sculley",
                "Y. Halpern"
            ],
            "title": "Fairness is not static: deeper understanding of long term fairness via simulation studies",
            "venue": "In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency,",
            "year": 2020
        },
        {
            "authors": [
                "M.D. Delis",
                "P. Papadopoulos"
            ],
            "title": "Mortgage lending discrimination across the us: New methodology and new evidence",
            "venue": "Journal of Financial Services Research,",
            "year": 2019
        },
        {
            "authors": [
                "J. Dixmier"
            ],
            "title": "Les C*-alg\u00e8bres et leurs repr\u00e9sentations",
            "venue": "Gauthier-Villars, Paris, France. English translation: C*-algebras (North-Holland, 1982).",
            "year": 1969
        },
        {
            "authors": [
                "R. Dong",
                "E. Miehling",
                "C. Langbort"
            ],
            "title": "Protecting consumers against personalized pricing: A stopping time approach",
            "venue": "arXiv preprint arXiv:2002.05346,",
            "year": 2020
        },
        {
            "authors": [
                "J. Dressel",
                "H. Farid"
            ],
            "title": "The dangers of risk prediction in the criminal justice system",
            "year": 2021
        },
        {
            "authors": [
                "S. Dutta",
                "D. Wei",
                "H. Yueksel",
                "Chen",
                "P.-Y",
                "S. Liu",
                "K.R. Varshney"
            ],
            "title": "An information-theoretic perspective on the relationship between fairness and accuracy. ArXiv, abs/1910.07870",
            "year": 2019
        },
        {
            "authors": [
                "C. Dwork"
            ],
            "title": "Differential privacy",
            "venue": "Bugliesi, M., Preneel, B., Sassone, V., & Wegener, I. (Eds.), Automata, Languages and Programming, pp. 1\u201312, Berlin, Heidelberg. Springer Berlin Heidelberg.",
            "year": 2006
        },
        {
            "authors": [
                "C. Dwork",
                "M. Hardt",
                "T. Pitassi",
                "O. Reingold",
                "R. Zemel"
            ],
            "title": "Fairness through awareness",
            "venue": "In Proceedings of the 3rd innovations in theoretical computer science conference,",
            "year": 2012
        },
        {
            "authors": [
                "M.K.S. Faradonbeh",
                "A. Tewari",
                "G. Michailidis"
            ],
            "title": "Finite time identification in unstable linear systems",
            "year": 2018
        },
        {
            "authors": [
                "M. Feldman",
                "S.A. Friedler",
                "J. Moeller",
                "C. Scheidegger",
                "S. Venkatasubramanian"
            ],
            "title": "Certifying and removing disparate impact",
            "venue": "In Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining,",
            "year": 2015
        },
        {
            "authors": [
                "A. Fern\u00e1ndez",
                "S. Garcia",
                "F. Herrera",
                "N.V. Chawla"
            ],
            "title": "Smote for learning from imbalanced data: progress and challenges, marking the 15-year anniversary",
            "venue": "Journal of artificial intelligence research,",
            "year": 2018
        },
        {
            "authors": [
                "Fernando",
                "M.-P",
                "F. C\u00e8sar",
                "N. David",
                "Jos\u00e9",
                "H.-O"
            ],
            "title": "Missing the missing values: The ugly duckling of fairness in machine learning",
            "venue": "International Journal of Intelligent Systems,",
            "year": 2021
        },
        {
            "authors": [
                "X. Ferrer",
                "T. van Nuenen",
                "J.M. Such",
                "M. Cot\u00e9",
                "N. Criado"
            ],
            "title": "Bias and discrimination in ai: a cross-disciplinary perspective",
            "year": 2021
        },
        {
            "authors": [
                "J.R. Foulds",
                "R. Islam",
                "K.N. Keya",
                "S. Pan"
            ],
            "title": "An intersectional definition of fairness",
            "venue": "IEEE 36th International Conference on Data Engineering (ICDE),",
            "year": 2020
        },
        {
            "authors": [
                "P. Gajane",
                "M. Pechenizkiy"
            ],
            "title": "On formalizing fairness in prediction with machine learning",
            "venue": "Conference on Fairness, Accountability and Transparency, FAT 2018,",
            "year": 2018
        },
        {
            "authors": [
                "I. Gelfand",
                "M. Neumark"
            ],
            "title": "On the imbedding of normed rings into the ring of operators in Hilbert space",
            "venue": "Rec. Math. [Mat. Sbornik] N.S.,",
            "year": 1943
        },
        {
            "authors": [
                "N. Grgi\u0107-Hla\u010da",
                "M.B. Zafar",
                "K.P. Gummadi",
                "A. Weller"
            ],
            "title": "Beyond distributive fairness in algorithmic decision making: Feature selection for procedurally fair learning",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "M. Hardt",
                "E. Price",
                "N. Srebro"
            ],
            "title": "Equality of opportunity in supervised learning",
            "venue": "In Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "E. Hazan",
                "H. Lee",
                "K. Singh",
                "C. Zhang",
                "Y. Zhang"
            ],
            "title": "Spectral filtering for general linear dynamical systems",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2018
        },
        {
            "authors": [
                "E. Hazan",
                "K. Singh",
                "C. Zhang"
            ],
            "title": "Learning linear dynamical systems via spectral filtering",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "H. He",
                "Y. Ma"
            ],
            "title": "Imbalanced Learning: Foundations, Algorithms, and Applications",
            "year": 2013
        },
        {
            "authors": [
                "P. Hegarty"
            ],
            "title": "Inequality brokered",
            "venue": "Proceedings of the National Academy of Sciences, 116 (19), 9152\u20139154.",
            "year": 2019
        },
        {
            "authors": [
                "J.W. Helton"
            ],
            "title": "Positive\u201d noncommutative polynomials are sums of squares",
            "venue": "Annals of Mathematics, 156 (2), 675\u2013694.",
            "year": 2002
        },
        {
            "authors": [
                "D. Henrion",
                "Lasserre",
                "J.-B"
            ],
            "title": "Detecting global optimality and extracting solutions in gloptipoly",
            "venue": "In Positive polynomials in control,",
            "year": 2005
        },
        {
            "authors": [
                "S. Huang",
                "M. Salm"
            ],
            "title": "The effect of a ban on gender-based pricing on risk selection in the german health insurance market",
            "venue": "Health economics,",
            "year": 2020
        },
        {
            "authors": [
                "H. Jeong",
                "H. Wang",
                "F.P. Calmon"
            ],
            "title": "Fairness without imputation: A decision tree approach for fair prediction with missing values",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "C. Jung",
                "S. Kannan",
                "C. Lee",
                "M. Pai",
                "A. Roth",
                "R. Vohra"
            ],
            "title": "Fair prediction with endogenous behavior",
            "venue": "In Proceedings of the 21st ACM Conference on Economics and Computation, EC",
            "year": 2020
        },
        {
            "authors": [
                "F. Kamiran",
                "A. Karim",
                "X. Zhang"
            ],
            "title": "Decision theory for discrimination-aware classification",
            "venue": "In 2012 IEEE 12th International Conference on Data Mining,",
            "year": 2012
        },
        {
            "authors": [
                "T. Katayama"
            ],
            "title": "Subspace methods for system identification",
            "venue": "Springer Science & Business Media, London, UK.",
            "year": 2006
        },
        {
            "authors": [
                "N. Kilbertus",
                "M.R. Carulla",
                "G. Parascandolo",
                "M. Hardt",
                "D. Janzing",
                "B. Sch\u00f6lkopf"
            ],
            "title": "Avoiding discrimination through causal reasoning",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "J. Kleinberg",
                "J. Ludwig",
                "S. Mullainathan",
                "C.R. Sunstein"
            ],
            "title": "Discrimination in the age of algorithms",
            "venue": "Journal of Legal Analysis,",
            "year": 2018
        },
        {
            "authors": [
                "J. Kleinberg",
                "S. Mullainathan",
                "M. Raghavan"
            ],
            "title": "Inherent trade-offs in the fair determination of risk scores. In 8th Innovations in Theoretical Computer Science Conference (ITCS 2017)",
            "venue": "Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik",
            "year": 2017
        },
        {
            "authors": [
                "I. Klep",
                "V. Magron",
                "J. Povh"
            ],
            "title": "Sparse noncommutative polynomial optimization",
            "venue": "Mathematical Programming,",
            "year": 2022
        },
        {
            "authors": [
                "I. Klep",
                "J. Povh",
                "J. Volcic"
            ],
            "title": "Minimizer extraction in polynomial optimization is robust",
            "venue": "SIAM Journal on Optimization,",
            "year": 2018
        },
        {
            "authors": [
                "M. Kozdoba",
                "J. Marecek",
                "T. Tchrakian",
                "S. Mannor"
            ],
            "title": "On-line learning of linear dynamical systems: Exponential forgetting in kalman filters",
            "venue": "In The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19). arXiv preprint arXiv:1809.05870",
            "year": 2019
        },
        {
            "authors": [
                "C. Liu",
                "S.C. Hoi",
                "P. Zhao",
                "J. Sun"
            ],
            "title": "Online arima algorithms for time series prediction",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2016
        },
        {
            "authors": [
                "L. Ljung"
            ],
            "title": "System Identification: Theory for the User",
            "venue": "Pearson Education, New Jersey, USA.",
            "year": 1998
        },
        {
            "authors": [
                "F. Locatello",
                "G. Abbati",
                "T. Rainforth",
                "S. Bauer",
                "B. Sch\u00f6lkopf",
                "O. Bachem"
            ],
            "title": "On the fairness of disentangled representations",
            "venue": "In Advances in Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "L. Lu",
                "P. Jin",
                "G. Pang",
                "Z. Zhang",
                "G.E. Karniadakis"
            ],
            "title": "Learning nonlinear operators via deeponet based on the universal approximation theorem of operators",
            "venue": "Nature Machine Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "S. Maity",
                "D. Mukherjee",
                "M. Yurochkin",
                "Y. Sun"
            ],
            "title": "Does enforcing fairness mitigate biases caused by subpopulation shift",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "S. McCullough"
            ],
            "title": "Factorization of operator-valued polynomials in several noncommuting variables",
            "venue": "Linear Algebra and its Applications, 326 (1-3), 193\u2013203.",
            "year": 2001
        },
        {
            "authors": [
                "N. Moniz",
                "P. Branco",
                "L. Torgo"
            ],
            "title": "Resampling strategies for imbalanced time series forecasting",
            "venue": "International Journal of Data Science and Analytics,",
            "year": 2017
        },
        {
            "authors": [
                "H. Mouzannar",
                "M.I. Ohannessian",
                "N. Srebro"
            ],
            "title": "From fair decision making to social equality",
            "venue": "In Proceedings of the Conference on Fairness, Accountability, and Transparency,",
            "year": 2019
        },
        {
            "authors": [
                "R. Neil",
                "R.J. Sampson",
                "D.S. Nagin"
            ],
            "title": "Social change and cohort differences in group-based arrest trajectories over the last quarter-century",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2021
        },
        {
            "authors": [
                "D Nickerson"
            ],
            "title": "Asset price volatility, credit rationing and rational lending discrimination",
            "venue": "International Journal of Economics and Finance,",
            "year": 2016
        },
        {
            "authors": [
                "H. Nilforoshan",
                "J.D. Gaebler",
                "R. Shroff",
                "S. Goel"
            ],
            "title": "Causal conceptions of fairness and their consequences",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "E. Ntoutsi",
                "P. Fafalios",
                "U. Gadiraju",
                "V. Iosifidis",
                "W. Nejdl",
                "Vidal",
                "M.-E",
                "S. Ruggieri",
                "F. Turini",
                "S. Papadopoulos",
                "E Krasanakis"
            ],
            "title": "Bias in data-driven artificial intelligence systems\u2014an introductory survey",
            "venue": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery,",
            "year": 2020
        },
        {
            "authors": [
                "OECD"
            ],
            "title": "Personalised pricing in the digital era",
            "venue": "the joint meeting between the Competition Committee and the Committee on Consumer Policy.",
            "year": 2018
        },
        {
            "authors": [
                "B. Paa\u00dfen",
                "A. Bunge",
                "C. Hainke",
                "L. Sindelar",
                "M. Vogelsang"
            ],
            "title": "Dynamic fairnessbreaking vicious cycles in automatic decision making",
            "venue": "In Proceedings of the 27th European Symposium on Artificial Neural Networks",
            "year": 2019
        },
        {
            "authors": [
                "F. Petersen",
                "D. Mukherjee",
                "Y. Sun",
                "M. Yurochkin"
            ],
            "title": "Post-processing for individual fairness",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "C. Pinz\u00f3n",
                "C. Palamidessi",
                "P. Piantanida",
                "F. Valencia"
            ],
            "title": "On the impossibility of non-trivial accuracy under fairness constraints",
            "venue": "arXiv preprint arXiv:2107.06944,",
            "year": 2021
        },
        {
            "authors": [
                "S. Pironio",
                "M. Navascu\u00e9s",
                "A. Ac\u00edn"
            ],
            "title": "Convergent relaxations of polynomial optimization problems with noncommuting variables",
            "venue": "SIAM Journal on Optimization,",
            "year": 2010
        },
        {
            "authors": [
                "G. Pleiss",
                "M. Raghavan",
                "F. Wu",
                "J. Kleinberg",
                "K.Q. Weinberger"
            ],
            "title": "On fairness and calibration",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "K.T. Rodolfa",
                "H. Lamba",
                "R. Ghani"
            ],
            "title": "Empirical observation of negligible fairness\u2013 accuracy trade-offs in machine learning for public policy",
            "venue": "Nature Machine Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "E. Rolf",
                "T.T. Worledge",
                "B. Recht",
                "M. Jordan"
            ],
            "title": "Representation matters: Assessing the importance of subgroup allocations in training data",
            "venue": "Proceedings of the 38th International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "L. Salmela",
                "N. Tsipinakis",
                "A. Foi",
                "C. Billet",
                "J.M. Dudley",
                "G. Genty"
            ],
            "title": "Predicting ultrafast nonlinear dynamics in fibre optics with a recurrent neural network",
            "venue": "Nature Machine Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "T. Sarkar",
                "A. Rakhlin"
            ],
            "title": "Near optimal finite time identification of arbitrary linear dynamical systems",
            "venue": "Proceedings of the 36th International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "I.E. Segal"
            ],
            "title": "Irreducible representations of operator algebras",
            "venue": "Bulletin of the American Mathematical Society, 53 (2), 73\u201388.",
            "year": 1947
        },
        {
            "authors": [
                "S. Sharifi-Malvajerdi",
                "M. Kearns",
                "A. Roth"
            ],
            "title": "Average individual fairness: Algorithms, generalization and experiments",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "M. Simchowitz",
                "R. Boczar",
                "B. Recht"
            ],
            "title": "Learning linear dynamical systems with semi-parametric least squares",
            "venue": "Proceedings of the Thirty-Second Conference on Learning Theory, Vol. 99 of Proceedings of Machine Learning Research,",
            "year": 2019
        },
        {
            "authors": [
                "M. Simchowitz",
                "H. Mania",
                "S. Tu",
                "M.I. Jordan",
                "B. Recht"
            ],
            "title": "Learning without mixing: Towards a sharp analysis of linear system identification",
            "venue": "In Conference On Learning Theory,",
            "year": 2018
        },
        {
            "authors": [
                "A.K. Tangirala"
            ],
            "title": "Principles of system identification: theory and practice",
            "venue": "Crc Press, USA.",
            "year": 2014
        },
        {
            "authors": [
                "Y. Thiery",
                "C. Van Schoubroeck"
            ],
            "title": "Fairness and equality in insurance classification",
            "venue": "The Geneva Papers on Risk and Insurance-Issues and Practice,",
            "year": 2006
        },
        {
            "authors": [
                "L. Torgo",
                "B. Krawczyk",
                "P. Branco",
                "N. Moniz"
            ],
            "title": "Learning with imbalanced domains: Preface",
            "venue": "In First International Workshop on Learning with Imbalanced Domains: Theory and Applications,",
            "year": 2017
        },
        {
            "authors": [
                "C. Tran",
                "M. Dinh",
                "F. Fioretto"
            ],
            "title": "Differentially private empirical risk minimization under the fairness lens",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "A. Tsiamis",
                "N. Matni",
                "G. Pappas"
            ],
            "title": "Sample complexity of kalman filtering for unknown systems",
            "venue": "Proceedings of the 2nd Conference on Learning for Dynamics and Control,",
            "year": 2020
        },
        {
            "authors": [
                "A. Tsiamis",
                "G. Pappas"
            ],
            "title": "Online learning of the kalman filter with logarithmic regret",
            "venue": "arXiv preprint arXiv:2002.05141,",
            "year": 2020
        },
        {
            "authors": [
                "A. Tsiamis",
                "G.J. Pappas"
            ],
            "title": "Finite sample analysis of stochastic system identification",
            "venue": "IEEE 58th Conference on Decision and Control (CDC),",
            "year": 2019
        },
        {
            "authors": [
                "P. Van Overschee",
                "B. De Moor"
            ],
            "title": "Subspace identification for linear systems: Theory \u2014 Implementation \u2014 Applications",
            "year": 2012
        },
        {
            "authors": [
                "V.V. Vazirani"
            ],
            "title": "Approximation algorithms",
            "venue": "Springer Science & Business Media, Berlin-Heidelberg, DE.",
            "year": 2013
        },
        {
            "authors": [
                "R. Vogel",
                "A. Bellet",
                "S. Cl\u00e9mencon"
            ],
            "title": "Learning fair scoring functions: Bipartite ranking under roc-based fairness constraints",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "J. Wang",
                "V. Magron"
            ],
            "title": "Exploiting term sparsity in noncommutative polynomial optimization",
            "venue": "Computational Optimization and Applications,",
            "year": 2021
        },
        {
            "authors": [
                "J. Wang",
                "V. Magron",
                "Lasserre",
                "J.-B"
            ],
            "title": "Chordal-tssos: a moment-sos hierarchy that exploits term sparsity with chordal extension",
            "venue": "SIAM Journal on Optimization,",
            "year": 2021
        },
        {
            "authors": [
                "J. Wang",
                "V. Magron",
                "Lasserre",
                "J.-B"
            ],
            "title": "Tssos: A moment-sos hierarchy that exploits term sparsity",
            "venue": "SIAM Journal on Optimization,",
            "year": 2021
        },
        {
            "authors": [
                "S. Wang",
                "W. Guo",
                "H. Narasimhan",
                "A. Cotter",
                "M. Gupta",
                "M. Jordan"
            ],
            "title": "Robust optimization for fairness with noisy protected groups",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "M. Wen",
                "O. Bastani",
                "U. Topcu"
            ],
            "title": "Algorithms for fairness in sequential decision making",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "M. West",
                "J. Harrison"
            ],
            "title": "Bayesian Forecasting and Dynamic Models (2nd ed.)",
            "year": 1997
        },
        {
            "authors": [
                "P. Wittek"
            ],
            "title": "Algorithm 950: Ncpol2sdpa\u2014sparse semidefinite programming relaxations for polynomial optimization problems of noncommuting variables",
            "venue": "ACM Transactions on Mathematical Software (TOMS), 41 (3), 1\u201312.",
            "year": 2015
        },
        {
            "authors": [
                "F. Yang",
                "M. Cisse",
                "S. Koyejo"
            ],
            "title": "Fairness with overlapping groups; a probabilistic perspective",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Y. Zhang",
                "Q. Long"
            ],
            "title": "Assessing fairness in the presence of missing data",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Q. Zhou",
                "J. Mare\u010dek"
            ],
            "title": "Proper learning of linear dynamical systems as a noncommutative polynomial optimisation problem",
            "venue": "arXiv preprint arXiv:2002.01444,",
            "year": 2020
        },
        {
            "authors": [
                "Q. Zhou",
                "J. Mare\u010dek",
                "R.N. Shorten"
            ],
            "title": "Fairness in forecasting and learning linear dynamical systems",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "I. Zliobaite"
            ],
            "title": "On the relation between accuracy and fairness in binary classification",
            "venue": "The 2nd workshop on Fairness, Accountability, and Transparency in Machine Learning (FATML) at ICML\u201915.",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "some underlying human population. This behaviour can often be modelled as observations of an unknown dynamical system with an unobserved state. When the training data for the subgroups are not controlled carefully, however, under-representation bias arises. To counter under-representation bias, we introduce two natural notions of fairness in timeseries forecasting problems: subgroup fairness and instantaneous fairness. These notion extend predictive parity to the learning of dynamical systems. We also show globally convergent methods for the fairness-constrained learning problems using hierarchies of convexifications of non-commutative polynomial optimisation problems. We also show that by exploiting sparsity in the convexifications, we can reduce the run time of our methods considerably. Our empirical results on a biased data set motivated by insurance applications and the well-known COMPAS data set demonstrate the efficacy of our methods."
        },
        {
            "heading": "1. Introduction",
            "text": "Forecasts affect almost all aspects of our daily life, as a basis for access-control mechanisms. As the quality of the forecasts impacts our lives, for better or worse, it is becoming more and more apparent that many of the tools that produce the forecasts seem to be, or indeed are, unfair, in a sense we formalise below. If the tools used to produce the forecasts are unfair, society suffers.\n\u00a92023 AI Access Foundation. All rights reserved.\nOne such example of a forecasting tool that shapes the very pillars of our society is the FICO Score (Fair Isaac Corporation, 2021). FICO is a measure of an individual\u2019s creditworthiness (or conversely, credit-default risk), computed by the Fair Isaac Corporation. It has been suggested (Nickerson et al., 2016; Delis & Papadopoulos, 2019; Hegarty, 2019; Vogel, Bellet, & Cl\u00e9mencon, 2021) that the FICO Score may be unfair to certain minorities, although this has been disputed (Avery, Brevoort, & Canner, 2012).\nAs another example, consider college admissions, where results of standardised tests were often presented as forecasts of potential academic success. In the context of COVID-19, forecasting algorithms utilising previous grades and input from teachers replaced standardised tests in determining the satisfaction of college-admission requirements in many jurisdictions.\nOther forecasting tools are perhaps less well known, but perhaps even more alarming, as they have the potential to shape the very core of society. One striking example is Northpointe\u2019s Correctional Offender Management Profiling for Alternative Sanctions (COMPAS). COMPAS is a criminal-risk assessment tool that is widely used in pretrial, parole, and sentencing decisions at courts in New York, Wisconsin, California, and Florida. COMPAS forecasts the likelihood that an individual will re-offend within two years. It has been suggested (Angwin, Larson, Mattu, & Kirchner, 2016; Dressel & Farid, 2021) that COMPAS under-predicts recidivism for Caucasian defendants, and over-predicts recidivism for African-American defendants.1\nThe applications, where fairness seems most important, often capture the behaviour of multiple subgroups of some underlying human population in the training data. Let us consider a model, where there are a number of individuals within a population P. The population P is partitioned into subgroups indexed by S. For each subgroup s \u2208 S, there is a set I(s) of trajectories of observations available and each trajectory i \u2208 I(s) has observations for periods T (i,s), possibly of varying cardinality |T (i,s)|. Each subgroup s \u2208 S is associated with a model, L(s). For all i \u2208 I(s), s \u2208 S, the trajectory {Yt}(i,s), for t \u2208 T (i,s), is hence generated by precisely one model L(s). Throughout, the superscripts distinguish the trajectories and subgroups, while subscripts indicate the periods.\nIn this setting, under-representation bias (Blum & Stangl, 2019, cf. Section 2.2) arises, where the trajectories of observations from one (\u201cdisadvantaged\u201d) subgroup are under-represented in the training data. This is particularly important if the forecasting is constrained to be subgroup-blind, i.e., we wish to learn a single subgroup-blind model L. This is the case when the use of protected attributes distinguishing each subgroup can be regarded as discriminatory, such as in the case of gender and race (Gajane & Pechenizkiy, 2018; Kleinberg, Ludwig, Mullainathan, & Sunstein, 2018). Notice that such anti-discrimination measures are increasingly stipulated legally, e.g., within insurance pricing, where the sex of the applicant cannot be used, despite being known. More broadly, under-representation bias harms both the accuracy of the forecast and fairness in the sense of varying accuracy across the subgroups.\nTo address under-representation bias in the training of a forecasting model, it is natural to seek a notion of fairness that captures the overall behaviour across all subgroups, while taking into account the varying amounts of training data for the individual subgroups. To\n1. We note that this has been disputed (Kleinberg, Mullainathan, & Raghavan, 2017; Dressel & Farid, 2021), and that it has been suggested that such forecasts (Neil, Sampson, & Nagin, 2021) are difficult to make, in general, due to the cohort differences in group-based arrest trajectories.\nformalise this, suppose that we learn one model L from the multiple trajectories and define a loss function that measures the loss of accuracy for a certain observation Y (i,s)t when adopting the forecast ft for the overall population. For t \u2208 T (i,s), i \u2208 I(s), s \u2208 S, we have\n(i,s) loss(ft) := ||Y (i,s)t \u2212 ft||. (1)\nLet T + = \u222ai\u2208I(s),s\u2208ST (i,s). Following the definitions of T (i,s), there is not an observation for t /\u2208 T +, in which case, loss in Equation (1) does not exist. To evaluate the performance of the forecasts, we only consider ft made in periods t \u2208 T +. Note that, since each trajectory is of varying length, it is possible that for a certain triple (t, i, s), there is no observation Y\n(i,s) t .\nFollowing much recent work on fairness in classification, e.g., (Zliobaite, 2015; Hardt, Price, & Srebro, 2016; Kilbertus, Carulla, Parascandolo, Hardt, Janzing, & Sch\u00f6lkopf, 2017; Kusner, Loftus, Russell, & Silva, 2017; Chouldechova & Roth, 2020; Aghaei, Azizi, & Vayanos, 2019), we propose two objectives to address the under-representation bias, which extend group fairness (Feldman, Friedler, Moeller, Scheidegger, & Venkatasubramanian, 2015) to time series:\n1. Subgroup Fairness. The objective seeks to equalise, across all subgroups, the sum of losses for the subgroup. Considering the number of trajectories in each subgroup and the number of observations across the trajectories may differ, we include |I(s)|, |T (i,s)| as weights:\nmin ft,t\u2208T + max s\u2208S  1|I(s)| \u2211 i\u2208I(s)\n1 |T (i,s)| \u2211\nt\u2208T (i,s)\n(i,s) loss(ft)  (2) 2. Instantaneous Fairness. The objective seeks to equalise the instantaneous loss, by\nminimising the maximum of the losses across all subgroups and all times:\nmin ft,t\u2208T +\n{ max\nt\u2208T (i,s),i\u2208I(s),s\u2208S\n{ (i,s)\nloss(ft)\n}} (3)\nSpecific Contributions: This paper builds on our preliminary work that was presented in AAAI 2021 (Zhou, Mare\u010dek, & Shorten, 2021). The present manuscript extends this work by:\n\u2022 We have extended our fairness notions presented at (Zhou et al., 2021) to more generally applicable post-processing methods.\n\u2022 We have added a comparison of our fairness notions with all post-processing methods in the AI Fairness 360 library, which are based on previous fairness notions of \u201ccalibrated equalised odds\u201d, \u201cequalised odds\u201d and \u201cdemographic parity\u201d, respectively.\nWith respect to the state of the art, this paper defines two new notations of fairness. We then cast the learning of a linear dynamical system with such fairness considerations as a noncommutative polynomial optimisation problem (NCPOP), which can be solved efficiently using a globally-convergent hierarchy of semidefinite programming (SDP) relaxations, which can be of independent interest. A comprehensive comparison is given to illustrate the efficacy of our approach."
        },
        {
            "heading": "2. Definitions and Related Work",
            "text": "Recent years have seen an unprecedented explosion in attention of notions of fairness in the field of artificial intelligence and machine learning (Ntoutsi, Fafalios, Gadiraju, Iosifidis, Nejdl, Vidal, Ruggieri, Turini, Papadopoulos, Krasanakis, et al., 2020; Chouldechova & Roth, 2020). In a typical machine learning process, the training set usually contains individuals\u2019 protected attributes (e.g., race, gender), remaining attributes, and a target variable Y . Other than not using the protected attributes (\u201cfairness under unawareness\u201d), several candidate definitions of fairness have been proposed and we would start from statistical notions of fairness, which could be roughly categorised into three types (Barocas, Hardt, & Narayanan, 2019): (i) independence; (ii) separation; and (iii) sufficiency; a more fine-grained discussion of fairness is presented in the sequel. The independence notion typically asks the output to be independent of protected attributes. A simple example is the \u201cdemographic parity\u201d (Calder, Malthouse, & Schaedel, 2009), which requires each segment of a protected class (e.g., defined by gender) to receive the positive outcome at equal rates. The notion of separation, e.g., \u201cequal odds\u201d or \u201cequal opportunity\u201d in (Hardt et al., 2016), requires the predictor\u2019s output to be unrelated to protected attributes, but conditional on the target variables Y . Finally, the notion of sufficiency, derived from calibration, asked the target variables be independent from protected attributes conditional on the predictor output. For instance, we would expect the portion of defendants who were predicted to re-offend by the COMPAS system and actually re-offend to be equalised across subgroups. Calibration would require that for any given COMPAS score, the recidivism rates are similar.\nThe notions of independence, separation, and sufficiency are all related to subgroups of the population and provide an average guarantee for individuals in the protected group (Awasthi, Cortes, Mansour, & Mohri, 2020). In contrast, the notion of individual fairness asks for constraints that bind on specific pairs of individuals, rather than on a quantity that is averaged over groups (Chouldechova & Roth, 2020). In other words, it requires \u201csimilar individuals should be treated similarly\u201d (Petersen, Mukherjee, Sun, & Yurochkin, 2021; Dwork, Hardt, Pitassi, Reingold, & Zemel, 2012). However, this notion requires a similarity metric capturing the ground truth, which requires general and task-specific assumption on its definition (Sharifi-Malvajerdi, Kearns, & Roth, 2019). Apart from notions based on correlations of statistical measures and fairness, the notion of counterfactual fairness, pioneered by (Kusner et al., 2017), operates at the individual level such that causal methods are used to examine whether a decision is the same as in situations whether an individual\u2019s protected attributes are altered or not. Its generalised variant path-specific fairness in (Nilforoshan, Gaebler, Shroff, & Goel, 2022; Chiappa, 2019) specifies the effects of protected attributes along certain path in a causal directed acyclic graph. The notion of \u201cprocedural fairness\u201d, or in other words, the fairness of the decision-making process, especially in processes that resolve disputes and allocate resources, deeply rooted in legal science, has recently been tied to causal methods and fair feature selection in (Belitz, Jiang, & Bosch, 2021; Grgi\u0107-Hla\u010da, Zafar, Gummadi, & Weller, 2018). As the many notions of fairness arise, it is necessary to build up a comprehensive framework of multiple fairness criteria, especially when there is not a widely-recognised trivial fairness notion should be used (Awasthi et al., 2020) or when certain notions are incompatible with one another (Chakraborty, Segal-Halevi, & Suk-\nsompong, 2022). One could consider dynamically learning fair policies using feedback (Wen, Bastani, & Topcu, 2021; D\u2019Amour, Srinivasan, Atwood, Baljekar, Sculley, & Halpern, 2020).\nSomewhat removed from the mainstream literature, there are some excellent works in (Foulds, Islam, Keya, & Pan, 2020; Yang, Cisse, & Koyejo, 2020), who give the definition of independent subgroups, intersectional subgroups, and gerrymandering subgroups for the situations of overlapping subgroups. (Tran, Dinh, & Fioretto, 2021; Pinz\u00f3n, Palamidessi, Piantanida, & Valencia, 2021; Chang & Shokri, 2021; Cummings, Gupta, Kimpara, & Morgenstern, 2019) discuss the trade-off between differential privacy (Dwork, 2006) which is an important direction for further work. An empirical study of real-world problems in (Rodolfa, Lamba, & Ghani, 2021) challenged the existence or magnitude of the trade-off accuracy between fairness. While maintaining accuracy, there exist tension between fairness and interpretability (feature deduction) (Agarwal, 2021). For the cases of unknown or ambiguous protected attributes, (Amini, Soleimany, Schwarting, Bhatia, & Rus, 2019) introduce the latent variables which may over-represent some subgroups as the proxies of unknown protected attributes. (Wang, Guo, Narasimhan, Cotter, Gupta, & Jordan, 2020) use the technologies of distributional robust optimisation to minimise the worse-case expected loss of the predictor with an upper bound on the distance between the distribution of ambiguous and actual protected attributes. (Zhang & Long, 2021; Jeong, Wang, & Calmon, 2022) discuss the impact of missing data on fairness in uniformly sampled time series, which our model of non-uniformly sampled trajectories largely avoids. Some literature in (Caton, Malisetty, & Haas, 2022; Fernando, C\u00e8sar, David, & Jos\u00e9, 2021) also discusses imputation strategies for fairness with respect to missing data.\nOur approach to addressing the under-representation bias is rooted within the imbalancedlearning literature e.g., (He & Ma, 2013; Rolf, Worledge, Recht, & Jordan, 2021) and presents a step forward within the fairness in forecasting studied recently by (Gajane & Pechenizkiy, 2018; Chouldechova, 2017; Locatello, Abbati, Rainforth, Bauer, Sch\u00f6lkopf, & Bachem, 2019; Jeong et al., 2022), as outlined in the excellent survey of (Chouldechova & Roth, 2020; Barocas et al., 2019). On a more technical level, our work on fairness in learning linear dynamical systems is complemented by several recent studies involving dynamics and fairness (Mouzannar, Ohannessian, & Srebro, 2019; Paa\u00dfen, Bunge, Hainke, Sindelar, & Vogelsang, 2019; Jung, Kannan, Lee, Pai, Roth, & Vohra, 2020), and several even more recent studies on the learning of non-linear dynamics (Salmela, Tsipinakis, Foi, Billet, Dudley, & Genty, 2021; Lu, Jin, Pang, Zhang, & Karniadakis, 2021). We rely crucially on tools developed in non-commutative polynomial optimisation (Pironio, Navascu\u00e9s, & Ac\u00edn, 2010; Wang, Magron, & Lasserre, 2021b, 2021a) and non-commutative algebra (Gelfand & Neumark, 1943; Segal, 1947; McCullough, 2001; Helton, 2002), which have not seen much use in Statistics and Machine Learning, yet."
        },
        {
            "heading": "3. Our Models",
            "text": "As the simplest example of the use of subgroup fairness and instantaneous fairness, cf. Equations (2) and (3), consider their applications in linear regression. For simplicity, let us assume that the cardinality of each subgroup is the same and the lengths of all trajectories\nare equal. Then:\nmin z,A,ft,t\u2208T +\nz Subgroup Fairness in LR\ns.t. z \u2265 \u2211\ni\u2208I(s),t\u2208T + |Y (i,s)t \u2212 ft|, \u2200s \u2208 S\nft = AXt,\nmin z,A,ft,t\u2208T +\nz Instantaneous Fairness in LR\ns.t. z \u2265 |Y (i,s)t \u2212 ft|, \u2200i \u2208 I(s), s \u2208 S, t \u2208 T +\nft = AXt,\nwhere A concatenates the regression coefficients. Xt concatenates explanatory variables. ft is the dependent variable and Y (i,s)t is the actual observation in a compatible fashion. The auxiliary scalar variable z is used to reformulate \u201cmax\u201d in the objective in Equations (2) and (3).\nNext, let us consider more elaborate models, which assume that there exists a linear dynamical system (LDS) corresponding to each subgroup s \u2208 S. A discrete-time model of a linear dynamical system L = (G,F, V,W ) (West & Harrison, 1997) suggests that the random variable Yt \u2208 Rm capturing the observed component ( i.e., output, observations or measurements) evolves over time t \u2265 1 according to:\n\u03d5t = G\u03d5t\u22121 + wt, Yt = F \u2032\u03d5t + vt,\n(4)\nwhere \u03d5t \u2208 Rn is the hidden component (state) and G \u2208 Rn\u00d7n and F \u2208 Rn\u00d7m are compatible system matrices. Random variables wt, vt capture normally-distributed process noise and observation noise, with zero means and covariance matrices W \u2208 Rn\u00d7n and V \u2208 Rm\u00d7m, respectively.\nThe objectives in Equations (2) and (3), subject to the state-evolution and observation equations, in Equation (4), yield two operator-valued optimisation problems. Their inputs are Y (i,s)t , t \u2208 T (i,s), i \u2208 I(s), s \u2208 S, i.e., the observations of multiple trajectories and the multipliers \u03bb1, \u03bb2 > 0. The operator-valued decision variables O include operators F,G, vectors mt, \u03c9t, and scalars ft, \u03bdt, z. Notice that t ranges over t \u2208 T +, except for mt, where t \u2208 T + \u222a {0}. The auxiliary scalar variable z is used to reformulate \u201cmax\u201d in the objective in Equations (2) and (3). Since the process noise and observation noise are assumed to be samples of mean-zero normally-distributed random variables, we add the sum of squares of \u03c9t (resp. \u03bdt) to the objective with the positive multiplier \u03bb1 (resp. \u03bb2), seeking a solution with \u03c9t (resp. \u03bdt) close to zero. Overall, the subgroup-fair and instant-fair formulations\nread: min O z + \u03bb1 \u2211 t\u22651 \u03c92t + \u03bb2 \u2211 t\u22651 \u03bd2t Subgroup-Fair\ns.t. z \u2265 1 |I(s)| \u2211 i\u2208I(s)\n1 |T (i,s)| \u2211\nt\u2208T (i,s)\n(i,s) loss(ft), s \u2208 S,\nmt = Gmt\u22121 + \u03c9t , t \u2208 T +, ft = F \u2032mt + \u03bdt , t \u2208 T +.\n(5)\nmin O z + \u03bb1 \u2211 t\u22651 \u03c92t + \u03bb2 \u2211 t\u22651 \u03bd2t Instant-Fair\ns.t. z \u2265 (i,s)\nloss(ft) , t \u2208 T (i,s), i \u2208 I(s), s \u2208 S, mt = Gmt\u22121 + \u03c9t, t \u2208 T +, ft = F \u2032mt + \u03bdt , t \u2208 T +.\n(6)\nFor comparison, we use a traditional formulation that focuses on minimising the overall loss:\nmin O \u2211 s\u2208S \u2211 i\u2208I(s) \u2211 t\u2208T (i,s) (i,s) loss(ft) + \u03bb1 \u2211 t\u22651 \u03c92t + \u03bb2 \u2211 t\u22651 \u03bd2t Unfair s.t. mt = Gmt\u22121 + \u03c9t, t \u2208 T +, ft = F \u2032mt + \u03bdt , t \u2208 T +.\n(7)\nAs we explain in the Appendix, the operator-valued optimisation problems (i.e., \u201cUnfair\u201d, \u201cInstant-Fair\u201d, and \u201cSubgroup-Fair\u201d) can be convexified to any given accuracy, and thence solved efficiently, under a technical assumption related to the stability of the LDS, which entails that the estimates of states and observations remain bounded, and thus all operatorvalued decision variables remain bounded."
        },
        {
            "heading": "4. Numerical Illustrations",
            "text": "Under-representation bias considers the situation where some subgroups would be given unfair treatments, either due to the varying numbers or lengths of trajectories across subgroups. In response to under-representation bias, we have introduced two natural fairness notions for forecasting. We use a Linear Dynamic System to predict the next observation, as in Equation (4). Then, we have given two formulations associated with each notion. We tested our formulations on the famous Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) dataset. Our implementation is available on-line at https://github.com/Quan-Zhou/Fairness-in-Learning-of-LDS."
        },
        {
            "heading": "4.1 Generation of Biased Training Data",
            "text": "To illustrate the impact of our models on data with varying degrees of under-representation bias, we consider a method to generate data with a given degree of bias, which is based on (Blum & Stangl, 2019, cf. Section 2.2). Suppose that there is one advantaged subgroup (a) and one disadvantaged subgroup (d), i.e., S = {a, d}, with trajectories I(a) and I(d) in each subgroup. Under-representation bias can enter the training set in the following steps:\n1. Consider that the LDS for both subgroups L(s), s \u2208 S have the same system matrices:\nG(s) = [ 0.99 0 1.0 0.2 ] , F (s) = [ 1.1 0.8 ] ,\nwhile the covariance matrices V (s),W (s), s \u2208 S are sampled randomly from a uniform distribution over [0, 1) and [0, 0.1), respectively. The initial states m(s)0 of both subgroups are 5 and 7.\n2. Observations Y (i,s)t are sampled from corresponding LDS L(s). Thus each Y (i,s) t \u223c L(s).\n3. Let \u03b2(d) denote the probability that an observation from subgroup d stays in the training data, and 0 \u2264 \u03b2(d) \u2264 1. It can be seen as the ratio of the number of observations in disadvantaged subgroup to that of advantaged subgroup. The degree of underrepresentation bias can be controlled by simply adjusting \u03b2(d). Smaller values of \u03b2(d)\ncorrespond to higher level of bias in the training set.\nThe last step makes the number of observations of the disadvantaged subgroup less than that of the advantaged subgroup when 0 \u2264 \u03b2(d) < 1. Hence, the advantaged subgroup becomes over-represented. Note that for a small sample size, it is necessary to make sure that there is at least one observation in each subgroup at each period."
        },
        {
            "heading": "4.2 Effects of Under-Representation Bias on Forecast",
            "text": "To illustrate the impact of our models on data with varying degrees of under-representation bias, suppose there is an advantaged subgroup (a) and a disadvantaged subgroup (d), i.e., S = {a, d}. Figure 1 illustrates 10 experiments with general forecasting procedures. For each experiment, the same set of observations Y (i,s)t , t \u2208 T (i,s), i \u2208 I(s), s \u2208 S is reused, and the trajectories of advantaged and disadvantaged subgroups are denoted by dotted curves and dashed curves, respectively. However, in each experiment, a subset of observations with the same cardinality is randomly selected and discarded and thus a new biased training set is generated, albeit based on the same \u201cground set\u201d of observations. The three models in Equations (5)-(7) are applied in each experiment with \u03bb1 of 1, 3, and 5, respectively, as chosen by iterating over integers 1 to 10, while \u03bb2 remains 0.01, The mean of forecast ft across 10 experiments and its standard deviation are shown as solid curves with error bands. The red curve gives an overview of how a prediction without considering fairness would cause an unevenly distributed prediction loss for each subgroup. This is simply because the advantaged subgroup is of larger cardinality, and the overall loss would decrease more steeply if the predicted trajectory gets closer to the advantaged subgroup."
        },
        {
            "heading": "4.3 Fairness as a Function of Bias",
            "text": "Figure 2 suggests how the degree of bias affects accuracy in each subgroup with and without considering fairness. With the number of trajectories in both subgroups set to two, i.e., |Ia| = |Id| = 2, we vary the degree of bias by adjusting \u03b2(d) within the range of [0.5, 0.9]. To measure the effect of the degree on accuracy, we introduce the normalised root mean square\nerror (nrmse) fitness value for each subgroup s \u2208 S:\n(s) nrmse := \u221a\u221a\u221a\u221a\u221a\u221a \u2211 i\u2208I(s) \u2211 t\u2208T (i,s) ( Y (i,s) t \u2212 ft )2 \u2211\ni\u2208I(s) \u2211 t\u2208T (i,s) ( Y (i,s) t \u2212mean(s) )2 , where mean(s) := 1|I(s)| \u2211 i\u2208I(s) 1 |T (i,s)| \u2211 t\u2208T (i,s) Y (i,s) t . Higher nrmse(s) indicates lower accuracy for subgroup s, i.e., the predicted trajectory of subgroup-blind L is further away from this subgroup.\nThe training data are generated in the same way as the set of observations used in Figure 1, but with two trajectories in each subgroup (|Ia| = |Id| = 2). Then, the biased training data generalisation process (described in Section 4.1) is applied in each experiment with the value of \u03b2(d) selecting from 0.5 to 0.9 at the step of 0.1. For each value of \u03b2(d), three models in Equations (5)-(7) are conducted for 10 experiments with a new biased training set in each experiment. Therefore, the quartiles of nrmse(s) across 10 experiments for each subgroup are shown as boxes in Figure 2.\nOne could expect that nrmse fitness values of the advantaged subgroup in Figure 2 to be generally lower than those of the disadvantaged subgroup (nrmse(d) \u2265 nrmse(a)), leaving a gap. Those gaps narrow down as \u03b2(d) increases, simply because more observations of disadvantaged subgroup remain in the training data. Compared the to \u201cUnfair\u201d, models with fairness constraints, i.e., \u201cSubgroup-Fair\u201d and \u201cInstant-Fair\u201d, show narrower gaps and\nhigher fairness between two subgroups. More surprisingly, when nrmse(a) decreases as \u03b2(d) gets close to 0.5, \u201cSubgroup-Fair\u201d model still can keep nrmse(d) at almost the same level, indicating a rise in overall accuracy. This is in contrast to the results of (Zliobaite, 2015; Dutta, Wei, Yueksel, Chen, Liu, & Varshney, 2019) in classification, but in line with recent work (Maity, Mukherjee, Yurochkin, & Sun, 2021)."
        },
        {
            "heading": "4.4 Evaluation of Run Time of the Method",
            "text": "Minimising multivariate operator-valued polynomial optimisation problems (5-7) is a known non-trivial problem. We exploit sparsity-exploiting variants (TSSOS) of the globally convergent Navascu\u00e9s-Pironio-Ac\u00edn (NPA) hierarchy used in the proof of Theorem 2, to develop fast computational methods. See (Klep, Magron, & Povh, 2022; Wang et al., 2021b, 2021a; Wang & Magron, 2021). The SDP of a given order in the respective hierarchy can be constructed using ncpol2sdpa 1.12.22 of (Wittek, 2015) or the tools of (Wang & Magron, 2021) 3 and then solved by mosek 9.2 of (MOSEK, ApS, 2020).\nIn Figure 3, we illustrate the run-time and size of the relaxations as a function of the length of the time window. Models \u201cSubgroup-Fair\u201d in Equation (5) and \u201cInstant-Fair\u201d in Equation (6) are implemented three times for each length of the time window, with the same data set used in Figure 2. The type of models, i.e., \u201cSubgroup-Fair\u201d (solid curves) and \u201cInstant-Fair\u201d (dashed curves), is distinguished by line styles. The deep-pink and cornflower-\n2. https://github.com/peterwittek/ncpol2sdpa 3. https://github.com/wangjie212/TSSOS\nblue curves show the run-time of the first-order SDP relaxation of NPA and the second-order SDP relaxation of TSSOS hierarchy, respectively, implemented with five CPUs and 64GB of memory per CPU. The mean and mean \u00b1 1 standard deviation of run-time across 3 experimental runs are presented by curves with shaded error bands. The grey curve displays the number of variables in the first-order SDP relaxation of our models in Equations (5) against the length of time window. Further, models \u201cSubgroup-Fair\u201d in Equation (5) and \u201cInstant-Fair\u201d in Equation (6) are implemented once via TSSOS for each length of the time window, using COMPAS dataset, as the experiment in Figure 4, with the run-time displayed by a coral solid curve and a coral dashed curve, respectively. It is clear that the run-time of TSSOS exhibits a modest growth with the length of time window, while that of the plain-vanilla NPA hierarchy grows much faster."
        },
        {
            "heading": "5. Numerical Results of COMPAS Dataset",
            "text": "Finally, we wish to suggest the broader applicability of the two notions of subgroup fairness and instantaneous fairness. We use the well-known dataset (Angwin et al., 2016) of estimates of the likelihood of recidivism made by the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), as used by courts in the United States, cf. Appendix C. The COMPAS dataset, analysed by ProPublica, comprises of defendants\u2019 gender, race, age, charge degree, COMPAS recidivism scores, two-year recidivism label, as well as information on prior incidents. The COMPAS recidivism scores, ranging from 1 to 10, are positively\nrelated to the estimated likelihood of recidivism, given by the COMPAS system. The twoyear recidivism label denotes whether a person actually got rearrested within two years (label 1) or not (label 0). If the two-year recidivism label is 1, there is also information concerning the recharge degree and the number of days until the person gets rearrested. The dataset also consists of information on \u201cDays before Re-offending\u201d, which is the date difference between the defendant\u2019s crime offend date and recharge offend date. It could be negatively correlated to the defendant\u2019s actual risk level while the COMPAS recidivism scores would be the estimated risk level."
        },
        {
            "heading": "5.1 An Alternative Approach to COMPAS Dataset",
            "text": "From the COMPAS dataset cf. Appendix C, we choose 119 defendants with recidivism label being 1, who are either African-American or Caucasian, male, within the age range of 25-45, and with prior crime counts less than two, with charge degree M and recharge degree M1 or M2. The defendants are partitioned into two subgroups by their ethnicity and then partitioned by the type of their recharge degree (M1 or M2). Hence, we obtain the 4 sub-samples.\nIn the days-to-reoffend-vs-score plot, such as Figure 4, dots suggest COMPAS recidivism scores of the four sub-samples against the days before rearrest. Each curve represents one model, either subgroup-dependent (plotted thin) or Subgroup-Fair (plotted thick). The thick cyan curve is the race-blind prediction from our Subgroup-Fair method, which equalises scores across the two subgroups. Ideally, one should like to see smooth, monotonically decreasing curves, overlapping across all subgroup-dependent models. For each sub-sample, the aggregate deviation from the Subgroup-Fair curve would be similar to the aggregate deviations of other sub-samples.\nIn Figure 4, the dots are far from the ideal monotonically decreasing curve. Furthermore, the subgroup-specific curves (plotted thin) are very different from each other (\u201csubgroupspecific models are unfair\u201d). Specifically, the red and yellow curves are above the sky blue and cornflower blue curves (\u201cat the same risk level, Caucasian defendants get lower COMPAS scores\u201d). Notice that the subgroup-dependent models are obtained as follows: we discretise time to 20-day periods. For each subgroup, we check if anyone re-offends within 20 days (the first period). If so, the (average) COMPAS score (for all cases within the 20 days) is recorded as the observation of the first period of the trajectory of the sub-sample. If not, there is no observation of this period. We repeat this for the subsequent periods and for the three other sub-samples."
        },
        {
            "heading": "5.2 A Comparison Against the State of the Art on COMPAS Dataset",
            "text": "Generally speaking, fairness objectives or constraints might not be easily applied to models that are already in use in applications. For such systems, revision of the model output with some post-processing tools would be a widely applicable and practical solution. Since we have shown the existence of unfairness in COMPAS recidivism scores, we now illustrate this approach to improve upon the COMPAS scores by using post-processing methods that embed our fairness notions. We then compare our methods using the AI Fairness 360 toolkit\nAIF3604 of (Bellamy, Dey, Hind, Hoffman, Houde, Kannan, Lohia, Martino, Mehta, Mojsilovic, Nagar, Ramamurthy, Richards, Saha, Sattigeri, Singh, Varshney, & Zhang, 2018).\nThe training set and test sets: The sample set contains 1005 defendants, whose race is either African-American or Caucasian, selected from the first 1200 rows of the COMPAS dataset cf. Appendix C. For a single trial, we randomly pick 80% of samples as the training set then test the output on the rest 20% of the samples. Each trial uses a new batch of the training set and the test set generated from the same sample set of 1005 defendants.\nNotice that the sample set is biased as there are only 403 Caucasian defendants. Since existing data may generally contain biases, stemming for example from poor information acquisition process (Bertail, Cl\u00e9men\u00e7on, Guyonvarch, & Noiry, 2021), due to historical and social injustices (Ferrer, van Nuenen, Such, Cot\u00e9, & Criado, 2021), we seek other methods to validate our approaches. To this end we randomly remove some observations of AfricanAmerican defendants from the original test set, such that the number of defendants in both subgroups are the same. The resulted subset is called the re-weighted test set.\nPerformance indices: We use three baseline fairness metrics (i.e., independence, separation, and sufficiency), as well as prediction inaccuracy, to measure the performance of postprocessing models. Essentially, the sample set includes two race subgroups S = {AfricanAmerican defendants (AA), Caucasian defendants (C)}. The recidivism label and the prediction of the recidivism label outputted from a model, are denoted by binary variables Y and f respectively. Let P (f = f |Y = Y, s = s) be the probability of a defendant from subgroup s with recidivism label Y being predicted to recidivism label f . We set Y = 1 and f = 1 to be a defendant re-offending and being predicted to re-offend, thus they are negative events. Further, we define the indices of three baseline fairness metrics (IND, SP, SF), inaccuracy (INA) and their re-weighted versions (i.e., INDrw, SPrw, SFrw, INArw) in Equation (8):\nIND(rw) := |P (f = 1 | s = AA)\u2212 P (f = 1 | s = C)|, SP(rw) := |P (f = 0 | Y = 1, s = AA)\u2212 P (f = 0 | Y = 1, s = C)|\n+ |P (f = 1 | Y = 0, s = AA)\u2212 P (f = 1 | Y = 0, s = C)|, SF(rw) := |P (Y = 1 | f = 1, s = AA)\u2212 P (Y = 1 | f = 1, s = C)|\n+ |P (f = 0 | Y = 0, s = AA)\u2212 P (f = 0 | Y = 0, s = C)|, INA(rw) := P (Y \u0338= f | s = AA) + P (Y \u0338= f | s = C),\n(8)\nwhere, for example, IND(rw) implies both indices IND and INDrw. The difference between IND and INDrw is that IND measures the performance of a model on the original test set while INDrw on the re-weighted test set. The same applies for SP(rw), SF(rw), INA(rw). To interpret the definitions in Equation (8): IND(rw) are race-wise absolute difference of negative rate; SP(rw) combine race-wise absolute difference of false false positive and false negative rates; SF(rw) captures the race-wise absolute difference of positive predictive value and negative predictive value; INA(rw) measure inaccuracy of test set. In our setting, smaller values of IND(rw), SP(rw), SF(rw), INA(rw) indicate better performance in terms of independence, separation, sufficiency and accuracy, respectively.\n4. https://github.com/Trusted-AI/AIF360\nClassification thresholds: Since the outputs of all post-processing tools implemented in this paper and COMPAS system are scores from varying intervals and, to transfer the scores to binary labels, we would need a threshold such that f = 1 when the score, denoted by g is higher than this threshold, and f = 0 otherwise. For ease of comparison, we define uni-race thresholds which differ across different models but all of them are defined as the xth percentile of all scores outputted by the corresponding model, where x \u2208 [0, 100] is fixed. Notice that there is a gap between the percentage of recidivism in African-American defendants (46%) and Caucasian defendants (59%) in terms of the sample set, and we call those percentages base rates, as in (Pleiss, Raghavan, Wu, Kleinberg, & Weinberger, 2017). In fairness to African-American defendants, we introduce race-wise thresholds using base rates: for each model, the percentage of defendants in a subgroup whose scores are higher than the subgroup\u2019s threshold needs to be the same as the subgroup\u2019s base rate.\nPost-processing methods: Associated with our fairness notions, we propose two postprocessing methods. Both methods use simple race-wise linear regression models\ng(i,s) = A(s)X(i,s) + e(s), i \u2208 I(s), s \u2208 S, (9)\nwhere the subscript t is removed such that we only consider prediction in one period. In other words, we cast the problem of prediction into classification. A(s) concatenates the regression coefficients. X(i,s) concatenates explanatory variables, including COMPAS recidivism score, prior incidents (i.e., the sum of \u201cprior counts\u201d, \u201cjuv_ fel_ count\u201d and \u201cjuv_ misd_ count\u201d), age category (i.e., 1 if age is less than 25 and 0 otherwise), and recidivism label. e(s) corresponds to a noise to the linear relationship. g(i,s) is the post-processed recidivism score of the defendant i in subgroup s, and Y (i,s) is the actual recidivism label (i.e., the ground truth). Let loss(i,s)(g) := \u2225Y (i,s) \u2212 g(i,s)\u2225, our post-processing methods are Equation (10) subject to Equation (9), with \u03bb3 = 0.05. Further, the score g(i,s) would be mapped to the binary prediction of recidivism label f (i,s) using a threshold.\nSubgroup-Fair ming,A,e { maxs\u2208S { 1 |I(s)| \u2211 i\u2208I(s) loss (i,s)(g) } + \u03bb3 \u2211 s\u2208S ( e(s) )2} Instant-Fair ming,A,e { maxi\u2208I(s),s\u2208S { loss(i,s)(g) } + \u03bb3 \u2211 s\u2208S ( e(s)\n)2} (10) In Figure 5, we test the performance of all post-processing methods implemented in AI\nFairness 360 toolkit:\n\u2022 \u201cAIF360\u201d: calibrated equalised odds post-processing with cost constraint being a combination of both false negative rate and false positive rate, as suggested by the authors of the AI Fairness 360 toolkit (Bellamy et al., 2018),\n\u2022 \u201cCaliEqOdds(fnr)\u201d: calibrated equalised odds post-processing with cost constraint being the false negative rate,\n\u2022 \u201cCaliEqOdds(fpr)\u201d: calibrated equalised odds post-processing with cost constraint being the false positive rate,\n\u2022 \u201cEqOdds\u201d: equalised odds post-processing,\n\u2022 \u201cRejectOption\u201d: reject option classification.\nNote that \u201cAIF360\u201d, \u201cCaliEqOdds(fnr)\u201d, \u201cCaliEqOdds(fpr)\u201d are based on the fairness notion of \u201ccalibrated equalised odds\u201d in (Pleiss et al., 2017). \u201cEqOdds\u201d is derived from the fairness notion of \u201cequalised odds\u201d in (Hardt et al., 2016). \u201cRejectOption\u201d comes from (Kamiran, Karim, & Zhang, 2012), which is rooted in the fairness notion of \u201cdemographic parity\u201d (Calder et al., 2009). Those five methods are implemented in five trials for each of three unirace thresholds x = [47, 53, 60] (5\u00d75\u00d73 runs). The left subplot displays mean values of eight indices across all five trials and three thresholds, with each angular axis representing one index, and each colour denoting one post-processing method. The right subplot represents the values of all experimental runs as dots in a circular sector, with each sector representing one index. Each sector is labelled with the index immediately counter-clockwise to it. For instance, the sector between the labels \u201cIND\u201d and \u201cINDrw\u201d displays the \u201cIND\u201d values of all experimental runs. In both subplots, the value represented by a dot is displayed by its distance from the original point, with shorter distances indicating better performance.\nFigure 5 depicts a summary of the state of the art on COMPAS dataset, and how we select the appropriate method to benchmark our own algorithms. Referring to this figure, since in both subplots, most of yellow (\u201cAIF360\u201d) dots are relatively closer to the origin than other dots, it seems fair to consider \u201cAIF360\u201d as the state of the art post-processing method, at least within those implemented in AI Fairness 360 toolkit, and to compare our methods against it in the following.\nIn Figure 6, COMPAS scores (\u201cCOMPAS\u201d red), the state of the art (\u201cAIF360\u201d, yellow), and the outputs of our methods \u201cSubgroup-Fair\u201d (blue) and \u201cInstant-Fair\u201d (green) are evaluated across 50 trials using base rates as race-wise thresholds (50\u00d74 runs). The left subplot illustrates the average performance of four methods, where dots represent the mean values of original indices, and bars are those of re-weighted indices. The right subplot displays fairness performance of all experimental runs in a triangular area. For a single run, the original fairness metrics (i.e., IND, SP, SF) are denoted by one dot and re-weighted ones (i.e., INDrw, SPrw, SFrw) are shown as one square. A marker, that is, a dot or a square, represents the value of IND(rw), SP(rw), SF(rw), by its positions along the left, right, and bottom axes in ternary coordinates. The colour of this marker denotes the method used in this run.\nFigure 6 illustrates the performance of our methods compared with the state of the art and COMPAS scores when using base rates as race-wise thresholds. As we can see on the left, there is not much difference between the values of original indices and their re-weighted versions, except that \u201cInstant-Fair\u201d generally performs worse in re-weighted version than in original version. It implies that \u201cInstant-Fair\u201d might not be appropriate to use in this case because its performance varies with the test set being re-weighted or not. The performance of \u201cSubgroup Fair\u201d is similar to that of \u201cCOMPAS\u201d, but with a slight improvement in IND(rw) and SP(rw). \u201cAIF360\u201d seems to sacrifice a lot of accuracy for lower average fairness indices, while its fairness performance shows a lot of variability, as shown in the right subplot. On the contrary, the concentration of blue and green markers (i.e., dots and squares) indicates less variability of our methods.\nIn Figure 7, COMPAS scores (\u201cCOMPAS\u201d red), the state of the art (\u201cAIF360\u201d, yellow), and the outputs of our methods \u201cSubgroup-Fair\u201d (blue) and \u201cInstant-Fair\u201d (green) are evaluated across 50 trials, with 10 different uni-race thresholds x = [20, 27, . . . , 80] (50\u00d7 10\u00d7 4 runs). Each subplot represents the mean (curves) and mean \u00b1 one standard deviations\n(shaded error bands) of the corresponding index across 50 trials, against 10 different unirace thresholds x = [20, 27, . . . , 80] with four methods distinguished by the same palette as in Figure 6.\nFigure 7 depicts an investigation of the performance of \u201cSubgroup-Fair\u201d, \u201cInstant-Fair\u201d, \u201cAIF360\u201d and \u201cCOMPAS\u201d for different uni-race thresholds. Notice that the error bands generally overlap each other in subplots of the first and third rows (which represent the indices IND(rw) and SF(rw)). One potential implication of this work is that there might not be significant differences amongst the four methods, in terms of IND(rw) and SF(rw), when using uni-race thresholds. If we look at the remaining indices, \u201cSubgroup-Fair\u201d (blue) surpasses \u201cCOMPAS\u201d (red) in terms of the performance indexes SP(rw), and both achieve the best in INA(rw). Furthermore, \u201cAIF360\u201d has relatively low values of SP(rw), but at a large expense of INA(rw)."
        },
        {
            "heading": "6. Conclusions",
            "text": "We have introduced the two natural notions of fairness in forecasting. When the corresponding optimisation problems are solved to global optimality, the solutions outperform the COMPAS system in terms of independence and separation indices IND(rw) and SP(rw), cf. Equation (8).\nAs a further technical contribution, we have presented globally convergent methods for solving the optimisation problems arising from the two notions of fairness using hierarchies of convexifications of non-commutative polynomial optimisation problems. Also, we have shown that the run-time of standard solvers for the convexifications is independent of the dimension of the hidden state. This provides a technical tool in machine learning and statistics that is of independent interest, and that can also be applied in other settings."
        },
        {
            "heading": "Acknowledgments",
            "text": "Quan Zhou\u2019s and Robert Shorten\u2019s work has been supported by the Science Foundation Ireland under Grant 16/IA/4610. Jakub Mare\u010dek acknowledges support of the OP RDE funded project CZ.02.1.01/0.0/0.0/16_019/0000765 \u201cResearch Center for Informatics\u201d. This work has received funding from the European Union\u2019s Horizon Europe research and innovation programme under grant agreement No. 101070568. This work was also supported by Innovate UK under the Horizon Europe Guarantee; UKRI Reference Number: 10040569 (Human-Compatible Artificial Intelligence with Guarantees (AutoFair))."
        },
        {
            "heading": "Appendix A. Motivation",
            "text": "A.1 Insurance Pricing\nLet us consider two motivating examples. One important application arises in Actuarial Science. In the European Union, a directive (implementing the principle of equal treatment between men and women in the access to and supply of goods and services), bars insurers from using gender as a factor in justifying differences in individuals\u2019 premiums. In contrast, insurers in many other territories classify insureds by gender, because females and males have different behaviour patterns, which affects insurance payments. Take the annuity-benefit scheme for example. It is a well-known fact that females have a longer life expectancy than males (Huang & Salm, 2020). The insurer will hence pay more to a female insured during her lifetime, compared to a male insured, on average (Thiery & Van Schoubroeck, 2006). Because of the directive, a unisex mortality table needs to be used. As a result, male insureds receive less benefits, while paying the same premium in total as the female subgroup (Thiery & Van Schoubroeck, 2006). Consequently, male insureds might leave the annuity-benefit scheme (known as adverse selection), which makes the unisex mortality table more challenging to use in the estimation of the life expectancy of the \u201cunisex\u201d population, where female insureds become the advantaged subgroup.\nConsider a simple actuarial pricing model of annuity insurance. Insureds enter an annuity-benefit scheme at time 0 and each insured can receive 1 euro at the end of each year for at most 10 years on the condition that it is still alive. Let pt denotes how many\ninsureds left in the scheme in the end of the tth year. Suppose there are p0 insureds in the beginning and the pricing interest rate is i (i \u2264 1). The formula of calculating the pure premium is in Equation (A.1), thus summing up the present values of payment in each year and then divided by the number of insureds in the beginning.\npremium :=\n\u221110 t=1 pt \u00d7 (1 + i)\u2212t\np0\nThe most important quality pt is derived from estimating insureds\u2019 life expectancy. Suppose the insureds can be divided into female and male subgroups. Each subgroup has one trajectory: {Yt}( \u00b7 ,f) for female subgroup, {Yt}( \u00b7 ,m) for male subgroup for 1 \u2264 t \u2264 10, where the superscript i is dropped. The two trajectories indicate how many female and male insureds are alive at the end of the tth year, respectively. Both trajectories can be regarded as linear dynamic systems. We have\nY ( \u00b7 ,f) t = G (f)Y ( \u00b7 ,f) t\u22121 + \u03c9 (f) t , 2 \u2264 t \u2264 10,\nY ( \u00b7 ,m) t = G (m)Y ( \u00b7 ,m) t\u22121 + \u03c9 (m) t , 2 \u2264 t \u2264 10,\npt = Y ( \u00b7 ,f) t + Y ( \u00b7 ,m) t , 1 \u2264 t \u2264 10,\nwhere \u03c9(f)t and \u03c9 (m) t are measurement noises while G(f) and G(m) are system matrices for female LDS L(f) and male LDS L(m) respectively. Note that these are state processes, without any observation process: the number of survivals can be precisely observed. To satisfy the directive, one needs to consider a unisex model:\nft = Gft\u22121 + \u03c9t, 2 \u2264 t \u2264 10,\nwhere 2 \u2264 t \u2264 10 and \u03c9t and G pertain to the unisex insureds LDS L. Subsequently, the loss functions for female (f) and male (m) subgroups are:\n( \u00b7 ,f) loss (ft) := ||Y ( \u00b7 ,f)t \u2212 ft|| , 1 \u2264 t \u2264 10,\n( \u00b7 ,m) loss (ft) := ||Y ( \u00b7 ,m)t \u2212 ft|| , 1 \u2264 t \u2264 10,\nSince the trajectories {Yt}( \u00b7 ,f) and {Yt}( \u00b7 ,m) have the same length and there is only one trajectory in each subgroup, the two objective Eq.(2)-Eq.(3)has the form:\nmin ft,1\u2264t\u226410 max { 10\u2211 t=1 ( \u00b7 ,f) loss (ft), 10\u2211 t=1 ( \u00b7 ,m) loss (ft) }\nmin ft,1\u2264t\u226410\n{ max\n1\u2264t\u226410,s\u2208{f,m}\n{ ( \u00b7 ,s) loss (ft) }}\nA.2 Personalised Pricing\nAnother application arises in personalised pricing (PP). For example, Amazon has been found (OECD, 2018) to sell certain products to regular consumers at higher prices. This is legal, albeit questionable. In contrast, gender-based price discrimination (Abdou, 2019) violates (OECD, 2018) anti-discrimination laws in many jurisdictions.\nLet us consider an idealised example of PP: Consider a soap retailer, whose customers contain female and male subgroups. Each gender has a specific dynamic system modelling its willing to pay (\u201cdemand price\u201d of each subgroup), while the retailer should set a \u201cunisex\u201d price. As in the discussion of insurance pricing, we consider subgroups S = {female, male} and use superscripts (f), (m) to distinguish the related quantities. Unlike in insurance pricing, the demand price of each customer is regarded as a single trajectory. More importantly, since customers might start buying soap, quit buying the soap, or move to other substitutes at different time points, those trajectories of demand prices are assumed to be of varying lengths. For example, a customer starts to buy the soap at time 3 but decides to buy hand wash instead from time 7.\nLet us assume there are |I(f)| female customers and |I(m)| customers in the overall time window T +. Let Y (i,s)t denote the estimated demand price at time t of the ith customer in subgroup s. These evolve as:\n\u03d5ft = G (f)\u03d5 (f) t\u22121 + \u03c9 (f) t , t \u2208 T +,\nY (i,f) t = F (f)\u2032\u03d5 (f) t + \u03bd (i,f) t , t \u2208 T (i,f), i \u2208 I(f),\n\u03d5mt = G (m)\u03d5 (m) t\u22121 + \u03c9 (m) t , t \u2208 T +,\nY (i,m) t = F (m)\u2032\u03d5 (m) t + \u03bd (i,m) t , t \u2208 T (i,m), i \u2208 I(m).\nThe unisex model for demand price considers the unisex state mt, the unisex system matrices G,F , and unisex noises \u03c9t, \u03bdt:\nmt = Gmt\u22121 + \u03c9t , t \u2208 T +, ft = F \u2032mt + \u03bdt , t \u2208 T +.\nFor loss(i,f)(ft) := ||Y (i,f)t \u2212 ft||, t \u2208 T (i,f), i \u2208 I(f) and loss(i,m)(ft) := ||Y (i,m) t \u2212 ft||, t \u2208 T (i,m), i \u2208 I(m), the two objectives Eq.(2)-Eq.(3) have the form:\nmin ft,t\u2208T + max s\u2208S  1|I(s)| I(s)\u2211 i=1\n1 |T (i,s)| \u2211\nt\u2208T (i,s)\n(i,s) loss(ft)  min\nft,t\u2208T +\n{ max\nt\u2208T (i,s),i\u2208Is,s\u2208S\n{ (i,s)\nloss(ft)\n}}\nWe also refer to (Dong, Miehling, & Langbort, 2020) for further work on protecting customers\u2019 interests in personalised pricing via fairness considerations."
        },
        {
            "heading": "Appendix B. Background",
            "text": "In this paper, we consider the case of multiple variants of the LDS and conduct proper learning of the LDS in a way of fairness using the technologies of non-commutative polynomial optimisation. In Section B, we firstly set our work in the context of system identification and control theory. Secondly, we introduce the concept of fairness, which can be used to deal with multiple variants of the LDS. In the end of this section, we provide a brief overview of non-commutative polynomial optimisation, pioneered by (Pironio et al., 2010) and nicely surveyed by (Burgdorf, Klep, & Povh, 2016), which is our key technical tool.\nB.1 Related Work in System Identification and Control\nResearch within System Identification variously appears in venues associated with Control Theory, Statistics, and Machine learning. We refer to (Ljung, 1998) and (Tangirala, 2014) for excellent overviews of the long history of research in the field, going back at least to (\u00c5str\u00f6m & Torsten, 1965). In this section, we focus on pointers to key more recent publications. In improper learning of LDS, a considerable progress has been made in the analysis of predictions for the expectation of the next measurement using auto-regressive (AR) processes. In (Anava, Hazan, Mannor, & Shamir, 2013), first guarantees were presented for auto-regressive moving-average (ARMA) processes. In (Liu, Hoi, Zhao, & Sun, 2016), these results were extended to a subset of autoregressive integrated moving average (liu2016online) processes. (Kozdoba, Marecek, Tchrakian, & Mannor, 2019) have shown that up to an arbitrarily small error given in advance, AR(s) will perform as well as any Kalman filter on any bounded sequence. This has been extended by (Tsiamis & Pappas, 2020) to Kalman filtering with logarithmic regret. Another stream of work within improper learning focuses on sub-space methods (Katayama, 2006; Van Overschee & De Moor, 2012) and spectral methods. (Tsiamis, Matni, & Pappas, 2020; Tsiamis & Pappas, 2019) presented the present-best guarantees for traditional sub-space methods. Within spectral methods, (Hazan, Singh, & Zhang, 2017) and (Hazan, Lee, Singh, Zhang, & Zhang, 2018) have considered learning LDS with input, employing certain eigenvalue-decay estimates of Hankel matrices in the analyses of an auto-regressive process in a dimension increasing over time. We stress that none of these approaches to improper learning are \u201cprediction-error\u201d: They do not estimate the system matrices.\nIn proper learning of LDS, many state-of-the-art approaches consider the least-squares method, despite complications encountered in unstable systems (Faradonbeh, Tewari, & Michailidis, 2018). (Simchowitz, Mania, Tu, Jordan, & Recht, 2018) have provided nontrivial guarantees for the ordinary least-squares (OLS) estimator in the case of stable G and there being no hidden component, i.e., F \u2032 being an identity and Yt = \u03d5t. Surprisingly, they have also shown that more unstable linear systems are easier to estimate than less unstable ones, in some sense. (Simchowitz, Boczar, & Recht, 2019) extended the results to allow for a certain pre-filtering procedure. (Sarkar & Rakhlin, 2019) extended the results to cover stable, marginally stable, and explosive regimes.\nOur work could be seen as a continuation of the least squares method to processes with hidden components, with guarantees of global convergence. In Computer Science, our work could be seen as an approximation scheme (Vazirani, 2013), as it allows for \u03f5 error for any \u03f5 > 0.\nB.2 Learning from Imbalanced Data\nTraditional machines learning algorithms can be biased towards majority class over-prevalence (Chawla, 2003), i.e., the under-representation bias (Blum & Stangl, 2019). Also, the cost of mis-classifying an abnormal event (minority class) as a normal event (majority class) is often relatively high (Chawla, Cieslak, Hall, & Joshi, 2008; Chawla, Bowyer, Hall, & Kegelmeyer, 2002). For example, in the case of fraud, diseases, those cases are rare but able to cause serious damages, so it is of great interest to research. The benchmark of learning from imbalanced data was pioneered by (Chawla et al., 2002). They proposed the Synthetic Minority Over-sampling Technique (SMOTE), such that a combination of over-sampling the minority class and under-sampling the majority class can efficiently improve the classifier performance.\nThe research in learning from imbalanced data has been extensively studied with a particular focus on classification and other predictive contexts as many real-world applications are already facing this problem (Torgo, Krawczyk, Branco, & Moniz, 2017; Fern\u00e1ndez, Garcia, Herrera, & Chawla, 2018). SMOTE has been successfully extended to a variety of applications because of its simplicity and robustness (Cieslak & Chawla, 2008). Surprisingly, (Chawla et al., 2008) provides an algorithm that automatically discovers the amount of re-sampling. One the other hand, (Moniz, Branco, & Torgo, 2017) proposed the concept of temporal and relevance bias in extension of re-sampling strategies. For the clear journey of SMOTE, please refer to (Fern\u00e1ndez et al., 2018).\nUnlike the common solution of re-sampling, we address the under-representation bias from the view of optimisation, such that the \u201closs\u201d, or other statistical performance is equalised over majority and minority subgroups.\nB.3 Non-Commutative Polynomial Optimisation\nIn learning of the LDS, the key technical tool of this paper is non-commutative polynomial optimisation (NCPOP), first introduced by (Pironio et al., 2010). Here, we provide a brief summary of their results, and refer to (Burgdorf et al., 2016) for a book-length introduction. NCPOP is an operator-valued optimisation problem with a standard form in Equation (11):\nP :\np\u2217 = min (H,X, \u03d5) \u27e8\u03d5, p(X)\u03d5\u27e9\ns.t. qi(X) \u227d 0,i = 1, . . . ,m,\n\u27e8\u03d5, \u03d5\u27e9 = 1,\n(11)\nwhere X = (X1, . . . , Xn) is a n-tuple of bounded operators on a Hilbert space H in this section. The normalised vector \u03d5, i.e., \u2225\u03d5\u22252 = 1 is also defined on H with inner product \u27e8\u03d5, \u03d5\u27e9 equals to 1. p(X) and qi(X) are polynomials and qi(X) \u227d 0 denotes that the operator qi(X) is positive semi-definite.\nIn contrast to traditional scalar-valued, vector-valued, or matrix-valued optimisation techniques, the dimension of operators X is unknown a priori. Let [X,X\u2020] denotes these 2n operators, with the \u2020-algebra being conjugate transpose. Monomials \u03c9, \u00b5 and \u03bd in following text are products of powers of variables from [X,X\u2020]. The degree of a monomial, denoted by |\u03c9|, refers to the sum of the exponents of all operators in the monomial \u03c9. Let Wk\ndenote the collection of all monomials whose degrees |\u03c9| \u2264 k. Polynomials p(X) and qi(X) of degrees deg(p) and deg(qi), respectively, can be written as:\np(X) = \u2211\n|\u03c9|\u2264deg(p)\np\u03c9\u03c9, qi(X) = \u2211\n|\u00b5|\u2264deg(qi)\nqi,\u00b5\u00b5,\nwhere i = 1, . . . ,m. Following (Akhiezer & Krein, 1962), we can define the moments on field R or C, with a feasible solution (H,X, \u03d5) of problem in Equation (11):\ny\u03c9 = \u27e8\u03d5, \u03c9\u03d5\u27e9,\nfor all \u03c9 \u2208 W\u221e and y1 = \u27e8\u03d5, \u03d5\u27e9 = 1. Given a degree k, the moments whose degrees are less or equal to k form a sequence of y = (y\u03c9)|\u03c9|\u22642k. With a finite set of moments y of degree k, we can define a corresponding kth order moment matrix Mk(y):\nMk(y)(\u03bd, \u03c9) = y\u03bd\u2020\u03c9 = \u27e8\u03d5, \u03bd\u2020\u03c9\u03d5\u27e9,\nfor any |\u03bd|, |\u03c9| \u2264 k and a localising matrix Mk\u2212di(qiy):\nMk\u2212di(qiy)(\u03bd, \u03c9) = \u2211\n|\u00b5|\u2264deg(qi)\nqi,\u00b5y\u03bd\u2020\u00b5\u03c9\n= \u2211\n|\u00b5|\u2264deg(qi)\nqi,\u00b5\u27e8\u03d5, \u03bd\u2020\u00b5\u03c9\u03d5\u27e9,\nfor any |\u03bd|, |\u03c9| \u2264 k \u2212 di, where di = \u2308deg(qi)/2\u2309. The upper bounds of |\u03bd| and |\u03c9| are lower than that of moment matrix because y\u03bd\u2020\u00b5\u03c9 is only defined on \u03bd\u2020\u00b5\u03c9 \u2208 W2k while \u00b5 \u2208 Wdeg(qi).\nIf (H,X, \u03d5) is feasible, one can utilise the Sums-of-Squares theorem of (Helton, 2002) and (McCullough, 2001) to derive semidefinite programming (SDP) relaxations. In particular, we can obtain a kth order SDP relaxation of the non-commutative polynomial optimisation problem in Equation (11) by choosing a degree k that satisfies the condition of 2k \u2265 max{deg(p),maxi deg(qi)}. The SDP relaxation of order k, which we denote Rk, has the form:\nRk :\npk = min y = (y\u03c9)|\u03c9|\u22642k \u2211 |\u03c9|\u2264d p\u03c9y\u03c9\ns.t. Mk(y) \u227d 0,\nMk\u2212di(qiy) \u227d 0,i = 1, . . . ,m,\n\u27e8\u03d5, \u03d5\u27e9 = 1.\n(12)\nLet us define the quadratic module, following (Pironio et al., 2010). Let Q = {qi, i = 1, . . . ,m} be the set of polynomials determining the constraints. The positivity domain SQ of Q are n-tuples of bounded operators X on a Hilbert space H making all qi(X) positive semidefinite. The quadratic module MQ is the set of \u2211 i f \u2020 i fi + \u2211 i \u2211 j g \u2020 ijqigij where fi and gij are polynomials in the 2n operators in [X,X\u2020]. As in (Pironio et al., 2010), if the Archimedean assumption is satisfied, limk\u2192\u221e pk = p\u2217 for a finite k.\nB.4 The Formal Statement\nIn order to utilise subgroup fairness or instantaneous fairness, one needs to be able to guarantee that global optima for the corresponding optimisation problems can be found. Such guarantees are non-trivial in the case of non-convex, non-commutative optimisation problems. Following (Zhou & Mare\u010dek, 2020), one can formalise the guarantees we provide:\nAssumption 1 (Archimedean). Quadratic module MQ of Eq.(5) or Eq.(6) is Archimedean, i.e., there exists a real constant C such that C2 \u2212 (X\u20201X1 + \u00b7 \u00b7 \u00b7+X \u2020 2nX2n) \u2208 MQ, for these"
        },
        {
            "heading": "2n operators in [X,X\u2020].",
            "text": "Our main result shows that it is possible to recover the quadruple (G,F, V,W ) of the subgroup-blind L with guarantees of global convergence: Theorem 2. For any observable linear system L = (G,F, V,W ), for any length T + of a time window, and any error \u03f5 > 0, under Assumption 1, there is a convex optimisation problem from whose solution one can extract the best possible estimate of system matrices of a system L based on the observations, with fairness subgroup-fair considerations Eq.(5), up to an error of at most \u03f5 in Frobenius norm. Furthermore, with suitably modified assumptions, the result holds also for the instant-fair considerations Eq.(6).\nProof. First, we need to show the existence of a sequence of convex optimisation problems, whose objective function approaches the optimum of the non-commutative polynomial optimisation problem. As explained in the subsection above, (Pironio et al., 2010) shows that, indeed, there are natural semidefinite programming problems, which satisfy this property. In particular, the existence and convergence of the sequence is shown by Theorem 1 of (Pironio et al., 2010), which requires Assumption 1.\nNotice that we can use the so-called rank-loop condition of (Pironio et al., 2010) to detect global optimality. Once optimality is detected, it is possible to extract the global optimum (H\u2217,X\u2217, \u03d5\u2217) from the optimal solution y of problem Rk, by Gram decomposition; cf. Theorem 2 in (Pironio et al., 2010). Simpler procedures for the extraction have been considered, cf. (Henrion & Lasserre, 2005), but remain less well understood.\nMore broadly, we would like to show the extraction of the minimiser from the SDP relaxation of order k(\u03f5) in the series is possible. There, one utilises the Gelfand\u2013Naimark\u2013 Segal (GNS) construction (Gelfand & Neumark, 1943; Segal, 1947), as explained in Section 2.2 of (Klep, Povh, & Volcic, 2018), which does not require the rank-loop condition to be satisfied, We refer to Section 2.2 of (Klep et al., 2018) and Section 2.6 of (Dixmier, 1969) for details.\nIn summary, Theorem 2 makes it possible to recover the quadruple (G,F, V,W ) of the subgroup-blind L using the technologies of NCPOP with guarantees of global convergence (Pironio et al., 2010). To do so, we need to have the non-commutative versions of those formulations firstly, thus introduce a a Hilbert space H with all operators and a normalised vector defined on H."
        },
        {
            "heading": "Appendix C. The COMPAS dataset",
            "text": "COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) is a popular commercial algorithm used by judges and parole officers for scoring criminal defendant\u2019s\nlikelihood of re-offending (recidivism). It has been shown that the algorithm is biased in favour of white defendants, based on a 2 year follow-up study (i.e., who actually committed crimes or violent crimes after 2 years).\nDownloaded from https://github.com/propublica/compas-analysis, this dataset is what (Angwin et al., 2016) used in analysing the racial bias in COMPAS recidivism scores. The COMPAS dataset comprises of defendants\u2019 gender, race, age, charge degree, COMPAS recidivism scores, two-year recidivism label, as well as information on prior incidents. The COMPAS recidivism scores, ranging from 1 to 10, are positively related to the estimated likelihood of recidivism, given by the COMPAS system. The two-year recidivism label denotes whether a person actually got rearrested within two years (label 1) or not (label 0). If the two-year recidivism label is 1, there is also information concerning the recharge degree and the number of days until the person gets rearrested. The dataset also consists of information on \u2019Days before Re-offending\u2019, which is the date difference between the defendant\u2019s crime offend date and recharge offend date. It could be negatively correlated to the defendant\u2019s actual risk level while the COMPAS recidivism scores would be the estimated risk level."
        }
    ],
    "title": "Fairness in Forecasting of Observations of Linear Dynamical Systems",
    "year": 2023
}