{
    "abstractText": "Large-scale cloud service systems are plagued by performance challenges, leading to significant financial repercussions. Identifying and localizing these issues effectively requires the careful analysis of service monitoring metrics, a task made complex by the scale and intricacies of contemporary cloud environments. While existing approaches attempt to manage this complexity by independently scrutinizing each metric, this often results in a deluge of alerts, making manual diagnosis cumbersome for engineers. To enhance performance, it is critical to recognize not only the temporal fluctuations of metrics but also the correlations among them, characterizing what can be termed a multivariate metrics anomaly detection problem. Most current methods, however, fail to clearly define these dual aspects. Additionally, the presence of unlabeled anomalies in training data can impede optimal detection performance. To overcome these challenges, we introduce the Relational-Temporal Anomaly Detection Model. This model synthesizes both relational and temporal metric information, utilizing a graph attention layer to discern dependencies among metrics, thereby effectively identifying the anomalous metrics causing an anomaly. We also incorporate positive unlabeled learning to navigate the complexities of potential anomalies within training data. We validate RTAnomaly\u2019s efficacy through testing on one publicly available dataset and two proprietary industrial datasets. By achieving an average F1 score of 0.929 and Hit@3 of 0.920, RTAnomaly convincingly outpaces all competitor baseline models, thereby highlighting its superiority in this complex task. and Hit@3 of 0.920, demonstrating its superiority.",
    "authors": [
        {
            "affiliations": [],
            "name": "Wenwei Gu"
        },
        {
            "affiliations": [],
            "name": "Jinyang Liu"
        },
        {
            "affiliations": [],
            "name": "Zhuangbin Chen"
        },
        {
            "affiliations": [],
            "name": "Jianping Zhang"
        },
        {
            "affiliations": [],
            "name": "Yuxin Su"
        },
        {
            "affiliations": [],
            "name": "Jiazhen Gu"
        },
        {
            "affiliations": [],
            "name": "Cong Feng"
        },
        {
            "affiliations": [],
            "name": "Zengyin Yang"
        },
        {
            "affiliations": [],
            "name": "Michael R. Lyu"
        }
    ],
    "id": "SP:c3318d0b15f007cb1c6cc8c2441137177572b6a0",
    "references": [
        {
            "authors": [
                "L. Qian",
                "Z. Luo",
                "Y. Du",
                "L. Guo"
            ],
            "title": "Cloud computing: An overview",
            "venue": "IEEE international conference on cloud computing. Springer, 2009, pp. 626\u2013631.",
            "year": 2009
        },
        {
            "authors": [
                "M. Jiang",
                "M.A. Munawar",
                "T. Reidemeister",
                "P.A. Ward"
            ],
            "title": "System monitoring with metric-correlation models: problems and solutions",
            "venue": "Proceedings of the 6th international conference on Autonomic computing, 2009, pp. 13\u201322.",
            "year": 2009
        },
        {
            "authors": [
                "Y. Amannejad",
                "D. Krishnamurthy",
                "B. Far"
            ],
            "title": "Detecting performance interference in cloud-based web services",
            "venue": "2015 IFIP/IEEE International Symposium on Integrated Network Management (IM). IEEE, 2015, pp. 423\u2013431.",
            "year": 2015
        },
        {
            "authors": [
                "O. Ibidunmoye",
                "F. Hern\u00e1ndez-Rodriguez",
                "E. Elmroth"
            ],
            "title": "Performance anomaly detection and bottleneck identification",
            "venue": "ACM Computing Surveys (CSUR), vol. 48, no. 1, pp. 1\u201335, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "M. Kazdagli",
                "M. Tiwari",
                "A. Kumar"
            ],
            "title": "Using constraint programming and graph representation learning for generating interpretable cloud security policies",
            "venue": "arXiv preprint arXiv:2205.01240, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J.A. Cid-Fuentes",
                "C. Szabo",
                "K. Falkner"
            ],
            "title": "Adaptive performance anomaly detection in distributed systems using online svms",
            "venue": "IEEE Transactions on Dependable and Secure Computing, vol. 17, no. 5, pp. 928\u2013941, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "M. Peiris",
                "J.H. Hill",
                "J. Thelin",
                "S. Bykov",
                "G. Kliot",
                "C. Konig"
            ],
            "title": "Pad: Performance anomaly detection in multi-server distributed systems",
            "venue": "2014 IEEE 7th International Conference on Cloud Computing. IEEE, 2014, pp. 769\u2013776.",
            "year": 2014
        },
        {
            "authors": [
                "X. Guo",
                "X. Peng",
                "H. Wang",
                "W. Li",
                "H. Jiang",
                "D. Ding",
                "T. Xie",
                "L. Su"
            ],
            "title": "Graph-based trace analysis for microservice architecture understanding and problem diagnosis",
            "venue": "Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2020, pp. 1387\u20131397.",
            "year": 2020
        },
        {
            "authors": [
                "R.P. Padhy"
            ],
            "title": "Big data processing with hadoop-mapreduce in cloud systems",
            "venue": "International Journal of Cloud Computing and Services Science, vol. 2, no. 1, p. 16, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "J.S. Ward",
                "A. Barker"
            ],
            "title": "Semantic based data collection for large scale cloud systems",
            "venue": "Proceedings of the fifth international workshop on Data-Intensive Distributed Computing Date, 2012, pp. 13\u201322.",
            "year": 2012
        },
        {
            "authors": [
                "Z. Chen",
                "J. Liu",
                "Y. Su",
                "H. Zhang",
                "X. Wen",
                "X. Ling",
                "Y. Yang",
                "M.R. Lyu"
            ],
            "title": "Graph-based incident aggregation for large-scale online service systems",
            "venue": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2021, pp. 430\u2013442.",
            "year": 2021
        },
        {
            "authors": [
                "G. Zhao",
                "S. Hassan",
                "Y. Zou",
                "D. Truong",
                "T. Corbin"
            ],
            "title": "Predicting performance anomalies in software systems at run-time",
            "venue": "ACM Transactions on Software Engineering and Methodology (TOSEM), vol. 30, no. 3, pp. 1\u201333, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Borghesi",
                "A. Bartolini",
                "M. Lombardi",
                "M. Milano",
                "L. Benini"
            ],
            "title": "Anomaly detection using autoencoders in high performance computing systems",
            "venue": "Proceedings of the AAAI Conference on artificial intelligence, vol. 33, no. 01, 2019, pp. 9428\u20139433.",
            "year": 2019
        },
        {
            "authors": [
                "D. Scheinert",
                "A. Acker",
                "L. Thamsen",
                "M.K. Geldenhuys",
                "O. Kao"
            ],
            "title": "Learning dependencies in distributed cloud applications to identify and localize anomalies",
            "venue": "2021 IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence). IEEE, 2021, pp. 7\u201312.",
            "year": 2021
        },
        {
            "authors": [
                "H. Xu",
                "W. Chen",
                "N. Zhao",
                "Z. Li",
                "J. Bu",
                "Z. Li",
                "Y. Liu",
                "Y. Zhao",
                "D. Pei",
                "Y. Feng"
            ],
            "title": "Unsupervised anomaly detection via variational autoencoder for seasonal kpis in web applications",
            "venue": "Proceedings of the 2018 world wide web conference, 2018, pp. 187\u2013196.",
            "year": 2018
        },
        {
            "authors": [
                "B. Zong",
                "Q. Song",
                "M.R. Min",
                "W. Cheng",
                "C. Lumezanu",
                "D. Cho",
                "H. Chen"
            ],
            "title": "Deep autoencoding gaussian mixture model for unsupervised anomaly detection",
            "venue": "International conference on learning representations, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "C. Zhang",
                "D. Song",
                "Y. Chen",
                "X. Feng",
                "C. Lumezanu",
                "W. Cheng",
                "J. Ni",
                "B. Zong",
                "H. Chen",
                "N.V. Chawla"
            ],
            "title": "A deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data",
            "venue": "Proceedings of the AAAI conference on artificial intelligence, vol. 33, no. 01, 2019, pp. 1409\u20131416.",
            "year": 2019
        },
        {
            "authors": [
                "M.B. Chhetri",
                "Q.B. Vo",
                "R. Kowalczyk"
            ],
            "title": "Cl-slam: Cross-layer sla monitoring framework for cloud service-based applications",
            "venue": "Proceedings of the 9th International Conference on Utility and Cloud Computing, 2016, pp. 30\u201336.",
            "year": 2016
        },
        {
            "authors": [
                "S. Luo",
                "H. Xu",
                "C. Lu",
                "K. Ye",
                "G. Xu",
                "L. Zhang",
                "Y. Ding",
                "J. He",
                "C. Xu"
            ],
            "title": "Characterizing microservice dependency and performance: Alibaba trace analysis",
            "venue": "Proceedings of the ACM Symposium on Cloud Computing, 2021, pp. 412\u2013426.",
            "year": 2021
        },
        {
            "authors": [
                "L. Shen",
                "Z. Li",
                "J. Kwok"
            ],
            "title": "Timeseries anomaly detection using temporal hierarchical one-class network",
            "venue": "Advances in Neural Information Processing Systems, vol. 33, pp. 13 016\u201313 026, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Su",
                "Y. Zhao",
                "C. Niu",
                "R. Liu",
                "W. Sun",
                "D. Pei"
            ],
            "title": "Robust anomaly detection for multivariate time series through stochastic recurrent neural network",
            "venue": "Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, 2019, pp. 2828\u2013 2837.",
            "year": 2019
        },
        {
            "authors": [
                "J. Soldani",
                "A. Brogi"
            ],
            "title": "Anomaly detection and failure root cause analysis in (micro) service-based cloud applications: A survey",
            "venue": "ACM Computing Surveys (CSUR), vol. 55, no. 3, pp. 1\u201339, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Chen",
                "J. Liu",
                "Y. Su",
                "H. Zhang",
                "X. Ling",
                "Y. Yang",
                "M.R. Lyu"
            ],
            "title": "Adaptive performance anomaly detection for online service systems via pattern sketching",
            "venue": "Proceedings of the 44th International Conference on Software Engineering, 2022, pp. 61\u201372.",
            "year": 2022
        },
        {
            "authors": [
                "H. Wang",
                "Z. Wu",
                "H. Jiang",
                "Y. Huang",
                "J. Wang",
                "S. Kopru",
                "T. Xie"
            ],
            "title": "Groot: An event-graph-based approach for root cause analysis in industrial settings",
            "venue": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2021, pp. 419\u2013429.",
            "year": 2021
        },
        {
            "authors": [
                "A.S. Milani",
                "N.J. Navimipour"
            ],
            "title": "Load balancing mechanisms and techniques in the cloud environments: Systematic literature review and future trends",
            "venue": "Journal of Network and Computer Applications, vol. 71, pp. 86\u201398, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "M.S. Bali",
                "S. Khurana"
            ],
            "title": "Effect of latency on network and end user domains in cloud computing",
            "venue": "2013 International Conference on Green Computing, Communication and Conservation of Energy (ICGCE). IEEE, 2013, pp. 777\u2013782.",
            "year": 2013
        },
        {
            "authors": [
                "S. Ghosh",
                "M. Shetty",
                "C. Bansal",
                "S. Nath"
            ],
            "title": "How to fight production incidents? an empirical study on a large-scale cloud service",
            "venue": "Proceedings of the 13th Symposium on Cloud Computing, 2022, pp. 126\u2013141.",
            "year": 2022
        },
        {
            "authors": [
                "E.J. Ghomi",
                "A.M. Rahmani",
                "N.N. Qader"
            ],
            "title": "Load-balancing algorithms in cloud computing: A survey",
            "venue": "Journal of Network and Computer Applications, vol. 88, pp. 50\u201371, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "N. Zhao",
                "J. Chen",
                "X. Peng",
                "H. Wang",
                "X. Wu",
                "Y. Zhang",
                "Z. Chen",
                "X. Zheng",
                "X. Nie",
                "G. Wang"
            ],
            "title": "Understanding and handling alert storm for online service systems",
            "venue": "Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice, 2020, pp. 162\u2013171.",
            "year": 2020
        },
        {
            "authors": [
                "K. Hundman",
                "V. Constantinou",
                "C. Laporte",
                "I. Colwell",
                "T. Soderstrom"
            ],
            "title": "Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding",
            "venue": "Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining, 2018, pp. 387\u2013395.",
            "year": 2018
        },
        {
            "authors": [
                "S. Brody",
                "U. Alon",
                "E. Yahav"
            ],
            "title": "How attentive are graph attention networks?",
            "venue": "arXiv preprint arXiv:2105.14491,",
            "year": 2021
        },
        {
            "authors": [
                "B. Xu",
                "N. Wang",
                "T. Chen",
                "M. Li"
            ],
            "title": "Empirical evaluation of rectified activations in convolutional network",
            "venue": "arXiv preprint arXiv:1505.00853, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "T.N. Kipf",
                "M. Welling"
            ],
            "title": "Semi-supervised classification with graph convolutional networks",
            "venue": "arXiv preprint arXiv:1609.02907, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Lee",
                "I. Lee",
                "J. Kang"
            ],
            "title": "Self-attention graph pooling",
            "venue": "International conference on machine learning. PMLR, 2019, pp. 3734\u20133743.",
            "year": 2019
        },
        {
            "authors": [
                "A. Vaswani",
                "N. Shazeer",
                "N. Parmar",
                "J. Uszkoreit",
                "L. Jones",
                "A.N. Gomez",
                "\u0141. Kaiser",
                "I. Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, vol. 30, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. Cangea",
                "P. Veli\u010dkovi\u0107",
                "N. Jovanovi\u0107",
                "T. Kipf",
                "P. Li\u00f2"
            ],
            "title": "Towards sparse hierarchical graph classifiers",
            "venue": "arXiv preprint arXiv:1811.01287, 2018.",
            "year": 1811
        },
        {
            "authors": [
                "T. Huang",
                "P. Chen",
                "J. Zhang",
                "R. Li",
                "R. Wang"
            ],
            "title": "A transferable time series forecasting service using deep transformer model for online systems",
            "venue": "37th IEEE/ACM International Conference on Automated Software Engineering, 2022, pp. 1\u201312.",
            "year": 2022
        },
        {
            "authors": [
                "R. Fu",
                "Z. Zhang",
                "L. Li"
            ],
            "title": "Using lstm and gru neural network methods for traffic flow prediction",
            "venue": "2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC). IEEE, 2016, pp. 324\u2013328.",
            "year": 2016
        },
        {
            "authors": [
                "A. v. d. Oord",
                "S. Dieleman",
                "H. Zen",
                "K. Simonyan",
                "O. Vinyals",
                "A. Graves",
                "N. Kalchbrenner",
                "A. Senior",
                "K. Kavukcuoglu"
            ],
            "title": "Wavenet: A generative model for raw audio",
            "venue": "arXiv preprint arXiv:1609.03499, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S. Ioffe",
                "C. Szegedy"
            ],
            "title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
            "venue": "International conference on machine learning. PMLR, 2015, pp. 448\u2013456.",
            "year": 2015
        },
        {
            "authors": [
                "D.P. Kingma",
                "M. Welling"
            ],
            "title": "Auto-encoding variational bayes",
            "venue": "arXiv preprint arXiv:1312.6114, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "D.J. Rezende",
                "S. Mohamed",
                "D. Wierstra"
            ],
            "title": "Stochastic backpropagation and approximate inference in deep generative models",
            "venue": "International conference on machine learning. PMLR, 2014, pp. 1278\u2013 1286.",
            "year": 2014
        },
        {
            "authors": [
                "J. Lin",
                "P. Chen",
                "Z. Zheng"
            ],
            "title": "Microscope: Pinpoint performance issues with causal graphs in micro-service environments",
            "venue": "Service-Oriented Computing: 16th International Conference, ICSOC 2018, Hangzhou, China, November 12-15, 2018, Proceedings 16. Springer, 2018, pp. 3\u201320.",
            "year": 2018
        },
        {
            "authors": [
                "H. Shan",
                "Y. Chen",
                "H. Liu",
                "Y. Zhang",
                "X. Xiao",
                "X. He",
                "M. Li",
                "W. Ding"
            ],
            "title": "-diagnosis: Unsupervised and real-time diagnosis of small-window long-tail latency in large-scale microservice platforms",
            "venue": "The World Wide Web Conference, 2019, pp. 3215\u20133222.",
            "year": 2019
        },
        {
            "authors": [
                "H. Nguyen",
                "Y. Tan",
                "X. Gu"
            ],
            "title": "Pal: P ropagation-aware a nomaly l ocalization for cloud hosted distributed applications",
            "venue": "Managing Large-scale Systems via the Analysis of System Logs and the Application of Machine Learning Techniques, 2011, pp. 1\u20138.",
            "year": 2011
        },
        {
            "authors": [
                "M. Ma",
                "Z. Yin",
                "S. Zhang",
                "S. Wang",
                "C. Zheng",
                "X. Jiang",
                "H. Hu",
                "C. Luo",
                "Y. Li",
                "N. Qiu"
            ],
            "title": "Diagnosing root causes of intermittent slow queries in cloud databases",
            "venue": "Proceedings of the VLDB Endowment, vol. 13, no. 8, pp. 1176\u20131189, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Weng",
                "J.H. Wang",
                "J. Yang",
                "Y. Yang"
            ],
            "title": "Root cause analysis of anomalies of multitier services in public clouds",
            "venue": "IEEE/ACM Transactions on Networking, vol. 26, no. 4, pp. 1646\u20131659, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "L. Yang",
                "J. Chen",
                "Z. Wang",
                "W. Wang",
                "J. Jiang",
                "X. Dong",
                "W. Zhang"
            ],
            "title": "Plelog: Semi-supervised log-based anomaly detection via probabilistic label estimation",
            "venue": "2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion). IEEE, 2021, pp. 230\u2013231.",
            "year": 2021
        },
        {
            "authors": [
                "R. Kiryo",
                "G. Niu",
                "M.C. Du Plessis",
                "M. Sugiyama"
            ],
            "title": "Positiveunlabeled learning with non-negative risk estimator",
            "venue": "Advances in neural information processing systems, vol. 30, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "B. Sch\u00f6lkopf",
                "J.C. Platt",
                "J. Shawe-Taylor",
                "A.J. Smola",
                "R.C. Williamson"
            ],
            "title": "Estimating the support of a high-dimensional distribution",
            "venue": "Neural computation, vol. 13, no. 7, pp. 1443\u20131471, 2001.",
            "year": 2001
        },
        {
            "authors": [
                "F.T. Liu",
                "K.M. Ting",
                "Z.-H. Zhou"
            ],
            "title": "Isolation forest",
            "venue": "2008 eighth ieee international conference on data mining. IEEE, 2008, pp. 413\u2013422.",
            "year": 2008
        },
        {
            "authors": [
                "M.M. Breunig",
                "H.-P. Kriegel",
                "R.T. Ng",
                "J. Sander"
            ],
            "title": "Lof: identifying density-based local outliers",
            "venue": "Proceedings of the 2000 ACM SIGMOD international conference on Management of data, 2000, pp. 93\u2013104.",
            "year": 2000
        },
        {
            "authors": [
                "D. Park",
                "Y. Hoshi",
                "C.C. Kemp"
            ],
            "title": "A multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder",
            "venue": "IEEE Robotics and Automation Letters, vol. 3, no. 3, pp. 1544\u20131551, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "J. Audibert",
                "P. Michiardi",
                "F. Guyard",
                "S. Marti",
                "M.A. Zuluaga"
            ],
            "title": "Usad: Unsupervised anomaly detection on multivariate time series",
            "venue": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2020, pp. 3395\u20133404.",
            "year": 2020
        },
        {
            "authors": [
                "H. Ren",
                "B. Xu",
                "Y. Wang",
                "C. Yi",
                "C. Huang",
                "X. Kou",
                "T. Xing",
                "M. Yang",
                "J. Tong",
                "Q. Zhang"
            ],
            "title": "Time-series anomaly detection service at microsoft",
            "venue": "Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, 2019, pp. 3009\u2013 3017.",
            "year": 2019
        },
        {
            "authors": [
                "S. Tuli",
                "G. Casale",
                "N.R. Jennings"
            ],
            "title": "Tranad: Deep transformer networks for anomaly detection in multivariate time series data",
            "venue": "arXiv preprint arXiv:2201.07284, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "Y. Zhao",
                "Z. Nasrullah",
                "Z. Li"
            ],
            "title": "Pyod: A python toolbox for scalable outlier detection",
            "venue": "arXiv preprint arXiv:1901.01588, 2019.",
            "year": 1901
        }
    ],
    "sections": [
        {
            "text": "Performance Issue Identification in Cloud Systems with Relational-Temporal Anomaly Detection\nWenwei Gu\u2217, Jinyang Liu\u2217, Zhuangbin Chen\u2020, Jianping Zhang\u2217, Yuxin Su\u2020, Jiazhen Gu\u2217, Cong Feng\u2021, Zengyin Yang\u2021, and Michael R. Lyu\u2217\n\u2217Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China. Email: {wwgu21, jyliu, jpzhang, lyu}@cse.cuhk.edu.hk, jiazhengu@cuhk.edu.hk\n\u2020Sun Yat-sen University, Guangzhou, China. Email: {chenzhb36, suyx35}@mail.sysu.edu.cn \u2021Huawei Company, Shenzhen, China. Email: {fengcong5, yangzengyin}@huawei.com\nAbstract\u2014Large-scale cloud service systems are plagued by performance challenges, leading to significant financial repercussions. Identifying and localizing these issues effectively requires the careful analysis of service monitoring metrics, a task made complex by the scale and intricacies of contemporary cloud environments. While existing approaches attempt to manage this complexity by independently scrutinizing each metric, this often results in a deluge of alerts, making manual diagnosis cumbersome for engineers. To enhance performance, it is critical to recognize not only the temporal fluctuations of metrics but also the correlations among them, characterizing what can be termed a multivariate metrics anomaly detection problem. Most current methods, however, fail to clearly define these dual aspects. Additionally, the presence of unlabeled anomalies in training data can impede optimal detection performance. To overcome these challenges, we introduce the Relational-Temporal Anomaly Detection Model. This model synthesizes both relational and temporal metric information, utilizing a graph attention layer to discern dependencies among metrics, thereby effectively identifying the anomalous metrics causing an anomaly. We also incorporate positive unlabeled learning to navigate the complexities of potential anomalies within training data. We validate RTAnomaly\u2019s efficacy through testing on one publicly available dataset and two proprietary industrial datasets. By achieving an average F1 score of 0.929 and Hit@3 of 0.920, RTAnomaly convincingly outpaces all competitor baseline models, thereby highlighting its superiority in this complex task. and Hit@3 of 0.920, demonstrating its superiority.\nIndex Terms\u2014Anomaly Detection, Cloud Reliability, Multivariate Metrics, Cloud Service Systems\nI. INTRODUCTION Cloud computing has surged in popularity in recent years. Large-scale cloud service vendors, e.g., Microsoft Azure, Amazon Web Services, and Google Cloud Platform, provide customers with various resources and services over the Internet [1]. Due to the huge scale and the complexity of cloud systems, performance issues (e.g., degradation of overall availability, increment of network latency, and application processing delays) are inevitable [2]. Such performance issues may cause SLA (Service Level Agreement) violations, leading to substantial economic losses [3]. Therefore, identifying performance issues accurately is a critical task during the maintenance of cloud online service systems [4].\nIn current practice, due to the privacy of the client service [5], cloud service vendors typically collect external information (e.g., computing resource utilization and throughput\nof the services) via the backend monitoring system [6], and then analyze the collected information to identify potential issues. Simple as the process might seem, it is non-trivial to identify performance issues in cloud service systems. In particular, a service system is typically huge in scale [7] with microservices architecture [8] and produces a large volume of monitoring data [9], [10]. Manually analyzing large amounts of data to identify issues is tedious and labour-intensive [11], which is not a feasible approach to cloud maintenance. As a result, engineers resort to automatic methods based on machine learning techniques (including deep learning), e.g., LSTMbased models [12], to identify performance issues.\nSince the external information (i.e., various key performance indicators) can be organized as multivariate metrics, the performance issue identification problem is typically formulated as an anomaly detection problem on multivariate metrics in the literature [13]\u2013[15]. In particular, a body of work [16], [17] adopts unsupervised learning methods to learn the behavior of the service system in failure-free status and detect anomalies that deviate from the behavior due to the lack of labeled data. These methods assume the training data are \u201dnormal\u201d (i.e., do not contain performance issues). However, this assumption may not be true for metrics from production cloud systems. Specifically, mild performance issues exist in real production systems that may not cause obvious anomalies, which is noise in the metric data.\nIn particular, a cloud service generally consists of various components (e.g., storage, computing, and middleware) whose corresponding monitoring metrics have complicated interdependencies [14], [18], [19]. Take CPU usage and network latency in a service system as an example; both metrics appear normal most of the time in isolation. However, we notice that when the system experiences heavy traffic, there\u2019s a violation of the correlation between CPU usage and network latency. Specifically, the CPU usage remains low while network latency spikes, indicating that there may be a bottleneck in the network layer that\u2019s causing the system to slow down. Though this case seems simple, there exists a multitude of correlations between a large number of system metrics that are intricate and challenging to extract manually. Furthermore, engineers may encounter difficulties in comprehending the underlying causes of performance issues, which may make troubleshooting and ar X\niv :2\n30 7.\n10 86\n9v 2\n[ cs\n.L G\n] 1\nA ug\n2 02\n3\noptimization more demanding. Existing approaches [12], [20], [21] only focus on detecting single anomalous metrics without considering the correlation between different metrics. Specifically, they just embed the temporal dependency and alert anomalies on each metric individually. Though [17] computes the correlations between metrics as pairwise inner products through a signature matrix, it cannot meet the industrial requirements of performance anomaly detection without learning from the dynamics of each metric. Therefore, it is also essential to consider the correlations between different metrics to accurately identify performance anomalies in cloud systems.\nHowever, obtaining the correlations between metrics and conducting anomaly detection accordingly is a non-trivial task. First, it is hard to automatically and effectively model the complicated correlations among a variety of metrics. A typical cloud application consists of tens of micro-services, each having tens of metrics, leading to a large number of metrics. Moreover, the correlation between metrics is complicated. Even experienced engineers cannot comprehensively clarify the relations among different metrics. Second, due to a large number of correlated metrics, approaches simply producing binary outputs (i.e., normal and abnormal) are not enough. Engineers still have to spend extensive efforts investigating the problematic metrics. For large-scale online services with hundreds of metrics, this process can be extremely timeconsuming. Thus, localizing the correlation-violated metric is a problem to be addressed. However, existing methods take anomaly detection and metrics localization as two independent tasks without integrating them into a unified framework [22]. Finally, metric data from large-scale production systems are noisy [23], i.e., mild performance issues may not cause obvious anomalies in the metric data. It is infeasible and impossible to manually annotate a huge volume of noisy data. On the other hand, simply neglecting such noise and treating the data as normal ones may lead to inaccurate results.\nTo address these challenges, we propose a method named Relational-Temporal Anomaly Detection (RTAnomaly). It utilizes the strength of graph neural networks to capture the complicated correlations explicitly aiming at solving the first challenge. For the second challenge, root cause refers to the component of the service system that causes production failures with serious business impacts [24]. Intuitively, the metrics that indicate the root cause will show abnormal indicators when performance anomaly occurs, i.e., the correlations between others change a lot, which can also be obtained by our framework. Furthermore, unlike existing VAE-based methods, we propose a novel architecture, LC-VAE, that can take both negative and positive samples. Eventually, we adopt positive unlabeled learning that helps against noise to solve the third challenge. We summarize the main contributions of this work as follows:\n\u2022 We propose the first end-to-end model that considers both the relational and temporal dependency between monitoring metrics explicitly and utilizes the relational information to localize anomalous metrics that would be the root cause. Besides, we are among the first to\nadopt positive unlabeled learning on metrics performance anomaly detection that alleviates the negative effect of noise. \u2022 We conduct extensive experiments on two industrial datasets collected from large-scale online service systems of a cloud provider and a publicly available dataset. The result shows that RTAnomaly achieves an average F1 score of 0.929 and Hit@3 of 0.920, which outperforms state-of-the-art baselines. We also conduct ablation studies to further validate the effectiveness of our design. A case study further shows the practical usefulness of our proposed RTAnomaly. \u2022 We have successfully deployed RTAnomaly into the troubleshooting system of a large-scale cloud service company H. The success stories of our deployment confirm the practical usefulness of our method."
        },
        {
            "heading": "II. BACKGROUND",
            "text": "In this section, we first discuss the background of performance anomaly detection. Then, we present an example in the industrial scenario to motivate our problem. Based on this understanding, we outline the industrial requirements that inspire our method design."
        },
        {
            "heading": "A. Performance Issues in Cloud Service Systems",
            "text": "In recent years, cloud service systems have gained significant traction due to their ability to provide scalable, on-demand resources and services. However, performance issues have emerged as a primary concern, potentially undermining the effectiveness of cloud service systems. Some typical factors contributing to these performance issues are resource overload and network latency. Resource overload occurs when the demand for resources exceeds the available capacity, resulting in performance degradation and potential service disruptions [25]. Network latency, exacerbated by the distributed nature of cloud systems, can result in reduced application responsiveness, impacting the overall user experience [26].\nIn modern cloud service systems, to monitor the overall status of the system, coupled multivariate metrics are collected in run-time. The collected metrics provide insights into the performance of logical and physical resources within the system, allowing operators to identify and address performance issues before they lead to service disruptions. However, due to the complex inter-dependencies between system components [27], these metrics are often strongly correlated with each other, reflecting the interconnected nature of the system. For example, the performance of a virtual machine may be influenced by the workload placed on the underlying physical server, and the performance of a microservice may depend on the availability of other microservices it interacts with. As a result, the metrics collected from different components can exhibit strong correlations with each other, reflecting the complex inter-dependencies within the system.\nB. Intrinsic Dependency between Metrics Different types of metrics that depict the status of a service will be monitored and analyzed collectively. They provide\nsystem engineers with an intuitionistic view to understanding the operation of the system. Since different components of a service are coupled and work synergistically, there exists dependency among different metrics. As a result, when performance issues happen, not only some specific metrics will exhibit abnormal tendencies, but also the dependencies reflecting the intrinsic properties of two metrics will be violated. Due to the complex correlation of the multivariate metrics, it is challenging to accurately detect true anomalies at the service level.\nAn industrial case in the online service system of a cloud vendor is shown in Figure 1. Three metrics of the service are shown in the figure for convenience of presentation. Specifically, metric A represents the throughput of microservice X , and metric B represents the throughput of microservice Y , which is the downstream microservice that processes the outputs of X . While metric C is the average CPU usage of all virtual machines of this service. We can observe that the variation tendencies between metric A and metric B are somehow consistent during the anomaly-free period. Metric C is used to monitor the resource usage of the service and can raise alerts when there are resource overload issues. However, with the existence of load balance [28], a sudden spike in CPU usage will not necessarily lead to a performance issue. Thus, if we trigger alerts based on pre-defined thresholds (as the red dashed line shows), many false alarms will be reported and cause an alert storm that aggravates the burden of engineers [29].\nThe red areas in Figure 1 denote a confirmed performance issue by engineers. This issue is caused by a network device failure between X and Y . As a result, the outputs of X can not be attained by Y , causing the throughput of X suddenly drops even if the throughput of Y increases. In this case, the correlation between metric A and metric B is critical to rapidly identify this issue. It is worth noting that a straightforward way to identify this issue is to build a new metric that combines metric A and metric B. However, since a cloud service system typically has a variety of metrics, it is infeasible for engineers\nto design such combined metrics comprehensively. Besides, due to the large metric number, it is also critical for the anomaly detection methods to identify the metrics that violate the correlations, which can greatly facilitate further issue diagnosis."
        },
        {
            "heading": "III. METHODOLOGY",
            "text": "In this section, we present RTAnomaly, an anomaly detection approach for multivariate metrics monitored in cloud systems. We first give a formal definition of the problem. Then we give an overview of RTAnomaly and elaborate on the design details."
        },
        {
            "heading": "A. Problem Formulation",
            "text": "A group of monitoring metrics can be seen as a multivariate time series X \u2208 RN\u00d7M , where N denotes the number of observations collected at an equal interval [21] and M is the number of metrics. The observation at timestamp t, xt = [x 1 t , x 2 t , ..., x M t ], is an M -dimensional vector [30] that reflects the running status of the system. While the N - dimensional vector xk = [xk1 , x k 2 , ..., x k N ] is the k\nth metric during the whole monitoring period. Indeed, historical values can be useful for modeling the pattern of current observation. Therefore, a sliding window of historical values xkt\u2212w:t = [xkt\u2212w+1, x k t\u2212w+2, ..., x k t ] is used instead of merely the current observation xt, where w is the length of the sliding window. The objective is to determine whether there is an occurrence of performance issues at observation xt. A typical anomaly detection approach calculates the anomaly score st \u2208 [0, 1] that represents the degree of being anomalous for each xt\u2212w:t. Then the anomaly result can be obtained by comparing the anomaly score against a pre-defined threshold \u03b8. If st > \u03b8, the approach will predict the observation xt as an anomaly. However, it is still unclear to engineers how the anomaly happens. Thus, a kind of anomaly interpretation can be achieved through anomalous metrics localization, i.e., pinpointing a set of metrics {xk1 , xk2 , ...xkr}, that is related to the root cause of the anomaly by the degree of deviation of temporal pattern or break of correlation with other metrics, where r is the number of metrics that are recommended as the root cause."
        },
        {
            "heading": "B. Overview",
            "text": "We propose RTAnomaly, an automated method that learns correlations among metrics, detects performance anomalies, and locates anomalous metrics. The overview of RTAnomaly is shown in Figure 2, which contains two main parts: the rational-temporal embedding part and the anomaly detection with LC-VAE part. Specifically, since both abnormal temporal patterns and correlation violations between metrics can indicate performance issues, in the relational-temporal embedding part, RTAnomaly captures the relational and temporal patterns from the original metrics (Section III-C). In particular, due to the lack of information about the correlation among metrics, a complete graph is constructed, then RTAnomaly employs graph attention to extract the correlation among metrics. RTAnomaly also captures the temporal dependency\nof each metric through GRU and temporal convolution. In the anomaly detection part, a novel label-conditional-VAE (LCVAE) is adopted to distinguish anomalies from normal patterns (Section III-D). Different from existing VAE-based methods that only learn from negative (normal) samples, the LC-VAE can take both positive and negative samples as inputs and learn features, achieving better performance. After detecting an anomaly, the correlation learned from relational-temporal embedding can help localize the correlation-violation metric (Section III-E). Since background noise inevitably exists in the data, we propose to use the positive unlabeled learning strategy when training RTAnomaly (Section III-F), which identifies positive samples in unlabeled training data, avoiding the impact of noisy data."
        },
        {
            "heading": "C. Relational-Temporal Embedding",
            "text": "The relational-temporal embedding part takes an MTS (i.e., a group of metrics) as inputs. Since different metrics may have a wide variety of scales, RTAnomaly first normalizes the input metrics using the Min-max normalization.\nRelational embedding is designed to extract the intrinsic dependencies between metrics and embeds the dependencies as a feature vector. Temporal embedding is used to obtain the temporal patterns of metrics as another feature vector because metrics are time series.\n1) Relational Embedding: Specifically, for multivariate metrics with size M\u00d7W , we can treat each metric xi, (i = 1, 2, ...M) as a feature vector. The correlations between nodes can be depicted by an adjacency matrix A \u2208 RM\u00d7M . Since we don\u2019t have prior knowledge about the correlation between different metrics, we should construct a fully connected graph. We then adopt graph attention networks (GAT) [31] to learn the correlation between metrics. The attention score is calculated as follows:\naij = exp(pTLeakyReLU(w \u00b7 (xi \u2295 xj)))\u2211M k=1 exp(p TLeakyReLU(w \u00b7 (xi \u2295 xk))) (1)\nThe symbol \u2295 represents the concatenation operator between two metrics xi and xj , w \u2208 R2W\u00d7d is a matrix of learnable parameters to aggregate the two features. After a nonlinear activation function LeakyReLU [32], another learnable vector p \u2208 Rd is applied. To make the training process more robust and reduce the impact of noise, a threshold t is set to make the adjacency matrix a sparse binary matrix. Then, a widely used graph convolution layer [33] is adopted. The formula of graph convolution is shown as follows:\nh\u0302(l+1) =\u03c3(D\u0303 \u2212 12 l A\u0303lD\u0303 \u2212 12 l h (l)\u0398l) (2)\nwhere \u03c3 is the ReLU activation function and A\u0303l = Al+I is the adjacency matrix at the layer l, D\u0303 \u2208 RM\u00d7M is the degree matrix of A\u0303l, h(l) is the output representation of the hidden layer l and \u0398l \u2208 RM\u00d7F is a learnable parameter. Due to the limitation of space, we only show one layer in Figure 2.\nWe further apply graph pooling layers between the graph convolution layers to reduce the number of parameters, which\ncan also avoid overfitting. Specifically, as proposed by [34], self-attention [35] is utilized to focus more on important features and less on unimportant features. Thus, self-attention scores can be obtained by using another graph convolution. After obtaining the attention scores Z, a portion of the nodes and features will be reserved according to the scores. A hyperparameter k refers to the pooling ratio, and the corresponding nodes with the top \u230akM\u230b value of Z will be retained.\nReadout layer [36] is useful to aggregate all node features and get a summarized representation, which is used to output the relational embedding. The output of the readout layer is as follows:\nrl = 1\nNl Nl\u2211 n=1 h(l)n \u2295 Nl max n=1 h(l)n (3)\nwhere Nl denotes the node number of layer l, h (l) n is the nth node feature of h(l) and \u2295 is concatenation operator. The outputs of each layer will go through readout layers and will be added up as the output of the relational embedding module because the features of different sparsity of graph can be combined.\n2) Temporal Embedding: Existing metrics anomaly detection works [12], [30] utilize LSTM to acquire sequential information as Long-term temporal dependency inherently exists in monitoring metrics [37]. However, LSTM suffers from the gradient vanishing problem incurred by long-time lags [38]. To overcome the drawbacks of LSTM, we apply a GRU to capture the sequential information tg , especially the long-term pattern in the metrics. Then, global average pooling layers are applied on the time series dimension of the output of DC convolution and GRU to get the temporal embedding.\nTemporal convolution is useful to capture the multi-scale temporal information of metrics. Unlike the existing methods that embed metrics with only recurrent neural networks, we also deploy causal convolution implemented by shifting the output of the 1D convolution. To further increase the receptive field of the convolutions, we use dilated convolutions. Dilated convolution is equivalent to filling the convolution kernel with zero padding so as to get a larger convolutional filter. Thus, we adopt dilated causal convolution (DC convolution) [39] to extract the temporal embedding of the metrics as it has advantages over the original convolutional operation with a larger receptive field, which is beneficial to our temporal embedding module as it can capture the behaviors of monitoring metrics at multi-scale. A block that consists of DC convolution, batch normalization [40], and activation function (i.e. ReLU) is utilized to form the temporal convolution. Eventually, the temporal embedding will be concatenated to the relational embedding and go through a fully connected layer to get the relational-temporal embedding."
        },
        {
            "heading": "D. Label-Conditional VAE",
            "text": "With the extracted relational-temporal embedding, we then use a novel Label Conditional VAE to detect performance issues. Unlike traditional autoencoder-based methods that only\ntake normal samples as input to capture the distribution of metrics, our proposed Label Conditional VAE takes the label as a part of the input to further help the model differentiate anomalies from normal data because there exist some mild performance issues that are ignored by engineers in training data.\nSince the posterior of the distribution p\u03b8(z|y, e) is critical for training and prediction of the model but is hard to obtain. Thus the variational inference is used to fit a neural network as the approximation posterior q\u03d5(z|y, e). Suppose the prior of the latent variable Z is Gaussian distribution N (0, 1) and y is the true label of the input sliding windows. Then both posteriors of e and z are chosen to be Gaussian distribution: p\u03b8(e|y, z) = N (\u00b5\u03b8(z), \u03c32\u03b8(z)) and q\u03d5(z|y, e) = N (\u00b5\u03d5(e), \u03c32\u03d5(e)), where \u00b5\u03b8(z), \u03c3\u03b8(z) and \u00b5\u03d5(e), \u03c3\u03d5(e), are the means and standard deviations of input embedding and latent variable. The input embedding e will be concatenated with the one-hot label vector y, and then the latent variable z will be sampled from a posterior p\u03b8(e|y, z) at the encoder, which is usually derived by linear layers [41]. Eventually, the latent variable will also be concatenated with y, and the input embedding will be reconstructed from q\u03d5(z|y, e) at the decoder. The reconstructed embedding can be denoted as e\u0302.\nIn general, the parameters of the LC-VAE can be estimated efficiently with the stochastic gradient variational Bayes (SGVB) algorithm [42]. The evidence-lower bound (ELBO) is a surrogate objective function that can help the estimation. Besides, to better capture the latent pattern of normal sliding windows, we add an additional reconstruction error term. The loss function of the proposed LC-VAE is shown as follows:\nLLCV AE =sgn(0.5\u2212 y) \u2217 (\u2212KL(q\u03d5(z|y, e)\u2225p\u03b8(e|y, z))\n+ 1\nS S\u2211 s=1 (log p\u03b8(es|y) + \u03bb \u00b7 \u2225es \u2212 e\u0302s\u22252))\n(4) where S is the number of sliding window samples. The\nfirst two terms are from evidence-lower bound (ELBO), and the third term is the reconstruction error of the embedding. In this way, we combine the strength of reconstruction and probabilistic estimation together. The coefficient \u03bb > 0 is to trade off the loss terms. As mentioned above, metrics anomaly detection works by learning the normal patterns of sliding windows of metrics; thus, we should minimize the loss function for a coming normal sliding window. However, when there is an anomalous sample input, we should avoid the model to learn the pattern of anomaly by maximizing the loss function. Thus we denote the loss function with the Signum function to control the sign. In this way, during the detection phase, the anomalies are easy to differentiate by RTAnomaly. The reconstruction error \u2225es \u2212 e\u0302s\u22252 will be used as the anomaly score during the detection phase."
        },
        {
            "heading": "E. Anomalous Metric Localization",
            "text": "Once an anomaly has been detected in a service system, further analyses will be enacted to determine the possible causes for such a performance anomaly [43], [44]. This allows application operators to determine which part of the service this performance issue reported is related to. For monitoring metrics, to further understand the mechanism of the happening of performance issues, pinpointing a few metrics that are highly correlated with the root cause is crucial. For example, when we observed that the throughput metrics of two devices are highlighted, it seems to happen a performance issue related to the communication between two devices. While our model highlights the CPU utilization of a service, it is likely to occur due to a lack of computing resources in the run-time environment [45].\nHowever, existing methods regarding monitoring metrics have not integrated anomaly detection and metric localization, namely root cause localization together in a unified pipeline [22]. In this case, the knowledge during the anomaly detection phase cannot be shared with the localization. We in-\ntegrate these two closely related tasks into a unified framework to provide more hints to system operators.\nSince there exist correlations between metrics of service in modern online service systems, the learned correlations graph between metrics during the anomaly detection phase is useful for localizing the metrics that reveal the cause of the anomaly [24], [46], [47]. It is straightforward to understand that no matter whether the anomaly is a temporal anomaly that happens on some specific metrics or an anomaly due to the contravention of correlation compared with the anomalyfree stage, the correlation between anomalous metrics and others will undergo drastic changes. Particularly based on the above assumption, we can calculate the correlation change as follows:\n\u2206Ai = \u2211 j \u0338=i \u2225Aaij \u2212Anij\u22251 (5)\nwhere \u2206Ai is the variation of correlation between normal and abnormal periods for metric i. The Anij is computed by averaging aij on the training period, while the Aaij is the mean of aij during the anomaly segment. Eventually, RTAnomaly would highlight a few metrics with high \u2206Ai and recommend them to engineers to help them to get fine-grained information on the performance issue and double-check the devices related to these metrics."
        },
        {
            "heading": "F. Positive Unlabeled Learning",
            "text": "As mentioned in Section III-D, unsupervised methods assume that the training data is anomaly-free. However, there are inevitably some unlabeled anomalies that are ignored by engineers. Existing log anomaly detection works like [48] adopt the assumptions that samples with similar features should share the same labels. In our scenario, we only have a small portion of negative data with high confidence, but we don\u2019t have positive data because finding positive from a large number of negative samples is like looking for a needle in the ocean.\nTo tackle this, RTAnomaly tries to find out the anomalous using the idea of positive unlabeled learning (PU earning) [49]. Specifically, as shown in Figure 3, a small amount of negative samples labeled by engineers is utilized for training the model since the cost of manually labeling a small amount of data is not high. In this way, human expertise can be incorporated.\nBased on the trained model, the remaining unlabeled training data can be predicted. Intuitively, the anomalous samples conceal in the training data are hard to be reconstructed with the model trained with labeled negative and thus have a high anomaly score. After obtaining the anomaly score, the samples with an anomaly score that exceeds a pre-defined threshold \u03b2 will be labeled as positive. All the data with pseudo labels are used to update the model. Finally, this updated model will be used to detect performance issues from metrics."
        },
        {
            "heading": "IV. EVALUATION",
            "text": "To fully evaluate the effectiveness of our proposed approaches RTAnomaly, we use both a public dataset and two\nreal-world monitoring metric datasets from online services of company H. Particularly, we aim to answer the following research questions (RQs):\n\u2022 RQ1: How effective is RTAnomaly compared with metric anomaly detection baselines? \u2022 RQ2: How effective is each component of RTAnomaly in anomaly detection? \u2022 RQ3: How effective is RTAnomaly in localizing the anomalous metrics? \u2022 RQ4: How sensitive is RTAnomaly to the parameters?"
        },
        {
            "heading": "A. Datasets",
            "text": "We conduct experiments on a publicly available dataset. To confirm the practical significance of RTAnomaly, we collect two datasets from large-scale online services of Company H. The statistics of the datasets are shown in Table I\nPublic Dataset The public dataset for our experiments is SMD (Server Machine Dataset), which is collected from a large Internet company containing a 5-week-long monitoring metrics of 28 machines [21]. The authors divided the SMD into two subsets of equal size: the first half for the training set and the second half for the testing set. Anomalies in the SMD testing set are labeled by domain experts based on incident reports.\nIndustrial Dataset In order to evaluate the effectiveness of RTAnomaly in production scenarios, we collect metrics Application CPU Usage, Memory Usage, Interface Throughput, and so on from the online service of the company. We collect metrics with a sampling interval of one minute for more than one week from two regions of the company. The anomalies representing the performance issues of the service are labeled by experienced software engineers with incidents associated with the metrics. The monitoring metrics collected from services are interdependent and should be considered jointly to analyze the health status of services. Besides, based on the incident reports, the metrics that are correlated to the performance issues are also labeled by engineers. Using these labels, we can also evaluate the accuracy of metrics localization of RTAnomaly."
        },
        {
            "heading": "B. Experiment Setting",
            "text": "1) Baselines: The following methods are compared to evaluate the effectiveness of RTAnomaly. All the baselines are implemented from the open-sourced codes released by the authors. \u2022 OCSVM [50]. OCSVM is a clustering-based anomaly de-\ntection method that learns the boundary for the normal data points and identifies the data outside the border to be anomalies. \u2022 IForest [51]. Isolation Forest ensembles a number of isolation trees and recursively partition the feature space to detect anomalies. The samples with awfully shorter heights are likely to be anomalies. \u2022 LOF [52]. Local Outlier Factor (LOF) is based on density estimation that calculates the local density deviation of a given sample with respect to its neighbors. The anomalies have a substantially lower density than their neighbors. \u2022 DAGMM [16]. DAGMM is a model that first utilizes an autoencoder to generate a low-dimensional representation for metrics at each timestamp. Then, the representation is fed into a Gaussian Mixture Model to go through a probabilistic estimation to obtain the anomaly score. \u2022 LSTM [12], [30]. LSTM neural network captures the normal behaviors of metrics by forecasting the next values of metrics based on historical observations. Anomalies will be reported if the differences between predicted values and real values exceed a pre-defined threshold \u2022 LSTM-VAE [53]. LSTM-VAE detects anomalies by integrating LSTM and VAE. It projects observations at each timestamp into a latent space and then estimates the distribution of it using VAE. \u2022 OmniAnomaly [21]. OmniAnomaly is a model that captures the normal patterns by learning robust representations of metrics with stochastic Recurrent Neural Network (RNN) and planar normalizing flow. The anomalies are detected based on the reconstruction error. \u2022 THOC [20]. THOC is a model that captures the multiscale temporal features from dilated recurrent layers by a hierarchical clustering mechanism and detects the anomalies by the multi-layer distances. 2) Evaluation Metrics: The anomaly detection problem is modeled as a binary classification problem, so the widelyused binary classification measurements can be applied to evaluate the performance of models. We employ Precision: PC = TPTP+FP , Recall: RC = TP TP+FN , F1 score: F1 =\n2 \u00b7 PC\u00b7RCPC+RC . To be specific, TP is the number of discovered abnormal samples by the model correctly; FP is the number of normal samples that are incorrectly classified as anomalies; FN is the number of anomalous samples that failed to be detected by the model. F1 score is the harmonic mean of the precision and recall, which symmetrically represents both precision and recall in one metric. Following [54], we get the anomaly threshold by grid search for all baselines and RTAnomaly to evaluate the performance.\nIn real-world applications, anomalies will last for a while, leading to consecutive anomalies in the monitoring metrics. Therefore, it is acceptable for the model to trigger an alert for any point in a contiguous anomaly segment if the delay is within the acceptable range. Thus, we adopt the evaluation strategy following [21], [55], [56] that marks the whole segment of continuous anomalies as an anomaly. In other words, we consider the model makes a correct prediction for an anomalous segment if at least one timestamp in the segment is successfully predicted as an anomaly.\n3) Implementations: The implementation of RTAnomaly is publicly available at GitHub 1. We run all the experiments on a Linux server with Intel Xeon Gold 6140 CPU @ 2.30GHZ and Tesla V100 PCIe GPU. The proposed model is implemented under the PyTorch framework and runs on the GPU.\nThe hidden sizes of the GAT layer, GRU layer and temporal convolution layers are 256, 128 and 128. The coefficient of loss function \u03bb is 0.5. The dimension of the latent variable in CVAE is 10. The threshold of positive learning is 0.9. We train RTAnomaly with the Adam optimizer [57] with a learning rate of 0.001, a batch size of 128, and an epoch number of 50."
        },
        {
            "heading": "C. Experimental Results",
            "text": "1) RQ1 The effectiveness of RTAnomaly: To answer this research question, we compare the performance of RTAnomaly with other state-of-the-art baselines on a public dataset and two industrial datasets. First, We train RTAnomaly on a small portion of negative samples. Then, RTAnomaly will assign pseudo labels to the remaining training data according to the anomaly score and threshold \u03b2. During the test phase, the anomaly score for each timestamp will be computed. The anomaly threshold will be searched following [54] to produce the prediction result.\nThe results are shown in Table II, where the best F1 scores are marked with boldface. We can see the average F1 score of RTAnomaly outperforms all baseline methods in three datasets. The experimental results are shown in Table 2. In Dataset B, the improvement achieved by RTAnomaly is more significant as the metrics correlations between metrics in Dataset B are more complicated. Generally speaking, RTAnomaly\u2019s good performance can be attributed to two reasons: First, the utilization of relational-temporal embedding, as the anomalies can be caused by the violation of correlation which can hardly be detected by finding the spikes on a single metric, it can also help facilitate localization of the anomalous\n1https://github.com/ASE-Submission/RTAnomaly\nmetrics; Second, RTAnomaly learns the potential anomalous samples from training data, which can avoid the overfitting to the anomalous pattern during the training process.\nTypically, the baseline methods have higher precision than recall because there are some anomalies that are not very apparent. We can observe that OCSVM, IForest and LOF have relatively low performance compared with other baseline models since these methods learn the metrics pattern at each timestamp independently without considering the temporal dependency. While LSTM-based methods and autoencoderbased methods, including LSTM, DAGMM and LSTM-VAE, perform notably better than OCSVM, IForest and LOF and achieve 0.7094\u223c0.8421 F1 score because these models take the historical observation window of the data, that helps to retain valuable historical temporal pattern. Among the baselines, we can find OmniAnomaly and THOC can achieve comparable accuracy compared with RTAnomaly (like 0.8892) because both OmniAnomaly and THOC introduce some mechanisms to ensure robust anomaly detection. Specifically, OmniAnomaly models the metrics through stochastic variables and uses reconstruction probabilities to determine anomalies. While in THOC, the complex nonlinear temporal dynamics of the system\u2019s normal behavior are captured. Though extracting temporal information well, the limitation of OmniAnomaly and THOC lies in not addressing the feature correlations explicitly, which is essential to successfully detecting anomalies from multivariate metrics.\n2) RQ2 The effectiveness of components in RTAnomaly: To answer this research question, we conduct an extensive ablation study on RTAnomaly. Particularly, we derive two baseline models based on removing the relational-temporal embedding and positive unlabeled learning parts of RTAnomaly to investigate the contribution of these two components.\n\u2022 RTAnomaly w/o RT This baseline removes the relationaltemporal embedding that captures both information of metrics. Instead, only an LSTM layer is utilized in this baseline to embed the raw metrics data that will be further fed into the CVAE. \u2022 RTAnomaly w/o PU This baseline removes the positive unlabeled learning that finds anomalous samples from a large number of normal samples. All the training data are considered normal in this baseline.\nTable III shows the experimental results of RTAnomaly\nand its variants. Overall, relational-temporal embedding and positive unlabeled learning help to improve the effectiveness of RTAnomaly as it performs the best, while the degree of contribution of relational temporal embedding is larger. We attribute this to the good capability of relational temporal embedding in extracting both the temporal information of each metric and correlational information between metrics. When an anomaly happens due to a breach of relationship during the anomaly-free period, it can be easily identified by RTAnomaly, while other methods have difficulty identifying it as they are more effective on temporal outliers.\nThe variant without relational-temporal embedding is similar to LSTM-VAE, which employs LSTM to extract the sequential information and VAE to differentiate the anomaly from normal. However, due to the design of positive unlabeled learning and conditional VAE, the variant can identify the noise of training data and label them as positive. Thus, the performances on three datasets of RTAnomaly without relational-temporal embedding in terms of F1 score have increased by 6.51%, 10.11% and 14.75% compared to LSTMVAE, respectively. We believe that in some scenarios with a higher ratio of noise, positive unlabeled learning would play a greater role in improving performance.\n3) RQ3 The effectiveness of RTAnomaly in localizing the anomalous metrics: To further demonstrate the capability of RTAnomaly, experiments on localizing the metrics are conducted. Specifically, we localize the metrics by three methods: \u2022 Anomaly score This method purely uses the anomaly score\nof each metric as the degree of being the root cause of the performance issue. Several metrics with the highest scores will be highlighted as anomalous metrics. \u2022 Correlation score This method sums up the correlation of a specific metric between other metrics as the degree of being the root cause. Metrics with the highest correlation with other metrics will be recommended. \u2022 Correlation Change Different from simply using the correlation between metrics, using the discrepancy between anomaly-free period and anomaly period is more rational because the correlation between metrics may undergo drastic changes compared to the normal period when an anomaly happens on some specific metrics. As mentioned in Section II, a metric that shows very abnormal behaviors compared to the normal period is not\nnecessarily the root cause because it can have a small influence on other metrics and will self-heal. As for merely using correlation scores, it can cause inaccurate results because some metrics show consistently high correlations with others, no matter whether it is during an anomaly period or not. In other words, metrics like the throughput of a device may have a strong correlation with the resource usage of some gateways. Indeed, the correlation difference between normal and abnormal time is a stronger indicator of anomalous metrics because when an anomaly happens, the correlation would be obeyed and cause a huge correlation change.\nTable IV presents the comparison of three methods, and we can observe that metrics localization with correlation change performs better than the other two methods achieving a Hit@1 of 80.95%, 83.87% and Hit@3 of 90.48%, 93.54% on two industrial datasets. The Hit@1 of correlation change is even higher than the Hit@3 of the correlation score. Thus, our method can provide accurate hints for engineers on which part of the service system they can remedy to ensure the system\u2019s reliability. Compared to using the anomaly score, using the correlation score is more effective as the anomaly score is computed on a single metric and is not aware of other metrics, while correlation considers the global information of metrics. Usually, the metrics that have a higher correlation with other metrics seem to play a greater influence on the service system and are more likely to be the root cause of an anomaly, which is another reason that correlation performs better than anomaly score.\n4) RQ4 The sensitivity of RTAnomaly to the parameters: The pre-determined threshold \u03b2, i.e., the threshold that determines the label of training data during positive unlabeled learning, may affect the performance by affecting the label distribution of training samples. We hereon evaluate the sensitivity of RTAnomaly to this hyper-parameter on three datasets. We change the value of \u03b2 while keeping all other parameters unchanged to guarantee fairness. Specifically, for the three datasets, we select the value of \u03b2 ranging from 0.6 to 1 at a step of 0.1. When the value of \u03b2 is 1, it is equivalent to the variant without positive unlabeled learning since all the samples have an anomaly score lower than 1, and all samples\nwill be seen as normal. When the value of \u03b2 is lower than 0.5, a large portion of samples will be labeled as anomalous and introduce severe noise to training data, which is not the case in the real scenario.\nFigure 4 presents the experimental results of RQ4. On the one hand, the F1 score of RTAnomaly is stable under different values of \u03b2 at the interval between 0.6 to 1.0, which means that the performance does not rely heavily on the selection of threshold during positive unlabeled learning. On the other hand, a good threshold indeed helps improve the accuracy of our model. In dataset A, the best threshold is between 0.7 to 0.8, while in dataset B, the best threshold is between 0.8 to 0.9. This is because the anomaly ratio of Dataset B is slightly lower than Dataset A, so a lower amount of unlabeled anomalous samples exist in the training part. Similarly, as the anomaly ratio of SMD is the lowest (around 2%), the best threshold is between 0.9 to 1. Compared to without positive unlabeled learning, a properly selected threshold would improve the recall because some abnormal behaviors have been labeled as positive, and these abnormal patterns would be reported in the testing set and thus reduce the false negative."
        },
        {
            "heading": "V. DISCUSSION",
            "text": "In this section, we share the success story of our deployment of RTAnomaly on the industrial environment of the service system of Company H. Some possible threats to validity are also shown."
        },
        {
            "heading": "A. Success Story",
            "text": "RTAnomaly has been successfully incorporated into the performance issue detection system of a large-scale online service system in Company H. Particularly, the troubleshooting system continuously collects the monitoring metrics and detects performance anomalies in run-time. Alerts will be triggered immediately and sent to the on-call operations engineers when an anomaly has been detected by RTAnomaly. The results of RTAnomaly provide not only the time a performance issue happens but also the specific metrics that are most related to this issue, which can guide the on-site engineers to alleviate the performance issue. Positive feedback has been received from the on-site engineers. Particularly, engineers confirmed its superiority in accurate anomaly detection and root cause localization of metrics that traditional methods cannot achieve. RTAnomaly has been a powerful part of the troubleshooting system that reports when and where the performance issues occur automatically and timely."
        },
        {
            "heading": "B. Threats to Validity",
            "text": "Internal threats. The correctness of the implementation of baselines constitutes one of the internal threats to our study\u2019s validity. For the baselines, we utilized the open-sourced code released by the authors of the papers or packages on GitHub like [58]. As for our proposed approach, the source code has been reviewed meticulously by the authors, as well as several experienced software engineers, to minimize the risk of errors and increase the overall confidence in our results. For parameter selection, we conducted extensive experiments with different parameters, systematically exploring the parameter space to find the most suitable configurations. We chose the parameters based on the best results obtained in these experiments. To make our results reproducible, we have also made our code and partial data available.\nExternal threats. The external threats to the validity of our study mainly lie in the generalizability of our experimental results. We conduct experiments on the large-scale online systems of two regions within a prominent cloud service company. In addition to this, our approach is also evaluated on a publicly available dataset containing monitoring metrics of server machines from an Internet company, further expanding the scope of our evaluation. While the diversity of the experimental settings provides some confidence in the generality of our findings, it is essential to acknowledge that results might vary when applied to different cloud service providers, industries, or specific use cases. Nevertheless, we believe that our experimental results, obtained from these multiple sources, can demonstrate the generality and effectiveness of our proposed approach, RTAnomaly."
        },
        {
            "heading": "VI. RELATED WORK",
            "text": "Detecting performance issues on monitoring metrics for online service systems has been a hot topic. Monitoring metrics used to reflect the run-time status of the whole system are usually denoted as multivariate time series. The main challenge of multivariate metrics anomaly detection is two folds: First, effective modeling of complex relational and temporal dependency. Second, noise data will be introduced inevitably during the manual labeling process. It is hard to get rid of these noises. Related studies can be categorized into traditional machine learning-based and deep learning-based approaches.\nTraditional Machine Learning Methods OCSVM [50] is a clustering-based method that learns the boundary for the normal data without anomalous samples and identifies the data outside the border as anomalies. Isolation Forest (iForest) [51] applies multiple isolation trees and ensembles them based on the assumption that anomalies should be rare and isolated from normal observations with very short heights. Local Outlier Factor (LOF) is a density estimation-based anomaly detection approach that calculates the local density. The samples with an extremely lower density compared to their neighbors would be recognized as anomalies.\nDeep Learning Based Methods Recently, there has been a variety of studies in applying deep learning to conduct anomaly detection on multivariate metrics data. A deep autoencoder with a Gaussian mixture model (DAGMM) to detect anomalous data points from observation at each timestamp has been proposed [16]. However, it does not consider the temporal dependencies in historical values of metrics. In order to detect performance degradation anomalies in software systems, Long Short-Term Memory (LSTM) has been deployed to guarantee high performance in [12]. Similarly, LSTM-NDT [30] leverages Long Short-Term Memory (LSTM) networks with non-parametric dynamic thresholds to pursue the reliability of the systems. LSTM-VAE [53] combines the LSTM networks and the VAE to reconstruct the distribution of observed sliding windows from multivariate metrics. However, LSTMVAE ignores the temporal dependencies in time series [23]. OmniAnomaly [21] extends the LSTM-VAE with a normalizing flow and utilizes the reconstruction error for detection. However, the capability of this approach is degraded when they encounter severe noise in training metrics. THOC is a model that [20] fuses the temporal features at multi-scale from intermediate layers by hierarchical clustering and detects the anomalies by the multi-layer distances loss.\nHowever, the aforementioned machine learning-based and deep learning-based methods have not taken both the temporal dependencies and relational dependencies into consideration. Besides, the performance of these models will degrade due to the existence of unlabeled noise in training data."
        },
        {
            "heading": "VII. CONCLUSION",
            "text": "In this work, we propose RTAnomaly, a novel framework to mine correlations among metrics, detect performance issues,\nand localize the correlation-violation metrics. Specifically, RTAnomaly leverages a graph neural network with graph attention to capture the complex correlations between a variety of metrics and a label-conditional VAE model to distinguish normal and abnormal patterns. We also propose to utilize the positive unlabeled learning strategy to overcome the impacts of noisy data. Extensive experiments on one public dataset and two industrial datasets show that RTAnomaly achieves 0.929 F1-Score on anomaly detection and 0.920 Hit@3 in terms of localizing correlation-violation metrics, outperforming all the baselines. Both the codes and data are released to facilitate future research."
        }
    ],
    "title": "Performance Issue Identification in Cloud Systems with Relational-Temporal Anomaly Detection",
    "year": 2023
}