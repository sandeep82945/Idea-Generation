{
    "abstractText": "Large language models (LLMs) such as ChatGPT have sparked extensive discourse within the medical education community, spurring both excitement and apprehension. Written from the perspective of medical students, this editorial offers insights gleaned through immersive interactions with ChatGPT, contextualized by ongoing research into the imminent role of LLMs in health care. Three distinct positive use cases for ChatGPT were identified: facilitating differential diagnosis brainstorming, providing interactive practice cases, and aiding in multiple-choice question review. These use cases can effectively help students learn foundational medical knowledge during the preclinical curriculum while reinforcing the learning of core Entrustable Professional Activities. Simultaneously, we highlight key limitations of LLMs in medical education, including their insufficient ability to teach the integration of contextual and external information, comprehend sensory and nonverbal cues, cultivate rapport and interpersonal interaction, and align with overarching medical education and patient care goals. Through interacting with LLMs to augment learning during medical school, students can gain an understanding of their strengths and weaknesses. This understanding will be pivotal as we navigate a health care landscape increasingly intertwined with LLMs and artificial intelligence. (JMIR Med Educ 2023;9:e50945) doi: 10.2196/50945",
    "authors": [
        {
            "affiliations": [],
            "name": "Conrad W Safranek"
        },
        {
            "affiliations": [],
            "name": "Anne Elizabeth Sidamon-Eristoff"
        },
        {
            "affiliations": [],
            "name": "BA; Aidan Gilson"
        },
        {
            "affiliations": [],
            "name": "David Chartash"
        }
    ],
    "id": "SP:ff0fc2e75bc407c56d009a12e35443226fa7d296",
    "references": [
        {
            "authors": [
                "T Brants",
                "AC Popat",
                "P Xu",
                "FJ Och",
                "J. Dean"
            ],
            "title": "Large language models in machine translation",
            "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
            "year": 2007
        },
        {
            "authors": [
                "S Singh",
                "A. Mahmood"
            ],
            "title": "The NLP cookbook: modern recipes for transformer based deep learning architectures",
            "venue": "IEEE Access",
            "year": 2021
        },
        {
            "authors": [
                "L Ouyang",
                "J Wu",
                "X Jiang",
                "D Almeida",
                "C Wainwright",
                "P Mishkin",
                "In et al. Training language models to follow instructions with human feedback."
            ],
            "title": "Koyejo S, Mohamed S, Agarwal A, Belgrave D, Cho K, Oh A, editors",
            "venue": "Advances in Neural Information Processing Systems 35",
            "year": 2022
        },
        {
            "authors": [
                "Hirschberg J",
                "Manning CD"
            ],
            "title": "Advances in natural language processing",
            "venue": "Science 2015 Jul",
            "year": 2015
        },
        {
            "authors": [
                "G. Eysenbach"
            ],
            "title": "The role of ChatGPT, generative language models, and artificial intelligence in medical education: a conversation with ChatGPT and a call for papers",
            "venue": "JMIR Med Educ 2023 Mar 06;9:e46885 [FREE Full text]",
            "year": 2023
        },
        {
            "authors": [
                "H. Lee"
            ],
            "title": "The rise of ChatGPT: exploring its potential in medical education",
            "venue": "Anat Sci Educ 2023 Mar 14:1 [doi: 10.1002/ase.2270]",
            "year": 2023
        },
        {
            "authors": [
                "VW Xue",
                "P Lei",
                "WC. Cho"
            ],
            "title": "The potential impact of ChatGPT in clinical and translational medicine",
            "venue": "Clin Transl Med",
            "year": 2023
        },
        {
            "authors": [
                "P Lee",
                "S Bubeck",
                "J. Petro"
            ],
            "title": "Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine",
            "venue": "N Engl J Med",
            "year": 2023
        },
        {
            "authors": [
                "P. Olson"
            ],
            "title": "ChatGPT needs to go to college. Will OpenAI pay",
            "venue": "URL: https://www. washingtonpost.com/business/2023/06/05/chatgpt-needs-better-training-data-will-openai-and-google-pay-up-for-it/ f316828c-035d-11ee-b74a-5bdd335d4fa2_story.html",
            "year": 2023
        },
        {
            "authors": [
                "K. Barr"
            ],
            "title": "GPT-4 is a giant black box and its training data remains a mystery",
            "venue": "Gizmodo. 2023 Mar 16. URL: https://gizmodo",
            "year": 2023
        },
        {
            "authors": [
                "M. Sallam"
            ],
            "title": "ChatGPT utility in healthcare education, research, and practice: systematic review on the promising perspectives and valid concerns. Healthcare (Basel) 2023 Mar 19;11(6):887 [FREE Full text] [doi: 10.3390/healthcare11060887] [Medline",
            "year": 2023
        },
        {
            "authors": [
                "L Farrell",
                "G Bourgeois-Law",
                "G Regehr",
                "R. Ajjawi"
            ],
            "title": "Autoethnography: introducing 'I' into medical education research",
            "venue": "Med Educ",
            "year": 2015
        },
        {
            "authors": [
                "M Wijnen-Meijer",
                "W Burdick",
                "L Alofs",
                "C Burgers",
                "O. ten Cate"
            ],
            "title": "Stages and transitions in medical education around the world: clarifying structures and terminology",
            "venue": "Med Teach",
            "year": 2013
        },
        {
            "authors": [
                "K Singhal",
                "S Azizi",
                "T Tu",
                "SS Mahdavi",
                "J Wei",
                "HW Chung"
            ],
            "title": "Large language models encode clinical knowledge",
            "venue": "arXiv. Preprint posted online on December",
            "year": 2022
        },
        {
            "authors": [
                "G Xu",
                "W Rong",
                "Y Wang",
                "Y Ouyang",
                "Z. Xiong"
            ],
            "title": "External features enriched model for biomedical question answering",
            "venue": "BMC Bioinformatics",
            "year": 2021
        },
        {
            "authors": [
                "PM Nadkarni",
                "L Ohno-Machado",
                "WW. Chapman"
            ],
            "title": "Natural language processing: an introduction",
            "venue": "J Am Med Inform Assoc",
            "year": 2011
        },
        {
            "authors": [
                "D Johnson",
                "R Goodman",
                "J Patrinely",
                "C Stone",
                "E Zimmerman",
                "R Donald"
            ],
            "title": "Assessing the accuracy and reliability of AI-generated medical responses: an evaluation of the Chat-GPT model",
            "venue": "Res Square. Preprint posted online on February",
            "year": 2023
        },
        {
            "authors": [
                "A Gilson",
                "CW Safranek",
                "T Huang",
                "V Socrates",
                "L Chi",
                "RA Taylor"
            ],
            "title": "How does ChatGPT perform on the United States Medical Licensing Examination? The implications of large language models for medical education and knowledge assessment",
            "venue": "JMIR Med Educ 2023 Feb 08;9:e45312 [FREE Full text]",
            "year": 2023
        },
        {
            "authors": [
                "TH Kung",
                "M Cheatham",
                "A Medenilla",
                "C Sillos",
                "L De Leon",
                "C Elepa\u00f1o"
            ],
            "title": "Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models. PLOS Digit Health 2023 Feb;2(2):e0000198 [FREE Full text] [doi: 10.1371/journal.pdig.0000198] [Medline",
            "year": 2023
        },
        {
            "authors": [
                "H Nori",
                "N King",
                "SM McKinney",
                "D Carignan",
                "E. Horvitz"
            ],
            "title": "Capabilities of GPT-4 on medical challenge problems",
            "venue": "arXiv. Preprint posted online on March 20,",
            "year": 2023
        },
        {
            "authors": [
                "P Hrynchak",
                "H. Batty"
            ],
            "title": "The educational theory basis of team-based learning",
            "venue": "Med Teach",
            "year": 2012
        },
        {
            "authors": [
                "B Charlin",
                "L Roy",
                "C Brailovsky",
                "F Goulet",
                "C. van der Vleuten"
            ],
            "title": "The Script Concordance test: a tool to assess the reflective clinician",
            "venue": "Teach Learn Med",
            "year": 2000
        },
        {
            "authors": [
                "P. Croskerry"
            ],
            "title": "Achieving quality in clinical decision making: cognitive strategies and detection of bias",
            "venue": "Acad Emerg Med",
            "year": 2002
        },
        {
            "authors": [
                "E Jones",
                "J. Steinhardt"
            ],
            "title": "Capturing failures of large language models via human cognitive biases",
            "venue": "arXiv. Preprint posted online on February",
            "year": 2022
        },
        {
            "authors": [
                "Kost A",
                "Chen FM"
            ],
            "title": "Socrates was not a pimp: changing the paradigm of questioning in medical education",
            "venue": "Acad Med",
            "year": 2015
        },
        {
            "authors": [
                "W Hersh",
                "J. Ehrenfeld"
            ],
            "title": "Clinical informatics",
            "venue": "Skochelak SE, editor. Health Systems Science. 2nd Edition. Amsterdam, The Netherlands: Elsevier; May",
            "year": 2020
        },
        {
            "authors": [
                "R. Asher"
            ],
            "title": "Clinical sense. The use of the five senses",
            "venue": "Br Med J 1960 Apr",
            "year": 1960
        },
        {
            "authors": [
                "N Talley",
                "S. O'Connor"
            ],
            "title": "Clinical Examination: A Systematic Guide to Physical Diagnosis",
            "year": 2014
        },
        {
            "authors": [
                "A Martin",
                "I Weller",
                "D Amsalem",
                "R Duvivier",
                "D Jaarsma",
                "MA. de Carvalho Filho"
            ],
            "title": "Co-constructive patient simulation: a learner-centered method to enhance communication and reflection skills. Simul Healthc 2021 Dec 01;16(6):e129-e135 [FREE Full text] [doi: 10.1097/SIH.0000000000000528] [Medline",
            "year": 2021
        },
        {
            "authors": [
                "K. Adams"
            ],
            "title": "Epic to integrate GPT-4 into its EHR through expanded Microsoft partnership",
            "venue": "MedCity News. 2023",
            "year": 2023
        },
        {
            "authors": [
                "H. Landi"
            ],
            "title": "Doximity rolls out beta version of ChatGPT tool for docs aiming to streamline administrative paperwork",
            "venue": "Fierce Healthcare",
            "year": 2023
        },
        {
            "authors": [
                "H. Landi"
            ],
            "title": "Microsoft's Nuance integrates OpenAI's GPT-4 into voice-enabled medical scribe software",
            "venue": "Fierce Healthcare",
            "year": 2023
        },
        {
            "authors": [
                "D Chartash",
                "M Rosenman",
                "K Wang",
                "E. Chen"
            ],
            "title": "Informatics in undergraduate medical education: analysis of competency frameworks and practices across North America",
            "venue": "JMIR Med Educ 2022 Sep 13;8(3):e39794 [FREE Full text]",
            "year": 2022
        },
        {
            "authors": [
                "WR Hersh",
                "PN Gorman",
                "FE Biagioli",
                "V Mohan",
                "JA Gold",
                "GC. Mejicano"
            ],
            "title": "Beyond information retrieval and electronic health record use: competencies in clinical informatics for medical education",
            "venue": "Adv Med Educ Pract",
            "year": 2014
        },
        {
            "authors": [
                "K Paranjape",
                "M Schinkel",
                "R Nannan Panday",
                "J Car",
                "P. Nanayakkara"
            ],
            "title": "Introducing artificial intelligence training in medical education",
            "venue": "JMIR Med Educ",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Large language models (LLMs) such as ChatGPT have sparked extensive discourse within the medical education community, spurring both excitement and apprehension. Written from the perspective of medical students, this editorial offers insights gleaned through immersive interactions with ChatGPT, contextualized by ongoing research into the imminent role of LLMs in health care. Three distinct positive use cases for ChatGPT were identified: facilitating differential diagnosis brainstorming, providing interactive practice cases, and aiding in multiple-choice question review. These use cases can effectively help students learn foundational medical knowledge during the preclinical curriculum while reinforcing the learning of core Entrustable Professional Activities. Simultaneously, we highlight key limitations of LLMs in medical education, including their insufficient ability to teach the integration of contextual and external information, comprehend sensory and nonverbal cues, cultivate rapport and interpersonal interaction, and align with overarching medical education and patient care goals. Through interacting with LLMs to augment learning during medical school, students can gain an understanding of their strengths and weaknesses. This understanding will be pivotal as we navigate a health care landscape increasingly intertwined with LLMs and artificial intelligence.\n(JMIR Med Educ 2023;9:e50945) doi: 10.2196/50945"
        },
        {
            "heading": "KEYWORDS",
            "text": "large language models; ChatGPT; medical education; LLM; artificial intelligence in health care; AI; autoethnography"
        },
        {
            "heading": "Background on Large Language Models",
            "text": "Artificial intelligence has consistently proven itself to be a transformative force across various sectors, with the medical field being no exception. A recent advancement in this sphere is large language models (LLMs) such as OpenAI\u2019s ChatGPT and its more recent model, GPT-4 [1]. Fundamentally, LLMs leverage deep neural networks\u2014complex structures with multiple layers of statistical correlation, or \u201chidden layers\u201d\u2014that facilitate nuanced, complex relations and advanced information abstraction [2]. The breakthrough of ChatGPT represents the convergence of two significant advancements in computer science: scaled advancement of the processing power of LLMs and the implementation of real-time reinforcement learning with human feedback [3-5]. As a result, computers can now\nhandle vast volumes of training data and generate models with billions of parameters that exhibit advanced humanlike language performance.\nSignificant constraints accompany the use of LLMs. These include their sporadic propensity to concoct fictitious information, a phenomenon aptly named \u201challucinating,\u201d as well as their unpredictable sensitivity to the structure of user input \u201cprompting\u201d [6-8]. Additionally, both ChatGPT and GPT-4 were not trained on data sourced past 2021 and largely do not have access to information behind paywalls [9,10]. As the training was proprietary, it is challenging to model a priori bias and error within the model [11,12]. Deducing these vulnerabilities and understanding how they influence model output is important for the accurate use of LLMs.\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 1https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX\nSince ChatGPT\u2019s release in November 2022, LLMs\u2019 potential role in medical education and clinical practice has sparked significant discussion. Educators have considered ChatGPT\u2019s capacity for studying assistance, medical training, and clinical decision-making [6,7,13]. More specifically, ChatGPT has been suggested for generating simulated patient cases and didactic assessments to supplement traditional medical education [6].\nUsing an autoethnographic framework [14], we aim to address these potential use cases from the perspective of medical students in the preclinical phase (authors CWS and AESE) and clinical phase (authors AG and DC) of basic medical education. Since its release, we have integrated ChatGPT into our daily academic workflow while simultaneously engaging with research regarding LLMs\u2019 impact on medical education and health care. Throughout this process, we have continuously had reflective conversations with peers, mentors, and faculty regarding the metacognitive use of LLMs in medical education. In this editorial, we first discuss the performance of LLMs on medical knowledge and reasoning tasks representative of basic medical education [15,16]. We then delve into specific use cases of ChatGPT in medical education that have emerged through a reflective, iterative, and evaluative investigation. Building upon this basis and reflecting on the current state of LLM capabilities and use in basic medical education, we additionally examine the potential for such technology to influence future physicians in training and practice."
        },
        {
            "heading": "Understanding the Scope of LLMs\u2019 Performance on Medical Knowledge Tasks",
            "text": "The capacity of LLMs to model the semantics of medical information encoded in the clinical sublanguage has shown potential for medical question-answering tasks [17-19]. A vanguard of this technology is ChatGPT, which has demonstrated promise beyond specific medical question-answering tasks, responding to questions in domains such as knowledge retrieval, clinical decision support, and patient triage [20]. As ChatGPT\u2019s training data is proprietary, it is difficult to examine the medical knowledge to which the model was exposed.\nRecent research using multiple-choice questions sourced from the United States Medical Licensing Exam (USMLE) as a proxy for medical knowledge found that ChatGPT could approximate the performance of a third-year medical student [21,22]. Beyond question-answering, ChatGPT consistently provided narratively coherent answers with logical flow, integrating internal and external information from the question [21]. GPT-4, the successor of ChatGPT, has demonstrated performance\nsuperiority with an accuracy >80% across all three steps of the examination [23]. The demonstrated capacity of ChatGPT to construct coherent and typically accurate responses on medical knowledge and reasoning tasks has opened new avenues for exploration within medical education. Recognition of this opportunity served as the impetus for this study, aiming to critically interrogate the potential role of LLMs as an interactive instrument in medical education."
        },
        {
            "heading": "Use Cases for ChatGPT in Medical Education",
            "text": "The following use cases are those that demonstrated particular value while experimenting with the integration of ChatGPT into the daily routine of medical school studies."
        },
        {
            "heading": "Differential Diagnoses: Use Case 1",
            "text": "ChatGPT can be used to generate a list of differential diagnoses given the presentation of signs and symptoms by students (Figure 1). During learning, students often focus on a single domain of medicine, whereas ChatGPT is not constrained and may include diseases not yet learned or not part of the student\u2019s focused material in a current or recent curricular unit. ChatGPT can therefore facilitate students\u2019 development of a holistic, integrated understanding of differential diagnosis and pathophysiology, key learning objectives of preclinical education. From experience, ChatGPT often provides clinical logic to link signs and symptoms with each differential diagnosis, reinforcing student learning objectives.\nGiven ChatGPT\u2019s dialogic interface, students can also ask follow-up questions. We have found that ChatGPT is strong at explaining and contextualizing the underlying biology and pathophysiology, and helps facilitate a more in-depth understanding of both pathophysiology and clinical logic expected during clinical presentation. Follow-up questions can simulate the narrowing or broadening of a differential diagnosis as new information is added in the form of further history, physical exam, and laboratory or imaging investigations. Such use of a dialogic interface supports students in developing a simulated proficiency of the core Entrustable Professional Activities (EPAs) expected prior to the transition to residency [24,25]. For instance, students can refine their understanding of how to \u201cprioritize a differential diagnosis\u201d (EPA 2), \u201cgather a history and perform a physical examination\u201d (EPA 1), and \u201crecommend...common diagnostic and screening tests\u201d (EPA 3). The ubiquitously available ChatGPT can augment the preclinical learning of clinical skills even when patients and professors are unavailable, fundamentally advancing students\u2019 self-directed learning.\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 2https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX"
        },
        {
            "heading": "Interactive Practice Cases: Use Case 2",
            "text": "Simulating clinical cases fosters the application of pathophysiological frameworks learned in lectures and supports clinical skills such as history-taking and physical examination interpretation. With the implementation of explicit prompt engineering [26], students can enter into a dialogic, interactive case with ChatGPT playing the role of a simulated patient or medical professor (Figure 2). Unlike in static clinical cases from textbooks, ChatGPT\u2019s interactive nature allows students to clarify or expand information presented dynamically. This form of constructivist, active learning emphasizes the importance of interaction and hands-on engagement for deeper, more durable knowledge acquisition [27]. Additionally, manipulating the case by adding or subtracting information supports a mode of inquiry similar to the script concordance test, a tool used for teaching and evaluating medical reasoning in ambiguous clinical scenarios [28].\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 3https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX"
        },
        {
            "heading": "Multiple-Choice Review: Use Case 3",
            "text": "To enhance assessment review, ChatGPT can assist students by offering supplementary explanations when reviewing multiple-choice questions (Figure 3). Providing multiple-choice questions to ChatGPT when the student is unaware of the correct answer poses some risk, as ChatGPT may \u201challucinate\u201d an incorrect answer. However, by having the student verify the model\u2019s responses against the official answer key, protecting against hallucinations, the student can deepen their comprehension of the question and the defensible rationale. Follow-up questions can prompt ChatGPT to clarify concepts or terminology or to explain why alternative answers are incorrect.\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 4https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX"
        },
        {
            "heading": "Definitive Answer to Ambiguous Question: Negative Use Case",
            "text": "If misused, LLMs can present challenges to the learning process. For example, when ChatGPT is presented with a scenario designed to clarify ambiguity (eg, a patient presentation that could be interpreted as either atypical bacterial or viral pneumonia), the user\u2019s prompt for the single statistically most likely diagnosis challenges ChatGPT\u2019s clinical reasoning and knowledge of relative risk (Figure 4).\nIn its response, ChatGPT misinterprets and overemphasizes the potential for bird exposure during a recent zoo visit. ChatGPT\u2019s response fails to unpack the clinical context in which the bird exposure detail came to light. The uncertain information obtained from the patient may not signal a significant bird encounter but likely reflects the inability to definitively rule out such an exposure. ChatGPT\u2019s response misses this nuance and gives undue weight to the ambiguous exposure (representative of the cognitive bias of anchoring) [29,30]. Overall, this case\nis an example of a classic teaching point: \u201cAn atypical presentation of a common disease is often more likely than a typical presentation of a rare disease.\u201d ChatGPT\u2019s error also exemplifies how standardized testing material available on the web\u2014what we assume ChatGPT is trained upon\u2014is likely to overemphasize less common diseases to evaluate the breadth of medical knowledge. Thus, anchoring may be a result of the difference in the training set\u2019s prevalence of psittacosis, where there are many cases of parrot exposure leading to infection in questions as opposed to the real-world incidence of the disease.\nThis case is included as a negative use case not because ChatGPT provides incorrect information but rather because the student is misusing ChatGPT. Responsible student users of LLMs should understand the propensity of the LLM to overweight information likely to be tested more frequently than their prevalence in the population. Asking ChatGPT for a singular definitive answer, therefore, makes the student vulnerable to incorrect answers resulting from biases encoded within the model.\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 5https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX"
        },
        {
            "heading": "Use Cases: Beyond",
            "text": "ChatGPT can be used in myriad other ways to augment medical education (Figure 5). The breadth of options is only beginning to be realized, and as medical students begin to creatively integrate LLMs into their study routines, the list will continue to grow. During this integration process, it is important to minimize the risk of hallucinations by being deliberate with the type of questions posed. Across our experimentation, ChatGPT was generally strong at brainstorming-related questions and generative information seeking (eg, Differential Diagnoses: Use Case 1 section). In contrast, forcing ChatGPT to pick a single \u201cbest\u201d choice between ambiguous options can potentially lead\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 6https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX\nto convincing misinformation (eg, Definitive Answer to Ambiguous Question: Negative Use Case section).\nThe following analogy emerged as a helpful framework for conceptualizing the relationship between ChatGPT and misinformation: ChatGPT is to a doctor as a calculator is to a mathematician. Whether a calculator only produces the correct answer to a mathematical problem is contingent upon whether the inputs it is fed are complete and correct; performing correct computation does not necessarily imply correctly solving a problem. Similarly, ChatGPT may produce a plausible string of text that is misinformation if incorrect or incomplete information were provided to it either in training or by the user interacting with it. Therefore, responsible use of these tools does not forgo reasoning and should not attribute an output as a definitive source of truth.\nThe responsible use of LLMs in medical education is not set in stone. A more comprehensive list of LLM best practices for medical education will be refined as students and professors continue to implement and reflect upon these tools. The following key considerations emerged from our work. First, it is crucial to validate ChatGPT\u2019s outputs with reputable resources, as it aids learning and can prompt critical thinking but does not replace established authorities. Second, much like the advice given to clinical preceptors [31], the framing of inquiries should favor open-ended generative questions over binary or definitive ones to foster productive discussion and avoid misleading responses. Third, understanding the scope and limitations of LLMs\u2019 training data sets is a key step in guarding against possible biases embedded within these models. Finally, incorporating structured training on artificial intelligence into the medical curriculum can empower students to further discern optimal use cases and understand potential pitfalls [32]. Attention to these practices while implementing and reflecting will support the responsible and effective use of LLMs, ultimately enhancing medical education."
        },
        {
            "heading": "Limitations of LLMs for Medical Education",
            "text": ""
        },
        {
            "heading": "Overview",
            "text": "Artificial intelligence, for all its merits, is not currently a substitute for human intuition and clinical acumen. While LLMs can exhibit profound capability in providing detailed medical knowledge, generating differential diagnoses, and even simulating patient interactions, they are not without their shortcomings. It is crucial to remember that these are artificial systems. They do not possess human cognition or intuition, their algorithms operate within predefined bounds, and they base their outputs on patterns identified from the prompt provided\nand training data. This section explores key areas where ChatGPT falls short for medical education, particularly with regard to fully mirroring the depth and breadth of human medical practice."
        },
        {
            "heading": "Integration of Contextual and External Information",
            "text": "As shown by studies to date, ChatGPT has difficulty using external and contextual information. For instance, prior to 2020, COVID-19 may not have been high on a differential for signs of the common cold, highlighting the importance of contextual medical knowledge. This shortcoming is compounded by the fact that ChatGPT lacks the contextual local understanding that medical students and physicians implicitly deploy while\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 7https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX\nworking. For example, within the Yale New Haven Health System, certain centers are magnets for complex cases, leading to a higher prevalence of rare diseases (and altering differential diagnoses). Lacking this understanding limits ChatGPT\u2019s ability to generate contextually accurate differentials. While descriptive prompting may alter ChatGPT\u2019s performance to brainstorm differentials more aptly, it is not feasible to comprehensively capture the complex environment inherent in the practice of medicine. When including only a partial snapshot of the true context in our prompt, for example, mentioning that we are a student working on a differential at a large referral center for complex cases, ChatGPT tends to overweight these isolated details (similar to case presentation in Figure 4).\nIn addition to the challenges of providing full contextual information when querying ChatGPT, it is equally concerning that the model typically does not seek further clarification. OpenAI acknowledges that ChatGPT fails in this sense:\nIdeally, the model would ask clarifying questions when the user provided an ambiguous query. Instead, our current models usually guess what the user intended [1]\nThis harkens back to the analogy of ChatGPT as a calculator for doctors, the importance of the user\u2019s inputs, and the critical lens that must be applied to ChatGPT\u2019s responses."
        },
        {
            "heading": "Sensory and Nonverbal Cues",
            "text": "A physician\u2019s ability to integrate multiple sensory inputs is indispensable. A patient visit is never textual or verbal information alone; it is intertwined with auditory, visual, somatic, and even olfactory stimuli. For instance, in a case of diabetic ketoacidosis, the diagnosis potentially lies at a convergence of stimuli beyond just words\u2014hearing a patient\u2019s rapid deep \u201cKussmaul\u201d breathing, feeling dehydration in a patient\u2019s skin turgor, and smelling the scent of acetone on a patient\u2019s breath. The human brain must use multimodal integration of sensory and spoken information in a way that language models inherently cannot replicate with text alone. Such practical elements of \u201cclinical sense\u201d are impossible to truly learn or convey within a text-only framework [33].\nThe significance of patient demeanor and nonverbal communication can additionally not be underestimated. Translating symptoms into medical terminology is beyond simple translation; often patients describe symptoms in unique, unexpected ways, and learning to interpret this is part of comprehending and using clinical sublanguage. Moreover, a physician\u2019s intuitive sense of a patient appearing \u201csick\u201d can guide a differential diagnosis before a single word is exchanged. ChatGPT lacks this first step in the physical exam (\u201cinspection from the foot of the bed\u201d [34]) and, thus, is hindered in its use of translated and transcribed medical terminology input by the user."
        },
        {
            "heading": "Rapport and Interpersonal Interaction",
            "text": "A crucial facet of the medical practice lies in the art of establishing rapport and managing interpersonal interactions with human patients, which simulation via LLMs has difficulty replicating and thus cannot effectively teach to medical students [35]. Real-world patient interactions require a nuanced\nunderstanding of emotional subtleties, contextual hints, and cultural norms, all paramount in fostering trust and facilitating open dialogue. For instance, how should a health care provider approach sensitive topics such as illicit drug use? ChatGPT is able to answer this question surprisingly well, emphasizing the importance of establishing rapport, showing empathy, and approaching the patient gently. However, reading those phrases is far different from observing such an interaction in person, let alone navigating the conversation with a patient yourself.\nA firsthand experience underscores the importance of emotional and situational awareness in a higher fidelity simulation than is possible with ChatGPT. During an educational simulation at the Yale Center for Healthcare Simulation, our team evaluated a woman presenting to the emergency department with abdominal pain, her concerned boyfriend at her side. Our team deduced the potential for an ectopic pregnancy. Yet, amid the diagnostic process and chaos of the exam room, we overlooked a critical aspect\u2014ensuring the boyfriend\u2019s departure from the room before discussing this sensitive issue. This experience starkly illuminated how the art of managing interpersonal dynamics can play an equally significant role as medical knowledge in patient care. It is these gaps that reiterate the critical role of human interaction and empathy in health care, attributes that, as of now, remain beyond the reach of what artificial intelligence can help medical students learn."
        },
        {
            "heading": "Alignment With Medical Education and Patient Care Goals",
            "text": "A final critical limitation of using LLMs in medical education lies in the potential misalignment between the underlying mechanics of artificial intelligence systems and the core objectives of medical education and patient care. Medical training encompasses a multifaceted blend of knowledge acquisition, skill development, clinical reasoning, empathy, and ethics. LLMs like ChatGPT predominantly function to support medical knowledge, and while this knowledge is a lynchpin for the broader competencies of the physician, it is not the entirety of clinical practice or the learning expected of the medical student transforming into a student doctor and finally physician. In the clinical phase of medical education, where communication and procedural skills rise to prominence, the medical knowledge supported by LLMs cannot meet the patient-centered values and ethical considerations required for human interaction in the hospital. As with existing medical knowledge bases and clinical decision support (eg, UpToDate or DynaMedex), LLMs can be valuable adjuncts to clinical education. It is critical that LLMs do not detract from the humanistic elements of practice that are developed through clinical education.\nFuture Integration of LLMs Into Health"
        },
        {
            "heading": "Care and the Importance of Understanding Strengths and Weaknesses",
            "text": "The integration of LLMs into health care is fast becoming a reality, with both the availability of LLMs at students\u2019 fingertips and the rapid influx of research-driven deployments. Such integration is underscored by the impending inclusion of\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 8https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX\nChatGPT into Epic Systems Corporation\u2019s software [36]. Potential applications range from reducing administrative tasks, like generating patient discharge instructions, assisting with insurance filings, and obtaining prior authorizations for medical services [37], to improving care quality through extracting key past medical history from complex patient records and providing interactive cross-checks of standard operating procedures (Figure 6).\nAcross the range of emerging applications, the most notable are the potential for LLMs to digest the huge volumes of unstructured data in electronic health records and the possibility for LLMs to assist with clinical documentation [9,38]. However, these benefits are not without their challenges. Ethical considerations must be addressed regarding the impacts of misinformation and bias if LLMs are implemented to help generate clinical notes or instructions for patients or if they are applied to automate chart review for clinical research. Systematic approaches and ethical frameworks must be developed to mitigate these risks. Moreover, steps must be taken\nto ensure that the use of patients\u2019 protected health information is in accordance with the Health Insurance Portability and Accountability Act (HIPAA) privacy and security requirements.\nAs we move toward a health care landscape increasingly intertwined with artificial intelligence, medical students must become adept at understanding and navigating the strengths and weaknesses of such technologies [39-41]. To be future leaders in health care, we must critically evaluate the best ways to harness artificial intelligence for improving health care while being cognizant of its limitations and the ethical, legal, and practical challenges it may pose.\nThe proactive curricular discourse surrounding topics like hallucinations, bias, and artificial intelligence models\u2019 self-evaluation of uncertainty, coupled with an exploration of potential legal and ethical issues, might be woven into the delivery of topics related to physicians\u2019 responsibility. By readily encouraging these dialogues, students can prepare for the challenges and opportunities that will come with the future integration of artificial intelligence into health care."
        },
        {
            "heading": "Conclusions",
            "text": "LLMs like ChatGPT hold significant potential for augmenting medical education. By integrating them into the educational process, we can foster critical thinking, promote creativity, and offer novel learning opportunities. Moreover, a deeper understanding of these models prepares students for their impending role in a health care landscape increasingly intertwined with artificial intelligence. Reflecting on the use of ChatGPT in medical school is an essential step to harness the potential of technology to lead the upcoming transformations in the digital era of medicine. The next generation of health care professionals must be not only conversant with these technologies but also equipped to leverage them responsibly and effectively in the service of patient care."
        },
        {
            "heading": "Acknowledgments",
            "text": "Research reported in this publication was supported by the National Heart, Lung, and Blood Institute of the National Institutes of Health under award T35HL007649 (CWS), the National Institute of General Medical Sciences of the National Institutes of\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 9https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX\nHealth under award T32GM136651 (AESE), the National Institute of Diabetes and Digestive and Kidney Diseases of the National Institutes of Health under award T35DK104689 (AG), and the Yale School of Medicine Fellowship for Medical Student Research (AG). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health."
        },
        {
            "heading": "Authors' Contributions",
            "text": "CWS, AESE, and DC contributed to the study conceptualization and drafting of the original manuscript. All authors participated in the investigation and validation process. All authors edited the manuscript draft and reviewed the final manuscript."
        },
        {
            "heading": "Conflicts of Interest",
            "text": "None declared."
        },
        {
            "heading": "Abbreviations",
            "text": "EPA: Entrustable Professional Activity HIPAA: Health Insurance Portability and Accountability Act LLM: large language model USMLE: United States Medical Licensing Exam\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 11https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX\nEdited by T de Azevedo Cardoso; this is a non\u2013peer-reviewed article. Submitted 17.07.23; accepted 26.07.23; published 14.08.23.\nPlease cite as: Safranek CW, Sidamon-Eristoff AE, Gilson A, Chartash D The Role of Large Language Models in Medical Education: Applications and Implications JMIR Med Educ 2023;9:e50945 URL: https://mededu.jmir.org/2023/1/e50945 doi: 10.2196/50945 PMID: 37578830\n\u00a9Conrad W Safranek, Anne Elizabeth Sidamon-Eristoff, Aidan Gilson, David Chartash. Originally published in JMIR Medical Education (https://mededu.jmir.org), 14.08.2023. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Medical Education, is properly cited. The complete bibliographic information, a link to the original publication on https://mededu.jmir.org/, as well as this copyright and license information must be included.\nJMIR Med Educ 2023 | vol. 9 | e50945 | p. 12https://mededu.jmir.org/2023/1/e50945 (page number not for citation purposes)\nXSL\u2022FO RenderX"
        }
    ],
    "title": "The Role of Large Language Models in Medical Education: Applications and Implications",
    "year": 2023
}