{
    "abstractText": "Precise thigh muscle volumes are crucial to monitor the motor functionality of patients with diseases that may result in various degrees of thigh muscle loss. T1-weighted MRI is the default surrogate to obtain thigh muscle masks due to its contrast between muscle and fat signals. Deep learning approaches have recently been widely used to obtain these masks through segmentation. However, due to the insufficient amount of precise annotations, thigh muscle masks generated by deep learning approaches tend to misclassify intra-muscular fat (IMF) as muscle impacting the analysis of muscle volumetrics. As IMF is infiltrated inside the muscle, human annotations require expertise and time. Thus, precise muscle masks where IMF is excluded are limited in practice. To alleviate this, we propose a few-shot segmentation framework to generate thigh muscle masks excluding IMF. In our framework, we design a novel pseudo-label correction and evaluation scheme, together with a new noise robust loss for exploiting high certainty areas. The proposed framework only takes 1% of the fine-annotated training dataset, and achieves comparable performance with fully supervised methods according to the experimental results.",
    "authors": [
        {
            "affiliations": [],
            "name": "Sheng Chen"
        },
        {
            "affiliations": [],
            "name": "Zihao Tang"
        },
        {
            "affiliations": [],
            "name": "Dongnan Liu"
        },
        {
            "affiliations": [],
            "name": "Ch\u00e9 Fornusek"
        },
        {
            "affiliations": [],
            "name": "Michael Barnett"
        },
        {
            "affiliations": [],
            "name": "Chenyu Wang"
        },
        {
            "affiliations": [],
            "name": "Mariano Cabezas"
        },
        {
            "affiliations": [],
            "name": "Weidong Cai"
        }
    ],
    "id": "SP:b2d4854dbde2e623eece2aa410cefd1d20e71d53",
    "references": [
        {
            "authors": [
                "M. Kiernan",
                "S. Vucic",
                "B. Cheah",
                "M. Turner"
            ],
            "title": "Amyotrophic lateral sclerosis",
            "venue": "The Lancet, vol. 377, no. 9769, pp. 942\u2013955, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "C. Fornusek",
                "P. Hoang"
            ],
            "title": "Neuromuscular electrical stimulation cycling exercise for persons with advanced multiple sclerosis",
            "venue": "Journal of Rehabilitation Medicine, vol. 46, no. 7, pp. 698\u2013702, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "I. Lorenzo",
                "M. Serra-Prat",
                "J. Y\u00e9benes"
            ],
            "title": "The role of water homeostasis in muscle function and frailty: a review",
            "venue": "Nutrients, vol. 11, no. 8, pp. 1857, 2019.",
            "year": 1857
        },
        {
            "authors": [
                "S. Orgiu",
                "C. Lafortuna",
                "F. Rastelli",
                "M. Cadioli",
                "A. Falini",
                "G. Rizzo"
            ],
            "title": "Automatic muscle and fat segmentation in the thigh from T1-weighted MRI",
            "venue": "Journal of Magnetic Resonance Imaging, vol. 43, no. 3, pp. 601\u2013610, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-Net: Convolutional networks for biomedical image segmentation",
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2015, pp. 234\u2013241.",
            "year": 2015
        },
        {
            "authors": [
                "O. Oktay",
                "J. Schlemper",
                "L. Folgoc",
                "M. Lee",
                "M. Heinrich",
                "K. Misawa",
                "K. Mori",
                "S. McDonagh",
                "N. Hammerla",
                "B. Kainz"
            ],
            "title": "Attention U-Net: Learning where to look for the pancreas",
            "venue": "Medical Imaging with Deep Learning (MIDL), 2018.",
            "year": 2018
        },
        {
            "authors": [
                "M. Alom",
                "C. Yakopcic",
                "M. Hasan",
                "T. Taha",
                "V. Asari"
            ],
            "title": "Recurrent residual U-Net for medical image segmentation",
            "venue": "Journal of Medical Imaging, vol. 6, no. 1, pp. 014006, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "C. Chen",
                "Q. Liu",
                "Y. Jin",
                "Q. Dou",
                "P. Heng"
            ],
            "title": "Source-free domain adaptive fundus image segmentation with denoised pseudo-labeling",
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention (MIC- CAI). Springer, 2021, pp. 225\u2013235.",
            "year": 2021
        },
        {
            "authors": [
                "Z. Huang",
                "H. Zhang",
                "A. Laine",
                "E. Angelini",
                "C. Hendon",
                "Y. Gan"
            ],
            "title": "Co-seg: An image segmentation framework against label corruption",
            "venue": "2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI). IEEE, 2021, pp. 550\u2013553.",
            "year": 2021
        },
        {
            "authors": [
                "D. Liu",
                "D. Zhang",
                "Y. Song",
                "F. Zhang",
                "L. O\u2019Donnell",
                "H. Huang",
                "M. Chen",
                "W. Cai"
            ],
            "title": "Unsupervised instance segmentation in microscopy images via panoptic domain adaptation and task re-weighting",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 4243\u20134252.",
            "year": 2020
        },
        {
            "authors": [
                "R. Amer",
                "J. Nassar",
                "D. Bendahan",
                "H. Greenspan",
                "N. Ben- Eliezer"
            ],
            "title": "Automatic segmentation of muscle tissue and intermuscular fat in thigh and calf MRI images",
            "venue": "International Conference on Medical Image Computing and Computer- Assisted Intervention (MICCAI). Springer, 2019, pp. 219\u2013227.",
            "year": 2019
        },
        {
            "authors": [
                "O. Addison",
                "R. Marcus",
                "P. LaStayo",
                "A. Ryan"
            ],
            "title": "Intermuscular fat: A review of the consequences and causes",
            "venue": "International Journal of Endocrinology, vol. 2014, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "K. Wang",
                "J. Liew",
                "Y. Zou",
                "D. Zhou",
                "J. Feng"
            ],
            "title": "Panet: Fewshot image semantic segmentation with prototype alignment",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp. 9197\u20139206.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Wu",
                "Z. Ge",
                "D. Zhang",
                "M. Xu",
                "L. Zhang",
                "Y. Xia",
                "J. Cai"
            ],
            "title": "Mutual consistency learning for semi-supervised medical image segmentation",
            "venue": "Medical Image Analysis, vol. 81, pp. 102530, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Wu",
                "M. Xu",
                "Z. Ge",
                "J. Cai",
                "L. Zhang"
            ],
            "title": "Semi-supervised left atrium segmentation with mutual consistency training",
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2021, pp. 297\u2013306.",
            "year": 2021
        },
        {
            "authors": [
                "L. Yu",
                "S. Wang",
                "X. Li",
                "C. Fu",
                "P. Heng"
            ],
            "title": "Uncertainty-aware self-ensembling model for semi-supervised 3D left atrium segmentation",
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2019, pp. 605\u2013613.",
            "year": 2019
        },
        {
            "authors": [
                "Z. Zheng",
                "Y. Yang"
            ],
            "title": "Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation",
            "venue": "International Journal of Computer Vision, vol. 129, no. 4, pp. 1106\u20131120, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Shu",
                "X. Wu",
                "W. Li"
            ],
            "title": "LVC-Net: Medical image segmentation with noisy label based on local visual cues",
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2019, pp. 558\u2013566.",
            "year": 2019
        },
        {
            "authors": [
                "H. Wu",
                "H. Wang",
                "H. He",
                "Z. He",
                "G. Wang"
            ],
            "title": "A novel weakly supervised framework based on noisy-label learning for medical image segmentation",
            "venue": "2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI). IEEE, 2021, pp. 1768\u20131772.",
            "year": 2021
        },
        {
            "authors": [
                "T. Chen",
                "S. Kornblith",
                "M. Norouzi",
                "G. Hinton"
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "International Conference on Machine Learning (ICML), 2020, pp. 1597\u20131607.",
            "year": 2020
        },
        {
            "authors": [
                "Z. Tang",
                "C. Wang",
                "P. Hoang",
                "S. Liu",
                "W. Cai",
                "D. Soligo",
                "R. Oliver",
                "M. Barnett",
                "C. Fornusek"
            ],
            "title": "Automatic segmentation of thigh muscle in longitudinal 3D T1-weighted magnetic resonance (MR) images",
            "venue": "Data Driven Treatment Response Assessment and Preterm, Perinatal, and Paediatric Image Analysis (DATRA), pp. 14\u201321. Springer, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Z. Tang",
                "K. Kyle",
                "M. Barnett",
                "C. Fornusek",
                "W. Cai",
                "C. Wang"
            ],
            "title": "Attention-based semantic segmentation of thigh muscle with T1-weighted magnetic resonance imaging",
            "venue": "Annual Meeting of the International Society for Magnetic Resonance in Medicine (ISMRM), 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Zhu",
                "T. Park",
                "P. Isola",
                "A. Efros"
            ],
            "title": "Unpaired image-toimage translation using cycle-consistent adversarial networks",
            "venue": "Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2017, pp. 2223\u20132232.",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014 few-shot, intra-muscular fat, thigh muscle segmentation, pseudo-label denoising, MRI"
        },
        {
            "heading": "1. INTRODUCTION",
            "text": "Precise thigh muscle volumes are critical for analyzing the motor functionality of patients with diseases that can cause different levels of muscle loss directly or indirectly due to sedentarism, such as amyotrophic lateral sclerosis [1] or multiple sclerosis [2]. T1-weighted MRI is a commonly used surrogate for studying muscles as water is their primary mass component and T1-weighted images have good contrast between water and fat [3]. Traditional thigh muscle segmentation approaches usually involve intensity-based al-\ngorithms and a relatively complex pipeline for pre- and postprocessing the images [4]. Recently, with the advancements in deep learning strategies, convolutional neural networks (CNNs) [5, 6, 7] have improved the accuracy of medical segmentation tasks and helped reduce human workload significantly [5, 8]. However, when precise annotations are limited or noisy, the model performance decreases significantly [9]. In addition, the variability of the acquisition parameters for different scanners and protocols limits the generalization of learning-based methods [10]. Fully-supervised models may overfit a particular dataset and suffer from performance drops on other datasets. Fine-tuning to these other datasets is also constrained by the availability of the scans from these new acquisition setups. Regarding thigh muscle segmentation, distinguishing intra-muscular fat (IMF) from thigh muscle remains challenging. IMF is defined as the fat that appears between muscle tissues, and it usually presents a complex structure that is spread into discontinuous branches [11, 12]. Furthermore, muscle regions tend to present intensity inhomogeneities that disrupt their intensity distribution and affect the segmentation results [4]. Thus, precise human annotation requires expertise and intensive labor, limiting the availability of precise thigh muscle masks where IMF is excluded.\nTo exploit the limited availability of precise annotations, few-shot segmentation methods commonly use a strategy based on class prototype information [13]. Few-shot methods also address the performance drop problem between different domains by adapting to a new dataset with few scans. Consequently, semi-supervised methods have gained increasing attention in medical image segmentation to segment challenging areas and structures for specific clinical tasks [14]. For our purpose, pseudo-labels derived from precisely labeled data can enrich the datasets, improving the exclusion of IMF. Several works have shown that combining uncertainty estimation with semi-supervised tasks helps reduce noise in pseudo-labels [15, 16]. There are two popular approaches regarding uncertainty estimation to improve pseudo-labels.\nar X\niv :2\n30 4.\n14 05\n3v 1\n[ ee\nss .I\nV ]\n2 7\nA pr\nThe first approach is to embed dropout layers [16] and use Monte Carlo sampling to generate uncertainty maps to reduce the effect of poorly determined regions. The second approach is to construct multiple decoders with different up-sampling methods [14, 17] and enforce a mutual consistency on the multiple outputs to constrain their uncertainty.\nIn this paper, we propose a two-stage few-shot segmentation framework specifically designed for precise thigh muscle segmentation excluding IMF. The proposed framework includes a pseudo-label generation (PLG) stage and a pseudolabel denoising (PLD) stage. In the PLG stage, pseudo-labels are generated by MC-Net [15] to enrich the dataset. In the PLD stage, these pseudo-labels are denoised by a novel correction and evaluation strategy. Moreover, a noise-robust loss is proposed to exploit the corrected pseudo-labels. Evaluated by dice for IMF and thigh muscle, our results demonstrate that the proposed method using only 13 (1% of the dataset) precisely labeled images outperforms other methods and can achieve comparable performance to the fully-supervised method."
        },
        {
            "heading": "2. METHOD",
            "text": "The overview of our two-stage framework is illustrated in Fig. 1. In the following sections, we focus on the two stages of our approach (PLG and PLD) and our novel loss function, define them formally and present the intuition behind them. Finally, we introduce our data augmentation scheme to further extend the training set."
        },
        {
            "heading": "2.1. Pseudo-label Generation",
            "text": "Considering that thigh muscle annotations usually include the IMF, we chose MC-Net, a semi-supervised approach [15], as\nour backbone to combine precise and noisy segmentations to enrich our training set. Specifically, two decoders (\u03b8dA and \u03b8dB) are designed with different up-sampling strategies based on the features from a single encoder \u03b8e. Two probability outputs (PA and PB) are generated by independent decoders using the sigmoid function and then thresholded (> 0.5) into pseudo labels (PLA and PLB). To ensure consistency and reduce uncertainty on the predictions, a cyclical scheme is introduced [14].\nFinally, the loss functions involved in this stage consist of a segmentation loss Lseg and a self-supervised consistency loss Lc. Lseg is only used for training samples with precisely annotated masks (Y\u0303 ), where Lc is used for all training data. The overall loss function can be formulated as:\nLseg = Dice(PA, Y\u0303 ) +Dice(PB , Y\u0303 ), (1) Lc = ||(PA \u2212 PLB)||2 + ||(PB \u2212 PLA)||2. (2)\nOnce the model is trained, pseudo-labels (Ypseudo) for all images (X) in the dataset can be generated by the mean prediction between the decoders as follows, where \u03c3 is the sigmoid function followed by a thresholding operation:\nYpseudo = \u03c3(0.5\u00d7 (\u03b8dA1(\u03b8e1(X)) + \u03b8dB1(\u03b8e1(X)))). (3)"
        },
        {
            "heading": "2.2. Pseudo-label Correction",
            "text": "Although MC-Net can reduce the uncertainty between the decoders, the generated pseudo-labels Ypseudo still contain errors, especially on challenging samples. To further distinguish thigh muscle from IMF and reduce the effect of the noisy pseudo-labels, we propose a new denoising strategy.\nInspired by source-free domain adaptation approaches [8], we argue that the feature within the same category should lie closer to their class prototypes, enforcing a high correlation for samples of the same class. In the case of segmentation, image regions with highly correlated voxels in feature space often have compact intensity ranges [18]. Thus, instead of estimating the distance of a pixel to different class prototypes [13], we directly exploit the class prototype information hidden in the intensity distribution of a set of given regions. As the intensity values of the thigh muscle are mostly distributed in the range of (0.2, 0.6) after normalizing the input images (X) to the range (0, 1), we extract coarse masks Ycoarse that exclude most of the IMF tissue. A single coarse mask Ycoarse is denoted as:\nYcoarse = { 1, pixel \u2208 (0.2, 0.6) 0, otherwise.\n(4)\nFinally, we define the set of corrected pseudo-labels Ycorrected as the intersection between the Ycoarse and Ypseudo masks. Examples are shown in Fig. 2."
        },
        {
            "heading": "2.3. Noise Robust Loss",
            "text": "Even though the corrected pseudo-labels Ycorrected can exclude most of the IMF, these masks present errors in the muscle\u2019s morphological structure. If the model is trained only with Ycorrected masks, the original Lseg will be affected by these errors and lead to incorrect masks. To address that issue, we propose a confidence evaluation (CE) strategy to ignore unreliable masks (Y\u0303corrected) when evaluating the Lseg loss. Inspired by [19], we also introduce a new noise robust loss (Lr) that takes into account the Y\u0303corrected masks.\nGiven an input image X and its Ypseudo and Ycoarse masks, we define its confidence score S as the Dice similarity coefficient between the masks:\nS = 2\u00d7 (Ypseudo \u00d7 Ycoarse) Ypseudo + Ycoarse . (5)\nIn those cases where the confidence score is low, the resulting Ycorrected mask will vary greatly from the original two masks due to their low intersection. This will either mean that the morphological structure of the muscle in Ycorrected is unreliable or that the sample X is a hard example. Consequently, if the confidence score of the Ycorrected mask is lower than 0.8, the sample is excluded from the Lseg loss (now calculated on eligible Ycorrected masks).\nThis new constrain, offers a trade-off between highlyconfident structural segmentations and supervision information. To offset the effect of the loss examples and to fully exploit all the Ycorrected pseudo-labels with missing muscle voxels, we design a loss that penalizes differences in the predictions (PA and PB) under the Ycorrected masks. Thus, we define our noise robust loss Lr as:\nLr = ||(PA \u00d7 Ycorrected \u2212 Ycorrected)||2 + ||(PB \u00d7 Ycorrected \u2212 Ycorrected)||2. (6)\nFinally, the overall loss function for this second stage in our framework can be defined as:\nloss = { S \u00d7 Lseg + Lr + 0.5\u00d7 Lc if S \u2265 0.8, Lr + 0.5\u00d7 Lc if S < 0.8.\n(7)"
        },
        {
            "heading": "2.4. Data Augmentation",
            "text": "While the previous contributions focus on enhancing the dataset with pseudo-labels, we further address the limited amount of data [20] by using augmentation techniques (including contrast adjustments to deal with inhomogeneities) that can help to learn better feature representations for muscles and IMF. Specifically, given an input image X , we apply an augmentation function T that consists of flipping, rotation, and affine transformations. Finally, we adjust the contrast of T (X) by a random factor \u03b3 \u2208 [0.5, 0.7]."
        },
        {
            "heading": "3. EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "3.1. Dataset and Implementation Details",
            "text": "We evaluate the proposed framework on a thigh dataset from multiple sclerosis subjects. The dataset consists of magnetic resonance imaging (MRI) volumes of the thigh muscle from 11 participants that were scanned at different timelines and precisely annotated (excluding IMF). All subjects were scanned with a 3DT1 sequence (IRFSPGR, TE = 2.7msec, TR = 6.5msec, acquisition matrix = 480\u00d7 480, Slice thickness = 1mm). The baseline and follow-up images were registered following the process described in Tang et al. [21] and using the femur as the target. All the volumes were pre-processed into 2D slices of 256 \u00d7 256 [22]. A random subject-wise data split of 7 and 4 participants for training and testing, respectively, was applied to the multiple timepoints. The final dataset contained 1040 slices from 34 3D MRIs for training and 249 slices from 8 3D MRIs for testing. 13 of the training slices, around 1% in the training set, were randomly selected as precise annotations for the PLG stage only. Finally, the two stages of our framework were trained for 20 (PLG) and 10 (PLD) epochs, respectively. The optimization settings followed Zhu et al.\u2019s training scheme [23]. The code was implemented in PyTorch 1.4 and tested with an NVIDIA GTX 1080."
        },
        {
            "heading": "3.2. Evaluations and Comparisons",
            "text": "For the evaluation of the segmentation, we use the Dice similarity coefficient for both thigh muscle (DiceTM ) and IMF (DiceIMF ). To generate an IMF mask, we apply a binary closing operation to the testing thigh muscle mask (Ytest) to close all IMF branches and generate noisy masks (Ynoisy). The differences between the Ytest and Ynoisy mask are then considered the IMF mask. The results on that mask can give us a clearer idea on the improvement to exclude IMF areas from the final mask.\nTable 1 lists the quantitative results (evaluated on the testing data) including state-of-the-art approaches for the following methods: U-Net (Baseline) [5], ResU-Net [7], AttentionU-Net [6, 22], MC-Net [15], a fully supervised UNet, and our proposed method. Qualitative results are shown\n(a) Image X (b) GT (c) Baseline (d) Our method (e) ResU-Net (f) AttU-Net (g) MC-Net (h) Fully U\nFig. 3. Muscle segmentation results with (a) as the input of the framework. (b) is the ground truth image GT and (c)-(h) are the corresponding muscle masks generated by baseline, the proposed method, ResU-Net, AttentionU-Net (AttU-Net), MC-Net, and fully-supervised U-Net (Fully U), respectively. The interested areas are enclosed with red squares.\nin Fig. 3. When only 13 labeled 2D samples were available for training, the proposed method outperformed all the compared methods with an improvement of the DiceIMF and DiceTM metrics of 11% and 4.2% when compared to the baseline. Furthermore, our method proposal with a low number of samples gave results comparable to those of a fully supervised U-Net trained with 1040 labeled samples."
        },
        {
            "heading": "3.3. Ablation Study",
            "text": "To verify the effectiveness of each component in our proposed framework, we conducted a set of ablation studies. Table 1 summarizes the results regarding the data augmentation strategies. Adjusting the contrast of input images reduces the effect from intensity inhomogeneity as evidenced by the improvement on the Dice metrics. Further ablation studies were conducted regarding the PLD stage. When training the model without confidence evaluation (CE), the performance decreases considerably as Lseg is supervised by Ycorrected\nmasks that contain potentially incomplete structures. By constraining the supervision signal with CE and Lr (visual examples in Fig. 4), the model is capable of better exploiting the Ycorrected masks."
        },
        {
            "heading": "4. CONCLUSION",
            "text": "In this paper, we propose a two-stage few-shot segmentation framework to generate precise thigh muscle masks without IMF. Combining pseudo-label evaluation and denoising schemes, our method could be trained with only 13 images (1% of the dataset) to achieve a comparable performance to a fully supervised method and outperform other state-of-the-art approaches with limited annotations. Therefore, our method presents a novel way to leverage class prototypes in scenarios with scarce and noisy annotations. Moreover, our proposed robust noise loss provides a new supervision approach for exploiting uncertainty in semi-supervised problems. In conclusion, our proposed method can generate precise thigh muscle masks where the IMF is excluded and could be used as part of an automatic muscle volume tracking tool for longitudinal clinical studies."
        },
        {
            "heading": "5. COMPLIANCE WITH ETHICAL STANDARDS",
            "text": "The study was approved by the University of Sydney Human Research and Ethics Committee and all procedures adhered the tenets of the Declaration of Helsinki."
        },
        {
            "heading": "6. ACKNOWLEDGEMENTS",
            "text": "The authors would like to acknowledge funding support of Multiple Sclerosis Research Australia (18-0416), Australia Medical Research Future Fund under Grant (MRFFAI000085) and Australian Government Research Training Program (RTP) Scholarship."
        },
        {
            "heading": "7. REFERENCES",
            "text": "[1] M. Kiernan, S. Vucic, B. Cheah, M. Turner, et al., \u201cAmyotrophic lateral sclerosis,\u201d The Lancet, vol. 377, no. 9769, pp. 942\u2013955, 2011.\n[2] C. Fornusek and P. Hoang, \u201cNeuromuscular electrical stimulation cycling exercise for persons with advanced multiple sclerosis.,\u201d Journal of Rehabilitation Medicine, vol. 46, no. 7, pp. 698\u2013702, 2014.\n[3] I. Lorenzo, M. Serra-Prat, and J. Ye\u0301benes, \u201cThe role of water homeostasis in muscle function and frailty: a review,\u201d Nutrients, vol. 11, no. 8, pp. 1857, 2019.\n[4] S. Orgiu, C. Lafortuna, F. Rastelli, M. Cadioli, A. Falini, and G. Rizzo, \u201cAutomatic muscle and fat segmentation in the thigh from T1-weighted MRI,\u201d Journal of Magnetic Resonance Imaging, vol. 43, no. 3, pp. 601\u2013610, 2016.\n[5] O. Ronneberger, P. Fischer, and T. Brox, \u201cU-Net: Convolutional networks for biomedical image segmentation,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2015, pp. 234\u2013241.\n[6] O. Oktay, J. Schlemper, L. Folgoc, M. Lee, M. Heinrich, K. Misawa, K. Mori, S. McDonagh, N. Hammerla, B. Kainz, et al., \u201cAttention U-Net: Learning where to look for the pancreas,\u201d Medical Imaging with Deep Learning (MIDL), 2018.\n[7] M. Alom, C. Yakopcic, M. Hasan, T. Taha, and V. Asari, \u201cRecurrent residual U-Net for medical image segmentation,\u201d Journal of Medical Imaging, vol. 6, no. 1, pp. 014006, 2019.\n[8] C. Chen, Q. Liu, Y. Jin, Q. Dou, and P. Heng, \u201cSource-free domain adaptive fundus image segmentation with denoised pseudo-labeling,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2021, pp. 225\u2013235.\n[9] Z. Huang, H. Zhang, A. Laine, E. Angelini, C. Hendon, and Y. Gan, \u201cCo-seg: An image segmentation framework against label corruption,\u201d in 2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI). IEEE, 2021, pp. 550\u2013553.\n[10] D. Liu, D. Zhang, Y. Song, F. Zhang, L. O\u2019Donnell, H. Huang, M. Chen, and W. Cai, \u201cUnsupervised instance segmentation in microscopy images via panoptic domain adaptation and task re-weighting,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 4243\u20134252.\n[11] R. Amer, J. Nassar, D. Bendahan, H. Greenspan, and N. BenEliezer, \u201cAutomatic segmentation of muscle tissue and intermuscular fat in thigh and calf MRI images,\u201d in International Conference on Medical Image Computing and ComputerAssisted Intervention (MICCAI). Springer, 2019, pp. 219\u2013227.\n[12] O. Addison, R. Marcus, P. LaStayo, and A. Ryan, \u201cIntermuscular fat: A review of the consequences and causes,\u201d International Journal of Endocrinology, vol. 2014, 2014.\n[13] K. Wang, J. Liew, Y. Zou, D. Zhou, and J. Feng, \u201cPanet: Fewshot image semantic segmentation with prototype alignment,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp. 9197\u20139206.\n[14] Y. Wu, Z. Ge, D. Zhang, M. Xu, L. Zhang, Y. Xia, and J. Cai, \u201cMutual consistency learning for semi-supervised medical image segmentation,\u201d Medical Image Analysis, vol. 81, pp. 102530, 2022.\n[15] Y. Wu, M. Xu, Z. Ge, J. Cai, and L. Zhang, \u201cSemi-supervised left atrium segmentation with mutual consistency training,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2021, pp. 297\u2013306.\n[16] L. Yu, S. Wang, X. Li, C. Fu, and P. Heng, \u201cUncertainty-aware self-ensembling model for semi-supervised 3D left atrium segmentation,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2019, pp. 605\u2013613.\n[17] Z. Zheng and Y. Yang, \u201cRectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation,\u201d International Journal of Computer Vision, vol. 129, no. 4, pp. 1106\u20131120, 2021.\n[18] Y. Shu, X. Wu, and W. Li, \u201cLVC-Net: Medical image segmentation with noisy label based on local visual cues,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). Springer, 2019, pp. 558\u2013566.\n[19] H. Wu, H. Wang, H. He, Z. He, and G. Wang, \u201cA novel weakly supervised framework based on noisy-label learning for medical image segmentation,\u201d in 2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI). IEEE, 2021, pp. 1768\u20131772.\n[20] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, \u201cA simple framework for contrastive learning of visual representations,\u201d in International Conference on Machine Learning (ICML), 2020, pp. 1597\u20131607.\n[21] Z. Tang, C. Wang, P. Hoang, S. Liu, W. Cai, D. Soligo, R. Oliver, M. Barnett, and C. Fornusek, \u201cAutomatic segmentation of thigh muscle in longitudinal 3D T1-weighted magnetic resonance (MR) images,\u201d in Data Driven Treatment Response Assessment and Preterm, Perinatal, and Paediatric Image Analysis (DATRA), pp. 14\u201321. Springer, 2018.\n[22] Z. Tang, K. Kyle, M. Barnett, C. Fornusek, W. Cai, and C. Wang, \u201cAttention-based semantic segmentation of thigh muscle with T1-weighted magnetic resonance imaging,\u201d in Annual Meeting of the International Society for Magnetic Resonance in Medicine (ISMRM), 2020.\n[23] J. Zhu, T. Park, P. Isola, and A. Efros, \u201cUnpaired image-toimage translation using cycle-consistent adversarial networks,\u201d in Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2017, pp. 2223\u20132232."
        }
    ],
    "title": "PRECISE FEW-SHOT FAT-FREE THIGH MUSCLE SEGMENTATION IN T1-WEIGHTED MRI",
    "year": 2023
}