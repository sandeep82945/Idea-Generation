{
    "abstractText": "Multispectral photometric stereo (MPS) aims at recovering the surface normal of a scene from a single-shot multispectral image captured under multispectral illuminations. Existing MPS methods adopt the Lambertian reflectance model to make the problem tractable, but it greatly limits their application to real-world surfaces. In this paper, we propose a deep neural network named NeuralMPS to solve the MPS problem under general non-Lambertian spectral reflectances. Specifically, we present a spectral reflectance decomposition (SRD) model to disentangle the spectral reflectance into geometric components and spectral components. With this decomposition, we show that the MPS problem for surfaces with a uniform material is equivalent to the conventional photometric stereo (CPS) with unknown light intensities. In this way, NeuralMPS reduces the difficulty of the non-Lambertian MPS problem by leveraging the well-studied non-Lambertian CPS methods. Experiments on both synthetic and real-world scenes demonstrate the effectiveness of our method.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jipeng Lv"
        },
        {
            "affiliations": [],
            "name": "Heng Guo"
        },
        {
            "affiliations": [],
            "name": "Guanying Chen"
        },
        {
            "affiliations": [],
            "name": "Jinxiu Liang"
        },
        {
            "affiliations": [],
            "name": "Boxin Shi"
        }
    ],
    "id": "SP:837f00235b6622ed87f4c0001b5aa431e8e85524",
    "references": [
        {
            "authors": [
                "Robert Anderson",
                "Bj\u00f6rn Stenger",
                "Roberto Cipolla"
            ],
            "title": "Augmenting depth camera output using photometric stereo",
            "venue": "Machine Vision and Applications,",
            "year": 2011
        },
        {
            "authors": [
                "Robert Anderson",
                "Bj\u00f6rn Stenger",
                "Roberto Cipolla"
            ],
            "title": "Color photometric stereo for multicolored surfaces",
            "venue": "In Proc. of International Conference on Computer Vision (ICCV),",
            "year": 2011
        },
        {
            "authors": [
                "Ayan Chakrabarti",
                "Kalyan Sunkavalli"
            ],
            "title": "Single-image rgb photometric stereo with spatially-varying albedo",
            "venue": "In International Conference on 3D Vision (3DV),",
            "year": 2016
        },
        {
            "authors": [
                "Guanying Chen",
                "Kai Han",
                "Boxin Shi",
                "Yasuyuki Matsushita",
                "Kwan-Yee K. Wong"
            ],
            "title": "Self-calibrating deep photometric stereo networks",
            "venue": "In Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2019
        },
        {
            "authors": [
                "Guanying Chen",
                "Kai Han",
                "Kwan-Yee K. Wong"
            ],
            "title": "PS- FCN: A flexible learning framework for photometric stereo",
            "venue": "In Proc. of European Conference on Computer Vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Lixiong Chen",
                "Yinqiang Zheng",
                "Boxin Shi",
                "Art Subpa-Asa",
                "Imari Sato"
            ],
            "title": "A microfacet-based model for photometric stereo with general isotropic reflectance",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Jonathan Dupuy",
                "Wenzel Jakob"
            ],
            "title": "An adaptive parameterization for efficient material acquisition and rendering",
            "venue": "ACM Trans. on Graph.,",
            "year": 2018
        },
        {
            "authors": [
                "Kenji Enomoto",
                "Michael Waechter",
                "Kiriakos N Kutulakos",
                "Yasuyuki Matsushita"
            ],
            "title": "Photometric stereo via discrete hypothesis-and-test search",
            "venue": "In Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2020
        },
        {
            "authors": [
                "CH Esteban",
                "G Vogiatzis",
                "R Cipolla"
            ],
            "title": "Overcoming shadows in 3-source photometric stereo",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2011
        },
        {
            "authors": [
                "Heng Guo",
                "Fumio Okura",
                "Boxin Shi",
                "Takuya Funatomi",
                "Yasuhiro Mukaigawa",
                "Yasuyuki Matsushita"
            ],
            "title": "Multispectral photometric stereo for spatially-varying spectral reflectances: A well posed problem",
            "venue": "In Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2021
        },
        {
            "authors": [
                "Zhuo Hui",
                "Aswin C Sankaranarayanan"
            ],
            "title": "Shape and spatially-varying reflectance estimation from virtual exemplars",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2016
        },
        {
            "authors": [
                "Satoshi Ikehata"
            ],
            "title": "CNN-PS: CNN-based photometric stereo for general non-convex surfaces",
            "venue": "In Proc. of European Conference on Computer Vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Micah K Johnson",
                "Edward H Adelson"
            ],
            "title": "Shape estimation in natural illumination",
            "venue": "In Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2011
        },
        {
            "authors": [
                "Yakun Ju",
                "Xinghui Dong",
                "Yingyu Wang",
                "Lin Qi",
                "Junyu Dong"
            ],
            "title": "A dual-cue network for multispectral photometric stereo",
            "venue": "Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Yakun Ju",
                "Lin Qi",
                "Jichao He",
                "Xinghui Dong",
                "Feng Gao",
                "Junyu Dong"
            ],
            "title": "MPS-Net: Learning to recover surface normal for multispectral photometric stereo",
            "year": 2020
        },
        {
            "authors": [
                "Yakun Ju",
                "Lin Qi",
                "Huiyu Zhou",
                "Junyu Dong",
                "Liang Lu"
            ],
            "title": "Demultiplexing colored images for multispectral photometric stereo via deep neural networks",
            "venue": "IEEE Access,",
            "year": 2018
        },
        {
            "authors": [
                "Leonid L Kontsevich",
                "AP Petrov",
                "IS Vergelskaya"
            ],
            "title": "Reconstruction of shape from shading in color images",
            "venue": "Journal of the Optical Society of America,",
            "year": 1994
        },
        {
            "authors": [
                "Keisuke Ozawa",
                "Imari Sato",
                "Masahiro Yamaguchi"
            ],
            "title": "Single color image photometric stereo for multi-colored surfaces",
            "venue": "Computer Vision and Image Understanding,",
            "year": 2018
        },
        {
            "authors": [
                "Sejuti Rahman",
                "Antony Lam",
                "Imari Sato",
                "Antonio Robles-Kelly"
            ],
            "title": "Color photometric stereo using a rainbow light for non-lambertian multicolored surfaces",
            "venue": "In Proc. of Asian Conference on Computer Vision (ACCV),",
            "year": 2014
        },
        {
            "authors": [
                "Hiroaki Santo",
                "Masaki Samejima",
                "Yusuke Sugano",
                "Boxin Shi",
                "Yasuyuki Matsushita"
            ],
            "title": "Deep photometric stereo network",
            "venue": "In Proc. of International Conference on Computer Vision Workshops (ICCVW),",
            "year": 2017
        },
        {
            "authors": [
                "Boxin Shi",
                "Zhipeng Mo",
                "Zhe Wu",
                "Dinglong Duan",
                "Sai-Kit Yeung",
                "Ping Tan"
            ],
            "title": "A benchmark dataset and evaluation for non-Lambertian and uncalibrated photometric stereo",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Boxin Shi",
                "Ping Tan",
                "Yasuyuki Matsushita",
                "Katsushi Ikeuchi"
            ],
            "title": "Bi-polynomial modeling of low-frequency reflectances",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2014
        },
        {
            "authors": [
                "William M. Silver"
            ],
            "title": "Determining shape and reflectance using multiple images",
            "venue": "PhD thesis, Massachusetts Institute of Technology,",
            "year": 1980
        },
        {
            "authors": [
                "Richard Szeliski"
            ],
            "title": "Computer vision: algorithms and applications",
            "venue": "Springer Science & Business Media,",
            "year": 2010
        },
        {
            "authors": [
                "Olivia Wiles",
                "Andrew Zisserman"
            ],
            "title": "SilNet: Singleand multi-view reconstruction by learning from silhouettes. 2017",
            "year": 2017
        },
        {
            "authors": [
                "Robert J. Woodham"
            ],
            "title": "Photometric method for determining surface orientation from multiple images",
            "venue": "Optical engineering,",
            "year": 1980
        },
        {
            "authors": [
                "Wuyuan Xie",
                "Yunbo Zhang",
                "Charlie CL Wang",
                "Ronald C-K Chung"
            ],
            "title": "Surface-from-gradients: An approach based on discrete geometry processing",
            "venue": "In Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2014
        },
        {
            "authors": [
                "Zhuokun Yao",
                "Kun Li",
                "Ying Fu",
                "Haofeng Hu",
                "Boxin Shi"
            ],
            "title": "GPS-NET: Graph-based photometric stereo network",
            "venue": "Proc. of Annual Conference on Neural Information Processing Systems (NeurIPS),",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1. Introduction",
            "text": "Photometric stereo methods, originally proposed by Woodham [26] and Silver [23], recover detailed geometry of three-dimensional (3D) surfaces from images captured from a fixed camera under varying lighting directions, which are commonly obtained at different timestamps. Since conventional photometric stereo (CPS) methods stack images with time-multiplexing, the target surface has to be kept static during the multiple shots. With spectralmultiplexing, multispectral photometric stereo (MPS) [17] can recover surface normals from a one-shot multispectral image. As shown in Fig. 1, a single input image for MPS encodes observations under varying lighting directions in different spectral bands, conveying the information about surface normals and spectral reflectances. With a multispectral camera and spectral light sources, MPS can recon-\n*These authors contributed equally to this work.\nstruct the 3D shapes of dynamic objects. Existing MPS methods [2, 3, 10, 18] mostly focus on the Lambertian reflectance, which has limited ability to represent the surface appearance in real-world scenes. For non-Lambertian surfaces, the spectral reflectance varies not only with the spectral band, but also the incident-outgoing lighting directions w.r.t. the surface normal at different scene points. There have been a few MPS methods working for nonLambertian reflectance, which assumed a specific hardware setup [19] with two-shot capturing or an input image containing only three spectral channels with fixed spectral bands [14\u201316]. Due to the restrictive capture setting and limited surface normal estimation accuracy of existing methods, non-Lambertian MPS remains an open and challenging problem.\nDespite that modeling non-Lambertian reflectance is well-studied in the CPS context and great progress has been achieved with data-driven approaches (e.g., [5, 12, 20, 28]), non-Lambertian CPS methods cannot be directly applied to multispectral image observations, as the wavelengthdependent responses have not been considered.\n1Please check the supplementary video for the full sequence.\nar X\niv :2\n21 1.\n15 31\n1v 1\n[ cs\n.C V\n] 2\n8 N\nov 2\n02 2\nIn this paper, we propose a spectral reflectance decomposition (SRD) model for the task of MPS, which enables accurate recovery of dynamic non-Lambertian surfaces. With the proposed SRD model, MPS can be reformulated as a CPS problem, which allows us to borrow experiences from well-established CPS theory and practice. Specifically, we decompose the non-Lambertian spectral reflectance into two independent components: geometric and spectral. The geometric component only varies with the incident-outgoing lighting directions, which can be wellmodeled by non-Lambertian CPS methods. The spectral component is the response w.r.t. the spectral wavelength. For surfaces covered by a uniform material, we can entangle it with the input light intensity as an equivalent light intensity. Then the MPS problem can be formulated as a CPS one with unknown equivalent light intensities. We, therefore, propose a neural network NeuralMPS to first predict the equivalent light intensity, including the spectral component, and then embed existing CPS methods to recover the surface normal map considering the geometric component only.\nTo summarize, our contributions are as follows:\n\u2022 We introduce an SRD model and transform the MPS problem to the well-studied CPS with unknown equivalent light intensity.\n\u2022 We propose a learning-based MPS network named NeuralMPS to obtain accurate surface normal prediction under non-Lambertian reflectance.\n\u2022 Extensive experiments on both synthetic and real datasets show that NeuralMPS outperforms existing non-Lambertian MPS methods."
        },
        {
            "heading": "2. Related Works",
            "text": "The general reflectance for a surface can be modeled by the Bidirectional Reflectance Distribution Function (BRDF) [24], which describes how much light at each wavelength arriving at an incident direction is emitted in a reflected direction. With a fixed view direction, the isotropic spectral BRDF is a function R(n, l, \u03bb) of the surface normal n, the lighting direction l and the wavelength \u03bb. Therefore, the BRDF response w.r.t. the three variables can be recorded as a cube, as shown in Fig. 2. In this section, we review CPS and MPS approaches under Lambertian reflectance and non-Lambertian reflectance, respectively. These four categories are based on different simplifications on the spectral BRDF cube. Among all the categories, we assume distant lights with calibrated directions.\nLambertian, CPS CPS under the Lambertian reflectance assumption is the most classic setup. In such case, the spectral reflectance under varying lighting directions and wavelengths is a constant value, i.e., R(n, l, \u03bb) = c\n(see Fig. 2 (a)). Without loss of generality, we set c = 1. Given image measurements under more than 3 noncoplanar lighting directions, classical photometric stereo works [23, 26] provided a closed-form solution to surface normal estimation.\nNon-Lambertian, CPS The spectral reflectance for nonLambertian CPS is varying with the incident-outgoing lighting directions (geometric component), but omitting the variation w.r.t the wavelength (spectral component). Therefore, the spectral BRDF R(n, l, \u03bb) = R(n, l) and the spectral cube shown in Fig. 2 (b) is a Kronecker product of an allin-one spectral response vector and the geometric response matrix. Existing non-Lambertian CPS methods applied analytical [6, 22] or non-parametric model [8, 11] to represent the geometric component of the spectral reflectance. Recently, neural-based photometric stereo methods [5, 12, 28] achieved high accuracy on surface normal estimation under non-Lambertian reflectance, where the geometric component is learned from data with diverse reflectances. Please refer to the survey [21] for a comprehensive review of nonLambertian CPS methods.\nLambertian, MPS In MPS, the spectral component has to be taken into account. Under Lambertian reflectance, the BRDF keeps constant w.r.t. geometric component, i.e., R(n, l, \u03bb) = R(\u03bb). Therefore, the spectral cube shown in Fig. 2 (c) is a Kronecker product of spectral response vector and an all-in-one matrix recording the variation on the geometric response. Different from Lambertian CPS, MPS is ill-posed even under Lambertian reflectance. Existing methods require additional shape priors [1, 2] or reflectance clustering [3, 18] to solve the problem. Recently, Guo et al. [10] formulated the Lambertian MPS problem into a well-posed one and provided a unique solution for surface normals with image cue only.\nNon-Lambertian, MPS Non-Lambertian MPS problem is the most challenging case among the four categories, as the spectral BRDF R(n, l, \u03bb) is related to both wavelength and incident-outgoing lighting directions. Therefore, the spectral BRDF is recorded as a general cube (see Fig. 2 (d)). Existing non-Lambertian MPS methods assumed analytical BRDF model and two-shot data capturing [19]. However, the analytical BRDF model is limited to a small set of materials, and the two-shot data capturing eliminates the advantage of MPS over CPS on dynamic shape recovery. Ju et al. [14, 15] propose learning-based methods to solve non-Lambertian reflectance. However, the spectral band of the input multispectral images in the test phase is required to keep fixed in the training stage, which limits their application to real-world scenarios. To obtain accurate dynamic surface normal recovery under non-Lambertian reflectance, our method regards the spectral BRDF cube as\na Kronecker product of the spectral response vector (spectral component) and geometric response matrix (geometric component). As we can see in the following sections, such a decomposition enables the application of off-the-shell nonLambertian CPS methods on the non-Lambertian MPS task."
        },
        {
            "heading": "3. Spectral Reflectance Decomposition Model",
            "text": "In the context of MPS, the material spectral reflectance varies with both the incident-outgoing lighting directions and spectral bands. Under a fixed view direction, it can be formulated as a function of surface normal n, lighting direction l, and wavelength \u03bb. Our spectral decomposition model disentangles the non-Lambertian spectral reflectance into two independent components such that\nR(n, l, \u03bb) = Rs(\u03bb)Rg(n, l), (1)\nwhere Rs(\u03bb) is the spectral component related only to the wavelength, andRg(n, l) denotes the geometric component that coresponses to the variation w.r.t. surface normal and lighting direction. For surfaces covered by uniform material, we assume all scene points share the same spectral component, but the geometric response can vary from point to point depending on their surface normal directions. Intuitively, this assumption means the chromaticity of the whole surface will not change by moving the light source positions. Similar assumptions about spectral reflectance have been used in [2, 9], with a focus on the Lambertian case where Rg(n, l) keeps constant.\nWe illustrate and verify our SRD model by measured spectral BRDFs [7]. As shown in Fig. 3, we plot measured spectral reflectances of two materials: \u201cpaper blue\u201d\nand \u201ccm toxic green\u201d in the [360nm, 1000nm] wavelength range, where different color curves show the spectral reflectance at varying lighting direction and surface normal pairs: (l,n). If the surface follows Lambertian reflectance [2, 9], the spectral reflectance shown in the figure should contain one single curve, which is not flexible to represent the real-world spectral reflectances. To verify our SRD model, we sample 195 wavelengths and 200\u00d7200 pairs of (l,n) to build the spectral reflectance response matrix R \u2208 R195,200\u00d7200. To obtain decomposed reflectance component, we conduct SVD on R such that\nR = U\u03a3V>,\nrs = U1, rg = V1, (2)\nwhere rs and rg are the decomposed spectral and geometric components in the vector form, which are obtained from the first column of U and V, respectively. We observe that the largest singular value captures more than 75% of the energy in \u03a3, which reveals that we can approximate the spectral reflectance in high accuracy with the decomposed rs and rg . The recovered spectral reflectance curves from the spectral and geometric components are shown in the figure, which is close to the originally measured one."
        },
        {
            "heading": "3.1. SRD-based Image Formation Model",
            "text": "Based on the proposed SRD model, we show that the MPS problem is equivalent to the CPS under unknown light intensity. This conclusion can be derived from the multispectral image formation model.\nFollowing the conventional practice, we assume an orthogonal multispectral camera with a linear radiometric\nresponse and f spectral directional lights with calibrated lighting directions. By turning on all the spectral light sources, we can capture a single multispectral image with f spectral bands recording measurements under varying lighting directions. Consider a non-Lambertian surface with the spectral reflectance modeled by a general isotropic BRDF, the image observation for each scene point on the surface under the j-th incoming lighting can be written as follows:\nmj = ejmax(n >lj , 0) \u222b \u03bb R(n, lj , \u03bb)Cj(\u03bb)Ej(\u03bb) d\u03bb, (3)\nwhere n \u2208 S2 \u2282 R3 represents the unit surface normal vector, lj \u2208 S2 \u2282 R3 and ej \u2208 R+ are lighting direction and radiance of the j-th light source, respectively, with its spectra defined by Ej(\u03bb) : R+ \u2192 R+. The camera spectral sensitivity at the j-th spectral band is represented by Cj(\u03bb), and the attach shadow is modeled by max(\u00b7).\nWe assume the crosstalk between spectral bands is negligible [3, 10, 18], i.e., the observations under each spec-\ntral light can only be observed in its corresponding camera channel. Based on the negligible crosstalk and the spectral reflectance decomposition model shown in Eq. (1), the image observation can be re-written as\nmj = e \u2032 jRg(n, lj)max(n >lj , 0), (4)\nand e\u2032j is defined by\ne\u2032j = ej \u222b \u03bb\u2208\u2126j Rs(\u03bb)C(\u03bb)E(\u03bb) d\u03bb, (5)\nwhere \u2126j is the j-th spectral band of the corresponding spectral light and camera channel. The camera spectral sensitivity, light spectra, material spectral component, and the light intensity are encoded in the e\u2032j . If the material spectral component is uniform for the whole surface (e.g. uniform material), e\u2032j keeps constant for all the surface points. Therefore, we name e\u2032j as the equivalent light intensity. According to the multispectral image formation model shown in Eq. (4), given the image measurement m and its corresponding lighting direction l, the non-Lambertian MPS task can be reformulated as estimating the surface normal n under unknown geometric reflectance Rg(n, l) and the equivalent light intensity e\u2032j . In this way, non-Lambertian MPS is equivalent to the non-Lambertian CPS problem with unknown light intensities."
        },
        {
            "heading": "4. Learning Non-Lambertian MPS",
            "text": "In this section, we present our NeuralMPS for surface normal recovery under non-Lambertian reflectances. As shown in Fig. 4, there are two modules in the proposed method with functionalities indicated by their names: Equivalent Light Intensity Estimation Network (ELIE-Net) and Surface Normal Estimation (SNE) Module.\nELIE-Net As discussed in the previous section, the MPS problem is recast into a CPS with unknown equivalent light intensities. ELIE-Net aims at predicting the equivalent light intensities from the image observations and the calibrated lighting directions. The overall framework is shown in Fig. 4. Specifically, each image observation, as well as the corresponding calibrated lighting direction and object mask, are fed into a shared encoder separately to extract their local features first. The local features of different observations are then pooled into a global one by a maxpooling layer. By a shared decoder fed with concatenated local and global features, the equivalent light intensity for each observation can then be predicted.\nThe network architecture of ELIE-Net is similar to the LC-Net in [4]. However, the LC-Net in [4] is used to estimate both lighting direction and intensity in uncalibrated CPS, which is a different task from our MPS problem. Also,\nto ease the learning difficulty in their task, the regressionbased problems of lighting direction and intensity are recast as a classification-based one, where the continuous lighting space is discretized into a discrete one with pre-defined ranges and classes. However, we show that such discretization is too rough for the estimation of equivalent lighting intensity in our MPS task. Specifically, the equivalent light intensity in our method has a high dynamic range (HDR), as it encodes not only the irradiance of the light source but also the integral of camera spectral sensitivity, light spectra, and the material spectral component according to Eq. (5). As shown in Fig. 5, we plot the histogram of equivalent light intensities from 51 measured materials, whose log intensity value range varies from 10\u22124 to 10\u22120.5, revealing the HDR property of equivalent light intensity. Therefore, we treat the equivalent light intensity prediction from the image observations and calibrated lighting directions as a regression problem, which is different from the classification loss in LC-Net [4]. Given the ground-truth equivalent lighting\nintensity, we supervise the ELIE-Net by the `2 regression loss:\nLins = \u2016s\u2212 s\u0302\u201622 , (6)\nwhere s and s\u0302 correspond to the GT and predicted equivalent lighting intensity.\nSNE module With the estimated equivalent lighting intensities, we can then normalize the input multispectral images at corresponding spectral bands with equal lighting intensities. With these normalized image observations (I\u2032 in Fig. 4) as well as the calibrated lighting directions as inputs, our SNE module recovers the surface normal map with considering the geometric component only. As discussed in Sec. 3, any existing non-Lambertian CPS methods can be used as our SNE module. In this paper, we discuss and test the stateof-the-art CPS method PS-FCN [5] as our SNE module. For better collaboration between the proposed ELIE-Net and the SNE module, the PS-FCN is re-trained on the proposed multispectral dataset \u201cPS-Spectral\u201d, as we will show in the next. Following the training strategy of PS-FCN [5], the loss function is defined as the cosine similarity loss of the surface normal:\nLn = 1\np p\u2211 i=1 (1\u2212 n>i n\u0302i), (7)\nwhere p is the number of valid pixels in the object mask, ni and n\u0302i denote the ground-truth and estimated surface normal vectors at the i-th pixel position.\nDifference from SDPS-Net As discussed above, our network structure is similar to SDPS-Net [4]. Here we elaborate on the differences between our work and SDPS-Net [4]. Firstly, SDPS [4] focuses on the non-Lambertian uncalibrated CPS problem, which has a completely different image formation from the non-Lambertian MPS problem that\nwe focus on. In this paper, we embed the distribution of spectral bands into equivalent light intensity mathematically to ease the difficulties in solving the non-Lambertian MPS problem. Secondly, PS-FCN in [5] is chosen as the SNE module for illustration of the proposed method. In fact, any existing CPS methods can be utilized as SNE module. Thirdly, the network design of the prediction head of ELIENet is different from the LC-Net [4] due to their different purposes and inputs/outputs.\n\u201cPS-Spectral\u201d Dataset For training and testing, we build a synthetic dataset with shapes from the Blobby dataset [13] as well as the Sculpture dataset [25], where each shape is rendered with 51 measured isotropic spectral BRDFs [7].\nFor one object, the image observation tensor and the corresponding spectral reflectance tensor have the size of [f, p, t], denoting the number of light directions, pixels in the image, and spectral bands, respectively. In MPS task, each lighting direction corresponds to one wavelength band, therefore we randomly select t out of f directions to produce one multispectral image data with the size of [t, p, t]. In this work, we select f = 39 lighting directions distributed uniformly, and t = 195 spectral bands following the same wavelength range of [7]. The image resolution in our rendering is set as 128 \u00d7 128. To generate the groundtruth equivalent lighting intensity, we conduct the SVD decomposition on the spectral reflectance tensor R with our SRD model. We also render a test dataset including two shapes: SPHERE and BUNNY. The spectral image observations of the test dataset are shown in Fig. 6.\nImplementation The two components ELIE-Net and SNE module of our NeuralMPS are trained separately. The ground truth equivalent light intensities are used as the supervised signal of ELIE-Net and the input of SNE module. To increase the lighting invariance of the model, we sim-\nulated the randomly distributed lighting effects in the real world by a multiplication factor ranging in (0.1, 1) on the SVD light intensity during training."
        },
        {
            "heading": "5. Experiments",
            "text": "In this section, we evaluate our method on both synthetic and real captured data. In Sec. 5.1, the accuracy of the proposed SRD model is verified on measured spectral BRDF database [7] firstly. Then, in Sec. 5.2 we compare our NeuralMPS with the state-of-the-art MPS method GO21 [10] on surface normal estimation on BUNNY and SPHERE test dataset. The comparison on surface normal recoveries with and without the ELIE-Net is also provided to evaluate effectiveness of our ELIE-Net module. Finally, in Sec. 5.3 we give the qualitative evaluation on real-captured data to verify our application on real scenarios."
        },
        {
            "heading": "5.1. Verification of the SRD Model",
            "text": "Our SRD model decomposes the spectral reflectance into the geometric and spectral components via SVD decomposition. We verify the accuracy of the SRD model on diverse measured spectral BRDFs [7]. Specifically, we first choose a sphere shape containing diverse surface normals and lighting directions with uniform distribution and then render image observations with 51 spectral BRDFs [7]. As mentioned in Sec. 4 and Eq. (2), the spectral reflectance can be concentrated as a matrix R with shape [f, p, t]. With our SRD mode, R is decomposed into geometric component Rg of shape [f, p] and spectral component rs of shape [t] via SVD. In the case of spectral Lambertian assumption [10], the geometric component is an all-in-one matrix, Rg = 1. Therefore, we find the spectral component rs in the Lambertian case that best fit Rg and R via least-square.\nWe reconstruct the reflectance matrix R\u2032 = Rg \u2297Rs via tensor multiplication on the geometric and spectral component obtained by our SRD model and the Lambertian case. To measure reconstruction error Er over 51 measured materials, we use Frobenius norm between GT and reconstructed spectral reflectance, i.e.,\nEr = 1\n51 \u2211 i \u2016Ri \u2212R\u2032i\u2016F . (8)\nAs shown in Fig. 7 (top), the reconstructed spectral reflectance from our SRD model is more accurate than the Lambertian assumption used in GO21 [10], revealing the effectiveness of our SRD model for general non-Lambertian spectral reflectance. Besides, we found that the reconstruction errors with t = 12 bands as well as t = 195 bands have little difference. Therefore, our SRD model can be applied to real-world multispectral cameras with limited spectral bands.\nFrom Fig. 7 we observe that our SRD model works well for most materials. However, there are materials (e.g.,\n\u201ccc ibiza sunset\u201d) showing varying spectral characteristics under different lighting directions, as shown on the top of the Fig. 7. The spectral BRDFs for these materials violate our SRD model which assumes the spectral component is independent of the geometric component, like the monochromatic material \u201cpaper blue\u201d. In our NeuralMPS, we drop the last 9 materials whose reconstruction errors are larger than 0.05 during the training."
        },
        {
            "heading": "5.2. Evaluation of NeuralMPS",
            "text": "As shown in Fig. 7 (bottom), we show the normal estimation result on the SPHERE test dataset. Benefiting from our SRD model and designed network for non-Lambertian MPS, the surface normal estimation of our method is more accurate compared with the state-of-the-art MPS method GO21 [10] on diverse materials, revealing the strength of our method on general spectral reflectance.\nEffectiveness of ELIE-Net As shown in Table 1, to demonstrate the effectiveness of ELIE-Net, we test our NeuralMPS with and without the module on synthetic data SPHERE and BUNNY. Specifically, \u201cw/o\u201d or \u201cw/\u201d in the first column refers to results generated by feeding SNE module with all-one vector or equivalent light intensities estimated by \u201cELIE-Net \u201d. Based on the mean angular error of the surface normal estimates over the test dataset, the absence of equivalent light intensities leads to a performance drop in normal prediction. Therefore, the CPS method used in our SNE module (\u201cw/o ELIE-Net\u201d) cannot be used for solving the MPS task. It is necessary to predict the equivalent lighting intensity including the spectral component of the spectral reflectance with our proposed ELIE-Net."
        },
        {
            "heading": "5.3. Experiments on Real Data",
            "text": "As shown in Fig. 8, We test our method on real multispectral images of non-Lambertian surfaces captured by GO21 [10]. Taking the spectral image observations and calibrated lighting directions as input, we compare our NeuralMPS with existing MPS methods CS16 [3] and GO21 [10] on surface normal recovery. As CS16 [3] takes only three-channel RGB images as input, we select the image observations with the wavelength 450, 550, and 650 [nm] to mimic the RGB input. For GO21 [10] and our method, we test the methods on multispectral images with 12 and 4 spectral bands (labeled as f4 and f12) to evaluate the application on real-world multispectral cameras with varying spectral channels. Since the ground-truth surface normal and shape are not available for the real captured data, we conduct a qualitative evaluation by comparing the integrated shape from the surface normal map following [27].\nAs shown in Fig. 8, we show the estimated surface normals from existing methods and ours. As CS16 [3] mainly focuses on Lambertian reflectance, the recovered shape is distorted due to the specular highlights, as highlighted in the closed-up views. GO21 [10] is adapted to arbitrarily many spectral bands as the input and removes the spec-\nImage observation\nCS16\nGO21 (\ud835\udc53!)\nOurs (\ud835\udc53!)\nGO21(\ud835\udc53\"#)\nOurs (\ud835\udc53\"#)\nDOG BUDDHA CORN DISK\nFigure 8: Qualitative comparison with existing MPS methods on real data. Shape distortions caused by non-Lambertian specular highlights are emphasized in the closed-up views.\nular highlights and shadows as outliers with the position thresholding strategy [21]. Therefore, the shape recoveries from GO21 (f12) are reasonable with 12 spectral bands as input. However, the method fails with limited spectral input (GO21 (f4)), as the position thresholding strategy prefers more data for the outlier removal. Compared with existing methods, our NeuralMPS achieves reasonable surface normal estimation results for all four objects. The recovered shapes have no distortions caused by specular highlights. Since our method learns the non-Lambertian spectral reflectance from the measured spectral BRDF dataset, rather than treating it as outliers, the recovered surface normal under limited spectral bands remains in good quality, as shown in Ours (f4)."
        },
        {
            "heading": "6. Conclusion",
            "text": "In this paper, we propose a multispectral photometric stereo method NeuralMPS for surface normal recovery under non-Lambertian spectral reflectance. The spectral reflectance decomposition model is the key for our method,\nwhich represents spectral reflectance as a composition of geometry components and spectral components. In this way, the non-Lambertian MPS problem can be recast into the well-studied non-Lambertian CPS problem with unknown equivalent light intensity in which the spectral component is embedded. As a result, we design the ELIE-Net and the SNE module to estimate the equivalent light intensity and further recover the surface normal in MPS.\nLimitation We assume the surface is covered by uniform material so that the spectral reflectance can be decomposed into a global spectral component and geometric component. Intuitively, our NeuralMPS works on monochromatic targets as shown in Fig. 8. It is desirable to consider more general spatially-varying non-Lambertian spectral reflectance. As real-world surfaces are mostly covered by limited materials, one possible solution is adopting material classification and segmenting the surface into regions with uniform materials. Our NeuralMPS can be then applied for surface normal recovery for each sub-region."
        }
    ],
    "title": "NeuralMPS: Non-Lambertian Multispectral Photometric Stereo via Spectral Reflectance Decomposition",
    "year": 2022
}