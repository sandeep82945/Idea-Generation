{
    "abstractText": "Research Center for Healthcare Data Science, Zhejiang Lab, Hangzhou 311121, China AI Research Center for Medical Image Analysis and Diagnosis, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong 518060, China Department of Computer Science, COMSATS University Islamabad, Abbottabad Campus, Tobe Camp, Abbottabad 22060, Pakistan Computer Science Department MNS-University of Agriculture, Multan 60650, Pakistan Software Competence Center Hagenberg GmbH, Softwarepark, Hagenberg, Linz, Austria Pak-Austria Fachhochschule-Institute of Applied Sciences and Technology, Mang, Haripur, Pakistan Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China Lappeenranta University of Technology, Department of Information Technology, Lappeenranta 53851, Finland IoT Research Center, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong 518060, China Centre for VLSI and Embedded System Technologies, International Institute of Information Technology, Hyderabad, Telangana 500032, India Department of Science and Engineering, Novel Global Community Educational Foundation, Hebersham, NSW 2770, Australia Department of Physics, Integrated Science Lab (IceLab), Umea University, Umea 90187, Sweden",
    "authors": [
        {
            "affiliations": [],
            "name": "Syed Furqan Qadri"
        },
        {
            "affiliations": [],
            "name": "Hongxiang Lin"
        },
        {
            "affiliations": [],
            "name": "Linlin Shen"
        },
        {
            "affiliations": [],
            "name": "Mubashir Ahmad"
        },
        {
            "affiliations": [],
            "name": "Salman Qadri"
        },
        {
            "affiliations": [],
            "name": "Salabat Khan"
        },
        {
            "affiliations": [],
            "name": "Maqbool Khan"
        },
        {
            "affiliations": [],
            "name": "Syeda Shamaila Zareen"
        },
        {
            "affiliations": [],
            "name": "Muhammad Azeem Akbar"
        },
        {
            "affiliations": [],
            "name": "Md Belal"
        },
        {
            "affiliations": [],
            "name": "Bin Heyat"
        },
        {
            "affiliations": [],
            "name": "Saqib Qamar"
        }
    ],
    "id": "SP:f2748ad89fd8073428d0b47ce7d8139a2f49afef",
    "references": [
        {
            "authors": [
                "D.P. Anitha",
                "T. Baum",
                "J.S. Kirschke",
                "K. Subburaj"
            ],
            "title": "Efect of the intervertebral disc on vertebral bone strength prediction: a fnite-element study",
            "venue": "Te Spine Journal, vol. 20, no. 4, pp. 665\u2013671, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "M.T. L\u00f6fer",
                "N. Sollmann",
                "K. Mei"
            ],
            "title": "X-ray-based quantitative osteoporosis imaging at the spine",
            "venue": "Osteoporosis International, vol. 31, no. 2, pp. 233\u2013250, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "F. Laouissat",
                "A. Sebaaly",
                "M. Gehrchen",
                "P. Roussouly"
            ],
            "title": "Classifcation of normal sagittal spine alignment: refounding the Roussouly classifcation",
            "venue": "European Spine Journal, vol. 27, no. 8, pp. 2002\u20132011, 2018.",
            "year": 2002
        },
        {
            "authors": [
                "T.R. Oxland"
            ],
            "title": "Fundamental biomechanics of the spine\u2014what we have learned in the past 25 years and future directions",
            "venue": "Journal of Biomechanics, vol. 49, no. 6, pp. 817\u2013832, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S.F. Qadri",
                "M. Ahmad",
                "D. Ai",
                "J. Yang",
                "Y. Wang"
            ],
            "title": "Deep belief network based vertebra segmentation for CT images",
            "venue": "Chinese Conference on Image and Graphics Technologies, vol. 757, pp. 536\u2013545, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "M. Pereanez",
                "K. Lekadir",
                "I. Castro-Mateos",
                "J.M. Pozo",
                "A. Lazary",
                "A.F. Frangi"
            ],
            "title": "Accurate Segmentation of Vertebral Bodies and Processes Using Statistical Shape Decomposition and Conditional Models",
            "venue": "IEEE Trans. Med. Imaging, vol. 34, no. 8, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "I. Castro-Mateos",
                "J.M. Pozo",
                "M. Perea\u00f1ez",
                "K. Lekadir",
                "A. Lazary",
                "A.F. Frangi"
            ],
            "title": "Statistical interspace models (SIMs): application to robust 3D spine segmentation",
            "venue": "IEEE Transactions on Medical Imaging, vol. 34, no. 8, pp. 1663\u2013 1675, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "A. Rasoulian",
                "R. Rohling",
                "P. Abolmaesumi"
            ],
            "title": "Lumbar spine segmentation using a statistical multi-vertebrae anatomical shape + pose model",
            "venue": "IEEE Transactions on Medical Imaging, vol. 32, no. 10, pp. 1890\u20131900, 2013.",
            "year": 1890
        },
        {
            "authors": [
                "B. Ibragimov",
                "R. Korez",
                "B. Likar",
                "F. Pernu\u0161",
                "L. Xing",
                "T. Vrtovec"
            ],
            "title": "Segmentation of pathological structures by landmark-assisted deformable models",
            "venue": "IEEE Transactions on Medical Imaging, vol. 36, no. 7, pp. 1457\u20131469, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "B. Ibragimov",
                "B. Likar",
                "F. Pernu\u0161",
                "T. Vrtovec"
            ],
            "title": "Shape representation for efcient landmark-based segmentation in 3-D",
            "venue": "IEEE Transactions on Medical Imaging, vol. 33, no. 4, pp. 861\u2013874, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "S. Kadoury",
                "H. Labelle",
                "N. Paragios"
            ],
            "title": "Spine segmentation in medical images using manifold embeddings and higherorder MRFs",
            "venue": "IEEE Transactions on Medical Imaging, vol. 32, no. 7, pp. 1227\u20131238, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "S. Kadoury",
                "H. Labelle",
                "N. Paragios"
            ],
            "title": "Automatic inference of articulated spine models in CT images using high-order Markov Random Fields",
            "venue": "Medical Image Analysis, vol. 15, no. 4, pp. 426\u2013437, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "J.S. Athertya",
                "G. Saravana Kumar"
            ],
            "title": "Automatic segmentation of vertebral contours from CT images using fuzzy corners",
            "venue": "Computers in Biology and Medicine, vol. 72, pp. 75\u201389, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "K. Hammernik",
                "T. Ebner",
                "D. Stern",
                "M. Urschler",
                "T. Pock"
            ],
            "title": "Vertebrae segmentation in 3D CT images based on a variational framework",
            "venue": "Recent Advances in Computational Methods and Clinical Applications for Spine Imaging, pp. 227\u2013233, Springer, Berlin, Germany, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "P.H. Lim",
                "U. Bagci",
                "L. Bai"
            ],
            "title": "A robust segmentation framework for spine trauma diagnosis",
            "venue": "Computational Methods and Clinical Applications for Spine Imaging, pp. 25\u201333, Springer, Berlin, Germany, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "R. Korez",
                "B. Ibragimov",
                "B. Likar",
                "F. Pernu\u0161",
                "T. Vrtovec"
            ],
            "title": "A framework for automated spine and vertebrae interpolationbased detection and model-based segmentation",
            "venue": "IEEE Transactions on Medical Imaging, vol. 34, no. 8, pp. 1649\u2013 1662, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "A. Suzani",
                "A. Rasoulian",
                "A. Seitel",
                "S. Fels",
                "R.N. Rohling",
                "P. Abolmaesumi"
            ],
            "title": "Deep learning for automatic localization, identifcation, and segmentation of vertebral bodies in volumetric MR images",
            "venue": "Proceedings of the Medical Imaging 2015: Image-Guided Procedures, Robotic Interventions, and Modeling, Article ID 941514, Orlando, Florida, February 2015.",
            "year": 2015
        },
        {
            "authors": [
                "C. Chu",
                "D.L. Belav\u00fd",
                "G. Armbrecht",
                "M. Bansmann",
                "D. Felsenberg",
                "G. Zheng"
            ],
            "title": "Fully automatic localization and segmentation of 3D vertebral bodies from CT/MR images via a learning-based method",
            "venue": "PLoS One, vol. 10, no. 11, p. e0143327, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "R. Korez",
                "B. Likar",
                "F. Pernu\u0161",
                "T. Vrtovec"
            ],
            "title": "Model-based segmentation of vertebral bodies from MR images with 3D CNNs",
            "venue": "Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 433\u2013441, Athens, Greece, October 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S.F. Qadri",
                "L. Shen",
                "M. Ahmad",
                "S. Qadri",
                "S.S. Zareen",
                "S. Khan"
            ],
            "title": "OP-convNet a patch classifcation based framework for CT vertebrae segmentation",
            "venue": "IEEE Access, vol. 9, pp. 158227\u2013158240, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A. Sekuboyina",
                "J. Kuka\u010dka",
                "J.S. Kirschke",
                "B.H. Menze",
                "A. Valentinitsch"
            ],
            "title": "Attention-driven deep learning for pathological spine segmentation",
            "venue": "Proceedings of the International Workshop and Challenge on Computational Methods and Clinical Applications inMusculoskeletal Imaging, pp. 108\u2013119, Canada, September 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A. Sekuboyina",
                "A. Valentinitsch",
                "J.S. Kirschke",
                "B.H. Menze"
            ],
            "title": "A Localisation-Segmentation Approach for Multi-Label Annotation of Lumbar Vertebrae Using Deep Nets",
            "venue": "2017, https://arxiv.org/abs/1703.04347. International Journal of Intelligent Systems 13",
            "year": 2017
        },
        {
            "authors": [
                "R. Janssens",
                "G. Zeng",
                "G. Zheng"
            ],
            "title": "Fully automatic segmentation of lumbar vertebrae from CT images using cascaded 3D fully convolutional networks",
            "venue": "Proceedings of the 2018 IEEE 15th International Symposium on Biomedical Imaging, pp. 893\u2013897, ISBI 2018, Washington, DC, USA, April 2018.",
            "year": 2018
        },
        {
            "authors": [
                "N. Lessmann",
                "B. van Ginneken",
                "I. I\u0161gum"
            ],
            "title": "Iterative convolutional neural networks for automatic vertebra identifcation and segmentation in CT images",
            "venue": "Medical Imaging 2018 Image Processing, vol. 10574, Article ID 1057408, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "N. Lessmann",
                "B. van Ginneken",
                "P.A. de Jong",
                "I. I\u0161gum"
            ],
            "title": "Iterative fully convolutional neural networks for automatic vertebra segmentation and identifcation",
            "venue": "Medical Image Analysis, vol. 53, pp. 142\u2013155, Apr. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "C. Payer",
                "D. \u0160tern",
                "H. Bischof",
                "M. Urschler"
            ],
            "title": "Coarse to fne vertebrae localization and segmentation with SpatialConfguration-net and U-net",
            "venue": "Proceedings of the 15th International Joint Conference on Computer Vision Imaging and Computer Graphics Teory and Applications, pp. 124\u2013133, Valletta, Malta, January 2020.",
            "year": 2020
        },
        {
            "authors": [
                "G.E. Hinton",
                "R.R. Salakhutdinov"
            ],
            "title": "Reducing the dimensionality of data with neural networks",
            "venue": "Science, vol. 313, no. 5786, pp. 504\u2013507, Jul. 2006.",
            "year": 2006
        },
        {
            "authors": [
                "H.-C. Shin",
                "M.R. Orton",
                "D.J. Collins",
                "S.J. Doran",
                "M.O. Leach"
            ],
            "title": "Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 8, pp. 1930\u20131943, 2012.",
            "year": 1930
        },
        {
            "authors": [
                "M.A. Aslam",
                "C. Xue",
                "Y. Chen"
            ],
            "title": "Breath analysis based early gastric cancer classifcation from deep stacked sparse autoencoder neural network",
            "venue": "Scientifc Reports, vol. 11, no. 1, pp. 1\u201312, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "G.B. Praveen",
                "A. Agrawal",
                "P. Sundaram",
                "S. Sardesai"
            ],
            "title": "Ischemic stroke lesion segmentation using stacked sparse autoencoder",
            "venue": "Computers in Biology and Medicine, vol. 99, no. May, pp. 38\u201352, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S.F. Qadri",
                "Z. Zhao",
                "D. Ai",
                "M. Ahmad",
                "Y. Wang"
            ],
            "title": "Vertebrae segmentation via stacked sparse autoencoder from computed tomography images",
            "venue": "Proceedings of the Eleventh International Conference on Digital Image Processing, Guangzhou, China, Auguest 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Guo",
                "Y. Gao",
                "D. Shen"
            ],
            "title": "Deformable MR prostate segmentation via deep feature learning and sparse patch matching",
            "venue": "IEEE Transactions on Medical Imaging, vol. 35, no. 4, pp. 1077\u20131089, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "J. Xu",
                "L. Xiang",
                "Q. Liu"
            ],
            "title": "Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images",
            "venue": "IEEE Transactions on Medical Imaging, vol. 35, no. 1, pp. 119\u2013130, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "X. Wang",
                "S. Zhai",
                "Y. Niu"
            ],
            "title": "Automatic vertebrae localization and identifcation by combining deep SSAE contextual features and structured regression forest",
            "venue": "Journal of Digital Imaging, vol. 32, no. 2, pp. 336\u2013348, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "S. Li",
                "H. Jiang",
                "J. Bai",
                "Y. Liu",
                "Y. d. Yao"
            ],
            "title": "Stacked sparse autoencoder and case-based postprocessing method for nucleus detection,\u201dNeurocomputing",
            "year": 2019
        },
        {
            "authors": [
                "S. Li",
                "H. Lei",
                "F. Zhou",
                "J. Gardezi",
                "B. Lei"
            ],
            "title": "Longitudinal and multi-modal data learning for Parkinson\u2019s disease diagnosis via stacked sparse auto-encoder",
            "venue": "Proceedings of the2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), pp. 384\u2013387, Venice, Italy, April 2019.",
            "year": 2019
        },
        {
            "authors": [
                "S.F. Qadri",
                "L. Shen",
                "M. Ahmad",
                "S. Qadri",
                "S.S. Zareen",
                "M.A. Akbar"
            ],
            "title": "SVseg: stacked sparse autoencoder-based patch classifcation modeling for vertebrae segmentation",
            "venue": "Mathematics, vol. 10, no. 5, p. 796, Mar. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "J. Jantzen",
                "J. Norup",
                "G. Dounias",
                "B. Bjerregaard"
            ],
            "title": "Papsmear benchmark data for pattern classifcation",
            "venue": "Proceedings of the Nature inspired Smart Information Systems (NiSIS), pp. 1\u20139, Albufeira, Portugal, 2005.",
            "year": 2005
        },
        {
            "authors": [
                "H.-C. Shin",
                "H.R. Roth",
                "M. Gao"
            ],
            "title": "Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning",
            "venue": "IEEE Transactions on Medical Imaging, vol. 35, no. 5, pp. 1285\u2013 1298, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "M.F. M\u00f8ller"
            ],
            "title": "A scaled conjugate gradient algorithm for fast supervised learning",
            "venue": "Neural Networks, vol. 6, no. 4, pp. 525\u2013533, 1993.",
            "year": 1993
        },
        {
            "authors": [
                "Y. Kang",
                "K. Engelke",
                "W.A. Kalender"
            ],
            "title": "A new accurate and precise 3-D segmentation method for skeletal structures in volumetric CT data",
            "venue": "IEEE Transactions on Medical Imaging, vol. 22, no. 5, pp. 586\u2013598, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "J. Yao",
                "J.E. Burns",
                "D. Forsberg"
            ],
            "title": "A multi-center milestone study of clinical vertebral CT segmentation",
            "venue": "Computerized Medical Imaging and Graphics, vol. 49, pp. 16\u201328, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "M.T. L\u00f6fer",
                "A. Sekuboyina",
                "A. Jacob"
            ],
            "title": "A vertebral segmentation dataset with fracture grading",
            "venue": "Radiology: Artifcial Intelligence, vol. 2, no. 4, Article ID 190138, 2020.",
            "year": 1901
        },
        {
            "authors": [
                "H. Liebl",
                "D. Schinz",
                "A. Sekuboyina"
            ],
            "title": "A computed tomography vertebral segmentation dataset with anatomical variations and multi-vendor scanner data",
            "venue": "Scientifc Data, vol. 8, no. 1, p. 284, Dec. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "A.A. Taha",
                "A. Hanbury"
            ],
            "title": "Metrics for evaluating 3D medical image segmentation: analysis, selection, and tool",
            "venue": "BMC Medical Imaging, vol. 15, no. 1, p. 29, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "P. Jaccard"
            ],
            "title": "Te distribution of the fora in the alpine zone. 1",
            "venue": "New Phytologist, vol. 11, no. 2, pp. 37\u201350, 1912.",
            "year": 1912
        },
        {
            "authors": [
                "L.R. Dice"
            ],
            "title": "Measures of the amount of ecologic association between species",
            "venue": "Ecology, vol. 26, no. 3, pp. 297\u2013302, 1945.",
            "year": 1945
        },
        {
            "authors": [
                "S. Pang",
                "C. Pang",
                "L. Zhao"
            ],
            "title": "SpineParseNet: spine parsing for volumetric MR image by a two-stage segmentation framework with semantic image representation",
            "venue": "IEEE Transactions on Medical Imaging, vol. 40, no. 1, pp. 262\u2013273, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S.F. Qadri"
            ],
            "title": "Automatic deep feature learning via patch-based deep belief network for vertebrae segmentation in CTimages",
            "venue": "Applied Sciences, vol. 9, no. 1, p. 69, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "H. Lee",
                "R. Grosse",
                "R. Ranganath",
                "A.Y. Ng"
            ],
            "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations",
            "venue": "Proceedings of the 26th Annual International Conference on Machine Learning, pp. 609\u2013616, Montreal Quebec Canada, July 2009.",
            "year": 2009
        },
        {
            "authors": [
                "O. Ronneberger",
                "P. Fischer",
                "T. Brox"
            ],
            "title": "U-net: convolutional networks for biomedical image segmentation",
            "venue": "Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234\u2013241, Munich, Germany, October 2015.",
            "year": 2015
        },
        {
            "authors": [
                "R. Wang",
                "J.H. Yi Voon",
                "D. Ma",
                "S. Dabiri",
                "K. Popuri",
                "M.F. Beg"
            ],
            "title": "Vertebra segmentation for clinical CT images using mask R-CNN",
            "venue": "IFMBE Proceedings, vol. 80, pp. 1156\u2013 1165, 2021. 14 International Journal of Intelligent Systems",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "Research Article",
            "text": ""
        },
        {
            "heading": "CT-Based Automatic Spine Segmentation Using Patch-Based",
            "text": ""
        },
        {
            "heading": "Deep Learning",
            "text": "Syed Furqan Qadri ,1,2 Hongxiang Lin ,1 Linlin Shen ,2 Mubashir Ahmad ,3 Salman Qadri ,4 Salabat Khan ,2 Maqbool Khan ,5,6 Syeda Shamaila Zareen ,7 Muhammad Azeem Akbar,8 Md Belal Bin Heyat ,9,10,11 and Saqib Qamar12\n1Research Center for Healthcare Data Science, Zhejiang Lab, Hangzhou 311121, China 2AI Research Center for Medical Image Analysis and Diagnosis, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong 518060, China 3Department of Computer Science, COMSATS University Islamabad, Abbottabad Campus, Tobe Camp, Abbottabad 22060, Pakistan 4Computer Science Department MNS-University of Agriculture, Multan 60650, Pakistan 5Software Competence Center Hagenberg GmbH, Softwarepark, Hagenberg, Linz, Austria 6Pak-Austria Fachhochschule-Institute of Applied Sciences and Technology, Mang, Haripur, Pakistan 7Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China 8Lappeenranta University of Technology, Department of Information Technology, Lappeenranta 53851, Finland 9IoT Research Center, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, Guangdong 518060, China 10Centre for VLSI and Embedded System Technologies, International Institute of Information Technology, Hyderabad, Telangana 500032, India 11Department of Science and Engineering, Novel Global Community Educational Foundation, Hebersham, NSW 2770, Australia 12Department of Physics, Integrated Science Lab (IceLab), Umea University, Umea 90187, Sweden\nCorrespondence should be addressed to Syed Furqan Qadri; furqangillani79@gmail.com, Hongxiang Lin; hxlin@zhejianglab.edu.cn, and Linlin Shen; llshen@szu.edu.cn\nReceived 17 November 2022; Revised 13 January 2023; Accepted 31 January 2023; Published 4 March 2023\nAcademic Editor: Alexander Hos\u030covsky\u0301\nCopyright \u00a9 2023 Syed Furqan Qadri et al. Tis is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nCTvertebral segmentation plays an essential role in various clinical applications, such as computer-assisted surgical interventions, assessment of spinal abnormalities, and vertebral compression fractures. Automatic CTvertebral segmentation is challenging due to the overlapping shadows of thoracoabdominal structures such as the lungs, bony structures such as the ribs, and other issues such as ambiguous object borders, complicated spine architecture, patient variability, and fuctuations in image contrast. Deep learning is an emerging technique for disease diagnosis in the medical feld. Tis study proposes a patch-based deep learning approach to extract the discriminative features from unlabeled data using a stacked sparse autoencoder (SSAE). 2D slices from a CT volume are divided into overlapping patches fed into the model for training. A random under sampling (RUS)-module is applied to balance the training data by selecting a subset of the majority class. SSAE uses pixel intensities alone to learn high-level features to recognize distinctive features from image patches. Each image is subjected to a sliding window operation to express image patches using autoencoder high-level features, which are then fed into a sigmoid layer to classify whether each patch is a vertebra or not. We validate our approach on three diverse publicly available datasets: VerSe, CSI-Seg, and the Lumbar CT dataset. Our proposed method outperformed other models after confguration optimization by achieving 89.9% in precision, 90.2% in recall, 98.9% in accuracy, 90.4% in F-score, 82.6% in intersection over union (IoU), and 90.2% in Dice coefcient (DC). Te results of this study demonstrate that our model\u2019s performance consistency using a variety of validation strategies is fexible, fast, and generalizable, making it suited for clinical application.\nHindawi International Journal of Intelligent Systems Volume 2023, Article ID 2345835, 14 pages https://doi.org/10.1155/2023/2345835"
        },
        {
            "heading": "1. Introduction",
            "text": "Te spine plays a key function in mobility and weight transfer in the musculoskeletal system while supporting and sustaining the body and organ structure. It also protects the spinal cord from mechanical shocks and injuries. A number of techniques are used to understand better and quantify the human spine\u2019s biomechanics, including vertebral fnite element modeling [1], quantitative imaging [2], spinal alignment analysis [3], and complicated biomechanical models [4]. Biomechanical changes can result in disability and severe discomfort in the short term but can have far worse long-term complications, such as an eightfold higher mortality rate due to osteoporosis. Despite their critical nature, spine diseases are frequently underdiagnosed. Tis necessitates using a computer-aided approach to detecting such pathologies early and efciently, allowing for their prevention and efective treatment.\nOver the years, the medical imaging community has paid increasing attention to the study of spine image analysis, and vertebrae segmentation [5] is an essential step in comprehending it. Vertebra segmentation has diagnostic signifcance for detecting and classifying vertebral fractures, estimating the spine curve, and recognizing spine deformities such as kyphosis and scoliosis. Aside from diagnostic purposes, these tasks help with fnite element modeling analysis, biomechanical modeling, and surgical planning for metal implantations. Annotating huge structures needs a lot of time, making manual segmentation impractical. A consistent and precise manual delineation is also difcult due to the complicated shape of posterior vertebral components and lower scan resolutions. Various problems exist in automating these tasks, including datasets with highly variable felds of vision, scans in large sizes, scan noise with highly correlated forms of nearby vertebrae, fuctuating scanner settings, and multiple anomalies or pathologies.\nVertebral segmentation traditionally relied on modelbased techniques, which ft a shape before the spine and then distort it to conform to its shape. Statistical shape models [6\u20138], geometric models [9, 10], Markov random felds (MRF) [11, 12], and active contours [13] are all used as prior shape models. Other approaches use intensities such as a priori variational intensity models [14], level sets [15], and automatic vertebrae segmentation from shape models based on landmark frameworks [16]. Machine learning has recently become more popular for the segmentation of vertebrae. A. Suzani et al. [17] detected vertebral structures with a multilayer perceptron (MLP) and segmented them using deformable registration. Similarly, Chu et al. [18] identifed and located the vertebrae using random forest regression followed by segmentation at the voxel level using random forest classifcation. R. Korez et al. [19] employed 3D convolutional neural networks (CNNs) to learn vertebral appearances and forecast probability maps that guided the deformable model\u2019s boundaries for vertebral body\u2019s segmentation.\nRecent years have seen an increase in the popularity of deep learning for vertebral segmentation, and many published approaches used convolutional [20] and recurrent neural networks instead of explicit modeling of vertebral appearance and shape. Te growing popularity of deep learning in vertebral segmentation and greater processing power have prompted researchers to produce promising results. A. Sekuboyina et al. [21] used U-Net to perform patch-based binary segmentation and then denoise the vertebrae masks heat maps with a low resolution. In their other work [22], two diferent types of neural networks were used to segment lumbar vertebrae. First, a simple multilayer perceptron is trained to regress the lumbar region localization, and then a U-Net is trained to perform multiclass segmentation. Janssens et al. [23] improved this by substituting a CNN for the multilayer perceptron and using two sequential CNNs for lumbar vertebrae multiclass segmentation. Using a two-stage iterative technique, Lessmann et al. [24] frst identifed and segmented lower-resolution vertebrae one after the other and then refned the masks with a low resolution using a second CNN. Tese fndings led to the development of a single-phase fully convolutional network by Lessmann et al. [25] that iteratively regressed and segmented the vertebral anatomical label. A maximum likelihood technique is used to adjust the vertebral labels after the complete scan has been segmented. A diferent strategy is proposed by Payer et al. [26], using a coarse-to-fne technique including three steps: vertebra labeling, spine localization, and vertebrae segmentation, all of which rely on purposely built fully convolutional networks.\nOne limitation of the methodologies described previously was complicated network modeling. As an alternative to the approaches stated previously, it is argued to further improve vertebrae segmentation outcomes. Contextual high-level features that may capture more discriminative sample feature representation are exploited using a regression model to segment the vertebrae in CT images. With the fast advancement of deep learning, an increasing number of deep learning techniques specifcally stacked sparse autoencoders (SSAEs), have been applied to medical images since Hinton and Salakhutdinov [27], and they developed the frst deep autoencoder network. Shin et al. [28] used stacked autoencoders in MRI to identify organs in medical imaging to show the potential of the deep learning technique to be applied in medical image analysis. Many complex medical imaging problems have been addressed using it. For example, CAD system to classify gastric cancer from the breath samples using SSAE [29], stroke lesions segmentation using sparse autoencoder (SAE) layers, followed by support vector machine (SVM) classifer [30], SSAE-based modeling for the vertebrae segmentation [31], deformable prostate segmentation method [32], nuclei detection from histopathological images of breast cancer [33], an automatic vertebrae localization and identifcation by SSAE and structured regression forest [34], an automated nucleus detection [35], and Parkinson\u2019s disease diagnosis\nmodeling also based on stacked sparse autoencoder framework [36].\nBased on the previous work [37], we presented CT-based automatic spine segmentation utilizing patch-based deep learning and new PE and RUS-modules were proposed. Te PE-module is used to extract overlapping image patches and label them with a certain pixel ratio, while the RUS-module is employed to address the class imbalance problem. We tested the generalizability and fexibility of our model on three publically available datasets (VerSe, CSI-Seg, and the Lumbar dataset) to show that it is well-suited for clinical application, which was not done in preliminary work [37]. Te proposed work is a fully connected framework for high-level feature extraction using SSAE instead of convolutional neural network feature-based representation, which utilizes convolutional and subsampling techniques to extract features from a cluster of locally connected neurons via their local receptive felds. SSAE is a two-stage architecture with an encoderdecoder in which \u201cencoder\u201d encodes pixel intensities via low-dimensional features, while the \u201cdecoder\u201d architecture uses low-dimensional attributes to reconstruct the original pixel intensities. SSAE is a fully connected network that uses a single global weight matrix to represent features, while CNN is a model of partial connections that emphasizes the signifcance of locality. Notwithstanding this, SSAE extracts high-level features from the bottom up in an unsupervised manner. Tese efcient representations cause precise image patch classifcation, leading to more robust CT vertebrae segmentation. Terefore, we choose to employ SSAE rather than convolutional neural networks in this work. Te major contributions of this study are as follows:\n(i) PE-module is applied to extract overlapping patches from input slices of CT images. Splitting slices into patches enhances localization because the trained network is built to focus more on patches\u2019 local details.\n(ii) To classify vertebrae patches efectively (reducing false negatives), RUS-module is used to address the class imbalance problem by sampling an equivalent number of patches (vertebrae and nonvertebrae patches) in the training phase.\n(iii) Te pretraining step, an unsupervised feature learning module based on the SSAE framework, is used to learn high-level features from a large number of unlabeled image patches, while, in the fne-tuning step, these most discriminative sets of features are then subsequently fed to a sigmoid layer to classify each patch as vertebra or not.\n(iv) We designed a fve-layer SSAE architecture: one input layer, three hidden layers, and one output layer (sigmoid layer). We validated our approach on three diverse publicly available datasets (VerSe, CSISeg, and the Lumbar dataset) to demonstrate that our approach is fexible, fast, and generalizable, making it suited for clinical application.\nTe remaining paper is organized as follows: Section 2 briefy describes our proposed method, composed of six modules. Section 3 describes the experimentation, including datasets, performance evaluation, model training, and architecture optimization. Section 4 reports the results and discussion in detail. Finally, Section 5 concludes this work and ofers suggestions for future work."
        },
        {
            "heading": "2. Methods",
            "text": "Figure 1 illustrates that the proposed method consists of the following steps: (i) preprocessing, (ii) patch extraction module (PE-module), (iii) random under sampling (RUS)module, (iv) L2 regularized SSAE, (v) sigmoid regression, and (vi) postprocessing.\n2.1. Preprocessing. Temain aim of the preprocessing step is to increase the discrimination between vertebrae and other tissues by identifying bone pixels and removing noise from the image. We applied a threshold approach to eliminate noise artifacts from the whole CT scan. For this reason, infuences from the tissues around the vertebra, noise, and imaging artifacts are reduced by setting the intensity to zero outside the bone intensity range of 100HU (Hounsfeld unit) and 1,500HU automatically. Input spine CT scans are volumetric and must be processed slice by slice. Because the pixel intensities of vertebrae in CT scans are higher than those of other tissues, the applied threshold diferentiates them from soft tissues. However, vertebrae have similar intensities to other bones (such as the ribs), so we trained a deep learningmodel to discriminate between vertebrae and other bony structures in CT scans. Ten, a Gaussian flter with a sigma value of 2 is applied to the CT images to smooth them out and ensure that the image gradients are welldefned and there are no intensity singularities. Te data are normalized to a range of 0-1.\n2.2. PE-Module. PE-module is applied to extract n\u00d7 n size overlapping patches from the input CT images by taking a certain pixel stride (Figure 2). A 32\u00d7 32 patch-sized image contains 1024 pixels in total.Te patch is labeled 1 (vertebra) if the total pixels inside it are equal to or greater than 60%; otherwise, it is labeled 0 (background). PE-module uses a specifc pixel stride to construct overlapping patches from the 2D slices for the sliding window. PE-module is an image partition module employed successfully on a patch-based deep learning model for network training to improve classifcation accuracy.\n2.3. RUS-Module. After the PE-module, the number of image patches was unbalanced because the area occupied by the spine in the CT scans was so small compared to the background. Te classifer may be biased in the background because most patches are labeled as 0. A high sensitivity rate is preferable from a medical perspective, but on a practical\nlevel, a high false negative rate is unsuitable [38]. It is necessary to strike a balance between the size of the positive and negative training image patches to solve this dilemma.\nTe RUS-module is applied to balance the training data by selecting a subset of the majority class (background patches). Tis module deletes random image patches from the\nmajority class (Figure 3). Expressing class B as the majority and class F as the minority, the ratio of the size of the minority and majority classes is defned as r, and we performed RUS on B to achieve a balanced ratio of r. Te balanced r ratios after RUS-module were r (nonvertebrae patch)\ufffd 0.6 and r (vertebrae patch)\ufffd 0.4 that were unbalanced r ratios (nonvertebrae patch)\ufffd 0.94 and (vertebrae patch)\ufffd 0.06 before the RUS-module. Tis improves the network\u2019s accuracy and convergence rate during the model training [39]. However, the testing stage does not include a balanced class of image patches.\n2.4. L2 Regularized SSAE. A fundamental component of SSAE is an autoencoder (AE) composed of three layers: an input, a hidden layer, and an output. Te nodes in an AE\u2019s diferent layers are all fully connected. A multilayer neural\nnetwork can be formed by stacking multi-AEs. We improve the three-layer SSAE network by stacking three AEs (Figure 4). We pretrained the model using the greedy layer-wise SSAE approach. Due to the unsupervised nature of pretraining, the label (ground truth) information is not used. We consider that x \ufffd (x1, x2,...,xn) expresses the autoencoder input vector, y \ufffd (y1, y2,...,yn) expresses the reconstructed representation vector of x, and z \ufffd (z1, z2,...,zn) expresses k hidden node activation vector. Te autoencoder uses the weights w1 and bias b1 for encoding the input vector x to \ufffd f(w1x + b1) because it uses the intermediate hidden layer to rebuild input features on the output layer. In the hidden layer, activation vector y is decoded the z output using decoding weights w2 and bias b2 and then y maps the hidden layer latent representation to the output z by y \ufffd f(w2y + b2). We constructed an L2 regularized sparse autoencoder using the following cost function:\nE(W, b) \ufffd 1 p \np\nj\ufffd1 \nn\ni\ufffd1 yij \u2212 xij \n2 + \u03bb\u03a9weights + \u03b2\u03a9sparsity,\n(1)\nwhere W (weights) and b (bias) are the AE network parameters, mean squared error (MSE) is the frst part in equation, and p is the training data sample size. Te cost function\u2019s second portion is the L2 regularization on the encoding weights, where \u03a9weights \ufffd 1/2 p j\ufffd1 n i\ufffd1(wji)\n2 and \u03bb denotes the L2 regularization term\u2019s penalty coefcient. Sparsity regularization is the third portion of the cost function, where \u03b2 is the sparsity regularization coefcient and \u03a9sparsity is the Kullback\u2013Leibler (KL) divergence [28] which is expressed as follows:\n\u03a9sparsity \ufffd  k\ni\ufffd1 \u03c1log\n\u03c1j\u2032 \u03c1 +(1 \u2212 \u03c1)log 1 \u2212 \u03c1j\u2032 1 \u2212 \u03c1 , (2)\nwhere \u03c1i\u2032 \ufffd 1/p p j\ufffd1[zi(xj)] shows average activation of the hidden node j over training samples and \u03c1 is the predefned constant sparsity parameter. For a L2 regularized sparse autoencoder, the weights w and bias b can be optimized using the scaled conjugate gradient descent algorithm [40] to obtain the encoder of a sparse autoencoder.Te hidden layer z\u2019s output of layer L-1 autoencoder would be considered as input x of layer L autoencoder. Finally, L2 regularized SSAE is formed by stacking the multiple sparse AEs.\n2.5. Sigmoid Regression. As SSAE is an unsupervised learning approach, each network layer has been trained using unlabeled data. A feature vector was used to generate the input reconstruction. Te classifer uses these feature vectors to classify the input data of the stacked sparse autoencoder. We used a sigmoid regression layer to discriminate between vertebrae and nonvertebrae patches (Figure 4). MLP and SVM are other classifers that can be used instead of the sigmoid layer. Te MLP is a feedforward neural network with several layers and a large number of nodes in each layer that gets stuck in local\nminima due to the over-ftting problem. In contrast, SVM classifers determine whether a pixel is part of the target or background class based on its posterior probability value, but it takes a lot of generalization to produce a probability image by reconstructing the score vector. However, the sigmoid layer enables the joint to optimize the entire deep framework via fne-tuning. Sigmoid regression is a binary classifcation technique for supervised learning. Te output probabilities calculate each class label\u2019s likelihood based on the input data. Te sigmoid regression model\u2019s coefcient vector gets optimization by reducing the cost function.\n\u03c3(x) \ufffd 1\n1 + e\u2212 x , (3)\nwhere \u03c3 is the output sigmoid function and x is the input. At the stage of supervised learning, the pretrained SSAE and sigmoid layer are combined into a single model for classifcation. Using the scaled gradient descent approach [40], each iteration simultaneously updates the weights of all SSAE layers and all sigmoid layer parameters to fne-tune the whole model.\n2.6. Postprocessing. Following training, the trained model is validated using unseen test patches. Our study addresses two-class classifcation issues where the patch labels are 0 and 1, with 1 denoting vertebrae patches and 0 representing nonvertebrae patches, respectively. Te same preprocessing is applied to the CT scans used for testing. Input image patches are given to the trained model, which returns a value between 0 and 1, which can be analyzed as the probability that an image patch belongs to a vertebra or not. Te segmented binary image is created by reconstructing the predicted image patches based on these results. Due to the high contrast between the vertebra, rib, and other skeletal structural tissues, some background pixels are misclassifed as vertebrae, while some vertebrae pixels were missed from the foreground. For this reason, morphological operations [41] were applied to the binary predicted image in the postprocessing step to eliminate the outliers."
        },
        {
            "heading": "3. Experiments",
            "text": "3.1. Datasets. Tree publicly available datasets of CT spine images were used to evaluate the proposed automated method for vertebral segmentation. Reference segmentation ground truths for three of these datasets are publicly available. Figure 5 shows examples of images from the datasets.\n3.1.1. Dataset 1. Te University of California-Irvine School of Medicine\u2019s Department of Radiological Sciences acquired CT scans using multidetector CT scanners from Philips and Siemens. At a trauma center, thoracolumbar spine CT scans [42] were taken as part of the daily routine without intravenous contrast from 15 adults aged 16 to 35 years old. Te slice thickness is 1mm, and the in-plane resolution is 0.312 to 0.336mm. Each scan includedmanual segmentation of all 12 thoracics and 5 lumbar vertebrae, for a total of 180 thoracic and 75 lumbar vertebrae across 15 subjects, and served as references for ground truth. We used 5 scans to train the model and 10 scans (120 thoracic and 50 lumbar) to test it.\n3.1.2. Dataset 2. Te CT dataset for the lumbar (T1\u2013T5) spine comprises 10 scans and associated manual reference ground truth of the 50 lumbar vertebrae [10]. In-plane voxel sizes ranged from 0.28 to 0.79mm, and slice thicknesses ranged from 0.72 to 1.53mm. Each of the lumbar vertebrae was manually segmented to create a binary mask. Tese scans were utilized as a training dataset.\n3.1.3. Dataset 3. Te VerSe [43, 44] dataset was acquired at multiple locations utilizing CT scanners from four main vendors (Phillips, Siemens, Toshiba, and GE). In terms of feld-of-view (FoV), fndings, and scan parameters, the data were carefully arranged to match a clinical distribution. Data were acquired from patients with an average age of 59 (\u00b117) years. It comprises a range feld of views (including cervicothoracolumbar, thoracolumbar, and cervical scans) and a combination of sagittal and isotropic reformations and fractures of the vertebrae, foreign materials, and metallic implants. Manual ground truths for the cervical, thoracic, and lumbar vertebrae are included in the data. Experiments used 25 thoracolumbar (T1\u2013T12, L1\u2013L5) scans for the training data.\n3.2. PerformanceEvaluation. Evaluationmetrics [45] are used to compare the performance of vertebrae segmentation with other existing approaches. In medical image analysis, these metrics are widely used and well-known. In this paper, precision, recall, accuracy, F-score, intersection over union (IoU) [46], andDice coefcient (DC) [47] are quantitative assessment measures for segmentation performance evaluation [48, 49]. We evaluated true positive (TP), false positive (FP), true negative (TN), and false negative (FN) by comparing the ground truth images with predicted segmented images.\nPrecision \ufffd TP\nTP + FP ,\nRecall \ufffd TP\nTP + FN ,\nAccuracy \ufffd TP + TN\nTP + TN + FP + FN ,\nF \u2212 score \ufffd 2 \u00d7 TP\n(2 \u00d7 TP) + FP + FN ,\nIoU \ufffd |A\u2229B| |A\u222aB| \ufffd TP TP + FP + FN ,\nDC \ufffd 2|A\u2229B| |A| +|B| \ufffd 2TP 2TP + FP + FN .\n(4)\n3.3. Model Training. For training the model, a total of 805,120 image patches were extracted, of which 483,072 were nonvertebrae patches and 322,048 were vertebrae patches. We randomly selected 644,096 (80%) image patches for training and 161,024 for validation. For effcient training, the mini-batch size is set to 64, and training patches are split into 10,064 mini-batches, while validation patches are split into 2,516 mini-batches. Te proposed approach has fve network layers: a 1,024- neuron input layer, three hidden layers, each having 200 hidden neurons, and one sigmoid layer has two neurons, one for each output class. Tis algorithm was implemented in MATLAB 2018a on 32 GB RAM, an NVIDIA GeForce MX250 GPU, and a 1.80 GHz i7 CPU. Te algorithm was trained approximately 23.42 hours and 9 seconds for the segmentation time of a 512 \u00d7 512 image.\nWe frst determined the number of epochs required in pretraining of SSAE to ensure the training process convergence in the proposed model. Figures 6(a)\u20136(c) show the training patch-based learning curve for weights between the input layer and the hidden layers (pretraining learning curves of 3-hidden layers). Te mean square error (MSE) between the original input and the reconstructed input from the autoencoder-decoder was computed and plotted. We conducted our studies with a variety of empirical numbers of hidden nodes. Tese observations reveal that learning processes converge after 300 epochs in diferent hidden node settings. We chose 500 epochs in the experiment pretraining to ensure SSAE convergence. Figure 6(d) shows the fne-tuning\nmodel learning curve for a number of epochs after pretraining. We found the best ft curve for our model training with an MSE of 0.025 for training and 0.029 for validation. Prior to 2,000 epochs, the learning curve rapidly diverges and then stabilizes after 4,000 epochs, and we chose 5,000 epochs in the model fne-tuning.\nTe fve-layered SSAE is based on a visualization model [50] to show the feature presentations of the frst, second, and third hidden layers in Figure 7. Tere are 200 nodes in the frst hidden layer, representing the learned feature representation of the vertebrae and other structures, while the second and third hidden layers (200 nodes) represent more high-level feature learning from image patches. Weights between hidden nodes and pixels in the original image are represented by squares. In the weight matrix, white pixels represent positive values, while gray pixels represent negative values in the weight matrix.\n3.4. Architecture Optimization. Next, we started optimizing the architecture of the proposed model. A grid search was used to optimize the number of hidden layers and nodes on each layer of SSAE.\nUntil now, there has been no theory to determine the optimal SSAE architecture for a particular application. Terefore, we conducted the experiments using a variety of empirical values for the number of hidden layers and nodes. SSAE\u2019s high-level feature representation is determined by the number of hidden nodes. Hence, we chose empirical values (100, 200, 300, 400, and 500) for the number of hidden nodes and empirical values [1\u20134] for the number of hidden layers. Te sparsity coefcients were set to sparsity L2 regularization \u03bb 0.10, sparsity constraint \u03b2 0.20, and target activation \u03c1 0.05. For every possible combination of hidden layers and nodes, the performance metrics were calculated, and the results are shown in Figure 8.\nTe 3-hidden-layer architecture with 200 nodes produced the best precision results (89.9%). Te same design yielded the best recall (90.2%), accuracy (98.8%), IoU (82.6%), and DC (90.2%), respectively. A 2-hidden-layer architecture with 200 hidden nodes produced the best Fscore results (90.5%). Precision, recall, accuracy, IoU, and DC values from the best-performing architecture resulted in an acceptable F-score (90.4%). Diferent architectures might be chosen depending on the needs of the application. We chose the three-layer architecture for SSAE based on DC requirements, and each layer contains 200 hidden nodes. Figure 9 shows the results in confusion matrices of training and randomly selected test case separately."
        },
        {
            "heading": "4. Results and Discussion",
            "text": "4.1. Results. Our approach is developed based on SSAE for vertebrae segmentation. In experiments, our model achieved 89.9% in precision, 90.2% in recall, 98.8% in accuracy, 90.4% in F-score, 82.6% in IoU, and 90.2% in DC. In order to show the efectiveness of L2 regularized SSAE, our method is compared against the state-of-the-art three-layered stacked autoencoder (TSAE) model [33]. If L2 regularization term\u2019s\npenalty coefcient \u03bb and sparsity regularization coefcient \u03b2, the second and third portions of the cost function in equation (1) are limited to zero, then it turns into a threelayered stacked AE (TSAE) model. Table 1 indicates the means of precision, recall, accuracy, F-score, IoU, and DC of our approach and comparative model of TSAE. Te results show the signifcance of the L2 regularized SSAE of our method that is in superior performance compared to TSAE in all metrics.\nTe proposed approach is also compared with multiple deep learning models. Table 2 shows our approach is compared with well-known vertebrae segmentation methods including classical U-Net [51], SpineParseNet [48], patch-based deep belief networks model (PaDBNs) [49], TSAE [33], Butterfy FCN model [21], OP-convNet [20], and Mask R-CNN [52], proving that the proposed model outperformed all of the other models in terms of Fscore, IoU, and DC. Note that for TSAE results, we used the\nsame experimental sitting except for sparsity regularization \u03bb on hidden layers. When compared with the classical UNet [51], SpineParseNet [48], PaDBNs [49], TSAE [33], Butterfy FCN model [21], OP-convNet [20], and Mask R-CNN [52], our model outperforms them by (9, 10.7, 6.9), (2.8, 5.1, 2.9), (5.5, 6, 4.1), (7.6, 8.7, 5), (4, 5.7, 3.2), (0.2, 0.3, 0.3), and (20.3, 29.5, 21) average in (F-score%, IoU%, and DC%), respectively.\nQualitative examples of segmentation results for 2D axial images are shown in the frst, second, third, and fourth rows with the original images, their respective labeled images, predicted segmented images, and overlaid predicted segmented images on original images, respectively (Figure 10). It can be seen that our proposed approach performed well, and the generated results were well-segmented.\n4.2. Discussion. To our knowledge, this is the frst time an SSAE has been used in patch-based classifcation for automatic vertebral segmentation using three distinct CT spine datasets. Using deep learning\u2019s excellent data mining advantage on big data, our approach proved the SSAE network\u2019s strong ability to segment vertebrae automatically. Our approach has the potential to function as fully automated CAD software with minimal human intervention and training or analysis; there is no need to choose any handcrafted features. Tis is an important feature of CAD in today\u2019s fast-paced clinical settings. Te SSAE neural network was used to capture the high-level features from overlapping patches in unsupervised learning. In our method, vertebrae and nonvertebrae patches were efectively classifed by these high-level features. Te\nsigmoid regression layer was then used to incorporate these high-level features to improve classifcation accuracy. Our proposed approach is reliable, robust, and precise. In terms of clinical applications, the developed approach has a high level of overall performance.\nSSAE is a neural network, so the convergence of the training procedure was critical to the model\u2019s classifcation of image patches. In SSAE, a premature network might be the result of insufcient training epochs that cause a lack of optimal performance. Terefore, it is required to conduct a convergence test to determine the correct number of epochs in deep learning. In our experiment, we used 500 epochs for pretraining. Tis setting ensured the training\u2019s convergence and avoided time wastage. Te architecture of neural networks is another critical consideration. It has already been stated that there are no general criteria for designing a neural network\u2019s architecture. Indeed, the optimum neural network architecture is decided by the intricacy of the data that is being used. An early indication of SSAE architecture design could be provided by optimization experiments in our situation. We also found that sparse regularization was necessary during training to build deep feature representations that positively impacted the fnetuning phase. During training, sparsity pushes the flters to capture more detailed features from image patches. Te performance comparison indicated our approach\u2019s efectiveness and its superior capability when compared to other well-known models.\nOur proposed approach performs well in classifying the test patches into vertebrae or nonvertebrae patches and then segmenting the vertebrae from the reconstruction of image patches. Each spinal level has its own set of vertebral patterns. Signifcant morphologic variations can be seen between two vertebrae separated by a wide spatial distance\nwithin the spinal column, such as the upper thoracic vertebrae and the lower lumbar vertebrae. It is therefore challenging to achieve accurate segmentation of all the vertebrae. Our proposed model has some limitations with segmentation in the upper thoracic vertebrae (T1\u2013T3) due to the existence of rib structure, and the L5 vertebrae also obtained lower DC than other vertebrae. Figure 11 illustrates the results of poor segmentation where high false negatives represent the vertebrae regions which are not detected by the model, whereas false positives are the background regions that have been segmented wrongly as vertebrae."
        },
        {
            "heading": "5. Conclusion",
            "text": "Tis study presented a stacked sparse autoencoder framework for automated vertebrae segmentation using publicly available three distinct CT spine datasets (VerSe, CSI-seg, and the Lumbar dataset). We used 2D image slices to extract overlapped patches for model training. A high-level feature representation of pixel intensity is captured in an unsupervised fashion using the proposed model from image patches. A sigmoid layer efciently classifes vertebrae and nonvertebrae patches using these high-level features. Our approach performed optimally after setting main parameters such as the number of hidden layers, dimension of hidden nodes, and epochs. Sparsity constraints on hidden layers are also demonstrated to be efcient. It was noticed that the training using sparsity regularization is necessary to build feature representations that positively infuence the fnal supervised tuning phase. Te scheme of distinguishing vertebrae regions using image patches rather than individual pixels also decreases the rate of false positives. Te method demonstrates signifcant potential for resolving issues caused by morphological variations of vertebrae. When\ncompared to other state-of-the-art vertebrae segmentation methods, our approach outperformed them in terms of segmentation accuracy. We carried out further experiments that enabled us to identify our method\u2019s limitations, specifcally in fractured vertebrae. Future work will improve our approach by developing a more discriminative deep neural network design to make our method more robust in these cases."
        },
        {
            "heading": "Data Availability",
            "text": "Te data supporting the fndings of this study are available at (Dataset 1 and Dataset 2) https://spineweb. digitalimaginggroup.ca/Index.php?n=Main.Datasets and (Dataset 3) https://osf.io/t98fz/."
        },
        {
            "heading": "Conflicts of Interest",
            "text": "Te authors declare that there are no conficts of interest."
        },
        {
            "heading": "Acknowledgments",
            "text": "Tis work was supported in part by the National Natural Science Foundation of China under grant numbers 82261138629 and 91959108 and Shenzhen Municipal Science and Technology Innovation Council under grant number JCYJ20220531101412030."
        }
    ],
    "title": "CT-Based Automatic Spine Segmentation Using Patch-Based Deep Learning",
    "year": 2023
}