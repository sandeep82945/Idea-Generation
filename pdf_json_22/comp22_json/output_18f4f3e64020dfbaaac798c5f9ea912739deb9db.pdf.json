{
    "abstractText": "Attention deficit hyperactivity disorder (ADHD) is a common neurodevelopmental condition worldwide. In this research, we used an ADHD electroencephalography (EEG) dataset containing more than 4000 EEG signals. Moreover, these EEGs are noisy signals. A new hand-modeled EEG classification model has been proposed to separate healthy versus ADHD individuals using the EEG signals. In this model, a new ternary motif pattern (TMP) has been incorporated. We have mimicked deep learning networks to create this hand-modeled classification method. The Tunable Q Wavelet Transform (TQWT) has been utilized to generate wavelet subbands. We applied the proposed TMP and statistics to construct informative features from both raw EEG signals and wavelet bands by generating TQWT. Herein, features have been generated by 18 subbands and the original EEG signal. Thus, this model is named TMP19. The most informative features have been chosen by deploying neighborhood component analysis (NCA), and the selected features have been classified using the k-nearest neighbor (kNN) classifier. The used ADHD EEG dataset has 14 channels. Thus, these three phases\u2014(i) feature extraction with TQWT, TMP, and statistics; (ii) feature selection by deploying NCA; and (iii) classification with kNN\u2014have been applied to each channel. Iterative hard majority voting (IHMV) has been applied to obtain a higher and more general classification response. Our model attained 95.57% and 77.93% classification accuracies by deploying 10-fold and leave one subject out (LOSO) cross-validations, respectively.",
    "authors": [
        {
            "affiliations": [],
            "name": "Prabal Datta Barua"
        },
        {
            "affiliations": [],
            "name": "Mehmet Baygin"
        },
        {
            "affiliations": [],
            "name": "Elizabeth Emma Palmer"
        },
        {
            "affiliations": [],
            "name": "Edward J. Ciaccio"
        },
        {
            "affiliations": [],
            "name": "Rajendra Acharya"
        }
    ],
    "id": "SP:464f2d23fa4ce1e005040382d97e9fd2d187f1df",
    "references": [
        {
            "authors": [
                "P. Leijten",
                "S. Scott",
                "S. Landau",
                "V. Harris",
                "J. Mann",
                "J. Hutchings",
                "J. Beecham",
                "F. Gardner"
            ],
            "title": "Individual participant data metaanalysis: Impact of conduct problem severity, comorbid attention-deficit/hyperactivity disorder and emotional problems, and maternal depression on parenting program effects",
            "venue": "J. Am. Acad. Child Adolesc. Psychiatry",
            "year": 2020
        },
        {
            "authors": [
                "S.K. Yadav",
                "A.A. Bhat",
                "S. Hashem",
                "S. Nisar",
                "M. Kamal",
                "N. Syed",
                "M.-R. Temanni",
                "R.K. Gupta",
                "S. Kamran",
                "M.W. Azeem"
            ],
            "title": "Genetic variations influence brain changes in patients with attention-deficit hyperactivity disorder",
            "venue": "Transl. Psychiatry",
            "year": 2021
        },
        {
            "authors": [
                "S. Faraone",
                "P. Asherson",
                "T. Banaschewski",
                "J. Biederman",
                "J. Buitelaar",
                "J. Ramos-Quiroga",
                "L. Rohde",
                "E. Sonuga-Barke",
                "R. Tannock",
                "B. Franke"
            ],
            "title": "Attention-deficit/hyperactivity disorder",
            "venue": "Nature reviews. Dis. Prim",
            "year": 2015
        },
        {
            "authors": [
                "R.-F. Tzang",
                "Y.-C. Chang",
                "K.-L. Kao",
                "Y.-H. Huang",
                "H.-C. Huang",
                "Y.-C. Wang",
                "C.-H. Muo",
                "S.-I. Wu",
                "F.-C. Sung",
                "R. Stewart"
            ],
            "title": "Increased risk of developing psychiatric disorders in children with attention deficit and hyperactivity disorder (ADHD) receiving sensory integration therapy: A population-based cohort study",
            "venue": "Eur. Child Adolesc. Psychiatry",
            "year": 2019
        },
        {
            "authors": [
                "M. Bonati",
                "M. Cartabia",
                "M. Zanetti",
                "L. Reale",
                "A. Didoni",
                "M.A. Costantino"
            ],
            "title": "Age level vs. grade level for the diagnosis of ADHD and neurodevelopmental disorders",
            "venue": "Eur. Child Adolesc. Psychiatry",
            "year": 2018
        },
        {
            "authors": [
                "M. Pawaskar",
                "M. Fridman",
                "R. Grebla",
                "M. Madhoo"
            ],
            "title": "Comparison of quality of life, productivity, functioning and self-esteem in adults diagnosed with ADHD and with symptomatic ADHD",
            "venue": "J. Atten. Disord",
            "year": 2020
        },
        {
            "authors": [
                "P. S\u00f6r\u00f6s",
                "E. Hoxhaj",
                "P. Borel",
                "C. Sadohara",
                "B. Feige",
                "S. Matthies",
                "H.H.O. M\u00fcller",
                "K. Bachmann",
                "M. Schulze",
                "A. Philipsen"
            ],
            "title": "Hyperactivity/restlessness is associated with increased functional connectivity in adults with ADHD: A dimensional analysis of resting state fMRI",
            "venue": "BMC Psychiatry",
            "year": 2019
        },
        {
            "authors": [
                "A. Serrano-Barroso",
                "R. Siugzdaite",
                "J. Guerrero-Cubero",
                "A.J. Molina-Cantero",
                "I.M. Gomez-Gonzalez",
                "J.C. Lopez",
                "J.P. Vargas"
            ],
            "title": "Detecting attention levels in ADHD children with a video game and the measurement of brain activity with a single-channel BCI headset",
            "year": 2021
        },
        {
            "authors": [
                "J. Biederman",
                "T. Spencer",
                "A. Lomedico",
                "H. Day",
                "C. Petty",
                "S.V. Faraone"
            ],
            "title": "Deficient emotional self-regulation and pediatric attention deficit hyperactivity disorder: A family risk analysis",
            "venue": "Psychol. Med",
            "year": 2012
        },
        {
            "authors": [
                "E.G. Willcutt",
                "A.E. Doyle",
                "J.T. Nigg",
                "S.V. Faraone",
                "B.F. Pennington"
            ],
            "title": "Validity of the executive function theory of attentiondeficit/hyperactivity disorder: A meta-analytic review",
            "venue": "Biol. Psychiatry",
            "year": 2005
        },
        {
            "authors": [
                "V. Simon",
                "P. Czobor",
                "S. B\u00e1lint",
                "A. M\u00e9sz\u00e1ros",
                "I. Bitter"
            ],
            "title": "Prevalence and correlates of adult attention-deficit hyperactivity disorder: Meta-analysis",
            "venue": "Br. J. Psychiatry",
            "year": 2009
        },
        {
            "authors": [
                "P. Quinn",
                "S. Wigal"
            ],
            "title": "Perceptions of girls and ADHD: Results from a national survey",
            "venue": "Medscape Gen. Med. 2004,",
            "year": 2004
        },
        {
            "authors": [
                "J.J. Bauermeister",
                "P.E. Shrout",
                "L. Ch\u00e1vez",
                "M. Rubio-Stipec",
                "R. Ram\u00edrez",
                "L. Padilla",
                "A. Anderson",
                "P. Garc\u00eda",
                "G. Canino"
            ],
            "title": "ADHD and gender: Are risks and sequela of ADHD the same for boys and girls",
            "venue": "J. Child Psychol. Psychiatry",
            "year": 2007
        },
        {
            "authors": [
                "O. Zahmacioglu",
                "E.Z. Kilic"
            ],
            "title": "Early diagnosis and treatment of ADHD are important for a secure transition to adolescence",
            "venue": "Anatol. J. Psychiatry/Anadolu Psikiyatr. Derg",
            "year": 2017
        },
        {
            "authors": [
                "S.A. Safren",
                "S. Sprich",
                "M.J. Mimiaga",
                "C. Surman",
                "L. Knouse",
                "M. Groves",
                "M.W. Otto"
            ],
            "title": "Cognitive behavioral therapy vs. relaxation with educational support for medication-treated adults with ADHD and persistent symptoms: A randomized controlled trial",
            "year": 2010
        },
        {
            "authors": [
                "A.S. Bell"
            ],
            "title": "A critical review of ADHD diagnostic criteria: What to address in the DSM-V",
            "venue": "J. Atten. Disord",
            "year": 2011
        },
        {
            "authors": [
                "H.W. Loh",
                "C.P. Ooi",
                "S. Seoni",
                "P.D. Barua",
                "F. Molinari",
                "U.R. Acharya"
            ],
            "title": "Application of Explainable Artificial Intelligence for Healthcare: A Systematic Review of the Last Decade (2011\u20132022)",
            "venue": "Comput. Methods Programs Biomed",
            "year": 2022
        },
        {
            "authors": [
                "A. Lenartowicz",
                "S.K. Loo"
            ],
            "title": "Use of EEG to diagnose ADHD",
            "venue": "Curr. Psychiatry Rep",
            "year": 2014
        },
        {
            "authors": [
                "M.A. Stein",
                "S.M. Snyder",
                "T.A. Rugino",
                "M. Commentary Hornig"
            ],
            "title": "Objective aids for the assessment of ADHD\u2013further clarification of what FDA approval for marketing means and why NEBA might help clinicians",
            "venue": "A response to Arns et al.",
            "year": 2016
        },
        {
            "authors": [
                "M. Moghaddari",
                "M.Z. Lighvan",
                "S. Danishvar"
            ],
            "title": "Diagnose ADHD disorder in children using convolutional neural network based on continuous mental task",
            "venue": "EEG. Comput. Methods Programs Biomed",
            "year": 2020
        },
        {
            "authors": [
                "M. Tosun"
            ],
            "title": "Effects of spectral features of EEG signals recorded with different channels and recording statuses on ADHD classification with deep learning",
            "venue": "Phys. Eng. Sci. Med",
            "year": 2021
        },
        {
            "authors": [
                "S. Khoshnoud",
                "M. Shamsi",
                "M.A. Nazari"
            ],
            "title": "Non-linear EEG analysis in children with attention-deficit/hyperactivity disorder during the rest condition",
            "venue": "In Proceedings of the 2015 22nd Iranian Conference on Biomedical Engineering (ICBME),",
            "year": 2015
        },
        {
            "authors": [
                "H. Chen",
                "Y. Song",
                "X. Li"
            ],
            "title": "A deep learning framework for identifying children with ADHD using an EEG-based brain",
            "year": 2019
        },
        {
            "authors": [
                "A. Tenev",
                "S. Markovska-Simoska",
                "L. Kocarev",
                "J. Pop-Jordanov",
                "A. M\u00fcller",
                "G. Candrian"
            ],
            "title": "Machine learning approach for classification of ADHD adults",
            "venue": "Int. J. Psychophysiol",
            "year": 2014
        },
        {
            "authors": [
                "S. Saini",
                "R. Rani",
                "N. Kalra"
            ],
            "title": "Prediction of Attention Deficit Hyperactivity Disorder (ADHD) using machine learning Techniques based on classification of EEG signal",
            "venue": "In Proceedings of the 2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS), Coimbatore, India,",
            "year": 2022
        },
        {
            "authors": [
                "L. Dubreuil-Vall",
                "G. Ruffini",
                "J.A. Camprodon"
            ],
            "title": "Deep learning convolutional neural networks discriminate adult ADHD from healthy individuals on the basis of event-related spectral EEG",
            "venue": "Front. Neurosci",
            "year": 2020
        },
        {
            "authors": [
                "H.T. Tor",
                "C.P. Ooi",
                "N.S. Lim-Ashworth",
                "J.K.E. Wei",
                "V. Jahmunah",
                "S.L. Oh",
                "U.R. Acharya",
                "D.S.S. Fung"
            ],
            "title": "Automated detection of conduct disorder and attention deficit hyperactivity disorder using decomposition and nonlinear techniques with EEG signals",
            "venue": "Comput. Methods Programs Biomed",
            "year": 2021
        },
        {
            "authors": [
                "H.W. Loh",
                "C.P. Ooi",
                "P.D. Barua",
                "E.E. Palmer",
                "F. Molinari",
                "U. Acharya"
            ],
            "title": "Automated detection of ADHD: Current trends and future perspective",
            "venue": "Comput. Biol. Med",
            "year": 2022
        },
        {
            "authors": [
                "M. Samavati",
                "A.M. Nasrabadi",
                "M.R. Mohammadi"
            ],
            "title": "EEG data for ADHD/Control children",
            "venue": "IEEE DataPort 2020",
            "year": 2020
        },
        {
            "authors": [
                "M. Samavati",
                "A.M. Nasrabadi",
                "M.R. Mohammadi"
            ],
            "title": "Automatic minimization of eye blink artifacts using fractal dimension of independent components of multichannel EEG",
            "venue": "In Proceedings of the 20th Iranian Conference on Electrical Engineering",
            "year": 2012
        },
        {
            "authors": [
                "I.W. Selesnick"
            ],
            "title": "Wavelet transform with tunable Q-factor",
            "venue": "IEEE Trans. Signal Process",
            "year": 2011
        },
        {
            "authors": [
                "E. Akbal",
                "T. Tuncer"
            ],
            "title": "FusedTSNet: An automated nocturnal sleep sound classification method based on a fused textural and statistical feature generation",
            "venue": "network. Appl. Acoust",
            "year": 2021
        },
        {
            "authors": [
                "J. Goldberger",
                "G.E. Hinton",
                "S. Roweis",
                "R.R. Salakhutdinov"
            ],
            "title": "Neighbourhood components analysis",
            "venue": "Adv. Neural Inf. Process. Syst. 2004,",
            "year": 2004
        },
        {
            "authors": [
                "L.E. Peterson"
            ],
            "title": "K-nearest neighbor",
            "venue": "Scholarpedia 2009,",
            "year": 2009
        },
        {
            "authors": [
                "A. Dogan",
                "M. Akay",
                "P.D. Barua",
                "M. Baygin",
                "S. Dogan",
                "T. Tuncer",
                "A.H. Dogru",
                "U.R. Acharya"
            ],
            "title": "PrimePatNet87: Prime pattern and tunable q-factor wavelet transform techniques for automated accurate EEG emotion recognition",
            "venue": "Comput. Biol. Med",
            "year": 2021
        },
        {
            "authors": [
                "M.R. Mohammadi",
                "A. Khaleghi",
                "A.M. Nasrabadi",
                "S. Rafieivand",
                "M. Begol",
                "H. Zarafshan"
            ],
            "title": "EEG classification of ADHD and normal children using non-linear features and neural network",
            "venue": "Biomed. Eng. Lett. 2016,",
            "year": 2016
        },
        {
            "authors": [
                "J.E. Koh",
                "C.P. Ooi",
                "N.S. Lim-Ashworth",
                "J. Vicnesh",
                "H.T. Tor",
                "O.S. Lih",
                "R.-S. Tan",
                "U.R. Acharya",
                "D.S.S. Fung"
            ],
            "title": "Automated classification of attention deficit hyperactivity disorder and conduct disorder using entropy features with ECG signals",
            "venue": "Comput. Biol. Med",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Citation: Barua, P.D.; Dogan, S.;\nBaygin, M.; Tuncer, T.; Palmer, E.E.;\nCiaccio, E.J.; Acharya, U.R. TMP19: A\nNovel Ternary Motif Pattern-Based\nADHD Detection Model Using EEG\nSignals. Diagnostics 2022, 12, 2544.\nhttps://doi.org/10.3390/\ndiagnostics12102544\nAcademic Editor: Vadim V. Grubov\nReceived: 23 September 2022\nAccepted: 17 October 2022\nPublished: 20 October 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: ternary motif pattern; ADHD detection; EEG signal classification; signal processing"
        },
        {
            "heading": "1. Introduction",
            "text": "Attention deficit hyperactivity disorder (ADHD) is a persistent neurodevelopmental disorder [1\u20133]. It can increase the risk of poor educational and occupational outcomes, social disability, and other psychiatric conditions [4]. ADHD is often diagnosed between the ages of 3 and 7 years, but may not be recognized until adulthood [5,6]. ADHD symptoms include inattentiveness and hyperactivity-impulsivity [7]. People with ADHD often have additional features such as impairments in their executive function and emotional regulation [8\u201310]. Systematic reviews show that ADHD affects 5% of children and adolescents and 2.5% of adults globally [11]. Boys are more likely to be diagnosed with ADHD\nDiagnostics 2022, 12, 2544. https://doi.org/10.3390/diagnostics12102544 https://www.mdpi.com/journal/diagnostics\nthan girls [12,13]. Early diagnosis is very important for this condition to optimize management and reduce the long-term negative sequalae in psychosocial wellbeing and integration into the community [14]. Management usually combines patient and family education and pharmacological and non-pharmacological interventions such as a range of behavioral and neurocognitive therapies [15]. The aim is to eliminate disease symptoms. Psychologists diagnose ADHD, and the professionals have responsibility for assessment and diagnosis. This assessment typically involves a combination of standardized evaluation scales plus a clinical interview, compared to the DSM-5 or ICD (International Statistical Classification of Diseases and Related Health Problems) diagnostic criteria [16]. Diagnosing ADHD can be challenging, particularly in regions with limited access to suitably trained health professionals. There is, therefore, interest in the ability of other diagnostic tools to improve equitable access to an early diagnosis [17]. One suggested diagnostic data type is the EEG [18]. The FDA has stated that the EEG may be a helpful diagnostic tool in ADHD diagnoses [19]. An increasing number of studies on the potential diagnostic utility of EEG have now been reported in the literature. This paper proposes a new hand-modeled EEG classification for the automatic interpretation of EEG signals for diagnosing ADHD in children. The model developed in this study has high classification success and low computational complexity. The diagnosis of ADHD using EEG signals remains a hot topic with as yet no universally agreed upon guideline for the diagnostic use and interpretation of the EEG. Moghaddari et al. [20] used the Convolutional Neural Network (CNN) for ADHD diagnosis in children. Their study utilized EEG signals from 31 ADHD and 30 healthy children, which were preprocessed and free of noise and artifacts. Thereafter, the EEG signals were converted to RGB images and provided as input to a 13-layer CNN. The developed model was evaluated with the 5-fold cross-validation technique, and an average accuracy of 99.06% was achieved. An ADHD classification method using power spectral density (PSD), spectral entropy (SE), and long short-term memory (LSTM) methods has been proposed by Tosun [21]. Their study applied an 80:20 hold-out validation strategy, and the proposed method yielded a 92.15% accuracy. Khoshnoud et al. [22] performed a nonlinear EEG analysis in children with ADHD. The largest Lyapunov exponent (LLE) and approximate entropy (ApEn) methods were used to obtain the nonlinear characteristics of the signal. These features were evaluated with a Probabilistic Neural Network (PNN), and an 87.5% classification accuracy was obtained. Chen et al. [23] proposed a deep learning framework to identify children with ADHD. In their proposed method, EEG signals are converted into image data and given as input to the CNN developed in the study. EEG signals from 50 children with ADHD and 51 healthy children were utilized. The developed model provided a 94.67% accuracy performance on the test data. Tenev et al. [24] proposed a learning approach for classifying adult ADHD individuals automatically. Their study analyzed EEG signals from 117 adults (67 ADHD and 50 controls) using a Support Vector Machine (SVM) and voting method. The proposed method achieved an 82.3% success rate in separating ADHD versus control groups. Saini et al. [25] developed an EEG signal-based machine learning model for ADHD diagnosis. The developed model uses principal component analysis (PCA) for feature selection and k-nearest neighbor (kNN) for classification. In this study, EEG signals from 77 ADHD and 80 healthy children were classified, and an accuracy of 86% was achieved. Dubreuil-Vall et al. [26] collected EEG signals from 40 subjects (20 ADHD and 20 controls) for ADHD classification. In their study, firstly, the signal was preprocessed and then the spectrogram of the signal was extracted. Thereafter, the spectrogram images of the EEG signal were fed as input to the custom designed CNN, and classification was made. The developed model reached an 88% classification accuracy. Tor et al. [27] used empirical mode decomposition (EMD) and discrete wavelet transform (DWT) decomposition methods and nonlinear features for ADHD, conduct disorder (CD), and ADHD+CD detection. They analyzed EEG data of 123 children (45 ADHD, 62 conduct disorder + ADHD, and 16 conduct disorder subjects) with a kNN classifier and obtained an accuracy of 97.88%. Loh et al. [28] reviewed the automated ADHD detection methods\npublished in the last decade. They reviewed all the machine learning and deep learning techniques employed for the automated detection of ADHD using both physiological signals and images.\nThe essential motivations of the presented model are:\n\u2022 Presenting a new motif pattern to generate textural features; \u2022 Proposing a hand-modeled one-dimensional signal classification architecture; \u2022 Attaining robust and high classification performance with low time complexity.\nThus, this study has three main motivations. First, motifs of signals are very useful for extracting features. A new feature generation model has been proposed to use motifs as a feature vector, and this feature extraction function is named TMP. We aimed to present a highly accurate feature engineering model. Hence, we used both hand-crafted features and an architecture miming a deep learning architecture to attain high classification accuracy. Deep learning models have multiple levels/layers to generate distinctive features. Thus, we have used a multileveled feature extraction model. By using this model, an accurate EEG signal classification method has been proposed. To demonstrate its robustness, we used two validation techniques (10-fold CV and LOSO CV). These validations yielded 95.57% and 77.93% classification accuracies by deploying 10-fold CV and LOSO CV, respectively.\nThe novelties and contributions are:\n\u2022 A new ternary motif pattern has been proposed in this research. The main objective of the proposed TMP is to extract hidden and informative features from EEG signals. \u2022 A new generation multilevel feature engineering model has been proposed in this research to attain high classification accuracy on the EEG dataset. The presented feature engineering model uses 19 levels and TMP to extract features. Thus, this model is named TMP19. \u2022 In the feature selection phase, the main feature extraction function is NCA. At the same time, we employed threshold-based elimination to obtain more distinctive features. Thus, the model is named threshold\u2013based NCA. \u2022 We integrated a noisy EEG dataset containing 4173 EEG signals, each of four seconds in length. We believe this is the first proposal of a classification model for this dataset in the literature. \u2022 Our proposal\u2014TMP19\u2014was tested using two validation techniques and showed robust results. The TMP19 attained 95.57% and 77.93% classification accuracies by deploying 10-fold CV and LOSO CV, respectively."
        },
        {
            "heading": "2. Material and Method",
            "text": ""
        },
        {
            "heading": "2.1. Material",
            "text": "We utilized a noisy EEG dataset in this work [29,30]. The dataset contains 2330 healthy EEG signals and 1843 ADHD EEG signals. The lengths of these EEG signals are equal and four seconds in length. In this EEG dataset, there are 14 channels. The frequency sampling of these EEG signals is 128 Hz."
        },
        {
            "heading": "2.2. Method",
            "text": "In this paper, a new local feature extraction function has been proposed, named the ternary motif pattern. Herein, we integrated five-sized overlapping blocks to obtain motifs, and we applied the ternary function to find upper, equal, and lower values. Two feature maps have been generated using these values, and histograms of these feature maps have been utilized as feature vectors. The model overview of the presented TMP is demonstrated in Figure 1.\nDiagnostics 2022, 12, 2544 4 of 14\nDiagnostics 2022, 12, x FOR PEER REVIEW 4 of 13\nhave been utilized as feature vectors. The model overview of the presented TMP is demonstrated in Figure 1.\nFigure 1. Model overview of the proposed TMP feature extraction function.\nTo better explain this model, detailed descriptions have been given below. Step 1: Create overlapping blocks with a length of five.\n\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc61\ud835\udc61 = \ud835\udc46\ud835\udc46(\ud835\udc61\ud835\udc61: \ud835\udc61\ud835\udc61 + 4), \ud835\udc61\ud835\udc61 \u2208 {1,2, \u2026 , \ud835\udc4f\ud835\udc4f\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59 \u2212 4} (1) Herein, \ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc61\ud835\udc61 is the overlapping block with a length of five, and \ud835\udc4f\ud835\udc4f\ud835\udc59\ud835\udc59\ud835\udc59\ud835\udc59 defines the length\nof the signal. Step 2: Generate ternary motifs.\n\ud835\udc63\ud835\udc63\ud835\udc63\ud835\udc63\ud835\udc4f\ud835\udc4f\ud835\udc58\ud835\udc58 = \ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ufffd\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc56\ud835\udc56\ud835\udc61\ud835\udc61 ,\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc57\ud835\udc57\ud835\udc61\ud835\udc61\ufffd, \ud835\udc56\ud835\udc56 \u2208 {1,2,3,4}, \ud835\udc57\ud835\udc57 \u2208 {\ud835\udc56\ud835\udc56 + 1, \ud835\udc56\ud835\udc56 + 2, \u2026 ,5},\ud835\udc58\ud835\udc58 \u2208 {1,2, \u2026 ,10} (2)\n\ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61\ufffd\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc56\ud835\udc56\ud835\udc61\ud835\udc61 ,\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc57\ud835\udc57\ud835\udc61\ud835\udc61\ufffd = \ufffd 0, \ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc56\ud835\udc56\ud835\udc61\ud835\udc61 < \ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc57\ud835\udc57\ud835\udc61\ud835\udc61\n1, \ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc56\ud835\udc56\ud835\udc61\ud835\udc61 = \ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc57\ud835\udc57\ud835\udc61\ud835\udc61 2, \ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc56\ud835\udc56\ud835\udc61\ud835\udc61 > \ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc4f\ud835\udc57\ud835\udc57\ud835\udc61\ud835\udc61\n(3)\nwhere \ud835\udc63\ud835\udc63\ud835\udc63\ud835\udc63\ud835\udc4f\ud835\udc4f represents ternary motif values, and \ud835\udc61\ud835\udc61\ud835\udc61\ud835\udc61() defines ternary function. Step 3: Calculate map values using ternary motif values.\n\ud835\udc5a\ud835\udc5a\ud835\udc61\ud835\udc611 = \ufffd\ud835\udc63\ud835\udc63\ud835\udc63\ud835\udc63\ud835\udc4f\ud835\udc4f\ud835\udc57\ud835\udc57 \u00d7 3\ud835\udc57\ud835\udc57\u22121 5\n\ud835\udc57\ud835\udc57=1\n(4)\n\ud835\udc5a\ud835\udc5a\ud835\udc61\ud835\udc612 = \ufffd\ud835\udc63\ud835\udc63\ud835\udc63\ud835\udc63\ud835\udc4f\ud835\udc4f\ud835\udc57\ud835\udc57+5 \u00d7 3\ud835\udc57\ud835\udc57\u22121 5\n\ud835\udc57\ud835\udc57=1\n(5)\nThe symbols \ud835\udc5a\ud835\udc5a1 and \ud835\udc5a\ud835\udc5a2 represent the first and second map signals, respectively. Step 4: Extract histograms of map signals.\n\u210e1 = \ud835\udf17\ud835\udf17(\ud835\udc5a\ud835\udc5a1) (6) \u210e2 = \ud835\udf17\ud835\udf17(\ud835\udc5a\ud835\udc5a2) (7)\nFigure 1. odel overview of the proposed T P feature extraction function.\nTo better explain this model, detailed descriptions have been given below.\nStep 1: Create overlapping blocks with a length of five.\nblt = S(t : t + 4), t \u2208 {1, 2, . . . , len\u2212 4} (1)\nHerein, blt is the overlapping block with a length of five, and len defines the length of the signal.\nStep 2: Generate ternary motifs.\nvalk = t f ( blti , bl t j ) , i \u2208 {1, 2, 3, 4}, j \u2208 {i + 1, i + 2, . . . , 5}, k \u2208 {1, 2, . . . , 10} (2)\nt f (\nblti , bl t j\n) =  0, blti < bl t j 1, blti = bl t j\n2, blti > bl t j\n(3)\nwhere val represents ternary motif values, and t f () defines ternary function.\nStep 3: Calculate map values using ternary motif values.\nm1t = 5\n\u2211 j=1\nvalj \u00d7 3j\u22121 (4)\nm2t = 5\n\u2211 j=1\nvalj+5 \u00d7 3j\u22121 (5)\nThe symbols m1 and m2 represent the first and second map signals, respectively.\nStep 4: Extract histograms of map signals.\nh1 = \u03d1 ( m1 )\n(6)\nh2 = \u03d1 ( m2 )\n(7)\nwhere h1 and h2 are histograms of first and second maps. The length of each map signal is 243 (=35).\nStep 5: Merge the generated histograms and obtain a feature vector.\nf v(q) = hc(q + 243\u00d7 (c\u2212 1)), c \u2208 {1, 2}, q \u2208 {1, 2, . . . , 243} (8)\nThe symbol f v defines the generated feature vector with a length of 486 (=243 \u00d7 2). These five steps above define the proposed TMP. We suggested a new hand-modeled signal classification method in this paper, and our\nproposal is named TMP19. TMP19 contains four main phases, and these phases are:\n\u2022 Feature extraction; \u2022 Feature selection; \u2022 Classification; \u2022 Majority voting.\nIn Figure 2, a graphical overview of the proposed TMP19 is demonstrated.\nDiagnostics 2022, 12, x FOR PEER REVIEW 5 of 13\nwhere \u210e1 and \u210e2 are histograms of first and second maps. The length of each map signal is 243 (=35). Step 5: Merge the generated histograms and obtain a feature vector.\n\ud835\udc61\ud835\udc61\ud835\udc63\ud835\udc63(\ud835\udc5e\ud835\udc5e) = \u210e\ud835\udc50\ud835\udc50\ufffd\ud835\udc5e\ud835\udc5e + 243 (\ud835\udc50\ud835\udc50 1)\ufffd, \ud835\udc50\ud835\udc50 \u2208 {1,2}, \ud835\udc5e\ud835\udc5e \u2208 {1,2, \u2026 ,243} (8) The symbol \ud835\udc61\ud835\udc61\ud835\udc63\ud835\udc63 defines the generated feature vector with a length of 486 (=243 \u00d7 2). These five steps above define the proposed TMP. We suggested a new hand-modeled signal classification method in this paper, and\nour proposal is named TMP19. TMP19 contains four main phases, and these phases are: \u2022 Feature extraction; \u2022 Feature selection; \u2022 Classification; \u2022 Majority voting.\nIn Figure 2, a graphical overview of the proposed TMP19 is demonstrated.\nFigure 2. (a) Overview of the TMP19 signal classification architecture, (b) the proposed statistical and TMP-based feature extraction method, and (c) feature selection with the thresholded NCA method.\nFigure 2 depicts our proposed TMP19 architecture. In Figure 3, C represents the number of channels. Phases of this model are defined below, briefly describing the TMP19 EEG signal classification model.\nFigure 2. (a) Overview of the TMP19 signal classification architecture, (b) the proposed statistical and TMP-based feature extraction method, and (c) feature selection with the thresholded NCA method.\nFigure 2 depicts our proposed TMP19 architecture. In Figure 3, C represents the number of channels. Phases of this model are defined below, briefly describing the TMP19 EEG signal classification model. Diagnostics 2022, 12, x FOR PEER REVIEW 6 of 13"
        },
        {
            "heading": "2.2.1. Feature Extraction",
            "text": "In the feature extraction phase, we utilized three methods: (i) TQWT [31], (ii) the proposed TMP feature extraction function, and (iii) statistical feature generator. First, we generated wavelet bands using TQWT transformation. TQWT is a parametric and third-generation wavelet transform. By using redundancy (r), oscillation (Q), and the number of level (J) parameters, a variable multileveled wavelet transform was created. The high oscillatory wavelet transform was assigned 4 and 3 for the Q and r parameters. The system\u2019s main aim was to propose a new feature engineering model as in DarkNet19. Thus, we generated 18 wavelet coefficient bands to use 19 inputs. These 19 signals (raw EEG signal + 18 wavelet bands) have been utilized as inputs to the feature extraction functions. The system contains two feature extraction functions: the TMP and the statistical feature generator. Both statistical parameters and motifs have been extracted using these feature extractors in the space and frequency domains. The steps of the proposed feature extraction method are given below. Step 1: Apply TQWT to the EEG signal for generating wavelet bands.\n\ud835\udc45\ud835\udc45 = \ud835\udf0f\ud835\udf0f(\ud835\udc46\ud835\udc46, 4,3,17) (9) where \ud835\udc45\ud835\udc45 defines TQWT bands, \ud835\udc46\ud835\udc46 is the EEG signal, 4, 3, and 18 are the Q, r, and J parameters of the TQWT function (\ud835\udf0f\ud835\udf0f()). Step 2: Generate features using TMP and statistical feature generation function.\n\ud835\udc61\ud835\udc611 = \ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc59\ud835\udc59\ud835\udc50\ud835\udc50\ud835\udc63\ud835\udc63\ud835\udc61\ud835\udc61\ufffd\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47(\ud835\udc46\ud835\udc46), \ud835\udc46\ud835\udc46\ud835\udc46\ud835\udc46(\ud835\udc46\ud835\udc46)\ufffd (10) \ud835\udc61\ud835\udc61\ud835\udc59\ud835\udc59+1 = \ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc59\ud835\udc59\ud835\udc50\ud835\udc50\ud835\udc63\ud835\udc63\ud835\udc61\ud835\udc61\ufffd\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47(\ud835\udc45\ud835\udc45\ud835\udc59\ud835\udc59), \ud835\udc46\ud835\udc46\ud835\udc46\ud835\udc46(\ud835\udc45\ud835\udc45\ud835\udc59\ud835\udc59)\ufffd, \ud835\udc4f\ud835\udc4f \u2208 {1,2, \u2026 ,18} (11)\nIn this step (Step 2), 19 feature vectors have been generated by deploying the TMP feature generator (\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47()), and statistical generator (\ud835\udc46\ud835\udc46\ud835\udc46\ud835\udc46()). \ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47\ud835\udc47() function generates 486 features from a one-dimensional signal, and \ud835\udc46\ud835\udc46\ud835\udc46\ud835\udc46() extracts 14 features from a signal since 14 statistical moments [32] have been used in this function. These moments are (i) maximum, (ii) minimum, (iii) average, (iv) variance, (v) standard deviation, (vi) median, (vii) range, (viii) root mean square, (ix) energy, (x) Shannon entropy, (xi) sure entropy, (xii) log energy entropy, (xiii) threshold entropy, and (xiv) mean absolute deviation. \ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc50\ud835\udc59\ud835\udc59\ud835\udc50\ud835\udc50\ud835\udc63\ud835\udc63\ud835\udc61\ud835\udc61() is concatenation function and it is feature merging function. By using Step 2, 19 feature vectors have been created and the length of each feature vector is 500 (=486 + 14). Step 3: Concatenate the 19 generated feature vectors to create the final feature vectors.\n\ud835\udc61\ud835\udc61\ud835\udc54\ud835\udc54(\ud835\udc5d\ud835\udc5d) = \ud835\udc4b\ud835\udc4b\ufffd\ud835\udc5d\ud835\udc5d + 500 \u00d7 (\ud835\udc54\ud835\udc54 \u2212 1)\ufffd, \ud835\udc5d\ud835\udc5d \u2208 {1,2, \u2026 ,500},\ud835\udc54\ud835\udc54 \u2208 {1,2, \u2026 ,19} (12) Herein, \ud835\udc4b\ud835\udc4b defines the merged feature vector with a length of 9500 (=500 \u00d7 19).\nFig re 3. e erate co f sion atrices by TMP19 on the ADHD EEG dataset by deploying (a) 10-fold CV, (b) LOSO CV. Herein, the used classes are enumerated as 1 and 2. These numbers are defined as healthy and ADHD classes. 1: Healthy, 2: ADHD.\n. . . t r t ti\nI the feature extraction phase, we utilized three methods: (i) TQWT [31], (ii) the roposed TMP feature extractio function, and (iii) statistical feature generator. First, we gen rated wavelet bands using TQWT transformation. TQWT is parametric and thirdgeneration wavelet transform. By using re u dancy (r), oscillation (Q), and the number of level (J) parameters, v riable multileveled wavelet transform was created. The high oscillatory wavelet transform w s assigned 4 and 3 for the Q and r p ram ters.\ne s ste \u2019s ai ai as t r ose a e feat re engineering odel as in arket19. h s, e generate 18 avelet coefficient ban s to se 19 in ts. hese 19 signals (ra EE signal + 18 avelet bands) have been utilized as inputs to the feature extraction functions. The syste contains t o feature extraction functions: the TMP and the statistical feature generator. Both statistical parameters and motifs have been extracted using these feature extractors in the space and frequency domains. The steps of the proposed feature extraction method are given below.\nA ply TQWT to the EG signal for generating wavelet bands.\nR = \u03c4(S, 4, 3, 17) (9)\nwhere R defines TQWT bands, S is the EEG signal, 4, 3, and 18 are the Q, r, and J parameters of the TQWT function (\u03c4()).\nStep 2: Generate features using TMP and statistical feature generation function.\nf1 = concat(TMP(S), SG S)) (10)\nfl+1 = concat(TMP(Rl), SG(Rl)), l \u2208 {1, 2, . . . , 18} (11)\nIn this step (Step 2), 19 feature vectors have been ge erated by deploying the TMP feature generator (TMP()), and statistical generator (SG()). TMP() function generates 486 features from a one-dimensional signal, and SG() extracts 14 features from a signal since 14 statistical moments [32] have been used in this function. These moments are (i) maximum, (ii) minimum, (iii) average, (iv) variance, (v) standard deviation, (vi) median,\n(vii) range, (viii) root mean square, (ix) energy, (x) Shannon entropy, (xi) sure entropy, (xii) log energy entropy, (xiii) threshold entropy, and (xiv) mean absolute deviation. concat() is concatenation function and it is feature merging function. By using Step 2, 19 feature vectors have been created and the length of each feature vector is 500 (=486 + 14).\nStep 3: Concatenate the 19 generated feature vectors to create the final feature vectors.\nfg(p) = X(p + 500\u00d7 (g\u2212 1)), p \u2208 {1, 2, . . . , 500}, g \u2208 {1, 2, . . . , 19} (12)\nHerein, X defines the merged feature vector with a length of 9500 (=500 \u00d7 19).\n2.2.2. Feature Selection\nIn this research, we proposed an improved NCA-based protocol [33], with the feature selection method being named the threshold-based NCA. The selector has two layers: (i) threshold-based redundant feature elimination and (ii) NCA-based feature selection. In this phase, we selected the most informative and valuable 250 features from the generated 9500 features. The steps of this phase are:\nStep 4: Normalize the final feature vector by deploying a min-max normalization.\nXN = X\u2212min(X)\nmax(X)\u2212min(X) (13)\nwhere XN defines the normalized final features, and min() and max() are the minima and maximum value finding functions, respectively.\nStep 5: Eliminate the redundant features using a threshold value.\nagd = n\n\u2211 i=1\nXN(d, i), d \u2208 {1, 2, . . . , dim} (14)\nnX(:, ct) = X(:, i), i f agd > th (15)\nHerein, the summarization value of each vector (agd) has been calculated in Equation (14), where dim is the number of EEG signals. In Equation (15), features are eliminated, and a new final feature vector (nX) has been generated using a threshold value (th). In this research, th is selected as zero.\nStep 6: Calculate qualified/sorted indexes by deploying the NCA feature selection function.\nid = \u03be(nX, y) (16)\nwhere id is a sorted index vector with a length of 9500, y defines real outputs/labels, and \u03be() is the NCA feature selection function.\nStep 7: Select the most meaningful 250 features from the nX.\nsX(d, i) = nX(d, id(i)), i \u2208 {1, 2, . . . , 250} (17)\nHerein, sX is a selected feature vector with a length of 250.\n2.2.3. Classification\nTo obtain classification accuracy and the predicted vector of each channel, we used a simple/shallow classifier. The kNN [34] classifier has been used, which is named the Weighted kNN. The hyperparameters of the Weighted kNN are:\nk:10; Distance weight: squared inverse; Distance: L1-norm (Manhattan); Validation: 10-fold CV/LOSO CV.\nAs is evident from the above description, we used two validation techniques (10-fold CV and LOSO CV) to calculate the robust results obtained with this classifier. The classification step is given below.\nStep 8: Calculate the predicted vector of each channel by applying the kNN classifier.\npc = \u03ba(sX, y), c \u2208 {1, 2, . . . , 14} (18)\nwhere pc represented predicted vectors of the cth channel, and \u03ba() is the defined kNN classifier.\nStep 9: Repeat Steps 1\u20138 by the number of channels. We used an ADHD dataset containing 14 channels. Thus, we repeated these steps 14 times.\n2.2.4. Majority Voting\nIn the majority voting phase, the iterative hard majority voting (IHMV) algorithm was used to obtain the best classification result. IHMV was proposed by Dogan et al. [35] in 2021. We calculated 14 predicted vectors from the EEG channels individually. By incorporating the 14 predicted vectors, 12 (=14 \u2212 2) new voted predicted vectors were created for each validation technique. The steps of this phase are listed below.\nStep 10: Calculate the classification accuracy of each channel. Step 11: Qualify/sort the predicted vectors using the predicted vectors and obtain quali-\nfied/sorted indexes.\nix = sort(p) (19)\nwhere ix defines indexes of the sorted predicted vectors.\nStep 12: Calculate voted predicted vectors by deploying the mode function.\nvr\u22122 = \u03c9 ( pix1 , pix2 , . . . , pixr ) , r \u2208 {3, 4, . . . , C} (20)\nHerein, v represents the voted vector, C represents the number of channels, and \u03c9() defines the mode function. In these steps, 12 voted vectors have been generated.\nStep 13: Calculate classification accuracies of the voted vectors. Step 14: Choose the most accurate voted vector as the final predicted vector.\nThe given 14 steps above define the proposed TMP19 feature engineering model."
        },
        {
            "heading": "3. Results",
            "text": "We have proposed a new feature engineering model that uses four phases in this research. These phases use lightweight methods. Thus, the proposed TMP19 is a lightweight signal classification model, and there is no need to use expensive hardware. We implemented this model on a simply configured computer (main memory: 16 GB, processor: Intel i7-7700, operating system: Windows 11, programming environment: MATLAB 2021a). We used two validation techniques. Moreover, channel-wise voted results have been given in this section."
        },
        {
            "heading": "3.1. Performance Metrics",
            "text": "The used ADHD EEG dataset contains two classes, ADHD and normal. Thus, this is a binary classification problem. We built in two common classification performance measures: classification accuracy and geometric mean. To assess these metrics, the number of true positives (tp), false positives (fp), true negatives (tn), and false negatives (fn) are deployed. The mathematical notations of the accuracy (acc) and geometric mean (gm) are given below.\nacc = tp + tn\ntp + f p + tn + f n (21)\ngm =\n\u221a tp\ntp + f n \u00d7 tn tn + f p (22)"
        },
        {
            "heading": "3.2. Channel-Wise Results",
            "text": "The used EEG dataset contains 14 channels. To comprehensively depict the proposed model\u2019s classification performance, we applied our proposal to each channel, and the classification performances of each channel were calculated. Furthermore, two validations were used in the classification phase. The channel-wise results are tabulated in Table 1.\nTable 1 highlights the best results using a bold font face. By applying a 10-fold CV, the most accurate channel is the 13th since our TMP19 model yielded 92.16% classification accuracy and 91.91% geometric mean. According to LOSO CV results, the best classification accuracy is 74.84% on the 7th channel, and the best geometric mean attained on the 13th channel by employing LOSO CV."
        },
        {
            "heading": "3.3. Voted Results",
            "text": "In the last phase of the TMP19, the majority voting component is availed of. We applied the IHMV algorithm in this phase to create C-2-voted vectors. Twelve voted vectors were generated by deploying the IHMV algorithm. The results of the voted vectors are listed in Table 2. Table 2 shows that the best classification accuracies were obtained by using 11th and 1st voted vectors when deploying 10-fold CV and LOSO CV, respectively. Per Table 2, IHMV increased the classification accuracies from 92.16% and 74.84% to 95.57% and 77.93% by deploying 10-fold CV and LOSO CV, respectively. These results are the final results of the proposed TMP19."
        },
        {
            "heading": "3.4. Final Results",
            "text": "Our proposed TMP19-based model generates 26 (=14 results from 14 channels + 12 voted results) results, and this model selects the best results among the 26 generated results. Thus, the suggested TMP19 is a self-organized feature engineering model. Moreover, two validations were applied in the classification phase. The calculated confusion matrices of the presented TMP19 by deploying LOSO CV and 10-fold CV are given in Figure 3. As can be seen from Figure 3, our proposed TMP19 attained 95.57% and 77.93% classification accuracies on the ADHD dataset with a 10-fold CV and LOSO CV, respectively."
        },
        {
            "heading": "4. Discussion",
            "text": "A new feature engineering model has been proposed in this research by mimicking a deep learning structure. The main motivation of the proposed TMP19 is to extract hidden motifs to obtain high classification performances. The TMP19 generates features at both high levels and low levels. High-level features have been generated using wavelet bands. Moreover, features at the frequency domain have been extracted. The threshold-based NCA method has been used to obtain distinctive features. kNN has been employed to show the classification capability of the generated features. The best classification results were generated and selected from the model by applying a majority voting technique. Then the channel-wise and voted results were given. Per the results, the most appropriate channels are the 7th and 13th for ADHD detection. Our model attained a 95.57% classification accuracy by deploying a 10-fold CV and a 77.93% classification accuracy using LOSO CV. These results showed that the presented TMP19 is a successful EEG classification model. Furthermore, we believe that we are the first team to use this dataset to develop a machine-learning model. The results of other state-of-art classification models and our TMP19 were compared to highlight the classification ability of our model. These results are listed in Table 3.\nAs can be seen from Table 3, our model produced better accuracy than the results of other state-of-the-art methods. Tor et al. [27] achieved better accuracy than our study. They used 3 classes with 123 subjects in the study. Classes include 45 ADHD, 62 conduct disorder + ADHD, and 16 conduct disorder subjects, and the amount of data for each class is small. In addition, two different validation techniques were used in this study. These are the 10-fold CV and the LOSO CV, respectively. Another advantage is that noisy EEG signals were used in our study. A superior side of our study to other previously presented works is to use LOSO CV. Since reliable results have been calculated using LOSO CV, we depicted our model\u2019s performances in real-world applications by helping LOSO CV. Although our proposed method exhibits a low computational complexity, it outperforms. The results obtained show the superiority of the proposed method.\nThe benefits of the presented TMP:\n\u2022 A novel feature generation function was introduced. This function generates motifs. Thus, this feature generator is named TMP. \u2022 An accurate one-dimensional signal classification architecture has been proposed by using TMP. This model contains 19 levels. Thus, it is named TMP19. \u2022 Simple methods have been used to create the TMP19 model. Thus, the implementation of this model is straightforward and of low complexity.\n\u2022 TMP19 is a parametric model. Therefore, next-generation TMP-based classification models can be proposed by using different classification methods. \u2022 TMP19 is a highly accurate model. \u2022 The robustness of the presented TMP19 is demonstrated by deploying a 10-fold CV\nand LOSO CV.\nDrawbacks:\n\u2022 Parameters should be optimized to gain higher classification performances. \u2022 Recently, authors in [37] have developed an automated system to detect ADHD and\nconduct disorder in children using empirical wavelet transform and entropy features extracted from electrocardiogram (ECG) signals. They obtained an accuracy of 88% in classifying ADHD, ADHD + CD, and CD patients for appropriate intervention using accessible ECG signals. In the future, ECG and heart rate variability (HRV) signals can be used for automated ADHD detection as they can be easily acquired using wearable devices.\n\u2022 More disorders can be used to evaluate the performance of the TMP19 model."
        },
        {
            "heading": "5. Conclusions",
            "text": "ADHD detection using EEG signals has great potential in improving the equitable early diagnosis of ADHD, maximizing appropriate treatments, and minimizing the potential longterm negative impacts of this globally common neurodevelopmental condition. However, there is a lack of consensus on the best way to utilize EEG and how machine learning may be beneficial in optimizing this as a diagnostic tool. To overcome this problem, we proposed a new feature generator called TMP. The main goal of the TMP is to extract distinctive features from EEG signals. A feature engineering model was proposed by applying the proposed feature generator\u2014TMP. This model has 19 levels in the feature extraction phase. Hence, it is named TMP19. TMP19 was applied to a noisy EEG signal dataset for the detection of ADHD. Moreover, we used two validation techniques to show the robustness of the proposed TMP19. As can be seen from Section 5, our TMP19 reached 95.57% and 77.93% classification accuracies using 10-fold CV and LOSO CV techniques, respectively. We plan to develop an intelligent EEG signal classification application in future work. This application will extract information from EEG signals to detect ADHD and potentially other neurodevelopmental and mental health conditions. Moreover, we plan to devise and develop an intelligent brain cap that will detect changes automatically.\nAuthor Contributions: Conceptualization: P.D.B., S.D., M.B., T.T., E.E.P., E.J.C., U.R.A.; methodology, P.D.B., S.D., M.B., T.T., E.E.P., E.J.C., U.R.A.; software, S.D., T.T.; validation, P.D.B., S.D., M.B., T.T.; formal analysis, P.D.B., S.D., M.B., T.T., E.E.P., E.J.C., U.R.A.; investigation P.D.B., S.D., M.B., T.T.; resources, P.D.B., S.D., M.B., T.T.; data curation, P.D.B., S.D., M.B., T.T.; writing\u2014original draft preparation, P.D.B., S.D., M.B., T.T., E.E.P., E.J.C., U.R.A.; writing\u2014review and editing, P.D.B., S.D., M.B., T.T., E.E.P., E.J.C., U.R.A.; visualization, P.D.B., S.D., M.B., T.T., E.E.P., E.J.C., U.R.A.; supervision, U.R.A.; project administration, U.R.A. All authors have read and agreed to the published version of the manuscript.\nFunding: This research received no external funding.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: The EEG dataset database has been downloaded from [29,30].\nConflicts of Interest: The authors declare no conflict of interest."
        }
    ],
    "title": "TMP19: A Novel Ternary Motif Pattern-Based ADHD Detection Model Using EEG Signals",
    "year": 2022
}