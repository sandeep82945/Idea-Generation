{
    "abstractText": "Aiming at the insufficient accuracy and accumulated error of the point cloud registration of LiDAR-inertial odometry (LIO) in an urban environment, we propose a LiDAR-inertial-GNSS fusion positioning algorithm based on voxelized accurate registration. Firstly, a voxelized point cloud downsampling method based on curvature segmentation is proposed. Rough classification is carried out by the curvature threshold, and the voxelized point cloud downsampling is performed using HashMap instead of a random sample consensus algorithm. Secondly, a point cloud registration model based on the nearest neighbors of the point and neighborhood point sets is constructed. Furthermore, an iterative termination threshold is set to reduce the probability of the local optimal solution. The registration time of a single frame point cloud is increased by an order of magnitude. Finally, we propose a LIO-GNSS fusion positioning model based on graph optimization that uses GNSS observations weighted by confidence to globally correct local drift. The experimental results show that the average root mean square error of the absolute trajectory error of our algorithm is 1.58m on average in a large-scale outdoor environment, which is approximately 83.5% higher than that of similar algorithms. It is fully proved that our algorithm can realize a more continuous and accurate position and attitude estimation and map reconstruction in urban environments.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xuan He"
        },
        {
            "affiliations": [],
            "name": "Shuguo Pan"
        },
        {
            "affiliations": [],
            "name": "Wang Gao"
        },
        {
            "affiliations": [],
            "name": "Xinyu Lu"
        }
    ],
    "id": "SP:3e9dc1a41a46151f959e197b3ab178923b195eec",
    "references": [
        {
            "authors": [
                "R. Mascaro",
                "L. Teixeira",
                "T. Hinzmann",
                "R. Siegwart",
                "M. Chli"
            ],
            "title": "GOMSF: Graph-Optimization based Multi-Sensor Fusion for robust UAV pose estimation",
            "venue": "In Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, Australia,",
            "year": 2018
        },
        {
            "authors": [
                "W. Lee",
                "K. Eckenhoff",
                "P. Geneva",
                "G.Q. Huang"
            ],
            "title": "Intermittent GPS-aided VIO: Online Initialization and Calibration",
            "venue": "In Proceedings of the 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France,",
            "year": 2020
        },
        {
            "authors": [
                "J. Zhang",
                "K. Khoshelham",
                "A. Khodabandeh"
            ],
            "title": "Seamless Vehicle Positioning by Lidar-GNSS Integration: Standalone and MultiEpoch Scenarios",
            "venue": "Remote Sens. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "C. Forster",
                "L. Carione",
                "F. Dellaert",
                "D. Scaramuzza"
            ],
            "title": "On-Manifold Preintegration for Real-Time Visual\u2013Inertial Odometry",
            "venue": "IEEE Trans. Robot",
            "year": 2017
        },
        {
            "authors": [
                "T. Shan",
                "B. Englot"
            ],
            "title": "LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain",
            "venue": "In Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),",
            "year": 2018
        },
        {
            "authors": [
                "S. Li",
                "J. Li",
                "B. Tian",
                "L. Chen",
                "L. Wang",
                "G. Li"
            ],
            "title": "A laser SLAM method for unmanned vehicles in point cloud degenerated tunnel environments",
            "venue": "Acta Geod. Cartogr. Sin. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "Z. Gong",
                "P. Liu",
                "F. Wen",
                "R.D. Ying",
                "X.W. Ji",
                "R.H. Miao",
                "W.Y. Xue"
            ],
            "title": "Graph-Based Adaptive Fusion of GNSS and VIO Under Intermittent GNSS-Degraded Environment",
            "venue": "IEEE Trans. Instrum. Meas",
            "year": 2021
        },
        {
            "authors": [
                "X. He",
                "W. Gao",
                "C.Z. Sheng",
                "Z.T. Zhang",
                "S.G. Pan",
                "L.J. Duan",
                "H. Zhang",
                "X.Y. Lu"
            ],
            "title": "LiDAR-Visual-Inertial Odometry Based on Optimized Visual Point-Line Features",
            "venue": "Remote Sens. 2022,",
            "year": 2022
        },
        {
            "authors": [
                "P. Biber",
                "W. Strasser"
            ],
            "title": "The normal distributions transform: A new approach to laser scan matching",
            "venue": "In Proceedings of the 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Las Vegas, NV,",
            "year": 2003
        },
        {
            "authors": [
                "P.J. Besl",
                "N.D. Mckay"
            ],
            "title": "A method for registration of 3-D shapes",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 1992
        },
        {
            "authors": [
                "J. Servos",
                "S.L. Waslander"
            ],
            "title": "Multi-Channel Generalized-ICP",
            "venue": "Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA), Hong Kong, China,",
            "year": 2014
        },
        {
            "authors": [
                "S.Y. Du",
                "J. Liu",
                "B. Bi",
                "J.H. Zhu",
                "J.R. Xue"
            ],
            "title": "New iterative closest point algorithm for isotropic scaling registration of point sets with noise",
            "venue": "J. Vis. Commun. Image Represent",
            "year": 2016
        },
        {
            "authors": [
                "Z. Wu",
                "H. Chen",
                "S. Du"
            ],
            "title": "Robust Affine Iterative Closest Point Algorithm Based on Correntropy for 2D Point Set Registration",
            "venue": "In Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN),",
            "year": 2016
        },
        {
            "authors": [
                "L.Y. Wu",
                "L. Xiong",
                "D.Y. Bi",
                "T. Fang",
                "S.Y. Du",
                "W.T. Cui"
            ],
            "title": "Robust Affine Registration Based on Corner Point Guided ICP Algorithm",
            "venue": "In Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics (SMC),",
            "year": 2017
        },
        {
            "authors": [
                "G. Grisetti",
                "C. Stachniss",
                "W. Burgard"
            ],
            "title": "Improved techniques for grid mapping with Rao-Blackwellized particle filters",
            "venue": "IEEE Trans. Robot",
            "year": 2007
        },
        {
            "authors": [
                "H. Andreasson",
                "T. Stoyanov"
            ],
            "title": "Real-Time Registration of RGB-D Data Using Local Visual Features and 3D-NDT Registration",
            "venue": "[DB/OL]. Available online: https://www.researchgate.net/publication/267688026_Real_Time_Registration_of_RGB-D_Data_ using_Local_Visual_Features_and_3D-NDT_Registration (accessed on",
            "year": 2022
        },
        {
            "authors": [
                "F. Caballero",
                "L. Merino"
            ],
            "title": "DLL: Direct LIDAR Localization. A map-based localization approach for aerial robots",
            "venue": "In Proceedings of the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Prague, Czech Republic,",
            "year": 2021
        },
        {
            "authors": [
                "C. Chen",
                "B. Yang",
                "M. Tian",
                "J. Li",
                "X. Zou",
                "W. Wu",
                "Y. Song"
            ],
            "title": "Automatic registration of vehicle-borne mobile mapping laser point cloud and sequent panoramas",
            "venue": "Acta Geo Daetica Cartogr. Sin. 2018,",
            "year": 2018
        },
        {
            "authors": [
                "K. Koide",
                "M. Yokozukam",
                "S. Oishi",
                "A. Banno"
            ],
            "title": "Voxelized GICP for Fast and Accurate 3D Point Cloud Registration",
            "venue": "In Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), Xi\u2019an, China,",
            "year": 2021
        },
        {
            "authors": [
                "J. Yang",
                "H.D. Li",
                "D. Campbell",
                "Y. Jia"
            ],
            "title": "Go-ICP: A Globally Optimal Solution to 3D ICP Point-Set Registration",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 2016
        },
        {
            "authors": [
                "Y. Pan",
                "P. Xiao",
                "Y. He",
                "Z. Shao",
                "Z. Li"
            ],
            "title": "MULLS: Versatile LiDAR SLAM via Multi-metric Linear Least Square",
            "venue": "In Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), Xi\u2019an, China,",
            "year": 2021
        },
        {
            "authors": [
                "C. Qin",
                "H. Ye",
                "C.E. Pranata",
                "J. Han",
                "S. Zhang",
                "M. Liu"
            ],
            "title": "LINS: A Lidar-Inertial State Estimator for Robust and Efficient Navigation",
            "venue": "In Proceedings of the 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France,",
            "year": 2020
        },
        {
            "authors": [
                "W. Li",
                "G. Liu",
                "X. Cui",
                "M. Lu"
            ],
            "title": "Feature-Aided RTK/LiDAR/INS Integrated Positioning System with Parallel Filters in the Ambiguity-Position-Joint Domain for Urban Environments",
            "venue": "Remote Sens. 2021,",
            "year": 2013
        },
        {
            "authors": [
                "X.X. Li",
                "H.D. Wang",
                "S.Y. Li",
                "S.Q. Feng",
                "X.B. Wang",
                "J.C. Liao"
            ],
            "title": "GIL: A tightly coupled GNSS PPP/INS/LiDAR method for precise vehicle navigation",
            "venue": "Satell. Navig. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "A. Soloviev"
            ],
            "title": "Tight Coupling of GPS, INS, and Laser for Urban Navigation",
            "venue": "IEEE Trans. Aerosp. Electron. Syst",
            "year": 2010
        },
        {
            "authors": [
                "T. Shan",
                "B. Englot",
                "D. Meyers",
                "W. Wang",
                "C. Ratti",
                "D. Rus"
            ],
            "title": "LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping",
            "venue": "In Proceedings of the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Las Vegas, NV, USA,",
            "year": 2021
        },
        {
            "authors": [
                "X. Sun",
                "H. Guan",
                "Y. Su",
                "G. Xu",
                "Q. Guo"
            ],
            "title": "A tightly coupled SLAM method for precise urban mapping",
            "venue": "Acta Geod. Cartogr. Sin. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "A. Geiger",
                "P. Lenz",
                "C. Stiller",
                "R. Urtasun"
            ],
            "title": "Vision meets robotics: The KITTI dataset",
            "venue": "Int. J. Robot. Res",
            "year": 2013
        },
        {
            "authors": [
                "S. Chen",
                "B. Zhou",
                "C. Jiang",
                "W. Xue",
                "Q. Li"
            ],
            "title": "A LiDAR/Visual SLAM Backend with Loop Closure Detection and Graph Optimization",
            "venue": "Remote Sens. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "T. Qin",
                "P. Li",
                "S. Shen"
            ],
            "title": "Vins-mono: A robust and versatile monocular visual-inertial state estimator",
            "venue": "IEEE Trans. Robot",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Citation: He, X.; Pan, S.; Gao, W.; Lu,\nX. LiDAR-Inertial-GNSS Fusion\nPositioning System in Urban\nEnvironment: Local Accurate\nRegistration and Global Drift-Free.\nRemote Sens. 2022, 14, 2104.\nhttps://doi.org/10.3390/rs14092104\nAcademic Editor: Francesco Nex\nReceived: 14 March 2022\nAccepted: 25 April 2022\nPublished: 27 April 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: LiDAR-inertial odometry; point cloud registration; multi-sensor fusion"
        },
        {
            "heading": "1. Introduction",
            "text": "For any autonomous robot system, such as unmanned aerial vehicles and autonomous vehicles, the accurate and robust localization of a mobile carrier is one of the fundamental technologies [1]. Traditionally, the integrated navigation and positioning technology based on the global navigation satellite system (GNSS) and inertial navigation system (INS) is usually regarded as a reliable method to achieve high-accuracy positioning [2]. However, in complex urban environments, there are a large number of GNSS multipath or rejection areas due to the blockage of GNSS signals by urban objects such as tall buildings, tunnels and street trees. As a result, the integrated positioning method based on GNSS/INS is not effective in achieving a continuous and robust positioning of targets in large urban environments. In summary, there is an urgent need to upgrade and expand the traditional positioning techniques by introducing heterogeneous and complementary measurement information from other sensors. In recent years, the multi-sensor fusion positioning technology based on simultaneous localization and mapping (SLAM) has received extensive attention from related enterprises and researchers [3]. It can not only make use of the excellent characteristics of cameras, LiDAR and other sensors, including the independence from environmental occlusion and signal refraction in complex areas, but can also effectively make up for the signal lock-out defect of GNSS signals in the parking lot or tunnel area. Moreover, incremental map reconstruction can be achieved by sensing the external environment. Depending\nRemote Sens. 2022, 14, 2104. https://doi.org/10.3390/rs14092104 https://www.mdpi.com/journal/remotesensing\nRemote Sens. 2022, 14, 2104 2 of 26\non the primary sensor, SLAM-based multi-sensor fusion positioning solutions can be divided into vision-based SLAM and LiDAR-based SLAM [4]. Due to the superiority of the sensors, the solution of LiDAR-based SLAM allows for a higher frequency and more accurate acquisition of spatial fingerprint information, thus achieving a more accurate positioning than vision-based SLAM [5\u20137]. Secondly, analyzed at the algorithm level, LiDAR odometry is more lightweight in processing environmental features than visual odometry and more suitable for vehicle-mounted platforms with limited computational resources [8,9]. Therefore, the LiDAR-inertial odometry (LIO)-based SLAM scheme is widely used to obtain 3D geographic information of a complex environment, as well as carrier positioning and map reconstruction. Throughout the development of the LiDAR-based SLAM, it can be seen that the registration of the point cloud of LiDAR is a key step in the pose estimation of a mobile carrier. It strictly affects the pose estimation and the map reconstruction results. The commonly used point cloud registration methods include normal distribution transform (NDT) [10], iterative closest point (ICP) [11], generalized iterative closest point (GICP) [12] and other improved algorithms [13\u201316]. The core of NDT algorithm is used to take the probability density function of the source point cloud and the target point cloud as the objective function; then, it uses a nonlinear optimization method to minimize the probability density between them to obtain the optimal solution. Andreasson et al. [17] avoids an explicit nearest neighbor search by establishing segmented continuous and differentiable probability distributions, and the registration speed is effectively improved. Although the real-time performance is better, the covariance matrix needs to be constructed at multiple points, which has a low robustness in the sparse area of the point cloud. Caballero et al. [18] proposed an improved NDT algorithm that was used to model the alignment problem as a distance field. The optimization equation is constructed by using the distance between the feature points of the current frame and the prior map, which improves the speed by an order of magnitude. However, the robustness of the localization algorithm is not guaranteed for unknown sections where the priori map is missing or unreliable [19]. As another method of point cloud registration, the ICP algorithm has a higher positioning accuracy than NDT, but it needs to search for the nearest neighbor again and obtain the transformation matrix in each iteration process, so the calculation efficiency needs to be improved. Koide et al. [20] proposed a generalized iterative nearest point algorithm that used a Gaussian probability model to fit the distribution of the point cloud to reduce the computational complexity. However, its accuracy is still limited by the maximum number of iterations. In addition, the algorithm is heavily influenced by the observation noise and the accuracy of the initial positional transformation matrix, and there is a risk of the algorithm falling into local minima. In order to break out of the logical limitation of being limited to local optimal solutions, Yang et al. [21] proposed Go-ICP, a branch-and-bound scheme to impose domain restrictions on the objective function of rigid alignment. This processing reduced the abnormal influence of the local minimum, and made the registration result of the point cloud approach to the global optimal solution. In 2021, Pan et al. [22] proposed MULLS-ICP, which uses an improved ICP algorithm based on double-threshold filtering and multi-scale linear least squares to realize the registration between the current frame and local sub-map, but the high computational cost of multiple filtering is difficult to adapt to the vehicle platform with limited computational resources. To sum up, on the basis of reducing the calculation cost, a high-precision real-time point cloud registration algorithm suitable for a vehicle platform still needs to be investigated. In addition, as a local sensor integrator, the LIO has a cumulative offset between its local map and the global map when it performs a positional estimation of the current frame, which largely limits the positioning accuracy of the LIO position building scheme in large outdoor environments. Fortunately, the global observation information from GNSS can provide a credible global constraint correction for LIO [23]. Conversely, LIO systems can also compensate for the limitations of GNSS in terms of continuous precise positioning due to multipath effects and non-line-of-sight (NLOS) problems. Therefore, LIO-GNSS fusion\nRemote Sens. 2022, 14, 2104 3 of 26\npositioning technology provides a feasible technical scheme for realizing globally weak drift and locally accurate positioning and mapping targets. The mainstream LIO-GNSS fusion algorithms can be divided into two categories, filter-based methods and optimization-based methods, based on the method of sensor measurement data fusion. Li et al. [24] used the filter-based method as the integration strategy. They use the extended Kalman filter to realize LIO-GNSS tight coupling, but did not set up an anomaly detection mechanism, so it was prone to the dispersion of the positional estimates in GNSS multipath regions or point cloud degradation regions. To resolve this issue, Li et al. [25] uses an edge fault-tolerant mechanism to improve the robustness of the algorithm in case of single-sensor failure. However, it weakens the linearization error at the cost of increasing the amount of computation, which is contrary to the lightweight principle of large outdoor scenes. As another fusion method, the optimization-based method uses multiple iterations to approach the optimal solution, which can effectively handle such non-linear heterogeneous data fusion problems. Soloviev et al. [26] proposed an optimization-based LIO-GNSS scheme, but only the horizontal components of GNSS measurements were used to optimize the LIO pose estimation results, with low utilization of the measurement information. Shan et al. [27] puts forward an optimization framework that introduces 3D GNSS measurement factors to assist LIO, but the measurement information of a single key frame is redundant, and the reliability of GNSS factors added when driving to the GNSS multipath area is poor. Sun et al. [28] proposed a GNSS corner factor to constrain the local pose, but it does not consider the shortage of corners on straight road sections, so its application in a large-scale complex outdoor environment is limited. From the above analysis, it can be seen that the research points of the LIO-GNSS fusion scheme are as follows:\n1. Realizing real-time and high-precision point cloud alignment based on compressed computational costs. 2. On the basis of making full use of GNSS measurement information, global cumulative error correction of LIO is carried out by GNSS.\nTo address the above issues, in this contribution, we propose a LiDAR-inertial-GNSS fusion positioning system based on voxelized accurate registration. Firstly, a voxelized point cloud downsampling method based on curvature segmentation is proposed. Rough classification is carried out by a curvature threshold, and the voxelized point cloud downsampling is performed using HashMap instead of the random sample consensus algorithm. Therefore, the spatial distribution attributes of the source point cloud are retained to a greater extent. Secondly, a point cloud registration model based on the nearest neighbors of the point and neighborhood point sets is constructed. Thirdly, an optimization-based method is used to build a higher-order Markov model based on sliding windows, and a GNSS factor and loop factor are introduced into the factor graph to constrain LIO globally. Finally, on this basis, a GNSS residual construction method based on the GNSS reliability weight is proposed to make full use of GNSS measurement information. Therefore, the goal of positioning and mapping with a light weight, high precision and high applicability in a complex urban environment can be achieved."
        },
        {
            "heading": "2. System Overview",
            "text": "The proposed algorithm framework is shown in Figure 1. The main functions of each module are as follows. The front-end of the system is mainly used to preprocess IMU observations and LiDAR original point cloud sequences, and to optimize the generation of local maps by inter-frame matching. The LiDAR raw point cloud sequence is clustered and segmented by a breadthfirst-search combined with the Euclidean angle threshold, and then edge and plane feature point clouds are extracted. These two types of feature clouds are downsampled for point cloud alignment, and the local inter-frame matching is optimized using the IMU preintegration as the initial pose estimate. Finally, the LIO local pose estimates are used to pre-process the GNSS global observations, including the temporal interpolation alignment\nRemote Sens. 2022, 14, 2104 4 of 26\nof GNSS and LIO local observations and coordinate system alignment, so as to achieve the space\u2013time synchronization among sensors.\nRemote Sens. 2022, 14, x FOR PEER REVIEW 4 of 28 plane feature point clouds are extracted. These two types of feature clouds are downsampled for point cloud alignment, and the local inter-frame matching is optimized using the IMU pre-integration as the initial pose estimate. Finally, the LIO local pose estimates are used to pre-process the GNSS global observations, including the temporal interpolation alignment of GNSS and LIO local observations and coordinate system alignment, so as to achieve the space\u2013time synchronization among sensors.\nThe back-end mainly uses the residuals of pose estimates of each sensor to optimize the map. The residual factors from local sensors include the IMU pre-integration and LiDAR observation residual, whereas the global residual factors include the GNSS observation residual and loop residual. It should be noted that the global residual factors are added only when their existence is detected, and, when there is no global residual factor, the system only performs local position, such as when the carrier is travelling in a flat and straight tunnel environment. When global corrections are available, the obtained global positioning results are used to update the local pose estimates in the sliding window to obtain the best pose estimates with local accurate registration and global drift-free."
        },
        {
            "heading": "3. Point Cloud Voxelization Downsampling and Alignment",
            "text": "The accuracy of the registration of the environmental point cloud extracted by LiDAR strictly affects the result of the subsequent local pose estimation. Therefore, the processing steps of the front-end point cloud of the system need to be described in detail. This paper mainly involves the improved point cloud downsampling method and registration method."
        },
        {
            "heading": "3.1. Voxelized Downsampling Based on Curvature Segmentation",
            "text": "This paper presents a voxelized downsampling method based on curvature segmentation. Given a set of raw point cloud sequences collected by LiDAR, all points in the raw point cloud sequences are traversed and coarse clustering is performed using a breadthfirst algorithm. Furthermore, the geometric angle threshold based on Euclidean distance is used to finely segment the point cloud clusters with similar depth. Let the scanning center of LiDAR be O and the two adjacent edge points ap and bp in the point cloud cluster with depths ad and bd , respectively ( a bd d> ). Let the number of point clouds in\n. General framework of the algorithm. LIO\u2019s po e estimation results are used as local optimization factors, and GNSS pseudo-range single point positioning (SPP) results are used as global optimization factors for global constraint.\nThe back-end mainly uses the residuals of pose estimat s of each sensor to optimize the map. The residual factors from local sensors include the IMU pre-integration and Li observation residual, whereas the global residual factors include the GNSS observation residual and loop residual. It should be noted that the global residual factors are added only when their existence is detected, and, when there is no global residual factor, the system only performs local position, such as when the carrier is travelling in a flat and straight tunnel environment. When global corrections are available, the obtained global positioning results are used to update the local pose estimates in the sliding window to obtain the best pose estimates with local accurate registration and global drift-free."
        },
        {
            "heading": "3. Point Cloud Voxelization Downsampling and Alignment",
            "text": "The accuracy of the registration of the environmental point cloud extracted by LiDAR strictly affects the result of the subsequent local pose estimation. Therefore, the processing steps of the front-end point cloud of the system need to be described in detail. This paper mainly involves the improved point cloud downsampling method and registration method."
        },
        {
            "heading": "3.1. Voxelized Downsampling Based on Curvature Segmentation",
            "text": "This paper presents a voxelized downsampling method based on curvature segmentation. Given a set of raw point cloud sequences collected by LiDAR, all points in the raw point cloud sequences are traversed and coarse clustering is performed using a breadth-first algorithm. Furthermore, the geometric angle threshold based on Euclidean distance is used to finely segment the point cloud clusters with similar depth. Let the scanning center of LiDAR be O and the two adjacent edge points pa and pb in the point cloud cluster with depths da and db, respectively (da > db). Let the number of point clouds in the point cloud cluster where point pi is located be M. Then, the roughness of point cloud pi is:\nc = 1\n|M| \u00b7 \u2016di\u2016 \u2223\u2223\u2223\u2223\u2223 \u2223\u2223\u2223\u2223\u2223\u2211j 6=i ( di \u2212 dj )\u2223\u2223\u2223\u2223\u2223 \u2223\u2223\u2223\u2223\u2223, i, j \u2208 M (1)\nRemote Sens. 2022, 14, 2104 5 of 26\nSet the roughness threshold as c, then traverse M. We classify the points of c < c as the set of edge feature points, classify the points of c > c as the set of plane feature points and perform downsampling operations on them, respectively. This method is mainly used in the feature extraction step of LiDAR odometry [4]; we extend it to the downsampling step. This means that, for any application where downsampling of point clouds is required, such as artefact inspection, the method can better restore the spatial distribution properties of point clouds by downsampling in clusters. Next, this paper proposes a point cloud downsampling strategy based on HashMap, instead of the random sample consensus (RANSAC), so that the downsampling result of the point cloud is closer to the approximate center of gravity of voxels. Let the coordinate of a feature point in a set of point cloud sequences in the voxel space be p(x, y, z). If the voxel grid size is r, the dimension of the voxel grid in the x direction is Dx = (xmax \u2212 xmin)/r, and the index of p in the x direction within the voxel grid is hx = (x\u2212 xmin)/r. The same applies to the y and z directions. After obtaining the 3D index of feature points in the voxel space, if the random sorting strategy of [11] is adopted, the sorting complexity will be O((m + n) \u2217 log(m + n)), which has a negative impact on the down-sampling time. Therefore, this paper uses the hash function to sort the index of feature points quickly and map them to N containers (N = 80). The hash function is:\nhash(hx, hy, hz) = (hx + hy \u00b7 Dx + hz \u00b7 Dx \u00b7 Dy) %N R3 \u2192 R (2)\nTo avoid hash conflicts, set the conflict detection conditions as follows:\nhash(hx, hy, hz) = hash(h\u2032x, h \u2032 y, h \u2032 z) (hx 6= h\u2032x \u2223\u2223\u2223hy 6= h\u2032y\u2223\u2223\u2223hz 6= h\u2032z) (3) Once the hash conflict is detected, the index value in the current container is output\nand the container is emptied, and the new index value is put into the container. To sum up, the main improvement of this section lies in extending the curvature segmentation step originally used for feature extraction to the downsampling step, and using hash mapping instead of the random sampling method for point cloud sampling. For the LiDAR odometer, using the clustering line and surface features again after the feature extraction step can improve the accuracy of downsampling single-frame or discontinuous point clouds at a weak time cost, thus providing more accurate point cloud distribution results for the pose estimation step between consecutive frames. In addition, using HashMap to downsample can further improve the sampling efficiency, and the time consumption of quadratic curvature segmentation is almost negligible. For other applications that need to downsample point clouds, the point cloud clustering method based on curvature segmentation can restore the spatial distribution of point clouds more accurately, and the benefits of this method are extensive and obvious. The results and time consumption of the improved point cloud downsampling process are shown in Figure 2 and Table 1. Cloud number M = 112624, the line feature extraction threshold is 1, the surface feature extraction threshold is 0.1 and r = 0.3. It can be seen from Figure 2c that the present method has a clearer reduction in the spatial distribution of diagonal lines within a rectangular point cloud. Therefore, it can be proved that our method can retain the texture feature information of the source point cloud to a greater extent, and the accuracy and real-time performance of the downsampling results can be improved.\nRemote Sens. 2022, 14, 2104 6 of 26\nRemote Sens. 2022, 14, x FOR PEER REVIEW 6 of 28\nextent, and the accuracy and real-time performance of the downsampling results can be improved.\n(a) (b) (c)\nFigure 2. Comparison of point cloud downsampling results. (a) Source point cloud; (b) downsampling results before improvement; (c) downsampling results after improvement.\nTable 1. Comparison of the number of point clouds and time consumption after downsampling.\nPoint Cloud Type Number of Point Clouds Time Consumption Source point cloud 112,624 -\nBefore improvement 4100 0.004s After improvement 5929 0.002s\n3.2. Voxelized Point Cloud Registration The purpose of point cloud registration is to update the rigid frame transformation of a moving carrier by comparing two consecutive frames of point clouds or similar point clouds detected by a loopback to solve for the carrier\u2019s pose. Traditional LIO usually uses ICP to realize the precise registration of point clouds. The ICP can be briefly described as follows: given a set of source point cloud { }1 2, ,..., nA a a a= and target point cloud { }1 2, ,..., nB b b b= , the nearest neighbor search of KDTree is used to obtain the inter-frame pose transformation relationship i ib Ta= , and the optimal solution is achieved through multiple iterations. However, an unreasonable initial position selection will make ICP fall into the misunderstanding of the local optimal solution, and the calculation resource consumption of the single-point nearest neighbor search is large. In view of the defects of the ICP algorithm, this paper utilizes a method based on the distribution of feature points in voxels, as shown in Figure 3.\nFigure 3. Comparison of point cloud registration strategies. (a) ICP/GICP; (b) NDT; (c) our algorithm.\nAs shown in Figure 3. the problem of constructing the nearest neighbor model of a point pair by using a tree diagram is transformed into constructing the nearest neighbor\nFigure 2. Comparison of point cloud downsampling results. (a) Source point cloud; (b) downsampling results before improvement; (c) downsampling results after improvement.\nTable 1. Comparison of the number of point clouds and time consumption after downsampling.\nPoint Cloud Type Number of Point Clouds Time Consumption\nSource point cloud 112,624 - Before improvement 4100 0.004 s After improve ent 5929 0.002 s"
        },
        {
            "heading": "3.2. oxelized Point Cloud Registration",
            "text": "he r ose of oint clo registration is to ate the rigi fra e transfor ation f a i carrier c ari t c sec ti e fra es f i t cl s r si ilar i t cl s t ct l c t s l f r t c rri r\u2019s pose. Tra iti l I s ll s s I to realize the precise registration of point clouds. The ICP can e briefly described as follows: given a set of so rce oi t cloud A = 1, 2, . . . , an} and target point clo B = {b1, b2, . . . , bn}, the nearest neighbor search of KDTree is used to obtain the inter-frame pose transformation relationship bi = Tai, and the optimal solution is achieved through multiple ite ations. However, an unre sonable initial position selection will make ICP fall into the misunderstanding of the local optimal solution, and the calculation resource consumption of the single-point nearest neighbor search is large. In view of the defects of the ICP algorithm, this paper utilizes a method based on the distribution of feature points in voxels, as shown in Figure 3.\nRemote Sens. 2022, 14, x FOR PEER REVIEW 6 of 28\nextent, and the accuracy and real-time performance of the downsampling results can be improved.\n(a) (b) (c)\nFigure 2. Comparison of point cloud downsampling results. (a) Source point cloud; (b) downsampling results before improvement; (c) downsampling results after improvement.\nTable 1. Comparison of the number of point clouds and time consumption after downsampling.\nPoint Cloud Type Number of Poi t Clouds Time Consumption Source point cloud 112,624 -\nBefore improvement 4100 0.004s Afte improvement 5929 0.002s"
        },
        {
            "heading": "3.2. Voxelized Point Cloud Registration",
            "text": "The purpose of point cloud registration is to update the rigid frame transformation of a moving carrier by comparing two consecutive frames of point clouds or similar point clouds detected by a loopback to solve for the carrier\u2019s pose. Traditional LIO usually uses ICP to realize the precise registration of point clouds. The ICP can be briefly described as follows: given a set of source point cloud { }1 2, ,..., nA a a a= and target point cloud { }1 2, ,..., nB b b b= , the nearest neighbor search of KDTree is used to obt in the inter-frame pose transformation relationship i ib Ta= , and the optimal solution is achieved through multiple iterations. However, an unreasonable initial position selection will make ICP fall into the misunderstanding of the local optimal solution, and the calculation resource consumption of the single-point nearest neighbor search is large. In view of the defects of the ICP algorithm, this paper utilizes a method based on the distribution of feature points in voxels, as shown in Figure 3.\nAs shown in Figure 3. the problem of constructing the nearest neighbor model of a\npoint pair by using a tree diagram is transformed into constructing the nearest neighbor\ni r 3. o parison of point cloud registration strategies. (a) ICP/GICP; (b) NDT; (c) our algorithm.\nAs shown in Figure 3. the problem of constructing the nearest neighbor m del of a\npoint pair by using a tree diagram is transformed into constructing the nearest neighbor\nmodel of a point and a neighborhood point set. Firstly, the two sets of point cloud sequences are approximated as Gaussian distri utions, i.e., ai \u223c N(a\u0302i, \u03a3Ai ) nd bi \u223c N(b\u0302i, \u03a3Bi ), where i \u2208 (1, n). \u03a3Ai and \u03a3Bi are covariance mat ic s of tw sets of point cloud sequences, respectively. Let the distance between a pair of corresponding points between the target point cloud and the source point cloud be:\ndi = bi \u2212 Tai (4)\nRemote Sens. 2022, 14, 2104 7 of 26\nLet the neighborhood point set of ai be Bai = { bj \u2223\u2223\u2016ai \u2212 bj\u2016 < \u03bb}, where \u03bb is the\nneighborhood judgment threshold. Thus, the distance between the extended point and the neighborhood point set is:\nd\u0302i = \u2211j ( b\u0302j \u2212 Ta\u0302i )\n(5)\nAs a result of ai \u223c N(a\u0302i, \u03a3Ai ) and bi \u223c N(b\u0302i, \u03a3Bi ), the rigid body transformation error ei is calculated as:\nei \u223c (\u2211j ( b\u0302j \u2212 Ta\u0302i ) , \u2211j ( \u03a3Bj \u2212 T\u03a3Ai TT ) ) (6)\nIn this way, the smoothing of all neighboring point clouds in the neighborhood of ai is achieved. Let \u00b5 = N(\u2211j ( b\u0302j \u2212 Ta\u0302i ) and \u03a3 = \u2211j ( \u03a3Bj \u2212 T\u03a3Ai TT ) ; because ei is a highdimensional Gaussian distribution, its probability density function expansion form is:\nP(ei) = 1\u221a\n(2\u03c0)Ndet(\u03a3) exp\n{ \u22121\n2 (ei \u2212 \u00b5)T\u03a3\u22121(ei \u2212 \u00b5)\n} (7)\nThe negative logarithmic form of Equation (7) is:\n\u2212 ln(P(ei)) = 1 2\nln [ (2\u03c0)Ndet(\u03a3) ] +\n1 2 (ei \u2212 \u00b5)T(\u03a3)\u22121(ei \u2212 \u00b5) (8)\nSolving the inter-frame pose transformation matrix T by maximum likelihood method:\nT = argmax T \u03a0 i P(ei) = argmin T\n\u2211i eiT(\u03a3Bj \u2212 T\u03a3Ai TT)eiT (9)\nFurthermore, after introducing the number Ni of point clouds in the neighborhood ai, Equation (9) can be written as: T = argmin\u2211 i (Ni e\u0302Ti \u03a3 \u22121 i e\u0302i) e\u0302i = \u2211j bj Ni \u2212 Tai\n\u03a3\u0302i = \u2211j \u03a3Bj\nNi + T\u03a3Ai T T\n(10)\nIn addition to the smoothing of all neighboring point clouds in the neighborhood of ai, an iteration termination threshold \u03b5 was established to avoid falling into a blind region of local optima after multiple iterations as follows:\n|RMSEk+1 \u2212 RMSEk| > \u03b5 (11)\nwhere RMSEk+1 and RMSEk are the root mean square error of the previous k + 1 iterations and the previous k iterations, respectively. The iteration is completed when the absolute value of the change in the root mean square error |RMSEk+1 \u2212 RMSEk| \u2264 \u03b5, or the maximum number of iterations, is reached."
        },
        {
            "heading": "4. Graph Optimization Framework",
            "text": ""
        },
        {
            "heading": "4.1. Local Pose Map Structure",
            "text": "Authors should discuss the results and how they can be interpreted from the perspective of previous studies and of the working hypotheses. The findings and their implications should be discussed in the broadest context possible. Future research directions may also be highlighted.\nRemote Sens. 2022, 14, 2104 8 of 26\nThe local state vectors in the local coordinate system in which the LiDAR and IMU are located are given as follows:\nX L = [\nxb1, xb2, . . . , xbi, de1, d e 2, . . . , d e k, d p 1 , d p 2 , . . . , d p k ] xbi = [ pLbi, q L bi, v L bi, ba, bg\n] (12) where xbi denotes the state quantity after pre-integration of the ith IMU at tk, including position pLbi, rotation q L bi, speed v L bi and IMU bias ba, bg. d e k is the distance from the LiDAR feature point at tk\u22121 to the matching edge feature at tk, and d p k is the distance from the feature point at tk\u22121 to the matching planar feature at tk. From this, the Gauss\u2013Newton method can be used instead of the fastest gradient descent method used in [27] to minimize all cost functions so as to reduce the number of iterations for rapid convergence to a locally optimal estimate. The local optimization function is constructed as follows:\nmin X\n{ \u2211 dek + \u2211 d p k+\u2211 k\u2208B \u2016rB ( z\u0302kk+1,X ) \u2016 2 \u03a3b } (13)\nwhere \u2211 dek + \u2211 d p k is used to solve the carrier pose x LiDAR tk in the local coordinate system of LiDAR at time tk. rB ( z\u0302i\u22121i ,X )\nand \u03a3b are IMU measurement residuals and covariance matrices, respectively. The meanings of the terms are described below.\n4.1.1. IMU Pre-integration Factor Let [ \u03b1i+1i , \u03b8 i+1 i , \u03b2 i+1 i ]T be the IMU pre-integration calculation value between the ith and i + 1th LiDAR key frames. Details of the derivation of the IMU pre-integration are presented in Appendix A. \u2206ti is the time interval between the two LiDAR key frames, and the spatial transformation matrix from the IMU coordinate system to the LiDAR coordinate system in ith frame is represented by RbiL . The IMU residual can be obtained as follows:\nrB ( z\u0302i+1i ,X ) =  \u03b4\u03b1i+1i \u03b4\u03b8i+1i \u03b4\u03b2i+1i\n\u03b4ba \u03b4bg\n =  RbiL ( pLbi+1 \u2212 v L bi \u2206ti \u2212 pLbi + 1 2 g\u2206t 2 i ) \u2212 \u03b1\u0302i+1i 2 [ qL \u22121 bi \u2297 qLbi+1 \u2297 \u03b8\u0302 i+1\u22121 i ] xyz RbiL ( vLi+1 \u2212 vLi + g\u2206ti ) \u2212 \u03b2\u0302i+1i\nbai+1 \u2212 bai b\u03c9i+1 \u2212 b\u03c9i\n (14)\nwhere the symbol [\u00b7]xyz represents extracting the real part of the quaternion used to calculate the rotation state error, and \u2297 represents the quaternion multiplication.\nAfter the pose estimation of the previous key frame is completed, the IMU acceleration\nbias and gyroscope bigotry will be updated, the update amounts are set as \u03b4 ` b\nbi a and \u03b4 ` b bi\ng and the pre-integration calculation value at this time is updated as follows:\n\u03b1i+1i = \u03b1\u0302 i+1 i + \u03b4\u03b1\u0302i+1i \u03b4ba \u03b4 ` ba + \u03b4\u03b1\u0302i+1i \u03b4b\u03c9 \u03b4 ` b\u03c9\n\u03b8i+1i = \u03b8\u0302 i+1 i \u00b7 Exp( \u03b4\u03b8\u0302i+1i \u03b4b\u03c9 \u03b4 ` b\u03c9)\n\u03b2i+1i = \u03b2\u0302 i+1 i + \u03b4\u03b2\u0302i+1i \u03b4ba \u03b4 ` ba + \u03b4\u03b2\u0302i+1i \u03b4b\u03c9 \u03b4 ` b\u03c9\n(15)\nRemote Sens. 2022, 14, 2104 9 of 26\n4.1.2. LiDAR Factor\nThe feature point cloud extracted by LiDAR can be divided into two types: line features and surface features. The LiDAR residuals of the two types need to be constructed separately and then summed to obtain the total LiDAR residuals. Details of the specific derivation of LiDAR residuals are presented in Appendix B. Figure 4 shows the schematic diagram of LiDAR residual construction.\nRemote Sens. 2022, 14, x FOR PEER REVIEW 9 of 28 After the pose estimation of the previous key frame is completed, the IMU acceleration bias and gyroscope bigotry will be updated, the update amounts are set as biab\u03b4  and bi gb\u03b4  and the pre-integration calculation value at this time is updated as follows: 1 1 1 1\n1 1 1\n1 1 1 1\n\u02c6 \u02c6\u02c6\n\u02c6\u02c6 ( )\n\u02c6 \u02c6\u02c6\ni i i i i i i i a\na\ni i i i i i\ni i i i i i i i a\na\nb b b b\nExp b b\nb b b b\n\u03c9 \u03c9\n\u03c9 \u03c9\n\u03c9 \u03c9\n\u03b4\u03b1 \u03b4\u03b1\u03b1 \u03b1 \u03b4 \u03b4 \u03b4 \u03b4\n\u03b4\u03b8\u03b8 \u03b8 \u03b4 \u03b4\n\u03b4\u03b2 \u03b4\u03b2\u03b2 \u03b2 \u03b4 \u03b4 \u03b4 \u03b4\n+ + + +\n+ + +\n+ + + +\n= + +\n= \u22c5\n= + +\n \n\n \n(15)\n4.1.2. LiDAR Factor The feature point cloud extracted by LiDAR can be divided into two types: line features and surface features. The LiDAR residuals of the two types need to be constructed separately and then summed to obtain the total LiDAR residuals. Details of the specific derivation of LiDAR residuals are presented in Appendix B. Figure 4 shows the schematic diagram of LiDAR residual construction.\nFigure 4. Schematic diagram of LiDAR residual construction. (a) Line characteristic residual construction; (b) surface characteristic residual construction.\nAs shown in Figure 4, let a feature point obtained in the 1k + th scan have the coordinates of ( 1, ) L k oX + in the LiDAR coordinate system, and the coordinates of two end points of the line features matched with it in the k th scan are ( , ) L k aX and ( , ) L k bX . The residual error of the line features can be expressed by the point-to-line distance:\n( ) ( ) ( )( ) ( ) ( 1, ) ( , ) 1, , ( , ) , L L L L k o k a k o k bL ek L L k a k b X X X X d X X + +\u2212 \u00d7 \u2212 = \u2212 (16)\nSimilarly, if the surface features that match it in the k th scan are represented as ( , ) L k cX , ( , ) L k dX and ( , ) L k fX , then the surface feature residual can be represented by the\npoint-to-surface distance:\n( )( ) ( ) ( )( ) ( ) ( ) ( 1, ) ( , ) ( , ) ( , ) ( , ),\n( , ) ( , ) ( , ) ( , )\nL L L L L Lk o k c k d k c k fk dL pk L L L L\nk c k d k c k f\nX X X X X X d\nX X X X\n+ \u2212 \u2212 \u00d7 \u2212 =\n\u2212 \u00d7 \u2212\n (17)\n4.2. Spatial Unification of Multi-Sensor Poses Constructing the time\u2014space correlation of each sensor is a fundamental task in multi-sensor fusion optimization. For this system, it is necessary to spatially unify the positional estimation results of LiDAR and IMU in the local map with the GNSS measurements in the global map. Therefore, the spatial unification strategy of the multi-sensor pose involved in this paper is shown in Figure 5.\nFigure 4. Schematic diagram of LiDAR residual construction. (a) Line characteristic residual construction; (b) surface characteristic residual construction.\nAs shown in Figure 4, let a feature point obtained in the k + t c rdinates of XL(k+1,o) in the LiDAR coordinate system, and the coordinates of two end points of the line features matched with it in the kth scan are XL(k,a) and X L (k,b). The residual error of the line features can be expressed by the point-to-line distance:\ndLek = \u2223\u2223\u2223(XL(k+1,o) \u2212 XL(k,a)) (XL(k+1,o) \u2212 XL(k,b))\u2223\u2223\u2223\u2223\u2223\u2223XL(k,a) (k,b)\u2223\u2223\u2223 (16) Similarly, if t e that match it in the kth scan are represented as XL(k,c),\nXL(k,d) and X L (k, f ), then the surface feature residual can be represented by the point-to-surface d stance:\ndLpk = \u2223\u2223\u2223(XL(k+1,o) \u2212 XL(k,d)) \u00b7 ((XL(k,c) L(k,d))\u00d7 (XL(k,c) \u2212 XL(k, f )))\u2223\u2223\u2223\u2223\u2223\u2223(XL(k,c) \u2212 XL(k,d)) (XL(k,c) \u2212 XL(k, f ))\u2223\u2223\u2223 (17)"
        },
        {
            "heading": "4.2. Spatial Unification of Multi-Sensor Poses",
            "text": "Constructing the time\u2014space correlation of each sensor is a fundamental task in multisensor fusion optimization. For this system, it is necessary to spatially unify the positional estimation results of LiDAR and IMU in the local map with the GNSS measurements in the global map. Therefore, the spatial unification strategy of the multi-sensor pose involved in this paper is shown in Figure 5. Remote Sens. 2022, 14, x FOR PEER REVIEW 10 of 28\nFigure 5. Schematic diagram of the spatial unification of multi-sensor poses. The spatial association of the poses of LiDAR and IMU in the local coordinate system is on the left, and the spatial association of the poses of IMU and GNSS receivers in the global coordinate system is on the right.\nAs shown in Figure 5, IMUGNSSW is the external parameter conversion matrix from IMU to GNSS and LiDARIMUW is the external parameter conversion matrix from LiDAR to IMU. Since the hardware is fixed to the mobile carrier, both are calibrated to a constant value. The left figure shows the positional conversion between LiDAR and IMU in the local coordinate system, whereas the right figure shows the multi-sensor positional spatial unification from the local to the global coordinate system. Here, it is necessary to introduce the spatial transformation parameters LGF (including translation L Gp and rotation L Gq ) to correlate the two positional spaces. The spatial unification of the multi-sensor pose at the moment of t can be expressed as:\n( ) ( )( ) 2, 21 1min 2G GL L j TG L L IMU L G t G t GNSS t L q p i P q q W p p = \u2212 \u22c5 \u22c5 + + (18)\nwhere the initial value of LGF is set as the unit matrix. Every time the GNSS factor is added to solve the global optimum, the value of LGF at the next moment will be updated, thus correcting the cumulative offset between the local and global coordinate systems."
        },
        {
            "heading": "4.3. Global Pose Map Structure",
            "text": "Global pose map construction can be regarded as a nonlinear optimization problem; that is, the nonlinear optimization of the state vector in the sliding window. Different from the factor graph method adopted in [27], this paper adopts the graph optimization method to directly construct the residual block in the original pose graph structure for nonlinear optimization, and only optimizes the key frames in the sliding window. However, the factor graph based on GTSAM [29] needs to construct the optimization problem into a new graph corresponding to the original pose graph, with the optimization variables as the vertices and error terms as the edges. The complicated constraint relationship among the vertices is more favorable toward the optimization accuracy. However, once a new key frame is detected, all of its associated constraint nodes will be updated, which is complicated and takes too long in the engineering field. Therefore, in order to meet the requirements of the lightweight and real-time performance of the vehicle platform, we choose not to build a new constraint-related Bayesian network, but to construct the residual error and nonlinear optimization in the original pose map structure. The global pose optimization framework proposed in this paper is shown in Figure 6.\nFigure 5. Schematic diagram of the spatial unification of multi-sensor poses. The spatial association of the poses of LiDAR and IMU in the local coordinate system is on the left, and t e s ti l ss ci ti\nof the poses of IMU and GNSS receivers in the global coordinate system is on the right.\nRemote Sens. 2022, 14, 2104 10 of 26\nAs shown in Figure 5, W IMUGNSS is the external parameter conversion matrix from IMU to GNSS and WLiDARIMU is the external parameter conversion matrix from LiDAR to IMU. Since the hardware is fixed to the mobile carrier, both are calibrated to a constant value. The left figure shows the positional conversion between LiDAR and IMU in the local coordinate system, whereas the right figure shows the multi-sensor positional spatial unification from the local to the global coordinate system. Here, it is necessary to introduce the spatial transformation parameters FLG (including translation p L G and rotation q L G) to correlate the two positional spaces. The spatial unification of the multi-sensor pose at the moment of t can be expressed as:\nmin qGL ,p G L\n1 2\nj\n\u2211 i=1 \u2016PGt \u2212\n(( qLG )T \u00b7 ( qLt \u00b7W IMUGNSS + pLt ) + pGL ) \u2016 2\n2 (18)\nwhere the initial value of FLG is set as the unit matrix. Every time the GNSS factor is added to solve the global optimum, the value of FLG at the next moment will be updated, thus correcting the cumulative offset between the local and global coordinate systems."
        },
        {
            "heading": "4.3. Global Pose Map Structure",
            "text": "Global pose map construction can be regarded as a nonlinear optimization problem; that is, the nonlinear optimization of the state vector in the sliding window. Different from the factor graph method adopted in [27], this paper adopts the graph optimization method to directly construct the residual block in the original pose graph structure for nonlinear optimization, and only optimizes the key frames in the sliding window. However, the factor graph based on GTSAM [29] needs to construct the optimization problem into a new graph corresponding to the original pose graph, with the optimization variables as the vertices and error terms as the edges. The complicated constraint relationship among the vertices is more favorable toward the optimization accuracy. However, once a new key frame is detected, all of its associated constraint nodes will be updated, which is complicated and takes too long in the engineering field. Therefore, in order to meet the requirements of the lightweight and real-time performance of the vehicle platform, we choose not to build a new constraint-related Bayesian network, but to construct the residual error and nonlinear optimization in the original pose map structure. The global pose optimization framework proposed in this paper is shown in Figure 6. Remote Sens. 2022, 14, x FOR PEER REVIEW 11 of 28\nwhere \u03c1 is the GNSS confidence level expressed by the covariance of the error in the GNSS observations obtained by the pseudo-range single point positioning (SPP) algorithm solution. WkT is the pose transformation matrix between the current global point cloud k and the local point cloud k derived from the inter-frame local matching. The specific meaning of each sensor cost function in the formula are as follows.\n4.3.1. LIO Factor According to Section 4.1, the position Ltp and rotation L tq of the carrier in the local coordinate system at the moment t can be obtained. Therefore, the LIO local residual factor can be constructed as follows:\n( ) ( ) ( ) 1 1 1 1 1 1 1\n1 1 1 1\n,  L L L G G G\nt t t t t t t tD L L G G\nt t t t\nq p p q p p r z\nq q q q\n\u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212\n\u2212 \u2212 \u2212 \u2212    \u2212 \u2212    =         (20)\nwhere the symbol  represents the quaternion subtraction.\n4.3.2. GNSS Factor Set the time interval between two frames of GNSS observations as t\u0394 and realize the time alignment with LIO pose estimation by interpolation. Cubic spline interpolation is used for position interpolation and spherical linear interpolation is used for quaternion interpolation. Now, given the GNSS measurement GNSStp in the ENU coordinate system and the LIO positional observations Gtp in the global coordinate system, the GNSS residual factor is expressed as follows:\n( )1,t G GNSStG t tr z p p\u2212 = \u2212 (21) When the carrier moves to the GNSS signal confidence region, in order to fully and\nreliably utilize the GNSS observations, the GNSS factor is added with the GNSS confidence as the weight. The GNSS confidence is determined by the number of visible and effective GNSS satellites. After GNSS participates in the global pose estimation, it will\nRemote Sens. 2022, 14, 2104 11 of 26\nThe global optimization function is constructed as follows:\nX = argmin X\nn\n\u2211 t=0\n( \u2016zLt \u2212 hLt (X )\u2016 2 \u03a3kt + \u03c1\u2016zGt \u2212 hGt (X )\u2016 2 \u03a3kt ) + rloop ( TWk Pk,Sk ) (19)\nwhere \u03c1 is the GNSS confidence level expressed by the covariance of the error in the GNSS observations obtained by the pseudo-range single point positioning (SPP) algorithm solution. TWk is the pose transformation matrix between the current global point cloud Pk and the local point cloud Sk derived from the inter-frame local matching. The specific meaning of each sensor cost function in the formula are as follows.\n4.3.1. LIO Factor\nAccording to Section 4.1, the position pLt and rotation q L t of the carrier in the local\ncoordinate system at the moment t can be obtained. Therefore, the LIO local residual factor can be constructed as follows:\nrD ( z\u0302t\u22121t ,X ) = [ qLt\u22121 \u22121(pLt \u2212 pLt\u22121) qLt\u22121 \u22121qLt ] [ qGt\u22121 \u22121(pGt \u2212 pGt\u22121) qGt\u22121 \u22121qGt ] (20)\nwhere the symbol represents the quaternion subtraction.\n4.3.2. GNSS Factor\nSet the time interval between two frames of GNSS observations as \u2206t and realize the time alignment with LIO pose estimation by interpolation. Cubic spline interpolation is used for position interpolation and spherical linear interpolation is used for quaternion interpolation. Now, given the GNSS measurement pGNSSt in the ENU coordinate system and the LIO positional observations pGt in the global coordinate system, the GNSS residual factor is expressed as follows:\nrG ( z\u0302t\u22121t ,X ) = pGt \u2212 pGNSSt (21)\nWhen the carrier moves to the GNSS signal confidence region, in order to fully and reliably utilize the GNSS observations, the GNSS factor is added with the GNSS confidence as the weight. The GNSS confidence is determined by the number of visible and effective GNSS satellites. After GNSS participates in the global pose estimation, it will update the pose conversion parameter FLG between the local coordinate system and the global coordinate system. This ensures that, even if the mobile carrier enters a GNSS-rejected environment (e.g., indoor car parks and tunnels), our algorithm can provide a more accurate initial observation after GNSS correction.\n4.3.3. Loop Factor\nConsidering the possible overlap of the moving vehicle driving areas, it is necessary to add a loop detection link to establish possible loop constraints between non-adjacent frames. According to Equation (5), the loop factors can be constructed as follows:\nrL ( TWk Pk,Sk ) =  TWk = argmin\u2211 k (Nk e\u0302Tk \u03a3 \u22121 k e\u0302k) e\u0302k = \u2211k Pk Nk \u2212 TWk Sk\n\u03a3\u0302k = \u2211k \u03a3Pk\nNk + TWk \u03a3 S k T WT k\n(22)\nUsing the optimized point cloud registration method in Section 3.2, we optimize and correct the historical trajectory through the registration between the point cloud of the prior local map and the current global point cloud. This method ensures that the positional estimates converge to the global optimum result.\nRemote Sens. 2022, 14, 2104 12 of 26"
        },
        {
            "heading": "5. Experimental Setup and Results",
            "text": ""
        },
        {
            "heading": "5.1. Point Cloud Registration Results",
            "text": "To verify the superiority of the point cloud registration algorithm used in this paper, we compared the registration results of the ICP algorithm used in traditional LiDAR odometry with our algorithm. The comparison results are shown in Figures 7\u20139.\nRemote Sens. 2022, 14, x FOR PEER REVIEW 12 of 29 update the pose conversion parameter LGF between the local coordinate system and the global coordinate system. This ensures that, even if the mobile carrier enters a GNSS-rejected environment (e.g., indoor car parks and tunnels), our algorithm can provide a more accurate initial observation after GNSS correction. 4.3.3. Loop Factor Considering the possible overlap of the moving vehicle driving areas, it is necessary to add a loop detection link to establish possible loop constraints between non-adjacent frames. According to Equation (5), the loop factors can be constructed as follows: ( ) 1\u02c6 \u02c6arg min ( ) \u02c6, \u02c6 W T k k k k k k kW Wk L k k k k k k k k W W Tk k k k k\nk\nT N e e r T e T N\nT T N\n\u2212  = \u03a3  = = \u2212   \u03a3\u03a3 = + \u03a3            (22)\nUsing the optimized point cloud registration method in Section 3.2, we optimize and correct the historical trajectory through the registration between the point cloud of the prior local map and the current global point cloud. This method ensures that the positional estimates converge to the global optimum result.\n5. Experimental Setup and Results 5.1. Point Cloud Registration Results\nTo verify the superiority of the point cloud registration algorithm used in this paper, we compared the registration results of the ICP algorithm used in traditional LiDAR\ndometry with our algorit . The comparis results are shown in Figures 7\u20139.\n(a) (b) (c)\nFigure 7. Point cloud registration results. (a) Original source and target point clouds. (b) Alignment results using ICP algorithm. (c) Alignment results using our algorithm.\nFigure 7. Point cloud registration results. (a) Original source and target point clouds. (b) Alignment results using ICP algorithm. (c) Alignment results using our algorithm.\nRemote Sens. 2022, 14, x FOR PEER REVIEW 12 of 28 update the pose conversion parameter LGF between the local coordinate system and the global coordinate system. This ensures that, even if the mobile carrier enters a GNSS-rejected environment (e.g., indoor car parks and tunnels), our algorithm can provide a more accurate initial observation after GNSS correction. 4.3.3. Loop Factor Considering the possible overlap of the moving vehicle driving areas, it is necessary to add a loop detection link to establish possible loop constraints between non-adjacent frames. According to Equation (5), the loop factors can be constructed as follows: ( ) 1\u02c6 \u02c6arg min ( ) \u02c6, \u02c6 W T k k k k k k kW Wk L k k k k k k k\nk W W Tk k k k k\nk\nT N e e r T e T N\nT T N\n\u2212  = \u03a3  = = \u2212   \u03a3\u03a3 = + \u03a3            (22)\nUsing the optimized point cloud registration method in Section 3.2, we optimize and correct the historical trajectory through the registration between the point cloud of the prior local map and the current global point cloud. This method ensures that the positional estimates converge to the global optimum result.\n5. Experimental Setup and Results 5.1. Point Cloud Registration Results\nTo verify the superiority of the point cloud registration algorithm used in this paper, we compared the registration results of the ICP algorithm used in traditional LiDAR odometry with our algorithm. The comparison results are shown in Figures 7\u20139.\n(a) (b) (c)\nFigure 7. Point cloud registration results. (a) Original source and target point clouds. (b) Alignment results using ICP algorithm. (c) Alignment results using our algorithm.\nFigure 8. Detail diagram of point registration results of the point cloud registration results. (a) Original source and target point clouds. (b) Alignment results using ICP algorithm. (c) Alignment results using our algorithm.\n(a) (b) (c)\nFigure 9. A circular expansion of the point cloud alignment results. (a) Original source and target point clouds. (b) Alignment results using ICP algorithm. (c) Alignment results using our algorithm.\nCompared with the typical indoor environment, for mobile carriers in complex urban environments, the angles and translations between the source and target point clouds during the continuous frame and the loopback detection may be larger. As shown in Figure 7, when the initial position is unreasonable, the registration results of the ICP algorithm cannot fully approach the global optimal solution, which is detrimental to both the local pose estimation and loopback correction of the mobile carrier. However, the registration accuracy of our algorithm is not affected by the large positional transformation of the vehicle platform. Compared with the traditional ICP algorithm, the registration result of our algorithm suited the needs of the vehicle platform better. Furthermore, in order to avoid the contingency of the registered objects, we made a comparative experiment on the source point clouds with different rotation angles and translation distances, and quantitatively compared the registration accuracy and time consumption of each algorithm. The test results are shown in Table 2 and Table 3.\nPCL_NDT 456.43/0.03024 723.031/0.03375 1186.57/0.02511 577.64/2.28457 279.047/2.688\n36 Proposed 31.9215/0.00106 33.44/0.01716 41.26/0.01265 31.19/0.03011 33.88/0.03047\nFrom the vertical comparison between Table 2 and Table 3, it can be seen that the point cloud registration algorithm is more sensitive to rotation, which means that, if the\nFigure 9. A circular expansion of the point cloud alignment results. (a) Original source and target point clouds. (b) Alignment results using ICP algorithm. (c) Alignment results using our algorithm.\nCo pared ith the typical indoor environ ent, for obile carriers in co plex urban environ ents, the angles and translations between the source and target point clouds during the continuous frame and the loopback detection may be larger. As shown in Figure 7, when the initial position is unreasonable, the registration results of the ICP algorithm cannot fully approach the global ptimal solution, which is detrimental to both the local pose estimati n nd l opback correction of the mobile carrier. However, the registration accuracy of our algorithm is not aff cted by the large positi nal transf rmation of the vehicle platform. Compar d with the traditional ICP algorithm, the r gistration result of our algorithm suited n eds of the vehicl platform better.\nRemote Sens. 2022, 14, 2104 13 of 26\nFurthermore, in order to avoid the contingency of the registered objects, we made a comparative experiment on the source point clouds with different rotation angles and translation distances, and quantitatively compared the registration accuracy and time consumption of each algorithm. The test results are shown in Tables 2 and 3.\nFrom the vertical comparison between Tables 2 and 3, it can be seen that the point cloud registration algorithm is more sensitive to rotation, which means that, if the vehicle rotates at a large angle in the city, the point cloud registration between consecutive frames is perhaps less reliable. It may even lead to a failure of the pose estimation, as has been demonstrated in [5]. However, as the rotation angle increases, it can be seen from Table 2 that the registration accuracy of our algorithm decreases the least, and, at the extreme 90\u25e6 rotation angle, the accuracy is still more than four times better than the other algorithms, with a root mean square error of approximately 2.67116 m. On the other hand, for large translations (5 m) between the source and target point clouds, our algorithm also shows an excellent registration accuracy, with a root mean square error of approximately 0.03047 m. It is worth noting that, in the aspect of single-point cloud registration, the registration time of our algorithm is increased by approximately one order of magnitude compared with others. To sum up, it is sufficient to verify the superiority of the proposed registration algorithm in terms of compressing time and improving the registration accuracy."
        },
        {
            "heading": "5.2. Positioning Accuracy",
            "text": "In this paper, the absolute trajectory error (ATE) was selected as the evaluation index of SLAM system positioning accuracy so as to directly reflect the difference between the global position estimation of the moving carrier and the ground truth. The absolute trajectory error is calculated as follows.\nAi := g\u22121i Spi (23)\nwhere Ai is the absolute trajectory error of the SLAM system in the ith frame, gi and pi are the ground truth and the estimated pose, respectively, and S is the transformation matrix between the ground truth and the estimated pose. In this paper, the mean error (ATE_ME) and root mean square error (ATE_RMSE) of the absolute trajectory error were selected as evaluation criterion.\n5.2.1. Public Dataset\nTo verify the positioning accuracy of the fusion algorithm in different outdoor environments, the KITTI_RAW dataset [30], which includes a variety of outdoor scenes, was used\nRemote Sens. 2022, 14, 2104 14 of 26\nto evaluate the localization accuracy of the fusion algorithm and to compare it with other similar advanced algorithms. The experimental data acquisition platform is as follows: LiDAR point cloud data are acquired by Velodyne HDL~64 line LiDAR, with horizontal field angle of view of 360\u25e6, vertical field angle range of (\u221224.8\u25e6,+2\u25e6), horizontal resolution range of (0.08\u25e6, 0.35\u25e6), vertical angle resolution of 0.4\u25e6 and scanning frequency of 10 Hz, which can meet the requirements of in-vehicle point cloud data acquisition. The GPS/IMU integrated system adopts OXTS RT3003, with a GPS output frequency of 1 Hz/s and an IMU output frequency of 100 Hz. The ground truth is provided by a high-precision integrated navigation system. Four different outdoor scenarios were used to validate the performance of the fusion algorithm, including urban environments, open area, highway and forest road. The voxel grid size of the fusion algorithm was set to 0.3\u00d7 0.2\u00d7 0.3, the maximum iteration threshold was set to 30 and the iteration termination tolerance threshold was set to 1 \u00d7 10\u22128, so as to meet the real-time requirements and ensure the stable number of feature point clouds participating in the matching in sparse areas of outdoor environments. The comparison of the experimental results is shown in Figures 10 and 11 and Table 4. Remote Sens. 2022, 14, x FOR PEER REVIEW 15 of 28\nFigure . ris f t e esti ated trajectories. (a) Global positioni g trajectory. (b) Local details of the trajectory. (c) Local details of the trajectory.\nRemote Sens. 2022, 14, 2104 15 of 26\nRemote Sens. 2022, 14, x FOR PEER REVIEW 15 of 28\nFigure 10. Comparison of the estimated trajectories. (a) Global positioning trajectory. (b) Local de-\ntails of the trajectory. (c) Local details of the trajectory.\nFigure 11. Comparison of the positioning error of each algorithm. (a) APE fitting curve. (b) The box diagram of APE.\nFigure 11. Comparison of the positioning error of each algorithm. (a) APE fitting curve. (b) The box diagram of APE.\nFigure 10 shows the comparison of the positioning results of each algorithm in the 09_30_0018 dataset representing the urban environment. As shown in Figure 11b, both LiDAR odometry (LO), represented by A-LOAM, and LIO, represented by LeGO-LOAM, show significant degradation in the position estimation results in the first 50 s and the last 50 s. The reason is that LO and LIO systems only rely mainly on LiDAR to extract spatial geometric feature information. Once LiDAR feature constraints are sparse or fail, the carrier state estimation degradation will occur in this feature direction, and additional constraints need to be added. The first 50 s and last 50 s are both flat, open roads with sparse point cloud features, which are susceptible to the degradation of the LiDAR positional optimization results. However, the number of GNSS visible satellites in the flat and open road is enough, and using GNSS observations as global constraints can greatly improve the positioning accuracy and robustness in sparse areas of point clouds. As can be seen from Figure 11b, the ATE_RMSE of both the LIO-SAM with GNSS global constraints and the present algorithm is stable between (0 m, 2 m), and the positioning accuracy remains stable in the sparse region of the point cloud features in the latter 50 s without large data drift. In addition, from the box diagram shown in Figure 9c, it can be seen that the positional outliers estimated by LIO-SAM are reduced by approximately 80% compared with the LIO system. Furthermore, the positional estimation errors of our algorithm are concentrated between (0.68 m, 1.23 m) with very few outliers, which fully demonstrates the superiority of the proposed algorithm in its positioning accuracy in urban environments.\n5.2.2. Urban Dataset\nTo further investigate the extent to which improvements in both the front-end and backend components of the fusion algorithm improve its positioning accuracy, we conducted ablation experiments in a complex environment of GNSS signals. We constructed a system without GNSS global correction (-), a system without smoothed voxelized point cloud\nRemote Sens. 2022, 14, 2104 16 of 26\nregistration and loopback correction (#) and a complete system (Proposed), respectively. The experimental environment is the complex reflection area of GNSS in the urban environment. The experimental platform includes: the ground truth, which is provided by NovAtel SPAN-CPT positioning results; the LiDAR point cloud, which is acquired by HDL 32E Velodyne LiDAR, where the horizontal field of view angle is 360\u25e6, the vertical field of view angle range is (\u221230\u25e6,+10\u25e6) and the scanning frequency is 10 Hz, which is suitable for in-vehicle point cloud data acquisition; IMU, which is Xsens Mti 10, and the update frequency of the pose is 100 Hz; the GNSS receiver, which is u-blox M8T, and the update frequency is 1 Hz. Different from the KITTI_RAW dataset, the GNSS confidence parameter in this experiment is not fixed. After solving the raw observation data collected by u-blox with the SPP algorithm, we obtained the GNSS confidence covariance as the GNSS factor weight parameter. This is more in line with the real urban environment, where GNSS reflected and refracted signals interfere with the direct signal superimposed, thus causing the pseudorange and carrier phase observations to deviate from the true value of the direct signal. The experimental results are shown in Figures 12 and 13 and Table 5. Remote Sens. 2022, 14, x FOR PEER REVIEW 17 of 28\nFigure 12. Comparison of the estimated trajectories. (a) Global positioning trajectory. (b) Local details of the trajectory. (c) Local details of the trajectory.\nFigure 12. Comparison of the estimated trajectories. (a) Global positioning trajectory. (b) Local details of the trajectory. (c) Local details of the trajectory.\nRemote Sens. 2022, 14, 2104 17 of 26\nRemote Sens. 2022, 14, x FOR PEER REVIEW 17 of 28\nFigure 12. Comparison of the estimated trajectories. (a) Global positioning trajectory. (b) Local de-\ntails of the trajectory. (c) Local details of the trajectory.\nFigure 13. Comparison of the positioning error of each algorithm. (a) APE fitting curve. (b) The box diagram of APE.\nFigure 13. Comparison of the positioning error of each algorithm. (a) APE fitting curve. (b) The box diagram of APE.\nAs can be seen from Figure 13a, firstly, due to the accurate registration of the front-end point cloud, the absolute trajectory error of Proposed(-) decreases slightly compared to the pre-improved system. In the initial parking section of the dataset, the traditional ICP algorithm suffers from the problem of over-iterations, and the result is not the global optimal solution. However, the data smoothing processing and the setting of the iteration termination threshold of our algorithm can solve this problem well, providing a better initial value for the positional matching. The absolute trajectory error within the first 25 s drops by approximately 8m compared to LIO-SAM. Secondly, compared to LIO-SAM, which uses GNSS observations directly as global constraints without filtering, we introduced GNSS confidence into the optimization equation. It allows our algorithm to remain unaffected by poor-quality GNSS observations and to maintain a better positioning accuracy in the latter 50 s in areas with dense tall buildings and poor-quality point cloud distribution. In contrast, due to the poor quality of GNSS observations involved in optimization (LIO-SAM) and the low accuracy of LiDAR loop detection as a global constraint (A-LOAM and LeGO-LOAM), all other similar algorithms have a cumulative increase in the absolute trajectory error with steeper slopes. This is extremely detrimental for vehicle-mounted platforms driving in realistic large outdoor environments. From the experimental results, it can be seen that the global optimization link in our complete algorithm can well suppress the local cumulative drift and make the pose estimation result move more towards the global optimal solution. In summary, driven by a combination of respective front-end and back-end improvements, our complete algorithm achieves a higher positioning accuracy than other comparable algorithms within real urban environments. Furthermore, as a result of the inherent advantage of local sensors not being subject to signal refraction environmental interference, it compensates for positioning outliers arising from multipath effects in traditional GNSS positioning in urban environments. It fully ensures the integrity and reliability of the fusion system\u2019s positioning.\nRemote Sens. 2022, 14, 2104 18 of 26"
        },
        {
            "heading": "5.3. Time-Consuming Performance",
            "text": "In this paper, the KITTI 09_30_0033 sequence is randomly selected to verify the real-time performance of our algorithm and the similar algorithms. In this paper, the above-mentioned three similar advanced algorithms are selected as control algorithms to compare with our algorithm, so as to verify the superior real-time performance of this algorithm in three stages: downsampling, point cloud registration and optimization. The experimental results are shown in Figure 14. Remote Sens. 2022, 14, x FOR PEER REVIEW 19 of 28\n(a)\n(b)\n(c)\nFigure 14. Time-consuming comparison of three processes. (a) Point cloud downsampling process. (b) Point cloud registration process. (c) Position global optimization process.\nThe time consumption of the point cloud downsampling is shown in Figure 14a. The downsampling process of the three other algorithms uses RANSAC as the core algorithm, but its iterative approximation speed is slow, at approximately (0.5 ms, 1 ms), and the filtering and fitting quality of the depth information is not good. In contrast, our proposed algorithm uses HashMap instead of random sampling, which improves the speed of filtering out similar points in voxels to a certain extent and reduces the time consumption by two to five times compared with the traditional downsampling method. Although the time-consuming ratio of this process is relatively small in typical indoor environments or short-term positioning processes, for vehicles driving in large outdoor environments with complex point cloud environments for long periods of time, the accumulation of tiny instances of time consumption will lead to a cumulative increase in positioning time consumption. Therefore, the time-consuming compression in point cloud downsampling in this paper is beneficial for ensuring real-time vehicle positioning. The time consumption of the point cloud registration is shown in Figure 14b, which shows that the time taken for the LIO-SAM and A-LOAM point cloud registration step is in the range of (50 ms, 200 ms). By extracting and separating the ground point clouds, LeGO-LOAM can inhibit the time-consuming increase caused by outlier registration due to the interference between non-identical cluster point clouds to a certain extent. The point\nC os\nt T im\ne/ m s C os t T im e/ m s\nC os\nt T im\ne/ m\ns\nFigure 14. Time-consuming comparison of three processes. (a) Point cloud downsampling process. (b) Point cloud registration process. (c) Position global optimization process.\nThe time consumption of the point cloud downsampling is shown in Figure 14a. The downsampling process of the three other algorithms uses RANSAC as the core algorithm, but its iterative approximation speed is slow, at approximately (0.5 ms, 1 ms), and the filtering and fitting quality of the depth information is not good. In contrast, our proposed algorithm uses HashMap instead of rando sa pling, hich improves the speed of filtering out si ilar points in voxels to a certain extent and reduces the time consumption by two to five times compared with the traditional downsampling method. Although the time-consuming ratio of this process is relati el s all i t ical indoor environments or short-term positioning proces es, for vehicles driving in large outdoor environments with complex point cloud enviro ments for long periods of time, the accumulatio of\nRemote Sens. 2022, 14, 2104 19 of 26\ntiny instances of time consumption will lead to a cumulative increase in positioning time consumption. Therefore, the time-consuming compression in point cloud downsampling in this paper is beneficial for ensuring real-time vehicle positioning. The time consumption of the point cloud registration is shown in Figure 14b, which shows that the time taken for the LIO-SAM and A-LOAM point cloud registration step is in the range of (50 ms, 200 ms). By extracting and separating the ground point clouds, LeGOLOAM can inhibit the time-consuming increase caused by outlier registration due to the interference between non-identical cluster point clouds to a certain extent. The point cloud registration step takes approximately (50 ms, 100 ms). There are two possible factors for the obvious fluctuation of the above algorithm. The first is the fluctuation in the registration time due to the changing distribution of the ambient point cloud. The second is that, according to the experiments in Section 5.1, the rotation angle and displacement between the source and the target point cloud also have a certain influence on time consumption, which is obvious in the urban driving environment, where the speed and driving direction change irregularly. However, the time consumption of our algorithm is stable between (20 ms, 30 ms). The smoothing of the single-to-many distribution of the point cloud sequence greatly reduces the effect of the sparsity of the point cloud distribution on the alignment time, ensuring that the point cloud alignment step is both time-efficient and stable. The time consumption for the positional optimization step is shown in Figure 14c. The time taken to match the local map to the global map for LIO-SAM and LeGO-LOAM is around (30 ms, 130 ms). Due to the addition of GNSS sensors and the interference of some GNSS observations with low confidence, the total time consumption of LIO-SAM is even higher than that of LeGO-LOAM. However, A-LOAM takes (20 ms, 25 ms). The main reason is that the observation of only one sensor in LiDAR needs to be optimized, and the residual block is directly constructed in the original pose map structure, which reduces the computational burden of the multidimensional factor map. In this algorithm, the optimization method of A-LOAM is used for reference. It can be seen that, although the GNSS sensor is added, the time consumption is still stable at approximately 30 ms. The reason is that the global constraint of GNSS provides a more accurate transformation matrix from the local map to the global map for the fusion system, which makes it easier for the objective function of map matching to converge to the optimal solution. Secondly, we use the Gauss\u2013Newton method instead of the steepest gradient descent method used in [27] to minimize all of the cost functions, so as to reduce the number of iterations to converge quickly to the locally optimal estimate, which is one of the main reasons for the decrease in time consumption. The average total time of each algorithm in a single frame is shown in Table 6.\nIn summary, thanks to the double improvement of this algorithm in the front-end and back-end of our system, the time consumption of all three steps involved is compressed. Although the optimization vector of the GNSS sensor is newly added, it has a better real-time performance than other similar algorithms."
        },
        {
            "heading": "5.4. Mapping Results in the Real Urban Environment",
            "text": "As shown in Figure 15, this section shows the comparison of mapping results between our algorithm and similar advanced algorithms. Figure 15a shows the ground truth in the real outdoor environment, which is obtained by NovAtel SPAN-CPT. The vehicle travels for one week from the starting point in the lower right corner and then returns, and the trajectory is almost closed. Figure 15b shows the mapping result of LIO-SAM, and it is clear that the section near the end of the journey deviates significantly from the actual path\nRemote Sens. 2022, 14, 2104 20 of 26\ntravelled. The reason can be attributed to the fast displacement of the carrier, which leads to an increased difference in the point cloud clusters captured between the front and back frames, including rotation and displacement, resulting in the point cloud registration in the loopback detection of LIO-SAM being prone to failure and the loopback constraint results not being ideal. In addition, the GNSS constraint strategy adopted by LIO-SAM has a poor global correction effect on local sensors. However, compared with LIO-SAM, our algorithm has an obvious loop detection accuracy and GNSS global constraint effectiveness. Remote Sens. 2022, 14, x FOR PEER REVIEW 22 of 29\nFigure 15. Comparison of mapping effects of various algorithms. (a) The ground truth. (b) The mapping results of LIO-SAM. (c) The mapping results of the proposed algorithm."
        },
        {
            "heading": "6. Discussion",
            "text": "SLAM-based multi-sensor fusion positioning technology expands the application field of traditional GNSS-based mapping techniques and makes continuous and reliable positioning in complex urban environments with good/intermittent/rejection GNSS a reality. The superior sensing capability of LIO for natural sources has been demonstrated in the literature [5,6] and others. However, the accuracy limitation of point cloud registration and the local pose drift of LIO limit the application of LIO in large outdoor environments to some extent. This paper focuses on the above two technical bottlenecks faced by the existing LiDAR SLAM and proposes simplified but effective improvement solutions. First of all, the primary technical bottleneck is how to improve the accuracy of point cloud registration. Koideet al. [20] demonstrated that smoothing the point cloud cluster can improve the fault tolerance of point cloud registration and improve the accuracy of the point cloud from 1.20m to 0.89m. However, from our practical tests, it has been shown that, in long and large turning or translating sections in real environments, if the number of iterations is not limited, it may still fall into the local optimum problem. Therefore, on the basis of constructing a registration equation based on smooth voxelization filtering, we further use the judgment condition of iteration termination for the secondary constraint, so as to reduce the over-fitting problem of local point clouds in a typical environment. According to the registration experiment in Section 5.1 and the positional estimation accuracy experiment in Section 5.2, it can be seen that our registration method has a higher accuracy than the conventional methods. According to Figure 11, it can be seen that accurate point cloud alignment leads to an accurate initial value estimation of the positional attitude, which has a considerable positive effect on the positional estimation of the vehicle platform with a complex moving state. Secondly, there is the challenge of how to effectively use GNSS measurements and loopback detection mechanisms to converge the local positioning results of LIO to a globally optimal solution. Firstly, the main step of loop detection dependency is point cloud registration. The previous paragraph has specifically analyzed the superiority of our method. Thanks to the positive point cloud registration results, we can reason that our global constraint using loopback detection is superior, as demonstrated in Section 5.2.2. Next, some related research has been carried out on the research of GNSS and LIO fusion positioning. Optimization-based methods have been applied in [31,32] and so on. However, taking [27] for example, in the traditional graph optimization model, the covariance effect of measurements is only used to determine whether to add factors or not, which is crude for the screening of the measurements, especially for GNSS, a measurement signal that is greatly influenced by the environmental catadioptric surface, where its observation information has not been fully applied. Therefore, in this paper, on the basis of the rough screening of GNSS observations, the covariance of the quantitative measurements is\nAs shown in Figure 15c, the mapping trajectory of the algorithm proposed in this\npaper is basically fitted with the true value of the driving trajectory, and, in the loop road section in the lower right corner, the trajectories passing through the same landmark twice are basically coincident. The easons are as follows: firstly, smoothing t e point loud clusters c n improve the fault tolerance of the point cloud registration betwee th front and back frames; secondly, the we ghted GNSS global co st ain can liminate the GNSS measurements with large observation gross errors, thus achieving superior mapping results."
        },
        {
            "heading": "6. Discussion",
            "text": "SLAM-based multi-sensor fusi positi ning technology expands the pplication field of traditional GNSS-based mapping techniq es and makes c ntinuous and reliable positioning in complex urban environments with good/intermittent/rejection GNSS a reality. The superior sensing capability of LIO for natural sources has been demonstrated in the literature [5,6] and others. However, the accuracy limitation of point cloud registration and the local pose drift of LIO limit the application of LIO in large outdoor environments to some extent. This paper focuses on the above two technical bottlenecks faced by the existing LiDAR SLAM and proposes simplified but effective improvement solutions. First of all, the primary technical bottleneck is how to improve the accuracy of point cloud registration. Koideet al. [20] demonstrated that smoothing the point cloud cluster can improve the fault tolerance of point cloud registration and improve the accuracy of the point cloud from 1.20m to 0.89m. However, from our practical tests, it has been shown that, in long and large turning or translating sections in real environments, if the number of iterations is not limited, it may still fall into the local optimum problem. Therefore, on the basis of constructing a registration equation based on smooth voxelization filtering, we further use the judgment condition of iteration termination for the secondary constraint, so as to reduce the over-fitting problem of local point clouds in a typical environment. According to the registration experiment in Section 5.1 and the positional estimation accuracy experiment in Section 5.2, it can be seen that our registration method has a higher accuracy than the conventional methods. According to Figure 11, it can be seen that accurate point cloud alignment leads to an accurate initial value estimation of the positional attitude, which has a considerable positive effect on the positional estimation of the vehicle platform with a complex moving state.\nRemote Sens. 2022, 14, 2104 21 of 26\nSecondly, there is the challenge of how to effectively use GNSS measurements and loopback detection mechanisms to converge the local positioning results of LIO to a globally optimal solution. Firstly, the main step of loop detection dependency is point cloud registration. The previous paragraph has specifically analyzed the superiority of our method. Thanks to the positive point cloud registration results, we can reason that our global constraint using loopback detection is superior, as demonstrated in Section 5.2.2. Next, some related research has been carried out on the research of GNSS and LIO fusion positioning. Optimization-based methods have been applied in [31,32] and so on. However, taking [27] for example, in the traditional graph optimization model, the covariance effect of measurements is only used to determine whether to add factors or not, which is crude for the screening of the measurements, especially for GNSS, a measurement signal that is greatly influenced by the environmental catadioptric surface, where its observation information has not been fully applied. Therefore, in this paper, on the basis of the rough screening of GNSS observations, the covariance of the quantitative measurements is added as a weight to the graph optimization model. It achieves a more adequate and accurate global constraint on the LIO local poses using GNSS observations. From the ablation experiment results in Section 4.3.2, it is evident that the method of the weighted GNSS residual added in this paper achieves a satisfactory positioning accuracy. According to the above results, we can draw a reasonable inference: even when entering an indoor parking lot or tunnel, the accumulated error of LIO in this algorithm will start to accumulate from a lower initial value of drift. In contrast, for the LIO algorithms without GNSS constraints, they already have a large deviation between the local map and the global map before entering the denial environment. Therefore, the cumulative error range of this algorithm is acceptable. Once the GNSS signal is restored, the local error will be corrected within the time alignment interval of 0.1s as set in Section 4.3.2. This provides an accurate and continuous positional estimation for the in-vehicle platform during travel in complex urban environments."
        },
        {
            "heading": "7. Conclusions",
            "text": "In this paper, a LiDAR-IMU-GNSS fusion positioning algorithm with accurate local alignment and weak global drift is proposed for the high-precision continuous positioning of mobile carriers in complex urban environments. Firstly, a voxelized point cloud downsampling method based on curvature segmentation is proposed. Rough classification is carried out by a curvature threshold, and the voxelized point cloud downsampling is performed using HashMap instead of RANSAC, so that the spatial feature distribution attributes of the source point cloud, including texture feature information, such as surfaces and curves, are retained to a greater extent. Secondly, a point cloud registration model based on the nearest neighbors of the point and neighborhood point sets is constructed. Furthermore, an iterative termination threshold is set to reduce the probability of the local optimal solution. This greatly improves the real-time performance of the point cloud registration and can also play a large role in aligning the point cloud between the front and back frames of a fast-moving carrier with large displacement. Finally, we propose a LIO-GNSS fusion positioning model based on graph optimization that uses GNSS observations weighted by confidence to globally correct local drift. In addition, the loop detection mechanism using the above-mentioned point cloud registration algorithm is also added into the fusion system, resulting in further global constraints of the driving areas with prior maps. Experimental results show that our algorithm can realize a more continuous and accurate pose estimation and map reconstruction in complex urban environments than similar state-of-the-art algorithms. In the future work, there are still several issues in our work that deserve further exploration. Firstly, we plan to build a deeper constraint relationship between LIO and GNSS and make use of the rich planar features perceived by LiDAR in the urban environments to compensate for GNSS occlusion or the presence of multipath areas in the direction of\nRemote Sens. 2022, 14, 2104 22 of 26\nthe constraint. It will reduce the probability of the unreliability of SPP positioning results in the urban environments. Secondly, considering the environments with multi-sensor failures, such as tunnels with a high environmental texture similarity, where both GNSS rejection and point cloud degradation failures exist. We consider a more accurate degradation direction detection using the degeneracy factor (DF) algorithm proposed in [5], and make a non-linear optimization correction for the positional attitude in that direction. Finally, the perception ability of 3D environmental features by using only LiDAR, IMU and GNSS sensors is still relatively limited. We plan to use the observation residuals from other sensors to add multi-dimensional feature constraints to the fusion positioning algorithm, such as cameras, wheel odometers and so on, so as to make full use of environmental features and realize accurate and real-time navigation and positioning targets with high environmental universality.\nAuthor Contributions: Conceptualization, X.L.; methodology, X.H.; software, X.H.; validation, S.P.; formal analysis, X.H.; investigation, X.L.; resources, W.G.; data curation, X.H.; writing\u2014original draft preparation, X.L.; writing\u2014review and editing, X.H.; visualization, X.H.; supervision, S.P. and W.G.; project administration, W.G.; funding acquisition, S.P. All authors have read and agreed to the published version of the manuscript.\nFunding: This research study was funded by the National Key Research and Development Program of China (2021YFB3900804) and the Research Fund of the Ministry of Education of China and China Mobile (MCM20200J01).\nData Availability Statement: Not applicable.\nConflicts of Interest: The authors declare no conflict of interest."
        },
        {
            "heading": "Appendix A",
            "text": "Mathematical Derivation of the Equations (14) and (15). First, given the original accelerometer and gyroscope measurement values of IMU\nas follows: a\u0302t = at + bat + RLW gw + na \u03c9\u0302t = \u03c9t + bvt + nv\n(A1)\nwhere na \u223c N ( 0, \u03c32a ) and nv \u223c N ( 0, \u03c32v ) are white Gaussian noise of accelerometer and gyroscope, respectively. The following mathematical derivations are all completed in the IMU body coordinate system. Therefore, the position, rotation and velocity between the ith IMU frame and the i + 1th IMU frame can be obtained:\npi+1 = pi + vi\u2206ti + s\nt\u2208[ti ,ti+1]\n( RbW(a\u0302t \u2212 bt \u2212 na)\u2212 gw ) dt2\nqi+1 = qiExp(\u03c9\u0302t \u2212 bt \u2212 n\u03c9)\u2206ti vi+1 = vi + \u222b t\u2208[ti ,ti+1] ( RbW(a\u0302t \u2212 bt \u2212 na)\u2212 gw ) dt\n(A2)\nTo avoid repeated calculation of IMU parameters during pose estimation, pre-integration is introduced to simplify calculation, namely:\npi+1 = pi + vi\u2206ti \u2212 12 gw\u2206t2i + Rwb \u03b1 i i+1 qi+1 = qi \u2297 \u03b8ii+1 vi+1 = vi \u2212 gw\u2206ti + Rwb \u03b2 i i+1\n(A3)\nwhere [ \u03b1i+1i , \u03b8 i+1 i , \u03b2 i+1 i ]T is the IMU pre-integration value. It can be inferred from [28] that the IMU pre-integration value is only related to the IMU bias at different times. Since the\nRemote Sens. 2022, 14, 2104 23 of 26\nIMU bias change is very small, we assume that the pre-integration change is linear with the IMU bias, and then [ \u03b1i+1i , \u03b8 i+1 i , \u03b2 i+1 i ]T after each pose estimation can be recorded as:\n\u03b1i+1i = \u03b1\u0302 i+1 i + \u03b4\u03b1\u0302i+1i \u03b4ba \u03b4 ` ba + \u03b4\u03b1\u0302i+1i \u03b4b\u03c9 \u03b4 ` b\u03c9\n\u03b8i+1i = \u03b8\u0302 i+1 i \u2297  1 1 2 \u03b4\u03b8\u0302i+1i \u03b4b\u03c9 \u03b4 ` b\u03c9  \u03b2i+1i = \u03b2\u0302 i+1 i + \u03b4\u03b2\u0302i+1i \u03b4ba \u03b4 ` ba + \u03b4\u03b2\u0302i+1i \u03b4b\u03c9 \u03b4 ` b\u03c9\n(A4)\nEquation (A4) is the pre-integration form in the continuous time between the two IMU frames, and the actual IMU pre-integration is the incremental in the discrete time. Therefore, the mid-point integration is used for discretization, and the matrix form of the discrete IMU state error transfer equation is obtained:\n \u03b4\u03b1i+1 \u03b4\u03b8i+1 \u03b4\u03b2i+1 \u03b4bai+1 \u03b4b\u03c9i+1  = Fi  \u03b4\u03b1i \u03b4\u03b8i \u03b4\u03b2i \u03b4bai \u03b4b\u03c9i + Vi  n\u03b1i n\u03c9i n\u03b1i+1 n\u03c9i+1 nba nb\u03c9  (A5)\nwhere Fi and Vi are matrix abbreviations, with specific values as follows:\nFi  \u03b4\u03b1i \u03b4\u03b8i \u03b4\u03b2i \u03b4bai \u03b4b\u03c9i  =  I f01 \u03b4t f03 f04 0 f11 0 0 \u2212\u03b4t 0 f21 I f23 f24 0 0 0 I 0 0 0 0 0 I  (A6)\nf01 = \u03b4t2 f21 = \u2212 1 4 qk(a\u0302i \u2212 bi)\u00d7 \u03b4t2 \u2212 1 4 qi+1(a\u0302i+1 \u2212 bi)\u00d7\n[ I \u2212 ( \u03c9\u0302i+\u03c9\u0302i+1 2 \u2212 bi ) \u00d7 \u03b4t ] \u03b4t2\nf03 = \u2212 14 (qi + qi+1)\u03b4t2 f04 = \u03b4t2 f24 = 1 4 qi+1(a\u0302i+1 \u2212 bi)\u00d7 \u03b4t3\nf11 = I \u2212 ( \u03c9\u0302i+\u03c9\u0302i+1 2 \u2212 bk ) \u00d7 \u03b4t\nf21 = \u2212 12 qi(a\u0302i \u2212 bi)\u00d7 \u03b4t\u2212 1 2 qi+1(a\u0302i+1 \u2212 bi)\u00d7\n[ I \u2212 ( \u03c9\u0302i+\u03c9\u0302i+1 2 \u2212 bi ) \u00d7 \u03b4t ] \u03b4t\nf23 = \u2212 12 (qi + qi+1)\u03b4t2 f24 = 12 qi+1(a\u0302i+1 \u2212 bi)\u00d7 \u03b4t2\n(A7)\nVi =  v00 v01 v02 v03 0 0 0 \u03b4t2 0 \u03b4t 2 0 0 qi\u03b4t 2 v21 qi+1\u03b4t 2 v23 0 0\n0 0 0 0 \u03b4t 0 0 0 0 0 0 \u03b4t\n (A8)\nv00 = \u2212 14 qi\u03b4t2 v01 = v03 = \u03b4t2 v21 = 1 4 qi+1(a\u0302i+1 \u2212 bi)\u00d7 \u03b4t2 \u03b4t 2 v02 = \u2212 14 qi+1\u03b4t2 v21 = v23 = 14 qi+1(a\u0302i+1 \u2212 bi)\u00d7 \u03b4t2\n(A9)\nRemote Sens. 2022, 14, 2104 24 of 26\nLet z15\u00d71i = [\u03b4\u03b1i, \u03b4\u03b8i, \u03b4\u03b2i, \u03b4bai, \u03b4b\u03c9i] T and z15\u00d71i+1 = [\u03b4\u03b1i+1, \u03b4\u03b8i+1, \u03b4\u03b2i+1, \u03b4bai+1, \u03b4b\u03c9i+1] T\nbe the error state vector of the i th frame and the i+1 th frame, respectively, and n = [ n\u03b1i , n\u03c9i , n\u03b1i+1 , n\u03c9i+1 , nba , nb\u03c9 ]T is the noise vector; then, Equation (A5) can be written as: \u03b4z15\u00d71i+1 = F 15\u00d715\u03b4z15\u00d71i + V 15\u00d718n18\u00d71 (A10)\nwhere the initial Jacobian value is Ji = I and the Jacobian iteration formula in the process of nonlinear optimization is:\nJ15\u00d715i+1 = F 15\u00d715 J15\u00d715i (A11)\nThe iterative formula of the covariance of pre-integration in the nonlinear optimization process is:\n\u221115\u00d715i+1 = F \u2211 15\u00d715 i F T + VniVT (A12)\nAfter the pre-integration derivation, Equation (14) is the variable quantity of position, rotation, velocity and IMU bias between two frames."
        },
        {
            "heading": "Appendix B",
            "text": "Mathematical Derivation of the Equations (16) and (17). Equation (16) can be explained using the plane vector method. Let\u2223\u2223\u2223(XL(k+1,o) \u2212 XL(k,a))\u00d7 (XL(k+1,o) \u2212 XL(k,b))\u2223\u2223\u2223 be the area of the parallelogram formed by three points XL(k+1,o), X L (k,a) and X L (k,b). Let the spatial coordinates of the three points be XL(k+1,o)(x0, y0, z0), X L (k,a)(x1, y1, z1) and X L (k,b)(x2, y2, z2), from which, the three vectors are constructed as: \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 XL(k+1,o)X L (k,a) = X L (k+1,o) \u2212 X L (k,a) = (x1 \u2212 x0, y1 \u2212 y0, z1 \u2212 z0) \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 XL(k+1,o)X L (k,b) = X L (k+1,o) \u2212 X L (k,b) = (x2 \u2212 x0, y2 \u2212 y0, z2 \u2212 z0)\n\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 XL(k,a)X L (k,b) = X L (k,o) \u2212 X L (k,b) = (x2 \u2212 x1, y2 \u2212 y1, z2 \u2212 z1)\n(A13)\nThe molecules of Equation (11) can be obtained as follows:\n\u2223\u2223\u2223(XL(k+1,o) \u2212 XL(k,a))\u00d7 (XL(k+1,o) \u2212 XL(k,b))\u2223\u2223\u2223 = \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 XL(k+1,o) X L (k,a) X L (k,b) (x1 \u2212 x0) (y1 \u2212 y0) (z1 \u2212 z0) (x2 \u2212 x0) (y2 \u2212 y0) (z2 \u2212 z0) \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 (A14) The distance between the point XL(k+1,o) and the line X L (k,a)X L (k,b) represented by\nEquation (11) is:\ndLek = \u2223\u2223\u2223(XL(k+1,o)\u2212XL(k,a))\u00d7(XL(k+1,o)\u2212XL(k,b))\u2223\u2223\u2223\u2223\u2223\u2223XL(k,a)\u2212XL(k,b)\u2223\u2223\u2223 = sqrt{[(y1 \u2212 y0) \u2217 (z2 \u2212 z0)\u2212 (y2 \u2212 y0) \u2217 (z1 \u2212 z0)] \u2217[(y1 \u2212 y0) \u2217 (z2 \u2212 z0)\u2212 (y2 \u2212 y0) \u2217 (z1 \u2212 z0)] +[(x2 \u2212 x0) \u2217 (z1 \u2212 z0)\u2212 (x1 \u2212 x0) \u2217 (z2 \u2212 z0)] \u2217[(x2 \u2212 x0) \u2217 (z1 \u2212 z0)\u2212 (x1 \u2212 x0) \u2217 (z2 \u2212 z0)] +[(x1 \u2212 x0) \u2217 (y2 \u2212 y0)\u2212 (x2 \u2212 x0) \u2217 (y1 \u2212 y0)] \u2217[(x1 \u2212 x0) \u2217 (y2 \u2212 y0)\u2212 (x2 \u2212 x0) \u2217 (y1 \u2212 y0)] } ]\n/sqrt[(x2 \u2212 x1) \u2217 (x2 \u2212 x1) + (y2 \u2212 y1) \u2217 (y2 \u2212 y1) + (z2 \u2212 z1) \u2217 (z2 \u2212 z1)]\n(A15)\nRemote Sens. 2022, 14, 2104 25 of 26\nSimilarly, the molecule of Equation (17) can be expressed as the volume of a triangular pyramid composed of four points: XL(k+1,o), X L (k,c), X L (k,d) and X L (k, f ) in a geometric\nsense. It can be known that \u2223\u2223\u2223(XL(k,c) \u2212 XL(k,d))\u00d7 (XL(k,c) \u2212 XL(k, f ))\u2223\u2223\u2223 is twice the area of the base. Let the spatial coordinates of the four points be XL(k+1,\u03c1)(x3, y3, z3), X L (k,c)(x4, y4, z4), XL(k,d)(x5, y5, z5) and X L (k, f )(x6, y6, z6), so the three vectors required for constructing are: \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 XL(k+1,\u03c1)X L (k,d) = X L (k+1,\u03c1) \u2212 X L (k,d) = (x5 \u2212 x3, y5 \u2212 y3, z5 \u2212 z3) \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 XL(k,c)X L (k,d) = X L (k,c) \u2212 X L (k,d) = (x5 \u2212 x4, y5 \u2212 y4, z5 \u2212 z4)\n\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 XL(k,c)X L (k, f ) = X L (k,c) \u2212 X L (k, f ) = (x6 \u2212 x4, y6 \u2212 y4, z6 \u2212 z4)\n(A16)\nThe molecules of Equation (17) can be obtained as follows:\n\u2223\u2223\u2223(XL(k,c) \u2212 XL(k,d))\u00d7 (XL(k,c) \u2212 XL(k, f ))\u2223\u2223\u2223 = \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 XL(k,c) X L (k,d) X L (k, f ) (x5 \u2212 x4) (y5 \u2212 y4) (z5 \u2212 z4) (x6 \u2212 x4) (y6 \u2212 y4) (z6 \u2212 z4) \u2223\u2223\u2223\u2223\u2223\u2223\u2223\u2223 = sqrt(sa \u2217 sa, sb \u2217 sb, sc \u2217 sc) (A17)\nwhere sa, sb and sc represent the component vectors of x, y and z axes, respectively: sa = (y5 \u2212 y4) \u2217 (z6 \u2212 z4)\u2212 (y6 \u2212 y4) \u2217 (z5 \u2212 z4) sb = (z5 \u2212 z4) \u2217 (x6 \u2212 x4)\u2212 (z6 \u2212 z4) \u2217 (x5 \u2212 x4) sc = (x5 \u2212 x4) \u2217 (y6 \u2212 y4)\u2212 (x6 \u2212 x4) \u2217 (y5 \u2212 y4) (A18)\nTherefore, the point-to-surface distance can be obtained as follows:\ndLpk = \u2223\u2223\u2223(XL(k+1,o)\u2212XL(k,d)) \u00b7 ((XL(k,c)\u2212XL(k,d))\u00d7(XL(k,c)\u2212XL(k, f )))\u2223\u2223\u2223\u2223\u2223\u2223(XL(k,c)\u2212XL(k,d))\u00d7(XL(k,c)\u2212XL(k, f ))\u2223\u2223\u2223 = (x4\u2212x3)\u2217sa+(y4\u2212y3)\u2217sb+(z4\u2212z3)\u2217sc\n=sqrt(sa\u2217sa ,sb\u2217sb ,sc\u2217sc)\n(A19)\nReferences 1. Mascaro, R.; Teixeira, L.; Hinzmann, T.; Siegwart, R.; Chli, M. GOMSF: Graph-Optimization based Multi-Sensor Fusion for robust\nUAV pose estimation. In Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, Australia, 21\u201325 May 2018; pp. 1421\u20131428.\n2. Lee, W.; Eckenhoff, K.; Geneva, P.; Huang, G.Q. Intermittent GPS-aided VIO: Online Initialization and Calibration. In Proceedings of the 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 31 May\u201331 August 2020; pp. 5724\u20135731. 3. Zhang, J.; Khoshelham, K.; Khodabandeh, A. Seamless Vehicle Positioning by Lidar-GNSS Integration: Standalone and MultiEpoch Scenarios. Remote Sens. 2021, 13, 4525. [CrossRef] 4. Forster, C.; Carione, L.; Dellaert, F.; Scaramuzza, D. On-Manifold Preintegration for Real-Time Visual\u2013Inertial Odometry. IEEE Trans. Robot. 2017, 33, 1\u201321. [CrossRef] 5. Shan, T.; Englot, B. LeGO-LOAM: Lightweight and Ground-Optimized Lidar Odometry and Mapping on Variable Terrain. In Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, Spain, 1\u20135 October 2018; pp. 4758\u20134765. 6. Li, S.; Li, J.; Tian, B.; Chen, L.; Wang, L.; Li, G. A laser SLAM method for unmanned vehicles in point cloud degenerated tunnel environments. Acta Geod. Cartogr. Sin. 2021, 50, 1487\u20131499. 7. Gong, Z.; Liu, P.; Wen, F.; Ying, R.D.; Ji, X.W.; Miao, R.H.; Xue, W.Y. Graph-Based Adaptive Fusion of GNSS and VIO Under Intermittent GNSS-Degraded Environment. IEEE Trans. Instrum. Meas. 2021, 70, 9268091. [CrossRef] 8. Chou, C.C.; Chou, C.F. Efficient and Accurate Tightly-Coupled Visual-Lidar SLAM. IEEE Trans. Intell. Transp. Syst. 2021, 1\u201315. [CrossRef]\nRemote Sens. 2022, 14, 2104 26 of 26\n9. He, X.; Gao, W.; Sheng, C.Z.; Zhang, Z.T.; Pan, S.G.; Duan, L.J.; Zhang, H.; Lu, X.Y. LiDAR-Visual-Inertial Odometry Based on Optimized Visual Point-Line Features. Remote Sens. 2022, 14, 622. [CrossRef] 10. Biber, P.; Strasser, W. The normal distributions transform: A new approach to laser scan matching. In Proceedings of the 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Las Vegas, NV, USA, 27\u201331 October 2003; pp. 2743\u20132748. 11. Besl, P.J.; Mckay, N.D. A method for registration of 3-D shapes. IEEE Trans. Pattern Anal. Mach. Intell. 1992, 14, 239\u2013256. [CrossRef] 12. Servos, J.; Waslander, S.L. Multi-Channel Generalized-ICP. In Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA), Hong Kong, China, 31 May\u20137 June 2014; pp. 3644\u20133649. 13. Du, S.Y.; Liu, J.; Bi, B.; Zhu, J.H.; Xue, J.R. New iterative closest point algorithm for isotropic scaling registration of point sets with noise. J. Vis. Commun. Image Represent. 2016, 38, 207\u2013216. [CrossRef] 14. Wu, Z.; Chen, H.; Du, S. Robust Affine Iterative Closest Point Algorithm Based on Correntropy for 2D Point Set Registration. In\nProceedings of the IEEE International Joint Conference on Neural Networks (IJCNN), Vancouver, BC, Canada, 24\u201329 July 2016; pp. 1415\u20131419.\n15. Wu, L.Y.; Xiong, L.; Bi, D.Y.; Fang, T.; Du, S.Y.; Cui, W.T. Robust Affine Registration Based on Corner Point Guided ICP Algorithm. In Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics (SMC), Banff, AB, Canada, 5\u20138 October 2017; pp. 537\u2013541. 16. Grisetti, G.; Stachniss, C.; Burgard, W. Improved techniques for grid mapping with Rao-Blackwellized particle filters. IEEE Trans. Robot. 2007, 23, 34\u201346. [CrossRef] 17. Andreasson, H.; Stoyanov, T. Real-Time Registration of RGB-D Data Using Local Visual Features and 3D-NDT Registration. [DB/OL]. Available online: https://www.researchgate.net/publication/267688026_Real_Time_Registration_of_RGB-D_Data_ using_Local_Visual_Features_and_3D-NDT_Registration (accessed on 14 March 2022). 18. Caballero, F.; Merino, L. DLL: Direct LIDAR Localization. A map-based localization approach for aerial robots. In Proceedings of the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Prague, Czech Republic, 27 September\u20131 October 2021; pp. 5491\u20135498. 19. Chen, C.; Yang, B.; Tian, M.; Li, J.; Zou, X.; Wu, W.; Song, Y. Automatic registration of vehicle-borne mobile mapping laser point cloud and sequent panoramas. Acta Geo Daetica Cartogr. Sin. 2018, 47, 215\u2013224. 20. Koide, K.; Yokozukam, M.; Oishi, S.; Banno, A. Voxelized GICP for Fast and Accurate 3D Point Cloud Registration. In Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), Xi\u2019an, China, 30 May\u20135 June 2021; pp. 11054\u201311059. 21. Yang, J.; Li, H.D.; Campbell, D.; Jia, Y. Go-ICP: A Globally Optimal Solution to 3D ICP Point-Set Registration. IEEE Trans. Pattern Anal. Mach. Intell. 2016, 38, 2241\u20132254. [CrossRef] [PubMed] 22. Pan, Y.; Xiao, P.; He, Y.; Shao, Z.; Li, Z. MULLS: Versatile LiDAR SLAM via Multi-metric Linear Least Square. In Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), Xi\u2019an, China, 30 May\u20135 June 2021; pp. 11633\u201311640. 23. Qin, C.; Ye, H.; Pranata, C.E.; Han, J.; Zhang, S.; Liu, M. LINS: A Lidar-Inertial State Estimator for Robust and Efficient Navigation. In Proceedings of the 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France, 31 May\u201331 August 2020; pp. 8899\u20138906. 24. Li, W.; Liu, G.; Cui, X.; Lu, M. Feature-Aided RTK/LiDAR/INS Integrated Positioning System with Parallel Filters in the Ambiguity-Position-Joint Domain for Urban Environments. Remote Sens. 2021, 13, 2013. [CrossRef] 25. Li, X.X.; Wang, H.D.; Li, S.Y.; Feng, S.Q.; Wang, X.B.; Liao, J.C. GIL: A tightly coupled GNSS PPP/INS/LiDAR method for precise vehicle navigation. Satell. Navig. 2021, 26, 2. [CrossRef] 26. Soloviev, A. Tight Coupling of GPS, INS, and Laser for Urban Navigation. IEEE Trans. Aerosp. Electron. Syst. 2010, 46, 1731\u20131746. [CrossRef] 27. Shan, T.; Englot, B.; Meyers, D.; Wang, W.; Ratti, C.; Rus, D. LIO-SAM: Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping. In Proceedings of the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Las Vegas, NV, USA, 24 October\u201324 January 2021; pp. 5136\u20135142. 28. Sun, X.; Guan, H.; Su, Y.; Xu, G.; Guo, Q. A tightly coupled SLAM method for precise urban mapping. Acta Geod. Cartogr. Sin. 2021, 50, 1585\u20131593. 29. GTSAM. Available online: https://gtsam.org/tutorials/intro.html (accessed on 14 April 2022). 30. Geiger, A.; Lenz, P.; Stiller, C.; Urtasun, R. Vision meets robotics: The KITTI dataset. Int. J. Robot. Res. 2013, 32, 1231\u20131237. [CrossRef] 31. Chen, S.; Zhou, B.; Jiang, C.; Xue, W.; Li, Q. A LiDAR/Visual SLAM Backend with Loop Closure Detection and Graph Optimization. Remote Sens. 2021, 13, 2720. [CrossRef] 32. Qin, T.; Li, P.; Shen, S. Vins-mono: A robust and versatile monocular visual-inertial state estimator. IEEE Trans. Robot. 2018, 34,\n1004\u20131020. [CrossRef]"
        }
    ],
    "title": "LiDAR-Inertial-GNSS Fusion Positioning System in Urban Environment: Local Accurate Registration and Global Drift-Free",
    "year": 2022
}