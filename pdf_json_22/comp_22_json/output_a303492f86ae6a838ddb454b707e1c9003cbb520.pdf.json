{
    "abstractText": "DianYu Liu,a ChuanLe Suna and Jun Gaoa,b,c INPAC, Shanghai Key Laboratory for Particle Physics and Cosmology, School of Physics and Astronomy, Shanghai Jiao-Tong University, Shanghai 200240, China Key Laboratory for Particle Astrophysics and Cosmology (MOE), Shanghai 200240, China Center for High Energy Physics, Peking University, Beijing 100871, China E-mail: dianyu.liu@sjtu.edu.cn, chlsun60@sjtu.edu.cn, jung49@sjtu.edu.cn",
    "authors": [
        {
            "affiliations": [],
            "name": "DianYu Liu"
        }
    ],
    "id": "SP:8fe973d663bed0a6aeafe2253bc9098581fd0c74",
    "references": [
        {
            "authors": [
                "J. Gao",
                "L. Harland-Lang",
                "J. Rojo"
            ],
            "title": "The Structure of the Proton in the LHC Precision Era",
            "venue": "Phys. Rept. 742 ",
            "year": 2018
        },
        {
            "authors": [
                "K. Kova\u0159\u00edk",
                "P.M. Nadolsky",
                "D.E. Soper"
            ],
            "title": "Hadronic structure in high-energy collisions",
            "venue": "Rev. Mod. Phys. 92 ",
            "year": 2020
        },
        {
            "authors": [
                "J.C. Collins",
                "D.E. Soper",
                "G.F. Sterman"
            ],
            "title": "Factorization of Hard Processes in QCD",
            "venue": "Adv. Ser. Direct. High Energy Phys. 5 ",
            "year": 1989
        },
        {
            "authors": [
                "X. Ji",
                "Y.-S. Liu",
                "Y. Liu",
                "J.-H. Zhang",
                "Y. Zhao"
            ],
            "title": "Large-momentum effective theory",
            "venue": "Rev. Mod. Phys. 93 ",
            "year": 2021
        },
        {
            "authors": [
                "W. Beenakker"
            ],
            "title": "NLO+NLL squark and gluino production cross-sections with threshold-improved parton distributions",
            "venue": "Eur. Phys. J. C",
            "year": 2016
        },
        {
            "authors": [
                "S. Alioli",
                "M. Farina",
                "D. Pappadopulo",
                "J.T. Ruderman"
            ],
            "title": "Precision Probes of QCD at High Energies",
            "venue": "JHEP 07 ",
            "year": 2017
        },
        {
            "authors": [
                "T.-J. Hou"
            ],
            "title": "New CTEQ global analysis of quantum chromodynamics with high-precision data from the LHC",
            "venue": "Phys. Rev. D",
            "year": 2021
        },
        {
            "authors": [
                "S. Bailey",
                "T. Cridge",
                "L.A. Harland-Lang",
                "A.D. Martin",
                "R.S. Thorne"
            ],
            "title": "Parton distributions from LHC",
            "venue": "HERA, Tevatron and fixed target data: MSHT20 PDFs, Eur. Phys. J. C 81 ",
            "year": 2021
        },
        {
            "authors": [
                "S. Alekhin",
                "J. Bl\u00fcmlein",
                "S. Moch"
            ],
            "title": "NLO PDFs from the ABMP16 fit",
            "venue": "Eur. Phys. J. C 78 ",
            "year": 1803
        },
        {
            "authors": [
                "P. Jimenez-Delgado",
                "E. Reya"
            ],
            "title": "Delineating parton distributions and the strong coupling",
            "venue": "Phys. Rev. D 89 ",
            "year": 2014
        },
        {
            "authors": [
                "S. Park",
                "A. Accardi",
                "X. Jing",
                "J.F. Owens"
            ],
            "title": "CJ15 global PDF analysis with new electroweak data from the STAR and SeaQuest experiments, in 28th International Workshop on Deep Inelastic Scattering and Related Subjects",
            "venue": "Online conference U.S.A.,",
            "year": 2021
        },
        {
            "authors": [
                "J. Pumplin"
            ],
            "title": "Uncertainties of predictions from parton distribution functions",
            "venue": "The Hessian method, Phys. Rev. D",
            "year": 2001
        },
        {
            "authors": [
                "A.D. Martin",
                "W.J. Stirling",
                "R.S. Thorne",
                "G. Watt"
            ],
            "title": "Parton distributions for the LHC",
            "venue": "Eur. Phys. J. C 63 ",
            "year": 2009
        },
        {
            "authors": [
                "S. Forte",
                "L. Garrido",
                "J.I. Latorre",
                "A. Piccione"
            ],
            "title": "Neural network parametrization of deep inelastic structure functions",
            "venue": "JHEP 05 ",
            "year": 2002
        },
        {
            "authors": [
                "J. Pumplin",
                "D.R. Stump",
                "W.K. Tung"
            ],
            "title": "Multivariate fitting and the error matrix in global analysis of data",
            "venue": "Phys. Rev. D 65 ",
            "year": 2001
        },
        {
            "authors": [
                "D. Stump"
            ],
            "title": "Uncertainties of predictions from parton distribution functions",
            "venue": "The Lagrange multiplier method, Phys. Rev. D",
            "year": 2001
        },
        {
            "authors": [
                "J. Gao",
                "P. Nadolsky"
            ],
            "title": "A meta-analysis of parton distribution functions",
            "venue": "JHEP 07 ",
            "year": 2014
        },
        {
            "authors": [
                "C. Schmidt",
                "J. Pumplin",
                "C.P. Yuan",
                "P. Yuan"
            ],
            "title": "Updating and optimizing error parton distribution function sets in the Hessian approach",
            "venue": "Phys. Rev. D 98 ",
            "year": 2018
        },
        {
            "authors": [
                "B.-T. Wang"
            ],
            "title": "Mapping the sensitivity of hadronic experiments to nucleon structure",
            "venue": "Phys. Rev. D",
            "year": 2018
        },
        {
            "authors": [
                "D. Guest",
                "K. Cranmer",
                "D. Whiteson"
            ],
            "title": "Deep Learning and its Application to LHC Physics",
            "venue": "Ann. Rev. Nucl. Part. Sci. 68 ",
            "year": 2018
        },
        {
            "authors": [
                "S.S. Forte"
            ],
            "title": "Carrazza, Parton distribution functions, arXiv:2008.12305 [INSPIRE",
            "year": 2008
        },
        {
            "authors": [
                "A. Dainese",
                "M. Mangano",
                "A.B. Meyer",
                "A. Nisati",
                "M.A.G. Salam"
            ],
            "title": "Vesterinen, Report on the Physics at the HL-LHC,and Perspectives for the HE-LHC, CERN",
            "venue": "Yellow Rep. Monogr",
            "year": 2019
        },
        {
            "authors": [
                "R. Abdul Khalek",
                "S. Bailey",
                "J. Gao",
                "L. Harland-Lang",
                "J. Rojo"
            ],
            "title": "Towards Ultimate Parton Distributions at the High-Luminosity LHC",
            "venue": "Eur. Phys. J. C 78 ",
            "year": 1810
        },
        {
            "authors": [
                "R. Abdul Khalek",
                "S. Bailey",
                "J. Gao",
                "L. Harland-Lang",
                "J. Rojo"
            ],
            "title": "Probing Proton Structure at the Large Hadron electron Collider",
            "venue": "SciPost Phys. 7 ",
            "year": 2019
        },
        {
            "authors": [
                "S. Carrazza",
                "C. Degrande",
                "S. Iranipour",
                "J. Rojo",
                "M. Ubiali"
            ],
            "title": "Can New Physics hide inside the proton",
            "venue": "Phys. Rev. Lett. 123 ",
            "year": 2019
        },
        {
            "authors": [
                "A. Greljo"
            ],
            "title": "Parton distributions in the SMEFT from high-energy Drell-Yan tails, JHEP",
            "year": 2021
        },
        {
            "authors": [
                "M. Madigan",
                "J. Moore"
            ],
            "title": "Parton Distributions in the SMEFT from high-energy Drell-Yan tails",
            "venue": "PoS EPS-HEP2021 ",
            "year": 2022
        },
        {
            "authors": [
                "S. Iranipour",
                "M. Ubiali"
            ],
            "title": "A new generation of simultaneous fits to LHC data using deep learning",
            "venue": "JHEP 05 ",
            "year": 2022
        },
        {
            "authors": [
                "J. Alwall"
            ],
            "title": "The automated computation of tree-level and next-to-leading order differential cross sections, and their matching to parton shower simulations, JHEP",
            "year": 2014
        },
        {
            "authors": [
                "V. Bertone",
                "R. Frederix",
                "S. Frixione",
                "J. Rojo",
                "M. Sutton"
            ],
            "title": "aMCfast: automation of fast NLO computations for PDF fits",
            "venue": "JHEP 08 ",
            "year": 2014
        },
        {
            "authors": [
                "T. Carli"
            ],
            "title": "A posteriori inclusion of parton density functions in NLO QCD final-state calculations at hadron colliders: The APPLGRID Project",
            "venue": "Eur. Phys. J. C",
            "year": 2010
        },
        {
            "authors": [
                "G.P. Salam",
                "J. Rojo"
            ],
            "title": "A Higher Order Perturbative Parton Evolution Toolkit (HOPPET)",
            "venue": "Comput. Phys. Commun. 180 ",
            "year": 2009
        },
        {
            "authors": [
                "J.P. Berge"
            ],
            "title": "A Measurement of Differential Cross-Sections and Nucleon Structure Functions in Charged Current Neutrino Interactions on Iron",
            "venue": "Z. Phys. C",
            "year": 1991
        },
        {
            "authors": [
                "W.G. Seligman"
            ],
            "title": "Improved determination of \u03b1s from neutrino nucleon scattering",
            "venue": "Phys. Rev. Lett",
            "year": 1997
        },
        {
            "authors": [
                "D.A. Mason"
            ],
            "title": "Measurement of the strange - antistrange asymmetry at nlo in qcd from nutev dimuon data",
            "venue": "Ph.D. Thesis, Department of Physics, University of Oregon, Oregon U.S.A ",
            "year": 2006
        },
        {
            "authors": [
                "G. Moreno"
            ],
            "title": "Dimuon production in proton - copper collisions at \u221a s = 38.8\u2212GeV",
            "venue": "Phys. Rev. D",
            "year": 1991
        },
        {
            "authors": [
                "S. Dulat"
            ],
            "title": "New parton distribution functions from a global analysis of quantum chromodynamics",
            "venue": "Phys. Rev. D",
            "year": 2016
        },
        {
            "authors": [
                "H.-L. Lai"
            ],
            "title": "New parton distributions for collider physics",
            "venue": "Phys. Rev. D",
            "year": 2010
        },
        {
            "authors": [
                "C. Anastasiou",
                "C. Duhr",
                "F. Dulat",
                "F. Herzog",
                "B. Mistlberger"
            ],
            "title": "Higgs Boson Gluon-Fusion Production in QCD at Three Loops",
            "venue": "Phys. Rev. Lett. 114 ",
            "year": 1503
        },
        {
            "authors": [
                "E.L. Berger",
                "J. Gao",
                "C.S. Li",
                "Z.L. Liu",
                "H.X. Zhu"
            ],
            "title": "Charm-Quark Production in Deep-Inelastic Neutrino Scattering at Next-to-Next-to-Leading Order in QCD",
            "venue": "Phys. Rev. Lett. 116 ",
            "year": 2016
        },
        {
            "authors": [
                "J. Gao"
            ],
            "title": "Massive charged-current coefficient functions in deep-inelastic scattering at NNLO and impact on strange-quark distributions",
            "venue": "JHEP 02 ",
            "year": 2018
        },
        {
            "authors": [
                "J. Gao",
                "T.J. Hobbs",
                "P.M. Nadolsky",
                "C. Sun",
                "C.P. Yuan"
            ],
            "title": "General heavy-flavor mass scheme for charged-current DIS at NNLO and beyond",
            "venue": "Phys. Rev. D 105 ",
            "year": 2022
        },
        {
            "authors": [
                "S. Alekhin"
            ],
            "title": "Determination of Strange Sea Quark Distributions from Fixed-target and Collider",
            "venue": "Data, Phys. Rev. D",
            "year": 2015
        },
        {
            "authors": [
                "F. Faura",
                "S. Iranipour",
                "E.R. Nocera",
                "J. Rojo",
                "M. Ubiali"
            ],
            "title": "The Strangest Proton",
            "venue": "Eur. Phys. J. C 80 ",
            "year": 2020
        },
        {
            "authors": [
                "T. Kluge",
                "M.K. Rabbertz"
            ],
            "title": "Wobisch, FastNLO: Fast pQCD calculations for PDF fits, in 14th International Workshop on Deep Inelastic Scattering",
            "venue": "Tsukuba Japan, April",
            "year": 2006
        },
        {
            "authors": [
                "L.A. Harland-Lang",
                "A.D. Martin",
                "P. Motylinski",
                "R.S. Thorne"
            ],
            "title": "Parton distributions in the LHC era: MMHT 2014 PDFs",
            "venue": "Eur. Phys. J. C 75 ",
            "year": 2015
        },
        {
            "authors": [
                "A. Buckley"
            ],
            "title": "LHAPDF6: parton density access in the LHC precision era",
            "venue": "Eur. Phys. J. C",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "J H E P 0 8 ( 2 0 2 2 ) 0 8 8\nKeywords: Parton Distributions, Deep Inelastic Scattering or Small-X Physics\nArXiv ePrint: 2201.06586\nOpen Access, c\u00a9 The Authors. Article funded by SCOAP3. https://doi.org/10.1007/JHEP08(2022)088\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nContents"
        },
        {
            "heading": "1 Introduction 1",
            "text": ""
        },
        {
            "heading": "2 Setup of the Neural Network program 3",
            "text": "2.1 Basic setup of NNs 4 2.2 PDF parametrization form 5 2.3 Targets and samples 6"
        },
        {
            "heading": "3 Validation of NNs 7",
            "text": "3.1 \u03c72 of the global fit 8 3.2 Physics quantities 9"
        },
        {
            "heading": "4 Lagrange Multiplier scans 13",
            "text": "4.1 LM scans on PDFs 13 4.2 LM scans on cross sections 17 4.3 Study on impact of individual data sets 19 4.4 Two-dimensional LM scans 20"
        },
        {
            "heading": "5 Applications 22",
            "text": "5.1 Constraint from NOMAD data 22 5.2 Impact of High-luminosity LHC 26 5.3 Constraint on new physics with the global fit 30"
        },
        {
            "heading": "6 Conclusion 32",
            "text": ""
        },
        {
            "heading": "A More on the Neural Network approach 34",
            "text": ""
        },
        {
            "heading": "B Hessian PDF set 37",
            "text": "C Variant fits with NOMAD data 39"
        },
        {
            "heading": "1 Introduction",
            "text": "Precise understanding of the parton structure of the proton is a central topic of QCD [1, 2]. The parton structure can be described by parton distribution functions (PDFs), which represent distributions of momentum fractions of the proton carried by quarks and gluons, for instance in the case of QCD collinear factorization [3]. They are usually determined by fitting to a variety of experimental data, such as data from proton-proton collision, proton-antiproton collision, electron-proton collision, and neutrino\u2013nucleus scatterings. Besides, there have also been recent developments on calculating PDFs from first principles based on the large momentum effective theory [4] and lattice QCD simulations [5]. Especially, PDFs play important roles in LHC studies. For example, PDF uncertainties represent one of the dominant uncertainties in measurements of the Higgs boson\n\u2013 1 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\ncouplings [6]. Better control of PDF uncertainties are necessary in direct searches for new heavy resonances [7] and indirect searches for new physics beyond the SM [8]. Furthermore, PDF uncertainties also have a large impact on precision measurements of the SM parameters including the strong coupling constant [9], the weak mixing angle and the W boson mass [10, 11]. Modern analysis of PDFs requires calculations of the log-likelihood functions from thousands of experimental data points, and scans of multi-dimensional parameter space with tens of degrees of freedom. There are several groups providing regular updates of PDFs via global fits, see refs. [12\u201319] for recent results on PDF determinations. The difference between those PDF sets is mainly due to the choice of the experimental data sets, the theoretical calculations used, and the parametrization form of PDFs. PDF uncertainties can be determined with three methods: the Hessian [20, 21], Monte Carlo (MC) [22], and Lagrange Multiplier (LM) [23, 24] method. There also exist recently developed approaches, meta analysis [25], ePump [26] and L2 sensitivity [27], on accessing impacts of experimental data on PDFs based on the Hessian method. In the Hessian method, the log-likelihood function (\u03c72) of a global fit is approximated with a quadratic form of the PDF parameters at the neighborhood of the global minimum. The uncertainties are thus determined through error PDFs along eigenvector directions, constructed by requiring the increase of the total \u03c72 of 1 or of a certain tolerance. In the MC method, one can obtain the PDF uncertainties from an ensemble of PDF replicas which are fitted to an ensemble of \u201cpseudo-data\u201d. Those pseudo-data are generated from the probability distributions related to the original experimental data sets. On another hand, for the LM method, PDF uncertainties of an observable can be determined from the profiled \u03c72 as a function of the observable, without relying on any assumptions about the behavior of the \u03c72 at the neighborhood of the global minimum. This means PDF uncertainties estimated from the LM method are more robust than those from the Hessian method. However, the LM method requires a detailed scan of the PDF parameter space for every observable studied, which is usually time consuming. This drawback can be overcome with the help of machine learning (ML). ML has been widely used in studies of high-energy physics in recent years. In many cases, ML is used for classifications such as particle identification and event selection in experimental data analysis [28]. Neural networks (NNs) are also helpful in regression problems, for example, applications of NNs in the study of PDFs have been pioneered by the NNPDF collaboration [29]. Dependence of PDFs on the momentum fraction are parametrized using NNs, which ensures a great flexibility [30]. On another hand, dependence of the \u03c72 or any physics quantity, such as the cross section, on PDFs is complex in general. NNs offer an opportunity to relate physics quantities to PDFs efficiently. One can build NNs with PDFs as input variables to model their PDF dependence. Compared with traditional methods, NNs can greatly improve efficiencies on generating predictions for those physics quantities. With above motivations, in this paper we propose a new approach with which PDF uncertainties can be calculated efficiently using the LM method with the assistance of NNs. It takes three steps to achieve this goal. First, we construct and train NNs to model the \u03c72 of each individual data set used in the global fit with PDFs. Second, we construct and\n\u2013 2 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\ntrain other NNs to associate the physics quantity to be studied with PDFs. Finally, we can perform LM scans to determine PDF uncertainties in a robust way. The speed of LM scans can be improved by several orders of magnitude due to the introduction of the NNs. We demonstrate above idea in the framework of CT18 NNLO global analysis [12] and beyond. We show how the new approach can help to understand various PDF uncertainties and the interplay between different data sets in the global fit. Moreover, we explore several directions beyond CT18 as will be explained below. Only a few data sets in the CT18 global fit are sensitive to the strange-quark PDFs. The dimuon production in neutrino scatterings provides an opportunity to directly constrain strange-quark distributions in the nucleon. In recent NOMAD measurements [31], a sample of about 9 \u00d7 106 events of inclusive charged-current deep-inelastic scattering (CCDIS), together with about 15344 events of dimuon production, is collected. The large statistics lead to a better control on various systematic errors and also an improvement in statistical uncertainties. We include the NOMAD data in the global fit and evaluate the impact on the PDFs using the aforementioned approach. The High Luminosity LHC (HL-LHC) is supposed to accumulate an integrated luminosity of 3000 fb\u22121 for ATLAS and CMS and of 300 fb\u22121 for LHCb [32]. We take two of those HL-LHC pseudo-data sets constructed in refs. [33, 34], the high-mass Drell-Yan data and the forward W/Z production data, and evaluate their impacts on PDFs. Our projection shows they can largely improve separations of different flavors, especially for sea quarks. In the searches for new physics beyond the SM from scatterings involving nucleons, for instance at HERA or LHC, one key problem is on the degeneracy of PDF variations and the new physics contributions, especially in cases when similar measurements are used in both the global fit of PDFs and in the searches of new physics. Ideally a joint global fit including both PDFs and model parameters of the new physics should be performed, see refs. [35\u201339] for examples. We demonstrate successful application of our approach in such scenario by a simultaneous fit of both PDFs and the Wilson coefficient of lepton-quark contact interactions in the SM effective field theory (SMEFT). The rest of this paper is organized as follows. In section 2, we describe the basic setup of our approach, including architectures of the NNs, PDF parametrizations and experimental data sets considered in the global fit. In section 3, we discuss performances of the approach and show that the accuracy of approximations with NNs are far sufficient for phenomenological studies. In section 4, we explain the method of LM scans and discuss several features of the CT18 analysis based on the new approach. In section 5, we study the impact of the NOMAD measurements and of the two pseudo-data of HL-LHC on PDFs, and show a joint fit with both PDFs and new physics contributions. Finally, we conclude in section 6."
        },
        {
            "heading": "2 Setup of the Neural Network program",
            "text": "In this section, we give a brief introduction to the setup of our NNs, including the architectures, the input variables, and the target functions. We further explain the training processes from the generation of samples to the minimization of the loss function.\n\u2013 3 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nFigure 1. An example of the architecture of NNs in this work, taking \u03c72 as the target function.\nTarget No. ofhidden layers No. of nodes for each hidden layer Activation functions for each layer No. of total params \u03c72 2 60,40 tanh, (x2 + 2), linear 7581 \u03c3, fi(x,Q), fi(x,Q)/fj(x,Q) 1 40 tanh, linear 3441\nTable 1. The architecture of NNs in this paper. Structure is set up for either \u03c72 or other quantities."
        },
        {
            "heading": "2.1 Basic setup of NNs",
            "text": "The general structure of NNs includes three parts: the input layer, several hidden layers and the output layer. Each of these layers contains a collection of nodes termed by perceptrons. There exist various implementations of NNs, and we use Keras [40] in this work. From the NNs built by Keras, PDFs as inputs are associated with either \u03c72 or physics quantities as outputs. The log-likelihood function \u03c72 quantifies agreements between theory predictions and experimental measurements for each data set and is calculated according to [12]. The physics quantities considered include cross sections of several benchmark processes at the LHC, and PDFs or their ratios at different Q values. An example of the architecture of our NNs is shown in figure 1, in which the inputs are PDFs at an initial scale and the outputs are the \u03c72 of the fit to an experimental data set. In this figure, the PDFs fi(x,Q) are evaluated at an initial scale of Q = 1.295GeV with x selected among 14 different values, and i \u2208 {g, u, d, u\u0304, d\u0304, s} runs over all parton flavors. We always assume s = s\u0304 at the initial scale. They altogether form the input layer with 84 nodes {I1, I2 . . . I84}. In addition, the differences in setups between NNs for different target functions are shown in table 1. The choice on the architecture is based on the observation that cross sections or evolved PDFs are in general non-linear functions of the PDF parameters. The \u03c72 is positive defined and is a sum of various individual terms that depend on cross sections quadratically, and thus can be approximated by a more complicated architecture as prescribed. We include more details on the construction of our NNs in appendix A.\n\u2013 4 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nTo construct the lth layer of a NN, we define\nb (l) i =  \u2211 j w (l) ij Ij , (l = 1),\n\u2211 j w (l) ij h (l\u22121) j , (l > 1),\n(2.1)\nwhere b(l)i is the value before the activation of the ith node in the lth layer, w (l) ij is the weight matrix connecting the (l \u2212 1)th layer to the lth layer, Ij is the value of the jth node in the input layer, and h(l\u22121)j is the value of the jth node in the (l \u2212 1)th layer. The value of the ith node in the lth layer is then obtained by applying the activation function t(l) on b(l)i :\nh (l) i = t(l) ( b (l) i ) . (2.2)\nThis procedure iterates over all hidden layers, and in the end we obtain a single value for the output layer. The activation functions used include the conventional choices of linear, and tanh types, as well as a customized one of quadratic form, depending on the target functions and layers. Note we constrain elements of the weight matrix of the output layer to be positive for the NN associated with the \u03c72 since it is positive definite. Elements in the weight matrix, w(l)ij , are trained to minimize the so-called loss function, which is defined as\ndloss = 1 n n\u2211 k=1 ( AkNN(wij)\u2212AkTR )2 , (2.3)\nwhere n is the total number of events in the training sample and AkTR and AkNN are the truth of the target function and the prediction from NNs for the kth event."
        },
        {
            "heading": "2.2 PDF parametrization form",
            "text": "The parametrization form of PDFs used at the initial scale Q0 is\nfi (x,Q0) = a0xa1\u22121(1\u2212 x)a2Pi (y; a3, a4, . . .) , (2.4)\nwhere {a1, a2, . . .} are free parameters, and the behavior of xa1 at x\u2192 0 and (1\u2212 x)a2 at x\u2192 1 is guided by Regge theory and spectator counting rules respectively. Pi (y; a3, a4, . . .) is a polynomial dependent on y \u2261 \u221a x (y \u2261 1 \u2212 (1 \u2212 \u221a x)a3) for valence quark and gluon PDFs (light-quark sea PDFs). Parametrization forms used here are the same as in the CT18 NNLO analysis [12].\nFor the valence-quark (uv and dv) PDF,\nfv (x,Q0) = a0xa1\u22121 (1\u2212 x)a2 Pv (y) , Pv (y) = sinh [a3] (1\u2212 y)4 + sinh [a4] 4y (1\u2212 y)3 + sinh [a5] 6y2 (1\u2212 y)2\n+ ( 1 + 12a1 ) 4y3(1\u2212 y) + y4. (2.5)\nFor the gluon PDF,\nfg (x,Q0) = a0xa1\u22121(1\u2212 x)a2Pg(y), Pg(y) = sinh [a3] (1\u2212 y)3 + sinh [a4] 3y(1\u2212 y)2 + (3 + 2a1)y2(1\u2212 y) + y3.\n(2.6)\n\u2013 5 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nFor the sea quark (u\u0304, d\u0304 and s \u2261 s\u0304) PDF,\nfq\u0304 (x,Q0) = a0xa1\u22121(1\u2212 x)a2Pq\u0304(y), Pq\u0304(y) = (1\u2212 y)5 + a45y(1\u2212 y)4 + a510y2(1\u2212 y)3 + a610y3(1\u2212 y)2\n+ a75y4(1\u2212 y) + a8y5. (2.7)\nIn all, we have 8 free parameters for valence quarks after applying the valence sum rules and letting a1 be equal for uv and dv. We have 15 free parameters for sea quarks after fixing some of those ai or letting them be equal for different flavors [12]. We are left with 5 free parameters for gluon after applying the momentum sum rule. The total number of free PDF parameters is 28."
        },
        {
            "heading": "2.3 Targets and samples",
            "text": "In this paper, we associated PDFs with \u03c72 and other physics quantities through our NNs. Details of these target functions are described in the following:\n\u2022 The individual \u03c72 of each data set in an NNLO global analysis of PDFs. We use the same 39 experimental data sets as in CT18 NNLO global analysis. These experimental data sets are summarized in table 2. The theoretical calculations used are explained in the CT18 paper [12]. We take those calculations from CT18 except for minor updates on NNLO K-factors of several data sets. The global \u03c72 is simply a sum of the 39 individual \u03c72.\n\u2022 The cross sections of Higgs boson pair (top-quark pair with a Higgs boson) production in proton-proton collisions at center of mass energy \u221a s = 13TeV or 100TeV. They\nare computed at leading (next-to-leading) order in QCD using MG5_aMC@NLO [41] and AMCfast [42] to provide an interface with APPLgrid [43]. We choose these two processes for demonstrations, and any scattering cross sections at hadron collisions can be included in a similar way.\n\u2022 The PDFs and PDF ratios at various x and Q values. They are obtained using HOPPET [44] with DGLAP evolutions at NNLO.\nWe first generate randomly a training sample consisting of 6000 replicas of PDFs and another test sample of 2000 replicas to prevent from over training. Details about the generation of the replicas of PDFs can be found in appendix A. We compute all the target functions (\u03c72 or physics quantities) for each of the replicas, which can be time consuming depending on whether the fast interpolation approaches, like APPLgrid or FastNLO, are used or not. However, we only need to perform these heavy calculations once for all. Afterwards we construct a NN for each of the target function considered with the architectures shown in table 1. We train each NN for about 10 hours, depending slightly on the architecture, on a single CPU-core (2.4 GHz) according to the loss function defined in eq. (2.3). Thus for all \u03c72 of the 39 individual data sets that takes about 390 core-hours in total for the training process. We found a very good performance of the\n\u2013 6 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nID Experimental data set Npt ID Experimental data set Npt 160 HERA I+II 1 fb \u22121, H1 and ZEUS\nNC and CC reduced cross section comb. [45] 1120 101 BCDMS F p 2 [46] 337\n102 BCDMS F d2 [47] 250 104 NMC F d2 /F p 2 [48] 123 108 CDHSW F p2 [49] 85 109 CDHSW xBF p 3 [49] 96 110 CCFR F p2 [50] 69 111 CCFR xBF p 3 [51] 86 124 NuTeV \u03bd\u00b5\u00b5 SIDIS [52] 38 125 NuTeV \u03bd\u0304\u00b5\u00b5 SIDIS [52] 33 126 CCFR \u03bd\u00b5\u00b5 SIDIS [53] 40 127 CCFR \u03bd\u0304\u00b5\u00b5 SIDIS [53] 38 145 H1 \u03c3br [54] 10 147 Combined HERA charm production [55] 47 169 H1 FL [56] 9 201 E605 Drell-Yan process [57] 119 203 E866 Drell-Yan process \u03c3pd/(2\u03c3pp) [58] 15 204 E866 Drell-Yan process Q3d2\u03c3pp/(dQdxF ) [59] 184 225 CDF Run-1 lepton Ach, pT l > 25GeV [60] 11 227 CDF Run-2 electron Ach, pT l > 25GeV [61] 11 234 D\u2205 Run-2 muon Ach, pT l > 20GeV [62] 9 260 D\u2205 Z rapidity [63] 28 261 CDF Run-2 Z rapidity [64] 29 266 CMS 7TeV 4.7 fb\u22121, moun Ach, pT l > 35GeV [65] 11 267 CMS 7TeV 840 fb\u22121, electron Ach, pT l > 35GeV [66] 11 268 ATLAS 7TeV 35 pb\u22121 W/Z cross section, Ach [67] 41 281 D\u2205 Run-2 9.7 fb\u22121 electron Ach, pT l > 25GeV [68] 13 504 CDF Run-2 inclusive jet production [69] 72 514 D\u2205 Run-2 inclusive jet production [70] 110 245 LHCb 7TeV 1.0 fb \u22121 W/Z\nforward rapidity cross section [71] 33\n246 LHCb 8TeV 2.0 fb \u22121 Z \u2192 e\u2212e+ forward rapidity cross section [72] 17 249 CMS 8TeV 18.8 fb\u22121 muon charge asymmetry Ach\n[73] 11\n250 LHCb 8TeV 2.0 fb\u22121 W/Z cross section [74] 34 253 ATLAS 8TeV 20.3 fb\u22121, Z pT cross section [75] 27 542 CMS 7TeV 5 fb \u22121, single incl.\njet cross section, R = 0.7 (extended in y) [76] 158 544 ATLAS 7TeV 4.5 fb\u22121, single incl. jet cross section, R = 0.6 [77] 140\n545 CMS 8TeV 19.7 fb \u22121, single incl. jet cross section, R = 0.7, (extended in y) [78] 185 573 CMS 8TeV 19.7 fb\u22121, tt\u0304 norm. double-diff. top pT and y cross section [79] 16 580 ATLAS 8TeV 20.3 fb \u22121,\ntt\u0304 ptT and mtt\u0304 abs. spectrum [80] 15\nTable 2. Experimental data sets involved in the global fit [12].\nresulting NNs without much tuning on the training process for all target functions studied, which will be reported in the next section. In a later stage for the evaluation of the target functions with arbitrary PDF parameters, we can simply use the optimized NNs rather than direct calculations. Comparison between computational cost of the NNs and the direct computations are summarized in appendix A where substantial improvements in the speed from the NNs are observed."
        },
        {
            "heading": "3 Validation of NNs",
            "text": "In this section, we perform several comparisons between the truths and the predictions from our NNs before we apply them to further phenomenological studies. We emphasize that the entire NN approach we discussed so far and in the following is bound to the CT18 parametrization form, especially with the CT18 PDF set. All PDF replicas for training and testing are sampled from the CT18 PDFs. A first attempt of generalization to other parametrization forms or even independent of PDF parametrization shows promising results, and is detailed in appendix A. It should be noted that the NNs should be retrained in general if the underlying PDF parametrization changes.\n\u2013 7 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8"
        },
        {
            "heading": "3.1 \u03c72 of the global fit",
            "text": "In figure 2, we show the predictions to truths ratios of \u03c72 for three experimental data sets: measurements of the proton structure function by BCDMS, measurements of inclusive DIS reduced cross sections at HERA and measurements of the inclusive jet cross sections at \u221a s = 7TeV by CMS. The ratio of total \u03c72 for the full data set is also shown in the lower-right panel. The ratios are calculated for the PDFs from the aforementioned training sample and test sample of NNs as well as the CT18 NNLO PDFs. The CT18 NNLO PDFs consist of a central PDF set and 56 error PDFs in a total of 28 Hessian eigenvector directions. The horizontal axis represents the truths of \u03c72. Each mark corresponds to a PDF set from these three samples of PDF sets. The green squares and the blue circles represent the ratios corresponding to the PDFs from the training sample and test sample respectively, and the purple triangles represent the ratios corresponding to the PDFs from CT18 NNLO. We find good agreement between the training and test samples, although the NN produces greater deviation than the original CT18 NNLO PDFs. We find that the predictions and the truths in general agree within 1 per mille for each data set. For the total \u03c72, the deviation is within 0.6 per mille. We define \u2206\u03c72 as the difference between a certain \u03c72 value and its value at the best fit, which is conventionally used in the determination of PDF uncertainties. In figure 3, differences between predicted and true \u2206\u03c72 denoted as \u03b4(\u2206\u03c72\u03b1) \u2261 \u2206\u03c72\u03b1,pre \u2212\u2206\u03c72\u03b1,tru are demonstrated for each data set, where \u03b1 represents the PDF set used in the comparison. Here we choose a sample of PDF sets consisting of the 56 Hessian error PDFs in CT18 NNLO set, which are represented by the marks distributed along the vertical direction. We also show similar results for the total \u03c72. It can be seen that, for each individual data set the \u03b4(\u2206\u03c72\u03b1) is at most 1 unit, and the \u03b4(\u2206\u03c72\u03b1) for the full data set are within 2 units. The extent of \u03b4(\u2206\u03c72\u03b1) for HERA inclusive DIS data set and for total \u03c72 is slightly larger than other experimental data sets. It should be noticed that the number of data points of HERA inclusive DIS data set and the full data set is 1120 and 3671 respectively. Besides, the \u2206\u03c72\u03b1 of the full data set for most of the 56 Hessian error PDFs is about 100 units. This indicates the relative deviation of NNs predictions is below 2% for \u2206\u03c72. Furthermore, we compare the \u2206\u03c72 for the full data set along the 28 eigenvector directions of CT18 NNLO PDFs by scans of PDF parameters. A variable d is introduced to measure the distance that PDF parameters go along the direction of a certain eigenvector. The variation of PDF parameters for the scan along the jth eigenvector direction can be written as:\naj,scani (d) =  d ( a2j\u22121i \u2212 a0i ) + a0i , (d > 0) ,\nd ( a0i \u2212 a 2j i ) + a0i , (d < 0) ,\n(3.1)\nwhere i represents the index of the PDF parameters, {a0i } represents PDF parameters for the central PDF of CT18 NNLO, {a2j\u22121i } and {a 2j i } represent PDF parameters of the two error PDFs in the jth eigenvector direction of CT18 NNLO. The total \u03c72 are computed using the new set of PDF parameters. We define \u2206\u03c72 \u2261 \u03c72(d)\u2212\u03c72(d = 0), and compare the\n\u2013 8 \u2013\n8\ntruths of \u2206\u03c72 and the predictions from NNs as a function of d for a few selected eigenvector directions in figure 4. We find that the NNs can describe well the dependence of the \u2206\u03c72 on PDF parameters in all Hessian eigenvector directions. The predictions and the truths in general agree within 2% in all directions, which agrees with figure 3. We also notice that \u2206\u03c72 has a sizable deviation from quadratic shape in some directions. The NNs can reproduce well the asymmetric and non-quadratic behavior of \u2206\u03c72, which is one of the main advantages as comparing to the traditional Hessian method. It is justified to say the deviation of \u03c72 due to the NNs approximation is negligible for the PDF parameter space of interest."
        },
        {
            "heading": "3.2 Physics quantities",
            "text": "In figure 5, we show the ratios of the predictions to the truths for the cross section of top-quark pair with a Higgs boson production in proton-proton collisions at a center of\n\u2013 9 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n24 5 24 6 24 9 25 0 25 3 54 2 54 4 54 5 57 3 58 0 16 0 10 1 10 2 10 4 10 8 10 9 11 0 11 1 12 4 12 5 12 6 12 7 14 5 14 7 16 9 20 1 20 3 20 4 22 5 22 7 23 4 26 0 26 1 26 6 26 7 26 8 28 1 50 4 51 4 to ta l Exp ID 1.0 0.5\n0.0\n0.5\n1.0\n1.5\n( 2 )\nFigure 3. The \u03b4(\u2206\u03c72\u03b1) corresponding to the 56 error PDFs of CT18 NNLO are represented by the 56 marks distributed along the vertical direction for each individual data set and for the full data set.\nmass energy \u221a s = 13TeV, and for the PDF ratio d/u(x = 0.3, Q = 100GeV). The ratios are calculated for the PDFs from the training sample and test sample of NNs as well as the CT18 NNLO PDFs. We find good agreements between the distributions of marks for training sample and for test sample. Deviations for these two physics quantities are in general within 0.15 per mille and 0.2 per mille, respectively. The performance of the NNs for these two physics quantities is better than that for \u03c72, which is because the dependence of \u03c72 on PDFs is more complex than the cases for cross sections or PDF ratios. The dependence of these physics quantities on PDFs is even close to linear.\nWe further summarize the relative difference between the predictions from NNs and the truths for various physics quantities in figure 6. For each physics quantity, 57 marks distributed along the vertical direction correspond to the results from the 57 CT18 NNLO PDFs. The results for the cross sections of Higgs boson pair production and top-quark pair with a Higgs boson production in proton-proton collisions at center of mass energy \u221a s = 13TeV or 100TeV are shown in this figure. We find the predictions from NNs and the truths for these cross sections agree within 0.2 per mille. In addition, the results for cross sections of pp\u2192 hh and pp\u2192 htt\u0304 with high invariant mass mhh > 2.5TeV or mhtt\u0304 > 2.5TeV are also shown in figure 6, and the relative difference between the predictions and truths in general agree within 0.3 per mille. Comparisons for strangeness ratio Rs \u2261\ns(x,Q) + s\u0304(x,Q) u\u0304(x,Q) + d\u0304(x,Q) and\nPDF ratios d/u and d\u0304/u\u0304 at various x and Q are also shown in this figure, and the predictions and the truths agree within 1 per mille. We also show the results for PDF values for g and s-quark at various x and Q, and the deviations between the predictions and the truths are within 0.75 per mille.\n\u2013 10 \u2013\n\u2013 11 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n(a) (b)\nFigure 5. The ratios of the predictions from NNs to the truths for the cross section of top-quark pair with a Higgs boson production in proton-proton collisions at a center of mass energy \u221a s = 13TeV and the PDF ratio d/u(x = 0.3, Q = 100GeV).\npp hh\n( s=\n13 Te V) pp hh ( s= 10 0T eV ) pp ht t( s= 13 Te V) pp ht t( s= 10 0T eV )\npp hh\n( s=\n13 Te\nV, m\nhh >2\n.5 Te V) pp hh ( s= 10 0T eV ,m hh >2 .5 Te V) pp ht t( s= 13 Te V, m ht t> 2. 5T eV ) pp ht t( s= 10 0T eV ,m ht t> 2. 5T eV ) R s (x =0 .0 23 ,Q =1 .5 Ge V) R s (x =0 .1 ,Q =1 .5 Ge V) d/ u( x= 0. 00 2, Q= 10 0G eV ) d/ u( x= 0. 3, Q= 10 0G eV ) d/ u( x= 0. 00 2, Q= 10 0G eV ) d/ u( x= 0. 3, Q= 10 0G eV ) g( x= 0. 01 ,Q =1 25 Ge V) g( x= 0. 3, Q= 12 5G eV ) s( x= 0. 00 2, Q= 10 0G eV ) s( x= 0. 3, Q= 10 0G eV )\n0.00075\n0.00050\n0.00025\n0.00000\n0.00025\n0.00050\n0.00075\n0.00100\n(p re\ndi ct\nio n\ntr ut\nh) /tr\nut h\nFigure 6. The relative difference between the predictions from NNs and the truths for various physics quantities. For each physics quantity, 57 marks distributed along the vertical direction correspond to the results from 57 PDFs of CT18 NNLO.\n\u2013 12 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8"
        },
        {
            "heading": "4 Lagrange Multiplier scans",
            "text": "LM scan is a robust method to estimate PDF uncertainties, which was originally developed in refs. [23, 24]. In this method a physics quantity X({ai}) is introduced to the global fit as a Lagrange multiplier. Then the new function that needs to be minimized in the global fit becomes\n\u03a8 (\u03bb, {ai}) \u2261 \u03c72 ({ai}) + \u03bbX ({ai}) , (4.1)\nwhere \u03bb is a specified constant. For each value of \u03bb, one can determine a set of {ai}, X({ai}) and \u03c72 by minimizing \u03a8. Here the \u03c72 corresponds to the minimum of a constrained fit with X{ai} fixed to the corresponding value. Specially, the central value of X({ai}) and the global minimum of \u03c72, \u03c72min, can be determined by setting \u03bb = 0. A parametrically defined curve (X, \u03c72) can be determined by repeating the minimization for many values of \u03bb. This means the \u03c72 of the global fit depends on the value of X({ai}) and can be represented as \u03c72 = \u03c72min + \u2206\u03c72. The PDF uncertainty of X({ai}) can be determined by requiring \u2206\u03c72 + P = T , here T is the so-called \u201ctolerance factor\u201d. We assume that 90% CL region corresponds to T = 100. The penalty term P , called Tier-2 penalty, is introduced to ensure the tolerance will be reached as soon as any data set shows disagreement at 90% CL. The detailed definition of the penalty term can be found in refs. [1, 81]. In comparison, we briefly describe the calculation of PDF uncertainties in the framework of the Hessian method. Given the physics quantity X({ai}), the asymmetric PDF uncertainties can be calculated as [82]\n\u03b4+X = \u221a\u2211Nd\ni=1 [max (X2i\u22121 \u2212X0, X2i \u2212X0, 0)] 2,\n\u03b4\u2212X = \u221a\u2211Nd\ni=1 [max (X0 \u2212X2i\u22121, X0 \u2212X2i, 0)] 2,\n(4.2)\nwhere X0 represents the value of the physics quantity with the central PDF of the Hessian set, X2i\u22121 (X2i) represents the value of the physics quantity with the error PDF of the Hessian set in the positive (negative) direction of the ith eigenvector in the Nd-dimensional PDF parameter space."
        },
        {
            "heading": "4.1 LM scans on PDFs",
            "text": "We first study PDF values and ratios with LM scans based on the aforementioned NNs approximation of \u03c72 and physics quantities. The results are shown in figure 7. The black and the red solid lines represent \u2206\u03c72 and \u2206\u03c72 +P respectively. The dot and the dash lines indicate the contributions to \u2206\u03c72 from individual data sets. The blue and the green vertical dot-dash lines indicate the uncertainties at 90% CL determined with the LM method by requiring \u2206\u03c72 + P = 100 and with the Hessian method from the published CT18 NNLO PDFs, respectively. Among the generic features of the scans, it can be seen that the profile of the total \u2206\u03c72 and individual \u2206\u03c72 show almost a quadratic dependence on the variable at the neighborhood of the global minimum, which is a requirement of the Hessian method. Some individual data sets prefer PDF values or ratios that differ significantly from those at the global minimum. Besides, the HERA inclusive DIS data play important roles in all\n\u2013 13 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n760 780 800 820 840 g(x=0.01, Q=125GeV)\n20\n0\n20\n40\n60\n80 100 2\ntotal total+p 250LHCb8 W/Z 253ATLAS8 Zpt 542CMS7 jet 544ATLAS7 jet 545CMS8 jet 573CMS8 tt 160HEAR I+II 102BCDMS F2d 110CCFR F2 125NuTeV nub 147HERA charm 204E866pp 504CDF2 jet 514D0 2 jet Unc.[90% CL, LM] Unc.[90% CL, CT18]\n(a)\n0.01 0.02 0.03 s(x=0.3, Q=100GeV)\n20\n0\n20\n40\n60\n80\n100\n2\ntotal total+p 245LHCb7 W/Z 250LHCb8 W/Z 545CMS8 jet 160HEAR I+II 108CDHSW F2p 109CDHSW F3p 111CCFR F3 124NuTeV nu 125NuTeV nub 126CCFR nu 127CCFR nub 204E866pp Unc.[90% CL, LM] Unc.[90% CL, CT18]\n(b)\n0.34 0.36 0.38 0.40 d/u(x=0.3, Q=100GeV)\n20\n0\n20\n40\n60\n80\n100\n2\ntotal total+p 245LHCb7 W/Z 249CMS8 Ach 250LHCb8 W/Z 160HEAR I+II 101BCDMS F2p 102BCDMS F2d 104NMC F2d/F2p 281D0 2 e Unc.[90% CL, LM] Unc.[90% CL, CT18]\n(c)\n0.2 0.4 0.6 0.8 1.0 Rs(x=0.023, Q=1.5GeV)\n20\n0\n20\n40\n60\n80\n100\n2\ntotal total+p 250LHCb8 W/Z 160HEAR I+II 110CCFR F2 124NuTeV nu 125NuTeV nub 126CCFR nu 127CCFR nub 204E866pp Unc.[90% CL, LM] Unc.[90% CL, CT18]\n(d)\nFigure 7. LM scans on the g (x = 0.01GeV, Q = 125GeV), s (x = 0.3, Q = 100GeV), d/u (x = 0.3, Q = 100GeV) and Rs (x = 0.023, Q = 1.5GeV). The black and the red solid lines represent \u2206\u03c72 and \u2206\u03c72 + P respectively. The dot and the dash lines indicate the contributions to \u2206\u03c72 from individual data sets. The blue and the green vertical dot-dash lines indicate the uncertainties at 90% CL determined with the LM method by requiring \u2206\u03c72 +P = 100 and with the Hessian method from the published CT18 NNLO PDFs, respectively.\ncases, which can be understood as due to the high experimental precision and the large number of data points. The penalty term also gives strong constraints on some PDF values or ratios. In addition, there are some slight differences between the uncertainties determined with the Hessian method and the LM scans, which is expected.\nIn the upper-left panel of figure 7, we show the results of LM scans on the gluon PDF at Q = 125GeV and x = 0.01. We find that the HERA inclusive DIS data and the LHC jet data give the leading constraints. In addition, the CDF inclusive jet data (Exp. ID = 504) prefers a smaller value of the gluon PDF. At the global minimum, the \u03c72 for the CDF inclusive jet data is elevated by about 20 units. The Hessian method gives a smaller PDF uncertainty than the estimation based on the LM scans.\nIn the upper-right panel, we show the results of LM scans on the s-quark PDF at Q = 100GeV and x = 0.3. In this panel, the NuTeV and the CCFR dimuon data together with the HERA inclusive DIS data give the dominant constraints. These experimental\n\u2013 14 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\ndata are consistent with the global fit. A marked deviation from the quadratic shape can be observed in the profile of the \u2206\u03c72. In this case, a notable difference in uncertainties manifests between the LM method and the Hessian method, and the LM method should give the more reliable result.\nIn the bottom-left panel of figure 7, we show the results of LM scans on the PDF ratio d/u at Q = 100GeV and x = 0.3. The d/u ratio is dominantly constrained by the LHCb W and Z boson production and the fixed target experiments BCDMS and NMC. Contrasted with previous situations, the LM method gives a smaller PDF uncertainty for the d/u ratio.\nIn the bottom-right panel, we show the results of LM scans on the strangeness ratio Rs at Q = 1.5GeV and x = 0.023. We find that the NuTeV and the CCFR dimuon data and HERA inclusive DIS data give the dominant constraints. It is also worthy noting that the NuTeV dimuon data with anti-neutrinos (Exp. ID = 125) prefers Rs \u2248 0.25 which is smaller than the best fit value from the global fit Rs = 0.52 and results in a large penalty term. At the global minimum, the \u03c72 for the NuTeV dimuon data with anti-neutrinos is elevated by about 7 units. The LM method predicts Rs = 0.52+0.35\u22120.36 at 90% CL that has smaller uncertainties than Rs = 0.52+0.39\u22120.41 from the Hessian method. Above scans have also been performed in the CT18 analysis [12], and our results are consistent with those, which further proves the validity of our approach. After demonstrating the great efficiency and validity of our approach on LM scans, we are now ready to perform a systematic study on the PDF values and ratios for all flavors at a series of x values spreading over a wide range.\nIn figure 8, we compare the PDF uncertainties at 68% CL at Q = 1.295GeV between the LM method and the Hessian uncertainties from the CT18 NNLO PDFs. The blue and the red solid lines represent the central values of the CT18 NNLO and the PDFs determined with the aforementioned NNs approximation of \u03c72 respectively. The blue and the red hatched areas represent the uncertainties determined with the Hessian method and the LM method respectively. The results are normalized to the central value of CT18 NNLO PDFs. We find good agreements of both the uncertainties and the central values between the two methods. A notable difference, however, can be seen for u, d, u\u0304, d\u0304 and s-quark at small-x (. 10\u22124), as well as for d, u\u0304 and s-quark at large-x (& 0.4). This indicates a failure of the quadratic approximation in these regions. The uncertainties from the LM method can be either larger or smaller than the uncertainties from the Hessian method depending on the flavor and the x value.\nIn the lower-right panel, we find that s-quark PDFs have large uncertainties for both x . 0.001 and x & 0.4. This is because the large-x and small-x behavior of the s-quark are mostly constrained by the extrapolation of the PDF parametrization. The error band of s-quark of CT18 NNLO PDFs covers negative PDF values at x & 0.4. This unphysical behavior implies a limitation of the Hessian method. On the contrary, the error band determined with the LM method is bounded above zero in all regions.\nWe also perform the LM scans on the general PDF ratios that is defined as\nRf \u2261 fi(x1, Q) fj(x2, Q) . (4.3)\n\u2013 15 \u2013\n\u2013 16 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\ng u u d d s fi(x1, Q)\ng\nu\nu\nd\nd\ns\nf j( x 2\n,Q )\nRelative unc. of fi(x1, Q)/fj(x2, Q) at 90% CL [CT18]\nQ = 1.295 GeV\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(a) Hessian\ng u u d d s fi(x1, Q)\ng\nu\nu\nd\nd\ns\nf j( x 2\n,Q )\nRelative unc. of fi(x1, Q)/fj(x2, Q) by LM at 90% CL\nQ = 1.295 GeV\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(b) LM\nFigure 9. The relative uncertainties of Rf = fi(x1, Q)/fj(x2, Q) determined with the Hessian method and the LM method at 90% CL are shown in panel (a) and (b) respectively. The color code represents the relative uncertainties of the ratio Rf . The relative uncertainties are calculated at Q = 1.295GeV with x1 and x2 selected among 12 values from 3\u00d710\u22125 to 0.6 listed in table 3, and i, j \u2208 {g, u, u\u0304, d, d\u0304, s} runs over all parton flavors.\nThe relative uncertainties of Rf are calculated at Q = 1.295GeV with x1 and x2 selected among 12 values from 3\u00d710\u22125 to 0.6 listed in table 3, and i, j \u2208 {g, u, u\u0304, d, d\u0304, s} runs over all parton flavors. The results at 90% CL are shown in figure 9(a) and (b) for the Hessian and LM method respectively. The x and the y axis indicate the numerator and the denominator, and color code represents the relative uncertainties of the ratio Rf . By comparison of the two panels, we find good agreements between the uncertainties determined with the LM method and the Hessian method in most regions. Similar to figure 8, there are notable differences at small-x1, especially for those with sea quarks in the numerator."
        },
        {
            "heading": "4.2 LM scans on cross sections",
            "text": "Higgs bosons are produced dominantly through gluon fusions at the LHC. The inclusive gluon-fusion cross-section has been calculated to next-to-next-to-next-to-leading order in QCD [83], which further reduces the scale variations and makes the PDF uncertainties even more important. Besides, the production of Higgs boson pair and top-quark pair associated with a Higgs boson are of equal importance for studies of the Higgs boson self-coupling and the top-quark Yukawa coupling.\n\u2013 17 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n0.0125 0.0130 0.0135 (pp hh @13TeV)(pb)\n20\n0\n20\n40\n60\n80\n100 120 2\ntotal total+p 253ATLAS8 Zpt 545CMS8 jet 160HEAR I+II 101BCDMS F2p 102BCDMS F2d 108CDHSW F2p 110CCFR F2 Unc.[90% CL, LM] Unc.[90% CL, CT18]\n(a)\n0.62 0.63 0.64 0.65 (pp hh @100TeV)(pb)\n20\n0\n20\n40\n60\n80\n100\n120\n2\ntotal total+p 253ATLAS8 Zpt 160HEAR I+II 101BCDMS F2p 102BCDMS F2d 108CDHSW F2p 110CCFR F2 124NuTeV nu 125NuTeV nub 126CCFR nu 268ATLAS7 W/Z 504CDF2 jet Unc.[90% CL, LM] Unc.[90% CL, CT18]\n(b)\n0.44 0.45 0.46 0.47 0.48 (pp htt @13TeV)(pb)\n20\n0\n20\n40\n60\n80\n100\n120\n2\ntotal total+p 253ATLAS8 Zpt 545CMS8 jet 160HEAR I+II 101BCDMS F2p 102BCDMS F2d 124NuTeV nu 204E866pp Unc.[90% CL, LM] Unc.[90% CL, CT18]\n(c)\n30.5 31.0 31.5 32.0 (pp htt @100TeV)(pb)\n20\n0\n20\n40\n60\n80\n100\n120\n2\ntotal total+p 545CMS8 jet 160HEAR I+II 102BCDMS F2d 124NuTeV nu 125NuTeV nub 204E866pp 504CDF2 jet Unc.[90% CL, LM] Unc.[90% CL, CT18]\n(d)\nFigure 10. LM scans on the \u03c3pp\u2192hh and \u03c3pp\u2192htt\u0304 at \u221a s = 13TeV or 100TeV.\nIn figure 10 we show the results of LM scans on \u03c3pp\u2192hh and \u03c3pp\u2192htt\u0304 at \u221a s = 13TeV or\n100TeV. For \u03c3pp\u2192hh at \u221a s = 13TeV, in the upper-left panel, the behaviors of \u03c72 are very much similar to that shown in the upper-left panel of figure 7 for the gluon PDF. That is because the cross section of pp\u2192 hh at 13TeV is strongly correlated with the gluon PDF at x \u223c 0.02. Constraints from HERA inclusive DIS data, BCDMS proton and deuterium data, CMS 8TeV jet data and ATLAS 8TeV Z pT data stand out as expected. In addition, the BCDMS proton data and ATLAS 8TeV Z pT data both prefer a larger cross section contrasted with the BCDMS deuterium data which prefers a smaller value. For \u03c3pp\u2192hh at\u221a s = 100TeV, in the upper-right panel, the constraints are distributed among more data sets and are related to PDFs at small-x.\nThe cross section of pp\u2192 htt\u0304 mainly depends on the gluon, u-quark and d-quark PDFs. For \u03c3pp\u2192htt\u0304 at \u221a s = 13TeV, in the lower-left panel of figure 10, similar behaviors of the \u03c72 as \u03c3pp\u2192hh are observed. At \u221a s = 100TeV, the constraints from HERA inclusive DIS data predominate. In addition, constraints from NuTeV dimuon data, CMS jet data and BCDMS proton data also play important roles.\n\u2013 18 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n10 1 10 2 10 4 10 8 10 9 11 0 11 1 12 4 12 5 12 6 12 7 14 5 14 7 16 0 16 9 20 1 20 3 20 4 22 5 22 7 23 4 24 5 24 6 24 9 25 0 25 3 26 0 26 1 26 6 26 7 26 8 28 1 50 4 51 4 54 2 54 4 54 5 57 3 58 0 Exp ID 0.50 0.25 0.00\n0.25\n0.50\n0.75\n1.00\n1.25 1.50 R s (x =0 .0 23 ,Q =1 .5 Ge V)\nCentral value of NNs Unc. at 90% CL (CT18) Unc. by LM at 90% CL (baseline) Unc. by LM at 90% CL (with data subtracted)\nFigure 11. The results of LM scans on the Rs (x = 0.023, Q = 1.5GeV) with data subtracted. The horizontal axis represents the experimental data set removed from the LM scans. The blue mark and the red error bar respectively indicate the central value and uncertainties at 90% CL determined with the LM method with the rest of the data sets. The green hatched area and the gray band represent the uncertainties at 90% CL determined with the Hessian method and the LM method with the full data set respectively."
        },
        {
            "heading": "4.3 Study on impact of individual data sets",
            "text": "In order to assess the contribution from an individual experimental data set, we remove one data set at a time, and repeat the LM scans on physics quantities with the rest of the data sets. Difference between the fit with and without the data set can be an assessment of its contribution.\nThe results for Rs at x = 0.023 and Q = 1.5GeV are shown in figure 11. After the removal of each data set, we find that Rs value and its uncertainty are only changed slightly, as represented by those error bars comparing to the uncertainty from LM scans with the full data set represented by the gray band. The subtraction of a single data set shows largest effects for NuTeV dimuon production data (Exp. ID = 124, 125), CCFR dimuon production data (Exp. ID = 126, 127), E866 Drell-Yan data (Exp. ID = 204) and HERA inclusive DIS data (Exp. ID = 160). In addition, the NuTeV dimuon production data and HERA inclusive DIS data prefer a smaller Rs contrasted with E866 Drell-Yan data which prefers a larger value, that is consistent with the bottom-right panel of figure 7.\nIn figure 12 we show the results for d\u0304/u\u0304 at x = 0.3 and Q = 100GeV. The E866 Drell-Yan ratio data (Exp. ID = 203) gives the dominant constraints. The fit without E866 Drell-Yan ratio data predicts a result of d\u0304/u\u0304 = 1.26+0.82\u22120.59, while the fit with the full data set expects d\u0304/u\u0304 = 1.28+0.20\u22120.33. After the inclusion of E866 Drell-Yan ratio data, the uncertainties of d\u0304/u\u0304 are reduced by almost 60%. That is because the penalty term of E866 Drell-Yan ratio data provides a strong constraint on d\u0304/u\u0304. In addition, constraints from NMC deuteron data (Exp. ID = 104) and HERA inclusive DIS data also play important roles.\n\u2013 19 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n10 1 10 2 10 4 10 8 10 9 11 0 11 1 12 4 12 5 12 6 12 7 14 5 14 7 16 0 16 9 20 1 20 3 20 4 22 5 22 7 23 4 24 5 24 6 24 9 25 0 25 3 26 0 26 1 26 6 26 7 26 8 28 1 50 4 51 4 54 2 54 4 54 5 57 3 58 0 Exp ID 0.8 1.0\n1.2\n1.4\n1.6\n1.8 2.0 d/ u (x =0 .3 ,Q =1 00 Ge V) Central value of NNs Unc. at 90% CL (CT18) Unc. by LM at 90% CL (baseline) Unc. by LM at 90% CL (with data subtracted)\nFigure 12. The same as figure 11, but for the results of LM scans on the d\u0304/u\u0304 (x = 0.3 and Q = 100GeV).\nIn figure 13 we show the results for \u03c3pp\u2192hh at \u221a s = 13TeV. The constraints from\nHERA inclusive DIS data predominate as expected. In addition to that, constraints from BCDMS proton and deuterium data (Exp. ID = 101, 102) and ATLAS 8TeV Z pT data (Exp. ID = 253) also play important roles. The fit without HERA inclusive DIS data expects \u03c3pp\u2192hh = 0.0129+0.0007\u22120.0009 pb, while the fit with the full data set gives \u03c3pp\u2192hh = 0.0131+0.0005\u22120.0007 pb. An upward shift of about 2 \u00d7 10\u22124 pb is observed when we incorporate HERA inclusive DIS data, and the uncertainties of \u03c3pp\u2192hh are reduced by almost 20%. In addition, the HERA inclusive DIS data and BCDMS deuterium data both prefer a larger \u03c3pp\u2192hh contrasted with BCDMS proton data and ATLAS Z pT data which prefer a smaller value, that is consistent with the upper-left panel of figure 10."
        },
        {
            "heading": "4.4 Two-dimensional LM scans",
            "text": "Besides the PDF uncertainties, it is possible to quantify other statistical estimators such as the correlation between two physics quantities with two-dimensional LM (2-D LM) scans. That can be achieved by adding a second physics quantity into eq. (4.1). The new function that needs to minimized in the global fit becomes\n\u03a8 (\u03bb1, \u03bb2, {ai}) \u2261 \u03c72 ({ai}) + \u03bb1X1 ({ai}) + \u03bb2X2 ({ai}) , (4.4)\nwhere \u03bb1 and \u03bb2 are specified constants, and X1({ai}) and X2({ai}) represent the two physics quantities of interest. Similar to eq. (4.1), the constrained minimum of \u03c72 from the global fit depends on X1 and X2, and can be written as \u03c72 = \u03c72min + \u2206\u03c72, where \u03c72min = \u03c72(\u03bb1 = 0, \u03bb2 = 0). The contour of \u2206\u03c72 + P in the plane of X1 vs. X2 can be an assessment of the correlation between X1 and X2. As examples in figure 14 we show contours for d\u0304/u\u0304 (x = 0.3, Q = 100GeV) vs. Rs (x = 0.023, Q = 1.5GeV) and \u03c3pp\u2192hh ( \u221a s = 13TeV) vs. \u03c3pp\u2192hh ( \u221a s = 100TeV) determined\n\u2013 20 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n10 1 10 2 10 4 10 8 10 9 11 0 11 1 12 4 12 5 12 6 12 7 14 5 14 7 16 0 16 9 20 1 20 3 20 4 22 5 22 7 23 4 24 5 24 6 24 9 25 0 25 3 26 0 26 1 26 6 26 7 26 8 28 1 50 4 51 4 54 2 54 4 54 5 57 3 58 0 Exp ID 0.0120 0.0125\n0.0130\n0.0135\n0.0140 0.0145 (p p hh @ s= 13 Te V) (p\nb) Central value of NNs Unc. at 90% CL (CT18) Unc. by LM at 90% CL (baseline) Unc. by LM at 90% CL (with data subtracted)\nFigure 13. The same as figure 11, but for the results of LM scans on the \u03c3pp\u2192hh at \u221a s = 13TeV.\n0.0 0.2 0.4 0.6 0.8 1.0 Rs(x=0.023, Q=1.5GeV)\n0.8\n0.9\n1.0\n1.1\n1.2\n1.3\n1.4\n1.5\n1.6\nd/ u\n(x =0\n.3 ,Q\n=1 00\nGe V)\n2 + P = 10 2 + P = 30 2 + P = 100\n(a)\n0.0125 0.0130 0.0135 0.0140 (pp hh s=13TeV)(pb)\n0.620\n0.625\n0.630\n0.635\n0.640\n0.645\n0.650\n(p p\nhh\ns = 10\n0T eV\n)(p b)\n2 + P = 10 2 + P = 30 2 + P = 100\n(b)\nFigure 14. Contour plot of \u2206\u03c72 plus Tier-2 penalty term on the plane of d\u0304/u\u0304 (x = 0.3, Q = 100GeV) vs. Rs (x = 0.023, Q = 1.5GeV) and \u03c3pp\u2192hh ( \u221a s = 13TeV) vs. \u03c3pp\u2192hh ( \u221a s = 100TeV).\nwith the 2-D LM scans. In the left panel, a weak correlation between strangeness ratio Rs and u\u0304/d\u0304 ratio is observed. That is because the two quantities are dominantly constrained by different experimental data sets. At small \u2206\u03c72 + P the contour shows an elliptic shape. When \u2206\u03c72 + P gets larger, the shape of the contour becomes irregular due to the increase of penalty term contributions. On the contrary, the right panel demonstrates a strong correlation between \u03c3pp\u2192hh ( \u221a s = 13TeV) and \u03c3pp\u2192hh ( \u221a s = 100TeV) since both processes are sensitive to gluon PDFs and constrained by the relevant experimental data sets.\n\u2013 21 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8"
        },
        {
            "heading": "5 Applications",
            "text": "In this section, we evaluate the impact of the NOMAD measurements and of two pseudo-data sets of HL-LHC on PDFs based on the new approach. In addition, we study constraints on the new physics with a joint fit of both PDFs and the Wilson coefficient of lepton-quark contact interactions in the framework of the SMEFT."
        },
        {
            "heading": "5.1 Constraint from NOMAD data",
            "text": "The charm-quark production in CCDIS process provides a unique sensitivity to the strangequark distribution in the nucleon, with a clean signal of two muons with opposite charges in the final state. Recently, NOMAD collaboration reported a measurement of dimuon production in the neutrino-iron scattering experiment [31]. A sample of about 9 \u00d7 106 inclusive CCDIS events, including 15344 dimuon events, is collected, providing a reduced statistical uncertainty. Observables are taken to be the ratios of dimuon to inclusive cross-sections, which provides a large cancellation of the common systematic uncertainties presented in both the numerator and the denominator. Final results are distributed among three differential variables: the reconstructed neutrino energy E\u03bd , the Bjorken x and the partonic center of mass energy \u221a s\u0302. By the supplement of data from NOMAD, the improvement in the constraint on s-quark PDFs are studied in this section using the same NNs approach on \u03c72 mentioned in previous sections. On the theoretical side, structure functions in S-ACOT-\u03c7 general mass scheme up to NNLO are constructed, so that a full consideration of the charm-quark mass is included [84\u2013 86]. Predictions of inclusive CCDIS and open charm production cross-sections are made from these constructions, and dimuon cross sections are derived by further applying the inclusive decay branching ratio of charm quark to muon. The significant uncertainties of the decay branching ratio contribute as one of the dominant systematic errors on the dimuon cross sections, which are summarized in appendix C. In figure 15 we show comparison of NOMAD data and our predictions at both NLO and NNLO, as well as the Hessian PDF uncertainties at 68% CL for distributions over E\u03bd or x. The PDF uncertainties can be as large as 10% in most regions. This directly comes from the large uncertainties of the predictions of dimuon cross-sections, and can be further traced back to the poor knowledge about s-quark PDFs. In both distributions, most of the data points are consistent with our predictions, while a significant deviation can be found in the last two points of the distribution over Bjorken x. That can be due to the modeling of heavy nuclear corrections used in the experimental analysis. We will discard those two data points when including NOMAD data in our later global fit. It is also noted that the inclusion of NOMAD data to the global fit can improve the consistency with almost no cost of tension with the other data sets [87, 88]. Most of the data lie above our NLO predictions of central values. Given this fact, an increased s-quark PDF is expected after the inclusion of NOMAD data, and this increase gets larger due to the negative corrections from NNLO. As mentioned earlier, NOMAD presents measurements on three distributions. The different sensitivities of distributions over E\u03bd or x are illustrated in figure 16. It shows the PDF induced correlations among bins of each distributions calculated with CT18 NNLO\n\u2013 22 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n50 100 150 200 E /GeV 0.003 0.004\n0.005\n0.006\n0.007\n0.008\n0.009\n0.010\n/ in\nc\nNLO central NNLO central PDF Unc. at 68% CL Stat error Stat+Sys error\n(a)\n0.0 0.1 0.2 0.3 0.4 0.5 0.6 x\n0.002\n0.004\n0.006\n0.008\n0.010\n0.012\n0.014\n/ in\nc\nNLO central NNLO central PDF Unc. at 68% CL Stat error Stat+Sys error\n(b)\nFigure 15. NLO (blue line) and NNLO (red line) predictions for ratios of dimuon to CCDIS inclusive differential cross-sections with respect to neutrino energy (panel a) and Bjorken x (panel. b). The blue hatched areas represent the Hessian PDF uncertainties of the NLO predictions at 68% CL. NOMAD data are also shown with statistical uncertainties and the combination of both statistical and systematic uncertainties.\nPDF correlation for E (GeV)\n1 5\n.9 1\n2 4\n.3 8\n2 8\n.8 5\n3 2\n.8 8\n3 7\n.3 1\n4 1\n.7 8\n4 6\n.2 3\n5 1\n.1 7\n5 6\n.7 3\n6 2\n.8 7\n6 9\n.7 0\n7 7\n.2 9\n8 5\n.7 8\n9 5\n.0 1\n1 0\n5 .4\n1 1\n7 .6\n1 3\n3 .0\n1 5\n5 .4\n2 0\n5 .5\n15.91 24.38 28.85 32.88 37.31 41.78 46.23 51.17 56.73 62.87 69.70 77.29 85.78 95.01 105.4 117.6 133.0 155.4 205.5\n1.00\n0.98\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.99\n0.98\n0.98\n0.98\n0.98\n0.97\n0.97\n0.97\n0.96\n0.96\n0.98\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.99\n0.98\n0.98\n0.98\n0.98\n0.97\n0.97\n0.96\n0.97\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.99\n0.99\n0.98\n0.98\n0.98\n0.97\n0.96\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.99\n0.99\n0.98\n0.98\n0.97\n0.96\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.99\n0.99\n0.98\n0.98\n0.95\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.99\n0.98\n0.95\n0.98\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.98\n0.95\n0.98\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.94\n0.98\n0.98\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.94\n0.97\n0.98\n0.99\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.99\n0.93\n0.97\n0.98\n0.98\n0.99\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.93\n0.97\n0.98\n0.98\n0.99\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.93\n0.96\n0.97\n0.98\n0.99\n0.99\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.92\n0.96\n0.97\n0.98\n0.98\n0.99\n0.99\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.92\n0.96\n0.97\n0.97\n0.98\n0.98\n0.99\n0.99\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.92\n0.95\n0.96\n0.97\n0.98\n0.98\n0.98\n0.99\n0.99\n0.99\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.91\n0.95\n0.96\n0.96\n0.97\n0.97\n0.98\n0.98\n0.98\n0.99\n0.99\n0.99\n0.99\n0.99\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n0.99\n0.98\n0.98\n0.97\n0.96\n0.96\n0.95\n0.95\n0.95\n0.94\n0.94\n0.93\n0.93\n0.93\n0.92\n0.92\n0.92\n0.91\n0.99\n1.00\n1.00\n1.00\n0.99\n0.99\n0.99\n0.99\n0.98\n0.98\n0.98\n0.97\n0.97\n0.97\n0.96\n0.96\n0.96\n0.95\n0.95\n(a)\nPDF correlation for x\n0 .0\n2 6 7\n0 .0\n4 4 0\n0 .0\n5 9 8\n0 .0\n7 5 6\n0 .0\n9 1 7\n0 .1\n1 2 2\n0 .1\n3 8 9\n0 .1\n6 9 9\n0 .2\n0 6 6\n0 .2\n5 2 4\n0 .3\n1 6 5\n0 .4\n0 3 6\n0 .5\n1 1 6\n0 .6\n4 6 5\n0.0267\n0.0440\n0.0598\n0.0756\n0.0917\n0.1122\n0.1389\n0.1699\n0.2066\n0.2524\n0.3165\n0.4036\n0.5116\n0.6465\n0.64\n0.82\n0.96\n1.00\n0.98\n0.93\n0.86\n0.78\n0.69\n0.59\n0.48\n0.37\n0.26\n0.15\n0.02\n0.72\n0.89\n0.98\n1.00\n0.99\n0.94\n0.87\n0.78\n0.66\n0.52\n0.37\n0.23\n0.10\n-0.03\n0.65\n0.81\n0.93\n0.99\n1.00\n0.99\n0.93\n0.85\n0.73\n0.58\n0.41\n0.26\n0.10\n-0.05\n0.60\n0.74\n0.86\n0.94\n0.99\n1.00\n0.98\n0.92\n0.81\n0.67\n0.50\n0.34\n0.17\n-0.04\n0.58\n0.67\n0.78\n0.87\n0.93\n0.98\n1.00\n0.98\n0.90\n0.79\n0.64\n0.48\n0.31\n0.00\n0.57\n0.61\n0.69\n0.78\n0.85\n0.92\n0.98\n1.00\n0.97\n0.90\n0.78\n0.65\n0.47\n0.07\n0.57\n0.55\n0.59\n0.66\n0.73\n0.81\n0.90\n0.97\n1.00\n0.97\n0.90\n0.80\n0.63\n0.14\n0.57\n0.50\n0.48\n0.52\n0.58\n0.67\n0.79\n0.90\n0.97\n1.00\n0.97\n0.91\n0.77\n0.21\n0.54\n0.43\n0.37\n0.37\n0.41\n0.50\n0.78\n0.90\n0.97\n1.00\n0.98\n0.87\n0.28\n0.51\n0.37\n0.26\n0.23\n0.26\n0.34\n0.48\n0.65\n0.80\n0.91\n0.98\n1.00\n0.94\n0.38\n0.45\n0.28\n0.15\n0.10\n0.10\n0.17\n0.31\n0.47\n0.63\n0.77\n0.87\n0.94\n1.00\n0.63\n0.18\n0.11\n0.02\n-0.03\n-0.05\n-0.04\n0.00\n0.07\n0.14\n0.21\n0.28\n0.38\n0.63\n1.00\n1.00\n0.92\n0.82\n0.72\n0.65\n0.60\n0.58\n0.57\n0.57\n0.57\n0.54\n0.51\n0.45\n0.18\n0.92\n1.00\n0.96\n0.89\n0.81\n0.74\n0.67\n0.61\n0.55\n0.50\n0.43\n0.37\n0.28\n0.11\n(b)\nFigure 16. PDF induced correlations between theory predictions for different experimental bins, for NOMAD distribution in neutrino energy (a) and in Bjorken-x (b), calculated with CT18 NNLO Hessian PDF set. Numbers in the axis represent the center of each bin, and numbers in the table represent the correlation cosine for each pair of bins.\n\u2013 23 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nHessian PDFs. We find that for E\u03bd distribution, all data points are strongly correlated, and similar results are found for \u221a s\u0302 distribution which is not shown here. Both of them only impose constraints on the overall normalization of the s-quark distribution. Thus their constraints are diluted due to the systematic errors on the inclusive branching ratio of charm quark to muon (0.094\u00b10.01). On the other hand, the correlation pattern is nontrivial for x distribution which imposes further constraints on the shape of s-quark PDFs. We can not simply combine all these distributions from NOMAD data due to the lack of public statistical correlation between these distributions. Hence in the following, only the x distribution is included in our global analysis. In figure 17, we compare u, u\u0304, d\u0304 and s-quark PDFs at Q = 1.295GeV from fits with and without the inclusion of NOMAD data. The PDF uncertainties are shown through hatched areas with relevant colors. NOMAD data are taken from the distribution over Bjorken x excluding the last two points, with predictions calculated up to NNLO in QCD. Predictions for data sets 124-127 (dimuon measurements from NuTeV and CCFR) in the global fit are replaced with their NNLO versions when including NOMAD data, in order to match on the theoretical precision. Note in the fit without NOMAD data the predictions for data sets 124-127 are evaluated at NLO similar to those in CT18. All PDFs are normalized to the central value without NOMAD data in figure 17. In the upper-left panel, almost no change occurs in the region x & 0.1 of u-quark PDF, and a negligible downward shift smaller than 2% can be seen for x . 0.05. Slight downward shifts on both central value and uncertainty region can also be observed in the u\u0304 (upper-right panel) and the d\u0304-quark (lower-left panel) PDFs. The downward shifts observed are required to stabilize the W and Z production cross sections at collider experiments. The improvement in the constraints on u, u\u0304 and d\u0304-quark PDFs are smaller than about 3%. This insensitivity of u, u\u0304 and d-quark PDFs to NOMAD data is an indication of the CKM suppression in the charm-quark production. The constraint on s-quark PDF is, however, markedly improved around x = 0.05. In the region of x \u223c 0.05, the s-quark PDF achieves a factor of two better precision when NOMAD data are incorporated. This is because NOMAD data peak at neutrino energy E\u03bd \u2248 30GeV, which implies a sensitivity to kinematic region with Bjorken x \u223c 1/(1 + 2MnucleonE\u03bd/Q2) \u223c 0.03 at Q = 1.295GeV. An upward shift of more than 15% is also observed in most regions. It is indeed a manifestation of the trend of prediction-data comparison shown in figure 15. Both ABM and NNPDF groups considered the impact of NOMAD data [87, 88]. As to the analysis of ABM group, an at most 5% downward shift is reported near region x \u2248 0.05 at scale Q = 3GeV when NOMAD data are incorporated into the fit with only NuTeV/CCFR data (data sets 124-127 in this paper) [87]. More data sets are considered in the work of NNPDF group [88]. With the analysis performed there, NOMAD data together with ATLAS W/Z data sets [89, 90] contribute to a marked enhancement of s-quark PDF at Q = 10GeV compared with CT18 data sets. It is noted that, between these two kinds of data sets, ATLAS W/Z data sets are already reported to give a larger s-quark PDF compared with CT18 data sets [12], and the work of NNPDF group further demonstrated that ATLAS W/Z data sets prefer a larger s-quark PDF compared with NOMAD data. Finally, both the two groups and our analysis indicate strong constraints on s-quark PDF in the region near x \u2248 0.05, given the incorporation of NOMAD data.\n\u2013 24 \u2013\n8\nWe also compare the sensitivities to s-quark PDF between NOMAD data and the other data sets in figure 18, in which we show LM scans on s-quark PDF and Rs. This comparison is set at a scale of Q = 1.5GeV and x = 0.1 in panel (a). In this panel, NOMAD data predominate over the other experimental data sets. When x gets smaller to be 0.023 as in panel (b), NuTeV and CCFR neutrino DIS experiments become more important but still the NOMAD data show the most prominence. In panel (a), the fit without NOMAD data predicts Rs(x = 0.1, Q = 1.5GeV) = 0.40+0.35\u22120.20 at 90% CL, while fit including NOMAD data expects Rs(x = 0.1, Q = 1.5GeV) = 0.54+0.24\u22120.06, giving improved constraints by a factor of two. In panel (b), the corresponding values are Rs(x = 0.023, Q = 1.5GeV) = 0.53+0.33\u22120.38 and Rs(x = 0.023, Q = 1.5GeV) = 0.70+0.40\u22120.17, respectively. NOMAD data hence give about 20% reduction on PDF uncertainties. It is also noted that a slight tension exists between NOMAD data and data from the other two neutrino DIS experiments, i.e., NuTeV and\n\u2013 25 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nCCFR, in both panels. The latter two experiments both prefer smaller Rss contrasted with NOMAD data which prefer a larger one. Further investigations on the interplay of the three experiments and of different theories are included in appendix C. Moreover, the ATLAS W/Z data [89], which prefer an especially larger Rs(x = 0.023, Q = 1.38GeV) \u223c 1, show an even stronger tension with these two neutrino DIS experiments. NOMAD data, however, compromise between these two extremes. This conclusion is also observed in the analysis of [88]. Meanwhile, a similar result of Rs(x = 0.023, Q = 1.6GeV) = 0.71\u00b1 0.1 is obtained in that work once NOMAD data are included. On the other hand, we let the scale increase to be Q = 100GeV in panel (c) and panel (d). The case with x = 0.3 shows more sensitive than that with x = 0.002. In panel (d), it can be seen that NuTeV and CCFR data become comparable with NOMAD data. No significant shift in the central value is found when we incorporate NOMAD data, but an almost 30% better constraints on s-quark PDF is achieved. In panel (c), the sensitivity of NOMAD data becomes worse due to the favor of large-x at this scale, and collider data now play important roles. Only improvement of a few percent in the constraint on s-quark PDF can be obtained."
        },
        {
            "heading": "5.2 Impact of High-luminosity LHC",
            "text": "LHC data play important roles on constraining PDFs as shown in table 2. And the upgrade of the LHC, the HL-LHC, is expected to accumulate a total integrated luminosity of L = 3000 fb\u22121 for ATLAS and CMS and 300 fb\u22121 for LHCb. In this section, we take two of those HL-LHC pseudo-data sets constructed in ref. [33], and evaluate their impact on PDFs within the framework of CT18 based on our new approach. The HL-LHC pseudo-data are generated for processes of Drell-Yan production with high dilepton invariant mass and W and Z boson production in the forward region. Details of these pseudo-data are described as follows:\n\u2022 The distribution of dilepton invariant mass d\u03c3(pp\u2192 l+l\u2212)/dmll of high-mass DrellYan process at \u221a s =14TeV, covered by the ATLAS experiment, is generated according\nto the following requirements: pl1(2)T \u2265 40 (30) GeV, |\u03b7l| \u2264 2.5, and mll \u2265 116GeV. The total number of data points is 21. The binning and the systematic uncertainties are determined from refs. [33, 91].\n\u2022 The distributions for W and Z boson production in the forward region at \u221a s =14TeV,\ncovered by the LHCb experiment, are generated according to the following cuts: plT \u2265 20GeV, 2.0 \u2264 \u03b7l \u2264 4.5. An additional requirement for Z production is that 60GeV \u2264 mll \u2264 120GeV. The total number of data points is 90. The binning and the systematic uncertainties are determined from refs. [33, 74].\nWe include those pseudo-data in the CT18 global fit and quantify their impact on PDFs. In figure 19 we show a comparison of the PDFs with and without HL-LHC pseudo-data, together with the published Hessian set of CT18. All results are normalized to the central value of CT18. The PDF uncertainties are shown through hatched areas with relevant colors. In figure 19, a significant reduction in PDF uncertainties can be found in all cases\n\u2013 26 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n0.2 0.4 0.6 0.8 Rs(x=0.1, Q=1.5GeV)\n20\n0\n20\n40\n60\n80\n100 120 2\ntotal total+p 124NuTeV nu 127CCFR nub NOMAD NNLO Unc. at 90% CL (baseline) Unc. at 90% CL (+NOMAD) Central value (baseline) Central value (+NOMAD)\n(a)\n0.5 1.0 Rs(x=0.023, Q=1.5GeV)\n20\n0\n20\n40\n60\n80\n100\n120\n2\ntotal total+p 160HEAR I+II 124NuTeV nu 125NuTeV nub 126CCFR nu 204E866pp NOMAD NNLO Unc. at 90% CL (baseline) Unc. at 90% CL (+NOMAD) Central value (baseline) Central value (+NOMAD)\n(b)\n500 600 700 s(x=0.002, Q=100GeV)\n20\n0\n20\n40\n60\n80\n100\n120\n2\ntotal total+p 160HEAR I+II 125NuTeV nub 204E866pp 261CDF2 Z 268ATLAS7 W/Z NOMAD NNLO Unc. at 90% CL (baseline) Unc. at 90% CL (+NOMAD) Central value (baseline) Central value (+NOMAD)\n(c)\n0.01 0.02 0.03 s(x=0.3, Q=100GeV)\n20\n0\n20\n40\n60\n80\n100\n120\n2\ntotal total+p 545CMS8 jet 101BCDMS F2p 102BCDMS F2d 125NuTeV nub 127CCFR nub NOMAD NNLO Unc. at 90% CL (baseline) Unc. at 90% CL (+NOMAD) Central value (baseline) Central value (+NOMAD)\n(d)\nFigure 18. LM scans on the Rs at Q = 1.5GeV and x = 0.1 or 0.023 (upper panels), and LM scans on the s-quark at Q = 100GeV and x = 0.002 or 0.3 (lower panels). The blue and the green vertical solid (dot-dash) lines represent the central values (uncertainties) with and without NOMAD data respectively.\nonce including the pseudo-data, especially for sea quarks. In the upper-left panel, the PDF uncertainties are reduced by almost a factor of 2, from about 30% to about 15%, at small-x. Similar improvements can also be observed in d, u\u0304 and s-quark PDFs. That is because HL-LHC pseudo-data contribute a great improvement in statistics, and cover the kinematic regions where PDFs are not determined well. Specifically, the process of high-mass Drell-Yan is directly sensitive to sea quarks at large-x, and the process of forward W/Z production constrains the s-quark PDF at both small-x and large-x. In the lower-right panel, we find that the HL-LHC gives about 30% reduction on PDF uncertainties of s-quark in the regions of x \u223c 0.01 and x \u223c 0.1. This result highlights the importance of the process of forward W/Z production.\nWe show the results of LM scans on Rs and u/d ratio in figure 20. We find measurements of high-mass Drell-Yan process and forward W/Z production process at HL-LHC give strong constraints on Rs and u/d ratio at both small-x and large-x. The PDF uncertainties of Rs and u/d are significantly reduced after the inclusion of pseudo-data.\n\u2013 27 \u2013\n8\nIn the upper-left panel of figure 20 for Rs at x = 0.023 and Q = 1.5GeV, the constraints from HL-LHC pseudo-data predominate as expected. In addition to that, constraints from NuTeV dimuon, CCFR dimuon and HERA inclusive DIS data also play important roles. The fit without pseudo-data predicts a result of Rs = 0.53+0.33\u22120.38 at 90% CL, while fit including pseudo-data gives Rs = 0.54+0.22\u22120.19. After the inclusion of pseudo-data, the PDF uncertainties are reduced by almost 50%. As x increases to 0.1 in the upper-right panel, HL-LHC forward W/Z data becomes more important. Fit without pseudo-data gives a result of Rs = 0.40+0.35\u22120.20, while fit including pseudo-data gives Rs = 0.39+0.16\u22120.16.\nFor d/u at x = 0.002 and Q = 100GeV, in the lower-left panel, the most strong constraints originate from HL-LHC pseudo-data together with LHC W and Z boson data and the fixed target experiments E866 and NMC. The results of d/u are 0.946+0.038\u22120.032 and 0.954+0.026\u22120.032 corresponding to fit without and with pseudo-data respectively. After\n\u2013 28 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n0.2 0.4 0.6 0.8 1.0 Rs(x=0.023, Q=1.5GeV)\n20\n0\n20\n40\n60\n80 100 2\ntotal total+p 160HEAR I+II 124NuTeV nu 125NuTeV nub 126CCFR nu 127CCFR nub 204E866pp HL DY HL W/Z Unc. at 90% (baseline) Unc. at 90% (+HL) Central value (baseline) Central value (+HL)\n(a)\n0.2 0.4 0.6 0.8 Rs(x=0.1, Q=1.5GeV)\n20\n0\n20\n40\n60\n80\n100\n2\ntotal total+p 160HEAR I+II 104NMC F2d/F2p 110CCFR F2 124NuTeV nu 125NuTeV nub 126CCFR nu 127CCFR nub HL DY HL W/Z Unc. at 90% (baseline) Unc. at 90% (+HL) Central value (baseline) Central value (+HL)\n(b)\n0.900 0.925 0.950 0.975 1.000 d/u(x=0.002, Q=100GeV)\n20\n0\n20\n40\n60\n80\n100\n2\ntotal total+p 249CMS8 Ach 250LHCb8 W/Z 160HEAR I+II 104NMC F2d/F2p 203E866 HL DY HL W/Z Unc. at 90% (baseline) Unc. at 90% (+HL) Central value (baseline) Central value (+HL)\n(c)\n0.34 0.36 0.38 0.40 d/u(x=0.3, Q=100GeV)\n20\n0\n20\n40\n60\n80\n100\n2\ntotal total+p 245LHCb7 W/Z 249CMS8 Ach 160HEAR I+II 102BCDMS F2d 104NMC F2d/F2p 281D0 2 e HL DY HL W/Z Unc. at 90% (baseline) Unc. at 90% (+HL) Central value (baseline) Central value (+HL)\n(d)\nFigure 20. LM scans on the Rs at Q = 1.5GeV and x = 0.023 or 0.1 (upper panels), and LM scans on the d/u at Q = 100GeV and x = 0.002 or 0.3 (lower panels). The blue and the green vertical solid (dot-dash) lines represent the central values (uncertainties) with and without HL-LHC pseudo-data respectively.\nthe inclusion of pseudo-data, the PDF uncertainties are reduced by almost 30%. In the lower-right panel for x = 0.3 and Q = 100GeV, pseudo-data predominate over the other experimental data sets. Fit without and with pseudo-data give d/u = 0.376+0.028\u22120.021, and d/u = 0.385+0.020\u22120.016 respectively. PDF uncertainties are reduced by almost 25% in this case. Both of the two HL-LHC processes prefer a larger d/u, and their inclusion leads to an increase of the central value.\nIn figure 21, we show the results for the general PDF ratio Rf as defined in eq. (4.3). The uncertainties of Rf are also determined with the LM method. In panel (a), we show the relative uncertainties of Rf at 90% CL, \u2206Rf , from the fit with inclusion of HL-LHC pseudo-data. To compare with the results from the fit without HL-LHC pseudo-data, a reduction factor of \u2206Rf ,\nyred = 2 \u2206Rbasef \u2212\u2206R base+HL f\n\u2206Rbasef + \u2206R base+HL f\n, (5.1)\nis shown in panel (b). We find that the relative uncertainties of Rf have a noticeable\n\u2013 29 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\ng u u d d s fi(x1, Q)\ng\nu\nu\nd\nd s f j( x 2 ,Q ) Unc. of fi(x1, Q)/fj(x2, Q) by LM at 90% CL [baseline + HL] Q = 1.295 GeV\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(a) CT18NNLO + HL-LHC\ng u u d d s fi(x1, Q)\ng\nu\nu\nd\nd\ns\nf j( x 2\n,Q )\nReduction on Unc. of fi(x1, Q)/fj(x2, Q)\nQ = 1.295 GeV\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(b) Reduction\nFigure 21. The relative uncertainties of Rf = fi(x1, Q)/fj(x2, Q) determined with the LM method at 90% CL are shown in panel (a), where Q = 1.295GeV. In panel (b) we show the reduction factors on the relative uncertainties of Rf between with and without HL-LHC pseudo-data.\nreduction in general. For the case of the u and u\u0304-quark PDFs as the numerator, we find that the HL-LHC gives about 80% reduction on relative uncertainties in the region of x1 . 0.001, which is because the HL-LHC pseudo-data give strong constraints on u and u\u0304-quark PDFs in this region as shown in figure 19. In addition, for the case of the s-quark PDFs as the numerator, we find that the HL-LHC gives about 50% reduction on relative uncertainties in the region of x1 \u223c 0.01. However, for the fd(x1, Q)/fu(x2, Q), fd(x1, Q)/fu\u0304(x2, Q), fd\u0304(x1, Q)/fu(x2, Q) and fd\u0304(x1, Q)/fu\u0304(x2, Q), we find that the reduction factors on relative uncertainties are minor in the region of x1 . 1\u00d7 10\u22123 and x2 . 1\u00d7 10\u22123. That is because the correlation between u-quark PDFs and d-quark PDFs at small-x that originates from the parametrization form of PDFs. Besides, for the ratios of gluon PDFs fg(x1, Q)/fg(x2, Q), the uncertainties are reduced by only a few percent, which is expected due to the weak correlations between the two HL-LHC processes and gluon PDFs."
        },
        {
            "heading": "5.3 Constraint on new physics with the global fit",
            "text": "PDFs and their uncertainties play important roles in the indirect searches for new physics beyond the SM. In this case, the scale of the new physics can be well beyond the typical scale of hard scatterings, and its effects can be formally described in the framework of the SMEFT. PDFs are determined by fitting to a variety of experimental data under the assumption of the SM. This leads to a problem that the degeneracy of PDF variations and the new physics contributions cannot be identified. Therefore, to assess and furthermore constrain the new physics, a joint global fit including both PDFs and model parameters of new physics should be performed. In this paper, we only consider one dimension-six operator, namely the lepton-quark contact interactions, to model the BSM effects in the\n\u2013 30 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nSMEFT framework,\nLSMEFT = LSM + \u2211 i,j cij \u039b2 (q\u0304i\u03b3\u00b5qi)(l\u0304j\u03b3 \u00b5lj)\n= LSM + c\u0303 \u039b2 \u2211 i,j eqielj (q\u0304i\u03b3\u00b5qi)(l\u0304j\u03b3\u00b5lj), (5.2)\nwhere cij is the Wilson coefficient, lj and qi represent fields of charged leptons and quarks of flavor j and i respectively, and eqi(lj) are the corresponding electric charges. We assume the new interactions being vector-current type and have a flavor structure similar to the QED coupling for simplicity. Thus the contributions from the new physics are parametrized by a single variable of the effective Wilson coefficient c\u0303 that is normalized to the QED coupling. In the case of data sets of the CT18 global fit, the DIS and the Drell-Yan processes receive contributions from this operator. Processes with relatively large Q2 are especially sensitive to BSM effects, where Q is the momentum transfer. Most of the data of Drell-Yan process included in the CT18 analysis are collected near the Z-pole region, which is less sensitive to new physics. Hence, we only consider the HERA DIS process due to its large Q2. The amplitude of SM contributions from QED interactions is proportional to 1/Q2, and the amplitude of the BSM contributions is proportional to c\u0303/\u039b2.1 Hence, the total cross section including the BSM effects can be written as:\n\u03c3total = (1 + c\u0303 \u039b2Q 2)2 \u00d7 \u03c3DIS. (5.3)\nA new NNs is built by adding the parameter c\u0303/\u039b2 into the input layer. An association between the 29 variables {ai, c\u0303/\u039b2} and \u03c72 is constructed. With the new NNs, \u03c72 is recalculated and the results of LM scans on c\u0303/\u039b2 are shown in figure 22. HERA inclusive DIS data give the dominant constraints as expected. The LM scans predict a result of c\u0303/\u039b2 = 0.56+9.16\u22129.16 TeV\u22122 at 90% CL, which is consistent with the SM. The interplay between PDFs and BSM effects in the framework of the SMEFT has been studied in previous works [35, 36, 39]. A simultaneous determination of the PDFs and BSM effects from DIS data based on the NNPDF framework was presented in ref. [35]. The Wilson coefficients of the lepton-quark contact interactions (i.e. l-u, l-d, l-s and l-c contact interactions) are constrained by the HERA inclusive DIS data. The most stringent bounds are obtained for u-quark, followed by d-quark, and then c-quark and s-quark. The constraint on the Wilson coefficients for u-quark converted to c\u0303/\u039b2 is [-6.5 TeV\u22122, 39.2 TeV\u22122] at 90% CL. In ref. [36], the BSM effects are constrained by the high-mass Drell-Yan data. The result converted to c\u0303/\u039b2 is [-6.5 TeV\u22122, 57.8 TeV\u22122] at 95% CL. In figure 23, we compare u, d, u\u0304 and g PDFs at Q = 1.295GeV determined by fitting with and without the new physics contributions. The PDF uncertainties are shown through hatched areas with relevant colors. The PDFs from two fits are almost indistinguishable for both central value and the uncertainties. In addition, we find that the central value is slightly changed if the c\u0303/\u039b2 is fixed at -8.60 or 9.72TeV\u22122, as represented by the two black\n1The weak interactions from Z boson induce a different energy dependence of 1/(Q2 + M2Z) which we neglect here for simplicity.\n\u2013 31 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\n10 5 0 5 10 c/ 2 (TeV 2)\n0\n50\n100\n150\n200\n2\ntotal total+p 160HEAR I+II Unc. at 90% CL Central value\nFigure 22. LM scans on c\u0303/\u039b2. The blue vertical solid line represents the central value of c\u0303/\u039b2, and the blue vertical dot-dash lines represent the uncertainties at 90% CL.\nsolid lines. Specifically, in the upper-left panel, a shift as large as 2% can be observed in the region of x \u223c 0.02. Similar shifts can also be observed in panel (b) and panel (c). Besides, in the lower-right panel, a shift as large as 10% can be observed at both small-x (\u223c 10\u22124) and large-x (\u223c 0.6). These shifts on PDFs are required to compensate for the contributions from the new physics on DIS cross sections. Our approach can be extended to include more EFT operators from new physics which we leave for future studies."
        },
        {
            "heading": "6 Conclusion",
            "text": "Better understanding on parton distributions is essential for precision physics at hadron colliders, as well as for study of QCD. Nowadays the analysis of PDFs requires calculations of the log-likelihood functions \u03c72 from thousands of experimental data points, and scans of multi-dimensional parameter space with tens of degrees of freedom. Such analyses will benefit from development of new methods and improvement of computing efficiencies, for instance by various interpolation approaches. In this paper we propose a new approach of using Neural Networks and machine learning techniques to model the dependence of the \u03c72 or any physics quantities on the PDFs. We demonstrate the high accuracy of our approach through detailed comparisons in the PDF parameter space of interest, taking the CT18 NNLO analysis as an example. Importantly, compared with direct calculations the computational cost on calculating \u03c72 are reduced by several orders of magnitude. The improvement ensures efficient scans of the full PDF parameter space and is desirable for the determination of PDF uncertainties.\nBased on our NNs, we perform a series of LM scans to reevaluate PDF uncertainties in the CT18 NNLO analysis, and to understand the interplay between different data sets. The LM method is generally more reliable through a scan of the \u03c72 along the trajectory of constrained minimum of the physics quantity studied. Our new approach renders such extensive scans almost costless and ensures the possibility of detailed comparisons of PDF uncertainties determined from the LM and Hessian method. We first perform LM scans\n\u2013 32 \u2013\n8\non PDF values and ratios at various x and Q values, and find the results from the LM method and the Hessian method agree well in general. However, a notable difference can be observed in the small and the large-x regions. Since the quadratic approximation fails in the region where PDF uncertainties are large, and the results from the LM method are more reliable. Besides, we perform LM scans on the production cross sections of the Higgs boson pair and the top-quark pair in association with a Higgs boson, at the LHC or future colliders, as well as two dimensional scans on a pair of PDFs or cross sections. Furthermore, using LM scans we study the impact of individual data sets in the CT18 NNLO analysis by subtracting and adding back one data set at a time.\nWe show further applications of our approach on several extensions of the CT18 NNLO analysis. Especially, we study the impact of the NOMAD dimuon data on constraining the strange-quark PDFs. Theoretical predictions are calculated in the S-ACOT-\u03c7 general mass\n\u2013 33 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nscheme up to NNLO, based on which the NNs are constructed and LM scans are performed. We find that the NOMAD data place stringent constraints on the strange-quark PDFs at intermediate and large-x regions. At x \u223c 0.05, for example, the PDF uncertainties of the strange quark are reduced by almost a factor of 2. An upward shift of more than 15% in the strange-quark PDF as well as slight downward shift in the u and d-quark PDFs are also observed in most regions. We show the interplay of the NOMAD data and other data sets in the CT18 by detailed LM scans on Rs and s-quark PDFs at different scales and x values. The global fit with NOMAD data predicts Rs(x = 0.023, Q = 1.5GeV) = 0.70+0.40\u22120.17 at 90% CL and a slight tension between NOMAD and NuTeV data is observed. We also present a series of variant fits for clarifications on the impact of different theory predictions and of different choices of the decay branching ratio of the charm quark. Afterwards, we study the impact of two HL-LHC pseudo-data constructed in ref. [33], including the high-mass Drell-Yan data and the forward W/Z production data. We find potentially large reduction on PDF uncertainties of the sea quarks. These results highlight the importance of HL-LHC measurements. Besides, we performed a joint fit on both PDFs and effects of new physics beyond the SM. We take the lepton-quark contact interactions as an example that are described by high dimensional operators in the SMEFT. We determine the effective Wilson coefficient to be c\u0303/\u039b2 = 0.56+9.16\u22129.16 TeV\u22122 at 90% CL as mostly constrained by the HERA inclusive DIS data. Foreseen extensions of the study would be to include more SMEFT operators in the joint fit that is under investigation."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was sponsored by the National Natural Science Foundation of China under the Grant No. 11875189 and No.11835005. JG would like to thank members of CTEQ-TEA collaboration for helpful discussions and proofreading of the manuscript."
        },
        {
            "heading": "A More on the Neural Network approach",
            "text": "In this appendix we collect various details of the NN approach, including on the architectures and parametrization dependence, the generation of training and test samples, and the performances in terms of computational cost. One important feature of our approach is to use directly PDF values as inputs to the NNs rather than the PDF parameter themselves. That ensures a great flexibility of the functional space since we can select PDF values at an arbitrary number of x points. In our current study with CT18 parametrization form, we select the x grid consisting of 14 points for each PDF flavor with their values shown in table 4. They are selected randomly with the only criteria being distributed evenly in ln x. We explain briefly on the mathematical model behind our NNs. The true dependence of our target function, for instance, the \u03c72, on the PDF parameters is uniquely determined by the theory and experimental data used in the global fit, which we denote as ATR. On another hand if we exchange the PDF parameters by the PDF values at discrete x points, the mapping is not unique since we have input PDF values far more than the number of PDF parameters. Thus we arrive at a bunch of possible functions {A\u2217TR} depending\n\u2013 34 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nexplicitly on {Ik} which is the PDF value at the kth node, satisfying\n\u03c72truth = ATR(a) = A\u2217TR({Ik(a)}). (A.1)\nThe purpose of our NNs is to construct an explicit function of {Ik} depending on a set of tuneable parameters t\u03b2. By the training procedure we update ANN iteratively until it converges to the neighborhood of one of the truth function A\u2217TR with a choice on the parameters t\u0302\u03b2. Finally we arrive at our approximation to the \u03c72 dependence on the PDF parameters as\n\u03c72pred = ANN ( {Ik(a)} ; {t\u0302\u03b2} ) . (A.2)\nAs from above one expects that the outcome NN (or equivalently the solution t\u0302\u03b2) in general depends on the parametrization form of PDFs. However, in practice one can approximate either PDFs or cross sections in terms of interpolated functions on a dense x-grid with sufficient accuracy, as implemented successfully in APPLgrid [43], FastNLO [92], and FastKernal [14]. In that sense there may exist an almost universal solution for different parametrization forms if one start with a sufficiently large number of PDF inputs. We leave that for future investigations.\nThe 8000 PDF replicas used for training and test are generated through a randomly sampling of the PDF parameters defined in eq. (2.4) with the help of CT18 NNLO Hessian PDF set. Each replica or PDF parameters arepi is determined by 28 randomly distributed variables rj , namely\narepi = a0i + 28\u2211 j=1 rj ( a2j\u22121i \u2212 a 2j i ) /2, (A.3)\nwhere {a0i } represent the ith PDF parameter of the central PDF of CT18 NNLO, {a 2j\u22121 i } and {a2ji } represent the ith PDF parameter of the error PDFs in the plus and the minus direction of the ith eigenvector respectively. For each rj we use a Gaussian sampling with mean value 0 and variance 1/ \u221a 28 which ensures coverage of the PDF parameter space with average increase of global \u03c72 of a few hundred units comparing to CT18 best fit as shown in figure 2. We note that performances of the trained NNs are not sensitive to the choice of training samples as far as we are within or close to the uncertainty range of CT18.\nWe further test performance of our NN approach with alternative PDF parametrization forms taking the target function of \u03c72 of the ATLAS 7TeV jet data as an example. We have chosen MMHT2014 [93], NNPDF3.1 [94] and NNPDF4.0 [14] NNLO PDFs with 4000 MC PDF replicas each generated from the corresponding Hessian PDF sets with\n\u2013 35 \u2013\n8\nLHAPDF6 [95].2 We use the same architecture as used for CT18 except for extensions to include 9 PDF flavors, namely with s\u0304, c, and b-quark PDFs in addition. The NNs have been trained and tested for each individual parametrization form with the corresponding MC replicas. We find very good performance of the NNs in cases of MMHT2014 and NNPDF4.0 as shown in figure 24, similar to the case of CT18. Interestingly, we find performance of the same architecture is much better for the parametrization form of NNPDF4.0 than NNPDF3.1, possibly due to the smooth conditions applied in NNPDF4.0 [14]. We also try to train the NNs with an ensemble of PDF replicas, 12000 replicas in total, from CT18, MMHT14 and NNPDF4.0. The accuracy of the trained NNs is only marginally worse than the NNs trained to individual parametrization forms. That hints the possibility of a universal NN to accommodate for a variety of smooth PDF parametrizations, as discussed at earlier this section.\n2We have not used the native MC replicas of NNPDF since the numbers of replicas are limited to be 1000 in that case.\n\u2013 36 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nFinally we summarize the performances of our NNs in terms of computational cost in table 5 comparing to the traditional approaches. Note that we have not included the time cost for the process of training of the NNs since we do not need to repeat it in later scans of the PDF parameters. In table 5 the numbers indicate the time cost on a single CPU-core (2.4 GHz) of calculating the target functions for a single point in the PDF parameter space. For \u03c72 the cost includes those for the calculations of the needed cross sections (taking 10 points per data set as an example) and for the multiplications with covariance matrix. In the conventional approach the computing efficiency varies significantly, e.g., for the \u03c72, depending on the number of data points, the perturbative order of the theory calculations, and importantly whether the fast interpolation algorithms are used or not. Thus included numbers only represent typical average cost in the CT18 NNLO analysis for a direct calculation or using fast interpolations (shown in parenthesis). The fast interpolation method for calculations of a single cross section involves more PDF values on a dense grid and thus is slower than the NN approaches. Nevertheless, the NN approaches lead to significant improvement in general and ensure efficient scans of the PDF parameter space with much less cost. The NNs was programmed with PYTHON2.7, and we expect further reduction of the computational cost if transferred into more efficient programming languages like Fortran/C++. We are planning to provide open source access for the NN framework used together with trained NNs for various target functions of CT18 in the near future."
        },
        {
            "heading": "B Hessian PDF set",
            "text": "We further generate a Hessian PDF set based on the \u03c72 profile obtained with the NN approaches. The Hessian error matrix on the PDF parameters is calculated using a numeric method of finite difference. We use an iterative algorithm on diagonalization of the Hessian matrix that is developed in refs. [20, 23] and used in later CTEQ analyses. The iterative procedure greatly improves the performance of Hessian approximation in the case of large number of free parameters (28 here) and in the existence of flat directions. Once all orthogonal eigenvectors are determined, two error PDFs are generated for each eigenvector by scanning along the plus and the minus directions and looking for solutions with \u2206\u03c72 + P = 100 (for 90% CL). We compare the PDF uncertainties at 68% CL from the Hessian PDF set to the published CT18 NNLO PDFs in figure 25. We find very good agreements between predictions of\n\u2013 37 \u2013\n\u2013 38 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nthe two Hessian PDF sets in general. However, some notable differences can be seen for d-valence and gluon PDFs at large-x (\u223c 0.4) as well as for sea quarks at x . 10\u22123. There are two reasons that lead to the differences in the new Hessian set and the CT18 set. First as mentioned earlier in the global fit presented in this paper the NNLO K-factors used for predictions of the Drell-Yan data have been updated comparing to those used in the CT18 analysis. Besides, when calculating the Hessian error matrix numerically we use a step size of \u2206\u03c72 = 10 on sampling of the PDF parameters while a value of \u223c 1 is used in the CT18 analysis. The dependence on choices of this step size reflect one intrinsic uncertainty of the Hessian approaches [23].\nC Variant fits with NOMAD data\nIn this appendix we present a series of global fit with inclusion of the NOMAD data and with different theories or different choices of decay branching ratios of charm quark to muon. In section 5.1 when comparing to the global fit without NOMAD data, we use NLO cross sections (but with NNLO PDFs) for NuTeV and CCFR dimuon data to be consistent with the CT18 analysis. Thus the changes observed after including the NOMAD data can be due to both the NOMAD data or the changes of theories for the other two dimuon data. Now we further consider different choices of the theory predictions, namely either calculated at NLO or NNLO in QCD, to disentangle their effects. Furthermore, to compare with dimuon data, one has to convert the cross sections of charm-quark production to production of dimuon which relies on the input of inclusive semileptonic branching ratio Br(c\u2192 \u00b5). Since NOMAD dimuon data extend down to E\u03bd \u223c 6GeV the energy dependence of Br(c\u2192 \u00b5) is taken into account in NOMAD analysis, with a parametrization form\nBr(c\u2192 \u00b5) = a1 + b/E\u03bd , (C.1)\nwhere a and b are free parameters. In the NOMAD paper it suggests values of a = 0.094 \u00b1 0.010 and b = 6.6 \u00b1 3.9GeV as measured by the E531 experiment [96]. The uncertainties on parameters a and b will propagate into the unfolded charm-quark cross sections and are treated as additional correlated systematic errors that are summarized in table 6 for distribution in Bjorken-x. Other correlated systematic uncertainties for NOMAD data can be found in ref. [31]. On the other hand, for NuTeV and CCFR data, since the neutrino energies are sufficiently high, a constant value of Br(c \u2192 \u00b5)=0.099 \u00b1 0.010 has been suggested [52] and is used in the CT18 analysis. The central value is slightly higher than the parameter a used in our nominal fit of NOMAD data. Thus we perform variant fits using a = 0.099 \u00b1 0.010 for NOMAD data to further investigate the impact of this overall normalization on the outcome PDFs. In figure 26 we compare the strange-quark PDFs at 1.295GeV from all variant fits. We show the PDF uncertainties at 68% CL from LM scans for fits with and without NOMAD data and using NNLO predictions from dimuon production consistently. That can be compared with figure 17 where NLO predictions are used in fit without NOMAD data. We also present central PDFs obtained with NLO predictions or with higher branching ratio for\n\u2013 39 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nxBj Bin center \u03c3\u00b5\u00b5/\u03c3cc \u00b1 \u03b4stat \u00b1 \u03b4syst (10\u22123) \u03b4a, % \u03b4b, % 0.0000 \u2013 0.0336 0.0267 13.383 \u00b1 0.441 \u00b1 0.289 10.6 5.3 0.0336 \u2013 0.0511 0.0440 11.245 \u00b1 0.380 \u00b1 0.210 10.6 6.8 0.0511 \u2013 0.0672 0.0598 9.991 \u00b1 0.347 \u00b1 0.201 10.6 7.7 0.0672 \u2013 0.0836 0.0756 9.141 \u00b1 0.324 \u00b1 0.189 10.6 8.3 0.0836 \u2013 0.1000 0.0917 8.198 \u00b1 0.297 \u00b1 0.169 10.6 8.8 0.1000 \u2013 0.1246 0.1122 7.176 \u00b1 0.225 \u00b1 0.144 10.6 9.0 0.1246 \u2013 0.1535 0.1389 6.229 \u00b1 0.195 \u00b1 0.118 10.6 9.4 0.1535 \u2013 0.1870 0.1699 5.427 \u00b1 0.171 \u00b1 0.106 10.6 9.6 0.1870 \u2013 0.2277 0.2066 4.837 \u00b1 0.151 \u00b1 0.093 10.6 9.9 0.2277 \u2013 0.2800 0.2524 4.235 \u00b1 0.133 \u00b1 0.083 10.6 10.0 0.2800 \u2013 0.3590 0.3165 3.595 \u00b1 0.113 \u00b1 0.072 10.6 10.0 0.3590 \u2013 0.4583 0.4036 2.955 \u00b1 0.111 \u00b1 0.062 10.6 10.1 0.4583 \u2013 0.5838 0.5116 2.355 \u00b1 0.120 \u00b1 0.055 10.6 9.9 0.5838 \u2013 0.7500 0.6465 1.607 \u00b1 0.150 \u00b1 0.047 10.6 9.4\nTable 6. NOMAD measurements on the Bjorken-x distribution of dimuon to inclusive CC cross section ratio, including the binning, central values, statistical and total systematic uncertainties. The last two columns show the additional correlated systematic uncertainties in percentages, if converting back to production cross sections of charm-quark, due to input parameter a and b respectively. These additional errors are derived based on theoretical cross sections at NLO with CT18 NNLO PDFs.\nNOMAD data. We find including the NNLO corrections leads to a moderate increase of the strange-quark PDF, which is in consistent with the conclusions in ref. [12]. The inclusion of NOMAD data results in about 20% enhancement of the strange-quark PDF at x around 0.05 and a significant reduction of the PDF uncertainties. Changing to a = 0.099\u00b1 0.010 for NOMAD only induces a minor reduction of the strange-quark PDF. We further summarize the total or individual \u03c72 of all variant fits together with predictions on Rs(x = 0.023, Q = 1.5GeV) with uncertainties at 68% CL in table 7. By comparison with the \u03c72 we find the NNLO predictions in general lead to a slightly worse fit with increase on \u03c72 of a few units. However, in all cases the global fit can describe well various dimuon data as can be seen from the \u03c72 per number of degree of freedoms. When comparing fits in the last two rows we find using a consistent branching ratio in different data sets results in a better fit and reduced PDF uncertainties.\n\u2013 40 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nFigure 26. Strange-quark PDF at Q = 1.295GeV from LM scans in global fits with various conditions. The PDF uncertainties are shown for 68% CL.\ndata sets \u03c7 2 total (3671/3683) \u03c72nomad (12) \u03c72124 (38)\n\u03c72125 (33)\n\u03c72126 (40)\n\u03c72127 (38) Rs(0.023,1.5GeV)\nNUT (NLO) 4272.64 \u2014 18.83 39.55 29.89 19.42 0.518+0.349\u22120.363 NUT (NNLO) 4268.77 \u2014 21.44 32.84 34.06 22.54 0.616+0.441\u22120.377 NUT (NLO) + NOM (NLO) 4286.28 8.39 24.81 41.95 29.30 18.79 0.593 +0.256 \u22120.155\nNUT (NNLO) + NOM (NNLO) 4291.47 14.47 28.13 34.26 34.21 22.15 0.695 +0.384 \u22120.169\nBr(c\u2192 \u00b5)=0.099 4289.61 13.79 27.38 34.06 34.10 22.13 0.685+0.290\u22120.174\nTable 7. Total \u03c72 and individual \u03c72 of dimuon data for global fits with various conditions. Numbers in the first row indicate the total number of data points. The last column includes predictions on Rs(x = 0.023, Q = 1.5GeV) with uncertainties at 90% CL.\n\u2013 41 \u2013\nJ H E P 0 8 ( 2 0 2 2 ) 0 8 8\nOpen Access. This article is distributed under the terms of the Creative Commons Attribution License (CC-BY 4.0), which permits any use, distribution and reproduction in any medium, provided the original author(s) and source are credited. SCOAP3 supports the goals of the International Year of Basic Sciences for Sustainable Development."
        }
    ],
    "title": "Machine learning of log-likelihood functions in global analysis of parton distributions",
    "year": 2022
}