{
    "abstractText": "Defect depth is an essential indicator in magnetic flux leakage (MFL) detection and estimation. The quantification errors for defect depth are closely related to length and width errors, and this feature has always been used to support the operator\u2019s judgment in defect identification. However, the existing defect quantification algorithms based on shallow and deep neural networks only employed simple general network structures inspired by the field of artificial intelligence; consequently, these network structures lack the support of physical concepts and result in large quantification errors regarding defect size, especially depth. In this article, to describe and integrate the above theory into a deep neural network, we propose a physics-informed doubly fed cross-residual network (DfedResNet) suitable for MFL defect detection based on deep learning. Physics-based MFL defect quantification theory is studied and integrated into loss functions during the neural network training. DfedResNet quantifies defects in MFL data and automatically extracts deep features of defects. The experimental results show that it effectively achieves high-precision quantification of defect length, width, and depth simultaneously, especially defect depth. Moreover, it considers data from all three dimensions during network training, and use the originally measured magnetic signal data in place of recognized images to avoid defect information loss and further improve the quantification accuracy. The deep DfedResNet model proposed in this article reduces defect length and width quantification errors to within 0.3 mm and defect depth quantification errors to within 0.4% t. In addition, compared with Manuscript received February 17, 2021; revised April 7, 2021 and May 9, 2021; accepted June 7, 2021. Date of publication June 15, 2021; date of current version December 6, 2021. This work was supported by the National Natural Science Foundation of China under Grant 52077110 and Grant 52007088. Paper no. TII-21-0718. (Corresponding author: Songling Huang.) Hongyu Sun, Lisha Peng, Songling Huang, Yue Long, Shen Wang, and Wei Zhao are with the State Key Laboratory of Power System, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China (e-mail: shymanuscript@163.com; 466478319@qq.com; huangsling@tsinghua.edu.cn; long-y17@mails.tsinghua.edu.cn; wangshen@mail.tsinghua.edu.cn; zhaowei@tsinghua.edu.cn). Shisong Li is with the Department of Engineering, Durham University, DH1 3LE Durham, U.K. (e-mail: leeshisong@sina.com). Color versions of one or more figures in this article are available at https://doi.org/10.1109/TII.2021.3089333. Digital Object Identifier 10.1109/TII.2021.3089333 other network structures and traditional algorithms, DfedResNet improves defect quantification accuracy by 1\u20132 orders of magnitude and thus achieves a high quantification performance.",
    "authors": [
        {
            "affiliations": [],
            "name": "Hongyu Sun"
        },
        {
            "affiliations": [],
            "name": "Lisha Peng"
        },
        {
            "affiliations": [],
            "name": "Shisong Li"
        },
        {
            "affiliations": [],
            "name": "Wei Zhao"
        },
        {
            "affiliations": [],
            "name": "Songling Huang"
        }
    ],
    "id": "SP:81836fba1caed7f2fd43b671a6c35dc7b486f5c0",
    "references": [
        {
            "authors": [
                "J. Ahmed",
                "B. Gao",
                "W. Woo"
            ],
            "title": "Sparse low-rank tensor decomposition for metal defect detection using thermographic imaging diagnostics",
            "venue": "IEEE Trans. Ind. Informat., vol. 17, no. 3, pp. 1810\u20131820, Mar. 2021.",
            "year": 1810
        },
        {
            "authors": [
                "H. Wu",
                "K. Zheng",
                "S. Sfarra"
            ],
            "title": "Multiview learning for subsurface defect detection in composite products: A challenge on thermographic data analysis",
            "venue": "IEEE Trans. Ind. Informat., vol. 16, no. 9, pp. 5996\u20136003, Sep. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Q. Yi",
                "H. Malekmohammadi",
                "G. Tian"
            ],
            "title": "Quantitative evaluation of crack depths on thin aluminum plate using eddy current pulse-compression thermography",
            "venue": "IEEE Trans. Ind. Informat., vol. 16, no. 6, pp. 3963\u20133973, Jun. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "R. Romero",
                "J. Mason",
                "N. Pearson"
            ],
            "title": "Experimental study to differentiate between top and bottom defects for MFL tank floor inspections",
            "venue": "NDT&E Int., vol. 42, no. 1, pp. 16\u201321, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "H. Lei",
                "G. Tian"
            ],
            "title": "Broken wire detection in coated steel belts using the magnetic flux leakage method",
            "venue": "Insight, vol. 55, no. 3, pp. 126\u2013131, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "Y. Li",
                "G. Tian",
                "S. Ward"
            ],
            "title": "Numerical simulation on magnetic flux leakage evaluation at high speed",
            "venue": "NDT&E Int., vol. 39, no. 5, pp. 367\u2013373, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "S. Lu",
                "J. Feng",
                "H. Zhang",
                "J. Liu",
                "Z. Wu"
            ],
            "title": "An estimation method of defect size from MFL image using visual transformation convolutional neural network",
            "venue": "IEEE Trans. Ind. Informat., vol. 15, no. 1, pp. 213\u2013224, Jan. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "P. Ramuhalli",
                "L. Udpa",
                "S. Udpa"
            ],
            "title": "Neural network-based inversion algorithms in magnetic flux leakage nondestructive evaluation",
            "venue": "J. Appl. Phys., vol. 93, no. 10, pp. 8274\u20138276, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "H. Geoffrey",
                "O. Simon",
                "T. Yee-Whye"
            ],
            "title": "A fast learning algorithm for deep belief nets",
            "venue": "Neural Comput., vol. 18, pp. 1527\u20131554, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "L. Yann",
                "B. Yoshua",
                "H. Geoffrey"
            ],
            "title": "Deep learning",
            "venue": "Nature, vol. 521, pp. 436\u2013444, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J. Ye",
                "S. Ito",
                "N. Toyama"
            ],
            "title": "Computerized ultrasonic imaging inspection: From shallow to deep learning",
            "venue": "Sensors, vol. 18, no. 11, 2018, Art. no. 3820.",
            "year": 2018
        },
        {
            "authors": [
                "H. Liu",
                "Y. Zhang"
            ],
            "title": "Deep learning based crack damage detection technique for thin plate structures using guided lamb wave signals",
            "venue": "Smart Mater. Struct., vol. 29, 2020, Art. no. 15032.",
            "year": 2020
        },
        {
            "authors": [
                "Q. Luo",
                "B. Gao",
                "W. Woo",
                "Y. Yang"
            ],
            "title": "Temporal and spatial deep learning network for infrared thermal defect detection",
            "venue": "NDT&E Int., vol. 108, 2019, Art. no. 102164.",
            "year": 2019
        },
        {
            "authors": [
                "N. Munir"
            ],
            "title": "Performance enhancement of convolutional neural network for ultrasonic flaw classification by adopting au-to encoder",
            "venue": "NDT&E Int., vol. 111, 2020, Art. no. 102218.",
            "year": 2020
        },
        {
            "authors": [
                "J. Melville"
            ],
            "title": "Structural damage detection using deep learning of ultrasonic guided waves",
            "venue": "AIP Conf. Proc., vol. 1949, no. 1, 2018, Art. no. 230004.",
            "year": 1949
        },
        {
            "authors": [
                "H. Wang",
                "G. Chen"
            ],
            "title": "Defect size estimation method for magnetic flux leakage signals using convolutional neural networks",
            "venue": "Insight, vol. 62, 2020, Art. no. 86.",
            "year": 2020
        },
        {
            "authors": [
                "L. Peng",
                "S. Huang",
                "S. Wang",
                "W. Zhao"
            ],
            "title": "An element-combination method for arbitrary defect reconstruction from MFL signals",
            "venue": "Proc. IEEE Int. Instrum. Meas. Technol. Conf., 2020, pp. 1\u20136.",
            "year": 2020
        },
        {
            "authors": [
                "D.H. Hubel",
                "T.N. Wiesel"
            ],
            "title": "Receptive fields and functional architecture of monkey striate cortex",
            "venue": "J. Physiol., vol. 195, no. 1, pp. 215\u2013243, 1968.",
            "year": 1968
        },
        {
            "authors": [
                "Y.L. Cun"
            ],
            "title": "Handwritten digit recognition with a back-propagation network",
            "venue": "Proc. Adv. Neural Inf. Process. Syst., 1990, pp. 396\u2013404.",
            "year": 1990
        },
        {
            "authors": [
                "S. Loffe",
                "C. Szegedy"
            ],
            "title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
            "venue": "Proc. 32nd Int. Conf. Mach. Learn., 2015, pp. 448\u2013456.",
            "year": 2015
        },
        {
            "authors": [
                "S. Huang",
                "L. Peng",
                "Q. Wang",
                "S. Wang",
                "W. Zhao"
            ],
            "title": "An opening profile recognition method for magnetic flux leakage signals of defect",
            "venue": "IEEE Trans. Instrum. Meas., vol. 68, no. 6, pp. 2229\u20132236, Jun. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Hui",
                "G. Chang",
                "H. Sung",
                "S. Gwan"
            ],
            "title": "Determination scheme for accurate defect depth in underground pipeline inspection by using magnetic flux leakage sensors",
            "venue": "IEEE Trans. Magn., vol. 54, no. 11, pp. 1\u20135, Nov. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "W. Dehui",
                "S. Lingxin",
                "W. Xiaohong",
                "L. Zhitian"
            ],
            "title": "A novel nondestructive testing method by measuring the change rate of magnetic flux leakage",
            "venue": "J. Nondestruct. Eval., vol. 36, Mar. 2017, Art. no. 24.",
            "year": 2017
        },
        {
            "authors": [
                "R. Duda",
                "P. Hart"
            ],
            "title": "Pattern Classification and Scene Analysis",
            "venue": "Hoboken, NJ, USA: Wiley,",
            "year": 1973
        },
        {
            "authors": [
                "K. He",
                "X. Zhang",
                "S. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 770\u2013778.",
            "year": 2016
        },
        {
            "authors": [
                "X. Glorot",
                "A. Bordes",
                "Y. Bengio"
            ],
            "title": "Deep sparse rectifier neural networks",
            "venue": "Proc. 14th Int. Conf. Artif. Intell. Statist., 2011, pp. 315\u2013323.",
            "year": 2011
        },
        {
            "authors": [
                "D. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "Proc. 3rd Int. Conf. Learn. Representations, San Diego, CA, USA, 2015, pp. 1\u201315.",
            "year": 2015
        },
        {
            "authors": [
                "A. Chattopadhyay"
            ],
            "title": "Grad-CAM++: Generalized gradient-based visual explanations for deep convolutional networks",
            "venue": "Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV), 2018, pp. 839\u2013847.",
            "year": 2018
        },
        {
            "authors": [
                "A. Bernieri",
                "L. Ferrigno",
                "M. Laracca",
                "M. Molinara"
            ],
            "title": "Crack shape reconstruction in eddy current testing using machine learning systems for regression",
            "venue": "IEEE Trans. Instrum. Meas., vol. 57, no. 9, pp. 1958\u20131968, Sep. 2008.",
            "year": 1958
        }
    ],
    "sections": [
        {
            "text": "Manuscript received February 17, 2021; revised April 7, 2021 and May 9, 2021; accepted June 7, 2021. Date of publication June 15, 2021; date of current version December 6, 2021. This work was supported by the National Natural Science Foundation of China under Grant 52077110 and Grant 52007088. Paper no. TII-21-0718. (Corresponding author: Songling Huang.)\nHongyu Sun, Lisha Peng, Songling Huang, Yue Long, Shen Wang, and Wei Zhao are with the State Key Laboratory of Power System, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China (e-mail: shymanuscript@163.com; 466478319@qq.com; huangsling@tsinghua.edu.cn; long-y17@mails.tsinghua.edu.cn; wangshen@mail.tsinghua.edu.cn; zhaowei@tsinghua.edu.cn).\nShisong Li is with the Department of Engineering, Durham University, DH1 3LE Durham, U.K. (e-mail: leeshisong@sina.com).\nColor versions of one or more figures in this article are available at https://doi.org/10.1109/TII.2021.3089333.\nDigital Object Identifier 10.1109/TII.2021.3089333\nother network structures and traditional algorithms, DfedResNet improves defect quantification accuracy by 1\u20132 orders of magnitude and thus achieves a high quantification performance.\nIndex Terms\u2014Cross-residual network, deep learning, defect quantification, doubly fed, magnetic flux leakage (MFL) testing, physics-informed.\nI. INTRODUCTION\nA S THE main carriers for the long-distance transportation offlammable and explosive energy materials such as oil and natural gas, pipelines have the advantages of large transportation volumes, low cost, and environmental friendliness. However, during long-term pipeline operation, accidents often occur due to pipe corrosion, poor construction quality, and human-induced damage, leading to environmental pollution, national economic losses, and even threatening the people\u2019s safety and property. Nondestructive testing (NDT) methods can be used to detect defects in a tested specimen without destroying it; thus, they are beneficial for defect inspections of in-service industrial facilities such as pipes, plates, and complex structures [1]\u2013[3]. The current NDT technologies applicable to pipelines mainly include ultrasonic testing, eddy current testing, magnetic particle testing, and magnetic flux leakage (MFL) testing. MFL testing, which is currently a mature and widely used oil and gas detection technology, has a good defect detection capability for pipes with high magnetic permeability. Generally, pipelines may be dozens or even hundreds of kilometers long; consequently, the volume of MFL data detected by an inspection device is rather large. Therefore, methods of effectively analyzing and processing these data to estimate pipeline characteristics and defect information are important for pipeline NDT.\nWith the advances in MFL sensor technology and the continuous development of computer technology in recent years, MFL data analytics have expanded from an initial visual recognition to further defect quantification. In the early development stage of MFL detection technology, due to the limitations of the theoretical foundation and the capabilities of computer analysis and processing, it was possible to judge only the existence and location of defects\u2014that is, to perform a qualitative defect\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/\nanalysis. The most common method was to visualize the MFL defect data and obtain defect signal images. Technicians could then qualitatively analyze the defects by observing the features of the MFL test data depicted in the images, which were generated through approaches such as curve display, grayscale display, and pseudocolor display. By visualizing the MFL data using one or more complicated methods combined with technician experience and pipe-related drawings, the collected MFL data could be analyzed and processed. In general, artificial analysis methods are less efficient and can easily lead to defect misjudgments, while visualization methods such as those described above can enable only simple qualitative analyses of defects. As defect MFL testing technologies have developed, more MFL data are being collected, and defect estimation accuracy and efficiency are becoming an important priority. High-precision auto-quantification of defects is required.\nThe current main defect quantification methods based on MFL testing can be divided into indirect methods [4] and direct methods [5], [6]. In an indirect method, such as an iterative method using threshold feedback or a mapping method using an established defect feature library, the defect parameters are estimated indirectly based on the MFL signal. However, indirect methods are time-consuming and difficult to apply in the industrial field. In contrast, a direct method straightly obtains the length, width, and depth of a defect from corresponding measured signals. These methods have the advantages of fast speed, ease-of-use, and offer substantial advantages for offline MFL data analysis. The drawback of the direct methods is that they have a relatively low defect quantification accuracy. Thus, there is a need for industrial applications to develop suitable approaches for selecting an effective direct quantification method and improving its quantification accuracy.\nThe following processes are required to achieve defect quantification in industrial MFL\u2013NDT: collection and storage of MFL test data, defect location, and feature extraction, and finally, quantitative model establishment and defect size estimation. However, the following problems arise during these processes. The first is incomplete utilization of the test data: in most MFL testing, only the x-axis detection data are used, while the yand z-axis data are discarded [7]. Second, feature extraction is difficult and complicated; it relies on prior knowledge and the designer\u2019s subjective judgment. Several methods have been developed for extracting features from MFL signals, including statistical methods, frequency-domain transforms, and other intuitive feature extraction methods. The third problem is that the datasets are typically small, and the network structures are not targeted; that is, the theory of MFL testing has not been incorporated into the construction of neural networks [8]. In summary, many issues remain to be addressed in the available MFL defect quantification methods for industrial applications; these shortcomings lead to low defect quantification accuracy and poor operational reliability.\nA deep learning system uses a multilayer neural network constructed through stacking to adaptively extract the required features during the training process, thereby avoiding the need for complex signal processing steps [9], [10]. Deep learning methods have broad application prospects in computer vision,\nnatural language processing, and other fields and have been extended to various fields related to industrial information and applications, such as NDT [11], [12]. As a typical application of deep learning in NDT, Luo [13], Munir [14], and Melville [15] compared feature-engineering-based shallow neural networks and deep neural networks and obtained consistent conclusions: the shallow machine learning classification models require feature engineering as an auxiliary preprocessing method, while a deep convolutional neural network (CNN) can automatically extract high-level information without complicated feature engineering. However, in the field of MFL testing, to the best of our knowledge, except for one study on the use of shallow CNNs for defect detection [16], there have been few related works using deep learning. Combining the advantages of deep learning with MFL testing theory and related features has great application potential for solving existing problems in the industrial NDT field, such as the need for high-precision location, classification, and quantification of defects.\nIn this article, we propose a doubly fed cross-residual deep neural network (DfedResNet) suitable for MFL defect detection based on deep learning. The physics-informed DfedResNet can automatically extract deep features from defects and achieve high-precision defect length, width, and depth quantification. In terms of a physics-informed network, a doubly fed structure is used to simulate the operator\u2019s defect quantification logic. In addition, we adopt discrete convolution operations using the Sobel operator to enhance the network\u2019s physical understanding. Moreover, a 3-D synchronous quantification method is then used to achieve the mutual coupling of various quantification factors (length, width, and depth) and solve the problem of the low quantification accuracy for defect depth.\nThe rest of this article is organized as follows. Section II describes the steps in the construction of an MFL defect dataset, including data collection from a traction test, defect data extraction, and data augmentation. Section III describes the MFL quantification theory, explain the improvement of the network structure, and highlight how the \u201cphysics-informed\u201d works in the DfedResNet\u2019s training. Section IV describes the training process is introduced, and the training results are reported. Subsequently, the performances of various network structures and traditional algorithms for defect quantification are compared and discussed. Finally, Section VI concludes this article. We hope that this article will enable the effective application of deep learning in NDT from the perspective of physical knowledge."
        },
        {
            "heading": "II. DATASET COLLECTION",
            "text": "When a deep neural network is to be used for MFL defect detection, a sufficiently large dataset is required to capitalize on its advantages; however, obtaining sufficient experimental data is almost always difficult. Although it is possible to obtain defect data from a pipeline length of over 100 km from an actual engineering inspection, it is almost impossible to obtain accurate values for all the defect sizes. In contrast, using a finite length of the traction-test pipeline (approximately 100 m), the number of artificial defects with precise sizes that can be created is limited. Therefore, for dataset collection, a certain amount of pipeline\ninspection data was first collected; then, the defect data were extracted and labeled; and finally, the MFL dataset was enhanced through data augmentation techniques."
        },
        {
            "heading": "A. Experimental Data Acquisition",
            "text": "To obtain the experimental data, an X65 stainless steel pipe with a diameter of 273 mm and a wall thickness of 5 mm was selected for a traction test. The pipeline contained 243 standard artificial defects, with lengths and widths ranging from 10 to 50 mm and depths ranging from 10 to 50% t, where t denotes the thickness of the pipe wall. Fig. 1(a) shows the actual traction system and the MFL pipe inspection gauge (PIG) used. As shown in Fig. 1(b), the MFL-PIG consists of four main sections described as follows:\n1) A battery section that provides power for the MFL-PIG during the inspection process, ensuring an uninterrupted energy supply throughout the entire detection process. 2) A recording section that saves the magnetic and nonmagnetic data collected by the sensors and control, collects and records the signals from the sensors through the pulses periodically obtained by the mileage wheel. 3) A detection section that converts the MFL signal of a defect in the pipeline into an electrical signal and collects some necessary nonmagnetic data (such as temperature, speed, pressure, and mileage). This section is mainly composed of a magnetization device, various sensors, and signal processing circuits. The magnetization device uses permanent magnets to magnetize the tube wall to a near-saturation state to generate a magnetic leakage signal at the defect. A hall sensor uses the potential difference produced by the Hall effect to detect the magnitude of the leakage magnetic field, and the signal processing circuits\namplify and filter the signals to improve the signal-tonoise ratio. 4) A navigation section that drives the detector to move forward through the pipeline by relying on the pressure difference between the fluid ahead and behind the PIG. This section is mainly composed of multiple sets of leather bowls. The above sections are connected by Cardan joints to improve the ability of the detector to pass through deformed sections of the pipeline. During the inspection, the sampling rate of the sensors was 1 mm per scan, and the circumferential spacing of each channel was 2.7 mm. Fig. 1(c) shows examples of x-axis magnetic signals obtained as part of the detection data. Defect photographs corresponding to each detection signal are also shown. These standard defects are precision processed by electron discharge machining machine tools. The length and width processing error for a given defect is less than 4 \u03bcm, and the depth error is less than 0.01% t. By observing the amplitudes and sizes of the signals, it can be found that these four defects have different cross-sectional sizes and depths. After the MFL-PIG had successfully collected the pipeline inspection data, further defect information extraction was conducted."
        },
        {
            "heading": "B. Defect Data Extraction",
            "text": "The data collected by the MFL-PIG included signals of various defects as well as signals indicating no defects. However, a dataset to be used for network training must contain standardized data. Therefore, the original inspection data was processed to extract the defect information. Fig. 2 shows a flowchart of the dataset construction process and a schematic diagram corresponding to each step.\nFirst, it was necessary to locate and identify the defects in the input data; we used a threshold-based method for defect data extraction. As shown in Fig. 2, the magnitudes of the magnetic data values were compared between each data point and the average value of the channel in which the point was located. If the current value was 10% higher than the average value and at least one adjacent data point also satisfied this condition, the point was judged as valid defect data. Thereafter, a set of such valid defect data points was taken as a defect set. To separate the data for different defects, the following method was used: if the number of nondefect data points between two valid defect data points exceeded a certain distance (ten scans or two channels), those defect points were judged to belong to two different defect sets.\nTo train a deep neural network, the input data must all have the same structure before they can be fed into the network. However, as Fig. 2 shows, the size of each defect set was different; thus, it was necessary to standardize the defect data. To this end, the center of each original defect dataset was taken as the center of the corresponding new standardized set; then, all the detection data from the 31 channels and 81 scans around it were extracted to form the standardized defect dataset. In addition, data size normalization was ensured by performing data interpolation in the circumferential direction. Notably, these datasets included not only the x-axis magnetic data but also the y- and z-axis data. In addition, although the shape of each defect dataset was (81, 81, 3), the data were not treated as an image during the preprocessing and training process; instead, the magnetic data values of the original detection signals were directly used, thereby preserving as much of the information contained in the collected signals as possible for subsequent defect feature extraction to improve the quantization accuracy.\nNext, each set of defect data needed to be correctly labeled in accordance with the processing drawings for the defect, including its length, width, depth, hours, and mileage, as shown in\nFig. 2. Finally, the extracted, standardized, and labeled three-axis magnetic data were stored in a standardized format and used as the input to the network."
        },
        {
            "heading": "C. Data Augmentation",
            "text": "Due to the limited number of the artificial defects, it is difficult to create a dataset sufficiently large to meet the requirements for training of a deep neural network. Therefore, augmentation methods were applied to expand the dataset. Peng proposed an interpolation operation for MFL signals based on the premise that for defects with the same length and width, the MFL signal intensity is approximately linear with the defect depth [17]. The length and width increments of the artificial defects were 5 mm, the depth increment was 20% t, and there were 243 defects in total. Accordingly, by using the depth interpolation method expressed in (1) and (2) with the depth increment set to 1% t, the number of defect datasets was increased from 243 to 3321. Thus, the dataset was augmented by more than a factor of 13 to meet the requirements for training a deep learning model:\nBj30 \u2212Bj10 30 \u2212 10 i+Bj10 = Bji (i = 11, 12, . . . , 29;j = x, y, z)\n(1)\nBj50 \u2212Bj30 50 \u2212 30 i+Bj30 = Bji (i = 31, 32, . . . , 49;j = x, y, z)\n(2)\nwhere Bji denotes the j-axis magnetic data for the defect with a depth of i% t."
        },
        {
            "heading": "III. PHYSICS-INFORMED DFEDRESNET DESIGN",
            "text": ""
        },
        {
            "heading": "A. MFL Quantification Theory",
            "text": "Before considering the integration of physical information into neural networks, it is necessary to analyze the MFL defect\nquantification theory. The current feasible MFL defect quantification is generally carried out for the length and width with low accuracy, and the actual depth cannot be accurately judged due to its inconsistent characteristics. Nevertheless, it is still necessary to obtain defect length and width values first before back propagation of network errors. This process is essential for correcting the quantitative logic of the neural network from the perspective of physical knowledge.\nThe MFL analytical model is usually established based on the magnetic dipole method, and Fig. 3 shows the magnetic dipole model of a general rectangular defect.\nAssume that the magnetic dipoles are evenly distributed on the defect surface along the magnetization direction, for each magnetic charge element dp = \u03c3s y z, the element magnetic field dH at a distance r is given as\ndH= dp\n4\u03c0r3 \u00b7 r (3)\nwhere \u03c3s is the surface magnetic charge density, the x-axis direction is denoted as the magnetization direction, and the z-axis direction is perpendicular to the specimen surface. By integrating the element magnetic field dH generated by each magnetic dipole, H(x, y, z) can be calculated:\nH(x, y, z) = \u222b\u222b S dH (x, y, z) = \u222b\u222b S dp 4\u03c0r3 \u00b7 r. (4)\nFor a rectangular defect with size l\u00d7w\u00d7d, the x-component and y-component of magnetic leakage fields are given by\nH(l,w,d)x (x, y, z)\n= \u03c3s 4\u03c0 \u222b 0 \u2212d \u222b w/2 \u2212w/2\n\u239b \u239c\u239d\nx+l/2 ((x+l/2)2+(y\u2212y\u2032)2+(z\u2212z\u2032)2)3/2 \u2212\nx\u2212l/2 ((x\u2212l/2)2+(y\u2212y\u2032)2+(z\u2212z\u2032)2)3/2\n\u239e \u239f\u23a0dy\u2032dz\u2032\n(5)\nH(l,w,d)y (x, y, z)\n= \u03c3s 4\u03c0 \u222b 0 \u2212d \u222b w/2 \u2212w/2\n\u239b \u239d y\u2212y\u2032 ((x+l/2)2+(y\u2212y\u2032)2+(z\u2212z\u2032)2)3/2\n\u2212 y\u2212y\u2032\n((x\u2212l/2)2+(y\u2212y\u2032)2+(z\u2212z\u2032)2)3/2\n\u239e \u23a0dy\u2032dz\u2032.\n(6)\nAssuming an odd function in quantifying the defect length:\ng (x)\n= \u03c3s 4\u03c0 \u222b 0 \u2212d \u222b w/2 \u2212w/2\n\u239b \u239c\u239d x(\nx2 + (y \u2212 y\u2032)2 + (z \u2212 z\u2032)2 )3/2\n\u239e \u239f\u23a0dy\u2032dz\u2032.\n(7)\nWe can obtain\nH(l,w,d)x (x, y, z) = g (x+ l/2) + g (\u2212x+ l/2) (8) and\ng\u2032 (x) = \u03c3s 4\u03c0 \u222b 0 \u2212d \u222b w/2 \u2212w/2\n\u239b \u239c\u239d (y \u2212 y\u2032)\n2+(z \u2212 z\u2032)2 \u2212 2x2( x2+(y \u2212 y\u2032)2+(z \u2212 z\u2032)2\n)5/2 \u239e \u239f\u23a0dy\u2032dz\u2032\n\u2264 \u03c3s 4\u03c0 \u222b 0 \u2212d \u222b w/2 \u2212w/2\n\u239b \u239c\u239d (y\u2212y\u2032)\n2+(z\u2212z\u2032)2( (y\u2212y\u2032)2+(z\u2212z\u2032)2\n)5/2 \u239e \u239f\u23a0dy\u2032dz\u2032=g\u2032(0) .\n(9)\nWe can see from (9) that when x = 0, the slope of g(x) is the largest. Therefore, when x= l/2, Hx(x) has a component g(x+l/2) with the maximum slope, and the slope of g(\u2212x + l/2) has less influence than the former. Therefore, Hx(x) have a maximum slope near x = l/2. Combined with the odd function features of g(x), it can be inferred that the minimum slope of Hx(x) will appear near x = \u2212l/2.\nIn fact, at the edge of the defect, the wall thickness of the ferromagnetic material suddenly decreases, where the magnetic field will change sharply. The maximum/minimum value of the MFL signal\u2019s slope appears near the defect length\u2019s edges, which can provide a reference for the quantification of the defect length and guide the neural network\u2019s training logic. In addition, the errors in the above theory will also be corrected in the network training.\nAssuming a function h(x, y) in quantifying the defect width:\nh (x, y) = \u03c3s 4\u03c0 \u222b 0 \u2212d\n\u239b \u239c\u239d 1(\nx2 + y2 + (z \u2212 z\u2032)2 )1/2\n\u239e \u239f\u23a0dz\u2032. (10)\nSimilar to the length quantification, we can get\nH(l,w,d)y (x, y, z) = h (x+ l/2, y + w/2)\n\u2212 h (x+ l/2, y \u2212 w/2) \u2212 h (x\u2212 l/2, y + w/2) + h (x\u2212 l/2, y \u2212 w/2) (11)\nh (x, y) \u2264 \u03c3s 4\u03c0 \u222b 0 \u2212d\n\u239b \u239c\u239d 1(\n(z \u2212 z\u2032)2 )1/2\n\u239e \u239f\u23a0dz\u2032=h (0, 0) .\n(12)\nIt can be seen from (12) that when x = y = 0, the value of h(x, y) is the largest. Moreover, when (x, y) are, respectively, at the four vertices of the rectangular defect, namely (\u2212l/2, \u2212w/2), (\u2212l/2, w/2), (l/2, \u2212w/2), and (l/2, w/2), Hy(x, y) has maximum, minimum, minimum, and maximum components, respectively. Compared with the maximum value, the influence of other components is smaller. Therefore, near the above four points of the defect, the vertical component of the MFL signal will have its maximum/minimum value.\nIn general, by calculating the x-axis signal\u2019s first derivative threshold and the y-axis signal\u2019s threshold positions based on the above equations, we can obtain the theoretical value of defect length and width. However, theoretically speaking, errors still exist in the quantification of defect length and width, and it is difficult to apply it to the prediction of defect depth. In addition, the data collected by the PIG in the actual engineering contains noise and sudden changes, which will weaken the theoretical quantification accuracy of the defect size. Therefore, we can use the automatic extraction capabilities of deep neural networks\nto compensate for the shortcomings of traditional quantification theories."
        },
        {
            "heading": "B. Network Architecture Design",
            "text": "Traditional CNNs have achieved outstanding successes in various fields in computer vision because of their ability to gradually and automatically extract image features through local receptive fields [18], [19]. However, it is difficult to use a CNN to identify defects directly and further quantify them because of the difficulty of recognizing and interpreting in MFL signal images. Therefore, to maximize the retention of the defect features, we standardized the input to the network in this article, and the input values consisted of the magnetic field intensity data collected by the sensor.\nFig. 4 shows the proposed DfedResNet structure, which can be divided into three parts: the initial layer, the cross-residual layer, and the doubly fed regression layer. The proposed method is a physics-informed deep learning model based on neural network\nas the backbone, MFL testing theory as the mechanism, and a large number of actual experiments as the big data support. To extract the deep features of the input MFL defect data, we propose a 17-layer deep neural network called DfedResNet, which contains weight-updated layers, including convolutional layers, pooling layers, fully connected layers, and batch normalization layers, as well as static layers such as flatten layers and a preprocessing layer. The convolutional layers automatically learn the features of the input data at various levels and perform dimensionality reduction and feature extraction on the input through convolution operations. In addition, the smaller initial receptive fields capture the local and detailed information from the input data, while the receptive fields of the subsequent convolutional layers increase layer by layer to capture more complex and abstract information. After multiple convolutional layer operations, abstract representations of the input data at various scales are obtained [14]. Then, the pooling layers use a downsampling method to further reduce the dimensionality of the data based on the output from the convolutional layers. We use maximum pooling (max-pooling) layers to reduce the model size, increase the calculation speed, reduce the probability of overfitting, and improve the network\u2019s robustness for feature extractions. In a dense layer (or a fully connected layer), all the input and output nodes are connected, and such a layer can be regarded as the \u201cclassifier\u201d of a neural network. The regression output of the last dense layer represents the characteristics of the input data in accordance with certain defined labels, such as the length, width, and depth of a defect. A batch normalization layer normalizes its input through transformation and reconstruction, thereby substantially improving the speed of network training and convergence, without the need for dropout or special parameter initialization, which reduces the complexity of hyperparameter debugging. The forward propagation process in a batch normalization layer can be expressed as follows [20]:\n1 \u03b1 \u03b1\u2211 i=1 xi \u2192 \u03bc \u2192 1 \u03b1 \u03b1\u2211 i=1 (xi \u2212 \u03bc)2 \u2192 \u03c32 (13) xi \u2212 \u03bc\u221a \u03c32 + \u03b5 \u2192 x\u0302i \u2192 \u03b3x\u0302i + \u03b2 \u2261 BN\u03b3,\u03b2 (xi) \u2192 yi (14)\nwhere (13) calculates the mean value and variance of the batch, (14) normalizes, scales, and shifts the data, \u03b1 is the number of minibatches, \u03b5 is a constant added to the variance of the minibatch data, and\u03b3 and\u03b2 are learnable identity transformation parameters.\nIn DfedResNet, the initial layer includes an input layer, a preprocessing layer, a convolutional layer, a max-pooling layer, and a batch normalization layer. The inputs to the network are formatted as tensors with a shape of (100, 81, 81, 3), where 100 is the batch size, 81\u00d781 is the size of the data matrix for a defect, and 3 represents the number of spatial axes (x, y, and z) of the detection data. To further extract defect information and filter out redundant data, the preprocessing layer subtracts the base signal corresponding to the absence of a defect from each set of input data, and outputs the calculated result. The subsequent convolutional and pooling layers perform the initial extraction of defect information to ensure that the initial layer is trainable.\nAs shown in Fig. 4, the cross-residual layer includes two discrete convolution operations, four convolutional layers, four max-pooling layers, and two batch normalization layers. In MFL testing, although it is relatively easy and intuitive to quantify the length and width of a defect, it is more difficult to quantify the defect depth accurately. This is because the length and width information of a defect correspond to the position information in the detection data, which can be extracted via a simple threshold-based method [21]. Defect depth, which is an important index for evaluating the health of a sample, is difficult to quantify with high accuracy. Therefore, the defect depth estimation requires complex methods. A previous study on depth estimation revealed that the quantization accuracy is unsatisfactory because identifying the depth of a defect requires information such as its length, width, and signal amplitude to be comprehensively considered [22]. In other words, the same defect signal may correspond to different combinations of defect dimensions [23]. Therefore, based on the above analysis, the depth of a defect is accurately quantified by first determining the length and width of the defect and then using the additional features from the input data. Accordingly, in the cross-residual layer, the two discrete convolution operations are used to extract the horizontal and vertical features of the data using the Sobel operator [24]; these features correspond to the length and width of the defect, respectively. In addition, because the discrete convolutions are not updated during network training, to avoid feature information loss during the initial training stage and overfitting caused by redundant information later in the training process, cross-residual connections are adopted in this layer to accelerate error backpropagation and improve the training speed and performance [25]. Overall, the cross-residual layer separately extracts the length and width information from the defect data and improves the training speed and performance through identity mapping.\nTheoretically, when quantifying defect depth, it is necessary to obtain the length and width information in advance. Therefore, the doubly fed regression layer concatenates the two output tensors from the cross-residual layer to form the input to the defect depth discrimination network and more accurately quantify defect depth. The doubly fed regression layer includes two convolutional layers, two max-pooling layers, one batch normalization layer, and nine dense layers. The network loss function includes all three quantitative indicators, making it possible to simultaneously estimate the length, width, and depth of defects while improving the quantization accuracy, and thereby avoiding the time-consuming and incomplete feature extraction shortcomings of methods based on multiple regression calculations [7]."
        },
        {
            "heading": "C. Physical Consistency in Model\u2019s Loss Function",
            "text": "Differences between the forward calculation result of each iteration of the neural network and the true value are calculated in loss functions; thus, it guides the next training in the correct direction:\nargmin f\n{Loss (Opred,Oreal)} . (15)\nWe can now introduce a term using physical concepts based on (5, 6) and (9, 12) in the neural network loss function as shown in (16):\nargmin f\n{Loss (Opred,Oreal)\n+\u03bbphysLoss.PHY (Opred,Ophys)} (16)\nwhere \u03bbphys represents the weight of physical concepts in neural network training, and the first item in (16) is the experience loss item using the mean square error (MSE), the second term denotes the inconsistency loss between the predictions and theoretical results. Real labels and theoretical features both contribute to the network training: the introduction of theoretical values can correct \u201cbad labels,\u201d prevent the network from learning features that we do not concern about, and still have better performance and generalization capabilities under small datasets such as the NDT field. As shown in Fig. 4, physics-informed hybrid losses are introduced in DfedResNet, which improve the network structure and guide the training of the network accordingly."
        },
        {
            "heading": "IV. NETWORK TRAINING AND RESULTS",
            "text": "Network training and reasonable hyperparameter settings are important factors in improving network performance. The number of filters and the kernel size for each convolutional layer are specified in Fig. 4, and a rectified linear unit nonlinear activation function is applied after convolution [26]. In addition, the maxpooling operation for 2-D spatial data is used to downsample the input representation by taking the maximum value over a window with a (2, 2) pooling size; this window is shifted by a stride of two pixels in each dimension, and the padding mode is set to \u201csame.\u201d To improve the generalizability of DfedResNet, in this article, the entire dataset was divided into a training set, a validation set, and a test set at a ratio of 8:1:1. Moreover, the Nadam (Adam [27] with Nesterov momentum) optimizer was selected in preference of traditional training optimization algorithms and the learning rate was set to 0.0001. Adopting the Nesterov momentum vector rather than the traditional momentum vector in Adam places stronger constraints on the learning rate and has a more direct impact on the updating of the gradient. To make the model approach the local or global optimal solution, a learning rate decay was used to ensure that the loss would not undergo large fluctuations during the later training stages. During network training, the number of training epochs with no improvement was limited to 10, and the learning rate decay was set to 0.5. Furthermore, to increase the training efficiency and reduce model overfitting, an early stopping method was applied for network training, and the best network weight was saved when the training was stopped. MSE loss was used to solve the regression problem for defect quantification. We used Google\u2019s open-source deep learning platform TensorFlow because of its streamlined and flexible interface design, which provides the ability to quickly build network models and achieve rapid deployment in industrial systems. The software versions we used were TensorFlow 2.4, CUDA 11.1, and Python 3.8. The\nhardware platform parameters were as follows: an i9-10900K CPU, an RTX-3080 GPU, and 64 GB of memory.\nFig. 5 shows the training results for the proposed DfedResNet model, including the initial layer, cross-residual layer, and doubly fed regression layer, obtained by feeding the three-axis defect data shown at the top left into the network. The base values were subtracted from the data for each axis in the preprocessing layer; subsequently, the sigmoid activation function was used to convert the data tensors into figures (for display purposes only), and the results were then multiplied by 255. Note that these figures are merely a form of visualization, not the data themselves. For the initial figure, the red, green, and blue colors correspond to the x-, y-, and z-axis data, respectively. For the output images of the subsequent layers, the first three channels were used to generate the RGB values for display. Fig. 5 shows that the cross-residual layer initially extracts the basic features of the input (length and width), and then, through tensor concatenation and convolution, the doubly fed regression layer further identifies the higher level features of the data, such as the characteristics related to the defect depth. The output predictions of the network indicate that the size of the defect used for this example is 40.1786 mm\u00d7 44.8861 mm\u00d7 16.1475% t. Based on the generated data labels, as shown in Fig. 2, the labeled size of this defect is 40 mm \u00d7 45 mm \u00d7 16% t, which is extremely close to the network\u2019s output.\nFig. 6 shows the evolution of the loss and the learning rate decay on the training and validation datasets throughout the network training process. The learning rate decayed by half in the 73, 84, 104, and 139 epochs, and early stopping was triggered in the 150th epoch, at 134th epoch the best weights were saved. As the training and testing losses show, the model converges quickly and successfully without overfitting. Based on the network prediction results shown in Fig. 6, the mean prediction errors for the defect length and width are both within 0.3 mm, and the prediction error for the defect depth is less than 0.4% t. Because the defects studied in this article are all standard artificial defects, the MFL defect signal is relatively smooth; therefore, the quantization accuracy of the defect can be less than the sampling interval. Therefore, the deep DfedResNet model proposed in this article can adaptively and synchronously extract the deep features of defects and demonstrates very high quantitative performance.\nAiming at the black box problem of deep NN, the network\u2019s design basis is verified and explained visually using the popular interpretable method named Grad-CAM++ [28]. We calculated the network\u2019s gradients using a single backpropagation to obtain the saliency maps. Fig. 7 shows the saliency maps for defect length, width, and depth estimation. Compared with Fig. 4, the saliency maps in Fig. 7 have better interpretability. Fig. 7 shows that DfedResNet effectively identifies the signal features of defects and increase the weights associated with these features. In other words, the network\u2019s attention effectively shifts based on the training goal: when estimating defect length and width, the network\u2019s weights are automatically concentrated on the axial and circumferential boundaries. In addition, when estimating defect depth, the network\u2019s weights are both concentrated on the boundaries and amplitudes."
        },
        {
            "heading": "V. DISCUSSION OF DIFFERENT METHODS",
            "text": "To verify the advantages of the DfedResNet model proposed in this article, we considered different network structures to verify the contribution of the doubly fed cross-residual structure of the model and to demonstrate the advantages of using threeaxis input data for defect quantification. Figs. 8(a)\u2013(i) shows the training results for a uniaxial CNN (with only convolutional and dense layers), a three-axis CNN, and the proposed DfedResNet. The horizontal axis in each figure shows the defect signal label, while the vertical axis shows the value predicted by the network. The blue baseline represents the case in which the predicted\nresult is exactly equal to the actual defect size. By comparing the degree of dispersion of these data points, it can be found that the DfedResNet model proposed in this article yields the best quantitative accuracy. During network training, we repeated the training process for each network three times and averaged the prediction results to reduce the influence of random factors. The training and test results are listed in Table I, which shows that better defect quantification accuracy is achieved by using the inspection data from all three dimensions, resulting in an error between two and three times smaller than that of the prediction results based on data from a single axis (the x-axis). In addition, the prediction error of the doubly fed cross-residual structure network used in this article is significantly smaller\u2014by a factor of 5\u201310\u2014than the prediction error of the aforementioned three-axis CNN. These comparisons prove the effectiveness of the proposed DfedResNet architecture for the high-precision quantification of defects.\nIn this article, to verify the advantages of the proposed DfedResNet compared to the traditional methods used in industrial applications, we also used the same dataset to test several different defect quantification methods that have previously been proposed. To our knowledge, VT-CNN, which adaptively rotates the 3-D structures of defects to perform defect quantification [7], is the most advanced algorithm available for this purpose at\npresent. In addition to VT-CNN, we also compared our method with a support vector machine [29] and a backpropagation neural network [30] to quantify the defects in the same dataset. Table II shows the prediction errors of these algorithms, from which it can be seen that the DfedResNet model proposed in this article has obvious advantages in defect quantification, with an average error 9\u201318 times lower than those of both the advanced VT-CNN algorithm and the traditional methods."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "To address the problems presented by MFL-NDT in industrial applications, we proposed a physics-informed DfedResNet suitable for defect detection. We first extended deep learning theory to the MFL field and improved it to make it suitable for MFL defect inspection based on the ability of deep CNNs to\nautomatically extract high-level features from input defect data for defect size prediction. Besides, we studied the physics-based MFL defect quantification theory and integrated it into loss functions during the neural network training. In addition, based on the multiple combined characteristics of defect depth, length, and width, we developed a DfedResNet structure that effectively reduces the MFL defect quantization error by a factor of 5\u201310 relative to the theoretical level achievable by a basic CNN. For network training, we use detection data from all three dimensions as the network input and also used the actual detection data in place of the traditional MFL image pixel values, thereby further reducing the defect quantization error by a factor of 2\u20133 by avoiding defect information loss. Ultimately, the DfedResNet model proposed in this article reduces the quantization errors for defect length and width to within 0.3 mm and the quantification errors for defect depth to within 0.4% t. These results demonstrate the effectiveness of the proposed network structure.\nDue to the difficulty of quantitatively describing actual defects and limitations of the detector model, this article does not involve quantifying real defects with complex contours, or a quantification algorithm to address pipelines of different sizes. In the future, deep NNs could be developed based on the reconstruction method of complex defect opening contours. Therefore, a comprehensive analysis of pipeline inspection data consisting of different pipe diameters should be performed to obtain a quantitative strategy for MFL testing with generalizable capabilities."
        }
    ],
    "title": "Development of a Physics-Informed Doubly Fed Cross-Residual Deep Neural Network for High-Precision Magnetic Flux Leakage Defect Size Estimation",
    "year": 2021
}