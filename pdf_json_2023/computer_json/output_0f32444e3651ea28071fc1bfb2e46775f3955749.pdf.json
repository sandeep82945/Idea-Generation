{
    "abstractText": "The study of ancient documents provides a glimpse into our past. However, the low image quality and intricate details commonly found in these documents present significant challenges for accurate object detection. The objective of this research is to enhance object detection in ancient documents by reducing false positives and improving precision. To achieve this, we propose a method that involves the creation of synthetic datasets through computational mediation, along with the integration of visual feature extraction into the object detection process. Our approach includes associating objects with their component parts and introducing a visual feature map to enable the model to discern between different symbols and document elements. Through our experiments, we demonstrate that improved object detection has a profound impact on the field of Paleography, enabling in-depth analysis and fostering a greater understanding of these valuable historical artifacts. Document Image Analysis, Ancient Document, Feature Extraction and Transformer Model:",
    "authors": [
        {
            "affiliations": [],
            "name": "Zahra Ziran"
        },
        {
            "affiliations": [],
            "name": "Francesco Leotta"
        },
        {
            "affiliations": [],
            "name": "Massimo Mecella"
        }
    ],
    "id": "SP:9bdfc36129861664f74bff051d89c4ad7c3d661f",
    "references": [
        {
            "authors": [
                "M. Boccuzzi",
                "T Catarci"
            ],
            "title": "Identifying, Classifying, and Searching Graphic Symbols in the NOTAE System",
            "venue": "Communications in Computer and Information Science,",
            "year": 2020
        },
        {
            "authors": [
                "Z. Ziran",
                "E Bernasconi"
            ],
            "title": "Accurate Graphic Symbol Detection in Ancient Document Digital Reproductions",
            "venue": "Lecture Notes in Computer Science",
            "year": 2021
        },
        {
            "authors": [
                "H. Edwards",
                "A. Storkey"
            ],
            "title": "Towards A Neural Statistician",
            "venue": "5th International Conference on Learning Representations (ICLR),",
            "year": 2017
        },
        {
            "authors": [
                "Girshick",
                "Ros"
            ],
            "title": "Faster r-CNN",
            "venue": "Proceedings of the IEEE international conference on computer vision,",
            "year": 2015
        },
        {
            "authors": [
                "J. Huang",
                "V Rathod"
            ],
            "title": "Speed/accuracy trade-offs for modern convolutional object detectors",
            "year": 2017
        },
        {
            "authors": [
                "J. Lee",
                "Y Lee"
            ],
            "title": "Set Transformer: A Framework for Attention-based Permutation-Invariant",
            "venue": "Neural Networks. 36th International Conference on Machine Learning (ICML),",
            "year": 2019
        },
        {
            "authors": [
                "M. Phuong",
                "M. Hutter"
            ],
            "title": "Formal algorithms for transformers",
            "venue": "Technical report,",
            "year": 2022
        },
        {
            "authors": [
                "A.R. Kosiorek",
                "S Sabour"
            ],
            "title": "Stacked Capsule Autoencoders",
            "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS),",
            "year": 2019
        },
        {
            "authors": [
                "F. Pedregosa",
                "G Varoquaux"
            ],
            "title": "Scikit-learn: Machine Learning in Python",
            "venue": "Journal of Machine Learning Research,",
            "year": 2014
        },
        {
            "authors": [
                "M. Ankerst",
                "M.M Breunig"
            ],
            "title": "OPTICS: Ordering Points to Identify the Clustering Structure",
            "venue": "In Proceedings of the 1999 ACM SIGMOD International Conference on Management of Data,",
            "year": 1999
        },
        {
            "authors": [
                "J.Y. Zhu",
                "T Park"
            ],
            "title": "Unpaired Image-to-Image Translation using Cycle",
            "venue": "Consistent Adversarial Networks",
            "year": 2017
        },
        {
            "authors": [
                "B.M. Lake",
                "R Salakhutdinov"
            ],
            "title": "Human-level concept learning through probabilistic program induction",
            "venue": "In Science;",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 7.\n16 00\n5v 1\n[ cs\n.C V\n] 2\n9 Ju\nl 2 02\nThe study of ancient documents provides a glimpse into our past. However,\nthe low image quality and intricate details commonly found in these documents\npresent significant challenges for accurate object detection. The objective of this\nresearch is to enhance object detection in ancient documents by reducing false\npositives and improving precision. To achieve this, we propose a method that in-\nvolves the creation of synthetic datasets through computational mediation, along\nwith the integration of visual feature extraction into the object detection pro-\ncess. Our approach includes associating objects with their component parts and\nintroducing a visual feature map to enable the model to discern between differ-\nent symbols and document elements. Through our experiments, we demonstrate\nthat improved object detection has a profound impact on the field of Paleogra-\nphy, enabling in-depth analysis and fostering a greater understanding of these\nvaluable historical artifacts.\nDocument Image Analysis, Ancient Document, Feature Extrac-\ntion and Transformer Model:"
        },
        {
            "heading": "1 Introduction",
            "text": "The study of ancient documents is crucial for understanding the past and making these valuable resources accessible to a wider audience. Accurate object detection in these documents is essential for deciphering their content and context [1, 2]. However,\nthe unique characteristics of ancient documents, such as faded or damaged text, nonstandardized writing systems, and complex layouts, make object detection a challenging task. In this paper, we propose a novel method for improving object detection in ancient documents by leveraging synthetic data generation, transformer-based models, and tokenization techniques [3]. Our proposed method involves extracting visual features through tokenization and defining an optimization task to fit a transformer model on graphic symbol data for the image classification task. This approach is designed to capture the unique characteristics of ancient documents and enhance classification accuracy. We then use the image classifier with a fast search method to gather object detection annotations and train a Faster R-CNN model [4, 5]. A critical aspect of our method is the generation of an identical synthetic dataset, which is essential for accurate object detection. The resulting dataset is paired with the original data, creating a dictionary-like relationship. This relationship is useful for approximating continuous functions that transform vectors from the vector space of objects into the vector space of geometrical trapezoids, thus preserving the inherent structure and characteristics of the ancient documents. We present a symbol-level tokenization scheme, where X is a binary image that is transformed by replacing each element with a tuple of its pixel index in the image. By integrating synthetic data generation, transformer-based models [6, 7], and tokenization techniques, our method aims to enhance object detection in ancient documents, by learning the map between representations at part-level and object-level, [8]. In the section 2, we provide a pseudo-code algorithm to demonstrate the feature extraction process and showcase how our method is implemented."
        },
        {
            "heading": "2 Materials and Methods",
            "text": "The proposed method consists of a multi-step algorithm for detecting and classifying graphical symbols in images. In the first step, the input image is preprocessed to remove noise and convert it to a binary format. This is achieved by applying a series of image processing techniques [9], including thresholding and morphological operations. Next, the image is segmented into stroke segments, which are defined as contiguous regions of black pixels in the binary image. The coordinates of these stroke segments are then clustered using the OPTICS algorithm [10], which automatically identifies spatially related groups of stroke segments. A centroid is computed for each cluster by taking the average of the coordinates of the points in the group.\nTo create variable stroke thickness, two circles with variable radii are constructed at each end of the stroke segment. For each cluster, a circle is defined by calculating the centroid and its associated radius. The radius is determined by computing the mode of an array of Euclidean distances between the centroid and all other points in the cluster. The centroids and radii are then used to construct trapezoids that represent the strokes of the graphical symbols. The trapezoid vertices are defined as the intersecting points of the trapezoid sides with the perimeter outlines of the centroids. The trapezoids\u2019 vertex labels are oriented in a clockwise manner so that trapezoids from all clusters have the same orientation relative to the image area. The density of each trapezoid is computed by counting the foreground pixel values that are trapped inside the shape and dividing the sum by the area of the trapezoid. The resulting feature vector of a trapezoid includes four vertices and one brightness density related to the shape. The location of a bounding box is fully described by a set of affine transformations, which are subject to four axioms: closure, associativity, identity, and inverse. The affine transformations are used to approximate the transform T that maps the original image to the bounding boxes of the graphical symbols. The inverse of transform T is used to build a database of paired instances for producing synthetic training data [11][12]."
        },
        {
            "heading": "2.1 step-by-step pseudo-code algorithm",
            "text": "In this section, we provide a step-by-step pseudo-code algorithm for our proposed method for feature extraction in ancient documents.\n1. Perform random sampling on the binary image, obtaining an array of coordinates.\n2. Cluster the samples from step 1 using the OPTICS algorithm with minimum points set to 5 and epsilon set to infinity. Calculate the centroids for each cluster by taking the average of the coordinates of the points in the group.\n3. Connect the calculated centroids to construct trapezoids.\n4. For each cluster i, create a circle ci centered on the cluster core point and with a radius ri equal to the mode of the Euclidean distances from ci to all other points in cluster i.\n5. Ignore noise points, which are not inside any centroid (negative labels).\n6. Repeat steps 4 and 5 for cluster i, where i runs over from 1 till all clusters are iterated.\n7. Calculate the radii of the centroids using the mode of an array of distances to the centroid.\n8. Transform the image of the symbol into the number of clusters (NC).\n9. Link centroids ci and cj with a straight line and draw a pair of trapezoid sides, each perpendicular to the connecting segment, one containing centroid ci and the other containing centroid cj .\n10. Define the intersecting points of the trapezoid sides with the perimeter outlines of the centroids as vertices P 1, P 2, P 3, and P 4.\n11. Label the vertices such that the segment connecting P 1 to P 2 measures 2 \u00d7 ri in length and the segment connecting P 3 to P 4 measures 2 \u00d7 rj , where rj and rj are the corresponding radii related to centroids ci and cj , respectively.\n12. Rename the trapezoid vertices in a clockwise manner to ensure a consistent reference frame.\n13. Connect every pair of centroids ci and cj with a unique trapezoid.\n14. Trace each centroid back to the original image and calculate the density of each centroid by dividing the sum of the foreground pixel values by the area of the circle (\u03c0\u00d7r2) for a centroid, or by the area of the trapezoid ((ri+rj)\u00d7||ci\u2212cj||\n2) for a trapezoid.\n15. Create a feature vector for each trapezoid, including its four vertices and the brightness density related to the shape.\n16. Filter noise using the calculated trapezoid surface area as the basis.\nBy following these steps, the proposed method extracts feature from ancient documents, enabling accurate object detection and classification. This pseudo-code algorithm serves as a guideline for implementing the method in a scientific paper or research project.\nAlgorithm 1: Y \u2190 T(X|NT , dx)\nInput: X \u2208 Rdx\u00d7dx , vector representation of graphic symbols. Output: Y \u2208 Rdx\u00d7dx , updated representations of symbols in X, folding in\ninformation from their geometric shapes. Hyperparameters: NT \u2208 N, max number of trapezoids to visualize, dx,\nimage side length. 1 E \u2190 {(i, j)|i, j \u2208 {1, 2, ..., dx}, \u2200 i, j, X[i, j]}\n// Estimate clustering structure from vector array.\ncluster : Ndx \u00d7 dx \u00d7 2 \u2212\u2192 RNC \u00d7N... \u00d7 2.\n2 C \u2190 cluster(E)\n3 NC \u2190 length(C[:, 1, 1]) /* Count the number of clusters */\n4 for i = 1, 2, ..., NC do\n5 Ni \u2190 length(C[i, :, 1]) /* Count the points in cluster i */\n6 ci \u2190 1 Ni \u2211Ni k=1C[i, k, :] /* Calculate the center of cluster i */\n/* Calculate the radius of cluster j */\n7 ri \u2190 mode(magnitude([C[i, k, :]\u2212 ci)) for k \u2208 {1, 2, ..., Ni} 8 for j = 1, 2, ..., NC do\n9 Nj \u2190 length(C[j, :, 1]) /* Count the points in cluster j */\n10 cj \u2190 1 Nj \u2211Nj k=1C[j, k, :] /* Calculate the center of cluster j */\n/* Calculate the radius of cluster j */\n11 rj \u2190 mode(magnitude([C[j, k, :]\u2212 cj)) for k \u2208 {1, 2, ..., Nj} 12 P 1, P 2, P 3, P 4 \u2190 construct trapezoid(ci, ri, cj, rj) 13 M [i, j]\u2190 count foreground pixels(X, P 1[i, j], P 2[i, j], P 3[i, j], P 4[i, j]) 14 D[i, j]\u2190 calculate area(P 1[i, j], P 2[i, j], P 3[i, j], P 4[i, j])\n/* Calculate brightness density for trapezoid associated to i and j.\n*/\n15 S[i, j]\u2190 M [i,j] D[i,j]\n16 end\n17 end\n18 s\u2190 flatten(S) 19 p1,p2,p3,p4 \u2190 flatten(P 1), f latten(P 2), f latten(P 3), f latten(P 4) 20 sort((p1,p2,p3,p4, s), criteria = s, decreasingly = true)\n/* Draw NT trapezoids for a cleaner plot. */\n21 Y \u2190 plot trapezoid(p1[k],p2[k],p3[k],p4, s[k]) for k \u2208 {1, 2, ..., NT} 22 return Y"
        },
        {
            "heading": "3 Conclusion",
            "text": "The proposed method involves a multi-step algorithm for feature extraction, including preprocessing of the input image, segmentation of stroke segments, clustering of coordinates, and construction of trapezoids to represent graphical symbols. Synthetic data generation is used to create a paired dataset for accurate object detection. The method also incorporates transformer-based models and tokenization techniques to capture the unique characteristics of ancient documents. By following the step-by-step pseudo-code algorithm, researchers can implement the proposed method in their own projects and scientific papers. The algorithm provides guidance for extracting features from ancient documents and facilitating accurate object detection and classification. In conclusion, the presented method offers a valuable contribution to the field of document analysis by effectively tackling the difficulties caused by the low image quality and intricate details of ancient documents. Through the enhancement of object detection, researchers are empowered to delve deeper into the historical context and glean valuable insights from these invaluable resources. Moreover, the improved accessibility of ancient documents to a broader audience facilitates wider engagement and understanding of our past. To further expand the scope of its applicability, future research and experimentation can explore the potential of this method in various other domains of historical document analysis and digitization."
        }
    ],
    "title": "Enhancing Object Detection in Ancient Documents with Synthetic Data Generation and Transformer-Based Models",
    "year": 2023
}