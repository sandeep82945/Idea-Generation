{
    "abstractText": "A novel way of using neural networks to learn the dynamics of time delay systems from sequential data is proposed. A neural network with trainable delays is used to approximate the right hand side of a delay differential equation. We relate the delay differential equation to an ordinary differential equation by discretizing the time history and train the corresponding neural ordinary differential equation (NODE) to learn the dynamics. An example on learning the dynamics of the Mackey-Glass equation using data from chaotic behavior is given. After learning both the nonlinearity and the time delay, we demonstrate that the bifurcation diagram of the neural network matches that of the original system.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xunbi A. Ji"
        },
        {
            "affiliations": [],
            "name": "G\u00e1bor Orosz"
        }
    ],
    "id": "SP:d261a61948506e37c2002fdc0742e125c0197226",
    "references": [
        {
            "authors": [
                "S. Bai",
                "J.Z. Kolter",
                "V. Koltun"
            ],
            "title": "Deep equilibrium models",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "D. Breda",
                "S. Maset",
                "R. Vermiglio"
            ],
            "title": "Stability of linear delay differential equations: A numerical approach with MATLAB",
            "year": 2014
        },
        {
            "authors": [
                "S.L. Brunton",
                "J.N. Kutz"
            ],
            "title": "Data-driven science and engineering: Machine learning, dynamical systems, and control",
            "year": 2019
        },
        {
            "authors": [
                "R.T. Chen",
                "Y. Rubanova",
                "J. Bettencourt",
                "D. Duvenaud"
            ],
            "title": "Neural ordinary differential equations",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2018
        },
        {
            "authors": [
                "E. Dupont",
                "A. Doucet",
                "Y.W. Teh"
            ],
            "title": "Augmented neural ODEs",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "X. Glorot",
                "Y. Bengio"
            ],
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "venue": "In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics,",
            "year": 2010
        },
        {
            "authors": [
                "X.A. Ji",
                "T.G. Moln\u00e1r",
                "S.S. Avedisov",
                "G. Orosz"
            ],
            "title": "Feed-forward neural networks with trainable delay",
            "venue": "In Proceedings of the 2rd Conference on Learning for Dynamics and Control,",
            "year": 2020
        },
        {
            "authors": [
                "X.A. Ji",
                "T.G. Moln\u00e1r",
                "S.S. Avedisov",
                "G. Orosz"
            ],
            "title": "Learning the dynamics of time delay systems with trainable delays",
            "venue": "In Proceedings of the 3rd Conference on Learning for Dynamics and Control,",
            "year": 2021
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "Proceedings of the 3rd International Conference on Learning Representations",
            "year": 2015
        },
        {
            "authors": [
                "J. Koch",
                "T. Maxner",
                "V. Amatya",
                "A. Ranjbari",
                "C. Dowling"
            ],
            "title": "Physics-informed machine learning of parameterized fundamental diagrams. arXiv preprint arXiv:2208.00880",
            "year": 2022
        },
        {
            "authors": [
                "S.N. Kumpati",
                "P Kannan"
            ],
            "title": "Identification and control of dynamical systems using neural networks",
            "venue": "IEEE Transactions on Neural Networks,",
            "year": 1990
        },
        {
            "authors": [
                "X.D. Li",
                "J.K. Ho",
                "T.W. Chow"
            ],
            "title": "Approximation of dynamical time-variant systems by continuoustime recurrent neural networks",
            "venue": "IEEE Transactions on Circuits and Systems II: Express Briefs,",
            "year": 2005
        },
        {
            "authors": [
                "M.C. Mackey",
                "L. Glass"
            ],
            "title": "Oscillation and chaos in physiological control",
            "venue": "systems. Science,",
            "year": 1977
        },
        {
            "authors": [
                "C. Marcus",
                "R. Westervelt"
            ],
            "title": "Stability of analog neural networks with delay",
            "venue": "Physical Review A,",
            "year": 1989
        },
        {
            "authors": [
                "J.S. Pei",
                "E.C. Mai",
                "J.P. Wright",
                "S.F. Masri"
            ],
            "title": "Mapping some basic functions and operations to multilayer feedforward neural networks for modeling nonlinear dynamical systems and beyond",
            "venue": "Nonlinear Dynamics,",
            "year": 2013
        },
        {
            "authors": [
                "A. Rahman",
                "J. Drgo\u0148a",
                "A. Tuor",
                "J. Strube"
            ],
            "title": "Neural ordinary differential equations for nonlinear system identification",
            "venue": "American Control Conference,",
            "year": 2022
        },
        {
            "authors": [
                "F. Stelzer",
                "A. R\u00f6hm",
                "R. Vicente",
                "I. Fischer",
                "S. Yanchuk"
            ],
            "title": "Deep neural networks using a single neuron: folded-in-time architecture using feedbackmodulated delay loops",
            "venue": "Nature Communications,",
            "year": 2021
        },
        {
            "authors": [
                "G. St\u00e9p\u00e1n"
            ],
            "title": "Retarded Dynamical Systems: Stability and Characteristic Functions",
            "year": 1989
        },
        {
            "authors": [
                "E.M. Turan",
                "J. J\u00e4schke"
            ],
            "title": "Multiple shooting for training neural differential equations on time series",
            "venue": "IEEE Control Systems Letters,",
            "year": 2021
        },
        {
            "authors": [
                "A. Waibel",
                "T. Hanazawa",
                "G. Hinton",
                "K. Shikano",
                "K.J. Lang"
            ],
            "title": "Phoneme recognition using timedelay neural networks",
            "venue": "IEEE Transactions on Acoustics, Speech, and Signal Processing,",
            "year": 1989
        },
        {
            "authors": [
                "S. Wong",
                "L. Jiang",
                "R. Walters",
                "T.G. Moln\u00e1r",
                "G. Orosz",
                "R. Yu"
            ],
            "title": "Traffic forecasting using vehicleto-vehicle communication",
            "venue": "In Proceedings of the 3rd Conference on Learning for Dynamics and Control,",
            "year": 2021
        },
        {
            "authors": [
                "X. Zhang",
                "X. Xu",
                "Y. Zhu"
            ],
            "title": "An improved time delay neural network model for predicting dynamic heat and mass transfer characteristics of a packed liquid desiccant dehumidifier",
            "venue": "International Journal of Thermal Sciences,",
            "year": 2022
        },
        {
            "authors": [
                "Q. Zhu",
                "Y. Guo",
                "W. Lin"
            ],
            "title": "Neural delay differential equations",
            "venue": "In International Conference on Learning Representations",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n20 6.\n14 28\n8v 2\n[ cs\n.L G\n] 2\n6 A\nug 2\n02 2\nKeywords: neural ordinary differential equations, time delay systems, time delay neural networks, trainable time delays, Mackey-Glass equation."
        },
        {
            "heading": "1. INTRODUCTION",
            "text": "Artificial neural networks have been thriving in many fields over the past decade and their power in approximating and generalizing the underlying input-output relationships has been demonstrated for multiple examples. Multiple research studies related neural networks to dynamical systems; see, for instance, Kumpati et al. (1990); Pei et al. (2013); Brunton and Kutz (2019).\nKnowledge from dynamical systems can help to design and train neural networks and many ideas in recurrent neural networks were inspired by dynamical systems principles. The deep equilibrium model (DEM) in Bai et al. (2019) represents the discrete-time map between hidden states. Since a globally stable autonomous dynamical system approaches a fix point, one can directly solve for the fix point via root-finding. Neural ordinary differential equation (NODE) in Chen et al. (2018) expresses the time derivative (i.e., the right hand side of the differential equation), while the evolution of the network for a given time period provides the map from the initial condition (input) and the terminal state (target). The depth of the network is related to the simulation time of the corresponding ordinary differential equation. Neural networks can be used to learn the dynamical systems. For example, Wong et al. (2021) provides an example of using discrete-time recurrent neural network to learn traffic dynamics while Li et al. (2005) uses a continuous-time recurrent neural network to express the right hand side of a differential equation. Also, see Turan and Ja\u0308schke (2021); Rahman et al. (2022); Koch et al. (2022) for some recent applications of NODEs on learning nonlinear dynamical systems.\nIn case of delayed dynamical systems, one shall include time delays in the neural networks. As a matter of fact, incorporating time delays in the neural networks may increase the capabilities of the networks. For example, in the\nneural delay differential equation (NDDE) approach proposed by Zhu et al. (2021), adding the delayed state, the network is able to approximate trajectories that intersect in the original state space. One may increase the dimension of the system by defining extra states and construct an augmented ordinary differential equation (ANODE), as in Dupont et al. (2019), but this may not be able to capture the physical meaning of time delays in data-based systems.\nAlthough time delays have been introduced to neural networks in both discrete time (Waibel et al. (1989); Zhang et al. (2022)) and continuous time (Marcus and Westervelt (1989); Stelzer et al. (2021)), these delays were fixed rather than treated as parameters to be learned. In this work, we consider a network with trainable time delays, a concept that was originally proposed in Ji et al. (2020). Different from NDDE, we use an ordinary differential equation to approximate the delayed dynamics, and thus, methods developed for training NODE can be directly applied. This construction is based on the idea of approximating the infinitesimal generator through discretizing the history as in Breda et al. (2014). For data-based models, our method bridges the gap between infinite-dimensional time delay systems and discrete-time maps obtained via full discretization.\nThe layout of the paper is as follows. In Section 2, we relate delay differential equations (DDEs) to ordinary differential equations (ODEs) via discretization of the history. In Section 3, we introduce trainable time delay neural networks and construct the NODE by discretizing the history. In Section 4 we illustrate the training algorithm with a specific loss function. We provide an example of learning the Mackey-Glass equation from simulation data in Section 5 and conclude the results in Section 6."
        },
        {
            "heading": "2. DISCRITIZATION OF THE HISTORY",
            "text": "Consider an autonomous time delay system\nx\u0307(t) = g(xt), (1)\nwhere x \u2208 Rn and xt \u2208 X . Here X = C([\u2212\u03c4max, 0],Rn) is the space of continuous functions, i.e., xt(\u03d1) := x(t+ \u03d1), \u03d1 \u2208 [\u2212\u03c4max, 0], and \u03c4max > 0 is the maximum delay. The system (1) contains the functional g : X \u2192 Rn and it can be re-written as an operator differential equation: x\u0307t = G(xt), (2) where the operator G : X \u2192 X is defined as\nG(\u03d5) =    g(\u03d5), \u03d1 = 0, d\u03d5\nd\u03d1 , \u03d1 \u2208 [\u2212\u03c4max, 0),\n(3)\nsee Ste\u0301pa\u0301n (1989); Breda et al. (2014).\nWe discretize in the variable \u03d1 using a mesh of size M + 1 and define the vector\nX(t) =   X1(t) X2(t)\n... XM+1(t)\n  =   x(t) x(t\u2212 h)\n... x(t \u2212Mh)\n  (4)\nwhere h = \u03c4max/M . This way we can approximate (2) with the ordinary differential equation\nX\u0307(t) = G ( X(t) ) , (5)\nwhere the function G : Rn(M+1) \u2192 Rn(M+1) is given by\nG(X) = [ g\u0303(X) DMX ] . (6)\nHere g\u0303 : Rn(M+1) \u2192 Rn is the approximation of the functional g : X \u2192 Rn. For example, considering\ng(xt) = f ( x(t), x(t \u2212 (j + \u03b1)h), x(t \u2212 \u03c4max) ) (7)\nwith j \u2208 {0, 1, . . . ,M \u2212 1}, \u03b1 \u2208 (0, 1), and f : R3n \u2192 Rn, one may use linear interpolation to obtain\nx(t\u2212 (j+\u03b1)h) = (1\u2212\u03b1)x(t\u2212 jh)+\u03b1x(t\u2212 (j+1)h), (8) yielding\ng\u0303(X) = f ( X1, (1 \u2212 \u03b1)Xj+1 + \u03b1Xj+2, XM+1 ) , (9)\nThe matrix DM \u2208 R(n\u22121)(M+1)\u00d7n(M+1) represents the numerical differentiation scheme used to approximate the time derivative of past states. For instance, choosing the forward Euler method to approximate the time derivative\nx\u0307(t\u2212 jh) = 1 h\n( x(t\u2212 (j \u2212 1)h)\u2212 x(t \u2212 jh) ) , (10)\ngives X\u0307j+1(t) = 1 h ( Xj(t)\u2212Xj+1(t) ) , (11) yielding\nDM = 1\nh\n  I \u2212I I \u2212I\n. . . . . . I \u2212I\n  , (12)\nwhere I \u2208 Rn\u00d7n is the n-dimensional unit matrix and only the nonzero blocks of DM are spelled out.\nIn summary, (5,6) discretizes (2,3) in the history variable \u03d1. As illustrated in Fig. 1, we still maintain the continuous dynamics in time t. This enables us to propagate the state forward with high accuracy, which will be beneficial for learning. Note that, however, data samples will only be available with sampling time h."
        },
        {
            "heading": "3. TIME DELAY NEURAL NETWORKS",
            "text": "Time delay neural networks (TDNNs) were first proposed for speech recognition in Waibel et al. (1989). In particular, networks with input delays can be expressed by\nzt1 = f(W1z t 0 + b1), ztl = fl ( Wlz t l\u22121 + bl ) , l \u2265 2, (13)\nwhere l = 1, 2, . . . , L denotes the layers of the neural network while t denotes time. The inputs for the network are the delayed values of the signal zt0 which can be collected in the vector\nz t 0 =   zt\u2212\u03c410 ...\nzt\u2212\u03c4d0\n  , (14)\nwith input delays 0 \u2264 \u03c41 < \u00b7 \u00b7 \u00b7 < \u03c4d. The dimension of zl depends on the number of neurons in each layer, and the network output zL has the same dimension as z0. The matrix Wl and the vector bl are referred to as weight and bias respectively, while fl denotes the element-wise nonlinear function in each layer. Building on our previous work in Ji et al. (2021), we use trainable time delay neural networks approximate the right hand side of the delay differential equations. We shape the network indirectly by propagating the states of the approximate system forward via numerical simulation (using time steps much smaller than h) and comparing the result to data (which is available with sampling time h). This provides an efficient way of learning the nonlinear dynamics and the delays.\nIn order to use the construction (13,14) for learning the dynamics (5,6), we define zt0 = x(t). We assume that the number of delays d in the system is known (or at least the upper limit of this number is known). Note that, however, the values of the delays 0 \u2264 \u03c41 < \u00b7 \u00b7 \u00b7 < \u03c4d are not known. Then we define a matrix which allows us to approximate the delayed states zt\u2212\u03c4i0 in (14) with the components Xj in (4), namely\nz t 0 = PX(t), (15)\nwhere P \u2208 Rd\u00d7n(M+1) and since typically d \u226a M , P is a wide matrix. For the case of the linear interpolation given in example (7,8,9) we have\nP =\n[ I\n(1\u2212 \u03b1)I \u03b1I I\n] (16)\nwhere the block (1 \u2212 \u03b1)I is the j + 1-st column and the block \u03b1I is the j + 2-nd column. Indeed, one may use higher-order interpolation methods which result in more nonzero blocks in P .\nThe output of the neural network (13) is set to be the derivative\nx\u0307(t) = ztL = net ( PX(t) ) , (17)\nand thus the neural ordinary differential equation becomes\nX\u0307(t) = G\u0302 ( X(t) ) , (18)\nwhere the function G\u0302 : Rn(M+1) \u2192 Rn(M+1) is given by\nG\u0302(X) =\n[ net ( PX )\nDMX\n] , (19)\ncf. (5,6). We remark that to obtain DM , instead of the forward Euler method we will use the central difference method which yields\nDM = 1\n2h\n  I O \u2212I . . . . . . . . .\nI O \u2212I 2I \u22122I\n  , (20)\nwhere O \u2208 Rn\u00d7n is the n-dimensional zero matrix while the other nonzero blocks are not spelled out; cf. (12). Note that the last row in DM is still derived from forward Euler method.\nWhen training the NODE (18,19), the weights Wl and biases bl in (13) as well as the delays \u03c4i are updated at every iteration. The update in \u03c4i iteratively changes P defined in (15). The loss function and the training methods are introduced in the next section."
        },
        {
            "heading": "4. TRAINING THE NETWORKS WITH DELAYS",
            "text": "After constructing of the NODE (18,19), one can simulate the resulting differential equations with given initial condi-\ntion X(0). The corresponding solution is denoted by X\u0302(t)\nand we have x\u0302(t) = X\u03021(t). During the learning process this is compared to the data, which is obtained as the solution x(t) of (1). We assume that the data is available with the sampling time h and we compare the solutions along the time horizon T = Nh,N \u2208 N. We construct the loss function using the one-norm:\nL =\nN\u2211\nj=1\n\u2225\u2225x\u0302(jh)\u2212 x(jh) \u2225\u2225 1 , (21)\nwhich depends on the initial historyX(0) and the trainable parameters \u03b8 = {Wl, bl, \u03c4i}, l = 1, . . . , L, i = 1, . . . , d. Learning algorithms require the gradient\ng = \u2202L\n\u2202\u03b8 , (22)\nto iterate the parameters so that (21) decreases. The gradient of the loss with respect to delay \u03c4i is given by\n\u2202L \u2202\u03c4i =\n\u2202L \u2202x(\u2212\u03c4i) \u2202x(\u2212\u03c4i) \u2202\u03c4i =\n\u2202L \u2202x(\u2212\u03c4i) ( \u2212 x\u0307(\u2212\u03c4i) ) , (23)\nwhere \u2202L \u2202x(\u2212\u03c4i) is the gradient with respect to the initial delayed state and x\u0307(\u2212\u03c4i) is the time derivative of x at \u2212\u03c4i. The latter one is approximated from data again using central differences while the former one can be calculated via back propagation or through the adjoint variable method as in Chen et al. (2018) after the forward simulation pass is established. The gradient of the loss with respect to other parameters \u2202L\n\u2202Wl and \u2202L \u2202bl can be also\nobtained via back propagation.\nWith the availability of the gradient information, one may update the parameters using adaptive moment estimation (Adam, Kingma and Ba (2015)). The formula for updating each individual parameter is given by\n\u03b8k+1 = \u03b8k \u2212 \u03b7\u221a\nv\u0302k + \u01eb m\u0302k, (24)\nwith\nm\u0302k = mk\n1\u2212 \u03b2k1 ,\nv\u0302k = vk\n1\u2212 \u03b2k2 ,\n(25)\nwheremk and vk are the first moment estimate and second moment estimate, respectively. The updates for mk and vk are given by\nmk = \u03b21mk\u22121 + (1\u2212 \u03b21)gk, vk = \u03b22vk\u22121 + (1\u2212 \u03b22)g2k,\n(26)\nusing the gradient information gk at iteration k; cf. (22). The parameters \u03b7, \u01eb, \u03b21, \u03b22 in (24,25,26) can be tuned by the user to achieve better performance; see Kingma and Ba (2015).\nThe loss function described in (21) is based on one simulation with a given initial history. When using multiple trajectories (from multiple initial histories) for one update, the sum of simulation losses for all the trajectories in the batch is considered. Then the gradient is calculated by taking the average of the gradients in the batch. We remark that when updating the delay parameters, we limit the delay value to be between 0 and \u03c4max using \u03c4i = max ( min(\u03c4i, \u03c4max), 0 ) . Since the delay values are explicitly learned, one may in fact use the first row of the NODE (18,19) as a neural delay differential equation (NDDE) whose form is similar to (1)."
        },
        {
            "heading": "5. MACKEY-GLASS EQUATION",
            "text": "In this section, we examine the ability of the tools developed above while learning the dynamics of the MackeyGlass equation (Mackey and Glass (1977)), a scalar autonomous time delay system of the form\nx\u0307(t) = \u03b2x(t \u2212 \u03c4)\n1 + (x(t\u2212 \u03c4))\u03b4 \u2212 \u03b3x(t), (27)\nwith \u03b2 = 4, \u03b3 = 2, \u03b4 = 9.65. The system exhibits different qualitative behaviors as the time delay \u03c4 is varied. For small values of \u03c4 , there exists a globally stable equilibrium. This equilibrium looses stability as \u03c4 is increased via a supercritical Hopf bifurcation, giving rise to stable limit cycle oscillations. With \u03c4 increased further, the limit cycle loses stability via a supercritical period doubling bifurcation, and a period doubling cascade eventually leads to chaotic behavior; see the bifurcation diagram in Fig. 7(a). We set \u03c4 = 1, which yields chaotic behavior, and generate 100 trajectories using constant initial histories x(t) \u2261 c, t \u2208 [\u2212\u03c4max, 0] where c = 0.5 + i/99, i = 0, . . . 99 and \u03c4max = 1.5. The simulations are done in MATLAB using dde23.\nAccording to (5,6) one may also generate data using the approximate ODE\nX\u0307(t) =\n  \u03b2Xr(t)\n1 + ( Xr(t) )\u03b4 \u2212 \u03b3X1(t)\nDMX(t)\n  . (28)\nThis may serve as the baseline for the performance of the NODE explained below for which we use h = 0.05 yielding M = \u03c4max/h = 30 and r = \u03c4/h+ 1 = 21 and matrix (20).\nWhen constructing the NODE (18,19), we use two-hiddenlayer trainable time delay neural networks with 5 neurons in each hidden layer and choose tanh(\u00b7) as the nonlinear activation function. Thus, following (17), we can write\nX\u0307(t) =\n[ W3 tanh ( W2 tanh ( W1PX(t) + b1 ) + b2 )\nDMX(t)\n] .\n(29) where W1 \u2208 R5\u00d72, W2 \u2208 R5\u00d75, W3 \u2208 R1\u00d75, b1, b2 \u2208 R5\u00d71 and the tanh is applied element-wise. The matrix P is chosen to be the same as in (16). We focus on analyzing the case with knowledge of the number of delays. Recall that \u03c41 = 0 and only the second delay \u03c42 > 0 is learned. Both (28) and (29) are simulated using ode45 in MATLAB. Finally, we extract the NDDE\nx\u0307(t) = W3 tanh ( W2 tanh ( W1 [ x(t)\nx(t\u2212 \u03c42)\n] + b1 ) + b2 ) ,\n(30) utilizing the first row of (29) and simulate the corresponding equations using dde23.\nWhen generating data via (27) we drop the transients, that is, we only consider the trajectories in the time domain t \u2208 [10, 20] as indicated in Fig. 2. Then we sample the data with time step h = 0.05 and use the first 141 samples (t \u2208 [10, 17]) for training and the next 60 samples (t \u2208 (17, 20]) for testing. When calculating the loss (21), we set the simulation horizon to be N = 10 steps (i.e., T = Nh = 0.5). From the 141 samples in each trajectory, we take segments of 31 samples as initial histories and obtain predictions for next 10 steps. Thus, 101 input-output pairs (i.e., [x(t \u2212 \u03c4max), . . . , x(t)] \u2192 [x(t+ h), . . . , x(t+ T )], t = 11.50, 11.55, . . . , 17) are generated. This way, we obtain 10100 pairs from the 100 trajectories for training.\nWe train the network for 2000 iterations and use the batch size 1000, such that 10 out of the 101 pairs from each trajectory are used for each update. The delay \u03c42 is initialized uniformly between [0, \u03c4max], b1 and b2 are initialized as zeros, while W1,W1 and W3 are initialized using Glorot initialization (Glorot and Bengio (2010)). In the Adam updating rule (24,25,26) the learning rate \u03b7 is set to 0.01 while \u03b21, \u03b22, \u01eb are set to 0.9, 0.999, 10\n\u22128, respectively; see Kingma and Ba (2015). From different parameter initializations, the networks may converge to different local minima. We plot the delay learning path and training loss of the networks with three different learned delays as function of the iteration number in Fig. 3. For\nthe two paths leading to small delay values, the training loss stops decreasing very early, while for the third path the loss keeps decreasing with the iterations. This may be used to detect undesired local minima and to filter out the bad initialization at the early stages of training.\nThe predictions of three trained networks are shown in Fig. 4. The simulation of the network with correctly learned delay (blue solid curve) fits the data (red and black dashed curves) very well and makes good short-term predictions about the future. The NODEs with incorrect delays (magenta and orange curves) perform poorly both for training and for testing.\nWe also study the effect of the simulation horizon on the training process. We trained 100 networks with different initial parameters using 3-step, 10-step and 40-step hori-\nzons and plot the distribution of the learned delays at iteration 2000 in Fig. 5. We observe a trade-off between the performance and training time. Increasing the horizon can reduce the chance of being trapped at small delay values, but the training process is slower for longer horizons.\nTo illustrate on how well the learned network performs, we compare the nonlinearity obtained through NDDE (30) with that of the original DDE (27). The coloring in Fig. 6(a) shows x\u0307(t) (i.e., the right hand side of the DDE) as a function of x(t) and x(t\u2212 \u03c4). The black curve indicates x\u0307 = 0 and its intersection with the 45 degree red line gives the equilibria of the system, namely, x(t) \u2261 0 and x(t) \u2261 1. Panel (b) shows the network output \u02c6\u0307x(t) (i.e., the right hand side of the NDDE) as a function of x(t) and x(t\u2212 \u03c4), while panel (c) depicts the difference between the nonlinearities of the DDE and the NDDE. The gray trajectory indicates the chaotic attractor of the DDE which covers a significant portion of the plane.\nSince the time delay and the nonlinearity are learned separately, we can vary the time delay while keeping the net-\nwork with same weights and biases and analyze the behavior of the corresponding NDDE. Fig. 6(d) depicts the trajectory for \u03c42 = 0.8 where the system approaches a stable period two limit cycle. (Recall that the training was performed for \u03c42 = 1 where the system approached a chaotic attractor.) The constant initial condition x(t) = 0.2 is used which lies outside the training dataset. The neural network gives a good prediction for the limit cycle, since the nonlinearity of the learned NDDE is similar to the of the DDE. This demonstrates the advantage of learning the delays in addition to learning the weights and biases. With the explicitly learned time delays, the network generalizes well and provides insights to the system dynamics.\nWe exhibit the bifurcation diagram of the trained NDDE and compare it to that of the original DDE in Fig. 7. One may observe the formation of limit cycles and their stability changes as the delay increases from 0 to 2. The network is able to predict appearance of Hopf and period doubling bifurcations and give good predictions for the amplitude, period and stability of the limit cycles without requiring any retraining.\nFinally, the method still works if we do not have knowledge about the zero delay, or even about the number of the delays in the system. When (moderately) overestimating the number of delays, we can still learn the dynamics. Fig. 8 shows the delay learning paths of two different network configurations with 3 delays and with 4 delays, respectively. Observe that the delays converge to values around 0 and 1. The nice generalization ability of the networks in this example does depend on the system and training data. Thanks to the chaotic behavior, the training data is rich enough to recover the nonlinearity locally for this autonomous single-delay scalar system. However, similar to other data-driven methods, the performance of this method is limited by the quality of the data. For autonomous systems with multiple states and/or multiple delays, obtaining good training data with rich dynamics might be challenging in many applications."
        },
        {
            "heading": "6. CONCLUSION",
            "text": "A method for learning the dynamics of time delay systems was presented. The key idea is to transform the dynamics described by a delay differential equation to an ordinary differential equation through discretizing the history, while retaining continuous time evolution of the systems to enable high accuracy predictions. The dynamics was learned by constructing a neural ordinary differential equation, whose right hand side, represented by a neural network with certain structure, approximated the right hand side of the ODE. A neural delay differential equation can be extracted from the obtained NODE, and it generalized very well when either the parameters or the initial conditions were changed. The developed methods were applied to the Mackey-Glass equation where both the nonlinearity and the time delay were learned with high accuracy. Future research includes applying the developed method to real engineering systems with and without first principle models."
        }
    ],
    "title": "Learning Time Delay Systems with Neural Ordinary Differential Equations",
    "year": 2022
}