{
    "abstractText": "Electronic word-of-mouth communication in the form of online reviews influences people\u2019s product or service choices. People use text features to add or emphasise feelings and emotions in their text. The text emphasis can come in as capital letters, letter repetition, exclamation marks and emoticons. The existing literature has not paid sufficient attention to the effects of such textual variations on human text interpretation. This paper presents an analysis of text variations that can affect the interpretation of a text. A total of 1,041 online comments were collected, in which seven types of the most used textual variations were identified and simulated for hypothesis testing. Sentiment scores from 500 participants were collected to rate the value expressed for each of the textual variations. Statistical analysis showed that collected ratings are significant for the accurate calculation of sentiment values for short comments. Furthermore, the performance of ten existing sentiment tools was analysed based on seven textual variations. Results indicate that those tools should consider these textual variations to fully reflect a human interpretation on the text variations.",
    "authors": [
        {
            "affiliations": [],
            "name": "Phoey Lee Teh"
        },
        {
            "affiliations": [],
            "name": "Paul Rayson"
        },
        {
            "affiliations": [],
            "name": "Irina Pak"
        },
        {
            "affiliations": [],
            "name": "Scott Piao"
        },
        {
            "affiliations": [],
            "name": "Jessica Sze Yin Ho"
        },
        {
            "affiliations": [],
            "name": "Andrew Moore"
        }
    ],
    "id": "SP:6deafe744c39957b797f2225885dbcaacbc5ac50",
    "references": [
        {
            "authors": [
                "A.S.M. Alharbi",
                "E. de Doncker"
            ],
            "title": "Twitter sentiment analysis with a deep neural network: An enhanced approach using user behavioral information",
            "venue": "Cogn. Syst. Res",
            "year": 2019
        },
        {
            "authors": [
                "D. Archer",
                "M. Kyt\u00f6",
                "A. Baron",
                "P. Rayson"
            ],
            "title": "Guidelines for normalising Early Modern English",
            "year": 2015
        },
        {
            "authors": [
                "O. Artemenko",
                "V. Pasichnyk",
                "N. Kunanets",
                "K. Shunevych"
            ],
            "title": "Using sentiment text analysis of user reviews in social media for e-tourism mobile recommender systems",
            "venue": "CEUR Workshop Proc",
            "year": 2020
        },
        {
            "authors": [
                "A.S. Babii",
                "M.S. Kazyulina",
                "A.Y. Malafeev"
            ],
            "title": "Automatic Emotion Identification in Russian Text Messages, in: Computational Linguistics and Intellectual Technologies",
            "venue": "Nizhny Novgorod,",
            "year": 2020
        },
        {
            "authors": [
                "S. Brody",
                "N. Diakopoulos"
            ],
            "title": "Cooooooooooooooollllllllllllll !!!!!!!!!!!!!! Using Word Lengthening to Detect Sentiment in Microblogs, in: Empirical Methods in Natural Language Processing",
            "year": 2011
        },
        {
            "authors": [
                "C. Burgers",
                "Mulken",
                "M. Van",
                "P.J. Schellens"
            ],
            "title": "Verbal Irony: Differences in Usage Across Written",
            "year": 2012
        },
        {
            "authors": [
                "K. Byron"
            ],
            "title": "Carrying too heavy a load? The communication and miscommunication of emotion by email",
            "venue": "Acad. Manag. Rev",
            "year": 2008
        },
        {
            "authors": [
                "J. Carey"
            ],
            "title": "Paralanguage in computer mediated communication, in: ACL \u201980",
            "venue": "Proceedings of the 18th Annual Meeting on Association for Computational Linguistics. Association for Computational Linguistics",
            "year": 1980
        },
        {
            "authors": [
                "T. Chai",
                "R.R. Draxler"
            ],
            "title": "Root mean square error (RMSE) or mean absolute error (MAE)? \u2013 Arguments against avoiding RMSE in the literature",
            "venue": "Geosci. Model Dev",
            "year": 2014
        },
        {
            "authors": [
                "M. Chaudhary",
                "H. Kumar",
                "S. Kaushal",
                "A.K. Sangaiah"
            ],
            "title": "The case analysis on sentiment based ranking of nodes in social media space. Multimed",
            "venue": "Tools Appl",
            "year": 2018
        },
        {
            "authors": [
                "N.K. Cobb",
                "D. Mays",
                "A.L. Graham"
            ],
            "title": "Sentiment analysis to determine the impact of online messages on smokers\u2019 choices to use varenicline",
            "venue": "J. Natl. Cancer Inst. Monogr",
            "year": 2013
        },
        {
            "authors": [
                "S.A. Cohen",
                "K.K.H. Chui",
                "E.N. Naumova"
            ],
            "title": "Measuring disease burden in the older population using the slope-intercept method for population log-linear estimation (SIMPLE)",
            "venue": "Stat. Med",
            "year": 2011
        },
        {
            "authors": [
                "D. Derks",
                "A.E.R. Bos",
                "Grumbkow",
                "J. Von"
            ],
            "title": "Emoticons and social interaction on the Internet",
            "year": 2007
        },
        {
            "authors": [
                "C.G. DeWald",
                "L.H. Geyer"
            ],
            "title": "An operations research approach to the modeling and analysis of different feature sets proposed for human perception of capital letters",
            "venue": "Comput. Oper. Res",
            "year": 1975
        },
        {
            "authors": [
                "A. Esuli",
                "F. Sebastiani",
                "V.G. Moruzzi"
            ],
            "title": "SENTIWORDNET: A Publicly Available Lexical Resource for Opinion Mining, in: 5th Conference on Language Resources and Evaluation",
            "venue": "European Language Resources Association (ELRA), Genoa,",
            "year": 2006
        },
        {
            "authors": [
                "A. Garrison",
                "D. Remley",
                "P. Thomas",
                "E. Wierszewski"
            ],
            "title": "Conventional Faces: Emoticons in Instant Messaging Discourse",
            "venue": "Comput. Compos",
            "year": 2011
        },
        {
            "authors": [
                "F. Godin",
                "W. De Neve",
                "R. Van de Walle"
            ],
            "title": "Towards fusion of collective knowledge and audio-visual content features for annotating broadcast video",
            "venue": "Proc. 3rd ACM Conf. Int. Conf. Multimed. Retr. - ICMR",
            "year": 2013
        },
        {
            "authors": [
                "M. Hall",
                "E. Frank",
                "G. Holmes",
                "B. Pfahringer",
                "P. Reutemann",
                "I.H. Witten"
            ],
            "title": "The WEKA data",
            "year": 2009
        },
        {
            "authors": [
                "G. He",
                "Y. Deng",
                "Xiaochun Wu"
            ],
            "title": "Analysis of web-surfing behavior of enterprise network users",
            "venue": "in: 2nd International Conference on Computer Science and Network Technology. IEEE, Changchun,",
            "year": 2012
        },
        {
            "authors": [
                "D.R. Heise"
            ],
            "title": "Cultural variations in sentiments",
            "venue": "Springerplus 3,",
            "year": 2014
        },
        {
            "authors": [
                "A. Hogenboom",
                "D. Bal",
                "F. Frasincar",
                "M. Bal",
                "F. de Jong",
                "U. Kaymak"
            ],
            "title": "Exploiting emoticons in sentiment analysis, in: SAC\u201913",
            "venue": "Annual ACM Symposium on Applied Computing",
            "year": 2013
        },
        {
            "authors": [
                "A.H. Huang",
                "D.C. Yen",
                "X. Zhang"
            ],
            "title": "Exploring the potential effects of emoticons",
            "venue": "Inf. Manag. 45,",
            "year": 2008
        },
        {
            "authors": [
                "C.J. Hutto",
                "E. Gilbert"
            ],
            "title": "VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text",
            "venue": "in: Eighth International Conference on Weblogs and Social Media. Ann Arbor,",
            "year": 2014
        },
        {
            "authors": [
                "Z. Jianqiang",
                "G. Xiaolin",
                "Z. Xuejun"
            ],
            "title": "Deep Convolution Neural Networks for Twitter Sentiment",
            "year": 2018
        },
        {
            "authors": [
                "Y.M. Kalman",
                "D. Gergle"
            ],
            "title": "Letter repetitions in computer-mediated communication: A unique link between spoken and online language",
            "venue": "Comput. Human Behav",
            "year": 2014
        },
        {
            "authors": [
                "Y.M. Kalman",
                "D. Gergle"
            ],
            "title": "Letter and Punctuation Mark Repeats as Cues",
            "year": 2009
        },
        {
            "authors": [
                "D. Chicago. Kim",
                "M.G. Frank",
                "S.T. Kim"
            ],
            "title": "Emotional display behavior in different forms",
            "year": 2014
        },
        {
            "authors": [
                "X. Zhu",
                "S.M. Mohammad"
            ],
            "title": "Sentiment Analysis of Short Informal Texts",
            "year": 2014
        },
        {
            "authors": [
                "K. Larson"
            ],
            "title": "Nonverbal cues in e-mail supportive communication",
            "year": 2008
        },
        {
            "authors": [
                "Z. Liu"
            ],
            "title": "A method of SVM with Normalization in Intrusion Detection",
            "venue": "Commun. Soc",
            "year": 2011
        },
        {
            "authors": [
                "J. V",
                "R.F. Zanetti",
                "D. Reller",
                "T.A. Almeida"
            ],
            "title": "Short text opinion detection",
            "year": 2016
        },
        {
            "authors": [
                "S. Shanmuganathan",
                "J. Whalley"
            ],
            "title": "Sentiment lexicon construction using",
            "year": 2016
        },
        {
            "authors": [
                "S. Kiritchenko",
                "X. Zhu"
            ],
            "title": "NRC-Canada: Building the State-of-the-Art",
            "year": 2013
        },
        {
            "authors": [
                "D. Mohey",
                "E.M. Hussein"
            ],
            "title": "A survey on sentiment analysis challenges",
            "venue": "J. King Saud",
            "year": 2016
        },
        {
            "authors": [
                "A. Nagaoka",
                "Y. Arimoto"
            ],
            "title": "Accuracy of Automatic Cross-Corpus Emotion",
            "venue": "Univ. - Eng. Sci",
            "year": 2016
        },
        {
            "authors": [
                "A. Neviarouskaya",
                "H. Prendinger",
                "M. Ishizuka"
            ],
            "title": "Affect Analysis Model: novel rule",
            "year": 2011
        },
        {
            "authors": [
                "P.K. Novak",
                "J. Smailovi\u0107",
                "B. Sluban",
                "I. Mozeti\u010d"
            ],
            "title": "Sentiment of emojis",
            "venue": "PLoS One",
            "year": 2015
        },
        {
            "authors": [
                "I. Pak",
                "P.L. Teh"
            ],
            "title": "Value of expressions behind the letter capitalization in product reviews",
            "year": 2018
        },
        {
            "authors": [
                "P.L. Teh"
            ],
            "title": "Machine Learning Classifiers : Evaluation of the Performance in Online",
            "year": 2016
        },
        {
            "authors": [
                "I. Pak",
                "Teh",
                "P.L.P.L",
                "Cheah",
                "Y.-N.Y.-N.Y.-N"
            ],
            "title": "Hidden Sentiment Behind Letter Repetition in Online Reviews",
            "venue": "J. Telecommun. Electron. Comput. Eng",
            "year": 2018
        },
        {
            "authors": [
                "B. Pang",
                "L. Lee",
                "S. Vaithyanathan"
            ],
            "title": "Thumbs up? Sentiment classification using machine learning techniques",
            "venue": "Proc. Conf. Empir. Methods Nat. Lang. Process. July",
            "year": 2002
        },
        {
            "authors": [
                "V.A. Pfeifer",
                "E.L. Armstrong",
                "V.T. Lai"
            ],
            "title": "Do all facial emojis communicate emotion? The impact of facial emojis on perceived sender emotion and text processing",
            "venue": "Comput. Human Behav",
            "year": 2022
        },
        {
            "authors": [
                "P.M. Podsakoff",
                "S.B. MacKenzie",
                "N.P. Podsakoff",
                "Lee",
                "J.-Y"
            ],
            "title": "Common Method Biases in Behavioral Research: A Critical Review of the Literature and Recommended Remedies",
            "venue": "J. Appl. Psychol",
            "year": 2003
        },
        {
            "authors": [
                "R. Prabowo",
                "M. Thelwall"
            ],
            "title": "Sentiment analysis: A combined approach",
            "venue": "J. Informetr",
            "year": 2009
        },
        {
            "authors": [
                "P. Rayson"
            ],
            "title": "From key words to key semantic domains",
            "venue": "Int. J. Corpus Linguist",
            "year": 2008
        },
        {
            "authors": [
                "Riordan",
                "M. a",
                "R.J. Kreuz"
            ],
            "title": "Emotion encoding and interpretation in computer-mediated communication: Reasons for use",
            "venue": "Comput. Human Behav",
            "year": 2010
        },
        {
            "authors": [
                "M.A. Riordan",
                "R.J. Kreuz"
            ],
            "title": "Cues in computer-mediated communication: A corpus analysis",
            "venue": "Comput. Human Behav",
            "year": 2010
        },
        {
            "authors": [
                "Y. Rong",
                "X. Zhang",
                "X. Feng",
                "T. Ho",
                "W. Wei",
                "D. Xu"
            ],
            "title": "Comparative analysis for traffic flow forecasting models with real-life data in Beijing",
            "venue": "Adv. Mech. Eng",
            "year": 2015
        },
        {
            "authors": [
                "L. Schomaker",
                "M. Bulacu"
            ],
            "title": "Automatic writer identification using connected-component contours and edge-based features of uppercase western script",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 2004
        },
        {
            "authors": [
                "E. Sesa-Nogueras",
                "M. Faundez-Zanuy"
            ],
            "title": "Biometric recognition using online uppercase handwritten",
            "year": 2012
        },
        {
            "authors": [
                "Y. Sidi",
                "E. Glikson",
                "A. Cheshin"
            ],
            "title": "Do You Get What I Mean?!? The Undesirable Outcomes of (Ab)Using Paralinguistic Cues in Computer-Mediated Communication",
            "venue": "Front. Psychol",
            "year": 2021
        },
        {
            "authors": [
                "S. Smetanin"
            ],
            "title": "The Applications of Sentiment Analysis for Russian Language Texts: Current Challenges and Future Perspectives",
            "venue": "IEEE Access",
            "year": 2020
        },
        {
            "authors": [
                "M. Soderlund",
                "Oikarinen",
                "E.-L",
                "T.M. Tan"
            ],
            "title": "The happy virtual agent and its impact on the human customer in the service encounter",
            "venue": "J. Retail. Consum. Serv",
            "year": 2021
        },
        {
            "authors": [
                "S.M. Subramanian",
                "S. Vijayalakshmi",
                "B. Venkataraman"
            ],
            "title": "CCCa Framework Classification System in Big Data Environment with Clustering and Cache Concepts, in: Eighth International Conference on Soft Computing and Pattern Recognition (SoCPaR",
            "year": 2016
        },
        {
            "authors": [
                "T. Tang",
                "X. Tang",
                "T. Yuan"
            ],
            "title": "Fine-Tuning BERT for Multi-Label Sentiment Analysis in Unbalanced Code-Switching Text",
            "venue": "IEEE Access",
            "year": 2020
        },
        {
            "authors": [
                "T. Ted",
                "L. Wu",
                "H. Lu",
                "Y. Tao"
            ],
            "title": "Computers in Human Behavior The effect of emoticons in simplex and complex task-oriented communication : An empirical study of instant messaging",
            "year": 2010
        },
        {
            "authors": [
                "P.L. Teh",
                "I. Pak",
                "P. Rayson",
                "S. Piao"
            ],
            "title": "Exploring fine-grained sentiment values in online product reviews",
            "venue": "in: 2015 IEEE Confernece on Open Systems (ICOS). IEEE,",
            "year": 2015
        },
        {
            "authors": [
                "P.L. Teh",
                "P. Rayson",
                "I. Pak",
                "S. Piao"
            ],
            "title": "Sentiment Analysis Tools Should Take Account of the Number of Exclamation Marks !!",
            "venue": "IiWAS",
            "year": 2015
        },
        {
            "authors": [
                "P.L. Teh",
                "P. Rayson",
                "I. Pak",
                "S. Piao",
                "S.M. Yeng"
            ],
            "title": "Reversing Polarity With Emoticons, in: Natural Language Processing and Information Systems",
            "year": 2016
        },
        {
            "authors": [
                "M. Thelwall",
                "K. Buckley",
                "G. Paltoglou"
            ],
            "title": "Sentiment strength detection for the social web",
            "venue": "J. Am. Soc. Inf. Sci. Technol",
            "year": 2012
        },
        {
            "authors": [
                "M. Thelwall",
                "K. Buckley",
                "G. Paltoglou",
                "D. Cai"
            ],
            "title": "Sentiment Strength Detection in Short Informal Text",
            "venue": "Am. Soc. Informational Sci. Technol",
            "year": 2010
        },
        {
            "authors": [
                "M. Thelwall",
                "D. Wilkinson"
            ],
            "title": "Public dialogs in social network sites: What is their purpose",
            "venue": "Am. Soc. Informational Sci. Technolo-gy",
            "year": 2010
        },
        {
            "authors": [
                "C.C. Tossell",
                "P. Kortum",
                "C. Shepard",
                "L.H. Barg-Walkow",
                "A. Rahmati",
                "L. Zhong"
            ],
            "title": "A longitudinal study of emoticon use in text messaging from smartphones",
            "venue": "Comput. Human Behav",
            "year": 2012
        },
        {
            "authors": [
                "Y. Urabe",
                "R. Rzepka",
                "K. Araki"
            ],
            "title": "Emoticon recommendation system for effective communication",
            "venue": "in: 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM",
            "year": 2013
        },
        {
            "authors": [
                "I. Vandergriff"
            ],
            "title": "Emotive communication online: A contextual analysis of computermediated",
            "year": 2013
        },
        {
            "authors": [
                "Y. Wu",
                "Y. Zhang",
                "S.M. Luo",
                "X.J. Wang"
            ],
            "title": "Comprehensive information based semantic orientation identification",
            "venue": "in: IEEE NLP-KE 2007 - Proceedings of International Conference on Natural Language Processing and Knowledge Engineering. IEEE,",
            "year": 2007
        },
        {
            "authors": [
                "B. Xue",
                "C. Fu",
                "Z. Shaobin"
            ],
            "title": "A Study on Sentiment Computing and Classification of Sina Weibo with Word2vec",
            "venue": "IEEE International Congress on Big Data. IEEE,",
            "year": 2014
        },
        {
            "authors": [
                "S.M. Zavattaro",
                "P.E. French",
                "S.D. Mohanty"
            ],
            "title": "A sentiment analysis of U.S. local government tweets: The connection between tone and citizen involvement",
            "venue": "Gov. Inf. Q",
            "year": 2015
        },
        {
            "authors": [
                "T.T. Zin",
                "P. Tin",
                "T. Toriu",
                "H. Hama"
            ],
            "title": "Visual behavior analysis tool for consumer video surveillance",
            "venue": "in: The 1st IEEE Global Conference on Consumer Electronics",
            "year": 2012
        }
    ],
    "sections": [
        {
            "text": "Textual Variations Affect Human Judgements of Sentiment Values\nPhoey Lee Teh1, Paul Rayson2, Irina Pak1, Scott Piao2, Jessica Sze Yin Ho3, Andrew Moore2 and Yu-N Cheah4 1Sunway University, Sunway City, Selangor 47500 Malaysia. 2Lancaster University, Lancaster, LA1 4YW United Kingdom. 3Heriot-Watt University Malaysia, Putrajaya, Selangor 63100 Malaysia. 4Universiti Sains Malaysia, Pulau Pinang, 11800 Malaysia. Corresponding author: Phoey Lee Teh (e-mail: phoeyleet@sunway.edu.my). Electronic word-of-mouth communication in the form of online reviews influences people\u2019s product or service choices. People use text features to add or emphasise feelings and emotions in their text. The text emphasis can come in as capital letters, letter repetition, exclamation marks and emoticons. The existing literature has not paid sufficient attention to the effects of such textual variations on human text interpretation. This paper presents an analysis of text variations that can affect the interpretation of a text. A total of 1,041 online comments were collected, in which seven types of the most used textual variations were identified and simulated for hypothesis testing. Sentiment scores from 500 participants were collected to rate the value expressed for each of the textual variations. Statistical analysis showed that collected ratings are significant for the accurate calculation of sentiment values for short comments. Furthermore, the performance of ten existing sentiment tools was analysed based on seven textual variations. Results indicate that those tools should consider these textual variations to fully reflect a human interpretation on the text variations.\nKeywords: Sentiment analysis, text analysis, classification algorithms, text mining, NLP tools, computer mediated cues (CMC), punctuation.\nThis work was supported by the Sunway-Lancaster Grant SGSSL-FST-DCIS-0115-11 and Universiti Sains Malaysia Research University Grant 1001/PKOMP/8014002\nTextual Variations Affect Human Judgements of Sentiment Values"
        },
        {
            "heading": "1 Introduction",
            "text": "Research on Electronic word-of-mouth (EWoM) or social recommendation has become a hot topic in data science, market research and social media listening. EWoM or social recommendation in this paper refers to the comments and reviews posted by consumers online on social media. Recent research beyond natural language processing has revealed the importance of analysing EWoM communication. For instance, Lin and Shen (2011) specified that an analysis of consumers' buying behaviour is important to help explain: 1) the emotional motivation of the consumer, 2) the rational motivation as a means of understanding costeffective and affordable pricing, and 3) the purchase motivation when a consumer has unique preferences. EWoM, therefore, provides a significant value in understanding the purchasing decisions for products and services.\nMultiple general emotion classifications and labelling frameworks are available for\nmark-up in corpora (Mori et al., 2016), however, this paper focuses on the sentiment dimension, which has received much attention in the computational linguistics literature. Sentiment analysis is defined as a common task in Natural Language Processing (NLP) and a process of identifying the evaluative nature of the text (Alharbi and de Doncker, 2019; Kiritchenko et al., 2014; Tang et al., 2020). To date, most of the social media text analysis techniques exploited by commercial organisations are simplistic and fail to take account of the entire linguistic complexity of the text. Other studies discussed those textual variations as well. For instance, Carey (1980) in his study of paralanguage, initially referred to these different forms as \u201cgrammatical markers\u201d, Burgers et al. (2012) in their communication study of message irony referred to them as \u201ctypographic markers\u201d, while Kalman and Gergle (2009) referred to them as computer-mediated communication (CMC) cues or \u201cnonverbal cues\u201d.\nMoreover, \u201cgrammatical markers\u201d and \u201ctypographic markers\u201d can include letter capitalisation, letter repetition, emoticons and different types of punctuation. In a more recent study of (Jianqiang et al., 2018), term \u201csyntactic features\u201d was used for exclamation marks and emoticons and so on. Moreover, it was stated that researchers aim to determine sentiment value though extracting those features (Jianqiang et al., 2018).\nUnlike verbal or face-to-face communication, emotions and feelings in online reviews\nare conveyed through the text form alone. In the text, the use of these textual variations replaces non-verbal communication cues which would otherwise appear as body language, facial expressions or tone of voice.\nIn an online review setting, the analysis of short, informal and unformatted text can be\ncomplex because people tend to use multiple textual variations to highlight or emphasise different meanings of expressions. For human readers, the capitalisation of letters in a text can signify extra attention or voice volume, repeated letters tend to strengthen or emphasise the emotion, and emoticons can help visualise the facial expressions of the person. All of these features can affect the understanding of the sentiment of a given text. Presently, no detailed study on the scale of the effects of the textual variations on human readers in the context of sentiment analysis has been conducted.\nThis study proposes that the sentiment value of comments from social media should\nnot be normalised before being analysed by automatic systems and should preserve the original text form to avoid losing key information related to sentiment. Textual variations and additions that are expressed in various forms of text markers (e.g. symbols, punctuations, capital letters and emoticons) carry extra information that should be taken into account to accurately determining sentiment values. This work demonstrates this effect through an experiment with 500 participants who manually rated the value of scale in agreeing on the expression level for different textual variations. In addition, this study gauges the extent to which the various text\nmarkers, when used in combination with plain text, can affect the sentiment and value of comments regarding different online sentiment analysis tools. To test if current tools are able to sufficiently take textual changes into account when considering its sentiment, ten sentiment tools available online were tested with a set of non-emphasised textual comments and simulated seven types of variations, which contain capital letters, emoticons, exclamation marks and repeated letters. For example, \u201cI loooove this dress\u201d and \u201cI love this dress!!!!!!\u201d in comparison with its non-emphasised version \u201cI love this dress\u201d. The scoring for the text with different text variations was compared and analysed in all tools.\nThe rest of the paper is structured as follows. Section 2 summarises the previous work\non textual variations on CMC, including how they have been discussed in the sentiment analysis literature. In Section 3, data collection and survey design were described, and the method in which the existing sentiment tools were used in our experiments were explained. Section 4 shows the survey outcome and the comparative evaluation of the performance of the sentiment tools. Finally, the closing concludes with a summary and future work."
        },
        {
            "heading": "2 Literature review",
            "text": "Textual formats play an important role in communication in psychology, linguistics, and natural language processing. Studies on textual variations and emphases predate the use of nonstandard varieties in online contexts. In historical (Early Modern English) texts before the standardisation of spelling and publication of dictionaries, there were many reasons for spelling differences, including alignment and justification of the page by typesetters and printers. Archer et al. (2015) performed the first large-scale quantitative survey of spelling variations in Early Modern English. They showed that a majority of word types were non-standard in 16th century English. Later, Carey (1980) carried out one of the first studies of variation patterns in CMC, including the use of capital letters, letter repetitions, vocal (phonetic) spellings,\npunctuations and so on, and referred to different textual variations as \u201cgrammatical markers\u201d. People use them in (what were called at the time) computer conferencing systems to emphasise or highlight statements and opinions within the text. Burgers et al. (2012), on the other hand, referred to some textual variations (e.g. capital letters, emoticons, punctuation and so on) as \u201ctypographic markers\u201d. They stated that typographic markers could draw attention to ironic statements. In many sentiment analysis systems (Naradhipa and Purwarianti, 2011), these variations tend to be treated as a problem that needs to be fixed through pre-processing before sentiment classification on the \u201ccleaned\u201d text can begin. Moreover, Kim et al. (2014) hypothesised that users tend to use words in capital letters to emphasise a particular point or word. They observed that capital letters, emoticons, abbreviations and exclamation marks are used in online chat situations to give non-verbal signals. From the natural language processing approach, Neviarouskaya et al. (2011) stated the interpretation (meaning) behind text messaging in online communication created a model which could be used to infer the emotional state of the person writing the message.\nThere are numerous other studies that address the importance of sentiment analysis. For\ninstance, Pang et al. (2002) noted the value of sentiment classification and reviewed the type of machine language classifiers such as Naive Bayes, Maximum Entropy and Support Vector Machines in comparing movie reviews. Thelwall and Wilkinson (2010) analysed social media comments and highlighted the importance of emotional expressions in the informal text in blogs and online forums. In an experiment with MySpace comments, they predicted positive and negative emotions using the SentiStrength tool and described the role of emotions in free text language. Furthermore, Prabowo and Thelwall (2009) proposed an approach of dividing text using sentiment analysis based on consumer reviews, feedback and comments. They highlighted the importance of classifying text within a three-way sentiment model with positive, negative and neutral categories. Their findings showed that Statistics-Based Classifier\nhad improved the effectiveness of hybrid classification, which was not the case with General Inquirer-Based Classifier. Also, Thelwall et al. (2012) analysed free language text by extracting its sentiment value using SentiStrength, a revised version of the tool that can identify the positive or negative value of the text. Lochter et al. (2016) studied short text opinion detection in online social networks and surmised that the mining of online opinions may be helpful for marketing and sales departments in companies.\nThey managed noisy texts containing spelling variations by normalising the text using\na dictionary look-up approach and then applying ensemble sentiment methods to clean text. Such normalisation resulted in losing information from the textual variations. In another study (He et al., 2012), text reviews were collected and analysed to observe the behaviour of users who are in an enterprise network; the usefulness of such analysis is to monitor and detect the misuse of the workplace network. Likewise, Zin et al. (2012) also built a behavioural analysis tool to study consumer behaviour. Cobb et al. (2013) conducted experiments to understand how a consumer\u2019s decision-making process depends on online reviews and messages. They discovered that more positive thoughts about products lead to higher demand for the product. Xue et al. (2014) proposed a dictionary model that can classify text into positive, negative or neutral categories. The sharing of opinions online is widely evident in hotel, movie and restaurant reviewing sites (Kotelnikov and Pletneva, 2016). In a survey study of 47 academic papers, Mohey and Hussein (2016) highlighted the challenges in sentiment analysis, such as the nature of the topic and the review structure. They have determined that one of the main challenges in sentiment analysis is domain dependence. The solution they proposed for this problem is to find the relationship between the proportion of sentiment techniques usage in theoretical and technical types of challenge (Mohey and Hussein, 2016).\nFurther, they reflected the average results on each type of challenges (Mohey and\nHussein, 2016). In a more recent study (Smetanin, 2020), it was mentioned that sentiment\nanalysis could measure the reaction to certain news or event. Liang and Dai (2013) discussed the significance of analysing microblogs using sentiment values due to microblogging sites such as Twitter and Facebook. They developed an automated system that is able to extract messages from social media and classify sentiment into positive and negative values. The main issue they have tried to solve is to deal with the short social media messages, which was a challenging task for systems to handle (Liang and Dai, 2013). Table 1 summarises studies that examined different elements of variation in text-based communication."
        },
        {
            "heading": "2.1 Capitalisation",
            "text": "or/and emotional expression. According to Byron (2008), the use of capital letters indicates emotional intensity. Vandergriff (2013) used a pragmatics perspective to analyse the use of emotions in computer communication of advanced foreign language learners. According to the microanalytic approach (Ledbetter and Larson, 2008), letter capitalisation might be used to indicate \u201cincreasing volume\u201d (equivalent to raising one\u2019s voice in verbal communication). The use of capital letters can underline meaning and characterise signs of sarcasm. The authors\nstated that fully capitalised text is interpreted as shouting and often unwelcome. Similarly, M. a. Riordan and Kreuz (2010) have also discussed the possibility of capitalisation to reflect a different meaning in a text compared to lower case text. The study by Mohammad et al. (2013) also acknowledged the presence of one of the textual variations in their system, they were able to detect the number of words which are capitalised. However, whether or not the usage of capitalisation expresses a happy mood or unwelcome emotions, it has an impact on the reader\u2019s opinions when a comment or product review is read online. In conclusion, letter capitalisation is clearly used to reinforce the expression and underline the meaning of texts (Pak and Teh, 2018)."
        },
        {
            "heading": "2.2 Exclamation Marks",
            "text": "One of the most widely used punctuation characters is exclamation marks. There are\nquite a number of studies which stated that exclamation marks express different emotional value. For instance, Carey (1980) also noted that grammatical markers, in this case, exclamation marks, help convey the tone of voice and indicate pauses and emphasis. However, the study by (Carey, 1980) was conducted in 1980, and there were no mechanisms available at that time for automatically identifying grammatical markers. In the study of (Teh et al., 2015b), the number of exclamation marks has been tested in online sentiment tools to identify if they can consider this in their sentiment scoring. Twelve sentiment tools were tested, and only two of them were found to consider the difference in the number of exclamation marks when calculating their sentiment scores. However, the results showed that the sentiment value is higher (more positive) for positive comments if more exclamation marks are used. In contrast, negative comments have a lower (more negative) sentiment value when they contain more exclamation marks. In the studies by (Kalman and Gergle, 2014, 2009) on the repetition of punctuation, they observed that the repetition of exclamation marks has the most extensive use among other observed punctuation in their dataset. They provided examples that show\nexclamation marks being used multiple times in the same context (Kalman and Gergle, 2009). For instance, \u201cHave a great trip!!!!!\u201d and \u201cneat! Don\u2019t worry; I\u2019m excited to cook!!!! I\u2019ll try to do it in advance!!!! but if i can\u2019t, it\u2019ll need to cook at your place!!!! that ok?!?!?!!!!!! see you soon!!!!! Best\". It can be concluded that exclamation marks can strengthen the sentiment value of the text (Kalman and Gergle, 2009). The study of Lin Su (2018) stated that exclamation marks could indicate danger and red flags. Moreover, Lin Su (2018) also noted that punctuation marks, including exclamation marks, have their own tonality and different semantic and mood expressions. Babii et al. (2020) mentioned that number of exclamation marks may serve as as a marker for identifying emotion. A more recent study of Sidi et al. (2021) examined repeated exclamation marks in a simulation, where they presented email with repeated exclamation marks and asked participants to interpret them. They concluded that females in their study tended to express their emotions using repeated punctuations more than males in their cohort (Sidi et al., 2021). Moreover, the level of perceived sender happiness was higher for the participants who received the message with exclamation marks (Soderlund et al., 2021)."
        },
        {
            "heading": "2.3 Letter Repetition",
            "text": "Carey, (1980) pointed out that the repetition of vowels may express an individual dialect or regional accent, for instance, \u201cWeeeeell\u201d. That means letter repetition can represent prolonged pronunciations in some dialects. In other research, the formatting of different variations of text has been studied. For example, Kalman and Gergle (2014) conducted a study of the repetition of alphabetical letters by analysing Twitter microblogs and concluded that users tend to repeat punctuation characters in a text to express personalisation and more intention of messages. In addition, they mentioned that the usage of capital letters, asterisks, blank spaces or character repetitions, as well as combinations of these \u201cgimmicks\u201d, enhance and enrich the text. Meanwhile, the study of Mohammad et al. (2013) referred to words containing letter repetition\nas elongated words. Their system was able to detect words with letters repeated more than two times, for example, \u201co\u201d for the elongated word \u201csoooo\u201d. Brody and Diakopoulos (2011) discovered that the repetition of single letters occurs roughly in every six tweets on Twitter. They concluded that Twitter users tend to emphasise sentiment by repeating letters. There is a need to design methods that can consider letter repetition when calculating sentiment scores of text. Kalman and Gergle (2014) also stated that letter repetition indicates the stretching of a word to simulate the spoken conversation, for example, \u201cIt is sweeeeeeet\u201d. Letter repetition can also signify a change in pitch or lowering of one\u2019s voice, for example, \u201cYeeeeeeeeehaaaw!!!!!!!!!!\u201d, \u201cSshhhhhh......let\u2019s keep it between us\u201d. Moreover, they pointed out that letter repetition may represent musical intonation, such as \u201cHappy birthday to youuuu Happy birthday to youuuu Happy birthday dear\u201d. It is also postulated that letter repetition may replace vocal noises and sounds in face-to-face communication such as guttural sounds and laughter. For example, \u201cWOOOOOOOOOOHOOOOOOOOOOOOOOOO, Daddy\u2019s getting a new Blue Wave Bay boat!!!! WOOOHOOOO\u201d, \u201cAnd pfffffff, he is away\u201d, and \u201cHeeeeeheeee!\u201d (Kalman and Gergle, 2014). Several studies on letter repetition agreed that it could represent different vocal expressions.\nIn summary, studies have shown that letter repetition signifies emphasis or features\nwhich would alter the reader\u2019s interpretation of sentiment associated with the text."
        },
        {
            "heading": "2.4 Emoticons",
            "text": "While letter repetition can signify vocal noises or dialectal emphasis in text, emoticons\ncan symbolise facial expressions alongside the text and studies in Table 1 emphasise that. Emoticons represent non-verbal face-to-face expressions. For instance, Derks et al. (2007) studied the use of emoticons in online interactions and found that the frequency of using positive emoticons is higher than the negative ones. Huang et al. (2008) pinpointed that\nDeleted: Table 1\nemoticons are a valuable addition to communication methods. They found that increased emoticons' usage tends to positively affect personal interactions, perceived usefulness, and information richness. Urabe et al. (2013) discussed how emoticons could effectively express non-verbal emotional tones and body language and proposed an emoticon recommendation system that helps users express their emotions using emoticons. Moreover, the studies of Hogenboom et al. (2013) and Teh et al. (2016) suggested that emoticons cannot only convey the sentiment nature of the text, but they also have the potential to reverse the polarity of a statement. The study of Novak et al. (2015) went further and generated an Emoji Sentiment Ranking to identify emotional content behind more than 700 frequently used emojis. Moreover, Tossell et al. (2012) highlighted that users tend to use emoticons to include socio-emotional contexts in their messages. Garrison et al. (2011) claimed that emoticons are a meaningful linguistic unit, and Byron (2008) and Pfeifer et al. (2022) stated that emoticons are equivalent to emotions and facial expressions in face-to-face communication. Emoticons such as emoji, stickers, GIFs and other animated elements convey the emotional component of user feedback (Artemenko et al., 2020).\nFrom the literature above, it can be concluded that it is essential to analyse all these\ndifferent types of variations in the text. People tend to use textual variations to express various forms of emphasis or vocal signals. Furthermore, it can be seen from previous studies that these variations in the written forms will impact readers\u2019 interpretation of the text."
        },
        {
            "heading": "3 Method",
            "text": "Our data collection stage consisted of two phases. Phase 1 focused on collecting comments on products and identifying the textual variations in the comments (positive and negative). Phase 2 focused on assessing the textual variations for sentiment values based on the different text variants identified in Phase 1."
        },
        {
            "heading": "3.1 Phase 1: Comments Collection and Identification of Textual Variants",
            "text": "Phase 1 of our study involved the collection of comments on commercial items from social media websites. A total of 1,0411 comments containing 105,437 words from 10 different product categories were collected from a variety of social media platforms, including Amazon, Facebook, E-bay and GSM Arena. To ensure a wide comment coverage, the 10 product categories were selected from the main categories displayed on the Yahoo! homepage (at the time of data collection), namely \u201cMobiles and Tablets\u201d, \u201cFashion\u201d, \u201cJewellery and Watches\u201d, \u201cCameras\u201d, \u201cHome Appliances\u201d, \u201cConsumer Electronics\u201d, \u201cComputers\u201d, \u201cBeauty and Health\u201d, \u201cToys and Kids\u201d and \u201cSporting Goods\u201d. The existing dataset is a commonly cleaned version without variations. Using the Wmatrix corpus analysis system (Rayson, 2008) and text variation layers derived from (Teh et al., 2015a), the collected comments were examined to determine the judgement from participants on the variation of text from the most frequently used positive and negative terms. Table 2. This process is performed with the tool Wmatrix (Rayson, 2008).\nTo find out if different text variations could impact the level of expression of those emotional words, the top 20 commonly used emotional phrases were samples for later analysis. These\n1Collected comments are available at https://github.com/UCREL/HumanJudgementsOfSentimentValues\nDeleted: Table 2\nwords are extracted from the original terms with their own concordance and texts are displayed in\nTwenty statements from Table 2 were simulated in the questionnaire design described in Phase 2. Seven versions of each comment were derived, containing only standard text, using the seven major types of textual variations based on the model in Figure 1. The seven types of textual variations were categorised based on the manual analysis and observation of these comments. As shown in Figure 1, these variations include: a) Fully capitalised text, b) Text with two exclamation marks at the end, c) Text with four exclamation marks at the end, d) Text with a word in capital letters, e) Text with duplicated letters, f) Text with positive emoticon, g) Text with negative emoticon\nDeleted: Table 2\nOur hypothesis is that the sentiment values of these seven types of variations differ. In other words, the textual variations augment the sentiment value of standard text comments, for both positive and negative comments (Table 2). This is further explained below: 1) H1a-H1g: For positive comments, the sentiment values expressed in layers (a)(b)(c)(d)(e)(f)(g) from the model in Figure 1 vary significantly from the sentiment values of comments without textual variations. 2) H2a-H2g: For negative comments, the sentiment values expressed in layers (a)(b)(c)(d)(e)(f)(g) from the model in Figure 1 vary significantly from the sentiment values of comments without textual variations."
        },
        {
            "heading": "3.2 Phase 2: Assessment of Sentiment Values",
            "text": "A questionnaire was designed to verify the human judgment of sentiment values of phrases extracted in Table 2. The reason for this step is to gather the opinions of what a reader may understand from the sentiment expressed written within the comments. The judgements provided by the participants were to rate within the scales from 1 for \u201cStrongly dislike\u2019\u2019 to 7 for \u201cStrongly like\u201d. The ratings were performed for each of the variations in the textual variations layer. The questionnaire consists of three parts. In part one, the respondents were asked for general information about themselves. Such information was required to understand whether the respondents had any experience with online comments. Table 3 below summarises the respondents experience.\nDeleted: Table 2\nDeleted: Table 3\nWhich Social Media Platform have you commented? Facebook.com 347 69.4% eBay.com 77 15.4% Amazon.com 34 6.8% Twitter.com 21 4.2% Other 21 4.2% What is your purpose/intention of commenting (giving feedback/review) on products online? Sharing experience 225 45.0% Giving warning to others 102 20.4% Expressing yourself 82 16.4% Giving suggestion 72 14.4%\nOther 15 3%\nWhat is the category of product that you usually comment (giving feedback/review) ONLINE?\nMobile and Tablets 136 27.2% Fashion 148 29.6% Home Appliance 91 18.2% Computer 52 10.4% Jewellery and Watch 30 6.0% Toys and Kids 24 4.8% Camera 4 0.8% Consumer Electronics 4 0.8% Beauty and Health 11 2.2%\nA total of 277 (55.4%) people responded that they are native English speakers, the rest\n223 (44.6%) of respondents are not. The majority of respondents are between 19-35 years old with a frequency of 381 (76.2%), the rest 117 (23.4%) and 2 (0.4%) are 18 and below and 51 and above respectively. Among them, 243 (48.6%) are females and the rest are males. A total of 310 (62%) respondents agreed that they have experience in commenting on global social products online, and a lower number of people 190 (38%) responded that they do not comment. The most visited social media platform is Facebook with a frequency of 347 (69.4%), followed by eBay 77 (15.4%) and Amazon 34 (6.8%) and the same lowest number of 21 (4.2%) was recorded for Twitter and Other.\nAmong all the 500 respondents, the most popular reason for commenting is to share\nexperience by providing feedback/review on products, which constitute a total of 45%, followed by 30.4% in providing warnings to others. Expressing themselves was recorded as the third most popular reason which constitutes a total of 16.4%. Finally, the remaining reasons are 14% to give suggestions, and 3% with other reasons and 4 respondents left questions unanswered. Three categories such as Fashion, Mobile and Tablets and Home Appliance were\nselected as the top categories of product that people usually commented on, with frequencies of 148(29.6%), 136(27.2%) and 91(18.2%) respectively. The least popular categories are on Camera and Consumer Electronic with the frequency of 4(0.8%).\nIn order to test all the phrases with all the different variations, we require human raters\nto provide judgement, therefore, we gather from the participants the different ratings of judgements in terms of the variety of text format used for each of the phrases in Table 2. We wish to discover if the usage of different text variations could actually affect the sentiment level of expressions. In the questionnaire, the sequencing of the positive and negative sets of phrases was randomly arranged to eliminate straight-lining and respondent bias when answering the questions, this method is named as the intercept method (Cohen et al., 2011). Each question was divided into eight sub-questions and simulated as follows: -Unformatted text (e.g. I love it). -A whole phrase in capital letters (e.g. I LOVE IT). -A phrase that ends with two exclamation marks (e.g. I love it!!). -A phrase that ends with four exclamation marks (e.g. I love it!!!!). -A phrase with specific word(s) in capital letters (e.g. I LOVE it). -A phrase with repeated letters (e.g. I looooooove it). -A phrase with a positive emoticon (e.g. I love it :)).\n-A phrase with a negative emoticon (e.g. I love it :().\nTo collect a broader scale of values, the answers were set to a 7-point scale with the following preferences: 1) strongly dislike, 2) dislike, 3) slightly dislike, 4) neutral, 5) slightly like, 6) like, and 7) strongly like. Results from a 7-point scale are considered to be more accurate than those from a 5-point scale (M. a. Riordan and Kreuz, 2010). Using the intercept methods (Cohen et al., 2011), 500 university students were randomly and personally approached by respondents (Teh et al., 2015a). To participate in this study, the respondents must fit the criteria of having\nDeleted: Table 2\nprior experience in using social media and being fluent in English. The respondents were asked to rate the customer comments in the simulated variations based on whether the comments showed a liking or disliking for a product. Results for this experiment are presented in Section 4.1."
        },
        {
            "heading": "3.3 Phase 3: Experiment with Sentiment Tools",
            "text": "Ten2 freely accessible online sentiment tools were evaluated in this study. Sentiment analysis tools are a type of Natural Language Processing (NLP) tool (Wu et al., 2007) which examine the value of text and determines the overall emotional level. In general, each tool produces a score for the text based on the different methods, algorithms, and lexicons used, and so on. For instance, some tools rate the text based on polarity categories (e.g. positive, negative or neutral); others produce numeric scores that can be varied in range. The criterion for selecting those tools is that they can process short text messages similar to online comments/reviews. The software code that we have written can automatically extract the score from these tools and is now available online. Other tools needed to be downloaded, and a licence required. Different sentiment tools have different scales as displayed in Table 4 and inllustrated Figure 2.\nThe results of this study had to be scaled for consistent comparison and benchmarking purposes. For instance, the score for Opinionlexicon ranges from -2 to 2, which includes 0 in between, SentiStrength (Thelwall et al., 2010) ranges from -5 to +5 without having 0, Vader (Hutto and Gilbert, 2014) ranges from -1 to 1, including 0, and SentiWordNet (Esuli et al., 2006) ranges from -3 to 3 including 0. Without scaling, benchmarking cannot be done, and tools for different domains cannot be compared. Should there be a concern that normalisation could cause information loss, we argue that it has not affected the results of this study. The reason is that normalisation provides a standard scaling for comparison to be made and to demonstrate the ability of the tools in analysing the textual variation layer. The result of the comparison has no impact on our measurement. Table 5 summarizes the notations used in this model. Table 5 summarizes the notations used in this model.\nTable 5 Notations used in the paper.\nSymbol Description \ud835\udc67 Normalized score in the\nrange of \u2013 1 to 1 \ud835\udc65 Sentiment score collected from sentiment tools \ud835\udc54 Mean absolute error (MAE) \ud835\udc66! Prediction \ud835\udc65! True value \ud835\udc5b Total number of data points \ud835\udc5a Root mean squared error\n(RMSE) \ud835\udd26 Variable \ud835\udc57 Number of non-missing\ndata points \ud835\udc65! Actual observation time series \ud835\udc66! Is estimated time series \ud835\udeff Percent error \ud835\udc66\" Expected value \ud835\udc62 Root relative squared error (RRSE) \ud835\udc43#$\nValue predicted by the the individual model\n\ud835\udc58 Record \ud835\udc57 out of \ud835\udc5b records \ud835\udc47$ The target value for the\nrecord \ud835\udc57\nThe normalisation scoring range was set from -1 to 1, with 0 indicating neutral. Normalisation was performed manually by applying the following general rescaling formula (Li and Liu, 2011): \ud835\udc67 = ((\ud835\udc65! \u2212\ud835\udc5a\ud835\udc56\ud835\udc5b(\ud835\udc65 )/(\ud835\udc5a\ud835\udc4e\ud835\udc65(\ud835\udc65 ) \u2212 min (\ud835\udc65)) (1) where min x = -1 and max x = 1, and min x and max x refer to an arbitrary range of sentiment scores. To automatically test these ten tools, a prototype tool was built for accessing the sentiment tools. For each input text, the tool simultaneously produced ten sentiment analysis results using the ten tools. A total of fifty positive and fifty negative text samples were tested, with each sample simulated with the seven variations as in Figure 1. Result for each simulated sample was recorded for further analysis.\nOne hundred samples (real comments) from social media were selected randomly and\ntested on sentiment tools. Those samples are different from the previously mentioned 40\nsamples used for the survey. Each of the samples were simulated using the model shown in Figure 1. A total of eight variations of one sample was used, including unformatted text.\nThe sentiment score data generated with the sentiment tools were analysed using Weka,\na data mining tool (Hall et al., 2009). One classifier was selected, in light of a previous study, to produce five statistical measures to compare the sentiment tools\u2019 performance (Pak and Teh, 2016). Each tool was selected as a class to produce its corresponding outcome.\nThe five statistical measures such as mean absolute error (MAE), root mean squared\nerror (RMSE), relative absolute error (RAE), root relative squared error (RRSE), and the difference between MAE and RMSE were used for analysis.\nMAE measures the average magnitude of errors in a set of predictions without\nconsidering their direction. It is the average over the test samples of the absolute difference between prediction and actual observation where all individual differences have equal weight (Chai and Draxler, 2014). The formula for MAE is below:\n\ud835\udc54=\u2211 \"!\"# |%!&'! | \"\n(2)\nRMSE is a quadratic scoring rule that also measures the average magnitude of the error.\nIt is the square root of the average of squared differences between prediction and actual observation (Chai and Draxler, 2014). The formula for RMSE is below:\n\ud835\udc5a=#\u2211 (!\"# (*!&%! ) $\n( (3)\nRAE is very similar to the relative squared error in the sense that it is also relative to a\nsimple predictor, which is the average of the actual values (Subramanian et al., 2016). Mathematical equation of RAE is below:\n\ud835\udeff = &'!&%% %% & \u2219 100% (4) RRSE is relative to what it would have been if a simple predictor had been used. More\nspecifically, this simple predictor is just the average of the actual values. Thus, the relative\nsquared error takes the total squared error and normalises it by dividing the total squared error of the simple predictor (Subramanian et al., 2016). The mathematical equation of RRSE is below:\n\ud835\udc62=, \u2211 ,-&'&.'/\n$( ')# \u2211 ,.'&.0/ $( ')# (5)\nThe formula for \ud835\udc47. is below:\n\ud835\udc47.=1 \" \u2211 \ud835\udc47(\"(&1 (6)"
        },
        {
            "heading": "4 Results",
            "text": ""
        },
        {
            "heading": "4.1 Statistical Analysis Results from Phases 1 And 2",
            "text": "Before subjecting our survey data to hypothesis testing using one sample t-test, our data\nwas examined for sample size adequacy, data distribution and the threat of common method bias. Two outliers were removed due to participants not having experience in online shopping. Results from the sample size assessment using G*Power post-hoc analysis showed the appropriateness of the sample size for this study (n=498), with power = 1.000 based on 0.15 effect size. Further, the normality of the data distribution was assessed based on (Kline, 2005) skewness (\u00b13) and kurtosis (\u00b110) thresholds. To avoid common method bias, (Podsakoff et al., 2003) procedural remedy of retaining the survey respondents\u2019 anonymity during data collection was applied. The reliability of our measures based on the seven types of variants used in online comments was assessed. Results from Cronbach's alpha analysis (Table 6) verified the reliability of measurements used in this study, as all Cronbach\u2019s alpha values are recorded at >0.7 (Nunnally and Bernstein, 1979). Table 6 also shows the mean of all rankings provided by the participants based on the variety of the different sentences using the same typographical elements.\nTable 6 Mean, Standard Deviation and Cronbach's Alpha for each Evaluated Variation for Positive and Negative Text\nConstruct Mean S.D. Cronbach\u2019s Alpha\nPositive Statements Unformatted Text 4.667 0.77 0.873 Capital Letters 5.492 0.926 0.908 2 exclamation marks at the end 4.921 0.87 0.894 4 exclamation marks at the end 5.533 1.127 0.943 Certain Words in Capital 4.872 0.941 0.905 Repeated Letters 5.149 1.36 0.951 Positive Emoticons 5.205 1.184 0.932 Negative Emoticons 3.461 0.924 0.901 Negative Statements Unformatted Text 3.648 0.851 0.817 Capital Letters 2.879 1.279 0.875 2 exclamation marks at the end 3.266 1.092 0.878 4 exclamation marks at the end 2.693 1.393 0.914 Certain Words in Capital 2.999 1.074 0.866 Repeated Letters 2.783 1.07 0.850 Positive Emoticons 3.514 0.881 0.816 Negative Emoticons 2.587 0.989 0.850\nThe paired sample t-test results in Table 7 show that the means for all seven variations\nof sentiment format are significantly different from the unformatted positive statement with unformatted text.\nAll hypotheses are supported with mean differences varying from 0.204 to -1.207 (t-values ranging from 4.04 to 23.455, p-value <0.01***, 05**) and 95% confidence intervals that do not straddle the value of zero. Similarly, all seven variations of negative statements correlate with negative statements with normal text.\nTexts using a mix of capital letters and two exclamation marks at the end makes the\nleast mean difference when compared to standard positive statements (0.204 and 0.253, respectively). When positive comments are given in all capital letters and four exclamation marks at the end, the mean differences are 0.825 and 0.865, close to a one-unit increase in sentiment values. Repeated letters and positive emoticons used in positive statements also increase the sentiment value of positive text to 0.5 unit. The role of negative emoticons in changing the sentiment values of positive statements is the highest (more than one unit) compared to the other variations of text (mean difference = -1.207).\nThe use of positive emoticons in negative statements does not clearly affect the value\nof negative statements mean = -0.135). When negative statements are expressed with two exclamation marks at the end (mean difference = - 0.382), the sentiment values change the\nFigure 3 Average scores from collected survey for positive and negative statements.\nleast. It is worth noticing that for all other forms of variations in negative statements\n(all capital letters, four exclamation marks at the end, a mix of capital letters, and repeated letters), the magnitude of the mean difference exceeds more than 0.5 unit. As for positive statements, the role of negative emoticons in changing the sentiment values of negative statements is the highest (more than one unit) compared to the other variations of text (mean difference = -1.061).\nError! Reference source not found.3 shows the bar graph comparing positive and\nnegative statements with their respective sentiment variations. When comparing the use of variations for both statements, the magnitude of change in negative statements is larger compared to positive statements. The use of exclamation marks reinforces the sentiment value of both positive and negative statements. The magnitude of change is significant when negative emoticons are used in both positive and negative statements. Negative emoticons reduce positive value for positive text. Whereas, the use of negative emoticons in negative text increase their negative value."
        },
        {
            "heading": "4.2 Sentiment Tools\u2019 Results from Phase 3",
            "text": "Findings show that different textual variations affect the human judgement of sentiment values. In this section, further analysis of the impacts of the textual variations is compared with existing/available automatic sentiment analysis tools. Specifically, automated sentiment analysis and detection were investigated by testing the text samples with variations in ten existing tools listed in Table 8 and Table 9. The differences in tool performances were examined with and without the inclusion of variation.\nDeleted: Figure\ntools\u2019 performances. MAE and RMSE can be used together to diagnose the error variation in the study. The range for MAE and RMSE can be from 0 to 1. They are negatively oriented scores wherein lower values are better. Based on the MAE results in Table 8, the lowest value recorded by Opinionlexicon indicates that it has the lowest variance in individual errors. Moreover, the difference between MAE and RMSE for that tool is also the lowest followed by MPQA, SentiWordNet and SentiStrength, while IMDB shows the highest percentages for MAE, RMSE and the difference between the MAE and RMSE. It follows that the sentiment analysis based on IMDB failed the test for positive text. The sentiment algorithm based on WordNet in a study by Medagoda et al. (2016) reported an accuracy of 60%. Although in our study, RAE for WordNet is 33.69%, the remaining 66.31% of data were accurately classified, the accuracy close to that of (Medagoda et al., 2016).\nRRSE aggregates the magnitude of errors in multiple predictions into a single measure\nof predictive power. While RRSE is a good measure of accuracy, it is scale-dependent (Rong\net al., 2015), and therefore it only compares forecasting errors of different models for a particular variable\u2014not between variables. As such, smaller values are better and values greater than 100% indicate that the model is doing worse than just predicting the mean. RAE is computed similarly.\nAccording to the RAE results, the sentiment tools SentiStrength and Opinionlexicon\nrecorded the lowest values at 23.90% and 28.70% respectively. These show that the two tools outperformed the rest of the sentiment tools based on RAE results. Overall, the performances of Opinionlexicon and SentiStrength are considered to be the best according to the RAE and indicated RRSE values.\nTable 9 presents the results for negative text. Opinionlexicon is shown to record the\nlowest value for MAE (0.0118). However, Opinionlexicon has the second-lowest difference between MAE and RMSE (0.0083). Similarly, SentiWordNet has low values of MAE (0.0144) and the lowest difference between MAE and RMS (0.0059). SentiStrength, on the other hand, has the highest values of MAE and the difference between MAE and RMSE is 0.2514 and 0.5014, respectively. Therefore, based on MAE and RMSE, it can be concluded that Opinionlexicon and SentiWordNet perform the best for negative text testing, while SentiStrength is the poorest.\nThis study leads to the conclusion that human expressions in the form of textual\nvariations are equally important for analysis. This work can be a starting point for other studies to propose a method or framework to calculate sentiment by taking those textual variations into account. In addition, a previous study of Chaudhary et al. (2018) has also listed some possible weaknesses of current sentiment approaches which should be addressed. For instance, lexical affinity does not work well with negated sentences and is biased towards the text of a particular category. Overall, it can be seen that, even though the normalised set of data was used for\ncomparison, there is a difference in sentiment scoring between the available sentiment tools and human ratings."
        },
        {
            "heading": "5 Conclusion and Future Work",
            "text": "This paper investigated the issue of how textual variations affect human judgment, and the extent to which sentiment analysis tools fail to accurately reflect human judgement. Our main contribution in this research was to demonstrate that such textual variations have a significant impact on the accuracy of measuring sentiment values. More specifically, a novel large scale human rating experiment was carried out from which manual scores have been collected 3. The findings of our study further suggest that existing automatic sentiment analysis tools should take into account textual variations in text in comparison with human judgement.\nOur results show that sentiment analysis algorithms/tools should not remove or filter\ntextual variations from the analysis as it conveys vital sentiment information. These variations can be used to judge the sentiment values expressed in social media and online forums besides positive and negative ratings. Ignorance of textual variations is not \u201cbliss\u201d in this case, as previous research has also revealed their important implications, especially in linguistic studies. And our study uses technology and mathematics to prove the need to hold the value. This value is helpful in opinion mining for business, commerce, relevant text and data science. The implication for both industry practitioners and social media analysts is that the sentiment of comments in social media should not be judged at face value, as the \u201cemotion\u201d embedded within the textual variations hold the important sentiment. However, there are still more to be discovered, such as if emoticons can reverse the polarity of positive or negative comments (Teh et al., 2016), and how would it differ when it comes to textual variations? Future research should take that into account.\n3 The manual scores can be found at the following URL: at https://github.com/UCREL/HumanJudgementsOfSentimentValues\nThe findings of this study open several opportunities for future research. From the\ntechnical perspective, the limitations of existing sentiment analysis tools were highlighted, and the need to develop tools that consider textual variation information to be acknowledged. From the research and practical perspectives, this work shows the need to consider the textual variations in text-based comments (Teh et al., 2015b) when making marketing decisions based on social media content. Such studies can potentially lead to discoveries and study of influencer messages, texts and comments towards opinion leaders, customer advocates and even frustrated customers in EWoM. Finally, because linguistic usage and sentiments are culturally sensitive (Heise, 2014), a replication of this methodology for cross-cultural comparisons could be pursued."
        }
    ],
    "title": "Textual Variations Affect Human Judgements of Sentiment Values",
    "year": 2022
}