{
    "abstractText": "We propose a sample-based, sequential method to abstract a (potentially black-box) dynamical system with a sequence of memory-dependent Markov chains of increasing size. We show that this approximation allows to alleviating a correlation bias that has been observed in sample-based abstractions. We further propose a methodology to detect on the fly the memory length resulting in an abstraction with sufficient accuracy. We prove that under reasonable assumptions, the method converges to a sound abstraction in some precise sense, and we showcase it on two case studies.",
    "authors": [
        {
            "affiliations": [],
            "name": "Adrien Banse"
        },
        {
            "affiliations": [],
            "name": "Licio Romao"
        },
        {
            "affiliations": [],
            "name": "Alessandro Abate"
        },
        {
            "affiliations": [],
            "name": "Rapha\u00ebl M. Jungers"
        }
    ],
    "id": "SP:e0005e0353c31494ac3ae84677a4abe9cfd795a1",
    "references": [
        {
            "authors": [
                "E. Lee",
                "S. Seshia"
            ],
            "title": "Introduction to Embedded Systems: A Cyber-Physical Approach",
            "venue": "MIT Press",
            "year": 2011
        },
        {
            "authors": [
                "C. Baier",
                "J.P. Katoen"
            ],
            "title": "Principles of Model Checking",
            "venue": "MIT Press Books",
            "year": 2008
        },
        {
            "authors": [
                "A. van der Schaft"
            ],
            "title": "Equivalence of dynamical systems by bisimulation,",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2004
        },
        {
            "authors": [
                "P. Tabuada"
            ],
            "title": "Verification and Control of Hybrid Systems",
            "venue": "Springer",
            "year": 2009
        },
        {
            "authors": [
                "G. Reissig",
                "A. Weber",
                "M. Rungger"
            ],
            "title": "Feedback refinement relations for the synthesis of symbolic controllers,",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2017
        },
        {
            "authors": [
                "R. Majumdar",
                "N. Ozay",
                "A.K. Schmuck"
            ],
            "title": "On abstraction-based controller design with output feedback,",
            "venue": "Association for Computing Machinery, Inc,",
            "year": 2020
        },
        {
            "authors": [
                "M. Zamani",
                "M. Mazo",
                "M. Khaled",
                "A. Abate"
            ],
            "title": "Symbolic abstractions of networked control systems,",
            "venue": "IEEE Transactions on Control of Network Systems,",
            "year": 2018
        },
        {
            "authors": [
                "M.S. Mufid",
                "D. Adzkiya"
            ],
            "title": "and A",
            "venue": "Abate, \u201cBounded model checking of max-plus linear systems via predicate abstractions,\u201d vol. 11750 LNCS, pp. 142\u2013159, Springer",
            "year": 2019
        },
        {
            "authors": [
                "R. Majumdar",
                "K. Mallik",
                "S. Soudjani"
            ],
            "title": "Symbolic controller synthesis for b\u00fcchi specifications on stochastic systems,",
            "venue": "Association for Computing Machinery, Inc,",
            "year": 2020
        },
        {
            "authors": [
                "A. Salamati",
                "A. Lavaei",
                "S. Soudjani"
            ],
            "title": "and M",
            "venue": "Zamani, \u201cData-driven safety verification of stochastic systems via barrier certificates,\u201d IFAC-PapersOnLine, vol. 54, no. 5, pp. 7\u201312",
            "year": 2021
        },
        {
            "authors": [
                "M.D. Rossa",
                "Z. Wang",
                "L.N. Egidio"
            ],
            "title": "and R",
            "venue": "M. Jungers, \u201cData-driven stability analysis of switched affine systems,\u201d in 2021 60th IEEE Conference on Decision and Control (CDC), pp. 3204\u20133209",
            "year": 2021
        },
        {
            "authors": [
                "Z. Wang",
                "R.M. Jungers"
            ],
            "title": "A data-driven method for computing polyhedral invariant sets of black-box switched linear systems,",
            "venue": "IEEE Control Systems Letters,",
            "year": 2021
        },
        {
            "authors": [
                "R. Coppola",
                "A. Peruffo",
                "M. Mazo"
            ],
            "title": "Data-driven abstractions for verification of deterministic systems,",
            "year": 2022
        },
        {
            "authors": [
                "T. Badings",
                "L. Romao",
                "A. Abate",
                "D. Parker",
                "H. Poonawala",
                "M. Stoelinga"
            ],
            "title": "and N",
            "venue": "Jensen, \u201cRobust control for dynamical systems with non-gaussian via formal abstractions,\u201d Journal of Artificial Intelligence Research. To appear",
            "year": 2022
        },
        {
            "authors": [
                "A. Devonport",
                "A. Saoud"
            ],
            "title": "and M",
            "venue": "Arcak, \u201cSymbolic abstractions from data: A pac learning approach,\u201d in 2021 60th IEEE Conference on Decision and Control (CDC), pp. 599\u2013604",
            "year": 2021
        },
        {
            "authors": [
                "M. Lahijanian",
                "S.B. Andersson",
                "C. Belta"
            ],
            "title": "Formal verification and synthesis for discrete-time stochastic systems,",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2015
        },
        {
            "authors": [
                "C. Belta",
                "B. Yordanov",
                "E.A. Gol"
            ],
            "title": "Formal Methods for Discrete-time Dynamical Systems",
            "venue": "Springer",
            "year": 2017
        },
        {
            "authors": [
                "A.K. McCallum"
            ],
            "title": "Reinforcement learning with selective perception and hidden state",
            "venue": "University of Rochester",
            "year": 1996
        },
        {
            "authors": [
                "A.K. Schmuck",
                "J. Raisch"
            ],
            "title": "Asynchronous l-complete approximations,",
            "venue": "Systems and Control Letters,",
            "year": 2014
        },
        {
            "authors": [
                "L. Frezzatto"
            ],
            "title": "M",
            "venue": "C. de Oliveira, R. C. Oliveira, and P. L. Peres, \u201cRobust h\u221e filter design with past output measurements for uncertain discrete-time systems,\u201d Automatica, vol. 71, pp. 151\u2013158",
            "year": 2016
        },
        {
            "authors": [
                "D. Salamon"
            ],
            "title": "Measure and Integration",
            "venue": "European Mathematical Society, 2016",
            "year": 2016
        },
        {
            "authors": [
                "T. Tao"
            ],
            "title": "An Introduction to Measure Theory",
            "venue": "American Mathematical Society",
            "year": 2011
        },
        {
            "authors": [
                "W. Rudin"
            ],
            "title": "Real and Complex Analysis",
            "venue": "McGraw-Hill",
            "year": 1970
        },
        {
            "authors": [
                "A. Abate",
                "M. Prandini",
                "J. Lygeros"
            ],
            "title": "and S",
            "venue": "Sastry, \u201cProbabilistic reachability and safety for controlled discrete time stochastic hybrid systems,\u201d Automatica, vol. 44, no. 11, pp. 2724\u20132734",
            "year": 2008
        },
        {
            "authors": [
                "J.W. Polderman",
                "J.C. Willems"
            ],
            "title": "Introduction to Mathematical Systems Theory: A Behavioral Approach",
            "venue": "Berlin, Heidelberg: Springer-Verlag",
            "year": 1997
        },
        {
            "authors": [
                "M. Viana",
                "K. Oliveira"
            ],
            "title": "Foundations of ergodic theory",
            "venue": "No. 151, Cambridge University Press",
            "year": 2016
        },
        {
            "authors": [
                "N.P. Fogg",
                "V. Berth\u00e9",
                "S. Ferenczi",
                "C. Mauduit",
                "A. Siegel"
            ],
            "title": "Substitutions in dynamics",
            "venue": "arithmetics and combinatorics. Springer",
            "year": 2002
        },
        {
            "authors": [
                "C.P. Dettmann",
                "R.M. Jungers"
            ],
            "title": "and P",
            "venue": "Mason, \u201cLower bounds and dense discontinuity phenomena for the stabilizability radius of linear switched systems,\u201d Systems & Control Letters, vol. 142, p. 104737",
            "year": 2020
        },
        {
            "authors": [
                "D.P. Stanford",
                "J.M. Urbano"
            ],
            "title": "Some convergence properties of matrix sets,",
            "venue": "SIAM Journal on Matrix Analysis and Applications,",
            "year": 1994
        },
        {
            "authors": [
                "J.-M. Yang",
                "T. Moor"
            ],
            "title": "and J",
            "venue": "Raisch, \u201cRefinements of behavioural abstractions for the supervisory control of hybrid systems,\u201d Discrete Event Dynamic Systems, vol. 30, no. 3, pp. 533\u2013560",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Safety-critical applications, such as autonomous vehicles, traffic control, and space systems, require the control designer to enforce rich temporal properties on trajectories of complex models [1]. A renown approach to address this overall goal relies on abstractions [2], whereby a finite-state machine (also known as \u201dsymbolic model\u201d) approximates the behaviour of the original (a.k.a. \u201dconcrete\u201d) system that, instead, evolves in a continuous (or even hybrid) state space. Formal verification and correct-by-design synthesis frameworks have been developed by defining mathematical relationships between the finite-state machine and the original dynamics, such as alternating simulation relations [3\u20136].\nDespite the success of abstraction methods, most of the existing techniques rely on full knowledge of the underlying dynamical system [7\u20139]. This may hamper applicability of these methods when the model is too complex or when it cannot be fully built. For this reason, data-driven methods are gaining popularity [10\u201316]. In order to generate data-driven abstractions, a common approach consists in sampling the initial condition and observing trajectories of a fixed length that unfold from the sampled points, as in [17]. Alternative approaches consist in combining backward reachable-set computations and scenario optimization to generate, with a given confidence level, an abstract interval Markov chain [16], or in representing noisy dynamics with non-deterministic/probabilistic abstractions [18].\nBuilding Markov chain abstractions of dynamical systems must be made with care, as this process may introduce properties in the abstraction that were not present in the original dynamics. As an example of this phenomenon, consider the pictorial discrete-time dynamical system in Figure 1 and a partition of its state space into two cells corresponding to labels a and b. All initial states from the light-red region of a are mapped into the same region, as depicted by the self-loop, and all states in the dark-red region are mapped into a measure-zero subset of b \u2013 represented by the black line segment contained in b. Initial states at the yellow region of b are mapped into the same region, and points in the line segment are mapped back into partition a.\n\u2217Email address: adrien.banse@uclouvain.be. \u2020R. M. Jungers is a FNRS honorary Research Associate. This project has received funding from the European Research Council (ERC) under the European Union\u2019s Horizon 2020 research and innovation program under grant agreement No 864017 - L2C. R. M. Jungers is also supported by the Walloon Region and the Innoviris Foundation.\n\u2021Adrien Banse and Raphae\u0308l M. Jungers are with ICTEAM, UCLouvain, and Licio Romao and Alessandro Abate are with the Department of Computer Science, Oxford University.\nar X\niv :2\n21 2.\n01 92\n6v 1\n[ ee\nss .S\nY ]\n4 D\nec 2\n02 2\nOn the top-right corner of Figure 1 we illustrate an abstraction obtained by sampling initial conditions from a known distribution and using the frequencies of the different transitions to compute the probabilities shown on the edges; notice that we associate one state per element of the partition. Using the obtained abstraction to infer transitions of our dynamics leads to erroneous conclusions. First, observe that words abb or aabb may happen with non-zero probability on the abstraction but are, in fact, not valid trajectories of the original dynamics since each ab must necessarily be followed by an a. We call these words spurious. Notice also that the abstraction on the top-right corner of Figure 1 does not represent all allowable words. For instance, the word aba is not allowed in the abstraction, despite it being a valid word in the original dynamics. We call such words missing.\nIn this paper, we propose a new, sequential approach to build abstractions, where the uncertainty raising from the abstraction step is quantified probabilistically. Such an approach entails turning epistemic uncertainty about the dynamics into aleatoric uncertainty represented by transition probabilities of the Markov chain, a feature we believe to be unique to our strategy, as far as abstraction of dynamical systems is concerned. By handling abstract probabilistic models, we can analyse the convergence of the probabilistic behaviours, as the abstraction precision increases, and thus can heuristically estimate the error associated to our models. To illustrate how memory can increase the expressiveness power of the generated abstraction, let us return to the pictorial dynamics of Figure 1 and let us observe the memory-2 Markov model given at the bottom-right corner on the same figure. Due to the memory, our abstraction can now capture all possible words associated to the dynamics and, as opposed to the memory-1 model, does not possess spurious words.\nWe prove below that, under some reasonable assumption, our abstraction procedure converges to the original system in some sense. We show on numerical examples that the technique works well even when the assumptions are not satisfied. We finally add that leveraging memory to improve the description of a dynamical system has been largely explored in different fields of mathematics, engineering, and computer science (see, e.g. [19\u201322]). In particular, [15] recently proposed it in a non-probabilistic setting. We show here that adding memory is crucial for the construction of probabilistic data-driven abstractions.\nThis paper is organised as follows. In Section 2 we introduce the setting and describe our data-driven abstraction procedure. In Section 3 we first prove our theoretical results, and then provide numerical experiments in Section 4. We then briefly conclude in Section 5."
        },
        {
            "heading": "2 Definitions and methodology",
            "text": ""
        },
        {
            "heading": "2.1 Definitions",
            "text": "Consider the discrete-time stochastic system given by\n\u03a3(\u03bd) = xk+1 \u223c T (\u00b7|xk)yk = H(xk) x0 \u223c \u03bd,\n(1)\nwhere xk \u2208 X \u2282 Rn is the state variable, \u03bd is an initial distribution from which the initial state is sampled, T (\u00b7|\u00b7) : X \u2192 P(X) : xk 7\u2192 T (\u00b7|xk) is a mapping from X to the set of probability measures on X, and H : X \u2192 A, with A being a finite set of outputs. If the stochastic kernel T maps to a Dirac distribution, and the initial distribution \u03bd are Dirac distributions we say that the system is deterministic, and we rewrite the first line of 1 into xk+1 = F (xk) for the sake of clarity.\nAssumption A (Measurability). The mapping T : X \u2192 P(X) is such that, for any A \u2282 X the function g(x) = \u222b A T (d\u03be|x) is integrable with respect to any measure on X, that is, the integral \u222b A g(\u03be)\u00b5(d\u03be) is properly defined for any measure \u00b5 \u2208 P(X).\nAssumption A is a standard technical requirement that enables one to assign probabilities to (sets of) trajectories1 generated by the stochastic dynamical system (1). The semantics of the dynamical system is denoted as follows: given an initial state x0 \u223c \u03bd, at any time index k the next state xk+1 is defined by sampling according to the probability measure defined by the mapping T , conditional on the current state xk. Such semantics are known as stochastic hybrid systems [26].\nThe output map H induces a partition on the state space as follows. Let A = {y1, . . . , yM} and consider the equivalent relation on Rn given by x \u2248 x\u2032 if and only if H(x) = H(x\u2032). Denote the equivalence classes associated with each element of A by [yj ], j = 1, . . . ,M , i.e.,\n[yj ] = {x \u2208 Rn : H(x) = yj}.\nDefinition 1 (Probabilities on the states). For any k \u2208 N, consider the set A = A0 \u00d7A1 \u00d7 . . .\u00d7AL, where Aj \u2282 Rn for all j \u2264 k, and a probability measure \u00b5 \u2208 P(Rn) be given. The dynamical system (1) induces a measure on \u220fL+1 i=1 Rn that is given by\nQL(A) = \u222b A0 . . . \u222b AL L\u220f j=1 T (dxj |xj\u22121)\u00b5(dx0).\nDefinition 2 (Probabilities on the equivalence classes). For any L \u2208 N, let QL be defined as in Definition 1 and let y = (y0, y1, . . . , yL), where yj \u2208 A, j = 0, . . . , L, be the output of the dynamical system given in (1). Let A = [y0] \u00d7 [y1] \u00d7 . . . \u00d7 [yL] be the set associated with the word y. Then, the probability of such a word is given by QL(A).\nThe measures in definitions 1 and 2 are well defined thanks to Assumption A, which ensures that all the nested integrals are well-defined. Again we refer the reader to the textbooks mentioned above for the complete theoretical framework. Next, we formally introduce the set of trajectories that can be observed with probability larger than zero for the system (1), which is also referred to as the behaviour of (1) (see [27] for more details).\nDefinition 3 (Behaviour). Consider the dynamical system in (1), let A? be the countable Cartesian product of A and let AL be the L-fold Cartesian product of A. Then we have that:\n\u2022 The behaviour of system (1), denoted by B(\u03a3), is the subset of A? defined as B(\u03a3) = {y \u2208 A? : Q(y) > 0}, where Q is the unique measure induced by (1) in the space2 A?.\n\u2022 The L-th step behaviour of the dynamical system (1), denoted by BL(\u03a3), is a subset of AL+1 defined as BL(\u03a3) = {y = (y0, . . . , yL) \u2208 AL+1 : QL(y) > 0}.\nThe behaviours B(\u03a3) and BL(\u03a3) are naturally equipped with the probability measures QB(\u03a3) and QBL(\u03a3), as per their definition.\nIn addition to the concepts above, we provide a notion of metric between two behaviours.\n1For a complete measure-theoretical description of system (1) we refer the reader to [23,24] and Chapters 2-7 of [25]. 2This construction can be made rigorous using adequate measure-theoretic results that we omit for brevity, however see [24]\nfor more details.\nDefinition 4. Given two dynamical systems \u03a31 and \u03a32 with the same set of outputs A as in (1), and a horizon h \u2208 N, we define the metric dh(\u03a31,\u03a32) as\ndh(\u03a31,\u03a32) := QBh(\u03a31)(Bh(\u03a31) \\ Bh(\u03a32)) + QBh(\u03a32)(Bh(\u03a32) \\ Bh(\u03a31))."
        },
        {
            "heading": "2.2 Memory-based Markov chains",
            "text": "Inspired by the discussion about the behaviour of the dynamical system depicted in Figure 1, in this section we formalise the syntax and semantics of a memory-based Markov model, which we employ as a template for the abstractions of the given dynamical system.\nDefinition 5 (Memory-` Markov model). Let ` \u2208 N be a natural number and A be a finite alphabet. A memory-` Markov model is the 4-tuple \u03a3` := (S`, P`, \u03bd`, H`), where S` is a subset of A`, P` is the associated stochastic transition matrix, \u03bd` is the initial state probability, and H` : S` 7\u2192 A is the output (or labelling) map defined as H`((y0, . . . , y`\u22121)) = y`\u22121, that is, it is the projection onto the last coordinate of elements of S`. The semantics of the model is a follows: a path (y(0), . . . , y(L)), where each y(j) \u2208 A`, j = 0, . . . , L, is an admissible path of size L + 1 of a memory-` Markov model (S`, P`, \u03bd`, H`) if the following three conditions hold:\n1. Each y(j) is an element of S` and y(0) is sampled from \u03bd`.\n2. For all j = 0, . . . , L \u2212 1, each y(j+1) is obtained from y(j) by shifting its entries to the left, removing the first element, and inserting an element of A into the last, empty entry.\n3. For all j = 0, . . . , L \u2212 1, we have that P`(y(j+1) | y(j)) > 0, that is, there is a non-zero probability of transitioning from y(j) to y(j+1).\nSimilarly as in Definition 3 we denote by B(\u03a3`) the behaviour of a memory-` Markov model, which is the collection of all possible outputs that can be observed by running trajectories of the model according to its semantics. The probabilities QB(\u03a3`) and QBh(\u03a3`) are respectively the unique measures on B(\u03a3`) and Bh(\u03a3`), defined by the transition probability and the initial distribution on words. Details are omitted for brevity. An example of a memory-2 Markov model as explained above is depicted on the bottom-right corner in Figure 1.\nIn this work, we will compute the metric defined in Definition 4 on two Markov models \u03a3`1 and \u03a3`2 where one is a refinement of the other (if we assume that we have enough samples so as not to miss any trace), it is dh(\u03a3`1 ,\u03a3`2), where h > `1 > `2. In that case, the symmetric difference in the above definition actually only contains one term. This allows us to evaluate the quality of these models as approximations for the original dynamics."
        },
        {
            "heading": "2.3 Construction and refinement of probabilistic abstractions",
            "text": "In this subsection we explain in detail our methodology that provides, at every step, an abstract model in the form of a memory-` Markov model, obtained by recording the last ` observations. To refine our proposed abstraction we increase the memory of the model.\nOur technique, which is summarized in Algorithm 1, provides a memory-` abstraction for the dynamics in (1). It computes the probability P` by sampling long trajectories of length L > `, of the dynamics in (1). The entries of P` are estimated using the empirical probabilities, i.e., we let\nP`(y (2) | y(1)) = N\ny (1) 0 ...y (1) `\u22121y (2) `\u22121\n/ Ny(1) , (2)\nwhere y(1) = y (1) 0 . . . y (1) `\u22121, y (2) = y (1) 1 . . . y (1) `\u22122y (2) `\u22121 \u2208 A`. The symbol Ny, where y \u2208 A` for some ` \u2208 N, represents the number of times the word y appears in a word of size L > `. Notice also that y (1) 0 . . . y (1) `\u22121y (2) `\u22121 \u2208 A`+1. Additionally, the initial state distribution for the memory-` Markov model is defined for all y \u2208 A` by\n\u03bd`(y) = N \u2032 y /N \u2032, (3)\nwhere N \u2032y is the number of times the word y appears as the `-long prefix of a L-long sample, and N \u2032 is the total number of sampled trajectories of length L. In our results below, for the sake of clarity, we assume that we know exactly the conditional probabilities defined above. In practice, one would resort to finite sampling, and thereby would imply an estimation error. There are techniques in order to bound this error as, for instance, in [15]. However, the study of the impact of the sampling error, while certainly of practical importance, is not the focus of the present paper, and we leave it for further work. We formalise this in the next assumption:\nAssumption B. For any memory-` Markov model \u03a3` = (S`, P`, \u03bd`, H`), we assume that the transition probability P` and the initial distribution \u03bd` are known exactly.\nAn important feature of our approach is the fact that, irrespective of the memory of the model, the resulting Markov chain is only an approximation of the true dynamics. The reason for this relates to our discussion in the introduction of the paper: the original dynamics may require infinite memory to be represented without errors, and we are instead using a finite memory model, which naturally results in approximation errors. Despite this, we will show that under some hypotheses, successive refinements allow to better approximate the behaviour of a dynamical system. An important feature of our approach is the fact that, irrespective of the memory of the model, the resulting Markov chain is only an approximation of the true dynamics. The reason for this relates to our discussion in the introduction of the paper: the original dynamics may require infinite memory to be represented without errors, and we are instead using a finite memory model, which naturally results in approximation errors. Despite this, we will show below that under some hypotheses, successive refinements allow to better approximate the behaviour of a dynamical system. This claim will also be supported by the numerical examples to be presented later.\nAlgorithm 1 Overall technique (can be iterated for increasing `)\n1. Fix ` = 1, a number of samples N \u2032 1 and a sampling length L `\n2. Sample N \u2032 initial conditions according to initial distribution; simulate N \u2032 trajectories of length L\n3. Create memory-` Markov Model (cf. Def. 5) - initial distribution computed by restricting to `-prefixes, jump probabilities computed considering all subwords of length `+ 1, as per (2)\n4. If ` > 1, compute distance between models of memory 1, 2, . . . , `\u2212 1 and current model\n5. If distance is smaller than a given threshold, then compute the partitioning corresponding to the `-traces; output memory-` model as final model. If not, ` := `+ 1; return to item 2"
        },
        {
            "heading": "3 Technical Results",
            "text": "We first propose the following elementary proposition, which holds as a direct consequence of Assumption B. The proof is left for our extended version due to lack of space.\nProposition 1. Consider a dynamical system \u03a3 as in (1). For any horizon h \u2208 N, consider a Markov model approximation \u03a3h as in Subsection 2.3. It holds that dh(\u03a3h,\u03a3) = 0, where dh is defined as in Definition 4.\nWe now present our main result, which provides a justification for the procedure described in Subsection 2.3 and shows that it converges (in some sense) to a correct description of the infinite behaviour of the concrete system. The result leverages two important notions in dynamical systems theory: observability and ergodicity. In the result, we restrict our analysis to deterministic systems, and leave the derivation of a similar result for stochastic systems to future work.\nDefinition 6. A deterministic system as in (1) is observable if for any two trajectories x0x1 . . . and x \u2032 0x \u2032 1 . . . such that, for all i \u2265 0, H(xi) = H(x\u2032i), one has that liml\u2192\u221e \u2016xl \u2212 x\u2032l\u2016 = 0.\nTheorem 1. Consider a deterministic system \u03a3 as in (1), and the data-driven procedure explained in Subsection 2.3, generating successive abstract models \u03a3`, ` = 1, 2, . . . . Suppose that assumption B holds, and that the transition function F is an observable, continuous transformation of the compact state space X \u2282 Rn. Then there exists a function (`) > 0 such that (`) \u2192 0 and a perturbed system \u03a3 (`) that share the same probabilistic behaviour as the abstract model, that is B(\u03a3`) = B(\u03a3 (`)), and such that the dynamic equations of \u03a3 (`) are the same as those of the system \u03a3 perturbed by some noise W (x, k), that is:\n\u03a3 (`) := xk+1 = F (xk + wk)yk = H(xk) x0 \u223c \u03bd,\n(4)\nfor some wk \u223cW (xk, k) such that \u2016wk\u2016 < (`).\nProof. Our proof relies on the implicit existence of an abstraction of the concrete system \u03a3. In this abstraction, the abstract states correspond to the equivalence classes\n[y0 . . . y`\u22121] := {x : \u2203x0 : F `\u22121(x0) = x, H(F i(x0)) = yi : i = 0, . . . , `\u2212 1},\nwhere F i denotes the i-th functional power3. Let (`) be the diameter of the largest cell of the memory-` Markov model, that is, (`) = maxy0,...,y`\u22121{diam([y0 . . . y`\u22121])}. By observability of F and compactness of X, the maximal diameter (`) tends to zero. Moreover, it is well known that since F is continuous on the compact X, it admits an invariant measure \u00b5 (see [28, Theorem 2.1]). We now prove that, by Birkhoff\u2019s theorem [28, Theorem 3.2.3], and assuming perfect sampling by Assumption B, the probability on edge ([y0 . . . y`\u22121], [y1 . . . y`]) in model \u03a3` is equal to P(xk+1 \u2208 [y1 . . . y`] |xk \u2208 [y0 . . . y`\u22121]), where xk \u223c \u00b5, and \u00b5 is the ergodic measure of F . Indeed, denoting the indicator function\n\u03c7y0...y`(x) := { 1 if \u2203x0 : x = F `(x0) and H(x0F (x0) . . . F `(x0)) = y0 . . . y`, 0 otherwise,\nand applying Birkhoff\u2019s theorem, we have that\nNy0...y`/Ny0...y`\u22121 = \u222b X \u03c7[y0...y`](x)d\u00b5 /\u222b X \u03c7[y0...y`\u22121](x)d\u00b5 (5)\n= \u222b x\u2208[y0...y`\u22121]:H(F (x))=y` d\u00b5 /\u222b x\u2208[y0...y`\u22121] d\u00b5 (6)\n= P\u00b5(F (x) \u2208 [y1 . . . y`] |x \u2208 [y0 . . . y`\u22121]). (7)\nEquation (5) above follows from the application of Birkhoff\u2019s theorem (twice), Equation (6) follows from the invariance of the measure \u00b5, and Equation (7) is the definition of conditional probability.\nWe now claim that we can modify the initial probability distribution P0 such that the concrete system behaves as our model (we will then iterate the same argument for times k > 1). Consider any probability distribution P0, we show that one can build a probability distribution P\u20320 such that P\u20320([y0 . . . y`\u22121]) = P0([y0 . . . y`\u22121]), and such that P\u20320(x |x \u2208 [y0 . . . y`\u22121]) = P\u00b5(x |x \u2208 [y0 . . . y`\u22121]). This new distribution is defined over [y0 . . . y`\u22121] as follows:\nP\u20320(x) = \u00b5(x) P([y0 . . . y`\u22121]) \u00b5([y0 . . . y`\u22121]) .\n3For i = 0, f0 = id, the identity function, and for i > 0, the i-th functional power of some function f is defined inductively as f i = f \u25e6 f i\u22121 = f i\u22121 \u25e6 f .\nMoreover, since P\u20320([y0 . . . y`\u22121]) = P0([y0 . . . y`\u22121]), one can express x\u2032 \u223c P\u20320 as x\u2032 = x + w, where x \u223c P0 and w \u223c W (x, 0), and W (x, 0) has support of diameter (`) (because W (x, 0) perturbs P0 in the cell to which x belongs). Now, the push-forward measure P1 := P\u20320(F\u22121(x)) will not, in general, be equal to \u00b5. However, we can reiterate the construction above and provide a perturbation P\u20321 such that P\u20321([y0 . . . y`\u22121]) = P1([y0 . . . y`\u22121]), and such that P\u20321(x |x \u2208 [y0 . . . y`\u22121]) = P\u00b5(x |x \u2208 [y0 . . . y`\u22121]). Again, P\u20321 can be achieved by a perturbation w \u223c W (x, 1) such that w < (`), and the proof is concluded by induction."
        },
        {
            "heading": "4 Experiments",
            "text": "For a fixed dynamical system \u03a3, experiments are set up as follows. For successive values of `, we compute the associated memory-` Markov model \u03a3` = (S`, P`, \u03bd`, H`), as explained in subsection 2.3. We also fix a horizon h > `, for which we compute the corresponding memory-h Markov model \u03a3h = (Sh, Ph, \u03bdh, Hh). First, for each memory-` model, we compute their metric as defined in Definition 4 with respect to the memory-h model, that is, dh(\u03a3`,\u03a3h). This measure is a probabilistic representation of the quality of the memory-` model with respect to Bh(\u03a3), the h-step behaviour of the true system, which we use as a proxy for B(\u03a3). Second, for each pair of memory-` and memory-(`+ 1) models, we compute their metric with respect to the same horizon h, namely dh(\u03a3`,\u03a3`+1). This second measure can be effectively computed in practice, and this distance between models ` and ` + 1 allows us to estimate how close our approximations are to convergence. In our experiments, we then verify this by comparing Bh(\u03a3`) with Bh\u03a3 (which might not be available in practical applications).\nWe begin by considering the system generating Sturmian words [29].\nExample 1 (Deterministic dynamical system). A sturmian system is a deterministic system defined on the state-space [0, 2\u03c0) \u2282 R where the next state is defined as\nxk+1 = F (xk) = xk + \u03b8 mod 2\u03c0, (8)\nfor some irrational angle \u03b8 and where the output is yk = H(xk), where H(x) = 0 if x \u2208 [0, \u03b8) and H(x) = 1 otherwise. An illustration of the Sturmian dynamics is provided in Figure 2. In the formalism introduced in (1), the alphabet is A = {0, 1}.\nWe also consider a system of different nature, namely endowed with switching and stochastic behaviour, which has been studied in [30,31].\nExample 2 (Stochastic switched system). Consider a switched system with two modes defined on the statespace R2, where the next state is defined as xk+1 = F\u03c3k(xk), where \u03c3k \u2208 {1, 2} and the maps Fi : R2 \u2192 R2 are linear maps Fi(x) = Aix for two matrices A1, A2 \u2208 R2\u00d72 defined as\nA1 = ( cos(\u03c0/6) sin(\u03c0/6) \u2212 sin(\u03c0/6) cos(\u03c0/6) ) and A2 = ( 1.02 0 0 1/2 ) .\nSuppose in addition that, at each time step, there is a fair probability (equal to 1/2) to switch to either mode. In the formalism introduced in (1), the stochastic kernel T (\u00b7|xk) is defined as4\nT (\u00b7|\u00b7) : R2 \u2192 P(R2) : xk 7\u2192 T (\u00b7|xk) = 1\n2 \u03b4{F1(xk)} +\n1 2 \u03b4{F2(xk)}. (9)\nIt is not clear whether it is possible to obtain a bi-simulation with classical refinement techniques, and thus we wish to obtain a non-trivial abstraction thanks to the data-driven approach explained in Section 2.3. For this reason, we propose a first rough partition of the state space. The alphabet A = {0, 1, . . . , 8} and the output function H define a partitioning of the state-space as illustrated in the right part of Figure 3. Together with the output, three trajectories of length 20 are represented in the left of Figure 3.\nIn these examples, we assume that one knows the closed-form description of the systems, but would like to find an abstraction of them. Results of multiple executions of the algorithm described above for Example 1 and Example 2 can respectively be found in Figure 4 and Figure 5. One can observe in these figures the red curve dh(\u03a3`,\u03a3`+1), which we can compute in practice, and the blue curve dh(\u03a3`,\u03a3h), which shows that the successive models indeed converge to the concrete model in terms of their behaviours for the (large) horizon h. This suggests a heuristic argument that, using the method described in Algorithm 1, one can infer the probabilistic precision of the memory-` abstract Markov model with any horizon h. Moreover, in Figure 6 and Figure 7, we display how in practice we can automatically build non-trivial abstractions of the concrete models. Observe that the method works well even for Example 2, which does not satisfy all assumptions of Theorem 1.\nThe generated abstract models can be further used to perform analysis or verification on the initial system, leveraging information from the probabilistic behaviour of transitions between abstract cells. This goal requires proper handling of the results in Theorem 1, and is left to future work."
        },
        {
            "heading": "5 Conclusions",
            "text": "In this work, we have proposed a new approach to build data-driven abstraction of rather general dynamical systems. We approximate the concrete system with a Markov model, thus aggregating the (aleatoric and) epistemic nondeterminism of the given model in the exclusively aleatoric uncertainty of the abstract stochastic model.\nThis technique can be expanded in many directions, both theoretical and practical: by making our computations more efficient, by leveraging the obtained abstraction as an actionable symbolic model, by adding control inputs, or by relaxing or removing some of the raised assumptions. We finally note that, as done recently in a non-probabilistic setting [32], one could push this methodology further and refine only certain memory-states, rather than increasing the memory level uniformly from ` to ` + 1: we leave this amelioration to further work.\n4\u03b4A is the Dirac function, it is \u03b4A(x) = 1 if x \u2208 A, and \u03b4A(x) = 0 otherwise."
        }
    ],
    "title": "Data-driven memory-dependent abstractions of dynamical systems",
    "year": 2022
}