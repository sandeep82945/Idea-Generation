{
    "abstractText": "Target recognition in SAR images was widely studied over the years. Most of these works were usually based on the assumption that the targets in the test set belong to a limited set of classes. In the practical scenarios, it is common to encounter various kinds of new targets. It is therefore more meaningful to study target recognition in open-world environments. In these scenes, it is needed to reject the unknown classes while maintain the classification performance on known classes. In the past years, few works were devoted to open set target recognition. Though the detection performance on unknown targets can be improved to a certain extent in the preceding works, most detection schemes are independent of a pretrained feature extractor, leading to potential open space risks. Besides, the model architectures are complicated, resulting in huge computational cost. To solve these problems, a family of new methods for open set target recognition is proposed. Targets indistinguishable from known classes are constructed by random sampling combination strategy. They are further sent into the classifier for feature learning. The original open-world environment is then transformed into a closed-world environment containing the unknown class. Moreover, the special implication of generated unknown targets is highlighted and used to realize unknown detection. Extensive experimental results on the MSTAR benchmark dataset illustrate the effectiveness of the proposed methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xiaojing Geng"
        },
        {
            "affiliations": [],
            "name": "Ganggang Dong"
        },
        {
            "affiliations": [],
            "name": "Ziheng Xia"
        },
        {
            "affiliations": [],
            "name": "Hongwei Liu"
        }
    ],
    "id": "SP:8ba5840b27c1e20819df3e36e8a086343f0b3251",
    "references": [
        {
            "authors": [
                "W. Du",
                "F. Zhang",
                "F. Ma",
                "Q. Yin",
                "Y. Zhou"
            ],
            "title": "Improving SAR target recognition with multi-task learning",
            "venue": "Proc. IEEE Int. Geosci. Remote Sens. Symp., 2020, pp. 284\u2013287.",
            "year": 2020
        },
        {
            "authors": [
                "C. Yin",
                "E. Blasch",
                "H. Chen",
                "Q. Tao",
                "G. Chen"
            ],
            "title": "Experimental featurebased SAR ATR performance evaluation under different operational conditions",
            "venue": "Proc. SPIE-Int. Soc. Opt. Eng., 2008, pp. 69680F\u201369680F12.",
            "year": 2008
        },
        {
            "authors": [
                "C. Wang",
                "X. Liu",
                "J. Pei",
                "Y. Huang",
                "Y. Zhang",
                "J. Yang"
            ],
            "title": "Multiview attention CNN-LSTM network for SAR automatic target recognition",
            "venue": "IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 14, pp. 12504\u201312513, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "B. Ding",
                "G. Wen",
                "X. Huang",
                "C. Ma",
                "X. Yang"
            ],
            "title": "Data augmentation by multilevel reconstruction using attributed scattering center for SAR target recognition",
            "venue": "IEEE Geosci. Remote Sens. Lett., vol. 14, no. 6, pp. 979\u2013983, Jun. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "C. Wang"
            ],
            "title": "Semisupervised learning-based SAR ATR via selfconsistent augmentation",
            "venue": "IEEE Trans. Geosci. Remote Sens., vol. 59, no. 6, pp. 4862\u20134873, Jun. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C. Zheng",
                "X. Jiang",
                "X. Liu"
            ],
            "title": "Semi-supervised SAR ATR via multidiscriminator generative adversarial network",
            "venue": "IEEE Sens J., vol. 19, no. 17, pp. 7525\u20137533, Sep. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "S.A. Wagner"
            ],
            "title": "SAR ATR by a combination of convolutional neural network and support vector machines",
            "venue": "IEEE Trans Aerosp Electron Syst., vol. 52, no. 6, pp. 2861\u20132872, Jan. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "S. Chen",
                "H. Wang",
                "F. Xu",
                "Y. Jin"
            ],
            "title": "Target classification using the deep convolutional networks for SAR images",
            "venue": "IEEE Trans. Geosci. Remote Sens., vol. 54, no. 8, pp. 4806\u20134817, Aug. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "N.A. Inkawhich",
                "E.K. Davis",
                "M.J. Inkawhich",
                "U.K. Majumder",
                "Y. Chen"
            ],
            "title": "Training SAR-ATR models for reliable operation in open-world environments",
            "venue": "IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 14, pp. 3954\u20133966, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "F.A. Sadjadi",
                "A. Mahalanobis",
                "M. Scherreik",
                "B. Rigling"
            ],
            "title": "Multi-class open set recognition for SAR imagery",
            "venue": "Proc. SPIE-Int. Soc. Opt. Eng., 2016, pp. 98440M\u201398440M9.",
            "year": 2016
        },
        {
            "authors": [
                "A.B. Bapst",
                "J. Tran",
                "M.W. Koch",
                "M.M. Moya",
                "R. Swahn"
            ],
            "title": "Open set recognition of aircraft in aerial imagery using synthetic template models",
            "venue": "Proc. SPIE-Int. Soc. Opt. Eng., 2017, pp. 1020206\u2013102020618.",
            "year": 2017
        },
        {
            "authors": [
                "Q. Song",
                "H. Chen",
                "F. Xu",
                "T.J. Cui"
            ],
            "title": "Em simulation-aided zero-shot learning for SAR automatic target recognition",
            "venue": "IEEE Geosci. Remote Sens. Lett., vol. 17, no. 6, pp. 1092\u20131096, Jun. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "S. Dang",
                "Z. Cao",
                "Z. Cui",
                "Y. Pi"
            ],
            "title": "Open set SAR target recognition using class boundary extracting",
            "venue": "Proc. 6th Asia-Pacific Conf. Synth. Aperture Radar, 2019, pp. 1\u20134.",
            "year": 2019
        },
        {
            "authors": [
                "J. Tang",
                "D. Xiang",
                "F. Zhang",
                "F. Ma",
                "Y. Zhou",
                "H. Li"
            ],
            "title": "Incremental SAR automatic target recognition with error correction and high plasticity",
            "venue": "IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 15, pp. 1327\u20131339, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "D. Hendrycks",
                "K. Gimpel"
            ],
            "title": "A baseline for detecting misclassified and out-of-distribution examples in neural networks",
            "venue": "Proc. Int. Conf. Learn. Represent., 2017. [Online]. Available: https://openreview.net/forum?id= Hkg4TI9xl",
            "year": 2017
        },
        {
            "authors": [
                "A. Bendale",
                "T. Boult"
            ],
            "title": "Towards open set deep networks",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2016, pp. 1563\u20131572.",
            "year": 2016
        },
        {
            "authors": [
                "L. Goodfellow"
            ],
            "title": "Generative adversarial nets",
            "venue": "Proc. Adv. Neural Inf. Process. Syst., 2014. [Online]. Available: https://proceedings.neurips. cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf",
            "year": 2014
        },
        {
            "authors": [
                "X. Sun",
                "Z. Yang",
                "C. Zhang",
                "K.-V. Ling",
                "G. Peng"
            ],
            "title": "Conditional Gaussian distribution learning for open set recognition",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2020, pp. 13477\u201313486.",
            "year": 2020
        },
        {
            "authors": [
                "H. Zhang",
                "A. Li",
                "J. Guo",
                "Y. Guo"
            ],
            "title": "Hybrid models for open set recognition",
            "venue": "Proc. Eur. Conf. Comput. Vis., 2020, pp. 102\u2013117.",
            "year": 2020
        },
        {
            "authors": [
                "X. Ma",
                "K. Ji",
                "L. Zhang",
                "S. Feng",
                "G. Kuang"
            ],
            "title": "An open set recognition method for SAR targets based on multitask learning",
            "venue": "IEEE Geosci. Remote Sens. Lett., vol. 19, 2021, Art. no. 4014005.",
            "year": 2021
        },
        {
            "authors": [
                "P.V. Overschee",
                "B.D. Moor"
            ],
            "title": "Subspace Identification for Linear Systems",
            "venue": "Subspace Identification for Linear Systems,",
            "year": 1996
        },
        {
            "authors": [
                "M. Skurichina",
                "R.P.W. Duin"
            ],
            "title": "Bagging, boosting and the random subspace method for linear classifiers",
            "venue": "Pattern Anal. Appl., vol. 5, no. 2, pp. 121\u2013135, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "P. Perera",
                "V.I. Morariu",
                "R. Jain",
                "V. Manjunatha",
                "V.M. Patel"
            ],
            "title": "Generative-discriminative feature representations for open-set recognition",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2020, pp. 11811\u2013 11820.",
            "year": 2020
        },
        {
            "authors": [
                "S. Lawrence",
                "C.L. Giles"
            ],
            "title": "Overfitting and neural networks: Conjugate gradient and backpropagation",
            "venue": "Proc. Int. J. Conf. Neural Netw., 2000, pp. 114\u2013119.",
            "year": 2000
        },
        {
            "authors": [
                "L.I. Bing",
                "W. Hong"
            ],
            "title": "Study of noise jamming to SAR",
            "venue": "Acta Electron. Sin., vol. 32, pp. 2035\u20132037, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "Y. Kwak",
                "W.J. Song",
                "S.E. Kim"
            ],
            "title": "Speckle-noise-invariant convolutional neural network for SAR target recognition",
            "venue": "IEEE Geosci. Remote Sens. Lett., vol. 16, no. 4, pp. 549\u2013553, Apr. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "V. Verma"
            ],
            "title": "Manifold mixup: Better representations by interpolating hidden states",
            "venue": "Proc. Int. Conf. Mach. Learn., 2018, pp. 6438\u20136447.",
            "year": 2018
        },
        {
            "authors": [
                "Z. Cao",
                "L. Xu",
                "J. Feng"
            ],
            "title": "Automatic target recognition with joint sparse representation of heterogeneous multi-view SAR images over a locally adaptive dictionary",
            "venue": "Signal Process., vol. 126, no. sep., pp. 27\u201334, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L. Neal",
                "M. Olson",
                "X. Fern",
                "W.-K. Wong",
                "F. Li"
            ],
            "title": "Open set learning with counterfactual images",
            "venue": "Proc. Eur. Conf. Comput. Vis., 2018, pp. 620\u2013 635.",
            "year": 2018
        },
        {
            "authors": [
                "R. Yoshihashi",
                "W. Shao",
                "R. Kawakami",
                "S. You",
                "M. Iida",
                "T. Naemura"
            ],
            "title": "Classification-reconstruction learning for open-set recognition",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2019, pp. 4011\u20134020. GENG et al.: SAR TARGET RECOGNITION VIA RANDOM SAMPLING COMBINATION IN OPEN-WORLD ENVIRONMENTS 343",
            "year": 2019
        },
        {
            "authors": [
                "G. Chen",
                "P. Peng",
                "X. Wang",
                "Y. Tian"
            ],
            "title": "Adversarial reciprocal points learning for open set recognition",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, pp. 8065\u20138081, Nov. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "G. Chen",
                "L. Qiao",
                "Y. Shi",
                "P. Peng",
                "Y. Tian"
            ],
            "title": "Learning open set network with discriminative reciprocal points",
            "venue": "Proc. Eur. Conf. Comput. Vis., 2020, pp. 507\u2013522.",
            "year": 2020
        },
        {
            "authors": [
                "H.-M. Yang",
                "X.-Y. Zhang",
                "F. Yin",
                "C.-L. Liu"
            ],
            "title": "Robust classification with convolutional prototype learning",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2018, pp. 3474\u20133482.",
            "year": 2018
        },
        {
            "authors": [
                "X. Ma",
                "K. Ji",
                "L. Zhang",
                "S. Feng",
                "B. Xiong",
                "G. Kuang"
            ],
            "title": "An open set recognition method for SAR targets based on multitask learning",
            "venue": "IEEE Geosci. Remote Sens. Lett., vol. 19, pp. 1\u20135, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "W.J. Scheirer",
                "D.R.R. Anderson",
                "A. Sapkota",
                "T.E. Boult"
            ],
            "title": "Toward open set recognition",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 35, no. 7, pp. 1757\u20131772, Jul. 2013.",
            "year": 2013
        },
        {
            "authors": [
                "C. Geng",
                "S.J. Huang",
                "S. Chen"
            ],
            "title": "Recent advances in open set recognition: A survey",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 43, no. 10, pp. 3614\u20133631, Oct. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "W.J. Scheirer",
                "L.P. Jain",
                "T.E. Boult"
            ],
            "title": "Probability models for open set recognition",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 36, no. 11, pp. 2317\u20132324, Nov. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "S.A. Rebuffi",
                "A. Kolesnikov",
                "G. Sperl",
                "C.H. Lampert"
            ],
            "title": "iCaRL: Incremental classifier and representation learning",
            "venue": "Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2017, pp. 5533\u20135542.",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Open set target recognition, open-world environments, random sampling combination, synthetic aperture radar (SAR).\nI. INTRODUCTION\nD ESIGNING target recognition systems has received con-siderable critical attention for synthetic aperture radar (SAR) data in a real-world environment. With the characteristics of active coherent imaging, SAR acquires high-resolution surface image data all day, all weather, and plays an irreplaceable role in modern high-tech information warfare. Recent developments in remote sensing technology have enabled more and more SAR images to be acquired. The interpretation of large-scale SAR images is an increasingly important area, in which target recognition is one of the research hotspots [1], [2], [3].\nManuscript received 15 August 2022; revised 11 October 2022 and 8 November 2022; accepted 24 November 2022. Date of publication 1 December 2022; date of current version 15 December 2022. This work was supported in part by the National Natural Science Foundation of China under Grant 61971324, Grant 61525105; in part by the Fund of National Lab of Radar Signal Processing, and the Shaanxi Innovation Team Project. (Corresponding author: Ganggang Dong.)\nThe authors are with the National Lab of Radar Signal Processing, Xidian University, Xi\u2019an 710000, China (e-mail: xjgeng_stu@163.com; dongganggang@ nudt.edu.cn; xiaziheng@stu.xidian.edu.cn; hwliu@xidian.edu.cn).\nDigital Object Identifier 10.1109/JSTARS.2022.3225882\nMost current research of SAR target recognition methods focuses only on a closed-world environment. The closed-world environment describes such a scenario, where the classes in the training set are consistent with the classes in the test set. These classes included in the training set are called known classes, and targets appeared in the test set all belong to known classes. The main task of target recognition is to accurately divide targets into one of the known classes in a closed-world environment, which is called closed-set recognition (CSR). Traditional CSR technology mainly includes three stages: data preprocessing, feature extraction, classification, and recognition. Because there is a heavy dependency on a large amount of professional knowledge and prior information to manually design feature extractors, these technology have high computational complexity and poor generalization performance. With the continuous development of deep-learning theory, various methods based on automatic feature extraction of neural network have shown significant advantages and become mainstream methods.\nBecause SAR image data are scarce while the learning process of CNN requires a large amount of data, some scholars propose to augument the training sample set to improve recognition performance. For example, Ding et al. [4] extracted the attributed scattering centers of original SAR images to reconstruct targets to expand the database. Wang et al. [5] designed a semisupervised learning framework including self-consistent augmentation rule, mixup-based mixture, and weighted loss, which allows a classification network to utilize unlabeled data during training. Similarly, Zheng et al. [6] proposed to generate new samples with the help of generative countermeasure network. And these unlabeled generated images are input to CNN together with the labeled images for semisupervised recognition. The expansion of sample set effectively prevents model overfitting caused by the small amount of training data. However, the quality of these augmented samples is difficult to guarantee. When augumented features are not representative, the existing classification performance is affected. What is more, some CSR methods optimize classification models by combining CNN and other deep-learning models such as autoencoder and SVM. For example, Wagner [7] suggested replacing the fully connected layers of CNN by a collection of SVMs for the final classification. In addition, elastic deformation and affine transformation are used to expand the training set. By optimizing the algorithm structure, such methods aim to reduce network complexity while improving classification accuracy. However, the generalization ability is relatively poor when dealing with small training datasets. Besides, some target recognition methods based on multifeature\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nfusion are also popular. Such as Chen et al. [8] used convolutional kernels of different sizes to extract the multikernel-size deep features, and then, these features are fused in an optimal way to acquire the lowest loss. The feature information of different dimensions is fully used to achieve promising feature representation integrity in such methods. But they rely heavily on network parameters and are not well generalized on various types of datasets.\nIn the real-world target recognition problem, many unseen classes not included in the training set are likely to appear, which are called unknown classes. And these unknown targets are misjudged as known classes in CSR. This misjudgment is defined as open space risk and seriously affects the military application of recognition systems [9]. Therefore there is an urgent need to address the risk caused by the assumption of closed-world environments. The concept of open-world environments is proposed to describe this scenario where the test set contains various targets not belonging to known classes. In such an open setting, there are two primary goals. First, the system ought to correctly classify all targets belonging to known classes. Second, the targets not belonging to any known class are required to be identified as the unknown class and promptly rejected. The recognition problem setting is regarded as open set recognition (OSR) for SAR targets. Compared with CSR, OSR can additionally achieve the rejection of unknown classes, which is the significant difference between them. Fig. 1 describes the tasks that OSR and CSR need to achieve, respectively."
        },
        {
            "heading": "A. Traditional Strategies",
            "text": "Early there have been some efforts with traditional techniques toward developing efficient OSR methods for SAR targets, as shown in Fig. 2. For example, Scherreik and Rigling [10] proposed a support vector machine (SVM)-based method, which realize classification with a rejection option using the W-SVM and POS-SVM. Besides, some scholars proposed classification models based on artificially generated unknown targets. Such as [11], two template-based open set recognizers using synthetic images as unknown classes are adopted. Later, Song et al. [12] regarded physics-based electromagnetic (EM) simulated images under different azimuth angles as the unseen targets and ZSL\nmodel was designed. What is more, some methods using extreme value theory (EVT) are also representative. For instance, Dong et al. [13] put forward to select the edge exemplars by edge pattern selection and herding, and then fit the probabilistic distributions with EVT. The unknown class is rejected by thresholding distribution similarities."
        },
        {
            "heading": "B. Modern Strategies",
            "text": "Recently, with the emergence of deep neural networks, deeplearning based OSR methods have developed and achieved superior performance [14]. Most studies focus on discriminative models, which quantize the output distance or probability to constrain the decision boundary. For instance, Hendrycks Gimpel [15] compared output probabilities to a threshold based on a pertrained classifier. An instance belongs to the unknown class when the max probability is lower than the threshold. Bendale and Boult [16] defined scores from the penultimate layer of the deep network as activation score. Then activation scores were used to estimate whether the input data belong to the unknown class combining meta-recognition. However, they mostly serve as postprocessing methods on resulted CNN features. The division of decision boundaries depend heavily on the information obtained after training. When the extracted features are not rich enough, the recognition effect is greatly affected. Apart from these discriminative models, some generative models have also\ngained a lot of attention. They learn the decision boundaries by generating known targets or unknown targets using generative adversarial network (GAN) [17], autoencoder [18] and flow-based model [19]. An example can be drawn from [20], which learned the distribution of known classes with GAN and discriminator. Because the unknown samples did not fit in with the learned distribution, unknown classes were identified by thresholding the output scores of the discriminator."
        },
        {
            "heading": "C. Our Solution",
            "text": "Compared with discriminative methods, generative models are theoretically elegant and straightforward. However, these classifiers are trained independently of the targets generation process in existing methods. The deep unknown distribution learned by the classifier is ignored, resulting in the potential open space risk. Besides, the techniques used to generate targets are usually complicated. Motivated by these problems, a family of novel OSR methods, generative models via random sampling combination (GvRSC) is proposed in this article. Two technical routes are designed to estimate the distribution of unknown classes indistinguishable from known classes. The original open environment is then converted into a closed environment. Moreover, the different implications between prior information on determined known classes and simulated unknown classes are used to detect unknown targets.1\nThe main contributions of this article are as follows. 1) The designed generation process of unknown targets is\nstraightforward and effective. Furthermore, the classifier is trained in the feature space augmented by generated targets, making the model more general. 2) A rich deep feature space is further learned, so that decision boundaries of known classes are pushed away significantly. Meanwhile, the randomness of generation allows diverse novel features to be constructed continuously, effectively avoiding overfitting. 3) The proposed spatial clipping suppresses the noise interference effectively on the basis of retaining important details. By this way, the features used for classification are optimized with strong pertinence in SAR images."
        },
        {
            "heading": "II. BACKGROUND",
            "text": "Our work is mainly related to the concatenation and interpolation between known targets, aiming to simulate unknown targets. In this section, the challenges in OSR and the algebraic model of known class spaces are briefly discussed."
        },
        {
            "heading": "A. Challenges in OSR",
            "text": "Rejecting unknown targets while correctly classifying all known targets is just the targeted problem to be solved by OSR, even if these unknown targets come from varieties of categories. In a feature space, the positive half space for each known class is\n1\u201cUnknown detection\u201d means identifying whether the target is belonging to the unknown class for OSR problem, the concept of which is completely different from that of target detection technology. Target detection technology is used to locate regions of interest in a complete automatic target recognition system.\nconsidered to be relatively bounded. The prior information used to learn the known distribution is limited but sufficient. However, the distribution space of unknown classes is unbounded. The mixed unknown targets are roughly divided into two types: unknown targets far away from clusters of all known classes, and unknown targets close to some clusters of known classes, as shown in Fig. 3. Considering the identification process is essentially the process of finding the best match of feature information, the distribution of unknown targets is determined by the feature similarity between them and known classes. The first type of unknown targets have few similar features to all known classes, but the second type of unknown targets have a high feature similarity with known classes.\nUnknown targets far away from clusters of all known classes: The positive half space of each class is identified after a classifier is trained. When a sample appears deeper in an identified positive half space, the probability of belonging to the corresponding class is large. On the contrary, the probability tends to decline gradually as the sample is further away from the identified space. Hence, the output probabilities of such unknown targets under all classes are all low. In this case, these unknown targets are rejected directly by thresholding the maximum output probability.\nUnknown targets close to some clusters of known classes: Notably, the difficulty lies just in identifying such unknown targets, which have a semantically similar component/region to that of some known classes. The existence of common features leads to a high probability for these unknown targets under the nearest known class. This probability is as high as the probability of the known target being under the true class. As a result, thresholding probabilities simply fails to solve the rejection problem of these unknown targets."
        },
        {
            "heading": "B. Algebraic Model of Known Class Spaces",
            "text": "For all targets of the same classXk = {xk,1,xk,2, . . . ,xk,n}, it is generally considered that they span into a linear subspace of the class [21], [22]\nSpan(Xk) = \u03b1k,1xk,1 + \u03b1k,2xk,2 + \u00b7 \u00b7 \u00b7+ \u03b1k,nixk,n (1) where \u03b1k = [\u03b1k,1, \u03b1k,2, . . . , \u03b1k,n}is the coefficient vector. Each group of imaging data for this class is regarded as a specific element on the linear subspace. On the contrary, a\nlinear combination of two or more groups of imaging data from different classes theoretically do not belong to any related subspace spanned by the known class\n\u03b2 \u00b7 xk,i + \u03bb \u00b7 xj,l \u2208 Xk, Xj , { \u2200xk,i \u2208 Xk \u2200xj,l \u2208 Xj .\n(2)\nLikewise, each image is quantified into a group of limited discrete features set. The kth class ith SAR image is denoted as\nxk,i = {Aki, Bki, Cki, Dki, Eki, Fki, \u00b7 \u00b7 \u00b7 } (3)\nwhere Aki, Bki, Cki, Dki, Eki, Fki represents different underlying features. Because the targets from different classes span into their respective linear subspaces, the zero vector is the only common vector. This algebraic model indicates that subspaces of different classes are noninterconnected. Hence, feature sets of two or more targets from different classes are disjointed. Any feature set composed of some discrete features from different classes does not belong to any relevant known class\nx\u0303k,i \u222a x\u0303j,l /\u2208 Xk, Xj , { \u2200x\u0303k,i \u2208 Xk \u2200x\u0303j,l \u2208 Xj\n(4)\nwhere x\u0303k,i represents a feature subset of xk,i, i.e. x\u0303k,i \u2282 xk,i, the same as x\u0303j,l \u2282 xj,l.\nTargets constructed as above are obtained based on the feature transformation for known targets. Consequently, these targets are similar to known classes while not belonging to any known class. Inspired by that, known targets not in the same class are randomly combined to approximate the distribution of indistinguishable unknown targets in our study."
        },
        {
            "heading": "III. PROPOSED METHODS",
            "text": "Assuming the original training set contains K known classes, then OSR can be regarded as [9], [23]: simultaneously correctly classifying the K known classes and identifying unknown targets as the unknown class. That is, OSR is aK + 1-class classification problem containing prior information of K known classes. We concatenate known targets to simulate the prior information on indistinguishable unknown targets, and make these unknown targets participate in classifier training. Consequently, the original open space is transformed into a closed space containing prior information of K + 1 classes. Specifically, two technical routes about unknown samples generation are included. The first is that some known targets not in the same class are randomly cropped and spliced in the input layer. This technique is defined as spatial clipping used to generate unknown samples (SCG). The second is to make a random weighted combination of some known targets in the middle hidden layer, ensuring these targets are not in the same class. This technique is named as weighting used to generate unknown samples (WG).\nIn this section, we first propose the overall frameworks of the family of generative models in detail, and then explain the implementation process of unknown detection and known classification, followed by motivation."
        },
        {
            "heading": "A. Generative Model Based on SCG",
            "text": "1) Modeling: As an underlying support, the network architecture of our classification model is arbitrarily chosen according to pratical requirements. We denote the selected network as f(x; \u03b8) with parameters \u03b8, which inputs an image x and outputs a logit vector over the limited set of classes. Furthermore, the classification network is considered to be composed of an embedding function and a linear classifier, described as\nf(x) = WT\u03d5(x). (5)\nIn (5), \u03d5(x) : RD \u2192 Rd denotes the abstract embedding function for extracting features, whereD refers to the dimensionality of each input image and d refers to the dimensionality after mapping. W \u2208 Rd\u00d7(K+1) represents the weight matrix of the fully connected layer (FC) for linear classification, whereK + 1 indicates the network output has a total of K + 1 classification nodes with the K + 1th node corresponding to the unknown class.\n2) Implementation: Assuming a labeled training set Dtr = (xi, yi) L i=1 consisting ofK known classes,xi \u2208 RD is a training target and yi \u2208 Y = {1, 2, . . . ,K} is the associated class label. In the input layer, we first randomly sample four different targets not in the same class from Dtr for pairing. Noting that we do not pair (xi,xj ,xk,xl) for all possible combinations. Conversely, combinations are produced within mini-batches. Given the training batch of sizeB, four orders of training targets are obtained by shuffling the mini-batch. Then pairs containing the same target or belonging to the same class are discarded, leaving the remaining pairs for unknown targets construction.\nAfter target pairing, random cropping and stitching are performed to simulate novel targets. Within the length and width of the original training image, two values are sampled from Beta distribution to construct the boundary coordinate in every training step [23]. Supposing the size of the training image is a\u00d7 b, that is\nw = w\u2032 \u00d7 a, w\u2032 \u223c Beta(\u03b11, \u03b21) h = h\u2032 \u00d7 b, h\u2032 \u223c Beta(\u03b11, \u03b21). (6)\nTo guarantee the difference between generated images and original images, the boundary coordinates are required to fall on the target center area with a higher probability, while fall on the boundary area of the original image with a lower probability. Considering Beta distribution simulate the probability distribution of event occurrence probability, this characteristic is used to effectively constrain the probability distribution of selecting boundary coordinates. We set \u03b11 = \u03b21 = 2 > 1, and the corresponding probability distribution shape is shown in Fig. 6. By drawing a horizontal line and a vertical line at the position of (w, h), the original shape a\u00d7 b is divided into four new rectangles. We denote the shapes of these four rectangles as\n\u03bd1 \u223c [w, b\u2212 h], \u03bd2 \u223c [a\u2212 w, b\u2212 h] \u03bd3 \u223c [w, h], \u03bd4 \u223c [a\u2212 w, h]. (7)\n[\u00b7, \u00b7] represents the length and width of rectangles. The paired four-column images are sequentially cropped according to the\nshape \u03bdn, n = (1, 2, 3, 4). Specifically, the starting positions for cropping denoted as (an, bn), n = (1, 2, 3, 4) are randomly produced from beta distribution within a certain range\nan = a \u2032 n \u00d7 (a\u2212 wn), a\u2032n \u223c Beta(\u03b12, \u03b22) bn = b \u2032 n \u00d7 (b\u2212 hn), b\u2032n \u223c Beta(\u03b12, \u03b22). (8)\nThey are taken as the upper left corners of cropped areas. In order to avoid the cropped area contains a complete known target, starting positions are required to locate in the upper left region of the central target as little as possible. Therefore, we also use the Beta distribution to constrain the selection probability and set the parameters as \u03b12 = 1, \u03b22 = 4, resulting in the distribution shape shown in Fig. 6. Finally, the four cropped images in each pair are spliced around the boundary coordinates (w, h) to form\na novel unknown image with the same size as the known image. The specific explanation of the process is shown in Fig. 4.\nThe targets generated in each batch are augmented into the batch of Dtr with class label K + 1. The augmented dataset is expressed as D\u2032tr = (xi, yi) N i=1, where yi \u2208 Y\u0302 = {1, 2, . . . ,K,K + 1}. Then, D\u2032tr is sent to the classification network for joint training. The classification loss of K + 1 classes is expressed as\nlt1 = \u2211\n(x,y)\u2208D\u2032tr (f(x), y). (9)\nThe output distribution of network is optimized to match the one-hot encoded distribution of true labels, leading the generated targets to approximate the unknown class. After the network finishes iterative optimization, a K + 1-class classifier CK+1 is formed. The complete process of the SCG-based model is shown in Fig. 5."
        },
        {
            "heading": "B. Generative Model Based on WG",
            "text": "1) Modeling: Considering a higher dimensional information is in the middle hidden layer than the input layer, the hidden representations are used to construct unknown targets in this technique. We divide the network structure into two parts with the middle hidden layer as the boundary. The embedding function \u03d5(x) can be further expressed as\n\u03d5(x) = \u03d5pos(\u03d5pre(x)). (10)\nIn (10),\u03d5pre(\u00b7) represents the embedding function corresponding to the prelayers before middle layer, mapping input data into hidden representations. \u03d5pos(\u00b7) corresponds to the remaining layers of the feature extraction network, mapping the hidden representations into output features. Then, the classification network is described as\nf(x) = WT\u03d5pos(\u03d5pre(x)) (11)\nwhere \u03d5pre(xi) refers to the high-dimensional hidden representations of the input xi.\n2) Implementation: Similarly, known targets in Dtr are first sampled randomly for pairing, discarding the pairs containing the same target or in the same class. Denoting one of the obtained pairs as (xi, xj , xk, xl), the four known targets are\nseparately put into the previous part of the feature extraction network. The corresponding hidden representations are expressed as (\u03d5pre(xi), \u03d5pre(xj), \u03d5pre(xk), \u03d5pre(xl)). A linear weighted combination of these representations is performed to construct a novel unknown target, as shown in Fig. 7. The corresponding formula is as follows:\nx\u0302u = \u03bb1 \u00b7 \u03d5pre(xi) + \u03bb2 \u00b7 \u03d5pre(xj) + \u03bb3 \u00b7 \u03d5pre(xk) + \u03bb4 \u00b7 \u03d5pre(xl). (12)\nThese weight coefficients are also selected from Beta distribution. That is, \u03b21 \u223c Be(\u03b1, \u03b1), \u03b22 \u223c Be(\u03b21, \u03b21), \u03b23 \u223c Be(1\u2212 \u03b21, 1\u2212 \u03b21). In order to ensure the sum of weight coefficients is 1, we set\n\u03bb1 = \u03b22, \u03bb2 = \u03b21 \u2212 \u03b22 \u03bb3 = \u03b23 \u2212 \u03b21, \u03bb4 = 1\u2212 \u03b23. (13)\nThen, x\u0302u goes through the rest part of feature extraction network, corresponded to\u03d5pos(\u00b7). The final output is represented as f(x\u0302u). An additional loss function is constructed for generated targets, defined as:\nlu = \u2211\n(x,y)\u2208Dtr (WT\u03d5pos(x\u0302u),K + 1). (14)\nlu is used to optimize the output distribution of generated targets, leading these targets to simulate indistinguishable unknown targets as much as possible. As a result, the unknown distribution in open-world environments are constrained within a limited range.\nThe original training set Dtr is directly input to the complete classification network f(x) = WT\u03d5(x), so as to obtain the output distribution of known targets. The corresponding classification loss between known classes is denoted as lk\nlk = \u2211\n(x,y)\u2208Dtr (f(x), y). (15)\nFinally, the overall loss is obtained by the weighted summation of lu and lk, denoted as\nlt2 = lk + \u03b3 \u00b7 lu. (16) AK + 1-class classifierCK+1 is also formed after optimization. The corresponding complete process of the WG-based model is shown in Fig. 8.\nC. Implementation of the Identification Process\nThe output distribution difference between unknown and known targets is significantly improved after training. The output probabilities of class K + 1 are relatively high for unknown targets similar to some known classes. But it does not rule out that a high output probability of the similar known class may also appear. As for the known targets, the highest probability appear in their true class label while the probability of class K + 1 is low. However, the countless of such unknown targets is worth noting, just as mentioned in Algebraic model of known class spaces. The finiteness of the learned unknown features is normal and realistic, and the difference from known targets determines the output probability of class K + 1 is full of different representation meaning. Hence, we do not generalize the output probabilities of the unknown class and known classes, making full use of the limited feature information of generated unknown targets.\nDuring the recognition process of testing instances, the output probability of class K + 1 is not ignored just because it is not the max probability on all classes. When the absolute value of the probability is large, it has been stated the instance belongs to the indistinguishable unknown class with a high probability.\nAbove all, we reject the targets far away from all the clusters of K + 1 classes by thresholding, which corresponds to unknown targets having few similar features to all known classes\nmax k=1,2,...,K+1\nP (x) \u2264 \u03b51. (17)\nIf the above formula is satisfied, where \u03b51 is the threshold, the instance is directly judged as an unknown target, expressed as y = K + 1.\nOtherwise, other judgments need to be continued. The rejection on unknown targets similar to some known classes is achieved by thresholding the output probabilities of belonging to class K + 1. Specifically, if the output probability is greater than the threshold denoted as \u03b52\nPK+1(x) \u2265 \u03b52 (18) the instance is judged as indistinguishable unknown class: y = K + 1. If not, it is identified as the known class corresponding to the largest probability of the top K classes\ny = arg max k=1,2,...,K P (x) (19)"
        },
        {
            "heading": "D. Motivation",
            "text": "In this section, the effectiveness of GvRSC is theoretically demonstrated and expounded in detail. Three main reasons for improving the unknown detection performance while guaranteeing the known classification effect are included: efficient simulation of unknown targets, boundaries compactness of known classes, suppression of SAR noise interference.\n1) Generative Model Based on SCG: The targets generation process of SCG only uses image cropping and stitching without any extra time complexity. Besides, the diversity of feature combinations is increased by virtue of randomness. Thus, the generated targets are led to best approximate indistinguishable unknown targets, which is verified by the t-SNE visualization effect in Fig. 9(a). In addition, patching creates new global features in the generation process. This keeps neural network from overfitting to specific features [24].\nTargets generated by SCG always equips local features included in the original dataset, from which deep and comprehensive known features are further extracted. Many patch details in known classes are learned repeatedly. As a result, the decision boundary is moved away from the generated targets, resulting in a compact embedding space.\nFurthermore, the influence of background noise [25], [26] on recognition is reduced effectively, increasing the model stability. We assume the feature set corresponding to each target consists of main features used to classify and various noise. Because the background noise is random, the noise distribution among varieties of classes is also random. By cropping and splicing, various random noises on different images are randomly sampled on one certain image, so that the same noise distribution exists in the generated targets and K known classes. The uniformity of noise distribution is greatly enhanced in varieties of classes. During the network training process, the weight of all features to the target classes are determined. Therefore, when the noise tends to be evenly distributed across all classes, the information gain or weight assigned to the noise is weakened close to 0. On the contrary, the main features belonging to the inherent properties\nof each known class have regular distribution. The information gain assigned to each main feature is continuously strengthened after training. In summary, on the basis of not losing SAR image texture information, the interference of random noise on image classification is effectively suppressed. During the testing process, even if unseen random noise is mixed in, the weight of these main features still play a dominant role, and the stability of the classification effect is increased obviously.\n2) Generative Model Based on WG: From (12), we find the generation process also does not consume extra time complexity. WG builds complete new pixel-level features that original known targets do not include. Therefore, the various of learned unknown features are enriched drastically.\nSince the network learning process is regarded as the parameter learning process, a deeper abstract representation appears in each layer compared with the previous layer. As the parameters are updated through the network, targets generated in the middle hidden layer are continuously optimized. Thus, generated targets are allowed to better stand for the unknown targets similar to known classes, as the SNE visualization result in Fig. 9(b) proved. In addition, the combinations in the middle hidden layer prevent generated targets from being confused with other known targets, which prone to occur at the input layer. It means the distinguishability between known classes is effectively guaranteed.\nWeighted combination is understood as the establishment of a linear interpolation function, which makes the discrete sample space continuous. Verma et al. [27] proved the learning of unknown targets located at the interpolated position pushes the decision boundaries away in all directions, smoothing the decision boundaries. This characteristic is conducive to improving the generalization ability of the WG-based model. With the above characteristics, testing unknown instances are gathered around the cluster center of class K + 1."
        },
        {
            "heading": "IV. EXPERIMENT AND RESULTS",
            "text": "To evaluate the performance of GvRSC, we use the MSTAR public database for conducting experiments. The SAR images\nconsisted are imaged in the X-band and HH polarization with 0.3-m resolution for multiple targets. There are 10 classes of vehicle targets with a pixel size of 128\u00d7128, ie., BMP2 (tank), BTR70 (armored car), T72 (tank), BTR60 (armored car), 2S1 (cannon), BRDM2 (truck), D7 (bulldozer), T62 (tank), ZIL131 (truck), ZSU23/4 (cannon). These targets were captured with 190 \u223c 300 different aspect versions, which are more than 360\u25e6 full coverage. According to the recommended configuration [8], [28], the images with a depression angle of 17\u25e6 are used to train the network, and the images with a depression angle of 15\u25e6 are used for testing. The number of the ten-class targets images and some imaging parameters are shown in Table I. Because the data in MSTAR is insufficient, a set of data augmentation strategies is performed in all the experiments of this article.\nIn this section, we first compared the difference between open-world and closed-world, reflecting the important research significance of OSR. Then, we evaluate the performance in unknown detection and make a further extended experiment with openness changes. Subsequently, the performance on the OSR task is compared with other state of the art OSR methods. Finally, an ablation study is also conducted to further analyze the contribution of each part in our model. Notably, the result data are directly quoted from the relevant references if they exist. In other cases, where there are no directly citable literatures, we maintain the same conditional configuration as the original reference, and use the recommended parameter values in the literature to reproduce. Details on recommended values can be found in these reference."
        },
        {
            "heading": "A. Comparison Between Open-World and Closed-World",
            "text": "In order to reflect the difference between open-world environments and closed-world environments, we conduct a brief experimental comparison on the MSTAR dataset. Eight of the ten classes are randomly selected as known, labeled as 0 \u223c 7. The other two classes are merged into the class 8 as unknown. The comparative experiments consist of three parts: the plain CSR CNN in closed-world environments, the plain CSR CNN in open-world environments, and SCG-based model recognition in open-world environments. The experimental results are shown by the confusion matrix in Fig. 10. In Fig. 10(a), the CSR method ensures the accurate classification of known classes. But in the real open-world environment as shown in Fig. 10(b), the CSR method misjudges unknown targets as one of the known classes, leading to serious open space risks. Different from that, the proposed OSR method effectively addresses the misjudgments. In Fig. 10(c), most unknown targets are correctly identified as the unknown class, and the classification accuracy of known classes is also effectively guaranteed."
        },
        {
            "heading": "B. Unknown Detection",
            "text": "1) Experimental Datasets: From the MSTAR dataset, we randomly select eight classes as known classes, remaining the other two classes as the unknown class. The training set is composed of the corresponding eight classes of the MSTAR training images, while two groups of test sets are set up. The first test set contains 10 classes of the MSTAR testing images. The second test set contains eight known classes of the MSTAR testing images and two unknown classes of MSTAR-noise images. These MSTAR-noise images are randomly generated on the MSTAR images using GAN, which are similar to the original MSTAR images.\n2) Evaluation Metrics: In a real open-world environment, it is not known how rare or common the unknown targets are. An independent and flexible threshold is required for detecting unknown classes. The receiver operating characteristic (ROC) curve characterizes the performance of a detector with the threshold changing from zero recall to complete recall.\nFor this reason, we choose the ROC curve and the area under the ROC curve (AUC) as metrics, which provide calibration-free measures of detection performance.\nApart from this, any OSR method should remain capable of standard closed-set classification when detecting known and unknown targets. We choose the classification accuracy in a closed set space as another metric, which states if the classifier still working when applied to the known subset of classes.\n3) Network Architecture: The classification network for this experiment refers to the classifier32 network used in [29], with some changes. Considering SAR images are very sensitive to features such as imaging azimuth, learning deeper highdimensional features is the key to improve recognition accuracy. We add two combined layers composed of a convolutional layer and an activation function layer to the middle hidden layer of the original neural network. As a result, the network depth is increased and more abstract features are obtained. The momentum stochastic gradient descent (Momentum SGD) is used to optimize the network, and its learning rate starts from 0.1.\n4) Result Comparisons: As shown in Table II, the proposed two models are compared with newly proposed methodology under the same conditions. Among them, softmax is regarded as a baseline, which uses the highest output probability as the confidence score for detection. We report the mean AUC results over five trials in the Table II. It is apparent from this Table II the proposed methods significantly improve the recognition performance. Specifically, in the experiments on MSTAR dataset, both\nSCG-based model and WG-based model improve the detection performance by a considerable margin, pushing forward about 10% than Softmax. Their AUC scores have exceeded 90% and achieved excellent detection effect. As unknown targets become more indistinguishable in MSTAR+noise dataset, more prominent advantages are shown in SCG-based model than other advanced methods. The detection performance is pushed forward by 12.1% from Softmax, achieving a good effect of 85.2%. WG-based model also slightly improves the performance in unknown detection by 3.5% compared with the baseline, though the effect is not as good as the multitask learning-based model.\nMoreover, we draw ROC cruves of these listed methods for performance evaluation in Fig. 11. In the MSTAR dataset, ROC curves of SCG-based model and WG-based model are relatively closer to the upper left corner, which means they have higher identification accuracy. The ROC curve of RPL is closest to the lower right corner, which indicates RPL is the worst method to detect unknown. In addition, the ROC curve corresponding to SCG-based model is still closest to the upper left corner in the MSTAR+noise dataset, followed by that of multitask learningbased model. And the ROC curve of WG-based model is located in the upper left of RPL, ARPL, and GCPL. In view of this, the superiority and effectiveness of our proposed methods in detecting unknown classes is verified.\nWe also provide the closed-set accuracy in Table II. Compared with the baseline, the closed-set recognition performance of other newly proposed comparison methods is all obviously reduced, with accuracy reduced by several percentage points on different datasets. But the closed-set classification performance of SCG-based model and WG-based model has basically remained unchanged, only a few tenths of a percentage point fluctuation. From these results, it is concluded that the proposed methods realize accurate unknown detection without sacrificing the discriminative ability in the closed-set classification.\n5) Extended Research for Openness: Real open-world environments are very complex and unpredictable, where diverse unseen targets may be encountered. The more classes of unknown targets, the greater the open space risk in the recognition\nproblem, and the higher the difficulty in detecting unknown targets. Therefore, when evaluating the model, the influence of openness [35] on detection performance needs to be observed. Following the protocol given in [36], we quantify the complexity of the open-set task with simplified openness, defined as\nOpenness = 1\u2212 \u221a\nNtrain Ntest . (20)\nwhere Ntrain denotes the number of classes contained in the training set and Ntest denotes the number of classes contained in the test set. As we discussed in the preliminaries, we set Ntrain = K. To change the degree of openness, we vary K with a fixed Ntest = 10 for the MSTAR dataset. The detection results corresponding to a range of greater openness scores are shown in Fig. 12. As the openness degree increases from 10.56% to 45.23%, our models perform better in unknown detection, leading to significant differences with Softmax. When the openness degree reaches 45.23%, the AUC scores are improved by 24.8% for SCG-based model and 17.8% for WG-based model compared with the baseline. What is interesting in Fig. 12 is that AUC scores of the proposed two models both degrade gently as the openness increases. Their unknown detection performance does not deteriorate as drastically as Softmax. Particularly, SCG-based model appears to be unaffected by openness. Overall, these results suggest when Softmax is difficult to work in high degree of openness, the proposed methods handle these scenarios with stable and excellent performance.\n6) Visualization Detection Results: To analyze the feature similarity between testing instances and the class K + 1, we measure the second norm of the distance between testing instances and the center point of classK + 1 in a high-dimensional feature space. The corresponding high-dimensional feature distribution histograms with MSTAR as the test set are shown in Fig. 13. Apparently, the distribution peaks of known classes and the unknown class are clearly distinguished in both SCG-based model and WG-based model. The feature difference between unknown instances and the center of class K + 1 are much less, while the difference is relatively more for known instances. This finding confirms thresholding the output probability of class K + 1 is reliable and effective for unknown detection."
        },
        {
            "heading": "C. Open Set Recognition",
            "text": "In addition to detecting unknown targets, another purpose OSR needs to achieve is to accurately classify known targets. In this section, the open-set classification performance of GvRSC on known targets is verified.\n1) Experimental Datasets: To facilitate comparison with other OSR methods, we set up the experimental dataset with reference to [10]. We choose T72, BMP2, and BTR70 to make the training set. The whole 10 target classes make up the test set. This means OSR models should receive and classify T72, BMP2, BTR70, and simultaneously identify the rest seven classes as the unknown class during the test time.\n2) Evaluation Metrics: To analyze the comprehensive performance in both known classification and unknown detection, we introduce recall, precision, and macro-F1. Recall indicates the proportion of instances classified correctly among all positive instances, which measures the ability to identify positive instances. Precision indicates the proportion of instances that are actually positive and classified as positive. Macro-F1 is a weighted harmonic average between recall and precision. In a multiclass problem, these metrics are calculated as follows, where K denotes the number of all classes\nrecalli = TPi\nTPi + FNi , recall =\n\u2211K i=1 recalli\nK (21)\nprecisioni = TPi\nTPi + FPi , precision =\n\u2211K i=1 precisioni\nK (22)\nF1i = 2\u00d7 precisioni \u00d7 recalli\nprecisioni + recalli (23)\nmacro \u2212 F1 = \u2211K i=1 F1i\nK . (24)\n3) Result Comparisons: Regarding the classification network, we still use the network structure in Unknown Detection. We compare GvRSC with other six OSR methods in Table III, i.e., Softmax [30], ARPL [32], Openmax [16], W-SVM RBF [37], iCaRL [38], and EVM [39]. Among them, Softmax, ARPL, and Openmax belong to the universal OSR methods migrated from the optical field. It is apparent that their macro-F1 scores are all below 70%, yielding unsatisfactory performance in OSR. Especially for ARPL, the recognition ability to SAR images has almost lost, though ARPL performs well on optical\ndatasets. Therefore, OSR for SAR targets needs to be considered in combination with the characteristics of themselves. Compared with these migrated optical OSR methods, WG-based model still has a more passable recognition performance. The macro-F1 score is already close to 70% with the recall as high as 73.2%.\nHowever, the macro-F1 scores of iCaRL, EVM, and SCGbased model are all more than 80%. Performance differences have been revealed significantly compared to the optical methods. It is obvious that our SCG-based model has the best macroF1. Futhermore, the precision of EVM is relatively low, which means the accurate predicted results account for a low proportion of all predicted results. The recall of the SCG-based model is up to 89.3% and the precision is up to 82.4%. The results indicate that a good trade-off between avoiding missed detections and reducing false detections is achieved well. Consequently, it is inferred from Table III that SCG-based model performs better both on known classification and unknown detection than others."
        },
        {
            "heading": "D. Ablation Study",
            "text": "In this section, we conduct an ablation study and analyze each innovative part\u2019s contribution with the MSTAR dataset.\nWe continue to use the training set in Section IV-B, where eight out of ten classes are chosen as known and the other two classes are regarded as unknown. For the two innovative parts in our method: new technical routes of simulating indistinguishable unknown classes, ways of detecting unknown classes. We configure four groups of comparison experiments for analysis: Softmax, K+1-Softmax, SCG-based model, and WG-based model.\nAmong them, Softmax stands for a plain CNN, where the network contains K output nodes corresponding to K known classes participating in training. And unknown targets are rejected only by thresholding the maximum output probability of K classes. K + 1-Softmax means the output nodes of the classification network are set to K + 1, while there are still only K known classes participating in training. By thresholding the output probability of the K + 1th node, unknown classes are rejected. On the basis that the network output node is set to K + 1, SCG-based model means SCG is used to simulate indistinguishable unknown classes and augmented to the original training set, participating in training together with known targets. Finally, the output probability of the class K + 1 is thresholded to complete the OSR task. Similarly, in the WGbased model, WG is used to simulate indistinguishable unknown targets, and these targets are fed into the later part of the network for training. OSR is realized by thresholding the output probability of the unknown class K + 1. We evaluate the recognition performance by closed-set accuracy, AUC and macro F1-scores.\nThe results are shown in Table IV. In addition, ROC is also presented to simply and intuitively display the recognition effect of the comparison experiments, as shown in Fig. 14.\nWe can infer from the Table IV that thresholding the output probabilities of class K + 1 improves the OSR ability of plain CNN by a large margin. On this basis, simulating unknown classes to participate in training further results in better recognition effect. Specifically, the results indicate that adopting SCG and WG both improve recognition performance through effective simulation of the unknown class."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "SAR target recognition in open-world environments is important for practical applications, while only few researches were studied. In this article, we propose a family of generative models to solve the OSR problem, that is, SCG-based model and WG-based model. By random sampling combination, the targets generation processes do not consume extra computational complexity. Meanwhile, the kind of indistinguishable unknown distribution was approximated well by generated targets, resulting in compact embedding space of known classes. Besides, SCG-based model reduces the interference of the background noise to the OSR performance particularly. The targets generated by WG make the discrete space continuous, so that decision boundaries are pushed away in all directions. The smooth decision boundaries further improve the generalization ability of the model. What is more, the difference of simulated unknown targets from known classes is highlighted and fully exploited in unknown detection. A series of experimental results have verified that the proposed GvRSC performs well both in unknown detection and known classification. Particularly, the SCG-based model outperforms other state of the arts. Moreover, there is not a significant downward trend in unknown detection performance as the degree of openness increases.\nIn the practical application of OSR methods for SAR images, sometimes it is not enough to detect unknown targets, and it is necessary to further identify their specific attributes. Therefore, in the future, we will focus on the problem of class-incremental learning, which learn useful information in new targets, while retaining the original classification information.\nREFERENCES\n[1] W. Du, F. Zhang, F. Ma, Q. Yin, and Y. Zhou, \u201cImproving SAR target recognition with multi-task learning,\u201d in Proc. IEEE Int. Geosci. Remote Sens. Symp., 2020, pp. 284\u2013287. [2] C. Yin, E. Blasch, H. Chen, Q. Tao, and G. Chen, \u201cExperimental featurebased SAR ATR performance evaluation under different operational conditions,\u201d in Proc. SPIE-Int. Soc. Opt. Eng., 2008, pp. 69680F\u201369680F12. [3] C. Wang, X. Liu, J. Pei, Y. Huang, Y. Zhang, and J. Yang, \u201cMultiview attention CNN-LSTM network for SAR automatic target recognition,\u201d IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 14, pp. 12504\u201312513, 2021. [4] B. Ding, G. Wen, X. Huang, C. Ma, and X. Yang, \u201cData augmentation by multilevel reconstruction using attributed scattering center for SAR target recognition,\u201d IEEE Geosci. Remote Sens. Lett., vol. 14, no. 6, pp. 979\u2013983, Jun. 2017. [5] C. Wang et al., \u201cSemisupervised learning-based SAR ATR via selfconsistent augmentation,\u201d IEEE Trans. Geosci. Remote Sens., vol. 59, no. 6, pp. 4862\u20134873, Jun. 2021.\n[6] C. Zheng, X. Jiang, and X. Liu, \u201cSemi-supervised SAR ATR via multidiscriminator generative adversarial network,\u201d IEEE Sens J., vol. 19, no. 17, pp. 7525\u20137533, Sep. 2019. [7] S. A. Wagner, \u201cSAR ATR by a combination of convolutional neural network and support vector machines,\u201d IEEE Trans Aerosp Electron Syst., vol. 52, no. 6, pp. 2861\u20132872, Jan. 2016. [8] S. Chen, H. Wang, F. Xu, and Y. Jin, \u201cTarget classification using the deep convolutional networks for SAR images,\u201d IEEE Trans. Geosci. Remote Sens., vol. 54, no. 8, pp. 4806\u20134817, Aug. 2016. [9] N. A. Inkawhich, E. K. Davis, M. J. Inkawhich, U. K. Majumder, and Y. Chen, \u201cTraining SAR-ATR models for reliable operation in open-world environments,\u201d IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 14, pp. 3954\u20133966, 2021. [10] F. A. Sadjadi, A. Mahalanobis, M. Scherreik, and B. Rigling, \u201cMulti-class open set recognition for SAR imagery,\u201d in Proc. SPIE-Int. Soc. Opt. Eng., 2016, pp. 98440M\u201398440M9. [11] A. B. Bapst, J. Tran, M. W. Koch, M. M. Moya, and R. Swahn, \u201cOpen set recognition of aircraft in aerial imagery using synthetic template models,\u201d in Proc. SPIE-Int. Soc. Opt. Eng., 2017, pp. 1020206\u2013102020618. [12] Q. Song, H. Chen, F. Xu, and T. J. Cui, \u201cEm simulation-aided zero-shot learning for SAR automatic target recognition,\u201d IEEE Geosci. Remote Sens. Lett., vol. 17, no. 6, pp. 1092\u20131096, Jun. 2020. [13] S. Dang, Z. Cao, Z. Cui, and Y. Pi, \u201cOpen set SAR target recognition using class boundary extracting,\u201d in Proc. 6th Asia-Pacific Conf. Synth. Aperture Radar, 2019, pp. 1\u20134. [14] J. Tang, D. Xiang, F. Zhang, F. Ma, Y. Zhou, and H. Li, \u201cIncremental SAR automatic target recognition with error correction and high plasticity,\u201d IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 15, pp. 1327\u20131339, 2022. [15] D. Hendrycks and K. Gimpel, \u201cA baseline for detecting misclassified and out-of-distribution examples in neural networks,\u201d in Proc. Int. Conf. Learn. Represent., 2017. [Online]. Available: https://openreview.net/forum?id= Hkg4TI9xl [16] A. Bendale and T. Boult, \u201cTowards open set deep networks,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2016, pp. 1563\u20131572. [17] L. Goodfellow et al., \u201cGenerative adversarial nets,\u201d in Proc. Adv. Neural Inf. Process. Syst., 2014. [Online]. Available: https://proceedings.neurips. cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf [18] X. Sun, Z. Yang, C. Zhang, K.-V. Ling, and G. Peng, \u201cConditional Gaussian distribution learning for open set recognition,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2020, pp. 13477\u201313486. [19] H. Zhang, A. Li, J. Guo, and Y. Guo, \u201cHybrid models for open set recognition,\u201d in Proc. Eur. Conf. Comput. Vis., 2020, pp. 102\u2013117. [20] X. Ma, K. Ji, L. Zhang, S. Feng, and G. Kuang, \u201cAn open set recognition method for SAR targets based on multitask learning,\u201d IEEE Geosci. Remote Sens. Lett., vol. 19, 2021, Art. no. 4014005. [21] P. V. Overschee and B. D. Moor, Subspace Identification for Linear Systems. Subspace Identification for Linear Systems, 1996. [22] M. Skurichina and R. P. W. Duin, \u201cBagging, boosting and the random subspace method for linear classifiers,\u201d Pattern Anal. Appl., vol. 5, no. 2, pp. 121\u2013135, 2002. [23] P. Perera, V. I. Morariu, R. Jain, V. Manjunatha, and V. M. Patel, \u201cGenerative-discriminative feature representations for open-set recognition,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2020, pp. 11811\u2013 11820. [24] S. Lawrence and C. L. Giles, \u201cOverfitting and neural networks: Conjugate gradient and backpropagation,\u201d in Proc. Int. J. Conf. Neural Netw., 2000, pp. 114\u2013119. [25] L. I. Bing and W. Hong, \u201cStudy of noise jamming to SAR,\u201d Acta Electron. Sin., vol. 32, pp. 2035\u20132037, 2004. [26] Y. Kwak, W. J. Song, and S. E. Kim, \u201cSpeckle-noise-invariant convolutional neural network for SAR target recognition,\u201d IEEE Geosci. Remote Sens. Lett., vol. 16, no. 4, pp. 549\u2013553, Apr. 2019. [27] V. Verma et al., \u201cManifold mixup: Better representations by interpolating hidden states,\u201d in Proc. Int. Conf. Mach. Learn., 2018, pp. 6438\u20136447. [28] Z. Cao, L. Xu, and J. Feng, \u201cAutomatic target recognition with joint sparse representation of heterogeneous multi-view SAR images over a locally adaptive dictionary,\u201d Signal Process., vol. 126, no. sep., pp. 27\u201334, 2016. [29] L. Neal, M. Olson, X. Fern, W.-K. Wong, and F. Li, \u201cOpen set learning with counterfactual images,\u201d in Proc. Eur. Conf. Comput. Vis., 2018, pp. 620\u2013 635. [30] R. Yoshihashi, W. Shao, R. Kawakami, S. You, M. Iida, and T. Naemura, \u201cClassification-reconstruction learning for open-set recognition,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2019, pp. 4011\u20134020.\n[31] G. Chen, P. Peng, X. Wang, and Y. Tian, \u201cAdversarial reciprocal points learning for open set recognition,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, pp. 8065\u20138081, Nov. 2021. [32] G. Chen, L. Qiao, Y. Shi, P. Peng, and Y. Tian, \u201cLearning open set network with discriminative reciprocal points,\u201d in Proc. Eur. Conf. Comput. Vis., 2020, pp. 507\u2013522. [33] H.-M. Yang, X.-Y. Zhang, F. Yin, and C.-L. Liu, \u201cRobust classification with convolutional prototype learning,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2018, pp. 3474\u20133482. [34] X. Ma, K. Ji, L. Zhang, S. Feng, B. Xiong, and G. Kuang, \u201cAn open set recognition method for SAR targets based on multitask learning,\u201d IEEE Geosci. Remote Sens. Lett., vol. 19, pp. 1\u20135, 2021. [35] W. J. Scheirer, D. R. R. Anderson, A. Sapkota, and T. E. Boult, \u201cToward open set recognition,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 35, no. 7, pp. 1757\u20131772, Jul. 2013. [36] C. Geng, S. J. Huang, and S. Chen, \u201cRecent advances in open set recognition: A survey,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 43, no. 10, pp. 3614\u20133631, Oct. 2020. [37] W. J. Scheirer, L. P. Jain, and T. E. Boult, \u201cProbability models for open set recognition,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 36, no. 11, pp. 2317\u20132324, Nov. 2014. [38] S. A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert, \u201ciCaRL: Incremental classifier and representation learning,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog., 2017, pp. 5533\u20135542. [39] E. M. Rudd, L. P. Jain, W. J. Scheirer, and T. E. Boult, \u201cThe extreme value machine,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 40, no. 3, pp. 762\u2013768, Mar. 2018.\nXiaojing Geng received the B.S. degree in optoelectronic information science and engineering from Xidian University, Xi\u2019an, China, in 2021. She is currently working toward the master\u2019s degree, majoring in information and communication engineering, with the National Lab of Radar Signal Processing, Xidian University.\nHer research interests include radar automatic target recognition, pattern recognition, and machine learning.\nGanggang Dong received the M.S. and Ph.D. degrees in information and communication engineering from National University of Defense Technology, Changsha, China, in 2012 and 2016, respectively.\nHe is currently an Associate Professor with the National Lab of Radar Signal Processing, Xidian University, Xi\u2019an, China. His research interests include radar image interpretation, pattern recognition and deep learning, and radar signal processing.\nDr. Dong was a recipient of the 2017 Excellent Doctor thesis of Chinese Institute of Electronics. He\nalso served as the Reviewer of remote sensing and image processing, including IEEE TIP, TGRS, JSTRAS, GRSL, and IEEE SENSORS JOURNAL.\nZiheng Xia received the B.S. degree in nuclear physics from Peking University, Beijing, China, in 2015, and the M.Eng. degree in nuclear technology and application from Northwest Institute of Nuclear Technology, in 2017. He is currently working toward the Ph.D. degree in signal processing with Xidian University, Xi\u2019an, China.\nHis research interests include radar automatic target recognition, pattern recognition, and machine learning.\nHongwei Liu (Senior Member, IEEE) received the B.E. degree in electronic engineering from Dalian University of Technology, Dalian, China, in 1992, the M.S. degree in circuit and system and the Ph.D. degree in signal and information processing from Xidian University, Xi\u2019an, China, in 1995 and 1999, respectively.\nHe was a Visiting Scholar from January 2001 to October 2002 with Duke University, Durham, NC, USA. He is currently a Full Professor with the National Lab of Radar Signal Processing, Xidian University.\nHis research interests include radar target recognition, cognitive detection, networked cooperative detection, and radar intelligence."
        }
    ],
    "title": "SAR Target Recognition via Random Sampling Combination in Open-World Environments",
    "year": 2022
}