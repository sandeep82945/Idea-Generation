{
    "abstractText": "In this paper, a sample estimator of the tangency portfolio (TP) weights is considered. The focus is on the situation where the number of observations is smaller than the number of assets in the portfolio and the returns are i.i.d. normally distributed. Under these assumptions, the sample covariance matrix follows a singular Wishart distribution and, therefore, the regular inverse cannot be taken. In the paper, bounds and approximations for the first two moments of the estimated TP weights are derived, as well as exact results are obtained when the population covariance matrix is equal to the identity matrix, employing the Moore\u2013Penrose inverse. Moreover, exact moments based on the reflexive generalized inverse are provided. The properties of the bounds are investigated in a simulation study, where they are compared to the sample moments. The difference between the moments based on the reflexive generalized inverse and the sample moments based on the Moore\u2013Penrose inverse is also studied.",
    "authors": [
        {
            "affiliations": [],
            "name": "Gustav Alfelta"
        },
        {
            "affiliations": [],
            "name": "Stepan Mazurb"
        }
    ],
    "id": "SP:0540da1cebe52c0a6766f8ef59903a4abedc0b59",
    "references": [
        {
            "authors": [
                "G. Alfelt",
                "T. Bodnar",
                "F. Javed",
                "J. Tyrcha"
            ],
            "title": "Singular conditional autoregressive Wishart model for realized covariance matrices. Accepted for publication in Journal of Business and Economic Statistics (2022)",
            "year": 2022
        },
        {
            "authors": [
                "M. Ao",
                "L. Yingying",
                "X. Zheng"
            ],
            "title": "Approaching mean-variance efficiency for large portfolios",
            "venue": "Rev. Financ. Stud",
            "year": 2019
        },
        {
            "authors": [
                "D. Bauder",
                "T. Bodnar",
                "S. Mazur",
                "Y. Okhrin"
            ],
            "title": "Bayesian Inference for the Tangent Portfolio",
            "venue": "Int. J. Theor. Appl. Finance 21(08),",
            "year": 2018
        },
        {
            "authors": [
                "O. Bodnar"
            ],
            "title": "Sequential suveillance of the tangency portfolio weights",
            "venue": "Int. J. Theor. Appl. Finance",
            "year": 2009
        },
        {
            "authors": [
                "O. Bodnar",
                "T. Bodnar",
                "N. Parolya"
            ],
            "title": "Recent advances in shrinkage-based highdimensional inference",
            "venue": "Journal of Multivariate Analysis",
            "year": 2022
        },
        {
            "authors": [
                "T. Bodnar",
                "Y. Okhrin"
            ],
            "title": "On the product of inverse wishart and normal distributions with applications to discriminant analysis and portfolio theory",
            "venue": "Scand. J. Stat",
            "year": 2011
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Mazur",
                "Y. Okhrin"
            ],
            "title": "On the exact and approximate distributions of the product of a Wishart matrix with a normal vector",
            "venue": "J. Multivar",
            "year": 2013
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Mazur",
                "Y. Okhrin"
            ],
            "title": "Distribution of the product of singular Wishart Matrix and normal vector",
            "venue": "Theory Probab. Math. Stat. 91,",
            "year": 2014
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Mazur",
                "N. Parolya"
            ],
            "title": "Central limit theorems for functionals of large sample covariance matrix and mean vector in matrix-variate location mixture of normal distributions",
            "venue": "Scand. J. Stat. 46(2),",
            "year": 2019
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Mazur",
                "K. Podgorski"
            ],
            "title": "Singular inverse Wishart distribution and its application to portfolio theory",
            "venue": "Journal of Multivariate Analysis,",
            "year": 2016
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Mazur",
                "K. Podgorski"
            ],
            "title": "A test for the global minimum variance portfolio for small sample and singular covariance",
            "venue": "AStA Adv. Stat. Anal",
            "year": 2017
        },
        {
            "authors": [
                "T. Bodnar",
                "Y. Okhrin",
                "N. Parolya"
            ],
            "title": "Optimal shrinkage-based portfolio selection in high dimensions",
            "venue": "Journal of Business & Economic Statistics",
            "year": 2022
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Mazur",
                "S. Muhinyuza",
                "N. Parolya"
            ],
            "title": "On the product of a singular wishart matrix and a singular gaussian vector in high dimension",
            "venue": "Theory Probab. Math. Stat",
            "year": 2018
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Mazur",
                "E. Ngailo",
                "N. Parolya"
            ],
            "title": "Discriminant analysis in small and large dimensions",
            "venue": "Theory Probab. Math. Stat. 100,",
            "year": 2019
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Mazur",
                "K. Podgorski",
                "J. Tyrcha"
            ],
            "title": "Tangency portfolio weights for singular covariance matrix in small and large dimensions: Estimation and test theory",
            "venue": "J. Stat. Plan. Inference",
            "year": 2019
        },
        {
            "authors": [
                "T. Bodnar",
                "S. Dmytriv",
                "Y. Okhrin",
                "N. Parolya",
                "W. Schmid"
            ],
            "title": "Statistical inference for the expected utility portfolio in high dimensions",
            "venue": "IEEE Trans. Acoust. Speech Signal Process",
            "year": 2021
        },
        {
            "authors": [
                "T.L. Boullion",
                "P.L. Odell"
            ],
            "title": "Generalized Inverse Matrices",
            "year": 1971
        },
        {
            "authors": [
                "M. Britten-Jones"
            ],
            "title": "The sampling error in estimates of mean-variance efficient portfolio weights",
            "venue": "J. Finance 54(2),",
            "year": 1999
        },
        {
            "authors": [
                "J. Brodie",
                "I. Daubechies",
                "C. De Mol",
                "D. Giannone",
                "I. Loris"
            ],
            "title": "Sparse and stable Markowitz portfolios",
            "venue": "Proc. Natl. Acad. Sci. USA",
            "year": 2009
        },
        {
            "authors": [
                "T.T. Cai",
                "J. Hu",
                "Y. Li",
                "X. Zheng"
            ],
            "title": "High-dimensional minimum variance portfolio estimation based on high-frequency data",
            "venue": "J. Econom. 214(2),",
            "year": 2020
        },
        {
            "authors": [
                "R.D. Cook",
                "L. Forzani"
            ],
            "title": "On the mean and variance of the generalized inverse of a singular Wishart matrix",
            "venue": "Electron. J. Stat",
            "year": 2011
        },
        {
            "authors": [
                "Y. Ding",
                "Y. Li",
                "X. Zheng"
            ],
            "title": "High dimensional minimum variance portfolio estimation under statistical factor models",
            "venue": "J. Econom",
            "year": 2021
        },
        {
            "authors": [
                "G.A. Ghazal",
                "H. Neudecker"
            ],
            "title": "On second-order and fourth-order moments of jointly distributed random matrices: a survey",
            "venue": "Linear Algebra Appl. 321(1),",
            "year": 2000
        },
        {
            "authors": [
                "M. Gulliksson",
                "S. Mazur"
            ],
            "title": "An iterative approach to ill-conditioned optimal portfolio selection",
            "venue": "Comput. Econ",
            "year": 2020
        },
        {
            "authors": [
                "M. Gulliksson",
                "A. Oleynik",
                "S. Mazur"
            ],
            "title": "Portfolio selection with a rank-deficient covariance matrix",
            "year": 2021
        },
        {
            "authors": [
                "N. Hautsch",
                "L.M. Kyj",
                "P. Malec"
            ],
            "title": "Do high-frequency data improve high-dimensional portfolio allocations",
            "venue": "J. Appl. Econom. 30(2),",
            "year": 2015
        },
        {
            "authors": [
                "D.W. Hubbard"
            ],
            "title": "The Failure of Risk Management: Why It\u2019s Broken and How to Fix It",
            "year": 2020
        },
        {
            "authors": [
                "S. Imori",
                "D. Rosen"
            ],
            "title": "On the mean and dispersion of the Moore-Penrose generalized inverse of a Wishart matrix",
            "venue": "Electron. J. Linear Algebra",
            "year": 2020
        },
        {
            "authors": [
                "F. Javed",
                "S. Mazur",
                "E. Ngailo"
            ],
            "title": "Higher order moments of the estimated tangency portfolio weights",
            "venue": "J. Appl. Stat",
            "year": 2021
        },
        {
            "authors": [
                "F. Javed",
                "S. Mazur",
                "E. Thors\u00e9n"
            ],
            "title": "Tangency portfolio weights under a skew-normal model in small and large dimensions",
            "year": 2021
        },
        {
            "authors": [
                "S. Karlsson",
                "S. Mazur",
                "S. Muhinyuza"
            ],
            "title": "Statistical inference for the tangency portfolio in high dimension",
            "year": 1951
        },
        {
            "authors": [
                "I. Kotsiuba",
                "S. Mazur"
            ],
            "title": "On the asymptotic and approximate distributions of the product of an inverse wishart matrix and a gaussian vector",
            "venue": "Theory of Probability and Mathematical Statstics",
            "year": 2015
        },
        {
            "authors": [
                "R. Kress"
            ],
            "title": "Linear Integral Equations",
            "venue": "https://doi.org/",
            "year": 1999
        },
        {
            "authors": [
                "O. Ledoit",
                "M. Wolf"
            ],
            "title": "Nonlinear shrinkage of the covariance matrix for portfolio selection: Markowitz meets goldilocks",
            "venue": "Rev. Financ. Stud",
            "year": 2017
        },
        {
            "authors": [
                "H. Markowitz"
            ],
            "title": "Portfolio selection",
            "venue": "J. Finance 7(1),",
            "year": 1952
        },
        {
            "authors": [
                "A.M. Mathai",
                "S.B. Provost"
            ],
            "title": "Quadratic Forms in Random Variables",
            "year": 1992
        },
        {
            "authors": [
                "S. Muhinyuza"
            ],
            "title": "A test on mean-variance efficiency of the tangency portfolio in highdimensional setting. Theory of Probability and Mathematical Statistics In press (2020)",
            "year": 2020
        },
        {
            "authors": [
                "S. Muhinyuza",
                "T. Bodnar",
                "M. Lindholm"
            ],
            "title": "A test on the location of the tangency portfolio on the set of feasible portfolios",
            "venue": "Appl. Math. Comput",
            "year": 2020
        },
        {
            "authors": [
                "Y. Okhrin",
                "W. Schmid"
            ],
            "title": "Distributional properties of portfolio weights",
            "venue": "J. Econom. 134(1),",
            "year": 2006
        },
        {
            "authors": [
                "M. Planitz"
            ],
            "title": "Inconsistent systems of linear equations",
            "venue": "Math. Gaz. 63(425),",
            "year": 1979
        },
        {
            "authors": [
                "F. Rubio",
                "X. Mestre",
                "D.P. Palomar"
            ],
            "title": "Performance analysis and optimal selection of large minimum variance portfolios under estimation risk",
            "venue": "IEEE J. Sel. Top. Signal Process",
            "year": 2012
        },
        {
            "authors": [
                "N.N. Taleb"
            ],
            "title": "The Black Swan: The Impact of the Highly Improbable",
            "venue": "Random house,",
            "year": 2007
        },
        {
            "authors": [
                "A.N. Tikhonov"
            ],
            "title": "Arsenin, V.Y.: Solutions of Ill-Posed Problems",
            "year": 1977
        },
        {
            "authors": [
                "H. Tsukuma"
            ],
            "title": "Estimation of a high-dimensional covariance matrix with the Stein loss",
            "venue": "J. Multivar. Anal. 148,",
            "year": 2016
        }
    ],
    "sections": [
        {
            "text": "Keywords Tangency portfolio, singular inverse Wishart, Moore\u2013Penrose inverse, reflexive generalized inverse, estimator moments\n2010 MSC 62H12, 91G10\n\u2217Corresponding author.\n\u00a9 2022 The Author(s). Published by VTeX. Open access article under the CC BY license.\nwww.vmsta.org"
        },
        {
            "heading": "1 Introduction",
            "text": "How to efficiently allocate capital lies at the heart of financial decision making. Portfolio theory, as developed by [35], provides a framework for this problem, based on the means, variances and covariances of the assets in the considered portfolio. The theory revolves around the trade-off between expected return and variance (risk), denoted by mean-variance optimization. In this setting, investors allocate wealth in order to maximize expected return given a certain level of risk or conversely allocate wealth to minimize the risk given a certain level of expected return. Although it has received a lot of criticism (see, e.g., [42] and [27]), the framework remains one of the most crucial components in portfolio management.\nIn this paper, we consider the tangency portfolio (TP) which is one of the most important portfolios in the financial literature. The TP weights determine what proportions of the capital to invest in each asset and are obtained by maximizing the expected quadratic utility function. For a portfolio of p risky assets, the TP weights are given by\nwT P = \u03b1\u22121 \u22121(\u03bc \u2212 rf 1p), (1) where \u03bc is a p-dimensional mean vector of the asset returns, is a p \u00d7 p symmetric positive definite covariance matrix of the asset returns, the coefficient \u03b1 > 0 describes the investors\u2019 risk aversion,1 rf denotes the rate of a risk-free asset and 1p is a p-dimensional vector of ones. We allow for short sales and, therefore, some weights can be negative. Let us also note that wT P determines the structure of the portfolio which corresponds to risky assets and does in general not sum to 1. Consequently, the rest of the wealth 1 \u2212 w\u2032T P 1p needs to be invested into the risk-free asset.\nNaturally, the TP weights wT P depend on knowledge of the mean vector \u03bc and the covariance matrix . In general, these quantities are not known and need to be estimated from data on N historical return vectors x1, . . . , xN . Plugging sample estimates of the mean vector and covariance matrix into (1) leads us to the sample estimate of the TP weights expressed as\nw\u0302T P = \u03b1\u22121S\u22121(x\u0304 \u2212 rf 1p), (2) where S is the sample covariance matrix and x\u0304 is the sample mean vector, respectively, of x1, . . . , xN .2 The statistical properties of w\u0302T P have been extensively studied throughout the literature. [18] derived an exact test of the weights in the multivariate normal case. [39] obtained the univariate density for the TP weights as well as its asymptotic distribution, under the assumption that returns are independent and identically multivariate normally distributed. Further, [4] provided a procedure of monitoring the TP weights with a sequential approach. [6] obtained the density for, and\n1This value represents how willing an investor is to accept upward and downward risks on their investment. It can be determined through, e.g., qualitative assessment, such as interview questions posed to the investor.\n2It is worth to mention that a similar structure appears in the discriminant analysis. Namely, the coefficients of a discriminant function that maximizes the discrepancy between two datasets are expressed as a product of the inverse sample covariance matrix and the sample mean vector (see, for example, [6, 14]).\nseveral exact tests on, linear transformations of estimated TP weights, while [32] provided approximate and asymptotic distributions for the weights. [3] studied the distribution of w\u0302T P from a Bayesian perspective.3 [15] studied the TP weights in small and large dimensions when both the population and sample covariance matrix are singular. Analytical expressions of higher order moments of the estimated TP weights are derived in [29], while the article [31] presented the asymptotic distribution of the estimated TP weights as well as the asymptotic distribution of the statistical test on the elements of the TP under a high-dimensional asymptotic regime. [38] derived a test for the location of the TP, and [37] extended this result to the high-dimensional setting. Furthermore, [9] derived central limit theorems for the TP weights estimator under the assumption that the matrix of observations has a matrix-variate location mixture of normal distributions. More recently, [30] investigated the distributional properties of the TP weights under a skew-normal model in small and large dimensions.\nThe common scenario considered is that the number of observations available for the estimation, denoted by N , is greater than the portfolio size, denoted by p. In this case the sample covariance matrix S is positive definite, and w\u0302T P can be obtained as presented in (2). However, when the considered portfolio is large, it is possible that the number of available observations is less than the portfolio dimension. This can be due to a lack of data for all the assets in the portfolio, but it may also occur due to the fact that covariance of asset returns tends to change over time. As such, the assumption of a constant covariance might only hold for limited periods of time, hence limiting the amount of data available for estimation. Many applications consider portfolios of large dimensions, containing up to 50, 100 or even 1000 assets (see, e.g., [41, 26, 34, 2, 20, 16, 22, 5, 12, 1]). If returns are measured on weekly or monthly intervals, data reaching back several decades might be required to ensure p \u2264 N . Unless the considered assets can be assumed to have a constant covariance matrix over very long time periods, data spanning such long time intervals is not suitable to use in the estimation, or might simply not be available. Any such situations, where p > N , would result in a singular sample covariance matrix S, which in turn is noninvertible, in the standard sense.\nThis issue can be remedied by estimating \u22121 in (1) with the Moore\u2013Penrose inverse of S, which we will denote by S+. This generalized inverse has previously been successfully employed in portfolio theory for the p > N case by [10, 11, 44, 15].4 Applying the Moore\u2013Penrose inverse, the TP weights are estimated as w\u0303T P = \u03b1\u22121S+(x\u0304 \u2212 rf 1p). (3) An attractive feature of applying the Moore\u2013Penrose inverse S+ in (1) is that it is the least square solution to the system of equations described by\nSv = \u03b1\u22121(x\u0304 \u2212 rf 1p) (4)\n3In the Bayesian setting, the posterior distribution of TP weights is expressed as a product of the (singular) Wishart matrix and Gaussian vector. Statistical properties of those products are studied by [7, 8, 13, 9].\n4Instead of using the Moore\u2013Penrose inverse, one can consider regularization techniques such as the ridge-type method [43], the Landweber\u2013Fridman iteration approach [33], a form of Lasso [19], or an iterative algorithm based on a second order damped dynamical systems [24, 25].\nwhich in the singular case generally lacks exact solution. That is, as shown in [40], for any vector v \u2208 Rp, we have that \u2016Sv\u2212\u03b1\u22121(x\u0304\u2212rf 1p)\u20162 \u2265 \u2016SS+(x\u0304\u2212rf 1p)\u2212\u03b1\u22121(x\u0304\u2212 rf 1p)\u20162, where \u2016\u00b7\u20162 denotes the Euclidean norm of a vector. Phrased differently, (3) provides the best solution to equation (4), in the least square sense. In addition, when p \u2264 N , we have that S+ = S\u22121 and w\u0303T P = w\u0302T P , such that w\u0303T P can be viewed as a general estimator for the TP weights, covering both the singular and nonsingular case. For further properties of the Moore\u2013Penrose inverse, see, e.g., [17].\nThe expectation and variance of an estimator are key quantities to describe its statistical properties. With the standard assumption of normally distributed asset returns, the stochastic components of w\u0303T P consists of S+ and x\u0304, which are independent under the assumption of normally distributed data (see, e.g., [10]). Unfortunately, there exist no derivation of the expected value or variance of S+, when p > N . In [21] however, these quantities are presented in the special case of = Ip. The authors also provided approximate results, using moments of standard normal random variables, and exact results for moments of the generalized reflexive inverse, another quantity that can be applied as an inverse of S. Further, in a recent paper [28], several bounds on the mean and variance of S+ are provided, based on the Poincar\u00e9 separation theorem. Our paper builds on the results presented in [21] and [28] to provide bounds and approximations for the moments of the TP weights, E[w\u0303T P ] and V[w\u0303T P ], where E[\u00b7] and V[\u00b7] denote the expected value and variance, respectively. We also present a simulation study, where various measures compare the derived bounds with the equivalent sample quantities obtained from simulated data. Finally, we compare the moments obtained applying the reflexive generalized inverse and the sample moments based on the Moore\u2013Penrose inverse.\nThe rest of this paper is organized as follows. Section 2.1 provides exact moment results for the case = Ip. Section 2.2 presents bounds for the moments of w\u0303T P in the general case, while approximate moments are derived in Section 2.3. Exact moments applying the reflexive generalized inverse are derived in Section 3. The simulation study is presented in Section 4 while Section 5 summarizes."
        },
        {
            "heading": "2 Moments with the Moore\u2013Penrose inverse",
            "text": "Let X be a p \u00d7 N matrix with N asset return vectors of dimension p \u00d7 1 stacked as columns, where p > N . Further, we assume that these return vectors are independent and normally distributed with mean vector \u03bc and positive definite covariance matrix . Thus X \u223c MN p,N(\u03bc1N, , IN), where MN p,n(M, , U) denotes the matrix-variate normal distribution with p \u00d7 N mean matrix M, p \u00d7 p rowwise covariance matrix and N \u00d7 N column-wise covariance matrix U. Further, let the p \u00d7 1 vector x\u0304 be the row mean of X. Now, define Y = X \u2212 x\u03041\u2032N , such that Y \u223c MN p,N (0, , IN). Further, let S = YY\u2032/n, such that rank(S) = n < p with n = N \u2212 1, and nS \u223c Wp(n, ), i.e. nS follows a p-dimensional singular Wishart distribution with n degrees of freedom and the parameter matrix . Let S = QRQ\u2032 denote the eigenvalue decomposition of S, where R is the n \u00d7 n diagonal matrix of positive eigenvalues and Q is the p \u00d7 n matrix with corresponding eigenvectors as columns. Further, define\nS+ = QR\u22121Q\u2032.\nThen, S+ constitutes the Moore\u2013Penrose inverse of YY\u2032/n, and S+ is independent of x\u0304 (see [10]).\nIn the following, let \u03b7 = \u03b1\u22121(x\u0304 \u2212 rf 1p) and \u03b8 = E[\u03b7] = \u03b1\u22121(\u03bc \u2212 rf 1p). Consequently, from Corollary 3.2b.1 in [36], together with the fact that E[x\u0304] = \u03bc and V[x\u0304] = /(n + 1), we obtain that\nE[\u03b7\u03b7\u2032] = \u03b8\u03b8 \u2032 + \u03b12(n + 1) , (5)\nE[\u03b7\u2032\u03b7] = \u03b8 \u2032\u03b8 + tr( ) \u03b12(n + 1) , (6)\nE[\u03b7\u2032 \u03b7] = \u03b8 \u2032 \u03b8 + tr( ) \u03b12(n + 1) . (7)\nFurther, let sij denote the element on row i and column j of S+, and let \u03c3 ij denote the element on row i and column j of \u22121. Also let ei denotes a p \u00d7 1 vector where all values are equal to zero, except the i-th element, which is equal to one. Moreover, we assume that \u03bb1(M) \u2265 \u03bb2(M) \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03bbp(M) are the ordered eigenvalues of a symmetric p \u00d7 p matrix M, and that A \u2264L B denotes the L\u00f6wner ordering of two positive semi-definite matrices A and B."
        },
        {
            "heading": "2.1 Exact moments when = Ip",
            "text": "When is the identity matrix, it is possible to derive exact moments of the TP weights obtained from the Moore\u2013Penrose inverse in the singular case. First, note the following results presented in Theorem 2.1 of [21], which state that in the case = Ip and p > n + 3, we have that\nE[S+] = a1Ip, (8) V[vec(S+)] = a2(Ip2 + Cp2) + 2a3vec(Ip)vec\u2032(Ip), (9)\nwhere Cp2 is the commutation matrix, vec(\u00b7) is the vectorization operator and\na1 = n 2\np(p \u2212 n \u2212 1) , (10)\na2 = n 3[p(p \u2212 1) \u2212 n(p \u2212 n \u2212 2) \u2212 2]\np(p \u2212 1)(p + 2)(p \u2212 n)(p \u2212 n \u2212 1)(p \u2212 n \u2212 3) , (11)\na3 = n 3[n2(n \u2212 1) + 2n(p \u2212 2)(p \u2212 n) + 2p(p \u2212 1)]\np2(p \u2212 1)(p + 2)(p \u2212 n)(p \u2212 n \u2212 1)2(p \u2212 n \u2212 3) . (12)\nNote that constants in (10)\u2013(12) differ slightly from the constants presented in [21], since our paper considers results for nS \u223c Wp(n, ), while [21] derived the results for W \u223c Wp(n, ). The moments in (8) and (9) allow us to derive the following results.\nTheorem 1. If p > n + 3 and = Ip, then E[w\u0303T P ] = a1wT P ,\nV[w\u0303T P ] = (a2 + 2a3)wT P w\u2032T P + [ a2w\u2032T P wT P + a21 + (p + 1)a2 + 2a3 \u03b12(n + 1) ] Ip\nwith constants a1, a2 and a3 that are defined in (10)\u2013(12). Proof. Since w\u0303T P = \u03b1\u22121S+(x\u0304 \u2212 rf 1p), the first result follows directly from (8) and the independence of S+ and x\u0304. For the second result, first note that as discussed in [21], equation (9) can be written as\nCov(sij , skl) = a2(\u03b4ik\u03b4jl + \u03b4il\u03b4jk) + 2a3\u03b4ij \u03b4kl, where \u03b4ij = 1 if i = j and 0 otherwise, so that \u03b4ij , i, j = 1 . . . , p, denote the elements of Ip. Hence, we have that\nE[sij skl] = a2(\u03b4ik\u03b4jl + \u03b4il\u03b4jk) + (a21 + 2a3)\u03b4ij \u03b4kl . (13) Also note the following element representations of matrix operations, where A and B are symmetric p \u00d7 p matrices and tr(\u00b7) denotes the trace operator of a matrix:\n[Atr(BA)]ij = aij p\u2211\nk=1 p\u2211 l=1 aklbkl, (14)\n[ABA]ij = p\u2211\nk=1 p\u2211 l=1 bklaikajl\n= p\u2211\nk=1 p\u2211 l=1 bklailajk. (15)\nMoreover, with \u03b7 = \u03b1\u22121(x\u0304 \u2212 rf 1p) and E[\u03b7] = \u03b8 , V[w\u0303T P ] = V[S+\u03b7] = E [ E[S+\u03b7\u03b7\u2032S+ | \u03b7]]\u2212 E[S+]\u03b8\u03b8 \u2032 E[S+]. (16) By letting H = \u03b7\u03b7\u2032 and applying equations (13)\u2013(15) we obtain\nE[S+HS+ | \u03b7]ij = p\u2211\nk=1 p\u2211 l=1 hkl E[siksj l]\n= p\u2211\nk=1 p\u2211 l=1 hkl[a2(\u03b4ij \u03b4kl + \u03b4il\u03b4kj ) + (a21 + 2a3)\u03b4ik\u03b4jl]\n= a2 [ Iptr(HIp) ] ij\n+ a2[IpHIp]ij + (a21 + 2a3)[IpHIp]ij . Consequently, E[S+HS+ | \u03b7] = (a21 + a2 + 2a3)H + a2tr(H)Ip, and inserting the above result into (16) together with (5) and (8) gives\nV[S+\u03b7] = (a21 + a2 + 2a3) ( \u03b8\u03b8 \u2032 + \u03b1\u22122N\u22121Ip ) +\n+a2 ( tr(\u03b8\u03b8 \u2032) + \u03b1\u22122N\u22121p ) Ip \u2212 a21\u03b8\u03b8 \u2032\nand the theorem follows noting that \u03b8 = wT P when = Ip.\nA direct consequence of Theorem 1 is that the estimator w\u0303T P is biased, with bias factor a1. Hence, in the case of = Ip, we have that a\u221211 w\u0303T P constitutes an unbiased estimator. Further, in accordance with Corollary 2.1 in [21], as n, p \u2192 \u221e, assuming n/p \u2192 r , with 0 < r < 1, the constants of V[w\u0303T P ] emits the following asymptotic magnitudes: a1 = O(1), a2 = O(n\u22121) = O(p\u22121) and a3 = O(n\u22122) = O(p\u22122). Consequently, since tr(wT P w\u2032T P ) = O(p) in the general case, we have that a2tr(wT P w\u2032T P ) = O(1). Hence, unless wT P has some specific structure, V[w\u0303T P ] does not vanish to zero under this asymptotic regime. This is not unique for the singular case, since the corresponding is also true for w\u0302T P in the nonsingular case, when n, p \u2192 \u221e. Finally, we note that in practice the population covariance matrix of a portfolio of assets will likely never be equal to Ip, and hence the results in this section are mainly of theoretical nature."
        },
        {
            "heading": "2.2 Bounds on the moments",
            "text": "This section aims to provide upper and lower bounds for the expected value of w\u0303T P and upper bounds for the variance of w\u0303T P . First, define the following p\u00d7p matrices,\nD = a1(\u03bbp( \u22121))2 , Ua = a1(\u03bb1( \u22121))2 , Ub = n\np \u2212 n \u2212 1\u03bb1( \u22121)Ip,\nwith elements dij , u (a) ij and u (b) ij , respectively. Further denote by eij the elements of E[S+] and let u(\u2217)ii = min{u(a)ii , u(b)ii }, i = 1, . . . , p. Then we can derive the following result. Theorem 2. Suppose p > n + 3 and > 0. Let wi and \u03b8i , be the i-th elements of the p \u00d7 1 vectors w = E[w\u0303T P ] and \u03b8 = \u03b1\u22121(\u03bc \u2212 rf 1p), respectively. Then for i = 1, . . . , p, it holds that\nvii\u03b8i + p\u2211\nj =i vij \u03b8j \u2264 wi \u2264 zii\u03b8i + p\u2211 j =i zij \u03b8j\nwhere, for i, j = 1, . . . , p,\nvij = { gij if \u03b8j \u2265 0, hij if \u03b8j < 0,\nzij = { gij if \u03b8j < 0, hij if \u03b8j \u2265 0,\nwith gii = dii , hii = u(\u2217)ii , while for i = j ,\ngij = max \u23a7\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a8 \u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a9 dij \u2212 \u221a (u (\u2217) ii \u2212 dii)(u(\u2217)jj \u2212 djj ), u (a) ij \u2212 \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ), \u2212 \u221a (u (b) ii \u2212 dii)(u(b)jj \u2212 djj ), \u2212 \u221a\nu (\u2217) ii u (\u2217) jj\n\u23ab\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ac \u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ad ,\nhij = min \u23a7\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a8 \u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a9 dij + \u221a (u (\u2217) ii \u2212 dii)(u(\u2217)jj \u2212 djj ), u (a) ij + \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ),\u221a (u (b) ii \u2212 dii)(u(b)jj \u2212 djj ),\u221a\nu (\u2217) ii u (\u2217) jj\n\u23ab\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ac \u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ad .\nProof. The result follows directly from the element-wise bounds in Lemma A2 and that due to the independence of S+ and x\u0304 we have E[w\u0303T P ] = E[S+]\u03b8 .\nNote that when = Ip, we have that \u03bb1( \u22121)2 = \u03bbp( \u22121)2 = 1, and hence E[S+] = D = Ua = a1Ip. Consequently gij = hij = 0, i = j , and gii = hii = a1, i = 1, . . . , p, since u(a)ii = a1 < a1 pn = u(b)ii , and p > n. Hence, Theorem 2 yields that E[w\u0303T P ] = a1\u03b8 , consistent with the result of Theorem 1.\nThe following result provides two upper bounds for the variance of the TP weights estimate w\u0303T P . Theorem 3. Suppose p > n + 3 and > 0. Then V[w\u0303T P ] \u2264L (2c1 + c2)(\u03bb1( \u22121))4 ( k1 E[\u03b7\u03b7\u2032] + k2 E[\u03b7\u2032 \u03b7] ) , (17) V[w\u0303T P ] \u2264L (2c1 + c2)(\u03bb1( \u22121))4 E[(\u03b7\u2032\u03b7)]Ip, (18) with the expected values given in (5)\u2013(7) and\nc1 = n2[(p \u2212 n)(p \u2212 n \u2212 1)(p \u2212 n \u2212 3)]\u22121, c2 = (p \u2212 n \u2212 2)c1, k1 = [ 1 + n \u2212 (p + 1)(p(n + 1) \u2212 2) p(p + 1) \u2212 2 ] n p ,\nk2 = [\n1 \u2212 (p + 1)(p \u2212 n) p(p + 1) \u2212 2\n] n\np .\nProof. We are interested in bounds for the quantity \u03b1\u2032 V[w\u0303T P ]\u03b1 = \u03b1\u2032 V[S+\u03b7]\u03b1, for all \u03b1 \u2208 Rp. First, by the tower property we have\nV[S+\u03b7] = E [E[S+\u03b7\u03b7\u2032S+ | \u03b7]]\u2212 E[S+]\u03b8\u03b8 \u2032 E[S+]. Hence, we can obtain\n\u03b1\u2032 V[S+\u03b7]\u03b1 = E [E[\u03b1\u2032S+\u03b7\u03b7\u2032S+\u03b1 | \u03b7]]\u2212 \u03b1\u2032 E[S+]\u03b8\u03b8 \u2032 E[S+]\u03b1\u2032 = E [ E[(\u03b1\u2032S+\u03b7)2 | \u03b7] ] \u2212 (\u03b1\u2032 E[S+]\u03b8)2.\nThen, by noting that (\u03b1\u2032 E[S+]\u03b8)2 > 0 and applying the bounds from Lemma A4 on E[(\u03b1\u2032S+\u03b7)2] we can derive\n\u03b1\u2032 V[S+\u03b7]\u03b1 \u2264 (2c1 + c2)(\u03bb1( \u22121))4 \u00d7E [ k1(\u03b1 \u2032 \u03b7)2 + k2(\u03b1\u2032 \u03b1)(\u03b7\u2032 \u03b7) ] ,\n\u03b1\u2032 V[S+\u03b7]\u03b1 \u2264 (\u03bb1( \u22121))4(2c1 + c2)E[(\u03b1\u2032\u03b1)(\u03b7\u2032\u03b7)], and with the aid of (5)\u2013(7) the result follows."
        },
        {
            "heading": "2.3 Approximate moments",
            "text": "Regarding general , it is possible to provide approximate moments for w\u0303T P using simulations of standard normal matrices. Following Section 3.1 in [21], we denote the eigendecomposition of as = \u2032, with \u03bbi denoting the i-th diagonal element of , and let Z \u223c MN p,n(0, Ip, In), with z\u2032i denoting row i of Z. Further, denote mij ( ) = E[z\u2032i (Z\u2032 Z)\u22122zj ] and vij,kl( ) = Cov[z\u2032i (Z\u2032 Z)\u22122zj , z\u2032k(Z\u2032 Z)\u22122zl], where Cov[X, Y ] denotes the covariance between X and Y .\nAlso define\nM( ) = n p\u2211\ni=1 \u03bbimii( )eie\u2032i ,\nV( ) = n2 \u23a1 \u23a3 p\u2211\ni=1 p\u2211 j=1 \u03bbi\u03bbj vii,jj ( )(eie\u2032j \u2297 eie\u2032j )\n+ p\u2211\ni=1 p\u2211 j=1 \u03bbi\u03bbjvij,ij ( )(ej e\u2032j \u2297 eie\u2032i )(Ip2 + Cp2)\n\u22122 p\u2211 i \u03bb2i vii,ii ( )(eie \u2032 i \u2297 eie\u2032i )\n] (19)\nand make the decomposition\n( \u2297 )V( )( \u2032 \u2297 \u2032) = \u239b \u239c\u239d 11 \u00b7 \u00b7 \u00b7 1p ... . . . ...\np1 \u00b7 \u00b7 \u00b7 pp\n\u239e \u239f\u23a0 , (20)\nwhere ij are p \u00d7 p matrices, i, j = 1, . . . , p. The following result can then be derived. Theorem 4. If p > n + 3 and > 0, then E[w\u0303T P ] = M( ) \u2032\u03b8 ,\nV[w\u0303T P ] = p\u2211\ni=1 p\u2211 j=1 ( \u03b8i\u03b8j + \u03c3ij \u03b12(n + 1) ) ij + 1 \u03b12(n + 1) M( ) M( ) \u2032\nwith \u03b8i = \u03b1\u22121(\u03bci \u2212 rf ). Proof. From Theorem 3.1 in [21], we have that E[S+] = M( ) \u2032. Then the first result follows due to the independence of S+ and x\u0304. For the second result, we have that V[S+\u03b7] = E [E[S+\u03b7\u03b7\u2032S+ | \u03b7]]\u2212 E[S+]\u03b8\u03b8 \u2032 E[S+]. (21) Again we let H = \u03b7\u03b7\u2032. Applying Theorem 3.1 in [21] we have that\nV[vec(S+)] = ( \u2297 )V( )( \u2032 \u2297 \u2032),\nand in accordance with equation (6.8) in [23], we get\nE[S+HS+] = p\u2211\ni=1 p\u2211 j=1 hij ij + E[S+]HE[S+],\nwhere ij is obtained from the decomposition (20). Inserting the above into (21) gives\nV[S+\u03b7] = p\u2211\ni=1 p\u2211 j=1 E[hij ] ij + E[S+]E[H]E[S+] \u2212 E[S+]\u03b8\u03b8 \u2032 E[S+]\n= p\u2211\ni=1 p\u2211 j=1 ( \u03b8i\u03b8j + \u03c3ij \u03b12N ) ij + 1 \u03b12N M( ) M( ) \u2032\ndue to (5) and since \u2032 = . The theorem is proved. In [21] the authors note that the moments mij ( ) and vij,kl( ) do not seem to have tractable closed-form representations. However, these quantities can be approximated by simulation of Z, given the eigenvalues of ."
        },
        {
            "heading": "3 Exact moments with reflexive generalized inverse",
            "text": "An alternative to using the Moore\u2013Penrose inverse S+ to estimate \u22121 is an application of the reflexive generalized inverse, defined as\nS\u2020 = \u22121/2 ( \u22121/2S \u22121/2 )+ \u22121/2,\nwhere the elements of S\u2020 are denoted s\u2020ij . Then, the TP weights vector can be estimated by\nw\u2020T P = S\u2020\u03b7, and we derive the following result.\nTheorem 5. If p > n + 3 and > 0, then E[w\u2020T P ] = a1wT P , V[w\u2020T P ] = (a2 + 2a3)wT P w\u2032T P\n+ [ a2w\u2032T P wT P + a21 + (p + 1)a2 + 2a3 \u03b12(n + 1) ] \u22121.\nProof. The first result follows directly from Corollary 2.3 in [21], and the independence of S and x\u0304. For the second result, we have that\nV[S\u2020\u03b7] = E [ E[S\u2020\u03b7\u03b7\u2032S\u2020 | \u03b7] ] \u2212 E[S\u2020]\u03b8\u03b8 \u2032 E[S\u2020]. (22)\nAgain we let H = \u03b7\u03b7\u2032, and note that by Corollary 2.3 in [21] we have\nE[s\u2020iks\u2020lj ] = a2(\u03c3 ij \u03c3 kl + \u03c3 il\u03c3 kj ) + (a21 + 2a3)\u03c3 ik\u03c3 jl\nwhich combined with (14)\u2013(15) allows us to obtain\nE [ S\u2020HS\u2020 | \u03b7 ] ij = p\u2211\nk=1 p\u2211 l=1 hkl E [ s \u2020 iks \u2020 lj ]\n= p\u2211\nk=1 p\u2211 l=1 hkl ( a2(\u03c3 ij \u03c3 kl + \u03c3 il\u03c3 kj )\n+(a21 + 2a3)\u03c3 ik\u03c3 jl )\n= (a21 + a2 + 2a3) [ \u22121H \u22121 ] ij + a2tr(H \u22121) [ \u22121 ] ij\nso sthat\nE[S\u2020HS\u2020 | \u03b7] = (a21 + a2 + 2a3) \u22121H \u22121 + a2tr(H \u22121) \u22121. Inserting this into equation (22) gives\nV[S\u2020\u03b7] = (a21 + a2 + 2a3) \u22121 E[\u03b7\u03b7\u2032] \u22121 + a2tr(E[\u03b7\u03b7\u2032] \u22121) \u22121 \u2212E[S\u2020]\u03b8\u03b8 \u2032 E[S\u2020],\nand applying the first result on E[S\u2020] together with (5) concludes the proof. An obvious drawback of w\u2020T P is that must be known in order to construct S\n\u2020. Moreover, in the case of = Ip the results in Theorem 5 coincide with the results in Theorem 1, since in this case S\u2020 = S+."
        },
        {
            "heading": "4 Simulation study",
            "text": "The aim of this section is to compare the bounds on the moments of w\u0303T P derived in Section 2.2 with the sample mean and sample variance of this estimator. We will also investigate the difference between the moments of w\u2020T P derived in Theorem 5 and the sample moments of w\u0303T P . Ideally, the bounds should not deviate from the obtained sample moments very much. To this end, define bl and bu as the p \u00d7 1 vectors with elements\nbli = vii\u03bci + p\u2211\nj =i vij\u03bcj ,\nbui = zii\u03bci + p\u2211\nj =i zij\u03bcj ,\nsuch that bl and bu represent the element-wise lower and upper bounds for the expected TP weights vector presented in Theorem 2, where we set \u03b1 = 1 and rf = 0. Let\nB1 = (2c1 + c2)(\u03bb1( \u22121))4 ( k1 E[\u03b7\u03b7\u2032] + k2 E[\u03b7\u2032 \u03b7] ) ,\nB2 = (2c1 + c2)(\u03bb1( \u22121))4 E[(\u03b7\u2032\u03b7)]Ip represent the bounds in equations (17) and (18) in Theorem 3, respectively. Further, let m and V respectively denote the sample mean vector and sample covariance matrix of w\u0303T P based on an observed matrix X, as described in Section 2. Moreover, we define\ntl = 1\u2032p|bl \u2212 m|\np , (23)\ntu = 1\u2032p|bu \u2212 m|\np , (24)\nt\u2020 = 1 \u2032 p|E[w\u2020T P ] \u2212 m|\np , (25)\nso that tl , tu and t\u2020 measure the element-wise difference between the sample mean vector and the lower and upper bounds on the mean, and mean of w\u2020T P , respectively. Dividing by p allows comparing the measures between various portfolio sizes. Further, let\nT1 = \u2223\u2223\u22231\u2032p (B1 \u2212 V) 1p\u2223\u2223\u2223\np2 , (26)\nT2 = \u2223\u2223\u22231\u2032p (B2 \u2212 V) 1p\u2223\u2223\u2223\np2 , (27)\nT \u2020 = \u2223\u2223\u22231\u2032p (V[w\u2020T P ] \u2212 V) 1p\u2223\u2223\u2223\np2 , (28)\nwhere 1p is a p\u00d71 vector of ones. Then, T1 and T2 provide a measure of discrepancy between the sample covariance matrix and bounds presented in Theorem 3, while T \u2020 measures the discrepancy between the variance of w\u2020T P presented in Theorem 5 and the sample covariance matrix of w\u0303T P . Since it is divided by p2, the number of elements in B1, B2, V[w\u2020T P ] and V, the measures T1, T \u2020 and T2 again allow for comparison between different portfolio sizes. Moreover, define\nfl = \u2016bl \u2212 m\u20162F /\u2016m\u20162F , (29) fu = \u2016bu \u2212 m\u20162F /\u2016m\u20162F , (30) f \u2020 = \u2016E[w\u2020T P ] \u2212 m\u20162F /\u2016m\u20162F , (31) F1 = \u2016B1 \u2212 V\u20162F /\u2016V\u20162F , (32)\nF2 = \u2016B2 \u2212 V\u20162F /\u2016V\u20162F , (33) F \u2020 = \u2016V[w\u2020T P ] \u2212 V\u20162F /\u2016V\u20162F , (34)\nwhere \u2016M\u20162F denotes the Frobenius norm of the matrix M. Hence f1, f2, F1 and F2 represent the normalized Frobenius norm of differences between the bounds and the sample variance, while f \u2020 and F \u2020 denote the differences between the moments of w\u2020T P and the sample variance of w\u0303T P .\nIn the following, we will study simulations of (23)\u2013(34) for various parameter values. In order to account for a wide range of values of \u03bc and , these values will be randomly generated in the simulation study. Each of the p elements in the mean vector \u03bc will be independently generated as U(\u22120.1, 0.1), where U(l, u) denotes the uniform distribution between l and u. The positive definite covariance matrix will be determined as = \u2032, where the p \u00d7 p matrix represent the eigenvectors of and is generated according to the Haar distribution. The p \u00d7 p matrix is diagonal, and its elements represents the ordered eigenvalues of . Here we let the p eigenvalues be equally spaced from d to 1, for various values of d . Then, the parameter d represents a measure of dependency between the p assets in the portfolio, where d = 1 represents no dependency and larger d represents a stronger dependency structure. Consequently, the simulation procedure can be described as follows:\n1) Generate \u03bc, with \u03bci \u223c U(\u22120.1, 0.1), i = 1 . . . , p. 2) Generate according to the Haar distribution, and compute = \u2032, where\ndiag( ) = d . . . , 1. 3) Independently generate x\u0304 \u223c Np,1(\u03bc, /N) and nS \u223c Wp(n, ). 4) Compute w\u0303T P .\n5) Repeat steps 3) and 4) above s = 10000 times. 6) Based on the s samples of w\u0303T P , compute m and V.\n7) Given m and V, compute (23)\u2013(34).\nThe above procedure is repeated r = 10 times to get r values of (23)\u2013(34) for a given combination of p, N and d . Figures 1\u201312 display the mean value, for the r simulations, of each respective measure, for p = {25, 50, 75, 100}, d = {1, . . . , 10} and N = {2, 0.4p, 0.7p, p \u2212 3}.5 For easier reading, the values are displayed on a logarithmic scale and are connected with a solid line. First, we notice that most measures seem to increase with increasing dependency measure d . Further, tl , tu, t\u2020, T1, T2, T \u2020 increase with increasing sample size N . However, F2, the measure of the discrepancy between the sample variance of w\u0303T P and the variance bound B2, on the contrary, decreases with increasing N . Regarding the bounds on the expected value\n5The computation time for each set of simulations for p = {25, 50, 75, 100} is {12, 26, 55, 107} minutes, respectively, when calculation is run on 15 threads of an AMD Ryzen 7 5800H CPU. Hence, for future research, it is possible to explore even larger sample sizes on a standard PC.\nof w\u0303T P , tl and tu become very similar, and so do f1 and f2. The measures of the difference between E[w\u0303T P ] and E[w\u2020T P ], t\u2020 and f \u2020, are fairly small for most of the considered simulation parameters. This suggests that E[w\u2020T P ] can serve as a rough approximation of E[w\u0303T P ], especially for N \u2208 (0.4p, 0.7p). Furthermore, when d = 1 we have = Ip, and hence the both bounds b1 and b2, as well as E[w\u2020T P ], provide equality with E[w\u0303T P ]. In particular, for d = 1, these measures simply capture sample variance for the mean of m. Similarly, when d = 1, T \u2020 and F \u2020 capture the sample variance of V. Further, for N < p \u2212 3 and low values of d , T \u2020 and F \u2020 are fairly small, suggesting that V[w\u2020T P ] could be applied as a rough approximation of V[w\u0303T P ] in these cases. Finally, we notice that the measures F1 and F2 become very large for most of the combinations of p, N and d . It is however important to note that the Frobenius norm of differences, that these measures are based on, captures elementwise squared discrepancies, while B1 and B2 are not element-wise bounds, but rather bounds in the L\u00f6wner order sense."
        },
        {
            "heading": "5 Summary",
            "text": "The TP is an important portfolio in mean-variance asset optimization framework of [35], and the statistical properties of the typical TP weight estimator have been thor-\noughly studied. However, when the portfolio dimension is greater than the sample size, this estimator is not applicable since standard inversion of the now singular sample covariance matrix is not possible. This issue can be solved by applying the Moore\u2013Penrose inverse, to which a general TP weights estimator can be provided, covering both the singular and nonsingular case. Unfortunately, there exists no derivation of the moments for the Moore\u2013Penrose inverse of a singular Wishart matrix, and consequently the moments of the general TP estimator cannot be obtained.\nIn this paper, we provide bounds on the mean and variance of the TP weights estimator in the singular case. Further, we present approximate results, as well as exact moment results in the case when the population covariance is equal to the identity matrix. We also provide exact moment results when the reflexive generalized inverse is applied in the TP weights equation.\nMoreover, we investigate the properties of the derived bounds, and the estimator based on the reflexive generalized inverse, in a simulation study. The difference between the various bounds and the sample counterparts are measured by several quantities, and studied for numerous dimensions, sample sizes and levels of dependencies of the population covariance matrix. The results suggest that many of the derived bounds are closest to the sample moments when the population covariance\nmatrix implies low dependency between the considered assets. Finally, the study implies that in some cases the moments of TP weights based on the reflexive generalized inverse can be used as a rough approximation for the moments of TP weights based on the Moore\u2013Penrose inverse. For future studies, it would be relevant, for example, to perform a sensitivity analysis on how fluctuations in the population covariance matrix affect the estimated TP weights.\nAppendix\nLemma A1. The elements of E[S+] have the bounds, for i = 1, . . . , p,\n0 < dii \u2264 eii \u2264 u(a)ii , and, for i, j = 1, . . . , p, i = j ,\neij \u2264 min{dij , u(a)ij } + \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ),\neij \u2265 max{dij , u(a)ij } \u2212 \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ).\nProof. First note that in accordance with Theorem 3.2 and Theorem 3.3 of [28], we have that\nD \u2264L E[S+] \u2264L Ua, E[S+] \u2264L Ub.\nFurther, by definition of the L\u00f6wner order we have, with \u03b1 \u2208 Rp, that \u03b1\u2032D\u03b1 \u2264 \u03b1\u2032 E[S+]\u03b1 \u2264 \u03b1\u2032U\u03b1. (35)\nThus, since \u03b1\u2032(E[S+] \u2212 D)\u03b1 \u2265 0, we have that E[S+] \u2212 D is a positive semi-definite matrix, and the same holds for U \u2212 E[S+]. This gives that 0 < dii \u2264 eii \u2264 u(a)ii , i = 1, . . . , p.\nMoreover, note that every principal submatrix of a positive definite matrix is also positive definite. Combined with (35) it provides the following inequalities, for any i, j = 1, . . . , p, and with arbitrary nonzero scalars x1 and x2,\nx21u (a) ii + 2x1x2u(a)ij + x22u(a)jj \u2265 x21eii + 2x1x2eij + x22ejj \u2265\nx21dii + 2x1x2dij + x22djj > 0.\nNow, first assume x1 > 0, x2 > 0. Then, the above expressions can be applied to obtain\nx21eii + 2x1x2eij + x22eii \u2265 x21dii + 2x1x2dij + x22djj , (36) x21u (a) ii + 2x1x2eij + x22u(a)jj \u2265 x21dii + 2x1x2dij + x22djj ,\neij \u2265 \u2212 x21(u (a) ii \u2212 dii) + x22(u(a)jj \u2212 djj ) \u2212 2x1x2dij\n2x1x2\n= \u2212x1(u (a) ii \u2212 dii) 2x2 \u2212 x2(u (a) jj \u2212 djj ) 2x1 + dij (37)\nfor any i, j = . . . , p, i = j . As the right-hand side is a lower bound, we would like to obtain values x1 and x2 that maximizes this concave function. Deriving and setting the expression equal to zero, we obtain that it has its maximum at\nx21(u (a) ii \u2212 dii) = x22(u(a)jj \u2212 djj ).\nWithout loss of generality we can set x1 = 1 and thus obtain the maximum at x1 = 1,\nx2 = \u221a\u221a\u221a\u221a (u(a)ii \u2212 dii)\n(u (a) jj \u2212 djj )\n.\nApplying this result to equation (37) yields\neij \u2265 dij \u2212 \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ). (38)\nWith an equivalent approach, again with x1 > 0, x2 > 0, we can use inequalities\nx21dii + 2x1x2eij + x22djj \u2264 x21u(a)ii + 2x1x2u(a)ij + x22u(a)jj ,\neij \u2264 x21(u (a) ii \u2212 dii) + x22(u(a)jj \u2212 djj ) + 2x1x2u(a)ij\n2x1x2\nin order to obtain the upper bound\neij \u2264 u(a)ij + \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ). (39)\nInstead considering x1 < 0 and x2 > 0 (or x1 > 0 and x2 < 0), with a similar approach, we can obtain the bounds\neij \u2264 dij + \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ),\neij \u2265 u(a)ij \u2212 \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ).\nLetting x1 < 0 and x2 < 0 again yield bounds (38) and (39). Expressing it differently, the above bounds can be written as\neij \u2264 min{dij , u(a)ij } + \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ),\neij \u2265 max{dij , u(a)ij } \u2212 \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ),\nconcluding the proof.\nThe results in Lemma A1 can be further extended, by also considering the bounding matrix Ub. The following lemma summarizes this result. Lemma A2. The elements of E[S+] have the bounds, for i = 1, . . . , p, 0 < gii := dii \u2264 eii \u2264 hii := u(\u2217)ii ,\nwhere u(\u2217)ii = min{u(a)ii , u(b)ii }. Further, for i, j = 1, . . . , p, i = j ,\ngij \u2264 eij \u2264 hij\nwith\ngij = max \u23a7\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a8 \u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a9 dij \u2212 \u221a (u (\u2217) ii \u2212 dii)(u(\u2217)jj \u2212 djj ), u (a) ij \u2212 \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ), \u2212 \u221a (u (b) ii \u2212 dii)(u(b)jj \u2212 djj ), \u2212 \u221a\nu (\u2217) ii u (\u2217) jj\n\u23ab\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ac \u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ad ,\nhij = min \u23a7\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a8 \u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23a9 dij + \u221a (u (\u2217) ii \u2212 dii)(u(\u2217)jj \u2212 djj ), u (a) ij + \u221a (u (a) ii \u2212 dii)(u(a)jj \u2212 djj ),\u221a (u (b) ii \u2212 dii)(u(b)jj \u2212 djj ),\u221a\nu (\u2217) ii u (\u2217) jj\n\u23ab\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ac \u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ad .\nProof. First, we have that dij \u2212 \u221a (u (\u2217) ii \u2212 dii)(u(\u2217)jj \u2212 djj ) \u2264 eij \u2264 dij + \u221a (u (\u2217) ii \u2212 dii)(u(\u2217)jj \u2212 djj ),\nsince eii (and ejj ) in (36) can be replaced by either u (a) ii or u (b) ii , whichever is the smaller. Then\nu (a) ij \u2212\n\u221a (u\n(a) ii \u2212 dii)(u(a)jj \u2212 djj ) \u2264 eij \u2264 u(a)ij +\n\u221a (u\n(a) ii \u2212 dii)(u(a)jj \u2212 djj )\n\u2212 \u221a\n(u (b) ii \u2212 dii)(u(b)jj \u2212 djj ) \u2264 eij \u2264\n\u221a (u\n(b) ii \u2212 dii)(u(b)jj \u2212 djj )\nfollows directly from Lemma A1 and the fact that Ub is diagonal and thus u (b) ij = 0. Finally,\n\u2212 \u221a\nu (\u2217) ii u (\u2217) jj \u2264 eij \u2264\n\u221a u\n(\u2217) ii u (\u2217) jj\nfollows from \u2212 \u221a\nu (\u2217) ii u (\u2217) jj \u2264 \u2212 \u221a eiiejj \u2264 eij \u2264 \u221aeiiejj \u2264 \u221a u (\u2217) ii u (\u2217) jj .\nThe lemma is proved.\nIn the following, let\nk3 = n[p(n + 1) \u2212 2] p[p(p + 1) \u2212 2] , k4 = n(p \u2212 n) p[p(p + 1) \u2212 2] .\nFurther, define g(L) = \u220fni=1 |Li |+ and c(n, p) = (2\u03c0)np/22ns(n, p), where |Li |+ and s(n, p) are defined as on pages 128 and 129 in [28]. Lemma A3. Let an n \u00d7 p matrix L satisfy LL\u2032 = In. Then, for all \u03b1, x \u2208 Rp, (i) \u222b (\u03b1\u2032L\u2032L\u03b1)(x\u2032L\u2032Lx)g(L)dL = k1c(n, p)(\u03b1\u2032x)2 + k2c(n, p)(\u03b1\u2032\u03b1)(x\u2032x),\n(ii) \u222b (\u03b1\u2032L\u2032Lx)2g(L)dL = k3c(n, p)(\u03b1\u2032x)2 + k4c(n, p)(\u03b1\u2032\u03b1)(x\u2032x).\nProof. In accordance with page 130 in [28], we have\nn(Ip2 + Kp,p) + n2vec(Ip)vec\u2032(Ip) = c(n, p)\u22121 \u222b (L \u2297 L)\u2032 { p(In2 + Kn,n) + p2vec(In)vec\u2032(In) } \u00d7\n\u00d7 (L \u2297 L)g(L)dL, (40)\nwhere K\u00b7,\u00b7 is the commutation matrix. Now note that\n(\u03b1 \u2297 x)\u2032Ip2(\u03b1 \u2297 x) = (\u03b1\u2032\u03b1)(x\u2032x), (41) (\u03b1 \u2297 x)\u2032Kp,p(\u03b1 \u2297 x) = (\u03b1\u2032x)2, (42) (\u03b1 \u2297 x)\u2032vec(Ip)vec\u2032(Ip)(\u03b1 \u2297 x) = (\u03b1\u2032x)2, (43) (\u03b1 \u2297 x)\u2032(L \u2297 L)\u2032In2(L \u2297 L)(\u03b1 \u2297 x) = (\u03b1\u2032L\u2032L\u03b1)(x\u2032L\u2032Lx), (44) (\u03b1 \u2297 x)\u2032(L \u2297 L)\u2032Kn,n(L \u2297 L)(\u03b1 \u2297 x) = (\u03b1\u2032L\u2032Lx)2, (45) (\u03b1 \u2297 x)\u2032(L \u2297 L)\u2032vec(In)vec\u2032(In)(L \u2297 L)(\u03b1 \u2297 x) = (\u03b1\u2032L\u2032Lx)2 (46)\nand\n(\u03b1 \u2297 \u03b1)\u2032Ip2(x \u2297 x) = (\u03b1\u2032x)2, (\u03b1 \u2297 \u03b1)\u2032Kp,p(x \u2297 x) = (\u03b1\u2032x)2, (\u03b1 \u2297 \u03b1)\u2032vec(Ip)vec\u2032(Ip)(x \u2297 x) = (\u03b1\u2032\u03b1)(x\u2032x), (\u03b1 \u2297 \u03b1)\u2032(L \u2297 L)\u2032In2(L \u2297 L)(x \u2297 x) = (\u03b1\u2032L\u2032Lx)2, (\u03b1 \u2297 \u03b1)\u2032(L \u2297 L)\u2032Kn,n(L \u2297 L)(x \u2297 x) = (\u03b1\u2032L\u2032Lx)2, (\u03b1 \u2297 \u03b1)\u2032(L \u2297 L)\u2032vec(In)vec\u2032(In)(L \u2297 L)(x \u2297 x) = (\u03b1\u2032L\u2032L\u03b1)(x\u2032L\u2032Lx).\nThen, from equation (40) we can obtain the following two expressions: (\u03b1 \u2297 x)\u2032 { n(Ip2 + Kp,p) + n2vec(Ip)vec\u2032(Ip) } (\u03b1 \u2297 x)\n= c(n, p)\u22121(\u03b1 \u2297 x)\u2032 [\u222b (L \u2297 L)\u2032 { p(In2 + Kn,n) + p2vec(In)vec\u2032(In) }\n\u00d7 (L \u2297 L)g(L)dL ]\n(\u03b1 \u2297 x), n(\u03b1\u2032\u03b1)(x\u2032x) + (n + n2)(\u03b1\u2032x)2\n= c(n, p)\u22121 \u222b { p(\u03b1\u2032L\u2032L\u03b1)(x\u2032L\u2032Lx) + (p + p2)(\u03b1\u2032L\u2032Lx)2 } g(L)dL, (47)\nand\n(\u03b1 \u2297 \u03b1)\u2032 { n(Ip2 + Kp,p) + n2vec(Ip)vec\u2032(Ip) } (x \u2297 x)\n= c(n, p)\u22121(\u03b1 \u2297 \u03b1)\u2032 [\u222b (L \u2297 L)\u2032 { p(In2 + Kn,n) + p2vec(In)vec\u2032(In) }\n\u00d7 (L \u2297 L)g(L)dL ] (x \u2297 x),\n2n(\u03b1\u2032x)2 + n2(\u03b1\u2032\u03b1)(x\u2032x) = c(n, p)\u22121 \u222b { p2(\u03b1\u2032L\u2032L\u03b1)(x\u2032L\u2032Lx) + 2p(\u03b1\u2032L\u2032Lx)2 } g(L)dL. (48)\nFrom equation (47) we can then derive\u222b (\u03b1\u2032L\u2032L\u03b1)(x\u2032L\u2032Lx)g(L)dL = c(n, p)n\np\n[ (\u03b1\u2032\u03b1)(x\u2032x) + (n + 1)(\u03b1\u2032x)2 ]\n\u2212(1 + p) \u222b (\u03b1\u2032L\u2032Lx)2g(L)dL.\nInserting this expression into equation (48) yields\n\u222b (\u03b1\u2032L\u2032Lx)2g(L)dL = n\np (p(n + 1) \u2212 2)(\u03b1\u2032x)2 + (p \u2212 n)(\u03b1\u2032\u03b1)(x\u2032x) c(n, p)\u22121(p(p + 1) \u2212 2) ,\nand then we finally obtain \u222b (\u03b1\u2032L\u2032L\u03b1)(x\u2032L\u2032Lx)g(L)dL = n\np (\u03b1\u2032\u03b1)(x\u2032x) + (n + 1)(\u03b1\u2032x)2 c(n, p)\u22121\n\u2212(p+1) n p (p(n+1)\u22122)(\u03b1\u2032x)2+(p\u2212n)(\u03b1\u2032\u03b1)(x\u2032x) c(n, p)\u22121(p(p + 1) \u2212 2))\n= c(n, p)n p\n( 1 \u2212 (p + 1)(p \u2212 n) p(p + 1) \u2212 2 ) (\u03b1\u2032\u03b1)(x\u2032x)\n+c(n, p)n p\n( 1 + n \u2212 (p + 1)(p(n + 1) \u2212 2) p(p + 1) \u2212 2 )\n\u00d7(\u03b1\u2032x)2, completing the proof.\nLemma A4. Let nS \u223c Wp(n, ), p > n + 3 and > 0. Then, for all \u03b1, x \u2208 Rp, (i) E[(\u03b1\u2032S+x)2] \u2264 (2c1 + c2)(\u03bb1( \u22121))4 [ k1(\u03b1 \u2032 x)2 + k2(\u03b1\u2032 \u03b1)(x\u2032 x) ] ,\n(ii) E[(\u03b1\u2032S+x)2] \u2264 (\u03bb1( \u22121))4(2c1 + c2)(\u03b1\u2032\u03b1)(x\u2032x). Proof. First, let Y\u2032 \u22121/2 = TL, where LL\u2032 = In, L is an n \u00d7 p matrix and T is a lower triangular n\u00d7n matrix with positive elements. Further, note that in accordance with page 131 in [28], for p > n + 3, we have that\nE[vec(S+)vec\u2032(S+)] = c(n, p)\u22121 \u222b\n(c1(Ip2 + Kp,p)(P \u2297 P) +c2vec(P)vec\u2032(P))g(L)dL,\nwhere\nP = 1/2L\u2032(L L\u2032)\u22121(L L\u2032)\u22121L 1/2.\nThen, with equalities similar to (41)\u2013(46), (\u03b1\u2297x)\u2032 E[vec(S+)vec\u2032(S+)](\u03b1\u2297x) = c(n, p)\u22121(\u03b1\u2297x)\u2032 \u222b\n(c1(Ip2 + Kp,p)(P\u2297P), +c2vec(P)vec\u2032(P))g(L)dL(\u03b1 \u2297 x),\nE[(\u03b1\u2032S+x)2] = c(n, p)\u22121 [ (c1 + c2) \u222b (x\u2032P\u03b1)2g(L)dL\n+ c1 \u222b (x\u2032Px)(\u03b1\u2032P\u03b1)g(L)dL ] . (49)\nNow, by Lemma A5, we have that (x\u2032Px)(\u03b1\u2032P\u03b1) \u2265 (x\u2032P\u03b1)2. Further, combining this inequality with (49) and Lemma 2.4 (i) in [28], we have\nE[(\u03b1\u2032S+x)2] = c(n, p)\u22121 [ (c1 + c2) \u222b (x\u2032P\u03b1)2g(L)dL\n+ c1 \u222b (x\u2032Px)(\u03b1\u2032P\u03b1)g(L)dL ]\n\u2264 c(n, p)\u22121(2c1 + c2) \u222b (x\u2032Px)(\u03b1\u2032P\u03b1)g(L)dL\n\u2264 c(n, p)\u22121(2c1 + c2)(\u03bb1( \u22121))4 \u00d7 \u222b (\u03b1\u2032 1/2L\u2032L 1/2\u03b1)(x\u2032 1/2L\u2032L 1/2x)g(L)dL = (2c1 + c2)(\u03bb1( \u22121))4 [ k1(\u03b1 \u2032 x)2 + k2(\u03b1\u2032 \u03b1)(x\u2032 x) ] ,\nwhere Lemma A3 (i) has been applied in the last equality. On the other hand, if we instead apply the inequality in Lemma 2.4 (ii) of [28], we obtain\nE[(\u03b1\u2032S+x)2] \u2264 c(n, p)\u22121(\u03bb1( \u22121))4 [ (2c1 + c2)(\u03b1\u2032\u03b1)(x\u2032x) ] \u222b g(L)dL\n= (\u03bb1( \u22121))4 [ (2c1 + c2)(\u03b1\u2032\u03b1)(x\u2032x) ] where Lemma 3.1 (i) in [28] gives the equality and concludes the proof.\nLemma A5. Let A be a p \u00d7 p symmetric positive definite matrix. Then for any c, d \u2208 Rp,\n(c\u2032Ac)(d\u2032Ad) \u2265 (c\u2032Ad)2. Proof. Let A = QRQ\u2032 denote the eigenvalue decomposition of A, such that Q is orthogonal and R is a diagonal matrix with positive elements. Make the substitutions\nf = R1/2Q\u2032c, g = R1/2Q\u2032d,\nso that the inequality (c\u2032Ac)(d\u2032Ad) \u2265 (c\u2032Ad)2 can be written as (f\u2032f)(g\u2032g) \u2265 (f\u2032g)2. (50)\nFurther, since (f\u2032g) = \u2016f\u2016\u2016g\u2016cos(\u03b8), where \u2016\u00b7\u2016 denotes the Euclidean norm and \u03b8 is the angle between the vectors f and g, the inequality (50) becomes\n\u2016f\u20162\u2016g\u20162\u2265 \u2016f\u20162\u2016g\u20162cos(\u03b8)2, which holds since cos(\u03b8)2 \u2264 1. The lemma is proved."
        },
        {
            "heading": "Acknowledgement",
            "text": "We would like to thank Prof. Yuliya Mishura, the Associate Editor and the two anonymous referees for helping to improve the paper. We are also grateful to Andrii Dmytryshyn and M\u00e5rten Gulliksson for helpful remarks on matrix inequalities.\nFunding\nStepan Mazur acknowledges financial support from the internal research grants at \u00d6rebro University and from the project \u201cModels for macro and financial economics after the financial crisis\u201d (Dnr: P18-0201) funded by Jan Wallander and Tom Hedelius Foundation."
        }
    ],
    "title": "On the mean and variance of the estimated tangency portfolio weights for small samples",
    "year": 2022
}