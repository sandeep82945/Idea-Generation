{
    "abstractText": "Recent advances in sensor technologies, in particular video-based human detection, object tracking and pose estimation, have opened new possibilities for the automatic or semi-automatic per-frame annotation of sport videos. In the case of racket sports such as tennis and padel, state-ofthe-art deep learning methods allow the robust detection and tracking of the players from a single video, which can be combined with ball tracking and shot recognition techniques to obtain a precise description of the play state at every frame. These data, which might include the court-space position of the players, their speeds, accelerations, shots and ball trajectories, can be exported in tabular format for further analysis. Unfortunately, the limitations of traditional table-based methods for analyzing such sport data are twofold. On the one hand, these methods cannot represent complex spatio-temporal queries in a compact, readable way, usable by sport analysts. On the other hand, traditional data visualization tools often fail to convey all the information available in the video (such as the precise body motion before, during and after the execution of a shot) and resulting plots only show a small portion of the available data. In this paper we address these two limitations by focusing on the analysis of video-based tracking data of padel matches. In particular, we propose a domain-specific query language to facilitate coaches and sport analysts to write queries in a very compact form. Additionally, we enrich the data visualization plots by linking each data item to a specific segment of the video so that analysts have full access to all the details related to the query. We demonstrate the flexibility of our system by collecting and converting into readable queries multiple tips and hypotheses on padel strategies extracted from the literature.",
    "authors": [
        {
            "affiliations": [],
            "name": "Mohammadreza Javadiha"
        },
        {
            "affiliations": [],
            "name": "Carlos Andujar"
        },
        {
            "affiliations": [],
            "name": "Enrique Lacasa"
        }
    ],
    "id": "SP:50ed769c268c433ef07130714c837e023386be3c",
    "references": [
        {
            "authors": [
                "J.I. Priego",
                "J.O. Melis",
                "S.L. Belloch",
                "P.P. Soriano",
                "J.C.G. Garc\u00eda",
                "M.S. Almenara"
            ],
            "title": "Padel: A Quantitative study of the shots and movements in the high-performance",
            "venue": "J. Hum. Sport Exerc",
            "year": 2013
        },
        {
            "authors": [
                "A. Escudero-Tena",
                "B.J. S\u00e1nchez-Alcaraz",
                "J. Garc\u00eda-Rubio",
                "S.J. Ib\u00e1\u00f1ez"
            ],
            "title": "Analysis of Game Performance Indicators during 2015\u20132019 World Padel Tour Seasons and Their Influence on Match Outcome",
            "venue": "Int. J. Environ. Res. Public Health",
            "year": 2021
        },
        {
            "authors": [
                "A. Demeco",
                "A. de Sire",
                "N. Marotta",
                "R. Span\u00f2",
                "L. Lippi",
                "A. Palumbo",
                "T. Iona",
                "V. Gramigna",
                "S. Palermi",
                "M Leigheb"
            ],
            "title": "Match analysis, physical training, risk of injury and rehabilitation in padel: Overview of the literature",
            "venue": "Int. J. Environ. Res. Public Health 2022,",
            "year": 2022
        },
        {
            "authors": [
                "C.B. Santiago",
                "A. Sousa",
                "M.L. Estriga",
                "L.P. Reis",
                "M. Lames"
            ],
            "title": "Survey on team tracking techniques applied to sports",
            "venue": "In Proceedings of the 2010 International Conference on Autonomous and Intelligent Systems,",
            "year": 2010
        },
        {
            "authors": [
                "H.C. Shih"
            ],
            "title": "A survey of content-aware video analysis for sports",
            "venue": "IEEE Trans. Circuits Syst. Video Technol",
            "year": 2017
        },
        {
            "authors": [
                "R. Mukai",
                "T. Araki",
                "T. Asano"
            ],
            "title": "Quantitative Evaluation of Tennis Plays by Computer Vision",
            "venue": "IEEJ Trans. Electron. Inf. Syst",
            "year": 2013
        },
        {
            "authors": [
                "J.P.R. Lara",
                "C.L.R. Vieira",
                "M.S. Misuta",
                "F.A. Moura",
                "R.M.L. de Barros"
            ],
            "title": "Validation of a video-based system for automatic tracking of tennis players",
            "venue": "Int. J. Perform. Anal. Sport 2018,",
            "year": 2018
        },
        {
            "authors": [
                "G. Pingali",
                "A. Opalach",
                "Y. Jean"
            ],
            "title": "Ball tracking and virtual replays for innovative tennis broadcasts",
            "venue": "In Proceedings of the 15th International Conference on Pattern Recognition. ICPR-2000,",
            "year": 2000
        },
        {
            "authors": [
                "J. Mao"
            ],
            "title": "Tracking a Tennis Ball Using Image Processing Techniques",
            "venue": "Ph.D. Thesis,",
            "year": 2006
        },
        {
            "authors": [
                "T. Qazi",
                "P. Mukherjee",
                "S. Srivastava",
                "B. Lall",
                "N.R. Chauhan"
            ],
            "title": "Automated ball tracking in tennis videos",
            "venue": "In Proceedings of the 2015 Third International Conference on Image Information Processing (ICIIP), Waknaghat, India,",
            "year": 2015
        },
        {
            "authors": [
                "P.R. Kamble",
                "A.G. Keskar",
                "K.M. Bhurchandi"
            ],
            "title": "Ball tracking in sports: A survey",
            "venue": "Artif. Intell. Rev",
            "year": 2019
        },
        {
            "authors": [
                "Z. Zivkovic",
                "F. van der Heijden",
                "M. Petkovic",
                "W. Jonker"
            ],
            "title": "Image segmentation and feature extraction for recognizing strokes in tennis game videos",
            "venue": "In Proceedings of the ASCI, Heijen, The Netherlands,",
            "year": 2001
        },
        {
            "authors": [
                "R. Dahyot",
                "A. Kokaram",
                "N. Rea",
                "H. Denman"
            ],
            "title": "Joint audio visual retrieval for tennis broadcasts",
            "venue": "In Proceedings of the 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP\u201903), Hong Kong, China,",
            "year": 2003
        },
        {
            "authors": [
                "F. Yan",
                "W. Christmas",
                "J. Kittler"
            ],
            "title": "A tennis ball tracking algorithm for automatic annotation of tennis match",
            "venue": "In Proceedings of the British Machine Vision Conference, Oxford, UK,",
            "year": 2005
        },
        {
            "authors": [
                "J. Ram\u00f3n-Llin",
                "J. Guzm\u00e1n",
                "R. Mart\u00ednez-Gallego",
                "D. Mu\u00f1oz",
                "A. S\u00e1nchez-Pay",
                "B.J. S\u00e1nchez-Alcaraz"
            ],
            "title": "Stroke Analysis in Padel According to Match Outcome and Game Side on Court",
            "venue": "Int. J. Environ. Res. Public Health 2020,",
            "year": 2023
        },
        {
            "authors": [
                "J.R.L. Mas",
                "S.L. Belloch",
                "J. Guzm\u00e1n",
                "G. Vuckovic",
                "D. Mu\u00f1oz",
                "B.J.S.A. Mart\u00ednez"
            ],
            "title": "An\u00e1lisis de la distancia recorrida en p\u00e1del en funci\u00f3n de los diferentes roles estrat\u00e9gicos y el nivel de juego de los jugadores (Analysis of distance covered in padel based on level of play and number of points per match)",
            "venue": "Accio\u0301n Mot. 2020,",
            "year": 2020
        },
        {
            "authors": [
                "G. Vu\u010dkovi\u0107",
                "J. Per\u0161",
                "N. James",
                "M. Hughes"
            ],
            "title": "Measurement error associated with the SAGIT/Squash computer tracking software",
            "venue": "Eur. J. Sport Sci",
            "year": 2010
        },
        {
            "authors": [
                "J. Ram\u00f3n-Llin",
                "J.F. Guzm\u00e1n",
                "S. Llana",
                "R. Mart\u00ednez-Gallego",
                "N. James",
                "G. Vu\u010dkovi\u0107"
            ],
            "title": "The Effect of the Return of Serve on the Server Pair\u2019s Movement Parameters and Rally Outcome in Padel Using Cluster Analysis",
            "venue": "Front. Psychol",
            "year": 2019
        },
        {
            "authors": [
                "M. Javadiha",
                "C. Andujar",
                "E. Lacasa",
                "A. Ric",
                "A. Susin"
            ],
            "title": "Estimating Player Positions from Padel High-Angle Videos: Accuracy Comparison of Recent Computer Vision Methods",
            "venue": "Sensors 2021,",
            "year": 2021
        },
        {
            "authors": [
                "K. Chen",
                "J. Wang",
                "J. Pang",
                "Y. Cao",
                "Y. Xiong",
                "X. Li",
                "S. Sun",
                "W. Feng",
                "Z. Liu",
                "J Xu"
            ],
            "title": "MMDetection: Open MMLab Detection",
            "venue": "Toolbox and Benchmark",
            "year": 1906
        },
        {
            "authors": [
                "B. Xiao",
                "H. Wu",
                "Y. Wei"
            ],
            "title": "Simple baselines for human pose estimation and tracking",
            "venue": "In Proceedings of the European Conference on Computer Vision (ECCV), Munich, Germany,",
            "year": 2018
        },
        {
            "authors": [
                "S. Ren",
                "K. He",
                "R. Girshick",
                "J. Sun"
            ],
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 2017
        },
        {
            "authors": [
                "Z. Cai",
                "N. Vasconcelos"
            ],
            "title": "Cascade R-CNN: High Quality Object Detection and Instance Segmentation",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 2019
        },
        {
            "authors": [
                "Y. Wu",
                "A. Kirillov",
                "F. Massa",
                "W.Y. Lo",
                "R. Girshick"
            ],
            "title": "Detectron2. 2019. Available online: https://github.com/facebookresearch/ detectron2 (accessed on 1 November 2021)",
            "year": 2021
        },
        {
            "authors": [
                "K. Chen",
                "J. Pang",
                "J. Wang",
                "Y. Xiong",
                "X. Li",
                "S. Sun",
                "W. Feng",
                "Z. Liu",
                "J. Shi",
                "W Ouyang"
            ],
            "title": "Hybrid task cascade for instance segmentation",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "M. Sandler",
                "A. Howard",
                "M. Zhu",
                "A. Zhmoginov",
                "L.C. Chen"
            ],
            "title": "Mobilenetv2: Inverted residuals and linear bottlenecks",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA,",
            "year": 2018
        },
        {
            "authors": [
                "A. Newell",
                "K. Yang",
                "J. Deng"
            ],
            "title": "Stacked hourglass networks for human pose estimation",
            "venue": "In Proceedings of the European Conference on Computer Vision, Amsterdam, The Netherlands,",
            "year": 2016
        },
        {
            "authors": [
                "J. Huang",
                "Z. Zhu",
                "F. Guo",
                "G. Huang"
            ],
            "title": "The Devil Is in the Details: Delving Into Unbiased Data Processing for Human Pose Estimation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2020
        },
        {
            "authors": [
                "F. Zhang",
                "X. Zhu",
                "H. Dai",
                "M. Ye",
                "C. Zhu"
            ],
            "title": "Distribution-aware coordinate representation for human pose estimation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "K. Sun",
                "B. Xiao",
                "D. Liu",
                "J. Wang"
            ],
            "title": "Deep high-resolution representation learning for human pose estimation",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA,",
            "year": 2019
        },
        {
            "authors": [
                "B. Cheng",
                "B. Xiao",
                "J. Wang",
                "H. Shi",
                "T.S. Huang",
                "L. Zhang"
            ],
            "title": "HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human Pose Estimation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "N. Wojke",
                "A. Bewley",
                "D. Paulus"
            ],
            "title": "Simple online and realtime tracking with a deep association metric",
            "venue": "In Proceedings of the 2017 IEEE International Conference on Image Processing (ICIP), Beijing, China,",
            "year": 2017
        },
        {
            "authors": [
                "D. Zhang",
                "G. Guo",
                "D. Huang",
                "J. Han"
            ],
            "title": "PoseFlow: A Deep Motion Representati\u2013on for Understanding Human Behaviors in Videos",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA,",
            "year": 2018
        },
        {
            "authors": [
                "P. Bergmann",
                "T. Meinhardt",
                "L. Leal-Taixe"
            ],
            "title": "Tracking without bells and whistles",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, Republic of Korea,",
            "year": 2019
        },
        {
            "authors": [
                "A. Soto-Fern\u00e1ndez",
                "O. Camerino",
                "X. Iglesias",
                "M.T. Anguera",
                "M. Casta\u00f1er"
            ],
            "title": "LINCE PLUS software for systematic observational studies in sports and health",
            "venue": "Behav. Res. Methods",
            "year": 2022
        },
        {
            "authors": [
                "P. Mishra",
                "M.H. Eich"
            ],
            "title": "Join processing in relational databases",
            "venue": "ACM Comput. Surv",
            "year": 1992
        },
        {
            "authors": [
                "I. Fister",
                "M. Mernik",
                "J. Brest"
            ],
            "title": "Design and implementation of domain-specific language easytime",
            "venue": "Comput. Lang. Syst. Struct",
            "year": 2011
        },
        {
            "authors": [
                "A. Van Deursen",
                "P. Klint"
            ],
            "title": "Domain-specific language design requires feature descriptions",
            "venue": "J. Comput. Inf. Technol",
            "year": 2002
        },
        {
            "authors": [
                "S. Xie",
                "R. Girshick",
                "P. Doll\u00e1r",
                "Z. Tu",
                "K. He"
            ],
            "title": "Aggregated residual transformations for deep neural networks",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2017
        },
        {
            "authors": [
                "J.J. Remohi-Ruiz"
            ],
            "title": "P\u00e1del: Lo Esencial. Nivel Iniciaci\u00f3n y Medio; NPQ Editores: Valencia, Spain, 2019",
            "venue": "(In Spanish) Sensors 2023,",
            "year": 2023
        },
        {
            "authors": [
                "\u00d3. Mellado-Arbelo",
                "E.B. Vidal",
                "M.V. Us\u00f3n"
            ],
            "title": "An\u00e1lisis de las acciones de juego en p\u00e1del masculino profesional (Analysis of game actions in professional male padel)",
            "venue": "Cult. Cienc. Deporte 2019,",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "Citation: Javadiha, M.; Andujar, C.;\nLacasa, E. A Query Language for\nExploratory Analysis of Video-Based\nTracking Data in Padel Matches.\nSensors 2023, 23, 441. https://\ndoi.org/10.3390/s23010441\nAcademic Editor: Basilio Pueo\nReceived: 2 December 2022\nRevised: 21 December 2022\nAccepted: 27 December 2022\nPublished: 31 December 2022\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: sports science; racket sports; video-based analysis; player tracking; sport analytics; data analysis; data visualization"
        },
        {
            "heading": "1. Introduction",
            "text": ""
        },
        {
            "heading": "1.1. Padel Essential Characteristics",
            "text": "Padel is a modern racket sport that is becoming increasingly popular worldwide [1\u20133]. Although padel shares some features with squash and tennis, it also has important distinctive characteristics [3,4]. As in tennis, the court (20 \u00d7 10 m) is divided by a central net, but one of the most important differences between padel and tennis is that the padel court is delimited by walls (glass and metal mesh) except for two openings at the outer side of the net (Figure 1). Players are allowed to return the ball after it bounces on the walls, which decreases the technical ability to begin practicing it, and results in a varied range of shot types [5]. Furthermore, the serve in padel requires the player to bounce the ball and hit it below the hip. Unlike tennis, padel is essentially a doubles game, and thus partners need to collaborate to return the ball and to disturb the opponents to win the point. At the same time, padel is an open sport that requires constant decision-making, and the technical-tactical behavior of the\nSensors 2023, 23, 441. https://doi.org/10.3390/s23010441 https://www.mdpi.com/journal/sensors\nplayer has an enormous and endless margin for evolution. This explains why the analysis of padel matches is so attractive and justifies the need of tools allowing researchers and coaches to access the data to understand and study them."
        },
        {
            "heading": "1.2. Video-Based Tracking in Sport Science",
            "text": "In the last few years, we have witnessed a significant development of deep learning techniques, which currently offer unprecedented results in video-based object detection, recognition, and tracking. Although the interest in player tracking [6] and video analysis for sports [7] is not new, convolutional neural networks have greatly improved the accuracy of computer vision tasks. These advances have opened new opportunities for video-based performance, tactical and biomechanical analyses in sports. In this paper we focus on video-based spatio-temporal data in padel. The use of computer vision techniques in racket sports (such as tennis) has been studied extensively for tasks such as player tracking [8,9], ball tracking [10\u201313], shot recognition [14], content-based retrieval [15], virtual replays [10], and automatic annotation [16]. Concerning the positional analysis of padel players from a single video, besides direct observation [17], different approaches perform video analysis from zenithal [18,19] or nearly zenithal cameras [20]. For the de-facto camera standard in padel matches, state-of-the-art techniques provide per-frame court-space player positions [21], despite distinctive features of padel such as enclosing glass walls, inter-player occlusions, and occlusions by the mesh panels and structural elements. Player positions can be obtained in multiple ways. Detection algorithms can recognize and locate instances of multiple persons in an image, which are highlighted through a collection of enclosing rectangles [22\u201326]. Image segmentation algorithms (e.g., [25,27,28]) label each pixel of the image with the ID of the predicted class (e.g., person/background). Finally, pose estimation methods estimate the location of keypoints (e.g., head, shoulders, hip, feet) of detected people. Current pose estimation methods can be classified into top-down and bottom-up methods. Top-down methods (e.g., [23,29\u201331]) first detect person instances, and then their individual joints, whereas bottom-up methods (e.g., [32,33]) detect first all keypoints in the image, and then group keypoints into person instances. Although many pose estimation methods can operate on still images, when processing videos the best accuracy is achieved by combining them with tracking methods. Stateof-the-art tracking methods such as DeepSORT [34], PoseFlow [35] and Tracktor++ [36] have been shown to perform very well on sports data. For a recent comparison of 3D pose estimation and tracking in sports videos, we refer the reader to [37]."
        },
        {
            "heading": "1.3. Structuring Tracking Data",
            "text": "The deep learning advances discussed above greatly automate the task of generating per-frame annotations of the matches, which can include essential data about the players (positions, poses), the ball (position, bounces), and the play itself (shots, winning points, scores). All these data can be extracted automatically or semi-automatically from a single video of the match, and then put in tabular form for its posterior analysis. Tables 1\u20133 show\nexamples of how raw video-based data on points, shots, and frames can be structured into tables. The video-based tracking nature of the data is reflected by the fact that sometimes teams and players are identified by their position on the video (e.g., top left or TL player) rather than by name.\nUnfortunately, the advances in getting player/ball tracking data from sports videos are not on par with the development of interactive data analysis and exploration tools enabling non-IT professionals to perform complex queries on such datasets. The focus of this paper though is not on getting the data but rather on providing a high-level language to facilitate their analysis. We can apply traditional data analysis approaches to analyze the data, but these approaches do not allow non-experts to retrieve or analyze complex spatiotemporal relationships in a compact, readable way. In the context of video-based padel data, we have identified two major limitations in current data analysis approaches, which are discussed below."
        },
        {
            "heading": "1.4. Retrieving Data about Specific In-Game Situations from Tabular Data",
            "text": "Sports analysts, coaches, and professional players often make strategy recommendations (player positioning, synchronized actions, best technical actions for a given scenario) that might or might not be sufficiently supported by empirical evidence, or that might apply only to certain circumstances (e.g., they may apply to professional players but not to amateurs). Some samples of typical recommendations for padel are:\nE1 \u201cPlayers should try to win the net zone as much as they can; it is easier to score a point from the net zone than from the backcourt zone\u201d. E2 \u201cAn effective way to win the net zone is to play a lob\u201d. E3 \u201cWhen a player is about to serve, his/her partner should be waiting in the net zone,\nat about 2 m from the net\u201d.\nThe availability of tracking data from padel matches opens great opportunities to provide empirical support to such recommendations, to refute them, to quantify their impact, or to analyze under which circumstances they apply (men\u2019s matches vs. women\u2019s matches, professional vs. amateur, adult vs. child players, right-handed vs. left-handed). Similarly, coaches and sports analysts might be interested in comparing the decision-making processes of a player with those of elite players. Following the example sentences above, there are many options to exploit the data. For E1, we could estimate the conditional probabilities P(winning the point\n\u2223\u2223 net zone) and P(winning the point\n\u2223\u2223 backcourt zone) by computing the relative frequencies of winning points for the two conditions, from a sufficiently large and representative set of matches. If matches are conveniently labeled, we could also compute and compare these probabilities for different match categories (e.g., indoor vs. outdoor).\nRegarding E2, we could follow a similar approach and estimate P(winning the net \u2223\u2223 lob),\nthat is, the probability that a team wins the net after playing a lob. If large datasets on elite players are available, we could also measure the relative frequency of lob shots compared to other types of shots, and assume that elite players take the best technical actions most of the time. Concerning E3, we could plot the court-space position of server partners, and analyze e.g., whether the distance dn to the network and the distance dw to the lateral wall are normally distributed. If so, we could compute a simple Gaussian model for these variables, e.g., dn \u223c N \u00b5n, \u03c32n), where the parameters \u00b5n, \u03c32n can be estimated from the data. These types of analyses are certainly possible using tracking data in tabular form. However, to the best of our knowledge, no specific languages/tools have been reported to transform the raw tabular data from a collection of matches into the data that are relevant to the problem at hand. In other words, we are not aware of any high-level domain-specific language facilitating the filtering and retrieval of such padel data. The same lack of tools also applies to tennis and other racket sports. As a consequence, such analyses must be based on conventional tools, for example through manual counting, spreadsheets (filters, transformations, formulas), or computer programs operating on the tabular data [38]. Referring to the previous examples E1\u2013E3, let us consider what queries could retrieve data to support, refute or qualify them. The following queries (in plain English form) could be useful for this task:\nQ1 Retrieve all points, distinguishing by the winning team and the zone of the hitter player. Q2 Retrieve all lob shots with an additional column indicating whether the players could win the net zone or not. Q3 Retrieve all frames immediately after a serve, along with the court-space position of the server\u2019s partner.\nAlthough all these queries can be implemented, for example, in a spreadsheet, depending on the query complexity these tasks might require a considerable effort. Let us suppose that, starting from a table similar to Table 3, we wish to retrieve the position of the server\u2019s partner in the 2 s immediately after each serve. We start with a spreadsheet example, as this is a tool commonly used by sports analysts. First, we should identify, for each frame, which of the four players is the server\u2019s partner. Since this information is missing on the Frames table, we could add a column \u201cServer partner\u201d that, given a frame number, retrieves the game it belongs to, and the server\u2019s partner for that game. A vertical lookup function (vlookup in most spreadsheets) could help with this task. Then, we should remove all frames outside the 2-s window after a serve. Again, this would require adding\nmore columns (with non-trivial lookup functions) to compute the time offset between each frame and the serve. Additional functions will be required to select the server\u2019s partner position out of the four player. Finally, we could sort the data by time offset, remove the rows with an offset above the 2-s threshold, select the (new) column with the network distance, and plot/analyze the results. The spreadsheet example above already shows the different drawbacks of this approach. First, it requires non-trivial transformations of the data: adding new columns, using lookup functions (just computing column offsets for the result is error prone), sorting the data (or setting up filters/dynamic tables). Second, this approach lacks scalability. When new data come in, many of the steps above have to be repeated for each match. Third, it lacks flexibility: if our definition of \u201cnet zone\u201d changes (e.g., it is moved 50 cm away), this would require extensive changes in the spreadsheets. Finally, it lacks readability, as the computation and filter formulas are spread over the cells. It can be argued that, as a preprocess, we could enrich the tabular data to simplify these kinds of analyses. As we shall see (Section 5.3), padel concepts are so diverse that this approach would only benefit the simplest queries. Notice that the query example above (based on E3 and Q3) is relatively simple. Queries involving sequences of events (e.g., drive-lob-volley) further hinder the required transformations. High-level programming languages provide convenient data structures and methods to analyze tabular data. Python has a relatively smooth learning curve compared to other programming languages, and it is extensively used for data analysis. Pandas is a wellknown Python package that provides a DataFrame class, which is essentially a convenient representation of tabular data. Similar data structures and methods are available in other languages (such as R, Octave and MatLab). These languages provide a convenient way to transform and query tabular data, but the resulting code is often too complex and unreadable to be usable by coaches and sports professionals. Some queries do admit a very simple expression. For example, retrieving all serves in Python using pandas can be as simple as: serves = shots[shots['Shot type']=='Serve'], where shots is the input DataFrame (Table 2), and serves is the output DataFrame. Unfortunately, other types of queries are harder to write (Section 8.4). Many queries require combining data from multiple tables, which at the end require using either lookup functions or, in the case of DataFrames, different types of joins [39] (inner joins, outer joins, left joins, right joins). Join operators are a concept from database theory and relational algebra that requires data-retrieval skills. However, even mastering join operators, queries involving sequences of events (e.g., \u201clobs followed by a defensive smash and then a volley in the net zone\u201d) require additional operators that are usually too complex for people with no background in relational algebra."
        },
        {
            "heading": "1.5. Extracting Essential Information without Missing Relevant Details",
            "text": "A video of a padel match contains valuable information that can be hardly captured in tabular formats, such as the exact poses throughout the execution of a technical action, verbal communication between players, and non-verbal communication (e.g., gestures when rivals try to avoid playing to a particular player). Although sometimes we wish to analyze the data through abstraction, an essential part of the exploratory analysis is to interactively examine the details of specific situations. In traditional motion data analysis, the tabular data are often explored independently from its video source, with some notable exceptions such as [38]. This prevents sports analysts from performing a deep analysis of the data. For example, after finding that some player often loses the point after a particular technical action (e.g., an off-the-wall smash), a coach might want to retrieve all segments of the video where this situation occurs. Our solution to this problem is to provide interactive plots where, whenever possible, data items include links to the part of the video where they occur. If appropriate tools are used, this kind of plot greatly speeds-up the analysis of context information (body orientation, feet positioning, impact location and timing) that can provide valuable insights to improve the player\u2019s performance."
        },
        {
            "heading": "1.6. Contributions",
            "text": "The main contribution of this paper is the definition (and a free and open-source prototype implementation) of a domain-specific query language to define queries on video-based data from padel matches. Domain-specific languages (DSLs) are tailored to a specific application domain and thus provide important advantages over generalpurpose languages (GPLs) in such domain [40]. In particular, we propose a domain-specific language embedded in a GPL (more precisely, a Python API). Our language has greater expressive power, and ease of use, thus enabling writing queries in a simple, compact, flexible, and readable way. Furthermore, and although not the main focus of the paper, we propose a collection of interactive visualization tools to visually explore the output of such queries. A major novelty is that data items are seamlessly connected to video segments so that a precise analysis of specific technical actions is integrated into the exploratory analysis process. For evaluating the power and expressiveness of the query language, we have collected multiple statements about padel strategies (tips, comments, pieces of advice, hypotheses. . . ) from different published sources (books, papers). We discuss how to design queries to support, refute or analyze these hypotheses, and show how these queries can be written using our query language. The Supplementary Material shows a demonstration of our query system running on a Jupyter notebook."
        },
        {
            "heading": "2. Design Principles for the Query Language",
            "text": "Our ultimate goal is to develop a query language allowing sports analysts to perform exploratory analysis on video-based tracking data in the most efficient way. More precisely, we wanted the language to outperform traditional data analysis approaches in the following aspects:\nExpressiveness We wish the language to support complex queries, combining arbitrary conditions on player positions, poses, distances, shot attributes, court zones, timing, scores, sequences, and any other fact in the tabular data or that can be derived from it (such as speed, acceleration, motion paths). Compactness Queries (even complex ones) should require little space (e.g., a few lines of code). Expandability Analysts should be able to easily extend the language to incorporate their vision of fuzzy concepts. For example, different analysts might want to define court zones using different criteria and reuse these concepts in queries. When it comes to processing data, many concepts in padel (e.g., \u201cforced error\u201d, \u201cgood lob\u201d) need to be defined precisely, and the concrete definition might vary among analysts, or depend on the player profiles (professional vs. amateur). Once these concepts are defined, they should integrate seamlessly into query definitions. Easy to write We wish sports analysts to be able to write new queries, or at least be able to modify existing examples to suit their needs. Easy to read We wish sports analysts to be able to understand the queries after a brief introduction to the main concepts of the language.\nAmong all the criteria above, we prioritized expressiveness. As a consequence, we decided that the domain-specific query language had to adopt the form of an internal DSL, embedded in Python. We thus defined an API (Application Programming Interface) for the Python language. Compared to external DSLs, which require an automated code generator to transform it into programming language code, embedded DSLs fully benefit from an already existing programming language. This approach considerably lowers the entry barrier for users already knowing the GPL. It also allows IDEs (e.g., Jupyter Notebooks, frequently used for data analysis) to recognize the syntax of the DSL and thus provide full support to code completion, syntax highlighting, and error checking. Another advantage is that it simplifies the description of the grammar and its implementation, since the DSL reuses the grammar and the parser of the GPL."
        },
        {
            "heading": "3. Design of the Query Language",
            "text": ""
        },
        {
            "heading": "3.1. Domain Analysis",
            "text": "The design of a DSL starts with an analysis of the application domain to create a feature model [41]. A Feature Diagram (FD) describes graphically the main features of the domain along with its dependencies. The FD is usually represented as a tree where nodes represent domain features and arcs connecting the nodes determine the relationships between them. Close dots denote mandatory nodes, whereas open dots represent optional nodes. The following subsections discuss the FDs of our application domain.\n3.1.1. Domain Analysis of a Video-Recorded Padel Match\nThe FD of a video-recorded padel match is shown in Figure 2. The diagram shows the main features of the basic questions on padel match: who (teams, players), when (temporal play units), and how/where (position, speed, type of shot). As shown in the diagram, a padel match involves two teams composed of players that can be identified by their names. On a temporal plane, we can distinguish four scoring units in padel (as in tennis): match, set, game and point. Each of these scoring units have a winner (winning team) and results in a score update. Other smaller temporal units are the shots and the frames of the video. Although a shot is an event, we can also consider the temporal unit between one shot and the next; similarly, we will use the term point to refer to the temporal unit (often called rally) between a serve and the moment where one of the teams wins the point. Altogether, a video-recorded padel match can be broken down into these play units, as illustrated in Figure 3. As such, each play unit has a start time, an end time, and a duration.\nOn a spatial plane, computer vision and other sensing techniques allow the automatic tracking of the players\u2019 positions during a match. Therefore, the video-recorded match also contains the collection of player states, one for each frame, describing the position of the player within the court. These positions allow the computation of new parameters, such as speed, acceleration, distances to different court elements, and distance to the partner or opponent players. We can further analyze each of these concepts. For the sake of brevity, we only focus on shots, since they represent arguably the most relevant technical actions in padel. Figure 4 shows the FD of a shot in padel. A shot starts with some player (hitter) hitting the ball. The shot belongs to a specific match, set, game, and point, as shown in Figure 3. Shots have a start frame (when the player hits the ball) and an end frame (corresponding to the next shot, or end of the rally). Finally, shots have a collection of properties (such as the shot code) that, due to their complexity, will be discussed later in Section 7.\n3.1.2. Domain Analysis of Queries about Padel Matches\nThe FDs above describe the main features of a padel match from the point of view of videos annotated semi-automatically. Our language though deals with queries about these matches. Therefore queries are also an essential part of our application domain. Figure 5 shows the FD of such a query. We can distinguish two main parts: the query definition and the query execution. An important remark is that we only consider queries whose output is represented as tabular data, because most data analysis software use this representation. The research literature on padel often considers parameters from the point of view of sets, games, points, and shots. We should also add frames since videos can be annotated automatically on a per-frame basis. Therefore we consider queries returning a table whose rows belong to one of these concepts. Thus we support the query types shown in Figure 5. Besides the query type, a query definition includes a query filter, that is, a predicate that represents some condition on the chosen concept. For example, a Shot query includes a predicate that determines whether a shot satisfies the intended condition. Once a query has been defined (for example, to retrieve specific shots from a given player), the query can be executed on multiple matches. The query execution has three sub-features. The query scope is the match or collection of matches to be searched; the query attributes are the columns we wish to have in the output table, and the query result is the actual output table. The output table will contain one row for each item (e.g., shots) of the query scope that satisfies the query filter, and one column for each query attribute."
        },
        {
            "heading": "3.2. Query Language Syntax",
            "text": "The FDs reveal important concepts of the application domain and their structure. The next step is to define the DSL syntax and semantics. This can be achieved formally or informally [40]. In the latter case, the specification is given in natural language through a set of illustrative DSL examples. Since our DSL is embedded in the Python language, instead of describing its abstract syntax, we directly show the translation of our application domain concepts into components of the Python language (see Table 4) and show illustrative examples in the next sections.\nThe first block of Table 4 refers to concepts related to video-based padel matches (Figure 2). All these concepts are translated into Python classes or class properties. The second and third blocks refer to queries about matches (Figure 5). Essentially, a query definition corresponds to the definition of a Python function, and a query execution translates into a function call. We use Python decorators to simplify queries as much as possible. A decorator is a simple mechanism of the Python language for defining higher-order functions, that is, functions that take another function and extend its behavior. This mechanism is convenient because it moves a large part of the boilerplate code from the query definition to the internal implementation of the API."
        },
        {
            "heading": "4. Components of a Query",
            "text": "A query in our language requires four major components (see Figure 6), which are described below.\nQuery type The output of all our queries is a table with the retrieved data (more precisely, a QueryResult object that holds a Pandas\u2019 DataFrame). The Query type refers to the different types of queries according to the expected output (that is, the type of the rows in the output DataFrame). Table 5 shows the query types supported by our language. From now on, we will use the generic word \u201citem\u201d to collectively refer to the entities (points, shots, frames. . . ) that will form the rows of the output. Query definition The query definition is a Boolean predicate that establishes which items should be retrieved (e.g., all shots that match a specific shot type). In our language, this takes the form of a decorated Python function that takes as input an object of the intended class (e.g., a Shot object if defining a shot query) and returns a true/false value. These predicates act as filters that discard items for which the predicate evaluates to false, and\ncollect items for which the predicates evaluate to true. The output table will contain as many rows as items satisfy the predicate. Attributes This refers to the collection of attributes we wish for every item in the output table (that is, the output table will have one column for each attribute). For example, for every smash, we might be interested only in the name of the player, or also in its courtspace position, or just the distance to the net. One of the key ingredients of our language is that attributes are arbitrary Python expressions, with the only condition that they should be able to evaluate correctly from the item. For example, a shot has attributes such as hitter (the player that executed the shot), frame (the frame where the shot occurs), etc. Attributes can be simple expressions such as shot.hitter or more complex ones such as shot.next.hitter.distance_to_net < 3. Scope Once we have specified the elements above, we might want to execute the query on different collections of matches. The scope is the collection of matches that will be searched for items fulfilling the predicate.\nThe separation of the different query components allows analysts to maximize reusability. For example, the query definition in Figure 6 filters all the shots to select only volleys. Later on, we can reuse this definition with different attribute collections, depending on what data about each volley we wish to analyze. Some attributes that make sense for this query definition include hitter.last_name, hitter.position.x, hitter.position.y, and frame.frame_number, just to give a few examples."
        },
        {
            "heading": "5. Key Features of the API",
            "text": ""
        },
        {
            "heading": "5.1. Navigation through Method Chaining",
            "text": "We exploit the hierarchical and sequence relationships of the main concepts introduced in Section 3.1 to provide a natural way to navigate through related concepts. Figure 7 shows the methods that can be used to get access to related elements. Consider, for example, the classes Point and Shot. The following Python expressions illustrate the use of these methods; for each expression, we indicate the item it provides access to:\npoint.shots[i] # the i-th shot of a point shot.point # the point the shot belongs to shot.next # the next shot within the point (or None if last shot) shot.prev # the previous shot within the point (or None if serve)\nThe relationships among the other classes in Figure 7 work the same way. These operations can be chained arbitrarily to get access to the data we are interested in. This is especially useful in query definitions (since the Boolean function gets as a parameter a single object, for example, a Shot) and it is also useful for attributes:\nshot.hitter # player that executed the shot shot.prev.hitter # hitter of the previous shot shot.next.next.hitter.distance_to_net # for two shots ahead, distance to net of the hitter shot.point.winner # team that won the point the shot belongs to shot.point.game.winner # team that won the game the shot belongs to\nAlthough not shown in Figure 7 for simplicity, methods that allow traversing the hierarchy upwards can skip intermediate classes. For example, the expression\nframe.shot.point.game.set.match.gender can be written simply as frame.match.gender. Although implementation details are discussed in the Appendix A, we wish to note that the methods above are implemented as Python properties (using the @property decorator). Therefore instead of writing shot.next().next().frame() we can omit the parentheses and write shot.next.next.frame which is a bit more compact. Since query definitions require read-only access to all these objects, we consider that using properties instead of methods is safe."
        },
        {
            "heading": "5.2. Binding Players to Frames",
            "text": "When writing query definitions, we have observed that many times one needs to get attributes of a player (e.g., his/her position) at a specific moment during the game. In our API, the Player class represents personal information about the player (such as first name, last name and gender). As a consequence, if for example shot.next.next.hitter returns a Player object, his/her position will not be directly accessible. For the sake of compactness, we allow Player objects to refer to a particular frame of the video. In that case, we say the player object is bound to a specific frame. Methods returning a Player object return a temporary object that is bound to a specific frame (whenever this makes sense). For example, in a volley-drive-smash sequence, shot.next.next.hitter.position correctly gets the position of the player that plays the smash."
        },
        {
            "heading": "5.3. Tag Collections",
            "text": "Literature about padel tactics refers to many varied concepts attached to the central classes in Figure 7. For example, the following is just a small sample of concepts related to a shot: \u201cunforced error\u201d, \"from attack zone\", \"defensive shot\u201d, \u201chalf volley\u201d, \u201cdrop shot\u201d, \u201cbring (the ball) back\u201d, \u201cbackspin\u201d, \u201coverhead\u201d, \u201cat waist level\u201d, \u201cblock\u201d, \u201ccross court stroke\u201d, \u201clong shot\u201d, \u201csoft shot\u201d, and \u201cdouble wall\u201d. It is clear that including all these concepts as properties of a Shot class is not feasible nor convenient, since many of them are somehow fuzzy and can be defined in multiple ways (e.g., how much time, from the ball bounce to the shot impact, separates a half volley from other types of shot). Therefore, we decided to provide a minimalist set of properties for major classes, but let the classes be expandable so that analysts can add, at runtime, the concepts they wish. We achieve this expandability through two mechanisms, described below. First, all these classes have a tags property that represents a dynamic set of tags, where a tag is just a string that encodes some predefined (e.g., \u201cserve\u201d) or user-defined (e.g., \u201cflat serve\u201d, \u201cdouble fault\u201d) attribute. These classes provide a like method to check whether an object has some tag. For example, shot.like(\"volley\") is a shorter form of \"volley\" in shot.tags, and shot.like(\"cross-court volley\") is equivalent to \"cross-court\" in shot.tags and \"volley\" in shot.tags. We have observed that this syntax is very compact and readable when searching for specific frames, shots, or points: shot.like(\"winning smash from-defense-zone by-galvan\"). Second, we provide a simple method to define new tags, that is, a function to filter the objects that should include a user-defined tag. The syntax is nearly identical to that for query definitions (a Boolean function that gets as a parameter an item); the only difference is the function decorator, @shot_tag vs. @shot_query:\n# Define a new tag describing a volley near the net @shot_tag def attack_volley(shot):\nreturn (shot.like(\"vd\") or shot.like(\"vr\")) and shot.hitter.distance_to_net < 1.5 # Add the tag to a match attack_volley(match) # Query definitions can now use the new concept @shot_query def attack_volley_after_return_of_serve(shot):\nreturn shot.like(\"attack_volley\") and shot.prev.like(\"return\")\nIn the example above, \u201cvd\u201d and \u201cvr\u201d refer to drive volley and backhand volley, resp. [5]. The new concept can be added to a match by simply invoking the function on a match or list of matches so that queries can use the new concept. The Python function decorator deals with the necessary code to traverse the match items (in the above case, shots) to check whether the new tag has to be inserted in the tag set."
        },
        {
            "heading": "6. A Complete Example",
            "text": "Before describing the API in more detail, here we briefly discuss a complete example, including also a first analysis of the query results. Lines beginning with # are just comments.\n# Define the query @shot_query def attack_drive_volley(shot):\nreturn shot.like(\"vd\") and (shot.hitter.distance_to_net < 5) # Define the attributes attribs = [\"tags\", \"frame.frame_number\", \"hitter.position.x\", \"hitter.distance_to_net\", \"hitter.last_name\"] # Execute query on a match match = load(\"Estrella Damm Open'20 - Women's Final\") result = attack_drive_volley(match, attribs) # Analyze the results result.analyze() result.plot_positions()\nThe example is analyzing the position of the players when playing a drive volley less than 5 m away from the net. The query execution returns a QueryResult object, which provides some essential visualization methods. Figure 8 shows the output of the analyze and plot_positions methods."
        },
        {
            "heading": "7. Classes and Properties",
            "text": "Since our domain-specific language reuses the syntax of Python language, we need to describe the Python classes provided by the API. These classes provide properties and methods that can be used both in query definitions and query attributes. We first discuss classes representing temporal concepts (from Match to Frame), and then the Player class."
        },
        {
            "heading": "7.1. Match, Set, Game, Point, Shot, Frame",
            "text": "Figure 9 summarizes the main classes of the API, along with their most relevant methods and properties. For the sake of conciseness, we only discuss the main classes and a subset of their attributes. See the accompanying implementation for full details. Additionally, for some properties with long names, we show an abridged version of it.\nReferring to Figure 9, about one-half of the methods refer to the hierarchical and sequence relationships already discussed in Section 5.1. As already mentioned, these methods allow analysts to navigate through the different elements, as in shot.point.prev.winner, that given a shot, gets the team that won the preceding point. Besides these hierarchical and sequence relationships, all these classes have a tags attribute (not shown in Figure 9) that contains a set of strings encoding specific concepts about the class (Section 5.3). The presence of a tag can be checked with the like method, as in the expression shot.like(\"serve\"). All these classes have associated a time interval of the video, represented either as start_frame and end_frame properties, or just a frame_number. Sets, Games, Points, Shots also have a number with their position within their parent class. For example, for the first set of a match, set.number==1. Winning and losing teams are available for all temporal units for which this makes sense (Match, Set, Game, and Point). Points include a valid attribute to distinguish e.g., net shots."
        },
        {
            "heading": "7.2. Shot Types",
            "text": "Tags can also include non-string objects, provided that they behave as strings. This feature of Python is called Duck Typing, which is a concept related to Dynamic Typing. We fully benefit from this feature and provide a ShotType object that allows shot types to be represented by multiple equivalent strings (codes or full names, and in multiple languages). Our current prototype uses the shot classification proposed by [5]. Table 6 lists these shots, along with multiple strings that can be used to refer to them. For example, a query could use either shot.like(\"vd\") or the longer form shot.like(\"forehand volley\")."
        },
        {
            "heading": "7.3. Player",
            "text": "Figure 10 summarizes the main methods of the Player class. Since most methods are self-explanatory, here we only explain position, speed, and acceleration methods. These three methods return a 2D point (position) or a 2D vector (speed, acceleration) with (x, y) coordinates/components. Figure 10 shows the global coordinate system for the global position of the players within the court. We also provide relative distances to major court\nelements (net and walls). Notice that, for these relative distances, the reference element is taken with respect to the player. For example, in distance_to_right_wall, the right wall is defined with respect to the player; the left wall for the players of one team is the right wall for the opponents and vice versa."
        },
        {
            "heading": "8. Evaluation",
            "text": "We evaluated the expressiveness of our query language by selecting many different statements about padel from the literature, and translating them into (informal) plain English queries and then into query definitions."
        },
        {
            "heading": "8.1. Test Dataset",
            "text": "As a test dataset, we used tabular data obtained by annotating semi-automatically a public padel match: the women\u2019s final round of World Padel Tour\u2019s Estrella Damm Open 5 July 2020, Madrid Arena. The video is publicly available https://youtu.be/7s55wB9dR78 (accessed on 1 December 2022). The position of the players within the court was obtained automatically following [21], in particular combining cascade detectors [27] based on ResNeXt [42] with a HRNet [32] keypoint estimator. These methods achieved accuracy on par with those from human annotators, with more than 98% of the estimated positions within a 30 cm error tolerance with respect to ground truth, for players on the bottom half of the court. Positions are less accurate for players on the top half of the court (due to error amplification by the camera perspective) and players with both feet in the air. Frame numbers are approximate since we used the YouTube Player API Reference for Iframe Embeds https://developers.google.com/youtube/iframe_api_reference (accessed on 1 December 2022) to play the video from specific time stamps. Since this section aims to evaluate the effectiveness of the query language, rather than drawing conclusions on the player\u2019s performance, we removed about one-half of the points from the dataset before running the queries."
        },
        {
            "heading": "8.2. Test Statements",
            "text": "We list below the statements about padel strategies (mostly general observations and recommendations) we collected from padel coaches, books, papers, and websites. In Section 8.3 we will design and write queries that could be used to support, refute or analyze these.\nS1 \u201cOne generally volleys cross-court\u201d (source: [43]) S2 \u201cA very effective volley is a fast, down-the-line volley to the opponent\u2019s feet\u201d (source: [43]) S3 \u201cAn interesting aspect of women\u2019s padel is that the game speed is close to a second and a half, to be exact 1.37 s\u201d (source: [3], referring to a 2020 sample of padel matches). S4 \u201cThe serve should be a deep shot, targeted towards the glass, the T, or the receiving player\u2019s feet\u201d (source: basic padel tactics). S5 \u201cWhen a player is about to serve, his/her partner should be waiting in the net zone, at about 2 m from the net\u201d. (source: basic padel tactics). S6 \u201cThe serve is an attempt to seize the initiative for the attack, therefore the serving team tries to maintain the initiative by approaching the net\u201d. (source: [5]). S7 \u201cPlayers should try to win the net zone as much as they can; it is easier to score a point from the net zone than from the defense zone\u201d (source: basic padel tactics). S8 \u201cThe (physiological) intensity developed during the practice of padel is close to that\nexperienced in the practice of singles tennis (. . . ). The real demands are different. This is probably due to the shorter distance covered by padel players in their actions. An aspect that can be compensated by a greater number of actions compared to tennis, due to the continuity allowed by the walls\u201d. (source: [5]).\nS9 \u201cAn effective way to win the net zone is to play a lob\u201d (source: [43]). S10 \u201cThe data corroborate one of the maxims that surround this sport: first return and\nfirst volley inside, implying that no easy point should be given to the opponents\u201d (source: [5])."
        },
        {
            "heading": "8.3. Queries",
            "text": "Each of the statements above can be translated into multiple queries. We show below some plausible options, both in natural language and using our DSL.\n8.3.1. S1: \u201cOne Generally Volleys Cross-Court\u201d\nThis statement can be addressed with the following query:\nQ1 \u201cRetrieve all shots that are volleys (either forehand or backhand)\u201d.\nAccording to the shot classification we adopted (Table 6, we wish to include both forehand volleys (vd) and backhand volleys (vr). Since we foresee that many queries might use this \u201cvolley\u201d concept, we are going to define it as a shot tag:\n@shot_tag def volley(shot):\nreturn shot.one_of(\"vd,vr\")\nvolley(match) # add \"volley\" tag to shots in this match\nNow, we will retrieve all volleys with a simple query. Notice that we can now use like(\"volley\") within the query definition:\n@shot_query def volleys(shot):\nreturn shot.like(\"volley\")\nWe will estimate the volley direction by computing the vector from the player\u2019s position to the receiver player\u2019s position, so we need to include as attributes the position of shot.hitter and shot.next.hitter players. We will also add additional attributes for plotting the data (such as player\u2019s last name, and shot direction encoded as an angle):\nvolley(match) attribs = [\"frame.frame_number\", \"hitter.position.x\", \"hitter.position.y\", \"hitter.last_name\", \"next.hitter.position.x\", \"next.hitter.position.y\", \"angle\", \"abs_angle\"] q = volleys(match, attribs)\nq.plot_directions(color='angle') q.plot_distribution(density='angle', extent=[-30,30], groupby='player')\nFigure 11 shows the resulting plots. For each segment, the larger dots represent the volley origin, and the smaller dots the volley destination (estimated from the position of the opponent player that returned the ball).\nNotice that the query above can be extended easily to look for specific types of volleys: for example, volleys played at a certain maximum distance from the net, after a specific type of shot, or from a specific player:\n# Volleys shot from less than 4 m from the net @shot_query\ndef volley_from_attack_zone(shot): return shot.like(\"volley\") and shot.hitter.distance_to_net < 4\n# Volleys after a drive shot from the opponent @shot_query def volley_after_drive(shot):\nreturn shot.like(\"volley\") and shot.prev.like(\"drive\")\n8.3.2. S2: \u201cEffectiveness of a Fast, Down-the-Line Volley to the Opponent\u2019S Feet\u201d\nThe translation of this statement into a query (Q2) is straightforward:\nQ2 \u201cExtract all forehand or backhand volleys whose duration is below some threshold (1 s) and that are down-the-line\u201d.\nThere are several ways for measuring a down-the-line volley; we will use the angle of the shot path, but we could use alternative criteria, such as the x position of the hitter and returning players. We will also use the \"volley\" tag introduced above. From now on we will omit the definition of the attribute list attribs if it can be easily inferred from the output plots:\n@shot_query def fast_down_the_line_volley(shot):\nreturn shot.like(\"volley\") and shot.duration < 1 and shot.abs_angle < 8\nq=fast_down_the_line_volley(match, attribs) q.plot_directions(color='angle') q.plot_directions(color='winning')\nFigure 12 shows the result for the test match.\n8.3.3. S3: \u201cThe Game Speed Is Close to a Second and a Half\u201d\nWe will analyze S3 through the following query:\nQ3 \u201cFor each shot, get its duration (the time interval between a shot and the next shot)\u201d.\nUsing our API, this can be translated as a query that retrieves all shots except the last shot in a point, because the duration is not well defined of these:\ndef all_non_last_shots(shot): return shot.next # equivalent to: shot.next is not None\nattribs = [\"hitter.position.x\", \"hitter.position.y\", \"id\", \"duration\"]\nWe can plot the distribution of the duration variable (mean = 1.25 s for the test match), as well as the position of the shots, colored by duration:\nq.plot_distribution(\"duration\") q.plot_positions(color='duration')\nFigure 13 shows the resulting plots. Most of the long shots, as expected, correspond to lobs and passing shots.\n8.3.4. S4: \u201cThe Serve Should Be a Deep Shot\u201d\nHere the query definition is quite simple:\nQ4 \u201cRetrieve all serves; for each serve, get the serving player\u2019s position and the serve direction\u201d.\nIn our API:\n@shot_query def serves(shot):\nreturn shot.like(\"serve\") and shot.next q = serves(match, attribs)\nWhere attribs list contains the necessary attributes for the analysis. We can plot, for example, serve directions, coloring them either by angle or by player (Figure 14).\nq.plot_directions(color=\"angle\") q.plot_directions(color=\"player\")\n8.3.5. S5: \u201cServing Player\u2019s Partner Should Be Waiting in the Net Zone\u201d\nThe query definition is very similar to the previous example, but now we will retrieve (as an attribute) the position of the partner:\nQ5 \u201cRetrieve all serves; for each serve, get the position of the partner of the serving player\u201d.\nUsing our API, we would use the query definition of the previous example, but we add query attributes to acquire data about the player\u2019s partner (see Figure 15 for the results).\nq = serves(match, attribs + [\"hitter.partner.last_name\", \"hitter.partner.position.x\", \"hitter.partner.position.y\"]) q.plot_positions(color='player')\n8.3.6. S6: \u201cAfter Serving, the Player Should Move Quickly to the Net\u201d\nAll the queries so far required data (e.g., the type of shot, the position of the players) at a very specific moment (the time a shot is executed). Now we wish to analyze the movement/paths of the players for some time (e.g., one second immediately after a serve). This means we will have to use a frame_query which can provide data about arbitrary segments of the video.\nQ6 \u201cRetrieve all frames immediately after a serve (e.g., for 1 s); for each frame, get the position of the serving player\u201d.\nUsing our API, we could compare the current frame number with that of the point\u2019s start frame, to filter the frames immediately after a serve (i.e., immediately after the start of the point). See Figure 15 for the results.\n@frame_query def all_frames_after_serve(frame):\nreturn (frame.time - frame.point.start_time) < 1\nq=all_frames_after_serve(match, fattribs) q.plot_player_positions()\nWe plot all four players, although of course we could filter only serving players\u2019 paths (Figure 16).\n8.3.7. S7: \u201cPlayers Should Try to Win the Net Zone as Much as They Can\u201d\nWe will analyze S7 through two queries.\nQ7a \u201cFor each point, compute the total time both players were in the net zone, for the team that wins the point, and also for the team that loses the point\u201d. Q7b \u201cFor each winning shot, retrieve the position (and distance to the net) of the player that hit that ball\u201d.\nUsing our API, Q7a can be translated as\n@frame_query def time_on_net_for_winning_team(frame):\nwinner = frame.shot.point.winner return winner and frame.distance_to_net(winner.forehand_player) < 4\nand frame.distance_to_net(winner.backhand_player) < 4\nq1=time_on_net_for_winning_team(match,[\"duration\", (\"point.id\", \"point\")]) q1.sum(\"point\") # Group by point and sum\nwhere we compute for how long both players of a team are in the net zone (here, 4 m from the net). Similarly, we can define a query for the losing team, and combine both queries into a single plot:\nq1.addColumn(\"Team\", \"Point Winner\") q2.addColumn(\"Team\", \"Point Loser\") q = concat([q1,q2], \"Time on the net\") q.plot_bar_chart(x='point', y='duration', color='Team')\nFigure 17 shows the plot we got for our test match. This shows that, for that match, the time on the net for the point winning team was higher (total time: 110.8 s) than for the point losing team (total time: 68.7 s).\nSimilarly, Q7b can be translated as follows:\n@shot_query def winning_shots(shot):\nif not shot.hitter.from_point_winning_team: return False # not from the winning team return not shot.next or not shot.next.next # just winning shots\nattribs = [\"hitter.last_name\", \"hitter.position.x\", \"hitter.position.y\", \"frame.frame_number\", (\"hitter.distance_to_net\", \"distance\")]\nq = winning_shots(match, attribs)\nWe can plot the position of the players at the moment they played the winning shot:\nq.plot_positions() q.plot_histogram(\"distance\")\nThe resulting plot is shown in Figure 18. Notice that some winning shots were executed from the defense zone; by checking these in the video we observed that in most cases, the opponent made an unforced error when returning these shots (that is, the opponents could hit the ball, but not accurately enough to keep playing the point).\n8.3.8. S8: \u201cDistance Covered by the Players\u201d\nThere are many ways to analyze the distance covered by the players. Here we show just one reasonable option:\nQ8 \u201cRetrieve all frames, together with the position of the players and the distance they traversed for each point\u201d.\nUsing our API, we could just retrieve all frames and plot the players\u2019 positions, colored by name:\n@frame_query def all_frames(frame):\nreturn True\nq=all_frames(match, fattribs) q.plot_player_positions()\nAlternatively, we can compute the traversed distance on a per-frame basis, and then group by point. The example below compares the traversed distance of two players from the same team (Figure 19):\nq1=all_frames(match, [(\"salazar.distance_from_prev_frame\", \"distance\"), ...]) q1.sum(\"point\")\nq2=all_frames(match, [(\"sanchez.distance_from_prev_frame\", \"distance\"), ...]) q2.sum(\"point\")\nq1.addColumn(\"Player\", \"Salazar\") q2.addColumn(\"Player\", \"S\u00e1nchez\") q = concat([q1,q2], \"Distance traversed\") q.plot_bar_chart(x='point', y='distance', color='Player')\n8.3.9. S9: \u201cGood Lobs\u201d\nThe idea here is to quantify the effectiveness of lobs for moving the opponents back to the defensive zone; this can be achieved either by considering the position of the players two shots after the lob, or by checking the type of the opponents\u2019 shot.\nQ9 \u201cRetrieve all lobs followed by a defensive shot\u201d.\nWe can first specify which shots are considered to be defensive (we will define a new tag for this, considering the shot types in Table 6):\n@shot_tag def defensive(shot):\nreturn shot.one_of(\"d,r,ad,ar,pld,plr,spd,spr,bpd,bpr,dpa,dpc,dpag,cp,cpld,cplr\")\nNow we can retrieve all lobs followed by defensive shots:\n@shot_query def lobs(shot):\nreturn shot.like(\"lob\") and shot.next.like(\"defensive\")\nWe can use query attributes to get additional information about, for example, where the opponents had to return the lob, next.hitter.distance_to_backwall, or the distance to the net of the players two shots after the lob, next.next.hitter.distance_to_net, next.next.hitter.partner.distance_to_net.\n8.3.10. S10: \u201cFirst Volley\u201d\nThis statement requires identifying the shot sequence Serve\u2192 Return\u2192 Volley. We will add additional conditions to check another maxim in padel: if a serve goes to the T, the first volley should direct the ball toward the side wall of the returning player:\nQ10 \u201cRetrieve all serves directed to the T, followed by any shot, followed by a volley to the side wall of the same player that returned the serve\u201d.\nThis can be translated as follows, using 2.5 m as the distance threshold:\n@shot_query def serve_return_volley(shot):\nreturn shot.like(\"serve\") and shot.next.hitter.distance_to_side_wall > 2.5 and shot.next.next.like(\"volley\") and shot.next.next.next.hitter.distance_to_side_wall < 2.5 and shot.next.hitter == shot.next.next.next.hitter\nwhere shot is the serve, shot.next is the return, shot.next.next is the volley, and shot.next.next.next is the volley\u2019s return."
        },
        {
            "heading": "8.4. Comparison with State-of-the-Art Analysis Tools",
            "text": "We are not aware of any software solution designed specifically for video-based padel analysis. Therefore, we have to consider solutions covering other racket sports. Commercial products typically provide support for the analysis of a fixed, predefined number of variables. It would be unfair to compare our language against these tools, as they simply do not support complex queries (such as Q10). Fortunately, some video-based, open-source solutions do support arbitrary queries. For example, Lince Plus [38] features the possibility of performing specific analyses with the R language (through RStudio or an integrated console), which in turn is based on DataFrames. Therefore, we believe that the best way to compare our language with the closest state-of-the-art models is to translate some of our test queries to R or Python using raw DataFrame operations. For the sake of brevity, we will compare the definition of Q10 using Python + Pandas and using our query language.\nUsing Python + Pandas, in a best-case scenario, Q10 can be defined as follows:\ndef first_volley(df): df = df.reset_index() # make sure indexes pair with the number of rows for index, row in df.iterrows():\nif (row[\"shot_code\"] == \"serve\" and df[\"hitter.distance_to_side_wall\"][index + 1] > 2.5 and df[\"shot_code\"][index + 2] in [\"vd\", \"vr\"] and df[\"hitter.distance_to_side_wall\"][index + 3] < 2.5 and df[\"hitter.id\"][index + 1] == df[\"hitter.id\"][index + 3]): df.loc[index, \"Filter\"] = True\nreturn df[ df[\"Filter\"] == True ]\nNotice that we had to loop over the DataFrame (df) rows because the filter involves multiple rows (we are looking for a specific shot sequence). Notice also the use of index offsets, which decreases readability. Finally, we have assumed that the input DataFrame has already been enriched with additional columns (e.g., distance of the player from the net). Otherwise, extra code would be required to compute these columns. This code might\nnot be straightforward if, for example, the filter involves data from other DataFrames (e.g., to relate who played the volley with the team that won the point). Using our approach, Q10 definition can be written in a more compact and readable way:\n@shot_query def first_volley(shot):\nreturn shot.like(\"serve\") and shot.next.hitter.distance_to_side_wall > 2.5 and shot.next.next.like(\"volley\") and shot.next.next.next.hitter.distance_to_side_wall < 2.5 and shot.next.hitter == shot.next.next.next.hitter"
        },
        {
            "heading": "9. Discussion",
            "text": "Expressiveness was our main priority when designing a domain-specific query language for padel matches. Besides the statements discussed in Section 8, we have been able to write queries to support, refute or analyze all statements about padel strategies under the only assumption that the queries involve concepts captured by the tabular data. This is not a limitation of the language, but of the sensing technology to generate the input datasets. For example, our dataset has no information about shot effects (backspin, topspin, slice). We have observed that being able to navigate across temporal concepts (from shots to frames, frames to shot, from a shot to the next. . . ) largely simplifies the readability and compactness of the queries. As shown in many examples, the separation between the query definitions (\u201cretrieve all volleys\u201d) and query attributes (\u201cget the player\u2019s position\u201d) facilitates code reusability. User-defined tags and properties also provide a simple mechanism to include new concepts (\u201cdeep lob\u201d) that further simplify the task of writing queries in a language close to that of coaches. The output of a query is a QueryResult object that keeps internally a Panda\u2019s DataFrame object. As shown in many examples, this class provides methods for essential plots. Supported plots include scatter plots for players\u2019 positions on an overhead view of the court, as well as bar charts and histograms. More complex plots can be obtained by accessing directly the query output and using any visualization tool (we used Vega-Altair as well as HoloViz\u2019s hvPlot). Our approach though has some limitations. The flexibility of using a programming language, with arbitrary predicates on the query definitions, and arbitrary expressions on query attributes, comes at the price of raising the entry barrier for sports analysts to use the tool, since some Python skills are needed to write new queries. Although we believe that minor edits to the query definitions are doable with little Python knowledge, the main problem is the interpretation of potential syntax errors. Despite this, we believe that the queries using the proposed API are more readable than alternative methods. Although the focus of this paper is the query language and not how the input data have been obtained, the availability of large datasets including accurate data about many matches would certainly influence the impact of this work. On our test dataset, the most relevant issue was the accuracy of the positional data, which was questionable for players on top of the video, and also when jumping, since the perspective correction we apply to move from image space to court space coordinates assumes that the feet are on the floor. Advances in video tracking and pose estimation techniques, or the use of multi-camera approaches, would improve the quality of the data and thus the reliability of analysis tools."
        },
        {
            "heading": "10. Applications",
            "text": "The proposed API has multiple practical applications, as it simplifies writing queries and facilitates the exploratory analysis of padel matches. At a professional level, the tool speeds up the analysis of many variables and their relationship. For example, the tool can be useful in the following tasks:\n\u2022 Determine the game profile in professional padel, considering variables such as the number of games, number of points, average duration of games and points, time interval between shots, number of winning points, and number of unforced errors [5,44].\n\u2022 Analyze the frequency and success rate of the different technical actions (types of shots, their direction and speed) according to the in-game situation (preceding technical actions, position, and speed of the partner and the opponents). \u2022 Analyze the distance covered by the players, their positions, displacements, and coordinated movements, and relate them with the other variables [45]. \u2022 Analyze how all the variables above vary between women\u2019s matches and men\u2019s matches. \u2022 Analyze how other external factors (e.g., outdoor match) might affect the variables above. \u2022 Retrieve specific parts of the video (e.g., certain shot sequences) to quickly analyze\nvisually other aspects not captured by the input tabular data.\nAt an amateur level, coaches and padel clubs might offer the opportunity to record the videos of the training sessions to further analyze them. For example,\n\u2022 Compare the technical actions adopted by the trainee in particular scenarios against those adopted by professional players. \u2022 Show trainees specific segments of professional padel videos to provide visual evidence and representative examples of strategic recommendations. \u2022 If multiple videos are available, compare the different variables defining the game profile of a trainee with those of other amateur or professional players. \u2022 Help to monitor the progress and performance improvement of the trainees."
        },
        {
            "heading": "11. Conclusions and Future Work",
            "text": "In this paper we have presented a domain-specific query language, in particular a Python API, to analyze tabular tracking data on padel matches. We foresee that, as tracking software becomes more robust and accurate, more specialized tools will be required to fully benefit from these data. We have focused on padel because it is arguably the racket sport where tactics are more complex (due to the enclosing balls and ball bounces) and have a rich variety of technical actions. The fact that there is a large body of publicly available videos of padel matches, most of them from the de facto camera standard [21], also facilitates the digitization of matches. Despite this, we believe that most ideas of the query language can be applied to other racket sports such as tennis. As future work, we plan to evaluate the readability of the queries (and the ease of editing them) for different user profiles. We also plan to build a visual front-end to allow coaches with absolutely no programming experience to create their own queries. Similarly, an interesting avenue is to explore the use of GUI-based software wizards to guide users through a sequence of steps to create complex queries.\nSupplementary Materials: The following supporting information can be downloaded at: https:// www.mdpi.com/article/10.3390/s23010441/s1, Video S1: Interactive Demo.\nAuthor Contributions: Conceptualization, M.J. and C.A.; software, M.J. and C.A.; validation and resources, all authors; test statements, E.L. and C.A.; writing\u2014original draft preparation, C.A.; writing\u2014review and editing, all authors; visualization, C.A.; supervision, C.A. All authors have read and agreed to the published version of the manuscript.\nFunding: This research was funded by the Spanish Ministry of Science and Innovation and FEDER funds, grant number PID2021-122136OB-C21, MCIN/AEI/10.13039/501100011033/FEDER, UE.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: The source code of a free implementation of the API will be released upon acceptance. The test video is publicly available at https://youtu.be/7s55wB9dR78 (accessed on 1 December 2022).\nAcknowledgments: We would like to thank Angel Ric for his helpful feedback and support on the visualization of the query outputs. This project has received funding from the Spanish Ministry of Science and Innovation and FEDER funds (PID2021-122136OB-C21).\nConflicts of Interest: The authors declare no conflict of interest."
        },
        {
            "heading": "Appendix A. Implementation Details",
            "text": "Our API extensively uses Python\u2019s function decorators, such as @shot_tag and @shot_query. A decorator is a mechanism of the Python language for defining higherorder functions, that is, functions that take another function and extend its behavior. For example, when we add the @shot_tag decorator to a Boolean function deep_lob, in fact, we are creating a higher-order function that, when invoked on a match, traverses all shots, evaluates the Boolean function deep_lob on each shot, and if the function evaluates to true, adds a new tag to the shot called \u201cdeep_lob\u201d. This mechanism is convenient because it moves a large part of the boilerplate code from the tag/property definition to the internal implementation of the API. The same applies to query decorators such as @frame_query. Adding this decorator to a Boolean function, creates a higher-order function that, when invoked on a match, traverses all frames, evaluates the Boolean function on each of frame, and adds the user-defined attributes to the output if the function evaluates to true. The evaluation of query attributes (which can be arbitrary Python expressions) is also handled by the higher-order function created by the query decorators. The internal code takes care of evaluating the attributes (using Python\u2019s eval function), adding new columns to the output DataFrame, and filling them with the data.\nReferences 1. Priego, J.I.; Melis, J.O.; Belloch, S.L.; Soriano, P.P.; Garc\u00eda, J.C.G.; Almenara, M.S. Padel: A Quantitative study of the shots and movements in the high-performance. J. Hum. Sport Exerc. 2013, 8, 925\u2013931. [CrossRef] 2. Escudero-Tena, A.; S\u00e1nchez-Alcaraz, B.J.; Garc\u00eda-Rubio, J.; Ib\u00e1\u00f1ez, S.J. Analysis of Game Performance Indicators during 2015\u20132019\nWorld Padel Tour Seasons and Their Influence on Match Outcome. Int. J. Environ. Res. Public Health 2021, 18, 4904. [CrossRef] [PubMed]\n3. Almonacid Cruz, B.; Mart\u00ednez P\u00e9rez, J. Esto es P\u00e1del; Editorial Aula Magna; McGraw-Hill: Sevilla, Spain, 2021. (In Spanish) 4. Demeco, A.; de Sire, A.; Marotta, N.; Span\u00f2, R.; Lippi, L.; Palumbo, A.; Iona, T.; Gramigna, V.; Palermi, S.; Leigheb, M.; et al.\nMatch analysis, physical training, risk of injury and rehabilitation in padel: Overview of the literature. Int. J. Environ. Res. Public Health 2022, 19, 4153. [CrossRef] [PubMed]\n5. Almonacid Cruz, B. Perfil de Juego en p\u00e1del de Alto Nivel. Ph.D. Thesis, Universidad de Ja\u00e9n, Ja\u00e9n, Spain, 2011. 6. Santiago, C.B.; Sousa, A.; Estriga, M.L.; Reis, L.P.; Lames, M. Survey on team tracking techniques applied to sports. In\nProceedings of the 2010 International Conference on Autonomous and Intelligent Systems, AIS 2010, Povoa de Varzim, Portugal, 21\u201323 June 2010; pp. 1\u20136.\n7. Shih, H.C. A survey of content-aware video analysis for sports. IEEE Trans. Circuits Syst. Video Technol. 2017, 28, 1212\u20131231. [CrossRef] 8. Mukai, R.; Araki, T.; Asano, T. Quantitative Evaluation of Tennis Plays by Computer Vision. IEEJ Trans. Electron. Inf. Syst. 2013, 133, 91\u201396. [CrossRef] 9. Lara, J.P.R.; Vieira, C.L.R.; Misuta, M.S.; Moura, F.A.; de Barros, R.M.L. Validation of a video-based system for automatic tracking of tennis players. Int. J. Perform. Anal. Sport 2018, 18, 137\u2013150. [CrossRef] 10. Pingali, G.; Opalach, A.; Jean, Y. Ball tracking and virtual replays for innovative tennis broadcasts. In Proceedings of the 15th International Conference on Pattern Recognition. ICPR-2000, Barcelona, Spain, 3\u20137 September 2000; Volume 4, pp. 152\u2013156. 11. Mao, J. Tracking a Tennis Ball Using Image Processing Techniques. Ph.D. Thesis, University of Saskatchewan, Saskatoon, SK, Canada, 2006. 12. Qazi, T.; Mukherjee, P.; Srivastava, S.; Lall, B.; Chauhan, N.R. Automated ball tracking in tennis videos. In Proceedings of the 2015 Third International Conference on Image Information Processing (ICIIP), Waknaghat, India, 21\u201324 December 2015; pp. 236\u2013240. 13. Kamble, P.R.; Keskar, A.G.; Bhurchandi, K.M. Ball tracking in sports: A survey. Artif. Intell. Rev. 2019, 52, 1655\u20131705. [CrossRef] 14. Zivkovic, Z.; van der Heijden, F.; Petkovic, M.; Jonker, W. Image segmentation and feature extraction for recognizing strokes in tennis game videos. In Proceedings of the ASCI, Heijen, The Netherlands, 30 May\u20131 June 2001. 15. Dahyot, R.; Kokaram, A.; Rea, N.; Denman, H. Joint audio visual retrieval for tennis broadcasts. In Proceedings of the 2003\nIEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP\u201903), Hong Kong, China, 6\u201310 April 2003; Volume 3, p. III-561.\n16. Yan, F.; Christmas, W.; Kittler, J. A tennis ball tracking algorithm for automatic annotation of tennis match. In Proceedings of the British Machine Vision Conference, Oxford, UK, 5\u20138 September 2005; Volume 2, pp. 619\u2013628. 17. Ram\u00f3n-Llin, J.; Guzm\u00e1n, J.; Mart\u00ednez-Gallego, R.; Mu\u00f1oz, D.; S\u00e1nchez-Pay, A.; S\u00e1nchez-Alcaraz, B.J. Stroke Analysis in Padel According to Match Outcome and Game Side on Court. Int. J. Environ. Res. Public Health 2020, 17, 7838. [CrossRef]\n18. Mas, J.R.L.; Belloch, S.L.; Guzm\u00e1n, J.; Vuckovic, G.; Mu\u00f1oz, D.; Mart\u00ednez, B.J.S.A. An\u00e1lisis de la distancia recorrida en p\u00e1del en funci\u00f3n de los diferentes roles estrat\u00e9gicos y el nivel de juego de los jugadores (Analysis of distance covered in padel based on level of play and number of points per match). Acci\u00f3n Mot. 2020, 25, 59\u201367. 19. Vuc\u030ckovic\u0301, G.; Per\u0161, J.; James, N.; Hughes, M. Measurement error associated with the SAGIT/Squash computer tracking software. Eur. J. Sport Sci. 2010, 10, 129\u2013140. [CrossRef] 20. Ram\u00f3n-Llin, J.; Guzm\u00e1n, J.F.; Llana, S.; Mart\u00ednez-Gallego, R.; James, N.; Vuc\u030ckovic\u0301, G. The Effect of the Return of Serve on the Server Pair\u2019s Movement Parameters and Rally Outcome in Padel Using Cluster Analysis. Front. Psychol. 2019, 10, 1194. [CrossRef] [PubMed] 21. Javadiha, M.; Andujar, C.; Lacasa, E.; Ric, A.; Susin, A. Estimating Player Positions from Padel High-Angle Videos: Accuracy Comparison of Recent Computer Vision Methods. Sensors 2021, 21, 3368. [CrossRef] [PubMed] 22. Chen, K.; Wang, J.; Pang, J.; Cao, Y.; Xiong, Y.; Li, X.; Sun, S.; Feng, W.; Liu, Z.; Xu, J.; et al. MMDetection: Open MMLab Detection Toolbox and Benchmark. arXiv 2019, arXiv:1906.07155. 23. Xiao, B.; Wu, H.; Wei, Y. Simple baselines for human pose estimation and tracking. In Proceedings of the European Conference on Computer Vision (ECCV), Munich, Germany, 8\u201314 September 2018; pp. 466\u2013481. 24. Ren, S.; He, K.; Girshick, R.; Sun, J. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. IEEE Trans. Pattern Anal. Mach. Intell. 2017, 39, 1137\u20131149. [CrossRef] [PubMed] 25. Cai, Z.; Vasconcelos, N. Cascade R-CNN: High Quality Object Detection and Instance Segmentation. IEEE Trans. Pattern Anal. Mach. Intell. 2019, 43, 1483\u20131498. [CrossRef] 26. Wu, Y.; Kirillov, A.; Massa, F.; Lo, W.Y.; Girshick, R. Detectron2. 2019. Available online: https://github.com/facebookresearch/ detectron2 (accessed on 1 November 2021). 27. Chen, K.; Pang, J.; Wang, J.; Xiong, Y.; Li, X.; Sun, S.; Feng, W.; Liu, Z.; Shi, J.; Ouyang, W.; et al. Hybrid task cascade for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 16\u201320 June 2019. 28. Sandler, M.; Howard, A.; Zhu, M.; Zhmoginov, A.; Chen, L.C. Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 4510\u20134520. 29. Newell, A.; Yang, K.; Deng, J. Stacked hourglass networks for human pose estimation. In Proceedings of the European Conference on Computer Vision, Amsterdam, The Netherlands, 11\u201314 October 2016; pp. 483\u2013499. 30. Huang, J.; Zhu, Z.; Guo, F.; Huang, G. The Devil Is in the Details: Delving Into Unbiased Data Processing for Human Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Virtual, 14\u201319 June 2020. 31. Zhang, F.; Zhu, X.; Dai, H.; Ye, M.; Zhu, C. Distribution-aware coordinate representation for human pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Virtual, 14\u201319 June 2020; pp. 7093\u20137102. 32. Sun, K.; Xiao, B.; Liu, D.; Wang, J. Deep high-resolution representation learning for human pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 16\u201320 June 2019; pp. 5693\u20135703. 33. Cheng, B.; Xiao, B.; Wang, J.; Shi, H.; Huang, T.S.; Zhang, L. HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Virtual, 14\u201319 June 2020; pp. 5386\u20135395. 34. Wojke, N.; Bewley, A.; Paulus, D. Simple online and realtime tracking with a deep association metric. In Proceedings of the 2017 IEEE International Conference on Image Processing (ICIP), Beijing, China, 17\u201320 September 2017; pp. 3645\u20133649. [CrossRef] 35. Zhang, D.; Guo, G.; Huang, D.; Han, J. PoseFlow: A Deep Motion Representati\u2013on for Understanding Human Behaviors in Videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201322 June 2018. 36. Bergmann, P.; Meinhardt, T.; Leal-Taixe, L. Tracking without bells and whistles. In Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, Republic of Korea, 27 October\u20132 November 2019; pp. 941\u2013951. 37. \u0160ajina, R.; Iva\u0161ic\u0301-Kos, M. 3D Pose Estimation and Tracking in Handball Actions Using a Monocular Camera. J. Imaging 2022, 8, 308. [CrossRef] 38. Soto-Fern\u00e1ndez, A.; Camerino, O.; Iglesias, X.; Anguera, M.T.; Casta\u00f1er, M. LINCE PLUS software for systematic observational studies in sports and health. Behav. Res. Methods 2022, 54, 1263\u20131271. [CrossRef] 39. Mishra, P.; Eich, M.H. Join processing in relational databases. ACM Comput. Surv. 1992, 24, 63\u2013113. [CrossRef] 40. Fister, I.; Fister, I.; Mernik, M.; Brest, J. Design and implementation of domain-specific language easytime. Comput. Lang. Syst. Struct. 2011, 37, 151\u2013167. [CrossRef] 41. Van Deursen, A.; Klint, P. Domain-specific language design requires feature descriptions. J. Comput. Inf. Technol. 2002, 10, 1\u201317. [CrossRef] 42. Xie, S.; Girshick, R.; Doll\u00e1r, P.; Tu, Z.; He, K. Aggregated residual transformations for deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 1492\u20131500. 43. Remohi-Ruiz, J.J. P\u00e1del: Lo Esencial. Nivel Iniciaci\u00f3n y Medio; NPQ Editores: Valencia, Spain, 2019. (In Spanish)\n44. Mellado-Arbelo, \u00d3.; Vidal, E.B.; Us\u00f3n, M.V. An\u00e1lisis de las acciones de juego en p\u00e1del masculino profesional (Analysis of game actions in professional male padel). Cult. Cienc. Deporte 2019, 14, 191\u2013201. 45. Ram\u00f3n-Llin, J.; Guzm\u00e1n, J.F.; Belloch, S.L.; Vuckovic, G.; James, N. Comparison of distance covered in paddle in the serve team according to performance level. J. Hum. Sport Exerc. 2013, 8, S738\u2013S742. [CrossRef]\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
        }
    ],
    "title": "A Query Language for Exploratory Analysis of Video-Based Tracking Data in Padel Matches",
    "year": 2023
}