{
    "abstractText": "Haptic feedback can be almost as important as visual information in virtual reality environments. On the one hand, in Active Haptic Feedback, specialized devices such as vibrotactile gloves are employed; however, these solutions can be expensive, vendor-specific or cumbersome to setup. On the other hand, Passive Haptic Feedback approaches use inexpensive objects as proxies for the virtual entities; but mapping virtual objects to real props is not scalable nor flexible. We propose the Handas-a-Prop technique, which consists in using human hands as object props. We implemented two modalities: Self, where the user\u2019s non-dominant hand act as the virtual object while the dominant hand grabs, translates and releases it; and External, where the hand of another person is used. Hand-as-a-Prop can represent multiple shapes with a single prop and does not require extra hardware. We performed an evaluation comparing both Self and External Hand-as-a-Prop with traditional Object Props in terms of user experience (goodness, ease, realism, fatigue, and preference) and performance (task completion time and translation time). Results showed that Hand-as-a-Prop was rated as neutral tending to positive, and in some cases, the performance was similar to Object Props. Users preferred Self Hand-as-a-Prop over External Hand-as-a-Prop and also obtained better results.",
    "authors": [
        {
            "affiliations": [],
            "name": "Oscar Ardaiz"
        },
        {
            "affiliations": [],
            "name": "Asier Marzo"
        }
    ],
    "id": "SP:0c9519d43886fac6341caa76c5a2bf5f11d4db11",
    "references": [
        {
            "authors": [
                "P Abtahi",
                "S Follmer"
            ],
            "title": "Visuo-Haptic illusions for improving the perceived performance of shape displays",
            "venue": "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, pp 1\u201313. https:// doi",
            "year": 2018
        },
        {
            "authors": [
                "L Aguerreche",
                "Duval T",
                "A L\u00e9cuyer"
            ],
            "title": "Reconfigurable tangible devices for 3D virtual object manipulation by single or multiple users",
            "venue": "Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology,",
            "year": 2010
        },
        {
            "authors": [
                "B Araujo",
                "R Jota",
                "V Perumal",
                "JX Yao",
                "K Singh",
                "D Wigdor"
            ],
            "title": "Snake charmer: physically enabling virtual objects. In: Proceedings of the TEI \u201916: Tenth International Conference on Tangible, Embedded, and Embodied Interaction, pp 218\u2013226",
            "venue": "https:// doi",
            "year": 2016
        },
        {
            "authors": [
                "AS Arif"
            ],
            "title": "Statistical grounding. Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice (1st ed). Association for Computing Machinery, New York, NY, USA, pp 59\u201399",
            "venue": "https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "M Azmandian",
                "M Hancock",
                "H Benko",
                "E Ofek",
                "AD Wilson"
            ],
            "title": "Haptic retargeting: dynamic repurposing of passive haptics for enhanced virtual reality experiences",
            "venue": "Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, pp 1968\u20131979. https:// doi",
            "year": 2016
        },
        {
            "authors": [
                "Y Ban",
                "T Narumi",
                "T Tanikawa",
                "M Hirose"
            ],
            "title": "Air haptics: displaying feeling of contact with AR object using visuo-haptic interaction",
            "venue": "ACM SIGGRAPH",
            "year": 2015
        },
        {
            "authors": [
                "J Bergstr\u00f6m",
                "TS Dalsgaard",
                "J Alexander",
                "K Hornb\u00e6k"
            ],
            "title": "How to evaluate object selection and manipulation in VR? Guidelines from 20 years of studies",
            "venue": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. CHI \u201921: CHI Conference on Human Factors in Computing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "S Bovet",
                "HG Debarba",
                "B Herbelin",
                "E Molla",
                "R Boulic"
            ],
            "title": "The critical role of self-contact for embodiment in virtual reality",
            "venue": "IEEE Trans Visual Comput Graphics",
            "year": 2018
        },
        {
            "authors": [
                "J Cohen"
            ],
            "title": "Systems (IROS). https:// doi",
            "year": 1988
        },
        {
            "authors": [
                "AM Colman"
            ],
            "title": "A dictionary of psychology",
            "year": 2015
        },
        {
            "authors": [
                "C AJ Fang CM Harrison"
            ],
            "title": "Retargeted self-haptics for increased",
            "year": 2021
        },
        {
            "authors": [
                "https:// psycn et"
            ],
            "title": "apa. org/ journ als/ xge",
            "venue": "Grotowski J, Wiewiorowski TK, Morris K",
            "year": 1967
        },
        {
            "authors": [
                "D Hecht",
                "M Reiner"
            ],
            "title": "Sensory dominance in combinations",
            "year": 2009
        },
        {
            "authors": [
                "P Knierim",
                "T Kosch",
                "V Schwind",
                "M Funk",
                "F Kiss",
                "S Schneegass",
                "N Henze"
            ],
            "title": "Tactile drones-providing immersive tactile feedback in virtual reality through quadcopters",
            "venue": "Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "P Knierim",
                "T Kosch",
                "A Achberger",
                "M Funk"
            ],
            "title": "Flyables: exploring 3d interaction spaces for levitating tangibles",
            "venue": "Proceedings of the Twelfth International Conference on Tangible, Embedded,",
            "year": 2018
        },
        {
            "authors": [
                "L Kohli",
                "M Whitton"
            ],
            "title": "The haptic hand: providing user interface feedback with the non-dominant hand in virtual environments",
            "venue": "Proceedings of Graphics Interface",
            "year": 2005
        },
        {
            "authors": [
                "L Kohli",
                "MC Whitton",
                "FP Brooks"
            ],
            "title": "Redirected touching: the effect of warping space on task performance",
            "venue": "IEEE Symposium on 3D User Interfaces (3DUI),",
            "year": 2012
        },
        {
            "authors": [
                "L Kohli",
                "MC Whitton",
                "FP Brooks"
            ],
            "title": "Redirected touching: training and adaptation in warped virtual spaces. In: Proceedings",
            "venue": "IEEE Symposium on 3D User Interfaces,",
            "year": 2013
        },
        {
            "authors": [
                "P Kyriakou",
                "S Hermon"
            ],
            "title": "Can i touch this? Using natural interaction in a museum augmented reality system",
            "venue": "Digit Appl Archaeol Cult Heritage 12:e00088. https:// doi. org/ 10. 1016/j. daach. 2018",
            "year": 2019
        },
        {
            "authors": [
                "IS MacKenzie"
            ],
            "title": "Designing HCI Experiments. Human-computer interaction: an empirical research perspective",
            "year": 2013
        },
        {
            "authors": [
                "TH Massie",
                "JK Salisbury"
            ],
            "title": "The phantom haptic interface: A device for probing virtual objects",
            "venue": "Proceedings of the ASME Winter Annual Meeting, Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems,",
            "year": 1994
        },
        {
            "authors": [
                "JC McClelland",
                "RJ Teather",
                "Girouard"
            ],
            "title": "A (2017) Haptobend: shapechanging passive haptic feedback in virtual reality",
            "venue": "Proceedings of the 5th Symposium on Spatial User Interaction,",
            "year": 2017
        },
        {
            "authors": [
                "WA McNeely"
            ],
            "title": "Robotic graphics: a new approach to force feedback for virtual reality",
            "venue": "Proceedings of IEEE Virtual Reality Annual International Symposium. https:// doi. org/",
            "year": 2013
        },
        {
            "authors": [
                "VR Mercado",
                "M Marchal",
                "A Lecuyer"
            ],
            "title": "Haptics on-demand: a survey on encountered-type haptic displays. IEEE Trans Haptics 14:449\u2013464",
            "venue": "https:// doi. org/",
            "year": 2021
        },
        {
            "authors": [
                "I Rock",
                "J Victor"
            ],
            "title": "Vision and touch: an experimentally created confict between the two senses",
            "venue": "Science",
            "year": 1964
        },
        {
            "authors": [
                "M Sra",
                "S Garrido-Jurado",
                "C Schmandt",
                "P Maes"
            ],
            "title": "Procedurally generated virtual reality from 3D reconstructed physical space",
            "venue": "Proceedings of the 22nd ACM Conference on Virtual Reality",
            "year": 2016
        },
        {
            "authors": [
                "JL Taylor"
            ],
            "title": "Proprioception. In: Encyclopedia of Neuroscience (pp 1143\u20131149)",
            "year": 2009
        },
        {
            "authors": [
                "JO Wobbrock",
                "MR Morris",
                "AD Wilson"
            ],
            "title": "User-defined gestures for surface computing. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp 1083\u20131092",
            "venue": "https:// doi",
            "year": 2009
        },
        {
            "authors": [
                "A Zenner",
                "A Kruger"
            ],
            "title": "Shifty: a weight-shifting dynamic passive haptic proxy to enhance object perception in virtual reality",
            "venue": "IEEE Trans Visual Comput Graphics",
            "year": 2017
        },
        {
            "authors": [
                "Y Zhao",
                "S Follmer"
            ],
            "title": "A functional optimization based approach",
            "venue": "TVCG",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Vol.:(0123456789)\nKeywords Virtual reality\u00a0\u00b7 Manipulation\u00a0\u00b7 Human actuation\u00a0\u00b7 Self-haptics\u00a0\u00b7 Controller-free interaction"
        },
        {
            "heading": "1 Introduction",
            "text": "Providing haptic feedback in virtual reality (VR) improves the user experience and performance (Aguerreche et\u00a0al. 2010; Azmandian et\u00a0al. 2016; Cheng et\u00a0al. 2015; Hoffman\n1998; Insko 2001; Sra et\u00a0al. 2016). Some solutions for haptic feedback use what is known as \"Active Haptic Feedback\" (AHF), employing computer-controlled actuators to provide haptic feedback (Zenner and Kruger 2017). This approach enables the generation of tactile or kinesthetic sensations on the user's skin, allowing to explore the environment and understand its constraints (Kyriakou and Hermon 2019), for example wearing vibrotactile gloves or through robots (McNeely 2013). However, these devices are often expensive and interfere with the user experience. On the other hand, \"Passive Haptic Feedback\" works by mapping virtual objects to static physical objects with a similar shape in the real world (Insko 2001), and the real objects are also known as \u201cprops\u201d. This approach usually improves the user experience (Hoffman 1998) without adding interfering or expensive devices. However, requiring a physical prop for each virtual object or for each shape is not always practical. Situations where it is not possible to use a physical object to provide haptics include in\u00a0situ and mobile scenarios \"on the street\", \"out of the office\" or \"in the wild\" for casual or spontaneous use of virtual reality application in those situation physical props may not be available. * Oscar Ardaiz oscar.ardaiz@unavarra.es Sebastian Marichal sebastian.marichal@unavarra.es I\u00f1igo Ezcurdia inigofermin.ezcurdia@unavarra.es Rafael Morales rafael.morales@ultraleap.com Amalia Ortiz amalia.ortiz@unavarra.es Asier Marzo asier.marzo@unavarra.es 1 Institute of\u00a0Smart Cities, Public University of\u00a0Navarre, Pamplona, Spain 2 Ultraleap Ltd, Bristol, UK\n1 3\nWe explored practical and scalable alternatives to represent multiple virtual objects using limited resources. We drew inspiration from \u201cthe theater of the poor\u201d movement by Jerzy Grotowski (Grotowski et\u00a0al. 1967), who represented objects using their own body as a prop instead of real object props.\u00a0This practice led us to define the Hand-as-a-Prop technique. In this technique, the hand acts as a traditional prop and provides haptic feedback. Following this strategy, we designed and implemented two versions of the technique: Self Hand-as-a-Prop and External Hand-as-a-Prop. For example, using the Self Hand-as-a-Prop in an object translation task, would work as follows: The user's nondominant hand is moved to the position of the virtual object to be manipulated and tries to get its shape; meanwhile, with the dominant hand the user grabs, moves, and releases it. In this way, users benefit from the haptic feedback provided by themselves, a solution that does not require any external element to emulate the presence of virtual objects.\nIn this study, we aim to determine what the effect on User Experience and Performance of Hand-as-a-Prop is. We specifically investigate how object representation and manipulation might be affected. The research questions are as follows:\n\u2022 Is it possible to use human hands (either the user hand or an external person hand) to provide haptic feedback in Virtual Reality? \u2022 Is it possible to represent different shapes? \u2022 What is the effect in an object manipulation task?\nThe results of the conducted user study show that using hands as props is feasible in both modalities: self and external. In all the cases, users were able to accomplish the translation task with acceptable performance. Self Handas-a-Prop provided better performance than External Handas-a-Prop, sometimes with similar values to Object Props. Regarding User Experience, both Hand-as-a-Prop techniques were rated neutral tending to positive. Finally, users preferred using their hands rather than external hands.\nIn summary, the contributions of this work are as follows:\n\u2022 The design and implementation of Hand-as-a-Prop technique for self and external modalities. \u2022 A study on the ability to represent different object shapes. \u2022 A comparison of both techniques to real object props in\na translation task."
        },
        {
            "heading": "2 Related work",
            "text": "The related work is classified into three categories: (1) VR Haptic Feedback Devices split into Active and Passive, (2) Visuo-haptic illusions based on visual dominance and proprioception applied to static and dynamic props, and (3)\nSelf-haptics approaches where the user\u2019s body is employed for physical feedback."
        },
        {
            "heading": "2.1 VR active and\u00a0passive haptic feedback",
            "text": ""
        },
        {
            "heading": "2.1.1 Active haptic feedback (AHF)",
            "text": "One of the most common approach to provide haptics in VR is through AHF devices. Wearable gloves such as Wolverine (Choi et\u00a0al. 2016) can provide tactile and force feedback. Users wearing vibrotactile gloves can feel textures and forces, but they can still push and clip through the objects, which reduces presence and immersion. Externally grounded devices, like Phantom (Massie et\u00a0al. 1994), address this issue and provide a sensation of stiffness of the virtual objects, avoiding clipping through them. However, in large-scale systems, the approach is intrusive and requires bulky and expensive devices.\nShape-changing displays are classified as encounteredtype haptic devices since they present a contact surface to the user\u2019s hand (Abtahi and Follmer 2018). They provide AHF by dynamically changing their shape to represent virtual objects. However, this solution still presents limitations such as their cost, speed, size, and low spatial resolution (Abtahi and Follmer 2018)."
        },
        {
            "heading": "2.1.2 Passive haptic feedback (PHF)",
            "text": "Previous research indicates that passive haptics enhances the sense of presence and immersion in virtual reality (Azmandian et\u00a0al. 2016; Sra et\u00a0al. 2016). PHF commonly employs static physical objects called props, usually using a one-toone mapping where each virtual object is associated with a prop.\nHandheld props are the most common approach, i.e., physical objects with a similar shape to virtual objects. One of the first applications was using a doll\u2019s head for 3D neurosurgical visualizations (Hinckley et\u00a0al. 1994). The use of traditional static props presents two main limitations: it is not scalable since too many props might be required for mapping each virtual object and requiring a placement mechanism since something or someone has to place the correct prop in the target place at a specific moment. Mapping each virtual object to a physical prop is neither scalable nor flexible.\nSeveral placing and switching strategies of props have been explored. Robots can accomplish this task, for instance, Robotic Shape Displays (Araujo et\u00a0al. 2016; McNeely 2013) use robotic arms to place props in front of the user's hand when they are meant to be reached. There are attempts to use non-grounded devices like drones to provide positional physical feedback (Hoppe et\u00a0al. 2018; Knierim et\u00a0al. 2017, 2018). For an extended review of encountered-type Haptic Feedback on Demand see (Mercado et\u00a0al. 2021).\n1 3"
        },
        {
            "heading": "2.2 Visuo\u2011haptic illusions",
            "text": "Vision dominates over other senses when they are in conflict (Colman 2015; Gibson 1933; Hecht and Reiner 2009). In addition, vision dominates over proprioception (Burns et\u00a0al. 2007) which is the sense that allows perceiving us the location, movement and actions of parts of our body (Taylor 2009). This can be used to simplify the tactile stimuli necessary to represent certain virtual entities. Techniques such as Redirected touch and haptic retargeting exploit visual dominance effect.\nRedirected touch enables a one-to-many mapping, making it possible to use the same prop to provide haptic feedback for multiple virtual objects. Kohli et\u00a0al (2012, 2013) accomplished it by warping the visual virtual environment to direct the user hand toward the same physical prop, even when in the virtual world the hand seemed to be reaching different objects. They compared one-finger interaction in warped and non-warped environments, measuring performance using the Fitts\u2019 law for a multidirectional tapping task, concluding that users can effectively interact in a warped virtual space. In (Abtahi and Follmer 2018), redirected touch is used to increase the spatial resolution of shape displays, and in (Zhao and Follmer 2018), redirected touch was extended for multi-finger interaction.\nAzmandian et\u00a0al. (Azmandian et\u00a0al. 2016) propose the Haptic Retargeting framework to make statics props more flexible and scalable. Haptic retargeting defines a dynamic and minimally noticeable mapping that allows reusing physical objects to provide haptic feedback. This is possible by leveraging the visual dominance and dynamically aligning physical and virtual objects while the user interactions in the environment. Similarly, the Sparse Haptic Proxy (Cheng et\u00a0al. 2017a) technique makes use of a single human-size physical proxy which provides haptic feedback for many virtual objects. However, in both cases, external devices are needed, the interaction target has to be known beforehand and it only works when the movement starts with the hand resting on the initial position.\nFinally, shape-changing devices also take advantage of the visual dominance effect. The approach by (Abtahi and Follmer 2018) improves perceived speed and spatial resolution by using redirection, scaling, and retargeting visuohaptic illusions, this research is limited to one-finger interaction and results are dependent on the size and resolution of a specific shape display. The experiment by (McClelland et\u00a0al. 2017) evaluated how a shape-changing device approximates virtual object shapes."
        },
        {
            "heading": "2.3 Human\u2011provided feedback",
            "text": "Human actuation has been investigated by Cheng et\u00a0al. (2014, 2015, 2018); Cheng and Marwecki et\u00a0al. (2017)\nwithout users being aware that another human is on the other side. In Haptic Turk (Cheng et\u00a0al. 2014) and TurkDeck (Cheng et\u00a0al. 2015), dedicated humans presented and operated the props: walls, tables, chairs, and steps. Thus, physical representations are created on the fly, enabling the creation of arbitrarily large virtual worlds. Mutual Human Actuation (Cheng and Marwecki et\u00a0al. 2017) uses human feedback, but in this case, all users are immersed in different virtual environments. The iTurk technique (Cheng et\u00a0al. 2018) does not require an extra human, but it is the user who provides forces to object props in his own virtual reality world.\nProviding self-haptic feedback has been previously explored: Koli and Whitton (2005) designed \u201cthe haptic hand\u201d, a system that uses the non-dominant hand to provide haptic feedback to the dominant one. They explored the use of the non-dominant hand as touch surfaces, for example simulating a panel where the user had to interact with the dominant hand. Despite obtaining promising usability results, a formal comparison with alternative techniques was not conducted. Also, more complex object representations or tasks such as translating objects were not explored. (Ban et\u00a0al. 2015) applied retargeting to create the sensation of haptic feedback in one-hand tasks, they warped the index and thumb fingers so when the user was pinching an object they see the fingers in contact with the object\u2019s surface, but in reality, the fingers are touching each other. Similarly, (Bovet et\u00a0al. 2018) applied retargeting techniques to the locations of the user\u2019s hands in order to make them act as props for the other hand. Evaluations indicate that the technique can effectively provide touch, and when compared to no-haptic feedback interaction, it improves immersion and realism. Recently, Fang and Harrison self-haptic technique (2021) was not compared to alternative haptic mechanisms such as traditional object props or other person hand and was not measured in a manipulation task as we do, though Fang and Harrison implemented some two-handed tasks, whereas we only implemented one-hand manipulation of a single object.\nTo summarize, haptic feedback techniques have been explored to be more practical, flexible and improve the user experience in virtual reality environments. Shape-changing devices (McClelland et\u00a0al. 2017) can represent several objects with a single device. Also, previous research (Cheng et\u00a0al.\u00a02014, 2015, 2018; Cheng, Marwecki et\u00a0al. 2017) used human agents and users\u2019 own force to animate objects that will provide haptic feedback. Self-haptic feedback approaches exploiting the non-dominant hand as props have also been explored (Fang and Harrison 2021; Kohli and Whitton 2005). In our work, we explored two novel techniques to provide haptic feedback in virtual reality without needing a physical object (Self Hand-as-a-Prop and External Hand-as-a-Prop). In addition, we compared them with a traditional object props technique. In particular, Self\n1 3\nHand-as-a-Prop does not require an external agent but is the own user who provides haptic feedback himself.\n3 Design and\u00a0implementation of\u00a0hand\u2011as\u2011a\u2011prop\nHand-as-a-Prop takes inspiration from artistic performances. In theater, the human body is used on stage as a wall, table or handheld item; this was popularized by the \u201ctheater of the poor\u201d movement by Jerzy Grotowski (Grotowski et\u00a0al. 1967). Conceptual art borrowed the idea and applied it in performances such as \u201cRent-a-Body\u201d (Cao 1993).\nHand-as-a-Prop is a haptic feedback technique that does not require an active or external device to represent virtual objects; it only requires the hands. We designed the technique to take advantage of the visual dominance effect\nto convey the illusion of perceiving haptic feedback from the virtual objects. We also expected that proprioception could help to locate the object when the own hand is used is used as a prop. Furthermore, as the hand can adopt multiple shapes similarly to shape-changing devices (McClelland et\u00a0al. 2017), the technique allows modeling several objects using the hand. There are two modalities of Hand-as-a-Prop technique: External and Self.\nIn External Hand-as-a-Prop, the hand of an external person models the shape of the virtual object and it is the external person who places the hand to match the virtual object position, as seen in Fig.\u00a01 External Hand-as-a-Prop. This technique is based on Haptic Turk, TurkDeck, and Mutual Human actuation techniques by Cheng et\u00a0al. (2015, 2017) as an external agent provides actuation; however, we do not use any real prop. External Hand-as-a-Prop shares some of their disadvantages: the need of an external human agent, the\nagent has to be aware of virtual reality positions and actions, and they have to let their body to be moved by the user.\nIn the Self Hand-as-a-Prop case, it is the user who is in charge of modeling the shape of the target object in the correct location to match the virtual object position, see Fig.\u00a01 Self Hand-as-a-Prop. There is no need for an external display to show the position and shape of virtual objects. A hand pose algorithm is employed to detect the hand gesture and determine if it matches the target virtual object. When this occurs, the system enables the manipulation of the virtual object."
        },
        {
            "heading": "3.1 Implementation",
            "text": "To implement the Hand-as-a-Prop techniques we used a head-mounted display with a hand tracking system, the Oculus Quest 2 virtual reality headset. Both user\u2019s hands are displayed in virtual reality, except when the hand is representing a virtual object in the Self Hand-as-a-Prop technique. The hands models are from the Unity Oculus Virtual Reality Integration Package. Only the dominant hand had the possibility to grab."
        },
        {
            "heading": "3.1.1 External hand\u2011as\u2011a\u2011prop implementation",
            "text": "In this case, an external human places his/her hand in the position and shape of the virtual object. The hand tracking system incorporated in the head-mounted display is used to let the user see his real non-dominant hand position. The external agent hands were not tracked, and the virtual reality scene visualization is duplicated in an external display so that the external agent is aware of the target shape and position for the hand (Fig.\u00a01 External Hand-as-a-Prop). The external agent has to place his/her hand before the user approaches and grabs it. During the manipulation, (Fig.\u00a03 External Hand-as-a-Prop), the external agent has to let his/ her hand be moved and translated freely."
        },
        {
            "heading": "3.1.2 Self hand\u2011as\u2011a\u2011prop implementation",
            "text": "Initially, the user non-dominant hand is visualized in red and the user performs the matching gesture for the specific virtual object as seen in Fig.\u00a02 Self Hand-as-a-Prop. We used a static hand gesture detection method based on the distance between the joints to three pre-defined gesture poses. Upon\n1 3\ndetection of a gesture, the hand transforms into the object, meaning that it is ready to be grabbed as seen in Fig.\u00a02 Virtual Object. When the detected hand is grabbed, it cannot be tracked because it is being occluded by the dominant hand\u00a0(Fig.\u00a03 External Hand-as-a-Prop). At any time, if the grabbed hand becomes visible, it means that the object is not being grabbed anymore, and therefore, the virtual object is released."
        },
        {
            "heading": "4 User study",
            "text": "In this section, we evaluate the user experience and performance of the technique in a virtual reality manipulation task in order to answer our research questions: Is it possible to use human hands (either the user hand or an external person hand) to provide haptic feedback in Virtual Reality? Is it possible to represent different shapes? What is the effect in an object manipulation task?\nTo investigate these questions, we designed a within-subjects user study consisting of two different tasks; see Fig.\u00a04.\nThe first task (Exploration task) was to statically assess the goodness and realism of the physical representation of the objects. This task is based on experiments performed by McClelland et\u00a0al. (McClelland et\u00a0al. 2017) and Wobbrock et\u00a0al. (Wobbrock et\u00a0al. 2009) aimed at evaluating shapechanging haptic devices. This task was designed to evaluate object shape and haptic condition. Selected shapes were a cube, a cylinder, and flat volume, Fig.\u00a02 shows the virtual objects and their corresponding real objects that were 3D printed. Haptic conditions were External Hand-as-a-Prop (E_H), Self Hand-as-a-Prop (S_H), and traditional haptic feedback based on object props (O_P). In the Object Props case, an external human agent is employed to place the objects in the position of the virtual object.\nThe second task (translation task) was only aimed to evaluate the haptic condition. We evaluated the task completion time (TCT) manipulation time (MT), fatigue, realism, and goodness of the representation during a pick and place task. We follow guidelines from a recent research (Bergstr\u00f6m et\u00a0al. 2021) on the evaluation of virtual reality manipulation tasks \u201cDefine the goal of the evaluation: Choose speed\n1 3\nor accuracy\u201d: we decided to evaluate task completion time because in preliminary evaluations there were noticeable differences in that metric that made us investigate further."
        },
        {
            "heading": "4.1 Participants",
            "text": "We conducted the experiment with 12 participants, which aligns with the sample size commonly used in human\u2013computer interaction research with similar study designs, as recommended by previous works such as MacKenzie (2013) and Arif (2021). This approach was adopted because prior knowledge of the variance within a sample was not available, making it impractical to perform a priori power analysis for determining sample sizes.\nParticipants were 5 females, and 7 males between 20 and 45\u00a0years old, only two participants had not tried virtual reality before. Participants did not report motion sickness or any negative effect from virtual reality. Each participant performed the experiment individually and it took approximately 40\u00a0min per participant. After the exploration task and prior to performing the manipulation task, every participant was given a brief introduction for each haptic condition and had one minute to test the manipulation task with the corresponding haptic technique."
        },
        {
            "heading": "4.2 Procedure",
            "text": "We created a test environment with a virtual table, three objects (cylinder, sphere, and flat surface), and 6 areas where the objects should be placed during the translation task. Figure\u00a01 shows the virtual table, a virtual cube, and a target area. The virtual world was aligned so that the virtual table matched a real table (90\u00a0cm * 68\u00a0cm), the virtual and real objects also matched (cube = 7\u00a0cm side, cylinder = 5\u00a0cm diameter, 15\u00a0cm height, flat = 3,5 \u00d7 7 \u00d7 15\u00a0cm). Target areas were 6\u00a0cm squares, they were arranged in a 2 \u00d7 3 grid, separated by 21\u00a0cm vertically and 27\u00a0cm horizontally. Participants performed the tests sitting in an adjustable chair.\u00a0A head-mounted display was worn by the participants and they were instructed to remain seated during the experiment, but they still could change their point of view and move their torso and head. All the objects were within reach."
        },
        {
            "heading": "4.2.1 Exploration task",
            "text": "During each trial, one of the three virtual objects appeared on the table in front of the participants, where they could easily reach it with both hands. They were instructed to touch and explore the object. Once they explored the object, they were asked to answer two questions about the realism and the goodness of the representation of what they have physically explored. For goodness participants rated the statement \u201cthe virtual [object] is represented adequately by\nthe shape of what I just explored with my dominant hand\u201d, and for realism they rated the statement \u201cthe virtual [object] I just explored feels real\u201d. Under the Self Hand-as-a-Prop condition, participants were also asked for the easiness of performing the gesture. In this case they rated the statement \u201cthe shape of the virtual [object] is easy to perform with my non-dominant hand\u201d. The [object] was a Block, Cylinder or Flat. Each question used a Likert scale from \u22123 to 3, participants answered orally to avoid removing the headset in each trial. There was only one exploration of each shape by every user. Each user conducted 9 exploration tasks (3 conditions \u00d7 3 shapes), and this resulted in 108 trials."
        },
        {
            "heading": "4.2.2 Translation task",
            "text": "After the exploration task, the translation task started. During this task, one object appears in a pseudo-randomized area on the table, and in total, six areas were pre-defined on the table; for each condition 24 trials were performed, order and positions of objects are pseudo-randomized, but each shape appears 8 times. Positions and order are the same for all users. The participant had to grab and place the object on the target area, which is represented as a white rectangle on the table. Once they reach the target area, the contour of the object changes its color for 0.5\u00a0s and then stars emerge indicating that the trial has been completed. The first three trials were to warm-up and discarded from the analysis. At the end of the translation task, participants were asked to answer 8 questions about the easiness and realism of the translation of the objects, the fatigue of their dominant/non-dominant hands and arms, and two open questions where they could make general comments related to the objects\u2019 translation technique and the fatigue. Each question used a Likert scale from 1 to 7 or a textbox when it was an open question. Participants answered the questions using a laptop. We collected 864 trials = 12 participants \u00d7 3 Conditions \u00d7 24 trials."
        },
        {
            "heading": "4.3 Metrics",
            "text": "For the exploration task, participants were asked about the realism (i.e., \u201cthe explored object feels real\u201d) and representation goodness (i.e., \u201cthe explored object is correctly represented by what you just explored with your hand\u201d) of what they have physically explored. Under the Self Handas-a-Prop condition, they were also asked about the easiness (i.e., \u201cthe gesture was easy to perform\u201d) of performing the gesture (see Table\u00a01).\nFor the translation task, the software measured full completion time and manipulation time. Additionally, after each block, participants were asked to complete a questionnaire assessing realism (i.e., \u201cthe translation of the objects feels real\u201d), fatigue (i.e., assess how tired are the left and right arms and hands after the translation task), and easiness (i.e.,\n1 3\n\u201cthe translation of the objects was easy to perform\u201d) of the translation technique. Lastly, they were asked to rank the conditions from 1st to 3rd regarding their preference (see Table\u00a01)."
        },
        {
            "heading": "5 Results and\u00a0analysis",
            "text": ""
        },
        {
            "heading": "5.1 Task 1: exploration task",
            "text": "Two-way repeated-measures ANOVA was conducted to compare the effect of the three haptic feedback conditions (Self Hand-as-a-Prop S_H, External Hand-as-a-Prop E_H, Object Props O_P) and the different object shapes (Cylinder, Cube and Flat). We checked assumptions for ANOVA with Shapiro\u2013Wilk\u2019s test for normality and Mauchly\u2019s test for sphericity. Mauchly\u2019s tests indicate a violation for variables Representation Goodness and Gesture Ease and therefore Greenhouse\u2013Geisser adjustment were applied. F, p, and \u03b7 2 values of statistical significance are reported in Table\u00a02."
        },
        {
            "heading": "5.1.1 Perceived realism",
            "text": "The ANOVA results showed that the main effect of the haptic feedback condition was statistically significant (F(2, 22) = 32.435, p < 0.001, \u03b72 = 0.6) as well as the effect of the represented shapes (F(2, 22) = 9.874, p < 0.001). There was\nalso a significant interaction effect between the haptic feedback condition and the represented shapes (F(4, 44) = 3.713, p < 0.05).\nRegarding the haptic feedback condition, Post-hoc comparisons using Bonferroni corrections showed significant differences between E_H and O_P (p < 0.001) as well as between S_H and O_P (p < 0.001), but not between E_H and S_H.\nThe perceived realism in O_P is 2.6, corresponding to a high realism perception, while in S_H is 0.2 and in E_H is 0.3 (see Fig.\u00a05), both slightly over the middle point of the scale, suggesting a neutral realism perception for both conditions of Hand-as-a-Prop. O_P is perceived as the most realistic representation of virtual objects. The perceived representation of realism is similar for S_H (M = 0.2) and E_H (M = 0.3), suggesting that the perception of realism might not be affected by the sense of touch from your hand, but by the fact of touching a hand."
        },
        {
            "heading": "5.1.2 Representation goodness",
            "text": "Mauchly\u2019s test of sphericity indicates a violation and therefore Greenhouse\u2013Geisser adjustment was applied. The ANOVA results showed a significant main effect of the Feedback Condition (F(1.353, 14.887) = 33.774, p < 0.001,\u00a0\u03b72 = 0.565). There is also a significant main effect of the represented shapes (F(2, 22) = 7.785, p < 0.05) and an interaction effect Feedback Condition * object Shape (F(4, 44) = 3.526, p < 0.05).\nThe average representation of goodness for all shapes of the O_P condition is 2.56; it is significantly higher than E_H = 0.33 and S_H = 0.44 (see Fig.\u00a05). Both E_H and S_H are slightly higher than 0, suggesting a neutral-topositive perception of goodness.\nThe representation goodness is similar for S_H (M = 0.33) and E_H (M = 0.44), suggesting that both Hand-as-a-Prop variations are equally good whether they are external or the self.\nTable 1 Measures of dependent variables\nTask Metric Variable Measurement\nExploration User experience Realism Likert scale from \u22123 (low) to 3 (high) Representation goodness Gesture ease\nTranslation Performance Full task completion time (full TCT) Time from virtual object appearance until it is placed on the target Manipulation time (MT) Time from object grabbing until it is placed on the target\nUser experience Realism Likert scale from \u22123 (low) to 3 (high) Fatigue Translation ease Preference Ranking from 1 (most preferred) to 3 (least preferred)"
        },
        {
            "heading": "5.1.3 Objects shape",
            "text": "Regarding the object shapes, results show that the cylinder is perceived as the least realistic in S_H (M = \u22120.5, SD = 1.62) and E_H (M = \u22120.5, SD = 1.78), but not for the O_P (M = 2.58, SD = 0.76) where it had similar perceived realism as the other physical objects. Similarly, the cylinder representation goodness was considered the worst in the S_H (M = \u22120.25, SD = 1.865) and E_H (M = \u22120.33, SD = 1.723) but not in the O_P (M = 2.67, SD = 0.49) condition where it has a similar score to the other objects. Values slightly under the middle point of the scale suggest a neutral-to-negative rate. We interpret such results as a consequence of the shaping capabilities of the human hand which makes it more suitable to mimic a cube and a flat surface than a cylinder."
        },
        {
            "heading": "5.1.4 Gesture ease",
            "text": "Mauchly\u2019s test of sphericity indicates a violation and therefore Greenhouse\u2013Geisser adjustment was applied. The ANOVA results showed that there is no significant main effect of the represented object (F(1.185,13.036) = 2.437, p = 0.14, \u03b72 = 0.181); however effect size is not very high (Cohen, 1988). Thus, we cannot conclude that the three designed gestures were equally easy to perform. (Cylinder: M = 2, SD = 1.54, Cube: M = 2.58, SD = 0.79, Flat: M = 2.25, SD = 1.22)."
        },
        {
            "heading": "5.2 Task 2: translation task",
            "text": "Repeated-measures ANOVA was employed to compare the effect of the 3 conditions (Self Hand-as-a-Prop S_H, External Hand-as-a-Prop E_H, Object Prop O_P). We report on objective and subjective measurements. Outliers were filtered out (i.e., mean \u00b1 2 standard deviation). Shapiro\u2013Wilk\u2019s test results indicate data was normally distributed\nand Mauchly\u2019s test indicate sphericity is met. Post-hoc comparisons used Bonferroni corrections. F, p, and \u03b72 values of statistical significance are reported in Table\u00a03."
        },
        {
            "heading": "5.2.1 Time",
            "text": "We measured the full task completion time (Full TCT) and manipulation time (MT) at the translation task (see Fig.\u00a06).\n5.2.1.1 Full TCT Results showed a significance on TCT (F(2, 22) = 8.415, p = 0.002, \u03b72 = 0.433). The S_H (M = 4.61\u00a0 s, SD = 1.03) and E_H (M = 4.56\u00a0s, SD = 0.82) conditions are slower than O_P (M = 3.9\u00a0s, SD = 1.03). For Full TCT, S_H and E_H present similar results. Thus, S_H is slower during the initial stage of each trial, i.e., from when the object appears on the table until it is actually taken with the dominant hand. This could be a direct consequence of the extra time from the gesture recognizer in the S_H condition.\n5.2.1.2 Manipulation time (MT) Results showed a significant effect on MT (F(2, 22) = 42.507, p < 0.001, \u03b72 = 0.794) with differences between E_H (M = 2.66\u00a0 s, SD = 0.36) and O_P (M = 1.83\u00a0 s, SD = 0.42), but not between S_H (M = 2.04\u00a0 s, SD = 0.488) and O_P. S_H was also significantly faster than E_H (p < 0.001). Interestingly, there was no significant difference between S_H and O_P. Regarding\n1 3\nMT, results suggest that S_H and O_P conditions behave in a similar way, both faster than E_H. This indicates that moving someone else\u2019s hand implies more time than moving your own hand. Representing the object with your hand seems to be helpful in terms of coordination, i.e., the nondominant hand goes along with the dominant one assisting the translation movement."
        },
        {
            "heading": "5.3 Realism",
            "text": "Results showed a significant effect on the question \u201cvirtual object translation feels real\u201d (F(2, 22) = 8.134, p = 0.002, \u03b72 = 0.425), depending on the type of haptic feedback. Posthoc comparisons using Bonferroni corrections showed significant differences between O_P (M = 2.25, SD = 0.75) and S_H (M = 0.5, SD = 1.68) or E_H (M = 0.67, SD = 1.5) (see Fig.\u00a07).\nThe perceived realism for the translation under the O_P condition is 2.25, corresponding to a high realism perception, while the average perceived realism in S_H is 0.5 and in E_H is 0.67, suggesting a neutral-to-positive realism perception for the overall Hand-as-a-Prop. This confirms that\nO_P is perceived as the most realistic translation of virtual objects. The perceived translation realism is similar for S_H and E_H, suggesting that also during the translation of the objects, the perception of realism might not be affected by the sense of touch from the own hand."
        },
        {
            "heading": "5.4 Translation ease",
            "text": "Results showed a significant effect on the perceived realism question \u201cvirtual object translation was easy to perform\u201d (F(2, 22) = 6.937, p = 0.005, \u03b72 = 0.387), depending on the type of haptic feedback. Post-hoc comparisons using Bonferroni corrections showed significant differences between S_H (M = 1.67, SD = 1.23) and O_P (M = 2.58, SD = 0.52), and even stronger significant effects between E_H (M = 1.33, SD = 0.99) and O_P. The feedback condition evaluated as the easiest was O_P, then S_H, and lastly E_H (see Fig.\u00a08).\nThe average perceived ease for the translation under the O_P condition is 2.58, corresponding to a high easiness. For S_H is 1.67 and in E_H is 1.33, both are lower than O_P; however, results still suggest a high perception of ease for\n1 3\nthe overall Hand-as-a-Prop. O_P is perceived as the easiest translation, but Hand-as-a-Prop translation is also perceived as easy to perform.\nThe perceived translation ease is slightly higher for S_H than E_H, but the SD is also higher. It somehow suggests that both are perceived as easy to perform, but such a perception might be affected by the sense of touch, highly depending on each person."
        },
        {
            "heading": "5.5 Fatigue",
            "text": "Results showed a significant effect on fatigue (F(2,11) = 9.525, p = 0.001, \u03b72 = 0.462), depending on the type of haptic feedback. Post-hoc comparisons using Bonferroni corrections showed significant differences between S_H and O_P or E_H.\nIn every condition, fatigue of the right hand and arm as reported in questionnaires was similar (see Fig.\u00a08). In the S_H condition, fatigue of the left hand (M = \u22122, SD = 1.2) and left arm (M = \u22122, SD = 1.04) were higher than in E_H (Left Hand: M = \u22123, SD = 0, Left Arm: M = \u22122.92, SD = 0.29, p < 0.006) and O_P (Left Hand: M = \u22123, SD = 0, Left Arm: M = \u22123, SD = 0, p < 0.002) as reported in the questionnaires. In E_H and O_P, the left hand and arm fatigue was less than in the right, but not significantly. In all cases, the perceived fatigue is low, suggesting that none of the techniques causes significant fatigue."
        },
        {
            "heading": "5.6 User preference",
            "text": "User preference was collected in a rank order questionnaire (Fig.\u00a09). The preferred condition was O_P (chosen in the first place 75% of the times). S_H was the second preferred condition and was preferred in the first place 25% of the times. One participant who chose S_H as the preferred one expressed that \u201cgrabbing the object was easier than in the other techniques because I knew where my left hand was\u201d,\nthis suggests the benefits that proprioception might bring to this task. The E_H was the least preferred technique, it was never selected as the preferred one, and it was the most selected in the third position (66%). It seems that this technique does not feel real enough and at the same time is not easy to perform. Some participants expressed that it was difficult to move the external agent hand toward the target position, especially with the cylinder: \u201cI had to tilt the hand in order to reach the target\u201d, \u201cthe cylinder was more complex to place on the target and this made the exercise more difficult\u201d."
        },
        {
            "heading": "6 Discussion",
            "text": "The goal of this work was to determine the feasibility and impact of using hands (either the own hands or an external person hands) to provide haptic feedback for objects with different shapes in Virtual Reality in the context of a manipulation task. To this aim, we conducted a user study evaluating user experience and performance using qualitative and quantitative methods. Next, we discuss the main implications of using External or Self Hands-as-a-Prop, and compare them with traditional Object Props, in terms of their representation and translation capabilities."
        },
        {
            "heading": "6.1 Representation of\u00a0different object shapes",
            "text": "Through the exploration task, we investigated if different shapes can be represented by hand props, specifically, a cube, a cylinder, and a flat surface, similar shapes were used in shape-changing devices (McClelland et\u00a0al. 2017).\nUser questionnaires indicate, as expected, that a real object prop is perceived as the best match and the most realistic representation. The opinions of users toward using an external \u201chuman agent\u201d hand (E_H) or using their own\n1 3\nhand (S_H) to represent such shapes are lower but similar. The perception of realism and representation goodness for E_H and S_H was neutral-to-positive.\nThe cube and flat objects are easily represented by the human hand, whereas the cylinder is considered harder. The cylinder was represented only by one finger (see Fig.\u00a02 Real Hand) highlighting some of the limitations of the Hand-asa-Prop technique that should be considered when designing the map between hand gestures and objects. Even when the three gestures were rated as easy to perform (under the S_H condition), goodness and realism results suggest that shaping capabilities of the human hand are more suitable to mimic a cube and a flat surface than a cylinder. In general, O_P provided the best user experience while S_H and E_H were assessed as neutral-positive."
        },
        {
            "heading": "6.2 Manipulation performance and\u00a0user experience",
            "text": "One of the objectives of this research was to evaluate if it was possible to provide haptic feedback using only the hand (no props). We evaluated only manipulation performance in a translation task as recommended by Bergstr\u00f6m et\u00a0al. (2021). The results showed that manipulation times are similar between Self Hand-as-a-Prop and Object Props but significantly higher in the External Hand-as-a-Prop condition. This means that moving someone else\u2019s hand takes more time than moving an object prop or your own hand. Specifically, in the S_H case, the non-dominant hand might help to coordinate the translation movement and make it faster. When analyzing the Full TCT, the extra time to detect the non-dominant hand gesture might have influenced the user\u2019s performance, meaning that by optimizing gesture detection, S_H would provide even better results than E_H.\nRealism and ease of the sensation of holding and translating the virtual object showed significantly worse results in both Hand-as-a-Prop than in Object Props. However, as in the exploration tasks, results suggest that Hand-as-a-Prop is an easy to perform technique for translating objects, and realism was perceived as neutral-to-positive. All the techniques were assessed with a low fatigue perception. Object Prop provides the best user experience but Hand-as-a-Prop results are still positive.\nWhen we compare Self Hand-as-a-Prop with External Hand-as-a-Prop, the former technique does not require any external device or person. We might think that receiving external assistance leads to a better perception of the experience compared to using our own bodies. However, results indicate that there is no difference in terms of realism and ease during the translation task between Self and External Hand-as-a-Prop, suggesting that perception of realism might not be affected by the sense of touch from your \u201cown hand\u201d but just from using a hand, any hand.\nLastly, in terms of preference, O_P is the preferred technique. S_H was preferred over E_H, which was the least preferred technique. This preference of S_H over E_H might be interpreted as a partial consequence of proprioception \u201cself hand was easier than in the other techniques because I felt where my left hand was\u201d."
        },
        {
            "heading": "7 Summary",
            "text": "Overall, Hand-as-a-Prop (self or external) showed acceptable performance and it provided a neutral-to-positive User Experience in comparison with Object Props. Hand-as-aProp is a valid alternative to traditional static props for a virtual reality manipulation task. We conclude that Self Handas-a-Prop presents better results in terms of user experience and performance than External Hand-as-a-Prop, and it has the main benefit that it does not need external actuation (from a robot or a person).\nOur initial expectations were that External Hand-as-aProp might provide a more realistic experience than Self Hand-as-a-Prop because users will automatically find the object in the natural expected position, as in regular Object Props. We also expected Self Hand-as-a-Prop to present a better performance in terms of completion time since users could move both hands harmonically.\u00a0However, only the second assumption was proven true, the realism of the External Hand-as-a-Prop was not better than in Self. The External technique presents limitations in the translation tasks and the representation of different shapes compared to the Self Hand-as-a-Prop.\nThe perceived realism is affected because the props are human hands and the participants noticed it since the hand does not represent the virtual shape perfectly, it is an approximation. Many participants complained about the cylinder representation under this condition and one of them also mentioned that \u201cthe only thing that makes me feel not immersed is the temperature of the hand, I expected something colder\u201d. On the other hand, the translation can be problematic because moving someone else's hands might imply a kind of non-verbal negotiation in order to agree in the direction, orientation, and speed of the movement. Actually, one of the participants explained that \u201cExternal hand neither feels like a real object nor like something that has its own movement, it is confusing\u201d."
        },
        {
            "heading": "7.1 Limitations and\u00a0future work",
            "text": "In this work, we evaluated the feasibility of using Hand-asa-Prop within a manipulation task. In the study users were seated and only able to rotate the torso, head and arms, but walking was not considered. Further research should be done in this situation. Regarding the variety of the objects\n1 3\ninvolved in the study, we need to incorporate other objects with different sizes and shapes. The proposed technique is not suitable for tasks that require high haptic resolution such as surgery training. It is neither viable for simulating large objects like walls or doors in architecture design.\nResults for Self Hand-as-a-Prop technique might be biased by the hand gesture detection algorithm. Ideally, the gesture detection algorithm should be trained with the hands of each participant in order to improve its accuracy. Furthermore, the findings related to Self and External Hand-as-aProp might be biased by the Oculus built-in hand tracking algorithm since when hands overlap sometimes the recognition fails.\nIn the translation task under the External Hand-as-a-Prop technique, the external agent might bias the results by exerting more or less resistance to the user\u2019s movements or even unconsciously helping in the translation. Actually, one of the participants mentioned that \u201cIt felt less real, sometimes I had to tilt the external agent\u2019s hand in order to make the system detect that the object landed on the target\u201d. We understand that being the external agent requires certain training and expertise in order to avoid any kind of interference in the user\u2019s intended movements. Furthermore, another limitation of the External Hand-as-a-Prop technique is that it requires a display where the external agent checks the position of the virtual object that has to prop.\nLastly, in the Self Hand-as-a-Prop technique, the single hand manipulation is an intrinsic limitation of the technique, i.e., two objects cannot be manipulated independently by each hand.\nFuture work includes exploring how other object shapes can be represented by the hand, and whether visual dominance dominates over tactile shape as proposed by Rock and Victor (1964) and implementing and evaluating techniques with real-world complex tasks."
        },
        {
            "heading": "8 Conclusion",
            "text": "We designed and implemented a technique for providing haptic feedback while manipulating objects in virtual reality environments. The technique Hand-as-a-Prop employs a hand (the user or that from another person) as a proxy for the virtual object. We performed a user study to compare Handas-a-Prop with the traditional Object Props approach under a two-task experiment. The study showed that using Object Props provides the best user experience and performance within a manipulation task. Hand-as-a-Prop took more time to complete the tasks, with the exception of the manipulation time of using your own hand, which was similar to Object Props. The technique proved to be a feasible alternative which was rated with a neutral-to-positive user experience. Self Hand-as-a-prop provided better results than External\nHand-as-a-Prop with the benefit of not requiring the presence of any external agent. In particular, users preferred the Self Hand-as-a-Prop technique over the External Hand-asa-Prop for a translation task.\nWe hope that the results presented here would guide VR application developers in using the user\u2019s own hand as a representation for the virtual objects when some haptic feedback is required. When the VR user is accompanied by a colleague or helper, the External Hand-as-a-prop method will be useful if there are no prop objects available for example in casual gaming in the street or inspection of 3D models in remote locations. The Self Hand-as-a-prop method will be useful when no instructor or helper is available to provide haptics, for example in applications that require grasping and placing objects, i.e., self-training of machinery operators or instrumentation placement; or playing casual games alone without having to break immersion when searching for physical objects.\nFunding Open Access funding provided by Universidad P\u00fablica de Navarra. Sebastian Marichalar was funded by Public University of Navarra postdoc contract OTRI-2020\u2013901-135. This research was partially funded by the EU Horizon 2020 research and innovation programme under grant agreement No 101017746.\nData availability The datasets generated and analyzed during the current study are available from the corresponding author on reasonable request.\nDeclarations\nConflict of interest The authors declare no conflict of interest.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/."
        }
    ],
    "title": "Hand\u2010as\u2010a\u2010prop: using the hand as a haptic proxy for manipulation in virtual reality Sebastian Marichal1 \u00b7 In\u0303igo Ezcurdia1 \u00b7 Rafael Morales2 \u00b7 Amalia Ortiz1 \u00b7 Asier Marzo1 \u00b7 Oscar Ardaiz1",
    "year": 2023
}