{
    "abstractText": "The automatic projection filter is a recently developed numerical method for projection filtering that leverages sparse-grid integration and automatic differentiation. However, its accuracy is highly sensitive to the accuracy of the cumulantgenerating function computed via the sparse-grid integration, which in turn is also sensitive to the choice of the bijection from the canonical hypercube to the state space. In this paper, we propose two new adaptive parametric bijections for the automatic projection filter. The first bijection relies on the minimization of Kullback\u2013Leibler divergence, whereas the second method employs the sparse-grid Gauss\u2013Hermite quadrature. The two new bijections allow the sparse-grid nodes to adaptively move within the high-density region of the state space, resulting in a substantially improved approximation while using only a small number of quadrature nodes. The practical applicability of the methodology is illustrated in three simulated nonlinear filtering problems.",
    "authors": [
        {
            "affiliations": [],
            "name": "Muhammad F. Emzir"
        },
        {
            "affiliations": [],
            "name": "Zheng Zhao"
        },
        {
            "affiliations": [],
            "name": "Lahouari Cheded"
        },
        {
            "affiliations": [],
            "name": "Simo S\u00e4rkk\u00e4"
        }
    ],
    "id": "SP:6623e068197a8de8b47a1fb61af19906465005a7",
    "references": [
        {
            "authors": [
                "B. Hanzon",
                "R. Hut"
            ],
            "title": "New results on the projection filter,",
            "venue": "European Control Conference,",
            "year": 1991
        },
        {
            "authors": [
                "H.J. Kushner"
            ],
            "title": "On the differential equations satisfied by conditional probability densities of Markov processes",
            "venue": "with applications,\u201d Journal of the Society for Industrial and Applied Mathematics, Series A: Control, vol. 2, no. 1, pp. 106\u2013119",
            "year": 1964
        },
        {
            "authors": [
                "J. Armstrong",
                "D. Brigo"
            ],
            "title": "Nonlinear filtering via stochastic PDE projection on mixture manifolds in L2 direct metric,",
            "venue": "Mathematics of Control, Signals, and Systems,",
            "year": 2016
        },
        {
            "authors": [
                "S. Koyama"
            ],
            "title": "Projection smoothing for continuous and continuousdiscrete stochastic dynamic systems,",
            "venue": "Signal Processing,",
            "year": 2018
        },
        {
            "authors": [
                "A. Kutschireiter",
                "L. Rast"
            ],
            "title": "and J",
            "venue": "Drugowitsch, \u201cProjection Filtering with Observed State Increments with Applications in Continuous-Time Circular Filtering,\u201d IEEE Transactions on Signal Processing, vol. 70, pp. 686\u2013700",
            "year": 2022
        },
        {
            "authors": [
                "L.D. Brown"
            ],
            "title": "Fundamentals of Statistical Exponential Families with Applications in Statistical Decision Theory,",
            "venue": "Lecture Notes-Monograph Series,",
            "year": 1986
        },
        {
            "authors": [
                "R.E. Kass",
                "P.W. Vos"
            ],
            "title": "Geometrical Foundations of Asymptotic Inference",
            "venue": "ser. Wiley Series in Probability and Statistics. New York: Wiley",
            "year": 1997
        },
        {
            "authors": [
                "O. Calin",
                "C. Udri\u015fte"
            ],
            "title": "Geometric Modeling in Probability and Statistics",
            "venue": "Springer International Publishing",
            "year": 2014
        },
        {
            "authors": [
                "D. Brigo"
            ],
            "title": "Optimal Projection Filters,",
            "year": 2022
        },
        {
            "authors": [
                "W. Gautschi"
            ],
            "title": "Orthogonal Polynomials: Computation and Approximation",
            "venue": "ser. Numerical Mathematics and Scientific Computation. Oxford New York: Oxford university press",
            "year": 2004
        },
        {
            "authors": [
                "R.T. Rockafellar"
            ],
            "title": "Convex Analysis",
            "venue": "ser. Princeton Mathematical Series. Princeton, N.J: Princeton University Press",
            "year": 1970
        },
        {
            "authors": [
                "R. Herbrich"
            ],
            "title": "Minimising the Kullback\u2013Leibler Divergence,",
            "year": 2005
        },
        {
            "authors": [
                "T. Gerstner",
                "M. Griebel"
            ],
            "title": "Numerical integration using sparse grids,",
            "venue": "Numerical Algorithms,",
            "year": 1998
        },
        {
            "authors": [
                "T. Aubin"
            ],
            "title": "A Course in Differential Geometry",
            "venue": "ser. Graduate Studies in Mathematics. Providence, R.I: American Mathematical Society",
            "year": 2001
        },
        {
            "authors": [
                "M. Holtz"
            ],
            "title": "Sparse Grid Quadrature in High Dimensions with Applications in Finance and Insurance",
            "venue": "ser. Lecture Notes in Computational Science and Engineering. Heidelberg New York: Springer",
            "year": 2011
        },
        {
            "authors": [
                "B. Jia",
                "M. Xin",
                "Y. Cheng"
            ],
            "title": "Sparse Gauss-Hermite Quadrature Filter with Application to Spacecraft Attitude Estimation,",
            "venue": "Journal of Guidance, Control, and Dynamics,",
            "year": 2011
        },
        {
            "authors": [
                "L.N. Trefethen"
            ],
            "title": "Exactness of Quadrature Formulas,",
            "venue": "SIAM Review, vol. 64,",
            "year": 2022
        },
        {
            "authors": [
                "M. Hazewinkel",
                "S.I. Marcus",
                "H.J. Sussmann"
            ],
            "title": "Nonexistence of finite-dimensional filters for conditional statistics of the cubic sensor problem,",
            "venue": "Systems & Control Letters,",
            "year": 1983
        },
        {
            "authors": [
                "N. Chopin"
            ],
            "title": "An Introduction to Sequential Monte\u2013Carlo",
            "venue": "Cham, Switzerland: Springer",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014 projection filter, adaptive bijection, numerical quadrature, automatic differentiation, sparse-grid integration\nI. INTRODUCTION The projection filter [1], [2] is an approximate optimal filtering method based on projections of probability densities on manifolds. Specifically, the filter projects the Kushner\u2013Stratonovich equation [3] of the optimal filtering solution onto a finite-dimensional manifold of parametric densities, producing a finite-dimensional stochastic differential equation (SDE) representation. When the manifold is the manifold formed by mixtures of probability densities and the L2 metric is used, then the projection filter is equivalent to a Galerkin method for solving the Kushner\u2013Stratonovich equation (see [4, Theorem 5.1]).\nThe projection filter has so far been used only in limited scenarios. Outside of the Gaussian family, the most prevalent applications have been in univariate dynamical systems [2], [5]\u2013[7]. Recently, Emzir et al. [8] introduced an automatic projection filter for a wider class of filtering problems. Although the method is applicable to a large class of multivariate dynamical systems, its computational can be demanding for using a large number of quadrature nodes [8]. Using a large number of nodes is often needed because of the fixed (rather than an adaptive) bijection between the canonical hypercube and the integration domain. In the other way around, the fixed bijection also practically limits the numerical accuracy of the filter when the computational budget is limited.\nIn this study, we propose two bijections that transform the nodes of sparse-grid quadratures to adaptively cover the high-density domain of the projected conditional densities. The main challenge in constructing such bijections is found to be the impossibility of obtaining a bijection that transforms the integrand into a polynomial function in the transformed space, thereby achieving zero integration error (see Proposition 1). Further, we show that using squared integration error as an optimization cost function also leads to non-explicit bijection functions (see Proposition 2). To overcome these difficulties, in the first bijection, we minimize the Kullback\u2013Leibler divergence between the projected conditional density and a Gaussian density via moment matching (see Proposition 3). Not only does this result in an explicit bijection form, but it also optimizes the squared integration error under certain technical conditions (see Proposition 4). We then adapt this technique to Gauss\u2013Hermite quadrature.\nWhen the automatic projection filter algorithm is combined with these bijections, the part of the state space which has a high filtering density can be automatically tracked. This improvement requires much fewer quadrature nodes than those using static bijections. We illustrate the effectiveness of the proposed bijections using three numerical examples where it is challenging to confine conditional densities inside a fixed domain. We also generalize the filtering problems in comparison to [8] by only requiring that the drift and diffusion functions belong to a vector space that is closed under partial differentiation.\nThe paper is organized as follows. We first review the projection filter for the exponential family in Section II, and then explain how to propagate the SDE parameters using numerical integration and automatic differentiation. Section III delivers the main contributions of the paper, which are the two new bijections from the canonical hypercube to the state space of the projection filter. Section IV shows the practical applicability of the bijections in the automatic projection filter in three simulated nonlinear filtering problems. Finally, Section V summarizes the results and concludes the paper."
        },
        {
            "heading": "II. AUTOMATIC PROJECTION FILTER",
            "text": "In this section, we review the relevant theoretical results that constitute the foundation of the automatic projection filter [8] and also to present the extension of the model considered in this paper. We consider optimal filtering problems on the following statespace model consisting of continuous-time stochastic dynamic and observation models:\ndxt = f(xt) dt+ \u03f1(xt) dWt, (1a)\ndyt = h(xt) dt+ dVt, (1b)\nwhere xt \u2208 X := Rd, yt \u2208 Y := Rdy . The processes {Wt, t \u2265 0} and {Vt, t \u2265 0} are independent Wiener processes taking values in Rdw and Rdy with invertible spectral density matrices Qt and Rt for all t \u2265 0, respectively. For the sake of exposition, and without a loss of generality, in the rest of the paper, we assume that Rt = I for all t \u2265 0.\nThe conditional probability density of the state at time t, space xt, given a history of measurements y\u03c4 , 0 \u2264 \u03c4 \u2264 t, satisfies the Kushner\u2013Stratonovich equation [3]. Let us define a class of probability densities P with respect to the Lebesque measure on X as P = {p \u2208 L1 : \u222b X p(x) dx = 1, p(x) \u2265 0, \u2200x \u2208 X}. In particular, let us consider the exponential family\nEM(c) := { p \u2208 P : p(x) = exp ( c(x)\u22a4\u03b8 \u2212 \u03c8(\u03b8) )} , (2)\nwhere \u03b8 \u2208 \u0398 \u2282 Rm is the natural parameter and c : Rd \u2192 Rm is a vector of natural statistics that are assumed to be linearly independent. The natural parameter space \u0398 is defined as\n\u0398 := { \u03b8 \u2208 Rm : \u222b X exp ( c(x)\u22a4\u03b8 ) dx <\u221e } . (3)\nAn exponential family is said to be regular if \u0398 is an open subset of Rm. In this work, we focus on regular exponential families. In the development of the proposed improved projection filter, we\nar X\niv :2\n30 3.\n17 29\n0v 2\n[ m\nat h.\nO C\n] 2\n1 Se\np 20\n23"
        },
        {
            "heading": "2 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2017",
            "text": "extensively use the cumulant-generating function (i.e., the log Laplace transform or log partition function [8], [9]) defined by\n\u03c8(\u03b8) = log [\u222b X exp ( c(x)\u22a4\u03b8 ) dx ] , \u03b8 \u2208 \u0398. (4)\nBecause the exponential family is assumed to be regular and the natural statistics are linearly independent, the exponential family is minimal [10], [11]. We recall the following standard result for a minimal regular exponential family [10, Theorems 2.2.1 and 2.2.5].\nTheorem 1. In a regular exponential family, the set \u0398 as defined in (3) is convex. The cumulant-generating function \u03c8(\u03b8) is strictly convex on \u0398 and it is differentiable up to an arbitrary order. The moments of the natural statistics ci(x), i = 1, . . . ,m exist for any order, and the expectations of ci and the corresponding Fisher information matrix g are, respectively, given by,\nE\u03b8 [ci] = \u2202\u03c8(\u03b8)\n\u2202\u03b8i , gi,j(\u03b8) =\n\u22022\u03c8(\u03b8) \u2202\u03b8i\u2202\u03b8j . (5)"
        },
        {
            "heading": "If the representation is minimal, then g is positive definite.",
            "text": "Let us denote by S = {p\u03b8 : \u03b8 \u2208 \u0398 \u2286 Rm} a class of parametric densities which does not have to be the exponential family. There are a few approaches that can be used to project the Kushner\u2013 Stratonovich equation onto the manifold of parametric densities [12]. The standard way is to leverage the property that the square root of the density \u221a pt belongs to L2. Therefore, by requiring that the stochastic differential d \u221a pt is an element of L2 and by expressing the Kushner\u2013Stratonovich equation in its Stratonovich form, we can project d\n\u221a pt onto the tangent space T\u221ap\u03b8S\n1/2. This is elucidated in the following lemma [2, Lemma 2.1].\nLemma 1. Let p\u03b8 \u2208 S, and u be a function such that Ep\u03b8 [|u| 2] <\u221e. Then the projection of v := u \u221a p\u03b8 \u2208 L2 onto the tangent space T\u221ap\u03b8S 1/2 is given by\n\u03a0\u03b8v = m\u2211 i=1 m\u2211 j=1 4g\u22121ij \u2329 v, 1 2 \u221a p\u03b8 \u2202p\u03b8 \u2202\u03b8j \u232a 1 2 \u221a p\u03b8 \u2202p\u03b8 \u2202\u03b8i , (6)\nwhere the inner product is defined as \u27e8u, v\u27e9 = \u222b u(x) v(x) dx.\nFor the exponential family EM(c), the projection filter using Stratonovich projection is given by [2]:\nd\u03b8t = g(\u03b8t) \u22121E\u03b8t\n[ L [c]\u2212 1\n2 h\u22a4h [c\u2212 \u03b7(\u03b8t)]\n] dt\n+ g(\u03b8t) \u22121 dy\u2211 k=1 E\u03b8t [hk [c\u2212 \u03b7(\u03b8t)]] \u25e6 dyt,k. (7)\nIn the equation above, E\u03b8 is the expectation with respect to the parametric probability density p\u03b8 , hk is the k-th element of h, \u03b8t 7\u2192 \u03b7(\u03b8t) := E\u03b8t [c], L is the backward Kolmogorov diffusion operator, and \u25e6 denotes the Stratonovich multiplication.\nWe can now extend the class of state-space models considered in [8] as follows. Let P be a set of smooth functions \u03c6 : Rd \u2192 R such that P is a finite-dimensional vector space that is closed under partial differentiation with respect to x1, . . . , xd. Examples of sets P are polynomials on x1, . . . , xd with a total order less or equal to some k \u2208 N and functions of the form f(x) = \u2211nk j=1 ajcos(k \u22a4 j x)+ bjsin(\u2113\u22a4j x), with aj , bj \u2208 R, kj , \u2113j \u2208 Z d, and nk \u2208 N. We use the following assumptions on the model (1).\nAssumption 1. Elements of functions f, h, and \u03f1\u03f1\u22a4 belong to P .\nAssumption 2. The natural statistics {ci} are selected as linearly independent elements of P .\nAssumption 3. Each element of h is in the span of {1, c1, . . . , cm}. This means there exists \u03bbk \u2208 Rdy for k = 0, . . . ,m, such that h = \u03bb0 + \u2211dy k=1 \u03bbkck.\nUnder Assumption 3, the resulting exponential family of probability densities is known as the EM(c\u2217) family [2]. For this specific family, the projection filter equation reduces to [2, Theorem 6.3]\nd\u03b8t = g(\u03b8t) \u22121E\u03b8t\n[ L [c]\u2212 1\n2 (h\u22a4h) [c\u2212 \u03b7(\u03b8t)]\n] dt+ dy\u2211 k=1 \u03bbkdyt,k,\n(8) Assumptions 1 and 2 ensure that every element of {L[c], h\u22a4h, h\u22a4hc} belongs to a larger vector space P\u0303 spanned by the basis of P and a finite number of multiplications of basis functions of P . Explicitly, we can write L[c]\u2212 12 (h\n\u22a4h)c = a0+A0c\u0303 and 12 (h \u22a4h) = b0 + b\u22a4h c\u0303, where a0 \u2208 R m, A0 \u2208 Rm\u00d7(m+mh), b0 \u2208 R, bh \u2208 R(m+mh), and c\u0303\u22a4 = [c\u22a4, c\u22a4h ]. Note that ch : Rd \u2192 Rmh is the vector of the remaining statistics of x that are linearly independent of the elements of c. Therefore, under these assumptions, Equation (8) can be expressed as\nd\u03b8t = g(\u03b8t) \u22121 [a0 + b0\u03b7(\u03b8t) +M(\u03b8t)\u03b7\u0303(\u03b8t)] dt+ \u03bbdyt, (9)\nwhere \u03bb = [\u03bb1, . . . , \u03bbm]\u22a4, M(\u03b8t) = A0 + \u03b7(\u03b8t)b\u22a4h , and \u03b7\u0303(\u03b8t) := E\u03b8t [c\u0303].\nIn order to solve (9), we need to compute the expectation \u03b7\u0303 and the Fisher metric g. In the automatic projection filter [8], the Fisher metric g is obtained by automatic differentiation of the approximated cumulant-generating function via Theorem 1. The cumulantgenerating function can approximated via Gauss\u2013Chebyshev quadrature in the univariate case or via sparse-grid integration methods in the multivariate case. For the expected values of the extended statistics \u03b7\u0303, the automatic projection filter uses the following lemma to calculate the remaining expectations in (9) [8, Proposition 5.2].\nLemma 2. Let s(x) : Rd \u2192 R be a statistic, linearly independent of the natural statistics c(x). If there exists an open neighborhood about the zero \u03980 such that for c\u0303 := [c\u22a4(x) s(x)]\u22a4, the quantity \u03c8\u0303(\u03b8\u0303) := log (\u222b X exp ( c\u0303\u22a4\u03b8\u0303 ) dx ) <\u221e for any \u03b8\u0303 \u2208 \u0398\u00d7\u03980, then for any \u03b8 \u2208 \u0398\nE\u03b8[s] = \u2202\u03c8\u0303(\u03b8\u0303)\n\u2202\u03b8\u0303m+1 \u2223\u2223\u2223\u2223 \u03b8\u0303=\u03b8\u2217 , \u03b8\u2217 = [ \u03b8 0 ] ."
        },
        {
            "heading": "III. ADAPTIVE PARAMETRIC BIJECTIONS",
            "text": "In this section, we present the key contributions of this paper. Before doing so, let us first see the difficulties for adopting a static bijection, as was done in [8]."
        },
        {
            "heading": "A. Challenges of static bijection",
            "text": "Although the automatic projection filter has been shown to perform well with multivariate dynamics [8], it unfortunately requires a large number of quadrature nodes. This is due to the need for the accurate computation of the exponential of the cumulant-generating function (4), which is done via numerical integration. To compute the cumulant-generating function for a parametric density p\u03b8 a fixed smooth bijection \u03d5 : D \u2192 X is used, where D := (\u22121, 1)d is the canonical hypercube. Because during filtering, the high-density region of the filtering density moves within Rd, fixing the bijection can lead to numerical instabilities. To illustrate this, let us denote by X\u0303 = {x\u0303i}Ni=1 the set of quadrature nodes in the canonical hypercube and consider the univariate case with p\u03b8(x) =\n1\u221a 2\u03c0\nexp ( \u2212(x\u2212 \u03b8)2/2 ) and \u03d5 = tanh\u22121(x\u0303). In the domain D, when a substantial part of\nAUTHOR et al.: PREPARATION OF BRIEF PAPERS FOR IEEE TRANSACTIONS AND JOURNALS (FEBRUARY 2017) 3\nthe bijected nodes \u03d5(X\u0303) lies outside the high-density interval, the function \u03d5\u2032(x\u0303) p\u03b8(\u03d5(x\u0303)) moves to edge of D, and is almost zero at the other edge. Fig. 1 illustrates this effect with \u03b8 being either 0 or \u03c0/2, and by using only 16 quadrature nodes, {\u03d5(x\u0303i)} does not cover the region of high p\u03b8 value as \u03b8 moves away from zero. Even worse, when \u03b8 is far from zero, increasing the number of quadrature nodes does not noticeably decrease the integration error. We show how to address this problem in the next section."
        },
        {
            "heading": "B. First Gaussian-Based Parametric Bijection",
            "text": "The aforementioned challenges motivates us to propose a new parametric bijection \u03d5\u03be , where the bijection parameter \u03be \u2208 Rn\u03be , n\u03be \u2208 N can be used to reduce the numerical integration error. Let us first consider the univariate case and introduce a parametric probability density q\u03be with support R. Then \u03b6\u03be(x) := 2 \u222b x \u2212\u221e q\u03be(y)dy \u2212 1 is a valid bijection from R\u2192 D. Now let us choose an exponential family manifold with m natural parameters. Choosing \u03d5\u03be = \u03b6 \u22121 \u03be , we can rewrite the exponential of the cumulant-generating function as\nexp(\u03c8(\u03b8)) = \u222b D exp ( c(\u03d5(x\u0303))\u22a4\u03b8 ) 1 2q\u03be(\u03d5(x\u0303)) dx\u0303. (10)\nInstead of directly numerically computing this function using its definition (4), it is beneficial to use this transformed integral representation instead. The accuracy of the quadrature approximation to this integral depends on the choice of q\u03be . Recall that a Gaussian quadrature rule with N quadrature nodes is exact when the integrand is chosen to be a polynomial of order 2N\u22121 or less [13]. Therefore, in order to get an accurate integration result, we can choose a q\u03be such that the integrand is close to a polynomial of order 2N \u2212 1 or less. In fact, if we chose q\u03be to be exactly p\u03b8 , then we would have the integrand equal to 12 exp(\u03c8(\u03b8)). This would mean that the integration result would be exact, thus avoiding any integration errors. However, in the following proposition we show that there is no such\na bijection that can be evaluated explicitly and makes the integrand in (10) a polynomial.\nProposition 1. Let \u03d5 be a bijection from D to R and let EM(c) be the exponential family given by (2) with parameters \u03b8 \u2208 \u0398, where \u0398 is given by (3). If there is no explicit antiderivative for \u03b2(x) := exp ( c(x)\u22a4\u03b8 ) as a function of x, then there is no explicit bijection \u03d5 such that \u03b2(\u03d5(x\u0303))\u03d5(x\u0303)\u2032 is a polynomial of x\u0303.\nProof. Suppose \u03b2(\u03d5(x\u0303))\u03d5(x\u0303)\u2032 = \u03c1n(x\u0303), where \u03c1n is a polynomial of order n in x\u0303. Integrating both sides gives\nlim s\u2217\u2193\u22121 \u222b x\u0303 s=s\u2217 \u03b2(\u03d5(s)) d\u03d5(s) ds ds = lim s\u2217\u2193\u22121 \u222b x\u0303 s=s\u2217 \u03c1n(s) ds,\nlim s\u2217\u2193\u22121 \u222b \u03d5(x\u0303) \u03d5=\u03d5(s\u2217) \u03b2(\u03d5) d\u03d5 = \u222b x\u0303 s=\u22121 \u03c1n(s) ds = \u03c1\u0304n(x\u0303),\nwhere \u03c1\u0304n is a polynomial because \u03c1n is. Since the antiderivative of \u03b2 has no explicit form, there is no explicit form for \u03d5 neither.\nEven if the explicit antiderivative of \u03b2(x) does exist, that is,\u222b \u03b2(x) dx = \u03b2\u0304(x) + C, then solving for the bijection \u03d5 might still be impossible as \u03b2\u0304(\u03d5) might not be invertible. Therefore, instead of aiming at zero integration error, we focus on finding a parametric bijection, or a family of them, which leads to a smaller integration error. For this purpose, let us use a d-dimensional numerical quadrature with a positive weight function \u03c9(x\u0303) and with N quadrature nodes as\nQd,\u03c9N g := \u222b D g(x\u0303)\u03c9(x\u0303) dx\u0303 \u2248 N\u2211 i=1 wi g(x\u0303i), (11)\nwhere x\u0303i are the nodes and wi are the weights of the quadrature rule. The weighting function \u03c9(x\u0303) varies for different quadrature schemes. It is well-known that for a univariate Gauss-type quadrature, the quadrature nodes are distinct, and the weights {wi}Ni=1 are positive [13, Theorem 1.46]. As a generalization of one-dimensional bijection \u03d5\u03be , where \u2202\u03d5\u03be \u2202x\u0303 = (2q\u03be(x))\n\u22121, in multivariate context, the bijection operator (also denoted as \u03d5\u03be) is constructed from q\u03be ,\nwhere \u2223\u2223\u2223det \u2202\u03d5\u03be\u2202x\u0303 \u2223\u2223\u2223 = (2dq\u03be(x))\u22121. By using the quadrature rule, we can approximate the expectation of an arbitrary function f(x) with respect to the density p\u03b8 by\nE\u03b8,N [f ; \u03be] := Q d,\u03c9 N [ f(\u03d5\u03be)u(\u03d5\u03be)\u03c9 \u22121 ]\n(12)\nwhere u(x) := p\u03b8(x)/(2 dq\u03be(x)).\nThe operator f 7\u2192 E\u03b8,N [f ; \u03be] is linear, but it does not guarantee that E\u03b8,N [1; \u03be] = 1. The following lemma lists four important properties of this operator that we will use in the subsequent developments.\nLemma 3. If the approximation of the cumulant-generating function using N quadrature nodes is given by \u03c8(\u03b8)(N) = log ( Qd,\u03c9N [ exp ( c(\u03d5\u03be) \u22a4\u03b8 )\u2223\u2223\u2223det \u2202\u03d5\u03be\u2202x\u0303 \u2223\u2223\u2223\u03c9\u22121]), then the following hold:\n1) E\u03b8,N [1; \u03be] = exp\n( \u03c8(\u03b8)(N) ) exp(\u03c8(\u03b8)) ,\n2) \u2202\u03c8(\u03b8)(N)\n\u2202\u03b8j =\nE\u03b8,N [ cj ; \u03be ] E\u03b8,N [1; \u03be] ,\n3) \u22022\u03c8(\u03b8)(N)\n\u2202\u03b8j\u2202\u03b8k =\nE\u03b8,N [ cjck; \u03be ] E\u03b8,N [1; \u03be] \u2212 E\u03b8,N [ cj ; \u03be ] E\u03b8,N [1; \u03be] E\u03b8,N [ck; \u03be] E\u03b8,N [1; \u03be] ,\n4) E\u03b8,N [f ; \u03be] E\u03b8,N [1; \u03be]\n= \u2211N i=1 wif(\u03d5\u03be(x\u0303i))\n\u00d7 exp ( c(\u03d5(x\u0303i) \u22a4\u03b8 \u2212 \u03c8(\u03b8)(N)) )\u2223\u2223\u2223det \u2202\u03d5\u03be\u2202x\u0303 \u2223\u2223\u2223\u03c9(x\u0303i)\u22121."
        },
        {
            "heading": "4 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2017",
            "text": "Proof. For the first equality, using the definition (12), we get:\nE\u03b8,N [1; \u03be] = Q d,\u03c9 N [ u(\u03d5\u03be)\u03c9 \u22121 ] ,\n= Qd,\u03c9N\n[ exp ( c(\u03d5\u03be) \u22a4\u03b8 \u2212 \u03c8(\u03b8) )\u2223\u2223\u2223\u2223det \u2202\u03d5\u03be\u2202x\u0303 \u2223\u2223\u2223\u2223\u03c9\u22121]\n= exp\n( \u03c8(\u03b8)(N) ) exp(\u03c8(\u03b8)) .\nThe second and third equalities follow directly by taking derivatives of \u03c8(\u03b8)(N) with respect to \u03b8j , and with respect to \u03b8j and \u03b8k. The fourth equality follows from the first.\nA natural way to choose the parameter \u03be is by minimizing the square of numerical integration error of (10), that is, ( exp(\u03c8(\u03b8))\u2212\nexp ( \u03c8(\u03b8)(N) ))2. Let us define the integration error EN [f(x); \u03be] as follows:\nEN [f ; \u03be] := E\u03b8[f ]\u2212 E\u03b8,N [f ; \u03be]. (13) Then, since exp(\u03c8(\u03b8)) \u2212 exp ( \u03c8(\u03b8)(N) ) = exp(\u03c8(\u03b8))(1 \u2212 E\u03b8,N [1; \u03be]), minimizing the square of the numerical integration error of (10) is equivalent to minimizing EN [1; \u03be]\n2. The following proposition gives a necessary and sufficient condition such that the squared error EN [1; \u03be]\n2 is a convex function. We denote the partial ordering of two squared matrices as A \u2ab0 B if A \u2212 B is a positive semidefinite matrix.\nProposition 2. Let u(x) = p\u03b8(x) 2dq\u03be(x)\n, where q\u03be = exp ( c\u0303(x)\u22a4\u03be \u2212\n\u03c8(\u03be) ) , c(x) and c\u0303(x) \u2208 C2(R) are the natural statistics of p\u03b8 and q\u03be , respectively, \u03c8(\u03be) is the cumulant-generating function corresponding to q\u03be , and \u03d5\u03be is a smooth bijection from D to Rd constructed from q\u03be . Also, let \u039e := {\u03be \u2208 Rn\u03be : \u03c8(\u03be) <\u221e}. Then EN [1; \u03be]2 is convex on an open convex set \u039e0 \u2286 \u039e, if and only if for any \u03be \u2208 \u039e0, the following condition is satisfied:\nE\u03b8,N [ 1\nu\ndu d\u03be ; \u03be\n] E\u03b8,N [ 1\nu\ndu d\u03be ; \u03be\n]\u22a4 \u2ab0 EN [1; \u03be]E\u03b8,N [ 1\nu\nd2u d\u03be2 ; \u03be\n] .\n(14)\nProof. Using the definitions of EN [1; \u03be] and E\u03b8,N [\u00b7] from (13) and (12) respectively, we can write\n1\n2\n\u2202EN [1; \u03be] 2\n\u2202\u03be = \u2212EN [1; \u03be]E\u03b8,N\n[ 1\nu\ndu d\u03be ; \u03be\n] (15)\nand\n1\n2\n\u22022EN [1; \u03be] 2\n\u2202\u03be2 = E\u03b8,N\n[ 1\nu\ndu d\u03be ; \u03be\n] E\u03b8,N [ 1\nu\ndu d\u03be ; \u03be ]\u22a4 \u2212 EN [1; \u03be]E\u03b8,N [ 1\nu\nd2u d\u03be2 ; \u03be\n] . (16)\nTherefore, if for any \u03be \u2208 \u039e0, condition (14) is satisfied, then \u22022EN [1;\u03be] 2\n\u2202\u03be2 is positive semidefinite. By [14, Theorem 4.5] EN [1; \u03be]\n2\nis a convex function on \u039e0. The necessary part can be obtained using a similar argument to the proof of [14, Theorem 4.5].\nWe can now highlight two difficulties of using gradient-based method to find the minimizer of EN [1, \u03be]\n2. First, by parts 1) and 4) of Lemma 3, the Jacobian and Hessian of EN [1; \u03be]\n2 with respect to \u03be, which are given respectively by (15) and (16), cannot be explicitly calculated unless the cumulant-generating function \u03c8(\u03b8) is known in a closed form. Secondly, it is impossible to ensure the criterion that EN [1, \u03be]\n2 is locally convex even on some bounded interval since its Hessian cannot be evaluated. As a consequence, using gradient methods or (quasi-)Newton methods for finding a locally optimal \u03be is not feasible.\nWith that being said, a more promising approach is to select \u03be such that q\u03be covers the high-density area of p\u03b8 as tightly as possible by optimizing another criterion as explained below, and the resulting bijection \u03d5\u03be should then be amenable to direct computation. This turns out to be a viable approach to take, and the thus-constructed bijection could be shown to work in practice as well as be optimal with respect to the squared integration error, under some technical conditions. Our starting point is the following lemma [15].\nLemma 4. Let q\u03be be a density from an exponential family with natural statistics given by c\u0303(x). For any distribution p, the distribution q\u2217\u03be that minimizes KL(p||q\u03be), satisfies\nEq\u2217 \u03be [c\u0303] = Ep [c\u0303] . (17)\nEssentially, the exponential density q\u03be that minimizes the KL(p||q\u03be) distance satisfies the moment-matching equality (17). If we choose q\u03be to be a Gaussian density, then the mean \u00b5 and variance \u03a3 of q\u03be should satisfy\n\u00b5i = E\u03b8 [xi] , i = 1, . . . , d, (18a) \u03a3ij = E\u03b8 [ (xi \u2212 \u00b5i)(xj \u2212 \u00b5j) ] , i, j = 1, . . . , d. (18b)\nIn the actual implementation, we replace the cumulant-generating function by its approximation \u03c8(\u03b8)(N) that is obtained from numerical integration using N quadrature nodes. Since the approximation errors of the parameters \u00b5 and \u03a3, as well as the cumulantgenerating function \u03c8(\u03b8), depend linearly on the integration errors on\u222b exp ( c\u22a4x ) dx, then selecting an N such that all the approximation errors for \u00b5, \u03a3, and \u03c8(\u03b8) are simultaneously kept below their acceptable upper limits, is feasible (see [8, Theorem 3.1]).\nIn the following proposition, we show how to construct a smooth bijection \u03b6\u03be from Rd to D using a parametric density q\u03be . We also show that its inverse \u03d5\u03be = \u03b6 \u22121 \u03be can be expressed in a closed form when using Gaussian density q\u03be with parameters in (18).\nProposition 3. Let s : Rd \u00d7 P \u2192 D defined by\ns(z, q\u03be) = s1(z1, q\u03be)... sd(zd, q\u03be) , (19a) si(zi, q\u03be) = 2 \u222b zi \u2212\u221e q\u03be(z1, . . . , yi, . . . , zd)dyi\u222b\u221e \u2212\u221e q\u03be(z1, . . . , yi, . . . , zd)dyi \u2212 1. (19b)\nIf q\u03be is a smooth density with support equal to Rd, then s(\u00b7, q\u03be) is a smooth bijection from Rd onto D.\nAssume that q\u03be is a Gaussian density with mean \u00b5 and covariance matrix \u03a3 \u227b 0, and let the eigendecomposition of \u03a3 be given by \u03a3 = T\u22121\u039bT , where T is unitary. Let q\u0303\u03be be another Gaussian density with mean at T\u00b5 and variance \u039b. Define \u03b6\u03be : Rd \u2192 D as \u03b6\u03be(x) = s(Tx, q\u0303\u03be). Then\n\u2223\u2223\u2223det \u2202\u03b6\u03be\u2202x \u2223\u2223\u2223 = 2dq\u03be . Moreover, the inverse of \u03b6\u03be , denoted as \u03d5\u03be : D \u2192 Rd, is given by\n\u03d5\u03be(x\u0303) = \u00b5+ \u221a 2T\u22121\u039b1/2 erf\u22121(x\u0303), x\u0303 \u2208 D (20)\nwhere erf\u22121(x\u0303) = [ erf\u22121(x\u03031), . . . , erf\u22121(x\u0303d) ]\u22a4 .\nProof. Each si(zi, q\u03be) is a smooth bijection from R to (\u22121, 1). By the definition of s, for each x\u0303 \u2208 D there exists z \u2208 Rd such that s(z, q\u03be) = x\u0303. Let z, y \u2208 Rd, and suppose s(z, q\u03be) = s(y, q\u03be). Since si(zi, q\u03be) is a smooth bijection, zi must equal to yi, which leads to z = y. The smoothness of \u03b6\u03be follows from that of si(zi, q\u03be) for each i.\nFor the second part, it can be verified that with z = Tx\nand \u00b5z = T\u00b5 we have si(zi, q\u0303\u03be) = erf( \u039b \u22121/2 ii (zi\u2212\u00b5z,i)\u221a\n2 ).\nAUTHOR et al.: PREPARATION OF BRIEF PAPERS FOR IEEE TRANSACTIONS AND JOURNALS (FEBRUARY 2017) 5\nThen since T is unitary, we get \u2223\u2223\u2223det \u2202\u03b6\u03be\u2202x \u2223\u2223\u2223 = \u2223\u2223\u2223det \u2202s(z,q\u0303\u03be)\u2202z \u2223\u2223\u2223 =\u220fd\ni=1 2 1\u221a\n2\u03c0\u039bii exp\n( \u2212 12 (zi \u2212 \u00b5z,i) 2 )\n= 2dq\u03be . The inverse of \u03b6\u03be can be obtained directly from the definition of si\nProposition 3 tells us that for any non-degenerate Gaussian density q\u03be , there exists a bijection \u03b6\u03be such that the transformation of an infinitesimal volume dx on Rd under \u03b6\u03be is equivalent to 2dq\u03be times dx\u0303. The bijection \u03d5\u03be given by (20) can be interpreted as the following consecutive operations. First it transforms the quadrature nodes from the canonical hypercube to Rd by the inverse error function, then it scales each axis by the appropriate square roots of the eigenvalues of \u03a3. Afterwards, it rotates the quadrature nodes according to the unitary matrix T . Lastly it shifts the quadrature nodes by \u00b5 from the origin; see the middle columns of Figures 4 for an illustration of these operations. In the numerical implementation, we will use this bijection to project the Gauss\u2013Chebyshev nodes (for univariate case), or the sparse Gauss\u2013Patterson nodes (for multivariate case), fromD to Rd (see [16] for details). We will refer to these numerical integrations as the Gauss\u2013Chebyshev quadrature (GCQ) and the Gauss\u2013Patterson quadrature (GPQ), respectively.\nLet us turn our attention to checking if the parameters \u03be that are selected via the moment-matching rule (17) also optimize EN [1; \u03be] 2 locally. Proposition 4 below shows that if we use an approximated version of the moment-matching criterion (17) for a general exponential family EM(c\u0303) (it does not have to be a Gaussian family), then the selected parameters \u03be also optimize EN [1; \u03be]\n2 under certain constraints in the numerical expectation. Explicitly, in a special case where both natural statistics c and c\u0303 are equivalent, this constraint requires that the numerical expectation EN,\u03b8 [c; \u03be] /EN,\u03b8 [1; \u03be] is equal to the true value of E\u03b8 [c].\nProposition 4. Let q\u03be in (19a) be a density from EM(c\u0303) where the natural statistics c\u0303i \u2208 C2(Rd) are linearly independent. The param-\neter \u03be optimizes EN [1; \u03be] 2 if \u2202\u03c8(\u03be)\u2202\u03be \u2212 E\u03b8,N [c\u0303;\u03be] E\u03b8,N [1;\u03be] + E\u03b8,N\n[ dx d\u03be dm dx ;\u03be ] E\u03b8,N [1;\u03be] =\n0, where m(\u03be) := c\u22a4(x(\u03be))\u03b8 \u2212 c\u0303\u22a4(x(\u03be))\u03be \u2212 (\u03c8(\u03b8) \u2212 \u03c8(\u03be)). In particular, if the following approximated moment-matching rule is used to choose the parameter \u03be:\nE\u03b8,N [c\u0303; \u03be] E\u03b8,N [1; \u03be] = \u2202\u03c8(\u03be) \u2202\u03be , (21)\nthen, the selected parameter \u03be is a local optimum of EN [1; \u03be] 2 if E\u03b8,N [ dx d\u03be dm dx ; \u03be ] = 0. If c\u0303 = c and \u03be = \u03b8, then \u03be is a local optimum of EN [1; \u03be] 2.\nProof. Let us denote x(\u03be) := \u03d5\u03be(x\u0303). Using (15) from the proof of Proposition 2, we can write\n1 2E\u03b8,N [1; \u03be] dEN [1; \u03be]\n2\nd\u03be =\u2212 [\u2202\u03c8(\u03be) \u2202\u03be \u2212 E\u03b8,N [c\u0303; \u03be] E\u03b8,N [1; \u03be]\n+ E\u03b8,N\n[ dx d\u03be dm dx ; \u03be ] E\u03b8,N [1; \u03be] ]EN [1; \u03be].\nHence, if the approximated moment-matching rule (21) is satisfied, and E\u03b8,N [ dm dx dx d\u03be ; \u03be ] = 0, then 12 dEN [1;\u03be] 2\nd\u03be = 0, which ensures the local optimality. The case when c\u0303 = c follows directly by substitution.\nNote that the approximated moment-matching rule (21) can be implemented as an iterative procedure, where using initial parameters \u03bei, one computes the updated parameters \u03bei+1 via\nE\u03b8,N [c\u0303;\u03bei] E\u03b8,N [1;\u03bei] =\n\u2202\u03c8(\u03bei+1) \u2202\u03bei+1 . The update is repeated until the current iterate is close\nenough to the fixed point. To analyze the convergence of this iterative procedure, let us denote \u03be\u0302 := \u2202\u03c8(\u03be)\u2202\u03be . The mapping from \u03be to \u03be\u0302 is a diffeomorphism via the Legendre transformation [10, Theorem 2.2.3]. Therefore, we can write FN (\u03be\u0302) :=\nE\u03b8,N [c\u0303;\u03be] E\u03b8,N [1;\u03be]\n. The approximated moment-matching rule can then be written as a Picard iteration \u03be\u0302i+1 = FN (\u03be\u0302i). Using Banach\u2019s fixed-point theorem, in the proposition below, we show that there exists a fixed point of the mapping FN on some subset of \u039e\u0302 := {\u03be\u0302 : \u03be \u2208 \u039e}.\nProposition 5. Using the notations of Proposition 4, suppose that for each \u03b8 \u2208 \u0398, c\u0303i(\u03d5\u03be)u(\u03d5\u03be)\u03c9\u22121 belongs to Wrd(D) for any i \u2208 { 1, . . . , n\u03be } and for some r > 0 \u2208 N, uniformly for any \u03be \u2208 \u039e\u03b8 , where, Wrd(D) := {f : D \u2192 R : \u2225 \u2202|s|f\n\u2202x\u0303 s1 (1) ...\u2202x\u0303 sd (d)\n\u2225\u221e < \u221e, si < r},\nwith |s| = \u2211d i=1 si and \u039e\u03b8 \u2282 \u039e open. Moreover, assume that c\u0303i(\u03d5\u03be)u(\u03d5\u03be) is continuously differentiable in \u03be on \u039e\u03b8 . Then there exists an N0 \u2208 N and a subset \u039e\u0302c \u2282 \u039e\u0302 such that FN is a contraction in \u039e\u0302c for N \u2265 N0.\nProof. FN is continuously differentiable on \u039e\u03b8 by the assumption c\u0303i(\u03d5\u03be)u(\u03d5\u03be) is continuously differentiable in \u03be on \u039e\u03b8 and the definition of FN . Using the mean value theorem [17, \u00a70.27] we can write \u2225FN (\u03be\u03021)\u2212FN (\u03be\u03022)\u2225 \u2264 sup\u03be\u0302\u2208\u039e\u0302c \u2225 \u2202FN \u2202\u03be\u0302 \u2225\u2225\u03be\u03021\u2212 \u03be\u03022\u2225. Therefore, if sup \u03be\u0302\u2208\u039e\u0302c \u2225 \u2202FN \u2202\u03be\u0302 \u2225 < 1 in an open convex subset \u039e\u0302c then FN is a contraction in the set. Notice that using \u2202\u03be \u2202\u03be\u0302 = ( \u22022\u03c8(\u03be) \u2202\u03be2 )\u22121 [18, p. 17], we obtain \u2202FN \u2202\u03be\u0302 = ( \u22022\u03c8(\u03be) \u2202\u03be2 )\u22121 \u2202FN\u2202\u03be . Since {c\u0303i} are linearly independent, then (\u2202 2\u03c8(\u03be)\n\u2202\u03be2 ) is invertible for any \u03be \u2208 \u039e [11].\nTherefore, finding \u039e\u0302c such that sup\u03be\u0302\u2208\u039e\u0302c \u2225 \u2202FN \u2202\u03be\u0302 \u2225 < 1 is equivalent to finding an open convex subset \u039ec \u2282 \u039e\u03b8 such that\nsup \u03be\u2208\u039ec\n\u2225\u2225\u2225\u2225\u2225 ( \u22022\u03c8(\u03be) \u2202\u03be2 )\u22121 \u2202FN \u2202\u03be \u2225\u2225\u2225\u2225\u2225 < 1. (22) Since sup\u03be\u2208\u039ec \u2225( \u22022\u03c8(\u03be) \u2202\u03be2 )\u22121 \u2202FN\u2202\u03be \u2225 is less than sup\u03be\u2208\u039ec \u2225( \u22022\u03c8(\u03be) \u2202\u03be2 )\u22121\u2225 sup\u03be\u2208\u039ec \u2225 \u2202FN \u2202\u03be \u2225, and, for an invertible matrix T we have 1\u2225T\u2225 < \u2225T \u22121\u2225, condition in (22) is satisfied if sup\u03be\u2208\u039ec \u2225 \u2202FN \u2202\u03be \u2225 < inf\u03be\u2208\u039ec \u2225( \u22022\u03c8(\u03be) \u2202\u03be2 )\u22121\u2225\u22121 < inf\u03be\u2208\u039ec \u2225( \u22022\u03c8(\u03be) \u2202\u03be2 )\u2225. Since \u039e\u03b8 is open, we can select an open subset \u039ea \u2282 \u039e\u03b8 away from the boundary of \u039e such that there exists a positive \u03b1 satisfying \u03b1I \u227a \u2202 2\u03c8(\u03be)\n\u2202\u03be2 for any \u03be \u2208 \u039ea.\nThis is always possible since EM(c\u0303) is a regular exponential family, which means \u039e is an open convex subset of Rn\u03be [9]. Since for any i, c\u0303i(\u03d5\u03be)u(\u03d5\u03be)\u03c9\n\u22121 \u2208 Wrd(D) on \u039e\u03b8 , then \u2225FN (\u03be\u0302(\u03be)) \u2212 E\u03b8 [c\u0303] \u2225 = O(N\u2212r log(N)(d\u22121)(r\u22121)) on \u039e\u03b8 [19, \u00a74.1.1]. As N approaches infinity, the Jacobian \u2202FN\u2202\u03be at any \u03bea \u2208 \u039ea decreases to zero. Therefore, there exists N0 and r1 > 0 such that for any \u03be \u2208 B(\u03bea, r1) \u2282 \u039ea, the requirement \u2225 \u2202FN/\u2202\u03be \u2225 < \u03b1 is satisfied for N \u2265 N0 in \u039e\u0302c := {\u03be\u0302 : \u03be \u2208 B(\u03bea, r1)}.\nThe conditions in Proposition 5 can be shown to be satisfied for some r > 0 when |p\u03b8/(qr\u03be )| is bounded and goes to zero as \u2225x\u2225 \u2192 \u221e with \u039e\u03b8 = \u039e. This condition is valid for the three numerical simulations considered in Section IV."
        },
        {
            "heading": "C. Second Gaussian-Based Parametric Bijection",
            "text": "In Section III-B, we have used the approximated moment-matching rule (21) to construct the bijection from the hypercube D to Rd. However, there are other quadrature methods that do not operate on"
        },
        {
            "heading": "6 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2017",
            "text": "the hypercube, for example, the Gauss\u2013Hermite quadrature (GHQ) which operates on Rd. To compute the cumulant-generating function efficiently using these numerical integration methods, we introduce another bijection where we specifically focus on the GHQ case.\nWe use N(d, l) to denote the number of quadrature nodes for a dimension d and a level l, such that N := N(d, l). We obtain the sparse multivariate Gauss\u2013Hermite nodes and weights {x\u0303i, wi} N(d,l) i=1 by using the Smolyak construction on one-dimensional Gauss\u2013Hermite nodes (see [20] for details). We use a similar choice of univariate quadrature nodes per level as in GPQ, where, for a level l \u2208 N, the corresponding univariate nodes are given by N(1, l) = 2l+1 \u2212 1. This coincides with the choice of nodes introduced in [21], however in their work, the quadrature levels greater than three are abandoned. Interestingly, if we select N(1, l) = O(2l), then both GPQ and GHQ satisfy [16] N(d, l) = O(2lld\u22121).\nThe exponential of the cumulant-generating function is approximated as follows:\u222b\nRd exp\n( c(x)\u22a4\u03b8 ) dx\n= \u222b Rd exp ( c(\u03d5\u03be(x\u0303)) \u22a4\u03b8 ) exp ( x\u0303\u22a4x\u0303 ) \u00d7 \u2223\u2223\u2223\u2223det \u2202\u03d5\u03be(x\u0303)\u2202x\u0303 \u2223\u2223\u2223\u2223 exp(\u2212x\u0303\u22a4x\u0303)dx\u0303 \u2248 N(d,l)\u2211\ni=1\nwiz(x\u0303i),\n(23)\nwhere,\n\u03d5\u03be(x\u0303) := \u00b5+ \u221a 2T\u22121\u039b1/2x\u0303, (24a)\nz(x\u0303) := exp ( c(\u03d5\u03be(x\u0303)) \u22a4\u03b8 ) exp ( x\u0303\u22a4x\u0303 )\u2223\u2223\u2223\u2223det \u2202\u03d5\u03be(x\u0303)\u2202x\u0303 \u2223\u2223\u2223\u2223. (24b)\nIn (23), {x\u0303i} is the set of the Gauss\u2013Hermite quadrature nodes, and {wi} are their corresponding weights. We select \u00b5 and \u03a3 according to the moment-matching rule (17). Therefore, the bijection (24a) also ensures that the sparse Gauss\u2013Hermite quadrature nodes are always placed in the high-density domain in Rd.\nThe GHQ scheme suffers from a very weak nesting capability since the intersection between roots of Hermite polynomials of successive orders contains only the origin x = 0. This is in contrast with the GPQ scheme used in the previous section, which is highly efficient since it has a polynomial exactness up to order 3N + 1, in addition to being fully nested. Therefore, more integration nodes would be required by GHQ to achieve the same accuracy as GPQ (see [13, Section 3.1.2]). A problem with high-order Gauss\u2013Hermite methods is that the quadrature weights can easily lie below machine precision [22]. In some applications, fortunately, one can ignore the Gauss\u2013 Hermite nodes that have weights below machine precision and still obtain satisfying integration results. As we will see in Section IV, with a similar sparse integration level to that of GPQ, the GHQ scheme combined with the adaptive bijection (24a) might offer a competitive advantage compared to GPQ combined with (20) as their quadrature nodes spread wider than those of latter; see Figure 4.\nD. Integrating the parametric bijection in the automatic projection filter\nWe present Algorithm 1 that combines the parametric bijection with the automatic projection filter algorithm. The bijections (20) and (24a) have identical parameters \u00b5 and \u03a3, and thus can be implemented similarly."
        },
        {
            "heading": "IV. NUMERICAL EXAMPLES",
            "text": "In this section, we consider three numerical experiments to assess the effectiveness of our proposed bijections. For these examples, we\nAlgorithm 1 Single step from the automatic projection filter using parametric bijection.\n1: procedure AUTOMATICPROJECTIONFILTER(p\u03b8, \u03b8, \u03be, t, dyt) 2: g \u2190 FISHERMETRIC(p\u03b8; \u03be) \u25b7 Calculate Fisher Metric of p\u03b8 3: \u03b7\u0303 \u2190 EXTENDEDEXPECTATION(p\u03b8; \u03be) \u25b7 Calculate\nexpectation of the extended natural statistics c\u0303 4: \u03b7 \u2190 \u03b7\u0303[: m] \u25b7 The expectation of natural statistics c is the\nfirst m of \u03b7\u0303 5: d\u03b8 \u2190 FILTEREQUATION(g, \u03be, \u03b7\u0303, \u03b7, t, dyt) \u25b7 Eq. (9) 6: \u03b8 \u2190 \u03b8 + d\u03b8 \u25b7 Update the parameter 7: \u03be \u2190 UPDATEBIJECTIONPARAMETERS(\u03b7, g) \u25b7 Eq. (21) 8: return \u03b8, \u03be \u25b7 Return the updated value of the natural\nparameter \u03b8 and bijection parameter \u03be 9: end procedure\nchoose P as the set of polynomials in xt with order less than or equal to some np \u2208 N."
        },
        {
            "heading": "A. Univariate example",
            "text": "The first example is a scalar dynamical system with a nonlinear measurement model [1], [2]:\ndxt = \u03badt+ \u03c3dWt, (25a) dyt = \u03b2x 3 t dt+ dVt, (25b)\nwith two independent standard Wiener processes {Wt, t \u2265 0} and {Vt, t \u2265 0}, and three constants given by the process noise constant \u03c3 = 0.4, the drift constant \u03ba = 0.25, and the nonlinear measurement scale \u03b2 = 0.8. It is well known that the optimal filter for this problem is infinite dimensional [23]. We use an exponential manifold with ci \u2208 {x, x2, x3, x4}. We remark that the drift term in (25a) makes the filtering problem significantly harder than that of [8]. We choose the initial parameters of the projection filter as \u03b80 = [0, 2, 0,\u22121]\u22a4. This initial condition vector reflects exactly the initial density of the dynamical system which corresponds to a bimodal non-Gaussian density with peaks at \u22121 and 1. We solve the Kushner\u2013Stratonovich stochastic PDE on a uniform grid. The simulation time step is set to be 10\u22124. We generate one measurement realization with x0 = 1. We compare three different bijections: The first one is a static bijection tanh(x\u0303)\u22121, the second one is the Gaussian-based bijection (20), and the third one is the Gauss\u2013Hermite bijection (24a). Furthermore, we use 9 and 18 integration nodes for the static bijection and 9 such nodes for both parametrized bijections.\nThe simulation results, shown in Figure 2, depict the evolution of the densities obtained with the finite difference approach and with the projection filters, along with their corresponding Hellinger distances, where the Hellinger distance between two densities p and q is given by 12 \u222b X ( \u221a p \u2212 \u221aq)2dx. Even though both projection filters based on parametric bijections (20) and (24a) require less integration nodes than that based on the static bijection, they do however substantially reduce Hellinger distances compared to the finite difference approximation, as shown in Figure 2. The projection filter based on the bijection (20) with GCQ produces better approximated densities than the GHQ scheme across the entire simulation time. This is also shown in Figure 2, where the Hellinger distances associated with the GCQ scheme (FD-vs-Proj-GCQ-9) only oscillate between one and ten times the lowest Hellinger distance obtained from the static bijection with 18 quadrature nodes (FD-vs-static-18). In contrast to this and at the end of the simulation, the Hellinger distance between the finite difference solution and the projection filter approximation using the static bijection with 9 quadrature nodes (FD-vs-static9) is about one hundred times greater than that from the lowest\nAUTHOR et al.: PREPARATION OF BRIEF PAPERS FOR IEEE TRANSACTIONS AND JOURNALS (FEBRUARY 2017) 7\nHellinger distance (FD-vs-static-18). Thus, this simulation evidently shows that the parametric bijection (20) is superior to both the static and Gauss\u2013Hermite bijections (24a) for this example which portrays a hard stochastic nonlinear filtering problem to solve."
        },
        {
            "heading": "B. Modified Van der Pol Oscillator",
            "text": "In this section, we compare the projection filter with a bootstrap particle filter with systematic resampling [24]. The dynamic model considered here is a modified Van der Pol oscillator, the standard form of which is widely used as a model for oscillatory processes in physics, electronics, biology, neurology, sociology and economics:\nd [ x1,t x2,t ] = [ \u03bax1,t + x2,t \u2212x1,t + \u03bax2,t + \u00b5(1\u2212 x21,t)x2,t ] dt+ [ 0 \u03c3w ] dWt,\ndy = x1,tdt+ \u03c3vdVt. (26)\nIn this simulation, we set \u00b5 = 0.3, \u03ba = 1.25, and \u03c3v = \u03c3w = 1. We also set the simulation time step to be 2.5 \u00d7 10\u22123. Unlike the case with \u03ba = 0, where the probability density evolution can be easily contained using a compact support [8], the probability densities corresponding to (26) with \u03ba > 0 expand quickly in time. We use here both GPQ and GHQ with their sparse-grid integration schemes where we set the level to four. For the GPQ scheme, the number of nodes used is 129 while for the GHQ scheme, it is 189 after ignoring all nodes with weights less than 10\u22129. For the particle filter, we use 9.6 \u00d7 106 samples in our simulation. We discretize the dynamic model (26) using Euler\u2013Maruyama for both the particle filter and the measurement process. For a multi index i \u2208 N2, define xi = xi(1)1 x i(2) 2 . The natural statistics are set to be xi, where 1 \u2264 |i| \u2264 4. Further, the initial density is set to be the standard Gaussian density. To show the performance of the projection filter obtained by both sparse integration schemes, we calculate the empirical densities of the particle filter on a fixed grid. The comparison of the empirical densities from the particle filters with those from the projection filters is shown in Figure 4, while the Hellinger distances between the empirical densities and those from the projection filters are in Figure 3. Figure 4 shows that the bijected quadrature nodes of both sparse GPQ and GHQ schemes are systematically adapting to the shapes of the densities as they evolve in time. The shapes of the projection densities resemble those of the empirical densities from the particle filter, except that the projection filter\u2019s densities cannot capture some sharp notch-like shapes with low values as in Figure 4. The Hellinger distances from the projection filter\u2019s densities obtained using the GHQ scheme to the empirical\n0.0 0.2 0.4 0.6 0.8 1.0 t\n10\u22124\n10\u22123\nH el\nlin ge\nrd is\nta nc\ne\nParticle vs Proj-GPQ Particle vs Proj-GHQ\nFig. 3. Hellinger distance from the empirical densities to the projection filter\u2019s densities solved using both GPQ and GHQ.\nFig. 4. Comparison of empirical densities from particle filter (left) and densities from the projection filters solved using GPQ (center) and GHQ (right) at t = 0.995. The grey dots represents the position of the bijected quadrature nodes of the sparse Gauss\u2013Patterson or Gauss\u2013 Hermite schemes, respectively.\ndensities are slightly lower compared to those obtained using the GPQ scheme.\nTable I shows computational times of the projection filter with different sparse-grid levels and adaptive bijections, and the projection filter with a static bijection. For the static bijection, we use Gauss\u2013 Patterson sparse grid integration, where we set the static bijection to be tanh\u22121 following [8]. As can be seen, the execution time of the projection filter using GHQ level 4 with bijection (24a) is the fastest compared to the other projection filter schemes. We found that even with the maximum sparse-grid level available for Gauss\u2013 Patterson sparse grid integration (level 8), the projection filter with static bijection produces ill-defined projection densities around t = 0.7. Therefore, to accurately implement the projection filter using the static bijection, a sparse-grid level higher than 8 is necessary, which means a significant increase in the quadrature nodes that will result in a substantial rise in execution time. As shown in Table I, the computational times for the GHQ with bijection (24a) increase only modestly, compared to those of the GPQ with bijection (20)."
        },
        {
            "heading": "C. Stochastic Epidemiology Application",
            "text": "In this section, we consider an application of the projection filter to the stochastic suspected infected or recovery (SIR) nonlinear filtering problem, widely used for example in the study of the spread of"
        },
        {
            "heading": "8 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2017",
            "text": "infectious diseases. Consider the following SDE [25]:\nd [ x1,t x2,t ] = [ \u2212\u03b2x1,tx2,t \u2212 \u00b5x1,t + \u00b5 \u03b2x1,tx2,t \u2212 (\u03bb+ \u00b5)x2,t ] dt+ [ \u2212\u03c3x1,tx2,t \u03c3x1,tx2,t ] dWt,\ndy1,t = x2,tdt+ kdVt. (27)\nIn this equation, x1,t is the fraction of the suspected population, x2,t is the fraction of the infected population, assuming that the population size is constant. The fraction of the recovered population is given by 1\u2212 (x1,t + x2,t), and its dynamic is non-stochastic which can be excluded from the SDE. The constants \u03b2, \u00b5, \u03bb correspond to the average number of contacts per infection per day, the birth rate, and the recovery rate of the infected people, respectively. The constants \u03c3, and k are positive constants associated with the process and measurement noises, respectively.\nIf 0 < \u03b2 < min(\u03bb+\u00b5\u2212 \u03c3 2\n2 , 2\u00b5) then the disease-free equilibrium x\u2217 = (1, 0) is globally asymptotically stable [25, Theorem 2.1]. Therefore, the stationary probability measure has no density with respect to the Lebesgue measure. The high-density domain of the conditional probability density of SIR dynamics will be shrinking in time. In our simulation, we chose \u00b5 = 0.2, \u03b2 = 0.14, \u03bb = 0.1, \u03c3 = 0.2, k = 10\u22124 and set the initial density to be a Gaussian density with mean [0.95, 0.02]\u22a4 and variance diag[0.95, 0.02] \u00d7 10\u22123. Using a similar exponential family to that of the previous section, we compare here the performance of the projection filter achieved by using the bijection (20) and GPQ level 5 with that of the particle filter. The Hellinger distance between the two densities at different times can be seen in Figure 5. This, therefore, clearly shows that the bijection (20) can also perform very well in accurately tracking probability densities that shrink in time, as is the case here with SIR dynamics, and, by the same token, also demonstrates the adaptive capability of the proposed bijection (20). Compared to the projection filter with the proposed bijections, employing the projection filter alongside GPQ level 8 and the static bijection tanh\u22121 leads to an ill-defined projection density within just a few iterations."
        },
        {
            "heading": "V. CONCLUSIONS",
            "text": "In this work, we have introduced two new parametric bijections for the automatic projection filter that was recently proposed in [8]. The first bijection was constructed by selecting a Gaussian density q\u03be whose parameters were obtained by minimizing the KL divergence between the projected density p\u03b8 and the Gaussian density q\u03be , which is equivalent to evaluating moment-matching conditions. We have shown that this bijection also minimizes the squared integration error under some sufficient theoretical conditions. The second bijection was also constructed via the same moment-matching conditions, but it was tailored for the GHQ scheme. We then applied these bijections to three practically-motivated numerical examples, and we found that they all achieved superior performance in terms of the Hellinger distances to the ground truth than the static bijection, using fewer quadrature nodes and thus achieving both higher accuracy and reduced computational time.\nREFERENCES [1] B. Hanzon and R. Hut, \u201cNew results on the projection filter,\u201d in European\nControl Conference, Grenoble, Jul. 1991, p. 9. [2] D. Brigo, B. Hanzon, and F. L. Gland, \u201cApproximate nonlinear filtering\nby projection on exponential manifolds of densities,\u201d Bernoulli. Official Journal of the Bernoulli Society for Mathematical Statistics and Probability, vol. 5, no. 3, p. 495, Jun. 1999. [3] H. J. Kushner, \u201cOn the differential equations satisfied by conditional probability densities of Markov processes, with applications,\u201d Journal of the Society for Industrial and Applied Mathematics, Series A: Control, vol. 2, no. 1, pp. 106\u2013119, 1964. [4] J. Armstrong and D. Brigo, \u201cNonlinear filtering via stochastic PDE projection on mixture manifolds in L2 direct metric,\u201d Mathematics of Control, Signals, and Systems, vol. 28, no. 1, p. 5, Dec. 2016. [5] J. Armstrong, D. Brigo, and B. Hanzon, \u201cOptimal projection filters with information geometry,\u201d Info. Geo., Jun. 2023. [6] S. Koyama, \u201cProjection smoothing for continuous and continuousdiscrete stochastic dynamic systems,\u201d Signal Processing, vol. 144, pp. 333\u2013340, Mar. 2018. [7] A. Kutschireiter, L. Rast, and J. Drugowitsch, \u201cProjection Filtering with Observed State Increments with Applications in Continuous-Time Circular Filtering,\u201d IEEE Transactions on Signal Processing, vol. 70, pp. 686\u2013700, 2022. [8] M. F. Emzir, Z. Zhao, and S. Sa\u0308rkka\u0308, \u201cMultidimensional projection filters via automatic differentiation and sparse-grid integration,\u201d Signal Processing, vol. 204, p. 108832, Mar. 2023. [9] L. D. Brown, \u201cFundamentals of Statistical Exponential Families with Applications in Statistical Decision Theory,\u201d Lecture Notes-Monograph Series, vol. 9, pp. i\u2013279, 1986. [10] R. E. Kass and P. W. Vos, Geometrical Foundations of Asymptotic Inference, ser. Wiley Series in Probability and Statistics. New York: Wiley, 1997, \u201dA Wiley Interscience publication.\u201d. [11] O. Calin and C. Udris\u0327te, Geometric Modeling in Probability and Statistics. Springer International Publishing, 2014. [12] D. Brigo, \u201cOptimal Projection Filters,\u201d May 2022, comment: arXiv admin note: text overlap with arXiv:1610.03887. [13] W. Gautschi, Orthogonal Polynomials: Computation and Approximation, ser. Numerical Mathematics and Scientific Computation. Oxford New York: Oxford university press, 2004. [14] R. T. Rockafellar, Convex Analysis, ser. Princeton Mathematical Series. Princeton, N.J: Princeton University Press, 1970, no. 28. [15] R. Herbrich, \u201cMinimising the Kullback\u2013Leibler Divergence,\u201d Microsoft, Tech. Rep., 2005. [16] T. Gerstner and M. Griebel, \u201cNumerical integration using sparse grids,\u201d Numerical Algorithms, vol. 18, no. 3/4, pp. 209\u2013232, 1998. [17] T. Aubin, A Course in Differential Geometry, ser. Graduate Studies in Mathematics. Providence, R.I: American Mathematical Society, 2001, no. v. 27. [18] S.-i. Amari, Information Geometry and Its Applications, ser. Applied Mathematical Sciences. Tokyo: Springer Japan, 2016, vol. 194. [19] M. Holtz, Sparse Grid Quadrature in High Dimensions with Applications in Finance and Insurance, ser. Lecture Notes in Computational Science and Engineering. Heidelberg New York: Springer, 2011, no. 77. [20] H.-J. Bungartz and M. Griebel, \u201cSparse grids,\u201d Acta Numerica, vol. 13, pp. 147\u2013269, May 2004. [21] B. Jia, M. Xin, and Y. Cheng, \u201cSparse Gauss-Hermite Quadrature Filter with Application to Spacecraft Attitude Estimation,\u201d Journal of Guidance, Control, and Dynamics, vol. 34, no. 2, pp. 367\u2013379, Mar. 2011. [22] L. N. Trefethen, \u201cExactness of Quadrature Formulas,\u201d SIAM Review, vol. 64, no. 1, pp. 132\u2013150, Feb. 2022. [23] M. Hazewinkel, S. I. Marcus, and H. J. Sussmann, \u201cNonexistence of finite-dimensional filters for conditional statistics of the cubic sensor problem,\u201d Systems & Control Letters, vol. 3, no. 6, pp. 331\u2013340, Dec. 1983. [24] N. Chopin, An Introduction to Sequential Monte\u2013Carlo. Cham, Switzerland: Springer, 2020. [25] E. Tornatore, S. Maria Buccellato, and P. Vetro, \u201cStability of a stochastic SIR system,\u201d Physica A: Statistical Mechanics and its Applications, vol. 354, pp. 111\u2013126, Aug. 2005.\n1 Supplementary Materials for Gaussian-Based Parametric Bijections For Automatic Projection\nFilters Muhammad Emzir, Zheng Zhao, Lahouari Cheded, Simo S\u00e4rkk\u00e4\nI. INTRODUCTION\nIn this supplementary documentation, in Table I, we give the essential notations employed in the main paper. Alongside this, we offer supplementary plots that augment the paper\u2019s content.\nII. NOTATIONS"
        },
        {
            "heading": "A. Univariate Problem in Section IV.A",
            "text": "Figure 1 illustrates a comparison between conditional densities derived from solving Kushner\u2013Stratonovich SPDEs using the finite difference method (considered the ground truth) and those computed using the projection filter at different time points. This figure, similar to the Hellinger distance plot (Figure 2 in the paper), displays the similarity between the conditional densities approximated by the projection filter, utilizing Gauss\u2013Chebyshev numerical integration and bijection (20) (Proj-GCQ9), and the finite difference solutions to the Kushner\u2013Stratonovich equation (FD). Qualitatively, the densities Proj-GCQ-9 are comparable to the approximated conditional densities generated by the projection filter with a static bijection and twice the quadrature nodes (Proj-Static-18).\n2 t 0.0 0.5 1.0 1.5 2.0 x \u22125.0 \u22122.5 0.0 2.5 5.0 p 0.0 0.5 1.0 FD Proj-Static-9 Proj-Static-18 Proj-GCQ-9 Proj-GHQ-9\nFig. 1. This figure shows a comparison between the densities obtained by employing finite difference schemes (represented in black), densities obtained through the application of projection filters using a static bijection with 9 and 18 quadrature nodes and densities obtained from solving projection filters utilizing the bijections provided in formulas (20) and (24a) (depicted in blue and magenta respectively)."
        },
        {
            "heading": "B. Bivariate Problem in Section IV.B",
            "text": "Figure 2 shows that even with the maximum sparse-grid level available for Gauss\u2013Patterson sparse grid integration (level 8), the projection filter with static bijection produces an ill-defined projection densities around t = 0.7, which is reflected in the explosive Hellinger distance between the empirical densities from the particle filter and the densities obtained via the projection filter with the static bijection. Therefore, to accurately implement the projection filter using the static bijection, a sparse-grid level higher than 8 is necessary, which means a significant increase in the quadrature nodes that will result in a substantial rise in execution time.\nFigure 4 shows a comparison of moments calculated through partial differentiation of the cumulant-generating function using the projection filter algorithm and those derived from the particle filters, which are considered the ground truth. Notably, the moments obtained from GHQ exhibit a closer correspondence with the particle filter\u2019s moments than those derived from GPQ. These plots also show corresponding polynomial functions of state realizations for illustrative purposes."
        },
        {
            "heading": "C. Bivariate Problem in Section IV.C",
            "text": "The computational times for the numerical example in Section IV.C exhibit similarity to those in Section IV.B, as both involve bivariate dynamics. It is, however, crucial to highlight that in the numerical example outlined in Section IV.C, employing the projection filter alongside GPQ level 8 and the tanh\u22121 static bijection leads to an ill-defined projection density within a few iterations (see Figure 3). This observation implies that for this specific optimal filtering problem, the usage of Gauss\u2013Patterson sparse-grid quadrature with the static bijection tanh\u22121 demands a higher level of sparse-grid integration compared to that in Section IV.B. Consequently, this level would result in an increase in computational time. This also emphasizes the efficiency of the two proposed bijections in this paper, as employing these bijections along with sparse-grid quadrature enables seamless operation of the projection filter.\n3 0.0 0.2 0.4 0.6 0.8 1.0 t 103 1014 1025 1036 1047 1058 H el lin ge rd is ta nc e Particle vs Proj-GPQ Particle vs Proj-GHQ Particle vs Proj-Static\n(a) Hellinger Distance (b) Probability density function comparison at t = 0.720 Fig. 2. Figure 2a shows a comparison of Hellinger distances between the empirical densities of the particle filter and the projection filter densities obtained through adaptive and static bijections. In Figure 2b, it is obvious that starting from t = 0.72, the projection densities calculated using the static bijection tanh\u22121 and Gauss\u2013Patterson sparse-grid quadrature level 8 begin to deviate significantly from the empirical densities of the particle filter. The deviations appear since significant portions of high-density regions moved outside the quadrature node locations.\n4 0.0 0.2 0.4 0.6 0.8 1.0 t \u22121.5 \u22121.0 \u22120.5 0.0 0.5 1.0 1.5 E[ x 1 ] proj-GPQ proj-GHQ proj-Static particle realization 0.0 0.2 0.4 0.6 0.8 1.0 t 0 1 2 3 4 5 E[ x 2 1 ] proj-GPQ proj-GHQ particle realization 0.0 0.2 0.4 0.6 0.8 1.0 t \u22125.0 \u22122.5 0.0 2.5 5.0 7.5 E[ x 2 1 x 2 ] proj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n0\n1\n2\n3\n4\nE[ x\n2 1 x\n2 2 ]\n\u00d7101\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n\u22121\n0 1 E[ x 3 1 ]\n\u00d7101\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n0\n1\n2\n3\nE[ x\n3 1 x\n2 ]\n\u00d7101\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n0\n2\n4\n6\nE[ x\n4 1 ]\n\u00d7101\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n0\n1\n2\n3\nE[ x\n1 x\n2 ]\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n\u22121.0\n\u22120.5\n0.0\n0.5\n1.0\nE[ x\n1 x\n2 2 ]\n\u00d7101\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n0\n2\n4\n6\nE[ x\n1 x\n3 2 ]\n\u00d7101\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n\u22120.5\n0.0\n0.5\n1.0\n1.5\nE[ x\n2 ]\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n0\n2\n4\n6\n8\nE[ x\n2 2 ]\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n\u22121\n0\n1\n2\nE[ x\n3 2 ]\n\u00d7101\nproj-GPQ proj-GHQ particle realization\n0.0 0.2 0.4 0.6 0.8 1.0 t\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\nE[ x\n4 2 ]\n\u00d7102\nproj-GPQ proj-GHQ particle realization\nFig. 4. Comparison approximation of natural statistic\u2019s expected values solved by the projection filter and the particle filter."
        }
    ],
    "title": "Gaussian-Based Parametric Bijections For Automatic Projection Filters",
    "year": 2023
}