{
    "abstractText": "Deep learning algorithms have recently shown to be a successful tool in estimating parameters of statistical models for which simulation is easy, but likelihood computation is challenging. But the success of these approaches depends on simulating parameters that sufficiently reproduce the observed data, and, at present, there is a lack of efficient methods to produce these simulations. We develop new black-box procedures to estimate parameters of statistical models based only on weak parameter structure assumptions. For well-structured likelihoods with frequent occurrences, such as in time series, this is achieved by pre-training a deep neural network on an extensive simulated database that covers a wide range of data sizes. For other types of complex dependencies, an iterative algorithm guides simulations to the correct parameter region in multiple rounds. These approaches can successfully estimate and quantify the uncertainty of parameters from non-Gaussian models with complex spatial and temporal dependencies. The success of our methods is a first step towards a fully flexible automatic black-box estimation framework.",
    "authors": [
        {
            "affiliations": [],
            "name": "Amanda Lenzi"
        }
    ],
    "id": "SP:63c35a2876492d01b7e8cc7577816d47cb5a7464",
    "references": [
        {
            "authors": [
                "T.G. Andersen",
                "Chung",
                "H.-J.",
                "B.E. S\u00f8rensen"
            ],
            "title": "Efficient method of moments estimation of a stochastic volatility model: A monte carlo study",
            "venue": "Journal of econometrics, 91(1):61\u201387.",
            "year": 1999
        },
        {
            "authors": [
                "E. Carlstein"
            ],
            "title": "The use of subseries values for estimating the variance of a general statistic from a stationary sequence",
            "venue": "The annals of statistics, pages 1171\u20131179.",
            "year": 1986
        },
        {
            "authors": [
                "K. Cranmer",
                "J. Brehmer",
                "G. Louppe"
            ],
            "title": "The frontier of simulation-based inference",
            "venue": "Proceedings of the National Academy of Sciences, 117(48):30055\u201330062.",
            "year": 2020
        },
        {
            "authors": [
                "R.A. Davis",
                "C. Kl\u00fcppelberg",
                "C. Steinkohl"
            ],
            "title": "Statistical inference for max-stable processes in space and time",
            "venue": "Journal of the Royal Statistical Society: SERIES B: Statistical Methodology, pages 791\u2013819.",
            "year": 2013
        },
        {
            "authors": [
                "A.C. Davison",
                "S.A. Padoan",
                "M. Ribatet"
            ],
            "title": "Statistical modeling of spatial extremes",
            "venue": "Statistical science, 27(2):161\u2013186.",
            "year": 2012
        },
        {
            "authors": [
                "P. Fearnhead",
                "D. Prangle"
            ],
            "title": "Constructing summary statistics for approximate bayesian computation: semi-automatic approximate bayesian computation",
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), 74(3):419\u2013474.",
            "year": 2012
        },
        {
            "authors": [
                "D.T. Frazier",
                "G.M. Martin",
                "C.P. Robert",
                "J. Rousseau"
            ],
            "title": "Asymptotic properties of approximate bayesian computation",
            "venue": "Biometrika, 105(3):593\u2013607.",
            "year": 2018
        },
        {
            "authors": [
                "M. Fridman",
                "L. Harris"
            ],
            "title": "A maximum likelihood approach for non-gaussian stochastic volatility models",
            "venue": "Journal of Business & Economic Statistics, 16(3):284\u2013291.",
            "year": 1998
        },
        {
            "authors": [
                "F. Gerber",
                "D.W. Nychka"
            ],
            "title": "Fast covariance parameter estimation of spatial Gaussian process models using neural networks",
            "venue": "Stat, page e382.",
            "year": 2020
        },
        {
            "authors": [
                "A. Grelaud",
                "Marin",
                "J.-M.",
                "C.P. Robert",
                "F. Rodolphe",
                "Taly",
                "J.-F."
            ],
            "title": "Abc likelihoodfree methods for model choice in gibbs random fields",
            "venue": "Bayesian Analysis, 4(2):317\u2013335.",
            "year": 2009
        },
        {
            "authors": [
                "M.U. Gutmann",
                "J. Corander"
            ],
            "title": "Bayesian optimization for likelihood-free inference of simulator-based statistical models",
            "venue": "Journal of Machine Learning Research.",
            "year": 2016
        },
        {
            "authors": [
                "F. Hartig",
                "J.M. Calabrese",
                "B. Reineking",
                "T. Wiegand",
                "A. Huth"
            ],
            "title": "Statistical inference for stochastic simulation models\u2013theory and application",
            "venue": "Ecology letters, 14(8):816\u2013 827.",
            "year": 2011
        },
        {
            "authors": [
                "T. Hastie",
                "R. Tibshirani",
                "J. Friedman"
            ],
            "title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction",
            "venue": "Springer Science & Business Media.",
            "year": 2009
        },
        {
            "authors": [
                "J. Hermans",
                "V. Begy",
                "G. Louppe"
            ],
            "title": "Likelihood-free mcmc with amortized approximate ratio estimators",
            "venue": "International Conference on Machine Learning, pages 4239\u20134248. PMLR.",
            "year": 2020
        },
        {
            "authors": [
                "B. Jiang",
                "Wu",
                "T.-y.",
                "C. Zheng",
                "W.H. Wong"
            ],
            "title": "Learning summary statistic for approximate bayesian computation via deep neural network",
            "venue": "Statistica Sinica, pages 1595\u2013 1618.",
            "year": 2017
        },
        {
            "authors": [
                "Z. Kabluchko",
                "M. Schlather",
                "L De Haan"
            ],
            "title": "Stationary max-stable fields associated to negative definite functions",
            "venue": "The Annals of Probability,",
            "year": 2009
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980.",
            "year": 2014
        },
        {
            "authors": [
                "A. Lenzi",
                "J. Bessac",
                "J. Rudi",
                "M.L. Stein"
            ],
            "title": "Neural networks for parameter estimation in intractable models",
            "venue": "arXiv preprint arXiv:2107.14346.",
            "year": 2021
        },
        {
            "authors": [
                "S. Martino",
                "K. Aas",
                "O. Lindqvist",
                "L.R. Neef",
                "H. Rue"
            ],
            "title": "Estimating stochastic volatility models using integrated nested laplace approximations",
            "venue": "The European Journal of Finance, 17(7):487\u2013503.",
            "year": 2011
        },
        {
            "authors": [
                "Y.L. Murphey",
                "H. Guo",
                "L.A. Feldkamp"
            ],
            "title": "Neural learning from unbalanced data",
            "venue": "Applied Intelligence, 21(2):117\u2013128.",
            "year": 2004
        },
        {
            "authors": [
                "R. Nickl",
                "B.M. P\u00f6tscher"
            ],
            "title": "Efficient simulation-based minimum distance estimation and indirect inference",
            "venue": "Mathematical methods of statistics, 19(4):327\u2013364.",
            "year": 2010
        },
        {
            "authors": [
                "S.A. Padoan",
                "M. Ribatet",
                "S.A. Sisson"
            ],
            "title": "Likelihood-based inference for max-stable processes",
            "venue": "Journal of the American Statistical Association,",
            "year": 2010
        },
        {
            "authors": [
                "M. Ribatet"
            ],
            "title": "Spatial extremes: Max-stable processes at work",
            "venue": "Journal de la Soci\u00e9t\u00e9 Fran\u00e7aise de Statistique, 154(2):156\u2013177.",
            "year": 2013
        },
        {
            "authors": [
                "H. Rue",
                "S. Martino",
                "N. Chopin"
            ],
            "title": "Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations",
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), 71(2):319\u2013392.",
            "year": 2009
        },
        {
            "authors": [
                "M. Sainsbury-Dale",
                "A. Zammit-Mangion",
                "R. Huser"
            ],
            "title": "Fast optimal estimation with intractable models using permutation-invariant neural networks",
            "venue": "arXiv preprint arXiv:2208.12942.",
            "year": 2022
        },
        {
            "authors": [
                "H. Shang",
                "J. Yan",
                "X. Zhang"
            ],
            "title": "A two-step approach to model precipitation extremes in California based on max-stable and marginal point processes",
            "venue": "The Annals of Applied Statistics, pages 452\u2013473.",
            "year": 2015
        },
        {
            "authors": [
                "S.A. Sisson",
                "Y. Fan",
                "M. Beaumont"
            ],
            "title": "Handbook of approximate Bayesian computation",
            "venue": "CRC Press.",
            "year": 2018
        },
        {
            "authors": [
                "S.J. Taylor"
            ],
            "title": "Financial returns modelled by the product of two stochastic processes-a study of the daily sugar prices 1961-75",
            "venue": "Time series analysis: theory and practice, 1:203\u2013226.",
            "year": 1982
        },
        {
            "authors": [
                "S.N. Wood"
            ],
            "title": "Statistical inference for noisy nonlinear ecological dynamic systems",
            "venue": "Nature, 466(7310):1102\u20131104.",
            "year": 2010
        }
    ],
    "sections": [
        {
            "text": "Deep learning algorithms have recently shown to be a successful tool in estimating parameters of statistical models for which simulation is easy, but likelihood computation is challenging. But the success of these approaches depends on simulating parameters that sufficiently reproduce the observed data, and, at present, there is a lack of efficient methods to produce these simulations. We develop new black-box procedures to estimate parameters of statistical models based only on weak parameter structure assumptions. For well-structured likelihoods with frequent occurrences, such as in time series, this is achieved by pre-training a deep neural network on an extensive simulated database that covers a wide range of data sizes. For other types of complex dependencies, an iterative algorithm guides simulations to the correct parameter region in multiple rounds. These approaches can successfully estimate and quantify the uncertainty of parameters from non-Gaussian models with complex spatial and temporal dependencies. The success of our methods is a first step towards a fully flexible automatic black-box estimation framework.\nKeywords: Deep neural networks, intractable likelihoods, sequential, time-series Short title: Black-box Estimation\n1School of Mathematics, University of Edinburgh, Edinburgh EH9 3FD, Scotland, United Kingdom. 2Statistics Program, King Abdullah University of Science and Technology, Thuwal 23955-6900, Saudi Arabia.\nar X\niv :2\n30 3.\n15 04\n1v 1\n[ st\nat .M\nL ]\n2 7\nM ar\n2 02\n3"
        },
        {
            "heading": "1 Introduction",
            "text": "Statistical modeling consists of first devising stochastic models for phenomena we want to learn about and then to relate those models to data. These stochastic models have unknown parameters and the second step boils down to estimating these parameters from data through the likelihood function. However, there might be a discrepancy between these two steps, as models for describing mechanisms aim for scientific adequacy rather than computational tractability. Indeed, as soon as we move away from Gaussian processes as the canonical model for dependent data, likelihood computation becomes effectively impossible, and inference is too complicated for traditional estimation methods. Consider, for instance, datasets from finance or climate science, where skewness and jumps are commonly present and calculating the likelihood in closed form is often impossible, ruling out any numerical likelihood maximization and Bayesian methods. Yet it is possible to simulate from those models, and the question becomes whether the simulations look like the data.\nMuch effort has been directed toward the development of methods of approximate parameter estimation, often referred to as indirect inference (Gourieroux et al., 1993), likelihood-free inference (Grelaud et al., 2009; Gutmann and Corander, 2016), simulation-based inference (Nickl and Po\u0308tscher, 2010) or synthetic likelihood (Wood, 2010); for an overview, see, for example, the review by Hartig et al. (2011); Cranmer et al. (2020). The typical assumption by the different methods is that exact likelihood evaluation is hard to obtain but it is easy to simulate from the model given the parameter values, and the basic idea is to identify the model parameters which yield simulated data that resemble the observed data. The most common in this umbrella is arguably approximate Bayesian computation (ABC) (Fearnhead and Prangle, 2012; Frazier et al., 2018; Sisson et al., 2018), which avoids evaluating intractable likelihoods by matching summary statistics from observations with those computed from simulated data based on parameters drawn from a predefined prior distribution. The likelihood is approximated by the probability that the condition \u03b3(xsim, xobs) < is satisfied, where \u03b3 is some distance measure and the value\nof is a trade-off between sample efficiency and inference quality. In simpler cases, sufficient statistics are used as they provide all the information in the data, however, for complex models they are unlike to exist and it is not obvious which statistics will be most informative. Several works have proposed procedures for designing summary statistics (Fearnhead and Prangle, 2012; Jiang et al., 2017).\nDespite its popularity, ABC is not scalable to large numbers of observations, since inference for new data requires repeating most steps of the procedure. To address this issue, recent progress in deep learning capabilities, such as the integration of advanced automatic differentiation and probabilistic programming within the modeling workflow, were used, e.g., to approximate density ratios proportional to the likelihood estimation using a classifier in Hermans et al. (2020), parameter estimation in Gaussian processes (Gerber and Nychka, 2020) and in multivariate extremes (Lenzi et al., 2021; Sainsbury-Dale et al., 2022). Specifically for parameter estimation of spatial covariance functions, Gerber and Nychka (2020) used maximum likelihood estimators (MLEs) for training convolutional neural networks (CNNs). While they showed that their framework improves the computational aspects of inference for classical spatial models, it is case-specific and not scalable, as the CNN must be retrained with new MLEs for each new testing dataset. Additionally, exact methods, such as MLEs, are not available for intractable models that most benefit from an alternative estimation approach. Alternatively, Lenzi et al. (2021) avoided the shortcoming of using MLEs and proposed to computed parameter estimates from approximate likelihood methods and used those to design training data for the CNN.\nThe ABC and deep learning approaches mentioned above work best when the simulated data are from the same parameter space as the observations\u2019 parameters, which are unknown. In high dimensions and large parameter spaces, constructing a training parameter space large enough to cover all possible reasonable parameter values is infeasible. Instead, one needs a rule for picking the region to simulate data. However, ideally, the inference mechanism should be able to automatically perform inference without restrictive assumptions about the generating\nprocess, knowledge from experts, or computationally expensive preliminary steps. This work is about bridging this gap by employing general black-box methodologies that only require weak assumptions on the data-generating process and generalize to new datasets without needing to repeat computationally expensive steps. The proposed methods are a step further toward an automatic and generic workflow for performing statistical inference in intractable models.\nIn more detail, our black-box approaches can be divided into two categories: (A) a fully automatic iterative approach that modifies the training data using arbitrary, dynamically updated distribution parameters until it reaches the actual parameters in the data, and (B) A database that is extensive enough to handle estimation for different data sizes from the same model but that needs to be trained only once. We first demonstrate the success of the sequential framework in (A) in an independent, identically distributed (i.i.d.) Gaussian example and further extend it to intractable likelihoods for modeling spatial extremes. In both cases, the estimators dramatically reduce the bias of an initial guess and eventually approximate the actual parameter quite accurately, even when the initial training does not contain the truth. The strategy in (B) is designed for stationary time series data, and we show its usefulness for estimating parameters of a model widely used in finance, namely non-Gaussian stochastic volatility models. In such applications, where early access to results may carry a premium, our deep neural network (DNN) estimator is particularly advantageous. The network is trained ahead of time, and estimates are obtained instantaneously when new data becomes available. This example shows that our estimator is well calibrated, with uncertainty quantification closely matching those from the state-of-the-art Integrated Nested Laplace Approximation (INLA) approach (Rue et al., 2009).\nWe leverage our statistical knowledge about scaling data and parameters to effectively train the DNNs by reducing computational costs and improving convergence. Our approaches take advantage of modern and powerful computational resources for DNNs, such as graphical processing units (GPUs). At the same time, unlike classical deep learning for prediction, they preserve the statistical model and parameter interpretability. Uncertainty quantification is performed\nusing a modified parametric bootstrapping approach. The only requirement is to simulate from the model, and estimation is computationally cheap since it is achieved automatically from the pre-trained DNN.\nThe remainder of this paper is organized as follows. First, in Section 2, we outline the methodologies we develop for designing training data to train DNNs, along with some practical considerations. In Section 3, we introduce the construction of the automatic iterative approach and conduct simulation studies for Gaussian i.i.d and spatial extremes model, whereas in Section 4 we outline our unified database approach applied to time series data from an intractable model. In Section 5, we conclude and outline avenues for future research."
        },
        {
            "heading": "2 Parameter estimation with DNNs",
            "text": ""
        },
        {
            "heading": "2.1 Background",
            "text": "Consider a dataset x0 \u2208 RJ of observations generated from P \u2208 P(X ), where P is a Lesbegue measure and P(X ) denote the set of all Borel probability measures on the sample space X . To describe such a process, it is common practice to assume a statistical model P\u03b80 \u2208 P(X ) with probability density function p(\u00b7;\u03b80) parameterized by a finite number of parameters \u03b80 \u2282 \u0398 \u2208 RP . To characterize this distribution, one needs to estimate \u03b80 using the observations through the log-likelihood function l(\u03b80; x0) \u2261 log{p(x0;\u03b80)}.\nHighly structured data coming from a high-dimensional X are often related to intractable or computationally demanding likelihoods, but simulating data from p for given parameters is usually trivial. Recently, parameter estimation using DNNs have opened doors to solving previously intractable statistical estimation problems (see e.g., and Lenzi et al. (2021) and Sainsbury-Dale et al. (2022)). As shown in these papers, the key to efficiency is to avoid altogether learning likelihood functions and directly learn the mapping between data and parameters through DNNs by carrying out simulations. To formulate the problem, let xn \u2208 RJ be a simulated sample from p(\u00b7;\u03b8n) with given parameters \u03b8n \u2208 RP . Then, the mapping from x = (x1, . . . ,xN)> onto\n\u03b8 = (\u03b81, . . . ,\u03b8N) > is learned by adjusting the weights w and biases b, denoted by \u03c6 = (w,b)> of a DNN F\u03c6, such that\nF\u03c6 : x 7\u2192 \u03b8; \u03b8\u0302 = argmin\u03c6L{\u03b8,F\u03c6(x)}. (1)\nOptimizing (1) with respect to \u03c6 requires the minimization of the loss function L, which is chosen to reduce the error in prediction for a given output \u03b8 and simulated data x. A popular choice in regression problems is the mean squared error (MSE)\nL(\u03c6;\u03b8,x) = E{\u03b8 \u2212F\u03c6(x)}2.\nOften, no closed-form solutions can be derived for the optimization in (1), and advanced numerical optimizers built around batch gradient descent methods are employed (Kingma and Ba, 2014). Finally, once the DNN has been trained, one can use the estimated \u03c6\u0302 to plug in x0 into the trained DNN and retrieve F\u03c6\u0302(x0), which will then output parameter estimates of interest \u03b8\u03020."
        },
        {
            "heading": "2.2 Transformations to data and parameters",
            "text": "Here, we detail our rationale for choosing transformations to data and parameters and make the problem more palatable for the DNN. The key is to use our statistical knowledge of intrinsic data and parameter properties to leverage estimation. For instance, the quadratic loss in (2) is optimal for outputs with constant mean and variance that are a real-valued function of the inputs with Gaussian distributed noises. If these assumptions are met, the estimator F retains the desired properties, such as the minimum variance and fast convergence, as the gradient reduces gradually for relatively small errors (Friedman et al., 2001). Therefore, reparametrization related to scaling should aim for a constant variance for different parameter values.\nWhen minimizing the loss in (1), \u03c6 is usually initialized to random values and updated via an optimization algorithm, such as stochastic gradient descent based on training data. As is usually the case, the geometry of the surface that has to be optimized will be complicated and smooth\ndue to an ample search space and noisy data, and using the raw data will likely result in slow and unstable convergence. To remedy this problem and improve the algorithm\u2019s stability, one should aim for properties such as symmetric and unbounded distributions, orthogonal parameters, and constant Fisher information. The logarithm and square root transformations often used in time series problems are examples of desirable change that affects the distribution shape by reducing skewness, stabilizing the variance, and simultaneously avoiding boundaries. Parameterization with meaningful interpretations such as mean and variance should be preferred over directly using distribution parameters.\nIn Sections 3 and 4, we will use transformation within a DNN pipeline to estimate parameters of models for Gaussian data, spatial extremes, and non-Gaussian stochastic volatility models. We show that whereas these precautions are helpful in simple Gaussian examples, they are indispensable in complex models such as for spatial extremes."
        },
        {
            "heading": "2.3 Designing training data",
            "text": "Recall that the first step for optimizing (1) is generating pairs of training data (\u03b8n,xn) N n=1. The main challenge here is to generate training data that correspond to configurations covering the parameter domain of the observations, which is unknown. Since \u0398 is often unbounded and it is impossible to simulate over the entire domain. Not introducing an appropriate structure or prior scientific knowledge will lead to inaccurate training data and, thus, erroneous estimation.\nIn the context of intractable likelihoods for which MLEs are unavailable, Lenzi et al. (2021) proposed to simulate training data based on informative parameter estimates from approximate maximum likelihood methods fit to spatial extremes data. However, obtaining these estimates for every new dataset becomes problematic if likelihood estimation is slow or not feasible in the first place. Here, we propose two different strategies to deal with this challenge. The intuition behind these method goes as follow:\n(A) A fully automatic iterative approach: Promising regions in \u0398 are found sequentially. The\nDNN is initially trained with \u03b8 based on a crude guess (e.g., from a simpler model). The trained DNN then receives x0 and outputs \u03b8\u03020, which is used to simulate bootstrapping samples xb \u223c p(; \u03b8\u03020). Next, xb is fed into the trained DNN to output bootstrapping samples \u03b8\u0302b. The spread of \u03b8\u0302b and its distance from \u03b8\u03020 are used to guide simulations for training the DNN. After a few iterations, we reach our goal, and the training data and the bootstrapping samples are concentrated around the true parameters.\n(B) A general unified database approach for time series: Computation efficiency is achieved by\ntraining the DNN in advance and reusing it to estimate newly collected data for free. The pre-training is based on an extensive database comprising simulated time series data x and corresponding parameters \u03b8. Next, parameter estimates from new data of different lengths are obtained by replicating the observations to achieve the size of x.\nThe details on the building blocks of the frameworks in (A) and (B), along with the necessary\nadjustments for different applications, are given in Sections 3 and 4."
        },
        {
            "heading": "3 A fully automatic iterative approach",
            "text": ""
        },
        {
            "heading": "3.1 General framework",
            "text": "We now use the notation in Section 2 to describe an algorithm that sequentially samples training data until it reaches the correct parameter regions from the data. Our algorithm is initialized with simulated pairs (\u03b8n,xn) N n=1, where the elements in \u03b8n \u2208 RP are draw from P independent Uniform distributions, each bounded below by (a1,p) P p=1 and above by (a2,p) P p=1, while xn \u2208 RJ is data simulated with \u03b8n, n = 1, . . . , N . Intervals (a1,p, a2,p) P p=1 may or may not contain the true parameter (\u03b80,p) P p=1. Whereas good initial guesses of (a1,p) P p=1 and (a2,p) P p=1 are not essential here, most models allow for some data-driven estimates, e.g., based on simplified Gaussian assumptions. Next, a DNN is trained with (\u03b8n,xn) N n=1, and then used to retrieve estimates \u03b8\u03020 \u2208 RP when fed with observations x0 \u2208 RJ .\nThe main idea is to then dynamically update the training data (\u03b8n,xn) N n=1 by changing the\nvalues of (a1,p) P p=1 and (a2,p) P p=1 based on information on whether \u03b8\u03020,p is underestimating or overestimating \u03b80,p. For instance, if \u03b8\u03020,p is close to the upper boundary of the training data for a specific p, then new training samples should be expanded to contain data outside of that boundary. Information on the accuracy of (\u03b8\u03020,p) P p=1 is obtained by sampling new data xb = (x1b , . . . ,x B b ) > with xb \u2208 RJ\u00d7B using \u03b8\u03020, and feeding these data into the initially trained DNN producing a bootstrapped sample \u03b8\u0302b = (\u03b8\u0302 1 b , . . . , \u03b8\u0302 B b ) >, \u03b8\u0302b \u2208 RP\u00d7B. For each p, we then update a1,p and a2,p to values in a neighborhood of \u03b8\u03020,p, where the neighborhood region is defined by the size of the bias between \u03b8\u03020,p and \u03b8\u0303p, where \u03b8\u0303p is the median of \u03b8 1 p, . . . , \u03b8 B p , and the neighborhood width depends on the quantiles of the bias between the fitted value and the bootstrapped sample: Q\u03b1p (\u03b8\u03020,p \u2212 \u03b81p, . . . , \u03b8\u03020,p \u2212 \u03b8Bp ), where \u03b1 is a quantile. The algorithm stops when the bias between \u03b8\u03020,p and \u03b8\u0303p is sufficiently small compared to the standard deviation of (\u03b8 1 p, . . . , \u03b8 B p ) >, which we denote by Sp, for all p. In more detail, the algorithm is as follows. Algorithm 1 Iterative procedure Need: Observations x0 \u2208 RJ from a distribution p,\u03b80 \u2208 RP and a neural network F\u03c6(\u00b7) Pick \u03b3 \u2208 (0, 1), a1,p and a2,p, p = 1, . . . , P, 1: while bias(\u03b8\u03020,p, \u03b8\u0303b,p) > \u03b3 \u00d7 Sp, for all p do 2: Sample \u03b8n,p \u223c Unif(a1,p, a2,p), n = 1, . . . , N 3: Simulate xn \u223c p(;\u03b8n), n = 1, . . . , N 4: Train F\u03c6(x) and obtain \u03b8\u03020 from F\u03c6\u0302(x0) 5: Simulate xb \u223c p(; \u03b8\u03020) and obtain \u03b8\u0302b from F\u03c6\u0302(xb), b = 1, . . . , B 6: a1,p = \u03b8\u03020,p + bias(\u03b8\u03020,p, \u03b8\u0303p)\u2212Q0.05p (\u03b8\u03020,p \u2212 \u03b81p, . . . , \u03b8\u03020,p \u2212 \u03b8Bp ) 7: a2,p = \u03b8\u03020,p + bias(\u03b8\u03020,p, \u03b8\u0303p) +Q0.975p (\u03b8\u03020,p \u2212 \u03b81p, . . . , \u03b8\u03020,p \u2212 \u03b8Bp ) 8: end while\nSmall values of \u03b3 in line 1 of Algorithm 1 will make the algorithm run longer, since it requires\n\u03b8\u03020,p to be closer to \u03b8\u0303b,p relative to the spread of \u03b8 1 p, . . . , \u03b8 B p . At each iteration, line 5 automatically provides uncertainty quantification of \u03b8\u03020 through \u03b8\u0302b. This step works as a modified and more efficient parametric bootstrap method since it uses the previously trained DNN, and no model fitting is required to produce \u03b8\u0302b. One can use these samples to compute quantities of interest, such as confidence intervals and coverage, and check the overall appropriateness of the method.\nHere, we use them to quantify the accuracy of the current iteration and to update the training data for the next round (see lines 6 and 7).\nParameter values \u03b8 are usually in the transformed scale, and we continuously sample training data such that the values in this transformed scale are uniformly distributed (see line 2 of Algorithm 1) rather than applying transformations after the training data have been generated to train the DNN. The former would produce regions of scarcity in \u0398, and results for testing data within the underrepresented values would not be optimal. Indeed, the optimization inside the DNN will perform best if the training data have no significant gaps between values, a problem also called imbalanced data in classification problems (Murphey et al., 2004).\nIn Section 3.2, we estimate the parameters of an i.i.d Gaussian model as a proof-of-concept, whereas, in Section 3.3, we consider a spatial-extremes setting and estimate the parameters of the Brown-Resnick max-stable process with an intractable likelihood. This procedure supports a wide range of likelihoods with fixed and random effects, and distributions other than the Uniform could also have been used in line 2 of Algorithm 1."
        },
        {
            "heading": "3.2 I.i.d. data",
            "text": "Although classical inference for the models considered in this section is straightforward, they allow us to compare our estimates\u2019 accuracy and uncertainty with MLEs. For applications where our method is of practical interest, see Section 3.3. In what follows, we look at three problems of increasing complexity from parameters of Gaussian distributions: the logarithm variance (single parameter), the mean and the logarithm variance (two orthogonal parameters), and the first moment and logarithm of the second moment (two highly dependent parameters). With these examples, we aim to empirically illustrate that our framework: (1) approaches the MLE even when the initial training data is relatively far from the actual value; (2) learns independence in the data by permuting i.i.d samples (3) reaches the truth quicker when using meaningful parametrizations and orthogonal parameters.\nConsider i.i.d. observations x0 \u2208 RJ from a Gaussian distribution N (\u00b5, \u03c320). We find that \u03b3 = 0.3 in line 1 of Algorithm 1 is enough to provide good estimation accuracy without overly increasing computational cost. Algorithm 2 shows the steps of our procedure for the i.i.d. case (see Algorithm 1 for the general case), whereas some practical aspects are discussed in what follows. Algorithm 2 Iterative procedure for i.i.d. data Need: Observations x0 \u2208 RJ from a distribution p,\u03b80 \u2208 RP and a neural network F\u03c6(\u00b7) Pick a1,p and a2,p, p = 1, 2\n1: while bias(\u03b8\u03020,p, \u03b8\u0303b,p) > 0.3\u00d7 Sp, for all p do 2: Sample \u03b8n,p \u223c Unif(a1,p, a2,p), n = 1, . . . , N 3: Simulate x\u2217n \u223c p(;\u03b8n), n = 1, . . . , N 4: Permute the elements in x\u2217n L times to obtain xn 5: Train F\u03c6(x) and obtain \u03b8\u03020 from F\u03c6\u0302(x0) 6: Simulate xb \u223c p(; \u03b8\u03020) and obtain \u03b8\u0302b from F\u03c6\u0302(xb), b = 1, . . . , B 7: a1,p = \u03b8\u03020,p + bias(\u03b8\u03020,p, \u03b8\u0303p)\u2212Q0.05p (\u03b8\u03020,p \u2212 \u03b81p, . . . , \u03b8\u03020,p \u2212 \u03b8Bp ) 8: a2,p = \u03b8\u03020,p + bias(\u03b8\u03020,p, \u03b8\u0303p) +Q0.975p (\u03b8\u03020,p \u2212 \u03b81p, . . . , \u03b8\u03020,p \u2212 \u03b8Bp ) 9: Increase N by 5% 10: end while\nIntroducing independence through permutations For unstructured data such as the one described in this section, the order of the data points is irrelevant. In other words, for each n, the distribution of the vector xn does not change if we permute the vector elements: p(x (i) 1,n, . . . , x (i) J,n;\u03b8n) = p(x\n(i) \u03c31,n , . . . , x\u03c3(i)J,n ;\u03b8n) for all permutations \u03c3 of the indices {1, . . . , J}.\nWhereas typical MLEs for i.i.d. data encode independence on the likelihood function by factorizing it into individual likelihood terms, a neural network is subjected to learn random dependencies in the data wrongly. Independence is essential information when constructing an estimator, especially when only a limited number of samples are available. While one could argue that flexible deep learning models could learn by training, enforcing exchangeability improves learning efficiency. It implicitly increases the size of the training data without extra computational costs. Therefore, we instruct exchangeability by permuting the values within each training sample L times, such that N \u00d7 L samples are used for training. In contrast, the number of dis-\ntinct output values is still N . The idea is that when the neural network encounters the same output for different input data, it learns that even though the elements\u2019 order has changed, these data are equivalent, and no dependence structure is present.\nMulti-layer perceptron (MLP) A perceptron is a single neuron model, and MLPs are the classical type of neural network comprised of one or more layers of several neurons. It takes 1D vectors as the input and learns nonlinear relationships between inputs and outputs, making it a suitable choice for our i.i.d. regression problem. Due to the simplicity of this toy example, we find that a small MLP with a single hidden layer and 50 hidden units is enough to near the mapping between data and parameters. We consider an MLP for F\u03c6 taking output in RP and input in RJ (see line 5 of Algorithm 2).\nProgressively increasing training accuracy Our algorithm uses fewer training samples when estimation uncertainty is larger, at the beginning of the algorithm, and more samples towards the end, when more precision is required. When the estimates are close to stabilizing, and the uncertainty has decreased, the number of samples in the training data is set to increase by 5% (see line 9 of Algorithm 2).\nResults for a single parameter Figure 1 displays the results for estimating \u03b80 \u2261 log(\u03c320) = 1 when the mean is known using Algorithm 2. We set L = 10 and N = 1000 and uniformly generate training output samples {\u03b8n}Nn=1 \u223c Unif(\u22122, 1) and corresponding inputs {xn}Nn=1 \u223c N{1, exp(\u03b8n)}, where the elements in the later are permuted L = 10 times for each n. The grey boxes in this figure are the training data at each iteration, whereas fitted values are represented by the red line, with the blue boxes showing bootstrapped estimates for B = 10000. The left panel in this figure shows that after five iterations, the algorithm approaches the MLE (green dashed line) with low uncertainty (see narrow blue boxes). To quantify the appropriateness of our method and as a calibration measure, we compare 95% central intervals from the bootstrapping estimates with\nthe same interval from the empirical variance in the data. The 95% interval provides adequate uncertainty of the MLP estimates with a close match with the intended coverage probability of the MLE (see right panel of Figure 1).\nResults for two independent/dependent parameters We now increase the problem\u2019s complexity and evaluate the performance of Algorithm 2 when two parameters are estimated jointly. We use the same test data as in the single parameter estimation case (see Figure 1), that is, data from a Gaussian distribution with \u00b50 = 1 and log(\u03c3 2 0) = 1. Specifically, we look at two cases: 1. estimating the mean \u00b50 and log-variance log(\u03c3 2 0) and 2. estimating the first moment m1 = \u00b50 and the logarithm of the second moment m2 = log(\u00b5 2 0 + \u03c3 2 0). Whereas in case 1, the parameters are independent, the MLP has to learn the relation between data and highly dependent parameters in case 2. In both cases, initial training data does not contain the actual parameters, such that: 1. \u00b5n \u223c Unif(\u22120.5, 0.5), and log(\u03c32n) \u223c Unif(\u22122, 1), 2. m1,n \u223c Unif(\u22120.5, 0.5) and m2,n \u223c Unif{\u22120.52 + exp(\u22122), 0.52 + exp(1)}, n = 1, . . . , N . Similarly to\nthe single parameter estimation, we fix N = 1000, L = 10, and J = 20. Figure 2 displays the estimates for Case 1. (top row) and 2. (bottom row) after running Algorithm 2 with the logarithm transformations (left column) and without (right column). Estimates are more accurate when the parameters are transformed, and for Case 2, the MLP underestimates the raw moments. Especially for the second moment, the algorithm without transformation narrows the estimates close to the median of the initial training data. In contrast, the reparametrization is able to recover highly dependent parameters accurately. Indeed, in both cases, the MLP can detect accurate parameter estimates already in the first iteration. The subsequent iterations refine the estimates and concentrate the training and the bootstrapping samples around the MLEs. This experiment reiterates the benefit of using unbounded and orthogonal parameters for training the MLPs."
        },
        {
            "heading": "3.3 Spatial extremes",
            "text": "We now move to a more complex model for spatial extremes, which is well-known to have a likelihood function that is effectively impossible to compute. Max-stable distributions are the only possible non-degenerate limits of renormalized pointwise maxima of i.i.d random fields and, therefore, the most commonly used for studying multivariate extreme events Davison et al. (2012). We consider the following definition of a max-stable process\nX(s) = max i\u22651\n\u03beiWi(s), s \u2208 S, (2)\nwhere {\u03bei}i\u22651 are points of a Poisson process on (0,\u221e) with intensity d\u039b(\u03be) = \u03be\u22122d\u03be. We consider the Brown-Resnick model (Kabluchko et al., 2009), which arises when Wi(s) = exp{ i(s)\u2212\u03b3i(s)}. Each {Wi}i\u22651 is a nonnegative stochastic process with unit mean, whereas i(s) are copies of a zero-mean Gaussian process with semivariogram \u03b3(h) = (\u2016h\u2016/\u03bb)\u03bd , spatial separation distance h, range \u03bb > 0, smoothness \u03bd \u2208 (0, 2] and such that \u03c32(h) = var{ (h)} = 2\u03b3(h).\nThe cumulative distribution of X(s) is\np(X(s1) \u2264 x1, . . . , X(sD) \u2264 xD) = exp{\u2212V (x1, . . . , xD)},\nwhere V (x1, . . . , xD) = E[max{W (s1)/x1, . . . ,W (sD)/xD}] satisfies homogeneity and marginal constraints. The full likelihood is written as\nf(x1, . . . , xD) = exp{\u2212V (x1, . . . , xD)} \u2211 \u03c0\u2208\u0393 R\u220f r=1 {\u2212V\u03c0r(x1, . . . , xD)},\nwhere \u0393 is a collection of all partitions \u03c0 = {\u03c01, . . . , \u03c0R} of {1, . . . , D} and V\u03c0r denotes the partial derivative of V with respect to the variables indexed by \u03c0r. The full likelihood is intractable even for moderate D since the number of terms grows equals the Bell number, which is more than exponentially. The standard workaround for this issue is to consider only pairs of possibly weighted observations in the likelihood (Padoan et al., 2010; Davis et al., 2013; Shang et al.,\n2015):\nl(\u03b8) = \u2211\n(j1,j2)\u2208P\n\u03b1j1,j2 [ log{V1(xj1 , xj2)V2(xj1 , xj2)\u2212 V12(xj1 , xj2)} \u2212 V1(xj1 , xj2) ] ,\nwhere xj is the block maximum at location j, \u0393 = {(j1, j2) : 1 \u2264 j1 < j2 \u2264 D}, \u03b8 \u2208 \u0398 \u2282 RP is the vector of unknown parameters and \u03b1j1,j2 \u2265 0 is the weight of {j1, j2}.\nWe compare the estimators from our fully automatic iterative approach with pairwise likelihood estimation on I = 100 independent simulated datasets of a Brown-Resnick model with \u03bb0 = 6.2 and \u03bd0 = 1 on a spatial domain S of size [0; 30] \u00d7 [0; 30] with unit-square grid cells. The steps used for estimating parameters of Brown-Resnick processes are shown in Algorithm 3. To improve accuracy and efficiency, the pairwise likelihood if fit only with pairs with at most 5- units apart and using the R-function fitmaxstab from the SpatialExtremes R-package (Ribatet, 2013).\nAlgorithm 3 Iterative procedure for Brown-Resnick processes Need: Observations x0 \u2208 RJ from a distribution p,\u03b80 \u2208 RP and a neural network F\u03c6(\u00b7) Pick a1,p and a2,p, p = 1, 2, and set D = {} 1: while bias(\u03b8\u03020,p, \u03b8\u0303b,p) > 0.3\u00d7 Sp, for all p do 2: Sample \u03b8n,p \u223c Unif(a1,p, a2,p), n = 1, . . . , N 3: Simulate xn \u223c p(;\u03b8n), n = 1, . . . , N 4: Set Dtrain = (\u03b8n,xn)Nn=1 5: Train F\u03c6(x) on Dtrain \u22c3 D and obtain \u03b8\u03020 from F\u03c6\u0302(x0)\n6: Simulate xb \u223c p(; \u03b8\u03020) and obtain \u03b8\u0302b from F\u03c6\u0302(xb), b = 1, . . . , B 7: a1,p = \u03b8\u03020,p + bias(\u03b8\u03020,p, \u03b8\u0303p)\u2212Q0.05p (\u03b8\u03020,p \u2212 \u03b81p, . . . , \u03b8\u03020,p \u2212 \u03b8Bp ) 8: a2,p = \u03b8\u03020,p + bias(\u03b8\u03020,p, \u03b8\u0303p) +Q0.975p (\u03b8\u03020,p \u2212 \u03b81p, . . . , \u03b8\u03020,p \u2212 \u03b8Bp ) 9: Randomly select a subset of Dtrain such that Dtrain \u2229 D = \u2205 and add those into D 10: end while\nConvolution neural network (CNN) CNN uses convolutions, that is, the application of a filter to the input image that results in what is called an activation. Repeated application of the same filter to images results in a map of activations (feature map). This map indicates the locations and strength of a detected feature in the input, such as the edges of objects, and therefore, it is a common choice for regularly-spaced gridded images. We use two 2D convolutions\nwith 16 and 8 filters, respectively, and rectified linear unit (ReLU) activation function and kernel of size 3 \u00d7 3 (Hastie et al., 2009). We add one dense layer at the end of the network with four units that map the input image to an output vector of size two. The CNN weights are initialized randomly and trained using the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 0.01. The training is performed for 30 epochs, and at each epoch, the CNN weights are updated utilizing a batch size of 100 samples from the entire training dataset.\nInitialization We start the by simulatingN = 6000 pairs (\u03b8n,xn) N n=1, where \u03b8n \u2261 (\u03b8n,1, \u03b8n,2)> \u2261 {log(\u03bbn), logit(\u03bdn)}> and xn is simulated from (2). We initialize (\u03b8n,1)Nn=1 based on estimates of a Gaussian process with powered exponential covariance function C(h) = exp(\u2212(\u2016h\u2016/\u03b1)\u03b7), \u03b1 > 0, 0 < \u03b7 \u2264 2, which closely matches the Brown-Resnick variogram. We sample \u03b8n,1 \u223c Unif{log(\u03b1\u0302n)\u2212 c, log(\u03b1\u0302n) + c}. Such estimates are likely biased for Brown-Resnick, but they are quick to compute and a better start than a random guess. A line search for c indicates that c = 2 provides good results but found that other values of c gave similar accuracy. We uniformly draw (\u03b8n,2) N n=1 over approximately the whole (bounded) domain: \u03b8n,2 \u223c Unif{logit(0.1), logit(1.9)}. We initialize the pairwise likelihood with the powered exponential covariance function estimates for a fair comparison with our approach.\nRe-using data We reuse training data from the previous iteration since simulations of BrownResnick processes are relatively expensive. Among the samples not contained in the updated uniform interval of the current iteration, we randomly select 40% and add them to the training data of the current step (see line 9 of Algorithm 3). Besides increasing the size of the training without having to simulate new data, this broadens the range of the training while still keeping most of the samples in the updated region defined by the current step. Therefore, it prevents the current iteration from being stuck in the wrong region while maintaining more accurate training data in the most probable parameter region.\nFigure 3 shows a scatterplot of 100 independent estimates of \u03b81 \u2261 log(\u03bb0) versus \u03b82 \u2261 log(\u03bd0)\nfrom the last iteration of our approach (green) and from the pairwise likelihood (red). The \u00d7 symbol is the truth. Whereas the proposed method produces robust results across the different replicates, the pairwise likelihood tends to underestimate the smoothness parameter, and the performance varies considerably across datasets. In Figure 4, we access the accuracy of Algorithm 3 for estimating \u03b81 (left column) and \u03b82 (right column) with boxplots. The rows in this figure illustrate the results for two different datasets: The first is initialized with training data that do not contain \u03b81 (top), whereas the variogram estimate for the second dataset is close to the center of the training data. Indeed, whereas the space covering \u03b82 is bounded, and simulating training data covering the entire region is straightforward, the training data for \u03b82 is based on the variogram estimate and, therefore, only sometimes contains the truth. The grey and blue boxplots at each plot and iteration are the training output and bootstrapping samples, respectively. As expected, the gray boxplots in all cases at iterations 2 and 3 contain several outliers, which correspond to the samples reused from the previous step. Points in the red line are the fitted values from the CNN, and the green dashed lines are the actual parameters used to simulate data.\nEven when the true value is not included in the initial training data (see the top of Figure 4), the CNN estimates \u03b81 well and produces reasonable uncertainties. At the last iteration, the training data for both parameters are narrow and around the actual value, and the bootstrapping samples practically coincide with the training data. When initialized with training data containing the truth, the CNN quickly approaches the truth with low uncertainty for both parameters and remains stable until it reaches the stopping criteria. A quantitative measure of the effect of the iterations in Algorithm 3 is reported in Table 1, with bias, standard deviation, and root mean square error (RMSE) for the first and last iterations. The metrics are calculated from the bootstrapping samples among the 100 independent datasets. Point estimates are taken as the median of the bootstrapping samples. Under all three metrics, there is a considerable improvement from the first to the last iteration of the algorithm, and estimation at the last\niteration are about 15% more efficient for \u03b81 and 30% more efficient for \u03b82 (with the efficiency defined as the ratio of RMSEs)."
        },
        {
            "heading": "4 A general unified database approach for time series",
            "text": ""
        },
        {
            "heading": "4.1 General framework",
            "text": "Suppose we observe time series data x0 = {x0(1), . . . , x0(T )}> from a strictly stationary process {X0(t) : t \u2208 T } indexed on the temporal domain T \u2282 R+. Let p(;\u03b80) be the probability distribution of X0(t) depending on the parameter set \u03b80 \u2208 \u0398 \u2282 RP . The stationarity assumption is that the joint probability distribution of {X0(t\u2212 l), . . . , X0(t)}> does not depend on X0(t\u2212 l\u2032) for any l\u2032 > l. This Markov property is common in time series analysis similarly with ergodicity, which provides the justification for estimating \u03b80 from a single sequence x0.\nOur main goal is to estimate \u03b80 by training a DNN F\u03c6 using parameter candidates as output and corresponding simulated data as input (see Section 2). Here, we take advantage of the stationarity property to generalize and improve the estimation workflow described in Section 2. Our approach is best exemplified by a toy data x0 = {x0(1), . . . , x0(T )}> with T = 50 from an AR process of order 1 with coefficient \u03c11 = 0.9. Instead of simulating training data of length T = 50, we proceed by simulating time series of length Tk = 250 and construct data pairs (\u03b8n,xn) N n=1, where \u03b8n \u2208 RP and xn = {xn(1), . . . , xn(250)}> and train a DNN. Next, since x0 is shorter than the training data, we create a new time series x\u22170 by concatenating x0 to achieve the desired length. Figure 5 shows how to construct x\u22170 from x0 by replicating the observations five times. The red dashed line are the joining points. The resulting x\u22170 is then fed into the trained DNN to retrieve estimates \u03b8\u03020.\nAs we will see in the example in the next section, this technique has several advantages over training the DNN using simulated data with the same length as the observations: (i) allows estimation of time series of several sizes at almost no computational cost, since the DNN does not have to be retrained for each new dataset. (ii) improves the network\u2019s performance by increasing the amount of data. (iii) holds without requiring any particular dependence structure assumption as long as the data is stationary and Markov.\nConnection to non-overlapping block bootstrap (NBB) The intuition behind our approach resembles NBB approaches (Carlstein, 1986). Similarly, this technique splits the observations into non-overlapping blocks and resamples the blocks with replacement, which are replicated to obtain a bootstrapped series. However, unlike block bootstrap methods, where the complex problem of choosing the block size has to be solved, by construction, our block size is always fixed and equal to T .\nDiscontinuity at the joining points Our procedure of laying sequences of length T endto-end will inevitably produce m\u2212 1 discontinuity points where the joining occurs, similarly to what happens in bootstrap for time series. However, as we will show empirically in our examples, these discontinuities will have a negligible contribution to the model parameters structure.\nVarying observation lengths As long as the database for training the neural network is extensive enough, the proposed method is easily generalized for cases where T is not a multiple\nof Tk. One can for instance replicate the data into m blocks, where m = bTkT c, and complete the remaining values with a random block from x0 of size TkmodT . The idea is that if Tk is large enough compared to T and with mT w Tk, as m\u2192\u221e and Tk \u2192\u221e, the last components of x\u22170 have little influence in the dependence structure.\n1D Convolutional Neural Networks Since we are dealing with parameters from time series data, we train 1D CNNs, which have proven successful in learning features from dependent observations onto one-dimensional dependent sequences. As for 2D CNNs (see Section 3.3 for an example), the input layer receives the (transformed) data, and the output layer is an MLP with the number of neurons equal to the number of output variables. Each neuron in a hidden layer first performs a sequence of convolutions, the sum of which is passed through the activation function followed by a sub-sampling operation. The early convolutional layers can be seen as smoothing the input vector, where the filters are similar to parameters of a weighted moving average but learned jointly with the regression parameters from the MLP layer. In what follows, we use three 1D convolutions with four filters each, the ReLU activation function, a kernel of size three, and one final dense layer with four units. We set a learning rate of 0.01 with 30 epochs and a batch size of 50 samples to update the weights."
        },
        {
            "heading": "4.2 Non-Gaussian stochastic volatility model",
            "text": "To show the usefulness of our approach, we focus on estimating parameters of financial time series data that exhibit non-Gaussian time-varying volatility. Volatility is highly right-skewed and bounded, making Gaussian distributions a poor representation. A better description of volatility is achieved with stochastic volatility models (SVOL), first introduced in Taylor (1982) and currently central to econometrics and finance investments theory and practice. The idea of SVOL models is to parsimoniously fit the volatility process as a latent structure using an unconditional approach that does not depend on observations. We consider the following model\nstructure\nx(t) = \u221a exp{h(t)} t, \u221a \u03bd \u2212 2 \u03bd (t) \u223c T\u03bd , t = 1, . . . , T\nh(t) = \u03c1h(t\u2212 1) + \u03bet, \u03be(t) \u223c N(0, \u03c32), (3)\nwhere (t) and \u03be(t) are independent noises and T is the number of observations. The volatility variable h(t) is latent with an autoregressive of order one structure, and only x(t) is observed. When |\u03c1| < 1, x(t) is strictly stationary with mean \u00b5h = 1/(1\u2212\u03c1) and variance \u03c32h = \u03c32/(1\u2212\u03c12) (Fridman and Harris, 1998).\nLikelihood evaluation of continuous dynamic latent-variable models such as (3) requires the integration of the latent process out of the joint density, resulting in the following T -dimensional integral\nl(\u03b8) = \u222b h p(x | h,\u03b8)p(h | \u03b8)dh\n= \u222b h T\u220f t=1 p(x | h)p{h(t) | h(t\u2212 1)}dh, (4)\nwhere x = {x(1), . . . , x(T )}>, h = {h(1), . . . , h(T )}>, the conditional densities p(x | h,\u03b8) and p{h(t) | h(t\u2212 1)} have the form in (3), and the initial volatility h(0) is the stationary volatility distribution p(h). Since h(t) is not independent from the past, the integral in (4) cannot be factored into a product of T one-dimensional integrals and exact evaluation of the likelihood is possible only in special cases like when both p(x | h,\u03b8) and p{h(t) | h(t \u2212 1)} are Gaussian. Alternative approaches for likelihood evaluation include computationally demanding Markov Chain Monte Carlo (MCMC) (Andersen et al., 1999) and the more recent and faster Integrated Nested Laplace Approximation (INLA) (Martino et al., 2011).\nNext, we give practical details of our framework as well as the a comparison of the results from our approach and the state-of-the-art INLA approach for estimating parameters of the SVOL model.\nImplementation Consider observations x0 = {x0(1), . . . , x0(T )}>, from the SVOL model with \u03c30 = 0.1, \u03c10 = 0.8 and \u03bd0 = 6. We use scaled (variance one) versions of both h(t) and\nx(t) in (3), such that only \u03c10 and \u03bd0 need to be estimated. To show the effect of estimating time series of different lengths with a single DNN fit, we display the results for various time series lengths: T = (500, 1000, 2000, 3000, 4000, 5000). Estimation goes as follows. The training database contain N = 10000 samples pairs (\u03b8n,xn) 10000 n=1 of transformed parameters \u03b8n = (\u03b81, \u03b82) > = {f1(\u03c1n), f2(\u03bdn)}>, with f1(x) = log ( 1+x 1\u2212x ) and f2(x) = log(x \u2212 2) and corresponding data xn = {xn(1), . . . , xn(5000)}> simulated from (3). The transformed parameters are sampled uniformly in a neighborhood of the actual parameter values \u03b80,1 = f1(\u03c10) and \u03b80,2 = f2(\u03bd0):\nf1(\u03c1j) \u223c Unif{\u03b80,1 \u2212 ca1, \u03b80,1 + cb1} f2(\u03bdj) \u223c Unif(\u03b80,2 \u2212 ca2, \u03b80,2 + cb2). (5)\nNew test data x\u22170 is obtained by replicating x0 m times as many time as needed to achieve size 5000. We fix ca1 = c a 2 = c b 1 = c b 2 = 2 in (5) to ensure a large enough region around the true values, although other constants provided similar results.\nFigure 6 displays scatterplots of estimated \u03b80,1 versus estimated \u03b80,2 from I = 30 independent replicates of the SVOL model. Scatterplots from top to bottom, left to right, shows testing sets of different size: T = (500, 1000, 2000, 3000, 4000, 5000). Green dots are the 1D CNN estimates, and red dots are the mean of the predicted posterior distribution from fitting model (3) using INLA. The \u00d7 symbol in each plot represents the truth. As the testing data sizes increase, both methods concentrate the estimates around the truth, and the 1D CNN estimates are less variable and less biased for smaller values of T ; after that, both methods seem to perform similarly well. Whereas we set the INLA priors to default values, changing them to penalize parameter values far from the mode could potentially improve the results.\nTo quantify the uncertainty in the 1D CNN estimates, we create a bootstrapped dataset by independently sampling B = 100000 time series from the fitted model and then feeding these samples into the trained 1D CNN. The uncertainty in the estimation of \u03b80,1 (left) and \u03b80,2 (right)\nfrom both methods is grasped in Figure 7. The bars represent central 95% intervals, taken from the posterior distribution given by INLA (red) and the 1D CNN bootstrapped samples (blue) for one randomly chosen dataset among the I = 30 replicates in Figure 6. The x-axis represents different test data sizes T = (500, 1000, 2000, 3000, 4000, 5000), and the gray horizontal dashed line is the truth. As expected, the uncertainties decrease with sample sizes for both methods. The intervals from both methods are close for most data sizes, although the INLA distributions are more concentrated for \u03b80,1 and T = (4000, 5000). Overall, these results show that the 1D CNN is robust to estimating parameters of different data lengths and in agreement with the INLA estimator."
        },
        {
            "heading": "5 Conclusion",
            "text": "We proposed approaches that train DNNs to estimate parameters of intractable models and quantify their uncertainty. Unlike previously proposed approaches using DNNs, which are tailored to a specific application and can lead to poor parameter estimates for relying on computationally expensive initial guesses to construct training data, our methods (A) leverage an iterative learning framework coupled with a modified parametric bootstrap step to guide simulations in the direction of the parameter region of the actual data in multiple rounds (B) use an extensive pre-trained database to accurately estimate parameters of time series data of multiple lengths at no computational cost, rather than simulating data for every new dataset. Our estimators yield accurate parameter estimates with much less computation time than classical methods, even when accounting for the time required to generate training samples. Extending our database approach to the spatial case would require more research because of an increase of the edge effect due to the replications.\nWhile DNNs for parameter estimation are gaining popularity, we still need to learn more about black-box algorithms applied to previously intractable statistical problems and how to de-\nsign task-specific estimators more generally. There are several further opportunities for exploring DNNs for parameter estimation using newly designed optimization tools from the machine learning community. This work is another step towards this direction, where ultimately, inference is performed within a general and flexible simulation-based black-box pipeline."
        }
    ],
    "title": "Towards Black-Box Parameter Estimation",
    "year": 2023
}