{
    "abstractText": "In order to effectively detect the abnormal driving behavior of drivers and reduce the incidence of traffic accidents, a YOLOv3 abnormal behavior monitoring algorithm based on dual channel attention mechanism is proposed. The algorithm is based on YOLOv3 network model. Firstly, the K-mean clustering algorithm is used to recluster the anctor, and nine prior frames suitable for abnormal behavior are obtained. Then, a dual channel attention mechanism module is introduced into the YOLOv3 feature extraction network to increase the weight of important information in each channel of the feature map. Finally, the loss function of the model is improved. Giou loss is used as the loss function of the boundary box of the model to better realize the regression of the boundary box and improve the performance and accuracy of the model. The experimental results show that the map value of the improved YOLOv3 algorithm in driver abnormal behavior detection reaches 95.91%, which is much higher than the traditional YOLOv3 model and other target detection models, and the detection effect is remarkable.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhiwen Feng"
        },
        {
            "affiliations": [],
            "name": "Jun Zhao"
        }
    ],
    "id": "SP:19bd6c78eec3df365572d846e598ebbfbc8da0cb",
    "references": [
        {
            "authors": [
                "M.Y. Deng",
                "R. Fu",
                "G.J. Chen"
            ],
            "title": "Collection and analysis about background factors of road traffic accidents index",
            "venue": "Journal of Chongqing Jiaotong University 31(4), 852-856 (2012).",
            "year": 2012
        },
        {
            "authors": [
                "G.H. Chen",
                "H. Zhen"
            ],
            "title": "Statistical analysis of major road accidents in Guangdong Province and their countermeasures",
            "venue": "Chinese Safety Science Journal 20(10), 106-12 (2008).",
            "year": 2008
        },
        {
            "authors": [
                "Y He"
            ],
            "title": "A comparison of statistical survey methods of traffic accident data between China and the Uuited States",
            "venue": "Journal of Transport Information and Safety 36(1), 1-9+27 (2008).",
            "year": 2008
        },
        {
            "authors": [
                "B. Hua",
                "X. Liang",
                "S. Liu",
                "J.C. Sheng"
            ],
            "title": "Renovated abnormal passenger crowd behavior detection system based on the speeding-up and squeezing in the public places",
            "venue": "Journal of Safety and Environment 17(3), 1043-1048 (2017).",
            "year": 2017
        },
        {
            "authors": [
                "B Hua",
                "X Liang",
                "J Liu S"
            ],
            "title": "Renovated abnormal passenger crowd behavior detection system based on the speeding-up and squeezing in the public places",
            "venue": "Journal of Safety and Environment",
            "year": 2017
        },
        {
            "authors": [
                "Q. Ji",
                "Z. Zhu",
                "P.J. Lan"
            ],
            "title": "Real-time nonintrusive monitoring and prediction of driver fatigue",
            "venue": "IEEE Transactions on Vehicular Technology 53(4), 1052-1068 (1995).",
            "year": 1995
        },
        {
            "authors": [
                "D.D. Chen"
            ],
            "title": "Research on Abnormal Driving Behavior Recognition Technology Based on Vehicle Dynamic Monitoring Data",
            "venue": "Beijing Jiaotong University, Master\u2019s Thesis,",
            "year": 2012
        },
        {
            "authors": [
                "Y.J. Liang",
                "H.K. Xiang"
            ],
            "title": "Vehicle posture discrimination method based on FNN",
            "venue": "Journal of Liaoning Technical University (Natural Science Edition) 37(2), 416-421."
        },
        {
            "authors": [
                "H.C. Tian",
                "L.F. Mo",
                "R.Q. Yan"
            ],
            "title": "Driving behavior identification in electric vehicle based on information fusion of vehicle information",
            "venue": "Chinese Journal of Sensors and Actuators 31(3), 355-362 (2018).",
            "year": 2018
        },
        {
            "authors": [
                "M. Awais",
                "N. Badruddin",
                "M.C. Drieberg"
            ],
            "title": "EEG brain connectivaty analysis to detect driver drowsiness using coherence",
            "venue": "Inter. Conf. on Frontiers of Information Technology, 110 (2017).",
            "year": 2017
        },
        {
            "authors": [
                "Y. Sun",
                "X.B.J. Yu"
            ],
            "title": "An innovation nonintrusive driver assistance system for vital signal monitoring",
            "venue": "IEEE Journal of Biomedical and Health Informatics 18, 1932-1939 (2014).",
            "year": 1932
        },
        {
            "authors": [
                "B.G. Lee",
                "W.Y. Chung"
            ],
            "title": "Driver altertnass monitoring using fusion of facial features and biosignals",
            "venue": "IEEE Sensors Journal 12(7), 2416-2422 (2012).",
            "year": 2012
        },
        {
            "authors": [
                "N.E. Haouij",
                "J.M. Poggi",
                "R.J. Ghozi"
            ],
            "title": "Random forest-based approach for physiological functional variable selection for driver\u2019s stress level classification",
            "venue": "Statistical Methods & Applications 28, 157-185 (2018).",
            "year": 2018
        },
        {
            "authors": [
                "N. Das",
                "E. Oho-Bar",
                "M.M.C. Trivedi"
            ],
            "title": "On performance evaluation of driver hand detection algorithms: Challenges, dataset, and metrics",
            "venue": "2015 IEEE 18th Inter. Conf. on Intelligent Transportation Systems, 2953 (2015).",
            "year": 2015
        },
        {
            "authors": [
                "R.A. Berri",
                "A.G. Silva",
                "R.S.C. Parpinelli"
            ],
            "title": "A pattern recognition system for detecting use of mobile phones while driving",
            "venue": "2014 Inter. Conf. on Computer Vision Theory and Applications, 411 (2014).",
            "year": 2014
        },
        {
            "authors": [
                "A. Ragab",
                "C. Craye",
                "M.S.C. Kamel"
            ],
            "title": "A visual-based driver distraction recognition and detection using random forest",
            "venue": "Inter. Conf. on Image Analysis and Recognition, 256 (2014). Proc. of SPIE Vol. 12506 125066H-8 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use",
            "year": 2014
        },
        {
            "authors": [
                "T.Y. Lin",
                "P. Dollar",
                "R.C. Gitshick"
            ],
            "title": "Feature pyramid networks for object detection",
            "venue": "IEEE Conf. on Computer Vision and Pattern Recognition, 936 (2017).",
            "year": 2017
        },
        {
            "authors": [
                "Q.D. Li",
                "T.C. Wang",
                "J.W. Cui",
                "B. Mu"
            ],
            "title": "Detection on dangerous operation behavior of forklift based on deep learning algorithm",
            "venue": "Journal of Safety Science and Technology 16(5), 155-159 (2019).",
            "year": 2019
        },
        {
            "authors": [
                "J.Y. Zhang",
                "Y.L. Zhou",
                "J.W. Chen"
            ],
            "title": "Research on pilot behavior detection algorithm based on deep learning",
            "venue": "China\u2019s New Technologies and New Products (4), 26-28 (2019). Proc. of SPIE Vol. 12506 125066H-9 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "YOLOv3 abnormal behavior monitoring algorithm based on dual channel attention mechanism is proposed. The algorithm is based on YOLOv3 network model. Firstly, the K-mean clustering algorithm is used to recluster the anctor, and nine prior frames suitable for abnormal behavior are obtained. Then, a dual channel attention mechanism module is introduced into the YOLOv3 feature extraction network to increase the weight of important information in each channel of the feature map. Finally, the loss function of the model is improved. Giou loss is used as the loss function of the boundary box of the model to better realize the regression of the boundary box and improve the performance and accuracy of the model. The experimental results show that the map value of the improved YOLOv3 algorithm in driver abnormal behavior detection reaches 95.91%, which is much higher than the traditional YOLOv3 model and other target detection models, and the detection effect is remarkable.\nKeywords: Deep learning, abnormal behavior, attention mechanism, YOLOv3, loss function"
        },
        {
            "heading": "1. INTRODUCTION",
            "text": "With the gradual development of society and the acceleration of the pace of urbanization, especially in the past 20 years, the railway transportation and road transportation industries have developed rapidly, and the number of vehicles in my country has risen sharply. Although it is convenient for people to travel, it also leads to the increasing rate of traffic accidents to a certain extent, resulting in huge economic losses and casualties. According to statistics, more than 90% of traffic accidents are caused by human drivers, and 30% of them are caused by drivers\u2019 irregular behaviors1-3. Therefore, detecting the driver\u2019s behavior, analyzing abnormal behavior and giving early warning will greatly increase the safety of vehicle operation.\nIn the 1960s, scholars began to explore the mechanism of abnormal behavior from the perspective of behavioral environment4. For the research on abnormal driving behavior of drivers, the method of manual review was initially used to identify abnormal driving behavior of drivers, which consumes a lot of manpower and has low efficiency; some scholars judge whether the driver is driving normally by monitoring the changes of vehicle parameters5-8. However, it is expensive and difficult to operate on a large scale. In addition to the differences in driver habits, the modeling analysis is prone to deviation. Some researchers analyze the changes in the driver\u2019s psychological state during driving to judge whether the driver is driving normally9-12. However, the professional equipment by drivers will affect their driving status and psychological changes, and the cost is high. In recent years, research on driver behavior based on computer vision has become a hot topic13. Berri and Silva use support vector machines to classify features14; Crave and Karray proposed AdaBoost classifier and hidden Markov model15. Due to the poor robustness of traditional detection techniques and large redundancy of detection windows, the accuracy and speed of target detection are limited. With the emergence of convolutional neural network, because of its good learning ability, the research on abnormal behavior target detection gradually develops to convolutional neural network.\nTarget detection algorithms can be generally divided into two types: one-stage and two-stage. The two-stage algorithm is to generate target candidate regions first, and then classify them in a classifier, such as R-CNN, Faster R-CNN, etc. In one-stage, the image is first divided into image patches one by one, and then each image patch has M anchor boxes, and all anchors are sent to the classifier to output classification and detection positions, such as SSD, YOLOv3, etc. Obviously, the speed of YOLOv3 has been significantly improved in the latter one-stage compared to the former. Based on this, YOLOv3 is used as the initial network, and the attention mechanism is added to the feature layer of the model to\n* 2792583453@qq.com\nThird International Conference on Computer Science and Communication Technology (ICCSCT 2022) edited by Yingfa Lu, Changbo Cheng, Proc. of SPIE Vol. 12506, 125066H\n\u00a9 2022 SPIE \u00b7 0277-786X \u00b7 doi: 10.1117/12.2662537\nProc. of SPIE Vol. 12506 125066H-1 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nimprove the model\u2019s ability to extract key information features, and at the same time, the loss function is improved to realize bounding box regression and detect abnormal driver behavior.\n2. YOLOV3 AND ATTENTION MECHANISM"
        },
        {
            "heading": "2.1 YOLOv3",
            "text": "YOLOv1 was proposed in 2015, announcing the beginning of the YOLO series of algorithms. On this basis, in 2018, the author proposed the YOLOv3 algorithm, which breakthroughly used Darknet-53 as the backbone network, and introduced the reverse pyramid FPN architecture to achieve multi-dimensional prediction. Figure 1 shows the YOLOv3 network structure.\n2.1.1 Darknet-53 Network Structure. As the feature extraction network of YOLOv3, Darknet-53 adds many ResNet residual network structures to the network structure. Its network structure is shown in Figure 2. It is a fully convolutional neural network, including 53 convolutional layers, except for the pooling layer. 3\u00d73 and 1\u00d71 convolution units with Step 2 are used, and batch normalization and activation functions are used after convolution to prevent the network from overfitting.\n2.1.2 Multi-scale Feature Prediction. In order to improve the problem of low detection accuracy of small targets in the previous YOLO series network models, YOLOv3 draws on the idea of FPN, establishes multi-size feature prediction,\nProc. of SPIE Vol. 12506 125066H-2 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nand generates 3 feature maps of different sizes. The network features are shown in the figure. After 3 images, there are 3 kinds of downsampling, namely 8 times downsampling, 16 layers downsampling and 32 times downsampling, and 32 times downsampling is used, which uses feature maps of different sizes to be fused to enhance shallow features. For example, 13\u00d713 is changed to 26\u00d726, and fused with 26\u00d726 feature map to strengthen features and improve detection accuracy and improve the effect of YOLOv3 model.\n2.1.3 Loss Function. The loss function of the YOLOv3 model consists of coordinate prediction loss, confidence prediction loss, and category prediction loss. Among them, both the confidence loss and the category prediction loss are changed from the sum of squares of errors of YOLOv1 and YOLOv2 to the cross entropy which has better effect on category and confidence prediction. The loss function formula is:\n \n\n\n\n\n=\n= =\n= =\n= =\n= =\n\u2212\u2212+\n\u2212\u2212+\u2212\n\u2212\u2212+\u2212\n\u2212+\u2212+\n\u2212+\u2212=\n2\n2\n2\n2\n2\n0\n0 0\n0 0\n0 0\n22\n0 0\n22\n11\n11\n11\noss\nS\ni classes\nj\ni\nj\ni\nj\ni\nj\ni\nnoobj ij\nS\ni\nB\nj\nj j j i j j j i noobj ijcoord\nS\ni\nB\nj\nj\ni\nj i j i j i obj ij\nS\ni\nB\nj\nj\ni\nj\ni\nj\ni\nj\ni\nobj\nijcoord\nS\ni\nB\nj\nj\ni\nj\ni\nj\ni\nj\ni\nobj\nijcoord\n))]c(plog()p\u0302())c(plog()c(p\u0302[I\n)]Clog()C\u0302()Clog(C\u0302[I\n)]Clog()C\u0302()Clog(C\u0302[I\n])h\u0302h()w\u0302w[(I\n])y\u0302y()x\u0302x[(IL\n\n\n\n(1)\nwhere (x, y, w, h) represent the relative values of the center coordinates and width and height of the prediction frame relative to the network, I represents the anchor frame in the grid, C represents the real value of the object, and classes are different Classification of objects."
        },
        {
            "heading": "3. IMPROVED YOLOV3 ALGORITHM",
            "text": ""
        },
        {
            "heading": "3.1 Add attention mechanism module",
            "text": "During the driving process of the driver in the real environment, affected by the external environment, driver status, driver behavior habits, etc., it will add interference to the detection of abnormal behavior. By obtaining more and more accurate feature information in the environment, the detection accuracy of the YOLOv3 algorithm is improved.\nIn order to extract features from the network, the multi-scale prediction layer of YOLOv3 adopts a structure similar to Feature Pyramid Network (FPN)16, which fuses the extracted feature information on these three scales, and then performs object detection. This paper will introduce the dual-channel attention mechanism CBAM module, comprehensively use the attention mechanism from the two aspects of channel and space, add it to each branch of the multi-scale prediction layer of the feature extraction network, suppress useless information, and extract useful information more efficiently information to improve the detection ability of the algorithm. Channel attention is used to filter the F channel, while spatial attention emphasizes the obvious intervals of the feature map. The specific implementation process is shown in Figure 3. The input is the original feature F with dimension w\u00d7h\u00d7m, and the output is the attention meta-feature F. The calculation steps are as follows:\n(1) The channel information is adjusted. The input meta-feature F of dimension w\u00d7h\u00d7m enters the channel attention network, and performs global maximum pooling and global average pooling operations respectively to generate two tensors with dimensions of 1\u00d71\u00d7m. The tensors are spliced with each other to form a 1\u00d71\u00d7m fusion tensor. After activation by the Sigmoid function, it is multiplied with the original input feature F in the form of an element-wise matrix (element-wise) and corrected to obtain the intermediate element feature.\n(2) Spatial and channel attention information is fused. After entering the spatial attention network, the intermediate feature F\u2019 is subjected to channel maximum pooling and channel average pooling, respectively, to form two matrices with dimensions w \u00d7 h. These two matrices are spliced and fused to obtain a dimension of w. After the fusion tensor of h\nProc. of SPIE Vol. 12506 125066H-3 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nis activated by the Sigmoid function, it is finally multiplied with the input feature F in the form of an element matrix, and finally the meta-feature F\u2019of the attention mechanism of the target detection area is formed."
        },
        {
            "heading": "3.2 Improved loss function",
            "text": "The traditional Intersection over Union (IoU) is a commonly used indicator for evaluating the performance of target detection networks. The value of IoU is positively correlated with the degree of overlap between the predicted frame and the real frame. The calculation formula is as follows:\n|BA|\n|BA| IoU\n\n = (2)\nwhere A represents the real frame; B represents the prediction box.\nUsing IoU as the loss function, when there is no overlap between the real frame and the predicted frame, the loss function IoU is 0, and the distance between the real frame and the predicted frame cannot be measured, resulting in a gradient of 0 for the optimization loss function, which cannot be optimized. Aiming at this problem, it is proposed to use GIoU loss function instead of IoU to determine the error.\nUsing GIoU as the loss function can overcome the shortcomings of IoU\u2019s inability to measure the distance between the real box and the predicted box, and can better achieve bounding box regression, improve the model, and optimize the network in a better direction. Its calculation formula is as follows:\n|C|\n|)BA(\\C| IoUUGI  \u2212=o (3)\nwhere C represents the smallest bounding rectangle between the ground-truth box and the predicted box.\nThe IoU is replaced by the GIoU loss function, and the new loss function of the improved YOLOv3 model is obtained as follows:\nGIoULbbox \u2212=1 (4)"
        },
        {
            "heading": "3.3 Improved prior box",
            "text": "Anctor is a set of reference frames with different sizes, and its size is fixed. When doing target detection, the prior box is usually used as the initial prediction, and then gradually regressed and adjusted. Its calculation formula is as follows:\nProc. of SPIE Vol. 12506 125066H-4 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\n)centroid,box(IoU)centroid,,box(D)centroid,box(IoU)centroid,box(D \u2212=\u2212= 11\nUsing anctor suitable for abnormal behavior detection not only speeds up the convergence of the model, but also further improves the accuracy of object detection. The 9 anctors used by the YOLOv3 model were obtained using the K-means clustering algorithm on the COCO dataset.\nThe research content of this paper is the abnormal driving behavior of drivers. The target size of the abnormal behavior is different from the COCO data set. The nine priori boxes obtained by using the K-means clustering algorithm on the COCO data set are inappropriate and even affect Model localization and identification of abnormal behavior. Therefore, for the abnormal behavior data set, this paper uses the K-means clustering algorithm to re-cluster to obtain 9 anchors of different sizes suitable for abnormal behavior detection, as shown in Table 1 below:"
        },
        {
            "heading": "4. EXPERIMENT AND ANALYSIS OF DRIVER ABNORMAL BEHAVIOR DETECTION",
            "text": "This experiment uses the Windows10 operating system, installs CUDA10.1 and cudnn7.6.5 to support GPU operation, and uses GPU to accelerate training. The algorithm simulation software is Python3.8.12, tensorflow2.3."
        },
        {
            "heading": "4.1 Dataset",
            "text": "The research object of this experiment is the driver. According to the requirements of the traffic on the driver\u2019s driving behavior, smoking, answering the phone, drinking water and eating during driving are all abnormal behaviors of the driver. Since there is no public data set for abnormal driving behavior of drivers in China, this experiment constructed the data set by itself. There are three main sources of experimental data, namely self-photographed data, pictures collected on the Internet, and images available in existing datasets, some of which are shown in Figure 4.\nProc. of SPIE Vol. 12506 125066H-5 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nThe dataset is made in accordance with the VOC2007 deep learning dataset format. First images are labelled with labelimg and they are classified as driverphone\u2014calling, driversmoke\u2014smoking, drivercup\u2014drinking water, and drivereat\u2014eating; for training set and test set. Table 2 shows the number of data on various types of abnormal behavior."
        },
        {
            "heading": "4.2 Model abnormal behavior detection and result analysis",
            "text": "4.2.1 Evaluation Indicators. In this paper, the detection success rate and mAP are selected as evaluation indicators to judge the quality of the abnormal behavior detection model. The detection success rate is the probability that the images of this abnormal behavior that can be accurately identified account for all the data sets of this type. In the evaluation\nindicators of abnormal driving behavior of drivers, the commonly used parameters are as follows: PT (Ture Positivies)\nindicates that an abnormality is detected, and the abnormality is also marked in the picture; NT (Ture Negatives)\nindicates that the abnormality is detected, but the picture is not marked with abnormality; PF (False Positives) ) indicates\nthat no abnormality is detected and the picture is not marked with abnormality; NF (False Negatives) indicates that no\nabnormal behavior is detected, but there is abnormal behavior in the real picture. The precision rate (P, Precision) represents the proportion of images that are abnormal and are indeed abnormal to all images that are abnormal17,18, and the recall rate (R, Recall) represents that the abnormal and indeed abnormal images are detected. Annotate the proportion of anomalous images. Average Precision (AP) is the comprehensive recall (R) and precision (P), while mAP is the average precision (AP) mean, which is the standard and indicator for direct evaluation, and m represents the number of samples in the test set. Its calculation formula is as follows:\nPP\nP\nFT\nT P\n+ =\n(5)\nNP\nP\nFT\nT R\n+ =\n(6)\n =\n++= 1-n\n1i\n1ii1i ))p(rr-(rAP\n(7)\n == m i i AP\nm mAP\n1\n1\n(8)\n4.2.2 Optimizing Model Fusion Experiments. In order to verify the optimization effect of the CBAM attention mechanism module and the improved loss function respectively, and to demonstrate the superiority of the final model, this paper designs the optimization model fusion experiment, and the experimental results are shown in Table 3. Model 1 means that only the CBAM attention mechanism is introduced. Model 2 means that only the loss function is improved, and the improved YOLOv3 model is the final model in this paper. The experimental results in the table show that when only the attention mechanism is introduced, the mAP is 92.58%, an increase of 2.36% compared with the YOLOv3 model; the loss function is improved, the mAP value is 91.25%, an increase of only 1.03%, and when both are improved at the same time, namely The model in this paper, the mAP value can reach 95.51%, an increase of 5.69% compared with the YOLOv3 model. Compared with Model 1 and Model 2, both have great increases, 3.33% and 4.69%, respectively. Whether compared with YOLOv3 or a single improved model, the model in this paper has been greatly improved, which proves the superior effect of the model in this paper.\nProc. of SPIE Vol. 12506 125066H-6 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\n4.2.3 Object Detection Comparison Experiment. The improved YOLOv3 model in this paper and the Faster R-CNN, SSD, RetinaNet, and YOLOv3 models are trained and tested in the same dataset, and compared with each other. The test results of the detection success rate and mAP value are shown in Table 4. It can be seen from this that the detection success rate and mAP value of Faster R-CNN, SSD, and RetinaNet are generally below 85%, while the detection success rate and mAP value of the YOLOv3 model are much higher than other models. It reaches 91%, and the overall mAP value is 90.22%, which shows the good performance of YOLOv3 in the detection of abnormal driver behavior. Therefore, this paper selects YOLOv3 as the original model and improves it. It can be seen from the table that compared with YOLOv3, the improved YOLOv3 model in this paper has an increase of 6%, 7%, 11%, and 8% in the detection success rates of drinking water, answering calls, eating, and smoking, all of which are greatly improved, the success rate of drinking water and smoking detection even reached 97%, and mAP also increased by 5.69%, indicating that the model detection effect of this paper is remarkable and has superior performance.\n4.2.4 Comparison of Detection Effects. In order to verify the effect of improving the YOLOv3 model, the two network architectures of the improved YOLOv3 and YOLOv3 will be tested in the test set. One test image is randomly selected for each type and the test results are compared. The comparison chart of the detection effect is shown in Figures 5 and 6. It can be seen from the detection diagram that the detection confidence of the improved YOLOv3 has been improved, which are 0.96, 0.96, 0.98, and 0.90, respectively, which is much higher than the confidence of the original YOLOv3 model. Overall, while the model continues to improve, the detection confidence of the model will also increase, which verifies the improved detection performance of YOLOv3.\nProc. of SPIE Vol. 12506 125066H-7 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use"
        },
        {
            "heading": "5. CONCLUSION",
            "text": "The driver abnormal behavior monitoring method based on the improved YOLOv3 algorithm proposed in this paper, through the collection of abnormal behavior data sets, the recognition rate is improved compared with the previous method, the Darket-53 framework is used to train the recognition model, the attention mechanism is increased, and the loss is improved. The function improves the robustness of the algorithm. By detecting four abnormal behaviors of drinking water, answering calls, smoking, and eating, the mAP value of the identification reaches 95.51%. The experimental results show that the algorithm is effective."
        }
    ],
    "title": "Driver abnormal behavior detection based on dual-channel attention mechanism",
    "year": 2024
}