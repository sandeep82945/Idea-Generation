{
    "abstractText": "A miniaturized 1.4mm \u00d7 1.4mm, 128 \u00d7 120 single photon avalanche diode (SPAD) image sensor with a 5-wire interface is designed for time-resolved fluorescence microendoscopy. This is the first endoscopic chip-on-tip sensor capable of fluorescence lifetime imaging microscopy (FLIM). The sensor provides a novel, compact means to extend the photon counting dynamic range (DR) by partitioning the required bitdepth between in-pixel counters and off-pixel noiseless frame summation. The sensor is implemented in STMicroelectronics 40nm/90nm 3D-stacked backside-illuminated (BSI) CMOS process with 8 \u03bcm pixels and 45% fill factor. The sensor capabilities are demonstrated through FLIM examples, including ex-vivo human lung tissue, obtained at video rate.",
    "authors": [],
    "id": "SP:1895aaae8ec32046f05f8f90d53f353aeaa2ceef",
    "references": [
        {
            "authors": [
                "R.M. Sousa",
                "M. W\u00e4ny"
            ],
            "title": "P",
            "venue": "Santos and F. Morgado-Dias, \"NanEye- An Endoscopy Sensor With 3-D Image Synchronization,\" in IEEE Sensors Journal, vol. 17, no. 3, pp. 623-631, Feb. 1",
            "year": 2017
        },
        {
            "authors": [
                "T. Al Abbas",
                "N.A.W. Dutton",
                "O. Almer",
                "S. Pellegrini"
            ],
            "title": "Y",
            "venue": "Henrion and R. K. Henderson, \"Backside illuminated SPAD image sensor with 7.83\u03bcm pitch in 3D-stacked CMOS technology,\" 2016 IEEE International Electron Devices Meeting (IEDM), San Francisco, CA",
            "year": 2016
        },
        {
            "authors": [
                "M. W\u00e4ny",
                "S. Voltz"
            ],
            "title": "F",
            "venue": "Gaspar and L. Chen, \"Ultrasmall digital image sensor for endoscopic applications,\" in 2009 International Image Sensors Workshop ",
            "year": 2009
        },
        {
            "authors": [
                "B. Wolfs"
            ],
            "title": "C",
            "venue": "Esquenet and W. Iandolo, \"400\u00d7400 pixel image sensor for endoscopy in 1.7mm2 CSP package,\" in 2009 International Image Sensors Workshop ",
            "year": 2009
        },
        {
            "authors": [
                "S. Yoshizaki",
                "A. Serb"
            ],
            "title": "Y",
            "venue": "Liu and T. G. Constandinou, \"Octagonal CMOs image sensor with strobed RGB LED illumination for wireless capsule endoscopy,\" 2014 IEEE International Symposium on Circuits and Systems (ISCAS), Melbourne VIC",
            "year": 2014
        },
        {
            "authors": [
                "M. W\u00e4ny",
                "P. Santos",
                "E. Reis",
                "A. Andrade"
            ],
            "title": "R",
            "venue": "M. Sousa and L. N. Sousa, \"Octagonal CMOS Image Sensor for Endoscopic Applications,\" IS&T International Symposium on Electronic Imaging Science and Technology",
            "year": 2017
        },
        {
            "authors": [
                "D. Covi",
                "C. Cavallotti",
                "M. Vatteroni",
                "L. Clementel",
                "P. Valdastri",
                "A. Menciassi"
            ],
            "title": "P",
            "venue": "Dario and A. Sartori, \"Miniaturized digital camera system for disposable endoscopic applications,\" Sensors and Actuators A: Physical, Volume 162, Issue 2",
            "year": 2010
        },
        {
            "authors": [
                "A.P. Brown",
                "A.H. Jayatissa"
            ],
            "title": "Analysis of current and future technologies of capsule endoscopy: A mini review,",
            "venue": "Archives of Preventive Medicine",
            "year": 2020
        },
        {
            "authors": [
                "G. Pan",
                "L. Wang"
            ],
            "title": "Swallowable Wireless Capsule Endoscopy: Progress and Technical Challenges,",
            "venue": "Gastroenterology Research and Practice,",
            "year": 2012
        },
        {
            "authors": [
                "M.A. Al-Rawhani",
                "D. Chitnis",
                "J. Beeley",
                "S. Collins",
                "D.R.S. Cumming"
            ],
            "title": "Design and Implementation of a Wireless Capsule Suitable for Autofluorescence Intensity Detection in Biological Tissues,",
            "venue": "IEEE Transactions on Biomedical Engineering,",
            "year": 2013
        },
        {
            "authors": [
                "M.A. Al-Rawhani"
            ],
            "title": "J",
            "venue": "Beeley and D. R. S. Cumming, \"Wireless fluorescence capsule for endoscopy using single photon-based detection,\" in Nature, Scientific Reports 5, Article number: 18591",
            "year": 2015
        },
        {
            "authors": [
                "L. Marcu"
            ],
            "title": "Fluorescence Lifetime Techniques in Medical Applications,",
            "venue": "Ann Biomed Eng.,",
            "year": 2012
        },
        {
            "authors": [
                "S. Fernandes",
                "G. Williams",
                "E. Williams",
                "K. Ehrlich",
                "J. Stone",
                "N. Finlayson",
                "M. Bradley",
                "R.R. Thomson",
                "A.R. Akram"
            ],
            "title": "and K",
            "venue": "Dhaliwal, \"Solitary pulmonary nodule imaging approaches and the role of optical fibre-based technologies,\" European Respiratory Journal",
            "year": 2020
        },
        {
            "authors": [
                "B. Mills",
                "A.R. Akram",
                "E. Scholefield"
            ],
            "title": "M",
            "venue": "Bradley and K. Dhaliwal, \"Optical Screening of Novel Bacteria-specific Probes on Ex Vivo Human Lung Tissue by Confocal Laser Endomicroscopy,\" Journal of Visualized Experiments (JoVE), Aug. 13",
            "year": 2017
        },
        {
            "authors": [
                "M. Wang",
                "F. Tang",
                "X. Pan",
                "L. Yao",
                "X. Wang",
                "Y. Jing",
                "J. Ma",
                "G. Wang"
            ],
            "title": "and L",
            "venue": "Mi, \"Rapid diagnosis and intraoperative margin assessment of human lung cancer with fluorescence lifetime imaging microscopy,\" BBA Clinical 8 ",
            "year": 2017
        },
        {
            "authors": [
                "H.A.R. Homulle",
                "F. Powolny",
                "P.L. Stegehuis",
                "J. Dijkstra",
                "D.-U. Li",
                "K. Homicsko",
                "D. Rimoldi",
                "K. Muehlethaler",
                "J.O. Prior",
                "R. Sinisi",
                "E. Dubikovskaya"
            ],
            "title": "E",
            "venue": "Charbon and C. Bruschini, \"Compact solid-state CMOS single-photon detector array for in vivo NIR fluorescence lifetime oncology measurements,\" Biomed. Opt. Express 7, 1797- 1814 ",
            "year": 2016
        },
        {
            "authors": [
                "K. Ehrlich",
                "A. Kufcs\u00e1k",
                "S. McAughtrie",
                "H. Fleming",
                "N. Krstajic",
                "C.J. Campbell",
                "R.K. Henderson",
                "K. Dhaliwal",
                "R.R. Thomson"
            ],
            "title": "and M",
            "venue": "G. Tanner, \"pH sensing through a single optical fibre using SERS and CMOS SPAD line arrays,\" Opt. Express 25, 30976-30986 ",
            "year": 2017
        },
        {
            "authors": [
                "C. Bruschini"
            ],
            "title": "H",
            "venue": "Homulle and E. Charbon, \"Ten years of biophotonics single-photon SPAD imager applications retrospective and outlook,\" Proc. of SPIE, Vol. 10069",
            "year": 2017
        },
        {
            "authors": [
                "M. Perenzoni",
                "M. Moreno-Garc\u00eda"
            ],
            "title": "L",
            "venue": "Gasparini and N. Massari, \"Time-resolved single-photon detectors: Integration challenges in CMOS technologies,\" 2018 International Conference on IC Design & Technology (ICICDT), Otranto",
            "year": 2018
        },
        {
            "authors": [
                "E. Charbon"
            ],
            "title": "C",
            "venue": "Bruschini and M. Lee, \"3D-Stacked CMOS SPAD Image Sensors: Technology and Applications,\" IEEE International Conference on Electronics, Circuits and Systems (ICECS)",
            "year": 2018
        },
        {
            "authors": [
                "T. Al Abbas",
                "O. Almer",
                "S. Hutchings",
                "A.T. Erdogan",
                "I. Gyongy",
                "N.A.W. Dutton",
                "R.K. Henderson"
            ],
            "title": "A 128\u00d7120 5-Wire 1.96mm2 40nm/90nm 3D Stacked SPAD Time Resolved Image Sensor SoC for Microendoscopy,",
            "venue": "VLSI Circuits Symposium,",
            "year": 2019
        },
        {
            "authors": [
                "N.A.W. Dutton",
                "I. Gyongy",
                "L. Parmesan",
                "R.K. Henderson"
            ],
            "title": "Single Photon Counting Performance and Noise Analysis of CMOS SPAD-based Image Sensors,",
            "venue": "Sensors 2016,",
            "year": 2016
        },
        {
            "authors": [
                "J.A. Richardson",
                "L. Grant",
                "R. Henderson"
            ],
            "title": "Low Dark Count Single-Photon Avalanche Diode Structure Compatible with Standard Nanometer Scale CMOS Technology,",
            "venue": "IEEE PTL, vol. 21,",
            "year": 2009
        },
        {
            "authors": [
                "Z. You",
                "L. Parmesan",
                "S. Pellegrini",
                "R. Henderson"
            ],
            "title": "3\u03bcm Pitch",
            "venue": "1\u03bcm Active Diameter SPAD Arrays in 130nm CMOS Imaging Technology,\" in 2017 International Image Sensors Workshop ",
            "year": 2017
        },
        {
            "authors": [
                "D. Li",
                "S. Ameer-Beg",
                "J. Arlt",
                "D. Tyndall",
                "R. Walker",
                "D. Matthews",
                "V. Visitkul"
            ],
            "title": "J",
            "venue": "Richardson and R. Henderson, \"Time-Domain Fluorescence Lifetime Imaging Techniques Suitable for Solid-State Imaging Sensor Arrays,\" in Sensors (Basel)",
            "year": 2012
        },
        {
            "authors": [
                "D. Stoppa",
                "L. Pancheri",
                "M. Scandiuzzo",
                "L. Gonzo",
                "G. Dalla Betta",
                "A. Simoni"
            ],
            "title": "A CMOS 3-D Imager Based on Single Photon Avalanche Diode,",
            "venue": "IEEE Transactions on Circuits and Systems I: Regular Papers,",
            "year": 2007
        },
        {
            "authors": [
                "M. Perenzoni",
                "L. Gasparini",
                "D. Stoppa"
            ],
            "title": "Design and Characterization of a 43.2-ps and PVT-Resilient TDC for Single- Photon Imaging Arrays,",
            "venue": "IEEE Transactions on Circuits and Systems II: Express Briefs, vol. 65,",
            "year": 2018
        },
        {
            "authors": [
                "R. Li",
                "J. Pan",
                "Y. Si",
                "B. Yan",
                "Y. Hu",
                "H. Qin"
            ],
            "title": "Specular Reflections Removal for Endoscopic Image Sequences With Adaptive-RPCA Decomposition,",
            "venue": "IEEE Transactions on Medical Imaging,",
            "year": 2020
        },
        {
            "authors": [
                "J. Ogi",
                "T. Takatsuka",
                "K. Hizu",
                "Y. Inaoka",
                "H. Zhu",
                "Y. Tochigi",
                "Y. Tashiro"
            ],
            "title": "F",
            "venue": "Sano1, Y. Murakawa, M. Nakamura, and Y. Oike \"A 250fps 124dB Dynamic-Range SPAD Image Sensor Stacked with Pixel-Parallel Photon Counter Employing Sub-Frame Extrapolating Architecture for Motion Artifact Suppression,\" 2021 IEEE International Solid- State Circuits Conference (ISSCC)",
            "year": 2021
        },
        {
            "authors": [
                "R.K. Henderson",
                "N. Johnston",
                "S.W. Hutchings",
                "I. Gyongy",
                "T. Al Abbas",
                "N. Dutton",
                "M. Tyler"
            ],
            "title": "Susan Chan",
            "venue": "and J. Leach, \"A 256\u00d7256 40nm/90nm CMOS 3D-Stacked 120dB Dynamic-Range Reconfigurable Time-Resolved SPAD Imager,\" 2019 IEEE International Solid- State Circuits Conference - (ISSCC)",
            "year": 2019
        },
        {
            "authors": [
                "A. Eisele",
                "R. Henderson",
                "B. Schmidtke",
                "T. Funk",
                "L. Grant"
            ],
            "title": "J",
            "venue": "Richardson and W. Freude,\"185 MHz Count Rate, 139 dB Dynamic Range Single-Photon Avalanche Diode with Active Quenching Circuit in 130 nm CMOS Technology,\" in 2011 International Image Sensors Workshop ",
            "year": 2011
        },
        {
            "authors": [
                "T. Al Abbas",
                "D. Chitnis",
                "F.M.D. Rocca"
            ],
            "title": "and R",
            "venue": "K. Henderson, \u201cDual Layer 3D-Stacked High Dynamic Range SPAD Pixel,\u201d in 2019 International Image Sensors Workshop ",
            "year": 2019
        },
        {
            "authors": [
                "D. Magde"
            ],
            "title": "G",
            "venue": "E. Rojas and P. G. Seybold, \u201cSolvent Dependence of the Fluorescence Lifetimes of Xanthene Dyes,\u201d Photochemistry and Photobiology, 70(5), 737\u2013744",
            "year": 1999
        },
        {
            "authors": [
                "V. Zickus",
                "M.-L. Wu",
                "K. Morimoto",
                "V. Kapitany",
                "A. Fatima",
                "A. Turpin",
                "R. Insall",
                "J. Whitelaw",
                "L. Machesky",
                "C. Bruschini"
            ],
            "title": "D",
            "venue": "Faccio and E. Charbon, \u201cFluorescence lifetime imaging with a megapixel SPAD camera and neural network lifetime estimation,\u201d Scientific Reports, 10(1), 20986",
            "year": 2020
        },
        {
            "authors": [
                "D. Trinel",
                "A. Leray",
                "C. Spriet",
                "Y. Usson"
            ],
            "title": "and L",
            "venue": "H\u00e9liot, \u201cUpgrading time domain FLIM using an adaptive Monte Carlo data inflation algorithm,\u201d Cytometry Part A, 79 A(7), 528\u2013537",
            "year": 2011
        },
        {
            "authors": [
                "G. Melino",
                "C. Accarino",
                "M. Riehle",
                "M. Potter",
                "P. Fineron",
                "V.F. Annese",
                "J.P. Grant",
                "M.A. Al-Rawhani",
                "J. Beeley"
            ],
            "title": "I",
            "venue": "E. Carranza and D. R. S. Cumming, \"Capsule Endoscopy Compatible Fluorescence Imager Demonstrated Using Bowel Cancer Tumours,\" in IEEE Sensors Journal, vol. 20, no. 17, pp. 9763-9771, Sept.1",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "photon avalanche diode (SPAD) image sensor with a 5-wire interface is designed for time-resolved fluorescence microendoscopy. This is the first endoscopic chip-on-tip sensor capable of fluorescence lifetime imaging microscopy (FLIM). The sensor provides a novel, compact means to extend the photon counting dynamic range (DR) by partitioning the required bitdepth between in-pixel counters and off-pixel noiseless frame summation. The sensor is implemented in STMicroelectronics 40nm/90nm 3D-stacked backside-illuminated (BSI) CMOS process with 8 \u00b5m pixels and 45% fill factor. The sensor capabilities are demonstrated through FLIM examples, including ex-vivo human lung tissue, obtained at video rate.\nIndex Terms\u2014CMOS image sensor, CIS, fluorescence lifetime imaging microscopy, FLIM, single photon avalanche diode, SPAD, microendoscopy, time gating, time-resolved, high dynamic range, HDR, chip-on-tip, system-on-chip, SoC, 3D-stacking.\nI. INTRODUCTION\nltra small form factor cameras enable minimally invasive\nsurgical procedures and diagnostics in lung, blood vessel\nand urinary tract inspection [1]. A trend towards disposable \u201cchip on tip\u201d endoscopes to avoid laborious and sometimes\nimperfect sterilization procedures is made possible by low cost, nanoscale CMOS image sensor (CIS) manufacturing [2].\nThe literature includes examples of recent developments\naddressing some of the challenges imposed by miniaturization. A 10k pixel sensor with a 3 \u00b5m pixel pitch was presented in\nManuscript received March 5, 2021; revised September 13, 2021; accepted XXX. The PROTEUS project (http://proteus.ac.uk) funded this work (EP/K03197X/1) with silicon manufacturing through STMicroelectronics. I. Gyongy is grateful for the financial support from EPSRC (EP/S001638/1). A. T. Erdogan, N. Finlayson, C. Hopkinson, I. Gyongy, and R. K. Henderson are with the Institute for Integrated Micro and Nano Systems, School of Engineering, University of Edinburgh, Edinburgh, EH9 3FF, UK (email: ahmet.erdogan@ed.ac.uk; n.finlayson@ed.ac.uk; c.hopkinson@sms.ed. ac.uk; istvan.gyongy@ed.ac.uk; robert.henderson@ed.ac.uk).\nTarek Al Abbas was with the Institute for Integrated Micro and Nano Systems, School of Engineering, University of Edinburgh, Edinburgh, EH9 3FF, UK. He is now with Sense Photonics, Edinburgh, UK (e-mail: tarek.alabbas@sensephotonics.com). Oscar Almer was with the Institute for Integrated Micro and Nano Systems, School of Engineering, University of Edinburgh, Edinburgh, EH9 3FF, UK. (e-mail: o.almer@gmail.com). Neale A. W. Dutton is with STMicroelectronics Imaging Division, Tanfield, Edinburgh, EH3 5DA, UK (e-mail: neale.dutton@st.com).\n(ADC) to overcome power supply noise over long cabling\ndistances associated with some endoscopy applications. The work in [4] highlights the challenges of wafer level chip scale\npackaging (WLCSP) such as loss of peripheral area due to dicing and packaging wall spacers and compatibility with\nmicrolensing.\nOther works focus on optimizing the optical efficiency of the focal plane as the pixel area in CMOS image sensors tends\nto be rectangular in dimension while the lenses are spherical in shape resulting in aberrations and optical distortion at the\nedges of the rectangular image. To overcome that, a\nrectangular IC with an octagonal pixel array was proposed in\n[5] to match the focal plane of the image sensor and the lens.\nMore recently, a CIS with a unique octagonal layout was\ndemonstrated in [6]. The IC is sawn in an octagonal form such that it maximizes the imaging area when placed on the tip of\nconventionally cylindrical endoscopes.\nOn the other hand, other efforts target the endoscopy\nmodule or hardware system design in which the miniature\nsensor is a main component. A disposable camera system comprising a CIS, optics and a light emitting diode (LED) was\npresented in [7] for minimally invasive surgery. Miniature low power cameras are also being developed for ingestible pill\nendoscopy [8], [9]. A low power wireless capsule endoscope\nfor fluorescence imaging based on a SPAD sensor was presented in [10], [11] including optics, an LED source and a\nbattery unit.\nCurrently all endoscopy sensors are tailored for capturing intensity-based images and therefore lack time-resolved\ncapability. A time-resolved endoscope would be able to identify the presence of pathogens by measuring their auto-\nfluorescence lifetime against background tissue or by\nmeasuring changes in the lifetime of actively introduced biomarkers that bind to targeted molecules [12]-[15]. Such\nspecificity in detection would inform treatments prescribed by\nclinicians and assist in fluorescence-guided surgical oncology for cancerous tissue removal [16]. It would also open new\napplication avenues such as 3D imaging guided keyhole surgery and physical environment characterization such as pH\nsensing by Raman probes [17].\nThere are several challenges associated with designing time-resolved SPAD sensors including the detector integration\nU\nin CMOS, pixel sensitivity and functionality trade-off due to\nthe sophisticated embedded processing and the high data rates\nassociated with complex time-resolved systems [18], [19]. Meeting these challenges becomes harder in the context of\ndesigning a miniature sensor where the silicon area is\nrestricted and the data bandwidth is limited. In addition to employing smart layout, pixel and system architectures, the\nadvent of advanced CMOS technologies such as 3D-stacking opens the door to new design possibilities and higher built-in\nintelligence [20].\nIn this paper, we introduce a 128 x 120 SPAD array timeresolved image sensor for microendoscopy. A full\nmicroendoscopy system, integrating the image sensor introduced here with light sources and excitation/emission\nfilters, is currently being developed. As part of this\ndevelopment work, the sensor has already been demonstrated working successfully in an untethered 1.5m operation mode.\nThe sensor is integrated in a 3D-stacked 90nm/40nm CMOS\nprocess, measuring 1.4 mm x 1.4 mm, and having a 5-wire interface. Compared to commercially available endoscopy\nCMOS image sensors, this is the only sensor which enables video rate time-resolved capability, such as fluorescence\nlifetime imaging microscopy (FLIM), in order to provide\nclinicians with more informative diagnostic tools. In addition, we introduce a partitioned photon counting scheme between\nin-pixel counters and dense SRAM external to the pixel array, allowing for dynamic range (DR) extension by on-chip\nnoiseless frame summation. The sensor was first presented in\n[21]. More details about the sensor architecture, its implementation and extended characterization results,\nincluding initial and indicative ex-vivo FLIM imaging\nexamples, are reported here.\nThe paper is organized as follows. Section II describes the\nsensor architecture, Section III introduces dynamic range extension by performing on-chip oversampling, Section IV\nprovides characterization results and Section V concludes the\npaper."
        },
        {
            "heading": "II. SENSOR DESIGN",
            "text": "A photomicrograph of the sensor top tier with bottom tier blocks overlaid is shown in Fig. 1. The 1.4 mm x 1.4 mm chip is implemented in STMicroelectronics 3D-stacked CMOS process with a 40 nm bottom tier and a BSI 90 nm top tier at 8 \u00b5m pixel pitch and 45% fill factor. The bottom tier sensor block diagram in Fig. 2 consists of a 128 x 120 SPAD pixel array with peripheral addressing and readout blocks, a microcontrol unit (MCU), a ring oscillator (RO) based gate generator and distribution clock trees, a power generation network (with power-on-reset (POR), bandgap (BG), and 1.1V voltage regulator), and a 5-wire IO interface (VHV, VDD, GND, CLK and bidirectional DATA). The top tier chip (not shown) contains a corresponding array of 128 x 120 global shared well SPADs with one SPAD per pixel connected to the bottom tier chip via a 1-to-1 hybrid-bond site."
        },
        {
            "heading": "A. Pixel Architecture",
            "text": "The pixel circuit diagram is shown in Fig. 3. The front end is made of three thick oxide transistors MQ, M0 and M1. MQ is the passive quench and recharge transistor while M0 and M1 form an inverter operating at 1.1 V for direct voltage level shifting. This is followed by a 14-bit ripple counter which is triggered by the SPAD\u2019s leading edge. A triple input (ROW, COL and OVF) AND gate is used to implement the gating function where the counter overflow flag (OVF) is an active low signal based on the four most significant bits (MSBs) going high yielding a maximum photon counting capacity of 15360 events. If the pixel reaches its saturation limit, the OVF signal blocks the counter from receiving further SPAD pulses to prevent roll-over. All of the logic is implemented using 1.1 V thin oxide low power standard cells with the exception of the ripple counter bits Q<1:13> where optimized custom Dtype flip-flops (DFF) were used for area saving. The custom DFF cell consists of seventeen transistors which make it much smaller than the standard DFF cell, providing 40% saving in area which translates into more bits per pixel. Being digital, the pixel counter suffers from no accumulation noise and no\nadded readout noise as in analogue implementations [22]. Moreover, a digital counter provides a readily digitized output eliminating the need for complex analogue to digital converters (ADCs) which consume power and area. Conventional column parallel readout of the buffered counter bits is implemented through transmission gates driven by row select signals.\nThe pixel gating logic allows the sensor to operate in four different modes based on the state of the ROW and COL signals, as shown in Fig. 4. For rolling shutter (RS) operation, the COL signal is globally held high and the exposure period is defined by the ROW signal which is high throughout the rolling process until the row is selected for readout. Alternatively, in time gated RS mode, the COL signal is globally pulsed to generate intermittent time gates within the rolling exposure period. For global shutter (GS) operation, the ROW signal for all rows is globally held high and the COL signal is what determines the exposure period. It can either be set high for a predefined time interval or pulsed to generate time gates. The RS mode readout follows in a similar fashion to conventional image sensors. ROW signals are generated by the row scanner block in the imaging array and COL signals are generated by the gating logic block where both blocks are driven by the MCU.\nThe SPAD device implemented in this chip is based on the same p-well (PW) to deep n-well (DNW) junction SPAD described in [23]. This structure is proven to be scalable down to 3 \u00b5m pixel pitch [24]."
        },
        {
            "heading": "B. Array Readout",
            "text": "The readout of the imaging array is carried out by two subblocks: row scanner and readout multiplexer. The row scanner is a standard shift register with a token inserted at the top of the chain and shifted down to select rows for readout. When array readout is initiated, three operations take place: LATCH, RESET and READOUT.\nDuring the LATCH phase, the column bus data of the selected row is allowed some time to settle and is then latched into a 1792-bit (= 14-bit x 128 columns) temporary register memory. Next, the pixel counters are reset by the row RESET phase. This is followed by the READOUT phase where 28 bits of two consecutive pixels from the temporary register are funneled through the readout multiplexer (MUX) by using a 6- bit code to address the 64 pairs of pixels (i.e. corresponding to 128 pixel columns). All readout control signals and MUX addresses are issued by the MCU. Fig. 5 shows a typical\ntiming diagram of a single selected row in RS mode as an example."
        },
        {
            "heading": "C. Micro-Control Unit (MCU) and SRAM Memory",
            "text": "A block diagram of the MCU is shown in Fig. 6. It was designed to perform five main tasks: 1) Control the pixel array readout timing based on the selected mode of operation; 2) Manage the IO interface to read out frames or read in configuration register settings; 3) Act as a configuration block by hosting a wide range of programmable register settings that configure the various modes of operation and the settings of all other sub-systems such as the gating logic and power management; 4) Manage the data flow from the imaging array to the SRAM memory banks based on the selected mode of operation; 5) Perform simple arithmetic operations such as frame summation or comparison to predefined threshold values.\nAside from array readout routines, data transfer and configuration setup, the most important feature of the MCU is its data flow and frame manipulation functionality. This feature is at the heart of the SoC design and is aimed at: 1) Improving the sensor\u2019s dynamic range; 2) Mediating data flow to reduce data rates and improve frame rates given the single data pad output which is necessary for a miniature system.\nThe MCU supports a total of 28 sensor operation modes with different properties such as frame rate, bit depth and dynamic range. As summarized in Table I, these modes include 4 pixel modes (GS, GS with gating, RS, and RS with gating); 3 adder modes (32-bit integer, 16-bit integer, and 16- bit floating point); 2 integration modes (using one or two SRAM banks); and 2 readout modes (integrating before readout and integrating while readout). The two readout modes are independent of the four pixel modes. While pixel modes determine how the pixel array is readout into SRAM banks in the MCU where a number of image frames are\nintegrated, readout modes control how the final integrated image frames are readout of the sensor.\nThe MCU uses only two IO pads to interface with the external world; a CLK pad providing an external system clock of up to 100 MHz and a bi-directional DATA pad configured by the MCU as needed to relay frame information to the external world or to read in register settings as configuration bits. The sensor is controlled by custom software written in MATLAB and a custom firmware (implemented on an Opal Kelly XEM6310 FPGA board) provides interface between the sensor and a computer running the software. The ARM Serial Wire Debug (SWD) protocol [25] was implemented in MCU as a sub-block for managing the communication between the sensor and the FPGA. The sensor initially starts up with initial conditions and is in listening (i.e. idle) mode where a set of configuration registers in MCU can be configured from MATLAB in a series of 32-bit words. This causes the sensor to trigger exposure and readout actions based on the configuration register settings and the sensor data is received, processed and displayed by MATLAB through a USB3 interface from the FPGA board. The sensor then falls into listening mode again until another handshaking routine triggers it into action.\nUnlike other blocks, the MCU was designed and implemented using a fully digital design flow, using synthesizable Verilog-HDL. The synthesized MCU block was then integrated to the rest of the sensor as an IP block in the analog design flow. The footprint area of the synthesized MCU (excluding the two SRAM banks) is 225 \u00b5m x 214 \u00b5m, housing roughly 330k logic gates with approximately 33% occupancy density with the rest filled by decoupling cells.\nThe two SRAM banks and their controller logic are standard STMicroelectronics IP blocks, measuring 198 \u00b5m x\n833 \u00b5m. Each SRAM bank is configured as 8192 words and 32-bits/word, hence providing a 256 kbit memory capacity. This allows up to 32-bit/pixel photon counting capability when two SRAM banks are used together, providing high count rate, SNR and DR; or utilizing only one of the SRAM banks in a 16-bit/pixel counting mode for improved frame rate at the expense of reduced count rate, SNR and DR. As part of the digital design stage, the two SRAM banks were integrated into the MCU block functionality."
        },
        {
            "heading": "D. Power Network",
            "text": "Since the number of IO pads is limited there is a requirement to generate and regulate the necessary voltages internally through an on-chip power network. As shown in Fig. 7, the core blocks making up the power network are 1) Power-on-reset (POR) for initializing the sensor upon start-up; 2) Bandgap (BG) with multiple reference voltages (0.4 V, 0.9 V and 1.1 V); 3) Voltage regulator for generating the core logic 1.1 V supply with up to 20 mA current supply. These three blocks were provided by STMicroelectronics as standard IP blocks in their 40 nm CMOS process. The power generation network requires two supply inputs, 2.8 V and ground, both supplied through a VDD and a GND IO pads. The configuration registers which are addressable by the MCU ensure that the sensor starts with the correct initial conditions and allows reconfiguring several options in IP blocks such as voltage and current trimming values of the BG to account for process variability. When the 2.8 V supply is ramped up the POR reset signal is released and the BG starts functioning. After some start up delay the BG reference voltages are generated and the BG_OK flag is raised high, indicating that it is ready for operation. Following that the voltage regulator starts up and the 1.1 V supply is generated."
        },
        {
            "heading": "E. Gating Logic",
            "text": "For time-resolved imaging, a time-gating approach was preferred over time stamping or time correlated single photon counting (TCSPC) in order to maintain pixel simplicity, leave enough area for counter bits, and avoid high throughput parallel readout to keep up with the high data rates generated by TCSPC systems which conflicts with the miniaturization target of this work. It is possible to extract temporal information by simply collecting photons in two time gates and therefore determine parameters such as fluorescence lifetime (by rapid lifetime determination (RLD) [26]), or distance and depth (by indirect time of flight method [27]). This trades-off the accuracy of the statistical approach of histogramming time stamps of captured photons for pixel simplicity and compressed data rates.\nOn-chip time gate generation logic was implemented based on a fully digital custom design handcrafted in the analogue flow with the following design objectives: 1) Compactness for minimal chip area overhead; 2) Programmable for flexible and adaptive operation; 3) Sub-nanosecond temporal resolution to allow for very short width time gates. The design is based on a ring oscillator (RO) and programmable ripple counters to produce three time gates. Two of the time gates (GATE_A and GATE_B) are broadcast globally to the imaging array via balanced binary trees. These time gates can also be interleaved to odd and even columns to minimize motion distortion.\nFig. 8 shows a simplified block diagram of the gating logic. Each time gate is implemented by utilizing two 12-bit counters that operate in three phases which are derived from the system clock. During the first phase both counters are set to logic high and in the second phase each counter is set to a programmable 11-bit value by selectively resetting bits to logic low. The twelfth bit is always reset to logic low in this phase. During the third phase, the high speed RO clock is enabled and both counters start to count down until they roll back over to all logic high which is a different point in time for each counter based on their programmed values. Once the twelfth bit goes high for any of the counters, a rising edge is generated. The twelfth bit is used instead of a zero-crossing detection to avoid meta-stability due to different bit settling times when comparing 12 counter bits and because the MSB of a counter stays high for much longer than a single RO clock cycle, allowing sufficient time for signal propagation delays. The two rising edges generated by the pair of counters (with Edge 2 being inverted) feed into an AND gate which generates a corresponding time gate. While the lower count value of the two programmable counters defines the time offset in terms of number of RO clock cycles between the rising edges of the generated time gate and the system clock in phase 3, the count difference between the counters defines the time gate width in terms of number of RO clock cycles. Fig. 9 shows an example timing diagram for one counter pair where the time offset and the width of the generated time gate are both set to 2 RO clock cycles.\nThere is inefficiency in generating time gates in this implementation since a counter pair requires a three-phase operation during which only one phase generates a time gate. This inefficiency is removed by employing 3 counter pairs (instead of one) with a different order of the three-phase operation for each counter pair. At any system clock cycle one\nof the counter pairs is set to all logic high, the second is set to a programmable count value while the third is generating a time gate by the mechanism described above. This guarantees continuous time gate generation with every system clock cycle at the expense of increased circuit area for the gating logic. However, this increase in area is insignificant when the total sensor area is considered. Counter pairs for each time gate are programmed independently and hence the generated time gates can overlap or be delayed in time in respect to each other as necessary.\nThe temporal dynamic range of the time gate generation logic is dependent on the system clock frequency. An 11-bit value was used to ensure that as many RO cycles as required can be counted within a system clock period. It is also possible to divide the system clock frequency and use the divided version to drive the gating logic in order to increase the temporal coverage or dynamic range. On the other hand, the temporal resolution is defined by the RO clock period which is 390 ps.\nThe RO also has configurable settings controlled by the MCU allowing for it to be turned off for saving power when time gating is not used. Moreover, the RO employs a self-reset function every system clock cycle to minimize accumulated jitter. Since no process-voltage-temperature (PVT) compensation mechanism is integrated on-chip through a phase locked loop (PLL) or a delay locked loop (DLL) due to area constraints, allowing the RO to free run for long periods of time would result in accumulation of non-linearity and hence integrated jitter [28]. In order to minimize this jitter, the self-resetting function stops, resets and restarts the RO with every system clock cycle. By design it is ensured that selfresetting consumes minimal time such that the temporal dynamic range is not reduced. Fig. 10 shows a timing diagram of the RO in self-reset mode. In terms of PVT variations, for our sensor we expect the voltage and temperature variations to be small since the 1.1 V core logic power supply is regulated on-chip (as part of the power generation network) and the sensor\u2019s normal use is inside a human body where the temperature is ~37 C. This leaves the process variation as the\nmain factor affecting the RO clock period. There is no direct access to the RO clock to monitor and compensate it for PVT variations directly. However, variations in RO clock periods among different chips can be inferred indirectly by making use of the gating logic. For a set time gate width, a pulsed laser can be swept in small time steps across the time gate and photon counts recorded. Then time gate profiles for different chips can be reconstructed from the recorded photon counts and compared to each other. The time difference in reconstructed time gate profiles will be proportional to difference between their RO clock periods. This process can be used to tune the RO\u2019s supply voltages (hence their clock periods) via MCU configuration register settings, until the difference between time gate profiles is minimized."
        },
        {
            "heading": "III. DYNAMIC RANGE ENHANCEMENT",
            "text": "In fluorescence microendoscopy applications large areas of specular reflections occur at the smooth and watery surface of abdominal organs under endoscope illumination [29]. These specular reflections disturb the surgeon\u2019s observation and judgment. To avoid the resulting image saturation and clipping artifacts whilst preserving low intensity detail we have implemented a high DR scheme in our sensor.\nWe define the DR within a scene as:\n\ud835\udc37\ud835\udc45 = 20 \ud835\udc65 \ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc46/\ud835\udc45) (1)\nwhere S is the saturation signal level and R is the readout noise floor. Since SPADs with digital counters exhibit shot noise limited performance [2], the only noise source is the dark count rate (DCR) of the SPAD which in value is dependent on exposure time. Since the mean DCR value of a SPAD can be measured, it can be corrected for by subtraction and hence the minimum observable signal is not the DCR value itself but rather its shot noise component (i.e. square root of DCR). Therefore the DR can be redefined as follows:\n\ud835\udc37\ud835\udc45 = 20 \ud835\udc65 log(\ud835\udc46/\u221a\ud835\udc37\ud835\udc36\ud835\udc45) (2)\nThere are two options for improving the DR; one can either extend the maximum signal level to accommodate the higher end of light intensities or reduce the noise floor to extend the DR towards the lower end of the scale. SPAD devices can intrinsically offer a wide DR response in excess of 100 dB by virtue of low DCR noise floor and high maximum count rate due to short device dead-time (Tdead). For our passively quenched SPAD devices the maximum count rate is set by 1/(exp(1) x Tdead) [32]. Based on SPAD characterization results presented in [33], Tdead is ~3.5 ns and hence for our sensor the maximum count rate is in excess of 100 Mcps.\nHowever, it is difficult to capture this response as it requires a very large pixel photon counting capacity which translates to a large bit width counter with negative impact on pixel pitch and fill factor.\nThe oversampling method allows achieving high DR by summing multiple frames while keeping the pixel pitch small. Fig. 11 illustrates this for an Nc columns by Nr rows pixel array by replacing (N+k)-bit in-pixel counters with a combination of smaller N-bit in-pixel counters, (N+k)-bit SRAM memories for storing accumulated pixel counts, and a shared (N+k)-bit accumulator for summing N-bit pixel counts with their corresponding (N+k)-bit accumulated counts in SRAM memories. This arrangement allows controlling the pixel pitch by tuning N while keeping N+k fixed. This is enabled by using on-chip SRAM memories which offer approximately 16x higher bit density (accounting for SRAM periphery logic) than the in-pixel counters.\nWhen summing M frames together and given that uncorrelated noise sources add in quadrature, the DR can be expressed as:\n\ud835\udc37\ud835\udc45\ud835\udc40\ud835\udc62\ud835\udc59\ud835\udc61\ud835\udc56\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc39\ud835\udc5f\ud835\udc4e\ud835\udc5a\ud835\udc52 = 20 \ud835\udc65 log ( \ud835\udc40 \ud835\udc65 \ud835\udc46\n\u221a\ud835\udc40 \ud835\udc65 \u221a\ud835\udc37\ud835\udc36\ud835\udc45 ) (3)\nTherefore the improvement in DR is given by the difference between equations (3) and (2):\n\ud835\udc37\ud835\udc45\ud835\udc3c\ud835\udc5a\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61 = 20 \ud835\udc65 log(\u221a\ud835\udc40) (4)\nHowever, increasing M has a negative effect on the readout frame rate, representing a trade-off between DR and frame rate. The frame rate depends on the system clock frequency, MCU configuration settings in Table I, exposure time per frame, number of frames summed (M), and (N+k)-bit width of the SRAM memories (since (N+k)-bit pixel data is readout from SRAM memories serially via a single IO pad). For our sensor, the parameter N was fixed to 14-bits in the chip design phase to match the top tier SPAD pitch, while the parameter k is determined by the adder mode (configured via the MCU). It is 2-bits in 16-bit integer or floating point adder modes and 18-bits in 32-bit adder mode. Therefore, one can determine the M parameter based on the desired trade-off between DR and frame rate.\nThis on-chip noiseless frame summation scheme was first introduced in the initial presentation of this work in [21]. Since then there have been similar schemes presented for high DR SPAD image sensors, such as [30] and [31].\nAlthough it is possible to implement frame summation offchip, for our sensor it was critical to perform the frame summation on-chip due to limited bandwidth. The sensor has a 5-wire interface (and only a single wire reserved for data transmission) due to hard sensor area constraints imposed by microendoscopy systems. Assuming a system clock frequency of 37.5 MHz and RS pixel mode, while the pixel array can be transferred to MCU at a rate of 5.6 Gbit/s, it can only be readout of the sensor at a rate of 37.5 Mbit/s. Therefore, performing frame summation off-chip would result in both reducing frame rate and increasing IO power consumption significantly since each frame would need to be readout of the sensor."
        },
        {
            "heading": "IV. EXPERIMENTAL RESULTS",
            "text": ""
        },
        {
            "heading": "A. Sensor Characterization",
            "text": "The all-digital pixel circuit, having a 14-bit in-pixel counter\nwith overflow protection, yields a maximum count of 15360\nevents which equates to an intrinsic DR of 72 dB based on equation (2) and a DCR of 15 counts per second (cps). High\ndynamic range (HDR) imaging is provided by noiseless frame\nsummation in two 256 kbits on-chip SRAM banks, as described in Section III. The noiseless frame summation\nincreases DR up to 126 dB by summing a programmable number of frames while the on-chip processing eliminates the\nneed of reading out large amounts of data at high speeds. Fig.\n12 shows the mean photon count rate versus illumination from a controlled white LED source, at 1 V excess bias voltage\nabove the SPAD breakdown voltage of 16.5 V. The increase in DR as a function of the number of frames summed is\nclearly demonstrated, corresponding closely to photon shot\nnoise theory (inset), as estimated by equation (4).\nTo characterize the time gating performance a set of time\ngates were generated, all having the same time offset in\nrespect to the rising edge of the system clock but their gate widths incremented in steps of 390 ps. For each time gate, a\npulsed laser was then swept in steps of 25 ps across the time gate and counts were recorded over many frames in order to\nreconstruct the resulting gate profiles. Fig. 13 shows the time\ngating linearity and uniformity across the pixel array. A race condition between pixel read and reset signals has caused a\ncorner of the array to be insensitive to light. The time-gate width can be configured from 390 ps to >100 ns in 390 ps\nsteps. Example time-gates from 390 ps to 8.58 ns are shown in\nFig. 13(a) and their mean full width at half maximum (FWHM) across the pixel array in Fig. 13(b). The variation in time gates across the pixel array is shown in Fig. 13(c) for a selected time gate width of 3.9 ns. The corresponding histogram of time gates across the pixel array is depicted in Fig. 13(d), showing 3.92 ns mean time gate width and 200 ps standard deviation (excluding pixels insensitive to light).\nPhoto response non-uniformity (PRNU) is one of the most\nimportant figures for image sensors as it reflects the pixel to\npixel output variation with respect to constant input photon flux. To evaluate PRNU of the imaging array, photon counts\nwere captured under fixed and low illumination level for a 20\nms exposure time at 1 V excess bias voltage. Fig. 14 (a) shows the photon counts across the pixel array while the histogram of\nthe photon counts is shown in Fig. 14 (b) with the mean and standard deviation counts being 1227 and 44.94, respectively\n(excluding pixels insensitive to light and high DCR pixels).\nPRNU was then calculated as the standard deviation divided by the mean which equated to 3.66%.\nThe photon detection efficiency (PDE) varies between 1.3% and 12.6% for wavelengths from 450 nm to 900 nm (peaking\nat 615 nm) at 3 V excess bias voltage, based on measurements carried out on a test SPAD implemented in the same silicon\nrun [32]. The median DCR at room temperature is 15 cps and\n118 cps at 1 V and 2 V excess bias voltages, respectively. The VDD power consumption is 10 mW at maximum activity."
        },
        {
            "heading": "B. HDR Experiments",
            "text": "HDR imaging was performed in light conditions which caused single frames to saturate, as shown in Fig. 15 (a).\nSumming frames on-chip recovers detail in the clipped areas\nof the image, as shown in Figs. 15 (b) and (c) for 8 and 128 frames summed, corresponding to 9 dB and 12.6 dB\nimprovement in DR based on Eq. (4), respectively. All three images were captured at 15 fps, with a total exposure time of 5\nms, and cropped to an imaging area of 90 x 120 in order to\navoid the corner of the pixel array insensitive to light, as\ndescribed in Section IV. A.\nC. Instrument Response Function (IRF) and FLIM Experiments\nThe IRF and FLIM images were acquired using a Hamamatsu Picosecond Light Pulser PLP-10 (wavelength 483 nm, pulse width 80 ps, maximum power 150 mW, repetition rate 37.5 MHz). Measurements carried out on a test SPAD yielded a SPAD IRF of 70 ps [33], whereas all array measurements on SPAD and gating circuitry yielded a composite IRF of 0.55 +/- 0.02 ns. An epi-fluorescence optical set-up was used to capture FLIM images, with the laser beam directed onto the sample via a dichroic mirror and 10x magnification objective. The resulting sample fluorescence passes back through the dichroic, where it is filtered through a 495 nm long-pass filter to remove any residual scattered or reflected laser light, and focused onto the image sensor using a second objective of 10x magnification.\nFluorescein and Rhodamine B liquid samples were prepared by mixing with distilled water. Fig. 16 shows representative fluorescence decay and lifetime distributions of the samples. A least-squares fit using 15 time-gate bins is compared with a 2- gate RLD fit, yielding Fluorescein (least squares mean 4.2 ns +/- 0.3 ns, RLD mean 4.4 ns +/- 0.7 ns) and Rhodamine B (least squares mean 1.9 ns +/- 0.1 ns, RLD mean 1.8 ns +/- 0.2 ns) lifetimes which match closely the expected literature values [34]. The time-gate bin width is 390 ps for both methods. Although the lifetime distribution is much broader for Fluorescein with 2-gate RLD, Fluorescein and Rhodamine B samples can still be separated from each other. It is also worth mentioning that the lifetime estimates for Fluorescein with 2-gate RLD can be improved by increasing the time-gate bin width. As another example, fluorescence intensity and lifetime images of a Convallaria Majalis sample are shown in Fig. 17, again matching the expected lifetime distributions [35]. The sample was imaged with 10000 exposure cycles (corresponding to an exposure time of 266.7 \u00b5s per frame with a 37.5 MHz system clock) and 1000 frames summed in 32-bit adder and GS (gated GS for lifetime images) modes, giving a readout frame rate of 1 frame per second (fps) for intensity imaging. The Convallaria fluorescence lifetime image was obtained with the least-squared fit method using 5 time-gate bins (with 390 ps bin width), resulting in a frame rate of 0.2\nfps. It is worth noting that the frame rate for intensity images\ncan be increased by reducing the number of frames summed. While the frame rate for lifetime images can be increased by applying the 2-bin RLD method, trading accuracy for speed. In addition, the sensor can be operated in even and odd columns mode, allowing capturing photon counts for 2 time gates at the same time, doubling the frame rate with a reduced resolution of 120 rows and 64 columns.\nAchieving good lifetime contrast in auto-fluorescent lung tissue in living patients with and without fluorescent markers is very demanding and video rate performance is desirable to avoid motion artefacts. The autofluorescence intensity and lifetime of lung tissue is inhomogeneous and counts of 100 - 1000 and lifetimes of 0.5 \u2013 5 ns are typical for 1 - 10 fps video frame rates envisaged. Fig. 18 shows lifetime images from\nhematoxylin and eosin stained human lung tissue taken at video rate. For each image, two contrasting regions were selected, and the corresponding lifetime histograms are presented to show lifetime distribution across those regions. The lung sample was imaged with 60,000 exposure cycles and 10 frames summed, providing a frame rate of 7.4 fps. To increase the frame rate, the 2-bin RLD method (with 390 ps bin width) was used in even and odd columns mode (as described above).\nThe fluorescence lifetime signal-to-noise ratio (SNR) can be defined as \u03c4(N)/\u2206\u03c4(N) where \u03c4 is the lifetime, \u2206\u03c4 is the standard deviation and N is the number of photons detected over n time channels [36]. Achieving good SNR requires increasing N and hence longer exposure times which have negative effect on frame rate. In Fig. 19 we present lifetime SNR versus frame rate comparisons for our sensor. A homogeneous fluorescein sample was used for lifetime measurements which were obtained for different exposure times (by varying the number of exposure cycles and frames summed) and using the 2-gate RLD method in odd and even columns mode. It is clear that with the fluorescein sample a lifetime SNR > 5 can be achieved for frame rates up to 20 fps. However, the SNR versus frame rate profile will vary with different samples and parameter settings.\nTable II provides a comparison against some state-of-the-art\nacademic and commercial endoscopy image sensors. In general, chip-on-tip endoscopes are smaller and provide\nhigher frame rates compared to capsule endoscopes.\nCompared to chip-on-tip endoscopes, while our sensor has a larger area of 1.96 mm2 and a smaller number of pixels due to the bigger 8 \u00b5m pixel pitch, it is capable of video rate\noperation, higher dynamic range of 72 dB due to noiseless readout which can be boosted up to 126 dB by on-chip frame\nsummation and can operate in both rolling and global shutter\nmodes. Moreover, our sensor is the only miniature image sensor capable of time-resolved imaging with a 5-wire\ninterface."
        },
        {
            "heading": "V. CONCLUSION",
            "text": "We have presented a 128 x 120 SPAD array time-resolved image sensor for microendoscopy. The sensor is integrated in\na 3D-stacked 90nm/40nm CMOS process, measuring 1.4 mm\nx 1.4 mm, and having a 5-wire interface. It incorporates an 8\n\u00b5m pitch, 14-bit depth pixel with on-chip data processing,\nallowing for dynamic range extension by noiseless frame summation and for achieving video rate time-resolved\nimaging.\nTo the best of the authors\u2019 knowledge, this is the first SPAD image sensor designed for microendoscopy which enables\nvideo rate time-resolved imaging.\nACKNOWLEDGMENT\nThe authors would like to thank Dr. Ahsan Akram for\nprovision of the lung tissue sample.\nEthics statement: All experiments using ex vivo human lung\ntissue were performed following approval by the appropriate\nregional Research Ethics Committee (REC), NHS Lothian\n(references 13/ES/0126 and 16/LO/1883), and all subjects gave written informed consent."
        }
    ],
    "title": "A High Dynamic Range 128\u00d7120 3D-Stacked CMOS SPAD Image Sensor SoC for Fluorescence Microendoscopy",
    "year": 2022
}