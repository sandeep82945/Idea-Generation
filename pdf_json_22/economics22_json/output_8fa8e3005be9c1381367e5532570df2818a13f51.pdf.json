{
    "abstractText": "The choice to participate in a data-driven service, often made on the basis of quality of that service, influences the ability of the service to learn and improve. We study the participation and retraining dynamics that arise when both the learners and sub-populations of users are risk-reducing, which cover a broad class of updates including gradient descent, multiplicative weights, etc. Suppose, for example, that individuals choose to spend their time amongst social media platforms proportionally to how well each platform works for them. Each platform also gathers data about its active users, which it uses to update parameters with a gradient step. For this example and for our general class of dynamics, we show that the only asymptotically stable equilibria are segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can result in representation disparity and high overall loss for a single learner (Hashimoto et al., 2018; Miller et al., 2021), we find that repeated myopic updates with multiple learners lead to better outcomes. We illustrate the phenomena via a simulated example initialized from real data.",
    "authors": [
        {
            "affiliations": [],
            "name": "Sarah Dean"
        },
        {
            "affiliations": [],
            "name": "Mihaela Curmei"
        },
        {
            "affiliations": [],
            "name": "Lillian J. Ratliff"
        },
        {
            "affiliations": [],
            "name": "Jamie Morgenstern"
        },
        {
            "affiliations": [],
            "name": "Maryam Fazel"
        }
    ],
    "id": "SP:3f77452b54662d3631a47f675d1e1cb5c4c41ab2",
    "references": [
        {
            "authors": [
                "Guy Aridor",
                "Yishay Mansour",
                "Aleksandrs Slivkins",
                "Zhiwei Steven Wu"
            ],
            "title": "Competing bandits",
            "year": 2009
        },
        {
            "authors": [
                "Omer Ben-Porat",
                "Moshe Tennenholtz"
            ],
            "title": "Regression equilibrium",
            "venue": "In Proceedings of the 2019 ACM Conference on Economics and Computation,",
            "year": 2019
        },
        {
            "authors": [
                "Nicoletta Bof",
                "Ruggero Carli",
                "Luca Schenato"
            ],
            "title": "Lyapunov theory for discrete time systems",
            "venue": "arXiv preprint arXiv:1809.05289,",
            "year": 2018
        },
        {
            "authors": [
                "Gavin Brown",
                "Shlomi Hod",
                "Iden Kalemaj"
            ],
            "title": "Performative prediction in a stateful world",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2022
        },
        {
            "authors": [
                "Joshua Cutler",
                "Dmitriy Drusvyatskiy",
                "Zaid Harchaoui"
            ],
            "title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Frances Ding",
                "Moritz Hardt",
                "John Miller",
                "Ludwig Schmidt"
            ],
            "title": "Retiring adult: New datasets for fair machine learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Dmitriy Drusvyatskiy",
                "Lin Xiao"
            ],
            "title": "Stochastic optimization with decision-dependent distributions",
            "venue": "arXiv preprint arXiv:2011.11173,",
            "year": 2020
        },
        {
            "authors": [
                "Dean P Foster",
                "Rakesh V Vohra"
            ],
            "title": "An economic argument for affirmative action",
            "venue": "Rationality and Society,",
            "year": 1992
        },
        {
            "authors": [
                "Tony Ginart",
                "Eva Zhang",
                "Yongchan Kwon",
                "James Zou"
            ],
            "title": "Competing ai: How does competition feedback affect machine learning",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "Moritz Hardt",
                "Nimrod Megiddo",
                "Christos Papadimitriou",
                "Mary Wootters"
            ],
            "title": "Strategic classification",
            "venue": "In Proceedings of the 2016 ACM conference on innovations in theoretical computer science,",
            "year": 2016
        },
        {
            "authors": [
                "Tatsunori Hashimoto",
                "Megha Srivastava",
                "Hongseok Namkoong",
                "Percy Liang"
            ],
            "title": "Fairness without demographics in repeated loss minimization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Lars Hellemo",
                "Paul I Barton",
                "Asgeir Tomasgard"
            ],
            "title": "Decision-dependent probabilities in stochastic programs with recourse",
            "venue": "Computational Management Science,",
            "year": 2018
        },
        {
            "authors": [
                "Harold Hotelling"
            ],
            "title": "Stability in competition",
            "venue": "The Economic Journal,",
            "year": 1929
        },
        {
            "authors": [
                "Mary Inaba",
                "Naoki Katoh",
                "Hiroshi Imai"
            ],
            "title": "Applications of weighted voronoi diagrams and randomization to variance-based k-clustering",
            "venue": "In Proceedings of the tenth annual symposium on Computational geometry,",
            "year": 1994
        },
        {
            "authors": [
                "Zachary Izzo",
                "Lexing Ying",
                "James Zou"
            ],
            "title": "How to learn when data reacts to your model: performative gradient descent",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Matth\u00e4us Kleindessner",
                "Pranjal Awasthi",
                "Jamie Morgenstern"
            ],
            "title": "Fair k-center clustering for data summarization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Matth\u00e4us Kleindessner",
                "Samira Samadi",
                "Pranjal Awasthi",
                "Jamie Morgenstern"
            ],
            "title": "Guarantees for spectral clustering with fairness constraints",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Harold J Kushner"
            ],
            "title": "Stochastic stability and control",
            "venue": "Technical report, Brown Univ Providence RI,",
            "year": 1967
        },
        {
            "authors": [
                "Jun Liu",
                "Ye Yuan"
            ],
            "title": "On almost sure convergence rates of stochastic gradient methods",
            "venue": "In Conference on Learning Theory,",
            "year": 2022
        },
        {
            "authors": [
                "Celestine Mendler-D\u00fcnner",
                "Juan Perdomo",
                "Tijana Zrnic",
                "Moritz Hardt"
            ],
            "title": "Stochastic optimization for performative prediction",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "John P Miller",
                "Juan C Perdomo",
                "Tijana Zrnic"
            ],
            "title": "Outside the echo chamber: Optimizing the performative risk",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Adhyyan Narang",
                "Evan Faulkner",
                "Dmitriy Drusvyatskiy",
                "Maryam Fazel",
                "Lillian J Ratliff"
            ],
            "title": "Multiplayer performative prediction: Learning in decision-dependent games",
            "venue": "Proceedings of the 24th International Conference on Artificial Intelligence and Statistics",
            "year": 2022
        },
        {
            "authors": [
                "Francesco Orabona"
            ],
            "title": "Almost sure convergence of sgd on smooth non-convex functions on https: //parameterfree.com",
            "year": 2020
        },
        {
            "authors": [
                "Susan Hesse Owen",
                "Mark S Daskin"
            ],
            "title": "Strategic facility location: A review",
            "venue": "European journal of operational research,",
            "year": 1998
        },
        {
            "authors": [
                "Juan Perdomo",
                "Tijana Zrnic",
                "Celestine Mendler-D\u00fcnner",
                "Moritz Hardt"
            ],
            "title": "Performative prediction",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Georgios Piliouras",
                "Fang-Yi Yu"
            ],
            "title": "Multi-agent performative prediction: From global stability and optimality to chaos",
            "venue": "arXiv preprint arXiv:2201.10483,",
            "year": 2022
        },
        {
            "authors": [
                "Joaquin Qui\u00f1onero-Candela",
                "Masashi Sugiyama",
                "Anton Schwaighofer",
                "Neil D Lawrence",
                "editors"
            ],
            "title": "Dataset shift in machine learning",
            "year": 2008
        },
        {
            "authors": [
                "Mitas Ray",
                "Dmitriy Drusvyatskiy",
                "Maryam Fazel",
                "Lillian J Ratliff"
            ],
            "title": "Decision-dependent risk minimization in geometrically decaying dynamic environments",
            "venue": "In Proceedings of the Association for the Advancement of Artificial Intelligence Conference on AI (AAAI),",
            "year": 2022
        },
        {
            "authors": [
                "William H Sandholm"
            ],
            "title": "Evolutionary game theory. Complex Social and Behavioral Systems: Game Theory and Agent-Based Models, pages",
            "year": 2020
        },
        {
            "authors": [
                "Shokri Z Selim",
                "Mohamed A Ismail"
            ],
            "title": "K-means-type algorithms: A generalized convergence theorem and characterization of local optimality",
            "venue": "IEEE Transactions on pattern analysis and machine intelligence,",
            "year": 1984
        },
        {
            "authors": [
                "Killian Wood",
                "Emiliano Dall\u2019Anese"
            ],
            "title": "Stochastic saddle point problems with decision-dependent distributions",
            "venue": "arXiv preprint arXiv:2201.02313,",
            "year": 2022
        },
        {
            "authors": [
                "Killian Wood",
                "Gianluca Bianchin",
                "Emiliano Dall\u2019Anese"
            ],
            "title": "Online projected gradient descent for stochastic optimization with decision-dependent distributions",
            "venue": "IEEE Control Systems Letters,",
            "year": 2021
        },
        {
            "authors": [
                "Xueru Zhang",
                "Mohammadmahdi Khaliligarekani",
                "Cem Tekin",
                "Mingyan Liu"
            ],
            "title": "Group retention when using machine learning in sequential decision making: the interplay between user dynamics and fairness",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Perdomo"
            ],
            "title": "2020) introduces performative prediction as a model capturing user reaction via endogenous distribution shifts. This work models a single decision-maker facing a risk minimization problem subject to an underlying decision-dependent data distribution. Following its introduction, several relevant solution concepts have been explored and algorithms for achieving them proposed (Izzo et al., 2021",
            "venue": "Drusvyatskiy and Xiao,",
            "year": 2020
        },
        {
            "authors": [
                "V V (f(x"
            ],
            "title": "xeq is stable (resp. asymptotically stable)",
            "venue": "(Bof et al.,",
            "year": 2018
        },
        {
            "authors": [],
            "title": "It further converges to a minimum in the limit as long as the step size satisfies the Robbins-Munroe condition (see, e.g. (Liu and Yuan, 2022; Orabona, 2020)). Example E.1 (Semi-static participation). Suppose a population has a constant allocation of 20% to one learner",
            "year": 2020
        },
        {
            "authors": [
                "Hashimoto"
            ],
            "title": "Stability To illustrate the subtleties of determining stability when the total risk function has non-isolated local minima, we consider a setting with n = m = 2 subpopulations and learners",
            "year": 2020
        },
        {
            "authors": [],
            "title": "Experimental Details Full experimental details along with instructions for reproducing them can be found at https: //github.com/mcurmei627/MultiPlayerRiskReduction. The experiments used Python 3.9 on a MacBook Pro 2019",
            "year": 2019
        }
    ],
    "sections": [
        {
            "text": "For this example and for our general class of dynamics, we show that the only asymptotically stable equilibria are segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can result in representation disparity and high overall loss for a single learner (Hashimoto et al., 2018; Miller et al., 2021), we find that repeated myopic updates with multiple learners lead to better outcomes. We illustrate the phenomena via a simulated example initialized from real data."
        },
        {
            "heading": "1 Introduction",
            "text": "Numerous online services, including social media platforms, personalized recommendation engines, and advertising auction systems, collect user data continuously, and make small adjustments to models they use to personalize content. A primary reason for this practice is the awareness that the environment in which a system is deployed is non-stationary and may be subject to both exogeneous and endogeneous distribution shifts. Exogeneous shifts, or those which are fixed but unknown to the platform, include changes in user behavior that might arise from changes in tech policy (e.g. laws which limit the access of young users) or ambiently (e.g. increased free time on weekends or holidays). Endogeneous shifts arise directly from the platform\u2019s behavior (e.g. increased paid content causing decreased user interest). Though both sorts of shifts affect the performance of\n1sdean@cornell.edu\nar X\niv :2\n20 6.\n02 66\n7v 2\n[ cs\n.L G\n] 2\nmachine learning systems, endogeneous shifts are important in that they can be controlled by a service\u2014creating an opportunity for designers to reap performance benefits or at least to avert unintended consequences.\nIn this work, we study a particular form of endogenously shifting distributions over multiple rounds, in contexts where individuals prefer to use services whose predictions are more accurate. Much of the existing work on endogeneous distribution shift focuses on users who modify their features to achieve desired outcomes, as in strategic classification (Hardt et al., 2016) and related problems (Perdomo et al., 2020; Miller et al., 2021). While important, this model of data manipulation does not capture the most straightforward way that individuals express their preferences in a market: by choosing amongst alternative providers. In fact, recent work has shown that in the presence of a participation choice between competing providers, individuals have no incentive to perform costly data manipulations (Hardt et al., 2022).\nConsider as an example a social media platform. If the platform recommends content that does not appeal to the tastes of younger generations, these users will spend a smaller fraction of their time on that platform. This results in positive (i.e., self-reinforcing) feedback loop, where a services\u2019s poor performance on young customers dissuades them from using the service, leading to less data and smaller objective value placed on making better predictions for young customers in the future. Within a single service, these effects may lead to representation disparity (Hashimoto et al., 2018). However, in a broader ecosystem, individuals can choose amongst services. If a new social media platform can predict the tastes of younger users more accurately, the younger users may spend more of their time on the new service, and correspondingly less on an existing platform. The new platform will then receive more data and and improve its performance on young customers, while the old platform\u2019s predictions may deteriorate, reinforcing their exit. Such a feedback loop may also arise in settings like music recommendation or healthcare, where factors like nationality and gender influence quality of experience (Appendix A).\nIn this paper, we study the dynamics of populations apportioning themselves amongst services, and services that choose predictors based on their observed user population. Our first contribution is to formalize this general setting. In Section 2 we introduce risk reducing populations and services who choose their actions myopically, incrementally improving their utility based on current conditions. Our second contribution is to present a complete characterization of stable fixed points for this general class of dynamics in Section 3. By drawing a connection between the dynamics and the total risk, we further characterize the implications of this dynamic in terms of a utilitarian notion of social welfare, and argue that increasing the number of available services leads to better outcomes in terms of accurate predictions and user experience. In Section 4 we illustrate our theory with simulated experiments and conclude with a discussion of related and future work and Sections 5 and 6."
        },
        {
            "heading": "2 Framework and Setting",
            "text": "We consider a setting where the overall population of individuals is composed of n subpopulations spreading their participation amongst m learners (service providers or decision-makers). Figure 1 illustrates a simple example. Each subpopulation i \u2208 {1, . . . , n} =: [n] has features and labels distributed according to a fixed distribution (x, y) =: z \u223c Di and makes up \u03b2i proportion of the total population, so that \u2211n i=1 \u03b2i = 1. An \u03b1ij proportion of subpopulation i is associated to each\nlearner j \u2208 [m], normalized so that \u2211m\nj=1 \u03b1ij = 1. The subpopulations therefore redistribute their\nparticipation among the various learners; to model the ability of subpopulations to opt-out, one can include a \u201cnull learner\u201d.\nA subpopulation can be as broad as a demographic or affinity group and as granular as a single individual. The allocation of a subpopulation can represent several things: the fraction of a subpopulation which uses a given service, or the fraction of time users from that subpopulation choose to spend using learners\u2019 systems. Accordingly, the relative size \u03b2i of the population can represent the proportion of individuals or the total amount of time individuals spend. The only assumption we make about any subpopulation is that individual samples comprising it are drawn i.i.d. from the same distribution.\nThroughout, we take the number of learners to be smaller than the number of subpopulations, m \u2264 n. Each learner j observes data from the subpopulations who participate in it. Formally, they observe features and labels drawn from a mixture distribution determined by the participation and the relative subpopulation sizes: (x, y) = z \u223c ( \u2211n i=1 \u03b1ij\u03b2i) \u22121\u2211n\ni=1 \u03b1ij\u03b2iDi. Learners make predictions or decisions according to a parameter \u03b8j \u2208 Rd. Beyond the information encoded in features, the learners are not aware of which subpopulation individual data points are from.\nThe quality of predictions made by parameter \u03b8 \u2208 Rd for an individual instance z is quantified by the loss \u2113(\u03b8; z). The quality of \u03b8 for a subpopulation is quantified by the average loss, i.e. the risk Ri(\u03b8) = Ez\u223cDi [\u2113(\u03b8; z)]. Throughout we will make the additional assumption that the risk function for each subpopulation Ri(\u03b8) is convex and differentiable. Figure 2 illustrates an example of the risk functions arising in linear regression."
        },
        {
            "heading": "2.1 Decision dynamics of learners and subpopulations",
            "text": "Subpopulations and learners react to each other, in turn updating allocations \u03b1t and parameters \u0398t = (\u03b8t1, . . . , \u03b8 t m). We introduce a broad class of dynamics by way of a canonical example. Suppose that each subpopulation i updates their allocation by increasing their participation proportional to the quality of various models; for example, by spending more time on music recommendation platforms which require skipping fewer songs. Recalling that the risk (i.e. average loss) quantifies quality, this manifests as a multiplicative weights update: \u03b1t+1ij \u221d \u03b1tij \u00b7 exp(\u2212\u03b3Ri(\u03b8j)) for all j \u2208 [m] and some parameter \u03b3 > 0. This is similar to the retention function studied by Hashimoto et al. (2018) in expectation and has connections to replicator dynamics, a foundational evolutionary dynamic that can be interpreted as a process of information diffusion and imitation (Sandholm, 2020).\nAs a result, each learner j observes data from the mixture distribution ( \u2211n i=1 \u03b1ij\u03b2i) \u22121\u2211n\ni=1 \u03b1ij\u03b2iDi for which we use the shorthand D(\u03b1:,j), where \u03b1:,j \u2208 Rn denotes the vector of allocations from all subpopulations to learner j. Suppose the learners update their parameters using gradient descent to reduce the average loss over this data (e.g. to lessen the number of times that users skip songs).\nLeaving aside finite sample issues, this update takes the form \u03b8t+1j = \u03b8 t j \u2212 \u03b3t\u2207\u03b8 Ez\u223cD(\u03b1:,j) [ \u2113(\u03b8tj ; z) ] with a step size \u03b3t. This update is an incremental version of the repeated retraining dynamics which have been studied in the single learner setting by Hashimoto et al. (2018); Perdomo et al. (2020).\nThe sequential interaction between subpopulations and learners updating in this manner leads to complex nonlinear dynamics: multiplicative weights over non-stationary risks (due to learner updates) and gradient descent over non-stationary populations (due to subpopulation updates). Despite the apparent simplicity of independent update rules, the evolution of subpopulations and learners is highly coupled. To understand the behavior of this complex system, we now formalize key properties.\nThe first observation is that the updates are stateful, with allocations and parameters depending on previous values. This motivates a description of the dynamics arising from interactions between n subpopulations and m learners in terms of the overall state \u03b1 \u2208 \u2206m\u00d7\u00b7 \u00b7 \u00b7\u00d7\u2206m =: \u2206nm and \u0398 \u2208 Rm\u00d7d. We thus define for each subpopulation i a general allocation function \u03bdti : \u2206m \u00d7 Rm\u00d7d \u2192 \u2206m which describes the participation update \u03b1t+1i,: = \u03bd t i ( \u03b1ti,:,\u0398 t )\nat time t, where \u03b1i,: \u2208 \u2206m denotes the vector of allocations from the subpopulation i to all learners. Similarly, define \u00b5tj so learner j updates their parameter according to \u03b8t+1j = \u00b5 t j(\u03b8 t j , \u03b1 t :,j).\nThe second observation is that the basis for the updates is the average loss, i.e. risk. This motivates the following definition: given participation \u03b1 and parameters \u0398, the average risk experienced by each subpopulation i and each learner j is\nR\u0304subpopi (\u03b1i,:,\u0398) := E j\u223c\u03b1i,:\n[ E\nz\u223cDi [\u2113(\u03b8j ; z)]\n] , R\u0304learnerj (\u03b1:,j , \u03b8j) := E\nz\u223cD(\u03b1:,j) [\u2113(\u03b8j ; z)] .\nIn the example of music recommendation, R\u0304subpop corresponds to how often users in each subpopulation skip suggested songs, while R\u0304learner corresponds to how often a given platform observes their users skipping songs. Intuitively, multiplicative weights reduces the average subpopulation risk while gradient descent reduces the average learner risk.\nDefinition 2.1 (Reducing and Minimizing Dynamics). An update rule on u is P -reducing with respect to v if P (ut+1, vt) \u2264 P (ut, vt) for all t and any sequence of vt. It is further P -minimizing in the limit if the inequality is strict when ut is not a minimizer and limt\u2192\u221e P (ut, v) = minu P (u, v).\nWe call a subpopulation i risk reducing (resp. minimizing) when the allocation update on \u03b1i,: is R\u0304subpopi -reducing (resp. minimizing in the limit) with respect to \u0398. Similarly, we call a learner j risk reducing (resp. minimizing) when the parameter update on \u03b8j is R\u0304learnerj -reducing (resp. minimizing in the limit) with respect to \u03b1:,j .\nWe remark that the notion of risk minimizing in the limit is reasonable for subpopulations because their average risk is linear in \u03b1i,:. It is also reasonable for learners because their average risk is convex in \u03b8j (due to the assumption that risks Ri(\u03b8j) are convex). However, risk-reducing/minimizing is only a property defined with respect to the participation or parameter observed at a previous time step. Thus it does not necessarily hold that R\u0304learnerj or R\u0304 subpop i decrease when the state evolves (\u03b1t,\u0398t) \u2192 (\u03b1t+1,\u0398t+1) by sequential updates of \u03bdt and \u00b5t. Figure 3a illustrates this phenomenon.\nProposition 2.2. A subpopulation i updating their participation with multiplicative weights is risk minimizing in the limit as long as \u03b3 > 0 and \u03b10ij > 0 for all j. A learner j updating its parameter with gradient descent is risk minimizing in the limit when the risk functions Ri(\u03b8) are L smooth and the step size satisfies \u03b3t < 2L , \u2211\u221e t=0 \u03b3 t = \u221e, and \u2211\u221e t=1(\u03b3 t)2 <\u221e.\nWe provide a proof and detail several other examples of risk reducing dynamics in Appendix E.1."
        },
        {
            "heading": "2.2 Equilibria and stability",
            "text": "We focus on the equilibrium states resulting from risk-reducing subpopulations and learners.\nDefinition 2.3 (Equilibrium). The state (\u03b1eq,\u0398eq) is an equilibrium state if it is stationary under the dynamics update {\u03bdti}, {\u00b5tj}; i.e. that for all i \u2208 [n] and j \u2208 [m]:\n\u03b1eqi,: = \u03bd t i (\u03b1 eq i,: ,\u0398 eq) and \u03b8eqj = \u00b5 t j(\u03b1 eq :,j , \u03b8 eq j ) .\nIf learners and subpopulations are in an equilibrium state, they will remain that way indefinitely. However, some equilibrium configurations may be fragile. The following definition formalizes equilibria stable to perturbations.\nDefinition 2.4 (Stable Equilibrium). The state (\u03b1eq,\u0398eq) is a stable equilibrium state if it is an equilibrium and for each \u03f5\u03b1, \u03f5\u03b8 > 0, there exist \u03b4\u03b1, \u03b4\u03b8 > 0 such that\n\u2225\u03b10 \u2212 \u03b1eq\u2225 < \u03b4\u03b1, \u2225\u03980 \u2212\u0398eq\u2225 < \u03b4\u03b8 =\u21d2 \u2225\u03b1 t \u2212 \u03b1eq\u2225 \u2264 \u03f5\u03b1, \u2225\u0398t \u2212\u0398eq\u2225 \u2264 \u03f5\u03b8 \u2200 t \u2265 0.\nIt is further asymptotically stable if limt\u2192\u221e \u2225\u03b1t \u2212 \u03b1eq\u2225 = 0 and limt\u2192\u221e \u2225\u0398t \u2212\u0398eq\u2225 = 0.\nStability analysis identifies qualitatively different equilibrium states. For the class of risk reducing dynamics that we study, equilibria may be unstable, stable, or asymptotically stable; Appendix E.2 presents examples. While a quantitative understanding of convergence may also be of interest, it would require stronger assumptions on the behavior of subpopulations and learners; here we favor generality and leave this to future work. Furthermore, characterizing stable equilibria sets the foundation for understanding high probability behavior of systems under noisy updates which are risk reducing only in expectation (Kushner, 1967). This sets the stage for considering finite sample risk minimization or multi-agent user models, a challenge which we leave to future work."
        },
        {
            "heading": "3 Main Results",
            "text": "We study a large class of feedback dynamics between risk reducing learners and subpopulations described by the sequential updates: \u03b1t+1 = \u03bdt(\u03b1t,\u0398t) and \u0398t+1 = \u00b5t(\u03b1t+1,\u0398t). Our analysis allows for learners and subpopulations who exhibit a diverse range of risk reducing and minimizing behaviors. We do not require that every learner or every subpopulation update their parameter or allocation in the same manner or even at every timestep, allowing for any number of round-robin schemes. Proofs of all results are presented in the appendix."
        },
        {
            "heading": "3.1 Total Risk Reduction",
            "text": "Definition 3.1 (Total Risk). The total risk of all subpopulations over all learners is the weighted sum\nRtotal(\u03b1,\u0398) := n\u2211\ni=1 m\u2211 j=1 \u03b2i\u03b1ijRi(\u03b8j).\nThe total risk maps \u2206nm \u00d7 Rm\u00d7d \u2192 R. While our assumption that the loss is convex implies that the total risk is convex in \u0398, it is not jointly convex in (\u03b1,\u0398), illustrated in the right panel of Figure 2.\nOur first result shows that the total risk Rtotal(\u03b1t,\u0398t) is non-increasing over time.\nProposition 3.2. Under any risk-reducing subpopulation and learner dynamics, the total risk is non-increasing \u2200t: Rtotal(\u03b1t+1,\u0398t+1) \u2264 Rtotal(\u03b1t,\u0398t). If subpopulations and learners are risk minimizing in the limit, then the total risk is strictly decreasing unless (\u03b1t,\u0398t) is a local minimizer.\nThus, the total risk acts as a potential function for the feedback dynamics of learners and subpopulations. When the subpopulation and learner dynamics are risk minimizing in the limit, there is a strong connection between properties of the total risk function and equilibria of the dynamics.\nTheorem 3.3. For any learners and subpopulations who are risk minimizing in the limit, an equilibrium (\u03b1eq,\u0398eq) is asymptotically stable if it is an isolated local minimizer of the total risk Rtotal. If it is not a local minimizer of the total risk, then it is not stable.\nThe connection between stability and the total risk function is significant in at least two ways: first, it means that under general classes of myopic and self-interested behaviors on the part of subpopulations and learners, the total risk is driven to at least a local minimum. Second, it is a technically useful connection that will enable us to characterize and classify the stable equilibria for dynamics which are risk minimizing in the limit. We remark that Theorem 3.3 leaves open the question of stability for equilibria which are non-isolated minima of the total risk function. In Appendix E.2, we provide examples which show that such points may be asymptotically stable, stable, or unstable depending on the particular instantiation of dynamics. The following existence result further motivates our focus dynamics which are risk minimizing, rather than reducing.\nCorollary 3.4. Equilibria exist when learners and subpopulations are risk minimizing in the limit and the total risk function has isolated local minima. They may not exist otherwise."
        },
        {
            "heading": "3.2 Segmented and Balanced Equilibria",
            "text": "Definition 3.5 (Segmented allocation). An allocation is segmented if \u03b1ij \u2208 {0, 1} for all i, j.\nIn a segmented allocation, each subpopulation is associated with a single learner, and thus the population is partitioned across learners. For allocation dynamics like multiplicative weights, such configurations are clearly equilibria for any parameter choice \u0398 on the part of the learners. We thus consider the set of possible segmented equilibria and characterize which are asymptotically stable.\nTheorem 3.6. Suppose learners and subpopulations are risk minimizing in the limit, \u03b1eq is segmented, and Rtotal(\u03b1eq,\u0398) has a unique minimizer \u0398eq. Define a mapping \u03b3 : [n] \u2192 [m] such that \u03b3(i) = j is the learner with nonzero mass in \u03b1eqi,: . If every subpopulation strictly prefers their current learner:\nRi(\u03b8eq\u03b3(i)) < Ri(\u03b8 eq j ) , (1)\nfor all i and learners j \u0338= \u03b3(i), then (\u03b1eq,\u0398eq) is an asymptotically stable equilibrium. If there is a subpopulation who would strictly prefer to switch learners, then (\u03b1eq,\u0398eq) is not stable.\nWhen risks are strongly convex, there is always such a unique minimizer \u0398eq. In particular, in a segmented allocation, each \u03b8eqj minimizes the average loss over the group of subpopulations assigned to them. We use this perspective to provide intuitive necessary condition for stability for a special class of risk function in the appendix (Corollary D.1). This condition verifies that in Figure 2, a segmented equilibrium with subpopulation 1 and 3 assigned to the same learner cannot be stable.\nTheorem 3.6 leaves open the question of stability in the case that the risks in (1) are equal. Under such risk equivalence, is it natural to consider equilibria where a subpopulation has support over multiple learners.\nTheorem 3.7. Consider dynamics which are risk minimizing in the limit and an \u03b1eq with any subpopulation i having nonzero support on set of two or more learners j \u2208 J . Assume risks are strongly convex and define \u0398eq = argminRtotal(\u03b1eq,\u0398). Then (\u03b1eq,\u0398eq) cannot be stable unless it is \u201cbalanced\u201d in the sense that learners in J are risk equivalent and optimal for i, i.e. for all j, j\u2032 \u2208 J ,\nRi(\u03b8eqj ) = Ri(\u03b8 eq j\u2032 ) and \u2207Ri(\u03b8 eq j ) = 0 .\nIf it is balanced, so are all allocations for subpopulation i with support over J . Finally, all stable equilibria must be either balanced or segmented.\nThis result characterizes a set of possibly stable equilibria. It demonstrates that risk optimality, in addition to equivalence, is necessary. Guaranteeing the stability of such balanced equilibria requires further information about the dynamics, and it is not possible to make a general statement. Examples in Appendix E.2 demonstrate that such balanced equilibria may be asymptotically stable, stable, or unstable. Furthermore, the balance condition is fragile in the sense that it would not hold under small perturbations to the underlying risk functions. While the number of possible balanced equilibria is combinatorial in the number of learners and subpopulations, risk functions are continuous, so it is possible to find arbitrarily small perturbations to any the risk functions that would destabilize all balanced equilibria.\nProof Sketch of Theorems 3.6 and 3.7. By Theorem 3.3, characterizing the stable equilibria is equivalent to characterizing isolated and non-isolated local minima of the total risk. We show that it suffices to characterize local minima of the partial minimization F (\u03b1) = min\u0398Rtotal(\u03b1,\u0398) over the simplex product \u2206nm = \u2206m \u00d7 \u00b7 \u00b7 \u00b7 \u00d7\u2206m. Since F is concave, all minima occur on the boundary, i.e. a face or a vertex. Since F is still concave when restricted to a face of the simplex, the same argument shows the minima are on the boundary, hence vertices, except for the degenerate case where F takes a constant value over the face.\nThus, the isolated local minima occur at vertices of the simplex product, which correspond to segmentation. Further analysis of F yields the conditions presented in Theorem 3.6. The local minima in the degenerate case are characterized by the balanced equilibria conditions in Theorem 3.7."
        },
        {
            "heading": "3.3 Social Welfare for Segmented Populations",
            "text": "Definition 3.8. The social welfare of a state (\u03b1,\u0398) is strictly decreasing in the total risk Rtotal(\u03b1,\u0398).\nThis definition of social welfare is utilitarian in the sense that it depends on the cumulative quality of individuals\u2019 experiences. Maximizing the social welfare corresponds to minimizing the total risk, which can be posed as the following optimization problem\n(\u03b1\u22c6,\u0398\u22c6) \u2208 min \u03b1,\u0398 Rtotal(\u03b1,\u0398) s.t. \u03b1i,: \u2208 \u2206m \u2200 i = {1, . . . n} . (2)\nHere, (\u03b1\u22c6,\u0398\u22c6) is the social welfare maximizer.\nOur discussion of stable equilibria has so far focused on only local minimizers of the total risk. In fact, global minimization of this objective (and therefore maximization of social welfare) is a hard problem. The total risk objective can be viewed as an instance of the k-means clustering problem with k = m. In the language of this literature (e.g., (Selim and Ismail, 1984)), each subpopulation is a data point and the parameter selected by each learner is a cluster center. The allocations described by \u03b1 correspond to (fuzzy) cluster assignment and each risk function Ri(\u03b8j) corresponds to a measure of \u201cdissimilarity\u201d between data points (subpopulations) and cluster centers (learners).\nThe connection to k-means clustering elucidates the difficulty of minimizing the total risk. The \u201cminimum sum-of-squares clustering\u201d problem (i.e., squared Euclidean norm dissimilarity) is NP hard with general dimension even when k = 2 (Aloise et al., 2009). When the number of clusters and dimension are fixed, Inaba et al. (1994) present an algorithm for solving the minimum sum-of-squares clustering problem which is polynomial in the number of datapoints. Translated to our setting, its complexity is O(nmd). It is therefore unrealistic to hope that a myopic dynamic might generally lead to social welfare maximization. However, due to the connections with total risk, risk reducing dynamics are at least well-behaved with regards to social welfare.\nProposition 3.9. For risk reducing subpopulations and learners, social welfare is non-decreasing over time. If the dynamics are furthermore risk minimizing in the limit, social welfare is strictly increasing and stable equilibria correspond to local social welfare maxima.\nLocal maximization is not a panacea: Example E.10 in the appendix shows a local maximum of the social welfare can be much worse than the global one. In this example, a large gap between a stable local optimum and the global optimum arises in part due to a large difference in subpopulations\u2019 sizes. We further remark that minority groups can be under-served particularly when considering\nworst-case risk over subpopulations (Hashimoto et al., 2018). Even at a social welfare maximizer (\u03b1\u22c6,\u0398\u22c6), the worst-case subpopulation risk can be arbitrarily bad. It is straightforward to construct such examples even in the single learner case: consider a minority group with vanishingly small population proportion and arbitrarily high risk at the optimal parameter for the majority group (Example E.12).\nDespite these inherent difficulties, we find that the situation improves as the number of learners increases. It is straightforward to see that the maximal social welfare will increase: any point which is optimal for m learners can be trivially transformed into a feasible point for m+ 1 learners which achieves the same social welfare, by allocating no subpopulations to the new learner. There is more nuance involved when considering any possible stable equilibria. Instead, we make a statement about a particular learner growth process which corresponds to existing learner m \u201csplitting in half\u201d.\nProposition 3.10. Suppose that risks are strongly convex, there are m learners, (\u03b1eq,\u0398eq) is an equilibrium, and at least one subpopulation i allocated to learner m does not have optimal subpopulation risk, so \u2207Ri(\u03b8eqm ) \u0338= 0. The state is amended to add an additional learner: \u0398\u0303eq = [\u0398eq, \u03b8eqm ] and\n\u03b1\u0303eq:,j = { \u03b1eq:,j j \u2264 m 1 2\u03b1 eq :,m j \u2208 {m,m+ 1}\nUnder dynamics which are risk minimizing in the limit, the equilibrium (\u03b1\u0303eq, \u0398\u0303eq) is not stable, so a small perturbation will send the system to a state with strictly lower total risk (higher social welfare)."
        },
        {
            "heading": "4 Simulations",
            "text": "We illustrate the salient properties of the decision dynamics in simulation1. We consider both a synthetic setting as well as one instantiated from a prediction task on census data.\nSynthetic In Figure 3a we consider a simple scenario with n = 3 subpopulations of equal sizes \u03b2i = 1/3, quadratic risk functions Ri = \u2225\u03d5i \u2212 \u03b8\u22252 + 1 with distinct risk minimizing decisions\n1Code at https://anonymous.4open.science/r/MultiPlayerRiskReduction-70D6/\n\u03d5i and m = 2 learners. The learners minimize their risk according to full risk minimization (Example E.4) and the subpopulations update their participation via multiplicative weights update (Section 2.1). When \u03b10i,j = 1/2 for all i, j the risk equality condition from Theorem 3.7 is satisfied with \u03b8eqj = (\u03d51 + \u03d52 + \u03d53)/3, however the optimality condition is not. We therefore observe that this equilibrium is not stable, and slightly perturbing the initial conditions leads to split-market equilibria. Figure 3a illustrates trajectories from three different perturbations. It demonstrates that the total risk is non-increasing whereas the average risks for both learners and subpopulations are not monotonic.\nAnother set of experiments in Figure 3b illustrates how larger numbers of learners lead to better outcomes for the subpopulations. We consider a set of m = 2 learners and n = 50 subpopulations. We simulate the dynamics until the market has reached equilibrium, at which point one of the learners breaks up into two identical learners with half the user base. From this unstable equilibrium (Proposition 3.10) we slightly perturb the parameters of the two learners and allow the system to reach a new equilibrium state. The procedure repeats until the number of learners reaches number of subpopulations. These simulations illustrate how market diversity alleviates worst case outcomes: as more learners are added, not only does the total risk improve, but so does the risk of the worst-off subpopulation.\nCensus data We investigate a setting where subpopulations and their risk functions are instantiated by a prediction task on real data. Using folktables (Ding et al., 2021) we consider a modified version of ACSTravelTime prediction problem derived from the 2018 California Census data. We consider 8 subpopulations corresponding to racial groups with relative size ranging from 0.23% to 61.71%. We define the least-squares risk functions as Ri(\u03b8) = 1Ni \u2225Xi\u03b8 \u2212 yi\u2225\n2 where Xi \u2208 RNi\u00d7d are the features (containing demographics, educational attainment, income levels, and modes of transportation) and yi \u2208 RNi are the labels (log transform of the daily commute time in minutes) for individuals within subpopulation i. We simulate risk reducing dynamics from a perturbed balanced equilibrium as above. As in the synthetic example, the risks of learners and subpopulations are not all monotone (Figure 4a), but the total risk function is. Figure 4b illustrates the convergence of allocation dynamics to a segmented equilibrium."
        },
        {
            "heading": "5 Related Work",
            "text": "Here we summarize the most relevant related work and present a more complete overview in Appendix B. Many recent works study distribution shifts due to endogenous reactions, for example strategic behavior exhibited by a user population. Performative prediction, first introduced by Perdomo et al. (2020), models a single decision-maker facing a risk minimization problem subject to an underlying decision-dependent data distribution. A variant of this problem considers timedependent dynamics of the data distribution (Ray et al., 2022; Brown et al., 2022). Endogenous distribution shift has also been studied in settings with multiple decision-makers as a continuous game, such as the multi-player performative prediction problem (Narang et al., 2022; Piliouras and Yu, 2022; Wood and Dall\u2019Anese, 2022). However, these works focus on competitive equilibria while our work focuses on myopic decision-makers. Furthermore, work in the performative prediction setting primarily considers strategic covariate shifts in a single distribution. In contrast, we consider a mixture of distributions: sub-populations of users whose participation choices result in attrition and retention dynamics which are not captured by aforementioned models.\nUser retention in machine learning systems is closely related to the population participation dynamics we consider (Hashimoto et al., 2018; Zhang et al., 2019). In settings with multiple sub-populations of users of different types, the question of retention has been explored in parallel with the issue of fairness. Hashimoto et al. (2018) coined the term representation disparity for the phenomenon in which optimizing average performance leads low accuracy on minority groups, causing an exodus of said groups. For single learners, systems which instead perform robust risk minimization avoid such disparity. Our work generalizes the single-learner retention setting and analyzes the fixed points of dynamics between multiple systems and populations without modifying risk functions to be robust. Ginart et al. (2021) also consider user choice between multiple learning systems, with an empirical investigation and theoretical results focused on finite sample effects. In contrast, we propose a general class of risk reducing dynamics and develop a comprehensive theoretical understanding."
        },
        {
            "heading": "6 Discussion",
            "text": "In this paper, we study the feedback dynamics of user retention for loss minimizing learners, where subpopulations choose between providers. We introduce a formal notion of risk reducing and minimzing to capture this feedback, and show that there is a close connection between such dynamics and the total risk summed over subpopulations and learners. We provide a comprehensive characterization of stable equilibria and investigate the implications in terms of a utilitarian social welfare. This work relates to questions of fairness and minority representation in several ways. First, our results imply that risk-minimizing dynamics in multi-learner settings can result in higher welfare for small subpopulations compared with single-learner settings, as studied by (Hashimoto et al., 2018; Zhang et al., 2019). This resonates with recent work showing that monopolies have higher performative power and lead to lower individual utility (Hardt et al., 2022).\nThe dynamics that we study often lead to segmentation of subpopulations across learners as an emergent phenomenon2. This segmentation can lead to pointwise lower risks for subpopulations, especially when subpopulations have considerably different risk profiles. In some contexts, the\n2This connects to economic literature on \u201crational\" discrimination, where competitors have no inherent preference to discriminate and yet equilibria are segregated, e.g. Foster and Vohra (1992)\nbenefits of the reduced risk among subpopulations may outweigh possible harms from segregation. In others, where proportional representation of groups across learners, models, or clusters (Kleindessner et al., 2019a,b) is important, our work implies that independent risk minimization can lead to undesirable outcomes. In short, this work analyzes natural dynamics with consequences for the distribution of subpopulations amongst independent learners; whether or not the consequences are desirable depend on the specific application considered.\nWe highlight several directions for future work. Our results lay the groundwork for an investigation of the stochastic dynamics that occur for finite sample approximations to the risk or participation driven by decisions of individuals. Such behaviors are risk reducing in expectation, so we expect the noisy trajectories to converge with high probability to sets around the asymptotically stable equilbria we characterize. There are many interesting and relevant questions in the finite sample setting: What is the effect of sample size on the ability of new learners to enter a market and minority subpopulations to be adequately represented? Can we model heterogeneous learners who differ in which features they measure and with how much noise? Are there trade-offs between the expressivity of models and the practical difficulty of minimizing risk from finite samples in high dimensions?\nIt would also be interesting to consider extensions or alternative dynamics models for the learner and subpopulation decisions. One could investigate competitive learners who explicitly strategize to capture subpopulations (Ben-Porat and Tennenholtz, 2019; Aridor et al., 2020); this setting is related to facility location and Hotelling games (Owen and Daskin, 1998; Hotelling, 1929). One might imagine that subpopulations do not act uniformly and may not even be entirely independent of each other\u2014the participation update may depend on some underlying social network. The connections between total risk reduction and k-means clustering algorithms suggest interventions (like k-means++ initialization) which could improve social welfare. Results on \u201cground truth recovery\u201d may yield insight into particular population structures that lead to simpler dynamics or restricted sets of equilibria."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank Laurent Lessard for suggesting the clever argument to prove Lemma C.7. JM is supported by an NSF CAREER award (ID 2045402), an NSF AI Center Award (The Institute for Foundations of Machine Learning), and the Simons Collaboration on the Theory of Algorithmic Fairness. LJR is supported by NSF CNS-1844729, NSF IIS-1907907, and Office of Naval Research YIP Award N000142012571. MF is supported by NSF TRIPODS II-DMS 2023166, NSF TRIPODS-CCF 1740551, and NSF CCF 2007036."
        },
        {
            "heading": "A Motivating Examples",
            "text": "We discuss several real-world examples which exhibit degrees of market segmentation across characteristics such as nationality, age, and race. In these examples, market conditions are certainly affected by more complex phenomena, from network effects to explicit competition between firms. While we do not claim that the dynamics we study are necessarily the main contributing factor, our simple model isolates the potential contribution of learning dynamics: namely, to reinforce such segmentation. This perspective highlights the potential effects of efforts to incorporate data or improve personalization."
        },
        {
            "heading": "A.1 Music Streaming",
            "text": "Worldwide market share of music streaming services is split between several companies (see Figure 5). However, the distribution of music streaming by country shows clear patterns: most users in China use Tencent, most users in Mexico use Spotify, and most users in the Middle East and Northern Africa (MENA) use Anghami. On the other hand, the markets United States, Russia, and India are not dominated by a single service. However, the handful of most used services in these regions have a small market outside of their main market. Due to this segmented market, only certain platforms collect large scale data about music preferences in certain regions. If many users from western cultures make playlists containing both Arabic and Indian music, Spotify may learn to associate those genres in a way that is undesirable or even offensive to users from those cultures. This leads to a self-reinforcing effect: services who make bad predictions for users from certain cultures are unlikely to correct this bias as those users choose instead to use services that more accurately reflect their tastes.\n3All statistics recorded from Statista: Worldwide:https://www.statista.com/statistics/653926/music-streaming-service-subscriber-share, United States: https://www.statista.com/statistics/1351506/streaming-services-music-podcasts-united-states/, China: https://www.statista.com/statistics/711295/china-leading-mobile-music-platforms-by-active-user-number/, India: https://www.statista.com/statistics/922400/india-music-app-market-share/, Mexico: https://www.statista.com/statistics/1018370/over-the-top-audio-platforms-mexico-by-market-share,"
        },
        {
            "heading": "A.2 Social Media",
            "text": "Usage of various social media sites in the US varies across genders4 and age groups5. For example, the users of Facebook and LinkedIn skew older while Snapchat, Tiktok, Tumblr, and Twitch are more heavily used by the younger population. Similarly users of Pinterest strongly skew female while users of Twitch are more likely to be male. Figure 6 shows the disparities along gender and age for leading social media platforms. These disparities across platforms are reinforced by user behaviors: imaging the experience of a 45 year old logging onto Twitch for the first time compared with a 14 year old; or instead imagine a 14 year old logging into Facebook. Because the usage patterns determine the data available to the platforms, the disparities are also reinforced by the behavior of the platforms themselves. Similarly, Pinterest algorithms are more likely to be tailored to the tastes of an female demographic, while Twitch\u2019s to a demographic more representative of males."
        },
        {
            "heading": "A.3 Personalized health",
            "text": "The growing popularity of direct-to-consumer genetic testing is driven by the growth of two market leaders: AncestryDNA and 23andMe6. These tests are used both for determining ancestry as well as receiving polygenic risk scores for various medical conditions. The accuracy of the tests varies across ethnic groups; with Latino, Middle Eastern and, African ancestry being most under-represented. This issue is self re-inforcing; for instance people of African descent are less likely to use a large\nRussia: https://www.statista.com/statistics/1347035/most-popular-music-streaming-platforms-in-russia/, Middle East and North America: https://www.statista.com/statistics/1295716/ mena-share-of-paying-music-streaming-subscribers-by-platform/.\n4https://www.statista.com/statistics/1337563/us-distribution-leading-social-media-platforms-by-gender/ 5https://www.statista.com/statistics/1337525/us-distribution-leading-social-media-platforms-by-age-group/ 6https://www.statista.com/chart/17023/commercial-genetic-testing/\nservice like 23andMe and more likely to use a specialized service such as AfricanAncestry7."
        },
        {
            "heading": "B Related Work",
            "text": "The study of equilibria in the presence of utility optimizing agents has classical roots in game theory, and optimization over decision-dependent probabilities is classically studied by stochastic optimization and control (e.g., the review article by Hellemo et al. (2018)); we narrow our focus to the most relevant literature on this as it arises in machine learning systems.\nEndogenous Distribution Shifts. In the study of machine learning systems, a large body of literature studies exogenous distribution shifts such as covariate, label, or concept drift (Qui\u00f1oneroCandela et al., 2008). A more recent trend is to study shifts in the underlying data distribution due to endogenous reactions, for example due to strategic behavior exhibited by a user population. The work of Perdomo et al. (2020) introduces performative prediction as a model capturing user reaction via endogenous distribution shifts. This work models a single decision-maker facing a risk minimization problem subject to an underlying decision-dependent data distribution. Following its introduction, several relevant solution concepts have been explored and algorithms for achieving them proposed (Izzo et al., 2021; Drusvyatskiy and Xiao, 2020; Mendler-D\u00fcnner et al., 2020; Miller et al., 2021). A variant of the single decision-maker performative prediction problem studies time-dependent dynamics of the data distribution, with both exogenous (Wood et al., 2021; Cutler et al., 2021) and endogenous (Ray et al., 2022; Brown et al., 2022) sources. These works primarily consider strategic covariate shifts in a single distribution. In contrast, we consider a mixture of distributions: sub-populations of users whose participation choices result in attrition and retention dynamics which are not studied in the aforementioned distribution shift literature.\nMultiple Decision-Makers. Endogenous distribution shift has also been studied in settings with multiple decision-makers as a continuous game. For instance, the multi-player performative prediction problem extends the original problem by allowing for multiple competing decision-makers (Narang et al., 2022; Piliouras and Yu, 2022; Wood and Dall\u2019Anese, 2022). This line of work differs from ours in that the population is modeled as homogeneous and stateless. These works focus on characterizing the existence and uniqueness of different types of competitive equilibria for the game, and analyze learning dynamics that lead to different equilibrium concepts. In contrast, in our paper the focus is on asymptotically stable points (equilibrium) for the combined dynamical system resulting from myopic optimization by non-anticipating decision-makers and stateful user participation updates.\nRetention. User retention in machine learning systems is closely related to the population participation dynamics we consider (Hashimoto et al., 2018; Zhang et al., 2019). In settings with multiple sub-populations of users of different types, the question of retention has been explored in parallel with the issue of fairness. Hashimoto et al. (2018) coined the term representation disparity for the phenomenon in which the traditional approach of minimizing average performance leads to high overall accuracy coupled with low accuracy on minority groups, causing an exodus of said groups. For single learners, systems which instead perform robust risk minimization avoid such disparity.\nOur work generalizes the single-learner retention setting and analyzes the fixed points of dynamics between multiple systems and populations without modifying risk functions to be robust. Ginart et al.\n7https://africanancestry.com/\n(2021) also consider user choice between multiple learning systems, with an empirical investigation and theoretical results in restricted settings focused on finite sample effects. In contrast, we propose a general class of risk reducing dynamics and develop a comprehensive theoretical understanding."
        },
        {
            "heading": "C Preliminaries",
            "text": ""
        },
        {
            "heading": "C.1 Notation",
            "text": "We introduce a compact notation. The simplex product is defined as\n\u2206nm = A \u2208 Rn\u00d7m | m\u2211 j=1 Aij = 1  so that the rows sum to 1. Then the state space of subpopulation allocations and learner parameters is X = \u2206nm \u00d7 Rm\u00d7d. For a square matrix A, we use the notation diag(A) to represent the vector containing the diagonal entries of A. For a vector a, Diag(a) is a diagonal matrix with a along the diagonal. Furthermore we will say a \u2264 b for vectors a, b if the inequality holds elementwise.\nDefine a matrix valued risk function R : Rm\u00d7d \u2192 Rn\u00d7m so that Rij(\u0398) = Ri(\u03b8j). Recall that in Section 2.1, the subpopulation and learner risks played a key role. We therefore define vector valued functions R\u0304subpop : X \u2192 Rn and R\u0304learner : X \u2192 Rm as follows:\nR\u0304subpop(\u03b1,\u0398) = diag(\u03b1R(\u0398)\u22a4), R\u0304learner(\u03b1,\u0398) = diag ( Diag(\u03b1\u22a4\u03b2)\u22121\u03b1\u22a4Diag(\u03b2)R(\u0398) ) .\nThen the definition of risk reducing dynamics for subpopulations and learners can be written as\nR\u0304subpop(\u03b1t+1,\u0398) \u2264 R\u0304subpop(\u03b1t,\u0398) and R\u0304learner(\u03b1,\u0398t+1) \u2264 R\u0304learner(\u03b1,\u0398t) .\nRisk minimizing in the limit is defined similarly, where the inequality is strict for at least one entry of the vectors unless the state is at a local minimum.\nThe total risk can be written as\nRtotal(\u03b1,\u0398) := tr(diag(\u03b2)\u03b1R(\u0398)\u22a4) .\nLemma C.1. Under the assumption that all loss functions are continuous, the risk function R is continuous w.r.t. to \u0398, and thus Rtotal is continuous w.r.t. \u03b1 and \u0398.\nThe sequential dynamics updates described in Section 2.1 can be written as[ \u03b1t+1\n\u0398t+1\n] = [ \u03bd(\u03b1t,\u0398t) \u00b5(\u03b1t+1,\u0398t) ] = [ \u03bd(\u03b1t,\u0398t) \u00b5(\u03bd(\u03b1t,\u0398t),\u0398t) ] =: f(\u03b1t, \u0398t) . (3)\nLemma C.2. As long as the subpopulation and learner updates described in Section 2.1 are locally Lipschitz, so is the dynamics function f defined in (3)."
        },
        {
            "heading": "C.2 Background",
            "text": "For completeness, we include important results and definitions that our proofs will make use of. First, we state two theorems about Lyapunov theory for stability.\nTheorem C.3 (Theorem 1.2 in (Bof et al., 2018)). Let xeq \u2208 D be an equilibrium point for the autonomous systems xt+1 = f(xt) where f : D \u2192 X is locally Lipschitz in D \u2286 X . Suppose there exists a function V : D \u2192 R which is continuous and such that\nV (xeq) = xeq and V (x) > 0 \u2200 x \u2208 D \u2212 {xeq} V (f(x))\u2212 V (x) \u2264 0 (resp. < 0) \u2200 x \u2208 D\nThen xeq is stable (resp. asymptotically stable).\nTheorem C.4 (Theorem 1.5 in (Bof et al., 2018)). Let xeq \u2208 D be an equilibrium point for the autonomous systems xt+1 = f(xt) where f : D \u2192 X is locally Lipschitz in D \u2286 X . Let V : D \u2192 R be a continuous function with V (xeq) = 0 and V (x0) > 0 for some x0 arbitrarily close to xeq. Let r > 0 be such that Br(xeq) \u2286 D and U = {x \u2208 Br(xeq) | V (x) > 0}, and suppose that V (f(x))\u2212 V (x) > 0 for all x \u2208 U . Then xeq is not stable.\nNext, we state the definition of a (isolated) local minimum.\nDefinition C.5. The point u\u22c6 is a local minimum (resp. isolated local minimum) of a function h over a domain U if there is a \u03b4 > 0 such that for any u \u2208 U with \u2225u\u2212 u\u22c6\u2225 \u2264 \u03b4, h(u\u22c6) \u2264 h(u) (resp. h(u\u22c6) < h(u)).\nNext, we state the implicit function theorem.\nTheorem C.6 (Implicit Function Theorem). Let U \u2286 Rn, V \u2286 Rm be open sets and f : U \u00d7V \u2192 R is Cr for some r \u2265 1. For some x0 \u2208 U, y0 \u2208 V assume the partial derivative in the second argument D2f(x0, y0) : Rm \u2192 R is an isomorphism. Then there are neighborhoods U0 of x0 and W0 of f(x0, y0) and a unique Cr map g : U0 \u00d7W0 \u2192 V such that for all (x,w) \u2208 U0 \u00d7W0, f(x, g(x,w)) = w.\nFinally we prove a property of intersecting convex hulls.\nLemma C.7. Let x1, x2, \u00b7 \u00b7 \u00b7xn and y1, y2, . . . , ym be some points in Rd. Define by Cx and Cy the convex hulls of {xi}ni=1 and {yi}mi=1 respectively. Then there do not exist points x\u0304 \u2208 Rd and y\u0304 \u2208 Rd such that the following inequalities are satisfied:\n\u2225xi \u2212 x\u0304\u2225 < \u2225xi \u2212 y\u0304\u2225 \u2200i = 1, 2, . . . , n \u2225yj \u2212 y\u0304\u2225 < \u2225yj \u2212 x\u0304\u2225 \u2200j = 1, 2, . . . ,m\nProof. Assume by contradiction that the inequalities above hold. Define Hx := {z \u2208 Rd | \u2225z \u2212 x\u0304\u2225 < \u2225z \u2212 y\u0304\u2225} and Hy := {z \u2208 Rd | \u2225z \u2212 y\u0304\u2225 < \u2225z \u2212 x\u0304\u2225}. The sets Hx and Hy are disjoint half-spaces (without boundary) then defined by the hyperplane bisecting the segment connecting x\u0304 and y\u0304. By assumption then we have that xi \u2208 Hx for all i and yj \u2208 Hy for all j; since Hx and Hy are convex, it follows that Cx \u2282 Hx and Cy \u2282 Hy. Therefore Cx \u2229 Cy = \u2205, which leads to a contradiction."
        },
        {
            "heading": "C.3 Properties of partial minimization",
            "text": "In this section, we state a handful of important results about the partial minimization of the total risk. This is somewhat similar to the analysis presented by Selim and Ismail (1984) in the context of clustering algorithms.\nLemma C.8. Define the function F : Rm\u00d7n \u2192 R as F (\u03b1) = min\u0398Rtotal(\u03b1,\u0398). This function is concave and a point (\u03b10,\u03980) is a local minimum of Rtotal over the domain X = X\u03b1\u00d7Rm\u00d7d if \u03b10 is a local minimum of F over the domain X\u03b1 and \u03980 \u2208 argmin\u0398Rtotal(\u03b10,\u0398). Furthermore, in the case that \u03980 is the unique minimizer of Rtotal(\u03b10,\u0398), then (\u03b10,\u03980) is a local minimum (resp. isolated local minimum) if and only \u03b10 is a local minimum (resp. isolated local minimum).\nProof of Lemma C.8. F (\u03b1) is well defined due to the convexity of the risk functions. Concavity follows from the observation that F is the point-wise minimum of a family of functions which are linear in \u03b1 (since for every fixed \u0398, the total risk is linear in \u03b1).\nWe break the proof of equivalence into two implications.\n1. F minimized =\u21d2 Rtotal minimized There is a \u03b4 > 0 such that for any \u03b1 \u2208 X\u03b1 with \u2225\u03b10 \u2212 \u03b1\u2225 \u2264 \u03b4, F (\u03b10) \u2264 F (\u03b1), i.e.\nRtotal(\u03b10,\u03980) \u2264 Rtotal(\u03b1,\u0398\u2217(\u03b1))\nfor any minimizing \u0398\u2217(\u03b1). For fixed allocation \u03b1 define Rtotal\u03b1 (\u0398) = Rtotal(\u03b1,\u0398) which is is convex and minimized at \u0398\u2217(\u03b1) and hence:\nRtotal(\u03b1,\u0398\u2217(\u03b1)) \u2264 Rtotal(\u03b1,\u0398), \u2200 \u0398 .\nCombining the inequalities yields: Rtotal(\u03b10,\u03980) \u2264 Rtotal(\u03b1,\u0398), and thus (\u03b10,\u03980) is a local minimum of Rtotal. The implication for the isolated local minimum case follows by the same arguments with strict inequalities on the total risk, noting that if \u03980 is a unique minimizer, it must also be isolated.\n2. Rtotal minimized =\u21d2 F minimized Recall that Rtotal(\u03b1,\u0398) can be written as tr(diag(\u03b2)\u03b1R(\u0398)\u22a4). Then\nRtotal(\u03b10 +D,\u03980)\u2212Rtotal(\u03b10,\u03980) = tr(diag(\u03b2)DR(\u03980)\u22a4) \u2265 0\nwhere inequality holds for all D \u2208 Rn\u00d7m such that \u03b10 +D \u2208 X\u03b1 by the fact that \u03b10 is a minimum. Recognizing the gradient from Lemma C.9 and using the uniqueness of \u03980, the expression is equivalently \u27e8\u2207\u03b1F (\u03b10), D\u27e9 \u2265 0. In other words, the directional derivative in any feasible direction D is non-negative. Hence, \u03b10 is a local minimum of F . The implication for the isolated local minimum case follows by the same arguments with strict inequalities on the total risk.\nLemma C.9. For F : Rn\u00d7m \u2192 R defined as in Lemma C.8, suppose the minimizier \u0398\u2217(\u03b1) = argmin\u0398Rtotal(\u03b1,\u0398) is unique. The gradient is\n\u2207\u03b1F (\u03b1) = diag(\u03b2)R (\u0398\u2217(\u03b1)) , i.e. \u2202F (\u03b1) \u2202\u03b1ij = \u03b2iRi(\u03b8\u2217j (\u03b1)) .\nFurther suppose that the risks are strongly convex. Then second partial derivatives are given by\n\u22022F (\u03b1)\n\u2202\u03b1k\u2113\u2202\u03b1ij = { 0 k \u0338= j \u2212\u03b2i\u2207Ri(\u03b8\u22c6j )\u22a4 (\u2211 \u2113\u2032 \u03b2\u2113\u2032\u03b1\u2113\u2032j\u22072R\u2113\u2032(\u03b8\u22c6j ) ) \u2207R\u2113(\u03b8\u22c6j ) k = j .\nProof. Computing the gradient:\n\u2207\u03b1F (\u03b1) = \u2207\u03b1Rtotal(\u03b1,\u0398\u22c6(\u03b1)) +\u2207\u0398\u2217(\u03b1)\u2207\u03b8Rtotal(\u03b1,\u0398\u22c6(\u03b1)) = diag(\u03b2)R(\u0398) .\nThe first equality follows by product rule. The second equality follows because 1) the total risk is linear in \u03b1 and 2) the second term is zero due to the optimality of \u0398\u2217(\u03b1).\nNow notice that \u2202\n\u2202\u03b1k\u2113 Ri(\u03b8\u22c6j (\u03b1)) =\n\u2329 \u2202\u03b8\u22c6j (\u03b1)\n\u2202\u03b1k\u2113 ,\u2207\u03b8Ri(\u03b8\u22c6j (\u03b1)) \u232a To compute the derivatives of \u03b8\u22c6j (\u03b1) we use the implicit function theorem and the assumption that the risks are strongly convex. We apply the implicit function theorem to the first order optimality condition\n\u03b8\u22c6j (\u03b1) \u2208 argmin \u03b8j R\u0304learnerj (\u03b1:,j , \u03b8j)\nThe Hessian \u22072\u03b8R\u0304learnerj (\u03b1,\u0398)) is non-degenerate due to strong convexity of the subpopulation risks. There exists a neighborhood U0 of \u03b1 and a unique (sufficiently smooth) map \u03b8\u2217j (\u00b7) such that for all \u03b1 \u2208 U0, we have that \u2207\u03b8R\u0304learnerj (\u03b1, \u03b8\u2217(\u03b1)) = 0. Then by implicit function theorem we obtain\n\u2207\u03b8\u22c6j (\u03b1) = \u2212\u22072\u03b8R\u0304learnerj \u25e6 \u2207\u03b1\u03b8R\u0304learnerj (\u03b1:,j , \u03b8\u22c6j (\u03b1))\nby taking the derivative of the first order condition differentiating through \u03b8\u22c6j (\u00b7) and setting it to zero. We have that\n\u22072\u03b8R\u0304learnerj = \u2211 \u2113\u2032 \u03b2\u2113\u2032\u03b1\u2113\u2032j\u22072R\u2113\u2032(\u03b8\u22c6j ), \u2202 \u2202\u03b1k\u2113 \u2207\u03b8R\u0304learnerj = { 0 k \u0338= j \u2207R\u2113(\u03b8eqj ) k = j .\nThe result follows by combining the expressions."
        },
        {
            "heading": "D Full Proofs of Main Results",
            "text": "D.1 Connections between dynamics and total risk\nProposition 3.2. Under any risk-reducing subpopulation and learner dynamics, the total risk is non-increasing \u2200t: Rtotal(\u03b1t+1,\u0398t+1) \u2264 Rtotal(\u03b1t,\u0398t). If subpopulations and learners are risk minimizing in the limit, then the total risk is strictly decreasing unless (\u03b1t,\u0398t) is a local minimizer.\nProof of Proposition 3.2. The key to seeing that the total risk acts like a potential for the market dynamics is to note two equivalent decompositions of the total risk:\nRtotal(\u03b1,\u0398) = \u03b2\u22a4R\u0304subpop(\u03b1,\u0398) = \u03b2\u22a4\u03b1R\u0304learner(\u03b1,\u0398) .\nBeing risk-reducing learners\u2019 updates satisfy:\nR\u0304learner(\u03b1t,\u0398t+1) \u2264 R\u0304learner(\u03b1t,\u0398t) =\u21d2 Rtotal(\u03b1t,\u0398t+1) \u2264 Rtotal(\u03b1t,\u0398t) .\nSimilarly risk reducing subpopulations satisfy:\nR\u0304subpop(\u03b1t+1,\u0398t+1) \u2264 R\u0304subpop(\u03b1t,\u0398t+1) =\u21d2 Rtotal(\u03b1t+1,\u0398t+1) \u2264 Rtotal(\u03b1t,\u0398t+1) .\nFinally, combining the two updates yields the desired inequality.\nIn the case that learners and subpopulations are risk minimizing in the limit, the same argument holds with strict inequality, unless (\u03b1t+1,\u0398t+1) is a local minimum.\nTheorem 3.3. For any learners and subpopulations who are risk minimizing in the limit, an equilibrium (\u03b1eq,\u0398eq) is asymptotically stable if it is an isolated local minimizer of the total risk Rtotal. If it is not a local minimizer of the total risk, then it is not stable.\nProof of Theorem 3.3. We break this proof into two implications.\n1. Isolated local min =\u21d2 Asymptotic stability Define V (\u03b1,\u0398) = Rtotal(\u03b1,\u0398)\u2212Rtotal(\u03b1eq,\u0398eq). The dynamics f are Lipschitz by Lemma C.2 and this V satisfies the conditions of Theorem C.3 with strict inequality, thus we conclude that (\u03b1eq,\u0398eq) is an asymptotically stable equilibrium.\n2. Not local min =\u21d2 Not stable Define V (\u03b1,\u0398) = Rtotal(\u03b1eq,\u0398eq)\u2212Rtotal(\u03b1,\u0398) which will increase along trajectories. Since we are not at a local min, there must be some arbitrarily close \u03b10,\u03980 such that V (\u03b1,\u0398) > 0. Then we apply Theorem C.4 which guarantees that the equilibrium is not stable.\nCorollary 3.4. Equilibria exist when learners and subpopulations are risk minimizing in the limit and the total risk function has isolated local minima. They may not exist otherwise.\nProof of Corollary 3.3. We first argue that if the dynamics are risk minimizing, then an isolated local minimum of the total risk must be an equilibria. Let (\u03b10,\u03980) denote the isolated local minima of the total risk. It must be that \u03b10 is an isolated, and thus unique, minimizer of Rtotal(\u03b1,\u03980) since the function is linear in \u03b1. We can thus conclude that \u03bd(\u03b10,\u03980) = \u03b10. It also must be that \u03980 is a unique minimizer of Rtotal(\u03b10,\u0398) since the function is convex in \u0398. We can thus conclude that \u00b5(\u03b10,\u03980) = \u03980. Therefore (\u03b10,\u03980) is equilibrium of the dynamics.\nWe next show that equilibria may not exist when the dynamics are not risk minimizing in the limit. To show that they may not exist otherwise, consider the following example. Let all learners be static and identical so \u0398t+1 = \u0398t and \u0398 = (\u03b8, \u03b8, . . . , \u03b8). Let the subpopulation update break ties among equivalent learners randomly. Then the subpopulations will randomly switch between learners. Though these dynamics satisfy the definition of risk reducing (at equality), they will not converge to an equilibrium.\nWe lastly show that equilibria may not exist when the total risk function does not have an isolated equilibrium. Suppose that learners update with full risk minimization and all subpopulations have risk uniquely minimized at the same value \u03b8. Finally suppose that subpopulations will break ties among equivalent learners randomly (and are otherwise risk minimizing). As in the previous example, the subpopulations will randomly switch between learners and no equilibrium exists."
        },
        {
            "heading": "D.2 Stable equilibria",
            "text": "Theorem 3.6. Suppose learners and subpopulations are risk minimizing in the limit, \u03b1eq is segmented, and Rtotal(\u03b1eq,\u0398) has a unique minimizer \u0398eq. Define a mapping \u03b3 : [n] \u2192 [m] such that \u03b3(i) = j is the learner with nonzero mass in \u03b1eqi,: . If every subpopulation strictly prefers their current learner:\nRi(\u03b8eq\u03b3(i)) < Ri(\u03b8 eq j ) , (1)\nfor all i and learners j \u0338= \u03b3(i), then (\u03b1eq,\u0398eq) is an asymptotically stable equilibrium. If there is a subpopulation who would strictly prefer to switch learners, then (\u03b1eq,\u0398eq) is not stable.\nProof of Theorem 3.6. First note that it must be that every learner is associated to at least one subpopulation. Otherwise, the total risk would not have a unique minimizer over \u0398.\nWe start with the first statement, and show that the stated conditions imply that (\u03b1eq,\u0398eq) is isolated local minimum of the total risk. By Theorem 3.3, this implies asymptotic stability.\nWe specifically argue the conditions are sufficient for guaranteeing an isolated local minimum with respect to F (\u03b1), appealing to Lemma C.8. First notice that we have the unique \u0398eq = argmin\u0398Rtotal(\u03b1eq,\u0398) as required. Suppose by contradiction that there is some perturbation to \u03b1 that causes F (\u03b1) to decrease or remain the same. Equivalently, the projection of the negative gradient onto the simplex points towards some other vertex, i.e. the component of the gradient in the direction of learner j is less than or equal to that in the direction of \u03b3(i) for some j \u0338= \u03b3(i). We can write this condition as\n\u2202F (\u03b1) \u2202\u03b1i\u03b3(i) \u2265 \u2202F (\u03b1) \u2202\u03b1ij \u21d0\u21d2 Ri(\u03b8eq\u03b3(i)) \u2265 Ri(\u03b8 eq j )\nwhere we use Lemma C.9. This violates the risk comparison condition (1), and therefore there must be no such perturbation, and thus \u03b1eq is an isolated local minimum.\nWe turn our attention to the second statement. Theorem 3.3, it is equivalent to argue about minima of the total risk function. Suppose that for some subpopulation, there is some learner for which Ri(\u03b8eq\u03b3(i)) > Ri(\u03b8 eq j ). Then any small perturbation of that subpopulations\u2019s allocation towards that learner will decrease the total risk, and thus the point is not a minimum.\nIn a segmented allocation, each \u03b8eqj will minimize the average loss over the group of subpopulations assigned to them. Denote the parameter which minimizes risk of subpopulation i as \u03d5i := argmin\u03b8\u2208Rd Ri(\u03b8). Then each \u03b8 eq j is a convex combination of \u03d5i for i in jth partition. Using this perspective, we provide an intuitive necessary (but not sufficient) condition for a class of symmetric risk functions.\nCorollary D.1. Suppose that risk functions satisfy Ri(\u03b8) < Ri(\u03b8\u2032) \u21d0\u21d2 \u2225\u03b8 \u2212 \u03d5i\u2225 < \u2225\u03b8\u2032 \u2212 \u03d5i\u2225 for \u03d5i the subpopulation optimal parameter. Then in an asymptotically stable segmented equilibrium, the convex hulls of the grouped subpopulations optimal parameters {\u03d5i} are non-intersecting.\nApplying this Corollary to the example in Figure 2, we see that a segmented equilibrium with subpopulation 1 and 3 participating in the same learner cannot be stable.\nProof of Corollary D.1. Let \u03d51, \u03d52, \u00b7 \u00b7 \u00b7 , \u03d5k \u2208 Rd be the optimal decisions for the subpopulations allocated to the first learner and \u03c81, \u03c82, \u00b7 \u00b7 \u00b7 , \u03c8l \u2208 Rd be the optimal decisions for the subpopulations allocated to the second learner. Let \u03b81 and \u03b82 be the decisions of each learner. Assume that the convex hulls of {\u03d5i}ki=1 and {\u03c8}li=1 intersect. By Lemma C.7, there exists i such that \u2225\u03d5i \u2212 \u03b82\u2225 \u2264 \u2225\u03d5i \u2212 \u03b81\u2225. By the assumption about the risk runctions, this implies Ri(\u03b82) < Ri(\u03b81). In other words, there exist a subpopulation that would prefer to switch learners. Thus by Theorem 3.6 these allocation of subpopulations to learner is not stable and so the convex hulls must not intersect.\nTheorem 3.7. Consider dynamics which are risk minimizing in the limit and an \u03b1eq with any subpopulation i having nonzero support on set of two or more learners j \u2208 J . Assume risks are strongly convex and define \u0398eq = argminRtotal(\u03b1eq,\u0398). Then (\u03b1eq,\u0398eq) cannot be stable unless it is \u201cbalanced\u201d in the sense that learners in J are risk equivalent and optimal for i, i.e. for all j, j\u2032 \u2208 J ,\nRi(\u03b8eqj ) = Ri(\u03b8 eq j\u2032 ) and \u2207Ri(\u03b8 eq j ) = 0 .\nIf it is balanced, so are all allocations for subpopulation i with support over J . Finally, all stable equilibria must be either balanced or segmented.\nProof of Theorem 3.7. Theorem 3.3 shows that an equilibrium cannot be stable if it is not a local minimum of the total risk. We therefore develop conditions under which an equilibrium point will be a local minimum. By Lemma C.8, it is equivalent to argue about the local minima of the concave function F (\u03b1) over the simplex product \u2206nm. All minima of the total risk will occur on the boundary of the simplex product, i.e. a face or a vertex. Since F is still concave when restricted to a face of the simplex, the same argument shows the minima are on the boundary, hence vertices, except for the degenerate case where F takes a constant value over the face.\nWe now characterize this degenerate case. F takes a constant value over the face if and only if 1) the gradient of F is perpendicular to the face at \u03b1 and 2) remains perpendicular along the face. The face is described by a set of indices J \u2286 [m]. Mathematically, we write the two conditions as: for all pairs j, j\u2032 \u2208 J , \u2113 \u2208 [n], and k \u2208 [m],\n\u2202F (\u03b1) \u2202\u03b1ij = \u2202F (\u03b1) \u2202\u03b1ij\u2032 and\n\u2202\n\u2202\u03b1\u2113k\n( \u2202F (\u03b1)\n\u2202\u03b1ij \u2212 \u2202F (\u03b1) \u2202\u03b1ij\u2032\n) = 0 (4)\nUsing Lemma C.8, the first expression simplifies to the risk equivalent condition that Ri(\u03b8eqj ) = Ri(\u03b8eqj\u2032 ). Turning to the second expression in (4), we first use Lemma C.9 to compute\n\u2202\n\u2202\u03b1\u2113k\n\u2202F (\u03b1)\n\u2202\u03b1ij = { 0 k \u0338= j \u2212\u03b2i\u2207Ri(\u03b8eqj )\u22a4 (\u2211 \u2113\u2032 \u03b2\u2113\u2032\u03b1\u2113\u2032j\u22072R\u2113\u2032(\u03b8 eq j ) ) \u2207R\u2113(\u03b8eqj ) k = j\nThus, the condition trivially holds for k /\u2208 {j, j\u2032}. Otherwise, when \u2113 = i, the condition in (4) requires that\n\u2207Ri(\u03b8eqk ) \u22a4 (\u2211 \u2113\u2032 \u03b2\u2113\u2032\u03b1\u2113\u2032k\u22072R\u2113\u2032(\u03b8eqk ) ) \u2207Ri(\u03b8eqk ) = 0, k \u2208 {j, j \u2032}\nDue to the strong convexity of the risks, the Hessian matrix is positive definite. Thus it must be that \u2207Ri(\u03b8eqj ) = 0 for all j \u2208 J , i.e. the risk optimal condition. Risk optimality implies that the condition holds also when \u2113 \u0338= i and thus the characterization is complete."
        },
        {
            "heading": "D.3 Social Welfare",
            "text": "Proof of Proposition 3.9. Social welfare is non-decreasing (or increasing) if and only if total risk is non-increasing (or decreasing), as guaranteed by Proposition 3.2. Maxima of the social welfare are equivalent to minima of the total risk and therefore the connections to stable equilibria follow by Theorem 3.3.\nProof of Proposition 3.10. By construction (\u03b1\u0303eq, \u0398\u0303eq) is not segmented, and neither is it a stable balanced equilibrium (by the non-optimality assumption). Therefore, it is not stable (Theorem 3.7), and thus not a local minimum of the total risk (Theorem 3.3). A perturbation will thus send the system along a risk-reducing trajectory."
        },
        {
            "heading": "E Detailed Examples",
            "text": ""
        },
        {
            "heading": "E.1 Risk Reducing and Minimizing Dynamics",
            "text": "Proposition 2.2. A subpopulation i updating their participation with multiplicative weights is risk minimizing in the limit as long as \u03b3 > 0 and \u03b10ij > 0 for all j. A learner j updating its parameter with gradient descent is risk minimizing in the limit when the risk functions Ri(\u03b8) are L smooth and the step size satisfies \u03b3t < 2L , \u2211\u221e t=0 \u03b3 t = \u221e, and \u2211\u221e t=1(\u03b3 t)2 <\u221e.\nProof. To see that the subpopulation is risk minimizing, first see that\nR\u0304subpopi ( \u03b1t+1i,: ,\u0398 ) = m\u2211 j=1 \u03b1t+1ij Ri(\u03b8j)\n= m\u2211 j=1 \u03b1tij \u00b7 exp(\u2212\u03b3Ri(\u03b8j))\u2211m j=1 \u03b1 t ij \u00b7 exp(\u2212\u03b3Ri(\u03b8j)) Ri(\u03b8j)\n< m\u2211 j=1 \u03b1tijRi(\u03b8j) = R\u0304 subpop i ( \u03b1ti,:,\u0398 ) where the strict inequality holds as long as \u03b1tij is not on the boundary of the simplex. Second, observe that for a fixed \u0398, \u03b1tij \u2192 1 if and only if Ri(\u03b8j) is minimal over all learners for which \u03b10ij > 0.\nTo see that the learner is risk minimizing, notice that the gradient update is equivalently\n\u03b8t+1j = \u03b8 t j \u2212 \u03b3t\u2207\u03b8R\u0304learnerj (\u03b1:,j , \u03b8j) .\nGradient descent on an L-smooth and convex function leads to strictly decreasing objective values when \u03b8tj is not at a minimum and the step size satisfies \u03b3\nt < 2L . It further converges to a minimum in the limit as long as the step size satisfies the Robbins-Munroe condition (see, e.g. (Liu and Yuan, 2022; Orabona, 2020)).\nExample E.1 (Semi-static participation). Suppose a population has a constant allocation of 20% to one learner, while the remaining 80% is allocated to the remaining learners inversely proportional to the learner\u2019s risk on that population. This is risk reducing but not risk minimizing in the limit.\nExample E.2 (Shifting to lower-risk models). If a subpopulation\u2019s allocation updates always shift allocation from learners with high subpopulation risk to learners with lower subpopulation risk, then the allocation is risk reducing. It may or may not be risk minimizing in the limit.\nExample E.3 (Allocations determined by gradient descent). Consider an allocation determined by (projected) gradient descent with respect to a subpopulation\u2019s average risk. This is risk-reducing, and may be risk minimizing in the limit depending on the step-size.\nExample E.4 (Full risk minimization). Suppose that a learner updates its parameter to minimize the average risk function R\u0304learnerj (\u03b1t:,j , \u00b7) at each timestep. This has been studied as repeated retraining dynamics in the single learner case by Hashimoto et al. (2018); Perdomo et al. (2020)."
        },
        {
            "heading": "E.2 Stability",
            "text": "To illustrate the subtleties of determining stability when the total risk function has non-isolated local minima, we consider a setting with n = m = 2 subpopulations and learners where R1(\u03b8) = R2(\u03b8) = \u03b82. Then the total risk function is minimized for any \u03b1 \u2208 \u2206nm and \u0398 = (0, 0). This continuum of minima can contain equilibria of risk minimizing dynamics, and those equilibria may be stable, asymptotically stable, or unstable, which we illustrate with the following examples.\nExample E.5 (Continuum of stable balanced markets). Suppose that subpopulations update their allocation via any Lipschitz continuous risk minimizing update rule which is stationary whenever learners are risk equivalent (i.e. Ri(\u03b81) = Ri(\u03b82)). Suppose that learners update via full risk minimization. Then equilibria will have the form (\u03b1eq, (0, 0)) for any \u03b1eq \u2208 \u220622.\nThen starting from any (\u03b10,\u03980) with a \u03b4\u03b1, \u03b4\u03b8 ball of any equilibrium (\u03b1eq,\u0398eq),\n\u03b11 = \u03bd(\u03b10,\u03980), \u03981 = (0, 0)\nat which point the system is in a new equilibrium, since any allocation \u03b1 is a fixed point when \u0398 = (0, 0) so \u03b1t = \u03b11 and \u0398t = \u03981 for all t. We have that \u2225\u0398eq \u2212\u03980\u2225 = 0 and\n\u2225\u03b1eq \u2212 \u03b11\u2225 = \u2225\u03bd(\u03b1eq,\u0398eq)\u2212 \u03bd(\u03b10,\u03980)\u2225\nBy the assumption of Lipschitzness, this distance will scale linearly in \u03b4\u03b1, \u03b4\u03b8 so the definition of stability is satisfied for \u03b4 chosen proportionally to \u03f5 depending on the Lipschitz constant of \u03bd.\nIn this example, any perturbation converges to a new fixed point within one time step. The continuity of the update functions ensures that the new fixed point is within a bounded distance of the original, satisfying the definition of stability. This example is not asymptotically stable: the allocation does not convergence back to the original point.\nExample E.6 (Asymptotically stable segmentation). Consider the subpopulation and learner update rules as in the prior example, with one amendment. When Ri(\u03b81) = Ri(\u03b82), subpopulation 1 re-allocates half of its mass from learner 2 to learner 1, and while subpopulation 2 re-allocates half its mass from learner 1 to learner 2. Thus the subpopulation update can be written as\n\u03b1t+11,: =  \u03bd1(\u03b1 t 1,:,\u0398 t) R1(\u03b81) \u0338= R1(\u03b82)[ 1 1/2\n0 1/2\n] \u03b1t1,: R1(\u03b81) = R1(\u03b82) , \u03b1t+12,: =  \u03bd2(\u03b1 t 2,:,\u0398 t) R2(\u03b81) \u0338= R2(\u03b82)[ 0 1/2\n1 1/2\n] \u03b1t+12,: R2(\u03b81) = R2(\u03b82)\nThe only equilibrium has \u03b1eq segmented with subpopulation i associated to learner i for i = 1, 2 and \u0398eq = (0, 0). It is straightforward to see that this is an asymptotically stable equilibrium, since for any a \u2208 \u22062,\nlim t\u2192\u221e [ 1 1/2 0 1/2 ]t a = [ 1 1 0 0 ] a = [ 1 0 ] and lim t\u2192\u221e [ 0 1/2 1 1/2 ]t a = [ 0 0 1 1 ] a = [ 0 1 ] .\nExample E.7 (Asymptotically stable balanced market). Consider a setting similar to the previous example except that when Ri(\u03b81) = Ri(\u03b82), subpopulation i moves half the mass from group 1 to group 2 and half the mass from group 2 to group 1 for all i. Then the subpopulation update can be written as\n\u03b1t+11,: =  \u03bd1(\u03b1 t 1,:,\u0398 t) R1(\u03b81) \u0338= R1(\u03b82)[ 1/2 1/2\n1/2 1/2\n] \u03b1t1,: R1(\u03b81) = R1(\u03b82) , \u03b1t+12,: =  \u03bd2(\u03b1 t 2,:,\u0398 t) R2(\u03b81) \u0338= R2(\u03b82)[ 1/2 1/2\n1/2 1/2\n] \u03b1t+12,: R2(\u03b81) = R2(\u03b82)\nThe only equilibrium has \u03b1eqi,: = [1/2, 1/2] for i = 1, 2 and \u0398 eq = (0, 0). It is straightforward to see that this is an asymptotically stable equilibrium, since for any a \u2208 \u22062,\nlim t\u2192\u221e [ 1/2 1/2 1/2 1/2 ]t a = [ 1/2 1/2 1/2 1/2 ] a = [ 1/2 1/2 ] .\nExample E.8 (Unstable balanced market). Suppose that subpopulation allocations follow a projected gradient descent update for all i:\n\u03b1t+1i1 = Proj[0,1] ( \u03b1ti1 \u2212 \u03b3(Ri(\u03b81)\u2212Ri(\u03b82)) ) and \u03b1i2 = 1\u2212 \u03b1i1. Further suppose learners update with gradient descent:\n\u03b8t+1j = \u03b8 t j \u2212\n1\n2 \u221a t \u2207R\u0304learnerj (\u03b1t:,j , \u03b8tj) =\n\u221a t\nt+ 1 \u03b8tj\nBoth rules are risk minimizing in the limit (note that \u03b8tj = 1\u221a t \u03b80j ) and have a continuum of equilibria at any \u03b1eq \u2208 \u2206nm and \u0398eq = (0, 0). However, we show that the equilibria are not stable. Consider the initial condition (\u03b1eq, (\u03b4\u03b8, 0)). We have that\n\u03b1t+1i1 = Proj[0,1] ( \u03b10i1 \u2212 \u03b3\u03b42\u03b8 t\u2211 k=1 1 k ) \u2192 0 as t\u2192 \u221e.\nNo matter how small the perturbation \u03b4\u03b8 is, the summation increases with t and participation will converge all weight to learner 2. A similar argument shows that perturbations exist that will send all participation to learner 1.\nIn this example, the learners update slowly. Despite eventual convergence to the minimizing parameter, the accumulating error causes the participation allocation to shift completely to the unperturbed learner, precluding stability."
        },
        {
            "heading": "E.3 Social Welfare",
            "text": "We begin with a somewhat generic example with m = 2 and n = 3 that illustrates the difference between stable equilibria and social welfare optima.\nExample E.9 (Stability vs. optimality). Consider three subpopulations i \u2208 {1, 2, 3} with risks \u2225\u03b8\u2212\u03d5i\u222522, sizes \u03b2i, and two learners j \u2208 {1, 2}. Suppose that the \u03b1eq is such that the subpopulations are partitioned into {1} and {2, 3}. Then we have that\n\u03b8eq1 = \u03d51, \u03b8 eq 2 = \u03b22 \u03b22 + \u03b23 \u03d52 + \u03b23 \u03b22 + \u03b23 \u03d53\nBy Theorem 3.6, this is stable if and only if \u2225\u03d52 \u2212 \u03d53\u22252 \u2264 (\u03b22 + \u03b23)min { \u2225\u03d52 \u2212 \u03d51\u22252\n\u03b23 , \u2225\u03d53 \u2212 \u03d51\u22252 \u03b22\n} .\nHowever, it is only social optimal if and only if \u03d52 and \u03d53 are relatively close to each other than to \u03d51, i.e. \u2225\u03d52 \u2212 \u03d53\u22252 \u2264 min {\u2225\u03d52 \u2212 \u03d51\u22252, \u2225\u03d53 \u2212 \u03d51\u22252} . The set of subpopulation optima {\u03d51, \u03d52, \u03d53} satisfying the optimality condition are a subset of those satisfying the stability condition. As the difference between \u03b22 and \u03b23 becomes more extreme, the number of settings satisfying the stability but not optimality condition increases.\nWe use this generic example to illustrate a scenario in which the total risk can be arbitrarily high at a stable equilibria.\nExample E.10 (Arbitrarily high total risk at local optimum). Consider three subpopulations with\nR1(\u03b8) = \u03b82, R2(\u03b8) = (\u03b8 \u2212 1)2, R2(\u03b8) = (\u03b8 \u2212 \u03d5)2\nfor some \u03d5 > 2. Suppose that subpopulation sizes are \u03b21 = \u03b22 = \u03b2 and \u03b23 = 1 \u2212 2\u03b2 for some 0 < \u03b2 < 1/2. Further suppose that there are two learners. Up to permutation, the social welfare optimum is \u03b81 = 1/2 and \u03b82 = \u03d5, with total risk \u03b2/2. However, as long as \u03d5 < 1\u2212\u03b21\u22122\u03b2 , there is another stable equilibrium. Let \u03d5 = 1\u2212\u03b21\u22122\u03b2 \u2212 \u03f5. Then the following is a stable equilibrium: \u03b81 = 0 and \u03b82 = 1\u2212 \u03f5. The total risk is \u03b2 + (\u03b2\u2212\u03f5) 2\n1\u22122\u03b2 . For \u03b2 close to 1/2, this risk can be arbitrarily larger than the social optimum.\nExample E.11. Suppose there are two learners and three subpopulations with sizes \u03b21 = \u03b22 = \u03b2 and \u03b23 = 1 \u2212 2\u03b2 for some 0 < \u03b2 < 1/2. Consider the following: R1(\u03b8) = \u03b82, R2(\u03b8) = (\u03b8 \u2212 1)2, R2(\u03b8) = (\u03b8\u2212 1\u2212\u03b21\u22122\u03b2 + \u03f5)\n2. The social welfare optimizing decision \u0398\u22c6 = (1/2, 1\u2212\u03b21\u22122\u03b2 \u2212 \u03f5) corresponds to total risk \u03b2/2. However, there is a stable equilibrium at \u0398eq = (0, 1 + \u03f5) with total risk \u03b2 + (\u03b2\u2212\u03f5) 2\n1\u22122\u03b2 . For \u03b2 \u2192 1/2, the gap becomes arbitrarily large.\nFinally, we present an example which illustrates that even in the single learner setting, the risk of a subpopulation can be arbitrarily worse than the total risk.\nExample E.12 (Arbitrarily high risk for minority subpopulation). Consider two subpopulations with R1(\u03b8) = \u03b82 and R2(\u03b8) = (\u03b8 \u2212 \u03d5)2 with \u03b21 = \u03b2 and \u03b22 = 1\u2212 \u03b2 and a single learner. The single equilibrium and total risk minimizer is \u03b81 = (1\u2212 \u03b2)\u03d5 with total risk \u03b2(1\u2212 \u03b2)\u03d52 and R2(\u03b8\u22c6) = \u03b22\u03d52. The difference between the two quantities can be arbitrarily high as \u03b2 gets close to 1."
        },
        {
            "heading": "F Experimental Details",
            "text": "Full experimental details along with instructions for reproducing them can be found at https: //github.com/mcurmei627/MultiPlayerRiskReduction. The experiments used Python 3.9 on a MacBook Pro 2019."
        }
    ],
    "title": "Emergent segmentation from participation dynamics and multi-learner retraining",
    "year": 2023
}