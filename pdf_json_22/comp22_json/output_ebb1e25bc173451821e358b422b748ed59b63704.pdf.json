{
    "abstractText": "In automated planning the ability of expressing constraints on the structure of the desired plans is important to deal with solution quality, as well as to express control knowledge. In PDDL3 this is supported through state-trajectory constraints corresponding to a class of LTLf formulae. In this paper, first we introduce a formalism to express trajectory constraints over actions in the plan, rather than over traversed states; the new class of constraints retains the same temporal modal operators of PDDL3, and adds two useful modalities. Then we investigate compilation-based methods to deal with action-trajectory constraints in propositional planning, and propose a new simple effective method. Finally, we experimentally study the usefulness of our action-trajectory constraints as a tool to express control knowledge. The experimental results show that the performance of a classical planner can be significantly improved by exploiting knowledge expressed by action constraints and handled by our compilation, while the same knowledge turns out to be less beneficial when specified as state constraints and handled by two state-of-theart systems supporting state constraints.",
    "authors": [
        {
            "affiliations": [],
            "name": "Luigi Bonassi"
        },
        {
            "affiliations": [],
            "name": "Alfonso Emilio Gerevini"
        }
    ],
    "id": "SP:4b27478e45f7d34480b28ea87d079a8e535320dd",
    "references": [
        {
            "authors": [
                "Jorge A. Baier",
                "Sheila A. McIlraith. Planning with first-order temporally extended goals using heuristic search. In AAAI"
            ],
            "title": "pages 788\u2013795",
            "venue": "AAAI Press,",
            "year": 2006
        },
        {
            "authors": [
                "Jorge A. Baier",
                "Christian Fritz",
                "Meghyn Bienvenu",
                "Sheila A. McIlraith"
            ],
            "title": "Beyond classical planning: Procedural control knowledge and preferences in state-of-the-art planners",
            "venue": "AAAI, pages 1509\u20131512. AAAI Press,",
            "year": 2008
        },
        {
            "authors": [
                "Meghyn Bienvenu",
                "Christian Fritz",
                "Sheila A. McIlraith. Specifying",
                "computing preferred plans"
            ],
            "title": "Artif",
            "venue": "Intell., 175(7-8):1308\u20131345,",
            "year": 2011
        },
        {
            "authors": [
                "Luigi Bonassi",
                "Alfonso Emilio Gerevini",
                "Francesco Percassi",
                "Enrico Scala"
            ],
            "title": "On planning with qualitative state-trajectory constraints in PDDL3 by compiling them away",
            "venue": "ICAPS, pages 46\u201350. AAAI Press,",
            "year": 2021
        },
        {
            "authors": [
                "Blai Bonet",
                "Hector Geffner. General policies"
            ],
            "title": "representations",
            "venue": "and planning width. In AAAI, pages 11764\u201311773. AAAI Press,",
            "year": 2021
        },
        {
            "authors": [
                "Adi Botea",
                "Markus Enzenberger",
                "Martin M\u00fcller",
                "Jonathan Schaeffer"
            ],
            "title": "Macro-ff: Improving AI planning with automatically learned macro-operators",
            "venue": "J. Artif. Intell. Res., 24:581\u2013621,",
            "year": 2005
        },
        {
            "authors": [
                "Kutluhan Erol",
                "James A. Hendler",
                "Dana S. Nau"
            ],
            "title": "HTN planning: Complexity and expressivity",
            "venue": "AAAI, pages 1123\u20131128. AAAI Press / The MIT Press,",
            "year": 1994
        },
        {
            "authors": [
                "Fox",
                "Long",
                "2003] Maria Fox",
                "Derek Long"
            ],
            "title": "PDDL2.1: an extension to PDDL for expressing temporal planning domains",
            "venue": "J. Artif. Intell. Res.,",
            "year": 2003
        },
        {
            "authors": [
                "Alfonso Gerevini",
                "Patrik Haslum",
                "Derek Long",
                "Alessandro Saetti",
                "Yannis Dimopoulos"
            ],
            "title": "Deterministic planning in the fifth international planning competition: PDDL3 and experimental evaluation of the planners",
            "venue": "Artif. Intell., 173(5-6):619\u2013668,",
            "year": 2009
        },
        {
            "authors": [
                "Giuseppe De Giacomo",
                "Moshe Y. Vardi. Linear temporal logic",
                "linear dynamic logic on finite traces. In IJCAI"
            ],
            "title": "pages 854\u2013860",
            "venue": "IJCAI/AAAI,",
            "year": 2013
        },
        {
            "authors": [
                "Giuseppe De Giacomo",
                "Riccardo De Masellis",
                "Marco Montali"
            ],
            "title": "Reasoning on LTL on finite traces: Insensitivity to infiniteness",
            "venue": "AAAI, pages 1027\u2013 1033. AAAI Press,",
            "year": 2014
        },
        {
            "authors": [
                "Nir Lipovetzky",
                "Hector Geffner. Width",
                "serialization of classical planning problems. In ECAI"
            ],
            "title": "volume 242 of Frontiers in Artificial Intelligence and Applications",
            "venue": "pages 540\u2013545. IOS Press,",
            "year": 2012
        },
        {
            "authors": [
                "Andrea Micheli",
                "Enrico Scala. Temporal planning with temporal metric trajectory constraints. In AAAI"
            ],
            "title": "pages 7675\u20137682",
            "venue": "AAAI Press,",
            "year": 2019
        },
        {
            "authors": [
                "Francesco Percassi",
                "Alfonso Emilio Gerevini"
            ],
            "title": "On compiling away PDDL3 soft trajectory constraints without using automata",
            "venue": "ICAPS, pages 320\u2013328. AAAI Press,",
            "year": 2019
        },
        {
            "authors": [
                "Amir Pnueli. The temporal logic of programs. In FOCS"
            ],
            "title": "pages 46\u201357",
            "venue": "IEEE Computer Society,",
            "year": 1977
        },
        {
            "authors": [
                "T Ramesh"
            ],
            "title": "Traveling purchaser problem",
            "venue": "Opsearch, 18(1-3):78\u201391",
            "year": 1981
        },
        {
            "authors": [
                "Silvia Richter",
                "Matthias Westphal"
            ],
            "title": "The LAMA planner: Guiding cost-based anytime planning with landmarks",
            "venue": "J. Artif. Intell. Res., 39:127\u2013177,",
            "year": 2010
        },
        {
            "authors": [
                "Shirin Sohrabi",
                "Jorge A. Baier",
                "Sheila A. McIlraith. HTN planning with preferences"
            ],
            "title": "In IJCAI",
            "venue": "pages 1790\u20131797,",
            "year": 2009
        },
        {
            "authors": [
                "Jorge Torres",
                "Jorge A. Baier. Polynomial-time reformulations of LTL temporally extended goals into final-state goals. In IJCAI"
            ],
            "title": "pages 1696\u2013 1703",
            "venue": "AAAI Press,",
            "year": 2015
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "In automated planning temporal extended goals are constraints over the state trajectory of a plan that can be used to express desired properties of the solutions for a planning problem or domain control knowledge aimed at helping the planner. Linear Temporal Logic over finite traces (LTLf ) [Pnueli, 1977; Giacomo et al., 2014] and PDDL3 [Gerevini et al., 2009] are two of the most popular languages used to formulate such constraints in domain-independent planning.\nIn this paper, similarly to what done in [Bienvenu et al., 2011], we study an alternative way of expressing plan constraints and control knowledge through constraints over trajectories of actions rather than states, and we propose a new simple formalism extending classical planning with such constraints. For instance, in a logistics domain, for a planning problem we could request that a certain truck should drive\nfrom city1 to city2 during its journey, or that it should be refueled before driving.\nAction-trajectory constraints (hereinafter called action constraints) cannot be easily and naturally expressed using state-trajectory constraints (hereinafter state constraints). This requires that the domain is carefully modified by introducing additional fluents and revising the action models, for each problem in the domain that has different action constraints.1 On the contrary, to formulate action constraints we do not have to know how states and actions are modeled: we just need to use the labels of the (instantiated) actions and relate them via a temporal modal operator. Moreover, since action constraints are independent from the state representation, they could also be used with a more complex state representation, such as in numeric planning [Fox and Long, 2003].\nThe proposed language to express action constraints retains the same temporal modal operators of PDDL3, and adds two useful modalities (always-next and pattern). The language was designed with the purpose of expressing useful knowledge without incurring in significant computational overheads to handle it at planning time.\nAfter introducing classical planning enriched with action constraints (PAC), we investigate compilation-based methods to deal with action constraints in PAC planning, and propose a new effective method. Our method not only is polynomial, but it also generates a compiled problem that has solutions with exactly the same length of the solutions for the original problem. This is an advantage over other existing formalisms for expressing control knowledge in planning, such as those based on LTLf , that need more complex and costly compilations or increase the length of the compiled plans [Torres and Baier, 2015; Bienvenu et al., 2011; Baier et al., 2008].\nThen we experimentally study the usefulness of action constraints as a tool to express control knowledge and plan quality. The experimental results show that the performance of a classical planner can be significantly improved by exploiting knowledge expressed by action constraints and handled by our compilation method, while the same knowledge turns out to be less beneficial when formulated as state constraints\n1E.g., stating (sometime(at truck1 city2)) in PDDL3 does not work to simply request that the truck should drive from city1 to city2, if in the domain the truck can reach city2 from more cities.\nand handled by two state-of-the-art systems supporting state constraints [Baier and McIlraith, 2006; Bonassi et al., 2021].\nThe rest of the paper is organised as follows: Section 2 introduces PAC; Section 3 shows how action constraints can be compiled away in classical planning; Section 4 presents our experimental analysis; Section 5 briefly comments on related work; finally Section 6 gives the conclusions."
        },
        {
            "heading": "2 Classical Planning with Action Constraints",
            "text": "A classical planning problem is a tuple \u03a0 = \u3008F,A, I,G\u3009 where F is a set of atoms, I \u2286 F is the initial state, G is a formula over F , and A is a set of actions. An action a \u2208 A is a pair \u3008Pre(a),Eff(a)\u3009, where Pre(a) is a formula over F expressing the preconditions of a, and Eff(a) is a set of conditional effects, each of the form c . e, where c is a formula and e is a set of literals, both over F . With e\u2212 and e+ we indicate the partition of e featuring only negative and positive literals, respectively. A state s is a subset of F , with the meaning that if p \u2208 s, then p is true in s, and if p /\u2208 s, p is false in s. An action is applicable in s if s |= Pre(a), and the application of an action a in s yields the state s\u2032 = (s \\\n\u22c3 c.e\u2208Eff(a) with s|=c e\u2212) \u222a \u22c3 c.e\u2208Eff(a) with s|=c e+. We indicate\nwith s[a] the state resulting from applying action a in s, and, with a little abuse of notation, we write a conditional effect of the form > . e as a simple unconditional effect e. A plan \u03c0 for a problem \u03a0 = \u3008F,A, I,G\u3009 is a sequence of actions \u3008a1, a2, . . . , an\u3009 from A; \u03c0 is valid for \u03a0 (a solution) iff the sequence \u3008s1 = I, s2 = s1[a1], . . . , sn+1 = sn[an]\u3009 of states (state trajectory) is such that \u2200 i \u2208 [1, . . . , n] si |= Pre(ai), and sn+1 |= G. We denote with |\u03c0| the length of plan \u03c0, and with \u03c0(t) the t-th action of \u03c0.\nThe following definition formalizes the semantics of a formula \u03c6 in Negation Normal Form (NNF) defined over a set A of actions, intended as the set of atoms formed by the labels naming the actions in A.\nDefinition 1. LetA be a set of actions of a planning problem. Given a plan \u03c0, an action formula \u03c6 defined over A written in NNF is true at time t in \u03c0, i.e. \u03c0(t) satisfies \u03c6, iff:\n\u2022 If \u03c6 = a then \u03c0(t) = a.\n\u2022 If \u03c6 = \u00aca then \u03c0(t) 6= a. \u2022 If \u03c6 = \u03c81 \u2227 \u03c82 with \u03c81 and \u03c82 action formulae over A,\nthen \u03c0(t) satisfies \u03c81 and \u03c0(t) satisfies \u03c82.\n\u2022 If \u03c6 = \u03c81 \u2228 \u03c82 with \u03c81 and \u03c82 action formulae over A, then \u03c0(t) satisfies \u03c81 or \u03c0(t) satisfies \u03c82.\nIn a sequential plan, exactly one action is executed at each time step. I.e., given a plan formed by a set of actions {a1, a2, . . . , an}, the following formulae over the action atoms hold for t = 1 . . . |\u03c0|: \u03c0(t) = ai \u21d2 \u03c0(t) 6= aj , \u2200j \u2208 {1 . . . n}, j 6= i \u03c0(t) = a1 \u2228 \u03c0(t) = a2 \u2228 . . . \u2228 \u03c0(t) = an. Due to these properties of a sequential plan, there is only a restricted class of relevant formulae over action literals. For instance, action formula a1 \u2228\u00aca2 can be rewritten as the disjunction of all action names (atoms) of a planning problem\ndifferent from a2. This is because, for every time step of a plan, the execution of any action except a2 satisfies the formula. Another example is \u00aca1 \u2227 a2. Such formula is equivalent to a2, since a2 is the only action satisfying \u00aca1 \u2227 a2.\nIn general, it can be proven that for a sequential plan every action formula can be rewritten as an equivalent formula \u03c6 that is either a disjunction of positive action literals, > or \u22a5. An action atom a satisfies a disjunction of positive literals \u03c6 if a is a disjunct of \u03c6, and we denote this by a \u2208 \u03c6 (analogously, a 6\u2208 \u03c6 denotes that a is not a disjunct of \u03c6). In the rest of the paper, we assume that all action formulae are rewritten as disjunctions of positive literals. If a formula is equivalent to > (resp. \u22a5), we can rewrite it as the disjunction of all action atoms of the planning problem (resp. the empty disjunction).\nWe introduce action constraints as a class of temporal logic formulae over a sequence \u03c0 of actions. Such constraints use the same modal operators of the qualitative state constraints in PDDL3, except for the additional operators always-next and pattern. Specifically, they can be of the following types (where \u03c6 and \u03c8 are action formulae): (always \u03c6), shortened as A\u03c6, requires that only actions that satisfy \u03c6 are in \u03c0; (sometime \u03c6), shortened as ST\u03c6, requires that at least one action satisfying \u03c6 is in \u03c0; (at-most-once \u03c6), shortened as AO\u03c6, requires that an action satisfying \u03c6 can appear in \u03c0 only if no action satisfying \u03c6 is in \u03c0 before; (sometime-before \u03c6 \u03c8), shortened as SB\u03c6,\u03c8 , requires that if an action satisfying \u03c6 appears in \u03c0 at a time t, then an action satisfying \u03c8 is in \u03c0 at a time before t; (sometime-after \u03c6 \u03c8), shortened as SA\u03c6,\u03c8 , requires that if an action satisfying \u03c6 is in \u03c0 at a time t, then an action that satisfies \u03c8 is in \u03c0 at a time after t; (always-next \u03c6 \u03c8), shortened as AX\u03c6,\u03c8 , requires that if an action satisfying \u03c6 is in \u03c0, then it is immediately followed by an action satisfying \u03c8;2 (pattern \u03c61 . . . \u03c6k), shortened as PA\u03c61...\u03c6k , requires that, for i = 1 . . . k \u2212 1, there exists an action in \u03c0 satisfying \u03c6i followed at some later time by an action satisfying \u03c6i+1.\nDefinition 2. Given a plan \u03c0 = \u3008a1, a2, . . . , an\u3009, the following rules define when an action constraint is satisfied by \u03c0:\n\u03c0 satisfies (always \u03c6) iff \u2200t : 1 \u2264 t \u2264 |\u03c0| \u00b7 \u03c0(t) \u2208 \u03c6 \u03c0 satisfies (sometime \u03c6) iff \u2203t : 1 \u2264 t \u2264 |\u03c0| \u00b7 \u03c0(t) \u2208 \u03c6 \u03c0 satisfies (at-most-once \u03c6) iff \u2200t1 : 1 \u2264 t1 \u2264 |\u03c0| \u00b7 if \u03c0(t1) \u2208 \u03c6 then \u2200t2 : t1 < t2 \u2264 |\u03c0| \u00b7 \u03c0(t2) 6\u2208 \u03c6 \u03c0 satisfies (sometime-after \u03c6 \u03c8) iff \u2200t1 : 1 \u2264 t1 \u2264 |\u03c0| \u00b7 if \u03c0(t1) \u2208 \u03c6 then \u2203t2 : t1 \u2264 t2 \u2264 |\u03c0| \u00b7 \u03c0(t2) \u2208 \u03c8 \u03c0 satisfies (sometime-before \u03c6 \u03c8) iff \u2200t1 : 1 \u2264 t1 \u2264 |\u03c0| \u00b7 if \u03c0(t1) \u2208 \u03c6 then \u2203t2 : 1 \u2264 t2 < t1 \u00b7 \u03c0(t2) \u2208 \u03c8 \u03c0 satisfies (always-next \u03c6 \u03c8) iff \u2200t : 1 \u2264 t < |\u03c0| \u00b7 if \u03c0(t) \u2208 \u03c6\nthen \u03c0(t+ 1) \u2208 \u03c8 and \u03c0(|\u03c0|) 6\u2208 \u03c6 \u03c0 satisfies (pattern \u03c61 . . . \u03c6k) iff \u2203 a sequence of actions \u3008a1, . . . , ak\u3009 from\n\u03c0 that are ordered as in \u03c0, such that \u2200i \u2208 {1, . . . , k} ai \u2208 \u03c6i.\nWe call PAC the class of classical planning problems enriched with action constraints.\n2This constraint can express some complex valid action sequences. E.g., AXa,a\u2228b accepts plans with any number of consecutive a\u2019s repetitions, if this sequence terminates with action b.\nDefinition 3. A classical planning problem with action constraints (a PAC problem) is a tuple \u3008\u03a0, C\u3009 where \u03a0 is a classical planning problem and C is a set of action constraints.\nThe valid plans of \u3008\u03a0, C\u3009 are the valid plans of \u03a0 that satisfy all constraints in C. PAC allows the definition of action constraints that cannot be captured by using state constraints. Indeed, the same sequence (trajectory) of states can be generated by different sequences (trajectories) of actions. Therefore, in general, it is not possible to distinguish the different action trajectories by constraints over the state trajectory only. For instance, consider a problem where the set of actions A is {a1, a2, a3} with a1 = \u3008p0, {e0}\u3009, a2 = \u3008p1, {e0}\u3009, a3 = \u3008e0, {goal}\u3009, I = {p0, p1}, and G = goal. Both plans \u03c01 = \u3008a1, a3\u3009 and \u03c02 = \u3008a2, a3\u3009 solve the problem inducing the same state trajectory \u3008{p0, p1}, {p0, p1, e0}, {p0, p1, e0, goal}\u3009. Consider now action constraint (sometime a2). While \u03c02 satisfies such action constraint, \u03c01 does not. However, it is not possible to distinguish \u03c01 from \u03c02 by just looking at the (same) sequence of states induced by \u03c01 and \u03c02: there is no state-trajectory constraint that rules \u03c01 out.\nWe allow all constraints to be formulated in first-order representation. For instance, by writing:\n\u2200 bus . (sometime \u2203 city . Drive(bus, city, city-a) \u2228Drive(bus, city, city-b))\nwe are declaring an equivalent set of (instantiated) action constraints requiring that all buses have to drive to city-a or city-b at least once."
        },
        {
            "heading": "3 Solving PAC Problems through Compilation",
            "text": "In this section we propose a compilation schema, called PACC (PAC compiler), that translates a PAC problem into an equivalent classical planning problem. We distinguish our action constraints in two classes: Prevent Constraints (PC) and Request Constraints (RC). Intuitively, PCs are constraints used to express properties that must not be violated at any time in the plan, while RCs enforce that certain actions must occur in every solution plan. PCs are: A\u03c6, SB\u03c6,\u03c8 , AO\u03c6 and AX\u03c6,\u03c8; RCs are: ST\u03c6, SA\u03c6,\u03c8 and PA\u03c61...\u03c6k . PAC-C works by preventing the execution of actions that would violate some PCs, and forcing the planner to include in the plan the actions necessary to satisfy all RCs on a state dependent basis.\nActions that cannot appear in the plan at some time step t depend on actions scheduled before t. For instance, if (at-most-once a) is a required constraint, then having a in the plan at a time t should be prevented if a has already been scheduled in the plan prefix preceding t. The same logic applies to the actions that still need to be included in the plan to satisfy some RC. To record the presence in the plan under construction of the actions relevant for the constraints, PACC uses a set of fresh atoms, built by taking into account the constraint at hand, as described below. PC Atoms. For every AO\u03c6 and SB\u03c6,\u03c8 , atoms done\u03c6 and done\u03c8 are used to record whether \u03c6 and \u03c8 have ever held. For every AX\u03c6,\u03c8 , atom request\u03c8 is used to signal that the formula \u03c6 is satisfied at a plan step t, and the planner has to schedule an action a \u2208 \u03c8 immediately after t.\nAlgorithm 1: PAC-C Input : A PAC Problem \u03a0 = \u3008\u3008F,A, I,G\u3009, C\u3009 Output: A classical planning problem equivalent to \u03a0 /* Phase (I) */\n1 F \u2032 = F \u222a PC-atoms \u222a RC-atoms 2 I\u2032 = I \u222a \u22c3 SA\u03c6,\u03c8 got\u03c6,\u03c8\n/* Phase (II) */\n3 A\u2032 = {a | a \u2208 A and for each A\u03c6 \u2208 C, a \u2208 \u03c6} 4 foreach a \u2208 A\u2032 do 5 foreach c \u2208 PC(C) do 6 if c = AO\u03c6 and a \u2208 \u03c6 then 7 Pre(a) = Pre(a) \u2227 \u00acdone\u03c6 8 Eff(a) = Eff(a) \u222a {done\u03c6} 9 if c = SB\u03c6,\u03c8 then\n10 if a \u2208 \u03c6 then Pre(a) = Pre(a) \u2227 done\u03c8 11 if a \u2208 \u03c8 then Eff(a) = Eff(a) \u222a {done\u03c8} 12 if c = AX\u03c6,\u03c8 then 13 if a \u2208 \u03c6 then Eff(a) = Eff(a) \u222a {request\u03c8} 14 else if a \u2208 \u03c8 then Eff(a) = Eff(a) \u222a {\u00acrequest\u03c8} 15 if a 6\u2208 \u03c8 then Pre(a) = Pre(a) \u2227 \u00acrequest\u03c8 16 foreach c \u2208 RC(C) do 17 if c = ST\u03c6 and a \u2208 \u03c6 then Eff(a) = Eff(a) \u222a {got\u03c6} 18 if c = SA\u03c6,\u03c8 then 19 if a \u2208 \u03c8 then Eff(a) = Eff(a) \u222a {got\u03c6,\u03c8} 20 if a \u2208 \u03c6 and a 6\u2208 \u03c8 then Eff(a) = Eff(a) \u222a {\u00acgot\u03c6,\u03c8} 21 if c = PA\u03c61...\u03c6k then 22 foreach \u03c6i \u2208 \u3008\u03c61 . . . \u03c6k\u3009 \u00b7 a \u2208 \u03c6i do\n23 Eff(a) = Eff(a)\u222a { {stagei\u22121c . stage i c} if i > 1\n{stage1c} otherwise /* Phase (III) */\n24 G\u2032 = G \u2227 \u2227\nSA\u03c6,\u03c8\u2208C got\u03c6,\u03c8 \u2227 \u2227 ST\u03c6\u2208C got\u03c6 \u2227 \u2227\nAX\u03c6,\u03c8\u2208C \u00acrequest\u03c8 \u2227\u2227\nc=PA\u03c61...\u03c6k \u2208C\nstagekc\n25 return \u3008F \u2032, A\u2032, I\u2032, G\u2032\u3009\nRC Atoms. For every ST\u03c6 and SA\u03c6,\u03c8 , atoms got\u03c6 and got\u03c6,\u03c8 are used to record whether or not the constraint is satisfied by the prefix plan. For every PA\u03c61...\u03c6k , we add a set of atoms called stage atoms to keep track of the progress of the pattern in the plan. The set of stage atoms is defined as follows:\nStageAtoms(C) = \u22c3\nc=PA\u03c61...\u03c6k\u2208C\n{stage1c , . . . , stagekc}\nAtoms stageic (i \u2208 {1, . . . , k}) will hold in a plan state s iff (pattern \u03c61 . . . \u03c6i) is satisfied by the plan prefix up to s.\nCompilation schema. Algorithm 1 specifies the full compilation schema, called PAC-C. There are three different phases: (I) creation of necessary atoms and setup of the initial state to reflect the status of the constraints; (II) revision of the preconditions and effects of relevant actions; (III) setup of the goal to enforce the satisfaction of all RCs and AXs constraints.\nPhase (I). The necessary PC and RC atoms are created and the initial state is setup (lines 1-2). When a plan has no actions, all SA\u03c6,\u03c8 constraints are satisfied, and so the corresponding got\u03c6 atoms are set to true in the initial state.\nPhase (II). The algorithm prunes all actions that do not satisfy the always constraints. Then it modifies the actions to keep all constraints in check. For a PC, PAC-C determines new preconditions that must be fulfilled for the actions that\ninteract with the constraint. In particular, PAC-C prevents having in the plan actions that (a) make \u03c6 true a second time (in the case of an AO\u03c6), (b) make \u03c6 true if done\u03c8 is false (in the case of a SB\u03c6,\u03c8), and (c) cannot make \u03c8 true when there is a request of it triggered by the previous action (in the case of an AX\u03c6,\u03c8). For PCs, new effects are added to keep track of the execution of relevant actions. For instance, an AX\u03c6,\u03c8 constraint requires to restrict the possible actions in the plan at the next time step when \u03c6 becomes true. If an action a in the plan satisfies \u03c6 at some time t, the triggered request for some action satisfying \u03c8 at time t+1 is encoded by disallowing the occurrence of any action not satisfying \u03c8 (lines 13-15). If an action does not trigger the constraint and satisfies \u03c8 instead, then \u00acrequest\u03c8 is added to its effects (lines 13-14), disabling the request of \u03c8 demanded by the constraint.\nFor RCs, PAC-C adds a set of effects to keep track of the relevant actions that appear in the plan. A ST\u03c6 constraint requires that at least one action that satisfies \u03c6 appears sometime in the plan. Atom got\u03c6 is then added to all actions that make \u03c6 true. For a SA\u03c6,\u03c8 constraint, PACC adds effects to signal the necessity of \u03c8 whenever \u03c6 becomes true (lines 19-20). For a PA\u03c61...\u03c6k constraint, the algorithm checks if an action satisfies any formula in {\u03c61 . . . \u03c6k}. E.g., if an action a in the plan makes formula \u03c6i true and (pattern \u03c61 . . . \u03c6i\u22121) is already satisfied by the plan prefix up to a, then (pattern \u03c61 . . . \u03c6i) will become satisfied. PAC-C keeps track of this information by adding conditional effect stagei\u22121c . stage i c to all actions satisfying \u03c6i (line 23).\nPhase (III). The last step consists in setting up the new goals of the problem: all the ST\u03c6, SA\u03c6,\u03c8 , AX\u03c6,\u03c8 and PA\u03c61...\u03c6k constraints must be satisfied. This means that in the final state all got\u03c6, got\u03c6,\u03c8 and stagekc atoms have to hold, and there is no pending request of an action to satisfy some AX\u03c6,\u03c8 (line 24).\nThe additional preconditions and effects of the compilation prevent the planner form generating any sequence of actions that violates one or more PCs, while the additional goals force the planner to satisfy all RCs. The following theorem states that any plan of the original problem \u03a0 is a solution of \u03a0 if and only if the same plan with its actions modified by PACC is a solution for the translated problem \u03a0\u2032. Note that the original and the modified plan have exactly the same length.\nTheorem 1. Let \u03a0 = \u3008\u3008F,A, I,G\u3009, C\u3009 be a PAC problem and \u03a0\u2032 = \u3008F \u2032, A\u2032, I \u2032, G\u2032\u3009 the problem obtained by compiling \u03a0 through Algorithm 1. A plan \u03c0 = \u3008a1, a2, . . . , an\u3009 is a solution for \u03a0 iff plan \u03c0\u2032 = \u3008\u03c4(a1), \u03c4(a2), . . . , \u03c4 (an)\u3009 is a solution for \u03a0\u2032, where \u03c4(ai) is the transformation of ai performed by Algorithm 1 (Phase II) for i = 1 . . . n.\nProof Sketch. Both directions can be proven by contradiction, considering each type of constraints one by one. That is, we show that if \u03c0\u2032 (\u03c0) is not a valid plan for \u03a0\u2032 (\u03a0) then also \u03c0 (\u03c0\u2032) cannot be a valid plan for \u03a0 (\u03a0\u2032). Full proof in the supplementary material.3\n3Supplementary material, benchmark domains and Python implementation of PAC-C can be found at https://bit.ly/3kerz8s."
        },
        {
            "heading": "4 Experimental Analysis",
            "text": "Our experiments are aimed at evaluating the usefulness of action constraints as knowledge that can be effectively exploited to improve problem-solution coverage and plan quality. We evaluate the behavior of a classical planner with/without this (compiled) knowledge. For comparison reasons we also investigate how the classical planner can be enhanced by using the same control knowledge expressed as (compiled) state-trajectory constraints formulated in LTLf [Giacomo and Vardi, 2013] or PDDL3 [Gerevini et al., 2009]. As classical planner we used LAMA [Richter and Westphal, 2010], that was run on the original benchmark problems and on the corresponding problems extended with control knowledge. Such knowledge was compiled by three different methods: PACC3 (for action constraints), TCORE (for PDDL3 constraints) [Bonassi et al., 2021], and LTL-C (for LTLf constraints) [Baier and McIlraith, 2006]. To the best of our knowledge, TCORE and LTL-C are the most effective approaches to deal with the considered class of constraints.\nWe measured performance in terms of number of solved instances (coverage), CPU time of the planner, and plan length of the solution (when found). For the compilation-based approaches, CPU time includes compilation time. All experiments ran on an Xeon Gold 6140M 2.3 GHz, with time and memory limits of 1800s and 8GB, respectively."
        },
        {
            "heading": "4.1 Benchmark Design",
            "text": "Since there are no available benchmarks featuring action constraints, we generated a new benchmark suite3 starting from the problems of the 5th International Planning Competition. We considered the following domains: Trucks, Storage, TPP, Openstack and Rover. All original instances of Rover, TPP, and Openstack are easily solved by LAMA, while the planner struggles to find solutions for some instances of Trucks and Storage. For this reason, we designed our action constraints with different objectives for the two groups of domains: in Trucks and Storage, constraints were designed with the purpose of boosting problem coverage, while in the other domains the constraints were designed to improve plan quality. Our benchmark suite involves 160 instances: 30 in each of Trucks, Storage, TPP and Openstack, and 40 in Rover. To evaluate the use of LTLf and PDDL3, for each instance we generated two further instances: one encoding the action constraints into an equivalent formulation in LTLf ; the other encoding an equivalent instance using PDDL3 qualitative state-trajectory constraints. Such instances were not formulated starting from the action constraints specification; that is, the constraint knowledge was directly formulated into either action constraints or state constraints (PDDL3 or LTLf ), without going through action constraints first. Note that the conversion in PDDL3 has been possible only for a subset of the considered domains. In what follows we describe the constraints introduced in each domain.\nTPP. This domain encodes the Traveling Purchaser Problem (TPP) [Ramesh, 1981]. We have a set of markets and a set of products. Each market sells different products in different quantities, and the objective is to collect and deliver at\nthe depot the required quantity of products by using trucks. Each truck can drive to different locations, buy, load and unload products. While a single truck is sufficient to visit all markets, we observed that a greedy planner tends to move all trucks back and forth from depots to markets producing plans of very bad quality. To overcome this problem we forced the planner to use only a single truck driving in a subset of the roads via the following always constraints:\n(always \u2200 from, to . \u00acDrive(truck2, from, to)) (always \u00acDrive(truck1,market2, depot1)\u2227\n\u00acDrive(truck1,market1,market2))\nMoreover, we forced the truck to visit markets in a precise order through the following pattern constraint:\n(pattern Drive(truck1, depot1,market2)\nDrive(truck1,market2,market1)\nDrive(truck1,market1, depot1))\nIn TPP a planner is allowed to move a truck multiple times from depots to markets to deliver a product; a better strategy is gathering the required quantity of a product and then go back to unload the product. We enforced this by constraint\n(sometime \u2203market.Load(product1, truck1,market, levelx))\nThis constraint is repeated for every product, and in each case it is satisfiable as trucks have unlimited storing space. Finally, we require that after buying a product, that product is immediately loaded in the truck:\n(always-next\n\u2203 product, \u2203market. Buy(truck1, product,market) \u2203 product, \u2203market, \u2203 level.\nLoad(product, truck1,market, level))\nFor TPP we also designed an equivalent formulation using LTLf constraints by transferring the constraints over actions to constraints over states. This can be done by inspecting the action structure and enforcing to traverse only those states that would be traversed by the actions. E.g., we formulate pattern constraints in LTLf as follows:\n(at(truck1, depot1) \u2227at(truck1,market2)\u2227 ((at(truck1,market2) \u2227at(truck1,market1)\u2227 ((at(truck1,market1) \u2227at(truck1, depot1))))))\nOverall, we have one constraint in the smallest benchmark instance and 22 constraints in the largest one. Storage. In this domain the goal is to move some crates inside depots by a set of hoists. Hoists can operate inside and outside depots, lift crates, and drop them into depots or containers. Finding a solution in Storage can be a difficult task, because leaving a create right at the entrance of a depot will prevent hoists from moving into that depot in the future. To aid the planner, we forced crates to be positioned starting from the storage areas further away from the entrance. This was encoded using a pattern constraint. We also prevented the unnecessary lifting of a crate via the following constraint:\n\u2200 crate. (at-most-once \u2203hoist. Lift(hoist, crate))\nAll constraints were also translated into PDDL3 and LTLf . E.g., the previous at-most-once constraint was translated in LTLf by the following formula, for each crate c, where \u03c6 = \u2203hoist. lifting(hoist, c):\n(\u03c6\u21d2 (\u03c6U((\u00ac\u03c6) \u2228 final))) Each benchmark instance has from 2 to 21 constraints. Trucks. This is a logistics domain concerning the delivery of packages to different locations by some trucks. The space inside the trucks is partitioned into areas, and a package can be loaded in an area only if all areas in between the door and the area in consideration are free. This requirement must also hold when a package is unloaded. In addition, some packages must be delivered by a deadline. To improve problem coverage, we used at-most-once constraints to impose that every package is loaded inside a truck at most one time. Overall, each benchmark instances has from 3 to 20 constraints. Rover. The objective is acquiring data about soil, rocks and images of a planet. Data are gathered by a set of rovers that can move across waypoints. Each rover has different equipment to either sample the soil/rocks or take images. The acquired data must be communicated to the lander. In this domain there are many actions that are unnecessary to achieve the goal. E.g., if the goal does not require the data of the rock located at some waypoint, there is no need to sample it. Such actions can be forbidden through always constraints. Moreover, by set of sometime-before constraints we required that the rovers communicate data only after all the needed data have been gathered. Finally, we broke some symmetrical solutions by forcing an order to the communications:\n(sometime-before\n\u2203 rover. Send soil data(rover, waypointx) \u2203 rover. Send rock data(rover, waypointy))\nThese constraints were also formulated in LTLf and PDDL3. E.g., the previous action constraint in LTLf is:\n(\u00ac\u03c6\u2227\u03c8)R(\u00ac\u03c6) with \u03c6 = Communicated soil data(waypointx)\n\u03c8 = Communicated rock data(waypointy)\nEach benchmark instance has from 6 to 138 constraints. Openstack. This domain models a combinatorial optimization problem where a set of orders must be shipped. To start the production of an order, a new \u201cstack\u201d must be opened. Each order can be shipped only if a given set of products associated to that order has been produced. Once an order is shipped, the previously occupied stack can be used for new orders. To make a product, all orders that include it must be in a stack. The objective is to find a production that minimizes the number of opened stacks. The domain actions can open a new stack, start a new order, ship a finished order, set up the machine for production, and make a product. An optimal solution plan has the fewest open-new-stack actions.\nTo aid the planner in finding good quality solution, we used two always-next constraints: the first requires that after opening a new stack an order is immediately started; the second requires that after setting up the machine, the product is immediately made. Every instance of Openstack feature these two constraints."
        },
        {
            "heading": "4.2 Experimental Results",
            "text": "Coverage. Table 1 shows the overall coverage achieved using BASELINE (LAMA run on the original instances without constraints), PAC-C, LTL-C and TCORE. We first comment on the results obtained for Storage and Trucks, the two domains featuring constraints formulated to improve coverage. The action constraints in Trucks help the planner by pruning the search space, and this led PAC-C to solve 7 more instances w.r.t. BASELINE. For Storage, the BASELINE fails to solve 10 instances, and we advocate this to the fact that hoists can leave crates in areas that will obstruct future movements inside the depot, and this is not captured by LAMA\u2019s heuristic. This cannot happen for the instances with action constrains: a hoist can lift a crate at most once and crates must be positioned starting from areas that are far away from the door. With these constraints, PAC-C manages to solve all instances of Storage. These results confirm that action constrains can improve the performance of a state-of-the-art classical planner. Also using TCORE coverage is incremented, but not as much as with PAC-C: 3 and 8 more instances are solved in Trucks and Storage, respectively. By encoding the same knowledge as state constraints in LTLf and using LTL-C, we did not obtain any improvement. Rather, the performance of LAMA was even worsened (coverage reduces for all considered domains). PAC-C turned out to be (much) more effective, coverage wise, than LTL-C and TCORE.\nPlan quality. Table 2 and Figures 1a, 1b and 1c give an overall picture of the quality of the plans obtained by the compilation-based systems with respect to the baseline across all domains. From Figure 1a it is possible to see that PAC-C performs really well in Rover, TPP and Openstack. In\nTPP, the BASELINE moves trucks in a very suboptimal way to buy all products, while PAC-C substantially reduces the number of drive actions. Plan quality is improved for 25 instances and, on average, plans have 40 actions less than the BASELINE. Also in Rover and Openstack PAC-C performs well, improving quality in most cases. These results confirm that control knowledge expressed as action constraints can effectively lead to better quality solutions. With LTL-C the improvement is limited. TCORE shows good performance in Rover, while for Openstack and TPP it was not possible to reformulate our action constraints in PDDL3 (in the tables indicated with \u201c\u2013\u201d). For Trucks and Storage, plan quality is worsened by all compared systems. In our benchmarks, coverage and quality is not improved at the same time; this is not surprising since they were designed with constraints aimed at improving coverage or solution quality, but not both. CPU time. Figure 1d shows how coverage and CPU time are related. As expected, all compilation-based approaches tend to increase their coverage over time more slowly w.r.t. the BASELINE, since performing the compilation takes some time that we do not have in BASELINE. While the coverage of the BASELINE tails-off after around 26 secs (coverage gets to 132 solved instances), PAC-C keeps increasing coverage, outperforming the BASELINE after about 90 CPU seconds."
        },
        {
            "heading": "5 Related Work",
            "text": "Micheli and Scala (2019) introduced a formalism supporting action constraints specified as quantified temporal metric axioms. Such axioms define constraints over the execution tim-\ning of the actions. The constraints in PAC focus on a class of qualitative temporal constraints allowing to handle the constraints through a polynomial compilation into classical planning. Handling quantified temporal metric axiom is much more involved, and the computational complexity of planning with such axioms is still unknown.\nThe generation of macro actions is an approach to synthesize control knowledge where multiple consecutive actions are combined into a single macro action (e.g. [Botea et al., 2005]). PAC can express sequences of (possibly disjunctive) actions through pattern constraints. The main differences are that (i) in this type of constraints actions are not necessarily consecutive, and (ii) macro actions do not express constraints a valid plan should satisfy (typically macros are added to the domain without removing any original action).\nHierarchical Task Network (HTN) [Erol et al., 1994] is a well-know approach to planning that supports control knowledge. The main difference with PAC planning is that in HTN constraints represent specific domain knowledge, while in our approach constraints are specified at the problem level, and in the context of domain-independent PDDL planning rather than HTN planning.\nSohrabi et al. (2009) extend PDDL3 to formulate actioncentric preferences over HTN tasks, and propose to handle them natively through a dedicated HTN planning system (HTNPLAN-P). PAC planning does not require the specification of a hierarchical domain theory and, as we have shown, it allows efficient compilation into classical planning without constraints. This enables any classical planner supporting conditional effects to deal with PAC problems. Moreover, PAC constraints include operators that are not considered in Sohrabi et al.\u2019s language. LPP [Baier et al., 2008; Bienvenu et al., 2011] is a language that harnesses the expressive power of LTLf for specifying preferred and hard constraints over trajectories of actions as well as of states. PAC focuses on a more restricted language that, as it is the case for PDDL3 constraints versus more general LTLf formulae [Bonassi et al., 2021; Percassi and Gerevini, 2019], a planner can handle more effectively (without undergoing a potentially expensive automata-based compilation). A deeper comparison in terms of the relative expressiveness and effectiveness for planning between LPP and PAC is left to future work.\nFinally, recent work by Bonet and Geffner (2021) introduced an interesting language based on sketch rules that can be used to decompose a planning problem into specific subproblems, reducing the problem width [Lipovetzky and Geffner, 2012]. This language is significantly different from action constraints, and its usefulness has been theoretically studied only in the context of width-based planning algorithms."
        },
        {
            "heading": "6 Conclusions",
            "text": "Imposing constraints on the action trajectory of a plan is useful to guide the planner search as well as to generate plans that have some desired properties. We have presented a new language to express a class of action-trajectory constraints, and a compilation-based approach to plan with such constraints.\nOur compilation scheme can be used alongside any classical planner supporting conditional effects, and it is relatively simple, computationally efficient, and compact. As experimentally shown, action constraints and our compilation provide an effective tool to express and use useful control knowledge. A comparison with other approaches shows that, for the considered benchmarks, a classical planner can exploit knowledge expressed as (compiled) action constraints more effectively than equivalent formulations using state-trajectory constraints. Future work concerns investigating trajectory constraints over both actions and states, preferences over action constraints, and further experiments with numeric domains."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the anonymous reviewers for their helpful comments. The work was partially supported by projects H2020EU AIPlan4EU and MUR PRIN-2020 RIPER."
        }
    ],
    "title": "Planning with Qualitative Action-Trajectory Constraints in PDDL",
    "year": 2022
}