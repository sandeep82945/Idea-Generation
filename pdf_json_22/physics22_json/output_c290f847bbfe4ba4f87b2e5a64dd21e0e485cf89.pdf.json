{
    "abstractText": "This paper extends the methodology to use physics-informed enhanced super-resolution generative adversarial networks (PIESRGANs) for LES subfilter modeling in turbulent flows with finite-rate chemistry and shows a successful application to a non-premixed temporal jet case. This is an important topic considering the need for more efficient and carbon-neutral energy devices to fight the climate change. Multiple a priori and a posteriori results are presented and discussed. As part of this, the impact of the underlying mesh on the prediction quality is emphasized, and a multi-mesh approach is developed. It is demonstrated how LES based on PIESRGAN can be employed to predict cases at Reynolds numbers which were not used for training. Finally, the amount of data needed for a successful prediction is elaborated.",
    "authors": [
        {
            "affiliations": [],
            "name": "Mathis Bodea"
        }
    ],
    "id": "SP:6680a2537d347ef90589e72257c6cc9345080e9c",
    "references": [
        {
            "authors": [
                "G. Hinton",
                "L. Deng",
                "D. Yu"
            ],
            "title": "G",
            "venue": "Dahl, A.-r. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, B. Kingsbury, et al., Deep neural networks for acoustic modeling in speech recognition, IEEE Signal processing magazine 29 ",
            "year": 2012
        },
        {
            "authors": [
                "C. Dong",
                "C.C. Loy",
                "K. He",
                "X. Tang"
            ],
            "title": "Learning a deep convolutional network for image super-resolution",
            "venue": "in: European conference on computer vision, Springer",
            "year": 2014
        },
        {
            "authors": [
                "X. Wang",
                "K. Yu",
                "S. Wu",
                "J. Gu",
                "Y. Liu",
                "C. Dong",
                "Y. Qiao",
                "C. Loy"
            ],
            "title": "ES- RGAN: Enhanced Super-Resolution Generative Adversarial Networks",
            "venue": "Lecture Notes in Computer Science 11133 ",
            "year": 2019
        },
        {
            "authors": [
                "H. Greenspan",
                "B. Van Ginneken",
                "R.M. Summers"
            ],
            "title": "Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique",
            "venue": "IEEE Transactions on Medical Imaging 35 (5) ",
            "year": 2016
        },
        {
            "authors": [
                "O. Vinyals",
                "I. Babuschkin",
                "W. Czarnecki",
                "M. Mathieu",
                "A. Dudzik"
            ],
            "title": "J",
            "venue": "Chung, et al., Grandmaster level in StarCraft II using multi-agent reinforcement learning, Nature 575 ",
            "year": 2019
        },
        {
            "authors": [
                "A. Bhati",
                "S. Wan",
                "D. Alfe"
            ],
            "title": "A",
            "venue": "Clyde, et al., Pandemic drugs at pandemic speed: infrastructure for accelerating COVID-19 drug discovery with hybrid machine learning- and physics-based simulations on high performance computers, Interface Focus 20210018 ",
            "year": 2021
        },
        {
            "authors": [
                "K. Fukami",
                "R. Maulik",
                "N. Ramachandra",
                "K. Fukagata",
                "K. Taira"
            ],
            "title": "Global field reconstruction from sparse sensors with voronoi tessellation-assisted deep learning",
            "venue": "Nature Machine Intelligence 3 ",
            "year": 2021
        },
        {
            "authors": [
                "Y. Liang",
                "S.B. Pope",
                "P. Pepiot"
            ],
            "title": "A pre-partitioned adaptive chemistry methodology for the efficient implementation of combustion chemistry in particle pdf methods",
            "venue": "Combustion and Flame 162 ",
            "year": 2015
        },
        {
            "authors": [
                "M. Bode",
                "N. Collier",
                "F. Bisetti",
                "H. Pitsch"
            ],
            "title": "Adaptive chemistry lookup tables for combustion simulations using optimal B-spline interpolants",
            "venue": "Combustion Theory and Modelling 23 (4) ",
            "year": 2019
        },
        {
            "authors": [
                "W.T. Chung",
                "A.A. Mishra",
                "N. Perakis",
                "M. Ihme"
            ],
            "title": "Data-assisted combustion simulations with dynamic submodel assignment using random forests",
            "venue": "Combustion and Flame 227 ",
            "year": 2021
        },
        {
            "authors": [
                "C.J. Lapeyre",
                "A. Misdariis",
                "N. Cazard",
                "D. Veynante",
                "T. Poinsot"
            ],
            "title": "Training convolutional neural networks to estimate turbulent sub-grid scale reaction rates",
            "venue": "Combustion and Flame 203 ",
            "year": 2019
        },
        {
            "authors": [
                "M.T. Henry de Frahan",
                "S. Yellapantula",
                "R. King",
                "M.S. Day",
                "R.W. Grout"
            ],
            "title": "Deep learning for presumed probability density function models, Combustion and Flame",
            "year": 2019
        },
        {
            "authors": [
                "K. Wan",
                "S. Hartl",
                "L. Vervisch",
                "P. Domingo",
                "R.S. Barlow",
                "C. Hasse"
            ],
            "title": "Combustion regime identification from machine learning trained by raman/rayleigh line measurements",
            "venue": "Combustion and Flame 219 ",
            "year": 2020
        },
        {
            "authors": [
                "C. Dong",
                "C.C. Loy",
                "K. He",
                "X. Tang"
            ],
            "title": "Image super-resolution using deep convolutional networks",
            "venue": "IEEE transactions on pattern analysis and machine intelligence 38 (2) ",
            "year": 2015
        },
        {
            "authors": [
                "J. Kim",
                "J. Kwon Lee",
                "K. Mu Lee"
            ],
            "title": "Accurate image super-resolution using very deep convolutional networks",
            "venue": "in: Proceedings of the IEEE conference on computer vision and pattern recognition",
            "year": 2016
        },
        {
            "authors": [
                "J. Kim",
                "J. Kwon Lee",
                "K. Mu Lee"
            ],
            "title": "Deeply-recursive convolutional network for image super-resolution",
            "venue": "in: Proceedings of the IEEE conference on computer vision and pattern recognition",
            "year": 2016
        },
        {
            "authors": [
                "W.-S. Lai",
                "J.-B. Huang",
                "N. Ahuja",
                "M.-H. Yang"
            ],
            "title": "Deep laplacian pyramid networks for fast and accurate super-resolution",
            "venue": "in: Proceedings of the IEEE conference on computer vision and pattern recognition",
            "year": 2017
        },
        {
            "authors": [
                "Y. Tai",
                "J. Yang",
                "X. Liu",
                "C. Xu"
            ],
            "title": "Memnet: A persistent memory network for image restoration",
            "venue": "in: Proceedings of the IEEE international conference on computer vision",
            "year": 2017
        },
        {
            "authors": [
                "Y. Zhang",
                "K. Li",
                "K. Li",
                "L. Wang",
                "B. Zhong",
                "Y. Fu"
            ],
            "title": "Image super-resolution using very deep residual channel attention networks",
            "venue": "in: Proceedings of the European Conference on Computer Vision (ECCV)",
            "year": 2018
        },
        {
            "authors": [
                "C. Ledig",
                "L. Theis",
                "F. Husz\u00e1r",
                "J. Caballero",
                "A. Cunningham",
                "A. Acosta",
                "A. Aitken",
                "A. Tejani",
                "J. Totz"
            ],
            "title": "Z",
            "venue": "Wang, et al., Photo-realistic single image super-resolution using a generative adversarial network, in: Proceedings of the IEEE conference on computer vision and pattern recognition",
            "year": 2017
        },
        {
            "authors": [
                "J. Johnson",
                "A. Alahi",
                "L. Fei-Fei"
            ],
            "title": "Perceptual losses for real-time style transfer and super-resolution",
            "venue": "in: European conference on computer vision, Springer",
            "year": 2016
        },
        {
            "authors": [
                "K. Simonyan",
                "A. Zisserman"
            ],
            "title": "Very deep convolutional networks for largescale image recognition",
            "venue": "arXiv preprint arXiv:1409.1556 ",
            "year": 2014
        },
        {
            "authors": [
                "I. Goodfellow",
                "J. Pouget-Abadie",
                "M. Mirza",
                "B. Xu",
                "D. Warde-Farley",
                "S. Ozair",
                "A. Courville",
                "Y. Bengio"
            ],
            "title": "Generative adversarial nets",
            "venue": "in: Advances in neural information processing systems",
            "year": 2014
        },
        {
            "authors": [
                "M. Arjovsky",
                "S. Chintala",
                "L. Bottou"
            ],
            "title": "Wasserstein gan",
            "venue": "arXiv preprint arXiv:1701.07875 ",
            "year": 2017
        },
        {
            "authors": [
                "X. Wang",
                "K. Yu",
                "S. Wu",
                "J. Gu",
                "Y. Liu",
                "C. Dong",
                "Y. Qiao",
                "C. Change Loy"
            ],
            "title": "Esrgan: Enhanced super-resolution generative adversarial networks",
            "venue": "in: Proceedings of the European Conference on Computer Vision (ECCV)",
            "year": 2018
        },
        {
            "authors": [
                "M. Bode",
                "M. Gauding",
                "K. Kleinheinz",
                "H. Pitsch"
            ],
            "title": "Deep learning at scale for subgrid modeling in turbulent flows: regression and reconstruction",
            "venue": "LNCS 11887 ",
            "year": 2019
        },
        {
            "authors": [
                "M. Bode"
            ],
            "title": "Development of physics-informed enhanced superresolution generative adversarial networks for subfilter modeling, arXiv preprint (2021)",
            "year": 2021
        },
        {
            "authors": [
                "M. Bode",
                "M. Gauding",
                "Z. Lian",
                "D. Denker",
                "M. Davidovic"
            ],
            "title": "K",
            "venue": "Kleinheinz, et al., Using physics-informed enhanced super-resolution generative adversarial networks for subfilter modeling in turbulent reactive flows, Proceedings of the Combustion Institute 38 ",
            "year": 2021
        },
        {
            "authors": [
                "M. Gauding",
                "M. Bode"
            ],
            "title": "Using physics-informed enhanced superresolution generative adversarial networks to reconstruct mixture fraction statistics of turbulent jet flows",
            "venue": "in: H. Jagode, H. Anzt, H. Ltaief, P. Luszczek (Eds.), High Performance Computing, Vol. 11203, Springer International Publishing",
            "year": 2021
        },
        {
            "authors": [
                "M. Bode"
            ],
            "title": "Applying physics-informed enhanced super-resolution generative adversarial networks to large-eddy simulations of ECN Spray C",
            "venue": "SAE Technical Paper 2022-01-0503 ",
            "year": 2022
        },
        {
            "authors": [
                "M. Bode"
            ],
            "title": "Applying physics-informed enhanced super-resolution generative adversarial networks to direct numerical simulation data of spray and comparison to classical flamelet models",
            "venue": "arXiv preprint ",
            "year": 2022
        },
        {
            "authors": [
                "M. Bode"
            ],
            "title": "AI super-resolution: Application to turbulence and combustion",
            "venue": "in: N. Swaminathan, A. Parente (Eds.), Machine Learning and Its Application to Reacting Flows, Springer",
            "year": 2022
        },
        {
            "authors": [
                "D. Denker",
                "A. Attili"
            ],
            "title": "J",
            "venue": "Boschung, et al., Dissipation element analysis of non-premixed jet flames, Journal of Fluid Mechanics 904 ",
            "year": 2020
        },
        {
            "authors": [
                "D. Denker",
                "A. Attili",
                "M. Gauding",
                "K. Niemietz",
                "M. Bode",
                "H. Pitsch"
            ],
            "title": "A new modeling approach for mixture fraction statistics based on dissipation elements",
            "venue": "Proceedings of the Combustion Institute 38 ",
            "year": 2021
        },
        {
            "authors": [
                "O. Desjardins",
                "G. Blanquart",
                "G. Balarac",
                "H. Pitsch"
            ],
            "title": "High order conservative finite difference scheme for variable density low Mach number turbulent flows",
            "venue": "Journal of Computational Physics 227 (15) ",
            "year": 2008
        },
        {
            "authors": [
                "M. Bode",
                "M. Davidovic",
                "H. Pitsch"
            ],
            "title": "Towards clean propulsion with synthetic fuels: Computational aspects and analysis",
            "venue": "in: High-Performance Scientific Computing, Springer Nature",
            "year": 2019
        },
        {
            "authors": [
                "M. Bode",
                "T. Falkenstein",
                "S. Kang",
                "H. Pitsch"
            ],
            "title": "High-Q Club",
            "venue": "http://www.fzjuelich.de/ias/jsc/EN/Expertise/High-Q-Club/CIAO/ node.html ",
            "year": 2015
        },
        {
            "authors": [
                "R.D. Falgout",
                "U.M. Yang"
            ],
            "title": "hypre: A library of high performance preconditioners",
            "venue": "in: P. M. A. Sloot, A. G. Hoekstra, C. J. K. Tan, J. J. Dongarra (Eds.), Computational Science \u2014 ICCS 2002, Springer Berlin Heidelberg",
            "year": 2002
        },
        {
            "authors": [
                "V.E. Henson",
                "U.M. Yang"
            ],
            "title": "BoomerAMG: A parallel algebraic multigrid solver and preconditioner",
            "venue": "Applied Numerical Mathematics 41 (1) ",
            "year": 2002
        },
        {
            "authors": [
                "G.-S. Jiang",
                "C.-W. Shu"
            ],
            "title": "Efficient implementation of weighted ENO schemes",
            "venue": "Journal of Computational Physics 126 (1) ",
            "year": 1996
        },
        {
            "authors": [
                "G. Strang"
            ],
            "title": "On the construction and comparison of difference schemes",
            "venue": "SIAM Journal on Numerical Analysis 5 (3) ",
            "year": 1968
        },
        {
            "authors": [
                "A.C. Hindmarsh",
                "P.N. Brown",
                "K.E. Grant",
                "S.L. Lee",
                "R. Serban",
                "D.E. Shumaker",
                "C.S. Woodward"
            ],
            "title": "SUNDIALS: Suite of nonlinear and differential/algebraic equation solvers",
            "venue": "ACM Transactions on Mathematical Software 31 (3) ",
            "year": 2005
        },
        {
            "authors": [
                "P.N. Brown",
                "G.D. Byrne",
                "A.C. Hindmarsh"
            ],
            "title": "VODE: A variablecoefficient ODE solver",
            "venue": "SIAM Journal on Scientific and Statistical Computing 10 (5) ",
            "year": 1989
        },
        {
            "authors": [
                "J.O. Hirschfelder",
                "C.F. Curtiss",
                "R.B. Bird"
            ],
            "title": "Molecular theory of gases and liquids",
            "venue": "John Wiley and Sons, New York",
            "year": 1954
        },
        {
            "authors": [
                "N. Peters",
                "G. Paczko",
                "R. Seiser",
                "K. Seshadri"
            ],
            "title": "Temperature cross-over and non-thermal runaway at two-stage ignition of n-heplane",
            "venue": "Combustion and Flame 128 ",
            "year": 2002
        },
        {
            "authors": [
                "G.A. Lavoie",
                "J.B. Heywood",
                "J.C. Keck"
            ],
            "title": "Experimental and theoretical study of nitric oxide formation in internal combustion engines",
            "venue": "Combustion Science and Technology 1 ",
            "year": 1070
        },
        {
            "authors": [
                "A. Jolicoeur-Martineau"
            ],
            "title": "The relativistic discriminator: a key element missing from standard gan",
            "venue": "arXiv preprint arXiv:1807.00734 ",
            "year": 2018
        },
        {
            "authors": [
                "A. Krizhevsky",
                "I. Sutskever",
                "G.E. Hinton"
            ],
            "title": "Imagenet classification with deep convolutional neural networks",
            "venue": "in: Advances in neural information processing systems",
            "year": 2012
        },
        {
            "authors": [
                "A.L. Maas",
                "A.Y. Hannun",
                "A.Y. Ng"
            ],
            "title": "Rectifier nonlinearities improve neural network acoustic models",
            "venue": "Proceedings of the 30th International Conference on Machine Learning 30 ",
            "year": 2013
        },
        {
            "authors": [
                "M. Abadi",
                "A. Agarwal",
                "P. Barham",
                "E. Brevdo",
                "Z. Chen",
                "C. Citro",
                "G.S. Corrado",
                "A. Davis",
                "J. Dean"
            ],
            "title": "M",
            "venue": "Devin, et al., Tensorflow: Large-scale machine learning on heterogeneous systems, 2015, Software available from tensorflow. org 1 (2) ",
            "year": 2015
        }
    ],
    "sections": [
        {
            "text": "This paper extends the methodology to use physics-informed enhanced super-resolution generative adversarial networks (PIESRGANs) for LES subfilter modeling in turbulent flows with finite-rate chemistry and shows a successful application to a non-premixed temporal jet case. This is an important topic considering the need for more efficient and carbon-neutral energy devices to fight the climate change. Multiple a priori and a posteriori results are presented and discussed. As part of this, the impact of the underlying mesh on the prediction quality is emphasized, and a multi-mesh approach is developed. It is demonstrated how LES based on PIESRGAN can be employed to predict cases at Reynolds numbers which were not used for training. Finally, the amount of data needed for a successful prediction is elaborated.\nKeywords: Generative Adversarial Network, Direct Numerical Simulation, Large-Eddy Simulation, Non-Premixed Combustion, Simulation Workflows"
        },
        {
            "heading": "1. Introduction",
            "text": "Artificial intelligence (AI) and Data-driven approaches, such as machine learning (ML) and deep learning (DL), have become very important tools in many scientific domains. This is mainly due to two recent developments. First, ML/DL algorithms have improved drastically with respect to accuracy and robustness, and their execution on graphics processing units (GPUs) became much faster, as the speed of GPUs increased generally and newer GPU generations were developed with a focus on data-driven methods enabling high bandwidths as well as fast and efficient tensor multiplications. Second, the amount of data significantly increased as the size and number of scientific simulations grew, data completeness of experimental setups improved with new techniques, and new data sources appeared, such as mobile phones and the world wide web. Examples for successful applications cover a broad range including speech recognition [1], image processing [2, 3, 4], learning of optimal complex control [5], and acceleration of drug developments [6]. Also, researchers studying turbulence and reactive flows started to use ML/DL tools more frequently. Recent examples are time-advancement for flows by neural networks [7], data-driven tabulation as well as optimization of chemistry and combustion [8, 9, 10, 11], DL-supported evaluation of subgrid contributions and probability density functions (PDFs) [12, 13], and ML-assisted analysis of combustion behavior [14].\nAmong the ML/DL approaches, super resolution is one prominent technique, traditionally developed for image pro-\n\u2217Corresponding author Email address: m.bode@itv.rwth-aachen.de (Mathis Bode)\ncessing applications as single image super-resolution (SISR). The goal was to use data-driven methods to increase the image resolution (i. e., to super-resolve the image) by adding information into images to uncover originally hidden features. For this, a network is trained with a large number of images to learn common features. These features are then introduced into the target image based on local information outperforming the prediction accuracy of classical techniques, such as bicubic interpolation. Dong et al. [2] relied on a convolutional neural network (CNN) for their super-resolution convolutional neural network (SRCNN), which learned an end-to-end mapping between the low/high-resolution images. This approach has been improved over the years [15, 16, 17, 18, 19, 20]. However, as pointed out by Ledig et al. [21], these approaches typically produce oversmoothed results, resulting from the attempt to optimize the peak signal-to-noise ratio (PSNR). Although a high PSNR of a super-resolved image seems to be desirable, it does not necessarily mean that it is visually or perceptually superior.\nTo improve the high frequency details, which are also of high importance for super-resolution of scientific data, Johnson et al. [22] introduced the concept of perceptual loss, which optimizes the performance regarding the VGG-feature space instead of the PSNR. Furthermore, Ledig et al. [21] switched to a generative adversarial network (GAN) including residual blocks (RBs), called super-resolution GAN (SRGAN), instead of a single CNN, in addition to computing the mean squared error (MSE) in the VGG19-feature space [23] rather than in voxel space. GANs were developed by Goodfellow et al. [24] and aim to learn the unknown data probability distribution of observed data by unsupervised learning, i. e., without any la-\nPreprint submitted to October 31, 2022\nar X\niv :2\n21 0.\n16 24\n8v 1\n[ ph\nys ic\ns. fl\nudy\nn] 2\n8 O\nct 2\n02 2\nbels that are necessary in supervised learning scenarios. They only require access to data samples from the unknown distribution without an explicitly provided data likelihood function. Their training can be also understood as a minimax zero-sum game carried out by two players. The first player, the generator, creates samples that are presented to the second player, the discriminator, which tries to distinguish between generated and real data samples. Both players are coupled by the adversarial loss, and depending on the particular form of this loss term, finding the equilibrium of this game is equivalent to minimize different distance measures between the generator model and the true data distribution. Examples are Kullback-Leibler (KL) divergence, Jensen-Shannon (JS) divergence, and Wasserstein distance [25]. The SRGAN significantly improved the prediction results with respect to visual similarity and high frequency pattern recovery. However, it produced hallucinated artifacts in the images. Consequently, Wang et al. [26] developed the enhanced SRGAN (ESRGAN) to further increase the prediction accuracy. For this, they replaced the RBs by residual in residual dense blocks (RRDBs).\nBode et al. [27, 28, 29] transferred the concept of AI super-resolution to three-dimensional (3-D) turbulence data and developed an AI super-resolution-based subfilter modeling approach for large-eddy simulation (LES) called physicsinformed ESRGANs (PIESRGANs, short: PGs). For that, they advanced ESRGANs by introducing a physically informed loss term and enabling it to efficiently handle 3-D data. The general training happens with pairs of high-fidelity data (\u201dH\u201d), such as from fully resolved direct numerical simulations (DNSs), and corresponding filtered data (\u201dF\u201d). During an LES, the trained network generates so-called reconstructed data (\u201dR\u201d), which are used to calculate unclosed subfilter terms by applying a filter kernel and allow to advance the filtered equations accurately in time. PIERSGAN was first applied to turbulence data and spray combustion [29, 30, 31, 32]. More recently, this approach was extended to finite-rate-chemistry flows [33, 34]. A discussion of advantages and shortcoming of this method is available by Bode [35].\nThis work extends PG to non-premixed flows. Moreover, it is demonstrated how non-uniform meshes affect the reconstruction. To correct the resulting numerical errors, a multi-mesh training approach is introduced, which also helps to apply PG more generally in complex simulation scenarios. Finally, the flexibility of AI super-resolution and required amount of training data are discussed. These are crucial developments in the context of LES. Especially, considering the urgency to fight climate change and the resulting need for more efficient and carbon-neutral energy devices, such as turbines powered by hydrogen and engines burning ammonia, accurate subfilter modeling even for complex flows is absolutely mandatory.\nThis paper is structured as follows. Non-premixed combustion and a non-premixed temporal jet combustion case are outlined in the next section. Afterward, PGs for non-premixed combustion are described. The effect of non-uniform meshes is demonstrated next, and a priori and a posteriori results are presented. A Reynolds number variation and accelerated workflows are subsequently discussed. The paper finishes with con-\nclusions."
        },
        {
            "heading": "2. Description of non-premixed combustion and a nonpremixed temporal jet case",
            "text": "Fuel and oxidizer are initially separated in non-premixed combustion cases, such as in furnaces as well as diesel and jet engines. The governing equations are given in the next section, and afterward, a non-premixed temporal jet case is briefly described, which is used for analysis in this work."
        },
        {
            "heading": "2.1. Governing equations",
            "text": "Simulations of non-premixed combustion are described by conservation equations for mass, species, momentum, and some sort of energy, usually called reactive Navier-Stokes equations (NSEs). Depending on the case sensible specific enthalpy h, specific enthalpy including sensible enthalpy and chemical enthalpy hsc, total specific enthalpy ht, or the corresponding sensible energy are used. For some low-Mach simulations, a simplified temperature equation is very common. The sensible specific enthalpy is defined as\nh = \u222b T\nT0 Cp dT, (1)\nwhere Cp denotes the specific heat capacity at constant pressure and T the temperature with T0 as reference temperature at which the sensible specific enthalpy h0 is defined to be zero. hsc is given as\nhsc = h + ns\u2211 \u03b1=1 \u2206h\u25e6f,\u03b1Y\u03b1 (2)\nwith Y\u03b1 as mass fractions of the ns species and \u2206h\u25e6f,\u03b1 as chemical formation specific enthalpy defined as the enthalpy needed to form 1 kg of a species at the reference temperature Tf,0 = 298.15 K. The kinetic energy needs to be added for the total specific enthalpy as\nht = hsc + 1 2 u \u00b7 u (3)\nwith bold notation for vectors and u as velocity vector. Energy and enthalpy are linked by a pressure-based energy term, such as\net = ht \u2212 p \u03c1\n(4)\nfor the total sensible energy. Here, p is the pressure, and \u03c1 denotes the density.\nConservation of mass over time t reads\n\u2202t (\u03c1) + \u2207 \u00b7 (\u03c1u) = 0 (5)\nwith \u2202t as temporal derivative and the del operator \u2207. The mass conservation for species \u03b1 is\n\u2202t (\u03c1Y\u03b1) + \u2207 \u00b7 ( \u03c1 ( u + VD,\u03b1 ) Y\u03b1 ) = \u03c9\u0307\u03b1 (6)\nwith VD,\u03b1 as diffusion velocity vector of species \u03b1 and \u03c9\u0307\u03b1 as reaction rate of species \u03b1. Here, by definition, the identities\n\u2211ns \u03b1=1 Y\u03b1VD,\u03b1 = 0 and \u2211ns \u03b1=1 \u03c9\u0307\u03b1 = 0 are true. The conservation of momentum is given by\n\u2202t (\u03c1u) + \u2207 \u00b7 (\u03c1uu) = \u2212\u2207 (p) + \u2207 \u00b7 (\u03c4) + \u03c1 ns\u2211 \u03b1=1 Y\u03b1f\u03b1 (7)\nwith f\u03b1 as volume force vector acting on species \u03b1 and viscous stress tensor \u03c4 defined as\n\u03c4 = \u00b5 ( (\u2207 (u) + (\u2207 (u))\u1d40 \u2212 2\n3 \u2207 \u00b7 (u) I\n) (8)\nwith dynamic viscosity \u00b5 and identity tensor I. As example, the conservation of sensible specific enthalpy gives\n\u2202t (\u03c1h) + \u2207 \u00b7 (\u03c1uh) = \u2212 ns\u2211 \u03b1=1 \u2206h\u25e6f,\u03b1\u03c9\u0307\u03b1 + \u2202t (p) + u \u00b7 \u2207 (p) +\n+ \u2207 \u00b7 (\u03bb\u2207 (T )) \u2212 \u2207 \u00b7 \u03c1 ns\u2211\n\u03b1=1\nY\u03b1VD,\u03b1h\u03b1  + \u03c4 : \u2207 (u) + Q\u0307+ + \u03c1\nns\u2211 \u03b1=1 Y\u03b1f\u03b1 \u00b7 VD,\u03b1. (9)\nHere, \u03bb is the thermal conductivity, h\u03b1 denotes the sensible specific enthalpy of species \u03b1, and Q\u0307 describes a volume source term. This set of equations can be solved by selecting a suitable equation of state (EOS) and model for providing species properties, such as the reaction rates, heat capacities, and diffusion velocity vectors."
        },
        {
            "heading": "2.2. Case setup of a non-premixed temporal jet",
            "text": "Denker et al. [36, 37] computed a set of temporally evolving planar non-premixed jets with methane as fuel on a structured mesh denoted by \u03be = (\u03be1, \u03be2, \u03be3)\u1d40 on a domain of size L1 \u00d7 L2 \u00d7 L3. The configuration consists of a fuel stream in the center of a box with two periodic directions (x1- and x3directions) and outlets in cross-stream direction (x2-direction). The fuel stream moves in positive x1-direction and exhibits initial turbulence. Over time, the area of turbulence expands in ydirection. Additionally, mixing between the fuel and surrounding oxidizer stream happens.\nThe database features variations with respect to the Reynolds number, defined as\nRe = V0H0 \u03bdfuel\n(10)\nwith V0 as initial mean jet bulk velocity, H0 as initial jet width, and \u03bdfuel as kinematic viscosity of the fuel. Furthermore, they varied the dilution of the fuel stream, resulting in different stoichiometric mixture fractions Zst. The scalar dissipation rate, which reads \u03c7 = 2D (\u2207 (Z))2 (11) with D as diffusion coefficient, quantifies the local mixing in a flow. If the local scalar dissipation rate is too large, the flame quenches. To better understand quenching in nonpremixed flames was one of the goals of the dataset by Denker et al. [36, 37]. Therefore, the Damko\u0308hler number, given as\nDa = \u03c7qH0 Vc,0\n(12)\nwith \u03c7q = 120 s\u22121 as quenching scalar dissipation rate, is another important parameter. Three of their cases are considered in this work: The \u201dLow Re, high dilution case\u201d, the \u201dIntermediate Re case\u201d, and the \u201dHigh Re case\u201d. As the low dilution case is not used in this work, the three used cases are simply called \u201dLRe\u201d, \u201dIRe\u201d, and \u201dHRe\u201d. The most relevant parameters for the used cases are summarized in Tab. 1. To improve the comparability among the cases, Denker et al. [36, 37] introduced a non-dimensionalized time t\u2217. It is shifted by the duration for which the variance of the scalar dissipation rate at stoichiometric mixture faction is zero. Afterward, it is non-dimensionalized by the jet time, defined as H0/V0.\nThe cases were computed with the low-Mach solver of the code CIAO, which is also used in this work. CIAO is an arbitrary order finite difference code, which solves the NavierStokes equations along with multi-physics effects [38]. It is optimized to efficiently run on central processing unit (CPU)heavy supercomputers [39, 40]. The Poisson equation was solved with the multi-grid solver HYPRE-AMG [41, 42], and species as well as temperature equations were discretized with a fifth-order weighted essentially non-oscillatory (WENO) scheme [43]. Furthermore, those equations employed the symmetric operator split of Strang [44]. The resulting system of ordinary differential equations for the zero-dimensional homogeneous reactor in each grid cell was solved with a fully timeimplicit backward difference method [45, 46]. To simplify the multi-species diffusion, the Hirschfelder and Curtiss approximation [47] was employed with a velocity correction for ensuring species mass conservation. Moreover, the viscous heating was neglected, and changes in the mean pressure were assumed to be small as they are of higher Mach number order. Volume forces and volume source term did not occur. Consequently, a simplified set of momentum, species and temperature equations was solved. It reads\n\u2202t (\u03c1Y\u03b1)+\u2207\u00b7 ( \u03c1 ( u + VH,\u03b1 ) Y\u03b1 ) = \u2207\u00b7 ( \u03c1D\u03b1\nW\u03b1 W \u2207 (X\u03b1)\n) +\u03c9\u0307\u03b1 (13)\nfor species mass conservation with VH,\u03b1 = \u2211ns \u03b1=1 D\u03b1 W\u03b1 W \u2207 (X\u03b1) as correction velocity ensuring species mass conservation after applying the Hirschfelder and Curtiss approximation with W as mean molecular weight, which is computed as \u2211ns \u03b1=1 X\u03b1W\u03b1 with X\u03b1 and W\u03b1 being the mole fraction and molecular weight of species \u03b1. D\u03b1 is the diffusion coefficient, which can be computed from binary mass diffusion coefficients as\nD\u03b1 = 1 \u2212 Y\u03b1\u2211\n\u03b1,\u03b2 X\u03b2/D\u03b2\u03b1 . (14)\nThe conservation of momentum is given by\n\u2202t (\u03c1u) + \u2207 \u00b7 (\u03c1uu) = \u2212\u2207 (p) + \u2207 \u00b7 (\u03c4) . (15)\nThe temperature equation results in\n\u2202t ( \u03c1CpT ) + \u2207 \u00b7 ( \u03c1CpuT ) = \u2212 ns\u2211 \u03b1=1 ( h + \u2206h\u25e6f,\u03b1 ) \u03c9\u0307\u03b1+\n+ \u2207 \u00b7 (\u03bb\u2207 (T )) \u2212 \u03c1\u2207 (T ) \u00b7 \u2207 \u00b7  ns\u2211 \u03b1=1 CpD\u03b1 W\u03b1 W \u2207 (X\u03b1)  . (16) The used mechanism features 28 species and 102 reactions [48] for the oxidation of methane and is complemented by the Zeldovich mechanism for NO formation [49]. To save computing time and increase the numerical dissipation towards the cross-stream outlets, a non-uniform mesh was employed with increasing cell width in cross-stream direction."
        },
        {
            "heading": "3. PIESRGAN for turbulent non-premixed combustion",
            "text": "Rather than solving the fully resolved reactive NSEs as in DNSs, LESs solve a filtered form of the NSEs. Generally, a homogeneous filter operation, which furthermore is assumed to be a Reynolds operator and denoted with an overbar, can be used to define the Reynolds decomposition as\n{\u00b7} = {\u00b7} + {\u00b7}\u2032 (17)\nwith the overbar denoting the filtered part and the prime the subfilter part of a quantity with\n{\u00b7} = {\u00b7}1 = {\u00b7} (18)\nand {\u00b7}\u2032 = 0. (19)\nAdditionally, for flows with variable density, such as reactive flows, the Favre-filtering is commonly defined as\n{\u0303\u00b7} = {\u03c1\u00b7} \u03c1 . (20)\nThe corresponding Favre decomposition reads\n{\u00b7} = {\u0303\u00b7} + {\u00b7}\u2032\u2032. (21)\nHere, the identity \u03c1{\u00b7}\u2032\u2032 = 0 hold but {\u00b7}\u2032\u2032 , 0. For the reactive LES equations, Favre decomposition is introduced in the reactive NSEs, and a Reynolds filter is applied to all terms. This leads to\n\u2202t (\u03c1) + \u2207 \u00b7 ( \u03c1u\u0303 ) = 0 (22)\nfor the mass conservation, \u2202t ( \u03c1Y\u0303\u03b1 ) + \u2207 \u00b7 ( \u03c1u\u0303Y\u0303\u03b1 ) = \u2207 \u00b7 ( \u03c1VD,\u03b1Y\u03b1 \u2212 u\u2032\u2032Y\u03b1\u2032\u2032 ) + \u03c9\u0307\u03b1 (23)\nfor the species mass conservation,\n\u2202t ( \u03c1u\u0303 ) +\u2207\u00b7(\u03c1u\u0303u\u0303) = \u2212\u2207 (p)+\u2207\u00b7(\u03c4 \u2212 \u03c1u\u2032\u2032u\u2032\u2032)+\u03c1 ns\u2211\n\u03b1=1\nY\u03b1f\u03b1 (24)\nfor the momentum conservation, and \u2202t ( \u03c1\u0303h ) + \u2207 \u00b7 ( \u03c1u\u0303\u0303h ) = \u2202t (p) + u \u00b7 \u2207 (p)+\n+ \u2207 \u00b7 ( \u03bb\u2207 (T ) \u2212 \u03c1u\u2032\u2032h\u2032\u2032 ) \u2212 \u2207 \u00b7 \u03c1 ns\u2211 \u03b1=1 Y\u03b1VD,\u03b1h\u03b1  + + \u03c4 : \u2207 (u) + Q\u0307 + \u03c1\nns\u2211 \u03b1=1 Y\u03b1f\u03b1 \u00b7 VD,\u03b1 (25)\nfor the conservation of the sensible specific enthalpy. PG-based subfilter models can be used to systematically close all terms in the filtered NSEs. The algorithm and details are discussed next."
        },
        {
            "heading": "3.1. Loss function",
            "text": "The loss function is the target function of the problem which is minimized by the optimization solver. PG extends traditional loss functions by a physically motivated term, which prioritizes the fulfillment of important flow conditions, such as mass and species conservation, in the generated data. For example, a violation of the mass conservation condition usually leads to blowing up simulations and therefore the described weak enforcement is required. The loss function reads\nL = \u03b21Ladversarial + \u03b22Lpixel + \u03b23Lgradient + \u03b24Lphysics, (26)\nwhere \u03b21, \u03b22, \u03b23, and \u03b24 are coefficients weighting the different loss term contributions. Ladversarial is the discriminator/generator relativistic adversarial loss [50]. It measures both how well the generator is able to create data and how well the discriminator is able to identify fake data. Lpixel is defined using the meansquared error (MSE) of the quantity. Lgradient computes the MSE of the gradient of a quantity. The physical loss term is\nLphysics = \u03b241Lmass + \u03b242Lspecies + \u03b243Lelements, (27)\nwhere \u03b241, \u03b242, and \u03b243 are coefficients weighting the different physical loss term contributions. It accounts for mass conservation, species conservation, and elements conservation. Bode [33] and Bode et al. [34] pointed out that elements conservation was not required for their application cases. It turned out that this is dependent on the chemical reaction mechanism and the combustion regime. For the mechanism employed in this work, the elements loss term improved the prediction accuracy considerably. Both sets of weighting coefficient sum up to unity as \u2211 i \u03b2i = 1 and \u2211 i \u03b24i = 1."
        },
        {
            "heading": "3.2. Architecture",
            "text": "The PG architecture is depicted in Fig. 1. Training is done with pairs of data (\u03c6H and \u03c6F), which are computed in a prestep if training is done with DNS data. The generator creates the reconstructed data \u03c6R with \u03c6F as input. \u03c6H is used to evaluate all loss function terms. Both generator and discriminator use 3-D CNN layers (Conv3D) [51] with kernel size of 3 and stride 1 combined with leaky rectified linear unit (LeakyReLU) layers for activation [52]. Furthermore, the generator features a\nresidual in residual dense block (RRDB), which contains fundamental architectural elements such as residual dense blocks (RDBs) with skip-connections, an extended residual block (RB) with dense connections inside. Also, residual scaling factors \u03b2RSF are included in order to avoid instabilities in the forward and backward propagation. On the other hand, the discriminator has additional layers for batch normalization (BN) as well as a dropout with dropout factor \u03b2dropout and a final dense layer (Dense). In total, the generator has 80 layers, while the discriminator has only 28 layers for all cases considered in this work."
        },
        {
            "heading": "3.3. Hyperparameters",
            "text": "The hyperparameters are summarized in Tab. 2, which were optimized as described by Bode [33] in the context of species splitting. In addition to loss functions focussing on single time steps, multi-time step terms were employed. Generally, it was found that the network gives good results in a wider range of hyperparameters. Furthermore, a working hyperparameter set usually also gives good results for other related cases."
        },
        {
            "heading": "3.4. Species splitting",
            "text": "Species splitting as introduced by Bode [33] was used for the production runs in this work. Consequently, the set of species was split into primary and secondary species. While the secondary species were updated at the same time as the velocities, the update of the primary species is shifted by a half time step. Furthermore, the prediction accuracy for the primary species is improved by solving an additional transport equation on the reconstructed mesh. Table 3 lists the maximum mass fraction of each species at the later time of the HRe case to give an impression of the impact of each species on quantities such as the mixture fraction. The AutoML optimization for the case considered in this work resulted in N2, CH4, OH, H2, CO, CO2, and C2H3 as set of primary species."
        },
        {
            "heading": "3.5. Algorithm",
            "text": "Once the PG is trained, it is used to reconstruct all required data fields during every time step of a LES. This is part of a\nTable 3: Overview of the maximum mass fraction of each species at the later time for the HRe case.\nSpecies name \u03b1 Maximum mass fraction max\n(\nY late\u03b1\n)\nN2 9.2385 \u00d7 10\u22121 O2 2.3218 \u00d7 10\u22121 H 2.3023 \u00d7 10\u22124\nOH 2.3831 \u00d7 10\u22123 O 1.7899 \u00d7 10\u22123 H2 1.5442 \u00d7 10\u22123\nH2O 7.3748 \u00d7 10\u22122 HO2 1.3227 \u00d7 10\u22124 H2O2 2.5066 \u00d7 10\u22125 CO 3.1203 \u00d7 10\u22122 CO2 8.9805 \u00d7 10\u22122 CH 7.2214 \u00d7 10\u22126 CHO 1.2616 \u00d7 10\u22125 CH2 1.4534 \u00d7 10\u22125 CH2O 9.5527 \u00d7 10\u22124 CH3 1.0196 \u00d7 10\u22123 CH4 6.4785 \u00d7 10\u22122 C2H6 1.6349 \u00d7 10\u22123 C2H 5.1554 \u00d7 10\u22127 C2H2 3.3181 \u00d7 10\u22123 CHCO 6.7805 \u00d7 10\u22124 C3H3 5.9328 \u00d7 10\u22125 C2H3 2.3725 \u00d7 10\u22125 C2H4 1.3775 \u00d7 10\u22123 C2H5 8.2346 \u00d7 10\u22125 C3H4 6.6200 \u00d7 10\u22124 C3H5 2.4880 \u00d7 10\u22124 C3H6 9.0631 \u00d7 10\u22124\nN 2.9127 \u00d7 10\u221210 NO 3.4859 \u00d7 10\u22126\nmulti-step algorithm which computes all unclosed terms in the LES equations systematically. The algorithm starts with the LES solution \u03a6nF at time step n, which includes the entirety of all fields in the simulation except the primary species, and the LES solution of the primary species \u039en+1/2F at time step n + 1/2. It consists of repeating the following steps:\n1. Use the PG to reconstruct \u03a6nR from \u03a6 n LES with \u039e n+1/2 F as\nadditional information. 2. Use \u03a6nR to estimate the unclosed terms \u03a8 n LES in the LES\nequations for all \u03a6 fields by applying a filter operator. 3. Use \u03a8nLES and \u03a6 n LES to advance the LES equations of \u03a6 to\n\u03a6n+1LES. 4. Use the PG to reconstruct \u039en+1/2R from \u039e n+1/2 LES . 5. Use \u039en+1/2R to update the fields of \u039e to \u039e n+1/2;update R by solv-\ning the unfiltered scalar equations on the mesh of \u039en+1/2R with \u03a6nR as additional information. 6. Use \u039en+1/2;updateR to estimate the unclosed terms \u0393 n+1/2 LES in\nthe LES equations of \u039e for all fields by evaluating the local terms with \u039en+1/2;updateR , \u03a6 n F, \u03a6 n+1 F , and \u03a6 n R as well as applying a filter operator.\n7. Use \u0393n+1/2LES and \u039e n+1/2 LES to advance the LES equations of \u039e\nto \u039en+3/2LES ."
        },
        {
            "heading": "3.6. Training process",
            "text": "The RMSProp solver, relying on the stochastic gradient descent (SGD) approach, was used as optimizer during training in this work. Stability issues are the main problem during the training process of complex networks and especially GANs. In addition to standard difficulties in training deep neural networks which are due to traversing highly complex landscapes of the loss function spanned by the network, the intricate interplay of the two components of GANs, discriminator and generator, leads to further vulnerabilities during the training process. Standard techniques, such as adaptive learning rates, were employed in this work. Furthermore, it was found that normalization is crucial for the training success. Turbulent fluctuating fields were zero mean-centered and rescaled with their rootmean-square deviation (RMSD) value. The magnitude of the mass fraction fields were aligned with an estimate for the maximum value, mapping all fields between zero and about one.\nThe training with multiple cases, i.e., LRe and HRe for the application case in Sec. 5.1, is particularly challenging and sometimes, the loss function does not decrease further, as a local (non-optimum) minimum was found. Slightly disturbing the beta coefficients in Eqs. 26 and 27 helped to overcome this lock and further improve the solution.\nGenerally, the networks were initialized with the solution for decaying turbulence for varying Reynolds numbers from Bode et al. [29]. One way to improve the stability during the training process is to only update the generator network weights afterward. This makes it more difficult for the network to deviate from the solution of fully homogeneous isotropic turbulence (HIT), which was used for the decaying turbulence case. In this view, the discriminator supervises that the solution remains close to a turbulent solution, which might be also a problem for some cases, but gave good results in this work. An advantage\nof this approach is that one degree of freedom for the training process is eliminated, making the training more handy.\nFurthermore, it was found that it is essential to use consistent (high-order) numerics during the training process, such as for evaluating the loss function terms. Otherwise small numerical errors accumulate during the training process leading to deviations compared to the DNS solution. One way to check the quality of the achieved results is by means of the energy spectrum. If the numerics are not consistent and accurate enough, deviations for high wavenumbers are inevitable."
        },
        {
            "heading": "3.7. Runtime execution",
            "text": "On runtime, the same normalization as during training should be used. In order to efficiently execute the computations, reconstruction of data fields and consecutive filtering should be done on GPUs."
        },
        {
            "heading": "3.8. Implementation details",
            "text": "A PG implemented as part of a TensorFlow/Keras framework [53, 54] was used in this work. It was coupled to the simulation code CIAO employing the TensorFlow C API. During training and execution, subboxes were considered to reduce the memory requirements. A subbox size of 16 \u00d7 16 \u00d7 16 gave good results. In general, larger subboxes increase the accuracy, however, also super-linearly increase the computing cost.\nTraining can be done with stored data or on-the-fly along with a DNS. On-the-fly training is more efficient as storing cost can be reduced, which are usually non-negligible for large cases. Especially, if transient processes need to be learnt, the requirements with respect to the temporal resolution can be problematic. Additionally, on-the-fly training can be a smart usage of GPUs for simulation codes which cannot natively make use of GPUs, but need to run on computing clusters where all nodes are equipped with GPUs. Moreover, on-the-fly training can improve the convergence of the training process, as the transition is \u201dquasi-continuous\u201d and not discrete due to the storing frequency. An issue with respect to on-the-fly training is that data\nare only available once, which makes iterative update processes difficult.\nA base implementation of PG can be found on GitLab (https://git.rwth-aachen.de/Mathis.Bode/PIESRGAN.git), and a detailed discussion of computational aspects is given by Bode [55]."
        },
        {
            "heading": "4. PIESRGAN for non-uniform meshes",
            "text": "Bode et al. [29] did not discuss the effect of non-uniform meshes on PG-subfilter modeling. However, it can be expected that the model is mesh dependent, especially if a meshdependent filter is employed, whose filter width implicitly is subject to the local cell size. The mesh is also critical during up- and downsampling, as the LES has typically a much coarser mesh than the DNS. Obviously, it is not possible to do the reconstruction on the LES mesh, as it is not able to resolve the added information.\nThe effect can be discussed by introducing multiple meshes and mesh operators: The LES mesh DLES, the DNS mesh DDNS, the mesh for the reconstruction DR, the mesh after filtering the DNS data DF, the mesh after filtering the reconstructed data DRF, the mesh operator to interpolate the values on the LES mesh to the DNS mesh (DLES \u2192 DDNS) ILES\u2192DNS, the mesh operator to filter the data discretized on the mesh for the reconstruction, evaluate the unclosed terms, and store the resulting field on a mesh for filtering (DR \u2192 DRF) FR\u2192RF, the mesh operator to interpolate the values on the mesh for filtering to the LES mesh (DRF \u2192 DLES) IRF\u2192LES, and the mesh operator to filter the data discretized on the DNS mesh and store the resulting field on a mesh for filtering (DDNS \u2192 DF) FDNS\u2192F. Bode et al. [29] used a PG to reconstruct data discretized on the DNS mesh on the mesh for reconstruction, denoted as PDNS\u2192R.\nUsing these notations, computing data pairs for training can be expressed as FDNS\u2192F \u25e6 DDNS, (28) which maps DLES \u2192 DF. The trivial implementation used for execution is\nIRF\u2192LES \u25e6FR\u2192RF \u25e6PDNS\u2192R \u25e6ILES\u2192DNS \u25e6 DLES. (29)\nThis results in DLES \u2192 DDNS \u2192 DR \u2192 DRF \u2192 DLES. Bode et al. [29] chose DF = DR = DDNS, as their DNS data used a uniform mesh with cubes and in order to support the evaluation of the loss function terms. Furthermore, they used DRF = DLES, which is only correct if the LES uses a uniform mesh. This reduces the number of different meshes involved but has three major limitations: First, it only works for uniform meshes, as the effect of the non-uniform mesh on the filter is not considered. Second, the DNS mesh might be very large and thus using the DNS mesh as basis mesh can be difficult from a memory usage point of view. Finally, the additional interpolation operators, which need to be employed on runtime, can be expensive and introduce further numerical errors. Note that subboxes of the domain are used for training and reconstruction, i. e., the mesh resolutions must match, however, the minimum and maximum global values of the meshes do not need\nto match, and full meshes are assembled by subboxes. As described earlier, this is important for computational reasons, but also essential for making the network generally employable for different cases.\nTo overcome the limitations with respect to non-uniform meshes, a new computational domain \u2126 is defined as base mesh with the coordinates \u03be = (\u03be1, \u03be2, \u03be3)\u1d40. \u2126 is a rectangular algebraic mesh with uniform grid spacing in all directions. This is in contrast to the other defined meshes, which can be any kind of mesh, as long as a uni-directional mapping between D (with coordinates x = (x1, x2, x3)\u1d40) and \u2126 exist, i. e., the transformation can be done by a simple tensor operation. The resolution of \u2126 should be chosen similar to finest resolution in the DNS mesh. To account for the different meshes during training, the Jacobian is introduced as\nJ = \u03b4x \u03b4\u03be\n(30)\nand computed in every mesh cell. The Jacobian is used as additional input field for the PG reconstruction, which reconstructs from DLES to \u2126, denoted as PLES\u2192\u2126. Furthermore, the mesh operator to filter the data discretized on the computational domain, evaluate the unclosed terms, and store the resulting field on the LES mesh (\u2126\u2192 DLES) F\u2126\u2192LES is introduced. The execution process becomes\nF\u2126\u2192LES \u25e6PLES\u2192\u2126 \u25e6 DLES. (31)\nThe additional input field J is used by the network to consider the effect of the local mesh resolution. As it is impossible to train the network with all relevant J values, if the LES changes its local mesh size continuously or adaptively, the network needs to be enabled to do some kind of interpolation with respect to the filter width. For some particular filter kernels, this can be done analytically. However, it is more flexible to integrate this interpolation in the GAN. Therefore, the GAN is always trained with two data triples with different J, corresponding to different mesh resolution of \u2126, in this work. As will be shown in the next section, this significantly improves the results on non-uniform meshes, such as the target non-premixed temporal jet case in this work. However, this also increases the training cost, as multiple meshes need to be considered.\nThe described approach for non-uniform meshes has another advantage. If multiple datasets with different resolutions, such as turbulence data with different Reynolds numbers, are used for training, multiple mesh resolutions can be used for training without initial interpolation, employing the Jacobian approach."
        },
        {
            "heading": "4.1. Effect of non-uniform meshes",
            "text": "The effect of the non-uniform mesh is discussed by means of the HRe case, which features uniform meshes in the x1- and the x3-direction. The mesh in x2-direction is uniform in the center but the mesh increment increases towards the boundaries. A relative error based on the velocity field is defined as\n\u2217 = L2\n\u222b L1 \u222b L3 \u221a (uR \u2212 uH) \u00b7 (uR \u2212 uH) dx3 dx1\u222b\nL1 \u222b L2 \u222b L3 \u221a uH \u00b7 uH dx3 dx2 dx1\n. (32)\nFigure 2 shows the relative errors plotted as function of x2 for the simple algorithm (cf. Eq. 29) and the corrected algorithm with Jacobian as input (cf. Eq. 31). Furthermore, the mesh increment in x2-direction is plotted. While the corrected algorithm gives accurate results, the simple algorithm shows deviations which seem to correlate with the mesh increment in x2-direction. As the finer resolution in the center was used for training with the simple algorithm, the network seems to add the wrong amount of information in the stretched areas. The result is remarkable for two reasons: First, the accuracy of the corrected algorithm over the full width is very good. Second, the error introduced in the stretched regions by the simple algorithm is surprising, as the flow field is very weak there and not turbulent."
        },
        {
            "heading": "4.2. A priori testing",
            "text": "To evaluate the prediction accuracy of PG for the nonpremixed jet case, a priori results are discussed by means of cases LRe and HRe. A separate network was used for each case. The networks were trained with multiple time steps from the case. To have a weak distinction between training and test data, the time step used for testing was not used for training. This is not optimal, however, as only one realization per case exists, further distinction between training and test data was not possible. For the cases presented in the application section, a better distinction between training and testing data was ensured.\nThe analysis is done by means of mass fraction fields, velocity component fields, mixture fraction fields, and scalar dissipation rate fields. The time staggering is a double problem here: First, not all mass fractions are stored at the same time, as they are shifted by a half time step due to the species splitting. This was not done in the original DNS, which requires the original DNS data for these mass fractions to be interpolated in time using two consecutive time steps. Second, the mixture fraction and consecutively scalar dissipation rate are not solved quantities but computed by means of the solved mass fractions. Therefore, the mass fractions need to be interpolated to the same time step. As the primary species are the dominant species, the secondary species were interpolated by a half time\nstep, using two reconstructed data fields, which required three DNS time steps.\nTo get a first qualitative impression of the PG prediction and the evolution of the cases themselves, as well as the differences between the cases, Fig. 3 and Fig. 4 show two time snapshots for each case. 2-D cuts of the mixture fraction Z, the scalar dissipation rate \u03c7, and the temperature T are shown in three versions: the fully resolved data from DNSs, the filtered data, and the reconstructed data computed with PGs using the filtered data as input. It is notable that the first two fields are not directly solved in the simulations/reconstructions. Instead they are computed by means of the mass fraction fields. Both cases show an increased mixing of fuel and oxidizer stream over time. The turbulent area strongly increases in x2 direction over time. As expected, the mixing is much stronger in the case with high Reynolds numbers. The filtered data represent data filtered with a medium sized filter stencil width. Even though the filtering does not change the main character of the flow, it is obvious that small scale structures vanish by smoothing. The visual agreement between fully resolved data and reconstructed data is very good.\nA quantitative assessment of the prediction quality is discussed in the next sections by means of PDFs. All PDFs show a very strong peak at zero, representing, e. g., inert or laminar regions. This peak is not shown in the plots by choosing the ordinate accordingly."
        },
        {
            "heading": "4.2.1. Mixture fraction",
            "text": "The mixture fraction is one of the main indicators in nonpremixed combustion. As fuel and oxidizer are originally separated, mixing must take place before chemistry can happen. The mixture fraction was neither directly solved in the DNS nor during the reconstruction. Instead, it was computed by means of the mass fraction fields, which were solved and reconstructed, respectively.\nFig. 5 shows the PDFs for the mixture fractions for LRe and HRe at two time steps each indicated by the used symbols: triangles mark the earlier time step and boxes mark the later time step. Filtering results with three different filter stencil widths are shown with \u22061 < \u22062 < \u22063. The qualitative temporal evolution is similar for both cases. The peak of the PDFs shifts from Z = 1 to smaller values as mixing occurs. This process is further for the HRe case, which is expected by the higher Reynolds number. However, also note that the cases do not exactly represent the same time. The effect of the filter is visible but not too strong. The larger the filter width, the stronger are the differences, as especially visible for the later time step of LRe. The reconstruction result is very good."
        },
        {
            "heading": "4.2.2. Scalar dissipation rate",
            "text": "The scalar dissipation describes the local rate of mixing. Physically, it is very important as quenching occurs for too large scalar dissipation rates, as the mixing is too fast. For the conditions considered here, quenching happens for scalar dissipation rates larger than \u03c7q = 120 s\u22121. The scalar dissipation rate is numerically very challenging: First, it shows multi-scale behavior, and thus, multiple scales need to be predicted correctly.\nSecondly, the scalar dissipation rate is a derived quantity, and more importantly, is proportional to the squared gradient of the mixture fraction, which itself relies on all mass fractions. The gradient is very difficult to predict, as already small local deviations in the mixture fraction lead to potentially large deviations in the scalar dissipation rate. The PDFs are shown as log-log\nplot in Fig. 6 for both cases, LRe and HRe. The filtering removes turbulent fluctuations, which can be clearly seen by the lack of very high scalar dissipation rates in the filtered data. In terms of quenching, this is crucial. The indicated quenching dissipation rate reveals that quenching would not occur in the filtered data but in the DNS, and thus the underlying physics are changed. Again, the reconstruction seems to be good for all cases, however, it should be noted that small deviations are difficult to see due to the log-log representation."
        },
        {
            "heading": "4.2.3. Species prediction",
            "text": "As last a priori test, the PDFs of the mass fractions of two different species are shown in Fig. 7 and Fig. 8 for LRe and HRe at two time steps each. While CO is a primary species for the PG reconstruction, CH2O is a secondary species. CO increases\ntowards higher mass fraction values over time, as can be clearly seen in all PDFs. The behavior for CH2O is qualitatively different. While it evolves from a PDF with two smaller peaks at the earlier time step of HRe to a PDF with one distinctive peak at the later time step, this evolution cannot be seen for LRe. However, the two peaks of the PDF in the shown ordinate increase significantly. As before, the agreement between DNS data and reconstructed data is very good for all cases."
        },
        {
            "heading": "4.3. A posteriori testing",
            "text": "The a priori results in the previous section demonstrated that PG is able to very accurately reconstruct the DNS data using only the filtered data as input. However, high accuracy in a priori tests is much simpler to achieve than good accuracy in a posteriori tests. Even small errors in a priori, which are hardy visible, can accumulate over time in a posteriori tests or blowup the simulation. Therefore, it is highly recommended to introduce also a posteriori metrics in the training process. Fully optimizing the accuracy in an a priori sense only often does not lead to good a posteriori results in the long run.\nAll a posteriori results discussed here used all three filter stencil widths to correct for the non-uniform mesh. The a posteriori simulations were initialized with the DNS results at t\u2217 = 5. I. e., the a posteriori tests were initialized with a rather \u201dstable\u201d state and the more fluctuating initial phase was skipped."
        },
        {
            "heading": "4.3.1. Surface area",
            "text": "For both cases, the mixing increases the iso-surface with stoichiometric mixture fraction over time, as turbulence and mixing lead to rugged structures. As this iso-surface is where the oxidation takes place, i. e., where the flame sits, it is a very important metric to evaluate the accuracy of the PG-LES. Fig. 9 shows the temporal evolution of the normalized iso-surface with stoichiometric mixture fraction. The normalization was done with the initial area 2L1L3. The agreement for HRe is very good. The temporal evolution of LRe is too weak, leading to an underpredicted iso-surface area. It was not possible to identify a reason for the difference, as the level of turbulence was correctly predicted, but it shows how fragile the complex interplay between DNS data and PG-LES is."
        },
        {
            "heading": "4.3.2. Scalar dissipation rate",
            "text": "To further evaluate the a posteriori accuracy of the presented method, Fig. 10 shows the temporal evolution of the normalized scalar dissipation rate averaged over all locations with stoichiometric mixture fraction for LRe and HRe, which is an important quantity to predict quenching. The prediction accuracy for HRe is still very good, even though not as good as for the area prediction in Fig. 9, emphasizing the complex nature of this metric. In contrast, the prediction accuracy is slightly better for LRe\ncompared to the area prediction. However, at later times, the deviation in the area prediction result in a slight overprediction here, as the underlying iso-surface of stoichiometric mixture is not accurately predicted. Overall, the PG-LES prediction quality is very good and much better than what could have been expected with classical LES models."
        },
        {
            "heading": "4.3.3. Effect of primary species",
            "text": "Bode [33] introduced the species splitting in the context of PG-LES. One advantage of their approach can be easily demonstrated by the non-premixed combustion case in this work. For that, a PG was trained in which all species are secondary species, i. e., no additional equations are solved on the reconstructed mesh. This GAN is used to advance the HRe towards the later time step discussed earlier, and the PDF of the scalar dissipation rate is shown in Fig. 11. A PG employing primary and secondary species is able to accurately predict the PDF of the scalar dissipation rate at the later time step. The PG in which all species are secondary species is not able to predict the PDF of the scalar dissipation rate correctly, and a clear deviation is visible at about 1 \u00d7 10\u22123 s\u22121. Small normally distributed errors are the reason for this deviation and accumulate over time."
        },
        {
            "heading": "4.3.4. Effect of discriminator",
            "text": "GANs distinguish themselves from other ML/DL approaches by combining two networks during training. This has the disadvantage that it becomes more difficult to train the GAN, as the discriminator can be a source for diverging behavior. However, GANs are known to have a very good prediction accuracy. Furthermore, Bode et al. [29] discussed how the discriminator can be used to drive the training process in situations lacking highly\naccurate data. Precise and fair comparisons with and without discriminator are always difficult, as the training process has an effect on the prediction quality, and it is often only optimized for one type of network. Also the comparison in Fig. 12 has this shortcoming, as the training of PG-LES, i. e., training of the full GAN, is highly optimized, while training of CNN-LES, i. e., using the generator of PG only, employed the same training strategy, which might be not perfect. As a result, the averaged scalar dissipation rate at stoichiometric mixture is slightly underpredicted and the peak is clearly shifted to a later time. The reason is that the CNN-LES is not able to predict the level of turbulence as accurate as the PG-LES, i. e., it underpredicts the turbulent intensity, leading to a smaller averaged mixing rate."
        },
        {
            "heading": "5. Application",
            "text": "This section demonstrates the introduced method on two application cases. First, a PG which was trained with combined data from LRe and HRe is applied to IRe to prove the important intra-case capability of the method. Second, the amount of required training data is discussed, which is important to use PGs to accelerate simulation workflows."
        },
        {
            "heading": "5.1. Reynolds number variation",
            "text": "To demonstrate the intra-case capabilities of the PG-LES approach, a single PG was trained with data from the LRe and HRe cases. The discriminator network was initialized from the decaying Reynolds number case by Bode et al. [29] to better enable multiple Reynolds number. The generator of the GAN was then updated with the LRe and HRe data. The results presented in Fig. 13 show that the network trained with the combined data, i. e., trained without the data of the actual case, gives good results in the considered a priori test."
        },
        {
            "heading": "5.2. Accelerated simulation workflow",
            "text": "The purpose of traditional LES is often to reduce the cost of simulations to make them feasible or accelerate development workflows compared to DNS. If this idea is followed for PGs, the cost for computing the training data and the training itself needs to be considered. From that point of view, it is advantageous to use PGs in scenarios which require many LES realizations. The more realizations are needed to determine a statistical effect, the better in terms of computing cost for PG, as\ncost for training data and training only occur once. Bode et al. [34] used PG to evaluate cycle-to-cycle variations (CCVs) in premixed kernels under engine conditions and demonstrated this advantage.\nThe high prediction accuracy of PGs demonstrated in this work but also shown earlier [29, 31, 33, 34] motivates another way to accelerate simulations, as will be discussed by means of the HRe case. The HRe case needs a very large domain with 1280 \u00d7 960 \u00d7 960 cells for multiple reasons. First, the local resolution needs to fully resolve the turbulent structures and flame. Second, the boundaries in x2-direction needs to be distant enough to not disturb the flow. Finally, the x1- and x3-directions need to be large enough to fit the largest turbulent scales but also large enough to give sufficient statistics, as statistics are typically evaluated over x1x3-planes in a planar temporal jet as considered here. I. e., compared to a spatially evolving jet, which increases the statistical accuracy by running longer in time, the temporally evolving jet improves its statistics by increasing the number of cells in the domain. This raises the question whether the case used for training also needs to be large for statistical reasons or whether it can be run with a reduced domain, as the statistics are finally computed on the PG-LES data, which mimic larger domains. To evaluate this question, the original setup of the HRe case was recomputed with a reduced domain size and consequently reduced number of cells in x2-direction. Reductions to 5 %, 10 %, and 20 % of the original case were considered. The resulting workflow is: Compute a reduced case. Use the reduced case to train the PG network. Run PG-LES on a mesh corresponding to the DNS setup at its original size and compare the results. This is shown in Fig. 14. Four different realizations were trained for 5 % and 10 %, and two different realizations were trained for 20 %. The 5 %-PG-LES is not able to accurately reproduce the DNS data. The very slim DNS setup affects the turbulent field in the simulation, leading to a clear underprediction of the local turbulence intensity. Note that especially for the 5 % training, it is difficult to achieve PG-LES which do not blow up, however, only realizations which did not blow up were considered for Fig. 14. The results based on the 10 % training domain are already not too bad and mostly predict the trends correctly. For 20 %, the results converge towards the results achieved with the full training domain. This becomes also clear from Fig. 15, which shows the over all data points shown averaged error per case compared to the DNS data relatively to the error from the case trained with the full domain, defined as\n\u2217c = |\u03b4p| \u2212 |\u03b4100| |\u03b4100|\n(33)\nwith \u03b4 as deviation of each PG-LES data point from the DNS data points and p as domain size in percentage, i. e., 100 denotes the full DNS domain."
        },
        {
            "heading": "6. Conclusions",
            "text": "This paper extends the methodology of PG-LESs and applies PG-LES to a non-premixed combustion temporal jet case.\nThe presented generalization with respect to underlying meshes shows high accuracy and is especially important for target cases with complex geometries. The given a priori and a posteriori results emphasize the high prediction quality of the PG-LES approach which is remarkable considering the complexity of the model finite-rate-chemistry flow. Overall, PG-LES seems to be a very promising approach to accelerate the development of future flow-driven applications, such as the next generation of turbines and engines.\nAs the prediction quality of PG-LES was shown to be already high, the remaining main issue is the complexity of training suitable networks. Currently, there is no guarantee that a trained network gives good results, and typically multiple networks need to be trained to find one well-working one. New approaches simplifying this procedure would be desired. Moreover, limits in terms of extrapolation capabilities of GANs should be addressed in more detail in the future."
        },
        {
            "heading": "Acknowledgements",
            "text": "The author acknowledges computing time grants for the projects JHPC55 and TurbulenceSL by the JARA-HPC Vergabegremium provided on the JARA-HPC Partition part of\nthe supercomputer JURECA at Ju\u0308lich Supercomputing Centre, Forschungszentrum Ju\u0308lich, the Gauss Centre for Supercomputing e.V. (www.gauss-centre.eu) for funding this project by providing computing time on the GCS Supercomputer JUWELS at Ju\u0308lich Supercomputing Centre (JSC), and funding from the European Union\u2019s Horizon 2020 research and innovation program under the Center of Excellence in Combustion (CoEC) project, grant agreement no. 952181."
        }
    ],
    "title": "Applying Physics-Informed Enhanced Super-Resolution Generative Adversarial Networks to Turbulent Non-Premixed Combustion on Non-Uniform Meshes and Demonstration of an Accelerated Simulation Workflow",
    "year": 2022
}