{
    "abstractText": "Given the proximity of many wireless users and their diversity in consuming local resources (e.g., data-plans, computation and energy resources), device-to-device (D2D) resource sharing is a promising approach towards realizing a sharing economy. This paper adopts an easy-to-implement greedy matching algorithm with distributed fashion and only sub-linear O(logn) parallel complexity (in user number n) for large-scale D2D sharing. Practical cases indicate that the greedy matching\u2019s average performance is far better than the worst-case approximation ratio 50% as compared to the optimum. However, there is no rigorous average-case analysis in the literature to back up such encouraging findings and this paper is the first to present such analysis for multiple representative classes of graphs. For 1D linear networks, we prove that our greedy algorithm performs better than 86.5% of the optimum. For 2D grids, though dynamic programming cannot be directly applied, we still prove this average performance ratio to be above 76%. For the more challenging Erdos-R\u00e9nyi random graphs, we equivalently reduce to the asymptotic analysis of random trees and successfully prove a ratio up to 79%. Finally, we conduct experiments using real data to simulate realistic D2D networks, and show that our analytical performance measure approximates well practical cases.",
    "authors": [
        {
            "affiliations": [],
            "name": "Shuqin Gao"
        },
        {
            "affiliations": [],
            "name": "Costas A. Courcoubetis"
        },
        {
            "affiliations": [],
            "name": "Lingjie Duan"
        }
    ],
    "id": "SP:585ef5273a2feaf2d9f5a390f24e3ca455e109d2",
    "references": [
        {
            "authors": [
                "S. Gao",
                "C.L. Duan"
            ],
            "title": "Courcoubetis,\u201cAverage-Case Analysis of Greedy Matching for D2D Resource Sharing,",
            "venue": "19th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOPT),",
            "year": 2021
        },
        {
            "authors": [
                "X. Wang",
                "L. Duan",
                "R. Zhang"
            ],
            "title": "User-Initiated Data Plan Trading via a Personal Hotspot Market",
            "venue": "IEEE Transactions on Wireless Communications, vol. 15, no. 11, pp. 7885-7898, Nov. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "L. Zheng",
                "C. Joe-Wong",
                "C.W. Tan",
                "S. Ha",
                "M. Chiang"
            ],
            "title": "Secondary markets for mobile data: Feasibility and benefits of traded data plans",
            "venue": "2015 IEEE Conference on Computer Communications (INFOCOM), Kowloon, 2015, pp. 1580-1588.",
            "year": 2015
        },
        {
            "authors": [
                "L. Pu",
                "X. Chen",
                "J. Xu",
                "X. Fu"
            ],
            "title": "D2D Fogging: An Energy-Efficient and Incentive-Aware Task Offloading Framework via Networkassisted D2D Collaboration",
            "venue": "IEEE Journal on Selected Areas in Communications, vol. 34, no. 12, pp. 3887-3901, Dec. 2016, doi: 10.1109/JSAC.2016.2624118.",
            "year": 2016
        },
        {
            "authors": [
                "X. Chen",
                "L. Pu",
                "L. Gao",
                "W. Wu",
                "D. Wu"
            ],
            "title": "Exploiting Massive D2D Collaboration for Energy-Efficient Mobile Edge Computing",
            "venue": "IEEE Wireless Communications, vol. 24, no. 4, pp. 64-71, Aug. 2017.",
            "year": 2017
        },
        {
            "authors": [
                "Y. Guo",
                "L. Duan",
                "R. Zhang"
            ],
            "title": "Cooperative Local Caching Under Heterogeneous File Preferences",
            "venue": "IEEE Transactions on Communications, vol. 65, no. 1, pp. 444-457, Jan 2017.",
            "year": 2017
        },
        {
            "authors": [
                "D. Wu",
                "L. Zhou",
                "Y. Cai",
                "Y. Qian"
            ],
            "title": "Collaborative Caching and Matching for D2D Content Sharing",
            "venue": "IEEE Wireless Communications, vol. 25, no. 3, pp. 43-49, JUNE 2018, doi: 10.1109/MWC.2018.1700325.",
            "year": 2018
        },
        {
            "authors": [
                "L. Jiang",
                "H. Tian",
                "Z. Xing",
                "K. Wang",
                "K. Zhang",
                "S. Maharjan",
                "S. Gjessing",
                "Y. Zhang"
            ],
            "title": "Social-aware energy harvesting deviceto-device communications in 5G networks",
            "venue": "IEEE Wireless Communications, vol. 23, no. 4, pp. 20-27, August 2016.",
            "year": 2016
        },
        {
            "authors": [
                "A. Dhungana",
                "E. Bulut"
            ],
            "title": "Peer-to-peer energy sharing in mobile networks: Applications, challenges, and open problems",
            "venue": "Ad Hoc Networks, 97, p.102029, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "L. Keller",
                "A. Le",
                "B. Cici",
                "H. Seferoglu",
                "C. Fragouli",
                "A. Markopoulou"
            ],
            "title": "Microcast: Cooperative video streaming on smartphones",
            "venue": "Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services (MobiSys \u201912), New York, 2012, pp. 57\u201370.",
            "year": 2012
        },
        {
            "authors": [
                "Y. Han",
                "H. Wu"
            ],
            "title": "Minimum-Cost Crowdsourcing with Coverage Guarantee in Mobile Opportunistic D2D Networks",
            "venue": "IEEE Transactions on Mobile Computing, vol. 16, no. 10, pp. 2806-2818, 1 Oct. 2017, doi: 10.1109/TMC.2017.2677449.",
            "year": 2017
        },
        {
            "authors": [
                "Y. Liu",
                "W. Quan",
                "T. Wang",
                "Y. Wang"
            ],
            "title": "Delay-constrained utility maximization for video ads push in mobile opportunistic D2D networks",
            "venue": "IEEE Internet of Things Journal, 5(5), pp.4088-4099, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "M. Ibrar",
                "L. Wang",
                "A. Akbar",
                "M.A. Jan"
            ],
            "title": "Adaptive Capacity Task Offloading in Multi-hop D2D-based Social Industrial IoT",
            "venue": "IEEE Transactions on Network Science and Engineering, 2022, doi: 10.1109/TNSE.2022.3192478.",
            "year": 2022
        },
        {
            "authors": [
                "A.A. Simiscuka",
                "G. -M. Muntean"
            ],
            "title": "REMOS-IoT-A Relay and Mobility Scheme for Improved IoT Communication Performance",
            "venue": "IEEE Access, vol. 9, pp. 73000-73011, 2021, doi: 10.1109/AC- CESS.2021.3080133.",
            "year": 2021
        },
        {
            "authors": [
                "W. Sun",
                "J. Liu",
                "Y. Yue",
                "Y. Jiang"
            ],
            "title": "Social-Aware Incentive Mechanisms for D2D Resource Sharing in IIoT",
            "venue": "IEEE Transactions on Industrial Informatics, vol. 16, no. 8, pp. 5517-5526, Aug. 2020, doi: 10.1109/TII.2019.2951009.",
            "year": 2020
        },
        {
            "authors": [
                "R. Zhang",
                "F.R. Yu",
                "J. Liu",
                "T. Huang",
                "Y. Liu"
            ],
            "title": "Deep Reinforcement Learning (DRL)-Based Device-to-Device (D2D) Caching With Blockchain and Mobile Edge Computing",
            "venue": "IEEE Transactions on Wireless Communications, vol. 19, no. 10, pp. 6469-6485, Oct. 2020, doi: 10.1109/TWC.2020.3003454.",
            "year": 2020
        },
        {
            "authors": [
                "A. Schrijver"
            ],
            "title": "Combinatorial Optimization: Polyhedra and Efficiency",
            "venue": "Springer Science & Business Media, Vol. 24, 2003.",
            "year": 2003
        },
        {
            "authors": [
                "R. Preis"
            ],
            "title": "Linear time 1/2-approximation algorithm for maximum weighted matching in general graphs",
            "venue": "Annual Symposium on Theoretical Aspects of Computer Science, Springer, 1999, pp. 259- 269.",
            "year": 1999
        },
        {
            "authors": [
                "JH. Hoepman"
            ],
            "title": "Simple distributed weighted matchings",
            "venue": "2004, [Online]. Available: https://arxiv.org/abs/cs/0410047",
            "year": 2004
        },
        {
            "authors": [
                "Z. Lotker",
                "B. Patt-Shamir",
                "S. Pettie"
            ],
            "title": "Improved distributed approximate matching",
            "venue": "Journal of the ACM (JACM), vol. 62, no. 5, pp. 129-136, Nov 2015.",
            "year": 2015
        },
        {
            "authors": [
                "O. Kalinagac",
                "S.S. Kafiloglu",
                "F. Alagoz",
                "G. Gur"
            ],
            "title": "Caching and D2D Sharing for Content Delivery in Software-Defined UAV Networks",
            "venue": "2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall), 2019, pp. 1-5, doi: 10.1109/VTCFall.2019.8891497.",
            "year": 2019
        },
        {
            "authors": [
                "M. Tang",
                "S. Wang",
                "L. Gao",
                "J. Huang",
                "L. Sun"
            ],
            "title": "MOMD: A multi-object multi-dimensional auction for crowdsourced mobile video streaming",
            "venue": "IEEE INFOCOM 2017 - IEEE Conference on Computer Communications, 2017, pp. 1-9, doi: 10.1109/INFO- COM.2017.8057025.",
            "year": 2017
        },
        {
            "authors": [
                "M. Tang",
                "L. Gao",
                "H. Pang",
                "J. Huang",
                "L. Sun"
            ],
            "title": "A multidimensional auction mechanism for mobile crowdsourced video streaming",
            "venue": "2016 14th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt), 2016, pp. 1-8, doi: 10.1109/WIOPT.2016.7492948.",
            "year": 2016
        },
        {
            "authors": [
                "D.P. Bertsekas"
            ],
            "title": "Auction algorithms for network flow problems: A tutorial introduction,\u201dComputational optimization and applications",
            "year": 1992
        },
        {
            "authors": [
                "M. Wattenhofer",
                "R. Wattenhofer"
            ],
            "title": "Distributed Weighted Matching",
            "venue": "International Symposium on Distributed Computing, pp. 335-348, Springer, Berlin, Heidelberg, 2004.",
            "year": 2004
        },
        {
            "authors": [
                "JH. Hoepman",
                "S. Kutten",
                "Z. Lotker"
            ],
            "title": "Efficient Distributed Weighted Matchings on Trees",
            "venue": "International Colloquium on Structural Information and Communication Complexity, pp. 115- 129. Springer, Berlin, Heidelberg, 2006.",
            "year": 2006
        },
        {
            "authors": [
                "HB. Lim",
                "YM. Teo",
                "P. Mukherjee",
                "VT. Lam",
                "WF. Wong",
                "S. See"
            ],
            "title": "Sensor grid: integration of wireless sensor networks and the grid",
            "venue": "The IEEE Conference on Local Computer Networks 30th Anniversary (LCN\u201905), Sydney, NSW, 2005, pp. 91-99.",
            "year": 2005
        },
        {
            "authors": [
                "W. Sun",
                "H. Yamaguchi",
                "K. Yukimasa",
                "S. Kusumoto"
            ],
            "title": "GV- Grid: A QoS Routing Protocol for Vehicular Ad Hoc Networks",
            "venue": "200614th IEEE International Workshop on Quality of Service, New Haven, CT, 2006, pp. 130-139.",
            "year": 2006
        },
        {
            "authors": [
                "S. Janson",
                "T. Luczak",
                "A. Rucinski"
            ],
            "title": "Random graphs",
            "venue": "John Wiley & Sons, Sep 2011.",
            "year": 2011
        },
        {
            "authors": [
                "P. Erdos",
                "A. R\u00e9nyi"
            ],
            "title": "On the evolution of random graphs",
            "venue": "Publ. Math. Inst. Hung. Acad. Sci, 1960, pp. 17-61.",
            "year": 1960
        },
        {
            "authors": [
                "Z. T\u00f3th",
                "J. Tam\u00e1s"
            ],
            "title": "Miskolc IIS hybrid IPS: Dataset for hybrid indoor positioning",
            "venue": "2016 26th International Conference Radioelektronika, pp. 408-412. IEEE, 2016.",
            "year": 2016
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Average-case analysis, weighted matching, greedy algorithm, large-scale resource sharing\nF"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "THANKS to advances in wireless and smartphone tech-nologies, mobile users in proximity can use local wireless links (e.g., short-range communications) to share local resources (e.g., data-plans [2], [3], computation [4], [5], caching memory [6], [7] and energy [8], [9]). For instance, in a busy airport, subscribed users who have leftover data plans can set up personal/portable hotspots and share data connections to travelers with high roaming fees [2]; in a crowded stadium, users with unutilized storage can download faster and share the cached popular game videos with other users in the vicinity [6]; or in an exposition, users who would like to watch the product introductory videos can use cooperative video streaming to share video segments with each other [10]. Given the large diversity for each user in the levels of her individual resource utilization, device-todevice (D2D) resource sharing is envisioned as a promising approach to pool resources and increase social welfare.\nSome recent studies have been conducted for modeling and guiding D2D resource sharing in wireless networks (e.g., [2-16]). As a node in the established D2D network graph, each mobile user can be a resource consumer or supplier, depending on whether her local resource is sufficient or not. As in [5] and [6], according to their locations, each user can only connect to a subset of users in the neighborhood through wireless connections, and the available wireless links are modelled as edges in the network graph. Sharing between any two connected users brings in certain benefit to the pair, which is modelled as a non-negative weight to the corresponding edge.\nAll these works optimize resource allocation by matching users in a centralized manner that requires global information and strict coordination. Hence the developed\nThe work of Lingjie Duan was supported by the Ministry of Education, Singapore, under its Academic Research Fund Tier 2 Grant under Award MOE-T2EP20121-0001.\napproaches cannot scale well in a scenario involving a large number of users, due to a large communication and computation overhead caused by the centralized nature of the proposed solutions. Carrying this argument further, the existing optimal weighted matching algorithms from the literature cannot be effectively used in the case of large userdefined networks due to their centralized nature and superlinear time complexity [17]. This motivates the need for developing distributed algorithms that exploit parallelism, have low computation complexity and good average performance for practical parameter distributions.\nIn the broader literature of distributed algorithm design for matching many nodes in a large graph, a greedy matching algorithm of linear complexity is proposed in [18] and [19] without requiring a central controller. It simply selects each time the edges with local maximum weights and yields an approximation ratio of 1/2 as compared to the optimum. A parallel algorithm is further proposed in [20] to reduce complexity at the cost of obtaining a smaller approximation ratio than 1/2. It should be noted that in the analysis of these algorithms, complexity and approximation ratio are always worst-case measures, but the worst-case approximation ratio rarely happens in most network cases in practice. This work is motivated by our observation from the simulation that the greedy matching\u2019s average performance is far better than the worst-case approximation ratio of 50% as compared to the optimum, being at least 95% of the optimum in most cases. To our best knowledge, this work is the first analytical study to present an average-case performance analysis of distributed matching algorithms. The results of our average-case analysis are important in practice because they motivate the use of such simple greedy matching algorithms without substantial performance degradation.\nSince worst-case bounds no longer work for averagecase analysis, we develop totally new techniques to ana-\nar X\niv :2\n30 5.\n12 86\n2v 1\n[ cs\n.D C\n] 2\n2 M\nay 2\n02 3\n2 lyze average performance. These techniques become more accurate when taking into account the structure of the network graph, and provide a very positive assessment of the greedy matching\u2019s average performance that is far from the worst case. Since the greedy matching can be naturally implemented in parallel by each node in the network, we also prove that with high probability (w.h.p.), the algorithm has sub-linear parallel complexityO(log n) in the number of users n. Our main contributions are summarized as follows.\n\u2022 Average-case analysis of greedy matching in large-scale regular networks: For large-scale 1D linear networks, we first use a new graph decomposition method to compute the upper bound for the optimal matching and then derive a recursive formula for the greedy matching by using dynamic programming. We prove that our greedy algorithm performs at least better than 86.5% of the optimum, and the minimum ratio is achieved when all the edges take similar weight values. In 2D grids, the same analysis cannot be directly applied. We introduce a new asymptotic analysis method based on truncating the 2D grids and then manage to analyze the resulting specific sub-grids using a recursive calculation similar to the 1D case. We prove that our greedy matching\u2019s average performance ratio is still above 76%. For these types of graphs, our greedy algorithm has only sub-linear complexity O(log n) w.h.p.. Thus, our algorithm provides a great implementation advantage compared to the optimal matching algorithms that require super-linear complexity without sacrificing much on performance. \u2022 Average-case analysis of greedy matching in large-scale random graphs: Besides the grids of fixed topology, we develop a new theoretic technique to analyze large Erdos-Re\u0301nyi random graphs G(n, p), where each of n users connects to any other user with probability p. For a dense random graph with constant p, we prove that the greedy matching will almost surely provide the highest possible total matching value, leading to an average performance ratio that tends to 100% as n increases. The analysis of sparse graphs with p < 1/n is more challenging, but we reduce it to the asymptotic analysis of random trees since the probability of the existence of loops in the sparse random graphs is zero w.h.p.. By exploiting the recursive nature of trees, we derive a recursive formula for the greedy matching, which is not closed-form but can be solved using bisection. Finally, we manage to obtain rigorous average performance bounds and parallel complexity O(log n) w.h.p.. The average performance ratio reaches its minimum (still above 79%) when the graph is neither dense nor sparse. \u2022 Extension to multi-unit resource sharing: We extend from single-unit to multi-unit resource sharing in our model, where each user may have multiple units of local resources to share. Our greedy algorithm in the multi-unit version requires parallel complexity O(log n) w.h.p.. By developing a new graph decomposition method, we prove that its average performance ratio is at least 78%.\n\u2022 Application to practical scenarios: We conduct experiments using real data for mobile user locations to simulate realistic D2D networks with constraints on the maximum allowed communication distance between devices. We show that our analytical G(n, p) performance measure approximates well practical cases of such D2D sharing networks. To decide the maximum D2D sharing range among users, we take into account the D2D communication failure due to path-loss and mutual interference among matched pairs. The optimal sharing range is achieved by finding the best tradeoff between transacting with more devices but at the higher risk that the chosen best neighbor might not be effectively usable due to a communication failure.\nThe paper is organized as follows. In Section 2, we discuss the related work and emphasize how it differs from our work. In Section 3, we present our network model and the greedy matching algorithm for solving the D2D resource sharing problem in any network graph. In Sections 4 and 5, we analyze the average performance ratios of the algorithm in the 1D and 2D grids. Sections 6 and 7 extend the averagecase analysis to random graphs and multi-unit resource sharing. Section 8 shows simulation results for application to practical scenarios and Section 9 concludes the paper."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "We discuss the related work concerning the two main topics related to our paper, namely D2D resource sharing ideas and distributed matching algorithms.\nRecent research efforts have been devoted to D2D resource sharing due to advances in wireless and smartphone technologies. In [2] and [3], subscribed users who have leftover data plans can set up personal/portable hotspots and share data connections with those who face data deficits. In [4] and [5], mobile users can share the computation resources with each other by task offloading via cellular D2D links. In [11] and [12], mobile devices can collaborate with each other to process and deliver data over D2D channels to fulfill crowdsourcing tasks. In [21], unmanned aerial vehicles (UAVs) with residual cache capacity can help store contents for others using inter-UAV connections. [22] and [23] allow mobile video users to support others in proximity to download video segments through WiFi or Bluetooth. However, compared to our work, the key focus in these D2D resource sharing works is to design a way to match the supply with the demand locally, not to analyze performances theoretically.\nIn the theoretical literature on the classical maximum matching problem, most existing methods to solve it require a central controller to gather all participants\u2019 information and perform the computation centrally [17]. This severely hinders the scalability of large-scale D2D sharing. A distributed matching algorithm using the primal-dual method is proposed in [24] to find the optimum, but requires a prohibitively high average computational complexity. There are some recent works focusing on finding approximation distributed algorithms that run fast [25]. In particular, two log-time parallel algorithms (with respect to user number)\n3 are proposed in [20] and [26] for general graphs, and another faster algorithm is proposed to compute an efficient matching in an expected constant time for the special case of tree graphs in [27]. But these algorithms\u2019 complexity and approximation ratio are only analyzed in the worst case and may not hold in most cases. Our work is the first analytical study to present an average-case performance analysis of distributed matching algorithms."
        },
        {
            "heading": "3 SYSTEM MODEL AND PROBLEM FORMULATION",
            "text": ""
        },
        {
            "heading": "3.1 System Model for D2D Resource Sharing",
            "text": "We first describe our D2D resource sharing model that involves a large number of potential users to share resources with each other via local wireless links (e.g., short-range communications). In this model, resources are exchanged between participating users in repeated rounds. In each round, we first run an algorithm to determine how to match users that have sent requests to neighbors for exchanging resources in this round, and then realize the actual sharing of the corresponding resources as determined by the algorithm. The set of participating users and the available D2D links may be different for different rounds.\nIn each round, we depict the network graph as G = (U,E), where U is the set of nodes corresponding to users that are participating in the given round, and E is the set of D2D links between participating users that are feasible to establish with some minimum level of performance (e.g., signal strength, actual physical distance, etc., depending on the application). Our model reasonably assumes a time-scale separation between the time for users to change location and the time to perform a round of the algorithm (that typically should be in the order of a few seconds), in order to establish stable D2D communication for resource sharing [2-16]. This might not hold in the case of fast-moving cars but it is the case when users typically hang around in crowded urban areas with low mobility, e.g., walking streets, airports, stadiums, city parks, cafes, malls, etc.. For each user ui \u2208 U = {u1, u2, . . . , un}, the subset A(ui) \u2286 U denotes the set of her neighbors in G, i.e., there is a feasible D2D link eij \u2208 E between ui and any uj \u2208 A(ui). Note that different definitions of \u2018feasibility\u2019 for D2D links will imply a different set of edges E between the users in U . Also the set U is changing over time/rounds since new users may join the sharing economy and existing users may drop out after satisfying their needs or moving out of range.\nWith each edge eij \u2208 E, there is an associated weight wij \u2265 0 that models the surplus (or welfare gain) of sharing a unit resource between users i and j if they are \u2018matched\u2019 in our terminology, usually converted in some monetary basis (say $). Let W = {wij} be the weight vector over all edges of G. Note that our model is very flexible and can fit various applications of D2D resource sharing by allowing for different ways to define the values for wij . In the case of a consumer i with revenue ri for obtaining a unit resource and a supplier j with cost cj for offering a unit resource, the weight is clearly wij = ri \u2212 cj . For example, in a secondary data-plan trading market [2], [3], user ui with dataplan surplus shares her personal hotspot connection with neighboring user uj with high roaming fee, and weight wij models the difference between user uj \u2019s saved roaming fee\nFig. 1: An illustrative instance of the D2D resource sharing model with n = 7 users is captured spatially.\nand the sharing cost (e.g., energy consumption in battery) of user ui. In another example of cooperative video streaming [22], user ui seeks user uj \u2019s assistance to download and share video segments via a local wireless connection so as to improve the streaming experience. The quality of experience (QoE), which is usually referred as to user perception, is measured in terms of download time or video rate in this example. Then, wij becomes the difference between the QoE improvement (in some appropriate units) of user ui and the download/sharing cost of user uj .\nBesides the cases where nodes are partitioned into suppliers and consumers, there are certain applications where edges capture the effects of collaboration between users if these users are matched. A simple example is the exchange of information where both parties benefit (e.g., [6], [10]). Suppose that users i, j cache the sets Fi and Fj of popular files respectively, and assume that each user has files that the other user would also like to have. If they get matched by the algorithm, they will exchange a total |Fi\u222aFj |\u2212 |Fi\u2229Fj | files, and the total social benefit wij can be approximated to be proportional to the above number or some more accurate estimate of the value of the shared information. We have constructed a case study of such collaborative caching in a network graph based on some real data in Section 8.1.\nIn any given round, our sharing model corresponds to an instance of a random weighted graph (G = (U,E),W ). A simple interpretation of the model is that a typical user, when participating, corresponds to a randomly selected node in G. In particular, we don\u2019t care for the actual identity of the participating users (after all, we care for the total value generated in the economy, summed over all participants). To simplify the model, we assume certain properties for the resulting stochastic process, i.e., in each round the set U and the corresponding E, W are independent identically distributed (IID), with certain distributions. In particular, we assume that the weights wij take values from a finite discrete set V ={v1, v2, . . . , vK} according to the general probability distribution Pr(wij = vk) = pk with \u2211K k=1 pk = 1. Without loss of generality, we assume 0\u2264v1<v2< \u00b7 \u00b7 \u00b7<vK . A small-scale illustrative instance of the D2D resource sharing model is shown spatially on the ground in Fig. 1, which can be abstracted to a weight graph (G = (U = {u1, u2, . . . , u7}, E = {e12, e14, e15, e23, e37, e45, e46, }),W = {w12, w14, w15, w23, w37, w45, w46}).\nIn typical practices of D2D sharing (e.g., energy transfer),\n4 a user is only matched to a single neighbor (if any) to finally transact with1. Keeping this simple but practical case of single matching per user2, given a weighted graph (G = (U,E),W ), we would like to select the pairs of users to match in order to maximize the total sharing benefit (i.e.,\nthe \u2018social welfare\u2019). Assuming full and globally available information on G and W , we formulate the social welfare maximization problem as a maximum weighted matching problem:\nP1 : max \u2211 eij\u2208E wijxij , (1a)\ns.t. \u2211\nuj\u2208A(ui)\nxij \u2264 1, \u2200ui \u2208 U, (1b)\nxij \u2208 {0, 1}, \u2200eij \u2208 E, (1c)\nwhere xij is the binary optimization variable denoting whether edge eij is included in the final matching (xij = 1) or not (xij = 0). Constraint (1b) tells that any user ui can only be matched to at most one user in her set of neighbors A(ui)."
        },
        {
            "heading": "3.2 Preliminaries of Greedy Algorithm",
            "text": "According to [17], to optimally solve the maximum weighted matching problem P1, one needs to centrally gather the weight and graph connectivity information beforehand. Further, searching for all possible matchings results in super-linear computation complexity, which is formidably high for a large-scale network with a large number n of users. Alternatively, the greedy matching addresses these two issues by keeping information local and allowing the algorithm to be performed in a distributed fashion. Algorithm 1 outlines the key steps of the greedy matching algorithm (please see intuition in the text that follows).\nAlgorithm 1: Greedy matching algorithm for solving problem P1 for the graph (G = (U,E),W ).\nInitialization: U \u2032 = U ; A\u2032(ui) = A(ui),\u2200ui \u2208 U ; xij = 0,\u2200eij \u2208 E. In each iteration, repeat the following two phases: Proposal phase: For each unmatched user ui \u2208 U \u2032:\n\u2022 User ui selects a user uj\u2217 among her unmatched neighbors in A\u2032(ui) with the maximum weight wij\u2217 . \u2022 User ui sends to uj\u2217 a matching proposal.\nMatching phase: For a user pair (ui, uj) that both ui and uj receive proposals from each other:\n\u2022 Match ui and uj by updating xij = 1 and U \u2032 = U \u2032 \\ {ui, uj}. \u2022 Make ui and uj unavailable for matching with others, by updating A\u2032(uk) = A\u2032(uk) \\ {ui} for any uk \u2208 A\u2032(ui), and similarly for uj .\n1. Allowing more concurrent matchings per user might not greatly improve performance, since our simulations suggest that most of the total benefit is usually obtained from one among the possible matchings where the values of the matchings follow a Pareto distribution.\n2. We extend to multi-unit resource sharing with similar results in Section 7.\nFig. 2: A simple example of approximation ratio of 1/2 achieved by Algorithm 1. The greedy matching returned by Algorithm 1 is the red-colored edge e23 with weight 1 + , > 0, while the optimal matching is {e12, e34} in blue with total weight 2. The corresponding approximation ratio is (1 + )/2, taking its minimum value when \u2192 0+.\nFirst note that Algorithm 1 is randomized in the selection of preferred neighbors in case there are multiple equally best choices in the proposal phase. A way to simplify this and make the algorithm deterministic is to assume that nodes are assigned unique numbers and that a node assigns priority in the case of ties to its neighbor with the highest number. This avoids loops and guarantees termination in O(|E|) steps. In the rest of the paper, we can assume this deterministic version for Algorithm 1. This is a mild assumption that shall not affect the validity of our key analysis. More importantly, Algorithm 1 can be implemented distributedly: at each time, each user uses local information to choose the unmatched neighbor with the highest weight as her potential matching partner; she will stop once this preference becomes reciprocal, or there are no available unmatched neighbors. This algorithm calculates a matching with total weight at least 1/2 of the optimum (see [19]). This worst-case approximation ratio of 1/2 is achieved in the instance in Fig. 2 when \u2192 0+, since the greedy matching chooses the middle edge while the optimal matching chooses the two side edges. Besides, when considering the instability of the connections between matched pairs (e.g., due to users\u2019 mobility or network failure), we prove that if a fraction a% of devices become disconnected in the middle of the matching transaction, the social welfare is reduced by less than 2a% on average due to the different sharing alternatives available to the remaining nodes, and failures not being correlated with the value of the matching that would take place. This is another robustness property of Algorithm 1."
        },
        {
            "heading": "3.3 Our Problem Statement for Average-Case Analysis",
            "text": "Although the approximation ratio of Algorithm 1 is 1/2 with half efficiency loss in the worst case, see [18], [19], this ratio is achieved in Fig. 2 only when the middle edge has slightly larger weight than its two adjacent edges. In such a simple three-edge instance, given that weights of independent edges are equally likely to be either 1 or 1 + , the worst-case approximation ratio 50% happens only with probability 1/4. Here, our greedy algorithm still performs better than 87.5% of the optimum in the average sense3.\nIn a large-scale network instance, given the IID distribution of the choice of the weights, it is more improbable that the graph will consist of an infinite repetition of the above special weighted three-edge pattern which leads to\n3. Here, when running our greedy algorithm, we follow that the four nodes u1, u2, u3 and u4 in Fig. 2 are assigned decreasing ID values (i.e., decreasing priority over ties among neighbors whose edge has the same weight).\n5\nthe worst-case performance. Hence, we expect the average performance ratio of the greedy matching to be much greater than 1/2.\nSince worst-case bound no longer works for averagecase analysis, we aim to develop totally new techniques to theoretically analyze the average performance of representative classes of graphs with random parameters. To start with, we first provide the rigorous definitions for our average-case performance analysis.\nBy taking expectation with respect to the weights in W that are IID with a general discrete distribution Pr(wij = vk) = pk,\u2200k = 1, . . . ,K , we define the average performance ratio PR(G) of Algorithm 1 for a given graph G as follows:\nPR(G) = EW [f\u0302(G,W ) =\n\u2211 eij\u2208E wij x\u0302ij ]\nEW [f?(G,W ) = \u2211 eij\u2208E wijx ? ij ] , (2)\nwhere f?(G,W ) and f\u0302(G,W ) denote the total weights (i.e., social welfare) under the optimal matching and the greedy matching, respectively, {x?ij}, {x\u0302ij} being the corresponding matchings. Since over time the algorithm is repeated for new instances, the numerator and denominator correspond to the time-average of the social welfare obtained by running the greedy and the optimal algorithms, respectively.\nWe next evaluate the performance ratio for several special forms of practical interest for G that corroborate the excellent performance of the greedy matching, including the large-scale 1D and 2D grids of fixed topology, as well as the random graph G(n, p) networks. In the case of random graphs, we must take expectation in (2) over both G and W . Besides, we will also prove the sub-linear computation complexity to run Algorithm 1 for these large-scale networks."
        },
        {
            "heading": "4 AVERAGE-CASE ANALYSIS FOR D2D SHARING",
            "text": "IN 1D LINEAR NETWORKS When many users are distributed in an avenue or road and can locally share their resources (e.g., walking along 5th Av. at Christmas), we may use a 1D linear network to approximate their connectivity and analyze the greedy matching\u2019s average performance. 1D linear networks are the simplest case of regular graphs and are used as a theoretical device to get insights for our later average-case analysis of 2D regular graphs, the more general random graphs and the extension to multi-unit resource case in Sections 5, 6 and 7. As illustrated in Fig. 3, we consider a large weighted linear network, where each user ui (except for starting and ending users u1 and un) locally connects with two adjacent users ui\u22121 and ui+1. In such linear networks, for notational simplicity we use ei instead of ei,i+1 to denote the connection between users ui and ui+1, and similarly use weight wi instead of wi,i+1. The corresponding weight vector becomes W = {w1, w2, . . . , wn\u22121}.\nFor the linear network with n users as shown in Fig. 3, we first analyze the running time of Algorithm 1, where\nFig. 4: Illustration of the graph decomposition method for a linear network example with K = 2 possible edge weights v1 < v2. In the first step, we subtract v1 from all the 9 edges\u2019 weights, creating 4 zeroweight edges that reduce the graph into three linear sub-graphs of size 1, 3 and 1. In the second step, for each sub-graph, we subtract v2 \u2212 v1 to result in no edges with positive weights. An upper bound for the optimal matching is d 9 2 ev1+(1+d 32 e+1)(v2\u2212v1) = v1+4v2, obtained in a straightforward fashion using the total subtracted weights from the maximum cardinality matching for each step.\na unit of time corresponds to one iteration of the steps of Algorithm 1. We simulate the system in practice by running the greedy matching in parallel by each node. Different from the related literature (e.g., [18], [19]), we focus on analyzing the parallel complexity of Algorithm 1 below.\nLet H(ui) denote the length of the longest chain (sequence of edges) that has non-decreasing weights and starts from ui towards the left or right side. Suppose that wi\u22121 \u2264 wi\u22122 \u2264 \u00b7 \u00b7 \u00b7 \u2264 wi\u2212H(ui)+1 \u2264 wi\u2212H(ui) > wi\u2212H(ui)\u22121 is the longest chain. We claim that ui will terminate running Algorithm 1 (i.e., by being matched or knowing that it has no available unmatched neighbors) within H(ui)/2 time. This is easy to see since starting from time 0, the edge ei\u2212H(ui) will be included in the total matching in iteration 1, ei\u2212H(ui)+2 in iteration 2, etc. Hence, in less than H(ui)/2 steps, all neighbors of ui will have resolved their possible preferences towards users different than ui, and subsequently ui will either be matched with one of her neighbors or be left with an empty unmatched neighbor set.\nAs Algorithm 1 terminates when all users make their final decisions, if the probability of any user in G having a chain longer than c log n (i.e., maxui\u2208U H(ui) > c log n) for some constant c is very small, then the parallel execution of Algorithm 1 will terminate within O(log n) time with very high probability. This is the case for large-scale linear networks as the next proposition states. Note that in the literature, [19] just proves linear O(n) time bound for running the greedy matching (but the execution is not parallel). Proposition 1. In large-scale linear networks of n users,\nAlgorithm 1 runs in O(log n) time w.h.p..\nThe proof is given in Appendix A of the Supplementary Material of this TMC submission. Next, we focus on studying the average performance ratio PR(G) in (2). The exact value of the average total weight EW [f?(G,W )] under the optimal matching is difficult to analyze due to formidably many matching combinations over the large network. We aim to derive a lower bound for PR(G), by first deriving an upper bound for the denominator EW [f?(G,W )] in (2), and then obtaining an exact asymptotic expression for the numerator EW [f\u0302(G,W )] in (2)."
        },
        {
            "heading": "4.1 Average Performance Analysis of Optimal Matching",
            "text": "To find the upper bound on the average total weight EW [f?(G,W )] under the optimal matching, we propose\n6 a new graph decomposition method to reduce network connectivity, by creating edges with zero weight value purposely. Such edges do not contribute to the total weight of the matching, simplifying the optimal matching of the reduced graph.\nNote that in our weight set V , there are K possible weight values satisfying v1 < v2 < \u00b7 \u00b7 \u00b7 < vK . Our method\u2019s basic idea is to reduce the original network into a large number of disconnected components, by subtracting from all edge weights first v1, then v2 \u2212 v1, v3 \u2212 v2, etc. This procedure takes K steps to conclude until creating a graph consisting of zero-weight edges. An illustrative example for K = 2 is shown in Fig. 4, where we take two steps to obtain the performance upper bound of the optimum. The total amount of weights that are subtracted from the maximum cardinality matching in the reduced graph during each of the K steps is an upper bound for the optimal matching. In the next proposition we analytically obtain the closed-form upper bound for EW [f?(G,W )] for any linear network. Proposition 2. Given the weight set V = {v1, v2, . . . , vK}\nwith the weight distribution P = {p1, p2, . . . , pK}, the average total weight of the optimal matching in largescale linear networks of n users is upper bounded by\nEW[f?(G,W )]\u2264n v1 2 +n K\u22121\u2211 k=1 (vk+1\u2212vk) 1\u2212 \u2211k i=1 pi 2\u2212 \u2211k i=1 pi . (3)\nThe proof is given in Appendix B of the Supplementary Material of this TMC submission. The upper bound in (3) is linearly increasing in user number n and increases in weight value vk for any k \u2208 {1, 2, . . . ,K}. This bound is tight only when edges can take a single weight value, i.e., K = 1."
        },
        {
            "heading": "4.2 Average Performance Analysis of Algorithm 1",
            "text": "Without loss of generality, when running Algorithm 1, we suppose that each user facing the same weights of the two adjacent edges assigns higher priority to match with the lefthand-side neighbor in Fig. 3. Assumption 1. For each user ui having the same weights\nwi\u22121 = wi with the two adjacent neighbors ui\u22121 and ui+1, Algorithm 1 assigns higher priority to match with the left-side neighbor ui\u22121 (see Fig. 3).\nThis makes Algorithm 1 deterministic and returns a unique solution. We prove the following lemma. Lemma 1. Given the weight set size K , an edge ei that\nsatisfies wi > wi\u22121 and wi \u2265 wi+1 can be found within the first K edges of the linear network graph.\nFig. 5 shows an illustrative example for K = 2, and we always find such an edge (marked in red) with local maximum weight within the first 2 edges. This edge will be matched in Algorithm 1, and the remaining graph is still linear but with a smaller user size. Then, we reduce the total matching into two sub-problems: the matching of the edges from e1 to ei and the matching of the remaining edges to the right. Given such reduction, we are able to derive the recursive formula for calculating the result of the greedy matching by using dynamic programming. More specifically, by considering all the KK weight combinations {w1, . . . , wK} of the first K edges and the existence of edge\nFig. 5: Given the weight set size K = 2 and v1 < v2, an edge that certainly matches is always found within the first 2 edges, as marked in red. There are totally KK = 4 weight combination cases of the first 2 edges. In each case, after matching the red edge, the remaining graph is still linear but with a smaller size n\u2212 2 or n\u2212 3.\nei that will certainly match, we derive the recursive formula for the sequence {an}, where an denotes the average total weight of the greedy matching with n users. In the example of K = 2 in Fig. 5, there are four weight combination cases, where each realized case has a recursive formula. By taking the expectation with respect to the probabilities of the four cases, the expected recursive formula is given by\nan = p 2 1(v1 + an\u22122) + p2(v2 + an\u22122) + p1p2(v2 + an\u22123)\n= p21v1 + (p2 + p1p2)v2 + (p2 + p 2 1)an\u22122 + p1p2an\u22123. (4)\nBased on this, we derive an = p21v1+(p2+p1p2)v2\n2p2+2p21+3p1p2 n + o(n) by\nusing asymptotic analysis. Moreover, for an arbitrary K , it is also possible to derive the recursive formula for the sequence {an} as a function of V = {v1, v2, . . . , vK} and P = {p1, p2, . . . , pK}. For a uniform weight distribution (i.e., p1 =p2 = \u00b7 \u00b7 \u00b7=pK =1/K), this simplifies and we obtain the following closed-form result.\nProposition 3. For an arbitrary K , if p1 = \u00b7 \u00b7 \u00b7 = pK = 1K , the recursive formula for the sequence {an} in largescale linear networks is given by\nan = K\u2211 k=1 \u03b2kvk + \u03b3kan\u2212k\u22121,\nwhere \u03b2k = (K\u22121)K\u2212k KK(K+1)\u2212k+1 and \u03b3k = 1Kk+1 K\u2211 i=k i (i\u22121 k\u22121 ) . By applying asymptotic analysis for a large user number n, we derive closed-form an for our greedy matching\u2019s performance below:\nan = \u2211K k=1 \u03b2kvk\u2211K\nk=1(k + 1)\u03b3k n+ o(n). (5)\nThe proof is given in Appendix C of the Supplementary Material of this TMC submission. (5) is useful later in Sections 4.3 and 5 to derive the performance guarantee of Algorithm 1 in linear and grid networks."
        },
        {
            "heading": "4.3 Average Performance Ratio of Algorithm 1",
            "text": "We first check the special case of weight set size K = 2. Based on (3) and the general formula derived by (4), we obtain the closed-form average performance ratio of Algorithm 1 as compared to the optimal matching.\n7 Proposition 4. In large-scale linear networks with K = 2, the average performance ratio of Algorithm 1 satisfies\nlim n\u2192\u221e\nPR(G) \u2265 p 2 1v1 + (p2 + p1p2)v2\n(2p2 +2p21 +3p1p2)( v1 2 +(v2\u2212v1) 1\u2212p1 2\u2212p1 )\n\u2265 8 9 \u2248 88.9%,\nand it attains the minimum if v2v1 \u2192 1 + and p1 = p2 = 12 .\nThe proof is given in Appendix D of the Supplementary Material of this TMC submission. This proposition suggests that the greedy matching\u2019s average performance is surprisingly good (around 90% of the optimum), which is much greater than 50% in the worst case. It may be counterintuitive that the average performance ratio of Algorithm 1 is the smallest when all edges have almost the same weights (not exactly the same), but this is actually consistent with the worst-case instance in Fig. 2. There we greedily choose only the middle edge of weight 1 + instead of the two side edges of total weight 2. As \u2192 0, the greedy matching\u2019s performance worsens as compared to the optimum, which is equivalent to v2v1 \u2192 1\n+ in Proposition 4. As p1 and p2 get close to each other, the case that adjacent edges have nearly similar weights happens more frequently.\nSimilarly, for K \u2265 3, we can obtain the lower bound for PR(G) as a function of V = {v1, v2, . . . , vK} and P = {p1, p2, . . . , pK} and show that the greedy matching\u2019s average performance is always close to the optimum. Moreover, based on (3) and the general formula in (5), we prove that the ratio PR(G) is minimized when the possible weight values are similar given a uniform weight distribution p1 = \u00b7 \u00b7 \u00b7 = pK = 1K . Proposition 5. For an arbitraryK , if p1 = \u00b7 \u00b7 \u00b7 = pK = 1K , the\naverage performance ratio of Algorithm 1 in large-scale linear networks satisfies\nlim n\u2192\u221e\nPR(G) \u2265 \u2211K k=1 vk (K\u22121)K\u2212k (K+1)K\u2212k+1\u2211K\nk=1 vk K (2K+1\u2212k)(2K\u2212k)\n\u2265 1\u2212 (K \u2212 1 K + 1 )K \u2265 1\u2212 e\u22122 \u2248 86.5%,\nwhere the second inequality becomes equality when all the possible weight values become similar (i.e., vKv1 \u2192 1+).\nThe proof is given in Appendix E of the Supplementary Material of this TMC submission. The result here is consistent with Proposition 4, and the average performance ratio of Algorithm 1 is the smallest when all edges have almost the same weights. The ratio slightly reduces as K increases."
        },
        {
            "heading": "5 AVERAGE-CASE ANALYSIS FOR D2D SHARING",
            "text": "IN 2D GRID NETWORKS In wireless networks, 2D grids are widely used to model social mobility of users (e.g., [28], [29]). In this section, we analyze the average performance ratio and the parallel complexity of Algorithm 1 to validate its performance on planar user connectivity graphs. Note that the average-case analysis of 2D grids is an important benchmark for the more general random graphs analyzed in the following sections."
        },
        {
            "heading": "5.1 Average Performance Analysis of Optimal Matching",
            "text": "It is infeasible to obtain the exact value of the average total weight EW [f?(G,W )] under the optimal matching due to the exponential number of the possible matchings. Instead, we propose a method to compute an upper bound for the denominator EW [f?(G,W )] in (2) using a methodology that holds for general graphs. This upper bound will be used to derive a lower bound for the average performance ratio PR(G) in (2) later.\nIn any graph G = (U,E), each matched edge eij \u2208 E adds value wij to the final matching. Equivalently, we can think of it as providing individual users ui and uj with equal benefit wij/2. For any user ui, this individual benefit does not exceed half of the maximum weight of its neighboring edges. Using this idea and summing over all users, the total weight of the optimal matching is upper bounded by\nf?(G,W ) \u2264 1 2 \u2211 ui\u2208U max uj\u2208A(ui) wij . (6)\nBy taking expectation over the weight distribution, we obtain the closed-form upper bound of the average total weight. Proposition 6. For a general graph G = (U,E) with the\nweight set V ={v1, v2,. . ., vK} and the weight distribution P ={p1, p2,. . ., pK}, the average total weight of the optimal matching is upper bounded by\nEW [f?(G,W )] \u2264\n1\n2 \u2211 ui\u2208U K\u2211 k=1 vk(( k\u2211 i=1 pi) |A(ui)| \u2212 ( k\u22121\u2211 i=1 pi) |A(ui)|), (7)\nwhere |A(ui)| is the cardinality of A(ui).\nThe proof is given in Appendix F of the Supplementary Material of this TMC submission."
        },
        {
            "heading": "5.2 Average Performance Analysis of Algorithm 1",
            "text": "We start with the probabilistic analysis of the parallel complexity of Algorithm 1. The result follows a similar reasoning as in the case of linear networks, but the proof is more subtle. This is because in the case of 2D grids, the number of possible chains that start from any given node ui and have non-decreasing weights is no longer two (toward left or right) as in 1\u00d7n grid networks, but exponential in the size of the chain (since from each node there are 4 \u2212 1 = 3 \u2018out\u2019 ways for the chain to continue), and such chains now form with non-negligible probability. This problem is not an issue for Algorithm 1 since every node will need to use priorities over ties among neighbors whose edge has the same weight. This significantly reduces the number of possible chains that are relevant to a user\u2019s decisions and we can prove the following proposition. Proposition 7. In large-scale n \u00d7 n grids, Algorithm 1 runs\nin O(log n) time w.h.p..\nThe proof is given in Appendix G of the Supplementary Material of this TMC submission. In conclusion, our distributed matching algorithm has low complexity and\n8\nprovides a great implementation advantage compared to the optimal but computational-expensive centralized matching.\nWe next analyze the average total weight of the greedy matching, i.e., the numerator EW [f\u0302(G,W )] in (2). Unlike Section 4.2, in the case of 2D grid networks we cannot directly use dynamic programming since matching users does not divide the grid into sub-grids. One may want to extend our previous result in linear networks to n \u00d7 n grid, by dividing it into n linear networks of size 1 \u00d7 n. However, this provides a poor lower bound because all the vertical edges become unavailable to match. Alternatively, we split the grid network into sub-grids in a way that keeps half of the vertical edges, and then estimate a tighter lower bound by further creating sub-graphs without cycles. Our procedure involves the following three steps (see Fig. 6).\nStep 1: Split the n\u00d7n grid into n/2 sub-grids of size 2\u00d7n by eliminating the corresponding vertical edges between subgrids.\nStep 2: For each 2 \u00d7 n sub-grid after step 1, eliminate all the horizontal edges in the second row (i.e., the blue dashed lines of the \u2018Step 2\u2019 sub-graph in Fig. 6) to create a graph without cycles. Then we analyze the greedy matching\u2019s performance over the remaining edges by using dynamic programming techniques.\nStep 3: For all the unmatched users in the second row, greedily match them by using the results in linear networks (see Section 4.2).\nTo analyze the average total weight of the greedy matching, we first note that the graph created by step 2 can always be divided into two sub-graphs with the similar graph structure by matching an arbitrary edge. Here, a subgraph with the similar graph structure refers to a sub-grid of smaller size 2\u00d7n\u2032 (with any 0 \u2264 n\u2032 < n) and also with all the horizontal edges eliminated in the second row. Further, we can show that an edge that will certainly match in Algorithm 1 can be found within the first 2K edges (including the first K horizontal edges in the first row and the corresponding K vertical edges) of the created graph, by using the similar\nFig. 7: Given the weight set size K = 2 and v1 < v2, an edge that certainly matches is always found within the first 2K = 4 edges, as marked in red. In each case, after matching the red edge, the remaining graph still has the similar structure but with a smaller size n\u2212 1, n\u2212 2 or n\u2212 3.\narguments as in Lemma 14. Fig. 7 shows an illustrative example for K = 2, and we always find such an edge (marked in red) with local maximum weight within the first 2K = 4 edges. This edge will be matched in Algorithm 1, and the remaining graph has the similar structure but with a smaller size. Then, by considering all the K2K weight combinations of the first 2K edges, we can similarly derive the recursive formula for the greedy matching as in linear networks. Note that in the example of K = 2 in Fig. 7, we reduce the totally K2K = 16 combination cases into 5 cases ((a)-(e)) by combining these with the same certainly matched edges, and obtain the corresponding recursive formula for each of them. The final expected recursive formula is given by\nan=(1\u2212p41)v2+p21v1+p1p2an\u22121+(p31 + p2)an\u22122+p21p2an\u22123.\nBased on this, we can similarly derive the general formula for {an} when n is large by using asymptotic analysis. Moreover, this method can also be extended for any possible weight distribution.\nThen, after the matching in Step 2, users in the second row form linear segments with different lengths in step 3 (see Fig 6), and the greedy matching in these segments can be similarly analyzed as in Section 4.2. Finally, we combine the analysis in steps 2 and 3 for the greedy matching\u2019s performance, and compare to the upper bound for the optimal matching in (7) to obtain the lower bound for PR(G).\nProposition 8. In large-scale n \u00d7 n grids with the weight set V = {v1 = 1, v2 = 1 + \u2206} and uniform weight distribution p1 = p2 = 12 , the average performance ratio of Algorithm 1 satisfies\nlim n\u2192\u221e PR(G) \u2265 0.9213 + 0.6967\u2206 1 + 0.9375\u2206 ,\nThis ratio decreases from 92.1% to 74.3% when weight difference \u2206 increases from 0+ to\u221e.\n4. Here, without loss of generality, we assume that each user facing the same weights of adjacent edges assigns higher priority to match with the neighbor of smaller index. For example, the three neighbors ui\u22121, ui+1 and ui+n of user ui have decreasing priority to match when they have the same weight with ui.\n9 3 4 5 6 7 8 9 10 0.76 0.78 0.8 0.82 0.84 0.86 0.88 0.9\nWight set size K\nA v e ra\ng e p\ne rf\no rm\na n c e r\na ti o\nP R\n(G )\n\u2206 \u2192 0 + \u2206 = 0.2 \u2206 = 0.4\nFig. 8: The average performance ratio of Algorithm 1 in n \u00d7 n grids versus the weight set size K and weight difference \u2206. Here we assume edge weights are uniformly chosen from the weight set V = {1, 1 + \u2206, . . . , 1 + (K \u2212 1)\u2206}.\nThe proof is given in Appendix H of the Supplementary Material of this TMC submission. Different from Propositions 4 and 5 in linear networks, in the case of grids similar weight values (i.e., \u2206\u2192 0+) no longer lead to the minimum average performance ratio. Intuitively, even if the instance in Fig. 2 (three horizontal edges with similar weights) happens in grids, each user has at least a vertical neighbor to match.\nFinally, we further extend our analysis for larger weight set size K > 2. In Fig. 8, we present the average performance ratio of Algorithm 1 in n \u00d7 n grids against arbitrary K . Consistent with Proposition 8, here the average performance ratio bound decreases with \u2206 and is larger than 76%. It also decreases with K , which is also observed for linear networks."
        },
        {
            "heading": "6 AVERAGE-CASE ANALYSIS FOR D2D SHARING",
            "text": "IN G(n, p) NETWORKS In practice, a mobile user may encounter a random number of neighbors. In this section, we extend our analysis to random networks G(n, p), where n users connect with each other with probability p and hence each user has in the average (an order of magnitude) d = np neighbors. Although the actual spatial distribution of users is not necessarily planar, such random graphs can still represent their connectivity on the ground and the analysis also holds.\nWe study the average performance ratio of Algorithm 1 in the cases of dense random graphs with a constant p (i.e., dense since d = np increases linearly in n) [30], and sparse random graphs with a constant average neighbor number d < 1 (i.e., p < 1/n) [31]. Unlike the 2D grid networks, the structure of the random network G(n, p) is no longer fixed due to the random connectivity. Though it is more technically difficult to analyze the average performance of Algorithm 1 for random graph structure, we are able to derive the ratio using statistical analysis in the two important cases below. For intermediate values of d where our techniques cannot be applied, we have used exhaustive sets of simulations."
        },
        {
            "heading": "6.1 Average-Case Analysis of Dense Random Graphs",
            "text": "Given p remains a constant, as n increases, each user will have an increasing number of neighbors with the largest possible weight value vK . Since such edges are preferred by\ngreedy matching, as n goes to infinity, the greedy matching will almost surely provide the highest possible total matching value of nvK/2 (n/2 pairs of users with weight vK ).\nProposition 9. For a large-scale random graph G(n, p) with a constant p, the average performance ratio of Algorithm 1 satisfies PR = 100% w.h.p..\nThe proof is given in Appendix I of the Supplementary Material of this TMC submission. In this result, we have taken expectation over bothG andW in the definition of the average performance ratio PR. Note that the computation complexity is not anymore O(log n) in this case due to the increasing graph density. An obvious bound is O(|E|) = O(n2) proved in [19]."
        },
        {
            "heading": "6.2 Average-Case Analysis of Sparse Random Graphs",
            "text": "In this subsection, we consider that the connection probability is p = d/n and hence each user has a constant average number of neighbors d(n \u2212 1)/n \u2192 d as n becomes large. We first prove low parallel complexity for Algorithm 1 as long as each user has a small enough number of neighbors to pair with that depends on the edge weight distribution.\nProposition 10. For large-scale G(n, d/n) type of networks, Algorithm 1 runs in O(log n) time w.h.p. if d < 2/max{p1, p2, . . . , pK}.\nThe proof is given in Appendix J of the Supplementary Material of this TMC submission. Note that this condition is always satisfied when d < 1 because the weight probability pk \u2264 1 for any k.\nNext, we focus on studying the average performance ratio PR for sparse random graphs G(n, d/n). The average total weight of the optimal matching can be upper bounded by (7), which works for any graph. Then, we only need to study the average total weight EG\u223cG(n,d/n),W [f\u0302(G,W )] of the greedy matching. Note that when matching any graph G, we can equivalently view that the weight of any matched edge is equally split and allocated to its two end-nodes. Then we can rewrite the above expression as follows:\nEG\u223cG(n,d/n),W [f\u0302(G,W )] =nEG\u223cG(n,d/n),W [xi(G,W )], (8)\nwhere xi(G,W ) is half of the weight of the matched edge corresponding to each user ui under the greedy matching.\nWe cannot use dynamic programming directly to compute the average weight EG\u223cG(n,d/n),W [xi(G,W )] per user in (8) since G(n, d/n) may have loops and it cannot be divided into independent sub-graphs. Given that n is large and assuming d < 1, then graph G(n, d/n), with very high probability, is composed of a large number of random trees without forming loops. In this case the matching weight xi(G,W ) of user ui only depends on the connectivity with other users in the same tree. To analyze xi(G,W ), we want to mathematically characterize such trees which turn out to be \u2018small\u2019 because d < 1. Note that, in G(n, d/n), each user has n \u2212 1 independent potential neighbors, and its random neighbor number follows a binomial distribution B((n \u2212 1), d/n) with mean (n \u2212 1)d/n \u2192 d, as n becomes large. This binomial distribution can be well approximated by the Poisson distribution Poi(d) (with mean d). We define T (d) as a random tree where each node in the tree gives\n10\nbirth to children randomly according to the Poisson distribution Poi(d). Proposition 11. Given a sparse random network G(n, d/n)\nwith d < 1 and sufficiently large n, the average matching weight of any node ui is well approximated by the average matching weight of the root node of a random tree T (d), i.e.,\nlim n\u2192\u221e EG\u223cG(n, dn ),W [xi(G,W )]=ET\u223cT (d),W [xroot(T,W )]. (9)\nThe proof is given in Appendix K of the Supplementary Material of this TMC submission. We will show numerically later that the approximation in (9) yields trivial performance gap and remains accurate as long as d \u2264 10. By substituting (9) into (8), we obtain approximately the average total weight EG\u223cG(n,d/n),W [f\u0302(G,W )]. Hence, it remains to derive the form of ET\u223cT (d),W [xroot(T,W )]. Given the recursive nature of trees, we are able to use dynamic programming.\nThe root node may receive multiple proposals from its children corresponding to different possible edge weights in the set {v1, v2, . . . , vK}, and will match to the one (of them) with the maximum weight. We define yk, k \u2208 {1, 2, . . . ,K}, to denote the probability that the root node receives a proposal from a child who connects to it with an edge of weight vk. Then, by considering all the possible weight combinations of the root\u2019s children, we can compute the probability to match a child with any given weight, using the proposal probabilities yk. In a random tree T (d), given the root node is matched with one of its children, the remaining graph can be divided into several sub-trees which are generated from the grand-child or child nodes of the root node. In any case, a sub-tree starting with any given node has the similar graph structure and statistical property as the original tree T (d). Thus, we are able to analytically derive the recursive equations for finding the proposal probabilities {yk} for the root node. Proposition 12. In the random tree T (d), for any k \u2208 {1, 2, . . . ,K}, the proposal probability yk from a child of edge weight vk to the root node is the unique solution to the following equation:\nyk = e \u2212(pK+\n\u2211K j=k+1 yjpj)d \u221e\u2211 i=0 (pkd) i(1\u2212(1\u2212yk)i+1) (i+ 1)!yk . (10)\nThe proof is given in Appendix L of the Supplementary Material of this TMC submission. Though not in closed form, we can easily solve (10) using bisection, and then compute the probability that the root node matches to a child with any given weight. Based on that we derive the average matching weight ET\u223cT (d),W [xroot(T,W )] of the root for (9) and thus EG\u223cG(n,d/n),W [f\u0302(G,W )] in (8). Finally, by comparing with (7) under the optimal matching, we can obtain the average performance ratio of Algorithm 1."
        },
        {
            "heading": "6.3 Numerical Results for Random Graphs",
            "text": "Next, we conduct numerical analysis for sparse random graphs with d < 1 and random graphs with finite d \u2265 1. To do that by using analytic formulas, we need to approximate the random graph by random trees, and one may wonder if the approximation error is significant (when d > 1). To\nanswer this question, we consider large network size of n = 10, 000, with edge weights uniformly chosen from the weight set V = {1, 2} (\u2018low\u2019 and \u2018high\u2019). Our extensive numerical results show that the difference between the simulated average matching weight EG\u223cG(n, dn ),W [xi(G,W )] and the analytically derived average matching weight ET\u223cT (d),W [xroot(T,W )] in the approximated tree T (d) is always less than 0.05% when d < 1 and is still less than 1% even for large 1 \u2264 d \u2264 10. This is consistent with Proposition 11.\nFig. 9 shows the average performance ratio of Algorithm 1, which is greater than 79% for any d value. It approaches 100% as d is small in the sparse random graph regime. Intuitively, when the average neighbor number d is small and users are sparsely connected, both Algorithm 1 and the optimal algorithm try to match as many existing pairs as possible, resulting in trivial performance gap. When d is large, each user has many neighbors and choosing the second or third best matching in the greedy matching is also close to the optimum. This is consistent with Proposition 9 for dense random graphs."
        },
        {
            "heading": "7 EXTENSION TO MULTI-UNIT D2D RESOURCE SHARING",
            "text": "In D2D sharing, a user may have multiple units of resources to supply or demand, and may share with multiple users at a time. For instance, an Android phone user may open up personal hotspot and share data connections with up to 10 users at the same time. In this section, we extend our average-case analysis to multi-unit resource sharing in linear networks. Though more involved, our analysis can also be extended to grid networks."
        },
        {
            "heading": "7.1 Problem Description",
            "text": "Similar to the single-unit linear network in Fig. 3, we consider a large-scale linear sharing network where each user ui locally connects with two adjacent users ui\u22121 and ui+1 and has qi units of resource demand (or supply) to share. Note that, in the multi-unit resource sharing, as long as we assume that each node cannot be both a consumer and a supplier at the same time (within one round), the direction of the edges is implied by the identity of the nodes. There is no need to change to directed graph modeling. We define\n11\nQ = {qi} as the quantity vector for all n users and suppose the quantity qi is IID for each user ui. Similar to problem P1, we formulate the following multi-unit weighted allocation problem:\nP2 : max n\u22121\u2211 i=1 wi,i+1xi,i+1,\ns.t. xi,i+1+xi\u22121,i\u2264qi,\u2200i=2, 3, . . . , n\u2212 1, (11a) x1,2 \u2264 q1, xn\u22121,n \u2264 qn, (11b) xi,i+1 \u2208 {0, 1, 2, . . . }, \u2200i = 1, 2, . . . , n\u2212 1,\nwhere constraints (11a) and (11b) ensure that the total amount of resources allocated to user ui is constrained by her desired quantity qi.\nNote that the direct extension of Algorithm 1 to solve the multi-unit problem above is to break each user ui with quantity qi into qi copies of one-unit users. However, this greatly increases the dimensionality of the problem (with the increased network size from n to \u2211n i=1 qi) and unnecessarily introduces competition between copies of the same user. To solve P2 efficiently, we make changes to the matching phase of Algorithm 1: every time an edge ei (between users ui and ui+1) with the local maximum weight is found by the previous proposal phase, the allocation xi is no longer updated to 1, but increased by the minimum quantity min{qi, qi+1}. Meanwhile, the quantities of qi and qi+1 are decreased by the same amount.\nNote that each user still runs the steps of the revised algorithm based on local information, and will stop once her desired quantity is fully met or she sees no available neighbor. Thus, for each pair of users with the local maximum weight, at least one of them will fully satisfy her quantity in the matching phase and stop running the algorithm. The linear sharing network can be split due to any user\u2019s termination. Then, by using the similar arguments from single-unit case in Section 4, we prove the multi-unit version of Algorithm 1 still has sub-linear parallel complexity.\nLemma 2. In large-scale linear networks of n users, our revised Algorithm 1 for multi-unit resource sharing runs in O(log n) time w.h.p.."
        },
        {
            "heading": "7.2 Average Performance Analysis",
            "text": "To study the average performance ratio of the multi-unit version of Algorithm 1 for solving problem P2, we also start with the average performance analysis of the optimal allocation. First note that, in any graph G = (U,E), the optimal allocation for individual user ui (with the maximum weight \u2211 j\u2208A(ui) xijwij) is to allocate all her qi units of resource to the neighbors with the largest weights. As the allocation to any edge eij is constrained not only by qi but also by qj , the individual allocation weight of ui is upper bounded by\n|A(ui)|\u2211 t=1 wijtxijt . (12)\nFig. 10: Illustration of the new graph decomposition method for a multiunit linear network example with two possible quantity values 1 and 2 for each user. All the red-colored nodes have quantity 2 and all the blue-colored nodes have quantity 1.\nwhere jt is the neighbor of ui with the t-th largest weight (i.e., wij1 \u2265 wij2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 wij|A(ui)| ) and the allocation xijt assigned to pair (ui, ujt) is computed as follows:\nxijt = { min{qi, qjt}, if t = 1, max{0,min{qi \u2212 \u2211t\u22121 i=1 qji , qjt}}, if t \u2265 2. (13)\nRemember that in single-unit case, we derive the upper bound in (6) for the optimal matching based on the idea that each matched edge eij can be viewed as providing individual users ui and uj with equal benefit wij/2. Using this idea and the maximum individual weight in (12), we similarly derive the following upper bound of the total weight under the optimal allocation in any graph G = {U,E}. Lemma 3. For a general graph G = (U,E), the total weight\nof the optimal allocation is upper bounded by\nf?(G,W,Q) \u2264 1 2 \u2211 ui\u2208U |A(ui)|\u2211 t=1 wijtxijt . (14)\nIn particular, when qi = 1 for all user ui, (14) degenerates to (6). Note that in (14) we need to take expectation over both weight W and quantity Q distributions to compute the average performance.\nNext, to estimate a lower bound of the average total weight under the greedy allocation, we decompose the linear network into multiple single-unit linear networks. Different from the graph decomposition method proposed in Section 4.1, here we decompose the graph based on user quantities instead of edge weights. As an illustration, Fig. 10 shows the example for users with two possible quantity values (1 and 2). We split it to a single-unit linear network in sub-graph (1a) in Fig. 10 and the other sub-graph (1b) in Fig. 10 to include the rest users with extra quantities. This new graph decomposition method helps us find a lower bound on the greedy allocation\u2019s performance.\nNote that the average total weight of the single-unit greedy matchings in each sub-graph can be similarly analyzed as in Section 4.2. Finally, by comparing the derived lower bound for the greedy allocation with the upper bound for the optimal allocation in (14), we obtain the average performance ratio PR(G). Proposition 13. In large-scale linear networks with edge\nweights and user quantities uniformly chosen from the set V = {1, 1 + \u2206} and Q = {1, 2}, the average performance ratio achieved by the multi-unit version of Algorithm 1 satisfies\nlim n\u2192\u221e PR(G) \u2265 0.604 + 0.433\u2206 0.75 + 0.5\u2206 .\nThis ratio increases with weight difference \u2206 and is larger than 80.5% even when \u2206\u2192 0+.\n12\nThe proof is given in Appendix M of the Supplementary Material of this TMC submission. The obtained ratio increases with \u2206 and achieves its minimum value when all edges have the similar weights (i.e., \u2206 \u2192 0+). This is consistent with Proposition 4 for single-unit matching in linear networks.\nWe also extend our analysis to any possible weight and quantity distributions. In Fig 11, we illustrate the average performance ratio PR(G) of the multi-unit version of Algorithm 1 against different quantity set size Q. Similar to the case ofK = 2 in Proposition 13, the lower bound for PR(G) increases with \u2206 and is larger than 78%. It also decreases as Q increases, as the performance gap is enlarged from the single-unit version."
        },
        {
            "heading": "8 PRACTICAL APPLICATION ASPECTS",
            "text": "In practice, the network graphs that one may obtain by restricting the D2D sharing range may have different distributions than the 2D grids and the G(n, p) graphs used in our analysis. In addition to that, the actual performance of the algorithm might be degraded because of communication failures of nodes that are far or mutual interference among pairs. In this section, we provide an investigation of the above issues. We construct a case study of collaborative caching in a network graph based on real data for mobile user locations. We check how well our analytical G(n, p = d/n) performance measure in Section 8.1 captures the actual performance of the greedy algorithm on the above realistic graph instances, by tuning d to match the average number of neighbors in the instances. Later on, in Section 8.2, we analyze the impact of D2D communication failures on the optimal selection of D2D maximum sharing range. Finally, in Section 8.3, we study the tradeoff in choosing T (in minutes) for a dynamic scenario where users arrive/depart randomly and can participate in the sharing for several rounds."
        },
        {
            "heading": "8.1 Case Study of D2D Caching",
            "text": "The G(n, d/n) network studied in Section 6 assumes users connect with each other with the same probability p = d/n, and hence the average performance of Algorithm 1 in G(n, d/n) is characterized by the average neighbor number\nd. However, in practice, the connectivity distribution of users can follow different laws due to the structure of the environment and the D2D communication limitations. To validate our analysis in scenarios of practical interest, we run our greedy matching algorithm on the D2D caching network corresponding to real mobile user data and compare the numerical results with our analytically derived results for G(n, d/n) using Propositions 11 and 12.\nWe use the dataset in [32] that records users\u2019 position information in a three-story university building. We choose three instances in the peak (in term of density) time from the dataset and each instance contains hundreds of users. For these users, we consider random local caching where users leverage short-range communications (e.g., Bluetooth) to share cached files following common interests [6]. We define the set of popular files as F = {1, 2, . . . , 10} and each user ui caches three files from the library F randomly. The individual caching file set for ui is denoted by Fi \u2282 F with |Fi| = 3. Any two users who cache different files (i.e., Fi 6= Fj), are allowed to share diverse files with each other as long as the distance between them is less than the range L of the short-range communication. The corresponding weight (i.e., file sharing benefit) between them is determined by the number of different files they cache, i.e., wij = |Fi \u222a Fj | \u2212 |Fi \u2229 Fj |.\nIn the D2D caching network, by setting different values for L the structure of the graph changes and the average number d(L) of neighbors per user increases with L. In Fig. 12, we show the average matching weight (per user) of the greedy matching versus the average neighbor number d for the three practical instances of the resulting user network and its G(n, d/n) approximation. We observe that the average matching weight increases in d since increasing d (or increasing L) provides more sharing choices for each user. Our performance measure obtained for G(n, d/n) approximates well the actual performance of our algorithm."
        },
        {
            "heading": "8.2 D2D Sharing Range under Communication Failures",
            "text": "Our numerical results from the previous section suggest that, as expected, the average matching weight of the greedy matching keeps increasing with the maximum D2D sharing range L. But this happens only because we did not include the deterioration of the quality of the D2D links when L increases. In fact, for two users who are connected and share\n13\nresources via a D2D wireless link, a communication failure may occur more frequently due to the long-distance transmission or the mutual interference among different matched pairs. Such failures produce no matching and reduce the total matching weight. This suggests that after some value of L, the performance should decrease.\nTo show this tradeoff in choosing the best value for L, we assume there are two types of D2D communication failures: type-I failure caused by long-distance and typeII failure caused by interference. The transmission during resource sharing between any two users fails with a probability min{1, \u03b41D} for type-I failure and a probability min{1, \u03b42I}) for type-II failure, where D is the distance (in meters) between them and I is the number of interfering pairs in proximity. \u03b41 and \u03b42 are scalar values representing the impact of distance and interference on the communication failures. The failure probability increases in the distance (based on a practical path-loss model) and the number of interfering pairs (see [33]). In our simulation experiment, we consider a large number n = 10, 000 of users uniformly distributed in a circular ground cell with a radius of R = 1000 meters, and adjust the maximum sharing range L in which two users implement D2D resource sharing.\nIn Fig. 13, we depict the average matching weight (per user) of the greedy matching versus the maximum D2D sharing range L for three cases: A) without D2D communication failures, B) with D2D communication failures caused by long-distance (type-I failure), and C) with D2D communication failures caused by interference (type-II failure). We observe that the performance gap between cases A and B increases with L, as well as in cases A and C. Intuitively, when L is small, each user has few potential users to share resources or have interference, and failures occur rarely to be of an issue. But when L is large, since most of the neighbors are located remotely and the channels between matched pairs may cross each other, there is a higher chance for the algorithm to choose a remote neighbor, in which case it incurs large path-loss (type-I failure) or interference (typeII failure). This is in contrast to the model without failures, where the performance of the system is always increasing in L."
        },
        {
            "heading": "8.3 Optimal Time Interval",
            "text": "So far we have studied the average performance for a \u2018one-shot\u2019 D2D resource sharing instance captured by the static graph G. In this subsection, we extend our model to a dynamic environment of running Algorithm 1 over multiple sharing rounds when users remain connected in the system for multiple rounds. An interesting question is how frequently to repeat Algorithm 1 to meet changes in the graph structure due to users\u2019 random arrivals, departures and movement. If the time interval T (e.g., in minutes) to run the market matching algorithm is small, few new users will arrive and the existing users may not have extra resources to buy or sell. If T is large, many arriving users may depart before any resource sharing happens because they don\u2019t want to wait for too long. Of course, the choice of T depends on the type of resources that are being shared, how frequently a user can replenish its resources, if users remain active and connected to the application for a long time, etc. Hence our goal is not to estimate exactly the right T since this is context-dependent, but to investigate the fundamental tradeoff between using small and large values for T .\nTo characterize this tradeoff in system performance when choosing T , we consider a dynamic scenario that a fixed number \u03bb per minute of new users arrive for resource sharing in a circular ground cell with a radius of R = 1000 meters, and each user will leave the network after an exponential random time with rate \u00b5. The maximum D2D sharing range L is assumed to be 100m between users. Furthermore, for those who stayed since the last round, they are still interested to share resources again in the new round with probability \u03b3 < 1 and thus a user has resources to share for 1/(1 \u2212 \u03b3) rounds on average even if it remains in the system for a longer time. Let M be the average number of active participants in the steady-state. In our experiment setting, we have M = M\u03b3e\u2212\u00b5T + \u2211T\u22121 t=0 \u03bbe\n\u2212\u00b5(T\u2212t), where the first right-hand-side term of this equation tells the average number out of M users from the last round to stay and share in the current round, and the second term tells the average number of new arriving users during the last period T .\nWe run Algorithm 1 in this dynamic scenario and Fig. 14 shows the time-average total weight (per minute) versus\n14\nT under different values of \u03b3 and \u00b5. It first increases and then decreases with T , since a small T value does not allow enough new users to share, while a large T value discourages many users who are impatient to wait. The optimal T decreases with the probability \u03b3 for each user to keep sharing, since more users are available for sharing due to a larger \u03b3 and thus we can run the matching more frequently to minimize departures because of delayed service. The optimal T decreases with departure rate \u00b5, as users are more likely to leave the network and we need a smaller T to engage them in sharing."
        },
        {
            "heading": "9 CONCLUSIONS",
            "text": "In this paper, we adopt a greedy matching algorithm to maximize the total sharing benefit in large D2D resource sharing networks. This algorithm is fully distributed and has sub-linear complexity O(log n) in the number of users n. Though the approximation ratio of this algorithm is 1/2 (a worst-case result), we conduct average-case analysis to rigorously prove that this algorithm provides a significantly better average performance ratio compared to the optimum in large linear and grid networks. We then extend our analysis to random networks G(n, p) and to multi-unit resource sharing. We also use real mobile user location data to show that our analytical G(n, p) performance measure approximates well D2D networks encountered in practice. Finally, we consider the effect of communication failures due to increasing the communication range and study the related optimization problem.\nAn interesting direction for future research is to consider the case of users staying for multiple rounds and being able to choose when to get matched. Users become strategic: accept a current matching or wait for a possibly better one in the future. The equilibrium strategies in such a system depend on parameters such as the distribution of matching values and the rate of arrivals and departures. Even if we restrict the topology of the graph to be linear, how do we analyze the resulting game? We also plan to extend our D2D resource sharing model that involves directly connected devices to multi-hop networks where intermediate devices can serve as \u2018connectors\u2019 between the source and destination. One can capture the user connectivity graph with one-hop D2D connections and then add the edges when considering two-hop connections, etc."
        },
        {
            "heading": "APPENDIX A PROOF OF PROPOSITION 1",
            "text": "For any user ui in the linear network, let H(ui) denote the length of the longest chain (sequence of edges) that has nondecreasing weights and starts from ui towards the left or right side. Let I(ui) be the indicator variable that H(ui) is greater than c log n for some constant c. Let I(G) be the indicator variable that the linear graph G has at least one such chain with length greater than c log n. Then we have\nE(I(G)) \u2264 E( n\u2211 i=1 I(ui)) \u2264 2nq, (15)\nwhere q denotes the probability that c log n consecutive edges has non-decreasing weights.\nThe weight of each edge is assumed to independently take value from K kinds of weight values {v1, v2, . . . , vK} according to the probability distribution P = {p1, p2, . . . , pK}. Then, for any c log n edges, there are totally:\nK\u22121\u2211 k=1\n( 1 + c log n\nk\n)( K \u2212 2 k \u2212 1 ) ,\nkinds of non-decreasing weight combinations, and for each of the combinations, the probability to happen is upper bounded by (max{p1, p2, . . . , pK})c logn. Therefore, the upper bound of the probability q that any c log n consecutive edges have non-decreasing weights is given by: q \u2264 (max{p1, p2, . . . , pK})c logn K\u22121\u2211 k=1 ( 1 + c log n k )( K \u2212 2 k \u2212 1 )\n\u2264 nK(max{p1, p2, . . . , pK})c logn.\nThen, we have:\nE(I(G)) \u2264 2nK+1(max{p1, p2, . . . , pK})c logn.\nNote that when c > K+1\u2212 log max{p1,p2,...,pK} , E(I(G)) converges to 0 when n\u2192\u221e.\nTherefore, we can conclude that, in 1 \u00d7 n grid, the algorithm run in O(log n) time w.h.p. according to the first moment method."
        },
        {
            "heading": "APPENDIX B PROOF OF PROPOSITION 2",
            "text": "In the first step of the graph separation method, we create a new graph by reducing the weights of all edges by the smallest possible weight value v1 and the graph\u2019s weight vector is simplified to W \u2032 = W \u2212 v1 = {w1 \u2212 v1, w2 \u2212 v1, . . . , wn \u2212 v1} with zero weight for some wi = v1 (if any). First note that the optimal matching of the graph with weight vector W = {w1, w2, . . . , wn} may no longer be the optimal matching of the graph with weight vector W \u2032 = W \u2212 v1 = {w1 \u2212 v1, w2 \u2212 v1, . . . , wn \u2212 v1}, and thus we have \u2211n i=1(wi \u2212 v1)x?i (W ) = \u2211n i=1 w \u2032 ix ? i (W ) \u2264\u2211n\ni=1 w \u2032 ix ? i (W \u2032) = f?(W \u2032) where x?i (W ) is the optimal matching indicator for edge ei in a graph with weight vector\nW . Thus, the relationship between f?(W ) and f?(W \u2032) satisfies the following inequality\nf?(W )= n\u2211 i=1 x?i (W )wi = v1 n\u2211 i=1 x?i (W )+ n\u2211 i=1 (wi\u2212v1)x?i (W )\n\u2264 v1 n\n2 + n\u2211 i=1 (wi \u2212 v1)x?i (W )\n\u2264 v1 n\n2 + f?(W \u2032), (16)\nwhere the first inequality uses the fact that \u2211n i=1 x ? i (W ) \u2264 n 2 . This is because that, for any linear network with n users, no matter what its weight vector W = (w1, w2, . . . , wn) is, the total number of edges in the optimal matching of the graph is dn2 e at most and we ignore the ceiling operation since we consider a very large n. After taking expectation, the average total weights of the optimal matchings in W and W \u2032 satisfies\nEW [f?(W )] \u2264 v1 n\n2 + EW [f?(W \u2032)]. (17)\nIn the graph with weight vectorW \u2032 = W\u2212v1, the weight w\u2032i = wi \u2212 v1 of an edge ei whose original weight wi = v1 now becomes 0 and such edge appears with probability Pr(wi = v1) = p1. We remove all these edges as they have no influence on computing the optimal matching. Then, the graph becomes a lot of linear segments with different length as in Fig. 4 and the average total number of remaining edges is n(1\u2212 p1).\nNote that each segment starts from an edge with nonzero weight, and the following edge has zero weight with probability p1 and nonzero weight with probability 1 \u2212 p1. Thus, a segment has length 1 with probability p1 and has length larger than 1 with probability 1 \u2212 p1. Similarly, a segment of length t needs t \u2212 1 following consecutive nonzero-weight edges and then ends with a zero-weight edge. Thus, the probability that a segment has length t is p1(1\u2212 p1)t\u22121. For any nonzero-weight edge, the probability that this edge is within a segment of length t now is tp1(1\u2212p1)t\u22121\u2211+\u221e k=1 kp1(1\u2212p1)k\u22121\n= tp21(1 \u2212 p1)t\u22121. Accordingly, the average number of edges that are in a segment with length t is given by the average total number of nonzero-weight edges in the graph with weight vector W \u2032 times the probability, i.e., n(1\u2212 p1)\u00d7 tp21(1\u2212 p1)t\u22121. Further, the average number of segments with length t is np21(1\u2212 p1)t.\nFor a segment of length t, at most d t2e edges are included in any possible matching. Thus, for the graph with weight vector W \u2032, the average total number of nonzero-weight edges included in the optimal matching EW [ \u2211n i=1 x ? i (W \u2032)] \u2264 \u2211+\u221e t=1 np 2 1(1\u2212 p1)td t2e = n 1\u2212p1 2\u2212p1 . Now, we further deduct v2 \u2212 v1 from the weights of all nonzeroweight edges in the second step of the graph separation method to create another new graph with weight vector W \u2032\u2032 = (W \u2032 \u2212 (v2 \u2212 v1))+ and obtain that\nEW [f?(W \u2032)] \u2264 (v2 \u2212 v1) 1\u2212 p1 2\u2212 p1 n+ EW [f?(W \u2032\u2032)]. (18)\nwhere the inequality is also because the total weight of the optimal matching in graph with W \u2032\u2032 must be larger than or equal to the total weight of any possible matching.\n17\nIf weight space size K = 2, by aggregating the inequalities (17), (18) and the fact that f?(W \u2032\u2032) = 0 as W \u2032\u2032 = (W \u2212 v2)+ = 0, we finally obtain the upper bound of EW [f?(W )] in the case of K = 2 as follows:\nEW [f?(W )] \u2264 v1 n\n2 + (v2 \u2212 v1) 1\u2212 p1 2\u2212 p1 n.\nFor a graph with weight set size K larger than 2, similar to the case of K = 2 with {v1, v2}, we first deduct the weights of all edges with nonzero weight by v1 in step 1 and by v2\u2212v1 in step 2. For the graph created in step 2 with weight vectorW \u2032\u2032 = (W\u2212v2)+, the edges with zeros weight appear with probability p1 + p2. Then, we can also remove all the edges with zero weight in this graph, and prove that the average total number of nonzero-weight edges included in the optimal matching, \u2211n i=1 x ? i (W\n\u2032\u2032) must be less than or equal to n 1\u2212(p1+p2)2\u2212(p1+p2) using the similar arguments. Moreover, similarly, we further deduct v3 \u2212 v2 from the weights of all nonzero-weight edges to create another new graph with weight vector W \u2032\u2032\u2032 = (W \u2212 v3)+ and prove that\nEW [f?(W \u2032)] \u2264 (v3 \u2212 v2)n 1\u2212 p1 \u2212 p2 2\u2212 p1 \u2212 p2 + EW [f?(W \u2032\u2032\u2032)].\nBy repeating such deducting procedure for K steps in the separation method, we can finally create a new graph with zero weight vector (W \u2212 vK)+ = 0 and the relationship between the total weight of the optimal matching in the original graph with weight vector W and the total weight of the optimal matching in the decomposed graphs is\nEW [f?(W )] \u2264 v1 n\n2 +(v2\u2212v1)n 1\u2212p1 2\u2212p1 +(v3\u2212v2)n 1\u2212p1\u2212p2 2\u2212p1\u2212p2 +\n\u00b7 \u00b7 \u00b7+ (vK \u2212 vK\u22121)n 1\u2212\n\u2211K\u22121 i=1 pi\n2\u2212 \u2211K\u22121 i=1 pi + EW [f?((W \u2212 vK)+])\n= v1 n\n2 + n K\u22121\u2211 k=1 (vk+1 \u2212 vk) 1\u2212 \u2211k i=1 pi 2\u2212 \u2211k i=1 pi .\nThe proof is completed."
        },
        {
            "heading": "APPENDIX C PROOF OF PROPOSITION 3",
            "text": "In the case of K = 2, the recurrence formula of the average total weight under the greedy matching is given by:\nan = p 2 1v1 + (p2 + p1p2)v2 + (p2 + p 2 1)an\u22122 + p1p2an\u22123,\nand in the case of K = 3, we also have\nan = p1(p2p3 + p1)v1 + p2(p1 + p2)(p1 + 1)v2\n+ p3(p1p2 + p1 + p2 + 1)v3 + (p 2 1 + p 2 2 + p1p2 + p3)an\u22122 + (p1p 2 2 + p1p3 + p 2 1p2 + p2p3)an\u22123 + p1p2p3an\u22124.\nThus, we can imply that, for any arbitrary K, the recurrence formula of sequence {an} has the following structure:\nan =\u03b21v1 + \u03b22v2 + \u00b7 \u00b7 \u00b7+ \u03b2KvK + \u03b31an\u22122 + \u03b32an\u22123 + \u00b7 \u00b7 \u00b7+ \u03b3Kan\u2212K\u22121,\nwhere \u03b3i denotes the probability that edge ei is the first edge must be added in Algorithm 1 (i.e., the first edge satisfying wi \u2265 wi+1 and wi > wi\u22121), and \u03b2k denotes the probability\nthat an edge with weight vk is added because we add the first edge must be added (e.g., edge ei is the first edge must be added and edges ei\u22122, ei\u22124, and so on will also be added).\nTo obtain the general formula, we have to study the expression of \u03b3i and \u03b2k. First note that, given edge ei is the first edge must be added and wi = vj (probability is Pr(wi = vj) = 1 K ), then we have w1 < w2 < w3 \u00b7 \u00b7 \u00b7 <\nwi\u22121 < vj (probability is ( 1K ) i\u22121(j\u22121 i\u22121 ) ) and wi+1 \u2265 vj (probability is j 1K ). Thus, we have\n\u03b3i = K\u2211 j=i j( 1 K )i+1 ( j \u2212 1 i\u2212 1 ) .\nNext, we focus on finding the expression of \u03b2k. We first consider the case of k = K and \u03b2K denote the probability that an edge with the largest weight vK is added because we add the first edge must be added. Note that, if an edge ei is added because of adding the first edge must be added, then the first edge must be edge ei itself or an edge that is in position after ei and has higher weight than ei. Since vK is the largest weight, an edge ei with weight vK will be added if and only if itself is the first edge must be added, i.e. w1 < w2 < \u00b7 \u00b7 \u00b7 < wi\u22121 < wi = vK \u2265 wi+1 (the probability is ( 1K ) i (K\u22121 i\u22121 ) ). Thus, \u03b2K is given by\n\u03b2K = K\u2211 i=1 ( 1 K )i ( K \u2212 1 i\u2212 1 ) = 1 K (1 + 1 K )K\u22121.\nSimilarly, we consider the case of k = K\u22121. Note that, if an edge ei with weight vK\u22121 is not the first edge must be added but it is added because of adding the first edge, then the first edge must be in one of the position i+ 2, i+ 4 or above. In such a case, we must have wi+2 > wi+1 > wi = vK\u22121. But this is impossible since we only have one possible weight value larger than vK\u22121. Thus, similarly, an edge ei with weight vK\u22121 will be added if and only if itself is the first edge must be added, i.e., w1 < w2 < \u00b7 \u00b7 \u00b7 < wi\u22121 < wi = vK\u22121 \u2265 wi+1 (the probability is ( 1K ) i (K\u22122 i\u22121 ) K\u22121 K ). Accordingly, \u03b2K\u22121 is given by\n\u03b2K\u22121 = K\u22121\u2211 i=1 ( 1 K )i ( K \u2212 2 i\u2212 1 ) K \u2212 1 K = K \u2212 1 K2 (1 + 1 K )K\u22122.\nDifferent from the above two cases, an edge ei with weight vK\u22122 can be added not only when itself is the first edge must be added, i.e., w1 < w2 < \u00b7 \u00b7 \u00b7 < wi\u22121 < wi = vK\u22122 \u2265 wi+1 (the probability is ( 1K ) i K\u22122 K (K\u22123 i\u22121 ) ), but also when the edge ei+2 is the first edge must be added and wi+1 = vK\u22121 and wi+2 = vK , i.e., w1 < w2 < \u00b7 \u00b7 \u00b7 < wi\u22121 < wi = vK\u22122 < wi+1 = vK\u22121 < wi+2 = vK \u2265 wi+3 (the probability is ( 1K ) i (K\u22123 i\u22121 ) ( 1K ) 2). Thus, \u03b2K\u22122 is given by\n\u03b2K\u22122 = K\u22122\u2211 i=1 ( 1 K )i ( K\u22123 i\u22121 ) ( K\u22122 K + 1 K2 )= (K\u22121)2 K3 (1+ 1 K )K\u22123.\n18\nIn general, we can obtain the expression of \u03b2K\u2212t for any t \u2265 K as follows:\n\u03b2K\u2212t = K\u2212t\u2211 i=1 ( 1 K )i ( K \u2212 t\u2212 1 i\u2212 1 ) ( 1 K (K \u2212 t)\n+ ( 1\nK )3( t\u22121\u2211 j=1\n(j +K \u2212 t+ 1) ( j\n1\n) )\n+ ( 1\nK )5( t\u22121\u2211 j=3\n(j +K \u2212 t+ 1) ( j\n3\n) ) + \u00b7 \u00b7 \u00b7 )\n= (1 + 1\nK )K\u2212t\u22121\n1\nK (\n1\nK (K \u2212 t)\n+ \u2211\ni=3,5,...,K+1\n( 1\nK )i( t\u22121\u2211 j=i\u22122\n(j +K \u2212 t+ 1) ( j\ni\u2212 2\n) )),\n(19)\nwhere the second term can be simplified as follows:\u2211 i=3,5,...,K+1 ( 1 K )j( t\u22121\u2211 j=i\u22122 (j +K \u2212 t+ 1) ( j i\u2212 2 ) )\n(c) = t\u22121\u2211 j=1 \u2211 i=3,5,...,j+2 ( 1 K )i(j +K \u2212 t+ 1)\n( j\ni\u2212 2\n)\n= t\u22121\u2211 j=1 \u2211 i=1,3,...,j ( 1 K )i+2(j +K \u2212 t+ 1)\n( j\ni ) (d) =\nt\u22121\u2211 j=1 ( 1 K )2(j +K \u2212 t+ 1) +\u221e\u2211 i=1 (\u22121)i + 1i 2 ( 1 K )i+2\n( j\ni\n)\n= (1\u2212 1 K )t \u2212 K \u2212 t K ,\nwhere (c) exchanges the integration order and (d) is based on the formula \u2211n i=1 ia i (n i ) = na(1+a)n\u22121. By substituting the above equation back into (19), we obtain\n\u03b2K\u2212t = (1 + 1\nK )K\u2212t\u22121\n1 K (1\u2212 1 K )t\n= (1 + 1\nK )K\n(K \u2212 1)t\n(K + 1)t+1 , (20)\nand it can be rewritten as\n\u03b2k = (K \u2212 1)K\u2212k\nKK(K + 1)\u2212k+1 .\nThe proof is completed."
        },
        {
            "heading": "APPENDIX D PROOF OF PROPOSITION 4",
            "text": "In the case that k = 2, we have the following recurrence formula for {an}:\nan = p 2 1v1 + (p2 + p1p2)v2 + (p2 + p 2 1)an\u22122 + p1p2an\u22123.\n(21)\nNote that a general solution to (21) is given by\nan = p21v1 + (p2 + p1p2)v2 2(p2 + p21) + 3p1p2 n+ b,\n= p21v1 + (p2 + p1p2)v2\n2 + p1p2 n+ b, (22)\nwhere b can be any constant value. However, in our problem with a1 = 0, a2 = p1v1 + p2v2, the first two terms of the sequence do not follow an arithmetic progression. To obtain the converged b as n goes to infinity, we first list the following equations based on (21):\na1 = 0;\na2 = p1v1 + p2v2; a3 = p 2 1v1 + (p2 + p1p2)v2 + (p2 + p 2 1)a1; a4 = p 2 1v1 + (p2 + p1p2)v2 + (p2 + p 2 1)a2 + p1p2a1;\n. . .\nan\u22121 = p 2 1v1 + (p2 + p1p2)v2 + (p2 + p 2 1)an\u22123 + p1p2an\u22124; an = p 2 1v1 + (p2 + p1p2)v2 + (p2 + p 2 1)an\u22122 + p1p2an\u22123.\nBy summing them up, we obtain that\nan + an\u22121 + p1p2an\u22122 =\n(p21v1 + (p2 + p1p2)v2)(n\u2212 2) + p1v1 + p2v2. (23)\nTherefore, by substituting (22) into (23), we can show that b converges to (2+p1p2)(p1v1+p2v2)\u22123(p 2 1v1+(p1+p1p2)v2)\n(2+p1p2)2 as n \u2192\n\u221e. We finally obtain the general formula for the sequence {an} in the limit of large enough network size as follows:\nlim n\u2192\u221e\nEW [f\u0302(W = {w1, w2 . . . , wn})]\n= lim n\u2192\u221e\nan = p21v1 + (p2 + p1p2)v2\n2p2 + 2p21 + 3p1p2 n+O(1), (24)\nBased on (3) and (24), the average performance guarantee of Algorithm 1 is given by\nlim n\u2192\u221e\nPR(n) \u2265 p 2 1v1 + (p2 + p1p2)v2\n(2p2 + 2p21 + 3p1p2)( v1 2 + (v2 \u2212 v1) 1\u2212p1 2\u2212p1 )\n,\n(25)\nThen, by substituting p2 = 1\u2212 p1 into (25), we have\nlim n\u2192\u221e\nPR(G) \u2265 p 2 1v1 + (1\u2212 p21)v2\n(2 + p1 \u2212 p21)( p1 4\u22122p1 v1 + 1\u2212p1 2\u2212p1 v2)\n, (26)\nwhich is a function of v1, v2 and p1. Note that when v2 and p1 are fixed, this function is decreasing in v1 since the ratio of the coefficients of v1 in the numerator and the denominator p21 p1\n4\u22122p1 is less than or equal to the ratio of the constant terms\nin the numerator and the denominator 1\u2212p 2 1\n1\u2212p1 2\u2212p1 for any 0 \u2264 p1 \u2264 1. Moreover, the intrinsic bound for v1 is 0 \u2264 v1 < v2. Therefore, the average performance guarantee must achieve the minimum value when v1 infinitely approaches v2, i.e., v1 \u2192 v\u22122 . Now, given v1 \u2192 v \u2212 2 , (26) can be further rewritten as\nlim n\u2192\u221e PR(G) \u2265 2 (2 + p1 \u2212 p21) = 2 9 4 \u2212 (p1 \u2212 1 2 ) 2 .\nThis guarantee achieves its minimum value 89 when p1 = 1 2 obviously. Thus, we can conclude that the average performance guarantee given in (26) achieves its minimum value 89 when v2 v1 \u2192 1+ and p1 = p2 = 12 . The proof is completed.\n19"
        },
        {
            "heading": "APPENDIX E PROOF OF PROPOSITION 5",
            "text": "For any general weight set size K , we can similarly derive the general formula of sequence {an} as follows\nlim n\u2192\u221e\nan = n \u03b21v1 + \u03b22v2 + \u00b7 \u00b7 \u00b7+ \u03b2KvK\n2\u03b31 + 3\u03b32 + \u00b7 \u00b7 \u00b7+ (K + 1)\u03b3K +O(1). (27)\nBy substituting \u03b2k = (K\u22121)K\u2212k\nKK(K+1)\u2212k+1 and \u03b3k =\n1 Kk+1 K\u2211 i=k i (i\u22121 k\u22121 ) into (27), we obtain the following formula:\nlim n\u2192\u221e an = n K\u2211 k=1 vk (K \u2212 1)K\u2212k (K + 1)K\u2212k+1 +O(1).\nMoreover, in Proposition 2, we prove that the average total weight under the optimal matching is upper bounded as follows\nEW [f?(W )] \u2265 v1 n\n2 + n K\u22121\u2211 k=1 (vk+1 \u2212 vk) 1\u2212 \u2211k i=1 pi 2\u2212 \u2211k i=1 pi\n= n K\u22121\u2211 k=0 vk K (2K + 1\u2212 k)(2K \u2212 k) ,\nThus, the average performance guarantee is given by:\nPR(G) \u2265 \u2211K k=1 vk (K\u22121)K\u2212k (K+1)K\u2212k+1\u2211K\nk=1 vk K (2K+1\u2212k)(2K\u2212k) . (28)\nNote that the ratio of the coefficients of vk in the numerator and the denominator increases as k increases, i.e.,\n(K\u22121)K\u2212k (K+1)K\u2212k+1\nK (2K+1\u2212k)(2K\u2212k)\n<\n(K\u22121)K\u2212k\u22121 (K+1)K\u2212k\nK (2K\u2212k)(2K\u2212k\u22121)\n,\u2200k \u2208 {1, 2,. . .,K\u2212 1}.\nThus, the guarantee given in (28) is minimized when v1 infinitely approaches v2, v2 infinitely approaches v1 and so on. Moreover, the minimum value is given by\nPR(G) \u2265 \u2211K\u22121 t=0 (K\u22121)t (K+1)t+1\u2211K\u22121\nt=0 K (K+1+t)(K+t)\n= 1\u2212 (K \u2212 1 K + 1 )K ,\nwhich is decreasing in K when K \u2265 2 and the limit is given by:\nlim K\u2192\u221e 1\u2212(K \u2212 1 K + 1 )K= lim K\u2192\u221e 1\u2212(1\u2212 2 K + 1 ) K+1 2 2K K+1 =1\u2212e\u22122.\nMoreover, note that the coefficients of vK in the numerator and the denominator are the same. Thus, the guarantee given in (28) is maximized when 0 \u2264 v1 < v2 < \u00b7 \u00b7 \u00b7 < vK\u22121 vK and the maximum value is given by\nPR(G) \u2265 1\nK+1 1 K+1 = 1.\nThe proof is completed."
        },
        {
            "heading": "APPENDIX F PROOF OF PROPOSITION 6",
            "text": "For any user ui \u2208 U with degree d(ui), the probability that the maximum weight of all the d(ui) neighboring edges is equal to or less than vk is given by ( \u2211k i=1 pk) d(ui)\nwhere \u2211k i=1 pk is the probability that one edge has weight equal to or less than vk. Thus, the average maximum weight of all d(ui) edges incident to user ui is given by\u2211K k=1 vk(( \u2211k i=1 pk) d(ui) \u2212 ( \u2211k\u22121 i=1 pk)\nd(ui)). Further, the expectation of (6) can be given by\nEW [f?(G,W )] \u2264 1\n2 \u2211 ui\u2208U K\u2211 k=1 vk(( k\u2211 i=1 pi) d(ui) \u2212 ( k\u22121\u2211 i=1 pi) d(ui)).\nThe proof is completed."
        },
        {
            "heading": "APPENDIX G PROOF OF PROPOSITION 7",
            "text": "We first note that in n\u00d7n grid, the number of possible chains that start from any given node ui and have non-decreasing weights is no longer two (toward left or right) as in 1\u00d7n grid networks, but still limited to be less than 4K (the weight set size K is a given constant). This is because we assume in Algorithm 1, every node will need to use priorities over ties among neighbors whose edge has the same weight and thus the number of possible chains that are relevant to a user\u2019s decisions is significantly reduced. Similarly, let I(ui) be the indicator variable that the length H(ui) of the longest chain (sequence of edges) that has non-decreasing weights and starts from ui is greater than c log n for some constant c. Let I(G) be the indicator variable that the linear graph G has at least one such chain with length greater than c log n. Then we have\nE(I(G)) \u2264 E( n\u2211 i=1 I(ui)) \u2264 4Kn2q, (29)\nBy using the similar arguments as in linear networks, we can prove that in n \u00d7 n grid, the algorithm run in O(log n) time w.h.p.."
        },
        {
            "heading": "APPENDIX H PROOF OF PROPOSITION 8",
            "text": "Based on Proposition 6, we are able to compute the upper bound of the average total weight under the optimal matching for any given graph. We now consider a n \u00d7 n grid and that the weight set V = {v1 = 1, v2 = 1 + \u2206} and the weight probability distribution P = {p1 = 12 , p2 = 1 2} are given. Note that, in this gird, there are (n \u2212 2)2 nodes with degree 4, 4n \u2212 8 nodes with degree 3, and 4 nodes with degree 2 in the grid. Moreover, the average maximum weight of a node with degree d is 2\u2212 ( 12 )\nd. Thus, we finally obtain the average total weight under the optimal matching in the grid is upper bounded by 16+15\u220632 n+ o(n).\nRegarding the average total weight of greedy matching, we first note that for each 2 \u00d7 n sub-grid in step 2, the recursive formula for the sequence {an} is given by\nan = 19 + 15\u2206\n16 +\n1 4 an\u22121 + 5 8 an\u22122 + 1 8 an\u22123.\n20\nBased on this, we derive the general formula an = 19+15\u220630 n by using asymptotic analysis.\nThen, after the matching in Step 2, users in the second row might be unmatched and are available for the matching in step 3. To compute the probability pM that any user ui in the first row is matched to her vertical neighbor ui+n in the second row in step 2, we first define the proposal probability yrk (y l k) that ui receives a proposal from her right (left) neighbor given the weight between them is vk. Moreover, we have that yrk and y l k satisfy the following recursive formulas:\nyrk = k\nK (1\u2212 K\u2211 t=k+1 yrt K ),\nylk = k\nK (1\u2212 K\u2211 t=k yrt K ).\nWhen K = 2, we can obtain yr1 = 1 4 , y r 2 = 1, y l 1 = 4 15 and yl2 = 2 3 . Based on this, we can compute the matching probability pM = 415 for any user in the second row in step 2. After removing these matched users, the remaining graph in the second row becomes a lot of linear segments in step 3 as shown in Fig. 6. We first compute the average number of segments with length t by using probability analysis, which is given by (1 \u2212 pM )tp2Mn. Note that, for a linear segment with size 1\u00d7 t, its greedy matching is denoted by at. Then, the average weight caused by matched remaining edges in second row is equal to \u2211\u221e t=1(1\u2212 pM )tp2Mnat.\nTo compute that, we need the value of at for any t. We have a1 = 0, a2 = 2+\u22062 , a3 = 4+3\u2206 4 and at = 4+3\u2206 4 + 3 4at\u22122 + 1 4at\u22123 according to (4). Thus, we can compute the value of at for a finite number of t, for example, from t = 1 to t = 100, and further derive a lower bound for\n\u2211\u221e t=2(1 \u2212 pM )tp2Mnat, which is given by\u2211100\nt=2(1 \u2212 pM )tp2Mnat \u2248 (0.288 + 0.1967\u2206)n. Note that the value of \u2211\u221e t=101(1 \u2212 pM )tp2Mnat is almost zero since (1\u2212pM )t decreases exponentially while at increases linearly in t.\nIn sum, we can prove that the average total weight under the greedy matching in the n\u00d7 n grid is lower bounded by\nlim n\u2192\u221e\nEW [f\u0302(G,W )] \u2265 ( 19 + 15\u2206\n30 + 0.288 + 0.1967\u2206)\nn2\n2\n\u2265 0.9213 + 0.6967\u2206 2 n2 + o(n2)\nwhere EW [f\u0302(G,W )] denotes the average total weight under the greedy matching in the n\u00d7 n grid.\nBy combining this with the previously derived upper bound for the optimal matching, we finally obtain\nlim n\u2192\u221e PR(G) \u2265 0.9213 + 0.6967\u2206 1 + 0.9375\u2206 .\nThe proof is completed.\nAPPENDIX I PROOF OF PROPOSITION 9 In the random graph G(n, p) with a large user number n and a constant connection probability p, the probability that\nthere exist \u221a n nodes that have less edges than \u221a n among them is upper bounded by\nlim n\u2192\u221e ( n\u221a n )\u221a n\u22121\u2211 i=0 (\u221a n( \u221a n\u22121) 2 i ) yi(1\u2212 p) \u221a n( \u221a n\u22121) 2 \u2212i\n\u2264 lim n\u2192\u221e\n(1\u2212 p) n\u2212 \u221a n 2 ( n\u221a n )2 \u221an\u22121\u2211 i=0 ( p 1\u2212 p )i = 0.\nTherefore, for any \u221a n nodes in G(n, p), there are more than\u221a\nn edges among them with probability 1. Let Ei denote the number of edges in the random graph after the greedy matching algorithm adding i edges. The probability that the heaviest edge among Ei edges has weight vK is 1 \u2212 ( \u2211K\u22121 k=1 pk)\nEi . Thus, the probability that the first heaviest edge to add in the greedy algorithm has weight vK is given by 1 \u2212 ( \u2211K\u22121 k=1 pk)\nE0 . After adding the first edge in the greedy algorithm, the probability that the heaviest edge to add among the remaining edges has weight vK is given by (1 \u2212 ( \u2211K\u22121 k=1 pk) E0)(1 \u2212 ( \u2211K\u22121 k=1 pk)\nE1) \u2265 1 \u2212 ( \u2211K\u22121 k=1 pk) E0 \u2212 ( \u2211K\u22121 k=1 pk)\nE1 . Similarly, we have that when n \u2192 \u221e, the probability that the (n \u2212 \u221a n)/2-th edge to add have weight vK satisfies\nlim n\u2192\u221e 1\u2212 (n\u2212 \u221a n)/2\u22121\u2211 i=0 ( K\u22121\u2211 k=1 pk) Ei\n\u2265 lim n\u2192\u221e\n1\u2212 n\u2212 \u221a n 2 ( K\u22121\u2211 k=1 pk) E(n\u2212 \u221a n)/2\u22121\n\u2265 lim n\u2192\u221e\n1\u2212 n\u2212 \u221a n 2 ( K\u22121\u2211 k=1 pk) \u221a n = 1, (30)\nwhere the second inequality is because the number of edges E(n\u2212 \u221a n)/2\u22121 among the remaining \u221a n+2 unmatched users\nis large than \u221a nwith probability 1 when n\u2192\u221e as we have proved earlier, Therefore, we have that all the first (n \u2212 \u221a n)/2 edges added to the greedy matching have the largest weight vK with probability 1. Moreover, an obvious upper bound of the total weight under the optimal matching is given by nvK/2 since any two users can be matched with an edge with weight vK at most. Therefore, the average performance guarantee of the greedy algorithm is given by:\nlim n\u2192\u221e\nvK((n\u2212 \u221a n)/2)\nvKn/2 = 1.\nThe proof is completed."
        },
        {
            "heading": "APPENDIX J PROOF OF PROPOSITION 10",
            "text": "Similarly, for any user ui in the linear network, let H(ui) denote the length of the longest chain (sequence of edges) that has non-decreasing weights and starts from ui. Let I(ui) be the indicator variable that H(ui) is greater than c log n for some constant c. Let I(G) be the indicator variable\n21\nthat the linear graph G has at least one such chain with length greater than c log n. Then we have\nE(I(G)) \u2264 E( n\u2211 i=1 I(ui)) = nE(I(u1))\n\u2264 n(d(n\u2212 1) n )lognq < ndc lognq,\nwhere q denotes the probability that c log n consecutive edges has non-decreasing weights. The second inequality is because the expected size of ui\u2019s c log n-th generation is given by (d(n\u22121)n )\nlogn. By using the similar arguments as in the proof of Proposition 1, we have q < nK(max{p1,p2,...,pK}2 ) c logn. Then we obtain:\nE(I(G)) \u2264 (1 2 )\u2212KnK+1dc logn( max{p1, p2, . . . , pK} 2 )c logn.\n= ( 1\n2 )\u2212KnK+1\u2212c(\u2212 log\nmax{p1,p2,...,pK} 2 \u2212log d)\nNote that when d < 2max{p1,p2,...,pK} , there always exists a constant c > K+1log 2\u2212log max{p1,p2,...,pK}\u2212log d that makes E(I(G)) converge to 0 when n \u2192 \u221e. Therefore, we can conclude that the algorithm will terminate within c log n iterations w.h.p. according to the first moment method."
        },
        {
            "heading": "APPENDIX K PROOF OF PROPOSITION 11",
            "text": "In G(n, d/n) with d < 1, to prove (9), we first show the connected component of any user ui has no loops w.h.p., and thus we can analyze the conditional expectation of EG\u223cG(n,d/n)[xi(G)|C(ui) = 0] assuming the number of loops C(ui) in ui\u2019s component is zero, instead of directly analyzing EG\u223cG(n,d/n)[xi(G)] (step 1 below). Then, it remains to show EG\u223cG(n,d/n)[xi(G)|C(ui) = 0] can be well approximated by ET\u223cT (d),W [xroot(T,W )] in the approximated random tree T (d), as both of them are considered in graphs without loops (step 2 below).\nStep 1: In G(n, d/n), there are totally a random number of loops each of which includes at least three users, and for any t \u2265 3 users, they have totally (t\u22121)!2 kinds of permutations to form a loop. Thus, the average total number of loops is\nE(Loop)= n\u2211 t=3\n( n\nt\n) (t\u22121)!\n2 ( d n )t< 1 6 n\u2211 t=3 (d)t< (d)3 6(1\u2212d) , (31)\nwhich implies that regardless of the graph size n, there are at most a constant number of loops. Moreover, since [31] proves that G(n, d/n) almost surely has no connected components of size larger than c log n for some constant c, the average size of the largest connected component in G(n, d/n) is only o(n). By combining this with (31), the average total number of users in the components with loops should be less than o(n)E(Loop) = o(n). Therefore, the probability that user ui is one of these users who are in components with loops is\nlim n\u2192\u221e\nProb(C(ui) \u2265 1) = o(n)\nn = 0, (32)\nwhere C(ui) denotes the number of loops in the connected component of user ui. Based on (32), we now have:\nlim n\u2192\u221e EG\u223cG(n, dn )[xi(G)]= limn\u2192\u221eEG\u223cG(n, dn )[xi(G)|C(ui)=0]. (33)\nStep 2: In this step, our problem becomes to prove that the conditional expectation EG\u223cG(n,d/n)[xi(G)|C(ui) = 0] can be well approximated by ET\u223cT (d),W [xroot(T,W )]. Given the connected component of user ui is a tree (i.e., with C(ui) = 0 loop), we start by first showing that the users in the component connect with each other in a similar way as in the random tree T (d).\nWe do a breadth-first search (BFS) starting from ui to explore all its connected users by searching all its direct neighbors prior to moving on to the two-hop neighbors. Note that the number of neighbors we explore from user ui follows the binomial distribution B(n \u2212 1, d/n). In fact, for any user in the BFS tree of ui, the number of new neighbors we directly explore from this user follows the binomial distribution B(n\u2212m, d/n) where m is the number of users that have already been explored currently and cannot be explored again (otherwise a loop would occur). Meanwhile, in T (d), each node gives birth to children according to the same Poisson distribution Poi(d) no matter how large the tree currently is.\nNext, we prove that the difference between the branching under B(n\u2212m, d/n) and Poi(d) is trivial. Actually, for any t,m \u2264 c log n, the ratio of the probability of getting t from distribution B(n \u2212 m, d/n) and the probability of getting t from distribution Poi(d) is bounded by\n1\u2212 1\u221a n \u2264 (n\u2212m t ) ( dn ) t(1\u2212 dn ) n\u2212m\u2212t e\u2212ddt/(t)! \u2264 1 + 1\u221a n , (34)\nwhen n is sufficiently large. We define \u0398 as the set of all possible graph structures that the random tree T (d) can have, and p1(\u03b8) as the corresponding probability for any structure \u03b8 \u2208 \u0398. As the set \u0398 includes all possible structures that the BFS tree of ui can have, we also define p2(\u03b8) similarly for the BFS tree. Then, based on (34), for any \u03b8 \u2208 \u0398 with user size s(\u03b8) < c log n, we have\n(1\u2212 1\u221a n )s(\u03b8) \u2264 p2(\u03b8) p1(\u03b8) \u2264 (1 + 1\u221a n )s(\u03b8), (35)\nwhich is because both the probabilities p1(\u03b8) and p2(\u03b8) are given by the product of all s(\u03b8) users\u2019 individual probability to give birth to a given number of children as in structure \u03b8.\nWe now note that the difference between ET\u223cT (d)[xroot(T )] and EG\u223cG(n,d/n)[xi(G)|C(ui) = 0] is determined by the difference between p1(\u03b8) and p2(\u03b8)\nET\u223cT (d)[xroot(T )] = \u2211 \u03b8\u2208\u0398 p1(\u03b8)xroot(\u03b8), (36)\nEG\u223cG(n,d/n)[xi(G)|C(ui) = 0] = \u2211 \u03b8\u2208\u0398 p2(\u03b8)xroot(\u03b8). (37)\n(37) uses xroot(\u03b8) instead of xi(\u03b8) because the matching weight xi(\u03b8) of node ui should be equal to the matching weight xroot(\u03b8) of the root node when the BFS tree of ui has the same structure \u03b8 as the rooted tree.\n22\nBy substituting (35) into (36) and (37), we have\nlim n\u2192\u221e\n|ET\u223cT (d)[xroot(T )]\u2212 EG\u223cG(n,d/n)[xi(G)|C(ui) = 0]|\n= lim n\u2192\u221e | \u2211 \u03b8\u2208\u0398 xroot(\u03b8)(p1(\u03b8)\u2212 p2(\u03b8))|\n\u2264 lim n\u2192\u221e vK 2 \u2211 {\u03b8\u2208\u0398:s(\u03b8)\u2265c logn} p1(\u03b8) + p2(\u03b8)\n+ vK 2 \u2211 {\u03b8\u2208\u0398:s(\u03b8)<c logn} p1(\u03b8)((1 + 1\u221a n )s(\u03b8) \u2212 1)\n(a) = lim n\u2192\u221e vK 2 1\u221a n \u2211 {\u03b8\u2208\u0398:s(\u03b8)<c logn} p1(\u03b8)s(\u03b8)\n(b) \u2264 lim\nn\u2192\u221e vK 2 1\u221a n 1 1\u2212 d = 0, (38)\nwhere we split the analysis in two cases depending on whether the graph structure \u03b8 has size larger than c log n or not. As we mentioned earlier, [31] proves that G(n, d/n) almost surely has no connected components of size larger than c log n for the constant c, thus we have the probability \u2211 {\u03b8\u2208\u0398:s(\u03b8)\u2265c logn} p2(\u03b8) = 0 to derive equality (a). Inequality (b) is due to that the average size of the random tree T (d) is given by \u2211 \u03b8\u2208\u0398 p1(\u03b8)s(\u03b8) = \u2211\u221e t=0 d\nt = 11\u2212d where dt is the average size of the t-th generation as each node gives birth to d children on average. Moreover, according to the first moment method, we also have\u2211 {\u03b8\u2208\u0398:s(\u03b8)\u2265c logn} p1(\u03b8) = 0 for (a). Based on (33) and (38), we finally prove (9)."
        },
        {
            "heading": "APPENDIX L PROOF OF PROPOSITION 12",
            "text": "To compute the proposal probability yk, we further define yck to denote the probability that the root node receives a proposal from a child who connects to it with an edge of weight vk given this child gives birth to c grandchild nodes (happens with probability (n\u22121 c ) (d/n)c(1\u2212 d/n)n\u22121\u2212c \u2192 d c c! e \u2212d as n\u2192\u221e). If the edge between the root node and the child has the maximum weight (i.e., k = K), the child will send a proposal to the root node only when all i grandchildren that have the maximum weight among the c grandchild nodes (happens with probability (c i ) (pK)\ni(1\u2212pK)c\u2212i) either want great-grandchildren (happens with probability 1\u2212yK ) or have lower priority to be added. Thus, the recursive equation for the proposal probability ycK is given as follows:\nycK= c\u2211 i=0\n( c\ni\n) (pK) i(1\u2212pK)c\u2212i( i\u2211\nj=0\n( i\nj\n) yi\u2212jK (1\u2212yK) j 1\ni\u2212j+1 ).\nMoreover, by considering all possible number of grandchildren that the child can give birth to, we can derive the aggregate recursive equation for the matching possibility yK :\nyK = \u221e\u2211 c=0 dc c! e\u2212dycK\n= \u221e\u2211 c=0 dc c! e\u2212d c\u2211 i=0\n( c\ni\n) (pK) i(1\u2212pK)c\u2212i( i\u2211\nj=0\n(i j ) yi\u2212jK (1\u2212yK)j\ni\u2212 j + 1 )\n= e\u2212pKd \u221e\u2211 i=0 (pKd) i(1\u2212 (1\u2212 yK)i+1) (i+ 1)!yK , (39)\nafter a summation by parts. Note that the term 1yK (1\u2212 (1\u2212 yK)\ni+1) on the right-hand-side of the equation is decreasing in yK when yK \u2208 (0, 1). Moreover, when yK = 0, the RHS of the equation is equal to 1. When yK = 1, the RHS of the equation is equal to 1pKd (1\u2212 e\n\u2212pKd) < 1 for any d > 0 and 0 < pK < 1. Therefore, there exists a unique solution y?K satisfying the above equation in the interval (0, 1).\nThen, after the proposal probability yK of the maximum weight has been decided, the proposal probability yK\u22121 now have the highest priority to compute as wK\u22121 becomes the maximum weight among the remaining weights. Similarly, for the proposal probability yK\u22121, we can derive the following recursive equation\nyk = e \u2212(pK+yKpK)d \u221e\u2211 i=0 (pkd) i(1\u2212 (1\u2212 yk)i+1) (i+ 1)!yk . (40)\nUsing the similar argument for yK , we prove that there exists a unique solution y?K\u22121 satisfying the above equation in the interval (0, 1) after substituting the solution y?K to (39) into (40).\nEventually, for any k = 1, 2, . . .K, we can derive the following recursive equation\nyk = e \u2212(pK+\n\u2211K j=k+1 yjpj)d \u221e\u2211 i=0 (pkd) i(1\u2212 (1\u2212 yk)i+1) (i+ 1)!yk .\nand prove that there exists a unique solution to the equation."
        },
        {
            "heading": "APPENDIX M PROOF OF PROPOSITION 13",
            "text": "As shown in Fig 10, the decomposed sub-graph (1a) has size 1\u00d7 n and its average total weight an under the greedy matching is given by an = 4+3\u22069 + o(n) based on (4).\nAs for the decomposed sub-graph (1b), only the users with quantity 2 are left and they form a lot of linear segments. We first compute the average number of segments with length t by using probability analysis, which is given by n2t+2 . Note that, for a linear segment with size 1 \u00d7 t, its greedy matching is denoted by at. Then, the average weight caused by matched remaining edges in second row is equal to \u2211\u221e t=1 n 2t+2 at.\nTo compute that, we need the value of at for any t. We have a1 = 0, a2 = 2+\u22062 , a3 = 4+3\u2206 4 and at = 4+3\u2206 4 + 3 4at\u22122 + 1 4at\u22123 according to (4). Thus, we can compute the value of at for a finite number of t, for example, from t = 1 to t = 100 and further derive a lower bound for \u2211\u221e t=2 n 2t+2 at, which is given by \u2211100 t=2 n 2t+2 at \u2248\n(0.16 + 0.1\u2206)n. Note that the value of \u2211\u221e t=101 n 2t+2 at is almost zero since n2t+2 decreases exponentially while at increases linearly in t.\nIn sum, we can prove that the average total weight under the greedy matching in the linear network of n users is lower bounded by\nlim n\u2192\u221e\nEW [f\u0302(G,W )] \u2265 ( 4 + 3\u2206\n9 + 0.16 + 0.1\u2206)n\n\u2265 (0.604 + 0.433\u2206)n+ o(n)\nwhere EW [f\u0302(G,W )] denotes the average total weight under the greedy matching in the linear networks with two possible quantity values 1 and 2.\n23\nBy combining this with the derived upper bound for the optimal matching using (14), we finally obtain\nlim n\u2192\u221e PR(G) \u2265 0.604 + 0.433\u2206 0.75 + 0.5\u2206 .\nThe proof is completed."
        },
        {
            "heading": "APPENDIX N PROOF OF AVERAGE PERFORMANCE RATIO FOR NON-IID ROUNDS",
            "text": "In a more detailed model, the same user may stay for multiple rounds to fulfill its demand expressed in the first round. This will create dependence between adjacent rounds. To obtain the optimal matching when users stay for multiple rounds, we need to run the matching algorithm that takes into account the entire time horizon assuming full knowledge of the future. More specifically, using full knowledge of arrivals and departures over time, we can construct an enlarged graph where any two nearby users are connected if there is an overlap between their activity intervals. Since users can be matched only once during any activity interval, we can compute the optimal matching using this larger graph.\nHere, we further extend our methodology to compare the single-round greedy matching returned by running Algorithm 1 independently in each round with the multiround optimal matching using future information in the linear matching network model where users stay for 2 rounds. In this extended linear network model, we assume that there are a population of n users and in the first round each user becomes active in the system with probability 0.5. Once a user becomes active, it will wait for two rounds to be matched and becomes inactive after. Once inactive, the user joins the system again with the same probability 0.5 in the following rounds. For illustrative purposes, we also assume the weight set V = {v1 = 1, v2 = 1 + \u2206} and uniform weight distribution p1 = p2 = 12 for the sharing benefit between any pair of users.\nThen, to analyze the average performance ratio of the single-round greedy matching as compared to the multiround optimal matching, we first derive the upper bound of the optimum. Note that, in such a dynamic linear network, each of n users is active for 2/3 of rounds on average over the entire time horizon. For any user being active, her left/right neighbor is inactive (i.e., unavailable for matching) with probability 1\u2212 2/3 = 1/3 in her first participating round and keeps being inactive with probability 1/2 in the second round. Thus, during the two rounds, the user has two available neighbors with probability 25/36, one available neighbor with probability 10/36, and no available neighbor with probability 1/36. Then, by using similar arguments as in Section 5.1, we can prove that the individual matching weight of this user is upper bounded by\n4 + 3\u2206 8 \u00d7 25 36 + 2 + \u2206 4 \u00d7 10 36 + 0\u00d7 1 36 = 140 + 95\u2206 288 .\nHence, the average total weight under the optimal matching in each round is upper bounded by 140+95\u2206864 n.\nNext, we estimate a lower bound of the average total weight under the greedy matching. Note that in each round\nof the extended linear network, there are 1/3 of users who turn to active from inactive, 1/3 of users who keep being inactive, and 1/3 of users who keep being active since the last round on average. We run the greedy matching algorithm for new participating users independently in each round and these users form a lot of linear segments. Similar to the proof of Proposition 13 in Appendix M, we first compute the average number of segments with length t by using probability analysis, which is given by\n4n 3t+2 . Note that, for a linear segment with size 1 \u00d7 t, its greedy matching is denoted by at and we have a1 = 0, a2 = 2+\u2206 2 , a3 = 4+3\u2206 4 and at = 4+3\u2206 4 + 3 4at\u22122 + 1 4at\u22123 according to (4). Then, the average total matching weight for all the segments is \u2211\u221e t=1 4n 3t+2 at, which is lower bounded\nby \u2211100 t=1 4n 3t+2 at \u2248 0.0816 + 0.0476\u2206. Moreover, note that the users in the segments of size 1 \u00d7 1 have no available neighbor in the current round and thus can be left to match with the same kind of users in the next round. Such matching can make an additional matching weight of 10 243 + 11 486\u2206. In sum, we can prove that the total weight under the single-round greedy matching is lower bounded by 0.0816 + 0.0476\u2206 + 10243 + 11 486\u2206 = 0.1228 + 0.0703\u2206.\nFinally, by comparing the derived lower bound for the single-round greedy matching with the upper bound for the multi-round optimal matching, we obtain the lower bound of the average performance ratio PRt(G) for nonIID rounds as follows:\nlim n\u2192\u221e lim t\u2192\u221e\nPRt(G) \u2265 0.1228 + 0.0703\u2206\n140+95\u2206 864\n.\nThis ratio decreases from 75.8% to 63.9% as weight difference \u2206 increases from 0 to +\u221e.\nThe obtained ratio decreases with \u2206 and achieves its maximum value when all edges have similar weights (i.e., \u2206 \u2192 0+). This is different from Proposition 4 for singleround matching in linear networks. We believe this is because the network is sparser in the considered multi-round model where users participate with probability 0.5. Then, both the single-round greedy matching and the multi-round optimal matching try to match as many pairs as possible, resulting in similar numbers of matched edges and thus a trivial performance/weight gap when all edges have similar weights."
        }
    ],
    "title": "Average-Case Analysis of Greedy Matching for Large-Scale D2D Resource Sharing",
    "year": 2023
}