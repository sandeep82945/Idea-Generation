{
    "abstractText": "Virtual screening (VS) is a computational strategy that uses in silico automated protein docking inter alia to rank potential ligands, or by extension rank protein\u2013ligand pairs, identifying potential drug candidates. Most docking methods use preferred sets of physicochemical descriptors (PCDs) to model the interactions between host and guest molecules. Thus, conventional VS is often data-specific, method-dependent and with demonstrably differing utility in identifying candidate drugs. This study proposes four universality classes of novel consensus scoring (CS) algorithms that combine docking scores, derived from ten docking programs (ADFR, DOCK, Gemdock, Ledock, PLANTS, PSOVina, QuickVina2, Smina, Autodock Vina and VinaXB), using decoys from the DUD-E repository (http:// dude. docki ng. org/) against 29 MRSA-oriented targets to create a general VS formulation that can identify active ligands for any suitable protein target. Our results demonstrate that CS provides improved ligand\u2013protein docking fidelity when compared to individual docking platforms. This approach requires only a small number of docking combinations and can serve as a viable and parsimonious alternative to more computationally expensive docking approaches. Predictions from our CS algorithm are compared against independent machine learning evaluations using the same docking data, complementing the CS outcomes. Our method is a reliable approach for identifying protein targets and high-affinity ligands that can be tested as high-probability candidates for drug repositioning. * Amit K. Chattopadhyay a.k.chattopadhyay@aston.ac.uk 1 Department of Mathematics, College of Engineering and Physical Sciences, Aston University, Birmingham B4 7ET, UK 2 Life and Health Sciences, Aston University, Birmingham B4 7ET, UK 3 Acculi Labs Pvt. Ltd., Bangalore, Karnataka 560098, India 132 Interdisciplinary Sciences: Computational Life Sciences (2023) 15:131\u2013145 1 3 Graphical Abstract",
    "authors": [
        {
            "affiliations": [],
            "name": "Amit K. Chattopadhyay"
        }
    ],
    "id": "SP:786ab81c9db3d739a2fc60c2519852086bcd9c38",
    "references": [
        {
            "authors": [
                "JA DiMasi",
                "HG Grabowski",
                "RW Hansen"
            ],
            "title": "Innovation in the pharmaceutical industry: new estimates of R&D costs",
            "venue": "J Health Econ 47:20\u201333. https:// doi. org/ 10. 1016/j. jheal eco. 2016",
            "year": 2016
        },
        {
            "authors": [
                "TT Ashburn",
                "KB Thor"
            ],
            "title": "Drug repositioning: identifying and developing new uses for existing drugs",
            "venue": "Nat Rev Drug Discov 3(8):673\u2013683. https:// doi. org/",
            "year": 2004
        },
        {
            "authors": [
                "R Zrieq",
                "M Snoussi",
                "FD Algahtan"
            ],
            "title": "Repurposing of anisomycin and oleandomycin as a potential anti-(SARSCoV-2) virus targeting key enzymes using virtual computational approaches. Cell Mol Biol Noisylegrand (Noisy-le-grand) 67(5):387\u2013398",
            "venue": "https:// doi",
            "year": 2022
        },
        {
            "authors": [
                "TN Jarada",
                "JG Rokne",
                "R Alhajj"
            ],
            "title": "A review of computational drug repositioning: strategies, approaches, opportunities, challenges, and directions",
            "venue": "J atics 12(1):46. https:// doi",
            "year": 2020
        },
        {
            "authors": [
                "AS Reddy",
                "SP Pati",
                "PP Kumar",
                "HN Pradeep",
                "GN Sastry"
            ],
            "title": "Virtual screening in drug discovery\u2014a computational perspective",
            "venue": "Curr Protein Pept Sci 8(4):329\u2013351. https:// doi",
            "year": 2007
        },
        {
            "authors": [
                "A Lavecchia",
                "C Di Giovanni"
            ],
            "title": "Virtual screening strategies in drug discovery: a critical review",
            "venue": "Curr Med Chem",
            "year": 2013
        },
        {
            "authors": [
                "M Saeed",
                "M Imran",
                "MH Baig",
                "MA Kausar",
                "S Shahid",
                "I Ahmad"
            ],
            "title": "Virtual screening of natural anti-filarial compounds 144 Interdisciplinary Sciences: Computational Life Sciences (2023) 15:131\u2013145 1 3 against glutathione-S-transferase of Brugia malayi and Wuchereria bancrofti. Cell Mol Biol (Noisy-le-grand) 64(13):69\u201373",
            "venue": "https:// doi",
            "year": 2018
        },
        {
            "authors": [
                "DB Kitchen",
                "H Decornez",
                "JR Furr",
                "J Bajorath"
            ],
            "title": "Docking and scoring in virtual screening for drug discovery: methods and applications",
            "venue": "Nat Rev Drug Discov 3(11):935\u2013949. https:// doi. org/",
            "year": 2004
        },
        {
            "authors": [
                "S Ojha",
                "S Deep",
                "S Kundu"
            ],
            "title": "Plant derived antimicrobial peptide Ib-AMP1 as a potential alternative drug candidate for Staphylococcus aureus toxins",
            "venue": "Cell Mol Biol (Noisy-le-grand) 63(6):52\u201355. https:// doi",
            "year": 2017
        },
        {
            "authors": [
                "YC Chen"
            ],
            "title": "Beware of docking! Trends Pharmacol Sci 36(2):78\u201395",
            "venue": "https:// doi. org/ 10. 1016/j. tips",
            "year": 2015
        },
        {
            "authors": [
                "M Feher"
            ],
            "title": "Consensus scoring for protein\u2013ligand interactions. Drug Discovery Today 11(9):421\u2013428",
            "venue": "https:// doi. org/ 10. 1016/j. drudis",
            "year": 2006
        },
        {
            "authors": [
                "RD Clark",
                "A Strizhev",
                "JM Leonard",
                "JF Blake",
                "JB Matthew"
            ],
            "title": "Consensus scoring for ligand/protein interactions",
            "venue": "J Mol Graph Model 20(4):281\u2013295. https:// doi",
            "year": 2002
        },
        {
            "authors": [
                "R Wang",
                "S Wang"
            ],
            "title": "How does consensus scoring work for virtual library screening? An idealized computer experiment",
            "venue": "J Chem Inf Comput Sci 41(5):1422\u20131426. https:// doi",
            "year": 2001
        },
        {
            "authors": [
                "PS Charifson",
                "JJ Corkery",
                "MA Murcko",
                "WP Walters"
            ],
            "title": "Consensus scoring: a method for obtaining improved hit rates from docking databases of three-dimensional structures into proteins",
            "venue": "J Med Chem 42(25):5100\u20135109. https:// doi",
            "year": 1999
        },
        {
            "authors": [
                "A Oda",
                "K Tsuchida",
                "T Takakura",
                "N Yamaotsu",
                "S Hirono"
            ],
            "title": "Comparison of consensus scoring strategies for evaluating computational models of protein\u2212ligand complexes",
            "venue": "J Chem Inf Model 46(1):380\u2013391. https:// doi",
            "year": 2006
        },
        {
            "authors": [
                "S Schultes",
                "AJ Kooistra",
                "HF Vischer"
            ],
            "title": "Combinatorial consensus scoring for ligand-based virtual fragment screening: a comparative case study for serotonin 5-HT3A, histamine H1, and histamine H4 receptors",
            "venue": "J Chem Inf Model",
            "year": 2015
        },
        {
            "authors": [
                "H Park",
                "JW Eom",
                "YH Kim"
            ],
            "title": "Consensus scoring approach to identify the inhibitors of AMP-activated protein kinase \u03b12 with virtual screening",
            "venue": "J Chem Inf Model 54(7):2139\u20132146. https:// doi",
            "year": 2014
        },
        {
            "authors": [
                "AT Onawole",
                "TU Kolapo",
                "KO Sulaiman",
                "RO Adegoke"
            ],
            "title": "Structure based virtual screening of the Ebola virus trimeric glycoprotein using consensus scoring",
            "venue": "Comput Biol Chem",
            "year": 2018
        },
        {
            "authors": [
                "LR Bowen",
                "DJ Li",
                "DT Nola"
            ],
            "title": "Identification of potential Zika virus NS2B-NS3 protease inhibitors via docking, molecular dynamics and consensus scoring-based virtual screening",
            "venue": "J Mol Model 25(7):194. https:// doi",
            "year": 2019
        },
        {
            "authors": [
                "V Scardino",
                "M Bollini",
                "CN Cavasotto"
            ],
            "title": "Combination of pose and rank consensus in docking-based virtual screening: the best of both worlds. RSC Adv 11:35383",
            "venue": "https:// doi",
            "year": 2021
        },
        {
            "authors": [
                "SS Ericksen",
                "H Wu",
                "H Zhang"
            ],
            "title": "Machine learning consensus scoring improves performance across targets in structurebased virtual screening",
            "venue": "J Chem Inf Model 57(7):1579\u20131590. https:// doi. org/",
            "year": 2017
        },
        {
            "authors": [
                "R Teramoto",
                "H Fukunishi"
            ],
            "title": "Supervised consensus scoring for docking and virtual screening",
            "venue": "J Chem Inf Model",
            "year": 2007
        },
        {
            "authors": [
                "JC Pereira",
                "ER Caffarena",
                "CN dos Santos"
            ],
            "title": "Boosting docking-based virtual screening with deep learning",
            "venue": "J Chem Inf Model 56(12):2495\u20132506. https:// doi. org/",
            "year": 2016
        },
        {
            "authors": [
                "GPA Vigers",
                "JP Rizzi"
            ],
            "title": "Multiple active site corrections for docking and virtual screening",
            "venue": "J Med Chem 47(1):80\u201389. https:// doi",
            "year": 2004
        },
        {
            "authors": [
                "WJ Allen",
                "TE Balius",
                "S Mukherjee"
            ],
            "title": "DOCK 6: impact of new features and current docking performance",
            "venue": "J Comput Chem 36(15):1132\u20131156. https:// doi. org/",
            "year": 2015
        },
        {
            "authors": [
                "O Trott",
                "AJ Olson"
            ],
            "title": "AutoDock vina: improving the speed and accuracy of docking with a new scoring function, efficient optimization and multithreading",
            "venue": "J Comput Chem 31(2):455\u2013461. https:// doi",
            "year": 2010
        },
        {
            "authors": [
                "JM Yang",
                "CC Chen"
            ],
            "title": "GEMDOCK: a generic evolutionary method for molecular docking",
            "venue": "Proteins Struct Funct Bioinform 55(2):288\u2013304. https:// doi. org/",
            "year": 2004
        },
        {
            "authors": [
                "PA Ravindranath",
                "S Forli",
                "DS Goodsell",
                "AJ Olson",
                "MF Sanner"
            ],
            "title": "AutoDockFR: advances in protein\u2013ligand docking with explicitly specified binding site flexibility",
            "venue": "PLoS Comput Biol. https:// doi. org/",
            "year": 2015
        },
        {
            "authors": [
                "N Zhang",
                "H Zhao"
            ],
            "title": "Enriching screening libraries with bioactive fragment space",
            "venue": "Bioorg Med Chem Lett 26(15):3594\u20133597. https:// doi. org/ 10. 1016/j. bmcl. 2016",
            "year": 2016
        },
        {
            "authors": [
                "O Korb",
                "TSG Olsson",
                "SJ Bowden"
            ],
            "title": "Potential and limitations of ensemble docking",
            "venue": "J Chem Inf Model 52(5):1262\u20131274. https:// doi. org/ 10. 1021/",
            "year": 2012
        },
        {
            "authors": [
                "MCK Ng",
                "S Fong",
                "Siu"
            ],
            "title": "PSOVina: the hybrid particle swarm optimization algorithm for protein\u2013ligand docking",
            "venue": "SWI",
            "year": 2015
        },
        {
            "authors": [
                "A Alhossary",
                "SD Handoko",
                "Y Mu",
                "CK Kwoh"
            ],
            "title": "Fast, accurate, and reliable molecular docking with QuickVina 2. Bioinformatics 31(13):2214\u20132216",
            "venue": "https:// doi. org/",
            "year": 2015
        },
        {
            "authors": [
                "DR Koes",
                "MP Baumgartner",
                "CJ Camacho"
            ],
            "title": "Lessons learned in empirical scoring with smina from the CSAR 2011 benchmarking exercise",
            "venue": "J Chem Inf Model 53(8):1893\u20131904. https:// doi",
            "year": 2013
        },
        {
            "authors": [
                "MR Koebel",
                "G Schmadeke",
                "RG Posner",
                "S Sirimulla"
            ],
            "title": "2016) AutoDock VinaXB: implementation of XBSF, new empirical halogen bond scoring function, into AutoDock Vina",
            "venue": "J Cheminform",
            "year": 2016
        },
        {
            "authors": [
                "LM Weiner-Lastinger",
                "S Abner",
                "JR Edwards"
            ],
            "title": "Antimicrobial-resistant pathogens associated with adult healthcareassociated infections: Summary of data reported to the National Healthcare Safety Network, 2015\u20132017",
            "venue": "Infect Control Hosp Epidemiol 41(1):1\u201318. https:// doi",
            "year": 2020
        },
        {
            "authors": [
                "AP Graves",
                "R Brenk",
                "Shoichet"
            ],
            "title": "BK (2005) Decoys for docking",
            "venue": "J Med Chem 48(11):3714\u20133728. https:// doi. org/ 10. 1021/",
            "year": 2005
        },
        {
            "authors": [
                "R Zhang",
                "HY Ou",
                "CT Zhang"
            ],
            "title": "DEG: a database of essential genes",
            "venue": "Nucl Acids Res. 32(Database issue):D271\u2013D272. https:// doi. org/",
            "year": 2004
        },
        {
            "authors": [
                "SF Altschul",
                "W Gish",
                "W Miller",
                "EW Myers",
                "DJ Lipman"
            ],
            "title": "Basic local alignment search tool",
            "venue": "J Mol Biol 215(3):403\u2013410. https:// doi",
            "year": 1990
        },
        {
            "authors": [
                "HM Berman",
                "J Westbrook",
                "Z Feng"
            ],
            "title": "The protein data bank",
            "venue": "Nucl Acids Res",
            "year": 2000
        },
        {
            "authors": [
                "MM Mysinger",
                "M Carchia",
                "J Irwin John",
                "decoys Shoichet BK (2012) Directory of useful",
                "(DUD-E enhanced"
            ],
            "title": "better ligands and decoys for better benchmarking",
            "venue": "J Med Chem 55(14):6582\u20136594. https:// doi. org/ 10. 1021/ jm300 687e 145 Interdisciplinary Sciences: Computational Life Sciences",
            "year": 2023
        },
        {
            "authors": [
                "L Holm",
                "P Rosenstr\u00f6m"
            ],
            "title": "Dali server: conservation mapping in 3D",
            "venue": "Nucl Acids Res. 38(Web server issue):W545\u2013W549. https:// doi. org/",
            "year": 2010
        },
        {
            "authors": [
                "CA Lipinski",
                "F Lombardo",
                "BW Dominy",
                "PJ Feeney"
            ],
            "title": "Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings",
            "venue": "Adv Drug Deliv Rev 46(1\u20133):3\u201326. https:// doi",
            "year": 1997
        },
        {
            "authors": [
                "CH Ngan",
                "DR Hall",
                "B Zerbe",
                "LE Grove",
                "D Kozakov",
                "S Vajda"
            ],
            "title": "FTSite: high accuracy detection of ligand binding sites on unbound protein structures. Bioinformatics 28(2):286\u2013287",
            "venue": "https:// doi. org/",
            "year": 2012
        },
        {
            "authors": [
                "PA Ravindranath",
                "MF Sanner"
            ],
            "title": "AutoSite: an automated approach for pseudo-ligands prediction\u2014from ligand-binding sites identification to predicting key ligand atoms. Bioinformatics 32(20):3142\u20133149",
            "venue": "https:// doi. org/",
            "year": 2016
        },
        {
            "authors": [
                "K Palacio-Rodr\u00edguez",
                "I Lans",
                "CN Cavasotto",
                "P Cossio"
            ],
            "title": "Exponential consensus ranking improves the outcome in docking and receptor ensemble docking",
            "venue": "Sci Rep. https:// doi",
            "year": 2019
        },
        {
            "authors": [
                "P Willett"
            ],
            "title": "Combination of similarity rankings using data fusion",
            "venue": "J Chem Inf Model 53(1):1\u201310. https:// doi",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "Vol.:(0123456789)\n* Amit K. Chattopadhyay a.k.chattopadhyay@aston.ac.uk\n1 Department of\u00a0Mathematics, College of\u00a0Engineering and\u00a0Physical Sciences, Aston University, Birmingham\u00a0B4\u00a07ET, UK\n2 Life and\u00a0Health Sciences, Aston University, Birmingham\u00a0B4\u00a07ET, UK\n3 Acculi Labs Pvt. Ltd., Bangalore, Karnataka\u00a0560098, India\n1 3\nGraphical Abstract\nKeywords Molecular docking\u00a0\u00b7 Machine learning\u00a0\u00b7 Consensus scoring\u00a0\u00b7 Virtual screening"
        },
        {
            "heading": "1 Introduction",
            "text": "Apart from being time- and resource intensive, the success rate of traditional drug discovery is low [1, 2]. Drug Repurposing (DR), the evaluation of approved or safety-evaluated drugs as treatments for new or different diseases, has mostly relied on haphazard, trial-and-error drug discovery to match prospective drug candidates to cognate target proteins [2, 3]. Next-generation DR methods involve computationally intensive automated screening of extant compounds against protein or nucleic-acid targets [4]. This method has come to be known as Virtual Screening (VS). Virtual Screening (VS) protocols can computationally map compound libraries against biological targets to detect compounds with potential biological activities while eliminating unsuitable compounds [5\u20137]. Such in silico virtual screening can assess large numbers of compounds rapidly, including molecules yet to be synthesized.\nDocking is a widely used computational method to predict the likelihood of meaningful complementarity between small molecule compounds and protein targets [8, 9]. Despite major advances in algorithms and hardware, the quality of discrimination available within current docking programs remains sub-optimal [10]. When we combine thousands of proteins with tens of thousands of\nligands, the task becomes computationally challenging. To surmount this obstacle, efforts have been made to combine docking programs to derive consensus scores.\nA major advance in VS began with the implementation of screening combining inputs from multiple VS platforms, a methodology popularly known as \u201cconsensus scoring\u201d (CS) [11, 12]. Trial-and-error implementations of consensus CS generates superior ligand\u2013protein matching when compared to individual VS [11\u201313]. Initially conceptualized by Charifson [14], consensus scoring algorithms have been employed in both structure-based and ligand-based virtual screening [15, 16] and are now becoming the norm [17], making contributions to the identification of drug candidates for Ebola [18] and Zika [19]. Recently, Scardino et\u00a0al [20] have employed a new consensus method that uses ranking and pose of the docked ligands to ensure more robust virtual screening. A key advantage of consensus scoring over individual VS is its ability to reduce false positives and negatives in virtual screening [14], thereby optimizing the time and resources required.\nConsensus scoring protocols rely on established statistical (e.g. skewness-kurtosis, regression) measures [11, 12], complemented by machine learning [21\u201323]. The prerequisite for statistical consensus scores is a homologous set of initial scores. For instance, the docking scores can\nbe uniformly generated [13] or rescored with the same docking engine [14]. For heterogeneous docking scores spanning a range of docking programs with varying units and ranges, the individual scores are first normalized using either rank transform [11, 12], minimum\u2013maximum scaling [15] or z-score scaling [24] before the combination, which can contribute to data loss.\nThe present study makes use of a different normalization procedure that ensures convergence without data loss by using a three-tier approach. Tier 1 involves docking data from the enhanced DUD-E repository (http:// dude. docki ng. org/) (1000 ligands docked against 29 MRSA-oriented targets) using ten popular and easily accessible (open access) docking programs: ADFR, DOCK6, Gemdock, Ledock, PLANTS, PSOV-ina, QuickVina2, Smina, Autodock Vina and VinaXB. The choice is governed by reported individual success rates, e.g. DOCK6 at 73.3% [25], Autodock Vina at 80% [26], Gemdock at 79% [27], ADFR at 74% [28], Ledock at 75% [29], PLANTS at 72% [30], PSOVina 63% [31], QuickVina2 63% [32], Smina more than 90% [33] and VinaXB 46% [34]. The docking programs were randomly chosen focusing only on the need to use an open-sourced architecture that could be utilized on a terminal-based (that is, without a Graphical User Interface) Linux/Unix frontend, a requirement of the Midlands Supercomputing Cluster (now named SULIS) that we used for computations. Tier 2 combines data from all 10 scores using statistical (linear and nonlinear) models belonging to four universality classes. Tier 3 normalizes VS data from Tier 2 through a novel calibration of the individual best score (Smina in our case) against the respective probability density functions (PDF). Since PDF data is non-dimensional, normalization is guaranteed and is without meaningful information loss.\nThis study also outlines a self-consistent mechanism of understanding how multiple docking combinations ensure better convergence, answering questions relating to a possible improvement in CS accuracy with additional docking entries. The study convincingly demonstrates that a finite number of docking programs are required for the highest available accuracy. The precise number required may vary depending on the specific choice of docking programs used.\nWe analyze the strength of our novel CS model against Methicilin Resistance Staphylococcus aureus (MRSA). The bacterium is a prime example of antimicrobial resistance, accounting for up to 12% of hospital infections\nbetween 2011 and 2014 in the UK [35]; 323,700 infected patients in 2017 incurring an approximate cost of $1.7 billion [36]. In this work, we focus on MRSA essential genes as de facto targets for potential repurposed drugs acting as anti-MRSA antibiotics, arguing that inhibiting any essential gene should impair the biological activity of the whole bacteria. Benchmark is done using MRSA targets comparing different MRSA protein structures to targets obtained from the Directory of Useful Decoys\u2014 Enhanced (DUD-E)."
        },
        {
            "heading": "2 Methods",
            "text": ""
        },
        {
            "heading": "2.1 Target and\u00a0Ligand Selection",
            "text": "DUD-E decoys and active ligands are docked to MRSA structures that are structurally similar to their DUD-E targets. The idea is to evaluate the veracity of the docking structure used without the decoys necessarily binding to the targets, as in Graves, et\u00a0al. [37] 351 essential genes from the Database of Essential Genes [38] are aligned with PDB structures using BLAST [39], resulting in 113 target structures identified in the Protein Data Bank (PDB) [40]. To benchmark MRSA-oriented targets effectively, instead of re-docking DUD-E ligands against their respective targets, we compare protein structures of MRSA proteins and DUD-D targets. 102 target protein structures from DUD-E [41] are structurally aligned with those of 113 MRSA proteins using the Dali server [42] and visual inspection. 29 pairs of structurally similar MRSA\u2014DUD-E are recorded. For each DUD-E set of decoys and active ligands after filtering with Lipinski Rule of Five [43] for drug-like compounds, 999 decoys and one active ligand are reserved for each target.\nWe docked 1000 DUD-E ligands initially against 1 (DUD-E or MRSA) target. This is what we see in Table\u00a01, the last column. While the initial docking involved DUD-E ligands against DUD-targets, we later substituted DUDtargets with structurally similar MRSA targets, individually and collectively. For example, the MRSA target 4DQ1 is reasonably similar in structure to the DUD-E target TYSY, or (3WQT, 5JIC) are similar to HXK4 and could be substituted.\nDUD-E targets DEF DYR ADA, ALDR GLCM, PYRD DHI1, INHA HXK4 TYSY MRSA target 1LM4 2W9H 3M9Y, 3T05 3OSU, 4D44 3WQT, 5JIC 4DQ1\n1 3"
        },
        {
            "heading": "2.2 Molecular Docking",
            "text": "Ten docking programs were chosen due to their ease of use and prominence as follows: ADFR [28], UCSF DOCK [29], Gemdock [27], Ledock [29], PLANTS [30], PSOVina [31], QuickVina2 [32], Smina [33], Autodock Vina [26] and VinaXB [34]. All protein structures used were downloaded from the Protein Data Bank (PDB) [40]. Prior to docking, protein structures have water and ions removed and are then protonated. Decoys and ligands are prepared similarly. Binding site prediction is carried out using FTSite server [43] for DOCK, Gemdock, Ledock, PLANTS, PSOVina, QuickVina2, Smina, Autodock Vina and VinaXB while ADFR uses its own package Autosite [45]. 999 decoys and 1 active ligand are docked against all 29 MRSA targets. Each docking program generates various ligand conformations and orientations within a binding pocket (pose) and uses its underlying scoring function to estimate the likelihood of binding for each pose. The best scoring pose is retained for each decoy and ligand."
        },
        {
            "heading": "2.3 Normalization",
            "text": "To compare with other consensus scores, common methods of normalization are applied to docking scores before combination. We employed the three commonly-used normalization procedures. (A) Ranking: Ranks represent docking scores for each target assigned against ascending ranks. This implies that ligands with more negative scores rank higher. (B) Minimum\u2013maximum Scale (referred to hereafter as min\u2013max scale). Scores for each target are rescaled to a [0; 1] domain and then subtracted from the minimum score. The result is then divided by the difference between the maximum and the minimum score. (C) z-score. The min\u2013max docking scores are mean averaged or zero-centered and rescaled. A drawback of these normalization methods is that they shift the relative distribution of scores, which may cause a loss of information."
        },
        {
            "heading": "2.4 Consensus Algorithms",
            "text": "Molecular docking is a process that generates different conformations of poses of ligands and predicts the intermolecular interactions using sets of physicochemical properties, including hydrogen bonding and hydrophobicity. Consensus scoring creates an overall score consistent with the ensemble representation of the 3D molecule rather than an individual pose. To avoid information loss while using normalization, our consensus algorithms combine information from all docking programs and then generate the following four independent optimized functional ensemble data representations:\nHere Sc is the combined score. Si is the docking score of ligands for programs i = 1, 2,\u00a0\u2026,\u00a010. xi are coefficients of the docking programs i (ADFR, DOCK, Gemdock, Ledock, PLANTS, PSOVina, QuickVina2, Smina, Autodock Vina and VinaXB); these are the weights for docking outcomes. S is the mean of the set from program i. n represents the combinatorial order, real values only (n = 1 implies linear combination). Equations (1a\u20131d) were iterated over a total of 20 [9] ensembles involving 10 docking programs, each weighing between 0 and 1, incremented in steps of 0.05 each. Si represents the arithmetic means of the docking scores of all ligands for the same target for each docking program used. The rank of active ligands before and after combination was compared to evaluate the improvement produced by our consensus algorithm."
        },
        {
            "heading": "2.5 Consensus Outcomes",
            "text": "The mean or median rank of active ligands can be used to compare the performance of consensus scores and individual docking programs. Here, we use the median rank of active ligands across all targets, which provides a better threshold than mean ranks. We dock active ligands and rank them with the medians as thresholds across all 29 targets. The median rank of active ligands is expressed as the recovery rate of virtual screening performance: when 50% of active ligands are retrieved at a certain proportion of the ligand library. The fraction of the library screened is defined as the arithmetic mean of the median rank over 1000 ligands.\nWe compared the result against other consensus scores: Mean (MEAN), Median (MED), Minimum (MIN), Maximum (MAX), Euclidean Distance (EUC), Cubic Mean (CBM), Exponential Consensus Rank (ECR) [46] and Deprecated Sum Rank (DSR) [47] across ten sets of normalized docking scores (Si) as follows:\n(1a)Sc = 10 \u2211\ni=1\n20 \u2211\nj=0\nxi,jS n i,j\n(1b)Sc = 10 \u2211\ni=1\n20 \u2211\nj=0\nxi,jabs [ Sn i,j ]\n(1c)Sc = 10 \u2211\ni=1\n20 \u2211\nj=0\nxi,j\n(\nSn i,j \u2212 Si\n)n\n(1d)Sc = 10 \u2211\ni=1\n20 \u2211\nj=0\nxi,jabs [( Sn i,j \u2212 Si )n]\n(2a)MEAN = mean { S1, S2, S3,\u2026 , S10 }\n1 3\nModels defined through Eq. (2g) and (2h) assume the rank of the scores, not the scores themselves. Model from Eq.\u00a0(2h) is without the maximum of the list."
        },
        {
            "heading": "3 Results and\u00a0Discussion",
            "text": "29 targets were obtained from the DUD-E repository. For each target, 999 decoys and 1 active ligand were randomly chosen. These 1000 ligands were then docked against each target using ten docking programs (ADFR, DOCK, Gemdock, Ledock, PLANTS, PSOVina, QuickVina2, Autodock Vina and VinaXB), producing 10 matrices of 1000 \u00d7 29 (active ligands are intentionally located at the 1000th row). For consensus scores, the docking results of each ligandtarget pair were combined using Eqs. (1a\u20131d). While anal***yzing a new set of combined scores, for each target, all combined scores were picked in descending order, starting with the best binding energy. The medians of these repositioned values were then used to calculate the histogram leading to the probability distribution function."
        },
        {
            "heading": "3.1 Statistical Ranking of\u00a0Docking Scores (DUD\u2011E Database)",
            "text": "In this study, we used the median ranking order for evaluation. First, active ligands for 29 targets were randomly chosen and then ranked across a 1000 ligand (docked) arrays. A random selection leads to a median rank of 500. The median ranks obtained from 10 docking programs verified that the\n(2b)MED = median { S1, S2, S3,\u2026 , S10 }\n(2c)MIN = minimum { S1, S2, S3,\u2026 , S10 }\n(2d)MAX = maximum { S1, S2, S3,\u2026 , S10 }\n(2e)EUC =\n[\n10 \u2211\ni=1\nS2 i\n]1\u22152\n(2f)CBM =\n[\n10 \u2211\ni=1\nS3 i\n]1\u22153\n(2g)ECR = 10 \u2211\ni=1\nexp ( Si )\n(2h)DSR = \u221110 i=1 Si\nmaximum \ufffd Si \ufffd\nmedian ranks of active ligands (250 from ADFR) were better than those obtained from a random selection, as detailed in Table\u00a02.\nCompared against the statistical scores defined in Eqs.\u00a0(2a\u20132h), our rank-based normalization consistently returned low scores, complementing the predictions from the consensus algorithm. Table\u00a03 tabulates the consensus scores against varying normalization.\nAfter docking and calculating the ranks of active ligands across 29 targets, Smina returned the lowest median rank of 150, followed by PLANTS with median ranks of 163 and 185 in QuickVina2. Autodock Vina and Gemdock show comparative median ranks of 191 and 192. Surprisingly, the highly popular DOCK generated the worst score (median rank of 423). In general, Autodock Vina show promising results. Based on this evaluation, Smina was the single best-performing docking program for the DUD-E ligands. Converted to recovery rate, the percentage median scores of the docked results are 33.7%, 42.3%, 19.2%, 38.7%, 16.3%, 37.5%, 18.5%, 15%, 19.2% and 22.4% for ADFR, DOCK, Gemdock, Ledock, PLANTS, PSOVina, QuickVina2, Smina, Autodock Vina and VinaXB, respectively. See Fig.\u00a01. The boxplot for Smina shows the ratio of the box height from the median to 0 (median marked by the black line) divided by 1000 is 15%. Thus, if we take 15% of the bestranked ligands for Smina, we have half of the active ligands. Substituting the median baseline with mean and mode did not change the outcome. The first plot of Fig.\u00a02 shows the individual performance of docking programs while the three other plots illustrate the conventional consensus scores from ten docking programs after normalized with various normalization methods.\nAs demonstrated in Fig.\u00a01, these conventional consensus scores show no noticeable improvement compared to individual docking programs, given the choice of normalization methods."
        },
        {
            "heading": "3.2 Novel Consensus Scores",
            "text": "For each docking program, the median ranks of active ligands across 29 targets have been used and plotted using histograms. To establish the improved performance of consensus scores (CS) over individual docking, we compared scores from the individual best performer Smina against the CS score. This was estimated from the leftward areas (since binding energy is negative) of our best-performing individual docking platform (Smina, identified by the solid line close to the maxima of the histograms). Greater the area, the better the CS score (compared to Smina).\nAs clearly demonstrated in Fig.\u00a03, the linear consensus model was consistently the best performer, with the CS docking score progressively declining with increasing values of n. We found that three out of the four linear combinations\n1 3\n(n = 1) demonstrated higher ranks compared to the individual best performer Smina [82, 83 and 82 for model (1a\u20131c), respectively]. Another trend was the dominance of the odd n values against their even counterpart. This was to be expected, as the docking scores were energies, hence negative. This could be compensated for by the absolute (consensus) values [as in models in Eq.\u00a0(1b) and Eq.\u00a0(1d)]. Model\u00a0(1d) was the worst scorer, while linear combinations\nof models (1a\u20131c) showed similar behavior with approximate best ranks and comparable histograms (non-normalized probability density functions).\nAs evident from Figs.\u00a02 and 3, linear regression (Figs.\u00a02) over the set of 10 docking scores involving our ligand\u2013protein sets returned better docking score than nonlinear regression (Figs.\u00a03). Results for higher-ordered consensus regression are provided in the Appendix.\nTable 2 Performance of docking programs across 29 targets\nEach number represents the rank of 29 separate active ligands ranked against a set of 1000 ligands after docking to their targets. Best functioning docking programs that are capable of clearly distinguishing active ligands and decoys are identified by ranks close to 1. The median value represents the average performance of each docking program across all 29 targets\nADFR DOCK Gemdock Ledock PLANTS PSOVina QuickVina2 Smina Autodock Vina VinaXB\nTarget 1 761 344 712 235 446 900 838 641 637 613 Target 2 32 77 166 38 203 67 171 150 77 125 Target 3 337 826 330 514 83 685 83 62 191 224 Target 4 22 95 77 78 2 530 159 38 77 193 Target 5 769 46 137 385 178 375 332 190 242 388 Target 6 2 103 192 392 17 119 11 1 1 1 Target 7 110 445 32 98 667 388 635 497 475 521 Target 8 776 635 941 637 416 940 907 980 930 797 Target 9 334 571 331 490 94 376 250 194 231 260 Target 10 210 93 123 83 28 709 44 48 53 59 Target 11 339 64 523 387 146 376 367 299 390 374 Target 12 255 82 89 694 14 112 15 125 6 7 Target 13 861 831 316 806 646 418 696 423 438 211 Target 14 302 123 174 71 593 607 569 568 498 563 Target 15 881 523 758 843 362 837 823 922 931 877 Target 16 57 112 57 59 196 230 106 103 90 140 Target 17 275 477 666 276 169 27 143 101 139 166 Target 18 892 837 79 176 21 236 47 6 51 73 Target 19 446 669 264 312 295 338 487 383 305 338 Target 20 58 2 20 67 31 8 51 21 16 22 Target 21 688 731 456 422 360 442 406 294 583 457 Target 22 542 14 43 122 5 93 94 16 104 105 Target 23 168 123 9 403 13 194 342 227 365 387 Target 24 44 423 203 611 163 80 29 38 44 44 Target 25 842 795 84 448 382 287 157 260 185 240 Target 26 723 992 453 336 62 442 245 89 150 357 Target 27 408 41 619 782 74 17 185 43 622 100 Target 28 173 909 261 943 35 251 7 2 7 1 Target 29 646 831 138 545 422 527 636 664 476 669 Median 337 423 192 387 163 375 185 150 191 224\nTable 3 Average performance of traditional consensus scores across various normalization\nMean Median Min Max EUC CBM ECR DSR\nMin\u2013max normalization 228 246.5 184 202.5 206 201 217 224 Rank normalization 191 195 271 205.5 176 174 207.5 183 z-score normalization 203 209 256 231 1000 220 191 205\n1 3\nArea ratio is the area of the histogram of median ranks obtained from novel consensus models that show better ranking than that of the best individual docking program. Rank improvement is defined as the increment of rank compared to that of the best program."
        },
        {
            "heading": "3.3 Consensus Model Accuracy Convergence",
            "text": "To evaluate the strength of linear combination in each model, we estimated the correlation between the number of docking programs and the consensus performance. Two following\n1 3\ntypes of measures were calculated: area ratio and rank improvement, relative comparisons of which are shown in Table\u00a04. The model in Eq.\u00a0(1a) defines an explicit correlation between the number of docking programs and the consensus outcome. The area ratio increased from 2 to 7 programs and then became saturated after approximately 8 docking combinations (Fig.\u00a04b). Similarly, rank improvement drastically increased from 2 to 4 programs and flattened after 5 programs (Fig.\u00a04f). A comparison between these two measures suggested that having large numbers of docking programs does not necessarily enhance overall performance. Models (1a) and (1c) showed similar saturation patterns both for area\nratio and rank improvement. The consensus effect increases monotonically with combinations of two programs, reaching a maximum value after 5 or 6 programs (Fig.\u00a04a, c, e, g). Model (1d) showed poor improvement in both area ratio and rank, with the area ratio mostly remaining zero (Fig.\u00a04d) while rank showed negative changes around n = 8 programs (Fig.\u00a04h), indicating no improvement.\nA possible reason for the lack of convergence in Fig.\u00a04b, f is the use of absolute values, causing gradual increments (\u2018accumulation\u2019 effect) as the number of docking programs increases, unlike in models (1a) and (1c) for which the consensus accuracy converges faster by 4 or 5 programs.\n1 3\nTo compare our novel rank-based CS algorithm with more conventional statistical algorithms, such as the Receiver Operating Characteristic (ROC), we evaluated histograms of consensus models (DUD-E data) (Fig.\u00a05)\nusing CS scoring of the ROC data. The consensus results showed only minor improvement in the ROC area when compared to Smina. We found that conventional statistical approaches such as enrichment factor did not highlight the\n1 3\nadvantage of the CS method, unlike the previous (Figs.\u00a02, 3) rank-based method.\nHere, we used small incremental changes to the relative weights and compared each against the other, retaining only the top-scoring ones. The quality of this prediction compares favorably with results from machine learning, as shown below. Table\u00a05 converges to a ranking of the top DUD-E ligand candidates based on CS scoring."
        },
        {
            "heading": "3.4 Complementary Machine Learning Evaluation",
            "text": "High-Affinity Ligands (HAL)-Prime Protein Target (PPT) (\u201cHigh-Affinity-Ligand\u2013Protein-Complex\u201d or HPCs hereafter) are identified using k-Means Clustering (k-MC). See Table\u00a06. The HPCs are \u2018reverse mapped\u2019 to the original active database using mutual \u201caffinity scores\u201d between the 40 HALs and 29 PPTs for each dataset. From the 400 HAL-TPC datasets, three sets of test data (26 each) were chosen for evaluation. The first is set \u2018A\u2019, comprising the last 26 rows (ligands 375\u2013400) of the original dataset. The second test set, set \u2018B\u2019, comprises the middle 26\nrows (ligands 251\u2013276). The third test set is set \u2018C\u2019 and comprises the first 26 rows (ligands 1\u201326) of the original dataset. The test data was chosen to indicate the HPCs of the original dataset. The observations are shown below: observation-1: PPT identification, observation-2: HAL identification and observation-3: HPC identification. A summary observation describes the outcome of the complementary ML model."
        },
        {
            "heading": "3.4.1 Observation 1: Prime Protein Target (PPT)",
            "text": "Identification\nFrom k-MC, three distinct high-quality clusters were obtained. Using Euclidean distance measures across all datasets around the centroids of each cluster, Clusters 1, 2 and 3 are found to contain 62%, 19% and 18% of the ligands, respectively. This information has been reversed mapped to indicate which ligands have high affinity to the protein targets (see Table\u00a06a\u2013c). k-MC identifies PPT2, PPT14 and PPT27 as the prime protein targets (see Table\u00a05)."
        },
        {
            "heading": "378, 379, 381, 382 4 3 15.4",
            "text": "1 3"
        },
        {
            "heading": "3.4.2 Observation 2: High Affinity Ligand (HAL)",
            "text": "Identification\nFrom the test sets, observed by reverse mapping, it can be noticed that in Test set \u2018A\u2019: ligand numbers 379, 380, 381 and 392 (15%) have a maximum affinity towards PPT 14. Test set \u2018B\u2019: ligand numbers 259, 260, 261 (11%) have a maximum affinity towards PPT 14. Test set \u2018C\u2019: ligand numbers 12, 14 and 17 (11%) have a maximum affinity towards PPT27, PPT27 and PPT2, respectively."
        },
        {
            "heading": "3.4.3 Observation 3: HPC Identification",
            "text": "\u2022 PPT14 \u27f7 HAL #259\u2013261, #379\u2013381, #392 \u2022 PPT27 \u27f7 HAL #12, #14 \u2022 PPT2 \u27f7 HAL #17\nThe Machine Learning (ML) protocols used to identify the 14th protein target as a good match against ligands 259\u2013261, 379\u2013381 and 392, respectively, followed by the 27th protein target matching ligands 12 and 14, and finally the 2nd protein target finding a good match with ligand number 17. These are the top drug candidates identified within the ML landscape that offers an independent assessment of possibilities. Note, this is not to suggest that any approach, e.g. consensus is necessarily better or inferior to the other, e.g. ML. While not within the scope of this study, we are considering stage-wise comparison of both predictions, consensus and ML, versus molecular dynamics predictions that should provide insight into the stability of the proposed drug candidates."
        },
        {
            "heading": "3.4.4 Summary Observation (Table\u00a06)",
            "text": "Therefore, from 72 Test ligands, 14% are found to be HALs, whereas out of 29 Protein targets, 3 PPTs (10%) are HPCs. These HPCs can be proposed as candidates for experimental analysis and subsequent drug design. The method used can only explore the important HPCs numerically and is not suitable for ranking, which requires in\u00a0vitro experiments and empirical evaluation of individual HPCs.\nBased on these experiments, we conclude that PPT2 (average HPC is 41.1%) is the highest-ranked protein candidate, as most HALs show high affinity towards it, followed by PPT14 (average 25.46%), and then PPT15 (average 23.12%)."
        },
        {
            "heading": "3.4.5 Reverse Mapping (Table\u00a06)",
            "text": "In this table, \u2018HALs\u2019, \u2018PPTs\u2019**, and their respective \u2018Affinity scores\u2019 are \u2018green\u2019, \u2018yellow\u2019, and \u2018magenta\u2019 colored boxes. Table\u00a06 also shows HPCs obtained from test data \u2018B\u2019 and \u2018C\u2019 similarly. Figure\u00a0 6 explains our\nclustering-to-reverse-mapping approach to HAL-PPT affinity evaluation."
        },
        {
            "heading": "4 Conclusions",
            "text": "We investigated consensus scoring algorithms using MRSA datasets and ten docking programs (ADFR, DOCK, Gemdock, Ledock, PLANTS, PSOVina, QuickVina2, Smina, Autodock Vina and VinaXB). Our performance benchmark was the median rank of active ligands. We also compared the individual docking programs with conventional consensus scores (minimum, maximum, mean, median, reciprocal rank and Euclidean distance). We also included the newly reported Exponential Consensus Rank score [45].\nPrior to consensus scoring, we altered the distribution of docking scores with 12 pre-normalization (with molecular weight and number of heavy atoms) and normalization (rank, min\u2013max scaling, and z-scores) thresholds to offer a direct comparison with commonly used statistical consensus scores. Comparisons indicate that our dataset is not sensitive to conventional consensus scores, showing no improved rank compared to 150 in Smina. Nonetheless, our novel consensus scores consistently perform better than individual docking\n1 3\nprograms on the MRSA benchmark dataset. In this work, we used raw docking scores from ten docking programs (ADFR, DOCK, Gemdock, Ledock, PLANTS, PSOVina, QuickVina2, Smina, Autodock Vina and VinaXB). Due to the exhaustive search of possible combinations, there was no requirement for data normalization. Results suggest that our model gives better rankings of active ligands across this benchmark dataset.\nA key outcome is the preponderance of linear combinations of docking scores showing improved active ligand ranking over non-linear consensus approaches. Given that such complex systems are known to be inherently nonlinear, such linear mapping is interesting and potentially more useful than nonlinear scores. In Eqs. (1a\u20131d), odd-ordered combinations show consistently better performance than their even-ordered counterparts. Our findings also indicate that linear combinations using absolute values (model 1b) converge towards a better functional relationship linking the number of docking programs and consensus performance. While consensus prediction accuracy is proportional to the increasing number of docking programs (see Fig.\u00a04), it is not a monotonically diverging quantity. Rather, it saturates beyond a finite number of combinations, typically 5\u20137 for our sets of ligands and MRSA proteins. This is a remarkable feature of the consensus approach. It should allow for the systematic substitution of weaker docking programs with programs exhibiting a higher scoring accuracy, as they arise over time since consensus scoring will always outperform even the best-performing individual docking program.\nBoth as a benchmarking exercise and from the perspective of complementing extant consensus predictions, we used machine learning (k-means clustering) to identify the prime protein targets (PPTs) and high-affinity ligands (HALs). While CS offers a probabilistic list of ideal combinatorial candidates between the given ligand and protein sets, clustering methods can identify the principal PPTs and HALs. This is a key outcome of this study, as we can now suggest a self-consistent algorithm capable of finding the correct MRSA drug candidates suitable for wet lab experiments.\nThe combination of CS and ML offers a straightforward approach able to combine docking scores from diverse docking platforms with higher overall efficiency than any individual docking program (CS) and predict PPTS and HALs (ML). This model can also be used in ligand-based virtual screening, where normalization usually requires data fusion. We will expand our study to include a greater range of docking programs as well as targets other than MRSA. We also plan to explore other descriptors, such as negative and/or fractional statistics. Our algorithm can lead to repositioned drug candidates while simultaneously offering a complementary prediction platform based on machine learning. We\nnote that machine learning and our algorithm are complementary protocols; they should not be expected to benchmark any strategy, but rather assist in identifying overlap in prediction.\nAcknowledgements Do, Nhat Phuong acknowledges the Vietnam International Education Development (VIED), Decision No. 76/QDBGDDT scholarship through the School of Pharmacy, Tra Vinh University, 126 Nguyen Thien Thanh Street, Ward 5, Tra Vinh City, Viet Nam for partial financial support. All authors acknowledge computational time provided by the HPC Midlands supercomputing clusters (SULIS).\nData Availability Protein and ligand data from the open-sourced repository (http:// dude. docki ng. org) have been used. Data modelling codes are all ours, based on a combination of Matlab_R2020a, R4.1.1 and python3.8, which are proprietary only. Executable codes could be available on request.\nDeclarations\nConflict of interest All authors declare that they have no conflict of interest.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/."
        }
    ],
    "title": "Towards Effective Consensus Scoring in Structure\u2010Based Virtual Screening",
    "year": 2022
}