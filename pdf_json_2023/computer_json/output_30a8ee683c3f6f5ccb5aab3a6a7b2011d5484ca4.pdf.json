{
    "abstractText": "Image registration of liver dynamic contrastenhanced computed tomography (DCE-CT) is crucial for diagnosis and image-guided surgical planning of liver cancer. However, intensity variations due to the flow of contrast agents combined with complex spatial motion induced by respiration brings great challenge to existing intensity-based registration methods. To address these problems, we propose a novel structure-aware registration method by incorporating structural information of related organs with segmentation-guided deep registration network. Existing segmentation-guided registration methods only focus on volumetric registration inside the paired organ segmentations, ignoring the inherent attributes of their anatomical structures. In addition, such paired organ segmentations are not always available in DCE-CT images due to the flow of contrast agents. Different from existing segmentation-guided registration methods, our proposed method extracts structural information in hierarchical geometric perspectives of line and surface. Then, according to the extracted structural information, structure-aware constraints are constructed and imposed on the forward and backward deformation field simultaneously. In this way, all available organ segmentations, including unpaired ones, can be fully utilized to avoid the side effect of contrast agent and preserve the topology of organs during registration. Extensive experiments on an in-house liver DCE-CT dataset and a public LiTS dataset show that our proposed method can achieve higher registration accuracy and preserve anatomical structure more effectively than state-of-the-art methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Peng Xue"
        },
        {
            "affiliations": [],
            "name": "Jingyang Zhang"
        },
        {
            "affiliations": [],
            "name": "Mianxin Liu"
        },
        {
            "affiliations": [],
            "name": "Yuning Gu"
        },
        {
            "affiliations": [],
            "name": "Jiawei Huang"
        },
        {
            "affiliations": [],
            "name": "Feihong Liu"
        },
        {
            "affiliations": [],
            "name": "Yongsheng Pan"
        },
        {
            "affiliations": [],
            "name": "Lei Ma"
        },
        {
            "affiliations": [],
            "name": "Xiaohuan Cao"
        },
        {
            "affiliations": [],
            "name": "Dinggang Shen"
        }
    ],
    "id": "SP:123245ee2e75fb2afaee5df67f159ee9abbebc24",
    "references": [
        {
            "authors": [
                "Y. Fu",
                "Y. Lei",
                "T. Wang",
                "J. Zhou",
                "W.J. Curran",
                "P. Patel",
                "T. Liu",
                "X. Yang"
            ],
            "title": "Deformable MRI-CT liver image registration using convolutional neural network with modality independent neighborhood descriptors",
            "venue": "Medical Imaging 2021: Computer-Aided Diagnosis, vol. 11597. SPIE, 2021, pp. 102\u2013107.",
            "year": 2021
        },
        {
            "authors": [
                "E.E. Stewart",
                "X. Chen",
                "J. Hadway",
                "T.-Y. Lee"
            ],
            "title": "Hepatic perfusion in a tumor model using DCE-CT: an accuracy and precision study",
            "venue": "Physics in Medicine & Biology, vol. 53, no. 16, p. 4249, 2008.",
            "year": 2008
        },
        {
            "authors": [
                "V. Vishnevskiy",
                "T. Gass",
                "G. Szekely",
                "C. Tanner",
                "O. Goksel"
            ],
            "title": "Isotropic total variation regularization of displacements in parametric image registration",
            "venue": "IEEE transactions on medical imaging, vol. 36, no. 2, pp. 385\u2013395, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "P. Xue",
                "E. Dong",
                "H. Ji"
            ],
            "title": "Lung 4D CT image registration based on high-order markov random field",
            "venue": "IEEE Transactions on Medical Imaging, vol. 39, no. 4, pp. 910\u2013921, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Burger",
                "J. Modersitzki",
                "L. Ruthotto"
            ],
            "title": "A hyperelastic regularization energy for image registration",
            "venue": "SIAM Journal on Scientific Computing, vol. 35, no. 1, pp. B132\u2013B148, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "E. Hodneland",
                "A. Lundervold",
                "J. R\u00f8rvik",
                "A.Z. Munthe-Kaas"
            ],
            "title": "Normalized gradient fields for nonlinear motion correction of DCE- MRI time series",
            "venue": "Computerized Medical Imaging and Graphics, vol. 38, no. 3, pp. 202\u2013210, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "Y. Zheng",
                "A.D. Maidment",
                "J.C. Gee"
            ],
            "title": "Accurate registration of dynamic contrast-enhanced breast MR images with robust estimation and linear programming",
            "venue": "2010 IEEE International Symposium on Biomedical Imaging: From Nano to Macro. IEEE, 2010, pp. 536\u2013539.",
            "year": 2010
        },
        {
            "authors": [
                "M.P. Heinrich",
                "M. Jenkinson",
                "M. Bhushan",
                "T. Matin",
                "F.V. Gleeson",
                "M. Brady",
                "J.A. Schnabel"
            ],
            "title": "MIND: Modality independent neighbourhood descriptor for multi-modal deformable registration",
            "venue": "Medical image analysis, vol. 16, no. 7, pp. 1423\u20131435, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "W. Huizinga",
                "D.H. Poot",
                "J.-M. Guyader",
                "R. Klaassen",
                "B.F. Coolen",
                "M. van Kranenburg",
                "R. Van Geuns",
                "A. Uitterdijk",
                "M. Polfliet",
                "J. Vandemeulebroucke"
            ],
            "title": "PCA-based groupwise image registration for quantitative MRI",
            "venue": "Medical image analysis, vol. 29, pp. 65\u201378, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "G. Wollny",
                "P. Kellman",
                "A. Santos",
                "M.J. Ledesma-Carbayo"
            ],
            "title": "Automatic motion compensation of free breathing acquired myocardial perfusion data by using independent component analysis",
            "venue": "Medical image analysis, vol. 16, no. 5, pp. 1015\u20131028, 2012.",
            "year": 2012
        },
        {
            "authors": [
                "Y. Zhou",
                "Y. Sun",
                "W. Yang",
                "Z. Lu",
                "M. Huang",
                "L. Lu",
                "Y. Zhang",
                "Y. Feng",
                "W. Chen",
                "Q. Feng"
            ],
            "title": "Correlation-weighted sparse representation for robust liver DCE-MRI decomposition registration",
            "venue": "IEEE transactions on medical imaging, vol. 38, no. 10, pp. 2352\u20132363, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "P. Dong",
                "L. Wang",
                "W. Lin",
                "D. Shen",
                "G. Wu"
            ],
            "title": "Scalable joint segmentation and registration framework for infant brain images",
            "venue": "Neurocomputing, vol. 229, pp. 54\u201362, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "I. Aganj",
                "B. Fischl"
            ],
            "title": "Multimodal image registration through simultaneous segmentation",
            "venue": "IEEE signal processing letters, vol. 24, no. 11, pp. 1661\u20131665, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "M. Viergever",
                "J. Maintz",
                "W. Niessen",
                "H. Noordmans",
                "J. Pluim",
                "R. Stokking",
                "K. Vincken"
            ],
            "title": "Registration, segmentation, and visualization of multimodal brain images",
            "venue": "Computerized Medical Imaging and Graphics, vol. 25, no. 2, pp. 147\u2013151, 2001",
            "year": 2001
        },
        {
            "authors": [
                "D. Shen",
                "C. Davatzikos"
            ],
            "title": "HAMMER: hierarchical attribute matching mechanism for elastic registration",
            "venue": "IEEE transactions on medical imaging, vol. 21, no. 11, pp. 1421\u20131439, 2002.",
            "year": 2002
        },
        {
            "authors": [
                "T. Vercauteren",
                "X. Pennec",
                "A. Perchant",
                "N. Ayache"
            ],
            "title": "Diffeomorphic demons: Efficient non-parametric image registration",
            "venue": "NeuroImage, vol. 45, no. 1, pp. S61\u2013S72, 2009.",
            "year": 2009
        },
        {
            "authors": [
                "D. Rueckert",
                "L.I. Sonoda",
                "C. Hayes",
                "D.L. Hill",
                "M.O. Leach",
                "D.J. Hawkes"
            ],
            "title": "Nonrigid registration using free-form deformations: application to breast MR images",
            "venue": "IEEE transactions on medical imaging, vol. 18, no. 8, pp. 712\u2013721, 1999.",
            "year": 1999
        },
        {
            "authors": [
                "X. Cao",
                "J. Yang",
                "J. Zhang",
                "D. Nie",
                "M. Kim",
                "Q. Wang",
                "D. Shen"
            ],
            "title": "Deformable image registration based on similarity-steered cnn regression",
            "venue": "International Conference on Medical Image Computing and Computer Assisted Intervention. Springer, 2017, pp. 300\u2013308.",
            "year": 2017
        },
        {
            "authors": [
                "H. Uzunova",
                "M. Wilms",
                "H. Handels",
                "J. Ehrhardt"
            ],
            "title": "Training cnns for image registration from few samples with model-based data augmentation",
            "venue": "International Conference on Medical Image Computing and Computer Assisted Intervention. Springer, 2017, pp. 223\u2013231.",
            "year": 2017
        },
        {
            "authors": [
                "K.A. Eppenhof",
                "J.P. Pluim"
            ],
            "title": "Pulmonary CT registration through supervised learning with convolutional neural networks",
            "venue": "IEEE transactions on medical imaging, vol. 38, no. 5, pp. 1097\u20131105, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "A.V. Dalca",
                "G. Balakrishnan",
                "J. Guttag",
                "M.R. Sabuncu"
            ],
            "title": "Unsupervised learning of probabilistic diffeomorphic registration for images and surfaces",
            "venue": "Medical image analysis, vol. 57, pp. 226\u2013236, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "G. Balakrishnan",
                "A. Zhao",
                "M.R. Sabuncu",
                "J. Guttag",
                "A.V. Dalca"
            ],
            "title": "Voxelmorph: a learning framework for deformable medical image registration",
            "venue": "IEEE transactions on medical imaging, vol. 38, no. 8, pp. 1788\u20131800, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Hering",
                "S. Kuckertz",
                "S. Heldmann",
                "M.P. Heinrich"
            ],
            "title": "Enhancing label-driven deep deformable image registration with local distance metrics for state-of-the-art cardiac motion tracking",
            "venue": "Bildverarbeitung f\u00fcr die Medizin 2019. Springer, 2019, pp. 309\u2013314.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Hu",
                "M. Modat",
                "E. Gibson",
                "W. Li",
                "N. Ghavami",
                "E. Bonmati",
                "G. Wang",
                "S. Bandula",
                "C.M. Moore",
                "M. Emberton"
            ],
            "title": "Weakly-supervised convolutional neural networks for multimodal image registration",
            "venue": "Medical image analysis, vol. 49, pp. 1\u201313, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "R. Bajcsy",
                "S. Kovac\u02c7ic\u02c7"
            ],
            "title": "Multiresolution elastic matching",
            "venue": "Computer vision, graphics, and image processing, vol. 46, no. 1, pp. 1\u201321, 1989.",
            "year": 1989
        },
        {
            "authors": [
                "J. Canny"
            ],
            "title": "A computational approach to edge detection",
            "venue": "IEEE Transactions on pattern analysis and machine intelligence, no. 6, pp. 679\u2013698, 1986.",
            "year": 1986
        },
        {
            "authors": [
                "R.O. Duda",
                "P.E. Hart"
            ],
            "title": "Pattern classification and scene analysis",
            "venue": "Wiley New York,",
            "year": 1973
        },
        {
            "authors": [
                "T.-C. Lee",
                "R.L. Kashyap",
                "C.-N. Chu"
            ],
            "title": "Building skeleton models via 3-D medial surface axis thinning algorithms",
            "venue": "CVGIP: Graphical Models and Image Processing, vol. 56, no. 6, pp. 462\u2013478, 1994.",
            "year": 1994
        },
        {
            "authors": [
                "J. Zhang"
            ],
            "title": "Inverse-consistent deep networks for unsupervised deformable image registration",
            "venue": "arXiv preprint arXiv:1809.03443, 2018.",
            "year": 1809
        },
        {
            "authors": [
                "A.F. Frangi",
                "W.J. Niessen",
                "K.L. Vincken",
                "M.A. Viergever"
            ],
            "title": "Multiscale vessel enhancement filtering",
            "venue": "International conference on medical image computing and computer assisted intervention. Springer, 1998, pp. 130\u2013137.",
            "year": 1998
        }
    ],
    "sections": [
        {
            "text": "IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. X, NOVEMBER 2020 1\nStructure-aware Registration Network for Liver DCE-CT Images\nPeng Xue, Jingyang Zhang, Mianxin Liu, Yuning Gu, Jiawei Huang, Feihong Liu, Yongsheng Pan, Lei\nMa, Xiaohuan Cao, Dinggang Shen Fellow, IEEE Abstract\u2014Image registration of liver dynamic contrast-\nenhanced computed tomography (DCE-CT) is crucial for diagnosis and image-guided surgical planning of liver cancer. However, intensity variations due to the flow of contrast agents combined with complex spatial motion induced by respiration brings great challenge to existing intensity-based registration methods. To address these problems, we propose a novel structure-aware registration method by incorporating structural information of related organs with segmentation-guided deep registration network. Existing segmentation-guided registration methods only focus on volumetric registration inside the paired organ segmentations, ignoring the inherent attributes of their anatomical structures. In addition, such paired organ segmentations are not always available in DCE-CT images due to the flow of contrast agents. Different from existing segmentation-guided registration methods, our proposed method extracts structural information in hierarchical geometric perspectives of line and surface. Then, according to the extracted structural information, structure-aware constraints are constructed and imposed on the forward and backward deformation field simultaneously. In this way, all available organ segmentations, including unpaired ones, can be fully utilized to avoid the side effect of contrast agent and preserve the topology of organs during registration. Extensive experiments on an in-house liver DCE-CT dataset and a public LiTS dataset show that our proposed method can achieve higher registration accuracy and preserve anatomical structure more effectively than state-of-the-art methods.\nIndex Terms\u2014Image registration, liver DCE-CT, segmentation-guided registration network, structure-aware constraints\nI. INTRODUCTION IVER dynamic contrast-enhanced computed tomography (DCE-CT) imaging typically acquires a sequence of images before and after injection of contrast agent, namely pre- contrast phase, arterial phase and venous phase (both called postcontrast phase). Precise registration between DCE-CT images at pre- and post-contrast phases can obtain refined subtraction\nThis work was supported in part by National Natural Science Foundation of China under Grant 62131015, Science and Technology Commission of\nShanghai Municipality (STCSM) under Grant 21010502600, and The Key R&D Program of Guangdong Province, China under Grant 2021B0101420006. (Peng Xue and Jingyang Zhang contributed equally to this work.) (Corresponding authors: Xiaohuan Cao, Dinggang Shen.)\nPeng Xue, Jingyang Zhang, Yuning Gu, Jiawei Huang, Feihong Liu, Yongsheng Pan, Lei Ma are with School of Biomedical Engineering, ShanghaiTech University, Shanghai, China.\nXiaohuan Cao is with Shanghai United Imaging Intelligence Co., Ltd., Shanghai, China (e-mail: xiaohuan.cao@uii-ai.com). Dinggang Shen is with School of Biomedical Engineering, Shang- haiTech University, Shanghai 201210, China. He is also with Shanghai United Imaging Intelligence Co., Ltd., Shanghai 200230, China, and Shanghai Clinical Research and Trial Center, Shanghai 201210, China (email: Dinggang.Shen@gmail.com).\nimages to reveal the flow of contrast agent and expose the focuses (e.g. tumors), which is vital for quantitative analysis for diagnosis and therapy assessment [1], [2]. For liver cancer, surgery is an effective treatment manner. DCE-CT can provide complementary information from different phases, particularly the arterial and venous phases. The two phases can provide different information of tumors and their surroundings, thus helping clinicians evaluate the tumor comprehensively and performing more accurate surgical planning. In this work, we focus on one exemplar application of liver DCE-CT image registration which is to register images of arterial phase with venous phase for assisting the design of surgical planning.\nIn general, there are two major challenges for liver DCE-CT image registration: 1) Large motion of subtle anatomies within the liver. A DCE-CT scan typically requires a few minutes, during which the motion of patient, including respiratory motion, heart motion, and stomach and bowel peristalsis, is inevitable. The large motion makes it difficult to align subtle anatomies accurately, especially for vessels including both arteries and veins. 2) Intensity or local appearance variations due to the uptake and washout of contrast agent. As shown in Fig. 1, due to the flow of contrast agent, the hepatic artery and the portal vein exhibit similar intensity values at the arterial and the venous phase, respectively. Although the two types of vessels are adjacent spatially, the arteries and veins should not be overlapped when performing registration between these two phases. However, for such scenario, most intensity-based L\nFig. 1. Liver DCE-CT images at arterial phase and venous phase. Hepatic artery and portal vein are enhanced at the arterial phase and venous phase, respectively.\n2 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. x, 2020\nregistration methods may easily align these two different types of vessels incorrectly.\nFor tackling the large motion of subtle anatomies, a general way is to introduce a novel regularization term, such as isotropic total variation regularization [3], topology preservation term [4] or hyper-elastic regularization [5], into energy function to preserve the topological structure of the entire deformation field. Although these methods can partially improve the registration performance, they usually regularize the global deformation field in a uniform manner, which remains insufficient to process the images with large local deformations.\nIn order to handle the intensity variations between the fixed and moving images, several methods employ intensityinsensitive metrics, such as normalized gradient fields [6], Lorentzian estimator [7], and modality-independent neighborhood descriptor [8] to guide the registration. However, these similarity metrics cannot capture underlying anatomical information of organs to guarantee reasonable registration results.\nAnother way to reduce the effect of contrast variation in registration is to separate the motion components from the intensity variations caused by contrast agents. If enhanced components can be separated from post-contrast images, the remaining de-enhanced images can be easily registered by conventional intensity-based registration methods. Following this strategy, registration methods based on statistical models such as principal component analysis (PCA) [9], independent component analysis (ICA) [10], and correlation-weighted sparse representation [11] are proposed. Although the above deenhancing methods [9]\u2013[11] have shown relatively promising performance, the limited image samples from DCE-CT sequence is insufficient for effectively performing PCA or ICA.\nFurthermore, segmentation-guided registration strategy [12]\u2013[14] is another way to separate contrast-enhanced regions from post-contrast images. Specifically, corresponding structures can be segmented reliably with anatomical knowledge. Such segmentation results can then be used to highlight the organs of interest, focused regions, or other anatomical structures between paired images, and serve as guidance for alignment of voxels. Therefore, the segmentationguided registration strategy could avoid the influence of intensity variations effectively, and it has been widely used in various registration tasks.\nHowever, some limitations in existing segmentation-guided registration methods need to be further investigated for their application to liver DCE-CT images. First, existing methods only focus on volumetric registration inside the organ masks, ignoring the inherent geometric structure of the organs (e.g., the organ surface, organ morphology, tubular structures of vessels). More importantly, most segmentation-guided registration methods [12]\u2013[14] require paired segmentations for guidance. In some special scenarios, such as liver DCE-CT images, it can only obtain segmentations of either arterial or venous vessels at different phases (as shown in Fig. 1), and existing registration methods are incapable of utilizing such unpaired segmentations.\nFor tackling the above issues in liver DCE-CT image\nregistration, a structure-aware registration network is proposed in this paper. The structure-aware constraints are designed based on the geometric information of different organs from hierarchical perspectives. In addition, we propose a nonoverlap loss to utilize the unpaired segmentations of blood vessels in arterial phase and venous phase. Moreover, the designed structure-aware constraints are imposed on forward and backward registrations bidirectionally to relieve the bias in the guidance from unpaired segmentations.\nSpecifically, there are three highlights of our work: 1) We explore the structural characteristics of various organs\nfrom multiple geometrically meaningful perspectives (e.g., centerline, surface and volume of vessel). Then, a novel structure-aware and segmentation-guided deep registration network is designed by leveraging structural information to handle the effect of large local motion, and varied contrast-enhancement between fixed and moving images.\n2) We introduce several novel structure-aware constraints on deformation field. Different from existing global regularization constraints, our proposed structure-aware constraints fully consider a dense relationship of displacement within the extracted structure, and can preserve their topology of segmented organs from hierarchical perspectives of centerline and surface. 3) In order to fully utilize all available segmentations for registration, we employ volumetric overlap and nonoverlap losses for paired segmentations and unpaired segmentations, respectively. Meanwhile, we impose the structure-aware constraints on forward and backward deformation fields simultaneously to prevent bias introduced by the unpaired segmentations, and improve the registration performance effectively.\nII. RELATED WORK\nA. Conventional Image Registration Methods Conventional image registration methods, such as elastic\n[15], fluid [16], B-spline [17] or Markov random field (MRF) model [4], are usually based on the iterative optimization. Although the conventional image registration methods can solve a variety of registration tasks, there still remains some challenging problems that have not been well solved. For instance, it is difficult to accurately register images with large local deformations while keeping the smoothness of deformation field. Furthermore, the multi-modal image registration, or registration of images with domain shift, needs to be further explored. More importantly, the conventional optimization- based methods are computationally complex, and the efficiency cannot sufficiently meet the clinical requirements.\nB. Deep Learning-based Image Registration Methods Compared with conventional registration methods, deep learning-based methods can significantly improve the registration speed while achieving comparable performance at the same time. The convolutional neural network is designed to learn a complex mapping model between the to-be-registered\n3 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. x, 2020\nimage pair. Based on the network design and data information used to train the registration model, the deep learning-based registration can be summarized as three categories:\n(1) Supervised learning that uses the ground-truth deformations as the label to train the model [18]\u2013[20]. For supervised registration network, the training loss is usually defined by the distance metric between the predicted and the ground-truth deformation fields. Although the results of such methods are encouraging, the performance is affected by the quality of the generated ground truth and also the size of training data.\n(2) Unsupervised learning that mainly uses image similarity as the guidance to train the model without ground-truth labels. Such method is preferred for registration task since it does not need the \u201cground-truth\u201d transformations. Basically, the definition of loss function has two main terms: the image similarity after registration and the smoothness (regularization) of the predicted deformation field. A representative unsupervised network is VoxelMorph [21], [22], which uses variational methods to predict deformation fields and maintain diffeomorphism of deformation fields by integrating velocity fields. Due to the fact that it does not require extensive data annotation, its registration accuracy is not limited by the quality of the ground truth, and it can be generalized to a wide variety of clinical applications.\n(3) Weakly-supervised learning where part of segmentations are applied during the model training. The weakly-supervise learning can be understood as training the registration model using some auxiliary information such as organ segmentations as the guidance to train the registration network for higher accuracy. For instance, Hering et al. [23] used both weak and dual supervision by incorporating segmentation similarity and image similarity to the loss function for cardiac motion tracking. In addition, Hu et al. [24] proposed an end-to- end network to predict both affine transformation and local deformations, and the network is trained by the overlap rate of organ segmentations. By introducing auxiliary information, these weakly-supervised methods can improve registration performance compared with pure unsupervised training strategies.\nHowever, existing weakly-supervised registration network still have some limitations. First, they do not capture the inherent topological structure of organs during registration, leading to disconnection of small vessels and non-smoothness of organ surfaces. Second, limited by the image quality and physical acquisition process, paired organ segmentations of moving and fixed images are not always available in medical imaging, hampering clinical application of segmentationguided registration method.\nIII. METHOD\nA. Naive Weakly-Supervised Deep Registration Network The goal of deformable image registration aims to establish spatial correspondence between n-dimensional fixed image \ud835\udc3c :\u03a9 \u2208 \u211d and n-dimensional moving image \ud835\udc3c :\u03a9 \u2208 \u211d . It aims to find the deformation \ud835\udf11(\ud835\udc5d) for each voxel \ud835\udc5d \u2208 \u03a9 such that \ud835\udc3c (\ud835\udc5d) and [\ud835\udc3c \u2218 \ud835\udf11](\ud835\udc5d) correspond to similar anatomical\nlocation, where \ud835\udf11 = \ud835\udc3c\ud835\udc51 + \ud835\udc2e is the deformation field characterized by a displacement field u and \ud835\udc3c\ud835\udc51 represents the identity transform [25]. Existing deep learning-based registration framework usually applies an encoder-decoder network (referred as U-net or V-net) to estimate the deformation \ud835\udf11 from a pair of inputted images (\ud835\udc3c and \ud835\udc3c ).\nWhen using an unsupervised learning problem setting, the registration network minimizes a loss function \u2112 that measures the dissimilarity between the fixed image \ud835\udc3c and the warped moving image \ud835\udc3c \u2218 \ud835\udf11 : \u2112 = \u2112 (\ud835\udc3c , \ud835\udc3c \u2218 \ud835\udf11) + \ud835\udf06\u2112 (\ud835\udf11) (1) where \u2112 (\ud835\udc3c , \ud835\udc3c \u2218 \ud835\udf11) represents the dissimilarity loss, which is used to enforce \ud835\udc3c \u2218 \ud835\udf11 to be similar to \ud835\udc3c . \u2112 (\ud835\udf11) is a regularization term to preserve smoothness of the predicted deformation field \ud835\udf11.\nFollowing the typical weakly-supervised registration manner, several methods [23], [24] leverage the auxiliary information, such as organ segmentations, to train the registration network. If a deformation field \ud835\udf11 represent accurate anatomical correspondence, the regions in \ud835\udc3c and \ud835\udc3c \u2218 \ud835\udf11 corresponding to the same organ or anatomical structure should overlap well. Adopting this strategy, an auxiliary loss can be defined using some classical overlap metrics, such as Dice score, Jaccard, and cross-entropy. For example, the volumetric overlap of same anatomical structure can be quantified using Dice score: Dice(\ud835\udc46 ,\ud835\udc46 \u2218 \ud835\udf11) = 2 \u00d7 | \u2229( \u2218 )|| | | \u2218 | (2) where \ud835\udc46 and \ud835\udc46 \u2218 \ud835\udf11 represent the voxels of same anatomical structure for \ud835\udc3c and \ud835\udc3c \u2218 \ud835\udf11, respectively. Then, an auxiliary loss based on segmentations can be defined as: \u2112 (\ud835\udc46 , \ud835\udc46 \u2218 \ud835\udf11) = \u2212Dice(\ud835\udc46 , \ud835\udc46 \u2218 \ud835\udf11) (3) With the help of segmentation results, equation (3) have been proved to significantly improve the registration performance.\nB. Structure-aware Registration Network In general, the morphological or topological structures of different organs are not identical. We use these structural information to supervise registration network, to estimate the deformation field more effectively. Generally, the structural information of organs can be effectively characterized from several key geometric perspectives. For instance, volumetric structures, such as liver parenchyma, bladder, and rectum, can be effectively represented as 3D surfaces or 2D contours. And tubular structures, such as blood vessels, can be modeled by skeleton lines.\nTherefore, in this paper, for different anatomies, we utilize geometric representations for various organs and propose structure-aware constraints to preserve the organ morphology after registration. Specifically, the proposed structure-aware registration network is designed as shown in Fig. 2. The network takes pairs of images \ud835\udc3c and \ud835\udc3c with their\nsegmentations of liver and blood vessels (\ud835\udc46 , \ud835\udc46 and \ud835\udc46 , \ud835\udc46 ) as\ninputs, computes the forward deformation \ud835\udf11 and inverse deformation \ud835\udf11 . Among them, \ud835\udc46 and \ud835\udc46 represent the paired liver segmentations, \ud835\udc46 and \ud835\udc46 represent different types of vessel segmentations in the venous and arterial phases, respectively. Then, we warp the moving image \ud835\udc3c and its corresponding segmentation masks \ud835\udc46 and \ud835\udc46 to \ud835\udc3c \u2218 \ud835\udf11, \ud835\udc46 \u2218\ud835\udf11, and \ud835\udc46 \u2218 \ud835\udf11, respectively, for the evaluations of the similarity between \ud835\udc3c \u2218 \ud835\udf11 and \ud835\udc3c , the overlap between \ud835\udc46 \u2218 \ud835\udf11 and \ud835\udc46 , and the non-overlap between \ud835\udc46 \u2218 \ud835\udf11 and \ud835\udc46 .\nIn addition, for arterial and venous vessels, we extract their centerlines \ud835\udc36 and \ud835\udc36 from \ud835\udc46 and \ud835\udc46 , respectively. to represent their organ morphology. For liver parenchyma with large volume, paired surfaces \ud835\udc42 and \ud835\udc42 are extracted from \ud835\udc46 and \ud835\udc46 to represent the topology of the whole liver. Then, the structure-aware constraints that can preserve organ topologies are constructed using extracted structural information, and imposed on the forward deformation field \ud835\udf11 and inverse deformation field \ud835\udf11 simultaneously to avoid the bias introduced by the unpaired segmentations.\nIn summary, there are two different types of loss functions for the entire structure-aware registration network: 1) the losses of similarity term between warped images (\ud835\udc3c \u2218 \ud835\udf11 , \ud835\udc46 \u2218 \ud835\udf11 , \ud835\udc46 \u2218 \ud835\udf11) and fixed images (\ud835\udc3c , \ud835\udc46 , \ud835\udc46 ), and 2) the losses of local and global regularization terms for both forward deformation field \ud835\udf11 and inverse deformation field \ud835\udf11 . \u2112 = \u2112 (\ud835\udc3c , \ud835\udc3c \u2218 \ud835\udf11) + \ud835\udf06 \u2112 (\ud835\udc46 , \ud835\udc46 \u2218 \ud835\udf11) +\ud835\udf06 \u2112 (\ud835\udc46 , \ud835\udc46 \u2218 \ud835\udf11) + \ud835\udf06 \u2112 (\ud835\udf11) + \u2112 (\ud835\udf11 ) +\ud835\udf06 \u2112 (\ud835\udc42 ,\ud835\udf11) + \u2112 (\ud835\udc42 ,\ud835\udf11 ) +\ud835\udf06 \u2112 (\ud835\udc36 ,\ud835\udf11) + \u2112 (\ud835\udc36 ,\ud835\udf11 ) (4)\nwhere \ud835\udf06 \u2208 , , , , are hyper-parameters that can be empirically\nset to different values according to the experiment. \u2112 (\ud835\udc3c , \ud835\udc3c \u2218 \ud835\udf11) captures the dissimilarity between \ud835\udc3c \u2218 \ud835\udf11 and \ud835\udc3c , and we use normalize cross-correlation (NCC) to evaluate the dissimilarity between \ud835\udc3c \u2218 \ud835\udf11 and \ud835\udc3c . At the same time, as paired liver segmentation \ud835\udc46 and \ud835\udc46 are available, we compute the Dice loss in (3) as the volumetric overlap loss \u2112 (\ud835\udc46 , \ud835\udc46 \u2218\ud835\udf11) to ensure accurate alignment of the liver parenchyma. For unpaired blood vessel segmentations \ud835\udc46 and \ud835\udc46 , we directly use Dice score in (2) as non-overlap measure \u2112 (\ud835\udc46 , \ud835\udc46 \u2218 \ud835\udf11) to prevent overlapping between different types of vessels (i.e., arteries and veins). Based on this, we use squared \u2113-1 norm derivatives of the displacement field u as global regularization term \u2112 (\ud835\udf11) and \u2112 (\ud835\udf11 ) to preserve smoothness of the entire predicted deformation \ud835\udf11 and \ud835\udf11 .\nHowever, only relying on the above-mentioned losses cannot ensure the preservation of the topology of organs during registration. Therefore, according to the morphology of different organs, we construct structure-aware constraints \u2112 (\ud835\udc42 ,\ud835\udf11), \u2112 (\ud835\udc42 ,\ud835\udf11 ), \u2112 (\ud835\udc36 ,\ud835\udf11), \u2112 (\ud835\udc36 ,\ud835\udf11 ) to preserve the topology of organs during registration, which will be elaborated in the following subsection.\nC. Anatomical Structure Representation and Structureaware Constraint\nGenerally, most existing registration methods constrain deformation fields to be globally smooth and continuous to avoid physically implausible displacement. For instance, the widely-used global smoothness regularization penalizes the squared \u2113 -1norm derivatives of the deformation field components:\n5 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. x, 2020 \u2112 (\ud835\udf11) = \u2016\u2207\ud835\udc2e(\ud835\udc5d)\u2016\u2208 (5)\nwhere \u2207\ud835\udc2e(\ud835\udc5d) = ( \ud835\udc2e( ) , \ud835\udc2e( ) , \ud835\udc2e( )) , \ud835\udc2e( ) \u2248 \ud835\udc2e \ud835\udc5d +1,\ud835\udc5d ,\ud835\udc5d \u2212 \ud835\udc62([\ud835\udc5d ,\ud835\udc5d ,\ud835\udc5d ]) , and similar for \ud835\udc2e( ) and \ud835\udc2e( ) . However, a global homogeneous smoothing neglects local structural information of organs, and can lead to violation of the topology of organs during registration. Therefore, additional constraints should also be considered for registration.\nFor large volume like liver parenchyma, surface can well present the organ morphology. Thus, the smoothness of surface is crucial to preserve the organ topology. To keep the liver surface smooth after registration, the deformation of adjacent voxels should be locally consistent. The detailed implementation is shown in Fig. 3. Note that we use \ud835\udc42 and forward deformation field \ud835\udf11 to illustrate the construction of \u2112 (\ud835\udc42 ,\ud835\udf11), and the construction of \u2112 (\ud835\udc42 ,\ud835\udf11 ) is similar to \u2112 (\ud835\udc42 ,\ud835\udf11). First, the surface of liver \ud835\udc42 \u2208 \u03a9 is reconstructed from liver segmentation result by edge extraction algorithm (such as Canny operator [26] or Sobel operator [27]). Then, a structure-aware constraint is constructed according to \ud835\udc42 and deformation field \ud835\udf11.\nHere, we take a 2D slice as an example to illustrate. In a 2D slice, each voxel \ud835\udc5d has 8 neighboring voxels as shown in Fig. 3. Among them, the dark blue voxels \ud835\udc5d \u2208 \ud835\udc42 belonging to the liver surface \ud835\udc42 should have similar deformations \ud835\udc2e(\ud835\udc5d ) with the center voxel, so as to keep the smoothness of liver surface. However, equation (5) only calculates gradient of \ud835\udc2e(\ud835\udc5d ) along the direction of coordinate axis (as colored in red and green lines), ignoring the relation of deformations along the diagonal (as colored in blue and orange lines). In this way , equation (5) only constrains voxels along vertical and horizontal directions to have similar displacements as the center voxel, which cannot constrain other voxels along diagonal direction.\nTherefore, we design a novel regularization term \u2112 (\ud835\udc42 ,\ud835\udf11), which considers 8 neighboring voxels not only along the direction of the coordinate axis, but also along the gradient (directional derivative) of the diagonal direction: \u2112 ( \ud835\udc42 ,\ud835\udf11) = \u2016\u2207 \ud835\udc2e(\ud835\udc5d )\u2016\u2208 (6) where \u2207 \ud835\udc2e(\ud835\udc5d ) = \ud835\udc2e , \ud835\udc2e , \ud835\udc2e , \ud835\udc2e . Similar to forward differences \ud835\udc2e and \ud835\udc2e along directions of the x and y axes, \ud835\udf15\ud835\udc2e(\ud835\udc5d )\ud835\udf15\ud835\udc5a \u2248 \ud835\udc62 \ud835\udc5d + 1,\ud835\udc5d + 1 \u2212 \ud835\udc62 \ud835\udc5d , \ud835\udc5d\ud835\udc63 + \ud835\udc63 (7) and \ud835\udf15\ud835\udc2e(\ud835\udc5d )\ud835\udf15\ud835\udc5b \u2248 \ud835\udc62 \ud835\udc5d \u2212 1,\ud835\udc5d + 1 \u2212 \ud835\udc62 \ud835\udc5d , \ud835\udc5d\ud835\udc63 + \ud835\udc63 (8) represent the forward differences along directions of m (direction along blue line) and n (direction along orange line), and \ud835\udc63 and \ud835\udc63 represent spatial resolutions along the x and y\naxes. For liver vessels with tubular structures, the centerline can effectively represent their morphology. In order to maintain the morphology of vessels after registration, the deformation of adjacent voxels within the centerline should also be locally consistent. Similarly, we use \ud835\udc36 and forward deformation field \ud835\udf11 to illustrate the construction of \u2112 ( \ud835\udc36 ,\ud835\udf11). As shown in Fig. 4, centerlines \ud835\udc36 \u2208 \ud835\udc46 of vessels are extracted from vessel segmentation \ud835\udc46 using a classical skeleton extraction algorithm [28]. Then, the structure-aware constraints of vessels are constructed in a similar way to \u2112 ( \ud835\udc42 ,\ud835\udf11). It should be noted that the structure-aware constraints of vessels are constructed separately according to unpaired vessel segmentations, and imposed to the forward and backward deformation fields, respectively. In this way, unpaired segmentations can be fully exploited to preserve vessel morphology while avoiding bias at the same time.\nIn addition, to further preserve the topology of fine vessel branches, the structure-aware constraints are imposed with different weights along the centerline \ud835\udc36 . Specifically, a distance map dm(\ud835\udc5d) is calculated based on vessel segmentation \ud835\udc46 . Among them, each voxel \ud835\udc5d \u2208 \ud835\udc46 measures the shortest distance between p and background. Then, the structure-aware constraints \u2112 ( \ud835\udc36 ,\ud835\udf11) are constructed by applying different weights \ud835\udc64(\ud835\udc5d ) = ( ) ,\ud835\udc5d \u2208 \ud835\udc36 . In this way, a largeweighted constraint is imposed on fine branches to preserve the topology of tiny vessel branches. In summary, the structureaware constraints on centerline can be formulated as:\nFig. 3. The construction of structure-aware constraints for segmentation of liver.\nFig. 4. The construction of structure-aware constraints for segmentation of vessel.\n6 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. x, 2020 \u2112 ( \ud835\udc36 ,\ud835\udf11) = \ud835\udc64(\ud835\udc5d ) \u2016\u2207 \ud835\udc2e(\ud835\udc5d )\u2016\u2208 D. Implementation We have implemented the structure-aware network by Pytorch, and trained it on a single 20 GB NVIDIA V100 GPU. Adam optimizer is used with a learning rate of 1e-4. The structure-aware network is trained by 500 epochs with 200 iterations in each epoch. The five weights \ud835\udf06 \u2208{ , , , , } in (4) are set to 5, 4, 1, 0.5, and 1 empirically. Furthermore, we use a similar way as in [29] to generate the inverse deformation field \ud835\udf11 .\nIV. EXPERIMENTS AND RESULTS In this section, we first conduct extensive intra-subject registration experiments on an in-house liver DCE-CT dataset, to evaluate our proposed method and compare it with state-ofthe-art methods. In addition, we also conduct inter-subject experiments on a public LiTS dataset to further verify the robustness of our proposed method.\nA. Evaluation Metric To evaluate the registration performance, we calculate the metrics of Dice similarity coefficient (DSC), relative absolute volume difference (RAVD), average symmetric surface distance (ASSD), and maximum symmetric surface distance (MSSD) be- tween the paired liver segmentations. In general, higher DSC, smaller RAVD, smaller ASSD, and smaller MSSD of liver segmentations represent better performance of the registration method.\nSimilarly, we also calculate the metric of DSC between unpaired vessel segmentations to evaluate the overlap between arteries and veins. Note that, the smaller DSC of unpaired vessel segmentations indicates less overlap and more reasonable registration results. In addition, in order to further evaluate morphological preservation of vessels, we calculate the number of connected regions for the warped vessel segmentation to evaluate disconnection of vessels.\nB. Evaluation on In-house Liver DCE-CT Dataset 1) Dataset: The DCE-CT dataset used in this paper is inhouse data, with two-phasic (arterial phase and venous phase) 3D DCE-CT image sequence of 84 patients. Among them, the liver is segmented in both arterial and venous phases. For vessel segmentation, the arteries and veins are segmented from arterial phase and venous phases, respectively. All these segmentations are labelled by two medical imaging research fellows using an in-house voxel painting tool on the original image data. The resolution of the data is 0.70 \u00d7 0.70 \u00d7 0.87\ud835\udc5a\ud835\udc5a , and the image size is 353 \u00d7 280 \u00d7 230. In order to avoid degradation of image quality caused by resampling, we directly register the images at their original resolution. In this study, we randomly split our DCE-CT dataset into 60 and 24 subjects for training and testing, respectively.\n2) Pre-Processing: For liver DCE-CT image sequence, the intensities of corresponding blood vessels are inconsistent due to the flow of contrast agent. Therefore, a concise and effective\nimage pre-processing workflow is critical for subsequent registration. The specific pre-processing workflow is shown in Fig. 5. First, for each subject, rigid alignment of all the images (including raw DCE image and corresponding segmentations) at arterial phase with the images at venous phase are performed. Then, we mask out non-liver features (including bones, kidneys, spleen, and stomach) to make our proposed network focus on the registration of liver regions. Subsequently, the intensities are normalized to 0-1, to highlight features within the liver. Afterwards, blood vessels and other characteristics can be easily identified from the processed image (as shown in Fig. 5). However, the intensity values of corresponding blood vessels are still inconsistent at different phases, which could make the registration performance unstable. To resolve this issue, a windowed median filter with window 3 \u00d7 3 \u00d7 3 is first applied to each 3D image for noise suppression purpose. Then, the main blood vessels are enhanced using Frangi filter [30]. Note, the Frangi filer is only applied for the purpose of enhancing main vessels. After that, the enhanced blood vessels are superimposed on the filtered image, so that the corresponding vessels at different phases have similar intensity representation.\n3) Comparative Analysis: In order to comprehensively analyze the performance of the proposed method, we select 3 state-of-the-art registration methods (ANTs, NiftyReg and VoxelMorph) for comparative analysis. Among them, the deep learning-based VoxelMorph method can be used as a baseline to measure the validity of registration, and we train this model using its default parameters. In addition, two conventional registration methods (ANTs and NiftyReg) are also compared. We use Symmetric Normalization (SyN) implementation in the ANTs software package, with a mutual information (MI) similarity metric. In NiftyReg, we use B-spline based nonlinear deformation with MI as the similarity metric and the stochastic gradient descent optimizer.\nTable I lists the registration performance of various methods for the 24 testing subjects in the liver DCE-CT dataset, evaluated with paired liver segmentations and unpaired vessel segmentations. As shown in Table I, all compared methods can achieve relatively high DSC and small RAVD between paired liver segmentations. In addition, compared with other methods, the distance-based metrics, ASSD and MSSD, of our proposed methods are significantly (p < 0.05 in paired t-test) improved, which means that our proposed method exhibits better\nFig. 5. The workflow of preprocessing for liver DCE-CT dataset.\n7 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. x, 2020\nregistration accuracy for the surface of liver. On the other hand, in terms of registration accuracy for vessels, our proposed method offers significant smaller DSC between unpaired vessel segmentations, and less vessel disconnection compared with other registration methods. In addition, we also calculate the computation time for all methods, including inference time for deep learning-based method using GPU and optimization time for traditional methods using CPU. It can be seen from Table I that the deep learning-based methods have huge boost of speed. Compared with VoxelMorph, the computation time of our proposed method is slightly longer, which is due to the fact that our proposed network has 6-channel input while the VoxelMorph has 2-channel input. Fig. 6 demonstrates visualization results of one\n8 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. x, 2020\nrepresentative experiment for various registration methods. In our experiments, we select the image corresponding to arterial phase as the moving image, and the image corresponding to the venous phase as the fixed image for registration. Notice that, the moving image is with a segmentation of liver (indicated by purple in Fig. 6) and a segmentation of arterial vessel (indicated by red in Fig. 6). Correspondingly, the fixed image is with a segmentation of liver (indicated by cyan in Fig. 6) and a segmentation of vein vessel (indicated by green in Fig. 6). As illustrated in Fig. 6, the orange portion (in the second row of Fig. 6) of our proposed method is larger than other methods, which means that our proposed method has better registration performance in terms of liver region. In addition, for unpaired vessel segmentations with complex structures, our proposed method can effectively prevent the overlap between different types of vessels, and preserve the topology structure of registered vessels. For obvious areas, see the corresponding red dashed box area marked in Fig. 6.\n4) Ablation Study: We further perform ablation studies to verify individual contributions of three components in this work, including segmentation masks \ud835\udd4a (\u2112 ,\u2112 ), structure-aware constraints of liver surface \ud835\udd43 (\u2112 , \u2112 ), and structure-aware constraints of vessel centerline \ud835\udd4d (\u2112 ,\u2112 ) . Different combinations of these components used in our ablation studies are presented in Table II. For each combination, we use the same training set as described in Section IV-D, and train the networks using the same configuration.\nIt can be seen from Table II that, without the help of segmentation mask, the evaluation metrics (include DSC, RAVD, ASSD and MSSD) between paired liver segmentation degrade significantly. At the same time, there is a large overlap between arteries and veins after registration. Therefore, the registration accuracy of liver can be effectively improved by using classical DSC loss between paired liver segmentations. Furthermore, the introduction of negative DSC loss (i.e., nonoverlap loss) between different types of vessels can also effectively reduce the overlap between them. However, the non- overlap loss between arteries and veins forces vessels within the moving image to look for other similar vessels within the fixed image for alignment, resulting in severe vessel disconnection (especially for some vessels that are spatially adjacent and structurally similar).\nIn order to solve this problem and further improve the registration accuracy, we incorporate \ud835\udd43 and \ud835\udd4d in the registration network. As shown in Table II, with the help of \ud835\udd43, the registration accuracy of liver can be further improved. Additionally, by combining all components in our proposed method, the registration performance of liver and vessels are improved comprehensively. The above results validate the effectiveness of the proposed three components in the structureaware network.\nC. Evaluation on LiTS Dataset 1) Dataset: Different from DCE-CT dataset, the LiTS\ndataset contains 131 normal CT scans ( 131 \u00d7 130 image pairs) with ground-truth liver segmentations. The average resolution of the dataset is 0.80 \u00d7 0.80 \u00d7 1.45 \ud835\udc5a\ud835\udc5a , and the average image size is 512 \u00d7 512 \u00d7 448 voxels. This dataset has been randomly split into 101 (101 \u00d7 100 image pairs) and 30 scans (30 \u00d7 29 image pairs) for training and testing, respectively.\n2) Pre-Processing: For the pre-processing of the LiTS dataset, all raw scans are resampled into 180 \u00d7 160 \u00d7 78 voxels after cropping unnecessary area around the liver region. Then, we mask all the non-liver structures and normalize image intensities to 0-1. Subsequently, we use Ants-Registration to perform rigid alignment of all image pairs.\n3) Comparative Analysis: Table III lists the registration performances of various methods for the 30 testing subjects in the LiTS dataset. Since non-liver structures are masked during pre-processing, all compared methods can achieve relatively satisfactory registration performance. Specifically, compared with other registration methods, our proposed method has significantly higher DSC and lower RAVD between paired liver segmentations. Meanwhile, the ASSD and MSSD of our proposed method are also significantly smaller than other methods, indicating that our proposed structure-aware network can significantly improve registration performance.\nIn addition, registration results for the LiTS dataset can also be visually inspected in Fig. 7. Note that the color representation in Fig. 7 is similar to Fig. 6. As can be seen from Fig. 7, there is an obvious difference in the appearance of liver between moving image and fixed image. For such situation, most comparison methods (ANTs, Nifty and VoxelMorph) cannot accurately align liver regions. Compared with other registration methods, our proposed method can achieve better\n9 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. x, 2020\nregistration performance and preserve topology of the registered organs.\n4) Ablation Study: For LiTS dataset, we also conduct the ablation studies to further verify individual contributions of liver segmentation S and L in our proposed network. Table IV provides performances for different combinations of these components used in our proposed network. Similar to previous experiments, the evaluation metrics of liver is significantly improved with the help of segmentation. Further, the registration accuracy of liver, especially for the surface of liver, can be further improved by the integrating of \ud835\udd43 into registration network.\nV. DISCUSSION In liver DCE-CT image registration, intensity variations caused by the flow of contrast agents, combined with complex spatial motion induced by respiration and heart beats, limit the effectiveness of existing intensity-based registration methods. In this study, we leverage segmentation information to guide the deep learning-based registration network to solve the above problems and comprehensively improve registration performance.\nActually, the segmentation-guided registration strategy has been widely used in various registration tasks, including multimodality registration [13], [14] and infant brain registration [12]. For instance, during the development of infant brain, the gray matter and white matter tissues exhibit huge intensity differences across the MR images acquired at different ages. Such intensity differences are similar to the intensity variations of liver DCE-CT images, which bring a great challenge for intensity-based registration method. To track this problem, an effective strategy is to employ the segmentation- guided strategy to eliminate the effect of intensity variations. Although the segmentation-guided registration strategy has achieved great success, there are still some limitations to be further addresses. First of all, the existing segmentation- guided registration methods [12]\u2013[14] require paired organ segmentations for guidance, which is not always available in\nclinical practice. Furthermore, the above-mentioned registration methods [12]\u2013[14] mainly focus on volumetric registration inside the segmentations, and regularize the global deformation field in a uniform manner. These approaches ignore the inherent local structural information of organs (such as topological consistency and smoothness of organ surfaces), and cannot preserve the topology of some fine features effectively. In order to solve the above problems, we design a structureaware network by introducing hierarchical structural information to further improve registration performance. Specifically, according to different organ shapes (e.g., tubular or round shapes), we extract structural information from multiple geometrically-meaningful perspectives, and construct additional structure-aware regularization constraints based on the extracted structural information. The extracted structural information is simple-yet-effective to represent complex organ morphology. Since the constructed regularization constraints are directly imposed to the deformation field, our proposed method dose not rely on paired segmentations for guidance. Meanwhile, our designed structure-aware constraint can be regarded as a general regularization module, not limited to particular organs or tissues, can be flexibly applied to networks with various architectures.\nHowever, some limitations still exist in our work. According to the network structure of our proposed method, the number of structural-aware constraint losses depends on the number of organs to be registered. In order to ensure satisfactory registration performance of our proposed method, the weight of each loss in equation (4) need to be manually set, which will cause subjective human errors. It can be known from equations (6) and (9) that the designed structure-aware constraints with the widely-used global regularization term are constructed by derivatives of the displacement field components. Different from equation (5), our designed structure-aware constraint considers more directions. Therefore, the weight of structureaware constraint loss mainly depends on both the number of voxels within the extracted centerline or surface and the number of directions calculated. In the future, we plan to use a parameter estimation method to select appropriate weights for different losses.\nSince the structure-aware constraints are constructed according to extracted structural information, the registration performance of our proposed method still depends on the accuracy of organ segmentations. In the future research, also\n10 IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. xx, NO. x, 2020\nwithin the proposed framework, a segmentation network could be integrated to improve segmentation and registration performances simultaneously.\nVI. CONCLUSION A structure-aware deep learning framework for liver DCECT registration is proposed in this paper. The intensity variations and complex spatial motion within the liver are two major challenges in liver DCE-CT image registration. To address this problem, we leverage structural information of different organs to supervise the training of segmentationguided deep registration network. Specifically, we extract structural information from different organs, and then construct structure-aware constraints based on the extracted information. Subsequently, the structure-aware constraints are regarded as regularization term, and imposed on forward and backward deformation fields simultaneously. In this way, our proposed network can not only handle the intensity variations and preserve organ topology during registration, but also utilize unpaired organ segmentations for registration. The experimental results on the testing data indicate that the proposed method can achieve better registration accuracy compared with state-of-the-art registration methods."
        }
    ],
    "title": "Structure-aware Registration Network for Liver DCE-CT Images",
    "year": 2023
}