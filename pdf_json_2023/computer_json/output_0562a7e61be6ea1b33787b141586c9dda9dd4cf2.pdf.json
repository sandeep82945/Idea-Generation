{
    "abstractText": "1 Translational Research Center, Shanghai Yangzhi Rehabilitation Hospital (Shanghai Sunshine Rehabilitation Center), School of Electronic and Information Engineering, Tongji University, Shanghai, China, 2 Department of Neurology and Neurological Rehabilitation, Shanghai Disabled Person\u2019s Federation Key Laboratory of Intelligent Rehabilitation Assistive Devices and Technologies, Yangzhi Rehabilitation Hospital (Shanghai Sunshine Rehabilitation Center), School of Medicine, Tongji University, Shanghai, China, 3 Neurotoxin Research Center of Key Laboratory of Spine and Spinal Cord Injury Repair and Regeneration of Ministry of Education, Neurological Department of Tongji Hospital, School of Medicine, Tongji University, Shanghai, China",
    "authors": [
        {
            "affiliations": [],
            "name": "Jie Li"
        }
    ],
    "id": "SP:7150bfefce500f33c47688c1951b63da347c15e0",
    "references": [
        {
            "authors": [
                "M. Abdar",
                "F. Pourpanah",
                "S. Hussain",
                "D. Rezazadegan",
                "L. Liu",
                "M Ghavamzadeh"
            ],
            "title": "A review of uncertainty quantification in deep learning: techniques, applications and challenges",
            "venue": "Inf. Fus",
            "year": 2021
        },
        {
            "authors": [
                "K.K. Ang",
                "Z.Y. Chin",
                "H.H. Zhang",
                "C.T. Guan"
            ],
            "title": "Filter bank common spatial pattern (FBCSP) in brain-computer interface",
            "venue": "IEEE international joint conference on neural networks,",
            "year": 2008
        },
        {
            "authors": [
                "G. Bao",
                "B. Yan",
                "L. Tong",
                "J. Shu",
                "L. Wang",
                "K Yang"
            ],
            "title": "Data augmentation for EEG-based emotion recognition using generative adversarial networks",
            "year": 2021
        },
        {
            "authors": [
                "G. Blanchard",
                "B. Blankertz"
            ],
            "title": "BCI competition 2003- data set IIa: spatial patterns of self-controlled brain rhythm modulations",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2004
        },
        {
            "authors": [
                "C. Brunner",
                "R. Leeb",
                "G. M\u00fcller-Putz",
                "A. Schl\u00f6gl",
                "G. Pfurtscheller"
            ],
            "title": "BCI Competition 2008\u2013Graz data set A. Austria: Institute for Knowledge Discovery (Laboratory of Brain-Computer Interfaces)",
            "venue": "Graz University of Technology",
            "year": 2008
        },
        {
            "authors": [
                "Q. Chen",
                "Q. Wu",
                "J. Chen",
                "Q.Y. Wu",
                "A. van den Hengel",
                "M.K. Tan"
            ],
            "title": "Scripted video generation with a bottom-up generative adversarial network",
            "venue": "IEEE Trans. Image Process",
            "year": 2020
        },
        {
            "authors": [
                "L. Deng",
                "D. Yu"
            ],
            "title": "Deep learning: methods and applications",
            "venue": "Found. Trends Signal Process",
            "year": 2014
        },
        {
            "authors": [
                "J. Fan",
                "C. Sun",
                "C. Chen",
                "X. Jiang",
                "X. Liu",
                "X Zhao"
            ],
            "title": "EEG data augmentation: towards class imbalance problem in sleep staging",
            "venue": "tasks. J. Neural Eng. 17:056017",
            "year": 2020
        },
        {
            "authors": [
                "M. Hamedi",
                "S.H. Salleh",
                "A.M. Noor"
            ],
            "title": "Electroencephalographic motor imagery brain connectivity analysis for BCI: a review",
            "venue": "Neural Comput",
            "year": 2016
        },
        {
            "authors": [
                "K.G. Hartmann",
                "R.T. Schirrmeister",
                "T. Ball"
            ],
            "title": "EEG-GAN: generative adversarial networks for electroencephalograhic (EEG) brain",
            "year": 2018
        },
        {
            "authors": [
                "K.M. He",
                "X.Y. Zhang",
                "S.Q. Ren",
                "J. Sun"
            ],
            "title": "Deep residual learning for image recognition. 2016 IEEE conference on computer vision and pattern recognition",
            "year": 2016
        },
        {
            "authors": [
                "P. Herman",
                "G. Prasad",
                "T.M. McGinnity",
                "D. Coyle"
            ],
            "title": "Comparative analysis of spectral approaches to feature extraction for EEG-based motor imagery classification",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng",
            "year": 2008
        },
        {
            "authors": [
                "V.L. Ives-Deliperi",
                "J.T. Butler"
            ],
            "title": "Relationship between EEG electrode and functional cortex in the international 10 to 20 system",
            "venue": "J. Clin. Neurophysiol",
            "year": 2018
        },
        {
            "authors": [
                "A.M. Jiang",
                "J. Shang",
                "X.F. Liu",
                "Y.B. Tang",
                "H.K. Kwan",
                "Y.P. Zhu"
            ],
            "title": "Efficient CSP algorithm with Spatio-temporal filtering for motor imagery classification",
            "venue": "IEEE Trans. Neural Syst. Rehabil",
            "year": 2020
        },
        {
            "authors": [
                "J. Jin",
                "Y. Miao",
                "I. Daly",
                "C. Zuo",
                "D. Hu",
                "A. Cichocki"
            ],
            "title": "Correlation-based channel selection and regularized feature optimization for MI-based BCI",
            "venue": "Neural Netw",
            "year": 2019
        },
        {
            "authors": [
                "J.H. Kim",
                "F. Biessmann",
                "S.W. Lee"
            ],
            "title": "Decoding three-dimensional trajectory of executed and imagined arm movements from electroencephalogram signals",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng",
            "year": 2015
        },
        {
            "authors": [
                "A. Krizhevsky",
                "I. Sutskever",
                "G.E. Hinton"
            ],
            "title": "ImageNet classification with deep convolutional neural networks",
            "venue": "Commun. ACM 60,",
            "year": 2017
        },
        {
            "authors": [
                "O.Y. Kwon",
                "M.H. Lee",
                "C. Guan",
                "S.W. Lee"
            ],
            "title": "Subject-independent braincomputer interfaces based on deep convolutional neural networks",
            "venue": "IEEE Trans. Neural Netw. Learn. Syst",
            "year": 2020
        },
        {
            "authors": [
                "K. LaFleur",
                "K. Cassady",
                "A. Doud",
                "K. Shades",
                "E. Rogin",
                "B. He"
            ],
            "title": "Quadcopter control in three-dimensional space using a noninvasive motor imagery-based brain-computer interface",
            "venue": "J. Neural Eng. 10:046003",
            "year": 2013
        },
        {
            "authors": [
                "V.J. Lawhern",
                "A.J. Solon",
                "N.R. Waytowich",
                "S.M. Gordon",
                "C.P. Hung",
                "B.J. Lance"
            ],
            "title": "EEGNet: a compact convolutional neural network for EEG-based brain-computer interfaces",
            "venue": "J. Neural Eng. 15:056013",
            "year": 2018
        },
        {
            "authors": [
                "Y. LeCun",
                "K. Kavukcuoglu",
                "C. Farabet"
            ],
            "title": "Convolutional networks and applications in vision",
            "venue": "IEEE international symposium on circuits and systems,",
            "year": 2010
        },
        {
            "authors": [
                "S. Lemm",
                "B. Blankertz",
                "G. Curio",
                "K.R. Muller"
            ],
            "title": "Spatio-spectral filters for improving the classification of single trial EEG",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2005
        },
        {
            "authors": [
                "M.Y. Liu",
                "X. Huang",
                "J.H. Yu",
                "T.C. Wang",
                "A. Mallya"
            ],
            "title": "Generative adversarial networks for image and video synthesis: algorithms and applications",
            "venue": "Proc. IEEE",
            "year": 2021
        },
        {
            "authors": [
                "Y.L. Liu",
                "W.B. Su",
                "Z.J. Li",
                "G.M. Shi",
                "X.L. Chu",
                "Y Kang"
            ],
            "title": "Motorimagery-based teleoperation of a dual-arm robot performing manipulation tasks",
            "venue": "IEEE Trans. Cogn. Dev. Syst",
            "year": 2019
        },
        {
            "authors": [
                "F. Lotte",
                "C. Guan"
            ],
            "title": "Regularizing common spatial patterns to improve BCI designs: unified theory and new algorithms",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 2010
        },
        {
            "authors": [
                "Y. Luo",
                "L.Z. Zhu",
                "Z.Y. Wan",
                "B.L. Lu"
            ],
            "title": "Data augmentation for enhancing EEG-based emotion recognition with deep generative models",
            "venue": "J. Neural Eng. 17:056021",
            "year": 2020
        },
        {
            "authors": [
                "Y. Miao",
                "F. Yin",
                "C. Zuo",
                "X. Wang",
                "J. Jin"
            ],
            "title": "Improved RCSP and AdaBoostbased classification for motor-imagery BCI, 2019 IEEE international conference on computational intelligence and virtual environments for measurement systems and applications (CIVEMSA)",
            "year": 2019
        },
        {
            "authors": [
                "A.B. Nassif",
                "I. Shahin",
                "I. Attili",
                "M. Azzeh",
                "K. Shaalan"
            ],
            "title": "Speech recognition using deep neural networks: a systematic review",
            "venue": "IEEE Access",
            "year": 2019
        },
        {
            "authors": [
                "C. Neuper",
                "G.R. Muller-Putz",
                "R. Scherer",
                "G. Pfurtscheller"
            ],
            "title": "Motor imagery and EEG-based control of spelling devices and neuroprostheses",
            "venue": "Prog Brain Res",
            "year": 2006
        },
        {
            "authors": [
                "Q. Novi",
                "C. Guan",
                "T.H. Dat",
                "P. Xue"
            ],
            "title": "Sub-band common spatial pattern (SBCSP) for brain-computer interface",
            "venue": "3rd international IEEE/EMBS conference on neural engineering, Kohala Coast, HI,",
            "year": 2007
        },
        {
            "authors": [
                "G. Pfurtscheller",
                "C. Brunner",
                "A. Schlogl",
                "F.H.L. da Silva"
            ],
            "title": "Mu rhythm (de)synchronization and EEG single-trial classification of different motor imagery",
            "venue": "tasks. Neuroimage",
            "year": 2006
        },
        {
            "authors": [
                "G. Pfurtscheller",
                "C. Neuper"
            ],
            "title": "Motor imagery and direct brain-computer communication",
            "venue": "Proc. IEEE 89,",
            "year": 2001
        },
        {
            "authors": [
                "H. Ramoser",
                "J. Muller-Gerking",
                "G. Pfurtscheller"
            ],
            "title": "Optimal spatial filtering of single trial EEG during imagined hand movement",
            "venue": "IEEE Trans. Rehabil. Eng",
            "year": 2000
        },
        {
            "authors": [
                "S. Roy",
                "S. Dora",
                "K. McCreadie",
                "G. Prasad"
            ],
            "title": "MIEEG-GAN: generating artificial motor imagery electroencephalography signals. 2020 international joint conference on neural networks (Glasgow, UK: IJCNN)",
            "year": 2020
        },
        {
            "authors": [
                "D. Saxena",
                "J. Cao"
            ],
            "title": "Generative adversarial networks (GANs) challenges, solutions, and future directions",
            "venue": "ACM Comput. Surv",
            "year": 2021
        },
        {
            "authors": [
                "R.T. Schirrmeister",
                "J.T. Springenberg",
                "L.D.J. Fiederer",
                "M. Glasstetter",
                "K. Eggensperger",
                "M Tangermann"
            ],
            "title": "Deep learning with convolutional neural networks for EEG decoding and visualization",
            "venue": "Hum. Brain Mapp",
            "year": 2017
        },
        {
            "authors": [
                "J. Schmidhuber"
            ],
            "title": "Deep learning in neural networks: an overview",
            "venue": "Neural Netw",
            "year": 2015
        },
        {
            "authors": [
                "K. Simonyan",
                "A. Zisserman"
            ],
            "title": "Very deep convolutional networks for largescale image recognition",
            "venue": "arXiv Preprint arXiv:1409.1556",
            "year": 2014
        },
        {
            "authors": [
                "Y. Song",
                "L. Yang",
                "X. Jia",
                "L. Xie"
            ],
            "title": "Common spatial generative adversarial networks based EEG data augmentation for cross-subject brain-computer interface",
            "venue": "arXiv Preprint arXiv:2102.04456",
            "year": 2021
        },
        {
            "authors": [
                "H.I. Suk",
                "S.W. Lee"
            ],
            "title": "A novel Bayesian framework for discriminative feature extraction in brain-computer interfaces",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "year": 2013
        },
        {
            "authors": [
                "Y.R. Tabar",
                "U. Halici"
            ],
            "title": "A novel deep learning approach for classification of EEG motor imagery signals",
            "venue": "J. Neural Eng. 14:016003",
            "year": 2017
        },
        {
            "authors": [
                "R. Tibshirani"
            ],
            "title": "Regression shrinkage and selection via the lasso",
            "venue": "J. R. Stat. Soc",
            "year": 1996
        },
        {
            "authors": [
                "L. van der Maaten",
                "G. Hinton"
            ],
            "title": "Visualizing Data using t-SNE",
            "venue": "J. Mach. Learn. Res",
            "year": 2008
        },
        {
            "authors": [
                "A. Voulodimos",
                "N. Doulamis",
                "A. Doulamis",
                "E. Protopapadakis"
            ],
            "title": "Deep learning for computer vision: a brief review",
            "venue": "Comput. Intell. Neurosci",
            "year": 2018
        },
        {
            "authors": [
                "Y. Wang",
                "F. Bremond",
                "A. Dantcheva"
            ],
            "title": "Inmodegan: interpretable motion decomposition generative adversarial network for video generation",
            "venue": "arXiv Preprint arXiv:2101.03049",
            "year": 2021
        },
        {
            "authors": [
                "F. Xu",
                "G. Dong",
                "J. Li",
                "Q. Yang",
                "L. Wang",
                "Y Zhao"
            ],
            "title": "Deep convolution generative adversarial network-based electroencephalogram data augmentation for post-stroke rehabilitation with motor imagery",
            "venue": "Int. J. Neural Syst. 32:2250039",
            "year": 2022
        },
        {
            "authors": [
                "L. Yang",
                "Y. Song",
                "K. Ma",
                "L. Xie"
            ],
            "title": "Motor imagery EEG decoding method based on a discriminative feature learning strategy",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng",
            "year": 2021
        },
        {
            "authors": [
                "X. Yang",
                "Z.H. Wang",
                "J.Y. Zhao",
                "D. Yang"
            ],
            "title": "FG-GAN: a fine-grained generative adversarial network for unsupervised SAR-to-optical image translation",
            "venue": "IEEE Trans. Geosci. Remote Sens",
            "year": 2022
        },
        {
            "authors": [
                "J. Yang",
                "S.W. Yao",
                "J. Wang"
            ],
            "title": "Deep fusion feature learning network for MI-EEG classification",
            "venue": "IEEE Access",
            "year": 2018
        },
        {
            "authors": [
                "R. Zhang",
                "Y.Q. Li",
                "Y.Y. Yan",
                "H. Zhang",
                "S.Y. Wu",
                "Yu",
                "T. Y"
            ],
            "title": "Control of a wheelchair in an indoor environment based on a brain-computer Interface and automated navigation",
            "venue": "IEEE Trans. Neural Syst. Rehabil. Eng",
            "year": 2016
        },
        {
            "authors": [
                "Q. Zhang",
                "Y. Liu"
            ],
            "title": "Improving brain computer interface performance by data augmentation with conditional deep convolutional generative adversarial networks",
            "venue": "arXiv Preprint arXiv:1806.07108",
            "year": 2018
        },
        {
            "authors": [
                "D. Zhang",
                "L. Yao",
                "K. Chen",
                "J. Monaghan"
            ],
            "title": "A convolutional recurrent attention model for subject-independent EEG signal analysis",
            "venue": "IEEE Signal Process. Lett",
            "year": 2019
        },
        {
            "authors": [
                "X. Zhang",
                "L.N. Yao",
                "D.L. Zhang",
                "X.Z. Wang",
                "Q.Z. Sheng",
                "T. Gu"
            ],
            "title": "Multiperson brain activity recognition via comprehensive EEG signal analysis. Proceedings of the 14th EAI international conference on mobile and ubiquitous systems: computing, networking and services (Mobiquitous 2017)",
            "venue": "Association for Computing Machinery",
            "year": 2017
        },
        {
            "authors": [
                "Z.Q. Zheng",
                "Z.B. Yu",
                "Y. Wu",
                "H.Y. Zheng",
                "B. Zheng",
                "M. Lee"
            ],
            "title": "Generative adversarial network with multi-branch discriminator for imbalanced cross-species image-to-image translation",
            "venue": "Neural Netw",
            "year": 2021
        },
        {
            "authors": [
                "H. Zou",
                "T. Hastie"
            ],
            "title": "Regularization and variable selection via the elastic net",
            "venue": "J. R. Stat. Soc",
            "year": 2005
        }
    ],
    "sections": [
        {
            "text": "Frontiers in Neuroscience 01 frontiersin.org\nSubject-independent EEG classification based on a hybrid neural network Hao\u00a0Zhang 1, Hongfei\u00a0Ji 1*, Jian\u00a0Yu 1*, Jie\u00a0Li 1*, Lingjing\u00a0Jin 2,3, Lingyu\u00a0Liu 2, Zhongfei\u00a0Bai 2 and Chen\u00a0Ye 1\n1 Translational Research Center, Shanghai Yangzhi Rehabilitation Hospital (Shanghai Sunshine Rehabilitation Center), School of Electronic and Information Engineering, Tongji University, Shanghai, China, 2 Department of Neurology and Neurological Rehabilitation, Shanghai Disabled Person\u2019s Federation Key Laboratory of Intelligent Rehabilitation Assistive Devices and Technologies, Yangzhi Rehabilitation Hospital (Shanghai Sunshine Rehabilitation Center), School of Medicine, Tongji University, Shanghai, China, 3 Neurotoxin Research Center of Key Laboratory of Spine and Spinal Cord Injury Repair and Regeneration of Ministry of Education, Neurological Department of Tongji Hospital, School of Medicine, Tongji University, Shanghai, China\nA brain-computer interface (BCI) based on the electroencephalograph (EEG) signal is a novel technology that provides a direct pathway between human brain and outside world. For a traditional subject-dependent BCI system, a calibration procedure is required to collect sufficient data to build a subjectspecific adaptation model, which can be\u00a0 a huge challenge for stroke patients. In contrast, subject-independent BCI which can shorten or even eliminate the pre-calibration is more time-saving and meets the requirements of new users for quick access to the BCI. In this paper, we\u00a0design a novel fusion neural network EEG classification framework that uses a specially designed generative adversarial network (GAN), called a filter bank GAN (FBGAN), to acquire high-quality EEG data for augmentation and a proposed discriminative feature network for motor imagery (MI) task recognition. Specifically, multiple sub-bands of MI EEG are first filtered using a filter bank approach, then sparse common spatial pattern (CSP) features are extracted from multiple bands of filtered EEG data, which constrains the GAN to maintain more spatial features of the EEG signal, and finally we\u00a0design a convolutional recurrent network classification method with discriminative features (CRNN-DF) to recognize MI tasks based on the idea of feature enhancement. The hybrid neural network proposed in this study achieves an average classification accuracy of 72.74 \u00b1 10.44% (mean \u00b1 std) in four-class tasks of BCI IV-2a, which is 4.77% higher than the state-of-the-art subject-independent classification method. A promising approach is provided to facilitate the practical application of BCI.\nKEYWORDS\nelectroencephalograph (EEG), motor imagery (MI), subject-independent, braincomputer interface, generative adversarial networks (GAN)\n1. Introduction\nBrain-computer interface (BCI) provides an advanced approach that enables users to communicate with external devices (Pfurtscheller and Neuper, 2001). BCIs have shown great potential in many clinical applications, such as controlling assistive robots (Liu et\u00a0al., 2019) or wheelchairs (Zhang et\u00a0al., 2016) to help move, drink, and provide stroke rehabilitation, or communicating with others by spelling (Neuper et\u00a0 al., 2006). A variety of physiological"
        },
        {
            "heading": "OPEN ACCESS",
            "text": ""
        },
        {
            "heading": "EDITED BY",
            "text": ""
        },
        {
            "heading": "Biswanath Samanta, Georgia Southern University, United\u00a0States",
            "text": ""
        },
        {
            "heading": "REVIEWED BY",
            "text": "Ann-Kathrin Beck, University of Kaiserslautern, Germany Yilin Dong, Shanghai Maritime University, China Grace Mary Kanaga E, Karunya Institute of Technology and Sciences, India\n*CORRESPONDENCE Jie Li nijanice@163.com Hongfei Ji jhf@tongji.edu.cn Jian Yu yujian@tongji.edu.cn\nRECEIVED 19 December 2022 ACCEPTED 11 May 2023 PUBLISHED 02 June 2023"
        },
        {
            "heading": "CITATION",
            "text": ""
        },
        {
            "heading": "Zhang H, Ji H, Yu J, Li J, Jin L, Liu L, Bai Z and",
            "text": ""
        },
        {
            "heading": "Ye C (2023) Subject-independent EEG classification based on a hybrid neural network.",
            "text": "Front. Neurosci. 17:1124089. doi: 10.3389/fnins.2023.1124089"
        },
        {
            "heading": "COPYRIGHT",
            "text": "\u00a9 2023 Zhang, Ji, Yu, Li, Jin, Liu, Bai and Ye. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.\nTYPE Methods PUBLISHED 02 June 2023 DOI 10.3389/fnins.2023.1124089\nFrontiers in Neuroscience 02 frontiersin.org\ninformation is employed in the BCI systems, and growing attention has been paid to the analysis of electroencephalography (EEG) signals, especially motor imagery (MI), which is one of the most popular paradigms (Pfurtscheller and Neuper, 2001; LaFleur et\u00a0al., 2013; Kim et\u00a0al., 2015; Hamedi et\u00a0al., 2016) due to its portable and cost-effective acquisition system as well as zero clinical risks.\nFor the past few years, there have been outstanding outcomes in EEG-based classification of MI tasks (Herman et\u00a0al., 2008; Suk and Lee, 2013; Tabar and Halici, 2017; Jiang et\u00a0al., 2020). However, most of the current advanced works concentrate on subject-dependent scenario, where data from the same group of subjects is used for training and testing (Zhang et\u00a0al., 2019). Under the circumstances, a calibration procedure is indispensable to collect sufficient data to build a subject-specific adaptation model employed by a new user, which is time-consuming and labor-intensive. And collecting sufficient data for adaptation can be\u00a0a huge challenge for stroke patients. Hence, it is imperative to explore the subject-independent scenario for the scalability and usability of BCIs. Due to the high variability and instability of the EEG signals, data from diverse subjects are different, or even at different times on the same session for the same subject. This poses a significant challenge for subject-independent researches.\nMost of the conventional MI-based BCIs are exploited from subjectspecific approaches, which demand calibration time. One of the most widespread approaches in MI-based BCIs, testified by 2003 BCI competition (Blanchard and Blankertz, 2004), is known as common spatial patterns (CSPs) (Ramoser et\u00a0al., 2000), which can maximize the variance of one class and minimize the variance of the other for the binary classes. Based on CSP methods, many advanced algorithms have been developed. For example, Lemm et\u00a0al. (2005) proposed common spatio-spectral pattern (CSSP), which is developed from the CSP method with embedding time delay to extract robust features. In research (Novi et\u00a0al., 2007), the sub-band common spatial pattern (SBCSP) is proposed to avoid a time-consuming fine-tuning process by applying the CSP algorithm to different sub-bands decomposing the original EEG signal by using a filter bank. Ang et\u00a0 al. (2008) proposed another multiple sub-band input method that is termed the filter bank common spatial pattern (FBCSP), which applies a characteristic picking algorithm to automatically selected discriminative CSP features of different sub-bands. In order to find the optimal filter bank to obtain the discriminative features, Suk and Lee (2013) proposed the Bayesian spatio-spectral filter optimization (BSSFO) that constructs a data-driven discriminative filter bank and bandwidth picking to optimize spatio-spectral filter within a Bayesian framework. Although the efficiency of CSP algorithms is well known and widely used, CSPs are also considered to be\u00a0very sensitive to noise and prone to overfitting. Improved regularized CSPs have also been proposed recently. Lotte and Guan (2010) proposed CSP with Tikhonov regularization and weighted Tikhonov regularization and demonstrated its advanced performance by comparing them with various RCSP algorithms. Miao et\u00a0al. (2019) proposed a novel RCSP method to optimize feature extraction and perform MI-BCI classification using the AdaBoost algorithm. A novel regularized common spatial pattern (RCSP) method was also utilized in Jin et\u00a0al. (2019) to extract effective features to improve the classification accuracy of the MI task. However, these approaches have focused on constructing a pattern classifier to decode the brain patterns specific to the subjects and a calibration procedure is still required to train the decoder.\nIn recent years, deep learning techniques have attracted significant attention for their success in computer vision, natural language\nprocessing (LeCun et\u00a0al., 2010; Schmidhuber, 2015; Voulodimos et\u00a0al., 2018; Nassif et\u00a0al., 2019). Researchers have proposed a few end-to-end deep learning frameworks for subject-independent EEG classification based on MI. Yang et\u00a0al. (2018) proposed a framework that combines a long short-term memory network (LSTM) with a convolutional neural network (CNN) to simultaneously learn spatial information and capture temporal dynamics from the raw MI-EEG signals, which was employed in subject-independent MI decoders. To further explore the temporal correlation of an MI-EEG sequence, a recurrent-attention networks combined with CNN is developed to focus on most discriminative features in research (Zhang et\u00a0al., 2019). In research, Kwon et\u00a0al. (2020) proposed a framework for spectral-spatial feature representation based on deep CNN, which concatenates and fuses spectral-spatial features of discriminative frequency bands by applying spatial fusion technique, and validated the effectiveness on a self-built large MI database. These proposed methods demonstrate the potential of deep learning frameworks for subject-independent EEG classification, but the improvement in subject-independent EEG classification performance is limited due to shortcomings in discriminative feature extraction or dataset size. Due to the powerful feature learning capabilities of deep learning, separable features can be\u00a0effectively obtained by deep learning approaches with multi-layer nonlinear information processing (LeCun et\u00a0al., 2010; Deng and Yu, 2014).\nHowever, the performance of deep learning models depends heavily on the scale of the dataset (Abdar et\u00a0al., 2021). For target subjects, especially stroke patients, collecting sufficient EEG data for adaptive training is a huge challenge. Many researchers have conducted studies of cross-subject EEG classification problems using EEG expansion data collected from other subjects, which has been effective to some extent; however, due to the non-stationary nature of the EEG signal, there are significant individual differences caused by different physiological characteristics. Therefore, the method of data enhancement via EEG from other subjects is limited. On the other hand, the EEG signal has a low signal-to-noise ratio and is susceptible to interference from noise such as impedance and muscle artifacts. When subjects are inattentive during the experiment, they are easily involved in a large amount of irrelevant information. Hence, acquiring sufficient data for adaptation training and extracting effective discriminative features from the low signal-to-noise ratio EEG signal are two major issues affecting subject-independent classification.\nWith an emphasis on data generation, generative models offer a potential solution to the problem of data deficiency. In particular, GAN has been very successful in computer vision fields, such as image translation (Zheng et\u00a0al., 2021; Yang et\u00a0al., 2022) and video generation (Chen et\u00a0al., 2020; Liu et\u00a0al., 2021; Wang et\u00a0al., 2021), etc., due to its excellent artificial image generation capabilities (Saxena and Cao, 2021). However, since EEG is a multi-channel time series signal and is susceptible to interference, a few studies have reported the utilization of GAN for EEG feature or raw data enhancement. Luo et\u00a0 al. (2020) performed enhancement of the power spectral density and differential entropy of EEG signals using a conditional Wasserstein GAN to aid in emotion recognition. In research (Zhang and Liu, 2018), Zhang et\u00a0al. employed a conditional deep convolution GAN following a wavelet transform to augment the feature data. In addition to generating EEG features, researchers have also attempted to generate unwashed EEG signals for a wider purpose. Hartmann et\u00a0al. (2018) proposed an EEG-GAN to produce single-channel EEG signals with very well-examined visuals. Roy\nFrontiers in Neuroscience 03 frontiersin.org\net\u00a0 al. (2020) used long short-term memory networks in the generator and discriminator and acquired MI EEG signals which have the same characteristics of dynamic and time-frequency as the raw signals. These studies confirm the potential of GAN in generating MI EEG signals, but few studies have used GAN for subject-independent classification due to the high variability and individual differences in EEG signals.\nIn this paper, we\u00a0 propose a novel hybrid neural network framework based on data augmentation and feature enhancement for subject-independent EEG classification, which first employs filter bank GAN (FBGAN) for data augmentation and obtains high-quality data by adversarial training of generators and discriminators. Specifically, MI EEG are filtered using a filter bank approach, and then sparse CSP features extracted from the multiple sub-bands of filtered EEG data are used as part of the discriminator to maintain more spatial features. Meanwhile, we\u00a0propose a convolutional recurrent network with discriminative features (CRNN-DF) based on the idea of feature enhancement to extract distinguishable features from EEG signals with low signal-to-noise ratio to identify MI tasks. Furthermore, we\u00a0have evaluated and analyzed the proposed hybrid neural network from different perspectives and the results show that it offers a promising approach for the study of cross-subject EEG classification problems and for facilitating the practical application of BCI systems. The major innovations and contributions of this work can be\u00a0summarized as follows: (1) We\u00a0applied a filter bank approach to extract sparse CSP features from multiple candidate bands. (2) The extracted sparse features were used as part of a discriminator in the proposed FBGAN to inherit more detailed features from the target subjects. (3) We\u00a0also developed a CRNN-DF classifier based on the idea of feature enhancement to better distinguish MI tasks using extracted discriminative features. (4) Our hybrid neural network framework improves subject-independent EEG classification performance to a conspicuous level through data augmentation and feature enhancement, which helps improve the usability of the BCI system for new users.\nThe remainder of this paper is organized as follows: Part 2 discusses the methodology of the study. In Part 3, we\u00a0describe in detail the experiments and results. Details of the experimental analysis are discussed in Part 4. Finally, Part 5 concludes this article."
        },
        {
            "heading": "2. Methodology",
            "text": "In practical applications of BCI, good classification results cannot be\u00a0obtained with subject-independent data only, while calibration with target subject EEG signals requires too much data and it is difficult to extract effective discriminative features from the low signal-to-noise ratio and susceptible to interference EEG signal. In this context, we\u00a0 propose a novel fusion feature network, the general framework of which is shown in Figure\u00a01. First, a filter bank method is used to perform multiple sub-band filtering on the subject-specific EEG data, and each sub-band data is processed to obtain CSP features and spatial filters. Then, lasso regression is used to extract sparse CSP features from the spatial of all frequency bands and acquire the corresponding spatial filters. The sparse spatial features and corresponding spatial filters are then used as constraints for FBGAN for data augmentation. Finally, the augmented data of the target subject is introduced into the subject-independent data for adaptive\ntraining, which is applied to the training set of the proposed CRNN-DF."
        },
        {
            "heading": "2.1. Data description",
            "text": "The BCI competition IV dataset 2a (Brunner et\u00a0al., 2008) from Graz University of Technology is applied to verify our approach. The dataset contains EEG signals collected from two sessions of 9 healthy subjects on different days, recording the subjects performing 4 different MI tasks: the movements of left hand, right hand, both feet and tongue, where each session is comprised 6 runs separated by short breaks. One run consists of 48 trials (12 for each of the four classes), yielding a total of 288 trials per session. Two seconds after the start of a trial\uff0ca cue corresponding to one of the four classes appeared and stayed on the screen for 1.25 s. The subjects were asked to perform the MI task until the prompt message disappeared from the screen at t = 6 s. EEG data were captured by 22 electrodes and sampled at 250 Hz, and then bandpass filtered between 0.5 Hz and 100 Hz. An added 50 Hz notch filter is employed to dampen line noise. In this paper, we\u00a0represent the samples from each trial as a 2-D matrix XT\nC , where C is the number of EEG channels and T denotes the sampling points of the EEG data."
        },
        {
            "heading": "2.2. Preprocessing",
            "text": "In the raw data, \u201cNaN\u201d was replaced with the average of all sample points. A fifth-order Butterworth bandpass filter from 1 to 38\u00a0Hz was applied first to filter out components unrelated to the MI rhythm. The z-score standardization was used to reduce the instability and volatility of the EEG signal, which can be\u00a0expressed as\n\u2032 = \u2212X X \u00b5\n\u03c3 2 (1)\nwhere X and \u2032X represent the input filtered data and the standardized EEG signal, respectively. \u221d and \u03c3 2 denote the mean and variance that were calculated by using the training set. Then, the normalized EEG signals were divided into 10 frequency bands (as shown in Figure\u00a02): 1\u20134 Hz, 4\u20138 Hz, 8\u201312 Hz, 12\u201316 Hz, 16\u201320 Hz, 20\u201324 Hz, 24\u201328 Hz, 28\u201332 Hz, 32\u201335 Hz and 35\u201338 Hz. Finally, a 4-s slice from the start of the cue for each trial was used as a sample."
        },
        {
            "heading": "2.3. Feature extraction",
            "text": "CSP is a feature extraction method that is widely used in MI\u2019s BCI and has achieved great success in binary classification problems. It does this by optimizing a set of spatial filters to maximize the variance of one class and minimize that of the other. Since we\u00a0are faced with a multi-classification task, we\u00a0employ a modified one-versus-rest (OVR) strategy to overcome the drawbacks of traditional spatial filters. OVR refers to transforming multiple classification problems into multiple binary problems, consisting of one class and the remaining classes. We\u00a0divide samples of the entire task into 10 sub-bands and compute a sample\nFrontiers in Neuroscience 04 frontiersin.org\ncovariance matrix for each of the four bifurcations in each band. The average spatial covariance matrix can be\u00a0calculated as\nR N\nX X\ntr X X c\nc i\nN i c i c T\ni c i c T\nc\n= ( )=\u2211\n1\n1\n, ,\n, ,\n(2)\nwhere Rc denotes the mean spatial covariance matrix of class c, Nc is the number of trials of class c, Xi c, is the i-th trial in class c, and tr ( ) is used to compute the trace of a matrix.\nAccording to Ramoser et\u00a0 al. (2000), we\u00a0 can compute the eigenvector w corresponding to the eigenvalue \u03bb by solving the generalized eigenvalue problem R w R wc c= \u03bb , where Rc is the average spatial covariance matrix of the other class. Then, we\u00a0get a spatial filter for the binary categories in each sub-band. Since there are four classes for the whole task, four sub-filters are obtained for each sub-band. In order to reduce the computational complexity, we\u00a0remain the four\ncolumns corresponding to the four largest eigenvalues in each sub-filter. Thus, there are a total of 4 sub-filters \u00d7 4 eigenvectors.\nW w w wcsp fr m= \u2026[ ]1 2 4, , , (3)\nwhere Wcspfr represents the spatial filter obtained from the sub-band fr, and m is the number of eigenvectors retained by the sub-filter in each band. The final spatial filter is then obtained by stacking the sub-filters in each band, with a total of 10 sub-bands \u00d7 16 eigenvectors."
        },
        {
            "heading": "2.4. Feature selection",
            "text": "By applying CSP to the filtered signal in each sub-band according to the OVR strategy, we\u00a0can derive the following feature set\nFIGURE\u00a01 An overview of the hybrid neural network for subject-independent EEG classification.\nFIGURE\u00a02 The structural flow of EEG signals processing by the filter bank method. The obtained spatial filters correspond to the sparse CSP features selected by LASSO.\nFrontiers in Neuroscience 05 frontiersin.org\nF f f\nf f\nD\nN N D\n= \n\n  \n\n\n  \n11 1\n1\n, ,\n, ,\n(4)\nwhere fi j, denotes the j -th feature extracted from the filtered EEG signals for the i-th trial, and D m= \u00d74 10 is the dimensionality of the feature set. The least absolute shrinkage and selection operator (LASSO) is a penalized least squares method that imposes an L1 penalty on the regression coefficients (Tibshirani, 1996; Zou and Hastie, 2005), which can not only accurately select important variables, but also have the stability of feature selection. LASSO estimation can be\u00a0formulated as\nargmin ,\u03b2 \u03b2 \u03b2 \u03b2 \u03bb \u03b2\n0\n1\n2 1\n0\n2\n1 N y f i\nN i i T\nj\nD j\n= = \u2211 \u2211\u2212 \u2212( ) +\n   \n   \n(5)\nwhere yi denotes the class label of the i-th trial, fi is the D-dimensional feature vector of the i-th trial, \u03bb is a positive regularization parameter, \u03b2 is a D-dimensional regression parameter and is a vector, and \u03b20 is a scalar. The features corresponding to a coefficient of 0\u00a0in the LASSO are automatically discarded. Thus, the most important features are selected from multiple frequency bands. We\u00a0 save the spatial filter Wcsp corresponding to the most important features (as shown in Figure\u00a02), which can be\u00a0used as\nZ W Xcsp T= \u2032 (6)\nwhere Z is the sample processed by the sparse spatial filter Wcsp."
        },
        {
            "heading": "2.5. FBGAN",
            "text": "In order to inherit more detailed features from the target subject\u2019s EEG signals and prepare sufficient data for adaptive training, we\u00a0propose FBGAN in the hybrid neural network framework. To the best of our knowledge, it is the first time that the idea of FBCSP has been incorporated into a GAN. Specifically, the MI EEG signals are first filtered in multiple sub-bands, then sparse CSP features are extracted from multiple bands of filtered EEG data, which are used to constrain the GAN to maintain more spatial features of the EEG signal. The architecture of FBGAN is shown in Figure\u00a03. Distinct from the conventional GAN, it includes a generator and two discriminators, and a dedicated discriminator D\u03c8 is innovatively introduced to distinguish the sparse CSP features extracted from the real EEG data and fake EEG data.\nGAN consists of a generator (G), which learns from random noise to generate artificial data, and a discriminator (D), which is used to distinguish artificial data from real data. This can be\u00a0regarded as a game between G and D. When the game reaches equilibrium, G generates artificial data with a similar distribution to the real data (Goodfellow et\u00a0al., 2014).\nIn our framework, the generator is used to generate fake EEG signals with similar distribution to the real EEG. A randomly initialized normally distributed noise (1 1600\u00d7 ) to the generator, whose detailed network\nstructure is shown in Table\u00a01, with a fully connected layer FC followed by 5 transposed convolutional layers (ConvTrans ). Batch normalization was used to normalize the first four ConvTrans layers. The activation function is LeakyReLU .\nInspired by the study (Song et\u00a0al., 2021), the discriminator part was specially designed in order to make the generated data inherit the spatial features of the original EEG. The general approach is to distinguish the original data from the generated fake data by a discriminator D\u03d5 . In our method, in order to preserve more details of the target subjects, we\u00a0 introduce a sparse spatial filter obtained through the feature selection phase to filter the real data and generated data, as in Equation (6). Then, the obtained real and fake filter bank data (FB data) is fed into another discriminator D\u03c8 . The network structure of the discriminator is shown in Table\u00a02, where Conv denotes the convolutional layer, FC denotes the fully connected layer, and Maxpool is the maximum pooling layer. Since each target subject\u2019s EEG has its own specificity, we\u00a0use an adaptive approach to extract sparse spatial filters using LASSO, rather than extracting a fixed number of filters. Thus, kernel size Var in the third convolution layer of the D\u03c8 adaptively varies according to the dimensionality of the extracted sparse CSP features."
        },
        {
            "heading": "2.6. Classifier",
            "text": "The EEG samples with the shape C T\u00d7 are fed into the convolutional module, which conventionally requires a local filter to extract local features from a 2-D matrix. Common local filters for image and video processing are reasonable and successful, such as VGG (Simonyan and Zisserman, 2014), ResNet (He et\u00a0al., 2016), or AlexNet (Krizhevsky et\u00a0 al., 2017), however, which cannot perform well on raw EEG data. Since EEG signals exhibit diverse characteristics from image and videos, they possess spatial features in one dimension representing the electrode channels and temporal dynamic features in another dimension denoting the time series. Besides, The EEG signals from different electrode channels reflect the functions of different brain regions in the MI task, and there is an intimate relationship between different electrode channels (Ives-Deliperi and Butler, 2018). Therefore, as shown in Figure\u00a04, we\u00a0apply a convolutional module to extract the spatial features between different electrode channels. The unique convolutional layer in this module has a convolutional kernel size of C \u00d7 45 and a step size of 1, which can explore the spatial correlation between different electrode channels in the MI tasks. The sample points that are fed into it are encoded as a higher-level representation. Then, a max-pooling layer, which has a kernel size of 1 75\u00d7 and a step size of 10, is added to reduce the feature dimensionality and the number of parameters. The LSTM module is then employed to explore the temporal dynamics of the features between the different time points. The module consists of two recurrent layers, where the hidden state of each layer is 64. To mitigate overfitting of the classifier during training, the dropout of all network layers is set to 0.5. The detailed structural parameters are shown in Figure\u00a0 5. Finally, the extraction part of discriminative feature is utilized to improve the discriminativeness of features from different subjects\u2019 EEG data, which is essential for improving the accuracy of the classification of subject-independent EEG signals, which is described in the next subsection.\nFrontiers in Neuroscience 06 frontiersin.org"
        },
        {
            "heading": "2.7. Extraction of discriminative features",
            "text": "In general, the target function consisting of classification loss is used to guide training of models in classification tasks; however, the features extracted by models trained in this way are usually separable rather than discriminable. CSP maximizes the variance of one category while minimizing the variance of other category to obtain the most discriminative feature vector, which has achieved great success in the two-classification tasks. Inspired by this, we\u00a0introduce a novel discriminative feature approach (Yang et\u00a0al., 2021) into our model for subject-independent EEG data classification, which narrows the intraclass diversity and expands the inter-class distance to make the extracted features more discriminative. The brief steps of the method are described as follows.\nFirst, a center vector is computed for the feature vectors of each category in a batch of samples, which can be\u00a0employed to calculate the central distance loss Lcen . In the training process, the intra-class distance is reduced by narrowing the distance between the feature\nvector of each sample and the corresponding center vector in order to centralize the feature distribution of each class.\nL b v cencen\ni\nb k\ny k i = \u2212 = \u22111 1 2 i\n(7)\nWhere vik represents the characteristic vector corresponding to the i \u2212 th sample within the k \u2212 th iteration, b represents a batch number during training, yi indicates the class tag for the i \u2212 th sample, and ceny k i denotes the centroid of class yi within the k \u2212 th iteration, which will be\u00a0initialized with the class center vector of all training samples prior to training, and the initialization process is calculated as follows:\ncen y j v\ny j j\ni B\ni i\ni B\ni\n0 1\n0\n1 1\n= =( )\n+ =( ) =\n=\n\u2211 \u2211 \u03b4 \u03b4\n\u00b7\n(8)\nFIGURE\u00a03 The framework of FBGAN, including a generator and two discriminator modules. Discriminator D\u03d5 distinguishes between real EEG and generated EEG, and discriminator D\u03c8 is used to distinguish whether the filter bank (FB) data filtered by the sparse spatial filters is real or fake.\nTABLE\u00a01 The detailed network structure of the generator G\u03b8 .\nLayers Input Output Kernel Stride Normalization\nFC 1,600 256,000 \u2013 \u2013 \u2013\nConvTrans1 128 128 (3, 15) (1, 3) BatchNorm\nConvTrans2 128 128 (3, 15) (1, 3) BatchNorm\nConvTrans3 128 64 (3, 5) (1, 2) BatchNorm\nConvTrans4 64 32 (4, 5) (2, 1) BatchNorm\nConvTrans5 32 1 (1, 2) (1, 1) \u2013\nFrontiers in Neuroscience 07 frontiersin.org\nWhere cen j0 denotes the initialized center vector of the class for the label j , B denotes the number of samples in the entire training set, vi0 denotes the initial feature vector of the i \u2212 th sample, and \u03b4 y j if y j if y ji i i =( ) = \u2260 =    0 1 , , is utilized to identity whether the samples in the training set belong to a specific class. Then, the feature vectors of samples are more discriminative by expanding the distance between the center vectors of different classes. The process of increasing the distance of the class center vectors is to first calculate the center v\nC cenc\nk j k j C= =\u2211 1 1 (C is the number of categories),\nand then to enlarge the distance between the center vectors and the center, calculated as\ncen cen v cen\nv cen j k j k c\nk j k\nc k j k\n+ = +1 \u03b1\u00b7\n(\u03b1 is the step size of the move).\nFinally, the joint supervised training with central distance loss and classification loss is used to guide the optimization of the network parameters of the whole framework. The complete objective loss function is Loss\nb y y Li i ceni\nb = \u2212 +\u2032 ( )=\u2211 1 1 log \u00b7\u03bb , where\nyi and yi\u2032 denote the true class label and the predicted label corresponding to the i \u2212 th sample in a batch, respectively, and \u03bb represents the proportion of central distance loss within the entire loss function."
        },
        {
            "heading": "3. Experiments and results",
            "text": ""
        },
        {
            "heading": "3.1. Experiment settings",
            "text": "In Brunner et\u00a0al. (2008), 288 trials from the first session of the same subject are utilized as the training set and 288 trials from the second session are applied for testing. However, for the cross-subject scene, we\u00a0 apply the leave-one-subject-out (LOSO) approach for\nsubject-independent classification of EEG signals, which employs data from eight subjects for training and those from the remaining one subject for evaluation.\nFor BCI competition IV dataset 2a, the method randomly shuffles the EEG data of 4,608 trials (8 subjects \u00d7 2 sessions \u00d7 288 trials) of 8 subjects as the training set, and 576 trials from the remaining 1 subject as the test set to evaluate the classifier performance, and then we\u00a0introduce generated fake samples to expand the training dataset to validate the proposed hybrid neural network framework validity, in which we\u00a0take the 22 channels \u00d7 1,000 time points of each trial as a sample. Samples from the same subject do not appear in both the training set and test sets at the same time.\nThe entire neural network structure was implemented by the Tensorflow framework on the Quadro GTX 5000 platform. In FBGAN, an Adam optimizer with a learning rate of 0.0001 was used. The network parameters were updated after a batch size of 5. In classifier, the learning rate and batch size are fixed at 0.0001 and 32, respectively. In addition, the stride of the centric vector transfer for each epoch is 0.02, the central vector is updated every 15 epochs, and the hyperparameter \u03bb of the centric loss in the overall target function is selected experimentally. As shown in Figure\u00a06, when \u03bb is 0, the classifier is equivalent to CRNN without the introduction of discriminative features strategy. And when \u03bb is slightly larger and the value is 0.01, the classification accuracy has a significant improvement. It can be\u00a0seen in the figure that the recognition rate of the MI EEG tasks is the highest when \u03bb is determined to be\u00a00.1."
        },
        {
            "heading": "3.2. Evaluation of the generated data",
            "text": "In order to evaluate the effectiveness of FBGAN for data enhancement, we\u00a0compared generated signals with original signals of the target subject in terms of time, frequency and spatial\nTABLE\u00a02 The detailed network structure of the discriminator D\u03d5 and D\u03c8 .\nDiscriminator Layers Input Output Kernel Stride Activation layer\nD\u00c6\nConv1 1 10 (1, 23) (1, 1) LeakyReLU\nConv2 10 30 (22, 1) (1, 1) LeakyReLU\nConv3 30 30 (1, 17) (1, 1) LeakyReLU\nMaxpool \u2013 \u2013 (1, 6) (1, 6) \u2013\nConv4 30 30 (1, 7) (1, 7) LeakyReLU\nMaxpool \u2013 \u2013 (1, 6) (1, 6) \u2013\nFC 750 1 \u2013 \u2013 \u2013\nD\u00c8\nConv1 1 10 (1, 23) (1, 1) LeakyReLU\nConv2 10 30 (4, 1) (4, 1) LeakyReLU\nConv3 30 30 (Var , 1) (1, 1) LeakyReLU\nConv4 30 30 (1, 17) (1, 1) LeakyReLU\nMaxpool \u2013 \u2013 (1, 6) (1, 6) \u2013\nConv5 30 30 (1, 7) (1, 1) LeakyReLU\nMaxpool \u2013 \u2013 (1, 6) (1, 6) \u2013\nFC 750 1 \u2013 \u2013 \u2013\nFrontiers in Neuroscience 08 frontiersin.org\ndomain. As the FBGAN model was parallel for each class of each subject, the training simples and generated simples for subject 9 imagining left-handed movements were averaged separated for visualization.\nFirstly, the three main channels C3, Cz, and C4 of the MI region were chosen to compare the original signals and generated signals in the time domain (Pfurtscheller et\u00a0al., 2006). As shown in Figure\u00a07A, we\u00a0represent the original data in lime and the generated data in steel blue on the same axis. It can be\u00a0seen that the generated signals are similar to the real signals in time distribution, and the average and range are quite close.\nSecondly, the 22 channels of real and fake samples signals are average to show the power spectrum density by drawing the spectrograms. Figure\u00a07B plots the spectrogram with 1\u201338 Hz as the pre-processing. It can be\u00a0noticed that generated data displays higher power where the original data power is higher, especially in the range 1\u201330 Hz. Since the filtered sub-bands are selected by LASSO during\nthe pre-processing stage, the selected feature band will be\u00a0paid special attention to the generated model.\nThirdly, the heat map is employed to observe the details of generated data in terms of spatial distribution and to assess quality. The normalized covariance matrix of the original and generated data is plotted in the heat map, as shown in Figure\u00a07C As the covariance matrix reflects the relationship between the data rows, it can be\u00a0seen from the heat map that the relationship between adjacent electrode channels is well retained, which indicates that generated signals are spatially consistent with original signals."
        },
        {
            "heading": "3.3. Classification performance",
            "text": "To verify the effectiveness of the proposed subject-independent classification method CRNN-DF, we\u00a0 conducted a number of experiments on the BCI competition IV 2a dataset and compared them\nFIGURE\u00a05 The detailed network architecture of the proposed framework for the classification of subject-independent EEG data.\nFIGURE\u00a04 An overview of the CRNN-DF for subject-independent EEG classification.\nFrontiers in Neuroscience 09 frontiersin.org\nin detail with other advanced methods based on the same dataset, respectively. There are significant individual discrepancies in the EEG signals of different subjects due to their unique physiological structure and psychological state. To adequately validate our method, we\u00a0trained a model for each subject with LOSO approach to ensure that dataset used for training and testing were from different subjects, respectively.\nFIGURE\u00a06 The classification accuracy of cross-subject MI EEG with different values of hyperparameter \u03bb.\nFIGURE\u00a07 (A) Comparison of the C3, Cz, and C4 channels of the original signals and generated signals in the time domain. The original signals are marked by lime and the generated signals are marked by steel blue. (B) Comparison of the spectrograms of the original signals and generated signals after the 22 channels data have been averaged. The vertical axis indicates the frequency in Hz, and colorbar is in dB. (C) Heat map which compares the covariance matrix of the raw real data and the generated data illustrates the correlation between the electrode channels. Each small block denotes the covariance between the two electrodes.\nFrontiers in Neuroscience 10 frontiersin.org\nTable\u00a0 3 presents subject-independent MI EEG decoding accuracies and their average accuracies from subject A1 to subject A9. In this table, we\u00a0compared with competitive approaches on the BCI competition IV 2a dataset, including EEGNet (Lawhern et\u00a0al., 2018), CTCNN (Schirrmeister et\u00a0al., 2017), AE XGboost (Zhang et\u00a0al., 2017), FBCSP (Ang et\u00a0al., 2008), and CRAM (Zhang et\u00a0al., 2019). From the table, we\u00a0can observe that our classifier has higher average accuracy than the comparative approaches when tested on all subjects separately. Furthermore, the proposed method achieved the maximum average precision on the 2a dataset."
        },
        {
            "heading": "3.4. Comparison of feature distributions",
            "text": "To further demonstrate the validity of the classification method at the subject-independent EEG feature level, we\u00a0output feature vectors of typical subjects in 2a dataset. All these vectors are then converted to the two-dimensional plane via TSNE (van der Maaten and Hinton,\n2008). As can be\u00a0 seen in Figures\u00a0 8, 9, the sample features of the subjects are distributed chaotically in the feature space before the processing with the discriminative feature method, and the feature vectors of the different MI tasks are not sufficiently distinguishable. The comparison indicates that our method allows the similar sample features from different subjects to converge to the same area of the characteristic space, and the sample characteristic from diverse categories to become sufficiently discriminative in the feature space, which can help us achieve higher classification accuracy."
        },
        {
            "heading": "3.5. Data augmentation for subject-independent classification",
            "text": "After confirming the effectiveness of the designed subjectindependent classifier CRNN-DF, we\u00a0 tried to introduce fake data generated for the target subjects in the training set to better help the classifier perceive subject-specific features and separate the four MI\nTABLE\u00a03 Comparison of the subject-independent EEG decoding accuracy (%) with the present advanced classification approaches on the BCI competition IV 2a dataset and A1\u2013A9 denotes nine different subjects.\nComparision method\nTest subject (the remaining subjects used as training) Mean Std\nA1 A2 A3 A4 A5 A6 A7 A8 A9\nEEGNet 53.76 39.54 54.88 43.02 51.80 48.96 60.70 61.38 47.82 51.32 6.94\nCTCNN 55.90 26.04 70.66 45.49 33.16 35.42 40.97 61.29 60.07 47.67 14.20\nAE XGboost 32.12 32.34 32.29 32.99 33.85 32.47 39.06 30.90 32.64 33.18 2.20\nFBCSP 47.92 24.83 39.24 39.93 27.26 31.60 27.08 46.70 36.68 35.69 8.04\nCRAM 61.02 42.35 73.11 50.43 50.74 51.48 67.26 69.72 66.85 59.22 10.13\nCRNN-DF 65.51 45.18 78.62 53.58 55.64 56.03 71.28 75.02 70.78 63.52 10.70\nFIGURE\u00a08 The separative features of typical subjects from the BCI competition IV 2a dataset that are acquired by the proposed convolutional recurrent networks framework, mapped to the two-dimensional plane via TSNE.\nFrontiers in Neuroscience 11 frontiersin.org\ncategories. The classification results after introducing different numbers of fake data for augmentation are shown in Table\u00a04. Since there are four categories in the MI task, the number of samples in each one is one-fourth of the total number of samples introduced. It can be\u00a0seen from the table that when only 500 generated fake samples are introduced, the average classification accuracy is greatly improved. As the number of fake samples increases, the accuracy rate has improved to varying degrees. However, for subjects A4 and A8, the accuracy at the introduction of 3,000 samples was lower than that at the introduction of 2000 samples, which may be\u00a0due to the addition of other irrelevant information along with the target subject features when introducing the generated fake samples. Excessive augmented samples may cause the noise to dispel the effect of the valid information. Therefore, for each target subject, we\u00a0introduced 3,000 generated fake samples, that is, 750 samples per category in our framework.\nFigure\u00a010 presents the comparison of our proposed hybrid neural network framework with the current state-of-the-art subject-independent classification approach. It can be\u00a0seen from the table that our proposed framework obtains the best classification accuracy. As shown in Table\u00a03,\nthe CRNN-DF classification method designed in this paper obtained satisfactory recognition results with LOSO strategy and without the introduction of augmented data. Then, we\u00a0further introduced 3,000 fake samples for target subjects, which led to a huge improvement in the results of the four MI classification tasks. It is due to the combination of OVR and CSP in the pre-processing stage of the hybrid framework, which maximized the variance of one class while minimizing the variance of the other, expanding the difference between one and other categories. In addition, the introduction of augmented data from target subjects and the discriminative feature strategy employed in the classification phase played an important role in improving the distinguishability of the different classes."
        },
        {
            "heading": "4. Discussion",
            "text": "The brain patterns of different subjects performing the same MI tasks usually have individual differences, and these differences always interfere with the subject-independent MI EEG decoding process, which has long\nFIGURE\u00a09 The discriminative features of typical subjects from the BCI competition IV 2a dataset that are acquired by the proposed CRNN-DF, mapped to the two-dimensional plane via TSNE.\nTABLE\u00a04 The classification accuracy (%) from subject A1 to subject A9 for different numbers of augmentation samples, where Naug denotes the number of fake samples introduced in the training set and A1\u2013A9 denotes nine different subjects.\nNaug A1 A2 A3 A4 A5 A6 A7 A8 A9 Mean Std\n0 65.51 45.18 78.62 53.58 55.64 56.03 71.28 75.02 70.78 63.52 10.70\n500 74.01 48.78 80.97 60.51 64.40 57.56 74.45 80.07 76.04 68.53 10.55\n1,000 77.32 48.69 81.55 61.64 66.69 58.00 77.10 80.12 78.01 69.90 10.97\n2000 77.95 50.37 81.94 63.74 67.35 57.03 79.30 83.88 80.24 71.31 11.42\n3,000 79.60 54.25 83.84 60.93 70.54 62.18 79.94 82.01 81.36 72.82 10.44\n4,000 79.60 51.94 85.87 65.24 68.34 61.31 78.39 83.48 81.17 72.82 10.94\nFrontiers in Neuroscience 12 frontiersin.org\nrestricted the application of EEG-based BCI. In this study, we\u00a0proposed a subject-independent hybrid neural network framework to solve the crosssubject classification problem for MI tasks. To overcome the effects of large individual differences, low signal-to-noise ratio, and difficulty in collection in EEG data, we\u00a0designed FBGAN to generate EEG samples for data augmentation, and designed CRNN-DF to extract effective discriminative features based on the idea of feature augmentation.\nIn the article, the BCI Competition dataset 2a was employed to evaluate the method performance. As shown in Table\u00a03, the CRNN-DF achieved advanced classification performance with LOSO strategy for each subject and obtained the highest average classification accuracy. This is because the use of the discriminative feature strategy makes the features vectors of the same category sample more compact in the feature space and ones of samples of different classes more dispersive as shown in Figures\u00a08, 9, which improved the resolution of brain patterns across MI tasks and improved generalization to different subject\u2019 brain patterns. To enable the classifier to better perceive subject-specific features, we\u00a0introduced fake EEG samples of target subjects generated by FBGAN into the training set. As can be\u00a0seen in Table\u00a04, the average classification accuracy was greatly improved after 500 generated fake samples were introduced. As the number of introduced fake samples increased, the performance of the classifier improved to varying degrees. We\u00a0also compared FBGAN with some other powerful augmentation methods, such as adding Gaussian Noise, Segmentation and Recombination (S&R) (Fan et\u00a0 al., 2020), Variational Auto-Encoder (VAE) (Bao et\u00a0al., 2021), Deep Convolutional GAN (DCGAN) (Xu et\u00a0al., 2022), and Common Spatial GAN (CSGAN) (Song et\u00a0al., 2021), as shown in Figure\u00a0 10. The superiority of the proposed method is further demonstrated by the ablation experiments of discriminative feature strategy and FBGAN in hybrid neural networks. Furthermore, as shown in Figure\u00a07, we\u00a0have analyzed and compared the details of the data generated by FBGAN with the original data in three dimensions: time domain, frequency domain, and spatial domain, which confirms that the generated signals are indeed of sufficient quality.\nHowever, our method still has some limitations. Firstly, as can be\u00a0seen from Table\u00a03, although the decoding accuracy of our method is the highest on BCI Competition IV dataset 2a, the standard deviation\nis also relatively large and the stability is not yet good enough. The main reason is that EEG signals vary greatly from subject to subject. Although our method is able to overcome the differences in brain patterns between subjects to some extent, it is not yet well adapted to subjects with large variability. But this problem was alleviated after introducing more generated data from the target subjects due to the enhanced adaptability of the target subjects. Secondly, the introduction of augmented data did significantly improve the classification results for cross-subject MI tasks, but in fact, it can be\u00a0seen from Table\u00a04 that the quality of the signals generated by FBGAN was not always perfect. For example, the classification results for subject A4 introducing 3,000 samples were worse than those introducing 2000 samples, which is due to the fact that the input noise is high and somewhat random, and the generated signals has certain fluctuations. The balance between the amount of input noise and the diversity of the generated data deserves more research. Thirdly, as the FBGAN model is parallel to each category of each subject, which increases the computational cost."
        },
        {
            "heading": "5. Conclusion",
            "text": "In this paper, we\u00a0 present a novel hybrid neural network for subject-independent EEG signal classification. The framework uses a specially designed FBGAN to obtain high-quality EEG data for augmentation. Based on the idea of feature enhancement, the CRNN-DF is designed to recognize MI tasks, which introduces a discriminative feature strategy to expand the inter-class feature differences and narrow the intra-class feature distances. This improves the recognition rate of different subject brain patterns by enhancing the distinguishability between different classes of samples. The experimental results indicated that our method significantly outperforms previous subject-independent methods and can overcome the differences in brain patterns across subjects to some extent. In conclusion, the approach is expected to pave the way for the practical implementation of subject-independent BCI systems, alleviating the mutual interference between different subject brain patterns and improving the accuracy of the EEG decoding process.\nFIGURE\u00a010 The average classification accuracy of subject A1 to subject A9 compared to advanced augmentation methods, where CRNN-DF is the proposed classifier and no augmented data were used.\nFrontiers in Neuroscience 13 frontiersin.org"
        },
        {
            "heading": "Data availability statement",
            "text": "Publicly available datasets were analyzed in this study. This data can be\u00a0found here: https://www.bbci.de/competition/iv/."
        },
        {
            "heading": "Author contributions",
            "text": "HZ carried out experiment and writing. HJ, JY, and JL designed the overall framework. LJ, LL, ZB, and CY carried out methodological guidance and formal analysis. All authors contributed to the article and approved the submitted version."
        },
        {
            "heading": "Funding",
            "text": "This work was supported by the Shanghai Municipal Science and Technology Major Project (2021SHZDZX0100), the Fundamental Research Funds for the Central Universities, the Science and Technology Innovation Action Plan of the Shanghai Science and\nTechnology Commission (19441908000), and Program of Shanghai Academic Research Leader (20XD1403400)."
        },
        {
            "heading": "Conflict of interest",
            "text": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be\u00a0construed as a potential conflict of interest."
        },
        {
            "heading": "Publisher\u2019s note",
            "text": "All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher."
        }
    ],
    "title": "Subject-independent EEG classification based on a hybrid neural network",
    "year": 2023
}