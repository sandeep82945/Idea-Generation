{
    "abstractText": "We present a \u00d5(m \u221a \u03c4+n\u03c4) time algorithm for finding a minimum-cost flow in graphs with n vertices and m edges, given a tree decomposition of width \u03c4 and polynomially bounded integer costs and capacities. This improves upon the current best algorithms for general linear programs bounded by treewidth which run in \u00d5(m\u03c4 ) time by [DLY21, GS22], where \u03c9 \u2248 2.37 is the matrix multiplication exponent. Our approach leverages recent advances in structured linear program solvers and robust interior point methods. As a corollary, for any graph G with n vertices and m edges, we obtain a \u00d5(tw \u00b7m) time algorithm to compute a tree decomposition of G with width O(tw \u00b7 log(n)). \u2217 sallyqd@uw.edu. University of Washington. \u2020 ghye@mit.edu. MIT. Supported by NSF awards CCF-1955217 and DMS-2022448.",
    "authors": [
        {
            "affiliations": [],
            "name": "Sally Dong"
        },
        {
            "affiliations": [],
            "name": "Guanghao Ye"
        }
    ],
    "id": "SP:04ce1808bc49e2ceb9003da5f20165ddbf4236ae",
    "references": [
        {
            "authors": [
                "Stefan Arnborg",
                "Derek G Corneil",
                "Andrzej Proskurowski"
            ],
            "title": "Complexity of finding embeddings in a k-tree",
            "venue": "SIAM Journal on Algebraic Discrete Methods,",
            "year": 1987
        },
        {
            "authors": [
                "Sanjeev Arora",
                "Satyen Kale"
            ],
            "title": "A combinatorial, primal-dual approach to semidefinite programs",
            "venue": "Journal of the ACM (JACM),",
            "year": 2016
        },
        {
            "authors": [
                "Per Austrin",
                "Toniann Pitassi",
                "Yu Wu"
            ],
            "title": "Inapproximability of treewidth, one-shot pebbling, and related layout problems",
            "venue": "In International Workshop on Approximation Algorithms for Combinatorial Optimization (APPROX),",
            "year": 2012
        },
        {
            "authors": [
                "Hans L Bodlaender",
                "P\u00e5l Gr\u01ffn\u00e5s Drange",
                "Markus S Dregi",
                "Fedor V Fomin",
                "Daniel Lokshtanov",
                "Micha\u0142 Pilipczuk"
            ],
            "title": "A ckn 5-approximation algorithm for treewidth",
            "venue": "SIAM Journal on Computing,",
            "year": 2016
        },
        {
            "authors": [
                "Hans L Bodlaender",
                "John R Gilbert",
                "Hj\u00e1lmtyr Hafsteinsson",
                "Ton Kloks"
            ],
            "title": "Approximating treewidth, pathwidth, frontsize, and shortest elimination tree",
            "venue": "Journal of Algorithms,",
            "year": 1995
        },
        {
            "authors": [
                "Jan van den Band",
                "Yu Gao",
                "Arun Jambulapati",
                "Yin Tat Lee",
                "Yang P. Liu",
                "Richard Peng",
                "Aaron Sidford"
            ],
            "title": "Faster maxflow via improved dynamic spectral vertex sparsifiers",
            "venue": "CoRR, abs/2112.00722,",
            "year": 2021
        },
        {
            "authors": [
                "Aaron Bernstein",
                "Maximilian Probst Gutenberg",
                "Thatchaphol Saranurak"
            ],
            "title": "Deterministic decremental sssp and approximate min-cost flow in almost-linear time",
            "venue": "IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS),",
            "year": 2021
        },
        {
            "authors": [
                "Jan van den Brand",
                "Yin Tat Lee",
                "Yang P Liu",
                "Thatchaphol Saranurak",
                "Aaron Sidford",
                "Zhao Song",
                "Di Wang"
            ],
            "title": "Minimum cost flows, MDPs, and l1-regression in nearly linear time for dense instances",
            "venue": "In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing,",
            "year": 2021
        },
        {
            "authors": [
                "Jan van den Brand"
            ],
            "title": "A deterministic linear program solver in current matrix multiplication time",
            "venue": "In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms,",
            "year": 2020
        },
        {
            "authors": [
                "Sebastian Brandt",
                "Roger Wattenhofer"
            ],
            "title": "Approximating small balanced vertex separators in almost linear time",
            "venue": "Algorithmica, 81:4070\u20134097,",
            "year": 2019
        },
        {
            "authors": [
                "Li Chen",
                "Rasmus Kyng",
                "Yang P Liu",
                "Richard Peng",
                "Maximilian Probst Gutenberg",
                "Sushant Sachdeva"
            ],
            "title": "Maximum flow and minimum-cost flow in almost-linear time",
            "venue": "IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS),",
            "year": 2022
        },
        {
            "authors": [
                "Michael B Cohen",
                "Yin Tat Lee",
                "Zhao Song"
            ],
            "title": "Solving linear programs in the current matrix multiplication time",
            "venue": "Journal of the ACM (JACM),",
            "year": 2021
        },
        {
            "authors": [
                "Timothy A Davis"
            ],
            "title": "Direct methods for sparse linear systems",
            "year": 2006
        },
        {
            "authors": [
                "Sally Dong",
                "Yu Gao",
                "Gramoz Goranci",
                "Yin Tat Lee",
                "Richard Peng",
                "Sushant Sachdeva",
                "Guanghao Ye"
            ],
            "title": "Nested dissection meets ipms: Planar min-cost flow in nearly-linear time",
            "venue": "In Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),",
            "year": 2022
        },
        {
            "authors": [
                "David Durfee",
                "Rasmus Kyng",
                "John Peebles",
                "Anup B. Rao",
                "Sushant Sachdeva"
            ],
            "title": "Sampling random spanning trees faster than matrix multiplication",
            "venue": "In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing,",
            "year": 2017
        },
        {
            "authors": [
                "Sally Dong",
                "Yin Tat Lee",
                "Guanghao Ye"
            ],
            "title": "A nearly-linear time algorithm for linear programs with small treewidth: A multiscale representation of robust central path",
            "venue": "In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing,",
            "year": 2021
        },
        {
            "authors": [
                "David Eppstein",
                "Zvi Galil",
                "Giuseppe F Italiano",
                "Thomas H Spencer"
            ],
            "title": "Separator based sparsification: I. planarity testing and minimum spanning trees. journal of computer and system sciences",
            "year": 1996
        },
        {
            "authors": [
                "Uriel Feige",
                "MohammadTaghi Hajiaghayi",
                "James R Lee"
            ],
            "title": "Improved approximation algorithms for minimum weight vertex separators",
            "venue": "SIAM Journal on Computing,",
            "year": 2008
        },
        {
            "authors": [
                "Fedor V Fomin",
                "Daniel Lokshtanov",
                "Saket Saurabh",
                "Micha\u0142 Pilipczuk",
                "Marcin Wrochna"
            ],
            "title": "Fully polynomial-time parameterized computations for graphs and matrices of low treewidth",
            "venue": "ACM Transactions on Algorithms (TALG),",
            "year": 2018
        },
        {
            "authors": [
                "Yu Gao",
                "Yang P. Liu",
                "Richard Peng"
            ],
            "title": "Fully dynamic electrical flows: Sparse maxflow faster than Goldberg-Rao",
            "venue": "In 62st IEEE Annual Symposium on Foundations of Computer Science,",
            "year": 2021
        },
        {
            "authors": [
                "Yuzhou Gu",
                "Zhao Song"
            ],
            "title": "A faster small treewidth SDP solver",
            "venue": "arXiv preprint arXiv:2211.06033,",
            "year": 2022
        },
        {
            "authors": [
                "Monika R Henzinger",
                "Philip Klein",
                "Satish Rao",
                "Sairam Subramanian"
            ],
            "title": "Faster shortest-path algorithms for planar graphs",
            "venue": "Journal of Computer and System Sciences,",
            "year": 1997
        },
        {
            "authors": [
                "Arun Jambulapati",
                "Aaron Sidford"
            ],
            "title": "Ultrasparse ultrasparsifiers and faster laplacian system solvers",
            "venue": "Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms,",
            "year": 2021
        },
        {
            "authors": [
                "N. Karmarkar"
            ],
            "title": "A new polynomial-time algorithm for linear programming",
            "year": 1984
        },
        {
            "authors": [
                "Tom Leighton",
                "Satish Rao"
            ],
            "title": "Multicommodity max-flow min-cut theorems and their use in designing approximation algorithms",
            "venue": "Journal of the ACM (JACM),",
            "year": 1999
        },
        {
            "authors": [
                "Richard J Lipton",
                "Donald J Rose",
                "Robert Endre Tarjan"
            ],
            "title": "Generalized nested dissection",
            "venue": "SIAM journal on numerical analysis,",
            "year": 1979
        },
        {
            "authors": [
                "James Renegar"
            ],
            "title": "A polynomial-time algorithm, based on Newton\u2019s method, for linear programming",
            "venue": "Mathematical programming,",
            "year": 1988
        },
        {
            "authors": [
                "Daniel A Spielman",
                "Shang-Hua Teng"
            ],
            "title": "Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems",
            "venue": "In Proceedings of the thirty-sixth annual ACM symposium on Theory of computing,",
            "year": 2004
        },
        {
            "authors": [
                "Richard Y Zhang",
                "Javad Lavaei"
            ],
            "title": "Sparse semidefinite programs with near-linear time complexity",
            "venue": "IEEE Conference on Decision and Control (CDC),",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 8.\n14 72\n7v 1\n[ cs\n.D S]\n2 8\nA ug\nWe present a O\u0303(m \u221a \u03c4+n\u03c4) time algorithm for finding a minimum-cost flow in graphs with n vertices and m edges, given a tree decomposition of width \u03c4 and polynomially bounded integer costs and capacities. This improves upon the current best algorithms for general linear programs bounded by treewidth which run in O\u0303(m\u03c4 (\u03c9+1)/2) time by [DLY21, GS22], where \u03c9 \u2248 2.37 is the matrix multiplication exponent. Our approach leverages recent advances in structured linear program solvers and robust interior point methods.\nAs a corollary, for any graph G with n vertices and m edges, we obtain a O\u0303(tw3 \u00b7m) time algorithm to compute a tree decomposition of G with width O(tw \u00b7 log(n)).\n\u2217 sallyqd@uw.edu. University of Washington. \u2020 ghye@mit.edu. MIT. Supported by NSF awards CCF-1955217 and DMS-2022448.\nContents\n1 Introduction 3\n2 Overview 4\n3 Robust interior point method 5\n4 Nested dissection on bounded treewidth graphs 7\n4.1 Separator tree for bounded treewidth graph . . . . . . . . . . . . . . . . . . . . . . . 7 4.2 Nested dissection using a separator tree . . . . . . . . . . . . . . . . . . . . . . . . . 8\n5 Solution maintenance 10\n6 Proof of main theorems 11\n1 Introduction\nAn active area of research in recent years is the advancement of interior point methods (IPM) for linear and convex programs, with its origins tracing back to the works of [Kar84, Ren88]. This, along with the design of problem-specific data structures supporting the IPM, this had led to breakthroughs in faster general linear program solvers [CLS21] and faster max flow algorithms [LS14, BLL+21, GLP21, BGJ+21, CKL+22], among others.\nOne line of research, inspired by nested dissection from [LRT79] and methods in numerical linear algebra [Dav06], focuses on exploiting any separable structure in the constraint matrix of the linear program, which can be characterized by first associated a graph with the matrix. Given a graph G = (V,E) on n vertices, we say S \u2286 V is a balanced vertex separator if there exists some constant b \u2208 (0, 1) such that every connected component of G\\S has size1 at most b \u00b7n. More specifically, we say S is a b-balanced separator. We say G is f(n)-separable if any subgraph H of G has a balanced separator of size f(|V (H)|). The treewidth of a graph informally measures how close a graph is to a tree, and is closely related to separability. If G has treewidth \u03c4 , then any subgraph of G has a 1/2-balanced separator of size \u03c4 + 1; conversely, if G is \u03c4 -separable, then G has treewidth at most \u03c4 log n (c.f. [BGHK95]). By leveraging properties of separable graphs, the sequence of three papers [DLY21, DGG+22, DGL+23] have iteratively refined the robust IPM framework and associated data structures for solving structured linear programs.\n[DLY21] gave the first general linear program solver parametrized by treewidth: Given an LP of the form min{c\u22a4x : Ax = b,x \u2265 0} and a width \u03c4 decomposition of the dual graph2 GA of the constraint matrix A, suppose the feasible region has inner radius r and outer radius R, and the costs are polynomially bounded. Then the LP can be solved to \u03b5-accuracy in O\u0303(m\u03c42 log(R/(\u03b5r)) time. The \u03c42 factor arises from carefully analyzing the sparsity-pattern of the Cholesky factorization of AA\n\u22a4 and the associated matrix computation times. This run-time dependence on \u03c4 was improved from quadratic to (\u03c9+1)/2 \u2248 3.37/2 = 1.68 in [GS22], by means of a coordinate-batching technique applied to the updates during the IPM. [GS22] further combined [DLY21] with [ZL18] to give the current best algorithm for semi-definite programs with bounded treewidth.\nThe LP solver from [DLY21] is now subsumed by [DGL+23], which shows that under the same setup, except where GA is known to be a \u03ban\n\u03b1-separable graph3 the LP can be solved in O\u0303 (( \u03ba2(m+m2\u03b1+0.5) +m\u03ba(\u03c9\u22121)/(1\u2212\u03b1) + \u03ba\u03c9n\u03b1\u03c9 ) \u00b7 log(mR\u03b5r ) ) time. Taking \u03ba = \u03c4 and \u03b1 = 0 for bounded treewidth graphs recovers the [DLY21] result. For n\u03b1-separable graphs, the run-time expression simplifies to O\u0303 ( (m+m1/2+2\u03b1) log(mR\u03b5r ) ) .\nIn the special setting of flow problems, whereby the constraint matrix A is the vertex-edge incidence matrix of a graph and AA\u22a4 is its Laplacian, fast Laplacian solvers [ST04, JS21] and approximate Schur complements [DKP+17] can be combined with the separable structure of the graph to speed up the matrix computations further at every IPM step. Using these ideas, [DGG+22] gave a nearly-linear time min-cost flow algorithm for planar graphs, which are O( \u221a n)-separable.\nIn this work, we expand the landscape with an improved result for min-cost flow problems on bounded treewidth graphs. Previously, [FLS+18] showed how to compute a max vertex-disjoint flow in O(\u03c42 \u00b7 n log n) time given a directed graph with unit capacities and its tree decomposition of width \u03c4 ; their approach is combinatorial in nature.\n1An alternative weighted definition is sometimes used: For any weighting of the vertices, the connected components of G \\ S each has weight at most b \u00b7W , where W is the total weight.\n2The dual graph of a matrix A \u2208 Rn\u00d7m is a graph on n vertices, where each column of A gives rise to a clique (or equivalently, a hyper-edge). Importantly, when the linear program is a flow problem on a graph, GA is precisely the graph in the original problem.\n3Here, \u03ba is a constant expression, but could be a function of the size of GA (which is considered fixed).\nTheorem 1.1 (Main result). Let G = (V,E) be a directed graph with n vertices and m edges. Assume that the demands d, edge capacities u and costs c are all integers and bounded by M in absolute value. Given a tree decomposition of G with width \u03c4 and size S \u2264 n\u03c4 , there is an algorithm that computes a minimum-cost flow in O\u0303(m \u221a \u03c4 logM + S) expected time4.\nAs a direct corollary of Theorem 1.1, we can solve min-cost flow on any graph with n vertices, m edges and integral polynomially-bounded costs and constraints in O\u0303(m \u221a n) expected time, as the treewidth of any n-vertex graph is at most \u03c4 = n, and the tree decomposition is trivially the graph itself. This result matches that of [LS14] (later improved to O\u0303(m + n1.5) by [BLL+21]) obtained using the Lee-Sidford barrier for the IPM, which requires O\u0303( \u221a n) iterations. In contrast, we use the standard log barrier which requires O\u0303( \u221a m) iterations, and leverage the robustness of the IPM and custom data structures to reduce the amortized cost per iteration. Using our faster max-flow algorithm as a subroutine, we can efficiently compute a tree decomposition of any given graph, where the width is within a O(log n)-factor of the optimal:\nCorollary 1.2 (Approximating treewidth). Let G = (V,E) be a graph with n vertices and m edges. There is an algorithm to find a tree decomposition of G with width at most O(tw(G) \u00b7 log n) in O\u0303(tw(G)3 \u00b7m) expected time.\nIt is well known that computing the treewidth of a graph is NP-hard [ACP87] and there is conditional hardness result for even constant-factor approximation algorithm [APW12]. For polynomial time algorithms, the best known result is a O( \u221a log tw)-approximation algorithm by [FHL08].\nThere is a series of works focused on computing approximate treewidth for small treewidth graph in near-linear time, we refer the readers to [BDD+16] for a more detailed survey. Notably, [FLS+18] showed for any graph G, there is an algorithm to compute a tree decomposition of width O(tw(G)2) in O\u0303(tw(G)7 \u00b7n) time. [BW19] improved the running time to O\u0303(tw(G)3 \u00b7m) with slightly compromised approximation ratio O(tw(G)2 \u00b7 log1+o(1) n). More recently, [BGS22] showed how to compute a tree decomposition of width O(tw(G) \u00b7 log3 n) in O(m1+o(1)) time.\n2 Overview\nThe foundation of our algorithm is the planar min-cost flow algorithm from [DGG+22]. We begin with the identical robust IPM algorithm in abstraction, as given in Algorithm 1. [DGG+22] first defines a separator tree T for the input graph, and uses it as the basis for the data structures in the IPM. We modify the separator tree construction, so that instead of recursively decomposing the input planar graph which is O( \u221a n)-separable, we recursively decompose the \u03c4 -separable bounded treewidth graph. The leaf nodes of T partition the edges of the input graph; We guarantee that each leaf node contains O(\u03c4)-many edges, compared to constantly-many in the planar case.\nThere are two main components to the data structures from [DGG+22]:\n1. A data structure DynamicSC (Theorem 4.7) is used to maintain an approximate Laplacian and an approximate Schur complement matrix at every node of of the separator tree T , corresponding to the Laplacian of the subgraph represented by the node, and its Schur complement onto the boundary vertices. This data structure implicitly represents the matrix (B\u22a4WB)\u22121, where W are edge weights changing at every step of the IPM. We use DynamicSC in exactly the same way.\n4Throughout the paper, we use O\u0303(\u00b7) to hide polylog m and polylog M factors.\n2. A data structure MaintainSoln (Theorem 5.1) using T which implicitly maintains the primal and dual solutions f and s at the current IPM iteration, and explicitly maintains approximate solutions f and s at the current IPM iteration. The approximate solutions are used in the subsequent iteration to compute the step direction v and edge weights w.\nIn [DGG+22], the approximate solutions f and s are updated coordinate-wise, whenever a coordinate is sufficiently far from the true value. A coordinate update induces updates in the data structures as follows: If fe or se is updated for an edge e, (subsequently, we and ve are updated), then we find the unique leaf node H in T containing the edge e, and must update DynamicSC and MaintainSoln at all nodes along the path from H to the root of T . [DGG+22] shows this runtime depends on the sizes of the nodes visited.\n[GS22] introduced a natural batching technique for the coordinate updates, where coordinates representing edges are grouped into blocks, and coordinate-wise updates are performed block-wise instead. Since the leaves of our separator tree T contain O(\u03c4) edges, it is natural for us to also incorporate a blocking scheme, where the blocks are given by the edge partition according to the leaves of T . In this case, the runtime for data structure updates is the same whether we update a single coordinate or a block containing said coordinate, since they affect the same path from the leaf node to the root of T . We bound the overall runtime expression using properties of the new separator tree.\nLastly, the RIPM guarantees that for each k iterations, O\u0303(k2)-many blocks of f and s need to be updated, meaning that running our data structures for many IPM iterations leads to superlinear runtime scaling. We can, however, restart our data structures at any point, by explicitly computing the current exact solutions f , s and reinitializing the data structures with their values in O\u0303(m) total time. On balance, we choose to restart our data structures every \u221a m/\u03c4 -many iterations, for a total restarting cost of O\u0303(m \u221a \u03c4). Between each restart, we make O(m/\u03c4)-many block updates using O\u0303(\u03c4) time each, for a total update cost of O\u0303(m \u221a \u03c4). Hence, the overall run-time is O\u0303(m \u221a \u03c4).\n3 Robust interior point method\nFor the sake of completion, we give the robust interior point method developed in [DLY21], which is a refinement of the methods in [CLS21, Bra20], for solving linear programs of the form\nmin f\u2208F\nc\u22a4f where F = {B\u22a4f = b, l \u2264 f \u2264 u} (3.1)\nfor some matrix B \u2208 Rm\u00d7n. Theorem 3.1 ([DLY21]). Consider the linear program\nmin B\u22a4f=b, l\u2264f\u2264u\nc\u22a4f\nwith B \u2208 Rm\u00d7n. Suppose there exists some interior point f\u25e6 satisfying B\u22a4f\u25e6 = b and l+ r \u2264 f\u25e6 \u2264 u\u2212 r,5 for some scalar r > 0. Let L = \u2016c\u20162 and R = \u2016u\u2212 l\u20162. For any 0 < \u01eb \u2264 1/2, the algorithm RIPM (Algorithm 1) finds f such that B\u22a4f = b, l \u2264 f \u2264 u and\nc\u22a4f \u2264 min B\u22a4f=b, l\u2264f\u2264u c\u22a4f + \u01ebLR.\nFurthermore, the algorithm has the following properties:\n5For any vector v and scalar x, we define v + x to be the vector obtained by adding x to each coordinate of v. We define v \u2212 x to be the vector obtained by subtracting x from each coordinate of v.\nAlgorithm 1 Robust Interior Point Method from [DLY21]\n1: procedure RIPM(B \u2208 Rm\u00d7n, b, c, l,u, \u01eb) 2: Let L = \u2016c\u20162 and R = \u2016u\u2212 l\u20162 3: Define \u03c6i(x) def = \u2212 log(ui \u2212 x)\u2212 log(x\u2212 li) 4: Define \u00b5ti(fi, si) def = si/t+\u2207\u03c6i(fi) 5: Define \u03b3t(f , s)i def = \u2016(\u22072\u03c6i(fi))\u22121/2\u00b5ti(fi, si)\u20162\n\u22b2 Modify the linear program and obtain an initial (f , s) for modified linear program 6: Let t = 221m5 \u00b7 LR128 \u00b7 Rr 7: Compute fc = argminl\u2264f\u2264u c\u22a4f + t\u03c6(f) and f\u25e6 = argminB\u22a4f=b \u2016f \u2212 fc\u20162 8: Let f = (fc, 3R + f\u25e6 \u2212 fc, 3R) and s = (\u2212t\u2207\u03c6(fc), t3R+f\u25e6\u2212fc , t 3R) 9: Let the new matrix Bnew def = [B;B;\u2212B], the new barrier\n\u03c6newi (x) = { \u03c6i(x) if i \u2208 [m], \u2212 log x else.\n\u22b2 Find an initial (f , s) for the original linear program 10: ((f (1),f (2),f (3)), (s(1), s(2), s(3)))\u2190 Centering(Bnew, \u03c6new,f , s, t, LR) 11: (f , s)\u2190 (f (1) + f (2) \u2212 f (3), s(1))\n\u22b2 Optimize the original linear program 12: (f , s)\u2190 Centering(B, \u03c6,f , s, LR, \u01eb4m ) 13: return f\n14: end procedure\n15: procedure Centering(B, \u03c6,f , s, tstart, tend) 16: Let \u03b1 = 1220\u03bb and \u03bb = 64 log(256m 2) where m is the number of rows in B 17: Let t\u2190 tstart, f \u2190 f , s\u2190 s, t\u2190 t 18: while t \u2265 tend do 19: Set t\u2190 max((1\u2212 \u03b1\u221a\nm )t, tend)\n20: Update h = \u2212\u03b1/\u2016 cosh(\u03bb\u03b3t(f , s))\u20162 21: Update the diagonal weight matrix W = \u22072\u03c6(f)\u22121 22: Update the direction v where vi = sinh(\u03bb\u03b3 t(f , s)i)\u00b5 t(f , s)i 23: Pick v\u2016 and v\u22a5 such that W\u22121/2v\u2016 \u2208 Range(B), B\u22a4W1/2v\u22a5 = 0 and\n\u2016v\u2016 \u2212Pwv\u20162 \u2264 \u03b1\u2016v\u20162, \u2016v\u22a5 \u2212 (I\u2212Pw)v\u20162 \u2264 \u03b1\u2016v\u20162 (Pw def= W1/2B(B\u22a4WB)\u22121B\u22a4W1/2)\n24: Implicitly update f \u2190 f + hW1/2v\u22a5, s\u2190 s+ thW\u22121/2v\u2016 25: Explicitly maintain f , s such that \u2016W\u22121/2(f \u2212 f)\u2016\u221e \u2264 \u03b1 and \u2016W1/2(s\u2212 s)\u2016\u221e \u2264 t\u03b1 26: Update t\u2190 t if |t\u2212 t| \u2265 \u03b1t 27: end while 28: return (f , s) 29: end procedure\n\u2022 Each call of Centering involves O( \u221a m logm log(mR\u01ebr )) many steps, and t is only updated\nO(logm log(mR\u01ebr )) times.\n\u2022 In each step of Centering, the coordinate i in W,v changes only if f i or si changes.\n\u2022 In each step of Centering, h\u2016v\u20162 = O( 1logm).\n\u2022 Line 20 to Line 22 takes O(K) time in total, where K is the total number of coordinate changes in f , s.\nWe note that this algorithm only requires access to (f , s), but not (f , s) during the main while-loop in Centering. Hence, (f , s) can be implicitly maintained via any data structure.\n4 Nested dissection on bounded treewidth graphs\nIn this section, we show how to leverage the structural properties of bounded treewidth graphs to find a sparse Cholesky factorization of L def = B\u22a4WB, and hence implicitly maintain an approximation of L\u22121 as part of the projection matrix Pw def = W1/2B(B\u22a4WB)\u22121B\u22a4W1/2 used in the RIPM.\n4.1 Separator tree for bounded treewidth graph\nThe notion of using a separator tree to represent the recursive decomposition of a separable graph is well-established in literature, c.f [EGIS96, HKRS97]. In [DGG+22], the authors show that the separator tree can be used to construct a sparse approximate projection matrix for RIPM. Here, we extends their result to bounded treewidth graphs.\nDefinition 4.1 (\u03c4 -separator tree). Let G be a graph with n vertices and m edges. A separator tree T of G is a rooted binary tree whose nodes represent a recursive decomposition of G based on balanced vertex separators.\nFormally, each node H of T is a region (edge-induced subgraph) of G; we denote this by H \u2208 T . At a node H, we store subsets of vertices \u2202H,S(H), FH , where \u2202H is the set of boundary vertices of H, i.e. vertices with neighbours outside H in G; S(H) is a balanced vertex separator of H; and FH is the set of eliminated vertices at H.\nIn a \u03c4 -separator tree, the nodes and associated vertex sets are defined recursively in a top-down manner as follows:\n1. The root of T is the node H = G, with \u2202H = \u2205 and FH = S(H).\n2. A non-leaf node H \u2208 T has exactly two children H1,H2 \u2208 T that form a edge-disjoint partition of H. If |V (H)| \u2265 \u2126(\u03c4), then the intersection of the vertex sets V (H1)\u2229 V (H2) is a balanced vertex separator S(H) of H, with |S(H)| \u2264 \u03c4 . Define the set of eliminated vertices at H to be FH def = S(H) \\ \u2202H.\nBy definition of boundary vertices, we have \u2202H1 def = (\u2202H \u222a S(H)) \u2229 V (H1), and \u2202H2 def= (\u2202H \u222a S(H)) \u2229 V (H2).\n3. If H is a region with |E(H)| \u2264 \u0398(\u03c4), then we stop the recursion and H becomes a leaf node. Define S(H) = \u2205 and FH = V (H) \\ \u2202H.\nBy construction, the leaf nodes of T partition the edges of G. If H is a leaf node, let E(H) denote the edges contained in H. If H is not a leaf node, let E(H) denote the union of all the edges in the leaf nodes in the subtree TH . Let \u03b7 denote the height of T .\nNext, we show how to construct an appropriate separator tree for bounded treewidth graphs.\nTheorem 4.2. Let G be a graph with n vertices and m edges. Given a tree decomposition of G with width \u03c4 , we can construct a \u03c4 -separator tree T of G with height \u03b7 = O(logm) in O\u0303(n\u03c4) time. Remark 4.3. Given a \u03c4 -separator tree with \u03b7 = O(logm), then |FH \u222a \u2202H| < O(\u03c4 poly log(m)).\nBefore prove the theorem above, we need the following lemma about balanced vertex separators.\nLemma 4.4 ([DLY21, Theorem 4.17]). Let (X,T ) be a width-\u03c4 tree decomposition of a graph G on n vertices. Then in O(n\u03c4) time, we can find a 2/3-balanced vertex separator (A,S,B) of G, and tree decompositions (X1, T1) of G[A \u222a S] and (X2, T2) of G[B \u222a S] each of width at most \u03c4 . Proof of Theorem 4.2. We note that for any subgraph H of G, using the lemma above, we can find the 2/3-balanced vertex separator in time O(|V (H)| \u00b7 \u03c4). Then, we construct the separator tree T recursively as follows, starting with the subgraph H = G:\n1. Given a subgraph H of G, if |E(H)| \u2264 \u0398(\u03c4), then we stop the recursion and H becomes a leaf node.\n2. If|V (H)| > 2\u03c4 , then we can find a 2/3-balanced vertex separator (A,S,B) of H in time O(|V (H)| \u00b7 \u03c4). Then let H1 have vertex set A\u222aS and contain all edges incident to A, and let H2 have vertex set B \u222aS and contain all edges incident to B. We partition the edges in S(H) arbitrarily into H1 and H2.\n3. If |V (H)| \u2264 2\u03c4 , then we partition the edges of H into two sets each of size at most 23 |E(H)|, and let H1 and H2 be graphs on V (H) with their respective edge sets. 6\nConsider a non-leaf node H with children H1 and H2, we note that\n|V (Hi)| \u00b7 |E(Hi)| \u2264 2\n3 |V (H)| \u00b7 |E(H)| for i \u2208 {1, 2}.\nThis directly shows the height of the separator tree T is O(logm). The running time directly follows by the lemma above and the fact that we can find a balanced edge partition in O(|E(H)|) time for any subgraph H of G.\n4.2 Nested dissection using a separator tree\nDefinition 4.5 (Block Cholesky decomposition). The block Cholesky decomposition of a symmetric matrix L with two blocks indexed by F and C is:\nL =\n[ I 0\nLC,F (LF,F ) \u22121 I\n] [ LF,F 0\n0 Sc(L, C)\n] [ I (LF,F ) \u22121 LF,C\n0 I\n] ,\nwhere the middle matrix in the decomposition is a block-diagonal matrix with blocks indexed by F and C, with the lower-right block being the Schur complement Sc(L, C) of L onto C:\nSc(L, C) def = LC,C \u2212 LC,FL\u22121F,FLF,C .\n6We use 2\u03c4 here to differentiate between the second and third case, instead of the more natural \u03c4 , in order to avoid any infinite-loop edge cases in the recursive process arising from division and rounding.\nWe use the separator tree structure to factor the matrix L\u22121 def = (B\u22a4WB)\u22121:\nTheorem 4.6 (Approximate L\u22121 factorization, c.f. [DGG+22]). Let T be the separator tree of G with height \u03b7. For each node H \u2208 T with edges E(H), let B[H] \u2208 Rn\u00d7m denote the matrix B restricted to columns indexed by E(H), and define L[H] def = B[H]\u22a4WB[H].\nGiven approximation parameter \u01ebP, suppose for each node H at level i of T , we have a matrix L (H) satisfying the ei\u01ebP-spectral approximation\nL (H) \u2248i\u01ebP Sc(L[H], \u2202H \u222a FH). (4.1)\nThen, we can approximate L\u22121 by\nL \u22121 \u2248\u03b7\u01ebP \u03a0(0)\u22a4 \u00b7 \u00b7 \u00b7\u03a0(\u03b7\u22121)\u22a4\u0393\u03a0(\u03b7\u22121) \u00b7 \u00b7 \u00b7\u03a0(0), (4.2)\nwhere\n\u0393 def =   \u2211 H\u2208T (0) ( L (H) FH ,FH )\u22121 0 0 0 . . . 0\n0 0 \u2211\nH\u2208T (\u03b7) ( L (H) FH ,FH )\u22121\n  , (4.3)\nand for i = 0, . . . , \u03b7 \u2212 1, \u03a0 (i) def= I\u2212 \u2211\nH\u2208T (i) X\n(H), (4.4)\nwhere T (i) is the set of nodes at level i in T , the matrix \u03a0(i) is supported on \u22c3H\u2208T (i) \u2202H \u222aFH and padded with zeros to full dimension, and for each H \u2208 T ,\nX (H) def= L (H) \u2202H,FH ( L (H) FH ,FH )\u22121 . (4.5)\n[DGG+22] gives a data structure to maintain an implicit representation of L\u22121 as the weights w undergoes changes in the IPM:\nTheorem 4.7 ([DGG+22, Theorem 6]). Given a graph G with m edges and its O\u0303(\u03c4)-separator tree T with height \u03b7 = O(logm), there is a deterministic data structure DynamicSC which maintains the edge weights w from the IPM, and at every node H \u2208 T , maintains two Laplacians L(H) and S\u0303c(L(H), \u2202H) dependent on w. It supports the following procedures:\n\u2022 Initialize(G,w \u2208 Rm>0, \u01ebP > 0): Given a graph G, initial weights w, projection matrix approximation accuracy \u01ebP, preprocess in O\u0303(\u01ebP \u22122m) time.\n\u2022 Reweight(w \u2208 Rm>0, given implicitly as a set of changed coordinates): Update the weights to w in O\u0303(\u01ebP \u22122\u2211 H\u2208H |FH \u222a \u2202H|) time, where H def = {H \u2208 T : (w \u2212w(prev))|E(H) 6= 0} is the\nset of nodes containing an edge with updated weight. (Note that H is a union of paths from leaf nodes to the root.)\n\u2022 Access to Laplacian L(H) at any node H \u2208 T in time O\u0303 ( \u01ebP \u22122|\u2202H \u222a FH | ) . \u2022 Access to Laplacian S\u0303c(L(H), \u2202H) at any node H \u2208 T in time O\u0303 ( \u01ebP \u22122|\u2202H| ) .\nFurthermore, with high probability, for any node H in T , if H is at level i, then\nL (H) \u2248i\u01ebP Sc(L[H], \u2202H \u222a FH), and\nS\u0303c(L(H), \u2202H) \u2248\u01ebP Sc(L(H), \u2202H).\n5 Solution maintenance\nAssuming the correct maintenance of Laplacians and Schur complements along a recursive separator tree, [DGG+22] gave detailed data structures for maintaining the exact and approximate flow and slack solutions throughout the IPM. Recall that the leaf nodes of the separator tree T form a partition of the edges of G. In [DGG+22], each leaf node of the separator tree contains O(1)-many edges. while in our case, each leaf node contains O(\u03c4)-many edges, and therefore we update the approximate solution in a block manner. The data structures in [DGG+22] naturally generalized from coordinate-wise updates to the block-wise case, so we use their implementation in a black-box manner. Here, we state a combined version of their main theorems.\nWe use f[i] to denote the subvector of f indexed by edges in the i-th leaf node of T , and similarly s[i]. We use f (k) [i] and s (k) [i] to denote the vector f[i] and s[i] at the k-th step of the IPM. Each block contains O(\u03c4)-many variables.\nTheorem 5.1 ([DGG+22, Theorem 9, 10]). Given a graph G with m edges and its separator tree T with height \u03b7, there is a randomized data structure implicitly maintains the IPM solution pair (f , s) undergoing IPM changes, and explicitly maintains its approximation (f , s), and supports the following procedures with high probability against an adaptive adversary:\n\u2022 Initialize(G,f (init) \u2208 Rm, s(init) \u2208 Rm,v \u2208 Rm,w \u2208 Rm>0, \u01ebP > 0, \u01eb > 0): Given a graph G, initial solutions f (init), s(init), initial direction v, initial weights w, target step accuracy \u01ebP and target approximation accuracy \u01eb, preprocess in O\u0303(m\u01eb\u22122\nP ) time, set the implicit representations\nf \u2190 f (init), s\u2190 s(init), and set the approximations f \u2190 f , s\u2190 s.\n\u2022 Reweight(w \u2208 Rm>0, given implicitly as a set of changed weights): Set the current weights to w in O\u0303(\u01eb\u22122\nP \u03c4K)7 time, where where K is the number of blocks changed in w.\n\u2022 Move(\u03b1 \u2208 R,v \u2208 Rm given implicitly as a set of changed coordinates): Implicitly update\ns\u2190 s+ \u03b1W\u22121/2P\u0303wv, f \u2190 f + \u03b1W1/2v \u2212 \u03b1W1/2P\u0303\u2032wv,\nfor some P\u0303w satisfying \u2016(P\u0303w \u2212 Pw)v\u20162 \u2264 \u03b7\u01ebP \u2016v\u20162 and P\u0303wv \u2208 Range(B), and some other P\u0303\n\u2032 w satisfying \u2016P\u0303\u2032wv \u2212Pwv\u20162 \u2264 O(\u03b7\u01ebP) \u2016v\u20162 and B\u22a4W1/2P\u0303\u2032wv = B\u22a4W1/2v.\nThe total runtime is O\u0303(\u01eb\u22122 P \u03c4K), where K is the number of blocks changed in v.\n\u2022 Approximate()\u2192 R2m: Return the vector pair f , s implicitly as a set of changed coordinates, satisfying \u2016W\u22121/2(f \u2212 f)\u2016\u221e \u2264 \u01eb and \u2016W1/2(s\u2212 s)\u2016\u221e \u2264 \u01eb, for the current weight w and the current solutions f , s.\n\u2022 Exact()\u2192 R2m: Output the current vector f , s in O\u0303(m\u01ebP\u22122) time.\nSuppose \u03b1\u2016v\u20162 \u2264 \u03b2 for some \u03b2 for all calls to Move. Suppose in each step, Reweight, Move and Approximate are called in order. Let K denote the total number of blocks changed in v and w between the (k \u2212 1)-th and k-th Reweight and Move calls. Then at the k-th Approximate call,\n7The original bound here is O\u0303(\u01eb\u22122 P\n\u221a mK) where the \u221a mK factor comes from the fact that they can bound\u2211\nH\u2208H |FH \u222a \u2202H | \u2264 \u221a mK and H = {H \u2208 T : (w \u2212w(prev))|E(H) 6= 0}. See [DGG+22, Section 9] for more details.\nHere, we replace it by O\u0303(\u03c4K) using Remark 4.3.\n\u2022 the data structure sets f [i] \u2190 f (k)[i] , s[i] \u2190 s (k) [i] for O(Nk def = 22\u2113k(\u03b2\u01eb ) 2 log2 m) blocks i, where \u2113k\nis the largest integer \u2113 with k \u2261 0 mod 2\u2113 when k 6= 0 and \u21130 = 0, and\n\u2022 the amortized time for the k-th Approximate call is O\u0303(\u01eb\u22122 P \u03c4(K +Nk\u22122\u2113k )).\nWe note that running the data structure above for each 2\u2113 step, takes O\u0303(22\u2113\u03c4) total time. For 2\u2113 = \u2126( \u221a m) total steps, this is O(m\u03c4). However, the initialization only takes O\u0303(m) time. Therefore, we restart the data structure every 2\u2113 = \u2126( \u221a m/\u03c4) steps.\n6 Proof of main theorems\nAlgorithm 2 Implementation of Robust Interior Point Method\n1: procedure CenteringImpl(B, \u03c6,f , s, tstart, tend, \u03c4) 2: G: graph on n vertices and m edges with incidence matrix B 3: Solution: data structures for slack and flow maintenance \u22b2 Theorem 5.1 4: \u03b1 def = 1\n220\u03bb , \u03bb\ndef = 64 log(256m2)\n5: t\u2190 tstart, f \u2190 f , s\u2190 s, t\u2190 t, W\u2190 \u22072\u03c6(f )\u22121, k \u2190 0 \u22b2 variable initialization 6: vi \u2190 sinh(\u03bb\u03b3t(f , s)i)\u00b5ti(f i, si) for all i \u2208 [n] \u22b2 data structure initialization 7: solution.Initalize(G,f , t \u22121 s,v,W, \u01ebP = O(\u03b1/ logm), \u01eb = \u03b1) \u22b2 choose \u01ebP \u2264 \u03b1 < \u03b7 in Theorem 5.1 8: while t \u2265 tend do 9: t\u2190 max{(1 \u2212 \u03b1\u221a\nm )t, tend}, k \u2190 k + 1\n10: Update h = \u2212\u03b1/\u2016 cosh(\u03bb\u03b3t(f , s))\u20162 11: Update the diagonal weight matrix W = \u22072\u03c6(f)\u22121 12: Update step direction vi \u2190 sinh(\u03bb\u03b3t(f , s)i)\u00b5ti(f i, si) for all i where f i or si has changed\n13: solution.Reweight(W) \u22b2 update data structure with new weights 14: solution.Move(h,v) \u22b2 update f and s 15: f , ts\u2190 solution.Approximate() \u22b2 maintain f , s 16: if |t\u2212 t| \u2265 \u03b1t or k > \u221a m/\u03c4 then \u22b2 restart data structure 17: f , s\u2190 solution.Exact() 18: t\u2190 t, k \u2190 0 19: solution.Initalize(G,f , t \u22121 s,v,W, \u01ebP = O(\u03b1/ logm), \u01eb = \u03b1) 20: end if\n21: end while 22: return solution.Exact() 23: end procedure\nTheorem 1.1 (Main result). Let G = (V,E) be a directed graph with n vertices and m edges. Assume that the demands d, edge capacities u and costs c are all integers and bounded by M in absolute value. Given a tree decomposition of G with width \u03c4 and size S \u2264 n\u03c4 , there is an algorithm that computes a minimum-cost flow in O\u0303(m \u221a \u03c4 logM + S) expected time8.\n8Throughout the paper, we use O\u0303(\u00b7) to hide polylog m and polylog M factors.\nProof. Since Theorem 3.1 requires an interior point in the polytope, we note one can find an interior point with r \u2265 14m in O(m) time, see [DGG+22].\nNow, we bound the parameters L,R, r in Theorem 3.1. Clearly, L = \u2016cnew\u20162 = O(Mm) and R = \u2016unew \u2212 lnew\u20162 = O(Mm).\nThe RIPM in Theorem 3.1 runs the subroutine Centering twice. In the first run, the constraint matrix is the incidence matrix of a new underlying graph, constructed by making three copies of each edge in the original graph G. Since copying edges does not affect treewidth, and our data structures allow for duplicate edges, we use the implementation given in CenteringImpl (Algorithm 2) for both runs.\nBy the guarantees of Theorem 5.1, we correctly maintain f and s at every step in CenteringImpl, and the requirements on f and s for the RIPM are satisfied. Hence, Theorem 3.1 shows that we can find a circulation f such that (cnew)\u22a4f \u2264 OPT \u2212 12 by setting \u01eb = 1CM2m2 for some large constant C in Algorithm 1. Note that f , when restricted to the original graph, is almost a flow routing the required demand with flow value off by at most 12nM . This is because sending extra k units of fractional flow from s to t gives extra negative cost \u2264 \u2212knM . Now we can round f to an integral flow f int with same or better flow value using no more than O\u0303(m) time [KP15]. Since f int is integral with flow value at least the total demand minus 12 , f\nint routes the demand completely. Again, since f int is integral with cost at most OPT \u2212 12 , f int must have the minimum cost.\nFinally, we bound the runtime of CenteringImpl. Before, we use the data structure for flow and slack maintenance, we need to construct the separator tree, this can be done in O\u0303(n\u03c4) time using Theorem 4.2. We initialize the data structures for flow and slack by Initialize. Here, the data structures are given the first IPM step direction v for preprocessing; the actual step is taken in the first iteration of the main while-loop. At each step of CenteringImpl, we perform the implicit update of f and s using Move; we update W in the data structures using Reweight; and we construct the explicit approximations f and s using Approximate; each in the respective flow and slack data structures. We return the true (f , s) by Exact. The total cost of CenteringImpl is dominated by Move, Reweight, and Approximate.\nSince we call Move, Reweight and Approximate in order in each step and the runtime for Move, Reweight are both dominated by the runtime for Approximate, it suffices to bound the runtime for Approximate only. Theorem 3.1 guarantees that there are T = O( \u221a m log n log(nM)) total Approximate calls. We implement this by restarting the data structure for every \u221a\nm/\u03c4 steps.\nWe note that that at the k-th step, the number of blocks changed in w and v is bounded by K def = O(22\u2113k\u22121 log2 m), where \u2113k is the largest integer \u2113 with k \u2261 0 mod 2\u2113, or equivalently, the number of trailing zeros in the binary representation of k. Theorem 3.1 further guarantees we can apply Theorem 5.1 with parameter \u03b2 = O(1/ logm), which in turn shows the amortized time for the k-th call is\nO\u0303(\u01ebP \u22122\u03c4(K +Nk\u22122\u2113k )).\nwhere Nk def = 22\u2113k(\u03b2/\u03b1)2 log2 m = O(22\u2113k log2 m), where \u03b1 = O(1/ logm) and \u01ebP = O(1/ logm) are defined in CenteringImpl. Observe that K + Nk\u22122\u2113k = O(Nk\u22122\u2113k ). Now, summing over\nT = \u221a m/\u03c4 steps, the time is\nO( \u221a m/\u03c4) T\u2211\nk=1\nO\u0303(\u03c4Nk\u22122\u2113k ) = O( \u221a m/\u03c4) log T\u2211\n\u2113=0\nT 2\u2113 \u00b7 O\u0303(22\u2113\u03c4) = O\u0303(m).\nWe note the initialization time is also O\u0303(m). Recall that Theorem 3.1\u2019s guarantee of total\nnumber of iterations is O( \u221a m log n log(nM)), the data structure restarts for O\u0303(\u03c4)-many times in total. The total runtime for the RIPM data structure is O\u0303(m \u221a \u03c4 logM).\nHence, we conclude the overall running time is O\u0303(m \u221a \u03c4 logM + n\u03c4).\nCorollary 1.2 (Approximating treewidth). Let G = (V,E) be a graph with n vertices and m edges. There is an algorithm to find a tree decomposition of G with width at most O(tw(G) \u00b7 log n) in O\u0303(tw(G)3 \u00b7m) expected time.\nOur algorithm requires some tree decomposition of the graph as input. We use the following lemma to construct the initial tree decomposition.\nLemma 6.1 ([BW19]). For any 23 < \u03b1 < 1 and 0 < \u01eb < 1 \u2212 \u03b1, given a graph G with n vertices and m edges, if the graph G contains an \u03b1-balanced vertex separator of size K, then there is a randomized algorithm that finds a balanced vertex separator of size O\u0303(K2/\u01eb) in O\u0303(mK3/\u01eb) expected time. The algorithm does not require knowledge of K.\nThe following lemma establishes the relationship between max flow and balanced edge separators. We first give the relevant definitions. For a given constant c \u2264 1/2, a directed edge-cut (S, S) is called a c-balanced edge separator if both |S| \u2265 cn and |S| \u2265 cn. The capacity of the cut (S, S) is the total capacity of all edges crossing the cut. The minimum c-balanced edge separator problem is the c-balanced edge separator with minimum capacity. A \u03bb pseudo-approximation to the minimum c-balanced edge separator is a c\u2032-balanced cut (S, S) for some other constant c\u2032, whose capacities is within a factor of \u03bb of that of the minimum c-balanced edge separator.\nLemma 6.2 ([AK16]). An O(log n) pseudo-approximation to the minimum c-balanced edge separator in directed graphs can be computed using polylog n single-commodity flow computations on the same graph.\nProof of Corollary 1.2. It\u2019s well known that given a O(log n) approximation algorithm for finding a balanced vertex separator, one can construct a tree decomposition of width O(tw(G) log n). Specifically, the algorithm of [BGHK95] find a tree decomposition by recursively using a balanced vertex separator algorithm.\nNow, it suffices to show we can find a log(n) pseudo-approximation balanced vertex separator in O\u0303(m \u00b7 tw(G)3) expected time. Using the reduction from [LR99], we reduce the balanced vertex separator to directed edge separator on graph G\u2217 = (V \u2217, E\u2217), where\nV \u2217 = { v | v \u2208 V } \u222a { v\u2032 | v \u2208 V } ,\nand E\u2217 = { ( v, v\u2032 ) | v \u2208 V } \u222a { ( u\u2032, v ) | (u, v) \u2208 E } \u222a { ( v\u2032, u ) | (u, v) \u2208 E } .\nWe note that tw(G\u2217) = O(tw(G)). This shows G\u2217 has a 2/3-balanced vertex separator of size O(tw(G)). We first use Lemma 6.1 to construct a O\u0303(tw(G)2)-separator tree for G\u2217. Then, we use the algorithm in [AK16] combined with our flow algorithm to find a balanced edge separator in O\u0303(m \u00b7 tw(G)) expected time. Hence, we can find a balanced vertex separator in O\u0303(m \u00b7 tw(G)3) expected time.\nReferences\n[ACP87] Stefan Arnborg, Derek G Corneil, and Andrzej Proskurowski. Complexity of finding embeddings in a k-tree. SIAM Journal on Algebraic Discrete Methods, 8(2):277\u2013284, 1987. 4\n[AK16] Sanjeev Arora and Satyen Kale. A combinatorial, primal-dual approach to semidefinite programs. Journal of the ACM (JACM), 63(2):1\u201335, 2016. 13\n[APW12] Per Austrin, Toniann Pitassi, and Yu Wu. Inapproximability of treewidth, one-shot pebbling, and related layout problems. In International Workshop on Approximation Algorithms for Combinatorial Optimization (APPROX), pages 13\u201324. Springer, 2012. 4\n[BDD+16] Hans L Bodlaender, P\u00e5l Gr\u00f8\u0301n\u00e5s Drange, Markus S Dregi, Fedor V Fomin, Daniel Lokshtanov, and Micha\u0142 Pilipczuk. A ckn 5-approximation algorithm for treewidth. SIAM Journal on Computing, 45(2):317\u2013378, 2016. 4\n[BGHK95] Hans L Bodlaender, John R Gilbert, Hj\u00e1lmtyr Hafsteinsson, and Ton Kloks. Approximating treewidth, pathwidth, frontsize, and shortest elimination tree. Journal of Algorithms, 18(2):238\u2013255, 1995. 3, 13\n[BGJ+21] Jan van den Band, Yu Gao, Arun Jambulapati, Yin Tat Lee, Yang P. Liu, Richard Peng, and Aaron Sidford. Faster maxflow via improved dynamic spectral vertex sparsifiers. CoRR, abs/2112.00722, 2021. 3\n[BGS22] Aaron Bernstein, Maximilian Probst Gutenberg, and Thatchaphol Saranurak. Deterministic decremental sssp and approximate min-cost flow in almost-linear time. In 2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS), pages 1000\u20131008. IEEE, 2022. 4\n[BLL+21] Jan van den Brand, Yin Tat Lee, Yang P Liu, Thatchaphol Saranurak, Aaron Sidford, Zhao Song, and Di Wang. Minimum cost flows, MDPs, and \u21131-regression in nearly linear time for dense instances. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 859\u2013869, 2021. 3, 4\n[Bra20] Jan van den Brand. A deterministic linear program solver in current matrix multiplication time. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 259\u2013278. SIAM, 2020. 5\n[BW19] Sebastian Brandt and Roger Wattenhofer. Approximating small balanced vertex separators in almost linear time. Algorithmica, 81:4070\u20134097, 2019. 4, 13\n[CKL+22] Li Chen, Rasmus Kyng, Yang P Liu, Richard Peng, Maximilian Probst Gutenberg, and Sushant Sachdeva. Maximum flow and minimum-cost flow in almost-linear time. In 2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS), pages 612\u2013623. IEEE, 2022. 3\n[CLS21] Michael B Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matrix multiplication time. Journal of the ACM (JACM), 68(1):1\u201339, 2021. 3, 5\n[Dav06] Timothy A Davis. Direct methods for sparse linear systems. SIAM, 2006. 3\n[DGG+22] Sally Dong, Yu Gao, Gramoz Goranci, Yin Tat Lee, Richard Peng, Sushant Sachdeva, and Guanghao Ye. Nested dissection meets ipms: Planar min-cost flow in nearly-linear time. In Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages 124\u2013153. SIAM, 2022. 3, 4, 5, 7, 9, 10, 12\n[DGL+23] Sally Dong, Gramoz Goranci, Lawrence Li, Sushant Sachdeva, and Guanghao Ye. Personal communications. 2023. 3\n[DKP+17] David Durfee, Rasmus Kyng, John Peebles, Anup B. Rao, and Sushant Sachdeva. Sampling random spanning trees faster than matrix multiplication. In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2017, pages 730\u2013742, 2017. 3\n[DLY21] Sally Dong, Yin Tat Lee, and Guanghao Ye. A nearly-linear time algorithm for linear programs with small treewidth: A multiscale representation of robust central path. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, STOC 2021, pages 1784\u20131797. ACM, 2021. 1, 3, 5, 6, 8\n[EGIS96] David Eppstein, Zvi Galil, Giuseppe F Italiano, and Thomas H Spencer. Separator based sparsification: I. planarity testing and minimum spanning trees. journal of computer and system sciences, 52(1):3\u201327, 1996. 7\n[FHL08] Uriel Feige, MohammadTaghi Hajiaghayi, and James R Lee. Improved approximation algorithms for minimum weight vertex separators. SIAM Journal on Computing, 38(2):629, 2008. 4\n[FLS+18] Fedor V Fomin, Daniel Lokshtanov, Saket Saurabh, Micha\u0142 Pilipczuk, and Marcin Wrochna. Fully polynomial-time parameterized computations for graphs and matrices of low treewidth. ACM Transactions on Algorithms (TALG), 14(3):1\u201345, 2018. 3, 4\n[GLP21] Yu Gao, Yang P. Liu, and Richard Peng. Fully dynamic electrical flows: Sparse maxflow faster than Goldberg-Rao. In 62st IEEE Annual Symposium on Foundations of Computer Science, FOCS2021. IEEE, 2021. 3\n[GS22] Yuzhou Gu and Zhao Song. A faster small treewidth SDP solver. arXiv preprint arXiv:2211.06033, 2022. 1, 3, 5\n[HKRS97] Monika R Henzinger, Philip Klein, Satish Rao, and Sairam Subramanian. Faster shortest-path algorithms for planar graphs. Journal of Computer and System Sciences, 55(1):3\u201323, 1997. 7\n[JS21] Arun Jambulapati and Aaron Sidford. Ultrasparse ultrasparsifiers and faster laplacian system solvers. In D\u00e1niel Marx, editor, Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms, SODA 2021, Virtual Conference, January 10 - 13, 2021, pages 540\u2013559. SIAM, 2021. 3\n[Kar84] N. Karmarkar. A new polynomial-time algorithm for linear programming. Combinatorica, 4(4):373\u2013395, dec 1984. 3\n[KP15] Donggu Kang and James Payor. Flow Rounding. arXiv preprint arXiv:1507.08139, 2015. 12\n[LR99] Tom Leighton and Satish Rao. Multicommodity max-flow min-cut theorems and their use in designing approximation algorithms. Journal of the ACM (JACM), 46(6):787\u2013832, 1999. 13\n[LRT79] Richard J Lipton, Donald J Rose, and Robert Endre Tarjan. Generalized nested dissection. SIAM journal on numerical analysis, 16(2):346\u2013358, 1979. 3\n[LS14] Yin Tat Lee and Aaron Sidford. Path finding methods for linear programming: Solving linear programs in O\u0303( \u221a rank) iterations and faster algorithms for maximum flow. In\n2014 IEEE 55th Annual Symposium on Foundations of Computer Science, pages 424\u2013 433. IEEE, 2014. 3, 4\n[Ren88] James Renegar. A polynomial-time algorithm, based on Newton\u2019s method, for linear programming. Mathematical programming, 40(1-3):59\u201393, 1988. 3\n[ST04] Daniel A Spielman and Shang-Hua Teng. Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems. In Proceedings of the thirty-sixth annual ACM symposium on Theory of computing, pages 81\u201390, 2004. 3\n[ZL18] Richard Y Zhang and Javad Lavaei. Sparse semidefinite programs with near-linear time complexity. In 2018 IEEE Conference on Decision and Control (CDC), pages 1624\u20131631. IEEE, 2018. 3"
        }
    ],
    "title": "Faster Min-Cost Flow on Bounded Treewidth Graphs",
    "year": 2023
}