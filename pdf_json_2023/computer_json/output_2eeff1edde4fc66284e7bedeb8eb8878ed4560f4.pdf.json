{
    "abstractText": "The detection of machine-generated text, especially from large language models (LLMs), is crucial in preventing serious social problems resulting from their misuse. Some methods train dedicated detectors on specific datasets but fall short in generalizing to unseen test data, while other zero-shot ones often yield suboptimal performance. Although the recent DetectGPT has shown promising detection performance, it suffers from significant inefficiency issues, as detecting a single candidate requires scoring hundreds of its perturbations with the source LLM. This paper aims to bridge this gap. Technically, we propose to incorporate a Bayesian surrogate model, which allows us to select typical samples based on Bayesian uncertainty and interpolate scores from typical samples to other ones, to improve query efficiency. Our empirical results demonstrate that our method significantly outperforms existing approaches under a low query budget. Notably, our method achieves similar performance with up to 2 times fewer queries than DetectGPT and 3.7% higher AUROC at a query number of 5.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhijie Deng"
        },
        {
            "affiliations": [],
            "name": "Shanghai Jiao Tong"
        },
        {
            "affiliations": [],
            "name": "Hongcheng Gao"
        },
        {
            "affiliations": [],
            "name": "Yibo Miao"
        },
        {
            "affiliations": [],
            "name": "Hao Zhang"
        }
    ],
    "id": "SP:0385786d665b4e14ec8eee1ad1f87807beb844eb",
    "references": [
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Aakanksha Chowdhery",
                "Sharan Narang",
                "Jacob Devlin",
                "Maarten Bosma",
                "Gaurav Mishra",
                "Adam Roberts",
                "Paul Barham",
                "Hyung Won Chung",
                "Charles Sutton",
                "Sebastian Gehrmann"
            ],
            "title": "Palm: Scaling language modeling with pathways",
            "venue": "arXiv preprint arXiv:2204.02311,",
            "year": 2022
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "venue": "arXiv preprint arXiv:2302.13971,",
            "year": 2023
        },
        {
            "authors": [
                "Sebastian Gehrmann",
                "Hendrik Strobelt",
                "Alexander M Rush"
            ],
            "title": "Gltr: Statistical detection and visualization of generated text",
            "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,",
            "year": 2019
        },
        {
            "authors": [
                "Irene Solaiman",
                "Miles Brundage",
                "Jack Clark",
                "Amanda Askell",
                "Ariel Herbert-Voss",
                "Jeff Wu",
                "Alec Radford",
                "Gretchen Krueger",
                "Jong Wook Kim",
                "Sarah Kreps"
            ],
            "title": "Release strategies and the social impacts of language models",
            "venue": "arXiv preprint arXiv:1908.09203,",
            "year": 2019
        },
        {
            "authors": [
                "Daphne Ippolito",
                "Daniel Duckworth",
                "Chris Callison-Burch",
                "Douglas Eck"
            ],
            "title": "Automatic detection of generated text is easiest when humans are fooled",
            "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Eric Mitchell",
                "Yoonho Lee",
                "Alexander Khazatsky",
                "Christopher D. Manning",
                "Chelsea Finn"
            ],
            "title": "Detectgpt: Zero-shot machine-generated text detection using probability curvature, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Sid Black",
                "Stella Biderman",
                "Eric Hallahan",
                "Quentin Anthony",
                "Leo Gao",
                "Laurence Golding",
                "Horace He",
                "Connor Leahy",
                "Kyle McDonell",
                "Jason Phang"
            ],
            "title": "Gpt-neox-20b: An open-source autoregressive language model",
            "venue": "arXiv preprint arXiv:2204.06745,",
            "year": 2022
        },
        {
            "authors": [
                "Yarin Gal",
                "Riashat Islam",
                "Zoubin Ghahramani"
            ],
            "title": "Deep bayesian active learning with image data",
            "venue": "In International conference on machine learning,",
            "year": 2017
        },
        {
            "authors": [
                "Susan Zhang",
                "Stephen Roller",
                "Naman Goyal",
                "Mikel Artetxe",
                "Moya Chen",
                "Shuohui Chen",
                "Christopher Dewan",
                "Mona Diab",
                "Xian Li",
                "Xi Victoria Lin"
            ],
            "title": "Opt: Open pre-trained transformer language models",
            "venue": "arXiv preprint arXiv:2205.01068,",
            "year": 2022
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova"
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805,",
            "year": 2018
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov"
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "year": 1907
        },
        {
            "authors": [
                "Zhenzhong Lan",
                "Mingda Chen",
                "Sebastian Goodman",
                "Kevin Gimpel",
                "Piyush Sharma",
                "Radu Soricut"
            ],
            "title": "Albert: A lite bert for self-supervised learning of language representations",
            "year": 1909
        },
        {
            "authors": [
                "Sebastian Gehrmann",
                "Hendrik Strobelt",
                "Alexander Rush"
            ],
            "title": "GLTR: Statistical detection and visualization of generated text",
            "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,",
            "year": 2019
        },
        {
            "authors": [
                "Biyang Guo",
                "Xin Zhang",
                "Ziyuan Wang",
                "Minqi Jiang",
                "Jinran Nie",
                "Yuxuan Ding",
                "Jianwei Yue",
                "Yupeng Wu"
            ],
            "title": "How close is chatgpt to human experts? comparison corpus, evaluation, and detection, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Adaku Uchendu",
                "Thai Le",
                "Kai Shu",
                "Dongwon Lee"
            ],
            "title": "Authorship attribution for neural text generation",
            "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Anton Bakhtin",
                "Sam Gross",
                "Myle Ott",
                "Yuntian Deng",
                "Marc\u2019Aurelio Ranzato",
                "Arthur Szlam"
            ],
            "title": "Real or fake? learning to discriminate machine from human generated text",
            "year": 1906
        },
        {
            "authors": [
                "Fanchao Qi",
                "Mukai Li",
                "Yangyi Chen",
                "Zhengyan Zhang",
                "Zhiyuan Liu",
                "Yasheng Wang",
                "Maosong Sun"
            ],
            "title": "Hidden killer: Invisible textual backdoor attacks with syntactic trigger",
            "venue": "In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),",
            "year": 2021
        },
        {
            "authors": [
                "Xinlei He",
                "Xinyue Shen",
                "Zeyuan Chen",
                "Michael Backes",
                "Yang Zhang"
            ],
            "title": "MGTBench: Benchmarking Machine-Generated Text Detection",
            "venue": "CoRR abs/2303.14822,",
            "year": 2023
        },
        {
            "authors": [
                "Ganesh Jawahar",
                "Muhammad Abdul-Mageed",
                "VS Laks Lakshmanan"
            ],
            "title": "Automatic detection of machine generated text: A critical survey",
            "venue": "In Proceedings of the 28th International Conference on Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu"
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Christopher Williams",
                "Carl Rasmussen"
            ],
            "title": "Gaussian processes for regression",
            "venue": "Advances in neural information processing systems,",
            "year": 1995
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q Weinberger",
                "Yoav Artzi"
            ],
            "title": "Bertscore: Evaluating text generation with bert",
            "year": 1904
        },
        {
            "authors": [
                "Balaji Lakshminarayanan",
                "Alexander Pritzel",
                "Charles Blundell"
            ],
            "title": "Simple and scalable predictive uncertainty estimation using deep ensembles",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Wesley J Maddox",
                "Pavel Izmailov",
                "Timur Garipov",
                "Dmitry P Vetrov",
                "Andrew Gordon Wilson"
            ],
            "title": "A simple baseline for bayesian uncertainty in deep learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Zhijie Deng",
                "Jun Zhu"
            ],
            "title": "Bayesadapter: Being bayesian, inexpensively and reliably, via bayesian fine-tuning",
            "venue": "In Asian Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Salman Mohamadi",
                "Hamidreza Amindavar"
            ],
            "title": "Deep bayesian active learning, a brief survey on recent advances",
            "venue": "arXiv preprint arXiv:2012.08044,",
            "year": 2020
        },
        {
            "authors": [
                "Jasper Snoek",
                "Hugo Larochelle",
                "Ryan P Adams"
            ],
            "title": "Practical bayesian optimization of machine learning algorithms",
            "venue": "Advances in neural information processing systems,",
            "year": 2012
        },
        {
            "authors": [
                "Shashi Narayan",
                "Shay B Cohen",
                "Mirella Lapata"
            ],
            "title": "Don\u2019t give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
            "venue": "arXiv preprint arXiv:1808.08745,",
            "year": 2018
        },
        {
            "authors": [
                "Pranav Rajpurkar",
                "Jian Zhang",
                "Konstantin Lopyrev",
                "Percy Liang"
            ],
            "title": "Squad: 100,000+ questions for machine comprehension of text",
            "venue": "arXiv preprint arXiv:1606.05250,",
            "year": 2016
        },
        {
            "authors": [
                "Angela Fan",
                "Mike Lewis",
                "Yann Dauphin"
            ],
            "title": "Hierarchical neural story generation",
            "venue": "arXiv preprint arXiv:1805.04833,",
            "year": 2018
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980,",
            "year": 2014
        },
        {
            "authors": [
                "Ben Wang",
                "Aran Komatsuzaki"
            ],
            "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Large language models (LLMs) [1\u20134] have the impressive ability to replicate human language patterns, producing text that appears coherent, well-written, and persuasive. Although the generated text may contain factual errors and unsupported quotations, LLMs are increasingly used to simplify writing and presentation tasks, providing greater convenience in daily work and life. Regrettably, some individuals have misused LLMs for nefarious purposes, such as creating convincing fake news articles or engaging in cheating, which can have significant social consequences. Mitigating these negative impacts has become a pressing issue for the community.\nThe LLM-generated texts are highly articulate, posing a significant challenge for humans in identifying them [5]. Fortunately, it is shown that machine learning tools can be leveraged to recognize the watermarks underlying the texts. Some methods [e.g., 6] involve training supervised classifiers, which, yet, suffer from overfitting to the training data and ineffectiveness to generalize to new test data. Zero-shot LLM-generated text detection approaches bypass these issues by leveraging the source LLM to detect its samples [7, 5, 8]. They usually proceed by inspecting the average per-token log probability of the candidate text, but the practical detection performance can be unsatisfactory.\n\u2217Equal contribution. \u2020Corresponding authors.\nPreprint. Under review.\nar X\niv :2\n30 5.\n16 61\n7v 1\n[ cs\n.L G\n] 2\n6 M\nDetectGPT [9] is a recent method that achieves enhanced zero-shot detection efficacy by exploring the probability curvature of LLMs. It generates multiple perturbations of the candidate text and scores them using the source LLM to define detection statistics. It can even detect texts generated by GPT-2 [10] and GPT-NeoX-20B [11]. However, DetectGPT relies on hundreds of queries to the source LLM to accurately estimate the local probability curvature surrounding one single candidate passage, leading to considerable inefficiency. This level of computational expense is prohibitive for widely-used commercial LLMs, e.g., ChatGPT [3] and GPT-4 [12].\nThis paper aims to reduce the computational costs of probability curvature-based detectors to a more manageable level. We highlight that the inefficiency issues of current approach stem from the use of purely random perturbations to estimate the probability curvature around the candidate passage. Intuitively, due to the constraint on locality, the perturbed samples often share most words and have similar semantics, i.e., they are highly correlated. As a result, characterizing the local probability curvature can be essentially optimized as (i) identifying a set of typical samples and evaluating the source LLM on them and (ii) properly interpolating the results to other samples.\nA surrogate model that maps samples to LLM probability is necessary for interpolation, and it would be beneficial if the model could also identify typical samples. Given these, we opt for the Gaussian process (GP) model due to its non-parametric flexibility, resistance to overfitting in low-data regimes, and ease of use in solving regression problems. More importantly, the Bayesian uncertainty provided by GP can effectively indicate sample typicality, as demonstrated in active learning [13]. Technically, we perform sample selection and GP fitting sequentially. At each step, we select the sample that the current GP model is most uncertain about, score it using the source LLM, and update the GP accordingly. Early stops can be invoked adaptively. After fitting, we utilize the GP, rather than the source LLM, to score numerous randomly perturbed samples to compute detection statistics. This way, we create a zero-shot LLM-generated text detector with improved query efficiency.\nWe conduct comprehensive empirical studies on diverse datasets to showcase the effectiveness and efficiency of our method. We consider popular LLMs, including GPT-2 [10] and LLaMA-65B [4]. The results show that our method outperforms DetectGPT with significant margins under the low query budget\u2014it can achieve similar performance with up to 2 times fewer queries than DetectGPT and achieve 3.7% higher AUROC at a query number of 5. We also conduct thorough ablation studies to offer better insights into the behavior of our method."
        },
        {
            "heading": "2 Related Works",
            "text": "Large language models. LLMs [10, 1, 2, 14, 3] have revolutionized the field of natural language processing by offering several advantages over previous pre-trained models [15\u201317], including a better characterization of complex patterns and dependencies in the text due to the large mode and large data, and the appealing in-context learning ability for solving downstream tasks with minimal training examples. Representative models such as GPT-3 [1], PaLM [2], and ChatGPT [3] have showcased their remarkable ability to generate text with high coherence, fluency, and semantic relevance. They can even effectively address complex inquiries related to science, mathematics, history, current events, and social trends. Therefore, it is increasingly important to effectively regulate the use of LLMs to prevent significant social issues.\nLLM-generated text detection. Previous methods can be broadly categorized into two groups. The first group of methods performs detection in a zero-shot manner [7, 18, 9], but they require access to the source model that generates the texts to derive quantities like output logits or losses for detection. For instance, [7] suggests that a higher log probability for each token indicates that the text is likely to be machine-generated. When the output logits/losses of the source model are unavailable, these methods rely on a proxy model for detection. However, there is often a substantial gap between the proxy model and the source model from which the text is generated, leading to unsatisfactory detection performance. Another group of methods trains DNN-based classifiers on collected human-written and machine-generated texts for detection [19, 20, 6]. However, such detectors are purely data-driven and data-hungry, and may exhibit poor generalization ability when facing domain shift [21, 20]. Furthermore, training DNN-based classifiers is susceptible to backdoor attacks [22] and adversarial attacks [23]. Besides, [24] provides a survey of some automatic detection methods and identifies future directions for building useful detectors; [23] develops a benchmark for evaluating existing detection methods and calls for more robust detection methods."
        },
        {
            "heading": "3 Methodology",
            "text": "This section begins by briefly reviewing DetectGPT [9] and highlighting its inefficiencies, so as to justify the need for a surrogate model. We then emphasize the importance of being Bayesian and provide a comprehensive discussion on the specification of the surrogate model. Finally, we delve into the strategy for selecting typical samples based on Bayesian uncertainty. We provide an intuitive overview of our method in Fig. 1."
        },
        {
            "heading": "3.1 Preliminary",
            "text": "We consider the zero-shot LLM-generated text detection problem, which essentially involves binary classification to judge whether a text passage originates from a language model or not. Zero-shot detection implies we do not require a dataset composed of human-written and LLM-generated texts to train the detector. Instead, following common practice [7, 5, 8, 9], we assume access to the source LLM to score the inputs, based on which the detection statistics are constructed.\nDetectGPT [9] is a representative work in this line. It utilizes the following measure to determine if a text passage x is generated from a large language model p\u03b8:\nlog p\u03b8(x)\u2212 Ex\u0303\u223cq(\u00b7|x) log p\u03b8(x\u0303), (1) where q(\u00b7|x) is a perturbation distribution supported on the semantic neighborhood of the candidate text x. For example, q(\u00b7|x) can be defined with manual rephrasings of x while maintaining semantic similarity. DetectGPT, in practice, instantiates q(\u00b7|x) with off-the-shelf pre-trained mask-filling models like T5 [25] to avoid humans in the loop.\nFor tractablility, DetectGPT approximates Eq. (1) with Monte Carlo samples {xi}Ni=1 from q(\u00b7|x):\nlog p\u03b8(x)\u2212 1\nN N\u2211 i=1 log p\u03b8(xi) =: \u2113(x, p\u03b8, q). (2)\nBased on the hypothesis that LLM-generated texts should locate in the local maxima of the log probability of the source LLM, it is expected that \u2113(x, p\u03b8, q) is large for LLM-generated texts but small for human-written ones, and thus a detector emerges. Despite good performance, DetectGPT is costly because detecting one single candidate text hinges on N + 1 (usually, N \u2265 100) queries to the source model p\u03b8, which can lead to prohibitive overhead when applied to commercial LLMs."
        },
        {
            "heading": "3.2 Improve Query Efficiency with a Surrogate Model",
            "text": "Intuitively, we indeed require numerous perturbations to reliably estimate the structure of the local probability curvature around the candidate text x due to the high dimensionality of texts. However,\ngiven the mask-filling nature of the perturbation model and the requirement for semantic locality, the samples to be evaluated, referred to as X = {xi}Ni=0,3 share a substantial amount of content and semantics. Such significant redundancy and high correlation motivate us to select only a small set of typical samples for scoring by the source LLM and then reasonably interpolate the scores to other samples (see Fig. 1). This way, we obtain the detection measure in a query-efficient manner.\nA surrogate model that maps samples to LLM probability is required for interpolation, which should also help identify typical samples if possible. The learning of the model follows a standard regression setup. Let Xt = {xti}Ti=0 \u2282 X,4 denote a subset of typical samples selected via some tactics and yt = {log p\u03b8(xti)}Ti=0 the corresponding log-probabilities yielded by the source LLM. The surrogate model f : X \u2192 R is expected to fit the mapping from Xt to yt, while being able to generalize reasonably to score the other samples in place of the source LLM."
        },
        {
            "heading": "3.3 The Bayesian Surrogate Model",
            "text": "Before discussing how to select the typical samples, it is necessary to clarify the specifications of the surrogate model. In our approach, we fit a dedicated surrogate model for each piece of text x, and it approximates the source LLM only in the local region around x. This allows us to avoid the frustrating difficulty of approximating the entire probability distribution represented by the source LLM, and work with lightweight surrogate models as well as good query efficiency.\nThe surrogate model f is expected to be trained in the low-data regime while being expressive enough to handle non-trivial local curvature and not prone to overfitting. Additionally, the model should inherently incorporate mechanisms for typical sample selection. Given these requirements, we chose to use a Gaussian process (GP) model as the surrogate model due to its non-parametric flexibility, resistance to overfitting, and capability to quantify uncertainty [26]. Parametric models such as neural networks cannot meet all of these requirements simultaneously.\nConcretely, consider a GP prior in function space, f(x) \u223c GP(0, k(x,x\u2032)), where the mean function is set to zero following common practice and k(x,x\u2032) refers to the kernel function. Consider a Gaussian likelihood with noise variance \u03c32 for this problem, i.e., y(x)|f(x) \u223c N (y(x); f(x), \u03c32). Posterior predictive. It is straightforward to write down the posterior distribution of the function values fX\u2217 for unseen samples X\u2217 = {x\u2217i }Mi=1, detailed below p(fX\u2217 |Xt,yt,X\u2217) = N (f\u0304\u2217,\u03a3\u2217) (3) where\nf\u0304\u2217 := kX\u2217,Xt [kXt,Xt + \u03c3 2I]\u22121yt \u03a3\u2217 := kX\u2217,X\u2217 \u2212 kX\u2217,Xt [kXt,Xt + \u03c32I]\u22121kXt,X\u2217 . (4)\nkX\u2217,Xt \u2208 RM\u00d7(T+1),kXt,Xt \u2208 R(T+1)\u00d7(T+1),kX\u2217,X\u2217 \u2208 RM\u00d7M are evaluations of the kernel k. With this, we can analytically interpolate scores from the typical samples to new test samples.\nText kernel. It should be noted that the GP model described above is designed to operate within the domain of natural language, meaning traditional kernels like RBF and polynomial kernels are not suitable. To address this challenge, we draw inspiration from BertScore [27], which has demonstrated a good ability to capture similarities between text passages. We make a straightforward modification to BertScore, resulting in the following kernel:\nk(x,x\u2032) := \u03b1 \u00b7 BertScore(x,x\u2032) + \u03b2 (5) where \u03b1 \u2208 R+ and \u03b2 \u2208 R are two hyperparameters to boost flexibility. Other symmetric positive semi-definite kernels defined on texts are also applicable here.\nHyperparameter tuning. To make the hyperparameters \u03b1, \u03b2, and \u03c32 suitable for the data at hand, we optimize them to maximize the log marginal likelihood of the targets yt, a canonical objective for hyperparameter tuning for Bayesian methods:\nlog p(yt|Xt, \u03b1, \u03b2, \u03c32) \u221d \u2212[y\u22a4t (kXt,Xt + \u03c32I)\u22121yt + log |kXt,Xt + \u03c32I|], (6) where \u03b1 and \u03b2 exist in the computation of kXt,Xt . We can make use of AutoDiff libraries to perform gradient-based optimization of the hyperparameters directly. Since the number of samples in Xt is\n3If not misleading, x0 denotes the original candidate text x. 4We constrain t0 = 0 to include the original text x0 in Xt.\nAlgorithm 1 Efficient detection of LLM-generated texts with a Bayesian surrogate model. 1: Input: Text passage x, LLM p\u03b8 , perturbation model q(\u00b7|x), kernel k(x, x\u2032), hyperparameters \u03b1, \u03b2, \u03c32,\nsample sizes N,T, S, detecting threshold \u03b4. 2: Output: True/false indicating whether the text passage x comes from the LLM p\u03b8 or not. 3: Perform rephrasing with q(\u00b7|x), obtaining perturbations X = {xi}Ni=0; 4: Randomly initialize the typical set Xt and the set X\u2217 for selection; 5: yt \u2190 log p\u03b8(Xt); 6: while |Xt| < T or other early stop criteria have not been satisfied do 7: Optimize the hyperparameters \u03b1, \u03b2, and \u03c32 according to Eq. (6) given Xt and yt; 8: Estimate the predictive covariance \u03a3\u2217 for X\u2217 detailed in Eq. (4); 9: Identify the sample in X\u2217 with the largest uncertainty (i.e., the diagonal element of \u03a3\u2217);\n10: Score this sample with the LLM; 11: Append the sample and the target to Xt and yt respectively; 12: Approximately estimate the detection measure \u2113(x, p\u03b8, q) with the resulting GP model; 13: Return True if \u2113(x, p\u03b8, q) > \u03b4 else False;\ntypically less than 100, the computational resources required for calculating matrix inversion and log-determinant are negligible."
        },
        {
            "heading": "3.4 Sequential Selection of Typical Samples",
            "text": "As discussed above, once we obtain the set of typical samples, we can effortlessly score new samples using the GP model. We next describe how to use Bayesian uncertainty to identify the typical samples.\nIn our case, the typicity of a text sample depends on the surrogate model. If the surrogate model can accurately predict the score for the sample, it should not be considered typical, and vice versa. However, relying on the ground-truth score to measure typicity is query-intensive, and hence impractical.\nFortunately, in Bayesian methods, there is often a correlation between the model\u2019s prediction accuracy and uncertainty, with higher uncertainty implying lower accuracy [28\u201330]. This allows us to leverage the Bayesian uncertainty of the employed GP model to select typical samples sequentially. We should choose samples with high predictive uncertainty, i.e., samples the model is likely to predict inaccurately. Interestingly, such an uncertainty-based selection strategy has similarities with those used in active learning [13, 31], indicating the soundness of our approach. Our approach also resembles a Bayesian optimization program that finds points maximizing an acquisition function [32]. In our case, the acquisition contains only the uncertainty term.\nSpecifically, we perform data selection and model fitting alternately, with the following details.\nInitlization. We initialize Xt with a random subset of X, i.e., Xt = {xti}Si=0, 1 \u2264 S < T . Unless otherwise specified, we set S = 2, where the first sample refers to the original candidate text and the second a random perturbation of it. We use yt to denote the corresponding ground-truth scores.\nModel fitting. Optimize the hyperparameters of the GP model on data (Xt,yt) to maximize the log marginal likelihood defined in Eq. (6).\nData selection. Denote by X\u2217 the samples for selection. It can be the complement of Xt in X or other random perturbations around the candidate x. Compute the covariance matrix \u03a3\u2217 defined in Eq. (4), whose diagonal elements correspond to the predictive uncertainty of samples in X\u2217. Augment the sample with the largest uncertainty to Xt, and append its score yielded by the source LLM to yt.\nAdaptive exit. If the size of Xt equals T or a specific stop criterion is satisfied, e.g., the largest uncertainty is lower than a threshold, the program exits from the model fitting and data selection loop.\nEstimation of detection measure. We use the resulting GP model to compute the approximate log probability for all samples in X, and hence get an estimation of the detection measure \u2113(x, p\u03b8, q).\nWe depict the overall algorithmic procedure in Algorithm 1. We clarify our method also applies to situations where only a proxy of the source LLM is available, as demonstrated in Section 4.3. Despite decreasing the number of queries to the source LLM, our method needs to estimate the BertScore in the local environment frequently."
        },
        {
            "heading": "4 Experiments",
            "text": "We conduct extensive experiments to evaluate the efficiency and efficacy of our method for zero-shot LLM-generated text detection. We mainly compare our method to DetectGPT [9] because (i) both works adopt the same detection measure, and (ii) DetectGPT has proven to defeat prior zero-shot and supervised methods consistently. We are primarily concerned with detecting under a low query budget and admit that our method would perform similarly to DetectGPT if queries to the source model can be numerous. We also consider a black-box variant of the task where only a proxy of the source LLM is available for detection. We further qualitatively analyze the behavioral difference between our method and DetectGPT and showcase the limitations of our method.\nDatasets. Following DetectGPT [9], we primarily experiment on three datasets, covering news articles sourced from the XSum dataset [33], which represents the problem of identifying fake news, paragraphs from Wikipedia drawn from the SQuAD contexts [34], which simulates the detection of machine-generated academic essays, and prompted stories from the Reddit WritingPrompts dataset [35], which indicates the recognition of LLM-created creative writing submissions. These datasets are representative of a variety of common domains and use cases for LLM. We let the LLMs expand the first 30 tokens of the real text to construct generations. Refer to [9] for more details.\nEvaluation Metric. The detection of LLM-generated texts is actually a binary classification problem. Thereby, we use the area under the receiver operating characteristic curve (AUROC) as the key metric to evaluate the performance of the corresponding detectors (i.e., classifiers).\nThe LLMs of concern. We focus on two widely used open-source LLMs: GPT-2 [10] and LLaMA65B [4]. GPT-2 is an LLM that leverages the strengths of the GPT architecture. On the other hand, LLaMA-65B has gained more attention recently for its ability to build customized chatbots. It should be noted that the 65B-parameter LLaMA is the largest variant in the LLaMA family, and evaluating our method on this variant can effectively demonstrate its practical value and effectiveness.\nHyperparameters. Most hyperparameters regarding the perturbation model, i.e., q(\u00b7|x), follow DetectGPT [9]. We use T5-large when detecting samples from GPT-2 and T5-3B when detecting samples from LLaMA-65B. Unless otherwise specified, we set the sample size N for estimating the detection measure to 200 and S to 2. We tune the hyperparameters associated with the GP model with an Adam optimizer [36] using a learning rate of 0.01 (cosine decay is deployed) for 50 iterations."
        },
        {
            "heading": "4.1 Detection of GPT-2",
            "text": "We first compare our method to DetectGPT in detecting contents generated by GPT-2.\nSpecifically, we evaluate the detection performance of DetectGPT and our method with the query budget continually increasing. Letting Q denote the query budget, DetectGPT uses Q\u2212 1 random perturbations to estimate the detection measure \u2113(x, p\u03b8, q). In contrast, our method uses Q\u22121 typical samples for fitting the surrogate model and still uses a large number of random perturbations (as stated, 200) to estimate \u2113, which is arguably more reliable.\nIn Fig. 2, we present a comparison of detection AUROC on the datasets mentioned earlier. To reduce the influence of randomness, we report average results and variances over three random runs. For a comprehensive comparison, we also draw the performance of DetectGPT using 20 and 30 queries in the figure. As shown, our method outperforms DetectGPT significantly, achieving faster performance gains, particularly under a lower query budget. Notably, our method using only 10 queries can outperform DetectGPT using 20 queries in all three cases.\nInterestingly, our method can already surpass DetectGPT in the 2-query case, especially on the WritingPrompts dataset. In that case, our method fits a GP model with only the original text passage as well as a random perturbation. This result confirms that the GP-based surrogate model is highly data-efficient and excels at interpolating the scores of typical samples to unseen data. Furthermore, DetectGPT\u2019s performance gain with increasing query times is slow on the WritingPrompts dataset, as its detection AUROCs using 16, 20, and 30 queries are similar. In contrast, our method does not face this issue. Given that the variances are minor compared to the mean values, we omit repeated random runs in the following analysis.\nImpact of the perturbation model. The perturbation model used in the above studies is the T5-large model. We then question whether replacing it with a more powerful model results in higher detection performance. For an answer, we introduce the T5-3B model as the perturbation model and conduct a similar set of experiments, with the results displayed in Fig. 3.\nAs shown, the detection performance of DetectGPT and our method is substantially improved compared to the results in Fig. 2, indicating the higher ability of T5-3B to perturb in the semantic space. Still, our method consistently surpasses DetectGPT in these scenarios and it achieves similar performance with up to 2\u00d7 fewer queries than DetectGPT. In particular, the average AUROCs of our method at query times of 5 and 10 are 0.897 and 0.932 respectively while those for DetectGPT are 0.860 and 0.909. This highlights the high query efficiency of our surrogate model-based detector."
        },
        {
            "heading": "4.2 Detection of LLaMA-65B",
            "text": "As GPT-2 is limited in model size and capacity, we extend our evaluation to the LLaMA family [4] and focus on the largest variant, LLaMA-65B, to thoroughly investigate the practical application value of our method. LLaMA-65B is trained on a diverse range of web text and conversational data and has gained recent attention for its ability to build customized chatbots. The texts generated by LLaMA-65B are of exceptional quality and coherence, closely resembling texts written by humans.\nGiven the previous studies, we use T5-3B as the perturbation model in this case. Due to the non-trivial resource consumption of deploying LLaMA-65B, we consider the range of query times only up to 11. Nevertheless, we still include DetectGPT under 15 and 20 query budgets to emphasize the query-saving effects of our method. We display the comparison between DetectGPT and our method in Fig. 4, where the three datasets and various query budgets are also considered.\nAs shown, our method continues to outperform DetectGPT on XSum and WritingPrompts. Notably, in WritingPrompts, the performance gain of our method is even more substantial than in previous\nexperiments. With just 4 queries, our method exceeds DetectGPT\u2019s performance with 20 queries by a significant margin. We also find DetectGPT has difficulties realizing better detection under a higher query budget in this case, implying the inherent inefficiency of random perturbation-based detection.\nThe results on SQuAD are of more interest, where both our method and DetectGPT give a detection AUROC below 50%. This suggests that the probability curvature hypothesis postulated in [9] does not apply to the texts generated by LLaMA-65B based on the initial Wikipedia paragraphs sourced from SQuAD contexts. The possible reasons include (1) the generations do not locate around the local maxima of the model likelihood of LLaMA-65B; (2) the real texts in this dataset instead have higher model likelihood. We visualize some real texts and generated ones by LLaMA-65B in Appendix and found it hard to draw an intuitive conclusion. We leave an in-depth investigation as future work."
        },
        {
            "heading": "4.3 Cross Evaluation",
            "text": "In line with current trends in zero-shot LLM-generated text detection [7, 5, 8, 9], the above studies assume a white-box setting, where the LLM is directly utilized to detect its generations. However, in practice, we may not know which model the candidate passage was generated from. An alternative approach is to detect using a proxy model that provides an approximate estimate of the log probability of the source model [9].\nIn this section, we examine the impact of doing this on the final detection performance. To reduce costs, we consider using GPT-J [37], GPT-Neo-2.7 [38], and GPT-2 as the source and proxy models and evaluate the detection AUROC across all 9 source-proxy combinations. We present the average performance across 200 samples from XSum, SQuAD, and WritingPrompts in Fig. 5.\nAs demonstrated, using the same model for both generating and scoring yields the highest detection performance, but employing a scoring model different from the source model can still be advantageous. The column mean represents the quality of a scoring model, and our results suggest that GPT-Neo-2.7 is more effective in accounting for scoring. Furthermore, we observe significant improvements (up to 3% AUROC) in our method\u2019s results over DetectGPT, indicating the generalizability of our approach."
        },
        {
            "heading": "4.4 More Studies",
            "text": "To better understand our method, we lay out the following additional studies.\nHow does our method behave differently from DetectGPT? We are interested in how our method achieves better detection performance than DetectGPT. To chase an intuitive answer, we collect some human-written texts from the considered three datasets as well as the generated texts from GPT-2, and compute the detection measure \u2113(x, p\u03b8, q) estimated by DetectGPT and our method under a query budget of 15 and the T5-large perturbation model. We list the results in the Appendix due to space constraints. We find that (1) Our method\u2019s estimation of \u2113 is usually higher than DetectGPT. Recalling the expression of \u2113, we conclude our method can usually select samples with substantially lower log p\u03b8 than random samples. (2) Our method can occasionally produce too high or too low \u2113 for texts written by humans. This could be attributed to the fact that using a limited number of typical samples may fail to reliably capture the local curvature when it is ill-posed or complex.\nThe visualization of typical samples. As depicted in Fig. 1, typical samples have a direct physical meaning in toy cases. However, it is unclear whether this property can be maintained in the highdimensional space in which texts exist. To investigate this, we conducted a simple study based on the text passage, \u201cJoe Biden recently made a move to the White House.\u201d Specifically, we perturb it with the rewriting function of ChatGPT [3] for 50 times, and simulate the sequential procedure of typical sample selection. We present the original text and the first 11 typical samples in Fig. 6. We also display the BertScore among them as well as the log probabilities log p\u03b8 of GPT-2 for them. As shown, the row mean exhibits a clear increasing trend as the index of the typical sample increases, indicating that the later selected samples are becoming more similar to the earlier ones. In other words, the uniqueness or typicality of the selected samples decreases over the course of the selection process. This phenomenon is consistent with our expectations for the selected samples and confirms the effectiveness of our uncertainty-based selection method."
        },
        {
            "heading": "5 Conclusion and Social Impact",
            "text": "This paper tackles the issue that the existing probability curvature-based method for detecting LLMgenerated text requires using the source model to score a significant number of texts when detecting a candidate text passage. To address this, we introduce a Bayesian surrogate model to identify typical samples and then interpolate their scores to other samples. We use a Gaussian process regressor to instantiate the surrogate model and perform an online selection of typical samples based on Bayesian\nuncertainty. Extensive empirical studies on various datasets, using GPT-2 and LLaMA-65B, validate the superior effectiveness and efficiency of our method over DetectGPT. Additionally, we provide insightful visualizations to better understand the behavior of our method.\nA limitation is that our method is not compatible with parallel computing due to the sequential nature of sample selection. Regarding the social impact, we emphasize that detecting LLM-generated text is crucial in preventing serious social problems that may arise from the misuse of LLMs. For instance, LLM-generated text could be used to spread false information, manipulate public opinion, or even incite violence. Furthermore, the misuse of LLMs can erode trust in information sources and exacerbate existing societal issues, such as misinformation and polarization. Effective detection approaches are crucial in addressing these issues."
        },
        {
            "heading": "A Comparison between Real Texts and Generated Texts from LLaMA-65B on SQuAD",
            "text": "We list some randomly selected texts in Fig. 7, where the first 30 tokens of the real texts (highlighted in red) are used to prompt generation."
        },
        {
            "heading": "B The Behavioral Difference between DetectGPT and Our Method",
            "text": "We collect some human-written texts and generated texts from GPT-2, meanwhile computing the detection measure \u2113(x, p\u03b8, q) estimated by DetectGPT and our method under a query budget of 15 and the T5-large perturbation model. We present the results in Table 1."
        }
    ],
    "title": "Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model",
    "year": 2023
}