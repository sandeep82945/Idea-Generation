{
    "abstractText": "In a recirculating aquaculture system (RAS), feeding is an important factor affecting the growth of breeding objects. The traditional feeding methods relied on manual experience, which resulted in high labor costs and bait waste. To deal with these challenges, this paper proposes a dynamic scene images-assisted intelligent control method for industrial feeding through deep vision learning. First, a feeding video is processed according to the interframe difference method to obtain the image of the feeding state of the fish. Then, a modified VGG16 model is developed to determine the feeding state of the fish, transform it into a binary classification problem, and calculate the feeding frequency of the fish. After that, residual bait detection is deployed by adapting the YOLOv5 model. The results of the feeding frequency and the residual bait detection are then used to develop an intelligent feeding strategy to improve the growth rate of the fish and the conversion rate of the bait. Experimental tests on real-world scene images showed that the accuracy of identifying the feeding state by the modified VGG16 model reaches 92.4%. Through the verification of the medium-size RAS, compared with the traditional feeding method, the intelligent feeding method significantly saves manpower and reduce 15% of bait waste. \u00a9 2022 SPIE and IS&T [DOI: 10.1117/1.JEI.32.2.021611]",
    "authors": [
        {
            "affiliations": [],
            "name": "Junchao Yang"
        },
        {
            "affiliations": [],
            "name": "Yufeng Zhang"
        },
        {
            "affiliations": [],
            "name": "Lulu Jia"
        },
        {
            "affiliations": [],
            "name": "Qin Zhang"
        },
        {
            "affiliations": [],
            "name": "Chunyang Hu"
        },
        {
            "affiliations": [],
            "name": "Zhiwei Guo"
        },
        {
            "affiliations": [],
            "name": "Yu Shen"
        }
    ],
    "id": "SP:75ae96f4c135ee218f5e7247038ebdfa5fade7af",
    "references": [
        {
            "authors": [
                "X. Ta",
                "Y. Wei"
            ],
            "title": "Research on a dissolved oxygen prediction method for recirculating aquaculture systems based on a convolution neural network,",
            "venue": "Comput. Electron. Agric",
            "year": 2018
        },
        {
            "authors": [
                "W. Hu et al.",
                "\u201cDeveloping intelligent feeding systems based on deep learning",
                "\u201d in ACM ICEA \u201920"
            ],
            "title": "2020 ACM Int",
            "venue": "Conf. Intell. Comput. and Its Emerg. Appl., December 12-15, GangWon Republic of Korea, ACM, pp. 13:1\u201313:2",
            "year": 2020
        },
        {
            "authors": [
                "B. Zhu"
            ],
            "title": "Efficient offloading for minimizing task computation delay of NOMA-based multiaccess edge computing,",
            "venue": "IEEE Trans. Commun",
            "year": 2022
        },
        {
            "authors": [
                "M.G.B. Palconit"
            ],
            "title": "Multi-gene genetic programming of iot water quality index monitoring from fuzzified model for Oreochromis niloticus recirculating aquaculture system,",
            "venue": "J. Adv. Comput. Intell. Intell. Informatics",
            "year": 2022
        },
        {
            "authors": [
                "Y. Li"
            ],
            "title": "Optimized content caching and user association for edge computing in densely deployed heterogeneous networks,",
            "venue": "IEEE Trans. Mob. Comput",
            "year": 2022
        },
        {
            "authors": [
                "C. Chen"
            ],
            "title": "Hierarchical domain-based multi-controller deployment strategy in SDN-enabled space-air-ground integrated network,",
            "venue": "IEEE Trans. Aerosp. Electron. Syst",
            "year": 2022
        },
        {
            "authors": [
                "G. Wang et al.",
                "\u201cEvolution of intelligent feeding system for aquaculture"
            ],
            "title": "a review,\u201d in 3rd Int",
            "venue": "Conf. Artif. Intell. and Adv. Manuf., AIAM 2021, October 23-25, Manchester, IEEE, pp. 392\u2013397",
            "year": 2021
        },
        {
            "authors": [
                "X. Hu"
            ],
            "title": "Real-time detection of uneaten feed pellets in underwater images for aquaculture using an improved YOLO-V4 network,",
            "venue": "Comput. Electron. Agric",
            "year": 2021
        },
        {
            "authors": [
                "Z. Guo"
            ],
            "title": "Deep federated learning enhanced secure POI microservices for cyberphysical systems,",
            "venue": "IEEE Wireless Commun",
            "year": 2022
        },
        {
            "authors": [
                "S. H"
            ],
            "title": "AlZubi et al., \u201cAn intelligent behavior-based fish feeding system,",
            "venue": "Int. MultiConf. Syst., Signals & Devices, SSD 2016,",
            "year": 2016
        },
        {
            "authors": [
                "L. Huang"
            ],
            "title": "Throughput guarantees for multi-cell wireless powered communication networks with non-orthogonal multiple access,",
            "venue": "IEEE Trans. Veh. Technol",
            "year": 2022
        },
        {
            "authors": [
                "C. Wu"
            ],
            "title": "Underwater trash detection algorithm based on improved YOLOv5s,",
            "venue": "J. Real Time Image Process",
            "year": 2022
        },
        {
            "authors": [
                "Z. Cai",
                "Z. Duan",
                "W. Li"
            ],
            "title": "Exploiting multi-dimensional task diversity in distributed auctions for mobile crowdsensing,",
            "venue": "IEEE Trans. Mob. Comput",
            "year": 2021
        },
        {
            "authors": [
                "C. Zhou"
            ],
            "title": "Computer vision and feeding behavior based intelligent feeding controller for fish in aquaculture,",
            "venue": "in Comput. and Comput. Technol. in Agric. XI - 11th IFIP WG 5.14 Int. Conf., CCTA 2017, Jilin,",
            "year": 2017
        },
        {
            "authors": [
                "L. Zhao et al.",
                "\u201cElite"
            ],
            "title": "an intelligent digital twin-based hierarchical routing scheme for softwarized vehicular networks,\u201d IEEE Trans",
            "venue": "Mob. Comput.",
            "year": 2022
        },
        {
            "authors": [
                "C.K. Gokcek",
                "Y. Mazlum"
            ],
            "title": "Akyurt, \u201cEffect of feeding frequency on the growth and survival of himri barbel barbus luteus (heckel, 1843), fry under laboratory conditions,",
            "venue": "Pakistan J. Nutr",
            "year": 2008
        },
        {
            "authors": [
                "T. Itoh",
                "S. Tsuji",
                "A. Nitta"
            ],
            "title": "Swimming depth, ambient water temperature preference, and feeding frequency of young pacific bluefin tuna (thunnus orientalis) determined with archival tags,",
            "year": 2003
        },
        {
            "authors": [
                "J. Kolarevic"
            ],
            "title": "The use of acoustic acceleration transmitter tags for monitoring of atlantic salmon swimming activity in recirculating aquaculture systems (ras),",
            "venue": "Aquacult. Eng. 72,",
            "year": 2016
        },
        {
            "authors": [
                "G. Rakowitz"
            ],
            "title": "Use of high-frequency imaging sonar (didson) to observe fish behaviour towards a surface trawl,",
            "venue": "Fish. Res. 123,",
            "year": 2012
        },
        {
            "authors": [
                "G. Dong"
            ],
            "title": "Diet feeding rhythm and gastrointestinal evacuation time of juvenile channel catfish and hybrid sturgeon,",
            "venue": "Acta Hydrobiol. Sin",
            "year": 2013
        },
        {
            "authors": [
                "C. Zhou"
            ],
            "title": "Near-infrared imaging to quantify the feeding behavior of fish in aquaculture,",
            "venue": "Comput. Electron. Agric",
            "year": 2017
        },
        {
            "authors": [
                "J. Zhao"
            ],
            "title": "Spatial behavioral characteristics and statistics-based kinetic energy modeling in special behaviors detection of a shoal of fish in a recirculating aquaculture",
            "venue": "system,\u201d Comput. Electron. Agric",
            "year": 2016
        },
        {
            "authors": [
                "T. Zhou"
            ],
            "title": "Automatic detection of underwater small targets using forward-looking sonar images,",
            "venue": "IEEE Trans. Geosci. Remote Sens. 60,",
            "year": 2022
        },
        {
            "authors": [
                "S. Xia"
            ],
            "title": "Online distributed offloading and computing resource management with energy harvesting for heterogeneous mec-enabled iot,",
            "venue": "IEEE Trans. Wireless Commun",
            "year": 2021
        },
        {
            "authors": [
                "S. Llorens"
            ],
            "title": "Detection and target strength measurements of uneaten feed pellets with a single beam echosounder,",
            "venue": "Aquacult. Eng",
            "year": 2017
        },
        {
            "authors": [
                "D. Li",
                "L. Xu",
                "H. Liu"
            ],
            "title": "Detection of uneaten fish food pellets in underwater images for aquaculture,",
            "venue": "Aquacult. Eng",
            "year": 2017
        },
        {
            "authors": [
                "Y. Yu"
            ],
            "title": "Real-time underwater maritime object detection in side-scan sonar images based on transformer-yolov5,",
            "venue": "Remote. Sens. 13(18),",
            "year": 2021
        },
        {
            "authors": [
                "Z. Shen et al.",
                "\u201cDeformableGAN"
            ],
            "title": "generating medical images with improved integrity for healthcare cyber physical systems,\u201d IEEE Trans",
            "venue": "Network Sci. Eng.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Guo"
            ],
            "title": "Deep information fusion-driven POI scheduling for mobile social networks,",
            "venue": "IEEE Network 36(4),",
            "year": 2022
        },
        {
            "authors": [
                "D. Li"
            ],
            "title": "Automatic recognition methods of fish feeding behavior in aquaculture: a review,",
            "venue": "Aquaculture 528,",
            "year": 2020
        },
        {
            "authors": [
                "Z. Guo"
            ],
            "title": "Hybrid intelligence-driven medical image recognition for remote patient diagnosis in internet of medical things,",
            "venue": "IEEE J. Biomed. Health",
            "year": 2021
        },
        {
            "authors": [
                "Z. Cai",
                "X. Zheng",
                "J. Yu"
            ],
            "title": "A differential-private framework for urban traffic flows estimation via taxi companies,",
            "venue": "IEEE Trans. Ind. Inf",
            "year": 2019
        },
        {
            "authors": [
                "X. Zheng",
                "Z. Cai"
            ],
            "title": "Privacy-preserved data sharing towards multiple parties in industrial iots,",
            "venue": "IEEE J. Sel. Areas Commun",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Keywords: dynamic scene images; deep learning; intelligent control; industrial feeding.\nPaper 220845SS received Aug. 19, 2022; accepted for publication Nov. 1, 2022; published online Nov. 18, 2022."
        },
        {
            "heading": "1 Introduction",
            "text": "In recent years, with the economic growth and social development, the market demand for fish is increasing.1 As a result, fish farming has developed rapidly, but traditional farming methods not only lead to problems such as environmental degradation and shrinking resources, but also are susceptible to temperature seasons and other unexpected factors.2,3 Moreover, the damage to the environment caused by traditional farming methods affects not only the economic value of fish but also human health.4,5 Hence, the recirculating aquaculture system has received a lot of attention. The recirculating aquaculture system is a breeding model in which the water resources are purified and treated by a circulating water system and then recycled.6 The key technology of the recirculating aquaculture system is the purification treatment of aquaculture water and the rapid removal of harmful substances.7\nThe advantages of RAS are summarized as follows. First, it uses less water with low water quality, and water resources can be recycled. Second, it has a very low demand for land resources. Third, its breeding environment is easy to control and less affected by the external climate, which can more easily meet the needs of different breeding objects. Fourth, it discharges less\n*Address all correspondence to Chunyang Hu, huchunyangcs@163.com; Yu Shen, shenyu@ctbu.edu.cn\n1017-9909/2022/$28.00 z\u00a9 2022 SPIE and IS&T\nJournal of Electronic Imaging 021611-1 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe tra\nct d\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nwaste and has less impact on the environment.8 RAS accords with the concept of energy savings and emission reduction, the circular economy, and sustainable development.9,10\nFeeding is an important component of the breeding process in RAS.11,12 Low feeding frequency cannot ensure that fish have enough food to maintain normal survival and growth.13 However, excessive feeding not only reduces the conversion efficiency of bait but also increases breeding costs and causes pollution to the breeding environment. Therefore, in the breeding process of fish, reasonable feeding according to feeding frequency is essential.14 At present, feeding strategies are often formulated according to the feeding rhythm of breeding objects, and mechanical equipment is used for regular and quantitative feeding. Feeding time should be determined according to the feeding rhythm of the breeding objects to achieve the purpose of reducing bait waste and improving the growth efficiency of breeding objects and impurities and oxygenation technology.15,16 However, the feeding strategy tends to result in overfeeding or underfeeding when there are changes in the breeding object and breeding environment.\nAt present, a large number of scholars have studied the feeding frequency and intelligent feeding of fish. The main research methods include artificial experience, biological energy, machine acoustics, and computer vision. Gokcek et al.17 used the specific growth rate (SGR) and feed conversion ratio (FCR) to analyze the data using a one-way analysis of variance (ANOVA) to determine the bait requirements of fish. Itoh et al.18 implanted archival tags in fish. The archival tags recorded temperature changes in viscera that appeared to be caused by feeding, and those changes indicate that fish\u2019s common duration of feeding. However, this method needs to measure a mass of biological data and cannot achieve the purpose of precise feeding.\nResearch on the acoustic detection of fish behavior has attracted wide attention. Kolarevic et al.19 and Rakowitz et al.20 collected data through high-frequency imaging sonar and acoustic tags. The feeding frequency of fish was calculated based on the changes in fish behavior. However, this method had high noise requirements for the breeding environment, which makes applying it to real production practice difficult.21\nIn the study of fish feeding behavior, a considerable number of scholars have conducted research through computer vision techniques. Zhou et al.22 evaluated the changes in fish feeding behavior through Delaunay triangulation. Zhao et al.23 evaluated the feeding frequency by improving the kinetic energy model to detect the dispersion and aggregation behavior of fish. But the above methods are more suitable for low-density breeding environments. Research results show that using computer vision to analyze the feeding behavior of fish is available to calculate the feeding frequency.\nAlthough the aforementioned methods have good effects on bait consumption and feeding frequency, there are some shortcomings such as low labor efficiency, high technical difficulty, and high requirements for the aquaculture environment.24 In contrast, computer vision techniques have the advantages of high accuracy, high efficiency, and absence of contact, and they have become important research methods in the detection and analysis of fish.25 Therefore, to achieve better results of precise feeding, we introduce a feedback control mechanism to help formulate feeding strategies. The feeding status of the breeding objects was detected by automatic monitoring technology, and then the feeding frequency was quantified. Finally, the feeding strategy was dynamically adjusted according to the feeding frequency to achieve a better feeding effect and reduce bait waste . Therefore, this paper proposes a detection method of fish feeding frequency based on deep learning in RAS. First, we deal with the video data set of breeding ponds by interframe difference method and then use the modified VGG16 model to determine the feeding state of the fish. Thus, the feeding frequency is obtained based on the ratio of the total number of images determined by the model to be in the \u201cfeed\u201d state to the number of images in the entire feeding data set. This method can observe the feeding state of fish in real time, to achieve the purposes of precise feeding, reducing bait waste, and improving breeding efficiency.\nIn addition to judging the feeding situation of fish directly by detecting the feeding behavior of fish, we can also understand the change in the feeding demand of fish by detecting the residual bait. At present, many scholars have carried out research related to residual bait detection, and the main research methods are acoustics and machine learning. Llorens et al.26 detected the amount of residual bait in the breeding environment using a single-beam acoustic depth sounder. Although the residual bait can be detected by the acoustic method, due to the high cost of technology and ease of interference by the breeding environment, it is not suitable for recirculating aquaculture systems.\nJournal of Electronic Imaging 021611-2 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nR tra\nct\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nThe detection of residual bait by machine vision has also attracted people\u2019s attention. Li et al.27 proposed an adaptive threshold method to detect underwater residual bait, and the detection results were obtained by comparing the threshold calculated by the local intensity histogram with the center pixel of the mask. However, due to the limitations of traditional machine learning, it did not meet the requirements of fast detection speed and high accuracy, making it not conducive to the realization of real-time intelligent feeding decisions. However, with the development of deep learning technology, the emergence of the YOLOv5s model can well meet the requirements of detection speed and accuracy in residual bait detection.28 Therefore, this paper uses the YOLOv5s model to realize the real-time monitoring of residual bait. In this paper, through the calculation of fish feeding frequency and the detection of residual bait, an intelligent feeding algorithm is designed to realize the real-time formulation of feeding strategy and improve the breeding efficiency.\nThe main contributions of this paper are summarized as follows:\n\u2022 The modified VGG16 model is used to detect the feeding frequency of fish. The improved model reduces the number of parameters by 90% compared with the original without reducing the accuracy, and the number of model parameters is only 15.2M, which makes the model easier to deploy.\n\u2022 Based on the detection results of fish feeding frequency and residual bait, we propose an intelligent feeding algorithm. The method analyzes and evaluates the feeding frequency and residual bait of fish in real time using computer vision technology, and it predicts the feeding demand of fish in real time using the constructed intelligent feeding algorithm. Thus, we can reasonably judge whether to feed the fish and calculate the feeding amount to achieve the purpose of improving the utilization of bait and reducing waste.\n\u2022 A comparison experiment is set up to test the actual effects of the intelligent feeding decision algorithm. We found that the amount of bait consumed by the intelligent feeding decision algorithm was about 15% lower than that by the traditional artificial feeding method, and the change was more stable. This suggests that the intelligent feeding decision algorithm has better practical results.\nThe remainder of this paper is organized as follows. Section 2 depicts the RAS system and problem statement. Computer vision-aided residual bait detection and feeding frequency calculation for intelligent feeding are presented in Sec. 3. Performance evaluation and discussion are demonstrated in Sec. 4. Finally, Sec. 5 concludes this paper."
        },
        {
            "heading": "2 Preliminaries",
            "text": "2.1 Overview of RAS\nThe RAS is shown in Fig. 1. The whole system mainly uses biological filtration and physical filtration to deeply purify the aquaculture water to achieve the purpose of recycling.23 The main equipment of RAS is a breeding pond, microfiltration machine, circulating pump, biological pool, UV disinfection lamp, oxygenation pump, and electrified control cabinet. The breeding pond is the necessary infrastructure for the growth and feeding of aquaculture objects. The main function of the circulating pump is to assist in water filtration, which allows water to flow into the breeding pond and allows impurities to be gathered together. The main function of the oxygenation pump is increasing oxygen. The dissolved oxygen concentration affects the fish\u2019s normal growth, and oxygenation pump supplies oxygen. Equipment such as the microfiltration machine and protein skimmer filter out solid particles and colloidal substances such as fish feces and residual bait through a continuous cycle. The biological pool is the place where aquaculture water is purified by microorganisms. The UV disinfection lamp degrades chloride in the water by photolysis, so the aquaculture water can be recycled.\nIn the recirculating aquaculture system, the water discharged from the breeding pond first flows through the pipe to the microfiltration machine, which filters and separates some of the solid impurities and sticky substance in the water flow. It is then fed into the circulating pump to gather impurities for filtration. The filtered water is then transported by the circulating pump\nJournal of Electronic Imaging 021611-3 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nR tra\nct d\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nto the biological pool to remove other hazardous substances such as ammonia nitrogen and to purify the aquaculture water. Then the water is sterilized and disinfected by the UV disinfection lamp. The pure oxygen produced by the disinfected water through the pipeline and the oxygenation pump is fully mixed so the dissolved oxygen of the aquaculture water can maintain the normal life of the fish. Finally, the treated aquaculture water is transported to the breeding pond through the pipeline to maintain the normal growth of the fish.6\n2.2 Problem Statement\nAt present, most automatic feeding systems can only achieve the function of timing and quantitative feeding, which cannot be analyzed according to the changes in breeding environments and fish behavior or realize the real-time adjustment of the feeding strategy, which is not conducive to improving the breeding efficiency. The feeding time of current automatic feeding systems is often determined based on personal experience, without scientific calculation or adjustment. Therefore, when the breeding objects and breeding environment change, the system cannot be adjusted in real time. In addition, in the actual breeding process, the key to improving breeding efficiency is to obtain accurate feeding amounts and adjust the feeding strategy. However, most feeding systems are based on human experience or computerized feeding frequency and times. The feeding frequency of the bait can change depending on the type of bait, and thus the feeding frequency cannot be obtained accurately.29 The solution of feeding time and feeding amount is the key method to improve breeding efficiency.\nIn recent years, these two problems have been solved with the increase of fish farming applications of deep learning technologies.30 Deep learning technology can accurately and efficiently detect the amount of residual bait and the feeding behavior of fish. These parameters provide the possibility for realizing an intelligent feeding algorithm.31 With the development of aquaculture technology, intelligent feeding is one of the important methods to achieving the optimal feeding efficiency of aquaculture objects. In this paper, the feeding time is determined by residual bait detection, and the feeding amount is determined by feeding frequency detection; together, they are the design of an intelligent feeding algorithm. This enables the development of suitable feeding strategies in real time according to the changes in the breeding environment and the behavior of breeding objects, reducing breeding costs and improving production efficiency.\nFig. 1 Recirculating aquaculture system.\nJournal of Electronic Imaging 021611-4 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe tra\ncte\nd\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use"
        },
        {
            "heading": "3 Methodology",
            "text": "3.1 Feeding Frequency Calculation\nStudies have shown that changes in fish feeding behavior can directly reflect the feeding needs of fish. In the actual breeding process, the feed cost accounts for 40% to 80% of the total cost, so the determination of the feeding amount is the key to improving the breeding efficiency. After a large number of feeding experiments and data analysis, it was found that the initial and subsequent feeding amounts conformed to the law of exponential function distribution and were positively and linearly correlated with feeding performance. Therefore, we calculate the feeding frequency by quantifying the feeding behavior of the fish and then make an accurate calculation of the feeding amount. Faced with the problems of technical difficulty and disturbance in the breeding environment in the detection of feeding frequency, we detected the feeding frequency by the modified VGG16 model. The feeding frequency was calculated by quantifying the changes in the feeding behavior of the fish. Then combined with the results of residual bait detection, an appropriate feeding strategy was developed to reduce the cost of breeding and improve the conversion rate of bait.\n3.1.1 Calculation of feeding frequency\nThe amount of bait fed during the culture process is generally determined by the changing feeding requirements of the fish. According to the feeding habits of freshwater grouper, the bait is scattered slowly in batches at each feeding and then again after the fish finish the bait scattered in the previous feeding. Feeding bait cannot be poured into the breeding pond all at once; this causes not only bait waste and water pollution but also uneven feeding of fish. A reasonable amount of feeding not only improves the growth rate of fish and reduces the amount of residual bait but also maintains good water quality.\nFeeding frequency is the most direct reflection of changes in fish feeding requirements. Feeding frequency indicates the ratio of the total duration of fish feeding behavior occurring during the entire feeding time of the fed fish to the total feeding time. The amount of bait fed to the fish can be better determined by analyzing the changes in the feeding frequency of the fish over successive periods.\nTo calculate the feeding frequency, we turn it into a 0 to 1 classification problem. First, the feeding video is sliced into image data sets by interframe differences, and then a modified VGG16 model is used to determine the feeding status of the fish in each image after division. Finally, the ratio of the total number of images in which the state of the fish was determined to be \u201cfeed\u201d to the entire image data set is used to obtain the feeding frequency of the fish. The feeding frequency was calculated by the following equation:\nEQ-TARGET;temp:intralink-;e001;116;284freqfd \u00bc Nc N ; (1)\nwhere N represents the total number of images in the image data set divided by the interframe difference method for feeding videos and Nc represents the total number of images judged as \u201cfeed\u201d by the modified VGG16 model. By calculating the ratio of the total number of pictures determined by the model to be \u201cfeed\u201d to the total number of pictures divided by the whole feeding video, we can derive the feeding frequency.\n3.1.2 Modified VGG16\nVGG16 is a classical image classification model that has excellent performance and high accuracy in many image classification models.32 VGG16 has 13 convolution layers, 3 full connection layers, and 1 output layer. The VGG16 structure is simple, the generalization performance of migrating to other image data sets is very good, and the performance can be improved by deepening the network structure of the model. However, it has a large memory (138M) and a large number of parameters, which leads to a slower training speed of the model. And because the model has more neurons in the fully connected layer, the model is prone to over-fitting.33\nJournal of Electronic Imaging 021611-5 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nR tr\nct\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nThe data set of this experiment is not particularly large, and the original VGG16 is rather complex. Therefore, we modified VGG16 to reduce the complexity of the model. The comparison of the model structure is shown in Fig. 2. Because there are many parameters in the fully connected layer of VGG16, we choose the global average pooling layer to replace the first two fully connected layers. The number of parameters is reduced by replacing the global average pooling layer with the first two fully connected layers of the model. The model parameters are reduced to 152.2 million, about 90% less than the original VGG16. It helps a lot in simplifying VGG16, reducing the risk of over-fitting, and improving the performance of the model.\nHowever, the modified model does not change the running time of the model. As can be seen from Table 1, by computing the number of parameters and the amount of computation of the model, we found that, although the number of parameters of the model decreased from 138M to 15M, the FLOPs of the model decreased by only 1%. Moreover, the running speed of the model is also affected by factors such as hardware characteristics and the system environment. Therefore, the running speed of the modified VGG16 is not greatly affected.\n3.2 Residual Bait Detection\nThe amount of residual bait reflects the feeding of fish and is one of the important criteria for developing feeding strategies. Cichlasoma managuense has the habit of snatching food and not eating food from the bottom of the water, so it is not suitable to feed too much bait at one time to avoid uneven feeding and bait waste due to fish snatching food. Feeding fish often requires multiple feedings of bait, so how to determine the next feeding time is an important issue. And because the breeding object does not eat the food on the bottom of the water habit, we use floating bait. This bait can float on the water surface for a long time and has a color difference with the aquaculture water, which makes it easy to identify. Therefore, the amount of residual bait is visually detected and quantified, and the change in the amount of residual bait is visually\nTable 1 Comparison of model parameters.\nModel Total params GFLOPs\nGoogLeNet 5,975,600 1.58\nLetNet 25,233,964 0.15\nAlexNet 58,289,536 1.13\nVGG16 134,268,992 15.48\nModified-VGG16 15,226,688 15.39\nJournal of Electronic Imaging 021611-6 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe\ntra\nct\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nreflect the change in fish appetite. Consequently, we use the model to detect and quantify the residual bait in the breeding pond and thus determine whether to feed the fish.\nResidual bait detection belongs to the problem of target detection and identification. The YOLOv5s model has high accuracy and fast speed in target detection, which meets our requirements for residual bait detection models, so this paper implements residual bait detection by the YOLOv5s model. In the training process of the residual bait detection model, first we segment the fish feeding video into image data sets by the interframe difference method. Then the residual bait in the breeding pond of each image is labeled and then trained by the YOLOv5s model to achieve the detection and recognition of residual bait.\nYOLO is a single stage object detection network that is widely used in target detection. The YOLOv5 network is faster and more accurate than previous versions of the YOLO network. The model of YOLOv5s is smaller than the other three versions. It has the smallest network depth, the smallest width of the feature map in the YOlOv5 series, and the fastest detection speed. Facing the problems of multitarget detection, small target detection, and multiscale prediction, the YOLO algorithm can be a better solution.34 Because the bait particles in this study are small, the density of bait particles is high, and the detection speed is required to be fast among other needs. Therefore, we chose the YOLOv5s model to detect the amount of residual bait.\nThe YOLOv5s model consists of input, backbone, neck, and output, and the overall structure follows previous versions. In the input part, the model uses Mosaic data augmentation. This method not only enriches the data set but also improves the training speed of the model. The input part also adopts the adaptive anchor frame method, setting anchor frames with different initial lengths and widths for different data sets. The backbone is the main part of the network and is mainly used to process the input image. The attention structure is added in YOLOv5. The attention replaces the first three layers of the original v3 version, reducing the number of parameters and floating points and thereby increasing the speed of the model.\n3.3 Intelligent Feeding Algorithm\nIn RAS, intelligent feeding is very important for fishery management. Therefore, we designed the intelligent feeding algorithm. The intelligent feeding algorithm flow chart is shown in Fig. 3.\nWe define i as the feeding node (i \u00bc 0; 1; 2; 3; : : : ; n) and Ti as the corresponding feeding time from 0s to the current feeding node. We define Fi as the amount of bait fed at the i\u2019th feeding node, Bi as the amount of residual bait of the fish at the i\u2019th feeding node, and Vi as the feeding frequency of the fish at the i\u2019th feeding node. Moreover, we set the total feeding time of fish as 10 minutes and the total feeding amount as 500 g.\nWhen we began to feed the fish, we first put 50 g of bait to calculate the fish feeding frequency and residual bait. Then the amount of residual bait of the fish is used to determine whether to feed again. If the amount of residual bait is equal to 0, it indicates that the fish have a high desire to feed. Therefore, bait is fed to the fish in the amount of the previous feeding multiplied by the value of the open square of the current feeding frequency. If the amount of residual bait is greater than 0, it indicates that there is less feeding behavior present in the fish stock. To avoid food waste and pollution of aquaculture water, we end the feeding. When the total duration of fish feeding exceeds 10 min or the total amount of feeding exceeds 500 g, the feeding is ended. This is to avoid overfeeding the fish, which can lead to mortality. If the total feeding time and amount of feeding are not exceeded, we continue to judge whether to feed the fish again by the amount of residual bait.\nIn this algorithm, we set the feeding threshold to 0.30 for the following reasons. As shown in Fig. 4, the scatter plot shows the calculation results of feeding frequency of multiple videos with different feeding durations. With this figure, we found that more than 80% of the feeding frequency was higher than 0.40, and most of the rest were in the range of 0.25 to 0.35. Most studies have shown that fish feeding should follow the principle of 80% satiety. Therefore, in this algorithm, we decided to set the feeding threshold at 0.30, expecting to achieve better feeding results.\nIn this intelligent feeding algorithm, we developed the above feeding process by combining the feeding habits. Because the research object has the habit of food stealing and not eating sinking food, we divide the bait into multiple batches during feeding and only feed the next batch of bait after the previous batch is eaten by the fish. Moreover, the residual bait in the\nJournal of Electronic Imaging 021611-7 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nR tra\nct\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\npond is easy to identify and can visually reflect the feeding desire of the fish, so we use the amount of residual bait to determine whether to feed the fish. In addition, the feeding frequency of the fish can also reflect the feeding needs of the fish visually, so we use the feeding frequency to determine the amount of bait to be fed. And we found through a large number of artificial feeding experiments that the amount of bait fed in the next batch and the amount of bait fed in the previous batch conform to the exponential function released, so we can determine the amount of bait fed in the next batch by the amount of bait fed in the previous batch and the feeding frequency.\nFig. 4 Feeding frequency.\nJournal of Electronic Imaging 021611-8 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe\ntra\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\n4 Experiment and Evaluation\n4.1 Experimental Setup\n4.1.1 Experimental environment and data acquisition\nCichlasoma managuense is used in this experiment and evaluation. They have the advantages of lower oxygen concentration resistance and strong disease resistance. At the same time, they have a beautiful appearance, delicious meat, and rich nutrition. They can be used as ornamental fish or commercial fish for breeding. Because of their great economic potential, they are suitable for RAS.\nA medium-size RAS was built at Chongqing Technology and Business University for the experiment. The data used in this experiment were provided by the No. 1 breeding pond. There are about 100 fish stocks in the breeding pond, with an average weight of about 100 g, an overall weight of about 10000 g, and a body length range of 17 to 21 cm. The aquaculture water environment temperature is 25\u00b0C to 27\u00b0C, dissolved oxygen is 5 to 7 mg\u2215L. According to the present breeding situation, the fish were fed twice a day, and the daily bait consumption was controlled at 5% of the fish weight.\n4.1.2 Data preprocess\nThe data set was 20 feeding videos with a duration of 1 min, and the frame rate of each video was 50 Hz. We obtained the image data set by processing the feeding video data set using the interframe difference method. In this approach, the motion target contour was acquired by doing the difference operation between two adjacent frames in the video image sequence. In the case of multiple moving targets or camera movements, this method can effectively remove noise.\nWe put the processed data set into the modified VGG16 to detect the food intake of fish. First, the data set was divided into two categories according to whether the fish were feeding or not and placed separately in folders named \u201cfeed\u201d or \u201cnofeed.\u201d Then, by traversing the file name under the folder, the label corresponding to the image was given to indicate the feeding state of the fish shown in the image. In models, the ratio of the training set to the testing set is set to 8:2 and the Adam optimizer is used.\n4.2 Model Evaluation\n4.2.1 Evaluation of modified VGG16 model\nThe following metrics were used to evaluate the model in this experiment, i.e., accuracy (Acc), loss function (Loss), area under curve (AUC), and average precision (AP). The model accuracy and loss function are shown in Fig. 5. The epoch of the model is set to 20 and the learning rate is set to 0.0001. The horizontal coordinate indicates the number of training rounds, and the vertical coordinate indicates the values of the model accuracy and loss function. This figure represents the state of the model on the training set, and the blue line indicates the change in accuracy, which is roughly on an increasing trend. The orange line represents the change in the loss function, with an overall downtrend. Loss is 0.20 and accuracy is 0.92.\nThe PR graph is shown in Fig. 6, with the horizontal coordinate indicating recall and the vertical coordinate indicating precision. The PR curve of this graph first rises gradually and then rapidly decreases. The larger the value of AP is, the better the algorithm is. The value of AP in the model is 0.89, approaching 1.0, which proves that the model is effective.\nThe ROC curves are shown in Fig. 7, with the horizontal coordinate indicating the false positive rate (FPR) and the vertical coordinate indicating the true positive rate (TPR). The ROC curve changes are mainly divided into two stages. The curve is a gradual increase in the period before the value of FPR is 0.25, after which the curve remains largely unchanged. AUC refers to the proportion of the area under the curve to the total area. The better the classification performance of the model, the greater the value of the AUC. The value of the AUC of the model was 0.90, which tends to be 1.0, proving that the model is effective.\nJournal of Electronic Imaging 021611-9 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe tra\ncte d\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nFig. 6 PR curve of model.\nFig. 7 ROC curve of model.\nFig. 5 Acc and loss of model.\nJournal of Electronic Imaging 021611-10 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe\nt a\ncte d\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nFigure 8 shows the comparison of the accuracy changes of each model. The horizontal coordinate is the number of training rounds, and the vertical coordinate is the value of the model accuracy. The red line indicates modified VGG16, with the model accuracy rising faster until four rounds and then rising slowly to about 0.92. The blue line represents AlexNet, with the change in model accuracy being maintained at around 0.50. The orange line represents GoogLeNet, with the model showing an increasing trend until six rounds, after which it rises slowly to about 0.88. The green line represents LeNet, which is basically consistent with the change in the accuracy of AlexNet, remaining at around 0.50. The purple line represents the original VGG16, which rises faster before round 3 and only rises slowly to 0.91. The model with the highest accuracy is the modified VGG16, and the lowest is LeNet.\nFigure 9 shows the comparison of loss function changes in each model. The horizontal coordinate represents the number of training rounds, and the vertical coordinate represents the value of the model loss function. The red line represents the modified VGG16. Before four rounds, the loss function of the model decreases rapidly and then decreases slowly until the loss function is stable at about 0.20. The blue line indicates AlexNet, and the variation of the model loss function is kept at around 0.69. The orange lines represent GoogLeNet. The model shows a downward trend before six rounds, and then the model loss function decreases slowly to about 0.27. The green line represents LeNet. Before five rounds, the model loss function drops rapidly, and then slowly drops to about 2.4. The purple line indicates VGG16, with the model loss function\nFig. 9 Comparison of loss functions.\nJournal of Electronic Imaging 021611-11 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe\ntr\nct\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\ndecreasing faster until 5 rounds and then decreasing slowly to about 0.22. The lowest loss function is modified VGG16 and the highest is LeNet model.\nBy setting different parameters for experiments, we found that the over-fitting risk of the modified VGG16 was lower than that of the original VGG16. For example, with the learning rate set to 0.001 and training rounds to 7, the original VGG16 training set loss function is still declining, but the loss function of the test set is basically unchanged, and the model appears to over-fit. But the modified VGG16 under the same conditions did not appear to over-fit. This shows that the modified VGG16 can reduce the over-fitting risk of the model.\n4.2.2 Evaluation of YOLOv5s model\nThe following metrics were used to evaluate the model in this experiment, i.e., F1_curve, P_curve, R_curve, PR_curve, and confusion_matrix.\nFigures 10\u201313 show the evaluation results of YOLOv5s detection residual bait. The F1 curve plot is shown in Fig. 10. F1 score is a measurement standard of classification; it is a harmonic average function of the precision rate and the recall rate and is between 0 and 1. The F1 score\nFig. 10 F1_curve.\nFig. 11 P_curve.\nJournal of Electronic Imaging 021611-12 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe\ntra\nct d\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\nobtained by this model for the detection of residual baits is 0.76, which is close to 1. Figure 11 indicates a P-curve plot, with the horizontal coordinate confidence and the vertical coordinate indicating precision. The higher the confidence is, the higher the precision is. The curve reaches 1 at a confidence of 0.719. Figure 13 indicates a PR graph, with the vertical coordinate indicating precision and the horizontal coordinate indicating recall. The higher the recall is, the lower the precision is. The precision of the model in identifying residual baits is 77.7%. Figure 12 indicates the R-curve plot, with the horizontal coordinate indicating the confidence and the vertical coordinate indicating recall. The higher confidence is, the lower recall is. When the confidence is 0, the recall is 0.90.\nFigure 14 represents the confusion matrix for residual bait detection, and the image is divided into two parts: residual bait and background FP. The graph is normalized over each column, which shows that accuracy of the residual bait prediction is 90%.\nFigure 15 shows the identification results and confidence of the residual bait label. It can be seen that the YOLOv5s model can better detect the floating residual bait on the water surface, which plays an important role in the realization of the intelligent feeding algorithm designed in this paper.\nFig. 12 R_curve.\nJournal of Electronic Imaging 021611-13 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nR tra\ncte d\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use\n4.3 Comparison of Feeding Experimental Results\nTo evaluate the practical effect of the intelligent feeding algorithm in this paper, we conducted comparative experiments in different breeding ponds under the same environment. The experimental results are shown in Fig. 16. Among them, the daily feeding amount fluctuates more under the artificial feeding method and less under the intelligent feeding algorithm. After nearly a month of contrast experiments, we found that the daily feeding amount using the intelligent feeding algorithm was significantly smaller than the consumption under the artificial feeding method, and the bait consumption was reduced by about 15%. Therefore, we can conclude that intelligent feeding algorithm has a better effect than the artificial feeding method in reducing feed consumption and aquaculture cost.\nFig. 14 Confusion matrix.\nFig. 15 Results of residual bait detection.\nJournal of Electronic Imaging 021611-14 Mar\u2215Apr 2023 \u2022 Vol. 32(2)\nRe\ntra\ncte d\nDownloaded From: https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging on 25 Jan 2024 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use"
        },
        {
            "heading": "5 Conclusion",
            "text": "To achieve the objective of intelligent feeding in RAS, this paper proposed the computer visionbased method for residual bait detection and feeding frequency calculation. The accuracy of judging the feeding state of fish reached 92.4%. Finally, qualitative and quantitative decisions were made by based on residual bait and the feeding frequency of fish for intelligent feeding. Compared with the traditional feeding method, the intelligent feeding method saved a lot of manpower and reduced 15% of bait waste."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported in part by the Chongqing Municipal projects under GRANT No. KJCX2020035, CSTB2022BSXM-JCX0117, and cstc2020jcyj-msxmX0339 and in part by Chongqing Technology and Business University projects under GRANT No. 2156004, 212017)."
        }
    ],
    "title": "Dynamic scene images-assisted intelligent control method for industrialized feeding through deep vision learning",
    "year": 2024
}