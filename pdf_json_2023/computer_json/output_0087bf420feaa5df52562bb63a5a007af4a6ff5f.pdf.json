{
    "abstractText": "THE rapid growth of online service platforms has greatly influenced the way users conduct daily activities. In response to the requirements of frequent online activities, recommendation has become one of the best ways for the organizations, governments and individuals to understand their users and promote their services. Effective recommendation of online items has become critical in domains such as e-commerce and online media. Driven by the business success, academic research in this field has been active for many years. However, there are still many research challenges, such as context discovery, sequential user behavior influence, explainability and user interaction of system, big service data management. Especially, the highly dynamic online network data make these challenges even critical. Due to the high pressing interest and challenges in this area, this special issue is devoted to this topic, and focuses on the new solutions using AI and Big Data techniques. This issue covered many aspects of recommender systems, including context discovery, result summarization, explanation and presentation, trust of results, user behavior analysis, machine learning and Big Data analytics techniques, conversational and scenario-Oriented Recommendation. The issue received 56 research submissions. The Reviewers, Guest Editors, and Editors-in-Chief have worked very hard and selected 10 papers, with an acceptance rate of 17.9%, after two to four rounds of reviewing. In the paper \u201cCombinatorial Optimization Meets Reinforcement Learning: Effective Taxi Order Dispatching at LargeScale\u201d, Y. Tong, D. Shi, Y. Xu, W. Lv, Z. Qin and X. Tang proposed a novel solution called LTD that synergically integrates reinforcement learning (RL) and combinatorial optimization for large-scale taxi order dispatching. The traditional combinatorial optimization based strategies fail to deliver the theoretically claimed performance. Pioneer studies jointly optimize dispatching decisions by unidirectional integration of reinforcement learning with combinatorial optimization, which restricts the potential performance gains. The authors have augmented reinforcement learning to combinatorial optimization by online learning that adapts the dispatching strategies to the current situations. They optimize the efficiency by adopting shared value function and approxiation together with breadth first search. Experimental results proved that LTD outperforms the baselines on utility and efficiency by up to 36.4% and 42.0%, respectively.",
    "authors": [],
    "id": "SP:1255b0fdc3700fc48de6a0abad805086f2488d94",
    "references": [],
    "sections": [
        {
            "text": "Guest Editorial Special Issue on Online Recommendation Using AI\nand Big Data Techniques\nTHE rapid growth of online service platforms has greatly in-fluenced the way users conduct daily activities. In response to the requirements of frequent online activities, recommendation has become one of the best ways for the organizations, governments and individuals to understand their users and promote their services. Effective recommendation of online items has become critical in domains such as e-commerce and online media. Driven by the business success, academic research in this field has been active for many years. However, there are still many research challenges, such as context discovery, sequential user behavior influence, explainability and user interaction of system, big service data management. Especially, the highly dynamic online network data make these challenges even critical. Due to the high pressing interest and challenges in this area, this special issue is devoted to this topic, and focuses on the new solutions using AI and Big Data techniques.\nThis issue covered many aspects of recommender systems, including context discovery, result summarization, explanation and presentation, trust of results, user behavior analysis, machine learning and Big Data analytics techniques, conversational and scenario-Oriented Recommendation. The issue received 56 research submissions. The Reviewers, Guest Editors, and Editors-in-Chief have worked very hard and selected 10 papers, with an acceptance rate of 17.9%, after two to four rounds of reviewing.\nIn the paper \u201cCombinatorial Optimization Meets Reinforcement Learning: Effective Taxi Order Dispatching at LargeScale\u201d, Y. Tong, D. Shi, Y. Xu, W. Lv, Z. Qin and X. Tang proposed a novel solution called LTD that synergically integrates reinforcement learning (RL) and combinatorial optimization for large-scale taxi order dispatching. The traditional combinatorial optimization based strategies fail to deliver the theoretically claimed performance. Pioneer studies jointly optimize dispatching decisions by unidirectional integration of reinforcement learning with combinatorial optimization, which restricts the potential performance gains. The authors have augmented reinforcement learning to combinatorial optimization by online learning that adapts the dispatching strategies to the current situations. They optimize the efficiency by adopting shared value function and approxiation together with breadth first search. Experimental results proved that LTD outperforms the baselines on utility and efficiency by up to 36.4% and 42.0%, respectively.\nDigital Object Identifier 10.1109/TKDE.2023.3310728\nMotivated by the limitation of current recommender systems in handling atypical behaviors that may reflect users\u2019 temporary interest, in the paper \u201cLearning from Atypical Behavior: Temporary Interest Aware Recommendation Based on Reinforcement Learning\u201d, Z. Du, N. Yang, Z. Yu and P. S. Yu proposed a RL-based model, called TIARec, which can distinguish atypical interactions from normal ones and capture the temporary as well as the general preference of users. They have introduced a recommender agent and an auxiliary classifier agent that can be jointly trained. The experimental results demonstrated that TIARec can outperform the best baseline by up to 44.63% of recall.\nThe paper \u201cCausal Disentanglement for Semantics-Aware Intent Learning in Recommendation\u201d by X. Wang, Q. Li, D. Yu, P. Cui, Z. Wang and G. Xu proposed an unbiased and semantics-aware disentanglement learning called CaDSI from a causal perspective to address the bias problems that cover the users\u2019 true intent for recommendation. The authors designed a novel causal graph for the qualitative analysis of relationships in recommendation, based on which a pre-trained model is designed to semantically account for the item context influence towards the user intent. The experimental results proved that CaDSI improves over the best baselines w.r.t. Recall@40 by up to 78.8%.\nIn the paper \u201cMetaKG: Meta-learning on Knowledge Graph for Cold-start Recommendation\u201d, Y. Du, X. Zhu, L. Chen, Z. Fang and Y. Gao proposed a novel meta-learning based framework called MetaKG for cold-start recommendations. MetaKG has a collaborative-aware meta learner and a knowledge-aware meta learner, which captures meta users\u2019 preference and entities\u2019 knowledge. Experimental results demonstrated that MetaKG outperforms all STOA competitors w.r.t effectiveness, efficiency, and scalability.\nThe paper \u201cIntent Disentanglement and Feature Selfsupervision for Novel Recommendation\u201d by T. Qian, Y. Liang, Q. Li, X. Ma, K. Sun and Z. Peng pointed out that popularity bias and differentiating the degree of users\u2019 intents to popularity could incur a sharp decline of cold-start recommendation quality. To address this problem, the authors proposed an intent disentanglement and feature self-supervision (IDS4NR) model for novel recommendation. Experimental results demonstrated that IDS4NR yields significant improvements over STOA baselines w.r.t trade-off between accuracy and novelty.\nIn the paper \u201cGenerative Adversarial Reward Learning for Generalized Behavior Tendency Inference\u201d, X. Chen, L. Yao,\n1041-4347 \u00a9 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.\nX. Wang, A. Sun and Q. Z. Sheng proposed a new inverse reinforcement-learning-based method for capturing user\u2019s behavioural tendency. Traditional RL-based methods define reward functions and manually adjust them to model user\u2019s profiles, which may not reflect user\u2019s intention in practice. The authors have designed a model that automatically learns the rewards from user\u2019s actions. Experimental results have demonstrated that the new method outperforms STOA methods in traffic signal control, recommendation and scanpath prediction.\nThe paper \u201cKnowledge graph-enhanced sampling for conversational recommendation system\u201d by M. Zhao, X. Huang, L. Zhu, J. Sang and J. Yu pointed out that the exploitation and exploration problem results in the heavy burden on users in conversational recommender system. To address this issue, the authors proposed a Knowledge Graph-enhanced Sampling (KGenSam), which integrates the dynamic graph of user interaction with the external knowledge. The active learning and the hard-negative sample mining methods are introduced into CRS to solve the data sparsity problem of the user feedback. Experimental results have demonstrated KGenSam outperforms best STOA by 42% w.r.t. effectiveness and by 38.8% w.r.t. efficiency.\nIn the paper \u201cTAG: Joint Triple-hierarchical Attention and GCN for Reviewbased Social Recommender System\u201d, P. Qiao, Z. Zhang, Z. Li, Y. Zhang, K. Bian, Y. Li and G. Wang pointed out two critical issues in recommendation: 1) the degradation of review-based features during propagation between layers in graph neural networks (GNNs); 2) the fusion of heterogeneous structures in multiple relationship networks. To address these issues, the authors proposed a framework called TAG for predicting ratings to items. TAG uses jointly optimized hierarchical attention and inductive GNNs to model the review and relationships between users, items and user-item. Experimental results have proved that TAG outperforms STOA methods w.r.t. effectiveness.\nThe paper \u201cPopularity Bias Is Not Always Evil: Disentangling Benign and Harmful Bias for Recommendation\u201d by Z. Zhao, J. Chen, S. Zhou, X. He, X. Cao, F. Zhang and W. Wu pointed out the benigh popularity bias and temporal dynamics caused by conformity in recommendation. They proposed a time-aware disentangled framework TIDE for tackling popularity bias in recommendation. TIDE performs disentangled training using temporal information, and intervention-based inference to block the harmful conformity effect. Test results proved that TIDE outperforms the best SOTA method by up to 28.99% of recall.\nThe last paper of this special issue is \u201cValue-wise ConvNet for Transformer models: An Infinite Time-aware Recommender System\u201d by M. Saaki, S. Hosseini, S. Rahmani, M. Kangavari, W. Hua and X. Zhou. In this paper, the authors have proposed a unified context-aware framework, ConvTime, to recommend users to answer a query within a time constraint. Online platforms find experts to answer a question by community detection on a user-item bipartite graph, which incurs NP-hard time cost. This paper developed an attention-based text embedding to construct context-aware vectors, from which knowledge domains are identified. The user behavioral patterns and interests are modelled by a continuous-time model for relevant expertise estimation. Experimental results proved that ConvTime outperforms STOA methods w.r.t. effectiveness and efficiency.\nFinally, we would like to thank all the reviewers for their insightful suggestions to help improve the paper quality.\nLEI CHEN Information Hub Hong Kong University of Science and Technology (GZ) Guangzhou 511400, China leichen@cse.ust.hk\nXIANGMIN ZHOU School of Computing Technologies RMIT University Melbourne, VIC 3000, Australia xiangmin.zhou@rmit.edu.au\nXIAOCHUN YANG Northeastern University Shenyang 110819, China yangxc@mail.neu.edu.cn\nTIMOS SELLIS Archimedes Research Unit on AI, Data Science and Algorithms \u201cAthena\u201d Research and Innovation Centre Athens 15125, Attiki, Greece timossellisg@gmail.com\nLei Chen (Fellow, IEEE) received the PhD degree in computer science from the University of Waterloo, Canada, in 2005. He is a chair professor in data science and analytic thrust with HKUST (GZ), he is a distinguished member of the ACM. His research interests include data-driven AI, knowledge graphs, blockchains, data privacy, crowdsourcing, spatial and temporal databases, query optimization on large graphs, and probabilistic databases. He received the SIGMOD Testof-Time Award in 2015, Best research paper award in VLDB 2022. The system developed by his team won the excellent demonstration award in VLDB 2014. He had served as VLDB 2019 PC Co-chair. Currently, he serves as Editor-in-chief of IEEE Transaction on Data and Knowledge Engineering and an executive member of the VLDB endowment.\nXiangmin Zhou (Member, IEEE) received the PhD degree in computer science from the University of Queensland, Brisbane, Australia, in 2008. She is currently a lecturer with the School of Computing Technologies, RMIT University, Melbourne, Australia. She worked in ICT Centre, CSIRO Australia as a Research Scientist from 2008 to 2012. Her research interests include social network analysis, data-driven machine learning, recommender systems, and multimedia data analysis.\nXiaochun Yang (Senior Member, IEEE) received the PhD degree in computer science from Northeastern University, Shenyang, China, in 2001. She is a professor and head with the Computer Science Department, Northeastern University, China. Her research interests include Big Data management and knowledge engineering, data quality management, and recommender system and data privacy. She was elected Distinguished Professor in Liaoning provenance in 2019, and was awarded by Ten Thousand Talent Program in 2019, the NSF of China for Outstanding Young Scholars in 2013, and Program for New Century Excellent Talents in University in 2007.\nTimos Sellis (Fellow, IEEE) received the PhD degree from the University of California at Berkeley. He is director, Archimedes Research Unit on AI, Data Science and Algorithms \u201cAthena\u201d Research and Innovation Center. His research interests include Big Data, data streams, personalisation, data integration, and spatio-temporal database systems. He was elected IEEE fellow in 2009 for his contributions to database query optimisation and spatial data management, and ACM fellow in 2013 for his contributions to database query optimisation, spatial data management and data warehousing. In 2018, he was awarded the IEEE TCDE Impact Award, in recognition of his impact in the field and for contributions to database systems research and broadening the reach of data engineering research."
        }
    ],
    "title": "Guest Editorial Special Issue on Online Recommendation Using AI and Big Data Techniques",
    "year": 2023
}