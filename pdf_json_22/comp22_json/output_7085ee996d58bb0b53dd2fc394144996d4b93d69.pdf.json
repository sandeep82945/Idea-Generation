{
    "abstractText": "While interacting with chatbots, users may elicit multiple intents in a single dialogue utterance. Instead of training a dedicated multiintent detection model, we propose DialogUSR, a dialogue utterance splitting and reformulation task that first splits multi-intent user query into several single-intent sub-queries and then recovers all the coreferred and omitted information in the sub-queries. DialogUSR can serve as a plug-in and domainagnostic module that empowers the multiintent detection for the deployed chatbots with minimal efforts. We collect a high-quality naturally occurring dataset that covers 23 domains with a multi-step crowd-souring procedure. To benchmark the proposed dataset, we propose multiple action-based generative models that involve end-to-end and two-stage training, and conduct in-depth analyses on the pros and cons of the proposed baselines.",
    "authors": [
        {
            "affiliations": [],
            "name": "Haoran Meng"
        },
        {
            "affiliations": [],
            "name": "Xin Zheng"
        },
        {
            "affiliations": [],
            "name": "Tianyu Liu"
        },
        {
            "affiliations": [],
            "name": "Zizhen Wang"
        },
        {
            "affiliations": [],
            "name": "He Feng"
        },
        {
            "affiliations": [],
            "name": "Binghuai Lin"
        },
        {
            "affiliations": [],
            "name": "Xuemin Zhao"
        },
        {
            "affiliations": [],
            "name": "Yunbo Cao"
        },
        {
            "affiliations": [],
            "name": "Zhifang Sui"
        }
    ],
    "id": "SP:21ec90336318b7d3724fd67df8e525c7fa1cbbc1",
    "references": [
        {
            "authors": [
                "Liu"
            ],
            "title": "terances are highly overlapped, another approach is to edit rather than generate from scratch, specifying the operation by sequence tagging",
            "venue": "Pan et al",
            "year": 2019
        },
        {
            "authors": [
                "Jin"
            ],
            "title": "imitates semantic segmentation by predicting the word-level edit matrix, and with similarity Huang et al. (2021) used a semi auto-regressive generator",
            "year": 2021
        },
        {
            "authors": [
                "tems(Tur",
                "De Mori"
            ],
            "title": "Intent detection mainly aims to classify a given utterance with its intents from user inputs. Considering this strong correlation between the two tasks, some joint models are proposed based on the multi-task learning",
            "year": 2011
        },
        {
            "authors": [
                "framework. (Zhang",
                "2016 Wang",
                "2018 Goo et al",
                "2019 Qin et al",
                "2014 Yao et al",
                "2018). Li Li et al"
            ],
            "title": "2018) proposed the gate mechanism to explore incorporating the intent information for slot filling",
            "year": 2018
        },
        {
            "authors": [
                "multi-intent. Therefore",
                "Rychalska"
            ],
            "title": "2018) first adopted hierarchical structures to identify multiple user intents",
            "venue": "Qin et al",
            "year": 2020
        },
        {
            "authors": [
                "Inigo Casanueva",
                "Ivan Vuli\u0107",
                "Georgios Spithourakis",
                "Pawe\u0142 Budzianowski."
            ],
            "title": "NLU++: A multilabel, slot-rich, generalisable dataset for natural language understanding in task-oriented dialogue",
            "venue": "Findings of the Association for Computational Lin-",
            "year": 2022
        },
        {
            "authors": [
                "Alice Coucke",
                "Alaa Saade",
                "Adrien Ball",
                "Th\u00e9odore Bluche",
                "Alexandre Caulier",
                "David Leroy",
                "Cl\u00e9ment Doumouro",
                "Thibault Gisselbrecht",
                "Francesco Caltagirone",
                "Thibaut Lavril"
            ],
            "title": "Snips voice platform: an embedded spoken language understanding",
            "year": 2018
        },
        {
            "authors": [
                "Ahmed Elgohary",
                "Denis Peskov",
                "Jordan BoydGraber."
            ],
            "title": "Can you unpack that? learning to rewrite questions-in-context",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
            "year": 2019
        },
        {
            "authors": [
                "Rashmi Gangadharaiah",
                "Balakrishnan Narayanaswamy."
            ],
            "title": "Joint multiple intent detection and slot labeling for goal-oriented dialog",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Chih-Wen Goo",
                "Guang Gao",
                "Yun-Kai Hsu",
                "Chih-Li Huo",
                "Tsung-Chieh Chen",
                "Keng-Wei Hsu",
                "YunNung Chen."
            ],
            "title": "Slot-gated modeling for joint slot filling and intent prediction",
            "venue": "Proceedings of the 2018 Conference of the North American Chap-",
            "year": 2018
        },
        {
            "authors": [
                "Sonal Gupta",
                "Rushin Shah",
                "Mrinal Mohit",
                "Anuj Kumar",
                "Mike Lewis."
            ],
            "title": "Semantic parsing for task oriented dialog using hierarchical representations",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2018
        },
        {
            "authors": [
                "Jie Hao",
                "Linfeng Song",
                "Liwei Wang",
                "Kun Xu",
                "Zhaopeng Tu",
                "Dong Yu."
            ],
            "title": "RAST: Domainrobust dialogue rewriting as sequence tagging",
            "venue": "In",
            "year": 2021
        },
        {
            "authors": [
                "Charles T. Hemphill",
                "John J. Godfrey",
                "George R. Doddington."
            ],
            "title": "The ATIS spoken language systems pilot corpus",
            "venue": "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, Pennsylvania, June 24-27,1990.",
            "year": 1990
        },
        {
            "authors": [
                "Mengzuo Huang",
                "Feng Li",
                "Wuhe Zou",
                "Weidong Zhang."
            ],
            "title": "Sarg: A novel semi autoregressive generator for multi-turn incomplete utterance restoration",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 35(14):13055\u201313063.",
            "year": 2021
        },
        {
            "authors": [
                "Shumpei Inoue",
                "Tsungwei Liu",
                "Nguyen Hong Son",
                "Minh-Tien Nguyen."
            ],
            "title": "Enhance incomplete utterance restoration by joint learning token extraction and text generation",
            "venue": "CoRR, abs/2204.03958.",
            "year": 2022
        },
        {
            "authors": [
                "Lisa Jin",
                "Linfeng Song",
                "Lifeng Jin",
                "Dong Yu",
                "Daniel Gildea."
            ],
            "title": "Hierarchical context tagging for utterance rewriting",
            "venue": "Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, ThirtyFourth Conference on Innovative Applications of Ar-",
            "year": 2022
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
            "year": 2015
        },
        {
            "authors": [
                "Stefan Larson",
                "Kevin Leach."
            ],
            "title": "A survey of intent classification and slot-filling datasets for taskoriented dialog",
            "venue": "arXiv preprint arXiv:2207.13211.",
            "year": 2022
        },
        {
            "authors": [
                "Alon Lavie",
                "Michael J. Denkowski."
            ],
            "title": "The meteor metric for automatic evaluation of machine translation",
            "venue": "Machine Translation, 23(2\u20133):105\u2013115.",
            "year": 2009
        },
        {
            "authors": [
                "Changliang Li",
                "Liang Li",
                "Ji Qi."
            ],
            "title": "A selfattentive model with gate mechanism for spoken language understanding",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3824\u20133833, Brussels, Bel-",
            "year": 2018
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Qian Liu",
                "Bei Chen",
                "Jian-Guang Lou",
                "Bin Zhou",
                "Dongmei Zhang."
            ],
            "title": "Incomplete utterance rewriting as semantic segmentation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages",
            "year": 2020
        },
        {
            "authors": [
                "Tianyu Liu",
                "Fuli Luo",
                "Pengcheng Yang",
                "Wei Wu",
                "Baobao Chang",
                "Zhifang Sui."
            ],
            "title": "Towards comprehensive description generation from factual attribute-value tables",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational",
            "year": 2019
        },
        {
            "authors": [
                "Tianyu Liu",
                "Xin Zheng",
                "Baobao Chang",
                "Zhifang Sui."
            ],
            "title": "Towards faithfulness in open domain table-to-text generation from an entity-centric view",
            "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on In-",
            "year": 2021
        },
        {
            "authors": [
                "Yinhan Liu",
                "Jiatao Gu",
                "Naman Goyal",
                "Xian Li",
                "Sergey Edunov",
                "Marjan Ghazvininejad",
                "Mike Lewis",
                "Luke Zettlemoyer."
            ],
            "title": "Multilingual denoising pre-training for neural machine translation",
            "venue": "Transactions of the Association for Computational Linguis-",
            "year": 2020
        },
        {
            "authors": [
                "Amit Moryossef",
                "Yoav Goldberg",
                "Ido Dagan."
            ],
            "title": "Step-by-step: Separating planning from realization in neural data-to-text generation",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:",
            "year": 2019
        },
        {
            "authors": [
                "Zhufeng Pan",
                "Kun Bai",
                "Yan Wang",
                "Lianqiang Zhou",
                "Xiaojiang Liu."
            ],
            "title": "Improving open-domain dialogue systems via multi-turn incomplete utterance restoration",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
            "year": 2019
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Libo Qin",
                "Wanxiang Che",
                "Yangming Li",
                "Haoyang Wen",
                "Ting Liu."
            ],
            "title": "A stack-propagation framework with token-level intent detection for spoken language understanding",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Hong Kong",
                "China"
            ],
            "title": "Association for Computational Linguistics",
            "venue": "Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),",
            "year": 2087
        },
        {
            "authors": [
                "Libo Qin",
                "Xiao Xu",
                "Wanxiang Che",
                "Ting Liu."
            ],
            "title": "AGIF: An adaptive graph-interactive framework for joint multiple intent detection and slot filling",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1807\u20131816, Online.",
            "year": 2020
        },
        {
            "authors": [
                "Jun Quan",
                "Shian Zhang",
                "Qian Cao",
                "Zizhong Li",
                "Deyi Xiong."
            ],
            "title": "RiSAWOZ: A large-scale multidomain Wizard-of-Oz dataset with rich semantic annotations for task-oriented dialogue modeling",
            "venue": "Proceedings of the 2020 Conference on Empirical",
            "year": 2020
        },
        {
            "authors": [
                "Barbara Rychalska",
                "Helena T. Glabska",
                "Anna Wr\u00f3blewska."
            ],
            "title": "Multi-intent hierarchical natural language understanding for chatbots",
            "venue": "2018 Fifth International Conference on Social Networks Analysis, Management and Security (SNAMS), pages 256\u2013",
            "year": 2018
        },
        {
            "authors": [
                "Gokhan Tur",
                "Renato De Mori."
            ],
            "title": "Spoken language understanding: Systems for extracting semantic information from speech",
            "venue": "John Wiley & Sons.",
            "year": 2011
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
            "year": 2020
        },
        {
            "authors": [
                "Congying Xia",
                "Chenwei Zhang",
                "Xiaohui Yan",
                "Yi Chang",
                "Philip Yu."
            ],
            "title": "Zero-shot user intent detection via capsule neural networks",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2018
        },
        {
            "authors": [
                "Linting Xue",
                "Noah Constant",
                "Adam Roberts",
                "Mihir Kale",
                "Rami Al-Rfou",
                "Aditya Siddhant",
                "Aditya Barua",
                "Colin Raffel."
            ],
            "title": "mT5: A massively multilingual pre-trained text-to-text transformer",
            "venue": "Proceedings of the 2021 Conference of the North",
            "year": 2021
        },
        {
            "authors": [
                "Kaisheng Yao",
                "Baolin Peng",
                "Yu Zhang",
                "Dong Yu",
                "Geoffrey Zweig",
                "Yangyang Shi."
            ],
            "title": "Spoken language understanding using long short-term memory neural networks",
            "venue": "2014 IEEE Spoken Language Technology Workshop (SLT), pages 189\u2013194.",
            "year": 2014
        },
        {
            "authors": [
                "Wei-Nan Zhang",
                "Zhigang Chen",
                "Wanxiang Che",
                "Guoping Hu",
                "Ting Liu."
            ],
            "title": "The first evaluation of chinese human-computer dialogue technology",
            "venue": "arXiv preprint arXiv:1709.10217.",
            "year": 2017
        },
        {
            "authors": [
                "Xiaodong Zhang",
                "Houfeng Wang."
            ],
            "title": "A joint model of intent determination and slot filling for spoken language understanding",
            "venue": "Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA,",
            "year": 2016
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Thanks to the technological advances of natural language processing (NLP) in the last decade, modern personal virtual assistants like Apple Siri, Amazon Alexa have managed to interact with end users in a more natural and human-like way. Taking chatbots as human listeners, users may elicit multiple intents within a single query. For example, in Figure 1, a single user query triggers the inquiries on both highspeed train ticket price and the weather of destination. To handle multi-intent user queries, a straightforward solution is to train a dedicated natural language understanding (NLU) system for multi-intent detection. Rychalska et al. (2018) first adopted hierarchical structures to identify multiple user intents. Gangadharaiah and Narayanaswamy (2019) explored the joint multi-intent and slot-filling task with a recurrent neural network. Qin et al. (2020)\n*Equal contribution. \u2020Corresponding authors.\n\u6253\u5f00\u7a7a\u8c03\u548c\u53f3\u4fa7\u8f66\u7a97 Turn on AC and right window\n\u6253\u5f00\u7a7a\u8c03\u548c\u53f3\u4fa7\u8f66\u7a97 Open AC and right window\nIntent1: ac_control Intent2: car_control\n\u6253\u5f00\u7a7a\u8c03 Turn on AC \u6253\u5f00\u53f3\u4fa7\u8f66\u7a97 Open right window\nDialogUSR Module Single-intent\nNLU\nMulti-intent NLU\nIntent1: ac_control\nMulti-intent User Query\nIntent2: car_control\n\u4ece\u5317\u4eac\u5750\u9ad8\u94c1\u5230\u5357\u4eac\u591a\u5c11\u94b1\u90a3\u8fb9\u5929\u6c14\u600e\u4e48\u6837 How long does it take from Beijing to Nanjing in high-speed train and how is the weather there\nfurther proposed an adaptive graph attention network to model the joint intent-slot interaction. To integrate the multi-intent detection model into a product dialogue system, the developers would make extra efforts in continuous deployment, i.e. technical support for both single-intent and multiintent detection models, and system modifications, i.e. changes in the APIs and implementations of NLU and other related modules.\nTo provide an alternative way towards understanding multi-intent user queries, we propose complex dialogue utterance splitting and reformulation (DialogUSR) task with corresponding benchmark dataset that firstly splits the multi-intent query into several single-intent sub-queries and then recover the coreferred and omitted information in the subqueries, as illustrated in Fig 1. With the proposed task and dataset, the practitioners can train a multiintent query rewriting model that serves as a plug-in module for the existing chatbot system with minimal efforts. The trained transformation models are also domain-agnostic in the sense that the learned\nar X\niv :2\n21 0.\n11 27\n9v 1\n[ cs\n.C L\n] 2\n0 O\nct 2\n02 2\nquery splitting and rewriting skills in DialogUSR are generic for multi-intent complex user queries from diverse domains.\nWe employ a multi-step crowdsourcing procedure to annotate the dataset for DialogUSR which covers 23 domains with 11.6k instances. The naturally occurring coreferences and omissions account for 62.5% of the total human-written sub-queries, which conforms to the genuine user preferences. Specifically we first collect initial queries from 2 Chinese task-oriented NLU datasets that cover real-world user-agent interactions, then ask the annotators to write the subsequent queries as they were sending multiple intents to the chatbots, finally we aggregate the human written sub-queries and provide completed sub-queries if coreferences and omissions are involved. We also employ multiple screening and post-checking protocols in the entire data creation process, in order to ensure the high quality of the proposed dataset.\nFor baseline models, we carefully analyze the transformation from the input multi-intent queries to the corresponding single-intent sub-queries and summarize multiple rewriting actions, including deletion, splitting, completion and causal completion which are the local edits in the generation. Based on the summarized actions, we proposed three types of generative baselines: end-toend, two-stage and causal two-stage models which are empowered by strong pretrained models, and conduct a series of empirical studies including the exploration on the best action combination, the model performance on different training data scale and existing multi-intent NLU datasets.\nWe summarize our contributions as follows1: 1) The biggest challenges of multi-intent detection (MID) in the deployment is the heavy code refactoring on a running dialogue system which already does a good job in single-intent detection. It motivates us to design DialogUSR, which serves as a plug-in module and eases the difficulties of incremental development.\n2) Prior work on MID has higher cost of data annotation and struggles in the open-domain or domain transfer scenarios. Only NLU experts can adequately annotate the intent/slot info for a MID user query, and the outputs of MID NLU models are naturally limited by the pre-defined intent/slot ontology. In contrast, DialogUSR datasets can be\n1Code and data are provided in https://github.com/ MrZhengXin/multi_intent_2022.\nStep1. Initial Query Collection\n+,-./012345678 Check the high-speed train from Xiamen to Nanjing on Friday afternoon\nTask-oriented Query Datasets\nfghi:+,A/j12klh -./0345678 Hi, I wanna check the high-speed train that departs from Xiamen and arrives in Nanjing on Friday afternoon Sampling\nSentence Simplification\nStep2. Follow-up Query Creation\n'(* +,-./012345678 Check the high-speed train from Xiamen to Nanjing on Friday afternoon\n'K* 9:;<=> How long does it take 'Q* +A/BC6DEFG Check out the special cuisine there\nStep3. Query Aggregation\n'(* +,-./012345678 Check the high-speed train from Xiamen to Nanjing on Friday afternoon\n'K* 9:;<=> How long does it take\n'Q* +A/BC6DEFG Check out the special cuisine there\nmccnPcV%JS\"* +,-./0123456789:; <=>?@+A/BC6DEFG Check the high-speed train from Xiamen to Nanjing on Friday afternoon, how long does the journey take, then check out the special food there.\n'K* 9:;<=> How long does it take\n'Q* +A/BC6 DEFG Check out the special cuisine there\n'KonPb* 123456789 :;<=> How long does it take to travel from Xiamen to Nanjing in high-speed train\n'QonPb* +A/456DEFG Check out the special cuisine in Nanjing\nStep4. Query Completion\neasily annotated by non-experts, and the derived models are domain-agnostic in the sense that the learned query splitting, coreference/omission recovery skills are generic for distinct domains\n3) Presumably MID is more difficult than single intent detection (SID) given the same intent/slot ontology. From the perspective of task (re)formulation, DialogUSR is the first to convert a MID task to multiple SID tasks (the philosophy of \u2019divide and conquer\u2019) with a relatively low error propagation rate, providing an alternative and effective way to handle the MID task."
        },
        {
            "heading": "2 Dataset Creation",
            "text": "We collect a high quality dataset via a 4-step crowdsourcing procedure as illustrated in Fig 2."
        },
        {
            "heading": "2.1 Initial Query Collection",
            "text": "In order to determine the topic of the multi-intent user query, we sample an initial query from two Chinese user query understanding datasets for task-oriented conversational agents, namely SMPECDT2(Zhang et al., 2017) and RiSAWOZ3 (Quan et al., 2020). Then we ask human annotators to simplify the initial queries that have excessive length (longer than 15 characters), or are too verbose or repetitive in terms of semantics4. RiSAWOZ is a a large-scale multi-domain Chinese Wizard-of-Oz NLU dataset with rich semantic annotations, which covers 12 domains in tourist attraction, railway, hotel, restaurant, etc. SMP-ECDT is released as the benchmark for the \u201cdomain and intent identification for user query\u201d task in the evaluation track of Chinese Social Media Processing conference (SMP) 2017 and 2019. It covers divergent practical user queries from 30 domains which are collected from the production chatbots of iFLYTEK. We use the two source datasets as our query resources as they comprise a variety of common and naturally occurring user queries in daily life for task-oriented chatbot and cover diverse domains and topics."
        },
        {
            "heading": "2.2 Follow-up Query Creation",
            "text": "After specifying an initial query, we ask human annotators to put themselves in the same position of a real end user and imagine they are eliciting multiple intents in a single complex user query while interacting with conversational agents. The annotators are instructed to write up to 3 subsequent queries on what they need or what they would like to know about according to the designated initial query. Although most subsequent queries stick to the topic of the initial query, we allow the human annotators to switch to a different topic which is unrelated to the initial query5. For example in Figure 1, the second sub-query asks about the weather in Nanjing, where the initial query is an inquiry on the\n2http://ir.hit.edu.cn/SMP2017-ECDT 3https://github.com/terryqj0107/RiSAWOZ 4The sentence simplification phase makes the annotated multi-intent queries sound more natural, as users are not likely to elicit a lengthy query. Given the fact that we would add 2 or 3 following sub-queries to the initial queries, they should be simplified to keep a proper query length (Fig 2).\n5In fact, we neither encourage nor discourage topic switching in the annotation instruction.\nrailway information. We observe that 37.3% annotated multi-intent queries involve topic switching by manually checking 300 subsampled instances in the training set, which conforms to the user behaviour in the real-world multi-intent queries."
        },
        {
            "heading": "2.3 Query Aggregation",
            "text": "In the pilot study, we tried to ask human annotators to manually aggregate the sub-queries but found that the derived queries are somewhat lack of variations in the conjunctions between the subqueries, as the annotators tend to always pick up the most common Chinese conjunctions like \u2019and\u2019, \u2019or\u2019, \u2019then\u2019. We even observed sloppy annotators trying to hack the annotation job by not using any conjunctions at all for each query (most queries are fluent even without conjunctions). In a nutshell, we find it challenging to screen the annotators and ensure the diversity and naturalness of the derived query in the human-only annotation. We then resort to human-in-the-loop annotation, sampling from a rich conjunction set to connect sub-queries and post-checking the sentence fluency of aggregated queries by GPT-2. After each round of annotation (we have 6 rounds of annotations), we randomly pick up 100 samples and check their quality, finding that over 95% of samples are of high quality. Actually most sentences in the Fig 9 (appendix) are fluent and natural (especially in Chinese) without cherry-picking.\nMore concretely we propose a set of pre-defined templates that correspond to different text infilling strategies between consecutive queries. Specifically, with a 50% chance we concatenate two consecutive queries without using any text filler. For the other 50% chance, we sample a piece of text from a set of pre-defined text fillers with different sampling weights, such as \u201c\u9996\u5148\u201d (first of all), \u201c\u4ee5\u53ca\u201d (and), \u201c\u6211\u8fd8\u60f3\u77e5\u9053\u201d (I also would like to know), \u201c\u63a5\u4e0b\u6765\u201d (then), \u201c\u6700\u540e\u201d (finally), and then use the sampled text filler as a conjunction while concatenating consecutive queries. Although being locally coherent, the derived multi-intent query may still exhibit some global incoherence and syntactic issues, especially for longer text. We thus post-process the derived query with a ranking procedure as an additional screening step. For each annotated query set, we generate 10 candidate multiintent queries with different sampled templates and rank them according to language model perplexity using a GPT-2 (117M) model. We only keep the\nthe candidate with lowest perplexity to ensure the fluency and syntactic correctness. To avoid trivial hacks in the complex query splitting, we remove all the punctuations in the aggregated query, which conforms to the default settings of most production chatbots, i.e. no punctuations in the spoken language understanding phase after going through the automatic speech recognition module."
        },
        {
            "heading": "2.4 Query Completion",
            "text": "After assembling the multi-intent user queries, we observe that incomplete utterances, such as coreferences and omissions, are frequently occurring which account for 62.5% of total human-written subsequent queries. Note that, in the annotation instruction, we do not explicitly ask the crowdsource worker to use coreferences or omissions while writing the subsequent queries in the follow-up query creation phase. The naturally occurring incomplete utterances reflect genuine user preferences while sending out multiple intents. To gather sufficient information while splitting multi-intent queries into independent single-intent queries, we ask another group of annotators6 to write the completed utterances by recovering omitted and co-referred information for the incomplete queries."
        },
        {
            "heading": "2.5 Data Annotation Settings",
            "text": "To perform human annotation, we hired crowdsource workers from an internal data annotating group. The workers were limited to those who\n6The query completion phase starts when follow-up query creation phase has finished. We hire another group of annotators that did not participate in the follow-up query writing task to screen the quality of rewritten queries while doing query completion.\nhave abundant hand-on experiences in annotating conversational data with good records (recognized as experts in the internal assessment, rejection rate \u2264 1%). Additionally, all the workers were screened via a 10-case qualification test that covers various annotation tasks in Sec 2.1 to Sec 2.4 (correctly annotating 8 out of 10 cases). They were paid 0.6$ per datapoint, which is more than prevailing local minimum wage. We split the entire annotation procedure into multiple rounds and hire another group of human judges to post-check the quality of annotated dataset and filter unqualified instances after each round. In this way, we create a high-quality crowdsourcing dataset."
        },
        {
            "heading": "3 Dataset Analysis",
            "text": "Dataset Statistics In total, after accumulating annotations for several rounds, we obtain 11,669 instances. We conduct 6 rounds of annotation, increasing the annotation scale with each round (ranging from \u223c100 instances/round to \u223c4000 instances/round). On average, an aggregated multiintent complex query from the proposed DialogUSR dataset comprises 36.7 Chinese characters by assembling 3.6 single-intent queries (including initial and follow-up queries). After recovering missing information in the query completion phase (Sec 2.4), the average lengths of completed initial query, first follow-up query, second follow-up query and third follow-up query are 11.9, 12.3, 12.4, 10.8 respectively. We split the dataset into train, validation and test sets with sizes of 10,169 , 500, 1,000 respectively.\nDomain Statistics The domain statistics of DialogUSR is depicted in Fig 3. Thanks to the diverse\ndomains of our source datasets, DialogUSR covers 23 domains that chatbot users frequently query on in their daily life. Additionally, as mentioned in Sec 2.2, the annotators proactively switch topics or domains in the data creation procedure. We find that, on average, a complex query in DialogUSR involves 1.4 domains, showing the potential usage of recognizing user intents across different domains. The models training on the DialogUSR dataset can deal with divergent situations in the practical usage while accommodating the utility of personal virtual assistant.\nIncomplete Utterance Analysis Existing multiintent detection datasets, such as MixATIS and MixSNIPS (Qin et al., 2020), were created using simple heuristic rules, e.g. adding a particular conjunction \u201cand\u201d while concatenating two single-intent queries. The simple heuristic datasets largely undermine the multi-intent detection in the real-world conversational agents, where users naturally interact with chatbots with coreferences and omissions. As highlighted in Sec 2.4, nearly two thirds of human-written subsequent queries are incomplete. We further show the incomplete ratio of follow-up queries for different domains in Fig 4. In the incomplete utterances, according to our statistics, only 2.4% of them belong to the coreferred phenomenon, showing that users prefer not using pronouns to refer to previously mentioned entities."
        },
        {
            "heading": "4 Baseline Models",
            "text": ""
        },
        {
            "heading": "4.1 Task Overview",
            "text": "As depicted in Figure 5, the input (Q1) and the output (Q4) of DialogUSR have a large text overlap. The transformation from Q1 to Q4 can be viewed as several local edits that retain the main body of the input query. We thus define several implicit actions that guide the transformation: 1) The Split action (Q1\u2192Q2) divides the complex multi-intent query into specific single-intent query with a special token. In our implementation we use the semicolon (;) and set up a heuristic rule that puts the semicolons before the text fillers if the latter appear. 2) The Delete action (Q2\u2192Q3) removes the text fillers and keep the salient queries for the subsequent actions. 3) The Complete action (Q3\u2192Q4) recovers the coreferred and omitted information in the recognized single-intent queries so that they can be effectively parsed by the existing (single-query) NLU module. 4) The Causal Complete strategy consists of the Split action (Q1\u2192Q2) and several Complete actions that echo with the token-by-token auto-regressive text generation. The difference is that Causal Complete strategy in DialogUSR recovers the missing information in the incomplete user utterances with a query-by-query fashion (Q5\u2192Q6\u2192Q7)."
        },
        {
            "heading": "4.2 End-to-end Generative Models",
            "text": "The most straightforward way is to train a sequenceto-sequence model to learn the transformation from the multi-intent query (Q1) to the decomposed single-intent ones (Q4) in the end-to-end fashion. The models are trained to implicitly split the raw\nquery (without punctuation) (Q1\u2192Q2), delete the conjunctions (Q2\u2192Q3) and recover the missing information (Q3\u2192Q4) in one single turn of generation. Specifically given the multi-intention complex query, the model is trained to output the sequence of multiple completed independent queries \u201cQ1;Q2; ...;Qn; </s>\u201d, where \u201c;\u201d, n, \u201c</s>\u201d represent the query separation token, the number of queries and the end-of-sentence token, respectively."
        },
        {
            "heading": "4.3 Two-stage Generative Models",
            "text": "In stead of performing all three actions in one single turn, we try to guide the transformation by a stepby-step generation (Moryossef et al., 2019; Liu et al., 2019, 2021). Notably, the Split, Delete and Complete actions in Fig 5 can be arbitrarily permuted throughout the generation process, e.g. firstly removing text filler then split the complete the complex query (Delete\u2192Split\u2192Complete). However we observe the performance drop if we explicitly employ a 3-step generation due to the error propagation.\nTwo-stage model (once) we resort to a twostage procedure that firstly splits the complex query (Q1\u2192Q2) and then recovers the incomplete utterances (Q2\u2192Q4). As the Split action is relative easy, i.e. achieving nearly 100% accuracy on the query separation, the error accumulations are largely mitigated.\nTwo-stage model (casual) Due to the fact that the former sub-queries would not be affected by the subsequent queries, we propose a \u201ccausal\u201dstyle query-by-query generation (Q5\u2192Q6\u2192Q7) in which the current sub-query to be reformu-\nlated only conditions on the prior sub-query instead of seeing the bidirectional context. Specifically, the Causal complete action takes place after the Split action. In the t-th episode of Causal complete action, we feed the model with incomplete queries \u201cq1; ...; qt\u201d, and then train the model to generate the completed query Qt. In this way, we greatly reduce the search space without the sacrifice on model performance. From an engineering standpoint, the proposed Causal complete action is a natural fit for the \u201cstreaming\u201d conversational agent, i.e. simultaneous query splitting and information recovery followed by single-intent NLU while the users are eliciting multiple intents."
        },
        {
            "heading": "5 Experiment Settings",
            "text": "Model Setting We experiment with a variety of pretrained models via Hugging Face Transformers (Wolf et al., 2020), including mT5 (Xue et al., 2021) with three different parameter scales, namely T5-base (580M), T5-large (1.2B), T5-xl (3.7B) , and mBART-large (Liu et al., 2020b) with 340M parameters as the backbones for the end-to-end and two-stage models. They are all multi-lingual pre-trained models that support both Chinese and English DialogUSR. We use the Adam optimizer (Kingma and Ba, 2015) with the learning rate of 0.00003 and train the models for maximum 9 epochs on 4-8 A100 Gpus.\nEvaluation Metrics Viewing DialohUSR as a sequence generation task, i.e. concatenating the segmented single-intent queries with semicolons like Q4 in Fig 5, we use BLEU-4 (Papineni et al., 2002), METEOR (Lavie and Denkowski, 2009), ROUGE-L (Lin, 2004), which are three commonly\nStep1. Initial Query Collection\n!\"#$%&'()*+,-. Check the high-speed train from Xiamen to Nanjing on Friday afternoon\nTask-oriented Query Datasets /0123!\"4%5'(671 #$%&)*+,-. Hi, I wanna check the high-speed train that departs from Xiamen and arrives in Nanjing on Friday afternoon Sampling\nSentence Simplification\nStep2. Follow-up Query Creation\n89: !\"#$%&'()*+,-. Check the high-speed train from Xiamen to Nanjing on Friday afternoon\n8;: <3=>?@ How long does it take 8A: !4%BC,DEFG Check out the special cuisine there\nStep3. Query Aggregation\n89: !\"#$%&'()*+,-. Check the high-speed train from Xiamen to Nanjing on Friday afternoon\n8;: <3=>?@ How long does it take 8A: !4%BC,DEFG Check out the special cuisine there\nHIIJKILMNOP: !\"#$%&'()*+,-.<3= >?@QR!4%BC,DEFG Check the high-speed train from Xiamen to Nanjing on Friday afternoon, how long does the journey take, then check out the special food there.\n8;: <3=>?@ How long does it take\n8A: !4%BC, DEFG Check out the special cuisine there\n8;SJKT: '()*+,-.< 3=>?@ How long does it take to travel from Xiamen to Nanjing in high-speed train\n8ASJKT: !4%*+,DEFG Check out the special cuisine in Nanjing\nStep4. Query Completion\nUPVWMX89Y: !\"#$%&'()*+,-.<3=> ?@QR!4%BC,DEFG Check the high-speed train from Xiamen to Nanjing on Friday afternoon, how long does the journey take, then check out the special food there.\nZV[NMX8;Y: !\"#$%&'()*+,-. \\Z]^ < 3=>?@ \\Z]^QR!4%BC,DEFG Check the high-speed train from Xiamen to Nanjing on Friday afternoon [SP] how long does the journey take [SP] then check out the special food there.\n_K[KMKX8AY: !\"#$%&'()*+,-. \\Z]^ <3=>?@ \\Z]^ !4%BC,DEFG Translation is the same as above\n`OaV[KMKX8bY: !\"#$%&'()*+,-. \\Z]^ '()*+,-.<3=>?@ \\Z]^ !4%*+, DEFG Check the high-speed train from Xiamen to Nanjing on Friday afternoon [SP] How long does it take to travel from Xiamen to Nanjing in highspeed train [SP] Check out the special cuisine in Nanjing\n`LWcL[ `OaV[KMK: ZMKV9X8dYe!\"#$%&'()*+,-. fg !\"#$%&'()*+,-. Check the high-speed train from Xiamen to Nanjing on Friday afternoon => Translation is the same as above ZMKV;X8hYe!\"#$%&'()*+,-. \\Z]^ < 3=>?@ fg '()*+,-.<3=>?@ Check the high-speed train from Xiamen to Nanjing on Friday afternoon [SP] how long does the journey take => How long does it take to travel from Xiamen to Nanjing in high-speed train ZMKVAX8iYe!\"#$%&'()*+,-. \\Z]^ < 3=>?@ \\Z]^ QR!4%BC,DEFG fg !4%*+,DEFG Check the high-speed train from Xiamen to Nanjing on Friday afternoon [SP] how long does the journey take [SP] then check out the special food there => Check out the special cuisine in Nanjing\njPklMOlKPk Xj;jY: 89 \u2192 8b mTOlcMLIK XnPoKY: 89 \u2192 8; \u2192 8b mTOlcMLIK X`LcWL[Y: 89 \u2192 8; \u2192 \\8d \u2192 8h \u2192 8i^\nFigure 5: The overview for the actions taken to transform a multi-intent complex user query (Q1) to the executable single-intent queries (Q4). We use red, blue and green to highlight the text fillers, omitted information and query delimiters, respectively.\nused automatic evaluation metrics to measure the ngram similarity with the reference in the token level. We also propose two new sentence-level metrics, namely Split Accuracy (SACC) and Exact Match (EM) to evaluate the model performance for DialogUSR. Specifically SACC measures the ratio of correct query splitting. We consider a multiquery to be correctly separated if the models split it into exactly the same number of queries as the reference:\nSACC = 1\nn \u2211 1\u2264i\u2264n I len(Q(i)pred)=len(Q (i) ref ) ,\nwhere n is the number of instances, I is the indicator function, Q(i)pred and Q (i) ref are the i-th predicted and reference query list. As for EM, we consider it correct if the predicted query is exactly the same\nas the reference one:\nEM =\n\u2211 i \u2211 j IQ(i)pred_j=Qiref_j\u2211\n1\u2264i\u2264n len(Q (i) ref )\n,\nwhere Q(i)pred_j and Q (i) ref_j represent the j-th predicted and reference query of the i-th instance. We calculate Exact Match in three different situations: EM-Complete, where we only consider the queries that does not need further modification (Q5 in Fig 5); EM-Rewritten, where delete or complete actions are needed (Q6, Q7 in Fig 5); and finally EM-Average, in which we consider all the queries."
        },
        {
            "heading": "6 Analysis and Discussions",
            "text": "Baseline performance Table 1 shows the performance of the baseline models on DialogUSR. For\n!\"#$%& '()*+,-./0123456789: ;<=>?4@34ABCD/-.E01AFGH First search the train tickets from Guangzhou to Nanning and I want to know how many trains are there; how long does it take to arrive by train; how far is it to travel from Guangzhou to Nanning\nIJKJLJ\"MJ&)*+,-./012345 NOPQR-./ 01234<=>?4 NOPQR-./01@34ABC D/ NOPQR-.E01AFGH Search the train ticket from Guangzhou to Nanning [SP] How many trains are there from Guangzhou to Nanning [SP] How long does it take to arrive in Nanning from Guangzhou by train [SP] How far is it to travel from Guangzhou to Nanning.\nS\"TU%VUJ\"T&)*+,-./012345 NOPQR,./01<=>?4 NOPQR,-.@34ABCD/ NOPQR-.E01AFGH Search the train ticket from Guangzhou to Nanning [SP] How many trains are there from Guangzhou to Nanning [SP] How long does it take to travel by train from Guangzhou [SP] How far is it to travel from Guangzhou to Nanning\nWXVUY%Z[J\\V\"MJ]&)*+,-./012345 NOPQR ,-./01<=>?4 NOPQR,-.@34ABCD /01 NOPQR-.E01AFGH NOPQR Search the train ticket from Guangzhou to Nanning [SP] How many trains are there from Guangzhou to Nanning [SP] How long does it take to arrive in Nanning by train from Nanning [SP] How far is it to travel from Guangzhou to Nanning WXVUY%Z[J\\MZ$YZ^]_)*+,-./012345 NOPQR-./01234<=>?4 NOPQR-./01 @34ABCD/ NOPQR-.E01AFGH Translation is the same as the reference\nFigure 7: The demonstration of generated outputs for different baseline models. The query marked in red is wrong due to the missing destination of the train, while the query marked in blue is a paraphrase of the the reference.\nboth end-to-end and two-stage generative baselines, enlarging the model parameters of mT5 models leads to a considerable performance gain, which indicates that powerful pretrained models with larger capacity are important in learning query transformation in DialogUSR. In terms of the comparisons between end-to-end and two variants of two-stage models, we observe that for mT5-base and mT5large, the causal-style two-stage model is the clear winner among the three models, which shows that the query-by-query transformation (Q5\u2192Q6\u2192Q7 in Fig 5) is the most effective way to recover the missing information while reformulating the queries. For mT5-xl, the performance gap between two-stage and end-to-end baselines is largely reduced, indicating powerful trained models may close the gap between different baselines.\nWe also report the model performance on the existing multi-intent detection datasets, namely MixSNIPS and MixATIS. As mentioned in Sec 3, both of them are created by inserting specific conjunctions between two complete single-intent queries from the SNIPS (Coucke et al., 2018) or ATIS\n(Hemphill et al., 1990) datasets, without any coreference or omission phenomenon. In other words, both of them can be effectively solved with an endto-end model using the Delete and Split actions. The large performance gap of the same model on the MixATIS/ MixSNIPS and the proposed DialogUSR verifies that the multi-intent query splitting and reformulation task is far from solved.\nFindings in the different action combinations As elaborated in Sec 4.3 and Fig 5, the Split, Delete and Complete actions can be permuted during the generation. We thus try to find the most effective action combination for the two-stage (once) model as shown in Table 2. We find that 1) The 3-stage models7 (SP\u2192DE\u2192 CP) are not necessary in the multi-stage generation compared with its two-stage variants (SP\u2192 (DE+CP)) because of the risk of error propagation (performance drop) and larger computational overhead. 2) The Split action should be placed in the first stage, as placing it in the second stage exhibit large performance drop, e.g. SP \u2192 (DE+CP) and (DE+CP) \u2192 SP. Presumably this is because the query splitting transformation may not be robust to the potentially ill-formed rewritten queries due to the lack of exposure to the noisy training data. 3) The Delete and Complete actions should be merged and placed in the second stage of generation. These two actions together can be viewed as a rewriting operation that deletes the conjunctions and recovers the missing information.\nDetailed analysis on model outputs As the DialogUSR is actually a domain-agnostic query rewriting task, we investigate the performances of the baseline models with different training data scale in Fig 6 (left). With less training data, we observe a clear boost while employing the two-stage models. Fig 6 (right) shows the model performance while generating the sub-queries in different positions, e.g. Q5, Q6, Q7 in Fig 5) correspond to the first, second and third queries while splitting the multi-intent complex query. We observe a large performance drop while comparing the first query and the subsequent queries, because in real-world scenarios most users would not include coreferences or omissions in the query, which make it much easier to split and complete the first sub-query.\nWe also provide a case study for the generated outputs from different baseline models in Fig 7.\n7We try different actions permutations on the 3-stage models and put the most effective combination in Table 2.\nBoth the models trained with the two-stage strategy produce correct and executable single queries, while the end-to-end model misses the destination information in the third query, which would end up with the false parsing results in the downstream NLU modules of conversational agents."
        },
        {
            "heading": "7 Related Work",
            "text": "Incomplete Utterance Restoration To convert multi-turn incomplete dialogue into multiple singleturn complete utterance, two major paradigms are available currently. One straight-forward way is to consider it as a sequence-to-sequence problem, using models including RNN (Pan et al., 2019; Elgohary et al., 2019), Trans-PG+BERT (Hao et al., 2021) and T5 with importance token selection (Inoue et al., 2022). And since the source and target utterances are highly overlapped, another approach is to edit rather than generate from scratch, specifying the operation by sequence tagging. Pan et al. (2019) proposed Pick-and-Combine model, while Liu et al. (2020a) introduced Rewritten U-shaped Network which imitates semantic segmentation by predicting the word-level edit matrix, and with similarity Huang et al. (2021) used a semi auto-regressive generator. Later, Hao et al. (2021) proposed RUST to address the robustness issue and Jin et al. (2022) proposed hierarchical context tagging to achieve higher phrase coverage.\nMulti-intent detection Spoken language understanding (SLU) which consists of intent detection and slot filling is the core in spoken dialogue systems(Tur and De Mori, 2011). Intent detection mainly aims to classify a given utterance with its intents from user inputs. Considering this strong correlation between the two tasks, some joint models are proposed based on the multi-task learning framework. (Zhang and Wang, 2016; Goo et al., 2018; Qin et al., 2019; Yao et al., 2014; Li et al., 2018). Li et al. (2018) proposed the gate mechanism to explore incorporating the intent information for slot filling. Convolutional-LSTM and capsule network have been proposed to solve the problem (Xia et al., 2018). Gangadharaiah and Narayanaswamy (2019) shows that 52% utterances are multi-intent in the Amazon internal dataset which indicate that in real world scenario, however, users often input utterance containing multi-intent. Therefore, Rychalska et al. (2018) first adopted hierarchical structures to identify multiple user intents. Qin et al. (2020) associate multi-intent detec-\ntion with slots filling via graph attention network. Larson and Leach (2022) offers a thorough overview on the existing multi-intent detection datasets. Except from MixATIS and MixSNIPS datasets, TOP (Gupta et al., 2018) contains multiintent queries annotated in a hierarchical manner which dramatically improves the expressive power while DialogUSR contains queries and rewriting queries which can bridge the single-intent dection and multi-intent detection and also decoupling the query intent detection section and multi-intent query separation section. NLU++ (Casanueva et al., 2022) has been collected, filtered and carefully annotated by dialogue NLU experts while DialogUSR queries are created by human annotators and aggregated by rules and evaluated by model which lead to a lower cost of data annotation than NLU++."
        },
        {
            "heading": "8 Conclusion",
            "text": "We propose DialogUSR, a dialog utterance splitting and reformulation task and corresponding dataset, for multi-intent detection in the conversational agents. The model trained on DialogUSR can serve as a domain-agnostic and plug-in module for the existing product chatbots with minial efforts. The proposed dataset contains 11.6k high quality instances that cover 23 domains with a multi-step annotation process. We propose multiple action-based generative baselines to benchmark the dataset and analyze their pros and cons through a series of investigations.\nLimitations\nThe proposed DialogUSR focuses on a single task for the research community and lacks of implementation details in the product conversational agents. The approaches on how the proposed DialogUSR interacts with other modules, e.g. dialog manager, ranking module for candidate NLU parsing results, remains an interesting and important research area. We position our work in the line of researches which enhances advanced conversational AI (i.e. multi-turn or multi-intent) by query rewriting, and leave multi-intent slot-filling entity annotation to the further work."
        },
        {
            "heading": "Acknowledgement",
            "text": "We thank all the anonymous reviewers for their insightful feedback. This paper is supported by the National Key Research and Development Program\nof China 2020AAA0106700 and the National Natural Science Foundation of China (NSFC) project U19A2065."
        },
        {
            "heading": "B Query Aggregation Detail",
            "text": "In Table 5, we provide conjunction probability distribution when we have four queries need to be aggregated. Conjunction0 is placed at the head of consecutive query1. Conjunction1, Conjunction2 and Conjunction3 is placed at the tail of consecutive query1, query2 and query3 respectively. As described in Table 5, Conjunction0 have 50% chance to be empty and 25% probability to be \u201c\u5148\u201d(first) and another 25% chance to be \u201c\u9996\u5148\u201d(first of all). Similarly, Conjunction1 is placed at the middle of query1 and query2 with the probability described in the table and so on. Table 6 shows the probability distribution of conjunctions when three consecutive queries that need to be aggregated. We generate 10 candidate multi-intent queries by joining consecutive queries with conjunctions described in Table 5 and Table 6. After query aggregation, we calculate the perplexity of ten candidate multi-intent queries and select the most fluent sentence as multi-intent query in DialogUSR."
        },
        {
            "heading": "C DialogUSR Cases In All Domains",
            "text": "In Figure 8, for every twenty three domains, we respectively provide one case to show our dataset. All twenty three domains in DialogUSR are listed in Figure 8 including Attraction, TV, Railway, Weather, Restaurant, Flight, Movie, Hotel, Car, Hospital, Courses, Cook, News, App, Navigation, Music, Translation, Mail, Dial, Disease, Time, Sports. Query indicates the multi-intent query in\nDialogUSR and Query1 to Query4 represent the single-intent queries in DialogUSR.\nAs mentioned in Follow-up Query Creation section, we observe that 37.3% multi-intent queries involve topic switching and this phenomenon can be found in case of Translation, Time, Phone Courses etc. In Translation case, query1 to query3 is about translation while query4 What is the route to Tiananmen(\u53bb\u5929\u5b89\u95e8\u7684\u8def\u7ebf\u662f\u4ec0\u4e48) is about Navigation. As shown in Figure 4, a large amount of sub-queries in multi-intent query is missing information therefore they need to be rewritten by hu-\nman annotators. This situation can be easily found in many cases, for example, TV case, Railway case, Weather case, Restaurant case etc. For example, in Railway case, the sub-query I would also like to know what time is the latest train? (\u6211\u8fd8\u60f3\u77e5\u9053\u6700 \u665a\u7684\u8f66\u6b21\u662f\u51e0\u70b9\uff1f) lack the key information and human annotator rewirte the sub-query as What is the latest train number to Zhengzhou (\u5230\u90d1\u5dde \u6700\u665a\u7684\u8f66\u6b21\u662f\u51e0\u70b9). We also provide a English version of twenty three cases in every domain in Fig 9."
        },
        {
            "heading": "D Broader Impact and Ethnic Consideration",
            "text": "Data in DialogUSR does not involve user privacy. The data source we collect from SMP-ECDT and RiSAWOZ is open source for research and is licensed under the MIT License which is a short and simple permissive license with conditions only requiring preservation of copyright and license notices.\nOur generative baseline models have very low risk in terms of producing discriminatory, insulting words or divulging privacy due to the fact all the training data are strictly screened and do not include private user information or insulting content. All involved annotators voluntarily participated with decent payment."
        }
    ],
    "title": "DialogUSR: Complex Dialogue Utterance Splitting and Reformulation for Multiple Intent Detection",
    "year": 2022
}