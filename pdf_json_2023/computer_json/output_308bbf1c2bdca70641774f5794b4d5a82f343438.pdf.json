{
    "abstractText": "In this article we construct a maximal set of kernels for a multiparameter linear scale-space that allow us to construct trees for classification and recognition of one-dimensional continuous signals similar the Gaussian linear scale-space approach. Fourier transform formulas are provided and used for quick and efficient computations. A number of useful properties of the maximal set of kernels are derived. We also strengthen and generalize some previous results on the classification of Gaussian kernels. Finally, a new topologically invariant method of constructing trees is introduced.",
    "authors": [
        {
            "affiliations": [],
            "name": "Leon A. Luxemburg"
        },
        {
            "affiliations": [],
            "name": "Steven B. Damelin"
        }
    ],
    "id": "SP:1152ae9b8f55098e4776a9dfcba902456767caab",
    "references": [
        {
            "authors": [
                "M. Abramowitz",
                "I.A. Stegun"
            ],
            "title": "Handbook of mathematical functions",
            "venue": "\u201cDover\u201d, 1965, 9th printing",
            "year": 1970
        },
        {
            "authors": [
                "A. Aldroubi",
                "K. Gr\u00f6chenig",
                "L. Huang",
                "P. Jaming",
                "I. Krishtal",
                "J.L. Romero"
            ],
            "title": "Sampling the flow of a bandlimited function, arXiv:2004.14032",
            "year": 2004
        },
        {
            "authors": [
                "J. Babaud",
                "A.P. Witkin",
                "M. Baudin",
                "R.O. Duda"
            ],
            "title": "Uniqueness of the gaussian kernel for scale-space filtering",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell. 8 ",
            "year": 1986
        },
        {
            "authors": [
                "M.R.J.J. Benedetto"
            ],
            "title": "Dellomo, Reactive Sensing and Multiplicative Frame Super-resolution, arXiv:1903.05677",
            "year": 1903
        },
        {
            "authors": [
                "G. Chilov"
            ],
            "title": "Analyse math\u00e9matique: fonctions d\u2019une variable",
            "venue": "3e partie, \u00c9ditions Mir, Moscow",
            "year": 1973
        },
        {
            "authors": [
                "T.T. Clark"
            ],
            "title": "Singularities of contrast functions in scale space",
            "venue": "1st Int. Conf. Computer Vision, London. Proceedings",
            "year": 1987
        },
        {
            "authors": [
                "R. Duits",
                "L. Florack"
            ],
            "title": "J",
            "venue": "deGraaf and B. H. Romeny, On the axioms of scale space theory, Journal of Mathematical Imaging and Vision 20 ",
            "year": 2004
        },
        {
            "authors": [
                "L.M.J. Florack",
                "B.H. Romeny",
                "J.J. Koenderink",
                "M.A. Viergever"
            ],
            "title": "Scale and the differential structure of images",
            "venue": "Image Vision Comput. 10 ",
            "year": 1992
        },
        {
            "authors": [
                "J.J. Koenderink"
            ],
            "title": "The structure of images",
            "venue": "Biological Cybernetics 50 ",
            "year": 1984
        },
        {
            "authors": [
                "T. Lindeberg"
            ],
            "title": "Scale-space: A framework for hand ling image structures at multiple scales",
            "venue": "Reports-cern European organization Eureopean organization for Nucelar Research ",
            "year": 1996
        },
        {
            "authors": [
                "F Mokhtarian",
                "A.K. Mackworth"
            ],
            "title": "Scale-based description and recognition of planar curves and two-dimensional objects",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell. 8 ",
            "year": 1986
        },
        {
            "authors": [
                "F. Mokhtarian",
                "A.K. Mackworth"
            ],
            "title": "it Scale-based description and recognition of planar curves and two-dimensional shapes",
            "venue": "Tech. report, Vancouver, BC, Canada, Canada",
            "year": 1984
        },
        {
            "authors": [
                "E.J. Pauwels",
                "L.J. Van Gool",
                "P. Fiddelaers",
                "T. Moons"
            ],
            "title": "An extended class of scale-invariant and recursive scale space filters",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence 17 ",
            "year": 1995
        },
        {
            "authors": [
                "E.J. Pauwels",
                "T. Moons",
                "L.J. Van Gool",
                "A Oosterlinck"
            ],
            "title": "Scale space filters",
            "venue": "Geometry and topology of submanifolds, IV (Leuven, 1991), World Sci. Publ., River Edge, NJ, 1992, pp. 277\u2013285. MR MR1185733 ",
            "year": 2033
        },
        {
            "authors": [
                "G.E. Shilov"
            ],
            "title": "Elementary real and complex analysis",
            "venue": "Dover Publications Inc., Mineola, NY",
            "year": 1996
        },
        {
            "authors": [
                "G.E. Shilov"
            ],
            "title": "Elementary real and com:plex analysis",
            "venue": "english ed., Dover Publications Inc., Mineola, NY",
            "year": 1996
        },
        {
            "authors": [
                "K. Somchaipeng",
                "J. Sporring",
                "S. Kreiborg",
                "P. Johansen"
            ],
            "title": "Transitions of multi-scale singularity trees",
            "venue": "Lecture Notes in Computer Science ",
            "year": 2005
        },
        {
            "authors": [
                "J. Sporring"
            ],
            "title": "Gaussian scale-space theory",
            "venue": "Computational imaging and vision, vol. 8, Dordrecht, Kluwer Academic Publishers",
            "year": 1997
        },
        {
            "authors": [
                "T. Wada",
                "M. Sato"
            ],
            "title": "Scale-space tree and its hierarchy",
            "venue": "Pattern Recognition, 1990. Proceedings., 10th International Conference on ii ",
            "year": 1990
        },
        {
            "authors": [
                "J. Weickert",
                "S. Ishikawa",
                "A. Imiya"
            ],
            "title": "Linear scale-space has first been proposed in Japan",
            "venue": "J. Math. Imaging Vision 10 ",
            "year": 1999
        },
        {
            "authors": [
                "A.P. Witkin"
            ],
            "title": "Scale space filtering: A new approach to multiscale description",
            "venue": "Image Understanding (S. Ullman and W. Richards, eds.), Ablex: Norwood, NJ.",
            "year": 1984
        },
        {
            "authors": [
                "A.L. Yuille",
                "T.A. Poggio"
            ],
            "title": "Scaling theorems for zero crossings",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell. 8 ",
            "year": 1986
        }
    ],
    "sections": [
        {
            "text": "ar X\niv :2\n30 5.\n13 35\n0v 1\n[ m\nat h.\nST ]"
        },
        {
            "heading": "1 Introduction",
            "text": "Scale-space filtering provides a powerful framework for the structural feature extraction, and classification and recognition of waveforms. It is based on convolving a signal with a one-parametric family of kernels and the convolutions can be used to construct certain trees to correspond to the original signal ( [5, 17, 23, 26, 28]). In this article we solve the following important problems: (I) We construct a maximal set of kernels that allows us to construct trees and have the property that the signals with the same shape result in equivalent trees. It turns out that this maximal set of kernels is a set of pth frac tional derivatives of a Gaussian. (We introduce a variety of these fractional derivatives in this and in subsequent articles). Our main result,\n\u2217Department of Mathematics, Texas A& M University at Galveston, Texas, U.S.A.: luxembul@tamug.edu \u2020Department of Mathematics, University of Michigan, 530 Church Street, Ann Arbor, MI 48109, USA: damelin@umich.edu\nstated at the beginning of Section 4, strengthens and generalizes the results obtained in [5] and [28], and demonstrates an alternative for linear scale-space representation of signals beyond the widely published Gaussian method ( [5, 13, 14, 20, 28], and more recent methods using a spectrum of families of kernels ( [12,15,19,24,27] ). (II) In this section we introduce a new, topologically invariant way of constructing trees, which we expect to be less sensitive to noise. (III) In Section 5 we calculate the Fourier transforms of the kernels, which gives us a quick and efficient computational procedure for constructing trees. (IV) In Section 2 we review the scale-space axioms and explained how they are incorporated into our formulas. Briefly, we base our scale-space on the following axioms: (*) translation invariance (*) linearity (*) strong causality (*) scale invariance The axioms we do not incorporate are the (*) semi-group axiom (*) preservation of positivity (V) In Section 5 we prove a number of properties concerning the convergence of functions \u03c6(x, y) and their partial derivatives, where \u03c6(x, y) is defined as a convolution of a signal f(x) with a kernel \u039b\u03b1\u03b2p(x, y). We develop a general theory of convergence of kernels.\nIn the next article [16] we continue as follows: (VI) Using results in (I) and (II) above, we give a complete topological description of level curves \u03c6x(x, y) = c as well as level curves of arbitrary partial derivatives of \u03c6(x, y). (VII) If we consider a convolution \u039b\u03b1\u03b2p(x, y) = f(x) \u2217\u039b\u03b1\u03b2p(x, y) of a signal f(x) with a kernel \u039b\u03b1\u03b2p(x, y) then as \u03b1, \u03b2 and p vary, this results in different zero crossings and different trees. We study bifurcations of the curves under parameter change. This gives us useful integer invariants for the signal which provides another way to classify the signals. We also use methods of differential and algebraic topology to derive some global formulas for tree invariants.\nLet G(x, \u03c1) =\n\u03c1\u221a 2\u03c0 e\u2212(x\u03c1) 2/2, \u03c1 > 0, (1)\nbe a family of Gaussian kernels with parameter \u03c1 varying on (0,\u221e). For every \u03c1 > 0 and signal f(x), one can consider a convolution\n\u03c6(x, \u03c1) = f(x) \u2217G(x, \u03c1) \u2261 \u222b \u221e\n\u2212\u221e f(x\u2212 v)G(v, \u03c1)dv =\n\u222b \u221e\n\u2212\u221e f(v)G(x\u2212 v, \u03c1)dv ,\nand on the half plane (x, \u03c1), \u03c1 > 0 we construct level curves \u03c6(x, \u03c1) = 0 for fixed \u03c1. It turns out that Gaussian kernels provide a certain monotonicity condition which guarantees that as \u03c1 increases, maxima of \u03c6(x, \u03c1) increase and minima decrease. (In many references this property is called causality [15] or strong causality [12], and may be regarded as an axiom of scalespace theory.) This, in turn, guarantees that contours \u03c6(x, \u03c1) = 0 can close above but not below. A.P. Witkin has proposed to construct the trees in the following way in [5, 28]: a horizontal line is drawn touching the highest contour at its apex. The region between the x-axis and the horizontal line is then divided by the highest contour into three sub-regions which correspond to three branches of the first rank in the tree. As we proceed by drawing horizontal lines through the next highest apex of a contour, we get further subdivision of a sub-region into three parts, which gives us the branches of the second rank, etc., resulting in a trinary tree. The order of the branches of the same rank cannot be changed. The advantage of this method is that it is hierarchical, i.e., if three branches come out of a certain node (horizontal line), there would be no additions (of branches) to this node as \u03c1 increases. We note that this method may distinguish between two topologically equivalent sets of contours. (Two curves \u03c61 and \u03c62 on our halfplane can be called topologically equivalent if there is a homeomorphism of the closed half plane onto itself such that \u03c61 maps onto \u03c62.)\nIn the present paper we propose a new method for constructing a tree which can be used as an alternative to the very useful method described above. First, we form a node and construct first rank branches corresponding to connected contours that are not inside other contours. Then from each new node n, we construct branches corresponding to contours lying inside the contour corresponding to the node n. This forms branches of the second rank, etc. We expect these trees (which need not be trinary) to be less susceptible to noise \u2014 which would be unlikely to disturb the topological equivalence of contours. For a function f , the trinary tree constructed by the Witkin method (first method) will be denoted by TW (f). The tree constructed via topological invariance (second construction) is denoted by TT (f). It is easy to see that if TW (f) = TW (g) for two functions f and g, then TT (f) = TT (g). The converse is not true in general.\nConstructing a tree TT (f) or TW (f) is a first important step in signal classification. It is clear, however, that a class of functions having the same\ntree is very broad. In some instances we would like to have a quick and rather coarse classification, but in many cases we want to separate various signals whose trees are identical. Consider, for example, a class An of functions having no more than n extrema. This class contains all polynomials of degree at most n+ 1. Clearly, An has an uncountable number of elements. However, it is easy to prove that there could be only a finite number of trees of both kinds constructed for the functions of this class. As a further step in refining this classification one might suggest using partial derivatives \u2202\nnG \u2202xn of\na Gaussian as convolution kernels. It turns out that for a rather large class of signals (containing all those that grow not faster than an exponential) one can prove that\nf(x) \u2217 \u2202 nG \u2202xn = (\u22121)n \u2202 nf \u2202xn \u2217G.\nThus, convolving with an nth partial derivative of G in constructing a tree is the same as constructing a tree TW ( f (n)(x) ) or TT ( f (n)(x) )\n, where f (n)(x) is the nth derivative of f(x). One might, therefore, construct a series of trees TW ( f (n)(x) ) or TT ( f (n)(x) )\nfor every function f , thus providing a finer classification. It is easy to see, however, that there still would be uncountable subsets of the class An consisting of elements indistinguishable by this classification. This is a motivation for finding a further refinement for signal classification, which we will do by also computing fractional derivatives of a Gaussian and allowing more than one parameter for describing the family of kernels. In addition, we propose to construct (along with trees for curves representing zero crossings \u03c6(x, \u03c1) = 0) trees for level curves \u03c6(x, \u03c1) = c, c 6= 0. The advantage of such a construction is (as we will prove in [16]) that under very general conditions these level crossings are bounded for c 6= 0 and therefore allow for construction of trees by methods described above. Using this fact we will, in [16], construct two-dimensional surfaces and use Morse Theory to construct useful integer invariants for the pattern recognition of signals."
        },
        {
            "heading": "2 Conditions for a Linear Scale-Space",
            "text": "In this article we will consider a signal f to be admissible if f \u2208 L2(R). More general admissible signals could be considered, but this is sufficient for practical purposes. Whenever a reference is made to an nth derivative f (n)(x) of an admissible signal, it is assumed that f(x) is n times differentiable.\nThe family of kernels must be such that the construction of the tree TWg(f) should be possible, i.e. the contours should satisfy the monotonicity\ncondition (or axiom of strong causality), which we express here (see [5]) as\n\u03c6\u03c1(x, \u03c1)\u03c6xx(x, \u03c1) < 0 whenever either \u03c6\u03c1(x, \u03c1) 6= 0 or \u03c6xx(x, \u03c1) 6= 0, where \u03c6(x, \u03c1) = f(x) \u2217 g(x, \u03c1), for g \u2208 M, (2)\nwhich is equivalent to the requirement that the level curves \u03c6(x, \u03c1) = c never close below (even locally), thus enabling us to implement the construction of trees from the level curves. Remark: If we require only monotonicity for zero crossing curves we need a somewhat weaker condition:\n\u03c6\u03c1(x, \u03c1)\u03c6xx(x, \u03c1) < 0 whenever \u03c6x(x, \u03c1) = 0 and either \u03c6\u03c1(x, \u03c1) 6= 0 or \u03c6xx(x, \u03c1) 6= 0.\n(3)\nRemark: We have expressed the function g = g(x) as depending on a single parameter \u03c1 (i.e., g = g(x, \u03c1)). We will show below that, in fact, more parameters will be needed in order to completely describe the maximal family M . The parameter \u03c1 is sometimes referred to as the bandwidth parameter ( [5] for example). The parameter (\u03c3) which is the reciprocal of \u03c1 is usually called the scale parameter ( [28] for example). If the scale parameter is used instead of the bandwidth parameter then the inequality in (2) changes direction.\nWe now state another condition on the set M : Suppose that a signal f(x) is convolved with g(x, \u03c1) \u2208 M at a certain value \u03c1 = \u03c10 , and let us scale f(x) up by a certain number k to get the signal f(kx). Since scaling does not change the fundamental properties of the signal, we should be able to recognize it as the same signal, i.e., to construct the same tree TWg (f(kx)) = TWg (f(x)). Clearly, for each \u03c1 the shape of the convolution f(kx) \u2217 g(kx, \u03c1) is the same as that of f(x) \u2217 g(x, \u03c1). We want, however, to require that after scaling of the argument x and convolving with g(x, y) we get the same shape of the signal as without scaling. More precisely, there should be a real number \u03c4 = \u03c4(k, \u03c1) such that for any \u03c1 > 0,\nf(kx) \u2217 g(x, \u03c4) = cf(x) \u2217 g(x, \u03c1)\nfor some constant c = c(k, \u03c1). In particular, this equality is to hold for the \u03b4-function. This implies that\ng(kx, \u03c4(k, \u03c1)) = cg(x, \u03c1).\nNow recall that the main idea of the scale-space approach is that the scale becomes finer as the parameter (\u03c1) increases, therefore for a fixed k, \u03c4(k, \u03c1)\nshould increase as \u03c1 increases. For the same reason, as k increases, \u03c4(k, \u03c1) should decrease. Thus,\n\u2202\u03c4(k, \u03c1)\n\u2202k < 0,\n\u2202\u03c4(k, \u03c1)\n\u2202\u03c1 > 0.\nFurthermore, since scaling x by k results in a signal with a k-times finer scale, we are motivated to define \u03c4(k, \u03c1) = \u03c1/k. Thus, our next requirement is that\ng ( kx, \u03c1\nk\n)\n= c(k, \u03c1)g(x, \u03c1). (4)\nThis equation is an expression of the axiom of scale invariance. Different expressions for this axiom are offered in [27] (where it is required that g(kx, \u03c1\u2032) = g(x, \u03c1\u2032) for some \u03c1\u2032), [15], and [12], for example. It implies, in particular, that the tree constructed for f(kx) is the same as the one constructed for a signal f(x).\nIn order to assure stability of a kernel and the existence of f \u2217 g(x, \u03c1) for continuous functions f \u2208 Lp(R(x)) with 1 \u2264 p \u2264 \u221e, we need the requirement g(x, \u03c1) \u2208 L1(R(x)) for all \u03c1 > 0, i.e.\n\u222b \u221e\n\u2212\u221e |g(x, \u03c1)|dx < \u221e, for all \u03c1 > 0. (5)\nFinally, we want to satisfy the maximality condition of M . This condition can be stated in two different ways:\nEvery kernel satisfying properties (2), (4) and (5) belongs to M, or\nevery kernel g(x, \u03c1) satisfying properties (2), (4) and (5) has an equivalent kernel l(x, \u03c1) \u2208 M . (Two kernels g(x, \u03c1) and l(x, \u03c1) are equivalent if and only if there exist two real numbers c and k such that cg(kx, \u03c1) = l(x, \u03c1).) We give the name MW to an alternative maximal set which is described in the same way as M except that the strong monotonicity condition (2) is replaced by a weak one (3). Thus MW is described by either\nEvery kernel satisfying properties (3), (4) and (5) belongs to MW , or\nevery kernel g(x, \u03c1) satisfying properties (3), (4) and (5) has an equivalent kernel l(x, \u03c1) \u2208 MW . We consider kernels g(kx, \u03c1) and g(x, \u03c1) equivalent because, if the condi- tion (4) is satisfied, we can obtain the kernel g(kx, \u03c10) up to a constant factor by scaling \u03c10 down by k and taking g(x, \u03c10/k). We will also con- sider kernel cg(x, \u03c1) equivalent to g(x, \u03c1) for\nany constant c 6= 0, because obviously, TWcg(f) = TWg(cf) = TWg(f) (this means that the axiom of linearity, with respect to multiplication, is satisfied by a convolution oper- ator) and we do not want to distinguish between f (x) and cf (x). Thus, equivalent kernels always result in the same tree for the same function. Remark: Notice that condition (2) makes sense only if the partial derivatives \u03c6xx, \u03c6\u03c1, and \u03c6x exist. This is guaranteed by the existence of partial derivatives gxx , gx , and g\u03c1 of the kernel g(x, \u03c1). We will therefore need to verify below that partial derivatives gx, g\u03c1 , and gxx exist and are continuous and that they belong to L1(R(x)). Remark: We have assumed a number of axioms which are required for an axiomatic basis for a linear scale-space representation of signals. Explicitly mentioned thus far are the axioms of linearity (with respect to multiplication), strong causality, and scale invariance. In addition, we have implicitly assumed the axiom of translation invariance, which is satisfied by a convolution operator acting on a signal. All of these axioms, together with the axiom of recursivity (also known as the semi-group axiom ): (f(x) \u2217 g(x, \u03c11)) \u2217 g(x, \u03c12) = f(x) \u2217 g(x, \u03c11 + \u03c12), are necessary for a linear integral operator on admissible signals to be a Gaussian convolution operator. (It has been shown in [19] that these axioms are, however, not sufficient for the operator to be Gaussian convolution. In fact, a continuum of convolution operators are possible, with the Gaussian kernel g(x, \u03c1) = G(x, \u03c1), Cauchy kernel g(x, \u03c1) = \u03c1\u03c0(1+\u03c12x2) , and sinc-function g(x) = sin(x) x being the three basic (closed-form) kernel functions which are possible. In this article we are not going to assume the axiom of recursivity, but we will assume (or have assumed) the other mentioned axioms. The family of kernel functions we will derive will be expressed in terms of a certain class of hypergeometric functions, so we pause to review some properties of these functions and introduce the class of functions we will need."
        },
        {
            "heading": "3 Review of Hypergeometric Functions",
            "text": "In order to derive our expression for the kernel functions g(x, \u03c1), we need to review some of the properties of hypergeometric functions; in particular, confluent hypergeometric functions. Furthermore we will show how these hypergeometric functions are related to derivatives of the Gaussian function G(x, \u03c1), and also show how certain confluent hypergeometric functions can be expressed as solutions of a second order linear differential equation. After that we will derive expressions for the Fourier transforms of these\nhypergeometric functions. For any a \u2208 R and any positive integer n denote by (a)n the rising factorial a(a+1) \u00b7 \u00b7 \u00b7 (a+n\u2212 1), and set (a)0 = 1. If b \u2208 R is not a negative integer or zero then the confluent hypergeometric function M(a, b, z), known as Kummer\u2019s function of the first kind, given by the series\nM(a, b, z) = \u221e \u2211\nn=0\n(a)n (b)n\nzn n! (6)\nis an entire function (the ratio convergence test guarantees convergence for all complex numbers z). For any real number p we define an even function \u039bep(x) and an odd function \u039b o p(x) as follows:\n\u039bep(x) = 1\u221a 2\u03c0 M\n(\np+ 1 2 , 1 2 ,\u2212x\n2\n2\n)\n= 1\u221a 2\u03c0\n\u221e \u2211\nn=0\n[\nx2n\n(2n)! (\u22121)n\nn\u22121 \u220f\nk=0\n(p+ 2k + 1)\n]\n= 1\u221a 2\u03c0 \u2212 (p+ 1)x 2 2! \u221a 2\u03c0 + (p+ 1)(p + 3)x4 4! \u221a 2\u03c0 \u2212 \u00b7 \u00b7 \u00b7 (7)\n\u039bop(x) = x\u221a 2\u03c0 M\n(\np+ 2 2 , 3 2 ,\u2212x\n2\n2\n)\n= 1\u221a 2\u03c0\n\u221e \u2211\nn=0\n[\nx2n+1\n(2n+ 1)! (\u22121)n\nn\u22121 \u220f\nk=0\n(p + 2k)\n]\n= x\u221a 2\u03c0 \u2212 (p+ 2)x 3 3! \u221a 2\u03c0 + (p+ 2)(p + 4)x5 5! \u221a 2\u03c0 \u2212 \u00b7 \u00b7 \u00b7 (8)\nFunctions \u039b\u03b8p(x), \u03b8 = e, o are entire for all p. The following properties are a consequence of the definitions (7) and (8).\n\u039be0(x) = e\u2212x\n2/2\n\u221a 2\u03c0 . (9)\nd\u039bep(x)\ndx = \u2212(p+ 1)\u039bop+1(x). (10)\nd\u039bop\u22121(x)\ndx = \u039bep(x). (11)\nTherefore,\nd2n\u039bep(x)\ndx2n = (\u22121)n(p+ 1)(p + 3) \u00b7 \u00b7 \u00b7 (p+ 2n\u2212 1)\u039bep+2n(x), (12)\nd2n\u039bop(x)\ndx2n = (\u22121)n(p+ 2)(p + 4) \u00b7 \u00b7 \u00b7 (p + 2n)\u039bop+2n(x). (13)\nBy setting p = 0 in these equations it follows that\nd2n\u039be0(x)\ndx2n = (\u22121)n(2n)!\u039be2n(x) 2nn! , (14)\nd2n\u039be0(x)\ndx2n = (\u22121)n+1(2n+ 2)!\u039b02n+1(x) 2n+1(n+ 1)! . (15)\nFor hypergeometric series, it is known [1, page 504] that if z is complex and R(z) < 0, then as |z| \u2192 \u221e we have the equality\nM(a, b, z) = \u0393(b)\n\u0393(b\u2212 a)(\u2212z) \u2212a\n( 1 +O ( |z|\u22121 )) . (16)\nNotice that the gamma function is not defined for integers less than or equal to zero. Therefore, (16) does not apply only when b\u2212a is zero or a negative integer. Equality (16) implies that for x real\n\u039bep(x) = C1x \u2212p\u22121\n( 1 +O ( |x|\u22122 )) as x \u2192 \u221e, (17)\n\u039bop(x) = C2x \u2212p\u22121\n( 1 +O ( |x|\u22122 )) as x \u2192 \u221e, (18) where C1 and C2 are determined from (16). By the previous comment, formula (17) does not apply only if p = 2n for any non-negative integer n, and formula (18) does not apply only if p = 2n + 1 for any non-negative integer n (in particular, it does apply if p = 0).\nSince the Gaussian kernel and its derivatives are in L1(R) formulas (9), (14) and (15) imply that \u039be2n(x) and \u039b o 2n+1(x) are in L1(R) for integers n \u2265 0. Also, it now follows from (17) and (18) that \u039b\u03b8p(x), \u03b8 = e, o are in L1(R) if p > 0, but not in L1(R) if p < 0. Furthermore \u039b e 0(x) \u2208 L1(R); however, \u039bo0(x) 6\u2208 L1(R). In addition, the following equalities are satisfied only if p > \u22121\nlim x\u2192\u221e \u039b\u03b8p(x) = limx\u2192\u2212\u221e \u039b\u03b8p(x), \u03b8 = e, o. (19)\n(This is obviously true for the Gaussian and its derivatives.) Let us continue with our preliminary observations. For real numbers a and p consider a differential equation\nh\u0308(x) + a2xh\u0307(x) + a2ph(x) = 0, (20)\nwhere\nh\u0308 = d2h(x)\ndx2 , h\u0307(x) =\ndh(x)\ndx . (21)\nLemma 3.1. Let h(x) be an arbitrary even (respectively odd) solution of equation (20). Then h(x) is given by\nh(x) = c\u03bbep\u22121(ax) ( respectively h(x) = c\u039bop\u22121(ax) )\n(22)\nwhere c = \u221a 2\u03c0h(0) ( respectively c = \u221a 2\u03c0h\u0307(0) ) . (23)\nThe general solution of equation (20) is a linear combination\n\u03b1\u039bep\u22121(ax) + \u03b2\u039b o p\u22121(ax). (24)\nProof. Since functions \u039b\u03b8p(x), \u03b8 = e, o are entire for every p, we can differentiate each monomial separately. It can be verified by direct substitution of (7) and (8) into (20) that the function c\u039bep\u22121(ax) (respectively c\u039b o p\u22121(ax)) satisfies (20) with initial conditions \u039bep\u22121(0) = c/ \u221a 2\u03c0 , d\u039bep\u22121(0) dx = 0, (respectively \u039b0p\u22121(0) = 0 , d\u039bep\u22121(0) dx = c/ \u221a 2\u03c0 ). Now let h(x) be an even (respectively odd) solution of (20) with initial conditions h(0) = \u03b1 , h\u0307(0) = 0 (respectively h(0) = 0, h\u0307(0) = \u03b2). From the uniqueness of solutions of differential equation (20), it follows that h(x) = \u03b1 \u221a 2\u03c0\u039bep\u22121(ax) (respectively\nh(x) = \u03b2 \u221a 2\u03c0\u039bop\u22121(ax) ). Hence we get the expression (24) for the general solution of (20).\nLemma 3.2. Let h(x) be a function satisfying two differential equations\nh\u0308(x) + a21xh\u0307(x) + a 2 1(p1 + 1)h(x) = 0, a1 6= 0, and (25) h\u0308(x) + a22xh\u0307(x) + a 2 2(p2 + 1)h(x) = 0, a2 6= 0. (26)\nThen a1 = a2 and p1 = p2 if h(x) is not identical ly zero.\nProof. By Lemma 3.1 and (25), (26) we have:\nh(x) = \u03b11\u039b e p1(a1x) + \u03b21\u039b o p1(a1x) = \u03b12\u039b e p2(a2x) + \u03b22\u039b o p2(a2x). (27)\nFrom (7) and (8) it follows that\nh(0) = \u03b11\u221a 2\u03c0 = \u03b12\u221a 2\u03c0 , h\u0307(0) = \u03b21\u221a 2\u03c0 = \u03b22\u221a 2\u03c0 . (28)\nThus, \u03b11 = \u03b12, and \u03b21 = \u03b22. By virtue of analyticity of the function h(x) and the uniqueness of power series expansion, the coefficients of corresponding terms xn are equal in both expressions for h(x) in (27). By equating these coefficients and using (6), (7) and (8) we obtain the desired result.\nTheorem 3.3. If p > 0, then the Fourier transforms F \u03b8p (\u03c9) of \u039b \u03b8 p(x), \u03b8 = e, o exist and\nF ep (\u03c9) = c|\u03c9|pe\u2212\u03c9 2/2 = c1(s p + (\u2212s)p)es2/2, (29) F op (\u03c9) = d] sign(\u03c9)i|\u03c9|pe\u2212\u03c9 2/2 = c1(s p \u2212 (\u2212s)p)es2/2, (30)\nwhere i2 = \u22121, c1 is some complex number, and c, d 6= 0 are some real numbers. Also, F e0 (\u03c9) = ce \u2212\u03c92/2.\nProof. The existence of the Fourier transform F is guaranteed by the absolute integrability (as noted above) of functions \u039bep(x) for p > 0, and by their differentiability.\nLet \u039bep(x) = h(x). Then, for every x it satisfies the equation\nh\u0308(x) + xh\u0307(x) + (p+ 1)h(x) = 0. (31)\nFormulas (17) and (18) guarantee the existence of Fourier transforms of each summand in (31), and its convergence to zero as |x| \u2192 \u221e. By applying the Fourier transform to (31), we get\ns2H(s)\u2212 d ds [sH(s)] + (p+ 1)H(s) = 0, (32)\nhere H(s) = F [h(t)] and s = i\u03c9, \u03c9 real. Here we used the fact that if F(g) = G(s), then F [g(t)t] = \u2212dG(s)ds provided \u222b\u221e \u2212\u221e tg(t)e \u2212stdt converges uniformly in s and \u222b\u221e \u2212\u221e g(t)e \u2212stdt converges (see [14, 11.55a]). In our case, g(t) = h\u0307(t) and the conditions on convergence follow from (17), (18) and from the fact that p > 0. From (32) it follows that H \u2032(s)\nH(s) = s+ p/s. Integrating this along i\u03c9 gives us\nH(s) = 2c1s pes 2/2. (33)\nThe path of integration should not include 0, since we have a singular point there. Thus, if s0 = i\u03c90, for any \u03c90 > 0, formula (33) holds for s = j\u03c9 with \u03c9 > \u03c90. Since H(s) must be real because h(t) is an even function, H(s) = c\u03c9pe\u2212\u03c9 2/2 for some real \u03c9 > 0 and c real. Now, since H(\u2212s) = H(s)\nfor an even h(x), we have H(s) = c|\u03c9|pe\u2212\u03c92/2 for s = i\u03c9, \u03c9 < 0. This proves (29), since F ep (\u03c9) = H(s), and (30) can be proved in an entirely similar fashion. The last statement follows from the fact that \u039be0(x) is the Gaussian function.\nNow we are ready to state our main result."
        },
        {
            "heading": "4 Multiple Parameter Scale-Space",
            "text": "Theorem 4.1. If {g(x, \u03c1), \u03c1 > 0} is a one-parametric family of kernels satisfying the scaling property (4), the stability condition (5), and i) the strong monotonicity condition (2) if and only if ii) the weak monotonicity condition (3) if\ng(x, \u03c1) = \u03b1\u03c1p+1\u039bep(ax\u03c1) + \u03b2\u03c1 p+1\u039bop(ax\u03c1)\nfor some real \u03b1, \u03b2, a and p > 0 or (in case p = 0)\ng(x, \u03c1) = \u03b1\u03c1\u039be0(ax\u03c1) = \u03b1G(ax, \u03c1),\nwhere \u039bep(x) and \u039b o p(x) are the one-parametric families of entire functions defined in (7) and (8), which belong to L1(R) for the indicated values of the parameter p.\nMoreover, \u22022nG(x, \u03c1)\n\u2202x2n = c2n\u03c1\n2n+1\u039be2n(x\u03c1), (34)\n\u22022n+1G(x, \u03c1)\n\u2202x2n+1 = c2n+1\u03c1\n2n+2\u039b02n(x\u03c1), (35)\nwhere c2n = (\u22121)n(2n)!\n2nn! , c2n+1 = c2(n+1) , and G(x, \u03c1) is the Gaussian kernel defined in (1).\nRemark: We are not requiring the axiom of recursivity in Theorem 4.1.\nBefore giving the proof of Theorem 4.1, we first need:\nLemma 4.2. Let \u00b5 and \u03bd be non-zero vectors in a vector space V , over the field of complex numbers, with a scalar product \u3008\u00b7, \u00b7\u3009.Then, the statement:\nfor any vector f \u2208 V such that either \u3008f, \u00b5\u3009 6= 0 or \u3008f, \u03bd\u3009 6= 0, we have \u3008f, \u00b5\u3009 \u00b7 \u3008f, \u03bd\u3009 < 0\nis true if and only if there is a negative number \u03b1 such that \u00b5 = \u03b1\u03bd.\nProof. Suppose that the statement is true, and \u00b5 = \u03b1\u03bd+\u03b6 for some scalar \u03b1 and vector \u03b6 6= 0 perpendicular to \u03bd. Then since \u3008\u00b5, \u03b6\u3009 = \u3008\u03b6, \u03b6\u3009 6= 0 we have, by hypothesis, that \u3008\u00b5, \u03b6\u3009 \u00b7 \u3008\u03bd, \u03b6\u3009 < 0, which contradicts our assumption that \u03bd is perpendicular to \u03b6. Therefore, we must have \u00b5 = \u03b1\u03bd. Now let us take f = \u03bd. Obviously, \u3008f, \u03bd\u3009 6= 0, and therefore, \u3008f, \u03bd\u3009 \u00b7 \u3008f, \u00b5\u3009 = \u03b1\u3008\u03bd, \u03bd\u30092 < 0 which implies that \u03b1 < 0. The proof of the converse is trivial.\nIn the proof which follows we will assume, as a result of the scale invariance axiom, that g(x, \u03c1) has the form\ng(x, \u03c1) = \u03b6(\u03c1)h(x\u03c1). (36)\nfor some continuous \u03b6 and h, so that the convolution of a horizontally scaled signal f(kx) with the kernel g(x, \u03c1) will be the same as the horizontally scaled convolution of the unscaled signal f(x) with the kernel g(x, \u03c1/k), times a constant. This assumption is more general that the assumption g(x, \u03c1) = \u03c12h(x\u03c1) made in [29], for instance, and slightly different from the assumption g(x, \u03c1) = \u03b6(\u03c1)h(x\u03b6(\u03c1)) made in [27]. The reader will see below that our assumption is suitable for our purposes.\nProof of Theorem 4.1. Let us write the expressions for \u03c6(x, \u03c1) and its partial derivatives.\n\u03c6(x, \u03c1) = \u03b6(\u03c1)\n\u222b \u221e\n\u2212\u221e f(\u03bd)h(\u03c1(x\u2212 \u03bd))d\u03bd\n\u03c6x(x, \u03c1) = \u03b6(\u03c1)\u03c1\n\u222b \u221e\n\u2212\u221e f(\u03bd)h\u0307(\u03c1(x\u2212 \u03bd))d\u03bd (37)\n\u03c6xx(x, \u03c1) = \u03b6(\u03c1)\u03c1 2\n\u222b \u221e\n\u2212\u221e f(\u03bd)h\u0308(\u03c1(x\u2212 \u03bd))d\u03bd (38)\n\u03c6p(x, \u03c1) =\n\u222b \u221e\n\u2212\u221e f(\u03bd)[\u03b6\u0307(\u03c1)h(\u03c1((x \u2212 \u03bd)) + \u03b6(\u03c1)h\u0307(\u03c1(x\u2212 \u03bd))]d\u03bd (39)\nBy making the substitution t = \u2212\u03bd\u03c1 , and defining f1(t) = f(\u03bd) = f(\u2212t/\u03c1), he integrals (37), (38) and (39) can be expressed as follows:\n\u03c6x(x, \u03c1) = \u03b6(\u03c1)\n\u222b \u221e\n\u2212\u221e f1(t)h\u0307(x\u03c1+ t)dt (40)\n\u03c6xx(x, \u03c1) = \u03b6(\u03c1)\u03c1\n\u222b \u221e\n\u2212\u221e f1(t)h\u0308(x\u03c1+ t)dt (41)\n\u03c6p(x, \u03c1) = 1\n\u03c1\n\u222b \u221e\n\u2212\u221e [\u03b6\u0307(\u03c1)h(x\u03c1 + t) + \u03b6(\u03c1)\n(\nx+ t\n\u03c1\n)\nh\u0307(x\u03c1+ t)]f1(t)dt (42)\nWe let \u03c4(t) = x\u03c1+t, then the strong monotonicity condition (2) is equivalent to the statement\nWhenever either \u3008f1, h\u0308 \u25e6 \u03c4\u3009 6= 0 or \u3008f1, \u03b6\u0307h \u25e6 \u03c4+]\u03c4 (\u03b6(\u03c1)/\u03c1) h\u0307 \u25e6 \u03c4\u3009 6= 0\nthen \u3008f1, h\u0308 \u25e6 \u03c4\u3009\u3008f1\u03b6\u0307(\u03c1)h \u25e6 \u03c4 + \u03c4 (\u03b6(\u03c1)/\u03c1) h\u0307 \u25e6 \u03c4\u3009 < 0, (43)\nwhere the scalar product of functions f1 and f2 in L2(R) is given by \u3008f1, f2 = \u222b\u221e \u2212\u221e f1(t)f2(t)dt. Let us denote \u00b5 = \u03b6\u0307(\u03c1)h\u25e6\u03c4+\u03c4 (\u03b6(\u03c1)/\u03c1) h\u0307\u25e6\u03c4 , and \u03bd = h\u0308\u25e6\u03c4 . Using this notation we may restate (43) as\nWhenever either \u3008f1, \u00b5\u3009 6= 0 or \u3008f1, \u03bd\u3009 6= 0, then \u3008f1, \u00b5\u3009\u3008f1, \u03bd\u3009 < 0 (44)\nFrom Lemma 4.2 this is equivalent to\n\u03bd \u2261 \u2212a2\u00b5, for some real number a = a(\u03c1), (45)\nwhich is equivalent to the differential equation\nh\u0308(t) + a2(\u03c1)\n[\n\u03b6\u0307(\u03c1)h(t) + \u03b6(\u03c1)\n\u03c1 th\u0307(t)\n]\n= 0. (46)\nEquation (46) has to be satisfied for all \u03c1 > 0. From Lemma 3.2, it follows that\na2(\u03c1)\u03b6(\u03c1)\n\u03c1 and a2(\u03c1)\u03b6\u0307(\u03c1) are constants. (47)\nTherefore, their ratio \u03c1\u03b6\u0307(\u03c1)/\u03b6(\u03c1) is a constant and there exists a number p such that\n\u03c1\u03b6\u0307(\u03c1)\n\u03b6(\u03c1) = 1 + p (or \u03b6\u0307(\u03c1) = (1 + p)\n\u03b6(\u03c1)\n\u03c1 ). (48)\nSolving this differential equation determines that\n\u03b6(\u03c1) = c\u03c1p+1, (49)\nfor some constant c 6= 0. Since the coefficients of (46) are constants, there exists a constant a 6= 0 such that (46) can be rewritten as\nh\u0308(t) + a2th\u0307(t) + a2(p + 1)h(t) = 0. (50)\nBy Lemma 3.1, h(t) is given by\nh(t) = \u03b11\u039b e p(at) + \u03b21\u039b o p(at), (51)\nand then from (36), (49) and (51) we find that the strong monotonicity condition (2) is equivalent to\ng(x, \u03c1) = \u03b1\u03c1p+1\u039bep(ax\u03c1) + \u03b2\u03c1 p+1\u039bop(ax\u03c1), (52)\nwhere \u03b1 = c\u03b11, \u03b2 = c\u03b21. The necessity and sufficiency of condition (5) follows from the statements in Section 3, and (4) follows immediately from (52). In addition, it follows from (41), (42), (46) and (49) that\n\u03c6xx(x, \u03c1) = \u2212\u03c6\u03c1(x, \u03c1)\u03c13. (53)\n(This is another way to see that (2) is satisfied). It is clear that the the weak monotonicity condition (3) is satisfied by the given family of kernels.\nRemark: We will show below that \u039bop(x) and \u039b e p(x) are in some sense pth fractional derivatives of a Gaussian. We have already shown this for integer (non-fractional) values of p in (34). Remark: The reason we are interested in the weak monotonicity condition is that it guarantees a possibility of constructing trees based on zero crossing curves only. Remark: In the proof of Theorem 4.1 we only required the kernel functions h to have two derivatives in x and one derivative in \u03c1. However, the kernel functions g(x, \u03c1) which we derive are in fact infinitely differentiable in x and \u03c1.\nTheorem 4.1 describes a maximal family of kernels which allow us to construct trees via methods described above and thus provide us with amaximal set of invariants that can be used to classify signals. Since g(x, \u03c1) in Theorem 4.1 is in L1(R) \u2282 L2(R) we can normalize so that \u222b\u221e \u2212\u221e |g(x, \u03c1)|2dx = 1. By means of Parseval\u2019s identity, this is equivalent to \u222b\u221e \u2212\u221e |F(g)(s, \u03c1)|2ds = 1. Then by making use of the Fourier transform idenities in (29) and (30) we obtain the relation\n\u03b12 \u2212 \u03b22 = 1 (a\u03c1)p\u0393(p + 1/2) . (54)\nThis means that our family M of kernels can be described by means of parameters a, \u03c1, p, and one coefficient paramter. In certain situations we may want to consider only kernel functions which have either even or odd symmetry. Hence we define\ngep(x, \u03c1) := \u03c1 p+1\u039bep(x\u03c1), p \u2265 0, (55) gop(x, \u03c1) := \u03c1 p+1\u039bop(x\u03c1), p > 0, (56)\nand we have the following:\nCorollary 4.3. Let g(x, \u03c1), \u03c1 > 0 be a parametric family of kernels satisfying conditions (2), (4) and (5) above, and let g be either even or odd with respect to x. Then there exist three real numbers c, a, and p such that\ng(x, \u03c1) = c\u03c1p+1\u039bep(ax\u03c1), p \u2265 0, if g(x, \u03c1) is even. (57) g(x, \u03c1) = c\u03c1p+1\u039bop(ax\u03c1), p > 0, if g(x, \u03c1) is odd. (58)\nAs we showed in Section 3 the kernels g\u03b8p(x, \u03c1) = \u03c1 p+1\u039b\u03b8p(x\u03c1), \u03b8 = e, o are not stable for p < 0. Moreover, for p < \u22121 the convolution g\u03b8p \u2217 f may not exist for an admissible signal because gp(x, \u03c1) no longer converges to zero as x \u2192 \u221e . However, if f(x) is a transient signal, i.e. a signal which is zero outside of some finite interval [\u2212T, T ], then convolutions gp \u2217 f are well defined for any real value p and any piecewise continuous signal f (and even for any signal f integrable on [\u2212T, T ]). An exact analogue of Theorem 4.1 (without the stability condition (5) and without the restriction p > 0) therefore applies for transient signals.\nLet us discuss the one-parametric families of trees TT ep (f) and TW e p (f).\nWe have seen before that TT e2n(f) = TT e 0 (f (2n)) and TW e2n(f) = TW e 0 (f (2n)). Since the trees for f (2n\u22122) and for f (2n) are obviously very different for most functions f , there are points p between 2n\u22122 and 2n at which the structures of trees TW ep (f) and TT e p (f) change. In fact, trees TT e p (f) and TW e p (f), in general, depend continuously on p, and such discontinuity in structure occurs only for a discrete set of p\u2019s (see [16]). Also, see [9] for interesting results in this direction.\nA more general approach can be taken if we consider contours \u2202 k\u03c6(x,\u03c1) \u2202xk\n= c where c is an arbitrary number and \u03c6(x, \u03c1) is defined as a convolution of f(x) and \u03b1\u039bep(x) + \u03b2\u039b o p(x). Obviously such contours depend on the parameters \u03b1, \u03b2, c and p, and we will study the change in the corresponding tree structure as these parameters vary. We will use Morse Theory to study these bifurcations and also study many useful properties of the convolutions with our kernels and compute Fourier transforms of our kernels. This allows us to efficiently implement our methods on computers."
        },
        {
            "heading": "5 Properties of Convolution Kernels",
            "text": "Throughout this section we will suppose that any function \u03c7\u03b8 (where \u03c7 may be any of F, f,\u039b, \u03c6, g) is defined for p \u2265 0 when \u03b8 = e, and defined for p > 0 when \u03b8 = o. We will also assume that k, l,m, n are integers and p, q are nonnegative real numbers.\nAs before, let gthetap = \u03c1 p+1\u039b\u03b8p(x\u03c1) where \u03b8 = e, o . Then, in order to be able to compute the convolution \u03c6\u03b8p(x, \u03c1) = f(x) \u2217 g(x, \u03c1) more efficiently, we need to know its Fourier transform. This will allow us to perform computations in the frequency domain. Another question closely related to this is a question of finding the limiting function \u03c6\u03b8p(x, \u03c1) as \u03c1 \u2192 \u221e. It is well known that for the Gaussian ge0(x, \u03c1), the Fourier transform is ce\ns2/\u03c12 where c is some constant. As \u03c1 \u2192 \u221e, ces2/\u03c12 \u2192 c ; thus, when we perform the convolution, we get the same signal f(x) in the limit (this is due to the fact that the \u03b4 - function has the Fourier transform equal to 1). Therefore, the limiting value for \u03c6\u03b80(x, \u03c1) as \u03c1 \u2192 \u221e is the function f(x) itself, i.e., as \u03c1 increases, the complexity of the convolution \u03c6\u03b80(x, \u03c1) increases until we come to a signal f(x) = \u03c60(x,\u221e) in the limit. It turns out that if n is an integer, the limiting function for \u03c6\u03b8n(x, \u03c1) as \u03c1 \u2192 \u221e is the nth order derivative of f(x), where \u03b8 is odd or even, depending on whether n is odd or even.\nWe will generalize this simple property for every p by finding the limit \u03c6\u03b8p(x, \u03c1) as \u03c1 \u2192 \u221e , proving its existence and showing that it is in some sense a fractional pth order derivative of the signal. We will also consider here a number of very useful properties of convolutions with g\u03b8p(x, \u03c1). Remark: Since the trees of the signals do not change if we scale it or multiply it by a constant, we will determine Fourier transforms only up to a constant factor and will not spend any time on determining these factors precisely.\nIn what follows, a function f(x) and its Fourier transform F(f) will be called a Fourier pair if they are connected by the usual direct and inverse Fourier transform formulas. In this case, we will write f \u223c F(f). In general, the direct Fourier transform formula does not imply the inverse, i.e., if F(f) = F (s), it is not generally true that f(x) = F\u22121 (F (s)).\nLet us recall a definition of fractional derivatives. Let q < 0, then [13]\ndqf(x)\ndxq =\n1\n\u0393(\u2212q)\n\u222b x\n0\nf(\u03c1)dy (x\u2212 \u03c1)q+1 = 1 \u0393(\u2212q)\n\u222b x\n0\nf(x\u2212 \u03c1)dy \u03c1q+1\n(59)\nThis definition of fractional derivatives belongs to Liouville. We propose a related but slightly different definition. Let F(f) = F (s); then for s = j\u03c9,\ndpf(x)\ndxp = f (p)(x) =\nc\n2\u03c0j\n\u222b \u221e\n\u2212\u221e spF (s)esxds, (60)\nprovided the integral converges. We put a constant real number in (60) as usual to emphasize that we are only interested in functions up to a scalar factor. In what follows, we will use the following simple fact from the theory of Fourier transforms (see [8]:\nProposition 5.1. If a function f(x) is continuously differentiable with f (n)(x) \u2208 L1(R) for all n, 0 \u2264 n \u2264 m, then for some c > 0,\n|F (f(x)) (s)| = |F (s)| \u2264 c|sm| . (61)\nWe give a motivation for our definition as follows: let \u00b5\u03b1(t) = t \u2212\u03b1 for t > 0 and \u00b5\u03b1(t) = 0 for t \u2264 0 where 0 < \u03b1 < 1; then F (\u00b5\u03b1(t)) (s) = s\u03b1\u22121\u0393(1 \u2212 \u03b1). Therefore, by the convolution theorem we have (supposing certain convergence properties are satisfied for every f(x) and p):\nf (p)(x) = F\u22121 (cspF (s)) =\nF\u22121 (csp) \u2217 f(x) = c\u00b5p+1 \u2217 f(x) = c \u222b \u221e\n0\nf(x\u2212 \u03c1) \u03c1p+1 dy.\nIf, in addition, f(\u03c1) = 0 for \u03c1 < 0 then f (p)(x) = c \u222b\u221e 0 f(x\u2212\u03c1) \u03c1p+1 dy and this coincides with the classical definition (59). We need to establish the range of applicability of definition (60) and show that it extends the usual definition of the derivative when p is an integer. Our purpose here is not to develop a fractional calculus, but to use some of its concepts to explain our results and their applications. As usual, we introduce the equivalence relation equating a function f(x) with cf(x) where c is a constant not equal to zero.\nTheorem 5.2. If a function f(x) satisfies the conditions of Proposition 5.1 with m > p+ 1, then\n(i) formula (60) gives us a wel l defined f (p)(x).\n(ii) Also, if xf(x) is in L1(R), then\ncspF (s) = F (f(p)(x)) , F (cspF (s)) = f (p)(x). (62)\n(iii) Formula (60) gives us the usual derivative if p is an integer.\n(iv) If p+ q + 1 < m, then d p\ndxp\n( dq dxq f(x) ) = d p+q dx(p+q) f(x).\nProof. (i) Follows immediately from (61). (ii) If xf(x) is in L1(R), then F (s) is continuously differentiable (see [8]). Therefore, spF (s) is continuously differentiable. It is also in L1(R) as is seen from (61) and the condition m > p+1. Since 2\u03c0if (p)(\u2212x) = F (cspF (s)) by (60), we can now apply the theorem on the inversion of the Fourier transform [8], and conclude that F ( f (p)(x) )\n= cspF (s) and f (p)(x) = F\u22121 (cspF (s)). (iii) If p is an integer, the assertion of (iii) is a very well known fact. (iv) Follows immediately from (ii) and (60).\nRemark: Formulas (33) and Theorem 5.2 imply that the linear combination hp(x) := \u03b1\u039b e p(x)+\u03b2\u039b o p(x) is actually the pth fractional derivative of c1G(x), which is the Gaussian function multiplied by some complex constant c1. It will turn out that the limit function for f(x) \u2217 h(x\u03c1) as \u03c1 \u2192 \u221e is f (p)(x). This is a very important generalization of the formula for p = 0. This property follows from the following theorem. Before we state Theorem 5.4, we need a preliminary lemma.\nLemma 5.3. Let f \u2208 L2(R) be a continuously differentiable function, then\n(a) \u03c6\u03b8p(x, \u03c1) = f(x) \u2217 \u03c1p+1\u039bep(x\u03c1), \u03b8 = e, o, is well defined and infinitely differentiable in x and \u03c1.\n(b) The following functions constitute Fourier pairs.\ngep(x, \u03c1) = \u03c1 p+1\u039bep(x\u03c1) \u223c c(\u03c1) (sp + (\u2212s)p) es 2/(2\u03c12), (63) gop(x, \u03c1) = \u03c1 p+1\u039bop(x\u03c1) \u223c c(\u03c1) (sp \u2212 (\u2212s)p) es 2/(2\u03c12), (64)\n\u03c6ep(x, \u03c1) \u223c c(\u03c1) (sp + (\u2212s)p) es 2/(2\u03c12)F (s), (65) \u03c6op(x, \u03c1) \u223c c(\u03c1) (sp \u2212 (\u2212s)p) es 2/(2\u03c12)F (s), (66)\nwhere F (s) = F (f(x)), s = i\u03c9, and c(\u03c1) is a constant depending on \u03c1.\nProof. (a) trivially follows from the theorem on differentiation of improper integrals by a parameter [21,22]. (b) follows from Theorem 3.3.\nTheorem 5.4. If a function f(x) satisfies the conditions of Proposition 5.1 with m > p+ 1, then\n(i) Functions \u03c6ep(x, \u03c1), \u03b8 = e, o converge uniformly as \u03c1 \u2192 \u221e to a continuous function f \u03b8p (x) in C k(R) if k < m\u2212 p\u2212 1.\n(ii) If xf(x) \u2208 L1(R), then for any k, 0 < k < m \u2212 p \u2212 1 functions dk\n\u03c6ep(x,\u03c1) dxk, \u03b8 = e, o converge uniformly to d\nk\ndxk f \u03b8p (x) as \u03c1 \u2192 \u221e.\n(iii) For the functions f \u03b8p (x), \u03b8 = e, o we have the following Fourier correspondence:\nf ep)(x) \u223c c(\u03c1) (sp + (\u2212s)p)F (s), f op (x) \u223c c(\u03c1) (sp \u2212 (\u2212s)p)F (s),\nwhere F (s) = F (f(x)).\n(iv) Functions \u03c6ep(x, \u03c1), \u03b8 = e, o uniformly converge as \u03c1 \u2192 0 to an identically zero function.\n(v) Also, for every k, 0 < k < m\u2212 p\u2212 1, functions d k\u03c6\u03b8p(x,\u03c1)\ndxk , \u03b8 = e, o also\nconverge uniformly to zero.\n(vi) For 0 \u2264 k < m\u2212 p\u2212 1, \u03b8 = e, o we have\nlim \u03c1\u2192\u03c10\ndk\u03c6\u03b8p(x, \u03c1)\ndxk =\ndk\u03c6\u03b8p(x, \u03c10)\ndxk ,\nwhere \u03c10 \u2265 0, and the limit is uniform with respect to x. Proof. From Lemma 5.3 it follows that for s = i\u03c9\n\u03c6ep(x, \u03c1) = c\n2\u03c0i\n\u222b i\u221e\n\u2212i\u221e F (s) (sp + (\u2212s)p) es2/(2\u03c12)esxds. (67)\nSince m > p + 1, inequality (61) implies absolute convergence of the integral\nf ep(x) := c\n2\u03c0i\n\u222b i\u221e\n\u2212i\u221e F (s) (sp + (\u2212s)p) esxds (68)\nfor all x \u2208 (\u2212\u221e,\u221e). Let us prove that uniformly on (\u2212\u221e,\u221e), f ep (x) = lim\u03c1\u2192\u221e \u03c6ep(x, \u03c1). (69)\nLet \u01eb > 0. Since m > p+ 1, inequality (61) implies that \u2203T > 0 such that \u2223\n\u2223 \u2223 \u2223\nc\n2\u03c0i\n( \u222b i\u221e\niT +\n\u222b iT\ni\u221e\n) F (s) (sp + (\u2212s)p) esxds \u2223 \u2223 \u2223\n\u2223\n< \u01eb\n2 . (70)\nLet us define \u00b5 by\n\u00b5 = sup {\u2223 \u2223\n\u2223\nc\n2\u03c0i F (s)esx (sp + (\u2212s)p)\n\u2223 \u2223 \u2223 : s \u2208 [\u2212iT, T ] }\n(71)\nThen, since s = i\u03c9 there exists \u03c10 such that (for \u01eb small enough)\n\u2200 \u03c1 \u2265 \u03c10 \u2223 \u2223 \u2223 1\u2212 es2/(2\u03c12) \u2223 \u2223 \u2223 < \u01eb\u03c0\n2\u00b5Tc < 1. (72)\nFormulas (67), (68), (70)-(72) imply that for any x and for any \u03c1 \u2265 \u03c10\n|f ep(x)\u2212 \u03c6ep(x, \u03c1)| \u2264 \u2223 \u2223 \u2223\n\u2223\nc\n2\u03c0i\n\u222b i\u221e\n\u2212i\u221e F (s) (sp + (\u2212s)p) esx\n( 1\u2212 es2/(2\u03c12) ) ds\n\u2223 \u2223 \u2223 \u2223\n\u2264 \u2223 \u2223 \u2223\n\u2223\nc\n2\u03c0i\n( \u222b i\u221e\niT +\n\u222b iT\ni\u221e\n) F (s)esx (sp + (\u2212s)p) ds \u2223 \u2223 \u2223\n\u2223\n+\n\u2223 \u2223 \u2223 \u2223 \u222b iT\n\u2212iT\n\u01eb\u03c0\n2\u00b5Tc \u00b5ds\n\u2223 \u2223 \u2223 \u2223\n< \u01eb\n2 +\n\u01eb 2 = \u01eb,\nwhich proves (69). Therefore, f ep(x) is continuous. The fact that f e p(x) is k times continuously differentiable follows from (61), the fact that m > p + 1 + k, and from the theorem on differentiability of improper integrals by a parameter (see [22]). This proves (i) for \u03b8 = e. The proof for (ii) is entirely similar to the proof of (i) except that we need to multiply the functions under the integral by sk , and we still use (61) to justify absolute convergence.\nLet us prove (iii). Since xf(x) is in L1(R), F (s) is continuously differentiable in s. Therefore, F (s) (sp + (\u2212s)p) is also continuously differentiable in s. Absolute integrability of F (s) (sp + (\u2212s)p) again follows from (61). From (68) it follows that f ep(x) = F\u22121 (cF (s) (sp + (\u2212s)p)) . Therefore, from the theorem on the inverse Fourier transform, it follows that F (\nf ep(x) ) = cF (s) (sp + (\u2212s)p). This proves (iii) for \u03b8 = e. The proof for \u03b8 = o is entirely similar. (iv) Let \u00bf 0. From (67) and the fact that es\n2/(2\u03c12) < 1, it follows that \u2203T > 0 such that \u2200 \u03c1 > 0, we have\n\u2223 \u2223 \u2223 \u2223 c\n2\u03c0i\n( \u222b i\u221e\niT +\n\u222b \u2212iT\n\u2212i\u221e\n)\nF (s)es 2/(2\u03c12)esx (sp + (\u2212s)p) ds\n\u2223 \u2223 \u2223 \u2223 < \u01eb\n2 . (73)\nLet \u00b5 be defined as in (71). Then, \u2203\u03c10 > 0 such that for any \u03c1 < \u03c10, \u2223\n\u2223 \u2223 es\n2/(2\u03c12) \u2223 \u2223\n\u2223 <\n\u01eb\n4\u00b5T . (74)\nNow (67), (73) and (74) imply that for \u03c1 < \u03c10:\n\u2223 \u2223\u03c6ep(x, \u03c1) \u2223\n\u2223 \u2264 \u2223 \u2223 \u2223\n\u2223\nc\n2\u03c0i\n( \u222b i\u221e\niT +\n\u222b iT\ni\u221e\n)\nK(s)ds\n\u2223 \u2223 \u2223 \u2223 + \u2223 \u2223 \u2223 \u2223 c\n2\u03c0i\n\u222b iT\n\u2212iT K(s)ds\n\u2223 \u2223 \u2223 \u2223 <\n\u01eb 2 + \u01eb 4\u00b5T\n\u2223 \u2223 \u2223 \u2223 c\n2\u03c0i\n\u222b iT\n\u2212iT F (s) (sp + (\u2212s)p) esxds\n\u2223 \u2223 \u2223 \u2223\n\u2264 \u01eb 2 + \u01eb 4\u00b5T 2\u00b5T = \u01eb,\nwhere K(s) = F (s)es 2/(2\u03c12)esx (sp + (\u2212s)p). This proves (i) for \u03b8 = e. If \u03b8 = o the proof is similar. The proof of (v) is entirely similar. The proof of (vi) is a simplified version of (ii), and is therefore omitted.\nThe following theorem is important in showing that functions \u03c6\u03b8p(x, \u03c1) are essentially localized in a domain with bounded x and \u03c1.\nTheorem 5.5. If a function f(x) satisfies the conditions of Proposition 5.1 with m > p + 1, then for any \u01eb > 0 there exist T > 0 and Q > 0 such that if |x| > T or if \u03c1 < Q, then\n\u2223 \u2223 \u2223 \u03c6\u03b8p(x, \u03c1) \u2223 \u2223 \u2223 < \u01eb, (75)\ndk\u03c6\u03b8p(x, \u03c1)\ndxk < \u01eb.\nProof. Since m > p + 1 > 0 the function f (k)(x) is in L1(R) for 0 \u2264 k < m\u2212 p\u2212 2. As a result of the properties of convolutions f (k)(x) \u2217 \u03c1p+1\u039b\u03b8p(x) is in L1(R) for these values of k. This implies that for every \u03c1\nlim |x|\u2192\u221e\ndk\u03c6\u03b8p(x, \u03c1)\ndxk = 0, for 0 \u2264 k < m\u2212 p\u2212 2. (76)\nLet \u01eb > 0. From (75) and (76) and Theorem 5.4 (i) it follows that there exist positive numbers R and Q such that\n\u2223 \u2223 \u2223 f \u03b8p (x)\u2212 \u03c6\u03b8p(x, \u03c1) \u2223 \u2223 \u2223 < \u01eb\n2 , \u2200 \u03c1 > R, \u2200 x, (77)\nand \u2223\n\u2223 \u2223 \u03c6\u03b8p(x, \u03c1)\n\u2223 \u2223 \u2223 < \u01eb, \u2200 \u03c1\u2032 < Q, \u2200 x. (78)\nSince f \u03b8p (x) is in L1(R), lim|x|\u2192\u221e f \u03b8 p (x) = 0. This implies that \u2203T1 such\nthat \u2223\n\u2223 \u2223 f \u03b8p (x)\n\u2223 \u2223 \u2223 < \u01eb\n2 , \u2200 |x| > T1. (79)\nInequalities (77) and (79) imply that \u2223\n\u2223 \u2223 \u03c6\u03b8p(x, \u03c1)\n\u2223 \u2223 \u2223 <, \u01eb \u2200 \u03c1 > R, \u2200 |x| > T1. (80)\nUsing (80) and Theorem 5.4 (vi) we can show that for every \u03c1 \u2208 [Q,R] there exists an open neighborhood Oy such that for some positive number T (\u03c1)\n\u2223 \u2223 \u2223 \u03c6\u03b8p(x, \u03c1) \u2223 \u2223 \u2223 < \u01eb, \u2200 \u03c1\u2032 \u2208 Oy, and |x| > T (\u03c1). (81)\nSince [Q,R] is compact, there exists a finite number of open sets O\u03c11 , ..., O\u03c1n , covering [Q,R]. Let T = max(T1, T (\u03c1i), i = 1, ..., n), then (78), (80) and (81) imply that\n\u03c6\u03b8p(x, \u03c1) < \u01eb if either |x| > T or \u03c1 < Q. The second condition in (75) is proved similarly.\nRemark: The results of this section can be generalized to functions f(x) such that they and their derivatives have a finite number of jump discontinuities.\nTheorem 5.6. Let f(x) be as in Proposition 5.1 with m > p + 1. Then if \u2206 > 0 is such that p \u2212\u2206 > 0, p +\u2206+ 1 < m, then all convergence results in Theorem 5.4 are uniform with respect to q \u2208 [p \u2212 \u2206, p + \u2206]. In other words, \u2200 \u01eb > 0, \u2203\u03c10 such that if \u03c1 > \u03c10 , then \u2223 \u2223\u03c6\u03b8q(x, \u03c1)\u2212 f \u03b8q (x) \u2223\n\u2223 < \u01eb, \u2200 x and \u2200 q \u2208 [p\u2212\u2206, p+\u2206] (and similarly for convergences \u03c6\u03b8q(x, \u03c1) \u2192 \u03c6\u03b8q(x, \u03c11) as \u03c1 \u2192 \u03c11 and \u03c6\u03b8q(x, \u03c1) \u2192 0 uniformly as \u03c1 \u2192 0 for q \u2208 [p \u2212 \u2206, p + \u2206]. Furthermore, for any \u01eb > 0, \u2203T > 0 and Q > O such that if |x| > T or if \u03c1 < Q, then \u2200 q \u2208 [p\u2212\u2206, p+\u2206] where p\u2212\u2206 > 0, p +\u2206+ 1 < m we have\n|\u03c6q(x, \u03c1)| < \u01eb (82) \u2223 \u2223 \u2223 \u2223 \u2223 dk\u03c6\u03b8q(x, \u03c1) dxk \u2223 \u2223 \u2223 \u2223 \u2223 < \u01eb for 0 < k < m\u2212 p\u2212 2. (83)\nProof. The proof is entirely similar to the proof of Theorems 5.4 and 5.5, except that all inequalities can be satisfied uniformly on [p\u2212\u2206, p+\u2206].\nTheorem 5.7. Let f(x) be as in Proposition 5.1 with m > p+ 1 + 2l with l > 0. Then there is a continuous function \u03a8\u03b8p(x, \u03c3), \u03b8 = e, o, defined for all positive \u03c3 such that:\n(i) \u03a8\u03b8p(x, \u03c3) = \u03c6 \u03b8 p(x, \u03c1) for \u03c1 > 0, \u03c1 = 1 \u03c3 , and \u03a8 \u03b8 p(x, 0) = f \u03b8 p (x).\n(ii) Function \u03a8\u03b8p(x, \u03c3) has continuous mixed derivatives \u2202k+n \u2202xk\u2202\u03c3n \u03a8\u03b8p(x, \u03c3) for\nany k and n such that 2n+ k \u2264 2l.\n(iii) \u03a8ep(x, \u03c3) is even, and\u03a8 o p(x, \u03c3) is odd.\n(iv) \u03a8\u03b8p(x, \u03c3) \u223c F (s) (sp + (\u2212s)p) es 2\u03c32/2 if \u03b8 = e, and\n\u03a8\u03b8p(x, \u03c3) \u223c F (s) (sp \u2212 (\u2212s)p) es 2\u03c32/2 if \u03b8 = e,if \u03b8 = o\n(v) \u03c3 \u22022\u03a8\u03b8p(x,\u03c3)\n\u2202x2 =\n\u2202\u03a8\u03b8p(x,\u03c3)\n\u2202\u03c3 for every x and \u03c3.\nProof. Let \u03b8 = e. Then we define \u03a8\u03b8p(x, \u03c3) by\n\u03a8\u03b8p(x, \u03c3) = c\n2\u03c0i\n\u222b i\u221e\n\u2212i\u221e F (s) (sp + (\u2212s)p) es2\u03c32/2esxds, (84)\nwhere F (s) = F(f(x)), s = i\u03c9. As in the proof of Theorem 5.4, one can show that F (s) (sp + (\u2212s)p) es2\u03c32/2 is indeed the Fourier transform of \u03a8\u03b8p(x, \u03c3) for \u03b8 = e. This proves (iv). (iii) is obvious. (i) follows from Theorem 5.4.\nLet us prove (ii). From the theorem on differentiation of improper integrals by a parameter (see [22], 11.55 a), we can interchange differentiation of the right hand side of (85) with integration if the derivative of the expression under the integral absolutely converges. However,\n\u2202k+n\n\u2202xk\u2202\u03c3n F (s) (sp + (\u2212s)p) es2\u03c32/2esx = skp(s, \u03c3)es2\u03c32/2esx (F (s) (sp + (\u2212s)p)) (85) where p(s, \u03c3) is a polynomial whose degree on s is less than or equal to 2n.\nNow (85) together with the inequality m > p + 1 + 2l imply that if 2n + k \u2264 2l, the integral in (84) absolutely converges. This allows us to interchange integration and differentiation. Since the derivatives of all orders of the expression under the integral in (84) exist, (ii) follows. The proof for \u03b8 = o is entirely similar. In order to prove (v), we simply differentiate (84).\nTheorem 5.8. Let f(x) be as in Proposition 5.1 with m > p + 1 and let I = [a, p] (a > 0 if \u03b8 = o and a \u2265 0 if \u03b8 = e) be an interval on the real line. Then the set D\u01eb defined by condition\nD\u01eb = { x, \u03c3, p1 : \u2223 \u2223 \u2223 \u03a8\u03b8p1(x, \u03c3) \u2223 \u2223 \u2223 \u2265 \u01eb, p1 \u2208 [0, p] }\n(86)\nis compact if \u01eb > 0.\nProof. From Theorems 5.7 it follows that \u2200 p1 \u2208 I , \u2203\u2206 > 0 such that the set\nD\u01eb(p1) = { x, \u03c3, p2 : p2 \u2208 [p1 \u2212\u2206, p1 +\u2206], \u2223 \u2223 \u2223 \u03a8\u03b8p1(x, \u03c3) \u2223 \u2223 \u2223 \u2265 \u01eb }\n(87)\nis bounded if \u01eb > 0. Since M is compact, there is a finite covering of M with intervals [qj \u2212\u2206j, qj + \u2206j] such that each D\u01eb satisfying (86) for p1 \u2208 {qj} and \u2206 = \u2206j is bounded; thus, D\u01eb is also bounded as a union of a finite number of bounded sets. Since D\u01eb is closed in R\n3 = {x, \u03c3, p}, it follows that D\u01eb is compact.\nTheorem 5.9. If in Theorem 5.8 m > p+ 1 + k, then the set\nD\u01eb =\n{\nx, \u03c3, p1 :\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2202k\u03a8\u03b8p1 \u2202xk (x, \u03c3) \u2223 \u2223 \u2223 \u2223 \u2223 \u2265 \u01eb, p1 \u2208 [0, p] }\n(88)\nis compact if \u01eb > 0.\nProof. Let us take d kf\ndxk instead of function f(x) in Theorem 5.8. Then the\nfunction defined by the right side of (84) where F (s) = F ( dkf dxk ) is actually \u2202k\u03a8\u03b8p \u2202xk (x, \u03c3). Thus, Theorem 5.9 follows from Theorem 5.8.\nTheorem 5.10. (i) Consider functions \u039b\u03b8p(x), \u03b8 = e, o, as functions of p given by equalities (7) and (8) where p is now an arbitrary complex number. Then \u039b\u03b8p(x) is an analytic, even entire function of two variables x and p. (ii) Let function \u03a8\u03b8(p, x, \u03c3) := \u03a8\u03b8p(x, \u03c3) be defined by (84) where F (s) is the Fourier transform of f(x). For f(x) as in Proposition 5.1 with m > p + 1, \u03a8\u03b8(p, x, \u03c3) is a continuous function of three variables. It has continuous mixed order derivatives \u2202 k+n+l\u03a8\u03b8(p,x,\u03c3) \u2202xk\u2202\u03c3n\u2202pl\nwhere l is arbitrary, and k and n satisfy conditions of Theorem 5.7.\nProof. Let us assume \u03b8 = e. The ratio test shows that the series (7) converges absolutely and uniformly by p and x on every bounded set of pairs (x, p), |x| < R1, |p| < R2 . Since each term in (7) is an entire function, the sum is also entire. This proves (i). The proof of (ii) is similar to that of (ii) of Theorem 5.7 and is therefore omitted.\nRemark: Since \u03c6\u03b8p(x, \u03c1) = \u03c1p + 1\u039b \u03b8 p(x\u03c1) \u2217 f(x), it is easy to show that if the nth derivatives of f(x) are in L1(R) for n \u2264 m, then \u2202 n\u03c6\u03b8p dxn (x, \u03c1) = \u03c1p+1\u039b\u03b8p(x\u03c1)\u2217 \u2202 nf(x) dxn and therefore \u2202n\u03a8\u03b8p dxn (x, \u03c3) = 1 \u03c1p+1 \u039b\u03b8p( x \u03c3 )\u2217 \u2202nf(x) dxn for \u03c3 > 0. This shows that if a certain statement is true about contours \u03a8\u03b8p(x, \u03c3) = c, then it is true for contours \u2202n\u03a8\u03b8p(x,\u03c3)\ndxn = c if the assumptions for \u2202nf(x) dxn in the\nlatter case are the same as the assumptions for f(x) in the former."
        },
        {
            "heading": "6 Experimental Results",
            "text": "The purpose of our experiments was to demonstrate the following important properties of kernels gp(x, y) (we use \u03c0 = e). 1) We show that the trees resulting from convolutions with kernels with fractional (not integral) p can distinguish between signals that are indistinguishable by trees resulting from convolutions with integer indexed kernels (at least for low integers). Our experiments show that two signals which are very close to each other and whose higher order derivatives are also close can be distinguished by a convolution with gp with a low p. Since higher p results in significantly higher noise, this feature is highly desirable computationally and shows the advantages of using kernels with fractional p over Gaussian\nand its derivatives. Another advantage is that of constructing a surface for zero or level crossings and classifying it topologically with resulting integer invariants (the number of handles), which is discussed below.\nFigures 1A and 1B show two signals y1 and y2 . Their respective convolutions for p = 0, 1, 2 are shown in Figs.2A, 2B, 3A, 3B, 4A, and 4B respectively. Obviously, both Witkin and topological trees are indistinguishable. However, for fractional p = 1.35, we get different trees (see Figs.5A and 5B). In order to save space, we do not always draw the trees, assuming the reader can reconstruct it directly from the crossing curves. 2) We demonstrate that topological trees may be less sensitive to noise than Witkin trees.\nIn Fig.6A and 6B we show the original signal and the same signal with noise added. In Fig.7A and 7B we show the corresponding crossing curves. One can see that the crossing of 7B experiences Witkin bifurcation resulting in a different tree from 7A; however, topological trees are the same. 3) The following set of experiments demonstrates that (a) the trees resulting from fractional convolutions are relatively insensitive to noise (even though topological trees are more insensitive than the Witkin ones); (b) local modification of signals results in different trees allowing us to distinguish between the original and modified signal; (c) bifurcations occur frequently enough to provide additional fractional trees for low p, but not so frequently as to make computations difficult. Fig.8A shows a noiseless contour of England (256 samples). (d) The contours best and the least sensitive to noise tend to be for p < 2. The trees corresponding to the x coordinate were found for various p between 0.5 and 2.15. Here we only show contours at and around bifurcation points. Fig.9A and 9B corresponds to p = 0.6 and p = 0.7 respectively, Fig.10A and 10B to p = 0.8 (bifurcation point) and p = 0.8 respectively, Fig.11A and 11B to p = 1.02 (bifurcation point) and p = 1.04 respectively. The contours of the noisy map of England are shown in Figs. 12A, 12B, 13A and 13B for p = 0.6, p = 0.7, p = 0.78, and 0.79 (bifurcation point) and Figs.14A, 14B, 15A and 15B corresponding to p = 0.8, p = 0.9 (bifurcation point) p = 0.95, p = 0.97 respectively.\nAs the results of simulations have shown, the trees in the region p \u2208 [0.5, 1.5] are the same as for the noiseless map, but the bifurcations appear a little earlier. From these results, it is also clear that topological trees are easier to construct from the given contour. We have repeated this experiment by locally modifying the map (chopping off the southwestern part of England\u2019s map). See Fig.16 for the noiseless and Fig.17 for the noisy maps.\nFor noiseless signals, we have contours in Figs.18A, 18B, 19A and 19B for p = 0.6, p = 0.7 (bifurcation point), p = 0.8, p = 0.9 and in Figs.20A, 20B, 21A and 21B for p = 1, p = 1.1, p = 1.4, and p = 1.5 (bifurcation point) and in Figs.22A, 22B are contours for p = 1.6 and p = 1.7 respectively. We can see that the resulting trees are different from the previous unchopped contour of England. We only show the noisy maps for chopped off England for p = 0.72, and p = 0.74 in Figs.23A, 23B respectively. The bifurcation points are slightly delayed at the presence of noise and occur at p = 0.72 and p = 1.7 (not shown). Experiments just described were conducted for other signals as well. We chose level crossings at values of c(\u03c0(x, \u03c1) = c) close to 0 to avoid contours which do not close up."
        },
        {
            "heading": "7 Conclusion",
            "text": "Below we discuss important conceptual contributions of this paper as well as a practical significance of our results. With the assumption of monotonicity and scaling property we have constructed a maximal set of kernels. This allows us to construct maximal sets of tree invariants (i.e., trees which are invariant with respect to shape preserving signal transformations) for classification, recognition and feature extraction of signals. (a) In Theorem 4.1 we characterized the maximal set of kernels which satisfy our assumptions (axioms) for a linear scale-space, including the assumptions of scaling invariance, strong monotonicity, and stability. (b) Fourier transforms of our kernels were derived in Theorem 3.3 for quick and efficient computations of convolutions. (c) We have introduced a new topological method of tree construction which we believe is much less sensitive to noise than WitkinO\u0303s method. (d) For the purposes of applications, we demonstrated the usefulness of introducing kernels for fractional p in practical problems by showing that the Gaussian and its derivatives fail to distinguish between two similar signals whereas the kernels for fractional p succeed in this task. Furthermore, we have observed that our scale-space method is relatively immune to noise for low p as well as capable to detect a local modification of signals. In addition our methods allow us to\n(*) distinguish between the signals indistinguishable by a Gaussian kernel;\n(*) use the topological trees (along with WitkinO\u0303s trees) which are less noise sensitive; and\n(*) use level curves which assure that the contours will close up so that the tree can be constructed.\ne) We also gave a rigorous treatment of the structure of level crossings of functions \u2202 k\u03a8(x,\u03c3,p)\n\u2202xk which, in particular, generalizes many assumptions\nabout Gaussian convolutions (most of them have never been proved before). Thus, we have given a solid foundation to many papers [5, 9, 18, 28, 29] for the particular case of the Gaussian convolutions (\u039bep\u2217f) as a family of kernel function.\nWe, therefore, believe that our method will significantly enhance the applications of the linear scale-space method."
        }
    ],
    "title": "A Multiple Parameter Linear Scale-Space for one dimensional Signal Classification",
    "year": 2023
}