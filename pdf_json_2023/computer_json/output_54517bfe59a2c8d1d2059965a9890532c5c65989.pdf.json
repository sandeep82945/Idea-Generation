{
    "abstractText": "Object recognition is a crucial step in perception systems for autonomous and intelligent vehicles, as evidenced by the numerous research works in the topic. In this paper, object recognition is explored by using multisensory and multimodality approaches, with the intention of reducing the false positive rate (FPR). The reduction of the FPR becomes increasingly important in perception systems since the misclassification of an object can, depending on the circumstances, potentially cause accidents. In particular, this work presents a strategy through Bayesian inference to reduce the FPR considering the likelihood function as a cumulative distribution function from Gaussian kernel density estimations, and the prior probabilities as cumulative functions of normalized histograms. The validation of the proposed methodology is performed on the KITTI dataset using deep networks (DenseNet, NasNet, and EfficientNet), and recent 3D point cloud networks (PointNet, and PointNet++), by considering three object-categories (cars, cyclists, pedestrians) and the RGB and LiDAR sensor modalities.",
    "authors": [
        {
            "affiliations": [],
            "name": "Gledson Melotti"
        },
        {
            "affiliations": [],
            "name": "Johann J. S. Bastos"
        },
        {
            "affiliations": [],
            "name": "Bruno L. S. da Silva"
        },
        {
            "affiliations": [],
            "name": "Tiago Zanotelli"
        },
        {
            "affiliations": [],
            "name": "Cristiano Premebida"
        }
    ],
    "id": "SP:98218806de55e5365382aa6e43e2156dc15d537d",
    "references": [
        {
            "authors": [
                "R. Shi",
                "S. Yang",
                "Y. Chen",
                "R. Wang",
                "M. Zhang",
                "J. Lu",
                "Y. Cao"
            ],
            "title": "Cnn-transformer for visual-tactile fusion applied in road recognition of autonomous vehicles",
            "venue": "Pattern Recognition Letters, vol. 166, pp. 200\u2013 208, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "Y. Bao",
                "X. Wang",
                "R. Yu"
            ],
            "title": "Evaluation of false alarm alarms in truck fcw based on calibration of rss model under different driving scenarios",
            "venue": "International Journal of Transportation Science and Technology, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "H. He",
                "Z. Li",
                "G. Tian",
                "H. Chen",
                "L. Xie",
                "S. Lu",
                "H. Su"
            ],
            "title": "Towards accurate dense pedestrian detection via occlusion-prediction aware label assignment and hierarchical-nms",
            "venue": "Pattern Recognition Letters, vol. 174, pp. 78\u201384, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "G. Singh",
                "S. Akrigg",
                "M.D. Maio",
                "V. Fontana",
                "R.J. Alitappeh",
                "S. Khan",
                "S. Saha",
                "K. Jeddisaravi",
                "F. Yousefi",
                "J. Culley",
                "T. Nicholson",
                "J. Omokeowa",
                "S. Grazioso",
                "A. Bradley",
                "G.D. Gironimo",
                "F. Cuzzolin"
            ],
            "title": "Road: The road event awareness dataset for autonomous driving",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 1, pp. 1036\u20131054, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "Q. He",
                "Z. Wang",
                "H. Zeng",
                "Y. Zeng",
                "Y. Liu",
                "S. Liu",
                "B. Zeng"
            ],
            "title": "Stereo rgb and deeper lidar-based network for 3d object detection in autonomous driving",
            "venue": "IEEE Transactions on Intelligent Transportation Systems, vol. 24, no. 1, pp. 152\u2013162, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "J. Janai",
                "F. G\u00fcney",
                "A. Behl",
                "A. Geiger"
            ],
            "title": "Computer vision for autonomous vehicles: Problems, datasets and state of the art",
            "venue": "Foundations and Trends in Computer Graphics and Vision, vol. 12, no. 1\u20133, pp. 1\u2013 308, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C. Guo",
                "G. Pleiss",
                "Y. Sun",
                "K.Q. Weinberger"
            ],
            "title": "On calibration of modern neural networks",
            "venue": "34th International Conference on Machine Learning, vol. 70, 2017, pp. 1321\u20131330.",
            "year": 2017
        },
        {
            "authors": [
                "D. Su",
                "H. Zhang",
                "H. Chen",
                "J. Yi",
                "P.-Y. Chen",
                "Y. Gao"
            ],
            "title": "Is robustness the cost of accuracy? \u2013 a comprehensive study on the robustness of 18 deep image classification models",
            "venue": "European Conference on Computer Vision. Springer International Publishing, 2018, pp. 644\u2013661.",
            "year": 2018
        },
        {
            "authors": [
                "B. Ga\u0161parovi\u0107",
                "G. Mau\u0161a",
                "J. Rukavina",
                "J. Lerga"
            ],
            "title": "Evaluating yolov5, yolov6, yolov7, and yolov8 in underwater environment: Is there real improvement?",
            "venue": "in 8th International Conference on Smart and Sustainable Technologies (SpliTech),",
            "year": 2023
        },
        {
            "authors": [
                "C. Hogan",
                "G. Sistu"
            ],
            "title": "Automatic vehicle ego body extraction for reducing false detections in automated driving applications",
            "venue": "Artificial Intelligence and Cognitive Science. Springer Nature Switzerland, 2023, pp. 264\u2013275.",
            "year": 2023
        },
        {
            "authors": [
                "B. Mahaur",
                "K. Mishra"
            ],
            "title": "Small-object detection based on yolov5 in autonomous driving systems",
            "venue": "Pattern Recognition Letters, vol. 168, pp. 115\u2013122, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "G. Pereyra",
                "G. Tucker",
                "J. Chorowski",
                "L. Kaiser",
                "G.E. Hinton"
            ],
            "title": "Regularizing neural networks by penalizing confident output distributions",
            "venue": "ser. CoRR, arXiv: 1701.06548, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "G. Melotti",
                "W. Lu",
                "P. Conde",
                "D. Zhao",
                "A. Asvadi",
                "N. Gon\u00e7alves",
                "C. Premebida"
            ],
            "title": "Probabilistic approach for road-users detection",
            "venue": "IEEE Transactions on Intelligent Transportation Systems, vol. 24, no. 9, pp. 9253\u20139267, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "G. Melotti",
                "C. Premebida",
                "J.J. Bird",
                "D.R. Faria",
                "N. Gon\u00e7alves"
            ],
            "title": "Reducing overconfidence predictions in autonomous driving perception",
            "venue": "IEEE Access, vol. 10, pp. 54 805\u201354 821, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S.O. Tovias-Alanis",
                "H. Sossa",
                "W. G\u00f3mez-Flores"
            ],
            "title": "Learning smooth dendrite morphological neurons for pattern classification using linkage trees and evolutionary-based hyperparameter tuning",
            "venue": "Pattern Recognition Letters, vol. 172, pp. 274\u2013281, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "C.M. Bishop"
            ],
            "title": "Pattern Recognition and Machine Learning (Information Science and Statistics)",
            "venue": "New York: Springer-Verlag,",
            "year": 2006
        },
        {
            "authors": [
                "B. Liu",
                "H. Song",
                "Q. Li",
                "Y. Lin",
                "J. Yang"
            ],
            "title": "3D ARCNN: An asymmetric residual cnn for decreasing false positive rate of lung nodules detection",
            "venue": "IEEE International Conference on Bioinformatics and Biomedicine, 2022, pp. 1644\u20131647.",
            "year": 2022
        },
        {
            "authors": [
                "A. Vasiliuk",
                "M. Belyaev"
            ],
            "title": "Reducing false-positive detections using the distance between activation distributions in individual channels",
            "venue": "IEEE Ural-Siberian Conference on Biomedical Engineering, Radioelectronics and Information Technology, 2022, pp. 016\u2013019.",
            "year": 2022
        },
        {
            "authors": [
                "J. Mai",
                "M. Wang",
                "J. Zheng",
                "Y. Shao",
                "Z. Diao",
                "X. Fu",
                "Y. Chen",
                "J. Xiao",
                "J. You",
                "A. Yin",
                "Y. Yang",
                "X. Qiu",
                "J. Tao",
                "B. Wang",
                "H. Ji"
            ],
            "title": "Mhsnet: Multi-head and spatial attention network with false-positive reduction for lung nodule detection",
            "venue": "IEEE International Conference on Bioinformatics and Biomedicine, 2022, pp. 1108\u20131114.",
            "year": 2022
        },
        {
            "authors": [
                "D.-Y. Tu",
                "P.-C. Lin",
                "H.-H. Chou",
                "M.-R. Shen",
                "S.-Y. Hsieh"
            ],
            "title": "Slicefusion: Reducing false positives in liver tumor detection for mask r-cnn",
            "venue": "IEEE Transactions on Computational Biology and Bioinformatics, pp. 1\u201311, 2023.",
            "year": 2023
        },
        {
            "authors": [
                "P. Pitre",
                "A. Gandhi",
                "V. Konde",
                "R. Adhao",
                "V. Pachghare"
            ],
            "title": "An intrusion detection system for zero-day attacks to reduce false positive rates",
            "venue": "IEEE International Conference for Advancement in Technology, 2022, pp. 1\u20136.",
            "year": 2022
        },
        {
            "authors": [
                "H. Salmani"
            ],
            "title": "Gradual-n-justification (GNJ) to reduce false-positive hardware trojan detection in gate-level netlist",
            "venue": "IEEE Transactions on Very Large Scale Integration Systems, vol. 30, no. 4, pp. 515\u2013525, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "B. Yin",
                "B. Bu",
                "B. Gao",
                "Q. Li"
            ],
            "title": "A hybrid intrusion detection method using improved stacking ensemble algorithm and false positive elimination strategy for cbtc",
            "venue": "IEEE 25th International Conference on Intelligent Transportation Systems, 2022, pp. 4253\u20134258.",
            "year": 2022
        },
        {
            "authors": [
                "A. Kharkar",
                "R.Z. Moghaddam",
                "M. Jin",
                "X. Liu",
                "X. Shi",
                "C. Clement",
                "N. Sundaresan"
            ],
            "title": "Learning to reduce false positives in analytic bug detectors",
            "venue": "IEEE 44th International Conference on Software Engineering, 2022, pp. 1307\u20131316.",
            "year": 2022
        },
        {
            "authors": [
                "B.E. \u00c7aldiran",
                "T. Acarman"
            ],
            "title": "A late asymmetric fusion approach to eliminate false positives",
            "venue": "IEEE 25th International Conference on Intelligent Transportation Systems, 2022, pp. 2080\u20132085.",
            "year": 2022
        },
        {
            "authors": [
                "Z. Zhang",
                "Y. Shen",
                "H. Li",
                "X. Zhao",
                "M. Yang",
                "W. Tan",
                "S. Pu",
                "H. Mao"
            ],
            "title": "Maff-net: Filter false positive for 3d vehicle detection with multimodal adaptive feature fusion",
            "venue": "IEEE 25th International Conference on Intelligent Transportation Systems, 2022, pp. 369\u2013376.",
            "year": 2022
        },
        {
            "authors": [
                "D. Valcarce",
                "J. Parapar",
                "A. Barreiro"
            ],
            "title": "Additive smoothing for relevance-based language modelling of recommender systems",
            "venue": "4th Spanish Conference on Information Retrieval, 2016.",
            "year": 2016
        },
        {
            "authors": [
                "D.W. Scott"
            ],
            "title": "Multivariate Density Estimation: Theory, Practice, and Visualization, ser. Wiley Series in Probability and Statistics",
            "year": 2015
        },
        {
            "authors": [
                "W.L. Martinez",
                "A.R. Martinez"
            ],
            "title": "Computational Statistics Handbook with MATLAB, 3rd ed",
            "year": 2015
        },
        {
            "authors": [
                "G. Huang",
                "Z. Liu",
                "L. Van Der Maaten",
                "K.Q. Weinberger"
            ],
            "title": "Densely connected convolutional networks",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2261\u20132269.",
            "year": 2017
        },
        {
            "authors": [
                "B. Zoph",
                "V. Vasudevan",
                "J. Shlens",
                "Q.V. Le"
            ],
            "title": "Learning transferable architectures for scalable image recognition",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 8697\u20138710.",
            "year": 2018
        },
        {
            "authors": [
                "M. Tan",
                "Q.V. Le"
            ],
            "title": "Efficientnet: Rethinking model scaling for convolutional neural networks",
            "venue": "PMLR 36th International Conference on Machine Learning, vol. 97, 2019, pp. 6105\u20136114.",
            "year": 2019
        },
        {
            "authors": [
                "R.Q. Charles",
                "H. Su",
                "M. Kaichun",
                "L.J. Guibas"
            ],
            "title": "Pointnet: Deep learning on point sets for 3d classification and segmentation",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 77\u2013 85.",
            "year": 2017
        },
        {
            "authors": [
                "C.R. Qi",
                "L. Yi",
                "H. Su",
                "L.J. Guibas"
            ],
            "title": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space",
            "venue": "Advances in Neural Information Processing Systems, vol. 30, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A. Geiger",
                "P. Lenz",
                "R. Urtasun"
            ],
            "title": "Are we ready for autonomous driving? the KITTI vision benchmark suite",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2012, pp. 3354\u20133361.",
            "year": 2012
        },
        {
            "authors": [
                "A. Geiger",
                "P. Lenz",
                "C. Stiller",
                "R. Urtasun"
            ],
            "title": "Vision meets robotics: The KITTI dataset",
            "venue": "International Journal of Robotics Research (IJRR), vol. 32, no. 11, pp. 1231\u20131237, 2013.",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Bayesian Inference; Confidence Calibration; Object Recognition; Perception System; Probability Prediction.\nI. INTRODUCTION Research on sensory perception has achieved very satisfactory results in terms of object recognition, contributing significantly to the progress of autonomous and intelligent vehicles (AV/IV) and robotics, due to technological advances such as hardware, sensors and statistical learning techniques [1]\u2013 [3]. Perception systems for AV/IV can be understood as a process that interprets the data provided by the sensors in order to understand the surrounding environment, thus contributing to safer decision-making. An important item in perception systems is the object classification part, which is currently dominated by deep network (DN) architectures [4]\u2013[7].\nFrequently, the DNs output the predictions as normalized scores, between 0 and 1, by using the Softmax or the Sigmoid functions [8]\u2013[10]. However, DNs tend to be overconfident and do not always correctly classify the objects. The misclassified objects, false positives (FPs) or missing (FNs), hinder proper decision-makings by the perception systems. Thus, the reduction of the FPs in classification systems would provide safer actions for decision-making, especially in autonomous robots and intelligent vehicles applications [3], [11], [12].\nAn alternative to reduce the FPR can be through probabilistic explainable approach by observing the logit layer values\n1 Gledson Melotti, Johann J. S. Bastos, Bruno L. S. da Silva and Tiago Zanotelli are with Federal Institute of Espirito Santo, Brazil. E-mail: {gledson,bruno.legora,tiagoz}@ifes.edu.br and jjakobschmitz@gmail.com\n2 C.Premebida is with the Institute of Systems and Robotics (ISR-UC), and the Dep. of Electrical and Computer Engineering at University of CoimbraPortugal. E-mail: cpremebida@isr.uc.pt\n(score values before the prediction layer). Figure 1 shows the distribution of logit values from an already trained network, in the first row, while the second row shows the distribution of the same scores after the softmax. It is possible to see that the logit values are smoother than the softmax values i.e., the values from softmax function are extreme (many values close to zero and many values close to one) [8], [13]\u2013[15].\nSoftmax function (SM ) is generally used as prediction function to classify a given input (decision-making) [8], [16]. Such function can be taken in the probabilistic context by means of the Bayes\u2019 theorem, considering probabilistic generative models (Naive Bayes, Bayesian networks and Hidden Markov Models) where the class-conditional densities and the prior are modeled (or known), and then the posterior probabilities can be estimated through the Bayes\u2019 theorem. In other words, first we have to determine the class-conditional density (likelihood function) for each class individually and then the class prior probability. Equivalently, the joint distribution can be directly modeled and later normalized to obtain the posterior probability. In fact, the classification result is given through two stages, the first being inference (distribution modeling) and the second being decision-making (classification) [17].\nAlternatively, many traditional approaches to classification problems are of the type called discriminative models (logistic regression and support vector machine) or discriminant functions (traditional neural networks and k-nearest neighbors).\nar X\niv :2\n31 0.\n05 95\n1v 2\n[ cs\n.C V\n] 2\n2 O\nct 2\n02 3\nThe first tries to model a posterior probability directly using a parametric model in the inference stage, and consequently optimizing the parameters on the training set. Given the posterior model, for each new entry, it assigns a top-class label. The second case i.e., discriminant function, the approach defines a function which uses the training data to map each entry directly to a certain class (input-output mapping), and according to [17] the \u201cprobabilities play no role\u201d i.e., it is not possible to access posterior probabilities. In this case the inference and decision stages are into a single learning algorithm [17].\nThe result achieved by a machine learning algorithm, such as a classifier considering predictions after a SM , should be carefully analyzed, so that the prediction result may not be considered as a proper probabilistic value per se. To obtain adequate probabilistic results, the structure of the learning algorithms must encompasses probabilistic formulations.\nIn this context, this paper explores the well-known Bayes\u2019 theorem as a probabilistic interpretation of the predicted values from the logit values, through Maximum Likelihood (ML) and Maximum a-Posteriori (MAP) formulations. Additionally, we aim to reduce the false positive rate (FPR) without degrading the results already achieved by the neural networks. In fact, the ML and MAP formulations replace the predicted values of the neural network trained with the SM prediction function, without the need to retrain the network i.e., the likelihood functions and prior probabilities of each class were obtained with the logit values (before SM prediction layer). The likelihood function is then defined by as a cumulative distribution function (CDF) from the Gaussian kernel density estimation, and the prior probability as a cumulative function from of normalized histogram (NH), both with the logit values of trained networks.\nIn summary, the contributions are: \u2022 An investigation of the parametric and nonparametric\nmodeling to represent the likelihood function and the prior probabilities, considering CDFs; \u2022 Reducing the FPR through Maximum likelihood and Maximum a-Posteriori formulations for object classification; \u2022 A study with five distinct neural network architectures to validate the proposed approach, taking into account datasets from different modalities and sensors (RGB images, and 3D-LiDAR point clouds), contributing to advances in multisensory and multimodality perception."
        },
        {
            "heading": "II. RELATED WORK",
            "text": "There are many recent works that address False Positive Reduction techniques in different contexts, such as disease detection, security breach detection and vehicle detection. For the first context, the authors in [18] proposed a novel asymmetric residual network that uses 3D features and spatial information to improve classification and reduce false positives in lung nodule detection. Their network showed promising results in reducing false positive in clinical applications. In [19], the authors proposed a post-processing method to estimate the\nconfidence score of the predictions from a single channel CNN architecture. While using the confidence score of several layers of a CNN, their approach could reduce up to 18% of the false positive detection in one of their tests. The authors of [20] proposed a post-processing method to reduce false positives in lung cancer detection. Their method is lightweight and does not bring any constraints in the \u201cfront network\u201d, while reducing 6.4% of the false discovery rate in their tests. In [21], the authors proposed a novel slice-fusion method with a Mask R-CNN detection model to reduce false positives in liver tumor detection and segmentation.\nRegarding the security breach context, the authors of [22] proposed a framework for addressing zero-day attacks in software (attacks that occur before the developer can take action on it), combining features selection methods and fine-tuning of their datasets. In [23], the authors proposed a technique to reduce false positives in hardware Trojan (HT) detection. Their method combines signal justification and unsupervised K-means, and is a general technique that can be applied to suspicious signals in detecting HT. Their experiments were done on various combinations of full and partial-scans of circuits, and obtained a false positive ratio of 3.89% and 3.31% for full and partial scans of circuits. In [24], an improved stacking ensemble algorithm was proposed to enhance the true positive rate of a intrusion detection system (IDS). Their Hybrid IDS was tested and their results showed that the method was superior than the compared techniques, in terms of True and False positives. In the software development context, the authors of [25] proposed a Transformer-based learning approach to identify false positive bug warnings found by static analysis tools, which usually return a large number of false positives that developers must verify manually. Their approach improved the precision of a tool by 17.5% and 5.5%, when considering null dereferences and resource leaks warnings, respectively.\nLastly, in the vehicle detection context, the authors of [26] proposed an asymmetric late fusion approach to combine camera and LiDAR outputs from different networks. Their objective was to eliminate false positives in these object detectors. According to their results, their objective was attained and the method achieved up to 9.87% better class-wise performance than the LiDAR-only detector. In [27], two end-to-end trainable feature fusion techniques were proposed to combine RGB and point-cloud features. Their experiments showed that their methods can improve significantly the filtering of false positive from data. Their approaches can be applied to improve the false positive ratio in many different architectures. The paper in [11] addresses the influence of images from a fisheye camera i.e., such cameras can include undesirable parts of the vehicle\u2019s ego body in the perception system of autonomous vehicles, as well as the reflections of objects on car bodies, where both can produce false positives, and reduce the efficiency of object detection systems. Thus, the authors proposed a neural network architecture to identify and extract the vehicle\u2019s ego-body. Put another way, eliminating the possibility of pedestrians or other objects being wrongly\ndetected in the car\u2019s ego-body reflection. In this way, the authors showed a reduction in false positives by eliminating the vehicle\u2019s ego body with the reflected objects."
        },
        {
            "heading": "III. PROPOSED METHOD",
            "text": ""
        },
        {
            "heading": "A. Probabilistic Inference",
            "text": "This section presents the formulations to reduce FPR, through Maximum Likelihood (ML) and Maximum aPosteriori (MAP) functions, based on the Bayes\u2019 rule (1), including nonparametric and parametric modeling to define the posterior probability, likelihood function, and prior probability as well. Expressing the posterior by\nP (C|Sc) = P (Sc|C)P (C)\nP (Sc) , (1)\nwhere C is the random variable (RV) associated to the object categories, Sc1 are the classified object scores (predicted values), P (Sc|C) is the likelihood, P (C) is the prior probability, and P (Sc) \u0338= 0 is the model evidence, considering the pior and likelihood are known. From the Law of Total Probability [17], (1) can be rewritten using the per-class expression,\nP (ci|Sc) = P (Sc|ci)P (ci) nc\u2211 i=1 P (Sc|ci)P (ci) , (2)\nwhere P (Sc|ci) is the likelihood of an object for the class (ci). Given (2), an inference can be made on the test set about the \u201cunknown\u201d RV C from the dependence with Sc i.e., the value of the posterior distribution of C is determined from Sc [14], [15]."
        },
        {
            "heading": "B. ML and MAP Functions",
            "text": "We argue that the values from the logit layer are more suitable for representing a probability density function, when compared with the values of the SM function, as illustrated by the distributions in Fig. 1. Thus, from (2) we can define the Maximum Likelihood and the Maximum a-Posteriori function, as (3) and (4) respectively [14], [15]:\nML := argmax i (P (Sc|ci) + \u03bb) nc\u2211 i=1 (P (Sc|ci) + \u03bb) , (3)\nMAP := argmax i (P (Sc|ci)P (ci) + \u03bb) nc\u2211 i=1 (P (Sc|ci)P (ci) + \u03bb) , (4)\nwhere \u03bb represents the additive smoothing parameter, used here to avoid the zero probability problem [28]."
        },
        {
            "heading": "C. Kernel Density Estimation and Normalized Histogram",
            "text": "We propose to model the ML and MAP functions, which will perform the inference, by taking the CDF, where the density is extracted by using the logit layer values (i.e., before softmax values) from the training set data, as illustrated in Fig. 2.\n1Generally, neural network score values are obtained using a prediction function that normalizes logit values between zero and one, such as the softmax prediction function.\nThe curves on the left hand-side of Fig. 2 represent CDFs modelled by Gaussians (likelihood funtions) i.e., they are modeled using parametric estimates by means of a Kernel Density Estimation (KDE) given in (5) by\nf\u0302ker(d) = 1\nnh n\u2211 i=1 1\u221a 2\u03c0 e\u2212( 1 2h2 )(d\u2212Sci)2 , (5)\nwhere h is a smoothing parameter2 called window width or bandwidth (bw)3, n is the number of observations, d is a value set4 (domain) that evaluates the function f\u0302ker(d), Sci are the predicted values (scores) of each object classified to a certain class. Density estimation is obtained by computing the average of several probability density functions from (5), considering the set of values d, and consequently obtain a CDF [14], [29], [30].\nThe idea of applying Gaussian functions is to obtain a smoother distribution, as shown in Fig. 1 (see the 1st row). In other words, the distribution from the logit layer is more suitable for modeling a probability density function. Furthermore, the Gaussian distribution has a maximum entropy i.e., a distribution with more information and less confident information around the mean (distribution with high variance) [15], [17].\nPrior probabilities are represented by CDFs obtained from normalized histograms (NH), as illustrated on the right of Fig 2. According to [30] \u201cHistograms are a good way to i) summarize a data set to understand general characteristics of the distribution such as shape, spread, or location; ii) suggest possible probabilistic models, iii) or determine unusual behavior\u201d. In other words, here the NH is used to model proper distributions. The histogram is constructed from the number of bins (intervals) i.e., the number of bars, which must not overlap with each other and the bins should have the same width [14].\nIn an implementation perspective, the formulation to get P (Sc|ci) for the ML function can be computed as illustrated in Fig. 3, while the MAP function (posterior probability) follows as illustrated in Fig. 4. Therefore, the ML and MAP functions replace the softmax function only on the test data, using the logit layer values, while the CDFs were obtained with the\n2This smoothing parameter is not related to the smoothing parameter of Bayesian inference functions (ML and MAP).\n3Small values lead to rough curves, larger values lead to smoother curves. 4The d values are not related to the values of scores or logits.\nlogit data from the training dataset. Notice that, although the Bayesian formulation takes distributions into account, ML and MAP compute a point estimate rather than a distribution.\nThe use of different models to represent the distributions aims to capture different information from the training data. The choice of obtaining a CDF from a Gaussian distribution to represent the likelihood function and a CDF from NH to represent the prior probability were defined based on preliminary experiments. The reverse could be valid i.e., a Gaussian distribution for the likelihood and NH for the prior probability."
        },
        {
            "heading": "D. Setting the KDE and NH Parameters",
            "text": "KDE\u2019s formulation involves determining \u03bb parameters for ML and MAP functions, as well as h (smoothing parameter) for each class, according to (3), (4), and (5). Differently, the NHs are constructed using the number of bins (nbins) for each class. Thus, the determination of such parameters were obtained through a genetic algorithm5, considering in the cost function the F-score (F1) and FPR metrics, as defined in (6),\nFcost = min[(1\u2212 F1) + FPR]. (6)\nThe parameters \u03bb and h were determined by considering a subset of R as search space, while nbins were determined by\n5In this work, the Matlab genetic algorithm toolbox was used.\nhaving only integers in the search space. The optimization process of the genetic algorithm was carried out with the training data and validated on the validation data, for the determination of the KDE and NH parameters i.e., the parameters that provide the lowest value for FPR and the highest value for the F-score. The internal parameters of the genetic algorithm were crossover fraction equal to 0.8, maximum generation equal to 100 times the number of variables, population size equal to 200 and the mutation was determined by applying random number chosen from a Gaussian distribution, to each entry of the parent vector.\nNote that this paper aims to reduce the rate of false positives without degrading the classification results, in other words, without degrading the F-score metric: this is the reason of using the F-score in the cost function of the genetic algorithm."
        },
        {
            "heading": "E. Dataset",
            "text": "To validate the proposed methodology, this paper considers three neural networks that process RGB images (DenseNet [31], NasNet [32], and EfficienteNet [33]) and two neural network that directly processes 3D point clouds (PointNet [34], and PointNet++ [35]). The results were achieved using the KITTI Object Detection dataset, where the objects have been extracted (cropped) both from the RGB image frames and from the 3D point clouds frames, projecting the 3D points to the 2D image-plane [36], [37], as in Fig. 5 and Algorithm 1.\nThe point clouds projected on the image-plane are eliminated using the 2D bounding boxes of the 2D objects i.e., the projected points that are outside the 2D bounding boxes have their respective 3D points excluded from the 3D frame.\nIt cannot be overlooked that the LiDAR sensor\u2019s operating principle is the reflection of light beams i.e., objects are generated by light reflections. Like this, there are 3D points that do not belong to the cropped 3D objects therefore, such points are defined as backgrounds or foregrounds points. The Fig. 6 illustrates an pedestrian object with background points, from the 3D points projected according to the last row of Fig. 5.\nThe backgrounds or foregrounds points were removed via a clustering technique based on the distance between points, to define the points belonging to the objects, as shown in Alg. 2.\nThe 3D point clouds objects contain different amount of points because of the nature of the 3D LiDAR sensor. Thus, some objects had the amount of points reduced to 512 (random downsample) or increased to 512 points (considering the k nearest neighbors to sample the 3D points), as shown in Fig. 7. Table I shows the number of objects for images and point clouds modalities. The number of objects between 2D images and 3D point clouds are different, as the LiDAR sensor has distance limitations i.e., some objects are not captured by the sensor."
        },
        {
            "heading": "IV. EXPERIMENTS AND RESULTS",
            "text": "Assessing the false positive rate (FPR) in real world applications is relevant in autonomous driving scenarios, since objects\ncan be misclassified by neural networks with high score values. In this section we evaluated the proposed approaches by replacing the SM prediction function by the ML and\nAlgorithm 1: Cropped 3D point cloud. Input: LiDAR sensor data and 2D bounding boxes. Output: Cropped 3D point clouds. Getting the 3D point clouds pc\u2190 OpenLiDAR(data); indices\u2190 pc(:, 1) < 5; /* Points that do not belong to the 2D image-plan are removed (the value is an approximation) */ pc(indices, :)\u2190 [ ]; Project PC for image-plane pcproj \u2190 PrectRrectTCamLiDARPC; pcproj(:, 1)\u2190 pcproj(:, 1)/pcproj(:, 3); pcproj(:, 2)\u2190 pcproj(:, 2)/pcproj(:, 3); Defining the points inside the bounding box Boxes = [xmin ymin xmax ymax]; indices\u2190 [ ]; for i\u2190 1 : Size(pcproj) do\nif (pcproj(i, 1) >= Boxes(1) and pcproj(i, 1) <= Boxes(3) + 1) and (pcproj(i, 2) >= Boxes(2) and pcproj(i, 2) <= Boxes(4) + 1) then\nindices\u2190 [indices; i] end PC = pc(indices, :);\nMAP ones only on the test set, considering the likelihood as CDFs from Gaussian functions, and prior probabilities are represented as CDFs obtained from NHs as described in Sect.III.\nResults achieved on the classification test set are shown in Table II, in terms of FPR and F-score measures. It can be seen that the FPR decreased after replacing the SM function with ML and MAP. Regarding the RGB image classifications,\nRGB Images - 7481 Frames Car Cyclist Pedestrian\nTraining 18103 1025 2827 Validation 2010 114 314\nTesting 8620 488 1346 3D Point Clouds - 7481 Frames\nCar Cyclist Pedestrian Training 15324 923 2688\nValidation 1717 99 303 Testing 7332 452 1260\nparticularly with the EfficientNet network, the FPR decreased significantly, given that the reduction is 25.63% for ML and 15.34% for MAP. On the other hand, the values of the F-\nscores decreased very slightly in almost all networks (not compromising classification performance), with the exception of the NasNet network that increased the F-score using MAP - which is very positive. Another significant FPR reduction occurred with the PointNet network, achieving a value of 16.98% reduction when using ML. The parameters (nbins, \u03bb, and bw) determined by the genetic algorithm are presented in Tables III, IV, and V.\nFinally, it is worth mentioning that this paper is not aiming to identify which network is the best in terms of classification performance but, rather by proposing and evaluating a strategy to reduce the FPR i.e., the efficiency of the proposed methodology in networks that can potentially be employed as part of more reliable perception systems applied to robotics and autonomous vehicles. Furthermore, the research reported in this paper is not primary focused on developing a technique to eliminate background or foreground points nor a technique for sampling 3D point clouds to obtain a better classification result."
        },
        {
            "heading": "V. CONCLUDING REMARKS",
            "text": "The techniques and experimental results described in this paper are based on a proposed probabilistic approach that uses density distributions to model the networks logit values i.e., the top-class scores before the softmax prediction layer. The results reported in this work are very promising, given that ML and MAP reduced the FPR of the models without the need to retrain the neural networks, while the F-score metric achieved a very small reduction which means the overall classification performance was not compromised.\nA potential way to improve the results of the F-score metric by the ML and MAP functions is to adjust the internal parameters of the genetic algorithm (mutation rate, population size, crossover rate, etc.), as well as modifying its cost function.\nFinally, a potentially significant aspect that contributed to validate the proposed approach for real-world application domains is the use of distinct modalities and sensors, namely by considering RGB images (camera sensor) and 3D-LiDAR returns point-clouds and range-maps."
        }
    ],
    "title": "Reducing the False Positive Rate Using Bayesian Inference in Autonomous Driving Perception",
    "year": 2023
}