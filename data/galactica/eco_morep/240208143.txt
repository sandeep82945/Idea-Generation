Artificial intelligence (AI) advances and the rapid adoption of generative AI tools like ChatGPT present new opportunities and challenges for higher education. While substantial literature discusses AI in higher education, there is a lack of a systemic approach that captures a holistic view of the AI transformation of higher education institutions (HEIs). To fill this gap, this article, taking a complex systems approach, develops a causal loop diagram (CLD) to map the causal feedback mechanisms of AI transformation in a typical HEI. Our model accounts for the forces that drive the AI transformation and the consequences of the AI transformation on value creation in a typical HEI. The article identifies and analyzes several reinforcing and balancing feedback loops, showing how, motivated by AI technology advances, the HEI invests in AI to improve student learning, research, and administration. The HEI must take measures to deal with academic integrity problems and adapt to changes in available jobs due to AI, emphasizing AIcomplementary skills for its students. However, HEIs face a competitive threat and several policy traps that may lead to decline. HEI leaders need to become systems thinkers to manage the complexity of the AI transformation and benefit from the AI feedback loops while avoiding the associated pitfalls. We also discuss longterm scenarios, the notion of HEIs influencing the direction of AI, and directions for future research on 1. 5. discussion We discuss research insights and theoretical contributions, implications for academic leadership and policymakers, and future research directions. 5.1 findings and research implications This article takes a novel complex systems approach to how a HEI creates value and how AI affects those valuecreation processes. The article explores the effects of AI in higher education using a CLD, and it identifies multiple feedback loops and their interactions. Although AI has been relevant in higher education for the past twenty years, new waves of
AI, such as the generative AI today, create opportunities for transformation in a HEI. AI can help a HEI improve learning and increase its reputation, student enrollment, and revenue through several reinforcing loops. At the same time, current AI advances intensify academic integrity problems, a balancing loop, and if not adequately addressed, may undermine learning and the associated benefits for HEIs. If we focus on academic integrity problems, then a potential danger is education turning into
a ‘market for lemons’ in the eyes of employers if HEIs do not effectively address those problems. With increased student cheating, the employment market for graduates becomes a ‘lemon market’, as employers cannot easily discern which students learned. In extreme cases, the employment market collapses. Moreover, if a HEI has AIPs that are not in line with the peers, the institution puts itself at a competitive disadvantage by not investing in efforts to deal with AIPs. In other words, if a college has very high cheating rates, it will not be able to compete. Therefore, a HEI must maintain the proper amount of anticheating measures to be better or on par with competitors. This dynamic can also be interpreted as a ‘tragedy of the commons’, with the HEI’s reputation as a common resource and students acting as selfinterested parties; as the regulator of the common, the HEI must develop measures to fight academic integrity problems or risk that its reputation would collapse. Moreover, students who graduate from HEIs expect to find jobs, so job placement is a
crucial factor in the system under study. The CLD shows the crucial role of a HEI’s student job placement because it affects enrollments and revenues through several pathways. Job placement depends on student learning, a HEI's relative reputation, and job availability. AI impacts all three factors through several pathways, as shown in Figure 1. Therefore, the HEI needs to make the best use of AI to prepare its students for a job market shaped by AI, while other HEIs are likely to do the same, creating new AI opportunities and challenges over time. In the business world, AI automation lowers the demand for labor but increases the demand
for new skills. Successful HEIs adapt to those changes by teaching AI complementary skills. In the longterm scenario where AI automates all or most of the jobs, the current model of HEI collapses (see feedback loops R3, R4). HEIs, as we know them today, may disappear if there will be no demand for degrees, perhaps except for a small number of elite HEIs educating the government and business leaders. Those HEIs that survive and thrive will need models disconnected from degrees for jobs. They will need to create value in other ways, perhaps teaching humans leisure skills, providing lifelong learning training to humans (instead of intensive higher ed degrees as we know them today), or training and tuning AI systems in partnership with companies. If humans are supported by some kind of universal basic income (UBI) [130] due to the lack of jobs, then part of that income could be support for lifelong learning, a universal basic lifelong learning income (UBLI). Under this scenario, government support will be a source of revenue for the future HEIs. An alternative longterm scenario is that AI will become a new platform for new types of
jobs, and there will be an enormous demand for people to fill those jobs (similar to jobs in factories after the industrial revolution or office jobs with the adoption of computing). In that case, the future of HEIs is bright, especially if the job market is very fluid and people need multiple degrees over their lifetime. A HEI can grow and prosper or decline, depending on its AI investment and policies. Our
article shows that AI rewires the feedback loop structure that defines how a HEI creates value. Therefore, AI feedback loops can play an essential role in a HEI. This insight adds to previous research that finds that AI feedback loops play an important role in digital platforms [23,25]. Moreover, our work highlights that AI transformation is at the forefront of the ongoing digital transformation of higher education [131–134]. 5.2 lessons for academic leadership AI advances in the form of generative AI create several opportunities for AI transformation, including the promise to bring HEIs closer to the vision of personalized AI assistants that support students, faculty, and administrators. In that context, our research provides a first map of AI causal mechanisms to help HEI leaders navigate an uncharted landscape of opportunities and pitfalls. Leaders can use the CLD to build intuition and evaluate the benefits and risks of various
scenarios and HEI policies. Our discussion of feedback loops in section 4 is a starting point in that direction, but many other policies can be evaluated. For instance, a policy focused on costcutting at
the expense of education quality risks placing the HEI at a reinforcing decline trajectory primarily due to the feedback loop R3. If AI is used to support such a policy, then AI will speed up the decline, whereby revenues keep getting lower, and the HEI keeps costcutting until both approach zero. A crucial question for academic leaders is what competencies and skills will students need
to find a job. Following our earlier exploration, students should avoid competing headtohead with AI. Instead, they need foundational human skills that AI lacks, for instance, critical thinking, planning, complex problemsolving, creativity, lifelong learning, communication, management, and collaboration. Students need to learn how to learn and think in ways that differentiates them from machine learning. If AI becomes ubiquitous in firms, humans need skills that complement what AI can do well to benefit from AI. That includes skills to build, train, deploy, use, and manage AI systems, identify valuable use cases, devise AI strategies, lead teams or companies, etc. Moreover, students need to acquire those AI complementary skills in a way (quality, breadth, and depth) that allows them to compete effectively against other humans seeking similar jobs. For instance, managers that use AI effectively may replace those that do not. HEIs need to monitor changes in the job market [3] and remain adaptive. For instance, a
recent study argues that LLMs can transform the role of a data scientist from coding and datawrangling to assessing and managing analyses performed by AI tools [135]. In that case, skills related to strategic planning, coordinating resources, and overseeing the product life cycle become more important, and teaching data scientists must adapt accordingly, perhaps gradually over a period of time. The AI effects on productivity and automation are also relevant to what happens to jobs
within HEIs. Will AI make instructors, administrators, and staff more productive and their jobs more fulfilling? Will AI replace instructors, administrators, and staff in the longer term? Multiple effects play a role simultaneously, and the specified time horizon matters. However, a crucial framing question is: what does the HEI want to achieve with AI? The university policy and mission matters. For instance, a university that does not grow and does not aspire to the highest learning standards may manage with a small number of instructors, administrators, and staff, provided all those roles become more productive and many tasks are automated. However, a studentcentered and humancentered university that appreciates its people and wants to make their jobs more fulfilling may be successful by providing a superior education and differentiating itself from competitors that focus on costcutting. A related issue is the future direction of AI. Our exploration suggests that the direction of AI
advances is not predefined [136], and the social responsibility of a university lies in prioritizing how AI can empower humans by augmenting jobs rather than eliminating them [137]. As a starting point, HEIs could focus on designing and adopting personalized AI assistants for higher education: for faculty, students, staff, administrators (including department chairs and deans), advising, and more. At the same time, there is a need for careful integration of generative AI tools into education [138]; during the COVID19 pandemic, students suffered both academically and socially, and we relearned that education is a “deeply human act rooted in social interaction” (p. 7). Beyond the boundaries of the education sector, HEIs could promote AI assistants for various roles (e.g., financial analyst, CEO) across all industries and teach students accordingly. In that direction, our CLD suggests that a single HEI has very little influence over the
direction of AI, but a consortium of HEIs can have a meaningful influence. Moreover, similar to the proposals in the healthcare industry [139], there is value in opensource LLMs developed by a consortium of HEIs. Those insights suggest a tradeoff for a HEI: Investment in AI is a tool for getting ahead of its competition, but if it wants to influence the direction of AI meaningfully, the HEI needs to collaborate with other HEIs. Along those lines, AI advances could support education research that provides novel, rigorously validated insights into teaching and learning methods that could benefit all HEIs. Overall, AI promises several benefits but entails challenges, and ultimately, it depends on
what policy the HEI wants to follow and how to position itself by leveraging AIenabled transformation while protecting itself from the associated pitfalls. Regarding generative AI, HEIs deal with fastchanging technology and applications. Therefore, HEIs need to be adaptive. Start with smallscale experiments by faculty, students and staff, then learn from that, aggregate the experiences and perceptions, allow for more stability, and then plan and develop more comprehensive policies and guidelines. Leaders must take a balanced and realistic approach to their assessments and proceed cautiously. At this point, both businesses and HEIs are exploring how to take advantage of the latest AI innovations. Generative AI is the current novel tech, and it is natural to be overhyped and accompanied by an aura that will solve all the problems. This pattern is typical in technology space and tends to appear every few years. Contrary to conventional marketing, AI cannot solve all the problems but can create many new benefits and challenges. As long as AI advances at a fast pace, HEIs and AI will coevolve. In that coevolutionary process, universities could also learn from partnering with AI firms or other universities. All the complexities associated with the rapid AI adoption underscore the need for academic
leaders who are system thinkers. They must study the feedback loops that define the structure of value creation and determine the system behavior. Moreover, new technologies such as AI can bring a significant restructuring by creating new feedback loops, rewiring existing ones, and strengthening or weakening others. Leaders should aim to leverage those feedback loops for their benefit. A systems approach appreciates complexity, takes a wholesystem view, understands that system behavior over time is often nontrivial and counterintuitive, and considers the unintended consequences. For instance, an overreliance on costcutting approaches can place a HEI into a selfreinforcing decline. Another underappreciated systemic risk arises from the uniform adoption of identical AI models and practices across all HEIs, leading to an escalation in academic competition. 5.3 . 6. concluding remarks This article presents the first causal loop diagram of the AI transformation in HE, providing a holistic view of how important variables interact to drive AI investment and impact. We show that several reinforcing and balancing AI feedback loops work together to impact value creation in a HEI that interacts with companies that provide jobs for students, and the AI industry that drives AI advances. The model shows that the HEI invests in AI to improve teaching, research, and administration, but it must also adapt to student job market changes and take measures to deal with academic integrity problems. Student job placement is a crucial factor for the sustainability of the HEI model. Therefore, the HEI needs to emphasize AI complementary skills for its students. However, HEIs face a competitive threat and several traps that may lead to a decline. For instance, HEI policies focusing on excessive costcutting may reinforce its decline. In the long term, the current HEI model will not be viable if AI automation in companies becomes increasingly labordisplacing. The article makes several contributions. It provides a systemic view of AI in education and
proposes that academic leaders should become system thinkers to benefit from AI opportunities. It contributes to our understanding of the AI transformation of higher education from a complex systems perspective that focuses on the etiology and the consequences of AItransformed value creation in HEIs. The article integrates systems thinking and economic concepts to add to higher education economics and strategy with an emphasis on dynamic complexity. Moreover, it contributes to our thinking of how AI can support the sustainability of HEIs and highquality education, which is one of the UN’s sustainable development goals. Another significant contribution is connecting the HEI model affected by AI with job market factors, also affected by AI.