{
    "abstractText": "Quantifying eye movement is important for diagnosing various neurological and ocular diseases as well as AR/VR displays. We developed a simple setup for real-time dynamic gaze tracking and accommodation measurements based on Purkinje reflections, which are the reflections from front and back surfaces of the cornea and the eye lens. We used an accurate eye model in ZEMAX to simulate the Purkinje reflection positions at different focus distances of the eye, which matched the experimental data. A neural network was trained to simultaneously predict vergence and accommodation using data collected from 9 subjects. We demonstrated that the use of Purkinje reflection coordinates in machine learning resulted in precise estimation. The proposed system accurately predicted the accommodation with an accuracy better than 0.22 D using subject\u2019s own data and 0.40 D using other subjects\u2019 data with two-point calibration in tests performed with 9 subjects in our setup.",
    "authors": [
        {
            "affiliations": [],
            "name": "Faik Ozan Ozhan"
        },
        {
            "affiliations": [],
            "name": "Ugur Aygun"
        },
        {
            "affiliations": [],
            "name": "Afsun Sahin"
        },
        {
            "affiliations": [],
            "name": "Hakan Urey"
        }
    ],
    "id": "SP:113eaca3f495a33a417280acf796d9efc451f06e",
    "references": [
        {
            "authors": [
                "D. Barnes",
                "W. McDonald"
            ],
            "title": "The ocular manifestations of multiple sclerosis",
            "venue": "Abnormalities of eye movements. J. Neurol. Neurosurg. Psychiatry 55,",
            "year": 1992
        },
        {
            "authors": [
                "A. Serra",
                "C.G. Chisari",
                "Matta",
                "M. Eye movement abnormalities in multiple sclerosis"
            ],
            "title": "Pathogenesis, modeling, and treatment",
            "venue": "Front. Neurol. 9, 31",
            "year": 2018
        },
        {
            "authors": [
                "T.J. Crawford",
                "L. Henderson",
                "C. Kennard"
            ],
            "title": "Abnormalities of nonvisually-guided eye movements in Parkinson\u2019s disease",
            "venue": "Brain 112,",
            "year": 1989
        },
        {
            "authors": [
                "E. Pretegiani",
                "L.M. Optican"
            ],
            "title": "Eye movements in Parkinson\u2019s disease and inherited parkinsonian syndromes",
            "venue": "Front. Neurol. 8,",
            "year": 2017
        },
        {
            "authors": [
                "R.V. Kenyon",
                "K.J. Ciuffreda",
                "Stark",
                "L. Dynamic vergence eye movements in strabismus",
                "amblyopia"
            ],
            "title": "Symmetric vergence",
            "venue": "Investig. Ophthalmol. Vis. Sci. 19, 60\u201374",
            "year": 1980
        },
        {
            "authors": [
                "E. Niechwiej-Szwedo",
                "M. Chandrakumar",
                "H.C. Goltz",
                "Wong",
                "A.M.F. Effects of strabismic amblyopia",
                "I strabismus without Amblyopia on visuomotor behavior"
            ],
            "title": "Saccadic eye movements",
            "venue": "Investig. Ophthalmol. Vis. Sci. 53, 7458\u20137468",
            "year": 2012
        },
        {
            "authors": [
                "L. Dell\u2019Osso",
                "G. Gauthier",
                "G. Liberman",
                "L. Stark"
            ],
            "title": "Eye movement recordings as a diagnostic tool in a case of congenital nystagmus",
            "venue": "Am. J. Optom. Arch. Am. Acad. Optom",
            "year": 1972
        },
        {
            "authors": [
                "C. Wall",
                "F.O. Black"
            ],
            "title": "Algorithms for the clinical analysis of nystagmus eye movements",
            "venue": "IEEE Trans. Biomed. Eng",
            "year": 1981
        },
        {
            "authors": [
                "J.L. Newman",
                "J.S. Phillips",
                "S.J. Cox",
                "J. FitzGerald",
                "A. Bath"
            ],
            "title": "Automatic nystagmus detection and quantification in long-term continuous eye-movement data",
            "venue": "Comput. Biol. Med",
            "year": 2019
        },
        {
            "authors": [
                "S.T. Chung",
                "G. Kumar",
                "R.W. Li",
                "Levi",
                "D.M. Characteristics of fixational eye movements in amblyopia"
            ],
            "title": "Limitations on fixation stability and acuity",
            "venue": "Vision. Res. 114, 87\u201399",
            "year": 2015
        },
        {
            "authors": [
                "F. Ghasia",
                "J. Wang"
            ],
            "title": "Amblyopia and fixation eye movements",
            "venue": "J. Neurol. Sci. 441,",
            "year": 2022
        },
        {
            "authors": [
                "I. Gottlob",
                "R.D. Reinecke"
            ],
            "title": "Eye and head movements in patients with achromatopsia",
            "venue": "Graefes Arch. Clin. Exp. Ophthalmol",
            "year": 1994
        },
        {
            "authors": [
                "P.M. Allen",
                "O\u2019Leary",
                "D.J. Accommodation functions"
            ],
            "title": "Co-dependency and relationship to refractive error",
            "venue": "Vis. Res. 46, 491\u2013505",
            "year": 2006
        },
        {
            "authors": [
                "J.C. Chen",
                "K.L. Schmid",
                "Brown",
                "B. The autonomic control of accommodation",
                "implications for human myopia development"
            ],
            "title": "A review",
            "venue": "Ophthalmic Physiol. Opt. 23, 401\u2013422",
            "year": 2003
        },
        {
            "authors": [
                "F. Lara-Lac\u00e1rcel",
                "I. Mar\u00edn-Franch",
                "V. Fern\u00e1ndez-S\u00e1nchez",
                "R. Riquelme-Nicol\u00e1s",
                "N. L\u00f3pez-Gil"
            ],
            "title": "Objective changes in astigmatism during accommodation",
            "venue": "Ophthalmic Physiol. Opt",
            "year": 2021
        },
        {
            "authors": [
                "J. Geng"
            ],
            "title": "Three-dimensional display technologies",
            "venue": "Adv. Opt. Photonics",
            "year": 2013
        },
        {
            "authors": [
                "D.M. Hoffman",
                "A.R. Girshick",
                "K. Akeley",
                "M.S. Banks"
            ],
            "title": "Vergence-accommodation conflicts hinder visual performance and cause visual fatigue",
            "venue": "J. Vis",
            "year": 2008
        },
        {
            "authors": [
                "F. Daniel",
                "Z. Kapoula"
            ],
            "title": "Induced vergence-accommodation conflict reduces cognitive performance in the stroop test",
            "venue": "Sci. Rep. 9,",
            "year": 2019
        },
        {
            "authors": [
                "A.U. Batmaz",
                "M.D. Barrera Machuca",
                "J. Sun",
                "W. Stuerzlinger"
            ],
            "title": "The effect of the vergence-accommodation conflict on virtual hand pointing in immersive displays",
            "venue": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "D Consortium"
            ],
            "title": "3DC safety guidelines for dissemination of human-friendly",
            "year": 2010
        },
        {
            "authors": [
                "D.M. Win-Hall",
                "A. Glasser"
            ],
            "title": "Objective accommodation measurements in prepresbyopic eyes using an autorefractor and an aberrometer",
            "venue": "J. Cataract Refract. Surg",
            "year": 2008
        },
        {
            "authors": [
                "D.M. Win-Hall",
                "J. Houser",
                "A. Glasser"
            ],
            "title": "Static and dynamic measurement of accommodation using the grand seiko wam-5500 autorefractor",
            "venue": "Optom. Vis. Sci. Off. Publ. Am. Acad. Optom",
            "year": 2010
        },
        {
            "authors": [
                "A.M. Gehring",
                "J.X. Haensel",
                "M.K. Curtiss",
                "Roberts",
                "T.L. Validation of the powerref 3 for measuring accommodation"
            ],
            "title": "Comparison with the grand seiko wam-5500a autorefractor",
            "venue": "Transl. Vis. Sci. Technol. 11, 25\u201325 (2022). Figure 7. Schematic of the setup for measuring (a) accommodation effect, (b) accommodation and vergence combined effects, and (c) picture of the experimental setup. 10 Vol:.(1234567890) Scientific Reports |",
            "year": 2023
        },
        {
            "authors": [
                "R. Navarro",
                "J. Santamar\u00eda",
                "J. Besc\u00f3s"
            ],
            "title": "Accommodation-dependent model of the human eye with aspherics",
            "venue": "J. Opt. Soc. Am. A",
            "year": 1985
        },
        {
            "authors": [
                "Liou",
                "H.-L",
                "N.A. Brennan"
            ],
            "title": "Anatomically accurate, finite model eye for optical modeling",
            "venue": "J. Opt. Soc. Am. A 14,",
            "year": 1997
        },
        {
            "authors": [
                "J. Schwiegerling"
            ],
            "title": "Arizona eye model, in Field Guide to Visual and Ophthalmic Optics",
            "year": 2004
        },
        {
            "authors": [
                "T.N. Cornsweet",
                "H.D. Crane"
            ],
            "title": "Accurate two-dimensional eye tracker using first and fourth purkinje images",
            "venue": "JOSA 63,",
            "year": 1973
        },
        {
            "authors": [
                "H.D. Crane",
                "C.M. Steele"
            ],
            "title": "Accurate three-dimensional eyetracker",
            "venue": "Appl. Opt. 17,",
            "year": 1978
        },
        {
            "authors": [
                "Y. Itoh",
                "J. Orlosky",
                "K. Kiyokawa",
                "T. Amano",
                "M. Sugimoto"
            ],
            "title": "Monocular focus estimation method for a freely-orienting eye using purkinje-sanson images",
            "venue": "IEEE Virtual Reality (VR),",
            "year": 2017
        },
        {
            "authors": [
                "C. Lu",
                "P. Chakravarthula",
                "Y. Tao",
                "S. Chen",
                "H. Fuchs"
            ],
            "title": "Improved vergence and accommodation via purkinje image tracking with multiple cameras for ar glasses, in 2020",
            "venue": "IEEE International Symposium on Mixed and Augmented Reality (ISMAR),",
            "year": 2020
        },
        {
            "authors": [
                "J.W. Lee",
                "C.W. Cho",
                "K.Y. Shin",
                "E.C. Lee",
                "K.R. Park"
            ],
            "title": "3d gaze tracking method using purkinje images on eye optical model and pupil",
            "venue": "Opt. Lasers Eng",
            "year": 2012
        },
        {
            "authors": [
                "F.O. Ozhan",
                "A. Gulersoy",
                "U. Aygun",
                "A. Sahin",
                "H. Urey"
            ],
            "title": "Dynamic accommodation measurement using purkinje reflections and ml algorithms, in Ophthalmic Technologies XXXIII",
            "venue": "(SPIE,",
            "year": 2023
        },
        {
            "authors": [
                "K Kavakli"
            ],
            "title": "Pupil steering holographic display for pre-operative vision screening of cataracts",
            "venue": "Biomed. Opt. Express",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "1 Vol.:(0123456789) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0\nwww.nature.com/scientificreports"
        },
        {
            "heading": "Dynamic accommodation",
            "text": "measurement using Purkinje reflections and machine learning Faik Ozan Ozhan 1, Ugur Aygun 1, Afsun Sahin 2,3 & Hakan Urey 1,2*\nQuantifying eye movement is important for diagnosing various neurological and ocular diseases as well as AR/VR displays. We developed a simple setup for real-time dynamic gaze tracking and accommodation measurements based on Purkinje reflections, which are the reflections from front and back surfaces of the cornea and the eye lens. We used an accurate eye model in ZEMAX to simulate the Purkinje reflection positions at different focus distances of the eye, which matched the experimental data. A neural network was trained to simultaneously predict vergence and accommodation using data collected from 9 subjects. We demonstrated that the use of Purkinje reflection coordinates in machine learning resulted in precise estimation. The proposed system accurately predicted the accommodation with an accuracy better than 0.22 D using subject\u2019s own data and 0.40 D using other subjects\u2019 data with two-point calibration in tests performed with 9 subjects in our setup.\nEye movements are essential for our visual system to function correctly. Eyes converge to fixate on points in space during these movements. The distance between a specified point and the\u00a0eyes is called the vergence distance, and the amount of rotation during this process is known as the vergence angle. The quantification of eye movements and vergence is essential in the diagnosis and management of many neurological diseases such as multiple sclerosis1,2, Parkinson\u2019s disease3,4, ocular diseases such as strabismus5,6, nystagmus7\u20139, and visual impairments such as amblyopia5,10,11 or achromatopsia12. Eye movements are coupled with the focusing mechanism of the eye. The effective focal length of the eyes is adjusted by a change in the shape of the human crystalline lens, which is controlled by the ciliary muscles. This process is called accommodation, and the distance at which the eyes are focused is called accommodation depth measured in diopters (D), which is the reciprocal of the focus distance in meters. Accommodation depth typically varies between 4\u00a0D (25\u00a0cm) and 0\u00a0D (infinity) in adults. Accurately measuring the accommodation of the eye is crucial for understanding refractive errors13\u201315. Therefore, objectively measuring vergence and accommodation responses is beneficial in both research and clinics.\nThe accommodation and vergence are coupled and follow one another. Vergence can be predicted using eye movements and gaze angle. However, discrepancies are present between accommodation and vergence\u00a0in certain situations, such as with 3D displays. In the case\u00a0of 3D displays, the viewers\u2019 accommodation distance is at a\u00a03D screen in contrast to the vergence distance, which is at the object\u2019s apparent distance in 3D. This phenomenon is referred to as vergence-accommodation conflict (VAC)16, and its effects on various tasks have been analyzed in different studies17\u201320. Therefore, while vergence can be predicted with high accuracy using eye movements, accommodation cannot always be predicted accurately. Consequently, an alternative method is required for precise accommodation measurement.\nAutorefractors are a commonly used technique for measuring accommodation by examining how light is refracted by the eye to determine refractive errors21\u201323. Although widely used in clinical assessments, autorefractors rely on retinoscopy, a method involving the projection of a light beam into the eye and observing the light reflected from the retina. As a result, they do not provide information about the shape and optical power of the human crystalline lens during the accommodation process without a reference from the unaccommodated state. Moreover, many clinical autorefractors are bulky, limiting continuous monitoring and evaluation of accommodation during different activities and lacking information about vergence.\nAccommodation depth and vergence angle can be measured using the Purkinje reflections from the cornea and the eye lens illuminated by a point light source and measured using a camera focused on the pupil. Specifically, the first Purkinje image (P1) is the reflection from the anterior, the second Purkinje image (P2) from the posterior surface of the cornea, the third\u00a0Purkinje image (P3) from the anterior, and the fourth\u00a0Purkinje image\nOPEN\n1Department of Electrical and Electronics Engineering, Ko\u00e7 University, 34450 Istanbul, Turkey. 2Ko\u00e7 University Translational Medicine Research Center (KUTTAM), 34450 Istanbul, Turkey. 3School of Medicine, Ko\u00e7 University, 34450 Istanbul, Turkey. *email: hurey@ku.edu.tr\n2 Vol:.(1234567890) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0\n(P4) from the posterior surface of the human crystalline lens. It should be noted that P1 and P2 are indistinguishable since they are formed very closely to each other, and the combination of them forms the brightest spot. ZEMAX simulations are performed to simulate these reflections, and one NIR (near-infrared) LED source and one NIR camera are used to capture Purkinje images experimentally. Figure\u00a01 shows ZEMAX layouts demonstrating how Purkinje reflections are formed on the camera, the image formed on the camera sensor (from ZEMAX detector view), and the experimental result illustrating Purkinje image formations using NIR illumination.\nThe locations of Purkinje images are highly related to the shape of the human crystalline lens. As the eye accommodation depth changes, the shape of the\u00a0human crystalline lens changes. More specifically, as the subject focuses on near distances, the ciliary muscles contract, and the curvature of the lens increases. Researchers have developed accommodation-dependent models of the human eye by measuring the corneal radius of curvature, lens radii of curvature, and lens thickness as a function of accommodation24\u201326. Additionally, rotational movement of the eye occurs when the subject looks at different points, resulting in changes in the locations of reflections. Since P3 and P4 are formed after some refraction processes, the locations of P3 and P4 change significantly, while P1 and P2 remain almost stationary with eye rotation.\nPrior work has shown that Purkinje reflections can be used for vergence estimation and eye-tracking27,28. With the rise of machine learning\u00a0(ML) and deep learning techniques, researchers have explored the use of these methods on Purkinje reflections to develop an eye tracker capable of predicting accommodation depth\u00a0as well29\u201331. However, these studies use either P1 with P329,30 or P1 with P427,28,31 while discarding the other reflection. As a result, data and the accuracy of model predictions have been limited. In our previous study, we proposed a primitive version of our work, illustrating that accommodation can be measured dynamically using Purkinje images for different subjects32. However, the accommodation depth predicted with the previous\u00a0ML model, trained with the subject\u2019s own data, and resulted in\u00a0higher\u00a0error than the current version of our work, and vergence was only predicted with the feature extracted from P3 and P4 for one subject, not using ML.\nIn this work, we present a novel dynamic eye accommodation depth and vergence measurement system based on Purkinje reflections and the\u00a0ML model. In order to achieve user-independent dynamic accommodation measurement, we propose a simple optical setup consisting of a NIR LED illuminating the eye, a camera to capture Purkinje reflections, and a controllable RGB light source array with target points. We used the pupil center and the first 2 Purkinje reflections (P1 and P2) from the cornea and higher-order reflections (P3 and P4) from the eye lens for our measurements. In addition to AR/VR applications, the proposed system can be used in vision science applications and in multifocal intraocular lens simulators for cataract patients33 for dynamic accommodation and vergence measurement."
        },
        {
            "heading": "Results",
            "text": "The relationship between Purkinje images and accommodation/vergence We designed a setup that enables us to relate Purkinje images to both accommodation and vergence. Details of the optical setup are given in the Methods section. To simulate the changes in Purkinje reflections with accommodation, we modified Navarro\u2019s accommodation-dependent eye model24. The\u00a0Navarro model consists of four refracting surfaces, making it convenient to simulate Purkinje reflections. In addition, the model parameters\nFigure\u00a01. (a) Ray tracing simulation layouts illustrating 4 Purkinje reflections. (b) Detector view using the eye model in (a). (c) Experimental result illustrating Purkinje image formations using NIR illumination.\n3 Vol.:(0123456789) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0\nare well-established and accommodation-dependent, enabling continuous observation of\u00a0changes with accommodation. However, the ocular media in the model are designed for visible wavelengths. The refractive indices of the ocular media at NIR were adjusted to make the Purkinje reflection locations more accurate compared to our experiments. The axial length from the\u00a0cornea to the retina was kept constant.\u00a0In contrast, other model parameters (radius of curvature of the eye lens, lens thickness, anterior chamber length, and refractive indices of the ocular media) were changed to make focus adjustments (see Supplementary Table\u00a0S1 online). It should be noted that these parameters can vary between subjects due to anatomical variations in the eye. Eye rotation was also modeled. If the distance to a target point is d and the distance between the\u00a0optical axis of the eye and the target point is dtarget , the rotation angle is calculated using Eq.\u00a0(1) to take vergence into account in our model. We assumed that the height of the target point was properly adjusted with respect to the eyes, so the rotation only occurred in one direction.\nFigure\u00a02 illustrates the directions of Purkinje reflections for different accommodation and vergence values, as predicted by our eye model, corresponding to\u00a0the target point depicted by the small inset to the right of each subfigure. The optical path in each inset illustrates the top view of the eye and the\u00a0target point. Note that the most significant change due to accommodation occurs in the reflection from the anterior lens surface (P3). Importantly,\u00a0the relative positions of the eye, camera, and light source can affect the specific changes in the Purkinje image locations, and different setups would yield different results. We configured the position of the camera and the light source to achieve a large angular separation without causing vignetting for P3 and P4 reflections, especially when the\u00a0pupil size is small.\nThe captured images on the camera were processed using image processing techniques to identify Purkinje reflections. ZEMAX non-sequential ray tracing simulations resulted in similar changes in Purkinje reflection locations in response to changes in accommodation and vergence, as illustrated in Fig.\u00a03a. Based on these results, we identified 10 parameters, which are pupil center and size (xPC , yPC , r1, r2) and locations of Purkinje images (xP1, yP1, xP3, yP3, xP4, yP4). The use of 2 parameters r1, r2 for pupil size may seem confusing at first; however, it is necessary to accurately describe the size and the elliptical image of the pupil in our off-axis imaging system. These parameters and their dependence on accommodation and vergence changes can be seen in Fig.\u00a03b.\nAccommodation and vergence prediction using features extracted from the Purkinje images Before applying the ML algorithms, we first expressed the accommodation and vergence angles as functions of the features extracted from the parameters detailed in the previous section. To identify which features were most correlated with accommodation and vergence, we conducted correlation analyses between the different extracted features and the target accommodation depths for the\u00a0left eyes of 9 subjects. This allowed us to obtain a matrix of correlation coefficients, which revealed\u00a0that the vertical distance between P3 and P4 in our configuration was highly correlated with accommodation, while the distance between P1 and P4 was highly correlated with vergence. The unit of measure for distances is pixels (px). Using these findings, we calculated these features for all the experimental results and were able to express the linear relationship between these features and accommodation/\n(1)\u03b8 = arctan ( dtarget\nd\n)\nFigure\u00a02. Simulation layouts and optical paths illustrating chief ray reflections from 4 different optical layers for different accommodation and vergence conditions. (a) Focus of the eye at 1D (distance vision) with no eye rotation. (b) Focus of the eye at 1D (distance vision) with vergence angle of 5 deg. (c) Focus of the eye at 4D (near vision) with no eye rotation. (d) Focus of the eye at 4D (near vision) with vergence angle of 5 deg.\n4 Vol:.(1234567890) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0\nvergence for each subject individually. Figure\u00a04a,d illustrates the extracted features from experimental results with corresponding target accommodation/vergence values and curves based on linear relationships for one\u00a0of the subjects. Mathematically, the resulting function for accommodation prediction is expressed in Eq.\u00a0(2) where aacc (D/pixels) represents the slope of the curve, bacc (pixels) the x-intercept, as illustrated in Fig.\u00a04a. The resulting function for vergence prediction is expressed in Eq.\u00a0(3), where aver (deg/pixels) is the slope of the curve corresponding to Eq.\u00a0(3), and bver (pixels) is the x-intercept, as illustrated in Fig.\u00a04d.\nAfter determining these mathematical functions, we calculated\u00a0the accommodation depth and vergence angle using\u00a0experimentally found parameters and\u00a0these functions. Considering the experimental data collected can be expressed as a time sequence, we analyzed\u00a0the dynamic accommodation response and the change of vergence\n(2)Predicted Accommodation Depth [D] =aacc((yP4 \u2212 yP3)\u2212 bacc)\n(3)Predicted Vergence Angle [deg] =aver( \u221a (xP4 \u2212 xP3)2 + (yP4 \u2212 yP3)2 \u2212 bver)\nFigure\u00a03. (a) Image processing algorithm results and ZEMAX eye model predictions (figure inset) are compared and they are in good agreement . (b) Coordinates of 4 points (pupil center, P1, P3, and P4) extracted with our algorithm, which are used as input to the machine learning algorithm.\nFigure\u00a04. Accommodation and vergence predictions using analytical formulas (without machine learning) using data for 9 subjects (a) The vertical distance between P3 and P4 ( yP3 \u2212 yP4 ) obtained from the experimental results of one subject is correlated with accommodation distance of the target LED in the setup. (b) Predicted accommodation depth as a function of time using ( yP3 \u2212 yP4 ) (red line shows target LED distance) for one subject. (c) Mean values of predicted accommodation depths at all target accommodation depth levels for all 9 subjects. (d) The Euclidean distance between P1 and P4 ( d(P3\u2212 P4) ) obtained from the experimental results of one subject is correlated with vergence angle of the target LED. (e) Predicted vergence angle as a function of time using ( d(P3\u2212 P4) ) (red line shows target LED distance). (f) Mean values of predicted vergence angles at all target vergence angle levels for all 9 subjects.\n5 Vol.:(0123456789) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0\nangle for different subjects as functions of time. In Fig.\u00a04b,e, it is evident how well accommodation and vergence are predicted with mathematical functions over time for the same subject in Fig.\u00a04a. The same procedure is followed for 9 subjects, and average values of accommodation and vergence were calculated for all target accommodation depths and vergence values. The average values of predicted accommodation depth/vergence angle and corresponding target accommodation depth /vergence angle are illustrated in Fig.\u00a04c,f. As shown in Fig.\u00a04c,f, the accommodation depth is predicted by the feature of\u00a0the vertical distance between P3 and P4, with an\u00a0average root-mean-square-error (RMSE) of 0.21 D.\nAccommodation and vergence prediction utilizing machine learning The accommodation and vergence can be related to specific features obtained from the locations of Purkinje images, as can be seen in Fig.\u00a04. Even though vergence is predicted with low error, the accommodation depth error is high with this method. In the next step, we used ML regression algorithms where the inputs are the combination of 10 parameters (Purkinje reflection and pupil coordinates, and pupil shape) as defined above, and the outputs are the accommodation depth and the vergence angle. Different ML regression algorithms were tested for this purpose, and the multi-layer perceptron (MLP) was chosen as the best option. In the first method, the MLP algorithm was tested on the left eyes of all 9 subjects individually, and 30% of the each\u00a0subject\u2019s data was used for training while the entire dataset obtained from the same user was used for testing. After splitting the data into training and testing, the batch size, number of epochs, number of hidden units at each layer, and the\u00a0number of layers were specified by hyperparameter tuning. The predicted results from our MLP regression, using the locations of Purkinje reflections (xP1, yP1, xP3, yP3, xP4, yP4) as inputs, are expressed as a time sequence for one of the\u00a0subjects in Fig.\u00a05a. Figure\u00a05b illustrates the average values of the predicted accommodation depth and vergence angle for 2 different configurations and how they deviate from the target accommodation depth and vergence angle. The same procedure was followed for all subjects. Figure\u00a05c illustrates the average values of predicted accommodation depth/vergence angle and corresponding target accommodation depth (top) and vergence angle (bottom) by MLP regression for all subjects. The effect of pupil parameters on vergence and accommodation predictions was also investigated. Our aforementioned MLP model was used for analysis, but this time pupil parameters (xPC , yPC , r1, r2) besides the locations of the Purkinje images (xP1, yP1, xP3, yP3, xP4, yP4) were given as input to our MLP model. The results are included in Table\u00a01 and Supplementary Fig.\u00a0S1.\nThe\u00a0MLP regression model was trained and tested for each subject individually using the first method. A more robust and generalized approach is to use different subjects\u2019 data for training and testing. For this purpose, we applied leave-one-subject-out cross-validation\u00a0(LOSO-CV) by training the model using data from 8 subjects and leaving the remaining subject out at each fold. Grid search was used to tune hyperparameters for\nFigure\u00a05. Accommodation and vergence predictions for 9 subjects using machine learning trained only with the\u00a0subject\u2019s own data (a) Our MLP model, trained on the\u00a0subject\u2019s own data, predicts the accommodation depth (top) and vergence angle (bottom) for the subject as a time sequence. (b) The error between the\u00a0target and estimated points is\u00a0illustrated using the\u00a0average values of the predicted accommodation depth and vergence angle for this subject. (c) Average values of predicted accommodation depth and vergence angle are shown using our MLP model, trained on subjects\u2019 own data, for all 9 subjects.\n6 Vol:.(1234567890) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0\nthe training set at each time, and the best hyperparameters were chosen. After training the model using the data from 8 subjects, the user was asked to look at the 2 target calibration points at 3.5 D and 1.5 D, selected to provide a large range while allowing subjects with myopia and hypermetropia to focus. The\u00a010 parameters stated in the\u00a0previous section were calculated by our image processing algorithm using the set of frames obtained for the 2 calibration points (CP). The accommodation depth/vergence angle values at the\u00a0calibration points (ACP1(pred),ACP2(pred),VCP1(pred),VCP2(pred)) are predicted by the ML model. Subsequently, calibration data were used to introduce a variable offset to the initial predictions by the ML algorithm to obtain the final predicted accommodation and vergence values ( Apred and Vpred ) using Eqs.\u00a0(4) and (5):\nwhere ACP1(target) , VCP1(target) , ACP2(target) and VCP2(target) are target accommodation depths and vergence angles at the\u00a0calibration points, Apred and Vpred are the predicted accommodation depth and vergence angle found by the regression model, and Acalib and Vcalib are the accommodation depth and vergence angle after calibration. The results, where only Purkinje image locations were given as input to the\u00a0MLP model, are analyzed in Fig.\u00a06. The predicted results from our MLP regression are\u00a0expressed as a time sequence for one subject in Fig.\u00a06a. Figure\u00a06b shows the average values of predicted and calibrated accommodation depth and vergence angle for 2 different configurations, and how they deviate from the target accommodation depth and angle. The same procedure is followed for all subjects. Figure\u00a06c illustrates the average values of predicted accommodation depth/vergence angle and corresponding target accommodation depth (top) and\u00a0vergence angle (bottom) by MLP regression for all subjects. According to the\u00a0results, accommodation depth is found with an\u00a0RMSE of 0.32 D and vergence with 0.32\u25e6 on average.\nTable\u00a01 provides an\u00a0overview of the vergence and accommodation estimation results using different methods and parameters. Detailed statistical analyses for different subjects are presented\u00a0in Supplementary Fig.\u00a0S1. It shows the RMSE error for different subjects using the 14 target test points as input to different methods. The first ML method (ML trained with the subject\u2019s own data using P1, P3, and P4) results in the lowest maximum RMSE error of 0.22\u00a0D. On the other hand, the\u00a0second ML method using P1, P3, and P4, which uses a pre-trained model without the\u00a0subject\u2019s data, has a maximum error <\u00a00.40\u00a0D. Note that the\u00a0second method using P1, P3, and P4 performed better than the\u00a0second method using P1, P3, P4, PC, and PS. For 3D display applications, in order to minimize the vergence and accommodation conflict to <\u00a00.25\u00a0D, the accuracy of the method needs to be improved further, which can be done by enhancing the model using additional training data.\nTo investigate the impact of potential variability on the measurements, two of the subjects underwent additional tests. Their right eyes were\u00a0also tested to determine whether eye selection (right or left eye) affects measurements. We noticed no meaningful difference between the predictions for\u00a0the left and right eyes. The results of the\u00a0first ML method for the right and left eyes of\u00a0one of the subjects are compared with each other,\u00a0as\u00a0illustrated in Supplementary Fig.\u00a0S3. Similar patterns can be observed in this figure across the 2 measurements. A randomized procedure (LEDs are turned on and off randomly) on the left eyes of 2 subjects is\u00a0performed to avoid habituation to repeated stimulation. As expected,\u00a0accommodation response times are longer in the randomized procedure. However, the predicted accommodation depth accuracy remained similar, as seen in Supplementary Fig.\u00a0S2. System repeatability was tested by replicating experiments for the subjects and calculating the\u00a0Pearson correlation coefficient. A\u00a0fixed seed number was employed during calculations, guaranteeing the initial weights would\u00a0not change. When we used the first ML algorithm, trained with the\u00a0subject\u2019s own data and took P1, P3, and P4 as inputs, the measurements from the same subject were highly correlated (r\u00a0=\u00a00.99, p\u00a0<\u00a00.001\u00a0for both subjects). Additionally, measurements from the second algorithm, using others\u2019 data and taking P1, P3, and P4 as inputs,\u00a0were still highly correlated for 2 subjects (r\u00a0=\u00a00.91, p\u00a0<\u00a00.001; r\u00a0=\u00a00.85, p\u00a0<\u00a00.001).\nTo quantify the effects of the Purkinje image locations on the accommodation and vergence estimations, we used a feature importance technique on the whole dataset (experimental results from 9 subjects) named permutation importance. This technique randomly shuffles the values of a single feature in the dataset, then uses the\n(4) ACP1(target) \u2212 Acalib ACP1(pred) \u2212 Apred = Acalib \u2212 ACP2(target) Apred \u2212 ACP2(pred)\n(5) VCP1(target) \u2212 Vcalib VCP1(pred) \u2212 Vpred = Vcalib \u2212 VCP2(target) Vpred \u2212 VCP2(pred)\nTable 1. Comparison of different methods and features on our dataset: (i) analytical function, (ii) Purkinje image locations as inputs to ML model trained only with the\u00a0subject\u2019s own data, (iii) Purkinje image locations as well as pupil parameters as inputs to the ML model trained only with the\u00a0subject\u2019s own data, (iv) Purkinje image locations as inputs to the ML model trained by excluding the\u00a0subject\u2019s own data, and (v) Purkinje image locations as well as pupil parameters as inputs to the ML model trained by excluding the\u00a0subject\u2019s own data.\nDepth error [D] Angle error [deg]\nAnalytical function (Fig.\u00a04) 0.21 0.19\nML trained with own data using P1, P3, P4 (Fig.\u00a05) 0.18 0.16\nML trained with own data using P1, P3, P4, PC, PS 0.17 0.18\nML trained with others\u2019 data using P1, P3, P4 (Fig.\u00a06) 0.32 0.32\nML trained with others\u2019 data using P1, P3, P4, PC, PS 0.36 0.4\n7 Vol.:(0123456789) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0\nalgorithm to make estimations from the permuted dataset and measures how much the model\u2019s performance has decreased.\nThe relative weights of xP1 , yP1 , xP3 , yP3 , xP4 , and yP4 are found as 0.23\u00b1 0.005 , 0.13\u00b1 0.004 , 1.0\u00b1 0.035 , 0.50\u00b1 0.017 , 0.69\u00b1 0.020 , and 0.74\u00b1 0.015 , respectively, in the first configuration using the\u00a0permutation importance technique. Results reveal\u00a0that\u00a0the location of P1 is the least important feature for the accommodation estimation in the first configuration, as expected, given that\u00a0P1 is the reflection from the cornea and does not include information about the curvature of the lens. On the other hand, it is important to find relative weights in the second configuration to see the\u00a0vergence effect. The relative weights of xP1 , yP1 , xP3 , yP3 , xP4 , and yP4 are found as 0.47\u00b1 0.015 , 0.06\u00b1 0.002 , 0.18\u00b1 0.005 , 0.09\u00b1 0.005,1.0\u00b1 0.019 , and 0.01\u00b1 0.001 , respectively, in this configuration. The most important parameter is xP3 for accommodation estimation, while xP4 is an\u00a0indicator for vergence estimation. It should be noted that these values are specific to the camera, LED, and eye positions that have been optimized for our application. Variations may occur with different configurations."
        },
        {
            "heading": "Discussion",
            "text": "We proposed a simple setup for data collection and a real-time dynamic accommodation and vergence measurement system based on Purkinje reflections. Previous studies have explored the use of the first reflection (P1) from the cornea along with the third reflection (P3) from the anterior surface of the human crystalline lens29,30 or the fourth reflection (P4) from the posterior surface\u00a0of the human crystalline lens for eye tracking systems27,28,31. However, these studies reported limited accuracy even when the system was calibrated for a specific user. Some of these studies29,30 mention the use of two-dimensional pupil size for vergence measurement,\u00a0noting that vergence can be estimated by using changes in\u00a0two-dimensional pupil size only. However, such methods are sensitive to ambient illumination changes and require calibration for each user.\nIn this study, we built a controllable RGB light source array-based setup for data collection to train our ML algorithm. We found that both P3 and P4\u00a0are important for accurate estimations, and the\u00a0pupil center location is helpful for accurate vergence estimation. The proposed Purkinje reflection measurement setup is simple and uses only a camera and an NIR LED. We performed ZEMAX simulations to match our experimental results with the simulations, determining the optimum camera-LED-eye configuration for capturing all Purkinje images at accommodation depths covering 4 D to 1 D and vergence angles from 0 to 7 degrees.\nIn the first ML method, the data acquired from each subject was used in the training dataset for the ML algorithm. We demonstrate\u00a0that an average\u00a0RMSE of 0.17 D and 0.18 \u25e6 is achievable for accommodation and vergence predictions when the subject\u2019s pupils are monitored in subsequent trials. This method is an effective way\nFigure\u00a06. Accommodation and vergence predictions for 9 subjects using machine learning trained by excluding the\u00a0subject\u2019s own data. (a) Our MLP model, trained on data from other subjects and calibrated, predicts the accommodation depth (top) and vergence angle (bottom) for a single subject as a time sequence. (b) The error between the\u00a0target and estimated points is\u00a0illustrated using average values of the predicted accommodation depth and vergence angle for the same subject. (c) Average values of predicted accommodation depth and vergence angle using our MLP model, trained on data from other subjects and calibrated for all 9 subjects.\n8 Vol:.(1234567890) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0\nof finding the accommodation depth and vergence angle, as only a certain portion of the dataset is used for the analysis, while all of the images in the dataset are used when the results are found using the analytical function.\nIn the second ML method, we performed LOSO-CV to determine the possibility of predicting one subject\u2019s accommodation and vergence with the information obtained from all other subjects, eliminating the need for user-dependent model training. Using the LOSO-CV method, only with two-point calibration data, the accommodation and vergence angle for a new user were predicted with an average\u00a0accuracy of 0.32 D and 0.32 \u25e6 , respectively. It should be noted that due to the\u00a0effects of the different orientations of the eye during the experiments and the\u00a0intra-subject variability of human eyes, we have applied two-point calibration for both configurations to eliminate these effects. Nevertheless, subjects with refractive errors can affect the results as they cannot accommodate all target points. We tested our system on both eyes and observed similar patterns at various times using the\u00a0subject\u2019s own data. However, the\u00a0camera-LED-eye configuration may vary between the right and left eyes, potentially affecting the system\u2019s performance. We made repeatability and reproducibility tests using the data from the\u00a0same subject at different times. Even if the results indicate a\u00a0high correlation between measurements, subjects\u2019 alertness and misplacement of the eye may\u00a0cause the measurements to deviate from each other.\nAccommodation prediction of\u00a0<\u00a00.25\u00a0D can be considered adequate for AR/VR display applications since VAC remains within the acceptable limits20. The vergence prediction can be improved further by using a binocular system, such as those used in AR/VR headsets.\nIn conclusion, our prototype offers a reliable and accurate method for measuring dynamic accommodation and vergence based on Purkinje reflections. Our findings demonstrate the importance of using both P3 and P4 for precise estimation and provide a simple and efficient approach for implementing this technique. Our proposed method can be utilized for AR/VR displays and as a tool for vision research."
        },
        {
            "heading": "Methods",
            "text": "In this study, we developed a setup to measure both accommodation and vergence using Purkinje images. One component of the setup is a\u00a0controllable RGB light source array (WS2812B, Worldsemi Co.,Limited) placed in the visual field of the eye, covering target points from 4 to 1 D with 0.5 D intervals. The individual target LEDs on the RGB light source array were turned on and off, with each LED remaining on for 2\u00a0s. Participants were asked to accommodate their eyes to the LED turned on during the experiment. It was ensured that the LED brightness\u00a0was adjusted to a level where the subject can accommodate without any disruption. Red LEDs at 620\u00a0nm were chosen as target points since the reaction time to red stimuli is short, and accommodation does not\u00a0change significantly across different wavelengths34. One NIR LED source (TSAL6200, Vishay Intertechnology, Inc.) and one NIR camera (SQ11 Mini DV Camera, Dilwe1) were used to capture eye\u00a0images from the participants. The peak wavelength of the NIR LED illuminating the eye is selected as 940\u00a0nm. It is eye-safe, compatible with silicon detectors, and invisible to the eye, making it a practical choice for our system. Purkinje reflections in the model and the experiments are matched by changing the dispersion of the ocular media used in the model. We recorded the images captured from the camera at 50\u00a0Hz for 2\u00a0s, corresponding to 100 frames for each data point for 9 subjects. Reaction time, the time it takes for the visual system to respond to a visual stimulus, was considered during experiments, and the frames captured before eyes react were discarded. Purkinje image locations were detected in an average of\u00a015\u00a0ms. It took 16.4\u00a0s to train and test the data taken from one subject when the analysis was done individually. However, since the training with the other subjects\u2019 data can be done before testing, it takes 0.4\u00a0s to predict the accommodation/vergence with the LOSO-CV method. All analyses were performed with Python version 3.11.2, except for the correlation analyses between the different extracted features and the accommodation/vergence performed with the \u201ccorr\u201d function in MATLAB\u2019s Statistics and Machine Learning Toolbox (Math Works). Ray tracing simulations were carried out with ZEMAX OpticStudio version 19.4 SP1. All calculations were done with an\u00a0Intel(R) Core(TM) i7-6600U CPU @ 2.60GHz located inside DELL E5470. The speed can increase if more efficient processing units are used.\nThe precise position of the controllable RGB light source array was altered for different applications. Firstly, we placed the RGB light source array almost on the nose-to-chin axis to observe the effects of both vergence and accommodation. In this configuration, eye rotation was present to fixate on a point and accommodate. Both effects were present in this configuration. Secondly, the RGB light source array was also positioned along the left or right eye to enable observation of the effect of accommodation on the locations of Purkinje images. This allowed us to observe monocular accommodation\u00a0directly, which is useful for many different applications. In this configuration, we ensured that all light sources were clearly visible to the eyes and that no occlusion was present. It is important to note that Purkinje images are sensitive to head movements and different orientations. Therefore, correct head placement is necessary to prevent inaccurate results. To this end, we placed a monitor before capturing any images and asked the user to look at the specific part on the monitor and adjust their head location until their pupils were in the desired region on the monitor. We made adjustments using piezo stages when the user could not adjust their head correctly and minimized the errors caused by environmental effects and subject-specific variations. Our experimental setup schematics, designed for measuring the effects of both vergence and accommodation,\u00a0as well as only the effect of accommodation are illustrated in Fig.\u00a07, along with a picture of the setup.\n9 healthy adults participated in this study with no ophthalmological diseases, except for myopia or hypermetropia. An oral disclosure and paper-based consent form were given\u00a0to all participants prior to the study. Each participant gave written informed consent for participation in the study. All experimental protocols were approved by the\u00a0Ko\u00e7 University Ethics Committee on Human Research and conducted according to the institutional guidelines. This study was conducted according to the principles of the Declaration of Helsinki.\n9 Vol.:(0123456789) Scientific Reports | (2023) 13:21625 | https://doi.org/10.1038/s41598-023-47572-0"
        },
        {
            "heading": "Data availibility",
            "text": "Data underlying the results presented in this paper are not publicly available at this time but may be obtained from the authors upon reasonable request. Requests for data and materials should be adressed to H.U.\nReceived: 12 April 2023; Accepted: 15 November 2023"
        },
        {
            "heading": "Acknowledgements",
            "text": "The authors would like to thank F\u0131rat Turkkal and Arda Gulersoy for their help in prototype development. This work has been supported by European Innovation Council\u2019s HORIZON-EIC-2021-TRANSITION- CHALLENGES Program, Grant Number 101057672 and T\u00fcbitak\u2019s 2247-A National Lead Researchers Program, Project Number 120C145. Faik Ozan Ozhan is also supported by the TUBITAK\u2019s 2210/A Master\u2019s Scholarship Program."
        },
        {
            "heading": "Author contributions",
            "text": "F.O.O., U.A., A.S. and H.U. designed the study; F.O.O. and U.A constructed the experimental setup; F.O.O. performed the experiments and analyzed the data; F.O.O., U.A., A.S. and H.U. wrote the manuscript.\nCompeting Interests The authors declare no competing interests."
        },
        {
            "heading": "Additional information",
            "text": "Supplementary Information The online version contains supplementary material available at https:// doi. org/ 10. 1038/ s41598- 023- 47572-0.\nCorrespondence and requests for materials should be addressed to H.U.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n\u00a9 The Author(s) 2023"
        }
    ],
    "title": "Dynamic accommodation measurement using Purkinje reflections and machine learning",
    "year": 2023
}