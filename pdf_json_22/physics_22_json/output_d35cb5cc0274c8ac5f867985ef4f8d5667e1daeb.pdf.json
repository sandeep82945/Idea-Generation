{
    "abstractText": "Ionospheric forecasts are critical for space-weather anomaly detection. Forecasting ionospheric total electron content (TEC) from the global navigation satellite system (GNSS) is of great significance to near-earth space environment monitoring. In this study, we propose a novel ionospheric TEC forecasting model based on deep learning, which consists of a convolutional neural network (CNN), long-short term memory (LSTM) neural network, and attention mechanism. The attention mechanism is added to the pooling layer and the fully connected layer to assign weights to improve the model. We use observation data from 24 GNSS stations from the Crustal Movement Observation Network of China (CMONOC) to model and forecast ionospheric TEC. We drive the model with six parameters of the TEC time series, Bz, Kp, Dst, and F10.7 indices and hour of day (HD). The new model is compared with the empirical model and the traditional neural network model. Experimental results show the CNN-LSTM-Attention neural network model performs well when compared to NeQuick, LSTM, and CNN-LSTM forecast models with a root mean square error (RMSE) and R2 of 1.87 TECU and 0.90, respectively. The accuracy and correlation of the prediction results remained stable in different months and under different geomagnetic conditions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jun Tang"
        },
        {
            "affiliations": [],
            "name": "Yinjian Li"
        },
        {
            "affiliations": [],
            "name": "Mingfei Ding"
        },
        {
            "affiliations": [],
            "name": "Heng Liu"
        },
        {
            "affiliations": [],
            "name": "Dengpan Yang"
        },
        {
            "affiliations": [],
            "name": "Xuequn Wu"
        }
    ],
    "id": "SP:709ff94fc6bbb41252c23545847285840f1f1dc4",
    "references": [
        {
            "authors": [
                "D.R. Themens",
                "B. Reid",
                "P.T. Jayachandran",
                "B. Larson",
                "A.V. Koustov",
                "S. Elvidge",
                "A.M. McCaffrey",
                "C. Watson"
            ],
            "title": "E-CHAIM as a model of total electron content: Performance and diagnostics",
            "venue": "Space Weather 2021,",
            "year": 2021
        },
        {
            "authors": [
                "N.M. Francis",
                "P.S. Cannon",
                "A.G. Brown",
                "D.S. Broomhead"
            ],
            "title": "Nonlinear prediction of the ionospheric parameter foF2 on hourly, daily, and monthly timescales",
            "venue": "J. Geophys. Res",
            "year": 2000
        },
        {
            "authors": [
                "N.M. Francis",
                "A.G. Brown",
                "P.S. Cannon",
                "D.S. Broomhead"
            ],
            "title": "Prediction of the hourly ionospheric parameter foF2 using a novel nonlinear interpolation technique to cope with missing data points",
            "venue": "J. Geophys. Res",
            "year": 2001
        },
        {
            "authors": [
                "E. Tulunay",
                "E.T. Senalp",
                "S.M. Radicella",
                "Y. Tulunay"
            ],
            "title": "Forecasting total electron content maps by neural network technique",
            "venue": "Radio Sci. 2006, 41,",
            "year": 2005
        },
        {
            "authors": [
                "J.B. Habarulema",
                "L.A. McKinnell",
                "B.D. Opperman"
            ],
            "title": "Towards a GPS-based TEC prediction model for Southern Africa with feed forward networks",
            "venue": "Adv. Space Res",
            "year": 2009
        },
        {
            "authors": [
                "J.B. Habarulema",
                "L.-A. McKinnell",
                "B.D.L. Opperman"
            ],
            "title": "Regional GPS TEC modeling; Attempted spatial and temporal extrapolation of TEC using neural networks",
            "venue": "J. Geophys. Res",
            "year": 2011
        },
        {
            "authors": [
                "L. Huang",
                "J. Wang",
                "Y. Jiang",
                "J. Huang",
                "Z. Chen",
                "K. Zhao"
            ],
            "title": "A preliminary study of the single crest phenomenon in total electron content (TEC) in the equatorial anomaly region around 120\u25e6E longitude between",
            "venue": "Adv. Space Res",
            "year": 1999
        },
        {
            "authors": [
                "A.A. Ferreira",
                "R.A. Borges",
                "C. Paparini",
                "L. Ciraolo",
                "S.M. Radicella"
            ],
            "title": "Short-term estimation of GNSS TEC using a neural network model in Brazil",
            "venue": "Adv. Space Res",
            "year": 2017
        },
        {
            "authors": [
                "H. Bai",
                "H. Fu",
                "J. Wang",
                "K. Ma",
                "T. Wu",
                "J. Ma"
            ],
            "title": "A prediction model of ionospheric foF2 based on extreme learning machine",
            "venue": "Radio Sci",
            "year": 2018
        },
        {
            "authors": [
                "S. Lee",
                "E. Ji",
                "Y. Moon",
                "E. Park"
            ],
            "title": "One-Day Forecasting of global TEC using a novel deep learning model",
            "venue": "Space Weather 2021,",
            "year": 2020
        },
        {
            "authors": [
                "J. Wang",
                "F. Feng",
                "J. Ma"
            ],
            "title": "An adaptive forecasting method for ionospheric critical frequency of F2 layer",
            "venue": "Radio Sci. 2020,",
            "year": 2019
        },
        {
            "authors": [
                "M. Adolfs",
                "M.M. Hoque"
            ],
            "title": "A neural network-based TEC model capable of reproducing nighttime winter anomaly",
            "venue": "Remote Sens. 2021,",
            "year": 2021
        },
        {
            "authors": [
                "M.R.G. Razin",
                "A.R. Moradi",
                "S. Inyurt"
            ],
            "title": "Spatio-temporal analysis of TEC during solar activity periods using support vector machine. GPS Solut",
            "year": 2021
        },
        {
            "authors": [
                "S. Gampala",
                "V.R. Devanaboyina"
            ],
            "title": "Application of SST to forecast ionospheric delays using GPS observations",
            "venue": "IET Radar Sonar Navig",
            "year": 2017
        },
        {
            "authors": [
                "J.R.K.K. Dabbakuti",
                "R. Peesapati",
                "M. Yarrakula",
                "K.K. Anumandla",
                "S.V. Madduri"
            ],
            "title": "Implementation of storm-time ionospheric forecasting algorithm using SSA\u2013ANN model",
            "venue": "IET Radar Sonar Navig",
            "year": 2020
        },
        {
            "authors": [
                "J.R.K.K. Dabbakuti",
                "A. Jacob",
                "V.R. Veeravalli",
                "R.K. Kallakunta"
            ],
            "title": "Implementation of IoT analytics ionospheric forecasting system based on machine learning and ThingSpeak",
            "venue": "IET Radar Sonar Navig",
            "year": 2020
        },
        {
            "authors": [
                "A. Ruwali",
                "A.J.S. Kumar",
                "K.B. Prakash",
                "G. Sivavaraprasad",
                "D.V. Ratnam"
            ],
            "title": "Implementation of hybrid deep learning model (LSTM-CNN) for ionospheric TEC forecasting using GPS data",
            "venue": "IEEE Geosci. Remote Sens. Lett",
            "year": 2020
        },
        {
            "authors": [
                "P. Xiong",
                "D. Zhai",
                "C. Long",
                "H. Zhou",
                "X. Zhang",
                "X. Shen"
            ],
            "title": "Long short-term memory neural network for ionospheric total electron content forecasting over China",
            "venue": "Space Weather 2021,",
            "year": 2020
        },
        {
            "authors": [
                "J. Kim",
                "Y. Kwak",
                "Y. Kim",
                "S. Moon",
                "S. Jeong",
                "J. Yun"
            ],
            "title": "Potential of regional ionosphere prediction using a long short-term memory deep-learning algorithm specialized for geomagnetic storm period",
            "venue": "Space Weather 2021,",
            "year": 2021
        },
        {
            "authors": [
                "G.K. Zewdie",
                "C. Valladares",
                "M.B. Cohen",
                "D.J. Lary",
                "D. Ramani",
                "G.M. Tsidu"
            ],
            "title": "Data-driven forecasting of low-latitude ionospheric total electron content using the random forest and LSTM machine learning methods",
            "venue": "Space Weather 2021,",
            "year": 2020
        },
        {
            "authors": [
                "Z. Chen",
                "W. Liao",
                "H. Li",
                "J. Wang",
                "X. Deng",
                "S. Hong"
            ],
            "title": "Prediction of global ionospheric TEC based on deep learning",
            "venue": "Space Weather 2022,",
            "year": 2021
        },
        {
            "authors": [
                "Y. Liu",
                "Q. Zhang",
                "L. Song",
                "Y. Chen"
            ],
            "title": "Attention-based recurrent neural networks for accurate short-term and long-term dissolved oxygen prediction",
            "venue": "Comput. Electron. Agric",
            "year": 2019
        },
        {
            "authors": [
                "B. Zhang",
                "J. Ou",
                "Y. Yuan",
                "Z. Li"
            ],
            "title": "Extraction of line-of-sight ionospheric observables from GPS data using precise point positioning",
            "venue": "Sci. China Earth Sci",
            "year": 2012
        },
        {
            "authors": [
                "J. Gu",
                "Z. Wang",
                "J. Kuen",
                "L. Ma",
                "A. Shahroudy",
                "B. Shuai",
                "T. Liu",
                "X. Wang",
                "G. Wang",
                "J Cai"
            ],
            "title": "Recent advances in convolutional neural networks",
            "venue": "Pattern Recognit",
            "year": 2018
        },
        {
            "authors": [
                "F.A. Gers",
                "J. Schmidhuber",
                "F. Cummins"
            ],
            "title": "Learning to forget: Continual prediction with LSTM",
            "venue": "Neural Comput",
            "year": 2000
        },
        {
            "authors": [
                "D. Bahdanau",
                "K. Cho",
                "Y. Bengio"
            ],
            "title": "Neural machine translation by jointly learning to align and translate",
            "venue": "Comput. Sci. 2016. Available online: https://arxiv.org/abs/1409.0473 (accessed on",
            "year": 2022
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "Comput. Sci",
            "year": 2014
        },
        {
            "authors": [
                "B. Nava",
                "P. Co\u00efsson",
                "S. Radicella"
            ],
            "title": "A new version of the NeQuick ionosphere electron density model",
            "venue": "J. Atmos. Sol. Terr. Phys",
            "year": 2008
        },
        {
            "authors": [
                "Z. Wen",
                "S. Li",
                "L. Li",
                "B. Wu",
                "J. Fu"
            ],
            "title": "Ionospheric TEC prediction using long short-term memory deep learning network. Astrophys",
            "venue": "Space Sci",
            "year": 2021
        },
        {
            "authors": [
                "P. Galav",
                "S.S. Rao",
                "S. Sharma",
                "G. Gordiyenko",
                "R. Pandey"
            ],
            "title": "Ionospheric response to the geomagnetic storm of 15 May 2005 over midlatitudes in the day and night sectors simultaneously",
            "venue": "J. Geophys. Res. Space Phys",
            "year": 2014
        },
        {
            "authors": [
                "J. Tang",
                "X. Gao",
                "Y. Li",
                "Z. Zhong"
            ],
            "title": "Study of ionospheric responses over China during September 7\u20138, 2017 using GPS, Beidou (GEO), and Swarm satellite observations",
            "venue": "GPS Solut",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "Citation: Tang, J.; Li, Y.; Ding, M.;\nLiu, H.; Yang, D.; Wu, X. An\nIonospheric TEC Forecasting Model\nBased on a CNN-LSTM-Attention\nMechanism Neural Network. Remote\nSens. 2022, 14, 2433. https://doi.org/\n10.3390/rs14102433\nAcademic Editor: Shuanggen Jin\nReceived: 5 April 2022\nAccepted: 17 May 2022\nPublished: 19 May 2022\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional affil-\niations.\nCopyright: \u00a9 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nKeywords: ionospheric prediction; total electron content; deep learning; long-short term memory neural network; attention mechanism"
        },
        {
            "heading": "1. Introduction",
            "text": "The ionospheric total electron content (TEC), as a primary ionospheric parameter derived from global navigation satellite system (GNSS) observations, is defined as the total number of electrons within a 1 m2 column along a path through the ionosphere and is measured in TEC Units (TECU), where 1 TECU = 1016 electrons/m2 [1]. The prediction of ionospheric TEC is necessary to indicate adverse space weather conditions for initiating necessary measures in GNSS applications. Significant research studies were carried out to evaluate the utility of using different neural networks to investigate the ionospheric parameters forecasting [2\u201313]. Francis et al. [3] performed ionospheric parameter prediction and provided a technique to fill in missing data points, while minimizing the impact on data dynamics. Tulunay et al. [4] presented a neural network-based mapping technique for forecasting of ionospheric TEC over Europe. Habarulema et al. [5,6] forecasted ionospheric TEC in southern Africa using feedforward neural networks and investigated both the potential and the limitations of the ionospheric forecast extrapolation capabilities of artificial neural networks (ANNs). Huang et al. [7] implemented TEC forecasting for GPS ground stations using the radial basis function (RBF) neural network technique with the addition of a linear output layer. Ferreira et al. [8] used a neural network model for ionospheric TEC\nRemote Sens. 2022, 14, 2433. https://doi.org/10.3390/rs14102433 https://www.mdpi.com/journal/remotesensing\nRemote Sens. 2022, 14, 2433 2 of 22\nestimation in the Brazilian region with good results in the presence of low solar activity. Bai et al. [9] took advantage of the extreme learning machine (ELM) with fast learning speed and good generalization and established the ionospheric F2 layer critical frequency (foF2) forecast model. Lee et al. [10] achieved global ionospheric TEC forecasting using a deep learning approach based on conditional generation adversarial networks. Wang et al. [11] proposed a 1-h advance foF2 prediction method based on chaos theory, which has the advantages of simple structure, easy implementation, high prediction accuracy, a small training data set, and no solar and geomagnetic indices. Adolfs et al. [12] developed a fully connected neural network model using global ionosphere maps (GIMs) data from the last two solar cycles and made good predictions for the nighttime winter anomaly (NWA) forecast. Razin et al. [13] proposed a new method for spatial and temporal modeling forecasting of ionospheric TEC during periods of intense solar activity using a support vector machine (SVM) and evaluated the observation data from 37 GPS stations in Iran. To improve prediction accuracy, some ionospheric researchers performed feature extraction on the input data. Gampala et al. [14] used synchrosqueezing transform (SST) to improve the autoregressive moving average (ARMA) model for ionospheric TEC forecasting. Dabbakuti et al. [15] used singular spectrum analysis to preprocess the input data, which were then fed into an ANN for ionospheric TEC prediction. Meanwhile, they developed a prediction system based on the combination of variational mode decomposition (VMD) and kernel extreme learning machine (KELM) for an ionospheric analysis of the internet of things [16]. Recently, deep learning has inspired a surge of interest in ionosphere research. Ruwali et al. [17] developed a hybrid deep learning forecasted model based on GPS observations from Bengaluru, Guntur and Lucknow stations, which is a combination of long-short term memory (LSTM) and convolutional neural network (CNN). Xiong et al. [18] proposed an extended LSTM neural network model consisting of an encoder\u2013decoder structure to forecast ionospheric TEC, which was verified by using one solar cycle of observation data from 15 GPS stations in China. Kim et al. [19] used an LSTM neural network to design an ionospheric forecasting model suitable for geomagnetic storm periods and forecasted foF2 and fmF2 with good results. Zewdie et al. [20] first used a random forest approach to estimate input parameter importance and then used an LSTM deep recurrent neural network approach to predict ionospheric TEC. Chen et al. [21] used a multi-step auxiliary prediction model of deep learning to predict global ionospheric TEC and found that the method could effectively alleviate increasing errors with prediction time. Although some works have proposed hybrid deep learning methods to capture multiple features including spatial, temporal, and seasonal features for ionospheric parameters prediction, they are usually processed independently. However, the attention mechanism could learn dynamic spatio-temporal relationships in order to capture the relative importance of adjacent monitoring sites and, thus, improve the accuracy of the model [22]. Therefore, we develop a novel CNN-LSTM model with attention mechanism for ionospheric TEC forecasting. The model can optimize the weight distribution of the input information at the full connection layer to predict ionospheric TEC and reflect the spatiotemporal relationships between GNSS stations. In this study, the 9-year (from 2010 to 2018) observation data of 24 GNSS stations from the Crustal Movement Observation Network of China (CMONOC) were selected to predict the value of the TEC 24 h ahead. In addition, the prediction results of the CNN-LSTM-Attention model were compared with those of the NeQuick model, LSTM, and CNN-LSTM neural network model."
        },
        {
            "heading": "2. Data",
            "text": "The experimental data were selected from 2010 to 2018, which are GNSS observations of the CMONOC. The CMONOC is large-scale and high-precision GNSS network which consists of about 260 permanent GNSS continuous reference stations since 2010, and it can produce data with sampling intervals of 30 s. To comprehensively monitor changes of the ionospheric spatial environment in China, we selected 24 GNSS stations covering China for\nRemote Sens. 2022, 14, 2433 3 of 22\nexperimental analysis. The distribution of these stations is shown in Figure 1. Table 1 shows geographic coordinates of 24 GNSS stations from the CMONOC in detail. Table 2 shows the relationship between Universal Time (UT) and Local Time (LT) of 24 GNSS stations. We use the data of 24 GNSS stations in China to calculate the ionospheric TEC by the uncombined precise point positioning (UPPP) method of double-frequency GNSS receivers [23]. The interplanetary magnetic field southward component Bz, the geomagnetic index Kp, the magnetic storm ring current index Dst, and the solar activity index F10.7 are also used as auxiliary training data. The TEC time series is derived from GNSS observation data by using the UPPP method and is produced with sampling intervals of one hour. Other auxiliary training data are provided by NASA in 1 h increments.\nRemote Sens. 2022, 14, x FOR PEER REVIEW 3 of 23"
        },
        {
            "heading": "2. Data",
            "text": "The experimental data were selected from 2010 to 2018, which are GNSS observations of the CMONOC. The CMONOC is large-scale and high-precision GNSS network which consists of about 260 permanent GNSS continuous reference stations since 2010, and it can produce data with sampling intervals of 30 s. To comprehensively monitor changes of the ionospheric spatial environment in China, we selected 24 GNSS stations covering China for xperimental analysis. The distribution of these stations is shown in Figure 1. Table 1 sh ws geographic coordinates of 24 GNSS stations from the MONOC in d tail. Table 2 shows the relationship between Universal Time (UT) and Local Time (LT) f 24 GNSS stations. We use the d ta of 24 GNSS stations in China to calculate the ionospheric TEC by the uncombined precise point positi ning (UPPP) method of double-frequency GNSS rec ivers [23]. The i terplanetary magneti field sou hward compone t Bz, th geomagnetic index Kp, the magn tic storm ring current index Dst, and the solar activity ind x F10.7 are also used as auxiliary training data. The TEC time series is derived from GNSS observation data by using the UPPP metho and is produced with sampli g intervals of one hour. Other auxiliary training ata are provided by NASA in 1 h increments.\nFigure 1. Locations of the 24 GNSS stations from the CMONOC.\nTable 1. Geographic coordinates of 24 GNSS stations from the CMONOC.\nStations Latitude (\u00b0) Longitude (\u00b0) Stations Latitude (\u00b0) Longitude (\u00b0) BJFS 39.61 115.89 SHA2 31.10 121.20\nCHUN 43.79 125.44 TAIN 36.21 117.12 GDZH 22.28 113.57 TASH 37.77 75.23 GSMQ 38.63 103.09 WUHN 30.53 114.36 HISY 18.24 109.53 WUSH 41.20 79.21 HLHG 47.35 130.24 XIAA 34.18 108.99 HLMH 52.98 122.51 XIAM 24.45 118.08 KMIN 25.03 102.80 XJBE 47.69 86.86 LHAS 29.66 91.10 XJKE 41.79 86.19 NMDW 45.51 116.96 XNIN 36.60 101.77 SCTQ 30.07 102.77 XZBG 30.84 81.43\nSDYT 37.48 121.44 YANC 37.78 107.44\nFigure 1. Locations of the 24 SS stations fro the C C.\na le 1. e ra ic c r i ates f 24 stati s fr t e .\ntations Lati ude (\u25e6) ngitude (\u25e6) tations Lati ude (\u25e6) ngitude (\u25e6)\nBJFS 39.61 115.89 SHA2 31. 0 121.20 C UN 43.79 125.44 TAIN 36.21 117.12 GDZH 22.28 113.57 TASH 37.77 75.23 GSMQ 38.63 103.09 WUHN 30.53 114.36 HISY 18.24 109.53 WUSH 41.20 79.21 HLHG 47.35 130.24 XIAA 3 . 8 108.99 HLMH 52.98 122.51 XIAM 24. 5 118.08 KMIN 25.03 102.80 XJBE 47.69 86.86 LHAS 29.66 91.10 XJKE 41.79 86.19 NMDW 45.51 116.96 XNIN 36.60 101.77 SCTQ 30.07 102.77 XZBG 30.84 81.43 SDYT 37.48 121.44 YANC 37.78 107.44\nRemote Sens. 2022, 14, 2433 4 of 22"
        },
        {
            "heading": "3. Model and Methodology",
            "text": ""
        },
        {
            "heading": "3.1. Convolutional Neural Network",
            "text": "The essence of convolution is a weighted sum of data. CNN is a feedforward neural network based on convolutional convolutions, which was initially applied in the field of image recognition and later showed great potential in time series prediction [24]. CNN is composed of convolutional layer, pooling layer, and fully connected layer. The convolutional layer consists of several convolutional units, the parameters of each convolutional unit are optimized by a back-propagation algorithm, and the purpose of the convolutional operation is to extract the different features of the input. The input data are passed through the convolution layer to obtain the feature map. Feature map is the result of the convolution of the input data by the neural network, which characterizes a feature in the neural space. The purpose of the pooling layer is to reduce the feature map, and its main role is to reduce the computational effort by reducing the parameters of the network and to be able to control overfitting to some extent. The fully connected layer combines all local features into global features, which are used to calculate the final score for each category. In this case, the convolution operation is to multiply the local features by the corresponding weights and then accumulate the sum. The pooling operation is to sample the features extracted from the lower layers to reduce the size of the network and obtain the invariant features of the input data. The calculation formula of feature extraction by CNN is as follows:\ny = \u03c3(Wk \u2297 x + bk) (1)\nWk \u2297 xi,j = \u03b1\u22121 \u2211\nm=0\n\u03b2\u22121 \u2211 n=0 wm,n \u00d7 xi+m,j+n (2)\nwhere x is the input data; y is the output data; \u03c3 is the activation function; Wk and bk are the weight coefficient and bias function, respectively; k refers to number of convolution kernels. \u2297 denotes the discrete convolution operation; \u03b1 and \u03b2 are the size parameters of the convolution kernel, respectively. wm,n represents one of the weight coefficients of convolution kernel which is a weight matrix. m and n represent row and column index of input data, respectively."
        },
        {
            "heading": "3.2. Long-Short Term Memory Neural Network",
            "text": "LSTM neural network is improved on the basis of recurrent neural network (RNN). RNN suffers from gradient disappearance and gradient explosion when processing longer sequences. LSTM neural network provides a new solution to problem of short-term memory and introduces a state value and \u201cgate\u201d control structure based on the recurrent neural network. To selectively filter information, the transmission of data information between different units in the hidden layer is controlled by three thresholds: input gate, forget gate, and output gate [25]. The internal structure of LSTM and the form of data flow are shown in Figure 2. The function of the forget gate is to decide whether to reset the previous information and to multiply it with previous memory information to determine whether the information is retained. The input gate controls the input of the current information. When the information passes through the input unit, it is multiplied by the input gate to\nRemote Sens. 2022, 14, 2433 5 of 22\ndetermine whether to write the current information. The output gate controls the output of the current memory information, which is multiplied by current memory information to determine whether to output the information. The LSTM information flow process is calculated as follows:\nit = \u03c3(Wi[ht\u22121, xt] + bi) (3)\nft = \u03c3(W f [ht\u22121, xt] + b f ) (4)\not = \u03c3(Wo[ht\u22121, xt] + bo) (5)\nC\u0303t = tanh(WC \u00b7 [ht\u22121, xt] + bC) (6)\nCt = ft \u00b7 Ct\u22121 + it \u00b7 C\u0303t (7)\nht = ot \u00b7 tanh(Ct) (8)\nwhere it, ft, ot are the input gate, forget gate, and output gate, respectively; \u03c3 is the activation functions; W and b are the weight coefficient and bias function, respectively; C\u0303t and Ct are the immediate state and long-term state, respectively; tanh is the hyperbolic tangent activation function; x and h are the current input and output information, respectively.\nRemote Sens. 2022, 14, x FOR PEER REVIEW 5 of 23\nsequences. LSTM neural network provides a new solution to problem of short-term memory and introduces a state value and \u201cgate\u201d control structure based on the recurrent neural network. To selectively filter information, the transmission of data information between different units in the hidden layer is controlled by three thresholds: input gate, forget gate, and output gate [25]. The internal structure of LSTM and the form of data flow are shown in Figure 2. The function of the forget gate is to decide whether to reset the previous information and to multiply it with previous memory information to determine whether the information is retained. The input gate controls the input of the current information. When the information passes through the input unit, it is multiplied by the input gate to determine whether to write the current information. The output gate controls the output of the current memory information, which is multiplied by current memory information to determine whether to output the information. The LSTM information flow process is calculated as follows:\n[ ]1( , )t i t t ii W h x b\u03c3 \u2212= + (3)\n[ ]1( , )t f t t ff W h x b\u03c3 \u2212= + (4)\n[ ]1( , )t o t t oo W h x b\u03c3 \u2212= + (5)  1tanh( [ , ] )t C t t CC W h x b\u2212= \u22c5 + (6)\n 1 tt t t tC f C i C\u2212= \u22c5 + \u22c5 (7)\ntanh( )t t th o C= \u22c5 (8)\nwhere , ,t t ti f o are the input gate, forget gate, and output gate, respectively; \u03c3 is the activation functions; W and b are the weight coefficient and bias function, respectively;  tC and tC are the immediate state and long-term state, respectively; tanh is the hyperbolic tangent activation function; x and h are the current input and output information, respectively.\nFigure 2. LSTM neural network structure diagram including forget gate, input gate, and output gate.\n3.3. Attention Mechanism When dealing with a large amount of data information, some of the main information will be screened and magnified. Attention mechanism refers to selecting the most appropriate input from numerous alternative information according to observed environmental information. The main purpose of attention mechanism is to process more important\nFigure 2. LSTM neural network structure diagram including forget gate, input gate, and output gate."
        },
        {
            "heading": "3.3. Attention Mechanism",
            "text": "Wh n dealing with a large amount of data information, some of the main information will be screened and magnified. Attention mechanis refers to selecting the most appropriate input from numerous alternative infor ation according to observed environmental information. The main purpose of attention mechanism is to process more important information with limited resources and suppress other useless information. The essence is to focus on input weight allocation [26]. In this study, a CNN-LSTM-Attention neural network model is established. The structural framework is shown in Figure 3. The data are first input through the input layer, including the TEC time series and 5 auxiliary training indices of Bz, Kp, Dst, F10.7 and hour of day (HD). The CNN layer is composed of two 1-D convolutions and a maximum pooling layer as encoder based on classic encoder-decoder form. The first convolution reads the input sequence and projects the results onto the feature map. The second convolution performs the same operation on the feature map created at the first layer, trying to magnify its salient features. The pooling layer is selected for maximum pooling. Maximum pooling means taking the maximum value in the sample as the sample value after sampling. The maximum pooling layer simplifies the feature map, and then it flattens the extracted feature map into a long vector, which is used as the input to the decoding process. Then, the data flow into LSTM model to obtain the TEC forecasted value through three thresholds. Finally, the\nRemote Sens. 2022, 14, 2433 6 of 22\nfinal output value is obtained by a weighted sum of attention mechanism, and the TEC forecasted value in the next 24 h is the output.\nRemote Sens. 2022, 14, x FOR PEER REVIEW 6 of 23 information with limited resources and suppress other useless information. The essence is to focus on input weight allocation [26]. In this study, a CNN-LSTM-Attention neural network model is established. The structural framework is shown in Figure 3. The data are first input through the input layer, including the TEC time series and 5 auxiliary training indices of Bz, Kp, Dst, F10.7 and hour of day (HD). The CNN layer is composed of two 1-D convolutions and a maximum pooling layer as encoder based on classic encoder-decoder form. The first convolution reads the input sequence and projects the results onto the feature map. The second convolution performs the same operation on the feature map created at the first layer, trying to magnify its salient features.\nThe pooling layer is selected for maximum pooling. Maximum pooling means taking the maximum value in the sample as the sample value after sampling. The maximum pooling layer simplifies the feature map, and then it flattens the extracted feature map into a long vector, which is used as the input to the decoding process. Then, the data flow into LSTM model to obtain the TEC forecasted value through three thresholds. Finally, the final output value is obtained by a weighted sum of attention mechanism, and the TEC forecasted value in the next 24 h is the output.\nIn this study, experimental data are divided into two parts: the training set and the test set. The data from 2010 to 2017 are used as the training set to train the model, and the data from 2018 are used as the test set. Firstly, the outliers and missing values of the TEC data obtained by the solution are processed. The outliers are eliminated by the triple standard deviation method, and the missing values are filled using the bilinear interpolation method. The variation of TEC is associated with HD and solar and geomagnetic activity. Solar and geomagnetic activity can be characterized by the Bz, Kp, Dst, and F10.7 indices. Then, six features are considered as the training set, which are TEC time series, Bz, Kp, Dst, F10.7 indices, and HD. A total of 192 groups of data from 8 days were used as sample sliding segmentation. Each sample used the data of the first 7 days to forecast the TEC value for the last 1 day, and the training set samples are input into the network training forecast model. Figure 4 shows four input indices Bz, Kp, Dst, and F10.7 and the"
        },
        {
            "heading": "3.4. Data Organization and Parameter Setting",
            "text": "In this study, experimental data are divided into two parts: the training set and the test set. The data from 2010 to 2017 are used as the training set to train the model, and the data from 2018 are used as the test set. Firstly, the outliers and missing values of the TEC data obtained by the solution are processed. The outliers are eliminated by the triple standard deviatio method, and the missing values are filled using the bilinear interpol tion method. The variation of TEC is associated with HD and solar and geomagnetic activity. Solar and geomagnetic acti ity can be characterized by the Bz, Kp, Dst, a F10.7 indices. Then, six features are considered as the training set, which are TEC time series, Bz, Kp, Dst, F10.7 indices, and HD. A total of 192 groups of data from 8 days were used as sample sliding segmentation. Each sample used the data of the first 7 days to forecast the TEC value for the last 1 day, and the training set samples are input into the network training forecast model. Figure 4 shows four input indices Bz, Kp, Dst, and F10.7 and the measured TEC values of four stations at HLMH, BJFS, WUSH, and HISY from 2010 to 2018. The Bz index s uniformly distributed on both sides o 0. Geomag eti activity shows irregularities, including 2 mega-magnetic storms in 2015. Solar activity peaked in 2014, coinciding with a maximum TEC value. Hyperparameters are the parameters for which machine learning sets values before starting the learning process. The setting of hyperparameters is the key to the prediction effect of the neural network. We used the training set root mean square error (RMSE) as the evaluation index and chose the grid search method to find optimal hyperparameters. The hyperparameters include batch size, epochs number, and filters number and kernel size. We set the loss function as the mean absolute error (MAE) and used the \u2018tanh\u2019 activation function and \u2018adam\u2019 optimization algorithm [27] to drive the model.\nRemote Sens. 2022, 14, 2433 7 of 22\nRemote Sens. 2022, 14, x FOR PEER REVIEW 7 of 23 measured TEC values of four stations at HLMH, BJFS, WUSH, and HISY from 2010 to 2018. The Bz index is uniformly distributed on both sides of 0. Geomagnetic activity shows irregularities, including 2 mega-magnetic storms in 2015. Solar activity peaked in 2014, coinciding with a maximum TEC value.\nHyperparameters are the parameters for which machine learning sets values before starting the learning process. The setting of hyperparameters is the key to the prediction effect of the neural network. We used the training set root mean square error (RMSE) as the evaluation index and chose the grid search method to find optimal hyperparameters. The hyperparameters include batch size, epochs number, and filters number and kernel size. We set the loss function as the mean absolute error (MAE) and used the \u2018tanh\u2019 activation function and \u2018adam\u2019 optimization algorithm [27] to drive the model."
        },
        {
            "heading": "4. Results and Evaluation",
            "text": "To verify the advantages of the CNN-LSTM-Attention model for ionospheric TEC forecasting, we select the NeQuick model [28], the LSTM neural network [29], and the CNN-LSTM neural network [17] for comparative analysis. The NeQuick model is based on the NeQuick-2 version released by the Abdus Salam International Centre for Theoretical Physics (ICTP), and we used the daily solar radio flux as the input data. The LSTM and CNN-LSTM models have the same input data as the model in this paper. The forecast performance of each model is evaluated according to the station location, time variation, and geomagnetic activity from the test set forecasts. We also used the RMSE, correlation coefficient (R2), MAE, and mean absolute percentage error (MAPE) to evaluate model\nRemote Sens. 2022, 14, 2433 8 of 22\nperformances. RMSE and MAE indicate the dispersion of errors between forecasted and observed values. R2 indicates the correlation between forecasted and observed values. MAPE can measure the relative error between the average forecasted value and the observed value. The calculation formulas are as follows:\nRMSE = \u221a 1 n n\n\u2211 i=1\n(y\u0302i \u2212 yi)2 (9)\nR2 = (\ncov(y\u0302i, yi) \u03c3y\u0302i \u00b7 \u03c3yi\n)2 (10)\nMAE = 1 n\nn\n\u2211 i=1 |y\u0302i \u2212 yi| (11)\nMAPE = 1 n\nn\n\u2211 i=1 \u2223\u2223\u2223\u2223 y\u0302i \u2212 yiyi \u2223\u2223\u2223\u2223\u00d7 100% (12)\nwhere y\u0302i is the TEC forecasted value; yi is the observed value and n is the number of data points."
        },
        {
            "heading": "4.1. Accuracy Assessment of Different Stations",
            "text": "Figure 5 shows the two-dimensional scatterplot of the CNN-LSTM-Attention model predictions and GNSS measurements for HLMH, TASH, SDYT, and HISY stations. The horizontal axis indicates the measured values, and the vertical axis indicates the forecasted values. The color bar indicates the density share. Y = f(X) denotes the equation of the scatter-fitted straight line. Y is the forecasted TEC, and X is the observed TEC. It can be observed that the TEC distributions of different stations show different patterns. The TEC of high latitude station are basically distributed within 10 TECU. The maximum TEC of HISY station located at low latitudes exceeds 50 TECU. The CNN-LSTM-Attention model forecasts and GNSS measurements are highly correlated, with R2 of 0.87, 0.88, 0.90, and 0.91 for the four stations, respectively. Remote Sens. 2022, 14, x FOR PEER REVIEW 9 of 23\nFigure 5. Scatterplot of forecasted TEC as a function of observed TEC for the (a) HLMH, (b) TASH, (c) SDYT, and (d) HISY stations. The horizontal axis is the observed TEC; the vertical axis is the forecasted TEC, and color represents percentages.\nTable 3 shows the overall evaluation metrics of the four models. The statistical results are obtained from the data from 24 GNSS stations, 24 h a day and 365 days a year in the test set. The empirical model NeQuick model has the maximum RMSE and the minimum correlation. The RMSEs of LSTM, CNN-LSTM, and CNN-LSTM-Attention models are 2.25, 2.07, and 1.87 TECU, respectively, and the MAEs are 1.53, 1.36, and 1.17 TECU, respectively. This indicates the neural network model has good forecast performance. The prediction performance of the improved model is the best.\nWe selected 12 stations covering the range of China in the longitudinal and latitudinal directions for effect evaluation, with 6 stations distributed around 120\u00b0E in the longitudinal direction and 6 stations distributed around 30\u00b0N in the latitudinal direction. Figure 6 shows the performance evaluation indexes of the annual forecasted results for the four models test set of 12 GNSS stations. The evaluation results of the other 12 stations are shown in Figure A1. Figure 5a,c are the RMSE and R2 of the observed and forecasted values of the 6 stations distributed in longitude, respectively. Figure 5b,d are the RMSE and R2 of the observed and forecasted values of the six stations distributed in latitude, respectively. The four colors represent the four models used in the forecast, respectively. It can be observed that the CNN-LSTM-Attention model has better forecasting performance compared to the other three models. RMSE decreases with the increase in latitude near the same longitude, which is about 1 TECU in mid-latitude region and between 1.6 and 3 TECU in six stations around 30\u00b0N. The GDZH and HISY stations at low latitudes are affected by ionospheric anomalies near the equator [30]. The main driving forces are due to the interaction of an electric field, which develops close to the magnetic equator, and the horizontal magnetic field causing E \u00d7 B drift of the plasma from low altitudes to high altitudes with the plasma then falling under gravity to form the equatorial (or Appleton Anomaly) at approximately plus and minus 20 degrees. The RMSEs of GDZH and HISY\nFigure 5. Scatterplot of forecasted TEC as a function of observed TEC for the (a) HLMH, (b) TASH, (c) SDYT, and (d) HISY stations. The horizontal axis is the observed TEC; the vertical axis is the forecasted TEC, and color represents percentages.\nTable 3 shows the overall evaluation metrics of the four models. The statistical results are obtained from the data from 24 GNSS stations, 24 h a day and 365 days a year in the\nRemote Sens. 2022, 14, 2433 9 of 22\ntest set. The empirical model NeQuick model has the maximum RMSE and the minimum correlation. The RMSEs of LSTM, CNN-LSTM, and CNN-LSTM-Attention models are 2.25, 2.07, and 1.87 TECU, respectively, and the MAEs are 1.53, 1.36, and 1.17 TECU, respectively. This indicates the neural network model has good forecast performance. The prediction performance of the improved model is the best. We selected 12 stations covering the range of China in the longitudinal and latitudinal directions for effect evaluation, with 6 stations distributed around 120\u25e6E in the longitudinal direction and 6 stations distributed around 30\u25e6N in the latitudinal direction. Figure 6 shows the performance evaluation indexes of the annual forecasted results for the four models test set of 12 GNSS stations. The evaluation results of the other 12 stations are shown in Figure A1. Figure 5a,c are the RMSE and R2 of the observed and forecasted values of the 6 stations distributed in longitude, respectively. Figure 5b,d are the RMSE and R2 of the observed and forecasted values of the six stations distributed in latitude, respectively. The four colors represent the four models used in the forecast, respectively. It can be observed that the CNN-LSTM-Attention model has better forecasting performance compared to the other three models. RMSE decreases with the increase in latitude near the same longitude, which is about 1 TECU in mid-latitude region and between 1.6 and 3 TECU in six stations around 30\u25e6N. The GDZH and HISY stations at low latitudes are affected by ionospheric anomalies near the equator [30]. The main driving forces are due to the interaction of an electric field, which develops close to the magnetic equator, and the horizontal magnetic field causing E \u00d7 B drift of the plasma from low altitudes to high altitudes with the plasma then falling under gravity to form the equatorial (or Appleton Anomaly) at approximately plus and minus 20 degrees. The RMSEs of GDZH and HISY stations exceeded 3 TECU. In terms of correlation, the R2 of all 24 stations of the CNN-LSTM-Attention model exceeded 0.8, and the forecasted values are highly correlated with the measured values. Remote Sens. 2022, 14, x FOR PEER REVIEW 10 of 23 stations exceeded 3 ECU. In terms of correlation, the R2 of all 24 stations of the CNNLSTM-Att ntion model exceeded 0.8, and the forecasted valu s ar highly correlated wit the measured values. Table 3. The overall evaluation indexes of four models in 24 stations in the test set. Modes Evaluate Indexes RMSE (TECU) R2 MAE (TECU) NeQuick 3.59 0.81 2.60 LSTM 2.25 0.85 1.53 CNN-LSTM 2.07 0.87 1.36 CNN-LSTM-Attention"
        },
        {
            "heading": "1.87 0.90 1.17",
            "text": "Figure 7 shows the single-day RMSE box plots for the 12 GNSS stations. The RMSE\nbox plots for the other 12 stations are shown in Figure A2. Each box represents the 365\nRMSEs of a single model throughout the year, in which the red plus sign is an outlier. The top and bottom black bars represent the maximum and minimum values of the 365-day data, respectively. The upper and lower edges of the blue box represent the upper quartile and the lower quartile, respectively. Moreover, the middle red bar represents the median. Comparing the four boxes, it can be observed that the model proposed in this paper performs well in terms of prediction, and the maximum and minimum RMSEs are significantly better than the NeQuick model, which is not significantly different from the performance of LSTM and CNN-LSTM. In terms of median, the performance of the model in this paper is better. GDZH, HISY, and KMIN stations are 2.91 TECU, 3.36 TECU, and 2.66 TECU, respectively. The median of the remaining nine stations is below 2 TECU, which may be due to the active ionosphere at low latitudes.\nFi re 6. Histogram for RMSE and R2 of NeQuick (blue), LSTM (yellow), CNN-LSTM (green), and CNN-LSTM-Attention (red) models from 12 stations in the test set. (a,b) are RMSE. (c,d) are R2.\nTable 3. The overall evaluation indexes of four models in 24 stations in the test set.\nModes Evaluate Indexes\nRMSE (TECU) R2 MAE (TECU)\nNeQuick 3.59 0.81 2.60 LSTM 2.25 0.85 1.53 CNN-LSTM 2.07 0.87 1.36 CNN-LST -Attention 1.87 0.90 1.17\nRemote Sens. 2022, 14, 2433 10 of 22\nFigure 7 shows the single-day RMSE box plots for the 12 GNSS stations. The RMSE box plots for the other 12 stations are shown in Figure A2. Each box represents the 365 RMSEs of a single model throughout the year, in which the red plus sign is an outlier. The top and bottom black bars represent the maximum and minimum values of the 365-day data, respectively. The upper and lower edges of the blue box represent the upper quartile and the lower quartile, respectively. Moreover, the middle red bar represents the median. Comparing the four boxes, it can be observed that the model proposed in this paper performs well in terms of prediction, and the maximum and minimum RMSEs are significantly better than the NeQuick model, which is not significantly different from the performance of LSTM and CNN-LSTM. In terms of median, the performance of the model in this paper is better. GDZH, HISY, and KMIN stations are 2.91 TECU, 3.36 TECU, and 2.66 TECU, respectively. The median of the remaining nine stations is below 2 TECU, which may be due to the active ionosphere at low latitudes. Remote Sens. 2022, 14, x FOR PEER REVIEW 11 of 23\nRemote Sens. 2022, 14, 2433 11 of 22"
        },
        {
            "heading": "4.2. Accuracy Assessment at Different Time Periods",
            "text": "Figure 8 shows the monthly changes of the forecast performance of the four prediction models in different months. The RMSE of the NeQuick model was 2.73, 2.18, 2.85, and 2.94 TECU in June, July, August, and December, respectively, and it was greater than 3 TECU in all other months. The LSTM and CNN-LSTM models perform well, with monthly average RMSE lower than 3 TECU and correlation coefficient higher than 0.8. As observed from the figure, the LSTM neural network model is unstable in some months. The RMSEs for June and July are 2.60 TECU and 2.41 TECU, respectively. The error for July is even higher than the empirical model. The performance of the CNN-LSTM-Attention model is stable, with an RMSE below 2.2 TECU and R2 above 0.84 in 12 months, which show good stability. Remote Sens. 2022, 14, x FOR PEER REVIEW 12 of 23 Figure 9 shows the average of the measured values of the 24 stations of the CMONOC and the forecasts of four models for 12 months. The predicted values of the NeQuick model in May, October, and November are quite different from the measured values, and the predicted values of the LSTM and CNN-LSTM models are closer to the measured values. The predicted values of the improved model in this paper are closest to the measured values.\nFigure 8. The RMSE and R2 of NeQuick (blue bars), LSTM (yellow bars), CNN-LSTM (green bars), and CNN-LSTM-Attention (red bars) models from 12 months in the test set. (a,b) are RMSE and R2, respectively.\nFigure 9. The forecasted averages of GNSS measured values (gray bars), NeQuick (blue bars), LSTM (yellow bars), CNN-LSTM (green bars), and CNN-LSTM-Attention (red bars) models from 12 months in the test set.\nFigure 10 shows the forecast RMSE for each model averaged across all of the stations for the year 2018, where the horizontal axis shows the start time for the forecast in UT. The NeQuick model has the largest RMSE when the forecast is made at 8 UT at 5.97 TECU. The maximum RMSE of the LSTM, CNN-LSTM, and CNN-LSTM-Attention models occurs when the forecast is made at 7 UT with an RMSE of 3.57 TECU, 3.46 TECU, and 3.09\nFigure 8. The R S a 2 f ic ( l rs), S (yellow bars), CNN-LSTM (gr en bars), and C - (re bars) models from 12 months in th est set. (a,b) are RMSE and R2, respectively.\nFigure 9 shows the average of the measured values of the 24 stations of the CMONOC and the forecasts of four models for 12 months. The predicted values of the NeQuick model in May, October, and November are quite different from the measured values, and the predicted values of the LSTM and CNN-LSTM models are closer to the measured values. The predicted values of the improved model in this paper are closest to the measured values. Figure 10 shows the forecast RMSE for each model averaged across all of the stations for the year 2018, where the horizontal axis shows the start time for the forecast in UT. The NeQuick model has the largest RMSE when the forecast is made at 8 UT at 5.97 TECU. The maximum RMSE of the LSTM, CNN-LSTM, and CNN-LSTM-Attention models occurs when the forecast is made at 7 UT with an RMSE of 3.57 TECU, 3.46 TECU, and 3.09 TECU, respectively. The daily ranges of RMSE for these four models are 4.39 TECU, 2.60 TECU, 2.48 TECU, and 2.29 TECU, respectively. The MAPE of the CNN-LSTM-Attention model fluctuates in the range of 12% to 21% in a day. There is no significant fluctuation in MAPE\nwhen RMSE reaches its maximum value, which indicates that the large forecasted error\nat 7 UT and 8 UT is due to the large influence of TEC values. The results indicate that the\nCNN-LSTM-Attention model exhibits the best performance for all forecast periods, and\nNeQuick exhibits the worst.\nRemote Sens. 2022, 14, 2433 12 of 22\nRemote Sens. 2022, 14, x FOR PEER REVIEW 12 of 23 Figure 9 shows the average of the measured values of the 24 stations of the CMONOC and the forecasts of four models for 12 months. The predicted values of the NeQuick model in May, October, and November are quite different from the measured values, and the predicted values of the LSTM and CNN-LSTM models are closer to the measured values. The predicted values of the improved model in this paper are closest to the measured values.\nFigure 9. The forecasted averages of GNSS measured values (gray bars), NeQuick (blue bars), LSTM (yellow bars), CNN-LSTM (green bars), and CNN-LSTM-Attention (red bars) models from 12 months in the test set.\nFigure 10 shows the forecast RMSE for each model averaged across all of the stations for the year 2018, where the horizontal axis shows the start time for the forecast in UT. The NeQuick model has the largest RMSE when the forecast is made at 8 UT at 5.97 TECU. The maximum RMSE of the LSTM, CNN-LSTM, and CNN-LSTM-Attention models occurs when the forecast is made at 7 UT with an RMSE of 3.57 TECU, 3.46 TECU, and 3.09\nFigure 9. The forecasted averages of GNSS measured values (gray bars), NeQuick (blue bars), LSTM (yellow bars), CNN-LSTM (green bars), and CNN-LSTM-Attention (red bars) models from 12 m nths in the te t set.\nerror at 7 UT and 8 UT is due to the large influence of TEC values. The results indicate\nthat the CNN-LSTM-Attention model exhibits the best performance for all forecast peri-\nods, and NeQuick exhibits the worst.\nFigure 10. The forecasted (a) RMSE and (b) MAPE for each model, averaged across all of the stations for the year 2018, where the horizontal axis shows the start time for the forecast in UT."
        },
        {
            "heading": "4.3. Accuracy Assessment under Different Geomagnetic Conditions",
            "text": "Geomagnetic activity is one of the main factors affecting the development of ionospheric disturbances [31]. During magnetic storms, the ionospheric TEC at low and middle latitudes shows an enhanced and positive perturbation response. This phenomenon gradually decreases in response intensity with decreasing latitude [32]. To study the prediction ability of the model in this paper under different geomagnetic activity, we divide the data into magnetic quiet days and magnetic storm days for comparative analysis. The magnetic quiet and magnetic storm days are classified according to the daily average of the Kp index. The Kp index is used as an indicator of geomagnetic activity. Kp index presents the index of 3 h ranges in magnetic activity relative to a quiet day. Thus, a higher Kp index means the geomagnetic is more active. Generally, Kp \u2265 3 can be considered as a magnetic storm day. To further verify the prediction performance of the model under different geomagnetic activities, the GDZH station is selected to analyze the accuracy and the forecasted performance of geomagnetic storms. The GDZH station is located in lowlatitude region, and TEC is closely affected by geomagnetic activity, which can well reflect the influence of geomagnetic activity on TEC."
        },
        {
            "heading": "4.3.1. Magnetic Quiet Period",
            "text": "Figure 11 shows the comparison between GNSS measured values and forecasted values of 12 stations on 21 August 2018. The comparison of the other 12 stations is shown in Figure A3. The Kp index on the day is 1.7, and geomagnetic activity is quiet. As observed from the figure, the maximum TEC of the day increases with the decrease in latitude, and there is a great difference between the predicted and measured values of the four stations north of 40\u00b0N using the four models. The predictions of the NeQuick model at some station maxima or minima are inaccurate. The performance of the CNN-LSTM-Attention model is good at 12 stations on the day. The predictions of CNN-LSTM-Attention model for nine stations, which are HLMH, NMDW, CHUN, BJFS, GDZH, LHAS, SCTQ, WUHN, and KMIN, are basically agreement with the observed values. It can accurately present the variation trend of TEC. In general, the forecasted values of the proposed model are consistent with the measured values of GNSS.\nFigure 10. e f recaste (a) S a ( ) f r eac el, a era e acr ss all f t e statio s for the year 2018, here the horizo tal axis s t t t ti ."
        },
        {
            "heading": "4.3. Accuracy Assessment under Different Geomagnetic Conditions",
            "text": "Geomagnetic activity is one of the main factors affecting the development of ionospheric disturbances [31]. During magnetic storms, the ionospheric TEC at low and middle latitudes shows an enhanced and positive perturbation response. This phenomenon gradually decreases in response intensity with decreasing latitude [32]. To study the prediction ability of the model in this paper under different geomagnetic activity, we divide the data into magnetic quiet days and magnetic storm days for comparative analysis. The magnetic quiet and magnetic storm days are classified according to the daily average of the Kp index. The Kp index is used as an indicator of geomagnetic activity. Kp index presents the index of 3 h ranges in magnetic activity relative to a quiet day. Thus, a higher Kp index means the geomagnetic is more active. Generally, Kp \u2265 3 can be considered as a magnetic storm day. To further verify the prediction performance of the model under different geomagnetic activities, the GDZH station is selected to analyze the accuracy and the forecasted performance of geomagnetic storms. The GDZH station is located in low-latitude region, and TEC is closely affected by geomagnetic activity, which can well reflect the influence of geomagnetic activity on TEC.\n4.3.1. Magnetic Quiet Period\nFigure 11 shows the comparison between GNSS measured values and forecasted values of 12 stations on 21 August 2018. The comparison of the other 12 stations is shown in Figure A3. The Kp index on the day is 1.7, and geomagnetic activity is quiet. As observed from the figure, the maximum TEC of the day increases with the decrease in latitude, and there is a great difference between the predicted and measured values of the four stations\nRemote Sens. 2022, 14, 2433 13 of 22\nnorth of 40\u25e6N using the four models. The predictions of the NeQuick model at some station maxima or minima are inaccurate. The performance of the CNN-LSTM-Attention model is good at 12 stations on the day. The predictions of CNN-LSTM-Attention model for nine stations, which are HLMH, NMDW, CHUN, BJFS, GDZH, LHAS, SCTQ, WUHN, and KMIN, are basically agreement with the observed values. It can accurately present the variation trend of TEC. In general, the forecasted values of the proposed model are consistent with the measured values of GNSS. Remote Sens. 2022, 14, x FOR PEER REVIEW 14 of 23\nFigure 11. (a\u2013l) Comparison of GNSS measured values (black solid line), NeQuick (blue dotted line), LSTM (yellow dotted line), CNN-LSTM (green dotted line), and CNN-LSTM-Attention (red solid line) models forecasted values for 12 stations on magnetic quiet day. The gray dotted line indicates midnight LT.\nFigure 12 shows the distribution of the residuals between the forecasted and measured values of the magnetic quiet period. In general, NeQuick, LSTM, CNN-LSTM, and CNN-LSTM-Attention models forecasted residuals are distributed in the range of \u201312 to 12 TECU. The prediction residual distribution of CNN-LSTM-Attention model is closer to an unbiased Gaussian distribution. The RMSEs of the four models are 4.14 TECU, 4.29 TECU, 4.14 TECU, and 3.99 TECU, respectively. The MAEs of the four models are 3.16 TECU, 3.00 TECU, 2.98 TECU, and 2.81 TECU, respectively. The NuQuick model has the largest MAE, and the CNN-LSTM-Attention model has the smallest RMSE and MAE.\nFigure 11. ( l) ri l , i ( l otte line), LST (yello dotted line), C - ( r tt li ), - - tt ti ( li\nline) models forecasted values for 12 stations on agnetic quiet day. The gray dotted line indicates midnight LT.\nFigure 12 shows the distribution of the residuals between the forecasted and measured values of the magnetic quiet period. In general, NeQuick, LSTM, CNN-LSTM, and CNNLSTM-Attention models forecasted residuals are distributed in the range of \u201312 to 12 TECU. The prediction resi ual distribution of CNN-LSTM-Attention model is closer to an unbiased Gaussian distribution. The RMSEs of the four models ar 4.14 TECU, 4.29 TECU, 4.14 TECU, and 3.99 TECU, respectively. The MAEs of the four models are 3.16 TECU, 3.00 TECU, 2.98 TECU, and 2.81 TECU, respectively. The NuQuick model has the largest MAE, and the CNN-LSTM-A tention model has he smallest RMSE and MAE.\nRemote Sens. 2022, 14, 2433 14 of 22e ote e s. , , x FOR PEER REVIEW 15 of 3"
        },
        {
            "heading": "4.3.2. Magnetic Storm Period",
            "text": "Figure 13 shows the comparison between GNSS measured values and TEC forecasted values of 12 stations on the magnetic storm day of 26 August 2018. The comparison of the other 12 stations is shown in Figure A4. Magnetic storms lead to drastic changes in TEC, and the forecasts of the four forecasting models at the maximum value are all inaccurate. This flaw is particularly evident in the NeQuick model. The LSTM, CNN-LSTM, and CNN-LSTM-Attention models can reflect the impact of magnetic storm on TEC to a certain extent because the geomagnetic indices are added as a training set. The CNN-LSTMAttention model captures the feature more obviously because of the attention mechanism. The predicted values are the closest to the measured value of GNSS.\ni re 12. esi al istrib tio of iffere t o els for statio duri agnetic quiet perio . i ; ; ; ) - -\ni l.\n4.3.2. Magnetic Storm Period\nFigure 13 shows the comparison between GNSS measured values and TEC forecasted values of 12 stations on the magnetic storm day of 26 August 2018. The comparison of the other 12 stations is shown in Figure A4. Magnetic storms lead to drastic changes in TEC, and the forecasts of the four forecasting models at the maximum value are all inaccurate. This flaw is particularly evident in the NeQuick model. The LSTM, CNN-LSTM, and CNN-LSTM-Attention models can reflect the impact of magnetic storm on TEC to a certain extent because the geomagnetic indices are added as a training set. The CNN-LSTMAttention model captures the feature more obviously because of the attention mechanism. The predicted values are the closest to the measured value of GNSS. Figure 14 shows the distribution of forecasted residuals of the four models during the magnetic storm period. Similarly to the magnetic quiet period, the NeQuick model has the largest residual. The LSTM model forecasted results with RMSE and MAE, and the results are 5.19 TECU and 3.76 TECU, respectively. The forecasted results of the CNNLSTM model and CNN-LSTM-Attention model include a mean distributed around 0, with RMSEs of 4.43 TECU and 4.11 TECU, respectively, and MAEs of 3.06 TECU and 2.81 TECU, respectively. From the error values, the performance of the model in this paper is better. Table 4 shows the percentage of residuals between the forecasted and measured values of the four models for the 24 stations in the test set. In the magnetic quiet period and the magnetic storm period, the prediction ratio of residual errors of the improved model in this paper is less than 1 TECU are 62% and 52%, respectively.\nRemote Sens. 2022, 14, 2433 15 of 22\nTable 4. Residual percentage statistics of 24 stations and 4 models in the test set.\nModes \u2206<1 1\u2264\u2206<2 2\u2264\u2206<3 3\u2264\u2206<4 \u2206>4\nQuiet\nNeQuick 27% 24% 19% 11% 19% LSTM 48% 28% 13% 5% 6%\nCNN-LSTM 53% 27% 11% 4% 5% CNN-LSTM-Attention 62% 24% 7% 3% 4%\nStorm\nNeQuick 25% 23% 19% 15% 18% LSTM 38% 27% 16% 8% 11%\nCNN-LSTM 45% 28% 12% 6% 9% CNN-LSTM-Attention 52% 26% 11% 5% 6% Remote Sens. 2022, 14, x FOR PEER REVIEW 16 of 23\nFigure 13. (a\u2013l) Comparison of GNSS measured values (black solid line), NeQuick (blue dotted line), LSTM (yellow dotted line), CNN-LSTM (green dotted line), and CNN-LSTM-Attention (red solid line) models forecasted values for 12 stations on magnetic storm day. The gray dotted line indicates midnight LT.\nFigure 14 shows the distribution of forecasted residuals of the four models during the magnetic storm period. Similarly to the magnetic quiet period, the NeQuick model has the largest residual. The LSTM model forecasted results with RMSE and MAE, and the results are 5.19 TECU and 3.76 TECU, respectively. The forecasted results of the CNNLSTM model and CNN-LSTM-Attention model include a mean distributed around 0, with RMSEs of 4.43 TECU and 4.11 TECU, respectively, and MAEs of 3.06 TECU and 2.81 TECU, respectively. From the error values, the performance of the model in this paper is better.\nFigure 13. (a\u2013l) o parison of SS easured values (black solid line), NeQuick (blue dotted line), ( ll l - ttention (red solid\nli e) l l i i . r tte line indicates idnight LT.\nRemote Sens. 2022, 14, 2433 16 of 22 Remote Sens. 2022, 14, x FOR PEER REVIEW 17 of 23\nFigure 14. Residual distribution of different models for GDZH station during magnetic storm period. RMSE, MAE, and ME are also included. (a) NeQuick; (b) LSTM; (c) CNN-LSTM; (d) CNNLSTM-Attention model.\nTable 4 shows the percentage of residuals between the forecasted and measured values of the four models for the 24 stations in the test set. In the magnetic quiet period and the magnetic storm period, the prediction ratio of residual errors of the improved model in this paper is less than 1 TECU are 62% and 52%, respectively.\nTable 4. Residual percentage statistics of 24 stations and 4 models in the test set.\nModes \u0394 \uff1c 1 1 \u2264 \u0394 \uff1c 2 2 \u2264 \u0394 \uff1c 3 3 \u2264 \u0394 \uff1c 4 \u0394 \uff1e 4\nQuiet\nNeQuick 27% 24% 19% 11% 19% LSTM 48% 28% 13% 5% 6%\nCNN-LSTM 53% 27% 11% 4% 5% CNN-LSTM-Attention 62% 24% 7% 3% 4%\nStorm\nNeQuick 25% 23% 19% 15% 18% LSTM 38% 27% 16% 8% 11%\nCNN-LSTM 45% 28% 12% 6% 9% CNN-LSTM-Attention 52% 26% 11% 5% 6%"
        },
        {
            "heading": "5. Discussion",
            "text": "Deep learning approach has the possibility to find nonlinear functions to forecast their manifestation in the ionosphere. In this paper, a CNN-LSTM neural network model integrating attention mechanism was developed for ionospheric TEC prediction. The evaluation was carried out by using the observation data of 24 GNSS stations from the CMONOC. The observation data from 2010 to 2017 and the five parameters of Bz, Kp, Dst, F10.7, and daily hours were used as the training set. The 2018 data were used as the test set to verify the model\u2019s performance. We compare the CNN-LSTM-Attention model with NeQuick, LSTM, and CNN-LSTM models to analyze the model\u2019s forecasting performance\nFigure 14. Residual distribution of different models for GDZH station during magnetic storm period. RMSE, MAE, and ME are also included. (a) NeQuick; (b) LSTM; (c) CNN-LSTM; (d) CNN-LSTMAttention model."
        },
        {
            "heading": "5. Discussion",
            "text": "Deep learning approach has the possibility to find nonlinear functions to forecast their manifestation in the ionosphere. In this paper, a CNN-LSTM neural network model\nintegrating attention mechanism was eveloped for ionospheric TEC prediction. The\nevaluation was carried out by using the observation data of 24 GNSS stations from the CMONOC. The observation data from 2010 to 2017 and the five parameters of Bz, Kp, Dst, F10.7, and daily hours were used as the training set. The 2018 data were used as the test set to verify the model\u2019s performance. We compare the CNN-LSTM-Attention model with NeQuick, LSTM, and CNN-LSTM models to analyze the model\u2019s forecasting performance under different conditions. With the decrease in latitude, the forecasted error of the CNN-LSTM-Attention model gradually increases from 1 TECU to 4 TECU. In general, the forecasted errors at the same latitude are the same, which are much lower than that of the empirical model. The monthly average value of TEC increases gradually from January to April, reaches a peak in April, and then gradually decreases. However, the prediction error of the model in t is paper does not increase with the i creas in monthly average, and it is generally stable at 1.5\u20132.2 TECU. This shows that the CNN-LSTM-Attention model is stable at different times. Under different geomagnetic activities, the NeQuick model has RMSEs of 2.88 and 4.62 TECU with correlation coefficie ts of 0.83 an 0.90 d ring magnetic quiet and magnetic stor periods, respectively. The predicted and measured RMSEs for the magnetic quiet and magnetic storm periods are 1.92 and 3.97 TECU, respectively, which are 33.33% and 14.07% lower than those of the empirical model. The correlation coefficients of magnetic quiet and storm periods both are 0.92, which improve 10.84% and 2.22% compared with the empirical model, and the forecasted values are highly correlated with the measured values. The RMSE for the storm period is up to two times higher than for the quiet period. Ensemble learning methods achieve better accuracy than a single learning method, where combining multiple ensembles provides the most optimal results."
        },
        {
            "heading": "6. Conclusions",
            "text": "In this study, an ionospheric forecast model in China is established based on 24 GNSS stations from CMONOC. Compared with empirical models, deep learning model have\nRemote Sens. 2022, 14, 2433 17 of 22\nhigher prediction accuracy, especially during magnetic storms. In this paper, the attention mechanism is added to the LSTM neural network, which inherits the high precision of the deep learning model and effectively improves stability. It shows good performance in different time periods throughout a year in China. The RSME of the CNN-LSTM-Attention model test set for the entire year is 1.87 TECU. As a comparison, the RMSEs of the NeQuick, LSTM, and CNN-LSTM models are 3.59, 2.25, and 2.07 TECU, respectively. The proposed model performs well in both in quiet periods and storm periods of geomagnetic activity. During the quiet period and storm period, the percentages of forecasted residuals greater than 4 TECU are only 4% and 6%, and the percentages of residuals greater than 4 TECU for the NeQuick model are 19% and 18%. However, the time period selected (2010\u20132018) is limited by the availability of data from the network. Currently, it should be noted that our experiments only discuss a relatively quiet solar period. We acknowledge the increasing solar activity levels and suggest that measurements in the coming years, where activity is expected to be much stronger, will provide a good opportunity for continued model development.\nAuthor Contributions: J.T. and Y.L. designed and performed the experiment; J.T. and Y.L. wrote the paper; M.D. and H.L. analyzed the data; D.Y. drew some of the figures; J.T. and X.W. revised the paper. All authors have read and agreed to the published version of the manuscript.\nFunding: This research is supported by the National Key Research & Development Program (No. 2017YFE0131400), the Key Laboratory for Digital Land and Resources of Jiangxi Province, East China University of Technology (No. DLLJ202104), the National Natural Science Foundation of China (No. 42074045), and the National Natural Science Foundation of China (No. 41761089).\nData Availability Statement: OMNI data are obtained from the GSFC/SPDF OMNIWeb interface (http://omniweb.gsfc.nasa.gov, accessed on 6 January 2022). NeQuick data are from the Abdus Salam International Centre for Theoretical Physics (ICTP) (https://t-ict4d.ictp.it/nequick2, accessed on 6 January 2022).\nAcknowledgments: The authors acknowledge the Crustal Movement Observation Network of China (CMONOC) for providing GNSS data, the OMNIWeb for providing OMNI data, and the Abdus Salam International Centre for Theoretical Physics (ICTP) for providing NeQuick data. They would also like to thank the anonymous reviewers for their constructive comments in improving the article.\nConflicts of Interest: The authors declare conflict of interest.\nAppendix A\nRemote Sens. 2022, 14, x FOR PEER REVIEW 19 of 23\nCo flicts of Interest: The authors declare conflict of interest."
        },
        {
            "heading": "Appendix A",
            "text": "Figure A1. Histogram for RMSE and R2 of NeQuick (blue), LSTM (yellow), CNN-LSTM (green), and CNN-LSTM-Attention (red) models from other 12 GNSS stations. (a,b) are RMSE. (c,d) are R2. Figure A1. Histogram for RMSE and R2 of NeQuick (blue), LSTM (yellow), CNN-LSTM (green), and CNN-LSTM-Attention (red) models from other 12 GNSS stations. (a,b) are RMSE. (c,d) are R2.\nRemote Sens. 2022, 14, 2433 18 of 22 Remote Sens. 2022, 14, x FOR PEER REVIEW 20 of 23\nFigure A2. (a\u2013l) The RMSE of NeQuick, LSTM, CNN-LSTM, and CNN-LSTM-Attention models from other 12 GNSS stations. The top and bottom black bars represent the maximum and minimum values, respectively. The upper and lower edges of the blue box represent the upper quartile and the lower quartile, respectively. The middle red bar represents the median, and the red plus sign represents the outlier. Figure A2. (a\u2013l) The RMSE of NeQuick, LST , CNN-LSTM, and CNN-LSTM-Attention models from other 12 GNSS stations. The top and bottom black bars represent the maximum and minimum values, respectively. The upper and lower edges of the blue box represent the upper quartile and the lower quartile, respectively. The middle red bar represents the median, and the red plus sign represents the outlier.\nRemote Sens. 2022, 14, 2433 19 of 22 Remote Sens. 2022, 14, x FOR PEER REVIEW 21 of 23\nFigure A3. (a\u2013l) Comparison of GNSS measured values (black solid line), NeQuick (blue dotted line), LSTM (yellow dotted line), CNN-LSTM (green dotted line), and CNN-LSTM-Attention (red solid line) models forecasted values for other 12 GNSS stations on magnetic quiet days. The gray dotted line indicates midnight LT. Figure A3. (a\u2013l) Comparison of GNSS measured values (black solid line), NeQuick (blue dotted line), LSTM (yellow dotted line), CNN-LSTM (green dotted line), and CNN-LSTM-Attention (red solid line) models forecasted values for other 12 GNSS stations on magnetic quiet days. The gray dotted line indicates midnight LT.\nRemote Sens. 2022, 14, 2433 20 of 22 Remote Sens. 2022, 14, x FOR PEER REVIEW 22 of 23\nFigure A4. (a\u2013l) Comparison of GNSS measured values (black solid line), NeQuick (blue dotted line), LSTM (yellow dotted line), CNN-LSTM (green dotted line), and CNN-LSTM-Attention (red solid line) models forecasted values for other 12 GNSS stations on magnetic storm day. The gray dotted line indicates midnight LT.\nReferences 1. Themens, D.R.; Reid, B.; Jayachandran, P.T.; Larson, B.; Koustov, A.V.; Elvidge, S.; McCaffrey, A.M.; Watson, C. E-CHAIM as a\nmodel of total electron content: Performance and diagnostics. Space Weather 2021, 19. e2021SW002872. https://doi.org/10.1029/2021sw002872.\n2. Francis, N.M.; Cannon, P.S.; Brown, A.G.; Broomhead, D.S. Nonlinear prediction of the ionospheric parameter foF2 on hourly, daily, and monthly timescales. J. Geophys. Res. 2000, 105, 12839\u201312849. https://doi.org/10.1029/2000ja900005.\n3. Francis, N.M.; Brown, A.G.; Cannon, P.S.; Broomhead, D.S. Prediction of the hourly ionospheric parameter foF2 using a novel nonlinear interpolation technique to cope with missing data points. J. Geophys. Res. 2001, 106, 30077\u201330083. https://doi.org/10.1029/2000ja002227.\n4. Tulunay, E.; Senalp, E.T.; Radicella, S.M.; Tulunay, Y. Forecasting total electron content maps by neural network technique. Radio Sci. 2006, 41, RS4016. https://doi.org/10.1029/2005rs003285.\n5. Habarulema, J.B.; McKinnell, L.A.; Opperman, B.D. Towards a GPS-based TEC prediction model for Southern Africa with feed forward networks. Adv. Space Res. 2009, 44, 82\u201392. https://doi.org/10.1016/j.asr.2009.02.016.\n6. Habarulema, J.B.; McKinnell, L.-A.; Opperman, B.D.L. Regional GPS TEC modeling; Attempted spatial and temporal extrapolation of TEC using neural networks. J. Geophys. Res. 2011, 116, A04314. https://doi.org/10.1029/2010ja016269.\nFigure A4. (a\u2013l) Comparison of GNSS measured values (black solid line), NeQuick (blue dotted line), LSTM (yellow dotted line), CNN-LSTM (green dotted line), and CNN-LSTM-Attention (red solid line) models forecasted values for other 12 GNSS stations on magnetic storm day. The gray dotted line indicates midnight LT.\nReferences 1. Themens, D.R.; Reid, B.; Jayachandran, P.T.; Larson, B.; Koustov, A.V.; Elvidge, S.; McCaffrey, A.M.; Watson, C. E-CHAIM as a model of total electron content: Performance and diagnostics. Space Weather 2021, 19, e2021SW002872. [CrossRef] 2. Fra cis, N.M.; Cannon, P.S.; Brown, A.G.; Broomhead, D.S. Nonlinear prediction of the ionospheric parameter foF2 on hourly,\ndaily, and monthly timescales. J. Geophys. Res. 2000, 105, 12839\u201312849. [CrossRef]\nRemote Sens. 2022, 14, 2433 21 of 22\n3. Francis, N.M.; Brown, A.G.; Cannon, P.S.; Broomhead, D.S. Prediction of the hourly ionospheric parameter foF2 using a novel nonlinear interpolation technique to cope with missing data points. J. Geophys. Res. 2001, 106, 30077\u201330083. [CrossRef] 4. Tulunay, E.; Senalp, E.T.; Radicella, S.M.; Tulunay, Y. Forecasting total electron content maps by neural network technique. Radio Sci. 2006, 41, RS4016. [CrossRef] 5. Habarulema, J.B.; McKinnell, L.A.; Opperman, B.D. Towards a GPS-based TEC prediction model for Southern Africa with feed forward networks. Adv. Space Res. 2009, 44, 82\u201392. [CrossRef] 6. Habarulema, J.B.; McKinnell, L.-A.; Opperman, B.D.L. Regional GPS TEC modeling; Attempted spatial and temporal extrapolation of TEC using neural networks. J. Geophys. Res. 2011, 116, A04314. [CrossRef] 7. Huang, L.; Wang, J.; Jiang, Y.; Huang, J.; Chen, Z.; Zhao, K. A preliminary study of the single crest phenomenon in total electron content (TEC) in the equatorial anomaly region around 120\u25e6E longitude between 1999 and 2012. Adv. Space Res. 2014, 54, 2200\u20132207. [CrossRef] 8. Ferreira, A.A.; Borges, R.A.; Paparini, C.; Ciraolo, L.; Radicella, S.M. Short-term estimation of GNSS TEC using a neural network model in Brazil. Adv. Space Res. 2017, 60, 1765\u20131776. [CrossRef] 9. Bai, H.; Fu, H.; Wang, J.; Ma, K.; Wu, T.; Ma, J. A prediction model of ionospheric foF2 based on extreme learning machine. Radio Sci. 2018, 53, 1292\u20131301. [CrossRef] 10. Lee, S.; Ji, E.; Moon, Y.; Park, E. One-Day Forecasting of global TEC using a novel deep learning model. Space Weather 2021, 19, e2020SW002600. [CrossRef] 11. Wang, J.; Feng, F.; Ma, J. An adaptive forecasting method for ionospheric critical frequency of F2 layer. Radio Sci. 2020, 55, e2019RS007001. [CrossRef] 12. Adolfs, M.; Hoque, M.M. A neural network-based TEC model capable of reproducing nighttime winter anomaly. Remote Sens. 2021, 13, 4559. [CrossRef] 13. Razin, M.R.G.; Moradi, A.R.; Inyurt, S. Spatio-temporal analysis of TEC during solar activity periods using support vector machine. GPS Solut. 2021, 25, 121. [CrossRef] 14. Gampala, S.; Devanaboyina, V.R. Application of SST to forecast ionospheric delays using GPS observations. IET Radar Sonar Navig. 2017, 11, 1070\u20131080. [CrossRef] 15. Dabbakuti, J.R.K.K.; Peesapati, R.; Yarrakula, M.; Anumandla, K.K.; Madduri, S.V. Implementation of storm-time ionospheric forecasting algorithm using SSA\u2013ANN model. IET Radar Sonar Navig. 2020, 14, 1249\u20131255. [CrossRef] 16. Dabbakuti, J.R.K.K.; Jacob, A.; Veeravalli, V.R.; Kallakunta, R.K. Implementation of IoT analytics ionospheric forecasting system based on machine learning and ThingSpeak. IET Radar Sonar Navig. 2020, 14, 341\u2013347. [CrossRef] 17. Ruwali, A.; Kumar, A.J.S.; Prakash, K.B.; Sivavaraprasad, G.; Ratnam, D.V. Implementation of hybrid deep learning model (LSTM-CNN) for ionospheric TEC forecasting using GPS data. IEEE Geosci. Remote Sens. Lett. 2020, 18, 1004\u20131008. [CrossRef] 18. Xiong, P.; Zhai, D.; Long, C.; Zhou, H.; Zhang, X.; Shen, X. Long short-term memory neural network for ionospheric total electron content forecasting over China. Space Weather 2021, 19, e2020SW002706. [CrossRef] 19. Kim, J.; Kwak, Y.; Kim, Y.; Moon, S.; Jeong, S.; Yun, J. Potential of regional ionosphere prediction using a long short-term memory deep-learning algorithm specialized for geomagnetic storm period. Space Weather 2021, 19, e2021SW002741. [CrossRef] 20. Zewdie, G.K.; Valladares, C.; Cohen, M.B.; Lary, D.J.; Ramani, D.; Tsidu, G.M. Data-driven forecasting of low-latitude ionospheric total electron content using the random forest and LSTM machine learning methods. Space Weather 2021, 19, e2020SW002639. [CrossRef] 21. Chen, Z.; Liao, W.; Li, H.; Wang, J.; Deng, X.; Hong, S. Prediction of global ionospheric TEC based on deep learning. Space Weather 2022, 20, e2021SW002854. [CrossRef] 22. Liu, Y.; Zhang, Q.; Song, L.; Chen, Y. Attention-based recurrent neural networks for accurate short-term and long-term dissolved oxygen prediction. Comput. Electron. Agric. 2019, 165, 104964. [CrossRef] 23. Zhang, B.; Ou, J.; Yuan, Y.; Li, Z. Extraction of line-of-sight ionospheric observables from GPS data using precise point positioning. Sci. China Earth Sci. 2012, 55, 1919\u20131928. [CrossRef] 24. Gu, J.; Wang, Z.; Kuen, J.; Ma, L.; Shahroudy, A.; Shuai, B.; Liu, T.; Wang, X.; Wang, G.; Cai, J.; et al. Recent advances in convolutional neural networks. Pattern Recognit. 2018, 77, 354\u2013377. [CrossRef] 25. Gers, F.A.; Schmidhuber, J.; Cummins, F. Learning to forget: Continual prediction with LSTM. Neural Comput. 2000, 12, 2451\u20132471. [CrossRef] [PubMed] 26. Bahdanau, D.; Cho, K.; Bengio, Y. Neural machine translation by jointly learning to align and translate. Comput. Sci. 2016. Available online: https://arxiv.org/abs/1409.0473 (accessed on 18 January 2022). 27. Kingma, D.P.; Ba, J. Adam: A method for stochastic optimization. Comput. Sci. 2014. Available online: https://arxiv.org/abs/14 12.6980 (accessed on 18 January 2022). 28. Nava, B.; Co\u00efsson, P.; Radicella, S. A new version of the NeQuick ionosphere electron density model. J. Atmos. Sol. Terr. Phys. 2008, 70, 1856\u20131862. [CrossRef] 29. Wen, Z.; Li, S.; Li, L.; Wu, B.; Fu, J. Ionospheric TEC prediction using long short-term memory deep learning network. Astrophys. Space Sci. 2021, 366, 3. [CrossRef] 30. Song, R.; Zhang, X.; Zhou, C.; Liu, J.; He, J. Predicting TEC in China based on the neural networks optimized by genetic algorithm. Adv. Space Res. 2018, 62, 745\u2013759. [CrossRef]\nRemote Sens. 2022, 14, 2433 22 of 22\n31. Galav, P.; Rao, S.S.; Sharma, S.; Gordiyenko, G.; Pandey, R. Ionospheric response to the geomagnetic storm of 15 May 2005 over midlatitudes in the day and night sectors simultaneously. J. Geophys. Res. Space Phys. 2014, 119, 5020\u20135031. [CrossRef] 32. Tang, J.; Gao, X.; Li, Y.; Zhong, Z. Study of ionospheric responses over China during September 7\u20138, 2017 using GPS, Beidou (GEO), and Swarm satellite observations. GPS Solut. 2022, 26, 55. [CrossRef]"
        }
    ],
    "title": "An Ionospheric TEC Forecasting Model Based on a CNN-LSTM-Attention Mechanism Neural Network",
    "year": 2022
}