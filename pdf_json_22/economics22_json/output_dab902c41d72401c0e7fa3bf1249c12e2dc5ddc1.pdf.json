{
    "abstractText": "We consider a multi-period stochastic control problem where the multivariate driving stochastic factor of the system has known marginal distributions but uncertain dependence structure. To solve the problem, we propose to implement the nonparametric adaptive robust control framework. We aim to find the optimal control against the worst-case copulae in a sequence of shrinking uncertainty sets which are generated from continuously observing the data. Then, we use a stochastic gradient descent ascent algorithm to numerically handle the corresponding high dimensional dynamic inf-sup optimization problem. We present the numerical results in the context of utility maximization and show that the controller benefits from knowing more information about the uncertain model.",
    "authors": [
        {
            "affiliations": [],
            "name": "Erhan Bayraktar"
        },
        {
            "affiliations": [],
            "name": "Tao Chen"
        }
    ],
    "id": "SP:324f23138f97ff1da1e8a145c6e1b8302629a872",
    "references": [
        {
            "authors": [
                "T. Bhudisaksang",
                "A. Cartea"
            ],
            "title": "Online drift estimation for jump-diffusion processes",
            "venue": "Bernoulli - Journal of the Bernoulli Society,",
            "year": 2021
        },
        {
            "authors": [
                "E. Bayraktar",
                "T. Chen"
            ],
            "title": "Nonparametric adaptive robust control under model uncertainty",
            "year": 2022
        },
        {
            "authors": [
                "T. Bielecki",
                "T. Chen",
                "I. Cialenco"
            ],
            "title": "Recursive construction of confidence regions",
            "venue": "Electron. J. Statist.,",
            "year": 2017
        },
        {
            "authors": [
                "T.R. Bielecki",
                "T. Chen",
                "I. Cialenco"
            ],
            "title": "Time-inconsistent markovian control problems under model uncertainty with application to the mean-variance portfolio selection",
            "venue": "Submitted for publication,",
            "year": 2020
        },
        {
            "authors": [
                "D.P. Bertsekas",
                "S. Shreve"
            ],
            "title": "Stochastic Optimal Control: The Discrete-Time Case",
            "year": 1978
        },
        {
            "authors": [
                "H.F. Chen",
                "L. Guo"
            ],
            "title": "Identification and stochastic adaptive control",
            "venue": "Systems & Control: Foundations & Applications. Birkha\u0308user Boston, Inc.,",
            "year": 1991
        },
        {
            "authors": [
                "T. Chen",
                "M. Ludkovski"
            ],
            "title": "A machine learning approach to adaptive robust utility maximization and hedging",
            "venue": "SIAM Journal on Financial Mathematics,",
            "year": 2021
        },
        {
            "authors": [
                "T. Chen",
                "J. Myung"
            ],
            "title": "Nonparametric adaptive bayesian stochastic control under model uncertainty",
            "year": 2020
        },
        {
            "authors": [
                "E. Del Barrio",
                "E. Gin\u00e9",
                "C. Matr\u00e1n"
            ],
            "title": "Central limit theorems for the wasserstein distance between the empirical andthe true distributions",
            "venue": "The Annals of Probability,",
            "year": 1999
        },
        {
            "authors": [
                "P.M. Esfahani",
                "D. Kuhn"
            ],
            "title": "Data-driven distributionally robust optimization using the wasserstein metric: Performance guarantees and tractable reformulations",
            "venue": "Mathematical Programming,",
            "year": 2018
        },
        {
            "authors": [
                "N. Fournier",
                "A. Guillin"
            ],
            "title": "On the rate of convergence in wasserstein distance of the empirical measure",
            "venue": "Probability Theory and Related Fields,",
            "year": 2015
        },
        {
            "authors": [
                "R. Gao",
                "A. Kleywegt"
            ],
            "title": "Data-driven robust optimization with known marginal distributions",
            "venue": "Technical Report. Georgia Institute of Technology,",
            "year": 2017
        },
        {
            "authors": [
                "I. Gilboa",
                "D. Schmeidler"
            ],
            "title": "Maxmin expected utility with nonunique prior",
            "venue": "J. Math. Econom.,",
            "year": 1989
        },
        {
            "authors": [
                "P.R. Kumar",
                "P. Varaiya"
            ],
            "title": "Stochastic Systems: Estimation, Identification, and Adaptive Control",
            "year": 2015
        },
        {
            "authors": [
                "U. Rieder"
            ],
            "title": "Bayesian dynamic programming",
            "venue": "Adv. Appl. Prob.,",
            "year": 1975
        },
        {
            "authors": [
                "C.E. Rasmussen",
                "C.K.I. Williams"
            ],
            "title": "Gaussian Processes for Machine Learning",
            "year": 2006
        }
    ],
    "sections": [
        {
            "text": "Keywords: nonparametric adaptive robust control, model uncertainty, stochastic control, adaptive robust dynamic programming, Wasserstein distance, Markovian control problem, utility maximization, copula, machine learning, stochastic gradient descent ascent. MSC2010: 49L20, 49J55, 93E20, 93E35, 60G15, 65K05, 90C39, 90C40, 91G10, 91G60, 62G05"
        },
        {
            "heading": "1 Introduction",
            "text": "In this paper we propose a nonparametric approach for solving a stochastic Markovian control problem in discrete time under a special type of uncertainty. We assume that the multivariate driving random factor of the underlying stochastic process has known marginals and unknown dependence. Naturally, to deal with such kind of uncertainty, one can choose a parametric family of copula functions and learn the unknown parameter from the observed data. In this work, we avoid making such postulation to prevent model misspecification. When it comes to handling model uncertainty, there are different approaches, parametric and nonparametric, developed in the past decades to incorporate learning into solving control problems with unknown system models (cf. [KV15], [CG91], [Rie75], [CM20]). However, earlier studies show that a pure learning approach without awareness of the model risk is prone to risk caused by estimation error and often leads to overly aggressive controls and system outcomes with high variances. On the other hand, the central idea of robust control goes back to [GS89]. A large body of research have been devoted to this area since then, and produced fruitful results. Robust techniques are extremely successful in dealing with model risk but if the learning phase is lacking in the framework, corresponding controls can be overly conservative and even trivial. Our work aims to address all the issues mentioned above when handling dependence uncertainty through applying the nonparametric adaptive robust\n\u2217E. Bayraktar is partially supported by the National Science Foundation under grant DMS-2106556 and by the Susan M. Smith chair.\nDepartment of Mathematics, University of Michigan, Ann Arbor 530 Church Street, Ann Arbor, MI 48109, USA Email: erhan@umich.edu, URL: https://sites.lsa.umich.edu/erhan/\n\u2020\nEmail: chenta@umich.edu, URL: http://taochen.im\nar X\niv :2\n20 9.\n04 97\n6v 1\n[ m\nat h.\nO C\n] 1\n2 Se\np 20\n22\nmethodology proposed in [BC22] and developing an efficient numerical scheme for implementing such method. The main idea of adaptive robust control is to consider a specific type of sequential games: the controller first constructs a sequence of uncertainty sets by continuously observing the system data; then, at each time step the nature chooses one model from the time-t uncertainty set that is the worst for the controller; finally, the controller will apply an optimal control in response, and both players (the controller and the nature) repeat the same process at latter time steps. Note that such framework is data-driven and the learning phase is integrated into the optimization phase. Regarding constructing the desired uncertainty sets, we refer to [BCC17] and [BC21] for the parametric case in discrete time and continuous time, respectively. Discussion of constructing time dependent uncertainty sets in discrete time in the nonparametric case can be found in our earlier work [BC22]. In summary, to deal with the dependence uncertainty, we use the method described in the aforementioned papers to build uncertainty sets in terms of the Wasserstein ball centered at the nonparametric estimators of the copula by utilizing the concentration results for the empirical distribution and the Wasserstein distance (cf. [DBGM99], [FG15]), and formulate the corresponding robust control problem. Practically, numerical search of the worst-case copula in a Wasserstein ball is extremely difficult. One can utilize the results presented in [GK17] to obtain a duality result for solving the relevant inf-sup optimization problem. However, as we will see in the sequel, the Bellman equation derived in this framework has unavoidable high dimension. Thus, solving such optimization problem using brute force is virtually impossible. Towards this end, we design a stochastic gradient descent ascent algorithm to mitigate the computational burden. On top of that, we use the Gaussian process regression model to approximate the corresponding value function. The gradient of such approximation can be explicitly computed, and this fact increases the numerical efficiency in the dynamic programming backward recursion.\nThe rest of the paper is organized as follows. We begin Section 2 with setting up the model and then discuss the stochastic process that represents the learning of the unknown dependence, and the construction of the uncertainty sets which contain all the considered copulae at different time steps. Section 3 is dedicated to the formulation of the nonparametric adaptive robust control framework. We investigate the solution of the nonparametric adaptive robust control problem in Section 4. In this section, we prove the Bellman principle of optimality for the problem and show the existence of measurable worst-case model selector as well as the existence of measurable optimal control. We also discuss the comparison among several different methods that can be used to handle the stochastic control problem under dependence uncertainty. Finally, in Section 5 we consider an illustrative example. Namely, the uncertain utility maximization problem where the investor needs to allocate the wealth among the money market account and several risky assets without knowing the true dependence of return processes of the risky assets. We apply the nonparametric adaptive robust control approach to such problem and provide a numerical solver by using machine learning techniques such as stochastic gradient descent ascent and the Gaussian process. Numerical results presented in this section show that knowing more about the distribution of the underlying stochastic process leads to optimal trading strategy that is more balanced between profit seeking and risk aversion."
        },
        {
            "heading": "2 Nonparametric Adaptive Robust Control Problem Subject to",
            "text": "Dependence Uncertainty\nLet (\u2126,F ) be a measurable space, and T \u2208 N be a fixed time horizon. Let T = {0, 1, 2, . . . , T}, T \u2032 = {0, 1, 2, . . . , T \u2212 1}, and T \u2032\u2032 = {1, 2, . . . , T}. On the space (\u2126,F ) we consider a controlled\nstochastic process X = {Xt, t \u2208 T } taking values in Rd with dynamics\nXt+1 = S(t,Xt, \u03d5t, Zt+1), t \u2208 T \u2032. (2.1)\nThe above Zt = (Z (1) t , . . . , Z (n) t ), t \u2208 T \u2032\u2032, is an n-dimensional i.i.d. sequence adapted to the natural filtration of the process X which is denoted by F = {Ft, t \u2208 T }. The process \u03d5 = {\u03d5t, t \u2208 T \u2032} is also F-adapted and takes values in a compact subset A \u2282 Rm. For every t \u2208 T \u2032, the function S(t, \u00b7, \u00b7, \u00b7) : Rd\u00d7A\u00d7Rn \u2192 Rd is deterministic and continuous. In addition, we denote by At the set of all processes that take values in A and are adapted to the filtration Ft := {Fs, t \u2264 s \u2264 T \u2212 1}. Each element in At is called an admissible control starting at time t, and we use the convention A = A0. In this work, we assume that the process Z is observable, and for every fixed t \u2208 T \u2032\u2032, the marginal distributions of Zt are known to the controller, but the dependence structure among marginals is unknown and needs to be learned. We write P(Rn) as the set of all distributions on Rn. Finally, let ` : Rd \u2192 R be continuous, bounded from above, and playing the role of the loss function. In this work, denote by F\u2217 the true distribution of Zt, t \u2208 T \u2032\u2032, we will formulate and solve a robust optimization problem aiming to minimize the expected loss with the restriction that the worst-case distribution of Zt, t \u2208 T \u2032\u2032, matches the marginals of F\u2217. To proceed, we specify the following notations which will be used throughout.\n\u2022 For any z \u2208 Rn, z(i), i \u2208 N := {1, . . . , n}, is the ith component of z.\n\u2022 For any CDF F of a n-dimensional random variable, F (i), i \u2208 N , is the ith marginal CDF.\n\u2022 For any CDF F of a n-dimensional random variable, F\u22121 = (F (1),\u22121, . . . , F (n),\u22121).\n\u2022 For any CDF F of a n-dimensional random variable and z \u2208 Rn,\nF \u25e6 z =(F (1)(z(1)), . . . , F (n)(z(n))), F\u22121 \u25e6 z =(F (1),\u22121(z(1)), . . . , F (n),\u22121(z(n))).\n\u2022 For any function f on Rn, and CDF F of a n-dimensional random variable,\nf \u25e6 F =f(F (1), . . . , F (n)), f \u25e6 F\u22121 =f(F (1),\u22121, . . . , F (n),\u22121).\nIn order to deal with the dependence uncertainty, we will take the copula perspective and note that\nF\u2217(z) = C\u2217\n( F (1) \u2217 ( z(1) ) , . . . , F (n) \u2217 ( z(n) )) , (2.2)\nwhere C\u2217 is the unknown true copula function of Zt. Here, we make a standing assumption that F (i) \u2217 , i \u2208 N , is continuous and strictly increasing. Consequently, the copula function C\u2217 is unique. In the sequel, we will write PF and EF as the probability measure and expectation, respectively, associated to the distribution function F .\nIn the first step, having in mind the possibility that the parametric family which C\u2217 belongs to could be unknown, we need to define an estimator for C\u2217 based on the observed data of Z in a nonparametric manner. There are essentially two different ways to achieve this. One is to use the up-to-time t information of Z to construct a multi-dimensional empirical distribution F\u0302t for F\u2217, and define an estimator of C\u2217 via (2.2). The other is to consider a kernel based estimator of F\u2217 which is a smoothed version of F\u0302t instead. One example in such family of methods is the so-called perturbed\nempirical distribution. Both approaches have their advantages: using the empirical distribution will simplify the numerical computation; while the kernel based method offers a better estimator that is more in line with the assumption that F (i) \u2217 , i \u2208 N , are continuous. To this end, with slight abuse of notations, we choose the avenue of the first method mentioned earlier and denote by F\u0302t the empirical distribution of F\u2217 based on information up to time t, where F\u03020 is constructed by observing historical data of Z with sample size t0. It is not hard to see that F\u0302t satisfies the following updating rule\nF\u0302t+1(z) = (t0 + t)F\u0302t(z) +\n\u220f i\u2208N 1Z(i)t+1\u2264z(i)\nt0 + t+ 1 , z \u2208 [0, 1]n. (2.3)\nNext, we define\nC\u0302t(u) = F\u0302t(F \u22121 \u2217 \u25e6 u), u \u2208 [0, 1]n, (2.4)\nand C\u0302t is an estimator of the copula C\u2217. Moreover, we have\nC\u0302t+1(u) = (t0 + t)C\u0302t(u) +\n\u220f i\u2208N 1[0,ui] ( F (i) \u2217 ( Z (i) t+1 )) t0 + t+ 1 =: R(t, C\u0302t, Zt+1), u \u2208 [0, 1]n. (2.5)\nRemark 2.1. We want to stress that even though F\u2217 is uncertain, but we assume that the marginals F (i) \u2217 , i \u2208 N , are known, and therefore due to our definition F\u22121\u2217 is also well-known to the controller.\nIn many works, regardless of knowing F (i) \u2217 , i \u2208 N , or not, the empirical copula is defined as C\u0302t(u) = F\u0302t(F\u0302 \u22121 t \u25e6u) which means using the empirical marginals instead of the true ones to construct the estimator for the copula. Note that in such construction, due to the discontinuity of F\u0302t, the resulting C\u0302t is not necessarily a copula. On the other hand, the estimator of C\u2217 defined in (2.4) is not a copula either. Hence, any application or computation purely based on either of these two estimators could be problematic. We argue that, for this reason, one should consider a robust framework to mitigate the inherent risk comes from the statistical estimation procedure.\nIn rest of the paper, we write\nF\u0302t+1(z) = (t0 + t)F\u0302t(z) +Ht+1(z \u2212 Zt+1)\nt0 + t+ 1 , z \u2208 Rn,\nwhere Ht is a sequence of continuous distribution function such that limt\u2192\u221eHt = 1[0,\u221e)n if t is allowed to go to infinity, or Ht \u2261 1[0,\u221e)n for any considered t. The former choice corresponds to constructing F\u0302 as the so-called perturbed empirical distribution and the latter is the case of choosing F\u0302 to be the regular empirical distribution. We will prove all the technical results for both choices as our theory works for either one of the two possible frameworks.\nTo proceed, we fix the notations F\u0302 and C\u0302 for estimators defined as in (2.3) and (2.4), and assume that, for any 0 \u2264 \u03b1 \u2264 1, there exists a deterministic function r(\u03b1, t0, t) decreasing in t \u2208 T \u2032 such that\nP(dW,p(C\u0302t, C\u2217) \u2264 r(\u03b1, t0, t)) \u2265 1\u2212 \u03b1, (2.6)\nwhere dW,p is the Wasserstein distance between distributions in P([0, 1]n) of order p \u2265 1. In application, regarding construction of r(\u03b1, t0, t), we will use the concentration results for the empirical distribution in [FG15, Theorem 2] by imposing necessary integrability assumptions on C\u2217. The take-away is that there exists some function r(\u03b1, t0, t) satisfying (2.6).\nNext, we model the uncertainty of C\u2217, by using (2.6), in terms of the confidence region as C\u03b1t (C\u0302t) = { C \u2208 P([0, 1]n) : dW,p(C\u0302t, C) \u2264 r(\u03b1, t0, t) } , (2.7)\nand we call C\u03b1t the uncertainty set of C\u2217. Since [0, 1]n is a compact subset of Rn, then dW,p is a metric on P([0, 1]n). Throughout, we consider the metric space (P([0, 1]n), dW,p). As mentioned earlier, we will adopt the adaptive robust control framework to our setup in this project. Hence, we are going to find the worst-case copula function in C\u03b1t and search for the optimal control in reaction to such worst-case copula. One needs to realize that C\u03b1t includes all types of distributions on [0, 1]n and in general these distributions do not necessarily have uniform marginals. In other words, not all C \u2208 C\u03b1t are copulae, and this issue will be addressed in the sequel.\nBefore we discuss and formulate the nonparametric adaptive robust control problem under dependence uncertainty, we first provide the following technical results for preparation.\nLemma 2.2. For fixed t \u2208 T \u2032, the mapping R(t, \u00b7, \u00b7) : P([0, 1]n)\u00d7 R\u2192 P([0, 1]n) is continuous.\nProof. We will prove the result for Ht, t \u2208 T \u2032, being continuous distribution functions. Regarding the case of Ht \u2261 1[0,\u221e), we refer the readers to [CM20] or Lemma 3.1 below.\nAssume that (Ci, zi) \u2192 (C, z), where Ci, C \u2208 P([0, 1]n), zi, z \u2208 R, i = 1, 2, . . .. Then, dW,p(Ci, C) \u2192 0 and zi \u2192 z. Denote \u00b5Ci,zi = R(t, Ci, zi) and \u00b5C,z = R(t, C, z), and M := {f : |f(z) \u2212 f(z\u2032)| \u2264 \u2016z \u2212 z\u2032\u2016, z, z\u2032 \u2208 [0, 1]n}. Note that [0, 1]n is compact, so for any p \u2265 1 there exists a constant bp such that dW,p(F,G) \u2264 bpdW,1(F,G) for any F,G \u2208 P([0, 1]n). Hence, we have that\ndW,p(\u00b5Ci,zi , \u00b5C,z) \u2264 bpdW,1(\u00b5Ci,zi , \u00b5C,z) = bp sup {\u222b [0,1]n fd\u00b5Ci,zi \u2212 \u222b [0,1]n fd\u00b5C,z : f \u2208M. } By the construction of the function R, we obtain\nsup {\u222b [0,1]n fd(\u00b5Ci,zi \u2212 \u00b5C,z) : f \u2208M. } = sup { t0 + t t0 + t+ 1 \u222b [0,1]n fd(Ci \u2212 C)\n+\n\u222b [0,1]n fd(Ht+1(F \u22121 \u2217 \u25e6 u\u2212 zi)\u2212Ht+1(F\u22121\u2217 \u25e6 u\u2212 z))\nt+ t0 + 1 : f \u2208M\n} .\nNote that\nHt+1(F \u22121 \u2217 \u25e6 u\u2212 zi) =P(H\u0303 \u2264 F\u22121\u2217 \u25e6 u\u2212 zi) =P (( F (1) \u2217 (H\u0303 (1) + z (1) i ), . . . , F (n) \u2217 (H\u0303 (n) + z (n) i ) \u2264 u ) ,\nwhere H\u0303 is a multi-dimensional random variable with distribution Ht+1. Then, we get that\nsup {\u222b [0,1]n fd(Ht+1(F \u22121 \u2217 \u25e6 u\u2212 zi)\u2212Ht+1(F\u22121\u2217 \u25e6 u\u2212 z)) : f \u2208M } = sup { E [ f ( F (1) \u2217 (H\u0303 (1) + z (1) i ), . . . , F (n) \u2217 (H\u0303 (n) + z (n) i\n)] \u2212 E [ f ( F (1) \u2217 (H\u0303 (1) + z(1)), . . . , F (n) \u2217 (H\u0303 (n) + z(n) )] : f \u2208M }\n\u2264E [\u2225\u2225\u2225(F (1)\u2217 (H\u0303(1) + z(1)i ), . . . , F (n)\u2217 (H\u0303(n) + z(n)i ))\u2212 (F (1)\u2217 (H\u0303(1) + z(1)), . . . , F (n)\u2217 (H\u0303(n) + z(n)))\u2225\u2225\u2225].\nSince F j\u2217 , j \u2208 N , are all bounded continuous functions, thus by dominated convergence theorem,\nsup\n{\u222b [0,1]n fd(Ht+1(F \u22121 \u2217 \u25e6 u\u2212 zi)\u2212Ht+1(F\u22121\u2217 \u25e6 u\u2212 z))\nt+ t0 + 1 : f \u2208M\n} \u2192 0\nas zi \u2192 z. On the other hand,\nsup\n{ t0 + t\nt0 + t+ 1 \u222b [0,1]n fd(Ci \u2212 C) : f \u2208M } = t0 + t t0 + t+ 1 dW,1(Ci, C).\nIn view that dW,1(Ci, C) \u2264 dW,p(Ci, C) for p \u2265 1, we have that dW,p(Ci, C) \u2192 0 implies that the above term converges to 0 as well. Therefore, dW,p(\u00b5Ci,zi , \u00b5C,z) \u2192 0 and the mapping R(t, \u00b7, \u00b7) is continuous.\nAnother important property that C\u03b1t satisfies as a set valued function is upper hemi-continuity (u.h.c.) and it is stated below.\nLemma 2.3. For every t \u2208 T \u2032, the set valued function C\u03b1t is upper hemi-continuous.\nProof. We need to show that for any C \u2208 P([0, 1]n) and any open set E such that C\u03b1t (C) \u2282 E \u2282 P([0, 1]n), there exists a neighborhood D of C such that for all C \u2032 \u2208 D, C\u03b1t (C \u2032) \u2282 E.\nTo this end, let \u03b5 = dist(C, \u2202E) \u2212 r(\u03b1, t0, t) where dist(C, \u2202E) is the shortest Wasserstein-p distance from C to the boundary of E. Since E is an open set, then \u03b5 > 0. Hence, we take D as the Wasserstein-p ball centered at C with radius \u03b5. It is clear that for any C \u2032 \u2208 D, we have C\u03b1t (C \u2032) \u2282 E. Therefore, for fixed t \u2208 T \u2032, C\u03b1t is u.h.c.."
        },
        {
            "heading": "3 Nonparametric Adaptive Robust Control Problem",
            "text": "Now we proceed to formulate the nonparametric adaptive robust control problem assuming the true copula function C\u2217 is unknown. Recall that we consider P([0, 1]n) with the metric dW,p. Obviously, (P([0, 1]n, dW,p) is separable and complete. Hence, it is a Polish space and thus a Borel space. We define the augmented state process Y = {Yt = (Xt, C\u0302t), t \u2208 T }, and such process has the following dynamics\nYt+1 = G(t,Xt, \u03d5t, Zt+1) := (S(t,Xt, \u03d5t, Zt+1), R(t, C\u0302t, Zt+1)), t \u2208 T \u2032. (3.1)\nAccording to the assumption that S is continuous and Lemma 2.2, we get that G is continuous and therefore Borel measurable."
        },
        {
            "heading": "3.1 Transition Kernel of the State Process",
            "text": "Through the rest of this paper, we will write C\u03b1t (Yt) := C\u03b1t (C\u0302t) for Yt = (Xt, C\u0302t). For C \u2208 P([0, 1]n), one would like to define the transition kernel of Y as\nQt(dy \u2032|y, a, F ) = PC\u25e6F \u2217(G(t, y, a, Zt+1) \u2208 dy\u2032).\nHowever, C \u25e6 F \u2217 is a well-defined distribution on Rn only when C(i), i \u2208 N , is left continuous at 1 and\nlim u\u21920\nC(i)(u) = 0.\nDistribution C \u2208 P([0, 1]n) does not satisfies the above conditions will result in a distribution C\u25e6F \u2217 putting mass on infinity. To overcome this problem, we consider R = R \u22c3 {\u2212\u221e,\u221e} with Borel \u03c3-\nalgebra B(R) = \u03c3 (B(R) \u22c3 {[\u2212\u221e, x), (x,\u221e], x \u2208 R}). We also consider a metric on R consistent with B(R). Consequently, we have Rn equipped with the product topology and it is a Polish space as well as a Borel space. In addition, we consider P(Rn) the set of all probability distributions on Rn with topology consistent with weak convergence. For any F \u2208 P(Rn), we denote by F its extension in P(Rn) as\nF (x) =  F (x), x \u2208 Rn, 0, \u2212\u221e \u2208 {x(i), i \u2208 N}, 1, \u221e \u2208 {x(i), i \u2208 N}.\nNaturally, we change the state space of X to Rn, and define the augmented state space EY = Rn\u00d7P([0, 1]n) with product topology. It is then a Borel space and the Borel \u03c3-algebra EY coincides with the product \u03c3-algebra. In addition, for any relevant real valued function f , we write\nf(\u221e) = lim x\u2192\u221e f(x).\nTo proceed, for any t \u2208 T \u2032, (y, a) \u2208 EY \u00d7A, and distribution C \u2208 P([0, 1]n), Qt is a probability measure on EY such that\nQt(D|y, a, C) = PC\u25e6F\u2217(G(t, y, a, Zt+1) \u2208 D), D \u2208 EY .\nIn particular, when C is a copula, C \u25e6 F\u2217 is a n-dimensional probability distribution on Rn with marginals F (1) \u2217 , . . . , F (n) \u2217 . One important property of Qt is that it is Borel measurable for fixed t \u2208 T \u2032. Such property is crucial for proving the existence of measurable optimal control and worstcase copula. To this end, we extend Lemma 2.2 to the general case and provide the following technical results.\nLemma 3.1. For every fixed t \u2208 T \u2032, the mapping\nR(t, F, z\u2032) = (t0 + t)F (z) +Ht+1(z \u2212 z\u2032)\nt0 + t+ 1 , F \u2208 P(Rn), z, z\u2032 \u2208 Rn. (3.2)\nis continuous on P(Rn)\u00d7 Rn.\nProof. Assume that (Fi, z \u2032 i) \u2192 (F, z\u20320) and it implies that Fi \u2192 F in distribution and z\u2032i \u2192 z\u20320. Take any continuity set B of R(t, F0, z \u2032 0). That is for the boundary \u2202B of B, the probability PR(t,F0,z\u20320)(\u2202B) is equal to 0. Therefore, we get that B is also a continuity set of F and Ht+1(z\u2212z \u2032 0).\nNow, since Fi \u2192 F0 in distribution, then by the Portmanteau lemma, we know\nlim i\u2192\u221e PFi(B)\u2192 PF0(B).\nOn the other hand, for any z\u2032 \u2208 Rn, Ht+1(z\u2212 z\u2032) = P(H\u0303 \u2264 z\u2212 z\u2032) = P(H\u0303 + z\u2032 \u2264 z), where H\u0303 is the random variable with distribution Ht+1. Since z \u2032 i converges to the constant z \u2032 0, then H\u0303+z \u2032 i \u2192 H\u0303+z\u20320 in distribution. In turn, we get\nlim i\u2192\u221e PHt+1(z\u2212z\u2032i)(B)\u2192 PHt+1(z\u2212z\u20320)(B).\nTo summarize, we have that\nlim i\u2192\u221e PR(t,Fi,z\u2032i)(B) = PR(t,F0,z\u20320)(B),\nand R(t, F, z\u2032) is continuous on P(Rn)\u00d7 Rn.\nWith this result in hand, we define the transition kernel on the product space Rn\u00d7P(Rn) with product topology. That is, fix t \u2208 T \u2032, for any (x, F, a,G) \u2208 Rn \u00d7 P(Rn)\u00d7A\u00d7 P(Rn), and any set D belongs to the Borel \u03c3-algebra of Rn \u00d7 P(Rn), we write\nQt(D|x, F, a,G) = PG((S(t, x, a, Zt+1), R(t, F, Zt+1)) \u2208 D).\nThen, we show the measurability of Qt, t \u2208 T \u2032. Lemma 3.2. For every fixed t \u2208 T \u2032, Qt is a continuous stochastic kernel on R n \u00d7 P(Rn) given Rn \u00d7 P(Rn)\u00d7A\u00d7 P(Rn).\nProof. It is enough to prove that for any bounded continuous function f on Rn \u00d7 P(Rn) we have\u222b Rn\u00d7P(Rn) f(y)Qt(dy|x, F, a,G) (3.3)\nis continuous w.r.t. (x, F, a,G). To this end, we view that\u222b Rn\u00d7P(Rn) f(y)Qt(dy|x, F, a,G) = \u222b Rn f((S(t, x, a, z), R(t, F, z))dG(z).\nBy assumption on S and Lemma 3.1, for fixed t \u2208 T \u2032, S and R are continuous w.r.t. other variables. Since f is also continuous, then f((S(t, x, a, z), R(t, F, z)) is continuous w.r.t. (x, F, a, z). In addition, G(z) can be seen as a continuous stochastic kernel on Rn given (x, F, a,G) because it does not depend on (x, F, a). Hence, by [BS78, Proposition 7.30], we get that\u222b\nRn f((S(t, x, a, z), R(t, F, z))dG(z)\nis continuous w.r.t. (x, F, a,G). We immediately conclude that (3.3) is continuous w.r.t. (x, F, a,G).\nNext, we define the following mappings between P([0, 1]n) and P(Rn) similarly to (2.4): for any F \u2208 P(Rn),\nC(u) := F (F\u22121\u2217 \u25e6 u), u \u2208 [0, 1]n, (3.4)\nand for any C \u2208 P([0, 1]n),\nF (x) := C(F\u2217 \u25e6 x), x \u2208 R n . (3.5)\nWe realize that due to our assumptions on the marginals F (i) \u2217 , i \u2208 N , the mapping\nu\u2192 F\u2217 \u25e6 u, u \u2208 [0, 1]n,\ndefines a homeomorphism between [0, 1]n and Rn. By using such observation, we show the main result of this section as follows.\nProposition 3.3. For each t \u2208 T \u2032, the probability Qt( \u00b7 |y, a, C) is a continuous stochastic kernel on EY given EY \u00d7A\u00d7P([0, 1]n). Moreover, it is a Borel measurable stochastic kernel on EY given EY \u00d7A\u00d7 P([0, 1]n).\nProof. Through the proof, all the convergence for probability distributions are understood in the weak sense. We will prove the statements in several steps.\n1. Establish a mapping M1 from EY \u00d7A\u00d7P([0, 1]n) to R n\u00d7P(Rn)\u00d7A\u00d7P(Rn) that is continuous.\n2. Use Lemma 3.2 to obtain the continuous mapping Qt from R n \u00d7 P(Rn) \u00d7 A \u00d7 P(Rn) to\nP(Rn \u00d7 P(Rn)).\n3. Construct a mapping M2 from P(R n\u00d7P(Rn)) to P(EY ), which is restricted to the family of\nQt( \u00b7 |x, F, a,G), and satisfies some proper form of continuity.\nWe also need M1 and M2 to satisfy Qt = M2 \u25e6 Qt \u25e6 M1. To this end, for the first step, we take M1 : (x, C\u0303, a, C) 7\u2192 (x, C\u0303 \u25e6 F\u2217, a, C \u25e6 F\u2217), F,G \u2208 P([0, 1]n). Assume that the sequences {C\u0303i \u2208 P([0, 1]n), i = 1, 2, . . .} and {Ci \u2208 P([0, 1]n), i = 1, 2, . . .} converge to C\u03030 \u2208 P([0, 1]n) and C0 \u2208 P([0, 1]n) in distribution, respectively. It implies that for any continuity point u of C\u03030, we have C\u0303i(u)\u2192 C\u03030(u) as i\u2192\u221e. In view of the homeomorphism\nu\u2192 F\u22121\u2217 \u25e6 u, u \u2208 [0, 1]n,\nif z is a continuity point of C\u03030 \u25e6 F\u2217, then ( F (1) \u2217 (z (1)), . . . , F (n) \u2217 (z (n)) ) is a continuity point of C\u03030.\nRecall that C\u0303i converges to C\u03030 in distribution, we get\nlim i\u2192\u221e C\u0303i \u25e6 F\u2217(z) = lim i\u2192\u221e C\u0303i(F\u2217 \u25e6 z) = lim i\u2192\u221e C\u0303i\n( F (1) \u2217 (z (1)), . . . , F (n) \u2217 (z (n)) )\n= C\u03030\n( F (1) \u2217 (z (1)), . . . , F (n) \u2217 (z (n)) ) = C\u03030 \u25e6 F\u2217(z),\nwhich implies that C\u0303i\u25e6F\u2217 converges to C\u03030\u25e6F\u2217 in distribution. Similarly, Ci\u25e6F\u2217 converges to C0\u25e6F\u2217 in distribution, and step 1 is done. Also note that step 2 is fulfilled according to Lemma 3.2.\nNext, define M2 : Qt( \u00b7 |x, F, a,G) 7\u2192 Qt( \u00b7 |x, F \u25e6 F\u22121\u2217 , a,G \u25e6 F\u22121\u2217 ), F,G \u2208 P(R n ). We will show that Qt is continuous w.r.t. (x, F, a,G). In turn, the mapping M2 will be continuous according to the definition of continuous parametric mapping. Let D \u2208 EY be a closed set, and let (Fi, Gi) converges to (F0, G0). Similarly to the discussion in step 1, we have Fi \u25e6F\u22121\u2217 and Gi \u25e6F\u22121\u2217 converge to F0 \u25e6F\u22121\u2217 and G0 \u25e6F\u22121\u2217 , respectively. Thus, by Lemma 2.2 and the fact that continuity in distribution and continuity in the Wasserstein sense are equivalent on P([0, 1]n), the function G(t, x, F \u25e6 F\u22121\u2217 , a, z) is continuous w.r.t. (x, F, a, z). Consider any bounded continuous function f on EY , we get that\u222b\nEY\nf(y)Qt(dy|x, F \u25e6 F\u22121\u2217 , a,G \u25e6 F\u22121\u2217 ) = \u222b Rn f(G(t, x, F \u25e6 F\u22121\u2217 , a, z))dG(F\u22121\u2217 \u25e6 z). (3.6)\nThe integrand f(G(t, x, F \u25e6 F\u22121\u2217 , a, z)) is continuous w.r.t. (x, F, a, z). Also, we view the G \u25e6 F\u22121\u2217 as a continuous stochastic kernel w.r.t. (x, F, a,G). By [BS78, Proposition 7.30] again, the integral\u222b\nRn f(G(t, x, F \u25e6 F\u22121\u2217 , a, z))dG(F\u22121\u2217 \u25e6 z)\nis continuous in (x, F, a,G), and so is\u222b EY f(y)Qt(dy|x, F \u25e6 F\u22121\u2217 , a,G \u25e6 F\u22121\u2217 )\ndue to (3.6). As a result, Qt is continuous in (x, F, a,G), and step 3 is complete. Finally, we note that Qt = M2 \u25e6 Qt \u25e6M1. According to the above discussion and equivalence between continuity in distribution and in the Wasserstein sense on P([0, 1]n), Qt is a continuous stochastic kernel. Hence, it is also a Borel measurable stochastic kernel."
        },
        {
            "heading": "3.2 Formulation of Adaptive Robust Control Problem",
            "text": "In this work, we will formulate and solve a closed loop feedback control problem. To this end, with slight abuse of notations, we say that a control process \u03d5 is Markovian if for every t \u2208 T \u2032\n\u03d5t = \u03d5t(Y (t)),\nsuch that \u03d5t(\u00b7) : EY \u2192 A is a measurable mapping. Similarly, a process \u03c8 is called a Markovian model selector if\n\u03c8t = \u03c8t(Y (t)),\nwhere \u03c8t(\u00b7) : EY \u2192 P([0, 1]n) is measurable. In the adaptive robust framework, we consider the Markovian control processes and Markovian model selectors such that \u03c8t(y) \u2208 C\u03b1t (y) and \u03c8t(y) is restricted to be a copula for any y \u2208 EY . For every t \u2208 T \u2032, any time-t state yt \u2208 EY , and control process \u03d5 \u2208 At, we define\n\u03a8ytt = {\u03c8 : \u03c8s(ys) \u2208 C\u03b1s (ys), t \u2264 s \u2264 T \u2212 1} .\nIn addition, let \u03d5 \u2208 At, and \u03b4y be the Dirac probability measure assigns the mass at y \u2208 EY . Then, at time t, for the current state Yt = y, define the probability measure Q\u03d5,\u03c8y,t on the concatenated canonical space XTs=tEY as\nQ\u03d5,\u03c8y,t (Bt \u00d7 \u00b7 \u00b7 \u00b7 \u00d7BT ) = \u222b Bt \u222b Bt+1 \u00b7 \u00b7 \u00b7 \u222b BT T\u22121\u220f s=t Qs(dys+1|ys, \u03d5(s, ys), \u03c8(s, ys))\u03b4y(dyt).\nAccordingly, we consider the family of probability measures Q\u03d5y,t = { Q\u03d5,\u03c8y,t , \u03c8 \u2208 \u03a8 y t } , and we write, for simplicity, Q\u03d5y = Q\u03d5y,0. Finally, for Y0 = y \u2208 EY , the nonparametric adaptive robust control problem in this work is formulated as\ninf \u03d5\u2208A sup Q\u03c8\u2208Q\u03d5y EQ\u03c8 [`(XT )], (3.7)\ns.t. \u03c8t is a copula, t \u2208 T \u2032.\nNote that for every t \u2208 T \u2032, any y \u2208 EY , search for the worst-case copula in C\u03b1t (y) is practically impossible. To overcome such difficulty, we adopt the method of penalty functions and use it to reformulate (3.7). Ultimately, for every fixed t \u2208 T \u2032 and any fixed (y, a) \u2208 EY \u00d7 A, we want to find the optimizer \u03c8t(y, a) such that \u03c8t(y, a) \u25e6 F\u2217 has marginals F (i)\u2217 , i \u2208 N . Hence, we denote by Cb(R) the set of all continuous, bounded, real valued functions, and consider the penalty function\n\u03c1(\u03c8) = \u2211 t\u2208T \u2032 \u03c1t(\u03c8t) := \u2211 t\u2208T \u2032 \u2211 i\u2208N sup fi\u2208Cb(R) ( E(\u03c8t\u25e6F\u2217)(i) [fi]\u2212 EF (i)\u2217 [fi] ) The choice of the penalty function is inspired by the criterion that characterize the weak convergence of probability distributions, and it is similar to the penalty function used in [GK17]. Note that for such penalty, we have\nLemma 3.4. For any fixed t \u2208 T \u2032, \u03c8t is a copula if and only if \u03c1t(\u03c8t) = 0.\nProof. If \u03c8t is a copula, then it is obvious that \u03c1t(\u03c8t) = 0. On the other hand, note that for any i \u2208 N ,\nsup f\u2208Cb(R)\n( E(\u03c8t\u25e6F\u2217)(i) [f ]\u2212 EF (i)\u2217 [f ] ) \u2265 E(\u03c8t\u25e6F\u2217)(i) [0]\u2212 EF (i)\u2217 [0] = 0.\nHence, if \u03c1t(\u03c8t) = 0, we obtain that for any i \u2208 N\nsup f\u2208Cb(R)\n( E(\u03c8t\u25e6F\u2217)(i) [f ]\u2212 EF (i)\u2217 [f ] ) = 0.\nMoreover, we get that for any i \u2208 N , and any f \u2208 Cb(R)\nE(\u03c8t\u25e6F\u2217)(i) [f ]\u2212 EF (i)\u2217 [f ] = 0. (3.8)\nOtherwise, there exists some i \u2208 N and f0 \u2208 Cb(R) such that\nE(\u03c8t\u25e6F\u2217)(i) [f0]\u2212 EF (i)\u2217 [f0] < 0.\nIn turn, for such i, we have\nsup f\u2208Cb(R)\n( E(\u03c8t\u25e6F\u2217)(i) [f ]\u2212 EF (i)\u2217 [f ] ) \u2265E(\u03c8t\u25e6F\u2217)(i) [\u2212f0]\u2212 EF (i)\u2217 [\u2212f0]\n=\u2212 ( E(\u03c8t\u25e6F\u2217)(i) [f0]\u2212 EF (i)\u2217 [f0] ) > 0,\nand \u03c1t(\u03c8t) > 0 as a result which is a contradiction. Therefore, equality 3.8 holds true. Consequently, by the criterion of weak convergence, we get that \u03c8t is a copula.\nThe above result justifies the choice of \u03c1. Another advantage of using the proposed penalty function is that for any fixed f \u2208 Cb(R), the linearity in \u03c8t \u25e6 F\u2217 allows us to obtain a tractable numerical computation scheme (cf. Section 5.1) for the value functions to be defined later. To proceed, we provide the following technical result on the regularity property of \u03c1t, t \u2208 T \u2032, which plays an important role in proving the existence of optimal control.\nLemma 3.5. For every t \u2208 T \u2032, the penalty term \u03c1t is lower semi-continuous (l.s.c.).\nProof. We will show that lim infC\u2192C0 \u03c1t(C) \u2265 \u03c1t(C0) for any C0 \u2208 P([0, 1]n). To this end, let Cj be any sequence that converges to C0. If \u03c1t(C0) = +\u221e, then, for any b \u2208 R, there exists a family {fi, i \u2208 N} \u2282 Cb(R) such that \u2211\ni\u2208N\n( E(C0\u25e6F\u2217)(i) [fi]\u2212 EF (i)\u2217 [fi] ) > b.\nSince Cj \u2192 C0, then there exists a n0 > 0 such that for any j \u2265 n0 we get\u2211 i\u2208N ( E(Cj\u25e6F\u2217)(i) [fi]\u2212 EF (i)\u2217 [fi] ) > b 2 ,\nwhere continuity of E(C\u25e6F\u2217)(i) [fi] in C is obtained according to the proof of Proposition 3.3. Thus, we have that\n\u03c1t(Cj) > b\n2 , j \u2265 n0,\nand moreover lim j\u2192\u221e \u03c1t(Cj) = +\u221e.\nIf \u03c1t(C0) < +\u221e, then for any \u03b5 > 0, there exists a family {fi, i \u2208 N} \u2282 Cb(R) such that\u2211 i\u2208N ( E(C0\u25e6F\u2217)(i) [fi]\u2212 EF (i)\u2217 [fi] ) > \u03c1t(C0)\u2212 \u03b5.\nHence, from the convergence of Cj to C0, there exists n0 > 0 and for any j \u2265 n0 the following inequality holds true \u2211\ni\u2208N\n( E(Cj\u25e6F\u2217)(i) [fi]\u2212 EF (i)\u2217 [fi] ) > \u03c1t(C0)\u2212 2\u03b5.\nThus, \u03c1t(Cj) \u2265 \u03c1t(C0)\u22122\u03b5 for any j \u2265 n0, and limj\u2192\u221e \u03c1t(Cj) \u2265 \u03c1t(C0)\u22122\u03b5. Because \u03b5 is arbitrary, we get that limj\u2192\u221e \u03c1t(Cj) \u2265 \u03c1t(C0). In summary, we conclude that lim infC\u2192C0 \u03c1t(C) \u2265 \u03c1t(C0) and \u03c1t is l.s.c..\nIn the sequel, we will consider a reformulation of (3.7) as follows\ninf \u03d5\u2208A sup Q\u03c8\u2208Q\u03d5y\n( EQ\u03c8 [`(XT )]\u2212 \u03c1(\u03c8) ) . (3.9)\nBefore discussing the solution of (3.9), we want to remark that, in this work, the uncertainty set is some set of measures on P([0, 1]n) centered at the empirical copula. Another approach is to consider the worst-case model of Zt, t \u2208 T \u2032\u2032, chosen from some uncertainty set centered around the empirical distribution of Zt. By imposing a penalty function similar to \u03c1, we can ensure that the worst-case model matches F\u2217 in terms of the marginals. Thus, we are able to set up a problem that is similar to (3.9) without considering the copula. Regarding the comparison between such approach and our method, we refer to Section 4.3 below. In case that the marginals are also uncertain, one can extend the framework in [BC22] to the multi-dimensional case via the multivariate empirical distribution."
        },
        {
            "heading": "4 Solution of the Nonparametric Adaptive Robust Control Prob-",
            "text": "lem\nIn this section, we show that the solution of the nonparametric adaptive robust control problem (3.9) is given by solving the following adaptive robust Bellman equations\nVT (y) = `(x), y \u2208 EY ,\nVt(y) = inf a\u2208A sup C\u2208C\u03b1t (y)\n( EC\u25e6F\u2217 [Vt+1(G(t, y, a, Zt+1)]\u2212 \u03c1t(C) ) , y \u2208 EY , t \u2208 T \u2032. (4.1)"
        },
        {
            "heading": "4.1 Existence of Measurable Optimal Control",
            "text": "To show existence of measurable optimal control to the problem (4.1), we denote\nvt(y, a, C) = EC\u25e6F\u2217 [Vt+1(G(t, y, a, Zt+1)]\u2212 \u03c1t(C), t \u2208 T \u2032,\nand provide the following preliminary results.\nProposition 4.1. For every t \u2208 T , the functions vt and Vt are upper semi-continuous (u.s.c.). Moreover, there exists a Borel measurable function \u03c8\u2217t takes values in the set of copulae such that for any fixed (y, a)\nsup C\u2208C\u03b1t (y)\nvt(y, a, C) = vt(y, a, \u03c8 \u2217 t (y, a)). (4.2)\nProof. By our assumption, the function VT (y) = `(x) is continuous and hence u.s.c.. For any C \u2208 P([0, 1]n), we write\nEC\u25e6F\u2217 [VT (G(T \u2212 1, y, a, ZT ))] = \u222b EY VT (yT )dQT\u22121(yT |y, a, C).\nAccording to Proposition 3.3, QT\u22121 is a continuous stochastic kernel. Then, in view of the assumption that ` is bounded from above and [BS78, Proposition 7.31], we get that\nEC\u25e6F\u2217 [VT (G(T \u2212 1, y, a, ZT ))]\nis u.s.c.. On the other hand, by Lemma 3.5, \u2212\u03c1T\u22121(C) is u.s.c., and in turn, vT\u22121 are u.s.c.. Next, since that [0, 1]n is compact, then P([0, 1]n) (equipped with metric dW,p) is compact. Let\nD = \u22c3\n(y,a)\u2208EY \u00d7A({(y, a)} \u00d7 C \u03b1 t (y)) which can be viewed as the graph of the set valued function\nC\u03b1t (y). Note that C\u03b1t (y) is closed and, by Lemma 2.3, is u.h.c.. Hence, the set D is closed. According to [BS78, Proposition 7.33], the function V\u030cT\u22121(y, a) = supC\u2208C\u03b1t (y) vT\u22121(y, a, C) is u.s.c.. As a result, VT\u22121(y) = infa\u2208A V\u030cT\u22121(y, a) is u.s.c. as well. Moreover, for any fixed (y, a), there exists a Borel measurable function \u03c8\u2217 such that (4.2) holds true.\nLast but not the least, for any C \u2208 C\u03b1T\u22121(y) that is not a copula, it is not hard to see that \u03c1T\u22121(C) = +\u221e. Consequently, for such C, vT\u22121(y, a, C) = \u2212\u221e. For any C that is a copula, we have\nvT\u22121(y, a, C) = EC\u25e6F\u2217 [VT (G(t, y, a, ZT ))] \u2265 \u2212\u221e.\nThis indicates that for any (y, a), \u03c8\u2217T\u22121(y, a) is a copula. The rest of the proof follows analogously.\nThe above proposition proves the existence of measurable worst-case copula selector. Regarding the optimal control, we use the semi-analyticity property of the value function Vt as follows.\nProposition 4.2. For every t \u2208 T , the function Vt is lower semi-analytic (l.s.a.). Moreover, for any \u03b5 > 0, there exists an analytically measurable function \u03d5\u2217,\u03b5t such that\nsup C\u2208C\u03b1t (y)\nvt(y, \u03d5 \u2217,\u03b5 t (y), C) = { Vt(y) + \u03b5 if Vt(y) > \u2212\u221e, \u22121/\u03b5 if Vt(y) = \u2212\u221e.\n(4.3)"
        },
        {
            "heading": "In other words, \u03d5\u2217,\u03b5t is the \u03b5-optimal control.",
            "text": "Proof. Since VT (y) = `(x) is continuous by assumption, then VT is l.s.a.. Recall\nvT\u22121(y, a, C, \u03bbT\u22121) = \u222b EY VT (yT )QT\u22121(dyT |y, a, C)\u2212 \u03c1T\u22121(C).\nThe first term on the RHS is l.s.a. as QT\u22121 is a Borel measurable stochastic kernel by Proposition 3.3, and the second term \u2212\u03c1T\u22121(C) is l.s.a. because it is u.s.c.. Therefore, the function vT\u22121(y, a, C) is l.s.a..\nIn view of (4.2) in Proposition 4.1 where \u03c8\u2217T\u22121 is Borel measurable, we deduce that\nV\u0302t(y, a) = sup C\u2208C\u03b1T\u22121(y) vT\u22121(y, a, C)\nis l.s.a. according to part (3) of [BS78, Lemma 7.30]. Next, the set A is also Borel measurable and in turn analytic. Hence, by [BS78, Proposition 7.50], VT\u22121(y) is l.s.a., and (4.3) holds true for t = T \u22121. The rest of the proof follows analogously.\nRemark 4.3. We want to stress that in general the result in Lemma 4.2 cannot be improved in the sense that one is unable to obtain the measurable optimal control instead of \u03b5-optimal control. Following [BS78, Proposition 7.50], on the set\nI = { y \u2208 EY : \u2203ay \u2208 A such that V\u0302t(y, ay) = Vt(y) } one will get a universally measurable optimal control. In our setup, all the continuous points of Vt belong to I. However, due to the presence of the penalty term, it is impossible to show the lower semi-continuity of Vt to the best of our knowledge.\nNow, we proceed to show that the problem (3.9) satisfies the Bellman principle and is solved by (4.1)."
        },
        {
            "heading": "4.2 Dynamic Programming",
            "text": "Here we will use Proposition 4.1 and Proposition 4.2 to show that problem (3.9) is solved by the Bellman equation (4.1). Denote\n\u03c1t:T\u22121(\u03c8) = T\u22121\u2211 s=t \u03c1s(\u03c8s),\nthen we have the main result of this section as follows.\nTheorem 4.4. For every t \u2208 T \u2032, and any y \u2208 EY , we have\nVt(y) = inf \u03d5\u2208At sup Q\u2208Q\u03d5y,t\n(EQ[`(XT )]\u2212 \u03c1t:T\u22121(\u03c8)) .\nProof. We will prove the statement via backward induction in t = T \u2212 1, . . . , 1, 0. When t = T \u2212 1 and y \u2208 EY , we have\ninf \u03d5\u2208AT\u22121 sup Q\u03c8\u2208Q\u03d5y,T\u22121\n( EQ\u03c8 [`(XT )]\u2212 \u03c1T\u22121(\u03c8) ) = inf a\u2208A\nsup C\u2208C\u03b1T\u22121(y) (\u222b EY VT (y \u2032)QT\u22121(y \u2032|y, a, C)\u2212 \u03c1T\u22121(C) ) = VT\u22121(y).\nNext, for t = T \u2212 2, . . . , 0 and y \u2208 EY , denote \u03d5t = {\u03d5s, s = t, . . . , T \u2212 1} and \u03c8t = {\u03c8s, s = t, . . . , T \u2212 1}, then\ninf \u03d5\u2208At sup Q\u03c8\u2208Q\u03d5y,t\n( EQ\u03c8 [`(XT )]\u2212 \u03c1t:T\u22121(\u03c8) ) = inf\n(a,\u03d5t+1)\u2208At sup\nC\u2208C\u03b1t (y) \u222b EY sup Q\u03c8t+1\u2208Q\u03d5 t+1\ny\u2032,t+1\n( EQ\u03c8t+1 [`(XT )]\u2212 \u03c1t:T\u22121((C,\u03c8 t+1)) ) Qt(dy \u2032|y, a, C),\nwhere by induction\nsup Q\u03c8t+1\u2208Q\u03d5 t+1\ny\u2032,t+1\n( EQ\u03c8t+1 [`(XT )]\u2212 \u03c1t:T\u22121((C,\u03c8 t+1)) )\n= sup Q\u03c8t+1\u2208Q\u03d5 t+1\ny\u2032,t+1\n( EQ\u03c8t+1 [`(XT )]\u2212 \u03c1t+1:T\u22121(\u03c8 t+1)\u2212 \u03bbt\u03c1t(C) )\n\u2265Vt+1(y\u2032)\u2212 \u03c1t(C).\nHence, we get\ninf \u03d5\u2208At sup Q\u03c8\u2208Q\u03d5y,t\n( EQ\u03c8 [`(XT )]\u2212 \u03c1t:T\u22121(\u03c8) ) \u2265 inf\n(a,\u03d5t+1)\u2208At sup\nC\u2208C\u03b1t (y) \u222b EY ( Vt+1(y \u2032)\u2212 \u03c1t(C) ) Qt(dy \u2032|y, a, C)\n= inf a\u2208A sup C\u2208C\u03b1t (y) (\u222b EY Vt+1(y \u2032)Qt(dy \u2032|y, a, C)\u2212 \u03c1t(C) ) = Vt(y). (4.4)\nOn the other hand, for any \u03b5 > 0, let \u03d5t+1,\u03b5 \u2208 At+1 be an \u03b5-optimal control starting at time t+ 1. We obtain that\nsup Q\u03c8t+1\u2208Q\u03d5 t+1,\u03b5\ny\u2032,t+1\n( EQ\u03c8t+1 [`(XT )]\u2212 \u03c1t:T\u22121((C,\u03c8 t+1)) )\n\u2264 inf \u03d5t+1\u2208At+1 sup Q\u03c8t+1\u2208Q\u03d5 t+1\ny\u2032,t+1\n( EQ\u03c8t+1 [`(XT )]\u2212 \u03c1t:T\u22121((C,\u03c8 t+1)) ) + \u03b5\n= ( Vt+1(y \u2032)\u2212 \u03bbt\u03c1t(C) ) + \u03b5.\nIn what follows, we have\ninf \u03d5\u2208At sup Q\u03c8\u2208Q\u03d5y,t\n( EQ\u03c8 [`(XT )]\u2212 \u03c1t:T\u22121(\u03c8) ) \u2264 inf a\u2208A sup\nQ\u03c8\u2208Q(a,\u03d5 t+1,\u03b5)\ny\u2032,t+1\n( EQ\u03c8 [`(XT )]\u2212 \u03c1t:T\u22121((C,\u03c8t+1)) ) = inf a\u2208A\nsup C\u2208C\u03b1t (y) \u222b EY sup Q\u03c8t+1\u2208Q\u03d5 t+1,\u03b5\ny\u2032,t+1\n( EQ\u03c8t+1 [`(XT )]\u2212 \u03c1t:T\u22121((C,\u03c8 t+1)) ) Qt(dy \u2032|y, a, C)\n\u2264 inf a\u2208A sup C\u2208C\u03b1t (y) \u222b EY ( Vt+1(y \u2032)\u2212 \u03c1t(C) ) Qt(dy \u2032|y, a, C) + \u03b5\n= inf a\u2208A sup C\u2208C\u03b1t (y) (\u222b EY Vt+1(y \u2032)Qt(dy \u2032|y, a, C)\u2212 \u03c1t(C) ) + \u03b5\n=Vt(y) + \u03b5.\nSince \u03b5 is arbitrary, as a consequence,\ninf \u03d5\u2208At sup Q\u03c8\u2208Q\u03d5y,t\n( EQ\u03c8 [`(XT )]\u2212 \u03c1t:T\u22121(\u03c8) ) \u2264 Vt(y). (4.5)\nCombine (4.4) and (4.5), we conclude that\ninf \u03d5\u2208At sup Q\u03c8\u2208Q\u03d5y,t\n( EQ\u03c8 [`(XT )]\u2212 \u03c1t:T\u22121(\u03c8) ) = Vt(y).\nThe above theorem shows that the problem (3.9) is solved via the Bellman equation (4.1). In the next section, we will compare the approach (3.9) to some different methods that can be used to handle the optimization problem under dependence uncertainty."
        },
        {
            "heading": "4.3 Comparison to Robust Control Problem via Empirical Distribution",
            "text": "In this section, we will compare three different setups that can be used for solving the proposed problem. One of other approaches that is viable in this setup is, as we mentioned earlier, the multidimensional version of the methodology discussed in [BC22]. Briefly speaking, one can build confidence regions in terms of Wasserstein balls centered at the empirical distribution F\u0302t, say, denoted as C\u03b1,et (F\u0302t). Then, formulate the adaptive robust problem that optimizes the expected loss/utility against the worst-case model in C\u03b1,et (F\u0302t). Obviously, doing so will ignore the available information of the marginals F (i) \u2217 , i \u2208 N . However, for large value of T , such method will have a decent performance as the corresponding value function will get quite closed to the true one when t approaches T (cf. [BC22]). The associated Bellman equation is given as follows\nV et (y \u2032) = inf\na\u2208A sup F\u2208C\u03b1,et (y\u2032) EF [V et+1(G(t, y\u2032, a, Zt+1))], t \u2208 T \u2032, (4.6)\nwhere y\u2032 is the state of the process Y \u2032t = (Xt, F\u0302t), t \u2208 T \u2032. The third method is somewhat similar to the one we just described but utilizes the information of the known marginals. One can impose essentially the same penalty function as in this work and force the worst-case distribution to have correct marginals. To this end, we define the following one-step penalty function\n\u03c1mt (F ) = \u2211 i\u2208N sup fi\u2208Cb(S(i)) ( EF (i) [fi]\u2212 EF (i)\u2217 [fi] ) ,\nfor any F \u2208 C\u03b1,mt (F\u0302t), which is the Wasserstein ball centered at F\u0302t that might have a different radius compared to C\u03b1,et (F\u0302t). Also, the above S(i) is the support of Z (i) t+1, i \u2208 N . The corresponding Bellman equation is\nV mt (y \u2032) = inf\na\u2208A sup\nF\u2208C\u03b1,mt (y\u2032)\n( EF [V mt+1(G(t, y\u2032, a, Zt+1))]\u2212 \u03c1t(F ) ) , t \u2208 T \u2032, (4.7)\nwhere y\u2032 is defined the same way as in (4.6).\nNow the question is that which framework is the best in what situation, and can the methods with imposed penalty functions take advantage of the available information of the marginals and outperform the approach that ignores it? First off, note that one can always take C\u03b1,mt = C \u03b1,e t backed by the concentration result. Then, due to the presence of the penalty function \u03c1t(F ), framework (4.7) is essentially searching for the worst-case distribution in a smaller set compared to (4.6). Therefore, we have\nV mt (y \u2032) \u2264 V et (y\u2032).\nIn other words, (4.7) yields smaller loss which is meant to be minimized. In this sense, the solution corresponding to (4.7) is better than the one corresponding to (4.6).\nThe comparison between (3.9) and (4.7) is much more complicated, and it turns out that the preference depends on additional properties of F \u2217. To this end, we first discuss the relationship between the uncertainty sets C\u03b1t (y) and C \u03b1,e t (y\n\u2032) where y = (x, C\u0302) and y\u2032 = (x, F\u0302 ) such that C\u0302 = F\u0302 \u25e6 F\u22121\u2217 . This means that both methods use the exact same information at every time step t \u2208 T \u2032. In the first case, when there exists a constant B > 1 such that\n\u2016F\u2217 \u25e6 z1 \u2212 F\u2217 \u25e6 z2\u2016 \u2264 B\u2016z1 \u2212 z2\u2016, (4.8)\nwhere\nF\u2217 \u25e6 z = ( F (1) \u2217 (z (1)), . . . , F (n) \u2217 (z (n)) ) .\nHence, for any f1, f2 on [0, 1] n, such that\n|f1(u1)\u2212 f2(u2)| \u2264 \u2016u1 \u2212 u2\u2016p, u1, u2 \u2208 [0, 1]n,\nwe get\n|f1(F\u2217 \u25e6 z1)\u2212 f2(F\u2217 \u25e6 z2)| \u2264 \u2016F\u2217 \u25e6 z1 \u2212 F\u2217 \u25e6 z2\u2016p \u2264 Bp\u2016z1 \u2212 z2\u2016p, z1, z2 \u2208 Rn.\nFollowing such obervation, we have for any C\ndpW,p(C\u0302, C) = sup f1,f2 (\u222b [0,1]n f1(u)dC\u0302(u)\u2212 \u222b [0,1]n f2(u)dC(u) )\n= sup f1,f2 (\u222b Rn f1(F\u2217 \u25e6 z)dC\u0302(F\u2217 \u25e6 z)\u2212 \u222b Rn f2(F\u2217 \u25e6 z)dC(F\u2217 \u25e6 z) ) \u2264 Bp sup\ng1,g2 (\u222b Rn g1(z)dC\u0302(F\u2217 \u25e6 z)\u2212 \u222b Rn g2(z)dC(F\u2217 \u25e6 z) ) = BpdpW,p(F\u0302 , C \u25e6 F\u2217), (4.9)\nwhere |g1(z1)\u2212g2(z2)| \u2264 \u2016z1\u2212z2\u2016p for any z1, z2 \u2208 Rn. Thus, for the radius rm(\u03b1, t0, t) of C\u03b1,mt (y\u2032), it suffices to take rm(\u03b1, t0, t) = r(\u03b1, t0, t)/B. Note that, in theory one should choose r\ne(\u03b1, t0, t), which is the radius of C\u03b1,et , as r\ne(\u03b1, t0, t) = r(\u03b1, t0, t). Hence, in this case, (4.7) will perform better than (4.6) because it has a smaller associated Wasserstein ball.\nOn the other hand, between (3.9) and (4.7), in view of (4.9), we obtain that for any F \u2208 C\u03b1,mt (y\u2032), there exists a corresponding C \u2208 C\u03b1t (y). Consequently, we can view C \u03b1,m t as a \u201csmaller\u201d set than C\u03b1t . Moreover, we immediately get that\nV mt (y \u2032) \u2264 Vt(y),\nand (4.7) outperforms (3.9). One should note that, in this case, it is unclear which one is better between (3.9) and (4.7).\nThe other case is that each S(i), i \u2208 N , is a compact subset of R, and we suppose that there exists a constant B\u2032 > 0 such that\n\u2016F\u2217 \u25e6 z\u20321 \u2212 F\u2217 \u25e6 z\u20322\u2016 \u2265 B\u2032\u2016z\u20321 \u2212 z\u20322\u2016, (4.10)\nfor any z\u20321, z \u2032 2 \u2208 \u220f i\u2208N S(i). Under these assumptions, for any g1, g2 on Rn, such that\n|g1(z\u20321)\u2212 g2(z\u20322)| \u2264 \u2016z\u20321 \u2212 z\u20322\u2016p, z\u20321, z\u20322 \u2208 \u220f i\u2208N S(i),\nwe obtain\n|g1(F\u22121\u2217 \u25e6 u1)\u2212 g2(F\u22121\u2217 \u25e6 u2)| \u2264 \u2016F\u22121\u2217 \u25e6 u1 \u2212 F\u22121\u2217 \u25e6 u2\u2016p \u2264 1\nB\u2032 \u2016u1 \u2212 u2\u2016, u1, u2 \u2208 [0, 1]n.\nThen, for any F whose associated random variable has support \u220f i\u2208N S(i), and F = C \u25e6F\u2217 for some copula C, we have\ndpW,p(F\u0302 , F ) = sup g1,g2 (\u222b Rn g1(z)dF\u0302 (z)\u2212 \u222b Rn g2(z)dF (z) ) = sup g1,g2 (\u222b \u220f i\u2208N S(i) g1(z)dF\u0302 (z)\u2212 \u222b \u220f i\u2208N S(i) g2(z)dF (z) )\n= sup g1,g2 (\u222b \u220f i\u2208N S(i) g1(z)dC\u0302(F\u2217 \u25e6 z)\u2212 \u222b \u220f i\u2208N S(i) g2(z)dC(F\u2217 \u25e6 z) )\n= sup g1,g2 (\u222b [0,1]n g1(F \u22121 \u2217 (u)dC\u0302(u)\u2212 \u222b [0,1]n g2(F \u22121 \u2217 (u)dC(u) )\n\u2264 1 B\u2032 sup f1,f2 (\u222b [0,1]n f1(u)dC\u0302(u)\u2212 \u222b [0,1]n f2(u)dC(u) ) = 1\nB\u2032 dpW,p(C\u0302, C),\nwhere |f1(u1) \u2212 f2(u2)| \u2264 \u2016u1 \u2212 u2\u2016 for any u1, u2 \u2208 [0, 1]n. As a result, similarly to the above discussion, we view C\u03b1t as a \u201csmaller\u201d set than C \u03b1,m t , and we conclude\nVt(y) \u2264 V mt (y\u2032) \u2264 V et (y\u2032).\nIn other words, the framework proposed in this work will perform the best among all three mentioned approaches.\nFinally, we remark that when S(i), i \u2208 N , are compact, and both (4.8) and (4.10) hold true, the two frameworks (3.9) and (4.7) are equivalent. If neither (4.8) or (4.10) is satisfied, it is unclear which one between (3.9) and (4.7) is more preferable."
        },
        {
            "heading": "5 Uncertain Utility Maximization with Known Marginal Distri-",
            "text": "butions\nIn this section, we will apply the adaptive robust control methodology to the uncertain utility maximization problem where the marginal distributions of the underlying random noise are known. Note that even though our theory applies to both empirical distribution and perturbed empirical distribution, we will focus only on the case of empirical distribution in this section. The advantage of using the perturbed empirical distribution is that the resulting C\u0302 is a copula. This could be a more sounding approach in some applications, however in this work, it will increase the computation burden which is already heavy. Hence, we leave the corresponding investigating for potential future studies.\nTowards this end, we first discuss the algorithm that we will implement."
        },
        {
            "heading": "5.1 Numerical Algorithm",
            "text": "From the practical point of view, one major difficulty in solving a robust control problem with Wasserstein uncertainty set such as C\u03b1t is that direct searching through C\u03b1t (y) to find the optimizer \u03c8\u2217t (y) is impossible. Typically, one uses a duality argument to re-write such problem as a scalar optimization problem. In [EK18], the authors provide a rather comprehensive discussion on the tractable reformulations of an optimization problem over the Wasserstein ball. With some postulation on the loss function, the authors achieve a convex reduction of the worst-case expectation problems. However, results in [EK18] only apply to the case of optimizing the expected loss while in this work we deal with a different problem as in (4.1)\nsup C\u2208C\u03b1t (y) (EC\u25e6F\u2217 [Vt+1(G(t, y, a, Zt+1)]\u2212 \u03c1t(C)) . (5.1)\nDue to the non-linearity of the penalty function \u03c1t, one cannot directly adopt the idea in [EK18] to reformulate problem (4.1) for the numerical purpose.\nTo this end, we recall the paper [GK17] which considers the numerical solution of a 1-period robust optimization problem with Wasserstein uncertainty set centered at the estimated copula which is similar to our worst-case copula optimization problem. Let {z\u2212t0+1, . . . , zt} be the historical data of Z up to time t \u2208 T \u2032, the strong duality result in [GK17] implies that problem (5.1) can be solved as\ninf \u03b3\u2208R+,fi\u2208Cb(R) \u03b3r(\u03b1, t0, t)p + n\u2211 i=1 \u222b R fi(z)dF (i) \u2217 (z) + 1 t0 + t t\u2211 j=\u2212t0+1 V \u03b3t+1(G(t, y, a, zj)  , (5.2) where\nV \u03b3t+1(G(t, y, a, zj) = sup z\u2208Rn\n( Vt+1(G(t, y, a, z))\u2212\nn\u2211 i=1 fi(z (i))\u2212 \u03b3dpF\u2217(z, zj)\n) , (5.3)\nand\ndF\u2217(\u03be, \u03b6) = d (( F (1) \u2217 (\u03be (1)), . . . , F (n) \u2217 (\u03be (n)) ) , ( F (1) \u2217 (\u03b6 (1)), . . . , F (n) \u2217 (\u03b6 (n)) )) . (5.4)\nRemark 5.1. In general, the premetric dF\u2217 is defined as\ndF\u2217(\u03be, \u03b6) = lim inf d(\u03bei,\u03be),d(\u03b6i,\u03b6)\u21920\nd (( F (1) \u2217 (\u03be (1) i ), . . . , F (n) \u2217 (\u03be (n) i ) ) , ( F (1) \u2217 (\u03b6 (1) i ), . . . , F (n) \u2217 (\u03b6 (n) i ) )) .\nDue to our assumption that F (i) \u2217 , i \u2208 N , are continuous, so dF\u2217 becomes (5.4).\nIn [GK17], to use the strong duality result in practice, the authors essentially assume that the range of the random variable Zt, t \u2208 T , is a finite set. Such assumption is obviously not true in this work, and hence we will use the following treatment to overcome such obstacle. Towards this end, denote by C([0, 1]) the set of all continuous functions on [0, 1], we first apply the change of variable to (5.2) \u2013 (5.3) as follows\ninf \u03b3\u2208R+,fi\u2208C([0,1]) \u03b3r(\u03b1, t0, t)p + n\u2211 i=1 \u222b 1 0 fi ( F (i),\u22121 \u2217 (u) ) du+ 1 t0 + t t\u2211 j=\u2212t0+1 V \u03b3t+1 ( G ( t, y, a, F\u22121\u2217 (uj) )) ,\nwhere V \u03b3t+1 ( G ( t, y, a, F\u22121\u2217 (uj) )) = sup\nu\u2208[0,1]n\n( Vt+1 ( G ( t, y, a, F\u22121\u2217 (u) )) \u2212 n\u2211 i=1 fi ( F (i),\u22121 \u2217 (u (i)) ) \u2212 \u03b3dp(u, uj) ) .\nNext, we recall the Weierstrass approximation theorem which indicates that any fi \u25e6 F (i),\u22121\u2217 \u2208 C([0, 1]) can be approximated by polynomials. In addition, the Bernstein polynomials\n\u03b2k,K(u) =\n( K\nk\n) uk(1\u2212 u)K\u2212k, u \u2208 [0, 1], k = 0, . . . ,K,\nform a basis for the space of polynomials of degree K. Also, note that for fixed K and any k = 0, . . . ,K, \u222b\n[0,1] \u03b2k,K(u)du =\n1\nK + 1 .\nHence, the above optimization problem is approximated as\ninf \u03b3\u2208R+,gi,k\u2208R \u03b3r(\u03b1, t0, t)p + n\u2211 i=1 K\u2211 k=0 gi,k K + 1 + 1 t0 + t t\u2211 j=\u2212t0+1 V \u03b3t+1(G(t, y, a, F \u22121 \u2217 (uj)))  , where\nV \u03b3t+1(G(t, y, a, F \u22121 \u2217 (uj))) = sup\nu\u2208[0,1]n\n( Vt+1(G(t, y, a, F \u22121 \u2217 (u)))\u2212 n\u2211 i=1 K\u2211 k=0 gi,k\u03b2k,K(u (i))\u2212 \u03b3dp(u, uj) ) .\nBy including the optimization over feasible controls, the inf-sup problem we need to solve is\ninf a\u2208A,\u03b3\u2208R+,gi,k\u2208R \u03b3r(\u03b1, t0, t)p + n\u2211 i=1 K\u2211 k=0 gi,k K + 1 + 1 t0 + t t\u2211 j=\u2212t0+1 V \u03b3t+1(G(t, y, a, F \u22121 \u2217 (uj)))  , (5.5) where\nV \u03b3t+1(G(t, y, a, F \u22121 \u2217 (uj))) = sup\nu\u2208[0,1]n\n( Vt+1(G(t, y, a, F \u22121 \u2217 (u)))\u2212 n\u2211 i=1 K\u2211 k=0 gi,k\u03b2k,K(u (i))\u2212 \u03b3dp(u, uj) ) .\n(5.6)\nWith regard to designing a numerical algorithm to solve (5.5) \u2013 (5.6), we first note that the inf problem in (5.5) and the sup problem in (5.6) have dimensions m + n \u2217 (K + 1) + 1 and n, respectively. Hence, we have a non-trivial high dimensional inf-sup optimization problem for which a solver using brute force will be extremely inefficient and virtually impossible. On top of the inherent high dimension in optimization, it also requires large amount of computation cost to evaluate 1t0+t \u2211t j=\u2212t0+1 V \u03b3 t+1(G(t, y, a, F \u22121 \u2217 (uj))) given that t0 is decently big. In view of these difficulties, we propose to use the stochastic gradient descent ascent (SGDA) method to overcome the obstacles.\nTo explain the idea of SGDA in our work, for any fixed t \u2208 T \u2032, y \u2208 EY , we denote\nv\u0302t(a, \u03b3, g, u; u\u0302) =\u03b3(r(\u03b1, t0, t) p \u2212 dp(u, u\u0302)) + n\u2211 i=1 K\u2211 k=0 ( gi,k K + 1 \u2212 gi,k\u03b2k,K(u(i)) )\n+ Vt+1(G(t, y, a, F \u22121(u))),\nwhere u\u0302 \u2208 {uj , j = \u2212t0 + 1, . . . , t}. Such formulation comes from the considered loop as follows. Given some (a(l), \u03b3(l), g(l), u(l)), l = 0, 1, . . .,\n1. uniformly simulate u\u0302(l) \u2208 {uj , j = \u2212t0 + 1, . . . , t};\n2. update (a(l), \u03b3(l), g(l), u(l)) as\na(l + 1) = a(l)\u2212 \u03b7(l) \u2202 \u2202a v\u0302t(a(l), \u03b3(l), g(l), u(l); u\u0302(l)), \u03b3(l + 1) = \u03b3(l)\u2212 \u03b7(l) \u2202 \u2202\u03b3 v\u0302t(a(l), \u03b3(l), g(l), u(l); u\u0302(l)), g(l + 1) = g(l)\u2212 \u03b7(l) \u2202 \u2202g v\u0302t(a(l), \u03b3(l), g(l), u(l); u\u0302(l)), u(l + 1) = u(l) + \u03b7(l) \u2202\n\u2202u v\u0302t(a(l), \u03b3(l), g(l), u(l); u\u0302(l)),\nwhere \u03b7(l) denote the step size;\n3. Goto 1.\nThe above loop will stop when there is no improvement of (a(l), \u03b3(l), g(l), u(l)) anymore, and we denote the corresponding number l of iterations as l\u2217.\nTo apply SGDA, one needs to have a functional representation of Vt, t = 1, . . . , T \u22121, such that the above gradients of v\u0302t can be quickly computed. To construct such functional approximation, we first choose N so-called design points yjt , j = 1, . . . , N , at which we solve for Vt(y j t ), j = 1, . . . , N , and then build a regression model V\u0303t based on the training data (y j t , Vt(y j t )), j = 1, . . . , N . For the choice of the regression model, we will use the Gaussian process (GP) with kernel function k(\u00b7, \u00b7) of the Matern-3/2 type. For detailed discussion of GP, one can refer to [RW06]. We also summarize the basic idea of GP in earlier works (cf. [CL21], [BCC20], [CM20], [BC22]).\nWhen it comes to regression, one needs to note that the second component C\u0302 of the state variable y is in general a distribution and hence infinitely dimensional, which cannot be regressed against numerically. To such end, we will approximate each C\u0302 with its first m moments of marginals and covariance among marginals. By doing so, the dimension of the state variable y is reduced to mn+ ( n 2 ) + 1 and we denote the approximating vector by y\u0303.\nThe rationale behind choosing GP with the Matern-3/2 kernel is twofold. On one hand, it is a regression model sophisticated enough to capture the complicated structure of Vt with minimal assumptions, as Matern-3/2 kernel is used for regressing the function that has first order derivative. On the other hand, the gradients of V\u0303t, and in turn of v\u0302t, can be analytically computed which is of particular importance to our implementation. To see this, recall that given yjt , j = 1, . . . , N , the resulting regression model has the following representation\nV\u0303t(y\u0303) = (k(y\u0303, y\u0303 1 t ), . . . ,k(y\u0303, y\u0303 N t ))[K + \u03b5 2I]\u22121(Vt(y 1 t ), . . . , Vt(y N t )) >. (5.7)\nThe above \u03b52I with I being the identity matrix is the perturbation added to the matrix K to ensure that the latter is invertible. The matrix K satisfies that Kij = k(y\u0303 i t, y\u0303 j t ) and\nk(y\u03031, y\u03032) = ( 1 + \u221a 3ds(y\u0303 1, y\u03032) ) exp ( \u2212 \u221a 3ds(y\u0303 1, y\u03032) ) ,\nwhere ds is the scaled Euclidean distance between y 1 and y2 with parameter s:\nd\n(( y\u03031,(1)\ns(1) , . . . ,\ny\u03031,(n)\ns(n)\n) , ( y\u03032,(1)\ns(1) , . . . ,\ny\u03032,(n)\ns(n)\n)) ,\nwhere d(\u00b7, \u00b7) is the usual Euclidean distance. The vector s is called the length scale and fitting a GP model means to use the maximum likelihood method to find the optimal value of s. After V\u0303t is fitted, the product [K+ \u03b52I]\u22121(Vt(y 1 t ), . . . , Vt(y N t )) > in (5.7) is a fixed constant vector (\u03bd1t , . . . , \u03bd N t ).\nTherefore, (5.7) can be rewritten as V\u0303t(y\u0303) = \u2211N j=1 \u03bd j t k(y\u0303, y\u0303 j t ). As a result, gradient of V\u0303t is a linear combination of the gradients of k(y\u0303, y\u0303jt ) and with the explicit formula of k being available, its gradient can therefore be computed analytically. There is no need to stress how important the capability of computing the gradient without any numerical approximation is in a gradient based optimization algorithm. Our solver for problem (5.5) \u2013 (5.6) is summarized as follows. For t = T \u2212 2, . . . , 0,\n1. Assume that Vt+1(y i t+1) and \u03d5 \u2217,\u03b5 t+1(y i t+1), i = 1, . . . , N , are computed. Fit the GP models V\u0303t+1\nand \u03d5\u0303\u2217,\u03b5t+1 by using the training data (y i t+1, Vt+1(y i t+1)), and (y i t+1, \u03d5 \u2217,\u03b5 t+1(y i t+1)), i = 1, . . . , N , respectively.\n2. Choose yit \u2208 EY , i = 1, . . . , N .\n3. For each yit, choose initial guesses (a(0), \u03b3(0), g(0), u(0)), and use SGDA to compute (a(l\u2217), \u03b3(l\u2217), g(l\u2217), u(l\u2217)). Set Vt(y i t) = v\u0302t(a(l \u2217), \u03b3(l\u2217), g(l\u2217), u(l\u2217); u\u0302(l\u2217)), and \u03d5\u2217,\u03b5t (y i t) = a(l \u2217).\n4. Goto 1: start the next recursion for t\u2212 1.\nTo analyze the performance of the computed optimal control \u03d5\u2217,\u03b5, we use forward simulation to estimate the mean terminal loss over the out-of-sample paths. For t = 0, . . . , T \u2212 1,\n1. Draw N \u2032 > 0 i.i.d. Z1t+, . . . , Z N \u2032 t+1 from the true distribution corresponding to F\u2217.\n2. All paths start from the initial y0. The state along path i is updated according to G(t, yit, \u03d5\u0303 \u2217,\u03b5 t (y i t), Z i t+1), i = 1, . . . , N \u2032.\n3. Obtain the terminal state XiT , i = 1, . . . , N \u2032, and compute\nV c := 1\nN \u2032 N \u2032\u2211 i=1 `(XiT )\nas the estimated mean terminal loss.\nIn Section 4.3, we know that there is no complete theoretical result of the comparison between our adaptive robust method based on copula and the approach of using empirical distribution without marginal information. Hence, we will focus on such comparison when presenting our numerical results."
        },
        {
            "heading": "5.2 Numerical Results",
            "text": "In this section, we apply the algorithm described above to the uncertain utility maximization problem. We take d = 2 and consider two different stocks where Zt+1 is the vector of log-returns from time t to t + 1, which follows a multi-dimensional normal distribution. Correspondingly, let Xt be the wealth at time t with the dynamics\nXt = Xt\u22121 ( (1\u2212 \u03d5(1)t \u2212 \u03d5 (2) t )(1 + r) + \u03d5 (1) t e Z (1) t + \u03d5 (2) t e Z (2) t ) .\nThe above \u03d5 (i) t , i = 1, 2, is the proportion of wealth invested in stock i. The constant r and Z (i) t , i = 1, 2, are the interest rate and log-return of stock i, respectively. In addition, we choose the loss function ` such that \u2212` = U which is the exponential utility function. Then, we are effectively facing a utility maximization problem involving two different stocks under model uncertainty.\nWe compare three different types of strategies: 1. adaptive robust control method with known marginals; 2. adaptive robust control method based on empirical distribution without using marginal information; 3. optimal control without uncertainty. We denote by \u03d5\u2217,\u03b5, \u03d5e, and \u03d5tr the corresponding strategies, respectively. We also use V c, V e, and V tr to denote the corresponding estimated expected utility, respectively. In Section 4.3, we find that it is unclear which of \u03d5\u2217,\u03b5 and \u03d5e will perform better when the marginal CDFs are Lipschitz continuous. Hence, we will compare these two strategies for Lipschitz marginals by using numerical results presented in the sequel.\nTo proceed, we take the following values for our parameters: t0 = 400, T = 10, N = N \u2032 = 1000, \u03b1 = 0.1, p = 2, and m = 2. Regarding the true distribution F\u2217, it is bivariate normal with\nmean \u00b5 = (0.09, 0.13) and covariance matrix \u03a3 = (\n0.252 0.85\u00b70.25\u00b70.4 0.85\u00b70.25\u00b70.4 0.42\n) where all numbers are\nannualized. Finally, the annual interest rate is r = 0.02. With T = 10, it means that we consider 10 trading periods in a year.\nTable 1 shows that, in terms of the expected utility, adaptive robust using marginals performs better than the approach without using information of marginals, but worse than the case of knowing the true model. Similar comparison results hold true if we look at the 30% quantile and the minimum value of the terminal wealth. On the contrary, \u03d5e produces the highest variance, 90% quantile, and maximum of the terminal wealth, while \u03d5tr generates the lowest values in these aspects. These observations can be obtained by viewing the box plots in Figure 1. In addition, adaptive robust without information of marginals has the highest mean wealth while knowing the true model gives the lowest value.\nAs we can see, when the investor knows more about the true model, the resulting terminal wealth excels in the risk management aspects such as variance, 30% quantile, and minimum value. Knowing less information of the true model will produce higher mean, 90% quantile, and maximum of the wealth which signal a strategy that is relatively more aggressive and profit seeking. By looking at the expected utility which takes into account both profit seeking and risk aversion, we notice that the more information we know about the model the higher mean utility we obtain. With such numerical results, we conclude that, in general, knowing more about true model leads to a more balanced and less risky optimal strategy."
        }
    ],
    "title": "Data-Driven Nonparametric Robust Control under Dependence Uncertainty",
    "year": 2022
}