{
    "abstractText": "This work introduces a method to select linear functional measurements of a vector-valued time series optimized for forecasting distant timehorizons. By formulating and solving the problem of sequential linear measurement design as an infinite-horizon problem with the timeaveraged trace of the Cram\u00e9r\u2013Rao lower bound (CRLB) for forecasting as the cost, the most informative data can be collected irrespective of the eventual forecasting algorithm. By introducing theoretical results regarding measurements under additive noise from natural exponential families, we construct an equivalent problem from which a local dimensionality reduction can be derived. This alternative formulation is based on the future collapse of dimensionality inherent in the limiting behavior of many differential equations and can be directly observed in the low-rank structure of the CRLB for forecasting. Implementations of both an approximate dynamic programming formulation and the proposed alternative are illustrated using an extended Kalman filter for state estimation, with results on simulated systems with limit cycles and chaotic behavior demonstrating a linear improvement in the CRLB as a function of the number of collapsing dimensions of the system.",
    "authors": [
        {
            "affiliations": [],
            "name": "Helmuth Naumer"
        },
        {
            "affiliations": [],
            "name": "Farzad Kamalabadi"
        }
    ],
    "id": "SP:09596914f507829d4dafc8dfbb1ce3ac5ac10a1d",
    "references": [
        {
            "authors": [
                "Yaser S. Abu-Mostafa",
                "Amir F. Atiya"
            ],
            "title": "Introduction to financial forecasting",
            "venue": "Applied Intelligence,",
            "year": 1996
        },
        {
            "authors": [
                "S.P. Asprey",
                "S. Macchietto"
            ],
            "title": "Designing robust optimal dynamic experiments",
            "venue": "Journal of Process Control,",
            "year": 2002
        },
        {
            "authors": [
                "Benny Avelin",
                "Kaj Nystr\u00f6m"
            ],
            "title": "Neural ODEs as the deep limit of ResNets with constant weights",
            "venue": "Analysis and Applications,",
            "year": 2021
        },
        {
            "authors": [
                "Shaojie Bai",
                "J. Zico Kolter",
                "Vladlen Koltun"
            ],
            "title": "Deep equilibrium models",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Shaojie Bai",
                "Vladlen Koltun",
                "J. Zico Kolter"
            ],
            "title": "Multiscale deep equilibrium models",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "D.P. Bertsekas"
            ],
            "title": "Dynamic Programming and Optimal Control: Approximate Dynamic Programming, volume 2",
            "venue": "Athena Scientific,",
            "year": 2017
        },
        {
            "authors": [
                "D.P. Bertsekas"
            ],
            "title": "Dynamic Programming and Optimal Control, volume 1, chapter 6, pages 296\u2013424",
            "venue": "Athena Scientific,",
            "year": 2017
        },
        {
            "authors": [
                "Steven L. Brunton",
                "Joshua L. Proctor",
                "J. Nathan Kutz"
            ],
            "title": "Discovering governing equations from data by sparse identification of nonlinear dynamical systems",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2016
        },
        {
            "authors": [
                "Lijuan Cao",
                "Francis E.H Tay"
            ],
            "title": "Financial forecasting using support vector machines",
            "venue": "Neural Computing & Applications,",
            "year": 2001
        },
        {
            "authors": [
                "F.P. Casey",
                "D. Baird",
                "Q. Feng",
                "R.N. Gutenkunst",
                "J.J. Waterfall",
                "C.R. Myers",
                "K.S. Brown",
                "R.A. Cerione",
                "J.P. Sethna"
            ],
            "title": "Optimal experimental design in an epidermal growth factor receptor signalling and down-regulation model",
            "venue": "IET Systems Biology,",
            "year": 2007
        },
        {
            "authors": [
                "Kathryn Chaloner",
                "Isabella Verdinelli"
            ],
            "title": "Bayesian experimental design: A review",
            "venue": "Statistical Science,",
            "year": 1995
        },
        {
            "authors": [
                "Jiahao Chen",
                "Jarrett Revels"
            ],
            "title": "Robust benchmarking in noisy environments",
            "venue": "arXiv preprint,",
            "year": 2016
        },
        {
            "authors": [
                "Miles Cranmer",
                "Sam Greydanus",
                "Stephan Hoyer",
                "Peter Battaglia",
                "David Spergel",
                "Shirley Ho"
            ],
            "title": "Lagrangian neural networks",
            "venue": "In ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations,",
            "year": 2020
        },
        {
            "authors": [
                "Raj Dandekar",
                "Vaibhav Dixit",
                "Mohamed Tarek",
                "Aslan Garcia-Valadez",
                "Christopher Rackauckas"
            ],
            "title": "Bayesian neural ordinary differential equations",
            "venue": "arXiv preprint,",
            "year": 2021
        },
        {
            "authors": [
                "Simon Danisch",
                "Julius Krumbiegel"
            ],
            "title": "Makie.jl: Flexible high-performance data visualization for Julia",
            "venue": "Journal of Open Source Software,",
            "year": 2021
        },
        {
            "authors": [
                "Holger Dette"
            ],
            "title": "Designing experiments with respect to \u2018standardized\u2019 optimality criteria",
            "venue": "Journal of the Royal Statistical Society. Series B (Methodological),",
            "year": 1997
        },
        {
            "authors": [
                "Emilien Dupont",
                "Arnaud Doucet",
                "Yee Whye Teh"
            ],
            "title": "Augmented neural ODEs",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "M. Ehrendorfer"
            ],
            "title": "The Liouville equation and its potential usefulness for the prediction of forecast",
            "venue": "skill. part i: Theory. Monthly Weather Review,",
            "year": 1994
        },
        {
            "authors": [
                "M. Ehrendorfer"
            ],
            "title": "The Liouville equation and atmospheric predictability",
            "year": 2006
        },
        {
            "authors": [
                "N. Benjamin Erichson",
                "Lionel Mathelin",
                "J. Nathan Kutz",
                "Steven L. Brunton"
            ],
            "title": "Randomized dynamic mode decomposition",
            "venue": "SIAM Journal on Applied Dynamical Systems,",
            "year": 2019
        },
        {
            "authors": [
                "J. Fohring",
                "E. Haber"
            ],
            "title": "Adaptive a-optimal experimental design for linear dynamical systems",
            "venue": "SIAM/ASA Journal on Uncertainty Quantification,",
            "year": 2016
        },
        {
            "authors": [
                "William Gilpin"
            ],
            "title": "Deep reconstruction of strange attractors from time series",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Davis Gilton",
                "Gregory Ongie",
                "Rebecca Willett"
            ],
            "title": "Deep equilibrium architectures for inverse problems in imaging",
            "venue": "arXiv preprint,",
            "year": 2021
        },
        {
            "authors": [
                "Petr H\u00e1jek",
                "Michal Johanis"
            ],
            "title": "Smooth approximations",
            "venue": "Journal of Functional Analysis,",
            "year": 2010
        },
        {
            "authors": [
                "Xun Huan",
                "Youssef M. Marzouk"
            ],
            "title": "Sequential Bayesian optimal experimental design via approximate dynamic programming",
            "venue": "arXiv preprint,",
            "year": 2016
        },
        {
            "authors": [
                "E. Kaiser",
                "J.N. Kutz",
                "S.L. Brunton"
            ],
            "title": "Sparse identification of nonlinear dynamics for model predictive control in the low-data limit",
            "venue": "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences,",
            "year": 2018
        },
        {
            "authors": [
                "Hassan K. Khalil"
            ],
            "title": "Nonlinear Systems. Prentice-Hall",
            "venue": "Upper Saddle River, NJ,",
            "year": 2002
        },
        {
            "authors": [
                "John M. Lee"
            ],
            "title": "Introduction to Riemannian Manifolds",
            "year": 2018
        },
        {
            "authors": [
                "E.L. Lehmann",
                "George Casella"
            ],
            "title": "Theory of Point Estimation",
            "year": 1998
        },
        {
            "authors": [
                "Benjamin Letham",
                "Portia A. Letham",
                "Cynthia Rudin",
                "Edward P. Browne"
            ],
            "title": "Prediction uncertainty and optimal experimental design for learning dynamical systems",
            "venue": "Chaos: An Interdisciplinary Journal of Nonlinear Science,",
            "year": 2016
        },
        {
            "authors": [
                "Yingbo Ma",
                "Vaibhav Dixit",
                "Michael J Innes",
                "Xingjian Guo",
                "Chris Rackauckas"
            ],
            "title": "A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions",
            "year": 2021
        },
        {
            "authors": [
                "Sonia Mart\u0131\u0301nez",
                "Francesco Bullo"
            ],
            "title": "Optimal sensor placement and motion coordination for target",
            "venue": "tracking. Automatica,",
            "year": 2006
        },
        {
            "authors": [
                "Daniel A. Messenger",
                "David M. Bortz"
            ],
            "title": "Weak SINDy for partial differential equations",
            "venue": "Journal of Computational Physics,",
            "year": 2021
        },
        {
            "authors": [
                "Francesco Mezzadri"
            ],
            "title": "How to generate random matrices from the classical compact groups",
            "venue": "arXiv preprint,",
            "year": 2006
        },
        {
            "authors": [
                "Carl N. Morris"
            ],
            "title": "Natural Exponential Families",
            "venue": "ISBN 9780471667193",
            "year": 2006
        },
        {
            "authors": [
                "Chirag Pabbaraju",
                "Ezra Winston",
                "J Zico Kolter"
            ],
            "title": "Estimating Lipschitz constants of monotone deep equilibrium models",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "C. Penland",
                "T. Magorian"
            ],
            "title": "Prediction of Ni\u00f1o 3 sea surface temperatures using linear inverse modeling",
            "venue": "Journal of Climate,",
            "year": 1993
        },
        {
            "authors": [
                "Joshua L. Proctor",
                "Steven L. Brunton",
                "J. Nathan Kutz"
            ],
            "title": "Dynamic mode decomposition with control",
            "venue": "SIAM Journal on Applied Dynamical Systems,",
            "year": 2016
        },
        {
            "authors": [
                "Christopher Rackauckas",
                "Qing Nie"
            ],
            "title": "Differentialequations.jl\u2013a performant and featurerich ecosystem for solving differential equations in Julia",
            "venue": "Journal of Open Research Software,",
            "year": 2017
        },
        {
            "authors": [
                "M. Raissi",
                "P. Perdikaris",
                "G.E. Karniadakis"
            ],
            "title": "Physicsinformed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "venue": "Journal of Computational Physics,",
            "year": 2019
        },
        {
            "authors": [
                "Maziar Raissi",
                "George Em Karniadakis"
            ],
            "title": "Hidden physics models: Machine learning of nonlinear partial differential equations",
            "venue": "Journal of Computational Physics,",
            "year": 2017
        },
        {
            "authors": [
                "Juri Ranieri",
                "Amina Chebira",
                "Martin Vetterli"
            ],
            "title": "Nearoptimal sensor placement for linear inverse problems",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2014
        },
        {
            "authors": [
                "Ellen Clancy",
                "Alberto Arribas",
                "Shakir Mohamed"
            ],
            "title": "Skilful precipitation nowcasting using deep generative models of radar",
            "venue": "Nature, 597(7878):672\u2013677,",
            "year": 2021
        },
        {
            "authors": [
                "J. Revels",
                "M. Lubin",
                "T. Papamarkou"
            ],
            "title": "Forwardmode automatic differentiation in Julia",
            "venue": "arXiv preprint,",
            "year": 2016
        },
        {
            "authors": [
                "Peter J. Schmid"
            ],
            "title": "Dynamic mode decomposition of numerical and experimental data",
            "venue": "Journal of Fluid Mechanics,",
            "year": 2010
        },
        {
            "authors": [
                "Jack Sherman",
                "Winifred J. Morrison"
            ],
            "title": "Adjustment of an Inverse Matrix Corresponding to a Change in One Element of a Given Matrix",
            "venue": "The Annals of Mathematical Statistics,",
            "year": 1950
        },
        {
            "authors": [
                "Gerald L. Smith",
                "Stanley F. Schmidt",
                "Leonard A. McGee"
            ],
            "title": "Application of statistical filtering theory to the optimal estimation of position and velocity on board a circumlunar vehicle",
            "venue": "Technical report,",
            "year": 1962
        },
        {
            "authors": [
                "Steven H. Strogatz"
            ],
            "title": "Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry and Engineering",
            "year": 2015
        },
        {
            "authors": [
                "D.M. Titterington"
            ],
            "title": "Aspects of optimal design in dynamic systems",
            "venue": "Technometrics, 22(3):287\u2013299,",
            "year": 1980
        },
        {
            "authors": [
                "Mark K. Transtrum",
                "Peng Qiu"
            ],
            "title": "Optimal experiment selection for parameter estimation in biological differential equation models",
            "venue": "BMC Bioinformatics,",
            "year": 2012
        },
        {
            "authors": [
                "L.N. Trefethen",
                "D. Bau"
            ],
            "title": "Numerical Linear Algebra, page 59",
            "year": 1997
        },
        {
            "authors": [
                "Matthew O. Williams",
                "Ioannis G. Kevrekidis",
                "Clarence W. Rowley"
            ],
            "title": "A data\u2013driven approximation of the koopman operator: Extending dynamic mode decomposition",
            "venue": "Journal of Nonlinear Science,",
            "year": 2015
        },
        {
            "authors": [
                "Themistoklis C. Xygkis",
                "George N. Korres",
                "Nikolaos M. Manousakis"
            ],
            "title": "Fisher information-based meter placement in distribution grids via the d-optimal experimental design",
            "venue": "IEEE Transactions on Smart Grid,",
            "year": 2018
        },
        {
            "authors": [
                "Linan Zhang",
                "Hayden Schaeffer"
            ],
            "title": "On the convergence of the SINDy algorithm",
            "venue": "Multiscale Modeling & Simulation,",
            "year": 2019
        },
        {
            "authors": [
                "Helmuth Naumer",
                "Farzad"
            ],
            "title": "Kamalabadi That is, we can represent the space as the product of the manifoldM and an M \u2212K dimensional vectorspace representing the normals of the manifold. If M is smooth, such a neighborhood always exists by the tubular neighborhood theorem (Lee, 2018)",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "This work introduces a method to select linear functional measurements of a vector-valued time series optimized for forecasting distant timehorizons. By formulating and solving the problem of sequential linear measurement design as an infinite-horizon problem with the timeaveraged trace of the Crame\u0301r\u2013Rao lower bound (CRLB) for forecasting as the cost, the most informative data can be collected irrespective of the eventual forecasting algorithm. By introducing theoretical results regarding measurements under additive noise from natural exponential families, we construct an equivalent problem from which a local dimensionality reduction can be derived. This alternative formulation is based on the future collapse of dimensionality inherent in the limiting behavior of many differential equations and can be directly observed in the low-rank structure of the CRLB for forecasting. Implementations of both an approximate dynamic programming formulation and the proposed alternative are illustrated using an extended Kalman filter for state estimation, with results on simulated systems with limit cycles and chaotic behavior demonstrating a linear improvement in the CRLB as a function of the number of collapsing dimensions of the system."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "There is a long history of optimal experimental design in statistics. In such work, rather than directly design estimators, sequences of experiments are designed to optimize some information criteria. This criteria in turn implies the existence of accurate estimators. These optimization objectives often take the form of functions of the inverse Fisher\nProceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS) 2023, Valencia, Spain. PMLR: Volume 206. Copyright 2023 by the author(s).\ninformation matrix such as the alphabet optimality criteria including minimizing the trace, determinant, or maximum eigenvalue of the matrix (Chaloner and Verdinelli, 1995; Dette, 1997). In the past two decades, a significant motivation of optimal experimental design has been found in optimal sensor placement (Mart\u0131\u0301nez and Bullo, 2006; Ranieri et al., 2014; Xygkis et al., 2018). In control theory, sequential experimental design appears in the design of informative inputs to a parameterized system for the purpose of identifying the unknown parameters (Fohring and Haber, 2016; Asprey and Macchietto, 2002; Huan and Marzouk, 2016; Titterington, 1980). Despite this history, it has recently been observed that optimizing for correct system parameters often produces poor forecasts of the future system state, and that predictive performance should be considered directly (Casey et al., 2007; Transtrum and Qiu, 2012; Letham et al., 2016). These works typically assume the ability to control the system itself, observing multiple full trajectories and driving the system into informative regions of the state space. Contrary to this, in many time-series forecasting problems, we only observe a single trajectory of which we have no control.\nTime series forecasting is a long-studied problem often motivated by numerous applications such as weather prediction (Penland and Magorian, 1993; Ehrendorfer, 1994, 2006), finance (Abu-Mostafa and Atiya, 1996; Cao and Tay, 2001), and control (Bertsekas, 2017b). Oftentimes, algorithms focus only on short-term predictions, intrinsically coupled with state estimation as seen in classical techniques such as the Kalman filter and particle filter. In the extreme short-term, there have been significant developments in recent years applying machine learning tools such as generative adversarial networks to form the predictions (Shi et al., 2017; Ravuri et al., 2021).\nOn the other extreme timescale, there has been growing interest in reconstructing information about the limiting behavior of the time series from data. The approaches vary dramatically from the application of embeddings theorems to reconstruct the shape of attractors from lowerdimensional measurements (Gilpin, 2020), to regression techniques that learn sparse governing equations (Brunton et al., 2016; Kaiser et al., 2018; Zhang and Schaef-\nar X\niv :2\n30 3.\n15 40\n7v 1\n[ cs\n.L G\n] 2\n7 M\nar 2\n02 3\nfer, 2019; Messenger and Bortz, 2021), to Koopman operator and Dynamic Mode Decomposition (DMD) based techniques which form inherently linear approximations in higher dimensional spaces (Schmid, 2010; Williams et al., 2015; Proctor et al., 2016; Erichson et al., 2019). Furthermore, the scientific computing community has been recently experimenting with using neural networks to approximate the solutions of differential equations through physics-informed neural networks (Raissi et al., 2019) as a more computationally efficient alternative to Gaussian process regression (Raissi and Karniadakis, 2018).\nEven when the underlying data is not governed by differential equations, many modern techniques seek to learn a differential equation which well-represents the phenomena of interest as a new general form of regression \u2014 enabling the application of dynamical systems tools to broader learning problems. While some of these techniques are focused on using the expressive nature of differential equations in lieu of neural networks (Chen et al., 2018; Dupont et al., 2019; Dandekar et al., 2021; Massaroli et al., 2020; Avelin and Nystro\u0308m, 2021), others instead use the extensive understanding of differential equations to constrain the geometry of the estimates based on integrals of motion (Greydanus et al., 2019; Cranmer et al., 2020). Furthermore, there have been attempts to construct implicitly deep networks by fitting the fixed points of an ODE in deep equilibrium models (Bai et al., 2019, 2020; Pabbaraju et al., 2021; Gilton et al., 2021).\nA fortunate consequence of this trend in modeling is that the generative assumptions involving differential equations often implicitly imbue the future with significant structure. Even Lyapunov stability, one of the weakest forms, immediately implies that the feasible set of future points monotonically shrinks over time (Khalil, 2002). In many cases though, this additional structure takes the form of the guarantee that the long-term behavior is actually confined to a lower dimensional space than the ambient dimensionality. In this work, we propose methods based on this dimensionality collapse for informed data collection in forecasting time series modeled by differential equations.\nOur key observation is that, by incorporating the future structure of the dynamical system into the present, many linear measurements become entirely uninformative \u2014 no meaningful prediction regarding distant time-horizons can be made from the observation. By avoiding these uninformative measurements in favor of observing the informative subspace, we introduce a method for reducing the Crame\u0301r\u2013 Rao lower bound (CRLB) for forecasting. This reduction scales linearly with the dimensionality of the uninformative space, reducing the errors in estimation resulting from embedding a low-dimensional manifold of feasible data in a high-dimensional ambient observation space."
        },
        {
            "heading": "Contributions",
            "text": "\u2022 We analyze the problem of sequential linear measurement design in systems governed by differential equations with low-dimensional limiting behavior, providing both theoretical results and practical algorithms.\n\u2022 We prove that the time-averaged infinite horizon optimal sampling problem is equivalent to maximizing the sum ofK squared inner products subject to a norm constraint, where K is the dimensionality of the limiting behavior, thereby reducing the dimensionality of the problem.\n\u2022 We specialize our results to construct a computationally efficient solution to the problem when the system converges to an isolated limit cycle.\n\u2022 We demonstrate the algorithm on simulated chaotic systems and limit cycles systems: illustrating the broad applicability of the model assumptions and the linear improvement of the CRLB as a function of the number of collapsing dimensions."
        },
        {
            "heading": "2 PROBLEM FORMULATION",
            "text": "In this work, we construct a method to optimize a policy for linear functional sampling which minimizes the CRLB for forecasting future values of the time series. There are many closely related variations of this problem, all built upon the same theme. We begin this section by defining the model assumptions, before explicitly defining the variations of the problem solved in the manuscript. The section concludes with a brief note on the dynamic programming approach to the problems, which represent a clear baseline.\nSystem Model This work analyzes the state space model of the form\nx\u0307 = f(x), (1) yi = \u3008ui, x\u03c4i + \u03bei\u3009 (2)\nwhere x \u2208 RM is the state with temporal derivative x\u0307 = dxdt , f : R\nM \u2192 RM is Lipschitz on some domain containing the system trajectory with a Lipschitz continuous derivative, yi is the i\u2019th measurement, x\u03c4i is the state at time \u03c4i, \u3008ui, \u00b7\u3009 represents the i\u2019th chosen measurement functional based on the Euclidean inner product, and \u03bei is additive noise during observation i, independent between timesteps with further assumptions to be described in detail in the following paragraph. In general, we can combine unknown constant parameters of the dynamical system with the state. The Lipschitz dynamics constraint is common when working with differential equations because it enables the existence and uniqueness theorem, guaranteeing a unique solution to a differential equation for a given initial state (Khalil, 2002). The uniqueness of trajectories immediately implies the existence of a set of time-advancing\nfunctions \u03d5\u03c4 : RM \u2192 RM which satisfies the semigroup property \u03d5\u03c41 \u25e6 \u03d5\u03c42 = \u03d5\u03c41+\u03c42 , where \u25e6 represents function composition. Such a group of functions is known as the flow of the dynamical system. We denote the state at time \u03c4 as x\u03c4 , and the flow is defined such that x\u03c4 = \u03d5\u03c4 (x0) for any given initial state x0. If additionally f is differentiable in x, then \u03d5\u03c4 can be directly shown to be continuously differentiable in x for all \u03c4 through the construction of the sensitivity equation (Khalil, 2002). Differentiability is only a very mild additional assumption for Lipschitz dynamical systems, as Lipschitz functions from RN onto RN can always be uniformly approximated by smooth Lipschitz functions [see, for instance, (Ha\u0301jek and Johanis, 2010) for a more general case].\nMeasurement Family The family of measurements is defined through two steps. First, we assume that the state of the system represents some physically meaningful quantities for which we have some method of controlled linear functional observation under additive noise, as shown in Equation (2). Linear functional observations capture many common types of measurements. If our state space is extended, for instance, to almost everywhere bounded continuous functions, i.e. (C(\u2126), \u2016\u00b7\u2016\u221e), then line integrals representing tomography and Dirac delta functions representing discrete sensor placement both exist in our measurement family. Furthermore, in finite dimensional spaces, linear combinations of measurements represent common applications such as beamforming or discretized versions of the previous continuous examples.\nWe further assume that each \u03bei is in a natural exponential family (NEF). A random variable \u03be is said to be in a NEF if the probability density function can be written as\np(\u03be; \u03b8) = exp{\u03b8>\u03be \u2212A(\u03b8) +B(\u03be)} (3)\nwhere A is the log-partition function, \u03b8 is an unknown parameter vector, and B is the log-base function. Many common distributions can be reparameterized into this form, such as Gaussian, Gamma, or Poisson distributions (Morris, 2006). Note that the elements of the noise vector need not come from the same probability distribution, nor even the same family of distributions. For instance, one element could represent Gaussian noise, while another could be Poisson noise.\nForecasting Bound Objective The CRLB is a wellknown matrix inequality for the covariance of unbiased estimators. While a full description is provided in Appendix B, we briefly describe the key properties in this section. Through the well-known decomposition of mean squared error (MSE) into the sum of squared bias and variance, MSE = E [ \u2016x\u0302\u2212 E[x\u0302]\u201622 ] for all x\u0302 such that E[x\u0302\u2212 x] = 0. By expressing the squared norm as \u2016x\u0302 \u2212 E[x\u0302]\u201622 = (x\u0302 \u2212 E[x\u0302])>(x\u0302 \u2212 E[x\u0302]) and applying the cyclic permutation invariance and linearity of the trace, we observe that the MSE is lower bounded as\nE[\u2016x\u0302\u2212 x\u201622] = Tr ( E[(x\u0302\u2212 E[x\u0302])(x\u0302\u2212 E[x\u0302])>] ) (4)\n= Tr (\u03a3x\u0302) \u2265 Tr( \u00af \u03a3), (5)\nwhere \u03a3x\u0302 is the covariance of x\u0302 and \u00af \u03a3 is the CRLB, and Tr denotes the trace of a matrix. By considering the future state to be the unknown parameter, the same bound may be applied to forecasting. In forecasting deterministic Lipschitz dynamical systems based on measurements in exponential families of random variables, the CRLB undergoes the linear transformation\n\u00af \u03a3\u03c4 =\n[ d\u03d5\u03c4x0 ] \u00af \u03a30 [ d\u03d5\u03c4x0 ]> , (6)\nwhere \u00af \u03a3\u03c4 denotes the CRLB for predicting the state at time \u03c4 , \u00af \u03a30 denotes the CRLB for estimating the current state, and d\u03d5\u03c4x0 represents the differential of \u03d5 \u03c4 at x0. Brackets have been included to emphasize that d\u03d5\u03c4x0 is a matrix and represents the Jacobian of the flow. This transformation comes directly from the observation that advancing the state forward in time is a diffeomorphic reparameterization of the probability distribution (Lehmann and Casella, 1998).\nWe assert that in many stable systems, d\u03d5\u03c4x0 becomes approximately low-rank as \u03c4 grows large, and thus we can consider optimal data collection to be done by making measurements which minimize\n\u00af \u03a30 along the non-zero modes of\nthe Jacobians. This low-rank structure occurs due to systems converging to lower-dimensional limiting spaces. In Table 1, we provide a number of examples of dynamical systems with their ambient space and limiting space. In the most extreme case, the heat equation reduces from a Sobolev space W 1,2(\u2126), which is countably infinite, to the real line which is one dimensional. Full system definitions are provided in Appendix A.\nMeasurement Optimization Representing the expected squared magnitude of the error of potential estimators, we consider our cost to be the trace of the CRLB. We consider both the time averaged cost which is applicable to problems such as limit cycles, as well as a discounted cost formulation more strongly applicable to chaotic dynamics due to the exponential growth of the CRLB based on the largest Lyapunov exponent (Bertsekas, 2017a; Strogatz, 2015).\nTo simplify the computational aspects while retaining the meaningful structure, we approximate our cost through sampling. Then, we have the following two infinite-horizon dynamic programming problems, where \u03b3 represents the discount factor and S represents the set of indices for the measurement times.\nProblem 1 (Discounted Cost Optimal Design).\narg min {ui}i\u2208S lim N\u2192\u221e N\u2211 j=1 \u03b3j Tr ( \u00af \u03a3\u03c4j ({ui}i\u2208S) ) (7)\nProblem 2 (Average Cost Optimal Design).\narg min {ui}i\u2208S lim N\u2192\u221e\n1\nN N\u2211 j=1 Tr ( \u00af \u03a3\u03c4j ({ui}i\u2208S) ) (8)\nBoth discounted and average cost infinite-horizon problems are well-studied in stochastic control and in reinforcement learning, where numerous variants of value and policy iteration are applied (Bertsekas, 2017a).\nAn important note is that in unstable and chaotic systems, we still observe an approximate low dimensionality. Consider a system for which the two largest eigenvalues of d\u03d5\u03c4 are \u03bb1, \u03bb2 > 1. Without additional sampling, the ratio of the two largest eigenvalues of the geometric sum\u2211 j \u03b3 jd\u03d5\u03c4j in the discounted cost formulation will become\n1\u2212 \u03bb2\u03b3 1\u2212 \u03bb1\u03b3 . (9)\nThere always exists a discount factor \u03b3 < 1 for which this gap becomes arbitrarily large. Hence, there will always be some discounted cost formulation for which the cost matrix corresponding to the CRLB is approximately singular.\nDynamic Programming Formulation The standard formulation to infinite-horizon discounted and average cost problems is through the Bellman equation, enabling common algorithms such as value iteration and policy iteration. For a known state, the discounted cost Bellman equation becomes\nx+ = \u03d5 \u03c4 (x)\n\u00af \u03a3+(u) = [d\u03d5 \u03c4 x] ( \u00af \u03a3\u22121 + \u2016u\u2016\u22122\u039b\u03c3uu >)\u22121 [d\u03d5\u03c4x]> J(x,\n\u00af \u03a3) = Tr \u00af \u03a3 + \u03b3max u\u2208A {J (x+, \u00af \u03a3+(u))} ,\n(10)\nwhere x+ and \u00af \u03a3+ represent the updated state and CRLB respectively, \u2016u\u20162\u039b\u03c3 = u >\u039b\u03c3u represents the squared norm induced by the measurement noise covariance matrix \u039b\u03c3 , J represents the value function, and A denotes the set of possible normalized measurements functionals (Bertsekas, 2017a). The update to the CRLB comes from the total Fisher information of two independent observations being the sum of the Fisher information matrices. The CRLB update in Equation (10) comes directly from the form of the Fisher Information in Theorem 3.5.\nTo apply most common iterative algorithms for solving the Bellman equation, the state space must be discretized. Without strengthening the assumptions beyond the typical, already asserted, dynamical systems assumptions, the number of required samples can be shown to grow exponentially with the dimensionallity of the system. As a baseline in this work, we include a local-averaging approximation, the details of which including sample complexity are available in Appendix C of the supplemental information."
        },
        {
            "heading": "3 DIMENSIONALITY REDUCTION TECHNIQUE",
            "text": "The computational cost of the dynamic programming approach with sampled state space approximation becomes prohibitively expensive as the ambient dimensionality of the system grows (See Appendix C). However, the future of a dynamical system will often be low dimensional, and in many cases approximately one dimensional. In this section, we analyze the problem when the governing dynamical system converges to a low dimensional limit set, enabling a computationally efficient alternative to the dynamic programming formulation for the average cost formulation. We then briefly discuss the extension to arbitrary low-dimensional embedded limit sets. While proofs for all results appear in Appendix D, we include numerous lemmas to aid in the exposition.\nThe core ideas of this section can be seen in Figure 1 applied to the Van Der Pol oscillator, a common example of a system exhibiting a limit cycle. In all panels, the plot axes represent the state of the 2D system. In panels A and B, we see the vector field and some example trajectories of system. Panel D illustrates \u03d5\u221e := lim\u03c4\u2192\u221e \u03d5\u03c4 computed numerically, where the color indicates a representation of the phase along the limit cycle. As the mapping \u03d5\u221e illustrated in panel D maps onto a one-dimensional space in a smooth manner outside of the origin, the Jacobian of the limiting flow in the ambient space is at most rank 1. The row space of d\u03d5\u221ex is plotted in panel C, representing the subspace that does not vanish as time goes to infinity. Our proposed method seeks to minimize the CRLB with respect to this subspace.\nIn Section 3.1, we introduce a series of statements char-\nacterizing the Fisher information matrix of the state vector for a single measurement of the form described in Equation (2). We show that the contribution of each measurement is, under a mild condition, the outer product of the measurement vector u, normalized by a norm defined by the noise distribution covariance matrix. Then, in Section 3.2 we show that this matrix structure enables a simple reformulation of the infinite horizon objective in order to simplify the problem of sequential optimal experimental design for forecasting."
        },
        {
            "heading": "3.1 Linear Measurements And Fisher Information",
            "text": "In this section, we show that independent NEFs preserve essential structures under a weighted average, resulting in a simple expression for the Fisher information of a linear functional measurement.\nFirst, we must observe that the weighted average of independent random variables in NEFs is itself in another NEF.\nLemma 3.1 (Proof: See Lemma D.1). Given a finite set of independent random variables {\u03be(i)} in NEFs with logpartition functions {Ai}, parameters {\u03b8i}, and a set of real-valued weights {\u03b1i}, then \u03be\u0304 = \u2211 i \u03b1i\u03be(i) is in a NEF with a log partition function\nA(\u03b8) := \u2211 i Ai (\u03b8 + \u03b1i\u03b8i) . (11)\nWhile we still lack a significant amount of knowledge regarding the specific distribution, fundamental properties of the log-partition function allow us to directly compute the\n\u00b5 \u00b5\u0304\n\u03b8 \u03b8\u0304\nh\ng\u22121{g\u22121i }\nh\nT\nFisher information of the observation about the parameter in the new family of probability distribution.\nLemma 3.2 (Proof: See Lemma D.2). The Fisher information of a random variable in a NEF is the variance of the random variable.\nThe remaining task is to relate the Fisher information about the new parameter to the Fisher information regarding the mean values of the original distributions. The connections between the key parameters of interest are illustrated in the commutative diagram shown in Figure 2. In the illustration, \u00b5 represents the mean of the noise vector \u03be, \u00b5\u0304 represents the mean of \u03be\u0304, \u03b8 represents the parameter vector of \u03be, and \u03b8\u0304 represents the parameter of \u03be\u0304 in the new model family. We can immediately observe h : \u00b5 7\u2192 \u3008u, \u00b5\u3009 by construction, and g : \u03b8 7\u2192 \u2202\u2202\u0398A(\u0398) \u2223\u2223 \u0398=\u03b8\nwith the inverse denoted g\u22121. Next, gi and g are defined identically, but for \u03be(i) rather than \u03be\u0304. The diagram commutes, and so we denote T to be the implicitly defined mapping from \u00b5 to \u03b8\u0304.\nLemma 3.3 (Proof: See Lemma D.3). The diagram in Figure 2 commutes for any vector \u03be of independent random variables from NEFs.\nBefore using the above quantities, we need to establish when g\u22121 exists. While full proofs are available in the appendix, invertibility comes from proving g is strictly monotonic.\nLemma 3.4 (Proof: See Lemma D.4). Assume the logpartition function A of a NEF is twice differentiable and that the second moment of the associated random variable exists. Then the inverse of g(\u03b8) := \u2202\u2202\u0398A(\u0398) \u2223\u2223 \u0398=\u03b8\nexists if and only if the random variable is non-degenerate for almost all \u03b8.\nFinally, observe that T is an injective function, and is thus invertible on the image. Furthermore, while g\u22121i is model specific, the Jacobian is directly related to the Fisher information. By recalling that Jacobian of gi is the Fisher information of the probability distribution in the family, we can conclude the following theorem as the result of a reparameterization by T\u22121.\nTheorem 3.5 (Proof: See Theorem D.5). Suppose \u03be is a vector of independent random variables from NEFs with twice differentiable log-partition functions, mean vector \u00b5, and a diagonal covariance matrix \u039b\u03c3 . Then the Fisher in-\nformation of the observation \u3008u, \u03be\u3009 is\nI(\u00b5) = uu>\nu>\u039b\u03c3u (12)\nAs \u2016u\u2016\u039b\u03c3 = \u221a u>\u039b\u03c3u is a valid norm, we additionally immediately observe that the Fisher information is invariant to the scaling of the measurement functional. This corollary allows us to restrict our search for informative measurements to unit spheres.\nCorollary 3.6 (Proof: See Corollary D.6). The Fisher information for state estimation under independent noise is invariant to the scaling of the linear functional.\nFinally, when the noise is identically distributed, the form of the Fisher information matrix simplifies further.\nCorollary 3.7 (Proof: See Corollary D.7). Suppose the elements of the noise vector are i.i.d. with variance \u03c32. Then\nI(\u00b5) = \u03c3\u22122 uu>\n\u2016u\u201622 (13)"
        },
        {
            "heading": "3.2 Transporting the CRLB Through Time",
            "text": "We now use the form of the Fisher information matrix in Theorem 3.5 to construct an alternative optimization objective in Theorem 3.9 with the same solution as the original infinite-horizon optimal experimental design problem. We observe that this reformulation implies the existence of local informative subspaces. Finally, we show that when the system converges to a one dimensional space, the reformulation can be solved exactly.\nA key requirement for this analysis is a notion of stability of the nullspace of the Jacobian of the flow \u03d5\u03c4 . For this lemma, sensitivities to normal perturbations in the neighborhood of the attracting manifold must decay monotonically. This allows the construction of an M \u2212 K dimensional vectorspace at each x, commonly called a vector bundle, for which the local sensitivity of the flow converges to zero for all vectors.\nLemma 3.8 (Proof: See Lemma D.8). If the system in Equation (1) converges to a K-dimensional smooth manifold M such that there exists some \u03b1 > 0 for which v> ( [dfx] + [dfx] > ) v + \u03b1\u2016v||2 < 0 for each v \u2208 T\u22a5p M normal to the manifold at each p \u2208 M, then there exists an M \u2212K dimensional subspace S(x0) \u2282 RM for which[ d\u03d5\u03c4x0 ] u\u2192 0 as \u03c4 \u2192\u221e for each u \u2208 S(x0).\nWe now introduce the main theorem in this work. By recalling that when a probability distribution is reparameterized the CRLB undergoes a linear transformation based on the Jacobian of the reparameterization, previously shown in Equation (6), the information in measurements is restricted to that contained in a K-dimensional subspace.\nTheorem 3.9 (Proof: See Theorem D.9). Suppose the state space model in Equations (1) and (2) with noise satisfying the assumptions in Theorem 3.5 converges to a Kdimensional smooth manifold such that the Jacobian of the limiting flow is rank K. Then the linear functional which minimizes the CRLB for prediction in the infinite-horizon average cost formulation is the solution of\narg max u:\u2016u\u2016(\u039b\u03c3+\n\u00af \u03a3)=1\nK\u2211 i=1 \u03b1i\u3008vi, u\u30092 \u00af \u03a3 (14)\nfor some {\u03b1i}, where vi is the set of right singular vectors of the Jacobian of the limiting flow around the current state with nonzero singular vectors,\n\u00af \u03a3 is the CRLB for es-\ntimating the current state based on the past measurements, \u3008v, u\u3009\n\u00af \u03a3 = v > \u00af \u03a3u, and \u2016ui\u2016(\u039b\u03c3+ \u00af \u03a3) =\n\u221a u>(\u039b\u03c3 +\n\u00af \u03a3)u.\nIt is worth noting that this problem reformulation additionally holds for minimizing the trace of the covariance of biased estimators, as the bias introduces an additional linear transformation on the low-dimensional subspace (Lehmann and Casella, 1998). The {\u03b1i} coefficients become dependent on the bias of the estimator, but dimensionality reduction insights still hold. Through Lagrange multipliers, we can compute the informative subspace exactly.\nCorollary 3.10 (Proof: See Corollary D.10). Under the assumptions of Theorem 3.9, the optimal measurement vector exists in the subspace\nSpan {\n( \u00af \u03a3 + \u039b\u03c3) \u22121 \u00af \u03a3vi }K i=1 . (15)\nWe can consider this to be a local informative subspace, or an informative vector bundle. By further observing that the information content is invariant to scaling of the measurement vector, we can construct an exact solution to the time-averaged infinite-horizon optimal experimental design problem.\nCorollary 3.11 (Proof: See Corollary D.11). If, in addition to the assumptions of Theorem 3.9, the dynamical system converges to an isolated limit cycle, then\nu = ( \u00af \u03a3 + \u039b\u03c3) \u22121 \u00af \u03a3v (16)\nis an optimal measurement vector, where v is the right singular vector.\nAt this point, it is worth considering practical issues which largely represent opportunities for future work. For any given state, computing {vi} requires first-order local sensitivity analysis of the dynamical system. As this is a wellstudied problem with numerous existing techniques, we do not address this problem further in this manuscript (Chen and Revels, 2016; Ma et al., 2021).\nThe informative subspace is dependent on the state of the system. In Section 4, we propose and discuss the usage of\nthe state estimate produced by an extended Kalman filter due to the ability to reuse computation.\nFurthermore, we have not addressed how to optimize Equation (14) in the general case. We believe this local dimensionality reduction may be useful to reduce scaling issues in general approaches, reducing the action space to the dimensionality of the limiting manifold."
        },
        {
            "heading": "4 STATE ESTIMATION",
            "text": "In order to practically apply either the Bellman equation based dynamic programming algorithm or the proposed algorithm, we must include some form of state estimation. Due to its close connection with the propagation of the CRLB, we illustrate our algorithms using the extended Kalman filter (EKF).\nThe EKF is a two-step state estimation procedure which involves a prediction step followed by an estimation step. In its general form, the state vector is updated according to the system dynamics, then corrected based on the observation. The covariance matrices are propagated through a linearization of state transition operator and measurement operator. While the technique lacks the optimality guarantees of the original Kalman filter, it has remained a common method of state estimation in dynamical systems since its discovery in the 1960s (Smith et al., 1962).\nIn our application, the EKF is particularly efficient because the computationally expensive covariance update coincides with the CRLB update. Furthermore, as our measurements are scalars, the typically required matrix inversion in the estimation step becomes scalar division. When we incorporate our system model in Equations (1) and (2) and our noise model from Theorem 3.5, the EKF reduces to\nx\u0302i|i\u22121 = \u03d5 \u03c4 ( x\u0302i\u22121|i\u22121 ) , (17)\nx\u0302i|i = x\u0302i|i\u22121 + \u00af \u03a3iui(yi \u2212 u>i x\u0302i|i\u22121) u>i (\u039b\u03c3 + \u00af \u03a3i)u , (18)\n\u00af \u03a3i+1 = [d\u03d5\n\u03c4 x] ( \u00af \u03a3i \u2212 \u00af \u03a3iuiu > i \u00af\n\u03a3i u>i (\u039b\u03c3 + \u00af \u03a3i)u\n) [d\u03d5\u03c4x] > , (19)\nwhere the covariance update is identical to the CRLB update, and can thus be reused. The only additional computational cost to apply the EKF beyond the CRLB update is in Equation (18), which is negligible compared to the already required costs. A detailed description of operation counts is available in Appendix E."
        },
        {
            "heading": "5 EXPERIMENTAL RESULTS",
            "text": "The numerical simulations in this section were chosen to illustrate three key features of our proposed experimental design procedure. We begin by illustrating that, when the\nstate of the system is known exactly, both the proposed experimental design procedure and a computationally expensive dynamic programming baseline (Appendix C) achieve the expected CRLB reduction suggested by the dimensionality collapse. We then demonstrate that the application of the EKF is sufficiently accurate to maintain this improvement after a short delay. Finally, we demonstrate that the benefit improves linearly with the ambient dimensionality of the system. Simulations regarding computation time appear in Appendix E as further justification of the computational efficiency of the proposed algorithm.\nThroughout this section, we simulate representative examples of three important classes of systems: linear systems, limit cycles, and chaotic systems. As many real-world systems exhibit these fundamental behaviors in different operating regimes, our chosen examples help to elucidate how the proposed algorithm will perform in each behavior. The three characteristic systems on which the observation policies were evaluated were a stable linear system defined with eigenvalues \u03bb1 = \u221210 and \u03bb2 = \u22120.1, a Hopf bifurcation with dynamics {x\u0307(1) = x(1)(1 \u2212 \u2016x\u20162) \u2212 x(2); x\u0307(2) = x(2)(1\u2212 \u2016x\u20162) + x(1)}, and a Lorenz system with dynamics {x\u0307(1) = 10(x(2) \u2212 x(1)); x\u0307(2) = x(1)(28 \u2212 x(3)) \u2212 x(2); x\u0307(3) = x(1)x(2) \u2212 83x(3)}, where x(i) indicates the i\u2019th element of the state vector. While chaotic systems do not meet our theoretical convergence assumption, we include the Lorenz system to characterize performance on this related behavior. The specific parameters are available in Appendix H.\nIn Figure 3, we illustrate that the oracle solution of the optimal sampling procedure works across representative examples of each class of systems in which the true state is known to the decision process. A line corresponding the optimal CRLB reduction enabled by the loss of dimensionality is included for reference. The key observation in this figure is that all techniques approximately capture the full improvement potential. Furthermore, as the plot represents the CRLB for state estimation rather than forecasting, we observe the fundamental trade-off made in this work: while we attain an improvement for future time-horizons, our ability to estimate the current state is negatively impacted in the short term. This is particularly visible in the dynamic programming plot in Panel C where the CRLB reduction does not materialize for about 250 samples, or 2.5 seconds of the system trajectory.\nNext, we introduce the partially observed setting with the EKF in Panels A and B of Figure 4, normalizing the trace of the CRLB to that of the oracle solution in the Dynamic Programming approximation. Because the plots again illustrate the CRLB for the current state, we observe a shortterm performance benefit for the EKF approach, as it is less aggressive in prioritizing the future. As the Lorenz system is not truly 1D, we see a similar benefit in Panel B. In these simulations, we observe empirically that the EKF based\npolicy often converges to similar levels of performance to the oracle policy, particularly in the proposed method.\nFinally, in Panel C of Figure 4, we introduce a system based on expanding a Van der Pol oscillator, a common example of a system with a limit cycle, with additional dimensions governed by stable linear dynamics to illustrate the linear improvement as a function of the number of collapsing dimensions. In this system, the dynamics of the first two state variables are defined as {x\u0307(1) = 3.5(x(1) \u2212 13x 4 (1) \u2212 x(2)); x\u0307(2) = 2 7x(1)}, while the remaining dimensions all follow x\u0307(i) = \u2212x(i). Through these simulations, we remove any confounding issues and focus purely on the scaling with the dimensionality. The blue curve represents a baseline approach in which, at each decision point, the measurement vector is chosen uniformly at random over all unit vectors. This baseline represents an efficient method to collect measurements about the current state, particularly in the case when observations are made quickly relative to the rate of change of state in the system. We see that, in this greedy baseline approach, the trace of\nthe future CRLB increases linearly with dimensionality of the system while our proposed technique preserves a nearly constant value."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "In this work, we introduced a dimensionality reduction method for the sequential selection of linear functional measurements of a vector-valued time series when the system converges to a low-dimensional manifold. Based on theoretical properties of natural exponential families of probability distributions, we reformulated the average cost infinite horizon problem for systems which converge to low-dimensional sets, resulting in a computationally efficient alternative to a Bellman equation approach.\nBeyond theoretical results, we demonstrated the performance on three different common classes of dynamical systems: linear systems, limit cycles, and chaotic systems. Simulations were completed illustrating the performance\nof the dynamic programming formulation and the 1D reformulation using an extended Kalman filter for state estimation. Simulations showed that the measurement selection performance remained constant irrespective of the ambient dimensionality of the space \u2014 in contrast with i.i.d. uniform random measurements which grow linearly.\nThe contributions in this work enable the collection of significantly more informative data than would be acquired through uniform observations. This improvement is attained irrespective of the eventual forecasting algorithm. We believe this work opens new directions in forecasting time series, and anticipate follow-on work regarding the co-design of observation and forecasting algorithms."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was supported in part by the National Science Foundation under Grant 1936663."
        },
        {
            "heading": "APPENDIX",
            "text": "The appendix is organized as follows. Appendix A describes the systems shown in Table 1. Appendix C provides derivations of the performance of the dynamic programming base case. Appendix D provides the proofs for Section 3. Appendix E contains counts of multiplications required in the algorithms, as well as timing simulations and details regarding the gradient ascent procedure. Appendix F discusses potential numerical issues in the work relating to the requirement to invert approximately singular matrices, as well as the chosen solution to the problem. Appendix G describes the interface for incorporating new dynamical systems into the library produced in the course of this work. Finally, Appendix H includes all parameter used in generating the plots in the main body of the manuscript."
        },
        {
            "heading": "A TABLE 1 DETAILS",
            "text": "Representative trajectories for the systems in Table 1 are shown in Figure 5. Initializations were chosen in an arbitrary, often randomized manner as the chosen systems are known to contain only a small number of stable global behaviors In particular, all systems other than the gradient flow globally converge to a fixed behavior, while the chosen gradient flow contains only two stable equalibria.\nGradient Flow Let h : RM \u2192 R on some bounded interval be a Morse function. The gradient flow is defined as\nx\u0307 = \u2212\u2207h(x). (20)\nThe key property of a Morse function in this example is that all critical points occur in the interior of the manifoldM/\u2202M and that no critical points are degenerate. The lack of degeneracy is well-known to imply that critical points are isolated, thus resulting in a discrete-set of points.\nIn the particular simulation for Figure 5, h(x) = x4 \u2212 5x2 + 4.\nVan Der Pol Oscillator\nx\u0307 = y (21)\ny\u0307 = \u00b5(1\u2212 x2)y \u2212 x (22)\nThe Van Der Pol Oscillator is well-known to have a single globally stable limit cycle, though there is no closed form.\nIn the Figure 5, \u00b5 = 1.\nHopf Bifurcation\nx\u0307 = x(\u03bb+ b(x2 + y2))\u2212 y (23) y\u0307 = y(\u03bb+ b(x2 + y2)) + x (24)\nThe parameters are chosen such that the system exhibits a stable limit cycle, for example b = \u22121 and \u03bb = 1 in Figure 5. Under the above choice of parameters, there is a stable limit cycle at x2 + y2 = 1. By substituting in the constraint into the\nabove expression, the system becomes\nx\u0307 = \u2212y (25) y\u0307 = x (26)\nwhich is linear with purely imaginary eigenvalues.\nLorenz System\nx\u0307 = \u03c3(y \u2212 x) (27) y\u0307 = x(\u03c1\u2212 z)\u2212 y (28) z\u0307 = xy \u2212 \u03b2z (29)\nThe almost canonical set of parameters for the system is \u03c3 = 10, \u03c1 = 28, \u03b2 = 8/3, which generates the butterfly-shaped attractor pictured in Figure 5. In the case of this well-known chaotic dynamical system, the low-dimensional structure is less obvious. In fact, the attractor is not embedded in a 2D manifold at all. Instead, due to deep connections between chaos and fractals, chaotic attractors are often described by their fractal dimension. While there are many definitions of fractal dimensions, a common definition is the Hausdorff dimension, defined based on covering the space with arbitrarily small balls. In the case of the Lorenz system with the chosen parameters, the dimensionality is well-known to be approximately 2.06.\nHeat Equation The heat equation is one of the most fundamental linear partial differential equations, and represents spatial diffusion over time.\n\u2202u \u2202t = \u03b1\u2206u (30)\nIn Figure 5, the heat equation is simulated according to a finite-difference discretization with \u03b1 = 0.2. The only eigenfunction of the system which does not exponentially decay is the average value of u, and so the system converges only to a 1D space."
        },
        {
            "heading": "B CRAME\u0301R\u2013RAO LOWER BOUND",
            "text": "In this appendix, we provide a brief overview of the well-known Crame\u0301r\u2013Rao Lower Bound (CRLB), with regularity conditions adapted from Lehmann and Casella (1998).\nThe multivariate CRLB, sometimes known as an information inequality, is a matrix inequality on the covariance matrix of all estimators of an unknown, deterministic parameter of a probability distribution. Specifically, let p(\u03be; \u03b8) be a family of density functions of a random variable \u03be parameterized by a vector \u03b8 such that p satisfies the regularity conditions:\n1. \u0398 is an open set of possible parameters \u03b8.\n2. The densities p(\u00b7; \u03b8) have common support.\n3. For each \u03be \u2208 \u039e, \u03b8 \u2208 \u0398, and i \u2208 1, . . . ,M, \u2202p(\u03be;\u03b8)\u2202\u03b8i <\u221e.\nThen, for any estimator of the parameter \u03b8\u0302 such that i \u2208 1, . . . ,M, \u2202\u2202\u03b8iE [ \u03b8\u0302 ] = E [ \u2202 \u2202\u03b8i \u03b8\u0302 ] ,\n\u03a3 \u2265\ndE [ \u03b8\u0302 ]\nd\u03b8\n> J\u22121(\u03b8) dE [ \u03b8\u0302 ]\nd\u03b8  , (31) where \u03a3 is the covariance matrix of the estimator and J\u22121(\u03b8) is the inverse Fisher information matrix. The matrix inequality is interpreted such that a matrix A \u2265 0 is positive semi-definite. When applied to unbiased estimators where E [ \u03b8\u0302 ]\n= \u03b8, the CRLB reduces to the exceedingly common unbiased form\n\u03a3 \u2265 J\u22121(\u03b8). (32)\nAlgorithm 1 Interpolation Point Sampling Input: Eigenvalue Distribution \u00b5 Sample diagonal matrix \u039b \u223c \u00b5\n( \u039b \u2208 RM\u00d7M ) Sample G \u223c N (0, I) ( G \u2208 RM\u00d7M\n) Q,R\u2190 QR(G) (Q \u223c Haar Measure) xi \u2190 Q>\u039bQ ( xi \u2208 RM\u00d7M )\nThe Fisher information matrix is the covariance of the derivative of the log-likelihood function, i.e.\nJ(\u03b8) = E\n[( d\nd\u03b8 log p(\u03be; \u03b8)\n)( d\nd\u03b8 log p(\u03be; \u03b8)\n)>] . (33)\nOf note in this work is the impact of diffeomorphic reparameterization on the Fisher information matrix, which can be seen immediately by applying the chain rule to Equation (33)."
        },
        {
            "heading": "C DYNAMIC PROGRAMMING BASELINE",
            "text": "While the dynamic programming problem maps directly into the stochastic control and reinforcement learning frameworks, there are still a number of application-specific details in all such algorithms. In this section, we address the choice of an appropriate discretization scheme for the state space.\nFirst, we need to consider the structure of the state space and the action space. The policy is dependent both on the previous CRLB and on the previous system state. But note that the CRLB is a positive semi-definite (PSD) matrix, and so if the system state is in RM , then the space of CRLB matrices is embedded in R(M2+M)/2. Furthermore, the space of PSD matrices trivially forms a cone, which further reduces the space. An equivalent representation of the space is through the diagonalization A = U\u039bU>, where \u039b is a diagonal matrix and U \u2208 O(M) is an orthonormal matrix.\nThe space of PSD matrices has a non-trivial structure, yet we have strong heuristics for the problem. Thus, we opt to approximate through the interpolation of random sample points. We denote the set of sample points by X = {x1, ..., xN} and our approximation of the value function to be J\u0302X (x,\n\u00af \u03a3). We first describe the sampling distribution of X , before\ndiscussing the interpolation methods.\nRandom Sampling A practical approach to generating random PSD matrices is to decompose the problem into sampling from the space of orthonormal matrices and sampling non-negative eigenvalues. Not only is this approach straightforward, but as we have more intuition regarding the distribution of eigenvalues, it allows easy tuning of the approximation of the distribution. The full sampling routine is shown in Algorithm 1.\nUsing a naive prior to model the problem, we begin with sampling the orthonormal matrix components from a Haar measure. The Haar measure can be thought of as a uniform distribution \u2014 it is the unique measure that is invariant to the action of elements in the group (Mezzadri, 2006). It is exceedingly easy to generate random orthonormal matrices from this measure. It can be shown that due to the isotropic behavior, diagonalizing vectors of a matrix populated with i.i.d. Gaussian random variables results in such a distribution. Practically, sampling is done using QR factorization, typically with an eigenvalue correction term that cancels in similarity transforms (Mezzadri, 2006).\nUnderstanding that each measurement is optimized to minimize the eigenvalues of the CRLB, we follow the heuristic that smaller eigenvalues will be encountered more frequently and sample from an exponential distribution. The parameter of the distribution is then a hyperparameter of the problem.\nInterpolation Methods While one could choose any one of a large number of interpolation methods, in this work, we only analyze nearest neighbor and a locally averaged perturbation of nearest neighbor. While alternative approaches may yield higher accuracy, the approximation quality for classification tasks is extremely well studied with strong guarantees, typically providing both upper and lower bounds due to the connection to density estimation techniques.\nIt is clear that the CRLB of our measurement system will be unevenly distributed in any practical setting: as we gather more data, the CRLB decreases. Thus, we would like to weight our approximation quality to account for this phenomenon.\nHere, we provide a bound for function approximation accuracy under a non-uniform measure defined by a probability distribution.\nLemma C.1. Assume for every x \u2208 X , the approximation of the value function is exact, i.e. J\u0302X (x) = J(x), where J\u0302X is our approximation. Furthermore, assume J is Lipschitz with coefficient L. Then the mean absolute error of the function approximation is upper bounded by\nEX ,x [ |J\u0302X (x)\u2212 J(x)| ] \u2264 LEX ,x [ min x\u2032\u2208X \u2016x\u2212 x\u2032\u2016 ]\n(34)\nProof. By the Lipschitz assumption, |J(x)\u2212 J(x\u0303)| \u2264 L\u2016x\u2212 x\u0303\u2016, and so\nEX ,x [|J(x)\u2212 J(x\u0303)|] \u2264 LEX ,x [\u2016x\u2212 x\u0303\u2016] . (35)\nBy construction of nearest neighbor regression, J\u0302X (x) = J(x\u2032) where x\u2032 = arg min x\u0303\u2208X \u2016x\u2212 x\u0303\u2016. Thus\nEX ,x [ |J\u0302X (x)\u2212 J(x)| ] = EX ,x [|J(x)\u2212 J(x\u2032)|] \u2264 LEX ,x [ min x\u2032\u2208X \u2016x\u2212 x\u2032\u2016 ]\n(36)\nThe expected minimum distance to the dataset is dependent on the distribution and is non-trivial to compute analytically. We include a simulation in Figure 6 illustrating the expected minimum distance as a function of the number of samples. One important observation is the well-known curse of dimensionality, and so this particular function approximation would scale poorly to higher dimensions.\nFinally, the nearest neighbor model fails to produce reasonable decisions when the CRLB changes by less than twice the distance between sample points \u2014 resulting in the state staying constant in value iteration steps. To prevent this issue, we apply local averaging motivated by linear interpolation. In particular, in our local averaging model, an approximate point is evaluated as\nJ\u0302 (loc) X (x\u0302) =\n\u2211 x\u2208X J(x) min (0, dmax \u2212 \u2016x\u2212 x\u0302\u2016)\u2211\nx\u2208X min (0, dmax \u2212 \u2016x\u2212 x\u0302\u2016) , (37)\nwhere dmax is a chosen maximum distance for averaging and J\u0302X (x\u0302) is replaced by a nearest neighbor approximation if the denominator becomes 0. We can readily bound the perturbation of our locally averaged interpolation from our nearest neighbor interpolation based on the Lipschitz assumption.\nTheorem C.2. The mean absolute error of the locally averaged approximation is at most\nEX ,x [ |J\u0302 (loc)X (x)\u2212 J(x)| ] \u2264 L ( EX ,x [ min x\u2032\u2208X \u2016x\u2212 x\u2032\u2016 ] + 2dmax ) . (38)\nProof. The inequality comes from observing the maximum perturbation from the nearest neighbor solution.\nFirst, observe that if the dmax ball around x contains 1 or fewer points, then there is no change to the approximation. Next, consider the case when there are exactly two representation points in the ball. Then J\u0302 (loc)X (x) = (dmax\u2212d1)J(x1)+(dmax\u2212d2)J(x2)\n2dmax\u2212d1\u2212d2 , where di is the distance from x to xi. Now suppose d1 < d2, then J\u0302X (x) = J(x1).\nJ\u0302X (x)\u2212 J\u0302 (loc)X (x) = (J(x1)\u2212 J(x2)) dmax \u2212 d2\n(dmax \u2212 d1) + (dmax \u2212 d2) (39)\nNow, d1 < d2 \u21d2 (dmax \u2212 d1) > (dmax \u2212 d2)\u21d2 dmax\u2212d2(dmax\u2212d1)+(dmax\u2212d2) \u2264 1 2 . It then follows that\u2223\u2223\u2223J\u0302X (x)\u2212 J\u0302 (loc)X (x)\u2223\u2223\u2223 \u2264 12 |J(x1)\u2212 J(x2)| (40)\nThe distance between x1 and x2 is upper bounded by 2dmax which represents opposite ends of the ball. Thus, by the Lipschitz assumption \u2223\u2223\u2223J\u0302X (x)\u2212 J\u0302 (loc)X (x)\u2223\u2223\u2223 \u2264 Ldmax. (41) Consider the implication of adding additional points to the ball. Note that again, the worst-case scenario is when all points are nearly equidistant from the center, resulting in\n\u2223\u2223\u2223J\u0302X (x)\u2212 J\u0302 (loc)X (x)\u2223\u2223\u2223 \u2264 1N \u2223\u2223\u2223\u2223\u2223J(x1)\u2212 N\u2211 i=2 J(xi) \u2223\u2223\u2223\u2223\u2223 . (42) Once again, J(x1)\u2212 2Ldmax \u2264 J(xi) \u2264 J(x1) + 2Ldmax, and thus\u2223\u2223\u2223J\u0302X (x)\u2212 J\u0302 (loc)X (x)\u2223\u2223\u2223 \u2264 (N \u2212 1N ) 2Ldmax (43)\nBy observing (N \u2212 1)/N < 1 for all N > 1, we find one irrespective of the number of points in the ball.\u2223\u2223\u2223J\u0302X (x)\u2212 J\u0302 (loc)X (x)\u2223\u2223\u2223 \u2264 2Ldmax (44) Finally, apply the triangle inequality to conclude the original statement, i.e.\u2223\u2223\u2223J\u0302 (loc)X \u2212 J(x)\u2223\u2223\u2223 = \u2223\u2223\u2223J\u0302 (loc)X \u2212 J\u0302X (x) + J\u0302X \u2212 J(x)\u2223\u2223\u2223 (45)\n\u2264 \u2223\u2223\u2223J\u0302 (loc)X \u2212 J\u0302X (x)\u2223\u2223\u2223+ \u2223\u2223\u2223J\u0302X \u2212 J(x)\u2223\u2223\u2223 (46)\n\u2264 L (\n2dmax + min x\u2032\u2208X\n\u2016x\u2212 x\u2032\u2016 )\n(47)\n\u21d2 EX ,x [ |J\u0302 (loc)X (x)\u2212 J(x)| ] \u2264 L ( EX ,x [ min x\u2032\u2208X \u2016x\u2212 x\u2032\u2016 ] + 2dmax ) . (48)\nConveniently, as N increases, we can decrease dmax while retaining the averaging behavior. Thus, we choose dmax proportional to expected minimum distance to preserve the behavior of the bound."
        },
        {
            "heading": "D PROOFS FOR SECTION 3",
            "text": "Lemma D.1 (Context: See Lemma 3.1). Given a finite set of independent random variables {\u03be(i)} in NEFs with logpartition functions {Ai}, parameters {\u03b8i}, and a set of real-valued weights {\u03b1i}, then \u03be\u0304 = \u2211 i \u03b1i\u03be(i) is in a NEF with a log partition function A(\u03b8) :=\n\u2211 i Ai (\u03b8 + \u03b1i\u03b8i) . (49)\nProof. Without loss of generality, we prove the case of two random variables. The result can then be trivially extended to any finite set, either by induction or through a modification of the below proof.\nThe moment generating function of random variable X in a NEF is well-known to be\nMX(s) = exp{A(\u03b8 + s)\u2212A(\u03b8)}. (50)\nIf we denote the log-partition function of \u03bei to be Ai, then\nM\u03be1+\u03be2(s) = exp{A1(\u03b81 + s) +A2(\u03b82 + s)\u2212A1(\u03b81)\u2212A2(\u03b82)}. (51)\nWe then define the new log-partition function A : s 7\u2192 A1(\u03b81 + s) + A2(\u03b82 + s). Thus, by the structure of the MGF, the distribution itself is in a NEF.\nLemma D.2 (Context: See Lemma 3.2). The Fisher information of a random variable in a NEF is the variance of the random variable.\nProof. By definition of the NEF, the log-likelihood takes the form\n\u03b8\u03be \u2212A(\u03b8) +B(\u03be). (52)\nRecall that A\u2032(\u03b8) = E[\u03be]. Thus, by computing the derivative, the Fisher information is\nE[(\u03be \u2212A\u2032(\u03b8))2] = E[(\u03be \u2212 E[x])2] (53)\nLemma D.3 (Context: See Lemma 3.3). The diagram in Figure 2 commutes for any vector \u03be of independent random variables from NEFs.\nProof. We must show that {gi} \u25e6 h = h \u25e6 g. It suffices to show that each connection as drawn is accurate. The application of g and {gi} are well-known from the NEF. For completeness, recall that the expected value of the score function of a random variable is 0, i.e.\nE[ \u2202 \u2202\u03b8 log p(x; \u03b8)|\u03b8] = \u2202 \u2202\u03b8 E[log p(x; \u03b8)|\u03b8] = 0. (54)\nThen\nE[ \u2202 \u2202\u03b8 (x\u03b8 \u2212A(\u03b8) +B(x))] = E[x\u2212 \u2202 \u2202\u03b8 A(\u03b8)] (55)\n= \u00b5\u2212 g(\u03b8) = 0 (56) \u21d2 \u00b5 = g(\u03b8) (57)\nFurthermore, h : {\u00b5i} 7\u2192 \u00b5 follows by linearity of expectation.\nThus, the only tricky connection is to show \u03b8 = h({\u03b8i}). Fortunately, this follows by observing we have flexibility in the definition of the NEF of \u03be\u0304. In particular, adding a constant offset to our definition of \u03b8 does not impact the definition of the family. Thus, we are free to center \u03b8 and our NEF definition around \u03b8 = h({\u03b8i}).\nLemma D.4 (Context: See Lemma 3.4). Assume the log-partition function A of a NEF is twice differentiable and that the second moment of the associated random variable exists. Then the inverse of g(\u03b8) := \u2202\u2202\u0398A(\u0398) \u2223\u2223 \u0398=\u03b8\nexists if and only if the random variable is non-degenerate for almost all \u03b8.\nProof. First, assume that \u03be is non-degenerate. Then, we will show g is strictly monotonic and thus invertible. Recall that g := A\u2032, where A\u2032 is the derivative of A with respect to \u03b8. Furthermore, recall that under the above regularity conditions, A\u2032\u2032 is the Fisher information. Finally, by Lemma 3.2.\n\u2202\n\u2202\u03b8 g(\u03b8) = A\u2032\u2032(\u03b8) = E[(\u03be \u2212 E[\u03be])2] = Var(\u03be) > 0. (58)\nThus, g is strictly increasing and is therefore invertible.\nNow, by contrapositive, assume there exists an interval for which \u03be deterministically takes a constant value. Then by the above argument, \u2202\u2202\u03b8g(\u03b8) = 0 for all \u03b8 on the interval, and thus g is not invertible on the interval.\nTheorem D.5 (Context: See Theorem 3.5). Suppose \u03be is a vector of independent random variables from NEFs with twice differentiable log-partition functions, mean vector \u00b5, and a diagonal covariance matrix \u039b\u03c3 . Then the Fisher information of the observation \u3008u, \u03be\u3009 is\nI(\u00b5) = uu>\nu>\u039b\u03c3u (59)\nProof. The proof follows from the transformation to reparameterized Fisher information. That is, we can instead write \u03b8\u0304 = T (\u00b5).\nI(\u00b5) = [dT\u00b5] I(\u03b8\u0304) [dT\u00b5] > (60)\n= [dh\u00b5] dg \u22121 \u00b5\u0304 I(\u03b8\u0304)dg \u22121 \u00b5\u0304 [dh\u00b5] > (61)\nNow, recall that I(\u03b8\u0304) = dg\u00b5\u0304 = Var(\u03be\u0304) = \u2211 i u 2 (i)\u03c3 2 i = u\n>\u039b\u03c3u, where u(i) represents the i\u2019th element of u. Then by noting the inverse commutes with the derivative and that scalar multiplication commutes,\nI(\u00b5) = [dh\u00b5] [dh\u00b5] > 1\nu>\u039b\u03c3u . (62)\nFinally, observe [dh\u00b5] = u to conclude the proof.\nCorollary D.6 (Context: See Corollary 3.6). The Fisher information for state estimation under i.i.d. noise is invariant to the scaling of the linear functional.\nProof. Follows immediately from the previous corollary by writing it as\nI(\u00b5) = \u03c3\u22122 uu>\n\u2016ui\u20162 = \u03c3\u22122\n( u\n\u2016u\u2016\n)( u\n\u2016u\u2016\n)> , (63)\nand observing the absolute homogeneity of norms.\nCorollary D.7 (Context: See Corollary 3.7). Suppose the elements of the noise vector are i.i.d. with variance \u03c32. Then\nI(\u00b5) = \u03c3\u22122 uu>\n\u2016u\u20162 (64)\nProof. As the noise is identically distributed, it has the same variance and the covariance matrix becomes a scaled version of the identity. From Theorem 3.5\nI(\u00b5) = uu>\nu>\u039b\u03c3u = \u03c3\u22122\nuu> u>u = \u03c3\u22122 uu> \u2016u\u20162 (65)\nLemma D.8 (Context: See Lemma 3.8). If the system in Equation (1) converges to a K-dimensional smooth manifold M such that there exists some \u03b1 > 0 for which v> ( [dfx] + [dfx] > ) v + \u03b1\u2016v||2 < 0 for each v \u2208 T\u22a5p M normal to the\nmanifold at each p \u2208 M, then there exists an M \u2212 K dimensional subspace S(x0) \u2282 RM for which [ d\u03d5\u03c4x0 ] u \u2192 0 as \u03c4 \u2192\u221e for each u \u2208 S(x0).\nNote that this proof is long. As such, we have split some of the significant intermediate steps into italicised statements. Proofs of these intermediate statements are terminated with , while the full proof is terminated with .\nProof. By considering the sensitivity equation (Khalil, 2002)\nx\u0307 = f(x) (66) \u02d9[d\u03d5\u03c4 dx ] = [ df dx ] [ d\u03d5\u03c4 dx ] , (67)\nwe will see that the normal sensitivity is asymptotically stable once sufficiently close to the manifold. By our assumption that the trajectory converges, we can represent the state using Fermi coordinates on a tubular neighborhood of the manifold.\nThat is, we can represent the space as the product of the manifoldM and an M \u2212K dimensional vectorspace representing the normals of the manifold. If M is smooth, such a neighborhood always exists by the tubular neighborhood theorem (Lee, 2018).\nFor any \u03c4 , there exists a vector bundle S\u03c4 (x) \u2282 RM such that d\u03d5dxS\u03c4 (x) = T \u22a5 \u03d5\u03c4 (x)M is normal to the manifold.\nBecause \u03d5\u03c4 is a diffeomorphism, d\u03d5 \u03c4 dx is full rank. We can construct any vector v = [ df dx ]\u22121 u for some u. Therefore, there\nexists some subspace S(x) such that T\u22a5p M = [ df dx ]\u22121 S(x) where p = \u03c0M(\u03d5\u03c4 (x)) is the projection of \u03d5\u03c4 (x) onto the manifold.\nLet \u03a0\u22a5M be the orthogonal projection onto the normal space. Then lim\u03c4\u2192\u221e v > 0\n[ d\u03d5\u03c4\ndx ]> \u03a0\u22a5M [ d\u03d5\u03c4 dx ] v0 = 0.\nObserve that [ d\u03d5\u03c4\ndx\n] v0 is the solution of the sensitivity equation v\u0307 = [ df dx ] v. Let V (v, \u03c4) = v>\u03a0\u22a5Mv. We can compute the\ntime derivative of V (v, \u03c4) = v>\u03a0\u22a5Mv and show that the quantity decreases monotonically. Note that through the use of Fermi coordinates, we have removed the dependency on \u03c4 in \u03a0\u22a5M. The derivative then becomes\nV\u0307 (v, \u03c4) = v> ( \u03a0\u22a5M [ df\ndx ]\u2223\u2223\u2223\u2223 x=x0 + [ df dx ]\u2223\u2223\u2223\u2223> x=x0 \u03a0\u22a5M ) v (68)\n= v> ( \u03a0\u22a5M [ df\ndx ]\u2223\u2223\u2223\u2223 x=\u03c0M(x0) + [ df dx ]\u2223\u2223\u2223\u2223> x=\u03c0M(x0) \u03a0\u22a5M ) v + v> ( \u03a0\u22a5M\u0393(x) + \u0393(x) >\u03a0\u22a5M ) v, (69)\nwhere \u2016\u0393(x)\u2016 < L by the Lipschitz assumption. Because \u03a0\u22a5M is an orthogonal projection, \u2016\u03a0\u22a5M\u2016 = 1. The operator norms can then be used to upper bound the derivative as\nV\u0307 (v, \u03c4) \u2264 v> (\n\u03a0\u22a5M\n[ df\ndx ]\u2223\u2223\u2223\u2223 x=\u03c0M(x) + [ df dx ]\u2223\u2223\u2223\u2223> x=\u03c0M(x0) \u03a0\u22a5M ) v + 2 L\u2016v\u20162 (70)\n= 2v>\u03a0\u22a5M\n[ df\ndx ]\u2223\u2223\u2223\u2223 x=\u03c0M(x) v + 2 L\u2016v\u20162. (71)\nDecompose v into v\u22a5 \u2208 T\u22a5p M and v\u2016 \u2208 TpM such that v = v\u22a5 + v\u2016 and reorder terms as\nV\u0307 (v, \u03c4) \u2264 2v>\u03a0\u22a5M [ df\ndx ]\u2223\u2223\u2223\u2223 x=\u03c0M(x) (v\u22a5 + v\u2016) + 2 L\u2016v\u20162 (72)\n= 2v>\u22a5\n[ df\ndx ]\u2223\u2223\u2223\u2223 x=\u03c0M(x) (v\u22a5 + v\u2016) + 2 L\u2016v\u20162 (73)\n= 2v>\u22a5\n[ df\ndx ]\u2223\u2223\u2223\u2223 x=\u03c0M(x) v\u22a5 + 2v\u22a5 [ df dx ]\u2223\u2223\u2223\u2223 x=\u03c0M(x) v\u2016 + 2 L\u2016v\u20162 (74)\n\u2264 2( L\u2212 \u03b1)\u2016v\u22a5\u20162 + 2 L\u2016v\u22a5\u2016\u2016v\u2016\u2016+ 2v>\u22a5 [ df\ndx ]\u2223\u2223\u2223\u2223 x=\u03c0M(x) v\u2016, (75)\nwhere the final line comes from our eigenvalue assumption and the triangle inequality.\nBy recalling that f determines the geometry of the manifold through the trajectories, the rightmost term can be seen to represent the derivative of the normal vector along a curve in the manifold. By further considering the osculating circle at the point on the associated curve, or the unique circle which matches at least the first two derivatives (Lee, 2018), we can see that the directional derivatives of the normal vectors along the tangent space are zero. This is because the derivative of the normal component of the circle is zero along the tangent, i.e. ddx cos(x)|x=0 = sin(0) = 0. Thus\nV\u0307 (v, \u03c4) \u2264 2( L\u2212 \u03b1)\u2016v\u22a5\u20162 + 2 L\u2016v\u22a5\u2016\u2016v\u2016\u2016, (76)\nwhich is strictly less than zero if \u2016v\u22a5\u2016 \u2016v\u2016\u2016 \u2265 L \u03b1\u2212 L . (77)\nThus, the normal components of all vectors must decay to zero as \u2192 0, and so \u03a0\u22a5M [ d\u03d5\u03c4 dx ] v0 \u2192 0 as \u03c4 \u2192\u221e.\nFinally, by decomposing the transformation into two distinct functions through the semigroup property, we conclude the overall proof. Consider \u03d5\u03c4+T , where T is sufficiently large that the distance fromM is at most . Decompose the function as \u03d5\u03c4+T = \u03d5\u03c4 \u25e6 \u03d5T and apply the chain rule as\nd\u03d5\u03c4+T\ndx =\nd\u03d5\u03c4\nd\u03d5T (x)\nd\u03d5T\ndx . (78)\nFrom our intermediate results, for any \u03b4 we can always choose an appropriate \u03c4 and v such that\nd\u03d5T\ndx v \u2208 TpM and\nd\u03d5\u03c4\nd\u03d5T (x)\nd\u03d5T\ndx v < \u03b4. (79)\nWe now argue that such v converges to a subspace based on the adjoint sensitivity equation\nu\u0307 = \u2212 [ df\ndx\n]> u. (80)\nThe adjoint sensitivity equation runs backwards in time, identifying the directional derivative of the inverse function. We will characterize the limiting nullspace of d\u03d5 \u03c4\ndx based on the directional derivatives of \u03d5 \u2212\u03c4 along the normals, which we\nhave shown becomes the left nullspace of the matrix.\nRecall that we can expand the derivative as the derivative on the manifold and an perturbation, i.e.\nu\u0307 = ( \u2212 [ df\ndx ]\u2223\u2223\u2223\u2223> x=\u03c0M(x) + \u0393(x) ) u (81)\nwhere \u2016\u0393(x)\u2016 < . By observing that [ df dx ]\u2223\u2223\u2223> x=\u03c0M(x)\nu \u2208 T\u22a5\u03c0M(x)M, we see that the dynamics converge such that u cannot rotate out of the normal space as \u2192 0.\nThus, as T \u2192\u221e, the normal space becomes approximately closed in the adjoint analysis, and the vectors which map onto the normal space become S(x0).\nTheorem D.9 (Context: See Theorem 3.9). Suppose the state space model in Equations (1) and (2) with noise satisfying the assumptions in Theorem 3.5 converges to a K-dimensional smooth manifold such that the Jacobian of the limiting flow is rank K. Then the linear functional which minimizes the CRLB for prediction in the infinite-horizon average cost formulation is the solution of\narg max u:\u2016u\u2016(\u039b\u03c3+\n\u00af \u03a3)=1\nK\u2211 i=1 \u03b1i\u3008vi, u\u30092 \u00af \u03a3 (82)\nfor some {\u03b1i}, where vi is the set of right singular vectors of the Jacobian of the limiting flow around the current state with nonzero singular vectors,\n\u00af \u03a3 is the CRLB for estimating the current state based on the past measurements, u\u0304 = u\u2016u\u2016\n\u00af \u03a3\nis a unit-length version of u, \u3008v, u\u3009 \u00af \u03a3 = v > \u00af \u03a3u, and \u2016 \u00b7 \u2016 \u00af \u03a3 is the associated induced seminorm.\nProof. Apply the singular value decomposition to the Jacobian of the flow as [ d\u03d5\u03c4x0 ] = U\u03c4D\u03c4V \u2217 \u03c4 . For sufficiently large \u03c4 , by our low-rank assumption, there are at most K non-zero singular values. By Lemma 3.8, the row space V \u2217\u03c4 is invariant to \u03c4 . Thus, we let V \u2217\u03c4 = R \u2217 \u03c4V \u2217, where R\u03c4 is some K \u00d7K unitary transformation.\nIt follows that\n\u00af \u03a3\u03c4 = U\u03c4D\u03c4R\n\u2217 \u03c4 [V \u2217 \u00af \u03a30V ]\ufe38 \ufe37\ufe37 \ufe38\nK\u00d7K\nR\u03c4D\u03c4U \u2217 \u03c4 . (83)\nThus, by plugging the CRLB into our average cost objective\nlim N\u2192\u221e\n1\nN N\u2211 j=1 Tr ( \u00af \u03a3\u03c4j ) = 1 N N\u2211 j=1 Tr (U\u03c4D\u03c4R \u2217 \u03c4 [V \u2217 \u00af \u03a30V ]R\u03c4D\u03c4U \u2217 \u03c4 ) (84)\n= 1\nN N\u2211 j=1 Tr (D\u03c4R \u2217 \u03c4 [V \u2217 \u00af \u03a30V ]R\u03c4D\u03c4 ) . (85)\nUsing the Sherman\u2013Morrison formula (Sherman and Morrison, 1950) for our Fisher Information update, i.e.[ \u00af \u03a3\u22121 + 1\n\u2016ui\u20162\u039b\u03c3 uiu > i\n]\u22121 =\n\u00af \u03a3\u22121 \u2212 \u00af\n\u03a3\u22121uiu > i \u00af\n\u03a3\u22121 \u2016ui\u20162\u039b\u03c3 + u > i \u00af \u03a3\u22121ui , (86)\nthe update to the future cost becomes\n\u22121 N ( \u2016ui\u20162\u039b\u03c3 + \u2016ui\u2016 2\n\u00af \u03a3\u22121\n) N\u2211 j=1 Tr ( D\u03c4R \u2217 \u03c4 [ V \u2217 \u00af \u03a3\u22121uiu > i \u00af \u03a3\u22121V ] R\u03c4D\u03c4 ) . (87)\nNext, note that by expressing terms as\nV \u2217 \u00af \u03a3\u22121ui =  \u3008v1, ui\u3009\u03a3\u22121... \u3008vK , ui\u3009\u03a3\u22121  R\u03c4D\u03c4D\u03c4R\u2217\u03c4 =  \u03b1 (\u03c4) 1,1 \u03b1 (\u03c4) 1,2 \u00b7 \u00b7 \u00b7 \u03b1 (\u03c4) 1,K \u03b1 (\u03c4) 2,1 \u03b1 (\u03c4) 2,2 \u00b7 \u00b7 \u00b7 \u03b1 (\u03c4) 2,K ... ... . . . ...\n\u03b1 (\u03c4) K,1 \u03b1 (\u03c4) K,2 \u00b7 \u00b7 \u00b7 \u03b1 (\u03c4) K,K\n , (88)\nwe can rewrite the expression in the trace as\nTr ( D\u03c4R \u2217 \u03c4 [ V \u2217\n\u00af \u03a3\u22121uiu > i \u00af\n\u03a3\u22121V ] R\u03c4D\u03c4 ) = K\u2211 k=1 \u03b1 (\u03c4) k,k\u3008vk, ui\u3009 2 \u00af \u03a3\u22121 . (89)\nRewrite the summation in terms of our new expression for the trace and commute the summations as\narg max ui K\u2211 k=1  \u3008vk, ui\u30092\u00af\u03a3\u22121 \u2016ui\u20162\u039b\u03c3 + \u2016ui\u2016 2\n\u00af \u03a3\u22121\n lim N\u2192\u221e 1 N N\u2211 j=1 \u03b1 (\u03c4) k,k  (90) Finally, let \u03b1k := limN\u2192\u221e 1N \u2211N j=1 \u03b1 (\u03c4) k,k to express the objective as\narg max ui\n\u2211K k=1 \u03b1k\u3008vk, ui\u30092\n\u00af \u03a3\u22121\n\u2016ui\u20162\u039b\u03c3 + \u2016ui\u2016 2\n\u00af \u03a3\u22121\n. (91)\nObserve that \u2016ui\u20162\u039b\u03c3 + \u2016ui\u2016 2\n\u00af \u03a3\u22121 = \u2016ui\u20162\u039b\u03c3+ \u00af \u03a3\u22121 and apply bilinearity to move it inside the inner products as\narg max ui K\u2211 k=1 \u03b1k \u2329 vk, ui \u2016ui\u2016(\u039b\u03c3+\n\u00af \u03a3\u22121) \u232a2 \u00af \u03a3\u22121 . (92)\nFinally, replace the normalization with a constraint that \u2016ui\u2016(\u039b\u03c3+ \u00af \u03a3\u22121) = 1, noting that by the absolute homogeneity of norms, the result is invariant to scaling:\narg max ui:\u2016ui\u2016(\u039b\u03c3+\n\u00af \u03a3\u22121)=1\nK\u2211 k=1 \u03b1k \u3008vk, ui\u30092 \u00af \u03a3\u22121 . (93)\nCorollary D.10 (Proof: See Corollary 3.10). Under the assumptions of Theorem 3.9, the optimal measurement vector exists in the subspace\nSpan {\n( \u00af \u03a3 + \u039b\u03c3) \u22121 \u00af \u03a3vi }K i=1 . (94)\nProof. This statement follows quickly from the application of Lagrange multipliers. Begin with the statement form Theorem 3.9,\narg max u:\u2016u\u2016(\u039b\u03c3+\n\u00af \u03a3)=1\nK\u2211 i=1 \u03b1i\u3008vi, u\u30092 \u00af \u03a3. (95)\nIntroduce the construct the Lagrangian\nL(u, \u03bb) = K\u2211 i=1 \u03b1i\u3008vi, u\u30092 \u00af \u03a3 + \u03bb(1\u2212 \u2016u\u20162(\u039b\u03c3+ \u00af \u03a3)), (96)\nwhere the norm has been squared, leaving the constraint unchanged.\nExpand the expressions\nL(u, \u03bb) = K\u2211 i=1 \u03b1i ( v>i \u00af \u03a3u )2 + \u03bb(1\u2212 u> (\u039b\u03c3 + \u00af \u03a3)u). (97)\nCompute the derivative with respect to u:\ndL du = K\u2211 i=1 \u03b1i ( v>i \u00af \u03a3u ) \u00af \u03a3vi \u2212 2\u03bb (\u039b\u03c3 + \u00af \u03a3)u. (98)\nSet equal to zero and rearrange terms to find\nu = 1\n2\u03bb K\u2211 i=1 \u03b1i ( v>i \u00af \u03a3u )\ufe38 \ufe37\ufe37 \ufe38\n\u2208R\n(\u039b\u03c3 + \u00af \u03a3) \u22121 \u00af \u03a3vi. (99)\nFinally, observe that \u03b1i ( v>i \u00af \u03a3u ) \u2208 R, and thus\nu \u2208 Span {\n( \u00af \u03a3 + \u039b\u03c3) \u22121 \u00af \u03a3vi }K i=1 . (100)\nCorollary D.11 (Proof: See Corollary 3.11). If, in addition to the assumptions of Theorem 3.9, the dynamical system converges to an isolated limit cycle, then\nu = ( \u00af \u03a3 + \u039b\u03c3) \u22121 \u00af \u03a3v (101)\nis an optimal measurement vector, where v is the right singular vector.\nProof. By Corollary 3.6, the information content is invariant to the scaling of the linear functional. By Corollary 3.10, the optimal measurement functional is in the span of (\n\u00af \u03a3 + \u039b\u03c3) \u22121 \u00af \u03a3v. Thus, the vector generating the subspace is one possible\noptimal measurement."
        },
        {
            "heading": "E COMPUTATIONAL COSTS",
            "text": "In this section, we detail some of the specific aspects of the computation in this work. In particular, we detail the computational costs of the various operations, as well as provide more detail on the gradient ascent procedure for optimizing the 1D approximation. In Table 2 we include a summary of the computational cost scaling for the dynamic programming approach and the proposed gradient ascent based dimensionality reduction approach. Note that, as described in Section E.2, the evaluation cost of the proposed method can be reduced to O(CM2), where C is the number of gradient ascent steps, when the governing dynamics are particularly easy to solve.\nFrom this small table, the main observation is that the dynamic programming approach requires a prohibitively expensive initialization, as N is typically significantly larger than any other variables in the expressions. Furthermore, we do not necessarily incur a significant cost in the proposed method for evaluating the policy. Differences in iteration cost essentially reduce to a comparison of the number of gradient ascent steps C to the product of the number of discrete actions and the dimensionality of the system M |A|. As the surface area of the hypersphere grows exponentially with the dimensionality, the latter is often significantly larger."
        },
        {
            "heading": "E.1 Sampling State Space",
            "text": "O(NM3) multiplications, where N is the total number of samples.\nFirst, we must generate M2 + M scalar random variables. Then, QR factorization requires O(M3) multiplications (Trefethen and Bau, 1997). As N samples are required, the entire cost is O(NM3) multiplications."
        },
        {
            "heading": "E.2 Advancing State and CRLB in Time",
            "text": "Worst Case: O(M3) multiplications; Best Case: O(M2) multiplications\nAs evaluating \u03d5\u03c4 and d\u03d5\u03c4 are heavily dependent on the particular system, we treat these as some fixed constant cost, though it ranges from O(M) to O(M3).\nThe remainder of the update is then [d\u03d5\u03c4x] ( \u00af \u03a3\u22121 + \u03c3\u22122uu> )\u22121 [d\u03d5\u03c4x]\n>, where the inverse is computed using the Sherman\u2013 Morrison Formula (Sherman and Morrison, 1950)(\n\u00af \u03a3\u22121 + \u03c3\u22122uu>\n)\u22121 =\n\u00af \u03a3\u2212 \u00af\u03a3uu\n> \u00af \u03a3\n\u03c32 + u> \u00af \u03a3u\n. (102)\nThe number of multiplications for equation (102) can be limited through the following order of computations.\n1. Compute \u00af \u03a3u for M2 multiplications 2. Compute u>( \u00af \u03a3u) for M multiplications 3. Compute ( \u00af \u03a3u)/(\u03c32 + u> \u00af \u03a3u) for M multiplications\n4. Compute [ ( \u00af \u03a3u)/(\u03c32 + u> \u00af \u03a3u) ] [ \u00af \u03a3u] > for M2 multiplications.\nThus, the update equation requires 2(M2 +M) multiplications."
        },
        {
            "heading": "E.3 Computation of Local Average Weights",
            "text": "O(MN2|A|) multiplications, where |A| is the cardinality of the finite action space.\nThis involves computing the distance between all potential states after the observation at a given sample to all samples. Thus, as \u2016x\u2212 x\u2032\u2016 requires M + 1 multiplications, the computation of the entire set of distances requires MN2|A| multiplications, where |A| is the cardinality of the finite action space.\nIt is worth noting that this represents the primary cost of the dynamic programming approach, as the required value of N2 grows rapidly with the dimensionality of the system.\nE.4 Value Iteration\nO(|A|NKP ) multiplications, where K is the average number number of points in a dmax ball, and P is the number of steps in value iteration.\nIn this section, assume dmax is appropriately scaled such that states have an average number of K N neighbors. Then, each action for each state sample requires on average K multiplications, resulting in a total of |A|NK multiplications."
        },
        {
            "heading": "E.5 Dynamic Programming Optimal Action Evaluation",
            "text": "O((M3 +K)|A|) multiplications\nFor each possible action, we must advance the state and CRLB forward in time by one timestep, requiring O(M3) multiplications. We then must compute the local average of the sample value function for K multiplications."
        },
        {
            "heading": "E.6 Extended Kalman Filter",
            "text": "O(M2) multiplications\nx\u0302i|i = x\u0302i|i\u22121 + \u00af \u03a3iui(yi \u2212 u>i x\u0302i|i\u22121)\nu>i \u00af \u03a3iui + \u03c32\n, (103)\n1. Compute \u00af \u03a3u for M2 multiplications. 2. Compute u> ( \u00af \u03a3u) for M multiplications. 3. Compute u>x\u0302i|i\u22121 for M multiplications\n4. Combine multiplicative constants for 1 multiplication.\n5. Remaining update for M multiplications.\nAdding the above costs shows that the EKF update step requires M2 + 3M + 1 multiplications."
        },
        {
            "heading": "E.7 Gradient Ascent Optimization",
            "text": "O(M2) multiplications per gradient step\nWe now address the details of the iterative optimization of\narg max u:\u2016u\u2016=1\n(v> \u00af \u03a3u)2\nu> \u00af \u03a3u+ \u03c32u>u\n. (104)\nTo compute the gradient of the function on the sphere, we first need to compute the gradient in the ambient Euclidean space, then project onto the tangent space.\nBy the application of standard differentiation rules\nd\n( (v>\n\u00af \u03a3u)2\nu> \u00af \u03a3u+ \u03c32u>u\n) u = 2 ( u> \u00af \u03a3u+ \u03c32u>u ) v> \u00af \u03a3uv> \u00af \u03a3\u2212 ( v> \u00af \u03a3u )2 (u> \u00af \u03a3 + u>)\n(u> \u00af \u03a3u+ \u03c32u>u)\n2 (105)\n= 2\n( u>\n\u00af \u03a3u+ \u03c32\n) v>\n\u00af \u03a3uv> \u00af \u03a3\u2212\n( v> \u00af \u03a3u )2 (u> \u00af \u03a3 + u>)\n(u> \u00af \u03a3u+ \u03c32)\n2 , (106)\nwhere the second line comes from noting that \u2016u\u2016 = 1. Finally, we can slightly reduce the computation further by noting that we eventually orthogonalize the gradient to u. Thus, the following is an equivalent computation\n2\n( u>\n\u00af \u03a3u+ \u03c32\n) v>\n\u00af \u03a3uv> \u00af \u03a3\u2212\n( v> \u00af \u03a3u )2 u> \u00af \u03a3\n(u> \u00af \u03a3u+ \u03c32)\n2 , (107)\nBy performing operations in the following order, the differential of the value in Euclidean space requires few operations. Below, we count the number of multiplications.\n1. Compute \u00af \u03a3u for M2 multiplications.\n2. Compute u> ( \u00af \u03a3u) for M multiplications.\n3. Compute v> ( \u00af \u03a3u) for M multiplications.\n4. Compute v> \u00af \u03a3 for M2 multiplications.\n5. Computing remaining terms in numerator for 2M + 2 multiplications.\n6. Divide by numerator for M + 1 multiplications.\nFinally, we must project the result onto the tangent space of the sphere. Fortunately, the tangent space is straightforward for a sphere, in particular, it is the space orthogonal to u. Thus, we project the vector u out with 2M additional multiplications.\nBy adding all of the above, we find that computation of the gradient requires 2M2 + 7M + 3 multiplications.\nOnce the gradient has been computed, it defines the discrete-time approximation of the gradient flow by following the geodesic curve\nui+1 = cos(\u03b1i\u2016si\u2016)ui + sin(\u03b1i\u2016si\u2016)si/\u2016si\u2016, (108)\nwhere si is the gradient in the ambient space. The above computation requires another 3M multiplications.\nThus, each gradient ascent step requires 2M2 + 10M plus some constant number of multiplications from evaluating sine and cosine."
        },
        {
            "heading": "E.7.1 Gradient Ascent Simulations",
            "text": "To give a sense of the non-linear optimization problem, we include visualizations of two potential optimization surfaces for 3D systems, shown as two different panels in Figure 7. Because the domain of the function is the unit sphere, we include a pair of heatmaps in each panel representing the front and back of the sphere by a z-coordinate threshold to show the occluded side.\nThere are a two useful observations to be made. First, as was clear from both intuition and the form of the optimization problem, the function is symmetrical. Next, in these particular simulations, the function is relatively smooth with a \u201cunique\u201d maximum, only mirrored on the opposite side. This second observation allows the gradient ascent to be rather straightforward and gives us some certainty that, given appropriate step sizes, we will identify the true optimum. In these\nplots, v = [3\u22121/2, 3\u22121/2, 3\u22121/2] and \u03c32 = 1. The estimation CRLB took the form:\nPanel A: \u00af \u03a3 = 1.0 0.1 0.10.1 1.0 0.1 0.1 0.1 1.0  Panel B: \u00af \u03a3 = 1.0 0.0 0.00.0 1.0 0.0 0.0 0.0 1.0 \u2212 0.95vv>. (109) Figure 8 provides a representative trajectory of the gradient ascent operation over the previously illustrated objective.\nIn Panel A of Figure 8, we plot the trajectory of the gradient ascent on top of the objective function. The initialization was chosen to emphasize that the trajectory approximately follows a geodesic: when the projection of the sphere onto a plane is centered on the initial position, geodesic curves appear straight, similar to the behavior in this plot. Panel B shows the evaluation of the objective function over time, illustrating the rapid convergence in this simulation. In this simulation, a constant step size was chosen of \u03b1 = 0.1."
        },
        {
            "heading": "E.8 Timing Simulations",
            "text": "While the implementations in this work are not optimized, we include some timing plots below to give a sense of the rate at which the computational costs grow for the different approaches and provide a general order of magnitude for the performance. In our timing plots, a Van der Pol system is being observed. In order to best elucidate the scaling aspects, in the proposed method, the computation time is plotted as a function of dimensionality, while the dynamic programming computation time is plotted as a function of the number of state space representation points. The timing plots are available in Figure 9.\nTo generate the plots, the time required to initialize the algorithms as well as compute 1000 decision steps was recorded. Timing was done using the default number of runs in the BenchmarkTools library for Julia, which returns the minimum time of multiple runs to eliminate issues relating to just-in-time compilation and unrelated computer processes interfering with a run.\nTimesteps were spaced by 0.05 units of time in both simulations. In the proposed method, the 1D approximation was made at T = 10 units of time in the future, and 100 gradient ascent steps were computed. In the dynamic programming approach, the cardinality of the action space was 31, dmax = 1, and 100 steps of value iteration were completed in the initialization.\nIn the simulation of the proposed method shown in Panel A of Figure 9, we observe nearly linear growth in the computation time as a function of the dimensionality of the system with a sudden change around 40 dimensional systems potentially resulting in a change in caching at that point. This suggests that for the chosen parameters, the cost is dominated by system simulation costs which grow linearly for the chosen system as a function of dimension. In Panel B, the growth is clearly faster than linear.\nIt is additionally worth noting that, for reasonable performance, Panel B represents only a small subset of the domain of Panel A. As previously shown in Figure 6, the required number of samples rapidly increases with the dimensionality of the system, resulting in the dynamic programming approach becoming intractable while the proposed method still requires less than 1 second of computation."
        },
        {
            "heading": "E.9 System Specifications",
            "text": "The code in this project was run on on an AMD Ryzen Threadripper 3960X with 64 GB of RAM and 8GB swap running Ubuntu 20.04.2 LTS. All code was written in Julia 1.7.1, using the libraries\n1. DifferentialEquations v7.0.0, MIT \u201dExpat\u201d License, (Rackauckas and Nie, 2017)\n2. DiffEqSensitivity v6.69.0, MIT \u201dExpat\u201d License, (Ma et al., 2021)\n3. EllipsisNotation v1.1.3, MIT \u201dExpat\u201d License\n4. ForwardDiff v0.10.25, MIT License, (Revels et al., 2016)\n5. SafeTestsets v0.0.1, MIT \u201dExpat\u201d License\n6. Documenter v0.27.12, MIT License\n7. CSV v0.10.2, MIT \u201dExpat\u201d License\n8. BenchmarkTools v1.2.2, MIT \u201dExpat\u201d License, (Chen and Revels, 2016)\n9. CairoMakie v0.6.4, MIT \u201dExpat\u201d License, (Danisch and Krumbiegel, 2021)"
        },
        {
            "heading": "F NUMERICAL ISSUES",
            "text": "While the approximately singular behavior in this work benefit the statistical properties, they can introduce numerical issues in the implementation. While the algorithm introduced in the main paper functions in exact arithmetic, rounding errors in floating point arithmetic result in matrices becoming singular. In this section, we discuss the required modifications to account for these numerical issues relating to inverting such matrices.\nThe main issue is from the CRLB update formula\n\u00af \u03a3i+1 = [d\u03d5 \u03c4 x] ( \u00af \u03a3\u22121i + \u03c3 \u22122uu> )\u22121 [d\u03d5\u03c4x] > . (110)\nRecalling that \u00af \u03a3 and \u00af \u03a3\u22121 both begin as positive definite matrices, consider the operations that could make the inverse impossible. First, \u00af \u03a3\u22121 + \u03c3\u22122uu> may only become singular if \u03c3\u22122uu> is significantly large compared to an eigenvalue of the Fisher information. Fortunately, due to the dimensionality collapse and the continual collection of data, this issue does not appear.\nThe other, more likely, issue is that the application of the Jacobian creates a singular matrix. In practice, this happens quite often and thus must be addressed by replacement with an equivalent computation.\nTo resolve these issues, we complete the updates through the Sherman\u2013Morrison formula. We include here a brief note on the behavior of the Sherman\u2013Morrison formula when a matrix is singular.\n( \u00af \u03a3\u22121 + \u03c3\u22122uu> )\u22121 = \u00af \u03a3\u2212 \u00af\u03a3uu > \u00af \u03a3\n\u03c32 + u> \u00af \u03a3u\n. (111)\nWe argue that, when \u00af \u03a3 is singular, this update formula is equivalent to updating the subspace containing non-zero eigenvalues. To see this, we simply replace \u00af \u03a3\u22121 with the Moore-Penrose pseudoinverse before multiplying the terms to verify the property. Thus, replacement with the pseudo-inverse produces a new pseudo-inverse in the formula. By recalling that the pseudoinverse can be computed by inverting all non-zero singular values, we can conclude that the formula operates correctly in the subspace."
        },
        {
            "heading": "G CODE USAGE",
            "text": "The library produced for this manuscript is publicly available under the MIT license at github.com/Helmuthn/naumer_Dimensionality_2022.jl.\nThe implementation is a Julia package, and while not registered, can be installed through the package manager in the REPL through ] add https://github.com/Helmuthn/naumer_Dimensionality_2022.jl. We include here a short summary of the interface which much be defined to apply the library to a new problem.\nThe functions in the library make use of the type AbstractSystem, which is an abstract type with the following three functions:\ndimension\nThis function accepts an instance of AbstractSystem and returns the ambient dimensionality.\nflow\nThis function accepts an instance of abstractSystem, a state vector x, and a duration of time \u03c4 and returns the state advanced by \u03c4 .\nflowJacobian\nThis function accepts an instance of abstractSystem, a state vector x, and a duration of time \u03c4 and returns the Jacobian of the flow advancing by \u03c4 around initial condition x.\nWhile trivial, we now include the complete implementation of LinearSystem, which represents a linear system of ordinary differential equations, below as an example of an implementation of the interface.\n\"\"\" LinearSystem{T} <: AbstractSystem{T} Defines a linear system dx/dt = Ax ### Fields - \u2018dynamics::Matrix{T}\u2018 - Matrix defining dynamics \"\"\" struct LinearSystem{T} <: AbstractSystem{T} dynamics::Matrix{T} end\nfunction flow(x::Vector, \u03c4, system::LinearSystem) return exp(\u03c4 * system.dynamics) * x end\nfunction flowJacobian(x::Vector, \u03c4, system::LinearSystem) return exp(\u03c4 * system.dynamics) end\nfunction dimension(system::LinearSystem)\nreturn size(system.dynamics)[1] end\nIn typical applications, there will be no closed form solution for the dynamics. When this is the case, one can use standard libraries such as DifferentialEquations.jl and ForwardDiff.jl to define the AbstractSystem. An example is included below.\nusing DifferentialEquations, ForwardDiff\nstruct VanDerPolSystem{T} <: AbstractSystem{T} \u00b5::T end\nfunction dimension(system::VanDerPolSystem) return 2 end\nfunction vanderpolDynamics!(du, u, p, t) x, y = u \u00b5 = p du[1] = y du[2] = \u00b5 * (1 - x\u02c62) * y - x end\nfunction flow(x::Vector, \u03c4, system::VanDerPolSystem) problem = ODEProblem(vanderpolDynamics!, x, (0.0, \u03c4), system.\u00b5) sol = solve(problem, Tsit5(), reltol=1e-8)\nreturn sol[end] end\nfunction flowJacobian(x::Vector, \u03c4, system::VanDerPolSystem) problem = ODEProblem(hopfDynamics!, x, (0.0, \u03c4), system.\u00b5)\nfunction solvesystem(init) prob = remake(problem, u0=init) sol = solve(prob, Tsit5(), reltol=1e-8) return sol[end] end\nreturn ForwardDiff.jacobian(solvesystem, x) end\nDiscrete-time systems can be defined by restricting \u03c4 in the function definitions, i.e.\nflow(x::Vector, \u03c4::Integer, system::AbstractSystem)\nstruct DiscreteSystem{T} <: AbstractSystem{T} dynamics::Matrix{T} end\nfunction flow(x::Vector, \u03c4::Integer, system::DiscreteSystem) out = copy(x) for i in 1:\u03c4\nout .= system.dynamics * out end return out\nend\nfunction flowJacobian(x::Vector, \u03c4::Integer, system::DiscreteSystem) return system.dynamics\u02c6\u03c4\nend\nfunction dimension(system::DiscreteSystem) return size(system.dynamics)[1] end"
        },
        {
            "heading": "H SIMULATION DETAILS",
            "text": "In this section, we provide all parameters used in the generation of the figures in the main work. All code used to generate the figures is additionally available in the previously mentioned repository."
        },
        {
            "heading": "H.1 Figure 1",
            "text": "Simulations regarding the Van der Pol oscillator with parameter \u00b5 = 1 were completed for this figure.\nIn Panel A, the direction of the flow was plotted on a grid with samples spaced by approximately 1/3.\nIn Panel B, four trajectories initialized at\nx0 = [ 0.0 \u22124.0 ] x0 = [ 0.0 \u22120.1 ] x0 = [ 0.0 0.1 ] x0 = [ 0.0 4.0 ] , (112)\nand were simulated for 20 seconds of system time.\nIn Panel C, systems initialized at each of the grid points from Panel A were simulated for 20 seconds of system time with relative and absolute tolerance of 10\u22126. We then numerically differentiated the solution using the ForwardDiff library, a common forward mode automatic differentiation library in Julia with good support for differential equations sensitivity analysis. The singular value decomposition of the resulting Jacobian was computed, and the right singular vector associated with the largest singular value was plotted.\nIn Panel D, to compute a representation of the limit cycle, the system was initialized at\nx0 = [ 1.0 1.0 ]> (113)\nand was then simulated for 20 seconds of system time. We then computed the squared distances between the final point of the trajectory and the previous 100 positions spaced by 0.01 seconds of system time. As the period of the limit cycle is between 1 and 2 seconds of system time, we then computed the nearest position in the list. The trajectory from that index until the end was used to represent the phase of the limit cycle.\nAt each of the grid points from Panel A, the system trajectory was simulated for 40 seconds of system time. It was then assigned the index of the closest point in the phase representation of the limit cycle as its value and plotted as a heatmap with contours."
        },
        {
            "heading": "H.2 Figure 3",
            "text": ""
        },
        {
            "heading": "H.2.1 Panel A",
            "text": "Random sampling was completed through MersenneTwister in the Random library of Julia with the seed 1234, chosen arbitrarily.\nThe system took a constant value of x = [ 1 1 ]> .\nAs the system trajectory value does not impact the CRLB updates in this system, 1000 PSD matrix samples were used with eigenvalues following exponential distributions with parameter \u03bb = 1, while only one state space sample was chosen. The maximum distance for averaging was chosen as dmax = 1.\nObservations of the system were made under i.i.d. Gaussian noise with variance \u03c32 = 1. The action space for both the dynamic programming baseline approach and the proposed method was the set of vectors along the unit circle spaced by 0.1 radians between 0 and \u03c0.\nThe CRLB was initialized as\n\u00af \u03a3 = [ 4 0 0 4 ] , (114)\nwhile the state was randomly initialized by sampling two i.i.d. Gaussian random variables with variance 4.\nValue iteration was run for 1000 iterations with a discount factor of \u03b3 = 0.99 to ensure a focus on distant time horizons.\nThe proposed method was not run for this system, as it relies inherently on uneven singular values."
        },
        {
            "heading": "H.2.2 Panel B",
            "text": "Random sampling was completed through MersenneTwister in the Random library of Julia with the seed 1234, chosen arbitrarily.\nThe system followed the linear dynamics\nx\u0307 =\n[ \u221210.0 0\n0 \u22120.1\n] x, (115)\ndiscretized into timesteps of duration 0.01.\nAs the system trajectory value does not impact the CRLB updates in this system, 100 PSD matrix samples were used with eigenvalues following exponential distributions with parameter \u03bb = 1, while only one state space sample was chosen. The maximum distance for averaging was chosen as dmax = 2.\nObservations of the system were made under i.i.d. Gaussian noise with variance \u03c32 = 1. The action space for both the dynamic programming baseline approach and the proposed method was the set of vectors along the unit circle spaced by 0.05 radians between 0 and \u03c0.\nThe CRLB was initialized as\n\u00af \u03a3 = [ 4 0 0 4 ] , (116)\nwhile the state was randomly initialized by sampling two i.i.d. Gaussian random variables with variance 4.\nValue iteration was run for 10000 iterations with a discount factor of \u03b3 = 0.95 to ensure a focus on distant time horizons.\nFor the proposed technique, the limiting singular vector was approximated at 10 seconds of system time in the future."
        },
        {
            "heading": "H.2.3 Panel C",
            "text": "Random sampling was completed through MersenneTwister in the Random library of Julia with the seed 1234, chosen arbitrarily.\nThe system followed a Hopf bifurcation dynamic\nx\u0307(1) = x(1)(1\u2212 \u2016x\u20162)\u2212 x(2) x\u0307(2) = x(2)(1\u2212 \u2016x\u20162) + x(1)\n(117)\ndiscretized into timesteps of duration 0.01.\nThe dynamic programming space was approximated using the product space of 30 PSD matrix samples with eigenvalues following exponential distributions with parameter \u03bb = 1 and 120 state space samples. The state space samples were chosen by selecting 30 i.i.d. Gaussian vectors with each element independent with variance 25, then advancing each of the points by 4 timesteps, retaining each sample in the trajectory. The maximum distance for averaging was chosen as dmax = 2.\nObservations of the system were made under i.i.d. Gaussian noise with variance \u03c32 = 1. The action space for both the dynamic programming baseline approach and the proposed method was the set of vectors along the unit circle spaced by 0.1 radians between 0 and \u03c0.\nThe CRLB was initialized as\n\u00af \u03a3 = [ 4 0 0 4 ] , (118)\nwhile the state was randomly initialized by sampling two i.i.d. Gaussian random variables with variance 4.\nValue iteration was run for 100 iterations with a discount factor of \u03b3 = 0.99 to ensure a focus on distant time horizons.\nFor the proposed technique, the limiting singular vector was approximated at 30 seconds of system time in the future."
        },
        {
            "heading": "H.2.4 Panel D",
            "text": "Random sampling was completed through MersenneTwister in the Random library of Julia with the seed 1234, chosen arbitrarily.\nThe system followed a Hopf bifurcation dynamic\nx\u0307(1) = 10(x(2) \u2212 x(1)) x\u0307(2) = x(1)(28\u2212 x(3))\u2212 x(2)\nx\u0307(3) = x(1)x(2) \u2212 8\n3 x(3)\n(119)\ndiscretized into timesteps of duration 0.01.\nThe dynamic programming space was approximated using the product space of 30 PSD matrix samples with eigenvalues following exponential distributions with parameter \u03bb = 1 and 120 state space samples. The state space samples were chosen by selecting 100 i.i.d. Gaussian vectors with each element independent with variance 25. The maximum distance for averaging was chosen as dmax = 2.\nObservations of the system were made under i.i.d. Gaussian noise with variance \u03c32 = 1. The action space for both the dynamic programming baseline approach and the proposed method was a set of 50 i.i.d. uniformly chosen unit vectors.\nThe CRLB was initialized as\n\u00af \u03a3 = 1 0 00 1 0 0 0 1  , (120) while the state was randomly initialized by sampling two i.i.d. Gaussian random variables with variance 4.\nValue iteration was run for 100 iterations with a discount factor of \u03b3 = 0.9, intentionally lower due to the chaotic behavior of the system.\nFor the proposed technique, the limiting singular vector was approximated at 1 second of system time in the future, lower than the others to account for the lack of actual convergence. The time horizon was chosen based upon the time horizon being plotted."
        },
        {
            "heading": "H.3 Figure 4",
            "text": ""
        },
        {
            "heading": "H.3.1 Panels A and B",
            "text": "Simulations were identical to those in Figure 3 with the additional step of the extended Kalman filter. Observation decisions were made according to the estimated state.\nThe cost was normalized to the oracle solution for the dynamic programming approach in order to emphasize the difference between the performance of the four techniques."
        },
        {
            "heading": "H.3.2 Panel C",
            "text": "Random sampling was completed through MersenneTwister in the Random library of Julia with the seed 1234, chosen arbitrarily.\nThe simulated system followed a Van Der Pol Oscillator with \u00b5 = 1 as the chosen parameter augmented with additional linear dimensions governed by x\u0307(i) = \u2212x(i).\nThe CRLB was evaluated after 1000 observations, spaced by 0.05 units of system time. Observations were made under i.i.d. Gaussian noise with variance \u03c32 = 1.\n1000 steps of gradient ascent were completed for each observation with decaying step sizes \u03b1i = 104i\u22122/3, which empirically helped with ensuring quick convergence for all objective functions."
        },
        {
            "heading": "H.4 Figure 6",
            "text": "Random sampling was completed through MersenneTwister in the Random library of Julia with the seed 4321, chosen arbitrarily.\nFor each system dimensionalityM , 10000 i.i.d. M\u00d7M positive definite matrices were generated with eigenvalues sampled from an exponential distribution with parameter \u03bb = 1.\nThen, for each given number of samples N , we choose N + 1 points uniformly without replacement from the original dataset and compute the minimum distance from one of those selected points chosen randomly from the subset. The process is averaged 5000 times."
        }
    ],
    "title": "Dimensionality Collapse: Optimal Measurement Selection for Low-Error Infinite-Horizon Forecasting",
    "year": 2023
}