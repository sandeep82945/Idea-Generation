{
    "abstractText": "Active machine learning is widely used in computational studies where repeated numerical simulations can be conducted on high performance computers without human intervention. But translation of these active learning methods to physical systems has proven more difficult and the accelerated pace of discoveries aided by these methods remains as yet unrealized. Through the presentation of a general active learning framework and its application to large\u2010scale boundary layer wind tunnel experiments, we demonstrate that the active learning framework used so successfully in computational studies is directly applicable to the investigation of physical experimental systems and the corresponding improvements in the rate of discovery can be transformative. We specifically show that, for our wind tunnel experiments, we are able to achieve in approximately 300 experiments a learning objective that would be impossible using traditional methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Michael D. Shields"
        },
        {
            "affiliations": [],
            "name": "Kurtis Gurley"
        },
        {
            "affiliations": [],
            "name": "Ryan Catarelli"
        },
        {
            "affiliations": [],
            "name": "Mohit Chauhan"
        },
        {
            "affiliations": [],
            "name": "Mariel Ojeda\u2010Tuz"
        }
    ],
    "id": "SP:30fb396d3acea8e317fecd453ba0616239cf1a0a",
    "references": [
        {
            "authors": [
                "B. Settles"
            ],
            "title": "Active Learning Literature",
            "venue": "Survey (Tech Rep,",
            "year": 2009
        },
        {
            "authors": [
                "B. Shahriari",
                "K. Swersky",
                "Z. Wang",
                "R.P. Adams",
                "De Freitas",
                "N. Taking the human out of the loop"
            ],
            "title": "A review of Bayesian optimization",
            "venue": "Proc. IEEE 104, 148\u2013175",
            "year": 2015
        },
        {
            "authors": [
                "Z. Xiang",
                "Y. Bao",
                "Z. Tang",
                "H. Li"
            ],
            "title": "Deep reinforcement learning-based sampling method for structural reliability assessment",
            "venue": "Reliab. Eng. Syst. Saf. 199,",
            "year": 2020
        },
        {
            "authors": [
                "W. Shen",
                "Huan",
                "X. Bayesian sequential optimal experimental design for nonlinear models using policy gradient reinforcement learning. arXiv"
            ],
            "title": "2110",
            "venue": "15335",
            "year": 2021
        },
        {
            "authors": [
                "T. Blau",
                "E.V. Bonilla",
                "I. Chades",
                "A. Dezfouli"
            ],
            "title": "Optimizing sequential experimental design with deep reinforcement learning",
            "venue": "In International Conference on Machine Learning",
            "year": 2022
        },
        {
            "authors": [
                "Villarreal",
                "R. et al. Design of experiments for the calibration of history-dependent models via deep reinforcement learning",
                "an enhanced kalman filter. arXiv"
            ],
            "title": "2209",
            "venue": "13126",
            "year": 2022
        },
        {
            "authors": [
                "D.R. Jones",
                "M. Schonlau",
                "W.J. Welch"
            ],
            "title": "Efficient global optimization of expensive black-box functions",
            "venue": "J. Glob. Optim",
            "year": 1998
        },
        {
            "authors": [
                "B.J. Bichon",
                "M.S. Eldred",
                "L.P. Swiler",
                "S. Mahadevan",
                "J.M. McFarland"
            ],
            "title": "Efficient global reliability analysis for nonlinear implicit performance functions",
            "venue": "AIAA J. 46,",
            "year": 2008
        },
        {
            "authors": [
                "Y. Zhang",
                "D.W. Apley",
                "W. Chen"
            ],
            "title": "Bayesian optimization for materials design with mixed quantitative and qualitative variables",
            "venue": "Sci. Rep. 10,",
            "year": 2020
        },
        {
            "authors": [
                "Z. Zhou",
                "X. Li",
                "R.N. Zare"
            ],
            "title": "Optimizing chemical reactions with deep reinforcement learning",
            "venue": "ACS Cent. Sci",
            "year": 2017
        },
        {
            "authors": [
                "J Li"
            ],
            "title": "Synthesis of many different types of organic small molecules using one automated process",
            "venue": "Science 347,",
            "year": 2015
        },
        {
            "authors": [
                "P.S. Gromski",
                "A.B. Henson",
                "J.M. Granda",
                "L. Cronin"
            ],
            "title": "How to explore chemical space using algorithms and automation",
            "venue": "Nat. Rev. Chem",
            "year": 2019
        },
        {
            "authors": [
                "Sanderson",
                "K. Automation"
            ],
            "title": "Chemistry shoots for the moon",
            "venue": "Nature 568, 577\u2013580",
            "year": 2019
        },
        {
            "authors": [
                "N.S. Eyke",
                "W.H. Green",
                "K.F. Jensen"
            ],
            "title": "Iterative experimental design based on active machine learning reduces the experimental burden associated with reaction screening",
            "venue": "React. Chem. Eng",
            "year": 2020
        },
        {
            "authors": [
                "Y. Liu",
                "T. Zhao",
                "W. Ju",
                "S. Shi"
            ],
            "title": "Materials discovery and design using machine learning",
            "venue": "J. Materiom",
            "year": 2017
        },
        {
            "authors": [
                "Correa-Baena",
                "J.-P"
            ],
            "title": "Accelerating materials development via automation, machine learning, and high-performance computing",
            "venue": "Joule 2,",
            "year": 2018
        },
        {
            "authors": [
                "Tabor",
                "D. P"
            ],
            "title": "Accelerating the discovery of materials for clean energy in the era of smart automation",
            "venue": "Nat. Rev. Mater",
            "year": 2018
        },
        {
            "authors": [
                "Cao",
                "B. et al. How to optimize materials",
                "devices via design of experiments",
                "machine learning"
            ],
            "title": "Demonstration using organic photovoltaics",
            "venue": "ACS Nano 12, 7434\u20137444",
            "year": 2018
        },
        {
            "authors": [
                "T. Lookman",
                "P.V. Balachandran",
                "D. Xue",
                "R. Yuan"
            ],
            "title": "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design",
            "venue": "NPJ Comput. Mater",
            "year": 2019
        },
        {
            "authors": [
                "Melnikov",
                "A. A"
            ],
            "title": "Active learning machine learns to create new quantum experiments",
            "venue": "Proc. Natl. Acad. Sci. 115,",
            "year": 2018
        },
        {
            "authors": [
                "A.W. Naik",
                "J.D. Kangas",
                "D.P. Sullivan",
                "R.F. Murphy"
            ],
            "title": "Active machine learning-driven experimentation to determine compound effects on protein patterns",
            "venue": "Elife 5,",
            "year": 2016
        },
        {
            "authors": [
                "Y. Sverchkov",
                "M. Craven"
            ],
            "title": "A review of active learning approaches to experimental design for uncovering biological networks",
            "venue": "PLoS Comput. Biol. 13,",
            "year": 2017
        },
        {
            "authors": [
                "P. Carbonell",
                "T. Radivojevic",
                "H. Garcia-Martin"
            ],
            "title": "Opportunities at the intersection of synthetic biology, machine learning, and automation",
            "venue": "ACS Synth. Biol",
            "year": 2019
        },
        {
            "authors": [
                "M. Sesen",
                "G. Whyte"
            ],
            "title": "Image-based single cell sorting automation in droplet microfluidics",
            "venue": "Sci. Rep. 10,",
            "year": 2020
        },
        {
            "authors": [
                "A Lashkaripour"
            ],
            "title": "Machine learning enables design automation of microfluidic flow-focusing droplet generation",
            "venue": "Nat. Commun",
            "year": 2021
        },
        {
            "authors": [
                "J Tian"
            ],
            "title": "Low-rise gable roof buildings pressure prediction using deep neural networks",
            "venue": "J. Wind Eng. Ind. Aerodyn",
            "year": 2020
        },
        {
            "authors": [
                "J. Rabault",
                "M. Kuchta",
                "A. Jensen",
                "U. R\u00e9glade",
                "N. Cerardi"
            ],
            "title": "Artificial neural networks trained through deep reinforcement learning discover control strategies for active flow control",
            "venue": "J. Fluid Mech. 865,",
            "year": 2019
        },
        {
            "authors": [
                "S. Li",
                "R. Snaiki",
                "T. Wu"
            ],
            "title": "Active simulation of transient wind field in a multiple-fan wind tunnel via deep reinforcement learning",
            "venue": "J. Eng. Mech. 147,",
            "year": 2021
        },
        {
            "authors": [
                "Catarelli",
                "R. A"
            ],
            "title": "Automation and new capabilities in the university of florida NHERI boundary layer wind tunnel",
            "venue": "Front. Built Env",
            "year": 2020
        },
        {
            "authors": [
                "R Catarelli"
            ],
            "title": "Automated terrain generation for precise atmospheric boundary layer simulation in the wind tunnel",
            "venue": "J. Wind Eng. Ind. Aerodyn",
            "year": 2020
        },
        {
            "authors": [
                "P. Fern\u00e1ndez-Cab\u00e1n",
                "F. Masters"
            ],
            "title": "Near surface wind longitudinal velocity positively skews with increasing aerodynamic roughness length",
            "venue": "J. Wind Eng. Ind. Aerodyn",
            "year": 2017
        },
        {
            "authors": [
                "H. Schlichting"
            ],
            "title": "Boundary Layer Theory (McGraw-Hill",
            "venue": "Book Co.,",
            "year": 1979
        },
        {
            "authors": [
                "C.K. Williams",
                "C.E. Rasmussen"
            ],
            "title": "Gaussian Processes for Machine Learning Vol. 2 (MIT press, 2006)",
            "venue": "Scientific Reports |",
            "year": 2023
        },
        {
            "authors": [
                "B. Echard",
                "N. Gayton",
                "Lemaire",
                "M. AK-MCS"
            ],
            "title": "An active learning reliability method combining kriging and monte carlo simulation",
            "venue": "Struct. Saf. 33, 145\u2013154",
            "year": 2011
        },
        {
            "authors": [
                "C.Q. Lam"
            ],
            "title": "Sequential Adaptive Designs in Computer Experiments for Response Surface Model Fit",
            "venue": "Ph.D. thesis, The Ohio State University",
            "year": 2008
        },
        {
            "authors": [
                "A. Marrel",
                "B. Iooss",
                "B. Laurent",
                "O. Roustant"
            ],
            "title": "Calculations of sobol indices for the gaussian process metamodel",
            "venue": "Reliab. Eng. Syst. Saf",
            "year": 2009
        },
        {
            "authors": [
                "Phoon",
                "K.-K",
                "S. Huang",
                "S.T. Quek"
            ],
            "title": "Simulation of second-order processes using karhunen-loeve expansion",
            "venue": "Comput. Struct",
            "year": 2002
        }
    ],
    "sections": [
        {
            "text": "1 Vol.:(0123456789) Scientific Reports | (2023) 13:8402 | https://doi.org/10.1038/s41598-023-35257-7\nwww.nature.com/scientificreports"
        },
        {
            "heading": "Active learning applied",
            "text": "to automated physical systems increases the rate of discovery Michael D. Shields 1*, Kurtis Gurley 2, Ryan Catarelli 2, Mohit Chauhan 1, Mariel Ojeda\u2011Tuz 2 &"
        },
        {
            "heading": "Forrest J. Masters 2",
            "text": "Active machine learning is widely used in computational studies where repeated numerical simulations can be conducted on high performance computers without human intervention. But translation of these active learning methods to physical systems has proven more difficult and the accelerated pace of discoveries aided by these methods remains as yet unrealized. Through the presentation of a general active learning framework and its application to large\u2011scale boundary layer wind tunnel experiments, we demonstrate that the active learning framework used so successfully in computational studies is directly applicable to the investigation of physical experimental systems and the corresponding improvements in the rate of discovery can be transformative. We specifically show that, for our wind tunnel experiments, we are able to achieve in approximately 300 experiments a learning objective that would be impossible using traditional methods.\nActive learning is a subfield of machine learning (ML) in which an algorithm uses previously collected data to identify the most informative computational or physical experiment to run next, thus optimizing the learning rate for a specified objective1. In the past 20 years, active learning has grown into a discipline much of its own, with particular emphasis on the development of novel learning functions and their coupling with different ML methods. Prior applications of active learning (e.g. for Bayesian optimization2) have largely focused on the design of computer experiments in which the ML algorithm identifies the precise parameter values with which to initialize a computer model. Very recently, some related approaches have employed reinforcement learning (often used for active control) for the\u00a0design of computational experiments as well, e.g.3\u20136. Such applications are ubiquitous and are increasingly recognized as the state-of-the-art in design of computational experiments (see e.g.7\u20139).\nIn contrast to computational experiments, far fewer applications of active learning (or reinforcement learning10) for physical experiments can be found, largely due to the cost and logistical challenges associated with the automation of complex physical experiments. Several authors have composed \u201chow to\u201d articles that shed important light on potential future capabilities\u2014for example in chemical11\u201314 and materials discovery15\u201319, physics20, and in the biological sciences21\u201325. In the wind engineering field specifically, where large-scale physical testing is often required and numerical simulations remain an insufficient replacement, a few studies have used ML-based predictors derived from computational models with Boundary Layer Wind Tunnel (BLWT) experiments to validate the results26 or to control active flow purely using a priori numerical simulations27,28. But across fields, the potential for transformative discoveries remains largely unrealized, and active learning enabled discoveries from physical experiments remain largely hypothetical.\nIn this work, we describe and employ a novel framework for active learning within large-scale physical systems and apply it using actively learned BLWT experiments to discover fundamental relationships between terrain roughness, the resulting near-surface atmospheric turbulence, and ultimately the wind pressures needed to design critical infrastructure (Fig.\u00a01). Our automated and active learning-controlled experiments are enabled by the combination of effective learning functions, a novel automated \u201cTerraformer\u201d that rapidly modulates the tunnel\u2019s aerodynamic surface roughness, and a mechanized instrument traverse to measure experimental outcomes. We demonstrate that active learning can offer orders of magnitude reductions in the number of experimental configurations needed to enable foundational discoveries that would be otherwise infeasible.\nOPEN\n1Department of Civil and Systems Engineering, Johns Hopkins University, Baltimore, MD 21212, USA. 2Department of Civil and Coastal Engineering, University of Florida, Gainesville, FL 32611, USA. *email: michael.shields@ jhu.edu\n2 Vol:.(1234567890) Scientific Reports | (2023) 13:8402 | https://doi.org/10.1038/s41598-023-35257-7"
        },
        {
            "heading": "Methods",
            "text": "General active learning framework. Active learning for large-scale experimental investigations requires a tightly coordinated closed-loop system with active feedback between experimental equipment/instrumentation and data analysis/ML software. Our framework (Fig.\u00a01) is comprised of the following essential components:\n1. Quantities of interest: Each experiment must have a carefully selected and quantifiable objective in the form of a quantity of interest (QOI) or set of QOIs. The QOI is the measurable result of the experiment. It is a physically meaningful and informative takeaway from the experiment that serves as the basis for learning and discovery. 2. Experimental parameterization: The experimental design space must be appropriately parameterized and parameter ranges/distributions identified. An experimental design space may require a single parameter or hundreds of parameters. For expensive and time-consuming experiments, a down-selection mechanism is critical to identify the most influential parameters. 3. Automated/controlled actuation: Given a set of parameters, execution of the experiment must be automated. This requires a mechanized and controlled experimental apparatus that can configure and initialize experiments without requiring human intervention. 4. Automated measurement instrumentation: Instruments for measuring the data from which the QOI is extracted must be computer controlled and automated to eliminate costly and time-consuming manual operations, and coordinated and/or sequenced with automated experimental actuation. 5. Data processing/analysis utilities: Processing and/or analysis of the raw data from automated instrumentation is generally necessary. This may be simply extracting individual values (e.g., peaks) or performing complex regressions, optimization, or dimension reduction to extract salient features from the data. This data processing must be conducted rapidly \u201con-the-fly\u201d to extract the QOIs used for discovery and the associated active learning to select the next experiment. 6. Learning function: The learning function is the decision-making algorithm that specifies the parameter values for the next experiment based on previous QOIs. The learning function is typically designed from some underlying ML algorithm, but may also result from statistical analysis, data-driven learning methods, or even physics-based computations. The learning function must have low computational cost to avoid delays. 7. Human oversight (optional): Many experiments, especially those using large-scale and/or potentially dangerous or hazardous equipment, require that a human operator supervise certain aspects of the process. This generally involves human oversight of automated systems, human intervention as a failsafe, or perhaps an individual to manually initialize or verify a potentially risky automated sequence. Importantly, this human does not aid the learning process or interfere with the automated experiment.\nScope of the present study. We demonstrate how this active learning framework enables experimentally driven discoveries in a long-fetch open-circuit boundary layer wind tunnel (BLWT) having total dimensions\nFigure\u00a01. Schematic of the general active learning framework with specific application to boundary layer wind tunnel automation and learning.\n3 Vol.:(0123456789) Scientific Reports | (2023) 13:8402 | https://doi.org/10.1038/s41598-023-35257-7\nof 6 m W \u00d7 3 m H \u00d7 38 m L. Boundary layer flow development is investigated using controlled actuation of an automated roughness element grid that generates mechanical turbulence.\nIn a BLWT, fan-driven air is forced through a long duct with an array of roughness elements mounted to the floor to grow a boundary layer (BL) along the length of the tunnel. Near the floor, turbulence is created via mechanical mixing as air flows around the roughness elements. This influence of the surface roughness on turbulent behavior decays with height, as characterized by a turbulence BL profile (Fig.\u00a01\u2014inlay 1.), and depends on the spacing, shape, orientation, and height of the roughness elements. A trial-and-error procedure is typically utilized by manually adjusting roughness element arrays to simulate properly scaled standard BL profiles associated with terrains such as ocean-front, open farmland, or suburban conditions. The University of Florida BLWT (Fig.\u00a01\u2014inlay 3.) replaces the manual roughness adjustment approach with the Terraformer\u00a0-\u00a0a unique computer-controlled array of 1116 individual roughness elements (62 rows of 18) with fetch length of 18.3m that rapidly actuate to user-specified configurations29\u201331. Catarelli et\u00a0al.29 describes the characteristics, operation, and limitations of the system.\nWe harness the proposed active learning framework to discover families of Terraformer roughness grid configurations that produce statistically equivalent BL turbulence profiles. The goal is to reveal the critical relationship between terrain, turbulence and the resultant pressures on infrastructure being designed to resist wind loads. Statistical equivalence is defined through height dependent turbulence intensity (second-order) profiles of the wind velocity immediately downstream from the Terraformer roughness grid (Turbulence intensity is far from a complete descriptor of the turbulence profile. However, extensive investigations of various metrics, including complete power spectral profiles, demonstrated that turbulence intensity expresses many of the second-order salient features of the flow profile, while remaining scalar valued and thus easy to work with. Additional studies using more detailed descriptors are certainly possible, and this framework opens the door to such investigations). Any two profiles are considered statistically equivalent if the norm of their difference lies below a threshold, elaborated further below. The focus of this work is on the rapid discovery of second-order equivalent profiles enabled by active learning, while the significance of these second-order equivalent profiles to the engineering community will be presented in relevant domain-specific periodicals.\nWe apply the active learning framework to identify different Terraformer configurations that produce wind fields that are 2nd-order equivalent to those produced by a uniform grid with element heights all set to 80 mm (the benchmark configuration). This benchmark case for which equivalence is being sought creates mean and turbulence intensity profiles that match the standard models and metrics employed to investigate pressures on scale models of bluff body infrastructure (e.g. buildings)29,30, and are therefore of direct value to the wind engineering community. Each of the active learning components are described below with algorithmic and equipment design details provided in the Supplementary Materials (SM).\nQuantities of interest. This investigation seeks to discover 2nd-order equivalence between wind velocity fields generated from different terrains that achieve a surface-roughness Reynolds number Re\u2217 = u\u2217z0/\u03bd \u2265 2.5\u2014 defined by Schlichting32 to be aerodynamically fully-rough\u2014where u\u2217 is shear velocity, z0 is aerodynamic roughness length, and \u03bd is the kinematic viscosity of air . Our QOI measures the difference in the second-order statistical profiles of the wind velocity, defined through the turbulence intensity profile given by:\nwhere \u03c3(z) and \u00b5(z) are the standard deviation and mean velocity of the wind in the along-wind (x) direction at height (z) above the floor. Specifically, our QOI is defined as the L2 distance between two turbulence intensity profiles\nwhere l\u03b8x (z) is the experimental profile having parameters \u03b8 , and lbx(z) is the benchmark profile averaged over 25 repeated benchmark experiments with all element heights at 80 mm. The criterion d < \u01eb defines second-order equivalence where \u01eb is determined as the 99th percentile from a chi distribution obtained from statistical analysis of the 25 repeated benchmark experiments. See SM for a detailed derivation.\nExperimental parameterization. The Terraformer can be characterized by as many as 2232 degrees of freedom (i.e. the height and rotation angle for each element). We parameterized these degrees of freedom by choosing functional forms describing shapes that traverse the 62 rows of elements in the along-wind direction (the x-axis in Fig.\u00a01\u2014inlay 2 and 3.). We investigate five versions of this concept in three phases. Phase 1 controls the amplitude and wavenumber of a single sine wave (the phase and mean value are fixed). Phase 2 controls the mean element height and amplitude of three different wave shapes\u2014sine wave, triangular wave, and square wave. Phase 3 controls the parameters of a discretized random field (Fig.\u00a01\u2014inlay 2.). Details of these phases and the corresponding Terraformer parameterizations are provided in Table\u00a01 with additional information in the SM.\nAutomated measurement instrumentation. A mechanized instrument traverse in the BLWT is outfitted with three probes that measure the three fluctuating components of wind velocity (x,\u00a0y,\u00a0z) and static pressure in realtime (Fig.\u00a01\u2014inlay 4.). The probes collect data for 30 s and then move vertically in 20 mm increments to collect data at the next position. In total, data are collected over a height range from 180 to 500 mm in a plane perpen-\n(1)lx(z) = \u03c3(z)\n\u00b5(z)\n(2)d = \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 l\u03b8x (z)\u2212 l b x(z) \u2223 \u2223 \u2223 \u2223 \u2223 \u2223\n2\n4 Vol:.(1234567890) Scientific Reports | (2023) 13:8402 | https://doi.org/10.1038/s41598-023-35257-7\ndicular to the wind direction (Fig.\u00a01\u2014inlay 3.). The traverse and probe system automatically collect and transmit the necessary data to a computer to produce the QOI in the automated experimental sequence.\nData processing/analysis utilities. Data collected from the traverse-mounted probes are collected through a Labview DAQ system and stored to .th files that are read into a Matlab processing script that evaluates the turbulence intensity profile (1st QOI). Turbulence intensity profiles are then passed into a Python script that evaluates the distance from the benchmark profile (2nd QOI) and runs the learning function (described next) to identify the Terraformer parameter values for the next experiment. The script then generates the new Terraformer configuration file and notifies the equipment operator. In total, data processing and learning takes approximately 90 s per experiment.\nLearning function. The automated BLWT active learning framework is driven by a learning function whose objective is to identify the most informative experiment to run given the results of all prior experiments. We explored three learning functions summarized in Table\u00a02.\nAll learning functions are constructed from a Gaussian Process (GP) regression model33 used to predict the distance between the turbulence intensity profile of an as-yet untested parameterized Terraformer configuration and the benchmark turbulence intensity profile, along with a measure of the uncertainty in this prediction. More specifically, we define a performance function\nTable 1. Description of the three phases of experiments conducted in this study, including experimental parameterization. Notes: (i) Learning function names refer to Table\u00a02. (ii) Details of the Phase 3 expansion H(x) are found in the \u201cResults\u201d section below.\nPhase Terrain description Functional form and parameters Learning function\n1. Sine wave\nH(x) = \u00b5H + A sin(\u03c9(29, 500\u2212 x)+ \u03c0)\nNoisy U Noisy EIGF\nMean element height \u00b5H\nAmplitude A\nWave number \u03c9\n80 mm U(0,\u00a080) mm U(\u2212 2\u03c0 3000 , 2\u03c0 3000 )\nrad/mm\n2. (a) Sine wave (b) Triangular wave (c) Square wave\nHa(x) = \u00b5H + A sin(\u2212\u03c9(29, 500\u2212 x))\nHb(x) = \u00b5H + 2A \u03c0\narcsin(sin(\u2212\u03c9(29, 500\u2212 x))) Hc(x) = \u00b5H + A sgn(sin(\u2212\u03c9(29, 500\u2212 x)))\nNoisy UMean element height \u00b5H Amplitude A Wavenumber \u03c9\nU(50,\u00a0110) mm\nU(10,\u00a030) mm \u2212 \u03c0 3000 rad/mm\n3. Random field\nH(x) = \u00b5H + \u2211n i=1 \u03b8i \u221a i fi(29, 500\u2212 x)\nMUSIC Noisy U Mean element height \u00b5H Random field amplitudes \u03b8i , i = 1, . . . , n\n80 mm N(0,\u00a01)\nTable 2. Description of the learning functions employed in this study. Note: Definition of the terms in each equation can be found in the text body.\nLearning function Expression Objective\nNoisy U-function Un(\u03b8) = \u00b5g (\u03b8) \u221a\n\u03c3 2g (\u03b8)\u2212\u03c3 2 \u01eb (\u03b8)\nGoal: Conduct experiments along the parameter surface separating the 2 nd order equivalent and non-equivalent regions.\nHow: Conduct experiments that have the highest probability of incorrectly predicting the sign of the performance function.\nNoisy EIGF (Expected Improvement for Global Fit) E[In(\u03b8)] =\n(\n\u00b5g (\u03b8)\u2212 g(\u03b8 \u2217)\n)2\n+ \u03c3 2g (\u03b8)\u2212 \u03c3 2 \u01eb (\u03b8)\nGoal: Conduct experiments that globally best approximate the performance function.\nHow: Conduct experiments that have both high prediction uncertainty and large difference from nearby experiments.\nMUSIC\nGoal: Conduct experiments that allow efficient computation of sensitivity indices.\nHow: Conduct experiments that have both high prediction uncertainty and large differences from nearby experiments in conditional GP\n5 Vol.:(0123456789) Scientific Reports | (2023) 13:8402 | https://doi.org/10.1038/s41598-023-35257-7\nsuch that g(\u03b8) \u2264 0 corresponds to second-order equivalence and g(\u03b8) > 0 corresponds to second-order different profiles, where \u03b8 are the Terraformer configuration parameters, \u01eb is the threshold distance value for second-order equivalence. The GP regression model gives both a mean prediction \u00b5g (\u03b8) and the associated standard deviation \u03c3g (\u03b8) as a measure of uncertainty in the prediction. The Noisy U-function and Noisy EIGF, modified from34 and35 respectively to include noise in the GP, utilize these terms directly. Meanwhile, the MUSIC (Minimizing Uncertainty in Sensitivity Index Convergence) uses a main effect GP defined by the conditional expectation A(\u03b8(i)) = E\u03b8(\u2212i) [ g |\u03b8(i) ]\nwhere \u03b8(i) represents the ith component of \u03b8 and \u03b8(\u2212i) denotes all components of \u03b8 except component i, which has mean \u00b5A(i) (\u03b8 (i)) and standard deviation \u03c3A(i) ( \u03b8(i) ) 36.\nHuman oversight. The wind tunnel operator initializes the fans to the corresponding RPMs and, once the fans have reached the steady state the operator is in charge of running the LabVIEW interface to start collecting the data. Once the data collection is finished per experiment, the operator executes the Python script mentioned in the \u201cData processing/analysis utilities\u201d section to generate the next Terraformer configuration. The input file of the new Terraformer configuration is then loaded into the BLWT computer, and the process starts again. The safety-driven human operator actions account for less than 2 min of the 20 min needed per experiment, and the operator never interferes with the learning process."
        },
        {
            "heading": "Results",
            "text": "We studied the efficacy of the active learning approach in three phases of experiments (Table\u00a01). The first phase served as a proof of concept, the second was a validation exercise, and the third was a more comprehensive study of higher complexity intended to push the limits of active learning enabled discovery. Prior to any of the three heterogeneous element array phases described in Table\u00a01, we completed 25 identical uniform element array experiments (every element set to 80 mm) to provide the benchmark frame of reference for 2nd order equivalence exploration. The turbulence intensity profile averaged through these 25 experiments at each height provided the target second order profile, while the 25 individual turbulence intensity profiles provided the means to quantify the uncertainty among identical benchmark experiments at each height (See SM). Second order equivalence thus refers to whether the turbulence intensity profile from any individual heterogeneous element array experiment (from any of the 3 phases) is statistically \u2018within the experimental noise\u2019 of the benchmark turbulence intensity profile.\nPhase 1: Sine wave configuration & proof of concept. In phase 1, we considered a simple one-dimensional sine wave Terraformer element configuration in the along-wind direction with two variable parameters, the sine wave amplitude and the wave number (Table\u00a01), with the mean and phase fixed. The study served as a proof of concept, allowing us to \u201clearn the learning\u201d by applying two different learning functions to explore their capacity to achieve our objective of identifying second-order equivalence within the defined parameter space.\nWe began by conducting 25 experiments with different sine wave Terraformer configurations to train the GP surrogate and initialize the learning. We then performed 120 active learning experiments using the noisy U-function in which the amplitude was constrained by the maximum/minimum allowable element heights (160 mm and 0 mm, respectively), five manual experiments for validation (no learning), followed by 78 additional experiments over a reduced parameter space that focused on the region of second order equivalence with amplitude A \u2208 [0, 30] mm using the noisy EIGF. In total, 253 total experiments were conducted over 96 non-sequential hours. Despite using a variety of learning methods, and some manual intervention, this initial exploration of the learning gave us sufficient confidence that we could efficiently identify regions in the parameter space that resulted in second-order equivalence using the proposed learning function to select subsequent experiments.\nPhase 2: Wave shape study. In phase 2, we investigated the influence of three simple wave shapes (sinusoidal, triangular, and square) as a means of demonstrating the learning and its ability to identify the region of 2nd-order equivalence for related low-dimensional parameterized surface roughness. The three wave shapes were parameterized identically, varying the mean element height and wave amplitude over a range of interest identified from Phase 1 (Table\u00a01). In particular, the minimum amplitude of 10 mm ensured that all experiments would be sufficiently different from the benchmark (having zero amplitude) while extending to sufficiently large mean heights and amplitudes to capture the limits of equivalence. We were interested in studying these differences in shape to better understand the influence of different terrain features on turbulence profiles and learning. We initialized the learning by running 16 initial experiments with the same parameters, selected using stratified sampling to cover the space, for each shape to train the GP surrogate. We then ran active learning with the noisy U-function for a total of 43, 56 and 37 experiments for sine, triangular and square waves, respectively, over 78 h to adequately resolve the regions of 2nd-order equivalence. These regions are shown in Fig.\u00a02, where the solid lines showing the boundaries of the predicted equivalence regions are identified as the surface corresponding to g(\u03b8) = 0 from Eq. (3) using the actively learned GP surrogate. Observe that the sine and square wave profiles have very similar equivalence regions although the square wave region extends over a slightly narrower range of wave numbers and slightly lower amplitudes. This is perhaps intuitive because the square profiles have sharper transitions that will cause added turbulence. The second-order region for triangular waves, on the other hand, extends over similar wave numbers but extends to much higher amplitudes (up to \u223c 1 cm higher). This is because fewer elements project higher into the flow and the transitions are gradual, causing less turbulence. Importantly, these regions are identified by the learning very rapidly, requiring very few experiments to resolve.\n(3)g(\u03b8) = d ( l\u03b8x , l b x ) \u2212 \u01eb =\n\u2223\n\u2223\n\u2223\n\u2223\n\u2223 \u2223 l\u03b8x (z)\u2212 l b x(z)\n\u2223\n\u2223\n\u2223\n\u2223\n\u2223\n\u2223 2 \u2212 \u01eb\n6 Vol:.(1234567890) Scientific Reports | (2023) 13:8402 | https://doi.org/10.1038/s41598-023-35257-7\nThe paucity of required training points outside of the immediate regions of second-order equivalence illustrates the ability of this active learning framework to converge to a solution very efficiently. Videos showing the evolution of the boundary with each experiment can be found in the SM.\nPhase 3: Random field terraformer configuration. In the final phase, we exercised the active learning for a more complex Terraformer element configuration modeled as a one-dimensional Gaussian random field in the alongwind direction. The random field possesses the following covariance function\nwhere x1, x2 are two points along the length of the Terraformer, \u03c3 2 = 100 mm is the variance of the field, \u03c9 is the wave number, and a and \u03c9 are selected such that the length scale of the covariance function is given by L = a/(a2 + \u03c92) = 3000 mm, or approximately 1/6 of the Terraformer length. Shorter length scales may not adequately resolve the random field due to the discrete element construction of the Terraformer, while longer length scales would appear undesirably flat over the fetch length. We then expand the Gaussian random field using the Karhunen-Loeve Expansion37 shown in Table\u00a01 where i and fi(x) are the eigenvalues and eigenvectors of the covariance function respectively and \u03b8i , i = 1, . . . , n are standard normal random variables. We began by setting n = 10 and ran active learning for 300 total experiments, 27 initial training experiments and 273 using active learning with the newly developed MUSIC learning function (Table\u00a02) to compute sensitivity indices and reduce the dimension. Sensitivity estimates shown in Fig.\u00a03a indicated that second-order equivalence is, by far, most sensitive to dimension \u03b82 , corresponding to the second eigenvector, and has some modest sensitivity to dimension \u03b81 . All other main effect sensitivities are very small and considered negligible. These sensitivities do not add to one, as the remaining influences are from interactions. The GP-based sensitivity method used in the MUSIC learning function can also be used to compute interaction sensitivities. In this case, nearly all interactions sensitivities are attributed to interactions with \u03b82 such that its total effect sensitivity (main effects plus interactions) is close to 0.9.\nUsing a reduced dimension expansion with only n = 3 , justified by the active learning sensitivity analysis, we performed active learning with the noisy U-function starting with 27 initial experiments drawn using stratified sampling and a total of 197 experiments over 79 h. The 3D surface in Fig.\u00a03b shows the boundary of the predicted region of 2nd-order equivalence in this reduced 3D space with the parameters shown by their probabilities \ufffd(\u03b8i) , where \ufffd(\u00b7) is the standard normal cumulative distribution function. This equivalence region is consistent with the results of the sensitivity analysis, showing that indeed the \u03b82 dimension is the most sensitive. The region is relatively narrow in this dimension, extending only over the center of the distribution. Values in the tails of the distribution result in wind turbulence profiles that are not equivalent to the uniform 80mm element height benchmark. \u03b81 also appears to have some sensitivity, although the surface is wider in this dimension indicating a more gradual change in the second-order difference performance function. In \u03b81 the region extends almost completely into the lower tail (corresponding to large negative values), but does not extend into the upper tail. Finally, the \u03b83 dimension has very little sensitivity, with only very small variations in the region in this dimension. The region remains entirely open in both the upper and lower tails, meaning that even extreme values of this parameter in the tails of the distribution do not change whether the turbulence profile field is equivalent.\nThe equivalence region in Fig.\u00a03b was accurately resolved with less than 200 machine learning selected experiments. We did not use the experiments from sensitivity analysis in the analysis of second-order equivalence to\n(4)C(x1, x2) = \u03c3 2 exp (\u2212a|x2 \u2212 x1|) cos (\u03c9|x2 \u2212 x1|)\nFigure\u00a02. Phase 2 shape study\u2014regions of 2nd order equivalance for sine wave (blue), triangular wave (green), and square wave (red) terrains bounded by the limits of the experimental amplitude [10, 30] mm and mean height [50, 110] mm.\n7 Vol.:(0123456789) Scientific Reports | (2023) 13:8402 | https://doi.org/10.1038/s41598-023-35257-7\nmake these two distinct studies. If we had done so, the total number of experiments would have been even fewer. A video showing the evolution of these boundary with each experiment can be found in the SM."
        },
        {
            "heading": "Discussion",
            "text": "The direct impacts of this study on the field of wind engineering are the following:\n\u2022 Active machine learning can be used to efficiently produce wind fields with desired properties. \u2022 Vastly different terrains can produce wind fields with similar second-order statistical features. However, the\nhigher-order characteristics of these fields, which govern e.g. extreme wind loads, may not be the same. \u2022 Wide-ranging experimental investigations that have been historically intractable are now possible, which\nopens a new frontier of exploration for wind researchers that may translate to improved design and analysis practices for critical infrastructure.\nThese will be elaborated in domain appropriate publications, but the profound larger impact of these results shows the remarkable ability for active learning to enhance the rate of discovery from large-scale experiments. We first explored the potential for active learning and demonstrated rapid convergence toward the learning objective in a two dimensional parameter space. Phase 1 was notably inefficient since we explored the use of two learning functions, yet we achieved our objective with only 253 experiments and approximately 2 work weeks of automated experimental effort. By contrast, in order to achieve similar resolution of the second-order equivalence boundary using a na\u00efve Monte Carlo or tensor product space-filling experimental design approach would require an order of magnitude increase in resources, estimated at approximately 2500 experiments and 500 h (3 months) of full-time experimental effort, with many of these experiments wasted in regions of little influence. The improvement was even more remarkable in phase 2, where the learning was conducted in less than 100 total experiments for each case, a 25-fold reduction in effort compared with an expected 2500 experiments using a standard space-filling design.\nThe full benefits of pairing active learning with this experimental facility were truly realized in phase 3, where a full exploration of the 10-dimensional random field Terraformer configuration would require billions of experiments. A space-filling design with an average density of 10 samples in each dimension (e.g. a tensor product design) requires exploration of 1010 total Terraformer configurations, which would require several thousand human lifetimes to complete. Even if variance reduction or information maximization approaches for experimental design were applied, tens of thousands of experiments would be required and resulting in thousands of hours of experiments, which is still prohibitively large. Instead, the active learning sensitivity analysis required only 300 experiments to reduce the dimension to a modest 3 dimensions and only approximately 200 additional experiments to learn the equivalence region. In previous wind tunnel experimental frameworks, these studies would have been inconceivable. Of course, this owes to both the active learning and the state-of-the-art automation capabilities at the University of Florida BLWT facility. This highlights what is possible, through active learning, when such capabilities are available in experimental facilities (beyond just the BLWT) and serves as a strong motivator to construct new automated experimental facilities and modernize existing facilities with these capabilites.\nFigure\u00a03. Phase 3 random field terrain study\u2014(a) Main effect Sobol indices for each parameters of the KL expansion. (b) Second-order equivalence region in the first 3 dimensions identified from active learning. Note that axes are transformed to [0,1] by the standard normal cumulative distribution function \ufffd(\u00b7) . Points are colored according to coordinate \u03b83.\n8 Vol:.(1234567890) Scientific Reports | (2023) 13:8402 | https://doi.org/10.1038/s41598-023-35257-7\nThe impact of these findings extends far beyond the wind tunnel applications. With the active learning framework presented and demonstrated in this paper, active learning can have profound impacts on discovery across the scientific landscape. We have shown that active learning can have the same profound impact on physical experimentation and exploration as it has had on computational discoveries over the past 20 years. As a result, coupling active learning for sensitivity analysis to reduce dimension and other objectives for fundamental discovery in physical testing can transform the scientific endeavor in many areas from health to physics. That is not to say that dimension reduction of the order we achieved will always be possible, especially for problems that involve hundreds, or thousands, of parameters. But, in areas where this dimension reduction and learning are possible, the rate of scientific discovery is sure to increase substantially."
        },
        {
            "heading": "Data availability",
            "text": "The datasets generated and/or analysed during the current study are available through the DesignSafe repository38.\nReceived: 12 December 2022; Accepted: 15 May 2023"
        },
        {
            "heading": "Acknowledgements",
            "text": "This material is based upon work supported by the National Science Foundation under Grant Nos. 1930389, 1930625, 1520843, 2037725."
        },
        {
            "heading": "Author contributions",
            "text": "CRediT statement: M.D.S.: conceptualization, methodology, formal analysis, writing\u2014original draft, visualization, supervision, project administration, funding acquisition. K.G.: conceptualization, methodology, formal analysis, writing\u2014reviewing & editing, supervision, project administration, funding acquisition. R.C.: conceptualization, methodology, resources, writing\u2014reviewing & editing, visualization. M.C.: software, validation, formal analysis, investigation, writing\u2014reviewing & editing. M.O.-T.: software, validation, formal analysis, investigation, data curation, writing\u2014reviewing & editing. F.J.M.: conceptualization, resources, writing\u2014reviewing & editing."
        },
        {
            "heading": "Competing interests",
            "text": "The authors declare no competing interests."
        },
        {
            "heading": "Additional information",
            "text": "Supplementary Information The online version contains supplementary material available at https:// doi. org/ 10. 1038/ s41598- 023- 35257-7.\nCorrespondence and requests for materials should be addressed to M.D.S.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n\u00a9 The Author(s) 2023"
        }
    ],
    "title": "Active learning applied to automated physical systems increases the rate of discovery",
    "year": 2023
}