{
    "abstractText": "Standard full-shape clustering analyses in Fourier space rely on a fixed power spectrum template, defined at the fiducial cosmology used to convert redshifts into distances, and compress the cosmological information into the Alcock-Paczynski parameters and the linear growth rate of structure. In this paper, we propose an analysis method that operates directly in the cosmology parameter space and varies the power spectrum template accordingly at each tested point. Predictions for the power spectrummultipoles from the TNSmodel are computed at different cosmologies in the framework of\u039bCDM. Applied to the final eBOSS QSO and LRG samples together with the low-z DR12 BOSS galaxy sample, our analysis results in a set of constraints on the cosmological parameters \u03a9cdm, H0, \u03c38, \u03a9b and ns . To reduce the number of computed models, we construct an iterative process to sample the likelihood surface, where each iteration consists of a Gaussian process regression. This method is validated with mocks from N-body simulations. From the combined analysis of the (e)BOSS data, we obtain the following constraints: \u03c38 = 0.877\u00b10.049 and\u03a9m = 0.304+0.016 \u22120.010 without any external prior. The eBOSS quasar sample alone shows a 3.1\u03c3 discrepancy compared to the Planck prediction.",
    "authors": [
        {
            "affiliations": [],
            "name": "Richard Neveux"
        },
        {
            "affiliations": [],
            "name": "Etienne Burtin"
        },
        {
            "affiliations": [],
            "name": "Vanina Ruhlmann-Kleider"
        },
        {
            "affiliations": [],
            "name": "Arnaud de Mattia"
        },
        {
            "affiliations": [],
            "name": "Agne Semenaite"
        },
        {
            "affiliations": [],
            "name": "Kyle S. Dawson"
        },
        {
            "affiliations": [],
            "name": "Axel de la Macorra"
        },
        {
            "affiliations": [],
            "name": "Will J. Percival"
        },
        {
            "affiliations": [],
            "name": "Graziano Rossi"
        },
        {
            "affiliations": [],
            "name": "Donald P. Schneider"
        },
        {
            "affiliations": [],
            "name": "Gong-Bo Zhao"
        }
    ],
    "id": "SP:550cfb06921de3f9c48d8267e21e1d15cff4eac9",
    "references": [
        {
            "authors": [
                "S Alam"
            ],
            "title": "Living Reviews in Relativity",
            "venue": "Amendola L., et al.,",
            "year": 2020
        },
        {
            "authors": [
                "Blanton M. R",
                "AJ"
            ],
            "title": "ShapeFit: Extracting the power",
            "venue": "Brieden S., Gil-Mari\u0301n H., Verde L.,",
            "year": 2021
        },
        {
            "authors": [
                "S.-F. Chen",
                "Z. Vlah",
                "M. White"
            ],
            "title": "A new analysis of the BOSS",
            "year": 2021
        },
        {
            "authors": [
                "E. Rasmussen C",
                "I. Williams C. K"
            ],
            "title": "Gaussian Processes for Machine Learning (Adaptive Computation andMachine Learning)",
            "year": 2005
        },
        {
            "authors": [
                "P. Zhang",
                "Y. Cai"
            ],
            "title": "BOSS full-shape analysis from the EFTofLSS with exact time dependence",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Standard full-shape clustering analyses in Fourier space rely on a fixed power spectrum template, defined at the fiducial cosmology used to convert redshifts into distances, and compress the cosmological information into the Alcock-Paczynski parameters and the linear growth rate of structure. In this paper, we propose an analysis method that operates directly in the cosmology parameter space and varies the power spectrum template accordingly at each tested point. Predictions for the power spectrummultipoles from the TNSmodel are computed at different cosmologies in the framework of\u039bCDM. Applied to the final eBOSS QSO and LRG samples together with the low-z DR12 BOSS galaxy sample, our analysis results in a set of constraints on the cosmological parameters \u03a9cdm, \ud835\udc3b0, \ud835\udf0e8, \u03a9b and \ud835\udc5b\ud835\udc60 . To reduce the number of computed models, we construct an iterative process to sample the likelihood surface, where each iteration consists of a Gaussian process regression. This method is validated with mocks from N-body simulations. From the combined analysis of the (e)BOSS data, we obtain the following constraints: \ud835\udf0e8 = 0.877\u00b10.049 and\u03a9m = 0.304+0.016\u22120.010 without any external prior. The eBOSS quasar sample alone shows a 3.1\ud835\udf0e discrepancy compared to the Planck prediction.\nKey words: large-scale structure of Universe \u2013 cosmology: observations \u2013 cosmological parameters"
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Large scale structures (LSS) bring essential information on how the Universe evolved through the last 10 Gyr. The current spectroscopic surveys allow the construction of 3D maps of the Universe using biased tracers of matter (e.g. galaxies or quasars). In standard clustering analyses, the information encoded in the power spectrum of the tracer distribution in redshift space is compressed into three parameters: the Alcock-Paczynski parameters (\ud835\udefc\u2016 and \ud835\udefc\u22a5) that constrain the cosmological distances through the position of the baryon acoustic oscillations features (BAO) and the amplitude of velocity fluctuations \ud835\udc53 \ud835\udf0e8 measured from the clustering power as a function of the angle with respect to the line-of-sight. This compression is accurate but not exact as the information from the shape of the power spectrum is ignored (Brieden et al. 2021). In standard analyses, a fiducial cosmology is chosen to compute both\n\u2605 E-mail: richard.neveux@ed.ac.uk\nthe distances from object redshifts and the model power spectrum. In this case, the cosmological constraints extracted from the data present a dependency in the fiducial cosmology that requires to be treated as a systematic error (Smith et al. 2020). Recently, the eBOSS collaboration performed BAO and full shape (BAO+RSD) analyses at different epochs of the Universe evolution, from \ud835\udc67 = 0.6 to \ud835\udc67 = 2.2, in Fourier and configuration spaces (GilMar\u00edn et al. 2020; Bautista et al. 2021; de Mattia et al. 2021; Tamone et al. 2020; Neveux et al. 2020; Hou et al. 2021). The information from each tracer was compressed into a radial distance, a transverse distance and the growth rate of structures at each effective redshift. The eBOSS cosmological analysis (eBOSS Collaboration et al. 2020) was performed by fitting cosmological parameters onto these compressed quantities and showed that the inferred bias from the dependency in the fiducial cosmology was low enough regarding eBOSS statistical power but has to be considered for next-generation surveys like DESI (Collaboration et al. 2016) or Euclid (Amendola et al. 2018). Besides, different techniques have been used to take into\n\u00a9 2020 The Authors\nar X\niv :2\n20 1.\n04 67\n9v 3\n[ as\ntr o-\nph .C\naccount the full shape of the power spectrum, avoiding the compression step to directly constraint base cosmological parameters and accounting for the full shape of the power spectrum (S\u00e1nchez et al. 2017; Grieb et al. 2017; Tr\u00f6ster et al. 2020; Semenaite et al. 2021), andmore recently, using the Effective Field Theory approach (Ivanov et al. 2020; d\u2019 Amico et al. 2020; Colas et al. 2020; Chen et al. 2021; Zhang & Cai 2021). In the present analysis, we use a given cosmology to convert redshifts into distances to compute the data power spectrum. On the other hand, we evaluate the model power spectrum for different cosmologies in the\u039bCDM framework and compare the measured power spectrum to each model, letting nuisance parameters free while the informative parameters (\ud835\udefc\u2016 , \ud835\udefc\u22a5 and \ud835\udc53 \ud835\udf0e8) take their values as predicted in each considered cosmology. In this way, we are able to reconstruct the likelihood surface directly in the cosmological parameter space. We use the TNS model (Taruya et al. 2010) where calculation are done in the RegPT framework with correction computed at two loops (Taruya et al. 2012). Computing the model takes around 300 cpu hour per point, which is too expensive to be used in a Monte Carlo Markov Chain algorithm. To circumvent this problem, we construct an iterative emulator based on the algorithm presented in Pellejero-Iba\u00f1ez et al. (2020). Emulation has been gaining a lot of interest, as it allows to speed up the analysis by reducing the number of expensive function evaluations required by allowing to interpolate between model predictions at a set of points in the parameter space. This method has been used in a number of galaxy clustering analyses to directly emulate observables such as galaxy power spectrum (Kwan et al. 2015) and correlation function (Zhai et al. 2019) or model ingredients such as the redshift space power spectrum of halos (Kobayashi et al. 2021). Nevertheless, when building an emulator one must consider how theory model uncertainty might propagate to the cosmological parameter space which is non-trivial and needs to be validated for each new statistic or range of scales employed. The algorithm presented by Pellejero-Iba\u00f1ez et al. (2020) aims at dealing this challenge by emulating the likelihood function directly, which additionally simplifies the process of building the emulator by reducing the dimensions of the emulated quantity. It allows us to compute 100-1000 fewer models to span the cosmological parameter space and interpolate the whole likelihood surface by running a Gaussian process regression at each iteration. In section 2, we present the surveys we analysed as well as the mocks used to test our pipeline, section 3 presents the method, and section 4 lists the results obtained on mocks and on the (e)BOSS data."
        },
        {
            "heading": "2 CATALOGUES AND MOCKS",
            "text": "In this section, we present the BOSS and eBOSS data sets used in this work and describe the mocks built from the OuterRim N-body simulations used to test the analysis."
        },
        {
            "heading": "2.1 Data power spectrum",
            "text": "We analyse hereafter three samples of the SDSS collaboration (Blanton et al. 2017); the QSO and LRG sample of the extended Baryon Oscillation Spectroscopic Survey (eBOSS; Dawson et al. (2016)) and the low-z galaxy sample of BOSS (Dawson et al. 2013). Those data have been taken using the optical spectrograph of BOSS (Smee et al. 2013) in the 2.5m Sloan Foundation Telescope (Gunn et al. 2006). The quasars and galaxies target selections are presented in Myers\net al. (2015) and Prakash et al. (2016), respectively. We summarise, here, the statistic of those samples:\n\u2022 the eBOSS DR16 low-z quasar sample (0.8 < \ud835\udc67 < 2.2) including 343 708 objects,\n\u2022 the eBOSS DR16 LRG sample (0.6 < \ud835\udc67 < 1.0) including 377 458 objects,\n\u2022 the BOSS DR12 low-z LRG sample (0.2 < \ud835\udc67 < 0.5) including 604 002 objects.\nOur study is performed in Fourier space, and for the data part, we profit from all the results provided by the SDSS collaboration (Beutler et al. 2017; Gil-Mar\u00edn et al. 2020; Neveux et al. 2020). This includes power spectrum multipole measurements, window functions and fast mock power spectra used to compute the covariance matrix. The three samples are divided into northern (NGC) and southern (SGC) galactic caps. The k-ranges used in this work are the same as those used in each of the standard analyses and are summarised in table 1. Notice that the window functions are normalised following the normalisation of the power spectrum to ensure the consistency of the analysis (de Mattia & Ruhlmann-Kleider 2019). The eBOSS LRG and quasar samples slightly overlap at redshift 0.8 < \ud835\udc67 < 1.0. However, it consists of a relatively small part of the LRG sample. Following eBOSS analysis, the correlation has been estimated to be less than 0.1 and is neglected. For BOSS DR12, we use only the low-z part of the sample since the highest redshift part is included in the eBOSS DR16 sample. For the sake of simplifying the analysis, the BOSS galaxies within 0.5 < \ud835\udc67 < 0.6 are ignored. We use the fast mock power spectra provided with each sample to compute the covariance matrices for the individual likelihood computations, consistently with the individual analyses. Those power spectra are computed assuming the same redshift to distance relation as the data power spectrum."
        },
        {
            "heading": "2.2 QSO mocks",
            "text": "To test the analysis, we make use of mocks constructed from the OuterRim N-body simulation (Habib et al. 2016). This simulation contains 10 2403 dark matter particles of mass\ud835\udc5a = 1.85.109M h\u22121 in a box of length \ud835\udc3f = 3\u210e\u22121\ud835\udc3a\ud835\udc5d\ud835\udc50 with periodic boundary conditions. It was produced with a flat \u039bCDM cosmology:\n\u210e = 0.71, \u03a9cdmh2 = 0.1109, \u03a9bh2 = 0.02258, \ud835\udf0e8 = 0.8, ns = 0.963.\n(1)\nWe use QSO mocks built from one snapshot at \ud835\udc67 = 1.433 of the OuterRim simulation as explained in Smith et al. (2020). We use a halo occupation distribution (HOD) that is a function of the halo mass, composed by a top hat function to populate halos with central quasars and a power law for satellites. This HOD is used as our baseline in the following and is described in more details in Smith et al. (2020) where it is called \"mock2\". It was chosen as it is very\nMNRAS 000, 1\u201313 (2020)\nwell fit by the TNS model described in Sec 3.3. Therefore, we ensure that a difference in the cosmological inference of the present analysis would be due to our technique and not to the response of the TNS model to this particular HOD. We average the power spectra over 100 realisations for this particular HOD. The covariance matrix is rescaled considering that these 100 realisations are independent. As all realisations come from a unique dark matter distribution and so are not strictly independent, errors may be underestimated. From the same snapshot, we also use alternative mocks built with a different HOD, called \"mock4\" in Smith et al. (2020). This HOD combines a smooth step function for central quasars and a power law for satellites that corresponds to a more physical HOD for quasars."
        },
        {
            "heading": "3 ANALYSIS METHOD",
            "text": "We present here the general pipeline based on Pellejero-Iba\u00f1ez et al. (2020) and explain the different steps in more detail in the following subsections.\n(i) We compute the data power spectrum for a given fiducial cosmology. (ii) We create a Latin Hypercube sampling (LHS) to span the cosmological parameter space efficiently. (iii) We compute all cosmology-dependent terms of the model power spectrum for each point of the LHS and each effective redshift of the data using the 2-loop correction TNS model. (iv) For each point of the LHS, we fit the full model power spectrum to the data, minimizing only over nuisance parameters (as informative parameters are set to their true value in each model). Therefore, we obtain a likelihood value at each point. (v) We use aGaussian process to interpolate the likelihood surface in the cosmological parameter space. (vi) We select new points in the cosmological parameter space using the acquisition function to compute new power spectrum models. (vii) We fit those newmodel power spectra to the data, minimizing over nuisance parameters, and again run a Gaussian process. (viii) The two last points are iterated up to the convergence of the estimate likelihood distribution."
        },
        {
            "heading": "3.1 Data power spectrum",
            "text": "We use the data power spectra provided by the SDSS collaboration which have been all computed within the fiducial cosmology:\n\u210e = 0.676, \u03a9\ud835\udc5a = 0.31, \u03a9\ud835\udc4f\u210e2 = 0.022, \ud835\udf0e8 = 0.8, \ud835\udc5b\ud835\udc60 = 0.97\n(2)"
        },
        {
            "heading": "3.2 Latin Hypercube Sampling",
            "text": "To span the cosmological parameter space efficiently, we use a 5D Latin Hypercube sampling (LHS). Assuming \ud835\udc5b is the number of cosmological parameters, the LHS technique consists of dividing each dimension of the parameter space into \ud835\udc5b intervals. Then, for each parameter, the \ud835\udc5b intervals are filled only once, thereby enforcing minimal distance between points compared to a random Poisson sampling.\nThe cosmological parameter space chosen for this work encompasses large variations in order to avoid biasing the analysis:\n\u03a9cdm = [0.05, 0.9], \ud835\udf0e8 = [0.65, 1.5],\u03a9b = [0.015, 0.066], \ud835\udc5b\ud835\udc60 = [0.8, 1.15], \ud835\udc3b0 = [61, 76] .\n(3)\nThose ranges can be seen as a set of wide flat priors."
        },
        {
            "heading": "3.3 Model power spectrum",
            "text": "To model the power spectrum, we use the RegPT treatment of the TNSmodel (Taruya et al. 2012). In this framework, the redshift space tracer power spectrum is given by\n\ud835\udc43t (\ud835\udc58, \ud835\udf07) = \ud835\udc37 (\ud835\udc58, \ud835\udf07, \ud835\udf0e\ud835\udc63 , \ud835\udc4evir) [ \ud835\udc43t, \ud835\udeff \ud835\udeff (\ud835\udc58) + 2 \ud835\udc53 \ud835\udf072\ud835\udc43t, \ud835\udeff \ud835\udf03 (\ud835\udc58)\n+ \ud835\udc53 2\ud835\udf074\ud835\udc43\ud835\udf03 \ud835\udf03 (\ud835\udc58) + \ud835\udc4f31\ud835\udc34(\ud835\udc58, \ud835\udf07, \ud835\udc53 /\ud835\udc4f1) + \ud835\udc4f 4 1\ud835\udc35(\ud835\udc58, \ud835\udf07, \ud835\udc53 /\ud835\udc4f1)\n] ,\n(4)\nwhere the wavenumber \ud835\udc58 is the norm of the wavevector k and \ud835\udf07 its cosine angle with respect to the line-of-sight. \ud835\udc53 is the linear growth rate of structure. Here, \ud835\udc43t, \ud835\udeff \ud835\udeff (\ud835\udc58) and \ud835\udc43t, \ud835\udeff \ud835\udf03 (\ud835\udc58) are the tracer-tracer and tracervelocity power spectra, respectively, and are given by:\n\ud835\udc43t, \ud835\udeff \ud835\udeff (\ud835\udc58) = \ud835\udc4f21\ud835\udc43\ud835\udeff \ud835\udeff (\ud835\udc58) + 2\ud835\udc4f2\ud835\udc4f1\ud835\udc43\ud835\udc4f2, \ud835\udeff (\ud835\udc58) + 2\ud835\udc4f\ud835\udc602\ud835\udc4f1\ud835\udc43\ud835\udc4f\ud835\udc602, \ud835\udeff (\ud835\udc58)\n+ 2\ud835\udc4f3nl\ud835\udc4f1\ud835\udf0e23 (\ud835\udc58)\ud835\udc43 lin m (\ud835\udc58) + \ud835\udc4f22\ud835\udc43\ud835\udc4f22 (\ud835\udc58) + 2\ud835\udc4f2\ud835\udc4f\ud835\udc602\ud835\udc43\ud835\udc4f2\ud835\udc602 (\ud835\udc58) + \ud835\udc4f2\ud835\udc602\ud835\udc43\ud835\udc4f\ud835\udc6022 (\ud835\udc58) + \ud835\udc41\ud835\udc54, (5)\nand:\n\ud835\udc43t, \ud835\udeff \ud835\udf03 (\ud835\udc58) = \ud835\udc4f1\ud835\udc43\ud835\udeff\ud835\udf03 (\ud835\udc58) + \ud835\udc4f2\ud835\udc43\ud835\udc4f2, \ud835\udf03 (\ud835\udc58)\n+ \ud835\udc4f\ud835\udc602\ud835\udc43\ud835\udc4f\ud835\udc602, \ud835\udf03 (\ud835\udc58) + \ud835\udc4f3nl\ud835\udf0e23 (\ud835\udc58)\ud835\udc43 lin m (\ud835\udc58), (6)\nwhere \ud835\udc4f1 is the linear bias, \ud835\udc4f2 the second order local bias, \ud835\udc4f\ud835\udc602 the second order non-local bias, \ud835\udc4f3\ud835\udc5b\ud835\udc59 the third order non local bias and \ud835\udc41\ud835\udc54 the constant stochastic term. Assuming local Lagrangian bias, and following Saito et al. (2014), we set the non-local biases to:\n\ud835\udc4f\ud835\udc602 = \u2212 4 7 (\ud835\udc4f1 \u2212 1) , (7)\n\ud835\udc4f3nl = 32 315 (\ud835\udc4f1 \u2212 1) . (8)\nWe also assume no velocity bias, \ud835\udc43\ud835\udc61 , \ud835\udf03 \ud835\udf03 = \ud835\udc43\ud835\udf03 \ud835\udf03 . In this work, at each point in the cosmological parameter space we compute the linear matter power spectrum with CLASS and evaluate the non-linear matter power spectra \ud835\udc43\ud835\udeff \ud835\udeff ,\ud835\udc43\ud835\udeff\ud835\udf03 and \ud835\udc43\ud835\udf03 \ud835\udf03 , as well as RSD correction terms \ud835\udc34(\ud835\udc58, \ud835\udf07, \ud835\udc53 /\ud835\udc4f1) and \ud835\udc35(\ud835\udc58, \ud835\udf07, \ud835\udc53 /\ud835\udc4f1) at the 2-loop order, these last terms taking most of the computing time. The 1-loop bias terms \ud835\udc43\ud835\udc4f2, \ud835\udeff (\ud835\udc58), \ud835\udc43\ud835\udc4f\ud835\udc602, \ud835\udeff (\ud835\udc58), \ud835\udf0e23 (\ud835\udc58), \ud835\udc43\ud835\udc4f2, \ud835\udf03 (\ud835\udc58) and \ud835\udc43\ud835\udc4f\ud835\udc602, \ud835\udf03 (\ud835\udc58) are provided in Beutler et al. (2017). Finally, to account for non-linear effects, we include an overall damping function, \ud835\udc37 (\ud835\udc58, \ud835\udf07, \ud835\udf0e\ud835\udc63 , \ud835\udc4evir) = 1\u221a\ufe01\n1 + (\ud835\udc58\ud835\udf07\ud835\udc4evir)2 exp\n[ \u2212 (\ud835\udc58\ud835\udf07\ud835\udf0e\ud835\udc63 ) 2\n1 + (\ud835\udc58\ud835\udf07\ud835\udc4evir)2\n] . (9)\nAs explained inNeveux et al. (2020), this prescription allows to dissociate the Gaussian and the non-Gaussian part of the small scale nonlinear effects, through the parameters \ud835\udf0e\ud835\udc63 and \ud835\udc4evir, respectively. This damping term stands for the Finger-of-God effect as well as the redshift uncertainty. This damping term is based on the Finger-of-God of S\u00e1nchez et al. (2017), where we removed the \ud835\udc53 -dependency. Such an empirical term has been shown to correctly model various redshift smearing schemes in the eBOSS mock quasar challenge (Smith et al.\nMNRAS 000, 1\u201313 (2020)\n2020). Altogether, the model power spectrum is thus described by 5 nuisance parameters (\ud835\udc4f1, \ud835\udc4f2, \ud835\udc41\ud835\udc54, \ud835\udf0e\ud835\udc63 and \ud835\udc4evir). We make use of the model implementation of de Mattia et al. (2021), which has been tested against mocks as part of the eBOSS mock challenge (Alam et al. 2020; Smith et al. 2020) for redshifts \ud835\udc67 = 0.859 and \ud835\udc67 = 1.433. Those tests state that the main systematic error arises when using a template model cosmology different from the truth. Considering the tests when cosmologies match, the mock challenge indicates errors smaller than 3% for \ud835\udc53 \ud835\udf0e8 and 0.5% for the \ud835\udefc at both redshifts. Note that the model power spectrum requires to include the surveywindow functionwhich is computedwith the same fiducial cosmology as that used to estimate the data power spectrum."
        },
        {
            "heading": "3.4 Scaling the power spectrum",
            "text": "In standard clustering analyses, the same cosmology is used for the fiducial cosmology and the power spectrum model, and the scale factors are left free in the fitting procedure to recover the underlying cosmology. In this work, each template power spectrum model is evaluated in a cosmology that is different from the fiducial cosmology used to convert redshifts into distances. This difference produces geometrical distortions evaluated through theAlcock-Paczynski (AP) test (Alcock & Paczynski 1979) that are exactly accounted for by introducing two scaling factors:\n\ud835\udefc\u2016 = \ud835\udc37trueH (\ud835\udc67) \ud835\udc37fidM (\ud835\udc67) , \ud835\udefc\u22a5 = \ud835\udc37trueM (\ud835\udc67) \ud835\udc37fidM (\ud835\udc67) , (10)\nfor the line-of-sight and the transverse components, respectively, with distances evaluated in Mpc. Then, the wavenumber observed with the fiducial cosmology \ud835\udc58 and the true wavenumber \ud835\udc58 \u2032 are related by \ud835\udc58 \u2032\u2016 = \ud835\udc58 \u2016/\ud835\udefc\u2016 and \ud835\udc58 \u2032 \u22a5 = \ud835\udc58\u22a5/\ud835\udefc\u22a5. Transferring this into\n\ud835\udc58 = \u221a\ufe03 \ud835\udc582\u2016 + \ud835\udc58 2 \u22a5 and \ud835\udf07 the cosine with the line-of-sight leads to:\n\ud835\udc58 \u2032 = \ud835\udc58\n\ud835\udefc\u22a5\n[ 1 + \ud835\udf072 (( \ud835\udefc\u22a5 \ud835\udefc\u2016 )2 \u2212 1 )]1/2 \ud835\udf07\u2032 = \ud835\udf07\n\ud835\udefc\u22a5 \ud835\udefc\u2016\n[ 1 + \ud835\udf072 (( \ud835\udefc\u22a5 \ud835\udefc\u2016 )2 \u2212 1 )]\u22121/2 .\n(11)\nThe above (\ud835\udc58, \ud835\udf07) \u2192 (\ud835\udc58 \u2032, \ud835\udf07\u2032) mapping must be used together with Equation 4 to include the AP effect in the model power spectrum to be compared to data (see Equation 19 of de Mattia et al. (2021)). In this work, we operate directly in the \u039bCDM framework and the likelihood surface we build is expressed as a function of 5 cosmological parameters, \u03a9cdm, \ud835\udf0e8, \ud835\udc5b\ud835\udc60 ,\u03a9b and \ud835\udc3b0, where \ud835\udf0e8 is the normalisation of the linear power spectrum at redshift \ud835\udc67 = 0. Values of the standard parameters \ud835\udefc\u22a5, \u2016 and \ud835\udc53 \ud835\udf0e8 (\ud835\udc67) at any redshift of interest can be inferred from those of the cosmological parameters, using equation 10 for the dilation scales and taken from CLASS for the linear growth rate of structure \ud835\udc53 ."
        },
        {
            "heading": "3.5 Fit of nuisance parameters",
            "text": "For each model under test and for each galactic cap of each tracer, we find the best-fit nuisance parameters by maximizing the likelihood function,\n\ud835\udc3f \u221d \ud835\udc52\u2212\ud835\udf12 2/2, (12)\nwith\n\ud835\udf122 = (\ud835\udc43data \u2212 \ud835\udc43model (\ud835\udf03))\ud835\udc61\ud835\udc4a (Pdata \u2212 Pmodel (\ud835\udf03)), (13)\nwhere \ud835\udc43data is the data vector of power spectrum multipoles and \ud835\udc43model is the corresponding vector for the model that is a function of the parameters. We perform the \ud835\udf122 minimisation using the code MINUIT. The inverse of the covariance matrix,\ud835\udc4a , is computed from mocks and corrected for the finite number of mocks following the Hartlap et al. (2007) prescription:\n\ud835\udc4a = \ud835\udc41 \u2212 \ud835\udc5b \u2212 2 \ud835\udc41 \u2212 1 \ud835\udc36 \u22121, (14)\nwith \ud835\udc41 the number of mocks used in the construction of the covariance matrix and \ud835\udc5b the size of the data vector. Following Percival et al. (2014) and in line with standard analyses, we apply an additional scaling on the cosmological parameter covariance that results in an increase of the errors of the order of a few per cent. Then, for each point of the parameter space under consideration, the final data likelihood is obtained by taking the product of likelihoods for each tracer (QSO, LRG) and galactic caps (NGC, SGC), maximising its value over the five free nuisance parameters of the model (see section 3.3) for each tracer."
        },
        {
            "heading": "3.6 Gaussian process",
            "text": "To interpolate the likelihood surface in the 5-dimensional cosmological parameter space, we use a non-parametric technique that gives us the expected likelihood value at every point of the parameter space and the error on this interpolation. Two hypotheses must be verified to perform an efficient Gaussian process. The interpolated points have to be within the convex hull formed by the computed points. We use the approximation of restricting the interpolation interval by 5% for all parameters. The second hypothesis is that the surface to interpolate must be smooth enough; a small deviation in the hyperparameter space must induce a small deviation in the function. We expect the log-likelihood surface to follow this statement. We use a Gaussian process to estimate the value of the logarithm of the likelihood at a point (in the cosmological parameter space) \ud835\udc9a, \ud835\udc53\ud835\udc66 = log\ud835\udc3f (\ud835\udc9a), knowing the value of the likelihood on a set of points \ud835\udc4b = {\ud835\udc991, \ud835\udc992, ..., \ud835\udc99\ud835\udc41 }, \ud835\udc87 \ud835\udc4b = log\ud835\udc3f (\ud835\udc4b). We must evaluate the probability distribution of \ud835\udc53\ud835\udc66 knowing \ud835\udc87 \ud835\udc4b ; \ud835\udc5d( \ud835\udc53\ud835\udc66 | \ud835\udc87 \ud835\udc4b , \ud835\udc4b, \ud835\udc66). Assuming that the joint distribution of \ud835\udc87 \ud835\udc4b and \ud835\udc53\ud835\udc66 is Gaussian,\n\ud835\udc5d( \ud835\udc87 \ud835\udc4b , \ud835\udc53\ud835\udc66) = N (( \ud835\udf41\ud835\udc65 \ud835\udf07\ud835\udc66 ) , ( \ud835\udc3e\ud835\udc4b \ud835\udc3e\ud835\udc4b\ud835\udc66 \ud835\udc3e\ud835\udc47 \ud835\udc4b\ud835\udc66 \ud835\udc3e\ud835\udc66 . )) (15)\nAs in a standard Gaussian emulator analysis, we assume the central values of the multivariate Gaussian distribution to be \ud835\udf07\ud835\udc65 = \ud835\udf07\ud835\udc66 = 0. The interpolation is entirely governed by the covariance terms, \ud835\udc3e\ud835\udc4b referring to the covariance of \ud835\udc87 \ud835\udc4b , \ud835\udc3e\ud835\udc66 the (scalar) covariance of \ud835\udc53\ud835\udc66 , and \ud835\udc3e\ud835\udc4b\ud835\udc66 the (vector) covariance between \ud835\udc87 \ud835\udc4b and \ud835\udc53\ud835\udc66 . From \ud835\udc5d( \ud835\udc87 \ud835\udc4b , \ud835\udc53\ud835\udc66) and using the multivariate normal theorem we may calculate the conditional probability distribution as\n\ud835\udc5d( \ud835\udc53\ud835\udc66 | \ud835\udc87 \ud835\udc65) = N ( \ud835\udf41interp, \ud835\udc3einterp ) (16)\nwith\n\ud835\udf41interp = \ud835\udc3e\ud835\udc4b\ud835\udc66\ud835\udc3e \u22121 \ud835\udc66 \ud835\udc87 \ud835\udc4b (17)\n\ud835\udc3einterp = \ud835\udc3e\ud835\udc4b \u2212 \ud835\udc3e\ud835\udc4b\ud835\udc66\ud835\udc3e\u22121\ud835\udc66 \ud835\udc3e\ud835\udc47\ud835\udc4b\ud835\udc66 (18)\nIn these expressions, \ud835\udc87 \ud835\udc4b is known and we need to choose a form for the covariances. For this analysis wherewe expect the interpolated\nMNRAS 000, 1\u201313 (2020)\nsurface to vary smoothly, we choose the covariance (also called kernel) \ud835\udc3e to be a linear combination of a squared exponential (or radial basis function) and a linear kernel:\n\ud835\udc3e\ud835\udc56, \ud835\udc57 = \ud835\udf0erbf\ud835\udc52 \u2212 (\ud835\udc99\ud835\udc56\u2212\ud835\udc99 \ud835\udc57 )2 \ud835\udc59rbf + \ud835\udeff\ud835\udc37 (\ud835\udc56 \u2212 \ud835\udc57)\ud835\udf0efit, (19)\nwhere\ud835\udc3e\ud835\udc56, \ud835\udc57 is the covariance between point \ud835\udc99\ud835\udc56 and \ud835\udc99 \ud835\udc57 ,\ud835\udf0erbf represents the amplitude of the variance, \ud835\udc59rbf the characteristic interpolation length-scale and \ud835\udf0efit, the possible error in the determination of \ud835\udc87 \ud835\udc4b . In the Gaussian Process package that we use (GPy 2012), these three hyper-parameters are common to the five cosmological parameters, therefore we scale parameters by the standard deviation of current points X. The hyper-parameters are let free and fitted by maximizing the marginal log-likelihood of the probability function of the known points (Rasmussen & Williams 2005):\nlog \ud835\udc5d( \ud835\udc87 \ud835\udc4b |\ud835\udc4b, \ud835\udc3e) = \u2212 1 2 \ud835\udc87\ud835\udc47\ud835\udc4b\ud835\udc3e \u22121 \ud835\udc87 \ud835\udc4b \u2212 1 2 log |\ud835\udc3e | \u2212 \ud835\udc41 2 log(2\ud835\udf0b), (20)\nwith \ud835\udc41 , the number of points of the training sample. In a five-dimensional parameter space, even an algorithm as fast as the Gaussian process interpolation would take too long to run on a dense grid spanning the parameter space, therefore we run a Markov Chain Monte Carlo (MCMC) to obtain the interpolated loglikelihood hypersurface at each iteration step. One may further include additional priors when performing such sampling of the Gaussian process interpolation. In this analysis (see section 4.2), we study the impact of Gaussian priors: a prior on \ud835\udf14\ud835\udc4f = 0.0222 \u00b1 0.0005 inspired by the Big Bang Nucleosynthesis (BBN) analysis, and a prior on \ud835\udc5b\ud835\udc60 = 0.96 \u00b1 0.02, which are the minimal priors used in eBOSS Collaboration et al. (2020)."
        },
        {
            "heading": "3.7 New iteration and convergence",
            "text": "To check that the Gaussian process prediction has converged, we calculate newmodel power spectra. The choice of new points is done using an acquisition function \ud835\udc34(\ud835\udc99) that, in the general case, accounts for the interpolated log-likelihood and the error on the interpolation, \ud835\udf0e:\n\ud835\udc34(\ud835\udc99) = log \ud835\udc3finterp (\ud835\udc99) + \ud835\udefc\ud835\udf0elog \ud835\udc3finterp (\ud835\udc99)) (21)\nwhere \ud835\udefc is a free parameter that we set to 0 in our standard analysis. This gives an acquisition function that just accounts for the value of the interpolated likelihood to maximize the time spent to refine the region of spacewith high likelihood. Tests performedwith a non-zero value of \ud835\udefc did not show any improvement. The likelihood is computed at 10 points sampled from \ud835\udc34(\ud835\udc99), which we add to previously computed points for a new Gaussian process regression; such procedure is repeated until convergence. This is tested by computing the Kullback-Leibler divergence between the estimated likelihood distributions at iterations \ud835\udc56 and \ud835\udc56 \u2212 1, namely:\n\ud835\udc37KL (log \ud835\udc3finterp,i | | log \ud835\udc3finterp,i\u22121) = 1 2 [ log |\ud835\udc36\ud835\udc56\u22121 | |\ud835\udc36\ud835\udc56 | \u2212 \ud835\udc51 + \ud835\udc61\ud835\udc5f (\ud835\udc36\u22121 \ud835\udc56\u22121\ud835\udc36\ud835\udc56) + (\ud835\udf07\ud835\udc56\u22121 \u2212 \ud835\udf07\ud835\udc56) \ud835\udc47\ud835\udc36\u22121 \ud835\udc56\u22121 (\ud835\udf07\ud835\udc56\u22121 \u2212 \ud835\udf07\ud835\udc56) ] (22)\nwhere \ud835\udc51 is the dimension of the parameter space. Consistently with Pellejero-Iba\u00f1ez et al. (2020), we require the condition \ud835\udc37KL < 0.1 to be fulfilled to stop the iterative procedure."
        },
        {
            "heading": "4 RESULTS",
            "text": "In this section, we first study the efficiency of our analysis on mocks. The accuracy of the TNSmodel as well as the impact of observational systematics were evaluated in Beutler et al. (2017); Gil-Mar\u00edn et al. (2020); Neveux et al. (2020) and are not repeated here. Then, we present the results on BOSS and eBOSS data."
        },
        {
            "heading": "4.1 Results on QSO mocks",
            "text": "Our pipeline was tested on the mocks of section 2.2 to evaluate the performance of our full 5-D cosmological parameter space analysis."
        },
        {
            "heading": "4.1.1 Impact of the fiducial cosmology",
            "text": "Although the power spectrum template is varied throughout the cosmological parameter space, we check the dependence of the cosmological constraints with the fiducial cosmology chosen to convert redshifts to distances. Different tests were run to study this dependence, with results summarized in Table 2 and figure 1. We first take the OuterRim simulation cosmology (equation 1) as the fiducial cosmology. Note that the window function is also determined using that cosmology. The Latin hypercube performs a sampling of the cosmological parameter space with 100 initial points. For each new iteration, 10 points are drawn using the acquisition function presented in section 3.7. The results of the process are presented in blue in figure 1. The posteriors encompass the parameter expected values, even for \ud835\udc3b0, \u03a9b or \ud835\udc5b\ud835\udc60 which are not usually constrained by a clustering analysis. Moreover the \u03a9cdm and \ud835\udf0e8 parameters appear to be constrained with good accuracy and precision. Secondly, we perform the same analysis using the BOSS cosmology as the fiducial one (equation 2). This choice is extreme as the BOSS cosmology (\u03a9BOSS\ud835\udc5f\ud835\udc5a\ud835\udc5a = 0.31) is significantly different (around 7 times the Planck error on that parameter (Planck Collaboration et al. 2018)) from that of the OuterRim simulation (\u03a9ORm = 0.2648), which induces a dilation of 6.4% and 3.5%, of the parallel and perpendicular to the line of sight distances, respectively. In the general case, power spectrum analyses are performed on a specified \ud835\udc58 range. In different cosmologies, this implies that different physical modes enter the \ud835\udc58 range under consideration. To overcome this issue, we modify the initial \ud835\udc58 range (see Table 1) by scaling the limits of the range by a factor that depends on the isotropic distance scales as:\n\ud835\udc58BOSS = \ud835\udc58OR \ud835\udc37ORV \ud835\udc37BOSSV\n(23)\nwhere the distances are in [h\u22121 \u00b7Mpc] to also account for the different values of \ud835\udc3b0 between the two cosmologies. In the present case, the rescaled range is therefore \ud835\udc58 \u2208 [0.0209, 0.3134] h \u00b7Mpc\u22121. The purple contours and posteriors in figure 1 show the results using the BOSS cosmology and the rescaled \ud835\udc58-range. For all parameters, the results agree reasonably well with those obtained with the true cosmology of the simulation. The marginalized contour in the \ud835\udf0e8 \u2212 \u03a9cdm plane shows a slight drift along the line of degeneracy, equivalent to 0.9% and 2.3% shifts for \ud835\udf0e8 and \u03a9cdm, respectively. This is to be compared to 1.1% and 2.8% without updating the \ud835\udc58- range. For the other three parameters, \ud835\udc3b0, \u03a9b and \ud835\udc5b\ud835\udc60 , we note that the posteriors are bi-modal. This is likely to be due to the fact that our covariance matrix is approximate since it is based on 100 nonindependent realisations. Regardless of this issue, the marginalized 2-dimensional contours of the two analyses nicely overlap for these three parameters and their 68 and 95% constraints are in agreement.\nMNRAS 000, 1\u201313 (2020)\nTable 2. Constraints on the cosmological parameters in the QSO mock analysis for different configurations. The errors are the 68% marginalized confidence intervals. For \ud835\udc3b0 we report the 95% lower bound in the last three lines since the error interval reaches the flat prior boundaries we set in the fits. In the line \"Cfid = CBOSS & k = [0.0209, 0.3134] h \u00b7Mpc\u22121\", the results are presented as 95% confidence intervals for the \ud835\udc5b\ud835\udc60 and\u03a9b parameters because of their bi-modal posteriors.\nConfiguration \u03a9cdm \ud835\udf0e8 \ud835\udc5b\ud835\udc60 \u03a9b \ud835\udc3b0\nOuterRim cosmology input values 0.2200 0.800 0.963 0.0447 71.00\nCosmofid = CosmoOR (baseline) 0.2234 \u00b1 0.0072 0.794 \u00b1 0.012 0.986+0.016\u22120.067 0.0412 +0.0082 \u22120.0012 66.98 +8.4 \u22120.87\nCosmofid = CosmoBOSS 0.2297 \u00b1 0.0061 0.803 \u00b1 0.011 0.9095+0.061\u22120.0099 0.05157 +0.00060 \u22120.0079 > 66.48(95%)\nCfid = CBOSS & k = [0.0209, 0.3134] h \u00b7Mpc\u22121 0.2183 \u00b1 0.0066 0.787 \u00b1 0.011 0.898 < \ud835\udc5bfit\ud835\udc60 < 1.020 (95%) 0.0374 < \u03a9fitb < 0.0522 (95%) > 65.40(95%)\nalternative mock Cfid = COR 0.226 \u00b1 0.0067 0.803+0.0089\u22120.014 0.929 +0.064 \u22120.011 0.0501 +0.00064 \u22120.0081 > 66.09(95%)\nMNRAS 000, 1\u201313 (2020)\nWe also performed this mock analysis using the BOSS cosmology as the fiducial one butwith the initial range, \ud835\udc58 \u2208 [0.02, 0.3] h\u00b7Mpc\u22121. The pink contours in figure 1 show the corresponding constraints. For \ud835\udf0e8 and \u03a9cdm, the difference in contours and posteriors due to different \ud835\udc58 ranges is larger than that due to different fiducial cosmologies. This tends to prove that taking into account the same physical modes is of prime importance to obtain similar constraints. For the other parameters, the updating \ud835\udc58-range makes the contours and the likelihood profiles closer to those obtained with the true cosmology. Finally, the choice of the fiduciary cosmology may amount to a choice of range in \ud835\udc58 , which should be marginalised in a real data analysis."
        },
        {
            "heading": "4.1.2 Test using different HOD realizations",
            "text": "In previous section, we use the mock2. We test, here, with another HOD prescription called mock4 analysed in the same way, with the OuterRim cosmology as the fiducial one. Results are given in figure 2 and table 2. As for the baseline mocks, the posteriors for mock4 encompass the parameter values expected from the simulation cosmology. As in the previous section, posteriors obtained from the two mocks are in good agreement, especially when considering that the covariance matrix used in the cosmological fit only encompasses noise in the galaxy - halo connection and not cosmic variance (see Section 2.2). For \ud835\udf0e8 and \u03a9cdm, we note a slight shift of the contour along the degeneracy line, which results in a difference of 1.1% and 1.2% on the two parameter best fit values, respectively. Summarising, these mock studies demonstrate that the technique proposed here allows to recover the baseline cosmological parameters at 1.5% for \ud835\udf0e8 and 3% for\u03a9cdm independently of the chosen fiducial cosmology."
        },
        {
            "heading": "4.2 Results on data",
            "text": "The three data samples of section 2.1 were analysed in the same way as mocks. Our main results are shown in figures 3 and 6 and summarised in table 3. We present hereafter combined results as well as results from the individual samples and discuss the impact of priors from external probes."
        },
        {
            "heading": "4.2.1 Combined survey analysis",
            "text": "As shown in figure 3, when no external priors are used (grey contours), we find that \ud835\udc3b0 is very little constrained, as expected in a galaxy clustering analysis. Constraints can be set on \u03a9b and \ud835\udc5b\ud835\udc60 , namely\u03a9b = 0.0566+0.0040\u22120.0074 and \ud835\udc5b\ud835\udc60 = 0.973\u00b10.054. The uncertainty is an order of magnitude larger than that of the Planck CMB analysis (Planck Collaboration et al. 2018), \u03a9Planckb = 0.0493 \u00b1 0.0003 and \ud835\udc5bPlanck\ud835\udc60 = 0.965\u00b1 0.004. However, galaxy clustering analyses do not usually report any constraint on these parameters. The value of \u03a9cdm = 0.249+0.017\u22120.011 is within 1\ud835\udf0e of the Planck value. This is true also for the other parameters, except \ud835\udf0e8 = 0.877\u00b10.049whose value is 1.4\ud835\udf0e above that of Planck. Including a prior from the BBN (see section 3.6) on the value of \ud835\udf14b = \u03a9b \u00b7 h2 (black contours), the constraints improve on \ud835\udc3b0 = 66.1 \u00b1 1.5 km.s\u22121.Mpc\u22121 and \u03a9b = 0.0506 \u00b1 0.0022. It is however interesting to note that this prior has very little impact on the other constraints e.g. \u03a9cdm = 0.253+0.017\u22120.010 and \ud835\udc5b\ud835\udc60 = 0.983 \u00b1 0.056 or no impact at all, e.g. \ud835\udf0e8 = 0.877 \u00b1 0.051 and \u03a9m = 0.304+0.016\u22120.010.The matter density is identical, only its share between baryons and cold dark matter has varied.\nAdding a prior on \ud835\udc5b\ud835\udc60 (see section 3.6) to the previous analysis (black contours in figure 6) induces a slight change which remains very small with respect to the statistical error. Altogether, the weak impact of the priors shows that robust cosmological constraints on \u03a9m and \ud835\udf0e8 can be obtained without any additional information from external probes on parameters not constrained by galaxy clustering analyses like \ud835\udc5b\ud835\udc60 and \ud835\udf14b. In figure 4, we compare our results with those presented in eBOSS Collaboration et al. (2020) based on standard clustering analysis techniques and the \u039bCDM framework. This comparison is done under the same assumptions, i.e. including the same priors on \ud835\udf14b and \ud835\udc5b\ud835\udc60 . The contours have similar areas but different orientations and the constraints projected onto \ud835\udf0e8 and \ud835\udc3b0 are stronger with the standard analysis, most probably because of the more extended range in redshift of the extra samples that it includes, as detailed below. The present analysis allows a better constraint on \u03a9m despite the differences in terms of number of objects and effective volume. This stronger constraint illustrates the significant gain in precision allowed by a varying template analysis with no compression of the information. To emphasize this, we recall that the present analysis is composed of three samples (BOSS low-z galaxies, eBOSS LRGs and quasars) while the standard analysis is composed, in addition, of the MGS sample, BOSS high-z galaxies, and eBOSS ELG and Lyman-\ud835\udefc samples. Therefore, the complete SDSS survey contains 2.5 million objects over a redshift range of 0.07 < \ud835\udc67 < 4 while this analysis includes 1.3 million objects over 0.2 < \ud835\udc67 < 2.2. In addition, the standard analysis uses a consensus between the correlation function and power spectrum analyses, which usually improves errors by 10%, while the present study is only carried out in Fourier space. On the other hand, in this analysis, we do not include errors related to systematic effects. Nevertheless, systematic observational errors have been investigated in individual power spectrum analyses for the informative parameters (\ud835\udefc\u22a5, \u2016 and \ud835\udc53 \ud835\udf0e8) and remain small compared to the statistical error (e.g. \ud835\udf0eobs/\ud835\udf0estat \u223c 0.1 for quasars). Their addition in quadrature is therefore negligible. Considering the error due to the power spectrum modelling, we remind that the dominant source of error in eBOSS analyses comes from the specification of the cosmology for themodel computation. Taking the difference between our mock results obtained with the two different fiducial cosmologies (due to different effective \ud835\udc58-ranges) as model systematic error leads to \ud835\udf0emod\ud835\udf0e8 = 0.012 and \ud835\udf0e mod \u03a9cdm\n= 0.007, which corresponds to 25% and 44% of the statistical error, respectively. In addition to the present analysis, the full shape two point correlation function of the eBOSS QSO and BOSS DR12 galaxy samples sample were analysed by Semenaite et al. (2021). In their work, they directly constrain the cosmological parameters in configuration space by fitting their modelled two-point correlation function to the data and focus on \u210e-independent parameters \ud835\udf14m, \ud835\udf14DE and \ud835\udf0e12 as proposed by S\u00e1nchez (2020). In figure 5, we compare their results with the ones obtained in this work. The three parameters that are recovered from both analyses (\ud835\udf0e8, \u03a9m and \ud835\udc5b\ud835\udc60) are found to be compatible at the 1 \ud835\udf0e level, although the samples considered in both analyses are not exactly the same (our work includes the eBOSS LRG sample which is not used in Semenaite et al. (2021) who, however, additionally analyse the measurements from BOSS DR12 high-z sample). In addition to this, there are also differences in modelling the non-linear tracer power spectrum, in particular, Semenaite et al. (2021) use a different model for non-linear clustering predictions as well as a different bias prescription. Finally, the two analyses differ in the choice of priors - firstly, in terms of parameters on which a flat prior is imposed and secondly, in the use of the BBN prior with this analysis\nMNRAS 000, 1\u201313 (2020)\nemploying (when applicable) a significantly tighter Gaussian prior instead of the wider flat informative prior used in Semenaite et al. (2021)."
        },
        {
            "heading": "4.2.2 Single tracer analysis",
            "text": "In this section, we analyse the low redshift samples (BOSS galaxies and eBOSS LRGs) and the high redshift sample (eBOSS quasars) separately. Figure 6 presents the different contours when including the same priors on \ud835\udf14b and \ud835\udc5b\ud835\udc60 as for the combined analysis. Indeed, as written in table 3, without these priors, \ud835\udc5b\ud835\udc60 (resp. \ud835\udf14\ud835\udc4f) is not constrained better than its range of variation used in the fit to the galaxy (resp. quasar) sample. This may be due to the lower sample size and to the loss of leverage between high and low redshifts in individual analyses compared to the combined one. Including priors in the individual analyses has thus a more important impact than on the combined one. However, this difference is still smaller than the statistical uncertainty.\nThe posteriors of the low and high redshift analyses agree on\u03a9cdm and show a small but not negligible difference on \ud835\udc3b0, \u03a9b and \ud835\udc5b\ud835\udc60 , corresponding to deviations of 0.9\ud835\udf0e, 1\ud835\udf0e and 0.7\ud835\udf0e, respectively. The constraints on these parameters are also in agreement with Plank results, and so do our derived \u03a9m results. On the other hand, the galaxy and quasar analyses differ by 3.6\ud835\udf0e on \ud835\udf0e8. The constraint from the galaxy sample agrees with Planck result (1.6\ud835\udf0e lower) while that from the quasar sample is 3.1\ud835\udf0e higher. A 2\ud835\udf0e bias with respect to Planck is also visible in the standard analysis (Neveux et al. 2020), when fixing the linear growth rate of structure to the GR expectation. Nevertheless, this discrepancy is reinforced in the present study.\nThis notably high \ud835\udf0e8 value from high redshift quasars constitutes an unexplained tension with the other data sets used here. This may be due to an unknown or poorly understood systematic effect, physics not explained by the\u039bCDMmodel, or simply a statistical fluctuation. We did a few tests to check the robustness of this difference. In our framework, we constrain\ud835\udf0e8 (\ud835\udc67 = 0) from themeasurement of \ud835\udc53 \ud835\udf0e8 (\ud835\udc67) at \ud835\udc53 fixed to the value predicted by general relativity at each point of\nMNRAS 000, 1\u201313 (2020)\nthe cosmological parameter space. However, the \ud835\udf0e8 parameter also appears in the amplitude of the power spectrum monopole through the product \ud835\udc4f1\ud835\udf0e8 (\ud835\udc67) (in linear theory). In figure 7, we show the power spectrum multipoles for the NGC part of the quasar sample (the SGC shows a similar behavior) along with the best fit model for the cases where all tracers (dotted line) or only the quasar sample (solid line) are considered (no external priors). For both fits, there is no constraining power on the value of \u210e and we have set it to \u210e = 0.7 for the sake of comparison. The monopole is unaffected as a consequence of the \ud835\udc4f1\ud835\udf0e8 degeneracy previously mentioned. On the other hand, the amplitude of the best fit model for the quadrupole at large scales depends upon the samples considered. Therefore, the difference in \ud835\udf0e8 between the galaxy and quasar fits stems mostly from the amplitude of the quadrupole measured with the eBOSS quasar sample. More data from upcoming surveys should help settle this issue. We verified that the updated scheme to mitigate\nphotometric systematics using the neural network approach proposed by Rezaie et al. (2021) and used in the \ud835\udc53NL analysis of Mueller et al. (2021) had no effect on the power spectrummultipoles in the \ud835\udc58-range of interest of this work and cannot account for the high value of \ud835\udf0e8. The study presented in Semenaite et al. (2021) also considers the quasar sample alone and their results differ from ours by 1.6 and 1\ud835\udf0e for \ud835\udf0e8 and \u03a9m respectively, which differences in the analysis may explain."
        },
        {
            "heading": "5 CONCLUSIONS",
            "text": "We analysed the power spectrum of a subsample of the BOSS and eBOSS data using a TNSmodel with 2-loop RegPT correction terms. To avoid the fiducial cosmology dependency of the clustering analysis, we built an iterative emulator of the analysis likelihood surface\nMNRAS 000, 1\u201313 (2020)\nby varying the cosmology of the template model. We fit model power spectra for different cosmologies to the data power spectrum, fixing the dilation scales and the growth rate of structure to their values expected in each tested cosmology and letting the nuisance parameters vary freely. Then, we reconstruct the full likelihood surface in the 5D cosmological parameter space using a Gaussian process algorithm. This technique allows us to fit the cosmological parameters without the standard compression in \ud835\udc53 \ud835\udf0e8 and scaling parameters \ud835\udefc\u2016 and \ud835\udefc \u22a5 and with minimal power spectrum model computation.\nWe tested this pipeline on mocks built from the OuterRim N-body simulation and efficiently recovered the five cosmological parameters with good accuracy and precision. Then, we analysed three samples of the SDSS spectroscopic surveys both individually and jointly, namely the BOSS low-z galaxy sample and the eBOSS LRG and QSO samples. The analysis of the QSO sample leads to a \ud835\udf0e8 value significantly different from that predicted from the Planck constraints (Planck Collaboration et al. 2018). This bias is also visible in the standard analysis (Neveux et al. 2020), with a 2\ud835\udf0e deviation from\nthe Planck analysis when fixing the linear growth rate of structure to the GR expectation. Nevertheless, this discrepancy is reinforced in the present study and reaches a 3.1\ud835\udf0e significance. All other parameters are in good agreement with the constraints from the CMB analysis.\nThe combined likelihood of the three samples allows us to fit \u03a9b, \ud835\udc5b\ud835\udc60 , \u03a9m and \ud835\udf0e8 without any external prior. We compare our final results with the cosmological analysis of the full SDSS survey; we obtain similar constraints on the \ud835\udc3b0, \ud835\udf0e8 and \u03a9m parameters using data sample twice as small. The \u03a9m parameter is even better constrained due to the information loss in the compression step in the standard analysis. Such a pipeline that removes the dependence in the fiducial cosmology at all stages of the analysis could be used in future spectroscopic surveys such as DESI or Euclid to reduce the systematic and statistical errors on the cosmological parameters.\nMNRAS 000, 1\u201313 (2020)"
        },
        {
            "heading": "ACKNOWLEDGEMENTS",
            "text": "R. Neveux acknowledges support from grant ANR-16-CE31-0021, eBOSS and from ANR-17-CE31-0024-01, NILAC. Funding for the Sloan Digital Sky Survey IV has been provided by theAlfred P. Sloan Foundation, theU.S. Department of EnergyOffice of Science, and the Participating Institutions. SDSS acknowledges support and resources from the Center for High-Performance Computing at the University of Utah. The SDSSweb site is www.sdss.org. SDSS is managed by the Astrophysical Research Consortium for the Participating Institutions of the SDSS Collaboration including the Brazilian Participation Group, the Carnegie Institution for Science, Carnegie Mellon University, Center for Astrophysics | Harvard & Smithsonian (CfA), the Chilean Participation Group, the French Participation Group, Instituto de Astrof\u00edsica de Canarias, The Johns Hopkins University, Kavli Institute for the Physics and Mathematics of the Universe (IPMU) / University of Tokyo, the Korean Participation Group, Lawrence Berkeley National Laboratory, Leibniz Institut f\u00fcr Astrophysik Potsdam (AIP), Max-Planck-Institut f\u00fcr Astronomie (MPIA Heidelberg), Max-Planck-Institut f\u00fcr Astrophysik (MPA Garching), Max-Planck-Institut f\u00fcr Extraterrestrische Physik (MPE), National Astronomical Observatories of China, NewMexico State University, New York University, University of Notre Dame, Observat\u00f3rio Nacional / MCTI, The Ohio State University, Pennsylvania State University, Shanghai Astronomical Observatory, United Kingdom Participation Group, Universidad Nacional Aut\u00f3noma de M\u00e9xico, University of Arizona, University of Colorado Boulder, University of Oxford, University of Portsmouth, University of Utah, University of Virginia, University of Washington, University of Wisconsin, Vanderbilt University, and Yale University.\nDATA AVAILABILITY\nThe power spectrum, covariance matrices, and resulting likelihoods for cosmological parameters are available via the SDSS Science Archive Server (https://sas.sdss.org/)"
        }
    ],
    "title": "Combined full shape analysis of BOSS galaxies and eBOSS quasars using an iterative emulator",
    "year": 2022
}