{
    "abstractText": "With gates of a quantum computer designed to encode multi-dimensional vectors, projections of quantum computer states onto specific qubit states can produce kernels of reproducing kernel Hilbert spaces. We show that quantum kernels obtained with a fixed ansatz implementable on current quantum computers can be used for accurate regression models of global potential energy surfaces (PES) for polyatomic molecules. To obtain accurate regression models, we apply Bayesian optimization to maximize marginal likelihood by varying the parameters of the quantum gates. This yields Gaussian process models with quantum kernels. We illustrate the effect of qubit entanglement in the quantum kernels and explore the generalization performance of quantum Gaussian processes by extrapolating global six-dimensional PES in the energy domain. 1 ar X iv :2 20 2. 10 60 1v 1 [ qu an tph ] 2 2 Fe b 20 22",
    "authors": [],
    "id": "SP:59cfad188be22aecd2afc919ef00c58befb982d1",
    "references": [
        {
            "authors": [
                "J.D. Whitfield",
                "J. Biamonte",
                "A. Aspuru-Guzik"
            ],
            "title": "Simulation of electronic structure Hamiltonians using quantum computers",
            "venue": "Mol. Phys. 109, 5 ",
            "year": 2011
        },
        {
            "authors": [
                "I. Kassal",
                "J. Whitfield"
            ],
            "title": "A",
            "venue": "Perdomo-Ortiz, M.-H.Yung, and A. Aspuru-Guzik, Simulating chemistry using quantum computers, Annu. Rev. Phys. Chem. 62, 185 ",
            "year": 2011
        },
        {
            "authors": [
                "I.D. Kivlichan",
                "J. McClean",
                "N. Wiebe",
                "C. Gidney",
                "A. Aspuru-Guzik",
                "G.K. Chan",
                "R. Babbush"
            ],
            "title": "Quantum simulation of electronic structure with linear depth and connectivity",
            "venue": "Phys. Rev. Lett. 120, 110501 ",
            "year": 2018
        },
        {
            "authors": [
                "I.G. Ryabinkin",
                "T.C. Yen",
                "S.N. Genin",
                "A.F. Izmaylov"
            ],
            "title": "Qubit coupled cluster method: a systematic approach to quantum chemistry on a quantum computer",
            "venue": "J. Chem. Theor. Comp. 14, 12 ",
            "year": 2018
        },
        {
            "authors": [
                "K. Setia",
                "J.D. Whitfield"
            ],
            "title": "Bravyi-Kitaev superfast simulation of electronic structure on a quantum computer",
            "venue": "J. Chem. Phys. 148, 164104 ",
            "year": 2018
        },
        {
            "authors": [
                "R. Xia",
                "T. Bian",
                "S. Kais"
            ],
            "title": "Electronic structure calculations and the Ising Hamiltonian",
            "venue": "J. Phys. Chem. B 122, 113 ",
            "year": 2018
        },
        {
            "authors": [
                "K. Sugisaki",
                "S. Yamamoto",
                "S. Nakazawa",
                "K. Toyota",
                "K. Sato",
                "D. Shiomi",
                "T. Takui"
            ],
            "title": "Quantum chemistry on quantum computers: a polynomial-time quantum algorithm for constructing the wave functions of open-shell molecules",
            "venue": "J. Phys. Chem. A 120, 32 ",
            "year": 2016
        },
        {
            "authors": [
                "S. Wei",
                "H. Li",
                "G. Long"
            ],
            "title": "A full quantum eigensolver for quantum chemistry simulations",
            "venue": "Research 2020, 1486935 ",
            "year": 2020
        },
        {
            "authors": [
                "T. Bian",
                "D. Murphy",
                "R. Xia",
                "A. Daskin",
                "S. Kais"
            ],
            "title": "Quantum computing methods for electronic states of the water molecule",
            "venue": "Mol. Phys. 117, 15 ",
            "year": 2019
        },
        {
            "authors": [
                "R. Babbush",
                "N. Wiebe",
                "J. McClean",
                "J. McClain",
                "H. Neven",
                "G.K. Chan"
            ],
            "title": "Low-depth quantum simulation of materials",
            "venue": "Phys. Rev. X 8, 011044 ",
            "year": 2018
        },
        {
            "authors": [
                "A. Kandala",
                "A. Mezzacapo",
                "K. Temme",
                "M. Takita",
                "M. Brink",
                "J.M. Chow",
                "J.M. Gambetta"
            ],
            "title": "Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets",
            "venue": "14 Nature 549, 242 ",
            "year": 2017
        },
        {
            "authors": [
                "F. Arute",
                "K. Arya",
                "R. Babbush",
                "D. Bacon",
                "J.C. Bardin",
                "R. Barends",
                "S. Boixo",
                "M. Broughton",
                "B.B. Buckley"
            ],
            "title": "and D",
            "venue": "A. Buell et al., Hartree-Fock on a superconducting qubit quantum computer, Science 369, 6507 ",
            "year": 2020
        },
        {
            "authors": [
                "S. McArdle",
                "S. Endo",
                "A. Aspuru-Guzik",
                "S.C. Benjamin",
                "X. Yuan"
            ],
            "title": "Quantum computational chemistry",
            "venue": "Rev. Mod. Phys. 92, 015003 ",
            "year": 2020
        },
        {
            "authors": [
                "Y. Cao",
                "J. Romero",
                "J.P. Olson",
                "M. Degroote",
                "P.D. Johnson",
                "M. Kieferov\u00e1",
                "I.D. Kivlichan",
                "T. Menke",
                "B. Peropadre",
                "N.P.D. Sawaya",
                "S. Sim",
                "L. Veis",
                "A. Aspuru-Guzik"
            ],
            "title": "Quantum chemistry in the age of quantum computing",
            "venue": "Chem. Rev. 119, 19 ",
            "year": 2019
        },
        {
            "authors": [
                "P.J. Ollitrault",
                "A. Miessen",
                "I. Tavernelli"
            ],
            "title": "Molecular quantum dynamics: a quantum computing perspective",
            "venue": "Acc. Chem. Res. 54, 23 ",
            "year": 2021
        },
        {
            "authors": [
                "P.J. Ollitrault",
                "G. Mazzola",
                "I. Tavernelli"
            ],
            "title": "Nonadiabatic molecular quantum dynamics with quantum computers",
            "venue": "Phys. Rev. Lett. 125, 260511 ",
            "year": 2020
        },
        {
            "authors": [
                "R.J. MacDonell",
                "C.E. Dickerson",
                "C.J.T. Birch",
                "A. Kumar",
                "C.L. Edmunds",
                "M.J. Biercuk",
                "C. Hempel",
                "I. Kassal"
            ],
            "title": "Analog quantum simulation of chemical dynamics",
            "venue": "Chem. Sci. 12, 9794 ",
            "year": 2021
        },
        {
            "authors": [
                "I. Kassal",
                "S.P. Jordan",
                "P.J. Love",
                "M. Mohseni",
                "A. Aspuru-Guzik"
            ],
            "title": "Polynomial-time quantum algorithm for the simulation of chemical dynamics",
            "venue": "Proc. Natl. Acad. Sci. U.S.A. 105, 18681 ",
            "year": 2008
        },
        {
            "authors": [
                "A. Roggero",
                "C. Gu",
                "A. Baroni",
                "T. Papenbrock"
            ],
            "title": "Preparation of excited states for nuclear dynamics on a quantum computer",
            "venue": "Phys. Rev. C 102, 064624 ",
            "year": 2020
        },
        {
            "authors": [
                "E.T. Holland",
                "K.A. Wendt",
                "K. Kravvaris",
                "X. Wu",
                "W.E. Ormand",
                "J. L DuBois",
                "S. Quaglioni",
                "F. Pederiva"
            ],
            "title": "Optimal control for the quantum simulation of nuclear dynamics",
            "venue": "Phys. Rev. A 101, 062307 ",
            "year": 2020
        },
        {
            "authors": [
                "K.T. Sch\u00fctt",
                "F. Arbabzadah",
                "S. Chmiela",
                "K.R. M\u00fcller",
                "A. Tkatchenko"
            ],
            "title": "Quantum-chemical insights from deep tensor neural networks",
            "venue": "Nat. Commun. 8, 13890 ",
            "year": 2017
        },
        {
            "authors": [
                "O.T. Unke",
                "M. Meuwly"
            ],
            "title": "PhysNet: a neural network for predicting energies",
            "venue": "forces, dipole moments and partial charges, J. Chem. Theor. Comp. 15, 3678 ",
            "year": 2019
        },
        {
            "authors": [
                "S. Manzhos",
                "T. Jr"
            ],
            "title": "Carrington",
            "venue": "A random-sampling high dimensional model representation neural network for building potential energy surfaces, J. Chem. Phys. 125, 084109 ",
            "year": 2006
        },
        {
            "authors": [
                "S. Manzhos",
                "X. Wang",
                "R. Dawes",
                "T. Jr"
            ],
            "title": "Carrington",
            "venue": "A nested molecule-independent neural network approach for high-quality potential fits, J. Phys. Chem. A 110, 5295 ",
            "year": 2006
        },
        {
            "authors": [
                "J. Behler",
                "M. Parrinello"
            ],
            "title": "Generalized neural-network representation of high-dimensional potential-energy surfaces",
            "venue": "Phys. Rev. Lett. 98, 146401 ",
            "year": 2007
        },
        {
            "authors": [
                "J. Behler"
            ],
            "title": "Neural network potential-energy surfaces in chemistry: a tool for large-scale simulations",
            "venue": "Phys. Chem. Chem. Phys. 13, 17930 ",
            "year": 2011
        },
        {
            "authors": [
                "J. Behler"
            ],
            "title": "Constructing high-dimensional neural network potentials: A tutorial review",
            "venue": "Int. J. Quant. Chem. 115, 1032 ",
            "year": 2015
        },
        {
            "authors": [
                "E. Pradhan",
                "A. Brown"
            ],
            "title": "A ground state potential energy surface for HONO based on a neural network with exponential fitting functions",
            "venue": "Phys. Chem. Chem. Phys. 19, 22272 ",
            "year": 2017
        },
        {
            "authors": [
                "A. Leclerc",
                "T. Jr"
            ],
            "title": "Carrington",
            "venue": "Calculating vibrational spectra with sum of product basis functions without storing full-dimensional vectors or matrices, J. Chem. Phys. 140, 174111 ",
            "year": 2014
        },
        {
            "authors": [
                "S. Manzhos",
                "R. Dawes",
                "T. Jr"
            ],
            "title": "Carrington",
            "venue": "Neural network-based approaches for building high dimensional and quantum dynamics-friendly potential energy surfaces, Int. J. Quant. Chem. 115, 1012 ",
            "year": 2015
        },
        {
            "authors": [
                "J. Chen",
                "X. Xu",
                "X. Xu",
                "D.H. Zhang"
            ],
            "title": "A global potential energy surface for the H2 + OH \u2194 H2O + H reaction using neural networks",
            "venue": "J. Chem. Phys. 138, 154301 ",
            "year": 2013
        },
        {
            "authors": [
                "Q. Liu",
                "X. Zhou",
                "L. Zhou",
                "Y. Zhang",
                "X. Luo",
                "H. Guo",
                "B. Jiang"
            ],
            "title": "Constructing highdimensional neural network potential energy surfaces for gas-surface scattering and reactions",
            "venue": "J. Phys. Chem. C 122, 1761 ",
            "year": 2018
        },
        {
            "authors": [
                "S. Manzhos",
                "T. Jr"
            ],
            "title": "Carrington",
            "venue": "Neural network potential energy surfaces for small molecules and reactions, Chem. Rev. 121, 16 ",
            "year": 2021
        },
        {
            "authors": [
                "M. Meuwly"
            ],
            "title": "Machine learning for chemical reactions",
            "venue": "Chem. Rev. 121, 16 ",
            "year": 2021
        },
        {
            "authors": [
                "C.M. Handley",
                "G.I. Hawe",
                "D.B. Kellab",
                "P.L.A. Popelier"
            ],
            "title": "Optimal construction of a fast and accurate polarisable water potential based on multipole moments trained by machine learning",
            "venue": "Phys. Chem. Chem. Phys. 11, 6365 ",
            "year": 2009
        },
        {
            "authors": [
                "A.P. Bart\u00f3k",
                "M.C. Payne",
                "R. Kondor",
                "G. Cs\u00e1nyi"
            ],
            "title": "Gaussian approximation potentials: The accuracy of quantum mechanics",
            "venue": "without the electrons, Phys. Rev. Lett. 104, 136403 ",
            "year": 2010
        },
        {
            "authors": [
                "A.P. Bart\u00f3k",
                "G. Cs\u00e1nyi"
            ],
            "title": "Gaussian approximation potentials: A brief tutorial introduction",
            "venue": "Int. J. Quant. Chem. 115, 1051 ",
            "year": 2015
        },
        {
            "authors": [
                "J. Cui",
                "R.V. Krems"
            ],
            "title": "Efficient non-parametric fitting of potential energy surfaces for polyatomic molecules with Gaussian processes",
            "venue": "J. Phys. B: At. Mol. Opt. Phys. 49, 224001 ",
            "year": 2016
        },
        {
            "authors": [
                "P.O. Dral",
                "A. Owens",
                "S.N. Yurchenko",
                "W. Thiel"
            ],
            "title": "Structure-based sampling and selfcorrecting machine learning for accurate calculations of potential energy surfaces and vibrational levels",
            "venue": "J. Chem. Phys. 146, 244108 ",
            "year": 2017
        },
        {
            "authors": [
                "B. Kolb",
                "P. Marshall",
                "B. Zhao",
                "B. Jiang",
                "H. Guo"
            ],
            "title": "Representing global reactive potential energy surfaces using Gaussian processes",
            "venue": "J. Phys. Chem. A 121, 2552 ",
            "year": 2017
        },
        {
            "authors": [
                "A. Kamath",
                "R.A. Vargas-Hernandez",
                "R.V. Krems",
                "T. Jr"
            ],
            "title": "Carrington",
            "venue": "and S. Manzhos, Neural networks vs Gaussian process regression for representing potential energy surfaces: A comparative study of fit quality and vibrational spectrum accuracy, J. Chem. Phys. 148, 241702 ",
            "year": 2018
        },
        {
            "authors": [
                "G. Schmitz",
                "O. Christiansen"
            ],
            "title": "Gaussian process regression to accelerate geometry optimizations relying on numerical differentiation",
            "venue": "J. Chem. Phys. 148, 241704 ",
            "year": 2018
        },
        {
            "authors": [
                "Y. Guan",
                "S. Yang",
                "D.H. Zhang"
            ],
            "title": "Construction of reactive potential energy surfaces with Gaussian process regression: active data selection",
            "venue": "Mol. Phys. 116, 823 ",
            "year": 2018
        },
        {
            "authors": [
                "G. Laude",
                "D.Calderini",
                "D.P. Tew",
                "J.O. Richardson"
            ],
            "title": "Ab initio instanton rate theory made efficient using Gaussian process regression",
            "venue": "Faraday Discuss. 212,",
            "year": 2018
        },
        {
            "authors": [
                "Y. Guan",
                "S. Yang",
                "D.H. Zhang"
            ],
            "title": "Application of clustering algorithms to partitioning configuration space in fitting reactive potential energy surfaces",
            "venue": "J. Phys. Chem. A 122, 3140 ",
            "year": 2018
        },
        {
            "authors": [
                "A.E. Wiens",
                "A.V. Copan",
                "H.F. Schaefer"
            ],
            "title": "Multi-fidelity Gaussian process modeling for chemical energy surfaces",
            "venue": "Chem. Phys. Lett. X 3, 100022 ",
            "year": 2019
        },
        {
            "authors": [
                "C. Qu",
                "Q. Yu"
            ],
            "title": "B",
            "venue": "L. Jr Van Hoozen, J. M. Bowman, and Vargas-Hern\u00e0ndez, R. A. Assessing Gaussian process regression and permutationally invariant polynomial approaches to represent high-dimensional potential energy surfaces, J. Chem. Theor. Comp. 14, 3381 ",
            "year": 2018
        },
        {
            "authors": [
                "Q. Song",
                "Q. Zhang",
                "Q. Meng"
            ],
            "title": "Revisiting the Gaussian process regression for fitting highdimensional potential energy surface and its application to the OH + HO2 \u2192 O2 + H2O reaction",
            "venue": "J. Chem. Phys. 152, 134309 ",
            "year": 2020
        },
        {
            "authors": [
                "C. Qu",
                "R. Conte",
                "P.L. Houston",
                "J.M. Bowman"
            ],
            "title": "Full-dimensional potential energy surface for acetylacetone and tunneling splittings",
            "venue": "Phys. Chem. Chem. Phys. 23, 7758 ",
            "year": 2021
        },
        {
            "authors": [
                "O.T. Unke",
                "M. Meuwly"
            ],
            "title": "Toolkit for the construction of reproducing kernel-based representations of data: Application to multidimensional potential energy surfaces",
            "venue": "J. Chem. Inf. Model. 57, 1923 ",
            "year": 2017
        },
        {
            "authors": [
                "T.S. Ho",
                "H. Rabitz"
            ],
            "title": "A general method for constructing multidimensional molecular potential energy surfaces from ab initio calculations",
            "venue": "J. Chem. Phys. 104, 2584 ",
            "year": 1996
        },
        {
            "authors": [
                "T. Hollebeek",
                "T.S. Ho",
                "H. Rabitz"
            ],
            "title": "A fast algorithm for evaluating multidimensional potential energy surfaces",
            "venue": "J. Chem. Phys. 106, 7223 ",
            "year": 1997
        },
        {
            "authors": [
                "T.S. Ho",
                "H. Rabitz"
            ],
            "title": "Reproducing kernel Hilbert space interpolation methods as a paradigm of high dimensional model representations: Application to multidimensional potential energy surface construction",
            "venue": "J. Chem. Phys. 119, 6433 ",
            "year": 2003
        },
        {
            "authors": [
                "U.T. Unke"
            ],
            "title": "Potential energy surfaces: from force fields to neural networks",
            "venue": "Doctoral dissertation, University of Basel",
            "year": 2019
        },
        {
            "authors": [
                "Y. Liu",
                "S. Arunachalam",
                "K. Temme"
            ],
            "title": "A rigorous and robust quantum speed-up in supervised machine learning",
            "venue": "Nat. Phys. 17, 1013 ",
            "year": 2021
        },
        {
            "authors": [
                "M. Schuld",
                "A. Bocharov",
                "K.M. Svore",
                "N. Wiebe"
            ],
            "title": "Circuit-centric quantum classifiers",
            "venue": "Phys. Rev. A 101, 032308 ",
            "year": 2020
        },
        {
            "authors": [
                "M. Benedetti",
                "E. Lloyd",
                "S. Sack",
                "M. Fiorentini"
            ],
            "title": "Parameterized quantum circuits as machine learning models",
            "venue": "Quantum Sci. Technol. 4, 043001 ",
            "year": 2019
        },
        {
            "authors": [
                "M. Schuld",
                "I. Sinayskiy",
                "F. Petruccione"
            ],
            "title": "An introduction to quantum machine learning",
            "venue": "Contemp. Phys. 56, 2 ",
            "year": 2015
        },
        {
            "authors": [
                "J. Biamonte",
                "P. Wittek",
                "N. Pancotti",
                "P. Rebentrost",
                "N. Wiebe",
                "S. Lloyd"
            ],
            "title": "Quantum machine learning",
            "venue": "Nature 549, 195 ",
            "year": 2017
        },
        {
            "authors": [
                "P. Rebentrost"
            ],
            "title": "M",
            "venue": "Mohseni, and S.Lloyd, Quantum support vector machine for big data classification, Phys. Rev. Lett. 113, 130503 ",
            "year": 2014
        },
        {
            "authors": [
                "S. Maria",
                "N. Killoran"
            ],
            "title": "Quantum machine learning in feature hilbert spaces",
            "venue": "Phys. Rev. Lett. 122, 040504 ",
            "year": 2019
        },
        {
            "authors": [
                "V. Havl\u00ed\u010dek",
                "A.D. C\u00f3rcoles",
                "K. Temme",
                "A.W. Harrow",
                "A. Kandala",
                "J.M. Chow",
                "J.M. Gambetta"
            ],
            "title": "Supervised learning with quantum-enhanced feature spaces",
            "venue": "Nature 567, 209 ",
            "year": 2019
        },
        {
            "authors": [
                "Y. Suzuki",
                "H. Yano",
                "Q. Gao",
                "S. Uno",
                "T. Tanaka",
                "M. Akiyama",
                "N Yamamoto"
            ],
            "title": "Analysis and synthesis of feature map for kernel-based quantum classifier",
            "venue": "Quantum Mach. Intell. 2, 9 ",
            "year": 2020
        },
        {
            "authors": [
                "J. Park",
                "B. Quanz",
                "S. Wood",
                "H. Higgins",
                "R. Harishankar"
            ],
            "title": "Practical application improvement to Quantum SVM: theory to practice, arXiv:2012.07725",
            "year": 2012
        },
        {
            "authors": [
                "M. Schuld",
                "I. Sinayskiy",
                "F. Petruccione"
            ],
            "title": "Prediction by linear regression on a quantum computer",
            "venue": "Phys. Rev. A 94, 022342 ",
            "year": 2016
        },
        {
            "authors": [
                "G. Wang"
            ],
            "title": "Quantum algorithm for linear regression",
            "venue": "Phys. Rev. A 96, 012335 ",
            "year": 2017
        },
        {
            "authors": [
                "P. Date",
                "T. Potok"
            ],
            "title": "Adiabatic quantum linear regression",
            "venue": "Scientific Reports 11, 21905 ",
            "year": 2021
        },
        {
            "authors": [
                "N. Killoran",
                "T.R. Bromley"
            ],
            "title": "J",
            "venue": "M.Arrazola, M. Schuld, N. Quesada, and S. Lloyd, Continuousvariable quantum neural networks, Phys. Rev. Research 1, 033063 ",
            "year": 2019
        },
        {
            "authors": [
                "M. Otten",
                "I.R. Goumiri",
                "B.W. Priest",
                "G.F. Chapline",
                "M.D. Schneider"
            ],
            "title": "Quantummachine learning using Gaussian processes with performant quantum kernels, arXiv:2004.11280",
            "year": 2004
        },
        {
            "authors": [
                "J. Wang",
                "Q. Chen",
                "Y. Chen"
            ],
            "title": "RBF kernel based support vector machine with universal approximation and its application - Advances in neural networks",
            "venue": "edited by F. Yin, J. Wang, C. Guo, ",
            "year": 2004
        },
        {
            "authors": [
                "Q. Yu",
                "J.M. Bowman"
            ],
            "title": "Ab initio potential for H3O \u2192 H+ + H2O: A step to a many-body representation of the hydrated proton",
            "venue": "J. Chem. Theor. Comp. 12, 5284 ",
            "year": 2016
        },
        {
            "authors": [
                "J. Dai",
                "R.V. Krems"
            ],
            "title": "Interpolation and extrapolation of global potential energy surfaces for polyatomic systems by Gaussian processes with composite kernels",
            "venue": "J. Chem. Theor. Comp. 16, 3 ",
            "year": 2020
        },
        {
            "authors": [
                "C.E. Rasmussen",
                "C.K.I. Williams"
            ],
            "title": "Gaussian processes for machine learning",
            "year": 2006
        },
        {
            "authors": [
                "K. Asnaashari",
                "R.V. Krems"
            ],
            "title": "Gradient domain machine learning with composite kernels: improving the accuracy of PES and force fields for large molecules",
            "venue": "Mach. Learn.: Sci. & Technol. 3, 015005 ",
            "year": 2022
        },
        {
            "authors": [
                "R.A. Vargas-Hern\u00e0ndez",
                "Y. Guan",
                "D.H. Zhang",
                "R.V. Krems"
            ],
            "title": "Bayesian optimization for the inverse scattering problem in quantum reaction dynamics",
            "venue": "New J. Phys. (Fast Track Communication) 21, 022001 ",
            "year": 2019
        },
        {
            "authors": [
                "G. Schwarz"
            ],
            "title": "Estimating the dimension of a model",
            "venue": "The Annals of Statistics 2, 461 ",
            "year": 1978
        },
        {
            "authors": [
                "D.K. Duvenaud",
                "H. Nickisch",
                "C.E. Rasmussen"
            ],
            "title": "Additive gaussian processes",
            "venue": "Adv. Neur. Inf. Proc. Sys. 24, 226 ",
            "year": 2011
        },
        {
            "authors": [
                "D.K. Duvenaud",
                "J. Lloyd",
                "R. Grosse",
                "J.B. Tenenbaum",
                "Z. Ghahramani"
            ],
            "title": "Structure discovery in nonparametric regression through compositional kernel search",
            "venue": "Proceedings of the 30th International Conference on Machine Learning Research 28, 1166 ",
            "year": 2013
        },
        {
            "authors": [
                "R.A. Vargas-Hern\u00e0ndez",
                "J. Sous",
                "M. Berciu",
                "R.V. Krems"
            ],
            "title": "Extrapolating quantum observables with machine learning: Inferring multiple phase transitions from properties of a single phase",
            "venue": "Phys. Rev. Lett. 121, 255702 ",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "of quantum computer states onto specific qubit states can produce kernels of reproducing kernel\nHilbert spaces. We show that quantum kernels obtained with a fixed ansatz implementable on\ncurrent quantum computers can be used for accurate regression models of global potential energy\nsurfaces (PES) for polyatomic molecules. To obtain accurate regression models, we apply Bayesian\noptimization to maximize marginal likelihood by varying the parameters of the quantum gates. This\nyields Gaussian process models with quantum kernels. We illustrate the effect of qubit entanglement\nin the quantum kernels and explore the generalization performance of quantum Gaussian processes\nby extrapolating global six-dimensional PES in the energy domain.\nar X\niv :2\n20 2.\n10 60\n1v 1\n[ qu\nan t-\nph ]\n2 2\nFe b\nI. INTRODUCTION\nPredicting properties of complex molecules from first principles is considered to be one of the most promising applications of quantum computing. A computation of molecular properties within the Born-Oppenheimer approximation requires solving the electronic structure problem, fitting the results of potential energy calculations to produce global PES and solving the nuclear dynamics problem with the PES thus obtained. Several algorithms have been recently developed for solving electronic structure [1\u201316] and nuclear dynamics [17\u2013 22] problems on noisy intermediate-scale quantum (NISQ) computers. However, quantum algorithms for producing global PES of polyatomic molecules have not yet been demonstrated. The present work builds a quantum regression model of a six-dimensional PES for the molecular ion H3O+. Our results demonstrate a comparison with the corresponding classical models and illustrate the role of entanglement of the qubits used for the quantum algorithm of constructing PES.\nRecent work has demonstrated that PES of polyatomic molecules can be accurately represented by machine learning (ML) regression models, based on neural networks [23\u201336] or kernel methods [36\u201356]. Quantum computers have opened the possibility to research the quantum analogues of ML algorithms [57\u201373]. It has been shown that gate-based quantum devices can be used to build quantum kernels for kernel ML models [60\u201368, 73]. While most applications of quantum kernels have been for support vector classification of lowdimensional data [61\u201368], several studies have considered quantum algorithms for regression [69\u201373]. Particularly relevant for the present work is Ref. [73] that applied Gaussian process regression to several model applications, such as regression of the one-dimensional function x sinx. The goal of Ref. [73] was to simulate classical kernels using coherent states, or truncations of coherent states. In order to extend this work to regression problems for fitting PES, it is necessary to overcome several challenges. First, there is no general quantum circuit ansatz for building performant quantum kernels for PES interpolation. It is not known how to build a sequence of quantum gates in order to build the best quantum kernel for accurate models of PES. Second, accurate kernel regression models for complex problems with sparse data require optimization of kernel parameters. However, quantum kernel estimation is expensive, requiring many quantum measurements for each pair of training points. In addition, as will be illustrated in this work, the cost function used to train regression models\nwith quantum kernels can be very sensitive to quantum circuit parameters. This makes kernel parameter optimization difficult. Third, the number of quantum kernel parameters grows quickly with the number of qubits and gates in the corresponding quantum circuit. This precludes grid search of optimal kernel parameters, often used for building classical kernel ridge regression models. This also makes search of optimal quantum circuit ansatz difficult.\nHere, we demonstrate that quantum kernel regression models with a fixed quantum circuit ansatz readily deployable on current gate-based quantum computers can yield comparable accuracy with classical ML models. Our focus is on building accurate models with a small number of training points, aiming to produce global PES with a small number of ab initio potential energy calculations. To achieve this, we employ Bayesian optimization for tuning the parameters of quantum gates and optimize kernels by maximizing a modified version of log marginal likelihood. We consider two problems: interpolation of PES in a six-dimensional (6D) configuration space and extrapolation of PES in the energy domain. We show that the quantum models may exhibit better extrapolation accuracy than classical models with radial basis function kernels [74], when trained by the same number and distribution of potential energy points. We also show that the accuracy of quantum models is significantly enhanced by two-qubit gates, which illustrates a critical role of qubit entanglement in quantum kernels for regression problems. By demonstrating Bayesian regression models with quantum kernels, our work complements Ref. [73] to set the stage for the quantum analogue of Bayesian optimization on quantum computing devices."
        },
        {
            "heading": "II. CLASSICAL VS QUANTUM MODELS",
            "text": "We use Gaussian process (GP) models to represent PES of the molecule H3O+. The molecular geometry is described by the six-dimensional (6D) vector x, as in our previous work [76], where we built classical GP models of PES for H3O+. A GP model is trained by n input - output pairs, with inputs represented by n molecular geometries xi and outputs by n corresponding values of the potential energy, collected into a column vector y. The prediction of potential energy at an arbitrary point x\u2217 in the 6D input space is given by [77]:\nf\u0302(x\u2217) = k>(x\u2217) [ K+ \u03c32I ]\u22121 y (1)\nwhere \u03c32 is a hyperparameter representing variance of data noise, I is the identity matrix, K is an n\u00d7 n kernel matrix with entries k(xi,xj), k>(x\u2217) is the transpose of a column vector with n entries k(x\u2217,xi), and xi and xj represent the molecular geometries for the training points i and j. Because PESs are noiseless, we set \u03c32 to zero.\nThe function k(x,x\u2032) yielding the elements of the kernel matrix is the covariance function of the GP [77]. It must satisfy the properties of a kernel function of a reproducing kernel Hilbert space (RKHS). Specifically, k(x,x\u2032) must be positive-definite and symmetric to interchange of x and x\u2032. In the present work, we build GP models with classical and quantum kernels. In both cases, the prediction of the model is given by Eq. (1). The difference is in the kernel matrix K. For classical models, we use radial basis functions (RBF) as the kernel function,\nk(x,x\u2032) = exp ( \u2212\u03b8||x\u2212 x\u2032||2 ) . (2)\nRBF kernels are known to be universal [74] and provide benchmark results for quantum models developed in this work.\nFor quantum kernels, we consider a quantum computer with m qubits, initially in state |0m\u3009. A sequence of gates operating on these qubits produces a quantum state U(x)|0m\u3009. The measurable square of the inner product\nk(x,x\u2032) = |\u30080m|U \u2020(x\u2032)U(x)|0m\u3009|2 (3)\nsatisfies all the properties of a kernel of an RKHS. In order to build such quantum kernels, one must encode information about input vectors into parameters of the quantum gates of a quantum computer.\nIn the present work, we use the quantum circuit depicted in Figure 1 to build quantum kernels. This quantum circuit was introduced in Ref. [64] for classification problems. We use one qubit to represent one dimension of the input space, resulting in a 6-qubit quantum circuit for the present problem. Each qubit is initialized in state |0\u3009. Following the initialization, quantum states are created by a sequence of gate operations U \u2020(x\u2032)U(x), as depicted in the upper panel of Figure 1. The values of the kernels are obtained by projecting the resulting quantum states onto the state |0m\u3009.\nAs shown in Figure 1, the unitary transformation U includes a sequence of three types of\nquantum gates: the Hadamard gates (H),\nH = 1\u221a 2 1 1 1 \u22121  (4) which put the individual qubits into coherent superposition states, the single-qubit rotation gates RZ ,\nRZ(\u03c6i) = e\u2212i\u03c6i 0 0 ei\u03c6i  (5) and the two-qubit rotation gates RZZ ,\nRZZ(\u03c6ij) =  e\u2212i\u03c6ij 0 0 0 0 ei\u03c6ij 0 0 0 0 ei\u03c6ij 0\n0 0 0 e\u2212i\u03c6ij\n . (6)\nThe two-qubit gates introduce entanglement.\nThe input vectors x are encoded into the quantum gates as follows:\n\u03c6i = x i/\u03b8i (7)\n\u03c6ij = exp(\u2212(xi \u2212 xj)/\u03b8ij), (8)\nwhere the superscripts in xi and xj denote the i-th and j-th components of the 6D vector x> = [x1, . . . ,x6], and \u03b8i and \u03b8ij are parameters of the quantum circuit to be optimized. As shown in Figure 1, the unitary transformation U is built as\nU = UH\u2297nUH\u2297n, (9)\nwith\nU = exp [ \u2212i ( m\u2211 i \u03c6i(x, \u03b8i)\u03c3Z,i + m\u2211 i,j>i \u03c6ij(x, \u03b8ij)\u03c3Z,i\u03c3Z,j )] (10)\nwhere \u03c3Z,i is the Pauli Z-gate acting on qubit i, and the second term in the exponent correspond to the RZZ gate. This ansatz includes a sequence of two-qubit rotations, entangling each pair of the qubits in the circuit. The order of the individual RZZ gates in Eq. (10) is arbitrary, because the \u03c3Z,i operators commute. The parameters \u03b8i are independent for each\none-qubit rotation gate in U. In order to simplify the optimization of the kernel parameters, we require that the parameters of all two-qubit gates \u03b8ij be the same and set them equal to a single variable parameter \u03b812. The number of free parameters in the quantum kernel is thus equal to the number of RZ gates plus one, for a total of 7 parameters in U.\nThe covariance functions of the GP models are thus parametrized by \u03b8 in the classical models and \u03b8i=1,...,6 and \u03b812, hereafter represented collectively by \u03b8, in the quantum models. GP models are trained by maximizing the logarithm of marginal likelihood (LML), which yields optimal parameters of the kernels [77]. For GPs, LML can be written in closed form in terms of the kernel matrix K and its determinant as follows [77]:\nlogL(\u03b8) = \u22121 2 y> ( K+ \u03c32I )\u22121 y \u2212 1 2 log |K+ \u03c32I| \u2212 n 2 log 2\u03c0, (11)\nwhere the dependence on \u03b8 is through the elements of the kernel matrix. While it is straightforward to train classical GP models with the RBF kernel by maximizing LML, it will be illustrated in the next section that LML for quantum models is extremely sensitive to \u03b8 in some parts of the parameter space, leading to rapid variation of LML and lack of convergence of LML optimization. In order to overcome this problem, we show that quantum models can be trained by optimizing the following objective function instead of the LML:\nO(\u03b8) = log[L(\u03b8) + a] (12)\nwhere a is a hyperparameter, set to 1 in the present work. It will be shown that the constant a stabilizes optimization of LML and improves convergence.\nTo build quantum kernels, we use simulated qubits as implemented in the IBM qiskit package, using Statevector [78]. Quantum states are generated by the operation of gate sequences on qubits initially all in state |0\u3009. The gate operations are noiseless. The kernels as defined in Eq. (3) are computed from the corresponding probability amplitudes in the quantum states of m qubits after the sequence of gate operations. In order to examine the role of qubit entanglement, we consider two types of kernels for the quantum models: (a) kernels constructed as described above with 7 parameters \u03b8i and \u03b812; (b) kernels constructed as described above, but with all two-qubit gatesRZZ replaced with identity matrices, yielding quantum circuits with 6 free parameters and no entanglement between qubits. We will refer to these kernels as entangled and unentangled kernels, respectively."
        },
        {
            "heading": "III. RESULTS",
            "text": "Although Ref. [64] illustrated that the quantum circuit ansatz described in the previous section can be used to build kernels for classification problems, this ansatz has not been used for regression models. Therefore, out first goal is to explore the possibility of using the quantum circuit depicted in Figure 1 for regression problems. Specifically, we aim to build accurate interpolation and extrapolation models with a limited number of training points (200 to 1500 for a 6D problem). In this limit, and especially for extrapolation problems, kernel regression models must be sensitive to kernels. We use a comparison with the models based on optimized RBF kernels to benchmark the performance of the quantum kernels. It should be noted that RBF kernels do not always represent the best classical kernels for kernel models of PES. As we demonstrated previously, classical GP models of PES can be improved by increasing the kernel complexity by combining different simple mathematical forms of kernels into composite kernels [76, 79]. However, RBF kernels are proven to be universal [74] and represent one of the most frequently used type of kernels. Our goal is not to illustrate that quantum kernels can outperform classical kernels for small data regression problems. Rather, we aim to show that quantum kernels can produce regression models of similar accuracy as classical kernels.\nSpecifically, the present section illustrates:\n\u25e6 how to optimize quantum circuits to build accurate quantum GP models;\n\u25e6 the feasibility of building accurate GP regression models with quantum kernels using\na fixed quantum circuit ansatz depicted in Figure 1;\n\u25e6 comparison of quantum GP models for interpolation and extrapolation (in the energy\ndomain) of PES with the classical models with optimized RBF kernels;\n\u25e6 comparison of quantum GP models of PES with and without entanglement between\nqubits.\nThe ab initio results for the PES of H3O+ are taken from Ref. [75]. There are a total of 31124 potential energy points, spanning the energy range [0, 21000] cm\u22121. We construct global 6D PES by training GP models using n ab initio points in a specific energy interval. The value of n and the energy range for the training points is specified in the caption for\neach figure. The accuracy of the resulting models is quantified by computing the root mean squared error (RMSE)\nRMSE = \u221a\u221a\u221a\u221a 1 N N\u2211 i=1 ( yi \u2212 f\u0302(xi) )2 , (13)\nwhere f\u0302 are the GP model predictions given by Eq. (1), yi represent the ab initio potential energy points from Ref [75], and the sum extends over all ab initio points that are not used for training the models. For models trained by potential energy points from a limited range of energies (e.g. at energies \u2264 10, 000 cm\u22121), these RMSEs covering the entire energy range up to 21,000 cm\u22121 quantify the ability of GP models to extrapolate in the energy domain.\nA. Quantum kernel optimization\nFor classical GP models with simple analytical kernel functions, LML optimization is usually performed with a gradient-based optimization method, quickly converging to desired estimates of kernel parameters. As follows from the above description of quantum kernels, LML maximization for quantum models requires optimization of a large number of parameters \u03b8, with kernels given by the probability amplitudes in a quantum state. When implemented on a quantum computer, the present algorithm will yield kernels as quantum measurement outcomes, instead of analytical functions. This makes optimization of LML, or equivalently O(\u03b8), much more challenging. In this section, we illustrate that accurate quantum GP models can be obtained by optimizing O(\u03b8) in Eq. (12) with Bayesian optimization (BO).\nBO is a gradient-free optimization method that uses a balance between the prediction of a GP and the Bayesian uncertainty of the prediction to determine how to sample the function under optimization [80]. Here, we apply BO to find the parameters of the quantum circuit \u03b8 that maximize O(\u03b8). BO begins with the evaluation of O(\u03b8) at a small number of randomly selected values of \u03b8. The results of these evaluations are used to train a (classical) GP model F(\u03b8) characterized by the mean of the GP F denoted as \u00b5(\u03b8) and by the uncertainty of the GP F denoted as \u03c3(\u03b8). The subsequent evaluation of O(\u03b8) is performed at the maximum of the acquisition function \u03b1(\u03b8) defined as\n\u03b1(\u03b8) = \u00b5(\u03b8) + \u03ba\u03c3(\u03b8), (14)\nwhere \u03ba is a hyperparameter that determines the balance between exploration and exploitation. The result of the new evaluation of O(\u03b8) is added to the set of the previous evaluations and the new set of O values is used to train a new GP model F . The procedure is iterated until convergence is reached.\nWe use RBF kernels for the GP models F , initialize BO with 20 randomly chosen points and typically reach optimal results with \u223c 30 \u2212 100 iterations sampling 6 or 7 dimensions of the \u03b8 parameter space. We use the value of \u03ba in Eq. (14) set to 1. We have repeated calculations with multiple values of \u03ba and found that this choice of \u03ba leads to optimal convergence of BO for the present problems.\nFigure 2 illustrates the results of optimization of LML using the objective functions defined in Eqs. (11) and (12) for unentangled (left panel) and entangled (right panel) kernels. These optimization problems vary 6 and 7 parameters, respectively. LML exhibits sharp variation with \u03b8, with characteristic drops (c.f., right panel of Figure 2), suggesting the presence of singularities for some values of the quantum circuit parameters. Qubit entanglement makes the optimization of LML more challenging. However, introducing a constant under the logarithm of the objective function as in Eq. (12) stabilizes optimization and improves convergence for GP models with both unentangled and entangled kernels. We have repeated optimization with several different values of a \u2208 [0.1, 10] in Eq. (12) and found that the results are not sensitive to the value of a. All of the calculations reported in this work use the value a = 1.\nFigure 3 illustrates the effect of qubit entanglement on the results of LML optimization and the accuracy of the corresponding quantum GP models quantified by the RMSE over the entire data set. The results illustrate that including qubit entanglement enhances the accuracy of the quantum models. The right panel of Figure 3 shows that accurate models of 6D PES based on entangled kernels can be obtained with as few as 20 iterations of kernel optimization. This illustrates both the feasibility of obtaining accurate regression models with the fixed ansatz in Figure 1, and the efficiency of BO for optimizing quantum circuits for quantum regression problems.\nFigure 4 illustrates convergence of BO of LML for quantum models with entangled kernels based on different numbers of training points. As expected, LML increases and RMSE decreases with the number of training points. The optimization of LML converges with less than 30 iterations of BO for all three models. Figure 4 illustrates that quantum GPs\nproduce reasonable models of 6D PES, when trained with as few as 200 potential energy points randomly sampled from the 6D configuration space. It can be observed that the optimization of the quantum circuit parameters reduces the RMSE for models with 1000 potential energy points by a factor of 3. These results illustrate that the quantum circuit ansatz introduced in Ref. [64] for classification problems is also effective for regression problems and that it is flexible enough to allow learning of complex functions by optimization of quantum gate parameters.\nB. Quantum vs classical GP models of PES \u2013 interpolation\nFigure 5 illustrates the interpolation performance of the optimized quantum regression model of the 6D PES of H3O+ built with 1000 potential energy points. The line represents the quantum model predictions and the symbols \u2013 the potential energy points randomly sampled as functions of the separation R between the centers of mass of H+2 and OH fragments. At each value of R, we locate the energy point in the original set of ab initio points by varying the angles and/or the interatomic distances within the fragments. This energy point is then compared with the GP predictions. The training data for this model are sampled from the entire energy range of the PES. The quantum model is based on the entangled kernel and is obtained with 72 iterations of BO. The RMSE of the model is 82.30 cm\u22121. While this is a remarkable performance of the quantum kernel, we note that the accuracy of the model can be further increased by increasing the number of training points (c.f., Figure 4).\nIt is instructive to compare the performance of this quantum model with that of the quantum model based on unentangled qubits and of the classical GP model. Figure 6 shows that the quantum model with entangled qubits is significantly more accurate than the quantum model with unentangled qubits. This illustrates the importance of two-qubit gates in the quantum circuit ansatz. Figure 6 also illustrates that the accuracy of the GP model with the optimized RBF kernel is very close to the accuracy of the model with the entangled kernel, except for n = 100. Both models approach the RMSE of about 37 cm\u22121 as the number of training points increases.\nC. Extrapolation in the energy domain\nSeveral recent studies have explored the application of GP models for extrapolation problems. It was shown that the generalization accuracy of GP models increases if the complexity of GP kernels is increased by combining different simple kernels into composite kernels through an algorithm using Bayesian Information Criterion as the model selection metric [81\u201383]. It was shown that GP models thus constructed can extrapolate the properties of complex quantum systems across quantum phase transition lines [84]. The same approach was used to enhance the accuracy of GP models of PES for polyatomic molecules [76, 79, 85]. Since quantum circuits offer a conceptually different approach to building kernels for GP models, it is instructive to examine the potential of quantum kernels to extrapolate.\nFigure 7 compares the extrapolation accuracy of quantum models with both entangled and untangled kernels and the classical model with the RBF kernel. The results shown in Figure 7 are obtained with models trained by random samples of ab initio potential energy points from the energy interval below the energy threshold indicated on the horizontal axis. The RMSEs shown are calculated for the entire energy range of the PES extending to 21,000 cm\u22121. Figure 7 illustrates two important results. First, including the entanglement between qubits into the quantum circuit enhances the extrapolation accuracy to a great extent. Second, models with entangled kernels appear to outperform models with the RBF kernels for low thresholds of the training data range, corresponding to a larger extrapolation interval.\nTo illustrate the comparison between the model predictions and the original ab initio energies, we show in Figure 8 the results of several models corresponding to different energy ranges of the training samples (shown by the shaded intervals). All models illustrated in Figure 8 are trained by 1500 ab initio points. The lines represent the GP model predictions and the symbols \u2013 the potential energy points sampled as functions of the separation between H+2 and OH fragments. As in Figure 4, at each value of R, we locate the energy point in the original set of ab initio points by varying the angles and/or the interatomic distances within the fragments. This energy point is then compared with the GP predictions. The functional form of PES at high energies is qualitatively different from that at low energies. Figure 8 shows that optimized quantum kernels can produce GP models that generalize predictions to different function distributions."
        },
        {
            "heading": "IV. CONCLUSION",
            "text": "We have demonstrated that quantum circuits of gate-based quantum computers can be used to build kernels for regression models of global PES for polyatomic molecules. Such kernels can be obtained by measuring the individual qubit states. We have shown that such kernels can be constructed with a fixed quantum circuit ansatz, previously used for classification problems, provided the quantum gate parameters are optimized to maximize log[L + 1], where L is marginal likelihood. This yields Gaussian process models of PES with quantum kernels. While the standard procedure for training Gaussian process models is to maximize logL, our results illustrate that logL is very sensitive to variation of the circuit parameters, making the optimization challenging. However, we have shown that maximization of log[L + 1] can be performed with Bayesian optimization, yielding stable results that correspond to accurate regression models with quantum kernels.\nWe have compared the accuracy of Gaussian process models of PES with quantum kernels based on entangled qubits, quantum kernels with unentangled kernels and classical Gaussian process models with RBF kernels. In all cases considered, the accuracy of quantum models including two-qubit rotation gates is comparable with the accuracy of classical models with RBF kernels. The quantum models with entangled kernels outperform the classical models with optimized RBF kernels for the class of problems aiming to construct the 6D PES at high energies based on 1500 ab initio points at low energies. At the same time, the accuracy of all quantum models drops significantly, when the entangling two-qubit gates are omitted from the quantum circuits. This illustrates the critical role of qubit entanglement in the quantum kernel computation algorithm.\nOur work demonstrates that quantum kernels obtained with a small number of qubits and quantum gates can be used for accurate regression models. This is important because finite fidelity of current NISQ devices is a major obstacle to increasing the size of quantum circuits. The quantum circuit used in the present work can be readily implemented on the current IBM quantum computer. Moreover, we have built quantum kernels for Gaussian process models, which themselves could be used as surrogate models underlying Bayesian optimization. Thus, our work complements Ref. [73] to pave the way for the development of the quantum analogue of Bayesian optimization. If quantum kernels prove to offer better inference for supervised learning tasks with a small number of training points than classical\nkernels, Bayesian optimization with quantum GPs may offer a useful application of quantum computing to optimization of functions that are exceedingly expensive to evaluate.\nACKNOWLEDGMENT\nThis work was supported by NSERC of Canada\n[1] J. D. Whitfield, J. Biamonte, and A. Aspuru-Guzik, Simulation of electronic structure Hamil-\ntonians using quantum computers, Mol. Phys. 109, 5 (2011).\n[2] I. Kassal, J. Whitfield, A. Perdomo-Ortiz, M.-H.Yung, and A. Aspuru-Guzik, Simulating chem-\nistry using quantum computers, Annu. Rev. Phys. Chem. 62, 185 (2011).\n[3] I. D. Kivlichan, J. McClean, N. Wiebe, C. Gidney, A. Aspuru-Guzik, G. K. Chan, and R.\nBabbush, Quantum simulation of electronic structure with linear depth and connectivity,\nPhys. Rev. Lett. 120, 110501 (2018).\n[4] M. B. Hastings, D. Wecker, B. Bauer, and M. Troyer, Improving quantum algorithms for\nquantum chemistry, arXiv:1811.11184.\n[5] I. G. Ryabinkin, T. C. Yen, S. N. Genin, and A. F. Izmaylov, Qubit coupled cluster method:\na systematic approach to quantum chemistry on a quantum computer, J. Chem. Theor.\nComp. 14, 12 (2018).\n[6] K. Setia and J. D. Whitfield, Bravyi-Kitaev superfast simulation of electronic structure on a\nquantum computer, J. Chem. Phys. 148, 164104 (2018).\n[7] R. Xia, T. Bian, and S. Kais, Electronic structure calculations and the Ising Hamiltonian, J.\nPhys. Chem. B 122, 113 (2018).\n[8] K. Sugisaki, S. Yamamoto, S. Nakazawa, K. Toyota, K. Sato, D. Shiomi, and T. Takui, Quan-\ntum chemistry on quantum computers: a polynomial-time quantum algorithm for constructing\nthe wave functions of open-shell molecules, J. Phys. Chem. A 120, 32 (2016).\n[9] S. Wei, H. Li, and G. Long, A full quantum eigensolver for quantum chemistry simulations,\nResearch 2020, 1486935 (2020).\n[10] T. Bian, D. Murphy, R. Xia, A. Daskin, and S. Kais, Quantum computing methods for elec-\ntronic states of the water molecule, Mol. Phys. 117, 15 (2019).\n[11] R. Babbush, N. Wiebe, J. McClean, J. McClain, H. Neven, and G. K. Chan, Low-depth\nquantum simulation of materials, Phys. Rev. X 8, 011044 (2018).\n[12] N. C. Rubin, A hybrid classical/quantum approach for large-scale studies of quantum systems\nwith density matrix embedding theory, arXiv:1610.06910.\n[13] A. Kandala, A. Mezzacapo, K. Temme, M. Takita, M. Brink, J. M. Chow, and J. M. Gambetta,\nHardware-efficient variational quantum eigensolver for small molecules and quantum magnets,\nNature 549, 242 (2017).\n[14] F. Arute, K. Arya, R. Babbush, D. Bacon, J. C. Bardin, R. Barends, S. Boixo, M. Broughton,\nB. B. Buckley, and D. A. Buell et al., Hartree-Fock on a superconducting qubit quantum\ncomputer, Science 369, 6507 (2020).\n[15] S. McArdle, S. Endo, A. Aspuru-Guzik, S. C. Benjamin, and X. Yuan, Quantum computational\nchemistry, Rev. Mod. Phys. 92, 015003 (2020).\n[16] Y. Cao, J. Romero, J. P. Olson, M. Degroote, P. D. Johnson, M. Kieferov\u00e1, I. D. Kivlichan,\nT. Menke, B. Peropadre, N. P. D. Sawaya, S. Sim, L. Veis, and A. Aspuru-Guzik, Quantum\nchemistry in the age of quantum computing, Chem. Rev. 119, 19 (2019).\n[17] P. J. Ollitrault, A. Miessen, and I. Tavernelli, Molecular quantum dynamics: a quantum\ncomputing perspective, Acc. Chem. Res. 54, 23 (2021).\n[18] P. J. Ollitrault, G. Mazzola, and I. Tavernelli, Nonadiabatic molecular quantum dynamics\nwith quantum computers, Phys. Rev. Lett. 125, 260511 (2020).\n[19] R. J. MacDonell, C. E. Dickerson, C. J. T. Birch, A. Kumar, C. L. Edmunds, M. J. Biercuk,\nC. Hempel and I. Kassal, Analog quantum simulation of chemical dynamics, Chem. Sci. 12,"
        },
        {
            "heading": "9794 (2021).",
            "text": "[20] I. Kassal, S. P. Jordan, P. J. Love, M. Mohseni, and A. Aspuru-Guzik, Polynomial-time quan-\ntum algorithm for the simulation of chemical dynamics, Proc. Natl. Acad. Sci. U.S.A. 105,"
        },
        {
            "heading": "18681 (2008).",
            "text": "[21] A. Roggero, C. Gu, A. Baroni, and T. Papenbrock, Preparation of excited states for nuclear\ndynamics on a quantum computer, Phys. Rev. C 102, 064624 (2020).\n[22] E. T. Holland, K. A. Wendt, K. Kravvaris, X. Wu, W. E. Ormand, J. L DuBois, S. Quaglioni,\nand F. Pederiva, Optimal control for the quantum simulation of nuclear dynamics, Phys. Rev.\nA 101, 062307 (2020).\n[23] K. T. Sch\u00fctt, F. Arbabzadah, S. Chmiela, K. R. M\u00fcller, and A. Tkatchenko, Quantum-chemical\ninsights from deep tensor neural networks, Nat. Commun. 8, 13890 (2017).\n[24] O. T. Unke and M. Meuwly, PhysNet: a neural network for predicting energies, forces, dipole\nmoments and partial charges, J. Chem. Theor. Comp. 15, 3678 (2019).\n[25] S. Manzhos and T. Jr. Carrington, A random-sampling high dimensional model representation\nneural network for building potential energy surfaces, J. Chem. Phys. 125, 084109 (2006).\n[26] S. Manzhos, X. Wang, R. Dawes, and T. Jr. Carrington, A nested molecule-independent neural\nnetwork approach for high-quality potential fits, J. Phys. Chem. A 110, 5295 (2006).\n[27] J. Behler and M. Parrinello, Generalized neural-network representation of high-dimensional\npotential-energy surfaces, Phys. Rev. Lett. 98, 146401 (2007).\n[28] J. Behler, Neural network potential-energy surfaces in chemistry: a tool for large-scale simu-\nlations, Phys. Chem. Chem. Phys. 13, 17930 (2011).\n[29] J. Behler, Constructing high-dimensional neural network potentials: A tutorial review, Int. J.\nQuant. Chem. 115, 1032 (2015).\n[30] E. Pradhan and A. Brown, A ground state potential energy surface for HONO based on a neural\nnetwork with exponential fitting functions, Phys. Chem. Chem. Phys. 19, 22272 (2017).\n[31] A. Leclerc and T. Jr. Carrington, Calculating vibrational spectra with sum of product basis\nfunctions without storing full-dimensional vectors or matrices, J. Chem. Phys. 140, 174111\n(2014).\n[32] S. Manzhos, R. Dawes, and T. Jr. Carrington, Neural network-based approaches for building\nhigh dimensional and quantum dynamics-friendly potential energy surfaces, Int. J. Quant.\nChem. 115, 1012 (2015).\n[33] J. Chen, X. Xu, X. Xu, and D. H. Zhang, A global potential energy surface for the H2 + OH\n\u2194 H2O + H reaction using neural networks, J. Chem. Phys. 138, 154301 (2013).\n[34] Q. Liu, X. Zhou, L. Zhou, Y. Zhang, X. Luo, H. Guo, and B. Jiang, Constructing high-\ndimensional neural network potential energy surfaces for gas-surface scattering and reactions,\nJ. Phys. Chem. C 122, 1761 (2018).\n[35] S. Manzhos and T. Jr. Carrington, Neural network potential energy surfaces for small molecules\nand reactions, Chem. Rev. 121, 16 (2021).\n[36] M. Meuwly, Machine learning for chemical reactions, Chem. Rev. 121, 16 (2021).\n[37] C. M. Handley, G. I. Hawe, D. B. Kellab, and P. L. A. Popelier, Optimal construction of a\nfast and accurate polarisable water potential based on multipole moments trained by machine\nlearning, Phys. Chem. Chem. Phys. 11, 6365 (2009).\n[38] A. P. Bart\u00f3k, M. C. Payne, R. Kondor, and G. Cs\u00e1nyi, Gaussian approximation potentials:\nThe accuracy of quantum mechanics, without the electrons, Phys. Rev. Lett. 104, 136403\n(2010).\n[39] A. P. Bart\u00f3k and G. Cs\u00e1nyi, Gaussian approximation potentials: A brief tutorial introduction,\nInt. J. Quant. Chem. 115, 1051 (2015).\n[40] J. Cui and R. V. Krems, Efficient non-parametric fitting of potential energy surfaces for poly-\natomic molecules with Gaussian processes, J. Phys. B: At. Mol. Opt. Phys. 49, 224001 (2016).\n[41] P. O. Dral, A. Owens, S. N. Yurchenko, and W. Thiel, Structure-based sampling and self-\ncorrecting machine learning for accurate calculations of potential energy surfaces and vibra-\ntional levels, J. Chem. Phys. 146, 244108 (2017).\n[42] B. Kolb, P. Marshall, B. Zhao, B. Jiang, and H. Guo, Representing global reactive potential\nenergy surfaces using Gaussian processes, J. Phys. Chem. A 121, 2552 (2017).\n[43] A. Kamath, R. A. Vargas-Hernandez, R. V. Krems, T. Jr. Carrington, and S. Manzhos, Neural\nnetworks vs Gaussian process regression for representing potential energy surfaces: A compar-\native study of fit quality and vibrational spectrum accuracy, J. Chem. Phys. 148, 241702\n(2018).\n[44] G. Schmitz and O. Christiansen, Gaussian process regression to accelerate geometry optimiza-\ntions relying on numerical differentiation, J. Chem. Phys. 148, 241704 (2018).\n[45] Y. Guan, S. Yang, and D. H. Zhang, Construction of reactive potential energy surfaces with\nGaussian process regression: active data selection, Mol. Phys. 116, 823 (2018).\n[46] G. Laude, D.Calderini, D. P. Tew, and J. O. Richardson, Ab initio instanton rate theory made\nefficient using Gaussian process regression, Faraday Discuss. 212, 237 (2018).\n[47] Y. Guan, S. Yang, and D. H. Zhang, Application of clustering algorithms to partitioning\nconfiguration space in fitting reactive potential energy surfaces, J. Phys. Chem. A 122, 3140\n(2018).\n[48] A. E. Wiens, A. V. Copan, and H. F. Schaefer, Multi-fidelity Gaussian process modeling for\nchemical energy surfaces, Chem. Phys. Lett. X 3, 100022 (2019).\n[49] C. Qu, Q. Yu, B. L. Jr Van Hoozen, J. M. Bowman, and Vargas-Hern\u00e0ndez, R. A. Assessing\nGaussian process regression and permutationally invariant polynomial approaches to represent\nhigh-dimensional potential energy surfaces, J. Chem. Theor. Comp. 14, 3381 (2018).\n[50] Q. Song, Q. Zhang, and Q. Meng, Revisiting the Gaussian process regression for fitting high-\ndimensional potential energy surface and its application to the OH + HO2 \u2192 O2 + H2O reaction, J. Chem. Phys. 152, 134309 (2020).\n[51] C. Qu, R. Conte, P. L. Houston, and J. M. Bowman, Full-dimensional potential energy surface\nfor acetylacetone and tunneling splittings, Phys. Chem. Chem. Phys. 23, 7758 (2021).\n[52] O. T. Unke and M. Meuwly, Toolkit for the construction of reproducing kernel-based repre-\nsentations of data: Application to multidimensional potential energy surfaces, J. Chem. Inf.\nModel. 57, 1923 (2017).\n[53] T. S. Ho and H. Rabitz, A general method for constructing multidimensional molecular po-\ntential energy surfaces from ab initio calculations, J. Chem. Phys. 104, 2584 (1996).\n[54] T. Hollebeek, T. S. Ho, and H. Rabitz, A fast algorithm for evaluating multidimensional\npotential energy surfaces, J. Chem. Phys. 106, 7223 (1997).\n[55] T. S. Ho and H. Rabitz, Reproducing kernel Hilbert space interpolation methods as a paradigm\nof high dimensional model representations: Application to multidimensional potential energy\nsurface construction, J. Chem. Phys. 119, 6433 (2003).\n[56] U. T. Unke, Potential energy surfaces: from force fields to neural networks, Doctoral disserta-\ntion, University of Basel, 2019.\n[57] Y. Liu, S. Arunachalam, and K. Temme, A rigorous and robust quantum speed-up in super-\nvised machine learning, Nat. Phys. 17, 1013 (2021).\n[58] M. Schuld, A. Bocharov, K. M. Svore, and N. Wiebe, Circuit-centric quantum classifiers, Phys.\nRev. A 101, 032308 (2020).\n[59] M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini, Parameterized quantum circuits as machine\nlearning models, Quantum Sci. Technol. 4, 043001 (2019).\n[60] M. Schuld, I. Sinayskiy, and F. Petruccione, An introduction to quantum machine learning,\nContemp. Phys. 56, 2 (2015).\n[61] J. Biamonte, P. Wittek, N. Pancotti, P. Rebentrost, N. Wiebe, and S. Lloyd, Quantum machine\nlearning, Nature 549, 195 (2017).\n[62] P. Rebentrost, M. Mohseni, and S.Lloyd, Quantum support vector machine for big data clas-\nsification, Phys. Rev. Lett. 113, 130503 (2014).\n[63] S. Maria and N. Killoran, Quantum machine learning in feature hilbert spaces,\nPhys. Rev. Lett. 122, 040504 (2019).\n[64] V. Havl\u00ed\u010dek, A. D. C\u00f3rcoles, K. Temme, A. W. Harrow, A. Kandala, J. M. Chow, and J.\nM. Gambetta, Supervised learning with quantum-enhanced feature spaces, Nature 567, 209\n(2019).\n[65] Y. Suzuki, H. Yano, Q. Gao, S. Uno, T. Tanaka, M. Akiyama, and N Yamamoto, Analysis\nand synthesis of feature map for kernel-based quantum classifier, Quantum Mach. Intell. 2, 9\n(2020).\n[66] J. Park, B. Quanz, S. Wood, H. Higgins, and R. Harishankar, Practical application improve-\nment to Quantum SVM: theory to practice, arXiv:2012.07725.\n[67] R. Chatterjee and T. Yu, Generalized coherent states, reproducing kernels, and quantum\nsupport vector machines, arXiv:1612.03713.\n[68] J.R. Glick, T. P. Gujarati, A. D. C\u00f3rcoles, Y. Kim, A.Kandala, J. M. Gambetta, and K.\nTemme, Covariant quantum kernels for data with group structure, arXiv:2105.03406.\n[69] M. Schuld, I. Sinayskiy, and F. Petruccione, Prediction by linear regression on a quantum\ncomputer, Phys. Rev. A 94, 022342 (2016).\n[70] G. Wang, Quantum algorithm for linear regression, Phys. Rev. A 96, 012335 (2017).\n[71] P. Date and T. Potok, Adiabatic quantum linear regression, Scientific Reports 11, 21905\n(2021).\n[72] N. Killoran, T. R. Bromley, J. M.Arrazola, M. Schuld, N. Quesada, and S. Lloyd, Continuous-\nvariable quantum neural networks, Phys. Rev. Research 1, 033063 (2019).\n[73] M. Otten, I. R. Goumiri, B. W. Priest, G. F. Chapline, and M. D. Schneider, Quantummachine\nlearning using Gaussian processes with performant quantum kernels, arXiv:2004.11280.\n[74] J. Wang, Q. Chen, and Y. Chen, RBF kernel based support vector machine with universal\napproximation and its application - Advances in neural networks, edited by F. Yin, J. Wang,\nC. Guo, (Springer Berlin Heidelberg, Berlin, Heidelberg, 2004), pp.512-517.\n[75] Q. Yu and J. M. Bowman, Ab initio potential for H3O+ \u2192 H+ + H2O: A step to a many-body\nrepresentation of the hydrated proton?, J. Chem. Theor. Comp. 12, 5284 (2016)\n[76] J. Dai and R. V. Krems, Interpolation and extrapolation of global potential energy surfaces for\npolyatomic systems by Gaussian processes with composite kernels, J. Chem. Theor. Comp. 16,"
        },
        {
            "heading": "3 (2020).",
            "text": "[77] C. E. Rasmussen and C. K. I. Williams, Gaussian processes for machine learning (The MIT\nPress, Cambridge, 2006).\n[78] G. Aleksandrowicz, T. Alexander, P. Barkoutsos, L. Bello, Y. Ben-Haim, D. Bucher, F. J.\nCabrera-Hern\u00e1ndez, J. Carballo-Franquis, A. Chen, and C. Chen et al., Qiskit: An open-\nsource framework for quantum computing, doi=10.5281/zenodo.2573505.\n[79] K. Asnaashari and R. V. Krems, Gradient domain machine learning with composite kernels:\nimproving the accuracy of PES and force fields for large molecules, Mach. Learn.: Sci. &\nTechnol. 3, 015005 (2022).\n[80] R. A. Vargas-Hern\u00e0ndez, Y. Guan, D. H. Zhang and R. V. Krems, Bayesian optimization\nfor the inverse scattering problem in quantum reaction dynamics, New J. Phys. (Fast Track\nCommunication) 21, 022001 (2019).\n[81] G. Schwarz, Estimating the dimension of a model, The Annals of Statistics 2, 461 (1978).\n[82] D. K. Duvenaud, H. Nickisch, and C. E. Rasmussen, Additive gaussian processes, Adv. Neur.\nInf. Proc. Sys. 24, 226 (2011).\n[83] D. K. Duvenaud, J. Lloyd, R. Grosse, J. B. Tenenbaum, and Z. Ghahramani, Structure discov-\nery in nonparametric regression through compositional kernel search, Proceedings of the 30th\nInternational Conference on Machine Learning Research 28, 1166 (2013).\n[84] R. A. Vargas-Hern\u00e0ndez, J. Sous, M. Berciu, and R. V. Krems, Extrapolating quantum observ-\nables with machine learning: Inferring multiple phase transitions from properties of a single\nphase, Phys. Rev. Lett. 121, 255702 (2018).\n[85] H. Sugisawa, T Ida, and R. V. Krems, Gaussian process model of 51-dimensional potential\nenergy surface for protonated imidazole dimer, J. Chem. Phys. 153, 11 (2020)."
        }
    ],
    "year": 2022
}