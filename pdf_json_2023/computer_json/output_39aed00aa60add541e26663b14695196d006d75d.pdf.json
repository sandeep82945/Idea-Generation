{
    "abstractText": "The success of automated medical image analysis depends on large-scale and expert-annotated training sets. Unsupervised domain adaptation (UDA) has been raised as a promising approach to alleviate the burden of labeled data collection. However, they generally operate under the closed-set adaptation setting assuming an identical label set between the source and target domains, which is over-restrictive in clinical practice where new classes commonly exist across datasets due to taxonomic inconsistency. While several methods have been presented to tackle both domain shifts and incoherent label sets, none of them take into account the common characteristics of the two issues and consider the learning dynamics along network training. In this work, we propose optimization trajectory distillation, a unified approach to address the two technical challenges from a new perspective. It exploits the lowrank nature of gradient space and devises a dual-stream distillation algorithm to regularize the learning dynamics of insufficiently annotated domain and classes with the external guidance obtained from reliable sources. Our approach resolves the issue of inadequate navigation along network optimization, which is the major obstacle in the taxonomy adaptive cross-domain adaptation scenario. We evaluate the proposed method extensively on several tasks towards various endpoints with clinical and open-world significance. The results demonstrate its effectiveness and improvements over previous methods. Code is available at https://github.com/camwew/TADA-MI.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jianan Fan"
        },
        {
            "affiliations": [],
            "name": "Dongnan Liu"
        },
        {
            "affiliations": [],
            "name": "Hang Chang"
        },
        {
            "affiliations": [],
            "name": "Heng Huang"
        },
        {
            "affiliations": [],
            "name": "Mei Chen"
        },
        {
            "affiliations": [],
            "name": "Weidong Cai"
        }
    ],
    "id": "SP:2c0e777ac8277e416734a5b560937b566c7715d1",
    "references": [
        {
            "authors": [
                "Sanjeev Arora",
                "Rong Ge",
                "Yingyu Liang",
                "Tengyu Ma",
                "Yi Zhang"
            ],
            "title": "Generalization and equilibrium in generative adversarial nets (gans)",
            "venue": "In International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "Sheikh Shams Azam",
                "Seyyedali Hosseinalipour",
                "Qiang Qiu",
                "Christopher Brinton"
            ],
            "title": "Recycling model updates in federated learning: Are gradient subspaces low-rank",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Shai Ben-David",
                "John Blitzer",
                "Koby Crammer",
                "Fernando Pereira"
            ],
            "title": "Analysis of representations for domain adaptation",
            "venue": "Advances in neural information processing systems,",
            "year": 2006
        },
        {
            "authors": [
                "Debora Caldarola",
                "Barbara Caputo",
                "Marco Ciccone"
            ],
            "title": "Improving generalization in federated learning by seeking flat minima",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Junbum Cha",
                "Sanghyuk Chun",
                "Kyungjae Lee",
                "Han- Cheol Cho",
                "Seunghyun Park",
                "Yunsung Lee",
                "Sungrae Park"
            ],
            "title": "Swad: Domain generalization by seeking flat minima",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Pratik Chaudhari",
                "Anna Choromanska",
                "Stefano Soatto",
                "Yann LeCun",
                "Carlo Baldassi",
                "Christian Borgs",
                "Jennifer Chayes",
                "Levent Sagun",
                "Riccardo Zecchina"
            ],
            "title": "Entropy-SGD: Biasing gradient descent into wide valleys",
            "venue": "In International Conference on Learning Representations,",
            "year": 2017
        },
        {
            "authors": [
                "Cheng Chen",
                "Qi Dou",
                "Hao Chen",
                "Jing Qin",
                "Pheng-Ann Heng"
            ],
            "title": "Synergistic image and feature adaptation: Towards cross-modality domain adaptation for medical image segmentation",
            "venue": "In Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Wentao Chen",
                "Zhang Zhang",
                "Wei Wang",
                "Liang Wang",
                "Zilei Wang",
                "Tieniu Tan"
            ],
            "title": "Cross-domain cross-set few-shot learning via learning compact and aligned representations",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Zhao Chen",
                "Vijay Badrinarayanan",
                "Chen-Yu Lee",
                "Andrew Rabinovich"
            ],
            "title": "Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Ali Cheraghian",
                "Shafin Rahman",
                "Sameera Ramasinghe",
                "Pengfei Fang",
                "Christian Simon",
                "Lars Petersson",
                "Mehrtash Harandi"
            ],
            "title": "Synthesized feature based few-shot classincremental learning on a mixture of subspaces",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Joseph Paul Cohen"
            ],
            "title": "Covid-19 image data collection: Prospective predictions are the future",
            "year": 2006
        },
        {
            "authors": [
                "Felix Dangel",
                "Frederik Kunstner",
                "Philipp Hennig"
            ],
            "title": "Backpack: Packing more into backprop",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Debasmit Das",
                "Sungrack Yun",
                "Fatih Porikli"
            ],
            "title": "ConfeSS: A framework for single source cross-domain few-shot learning",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Susanna Dodd",
                "Mike Clarke",
                "Lorne Becker",
                "Chris Mavergames",
                "Rebecca Fish",
                "Paula R Williamson"
            ],
            "title": "A taxonomy has been developed for outcomes in medical research to help improve knowledge discovery",
            "venue": "Journal of clinical epidemiology,",
            "year": 2018
        },
        {
            "authors": [
                "C Dom\u00ednguez Conde",
                "C Xu",
                "LB Jarvis",
                "DB Rainbow",
                "SB Wells",
                "T Gomes",
                "SK Howlett",
                "O Suchanek",
                "K Polanski",
                "HW King"
            ],
            "title": "Cross-tissue immune cell analysis reveals tissuespecific features in humans",
            "year": 2022
        },
        {
            "authors": [
                "Zhekai Du",
                "Jingjing Li",
                "Hongzu Su",
                "Lei Zhu",
                "Ke Lu"
            ],
            "title": "Cross-domain gradient discrepancy minimization for unsupervised domain adaptation",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Jevgenij Gamper",
                "Navid Alemi Koohbanani",
                "Ksenija Benet",
                "Ali Khuram",
                "Nasir Rajpoot"
            ],
            "title": "Pannuke: an open pancancer histology dataset for nuclei instance segmentation and classification",
            "venue": "In European congress on digital pathology,",
            "year": 2019
        },
        {
            "authors": [
                "Yaroslav Ganin",
                "Evgeniya Ustinova",
                "Hana Ajakan",
                "Pascal Germain",
                "Hugo Larochelle",
                "Fran\u00e7ois Laviolette",
                "Mario Marchand",
                "Victor Lempitsky"
            ],
            "title": "Domain-adversarial training of neural networks. The journal of machine learning",
            "year": 2030
        },
        {
            "authors": [
                "Zhiqiang Gao",
                "Shufei Zhang",
                "Kaizhu Huang",
                "Qiufeng Wang",
                "Chaoliang Zhong"
            ],
            "title": "Gradient distribution alignment certificates better adversarial domain adaptation",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Yixiao Ge",
                "Dapeng Chen",
                "Hongsheng Li"
            ],
            "title": "Mutual meanteaching: Pseudo label refinery for unsupervised domain adaptation on person re-identification",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Rui Gong",
                "Martin Danelljan",
                "Dengxin Dai",
                "Danda Pani Paudel",
                "Ajad Chhatkuli",
                "Fisher Yu",
                "Luc Van Gool"
            ],
            "title": "Tacs: Taxonomy adaptive cross-domain semantic segmentation",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Simon Graham",
                "Mostafa Jahanifar",
                "Ayesha Azam",
                "Mohammed Nimir",
                "Yee-Wah Tsang",
                "Katherine Dodd",
                "Emily Hero",
                "Harvir Sahota",
                "Atisha Tank",
                "Ksenija Benes"
            ],
            "title": "Lizard: a large-scale dataset for colonic nuclear instance segmentation and classification",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Simon Graham",
                "Quoc Dang Vu",
                "Shan E Ahmed Raza",
                "Ayesha Azam",
                "Yee Wah Tsang",
                "Jin Tae Kwak",
                "Nasir Rajpoot"
            ],
            "title": "Hover-net: Simultaneous segmentation and classification of nuclei in multi-tissue histology",
            "venue": "images. Medical Image Analysis,",
            "year": 2019
        },
        {
            "authors": [
                "Yunhui Guo",
                "Noel C Codella",
                "Leonid Karlinsky",
                "James V Codella",
                "John R Smith",
                "Kate Saenko",
                "Tajana Rosing",
                "Rogerio Feris"
            ],
            "title": "A broader study of cross-domain few-shot learning",
            "venue": "In European conference on computer vision,",
            "year": 2020
        },
        {
            "authors": [
                "Yanxu Hu",
                "Andy J Ma"
            ],
            "title": "Adversarial feature augmentation for cross-domain few-shot classification",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Ashraful Islam",
                "Chun-Fu Richard Chen",
                "Rameswar Panda",
                "Leonid Karlinsky",
                "Rogerio Feris",
                "Richard J Radke"
            ],
            "title": "Dynamic distillation network for cross-domain few-shot recognition with unlabeled data",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Pavel Izmailov",
                "Dmitrii Podoprikhin",
                "Timur Garipov",
                "Dmitry Vetrov",
                "Andrew Gordon Wilson"
            ],
            "title": "Averaging weights leads to wider optima and better generalization",
            "venue": "Proceedings of the Conference on Uncertainty in Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Arthur Jacot",
                "Franck Gabriel",
                "Cl\u00e9ment Hongler"
            ],
            "title": "Neural tangent kernel: Convergence and generalization in neural networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Stanis\u0142aw Jastrz\u0119bski",
                "Zachary Kenton",
                "Devansh Arpit",
                "Nicolas Ballas",
                "Asja Fischer",
                "Yoshua Bengio",
                "Amos Storkey"
            ],
            "title": "Three factors influencing minima in sgd",
            "venue": "arXiv preprint arXiv:1711.04623,",
            "year": 2017
        },
        {
            "authors": [
                "Sajid Javed",
                "Arif Mahmood",
                "Muhammad Moazam Fraz",
                "Navid Alemi Koohbanani",
                "Ksenija Benes",
                "Yee-Wah Tsang",
                "Katherine Hewitt",
                "David Epstein",
                "David Snead",
                "Nasir Rajpoot"
            ],
            "title": "Cellular community detection for tissue phenotyping in colorectal cancer histology",
            "venue": "images. Medical image analysis,",
            "year": 2020
        },
        {
            "authors": [
                "Maggie Karthik"
            ],
            "title": "Aptos 2019 blindness detection. Kaggle",
            "year": 2019
        },
        {
            "authors": [
                "Jakob Nikolas Kather",
                "Cleo-Aron Weis",
                "Francesco Bianconi",
                "Susanne M Melchers",
                "Lothar R Schad",
                "Timo Gaiser",
                "Alexander Marx",
                "Frank Gerrit Z\u00f6llner"
            ],
            "title": "Multi-class texture analysis in colorectal cancer histology",
            "venue": "Scientific reports,",
            "year": 2016
        },
        {
            "authors": [
                "Nitish Shirish Keskar",
                "Dheevatsa Mudigere",
                "Jorge Nocedal",
                "Mikhail Smelyanskiy",
                "Ping Tak Peter Tang"
            ],
            "title": "On largebatch training for deep learning: Generalization gap and sharp minima",
            "venue": "In International Conference on Learning Representations,",
            "year": 2017
        },
        {
            "authors": [
                "Jogendra Nath Kundu",
                "Rahul Mysore Venkatesh",
                "Naveen Venkat",
                "Ambareesh Revanur",
                "R Venkatesh Babu"
            ],
            "title": "Classincremental domain adaptation",
            "venue": "In European Conference on Computer Vision,",
            "year": 2020
        },
        {
            "authors": [
                "Canran Li",
                "Dongnan Liu",
                "Haoran Li",
                "Zheng Zhang",
                "Guangming Lu",
                "Xiaojun Chang",
                "Weidong Cai"
            ],
            "title": "Domain adaptive nuclei instance segmentation and classification via category-aware feature alignment and pseudo-labelling",
            "venue": "In International Conference on Medical Image Computing and Computer-Assisted Intervention,",
            "year": 2022
        },
        {
            "authors": [
                "Tao Li"
            ],
            "title": "Diagnostic assessment of deep learning algorithms for diabetic retinopathy screening",
            "venue": "Information Sciences,",
            "year": 2019
        },
        {
            "authors": [
                "Wei-Hong Li",
                "Xialei Liu",
                "Hakan Bilen"
            ],
            "title": "Cross-domain few-shot learning with task-specific adapters",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Xinyan Li",
                "Qilong Gu",
                "Yingxue Zhou",
                "Tiancong Chen",
                "Arindam Banerjee"
            ],
            "title": "Hessian based analysis of sgd for deep nets: Dynamics and generalization",
            "venue": "In Proceedings of the 2020 SIAM International Conference on Data Mining,",
            "year": 2020
        },
        {
            "authors": [
                "Hanwen Liang",
                "Qiong Zhang",
                "Peng Dai",
                "Juwei Lu"
            ],
            "title": "Boosting the generalization capability in cross-domain fewshot learning via noise-enhanced supervised autoencoder",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Nina Linder",
                "Juho Konsti",
                "Riku Turkki",
                "Esa Rahtu",
                "Mikael Lundin",
                "Stig Nordling",
                "Caj Haglund",
                "Timo Ahonen",
                "Matti Pietik\u00e4inen",
                "Johan Lundin"
            ],
            "title": "Identification of tumor epithelium and stroma in tissue microarrays using texture analysis",
            "venue": "Diagnostic pathology,",
            "year": 2012
        },
        {
            "authors": [
                "Dongnan Liu",
                "Chaoyi Zhang",
                "Yang Song",
                "Heng Huang",
                "Chenyu Wang",
                "Michael Barnett",
                "Weidong Cai"
            ],
            "title": "Decompose to adapt: Cross-domain object detection via feature disentanglement",
            "venue": "IEEE Transactions on Multimedia,",
            "year": 2022
        },
        {
            "authors": [
                "Dongnan Liu",
                "Donghao Zhang",
                "Yang Song",
                "Fan Zhang",
                "Lauren O\u2019Donnell",
                "Heng Huang",
                "Mei Chen",
                "Weidong Cai"
            ],
            "title": "Unsupervised instance segmentation in microscopy images via panoptic domain adaptation and task re-weighting",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Xu Luo",
                "Jing Xu",
                "Zenglin Xu"
            ],
            "title": "Channel importance matters in few-shot image classification",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Zelun Luo",
                "Yuliang Zou",
                "Judy Hoffman",
                "Li F Fei- Fei"
            ],
            "title": "Label efficient learning of transferable representations acrosss domains and tasks",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Deborah Lupton"
            ],
            "title": "Medicine as culture: illness, disease and the body",
            "year": 2012
        },
        {
            "authors": [
                "Lucas Mansilla",
                "Rodrigo Echeveste",
                "Diego H Milone",
                "Enzo Ferrante"
            ],
            "title": "Domain generalization via gradient surgery",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Fausto Milletari",
                "Nassir Navab",
                "Seyed-Ahmad Ahmadi"
            ],
            "title": "V-net: Fully convolutional neural networks for volumetric medical image segmentation",
            "venue": "In 2016 fourth international conference on 3D vision (3DV),",
            "year": 2016
        },
        {
            "authors": [
                "Pau Panareda Busto",
                "Juergen Gall"
            ],
            "title": "Open set domain adaptation",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2017
        },
        {
            "authors": [
                "Cheng Perng Phoo",
                "Bharath Hariharan"
            ],
            "title": "Self-training for few-shot transfer across extreme task differences",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Sachin Ravi",
                "Hugo Larochelle"
            ],
            "title": "Optimization as a model for few-shot learning",
            "venue": "In International Conference on Learning Representations,",
            "year": 2017
        },
        {
            "authors": [
                "Kuniaki Saito",
                "Donghyun Kim",
                "Stan Sclaroff",
                "Trevor Darrell",
                "Kate Saenko"
            ],
            "title": "Semi-supervised domain adaptation via minimax entropy",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2019
        },
        {
            "authors": [
                "Ozan Sener",
                "Vladlen Koltun"
            ],
            "title": "Multi-task learning as multi-objective optimization",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Yuge Shi",
                "Jeffrey Seely",
                "Philip Torr",
                "Siddharth N",
                "Awni Hannun",
                "Nicolas Usunier",
                "Gabriel Synnaeve"
            ],
            "title": "Gradient matching for domain generalization",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Jake Snell",
                "Kevin Swersky",
                "Richard Zemel"
            ],
            "title": "Prototypical networks for few-shot learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Antonio Torralba",
                "Alexei A Efros"
            ],
            "title": "Unbiased look at dataset bias",
            "year": 2011
        },
        {
            "authors": [
                "Philipp Tschandl",
                "Christoph Rinner",
                "Zoe Apalla",
                "Giuseppe Argenziano",
                "Noel Codella",
                "Allan Halpern",
                "Monika Janda",
                "Aimilios Lallas",
                "Caterina Longo",
                "Josep Malvehy"
            ],
            "title": "Human\u2013computer collaboration for skin cancer recognition",
            "venue": "Nature Medicine,",
            "year": 2020
        },
        {
            "authors": [
                "Philipp Tschandl",
                "Cliff Rosendahl",
                "Harald Kittler"
            ],
            "title": "The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions",
            "venue": "Scientific data,",
            "year": 2018
        },
        {
            "authors": [
                "Hung-Yu Tseng",
                "Hsin-Ying Lee",
                "Jia-Bin Huang",
                "Ming- Hsuan Yang"
            ],
            "title": "Cross-domain few-shot classification via learned feature-wise transformation",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Hemanth Venkateswara"
            ],
            "title": "Deep hashing network for unsupervised domain adaptation",
            "venue": "In CVPR,",
            "year": 2017
        },
        {
            "authors": [
                "Qian Wang",
                "Toby Breckon"
            ],
            "title": "Unsupervised domain adaptation via structured prediction based selective pseudolabeling",
            "venue": "In Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Yaqing Wang",
                "Quanming Yao",
                "James T Kwok",
                "Lionel M Ni"
            ],
            "title": "Generalizing from a few examples: A survey on few-shot learning",
            "venue": "ACM computing surveys (csur),",
            "year": 2020
        },
        {
            "authors": [
                "Zirui Wang",
                "Zihang Dai",
                "Barnab\u00e1s P\u00f3czos",
                "Jaime Carbonell"
            ],
            "title": "Characterizing and avoiding negative transfer",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Julia K Winkler",
                "Christine Fink",
                "Ferdinand Toberer",
                "Alexander Enk",
                "Teresa Deinlein",
                "Rainer Hofmann-Wellenhof",
                "Luc Thomas",
                "Aimilios Lallas",
                "Andreas Blum",
                "Wilhelm Stolz"
            ],
            "title": "Association between surgical skin markings in dermoscopic images and diagnostic performance of a deep learning convolutional neural network for melanoma recognition",
            "venue": "JAMA dermatology,",
            "year": 2019
        },
        {
            "authors": [
                "Mengya Xu",
                "Mobarakol Islam",
                "Chwee Ming Lim",
                "Hongliang Ren"
            ],
            "title": "Class-incremental domain adaptation with smoothing and calibration for surgical report generation",
            "venue": "In International Conference on Medical Image Computing and Computer-Assisted Intervention,",
            "year": 2021
        },
        {
            "authors": [
                "Kaichao You",
                "Mingsheng Long",
                "Zhangjie Cao",
                "Jianmin Wang",
                "Michael I Jordan"
            ],
            "title": "Universal domain adaptation",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Tianhe Yu",
                "Saurabh Kumar",
                "Abhishek Gupta",
                "Sergey Levine",
                "Karol Hausman",
                "Chelsea Finn"
            ],
            "title": "Gradient surgery for multi-task learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Wang Yuan",
                "Zhizhong Zhang",
                "Cong Wang",
                "Haichuan Song",
                "Yuan Xie",
                "Lizhuang Ma"
            ],
            "title": "Task-level self-supervision for cross-domain few-shot learning",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Sangdoo Yun",
                "Dongyoon Han",
                "Seong Joon Oh",
                "Sanghyuk Chun",
                "Junsuk Choe",
                "Youngjoon Yoo"
            ],
            "title": "Cutmix: Regularization strategy to train strong classifiers with localizable features",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2019
        },
        {
            "authors": [
                "Qiming Zhang",
                "Jing Zhang",
                "Wei Liu",
                "Dacheng Tao"
            ],
            "title": "Category anchor-guided unsupervised domain adaptation for semantic segmentation",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Lin Zuo",
                "Mengmeng Jing",
                "Jingjing Li",
                "Lei Zhu",
                "Ke Lu",
                "Yang Yang"
            ],
            "title": "Challenging tough samples in unsupervised domain adaptation",
            "venue": "Pattern Recognition,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1. Introduction",
            "text": "Automated and objective analysis of medical images is an important research topic and has been explored in various clinical applications [65, 15]. To relieve the burden of acquiring massive annotated data for model development on new domains, several unsupervised domain adapta-\ntion (UDA) methods [7, 43, 42] are proposed to mitigate the data distribution bias [57] between a richly labeled source domain and a target domain with no explicit supervision.\nHowever, these works assume a closed-set adaptation setting that the source and target domains should necessarily share the identical category label space and definition [49]. The restriction limits their practical applicability in the clinical wild [17]. Unlike natural images where the definitions of different entity categories (e.g., cat v.s. dog) are structured and globally unified, in the medical domain, inconsistency in taxonomy across different countries or institutes is a common issue compromising the feasibility of cross-domain adaptation [14]. Take nuclei recognition in histology images as an example, the ambiguous biologi-\nar X\niv :2\n30 7.\n14 70\n9v 1\n[ cs\n.C V\n] 2\n7 Ju\nl 2 02\ncal characteristics of cells and distinct clinical usages of the analysis outcomes result in a lack of a unified categorization schema [17, 22]. With specific clinical purposes and downstream applications, different datasets could categorize nuclei with disparate granularities of biological concepts. Besides, as medical research evolves rapidly, novel cell and disease classes could be discovered and form datasets with continually expanding category label sets [46]. This motivates us to develop a generalized adaptation method with the capability to tackle both data distribution bias and category gap for more flexible UDA in clinical practice.\nTo this end, we study the problem of taxonomy adaptive domain adaptation [21]. It assumes the target domain could adopt a label space different from the source domain. Following UDA, a labeled source dataset and unlabeled samples from the target domain are available during training. Additionally, to recognize the novel/fine-grained categories which are non-existent or unspecified in the source domain, a few samples of those target-private categories are annotated and utilized as exemplars. The technical challenge for this setting lies in how to alleviate domain shifts and concurrently learn new classes with very limited supervision. Recently, several methods are proposed towards a similar goal [35, 24]. However, they typically address the two issues individually in separate contexts and fail to design a unified paradigm according to their common characteristics [21], which could incur a subtle collision across issues since their objectives are non-relevant [68]. Besides, existing works either focus on cross-domain/class alignment in the feature space [45, 40] or resort to model output-based regularization such as self-supervision [50], whereas those approaches suffer from the equilibrium challenge of adversarial learning [1] and the low-quality pseudo-labels [62].\nIn this work, we present a unified framework for taxonomy adaptive cross-domain adaptation from a new perspective, i.e., via optimization trajectory distillation. Our strategy is motivated by a common challenge existing in both cross-domain and small-data learning regimes, which is the inadequate navigation in the course of network optimization. For cross-domain learning, the unstable feature alignment procedure and noisy pseudo-labels tend to induce error accumulation along network training [71]. Similarly, with limited support samples in new class learning, the optimization of network is inclined to step towards restricted local minima and cannot cover a globally-generalizable space [63]. To this end, we propose to exploit the optimization trajectory from a reliable \u201cteacher\u201d to provide external guidance for regularizing the learning dynamics of insufficiently annotated domain and classes, as illustrated in Fig. 1(b).\nOur method consists of two key components, i.e., crossdomain/class distillation and historical self-distillation. (i) Cross-domain and cross-class distillation aim to leverage the optimization trajectory from the richly labeled do-\nmain and classes to serve as the \u201cteacher\u201d. Motivated by the Neural Tangent Kernel (NTK) theory [29], we characterize the network optimization trajectory through gradient statistics. Then, given the observation that the subspace spanned by the gradients from most iterations is generally low-rank [39, 2], we design a gradient projection approach to suppress the noisy signals in stochastic gradients and rectify the distillation process. Thereafter constraints are imposed on the gradient statistics of target domain and new classes to calibrate their training dynamics towards domain-invariant and unbiased learning procedure. (ii) Historical self-distillation further drives the optimization paths of model to converge towards flat minima. It is found that the flatness of loss landscapes is strongly related to the model\u2019s robustness and generalizability [28], while how to take advantage of the insight to tackle domain shifts and limited supervision is under-explored. We propose to exploit the historical gradients to construct the informative low-rank subspaces and then perform gradient projection to alleviate loss sharpness. It compensates for the intense and out-of-order optimization updates incurred by inadequate regularization and leads to better generalization.\nOur prime contributions are as follows: (1) We introduce a more generalized cross-domain adaptation paradigm for medical image analysis in which both data distribution bias and category gap exist across the source and target domains. (2) We leverage insights from recent learning theory research and propose a novel dual-stream optimization trajectory distillation method to provide external navigation in network training. We perform theoretical justifications from two perspectives to illustrate the merits of our method. (3) Experiments on various benchmarks validate the effectiveness and robustness of our proposed method and its improvements over existing approaches."
        },
        {
            "heading": "2. Related Works",
            "text": "Domain Adaptation Domain adaptation (DA) aims to mitigate the data distribution bias [18]. The classic semisupervised/unsupervised DA focuses on the scenario where the target domain has an identical label space to the source domain [53, 16, 36]. The over-restricted precondition cannot suffice the demand of clinical usages [66]. There exist several efforts to take a step further than the closed-set adaptation, such as open-set DA [49] and universal DA [67]. However, the aim of those works is solely to detect the previously unseen classes, instead of learning to separately identify each new class with few supports. Some recent studies suggest to explicitly recognize the target-private categories. [35] performs feature projection and alignment based on the prototypical networks [56]. [21] combines pseudo-labeling and contrastive learning to combat domain bias and label gap. Nevertheless, those works are limited to tackling the two issues individually, which fails to exploit\ntheir common characteristics and propose a unified solution. Cross-Domain Few-Shot Learning The technical challenge we need to resolve is similar to an emerging research topic, i.e., cross-domain few-shot learning [24]. The mainstream methods for this challenge include self-training [50, 27, 69], contrastive learning [13, 21], feature alignment/augmentation [60, 8, 26], and channel transformation [38, 44]. Those methods either focus on feature-level modulation or turn to output-level self-supervision and finetuning, which could bring instability along optimization [1, 62]. In this work, we propose a novel gradient-based framework to transfer knowledge in both cross-domain and few-shot settings. It implicitly characterizes the information in both feature space and output space. Gradient Manipulation In current deep learning systems where gradient descent serves as the most popular training algorithm, the directions and amplitudes of network optimization steps are embedded in the gradient space [9]. Gradient manipulation refers to directly modulating the optimization gradients for improved learning process [47]. Recently, it is introduced to mitigate the data distribution shift and shows promises in UDA and domain generalization [16, 19, 55]. However, those works are still restricted by the closed-set condition and do not consider the low-rank nature of gradients [39], which make their approaches vulnerable to noises in the small-data learning regime. Flatness in Optimization In previous machine learning research, the connection between convergence to flat minima in optimization and model generalizability has long been established [25, 34]. Theoretical and empirical studies prove that the flatness of loss landscapes highly correlates with generalization capability [4]. [5] averages the network weights of multiple checkpoints to prompt generalization across domains. Different from their post-hoc averaging approach operating on fixed models, we propose to regularize the intermediate dynamics of network optimization to achieve flat minima."
        },
        {
            "heading": "3. Method",
            "text": ""
        },
        {
            "heading": "3.1. Problem Statement",
            "text": "The taxonomy adaptive cross-domain adaptation problem can be formalized as follows. There exists a labeled source dataset Ds = {(xs,ys)}, an unlabeled target dataset Dut = {(xut )}, and a few-shot labeled support set from the target domain Dlt = {(xlt,ylt)}. Samples from source and target datasets are drawn from different data distributions, i.e., xs \u223c Ps, xt \u223c Pt, Ps \u0338= Pt. The label sets of source and target datasets are denoted as Cs and Ct. Due to the novel/fine-grained categories only existing in the target dataset, we have Cs \u0338= Ct. The shared and target-private new classes are indicated as C = Cs \u2229 Ct and C\u0302 = Ct\\C. We call C existing in both datasets as anchor classes since\nthey can be used as anchors to facilitate knowledge transfer. The goal is to train a model jointly on Ds,Dut ,Dlt which performs inferences on data from Pt with labels in Ct."
        },
        {
            "heading": "3.2. Characterization of Optimization Trajectory",
            "text": "The technical challenge for the identified problem lies in overcoming both domain shifts and overfitting incurred by scarce training samples. As discussed in Section 1, those issues could lead to unreliable navigation during neural network optimization [20, 10]. Therefore, we propose to distill the optimization trajectory knowledge from well-annotated sources to regularize the training dynamics of target domain and new classes.\nRecently, NTK theory [29] has been regarded as a tool to dictate the evolution of neural networks. For a network f parameterized by \u03b8, its training dynamics can be described by a kernel K. Given a training set with N samples, the kernel can be defined as an N \u00d7 N matrix with K(i, j; \u03b8) = \u2207\u03b8f(xi; \u03b8)\u22a4 \u00b7 \u2207\u03b8f(xj ; \u03b8), where xi and xj are two input samples. It indicates the strong correlations between the network\u2019s optimization trajectory and the gradients w.r.t. its parameters. We thus propose to collect a set of intermediate gradients during training and capture their statistics to characterize the optimization trajectory. Specifically, the second-order Taylor expansion shows that:\nf(x; \u03b8) =f(x; \u03b8\u2217) + (\u03b8 \u2212 \u03b8\u2217)\u22a4 \u00b7 \u2207\u03b8f(x; \u03b8\u2217)\n+ 1\n2 (\u03b8 \u2212 \u03b8\u2217)\u22a4 \u00b7 \u22072\u03b8f(x; \u03b8\u2217) \u00b7 (\u03b8 \u2212 \u03b8\u2217)\n+O(\u2225\u03b8 \u2212 \u03b8\u2217\u22252),\n(1)\nwhich motivates us to model the first- and second-order derivatives (Hessian) of f to represent its learning dynamics. We use the mean of gradients to indicate the first-order derivative and follow [30] to approximate the second-order derivative with gradient variances."
        },
        {
            "heading": "3.3. Cross-Domain and Cross-Class Distillation",
            "text": "Gradient-based optimization algorithms depend on a large number of update steps supervised by sufficient labeled data [52]. In domain-shifted and small-data regimes, those algorithms suffer from noisy update signals and overfitting, without guarantee to converge towards generalizable minima [24]. To this end, we propose to distill the training dynamics from the label-rich source domain and anchor classes to the target domain and new classes for external regularization by leveraging their intermediate gradients. We firstly compute the gradients g for each domain and class by backpropagating the obtained losses. With a general backbone F for feature extraction and a task-specific predictor C for sample-/pixel-wise classification, the individual gradients can be expressed as:\ng := [ \u2202L(C(F(x)), y) \u2202\u03b8C1 , \u00b7 \u00b7 \u00b7 , \u2202L(C(F(x)), y) \u2202\u03b8Cw ], (2)\nwhere L is the loss function, w indicates the total number of parameters in C, x and y are training data and the corresponding label. For unlabeled samples xut in the target dataset, online pseudo-labels y\u0303ut are used for loss calculation. Then, as shown in Fig. 2, we aggregate the individuallevel gradients in a memory buffer and retrieve the domainand class-level gradient statistics to model the global firstand second-order derivatives. According to Section 3.2, for gradients w.r.t. domain/class \u03c0 collected from a training set with n\u03c0 samples, we derive their mean and variance as:\ngm\u03c0 = 1\nn\u03c0\n\u2211n\u03c0 i=1 gi\u03c0, (3)\ngv\u03c0 = 1 n\u03c0 \u2212 1 \u2211n\u03c0 i=1 (gi\u03c0 \u2212 gm\u03c0 )2. (4)\nThose metrics are measured for each domain and class separately.\nHowever, the gradients obtained from insufficiently annotated domain and classes are dubious and error-prone [63]. To alleviate the issue, we take inspiration from recent learning theory findings that stochastic gradients along the optimization steps are generally low-rank [39], which indicates that the optimization process is governed by the top gradient eigenspace. Specifically, we devise a gradient projection approach to suppress the noisy model update signals in particular to the target domain and new classes by projecting their gradients on the reliable subspaces identified by the source domain and anchor classes with sufficient supervision. Our approach involves three iterative steps, i.e., subspace construction, gradient projection, and gradient statistics matching. Firstly, to identify the principal eigenspace, we perform Singular Value Decomposition (SVD) on the aggregated gradients from the source domain and anchor classes. We denote gradients collected from source domain, target domain, anchor class, and new\nclass as gs, gt, gA, and gN . Given the sets of gradients Gs = [g1s , g 2 s , \u00b7 \u00b7 \u00b7 , gKs ] and GA = [g1A, g2A, \u00b7 \u00b7 \u00b7 , gKA ] stored in the memory buffer of volume K, we apply SVD:\nGs = Us\u03a3sV \u22a4 s , GA = UA\u03a3AV \u22a4 A , (5)\nwhere U , V , and \u03a3 contain left singular vectors ui, right singular vector vi, and non-negative singular values \u03c3i, respectively. To capture the overall characteristics, we use the gradients averaged along all anchor classes to represent GA. Next, we adopt the low-rank matrix approximation to select the top-r significant left singular vectors in Us and UA based on the following criteria:\n\u2225(Gs)rs\u22252F \u2265 \u03c4 \u2225Gs\u2225 2 F , \u2225(GA) rA\u22252F \u2265 \u03c4 \u2225GA\u2225 2 F , (6) where (G)r = \u2211r\ni=1 \u03c3 iuivi\u22a4, \u2225\u00b7\u2225F denotes the Frobenius\nnorm, \u03c4 is a threshold to ensure most information is preserved and is set to 0.98. The principal subspace and the corresponding projection matrix are thereby constructed as Ms = [u 1 s,u 2 s, \u00b7 \u00b7 \u00b7 ,urss ] and MA = [u1A,u2A, \u00b7 \u00b7 \u00b7 ,u rA A ]. Afterward, all gradients are projected on the identified subspace as shown in Fig. 2:\ng\u2217s = MsM \u22a4 s gs, g \u2217 t = MsM \u22a4 s gt,\ng\u2217A = MAM \u22a4 A gA, g \u2217 N = MAM \u22a4 A gN .\n(7)\nThen following Eq.(3)(4), we minimize the discrepancy between the statistics (i.e., mean and variance) of projected gradients to distill the learning dynamics from the source domain and anchor classes to the target domain and new classes. The overall training objective can be formulated as:\nmin \u03b8 LERM + \u03bb\n{ \u2225(gm\u2217s \u2212 gm\u2217t )\u2225 2 2 + \u2225(g v\u2217 s \u2212 gv\u2217t )\u2225 2 2\n+ 1\nnnew\n\u2211nnew i=1 [ \u2225(gm\u2217A \u2212 gm\u2217Ni )\u2225 2 2 + \u2225(g v\u2217 A \u2212 gv\u2217Ni)\u2225 2 2 ]} .\n(8)\nHere LERM denotes the empirical risk loss, which is implemented with cross-entropy loss for classification and Dice loss [48] for segmentation. \u03bb is a balancing coefficient, nnew is the number of new classes in the target domain. It is noted that there exists discrepancy between the anchor and new classes in semantic concepts, which makes feature alignment across classes harmful due to negative transfer [64]. However, aligning class-wise learning dynamics by enforcing the similarity between their gradients could contribute to lower empirical error on new classes. We prove this property theoretically in the supplementary material."
        },
        {
            "heading": "3.4. Historical Self-distillation",
            "text": "Inferior generalization behaviour is an outstanding challenge for taxonomy adaptive cross-domain adaptation [21]. When domain shifts and unseen classes exist, a trained model could only maintain its performance on test samples sharing multiple similar attributes with the training data but cannot generalize well to the disparate ones [72]. Motivated by the connection between flat minima and generalizability [34], we devise the historical self-distillation module to smooth the optimization path towards a well-generalizable solution by calibrating gradient descent steps.\nTo reach flat loss landscapes [6], assuming a local loss function \u03c8 and a network f parameterized by \u03b8, instead of minimizing the original loss \u03c8(f(x; \u03b8)) only, the optimization objective should be:\nmin \u03b8 \u2212 log \u222b \u2225\u03b8\u2212\u03b8\u2217\u2225\u2264\u0393 exp(\u2212\u03c8(f(x; \u03b8\u2217))\u2212\u03b3 \u2225\u03b8 \u2212 \u03b8\u2217\u2225) d\u03b8\u2217, (9) where x indicates random input samples, \u0393 is defined as the width of a local parameter valley, \u03b3 is a balancing weight. In other words, when \u03b8 and \u03b8\u2217 are neighbouring, the following criteria is required to be satisfied:\n\u2225\u2207\u03b8\u03c8(f(x; \u03b8))\u2212\u2207\u03b8\u03c8(f(x; \u03b8\u2217))\u2225 \u2264 \u03b2 \u2225\u03b8 \u2212 \u03b8\u2217\u2225 , (10)\nwhere \u03b2 is a smoothness factor. To this end, we propose to impose regulations on the optimizer steps by enforcing minima with uniformly-distributed gradients. Given that the gradients from most iterations are generally lowrank [39, 2], we exploit past gradients to identify the lowdimensional subspace which indicates the principal gradient distribution of local minima and then project current gradients on the constructed subspace to exclude sharp and noisy signals. Specifically, we collect and store individual gradients for each iteration along the training procedure, denoted as GIt = [gt\u2212TIt , g t\u2212T+1 It , \u00b7 \u00b7 \u00b7 , g t\u22122 It , g t\u22121 It ], where t is the index of current iteration, T is the size of memory buffer. Thereafter we perform SVD on the set of gradients GIt to construct the historical subspace. Similar to Eq.(5)(6)(7), the top-r left singular vectors of the decomposed gradient set are concatenated to formulate the projection matrix\nMIt. Then for upcoming gradients obtained from backpropagation in each iteration, we project the gradients on the identified low-rank subspace and consider them as residuals. The subsequent optimizer step is conducted with the sum of the original and rectified gradients, as shown in Fig. 2. Take vanilla stochastic gradient descent as an example, with mini-batch gradients g\u0303 in each iteration, the parameters \u03b8 of the optimized network are updated by:\n\u03b8 := \u03b8 \u2212 1 \u03ba \u00b7 \u03b7 \u00b7 (MIt M\u22a4It + \u03ba) \u00b7 g\u0303, (11)\nwhere \u03b7 is the learning rate, \u03ba is a trade-off parameter. As training proceeds, the principal subspace and the corresponding projection matrix are periodically renewed by applying SVD on the recently collected gradients. The overall training procedure is summarized in the supplementary material."
        },
        {
            "heading": "3.5. Theoretical Analysis",
            "text": "In this section, we motivate our proposed method theoretically and provide mathematical insights on its merits. Joint Characterization of Feature and Output Space While our optimization trajectory distillation approach proposes a novel perspective that differs from existing works imposing regularization terms in feature and model-output space [35, 21], those information is still captured and implicitly modeled in the gradient-based framework. We prove this property for the classification and segmentation tasks under two commonly adopted loss functions. The detailed proof is presented in the supplemental material. It illustrates the superiority of our method as a unified framework that jointly characterizes the feature and output space as well as the learning dynamics. Impacts on Generalization Error In our method, we propose to minimize the discrepancy between the gradient statistics from different domains and classes in the identified principal subspace. We hereby prove its effectiveness towards a tighter generalization error bound on the target domain and new classes [3]. Details can be found in the supplemental material."
        },
        {
            "heading": "4. Experiments",
            "text": ""
        },
        {
            "heading": "4.1. Datasets and Experiment Settings",
            "text": "To evaluate the effectiveness of our method and its potential clinical implications, we conduct experiments on five medical image datasets in regard to three important downstream tasks from different clinical scenarios. Extended experiments on more diverse tasks, including radiology and fundus analysis, as well as general visual task, are presented in the supplemental material to substantiate the broader applicability of our method.\nNuclei Segmentation and Recognition Technically, this task can be formalized as a simultaneous instance segmentation and classification problem [23]. We evaluate our method by considering PanNuke [17] and Lizard [22] as the source and target datasets. They contain 481 and 291 visual fields cropped from whole-slide images with 189,744 and 495,179 annotated nuclei, respectively. There are six types of nuclei in Lizard and only two of them overlap with the five classes in PanNuke, which suggests four new classes in the target domain. We employ the widely used HoverNet [23] architecture with a standard ResNet-50 backbone as the base model. For quantitative evaluation, we follow [22] and report the average F1 and PQ (panoptic quality) scores for all classes (denoted as mF1 and mPQ) to provide a comprehensive assessment measuring the accuracy of nuclei detection, segmentation, and classification. Additionally, we also report the mF1* and mPQ* scores which are solely computed on new classes in the target domain. Cancer Tissue Phenotyping In this setting, we perform adaptation from a two-class discrimination task to an eightclass one on CRC-TP [31] and Kather [33] datasets. Kather consists of 5000 150\u00d7150 pathology image patches and includes six novel classes other than the two common classes also existing in the source domain. The experiments are conducted with ResNet-101 as backbone. For evaluation, we exploit the accuracy and F1 scores as metrics to indicate the classification performance. The average scores for all classes (mAcc and mF1) and particularly the ones on new classes only (mAcc* and mF1*) are reported. Skin Lesion Diagnosis We construct a fine-grained taxonomy adaptation setting from two coarse classes to seven subclasses with HAM10000 [59], which contains 10015 dermatoscopic images sampled from different body structures. The adopted experiment settings and evaluation metrics are the same as the cancer tissue phenotyping task. Since the label space of the source and target datasets do\nnot overlap, we only report the mAcc* and mF1* scores which are computed on target classes.\nFollowing previous works in UDA [7], for all experiments, each dataset is randomly split into 80%/20% for training/testing. To explicitly recognize the target-private new classes, we sample few (5/10) samples with corresponding labels to formulate the support set. The remaining target data is left unlabeled. More details can be found in the supplemental material."
        },
        {
            "heading": "4.2. Results",
            "text": "We compare our method with state-of-the-art approaches for cross-domain adaptation, including UDA methods DANN [18] and CGDM [16] which do not consider the taxonomic inconsistency, as well as LETR [45], FT-CIDA[35], STARTUP [50], DDN [27], TSA [38], and TACS [21] which are designed for both domain shifts and new class learning. For UDA methods, we jointly perform domain alignment and train the model with the labeled target data. In addition, we conduct comparisons with multi-task learning approach [54], which trains the model on all domains and label sets simultaneously. \u201cSup-only\u201d indicates the baseline where only the supervised loss on the labeled target dataset is used for training.\nTable 1 shows the comparison results on the crossdomain nuclei recognition and segmentation task. All methods adopt the same ResNet-50-HoverNet as base model following [23]. It can be observed that our proposed method outperforms the state-of-the-art cross-domain adaptation approaches by a large margin. We also notice an important point that compared with the \u201cSup-only\u201d baseline, most competing methods fail to attain better performance on the metrics specific to new classes (i.e., mF1* and mPQ*). For example, under the 5-shot setting, despite a 4.68% improvement is achieved by DANN on mF1, it achieves inferior performance on mF1* which is 4.94% worse than \u201cSup-only\u201d.\nThis phenomenon is incurred by the failure of cross-class generalization. In contrast, our method yields substantial improvements on those new class-specific metrics, which indicates the superior generalizability of our method. The observation is further verified through visual comparisons in the supplementary material.\nThe overall quantitative results on the cancer tissue phenotyping and skin lesion diagnosis tasks are presented in Table 2 and 3, respectively. All methods are implemented based on the ResNet-101 backbone. Under each few-shot setting, our method shows higher classification scores compared with previous approaches. In particular, we achieve 0.62%\u223c5.32% and 1.12%\u223c4.81% improvements against the second-best results in terms of mAcc and mF1 for cancer tissue phenotyping, as well as 4.92%\u223c7.58% and 2.88%\u223c4.93% improvements in terms of mAcc* and mF1* for skin lesion diagnosis. The higher accuracy consistently attained by our method under different cross-domain adaptation settings and clinical tasks is attributed to the strong generalizability brought by the proposed optimization trajectory distillation approach."
        },
        {
            "heading": "4.3. Analysis and Discussion",
            "text": "Ablation of Key Components Table 4 shows the ablation study results to illustrate the effectiveness of key components. \u201cprojection\u201d denotes the gradient projection approach introduced in Section 3.3. For the \u201cw/o projection\u201d ablation, we perform cross-domain and cross-class distillation by directly minimizing the statistics discrepancy between unrectified gradients (gs, gt) and (gA, gN ) in Eq. (7). It is observed that each component is indispensable and could improve the overall performance, which elaborates the importance of external navigation for learning target domain and new classes in network training. Interestingly, we notice that the impacts of cross-domain and cross-class distillation could be disparate across tasks. For example, crossclass distillation brings higher performance gain compared with cross-domain distillation on the cancer tissue phenotyping benchmark, while the situation is reversed for skin lesion diagnosis. It is caused by the different natures of each task. Class-imbalance is a serious issue for skin lesion diagnosis in that the class distribution is highly biased [59], which compromises the effectiveness of the cross-class distillation module. Differently, for cancer tissue phenotyping, classes are uniformly distributed [33] and could hence ensure the representativity of anchor classes and their exemplarity to be distilled to new classes.\nHyperparameter Sensitivity To investigate the effect of hyperparameters \u03bb in Eq. (8) and \u03ba in Eq. (11), we present the performance comparison by varying the choices of their values for cancer tissue phenotyping, as shown in Fig. 3. We only change one hyperparameter while keeping the other fixed at a time. The experimental results show that our framework is quite stable for hyperparameters in a wide interval, yet setting \u03bb and \u03ba to a large value is detrimental to the classification accuracy. Specifically, \u03bb is a balancing coefficient between class discriminativeness and gradient alignment. When it is too large, the trained model is biased to matching learning dynamics and would lose es-\nTable 4. Key component analysis of our method on three cross-domain adaptation benchmarks under 10-shot scheme. The best results are highlighted in bold.\nMethods Nuclei Cancer Skin\nmF1 mF1* mPQ mPQ* mAcc mAcc* mF1 mF1* mAcc* mF1*\nFull Framework 43.88 31.43 24.81 19.35 55.86 51.27 52.98 52.12 52.14 30.52 w/o cross-domain 39.96 30.08 22.29 18.10 52.81 49.93 51.62 50.64 44.34 25.28\nw/o cross-class 42.30 27.82 23.76 17.05 48.90 47.22 49.85 44.76 49.06 28.24 w/o historical 41.54 30.47 23.00 17.59 50.17 48.05 48.19 45.12 45.83 25.97 w/o projection 40.06 28.80 22.10 17.31 53.58 45.78 49.01 49.20 47.29 28.02\nFigure 3. Performance comparison between different choices of hyperparameters \u03bb and \u03ba on the cancer tissue phenotyping benchmark under 10-shot scheme.\nsential semantic knowledge. For \u03ba, it controls the proportions of unrectified gradients. Its large value indicates that most original gradients are preserved, which would incur noisy optimization steps and loss of flatness. Therefore, we decide to set \u03bb = 10 and \u03ba = 100. It achieves the best performance under most metrics. Impacts on Optimization Trajectory and Model Flatness To better understand the effectiveness of our method, we perform in-depth analysis about its impacts on model\u2019s training trajectory and flatness of the converged local minima. Firstly, as shown in Fig. 4(a), we visualize the optimization paths of our method and the multi-task baseline on the test accuracy surface with a contour plot. The details of plot procedure can refer to [28]. It can be observed that the optimization of the multi-task baseline fluctuates sharply and is restricted in a sub-optimal area with a relatively low test accuracy. This is induced by the biased navigation in the course of training due to domain shifts and category gap. With the devised dual-stream optimization trajectory distillation module, our method could by contrast suppress the noisy update signals and proceed consistently towards the optimum.\nBesides, we perform analysis about the solutions found by our method and the baseline in terms of flatness [5]. Specifically, the local flatness of a model parameter \u03b8 is quantified by the expected changes of test accuracy between \u03b8 and a neighbouring \u03b8\u2217 with perturbation rate \u03f1: F\u03f1(\u03b8) = E\u2225\u03b8\u2217\u2225=(1+\u03f1)\u2225\u03b8\u2225 [ Acc(\u03b8\u2217)\u2212 Acc(\u03b8) ] . We approximate the expected value by Monte-Carlo sampling over 50 samples. As demonstrated in Fig. 4(b), comparing with the\nbaseline approach, our method shows stronger robustness against model parameter perturbation. It proves that our method successfully converges to minima with better local flatness and thus possesses superior generalizability [34]."
        },
        {
            "heading": "5. Conclusion",
            "text": "In this paper, we study the taxonomy adaptive crossdomain adaptation paradigm, which allows incoherent label sets between source and target datasets. To jointly address the data distribution bias and category gap, we propose a unified framework which performs cross-domain and cross-class optimization trajectory distillation to calibrate the learning dynamics of insufficiently annotated domain and classes. Historical self-distillation is further devised to attain a well-generalizable solution via regulating gradient distributions. Extensive experiments on multiple benchmarks with different task contexts demonstrate the effectiveness and generalization capability of our method. In the future, we will extend this work to further discover the underlying mechanism of optimization trajectory distillation for model generalization and evaluate its potential in more adaptation scenarios.\nSupplementary Material: Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via Optimization Trajectory Distillation\nJianan Fan1, Dongnan Liu1, Hang Chang2, Heng Huang3, Mei Chen4, and Weidong Cai1\n1University of Sydney 2Lawrence Berkeley National Laboratory 3University of Maryland at College Park 4Microsoft jfan6480@uni.sydney.edu.au dongnan.liu@sydney.edu.au hchang@lbl.gov henghuanghh@gmail.com Mei.Chen@microsoft.com tom.cai@sydney.edu.au\nIn this supplementary, we provide additional illustration of our proposed method and proofs to support theoretical analysis, as well as dataset and implementation details. Extended experiments and analysis are performed to further verify the effectiveness and robustness of our method."
        },
        {
            "heading": "1. Overall Traininig Procedure",
            "text": "We summarize the workflow of our proposed method in Algorithm 1. The referred equation can be found in the main text."
        },
        {
            "heading": "2. Details for Theoretical Analysis",
            "text": ""
        },
        {
            "heading": "2.1. Joint Characterization of Feature and Output",
            "text": "Space\nHere, we prove that in our gradient-based method, information in feature space and model-output space can be jointly modeled implicitly, which demonstrates the superiority of our method as a unified framework that jointly characterizes the feature and output space as well as the learning dynamics. We illustrate this property under cross-entropy loss and Dice loss.\nSpecifically, for the task-specific prediction layer, which is implemented as a convolutional layer with 1 \u00d7 1 kernel, its function can be mathematically expressed as:\nu = W\u22a4z + b, (12)\nwhere z \u2208 RB\u00d7m\u00d7h\u00d7w denotes the input feature maps with batch size B, channel number m, and spatial size h \u00d7 w. W \u2208 Rm\u00d7c is the convolutional kernel matrix with input channel m and output channel c. b \u2208 Rc indicates the bias tensor. u \u2208 RB\u00d7c\u00d7h\u00d7w is the logit predictions.\nWe first consider the gradients for network parameter \u03b8 by backpropagating the cross entropy (CE) loss LCE :\nmin \u03b8\u223c[W , b]\n\u2212 p\u2211\nn=1 c\u2211 i=1 yni log eu n i\u2211c j=1 e unj , (13)\nAlgorithm 1: Training Procedure for Optimization Trajectory Distillation\nInput: Source dataset Ds, target dataset Dt, number of iterations I\nOutput: Optimized model parameters \u03b8 1 Init: Gradient memory buffer Gs,GA,GIt 2 for i\u2190 1 to I do 3 {(xs,ys)} \u2190 Image-label pairs sampled from(Ds) 4 {(xut )}, {(xlt,ylt)} \u2190 Sample from(Dt) 5 Generate online pseudo-label y\u0303ut 6 {(xt,yt)} \u2190 {(xut , y\u0303ut ), (xlt,ylt)} 7 Backpropagate gradients gs, gt, gA, gN by Eq.(2) 8 Cross-domain/class distillation: 9 Update Gs and GA with gs and gA\n10 if Gs andGA are full then 11 Apply SVD to identify the principal subspace and\nform the corresponding projection matrix Ms,MA by Eq.(5)(6)\n12 Clear Gs and GA 13 end 14 Perform gradient projection by Eq.(7) 15 Compute the overall training objective L by Eq.(8) 16 Temporal self-distillation: 17 Update GIt with gIt 18 if GIt is full then 19 Form the projection matrix MIt by Eq.(5)(6) 20 Clear GIt 21 end 22 Compute the mini-batch gradients g\u0303 \u2190 \u2207\u03b8L(\u03b8) 23 Update model parameters \u03b8 by Eq.(11)"
        },
        {
            "heading": "24 end",
            "text": ""
        },
        {
            "heading": "25 return \u03b8",
            "text": "where p = B \u00d7 h \u00d7 w is the total number of pixels, y \u2208 RB\u00d7c\u00d7h\u00d7w is the one-hot pixel-wise class label. Since our focus is on feature space z and output space u, without loss of generality, we set y to follow the uniform class dis-\n9\ntribution that y = [1/c, 1/c, ..., 1/c]. Then, for each pixel, the derivative of the CE loss can be formulated as:\n\u2202LCE \u2202\u03b8 \u2223\u2223\u2223\u2223 \u03b8=[\u03b81, \u03b82, ..., \u03b8c] = \u2202LCE \u2202u \u2223\u2223\u2223\u2223 u=[u1,u2, ...,uc] \u00b7 \u2202u \u2202\u03b8\n= \u22121 c \u00b7 \u2202 (\n\u2211c i=1 log eui\u2211c j=1 e uj )\n\u2202u \u00b7 \u2202u \u2202\u03b8\n= \u22121 c \u00b7 \u2202 (\n\u2211c i=1 ui \u2212 c \u00b7 log \u2211c j=1 e uj )\n\u2202u \u00b7 \u2202u \u2202\u03b8\n= \u22121 c \u00b7 (1\u2212 c \u00b7 [e u1 , eu2 , ..., euc ]\u2211c j=1 e uj ) \u00b7 z.\n(14)\nThen we summarize the gradient magnitudes over all pixels and channels:\nc\u2211 i=1 \u2225\u2202LCE \u2202\u03b8i \u2225 = p\u2211 n=1 c\u2211 i=1 \u2225\u2202LCE \u2202uni \u00b7 \u2202u n i \u2202\u03b8i \u2225\n= \u22121 c \u00b7 ( p\u2211 n=1 c\u2211 i=1 \u22251\u2212 c \u00b7 e uni\u2211c\nj=1 e unj\ufe38 \ufe37\ufe37 \ufe38\noutput space\n\u2225) \u00b7 ( p\u2211\nn=1 \u2225zn\u2225)\ufe38 \ufe37\ufe37 \ufe38 feature space .\n(15)\nThe result indicates that the gradients of CE loss characterize the information in both feature space and output space.\nSimilarly, for Dice loss LDice:\nmin \u03b8\u223c[W , b] p\u2211 n=1 c\u2211 i=1 (1\u2212 2y n i act(u n i ) yni + act(u n i ) ). (16)\nHere we omit the details of softmax layer and use act to denote the activation function for simplicity. When c is large, the pixel-wise derivative can be approximated by:\n\u2202LDice \u2202\u03b8 \u2223\u2223\u2223\u2223 \u03b8=[\u03b81, \u03b82, ..., \u03b8c] = \u2202LDice \u2202act(u) \u00b7 \u2202act(u) \u2202u \u00b7 \u2202u \u2202\u03b8\n\u2248 \u03be \u00b7 [e u1 , eu2 , ..., euc ]\n[act(u1)2, act(u2)2, ..., act(uc)2] \u00b7 z,\n(17)\nwhere \u03be is a constant term. Its gradient magnitudes can be written as: c\u2211\ni=1\n\u2225\u2202LDice \u2202\u03b8i\n\u2225 = p\u2211\nn=1 c\u2211 i=1 \u2225 \u2202LDice \u2202act(uni ) \u00b7 \u2202act(u n i ) \u2202uni \u00b7 \u2202u n i \u2202\u03b8i \u2225\n\u2248 \u03be \u00b7 ( p\u2211\nn=1 c\u2211 i=1 \u2225 e uni\nact(uni ) 2\ufe38 \ufe37\ufe37 \ufe38\noutput space\n\u2225) \u00b7 ( p\u2211\nn=1 \u2225zn\u2225)\ufe38 \ufe37\ufe37 \ufe38 feature space ,\n(18)\nwhich proves that the proposition also holds true for Dice loss."
        },
        {
            "heading": "2.2. Impacts on Generalization Error",
            "text": "In this section, we prove the effectiveness of our method towards a tighter generalization error bound on the target domain and novel classes.\nFirstly, we analyze the underlying mechanism for the cross-domain distillation module. Let H be a hypothesis space of VC-dimension d, for h \u2208 H, the correlations between the error on the target domain and the distance in gradient space across domains are established as [3, 19]:\n\u03f5T (h) \u2264 \u03f5\u0302S(h) + 4\nnl\n\u221a (d log\n2enl d + log 4 \u03b4 ) + \u039b\n+Div\u2207(U\u0303S, U\u0303T )+ 4\n\u221a 4 log(2nu) + log( 4 \u03b4 )\nnu ,\n(19)\nwith probability at least 1 \u2212 \u03b4. Here \u03f5T and \u03f5\u0302S represent the true and empirically estimated error of the target and source domain, respectively. Div\u2207(U\u0303S , U\u0303T ) is the distance between data distributions U\u0303S and U\u0303T in gradient space. nl and nu denote the number of labeled and unlabeled samples. \u039b, \u03b4, and e are constants. It implies that constraining the gradient descent trajectory of the target domain to approximate the source domain\u2019s, which reduces Div\u2207(U\u0303S , U\u0303T ), could lead to lower cross-domain generalization error.\nFurthermore, we demonstrate that the cross-class distillation module contributes to lower empirical error on novel classes from the multi-task learning perspective. Suppose that L is the empirical training loss and \u2207\u03b8Lq(\u03b8) denotes its derivative w.r.t. class q. Given a set of anchor classes {ai}Ai=1 and a novel class q, with the first-order Taylor expansion, we have:\nLq(\u03b8\u2212\u00b5\u00b7\u2206\u03b8\u2217) = Lq(\u03b8)\u2212\u00b5\u00b7\u2207\u03b8Lq(\u03b8)\u00b7\u2206\u03b8\u2217+O(\u00b5), (20)\nwhere the optimization step \u2206\u03b8\u2217 is characterized by\u2211A i=1 \u2207\u03b8Lai(\u03b8) +\u2207\u03b8Lq(\u03b8), \u00b5 is a small value. Then:\nLq(\u03b8 \u2212 \u00b5\u00b7\u2206\u03b8\u2217)\u2212 Lq(\u03b8) = \u2212\u00b5 \u00b7 { \u2225\u2207\u03b8Lq(\u03b8)\u22252\n+ A\u2211 i=1 [ \u2207\u03b8Lq(\u03b8) \u00b7 \u2207\u03b8Lai(\u03b8) ]} +O(\u00b5). (21)\nIt indicates that by enforcing the similarity between the gradients w.r.t. novel and anchor classes, we could drive the model to reduce the empirical loss on novel classes along optimization and thereby attain a well-generalizable solution."
        },
        {
            "heading": "3. Implementation Details",
            "text": ""
        },
        {
            "heading": "3.1. Nuclei Segmentation and Recognition",
            "text": ""
        },
        {
            "heading": "3.1.1 Datasets and Preprocessing",
            "text": "Accurate detection, segmentation, and classification of nuclei serve as essential prerequisites for various clinical and research studies within the digital pathology field [23]. Inconsistent taxonomy for nuclei categorization is common across different institutes, which results in the unmatched label sets among datasets. In this regard, we use PanNuke [17] and Lizard [22] as the source and target dataset, respectively. PanNuke contains 481 visual fields cropped from whole-slide images along with 189,744 annotated nuclei. It follows a categorization schema where nuclei are divided into five classes, including neoplastic, non-neoplastic epithelial, inflammatory, connective, and dead cells. We discard the \u201cdead\u201d class as it does not exist in most image patches. To ensure the dataset has a uniform data distribution, we use all images from the breast tissue to formulate the source dataset. Lizard consists of 291 image regions with an average size of 1016\u00d7917 pixels from the colon tissue and annotates 495,179 nuclei. It adopts a categorization schema different to PanNuke that there are six classes in total, i.e., neutrophil, eosinophil, plasma, lymphocyte, epithelial, and connective cells. We use the Dpath subset as the target dataset. For preprocessing, all the visual fields with divergent size are randomly cropped into image patches of 128\u00d7128 pixels. CutMix [70] is used to augment the target dataset."
        },
        {
            "heading": "3.1.2 Network Architectures and Parameter Settings",
            "text": "We employ the widely used Hover-Net [23] architecture with a standard ResNet-50 backbone as the base model. The optimizer is Adam with a learning rate of 1e \u2212 4 and (\u03b21, \u03b22) = (0.9, 0.999), and the batch size is set as 4. To supervise the classification and segmentation branches, we adopt a combined loss of CrossEntropyLoss + DiceLoss. \u03bb in Eq.(8) and \u03ba in Eq.(11) are empirically set to 1000 and 10, respectively."
        },
        {
            "heading": "3.1.3 Evaluation Metrics",
            "text": "F1 score is a popular metric to evaluate classification performance. It measures both precision and recall harmonically. We report the class-averaged score to indicate the overall accuracy. Panoptic quality (PQ) [23] is a unified metric for the instance segmentation task which models the quality of both detection and segmentation results concurrently:\nPQ = TP TP + 12FP +\n1 2FN\ufe38 \ufe37\ufe37 \ufe38\nDetection Quality\n\u00b7 \u2211 (y,y\u0302)\u2208TP IoU(y, y\u0302)\nTP\ufe38 \ufe37\ufe37 \ufe38 Segmentation Quality . (22)\nwhere TP,FP,FN are the true positive, false positive, and false negative detection predictions, respectively. (y, y\u0302) represents the pair of ground truth and predicted segmentation mask. IoU is the intersection over union score."
        },
        {
            "heading": "3.2. Cancer Tissue Phenotyping",
            "text": ""
        },
        {
            "heading": "3.2.1 Datasets and Preprocessing",
            "text": "Identifying distinct tissue phenotypes is an essential step towards systematic profiling of the tumor microenvironment in pathological examination [31]. Previous works are mostly limited to the discrimination of two classes of tissue: tumor and stroma [41], while recent studies argue that recognizing more heterogeneous tissues brings clinical value [33]. We therefore propose to perform adaptation from a dataset with only two categories of tissue to another dataset with several novel classes. In particular, we select images of tumor and stroma tissue from the CRC-TP [31] to form the source dataset. CRC-TP contains 20 H&E-stained colorectal cancer (CRC) slides obtained from 20 different patients. Region-level tissue phenotype annotations are provided by expert pathologists. To ensure a unique category label can be assigned to each image, patches are extracted at 20\u00d7 magnification with the size of 150\u00d7150 pixels. The patch-wise tissue phenotypes are decided based on the majority of their content. Kather [33] is then regarded as the target dataset. It consists of 5000 150 \u00d7 150 pathology image patches sampled from 10 anonymized CRC tissue slides. Other than tumor and stroma tissue, Kather includes six novel tissue types, i.e., complex stroma, immune cells, debris, normal mucosal glands, adipose tissue, background, and thus poses an 8-class classification problem."
        },
        {
            "heading": "3.2.2 Network Architectures and Parameter Settings",
            "text": "For experiments, we employ ResNet-101 as the image encoder and thereupon add two classification heads on top to perform 2-class and 8-class discrimination, respectively. During training, cross-entropy loss and Adam optimizer with learning rate 1e \u2212 4 are used to optimize the model with a batch size of 4. \u03bb and \u03ba are set to 10 and 100."
        },
        {
            "heading": "3.3. Skin Lesion Diagnosis",
            "text": ""
        },
        {
            "heading": "3.3.1 Datasets and Preprocessing",
            "text": "Automatic fine-grained skin lesion recognition remains a global challenge in dermatology. By taking a step further than the basic benign/malignant differentiation, identifying the specific subtypes of lesions demonstrates significant diagnostic value [58]. We hereby assign a benign/malignant discrimination dataset as the source domain, and a fine-grained multi-disease dataset as the target domain. HAM10000 is a dermatoscopic image dataset collected from different populations and modalities [59].\nAfter preprocessing procedures including histogram correction, sample filtering, and center crop, 10015 dermatoscopic images with lesions of seven diagnostic categories in total are provided. It contains four subtypes of benign lesions (melanocytic nevi (NV), benign keratinocytic lesions (BKL), dermatofibromas (DF), and vascular lesions (VASC)) and three subtypes of malignant ones (melanomas (MEL), basal cell carcinomas (BCC), and actinic keratoses intraepithelial carcinomas (AKIEC)). We use the face subset with only coarse two-class annotations as the source domain and the lower extremity subset with fine-grained seven-class annotations as the target domain. All images are randomly cropped to the size of 160\u00d7 160 pixels before being forwarded to the network."
        },
        {
            "heading": "3.4. Overall Experiment Settings",
            "text": "For all experiments, we implement our method with Pytorch and conduct training on a NVIDIA GeForce RTX 3090 GPU with 24GB of memory. Gradient backpropagation is performed for each mini-batch using BackPACK [12]. Following previous works in UDA [7], each dataset is randomly split into 80%/20% as the training/test sets. For novel classes in the target dataset, we sample few (5/10) samples with corresponding labels to formulate the support set. The remaining target data is left unlabeled. Data augmentation techniques such as rotation and horizontal/vertical flip are employed during training. Please refer to the source code for more details.\nIt is noted that although from the technical perspective, skin lesion diagnosis is a multi-class classification problem similar to cancer tissue phenotyping, they differ largely in the task context. Specifically, skin lesion diagnosis is more\nlike an object recognition task where its decision is dominated by the local attributes of lesions, while cancer tissue phenotyping relies on the global structure of the whole pathology images, instead of focusing on a salient object."
        },
        {
            "heading": "4. Additional Experiment Results",
            "text": ""
        },
        {
            "heading": "4.1. Visualization",
            "text": "We provide additional qualitative results on the three benchmarks. The comparison results shown in Fig. 5 demonstrate the superiority of our method to detect each nucleus and delineate its boundary, as well as differentiating nuclei of various types with their detailed biological features. The t-SNE visualization in Fig. 6 shows that our method could discover the underlying embedding structures of various classes even with very limited labeled data."
        },
        {
            "heading": "4.2. Results with More Annotations",
            "text": "In this section, we compare our method with previous state-of-the-art approaches for cross-domain adaptation\nwhen more labeled samples are available in the target domain. The results for nuclei segmentation and recognition with 30 labeled target samples are shown in Table 5. The overall improvements of our method under this setting are consistent with previous experiment results. It validates the effectiveness of our method under different levels of support."
        },
        {
            "heading": "4.3. Extended Experiments on Diverse Tasks",
            "text": "We further evaluate our method on two medical image tasks beyond pathology analysis and one general visual recognition task, where the medical image tasks include pneumonia screening in radiology and diabetic retinopathy grading in fundus photography. For radiology analysis, we adopt covid-kaggle [51] and Chest-Montreal [11] for TADA from normal/pneumonia coarse screening to finegrained pneumonia diagnosis. For fundus, DDR [37] and APTOS19 [32] are used to construct a TADA setting with two novel classes (grade level 3, 4). In these settings, distribution shifts exist across domains due to differences in image acquisition protocols among multiple cohorts. For general visual task, we adopt OfficeHome [61] and evaluate on \u201cArtist\u201d and \u201cReal-world\u201d domains. Experiments are conducted in 10-shot regime and the corresponding results are presented in Table 6. Through comparison with SOTA methods, the effectiveness and broader applicability of our\nmethod are proved."
        },
        {
            "heading": "4.4. Extended Key Component Analysis",
            "text": "In Table 7, we demonstrate the effectiveness of our method\u2019s key components. It complements the ablation study performed in the main text from a cumulative perspective. From the results, we observe that all the proposed modules are beneficial for improving the cross-domain adaptation performance. In particular, the employment of the cross-class distillation module contributes to a significant performance gain for target-private classes. For instance, it attains 3.48% and 2.18% improvements in terms of mF1* and mPQ* under 10-shot scheme. It verifies the effectiveness of our method to perform optimization trajectory distillation across domains and classes towards strong model generalization."
        },
        {
            "heading": "4.5. Extended Hyperparameter Sensitivity Analysis",
            "text": "We further analyze the choices of hyperparameters and their impacts on model performance in Fig. 7. We vary the values of K and T , which denote the volumes of memory bank employed in the cross-domain/class distillation and historical self-distillation modules. The choice of \u03c4 in Eq. (6) which coordinates the identification of principle subspace is also studied. The results indicate that the choices of those hyperparameters do not have a significant influence as long as they are set within reasonable intervals. Compared with them, the choices of \u03bb in Eq. (8) and \u03ba in Eq. (11) demonstrate more importance and are required to be carefully decided."
        },
        {
            "heading": "4.6. Robustness to Support Sample Selection",
            "text": "To evaluate the robustness of our method against the randomness during few-shot sample selection, we run the experiments for 10 times with different sets of labeled samples\nin the target domain. The averaged results are presented in Table 8. It demonstrates that our method consistently outperforms the competing approaches under diverse settings, which indicates its strong robustness."
        }
    ],
    "title": "Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via Optimization Trajectory Distillation",
    "year": 2023
}