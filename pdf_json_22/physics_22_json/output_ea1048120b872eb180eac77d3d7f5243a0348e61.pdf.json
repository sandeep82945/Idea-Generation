{
    "abstractText": "The nearing end of Moore\u2019s Law has been driving the development of domain-specific hardware tailored to solve a special set of problems. Along these lines, probabilistic computing with inherently stochastic building blocks (p-bits) have shown significant promise, particularly in the context of hard optimization and statistical sampling problems. p-bits have been proposed and demonstrated in different hardware substrates ranging from small-scale stochastic magnetic tunnel junctions (sMTJs) in asynchronous architectures to large-scale CMOS in synchronous architectures. Here, we design and implement a truly asynchronous and medium-scale p-computer (with \u2248 800 pbits) that closely emulates the asynchronous dynamics of sMTJs in Field Programmable Gate Arrays (FPGAs). Using hard instances of the planted Ising glass problem on the Chimera lattice, we evaluate the performance of the asynchronous architecture against an ideal, synchronous design that performs parallelized (chromatic) exact Gibbs sampling. We find that despite the lack of any careful synchronization, the asynchronous design achieves parallelism with comparable algorithmic scaling in the ideal, carefully tuned and parallelized synchronous design. Our results highlight the promise of massively scaled p-computers with millions of free-running p-bits made out of nanoscale building blocks such as stochastic magnetic tunnel junctions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Navid Anjum Aadit"
        },
        {
            "affiliations": [],
            "name": "\u2021 Andrea Grimaldi"
        },
        {
            "affiliations": [],
            "name": "Giovanni Finocchio"
        },
        {
            "affiliations": [],
            "name": "Kerem Y. Camsari"
        }
    ],
    "id": "SP:0721a29641f0928938a03c5e33fbf42607c62e14",
    "references": [
        {
            "authors": [
                "N. Mohseni",
                "P.L. McMahon",
                "T. Byrnes"
            ],
            "title": "Ising machines as hardware solvers of combinatorial optimization problems",
            "venue": "arXiv preprint arXiv:2204.00276, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K.Y. Camsari"
            ],
            "title": "Stochastic p-bits for invertible logic",
            "venue": "Physical Review X, vol. 7, no. 3, p. 031014, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Kaiser"
            ],
            "title": "Benchmarking a probabilistic coprocessor",
            "venue": "arXiv preprint arXiv:2109.14801, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Kaiser"
            ],
            "title": "Hardware-aware in situ learning based on stochastic magnetic tunnel junctions",
            "venue": "Physical Review Applied, vol. 17, no. 1, p. 014016, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A. Grimaldi"
            ],
            "title": "Spintronics-compatible approach to solving maximum-satisfiability problems with probabilistic computing, invertible logic, and parallel tempering",
            "venue": "Physical Review Applied, vol. 17, no. 2, p. 024052, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "N.A. Aadit"
            ],
            "title": "Massively parallel probabilistic computing with sparse ising machines",
            "venue": "arXiv preprint arXiv:2110.02481, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "M. Mohseni"
            ],
            "title": "Nonequilibrium monte carlo for unfreezing variables in hard combinatorial optimization",
            "venue": "arXiv preprint arXiv:2111.13628, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "W.A. Borders"
            ],
            "title": "Integer factorization using stochastic magnetic tunnel junctions",
            "venue": "Nature, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "K. Hayakawa"
            ],
            "title": "Nanosecond random telegraph noise in in-plane magnetic tunnel junctions",
            "venue": "Physical Review Letters, vol. 126, no. 11, p. 117202, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "C. Safranski"
            ],
            "title": "Demonstration of nanosecond operation in stochastic magnetic tunnel junctions",
            "venue": "Nano Letters, vol. 21, no. 5, pp. 2040\u20132045, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "B. Sutton"
            ],
            "title": "Autonomous probabilistic coprocessing with petaflips per second",
            "venue": "IEEE Access, vol. 8, pp. 157 238\u2013157 252, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "G. Finocchio"
            ],
            "title": "The promise of spintronics for unconventional computing",
            "venue": "Journal of Magnetism and Magnetic Materials, vol. 521, p. 167506, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Bhatti"
            ],
            "title": "Spintronics based random access memory: a review",
            "venue": "Materials Today, vol. 20, no. 9, pp. 530\u2013548, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "A.Z. Pervaiz"
            ],
            "title": "Weighted p-bits for fpga implementation of probabilistic circuits",
            "venue": "IEEE transactions on neural networks and learning systems, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S.C. Smithson"
            ],
            "title": "Efficient cmos invertible logic using stochastic computing",
            "venue": "IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 66, no. 6, pp. 2263\u20132274, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "R. Rahman",
                "S. Bandyopadhyay"
            ],
            "title": "Variability of binary stochastic neurons employing low energy barrier nanomagnets with in-plane anisotropy",
            "venue": "arXiv preprint arXiv:2108.04319, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "I. Hen"
            ],
            "title": "Probing for quantum speedup in spin-glass problems with planted solutions",
            "venue": "Physical Review A, vol. 92, no. 4, p. 042325, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "T. Albash",
                "D.A. Lidar"
            ],
            "title": "Demonstration of a scaling advantage for a quantum annealer over simulated annealing",
            "venue": "Physical Review X, vol. 8, no. 3, p. 031016, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "J. Gonzalez"
            ],
            "title": "Parallel gibbs sampling: From colored fields to thin junction trees",
            "venue": "Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics. JMLR Workshop and Conference Proceedings, 2011, pp. 324\u2013332.",
            "year": 2011
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014p-bits, combinatorial optimization, planted Ising, Chimera lattice, asynchronous computing, massive parallelism, magnetic tunnel junctions\nI. INTRODUCTION\nWith the nearing end of Moore\u2019s Law, domain-specific hardware and architectures are growing rapidly. The notion of performing some tasks more efficiently (area, speed and/or energy) rather than improving performance for general purpose computing has led to the proliferation of special-purpose accelerators. With their widespread use, hard optimization problems have been a primary target of this approach and a variety of different domain-specific hardware architectures have emerged (see, Ref. [1] for a general and recent review).\nAs an example of this growing trend, probabilistic bits or p-bits were introduced [2] as a building block which can accelerate a broad family of algorithms including Monte Carlo, Markov Chain Monte Carlo [3], Quantum Monte Carlo, statistical sampling for Bayesian inference and Boltzmann machine learning [4] methods. p-bits have been shown to be compatible with powerful optimization techniques such as\n\u00a7Corresponding authors: \u25e6gfinocchio@unime.it, \\camsari@ece.ucsb.edu\nparallel tempering [5] with competitive performance relative to all other Ising machines (classical and quantum) in select problems such as integer factorization and Boolean satisfiability [6]. Their combination with sophisticated algorithms [7] could yield further advantages.\nA natural advantage of the p-bit model is its native mapping to the Ising model and to the natural generalization of Ising Models. This ensures that coupled p-bits can systematically probe the exact Boltzmann distribution through Gibbs or Metropolis sampling without any approximations or reductions, often necessary in alternative, non-bistable abstractions of the Ising spin.\nOne particularly promising small-scale demonstration of p-bits in an asynchronously operating mode was performed in Ref. [8]. Combined with key breakthrough experiments demonstrating nanosecond fluctuations in suitably designed low barrier magnetic tunnel junctions (MTJ) [9], [10], these results suggest the intriguing possibility of designing > million bit probabilistic computers [11] in light of the remarkable advances in the magnetic memory chip industry reaching gigabit densities [12], [13]. Even though large scale p-bit emulators have been designed and tested in FPGAs or ASICs, [3], [6], [11], [14], [15], virtually all of these implementations have been on synchronous hardware where a global clock controlled the information flow.\nIn this paper, we make a first attempt in designing and building a physics-inspired, truly asynchronous architecture, closely emulating the dynamics of interacting nanodevicebased p-bits. This physics-inspired architecture bears similarities to locally interacting (sparsely connected) and asynchronous bodies with probabilistic dynamics (FIG. 1, upper panel). We achieve the design by an unconventional use of FPGAs where individual p-bits are activated by decoupled ring oscillators and can have overlapping and out-of-phase clocks with different frequencies. Considering how variations may influence individual p-bit behavior in magnetic tunnel junction based designs [16] the behavior of asynchronous p-computers with built-in variations is worth investigating.\nTo compare the performance of the truly asynchronous pcomputer in the FPGA, we choose the planted Ising model where a hard optimization problem is generated with a planted solution [17], [18], allowing a reliable evaluation of the\nar X\niv :2\n20 5.\n07 40\n2v 1\n[ cs\n.A R\n] 1\n5 M\nay 2\n02 2\nasynchronous design with respect to exact Gibbs sampling."
        },
        {
            "heading": "II. PHYSICS-INSPIRED ARCHITECTURE",
            "text": "The main equations of the p-bit model (FIG. 1a) involves stochastic activation and a local field (synapse) calculation, given by:\nmi = sgn(tanh(\u03b2Ii)\u2212 rU ) Ii = \u2211 Jijmj + hi (1)\nwhere mi represents the bipolar p-bit state (\u00b11), rU is a uniform random number between (\u22121,+1) and [J ], {h} are the weights and biases for a given problem and \u03b2 is the inverse temperature.\nStandard Gibbs sampling iterates Eq. (1) to reach the Boltzmann distribution defined by the weights and typically involves a serialized update procedure with nested for loops. One way to avoid this serial for loop is to perform block updates between unconnected p-bits. This approach when applied in software is named \u201cchromatic sampling\u201d [19] and a low-level hardware realization of it was recently reported in Ref. [6]. However, this design also involves carefully designed and equally phase shifted synchronous clocks so that multiple blocks do not update simultaneously.\nIn this work, inspired by truly asynchronous small-scale implementations of p-computers with nanodevices (based on stochastic MTJs [4], [8]), we implemented a physics-inspired, truly asynchronous Ising Computer where different p-bits receive clocks with different frequencies with random phases.\nIn contrast to synchronous designs, no careful engineering between the clocks of asynchronous p-bits were made. Moreover, unavoidable variations of sMTJs in highly scaled pcomputers with nanodevices would make such engineering extremely difficult if not impossible. We found that despite the deliberate randomization of p-bit clocks and unavoidable collisions breaking exact Gibbs sampling, the physics-inspired design exhibited massive parallelism observed in carefully tuned synchronous designs, not observed in standard CPUbased Gibbs sampling (FIG. 3).\nRing Oscillator Generation: A ROSC clock consists of an odd number of looped NOT gates. In our FPGA (Xilinx, VCU118), we attach controllable delays to our inverters to make logical delays comparable to wire delays (FIG. 1b). We designed the delay unit as a flip flop with a very fast master clock (300 MHz) compared to the ROSC frequencies that essentially acts as a combinational delay unit. In this way, we were able to obtain highly regular ROSC clocks as a function of ring sizes whose frequencies were measured by specially designed counters (FIG. 1c). In our experiments, we used 10 ROSCs to drive 800 p-bits in a Chimera lattice. Each p-bit has a pseudorandom number generator, which is a 32-bit Linear Feedback Shift Register (LFSR). The ROSCs activate the LFSRs of the p-bits randomly based on the frequencies. In this work, we have distributed the clocks evenly among the p-bits between 5 and 17 MHz. However, different distributions for\nthe clocks, e.g., Gaussian, could be used. Since the Chimera graph is bi-partite, we did not assign the same clock to two p-bits that are on the different partitions to avoid systematic parallel updates between connected p-bits. Future work will consider dynamic clocking schemes where each p-bit can have a different \u201cretention time\u201d much like MTJ-based p-bits."
        },
        {
            "heading": "III. PLANTED ISING MODEL",
            "text": "An important class of hard optimization problems are those with \u201cplanted\u201d ground states that allow effective evaluation of performance. We construct frustrated spin glasses with planted solutions [17] on a 800-spin Chimera graph where we changed the number of tiles for different problem sizes (FIG. 2a). A Hamiltonian generated by this process is the sum of several local frustrated Hamiltonians which we will call \u201cclauses\u201d. A planted solution will be used to define these clauses so that it will be the ground energy of the final Hamiltonian. Every instance is characterized by two parameters: the clause density \u03b1, defined as nc/nn, where nc is the number of clauses and nn is the number of nodes of the graph, and the length of possible loops that form the clauses, cl = [lmin, lmax], where lmin/max is the min/max loop length, respectively. In this work, we chose \u03b1 = 0.4 and cl = [4, 8] for all our instances used in this paper, that run on the same 800-spin Chimera lattice in our hardware. Clause generation: A total of nc = \u03b1nn clauses is generated. Each clause is an ordered sequence of nodes that creates a loop of acceptable length in the graph. To obtain one, following Ref. [17], we pick a random node and start a non-backtracking random walk of at most lmax steps. If the walker lands on an already visited node, it means that a loop was formed and the node can be considered its initial point. If the length of the loop is > lmin the clause is accepted, if it is not or if the maximum number of steps is reached without closing the loop, the process is repeated. FIG. 2b shows a few examples of this process. A planted solution s is generated by creating a random\narray of \u22121s and +1s of length nn. A clause can be defined as cm = {n1, n2, ..., nk, nk+1}, with k \u2208 [lmin, lmax], where nk+1 = n1, representing the closing of the loop. Now, \u2200i \u2208 [1, k] : i 6= j we increase Jni,ni+1 by sisi+1, while for j \u2208 [1, k], picked at random, we increase Jnj ,nj+1 by \u2212sjsj+1. This last step serves to create a frustrated loop. Once this is done for all clauses, the final J is calculated by summing J and JT and by normalizing so that all J lie between [\u22121,+1]."
        },
        {
            "heading": "IV. PERFORMANCE COMPARISON",
            "text": "We follow the time-to-solution formulation [17], [18] to measure performance of the physics-inspired asynchronous architecture.\nTTS(\u03c4, pR) = \u03c4Nr(\u03c4, pR) (2)\nwhere Nr is the expected number of repetitions we need to perform an annealing schedule of time \u03c4 to the energy ground state at least once with probability pR. Nr is defined as:\nNr(\u03c4, pR) = ln (1\u2212 pR)\nln (1\u2212 pS(\u03c4)) (3)\nwhere pS is the probability of success in finding the ground state in one annealing process of length \u03c4 .\nTo evaluate the performance of our asynchronous architecture, we compared it to serialized Gibbs sampling on CPU (2.6 GHz) and to synchronous colored Gibbs sampling on FPGA. We investigated the scaling difficulty of planted Ising instances with fixed cl and \u03b1 across several Chimera graphs increasing in size by changing the number of tiles used in a Chimera, as illustrated in FIG. 2. For each set of tiles, we generated 100 planted Ising instances, performing simulated annealing trials to estimate the success probability, pS(\u03c4), for each instance (FIG. 3). On FPGA, we performed 500 trials per instance while on CPU we only performed 50 trials because of the exceedingly long run-times.\nAfter estimating a pS for every instance, the average TTS for a point is obtained by simply calculating the average of\n32 72 128 200 288 392 512 648 800 number of p-bits\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\n10 1\n10 2\n10 3 10 4 TT S (s ) 100 instances/point 50 trials/instance CPU 500 trials/instance FPGA Annealing to = 7 \u03b2\nStandard Gibbs (CPU) Asynchronous Gibbs (FPGA)\nSynchronous Gibbs (FPGA)\nFIG. 3. Performance comparison of synchronous (graph colored-tuned), asynchronous (physics-inspired, not colored, not tuned) and standard Gibbs (CPU) samplers on the planted Ising problem.\nthe pS for instances of that size and applying Eq. (2) with the appropriate annealing time \u03c4 . The reference probability pR was set to 99%. The error bars are obtained through bootstrapping with 95% confidence intervals and 104 samples.\nWe present the TTS for solving 100 instances of the planted Ising problems of 9 different sizes in FIG. 3. The standard Gibbs (CPU) was implemented in Python using optimized libraries for matrix calculations. The final two points were not computed because of time limitations. We solved the exact same instances on the FPGA programmed with the asynchronous ROSC activated 800 p-bits with a fixed point representation using 10-bits. As a reference, the synchronous solver performing chromatic Gibbs sampling solves the same instances on the same FPGA where careful phase shifting ensures no simultaneous or incorrect updates (where Ii calculation is not complete) occur between neighboring p-bits (as in Ref. [6]). On the other hand, the asynchronous solver is expected to take samples with both of those errors when p-bit clock edges happen to be closely separated. Our experiment investigates the usefulness of such samples.\nWe defined a common linear simulated annealing schedule for all the architectures with \u03b2 = 0.5 to 7.0 with a step of 0.5 where, at each \u03b2, a total of 937 sweeps (attempted flips of all p-bits) are executed. In the FPGA the annealing time was fixed to \u03c4 = 1.4 ms for each trial. To obtain a configuration comparable to the asynchronous architecture, the synchronous architecture was set up with two stable and oppositely phase shifted clocks with the average frequency (9.375 MHz) of the 10 ROSC clocks. We believe this arrangement made the two designs equivalent beyond the asynchronous and inexact dynamics of the ROSC since both designs approximately take the same amount of samples within the fixed annealing time \u03c4 . The key result we obtained is shown in FIG. 3. We observe a clear scaling difference between the CPU implementation of standard serialized Gibbs sampling and the massively parallel FPGA implementations which (ideally) obtain a scaling factor of \u2248 N in their flips/second due to their massively parallel architecture. Both solvers provide a roughly 5-orders of magnitude prefactor improvement over the CPU. Intriguingly, the\nscaling of the synchronous and asynchronous FPGA remain similar, despite the possibility of many collisions (parallel or incorrect updates) in the asynchronous design. Indeed, the carefully tuned synchronous design performs strictly better than the asynchronous one in all instances. Nevertheless, it is encouraging to observe that the asynchronous design without any carefully engineered clocks or tuning performs nearly as well, leading to the promising possibility of truly asynchronous, million bit p-computers with stochastic MTJs or other nanodevices."
        },
        {
            "heading": "ACKNOWLEDGMENT",
            "text": "K.Y.C. and N.A.A. acknowledge support through National Science Foun-\ndation (CCF 2106260) and K.Y.C. through the Samsung GRO program. A.G. and G.F. were supported under the project PRIN 2020LWPKH7 funded by the Italian Ministry of University and Research and by the PETASPIN Association (www.petaspin.com).\n[1] N. Mohseni, P. L. McMahon, and T. Byrnes, \u201cIsing machines as hardware solvers of combinatorial optimization problems,\u201d arXiv preprint arXiv:2204.00276, 2022. [2] K. Y. Camsari et al., \u201cStochastic p-bits for invertible logic,\u201d Physical Review X, vol. 7, no. 3, p. 031014, 2017. [3] J. Kaiser et al., \u201cBenchmarking a probabilistic coprocessor,\u201d arXiv preprint arXiv:2109.14801, 2021. [4] J. Kaiser et al., \u201cHardware-aware in situ learning based on stochastic magnetic tunnel junctions,\u201d Physical Review Applied, vol. 17, no. 1, p. 014016, 2022. [5] A. Grimaldi et al., \u201cSpintronics-compatible approach to solving maximum-satisfiability problems with probabilistic computing, invertible logic, and parallel tempering,\u201d Physical Review Applied, vol. 17, no. 2, p. 024052, 2022. [6] N. A. Aadit et al., \u201cMassively parallel probabilistic computing with sparse ising machines,\u201d arXiv preprint arXiv:2110.02481, 2021. [7] M. Mohseni et al., \u201cNonequilibrium monte carlo for unfreezing variables in hard combinatorial optimization,\u201d arXiv preprint arXiv:2111.13628, 2021. [8] W. A. Borders et al., \u201cInteger factorization using stochastic magnetic tunnel junctions,\u201d Nature, 2019. [9] K. Hayakawa et al., \u201cNanosecond random telegraph noise in in-plane magnetic tunnel junctions,\u201d Physical Review Letters, vol. 126, no. 11, p. 117202, 2021. [10] C. Safranski et al., \u201cDemonstration of nanosecond operation in stochastic magnetic tunnel junctions,\u201d Nano Letters, vol. 21, no. 5, pp. 2040\u20132045, 2021. [11] B. Sutton et al., \u201cAutonomous probabilistic coprocessing with petaflips per second,\u201d IEEE Access, vol. 8, pp. 157 238\u2013157 252, 2020. [12] G. Finocchio et al., \u201cThe promise of spintronics for unconventional computing,\u201d Journal of Magnetism and Magnetic Materials, vol. 521, p. 167506, 2021. [13] S. Bhatti et al., \u201cSpintronics based random access memory: a review,\u201d Materials Today, vol. 20, no. 9, pp. 530\u2013548, 2017. [14] A. Z. Pervaiz et al., \u201cWeighted p-bits for fpga implementation of probabilistic circuits,\u201d IEEE transactions on neural networks and learning systems, 2018. [15] S. C. Smithson et al., \u201cEfficient cmos invertible logic using stochastic computing,\u201d IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 66, no. 6, pp. 2263\u20132274, 2019. [16] R. Rahman and S. Bandyopadhyay, \u201cVariability of binary stochastic neurons employing low energy barrier nanomagnets with in-plane anisotropy,\u201d arXiv preprint arXiv:2108.04319, 2021. [17] I. Hen et al., \u201cProbing for quantum speedup in spin-glass problems with planted solutions,\u201d Physical Review A, vol. 92, no. 4, p. 042325, 2015. [18] T. Albash and D. A. Lidar, \u201cDemonstration of a scaling advantage for a quantum annealer over simulated annealing,\u201d Physical Review X, vol. 8, no. 3, p. 031016, 2018. [19] J. Gonzalez et al., \u201cParallel gibbs sampling: From colored fields to thin junction trees,\u201d in Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics. JMLR Workshop and Conference Proceedings, 2011, pp. 324\u2013332."
        }
    ],
    "title": "Physics-inspired Ising Computing with Ring Oscillator Activated p-bits",
    "year": 2022
}