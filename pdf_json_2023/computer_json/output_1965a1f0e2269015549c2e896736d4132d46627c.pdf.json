{
    "abstractText": "Flexible manufacturing has given rise to complex scheduling problems such as the flexible job shop scheduling problem (FJSP). In FJSP, operations can be processed on multiple machines, leading to intricate relationships between operations and machines. Recent works have employed deep reinforcement learning (DRL) to learn priority dispatching rules (PDRs) for solving FJSP. However, the quality of solutions still has room for improvement relative to that by the exact methods such as OR-Tools. To address this issue, this paper presents a novel end-to-end learning framework that weds the merits of self-attention models for deep feature extraction and DRL for scalable decision-making. The complex relationships between operations and machines are represented precisely and concisely, for which a dual-attention network (DAN) comprising several interconnected operation message attention blocks and machine message attention blocks is proposed. The DAN exploits the complicated relationships to construct production-adaptive operation and machine features to support high-quality decisionmaking. Experimental results using synthetic data as well as public benchmarks corroborate that the proposed approach outperforms both traditional PDRs and the state-of-the-art DRL method. Moreover, it achieves results comparable to exact methods in certain cases and demonstrates favorable generalization ability to large-scale and real-world unseen FJSP tasks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Runqing Wang"
        },
        {
            "affiliations": [],
            "name": "Gang Wang"
        },
        {
            "affiliations": [],
            "name": "Jian Sun"
        },
        {
            "affiliations": [],
            "name": "Jie Chen"
        }
    ],
    "id": "SP:de782f477e34b016751cde3fca59bea125abcbcd",
    "references": [
        {
            "authors": [
                "S. Mao",
                "B. Wang",
                "Y. Tang",
                "F. Qian"
            ],
            "title": "Opportunities and challenges of artificial intelligence for green manufacturing in the process industry",
            "venue": "Eng., vol. 5, no. 6, pp. 995\u20131002, Dec. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "J. Chen",
                "J. Sun",
                "G. Wang"
            ],
            "title": "From unmanned systems to autonomous intelligent systems",
            "venue": "Eng., vol. 12, no. 5, pp. 16\u201319, 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K. Ding",
                "F.T. Chan",
                "X. Zhang",
                "G. Zhou",
                "F. Zhang"
            ],
            "title": "Defining a digital twin-based cyber-physical production system for autonomous manufacturing in smart shop floors",
            "venue": "Int. J. Prod. Res., vol. 57, no. 20, pp. 6315\u20136334, Jan. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "A. Arunarani",
                "D. Manjula",
                "V. Sugumaran"
            ],
            "title": "Task scheduling techniques in cloud computing: A literature survey",
            "venue": "Future Gener. Comput. Syst., vol. 91, pp. 407\u2013415, Feb. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "S. Satunin",
                "E. Babkin"
            ],
            "title": "A multi-agent approach to intelligent transportation systems modeling with combinatorial auctions",
            "venue": "Expert Syst. Appl., vol. 41, no. 15, pp. 6622\u20136633, Nov. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "J. Zhang",
                "G. Ding",
                "Y. Zou",
                "S. Qin",
                "J. Fu"
            ],
            "title": "Review of job shop scheduling research and its new perspectives under Industry 4.0",
            "venue": "J. Intell. Manuf., vol. 30, pp. 1809\u20131830, 2019.",
            "year": 1809
        },
        {
            "authors": [
                "J. Xie",
                "L. Gao",
                "K. Peng",
                "X. Li",
                "H. Li"
            ],
            "title": "Review on flexible job shop scheduling",
            "venue": "IET Collab. Intell. Manuf., vol. 1, no. 3, pp. 67\u201377, Sep. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "L. Meng",
                "C. Zhang",
                "Y. Ren",
                "B. Zhang",
                "C. Lv"
            ],
            "title": "Mixed-integer linear programming and constraint programming formulations for solving distributed flexible job shop scheduling problem",
            "venue": "Comput. Ind. Eng., vol. 142, p. 106347, Apr. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Demir",
                "S.K. \u0130\u015fleyen"
            ],
            "title": "Evaluation of mathematical models for flexible job-shop scheduling problems",
            "venue": "Appl. Math. Modell., vol. 37, no. 3, pp. 977\u2013988, Feb. 2013.",
            "year": 2013
        },
        {
            "authors": [
                "V. Mnih",
                "K. Kavukcuoglu",
                "D. Silver",
                "A.A. Rusu",
                "J. Veness",
                "M.G. Bellemare",
                "A. Graves",
                "M. Riedmiller",
                "A.K. Fidjeland",
                "G. Ostrovski"
            ],
            "title": "Human-level control through deep reinforcement learning",
            "venue": "Nature, vol. 518, no. 7540, pp. 529\u2013533, Feb. 2015.",
            "year": 2015
        },
        {
            "authors": [
                "M. Wang",
                "B. Xin"
            ],
            "title": "A genetic algorithm for solving flexible flow shop scheduling problem with autonomous guided vehicles",
            "venue": "IEEE Intl. Conf. Control Autom. IEEE, 2019, pp. 922\u2013927.",
            "year": 2019
        },
        {
            "authors": [
                "D. Rooyani",
                "F.M. Defersha"
            ],
            "title": "An efficient two-stage genetic algorithm for flexible job-shop scheduling",
            "venue": "IFAC-PapersOnLine, vol. 52, no. 13, pp. 2519\u20132524, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "G. Zhang",
                "X. Shao",
                "P. Li",
                "L. Gao"
            ],
            "title": "An effective hybrid particle swarm optimization algorithm for multi-objective flexible job-shop scheduling problem",
            "venue": "Comput. Ind. Eng., vol. 56, no. 4, pp. 1309\u20131318, May 2009.",
            "year": 2009
        },
        {
            "authors": [
                "W. Du",
                "W. Zhong",
                "Y. Tang",
                "W. Du",
                "Y. Jin"
            ],
            "title": "High-dimensional robust multi-objective optimization for order scheduling: A decision variable classification approach",
            "venue": "IEEE Trans. Ind. Inf., vol. 15, no. 1, pp. 293\u2013 304, May 2018.",
            "year": 2018
        },
        {
            "authors": [
                "J.-Q. Li",
                "M.-X. Song",
                "L. Wang",
                "P.-Y. Duan",
                "Y.-Y. Han",
                "H.-Y. Sang",
                "Q.-K. Pan"
            ],
            "title": "Hybrid artificial bee colony algorithm for a parallel batching distributed flow-shop problem with deteriorating jobs",
            "venue": "IEEE Trans. Cybern., vol. 50, no. 6, pp. 2425\u20132439, Oct. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "R. Haupt"
            ],
            "title": "A survey of priority rule-based scheduling",
            "venue": "Oper. Res. Spektrum, vol. 11, no. 1, pp. 3\u201316, Mar. 1989.",
            "year": 1989
        },
        {
            "authors": [
                "L. Wang",
                "Z. Pan",
                "J. Wang"
            ],
            "title": "A review of reinforcement learning based intelligent optimization for manufacturing scheduling",
            "venue": "Compl. Syst. Model. Simul., vol. 1, no. 4, pp. 257\u2013270, Dec. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "L. Wang",
                "X. Hu",
                "Y. Wang",
                "S. Xu",
                "S. Ma",
                "K. Yang",
                "Z. Liu",
                "W. Wang"
            ],
            "title": "Dynamic job-shop scheduling in smart manufacturing using deep reinforcement learning",
            "venue": "Comput. Netw., vol. 190, p. 107969, May 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Luo",
                "L. Zhang",
                "Y. Fan"
            ],
            "title": "Real-time scheduling for dynamic partialno-wait multiobjective flexible job shop by deep reinforcement learning",
            "venue": "IEEE Trans. Autom. Sci. Eng., vol. 19, no. 4, pp. 3020\u20133038, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y. Du",
                "J. Li",
                "C. Li",
                "P. Duan"
            ],
            "title": "A reinforcement learning approach for flexible job shop scheduling problem with crane transportation and setup times",
            "venue": "IEEE Trans. Neural Netw. Learn. Syst., Oct. 2022, DOI: 10.1109/TNNLS.2022.3208942.",
            "year": 2022
        },
        {
            "authors": [
                "P. Brandimarte"
            ],
            "title": "Routing and scheduling in a flexible job shop by tabu search",
            "venue": "Ann. Oper. Res., vol. 41, no. 3, pp. 157\u2013183, Sep. 1993.",
            "year": 1993
        },
        {
            "authors": [
                "A. Vaswani",
                "N. Shazeer",
                "N. Parmar",
                "J. Uszkoreit",
                "L. Jones",
                "A.N. Gomez",
                "\u0141. Kaiser",
                "I. Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Adv. Neural Inf. Process. Syst., vol. 30, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "M. Nazari",
                "A. Oroojlooy",
                "L. Snyder",
                "M. Tak\u00e1c"
            ],
            "title": "Reinforcement learning for solving the vehicle routing problem",
            "venue": "Adv. Neural Inf. Process. Syst., vol. 31, 2018.",
            "year": 2018
        },
        {
            "authors": [
                "H.V.H.W. Kool",
                "M. Welling"
            ],
            "title": "Attention, learn to solve routing problems!",
            "venue": "Proc. Int. Conf. Learn. Represent.,",
            "year": 2018
        },
        {
            "authors": [
                "A. Mirhoseini",
                "A. Goldie",
                "M. Yazgan",
                "J.W. Jiang",
                "E. Songhori",
                "S. Wang",
                "Y.-J. Lee",
                "E. Johnson",
                "O. Pathak",
                "A. Nazi"
            ],
            "title": "A graph placement methodology for fast chip design",
            "venue": "Nature, vol. 594, no. 7862, pp. 207\u2013 212, June 2021.",
            "year": 2021
        },
        {
            "authors": [
                "Y.-D. Kwon",
                "J. Choo",
                "I. Yoon",
                "M. Park",
                "D. Park",
                "Y. Gwon"
            ],
            "title": "Matrix encoding networks for neural combinatorial optimization",
            "venue": "Adv. Neural Inf. Process. Syst., vol. 34, pp. 5138\u20135149, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S. Manchanda",
                "A. Mittal",
                "A. Dhawan",
                "S. Medya",
                "S. Ranu",
                "A. Singh"
            ],
            "title": "GCOMB: Learning budget-constrained combinatorial algorithms over billion-sized graphs",
            "venue": "Adv. Neural Inf. Process. Syst., vol. 33, pp. 20 000\u2013 20 011, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "C. Zhang",
                "W. Song",
                "Z. Cao",
                "J. Zhang",
                "P.S. Tan",
                "X. Chi"
            ],
            "title": "Learning to dispatch for job shop scheduling via deep reinforcement learning",
            "venue": "Adv. Neural Inf. Process. Syst., vol. 33, pp. 1621\u20131632, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J. Park",
                "J. Chun",
                "S.H. Kim",
                "Y. Kim",
                "J. Park"
            ],
            "title": "Learning to schedule job-shop problems: Representation and policy learning using graph neural network and reinforcement learning",
            "venue": "Int. J. Prod. Res., vol. 59, no. 11, pp. 3360\u20133377, 2021.",
            "year": 2021
        },
        {
            "authors": [
                "R. Chen",
                "W. Li",
                "H. Yang"
            ],
            "title": "A deep reinforcement learning framework based on an attention mechanism and disjunctive graph embedding for the job-shop scheduling problem",
            "venue": "IEEE Trans. Ind. Inf., vol. 19, no. 2, pp. 1322\u20131331, Apr. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "K. Lei",
                "P. Guo",
                "W. Zhao",
                "Y. Wang",
                "L. Qian",
                "X. Meng",
                "L. Tang"
            ],
            "title": "A multi-action deep reinforcement learning framework for flexible jobshop scheduling problem",
            "venue": "Expert Syst. Appl., vol. 205, p. 117796, Nov. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "W. Song",
                "X. Chen",
                "Q. Li",
                "Z. Cao"
            ],
            "title": "Flexible job-shop scheduling via graph neural network and deep reinforcement learning",
            "venue": "IEEE Trans. Industr. Inform., vol. 19, no. 2, pp. 1600\u20131610, Feb. 2023.",
            "year": 2023
        },
        {
            "authors": [
                "G. Huang",
                "Z. Liu",
                "G. Pleiss",
                "L. Van Der Maaten",
                "K.Q. Weinberger"
            ],
            "title": "Convolutional networks with dense connectivity",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, no. 12, pp. 8704\u20138716, May 2019.",
            "year": 2019
        },
        {
            "authors": [
                "P. Veli\u010dkovi\u0107",
                "G. Cucurull",
                "A. Casanova",
                "A. Romero",
                "P. Lio",
                "Y. Bengio"
            ],
            "title": "Graph attention networks",
            "venue": "Proc. Int. Conf. Learn. Represent., 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Schulman",
                "F. Wolski",
                "P. Dhariwal",
                "A. Radford",
                "O. Klimov"
            ],
            "title": "Proximal policy optimization algorithms",
            "venue": "arXiv:1707.06347, 2017.",
            "year": 2017
        },
        {
            "authors": [
                "J. Schulman",
                "P. Moritz",
                "S. Levine",
                "M. Jordan",
                "P. Abbeel"
            ],
            "title": "Highdimensional continuous control using generalized advantage estimation",
            "venue": "arXiv:1506.02438, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "J. Hurink",
                "B. Jurisch",
                "M. Thole"
            ],
            "title": "Tabu search for the job-shop scheduling problem with multi-purpose machines",
            "venue": "Oper. Res. Spektrum, vol. 15, pp. 205\u2013215, Dec. 1994.",
            "year": 1994
        },
        {
            "authors": [
                "D.P. Kingma",
                "J. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv:1412.6980, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "V. Sels",
                "N. Gheysen",
                "M. Vanhoucke"
            ],
            "title": "A comparison of priority rules for the job shop scheduling problem under different flow time-and tardiness-related objective functions",
            "venue": "Int. J. Prod. Res., vol. 50, no. 15, pp. 4255\u20134270, Aug. 2012.",
            "year": 2012
        },
        {
            "authors": [
                "D. Behnke",
                "M.J. Geiger"
            ],
            "title": "Test instances for the flexible job shop scheduling problem with work centers",
            "venue": "Arbeitspapier/Research Paper/Helmut-Schmidt-Universit\u00e4t, Lehrstuhl f\u00fcr Betriebswirtschaftslehre, insbes. Logistik-Management, 2012.",
            "year": 2012
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Flexible job-shop scheduling, self-attention mechanism, deep reinforcement learning, graph attention networks\nI. INTRODUCTION\nIndustry 4.0 is transforming the way companies manufacture, improve, and distribute their products, by moving towards rapid, intelligent, and flexible manufacturing, which leads to a fundamental change in production capabilities of enterprises [1], [2]. The flexible job-shop scheduling problem (FJSP) is a classic problem that represents the typical scenarios faced by flexible manufacturing. FJSP has gained increasing attention in diverse fields, such as cyber-physical manufacturing [3], cloud\nThe work was supported in part by the National Key R&D Program of China under Grant 2021YFB1714800, in part by the National Natural Science Foundation of China under Grants 62173034, 61925303, 62025301, 62088101, in part by the CAAI-Huawei MindSpore Open Fund, and in part by the Chongqing Natural Science Foundation under Grant 2021ZX4100027. (Corresponding author: Jian Sun.)\nR. Wang, G. Wang, J. Sun, and F. Deng are with the National Key Lab of Autonomous Intelligent Unmanned Systems, School of Automation, Beijing Institute of Technology, Beijing 100081, China, and the Beijing Institute of Technology Chongqing Innovation Center, Chongqing 401120, China (email: rqwang@bit.edu.cn; gangwang@bit.edu.cn; sunjian@bit.edu.cn; dengfang@bit.edu.cn).\nJ. Chen is with the Department of Control Science and Engineering, Tongji University, Shanghai 201804, China, and the National Key Lab of Autonomous Intelligent Unmanned Systems, Beijing Institute of Technology, Beijing 100081, China (e-mail: chenjie@bit.edu.cn).\ncomputing [4], and intelligent transportation [5]. The jobshop scheduling problem (JSP), which is a simpler and easier instance of FJSP, is also a core issue in the manufacturing industry [6]. JSP involves a set of jobs and machines, where each job consists of multiple operations that must be processed on a given machine in a pre-defined order. The goal is to generate a processing sequence of operations that achieves a meaningful production goal, such as minimum completion time, lateness/tardiness, or production cost. Compared to JSP, FJSP is a more challenging problem as it allows each operation to be processed on multiple different machines.In addition to the operation sequencing problem in JSP, the machine assignment problem adds further manufacturing flexibility, rendering FJSP a more complex topology and a much larger solution space.\nIn fact, it has been shown that FJSP is a strongly NPhard problem [7]. The combinatorial nature of FJSP makes it challenging to find (near-)optimal solutions using traditional operation research methods such as constraint programming [8]. These methods have intractable computation costs that increase dramatically with the problem size, making them impractical for large-scale applications [9]. To strike a balance between the solution quality and the computation cost, research in the field has gradually shifted from traditional heuristic and meta-heuristic methods to intelligent methods such as deep learning [6] and particularly deep reinforcement learning (DRL) [10].\nMeta-heuristics, including genetic algorithms [11], [12], particle swarm optimization [13], differential evolution [14], and artificial bee colony [15], have been widely employed for scheduling problems, and they often find high-quality solutions by means of a complex solution search procedure. In contrast, rule-based heuristics, such as priority dispatching rules (PDRs), are more practical due to their ease of implementation and high efficiency [16]. PDRs repeatedly select the operation or machine with the highest priority based on some prescribed rules until a complete plan is generated. Nonetheless, designing effective PDRs often requires significant expertise and research effort, and they may only perform well in specific tasks.\nDRL methods have emerged as promising approaches to solve JSP and FJSP [17], which model the scheduling process as a Markov decision process (MDP). In these methods, a parameterized neural network model is designed to receive information about the production environment as state and output the priority of each feasible scheduling action, such as assigning an operation to a machine, forming an end-to-end\nar X\niv :2\n30 5.\n05 11\n9v 2\n[ cs\n.L G\n] 1\n7 Ju\nn 20\n23\n2 learning approach [18]. Through training on a set of production process data, the DRL model learns to adaptively select the best action at a state to maximize the total reward, which is related to the production goal. However, the effectiveness and efficiency of these methods heavily depend on the design of the state representation, which is a challenging task. As the problem size increases, the amount of production information grows significantly. Therefore, representing this information and complex constraints in the scheduling environment in a sufficiently and minimally expressive manner poses key challenges for designing the state representation. However, the trained DRL-based model is expected to be capable of solving problems of different sizes based on a single unifying architecture. Additionally, the structural information of the problem, which comprises diverse sets of constraints, also plays a critical role in making JSP and FJSP challenging. The priority of operations or machines is strongly related to these constraints, making it essential for the model to appropriately express and exploit them.\nSeveral attempts have been made to address these challenges. One approach is to use aggregated features of operations or machines, such as average machine workload, to represent the production state instead of separately representing each operation or machine, to achieve a uniform representation for problems of varying sizes. For example, this approach is used in [19] to characterize the production status of dynamic partial-no-wait FJSP. They designed 20 extracted features as the state and developed a hierarchical DRL-based framework to learn from these features and choose rules from a set of PDRs for the operation and machine selection independently. Similarly, in [20], a similar approach for state representation is used to describe FJSP with crane transportation and setup times, and a non-fully connected deep Q-network was employed for selecting compound rules to solve this problem. Although this state representation approach is generic for various production scenarios, such as FJSP with additional production constraints, and simplifies the depiction of FJSP, it compresses the information about the production state and makes little use of the structural information.\nAlternatively, the well-known disjunctive graph [21] has been widely used in many studies to represent the state of (F)JSP. This graph-based model represents operations as nodes and uses directed edges between nodes to indicate the processing order of operations, allowing it to describe features of each operation and represent the structural information of (F)JSP. Recent research has shown promising results in leveraging representation learning methods such as graph neural networks (GNNs) and self-attention mechanisms [22] to handle combinatorial optimization problems with complicated constraints, as these methods have the ability to capture the inherent structure of the problem and are size-agnostic.\nIntegration of these methods with DRL has been explored in various domains such as vehicle routing [23], [24], chip design [25], and production scheduling [26], and has demonstrated success in solving extremely large-scale problems [27]. In the domain of JSP, for example, a learning framework that incorporates GNN and DRL was proposed in [28] for generating the priority of operations at each step of the scheduling process\nusing a sparse graph as the state representation. Similarly, the work of [29] incorporated dynamic attributes in node features and designed a customized GNN for message passing to learn operation embeddings. In [30], graph embedding techniques were utilized to extract features of the disjunctive graph for downstream decision-making, and an attention-based model was proposed to generate solutions for JSP.\nRecent works have extended these solutions to handle FJSP by considering additionally machine features and improving decision-making models to handle both operation sequencing and machine assignment. For instance, the work of [31] introduced a two-step decision-making framework that uses a disjunctive graph for learning operation embeddings and a multi-layer perceptron (MLP) for passing machine messages. However, this approach may result in limited exploration during training since the priority of machines is only computed for the selected operation. On the other hand, [32] designed a heterogeneous graph that considers operations and machines as heterogeneous nodes and connects each machine to operations that it can process. They proposed a two-stage GNN for learning machine and operation embeddings and a decision-making model for selecting operations and machines simultaneously.\nIn general, albeit these DRL-based solutions yield better performance than traditional PDRs, some challenging problems still remain to be tackled for further improving the model\u2019s performance and narrowing the gap with exact methods. First, a more precise state representation is required which avoids to incorporate information that are irrelevant to decision-making. For instances, completed operations have no contributions to subsequent decision-making at a specific scheduling step, for they will not affect the production status. However, existing methods consider all operations at each step, which may affect the performance and also reduce the efficiency [33]. Second, diverse relationships between operations and machines require to be represented and exploited more rationally. Although existing methods have considered the operation-operation or operation-machine relationships, they have not modeled the relationship between machines yet. The relationship between machines can be viewed as the competition for remaining unscheduled operations which is crucial for discriminating high-priority machines.\nIn response to these challenges, we propose a novel end-toend learning framework for standard FJSP aiming to minimize the completion time. First, a tight state representation is introduced in the MDP formulation, which incorporates relevant information about decision-relevant operations and machines. Second, a dual attention network, comprising several operation and machine message attention blocks, is proposed to express the complicated relationships of operations and machines concisely. The operation message attention blocks learn to extract operation features by simply exploiting their precedence constraints, and the machine message attention blocks leverage the competitive relationships between machines to extract machine features. Finally, a size-agnostic decisionmaking framework is designed to simultaneously address the two critical subproblems in FJSP: operation sequencing and machine assignment. Experiment results show that our approach outperforms traditional PDRs and the state-of-the-\n3 art DRL method by a considerable margin on two synthetic data with different distributions. The performance is even comparable to exact methods (with time limits) on some tasks. Moreover, it exhibits favorable generalization ability, as models trained on small-scale instances achieve high-quality solutions when directly applied to solve large-scale or out-ofdistribution instances.\nThe contributions of this work are summarized as follows. \u2022 A tight state representation for describing operations\nand machines in FJSP that is minimal and sufficient for downstream decision-making with the state space decreasing as scheduling proceeds; \u2022 A dual-attention network consisting of several operation and machine message attention blocks for deep feature extraction of operations and machines; and, \u2022 A size-agnostic DRL-based approach with (markedly) improved performance and generalization capability compared to conventional PDRs and the state-of-the-art DRL method.\nThe remainder of the paper is structured as below. Section II introduces the necessary basics and the FJSP. Section III provides the detailed formulation of the proposed method. Section IV reports the experimental results with Section V concluding the paper."
        },
        {
            "heading": "II. PRELIMINARIES AND PROBLEM FORMULATION",
            "text": ""
        },
        {
            "heading": "A. Flexible job-shop scheduling problem and disjunctive graph",
            "text": "The FJSP can be formally stated as follows. Consider a set of n jobs and m machines, represented by J and M, respectively. We assume that all jobs arrive simultaneously at system production time Ts = 0. Each job Ji \u2208 J consists of ni operations which must be assembled in a specific order (i.e. precedence constraints) described by Oi = {Oi1, Oi2, . . . , Oini}. The set of all operations across all jobs is denoted by O = \u22c3 iOi. Each operation Oij can be processable by multiple machines, but can only be processed on a single machine from the set of available and compatible machines Mij \u2286 M. The associated processing time on machine Mk \u2208 Mij is given by pkij > 0. FJSP seeks to design a schedule that determines for each operation an appropriate processing machine and the start time while respecting the following constraints: c1) the operations of Ji must be processed in the order in Oi (i.e. precedence constraints); c2) each operation must be assigned to exactly one compatible machine; and c3) each machine can process at most an operation at a time. The goal of FJSP is to minimize the maximum completion time of all jobs; that is, minimizing the total makespan.\nThe disjunctive graph is a well-documented technique for representing the scheduling problems such as JSP and FJSP. In FJSP, a disjunctive graph G can be described by a tuple (V = O\u222a {Start, End}, C,D), see Fig. 1. The node set V is composed of all operations (i.e., nodes) and two dummy nodes (signifying the start and completion of production). The edge set C = {\u27e8Oij , Oi,j+1\u27e9|1 \u2264 i \u2264 |J |, 1 \u2264 j < ni} comprises all directed edges called conjunctions, which models constraint\n\ud835\udc4211\n\ud835\udc46\n\ud835\udc4212 \ud835\udc4213\n\ud835\udc4221\n\ud835\udc4231 \ud835\udc4233\n\ud835\udc4222\n\ud835\udc4232\n\ud835\udc47\n\ud835\udc401 \ud835\udc402 \ud835\udc403\n(a) An FJSP instance\n\ud835\udc4211\n\ud835\udc46\n\ud835\udc4212 \ud835\udc4213\n\ud835\udc4221\n\ud835\udc4231 \ud835\udc4233\n\ud835\udc4222\n\ud835\udc4232\n\ud835\udc47\n\ud835\udc401 \ud835\udc402 \ud835\udc403\n(b) A possible solution\nFig. 1: The disjunctive graph for FJSP.\nc1) above; and D is the set of undirected edges or disjunctions, which consists of m groups, denoted by D1, ...,Dm, respectively. Disjunctions in group Dk connect operations that machine Mk can process. Consequently, an operation can be linked to disjunctions in different groups according to their flexibility. A solution to FJSP can be obtained by updating these disjunctions. Once an operation Oij is scheduled to be processed on a machine Mk, all disjunctions linked to Oij except for the ones in Dk are then deleted. Meanwhile, disjunctions that link scheduled operations are converted into directed edges, whose direction indicates the processing sequence of operations on corresponding machines. As a result, the disjunctive graph becomes a directed acyclic graph when scheduling is completed."
        },
        {
            "heading": "B. Graph attention network",
            "text": "Graph attention networks (GATs) [34] are one of the most popular and effective architectures in the field of GNNs. The graph attention layer (GAL) is the core block of GATs which uses attention mechanisms to aggregate neighboring information and compute node embeddings. Roughly speaking, a GAL accepts as input a graph with a set H = {h\u20d7i \u2208 RF }Ni=1 of nodal feature vectors and outputs for each node a new feature vector h\u20d7\u2032i \u2208 RF \u2032 .\nLetting Ni collect the first-hop neighbors of node i (including node i itself), a GAL first computes the attention coefficients eij for each node i and j \u2208 Ni as follows\neij = LeakyReLU ( a\u20d7\u22a4 [ (Wh\u20d7i)\u2225(Wh\u20d7j) ]) (1)\nwhere W \u2208 RF \u2032\u00d7F is a linear transformation shared by all nodes, the operation [\u00b7\u2225\u00b7] concatenates two vectors to form a larger vector, and a\u20d7 \u2208 R2F \u2032\u00d71 is the weight vector of a singlelayer neural network with a LeakyReLU(\u00b7) activation function.\n4 These attention coefficients are further normalized using the softmax function as follows\n\u03b1ij = softmaxj(eij) = exp(eij)\u2211\nk\u2208Ni exp(eik) , \u2200i. (2)\nFinally, the weighted sum of transformed neighboring features using the normalized attention coefficients is computed, which is then fed into a nonlinear activation function \u03c3 : R \u2192 R (e.g., the exponential linear unit or ELU) to yield a new feature vector\nh\u20d7\u2032i = \u03c3 ( \u2211 j\u2208Ni \u03b1ijWh\u20d7j ) , \u2200i. (3)\nA GAT can have multiple GALs connected one by one forward similar to feedforward neural networks. The node embeddings at the last layer are employed in downstream tasks."
        },
        {
            "heading": "III. THE PROPOSED METHOD",
            "text": "In this section, we present our main results including the MDP formulation and a new end-to-end approach for standard FJSP. To this aim, we first formulate FJSP as a Markov decision process by defining its states, actions, state transitions, and rewards. Then, we introduce the proposed learning approach for FJSP, which is termed Dual Attention Network based reInforcEment Learning and DANIEL for short. It builds on GAT-style self-attention mechanisms and deep reinforcement learning. The workflow of the proposed method is depicted in Fig. 2. Specifically, our framework consists of i) a dual attention network for deep feature extraction of and between operations and machines; and, ii) a DRL-based decision-making network that considers operation-selection and machine-selection as a whole and outputs a probability distribution prioritizing available operation-machine pairs. At last, we demonstrate how to train the proposed model."
        },
        {
            "heading": "A. MDP formulation of FJSP",
            "text": "The scheduling process can be understood as dynamically assigning a ready operation to a compatible and idle machine. In this way, the decision point t is the production system time Ts(t) when there is at least a compatible operation-machine pair (Oij ,Mk) such that Oij can be processed on machine Mk at time Ts(t). At step t, the DRL model receives a state st from the environment and takes an action at that assigns a compatible pair to start processing immediately at time Ts(t), for which the FJSP environment returns a reward rt related to the makespan. A solution of FJSP can be obtained by repeating this procedure |O| times for the entire set of operations in the task. The MDP is defined as follows.\nState. We propose a tight state representation that sufficiently characterizes the operations and machines relevant to decision-making. Specifically, the operations can be categorized into three groups according to their status at the time, namely, completed operations, being processed operations, and unscheduled operations. Since the decision at step t only depends on the production status at system time Ts(t), all operations, except for the completed ones which will not affect subsequent scheduling, are referred to as relevant operations.\nLikewise, the machines that cannot process any of the remaining unscheduled operations are also termed irrelevant to subsequent scheduling. Therefore, information about irrelevant operations and machines are not meaningful for scheduling and will not be recorded in the state. Let Ou(t) andMu(t) be the set of relevant operations and machines at step t, and A(t) the set of compatible operation-machine pairs. The state st is a set of feature vectors, including hOij \u2208 R10 for each operation Oij \u2208 Ou(t), hMk \u2208 R8 for each machine Mk \u2208 Mu(t), and h(Oij ,Mk) \u2208 R8 for each compatible operation-machine pair (Oij ,Mk) \u2208 A(t). They are carefully handcrafted to provide a minimal yet sufficient description about the static and dynamic properties of scheduling-relevant entities; see the appendix for more details. It is worth stressing that, different from existing works, the state space gets smaller as the production/scheduling proceeds (until it becomes empty meaning that all operations have been scheduled and processing ends), making the representation computationally appealing for realtime and large-scale applications.\nAction. The set A(t) of all compatible operation-machine pairs defines the action space at step t, which becomes smaller as more operations get scheduled for processing across time. We also refer to the operations in A(t) as the candidates, all of which form the candidate set Jc(t).\nState transition. An action at corresponds to the processing of an operation on a machine. Upon taking the action, the environment (i.e., the production status of all operations and machines) changes. Then, the sets Ou(t),Mu(t) and A(t) as well as features of relevant entities are updated, and a new state st+1 is obtained.\nReward. The reward rt should be designed to guide the agent to choose actions that are helpful in reducing the maximum completion time of all operations in the task, namely the makespan, denoted by Cmax. Inspired by the design in [28], we estimate a lower bound of the completion time C(Oij , st) for each operation Oij at step t. If Oij has been scheduled, the value equals to its actual completion time Cij which is accurately known and can be computed. For all unscheduled operations, the lower bound can be approximated by iteratively running the recursion C(Oij , st) = C(Oi(j\u22121), st)+ min\nk\u2208Mij pkij\nassuming without loss of generality that C(Oi,0) = 0. The estimated maximum completion time max\nOij\u2208O C(Oij , st) over all\noperations can naturally be used as a measure of the makespan at step t. The reward rt is defined as the difference between\n5 \u00d7L\nFilte r\nConcat/Averaging\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\nLinear & Group\nConcat & Linear\nMask\nSoftMax\nCombination\nConcat/Averaging\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\nLinear\nConcat & Linear\nSoftMax\nCombination\nLin e a r\nOperation input features A group of an operation, its predecessor (left), and its successor (right) Operation output features Machine input features Machine output features O p e ra ti o n M e ss a g e A tt e n ti o n B lo ck M a ch in e M e ssa g e A tte n tio n B lo ck\nFig. 3: The architecture of the dual attention network (DAN).\nthe estimated makespan values at step t and t+ 1\nrt = max Oij\u2208O C(Oij , st)\u2212 max Oij\u2208O C(Oij , st+1). (4)\nWhen the discounting factor \u03b3 = 1, one can obtain the cumulative reward \u2211|O|\u22121 t=0 rt = maxOij\u2208O\nC(Oij , s0) \u2212 Cmax. In this way, maximizing the cumulative reward is equivalent to minimizing the makespan.\nPolicy. We employ a stochastic policy \u03c0(at|st) whose distribution is generated by an DRL algorithm (an actorcritic network in our simulations) with trainable parameters \u0398. Given a state st, this distribution returns the probability of choosing each action at \u2208 A(t)."
        },
        {
            "heading": "B. Dual attention network",
            "text": "Self-attention models can relate elements of input sequences and find the significant ones by exploiting their relationships, which are suitable for finding high priority operations and/or machines. In addition, self-attention models can handle length-varying sequences (as inputs), which is welltailored for solving FJSP instances across different scales. These considerations have motivated us to use self-attention models to extract features for operations and machines. The disjunctive graph of FJSP shows that there are multiple types of connections among operations, such as conjunctions and multiple groups of disjunctions. Each type can be seen as a kind of relationship. Therefore, it is inappropriate to relate all operations through a uniform attention model. Moreover, the competitive relationship between machines is not explicitly explored in a disjunctive graph, but it is intuitive that they are crucial for modeling the priority of machines.\nTo bypass these drawbacks, this paper proposes the dual attention network (DAN), an attention-based model for feature extraction of and between operations and machines in\nFJSP. The overall framework of DAN is shown in Fig. 3. DAN decomposes the complex relationships of operations and machines into two parts and handles them separately using two different attention blocks, which are called operation message attention block and machine message attention block, respectively. The former receives operation features as input and simply relates them through precedence constraints. The latter explicitly models the dynamic competitive relationships between machines, which handles the production state of each machine as well as its processing eligibility of the unscheduled operations. The connected two blocks altogether constitute a dual attention layer. Features of operations and machines are refined through L layers in turn, which exhibit similar structures but with a different number of attention heads and parameters. Let \u03c9 collect all the parameters of DAN. Details for updating the l-th layer\u2019s parameters at step t are given as below. In the following, the subscripts t and l are omitted when clear from context.\n1) Operation message attention block. This block aims to relate operations in the same job so as to find the most significant operations via their inherent properties. Concretely, for each Oij \u2208 Ou with input features hOij \u2208 Rdo , this block models the relationships between Oij , its predecessor Oi,j\u22121, and its successor Oi,j+1 (if it exists), by computing their attention coefficients as follows\nei,j,p = LeakyReLU ( a\u20d7\u22a4 [ (WhOij )\u2225(WhOip) ]) (5)\nwhere a\u20d7\u22a4 \u2208 R2d\u2032o and W \u2208 Rd\u2032o\u00d7do are linear transformations and for all |p\u2212 j| \u2264 1.\nNote that the computations are similar to those in GAT, but we have narrowed its scope. Due to the fact that the predecessor (or successor) of some operations may not exist or will be removed at some step, a dynamic mask on the attention coefficients of these predecessors and successors is performed. A softmax function is employed to normalize all ei,j,p across choices of p, obtaining normalized attention coefficients \u03b1i,j,p. Finally, the output feature vector h\u2032Oij \u2208 R\nd\u2032o is obtained by a weighted linear combination of transformed input features WhOi,j\u22121 , WhOi,j and WhOi,j+1 followed by a nonlinear activation function \u03c3:\nh\u2032Oij = \u03c3 ( j+1\u2211\np=j\u22121 \u03b1i,j,pWhOip\n) (6)\nBy connecting multiple operation message attention blocks one by one, the messages of Oij can be propagated to all operations in Ji.\n2) Machine message attention block. Two machines compete for the unscheduled operations that they can both process. This competitive relationship may change dynamically as production proceeds. We define Ckq as the set of operations that machines Mk and Mq compete for. Let Nk = {q | Ckq \u0338= \u2205} denote the set of competing machines with Mk. Additionally, we employ ckq = \u2211 Oij\u2208Ckq\u2229Jc hOij as a measure of the intensity of competition between Mk and Mq , which makes sense as the competition becomes more severe when their competed candidates are more important. The machine message attention block leverages ckq to compute the attention\n6 coefficients ukq (The \u2019filter\u2019 operator in Fig. 3 is used for obtaining ckq for each Mk and Mq). For each Mk \u2208 Mu with input features hMk \u2208 Rdm , the attention coefficients ukq for all q \u2208 Nk are computed as follows\nukq = LeakyReLU ( b\u20d7\u22a4 [ (Z1hMk)\u2225(Z1hMq )\u2225(Z2ckq) ]) (7)\nwhere Z1 \u2208 Rd\u2032m\u00d7dm and Z2 \u2208 Rd\u2032m\u00d7do are weight matrices and b\u20d7\u22a4 \u2208 R3d\u2032m is a linear transformation.\nNote that Ckk is the set of unscheduled operations that Mk can process and k is always in Nk. Therefore, (7) can be applied to compute ukk, for ckk can be seen as a measure of the processing capacity of Mk. When Ckq \u2229 Jc is empty, we fill ckq by zeros. Then, analogous softmax normalization (across choices of q), combination, and activation steps are conducted to obtain the output features h\u2032Mk \u2208 R\nd\u2032m . 3) Multi-head attention. We apply multiple attention heads to both blocks for the purpose of learning a variety of relationships between entities. This technique has been shown effective in strengthening the learning ability of attention models [22]. We specify its use in the operation message attention block, which is the same for the machine message attention block and thus omitted for brevity. Let H be the number of attention heads in a dual attention layer and H attention mechanisms with different parameters are applied. First, the computation of attention coefficients and the combination are performed in parallel. Then, their outputs are fed into an aggregation operator for integration. Adopted from GAT, the aggregation operator refers to a concatenation except for the last layer which uses an averaging operator. Finally, the activation function \u03c3 is applied to obtain the layer\u2019s output.\n4) Pooling. Let the raw (handcrafted) features of operation Oij and machine Mk denoted by h (0) Oij and h(0)Mk , respectively. Upon passing h(0)Oij and h (0) Mk through L dual attention layers, the learned features h(L)Oij and h (L) Mk\nare ready for downstream decision-making tasks. Similar to [24], we first apply an averaging pooling to the operation features and machine features separately, whose results are concatenated to form the global features of an FJSP instance; that is,\nh (L) G = [( 1 |Ou| \u2211 Oij\u2208Ou h (L) Oij )\u2225\u2225\u2225( 1|Mu| \u2211 Mk\u2208Mu h (L) Mk )] . (8)\n5) Analysis. Compared with the prior art [31], [32], our method has advantages in the following aspects. First, we model the time-varying competition between machines explicitly use and rely on this relationship to construct machine features. On top of this, we employ the sum of processable candidate features to represent the intensity of competition and consider its influence on the machine\u2019s priority. Moreover, our design incurs a much smaller computational overhead, since the learning process can be understood as handling two (much) smaller graphs, one for operations and the other for machines. The graph for operations can be seen as a modified disjunctive graph with the node set Ou(t), where conjunctions are maintained but replaced by undirected edges and disjunctions are removed. The graph for machines is used for describing information incorporated in disjunctions,\nwhich takes compatible machines as nodes and characterizes their competitions by means of incorporating dynamic edge features. Such a representation features simplicity as well as intuition, for the complex connections have been grouped into two categories with O(3|O|+|M|2) connections in total. Since |O| is often much larger than |M| in practice, the number of connections is significantly reduced relative to existing disjunctive graph based results in [31], [32]. Last but not the least, irrelevant operations and machines get removed as scheduling proceeds, contributing to a decreasing state space and bringing computational efficiency."
        },
        {
            "heading": "C. Decision-making module",
            "text": "We design the decision-making network based on actorcritic RL which maintains the size-agnostic property of attention models. Two MLPs are used as the actor and critic, whose parameters are denoted by \u03b8 and \u03d5, respectively. The actor network aims to generate a stochastic policy \u03c0\u03b8(at|st) in two steps: it first produces a scalar \u00b5(at|st) for each at \u2208 A(t) and uses the softmax function to output the desired distribution. We concatenate all information related to at = (Oij ,Mk) (including the extracted features of Oij and Mk, the global features, and the compatible operation-machine pair features) in a single vector which is subsequently fed into MLP\u03b8 to yield\n\u00b5(at|st) = MLP\u03b8 [ h (L) Oij \u2225\u2225h(L)Mk\u2225\u2225h(L)G \u2225\u2225h(Oij ,Mk)]. (9) Then, the probability of choosing action at is given by\n\u03c0\u03b8 (at | st) = exp(\u00b5(at|st))\u2211\nbt\u2208A(t) exp(\u00b5(bt|st)) . (10)\nThe critic network is an estimator that takes the global features h(L)G as input to produce a scalar v\u03d5(st), as an estimate of the state value."
        },
        {
            "heading": "D. Training procedure",
            "text": "We employ the proximal policy optimization (PPO) algorithm [35] to train the proposed scheduling model. The generalized advantage estimation (GAE) technique [36] is utilized to stabilize training. The training procedure is summarized in Algorithm 1. We train the model using Nep episodes. For each episode nep, the agent interacts with a batch of same-scale FJSP environments Etr in parallel and collects the transition data, which are used for updating the model parameters \u0398. The environments are resampled every Nr episodes, according to a fixed distribution. The policy is validated on some fixed validation data Eval (with the same distribution as the training data) every Nval episodes. Two strategies for the action-selection are considered in our experiments. One is a greedy strategy that always chooses the action with the highest probability \u00b5(at|st), used in validation. The other is an actionsampling strategy, i.e., sampling an action from the distribution \u03c0\u03b8, used during training for sufficient exploration.\n7 Algorithm 1 Training DANIEL for FJSP 1: Input: A dual attention network with initial parameters\n\u0398 = {\u03c9, \u03b8, \u03d5}, behavior actor network \u03b8old, pre-sampled training data Etr, and fixed validation data Eval;\n2: for nep = 1, 2, ..., Nep do 3: \u03b8old \u2190 \u03b8 4: for i = 1, 2, ..., |Etr| do 5: for t = 0, 1, ..., T do 6: Sample ai,t using \u03c0\u03b8old(\u00b7 | si,t); 7: Receive the reward ri,t and the new state si,t+1; 8: Collect the transition (si,t, ai,t, ri,t, si,t+1); 9: Update si,t \u2190 si,t+1;\n10: end for 11: Compute the generalized advantage estimates A\u0302i,t for t = 0, 1, ..., T using collected transitions; 12: end for 13: for k = 1, 2, ...,K do 14: Compute the total loss \u2211|Etr| i=1 \u2113 PPO i (\u0398); 15: Update all parameters \u0398; 16: end for 17: if Every Nr episodes then 18: Resample |Etr| instances to form the training data; 19: end if 20: if Every Nval episodes then 21: Validate \u03c0\u03b8 on Eval; 22: end if 23: end for"
        },
        {
            "heading": "IV. EXPERIMENTS",
            "text": "We numerically compare the proposed DANIEL algorithm with several baselines including several popular PDRs, the exact method Google OR-Tools 1, a genetic algorithm [12], and the DRL-based method [32] in this section. Both synthetically generated instances as well as popularly used FJSP benchmarks are used to verify its effectiveness in scheduling performance, generalization capability, and computational efficiency."
        },
        {
            "heading": "A. Datasets",
            "text": "An FJSP instance with n jobs and m machines is denoted as \u201cn\u00d7m\u201d in short hereafter (the number of operations varies in different instances). We consider two types of synthetic data with distinct distributions to examine the learning as well as generalization performance of the proposed DANIEL algorithm.\nThe first is adapted from [32], which allows jobs to have a varying number of operations, denoted by SD1 in the Table. We refer interested readers to the original text [32] for details. The second is a task with a wider range for the random processing time of operations, denoted by SD2 in the Table below. Specifically, for an n \u00d7 m FJSP instance generated for SD2, each job has m operations. For each Oij , the values |Mij | and pkij are integers sampled from U(1,m) and U(1, 99), respectively. For a fair comparison with the\n1https://developers.google.cn/optimization\napproach in [32], we consider six different scales of FJSP instances using the two data: 10\u00d75, 20\u00d75, 15\u00d710, 20\u00d710, 30\u00d710, and 40\u00d710. We train our model on four smaller sizes of each data with randomly generated instances (8 models in total), while testing is performed on two extra larger ones in addition to those. Both the testing data (unseen) and the validation data are generated in advance each having 100 instances. Furthermore, we evaluate the trained models on four groups of public benchmarks to explore their capabilities on cross-distribution tasks, including mk1-10 instances in [21] and 3 groups of la1-40 instances (except sdata) in [37].\nB. Configurations\nThe training configurations were kept the same as in [32] for comparison, with Nep = 1, 000, |Etr|, Nr = 20, and Nval = 10. Hyperparameters of algorithms were tuned on SD2 instances of size 10\u00d75 and kept the same for all 8 models. For a trade-off between performance and computational efficiency, our DAN used L = 2 dual attention layers and each block used H = 4 attention heads per layer with ELU as activation function \u03c3. The output dimensions of each attention head in the two blocks are d(1)o = d (1) m = 32 for the first layer and d(2)o = d (2) m = 8 for the second layer. Both MLP\u03b8 and MLP\u03d5 have two hidden layers of dimension 64 with tanh as activation. For the PPO parameters, the policy, value, and entropy coefficient in the loss funciton were set to be 1, 0.5, and 0.01. The clipping parameter \u03f5, GAE parameter \u03bb, and discounting factor \u03b3 were set to be 0.2, 0.98, and 1, respectively. During training, we updated the network for K = 4 epochs per episode via the Adam optimizer [38] with the learning rate lr = 3\u00d7 10\u22124. All experiments were carried out on a machine with an Intel Xeon Platinum 8163 CPU and a single NVIDIA Tesla T4 GPU. The code is available. 2"
        },
        {
            "heading": "C. Baselines and performance metrics",
            "text": "First, we selected four PDRs for operation sequencing that have been shown to yield good performance in [39], and generalized them to solve FJSP. In the experiments, we reported the results averaged over 5 independent runs for each PDR due to their stochastic nature. Specifics regarding the implementation are stated as follows.\n\u2022 First in first out (FIFO): selecting the earliest ready candidate operation and the earliest ready compatible machine. \u2022 Most operations remaining (MOPNR): selecting the candidate operation with the most remaining successors and a machine which can immediately process it. \u2022 Shortest processing time (SPT): selecting the compatible operation-machine pair with the shortest processing time. \u2022 Most work remaining (MWKR): selecting the candidate operation with the most remaining successor average processing time and a machine which can immediately process it.\nSecond, the results from OR-Tools and an advanced genetic algorithm were chosen as a reference line for time-consuming\n2https://github.com/wrqccc/FJSP-DRL\n8\nbut high-performance methods. As an authoritative constrained programming solver, OR-Tools was employed to generate (near-)optimal solutions with 1, 800 seconds set as the time limit. In [12], a two-stage genetic algorithm (2SGA) was designed to solve FJSP with improved performance and efficiency than regular genetic algorithms, whose results on two groups of benchmarks were directly imported due to lack of open-source implementations. Last but not the least, we compared DANIEL with the state-of-the-art DRL method recently proposed in [32]. We used their open-source code 3 to perform training and testing following their default settings. We directly imported their results on SD1, including the trained models and validation instances of four smaller sizes as well as testing instances of all six sizes. We reported the results of DANIEL and DRL for both greedy and sampling-based action-selection strategies in testing as done in [32]. Specifically, the sampling strategy uses action-sampling to solve an instance for 100 times in parallel and records the best one, to improve the solution quality at the price of an acceptable computation burden. Model\u2019s performance was evaluated in terms of the average makespan as well as the relative gap between its makespan and the best-known solution, which is either the solution of OR-Tools for synthetic instances or the best result reported in [40] for public benchmarks. In our experiments, performance of the two strategies was compared separately and the best results for the DRL-based methods and PDRs are\n3https://github.com/songwenas12/fjsp-drl\nemphasized in bold for each problem."
        },
        {
            "heading": "D. Results on synthetic data",
            "text": "In Table I, we reported each model\u2019s average makespan and gap on testing instances which are generated from the same scales using the same distribution as its training instances. It is clear from the bold numbers that, for both data across all problem sizes, DANIEL not only outperforms all PDRs by a significant margin, but also exhibits a notable improvement\n9\nrelative to the DRL solution in [32] for both action-selection strategies. Moreover, the optimality gap of DANIEL is less than 5% in three tasks when using the sampling strategy. Most excitingly, DANIEL even beats OR-Tools by 1.03% on the 20 \u00d7 10 FJSP instances on SD1 data, while all instances in this data weren\u2019t solved optimally by OR-Tools within the time limits. The advantage of DANIEL becomes more pronounced on SD2 data. When the processing time range gets larger, performance of both PDRs and the DRL [32] are affected, resulting in a considerable gap to the best solution. In this case, DANIEL still performs well, especially when using the sampling strategy. By means of the proposed tight state representation, DANIEL has runtime comparable to PDRs and is computationally efficient in general. Its runtime is close to that of [32], although implementations of the simulation environment of FJSP in the two algorithms are different. Another interesting phenomenon from the results of PDRs is that SPT consistently performs the worst for all problem sizes on SD1 data but performs the best for all sizes on SD2, demonstrating its unstable performance over varying tasks. This may be caused by the very different processing time ranges, since a compatible operation-machine pair with the shortest processing time may have a high priority on SD2 but a low priority on SD1 data. The training curves of DANIEL and DRL [32] on 10 \u00d7 5 and 20\u00d7 10 FJSP instances using SD1 and SD2 are presented in Fig. 4, where the averaged makespan over 100 validation instances are shown. It is worth mentioning that our method and [32] used the same training data, validation frequency, and validation data. It can be observed that our method converges to a better solution more smoothly for both data, corroborating its powerful and stable performance. Furthermore, we examined the generalization performance of the models trained over 10 \u00d7 5 and 20 \u00d7 10 tasks on two data using 30\u00d7 10 and 40\u00d7 10 testing instances, respectively. DANIEL was compared with [32] and the best PDRs in SD1 and SD2. As shown in Table II, DANIEL consistently generates high-quality solutions for large-scale problems with acceptable computation cost, which are considerably better than all baseline methods and occasionally beat OR-Tools.\n10\nEspecially for the 40\u00d7 10 FJSP instances on SD1, the model trained on 20 \u00d7 10 instances with the sampling strategy outperforms OR-Tools by 6.60%. These results show that DANIEL can learn general knowledge by training on smallscale tasks, which can be employed to solve unseen large-scale instances. Note that the model trained on 20\u00d710 consistently outperforms that trained on 10\u00d75 instances, which is expected because its size is closer to that of the testing data."
        },
        {
            "heading": "E. Results on benchmarks",
            "text": "Cross-distribution application is critical for a model in practical use, as real-world problems may come from unknown distributions. Therefore, we further explore the performance of models (trained on synthetic data) on four groups public benchmarks whose distributions are completely different from the training instances. Each benchmark comprises instances having different problem sizes. For example, the number of jobs and machines in the mk benchmark ranges from 10 to 20 and from 5 to 15, respectively. We selected the models trained on 10 \u00d7 5 and 15 \u00d7 10 using SD1 data for testing, which achieved the best results on these benchmarks in [32]. The results of MWKR (the best among the four PDRs), the OR-Tools, the GA baseline in [12], and the models of [32] (with greedy and sampling strategies) trained on the same data are presented in Table III. It can be seen that both OR-Tools and 2SGA are generally far ahead in performance but take quite a long time for computations. In contrast, the two DRL methods achieve good performance which is better than the best PDR with acceptable runtime. Again, DANIEL surpasses [32] in most cases and exhibits comparable performance in the remaining ones (the testing of greedy strategy on la (rdata) and sampling strategy on la (edata), where the difference is less than 0.6%). Particularly, DANIEL outperforms [32] by a big margin for both action-selection strategies on mk instances. These results showcase that DANIEL can genuinely capture the inherent structural information of FJSP and discriminate compatible pairs with high priority rather than only learning the regularity behind a specific data distribution. We believe that DANIEL can perform better on real-world problems with unknown distributions upon a small amount of fine-tuning, as DANIEL can outperform the exact methods on tasks with known distributions, which is left for future research."
        },
        {
            "heading": "V. CONCLUSIONS",
            "text": "This study proposes DANIEL, a novel end-to-end learning framework for addressing standard FJSPs. DANIEL combines the attention mechanism and DRL while maintaining the sizeagnostic property, i.e., training on small-size problems and deploying to larges-size ones. DANIEL builds on a concise representation of the complex FJSP structure, by employing two attention blocks to explore relationships between operations within the job as well as between the competing machines. The dual attention network receives abundant information about decision-relevant operations and machines as input and extracts their features through GAT-style attention mechanisms. The downstream decision-making network generates composite decisions for the operation sequencing\nand machine assignment problems simultaneously using actorcritic reinforcement learning, trained by the PPO algorithm. Substantial numerical results on synthetic data as well as publicly available benchmarks show that DANIEL performs significantly better than traditional PDRs and the state-ofthe-art DRL method while being computationally efficient. In several cases, DANIEL even beats the OR-Tools, which has never been reported for end-to-end learning approaches in the literature. Moreover, DANIEL demonstrates excellent generalization performance to large-scale and real-world instances when trained using small-size FJSP data relative to existing DRL methods. In the future, extending DANIEL to address dynamic FJSP with uncertainty, such as new job insertions, and to the multi-agent setting constitutes interesting topics for future research."
        },
        {
            "heading": "VI. APPENDIX",
            "text": "Here, details for the three types of feature vectors at state st (t is omitted below) are provided. 1) Features of operations: 4 static attributes and 6 dynamic properties are recorded for each Oij \u2208 Ou: \u2022 Minimum processing time among all machines. \u2022 Average processing time among all machines. \u2022 Span of processing time among all machines. \u2022 Proportion of machines that Oij can be processed on. \u2022 Scheduling tag: the value is 0 if Oij is unscheduled\notherwise 1. \u2022 Estimated Lower bound of the completion time: C(Oij)\ndefined in the text. \u2022 Job remaining number of operations: the number of\nunscheduled operations in Ji. \u2022 Job remaining workload: the sum of average processing\ntime of unscheduled operations in Ji. \u2022 Waiting time: the time from the ready time until Ts. (0\nfor Oij that is not ready yet) \u2022 Remaining processing time: the time from Ts until the\ncompletion time. (0 for unscheduled Oij) 2) Features of machines: Each machine Mk \u2208Mu owns a feature vector with 8 elements and the first two are static: \u2022 Minimum processing time among all operations. \u2022 Average processing time of operations that Mk can\nprocess. \u2022 Number of unscheduled operations that Mk can process. \u2022 Number of candidates that Mk can process. \u2022 Free time: the moment when Mk is free. \u2022 Waiting time: the time from the free time until Ts. (0 for\nworking Mk) \u2022 Working tag: the value is 0 if Mk is free otherwise 1. \u2022 Remaining processing time: the time from Ts until the\nfree time. (0 for free Mk) 3) Features of compatible operation-machine pairs: When a compatible pair (Oij ,Mk) is considered, we record 8 features for it and the first two are static:\n\u2022 Processing time pkij . \u2022 Ratio of pkij to the maximum processing time of Oij . \u2022 Ratio of pkij to the maximum processing time of candi-\ndates that Mk can process.\n11\n\u2022 Ratio of pkij to the maximum processing time of unscheduled operations. \u2022 Ratio of pkij to the maximum processing time of unscheduled operations that Mk can process. \u2022 Ratio of pkij to the maximum processing time of compatible pairs. \u2022 Ratio of pkij to remaining workload of Ji. \u2022 Summation of waiting time of Oij and Mk."
        }
    ],
    "title": "Flexible Job Shop Scheduling via Dual Attention Network Based Reinforcement Learning",
    "year": 2023
}