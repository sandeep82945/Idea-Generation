{
    "abstractText": "We present a novel physics-informed system identification method to construct a passive linear time-invariant system. In more detail, for a given quadratic energy functional, measurements of the input, state, and output of a system in the time domain, we find a realization that approximates the data well while guaranteeing that the energy functional satisfies a dissipation inequality. To this end, we use the framework of portHamiltonian (pH) systems and modify the dynamic mode decomposition, respectively operator inference, to be feasible for continuous-time pH systems. We propose an iterative numerical method to solve the corresponding least-squares minimization problem. We construct an effective initialization of the algorithm by studying the least-squares problem in a weighted norm, for which we present the analytical minimum-norm solution. The efficiency of the proposed method is demonstrated with several numerical examples.",
    "authors": [],
    "id": "SP:72bbee9af016a7ad5075166140f3070a9de750a8",
    "references": [
        {
            "authors": [
                "R. Altmann",
                "V. Mehrmann",
                "B. Unger"
            ],
            "title": "Port-Hamiltonian formulations of poroelastic network models",
            "venue": "Math. Comput. Model. Dyn. Sys., 27(1):429\u2013452",
            "year": 2021
        },
        {
            "authors": [
                "J. Annoni",
                "P. Gebraad",
                "P. Seiler"
            ],
            "title": "Wind farm flow modeling using an input-output reducedorder model",
            "venue": "Am. Control Conf., Boston, MA, USA",
            "year": 2016
        },
        {
            "authors": [
                "A.C. Antoulas",
                "S. Lefteriu",
                "A.C. Ionita"
            ],
            "title": "Chapter 8: A tutorial introduction to the Loewner framework for model reduction",
            "venue": "P. Benner, A. Cohen, M. Ohlberger, and K. Willcox, editors, Model Reduction and Approximation, pages 335\u2013376. SIAM, Philadelphia, PA, USA",
            "year": 2017
        },
        {
            "authors": [
                "P.J. Baddoo",
                "B. Herrmann",
                "B.J. McKeon",
                "J.N. Kutz",
                "S.L. Brunton"
            ],
            "title": "Physics-informed dynamic mode decomposition (piDMD)",
            "venue": "ArXiv e-print 2112.04307",
            "year": 2021
        },
        {
            "authors": [
                "C. Beattie",
                "V. Mehrmann",
                "P. Van Dooren"
            ],
            "title": "Robust port-Hamiltonian representations of passive systems",
            "venue": "Automatica J. IFAC, 100:182\u2013186",
            "year": 2019
        },
        {
            "authors": [
                "C. Beattie",
                "V. Mehrmann",
                "H. Xu",
                "H. Zwart"
            ],
            "title": "Port-Hamiltonian descriptor systems",
            "venue": "Math. Control Signals Systems, 30(17):1\u201327",
            "year": 2018
        },
        {
            "authors": [
                "P. Benner",
                "P. Goyal",
                "J. Heiland",
                "I. Pontes Duff"
            ],
            "title": "Operator inference and physics-informed learning of low-dimensional models for incompressible flows",
            "venue": "Electron. Trans. Numer. Anal., 56:28\u201351",
            "year": 2022
        },
        {
            "authors": [
                "P. Benner",
                "P. Goyal",
                "P. Van Dooren"
            ],
            "title": "Identification of port-Hamiltonian systems from frequency response data",
            "venue": "Systems Control Lett., 143:104741",
            "year": 2020
        },
        {
            "authors": [
                "P. Benner",
                "C. Himpe",
                "T. Mitchell"
            ],
            "title": "On reduced input-output dynamic mode decomposition",
            "venue": "Adv. Comput. Math., pages 1\u201318",
            "year": 2018
        },
        {
            "authors": [
                "P. Borja",
                "J.M.A. Scherpen",
                "K. Fujimoto"
            ],
            "title": "Extended balancing of continuous LTI systems: a structure-preserving approach",
            "venue": "IEEE Trans. Automat. Control",
            "year": 2021
        },
        {
            "authors": [
                "T. Breiten",
                "R. Morandin",
                "P. Schulze"
            ],
            "title": "Error bounds for port-Hamiltonian model and controller reduction based on system balancing",
            "venue": "Comput. Math. Appl., 116:100\u2013115",
            "year": 2022
        },
        {
            "authors": [
                "T. Breiten",
                "B. Unger"
            ],
            "title": "Passivity preserving model reduction via spectral factorization",
            "venue": "Automatica J. IFAC, 142:110368",
            "year": 2022
        },
        {
            "authors": [
                "R.T.Q. Chen",
                "Y. Rubanova",
                "J. Bettencourt",
                "D. Duvenaud"
            ],
            "title": "Neural ordinary differential equations",
            "venue": "32nd Conference on Neural Information Processing Systems ",
            "year": 2018
        },
        {
            "authors": [
                "K. Cherifi",
                "V. Mehrmann",
                "K. Hariche"
            ],
            "title": "Numerical methods to compute a minimal realization of a port-Hamiltonian system",
            "venue": "ArXiv e-print 1903.07042",
            "year": 2019
        },
        {
            "authors": [
                "Y.-B. Deng",
                "X.-Y. Hu",
                "L. Zhang"
            ],
            "title": "Least squares solution of BXA = T over symmetric",
            "venue": "skew-symmetric, and positive semidefinite X. SIAM J. Matrix Anal. Appl., 25(2):486\u2013494",
            "year": 2003
        },
        {
            "authors": [
                "N. Gillis",
                "P. Sharma"
            ],
            "title": "On computing the distance to stability for matrices using linear dissipative hamiltonian systems",
            "venue": "Automatica J. IFAC, 85:113\u2013121",
            "year": 2017
        },
        {
            "authors": [
                "N. Gillis",
                "P. Sharma"
            ],
            "title": "A semi-analytical approach for the positive semidefinite procrustes problem",
            "venue": "Linear Algebra Appl., 540:112\u2013137",
            "year": 2018
        },
        {
            "authors": [
                "S. Gugercin"
            ],
            "title": "Rostyslav V",
            "venue": "Polyuga, C. Beattie, and A. van der Schaft. Structure-preserving tangential interpolation for model reduction of port-Hamiltonian systems. Automatica J. IFAC, 48(9):1963\u20131974",
            "year": 2012
        },
        {
            "authors": [
                "B. Gustavsen",
                "A. Semlyen"
            ],
            "title": "Rational approximation of frequency domain responses by vector fitting",
            "venue": "IEEE Trans. Power Deliv., 14(3):1052\u20131061",
            "year": 1999
        },
        {
            "authors": [
                "J. Heiland",
                "B. Unger"
            ],
            "title": "Identification of linear time-invariant systems with dynamic mode decomposition",
            "venue": "Mathematics, 10(3):418",
            "year": 2022
        },
        {
            "authors": [
                "Nicholas J Higham"
            ],
            "title": "Matrix nearness problems and applications",
            "year": 1988
        },
        {
            "authors": [
                "B. Hillebrecht",
                "B. Unger"
            ],
            "title": "Certified machine learning: A posteriori error estimation for physicsinformed neural networks",
            "venue": "2022 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138",
            "year": 2022
        },
        {
            "authors": [
                "B. Hillebrecht",
                "B. Unger"
            ],
            "title": "Certified machine learning: Rigorous a posteriori error bounds for PDE defined PINNs",
            "venue": "ArXiv e-print 2210.03426",
            "year": 2022
        },
        {
            "authors": [
                "B. Jacob",
                "H. Zwart"
            ],
            "title": "Linear port-Hamiltonian systems on infinite-dimensional spaces",
            "venue": "Operator Theory: Advances and Applications. Birkh\u00e4user, Basel",
            "year": 2012
        },
        {
            "authors": [
                "J.-N Juang",
                "R.S. Pappa"
            ],
            "title": "An eigensystem realization algorithm for modal parameter identification and model reduction",
            "venue": "J. Guidance Control Dynam., 8(5):620\u2013627",
            "year": 1985
        },
        {
            "authors": [
                "G.E. Karniadakis",
                "I.G. Kevrekidis",
                "L. Lu",
                "P. Perdikaris",
                "S. Wang",
                "L. Yang"
            ],
            "title": "Physicsinformed machine learning",
            "venue": "Nature Reviews Physics, 3:422\u2013440",
            "year": 2021
        },
        {
            "authors": [
                "P. Kotyczka",
                "L. Lef\u00e8vre"
            ],
            "title": "Discrete-time port-Hamiltonian systems based on Gauss-Legendre collocation",
            "venue": "IFAC-PapersOnLine, 51(3):125\u2013130",
            "year": 2018
        },
        {
            "authors": [
                "J. Kutz",
                "S. Brunton",
                "B. Brunton",
                "J. Proctor"
            ],
            "title": "Dynamic Mode Decomposition",
            "venue": "SIAM, Philadelphia, PA",
            "year": 2016
        },
        {
            "authors": [
                "A.J. Mayo",
                "A.C. Antoulas"
            ],
            "title": "A framework for the solution of the generalized realization problem",
            "venue": "Linear Algebra Appl., 425(2-3):634\u2013662",
            "year": 2007
        },
        {
            "authors": [
                "V. Mehrmann",
                "R. Morandin"
            ],
            "title": "Structure-preserving discretization for port-Hamiltonian descriptor systems",
            "venue": "58th IEEE Conference on Decision and Control (CDC), Nice, France, pages 6863\u20136868",
            "year": 2019
        },
        {
            "authors": [
                "V. Mehrmann",
                "B. Unger"
            ],
            "title": "Control of port-Hamiltonian differential-algebraic systems and applications",
            "venue": "ArXiv e-print 2201.06590",
            "year": 2022
        },
        {
            "authors": [
                "T. Moser",
                "B. Lohmann"
            ],
            "title": "A new Riemannian framework for efficient H2-optimal model reduction of port-Hamiltonian systems",
            "venue": "2020 59th IEEE Conference on Decision and Control (CDC), pages 5043\u20135049",
            "year": 2020
        },
        {
            "authors": [
                "Y. Nesterov"
            ],
            "title": "Introductory lectures on convex optimization: A basic course",
            "venue": "volume 87. Springer Science & Business Media",
            "year": 2003
        },
        {
            "authors": [
                "B. Peherstorfer",
                "S. Gugercin",
                "K.E. Willcox"
            ],
            "title": "Data-driven reduced model construction with time-domain Loewner models",
            "venue": "SIAM J. Sci. Comput., 39(5):2152\u20132178",
            "year": 2017
        },
        {
            "authors": [
                "B. Peherstorfer",
                "K. Willcox"
            ],
            "title": "Data-driven operator inference for nonintrusive projection-based model reduction",
            "venue": "Computer Methods in Applied Mechanics and Engineering, 306:196\u2013215",
            "year": 2016
        },
        {
            "authors": [
                "R.V. Polyuga",
                "A. van der Schaft"
            ],
            "title": "Structure-preserving moment matching for port-Hamiltonian systems: Arnoldi and Lanczos",
            "venue": "IEEE Trans. Automat. Control,",
            "year": 2011
        },
        {
            "authors": [
                "R.V. Polyuga",
                "A. van der Schaft"
            ],
            "title": "Effort- and flow-constraint reduction methods for structure preserving model reduction of port-Hamiltonian systems",
            "venue": "Systems Control Lett.,",
            "year": 2012
        },
        {
            "authors": [
                "J.L. Proctor",
                "S.L. Brunton",
                "J.N. Kutz"
            ],
            "title": "Dynamic mode decomposition with control",
            "venue": "SIAM J. Appl. Dyn. Syst., 15(1):142\u2013161",
            "year": 2014
        },
        {
            "authors": [
                "M. Raissi",
                "P. Perdikaris",
                "G.E. Karniadakis"
            ],
            "title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "venue": "J. Comput. Phys., 378:686\u2013707",
            "year": 2019
        },
        {
            "authors": [
                "K. Sato",
                "H. Sato"
            ],
            "title": "Structure-Preserving H2 Optimal Model Reduction Based on the Riemannian Trust-Region Method",
            "venue": "IEEE Trans. Automat. Control, 63(2):505\u2013512",
            "year": 2018
        },
        {
            "authors": [
                "P.J. Schmid"
            ],
            "title": "Dynamic mode decomposition of numerical and experimental data",
            "venue": "J. Fluid Mech., 656:5\u201328",
            "year": 2010
        },
        {
            "authors": [
                "P. Schulze",
                "B. Unger"
            ],
            "title": "Data-driven interpolation of dynamical systems with delay",
            "venue": "Systems Control Lett., 97:125\u2013131",
            "year": 2016
        },
        {
            "authors": [
                "P. Schulze",
                "B. Unger",
                "C. Beattie",
                "S. Gugercin"
            ],
            "title": "Data-driven structured realization",
            "venue": "Linear Algebra Appl., 537:250\u2013286",
            "year": 2018
        },
        {
            "authors": [
                "P. Schwerdtner"
            ],
            "title": "Port-Hamiltonian system identification from noisy frequency response data",
            "venue": "ArXiv e-print 2106.11355",
            "year": 2021
        },
        {
            "authors": [
                "P. Schwerdtner",
                "M. Voigt"
            ],
            "title": "SOBMOR: Structured optimization-based model order reduction",
            "venue": "ArXiv e-print 2011.07567",
            "year": 2020
        },
        {
            "authors": [
                "P. Schwerdtner",
                "M. Voigt"
            ],
            "title": "Adaptive sampling for structure-preserving model order reduction of port-Hamiltonian systems",
            "venue": "IFAC-PapersOnLine, 54(19):143\u2013148",
            "year": 2021
        },
        {
            "authors": [
                "H. Sharma",
                "B. Kramer"
            ],
            "title": "Preserving Lagrangian structure in data-driven reduced-order modeling of large-scale mechanical systems",
            "venue": "ArXiv e-print 2203.06361",
            "year": 2022
        },
        {
            "authors": [
                "H. Sharma",
                "Z. Wang",
                "B. Kramer"
            ],
            "title": "Hamiltonian operator inference: Physics-preserving learning of reduced-order models for canonical Hamiltonian systems",
            "venue": "Phys. D, 432:133122",
            "year": 2022
        },
        {
            "authors": [
                "Jonathan H. Tu",
                "Clarence W. Rowley",
                "Dirk M. Luchtenburg",
                "Steven L. Brunton",
                "J. Nathan Kutz"
            ],
            "title": "On dynamic mode decomposition: Theory and applications",
            "venue": "J. Comput. Dyn.,",
            "year": 2014
        },
        {
            "authors": [
                "A. van der Schaft",
                "D. Jeltsema"
            ],
            "title": "Port-Hamiltonian systems theory: An introductory overview",
            "venue": "Foundations and Trends in Systems and Control,",
            "year": 2014
        },
        {
            "authors": [
                "S.W.R. Werner",
                "I.V. Gosea",
                "S. Gugercin"
            ],
            "title": "Structured vector fitting framework for mechanical systems",
            "venue": "IFAC-PapersOnLine, 55(20):163\u2013168",
            "year": 2022
        },
        {
            "authors": [
                "T. Wolf",
                "B. Lohmann",
                "R. Eid",
                "P. Kotyczka"
            ],
            "title": "Passivity and structure preserving order reduction of linear port-Hamiltonian systems using Krylov subspaces",
            "venue": "Eur. J. Control, 16",
            "year": 1062
        }
    ],
    "sections": [
        {
            "text": "Keywords: dynamic mode decomposition, port-Hamiltonian systems, system identification, dissipation inequality, passivity, knowledge-driven realization\nAMS subject classification: 37J06,37M99,65P10,93A30,93B30,93C05"
        },
        {
            "heading": "1. Introduction",
            "text": "Incorporating prior knowledge into modern learning architectures becomes increasingly important in several applications. Such knowledge-driven or physics-informed approaches [26,39] exploit expert knowledge during the learning process, either by optimizing only over a suitable set of candidate functions, or by using physical information in the cost functional. In our work, we deal with data from physical systems with the goal of identifying a linear dynamical system, which we refer to as a realization that approximates the data as well as possible with respect to the Frobenius norm. In more detail, assume that we have measurements (u(ti), x(ti), y(ti)) \u2208 Rm \u00d7 Rn \u00d7 Rm at time instances ti for i = 0, . . . ,M . Then, we want to determine matrices A \u2208 Rn\u00d7n, B \u2208 Rn\u00d7m, C \u2208 Rm\u00d7n, and D \u2208 Rm\u00d7m such that the data can be approximately recovered by the linear time-invariant system\nx\u0307 = Ax+Bu, y = Cx+Du. (1.1)\nSince we assume that the data is based on a physical process, we want to ensure that the realization satisfies a dissipation inequality, i.e., that the rate of change of the energy associated with the system is bounded by the externally supplied energy. We thus incorporate physical knowledge by prescribing the (quadratic) energy functional\nH(x) := 12x THx (1.2)\nwith symmetric positive definite matrix H \u2208 Rn\u00d7n. Our main goal is then to determine the matrices in (1.1) such that any solution of (1.1) satisfies the dissipation inequality\nd dtH(x(t)) \u2264 y(t) Tu(t) (1.3)\nDate: February 13, 2023. 1\nar X\niv :2\n20 4.\n13 47\n4v 2\n[ m\nat h.\nD S]\n1 0\nFe b\n20 23\n2 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?\nfor any t. One of the main advantages of requiring the learned model to satisfy a dissipation inequality is that whenever the model is coupled with another passive model via a powerconserving or dissipative interconnection, then the coupled model is also passive. Moreover, since the Hamiltonian also serves as a Lyapunov function, we are guaranteed that the identified system is stable (independent of the underlying physical system and the quality of the measurements). Our framework can thus be used to guarantee the physical behavior of coupled first-principle and purely data-inferred dynamical systems. To achieve this goal, we use the framework of port-Hamiltonian (pH) systems [24,50] and modify the dynamic mode decomposition (DMD) [28,41,49] and operator inference (OI) [35] accordingly. Our main contributions are the following:\n(i) Since DMD is designed to compute a discrete-time dynamical system, we follow [27, 30] and present a definition of a discrete-time pH system in section 2.2, which is motivated from the structure-preserving time-discretization of a continuous-time pH system. The corresponding modified DMD optimization problem is formulated in Problem 3.1. (ii) Although Problem 3.1 is convex and solvable, a closed-form solution formula is not immediately available. Instead, we propose an iterative method (Algorithm 1) combining the result of a skew-symmetric Procrustes problem [15] with a projected fast gradient method for a positive semidefinite Procrustes problem [17]. (iii) For an efficient initialization of Algorithm 1, we consider a weighted Frobenius norm, where we weight the problem according to the relevant information in the data, see the forthcoming Section 3.3. The analytic minimum-norm solution of the weighted problem is then presented in Theorem 3.7 and used, up to some modification, as initialization for our iterative method.\n1.1. Literature review. The construction of a realization of the form (1.1) from data is a well-studied subject with many popular approaches. We mention the eigensystem realization algorithm [25], the Loewner framework [29], vector fitting [19], neural ordinary differential equations [13], OI [35], and DMD [28]. Introducing expert knowledge to these approaches is not a novel idea and may even be the key idea to quantifying the error between the realization and the true physical system, cf. [22,23]. Exploiting expert knowledge in the identification of linear systems is reported in various applications and methods. For instance, the specific structure of mechanical systems is exploited in a vector fitting framework in [51]. The authors of [42, 43] exploit the fact that certain wave-type phenomena can be represented with delay equations to construct accurate linear time-invariant surrogate models from data. In the context of the Navier-Stokes equation, the specific structure of the (semi-discretized) equations is exploited in an OI approach in [7]. Extensions of OI to Hamiltonian and Lagrangian dynamics are reported in [47, 48]. Similar ideas are discussed in the context of DMD in [4] by restricting the discrete-time iteration matrix to specific manifolds. In essence, our method relies on a similar idea but with a specific structure of the iteration matrix not discussed in [4].\nAs detailed above, we use the framework of pH systems to achieve our goal of identifying a system that satisfies a dissipation inequality. In contrast to our approach, most existing results on learning linear time-invariant pH systems work in the frequency domain. Using rational interpolation, a pH system is constructed in [3] within the Loewner framework by interpolating the transfer function at the spectral zeros. Since these are typically not known a priori, the authors of [8] propose first identifying an (unstructured) system and\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 3\nthen computing the spectral zeros from this system. A parameterization of pH systems is used in [44\u201346] to approximately mimic an H\u221e-type cost functional. Note that these ideas can be transferred to time-domain data using similar ideas as, for instance, in [34]. Instead of directly identifying a pH structure (as we do in our contribution), the authors of [14] propose to first identify an unstructured model and then find the nearest pH systems. Let us emphasize that in contrast to the other methods, we assume knowledge of the energy functional, and instead of finding an arbitrary pH system, our goal is to identify a system such that the dissipation inequality for this energy functional is guaranteed.\nWe mention that many of the identification methods discussed above are closely related to intrusive structure-preserving model order reduction methods for pH systems. Popular approaches include the effort-and flow-constraint reduction method [37], tangential interpolation [18,36,52], generalized balancing [10,11], H2-and H\u221e-optimal approaches [32,40,45], and spectral factorization [12]. For further methods, we refer to the references cited in [31, Rem. 8.2].\n1.2. Organization of the manuscript. After this introduction, we recall basic results on DMD and OI (cf. section 2.1) and review the theory of linear time-invariant pH systems in section 2.2. In particular, we introduce a definition for a discrete-time pH system, following the more general discussion in [27, 30]. The port-Hamiltonian dynamic mode decomposition (pHDMD) problem is formulated in section 3.1, yielding a convex minimization problem. An iterative algorithm to solve the pHDMD problem is presented in section 3.2, whereas we discuss a clever initialization in section 3.3 by solving the pHDMD problem in a weighted norm. The algorithm is then applied to several numerical examples in section 4.\n1.3. Notation. We use the symbols N, R, Rn, and Rn\u00d7m to denote the positive integers, the real numbers, the set of columns vectors with n \u2208 N real entries, and the set of n\u00d7m real matrices, respectively. For a matrix A \u2208 Rn\u00d7m we denote its transpose with AT and its Moore-Penrose pseudoinverse with A\u2020. A matrix A \u2208 Rn\u00d7n is called symmetric (skewsymmetric), if A = AT (A = \u2212AT). The decomposition of a squared matrix A \u2208 Rn\u00d7n into its skew-symmetric resp. symmetric part is denoted as\nsym(A) = 12(A+A T), resp. skew(A) = 12(A\u2212A T).\nThe sets of all n \u00d7 n symmetric positive definite and symmetric positive semi-definite matrices with real entries are denoted with Sn and Sn . The projection P (A) of a matrix A \u2208 Rn\u00d7n onto Sn is given by\nP (A) = \u039e diag(\u039b+, 0, 0)\u039eT,\nwhere sym(A) = \u039e diag(\u039b+,\u039b\u2212, 0)\u039eT is the ordered eigendecomposition of the symmetric part of A. Here, \u039b+ and \u039b\u2212 are the diagonal matrices containing the positive and negative eigenvalues, respectively. The set of nonsingular matrices of size n \u00d7 n is denoted with GLn(R). The Stiefel manifold of n\u00d7 r dimensional matrices with real entries is denoted by\nSt(n, r) := { U \u2208 Rn\u00d7r | UTU = Ir } ,\nwhere Ir denotes the r \u00d7 r identity matrix. Furthermore, given \u2126 \u2208 Sn we denote the weighted Frobenius semi-norm as\n\u2016A\u2016\u2126 := \u221a trace (AT\u2126A). (1.4)\n4 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?"
        },
        {
            "heading": "2. Preliminaries",
            "text": "2.1. Dynamic Mode Decomposition and Operator Inference. Assume data triples (ui, xi, yi) \u2208 Rm \u00d7Rn \u00d7Rp (DMD) or data quadruples (ui, xi, x\u0307i, yi) \u2208 Rm \u00d7Rn \u00d7Rn \u00d7Rp (OI) for i = 0, . . . ,M of a dynamical system available, which may be obtained from measurements of real phenomena or the simulation of a model. The goal of (input-output) DMD [2, 38] or OI [35] is to find matrices A\u0303, B\u0303, C\u0303, D\u0303 of suitable size minimizing\nmin A\u0303,B\u0303,C\u0303,D\u0303 M\u22121\u2211 i=0 \u2016\u2206xi \u2212 A\u0303xi \u2212 B\u0303ui\u201622 + \u2016yi \u2212 C\u0303xi \u2212 D\u0303ui\u201622, (2.1)\nwhere \u2206xi := x\u0307i if we assume derivative information of the state to be available, and \u2206xi := xi+1, otherwise. The goal of solving (2.1) is to determine a linear system of the form\n\u2206x\u0303 = A\u0303x\u0303+ B\u0303u,\ny\u0303 = C\u0303x\u0303+ D\u0303u, (2.2)\nthat best approximates the data (in the sense of (2.1)), where \u2206 denotes the differentiation operator with respect to time if we are in the continuous time setting described by OI, and \u2206 denotes the forward shift in the discrete-time setting used in DMD. This is conveniently achieved by introducing the matrices\nZ0 := [ x0 . . . xM\u22121 u0 . . . uM\u22121 ] \u2208 R(n+m)\u00d7M and Z1 := [ \u2206x0 . . . \u2206xM\u22121 y0 . . . yM\u22121 ] \u2208 R(n+p)\u00d7M\nand studying the equivalent problem\nmin A\u2208R(n+p)\u00d7(n+m) \u2016Z1 \u2212AZ0\u2016F , (2.3)\nwhose solution, conformably partitioned, yields the matrices A\u0303, B\u0303, C\u0303, and D\u0303. The minimum norm solution A? of (2.3) is given by the Moore-Penrose pseudo-inverse of the data, i.e., A? = Z1Z\u20200. We emphasize that this is the unique solution of (2.3) if and only if r := rank(Z0) = n+m. The pseudo-inverse can be computed efficiently using the singular value decomposition (SVD). In more detail, set r := rank(Z0) and let Z0 = V \u03a3WT with V \u2208 St(n + m, r), \u03a3 \u2208 GLr(R), W \u2208 St(M, r) denote the skinny SVD of Z0. Then, Z\u20200 = W\u03a3\u22121V . Note that from a numerical point of view, we truncate singular values below a given tolerance to ensure that the inverse \u03a3\u22121, respectively the associated linear system, can be computed accurately. Such a truncation is equivalent to adding a regularization term to the minimization problem (2.3), see [9] for further details.\nRemark 2.1. If no measurements of the derivative are available, then a classical finite difference approach of the form\n\u2206xi \u2248 \u02d9\u0302xi := xi+1 \u2212 xi\n\u03b4i , (2.4)\nmay be used as an approximation, where \u03b4i is the time step between the snapshots. This is a common approach in the literature, see, e.g., [35], for which a convergence result for \u03b4i \u2192 0 is available [35, Thm. 1]. Throughout this manuscript, we do not assume x\u0307i available, and hence work with the approximation (2.4), instead.\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 5\nThe method can be further extended to include dimensionality reduction, which is then called reduced OI [35]. There, a low dimensional basis for the state space must is constructed. Afterwards, the data is projected onto this low-dimensional basis. Finally, (2.1) is solved for the reduced data, which results in a reduced order model. The low dimensional basis generation can be achieved, for instance, by applying the SVD to the state data, i.e., let X = V \u03a3W denote the skinny SVD of X. Then the reduced basis \u03a6 of size r can be defined as the first r columns of V .\n2.2. Port-Hamiltonian system. As outlined in the introduction, pH systems are a promising modeling tool that generalize the notion of Hamiltonian systems to allow for interaction with the environment. Since the aim of DMD is to produce a linear system, we review the pH framework only for linear dynamics and refer the reader for a more general definition to [31,50].\nDefinition 2.2 (Linear time-invariant pH system). Assume that we have given a quadratic function H(x) = 12x\nTH\u0302x, called the Hamiltonian, with H\u0302 \u2208 Sn and a suitable factorization H\u0302 = ETQ with E,Q \u2208 Rn\u00d7n. Then the system[\nEx\u0307 y ] = [ A B C D ] [ Qx u ] ,\n[ A B \u2212C \u2212D ] = J \u2212R, (2.5)\nwith J = \u2212J > \u2208 R(n+m)\u00d7(n+m) and R \u2208 Sn+m is called a pH system.\nIn Definition 2.2, the matrix J represents the conservation of energy, while R describes dissipation. Note that the specific structure requires the input and output dimension to match and directly implies that pH systems are stable and passive, and the Hamiltonian serves as a Lyapunov function. In more detail, any pH system together with its Hamiltonian satisfies the dissipation inequality (1.3). Conversely, any passive linear time-invariant system, i.e., any system for which a quadratic Hamiltonian exists such that the system with this Hamiltonian satisfies the dissipation inequality (1.3), has a pH representation, cf. [5]. Every pH system (2.5) can be equivalently written as\nEx\u0307 = (J \u2212R)Qx+ (G\u2212 P )u, (2.6a) y = (G+ P )TQx+ (S \u2212N)u, (2.6b)\nwith J = \u2212J>, N = \u2212N>, and\nR = [ R P PT S ] \u2208 Sn+m .\nFor further details on the properties that are encoded within this structure we refer to [6]. Multiplication of (2.6a) from the left with QT, see [31, Sec. 4.3], and introducing the matrices\nJ\u0302 := QTJQ, R\u0302 := QTRQ, G\u0302 := QTG, P\u0302 := QTP, S\u0302 := S, N\u0302 := N\nallows us to rewrite (2.6) as\nH\u0302x\u0307 = (J\u0302 \u2212 R\u0302)x+ (G\u0302\u2212 P\u0302 )u, (2.7a)\ny = (G\u0302+ P\u0302 )Tx+ (S\u0302 \u2212 N\u0302)u, (2.7b)\n6 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?\nwhich is linear in the system matrices. Due to the congruence transformation, we immediately conclude J\u0302 = \u2212J\u0302T, N\u0302 = \u2212N\u0302T and\nR\u0302 = [ R\u0302 P\u0302\nP\u0302T S\u0302\n] \u2208 Sn+m .\nRemark 2.3. Let us emphasize that from a mathematical perspective, the choice of the energy functional yielding to a pH system is generally not unique. Indeed, any solution of the corresponding Kalman-Yakubovich-Popov inequality can be used as the Hessian of the energy; see [5] for further details. Furthermore, recent results detail that the choice of the energy functional characterizes how easy it is to approximate the system [12].\nTo understand pH systems in the framework of DMD, we need to find a discrete-time analogue of (2.7). Since symplectic Gauss-Legendre collocation methods are able to preserve the underlying Dirac structure of the pH system [27,30], and DMD is able to recover the original dynamics if the DMD approximation is based on a discretization with a 1-stage Runge-Kutta method [20], we use the implicit midpoint rule for the time-discretization. More precisely, for a constant step size \u03b4t > 0, the continuous dynamics (2.7a) are replaced with the discrete dynamics\nH\u0302 xi+1\u2212xi\u03b4t = (J\u0302 \u2212 R\u0302) xi+1+xi 2 + (G\u0302\u2212 P\u0302 ) ui+1+ui 2 ,\nwith xi \u2248 x(i\u03b4t), and ui := u(i\u03b4t). Note that with respect to our goal to generate a discretetime pH system from data, we have replaced u((i+ 12)\u03b4t) from the implicit midpoint rule with the approximation\nu((i+ 12)\u03b4t) \u2248 ui+1+ui 2 .\nIt is natural to also replace the continuous output equation (2.6b) with its discrete counterpart using yi \u2248 y(i\u03b4t). To preserve port-Hamiltonian structure, we take the average of consecutive output equations arriving at\nyi+1+yi 2 = (G\u0302+ P\u0302 ) T xi+1+xi 2 + (S\u0302 \u2212 N\u0302) ui+1+ui 2 .\nThe previous analysis motivates the following definition.\nDefinition 2.4 (discrete-time pH system). Consider sequences of states xi \u2208 Rn, inputs ui \u2208 Rm, outputs yi \u2208 Rm, and a constant time step \u03b4t > 0. We call a system of the form\nH\u0302 xi+1\u2212xi\u03b4t = (J\u0302 \u2212 R\u0302) xi+1+xi 2 + (G\u0302\u2212 P\u0302 ) ui+1+ui\n2 , (2.8a) yi+1+yi\n2 = (G\u0302+ P\u0302 ) T xi+1+xi 2 + (S\u0302 \u2212 N\u0302) ui+1+ui 2 , (2.8b)\na discrete-time pH system with quadratic Hamiltonian H(x) := 12x TH\u0302x if and only if J\u0302 = \u2212J\u0302T, N\u0302 = \u2212N\u0302T, and R\u0302 = [ R\u0302 P\u0302 P\u0302T S\u0302 ] \u2208 Sn+m .\nRemark 2.5. The discrete-time pH system (2.8) is not in the standard form of a discretetime dynamical system. Nevertheless, assuming \u03b4t to be sufficiently small, defining the matrices A\u0302 := J\u0302 \u2212 R\u0302, B\u0302 := G\u0302 \u2212 P\u0302 , C\u0302 := (G\u0302 + P\u0302 )T, and D\u0302 := S\u0302 \u2212 N\u0302 , and assuming a consistent initialization of the output, i.e., y0 = C\u0302x0 + D\u0302u0, then (2.8) can be rewritten as\nxi+1 = ( 1\u03b4t H\u0302 \u2212 1 2A\u0302) \u22121( 1\u03b4t H\u0302 + 1 2A\u0302)xi + 1 2( 1 \u03b4t H\u0302 \u2212 12A\u0302) \u22121B\u0302(ui+1 + ui),\nyi = C\u0302xi + D\u0302ui. (2.9)\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 7\nWhile the equation (2.9) can be useful, since it represents xi+1 explicitly in terms of xi and of the output variables, the pH structure of the original system is not evident. Because of that, we prefer working with the system (2.8) instead.\nLet us emphasize that (2.8) can be equivalently written as[ H\u0302 xi+1\u2212xi\u03b4t \u2212yi+1+yi2 ] = (J\u0302 \u2212 R\u0302) [ xi+1+xi 2 ui+1+ui 2 ] , (2.10)\nwhere J\u0302 = \u2212J\u0302 T and R\u0302 \u2208 Sn+m . Defining \u2206Hi := 1\u03b4t (H(xi+1)\u2212H(xi)) and observing\n\u2206Hi = (xi+1+xi2 ) TH\u0302(xi+1\u2212xi\u03b4t )\nimmediately yields the following discrete version of the dissipation inequality (1.3).\nLemma 2.6. (Discrete-time dissipation inequality) Any discrete-time pH system in the form of (2.8) satisfies the discrete-time dissipation inequality\n\u2206Hi \u2264 (yi+1+yi2 ) T(ui+1+ui2 ). (2.11)\nRemark 2.7. To simplify our presentation, we use a constant time step \u03b4t throughout this manuscript. Nevertheless, it is straightforward to use a variable time step in all what follows."
        },
        {
            "heading": "3. Port-Hamiltonian Dynamic Mode Decomposition",
            "text": "In this section, we discuss a variant of DMD that allows to construct a continuous-time pH system from discrete-time data.\n3.1. The port-Hamiltonian Dynamic Mode Decomposition problem. If the data (xi, ui, yi) at hand are obtained from a physical system, we expect the real system to have a pH representation and thus want to reflect that in our time-discrete realization. Following our concise definition of a discrete-time pH system (2.10), we are thus interested in solving the following problem.\nProblem 3.1 (Port-Hamiltonian Dynamic Mode Decomposition). Consider data points (xi, ui, yi) \u2208 Rn \u00d7 Rm \u00d7 Rm for i = 0, 1, . . . ,M and define the matrices\n\u02d9\u0302 X := 1\u03b4t [ x1 \u2212 x0 . . . xM \u2212 xM\u22121 ] \u2208 Rn\u00d7M ,\nX\u0302 := 12 [ x1 + x0 . . . xM + xM\u22121 ] \u2208 Rn\u00d7M ,\nU\u0302 := 12 [ u1 + u0 . . . uM + uM\u22121 ] \u2208 Rm\u00d7M ,\nY\u0302 := 12 [ y1 + y0 . . . yM + yM\u22121 ] \u2208 Rm\u00d7M .\nGiven any matrix H\u0302 \u2208 Sn (defining the Hamiltonian), and a reduced basis \u03a6 \u2208 Rn\u00d7r\u0303, find matrices J\u0303 , R\u0303 \u2208 Rn\u0303\u00d7n\u0303 with n\u0303 := r\u0303 +m that solve\nmin \u2225\u2225\u2225Z\u0303 \u2212 (J\u0303 \u2212 R\u0303)T\u0303 \u2225\u2225\u2225\nF such that J\u0303 = \u2212J\u0303 > \u2208 Rn\u0303\u00d7n\u0303 and R\u0303 \u2208 S n\u0303 , (3.1)\nwhere Z\u0303 := [ \u03a6TH\u03a6\u03a6T \u02d9\u0302X \u2212Y\u0302 ] and T\u0303 := [ \u03a6TX\u0302 U\u0302 ] . If no dimension reduction is applied, then we set r\u0303 = n and \u03a6 = In.\n8 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?\nRemark 3.2. Note that the structural properties of J\u0303 and R\u0303 are preserved under the transformation with \u03a6, since it is a congruence transformation.\nUsing standard arguments, it is easy to establish that the minimization problem (3.1) is convex and solvable. Moreover, let us emphasize that by solving Problem 3.1, we directly learn the matrices of a continuous-time pH system without requiring further postprocessing. Moreover, Problem 3.1 includes two important special cases. First, suppose we know a-priori that no dissipation is involved. In that case, we can set R\u0303 = 0, and the minimization problem (3.1) reduces to a skew-symmetric Procrustes problem, which can be solved analytically. We refer to [4, 15] and the forthcoming Section 3.2. Second, if the system has no input and output, i.e., we have m = 0, then the task reduces to the identification of a dissipative Hamiltonian system, i.e., we want to solve\nmin \u2225\u2225\u2225H\u0302 \u02d9\u0302X \u2212 [J\u0303 \u2212 R\u0303] X\u0302\u2225\u2225\u2225\nF such that J\u0303 = \u2212J\u0303> \u2208 Rn\u0303\u00d7n\u0303 and R\u0303 \u2208 S n\u0303 . (3.2)\nRemark 3.3. If instead of prescribing the Hamiltonian and thus the matrix H\u0302, one also wants to determine H\u0302 \u2208 Sn from the data, then we observe that (3.2) is not a suitable formulation, since in this case (3.2) is not solvable. To see this, notice that Sn is an open set. Hence, for any \u03b5 > 0, set J\u0303 = R\u0303 = 0 \u2208 Rn\u00d7n and H\u0302 = \u03b5\n2\u2016 \u02d9\u0302X\u2016F In. Then H\u0302 \u2208 Sn ,\nJ\u0303 = \u2212J\u0303T, R\u0303 \u2208 Sn and we have\u2225\u2225\u2225H\u0302 \u02d9\u0302X \u2212 [J\u0303 \u2212 R\u0303] X\u0302\u2225\u2225\u2225 F = \u2225\u2225\u2225\u2225 \u03b52\u2016 \u02d9\u0302X\u2016F \u02d9\u0302X \u2225\u2225\u2225\u2225 F = \u03b52 < \u03b5,\nimplying that the infimum of (3.2) is zero with infimizer H = J\u0303 = R\u0303 = 0.\n3.2. An iterative algorithm for the pHDMD problem. Having established the existence of a solution for Problem 3.1, we will now derive a numerical algorithm to solve the minimization problem (3.1). In [16], a fast gradient method (FGM), cf. [33, p. 90], for the nearest stable matrix to a given matrix is proposed, which is formulated similarly as Problem 3.1. The FGM is an optimal first-order method for convex optimization, which means no other first-order method can converge faster while using the same first-order information. However, we notice that if we already have a guess for R\u0303, then Problem 3.1 simplifies to the skew-symmetric Procrustes problem\nmin \u2225\u2225\u2225Z1 \u2212 J\u0303 T \u2225\u2225\u2225F such that J\u0303 = \u2212J\u0303 > \u2208 Rn\u0303\u00d7n\u0303, (3.3)\nwhere Z1 := Z + R\u0303T . Fortunately, the solution of (3.3) can be computed analytically as detailed in the following theorem taken as a special case of [15, Lem. 2.1], so we propose to include this knowledge into the iterative algorithm to achieve acceleration.\nTheorem 3.4. Let T ,Z1 \u2208 Rn\u0303\u00d7M and let V \u03a3WT = T denote the SVD of T with\n\u03a3 = [ \u03a31 0 0 0 ] , with \u03a31 = diag(\u03c31, . . . , \u03c3r) \u2208 Rr\u00d7r and r = rank(T ).\nDefine \u03a6 = [\u03c6ij ] \u2208 Rr\u00d7r via \u03c6ij = 1\u03c32i +\u03c32j for i, j = 1, . . . , r. Then\nJ\u0303 = V T [ \u03a6 (2 skew(Z1\u03a31)) \u2212\u03a3\u221211 ZT3\nZ3\u03a3\u221211 J\u03034\n] V (3.4)\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 9\nis a solution of (3.3) for any skew-symmetric matrix J\u03034 \u2208 R(n\u0303\u2212r)\u00d7(n\u0303\u2212r), where\nZ1 = [ Ir 0 ] V Z1WT [ Ir 0 ]T \u2208 Rr\u00d7r, Z3 = [ 0 In\u2212r ] V Z1WT [ Ir 0\n]T \u2208 R(n\u0303\u2212r)\u00d7r. The solution is unique if, and only if, rank(T ) = n\u0303.\nProof. The proof follows along the proof of [15, Lem. 2.1].\nOn the other hand if J\u0303 is given, Problem 3.1 simplifies to a symmetric positive definite Procrustes problem\nmin \u2225\u2225\u2225Z2 \u2212 R\u0303T \u2225\u2225\u2225F s.t. R\u0303 \u2208 S n\u0303 , (3.5)\nwhere Z2 = J\u0303 T \u2212Z. Algorithmic solutions for this problem are available [17], for instance a FGM. By modifying this algorithm to allow a Z2 depending on the optimal solution J\u0303 of the skew-symmetric Procrustes problem (3.3), we arrive at Algorithm 1. In more\nAlgorithm 1 Semi-analytical fast gradient method for (3.1)\nInput: Data matrices Z, T \u2208 Rn\u0303\u00d7M\u0303 , initial guess for the dissipative part R\u0303(0) \u2208 Sn Output: Matrices J\u0303 = \u2212J\u0303 T \u2208 Rn\u0303\u00d7n\u0303 and R\u0303 \u2208 S n\u0303 that minimize (3.1)\n1: L = \u03c321(T ), q = \u03c32r L ; 2: k = 0; \u03b11 \u2208 (0, 1); 3: Q = R\u0303(0); 4: while not converged do 5: Z1 = Z + R\u0303(k)T 6: Solve (3.3) for Z1, T according to Theorem 3.4 to obtain J\u0303 (k+1) 7: Z2 = J\u0303 (k+1)T \u2212 Z 8: \u2207 = QT T T \u2212Z2T 9: R\u0303(k+1) = P (Q\u2212 1L\u2207)\n10: \u03b1k+1 = 12(q \u2212 \u03b1 2 k + \u221a (q \u2212 \u03b12k)2 + 4\u03b12k), \u03b2k = \u03b1k(1\u2212\u03b1k) \u03b12\nk +\u03b1k+1\n11: Q = R\u0303(k+1) + \u03b2k(R\u0303(k+1) \u2212 R\u0303(k)) 12: k = k + 1 13: end while 14: J\u0303 = J\u0303 (k), R\u0303 = R\u0303(k)\ndetail, within each iteration step of Algorithm 1, we first compute the solution of the skew-symmetric Procrustes problem (lines 5 and 6) and then compute the gradient with respect to the matrix R\u0303 in lines 7 and 8, ignoring for the moment that we need the new iterate to be symmetric positive definite. This is achieved by projecting onto the cone of symmetric positive definite matrices in line 9. The update is then computed as a linear combination of the current and previous iterate with the fast gradient coefficients (cf. lines 10 and 11).\nRemark 3.5. In general, we cannot guarantee convergence of Algorithm 1. Nevertheless, we can use the standard safety strategy for the fast-gradient, as, for instance, reported in [16], by using a reinitialization with a standard gradient step and a backtracking line\n10 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?\nsearch. By doing so, classical convergence results can be obtained since our objective function is convex and solvable.\nWe notice in our numerical experiments that the performance of the algorithm strongly depends on the initialization and may need many iterations to converge if a poor initialization is used. We thus study a particular initialization strategy in the next subsection by analyzing Problem 3.1 in a weighted norm.\n3.3. A weighted pHDMD problem. A different but related problem arises when the Frobenius norm of the Problem 3.1 is replaced with the weighted Frobenius seminorm introduced in (1.4), where T TT is used as the semi-definite weighting matrix. Problem 3.6 (Weighted Input-Output port-Hamiltonian Dynamic Mode Decomposition). For given data Z, T \u2208 Rn\u0303\u00d7M\u0303 , solve the optimization problem\nmin \u2225\u2225\u2225T T(Z \u2212 (J\u0303 \u2212 R\u0303)T )\u2225\u2225\u2225\nF such that J\u0303 = \u2212J\u0303 > \u2208 Rn\u0303\u00d7n\u0303 and R\u0303 \u2208 S n\u0303 . (3.6)\nTwo remarks are in order, first we immediately notice that by solving the weighted problem we solve the original problem, but weighted according to the relevant information in the data. Second, using the definition of the data matrices from Problem 3.1, we observe that the (i, i) entry of the matrix T T(Z \u2212 (J\u0303 \u2212 R\u0303)T ) reads\neTi (T T(Z \u2212 (J\u0303 \u2212 R\u0303)T )ei = eTi (X\u0302)TH\u0302 \u02d9\u0302 Xei \u2212 eTi U\u0302TY\u0302 ei + eTi [ (X\u0302)T U\u0302T ] R\u0303 [ X\u0302\nU\u0302\n] ei\n= \u2206Hi \u2212 (yi+1+yi2 ) T(ui+1+ui2 ) + e T i\n[ (X\u0302)T U\u0302T ] R\u0303 [ X\u0302\nU\u0302\n] ei,\nwhich resembles the power-balance equation corresponding to the discrete-time dissipation inequality (2.11). In particular, the weighted problem (3.6) uses the dissipation inequality as part of the cost-functional to determine the dissipative component, for which we need a good initialization.\nTheorem 3.7. Let T ,Z \u2208 Rn\u0303\u00d7M\u0303 and let V1\u03a31WT1 = T denote the skinny SVD of T , i.e., V1 \u2208 St(n\u0303, r), \u03a31 \u2208 GLr(R), and W1 \u2208 St(M\u0303, r), where r := rank(T ). Moreover, let W2 complement W1 to an orthogonal matrix, i.e., [ W1 W2 ] \u2208 St(M\u0303, M\u0303). Define\nZ\u03031 := \u03a31V T1 ZW1, Z\u03032 := \u03a31V T1 ZW2, and\nJ\u0303 ? := V1\u03a3\u221211 skew(Z\u03031)\u03a3 \u22121 1 V T 1 and R\u0303? := V1\u03a3\u221211 P (\u2212Z\u03031)\u03a3 \u22121 1 V T 1 . (3.7)\nThen, J\u0303 ? and R\u0303? are the unique minimum-norm minimizers of (3.6) with\u2225\u2225\u2225T TZ \u2212 T T(J\u0303 ? \u2212 R\u0303?)T \u2225\u2225\u22252 F = \u2225\u2225\u2225Z\u03032\u2225\u2225\u22252F + \u2016\u039b+\u20162F , (3.8)\nwhere \u039b+ is the diagonal matrix which contains the positive eigenvalues of sym(Z\u03031) Remark 3.8. The two terms on the right-hand side of (3.8) can be interpreted as follows. The first term is only present if we have too much data to fit, i.e., if T has more columns than rows. Then, in general, no linear system can perfectly capture the data, and the corresponding error contribution is \u2016Z\u03032\u20162F. On the other hand, due to the specific pH structure, not every linear system can be written as a pH system. This potential deviation corresponds to the second error term given by \u2016\u039b+\u20162F.\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 11\nBefore we present the proof, we first illustrate Theorem 3.7 with an academic toy example and need some further preliminary results that provide the best-fit in the Frobenius norm within the class of skew-symmetric and symmetric positive semi-definite matrices.\nExample 3.9. Consider Z = [ \u22121 2\n2 \u22121/2 ] and T = [ 1 00 2 ]. We immediately notice that we\ncan choose V1 = W1 = I2 and \u03a31 = T . We thus obtain Z\u03031 = \u03a31V T1 ZW1 = [ \u22121 2 4 \u22121 ] and thus sym(Z\u03031) = [ \u22121 3\n3 \u22121\n] and skew(Z\u03031) = [ 0 \u22121 1 0 ] .\nThen, the ordered eigendecomposition of Z\u0303sym is given by, Z\u0303sym = \u039e\u039b\u039eT = [\u221a 2 2 \u221a 2\n2\u221a 2 2 \u2212 \u221a 2 2\n] [ 2 0 0 \u22124 ] [\u221a2 2\n\u221a 2\n2\u221a 2 2 \u2212 \u221a 2 2\n] .\nThus, the unique minimizers are given by J\u0303 ? = [\n0 \u2212121 2 0\n] and R\u0303? = [ 2 \u22121 \u22121 12 ] . (3.9)\nThe minimal value of the optimization is given by\u2225\u2225\u2225T TZ \u2212 T T(J\u0303 ? \u2212 R\u0303?)T \u2225\u2225\u2225 F = \u2225\u2225\u2225\u2225[1 11 1 ]\u2225\u2225\u2225\u2225 F = 2 = \u2016\u039b+\u2016F .\nFor the proof of Theorem 3.7 we need the following technical result, taken from [16, Lem. 7], see also [21].\nLemma 3.10. Let Z \u2208 Rr\u00d7r, then the minimization problem min \u2016Z \u2212 (J \u2212R)\u2016F such that J = \u2212J\nT and R \u2208 Sr . (3.10) is solved by J? := skew(Z) and R? := P (\u2212Z).\nProof of Theorem 3.7. Let T = V \u03a3WT denote the singular value decomposition of T , with partitioning\nV = [ V1 V2 ] , \u03a3 = diag(\u03a31, 0), W = [ W1 W2 ] (3.11a)\nsuch that \u03a31 \u2208 GLr(R), where r = rank(T ). In particular, we obtain T = V1\u03a31WT1 . Let J\u0303 = \u2212J\u0303 T \u2208 Rn\u0303\u00d7n\u0303 and R\u0303 \u2208 S n\u0303 . Define[ J\u030311 \u2212J\u0303 T21 J\u030321 J\u030322 ] := V TJ\u0303 V, [ R\u030311 R\u0303T21 R\u030321 R\u030322 ] := V TR\u0303V [ Z11 Z12 Z21 Z22 ] := V TZW (3.11b)\nNote that throughout the proof we work with congruence transformations of J\u0303 and R\u0303, which preserve the skew-symmetry and the positive semi-definiteness. We then obtain\u2225\u2225\u2225T TZ \u2212 T T(J\u0303 \u2212 R\u0303)T \u2225\u2225\u22252 F = \u2225\u2225\u2225\u03a3V TZW \u2212 \u03a3V T(J\u0303 \u2212 R\u0303)V \u03a3\u2225\u2225\u22252 F\n= \u2225\u2225\u2225\u2225\u2225 [ \u03a31Z11 \u03a31Z12 0 0 ] \u2212 [ \u03a31(J\u030311 \u2212 R\u030311)\u03a31 0 0 0 ]\u2225\u2225\u2225\u2225\u2225 2\nF = \u2225\u2225\u2225Z\u03031 \u2212 \u03a31(J\u030311 \u2212 R\u030311)\u03a31\u2225\u2225\u22252F + \u2225\u2225\u2225Z\u03032\u2225\u2225\u22252F .\n12 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?\nWe immediately notice that J\u030321, J\u030322, R\u030321, and R\u030322 do not influence the objective function and can thus be chosen arbitrarily (provided that J\u030322 = \u2212J\u0303 T22 and R\u0303 \u2208 S n\u0303 ). For our further construction we set them to zero, in agreement with (3.7). It thus suffices to minimize over all skew-symmetric matrices J\u030311 \u2208 Rr\u00d7r and all R\u030311 \u2208 Sr . Thus, using Lemma 3.10, we obtain\nmin J\u0303=\u2212J\u0303 T, R\u0303\u2208Sn\u0303\n\u2225\u2225\u2225T TZ \u2212 T T(J\u0303 \u2212 R\u0303)T \u2225\u2225\u22252 F\n= min J\u030311=\u2212J\u0303 T11, R\u030311\u2208Sr \u2225\u2225\u2225Z\u03031 \u2212 \u03a31(J\u030311 \u2212 R\u030311)\u03a31\u2225\u2225\u22252F + \u2225\u2225\u2225Z\u03032\u2225\u2225\u22252F = min R\u030311\u2208Sr\n\u2225\u2225\u2225Z\u03031 \u2212 \u03a31(J\u0303 ?11 \u2212 R\u030311)\u03a31\u2225\u2225\u22252F + \u2225\u2225\u2225Z\u03032\u2225\u2225\u22252F = min R\u030311\u2208Sr\n\u2225\u2225\u2225sym(Z\u03031) + \u03a31R\u030311\u03a31\u2225\u2225\u22252F + \u2225\u2225\u2225Z\u03032\u2225\u2225\u22252F = \u2225\u2225\u2225sym(Z\u03031) + \u03a31R\u0303?11\u03a31\u2225\u2225\u2225F + \u2225\u2225\u2225Z\u03032\u2225\u2225\u22252F = \u2016\u039b+\u20162F + \u2225\u2225\u2225Z\u03032\u2225\u2225\u22252F .\nIt remains to show that J\u0303 ? and R\u0303? are the minimizers with minimal norm. To this end, let J\u0303 = \u2212J\u0303 T \u2208 Rn\u0303\u00d7n\u0303 and R\u0303 \u2208 S n\u0303 be further minimizers of (3.6). Then\u2225\u2225\u2225J\u0303 \u2225\u2225\u2225 F = \u2225\u2225\u2225WTJ\u0303W\u2225\u2225\u2225 F = \u2225\u2225\u2225\u2225\u2225 [ J\u030311 \u2212J\u0303 T12 J\u030321 J\u030322 ]\u2225\u2225\u2225\u2225\u2225 F .\nLemma 3.10 implies J\u030311 = J\u0303 ?11, and thus\u2225\u2225\u2225J\u0303 \u2225\u2225\u2225 F = \u2225\u2225\u2225\u2225\u2225 [ J\u0303 ?11 \u2212J\u0303 T12 J\u030321 J\u030322 ]\u2225\u2225\u2225\u2225\u2225 F \u2265 \u2225\u2225\u2225\u2225\u2225 [ J\u0303 ?11 0 0 0 ]\u2225\u2225\u2225\u2225\u2225 F = \u2225\u2225\u2225W J\u0303 ?W\u2225\u2225\u2225 F = \u2225\u2225\u2225J\u0303 ?\u2225\u2225\u2225 F .\nA similar argument shows \u2225\u2225\u2225R\u0303\u2225\u2225\u2225 F \u2265 \u2225\u2225\u2225R\u0303?\u2225\u2225\u2225 F , which completes the proof.\n3.4. Relation between the optimization problems. In this subsection we discuss the relation between the original pHDMD optimization Problem 3.1 and the weighted Problem 3.6 discussed in the previous section. We immediately obtain the following result, which showcases that whenever the data is sufficiently rich, then the cost functional of the projected optimization problem (3.6) provides an upper bound for the original minimization problem (3.1).\nLemma 3.11. For given Z, T \u2208 Rn\u0303\u00d7M\u0303 with rank(T ) = n\u0303 there exists a constant c > 0 such that for every J\u0303 , R\u0303 \u2208 Rn\u0303\u00d7n\u0303 we have\u2225\u2225\u2225Z \u2212 (J\u0303 \u2212 R\u0303)T \u2225\u2225\u2225\nF \u2264 c \u2225\u2225\u2225T TZ \u2212 T T(J\u0303 \u2212 R\u0303)T \u2225\u2225\u2225 F . (3.12)\nProof. Let T = V \u03a3WT denote the singular value decomposition of T . We then have T \u2020 = W\u03a3\u2020V T. Define c := \u2016T \u2020\u2016F = \u2016\u03a3\u2020\u2016F. Using rank T = n\u0303, we conclude \u03a3\u2020\u03a3 = In\u0303. Let J\u0303 , R\u0303 \u2208 Rn\u0303\u00d7n\u0303. Then\u2225\u2225\u2225Z \u2212 (J\u0303 \u2212 R\u0303)T \u2225\u2225\u2225 F = \u2225\u2225\u2225V V T(Z \u2212 (J\u0303 \u2212 R\u0303)T )\u2225\u2225\u2225 F = \u2225\u2225\u2225(T T)\u2020T T(Z \u2212 (J\u0303 \u2212 R\u0303)T )\u2225\u2225\u2225 F\n\u2264 \u2225\u2225\u2225(T T)\u2020\u2225\u2225\u2225\nF \u2225\u2225\u2225T TZ \u2212 T T(J\u0303 \u2212 R\u0303)T \u2225\u2225\u2225 F ,\nwhich completes the proof.\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 13\nIf T has not full row rank, i.e., rank(T ) < n\u0303, then we cannot expect to obtain a similar result, in particular if we use the minimum norm-minimizers from Theorem 3.7. The main reason for this behavior is that in this case, using the notation as in (3.11), we project out the data corresponding to Z21 and Z22. While the latter corresponds, similarly as Z12 to too much data, the contribution Z21 corresponds to the components J\u030321 \u2212 R\u030321, which are set zero in Theorem 3.7. In more detail, using the notation as in (3.11), we obtain for J\u0303 = \u2212J\u0303 T \u2208 Rn\u0303\u00d7n\u0303 and R\u0303 \u2208 S n\u0303 \u2225\u2225\u2225Z \u2212 (J\u0303 \u2212 R\u0303)T \u2225\u2225\u2225\nF = \u2225\u2225\u2225\u2225\u2225 [ V T1 V T2 ] Z [ W1 W2 ] \u2212 [ V T1 V T2 ] (J\u0303 \u2212 R\u0303) [ V1 V2 ] [\u03a31 0 0 0 ]\u2225\u2225\u2225\u2225\u2225 F\n= \u2225\u2225\u2225\u2225\u2225 [ Z11 Z12 Z21 Z22 ] \u2212 [ J\u030311 \u2212 R\u030311 \u2212J\u0303 T21 \u2212 R\u0303T12 J\u030321 \u2212 R\u030321 J\u030322 \u2212 R\u030322 ] [ \u03a31 0 0 0 ]\u2225\u2225\u2225\u2225\u2225 F\n= \u2225\u2225\u2225\u2225\u2225 [ Z11 \u2212 (J\u030311 \u2212 R\u030311)\u03a31 Z12 Z21 \u2212 (J\u030321 \u2212 R\u030321)\u03a31 Z22 ]\u2225\u2225\u2225\u2225\u2225 F .\nThus, whenever we find J\u030321, R\u030321 such that Z21\u03a3\u221211 = J\u030321 \u2212 R\u030321 we only have to ensure that J\u0303 remains skew-symmetric and R\u0303 remains symmetric positive semi-definite. A simple way to achieve this is via the choice\nJ\u0303 ?21 := Z21\u03a3\u221211 and R\u0303?21 = 0. (3.14)\nIn view of Algorithm 1, where we only require an initialization for R\u0303, we can directly use the result of Theorem 3.7. Nevertheless, in our numerical experiments, we observe that the initialization with J\u0303 ? and R\u0303? with the modification from (3.14) already yields promising results such that they can be used even without a further application of Algorithm 1. However, in general these are not the optimal choices as the next example illustrates.\nExample 3.12. Consider again Example 3.9 with the minimizers of the weighted problem J\u0303 ? and R\u0303? as presented in (3.9). We obtain \u2225\u2225\u2225Z \u2212 (J\u0303 ? \u2212 R\u0303?)T \u2225\u2225\u2225 F = \u221a 5 2 for the original pHDMD minimization problem. Nevertheless, for\nJ\u0303 (1) = [\n0 \u2212 15 1 5 0 ] we obtain \u2225\u2225\u2225Z \u2212 (J\u0303 (1) \u2212 R\u0303?)T \u2225\u2225\u2225 F = \u221a 200 105 < \u221a 5 2 , detailing that J\u0303 ? is not the optimal choice."
        },
        {
            "heading": "4. Numerical experiments",
            "text": "In this section, we demonstrate the theoretical discussion on two exemplary portHamiltonian systems. The first one is a Mass-Spring-Damper system taken from [18] and the second one is a linear poroelastic network model; for details see [1]. For our numerical experiments, we stop Algorithm 1 whenever\u2225\u2225J\u0303 (k+1)\u2212J\u0303 (k)\u2225\u2225\nF\u2225\u2225J\u0303 (k+1)\u2225\u2225 F\n+ \u2225\u2225R\u0303(k+1)\u2212R\u0303(k)\u2225\u2225\nF\u2225\u2225R\u0303(k+1)\u2225\u2225 F \u2264 \u03b5\nwith prescribed tolerance \u03b5. In our experiments, we use \u03b5 := 1e\u221210. To report the progress during our iterative method, we introduce the relative values of the cost functional of\n14 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?\nProblem 3.1 and Problem 3.6, which we denote by f(J\u0303 (k), R\u0303(k)) = \u2225\u2225Z\u2212(J\u0303 (k)\u2212R\u0303(k))T \u2225\u2225\nF \u2016Z\u2016F\nand fT (J\u0303 (k), R\u0303(k)) = \u2225\u2225T TZ\u2212T T(J\u0303 (k)\u2212R\u0303(k))T \u2225\u2225\nF \u2016T TZ\u2016F ,\nrespectively. Moreover, since we are working with academic toy examples, we report the H2 and H\u221e errors for the identified systems, defined as\n\u2016G\u2016H2 = ( 1\n2\u03c0 \u222b \u221e \u2212\u221e \u2016G(\u0131\u03c9)\u20162F d\u03c9 ) 1 2 and \u2016G\u2016H\u221e = sup \u03c9\u2208R \u2016G(\u0131\u03c9)\u2016F ,\nwith G is the transfer function of the error system. Note that these errors require access to the original linear time-invariant system, which of course is not available in practical applications.\nRemark 4.1. To have a fair comparison of our method with OI, we use also the implicit midpoint information as defined in Problem 3.1 for OI in all our numerical examples.\n4.1. SISO Mass-Spring-Damper system. In our first experiment, we want to identify the Mass-Spring-Damper system, visualized in Figure 1 with masses mi, spring constants ki and damping constants ci \u2265 0 for i = 1, . . . , n2 . A minimal realization of the MassSpring-Damper system, as pH system (2.7) for the order n = 6, which corresponds to three masses, three springs and three dampers is given by\nH\u0302 =  k1 0 \u2212k1 0 0 0 0 1 m1 0 0 0 0 \u2212k1 0 k1+k2 0 \u2212k2 0 0 0 0 1 m2 0 0\n0 0 \u2212k2 0 k2+k3 0 0 0 0 0 0 1\nm3\n , J\u0302 =  0 k1 m1\n0 \u2212 k1 m2\n0 0\n\u2212 k1 m1 0 k1 m1\n0 0 0\n0 \u2212 k1 m1\n0 k1+k2 m2\n0 \u2212 k2 m3\nk1 m2\n0 \u2212 k1+k2 m2 0 k2 m2\n0\n0 0 0 \u2212 k2 m2\n0 k2+k3 m3\n0 0 k2 m3\n0 \u2212 k2+k3 m3 0\n ,\nR\u0302 = diag(0, c1 m21 , 0, c2 m22 , 0, c3 m23 ), G\u0302T = [ 0 1m1 0 0 0 0 ] ,\nand P = 0, S = 0, N = 0. The parameter of the masses, springs and damper are chosen as mi = 4, ki = 4, and ci = 1 for i = 1, . . . , 3. The generation of the training data (xi, ui, yi) for i = 0, 1, . . . ,M takes place via the implicit midpoint rule. We collect M = 100 snapshots by running the simulation for 4 s, i.e., we set \u03b4t = 125 . A suitable training input is u(t) = exp(\u2212 t2) sin(t 2), since it has increasing frequency to excite the\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 15\nmodel. With the collected data in place, Algorithm 1 with r\u0303 = n and \u03a6 = In is performed using the initialization from Theorem 3.7. The algorithm terminates after the first iteration. The evolution of the optimization is shown in Table 1, where the values for fT , f , and the relative H2 and relative H\u221e errors are displayed in each iteration. We emphasize that the\ninitialization yields a fairly good approximation of the minimizer, which is only slightly improved with Algorithm 1. Moreover, since in this scenario the rank of T = n\u0303, according to Lemma 3.11 the optimal value of Problem 3.6 provides an upper bound to Problem 3.1,\u2225\u2225\u2225Z \u2212 (J\u0303 (0) \u2212 R\u0303(0))T \u2225\u2225\u2225\nF \u2264 c \u2225\u2225\u2225T Z \u2212 T (J\u0303 (0) \u2212 R\u0303(0))T \u2225\u2225\u2225 F = 1.31\u00d7 10\u221211 (4.1)\nwith c = 2.49\u00d7 103. The original and identified models are simulated for the testing input, shown in Figure 2b, for 10 s, i.e., on a longer time horizon than during the training. We compare the result of our method with the result of the standard DMD approach, where DMD identifies a discrete-time LTI system. The resulting outputs y\u0303DMD resp. y\u0303pHDMD and their absolute error to the original output trajectory y are presented in Figure 3. We notice that DMD identifies an unstable system with five (out of 6) unstable eigenvalues. This can not happen with our method, which guarantees that the identified system is stable. However, if we decrease the stepsize, e.g., to \u03b4t = 1\u00d7 10\u22124, yielding a total of M = 40000 data points, DMD is also able to identify a stable system. Nevertheless, the error of DMD is still significantly larger than pHDMD; see Figure 4a. Let us emphasize that the results of pHDMD are, at least in parts, attributed to the generation of the data with the implicit midpoint rule. If we use a different time discretization scheme instead, for instance, the Runge-Kutta 45 (RK45) method, then the approximation quality of pHDMD reduces several orders of magnitudes; see Figure 4b. The reason for this behavior is that the data generated by RK45 does not satisfy the discrete dissipation inequality (2.11). As\n16 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?\nbefore, applying DMD to data generated by evaluating the RK45 solution on a grid with the larger step size \u03b4t = 4.00\u00d7 10\u22122 yields an unstable system (cf. Figure 4b). If we use RK45 with the small step size, then DMD produces a slightly better approximation than pHDMD.\n4.2. SISO Mass-Spring-Damper system with noisy data. We repeat the experiment from Section 4.1 but add noise to the data. In particular, we add Gaussian noise with a standard deviation s = 1\u00d7 10\u22124 to the training data (xi, yi) and compare the results of our method with the results of OI, which also identifies a continuous time LTI system. The comparison is displayed in Figure 5. We observe that the error of OI increases over time while the error of pHDMD remains small. This is again because OI identifies an unstable system. In contrast, our method guarantees that the identified system is stable. We want to emphasize that the same argument holds for passivity\n4.3. MIMO Mass-Spring-Damper system. In this subsection, we apply the proposed dimensionality reduction to the Mass-Spring-Damper system with increased order n = 100. We also add a second input u2 (and consequently also a second output), which is applied to\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 17\nm2 the same way as u1 to m1 in Figure 1. We decrease \u03b4t to generate sufficiently rich data. As training input we use u1(t) = exp(\u2212 t2) sin(t 2) and u2(t) = exp(\u2212 t2) cos(t 2). In Figure 6, we compare our method with reduced OI and proper orthogonal decomposition (POD) by plotting the relative H2 error for different values of r\u0303. Moreover, we perturb the data by adding Gaussian noise with standard deviation s. We observe that the H2 error of the\nnon-intrusive reduced models is fairly close to the H2 error of the reduced POD model for both pHDMD and OI whenever the noise is sufficiently small.\n4.4. MIMO port-Hamiltonian Poroelastic Network Model. In our final experiment, we apply our algorithm to a linear poroelasticity problem and use the pH formulation\n18 RICCARDO MORANDIN\u2020, JONAS NICODEMUS?, AND BENJAMIN UNGER?\ndiscussed in [1], see also [12]. The model has an order of n = 980, with two inputs and two outputs (m = 2). We generate M = 10000 snapshots with the same settings as before and obtain rank(T ) = 100 < n\u0303 = 982. Hence, we cannot expect to identify the complete system dynamics. Nevertheless, Algorithm 1 yields matrices J\u0303 ?, R\u0303? with f(J\u0303 ?, R\u0303?) = 7.11\u00d7 10\u22129, i.e., Problem 3.1 is solved fairly accurately. To verify the approximation quality, we simulate the identified system with the testing input Figure 2b, then we approximately recover the true output as reported in Figure 7a for the first 0.1 s with the corresponding absolute error displayed in Figure 7b. For the full simulation until 10 s the identified system results in a\nrelative L2 error between the output of the original system and the output of the identified system of 2.95\u00d7 10\u22122 and a relative L\u221e error of 2.37\u00d7 10\u22122. In comparison, if we use the training input, then the relative L2 and L\u221e errors are 5.39\u00d7 10\u22128 and 3.47\u00d7 10\u22127, respectively."
        },
        {
            "heading": "5. Conclusions",
            "text": "We have developed a physics-informed system identification and dimensionality reduction algorithm that uses time-domain samples of the input, state, and output to infer a linear continuous-time dynamical system. Our algorithm is physics-informed in the sense that for a prescribed energy functional, the identified system is guaranteed to satisfy a dissipation inequality along any solution of the system. Hence, the identified system is guaranteed to be stable and passive independently of the data used for the identification. To achieve this goal, we present a generalization of dynamic mode decomposition and operator inference to port-Hamiltonian systems. The resulting method is an iterative algorithm based on a fast gradient method. For the initialization, we study a weighted problem, where we use the dominant information of the data as a weighting factor. For the weighted problem, we derive the analytical solution and detail in the numerical examples that the initialization is close to the optimum.\nAcknowledgments. The work of R. Morandin is funded by the Deutsche Forschungsgemeinschaft (DFG) within the CRC/Transregio 154 Mathematical Modelling, Simulation and Optimization using the Example of Gas Networks and the Werner-Von-Siemens Centre for Industry and Science within the project Maintenance, Repair & Overhaul. J. Nicodemus\nPORT-HAMILTONIAN DYNAMIC MODE DECOMPOSITION 19\nand B. Unger acknowledge funding from the DFG under Germany\u2019s Excellence Strategy \u2013 EXC 2075 \u2013 390740016 and are thankful for support by the Stuttgart Center for Simulation Science (SimTech). The authors like to thank the anonymous referees for valuable comments that significantly improved the manuscript."
        }
    ],
    "year": 2023
}