{
    "abstractText": "We propose a numerical algorithm for computing approximately optimal solutions of the matching for teams problem. Our algorithm is efficient for problems involving a large number of agent categories and allows for the measures describing the agent types to be non-discrete. Specifically, we parametrize the so-called transfer functions and develop a parametric version of the dual formulation. Our algorithm tackles this parametric formulation and produces feasible and approximately optimal solutions for the primal and dual formulations of the matching for teams problem. These solutions also yield upper and lower bounds for the optimal value, and the difference between the upper and lower bounds provides a direct sub-optimality estimate of the computed solutions. Moreover, we are able to control a theoretical upper bound on the sub-optimality to be arbitrarily close to 0 under mild conditions. We subsequently prove that the approximate primal and dual solutions converge when the sub-optimality goes to 0 and their limits constitute a true matching equilibrium. Thus, the outputs of our algorithm are regarded as an approximate matching equilibrium. We also analyze the theoretical computational complexity of our parametric formulation as well as the sparsity of the resulting approximate matching equilibrium. Through numerical experiments, we showcase that the proposed algorithm can produce high-quality approximate matching equilibria and is applicable to versatile settings, including a high-dimensional setting involving 100 agent categories.",
    "authors": [],
    "id": "SP:df87cb082047a0429ac7fcc9beb09bcc05183783",
    "references": [
        {
            "authors": [
                "M. Agueh",
                "G. Carlier"
            ],
            "title": "Barycenters in the Wasserstein space",
            "venue": "SIAM J. Math. Anal., 43(2): 904\u2013924",
            "year": 2011
        },
        {
            "authors": [
                "A. Alfonsi",
                "R. Coyaud",
                "V. Ehrlacher",
                "D. Lombardi"
            ],
            "title": "Approximation of optimal transport problems with marginal moments constraints",
            "venue": "Math. Comp., 90(328):689\u2013737",
            "year": 2021
        },
        {
            "authors": [
                "J.M. Altschuler",
                "E. Boix-Adser\u00e0"
            ],
            "title": "Wasserstein barycenters can be computed in polynomial time in fixed dimension",
            "venue": "J. Mach. Learn. Res.,",
            "year": 2021
        },
        {
            "authors": [
                "J.M. Altschuler",
                "E. Boix-Adser\u00e0"
            ],
            "title": "Wasserstein barycenters are NP-hard to compute",
            "venue": "SIAM J. Math. Data Sci., 4(1):179\u2013203",
            "year": 2022
        },
        {
            "authors": [
                "J.M. Altschuler",
                "E. Boix-Adser\u00e0"
            ],
            "title": "Polynomial-time algorithms for multimarginal optimal transport problems with structure",
            "venue": "Math. Program., 199(1-2):1107\u20131178",
            "year": 2023
        },
        {
            "authors": [
                "P.C. \u00c1lvarez-Esteban"
            ],
            "title": "E",
            "venue": "del Barrio, J. A. Cuesta-Albertos, and C. Matr\u00e1n. A fixed-point approach to barycenters in Wasserstein space. J. Math. Anal. Appl., 441(2):744\u2013762",
            "year": 2016
        },
        {
            "authors": [
                "E. Anderes",
                "S. Borgwardt",
                "J. Miller"
            ],
            "title": "Discrete Wasserstein barycenters: Optimal transport for discrete data",
            "venue": "Math. Methods Oper. Res., 84(2):389\u2013409",
            "year": 2016
        },
        {
            "authors": [
                "F.A. Ba",
                "M. Quellmalz"
            ],
            "title": "Accelerating the Sinkhorn algorithm for sparse multi-marginal optimal transport via fast Fourier transforms",
            "venue": "Algorithms, 15(9):311",
            "year": 2022
        },
        {
            "authors": [
                "C. Bayer",
                "J. Teichmann"
            ],
            "title": "The proof of Tchakaloff\u2019s theorem",
            "venue": "Proc. Amer. Math. Soc., 134 (10):3035\u20133040",
            "year": 2006
        },
        {
            "authors": [
                "J.-D. Benamou"
            ],
            "title": "Optimal transportation",
            "venue": "modelling and numerical simulation. Acta Numer., 30: 249\u2013325",
            "year": 2021
        },
        {
            "authors": [
                "J.-D. Benamou",
                "G. Carlier",
                "M. Cuturi",
                "L. Nenna",
                "G. Peyr\u00e9"
            ],
            "title": "Iterative Bregman projections for regularized transportation problems",
            "venue": "SIAM J. Sci. Comput., 37(2):A1111\u2013A1138",
            "year": 2015
        },
        {
            "authors": [
                "D.P. Bertsekas",
                "S.E. Shreve"
            ],
            "title": "Stochastic optimal control: the discrete time case",
            "venue": "volume 139 of Mathematics in Science and Engineering. Academic Press, Inc. [Harcourt Brace Jovanovich, Publishers], New York-London",
            "year": 1978
        },
        {
            "authors": [
                "O. Besbes",
                "F. Castro",
                "I. Lobel"
            ],
            "title": "Surge pricing and its spatial supply response",
            "venue": "Management Science, 67(3):1350\u20131367",
            "year": 2021
        },
        {
            "authors": [
                "J. Bigot",
                "E. Cazelles",
                "N. Papadakis"
            ],
            "title": "Penalization of barycenters in the Wasserstein space",
            "venue": "SIAM J. Math. Anal., 51(3):2261\u20132285",
            "year": 2019
        },
        {
            "authors": [
                "A. Blanchet",
                "G. Carlier"
            ],
            "title": "Optimal transport and Cournot-Nash equilibria",
            "venue": "Math. Oper. Res., 41(1):125\u2013145",
            "year": 2016
        },
        {
            "authors": [
                "A. Blanchet",
                "P. Mossay",
                "F. Santambrogio"
            ],
            "title": "Existence and uniqueness of equilibrium for a spatial model of social interactions",
            "venue": "Internat. Econom. Rev., 57(1):31\u201359",
            "year": 2016
        },
        {
            "authors": [
                "S. Borgwardt"
            ],
            "title": "An LP-based",
            "venue": "strongly-polynomial 2-approximation algorithm for sparse Wasserstein barycenters. Int. J. Oper. Res., 22(2):1511\u20131551",
            "year": 2022
        },
        {
            "authors": [
                "S. Borgwardt",
                "S. Patterson"
            ],
            "title": "A column generation approach to the discrete barycenter problem",
            "venue": "Discrete Optim., 43:100674",
            "year": 2022
        },
        {
            "authors": [
                "S. Borgwardt",
                "S. Patterson"
            ],
            "title": "An integer program for pricing support points of exact barycenters",
            "venue": "Preprint, arXiv:2210.14135",
            "year": 2022
        },
        {
            "authors": [
                "G. Buttazzo",
                "F. Santambrogio"
            ],
            "title": "A model for the optimal planning of an urban area",
            "venue": "SIAM J. Math. Anal., 37(2):514\u2013530",
            "year": 2005
        },
        {
            "authors": [
                "G. Carlier",
                "I. Ekeland"
            ],
            "title": "The structure of cities",
            "venue": "Journal of Global Optimization, 29(4): 371\u2013376",
            "year": 2004
        },
        {
            "authors": [
                "G. Carlier",
                "I. Ekeland"
            ],
            "title": "Matching for teams",
            "venue": "Econom. Theory, 42(2):397\u2013418",
            "year": 2010
        },
        {
            "authors": [
                "G. Carlier",
                "F. Santambrogio"
            ],
            "title": "A variational model for urban planning with traffic congestion",
            "venue": "ESAIM Control Optim. Calc. Var., 11(4):595\u2013613",
            "year": 2005
        },
        {
            "authors": [
                "G. Carlier",
                "A. Oberman",
                "E. Oudet"
            ],
            "title": "Numerical methods for matching for teams and Wasserstein barycenters",
            "venue": "ESAIM Math. Model. Numer. Anal., 49(6):1621\u20131642",
            "year": 2015
        },
        {
            "authors": [
                "S. Chewi",
                "T. Maunu",
                "P. Rigollet",
                "A.J. Stromme"
            ],
            "title": "Gradient descent algorithms for Bures- Wasserstein barycenters",
            "venue": "Conference on Learning Theory, pages 1276\u20131304. PMLR",
            "year": 2020
        },
        {
            "authors": [
                "L. Chizat"
            ],
            "title": "Doubly regularized entropic Wasserstein barycenters",
            "venue": "Preprint, arXiv:2303.11844",
            "year": 2023
        },
        {
            "authors": [
                "S. Claici",
                "E. Chien",
                "J. Solomon"
            ],
            "title": "Stochastic Wasserstein barycenters",
            "venue": "In Proceedings of the 35th International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "S. Cohen",
                "M. Arbel",
                "M.P. Deisenroth"
            ],
            "title": "Estimating barycenters of measures in high dimensions",
            "venue": "Preprint, arXiv:2007.07105",
            "year": 2020
        },
        {
            "authors": [
                "D. Coppersmith",
                "S. Winograd"
            ],
            "title": "Matrix multiplication via arithmetic progressions",
            "venue": "J. Symbolic Comput., 9(3):251\u2013280",
            "year": 1990
        },
        {
            "authors": [
                "M. Cuturi"
            ],
            "title": "Sinkhorn distances: Lightspeed computation of optimal transport",
            "venue": "Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2, NIPS\u201913, page 2292\u20132300, Red Hook, NY, USA",
            "year": 2013
        },
        {
            "authors": [
                "L. De Gennaro Aquino",
                "C. Bernard"
            ],
            "title": "Bounds on multi-asset derivatives via neural networks",
            "venue": "Int. J. Theor. Appl. Finance,",
            "year": 2020
        },
        {
            "authors": [
                "L. De Gennaro Aquino",
                "S. Eckstein"
            ],
            "title": "MinMax methods for optimal transport and beyond: Regularization, approximation and numerics",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "J. Eckstein"
            ],
            "title": "A simplified form of block-iterative operator splitting and an asynchronous algorithm resembling the multi-block alternating direction method of multipliers",
            "venue": "J. Optim. Theory Appl., 173(1):155\u2013182",
            "year": 2017
        },
        {
            "authors": [
                "S. Eckstein",
                "M. Kupper"
            ],
            "title": "Computation of optimal transport and related hedging problems via penalization and neural networks",
            "venue": "Appl. Math. Optim., 83(2):639\u2013667",
            "year": 2021
        },
        {
            "authors": [
                "S. Eckstein",
                "M. Nutz"
            ],
            "title": "Quantitative stability of regularized optimal transport and convergence of Sinkhorn\u2019s algorithm",
            "venue": "SIAM J. Math. Anal., 54(6):5922\u20135948",
            "year": 2022
        },
        {
            "authors": [
                "S. Eckstein",
                "M. Kupper",
                "M. Pohl"
            ],
            "title": "Robust risk aggregation with neural networks",
            "venue": "Mathematical Finance, 30(4):1229\u20131272",
            "year": 2020
        },
        {
            "authors": [
                "S. Eckstein",
                "G. Guo",
                "T. Lim",
                "J. Ob\u0142\u00f3j"
            ],
            "title": "Robust pricing and hedging of options on multiple assets and its numerics",
            "venue": "SIAM J. Financial Math., 12(1):158\u2013188",
            "year": 2021
        },
        {
            "authors": [
                "J. Fan",
                "A. Taghvaei",
                "Y. Chen"
            ],
            "title": "Scalable computations of Wasserstein barycenter via input convex neural networks",
            "venue": "Preprint, arXiv:2007.04462",
            "year": 2020
        },
        {
            "authors": [
                "G. Friesecke",
                "A.S. Schulz",
                "D. V\u00f6gler"
            ],
            "title": "Genetic column generation: Fast computation of high-dimensional multimarginal optimal transport problems",
            "venue": "SIAM J. Sci. Comput., 44(3): A1632\u2013A1654",
            "year": 2022
        },
        {
            "authors": [
                "D. Ge",
                "H. Wang",
                "Z. Xiong",
                "Y. Ye"
            ],
            "title": "Interior-point methods strike back: Solving the Wasserstein barycenter problem",
            "venue": "Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.",
            "year": 2019
        },
        {
            "authors": [
                "M.A. Goberna",
                "M.A. L\u00f3pez"
            ],
            "title": "Linear semi-infinite optimization",
            "venue": "John Wiley & Sons",
            "year": 1998
        },
        {
            "authors": [
                "G. Guo",
                "J. Ob\u0142\u00f3j"
            ],
            "title": "Computational methods for martingale optimal transport problems",
            "venue": "Ann. Appl. Probab., 29(6):3311\u20133347",
            "year": 2019
        },
        {
            "authors": [
                "F. Heinemann",
                "A. Munk",
                "Y. Zemel"
            ],
            "title": "Randomized Wasserstein barycenter computation: Resampling with statistical guarantees",
            "venue": "SIAM J. Math. Data Sci., 4(1):229\u2013259",
            "year": 2022
        },
        {
            "authors": [
                "P. Henry-Labord\u00e8re"
            ],
            "title": "Martingale) optimal transport and anomaly detection with neural networks: A primal-dual algorithm",
            "venue": "Available at SSRN 3370910",
            "year": 2019
        },
        {
            "authors": [
                "A. Korotin",
                "L. Li",
                "J. Solomon",
                "E. Burnaev"
            ],
            "title": "Continuous Wasserstein-2 barycenter estimation without minimax optimization",
            "venue": "Preprint, arXiv:2102.01752",
            "year": 2021
        },
        {
            "authors": [
                "A. Korotin",
                "V. Egiazarian",
                "L. Li",
                "E. Burnaev"
            ],
            "title": "Wasserstein iterative networks for barycenter estimation",
            "venue": "Preprint, arXiv:2201.12245",
            "year": 2022
        },
        {
            "authors": [
                "R. Krawtschenko",
                "C.A. Uribe",
                "A. Gasnikov",
                "P. Dvurechensky"
            ],
            "title": "Distributed optimization with quantization for computing Wasserstein barycenters",
            "venue": "Preprint, arXiv:2010.14325",
            "year": 2020
        },
        {
            "authors": [
                "M. Kuang",
                "E.G. Tabak"
            ],
            "title": "Sample-based optimal transport and barycenter problems",
            "venue": "Comm. Pure Appl. Math., 72(8):1581\u20131630",
            "year": 2019
        },
        {
            "authors": [
                "B. L\u00e9vy"
            ],
            "title": "A numerical algorithm for L2 semi-discrete optimal transport in 3D",
            "venue": "ESAIM Math. Model. Numer. Anal., 49(6):1693\u20131715",
            "year": 2015
        },
        {
            "authors": [
                "L. Li",
                "A. Genevay",
                "M. Yurochkin",
                "J.M. Solomon"
            ],
            "title": "Continuous regularized Wasserstein barycenters",
            "venue": "Advances in Neural Information Processing Systems, volume 33, pages 17755\u2013 17765. Curran Associates, Inc.",
            "year": 2020
        },
        {
            "authors": [
                "T. Lin",
                "N. Ho",
                "M. Cuturi",
                "M.I. Jordan"
            ],
            "title": "On the complexity of approximating multimarginal optimal transport",
            "venue": "J. Mach. Learn. Res., 23(65):1\u201343",
            "year": 2022
        },
        {
            "authors": [
                "R.E. Lucas"
            ],
            "title": "Jr",
            "venue": "and E. Rossi-Hansberg. On the internal structure of cities. Econometrica, 70 (4):1445\u20131476",
            "year": 2002
        },
        {
            "authors": [
                "G. Luise",
                "S. Salzo",
                "M. Pontil",
                "C. Ciliberto"
            ],
            "title": "Sinkhorn barycenters with free support via Frank-Wolfe algorithm",
            "venue": "Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.",
            "year": 2019
        },
        {
            "authors": [
                "A. Neufeld",
                "Q. Xiang"
            ],
            "title": "Numerical method for approximately optimal solutions of two-stage distributionally robust optimization with marginal constraints",
            "venue": "Preprint, arXiv:2205.05315",
            "year": 2022
        },
        {
            "authors": [
                "A. Neufeld",
                "Q. Xiang"
            ],
            "title": "Numerical method for feasible and approximately optimal solutions of multi-marginal optimal transport beyond discrete measures",
            "venue": "Preprint, arXiv:2203.01633v3",
            "year": 2022
        },
        {
            "authors": [
                "M. Nutz",
                "J. Wiesel"
            ],
            "title": "Entropic optimal transport: convergence of potentials",
            "venue": "Probability Theory and Related Fields",
            "year": 2021
        },
        {
            "authors": [
                "G. Peyr\u00e9",
                "M. Cuturi"
            ],
            "title": "Computational optimal transport: With applications to data science",
            "venue": "Foundations and Trends in Machine Learning, 11(5-6):355\u2013607",
            "year": 2019
        },
        {
            "authors": [
                "G. Puccetti",
                "L. R\u00fcschendorf",
                "S. Vanduffel"
            ],
            "title": "On the computation of Wasserstein barycenters",
            "venue": "J. Multivariate Anal., 176:104581, 16",
            "year": 2020
        },
        {
            "authors": [
                "S.T. Rachev",
                "L. R\u00fcschendorf"
            ],
            "title": "Mass Transportation Problems: Volume I: Theory",
            "venue": "Springer Science & Business Media",
            "year": 1998
        },
        {
            "authors": [
                "R.T. Rockafellar"
            ],
            "title": "Convex analysis",
            "venue": "Princeton Mathematical Series, No. 28. Princeton University Press, Princeton, N.J.",
            "year": 1970
        },
        {
            "authors": [
                "S. Srivastava",
                "C. Li",
                "D.B. Dunson"
            ],
            "title": "Scalable Bayes via barycenter in Wasserstein space",
            "venue": "J. Mach. Learn. Res., 19(1):312\u2013346",
            "year": 2018
        },
        {
            "authors": [
                "M. Staib",
                "S. Claici",
                "J.M. Solomon",
                "S. Jegelka"
            ],
            "title": "Parallel streaming Wasserstein barycenters",
            "venue": "Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.",
            "year": 2017
        },
        {
            "authors": [
                "E.G. Tabak",
                "G. Trigila",
                "W. Zhao"
            ],
            "title": "Distributional barycenter problem through data-driven flows",
            "venue": "Pattern Recognition, 130:108795",
            "year": 2022
        },
        {
            "authors": [
                "N. Tupitsa",
                "P. Dvurechensky",
                "A. Gasnikov",
                "C.A. Uribe"
            ],
            "title": "Multimarginal optimal transport by accelerated alternating minimization",
            "venue": "2020 59th IEEE Conference on Decision and Control (CDC), pages 6132\u20136137. IEEE",
            "year": 2020
        },
        {
            "authors": [
                "P.M. Vaidya"
            ],
            "title": "A new algorithm for minimizing convex functions over convex sets",
            "venue": "Math. Program., 73(3):291\u2013341",
            "year": 1996
        },
        {
            "authors": [
                "R.J. Vanderbei"
            ],
            "title": "Linear programming\u2014foundations and extensions",
            "venue": "volume 285 of International Series in Operations Research & Management Science. Springer, Cham",
            "year": 2020
        },
        {
            "authors": [
                "C. Villani"
            ],
            "title": "Topics in optimal transportation",
            "venue": "volume 58 of Graduate Studies in Mathematics. American Mathematical Society, Providence, RI",
            "year": 2003
        },
        {
            "authors": [
                "C. Villani"
            ],
            "title": "Optimal transport: Old and new",
            "venue": "volume 338 of Grundlehren der mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]. Springer-Verlag, Berlin",
            "year": 2009
        },
        {
            "authors": [
                "J. von Lindheim"
            ],
            "title": "Simple approximative algorithms for free-support Wasserstein barycenters",
            "venue": "Comput. Optim. Appl.,",
            "year": 2023
        },
        {
            "authors": [
                "Y. Xie",
                "X. Wang",
                "R. Wang",
                "H. Zha"
            ],
            "title": "A fast proximal point method for computing exact Wasserstein distance",
            "venue": "Uncertainty in Artificial Intelligence, pages 433\u2013453. PMLR",
            "year": 2020
        },
        {
            "authors": [
                "L. Yang",
                "J. Li",
                "D. Sun",
                "K.-C. Toh"
            ],
            "title": "A fast globally linearly convergent algorithm for the computation of Wasserstein barycenters",
            "venue": "J. Mach. Learn. Res., 22:21\u201337",
            "year": 2021
        },
        {
            "authors": [
                "J. Ye",
                "P. Wu",
                "J.Z. Wang",
                "J. Li"
            ],
            "title": "Fast discrete distribution clustering using Wasserstein barycenter with sparse support",
            "venue": "IEEE Trans. Signal Process., 65(9):2317\u20132332",
            "year": 2017
        },
        {
            "authors": [
                "C. Zhang",
                "H. Qian",
                "J. Xie"
            ],
            "title": "An asynchronous decentralized algorithm for Wasserstein barycenter problem",
            "venue": "Preprint, arXiv:2304.11653",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "1. INTRODUCTION\nThe goal of this paper is to provide an algorithm which constructs approximately optimal solutions of the matching for teams problem in theoretical economics involving a large number of agent categories. The matching for teams problem was introduced by Carlier and Ekeland [22], and the setting is described as follows.\nAssumption 1.1 (Matching for teams [22, Section 2.4]). We make the following assumptions: (A1) For i = 1, . . . , N (where N \u2208 N), (Xi, dXi) is a compact metric1 space (with metric dXi) and\nX := X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN . (A2) (Z, dZ) is a compact metric space. (A3) For i = 1, . . . , N , \u00b5i \u2208 P(Xi) is a probability measure on Xi. (A4) For i = 1, . . . , N , ci : Xi \u00d7Z \u2192 R is continuous.\nUsing the terminologies of Carlier and Ekeland [22], the matching for teams problem describes an economic game involving N categories of agents (e.g., one category of consumer and N \u2212 1 categories of different producers), where the number of agents in each category is infinite. The spaces X1, . . . ,XN , referred to as type spaces, each represents the types of agents from a category. The space Z , referred to as the quality space, represents a type of indivisible good with various qualities. In category i, the distribution of agent types is characterized by the probability measure \u00b5i \u2208 P(Xi). Moreover, the function ci(xi, z) represents the cost for an agent with type xi \u2208 Xi to be matched to a unit of good with quality z \u2208 Z . In order for a unit of good with quality z \u2208 Z to be traded, one agent from each category must come together to form a team and exchange money within the team. The goal is to find a matching equilibrium defined as follows.\nKey words and phrases. matching for teams; optimal transport; linear semi-infinite optimization. AN gratefully acknowledges the financial support by his Nanyang Assistant Professorship Grant (NAP Grant) Machine\nLearning based Algorithms in Finance and Insurance. 1hence, (Xi, dXi) is a Polish space\n1\nar X\niv :2\n30 8.\n03 55\n0v 1\n[ m\nat h.\nO C\n] 7\nA ug\n2 02\n3"
        },
        {
            "heading": "2 A. NEUFELD AND Q. XIANG",
            "text": "Definition 1.2 (Matching equilibrium [22, Definition 1]). Let Assumption 1.1 hold. A matching equilibrium consists of continuous functions \u03c61, . . . , \u03c6N : Z \u2192 R, probability measures \u03b31, . . . , \u03b3N \u2208 P(Xi \u00d7Z), and a probability measure \u03bd \u2208 P(Z) such that:\n(ME1) for i = 1, . . . , N , \u03b3i \u2208 \u0393(\u00b5i, \u03bd), where \u0393(\u00b5i, \u03bd) denotes the set of couplings of \u00b5i and \u03bd, i.e., \u0393(\u00b5i, \u03bd) contains all probability measures on Xi \u00d7 Z whose marginals on Xi and Z are \u00b5i and \u03bd;\n(ME2) \u2211N\ni=1 \u03c6i(z) = 0 for all z \u2208 Z; (ME3) for i = 1, . . . , N , \u03c6cii (xi) + \u03c6i(z) = ci(xi, z) for \u03b3i-almost all (xi, z) \u2208 Xi \u00d7 Z , where\n\u03c6cii : Xi \u2192 R is called the ci-transform of \u03c6i and is defined by\n\u03c6cii (xi) := inf z\u2208Z\n{ ci(xi, z)\u2212 \u03c6i(z) } \u2200xi \u2208 Xi.\nIn Definition 1.2, \u03c6i(z) represents the amount of money received by an agent of category i when trading a unit of good with quality z \u2208 Z , \u03bd \u2208 P(Z) represents the distribution of the qualities of traded goods, and for i = 1, . . . , N , \u03b3i \u2208 \u0393(\u00b5i, \u03bd) describes the matching between agents of category i and different qualities of goods. The condition (ME1) ensures that every agent is matched to some good. The condition (ME2) is called the balance condition as it requires each team to be self-financed, e.g., all money paid by the consumers will be transferred to the producers. The condition (ME3) requires that an agent of type xi \u2208 Xi is matched to a unit of good with quality z only if z minimizes the net cost, i.e., z \u2208 argminz\u2032\u2208Z { ci(xi, z \u2032) \u2212 \u03c6i(z\u2032) }\n. In the following, we present two examples of the matching for teams problem.\nExample 1.3 (Application 1: equilibrium of business location distribution). Let us consider the study of the geographic distribution of a type of business in a city by modeling the location of business outlets as well as the employees\u2019 workplace choices as a game involving N player populations. In this game, the first N \u2212 1 player populations represent N \u2212 1 categories of employees and the N -th player population represents the business owners. Specifically, the set Z \u2282 R2 represents the locations (in longitude and latitude) in the city where business outlets could possibly be located at. For i = 1, . . . , N \u2212 1, the set Xi \u2282 R2 represents the locations in the city where the i-th category of employees can reside and \u00b5i \u2208 P(Xi) represents the distribution of the dwellings of the i-th category of employees. The set XN represents the possible locations of the suppliers of the business in the city and \u00b5N \u2208 P(XN ) denotes their geographic distribution. Moreover, for i = 1, . . . , N \u2212 1, the cost function ci(\u00b7, \u00b7) represents the commuting cost of the i-th category of employees, i.e., ci(xi, z) denotes the cost of commuting from an employee\u2019s home located at xi \u2208 Xi to a business outlet located at z \u2208 Z . Furthermore, the cost function cN : XN \u00d7 Z \u2192 R represents the restocking cost of a business outlet, i.e., cN (xN , z) denotes the cost of transporting goods from a supplier at xN \u2208 XN to a business outlet located at z \u2208 Z . Under this setting, we are interested in finding a matching equilibrium consisting of (\u03c6i : Z \u2192 R)i=1:N , ( \u03b3i \u2208 P(Xi \u00d7 Z) ) i=1:N\n, and \u03bd \u2208 P(Z). For i = 1, . . . , N \u2212 1, \u03c6i(z) denotes the amount of salary earned by an employee working at a business outlet located at z \u2208 Z . \u03c6N (z) denotes the negative of the total amount of salary paid out by a business outlet located at z \u2208 Z to the N \u2212 1 categories of employees. \u03bd \u2208 P(Z) describes the geographic distribution of the business outlets in the city and \u03b3N \u2208 P(XN \u00d7 Z) describes how the business outlets choose the suppliers to restock from. Moreover, for i = 1, . . . , N \u2212 1, \u03b3i \u2208 P(Xi \u00d7 Z) describes where the employees in the i-th category choose to work at depending on where they reside. At equilibrium, the condition \u03b3i \u2208 \u0393(\u00b5i, \u03bd) for i = 1, . . . , N \u2212 1 requires each employee to work at some business outlet, and the condition \u03b3N \u2208 \u0393(\u00b5N , \u03bd) requires each supplier to be supplying some business outlet. The balance condition \u2211N i=1 \u03c6i(z) = 0 for all z \u2208 Z ensures that the total amount of salary paid out by each business owner, i.e.,\u2212\u03c6N (z), is equal to the total amount of salary received by the N \u2212 1 categories of employees, i.e., \u2211N\u22121 i=1 \u03c6i(z). Finally, for i = 1, . . . , N , the condition \u03c6cii (xi) + \u03c6i(z) = ci(xi, z) for \u03b3i-almost all (xi, z) \u2208 Xi \u00d7 Z states that each employee acts rationally when choosing the workplace, i.e., an employee that resides at xi minimizes the commuting cost ci(xi, z) minus the salary \u03c6i(z) when deciding the workplace, and each business owner acts rationally when choosing the location of the business outlet, i.e., a business\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 3\nowner with supplier at xN minimizes the cost cN (xN , z) of transporting goods plus the total salary \u2212\u03c6N (z) paid out to the employees. In this application, the computation of matching equilibria can not only aid the business owners when choosing the locations of business outlets, but also help city planners to improve transportation efficiency in the city.\nExample 1.4 (Application 2: Wasserstein barycenter [1]). When X1 = . . . = XN = Z and ci(x, z) := \u03bbidZ(x, z) p for i = 1, . . . , N where p \u2208 [1,\u221e), \u03bbi > 0, and \u2211N\ni=1 \u03bbi = 1, an optimizer of (MT) is known as a barycenter of \u00b51, . . . , \u00b5N \u2208 P(Z) in the Wasserstein space of order p with weights \u03bb1, . . . , \u03bbN . The most widely studied setting is the 2-Wasserstein barycenter problem, where X1 = . . . = XN = Z \u2282 Rd and ci(x, z) := \u03bbi\u2225x\u2212 z\u222522.\nIn the following, for i = 1, . . . , N , and for \u00b5i \u2208 P(Xi), \u03bd \u2208 P(Z), let Wci(\u00b5i, \u03bd) denote the optimal transportation cost between \u00b5i and \u03bd under the cost function ci(\u00b7, \u00b7), i.e.,\nWci(\u00b5i, \u03bd) := inf \u03b3i\u2208\u0393(\u00b5i,\u03bd) {\u222b Xi\u00d7Z ci(x, z) \u03b3i(dx,dz) } .\nCarlier and Ekeland [22] have proved the existence of matching equilibria and characterized them via three optimization problems, as detailed below.\nTheorem 1.5 (Existence and characterization of matching equilibria [22, Section 4.2 & Proposition 1 & Theorem 3]). Let Assumption 1.1 hold. Then, the following statements hold.\n(i) There exist continuous functions \u03c6\u03031, . . . , \u03c6\u0303N : Z \u2192 R, probability measures \u03b3\u03031, . . . , \u03b3\u0303N \u2208 P(Xi \u00d7Z), and a probability measure \u03bd\u0303 \u2208 P(Z) that constitute a matching equilibrium. (ii) (\u03c6\u0303i)i=1:N , (\u03b3\u0303i)i=1:N , and \u03bd\u0303 are a matching equilibrium if and only if (ME1\u2019)\u2013(ME3\u2019) below hold:\n(ME1\u2019) \u03bd\u0303 is an optimizer of the following problem:\ninf \u03bd\u2208P(Z) { N\u2211 i=1 Wci(\u00b5i, \u03bd) } ; (MT)\n(ME2\u2019) (\u03c6\u0303i)i=1:N is an optimizer of the following problem:\nsup { N\u2211 i=1 \u222b Xi \u03c6cii d\u00b5i : (\u03c6i)i=1:N are continuous, N\u2211 i=1 \u03c6i = 0 } ; (MT\u2217)\n(ME3\u2019) for i = 1, . . . , N , \u03b3\u0303i is an optimizer of the following problem:\ninf \u03b3i\u2208\u0393(\u00b5i,\u03bd\u0303) {\u222b Xi\u00d7Z ci(x, z) \u03b3i(dx,dz) } . (MTcp)\n(iii) (MT) and (MT\u2217) have identical optimal values.\nOur objective is to develop a numerical algorithm for efficiently computing feasible and approximately optimal solutions of the problems (MT), (MT\u2217), and (MTcp) when the number N of agent categories is large, and to apply it to concrete applications. Moreover, we will show that the computed approximate optimizers, which are referred to as an approximate matching equilibrium, converge to a true matching equilibrium when their sub-optimality goes to 0.\nRelated work. It is well-known that the problem (MT) admits an equivalent multi-marginal optimal transport (MMOT) reformulation, which has been discussed by Carlier and Ekeland [22, Section 6]. There are numerous existing studies about the computation of MMOT and related problems. Many of these studies either only consider discrete measures (see, e.g., [5, 8, 11, 39, 52, 65]) or approximate the problems via discretization of non-discrete measures (see, e.g., [37, 42]). Some studies develop regularization-based methods for approximating MMOT and related problems involving non-discrete measures. These methods typically involve solving an infinite-dimensional optimization problem parametrized by deep neural networks; see, e.g., [31, 32, 34, 36, 45]. See also [30, 35, 57] for the theoretical properties of entropic regularization and the Sinkhorn algorithm. One downside of neural networks based methods is the challenge posed by the non-convexity of the objective function when"
        },
        {
            "heading": "4 A. NEUFELD AND Q. XIANG",
            "text": "training these neural networks, and there is hence no theoretical guarantee on the quality of the approximate solutions represented by trained neural networks. Recently, Alfonsi, Coyaud, Ehrlacher, and Lombardi [2] and Neufeld and Xiang [56] developed approximation schemes for MMOT problems via relaxation of the marginal constraints into finitely many linear constraints. In particular, Neufeld and Xiang [56] developed a numerical algorithm which is capable of constructing a feasible and approximately optimal solution of the MMOT problem and computing a sub-optimality estimate of the constructed solution. Our numerical approach, however, is tailored to the structure of the problems (MT), (MT\u2217), and (MTcp) without relying on the MMOT formulation.\nWe would like to point out some existing studies about equilibrium/optimal spatial structure described by measures that are similar to the application in Example 1.3. Lucas and Rossi-Hansberg [53] and Carlier and Ekeland [21] studied the equilibrium structure of a city by analyzing the equilibrium distribution of business and residential districts while considering the positive externality of labor. Buttazzo and Santambrogio [20] and Carlier and Santambrogio [23] considered the optimal structure of a city rather than the equilibrium structure, when taking the congestion effect into account. Blanchet and Carlier [15] analyzed the spatial equilibrium of agents\u2019 preferences for land in an economy. Blanchet, Mossay, and Santambrogio [16] used the notion of Cournot\u2013Nash equilibrium to model agents\u2019 choices of holiday destinations. Besbes, Castro, and Lobel [13] modeled the equilibrium in the interaction between drivers and customers in a ride-hailing platform.\nThe Wasserstein barycenter problem (i.e., Example 1.4) has recently become a highly active research area due to its widespread applications in statistical inference [14, 62], pattern recognition [64], image synthesis [49], clustering [73], and various other fields in machine learning. Most studies about the computation of Wasserstein barycenter focus on the case where \u00b51, . . . , \u00b5N are discrete measures with finite support; see, e.g., [3, 4, 7, 17\u201319, 40, 44, 59, 70\u201372]. Some notable theoretical results about the computation of discrete Wasserstein barycenter are listed below.\n\u2022 There exists a sparsely supported Wasserstein barycenter \u03bd\u0302 of \u00b51, . . . , \u00b5N with |supp(\u03bd\u0302)| \u2264\u2211N i=1 |supp(\u00b5i)|\u2212N+1 (where supp(\u00b7) denotes the support of a probability measure); see,\ne.g., [17, Proposition 1]. \u2022 Altschuler and Boix-Adsera\u0300 [3] showed that there exists a polynomial-time algorithm for the\nexact computation of discrete Wasserstein barycenter in any fixed dimensions. \u2022 Altschuler and Boix-Adsera\u0300 [4] showed that the exact computation of discrete Wasserstein\nbarycenter is NP-hard in the dimension of the underlying space Z .\nChizat [26], Luise, Salzo, Pontil, and Ciliberto [54], and Xie, Wang, Wang, and Zha [71] have developed regularization-based methods for approximating discrete Wasserstein barycenter. Moreover, there are also numerical methods for computing Wasserstein barycenter when \u00b51, . . . , \u00b5N are continuous. Some of these methods are only applicable to specific families of probability measures, such as Gaussian or the location-scatter family; see, e.g., [6, 25]. Some studies consider the case where the measures \u00b51, . . . , \u00b5N are unknown with sample access, and develop stochastic optimization algorithms for approximating a Wasserstein barycenter with fixed support; see, e.g., [27, 48, 63, 74]. Recently, numerical methods for continuous Wasserstein barycenter based on neural network parametrization or generative neural networks have been developed; see, e.g., [28, 38, 46, 47, 51]. These methods also suffer from the aforementioned downside of neural network based methods due to the non-convexity of the objective function, posing challenge to the subsequent theoretical analyses.\nCarlier, Oberman, and Oudet [24] proposed a numerical method for (MT) with general cost functions c1, . . . , cN . After discretizing the underlying spaces X1, . . . ,XN ,Z , they developed a linear programming approximation of (MT) where the number of decision variables scale linearly with the number N of agent categories. They subsequently prove the convergence of their computed approximate optimizers to an optimizer of (MT). By discretizing X1, . . . ,XN ,Z , Carlier et al. [24] also developed another numerical method for approximating (MT\u2217) in the 2-Wasserstein barycenter case by a non-smooth concave maximization problem. From an optimizer of this non-smooth concave maximization problem, they are able to reconstruct an approximate optimizer of (MT) whose support lies in a pre-specified set based on the discretization of Z .\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 5\nCompared to existing methods for the computation of matching for teams and Wasserstein barycenter, our numerical approach is applicable to general cost functions c1, . . . , cN as well as general probability measures \u00b51, . . . , \u00b5N that are not necessarily discrete and not restricted to any family of measures. The approximate optimizers of (MT) constructed through our approach do not have prespecified support. Thus, our approach belongs to the so-called free support approaches. When the measures \u00b51, . . . , \u00b5N are continuous, our approach produces two approximate optimizers of (MT): one is a discrete measure with sparse support, and the other is a continuous measure. Moreover, our approach simultaneously constructs feasible and approximately optimal solutions of (MT), (MT\u2217), and (MTcp). The feasibility of these solutions provides us with upper and lower bounds for the optimal value of (MT) and (MT\u2217) that can be computed by our numerical algorithm. Most importantly, the difference between the computed upper and lower bounds corresponds to a sub-optimality bound of the computed solutions that is often much less conservative than sub-optimality bounds obtained through purely theoretical analyses. Furthermore, we also perform analysis about the theoretical computational complexity of our approach as well as the sparsity of the constructed discrete measure.\nContributions and outline of the paper. Specifically, this paper makes the following contributions. (1) We introduce a parametric formulation of the matching for teams problem that is a linear semi-\ninfinite programming (LSIP) problem. We show that one can construct feasible approximate optimizers of the problems (MT), (MT\u2217), and (MTcp) (which are referred to as approximate matching equilibria) from an approximate optimizer of the parametric formulation (see Theorem 2.12). (2) We establish important theoretical results about the aforementioned LSIP problem and the constructed approximate matching equilibria, including: \u2022 theoretical computational complexities of the LSIP problem (see Theorem 2.2), \u2022 the existence of an approximate optimizer of (MT) that has sparse support (see Corol-\nlary 2.13), \u2022 the convergence of the constructed approximate matching equilibria to true matching equi-\nlibria (see Theorem 2.15), \u2022 explicit estimates for the \u201csize\u201d of the parametric formulation in order to control the\nsub-optimality of the constructed approximate matching equilibria when the spaces X1, . . . ,XN ,Z are compact subsets of Euclidean spaces (see Theorem 2.17).\n(3) We develop a numerical algorithm that is able to compute \u03f5\u0303-approximate matching equilibria for any given \u03f5\u0303 > 0. We perform two numerical experiments on problems involving one- and two-dimensional type spaces X1, . . . ,XN to demonstrate the performance of the proposed algorithm. We showcase that the sub-optimality bounds computed by our algorithm are much less conservative compared to their purely theoretical bounds, which highlights a practical advantage of the proposed algorithm compared to existing methods for similar problems. Moreover, we analyze the computational cost of our algorithm and demonstrate that it is capable of solving large problem instances with N = 100 agent categories.\nThe rest of this paper is organized as follows. Section 2 introduces the parametric formulation of the matching for teams problem and the construction of approximate matching equilibria. In Section 3, we present the details of the numerical algorithm that we develop as well as its properties. In Section 4, we apply the developed algorithm to two problem settings to demonstrate its performance in practice. The proof of the theoretical results are presented in the appendix.\nNotions and notations. Throughout this paper, all vectors are assumed to be column vectors. We denote vectors and vector-valued functions by boldface symbols. In particular, for n \u2208 N, we denote by 0n the vector in Rn with all entries equal to 0, i.e., 0n := (0, . . . , 0\ufe38 \ufe37\ufe37 \ufe38\nn times\n)T. We also use 0 when the\ndimension is unambiguous. We denote by \u27e8\u00b7, \u00b7\u27e9 the Euclidean dot product, i.e., \u27e8x,y\u27e9 := xTy, and we denote by \u2225 \u00b7 \u2225p the p-norm of a vector for p \u2208 [1,\u221e]. A subset of a Euclidean space is called a polyhedron or a polyhedral convex set if it is the intersection of finitely many closed half-spaces."
        },
        {
            "heading": "6 A. NEUFELD AND Q. XIANG",
            "text": "In particular, a subset of a Euclidean space is called a polytope if it is a bounded polyhedron. For a subset A of a Euclidean space, let aff(A), conv(A), cone(A) denote the affine hull, convex hull, and conic hull of A, respectively. Moreover, let cl(A), int(A), relint(A), relbd(A) denote the closure, interior, relative interior, and relative boundary of A, respectively.\nFor a Polish space (Y, dY) with its corresponding metric dY(\u00b7, \u00b7), letB(Y) denote the Borel subsets of Y and let P(Y) denote the set of Borel probability measures on Y . We denote by \u03b4y the Dirac measure at any y \u2208 Y and we denote by supp(\u00b5) the support of any probability measure \u00b5 \u2208 P(Y). Moreover, we denote by C(Y) the set of all continuous functions on Y and we denote by L1(Y, \u00b5) the set of \u00b5-integrable functions on Y with respect to a probability measure \u00b5 \u2208 P(Y). Furthermore, we use \u0393(\u00b7, . . . , \u00b7) to denote the set of couplings of measures, i.e., the set of measures with fixed marginals, as detailed in the following definition.\nDefinition 1.6 (Coupling). Form \u2208 N Polish spaces (Y1, dY1), . . . , (Ym, dYm) and probability measures \u03bd1 \u2208 P(Y1), . . ., \u03bdm \u2208 P(Ym), let \u0393(\u03bd1, . . . , \u03bdm) denote the set of couplings of \u03bd1, . . . , \u03bdm, defined as\n\u0393(\u03bd1, . . . , \u03bdm) := { \u03b3 \u2208 P(Y1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 Ym) : the marginal of \u03b3 on Yj is \u03bdj for j = 1, . . . ,m } .\nFor any \u00b5, \u03bd \u2208 P(Y), let W1(\u00b5, \u03bd) denote the Wasserstein metric of order 1 between \u00b5 and \u03bd, which is given by\nW1(\u00b5, \u03bd) := inf \u03b3\u2208\u0393(\u00b5,\u03bd) {\u222b Y\u00d7Y dY(x, y) \u03b3(dx,dy) } .\n2. APPROXIMATION OF MATCHING FOR TEAMS\nIn this section, we develop a parametric version of the problem (MT\u2217) by parametrizing the transfer functions (\u03c6i)i=1:N . Specifically, for i = 1, . . . , N , we consider a finite set Gi = {gi,1, . . . , gi,mi} of mi \u2208 N continuous functions on Xi, and we consider a finite set H = {h1, . . . , hk} of k \u2208 N continuous functions on Z . Subsequently, we parametrize (MT\u2217) by requiring the transfer functions (\u03c6i)i=1:N to be linear combinations of H as well as \u2211N i=1 \u03c6i = 0, and replacing the integrand \u03c6 ci i in the objective of (MT\u2217) with a function \u03c8i : Xi \u2192 R which is a linear combination of Gi plus a constant, for i = 1, . . . , N . By requiring that \u03c8i(xi) + \u03c6i(z) \u2264 ci(xi, z) for all (xi, z) \u2208 Xi \u00d7 Z and i = 1, . . . , N , we guarantee that \u03c8i \u2264 \u03c6cii for i = 1, . . . , N and thus this parametric version of (MT\u2217) provides a lower bound for (MT\u2217). Through this parametric formulation, we reduce the decision space of (MT\u2217) from infinite dimensional to finite dimensional, which results in a linear semi-infinite programming (LSIP) problem.\nIn the following, Section 2.1 introduces the parametric formulation of (MT\u2217). Its theoretical computational complexity is analyzed in Section 2.2. In Section 2.3, we establish the strong duality between the parametric formulation and its dual, which is a minimization problem over probability measures subject to finitely many moment-based constraints. In Section 2.4, we construct approximate matching equilibria via approximate optimizers of the parametric formulation and its dual and show their convergence towards a matching equilibrium when the approximation error goes to 0. Moreover, we discuss the existence of an approximate optimizer of the dual of the parametric formulation which has sparse support. In Section 2.5, we consider the case where the underlying spaces X1, . . . ,XN , and Z are all Euclidean, and we show that the approximation error of our approach can be controlled to be arbitrarily close to 0 through explicit choices of the functions G1, . . . ,GN ,H.\n2.1. The parametric formulation of matching for teams. We let Gi := { gi,1, . . . , gi,mi } be a set of mi \u2208 N continuous R-valued functions on Xi, for i = 1, . . . , N , and we let H := {h1, . . . , hk} be a set of k \u2208 N continuous R-valued functions on Z . The precise choices of the functions G1, . . . ,GN ,H will be specified later in Section 2.5. For notational simplicity, let the vector-valued functions g1 : X1 \u2192 Rm1 , . . ., gN : XN \u2192 RmN , and h : Z \u2192 Rk be defined as\ngi(xi) := (gi,1(xi), . . . , gi,mi(xi)) T \u2200xi \u2208 Xi, \u22001 \u2264 i \u2264 N, (2.1)\nh(z) := (h1(z), . . . , hk(z)) T \u2200z \u2208 Z. (2.2)\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 7\nMoreover, let the vectors g\u03041 \u2208 Rm1 , . . ., g\u0304N \u2208 RmN be defined as g\u0304i := ( \u222b Xi gi,1 d\u00b5i, . . . , \u222b Xi gi,mi d\u00b5i )T \u22001 \u2264 i \u2264 N. (2.3) With these notations, the parametric version of (MT\u2217) is given by the following linear semi-infinite programming (LSIP) problem:\nmaximize (yi,0,yi,wi) N\u2211 i=1 yi,0 + \u27e8g\u0304i,yi\u27e9\nsubject to yi,0 + \u27e8gi(xi),yi\u27e9+ \u27e8h(zi),wi\u27e9 \u2264 ci(xi, zi) \u2200(xi, zi) \u2208 Xi \u00d7Z, \u22001 \u2264 i \u2264 N,\nN\u2211 i=1 wi = 0k,\nyi,0 \u2208 R, yi \u2208 Rmi , wi \u2208 Rk \u22001 \u2264 i \u2264 N.\n(MT\u2217par)\nIn (MT\u2217par), we have that \u03c8i(\u00b7) := yi,0 + \u27e8gi(\u00b7),yi\u27e9 and \u03c6i(\u00b7) := \u27e8h(\u00b7),wi\u27e9 are both continuous for i = 1, . . . , N . The semi-infinite inequality constraint in (MT\u2217par) requires that \u03c8i(xi) + \u03c6i(zi) \u2264 ci(xi, zi) for all (xi, zi) \u2208 Xi \u00d7 Z , for i = 1, . . . , N . The equality constraint \u2211N i=1wi = 0k\nguarantees that \u2211N\ni=1 \u03c6i = 0. Thus, one can observe that (MT \u2217 par) provides a lower bound for (MT \u2217).\n2.2. Analysis of the theoretical computational complexity of (MT\u2217par). In this subsection, we analyze the theoretical computational complexity of the LSIP problem (MT\u2217par) by viewing it as a so-called convex feasibility problem. In the subsequent analysis, the theoretical computational complexity of (MT\u2217par) is quantified in terms of the number of calls to an associated global minimization oracle defined as follows.\nDefinition 2.1 (Global minimization oracle for (MT\u2217par)). Let Assumption 1.1 hold. For i = 1, . . . , N , let mi \u2208 N and Gi := { gi,1, . . ., gi,mi } \u2282 C(Xi). Let k \u2208 N and let H := {h1, . . . , hk} \u2282 C(Z), where hl : Z \u2192 R is non-negative for l = 1, . . . , k. Moreover, let (gi : Xi \u2192 Rmi)i=1:N , h : Z \u2192 Rk, and (g\u0304i \u2208 Rmi)i=1:N be defined in (2.1), (2.2), and (2.3). A procedure Oracle(\u00b7, \u00b7, \u00b7) is called a global minimization oracle for (MT\u2217par) if, for every i \u2208 {1, . . . , N}, every yi \u2208 Rmi , and every wi \u2208 Rk, a call to Oracle(i,yi,wi) returns a minimizer (x\u22c6i , z\u22c6i ) \u2208 Xi \u00d7 Z of the global minimization problem infxi\u2208Xi, zi\u2208Z { ci(xi, zi) \u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi\u27e9 } as well as its corresponding objective value \u03b2\u22c6i := ci(x \u22c6 i , z \u22c6 i )\u2212 \u27e8gi(x\u22c6i ),yi\u27e9 \u2212 \u27e8h(z\u22c6i ),wi\u27e9.\nThe following theorem states that there exists an algorithm for solving (MT\u2217par) whose computational complexity is polynomial inN ,m, k, and the computational cost of each call to Oracle(\u00b7, \u00b7, \u00b7). In the theorem, we denote the computational complexity of the multiplication of two m \u00d7m matrices by O(m\u03c9). For example, with the standard matrix multiplication procedure, the computational complexity of this operation is O(m3). However, it is known that \u03c9 < 2.376; see, e.g., [29].\nTheorem 2.2 (Theoretical computational complexity of (MT\u2217par)). Let Assumption 1.1 hold. For i = 1, . . . , N , let mi \u2208 N and Gi := { gi,1, . . . , gi,mi } \u2282 C(Xi). Let k \u2208 N and let H :=\n{h1, . . . , hk} \u2282 C(Z), where hl : Z \u2192 R is non-negative for l = 1, . . . , k. Let m := \u2211N\ni=1mi and let (gi : Xi \u2192 Rmi)i=1:N , h : Z \u2192 Rk, and (g\u0304i \u2208 Rmi)i=1:N be defined in (2.1), (2.2), and (2.3). Let Oracle(\u00b7, \u00b7, \u00b7) be the global minimization oracle in Definition 2.1. Assume that2, for i = 1, . . . , N , \u2225gi(xi)\u22252 \u2264 1 for all xi \u2208 Xi, and that \u2225h(z)\u22252 \u2264 1 for all z \u2208 Z . Moreover, suppose that (MT\u2217par) has an optimizer (y \u22c6 1,0,y \u22c6T 1 ,w \u22c6T 1 , . . . , y \u22c6 N,0,y \u22c6T N ,w \u22c6T N )\nT and let L := \u2225(y\u22c61,0,y\u22c6T1 ,w\u22c6T1 , . . . , y\u22c6N,0,y\u22c6TN ,w\u22c6TN )T\u22252. Let \u03f5 > 0 be an arbitrary positive tolerance value. Then,\n2Since Xi is compact and gi,1, . . . , gi,mi are continuous, one may replace gi,j by maxxi\u2208Xi { \u2225gi(xi)\u22252 }\u22121 gi,j for j = 1, . . . ,mi to guarantee that \u2225gi(xi)\u22252 \u2264 1 for all xi \u2208 Xi. The same can be done to h1, . . . , hk to guarantee that \u2225h(z)\u22252 \u2264 1 for all z \u2208 Z . Due to the linearity of the objective and the constraints of (MT\u2217par), this rescaled version of (MT\u2217par) is equivalent to the original problem without rescaling."
        },
        {
            "heading": "8 A. NEUFELD AND Q. XIANG",
            "text": "there exists an algorithm which computes an \u03f5-optimizer of (MT\u2217par) with computational complexity O ( (m+Nk) log(N \u221a kL/\u03f5)(NT+(m+Nk)\u03c9) ) , where T is the cost of each call to Oracle(\u00b7, \u00b7, \u00b7).\nProof of Theorem 2.2. See Appendix A.1. \u25a1\nRemark 2.3. We can guarantee that the set of optimizers of (MT\u2217par) is non-empty under the additional assumption that supp(\u00b5i) = Xi for i = 1, . . . , N . This will be formally stated later in Proposition 2.7(i).\nRemark 2.4. Notice that Oracle(\u00b7, \u00b7, \u00b7) performs minimization over Xi \u00d7 Z , and thus its computational complexity is independent of N . As a consequence, when k and m1, . . . ,mN do not depend on the number N of agent categories, the theoretical computational complexity of (MT\u2217par) is polynomial in N . This will be numerically tested and verified in Section 4.2 in a numerical experiment.\n2.3. Duality results. In this subsection, we derive the dual optimization problem of (MT\u2217par). To begin, let us first recall the notion of moment sets by Neufeld and Xiang [56].\nDefinition 2.5 (Moment set [56, Definition 2.2.5]). Let (Y, dY) be a compact metric space. For a collection G of R-valued Borel measurable functions on Y , let P(Y;G) := { \u00b5 \u2208 P(Y) : G \u2286\nL1(Y, \u00b5) }\n. Let G\u223c be defined as the following equivalence relation on P(Y;G): for all \u00b5, \u03bd \u2208 P(Y;G),\n\u00b5 G\u223c \u03bd \u21d4 \u2200g \u2208 G, \u222b Y g d\u00b5 = \u222b Y g d\u03bd. (2.4)\nFor every \u00b5 \u2208 P(Y;G), let [\u00b5]G := { \u03bd \u2208 P(Y;G) : \u03bd G\u223c \u00b5 } be the equivalence class of \u00b5 under\nG\u223c. We call [\u00b5]G the moment set centered at \u00b5 characterized by test functions G. In addition, let W 1,\u00b5([\u00b5]G) denote the supremum W1-metric between \u00b5 and members of [\u00b5]G , i.e.,\nW 1,\u00b5([\u00b5]G) := sup \u03bd\u2208[\u00b5]G\n{ W1(\u00b5, \u03bd) } .\nNote that W 1,\u00b5([\u00b5]G) <\u221e due to the compactness of Y .\nThe following theorem reveals that this dual problem is a relaxation of (MT) through the momentbased equivalence relation (2.4). It also shows that the strong duality holds.\nTheorem 2.6 (Strong duality). Let Assumption 1.1 hold. For i = 1, . . . , N , let mi \u2208 N and let Gi := { gi,1, . . . , gi,mi } \u2282 C(Xi). Let k \u2208 N and letH := {h1, . . . , hk} \u2282 C(Z). Moreover, let gi(\u00b7), h(\u00b7), and g\u0304i be given by (2.1), (2.2), and (2.3), respectively. Then, the optimal value of (MT\u2217par) is equal to the optimal value of the following optimization problem:\ninf { N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8i : \u03b8i \u2208 \u0393(\u00b5\u0304i, \u03bd\u0304i), \u00b5\u0304i Gi\u223c \u00b5i, \u03bd\u0304i H\u223c \u03bd\u03041 \u22001 \u2264 i \u2264 N } . (MTpar)\nProof of Theorem 2.6. See Appendix A.1. \u25a1\nThe following proposition provides sufficient conditions for the set of optimizers of (MT\u2217par) to be non-empty and bounded.\nProposition 2.7 (Optimizers of (MT\u2217par)). Let Assumption 1.1 hold. For i = 1, . . . , N , let mi \u2208 N and let Gi := { gi,1, . . . , gi,mi } \u2282 C(Xi). Let k \u2208 N and let H := {h1, . . . , hk} \u2282 C(Z). Moreover, let gi(\u00b7), h(\u00b7), and g\u0304i be given by (2.1), (2.2), and (2.3), respectively. Then, the following statements hold.\n(i) If for i = 1, . . . , N , supp(\u00b5i) = Xi, then the set of optimizers of (MT\u2217par) is non-empty.\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 9\n(ii) Suppose that, for i = 1, . . . , N , supp(\u00b5i) = Xi and that there exist mi + 1 points xi,1, . . . , xi,mi+1\u2208 Xi such that the mi + 1 vectors gi(xi,1), . . . , gi(xi,mi+1) \u2208 Rmi are affinely independent. Moreover, suppose that there exist k + 1 points z1, . . . , zk+1 \u2208 Z such that the k + 1 vectors h(z1), . . . ,h(zk+1) \u2208 Rk are affinely independent. Then, the set of optimizers of (MT\u2217par) is non-empty and bounded.\nProof of Proposition 2.7. See Appendix A.1. \u25a1\n2.4. Construction and convergence of approximate matching equilibria. In this subsection, we show how approximate matching equilibria can be constructed from approximate optimizers of (MT\u2217par) and (MTpar) and we show their convergence to matching equilibria. The construction requires an operation on P(Xi \u00d7 Z) called reassembly [56, Definition 2.2.2], which is a direct consequence of the gluing lemma of probability measures (see, e.g., [68, Lemma 7.6]). Moreover, we also need an operation on a collection of probability measures that is called binding. These two operations are presented in the following definitions.\nDefinition 2.8 (Reassembly (see [56, Definition 2.2.2])). Let Assumption 1.1 hold and let \u03bd \u2208 P(Z). For any i \u2208 {1, . . . , N} and any \u03b8\u0302i \u2208 P(Xi \u00d7 Z), let its marginal on Xi and Z be denoted by \u00b5\u0302i and \u03bd\u0302i, respectively. Let X\u0304i := Xi and let Z\u0304 := Z in order to differentiate different copies of the same space. \u03b8\u0303i \u2208 P(Xi \u00d7 Z) is called a reassembly of \u03b8\u0302i with marginals \u00b5i and \u03bd if there exists \u03b3 \u2208 P(Xi \u00d7Z \u00d7 X\u0304i \u00d7 Z\u0304) which satisfies the following conditions:\n(i) the marginal of \u03b3 on Xi \u00d7Z is \u03b8\u0302i; (ii) the marginal of \u03b3 on Xi \u00d7 X\u0304i, denoted by \u03b7i, is an optimal coupling of \u00b5\u0302i and \u00b5i under the\ncost function dXi , i.e., \u03b7i \u2208 \u0393(\u00b5\u0302i, \u00b5i) satisfies\u222b Xi\u00d7X\u0304i dXi(xi, x\u0304i) \u03b7i(dxi, dx\u0304i)=W1(\u00b5\u0302i, \u00b5i);\n(iii) the marginal of \u03b3 on Z \u00d7 Z\u0304 , denoted by \u03b6i, is an optimal coupling of \u03bd\u0302i and \u03bd under the cost function dZ , i.e., \u03b6i \u2208 \u0393(\u03bd\u0302i, \u03bd) satisfies\u222b\nZ\u00d7Z\u0304 dZ(z, z\u0304) \u03b6i(dz, dz\u0304)=W1(\u03bd\u0302i, \u03bd);\n(iv) the marginal of \u03b3 on X\u0304i \u00d7 Z\u0304 is \u03b8\u0303i. LetR(\u03b8\u0302i;\u00b5i, \u03bd) \u2282 \u0393(\u00b5i, \u03bd) denote the set of reassemblies of \u03b8\u0302i with marginals \u00b5i and \u03bd. In particular, R(\u03b8\u0302i;\u00b5i, \u03bd) is non-empty, as shown by [56, Lemma 2.2.3].\nDefinition 2.9 (Binding). Let Assumption 1.1 hold and let \u03bd \u2208 P(Z). For i = 1, . . . , N , let \u03b3i \u2208 P(Xi\u00d7Z) be such that the marginal of \u03b3i onZ is \u03bd. Then, \u00b5\u0303 \u2208 P(X1\u00d7\u00b7 \u00b7 \u00b7\u00d7XN ) is called a binding of \u03b31, . . . , \u03b3N if there exists \u03b3 \u2208 P(X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN \u00d7Z) which satisfies the following conditions:\n(i) for i = 1, . . . , N , the marginal of \u03b3 on Xi \u00d7Z is \u03b3i; (ii) the marginal of \u03b3 on X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN is \u00b5\u0303.\nLet B(\u03b31, . . . , \u03b3N ) denote the set of bindings of \u03b31, . . . , \u03b3N .\nThe following lemma shows that the set of bindings is non-empty.\nLemma 2.10. Let Assumption 1.1 hold and let \u03bd \u2208 P(Z). For i = 1, . . . , N , let \u03b3i \u2208 P(Xi \u00d7Z) be such that the marginal of \u03b3i onZ is \u03bd. Then, there exists a binding \u00b5\u0303 \u2208 B(\u03b31, . . . , \u03b3N ) of \u03b31, . . . , \u03b3N .\nProof of Lemma 2.10. See Appendix A.1. \u25a1\nNext, let us define the function c\u0304 : X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN \u2192 R by:\nc\u0304(x1, . . . , xN ) := inf z\u2208Z { N\u2211 i=1 ci(xi, z) } \u2200x1 \u2208 X1, . . . , \u2200xN \u2208 XN . (2.5)"
        },
        {
            "heading": "10 A. NEUFELD AND Q. XIANG",
            "text": "Due to the continuity of c1, . . . , cN and the compactness of Z , it follows from [12, Proposition 7.32 & Proposition 7.33] that c\u0304 is continuous and there exists a measurable function z\u0303 : X \u2192 Z such that\nN\u2211 i=1 ci ( xi, z\u0303(x1, . . . , xN ) ) = c\u0304(x1, . . . , xN ) \u2200x1 \u2208 X1, . . . , \u2200xN \u2208 XN . (2.6)\nIn the following, in order to control the approximation error of (MT\u2217par) and (MTpar), we impose the assumption that the cost functions c1, . . . , cN are Lipschitz continuous. Thus, we extend Assumption 1.1 as follows.\nAssumption 2.11. In addition to (A1)\u2013(A4) in Assumption 1.1, we assume that: (A4+) For i = 1, . . . , N , there exist constants L(1)ci > 0 and L (2) ci > 0 such that ci : Xi \u00d7 Z \u2192 R\nsatisfies |ci(x, z)\u2212 ci(x\u2032, z\u2032)| \u2264 L(1)ci dXi(x, x\u2032) + L (2) ci dZ(z, z \u2032) for all x, x\u2032 \u2208 Xi, z, z\u2032 \u2208 Z .\nThe construction of approximate matching equilibria through parametrizing transfer functions is detailed in the following theorem.\nTheorem 2.12 (Approximation of matching for teams). Let Assumption 2.11 hold. For i = 1, . . . , N , let mi \u2208 N and let Gi := { gi,1, . . . , gi,mi } \u2282 C(Xi). Let k \u2208 N and let H := {h1, . . . , hk} \u2282 C(Z). Moreover, let gi(\u00b7), h(\u00b7), and g\u0304i be given by (2.1), (2.2), and (2.3), respectively. Furthermore, let \u03f5 > 0 be arbitrary and let\n\u03f5\u2021 := \u03f5+ (N \u2212 1) max 1\u2264i\u2264N { L(2)ci } sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 }\n+ N\u2211 i=1 L(1)ci W 1,\u00b5i ( [\u00b5i]Gi ) .\nLet (y\u0302i,0, y\u0302i, w\u0302i)i=1:N and (\u03b8\u0302i)i=1:N be feasible solutions of (MT\u2217par) and (MTpar) that satisfy 3\nN\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i \u2264 ( N\u2211 i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 ) + \u03f5. (2.7)\nMoreover, for i = 1, . . . , N , let \u00b5\u0302i \u2208 P(Xi) denote the marginal of \u03b8\u0302i on Xi and let \u03bd\u0302i \u2208 P(Z) denote the marginal of \u03b8\u0302i on Z . Let \u03bd\u0302 \u2208 P(Z) satisfy4\nN\u2211 i=1 W1(\u03bd\u0302, \u03bd\u0302i) \u2264 (N \u2212 1) sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 } . (2.8)\nLet z\u0303 : X \u2192 Z be a measurable function that satisfies (2.6). Then, the following statements hold. (i) \u2211N\ni=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 is a lower bound for the optimal value of (MT). (ii) Let z0 \u2208 Z be arbitrary and let \u03c6\u0303i,0 := inf\nxi\u2208Xi\n{ ci(xi, z0)\u2212 y\u0302i,0 \u2212 \u27e8gi(xi), y\u0302i\u27e9 } \u22001 \u2264 i \u2264 N \u2212 1,\n\u03c6\u0303i(z) := inf xi\u2208Xi\n{ ci(xi, z)\u2212 y\u0302i,0 \u2212 \u27e8gi(xi), y\u0302i\u27e9 } \u2212 \u03c6\u0303i,0 \u2200z \u2208 Z, \u22001 \u2264 i \u2264 N \u2212 1,\n\u03c6\u0303N (z) := \u2212 N\u22121\u2211 i=1 \u03c6\u0303i(z) \u2200z \u2208 Z.\n(2.9)\nThen, (\u03c6\u0303i)i=1:N is an \u03f5\u2021-optimizer of (MT\u2217). Moreover, for i = 1, . . . , N \u2212 1, \u03c6\u0303i is L(2)ci - Lipschitz continuous.\n(iii) \u03bd\u0302 is an \u03f5\u2021-optimizer of (MT). (iv) For i = 1, . . . , N , let \u03b3\u0302i \u2208 R(\u03b8\u0302i;\u00b5i, \u03bd\u0302). Then, \u03b3\u0302i \u2208 \u0393(\u00b5i, \u03bd\u0302) and \u222b Xi\u00d7Z ci d\u03b3\u0302i \u2264Wci(\u00b5i, \u03bd\u0302)+ \u03f5\u2021. 3In particular, (y\u0302i,0, y\u0302i, w\u0302i)i=1:N is an \u03f5-optimizer of (MT\u2217par) and (\u03b8\u0302i)i=1:N is an \u03f5-optimizer of (MTpar). 4A sufficient condition for (2.8) to hold is when \u03bd\u0302 = \u03bd\u0302i\u0302 for some i\u0302 \u2208 {1, . . . , N}.\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 11\n(v) Let (\u03b3\u0302i)i=1:N be defined as in statement (iv), let \u00b5\u0303 \u2208 B(\u03b3\u03021, . . . , \u03b3\u0302N ), and let \u03bd\u0303 := \u00b5\u0303 \u25e6 z\u0303\u22121. Then, \u03bd\u0303 is an \u03f5\u2021-optimizer of (MT). (vi) Let \u00b5\u0303, \u03bd\u0303 be defined as in statement (v) and let \u03b3\u0303i := \u00b5\u0303\u25e6(\u03c0i, z\u0303)\u22121 \u2208 \u0393(\u00b5i, \u03bd\u0303) for i = 1, . . . , N , where \u03c0i : X \u2192 Xi denotes the projection function onto Xi. Then, \u03b3\u0303i \u2208 \u0393(\u00b5i, \u03bd\u0303) and\u222b Xi\u00d7Z ci d\u03b3\u0303i \u2264Wci(\u00b5i, \u03bd\u0303) + \u03f5 \u2021.\nProof of Theorem 2.12. See Appendix A.1. \u25a1\nAs a consequence of Theorem 2.12, one can construct an approximate optimizer of (MT) which is supported on at most min1\u2264i\u2264N{mi} + k + 2 points via the parametric formulation. This is summarized in the following corollary.\nCorollary 2.13 (Approximate optimizer of (MT) with sparse support). Let the assumptions of Theorem 2.12 hold. Then, there exist q \u2208 N with 1 \u2264 q \u2264 min1\u2264i\u2264N{mi}+ k + 2, \u03b11 > 0, . . . , \u03b1q > 0 satisfying \u2211q l=1 \u03b1l = 1, z1 \u2208 Z, . . . , zq \u2208 Z , such that \u03bd\u0302 := \u2211q l=1 \u03b1l\u03b4zl \u2208 P(Z) is an \u03f5\n\u2021-optimizer of (MT).\nProof of Corollary 2.13. See Appendix A.1. \u25a1\nRemark 2.14. As shown by Corollary 2.13, \u03bd\u0302 \u2208 P(Z) in Theorem 2.12(iii) can be chosen to be a discrete probability measure with finite support. In contrast, \u03bd\u0303 \u2208 P(Z) in Theorem 2.12(v) can be a non-discrete probability measure even when \u03bd\u0302 is discrete, due to the presence of the reassembly step. A discrete probability measure \u03bd\u0302 \u2208 P(Z) can be interpreted as an approximate matching equilibrium in which agents only trade finitely many distinct types of goods. On the other hand, a non-discrete probability measure \u03bd\u0303 \u2208 P(Z) can be interpreted as an approximate matching equilibrium in which agents trade uncountably many types of goods.\nBy observing the connection between Theorem 2.12(ii)\u2013(vi) and the characterization of matching equilibria in (ME1\u2019)\u2013(ME3\u2019), we refer to ( (\u03c6\u0303i)i=1:N , (\u03b3\u0302i)i=1:N , \u03bd\u0302 ) and ( (\u03c6\u0303i)i=1:N , (\u03b3\u0303i)i=1:N , \u03bd\u0303 ) as \u03f5\u2021-approximate matching equilibria. The notion of \u03f5\u2021-approximate matching equilibrium is justified since when given a sequence of \u03f5\u2021(l)-approximate matching equilibria where liml\u2192\u221e \u03f5\u2021(l) = 0, one can extract a subsequence that converges to a matching equilibrium. This is detailed in the next theorem.\nTheorem 2.15 (Construction of matching equilibria). Let Assumption 2.11 hold. Let ( \u03f5(l) \u2208\n(0,\u221e) ) l\u2208N, let ( G(l)i ) i=1:N,l\u2208N and ( H(l) ) l\u2208N be collections of continuous functions, and let\n\u03f5\u2021(l) := \u03f5(l) + (N \u2212 1) max 1\u2264i\u2264N { L(2)ci } sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H (l) \u223c \u03bd \u2032 }\n+ N\u2211 i=1 L(1)ci W 1,\u00b5i ( [\u00b5i]G(l)i ) satisfy liml\u2192\u221e \u03f5\u2021(l) = 0. Moreover, for each l \u2208 N, let ( \u03c6\u0303 (l) i ) i=1:N , \u03bd\u0302(l), ( \u03b3\u0302 (l) i ) i=1:N\n, \u03bd\u0303(l), and( \u03b3\u0303 (l) i ) i=1:N be constructed in Theorem 2.12 (with (Gi)i=1:N \u2190 ( G(l)i ) i=1:N\n, H \u2190 H(l), and \u03f5 \u2190 \u03f5(l)). Then, the following statements hold.\n(i) For i = 1, . . . , N , ( \u03c6\u0303 (l) i ) l\u2208N has at least one accumulation point in C(Z) with respect to the\nmetric of uniform convergence. (ii) ( \u03bd\u0302(l) ) l\u2208N has at least one accumulation point in ( P(Z),W1 ) and for i = 1, . . . , N , ( \u03b3\u0302 (l) i ) l\u2208N\nhas at least one accumulation point in ( P(Xi \u00d7Z),W1 ) .\n(iii) ( \u03bd\u0303(l) ) l\u2208N has at least one accumulation point in ( P(Z),W1 ) and for i = 1, . . . , N , ( \u03b3\u0303 (l) i ) l\u2208N\nhas at least one accumulation point in ( P(Xi \u00d7Z),W1 ) .\nFurthermore, let (lk)k\u2208N \u2286 N be an increasing subsequence such that ( \u03bd\u0302(lk) ) k\u2208N converges\nin ( P(Z),W1 ) to \u03bd\u0302(\u221e), ( \u03bd\u0303(lk) ) k\u2208N converges in ( P(Z),W1 ) to \u03bd\u0303(\u221e), and for i = 1, . . . , N ,\n12 A. NEUFELD AND Q. XIANG( \u03c6\u0303 (lk) i ) k\u2208N converges uniformly to \u03c6\u0303 (\u221e) i \u2208 C(Z), ( \u03b3\u0302 (lk) i ) k\u2208N converges in ( P(Xi \u00d7 Z),W1 ) to \u03b3\u0302 (\u221e) i , and ( \u03b3\u0303 (lk) i ) k\u2208N converges in ( P(Xi \u00d7Z),W1 ) to \u03b3\u0303(\u221e)i . Then,\n(iv) ( \u03c6\u0303 (\u221e) i ) i=1:N , ( \u03b3\u0302 (\u221e) i ) i=1:N , \u03bd\u0302(\u221e) constitute a matching equilibrium.\n(v) ( \u03c6\u0303 (\u221e) i ) i=1:N , ( \u03b3\u0303 (\u221e) i ) i=1:N , \u03bd\u0303(\u221e) constitute a matching equilibrium.\nProof of Theorem 2.15. See Appendix A.1. \u25a1\nIn order to control the approximation error \u03f5\u2021 in Theorem 2.12 to be arbitrarily close to 0, we need to explicitly construct the test functions G1, . . . ,GN ,H. This is the aim of the next subsection.\n2.5. Explicit construction of moment sets on a Euclidean space. In this subsection, we consider the case where the underlying spaces X1, . . . ,XN ,Z are all compact subsets of Euclidean spaces. In this case, for any i \u2208 {1, . . . , N}, we adopt an explicit construction of a finite collection Gi of continuous test functions on Xi by Neufeld and Xiang [56], which characterizes a moment set [\u00b5i]Gi such that the supremum W1-metric between \u00b5i and [\u00b5i]Gi , i.e., W 1,\u00b5i ( [\u00b5i]Gi ) , can be controlled to be arbitrarily close to 0. Similarly, we can explicitly construct a finite collectionH of continuous test functions on Z such that the term sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 } can be controlled to\nbe arbitrarily close to 0. These constructions ensure that the error term \u03f5\u2021 in Theorem 2.12 can be controlled to be arbitrarily close to 0. This is stated in the proposition below.\nProposition 2.16 (Choice of test functions characterizing a moment set [56, Corollary 3.2.10]). Let d \u2208 N, let Y \u2286\n\u015ad j=1[M j ,M j ] be closed, where \u2212\u221e < M j < M j < \u221e for j = 1, . . . , d, and let\ndY be a metric on Y induced by a norm \u2225 \u00b7 \u2225 on Rd. Let \u03f5 > 0 be arbitrary, let \u03b8 \u2265 1 be a constant such that \u2225x\u2225 \u2264 \u03b8\u2225x\u22252 for all x \u2208 Y , and let nj :=\n\u2308 2(Mj\u2212Mj)\u03b8 \u221a d\n\u03f5\n\u2309 , \u03baj,l :=M j + l nj (M j \u2212M j)\nfor l = 0, . . . , nj , j = 1, . . . , d. Moreover, let G \u2282 C(Y) be defined as follows: G := { Y \u220b (x1, . . . , xd)T 7\u2192 max\n1\u2264j\u2264d\n{ nj\nMj\u2212Mj (xj \u2212 \u03baj,lj )\n+ } \u2208 R : 0 \u2264 lj \u2264 nj \u22001 \u2264 j \u2264 d } .\nThen, |G| = \u220fd\nj=1\n( 1+ \u2308 2(Mj\u2212Mj)\u03b8 \u221a d\n\u03f5\n\u2309) and W1(\u00b5, \u03bd) \u2264 \u03f5 for any \u00b5, \u03bd \u2208 P(Y) satisfying \u00b5 G\u223c \u03bd.\nConsequently, Proposition 2.16 allows us to control the approximation error \u03f5\u2021 in Theorem 2.12 to be arbitrarily close to 0 and to construct \u03f5\u0303-approximate matching equilibria for any \u03f5\u0303 > 0. This is stated in the theorem below. The theorem also contains a scalability result (in statement (vi)) which bounds the number of test functions needed to control the approximation error in Theorem 2.12 from above. Moreover, it includes a sufficient condition (in statement (viii)) for the affine independence in Proposition 2.7(ii) to hold.\nTheorem 2.17 (Controlling the approximation error in Theorem 2.12). Let Assumption 2.11 hold, let L (2) c\u0304 := max1\u2264i\u2264N { L (2) ci } , and let \u03f5\u0303 > 0 be arbitrary. For i = 1, . . . , N , let Xi be a compact subset of Rdi for di \u2208 N and let dXi be induced by a norm \u2225 \u00b7 \u2225 on Rdi . Moreover, let Z be a compact subset of Rd0 for d0 \u2208 N and let dZ be induced by a norm \u2225 \u00b7 \u2225 on Rd0 . Then, for any \u03f5 \u2208 (0, \u03f5\u0303), there exist finite collections of test functions G1, . . . ,GN ,H such that (\u03c6\u0303i)i=1:N , \u03bd\u0302, (\u03b3\u0302i)i=1:N , \u03bd\u0303, and (\u03b3\u0303i)i=1:N constructed via the process described in Theorem 2.12 satisfy5\n(i) (\u03c6\u0303i)i=1:N is an \u03f5\u0303-optimizer of (MT\u2217) and for i = 1, . . . , N \u2212 1, \u03c6\u0303i is L(2)ci -Lipschitz continuous;\n(ii) \u03bd\u0302 is an \u03f5\u0303-optimizer of (MT); (iii) for i = 1, . . . , N , \u03b3\u0302i \u2208 \u0393(\u00b5i, \u03bd\u0302) and \u222b Xi\u00d7Z ci d\u03b3\u0302i \u2264Wci(\u00b5i, \u03bd\u0302) + \u03f5\u0303; (iv) \u03bd\u0303 is an \u03f5\u0303-optimizer of (MT); (v) for i = 1, . . . , N , \u03b3\u0303i \u2208 \u0393(\u00b5i, \u03bd\u0303) and \u222b Xi\u00d7Z ci d\u03b3\u0303i \u2264Wci(\u00b5i, \u03bd\u0303) + \u03f5\u0303.\n5In particular, ( (\u03c6\u0303i)i=1:N , (\u03b3\u0302i)i=1:N , \u03bd\u0302 ) and ( (\u03c6\u0303i)i=1:N , (\u03b3\u0303i)i=1:N , \u03bd\u0303 ) constitute \u03f5\u0303-approximate matching equilibria.\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 13\nMoreover, the following statement holds. (vi) For i = 1, . . . , N , let \u2212\u221e < M i,j < M i,j < \u221e for j = 1, . . . , di satisfy Xi \u2286\n\u015adi j=1[M i,j ,M i,j ]. For i = 1, . . . , N , let \u03b8i \u2265 1 be a constant such that \u2225xi\u2225 \u2264 \u03b8i\u2225xi\u22252 for all xi \u2208 Xi, and let ni,j := \u2308 4NL (1) ci (M i,j\u2212M i,j)\u03b8i \u221a di\n\u03f5\u0303\u2212\u03f5\n\u2309 , \u03bai,j,l := M i,j + l ni,j\n(M i,j \u2212M i,j) for l = 0, . . . , ni,j , j = 1, . . . , di. Let \u2212\u221e < M0,j < M0,j < \u221e for j = 1, . . . , d0 satisfy Z \u2286\n\u015ad0 j=1[M0,j ,M0,j ], let \u03b80 \u2265 1 be a constant such that \u2225z\u2225 \u2264 \u03b80\u2225z\u22252 for all z \u2208 Z , and let n0,j := \u2308 4(N\u22121)L(2)c\u0304 (M0,j\u2212M0,j)\u03b80 \u221a d0\n\u03f5\u0303\u2212\u03f5\n\u2309 , \u03ba0,j,l := M0,j + l n0,j\n(M0,j \u2212 M0,j) for l = 0, . . . , n0,j , j = 1, . . . , d0. Then, a particular choice of the test functions G1, . . . ,GN ,H in order to satisfy (i)\u2013(v) above is given as follows:\nGi := { Xi \u220b (x1, . . . , xdi)\nT 7\u2192 max 1\u2264j\u2264di\n{ ni,j\nM i,j\u2212M i,j (xj \u2212 \u03bai,j,lj )\n+ } \u2208 R :\n0 \u2264 lj \u2264 ni,j \u22001 \u2264 j \u2264 di } \u22001 \u2264 i \u2264 N,\nH := { Z \u220b (z1, . . . , zd0)T 7\u2192 max\n1\u2264j\u2264d0\n{ n0,j\nM0,j\u2212M0,j (zj \u2212 \u03ba0,j,lj )\n+ } \u2208 R :\n0 \u2264 lj \u2264 n0,j \u22001 \u2264 j \u2264 d0 } .\nMoreover, |Gi| = \u220fdi\nj=1\n( 1 + \u2308 4NL (1) ci (M i,j\u2212M i,j)\u03b8i \u221a di\n\u03f5\u0303\u2212\u03f5 \u2309) for i = 1, . . . , N and |H| =\u220fd0\nj=1\n( 1 + \u2308 4(N\u22121)L(2)c\u0304 (M0,j\u2212M0,j)\u03b80 \u221a d0\n\u03f5\u0303\u2212\u03f5\n\u2309) .\n(vii) For i = 1, . . . , N , there exists a finite collection Ci of di-simplices6 in Rdi with the properties\u22c3 C\u2208Ci C \u2287 Xi, maxC\u2208Ci maxx,x\u2032\u2208C { \u2225x \u2212 x\u2032\u2225 } \u2264 \u03f5\u0303\u2212\u03f5\n4NL (1) ci\n, and if C1, C2 \u2208 Ci and C1 \u2229\nC2 \u0338= \u2205 then C1 \u2229 C2 is a face6 of both C1 and C2. Moreover, there exists a finite collection C0 of d0-simplices in Rd0 with the properties \u22c3 C\u2208C0 C \u2287 Z , maxC\u2208C0 maxx,x\u2032\u2208C { \u2225x \u2212\nx\u2032\u2225 } \u2264 \u03f5\u0303\u2212\u03f5\n4(N\u22121)L(2)c\u0304 , and if C1, C2 \u2208 C0 and C1 \u2229 C2 \u0338= \u2205 then C1 \u2229 C2 is a face of both\nC1 and C2. Let V (C) denote the set of extreme points of a polytope C. Furthermore, for i = 1, . . . , N and for every extreme point v of some C \u2208 Ci, let gi,v : Xi \u2192 R be defined 7 as follows:\ngi,v(x) := \u2211\nw\u2208V (F )\n\u03bbFw(x)1{w=v} \u2200x \u2208 relint(F ) \u2229 Xi,\nwhere x = \u2211\nw\u2208V (F ) \u03bb F w(x)w and F is a face of some C \u2208 Ci. For every extreme point v\nof some C \u2208 C0, let hv : Z \u2192 R be defined 7 as follows: hv(z) := \u2211\nw\u2208V (F )\n\u03bbFw(z)1{w=v} \u2200z \u2208 relint(F ) \u2229 Z,\nwhere z = \u2211\nw\u2208V (F ) \u03bb F w(z)w and F is a face of some C \u2208 C0. Then, a particu-\nlar choice of the test functions G1, . . . ,GN ,H in order to satisfy (i)\u2013(v) above is Gi :={ gi,v : v is an extreme point of some C \u2208 Ci } for i = 1, . . . , N and H := { hv :\nv is an extreme point of some C \u2208 C0 }\n. (viii) In statement (vii), for i = 1, . . . , N , let {vi,0,vi,1, . . . ,vi,mi} be an arbitrary enumeration of the finite set { v \u2208 Rdi : v is an extreme point of some C \u2208 Ci } (i.e., the cardinality of\n6The definitions of di-simplices and faces of a convex set can be found in, for example, [61, Section 1 & Section 18]. 7Note that gi,v(x) is well-defined for every x \u2208 Xi and hv(z) is well defined for every z \u2208 Z due to statements (i)\nand (ii) of [56, Proposition 3.2.6]."
        },
        {
            "heading": "14 A. NEUFELD AND Q. XIANG",
            "text": "this set is mi + 1 \u2208 N) and let gi(x) := ( gi,vi,1(x), . . . , gi,vi,mi (x) )T \u2200x \u2208 Xi. Moreover, let {v0,0,v0,1, . . . ,v0,k} be an arbitrary enumeration of the finite set { v \u2208 Rd0 :\nv is an extreme point of some C \u2208 C0 } (i.e., the cardinality of this set is k + 1 \u2208 N) and let\nh(z) := ( hv0,1(z), . . . , hv0,k(z) )T \u2200z \u2208 Z. For i = 1, . . . , N , if it holds that int(Xi) \u2229 int(C) \u0338= \u2205 for all C \u2208 Ci, then there exist mi+1 points xi,1, . . . ,xi,mi+1 \u2208 Xi such that themi+1 vectors g(xi,1), . . . , g(xi,mi+1) \u2208 Rmi are affinely independent. In addition, if it holds that int(Z) \u2229 int(C) \u0338= \u2205 for all C \u2208 C0, then there exist k + 1 points z1, . . . ,zk+1 \u2208 Z such that the k + 1 vectors h(z1), . . . ,h(zk+1) \u2208 Rk are affinely independent.\nProof of Theorem 2.17. See Appendix A.1. \u25a1\nRemark 2.18. Theorem 2.17(vi) provides insights about the scalability of the approximation scheme developed in this section. For simplicity, let Xi \u2286 [M,M ]d for d \u2208 N, \u2212\u221e < M < M < \u221e, let dXi be induced by the Euclidean norm \u2225 \u00b7 \u22252 on Rd for i = 1, . . . , N , let Z \u2286 [M,M ]d, let dZ be induced by the Euclidean norm \u2225 \u00b7 \u22252 on Rd, and let ci be Lc-Lipschitz continuous (with respect to the 1-product metric on Xi\u00d7Z) for some Lc > 0 for i = 1, . . . , N . Then, by Theorem 2.17, the total number of test functions in G1, . . . ,GN and H to control the approximation error in Theorem 2.12 to below \u03f5\u0303 is of the order O ( N (4NLc(M\u2212M)\u221ad \u03f5\u0303\u2212\u03f5 )d), which is exponential in the dimension d of the\nunderlying spaces. On the other hand, when (M \u2212M), d, and Lc are fixed, the total number of test functions grows polynomially in the number N of agent categories.\n3. NUMERICAL METHOD\nIn this section, we discuss the numerical method for approximately solving the matching for teams problem. To begin, we solve the LSIP problem (MT\u2217par) by developing a so-called cutting-plane discretization algorithm inspired by Conceptual Algorithm 11.4.1 in [41]. The core idea of the algorithm is to replace the semi-infinite constraint in (MT\u2217par) with a finite subcollection of constraints, which relaxes (MT\u2217par) into a linear programming (LP) problem. Subsequently, one iteratively adds more constraints to the existing subcollection until the approximation error falls below a pre-specified tolerance threshold. The addition of constraints can be thought of as introducing \u201ccuts\u201d to restrict the feasible set of an LP relaxation of (MT\u2217par).\nBefore presenting the algorithm, let us first introduce the following lemma, which deals with the construction of an optimal coupling in the discrete-to-discrete case, the discrete-to-continuous case (also known as the semi-discrete case), and the one-dimensional case. This lemma combines classical results about discrete optimal transport (see, e.g., [58, Section 2.3] and [10, Section 1.3]), semi-discrete optimal transport (see, e.g., [50] and [58, Section 5.2]), and one-dimensional optimal transport (see, e.g., [60, Section 3.1]).\nLemma 3.1 (Construction of optimal coupling). Let (Y, dY) be a compact metric space and let (\u2126,F ,P) be a probability space. For n \u2208 N, ( \u03b1i \u2208 (0, 1] ) i=1:n\n, distinct points (xi \u2208 Y)i=1:n with\u2211n i=1 \u03b1i = 1, let Y : \u2126 \u2192 Y be a random variable such that P[Y = xi] = \u03b1i for i = 1, . . . , n. Let \u03bd1 \u2208 P(Y) denote the law of Y and let \u03bd2 \u2208 P(Y). Suppose that any one of the following assumptions hold:\n(C1) The discrete-to-discrete case: \u03bd2 = \u2211n2 i=1 \u03b2i\u03b4yi for n2 \u2208 N, ( \u03b2i \u2208 (0, 1] ) i=1:n2\n, distinct points (yi \u2208 Y)i=1:n2 with \u2211n2 i=1 \u03b2i = 1.\n(C2) The discrete-to-continuous case. Y \u2282 Rd for d \u2208 N, dY is induced by a norm \u2225 \u00b7 \u2225 on Rd under which the closed unit ball { x \u2208 Rd : \u2225x\u2225 \u2264 1 } is a strictly convex set8, \u03bd2 is absolutely continuous with respect to the Lebesgue measure on Y . 8for example, under the p-norm (assuming d > 1), this condition is satisfied for all 1 < p < \u221e (by the Minkowski\ninequality), but fails when p = 1 or p = \u221e.\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 15\n(C3) The one-dimensional case. Y \u2282 R and dY is the Euclidean distance on R. Let the random variable Y\u0304 : \u2126 \u2192 Y be defined according to the procedures below in the three cases (C1)\u2013(C3). \u2022 The discrete-to-discrete case. Suppose that (C1) holds and let (\u03b3\u22c6i,j)i=1:n1,j=1:n2 be an opti-\nmizer of the following linear programming problem:\nminimize (\u03b3i,j) n\u2211 i=1 n2\u2211 j=1 dY(xi, yj)\u03b3i,j\nsubject to n2\u2211 j=1 \u03b3i,j = \u03b1i \u22001 \u2264 i \u2264 n,\nn\u2211 i=1 \u03b3i,j = \u03b2j \u22001 \u2264 j \u2264 n2, \u03b3i,j \u2265 0 \u22001 \u2264 i \u2264 n, \u22001 \u2264 j \u2264 n2.\nLet Y\u0304 : \u2126\u2192 Y be such that P[Y\u0304 = yj |Y = xi] = \u03b3\u22c6i,j for i = 1, . . . , n, j = 1, . . . , n2. \u2022 The discrete-to-continuous case. Suppose that (C2) holds and let ( \u03d5\u22c6i ) i=1:n\n\u2282 R be an optimizer of the following concave maximization problem (which always exists; see, e.g., [56, Proposition 3.1.2]):\nsup \u03d51,...,\u03d5n\u2208R\n{ n\u2211\ni=1\n\u03d5i\u03b1i \u2212 \u222b Y max 1\u2264i\u2264n { \u03d5i \u2212 dY(xi, y) } \u03bd2(dy) } . (3.1)\nFor i = 1, . . . , n, let\nVi := { z \u2208 Y : \u03d5\u22c6i \u2212 dY(xi, z) = max\n1\u2264k\u2264n\n{ \u03d5\u22c6k \u2212 dY(xk, z) }} . (3.2)\nLet Y\u0304 : \u2126\u2192 Y be such that P[Y\u0304 \u2208 E|Y = xi] = \u03bd2 ( E \u2229 Vi ) \u03bd2(Vi)\n\u2200E \u2208 B(Y), \u22001 \u2264 i \u2264 n. (3.3)\n\u2022 The one-dimensional case. Suppose that (C3) holds, let F\u22121\u03bd2 (t) := inf { y \u2208 Y : \u03bd2 ( Y \u2229\n(\u2212\u221e, y] ) \u2265 t }\nfor t \u2208 [0, 1], and let Y\u0304 : \u2126\u2192 Y be constructed via the following procedure. \u2013 Step 1: sort the sequence (x1, . . . , xn) into ascending order x(1) \u2264 x(2) \u2264 \u00b7 \u00b7 \u00b7 \u2264 x(n)\nand let \u03c3(xi) denote the order of xi in the sorted sequence, i.e., { \u03c3(xi) : 1 \u2264 i \u2264 n } =\n{1, . . . , n} and x(\u03c3(xi)) \u2261 xi for i = 1, . . . , n. \u2013 Step 2: for j = 0, 1, . . . , n, let F (j) := \u2211 1\u2264i\u2264n, \u03c3(xi)\u2264j \u03b1i. \u2013 Step 3: let U : \u2126\u2192 [0, 1] be a uniform random variable on [0, 1] that is independent of Y .\n\u2013 Step 4: let Y\u0304 := F\u22121\u03bd2 ( UF (\u03c3(X)) + (1\u2212 U)F (\u03c3(X)\u2212 1) ) .\nThen, in all three cases, the law \u03b3\u22c6 \u2208 P(Y\u00d7Y) of the random variable (Y, Y\u0304 ) : \u2126\u2192 Y\u00d7Y satisfies \u03b3\u22c6 \u2208 \u0393(\u03bd1, \u03bd2) and \u222b Y\u00d7Y dY(x, y) \u03b3 \u22c6(dx,dy)=W1(\u03bd1, \u03bd2).\nProof of Lemma 3.1. See Appendix A.2. \u25a1\nWe will work with the following assumptions throughout this section.\nAssumption 3.2. In addition to Assumption 2.11, we make the following assumptions: (i) For i = 1, . . . , N , supp(\u00b5i) = Xi, and at least one of the assumptions (C1)\u2013(C3) in\nLemma 3.1 is satisfied with respect to Y \u2190 Xi, dY \u2190 dXi , \u03bd2 \u2190 \u00b5i. (ii) For i = 1, . . . , N , Gi := { gi,1, . . . , gi,mi } \u2282 C(Xi) formi \u2208 N. Moreover, for gi : Xi \u2192 Rmi\ndefined in (2.1), there exist mi +1 points xi,1, . . . , xi,mi+1\u2208 Xi such that the mi +1 vectors gi(xi,1), . . . , gi(xi,mi+1) \u2208 Rmi are affinely independent."
        },
        {
            "heading": "16 A. NEUFELD AND Q. XIANG",
            "text": "(iii) It holds that H := {h1, . . . , hk} \u2282 C(Z) for k \u2208 N. Moreover, for h : Z \u2192 Rk defined in (2.2), there exist k + 1 points z1, . . . , zk+1 \u2208 Z such that the k + 1 vectors h(z1), . . . ,h(zk+1) \u2208 Rk are affinely independent.\nNote that by Proposition 2.7, Assumption 3.2 is sufficient to guarantee that the set of optimizers of (MT\u2217par) is non-empty and bounded, which is crucial for proving the convergence of the cutting-plane discretization algorithm in this section.\nRemark 3.3. When the underlying spaces X1, . . . ,XN ,Z are compact subsets of Euclidean spaces, recall that Theorem 2.17(viii) provides sufficient conditions under which Assumption 3.2(ii) and Assumption 3.2(iii) hold.\nAlgorithm 1 provides a concrete implementation of the cutting-plane discretization method for solving (MT\u2217par). A key step in Algorithm 1 is to solve LP relaxations of (MT \u2217 par) in which the semiinfinite constraint yi,0 + \u27e8gi(xi),yi\u27e9 + \u27e8h(zi),wi\u27e9 \u2264 ci(xi, zi) \u2200(xi, zi) \u2208 Xi \u00d7 Z is replaced by a finite subcollection of constraints for i = 1, . . . , N . Specifically, for any r \u2208 Z+ and any finite set C(r)i \u2282 Xi \u00d7Z , let (MT \u2217(r) par ) denote the following LP problem:\nmaximize (yi,0,yi,wi) N\u2211 i=1 yi,0 + \u27e8g\u0304i,yi\u27e9\nsubject to yi,0 + \u27e8gi(xi),yi\u27e9+ \u27e8h(zi),wi\u27e9 \u2264 ci(xi, zi)\n\u2200(xi, zi) \u2208 C(r)i , \u22001 \u2264 i \u2264 N, N\u2211 i=1 wi = 0k,\nyi,0 \u2208 R, yi \u2208 Rmi , wi \u2208 Rk \u22001 \u2264 i \u2264 N.\n(MT\u2217(r)par )\nThe LP problem (MT\u2217(r)par ) admits the following dual LP problem:\nminimize (\u03b8i,x,z), \u03be N\u2211 i=1 \u2211 (x,z)\u2208C(r)i \u03b8i,x,zci(x, z)\nsubject to \u2211\n(x,z)\u2208C(r)i\n\u03b8i,x,z = 1 \u22001 \u2264 i \u2264 N,\n\u2211 (x,z)\u2208C(r)i \u03b8i,x,zgi(x) = g\u0304i \u22001 \u2264 i \u2264 N,\n\u2211 (x,z)\u2208C(r)i \u03b8i,x,zh(z) = \u03be \u22001 \u2264 i \u2264 N,\n\u03b8i,x,z \u2208 R+ \u2200(x, z) \u2208 C(r)i , \u22001 \u2264 i \u2264 N,\n\u03be \u2208 Rk.\n(MT(r)par)\nRemark 3.4 explains the assumptions of Algorithm 1. The properties of Algorithm 1 are presented in Proposition 3.5.\nRemark 3.4 (Details of Algorithm 1). Algorithm 1 is inspired by the Conceptual Algorithm 11.4.1 in [41]. Let Assumption 3.2 hold. Below is a list explaining the inputs to Algorithm 1.\n\u2022 (Xi)i=1:N and (ci)i=1:N are given by Assumption 1.1. \u2022 (gi : Xi \u2192 Rmi)i=1:N , h : Z \u2192 Rk, and (g\u0304i \u2208 Rmi)i=1:N are defined in (2.1), (2.2), and\n(2.3).\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 17\nAlgorithm 1: Cutting-plane discretization algorithm for solving (MT\u2217par) and (MTpar)\nInput: (Xi)i=1:N , (ci)i=1:N , (gi : Xi \u2192 Rmi)i=1:N , (g\u0304i \u2208 Rmi)i=1:N , h : Z \u2192 Rk,( C(0)i \u2282 Xi \u00d7Z ) i=1:N\n, Oracle(\u00b7, \u00b7, \u00b7), \u03f5 > 0 Output: \u03b1UBMTpar , \u03b1 LB MTpar\n, (y\u0302i,0, y\u0302i, w\u0302i)i=1:N , (\u03b8\u0302i)i=1:N 1 r \u2190 0. 2 while true do 3 Solve the LP problem (MT\u2217(r)par ), denote the computed optimal value as \u03b1(r), denote the\ncomputed optimizer as ( y (r) i,0 ,y (r) i ,w (r) i ) i=1:N , and denote the corresponding optimizer\nof the dual LP problem (MT(r)par) as ( \u03b8 (r) i,x,z ) (x,z)\u2208C(r)i ,i=1:N , \u03be(r).\n4 for i = 1, . . . , N do 5 Call Oracle ( i,y\n(r) i ,w (r) i\n) and let ( x \u22c6(r) i , z \u22c6(r) i , \u03b2 (r) i ) be its output.\n6 Let C\u22c6(r)i \u2282 Xi \u00d7Z be a finite set such that ( x \u22c6(r) i , z \u22c6(r) i ) \u2208 C\u22c6(r)i . 7 C(r+1)i \u2190 C (r) i \u222a C \u22c6(r) i .\n8 if \u2211N\ni=1 y (r) i,0 \u2212 \u03b2 (r) i \u2264 \u03f5 then\n9 Skip to Line 11.\n10 r \u2190 r + 1.\n11 \u03b1UBMTpar \u2190 \u03b1 (r), \u03b1LBMTpar \u2190 \u03b1\n(r) \u2212 (\u2211N\ni=1 y (r) i,0 \u2212 \u03b2 (r) i\n) .\n12 for i = 1, . . . , N do 13 y\u0302i,0 \u2190 \u03b2(r)i , y\u0302i \u2190 y (r) i , w\u0302i \u2190 w (r) i .\n14 \u03b8\u0302i \u2190 \u2211\n(x,z)\u2208C(r)i \u03b8 (r) i,x,z\u03b4(x,z).\n15 return \u03b1UBMTpar , \u03b1 LB MTpar , (y\u0302i,0, y\u0302i, w\u0302i)i=1:N , (\u03b8\u0302i)i=1:N .\n\u2022 C(0)i \u2282 Xi \u00d7 Z is a finite set for i = 1, . . . , N . The sets ( C(0)i ) i=1:N are chosen such that\nthe LP problem (MT\u2217(r)par ) with r = 0 has bounded superlevel sets. The existence of such( C(0)i ) i=1:N\nis shown in Proposition 3.5(i). \u2022 Oracle(\u00b7, \u00b7, \u00b7) is the global minimization oracle in Definition 2.1. We assume that a compu-\ntational procedure can be implemented to solve this global minimization problem. \u2022 \u03f5 > 0 is a pre-specified numerical tolerance value (see Proposition 3.5).\nWe would like to remark that when solving the LP problem (MT\u2217(r)par ) in Line 3 by the dual simplex algorithm (see, e.g., [67, Chapter 6.4]) or the interior point algorithm (see, e.g., [67, Chapter 18]), one can obtain a corresponding optimizer of the dual LP problem (MT(r)par) from the output of these algorithms.\nProposition 3.5 (Properties of Algorithm 1). Let Assumption 3.2 hold. Then, (i) there exist finite sets ( C(0)i \u2208 Xi \u00d7 Z ) i=1:N\nsuch that the LP problem (MT\u2217(r)par ) with r = 0 has bounded superlevel sets.\nMoreover, assume that all inputs of Algorithm 1 are set according to Remark 3.4. Then, the following statements hold.\n(ii) Algorithm 1 terminates after finitely many iterations. (iii) \u03b1LBMTpar \u2264 (MT \u2217 par) \u2264 \u03b1UBMTpar where \u03b1 UB MTpar\n\u2212 \u03b1LBMTpar \u2264 \u03f5. (iv) (y\u0302i,0, y\u0302i, w\u0302i)i=1:N is an \u03f5-optimal solution of (MT\u2217par) and \u2211N i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 = \u03b1LBMTpar .\n(v) (\u03b8\u0302i)i=1:N is an \u03f5-optimal solution of (MTpar) where \u03b8\u0302i has finite support for i = 1, . . . , N and \u2211N i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i = \u03b1 UB MTpar ."
        },
        {
            "heading": "18 A. NEUFELD AND Q. XIANG",
            "text": "Algorithm 2: Procedure for constructing approximate matching equilibria via parametrizing transfer functions\nInput: (Xi)i=1:N , Z , (\u00b5i)i=1:N , (ci)i=1:N , \u03f5 > 0, (Gi)i=1:N ,H, z\u0303(\u00b7), Oracle(\u00b7, \u00b7, \u00b7) Output: (\u03c6\u0303i)i=1:N , \u03bd\u0302, (\u03b3\u0302i)i=1:N , \u03bd\u0303, (\u03b3\u0303i)i=1:N , \u03b1LBMT, \u03b1\u0302 UB MT, \u03b1\u0303 UB MT, \u03f5\u0302MT, \u03f5\u0303MT\n1 Let (gi(\u00b7))i=1:N , h(\u00b7), and (g\u0304i)i=1:N be defined by (2.1), (2.2), and (2.3). 2 Construct finite sets ( C(0)i \u2282 Xi \u00d7Z ) i=1:N\nsuch that the LP problem (MT\u2217(r)par ) with r = 0 has bounded superlevel sets.\n3 ( \u03b1UBMTpar , \u03b1 LB MTpar , (y\u0302i,0, y\u0302i, w\u0302i)i=1:N , (\u03b8\u0302i)i=1:N ) \u2190 the outputs of Algorithm 1 with inputs(\n(Xi)i=1:N , (ci)i=1:N , (gi(\u00b7))i=1:N , (g\u0304i)i=1:N , h(\u00b7), ( C(0)i ) i=1:N , Oracle(\u00b7, \u00b7, \u00b7), \u03f5 ) .\n4 Choose an arbitrary z0 \u2208 Z and let (\u03c6\u0303i)i=1:N be defined as in (2.9). 5 Let \u03bd\u0302i denote the marginal of \u03b8\u0302i on Z for i = 1, . . . , N . Choose an arbitrary i\u0302 \u2208 {1, . . . , N}. 6 K \u2190 |supp(\u03bd\u0302i\u0302)|. Express \u03bd\u0302i\u0302 = \u2211K l=1 \u03b1l\u03b4zl for (\u03b1l \u2208 (0, 1])l=1:K satisfying \u2211K l=1 \u03b1l = 1 and\n(zl \u2208 Z)l=1:K . Let (\u2126,F ,P) be a probability space and let Z : \u2126\u2192 Z be a random variable such that P[Z = zl] = \u03b1l for l = 1, . . . ,K. \u03bd\u0302 \u2190 the law of Z. 7 for i = 1, . . . , N do 8 Let the random variable Zi : \u2126\u2192 Z be constructed via Lemma 3.1 with Y \u2190 Z , dY \u2190 dZ , Y \u2190 Z, \u03bd2 \u2190 \u03bd\u0302i, Y\u0304 \u2190 Zi. 9 Let the random variable Xi : \u2126\u2192 Xi be such that P[Xi \u2208 E|Zi = z] = \u03b8\u0302i(E\u00d7{z})\u03bd\u0302i({z}) for\nevery z \u2208 supp(\u03bd\u0302i) and every E \u2208 B(Xi). 10 Let the random variable X\u0304i : \u2126\u2192 Xi be constructed via Lemma 3.1 with Y \u2190 Xi, dY \u2190 dXi , Y \u2190 Xi, \u03bd2 \u2190 \u00b5i, Y\u0304 \u2190 X\u0304i. 11 Define the random variable Z\u0304 : \u2126\u2192 Z as Z\u0304 := z\u0303(X\u03041, . . . , X\u0304N ). \u03bd\u0303 \u2190 the law of Z\u0304. 12 for i = 1, . . . , N do 13 \u03b3\u0302i \u2190 the law of (X\u0304i, Z), \u03b1\u0302i \u2190 E[ci(X\u0304i, Z)]. \u03b3\u0303i \u2190 the law of (X\u0304i, Z\u0304), \u03b1\u0303i \u2190 E[ci(X\u0304i, Z\u0304)]. 14 \u03b1LBMT \u2190 \u03b1LBMTpar , \u03b1\u0302 UB MT \u2190 \u2211N i=1 \u03b1\u0302i, \u03b1\u0303 UB MT \u2190 \u2211N i=1 \u03b1\u0303i. 15 \u03f5\u0302MT \u2190 \u03b1\u0302UBMT \u2212 \u03b1LBMT, \u03f5\u0303MT \u2190 \u03b1\u0303UBMT \u2212 \u03b1LBMT. 16 return (\u03c6\u0303i)i=1:N , \u03bd\u0302, (\u03b3\u0302i)i=1:N , \u03bd\u0303, (\u03b3\u0303i)i=1:N , \u03b1LBMT, \u03b1\u0302 UB MT, \u03b1\u0303 UB MT, \u03f5\u0302MT, \u03f5\u0303MT.\nProof of Proposition 3.5. See Appendix A.2. \u25a1\nThe concrete procedure for computing approximate matching equilibria based on the outputs of Algorithm 1 is detailed in Algorithm 2. Remark 3.6 explains the assumptions and details of Algorithm 2. The properties of Algorithm 2 are detailed in Theorem 3.7.\nRemark 3.6 (Details of Algorithm 2). Let Assumption 3.2 hold. Below is a list explaining the inputs to Algorithm 2.\n\u2022 (Xi)i=1:N , Z , (\u00b5i)i=1:N , and (ci)i=1:N are given by Assumption 1.1. \u2022 \u03f5 > 0 is a pre-specified error tolerance value when calling Algorithm 1 in Line 3 (see Theo-\nrem 3.7). \u2022 (Gi)i=1:N are test functions for \u00b51, . . . , \u00b5N that satisfy Assumption 3.2(ii). H are test func-\ntions on Z that satisfy Assumption 3.2(iii). The choice of (Gi)i=1:N and H controls the suboptimality of the outputs of Algorithm 2 (see Theorem 3.7). \u2022 z\u0303 : X \u2192 Z is a measurable function which satisfies (2.6). \u2022 Oracle(\u00b7, \u00b7, \u00b7) is the global minimization oracle in Definition 2.1.\nThe list below provides further explanations of some lines in Algorithm 2. \u2022 Line 2 constructs finite sets ( C(0)i \u2282 Xi \u00d7 Z ) i=1:N\nwhich are then used as input to Algorithm 1. This is possible due to Proposition 3.5(i), Assumption 3.2(ii), and Assumption 3.2(iii). \u2022 Line 6 requires the support of \u03bd\u0302i\u0302 to be finite, which is guaranteed by Proposition 3.5(v).\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 19\n\u2022 Line 8 constructs an optimal coupling between \u03bd\u0302i\u0302 and \u03bd\u0302i via Lemma 3.1. This is possible since the assumption (C1) is satisfied due to the finite support of \u03bd\u0302i. Moreover, the random variable Xi : \u2126\u2192 Xi in Line 9 is well-defined due to the finite support of (\u03bd\u0302i)i=1:N . \u2022 Line 10 constructs an optimal coupling between the law ofXi (which is equal to the marginal\nof \u03b8\u0302i on Xi) and \u00b5i via Lemma 3.1. This is possible due to Assumption 3.2(i).\nTheorem 3.7 (Properties of Algorithm 2). Let Assumption 3.2 hold. Assume in addition that all inputs of Algorithm 2 are set according to Remark 3.6. Moreover, let ( W 1,\u00b5i ) i=1:N\nsatisfy W 1,\u00b5i \u2265 W 1,\u00b5i ( [\u00b5i]Gi ) for i = 1, . . . , N , let W 1,Z satisfy W 1,Z \u2265 sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 }\n, and let \u03f5\u2021\nW 1 be defined as\n\u03f5\u2021 W 1 := \u03f5+ ( N\u2211 i=1 L(1)ci W 1,\u00b5i ) + (\u2211 i \u0338=i\u0302 L(2)ci ) W 1,Z ,\nwhere i\u0302 \u2208 {1, . . . , N} is chosen in Line 5. Then, the following statements hold.\n(i) (\u03c6\u0303i)i=1:N is an \u03f5\u0303MT-optimizer of (MT\u2217) and for i = 1, . . . , N \u2212 1, \u03c6\u0303i is L (2) ci -Lipschitz\ncontinuous. (ii) \u03bd\u0302 is an \u03f5\u0302MT-optimizer of (MT). (iii) For i = 1, . . . , N , \u03b3\u0302i \u2208 \u0393(\u00b5i, \u03bd\u0302) and \u222b Xi\u00d7Z ci d\u03b3\u0302i \u2264Wci(\u00b5i, \u03bd\u0302) + \u03f5\u0302MT. (iv) \u03bd\u0303 is an \u03f5\u0303MT-optimizer of (MT). (v) For i = 1, . . . , N , \u03b3\u0303i \u2208 \u0393(\u00b5i, \u03bd\u0303) and \u222b Xi\u00d7Z ci d\u03b3\u0303i \u2264Wci(\u00b5i, \u03bd\u0303) + \u03f5\u0303MT. (vi) \u03b1LBMT < (MT) < \u03b1\u0303 UB MT < \u03b1\u0302 UB MT and \u03f5\u0303MT \u2264 \u03f5\u0302MT \u2264 \u03f5\n\u2021 W 1 .\nMoreover, if we assume further that, for i = 1, . . . , N , Xi is a compact subset of Rdi for di \u2208 N and dXi is induced by a norm \u2225 \u00b7 \u2225 on Rdi , and that Z is a compact subset of Rd0 for d0 \u2208 N and dZ is induced by a norm \u2225 \u00b7 \u2225 on Rd0 , then the following statement holds.\n(vii) For any \u03f5\u2021 > 0 and any \u03f5 \u2208 (0, \u03f5\u2021), one can construct finite collections of test functions (Gi)i=1:N satisfying Assumption 3.2(ii), and a finite collection of test functions H satisfying Assumption 3.2(iii) such that \u03f5\u0303MT \u2264 \u03f5\u0302MT \u2264 \u03f5\u2021.\nProof of Theorem 3.7. See Appendix A.2. \u25a1\nRemark 3.8 (Sub-optimality estimates in Algorithm 2 and a priori upper bound). From a theoretical perspective, Theorem 3.7(vii) states that, for any given \u03f5\u2021 > 0, there exist explicit choices of the inputs \u03f5, (Gi)i=1:N , and H of Algorithm 2 such that ( (\u03c6\u0303i)i=1:N , (\u03b3\u0302i)i=1:N , \u03bd\u0302 ) and ( (\u03c6\u0303i)i=1:N ,\n(\u03b3\u0303i)i=1:N , \u03bd\u0303 )\ncomputed by Algorithm 2 are \u03f5\u2021-approximate matching equilibria. One such choice is to let \u03f5 \u2208 (0, \u03f5\u2021) be arbitrary and then let G1, . . . ,GN ,H be defined as in Theorem 2.17(vii) with \u03f5\u0303 \u2190 \u03f5\u2021. However, in practice, one often specifies \u03f5 > 0, (Gi)i=1:N , and H in the inputs of Algorithm 2 and subsequently uses the values of \u03f5\u0302MT and \u03f5\u0303MT in the output to estimate the sub-optimality of the computed solutions. The term \u03f5\u2021\nW 1 in Theorem 3.7(vi) provides a theoretical upper bound for\nthe computed sub-optimality estimates \u03f5\u0302MT and \u03f5\u0303MT. \u03f5 \u2021 W 1 is referred to as an a priori upper bound for \u03f5\u0302MT and \u03f5\u0303MT since it is based on the estimates ( W 1,\u00b5i ) i=1:N of ( W 1,\u00b5i ( [\u00b5i]Gi )) i=1:N and the\nestimate W 1,Z of sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 }\nthat can be computed independent of Algorithm 2. The computed sub-optimality estimates \u03f5\u0302MT and \u03f5\u0303MT are typically much less conservative than their a priori upper bound \u03f5\u2021\nW 1 , as we will demonstrate in the numerical experiments in\nSection 4."
        },
        {
            "heading": "20 A. NEUFELD AND Q. XIANG",
            "text": "4. NUMERICAL EXPERIMENTS\nIn this section, we perform numerical experiments to demonstrate the numerical algorithm (i.e., Algorithm 2) that we have developed. The first numerical experiment in Section 4.1 studies the business location distribution problem in Example 1.3 where X1, . . . ,XN ,Z \u2282 R2 are two-dimensional to demonstrate the convergence of the approximate matching equilibria constructed by Algorithm 2 to true matching equilibria. The second numerical experiment in Section 4.2 investigates the empirical scalability of our algorithm in a problem where X1, . . . ,XN \u2282 R and Z \u2282 R2. The code used in the numerical experiments is available on GitHub9.\n4.1. Experiment 1. In our first numerical experiment, we fix a few combinations of the test functions G1, . . . ,GN ,H and subsequently investigate the upper and lower bounds computed by our algorithm and the convergence of the computed approximate matching equilibria. Specifically, we consider the following setting, whose economic interpretation has been discussed in Example 1.3.\nAssumption 4.1 (Numerical experiment with two-dimensional type spaces). We assume that the following statements hold.\n\u2022 For i = 1, . . . , N , Xi = \u22c3\nC\u2208Ci C \u2282 R 2, where Ci is a finite collection of triangles such that\nwhenever C1 \u2229 C2 \u0338= \u2205 for distinct C1, C2 \u2208 Ci then C1 \u2229 C2 is a face (i.e., a vertex or an edge) of C1 and C2. Moreover, dXi(xi,x \u2032 i) := \u2225xi \u2212 x\u2032i\u22252.\n\u2022 Z = \u22c3\nC\u2208C0 C \u2282 R 2, where C0 is a finite collection of triangles such that whenever C1 \u2229\nC2 \u0338= \u2205 for distinct C1, C2 \u2208 C0 then C1 \u2229 C2 is a face (i.e., a vertex or an edge) of C1 and C2. Moreover, dZ(z, z\u2032) := \u2225z \u2212 z\u2032\u22252. \u2022 For i = 1, . . . , N , \u00b5i \u2208 P(Xi) is absolutely continuous with respect to the Lebsegue measure\non Xi and supp(\u00b5i) = Xi. \u2022 For i = 1, . . . , N , ci : Xi \u00d7Z \u2192 R is given by ci(xi, z) := 1N ( \u2225z\u222522 \u2212 2\u27e8xi, z\u27e9 ) . \u2022 For i = 1, . . . , N , let {vi,0,vi,1, . . . ,vi,mi} be an arbitrary enumeration of the finite set V (Ci) := { v \u2208 R2 : v is an extreme point of some C \u2208 Ci } (i.e., the cardinality of this set is\nmi+1 \u2208 N), let Gi := { gi,vi,1 , . . . , gi,vi,mi } , and let gi(xi) := ( gi,vi,1(xi), . . . , gi,vi,mi (xi) )T for all xi \u2208 Xi, where the functions (gi,vi,j : Xi \u2192 R)j=1:mi are defined in Theorem 2.17(vii). \u2022 Let {v0,0,v0,1, . . . ,v0,k} be an arbitrary enumeration of the finite set V (C0) := { v \u2208 R2 : v\nis an extreme point of some C \u2208 C0 }\n(i.e., the cardinality of this set is k + 1 \u2208 N), let H := { hv0,1 , . . . , hv0,k } , and let h(z) := ( hv0,1(z), . . . , hv0,k(z) )T for all z \u2208 Z , where the functions (hv0,l : Z \u2192 R)l=1:k are defined in Theorem 2.17(vii).\nIn particular, these statements imply that Assumption 3.2 is satisfied.\nIn the problem instance that we study, we let \u00b51 \u2208 P(X1), . . . , \u00b5N \u2208 P(XN ) be probability measures with continuous piece-wise affine density functions. Figure 4.1 shows the shape of the sets X1, . . . ,XN and Z , as well as the randomly generated probability density functions of \u00b51, . . . , \u00b5N , where darker color represents higher density. Throughout this experiment, we partition the sets Z and X1, . . . ,XN into finite collections of triangles in a number of different ways. Each combination C0,C1, . . . ,CN of such partitions satisfy Assumption 4.1 and thus yields collections of test functions H,G1, . . . ,GN . The grey-colored lines in Figure 4.1 show a particular combination of partitions of the sets Z,X1, . . . ,XN .\nDue to the structure of the cost functions c1, . . . , cN , we can derive the following proposition.\nProposition 4.2. Let Assumption 4.1 hold. Then, for i = 1, . . . , N and for any yi \u2208 Rmi , wi \u2208 Rk, it holds that\ninf xi\u2208Xi,zi\u2208Z\n{ ci(xi, zi)\u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi\u27e9 } = min\nxi\u2208V (Ci),zi\u2208Z\n{ ci(xi, zi)\u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi\u27e9 } .\n9https://github.com/qikunxiang/MatchingForTeams\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 21\nProof of Proposition 4.2. See Appendix A.2. \u25a1\nIn Algorithm 1, it follows from Proposition 4.2 that we may restrict the set C\u22c6(r)i in Line 6 to be a subset of V (Ci) \u00d7 Z while preserving its correctness. Subsequently, for i = 1 . . . , N , the output \u03b8\u0302i of Algorithm 1 will be a discrete probability measure with support in V (Ci)\u00d7Z . Since the marginal of \u03b8\u0302i on Xi is required to be in [\u00b5i]Gi by Proposition 3.5(v), one can check that the marginal of \u03b8\u0302i on Xi must be equal to \u00b5\u0302i, given by:\n\u00b5\u0302i = mi\u2211 j=0 (\u222b Xi gi,vi,j d\u00b5i ) \u03b4vi,j ,\nwhich only depends on \u00b5i and Gi. In Line 10 of Algorithm 2, an optimal coupling of \u00b5\u0302i and \u00b5i is constructed via Lemma 3.1. Since \u00b5\u0302i is discrete and \u00b5i is continuous, this corresponds to the discreteto-continuous case (C2) in Lemma 3.1. Thus, an optimal coupling of \u00b5\u0302i and \u00b5i can be characterized"
        },
        {
            "heading": "22 A. NEUFELD AND Q. XIANG",
            "text": "by (3.3) via subsets of Xi defined in (3.2), which are referred to as cells in a Laguerre diagram. Figure 4.2 shows the Laguerre diagrams characterizing the computed optimal couplings of \u00b5\u0302i and \u00b5i for i = 1, . . . , N , where the partitions C1, . . . ,CN of X1, . . . ,XN are identical to those shown in Figure 4.1. In Figure 4.2, each circle represents an atom in the discrete measure \u00b5\u0302i, where the color of the circle represents the probability of that atom. The cell surrounding each atom corresponds to the cell in the computed Laguerre diagram that the atom is coupled with. These Laguerre diagrams allow independent random samples to be efficiently generated from the couplings (\u03b3\u0302i)i=1:N and (\u03b3\u0303i)i=1:N via (3.3) in Lemma 3.1 and rejection sampling. This subsequently allows \u03b1\u0302UBMT and \u03b1\u0303 UB MT in Line 14 of Algorithm 2 to be efficiently and accurately approximated via Monte Carlo integration. In order to compute approximate matching equilibria for this matching for teams problem, we fix \u03f5 = 0.005 and test 7 different combinations of test functions resulted from partitions C0,C1, . . . ,CN of the sets Z,X1, . . . ,XN . Specifically, the test functions in G1, . . . ,GN are defined based on increasingly finer partitions of X1, . . . ,XN , and the value of |G1|+ \u00b7 \u00b7 \u00b7+ |GN | ranges between 60 and 4800. Moreover, the test functions in H are defined based on increasingly finer partitions of Z , and the value of |H| ranges between 35 and 863. The values of \u03b1\u0302UBMT, \u03b1\u0303UBMT in Line 14 of Algorithm 2 are computed via Monte Carlo integration using 106 independent random samples. Moreover, each Monte Carlo integration is repeated 100 times in order to examine the Monte Carlo error.\nFigure 4.3 shows the computed upper and lower bounds for (MT), the sub-optimality estimates \u03f5\u0302MT, \u03f5\u0303MT, and their a priori theoretical upper bound \u03f5\n\u2021 W 1 given by\n\u03f5\u2021 W 1 := \u03f5+ 4 N max z\u2208Z\n{ \u2225z\u22252 }( N\u2211 i=1 max C\u2208Ci max x,x\u2032\u2208C { \u2225x\u2212 x\u2032\u22252 })\n+\n[ 4(N \u2212 1)\nN max z\u2208Z\n{ \u2225z\u22252 } + 4\nN \u2211 i \u0338=i\u0302 max xi\u2208Xi { \u2225xi\u22252 }] max C\u2208C0 max z,z\u2032\u2208C { \u2225z \u2212 z\u2032\u22252 } .\nNote that the a priori theoretical upper bound \u03f5\u2021 W 1 is derived from Theorem 3.7(vi) with\nL(1)ci := 2\nN max z\u2208Z\n{ \u2225z\u22252 } \u22001 \u2264 i \u2264 N,\nL(2)ci := 2\nN ( max z\u2208Z { \u2225z\u22252 } +max x\u2208Xi { \u2225x\u22252 }) \u22001 \u2264 i \u2264 N,\nW 1,\u00b5i := 2max C\u2208Ci max x,x\u2032\u2208C\n{ \u2225x\u2212 x\u2032\u22252 } \u2265W 1,\u00b5i ( [\u00b5i]Gi ) \u22001 \u2264 i \u2264 N,\nW 1,Z := 2 max C\u2208C0 max z,z\u2032\u2208C\n{ \u2225z \u2212 z\u2032\u22252 } \u2265 sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 } .\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 23\nThe left panel of Figure 4.3 shows the upper bounds \u03b1\u0302UBMT, \u03b1\u0303 UB MT and the lower bound \u03b1 LB MT computed by Algorithm 2. The horizontal axis shows the number of test functions used, i.e., each tuple corresponds to ( |G1|+ \u00b7 \u00b7 \u00b7+ |GN |, |H| ) . It can be seen that the differences between the upper bounds and the lower bound are initially large when |G1|+ \u00b7 \u00b7 \u00b7+ |GN | = 60 and |H| = 35. When |G1|+ \u00b7 \u00b7 \u00b7+ |GN | and |H| both increase, the difference between the bounds decreases. When |G1|+ \u00b7 \u00b7 \u00b7+ |GN | = 4800 and |H| = 863, the values of the computed sub-optimality estimates \u03f5\u0302MT and \u03f5\u0303MT are 0.0633 and 0.0582, respectively. By Theorem 2.15, this shows that ( (\u03c6\u0303i)i=1:N , (\u03b3\u0302i)i=1:N , \u03bd\u0302 ) and ( (\u03c6\u0303i)i=1:N ,\n(\u03b3\u0303i)i=1:N , \u03bd\u0303 )\ncomputed by Algorithm 2 are approximate matching equilibria that are close to true matching equilibria. The center panel of Figure 4.3 shows a magnification of the left panel, with error bars indicating the 95% intervals of Monte Carlo integration. From the results, it can be observed that the differences between the two upper bounds \u03b1\u0302UBMT and \u03b1\u0303 UB MT are small. The right panel of Figure 4.3 compares the computed sub-optimality estimates \u03f5\u0302MT and \u03f5\u0303MT with their a priori theoretical upper bound \u03f5\u2021\nW 1 on the log-scale. The results show that the value of \u03f5\u2021 W 1 is one to two orders of magni-\ntude larger than \u03f5\u0302MT and \u03f5\u0303MT. This demonstrates that not only does Algorithm 2 produce feasible solutions of (MT), (MT\u2217), and (MTcp), it also produces sub-optimality estimates \u03f5\u0302MT, \u03f5\u0303MT of these feasible solutions that are much less conservative than suggested by an a priori theoretical analysis, as discussed in Remark 3.8. Specifically, when |G1|+ \u00b7 \u00b7 \u00b7+ |GN | = 4800 and |H| = 863, the value of \u03f5\u2021 W 1 is equal to 28.8769, which indicates that the solutions computed by Algorithm 2 could be poor. Despite that, the sub-optimality estimates \u03f5\u0302MT and \u03f5\u0303MT computed by Algorithm 2 are equal to 0.0633 and 0.0582, respectively, indicating that ( (\u03c6\u0303i)i=1:N , (\u03b3\u0302i)i=1:N , \u03bd\u0302 ) and ( (\u03c6\u0303i)i=1:N , (\u03b3\u0303i)i=1:N , \u03bd\u0303 ) are close to being optimal."
        },
        {
            "heading": "24 A. NEUFELD AND Q. XIANG",
            "text": "Finally, Figure 4.4 shows the approximately optimal transfer functions (\u03c6\u0303i)i=1:N and the approximately optimal couplings (\u03b3\u0302i)i=1:N , (\u03b3\u0303i)i=1:N computed by Algorithm 2 when |G1| + \u00b7 \u00b7 \u00b7 + |GN | = 4800 and |H| = 863. The top panel of Figure 4.4 shows the values of the functions (\u03c6\u0303i)i=1:N in color plots. The bottom-left panel shows independent realizations from the random variable (X\u03041, . . . , X\u0304N , Z) constructed by Algorithm 2. They can be seen as coupled random samples from the probability measures (\u03b3\u0302i)i=1:N . The bottom-right panel shows independent realizations from the random variable (X\u03041, . . . , X\u0304N , Z\u0304) constructed by Algorithm 2. They can be seen as coupled random samples from the probability measures (\u03b3\u0303i)i=1:N . These samples also demonstrate how agents from the 10 categories are matched together to form teams.\nWhen we adopt the interpretation of the matching for teams problem as an economic game of locating business outlets described in Example 1.3, up to additions of constants that sum up to 0, the functions \u03c6\u03031, . . . , \u03c6\u0303N\u22121 represent the amount of salary earned by the employees from the categories 1, . . . , N\u22121 working at each location of business outlet, and the function \u03c6\u0303N represents the negative of the total amount of salary paid out at each location of business outlet. Since for i = 1, . . . , N \u2212 1, the commuting cost ci(xi, z) := 1N ( \u2225z\u222522\u22122\u27e8xi, z\u27e9 ) = 1N \u2225xi\u2212z\u2225 2 2\u2212 1N \u2225xi\u2225 2 2 is equal to the scaled squared Euclidean distance 1N \u2225xi\u2212z\u2225 2 2 minus a term 1 N \u2225xi\u2225 2 2 that does not affect the matching, employees working at business outlets that are further from home will be paid more salary compared to employees working at business outlets closer to home. This can be observed from Figure 4.4. For example, since X1 is located to the north of Z (see Figure 4.1), for an employee from category 1, the south part of Z is further away compared to the north part of Z . Therefore, it can be observed from Figure 4.4 that the value of \u03c6\u03031 is larger in the south part of Z compared to the north part of Z . Similarly, since the restocking cost cN (xN , z) := 1N ( \u2225z\u222522\u22122\u27e8xN , z\u27e9 ) = 1N \u2225xN\u2212z\u2225 2 2\u2212 1N \u2225xN\u2225 2 2 is also equal to the scaled squared Euclidean distance 1N \u2225xN \u2212z\u2225 2 2 minus a term 1 N \u2225xN\u2225 2 2 that does not affect the matching, business outlets that are closer to the suppliers will pay more salary to their employees compared to business outlets that are further from the suppliers at an approximate matching equilibrium. This can also be observed from the relative positions of X10 and Z in Figure 4.1 and the values of \u03c6\u030310 in Figure 4.4. These experimental results can not only provide insights for the business owners to decide where to locate the business outlets, but also aid city planners in building future public transportation systems in the city.\n4.2. Experiment 2. In the second numerical experiment, we examine the scalability of Algorithm 1 in terms of how its running time changes with the number N of agent categories in the matching for teams problem. Specifically, we consider the following setting.\nAssumption 4.3 (Numerical experiment with one-dimensional type spaces). We assume that the following statements hold.\n\u2022 For i = 1, . . . , N , Xi = [\u03bai, \u03bai] \u2282 R, where \u2212\u221e < \u03bai < \u03bai <\u221e. Moreover, dXi(xi, x\u2032i) := |xi \u2212 x\u2032i|. \u2022 Z = \u22c3 C\u2208C0 C \u2282 R\n2 is a polytope, where C0 is a finite collection of triangles such that whenever C1 \u2229 C2 \u0338= \u2205 for distinct C1, C2 \u2208 C0 then C1 \u2229 C2 is a face (i.e., a vertex or an edge) of C1 and C2. Moreover, dZ(z, z\u2032) := \u2225z \u2212 z\u2032\u22252. \u2022 For i = 1, . . . , N , \u00b5i \u2208 P(Xi) is absolutely continuous with respect to the Lebsegue measure\non Xi and supp(\u00b5i) = Xi. \u2022 For i = 1, . . . , N , ci : Xi \u00d7 Z \u2192 R is given by ci(xi, z) := li ( xi \u2212 \u27e8si, z\u27e9 ) where\nsi \u2208 R2 and li : [\u03bbi,0, \u03bbi,ni ] \u2192 R is a continuous function that is piece-wise affine on [\u03bbi,0, \u03bbi,1], . . . , [\u03bbi,ni\u22121, \u03bbi,ni ] for ni \u2208 N, \u2212\u221e < \u03bbi,0 < \u03bbi,1 < \u00b7 \u00b7 \u00b7 < \u03bbi,ni <\u221e, satisfying \u03bbi,0 \u2264 \u03bai \u2212maxz\u2208Z { \u27e8si, z\u27e9 } , \u03bbi,ni \u2265 \u03bai \u2212minz\u2208Z { \u27e8si, z\u27e9 } .\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 25\n\u2022 For i = 1, . . . , N , \u03bai = \u03bai,0 < \u03bai,1 < \u00b7 \u00b7 \u00b7 < \u03bai,mi = \u03bai, and gi,0, gi,1, . . . , gi,mi : Xi \u2192 R are defined as follows:\ngi,0(xi) := (\u03bai,1 \u2212 xi)+\n\u03bai,1 \u2212 \u03bai,0 ,\ngi,j(xi) := min\n{ (xi \u2212 \u03bai,j\u22121)+\n\u03bai,j \u2212 \u03bai,j\u22121 , (\u03bai,j+1 \u2212 xi)+ \u03bai,j+1 \u2212 \u03bai,j\n} \u22001 \u2264 j \u2264 mi \u2212 1,\ngi,mi(xi) := (xi \u2212 \u03bai,mi\u22121)+\n\u03bai,mi \u2212 \u03bai,mi\u22121 .\nLet Gi := {gi,1, . . . , gi,mi} and let gi(xi) := ( gi,1(xi), . . . , gi,mi(xi) )T for all xi \u2208 Xi. \u2022 Let {v0,0,v0,1, . . . ,v0,k} be an arbitrary enumeration of the finite set V (C0) := { v \u2208 R2 : v\nis an extreme point of some C \u2208 C0 }\n(i.e., the cardinality of this set is k + 1 \u2208 N), let H := { hv0,1 , . . . , hv0,k } , and let h(z) := ( hv0,1(z), . . . , hv0,k(z) )T for all z \u2208 Z , where the functions (hv0,l : Z \u2192 R)l=1:k are defined in Theorem 2.17(vii).\nIn particular, these statements imply that Assumption 3.2 is satisfied.\nThus, under Assumption 4.3, the spaces X1, . . . ,XN representing agent types are all onedimensional, while the quality space Z is two-dimensional. In order to investigate the performance of our method, we independently randomly generate 10 problem instances (or scenarios) as follows:\n\u2022 each \u00b5i is a probability measure on the closed interval [0, 1] with a probability density function that is continuous and piece-wise affine on the intervals [ 0, 14 ] , [ 1 4 , 1 2 ] , [ 1 2 , 3 4 ] , [ 3 4 , 1 ] ,\nwhere the values of the density function at the points 0, 14 , 1 2 , 3 4 , 1 are randomly generated; \u2022 Z = conv ({(\n0 0 ) , ( 1 0 ) , ( 0 1 )}) ;\n\u2022 each si \u2208 R2 is a random point on the unit circle and each li(\u00b7) is defined by\nli(t) :=  0 if |t| \u2264 \u03b8i,1, 1 N ( |t| \u2212 \u03b8i,1 ) if \u03b8i,1 < |t| \u2264 \u03b8i,2,\n1 N (\u03b8i,2 \u2212 \u03b8i,1) if |t| > \u03b8i,2,\nwhere \u03b8i,2 > \u03b8i,1 > 0 are randomly generated constants; \u2022 for each i, mi = 49 and \u03bai,0 < \u03bai,1 < \u00b7 \u00b7 \u00b7 < \u03bai,mi are 50 evenly-spaced points in [0, 1]; \u2022 k = 560 and {v0,0,v0,1, . . . ,v0,k} form an evenly-spaced two-dimensional grid of 561\npoints in Z .\nThe choice of the function li reflects a practical interpretation of the matching for teams problem under Assumption 4.3. In this problem, each unit of good is characterized by its two qualities in Z . For each i, each agent within the i-th category has a randomly distributed latent preference variable xi \u2208 Xi, and the vector si \u2208 R2 represents the weights these agents use to assess the qualities of goods. The cost function ci(xi, z) depends on the absolute difference between the agent\u2019s preference xi and the agent\u2019s assessment \u27e8si, z\u27e9, where the cost is 0 if\n\u2223\u2223xi \u2212 \u27e8si, z\u27e9\u2223\u2223 is below a threshold \u03b8i,1, the cost grows linearly when\n\u2223\u2223xi \u2212 \u27e8si, z\u27e9\u2223\u2223 is above the threshold \u03b8i,1 but below a second threshold \u03b8i,2, and the cost remains constant when\n\u2223\u2223xi \u2212 \u27e8si, z\u27e9\u2223\u2223 exceeds the second threshold \u03b8i,2. In this experiment, we fix \u03f5 = 5\u00d7 10\u22125. It follows from the definition that ci is 1N -Lipschitz continuous (with respect to the 1-product metric on Xi\u00d7Z). Therefore, we define the a priori theoretical"
        },
        {
            "heading": "26 A. NEUFELD AND Q. XIANG",
            "text": "= 0.1293).\nupper bound \u03f5\u2021 W 1 by10\n\u03f5\u2021 W 1 := \u03f5+ ( N\u2211 i=1 2 N max 1\u2264j\u2264mi {\u03bai,j \u2212 \u03bai,j\u22121} ) + ( N\u2211 i=1 1 N ) 2 max C\u2208C0 max z,z\u2032\u2208C { \u2225z \u2212 z\u2032\u22252 } = \u03f5+ 2\nm1 + 2max C\u2208C0 max z,z\u2032\u2208C\n{ \u2225z \u2212 z\u2032\u22252 } = 0.1293,\nwhich remains constant for all values of N . In Algorithm 1 The global minimization problem Oracle(\u00b7, \u00b7, \u00b7) in Definition 2.1 is formulated into a mixed-integer programming problem11 and are subsequently solved by the mixedinteger solver of Gurobi [43]. We would like to remark that the global minimization problems Oracle ( 1,y\n(r) 1 ,w (r) 1\n) , . . . , Oracle ( N,y\n(r) N ,w (r) N\n) in Line 5 of Algorithm 1 can be solved in par-\nallel. However, we choose to solve them sequentially in our implementation of Algorithm 1 in order not to over-complicate the running time analysis.\nWe apply Algorithm 2 to the 10 randomly generated problem instances and record the computed values of the sub-optimality estimate \u03f5\u0302MT as well as the running time of Algorithm 1 for N = 4, 6, 8, 10, 12, 14, 16, 18, 20, 50, 80, 100 agent categories. \u03f5\u0302MT is computed via Monte Carlo integration using 107 independent samples. We only examine the values of \u03f5\u0302MT here because \u03f5\u0303MT \u2264 \u03f5\u0302MT and the computation of \u03f5\u0303MT requires us to solve a global minimization problem (2.5), which is more computationally costly than the computation of \u03f5\u0302MT. In addition, we only examine the running time of Line 3 in Algorithm 2, i.e., the running time of Algorithm 1. The running time of the rest of Algorithm 2 consists mostly of time spent computing \u03b1\u0302UBMT via Monte Carlo integration in Line 13, which can be parallelized and is negligible compared to the running time of Line 3 when N is large.\nThe left part of Table 4.1 shows the average and maximum sub-optimality estimates and the average and maximum running time of Algorithm 1 when N = 4, 6, 8, 10, 12, 14, 16, 18, 20, 50, 80, 100. From the results, it can be seen that the values of the sub-optimality estimate \u03f5\u0302MT computed by\n10For i = 1, . . . , N , it follows from the definitions of Gi and the proof of Theorem 2.17(vii) that W 1,\u00b5i ( [\u00b5i]Gi ) \u2264 2max1\u2264j\u2264mi{\u03bai,j \u2212 \u03bai,j\u22121}. Moreover, it follows from the definition of H and the proof of Theorem 2.17(vii) that sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd\u2032 \u2208 P(Z), \u03bd H\u223c \u03bd\u2032 } \u2264 2maxC\u2208C0 maxz,z\u2032\u2208C { \u2225z \u2212 z\u2032\u22252 } .\n11Additional details about the mixed-integer programming formulation can be found in the online appendix on GitHub: https://github.com/qikunxiang/MatchingForTeams.\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 27\nour algorithm are about two orders of magnitude smaller than the a priori theoretical upper bound \u03f5\u2021 W 1 = 0.1293.\nFigure 4.5 shows the total running time of the LP solver in Line 3 of Algorithm 1, and the total running time of Oracle(\u00b7, \u00b7, \u00b7) in Line 5 of Algorithm 1. It can be seen that the total running time of Oracle(\u00b7, \u00b7, \u00b7) in Algorithm 1 is much longer relative to the LP solver for all values of N , showing that almost all of the running time is spent on computing Oracle(\u00b7, \u00b7, \u00b7). An interesting observation is that the total running time of Oracle(\u00b7, \u00b7, \u00b7) seems to grow approximately linearly in N . This is in line with our discussion in Remark 2.4. Under Assumption 4.3, for i = 1, . . . , N and for yi \u2208 Rmi , wi \u2208 Rk, the global minimization problem Oracle(\u00b7, \u00b7, \u00b7) is given by\nminimize xi,zi\nli ( xi \u2212 \u27e8si, zi\u27e9 ) \u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi)\u27e9\nsubject to \u03bai \u2264 xi \u2264 \u03bai, zi \u2208 Z,\nwhich corresponds to minimizing a continuous piece-wise affine function with 3 variables, since Xi \u00d7 Z \u2282 R3. Thus, the computational cost of this minimization indeed does not depend on N . Since each iteration of Algorithm 1 solves N such minimization problems, the total running time of Oracle(\u00b7, \u00b7, \u00b7) in each iteration of Algorithm 1 increases linearly in N . In addition, in Algorithm 1, the number of iterations till convergence grows slowly relative to the growth of N , which makes the total running time of Oracle(\u00b7, \u00b7, \u00b7) in Algorithm 1 grow approximately linearly inN . Moreover, this shows that in a computing environment with sufficient parallelization capabilities, a suitable parallel implementation of the for-loop in Line 4 can drastically reduce the running time of Algorithm 1.\nRemark 4.4. The LP problem (MT\u2217(r)par ) that is solved in Line 3 of Algorithm 1 has a structure which allows it to be efficiently solved by parallel algorithms based on operator splitting methods; see, e.g., [33]. In this experiment, we use the standard LP solver provided by Gurobi [43] since it is reasonably efficient. The investigation of the parallelization aspects of Algorithm 1 is left as future work.\nFurthermore, recall that we have shown in Corollary 2.13 the existence of an approximate optimizer \u03bd\u0302 of (MT) with |supp(\u03bd\u0302)| \u2264 min1\u2264i\u2264N{mi} + k + 2. The right part of Table 4.1 shows the average and maximum values of |supp(\u03bd\u0302)|, where \u03bd\u0302 is the discrete approximate optimizer of (MT) computed by Algorithm 2. It shows that \u03bd\u0302 computed by Algorithm 2 is even more sparse than what Corollary 2.13 suggests, even though |supp(\u03bd\u0302)| still increases with N . A possible explanation of the latter phenomenon is as follows. As discussed by Carlier et al. [24, Section 2.2], one can restrict the quality space Z to any subset Z \u2032 \u2286 Z satisfying Z \u2032 \u2287 z\u0303(X ) without affecting the optimal value of (MT). This suggests that there could be many test functions in H that are redundant since they are identical when their domains are restricted to a suitable choice of Z \u2032."
        },
        {
            "heading": "28 A. NEUFELD AND Q. XIANG",
            "text": "APPENDIX A. PROOF OF THEORETICAL RESULTS\nA.1. Proof of results in Section 2.\nProof of Theorem 2.2. This proof is based on the theoretical computational complexity of the cuttingplane algorithm of Vaidya [66]. In order to apply the theory of Vaidya [66], we will need the superlevel sets of (MT\u2217par) to contain a Euclidean ball, which is prevented by the presence of the equality constraint \u2211N i=1wi = 0k. Therefore, we will first show that, under the assumption that the functions\nh1, . . . , hk are all non-negative, we can relax the equality constraint into an inequality constraint\u2211N i=1wi \u2265 0k, that is, we will show that the optimal value of (MT\u2217par) is equal to the optimal value of the following problem:\nmaximize (yi,0,yi,wi) N\u2211 i=1 yi,0 + \u27e8g\u0304i,yi\u27e9\nsubject to yi,0 + \u27e8gi(xi),yi\u27e9+ \u27e8h(zi),wi\u27e9 \u2264 ci(xi, zi) \u2200(xi, zi) \u2208 Xi \u00d7Z, \u22001 \u2264 i \u2264 N,\nN\u2211 i=1 wi \u2265 0k,\nyi,0 \u2208 R, yi \u2208 Rmi , wi \u2208 Rk \u22001 \u2264 i \u2264 N.\n(A.1)\nSuppose that (yi,0,yi,wi)i=1:N is feasible for (A.1), and let w\u0302i := wi for i = 1, . . . , N \u2212 1, w\u0302N := \u2212 \u2211N\u22121 i=1 wi. Since \u2211N i=1wi \u2265 0k, we have w\u0302N \u2264 wN . For any xN \u2208 XN and any zN \u2208 Z , since h(zN ) \u2265 0k, we have\nyN,0 + \u27e8gN (xN ),yN \u27e9+ \u27e8h(zN ), w\u0302N \u27e9 \u2264 yN,0 + \u27e8gN (xN ),yN \u27e9+ \u27e8h(zN ),wN \u27e9 \u2264 cN (xN , zN ).\nIt follows that (yi,0,yi, w\u0302i)i=1:N is feasible for (MT\u2217par) and that its corresponding objective value is equal to the objective value of (yi,0,yi,wi)i=1:N . This shows that each feasible solution of (A.1) can be modified into a feasible solution of (MT\u2217par) with equal objective value. In particular, (MT \u2217 par) and (A.1) have identical optimal values. In the following, for notational simplicity, let \u03b1\u22c6 \u2208 R denote the optimal value of (A.1), let S \u2282 Rm+N(k+1) denote the feasible set of (A.1), i.e.,\nS := { (y1,0,y T 1 ,w T 1 , . . . , yN,0,y T N ,w T N ) T \u2208 Rm+N(k+1) : \u2211N i=1wi \u2265 0k,\nyi,0 + \u27e8gi(xi),yi\u27e9+ \u27e8h(zi),wi\u27e9 \u2264 ci(xi, zi) \u2200(xi, zi) \u2208 Xi \u00d7Z \u22001 \u2264 i \u2264 N } ,\nand let S\u03b1 \u2286 S denote the \u03b1-superlevel set of (A.1) for all \u03b1 \u2208 R, i.e., S\u03b1 := { (y1,0,y T 1 ,w T 1 , . . . , yN,0,y T N ,w T N ) T \u2208 S : \u2211N i=1 yi,0 + \u27e8g\u0304i,yi\u27e9 \u2265 \u03b1 } .\nMoreover, for r > 0, let B(r) \u2282 Rm+N(k+1) denote the Euclidean ball with radius r centered at the origin. In the remainder of this proof, we apply the cutting-plane algorithm of Vaidya [66], where we consider the maximization of the linear objective function\nRm+N(k+1) \u220b (y1,0,yT1 ,wT1 , . . . , yN,0,yTN ,wTN )T 7\u2192 N\u2211 i=1 yi,0 + \u27e8g\u0304i,yi\u27e9 \u2208 R\nover the feasible set S \u2229B(L+ 1). By assumption, restricting the feasible set of (A.1) to B(L+ 1) does not affect its optimal value. In order to apply the theory of Vaidya [66], we need to establish the two following statements.\n(i) For any 0 < \u03f5 < 1, the set S\u03b1\u22c6\u2212\u03f5 \u2229B(L+ 1) contains a Euclidean ball with radius \u03f54\u221a3kN .\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 29\n(ii) There exists a so-called separation oracle, which, given any (y\u0302i,0 \u2208 R, y\u0302i \u2208 Rmi , w\u0302i \u2208 Rk)i=1:N , either outputs that (y\u03021,0, y\u0302T1 , w\u0302T1 , . . . , y\u0302N,0, y\u0302TN , w\u0302TN )T \u2208 S \u2229B(L+1) or outputs a vector (g\u03021,0, g\u0302T1 , h\u0302 T 1 , . . . , g\u0302N,0, g\u0302 T N , h\u0302 T N ) \u2208 Rm+N(k+1) such that\nN\u2211 i=1 g\u0302i,0yi,0 + \u27e8g\u0302i,yi\u27e9+ \u27e8h\u0302i,wi\u27e9 \u2264 N\u2211 i=1 g\u0302i,0y\u0302i,0 + \u27e8g\u0302i, y\u0302i\u27e9+ \u27e8h\u0302i, w\u0302i\u27e9\n\u2200(y1,0,yT1 ,wT1 , . . . , yN,0,yTN ,wTN )T \u2208 S \u2229B(L+ 1).\nMoreover, the cost of each call to this separation oracle is O(NT ).\nTo prove statement (i), let (y\u22c61,0,y \u22c6T 1 ,w \u22c6T 1 , . . . , y \u22c6 N,0,y \u22c6T N ,w \u22c6T N ) T be the optimizer of (MT\u2217par) in the statement of the theorem. For i = 1, . . . , N , let y\u0302i,0 := y\u22c6i,0 \u2212 \u03f52N , y\u0302i := y \u22c6 i , w\u0302i := w\u22c6i + \u03f5 4 \u221a kN\n1k, where 1k denotes the vector in Rk with all entries equal to 1. For i = 1, . . . , N , the definition of g\u0304i in (2.3) and the assumption \u2225gi(xi)\u22252 \u2264 1 for all xi \u2208 Xi imply that \u2225g\u0304i\u22252 \u2264 1. Let (u1,0,uT1 , sT1 , . . . , uN,0,uTN , sTN )T \u2208 Rm+N(k+1) be an arbitrary vector with \u2225(u1,0,uT1 , sT1 , . . . , uN,0,uTN , sTN )T\u22252 \u2264 1. We have\nN\u2211 i=1 y\u0302i,0 + \u03f5 4 \u221a 3kN ui,0 + \u2329 g\u0304i, y\u0302i + \u03f5 4 \u221a 3kN ui \u232a\n= ( N\u2211 i=1 y\u22c6i,0 + \u27e8g\u0304i,y\u22c6i \u27e9 ) \u2212 ( N\u2211 i=1 \u03f5 2N ) +\n\u03f5\n4 \u221a 3kN ( N\u2211 i=1 ui,0 + \u27e8g\u0304i,ui\u27e9 )\n= \u03b1\u22c6 \u2212 \u03f5 2 +\n\u03f5\n4 \u221a 3kN ( N\u2211 i=1 ui,0 + \u27e8g\u0304i,ui\u27e9 ) \u2265 \u03b1\u22c6 \u2212 \u03f5\n2 \u2212 \u03f5 4 \u221a 3kN \u2225\u2225(1, g\u0304T1 , . . . , 1, g\u0304TN )T\u2225\u22252\u2225\u2225(u1,0,uT1 , . . . , uN,0,uTN )T\u2225\u22252 = \u03b1\u22c6 \u2212 \u03f5\n2 \u2212 \u03f5 4 \u221a 3kN ( N\u2211 i=1 1 + \u2225g\u0304i\u222522 ) 1 2\u2225\u2225(u1,0,uT1 , . . . , uN,0,uTN )T\u2225\u22252\n> \u03b1\u22c6 \u2212 \u03f5.\n(A.2)\nIn addition, for i = 1, . . . , N and for any (xi, zi) \u2208 Xi \u00d7Z , we have\ny\u0302i,0 + \u03f5 4 \u221a 3kN\nui,0 + \u2329 gi(xi), y\u0302i +\n\u03f5 4 \u221a 3kN\nui \u232a + \u2329 h(zi), w\u0302i +\n\u03f5 4 \u221a 3kN\nsi \u232a\n= ( y\u22c6i,0 + \u27e8gi(xi),y\u22c6i \u27e9+ \u27e8h(zi),w\u22c6i \u27e9 ) \u2212 \u03f5\n2N +\n\u03f5\n4 \u221a kN \u27e8h(zi),1k\u27e9\n+ \u03f5\n4 \u221a 3kN\n( ui,0 + \u27e8gi(xi),ui\u27e9+ \u27e8h(zi), si\u27e9 ) \u2264 ci(xi, zi)\u2212 \u03f5\n2N +\n\u03f5\n4 \u221a kN \u2225h(zi)\u22252\u22251k\u22252\n+ \u03f5\n4 \u221a 3kN \u2225\u2225(1, gi(xi)T,h(zi)T)T\u2225\u22252\u2225(ui,0,uTi , sTi )\u22252 \u2264 ci(xi, zi)\u2212 \u03f5\n2N +\n\u03f5\n4N +\n\u03f5\n4 \u221a 3kN\n( 1 + \u2225gi(xi)\u222522 + \u2225h(zi)\u222522 ) 1 2 \u2225(ui,0,uTi , sTi )\u22252\n\u2264 ci(xi, zi)\u2212 \u03f5\n2N +\n\u03f5\n4N +\n\u03f5\n4 \u221a kN\n\u2264 ci(xi, zi).\n(A.3)"
        },
        {
            "heading": "30 A. NEUFELD AND Q. XIANG",
            "text": "Furthermore, we have N\u2211 i=1 w\u0302i + \u03f5 4 \u221a 3kN si = ( N\u2211 i=1 w\u22c6i ) +\n\u03f5\n4 \u221a kN\nN1k + \u03f5\n4 \u221a 3kN ( N\u2211 i=1 si )\n= 0k + \u03f5\n4 \u221a kN\n( N1k +\n1\u221a 3 N\u2211 i=1 si ) \u2265 0k.\n(A.4)\nLastly, we have\u2225\u2225(y\u03021,0, y\u0302T1 , w\u0302T1 , . . . , y\u0302N,0, y\u0302TN , w\u0302TN )T + \u03f54\u221a3kN (u1,0,uT1 , sT1 , . . . , uN,0,uTN , sTN )T\u2225\u22252 \u2264 \u2225\u2225(y\u22c61,0,y\u22c6T1 ,w\u22c6T1 , . . . , y\u22c6N,0,y\u22c6TN ,w\u22c6TN )T\u2225\u22252 + \u2225\u2225\u2225( \u03f52N ,0Tm1 , \u03f54\u221akN 1Tk , . . . , \u03f52N ,0TmN , \u03f54\u221akN 1Tk )T\u2225\u2225\u22252\n+ \u03f5\n4 \u221a 3kN \u2225\u2225(u1,0,uT1 , sT1 , . . . , uN,0,uTN , sTN )T\u2225\u22252 \u2264 L+ ( N ( \u03f5\n2N\n)2 +Nk ( \u03f5\n4 \u221a kN\n)2) 12 +\n\u03f5\n4 \u221a 3kN\n< L+ 1.\n(A.5)\nWe combine (A.2), (A.3), (A.4), and (A.5) to conclude that the set S\u03b1\u22c6\u2212\u03f5 \u2229 B(L + 1) contains a Euclidean ball with radius \u03f5\n4 \u221a 3kN centered at (y\u03021,0, y\u0302T1 , w\u0302 T 1 , . . . , y\u0302N,0, y\u0302 T N , w\u0302 T N ) T. To prove statement (ii), let us fix arbitrary (y\u0302i,0, y\u0302i, w\u0302i)i=1:N and consider the three following cases separately. Case 1: \u2225(y\u03021,0, y\u0302T1 , w\u0302T1 , . . . , y\u0302N,0, y\u0302TN , w\u0302TN )T\u22252 > L+ 1. In this case, we let g\u0302i,0 := y\u0302i,0, g\u0302i := y\u0302i, h\u0302i := w\u0302i for i = 1, . . . , N . Thus, it holds for all (y1,0,yT1 ,w T 1 , . . . , yN,0,y T N ,w T N )\nT \u2208 S\u2229B(L+1) that\nN\u2211 i=1 g\u0302i,0yi,0 + \u27e8g\u0302i,yi\u27e9+ \u27e8h\u0302i,wi\u27e9 \u2264 N\u2211 i=1 g\u0302i,0y\u0302i,0 + \u27e8g\u0302i, y\u0302i\u27e9+ \u27e8h\u0302i, w\u0302i\u27e9\n= \u2225(y\u03021,0, y\u0302T1 , w\u0302T1 , . . . , y\u0302N,0, y\u0302TN , w\u0302TN )T\u222522.\nThe computational cost incurred in this case is O(NT ). Case 2: \u2225(y\u03021,0, y\u0302T1 , w\u0302T1 , . . . , y\u0302N,0, y\u0302TN , w\u0302TN )T\u22252 \u2264 L+ 1 but \u2211N i=1 w\u0302i \u2265 0k fails to hold. In this\ncase, let l \u2208 {1, . . . , k} be such that the l-th entry of the vector \u2211N\ni=1 w\u0302i is negative. Moreover, let el be the l-th standard basis vector in Rk, and let g\u0302i,0 := 0, g\u0302i := 0mi , h\u0302i := \u2212el for i = 1, . . . , N . Then, it holds for all (y1,0,yT1 ,w T 1 , . . . , yN,0,y T N ,w T N )\nT \u2208 S \u2229B(L+ 1) that N\u2211 i=1 g\u0302i,0yi,0 + \u27e8g\u0302i,yi\u27e9+ \u27e8h\u0302i,wi\u27e9 = \u2212 ( N\u2211 i=1 \u27e8el,wi\u27e9 ) = \u2212 \u2329 el, \u2211N i=1wi \u232a\n\u2264 0 \u2264 \u2212 \u2329 el, \u2211N i=1 w\u0302i \u232a\n= N\u2211 i=1 g\u0302i,0y\u0302i,0 + \u27e8g\u0302i, y\u0302i\u27e9+ \u27e8h\u0302i, w\u0302i\u27e9.\nThe computational cost incurred in this case is O(NT ). Case 3: \u2225(y\u03021,0, y\u0302T1 , w\u0302T1 , . . . , y\u0302N,0, y\u0302TN , w\u0302TN )T\u22252 \u2264 L+ 1 and \u2211N i=1 w\u0302i \u2265 0k both hold. In this case, we call Oracle(i, y\u0302i, w\u0302i) for i = 1, . . . , N and denote their outputs by (x\u22c6i , z \u22c6 i , \u03b2 \u22c6 i )i=1:N ,\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 31\nwhere (x\u22c6i , z \u22c6 i ) is a minimizer of infxi\u2208Xi,zi\u2208Z { ci(xi, zi) \u2212 \u27e8gi(xi), y\u0302i\u27e9 \u2212 \u27e8h(zi), w\u0302i\u27e9 } and \u03b2\u22c6i = ci(x \u22c6 i , z \u22c6 i )\u2212 \u27e8gi(x\u22c6i ), y\u0302i\u27e9 \u2212 \u27e8h(z\u22c6i ), w\u0302i\u27e9. Subsequently, if \u03b2\u22c6i \u2265 y\u0302i,0 holds for i = 1, . . . , N , then we have ci(xi, zi) \u2265 y\u0302i,0 + \u27e8gi(xi), y\u0302i\u27e9 + \u27e8h(zi), w\u0302i\u27e9 for all (xi, zi) \u2208 Xi \u00d7 Z and for i = 1, . . . , N . The separation oracle will thus return (y\u03021,0, y\u0302T1 , w\u0302 T 1 , . . . , y\u0302N,0, y\u0302 T N , w\u0302 T N )\nT \u2208 S \u2229 B(L + 1). On the other hand, if \u03b2\u22c6\ni\u0302 < y\u0302i\u0302,0 for some i\u0302 \u2208 {1, . . . , N}, then we have ci\u0302(x \u22c6 i\u0302 , z\u22c6 i\u0302 ) < y\u0302i\u0302,0 + \u27e8gi\u0302(x \u22c6 i\u0302 ), y\u0302i\u0302\u27e9 +\n\u27e8h(z\u22c6 i\u0302 ), w\u0302i\u0302\u27e9, and we let g\u0302i\u0302,0 := 1, g\u0302i\u0302 := gi\u0302(x \u22c6 i\u0302 ), h\u0302i\u0302 := h(z \u22c6 i\u0302 ), and g\u0302i,0 := 0, g\u0302i := 0mi , h\u0302i := 0k for i \u0338= i\u0302. Then, it holds for all (y1,0,yT1 ,wT1 , . . . , yN,0,yTN ,wTN )T \u2208 S \u2229B(L+ 1) that\nN\u2211 i=1 g\u0302i,0yi,0 + \u27e8g\u0302i,yi\u27e9+ \u27e8h\u0302i,wi\u27e9 = yi\u0302,0 + \u27e8gi\u0302(x \u22c6 i\u0302 ),yi\u0302\u27e9+ \u27e8h(z \u22c6 i\u0302 ),wi\u27e9\n\u2264 ci\u0302(x \u22c6 i\u0302 , z\u22c6 i\u0302 ) \u2264 y\u0302i\u0302,0 + \u27e8gi\u0302(x \u22c6 i\u0302 ), y\u0302i\u0302\u27e9+ \u27e8h(z \u22c6 i\u0302 ), w\u0302i\u27e9\n= N\u2211 i=1 g\u0302i,0y\u0302i,0 + \u27e8g\u0302i, y\u0302i\u27e9+ \u27e8h\u0302i, w\u0302i\u27e9.\nThe computational cost incurred in this case involves the cost of N calls to Oracle(\u00b7, \u00b7, \u00b7), the cost of comparing N pairs of numbers, and the cost of evaluating gi\u0302(x \u22c6 i\u0302 ) and h(z\u22c6 i\u0302 ). Therefore, the total cost incurred in this case is O(NT ). We would like to remark that Vaidya\u2019s algorithm assumes that given any (y\u0302i,0 \u2208 R, y\u0302i \u2208 Rmi , w\u0302i \u2208 Rk)i=1:N , the separation oracle can compute a vector (g\u03021,0, g\u0302T1 , h\u0302T1 , . . . , g\u0302N,0, g\u0302TN , h\u0302TN ) \u2208 Rm+N(k+1) that satisfies\n{ (y1,0,y T 1 ,w T 1 , . . . , yN,0,y T N ,w T N ) T \u2208 Rm+N(k+1) : \u2211N i=1yi,0 + \u27e8g\u0304i,yi\u27e9 \u2265 \u2211N i=1y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 }\n\u2286 { (y1,0,y T 1 ,w T 1 , . . . , yN,0,y T N ,w T N )\nT \u2208 Rm+N(k+1) :\u2211N i=1g\u0302i,0yi,0 + \u27e8g\u0302i,yi\u27e9+ \u27e8h\u0302i,wi\u27e9 \u2265 \u2211N i=1g\u0302i,0y\u0302i,0 + \u27e8g\u0302i, y\u0302i\u27e9+ \u27e8h\u0302i, w\u0302i\u27e9 } .\nNotice that since we are maximizing over a linear objective function, choosing the vector (g\u03021,0, g\u0302 T 1 , h\u0302 T 1 , . . . , g\u0302N,0, g\u0302 T N , h\u0302 T N ) T := (1, g\u0304T1 ,0 T k , . . . , 1, g\u0304 T N ,0 T k )\nT satisfies the assumption above. Thus, the cutting-plane algorithm of Vaidya [66] is able to compute an \u03f5-optimizer of (A.1) with computational complexityO ( (m+N(k+1)) log2(4 \u221a 3kN(L+1)/\u03f5)(NT +(m+N(k+1))\u03c9) ) =\nO ( (m + Nk) log(N \u221a kL/\u03f5)(NT + (m + Nk)\u03c9) ) . It follows from the argument at the beginning of the proof that an \u03f5-optimizer of (A.1) can be modified into an \u03f5-optimizer of (MT\u2217par), and the computation cost of this step is O(Nk). The proof is now complete. \u25a1\nProof of Theorem 2.6. Let us first establish the weak duality between (MT\u2217par) and (MTpar). It follows from the compactness of X1, . . . ,XN and Z that (MT\u2217par) is feasible. In addition, observe that (MTpar) is also feasible. Let us fix an arbitrary feasible solution (yi,0,yi,wi)i=1:N of (MT\u2217par) as well as an arbitrary feasible solution (\u03b8i)i=1:N of (MTpar). By the constraints of (MT\u2217par), it holds that \u2211N i=1wi = 0k, and yi,0 + \u27e8gi(xi),yi\u27e9 + \u27e8h(zi),wi\u27e9 \u2264 ci(xi, zi) for all (xi, zi) \u2208 Xi \u00d7 Z , for i = 1, . . . , N . Moreover, by the constraints of (MTpar), it holds that \u03b8i \u2208 \u0393(\u00b5\u0304i, \u03bd\u0304i) for some"
        },
        {
            "heading": "32 A. NEUFELD AND Q. XIANG",
            "text": "(\u00b5\u0304i)i=1:N , (\u03bd\u0304i)i=1:N satisfying \u00b5\u0304i Gi\u223c \u00b5i and \u03bd\u0304i H\u223c \u03bd\u03041, for i = 1, . . . , N . Consequently, we obtain\nN\u2211 i=1 \u222b Xi\u00d7Z ci(xi, zi) \u03b8i(dxi, dzi)\n\u2265 N\u2211 i=1 \u222b Xi\u00d7Z yi,0 + \u27e8gi(xi),yi\u27e9+ \u27e8h(zi),wi\u27e9 \u03b8i(dxi, dzi)\n= ( N\u2211 i=1 \u222b Xi yi,0 + \u27e8gi(xi),yi\u27e9 \u00b5\u0304i(dxi) ) + ( N\u2211 i=1 \u222b Z \u27e8h(zi),wi\u27e9 \u03bd\u0304i(dzi) )\n= ( N\u2211 i=1 \u222b Xi yi,0 + \u27e8gi(xi),yi\u27e9\u00b5i(dxi) ) + \u222b Z \u2329\u2211N i=1 h(z),wi \u232a \u03bd\u03041(dz)\n= N\u2211 i=1 yi,0 + \u27e8yi, g\u0304i\u27e9.\nTaking the supremum over all feasible (yi,0,yi,wi)i=1:N and taking the infimum over all feasible (\u03b8i)i=1:N in the inequality above proves (MT\u2217par) \u2264 (MTpar). Next, let us show that the strong duality (MT\u2217par) = (MTpar) holds. To that end, let m :=\u2211N i=1mi, let the decision variables of the LSIP problem (MT\n\u2217 par) be arranged into a vector q :=(\ny1,0,y T 1 ,w T 1 , . . . , yN,0,y T N ,w T N )T \u2208 Rm+N(k+1), and let the corresponding objective vector be denoted by\nr := ( 1, g\u0304T1 ,0 T k , . . . , 1, g\u0304 T N ,0 T k )T \u2208 Rm+N(k+1). (A.6) For i = 1, . . . , N , let us define 0(i) := 01+mi+k for notational simplicity. Let ai : Xi \u00d7 Z \u2192 Rm+N(k+1) be defined as follows:\na1(x1, z1) := ( 1, g1(x1) T,h(z1) T,0(2)T, . . . ,0(N)T )T \u2200(x1, z1) \u2208 X1 \u00d7Z,\na2(x2, z2) := ( 0(1)T, 1, g2(x2) T,h(z2) T,0(3)T, . . . ,0(N)T )T \u2200(x2, z2) \u2208 X2 \u00d7Z,\n...\naN (xN , zN ) := ( 0(1)T, . . . ,0(N\u22121)T, 1, gN (xN ) T,h(zN ) T )T \u2200(xN , zN ) \u2208 XN \u00d7Z.\n(A.7)\nFor l = 1, . . . , k, let el denote the l-th standard basis vector of Rk. Let us define u(l) \u2208 Rm+N(k+1) as follows:\nu(l) := ( 0,0Tm1 , e T l , 0,0 T m2 , e T l , . . . , 0,0 T mN , eTl )T \u22001 \u2264 l \u2264 k. (A.8)\nThus, with the newly introduced notations, we can now express (MT\u2217par) concisely as follows:\nmaximize q\n\u27e8r, q\u27e9\nsubject to \u27e8ai(xi, zi), q\u27e9 \u2264 ci(xi, zi) \u2200(xi, zi) \u2208 Xi \u00d7Z, \u22001 \u2264 i \u2264 N,\n\u27e8u(l), q\u27e9 = 0 \u22001 \u2264 l \u2264 k,\nq \u2208 Rm+N(k+1).\n(A.9)\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 33\nThe so-called Haar\u2019s dual optimization problem of (A.9) (see, e.g., [41, p.49]) is given by:\nminimize (\u03b8i,j ,xi,j ,zi,j), (\u03bel) N\u2211 i=1 ni\u2211 j=1 \u03b8i,jci(xi,j , zi,j)\nsubject to  N\u2211 i=1 ni\u2211 j=1 \u03b8i,jai(xi,j , zi,j) +( k\u2211 l=1 \u03belu (l) ) = r,\n ni \u2208 N, (\u03b8i,j)j=1:ni \u2282 R+, (xi,j)j=1:ni \u2282 Xi, (zi,j)j=1:ni \u2282 Z\n\u22001 \u2264 i \u2264 N,\n(\u03bel)l=1:k \u2282 R.\n(A.10)\nIn the following, we prove the strong duality between (A.9) and (A.10) by characterizing the socalled second-moment cone of (A.9) (see, e.g., [41, p.81]). For i = 1, . . . , N , let us define\nC1,i := cone ({ ai(xi, zi) : xi \u2208 Xi, zi \u2208 Z }) \u2282 Rm+N(k+1),\nK\u03031,i := conv ({( ai(xi, zi) T, ci(xi, zi) )T : xi \u2208 Xi, zi \u2208 Z }) \u2282 Rm+N(k+1)+1,\nC\u03031,i := cone(K\u03031,i) \u2282 Rm+N(k+1)+1,\n(A.11)\nand define C2 := cone ({ \u03b9u(l) : \u03b9 \u2208 {\u22121, 1}, 1 \u2264 l \u2264 k }) \u2282 Rm+N(k+1),\nC\u03032 := cone ({( \u03b9u(l)T, 0 )T : \u03b9 \u2208 {\u22121, 1}, 1 \u2264 l \u2264 k }) \u2282 Rm+N(k+1)+1.\n(A.12)\nThe second-moment cone of (A.9) is given by C\u0303 := C\u03031,1 + \u00b7 \u00b7 \u00b7 + C\u03031,N + C\u03032. Notice that for i = 1, . . . , N , the continuity of gi(\u00b7), h(\u00b7), and ci(\u00b7, \u00b7), the compactness of Xi \u00d7 Z , and [61, Theorem 17.2] imply that K\u03031,i is a compact set. In addition, observe that K\u03031,i does not contain the origin. It thus follows from [61, Corollary 9.6.1] that C\u03031,i is closed. Moreover, C\u03032 is also closed since it is a subspace of Rm+N(k+1)+1 by definition. Now, let s1 := 1 and let si := si\u22121 + 1 + mi\u22121 + k for i = 2, . . . , N . For every i \u2208 {1, . . . , N} and every b1,i \u2208 K\u03031,i, it follows from the definition of ai(\u00b7, \u00b7) in (A.7) that the si-th component of b1,i is equal to 1 and that the si\u2032-th component of b1,i is equal to 0 for every i\u2032 \u0338= i. Moreover, for any b2 \u2208 C\u03032, it follows from the definition of( u(l) ) l=1:k\nin (A.8) that the si-th component of b2 is equal to 0 for i = 1, . . . , N . Consequently, if b1,1 + \u00b7 \u00b7 \u00b7 + b1,N + b2 = 0 for b1,1 \u2208 C\u03031,1, . . ., b1,N \u2208 C\u03031,N , and b2 \u2208 C\u03032, then it necessarily holds that b1,1 = \u00b7 \u00b7 \u00b7 = b1,N = b2 = 0. Therefore, since C\u03031,1, . . ., C\u03031,N , C\u03032 are all closed sets, it holds by [61, Corollary 9.1.3] that C\u0303 is closed. It then follows from [41, Theorem 4.5] (with M \u2190 C1,1 + \u00b7 \u00b7 \u00b7 + C1,N + C2, N \u2190 C\u0303, and K \u2190 cone ( C\u0303 \u222a (0Tm+N(k+1), 1) T ) in the notation of\n[41]) that cone ( C\u0303 \u222a (0Tm+N(k+1), 1) T )\nis closed. Subsequently, it follows from [41, Theorem 8.2] that the optimal values of (A.9) and (A.10) are identical (see the last three cases in [41, Table 8.1]).\nSummarizing the results we have derived so far in this proof, we have (MTpar) \u2265 (MT\u2217par) = (A.9) = (A.10). Therefore, to prove the strong duality (MTpar) = (MT\u2217par), it remains to show that (A.10) \u2265 (MTpar). Since (MTpar) is feasible and (MT\u2217par) = (A.10), (A.10) is also feasible. Thus, let us fix an arbitrary feasible solution (\u03b8i,j , xi,j , zi,j)j=1:ni,i=1:N , (\u03bel)l=1:k of (A.10) and characterize its properties. We know by the constraints in the problem (A.10) that the following equality holds: N\u2211\ni=1 ni\u2211 j=1 \u03b8i,jai(xi,j , zi,j) +( k\u2211 l=1 \u03belu (l) ) = r. (A.13)"
        },
        {
            "heading": "34 A. NEUFELD AND Q. XIANG",
            "text": "Consequently, it follows from the definitions of r, (a(\u00b7, \u00b7))i=1:N , (u(l))l=1:k in (A.6), (A.7), (A.8), and an entry-wise expansion of (A.13), that the following equalities hold:\nni\u2211 j=1 \u03b8i,j = 1 \u22001 \u2264 i \u2264 N, (A.14)\nni\u2211 j=1 \u03b8i,jgi(xi,j) = g\u0304i \u22001 \u2264 i \u2264 N, (A.15)\nni\u2211 j=1 \u03b8i,jh(zi,j) + k\u2211 l=1 \u03belel = 0k \u22001 \u2264 i \u2264 N. (A.16)\nSubsequently, let us define \u03b8i := \u2211ni\nj=1 \u03b8i,j\u03b4(xi,j ,zi,j) for i = 1, . . . , N , where \u03b4(xi,j ,zi,j) \u2208 P(Xi \u00d7 Z) denotes the Dirac measure at (xi,j , zi,j). By (A.14) and by (\u03b8i,j)j=1:ni \u2282 R+, it holds that \u03b8i \u2208 P(Xi \u00d7 Z). Let \u00b5\u0304i and \u03bd\u0304i denote the marginals of \u03b8i on Xi and Z , respectively. Then, for i = 1, . . . , N , j = 1, . . . ,mi, (A.15), (2.1), and (2.3) imply that\u222b\nXi gi,j d\u00b5\u0304i = \u222b Xi\u00d7Z gi,j(x) \u03b8i(dx,dz)= ni\u2211 t=1 \u03b8i,tgi,j(xi,t) = \u222b Xi gi,j d\u00b5i.\nHence, it holds that \u00b5\u0304i Gi\u223c \u00b5i for i = 1, . . . , N . Moreover, for i = 1, . . . , N , l = 1, . . . , k, (A.16) and (2.2) imply that \u222b Z hl d\u03bd\u0304i = \u222b Xi\u00d7Z hl(z) \u03b8i(dx,dz)= ni\u2211 t=1 \u03b8i,thl(zi,t) = \u2212\u03bel.\nThis shows that \u222b Z hl d\u03bd\u03041 = \u00b7 \u00b7 \u00b7 = \u222b Z hl d\u03bd\u0304N = \u2212\u03bel for l = 1, . . . , k and hence \u03bd\u03041\nH\u223c \u00b7 \u00b7 \u00b7 H\u223c \u03bd\u0304N . The above analysis shows that (\u03b8i)i=1:N is a feasible solution of (MTpar). Furthermore, it holds that\nN\u2211 i=1 \u222b Xi\u00d7Z ci(x, z) \u03b8i(dx,dz)= N\u2211 i=1 ni\u2211 t=1 \u03b8i,tci(xi,t, zi,t).\nTherefore, we have shown that (A.10) \u2265 (MTpar). The proof is now complete. \u25a1\nProof of Proposition 2.7. In this proof, we again work with the concise representation of (MT\u2217par) in (A.9), and let r, (0(i))i=1:N , (ai(\u00b7, \u00b7))i=1:N , (u(l))l=1:k, (C1,i)i=1:N , C2 be defined as in the proof of Theorem 2.6 (see (A.6)\u2013(A.12)). Specifically, let us consider the so-called first-moment cone of (A.9) (see, e.g., [41, p.81]), which is given by C := C1,1 + \u00b7 \u00b7 \u00b7+C1,N +C2. Moreover, let us define the following sets:\nKgi := conv ({ gi(xi) : xi \u2208 Xi }) \u2208 Rmi \u22001 \u2264 i \u2264 N,\nKh := conv ({ h(z) : z \u2208 Z }) \u2208 Rk,\nC\u03021,i := cone ({( 1, gi(xi) T,h(z)T )T : xi \u2208 Xi, z \u2208 Z }) \u2208 R1+mi+k \u22001 \u2264 i \u2264 N. (A.17)\nLet us first assume that supp(\u00b5i) = Xi for i = 1, . . . , N and prove statement (i). We will first prove the following claim:\ng\u0304i \u2208 relint(Kgi) \u22001 \u2264 i \u2264 N. (A.18)\nTo that end, let us fix an arbitrary i \u2208 {1, . . . , N} and suppose for the sake of contradiction that g\u0304i /\u2208 relint(Kgi). By the convexity of Kgi and [61, Theorem 20.2], there exists a hyperplane\nH := { w \u2208 Rmi : \u27e8yi,w\u27e9 = \u03b1 } ,\nwith yi = (yi,1, . . . , yi,mi) \u0338= 0 and \u03b1 \u2208 R, that separates Kgi and {g\u0304i} properly and that Kgi \u2288 H . Suppose without loss of generality that g\u0304i is contained in the closed half-space { w \u2208 Rmi :\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 35 \u27e8yi,w\u27e9 \u2264 \u03b1 }\n. Then, it follows that \u27e8yi, gi(xi)\u27e9 \u2265 \u03b1 \u2265 \u27e8yi, g\u0304i\u27e9 for all xi \u2208 Xi, which implies that mi\u2211 j=1 yi,j ( gi,j(xi)\u2212 \u222b Xigi,j d\u00b5i ) \u2265 0 \u2200xi \u2208 Xi.\nSince it holds that \u222b Xi \u2211mi j=1yi,j ( gi,j(xi)\u2212 \u222b Xigi,j d\u00b5i ) \u00b5i(dxi)= 0,\nand that the integrand is non-negative and is continuous by assumption, it follows that the integrand is identically equal to 0 on Xi. This shows that \u27e8yi, gi(xi)\u27e9 = \u27e8yi, g\u0304i\u27e9 = \u03b1 for all xi \u2208 Xi, which implies that \u27e8yi,w\u27e9 = \u27e8yi, g\u0304i\u27e9 = \u03b1 for all w \u2208 Kgi . Consequently, Kgi \u2286 H , which contradicts Kgi \u2288 H . We have thus proved (A.18).\nNext, since Kh \u2282 Rk is convex, its relative interior is non-empty. Let us fix an arbitrary h\u0302 = (h\u03021, . . . , h\u0302k) T \u2208 relint(Kh). Since it holds by [61, Corollary 6.8.1] that\nrelint(C\u03021,i) = { (\u03bb, \u03bbkTgi , \u03bbk T h) T : \u03bb > 0, kgi \u2208 relint(Kgi), kh \u2208 relint(Kh) }\n\u22001 \u2264 i \u2264 N, (A.19)\nwe have\n(1, g\u0304Ti , h\u0302 T)T \u2208 relint(C\u03021,i) \u22001 \u2264 i \u2264 N. (A.20)\nMoreover, it follows from the definitions of (C1,i)i=1:N and (ai(\u00b7, \u00b7))i=1:N in (A.11) and (A.7) that C1,1+ \u00b7 \u00b7 \u00b7+ C1,N = C\u03021,1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 C\u03021,N and thus\n(1, g\u0304T1 , h\u0302 T, . . . , 1, g\u0304TN , h\u0302 T)T \u2208 relint(C\u03021,1)\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 relint(C\u03021,N ) = relint(C1,1 + \u00b7 \u00b7 \u00b7+ C1,N ).\n(A.21)\nOn the other hand, since the set C2 is a subspace of Rm+N(k+1) by definition, we have relint(C2) = C2. Moreover, it follows from the definitions of (u(l))l=1:k, C2, and r in (A.8), (A.12), and (A.6) that\nk\u2211 l=1 (\u2212h\u0302l)u(l) \u2208 C2 = relint(C2) (A.22)\nand\n(1, g\u0304T1 , h\u0302 T, . . . , 1, g\u0304TN , h\u0302\nT)T + k\u2211\nl=1\n(\u2212h\u0302l)u(l)\n= ( 1, g\u0304T1 , ( h\u0302\u2212 \u2211k l=1 h\u0302lel )T , . . . , 1, g\u0304TN , ( h\u0302\u2212 \u2211k l=1 h\u0302lel )T)T = r.\n(A.23)\nFinally, it follows from [61, Corollary 6.6.2], (A.21), (A.22), (A.23) that\nr \u2208 relint(C1,1+ \u00b7 \u00b7 \u00b7+ C1,N ) + relint(C2) = relint(C).\nHence, it follows from [41, Theorem 8.1(v)] (with c \u2190 r, M \u2190 C in the notation of [41]) that the set of optimizers of (MT\u2217par) is non-empty. This proves statement (i).\nTo prove statement (ii), let us assume in addition that for i = 1, . . . , N , there exist mi + 1 points xi,1, . . . , xi,mi+1\u2208 Xi such that the mi + 1 vectors gi(xi,1), . . . , gi(xi,mi+1) \u2208 Rmi are affinely independent, and that there exist k + 1 points z1, . . . , zk+1 \u2208 Z such that the k + 1 vectors h(z1), . . . ,h(zk+1) \u2208 Rk are affinely independent. Subsequently, one may check that, for"
        },
        {
            "heading": "36 A. NEUFELD AND Q. XIANG",
            "text": "i = 1, . . . , N , the following 2 +mi + k vectors\n(0,0Tmi ,0 T k ) T, (1, gi(xi,1) T,h(zk+1) T)T, (1, gi(xi,2) T,h(zk+1) T)T, . . . , (1, gi(xi,mi+1) T,h(zk+1) T)T,\n(1, gi(xi,mi+1) T,h(zk) T)T, (1, gi(xi,mi+1) T,h(zk\u22121) T)T, . . . , (1, gi(xi,mi+1) T,h(z1) T)T\nare elements of C\u03021,i \u2282 R1+mi+k that are affinely independent. This shows that dim(C\u03021,i) = 1+mi+ k for i = 1, . . . , N , and thus dim(C1,1+\u00b7 \u00b7 \u00b7+C1,N ) = dim(C\u03021,1\u00d7\u00b7 \u00b7 \u00b7\u00d7C\u03021,N ) = \u2211N i=1 1+mi+k = m+N(k + 1). Therefore, aff(C) = Rm+N(k+1) and r \u2208 relint(C) = int(C). It then follows from [41, Theorem 8.1(vi)] (with c \u2190 r, M \u2190 C in the notation of [41]) that the set of optimizers of (MT\u2217par) is bounded. The proof is now complete. \u25a1\nProof of Lemma 2.10. This proof follows from repeated applications of the gluing lemma (see, e.g., [68, Lemma 7.6]). Let \u03b3(1) := \u03b31 \u2208 P(X1\u00d7Z). For i = 2, . . . , N , let \u03b3(i) \u2208 P(X1\u00d7 \u00b7 \u00b7 \u00b7 \u00d7Xi\u00d7Z) be formed by \u201cgluing together\u201d \u03b3(i\u22121) \u2208 P(X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 Xi\u22121 \u00d7 Z) and \u03b3i \u2208 P(Xi \u00d7 Z), that is, \u03b3(i) satisfies the properties that its marginal on X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 Xi\u22121 \u00d7 Z is \u03b3(i\u22121) and its marginal on Xi \u00d7 Z is \u03b3i. Notice that this is possible due to the assumption that the marginals of \u03b31, . . . , \u03b3N on Z are all identical. Finally, let \u03b3 := \u03b3(N) and let \u00b5\u0303 \u2208 P(X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN ) be the marginal of \u03b3 on X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN . It follows from Definition 2.9 that \u00b5\u0303 \u2208 B(\u03b31, . . . , \u03b3N ). The proof is complete. \u25a1\nProof of Theorem 2.12. To prove statement (i), we have by Theorem 2.6 that\nN\u2211 i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 \u2264 inf { N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8i : \u03b8i \u2208 \u0393(\u00b5\u0304i, \u03bd\u0304i), \u00b5\u0304i Gi\u223c \u00b5i, \u03bd\u0304i H\u223c \u03bd\u03041 \u22001 \u2264 i \u2264 N }\n= inf { N\u2211 i=1 Wci(\u00b5\u0304i, \u03bd\u0304i) : \u00b5\u0304i Gi\u223c \u00b5i, \u03bd\u0304i H\u223c \u03bd\u03041 \u22001 \u2264 i \u2264 N }\n\u2264 inf { N\u2211 i=1 Wci(\u00b5i, \u03bd) : \u03bd \u2208 P(Z) } .\nThus, \u2211N\ni=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 is a lower bound for the optimal value of (MT). Next, let us prove statements (ii), (iii), and (iv). For i = 1, . . . , N , let \u03c8i : Xi \u2192 R be defined by\n\u03c8i(xi) := y\u0302i,0 + \u27e8gi(xi), y\u0302i\u27e9 \u2200xi \u2208 Xi.\nIt thus holds for i = 1, . . . , N \u2212 1 and all z \u2208 Z that \u03c6\u0303i(z) = infxi\u2208Xi { ci(xi, z)\u2212 \u03c8i(xi) } \u2212 \u03c6\u0303i,0. Hence, we have\n\u03c6\u0303cii (xi) = inf z\u2208Z\n{ ci(xi, z)\u2212 inf\nx\u2032i\u2208Xi\n{ ci(x \u2032 i, z)\u2212 \u03c8i(x\u2032i) }} + \u03c6\u0303i,0 \u2265 \u03c8i(xi) + \u03c6\u0303i,0\n\u2200xi \u2208 Xi, \u22001 \u2264 i \u2264 N \u2212 1. (A.24)\nMoreover, it follows from the constraints of (MT\u2217par) that\n\u27e8h(z), w\u0302i\u27e9 \u2264 inf xi\u2208Xi\n{ ci(xi, z)\u2212 \u03c8i(xi) } = \u03c6\u0303i(z) + \u03c6\u0303i,0 \u2200z \u2208 Z, \u22001 \u2264 i \u2264 N \u2212 1,\n\u27e8h(z), w\u0302N \u27e9 \u2264 inf xN\u2208XN\n{ cN (xN , z)\u2212 \u03c8N (xN ) } \u2200z \u2208 Z.\n(A.25)\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 37 Summing up the inequalities in (A.25) over i = 1, . . . , N , using the constraint \u2211N\ni=1 w\u0302i = 0k, and then taking the infimum over z \u2208 Z on both sides lead to\n0 \u2264 inf z\u2208Z\n{ inf\nxN\u2208XN\n{ cN (xN , z)\u2212 \u03c8N (xN ) } + ( N\u22121\u2211 i=1 \u03c6\u0303i(z) + \u03c6\u0303i,0 )}\n= inf z\u2208Z\n{ inf\nxN\u2208XN\n{ cN (xN , z)\u2212 \u03c8N (xN ) } \u2212 \u03c6\u0303N (z) } + ( N\u22121\u2211 i=1 \u03c6\u0303i,0 )\n= inf xN\u2208XN { inf z\u2208Z { cN (xN , z)\u2212 \u03c6\u0303N (z) } \u2212 \u03c8N (xN ) } + ( N\u22121\u2211 i=1 \u03c6\u0303i,0 )\n= inf xN\u2208XN\n{ \u03c6\u0303cNN (xN )\u2212 \u03c8N (xN ) } + ( N\u22121\u2211 i=1 \u03c6\u0303i,0 ) .\nThis implies that\n\u03c6\u0303cNN (xN ) \u2265 \u03c8N (xN )\u2212 ( N\u22121\u2211 i=1 \u03c6\u0303i,0 ) \u2200xN \u2208 XN . (A.26)\nNotice that ( \u03c6\u0303i ) i=1:N and ( \u03c6\u0303cii ) i=1:N\nare continuous functions by the continuity of (ci)i=1:N and functions in (Gi)i=1:N and by the compactness of (Xi)i=1:N andZ . Subsequently, combining (A.24), (A.26), (2.1), (2.3), and denoting y\u0302i = (y\u0302i,1, . . . , y\u0302i,mi) T, we get\nN\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i \u2265 N\u2211 i=1 \u222b Xi \u03c8i d\u00b5i\n= N\u2211 i=1 y\u0302i,0 + mi\u2211 j=1 y\u0302i,j \u222b Xi gi,j d\u00b5i  =\nN\u2211 i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9.\n(A.27)\nMoreover, since \u2211N\ni=1 \u03c6\u0303i = 0 by definition, (\u03c6\u0303i)i=1:N is a feasible solution of (MT \u2217) with objective value \u2211N\ni=1 \u222b Xi \u03c6\u0303 ci i d\u00b5i. Furthermore, for i = 1, . . . , N \u2212 1, the L (2) ci -Lipschitz continuity of \u03c6\u0303i can\nbe established as follows. For any z, z\u2032 \u2208 Z , there exists x\u22c6i \u2208 Xi such that \u03c6\u0303i(z\u2032) = ci(x\u22c6i , z\u2032) \u2212 \u03c8i(x \u22c6 i )\u2212 \u03c6\u0303i,0, and thus it follows from the assumption (A4+) that\n\u03c6\u0303i(z)\u2212 \u03c6\u0303i(z\u2032) = inf xi\u2208Xi\n{ ci(xi, z)\u2212 \u03c8i(xi) } \u2212 ci(x\u22c6i , z\u2032) + \u03c8i(x\u22c6i )\n\u2264 ci(x\u22c6i , z)\u2212 ci(x\u22c6i , z\u2032) \u2264 L(2)ci dZ(z, z \u2032).\n(A.28)\nExchanging the roles of z and z\u2032 in (A.28) proves the L(2)ci -Lipschitz continuity of \u03c6\u0303i for i = 1, . . . , N \u2212 1.\nNow, let us first fix an arbitrary i \u2208 {1, . . . , N} and let X\u0304i := Xi, Z\u0304 := Z in order to differentiate copies of the same space. Then, since \u03b3\u0302i \u2208 R(\u03b8\u0302i;\u00b5i, \u03bd\u0302), there exists \u03c1i \u2208 P(Xi\u00d7Z\u00d7X\u0304i\u00d7Z\u0304) such that the marginal \u03b7i \u2208 \u0393(\u00b5\u0302i, \u00b5i) of \u03c1i on Xi \u00d7 X\u0304i satisfies \u222b Xi\u00d7X\u0304i dXi(xi, x\u0304i) \u03b7i(dxi,dx\u0304i)= W1(\u00b5\u0302i, \u00b5i),\nthe marginal \u03b6i \u2208 \u0393(\u03bd\u0302i, \u03bd\u0302) of \u03c1i on Z \u00d7 Z\u0304 satisfies \u222b Z\u00d7Z\u0304 dZ(z, z\u0304) \u03b6i(dz,dz\u0304) = W1(\u03bd\u0302i, \u03bd\u0302), the marginal of \u03c1i on Xi \u00d7 Z is \u03b8\u0302i, and the marginal of \u03c1i on X\u0304i \u00d7 Z\u0304 is \u03b3\u0302i. Subsequently, by the"
        },
        {
            "heading": "38 A. NEUFELD AND Q. XIANG",
            "text": "assumption (A4+), we have\nWci(\u00b5i, \u03bd\u0302) \u2264 \u222b X\u0304i\u00d7Z\u0304 ci(x\u0304i, z\u0304) \u03b3\u0302i(dx\u0304i, dz\u0304)\n= \u222b Xi\u00d7Z\u00d7X\u0304i\u00d7Z\u0304 ci(x\u0304i, z\u0304) \u03c1i(dxi, dz,dx\u0304i,dz\u0304)\n\u2264 \u222b Xi\u00d7Z\u00d7X\u0304i\u00d7Z\u0304 ci(xi, z) + L (1) ci ( dXi(xi, x\u0304i) + d (2) Z (z, z\u0304) ) \u03c1i(dxi,dz, dx\u0304i, dz\u0304)\n= \u222b Xi\u00d7Z ci(x, z) \u03b8\u0302i(dxi, dz)+ L (1) ci \u222b Xi\u00d7X\u0304i dXi(xi, x\u0304i) \u03b7i(dxi,dx\u0304i)\n+ L(2)ci \u222b Z\u00d7Z\u0304 dZ(z, z\u0304) \u03b6i(dz,dz\u0304)\n= \u222b Xi\u00d7Z ci d\u03b8\u0302i + L (1) ci W1(\u00b5\u0302i, \u00b5i) + L (2) ci W1(\u03bd\u0302i, \u03bd\u0302)\n\u2264 \u222b Xi\u00d7Z ci d\u03b8\u0302i + L (1) ci W 1,\u00b5i([\u00b5i]Gi) + L (2) ci W1(\u03bd\u0302i, \u03bd\u0302).\n(A.29)\nSumming (A.29) over i = 1, . . . , N , denoting L(2)c\u0304 := max1\u2264i\u2264N { L (2) ci } , and using the assumption (2.8), we obtain\nN\u2211 i=1 Wci(\u00b5i, \u03bd\u0302)\n\u2264 N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0302i\n\u2264 ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i ) + ( N\u2211 i=1 L(1)ci W 1,\u00b5i([\u00b5i]Gi) ) + ( N\u2211 i=1 L(2)ci W1(\u03bd\u0302i, \u03bd\u0302) )\n\u2264 ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i ) + ( N\u2211 i=1 L(1)ci W 1,\u00b5i([\u00b5i]Gi) ) + L (2) c\u0304 ( N\u2211 i=1 W1(\u03bd\u0302i, \u03bd\u0302) )\n\u2264 ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i ) + ( N\u2211 i=1 L(1)ci W 1,\u00b5i([\u00b5i]Gi) ) + L\n(2) c\u0304 (N \u2212 1) sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 } .\n(A.30)\nSubsequently, we combine (A.30), (2.7), and (A.27) to obtain\nN\u2211 i=1 Wci(\u00b5i, \u03bd\u0302) \u2264 ( N\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i ) + \u03f5+ ( N\u2211 i=1 L(1)ci W 1,\u00b5i([\u00b5i]Gi) ) + L\n(2) c\u0304 (N \u2212 1) sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 }\n= ( N\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i ) + \u03f5\u2021.\n(A.31)\nTherefore, since \u03bd\u0302 is a feasible solution of (MT) with objective value \u2211N\ni=1Wci(\u00b5i, \u03bd\u0302) and (\u03c6\u0303i)i=1:N is a feasible solution of (MT\u2217) with objective value \u2211N i=1 \u222b Xi \u03c6\u0303 ci i d\u00b5i, Theorem 1.5(iii) and (A.31) imply that \u03bd\u0302 is an \u03f5\u2021-optimizer of (MT) and (\u03c6\u0303i)i=1:N is an \u03f5\u2021-optimizer of (MT\u2217). This completes\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 39\nthe proof of statements (ii) and (iii). Furthermore, combining (A.30), (2.7), and statement (i) yields N\u2211 i=1 (\u222b Xi\u00d7Z ci d\u03b3\u0302i \u2212Wci(\u00b5i, \u03bd\u0302) ) \u2264 ( N\u2211 i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 ) \u2212 ( N\u2211 i=1 Wci(\u00b5i, \u03bd\u0302) ) + \u03f5\u2021\n\u2264 \u03f5\u2021.\n(A.32)\nSince \u03b3\u0302i \u2208 \u0393(\u00b5i, \u03bd\u0302), every term in the sum in the leftmost term of (A.32) is non-negative, which shows that \u222b Xi\u00d7Z ci d\u03b3\u0302i \u2264 Wci(\u00b5i, \u03bd\u0302) + \u03f5\n\u2021 for i = 1, . . . , N . This completes the proof of statement (iv).\nFinally, let us prove statements (v) and (vi). Let c\u0304 be given by (2.5). By Definition 2.9, there exists \u03b3 \u2208 P(X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN \u00d7Z) such that for i = 1, . . . , N , the marginal of \u03b3 on Xi \u00d7Z is \u03b3\u0302i, and that the marginal of \u03b3 on X1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN is \u00b5\u0303. Thus, we have\u222b\nX c\u0304d\u00b5\u0303 = \u222b X inf z\u2208Z {\u2211N i=1 ci(xi, z) } \u00b5\u0303(dx1, . . . ,dxN )\n\u2264 \u222b X\u00d7Z \u2211N i=1 ci(xi, z) \u03b3(dx1, . . . ,dxN , dz)\n= N\u2211 i=1 \u222b Xi\u00d7Z ci(xi, z) \u03b3\u0302i(dxi,dz).\n(A.33)\nMoreover, let us define \u03b8\u0303 := \u00b5\u0303 \u25e6 (id, z\u0303)\u22121 \u2208 P(X \u00d7 Z) where id : X \u220b x 7\u2192 x \u2208 X denotes the identity mapping on X . Thus, the marginal of \u03b8\u0303 on X is \u00b5\u0303 and the marginal of \u03b8\u0303 on Z is \u03bd\u0303. Subsequently, for i = 1, . . . , N , it follows from the definition of \u03b3\u0303i in statement (vi) that the marginal of \u03b8\u0303 on Xi \u00d7Z is exactly \u03b3\u0303i. We thus have\u222b\nX c\u0304d\u00b5\u0303 = \u222b X \u2211N i=1 ci ( xi, z\u0303(x1, . . . , xN ) ) \u00b5\u0303(dx1, . . . ,dxN )\n= \u222b X\u00d7Z \u2211N i=1 ci(xi, z) \u03b8\u0303(dx1, . . . ,dxN ,dz)\n= N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0303i.\n(A.34)\nFurthermore, for i = 1, . . . , N , since \u03b3\u0303i \u2208 \u0393(\u00b5i, \u03bd\u0303), we have\u222b Xi\u00d7Z ci d\u03b3\u0303i \u2265Wci(\u00b5i, \u03bd\u0303). (A.35)\nLet us now combine (A.35), (A.34), (A.33), (A.30), (2.7), and (A.27) to obtain N\u2211 i=1 Wci(\u00b5i, \u03bd\u0303) \u2264 ( N\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i ) + \u03f5+ ( N\u2211 i=1 L(1)ci W 1,\u00b5i([\u00b5i]Gi) ) + L\n(2) c\u0304 (N \u2212 1) sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 }\n= N\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i + \u03f5 \u2021.\n(A.36)\nTherefore, by the same argument in the proof of statement (iii), \u03bd\u0303 is an \u03f5\u2021-optimizer of (MT). This proves statement (v). Moreover, combining (A.34), (A.33), (2.7), and statement (i) yields\nN\u2211 i=1 (\u222b Xi\u00d7Z ci d\u03b3\u0303i \u2212Wci(\u00b5i, \u03bd\u0303) ) \u2264 ( N\u2211 i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 ) \u2212 ( N\u2211 i=1 Wci(\u00b5i, \u03bd\u0303) ) + \u03f5\u2021\n\u2264 \u03f5\u2021.\n(A.37)"
        },
        {
            "heading": "40 A. NEUFELD AND Q. XIANG",
            "text": "By (A.35), every term in the sum in the leftmost term of (A.37) is non-negative, which shows that\u222b Xi\u00d7Z ci d\u03b3\u0303i \u2264 Wci(\u00b5i, \u03bd\u0303) + \u03f5\n\u2021 for i = 1, . . . , N . This completes the proof of statement (vi). The proof is now complete. \u25a1\nBefore proving Corollary 2.13, let us first prove the following lemma.\nLemma A.1. Let Assumption 1.1 hold. For i = 1, . . . , N , let mi \u2208 N and let Gi :={ gi,1, . . . , gi,mi } \u2282 C(Xi). Let k \u2208 N and let H := {h1, . . . , hk} \u2282 C(Z). Then, there exist\n(qi \u2208 N)i=1:N with 1 \u2264 qi \u2264 2 + mi + k, \u03b1i,1 > 0, . . . , \u03b1i,qi > 0 satisfying \u2211qi\nl=1 \u03b1i,l = 1, xi,1 \u2208 Xi, . . . , xi,qi \u2208 Xi, zi,1 \u2208 Z, . . . , zi,qi \u2208 Z for i = 1, . . . , N , such that by letting \u03b8\u0302i := \u2211qi l=1 \u03b1i,l\u03b4(xi,l,zi,l) \u2208 P(Xi \u00d7 Z) for i = 1, . . . , N , (\u03b8\u0302i)i=1:N is an optimizer of (MTpar).\nProof of Lemma A.1. Since all test functions in G1, . . . ,GN ,H are assumed to be continuous, the feasible set of (MTpar) is a closed subset of the compact metric space \u015aN i=1 P(Xi \u00d7 Z) (see, e.g., [69, Remark 6.19]). Thus, an optimizer of (MTpar) is attained. Let us fix an arbitrary optimizer (\u03b8\u22c6i )i=1:N of (MTpar). For i = 1, . . . , N , let \u00b5\u0304 \u22c6 i and \u03bd\u0304 \u22c6 i denote the marginals of \u03b8 \u22c6 i on Xi and Z ,\nrespectively, and let us denote \u03b2i := \u222b Xi\u00d7Z ci d\u03b8 \u22c6 i . We thus have\nN\u2211 i=1 \u03b2i = inf { N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8i : \u03b8i \u2208 \u0393(\u00b5\u0304i, \u03bd\u0304i), \u00b5\u0304i Gi\u223c \u00b5i, \u03bd\u0304i H\u223c \u03bd\u03041 \u22001 \u2264 i \u2264 N } . (A.38)\nFor i = 1, . . . , N , let \u03d5i : Xi \u00d7Z \u2192 R2+mi+k be given by \u03d5i(xi, zi) := ( 1, gi,1(xi), . . . , gi,mi(xi), . . . , h1(zi), . . . , hk(zi), ci(xi, zi) )T \u2200xi \u2208 Xi, \u2200zi \u2208 Z. By an application of Tchakaloff\u2019s theorem in [9, Corollary 2], there exist qi \u2208 N with 1 \u2264 qi \u2264 2 + mi + k, \u03b1i,1 > 0, . . . , \u03b1i,qi > 0 satisfying \u2211qi l=1 \u03b1i,l = 1, xi,1 \u2208 Xi, . . . , xi,qi \u2208 Xi, zi,1 \u2208 Z, . . . , zi,qi \u2208 Z , such that qi\u2211 l=1 \u03b1i,l = \u222b Xi\u00d7Z 1 d\u03b8\u22c6i = 1, (A.39)\nqi\u2211 l=1 \u03b1i,lgi,j(xi,l) = \u222b Xi\u00d7Z gi,j(x) \u03b8 \u22c6 i (dx,dz)\n= \u222b Xi gi,j d\u00b5\u0304 \u22c6 i = \u222b Xi gi,j d\u00b5i \u22001 \u2264 j \u2264 mi,\n(A.40)\nqi\u2211 l=1 \u03b1i,lhl(zi,l) = \u222b Xi\u00d7Z hl(z) \u03b8 \u22c6 i (dx,dz)\n= \u222b Z hl d\u03bd\u0304 \u22c6 i = \u222b Z hl d\u03bd\u0304 \u22c6 1 \u22001 \u2264 l \u2264 k,\n(A.41)\nqi\u2211 l=1 \u03b1i,lci(xi,l, zi,l) = \u222b Xi\u00d7Z ci d\u03b8 \u22c6 i = \u03b2i. (A.42)\nLet \u03b8\u0302i := \u2211qi\nl=1 \u03b1i,l\u03b4(xi,l,zi,l). Then, it follows from (A.39) that \u03b8\u0302i \u2208 P(Xi \u00d7 Z). Let \u00b5\u0302i and \u03bd\u0302i denote the marginals of \u03b8\u0302i on Xi and Z , respectively. Then, (A.40) guarantees that \u222b Xi gi,j d\u00b5\u0302i =\u222b\nXi\u00d7Z gi,j(x) \u03b8\u0302i(dx,dz) = \u2211qi l=1 \u03b1i,lgi,j(xi,l) = \u222b Xi gi,j d\u00b5i for j = 1, . . . ,mi. Moreover,\n(A.41) guarantees that \u222b Z hl d\u03bd\u0302i = \u222b Xi\u00d7Z hl(x) \u03b8\u0302i(dx, dz) = \u2211qi l=1 \u03b1i,lhl(zi,l) = \u222b Z hl d\u03bd\u0304 \u22c6 1 for l = 1, . . . , k. This shows that \u00b5\u0302i G\u223c \u00b5i and \u03bd\u0302i\nH\u223c \u03bd\u03021 for i = 1, . . . , N . Finally, (A.42) implies that \u2211N i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i = \u2211N i=1 \u2211qi l=1 \u03b1i,lci(xi,l, zi,l) = \u2211N i=1 \u03b2i, which, by (A.38), shows that (\u03b8\u0302i)i=1:N is an optimizer of (MTpar). The proof is now complete. \u25a1\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 41\nProof of Corollary 2.13. By Lemma A.1, one can choose (\u03b8\u0302i)i=1:N in the statement of Theorem 2.12 such that \u2223\u2223supp(\u03b8\u0302i)\u2223\u2223 \u2264 2 + mi + k for i = 1, . . . , N . Let \u03bd\u0302i denote the marginal of \u03b8\u0302i on Z for i = 1, . . . , N . Moreover, let i\u0302 \u2208 {1, . . . , N} be such that mi\u0302 = min1\u2264i\u2264N{mi} and let \u03bd\u0302 := \u03bd\u0302i\u0302. Thus, there exist q \u2208 N with 1 \u2264 q \u2264 mi\u0302 + k + 2, \u03b11 > 0, . . . , \u03b1q > 0 satisfying \u2211q l=1 \u03b1l = 1,\nz1 \u2208 Z, . . . , zq \u2208 Z such that \u03bd\u0302 = \u2211q\nl=1 \u03b1l\u03b4zl . Moreover, since this choice of \u03bd\u0302 satisfies (2.8), it follows from Theorem 2.12(iii) that \u03bd\u0302 is an \u03f5\u2021-optimizer of (MT). The proof is complete. \u25a1\nProof of Theorem 2.15. For i = 1, . . . , N \u2212 1 and for all l \u2208 N, Theorem 2.12(ii) states that \u03c6\u0303(l)i is L(2)ci -Lipschitz continuous. Moreover, since Z in compact and that for every l \u2208 N, there exists z (l) 0 \u2208 Z such that \u03c6\u0303 (l) 1 ( z (l) 0 ) = \u00b7 \u00b7 \u00b7 = \u03c6\u0303(l)N\u22121 ( z (l) 0 ) = 0, there exists M > 0 such that\n\u2223\u2223\u03c6\u0303(l)i (z)\u2223\u2223 \u2264M for all z \u2208 Z , all l \u2208 N, and all i \u2208 {1, . . . , N \u22121}. Consequently, it follows from the Arzela\u0300\u2013Ascoli theorem that ( \u03c6\u0303 (l) i ) l\u2208N has a uniformly convergent subsequence for i = 1, . . . , N \u2212 1. Moreover,\nsince \u03c6\u0303(l)N = \u2212 \u2211N\u22121 i=1 \u03c6\u0303 (l) i for all l \u2208 N, ( \u03c6\u0303 (l) N ) l\u2208N also has a uniformly convergent subsequence by the Arzela\u0300\u2013Ascoli theorem. This proves statement (i). Statements (ii) and (iii) follow from the compactness of the metric spaces ( P(Z),W1 ) , ( P(X1\u00d7Z),W1 ) , . . . , ( P(XN \u00d7Z),W1 ) (see, e.g., [69, Remark 6.19]). Next, let us prove statements (iv) and (v). It follows from [22, Corollary 1] that for i = 1, . . . , N ,\nthe mapping C(Z) \u220b \u03c6 7\u2192 \u222b Xi \u03c6 ci d\u00b5i \u2208 R is continuous. Thus, since ( \u03c6\u0303 (l) i ) i=1:N\nis an \u03f5\u2021(l)optimizer of (MT\u2217) for all l \u2208 N by Theorem 2.12(ii) and liml\u2192\u221e \u03f5\u2021(l) = 0, we have\nN\u2211 i=1 \u222b Xi \u03c6\u0303 (\u221e) i ci d\u00b5i = lim k\u2192\u221e N\u2211 i=1 \u222b Xi \u03c6\u0303 (lk) i ci d\u00b5i\n= sup { N\u2211 i=1 \u222b Xi \u03c6cii d\u00b5i : (\u03c6i)i=1:N \u2282 C(Z), N\u2211 i=1 \u03c6i = 0 } ,\n(A.43)\nwhich shows that ( \u03c6\u0303 (\u221e) i ) i=1:N is an optimizer of (MT\u2217). Moreover, since \u2223\u2223Wci(\u00b5i, \u03bd) \u2212\nWci(\u00b5i, \u03bd \u2032) \u2223\u2223 \u2264 L(2)ci W1(\u03bd, \u03bd \u2032) for all \u03bd, \u03bd \u2032 \u2208 P(Z), the mapping P(Z) \u220b \u03bd 7\u2192 Wci(\u00b5i, \u03bd) \u2208 R is a continuous mapping. Therefore, since \u03bd\u0302(l) is an \u03f5\u2021(l)-optimizer of (MT) by Theorem 2.12(iii) and liml\u2192\u221e \u03f5\n\u2021(l) = 0, we have N\u2211 i=1 Wci ( \u00b5i, \u03bd\u0302 (\u221e)) = lim k\u2192\u221e N\u2211 i=1 Wci ( \u00b5i, \u03bd\u0302 (lk) ) = inf \u03bd\u2208P(Z) { N\u2211 i=1 Wci(\u00b5i, \u03bd) } , (A.44)\nwhich shows that \u03bd\u0302(\u221e) is an optimizer of (MT). Finally, for i = 1, . . . , N , since \u03b3\u0302(lk)i \u2208 \u0393(\u00b5i, \u03bd\u0302(lk)) for all k \u2208 N, ( \u03b3\u0302 (lk) i ) k\u2208N converges in ( P(Xi \u00d7 Z),W1 ) to \u03b3\u0302(\u221e)i , and ( \u03bd\u0302(lk) ) k\u2208N converges in(\nP(Z),W1 )\nto \u03bd\u0302(\u221e), it holds that \u03b3\u0302(\u221e)i \u2208 \u0393(\u00b5i, \u03bd\u0302(\u221e)). Moreover, we have by the continuity of the mapping P(Xi \u00d7Z) \u220b \u03b3 7\u2192 \u222b Xi\u00d7Z ci d\u03b3 \u2208 R, Theorem 2.12(iv), (A.44), and liml\u2192\u221e \u03f5\n\u2021(l) = 0 that\u222b Xi\u00d7Z ci d\u03b3\u0302 (\u221e) i = lim k\u2192\u221e \u222b Xi\u00d7Z ci d\u03b3\u0302 (lk) i\n\u2264 lim inf k\u2192\u221e\n( Wci ( \u00b5i, \u03bd\u0302 (lk) ) + \u03f5\u2021(lk) ) =Wci ( \u00b5i, \u03bd\u0302 (\u221e)). (A.45)\nIt follows from (A.43), (A.44), (A.45), and Theorem 1.5(ii) that ( \u03c6\u0303 (\u221e) i ) i=1:N , ( \u03b3\u0302 (\u221e) i ) i=1:N\n, \u03bd\u0302(\u221e) is indeed a matching equilibrium. This completes the proof of statement (iv). The proof of statement (v) follows from Theorem 2.12(v) and Theorem 2.12(vi) by the same argument. \u25a1\nProof of Theorem 2.17. For i = 1, . . . , N , the compactness of Xi and Proposition 2.16 imply that there exists a finite collection of test functions Gi such thatW 1,\u00b5i ( [\u00b5i]Gi ) \u2264 sup { W1(\u00b5, \u00b5 \u2032) : \u00b5, \u00b5\u2032 \u2208"
        },
        {
            "heading": "42 A. NEUFELD AND Q. XIANG",
            "text": "P(Xi), \u00b5 Gi\u223c \u00b5\u2032 } \u2264 \u03f5\u0303\u2212\u03f5\n2NL (1) ci\n. Moreover, since Z is also compact, Proposition 2.16 implies that there\nexists a finite collection of test functions H such that sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 } \u2264\n\u03f5\u0303\u2212\u03f5 2(N\u22121)L(2)c\u0304 . Subsequently, it follows from Theorem 2.12 that (\u03c6\u0303i)i=1:N is an \u03f5\u2021-optimizer of (MT\u2217), \u03bd\u0302 is an \u03f5\u2021-optimizer of (MT), \u03bd\u0303 is an \u03f5\u2021-optimizer of (MT), and for i = 1, . . . , N , \u03b3\u0302i \u2208 \u0393(\u00b5i, \u03bd\u0302) satisfies \u222b Xi\u00d7Z ci d\u03b3\u0302i \u2264Wci(\u00b5i, \u03bd\u0302)+\u03f5 \u2021, \u03b3\u0303i \u2208 \u0393(\u00b5i, \u03bd\u0303) satisfies \u222b Xi\u00d7Z ci d\u03b3\u0303i \u2264Wci(\u00b5i, \u03bd\u0303)+\u03f5 \u2021, with\n\u03f5\u2021 := \u03f5+ (N \u2212 1)L(2)c\u0304 sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 } + N\u2211 i=1 L(1)ci W 1,\u00b5i ( [\u00b5i]Gi ) \u2264 \u03f5+ (N \u2212 1)L (2) c\u0304 (\u03f5\u0303\u2212 \u03f5)\n2(N \u2212 1)L(2)c\u0304 + N\u2211 i=1 L (1) ci (\u03f5\u0303\u2212 \u03f5) 2NL (1) ci\n= \u03f5+ \u03f5\u0303\u2212 \u03f5 2 + \u03f5\u0303\u2212 \u03f5 2 = \u03f5\u0303.\nThe properties (i)\u2013(v) thus follow. To prove statement (vi), let Gi be a collection of functions on Xi constructed via Proposition 2.16 with Y \u2190 Xi, dY \u2190 dXi , d \u2190 di, \u03b8 \u2190 \u03b8i, (M j ,M j)j=1:d \u2190 (M i,j ,M i,j)j=1:di , \u03f5 \u2190 \u03f5\u0303\u2212\u03f52NL(1)ci , G \u2190 Gi. Similarly, let H be a collection of functions on Z constructed via Proposition 2.16 with Y \u2190 Z , dY \u2190 dZ , d \u2190 d0, \u03b8 \u2190 \u03b80, (M j ,M j)j=1:d \u2190 (M0,j ,M0,j)j=1:d0 , \u03f5 \u2190 \u03f5\u0303\u2212\u03f52(N\u22121)L(2)c\u0304 ,\nG \u2190 H. We thus have W 1,\u00b5i ( [\u00b5i]Gi ) \u2264 \u03f5\u0303\u2212\u03f5\n2NL (1) ci\nand |Gi| = \u220fdi\nj=1\n( 1 + \u2308 4NL (1) ci (M i,j\u2212M i,j)\u03b8i \u221a di\n\u03f5\u0303\u2212\u03f5 \u2309) for i = 1, . . . , N , as well as sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032 } \u2264 \u03f5\u0303\u2212\u03f5\n2(N\u22121)L(2)c\u0304 and |H| =\u220fd0\nj=1\n( 1 + \u2308 4(N\u22121)L(2)c\u0304 (M0,j\u2212M0,j)\u03b80 \u221a d0\n\u03f5\u0303\u2212\u03f5\n\u2309) .\nIn statement (vii), the existence of the finite collections C0,C1, . . . ,CN follows from the discussion before Proposition 3.2.6 in [56]. Subsequently, it follows from [56, Proposition 3.2.6(iii)] and [56, Theorem 3.2.9] that W 1,\u00b5i ( [\u00b5i]Gi ) \u2264 \u03f5\u0303\u2212\u03f5\n2NL (1) ci\nfor i = 1, . . . , N and that sup { W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208\nP(Z), \u03bd H\u223c \u03bd \u2032 } \u2264 \u03f5\u0303\u2212\u03f5\n2(N\u22121)L(2)c\u0304 . Finally, statement (viii) follows from [56, Proposition 3.2.7]. The\nproof is now complete. \u25a1\nA.2. Proof of results in Section 3 and Section 4.\nProof of Lemma 3.1. In the discrete-to-discrete case, the linear programming formulation of the optimal transport problem is well-known (see, e.g., [58, Section 2.3] and [10, Section 1.3]). Subsequently, by the definition of the random variable Y\u0304 , we have \u03b3\u22c6 = \u2211n i=1 \u2211n2 j=1 \u03b4(xi,yj), which is an optimal coupling between \u03bd1 and \u03bd2 under the cost dY . In the discrete-to-continuous case, it follows from the arguments in the proofs of [56, Lemma 3.1.1] and [56, Proposition 3.1.2] that \u03b3\u22c6 \u2208 \u0393(\u03bd1, \u03bd2) and\u222b Y\u00d7Y dY(x, y) \u03b3\n\u22c6(dx,dy)=W1(\u03bd1, \u03bd2). Finally, let us prove that \u03b3\u22c6 \u2208 \u0393(\u03bd1, \u03bd2) and \u222b Y\u00d7Y dY(x, y) \u03b3\n\u22c6(dx, dy)= W1(\u03bd1, \u03bd2) in the onedimensional case. Let F\u03bd1(y) := \u03bd1 ( Y \u2229 (\u2212\u221e, y] ) for y \u2208 R \u222a {\u2212\u221e,\u221e} and let F\u22121\u03bd1 (t) :=\ninf { y \u2208 Y : F\u03bd1(y) \u2265 t } for t \u2208 [0, 1]. It thus follows from the argument in the proof of [55, Proposition 3.7] that UF (\u03c3(X)) + (1\u2212 U)F (\u03c3(X)\u2212 1) is uniformly distributed on [0, 1], and that Y = F\u22121\u03bd1 ( UF (\u03c3(X))+(1\u2212U)F (\u03c3(X)\u22121) ) holds P-almost surely. Consequently, \u03b3\u22c6 \u2208 \u0393(\u03bd1, \u03bd2)\nand \u222b Y\u00d7Y dY(x, y) \u03b3\n\u22c6(dx, dy)=W1(\u03bd1, \u03bd2) follow from [55, Lemma EC.2.1(iv)]. The proof is now complete. \u25a1\nProof of Proposition 3.5. Statement (i) follows from Assumption 3.2, Proposition 2.7(ii), and the equivalence between (i) and (iii) of [41, Corollary 9.3.1]. Due to the compactness of X1, . . . ,XN ,Z\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 43 and the continuity of the functions in G1, . . . ,GN ,H, the set { gi(xi) : xi \u2208 Xi } is bounded for\ni = 1, . . . , N and so is the set { h(z) : z \u2208 Z } . Moreover, the global minimization problem in Line 5 is always bounded from below. Therefore, statement (ii) follows from [41, Theorem 11.2] with\ng ( (i, xi, zi), (yi\u2032,0,yi\u2032 ,wi\u2032)i\u2032=1:N ) \u2190 ci(xi, zi)\u2212 yi,0 \u2212 \u27e8yi, gi(xi)\u27e9 \u2212 \u27e8wi,h(zi)\u27e9\n\u2200(xi, zi) \u2208 Xi \u00d7Z, \u22001 \u2264 i \u2264 N.\nNext, to prove statements (iii), (iv), and (v), we will show that (y\u0302i,0, y\u0302i, w\u0302i)i=1:N is a feasible solution of (MT\u2217par) whose objective value is equal to \u03b1 LB MTpar\nand that (\u03b8\u0302i)i=1:N is a feasible solution of (MTpar) whose objective value is equal to \u03b1UBMTpar . Subsequently, since Line 8, Line 9, and Line 11 guarantee that \u03b1UBMTpar\u2212\u03b1 LB MTpar = \u2211N i=1 y (r) i,0 \u2212\u03b2 (r) i \u2264 \u03f5, statements (iii), (iv), and (v) will follow from the strong duality in Theorem 2.6. On one hand, by Line 5 and Line 13, it holds for i = 1, . . . , N and any (xi, zi) \u2208 Xi \u00d7Z that\nci(xi, zi)\u2212 y\u0302i,0 \u2212 \u27e8gi(xi), y\u0302i\u27e9 \u2212 \u27e8h(zi), w\u0302i\u27e9\n= ci(xi, zi)\u2212 \u03b2(r)i \u2212 \u27e8gi(xi),y (r) i \u27e9 \u2212 \u27e8h(zi),w (r) i \u27e9\n= ci(xi, zi)\u2212 \u27e8gi(xi),y(r)i \u27e9 \u2212 \u27e8h(zi),w (r) i \u27e9\n\u2212 inf x\u2032i\u2208Xi, z\u2032i\u2208Z\n{ ci(x \u2032 i, z \u2032 i)\u2212 \u27e8gi(x\u2032i),y (r) i \u27e9 \u2212 \u27e8h(z \u2032 i),w (r) i \u27e9 }\n\u2265 0. Moreover, since ( y (r) i,0 ,y (r) i ,w (r) i ) i=1:N\nis feasible for (MT\u2217(r)par ) by Line 3, it holds by Line 13 that\u2211N i=1 w\u0302i = \u2211N i=1w (r) i = 0k. Furthermore, it follows from Line 3, Line 11, and Line 13 that\nN\u2211 i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 = N\u2211 i=1 \u03b2 (r) i + \u27e8g\u0304i,y (r) i \u27e9\n= ( N\u2211 i=1 y (r) i,0 + \u27e8g\u0304i,y (r) i \u27e9 ) \u2212 ( N\u2211 i=1 y (r) i,0 \u2212 \u03b2 (r) i )\n= \u03b1(r) \u2212 ( N\u2211 i=1 y (r) i,0 \u2212 \u03b2 (r) i ) = \u03b1LBMTpar .\nThis shows that (y\u0302i,0, y\u0302i, w\u0302i)i=1:N is a feasible solution of (MT\u2217par) with objective value \u03b1 LB MTpar . On the other hand, by Line 3, ( \u03b8 (r) i,x,z ) (x,z)\u2208C(r)i , i=1:N\n, \u03be(r) is an optimizer of (MT(r)par). Let us denote \u03be(r) =( \u03be (r) 1 , . . . , \u03be (r) k )T. Consequently, it holds by Line 14, (2.1), (2.3), and (2.2) that, for i = 1, . . . , N , \u03b8\u0302i is a positive Borel measure on Xi \u00d7Z with finite support which satisfies\n\u03b8\u0302i(Xi \u00d7Z) = \u2211\n(x,z)\u2208C(r)i\n\u03b8 (r) i,x,z = 1,\n\u222b Xi\u00d7Z gi,j(xi) \u03b8\u0302i(dxi, dzi)= \u2211\n(x,z)\u2208C(r)i\n\u03b8 (r) i,x,zgi,j(x) = \u222b Xi gi,j d\u00b5i \u22001 \u2264 j \u2264 mi,\n\u222b Xi\u00d7Z hl(zi) \u03b8\u0302i(dxi, dzi)= \u2211\n(x,z)\u2208C(r)i\n\u03b8 (r) i,x,zhl(z) = \u03be (r) l \u22001 \u2264 l \u2264 k.\n(A.46)\nThus, \u03b8\u0302i \u2208 P(Xi \u00d7 Z) for i = 1, . . . , N . For i = 1, . . . , N , let \u00b5\u0302i and \u03bd\u0302i denote the marginals of \u03b8\u0302i on Xi and Z , respectively. It hence follows from (A.46) that \u00b5\u0302i Gi\u223c \u00b5i and \u03bd\u0302i H\u223c \u03bd\u03021 for i = 1, . . . , N ."
        },
        {
            "heading": "44 A. NEUFELD AND Q. XIANG",
            "text": "Moreover, it follows from Line 3, Line 11, Line 14, and the strong duality of LP problems that N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i = N\u2211 i=1 \u2211 (x,z)\u2208C(r)i \u03b8 (r) i,x,zci(x, z) = \u03b1 (r) = \u03b1UBMTpar .\nTherefore, (\u03b8\u0302i)i=1:N is a feasible solution of (MTpar) with objective value \u03b1UBMTpar . The proof is now complete. \u25a1\nProof of Theorem 3.7. It follows from Line 2, Line 3, and Proposition 3.5 that (y\u0302i,0, y\u0302i, w\u0302i)i=1:N is feasible for (MT\u2217par), (\u03b8\u0302i)i=1:N is feasible for (MTpar), and that\nN\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i = \u03b1 UB MTpar \u2264 \u03b1 LB MTpar + \u03f5 = ( N\u2211 i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 ) + \u03f5. (A.47)\nIt then follows from Line 4 and Theorem 2.12(ii) that (\u03c6\u0303i)i=1:N is feasible for (MT\u2217) and for i = 1, . . . , N \u2212 1, \u03c6\u0303i is L(2)ci -Lipschitz continuous. Moreover, it follows from (A.47), (A.27), and Line 14 that\nN\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i \u2265 N\u2211 i=1 y\u0302i,0 + \u27e8g\u0304i, y\u0302i\u27e9 = \u03b1LBMTpar = \u03b1 LB MT. (A.48)\nNext, by letting Z\u0304 := Z , Zi := Z , X\u0304i := Xi for i = 1, . . . , N and letting \u03c4 \u2208 P(X1\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 XN\u00d7 Z1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 ZN \u00d7 Z \u00d7 X\u03041 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7X\u0304N \u00d7 Z\u0304) denote the law of the random variable (X1, . . . , XN , Z1, . . . , ZN , Z, X\u03041, . . . , X\u0304N , Z\u0304), the following statements hold.\n(S1) It holds by Line 6 that \u03bd\u0302 = \u03bd\u0302i\u0302. For i = 1, . . . , N , it follows from Line 8 that the marginal \u03b6i of \u03c4 on Zi \u00d7 Z satisfies \u03b6i \u2208 \u0393(\u03bd\u0302i, \u03bd\u0302) and \u222b Zi\u00d7Z dZ(zi, z) \u03b6i(dzi,dz) = W1(\u03bd\u0302i, \u03bd\u0302), and it follows from Line 9 that the marginal of \u03c4 on Xi \u00d7Zi is \u03b8\u0302i. (S2) For i = 1, . . . , N , let \u00b5\u0302i denote the marginal of \u03c4 on Xi. Then, it follows from Line 10 that\nthe marginal of \u03c4 on X\u0304i is \u00b5i and the marginal \u03b7i of \u03c4 on Xi\u00d7X\u0304i satisfies \u03b7i \u2208 \u0393(\u00b5\u0302i, \u00b5i) and\u222b Xi\u00d7X\u0304i dXi(xi, x\u0304i) \u03b7i(dxi,dx\u0304i)=W1(\u00b5\u0302i, \u00b5i).\n(S3) Let \u00b5\u0303 denote the marginal of \u03c4 on X\u03041\u00d7\u00b7 \u00b7 \u00b7\u00d7X\u0304N . Then, it holds by Line 11 that \u03bd\u0303 = \u00b5\u0303\u25e6 z\u0303\u22121, and for i = 1, . . . , N , the marginal of \u03c4 on X\u0304i \u00d7 Z\u0304 is \u03b3\u0303i = \u00b5\u0303 \u25e6 (\u03c0i, z\u0303)\u22121 \u2208 \u0393(\u00b5i, \u03bd\u0303).\nSubsequently, it follows from (S1), (S2), and Line 13 that \u03b3\u0302i \u2208 R ( \u03b8\u0302i;\u00b5i, \u03bd\u0302 ) \u2282 \u0393(\u00b5i, \u03bd\u0302) for i = 1, . . . , N . We thus get from Line 13 and Line 14 that\n\u03b1\u0302UBMT = N\u2211 i=1 \u03b1\u0302i = N\u2211 i=1 E[ci(X\u0304i, Z)] = N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0302i \u2265 N\u2211 i=1 Wci(\u00b5i, \u03bd\u0302). (A.49)\nIt thus follows from (A.48), (A.49), and Line 15 that( N\u2211 i=1 Wci(\u00b5i, \u03bd\u0302) ) \u2212 ( N\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i ) \u2264 \u03b1\u0302UBMT \u2212 \u03b1LBMT = \u03f5\u0302MT.\nThis and Theorem 1.5(iii) show that \u03bd\u0302 is an \u03f5\u0302MT-optimizer of (MT) and prove statement (ii). Moreover, Theorem 1.5(iii), (A.48), (A.49), and Line 15 imply that\nN\u2211 i=1 (\u222b Xi\u00d7Z ci d\u03b3\u0302i \u2212Wci(\u00b5i, \u03bd\u0302) ) \u2264 ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0302i ) \u2212 ( N\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i ) \u2264 \u03b1\u0302UBMT \u2212 \u03b1LBMT = \u03f5\u0302MT.\n(A.50)\nSince \u222b Xi\u00d7Z ci d\u03b3\u0302i \u2265 Wci(\u00b5i, \u03bd\u0302) for i = 1, . . . , N , (A.50) shows that \u222b Xi\u00d7Z ci d\u03b3\u0302i \u2264 Wci(\u00b5i, \u03bd\u0302) + \u03f5\u0302MT for i = 1, . . . , N and proves statement (iii).\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 45\nOn the other hand, it follows from (S3), Line 13, and Line 14 that\n\u03b1\u0303UBMT = N\u2211 i=1 \u03b1\u0303i = N\u2211 i=1 E[ci(X\u0304i, Z\u0304)] = N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0303i \u2265 N\u2211 i=1 Wci(\u00b5i, \u03bd\u0303). (A.51)\nIt thus follows from (A.48), (A.51), and Line 15 that( N\u2211 i=1 Wci(\u00b5i, \u03bd\u0303) ) \u2212 ( N\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i ) \u2264 \u03b1\u0303UBMT \u2212 \u03b1LBMT = \u03f5\u0303MT. This and Theorem 1.5(iii) show that (\u03c6\u0303i)i=1:N is an \u03f5\u0303MT-optimizer of (MT\u2217) and that \u03bd\u0303 is an \u03f5\u0303MToptimizer of (MT), which prove statement (i) and statement (iv). Moreover, Theorem 1.5(iii), (A.48), (A.51), and Line 15 imply that\nN\u2211 i=1 (\u222b Xi\u00d7Z ci d\u03b3\u0303i \u2212Wci(\u00b5i, \u03bd\u0303) ) \u2264 ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0303i ) \u2212 ( N\u2211 i=1 \u222b Xi \u03c6\u0303cii d\u00b5i ) \u2264 \u03b1\u0303UBMT \u2212 \u03b1LBMT = \u03f5\u0303MT.\n(A.52)\nSince \u222b Xi\u00d7Z ci d\u03b3\u0303i \u2265 Wci(\u00b5i, \u03bd\u0303) for i = 1, . . . , N , (A.52) shows that \u222b Xi\u00d7Z ci d\u03b3\u0303i \u2264 Wci(\u00b5i, \u03bd\u0303) + \u03f5\u0303MT for i = 1, . . . , N and proves statement (v). Next, since \u03bd\u0302 = \u03bd\u0302i\u0302 satisfies (2.8), combining Line 14, Line 15, (A.30), and (A.47) leads to\n\u03f5\u0302MT = \u03b1\u0302 UB MT \u2212 \u03b1LBMT\n= ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0302i ) \u2212 \u03b1LBMT\n\u2264 ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b8\u0302i ) \u2212 \u03b1LBMTpar\n+ ( N\u2211 i=1 L(1)ci W 1,\u00b5i([\u00b5i]Gi) ) + ( N\u2211 i=1 L(2)ci W1(\u03bd\u0302i, \u03bd\u0302i\u0302) )\n\u2264 \u03f5+ ( N\u2211 i=1 L(1)ci W 1,\u00b5i([\u00b5i]Gi) )\n+ \u2211 i \u0338=i\u0302 L(2)ci  sup{W1(\u03bd, \u03bd \u2032) : \u03bd, \u03bd \u2032 \u2208 P(Z), \u03bd H\u223c \u03bd \u2032}\n\u2264 \u03f5+ ( N\u2211 i=1 L(1)ci W 1,\u00b5i ) + \u2211 i \u0338=i\u0302 L(2)ci W 1,Z = \u03f5\u2021\nW 1 .\n(A.53)\nMoreover, (S3) and Line 13 show that \u00b5\u0303 \u2208 B(\u03b3\u03021, . . . , \u03b3\u0302N ). Thus, combining Line 14, Line 15, (A.34), and (A.33) yields\n\u03f5\u0303MT = \u03b1\u0303 UB MT \u2212 \u03b1LBMT = ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0303i ) \u2212 \u03b1LBMT\n\u2264 ( N\u2211 i=1 \u222b Xi\u00d7Z ci d\u03b3\u0302i ) \u2212 \u03b1LBMT = \u03f5\u0302MT.\n(A.54)\nCombining (A.48), (A.49), (A.51), (A.53), and (A.54) proves statement (vi)."
        },
        {
            "heading": "46 A. NEUFELD AND Q. XIANG",
            "text": "Finally, statement (vii) can be proved applying the same argument in the proof of Theorem 2.17 with \u03f5\u0303\u2190 \u03f5\u2021. The proof is now complete. \u25a1\nProof of Proposition 4.2. Let us fix an arbitrary i \u2208 {1, . . . , N}, an arbitrary yi \u2208 Rmi , and an arbitrary wi \u2208 Rk. We have\ninf xi\u2208Xi,zi\u2208Z\n{ ci(xi, zi)\u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi\u27e9 } = inf\nzi\u2208Z\n{ inf\nxi\u2208Xi\n{ 1\nN\n( \u2225zi\u222522 \u2212 2\u27e8xi, zi\u27e9 ) \u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi\u27e9 }} = inf\nzi\u2208Z\n{ 1\nN \u2225zi\u222522 \u2212 \u27e8h(zi),wi\u27e9+ inf xi\u2208Xi { \u22122 N \u27e8xi, zi\u27e9 \u2212 \u27e8gi(xi),yi\u27e9 }} .\nNotice that, for j = 1, . . . ,mi, it follows from the definition of gi,vi,j in Theorem 2.17(vii) that gi,vi,j is a continuous function that is piece-wise affine on each triangle C \u2208 Ci. Thus, for any zi \u2208 Z , the mapping Xi \u220b xi 7\u2192 \u22122N \u27e8xi, zi\u27e9 \u2212 \u27e8gi(xi),yi\u27e9 \u2208 R is continuous and piece-wise affine on each triangle C \u2208 Ci. Consequently, for any zi \u2208 Z , infxi\u2208Xi { \u22122 N \u27e8xi, zi\u27e9 \u2212 \u27e8gi(xi),yi\u27e9 } can be attained at an extreme point of a triangle C \u2208 Ci. It hence holds that inf\nxi\u2208Xi,zi\u2208Z\n{ ci(xi, zi)\u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi\u27e9 } = inf\nzi\u2208Z\n{ 1\nN \u2225zi\u222522 \u2212 \u27e8h(zi),wi\u27e9+ inf xi\u2208Xi { \u22122 N \u27e8xi, zi\u27e9 \u2212 \u27e8gi(xi),yi\u27e9 }} = inf\nzi\u2208Z\n{ 1\nN \u2225zi\u222522 \u2212 \u27e8h(zi),wi\u27e9+ min\nxi\u2208V (Ci)\n{ \u22122 N \u27e8xi, zi\u27e9 \u2212 \u27e8gi(xi),yi\u27e9 }} = inf\nzi\u2208Z\n{ min\nxi\u2208V (Ci)\n{ ci(xi, zi)\u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi\u27e9 }} = min\nxi\u2208V (Ci),zi\u2208Z\n{ ci(xi, zi)\u2212 \u27e8gi(xi),yi\u27e9 \u2212 \u27e8h(zi),wi\u27e9 } ,\nwhere the minimum over zi \u2208 Z is attained due to the continuity of ci(\u00b7, \u00b7), h(\u00b7) and the compactness of Z . The proof is now complete. \u25a1\nREFERENCES\n[1] M. Agueh and G. Carlier. Barycenters in the Wasserstein space. SIAM J. Math. Anal., 43(2): 904\u2013924, 2011. [2] A. Alfonsi, R. Coyaud, V. Ehrlacher, and D. Lombardi. Approximation of optimal transport problems with marginal moments constraints. Math. Comp., 90(328):689\u2013737, 2021. [3] J. M. Altschuler and E. Boix-Adsera\u0300. Wasserstein barycenters can be computed in polynomial time in fixed dimension. J. Mach. Learn. Res., 22(1):1532\u20134435, Jan 2021. [4] J. M. Altschuler and E. Boix-Adsera\u0300. Wasserstein barycenters are NP-hard to compute. SIAM J. Math. Data Sci., 4(1):179\u2013203, 2022. [5] J. M. Altschuler and E. Boix-Adsera\u0300. Polynomial-time algorithms for multimarginal optimal transport problems with structure. Math. Program., 199(1-2):1107\u20131178, 2023.\n[6] P. C. A\u0301lvarez-Esteban, E. del Barrio, J. A. Cuesta-Albertos, and C. Matra\u0301n. A fixed-point approach to barycenters in Wasserstein space. J. Math. Anal. Appl., 441(2):744\u2013762, 2016. [7] E. Anderes, S. Borgwardt, and J. Miller. Discrete Wasserstein barycenters: Optimal transport for discrete data. Math. Methods Oper. Res., 84(2):389\u2013409, 2016. [8] F. A. Ba and M. Quellmalz. Accelerating the Sinkhorn algorithm for sparse multi-marginal optimal transport via fast Fourier transforms. Algorithms, 15(9):311, 2022. [9] C. Bayer and J. Teichmann. The proof of Tchakaloff\u2019s theorem. Proc. Amer. Math. Soc., 134 (10):3035\u20133040, 2006. [10] J.-D. Benamou. Optimal transportation, modelling and numerical simulation. Acta Numer., 30: 249\u2013325, 2021.\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 47\n[11] J.-D. Benamou, G. Carlier, M. Cuturi, L. Nenna, and G. Peyre\u0301. Iterative Bregman projections for regularized transportation problems. SIAM J. Sci. Comput., 37(2):A1111\u2013A1138, 2015. [12] D. P. Bertsekas and S. E. Shreve. Stochastic optimal control: the discrete time case, volume 139 of Mathematics in Science and Engineering. Academic Press, Inc. [Harcourt Brace Jovanovich, Publishers], New York-London, 1978. [13] O. Besbes, F. Castro, and I. Lobel. Surge pricing and its spatial supply response. Management Science, 67(3):1350\u20131367, 2021. [14] J. Bigot, E. Cazelles, and N. Papadakis. Penalization of barycenters in the Wasserstein space. SIAM J. Math. Anal., 51(3):2261\u20132285, 2019. [15] A. Blanchet and G. Carlier. Optimal transport and Cournot-Nash equilibria. Math. Oper. Res., 41(1):125\u2013145, 2016. [16] A. Blanchet, P. Mossay, and F. Santambrogio. Existence and uniqueness of equilibrium for a spatial model of social interactions. Internat. Econom. Rev., 57(1):31\u201359, 2016. [17] S. Borgwardt. An LP-based, strongly-polynomial 2-approximation algorithm for sparse Wasserstein barycenters. Int. J. Oper. Res., 22(2):1511\u20131551, 2022. [18] S. Borgwardt and S. Patterson. A column generation approach to the discrete barycenter problem. Discrete Optim., 43:100674, 2022. [19] S. Borgwardt and S. Patterson. An integer program for pricing support points of exact barycenters. Preprint, arXiv:2210.14135, 2022. [20] G. Buttazzo and F. Santambrogio. A model for the optimal planning of an urban area. SIAM J. Math. Anal., 37(2):514\u2013530, 2005. [21] G. Carlier and I. Ekeland. The structure of cities. Journal of Global Optimization, 29(4): 371\u2013376, 2004. [22] G. Carlier and I. Ekeland. Matching for teams. Econom. Theory, 42(2):397\u2013418, 2010. [23] G. Carlier and F. Santambrogio. A variational model for urban planning with traffic congestion. ESAIM Control Optim. Calc. Var., 11(4):595\u2013613, 2005. [24] G. Carlier, A. Oberman, and E. Oudet. Numerical methods for matching for teams and Wasserstein barycenters. ESAIM Math. Model. Numer. Anal., 49(6):1621\u20131642, 2015. [25] S. Chewi, T. Maunu, P. Rigollet, and A. J. Stromme. Gradient descent algorithms for BuresWasserstein barycenters. In Conference on Learning Theory, pages 1276\u20131304. PMLR, 2020. [26] L. Chizat. Doubly regularized entropic Wasserstein barycenters. Preprint, arXiv:2303.11844, 2023. [27] S. Claici, E. Chien, and J. Solomon. Stochastic Wasserstein barycenters. In Proceedings of\nthe 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 999\u20131008. PMLR, 10\u201315 Jul 2018.\n[28] S. Cohen, M. Arbel, and M. P. Deisenroth. Estimating barycenters of measures in high dimensions. Preprint, arXiv:2007.07105, 2020. [29] D. Coppersmith and S. Winograd. Matrix multiplication via arithmetic progressions. J. Symbolic Comput., 9(3):251\u2013280, 1990. [30] M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2, NIPS\u201913, page 2292\u20132300, Red Hook, NY, USA, 2013. [31] L. De Gennaro Aquino and C. Bernard. Bounds on multi-asset derivatives via neural networks. Int. J. Theor. Appl. Finance, 23(8):2050050, 31, 2020. [32] L. De Gennaro Aquino and S. Eckstein. MinMax methods for optimal transport and beyond: Regularization, approximation and numerics. In Advances in Neural Information Processing Systems, volume 33, pages 13818\u201313830, 2020. [33] J. Eckstein. A simplified form of block-iterative operator splitting and an asynchronous algorithm resembling the multi-block alternating direction method of multipliers. J. Optim. Theory Appl., 173(1):155\u2013182, 2017. [34] S. Eckstein and M. Kupper. Computation of optimal transport and related hedging problems via penalization and neural networks. Appl. Math. Optim., 83(2):639\u2013667, 2021."
        },
        {
            "heading": "48 A. NEUFELD AND Q. XIANG",
            "text": "[35] S. Eckstein and M. Nutz. Quantitative stability of regularized optimal transport and convergence of Sinkhorn\u2019s algorithm. SIAM J. Math. Anal., 54(6):5922\u20135948, 2022. [36] S. Eckstein, M. Kupper, and M. Pohl. Robust risk aggregation with neural networks. Mathematical Finance, 30(4):1229\u20131272, 2020. [37] S. Eckstein, G. Guo, T. Lim, and J. Ob\u0142o\u0301j. Robust pricing and hedging of options on multiple assets and its numerics. SIAM J. Financial Math., 12(1):158\u2013188, 2021. [38] J. Fan, A. Taghvaei, and Y. Chen. Scalable computations of Wasserstein barycenter via input convex neural networks. Preprint, arXiv:2007.04462, 2020. [39] G. Friesecke, A. S. Schulz, and D. Vo\u0308gler. Genetic column generation: Fast computation of high-dimensional multimarginal optimal transport problems. SIAM J. Sci. Comput., 44(3): A1632\u2013A1654, 2022. [40] D. Ge, H. Wang, Z. Xiong, and Y. Ye. Interior-point methods strike back: Solving the Wasserstein barycenter problem. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. [41] M. A. Goberna and M. A. Lo\u0301pez. Linear semi-infinite optimization. John Wiley & Sons, 1998. [42] G. Guo and J. Ob\u0142o\u0301j. Computational methods for martingale optimal transport problems. Ann. Appl. Probab., 29(6):3311\u20133347, 2019. [43] Gurobi Optimization, LLC. Gurobi Optimizer Reference Manual, 2022. URL http://www. gurobi.com. [44] F. Heinemann, A. Munk, and Y. Zemel. Randomized Wasserstein barycenter computation: Resampling with statistical guarantees. SIAM J. Math. Data Sci., 4(1):229\u2013259, 2022. [45] P. Henry-Laborde\u0300re. (Martingale) optimal transport and anomaly detection with neural networks: A primal-dual algorithm. Available at SSRN 3370910, 2019. [46] A. Korotin, L. Li, J. Solomon, and E. Burnaev. Continuous Wasserstein-2 barycenter estimation without minimax optimization. Preprint, arXiv:2102.01752, 2021. [47] A. Korotin, V. Egiazarian, L. Li, and E. Burnaev. Wasserstein iterative networks for barycenter estimation. Preprint, arXiv:2201.12245, 2022. [48] R. Krawtschenko, C. A. Uribe, A. Gasnikov, and P. Dvurechensky. Distributed optimization with quantization for computing Wasserstein barycenters. Preprint, arXiv:2010.14325, 2020. [49] M. Kuang and E. G. Tabak. Sample-based optimal transport and barycenter problems. Comm. Pure Appl. Math., 72(8):1581\u20131630, 2019. [50] B. Le\u0301vy. A numerical algorithm for L2 semi-discrete optimal transport in 3D. ESAIM Math. Model. Numer. Anal., 49(6):1693\u20131715, 2015. [51] L. Li, A. Genevay, M. Yurochkin, and J. M. Solomon. Continuous regularized Wasserstein\nbarycenters. In Advances in Neural Information Processing Systems, volume 33, pages 17755\u2013 17765. Curran Associates, Inc., 2020.\n[52] T. Lin, N. Ho, M. Cuturi, and M. I. Jordan. On the complexity of approximating multimarginal optimal transport. J. Mach. Learn. Res., 23(65):1\u201343, 2022. [53] R. E. Lucas, Jr. and E. Rossi-Hansberg. On the internal structure of cities. Econometrica, 70 (4):1445\u20131476, 2002. [54] G. Luise, S. Salzo, M. Pontil, and C. Ciliberto. Sinkhorn barycenters with free support via Frank-Wolfe algorithm. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. [55] A. Neufeld and Q. Xiang. Numerical method for approximately optimal solutions of two-stage distributionally robust optimization with marginal constraints. Preprint, arXiv:2205.05315, 2022. [56] A. Neufeld and Q. Xiang. Numerical method for feasible and approximately optimal solutions of multi-marginal optimal transport beyond discrete measures. Preprint, arXiv:2203.01633v3, 2022. [57] M. Nutz and J. Wiesel. Entropic optimal transport: convergence of potentials. Probability Theory and Related Fields, 2021. [58] G. Peyre\u0301 and M. Cuturi. Computational optimal transport: With applications to data science. Foundations and Trends in Machine Learning, 11(5-6):355\u2013607, 2019.\nFEASIBLE APPROXIMATION FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS 49\n[59] G. Puccetti, L. Ru\u0308schendorf, and S. Vanduffel. On the computation of Wasserstein barycenters. J. Multivariate Anal., 176:104581, 16, 2020. [60] S. T. Rachev and L. Ru\u0308schendorf. Mass Transportation Problems: Volume I: Theory. Springer Science & Business Media, 1998. [61] R. T. Rockafellar. Convex analysis. Princeton Mathematical Series, No. 28. Princeton University Press, Princeton, N.J., 1970. [62] S. Srivastava, C. Li, and D. B. Dunson. Scalable Bayes via barycenter in Wasserstein space. J. Mach. Learn. Res., 19(1):312\u2013346, 2018. [63] M. Staib, S. Claici, J. M. Solomon, and S. Jegelka. Parallel streaming Wasserstein barycenters. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. [64] E. G. Tabak, G. Trigila, and W. Zhao. Distributional barycenter problem through data-driven flows. Pattern Recognition, 130:108795, 2022. [65] N. Tupitsa, P. Dvurechensky, A. Gasnikov, and C. A. Uribe. Multimarginal optimal transport by accelerated alternating minimization. In 2020 59th IEEE Conference on Decision and Control (CDC), pages 6132\u20136137. IEEE, 2020. [66] P. M. Vaidya. A new algorithm for minimizing convex functions over convex sets. Math. Program., 73(3):291\u2013341, 1996. [67] R. J. Vanderbei. Linear programming\u2014foundations and extensions, volume 285 of International Series in Operations Research & Management Science. Springer, Cham, 2020. Fifth edition. [68] C. Villani. Topics in optimal transportation, volume 58 of Graduate Studies in Mathematics. American Mathematical Society, Providence, RI, 2003. [69] C. Villani. Optimal transport: Old and new, volume 338 of Grundlehren der mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]. Springer-Verlag, Berlin, 2009. [70] J. von Lindheim. Simple approximative algorithms for free-support Wasserstein barycenters. Comput. Optim. Appl., 85(1):213\u2013246, 2023. [71] Y. Xie, X. Wang, R. Wang, and H. Zha. A fast proximal point method for computing exact Wasserstein distance. In Uncertainty in Artificial Intelligence, pages 433\u2013453. PMLR, 2020. [72] L. Yang, J. Li, D. Sun, and K.-C. Toh. A fast globally linearly convergent algorithm for the computation of Wasserstein barycenters. J. Mach. Learn. Res., 22:21\u201337, 2021. [73] J. Ye, P. Wu, J. Z. Wang, and J. Li. Fast discrete distribution clustering using Wasserstein barycenter with sparse support. IEEE Trans. Signal Process., 65(9):2317\u20132332, 2017. [74] C. Zhang, H. Qian, and J. Xie. An asynchronous decentralized algorithm for Wasserstein barycenter problem. Preprint, arXiv:2304.11653, 2023.\nDIVISION OF MATHEMATICAL SCIENCES, NANYANG TECHNOLOGICAL UNIVERSITY, 21 NANYANG LINK, 637371 SINGAPORE\nEmail address: ariel.neufeld@ntu.edu.sg\nDIVISION OF MATHEMATICAL SCIENCES, NANYANG TECHNOLOGICAL UNIVERSITY, 21 NANYANG LINK, 637371 SINGAPORE\nEmail address: qikun.xiang@ntu.edu.sg"
        }
    ],
    "title": "FEASIBLE APPROXIMATION OF MATCHING EQUILIBRIA FOR LARGE-SCALE MATCHING FOR TEAMS PROBLEMS",
    "year": 2023
}