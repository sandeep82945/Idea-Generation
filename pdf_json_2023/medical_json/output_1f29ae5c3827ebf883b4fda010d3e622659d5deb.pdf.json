{
    "abstractText": "This paper presents a new Edge-AI algorithm for real-time and multi-feature (social distancing, mask detection, and facial temperature) measurement to minimize the spread of COVID-19 among individuals. COVID-19 has extenuated the need for an intelligent surveillance video system that can monitor the status of social distancing, mask detection, and measure the temperature of faces simultaneously using deep learning (DL) models. In this research, we utilized the fusion of three different YOLOv4-tiny object detectors for each task of the integrated system. This DL model is used for object detection and targeted for real-time applications. The proposed models have been trained for different data sets, which include people detection, mask detection, and facial detection for measuring the temperature, and evaluated on these existing data sets. Thermal and visible cameras have been used for the proposed approach. The thermal camera is used for social distancing and facial temperature measurement, while a visible camera is used for mask detection. The proposed method has been executed on NVIDIA platforms to assess algorithmic performance. For evaluation of the trained models, accuracy, recall, and precision have been measured. We obtained promising results for real-time detection for human recognition. Different couples of thermal and visible cameras and different NVIDIA edge platforms have been adopted to explore solutions with different trade-offs between cost and performance. The multi-feature algorithm is designed to monitor the individuals continuously in the targeted environments, thus reducing the impact of COVID-19 spread.",
    "authors": [
        {
            "affiliations": [],
            "name": "Abdussalam Elhanashi"
        }
    ],
    "id": "SP:91e54295ca9385c1ee612291acfdb141004ffe53",
    "references": [
        {
            "authors": [
                "T.V. Team",
                "D.J"
            ],
            "title": "Coronavirus: a visual guide to the outbreak",
            "venue": "https:// www. bbc. co. uk/ news/",
            "year": 2020
        },
        {
            "authors": [
                "A. Nalbandian",
                "K. Sehgal",
                "A Gupta"
            ],
            "title": "Post-acute COVID19 syndrome",
            "venue": "Nat. Med. 27, 601\u2013615",
            "year": 2021
        },
        {
            "authors": [
                "D Soba"
            ],
            "title": "Traffic restrictions during COVID-19 lockdown improve air quality and reduce metal biodeposition in tree leaves",
            "venue": "Urban For. Urban Green. 70, 127542",
            "year": 2022
        },
        {
            "authors": [
                "S. Hsiang",
                "D. Allen",
                "S Annan-Phan"
            ],
            "title": "The effect of largescale anti-contagion policies on the COVID-19 pandemic",
            "venue": "Nature 584, 262\u2013267",
            "year": 2020
        },
        {
            "authors": [
                "K. Goniewicz",
                "A. Khorram-Manesh"
            ],
            "title": "maintaining social distancing during the COVID-19 outbreak",
            "venue": "Soc. Sci. 10, 14",
            "year": 2021
        },
        {
            "authors": [
                "J. Mahmoudi",
                "C. Xiong"
            ],
            "title": "How social distancing, mobility, and preventive policies affect COVID-19 outcomes: big data-driven evidence from the District of Columbia-Maryland-Virginia (DMV) megaregion",
            "venue": "PLoS ONE 17(2), e0263820",
            "year": 2022
        },
        {
            "authors": [
                "P. Somaldo",
                "F.A. Ferdiansyah",
                "G. Jati",
                "W. Jatmiko"
            ],
            "title": "Developing smart COVID-19 social distancing surveillance drone using YOLO implemented in robot operating system simulation environment",
            "venue": "IEEE 8th R10 Humanitarian Technology Conference (R10-HTC), Kuching, Malaysia,",
            "year": 2020
        },
        {
            "authors": [
                "S. Saponara",
                "A. Elhanashi",
                "A. Gagliardi"
            ],
            "title": "Implementing a realtime, AI-based, people detection and social distancing measuring system for Covid-19",
            "venue": "J. Real-Time Image Proc. 18, 1937\u20131947",
            "year": 2021
        },
        {
            "authors": [
                "L. Zhang",
                "Y. Zhu",
                "M. Jiang",
                "Y. Wu",
                "K. Deng",
                "Q. Ni"
            ],
            "title": "Body temperature monitoring for regular COVID-19 prevention based on human daily activity recognition",
            "venue": "Sensors (Basel). 21(22), 7540",
            "year": 2021
        },
        {
            "authors": [
                "S.H. Safiabadi Tali",
                "J.J. LeBlanc",
                "Z. Sadiq",
                "O.D. Oyewunmi",
                "C. Camargo",
                "B. Nikpour",
                "N. Armanfard",
                "S.M. Sagan",
                "S. Jahanshahi-Anbuhi"
            ],
            "title": "Tools and techniques for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)/COVID-19 detection",
            "venue": "Clin. Microbiol. Rev. 34(3), e00228-e320",
            "year": 2021
        },
        {
            "authors": [
                "G.B. Dell\u2019Isola",
                "E. Cosentini",
                "L. Canale",
                "G. Ficco",
                "M. Dell\u2019Isola"
            ],
            "title": "Noncontact body temperature measurement: uncertainty evaluation and screening decision rule to prevent the spread of COVID-19",
            "venue": "Sensors 21, 346",
            "year": 2021
        },
        {
            "authors": [
                "Z Zhou"
            ],
            "title": "Temperature dependence of the SARS-CoV-2 affinity to human ACE2 determines COVID-19 progression and clinical outcome",
            "venue": "Comput. Struct. Biotechnol. J. 19, 161\u2013167",
            "year": 2021
        },
        {
            "authors": [
                "S. Saponara",
                "A. Elhanashi",
                "Q. Zheng"
            ],
            "title": "Recreating fingerprint images by convolutional neural network autoencoder architecture",
            "venue": "IEEE Access 9, 147888\u2013147899",
            "year": 2021
        },
        {
            "authors": [
                "Q Zheng"
            ],
            "title": "Improvement of generalization ability of deep CNN via implicit regularization in a two-stage training process",
            "venue": "IEEE Access 6, 15844\u201315869",
            "year": 2018
        },
        {
            "authors": [
                "C. Tang",
                "Y. Feng",
                "X. Yang",
                "C. Zheng",
                "Y. Zhou"
            ],
            "title": "The object detection based on deep learning",
            "venue": "4th International Conference on Information Science and Control Engineering (ICISCE),",
            "year": 2017
        },
        {
            "authors": [
                "S. Il Lee",
                "H. Kim"
            ],
            "title": "Instant and accurate instance segmentation equipped with path aggregation and attention gate",
            "venue": "International SoC Design Conference (ISOCC),",
            "year": 2020
        },
        {
            "authors": [
                "Q. Zheng",
                "P. Zhao",
                "Y Li"
            ],
            "title": "Spectrum interference-based two-level data augmentation method in deep learning for automatic modulation classification",
            "venue": "Neural Comput. Appl. 33, 7723\u20137745",
            "year": 2021
        },
        {
            "authors": [
                "Q. Zheng",
                "P. Zhao",
                "H. Wang",
                "A. Elhanashi",
                "S. Saponara"
            ],
            "title": "Fine-grained modulation classification using multi-scale radio transformer with dual-channel representation",
            "venue": "IEEE Commun. Lett. 26(6), 1298\u20131302",
            "year": 2022
        },
        {
            "authors": [
                "S. Saponara",
                "A. Elhanashi"
            ],
            "title": "Impact of Image Resizing on Deep Learning Detectors for Training Time and Model Performance.",
            "venue": "ApplePies",
            "year": 2021
        },
        {
            "authors": [
                "Z. Jiang",
                "L. Zhao",
                "S. Li",
                "Y. Jia"
            ],
            "title": "Real-time object detection method based on improved YOLOv4-tiny,",
            "venue": "[cs],",
            "year": 2011
        },
        {
            "authors": [
                "S. Saponara",
                "A. Elhanashi",
                "Q. Zheng"
            ],
            "title": "Developing a real-time social distancing detection system based on YOLOv4-tiny and bird-eye view for COVID-19",
            "venue": "J Real-Time Image Proc 19, 551\u2013 563",
            "year": 2022
        },
        {
            "authors": [
                "S. Saponara",
                "A. Elhanashi",
                "A. Gagliardi"
            ],
            "title": "Exploiting R-CNN for video smoke/fire sensing in antifire surveillance indoor and outdoor systems for smart cities",
            "venue": "IEEE International Conference on Smart Computing (SMARTCOMP),",
            "year": 2020
        },
        {
            "authors": [
                "M. Sandler",
                "A. Howard",
                "M. Zhu",
                "A. Zhmoginov",
                "Chen",
                "L.-C"
            ],
            "title": "RestNet50: Inverted residues and linear bottlenecks",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Won",
                "J.-H.",
                "Lee",
                "D.-H.",
                "Lee",
                "K.-M.",
                "Lin",
                "C.-H."
            ],
            "title": "An improved YOLOv3-based neural network for de-identification technology",
            "venue": "2019 34th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC), JeJu, Korea Journal of Real-Time Image Processing",
            "year": 2023
        },
        {
            "authors": [
                "Lin",
                "T.-Y",
                "P. Doll\u00e1r",
                "R. Girshick",
                "K. He",
                "B. Hariharan",
                "S. Belongie"
            ],
            "title": "Type pyramid networks for object detection",
            "venue": "IEEE Conference Proceedings on Computer Vision and Pattern Recognition,",
            "year": 2017
        },
        {
            "authors": [
                "F Hohman"
            ],
            "title": "Visual analytics in deep learning: an interrogative survey for the next frontiers",
            "venue": "IEEE Trans Vis Comput Graph 25(8), 2674\u20132693",
            "year": 2018
        },
        {
            "authors": [
                "G. Singh",
                "S. Tiwari",
                "J. Singh"
            ],
            "title": "Real time object detection using neural networks: a comprehensive survey",
            "venue": "Third International Conference on Artificial Intelligence and Smart Energy (ICAIS), Coimbatore, India,",
            "year": 2023
        },
        {
            "authors": [
                "Lin",
                "T.-Y",
                "P. Doll\u00e1r",
                "R. Girshick",
                "K. He",
                "B. Hariharan",
                "S. Belongie"
            ],
            "title": "Feature pyramid networks for object detection",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2017
        },
        {
            "authors": [
                "K. He",
                "G. Gkioxari",
                "P. Doll\u00e1r",
                "R. Girshick"
            ],
            "title": "Mask R-CNN",
            "venue": "IEEE International Conference on Computer Vision (ICCV),",
            "year": 2017
        },
        {
            "authors": [
                "S. Ren",
                "K. He",
                "R. Girshick",
                "J. Sun"
            ],
            "title": "Faster R-CNN: towards realtime object detection with region proposal networks",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell. 39(6), 1137\u20131149",
            "year": 2017
        },
        {
            "authors": [
                "J. Redmon"
            ],
            "title": "You only look once: Unified, real-time object detection",
            "venue": "IEEE CVPR,",
            "year": 2016
        },
        {
            "authors": [
                "A. Bochkovskiy",
                "C. Wang",
                "H. Liao"
            ],
            "title": "YOLOv4: optimal speed and accuracy of object detection",
            "venue": "Comput Sci",
            "year": 2020
        },
        {
            "authors": [
                "P. Viola",
                "M. Jones"
            ],
            "title": "Fast object detection using an enhanced cascade of simple features",
            "venue": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "year": 2001
        },
        {
            "authors": [
                "N Ottakath"
            ],
            "title": "ViDMASK dataset for face mask detection with social distance measurement",
            "venue": "Displays 73, 102235",
            "year": 2022
        },
        {
            "authors": [
                "H. Farman",
                "T. Khan",
                "Z. Khan",
                "S. Habib",
                "M. Islam",
                "A. Ammar"
            ],
            "title": "Real-time face mask detection to ensure COVID-19 precautionary measures in the developing countries",
            "venue": "Appl. Sci. 12, 19",
            "year": 2022
        },
        {
            "authors": [
                "I. Javed",
                "M.A. Butt",
                "S Khalid"
            ],
            "title": "Face mask detection and social distance monitoring system for COVID-19 pandemic",
            "venue": "Multimed. Tools Appl. 82, 14135\u201314152",
            "year": 2023
        },
        {
            "authors": [
                "M. Zhao",
                "A. Jha",
                "Q. Liu",
                "B.A. Millis",
                "A. Mahadevan-Jansen",
                "L. Lu",
                "B.A. Landman",
                "M.J. Tyska",
                "Y. Huo"
            ],
            "title": "Faster mean-shift: GPU-accelerated clustering for cosine embedding-based cell segmentation and tracking",
            "venue": "Med. Image Anal. 71, 102048",
            "year": 2021
        },
        {
            "authors": [
                "B. Qin",
                "D. Li"
            ],
            "title": "Identifying facemask-wearing condition using image super-resolution with classification network to prevent COVID-19",
            "venue": "Sensors 20(18), 5236",
            "year": 2020
        },
        {
            "authors": [
                "A. Elhanashi",
                "D. Lowe",
                "S. Saponara",
                "Y. Moshfeghi"
            ],
            "title": "Deep learning techniques to identify and classify COVID-19 abnormalities on chest x-ray images",
            "venue": "Proc. SPIE 12102,",
            "year": 2022
        },
        {
            "authors": [
                "T. Greenhalgh",
                "M.B. Schmid",
                "T. Czypionka",
                "D. Bassler",
                "L. Gruer"
            ],
            "title": "Face masks for the public during the COVID-19 crisis",
            "venue": "BMJ 369, m1435",
            "year": 2020
        },
        {
            "authors": [
                "Salagrama S",
                "Kumar H.H",
                "R. Nikitha",
                "G. Prasanna",
                "K. Sharma",
                "S. Awasthi"
            ],
            "title": "Real time social distance detection using Deep Learning",
            "venue": "Greater Noida, India,",
            "year": 2022
        },
        {
            "authors": [
                "Vibhuti",
                "N. Jindal",
                "H Singh"
            ],
            "title": "Face mask detection in COVID-19: a strategic review",
            "venue": "Multimed. Tools Appl. 81, 40013\u2013 40042",
            "year": 2022
        },
        {
            "authors": [
                "Y. Wu",
                "Q. Zhang",
                "L. Li",
                "M. Li",
                "Y. Zuo"
            ],
            "title": "Control and prevention of the COVID-19 epidemic in China: a qualitative community case study",
            "venue": "Risk Manag. Health Policy. 9(14), 4907\u20134922 (2021). https:// doi. org/ 10. 2147/ RMHP. S3360 39."
        },
        {
            "authors": [
                "Q. Zhao",
                "Y. Wang",
                "M Yang"
            ],
            "title": "Evaluating the effectiveness of measures to control the novel coronavirus disease 2019 in Jilin Province, China",
            "venue": "BMC Infect. Dis. 21, 245",
            "year": 2021
        },
        {
            "authors": [
                "C. Dzien",
                "W. Halder",
                "H Winner"
            ],
            "title": "Covid-19 screening: are forehead temperature measurements during cold outdoor temperatures helpful",
            "venue": "Wien Klin Wochenschr 133,",
            "year": 2021
        },
        {
            "authors": [
                "J. Prasad",
                "A. Jain",
                "D. Velho",
                "K.S. Sendhil Kumar"
            ],
            "title": "COVID vision: an integrated face mask detector and social distancing tracker",
            "venue": "Int. J. Cognit. Comput. Eng. 3, 106\u2013113 (2022)."
        },
        {
            "authors": [
                "B. Varshini",
                "H.R. Yogesh",
                "S. Pasha",
                "M. Suhail",
                "V. Madhumitha",
                "A. Sasi"
            ],
            "title": "IoT-enabled smart doors for monitoring body temperature and face mask detection",
            "venue": "Glob. Trans. Proc.",
            "year": 2021
        },
        {
            "authors": [
                "G. Lippi",
                "R. Nocini",
                "C. Mattiuzzi",
                "B.M. Henry"
            ],
            "title": "Is body temperature mass screening a reliable and safe option for preventing COVID-19 spread? Diagnosis (Berl)",
            "venue": "9(2), 195\u2013198 (2021). https:// doi. org/ 10. 1515/ dx- 2021- 0091.",
            "year": 2762
        },
        {
            "authors": [
                "A. Kuzdeuov",
                "D. Aubakirova",
                "D. Koishigarina",
                "H.A. Varol"
            ],
            "title": "TFW: annotated thermal faces in the wild dataset",
            "venue": "IEEE Trans. Inf. Forensics Secur. 17, 1\u201311",
            "year": 2022
        },
        {
            "authors": [
                "P. Dini",
                "S. Saponara"
            ],
            "title": "Analysis, design, and comparison of machine-learning techniques for networking intrusion detection",
            "venue": "Designs 5(1), 9",
            "year": 2021
        },
        {
            "authors": [
                "P Dini"
            ],
            "title": "Design and testing novel one-class classifier based on polynomial interpolation with application to networking security",
            "venue": "IEEE Access 10, 67910\u201367924",
            "year": 2022
        },
        {
            "authors": [
                "R. Giuliano",
                "E. Innocenti",
                "F. Mazzenga",
                "A.M. Vegni",
                "A. Vizzarri"
            ],
            "title": "IMPERSONAL: an IoT-Aided computer vision framework for social distancing for health safety",
            "venue": "IEEE Internet of Things J. 9(10), 7261\u20137272",
            "year": 2022
        },
        {
            "authors": [
                "A.H. Ahamad",
                "N. Zaini",
                "Latip"
            ],
            "title": "M.F.A.: Person detection for social distancing and safety violation alert based on segmented ROI",
            "venue": "IEEE International Conference on Control System, Computing and Engineering (ICCSCE), Penang, Malaysia,",
            "year": 2020
        },
        {
            "authors": [
                "B. Gopal",
                "A. Ganesan"
            ],
            "title": "Real time deep learning framework to monitor social distancing using improved single shot detector based on overhead position",
            "venue": "Earth Sci. Inform. 15, 585\u2013602",
            "year": 2022
        },
        {
            "authors": [
                "P Nagrath"
            ],
            "title": "SSDMNV2: A real-time DNNbased face mask detection system using single shot multibox detector and MobileNetV2",
            "venue": "Sustain. Cities Soc. 66, 102692",
            "year": 2021
        },
        {
            "authors": [
                "S. Teboulbi",
                "S. Messaoud",
                "M.A. Hajjaji",
                "A. Mtibaa"
            ],
            "title": "Real-time implementation of AI-based face mask detection and social distancing measuring system for COVID-19 prevention",
            "venue": "Sci. Program. 2022, 8340779",
            "year": 2022
        },
        {
            "authors": [
                "Q. Chen",
                "L. Sang"
            ],
            "title": "Face-mask recognition for fraud prevention using Gaussian mixture model",
            "venue": "J. Vis. Commun. Image Represent. 55, 795\u2013801 (2018) Journal of Real-Time Image Processing",
            "year": 2023
        },
        {
            "authors": [
                "Y Li"
            ],
            "title": "Cropping and attention based approach for masked face recognition",
            "venue": "Appl. Intell. 51, 3012\u20133025",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Vol.:(0123456789)\nKeywords Multi-feature detection\u00a0\u00b7 Social distancing\u00a0\u00b7 Mask detection\u00a0\u00b7 Facial temperature\u00a0\u00b7 Real-time\u00a0\u00b7 COVID-19\u00a0\u00b7 YOLOv4-tiny\u00a0\u00b7 Edge AI/video platforms"
        },
        {
            "heading": "1 Introduction",
            "text": "A. Motivations\nThe ongoing pandemic of COVID-19 has had a negative impact on the development of society, the economy, and the environment worldwide [1]. COVID-19 has spread widely worldwide, mainly by direct transmission, aerosol,\nand contact transmission. Direct transmission, when droplets cause infection breathed in through close-range interaction; by Aerosol, when droplets mixed with air form an aerosol that is inhaled [2]; and by Contact if droplets deposited on objects reach the nasal and oral cavities, eyes, or mucous membranes, due to non-sanitized hands. Symptoms of infection recorded are fever, dry cough, general fatigue, nasal congestion, and, more rarely, hypoxia. In the most severe cases, 50% have dyspnea after the first week, which could develop into acute respiratory distress, septic shock, metabolic acidosis, hemorrhage, and coagulation dysfunction. Most patients recover well, but a not-insignificant percentage remain in critical condition or even die. Many countries have taken restrictive measures to limit the spread of infection [3, 4], but with relatively little success. Even now, the key elements to ensure the safety of individuals are technologies that can detect social distance [5\u20138], face masks, and body * Abdussalam Elhanashi a.elhanashi@studenti.unipi.it 1 Ingegneria Informazione, University of\u00a0Pisa, Pisa, Italy 2 School of\u00a0Intelligent Engineering, Shandong Management University, Jinan\u00a0250357, Shandong, China 3 Department of\u00a0Information Engineering, Hiroshima\nUniversity, Hiroshima, Japan\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\n95 Page 2 of 14\ntemperature [9\u201312]. To this aim, a promising solution comes from AI-based systems.\nThis paper proposes integrating an embedded platform of three parallelized models of YOLOv4, a widely used deeplearning detector for object detection. The goal is to increase the degree of detail in detecting the attitudes of individuals that often cause the spread of infection.\nB. State-of-the-art overview\nConvolutional neural network models appear to be best suited for applications in image reconstruction and classification [13, 14], object detection [15], and instance segmentation [16]. They are also exploited for their ability to extract features and handle limited or incomplete data sets [17, 18]. YOLO certainly appears to be the most widely used of all the CNN-specific models due to its ability to integrate realtime systems [19]. In this work, three YOLOv4-tiny models have been proposed [20] to parallelize the detection of distance, presence of face mask, and temperature on different cores of the same processor. The proposed research takes inspiration from previous work [8, 21], which is limited to a single feature detection (social distancing only, enhanced with a bird\u2019s eye view for perspective in [21]) and taking input from a thermal camera only.\nIn contrast, this work refers to real-time multi-feature detection using thermal and visible cameras. Using multiple DL models, the proposed method involves detecting humans and faces with bounding boxes. These detected boxes are then processed to classify whether the individual wears a mask. Meanwhile, the proposed approach is a standalone application to proximate the distance between these individuals and measure their facial temperature. DL is used today in different real-time applications to protect the life of people from damage such as fire disasters [22], health care, and facial feature analysis by processing image or video surveillance systems. Compared with previous work, in addition to changing the application, we have improved aspects related to the computational capabilities of the DL models, as well as enhanced the integration flow on the embedded system to ensure real-time throughput by allowing us to use as many as three different YOLO models parallelized on other cores. Furthermore, several researchers use a combination of RestNet50 [23] and YOLOV3 [24] lightweight neural network architectures with transfer learning techniques. This is to regularize the resource constraints and the accuracy of object detection. In recent years, DL object recognition techniques [25] have been exploited significantly in computer vision tasks and can potentially be more effective than shallow models in solving complex problems. However, DL recognition models emphasize feature and contextual learning [26]. Therefore, object detection architectures [27] are split into two categories, which include two-stage models\nsuch as FPN [28], Mask R-CNN [29], and Faster R-CNN [30], and single-stage models such as YOLO [31] YOLOv2 [32], and YOLOv4 [33]. In the case of two-stage detectors, detection occurs in stages, with proposals being calculated in the first stage and object categories being classified in the final stage. At the same time, single-stage models consider the prediction a regression problem, which detects all the objects in the image in a single shoot.\nIn [34], the authors presented an object detection approach, which has been trained to predict the targeted objects in the images for face recognition. Researchers have proven that wearing face masks can significantly minimize COVID-19 spread in public areas. In addition, deep learning models can be trained to recognize whether people have face masks.\nFace mask detection has been used in transportation systems widely [35]. Face mask detection and social distance measurement can be accomplished using deep learning models [36]. The video camera can be utilized. and the DL algorithm can be used to perform face mask detection and people violating social distancing measurements. Moreover, it performs an effective process for feature extraction from the images. Authors in [37] proposed a framework for performing face mask detection and monitoring social distance to reduce the COVID-19 spread between individuals. They implemented their work on Raspberry PI4, which can perform multiple activities simultaneously. Embedded system-based deep learning algorithms gain increasing attention for different applications of object detection and tracking system [38]. Authors in [39] proposed a system that performs face mask detection, temperature measurement, and measuring social distancing to protect individuals from COVID-19. They presented an integrated approach, which includes Arduino Uno Raspberry Pi-based IoT system. In [40], authors proposed a detection system, non-real-time, for identifying COVID-19 by applying DL models on chest X-ray images.\nIt proved to be very accurate and hence quite beneficial for radiologists to prompt the detection of COVID-19. Artificial intelligence-enabled technology solutions, such as self-explanatory digital solutions, are needed to deal with the post-pandemic situation in society and industry. It will provide extreme support to minimize the impact of COVID-19 on the counter-economic circumstances [41, 42]. A previous study performed randomized social distancing and mask detection trials, which found that an inexpensive intervention would help interrupt respiratory virus transmission in society [43]. Recent studies have been carried out on handling community gatherings using different methods to minimize the spread of COVID-19 among individuals, such as social distancing and mask usage and temperature measurement, which is also an essential tool to detect symptoms of the virus. These studies utilized different techniques using\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\nPage 3 of 14 95\none or a combination of two methods to prevent the spread of COVID-19. However, these studies hold few limitations from a conceptual framework point of view. The evidence explored literature depicts the need to devise an efficient method to strengthen deep learning technology to respond effectively to the outbreak. In this paper, we propose an integrated approach that incorporates all three technologies (mask detection, social distancing, and temperature measurement) that can provide numerous advantages in controlling the spread of infectious diseases. It can help identify individuals who may be infected but are asymptomatic and provide real-time data on compliance with public health guidelines. Furthermore, an integrated approach can help to overcome the limitations of using each technology individually. Table\u00a01 shows a summary of existing studies.\nC. Contributions\nOur goal in this research is to enrich COVID-19 prevention system and examine the integrated algorithm to the other methodologies from the state-of-the-art. Therefore, an AI-enabled technology will enhance the overall situation by minimizing the lockdown phases, where systems such as surveillance, detection, and monitoring will be implemented by utilizing DL models and IoT-embedded devices as the required core solution to the ongoing pandemic. The contributions of this work are summarized as the followings:\n\u2022 This integrated approach can help prevent the spread of COVID-19 by monitoring social distancing, face mask detection, and facial temperature measurement by employing fusion of three different YOLOv4-tiny object detectors, to simultaneously monitor and detect these features in real-time. \u2022 The proposed YOLOv4 tiny can perform object detection and tracking much faster than the other state-of-the-art deep learning models. Despite its smaller size, YOLOv4 tiny can still achieve high accuracy in detecting objects for real-time applications. \u2022 Executing the proposed models on NVIDIA boards (Jetson nano and Xavier AGX) showcases its potential scalability and efficiency, paving the way for real-world applications in various scenarios with different trade-offs between cost and performance. \u2022 A single thermal camera has developed thermal screening systems to measure facial temperature for more than one person at once, while this camera continues to monitor social distancing between pedestrians.\nThe aim of YOLOv4-tiny in this research is to detect the objects in video frames. Given an input frame, the model processes it through its convolutional neural network to generate bounding box predictions and associated class Ta bl e 1 C\nom pa\nris on\nre vi\new o\nf d iff\ner en\nt s tu\ndi es\n, u si\nng d\niff er\nen t t\nec hn\niq ue\ns ( on\ne m\net ho\nd so\nle ly\no r a\nc om\nbi na\ntio n\nof tw\no) to\np re\nve nt\nC O\nV ID\n-1 9\nsp re\nad\nRe se\nar ch\na rti\ncl e\nM as k D et ec - tio n\nSo ci\nal\nD ist\nan c-\nin g\nTe m\npe ra\ntu re\nM\nea su\nre -\nm en\nt\nLi m\nita tio\nns\nRe vi\new a\nnd p\nro sp\nec t o\nf C O\nV ID\n-1 9\npa nd\nem ic\np re\nve nt\nio n\nan d\nco nt\nro l m\nea s-\nur es\nin C\nhi na\n[4 4]\n\u2717 \u2717\n\u2713 Li\nm ite\nd eff\nec tiv\nen es\ns o f t\nem pe\nra tu\nre m\nea su\nre m\nen t a\ns m an\ny CO\nV ID\n-1 9-\npo si - tiv e in di vi du al s m ay n ot h av e a fe ve\nr Ev al ua tin g th e eff ec tiv en es s o f m ea su re s t o co nt ro l t he n ov el c or on av iru s di se as e 20 19 in Ji lin P ro vi nc e, C hi na [4 5] \u2717 \u2713 \u2717 So ci al d ist an ci ng is c ha lle ng in g to m ai\nnt ai\nn in\nc ro\nw de\nd ar\nea s\nCO V\nID -1\n9 sc\nre en\nin g:\na re\nfo re\nhe ad\nte m\npe ra\ntu re\nm ea\nsu re\nm en\nts d\nur in\ng co\nld\nou td\noo r t\nem pe\nra tu\nre s h\nel pf\nul ?\n[4 6]\n\u2717 \u2717\n\u2713 Te\nm pe\nra tu\nre m\nea su\nre m\nen t i\ns u se\nfu l,\nbu t n\not e\nve ry\non e\nw ith\nC O\nV ID\n-1 9\nha s a\nfe\nve r;\npe op\nle w\nith a\nfe ve\nr m ay\nn ot\nh av\ne CO\nV ID\n-1 9\nCO V\nID v\nis io\nn: a\nn in\nte gr\nat ed\nfa ce\nm as\nk de\nte ct\nor a\nnd so\nci al\nd ist\nan ci\nng tr\nac ke r [4 7] \u2713\n\u2713 \u2717\nLi m\nite d\neff ec\ntiv en\nes s o\nf m as\nk de\nte ct\nio n\nin n\noi sy\ne nv\niro nm\nen ts\nA ut\nom at\ned c\non ta\nct le\nss te\nm pe\nra tu\nre a\nnd fa\nce m\nas k\nde te\nct io\nn us\nin g\nde ep\nle ar nin g [4 8] \u2713\n\u2717 \u2713\nM as\nks m\nay n\not b\ne ad\neq ua\nte ly\nw or\nn, o\nnl y\nch ec\nks fo\nr t he\nte m\npe ra\ntu re\na t o\nne\npo in t Is b od y te m pe ra tu re m as s s cr ee ni ng a re lia bl e an d sa fe o pt io n fo r p re ve nt in g CO V ID -1 9 sp re ad ? [4 9] \u2717 \u2717 \u2713 Te m\npe ra\ntu re\nm ea\nsu re\ns a lo\nne c\nan no\nt d et\nec t a\nsy m\npt om\nat ic\nc ar\nrie rs\n, f al\nse n\neg a-\ntiv es\nm ay\no cc\nur d\nue to\ne ar\nly st\nag es\no f i\nnf ec\ntio n\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\n95 Page 4 of 14\nprobabilities. Specifically, we integrated three different YOLOv4-tiny object detectors into the system, each serving a specific task: social distancing monitoring, mask detection, and facial temperature measurement. YOLOv4-tiny is a deep learning model known for its efficiency and suitability for real-time applications, making it a suitable choice for this edge-AI algorithm. The proposed models were trained on different data sets for people detection, mask detection, and facial temperature measurement. These data sets contain a diverse range of samples to ensure robustness and accuracy in different scenarios.\nThe rest of the paper is organized as follows: Section\u00a02 presents the proposed methodology; Section\u00a03 presents the obtained results and the discussion; Section\u00a04 describes realtime implementation on edge NVIDIA platforms. Finally, conclusions are drawn in Sect.\u00a05."
        },
        {
            "heading": "2 Proposed algorithm design methodology",
            "text": "In this work, we implemented the proposed method for multiple tasks, including monitoring social distancing and facial temperature measurement, using face mask detection algorithms. This approach provides an automated surveillance system, which uses video cameras to warn authorities and help them ensure the individuals comply with social distancing regulations, measuring their face temperature, and face mask detection norms to reduce virus spread. Three models of YOLOv4-tiny are utilized for the tasks described above. The proposed approach started with collecting the data sets for 3 tasks. Then, we trained and tested the YOLOv4-tiny models to evaluate their performance and robustness. The final prototype approach executed on the embedded system (Jetson Nano or Xavier AGX) is connected to the monitoring system to be executed as a standalone application in these devices. We used a visible video camera for face mask\ndetection and a thermal camera for social distance classification and measuring facial temperature. The visible and thermal cameras are operated simultaneously, installed, and executed on NVIDIA devices. Figure\u00a01 shows the integrated approach for face mask detection, social measuring, and facial temperature video measurement.\nA. Face mask detection\nThe images of face masks have been used from various sources on the internet. We selected various people of different ages in indoor and outdoor public places. 900 images have been used for this experiment. The selected images include single faces and crowded groups of individuals that appeared from different angles in these images. We have selected different types of masks with different colors, see Fig.\u00a02. A data annotation tool has been used to label the targeted faces on the images. There are various data annotations, such as image and video annotations, key-point annotations, and Polygonal segmentation annotations. In addition, LabelImg was utilized to label object bounding boxes on the images. This tool allows saving annotations in different formats. The YOLOv4-tiny model has been designed and trained for face mask detection. Figure\u00a03 shows the workflow for designing and training YOLOv4-tiny for face mask detection. The proposed approach aims to build a custom real-time model for face mask detection.\nB. Social distancing\nIn this research, YOLOv4-tiny model is used for human detection. 2000 thermal images have been collected from various sources. This data set consists of thermal images of people, which were acquired from different realistic indoor and outdoor environments. These thermal images contain natural scenes of human activity recognition, including\nwalking, talking, standing, and sitting. A custom annotation tool has been utilized to label persons with bounding boxes. We used the Euclidean formula to compute the distance and the centroid information for the detected bounding boxes. In this work, the Euclidean measurement distance is determined as 6 feet. We have assigned two different thresholds\nfor violation rules as dangerous and warn for the detected persons. We assigned the first threshold as warn, determined with yellow color, and the second threshold as dangerous, determined with red. If the distance between the detected people is less than or equal to 5 feet, the color of the bounding box is set to red. The bounding box color changes to yellow when the space between the detected bounding boxes is less than or equal to 6 feet and more than 5 feet. When the distance between the detected persons is more than 6 feet, the bounding box color is set to green, meaning social distancing is maintained safely.\nThe proposed approach has been implemented with Bird\u2019s eye view to eliminate the perspective view from the video camera. The top-down view helps our idea to improve the scalability of a social distancing estimation system. The video camera does not have to be set up in a specific way. Neither the camera's height nor the inclination angle needs to be determined. Instead, it needs to click four dots on the captured video images that will be the plane's corner points, transforming the targeted classes into a top-down view. These points must create a rectangle with at least 2 two opposite sides parallel. If this system is turned into a product, it can be adopted effectively.\nC. Facial temperature measurement\nFacial images have been utilized from work [50], see Fig.\u00a04. Most facial thermal data sets were collected from indoor and outdoor environments. These images were acquired from different scenes, including people in different body positions and facial expressions from a thermal video camera. 9.982 images have been utilized for this work. The thermal images have been inverted to get the negative images. Gamma correction has been applied\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\n95 Page 6 of 14\nto these negative images to improve their visibility. This enhanced the brightness of the features from the captured facials. The proposed system calculates the average temperature of individuals\u2019 faces based on pixel interpolation from a given image frame. The process determines the average temperature for each person \u2018face within the frame. Initially, the code loops through each person's faces bounding box in the frame and extracts the region of interest (ROI) corresponding to that person's faces. The process begins with the function get_person_temperature, which takes a list of bounding boxes (boxs) and an input image frame (frame). It proceeds to iterate over each bounding box in the list and extracts the region of interest (ROI) from the input image, assuming that the ROI contains the person's face. Python and appropriate libraries (e.g., OpenCV or PyTorch) are utilized to read the image and extract raw pixel values. By analyzing the pixels in the ROI, the code calculates the average temperature value. This temperature value is then mapped to a temperature range 36\u201338\u00a0\u00b0C using a custom map_function, allowing for better representation and visualization. The map_function is instrumental in this process as it transforms the calculated average temperature value from its original range. Finally the obtained raw pixel values are converted into integers.\nD. Model building and training\nYOLOv4-tiny structure is a deep convolutional neural network designed for object detection and recognition. It is a smaller and faster version of the original YOLOv4 model but still maintains high accuracy and precision in detecting objects in images and videos. The lightweight nature of YOLOv4-tiny also makes it suitable for use in mobile and embedded devices, which are becoming increasingly popular for real-time applications. With the rise of the Internet of Things (IoT), there is a growing need for low-power, low-cost devices that can perform real-time object detection. YOLOv4-tiny is well-suited for this task, as it can run on devices with limited processing power and memory. In YOLOv4-tiny, the classification model is typically based on the CSPDarknet53 architecture, which is a custom deep neural network architecture specifically designed for the YOLO models. CSPDarknet53 is a convolutional neural network and backbone for object detection that uses DarkNet-53. It employs a CSPNet strategy to partition the feature map of the base layer into two parts and then merges them through a cross-stage hierarchy. The use of a split and merge strategy allows for more gradient flow through the network; Fig.\u00a05 shows the structure of YOLOv4-tiny model. The convolutional neural network layers have been compressed to 29 layers to achieve fast detection. As a result, YOLOv4-tiny reached up to 371 fps, which could meet the requirement of real-time applications. YOLOv4-tiny model utilizes the\nCSPDarknet53-tiny network as a backbone, substituting the CSPDarknet53 network used in YOLOv4 architecture. The CSPDarknet53-tiny network is the CSP-Block architecture in the cross-stage model. It substituted the Res-Block architecture within the residual network. The feature map is divided by CSP-Block architecture into two segments. This creates a gradient, which could generate two separate paths for the network. CSP-Block architecture has the capability to enhance the learning of CNN in contrast to the ResBlock architecture. However, the accuracy of the model is improved by the increased computation. It eliminates the computational bottlenecks with higher computational overhead in the CSP-Block architecture to minimize the computational cost. Furthermore, it enhances the performance of the YOLOv4-tiny model with constant by reducing the computation. To improve the computation process, the Leaky-ReLU function is used as an activation function in YOLOv4-tiny model instead of mixed activation function used in YOLOv4 architecture, see Eq [1]. The Leaky-ReLU function is\nwhere ai \u2208 (1,+\u221e) is a constant value. The final stage of YOLOv4-tiny model is YOLO head. It is used to perform dense prediction. The outcome of dense prediction consisting of a vector containing the center coordinates that include {xcenter, ycenter, w, h} for the targeted objects. The data set of images has been split into training, validation, and testing with 70%, 20%, and 10%, respectively. These split balances training the model on enough data to prevent overfitting. A separate testing set is essential to evaluate the model's performance on unseen data. The\n(1)yi = \u23a7 \u23aa \u23a8 \u23aa \u23a9 xi ai ifxi < 0 xiifxi \u2265 0,\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\nPage 7 of 14 95\nresults obtained from the testing set are considered the final evaluation of the model.\nA graphical image labelling tool is utilized to annotate the bounding boxes for the targeted classes. The anchor box sizes are usually defined based on the aspect ratios and scales of objects present in the data set. Table\u00a02 provides a simplified example of anchor box sizes for each task. In practice, these sizes would be determined through experimentation and fine-tuning to achieve optimal performance for the specific data set and model architecture used in the research. To fine-tune the YOLOv4-tiny model, several hyperparameters were adjusted based on the specifications provided in Table\u00a03. The chosen method for training was \"sdgm.\" The training process was run for a total of 80 epochs, allowing the model to iterate over the entire data set 80 times. This helps the model learn and improve its performance over time. To prevent overfitting during training, L2 regularization was applied with a coefficient of 0.05. L2 regularization is used during to train the proposed models, to prevent overfitting and improve the generalization performance of the model on unseen data. L2 regularization helps address this issue by adding a penalty term to the loss function based on the L2 norm of the model's weights. L2 regularization term encourages the optimizer to minimize the weights of the model. As a result, the optimizer tends to penalize large weight values, reducing their impact on the final predictions. Smaller weights lead to a simpler model that is less to overfit and can generalize better to new data. The batch size used during training was set to 16. Batch size refers to the number of samples processed together in each iteration of the training process. The learning rate in this system was tuned through iterative experimentation, evaluating the model's response to error during training. Different learning rates were applied, and the model's performance was monitored on a validation set. The learning\nrate of 0.001 was eventually selected, as it demonstrated the best balance between stable convergence and achieving better performance on the specific task. YOLOv4-tiny model was optimized to achieve better performance and accuracy on the specific task or data set it was being trained for. The selection of these hyperparameters played a crucial role in shaping the model's ability to detect objects and produce meaningful predictions during inference. Figure\u00a06 shows the loose training curve for the three YOLOv4-tiny models for each task. All the experiments have been carried out to train the proposed models using Google Colab and NVIDIA Tesla K80 GPU system."
        },
        {
            "heading": "3 Experiment results and\u00a0discussion",
            "text": "A. Evaluation matrices In this research, we used the following performance confusion metrics criteria [51, 52] to evaluate the proposed framework: accuracy, recall, and precision see Eq. [2], where TP True Positive, TN True Negative, FPFalsePositive, FN FalseNegative were calculated from confusion matrix criteria. Accuracy can be defined as the number of all correct predictions divided by the total number of the data set. Precision is the percentage of correct positive predictions. It indicates how many selected predictive values are relevant. Finally, recall is the ability of the model to find all the appropriate cases within the given data set:\nB. Results of the proposed system The full description of the experiment results performed in this study is included in this subsection. The proposed system operates automated for social distancing, face mask detection, and facial temperature measurement. The simulation has been performed on the testing data set for the three tasks. The images have been acquired from different realistic situations, including indoor/outdoor environments. In addition, we designed other DL models, which include YOLO, YOLOv2, YOLOv3-tiny, and Faster R-CNN. This is to assess the proposed YOLOv4-tiny performance using the same training/testing data sets with these object detection architectures. According to the results from the experiments, see Fig.\u00a07, the performance of YOLOv4-tiny overcomes the other DL models for the three tasks (person detection, mask detection, and facial detection for temperature measurement). The first YOLOv4-tiny model for person detection\n(2)\nAccuracy = (TP + TN)\n(TN + FN) + (FP + TP)\nPrecision = TP\n(FP + TP)\nRecall = TP\n(FN + TP) .\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\n95 Page 8 of 14\nhas been assessed on thermal videos, which showed promising results among the social distancing classification algorithm.\nThe key challenge for social distancing is the accuracy of measuring the actual distance between the detected individuals in the thermal videos. Top-down view approach has improved the perspective view and has been used to process the video images from a 2-D view to a Bird\u2019s eye view. As a result, the centroids of the detected bounding box are transformed from the input image onto a top-down view, and then the social distance classification is performed. In addition,\nFig. 7 Performance of YOLOv4-tiny a social distancing, b facial temperature measurement, c mask detection\nJournal of Real-Time Image Processing (2023) 20:95\nPage 9 of 14 95\nthe threshold of violation for social distance is highlighted, which can also be correlated with the assigned bounding box colors among the individuals. Simultaneously, the second YOLOv4-tiny is executed to perform facial detection to measure individual temperature. The average acquired pixels have been mapped from the enclosed bounding boxes on the faces, which are assigned with blue color, and then converted into numbers, see Fig.\u00a08.\nWe examined the third YOLOv4-tiny model to detect if people wear respirator face masks or not. A green color indicates those people wearing face masks, while red is used for those not wearing face masks. In addition, on the top of each detected bounding box, two labels are assigned (Mask or No Mask), see Fig.\u00a09 (false negatives and positives were noted from this experiment). However, the proposed model achieved promising results in detecting real-time interactions among individuals. The proposed work for social distancing achieved better results in comparison with the method [8], which utilized two data sets of thermal images. It used a customized YOLOv2 lightweight architecture for object detection. YOLOv4-tiny represents a significant improvement over YOLOv2 in various aspects. It boasts a more powerful backbone network, utilizing CSPDarknet53, leading to enhanced feature extraction and better object detection performance. The proposed techniques are compared to the other methodologies for measuring social distance and face mask detection to assess performance based on accuracy [53\u201358]. These methods utilized different data sets for social distancing and mask detection in comparison with this work. The proposed approach achieved an accuracy of 96.2% for social distance measurement and 95.1% for face mask detection, and 96% for facial temperature model. Furthermore, YOLOv4-tiny utilizes anchor boxes to detect objects in different scales and aspect ratios. This architecture enables faster and more accurate object detection than MobileNet single shot detector (SSD), which has been utilized in the method [54]. In addition, robustness to occlusion and small\nobjects: YOLOv4-tiny is more robust and can detect small objects better CV and IoT algorithm, which was utilized in the method [53]. This is because YOLOv4-tiny uses a better feature extractor that can capture more detailed features of objects from the images. Nagrath et\u00a0al. [56] utilize MobileNetv2 for facemask detection. Its convolutional neural network architecture has gained popularity due to its lightweight and efficient design, making it a suitable choice for mobile and embedded devices. However, despite its advantages, there are still some drawbacks and limitations of the MobileNetV2 architecture: the lack of residual connections, which are present in other deep learning models, such as ResNet in YOLOv4-tiny. These connections allow information to flow directly from one layer to another, facilitating the training of deeper networks. Without these connections, the model may suffer from the vanishing gradient problem, making it difficult to train the model. Tables\u00a04 and 5 show the model accuracy compared to the other social distancing and mask detection methods. YOLOv4-tiny made it possible to detect COVID-19 pandemic in terms of respecting social distancing, face mask detection, and measuring the facial temperatures among individuals.\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\n95 Page 10 of 14"
        },
        {
            "heading": "4 Real\u2011time edge implementation",
            "text": "The final designed models have been executed in realtime on resource-constrained Edge NVIDIA platforms. We utilized Jetson Xavier and Jetson nano to execute the proposed architectures. Table\u00a06 presents a comparison of the proposed NVIDIA platforms, Jetson Nano, and Jetson Xavier. The Jetson Nano features a 128-core Maxwell GPU, a Quad-core ARM A57 CPU, and delivers 472 GFLOPs of AI performance. It is equipped with 4\u00a0GB of 64-bit LPDDR4 RAM and a MicroSD card slot for storage, offering a maximum resolution of 4\u00a0K @ 30 fps. Supported AI frameworks include TensorFlow, PyTorch, and Caffe. In contrast, the Jetson Xavier boasts a 512-core GPU, an 8-core ARMv8.2 CPU, providing 30 TOPs of AI performance. It comes with 16\u00a0GB of 256-bit LPDDR4x RAM and 16\u00a0GB eMMC flash storage, supporting 2 \u00d7 4\u00a0K @ 30 fps resolution. In addition, it supports various AI frameworks, such as TensorFlow, PyTorch, Caffe, cuDNN, CUDA, among others. However, the Jetson Xavier consumes more power, ranging from 10 to 30 W, while the Jetson Nano's power consumption lies between 5 and 10W. This research activity integrated the face mask detection approach with social distancing and measuring the face temperature of the individuals. This approach examines multiple DL model execution on a single NVIDIA board. Different cameras were utilized in this work, including\nRaspberry Pi model 2.1, See2CAM camera as a visible camera for face mask detection, and lepton 3.5, FLIR BOSON cameras for social distancing and measuring the facial temperature for the individuals. Lepton and Raspberry cameras have been connected with Jetson-nano. Boson and See3CAM cameras have been connected with Jetson Xavier AGX. Thermal cameras are radiometric measurements that can extract every pixel in the image. Therefore, the color map in the image has been converted to an array and integral of temperature values, which can be read.\nin numbers. Thanks to OpenCV and its supported libraries. We adjusted the frame height and width sizes for each camera output to 416 \u00d7 416. The proposed integrated approach has been executed on both Edge NVIDIA platforms. Based on the experiment results, the two cameras simultaneously produced mask face detection, facial temperature, and social distancing classification on the centralized monitoring system, see Fig.\u00a010.\nWe recorded the real-time detection and power consumption on both Edges NVIDIA platforms to assess the proposed techniques\u2019 performance, which includes social distancing (SD), Mask detection (MD), and facial temperature measurement (FTM) with different algorithm running scenarios, see Tables\u00a07 and 8. It has been observed that when three models run together, real-time detection performance decreases due to increased computation cost. Furthermore, for the variation\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\nPage 11 of 14 95\nof temperature, it is observed that the temperature of Jetson nano is higher than the temperature of Jetson Xavier when the proposed approach is running simultaneously for the three tasks, which leads to generating an alarm of over temperature and degrades the performance of Jetson nano, see Fig.\u00a011, b. This temperature difference attributed to the increased workload on Jetson nano as it struggles to handle the simultaneous execution of the three tasks, leading to elevated heat generation and potentially impacting overall performance.\nThis research compares the proposed approach to other methodologies, including pre-trained neural network models. The advantage of the integrated techniques is its small disk storage size (22.9\u00a0MB) for the YOLOv4-tiny of social distancing task, (22.8\u00a0MB) for facial temperature YOLOv4tiny model, and (23\u00a0MB) for mask detection YOLOv4-tiny,\nwhich these architectures have few learnable parameters. This makes them executable for low-cost IoT devices. On the other hand, other methodologies utilize pre-trained CNN layers that require large storage sizes to disk, such as the Resnet50 model [42]. In addition, the performance of these pre-trained models is very low for real-time applications on low-cost embedded, which impairs the performance of the targeted deep learning models from videos and images. The proposed DL for the three tasks algorithms utilizes lightweight and efficient deep learning models. These models are specifically designed to run on resource-constrained devices. Techniques such as model quantization, pruning, and knowledge distillation are applied to reduce the model's size and computational complexity while preserving its accuracy to the extent possible. NVIDIA devices (Jetson nano & Jetson Xavier) integrate specialized hardware accelerators such GPUs (Graphics Processing Units). These accelerators are optimized for performing matrix operations and other machine learning tasks, significantly speeding up the computations required for AI processing. To process multiple features simultaneously, NVIDIA devices leverage parallel computing techniques. They split the workload across multiple cores or threads available on the device's processor, allowing the algorithm to handle multiple inputs and outputs concurrently."
        },
        {
            "heading": "5 Conclusion",
            "text": "This research presented social distancing, mask detection algorithm, and facial temperature as an integrated approach executed in real-time on a single NVIDIA board. This assesses the robustness of low-cost embedded systems to run multiple deep-learning models simultaneously. The proposed vision-based system can be utilized in any indoor/ environment, such as public areas, train stations, streets, shopping centers, and smart cities, where the performance is suitable to fulfill the purpose. The proposed work ensures safe conditions between the individuals. In addition, the developed deep learning models were validated through multiple experiments and achieved promising results. Jetsons are low power consumption relative to computing power. We performed different experiments on Jetson nano & Jetson Xavier AGX with different algorithms scenarios. The highest real-time performance was obtained on Jetson Xavier AGX, which achieved 18 fps from the thermal camera and 62 fps from the visible camera when the three YOLOv4-tiny, based models executed at the same time. It is noted in this research that the claims of improved realtime detection in Jetson Xavier AGX lead to increased power demands compared to the performance in Jetson nano. This is due to continuously consuming a large amount of energy for the GPU architectures in Jetson Xavier AGX. Further to\nTable 8 Real-time detection for proposed method on Jetson Xavier AGX\nAlgorithm scenario Thermal cam Visible cam Power\nSD + MD + FTM 18 fps 62 fps 22.6 W SD + FT 23 fps \u2013 18 W MD \u2013 68 fps 13 W\nFig. 11 Temperature measurement for a Jetson nano b Jetson Xavier AGX\nJournal of Real-Time Image Processing (2023) 20:95\n1 3\n95 Page 12 of 14\nour exploration, recently released YOLOv7 will be considered for the integrated approach.\nAcknowledgements We thank the Re-Start Toscana COVID-19 project and the Testarossa EuroHPC project for their support.\nAuthor contributions AE carried out the experiments, and wrote the main manuscript text with support from PD BR & DM contributed to the final version of the manuscript. SS supervised the project.\nFunding Open access funding provided by Universit\u00e0 di Pisa within the CRUI-CARE Agreement.\nDeclarations\nConflict of interest The authors declare no competing interests.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/."
        }
    ],
    "title": "An integrated and real\u2010time social distancing, mask detection, and facial temperature video measurement system for pandemic monitoring Abdussalam Elhanashi1 \u00b7 Sergio Saponara1 \u00b7 Pierpaolo Dini1 \u00b7 Qinghe Zheng2 \u00b7 Daiki Morita3 \u00b7 Bisser Raytchev3",
    "year": 2023
}