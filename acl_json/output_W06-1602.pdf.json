{
    "abstractText": "In this paper we introduce an empirical approach to the semantic interpretation of superlative adjectives. We present a corpus annotated for superlatives and propose an interpretation algorithm that uses a wide-coverage parser and produces semantic representations. We achieve Fscores between 0.84 and 0.91 for detecting attributive superlatives and an accuracy in the range of 0.69\u20130.84 for determining the correct comparison set. As far as we are aware, this is the first automated approach to superlatives for open-domain texts and questions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Johan Bos"
        },
        {
            "affiliations": [],
            "name": "Malvina Nissim"
        }
    ],
    "id": "SP:d29c726729767b3782e6cd62f8ec91e84422df99",
    "references": [
        {
            "authors": [
                "Hiyan Alshawi",
                "editor"
            ],
            "title": "The Core Language Engine",
            "year": 1992
        },
        {
            "authors": [
                "J. Bos",
                "S. Clark",
                "M. Steedman",
                "J.R. Curran",
                "Hockenmaier J."
            ],
            "title": "Wide-Coverage Semantic Representations from a CCG Parser",
            "venue": "Proceedings of",
            "year": 2004
        },
        {
            "authors": [
                "Johan Bos."
            ],
            "title": "Towards wide-coverage semantic interpretation",
            "venue": "Proceedings of Sixth International Workshop on Computational Semantics IWCS-6, pages 42\u201353.",
            "year": 2005
        },
        {
            "authors": [
                "Thorsten Brants."
            ],
            "title": "TnT - A Statistical Part-ofSpeech Tagger",
            "venue": "Proceedings of the Sixth Applied Natural Language Processing Conference ANLP2000, Seattle, WA.",
            "year": 2000
        },
        {
            "authors": [
                "Jean Carletta."
            ],
            "title": "Assessing agreement on classification tasks: the kappa statistic",
            "venue": "Computational Linguistics, 22(2):249\u2013254.",
            "year": 1996
        },
        {
            "authors": [
                "S. Clark",
                "J.R. Curran."
            ],
            "title": "Parsing the WSJ using CCG and Log-Linear Models",
            "venue": "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL \u201904), Barcelona, Spain.",
            "year": 2004
        },
        {
            "authors": [
                "Jacob Cohen."
            ],
            "title": "A coefficient of agreement for nominal scales",
            "venue": "Educational and Psychological Measurements, 20:37\u201346.",
            "year": 1960
        },
        {
            "authors": [
                "Barbara Di Eugenio",
                "Michael Glass."
            ],
            "title": "The kappa statistic: a second look",
            "venue": "Computational Linguistics, 30(1).",
            "year": 2004
        },
        {
            "authors": [
                "Donka F. Farkas",
                "Katalin \u00c8. Kiss."
            ],
            "title": "On the comparative and absolute readings of superlatives",
            "venue": "Natural Language and Linguistic Theory, 18:417\u2013 455.",
            "year": 2000
        },
        {
            "authors": [
                "Jean Mark Gawron."
            ],
            "title": "Comparatives, superlatives, and resolution",
            "venue": "Linguistics and Philosophy, 18:333\u2013 380.",
            "year": 1995
        },
        {
            "authors": [
                "Ben Hachey",
                "Beatrice Alex",
                "Markus Becker."
            ],
            "title": "Investigating the effects of selective sampling on the annotation task",
            "venue": "Proceedings of the 9th Conference on Computational Natural Language Learning, Ann Arbor, Michigan, USA.",
            "year": 2005
        },
        {
            "authors": [
                "Irene Heim."
            ],
            "title": "Notes on superlatives",
            "venue": "MIT.",
            "year": 1999
        },
        {
            "authors": [
                "J. Hockenmaier",
                "M. Steedman."
            ],
            "title": "Generative Models for Statistical Parsing with Combinatory Categorial Grammar",
            "venue": "Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia, PA.",
            "year": 2002
        },
        {
            "authors": [
                "Bernard J. Jansen",
                "Amanda Spink."
            ],
            "title": "The excite research project: A study of searching by web users",
            "venue": "Bulletin of the American Society for Information Science and Technology, 27(1):5\u201317.",
            "year": 2000
        },
        {
            "authors": [
                "H. Kamp",
                "U. Reyle."
            ],
            "title": "From Discourse to Logic; An Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and DRT",
            "venue": "Kluwer, Dordrecht.",
            "year": 1993
        },
        {
            "authors": [
                "Klaus Krippendorff."
            ],
            "title": "Content Analysis: An Introduction to Its Methodology",
            "venue": "Sage Publications.",
            "year": 1980
        },
        {
            "authors": [
                "M. Steedman."
            ],
            "title": "The Syntactic Process",
            "venue": "The MIT Press.",
            "year": 2001
        },
        {
            "authors": [
                "Anna Szabolcsi."
            ],
            "title": "Comparative superlatives",
            "venue": "N. Fukui et al., editor, Papers in Theoretical Linguistics, MITWPL, volume 8. MIT.",
            "year": 1986
        },
        {
            "authors": [
                "Erik F. Tjong Kim Sang."
            ],
            "title": "Introduction to the conll-2002 shared task: Language-independent named entity recognition",
            "venue": "Proceedings of CoNLL-2002, pages 155\u2013158. Taipei, Taiwan.",
            "year": 2002
        }
    ],
    "sections": [
        {
            "text": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 9\u201317, Sydney, July 2006.c\u00a92006 Association for Computational Linguistics"
        },
        {
            "heading": "1 Introduction",
            "text": "Although superlative noun phrases (the nation\u2019s largest milk producer, the most complex armscontrol talks ever attempted, etc.) received considerable attention in formal linguistics (Szabolcsi, 1986; Gawron, 1995; Heim, 1999; Farkas and Kiss, 2000), this interest is not mirrored in computational linguistics and NLP. On the one hand, this seems remarkable, since superlatives are fairly frequently found in natural language. On the other hand, this is probably not that surprising, given that their semantic complexity requires deep linguistic analysis that most wide-coverage NLP systems do not provide.\nBut even if NLP systems incorporated linguistic insights for the automatic processing of superlatives, it might not be of help: the formal semantics literature on superlatives focuses on linguistically challenging examples (many of them artificially constructed) which might however rarely occur in real data and would therefore have little impact\non the performance of NLP systems. Indeed, no corpus-based studies have been conducted to get a comprehensive picture of the variety of configurations superlatives exhibit, and their distribution in real occurring data.\nIn this paper we describe our work on the analysis of superlative adjectives, which is empirically grounded and is implemented into an existing wide-coverage text understanding system. To get an overview of the behaviour of superlatives in text, we annotated newswire data, as well as queries obtained from search engines logs. On the basis of this corpus study, we propose, implement and evaluate a syntactic and semantic analysis for superlatives. To the best of our knowledge, this is the first automated approach to the interpretation of superlatives for open-domain texts that is grounded on actual corpus-evidence and thoroughly evaluated. Some obvious applications that would benefit from this work are question answering, recognition of entailment, and more generally relation extraction systems."
        },
        {
            "heading": "2 Syntax and Semantics of Superlatives",
            "text": ""
        },
        {
            "heading": "2.1 Surface Forms",
            "text": "In English, superlative adjectives appear in a large variety of syntactic and morphological forms. One-syllable adjectives and some two-syllable adjectives are directly inflected with the suffix \u201c-est\u201d. Some words of two syllables and all words of three or more syllables are instead introduced by \u201cmost\u201d (or \u201cleast\u201d). Superlatives can be modified by ordinals, cardinals or adverbs, such as intensifiers or modals, and are normally preceeded by the definite article or a possessive. The examples below illustrate the wide variety and uses of superlative adjectives.\n9\nthe tallest woman\nAS Roma\u2019s quickest player\nthe Big Board\u2019s most respected floor traders\nFrance\u2019s third-largest chemical group\nthe most-recent wave of friendly takeovers\nthe two largest competitors\nthe the southern-most tip of England\nits lowest possible prices\nSuperlative adjectives can manifest themselves in predicative (\u201cMia is the tallest.\u201d) or attributive form (\u201cthe tallest woman\u201d). Furthermore, there are superlative adverbs, such as \u201cmost recently\u201d, and idiomatic usages."
        },
        {
            "heading": "2.2 The Comparison Set",
            "text": "It is well known that superlatives can be analysed in terms of comparative constructions (Szabolcsi, 1986; Alshawi, 1992; Gawron, 1995; Heim, 1999; Farkas and Kiss, 2000). Accordingly, \u201cthe oldest character\u201d can be interpreted as the character such that there is no older character, in the given context. Therefore, a correct semantic interpretation of the superlative depends on the correct characterisation of the comparison set. The comparison set denotes the set of entities that are compared to each other with respect to a certain dimension (see Section 2.3). In \u201cthe oldest character in the book\u201d, the members of the comparison set are characters in the book, and the dimension of comparison is age.\nThe computation of the comparison set is complicated by complex syntactic structure involving the superlative. The presence of possessives for example, as in \u201cAS Roma\u2019s quickest player\u201d, extends the comparison set to players of AS Roma. Prepositional phrases (PPs), gerunds, and relative clauses introduce additional complexity. PPs that are attached to the head noun of the superlative are part of the comparison set \u2014 those that modify the entire NP are not. Similarly, restrictive relative clause are included in the comparison set, non-restrictive aren\u2019t.\nWe illustrate this complexity in the following examples, taken from the Wall Street Journal, where the comparison set is underlined:\nThe oldest designer got to work on the dashboard, she recalls. (WSJ02)\nA spokesman for Borden Inc., the nation\u2019s largest milk producer, concedes Goya may be on to something. (WSJ02)\nRight now, the largest loan the FHA can insure in high-cost housing markets is $101,250. (WSJ03)\nWith newspapers being the largest single component of solid waste in our landfills ... (WSJ02)\n... questions being raised by what generally are considered the most complex arms-control talks ever attempted. (WSJ02)\nBesides syntactic ambiguities, the determination of the comparison set can be further complicated by semantic ambiguities. Some occurrences of superlatives licence a so-called \u201ccomparitive\u201d reading, as in the following example discussed in the formal semantics literature (Heim, 1999; Szabolcsi, 1986):\nJohn climbed the highest mountain.\nHere, in the standard interpretion, the mountain referred to is the highest available in the context. However, another interpretation might arise in a situation where several people climbed several mountains, and John climbed a mountain higher than anyone else did, but not necessarily the highest of all mountains in the context. Our corpus study reveals that these readings are rare, although they tend to be more frequent in questions than in newspaper texts."
        },
        {
            "heading": "2.3 Dimension",
            "text": "Part of the task of semantically interpretating superlative adjectives is the selection of the dimension on which entities are compared. In \u201cthe highest mountain\u201d we compare mountains with respect to the dimension height, in \u201cthe best paper\u201d we compare papers with respect to the dimension quality, and so on. A well-known problem is that some adjectives can be ambiguous or vague in choosing their dimension. Detecting the appropriate dimension is not covered in this paper, but is orthogonal to the analysis we provide."
        },
        {
            "heading": "2.4 Superlatives and Entailment",
            "text": "Superlatives exhibit a non-trivial semantics. Some examples of textual entailment make this very evident. Consider the contrasts in the following entailment tests with indefinite and universally quantified noun phrases:\nI bought a blue car |= I bought a car I bought a car 6|= I bought a blue car\nI bought every blue car 6|= I bought every car I bought every car |= I bought every blue car\nObserve that the directions of entailments are mirrorred. Now consider a similar test with superlatives, where the entailments fail in both directions:\nI bought the cheapest blue car 6|= I bought the cheapest car I bought the cheapest car 6|= I bought the cheapest blue car.\nThese entailment tests underline the point that the meaning of superlatives is rather complicated, and that a shallow semantic representation, say \u03bbx.[cheapest(x) \u2227 car(x)] for \u201ccheapest car\u201d, simply won\u2019t suffice. A semantic represention capturing the meaning of a superlative requires a more sophisticated analysis. In particular, it is important to explicitly represent the comparison set of a superlative. In \u201cthe cheapest car\u201d, the comparison set is formed by the set of cars, whereas in \u201cthe cheapest blue car\u201d, the comparison set is the set of blue cars. Semantically, we can represent \u201ccheapest blue car\u201d as follows, where the comparison set is made explicit in the antecedent of the conditional:\n\u03bbx.[car(x) \u2227 blue(x) \u2227 \u2200y((car(y) \u2227 blue(y) \u2227 x 6=y) \u2192 cheaper(x,y))]\nParaphrased in English, this stipulates that some blue car is cheaper than any other blue car. A meaning representation like this will logically predict the correct entailment relations for superlatives."
        },
        {
            "heading": "3 Annotated Corpus of Superlatives",
            "text": "In order to develop and evaluate our system we manually annotated a collection of newspaper article and questions with occurrences of superlatives. The design of the corpus and its characteristics are described in this section."
        },
        {
            "heading": "3.1 Classification and Annotation Scheme",
            "text": "Instances of superlatives are identified in text and classified into one of four possible classes: attributive, predicative, adverbial, or idiomatic:\nits rates will be among the highest (predicative)\nthe strongest dividend growth (attributive)\nfree to do the task most quickly (adverbial)\nwho won the TONY for best featured actor? (idiom)\nFor all cases, we annotate the span of the superlative adjective in terms of the position of the tokens in the sentence. For instance, in \u201cits1 rates2 will3 be4 among5 the6 highest7\u201d, the superlative span would be 7\u20137.\nAdditional information is encoded for the attributive case: type of determiner (possessive, definite, bare, demonstrative, quantifier), number (sg, pl, mass), cardinality (yes, no), modification (adjective, ordinal, intensifier, none). Table 1 shows some examples from the WSJ with annotation values.\nNot included in this study are adjectives such as \u201cnext\u201d, \u201cpast\u201d, \u201clast\u201d, nor the ordinal \u201cfirst\u201d, although they somewhat resemble superlatives in their semantics. Also excluded are adjectives that lexicalise a superlative meaning but are not superlatives morphologically, like \u201cmain\u201d, \u201cprincipal\u201d, and the like. For etymological reasons we however include \u201cforemost\u201d and \u201cuttermost.\u201d"
        },
        {
            "heading": "3.2 Data and Annotation",
            "text": "Our corpus consists of a collection of newswire articles from the Wall Street Journal (Sections 00, 01, 02, 03, 04, 10, and 15) and the Glasgow Herald (GH950110 from the CLEF evaluation forum), and a large set of questions from the TREC QA evaluation exercise (years 2002 and 2003) and natural language queries submitted to the Excite search engine (Jansen and Spink, 2000). The data was automatically tokenised, but all typos and extra-grammaticalities were preserved. The corpus was split into a development set used for tuning the system and a test set for evaluation. The size of each sub-corpus is shown in Table 2.\nThe annotation was performed by two trained linguists. One section of the WSJ was annotated by both annotators independently to calculate inter-annotator agreement. All other documents were first annotated by one judge and then checked by the second, in order to ensure maximum correctness. All disagreements were discussed and resolved for the creation of a gold standard corpus.\nInter-annotator agreement was assessed mainly using f-score and percentage agreement as well as\nthe kappa statistics (K), where applicable (Carletta, 1996). In using f-score, we arbitrarily take one of the annotators\u2019 decisions (A) as gold standard and compare them with the other annotator\u2019s decisions (B). Note that here f-score is symmetric, since precision(A,B) = recall(B,A), and (balanced) f-score is the harmonic mean of precision and recall (Tjong Kim Sang, 2002; Hachey et al., 2005, see also Section 5).\nWe evaluated three levels of agreement on a sample of 1967 sentences (one full WSJ section). The first level concerns superlative detection: to what extent different human judges can agree on what constitutes a superlative. For this task, fscore was measured at 0.963 with a total of 79 superlative phrases agreed upon.\nThe second level of agreement is relative to type identification (attributive, predicative, adverbial, idiomatic), and is only calculated on the subset of cases both annotators recognised as superlatives (79 instances, as mentioned). The overall f-score for the classification task is 0.974, with 77 cases where both annotators assigned the same type to a superlative phrase. We also assessed agreement for each class, and the attributive type resulted the most reliable with an f-score of 1 (total agreement on 64 cases), whereas there was some disagreement in classifying predicative and adverbial cases (0.9 and 0.8 f-score, respectively). Idiomatic uses where not detected in this portion of the data. To assess this classification task we also used the kappa statistics which yielded KCo=0.922 (following (Eugenio and Glass, 2004) we report K as KCo, indicating that we calculate K a\u0300 la Cohen (Cohen, 1960). KCo over 0.9 is considered to signal very good agreement (Krippendorff, 1980).\nThe third and last level of agreement deals with the span of the comparison set and only concerns attributive cases (64 out of 79). Percentage agreement was used since this is not a classification task\nand was measured at 95.31%. The agreement results show that the task appears quite easy to perform for linguists. Despite the limited number of instances compared, this has also emerged from the annotators\u2019 perception of the difficulty of the task for humans."
        },
        {
            "heading": "3.3 Distribution",
            "text": "The gold standard corpus comprises a total of 3,045 superlatives, which roughly amounts to one superlative in every 25 sentences/questions. The overwhelming majority of superlatives are attributive (89.1%), and only a few are used in a predicative way (6.9%), adverbially (3.0%), or in idiomatic expressions (0.9%).1 Table 3 shows the detailed distribution according to data source and experimental sets. Although the corpus also includes annotation about determination, modification, grammatical number, and cardinality of attributive superlatives (see Section 3.1), this information is not used by the system described in this paper."
        },
        {
            "heading": "4 Automatic Analysis of Superlatives",
            "text": "The system that we use to analyse superlatives is based on two linguistic formalisms: Combinatory Categorial Grammar (CCG), for a theory of syntax; and Discourse Representation Theory (DRT)\n1Percentages are rounded to the first decimal and do not necessarily sum up to 100%.\nfor a theory of semantics. In this section we will illustrate how we extend these theories to deal with superlatives and how we implemented this into a working system."
        },
        {
            "heading": "4.1 Combinatory Categorial Grammar (CCG)",
            "text": "CCG is a lexicalised theory of grammar (Steedman, 2001). We used Clark & Curran\u2019s widecoverage statistical parser (Clark and Curran, 2004) trained on CCG-bank, which in turn is derived from the Penn-Treebank (Hockenmaier and Steedman, 2002). In CCG-bank, the majority of superlative adjective of cases are analysed as follows:\nthe tallest woman\nNP/N N/N N N\nNP\nmost devastating droughts\n(N/N)/(N/N) N/N N N/N\nN\nthird largest bank\nN/N (N/N)\\(N/N) N N/N\nN\nClark & Curran\u2019s parser outputs besides a CCG derivation of the input sentence also a part-ofspeech (POS) tag and a lemmatised form for each input token. To recognise attributive superlatives in the output of the parser, we look both at the POS tag and the CCG-category assigned to a word. Words with POS-tag JJS and CCGcategory N/N, (N/N)/(N/N), or (N/N)\\(N/N) are considered attributive superlatives adjectives, and so are the words \u201cmost\u201d and \u201cleast\u201d with CCG category (N/N)/(N/N).\nHowever, most hyphenated superlatives are not recognised by the parser as JJ instead of JJS, and are corrected in a post-processing step.2 Examples that fall in this category are \u201cmost-recent wave\u201d and \u201cthird-highest\u201d."
        },
        {
            "heading": "4.2 Discourse Representation Theory (DRT)",
            "text": "The output of the parser, a CCG derivation of the input sentence, is used to construct a Discourse Representation Structure (DRS, the semantic representation proposed by DRT (Kamp and Reyle,\n2This is due to the fact that the Penn-Treebank annotation guidelines prescribe that all hyphenated adjectives ought to be tagged as JJ.\n1993)). We follow (Bos et al., 2004; Bos, 2005) in automatically building semantic representation on the basis of CCG derivations in a compositional fashion. We briefly summarise the approach here.\nThe semantic representation for a word is determined by its CCG category, POS-tag, and lemma. Consider the following lexical entries:\nthe: \u03bbp.\u03bbq.( x ;p(x);q(x))\ntallest: \u03bbp.\u03bbx.( ( y\ny 6=x ;p(y))\u21d2 taller(x,y) ;p(x))\nman: \u03bbx. man(x)\nThese lexical entries are combined in a compositional fashion following the CCG derivation, using the \u03bb-calculus as a glue language:\ntallest man: \u03bbx. man(x) y\ny6=x man(y) \u21d2 taller(x,y)\nthe tallest man: \u03bbq.(\nx\nman(x) y\ny6=x man(y) \u21d2 taller(x,y)\n;q(x))\nIn this way DRSs can be produced in a robust way, achieving high-coverage. An example output representation of the complete system is shown in Figure 1.\nAs is often the case, the output of the parser is not always what one needs to construct a meaningful semantic representation. There are two cases where we alter the CCG derivation output by the parser in order to improve the resulting DRSs. The first case concerns modifiers following a superlative construction, that are attached to the NP node rather than N. A case in point is\n... the largest toxicology lab in New England ...\nwhere the PP in New England has the CCG category NP\\NP rather than N\\N. This would result in a comparison set containing of toxicology labs, rather than a set toxicology labs in New England.\nThe second case are possessive NPs preceding a superlative construction. An example here is\n... Jaguar\u2019s largest shareholder ...\nwhere a correct interpretation of the superlative requires a comparison set of shareholders from Jaguar, rather than just any shareholder. However, the parser outputs a derivation where \u201clargest\u201d is combined with \u201cshareholder\u201d, and then with the possessive construction, yielding the wrong semantic interpretation. To deal with this, we analyse possessives that interact with the superlative as follows:\nRome \u2019s oldest church NP ((NP/N)/(N/N)\\NP N/N N\n(NP/N)/(N/N) NP/N NP\nThis analysis yields the correct comparison set for superlative that follow a possessive noun phrase, given the following lexical semantics for the genitive: \u03bbn.\u03bbS.\u03bbp.\u03bbq.( u\n;S(\u03bbx.(p(x);n(\u03bby. of(y,x) )(u);q(u))))\nFor both cases, we apply some simple postprocessing rules to the output of the parser to obtain the required derivations. The effect of these rules is reported in the next section, where we assess the accuracy of the semantic representations produced for superlatives by comparing the automatic analysis with the gold standard."
        },
        {
            "heading": "5 Evaluation",
            "text": "The automatic analysis of superlatives we present in the following experiments consists of two se-\nquential tasks: superlative detection, and comparison set determination.\nThe first task is concerned with finding a superlative in text and its exact span (\u201clargest\u201d, \u201cmost beautiful\u201d, \u201c10 biggest\u201d). For a found string to to be judged as correct, its whole span must correspond to the gold standard. The task is evaluated using precision (P), recall (R), and f-score (F), calculated as follows:\nP = correct assignments of ctotal assignments of c R = correct assignments of ctotal corpus instances of c\nF = 2PcRcPc+Rc The second task is conditional on the first: once a superlative is found, its comparison set must also be identified (\u201crarest flower in New Zealand\u201d, \u201cNew York\u2019s tallest building\u201d, see Section 2.2). A selected comparison set is evaluated as correct if it corresponds exactly to the gold standard annotation: partial matches are counted as wrong. Assignments are evaluated using accuracy (number of correct decisions made) only on the subset of previously correctly identified superlatives.\nFor both tasks we developed simple baseline systems based on part-of-speech tags, and a more sophisticated linguistic analysis based on CCG and DRT (i.e. the system described in Section 4). In the remainder of the paper we refer to the latter system as DLA (Deep Linguistic Analysis)."
        },
        {
            "heading": "5.1 Superlative Detection",
            "text": "Baseline system For superlative detection we generated a baseline that solely relies on part-ofspeech information. The data was tagged using TnT (Brants, 2000), using a model trained on the Wall Street Journal. In the WSJ tagset, superlatives can be marked in two different ways, depending on whether the adjective is inflected or modified by most/least. So, \u201clargest\u201d, for instance, is tagged as JJS, whereas \u201cmost beautiful\u201d is a sequence of RBS (most) and JJ (beautiful). We also checked that they are followed by a common or proper noun (NN.*), allowing one word to occur in between. To cover more complex cases, we also considered pre-modification by adjectives (JJ), and cardinals (CD). In summary, we matched on sequences found by the following pattern:\n[(CD || JJ)* (JJS || (RBS JJ)) * NN.*]\nThis rather simple baseline is capable of detecting superlatives such as \u201c100 biggest banks\u201d, \u201cfourth largest investors\u201d, and \u201cmost important\nelement\u201d, but will fail on expressions such as \u201cfastest growing segments\u201d or \u201cScotland \u2019s lowest permitted 1995-96 increase\u201d.\nDLA system For evaluation, we extrapolated superlatives from the DRSs output by the system. Each superlative introduces an implicational DRS condition, but not all implicational DRS conditions are introduced by superlatives. Hence, for the purposes of this experiment superlative DRS conditions were assigned a special mark. While traversing the DRS, we use this mark to retrieve superlative instances. In order to retrieve the original string that gave rise to the superlative interpretation, we exploit the meta information encoded in each DRS about the relation between input tokens and semantic information. The obtained string position can in turn be evaluated against the gold standard.\nTable 4 lists the results achieved by the baseline system and the DLA system on the detection task. The DLA system outperforms the baseline system on precision in all sub-corpora. However, the baseline achieves a higher recall on the Excite queries. This is not entirely surprising given that the coverage of the parser is between 90\u201395% on unseen data. Moreover, Excite queries are often ungrammatical, thus further affecting the performance of parsing."
        },
        {
            "heading": "5.2 Comparison Set Determination",
            "text": "Baseline For comparison set determination we developed two baseline systems. Both use the same match on sequences of part-of-speech tags described above. For Baseline 1, the beginning of the comparison set is the first word following the superlative. The end of the comparison set is the first word tagged as NN.* in that sequence (the\nsame word could be the beginning and end of the comparison set, as it often happens).\nThe second baseline takes the first word after the superlative as the beginning of the comparison set, and the end of the sentence (or question) as the end (excluding the final punctuation mark). We expect this strategy to perform well on questions, as the following examples show. Where is the oldest synagogue in the United States?\nWhat was the largest crowd to ever come see Michael Jordan?\nThis approach is obviously likely to generate comparison sets much wider than required.\nMore complex examples that neither baseline can tackle involve possessives, since on the surface the comparison set lies at both ends of the superlative adjective:\nThe nation\u2019s largest pension fund the world\u2019s most corrupt organizations\nDLA 1 We first extrapolate superlatives from the DRS output by the system (see procedure above). Then, we exploit the semantic representation to select the comparison set: it is determined by the information encoded in the antecedent of the DRSconditional introduced by the superlative. Again, we exploit meta information to reconstruct the original span, and we match it against the gold standard for evaluation.\nDLA 2 DLA 2 builds on DLA 1, to which it adds post-processing rules to the CCG derivation, i.e. before the DRSs are constructed. This set of rules deal with NP post-modification of the superlative (see Section 4).\nDLA 3 In this version we include a set of postprocessing rules that apply to the CCG derivation to deal with possessives preceding the superlative (see Section 4).\nDLA 4 This is a combination of DLA 2 and DLA 3. This system is clearly expected to perform best.\nResults for both baseline systems and all versions of DLA are shown in Table 5\nOn text documents, DLA 2/3/4 outperform the baseline systems. DLA 4 achieves the best performance, with an accuracy of 69\u201383%. On questions, however, DLA 4 competes with the baseline: whereas it is better on TREC questions, it performs worse on Excite questions. One of the obvious reasons for this is that the parser\u2019s model\nfor questions was trained on TREC data. Additionally, as noted earlier, Excite questions are often ungrammatical and make parsing less likely to succeed. However, the baseline system, by definition, does not output semantic representations, so that its outcome is of little use for further reasoning, as required by question answering or general information extraction systems."
        },
        {
            "heading": "6 Conclusions",
            "text": "We have presented the first empirically grounded study of superlatives, and shown the feasibility of their semantic interpretation in an automatic fashion. Using Combinatory Categorial Grammar and Discourse Representation Theory we have implemented a system that is able to recognise a superlative expression and its comparison set with high accuracy.\nFor developing and testing our system, we have created a collection of over 3,000 instances of superlatives, both in newswire text and in natural language questions. This very first corpus of superlatives allows us to get a comprehensive picture of the behaviour and distribution of superlatives in real occurring data. Thanks to such broad view of the phenomenon, we were able discover issues previously unnoted in the formal semantics literature, such as the interaction of prenominal possessives and superlatives, which cause problems at the syntax-semantics interface in the determination of the comparison set. Similarly problematic are hyphenated superlatives, which are tagged as normal adjectives in the Penn Treebank.\nMoreover, this work provides a concrete way of evaluating the output of a stochastic widecoverage parser trained on the CCGBank (Hockenmaier and Steedman, 2002). With respect to superlatives, our experiments show that the qual-\nity of the raw output is not entirely satisfactory. However, we have also shown that some simple post-processing rules can increase the performance considerably. This might indicate that the way superlatives are annotated in the CCGbank, although consistent, is not fully adequate for the purpose of generating meaningful semantic representations, but probably easy to amend."
        },
        {
            "heading": "7 Future Work",
            "text": "Given the syntactic and semantic complexity of superlative expressions, there is still wide scope for improving the coverage and accuracy of our system. One obvious improvement is to amend CCGbank in order to avoid the need for postprocessing rules, thereby also allowing the creation of more accurate language models. Another aspect which we have neglected in this study but want to consider in future work is the interaction between superlatives and focus (Heim, 1999; Gawron, 1995). Also, only one of the possible types of superlative was considered, namely the attributive case. In future work we will consider the interpretation of predicative and adverbial superlatives, as well as comparative expressions. Finally, we would like to investigate the extent to which existing NLP systems (such as open-domain QA systems) can benefit from a detailed analysis of superlatives."
        },
        {
            "heading": "Acknowledgements",
            "text": "We would like to thank Steve Pulman (for information on the analysis of superlatives in the Core Language Engine), Mark Steedman (for useful suggestions on an earlier draft of this paper), and Jean Carletta (for helpful comments on annotation agreement issues), as well as three anonymous reviewers for their comments. We are extremely grateful to Stephen Clark and James Curran for making their parser available to us. Johan Bos is supported by a \u201cRientro dei Cervelli\u201d grant (Italian Ministry for Research); Malvina Nissim is supported by the EU FP6 NeOn project."
        }
    ],
    "title": "An Empirical Approach to the Interpretation of Superlatives",
    "year": 2006
}