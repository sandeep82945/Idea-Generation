{
    "abstractText": "The capacity of a channel can usually be characterized as a maximization of certain entropic quantities. From a practical point of view it is of primary interest to not only compute the capacity value, but also to find the corresponding optimizer, i.e., the capacity-achieving input distribution. This paper addresses the general question of whether or not it is possible to find algorithms that can compute the optimal input distribution depending on the channel. For this purpose, the concept of Turing machines is used which provides the fundamental performance limits of digital computers and therewith fully specifies which tasks are algorithmically feasible in principle. It is shown for discrete memoryless channels that it is impossible to algorithmically compute the capacity-achieving input distribution, where the channel is given as an input to the algorithm (or Turing machine). Finally, it is further shown that it is even impossible to algorithmically approximate these input distributions.",
    "authors": [
        {
            "affiliations": [],
            "name": "Holger Boche"
        },
        {
            "affiliations": [],
            "name": "Rafael F. Schaefer"
        }
    ],
    "id": "SP:c6b7578ccdd968e7a14b9bb2c74d57ef89e49f12",
    "references": [
        {
            "authors": [
                "H. Boche",
                "R.F. Schaefer",
                "H.V. Poor"
            ],
            "title": "Capacity-achieving input distributions: Algorithmic computability and approximability",
            "venue": "Proc. IEEE Int. Symp. Inf. Theory, Espoo, Finland, Jun. 2022, pp. 2774\u20132779.",
            "year": 2022
        },
        {
            "authors": [
                "C.E. Shannon",
                "R.G. Gallager",
                "E.R. Berlekamp"
            ],
            "title": "Lower bounds to error probability for coding on discrete memoryless channels",
            "venue": "Information and Control, vol. 10, no. 1, pp. 65\u2013103, 1967.",
            "year": 1967
        },
        {
            "authors": [
                "R.E. Blahut"
            ],
            "title": "Computation of channel capacity and rate-distortion functions",
            "venue": "IEEE Trans. Inf. Theory, vol. 18, no. 4, pp. 460\u2013473, Jul. 1972.",
            "year": 1972
        },
        {
            "authors": [
                "S. Arimoto"
            ],
            "title": "An algorithm for computing the capacity of arbitrary discrete memoryless channels",
            "venue": "IEEE Trans. Inf. Theory, vol. 18, no. 1, pp. 14\u201320, Jan. 1972.",
            "year": 1972
        },
        {
            "authors": [
                "I. Csisz\u00e1r"
            ],
            "title": "On the computation of rate-distortion functions",
            "venue": "IEEE Trans. Inf. Theory, vol. 20, no. 1, pp. 122\u2013124, Jan. 1974.",
            "year": 1974
        },
        {
            "authors": [
                "I. Csisz\u00e1r",
                "G. Tusn\u00e1dy"
            ],
            "title": "Information geometry and alternating minimization procedures",
            "venue": "Statistics and Decisions, Supplement Issue 1, pp. 205\u2013237, 1984.",
            "year": 1984
        },
        {
            "authors": [
                "T.M. Cover",
                "J.A. Thomas"
            ],
            "title": "Elements of Information Theory, 2nd ed",
            "year": 2006
        },
        {
            "authors": [
                "R.W. Yeung"
            ],
            "title": "Information Theory and Network Coding",
            "year": 2008
        },
        {
            "authors": [
                "F. Dupuis",
                "W. Yu",
                "F.M.J. Willems"
            ],
            "title": "Blahut-Arimoto algorithms for computing channel capacity and rate-distortion with side information",
            "venue": "Proc. IEEE Int. Symp. Inf. Theory, Chicago, IL, USA, Jun. 2004, p. 179.",
            "year": 2004
        },
        {
            "authors": [
                "P.O. Vontobel",
                "A. Kavcic",
                "D.M. Arnold",
                "H.-A. Loeliger"
            ],
            "title": "A generalization of the Blahut\u2013Arimoto algorithm to finite-state channels",
            "venue": "IEEE Trans. Inf. Theory, vol. 54, no. 5, pp. 1887\u20131918, May 2008.",
            "year": 1887
        },
        {
            "authors": [
                "T.J. Oechtering",
                "M. Andersson",
                "M. Skoglund"
            ],
            "title": "Arimoto-Blahut algorithm for the bidirectional broadcast channel with side information",
            "venue": "Proc. IEEE Inf. Theory Workshop, Taormina, Italy, Oct. 2009, p. 394\u2013398.",
            "year": 2009
        },
        {
            "authors": [
                "I. Naiss",
                "H.H. Permuter"
            ],
            "title": "Extension of the Blahut\u2013Arimoto algorithm for maximizing directed information",
            "venue": "IEEE Trans. Inf. Theory, vol. 59, no. 1, pp. 204\u2013222, Jan. 2013.",
            "year": 2013
        },
        {
            "authors": [
                "K.F. Trillingsgaard",
                "O. Simeone",
                "P. Popovski",
                "T. Larsen"
            ],
            "title": "Blahut- Arimoto algorithm and code design for action-dependent source coding problems",
            "venue": "Proc. IEEE Int. Symp. Inf. Theory, Istanbul, Turkey, Jul. 2013, pp. 1192\u20131196.",
            "year": 2013
        },
        {
            "authors": [
                "Y. Ugur",
                "I.E. Aguerri",
                "A. Zaidi"
            ],
            "title": "A generalization of Blahut-Arimoto algorithm to compute rate-distortion regions of multiterminal source coding under logarithmic loss",
            "venue": "Proc. IEEE Inf. Theory Workshop, Kaohsiung, Taiwan, Nov. 2017, pp. 349\u2013353.",
            "year": 2017
        },
        {
            "authors": [
                "H. Li",
                "N. Cai"
            ],
            "title": "A Blahut-Arimoto type algorithm for computing classical-quantum channel capacity",
            "venue": "Proc. IEEE Int. Symp. Inf. Theory, Paris, France, Jul. 2019, pp. 255\u2013259.",
            "year": 2019
        },
        {
            "authors": [
                "N. Ramakrishnan",
                "R. Iten",
                "V. Scholz",
                "M. Berta"
            ],
            "title": "Quantum Blahut- Arimoto algorithms",
            "venue": "Proc. IEEE Int. Symp. Inf. Theory, Los Angeles, CA, USA, Jun. 2020, pp. 1909\u20131914.",
            "year": 2020
        },
        {
            "authors": [
                "G. Ungerboeck",
                "A.J. Carlson"
            ],
            "title": "System and method for huffman shaping in a data communication system",
            "venue": "US Patent US8 000 387B2, 2011.",
            "year": 2011
        },
        {
            "authors": [
                "G. Zeitler",
                "R. Koetter",
                "G. Bauch",
                "J. Widmer"
            ],
            "title": "Relay station for a mobile communication system",
            "venue": "US Patent US8 358 679B2, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "A. Ephremides",
                "B. Hajek"
            ],
            "title": "Information theory and communication networks: An unconsummated union",
            "venue": "IEEE Trans. Inf. Theory, vol. 44, no. 6, pp. 2416\u20132434, Oct. 1998. 14",
            "year": 1998
        },
        {
            "authors": [
                "A.M. Turing"
            ],
            "title": "On computable numbers, with an application to the Entscheidungsproblem",
            "venue": "Proc. London Math. Soc., vol. 2, no. 42, pp. 230\u2013265, 1936.",
            "year": 1936
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "On computable numbers, with an application to the Entscheidungsproblem. A correction",
            "venue": "Proc. London Math. Soc., vol. 2, no. 43, pp. 544\u2013546, 1937.",
            "year": 1937
        },
        {
            "authors": [
                "K. Weihrauch"
            ],
            "title": "Computable Analysis - An Introduction",
            "venue": "Berlin, Heidelberg: Springer-Verlag,",
            "year": 2000
        },
        {
            "authors": [
                "J. Avigad",
                "V. Brattka"
            ],
            "title": "Computability and analysis: The legacy of Alan Turing",
            "venue": "Turing\u2019s Legacy: Developments from Turing\u2019s Ideas in Logic, R. Downey, Ed. Cambridge, UK: Cambridge University Press, 2014.",
            "year": 2014
        },
        {
            "authors": [
                "K. G\u00f6del"
            ],
            "title": "Die Vollst\u00e4ndigkeit der Axiome des logischen Funktionenkalk\u00fcls",
            "venue": "Monatshefte f\u00fcr Mathematik, vol. 37, no. 1, pp. 349\u2013360, 1930.",
            "year": 1930
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "On undecidable propositions of formal mathematical systems",
            "venue": "Notes by Stephen C. Kleene and Barkely Rosser on Lectures at the Institute for Advanced Study, Princeton, NJ, 1934.",
            "year": 1934
        },
        {
            "authors": [
                "S.C. Kleene"
            ],
            "title": "Introduction to Metamathematics",
            "year": 1952
        },
        {
            "authors": [
                "M. Minsky"
            ],
            "title": "Recursive unsolvability of Post\u2019s problem of \u2019tag\u2019 and other topics in theory of Turing machines",
            "venue": "Ann. Math., vol. 74, no. 3, pp. 437\u2013455, 1961.",
            "year": 1961
        },
        {
            "authors": [
                "H. Boche",
                "R.F. Schaefer",
                "H.V. Poor"
            ],
            "title": "Secure communication and identification systems \u2013 Effective performance evaluation on Turing machines",
            "venue": "IEEE Trans. Inf. Forensics Security, vol. 15, pp. 1013\u20131025, 2020.",
            "year": 2020
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "Shannon meets Turing: Non-computability of the finite state channel capacity",
            "venue": "Commun. Inf. Syst., vol. 20, no. 2, pp. 81\u2013116, 2020, invited in honor of Prof. Thomas Kailath on the occasion of his 85th birthday.",
            "year": 2020
        },
        {
            "authors": [
                "\u2014\u2014"
            ],
            "title": "Coding for non-iid sources and channels: Entropic approximations and a question of Ahlswede",
            "venue": "Proc. IEEE Inf. Theory Workshop, Visby, Sweden, Aug. 2019, pp. 1\u20135.",
            "year": 2019
        },
        {
            "authors": [
                "M.B. Pour-El",
                "J.I. Richards"
            ],
            "title": "Computability in Analysis and Physics",
            "year": 2017
        },
        {
            "authors": [
                "H. Boche",
                "R.F. Schaefer",
                "S. Baur",
                "H.V. Poor"
            ],
            "title": "On the algorithmic computability of the secret key and authentication capacity under channel, storage, and privacy leakage constraints",
            "venue": "IEEE Trans. Signal Process., vol. 67, no. 17, pp. 4636\u20134648, Sep. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "R.I. Soare"
            ],
            "title": "Recursively Enumerable Sets and Degrees",
            "venue": "Berlin, Heidelberg: Springer-Verlag,",
            "year": 1987
        },
        {
            "authors": [
                "C.E. Shannon"
            ],
            "title": "A mathematical theory of communication",
            "venue": "Bell Syst. Tech. J., vol. 27, no. 3, pp. 379\u2013423, Jul. 1948.",
            "year": 1948
        },
        {
            "authors": [
                "A. El Gamal",
                "Y.-H. Kim"
            ],
            "title": "Network Information Theory",
            "year": 2011
        },
        {
            "authors": [
                "D.R.R.G. Bartle"
            ],
            "title": "Sherbert, Introduction to Real Analysis, 3rd ed",
            "venue": "New York: Wiley,",
            "year": 2000
        },
        {
            "authors": [
                "H. Boche",
                "V. Pohl"
            ],
            "title": "On the algorithmic solvability of spectral factorization and applications",
            "venue": "IEEE Trans. Inf. Theory, vol. 66, no. 7, pp. 4574\u20134592, Jul. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "T.Y. Chow"
            ],
            "title": "What is a closed-form number?",
            "venue": "Amer. Math. Monthly,",
            "year": 1999
        },
        {
            "authors": [
                "J.M. Borwein",
                "R.E. Crandall"
            ],
            "title": "Closed forms: What they are and why we care",
            "venue": "Notices of the American Mathematical Society, vol. 60, pp. 50\u201365, 2013.",
            "year": 2013
        },
        {
            "authors": [
                "E. Specker"
            ],
            "title": "Der Satz vom Maximum in der rekursiven Analysis",
            "venue": "Constructivity in Math, pp. 254\u2013265, 1959.",
            "year": 1959
        },
        {
            "authors": [
                "G.P. Fettweis",
                "H. Boche"
            ],
            "title": "6G: The personal Tactile Internet and open questions for information theory",
            "venue": "IEEE BITS the Information Theory Magazine, vol. 1, no. 1, pp. 71\u201382, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "P. Schwenteck",
                "G.T. Nguyen",
                "H. Boche",
                "W. Kellerer",
                "F.H.P. Fitzek"
            ],
            "title": "6G: Perspective of Mobile Network Operators, Manufacturers, and Verticals",
            "venue": "IEEE Netw. Let., 2023.",
            "year": 2023
        },
        {
            "authors": [
                "G.P. Fettweis",
                "H. Boche"
            ],
            "title": "On 6G and trustworthiness",
            "venue": "Commun. ACM, vol. 65, no. 4, pp. 48\u201349, Apr. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "A. Gelfond"
            ],
            "title": "On Hilbert\u2019s seventh problem",
            "venue": "Doklady Akademii Nauk SSSR, p. 177\u2013182, 1934.",
            "year": 1934
        },
        {
            "authors": [
                "T. Schneider"
            ],
            "title": "Transzendenzuntersuchungen periodischer Funktionen I. Transzendenz von Potenzen",
            "venue": "Journal f\u00fcr die reine und angewandte Mathematik, no. 172, pp. 65\u201369, 1935.",
            "year": 1935
        }
    ],
    "sections": [
        {
            "text": "Index Terms\u2014Capacity-achieving input distribution, Turing machine, computability, approximability.\nI. INTRODUCTION\nThe capacity of a channel describes the maximum rate at which a sender can reliably transmit a message over a noisy channel to a receiver. Accordingly, the capacity is a function of the channel and is usually expressed by entropic quantities that are maximized over all possible input distributions. To this end, a (numerical) evaluation of the capacity and a characterization of the optimal input distribution that\nThis work of H. Boche was supported in part by the German Federal Ministry of Education and Research (BMBF) within the national initiative on 6G Communication Systems through the research hub 6G-life under Grant 16KISK002, within the national initiative on Post Shannon Communication (NewCom) under Grant 16KIS1003K, and the project Hardware Platforms and Computing Models for Neuromorphic Computing (NeuroCM) under Grant 16ME0442. It has further received funding by the Bavarian Ministry of Economic Affairs, Regional Development and Energy as part of the project 6G Future Lab Bavaria. This work of R. F. Schaefer was supported in part by the BMBF within NewCom under Grant 16KIS1004 and 6G-life under Grant 16KISK001K as well as in part by the German Research Foundation (DFG) under Grant SCHA 1944/6-1. This work of H. V. Poor was supported by the U.S. National Science Foundation under Grant CCF-1908308. This article was presented in part at the IEEE International Symposium on Information Theory (ISIT), Espoo, Finland, June 2022 [1].\nHolger Boche is with the Institute of Theoretical Information Technology, Technical University of Munich, the BMBF Research Hub 6G-life, the Munich Quantum Valley (MQV), 80290 Munich, Germany, and the Excellence Cluster Cyber Security in the Age of Large-Scale Adversaries (CASA), Ruhr University Bochum, 44801 Bochum, Germany (email: boche@tum.de).\nR. F. Schaefer is with the Chair of Information Theory and Machine Learning, Technische Universita\u0308t Dresden, the BMBF Research Hub 6G-life, the Cluster of Excellence \u201cCentre for Tactile Internet with Human-in-the-Loop (CeTI)\u201d, and the 5G Lab Germany, Technical University of Dresden, 01069 Dresden, Germany (E-mail: rafael.schaefer@tu-dresden.de).\nH. Vincent Poor is with the Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ 08544, USA (email: poor@princeton.edu).\nmaximizes the capacity expression are important and common tasks in information and communication theory. To date, for discrete memoryless channels (DMCs) no general closed form solutions for the capacity expressions or the corresponding optimal input distribution as a function of the channel are known. Therefore, several approaches have been proposed to algorithmically compute the capacity and also (implicitly) the corresponding optimizer. Such a numerical simulation and computation on digital computers has been already proposed by Shannon, Gallager, and Berlekamp in [2] and Blahut in [3]. This is an interesting and challenging task for digital computers which can be seen already for the binary symmetric channel with rational crossover probability p whose capacity is a transcendental number1 in general except for the trivial case p = 12 (see also the appendix for a detailed discussion on this). Thus, an exact computation of the capacity value is not possible on a digital computer as any practical algorithm must stop after a finite number of computation steps and, therefore, only an approximation of the capacity value is possible. From a practical point of view, this is not a problem since there are algorithms that take the rational crossover probability p and a given approximation error 12n with n \u2208 N as inputs and stop when a rational number is calculated whose approximation error to the corresponding capacity is smaller than the required approximation error 12n .\nA famous iterative algorithm for the computation of the capacity of an arbitrary DMC was independently proposed in 1972 by Blahut [3] and Arimoto [4], where the former further presented a corresponding algorithm for the computation of the rate-distortion function. This iterative algorithm is now referred to as the Blahut-Arimoto algorithm. It was further studied by Csisza\u0301r [5] and later generalized by Csisza\u0301r and Tusna\u0301dy [6]. The Blahut-Arimoto algorithm also appears in introductory textbooks on information theory such as [7] and [8]. Since then, the Blahut-Arimoto algorithm has been extensively studied and extended to various scenarios, cf. for example [9\u201316]. It further has served as the basis for the computation of the optimal input distribution in various patents such as [17] and [18].\nBlahut motivated his studies in [3] by the desire to use digital computers, which were becoming more and more powerful at this time, for the numerical computation of the capacity of DMCs. Since the seminal works [3] and [4], digital computers have been extensively used in information and communication theory to simulate and evaluate the per-\n1An algebraic number is a number that is a root of a non-zero polynomial with integer coefficients. A transcendental number is a number that is not algebraic, i.e., it is not a root of any non-zero integer polynomial.\nar X\niv :2\n20 2.\n12 61\n7v 2\n[ cs\n.I T\n] 2\n3 M\nay 2\n02 3\n2 formance of communication systems. Not surprisingly, higherlayer network simulations on high performance computers has become a commonly used approach for the design of practical systems. A critical discussion on this trend is given in [19].\nIn this paper, we address the issue of computing the optimal input distribution from a fundamental algorithmic point of view by using the concept of a Turing machine [20\u201322] and the corresponding computability framework. The Turing machine is a mathematical model of an abstract machine that manipulates symbols on a strip of tape according to certain given rules. It can simulate any given algorithm and therewith provides a simple but very powerful model of computation. Turing machines have no limitations on computational complexity, unlimited computing capacity and storage, and execute programs completely error-free. They are further equivalent to the von Neumann-architecture without hardware limitations and the theory of recursive functions, cf. also [23\u201327]. Accordingly, Turing machines provide fundamental performance limits for today\u2019s digital computers and are the ideal concept to study whether or not such computation tasks can be done algorithmically in principle.\nCommunication from a computability or algorithmic point of view has attracted some attention recently. In [28] the computability of the capacity functions of the wiretap channel under channel uncertainty and adversarial attacks is studied. The computability of the capacity of finite state channels is studied in [29] and of non-i.i.d. channels in [30]. These works have in common that they study capacity functions of various communication scenarios and analyze the algorithmic computability of the capacity function itself. While for DMCs the capacity function is a computable continuous function and therewith indeed algorithmically computable [31, 32], this is no longer the case for certain multi-user scenarios or channels with memory. However, they do not consider the computation of the optimal input distributions which, to the best of our knowledge, has not been studied so far from a fundamental algorithmic point of view. In addition, even if the capacity is computable, it is still not clear whether or not the corresponding optimal input distributions can be algorithmically computed.\nWe consider finite input and output alphabets. Due to the properties of the mutual information, the set of capacityachieving input distributions is mathematically well defined for every DMC and so are all functions that map every channel to a corresponding capacity-achieving input distribution. A practically relevant question is now whether or not these functions are also algorithmically well defined. With this we mean whether or not it is possible to find at least one function that can be implemented by an algorithm (or Turing machine). This is equivalent to the question of whether or not a Turing machine exists that takes a computable channel as input and subsequently computes an optimal input distribution of this channel.\nIn this paper, we give a negative answer to the question above by showing that it is in general impossible to find an algorithm (or Turing machine) that is able to compute the optimal input distribution when the channel is given as an input. To this end, we first introduce the computability\nframework based on Turing machines in Section II. The communication system model and the Blahut-Arimoto algorithm are subsequently introduced in Section III. In Section IV we study the computability of an optimal input distribution and show that all functions that map channels to their corresponding optimal input distributions are not Banach-Mazur computable and therewith also not Turing computable. As a consequence, there is no algorithm (or Turing machine) that is able to compute the optimizer, i.e., the capacity-achieving input distribution. Subsequently, it is shown in Section V that it is further not even possible to algorithmically approximate the optimizer, i.e., the capacity-achieving input distribution, within a given tolerated error. Finally, a conclusion is given in Section VI.\nNotation\nDiscrete random variables are denoted by capital letters and their realizations and ranges by lower case and calligraphic letters, respectively; all logarithms and information quantities are taken to the base 2; N, Q, and R are the sets of non-negative integers, rational numbers, and real numbers; P(X ) denotes the set of all probability distributions on X and CH(X ;Y) denotes the set of all stochastic matrices (channels) X \u2192 P(Y); the binary entropy is denoted by h2(p) = \u2212p log p \u2212 (1 \u2212 p) log(1 \u2212 p) and I(X;Y ) denotes the mutual information between the input X and the output Y which we interchangeably also write as I(p,W ) to emphasize the dependency on the input distribution p \u2208 P(X ) and the channel W \u2208 CH(X ;Y); the \u21131-norm is denoted by \u2225 \u00b7 \u2225\u21131 ."
        },
        {
            "heading": "II. COMPUTABILITY FRAMEWORK",
            "text": "We first introduce the computability framework based on Turing machines which provides the needed background. Turing machines are extremely powerful compared to stateof-the-art digital signal processing (DSP) and field gate programmable array (FPGA) platforms and even current supercomputers. It is the most general computing model and is even capable of performing arbitrary exhaustive search tasks on arbitrary large but finite structures. The complexity can even grow faster than double-exponentially with the set of parameters of the underlying communication system (such as time, frequencies, transmit power, modulation scheme, number of antennas, etc.).\nIn what follows, we need some basic definitions and concepts of computability which are briefly reviewed. The concept of computability and computable real numbers was first introduced by Turing in [20] and [21].\nRecursive functions f : N \u2192 N map natural numbers into natural numbers and are exactly those functions that are computable by a Turing machine. They are the smallest class of partial functions that includes the primitive functions (i.e., the constant function, successor function, and projection function) and is further closed under composition, primitive recursion, and minimization. For a detailed introduction, we refer the reader to [31] and [33]. With this, we call a sequence of rational numbers (rn)n\u2208N a computable sequence if there\n3 exist recursive functions a, b, s : N \u2192 N with b(n) \u0338= 0 for all n \u2208 N and\nrn = (\u22121)s(n) a(n)\nb(n) , n \u2208 N; (1)\ncf. [33, Def. 2.1 and 2.2] for a detailed treatment. A real number x is said to be computable if there exists a computable sequence of rational numbers (rn)n\u2208N and a recursive function \u03c6 such that we have for all M \u2208 N\n|x\u2212 rn| < 2\u2212M (2) for all n \u2265 \u03c6(M). Thus, the computable real x is represented by the pair ((rn)n\u2208N, \u03c6). Note that a computable real number usually has multiple different representations. For example, there are multiple algorithms known for the computation of 1\u03c0 or e\u22121. This form of convergence (2) with a computable control of the approximation error is called effective convergence.\nFor the definition of a computable sequence of computable real numbers we need the following definition as in [31].\nDefinition 1. Let (xnk)n,k\u2208N be a double sequence of real numbers and (xn)n\u2208N a sequence of real numbers such that xnk \u2192 xn for each n as k \u2192 \u221e. We say that xnk \u2192 xn effectively in k and n if there is a recursive function \u03c6 : N\u00d7N \u2192 N such that for all n,N we have k \u2265 \u03c6(n,N) implies\n|xnk \u2212 xn| \u2264 2\u2212N . With this, we get the following definition.\nDefinition 2. A sequence of computable real numbers (xn)n\u2208N is a computable sequence if there is a computable double sequence of rational numbers rnk such that rnk \u2192 xn as k \u2192 \u221e, effectively in k and n.\nThis can alternatively be stated as follows, cf. also [31]. A sequence of computable real numbers (xn)n\u2208N is a computable sequence if there is a computable double sequence of rational numbers (rnk)n,k\u2208N such that\n|rnk \u2212 xn| \u2264 2\u2212k, for all k and n. Note that if a computable sequence of computable real\nnumbers (rn)n\u2208N converges effectively to a limit x, then x is a computable real number, cf. [31]. Furthermore, the set Rc of all computable real numbers is closed under addition, subtraction, multiplication, and division (excluding division by zero). We denote the set of computable real numbers by Rc. Based on this, we define the set of computable probability distributions Pc(X ) as the set of all probability distributions PX \u2208 P(X ) such that PX(x) \u2208 Rc for all x \u2208 X . Further, let CHc(X ;Y) be the set of all computable channels, i.e., for a channel W : X \u2192 P(Y) we have W (\u00b7|x) \u2208 Pc(Y) for every x \u2208 X . Definition 3. A function f : Rc \u2192 Rc is called Borel-Turing computable if there exists an algorithm or Turing machine Tf such that Tf obtains for every x an arbitrary representation ((rn)n\u2208N, \u03c6) for it as input and then computes a representation ((r\u0302n)n\u2208N, \u03c6\u0302) for f(x).\nRemark 1. Borel-Turing computability characterizes exactly the behavior that is expected when functions are simulated\nand evaluated on digital hardware platforms. A program for the computation of f(x) must receive a representation ((rn)n\u2208N, \u03c6) for the input x. Based on this, the program computes the representation ((r\u0302n)n\u2208N, \u03c6\u0302) for f(x). This means that if f(x) needs to be computed with a tolerated approximation error of 1\n2M , then it is sufficient to compute the rational\nnumber r\u0302\u03c6\u0302(M) and the corresponding Turing machine outputs r\u0302\u03c6\u0302(M). For example, this is done and further discussed for the function f(x) = e\u2212x, x \u2208 [0, 1], x \u2208 Rc in Appendix A.\nRemark 2. A practical digital hardware platform and also a Turing machine must stop after finitely many computation steps when computing a value of a function. Thus, the computed value of the function must be a rational number. As a consequence, a Turing machine can only compute rational numbers exactly. However, it is important to note that in information and communication theory, the relevant informationtheoretic functions are in general not exactly computable even for rational channel and system parameters. For example, already for |X | = 2 and rational probability distribution p \u2208 P(X ), p \u0338= ( 1 2 , 1 2 ) , the corresponding binary entropy h2(p) is a transcendental number and therewith not exactly computable. Even if this would be done symbolically with algebraic numbers, the binary entropy would not be computable. As a consequence, already for the binary symmetric channel (BSC) with rational crossover probability \u03f5 \u2208 (0, 12 ) \u2229 Q, the capacity CBSC(\u03f5) = 1 \u2212 h2(\u03f5) is a transcendental number and therewith an exact computation of the capacity is not possible. A proof for this statement is given in Appendix B for completeness.\nThere are also weaker forms of computability including Banach-Mazur computability. In particular, Borel-Turing computability implies Banach-Mazur computability, but not vice versa. For an overview of the logical relations between different notions of computability we refer to [23] and, for example, the introductory textbook [22].\nDefinition 4. A function f : Rc \u2192 Rc is called BanachMazur computable if f maps any given computable sequence (xn)n\u2208N of computable real numbers into a computable sequence (f(xn))n\u2208N of computable real numbers.\nWe further need the concepts of a recursive set and a recursively enumerable set as, for example, defined in [33].\nDefinition 5. A set A \u2282 N is called recursive if there exists a computable function f such that f(x) = 1 if x \u2208 A and f(x) = 0 if x /\u2208 A.\nDefinition 6. A set A \u2282 N is recursively enumerable if there exists a recursive function whose range is exactly A.\nWe have the following properties which will be crucial later for proving the desired results; cf. also [33] for further details.\n\u2022 A is recursive is equivalent to A is recursively enumerable and Ac is recursively enumerable. \u2022 There exist recursively enumerable sets A \u2282 N that are not recursive, i.e., Ac is not recursively enumerable. This means there are no computable, i.e., recursive, functions\n4 f : N \u2192 Ac where for each m \u2208 Ac there exists an x with f(x) = m."
        },
        {
            "heading": "III. SYSTEM MODEL AND BLAHUT-ARIMOTO ALGORITHM",
            "text": "Here, we introduce the communication scenario of interest and discuss the Blahut-Arimoto algorithm."
        },
        {
            "heading": "A. Communication System Model",
            "text": "We consider a point-to-point channel with one transmitter and one receiver which defines the most basic communication scenario. Let X and Y be finite input and output alphabets. Then the channel is given by a stochastic matrix W : X \u2192 P(Y) which we also equivalently write as W \u2208 CH(X ;Y). The corresponding DMC is then given by Wn(yn|xn) := \u220fni=1 W (yi|xi) for all xn \u2208 Xn and yn \u2208 Yn. Definition 7. An (Mn, En, Dn)-code Cn(W ) of blocklength n \u2208 N for the DMC W \u2208 CH(X ;Y) consists of an encoder En : Mn \u2192 Xn at the transmitter with a set of messages Mn := {1, ...,Mn} and a decoder Dn : Yn \u2192 Mn at the receiver.\nThe transmitted codeword needs to be decoded reliably at the receiver. To model this requirement, we define the average probability of error as\ne\u0304n := 1 |Mn| \u2211\nm\u2208Mn \u2211 yn:Dn(yn )\u0338=m Wn(yn|xnm)\nand the maximum probability of error as\nemax,n := max m\u2208Mn \u2211 yn:Dn(yn )\u0338=m Wn(yn|xnm)\nwith xnm = En(m) the codeword for message m \u2208 Mn. Definition 8. A rate R > 0 is called achievable for the DMC W if there exists a sequence (Cn(W ))n\u2208N of (Mn, En, Dn)codes such that we have 1n logMn \u2265 R and e\u0304n \u2264 \u03f5n (or emax,n \u2264 \u03f5n, respectively) with \u03f5n \u2192 0 as n \u2192 \u221e. The capacity C(W ) of the DMC W is given by the supremum of all achievable rates R.\nThe capacity of the DMC has been established and goes back to the seminal work of Shannon [34].\nTheorem 1. The capacity C(W ) of the DMC W under both the average and maximum error criteria is\nC(W ) = max X I(X;Y ) = max p\u2208P(X ) I(p,W ). (3)\nThe capacity of a channel characterizes the maximum transmission rate at which the users can reliably communicate with vanishing probability of error. Note that for DMCs, there is no difference in the capacity whether the average error or the maximum error criterion is considered.\nRemark 3. Capacity expressions such as (3) for the pointto-point channel have further been established for various multi-user communication scenarios, cf. for example [35] and references therein. They all have in common that these are characterized by entropic quantities."
        },
        {
            "heading": "B. Blahut-Arimoto Algorithm",
            "text": "The Blahut-Arimoto algorithm as initially proposed in [3] and [4] tackles the problem of numerically computing the capacity of DMCs with finite input and output alphabets. This algorithm is an alternating optimization algorithm, which has become a standard technique of convex optimization. It has the advantage that it exploits the properties of the mutual information to obtain a simple method to compute the capacity.\nFor a DMC W , the algorithm computes the following two quantities at the n-th iteration:\n1) an input distribution pn = pn(W ) 2) an approximation to the capacity given by the mutual\ninformation I(pn,W ) for this input distribution. This means that the algorithm computes a sequence p0(W ), I(p0,W ), p1(W ), I(p1,W ), ... , pn(W ), I(pn,W ), ... where each element in the sequence is a function of the previous ones except the initial input distribution p0(W ) which is arbitrarily chosen. It is clear that the sequence (pn(W ))n\u2208N of computable input distributions is a function of the initial input distribution p0(W ). The same is true for the sequence (I(pn(W ),W ))n\u2208N.\nFor the sequence p0(W ), p1(W ), ... it is shown in [3\u2013 5] that it always contains a convergent subsequence and that all these convergent subsequences converge to a corresponding optimal input distribution. First, the existence of a limit p\u2217 = p\u2217(W ) \u2208 P(X ) of this subsequence is shown by the Bolzano\u2013Weierstra\u00df theorem, cf. for example [36]. Subsequently, it is shown that this limit must be an optimal input distribution, i.e., p\u2217 \u2208 Popt(W ) with\nPopt(W ) = { p \u2208 P(X ) : I(p,W ) = C(W ) } (4)\nthe set of optimal input distributions. The Bolzano-Weierstra\u00df theorem is a simple technique to show the existence of solutions of certain problems, but, in general, it does not provide an algorithm to compute this solution; in this case the optimal input distribution as a function of the channel.\nFor the capacity, a stopping criterion is provided, i.e., we can choose a certain approximation error 1\n2M > 0, M \u2208 N,\nand the algorithm stops if this tolerated error is satisfied so that the computed value I(pn,W ) is within this error to the actual capacity C(W ), i.e.,\u2223\u2223C(W )\u2212 I(pn,W )\u2223\u2223 < 1\n2M ,\nsee [4, Corollary 1] for a stopping condition for iterations of the capacity estimation.\nOn the other hand, although it has been studied in [3\u20135], a stopping criterion for the optimizer, i.e., the optimal input distribution, has not been given in [3\u20135], i.e., we cannot control when the algorithm should stop for a given maximum tolerable error. Such a stopping criterion could similarly be defined, e.g., when \u2225\u2225p\u2217 \u2212 pn(W )\u2225\u2225\u21131 < 12M (5) is satisfied with p\u2217 \u2208 Popt(W ) a capacity-achieving input distribution and further a computable upper bound for the speed of convergence is given. Surprisingly, to date such a stopping criterion has not been found although it has been studied\n5 <latexit sha1_base64=\"4HGdYQOEIFNXYe2OJ8ZKGlM3VQQ=\">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LC2Cp5KIqMeCF48t2A9oQ9lsJ+3azSbsboQS+gu8eFDEqz/Jm//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ3dzvPKHSPJYPZpqgH9GR5CFn1Fip2RmUq27NXYCsEy8nVcjRGJS/+sOYpRFKwwTVuue5ifEzqgxnAmelfqoxoWxCR9izVNIItZ8tDp2Rc6sMSRgrW9KQhfp7IqOR1tMosJ0RNWO96s3F/7xeasJbP+MySQ1KtlwUpoKYmMy/JkOukBkxtYQyxe2thI2poszYbEo2BG/15XXSvqx517Wr5lW1XsnjKMIZVOACPLiBOtxDA1rAAOEZXuHNeXRenHfnY9lacPKZU/gD5/MHrYOMxA==</latexit> W <latexit sha1_base64=\"VEtun57WPfJ2KQn3mNQxCDG17Hk=\">AAACC3icbVBNS8NAEN3Ur1q/oh69hBahXkoiRT0WvHisYD+gCWGz3bRLN5uwOxFLyN2Lf8WLB0W8+ge8+W/ctjlo64OBx3szzMwLEs4U2Pa3UVpb39jcKm9Xdnb39g/Mw6OuilNJaIfEPJb9ACvKmaAdYMBpP5EURwGnvWByPfN791QqFos7mCbUi/BIsJARDFryzWpS7525TLgRhjHBPGvnfuYCfYAsTiDPteubNbthz2GtEqcgNVSg7Ztf7jAmaUQFEI6VGjh2Al6GJTDCaV5xU0UTTCZ4RAeaChxR5WXzX3LrVCtDK4ylLgHWXP09keFIqWkU6M7ZyWrZm4n/eYMUwisvYyJJgQqyWBSm3ILYmgVjDZmkBPhUE0wk07daZIwlJqDjq+gQnOWXV0n3vOFcNJq3zVqrWsRRRieoiurIQZeohW5QG3UQQY/oGb2iN+PJeDHejY9Fa8koZo7RHxifP0MTmxw=</latexit> p(W ) 2 Popt(W ) <latexit sha1_base64=\"rOTYw8hxSSSPI+COVbyX5Mj75MI=\">AAACHHicbVDLSsNAFJ34rPVVdekmtBTqpiRa1GXBjcsKfUETwmQ6aYdOJmHmRiwhH+LGX3HjQhE3LgT/xknbhbZemOFwzrnce48fc6bAsr6NtfWNza3twk5xd2//4LB0dNxVUSIJ7ZCIR7LvY0U5E7QDDDjtx5Li0Oe0509ucr13T6VikWjDNKZuiEeCBYxg0JRXunBCDONA4knazmq9s2I11r/DxIwnmKetzEsdoA+QRjFkuccrVay6NStzFdgLUEGLanmlT2cYkSSkAgjHSg1sKwY3xRIY4TQrOomiMSYTPKIDDQUOqXLT2XGZWdXM0AwiqZ8Ac8b+7khxqNQ09LUzX1ktazn5nzZIILh2UybiBKgg80FBwk2IzDwpc8gkJcCnGmAimd7VJGMsMQGdZ1GHYC+fvAq653X7st64a1Sa5UUcBXSKyqiGbHSFmugWtVAHEfSIntErejOejBfj3fiYW9eMRc8J+lPG1w+D7aGT</latexit> T(W )\n<latexit sha1_base64=\"4HGdYQOEIFNXYe2OJ8ZKGlM3VQQ=\">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LC2Cp5KIqMeCF48t2A9oQ9lsJ+3azSbsboQS+gu8eFDEqz/Jm//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ3dzvPKHSPJYPZpqgH9GR5CFn1Fip2RmUq27NXYCsEy8nVcjRGJS/+sOYpRFKwwTVuue5ifEzqgxnAmelfqoxoWxCR9izVNIItZ8tDp2Rc6sMSRgrW9KQhfp7IqOR1tMosJ0RNWO96s3F/7xeasJbP+MySQ1KtlwUpoKYmMy/JkOukBkxtYQyxe2thI2poszYbEo2BG/15XXSvqx517Wr5lW1XsnjKMIZVOACPLiBOtxDA1rAAOEZXuHNeXRenHfnY9lacPKZU/gD5/MHrYOMxA==</latexit>\nW <latexit sha1_base64=\"4NT0cPNUq2zaOayk/uRQd4yiK4E=\">AAACHnicbVDLSsNAFJ3UV42vqks3oaXQgpRE6mNZcOOyQh9CE8pkOmmHTiZh5kYsIV/ixl9x40IRwZX+jdPHQlsPDBzOOZe59/gxZwps+9vIra1vbG7lt82d3b39g8LhUUdFiSS0TSIeyTsfK8qZoG1gwOldLCkOfU67/vh66nfvqVQsEi2YxNQL8VCwgBEMWuoXzt0QwyiQeJy2skr3VFTNclzpVl0mZg7BPG1m/dQF+gBpFEOmU9V+oWTX7BmsVeIsSAkt0OwXPt1BRJKQCiAcK9Vz7Bi8FEtghNPMdBNFY0zGeEh7mgocUuWls/Myq6yVgRVEUj8B1kz9PZHiUKlJ6OvkdGW17E3F/7xeAsGVlzIRJ0AFmX8UJNyCyJp2ZQ2YpAT4RBNMJNO7WmSEJSagGzV1Cc7yyaukc1ZzLmr123qpUVzUkUcnqIgqyEGXqIFuUBO1EUGP6Bm9ojfjyXgx3o2PeTRnLGaO0R8YXz/ZjKJB</latexit> T(W, n) <latexit sha1_base64=\"wqcOZDtq9LPRV7IdVmDpd802ES0=\">AAACIXicbVDLSsNAFJ34rPEVdekmtBRakJJI0S4LblxW6AuaUibTSTt0MgkzN2IJ+RU3/oobF4p0J/6M08dCWw8MHM45l7n3+DFnChzny9ja3tnd288dmIdHxyen1tl5W0WJJLRFIh7Jro8V5UzQFjDgtBtLikOf044/uZv7nUcqFYtEE6Yx7Yd4JFjACAYtDayaMIteiGEcSDxJm1mpcyXKZjEudcoeEwuHYJ42skHqAX2CNIoh06nywCo4FWcBe5O4K1JAKzQG1swbRiQJqQDCsVI914mhn2IJjHCamV6iaIzJBI9oT1OBQ6r66eLCzC5qZWgHkdRPgL1Qf0+kOFRqGvo6OV9ZrXtz8T+vl0BQ66dMxAlQQZYfBQm3IbLnddlDJikBPtUEE8n0rjYZY4kJ6FJNXYK7fvImaV9X3JtK9aFaqOdXdeTQJcqjEnLRLaqje9RALUTQM3pF7+jDeDHejE9jtoxuGauZC/QHxvcPWUyi/A==</latexit> n\n<latexit sha1_base64=\"sUvF+HHRq2G5YO5vazRSoR7Sg/E=\">AAACaXicbVHBahsxFNRu0zbdpo3TkhLai4gx2JCY3RDaHnoI9NKjC3Ec8LqLVtbGwlqtkN42MYog35hbfyCX/kS1tg+t0weCYWaent4oV4IbiONfQfhk6+mz59svopc7r17vtvbeXJiq1pQNaSUqfZkTwwSXbAgcBLtUmpEyF2yUz782+ugn04ZX8hwWik1KciV5wSkBT2Wtu46MOmlJYFZoMrfnrjs6kr2oo7qjXsrlUqFE2IHLbArsBmylwHlXL1KZ3HBQvLLgaw4z7NLb5pbjxnfru5kQWeLwF5z6UdQmzp78kC5rteN+vCz8GCRr0EbrGmSt+3Ra0bpkEqggxoyTWMHEEg2cCuaitDZMETonV2zsoSQlMxO7TMrhjmemuKi0PxLwkv27w5LSmEWZe2ezl9nUGvJ/2riG4vPEcqlqYJKuBhW1wFDhJnY85ZpREAsPCNXcvxXTGfE5gP+cyIeQbK78GFyc9JOP/dPvp+2zw3Uc2+gDOkRdlKBP6Ax9QwM0RBQ9BDvBfvAu+B3uhQfh+5U1DNY9b9E/Fbb/AEeIuSw=</latexit>\npn 2 Pc with kp(W ) pnk`1 < 1\n2n\n<latexit sha1_base64=\"wqcOZDtq9LPRV7IdVmDpd802ES0=\">AAACIXicbVDLSsNAFJ34rPEVdekmtBRakJJI0S4LblxW6AuaUibTSTt0MgkzN2IJ+RU3/oobF4p0J/6M08dCWw8MHM45l7n3+DFnChzny9ja3tnd288dmIdHxyen1tl5W0WJJLRFIh7Jro8V5UzQFjDgtBtLikOf044/uZv7nUcqFYtEE6Yx7Yd4JFjACAYtDayaMIteiGEcSDxJm1mpcyXKZjEudcoeEwuHYJ42skHqAX2CNIoh06nywCo4FWcBe5O4K1JAKzQG1swbRiQJqQDCsVI914mhn2IJjHCamV6iaIzJBI9oT1OBQ6r66eLCzC5qZWgHkdRPgL1Qf0+kOFRqGvo6OV9ZrXtz8T+vl0BQ66dMxAlQQZYfBQm3IbLnddlDJikBPtUEE8n0rjYZY4kJ6FJNXYK7fvImaV9X3JtK9aFaqOdXdeTQJcqjEnLRLaqje9RALUTQM3pF7+jDeDHejE9jtoxuGauZC/QHxvcPWUyi/A==</latexit>\nn <latexit sha1_base64=\"x4NMfTfMnA4fFhyOFwlCOjtby7M=\">AAACaXicbVFNbxMxEPUuX2UpkIJACC5Wo0jpgWi3qloOHCpx4RikpqmUDSuvM9tY8XpX9ixt5FriN/bWP8CFP4E3yQFSRrL09N4bj+c5r6UwGMd3Qfjg4aPHT3aeRs92n7942dl7dW6qRnMY8UpW+iJnBqRQMEKBEi5qDazMJYzzxZdWH/8AbUSlznBZw7Rkl0oUgjP0VNb52VNRWjKcF5ot7JnLxn11EPXq/vggFWqlcCbt0GU2RbhGW9XonFe9J1NbFk7XHnolcE5detNe87H13fh2kDJLHP1MUz+L28TZw+/KZZ1uPIhXRe+DZAO6ZFPDrHObzirelKCQS2bMJIlrnFqmUXAJLkobAzXjC3YJEw8VK8FM7SopR3uemdGi0v4opCv27w7LSmOWZe6d7V5mW2vJ/2mTBotPUytU3SAovh5UNJJiRdvY6Uxo4CiXHjCuhX8r5XPmc0D/OZEPIdle+T44Pxwkx4Ojb0fd0/1NHDvkA9knfZKQE3JKvpIhGRFOfgW7wZvgbfA73Avfhe/X1jDY9Lwm/1TY/QO3A7lf</latexit> TW (n)\n<latexit sha1_base64=\"sUvF+HHRq2G5YO5vazRSoR7Sg/E=\">AAACaXicbVHBahsxFNRu0zbdpo3TkhLai4gx2JCY3RDaHnoI9NKjC3Ec8LqLVtbGwlqtkN42MYog35hbfyCX/kS1tg+t0weCYWaent4oV4IbiONfQfhk6+mz59svopc7r17vtvbeXJiq1pQNaSUqfZkTwwSXbAgcBLtUmpEyF2yUz782+ugn04ZX8hwWik1KciV5wSkBT2Wtu46MOmlJYFZoMrfnrjs6kr2oo7qjXsrlUqFE2IHLbArsBmylwHlXL1KZ3HBQvLLgaw4z7NLb5pbjxnfru5kQWeLwF5z6UdQmzp78kC5rteN+vCz8GCRr0EbrGmSt+3Ra0bpkEqggxoyTWMHEEg2cCuaitDZMETonV2zsoSQlMxO7TMrhjmemuKi0PxLwkv27w5LSmEWZe2ezl9nUGvJ/2riG4vPEcqlqYJKuBhW1wFDhJnY85ZpREAsPCNXcvxXTGfE5gP+cyIeQbK78GFyc9JOP/dPvp+2zw3Uc2+gDOkRdlKBP6Ax9QwM0RBQ9BDvBfvAu+B3uhQfh+5U1DNY9b9E/Fbb/AEeIuSw=</latexit>\npn 2 Pc with kp(W ) pnk`1 < 1\n2n\nFig. 1. Computation of the optimal input distribution. The Turing machine T obtains a description of the channel W as input and outputs a description of an optimal input distribution p(W ) (as an implementation of the function G).\nextensively and further has played a crucial role in various patents such as [17] and [18]. In particular, our results even show that such a stopping criterion cannot exist! We will come back to this issue in more detail in the following subsection. We will also show that the optimization over possible starting points, i.e., the computable choice of a suitable starting point for the iterating algorithm depending on the input channel W does not yield a solution, i.e., a computable stopping criterion such as (5).\nIn fact, both seminal papers [3] and [4] do not only aim at computing the capacity, but also propose an algorithm for the computation of a sequence of input distributions pn \u2208 P(X ) and study the convergence to a maximum p\u2217 \u2208 Popt(W ) for a fixed channel W , i.e.,\nI(p\u2217,W ) = C(W ) = max p\u2208P(X ) I(p,W ). (6)\nThey state that a suitable subsequence (pnl)l\u2208N converges to an optimizer, but without providing a stopping criterion. That this is problematic has been realized afterwards by Csisza\u0301r who explicitly states in [5] that there is no stopping criterion for the computation of the optimizer. In particular, Arimoto considered the problem of estimating the convergence speed for the calculation of the input distribution. However, only under certain conditions on the input distribution was he able to show monotonicity [4, Theorem 2] and properties of the rate of convergence [4, Theorem 3]. From an algorithmic point of view, these results are not useful, since i) [4, Theorem 2] shows only monotonicity, ii) [4, Theorem 3] shows only the existence of certain parameters, but no explicit construction of them so that the result is non-constructive, and iii) there is no algorithm known to test these conditions, i.e., it is not verifiable whether [4, Theorem 2] and [4, Theorem 3] are applicable. Csisza\u0301r studied in [5] the question of understanding and calculating the convergence speed of the input distribution. However, he was only able to show convergence but not to calculate the rate of convergence. Accordingly, the corresponding proof of existence is non-constructive."
        },
        {
            "heading": "IV. COMPUTABILITY OF AN OPTIMAL INPUT DISTRIBUTION",
            "text": "The capacity C(W ) = maxp\u2208P(X ) I(p,W ) of the DMC W , cf. (3), is given by a maximization problem, where the mutual information I(p,W ) is maximized over all possible input distributions p \u2208 P(X ). Since I(p,W ) is continuous in (p,W ), concave in the input distribution p, and convex in the channel W , there exists for every channel W \u2208 CH(X ;Y) at least one optimal input distribution p\u2217(W ) \u2208 Popt(W ). Note that the set Popt(W ) is a convex set for each channel W . Now, we can choose for every channel W \u2208 CH(X ;Y) such\na capacity-achieving input distribution p\u2217 = p\u2217(W ). Then F (W ) = p\u2217(W ) is a mathematically well defined function of the form\nF : CH(X ;Y) \u2192 P(X ) (7)\nwhich maps every channel to an optimal input distribution for this channel. We call F an optimal assignment function and denote by Mopt(X ;Y) the set of all these functions. The set Mopt(X ;Y) is of crucial practical importance and, in particular, it would be interesting to find functions F \u2208 Mopt(X ;Y) that can be described algorithmically. Note that in general, this function F does not need to be unique and there can be infinitely many such functions. Further, for computable channels W \u2208 CHc(X ;Y) we always have F (W ) \u2208 Pc(X ). Remark 4. From a practical point of view it is interesting to understand whether or not there exists a function F with F (W ) \u2208 Popt(W ) for all W \u2208 CHc(X ;Y) that is Borel-Turing computable. Since exactly in this case there is an algorithm (or Turing machine) that takes the channel W \u2208 CHc(X ;Y) as an input and computes a corresponding capacity-achieving input distribution F (W ) = p\u2217(W ) \u2208 Popt(W ). It is clear that we consider only computable channels W \u2208 CHc(X ;Y) as inputs for the Turing machine as it can operate work only with such inputs. More specifically, for W \u2208 CHc(X ;Y) such a Turing machine takes an arbitrary representation of W as input, i.e., W (y|x) is given by a representation ((rn(x, y))n\u2208N, \u03c6(x,y)) for all x \u2208 X , y \u2208 Y . This means that for all x \u2208 X , y \u2208 Y we have for all N \u2208 N\u2223\u2223W (y|x)\u2212 rn(x, y)\u2223\u2223 < 1\n2N\nfor all n \u2265 \u03c6(x,y)(N). As a result, the Turing machine computes a representation of F (W ) \u2208 Popt(W ), i.e., ((r\u2217n(x))n\u2208N, \u03c6\n(\u2217,x)) is a representation of p\u2217(x), x \u2208 X , with F (W ) = p\u2217 = ( p\u2217(1), . . . , p\u2217(|X |) ) . Thus, for all x \u2208 X it holds that for all N \u2208 N\u2223\u2223p\u2217(x)\u2212 r\u2217n(x)\u2223\u2223 < 12N (8) for all n \u2265 \u03c6(\u2217,x)(N).\nAccordingly, in the following we will address this question in detail and study whether or not it is possible to find such a Turing machine that computes a capacity-achieving input distribution for a given channel.\nQuestion 1: Let X and Y be finite input and output alphabets. Is there an algorithm (or Turing machine) T that takes an arbitrary representation of W \u2208 CHc(X ;Y) as an input and computes a description of p\u2217(W ) \u2208 Popt(W )?\nRemark 5. Question 1 is visualized in Fig. 1 and formalizes exactly what we would require from an algorithmic construction of optimal input distributions on digital hardware platforms. From a practical point of view, a simulation on digital hardware must stop after a finite number of computations. Usually, it should stop if for W \u2208 CHc(X ;Y) the computed\n6 approximation of an input distribution p\u2217(W ) \u2208 Popt(W ) satisfies a given but fixed approximation error. This constraint on the approximation error is exactly modeled by the representation of p\u2217(W ). If the representation ((r\u2217n(x))n\u2208N, \u03c6\n(\u2217,x)), x \u2208 X , of p\u2217(W ) has been computed for a tolerated error 1\n2N and r being the smallest natural number such that 2r > |X |, then the approximation process can be stopped after N\u2217 = maxx\u2208X \u03c6\n(\u2217,x)(N + r) steps, since we have\u2211 x\u2208X \u2223\u2223p\u2217(x)\u2212 r\u2217N\u2217(x)\u2223\u2223 < \u2211 x\u2208X 1 2N+r = |X | 2N+r < 1 2N .\nThis would provide us a stopping criterion as discussed in Section III-B for the Blahut-Arimoto algorithm.\nNow we can state the following result which provides a negative answer to Question 1 above.\nTheorem 2. Let X and Y be arbitrary but finite alphabets with |X | \u2265 3 and |Y| \u2265 2. Then there is no function F \u2208 Mopt(X ;Y) that is Banach-Mazur computable.\nProof: The proof is given below in Section IV-B. From this, we can immediately conclude the following.\nCorollary 1. There is no Turing machine T that takes a channel W \u2208 CHc(X ;Y) as an input and computes an optimal input distribution p \u2208 Popt(W ) for this channel.\nProof: If such a Turing machine would exist, then the corresponding function F would be Banach-Mazur computable. This is a contradiction to Theorem 2 so that such a Turing machine cannot exist."
        },
        {
            "heading": "A. Preliminary Considerations",
            "text": "Before we present the proof of Theorem 2, we first need to define and discuss specific channels and their optimal input distributions.\nLet X and Y be arbitrary but finite alphabets with |X | = 3 and |Y| = 2. We define the channel\nW\u2217 = ( 1 0 0 0 1 1 ) (9)\nand further consider the channels\nW1,\u00b5 = ( 1 0 \u00b5 0 1 1\u2212 \u00b5 ) and W2,\u00b5 = ( 1 \u00b5 0 0 1\u2212 \u00b5 1 ) for \u00b5 \u2208 (0, 1). We define the distance between two channels W1,W2 \u2208 CH(X ;Y) based on the total variation distance as\nD(W1,W2) := max x\u2208X \u2211 y\u2208Y \u2223\u2223W1(y|x)\u2212W2(y|x)\u2223\u2223 and observe that\nlim \u00b5\u21920 D(W\u2217,W1,\u00b5) = lim \u00b5\u21920 D(W\u2217,W2,\u00b5) = 0.\nWe consider the set P1 = { p = (p1, p2, p3) \u2208 P(X ) : p1 = 1\n2 and p2 + p3 =\n1\n2\n} .\nThen we have\nmax p\u2208P(X ) I(p,W\u2217) = 1 = I(p\u2217,W\u2217)\nwith p\u2217 \u2208 P1 arbitrary. This means P1 is the set of all maximizing input distributions for the channel W\u2217, since\nI(p,W\u2217) = p1 \u00b7 1 \u00b7 log 1 \u00b7 p1 p1 \u00b7 p1 + p2 \u00b7 1 \u00b7 log 1 \u00b7 p2 p2(p2 + p3)\n+ p3 \u00b7 1 \u00b7 log 1 \u00b7 p3\np3(p2 + p3)\n= p1 log 1\np1 + (p2 + p3) log\n1\np2 + p3\n= p1 log 1\np1 + (1\u2212 p1) log\n1\n1\u2212 p1 = h2(p1)\nwhere h2(\u00b7) is the binary entropy function. This means that for all p with p1 \u2208 [0, 1]\\{ 12} we always have\nI(p,W\u2217) < 1 = h2(p\u2217) = I(p\u2217,W\u2217)\nwith p\u2217 \u2208 P1 arbitrary as defined above. Next, we define the channel\nW\u0302 = ( 1 0 1 0 1 0 ) and for \u00b5 \u2208 [0, 1] we have\nW1,\u00b5 = (1\u2212 \u00b5)W\u2217 + \u00b5W\u0302 .\nThen for p \u2208 P(X ) arbitrary, we always have\nI(p,W1,\u00b5) \u2264 (1\u2212 \u00b5)I(p,W\u2217) + \u00b5I(p, W\u0302 ).\nWe now consider the set P2 = { p = (p1, p2, p3) \u2208 P(X ) : p2 = 1\n2 and p1 + p3 =\n1\n2\n} .\nSimilarly, we can show for the channel W\u0302 that\nmax p\u2208P(X ) I(p, W\u0302 ) = 1 = I(p\u0302, W\u0302 )\nwith p\u0302 \u2208 P2 arbitrary. Further, we have\nP1 \u2229 P2 =  121 2 0  . For p \u2208 P(X ), p \u0338= ( 12 , 12 , 0), we must have\nI(p,W\u2217) < 1 or I(p, W\u0302 ) < 1.\nThus, for arbitrary p \u2208 P(X ) with p \u2208 P(X ), p \u0338= ( 12 , 12 , 0) we always have\nI(p,W1,\u00b5) \u2264 (1\u2212 \u00b5)I(p,W\u2217) + \u00b5I(p, W\u0302 ) < (1\u2212 \u00b5) + \u00b5 = 1.\nFor\np (1) \u2217 =  121 2 0  we have\nI(p (1) \u2217 ,W1,\u00b5) = 1\n7 for \u00b5 \u2208 [0, 1]. Consequently, for channel W1,\u00b5 for \u00b5 \u2208 (0, 1) there is exactly one optimal input distribution, i.e., Popt(W1,\u00b5) = {p(1)\u2217 }.\nSimilarly, one can show that for channel W2,\u00b5 for \u00b5 \u2208 (0, 1) there is exactly one optimal input distribution, i.e., Popt(W2,\u00b5) = {p(2)\u2217 } given by\np (2) \u2217 =  120 1 2  ."
        },
        {
            "heading": "B. Non-Computability of an Optimal Input Distribution",
            "text": "Now we are in the position to prove Theorem 2.\nProof of Theorem 2: We start with the case |X | = 3 and |Y| = 2 and prove the desired result by contradiction. For this purpose, we assume that there exists a function F \u2208 Mopt(X ;Y) that is Banach-Mazur computable. This means that every computable sequence (Wn)n\u2208N of computable channels Wn \u2208 CHc(X ;Y) is mapped to a computable sequence (pn)n\u2208N of computable input distributions pn \u2208 Pc(X ) for all n \u2208 N. For the set of optimal input distributions (4) we always have Popt(W ) \u0338= \u2205. Further, let F be an arbitrary function as in (7) and\nF (W ) \u2208 Popt(W ),\ni.e., F maps every channel to an optimal input distribution for this channel.\nFor our previously defined channel W\u2217, cf. (9), we therefore have\nF (W\u2217) \u2208 Popt(W\u2217) = P1.\nFor \u00b5 \u2208 (0, 1), we further have\nF (W1,\u00b5) = p (1) \u2217\nsince Popt(W1,\u00b5) = {p(1)\u2217 } for \u00b5 \u2208 (0, 1). For \u00b5 \u2208 (0, 1) we also have\nF (W2,\u00b5) = p (2) \u2217\nsince Popt(W2,\u00b5) = {p(2)\u2217 } for \u00b5 \u2208 (0, 1). We have p(1)\u2217 \u2208 P1, p (2) \u2217 \u2208 P1, and \u2225p(1)\u2217 \u2212 p(2)\u2217 \u2225 = 1. With this, we obtain\n1 = \u2225\u2225p(1)\u2217 \u2212 p(2)\u2217 \u2225\u2225\u21131\n= \u2225\u2225p(1)\u2217 \u2212 F (W\u2217) + F (W\u2217)\u2212 p(2)\u2217 \u2225\u2225\u21131\n\u2264 \u2225\u2225p(1)\u2217 \u2212 F (W\u2217)\u2225\u2225\u21131 + \u2225\u2225F (W\u2217)\u2212 p(2)\u2217 \u2225\u2225\u21131\n\u2264 2max {\u2225\u2225p(1)\u2217 \u2212 F (W\u2217)\u2225\u2225\u21131 ,\u2225\u2225p(2)\u2217 \u2212 F (W\u2217)\u2225\u2225\u21131}\nso that max {\u2225\u2225p(1)\u2217 \u2212 F (W\u2217)\u2225\u2225\u21131 ,\u2225\u2225p(2)\u2217 \u2212 F (W\u2217)\u2225\u2225\u21131} \u2265 12 .\nLet A \u2282 N be a recursively enumerable set that is not recursive, cf. Section II. Let g : N \u2192 A be a computable function where for each m \u2208 A there exists a k with g(k) = m and g(k1) \u0338= g(k2) for k1 \u0338= k2.\nLet TA be a Turing machine that accepts exactly the set A, i.e., TA stops for input k \u2208 N if and only if k \u2208 A. Otherwise,\nTA runs forever and does not stop. For k \u2208 N and n \u2208 N, we define the function\nq(k, n)= { 2s+2 if TA stops for input k after s \u2264 n steps 2n+2 if TA does not stop for input k after n steps.\nNote that q : N\u00d7 N \u2192 N is a computable function. Let k, n \u2208 N be arbitrary. If k is odd, i.e., k \u2208 O with O \u2282 N the set of all odd numbers, then we have k = 2l \u2212 1, l \u2265 1, l \u2208 N, and we consider the channel Wk,n := W1, 1\nq(l,n) .\nIf k is even, i.e., k \u2208 E with E \u2282 N the set of all even numbers, then we have k = 2l, l \u2265 1, l \u2208 N, and we consider Wk,n := W2, 1\nq(l,n) . Note that in both cases, l is a function of\nk. With this, (Wk,n)k\u2208N,n\u2208N is a computable double sequence. Now, we define the following sequence (W \u2217k )k\u2208N. We will later show in the proof that (W \u2217k )k\u2208N is even a computable sequence of computable channels. For k \u2208 N, k is either odd or even:\n1) k \u2208 O odd, i.e., k = 2l\u2212 1, l \u2265 1, l \u2208 N. If l \u2208 A, then we set W \u2217k := W1, 1\n2s+2 with TA has stopped for input\nl after s steps. If l /\u2208 A, then we set W \u2217k := W\u2217. 2) k \u2208 E even, i.e., k = 2l, l \u2265 1, l \u2208 N. If l \u2208 A, then\nwe set W \u2217k := W2, 1 2s+2 with TA has stopped for input l after s steps. If l /\u2208 A, then we set W \u2217k := W\u2217.\nNext, we show that the double sequence (Wk,n)k\u2208N,n\u2208N converges effectively to the sequence (W \u2217k )k\u2208N. This implies that (W \u2217k )k\u2208N is a computable sequence of computable channels. Further, we show that for all k \u2208 N and n \u2208 N we have\nD(W \u2217k ,Wk,n) < 1\n2n (10)\nso that (Wk,n)k\u2208N,n\u2208N indeed converges effectively. Let k \u2208 N be arbitrary. We first consider the case k \u2208 O, i.e., k = 2l \u2212 1, l \u2265 1, l \u2208 N. If l /\u2208 A, we have W \u2217k = W\u2217 so that\nD ( W \u2217k ,Wk,n ) = D ( W\u2217,W1, 1\n2n+2\n) = 2\n2n+2 <\n1\n2n\nwhich already shows (10) for this case. In the other case, if l \u2208 A, we have W \u2217k = W1, 1\n2s+2 , where s is the actual number\nof steps after which the Turing machine TA stopped for input l. Now, let n \u2208 N be arbitrary. For n \u2265 s we have\nWk,n = W2l\u22121,n = W1, 1 2s+2\n= W \u2217k\nso that D(W \u2217k ,Wk,n) = 0.\nFor n < s we have Wk,n = W1, 1 2n+2 so that\nD(W \u2217k ,Wk,n) = D(W1, 1 2s+2 ,W1, 1 2n+2 ) = \u2223\u2223\u2223(1\u2212 1\n2s+2\n) \u2212 ( 1\u2212 1\n2n+2 )\u2223\u2223\u2223+ \u2223\u2223\u2223 1 2s+2 \u2212 1 2n+2 \u2223\u2223\u2223 = 2 \u2223\u2223\u2223 1 2n+2 \u2212 1 2s+2 \u2223\u2223\u2223 < 2 1 2n+2 < 1 2n\nwhich shows (10) for this case as well. The proof for even numbers k \u2208 E follows as above for odd numbers k \u2208 O and is omitted for brevity. As a consequence, (W \u2217k )k\u2208N is a computable sequence of computable channels. If the function F is Banach-Mazur computable, then the\n8 sequence (F (W \u2217k ))k\u2208N must be a computable sequence of computable input distributions in Pc(X ).\nWe consider the computable sequence( F (W \u2217k )\u2212 F (W\u2217) ) k\u2208N (11)\nand the following Turing machine: For l \u2208 N we start two Turing machines in parallel.\nThe first Turing machine T1 is given by T1 = TA, i.e., for input l it runs the algorithm for TA step by step.\nThe second Turing machine is given as follows. We compute n = 2l\u22121 and also F (W \u22172l\u22121)\u2212F (W\u2217) which is possible since (11) is a computable sequence. We compute \u2225F (W \u22172l\u22121) \u2212 F (W\u2217)\u2225\u21131 . In parallel, we further compute n = 2l and also F (W \u22172l)\u2212F (W\u2217) and \u2225F (W \u22172l)\u2212F (W\u2217)\u2225\u21131 . We now compute\nrl = max { \u2225F (W \u22172l\u22121)\u2212F (W\u2217)\u2225\u21131 , \u2225F (W \u22172l)\u2212F (W\u2217)\u2225\u21131 } .\nWe now use the Turing machine T< 14 from [31, page 14] and test if rl < 14 is true. Our second Turing machine T2 stops if and only if the Turing machine T< 14 stops for input rl.\nWe start both Turing machines in parallel in such a way that the computing steps are synchronous. Whenever the first Turing machine stops, we set l \u2208 A. Otherwise, if the second Turing machine stops, we set l /\u2208 A. The first Turing machine stops if and only if l \u2208 A. The second Turing machine stops if and only if rl < 14 . As for l \u2208 A we have rl \u2265 12 and for l /\u2208 A we have rl = 0, the second Turing machine stops if and only if l /\u2208 A.\nWith this, we have obtained a Turing machine T\u2217 that always decides for l \u2208 N whether l \u2208 A or l /\u2208 A. This means that A must be a recursive set which is a contradiction to our initial assumption. Thus, the function F is not BanachMazur computable which proves the desired result for the case |X | = 3 and |Y| = 2.\nFinally, we outline how the proof extends to arbitrary |X | \u2265 3 and |Y| \u2265 2. In this case, for the set CHc(X ;Y) we consider the subset CHc(X ;Y) of all channels W \u2208 CHc(X ;Y) and choose an arbitrary channel W \u2208 CHc(X1;Y1) with |X1| = 3 and |Y1| = 2. We set\nW (y|x) = { W (y|x) y \u2208 {1, 2}x \u2208 {1, 2, 3} 0 y \u2208 {3, ..., |Y|}x \u2208 {1, 2, 3} (12)\nas well as\nW (\u00b7|x) = W (\u00b7|1) x \u2208 {4, ..., |X |}. (13)\nAs above, we assume that F \u2208 Mopt(X ;Y) is a BanachMazur computable function that computes an optimal input distribution for the set CHc(X ;Y). Then we always have F (W ) \u2208 P(X ) for W \u2208 CHc(X ;Y). For W \u2208 CHc(X1;Y1) we can immediately compute an optimal input distribution p\u22171 \u2208 Popt(W ) as follows. We take W which is constructed as above in (12)-(13). Let W \u2208 CHc(X ;Y) and consider p(W ) := F (W ). With\np(W ) =  p1(W )... p|X |(W ) \nwe set\np\u22171(W ) := p1(W ) + |X |\u2211 x=4 px(W ) (14)\nand\np\u22172(W ) := p2(W ), (15) p\u22173(W ) := p3(W ). (16)\nFor W \u2208 CH(X1;Y1) we consider the mapping\nG(W ) = p\u22171(W )p\u22172(W ) p\u22173(W )  which is defined by (14)-(16). The mapping G is a composition of the following components: 1) it constructs from W the channel W according to (12)-(13); 2) it applies the function F on W ; and 3) it applies the operations (14)-(16) on F . The construction (12)-(13) and also the operations (14)-(16) are Borel-Turing computable. Since F is further Banach-Mazur computable by assumption, the mapping G must be BanachMazur computable as well. However, we have p\u2217 \u2208 Popt(W ). This is a contradiction since for |X1| = 3 and |Y1| = 2 all functions G \u2208 Mopt(X1;Y1) can not be Banach-Mazur computable. This proves the general case and therewith completes the proof of Theorem 2.\nBy inspection of the proof of Theorem 2, we observe that we have shown a stronger statement than was initially required. More specifically, we even have shown the following result:\nTheorem 3. Let X and Y be arbitrary finite alphabets. Then there exists a computable sequence (Wn)n\u2208N of Borel-Turing computable channels, where every channel Wn, n \u2208 N has only rational entries, such that for all G \u2208 Mopt(X ;Y) it always holds that (G(Wn))n\u2208N is not a Borel-Turing computable sequence.\nSome remarks are in order. We actually have a universal non-Banach-Mazur computability here. To show that a specific function G \u2208 Mopt(X ;Y) is not Banach-Mazur computable, we have to show that for this function G there is a computable sequence (Wn)n\u2208N such that (G(Wn))n\u2208N is not a computable sequence of computable input distributions in P(X ). In general, the sequence (Wn)n\u2208N depends on the function G. From a practical point of view, it could be the case that for an arbitrary given computable sequence (Wn)n\u2208N of computable channels (which contain all practically relevant channels for certain application) there is a G such that G((Wn))n\u2208N becomes a computable sequence of output distributions (p(Wn))n\u2208N. However, we have shown that this possibility for the optimization of the mutual information is not possible, since Theorem 3 excludes such a behavior since the sequence (Wn)n\u2208N in Theorem 3 is a universal sequence such that for all G \u2208 Mopt(X ;Y), the sequence (G(Wn))n\u2208N is not a computable sequence.\nAs discussed in the previous Section IV, we must not necessarily have G(W ) \u2208 Pc(X ) for W \u2208 CHc(X ;Y). In particular, already on the interval [0, 1] there are computable continuous functions f such that for all optimizers x\u2217 \u2208 [0, 1]\n9 we have x\u2217 /\u2208 Rc. However, we know that such a behavior cannot occur for the mutual information since for |X | \u2265 2 and W \u2208 CHc(X ;Y) arbitrary we have the following reasoning: Popt(W ) is a non-empty set and if there is only one element in Popt(W ), i.e., |Popt(W )| = 1, then we know from [31, Sec. 0.6] that for the optimal input distribution p\u2217 \u2208 Pc(X ) is satisfied. On the other hand, if Popt(W ) contains more than one element, i.e., |Popt(W )| \u2265 2, then Popt(W ) is a convex set, i.e., for p(1), p(2) \u2208 Popt(W ) with p(1) \u0338= p(2) we also have p\u03bb := (1\u2212 \u03bb)p(1) + \u03bbp(2) \u2208 Popt(W ) for \u03bb \u2208 [0, 1].\nNow let i(1) be an arbitrary index of X with p(1)(i(1)) \u0338= p(2)(i(1)). For p\u03bb(i(1)) = (1\u2212 \u03bb)p(1)(i(1)) + \u03bbp(2)(i(1)) we always have\np\u03bb(i(1)) \u2208 [a1, a1]\nwith a1 < a 1 and a1 = min { p(1)(i(1)), p(2)(i(1)) } ,\na1 = max { p(1)(i(1)), p(2)(i(1)) } .\nThis implies the existence of a \u03bb\u0302 \u2208 (0, 1) with p\u03bb\u0302(i(1)) \u2208 Rc. Next, we consider Xi = X\\{i(1)} and M1 = {p \u2208 P(X ) : p(i(1)) = p\u03bb\u0302(i(1))} and study the relation\nmax p\u2208M1 I(p,W ) = max p\u2208P(X ) I(p,W ).\nNow, let Popt(W,M1) be the set of all p\u2217M1 with\nI(p\u2217,W ) = max p\u2208M1 I(p,W ).\nIf Popt(W,M1) consists of only one element, then we must have p\u2217 \u2208 Pc(X ). If Popt(W,M1) consists of more than one element, then the set Popt(W,M1) must be convex. In this case, we find another index i(2) with i(2) \u0338= i(1) such that for i(2) there is a p\u0302\u2217 \u2208 Popt(w,M1) with p\u0302\u2217 \u2208 Popt(W,M1) and p\u0302\u2217(i(2)) \u2208 Rc. This procedure can be continued iteratively such that the index set is reduced by one element in each iteration. After finitely many steps, we obtain a p\u0303 \u2208 Popt(W ) with p\u0303 \u2208 Pc(X ).\nIt is clear that this procedure allows us to show the existence of such a p\u0303 only, but that p\u0303 cannot be constructed algorithmically. It is interesting to note that this allows us to show the existence of such a function G with G(W ) = Popt(W ) for all W \u2208 CHc(X ;Y) such that we always have G(W ) \u2208 Pc(X ) for W \u2208 CHc(X ;Y) is true. Accordingly, for W \u2208 CHc(X ;Y) it is impossible that Popt(W ) contains only non-Borel-Turing computable input distributions.\nFinally, we want to emphasize that it has recently been shown for other information theoretic problems arising in prediction theory that for simple spectral power densities the corresponding prediction filters and Wiener filter, accordingly, for Borel-Turing computable frequences have nonBorel-Turing computable values [37]. In contrast to this, such a behavior cannot occur for the optimal input distribution in our case."
        },
        {
            "heading": "C. Discussion",
            "text": "Some discussion is in order.\nRemark 6. This shows that such a Turing machine cannot exist providing a negative answer to Question 1 above. As a consequence, this means also that a function F as in (7) cannot exist for which F (W ) can \u201ceasily\u201d be computed for W . In particular, this excludes the possibility of finding a function F that provides a \u201cclosed form solution\u201d, since this would be then Turing computable and therewith algorithmically constructable, cf. also [38, 39].\nRemark 7. It is of interest to discuss the Blahut-Arimoto algorithm taking the result in Theorem 2 into account. This algorithm computes for each channel W \u2208 CHc(X ;Y) a sequence (pn(W ))n\u2208N of input distributions such that all convergent subsequences always converge to a corresponding optimizer p\u2217(W ) \u2208 Popt(W ). The second crucial ingredient of the representation of p\u2217(W ) is a stopping criterion for the computation of the sequence (pn)n\u2208N for a given approximation error 1\n2N . Such a stopping criterion is not\nprovided by the Blahut-Arimoto algorithm. This was already criticized by Csisza\u0301r in [5]. Our Theorem 2 shows now that such a computable stopping criterion as a function of the representation of the channel cannot exist.\nRemark 8. Theorem 2 further shows that the convergence behavior of the Blahut-Arimoto algorithm cannot be improved by optimizing the starting point of the algorithm, i.e., by choosing the starting point in the form of a Turing computable pre-processing such that it results in a computable stopping criterion for the algorithm. As a consequence, there is no Turing computable function G0 : CHc(X ;Y) \u2192 Popt(W ) with p0(W ) = G0(W ) such that a Turing computable stopping criterion would exist for the Blahut-Arimoto algorithm with p0(W ) as initialization.\nThe statement on the impossibility of the algorithmic solvability is closely connected to the underlying hardware platform (Turing machine) and therewith, equivalently, to the admissible programming languages (Turing complete) and also the admissible signal processing operations. Note that for other computing platforms (such as neuromorphic or quantum computing platforms) this statement need not be the case. However, whenever simulations are done in the broad area of information theory, communication theory, or signal processing, these are done on digital hardware platforms for which Turing machines provide the underlying computing framework.\nRemark 9. It is helpful and very interesting to gain further intuition and insight into the non-computability by Turing machines and other potential computing platforms. For example, it has been a long-standing open problem to describe the roots of polynomials by radicals as a function of the coefficients of the polynomial. To this end, Galois showed this is not possible in general for polynomials of the order 5 or higher [40]. This means that the roots of polynomials of order 5 or higher cannot be expressed as a \u201cclosed form solution\u201d by radicals; see [40] and further discussions in [38, 39]. On the other hand, from the complex analysis there are algorithms known that are able to approximate these roots. This shows that the \u201ccomputing theory of radicals\u201d is not sufficient for the computation of the roots of polynomials of order 5 or higher, but other techniques\n10 <latexit sha1_base64=\"4HGdYQOEIFNXYe2OJ8ZKGlM3VQQ=\">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LC2Cp5KIqMeCF48t2A9oQ9lsJ+3azSbsboQS+gu8eFDEqz/Jm//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ3dzvPKHSPJYPZpqgH9GR5CFn1Fip2RmUq27NXYCsEy8nVcjRGJS/+sOYpRFKwwTVuue5ifEzqgxnAmelfqoxoWxCR9izVNIItZ8tDp2Rc6sMSRgrW9KQhfp7IqOR1tMosJ0RNWO96s3F/7xeasJbP+MySQ1KtlwUpoKYmMy/JkOukBkxtYQyxe2thI2poszYbEo2BG/15XXSvqx517Wr5lW1XsnjKMIZVOACPLiBOtxDA1rAAOEZXuHNeXRenHfnY9lacPKZU/gD5/MHrYOMxA==</latexit>W <latexit sha1_base64=\"VEtun57WPfJ2KQn3mNQxCDG17Hk=\">AAACC3icbVBNS8NAEN3Ur1q/oh69hBahXkoiRT0WvHisYD+gCWGz3bRLN5uwOxFLyN2Lf8WLB0W8+ge8+W/ctjlo64OBx3szzMwLEs4U2Pa3UVpb39jcKm9Xdnb39g/Mw6OuilNJaIfEPJb9ACvKmaAdYMBpP5EURwGnvWByPfN791QqFos7mCbUi/BIsJARDFryzWpS7525TLgRhjHBPGvnfuYCfYAsTiDPteubNbthz2GtEqcgNVSg7Ztf7jAmaUQFEI6VGjh2Al6GJTDCaV5xU0UTTCZ4RAeaChxR5WXzX3LrVCtDK4ylLgHWXP09keFIqWkU6M7ZyWrZm4n/eYMUwisvYyJJgQqyWBSm3ILYmgVjDZmkBPhUE0wk07daZIwlJqDjq+gQnOWXV0n3vOFcNJq3zVqrWsRRRieoiurIQZeohW5QG3UQQY/oGb2iN+PJeDHejY9Fa8koZo7RHxifP0MTmxw=</latexit> p(W ) 2 Popt(W ) <latexit sha1_base64=\"rOTYw8hxSSSPI+COVbyX5Mj75MI=\">AAACHHicbVDLSsNAFJ34rPVVdekmtBTqpiRa1GXBjcsKfUETwmQ6aYdOJmHmRiwhH+LGX3HjQhE3LgT/xknbhbZemOFwzrnce48fc6bAsr6NtfWNza3twk5xd2//4LB0dNxVUSIJ7ZCIR7LvY0U5E7QDDDjtx5Li0Oe0509ucr13T6VikWjDNKZuiEeCBYxg0JRXunBCDONA4knazmq9s2I11r/DxIwnmKetzEsdoA+QRjFkuccrVay6NStzFdgLUEGLanmlT2cYkSSkAgjHSg1sKwY3xRIY4TQrOomiMSYTPKIDDQUOqXLT2XGZWdXM0AwiqZ8Ac8b+7khxqNQ09LUzX1ktazn5nzZIILh2UybiBKgg80FBwk2IzDwpc8gkJcCnGmAimd7VJGMsMQGdZ1GHYC+fvAq653X7st64a1Sa5UUcBXSKyqiGbHSFmugWtVAHEfSIntErejOejBfj3fiYW9eMRc8J+lPG1w+D7aGT</latexit> T(W )\n<latexit sha1_base64=\"wqcOZDtq9LPRV7IdVmDpd802ES0=\">AAACIXicbVDLSsNAFJ34rPEVdekmtBRakJJI0S4LblxW6AuaUibTSTt0MgkzN2IJ+RU3/oobF4p0J/6M08dCWw8MHM45l7n3+DFnChzny9ja3tnd288dmIdHxyen1tl5W0WJJLRFIh7Jro8V5UzQFjDgtBtLikOf044/uZv7nUcqFYtEE6Yx7Yd4JFjACAYtDayaMIteiGEcSDxJm1mpcyXKZjEudcoeEwuHYJ42skHqAX2CNIoh06nywCo4FWcBe5O4K1JAKzQG1swbRiQJqQDCsVI914mhn2IJjHCamV6iaIzJBI9oT1OBQ6r66eLCzC5qZWgHkdRPgL1Qf0+kOFRqGvo6OV9ZrXtz8T+vl0BQ66dMxAlQQZYfBQm3IbLnddlDJikBPtUEE8n0rjYZY4kJ6FJNXYK7fvImaV9X3JtK9aFaqOdXdeTQJcqjEnLRLaqje9RALUTQM3pF7+jDeDHejE9jtoxuGauZC/QHxvcPWUyi/A==</latexit>\nn <latexit sha1_base64=\"x4NMfTfMnA4fFhyOFwlCOjtby7M=\">AAACaXicbVFNbxMxEPUuX2UpkIJACC5Wo0jpgWi3qloOHCpx4RikpqmUDSuvM9tY8XpX9ixt5FriN/bWP8CFP4E3yQFSRrL09N4bj+c5r6UwGMd3Qfjg4aPHT3aeRs92n7942dl7dW6qRnMY8UpW+iJnBqRQMEKBEi5qDazMJYzzxZdWH/8AbUSlznBZw7Rkl0oUgjP0VNb52VNRWjKcF5ot7JnLxn11EPXq/vggFWqlcCbt0GU2RbhGW9XonFe9J1NbFk7XHnolcE5detNe87H13fh2kDJLHP1MUz+L28TZw+/KZZ1uPIhXRe+DZAO6ZFPDrHObzirelKCQS2bMJIlrnFqmUXAJLkobAzXjC3YJEw8VK8FM7SopR3uemdGi0v4opCv27w7LSmOWZe6d7V5mW2vJ/2mTBotPUytU3SAovh5UNJJiRdvY6Uxo4CiXHjCuhX8r5XPmc0D/OZEPIdle+T44Pxwkx4Ojb0fd0/1NHDvkA9knfZKQE3JKvpIhGRFOfgW7wZvgbfA73Avfhe/X1jDY9Lwm/1TY/QO3A7lf</latexit> TW (n)\n<latexit sha1_base64=\"sUvF+HHRq2G5YO5vazRSoR7Sg/E=\">AAACaXicbVHBahsxFNRu0zbdpo3TkhLai4gx2JCY3RDaHnoI9NKjC3Ec8LqLVtbGwlqtkN42MYog35hbfyCX/kS1tg+t0weCYWaent4oV4IbiONfQfhk6+mz59svopc7r17vtvbeXJiq1pQNaSUqfZkTwwSXbAgcBLtUmpEyF2yUz782+ugn04ZX8hwWik1KciV5wSkBT2Wtu46MOmlJYFZoMrfnrjs6kr2oo7qjXsrlUqFE2IHLbArsBmylwHlXL1KZ3HBQvLLgaw4z7NLb5pbjxnfru5kQWeLwF5z6UdQmzp78kC5rteN+vCz8GCRr0EbrGmSt+3Ra0bpkEqggxoyTWMHEEg2cCuaitDZMETonV2zsoSQlMxO7TMrhjmemuKi0PxLwkv27w5LSmEWZe2ezl9nUGvJ/2riG4vPEcqlqYJKuBhW1wFDhJnY85ZpREAsPCNXcvxXTGfE5gP+cyIeQbK78GFyc9JOP/dPvp+2zw3Uc2+gDOkRdlKBP6Ax9QwM0RBQ9BDvBfvAu+B3uhQfh+5U1DNY9b9E/Fbb/AEeIuSw=</latexit>\npn 2 Pc with kp(W ) pnk`1 < 1 2n\nfrom complex analysis enable the approximation thereof.\nNext, we want to further discuss the implications of Theorem 2 and the problem of the computation of C(W ), W \u2208 CHc(X ;Y). For this purpose, let W \u2208 CHc(X ;Y) be fixed and we consider the function fW (p) := I(p,W ). The function fW is concave and further a computable function in p since W \u2208 CHc(X ;Y). Therefore, from [31, Section 0.6] follows that the condition C(W ) \u2208 Rc is satisfied, cf. also (6). For p\u2217 \u2208 Popt(W ) arbitrary we have fW (p\u2217) = C(W ), but p\u2217 must not necessarily be a computable input distribution, i.e., p\u2217 \u2208 Pc(X ) is not necessarily satisfied. In fact, in [41] it has been shown that already on the interval [0, 1] it is possible to construct continuous computable functions g such that for every point x\u2217 \u2208 [0, 1] with maxx\u2208[0,1] g(x) = g(x\u2217) it holds that x\u2217 /\u2208 Rc, i.e., there is no Borel-Turing computable maximizer, although we have maxx\u2208[0,1] g(x) \u2208 Rc.\nFor the mutual information, i.e., for our function fW , such a behavior cannot exist. This means there always exists an optimal p\u2217 \u2208 Popt(W ) such that p\u2217 \u2208 Pc(X ) is satisfied. This implies the following: For an optimal p\u2217 \u2208 Pc(X )\u2229Popt(W ) there exists by definition an algorithm (or Turing machine) that approximates the optimal p\u2217 by rational probability distributions with arbitrarily small approximation error. In particular, with this we can find a function G\u2217 such that for every W \u2208 CHc(X ;Y) it always holds G\u2217(W ) \u2208 Pc(X )\u2229Popt(W ). This means the function G\u2217 is mathematically well defined and gives always a computable optimal input distribution, i.e., the output of G\u2217 is in Pc(X ). But, at the same time, the function G\u2217 itself is not Borel-Turing computable, i.e., the function W \u2192 p\u2217(W ) \u2208 Pc(X ) \u2229 Popt(W ) does not depend on W in a Borel-Turing computable way. In particular, for every W \u2208 CHc(X ;Y) there exists a p\u2217(W ) \u2208 Pc(X ) \u2229 Popt(W ), but this p\u2217(W ) cannot be computed algorithmically.\nRemark 10. For W \u2208 CH(X ;Y) the set Popt is always convex. For practical applications, it would be interesting to know the extreme points of this set. Then it is of further interest to understand if for W \u2208 CHc(X ;Y) the extreme points of the set Popt are also in Pc(X ), i.e., a computable input distribution. This question remains open and for general continuous computable concave functions it could be the case that no extreme point of Popt is computable."
        },
        {
            "heading": "V. APPROXIMABILITY OF AN OPTIMAL INPUT DISTRIBUTION",
            "text": "Above we have shown that it is impossible to algorithmically construct optimal, i.e., capacity-achieving, input distributions. Consequently, we are now interested in understanding\n<latexit sha1_base64=\"4HGdYQOEIFNXYe2OJ8ZKGlM3VQQ=\">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LC2Cp5KIqMeCF48t2A9oQ9lsJ+3azSbsboQS+gu8eFDEqz/Jm//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ3dzvPKHSPJYPZpqgH9GR5CFn1Fip2RmUq27NXYCsEy8nVcjRGJS/+sOYpRFKwwTVuue5ifEzqgxnAmelfqoxoWxCR9izVNIItZ8tDp2Rc6sMSRgrW9KQhfp7IqOR1tMosJ0RNWO96s3F/7xeasJbP+MySQ1KtlwUpoKYmMy/JkOukBkxtYQyxe2thI2poszYbEo2BG/15XXSvqx517Wr5lW1XsnjKMIZVOACPLiBOtxDA1rAAOEZXuHNeXRenHfnY9lacPKZU/gD5/MHrYOMxA==</latexit> W <latexit sha1_base64=\"VEtun57WPfJ2KQn3mNQxCDG17Hk=\">AAACC3icbVBNS8NAEN3Ur1q/oh69hBahXkoiRT0WvHisYD+gCWGz3bRLN5uwOxFLyN2Lf8WLB0W8+ge8+W/ctjlo64OBx3szzMwLEs4U2Pa3UVpb39jcKm9Xdnb39g/Mw6OuilNJaIfEPJb9ACvKmaAdYMBpP5EURwGnvWByPfN791QqFos7mCbUi/BIsJARDFryzWpS7525TLgRhjHBPGvnfuYCfYAsTiDPteubNbthz2GtEqcgNVSg7Ztf7jAmaUQFEI6VGjh2Al6GJTDCaV5xU0UTTCZ4RAeaChxR5WXzX3LrVCtDK4ylLgHWXP09keFIqWkU6M7ZyWrZm4n/eYMUwisvYyJJgQqyWBSm3ILYmgVjDZmkBPhUE0wk07daZIwlJqDjq+gQnOWXV0n3vOFcNJq3zVqrWsRRRieoiurIQZeohW5QG3UQQY/oGb2iN+PJeDHejY9Fa8koZo7RHxifP0MTmxw=</latexit> p(W ) 2 Popt(W ) <latexit sha1_base64=\"rOTYw8hxSSSPI+COVbyX5Mj75MI=\">AAACHHicbVDLSsNAFJ34rPVVdekmtBTqpiRa1GXBjcsKfUETwmQ6aYdOJmHmRiwhH+LGX3HjQhE3LgT/xknbhbZemOFwzrnce48fc6bAsr6NtfWNza3twk5xd2//4LB0dNxVUSIJ7ZCIR7LvY0U5E7QDDDjtx5Li0Oe0509ucr13T6VikWjDNKZuiEeCBYxg0JRXunBCDONA4knazmq9s2I11r/DxIwnmKetzEsdoA+QRjFkuccrVay6NStzFdgLUEGLanmlT2cYkSSkAgjHSg1sKwY3xRIY4TQrOomiMSYTPKIDDQUOqXLT2XGZWdXM0AwiqZ8Ac8b+7khxqNQ09LUzX1ktazn5nzZIILh2UybiBKgg80FBwk2IzDwpc8gkJcCnGmAimd7VJGMsMQGdZ1GHYC+fvAq653X7st64a1Sa5UUcBXSKyqiGbHSFmugWtVAHEfSIntErejOejBfj3fiYW9eMRc8J+lPG1w+D7aGT</latexit> T(W )\n<latexit sha1_base64=\"4HGdYQOEIFNXYe2OJ8ZKGlM3VQQ=\">AAAB6HicbVBNS8NAEJ3Ur1q/qh69LC2Cp5KIqMeCF48t2A9oQ9lsJ+3azSbsboQS+gu8eFDEqz/Jm//GbZuDtj4YeLw3w8y8IBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ3dzvPKHSPJYPZpqgH9GR5CFn1Fip2RmUq27NXYCsEy8nVcjRGJS/+sOYpRFKwwTVuue5ifEzqgxnAmelfqoxoWxCR9izVNIItZ8tDp2Rc6sMSRgrW9KQhfp7IqOR1tMosJ0RNWO96s3F/7xeasJbP+MySQ1KtlwUpoKYmMy/JkOukBkxtYQyxe2thI2poszYbEo2BG/15XXSvqx517Wr5lW1XsnjKMIZVOACPLiBOtxDA1rAAOEZXuHNeXRenHfnY9lacPKZU/gD5/MHrYOMxA==</latexit>\nW <latexit sha1_base64=\"4NT0cPNUq2zaOayk/uRQd4yiK4E=\">AAACHnicbVDLSsNAFJ3UV42vqks3oaXQgpRE6mNZcOOyQh9CE8pkOmmHTiZh5kYsIV/ixl9x40IRwZX+jdPHQlsPDBzOOZe59/gxZwps+9vIra1vbG7lt82d3b39g8LhUUdFiSS0TSIeyTsfK8qZoG1gwOldLCkOfU67/vh66nfvqVQsEi2YxNQL8VCwgBEMWuoXzt0QwyiQeJy2skr3VFTNclzpVl0mZg7BPG1m/dQF+gBpFEOmU9V+oWTX7BmsVeIsSAkt0OwXPt1BRJKQCiAcK9Vz7Bi8FEtghNPMdBNFY0zGeEh7mgocUuWls/Myq6yVgRVEUj8B1kz9PZHiUKlJ6OvkdGW17E3F/7xeAsGVlzIRJ0AFmX8UJNyCyJp2ZQ2YpAT4RBNMJNO7WmSEJSagGzV1Cc7yyaukc1ZzLmr123qpUVzUkUcnqIgqyEGXqIFuUBO1EUGP6Bm9ojfjyXgx3o2PeTRnLGaO0R8YXz/ZjKJB</latexit> T(W, n) <latexit sha1_base64=\"wqcOZDtq9LPRV7IdVmDpd802ES0=\">AAACIXicbVDLSsNAFJ34rPEVdekmtBRakJJI0S4LblxW6AuaUibTSTt0MgkzN2IJ+RU3/oobF4p0J/6M08dCWw8MHM45l7n3+DFnChzny9ja3tnd288dmIdHxyen1tl5W0WJJLRFIh7Jro8V5UzQFjDgtBtLikOf044/uZv7nUcqFYtEE6Yx7Yd4JFjACAYtDayaMIteiGEcSDxJm1mpcyXKZjEudcoeEwuHYJ42skHqAX2CNIoh06nywCo4FWcBe5O4K1JAKzQG1swbRiQJqQDCsVI914mhn2IJjHCamV6iaIzJBI9oT1OBQ6r66eLCzC5qZWgHkdRPgL1Qf0+kOFRqGvo6OV9ZrXtz8T+vl0BQ66dMxAlQQZYfBQm3IbLnddlDJikBPtUEE8n0rjYZY4kJ6FJNXYK7fvImaV9X3JtK9aFaqOdXdeTQJcqjEnLRLaqje9RALUTQM3pF7+jDeDHejE9jtoxuGauZC/QHxvcPWUyi/A==</latexit> n\n<latexit sha1_base64=\"sUvF+HHRq2G5YO5vazRSoR7Sg/E=\">AAACaXicbVHBahsxFNRu0zbdpo3TkhLai4gx2JCY3RDaHnoI9NKjC3Ec8LqLVtbGwlqtkN42MYog35hbfyCX/kS1tg+t0weCYWaent4oV4IbiONfQfhk6+mz59svopc7r17vtvbeXJiq1pQNaSUqfZkTwwSXbAgcBLtUmpEyF2yUz782+ugn04ZX8hwWik1KciV5wSkBT2Wtu46MOmlJYFZoMrfnrjs6kr2oo7qjXsrlUqFE2IHLbArsBmylwHlXL1KZ3HBQvLLgaw4z7NLb5pbjxnfru5kQWeLwF5z6UdQmzp78kC5rteN+vCz8GCRr0EbrGmSt+3Ra0bpkEqggxoyTWMHEEg2cCuaitDZMETonV2zsoSQlMxO7TMrhjmemuKi0PxLwkv27w5LSmEWZe2ezl9nUGvJ/2riG4vPEcqlqYJKuBhW1wFDhJnY85ZpREAsPCNXcvxXTGfE5gP+cyIeQbK78GFyc9JOP/dPvp+2zw3Uc2+gDOkRdlKBP6Ax9QwM0RBQ9BDvBfvAu+B3uhQfh+5U1DNY9b9E/Fbb/AEeIuSw=</latexit>\npn 2 Pc with kp(W ) pnk`1 < 1\n2n\nwhether or not it is at least possible to algorithmically approximate such distributions. This is visualized in Fig. 2 for the case where the Turing machine would obtain both the channel and the block length as inputs and in Fig. 3 for the case where the channel is known beforehand and only the block length is given as an input to the Turing machine.\nWe have seen that all functions F : CHc(X ;Y) \u2192 P(X ) with F (W ) \u2208 Popt(W ) for all W \u2208 CHc(X ;Y) are not Banach-Mazur computable and therewith also not BorelTuring computable. The question is now whether or not we can instead solve this problem approximately, i.e., does there exist a computable sequence of Borel-Turing computable functions Fn, n \u2208 N, with Fn : CHc(X ;Y) \u2192 Pc(X ), n \u2208 N, such that for all W \u2208 CHc(X ;Y) for a suitable function F with F (W ) \u2208 Popt(W ) for all W \u2208 CHc(X ;Y) we always have\n\u2225\u2225F (W )\u2212 Fn(W )\u2225\u2225\u21131 < 12n . This is equivalent to the question of whether or not there exists a Turing machine T that takes an arbitrary representation of W \u2208 CHc(X ;Y) and n \u2208 N as inputs and then computes for W and n a representation for pn(W ) \u2208 P(X ) such that\n\u2225\u2225F (W )\u2212 pn(W )\u2225\u2225\u21131 < 12n . (17) And this is equivalent to the question of whether or not it is possible to find a Turing machine T with the following properties: T takes the channel and natural numbers as inputs and computes a description of an input distribution. This input distribution must satisfy the following: for all W \u2208 CHc(X ;Y) and all n \u2208 N the Turing machine must compute for every description for W a description of pn(W ) such that for a suitable p\u2217(W ) \u2208 Popt(W ) it always holds that\n\u2225\u2225p\u2217(W )\u2212 pn(W )\u2225\u2225\u21131 < 12n . The input n of this Turing machine T could enable the algorithmic approximation of the optimal input distribution.\nA negative answer can be immediately given to this question based on the results obtained above, since a function F must be Borel-Turing computable, see also [29]. We can formalize\n11\nthe following question.\nQuestion 2: Let X and Y be finite input and output alphabets with |X | \u2265 3 and |Y| \u2265 2. Is it possible to approximate a function F \u2208 Mopt(X ;Y) by computable functions? Is there a function F \u2208 Mopt(X ;Y) and a computable function F1 such that\nsup W\u2208CHc(X ;Y) \u2225\u2225F (W )\u2212 F1(W )\u2225\u2225\u21131 < 12 ? Remark 11. With this question we ask whether or not the previous condition (17) as the supremum can be satisfied for the trivial case n = 1.\nTheorem 4. Let X and Y be arbitrary but finite alphabets with |X | \u2265 3 and |Y| \u2265 2. Let F \u2208 Mopt(X ;Y) be an arbitrary function and let F1 be another arbitrary function with\nsup W\u2208CHc(X ;Y) \u2225\u2225F (W )\u2212 F1(W )\u2225\u2225\u21131 = \u03b1 < 12 . Then F1 is not Banach-Mazur computable.\nProof: We prove the result by contradiction. Therefore, we assume that there exists a function F \u2208 Mopt(X ;Y) such that there is a function F1 with\nsup W\u2208CHc(X ;Y) \u2223\u2223F (W )\u2212 F1(W )\u2223\u2223 = \u03b2 < 1 that is Banach-Mazur computable. Then, there exists a computable real number \u03b1 with \u03b2 \u2264 \u03b1 < 1.\nWe now consider the computable sequence (W \u2217n)n\u2208N as used in the proof of Theorem 2. For l \u2208 N, let\u2225\u2225F1(W \u22172l)\u2212 F (W \u22172l)\u2225\u2225\u21131 \u2264 \u03b1 and \u2225\u2225F1(W \u22172l\u22121)\u2212 F (W \u22172l\u22121)\u2225\u2225\u21131 \u2264 \u03b1 be satisfied. Then, we also have for l \u2208 A the following: 1 =\n\u2225\u2225F (W \u22172l)\u2212 F (W \u22172l\u22121)\u2225\u2225\u21131 =\n\u2225\u2225F (W \u22172l)\u2212 F1(W \u22172l) + F1(W \u22172l)\u2212 F1(W \u22172l\u22121) + F1(W \u2217 2l\u22121)\u2212 F (W \u22172l\u22121) \u2225\u2225 \u21131\n\u2264 \u2225\u2225F (W \u22172l)\u2212 F1(W \u22172l)\u2225\u2225\u21131 + \u2225\u2225F1(W \u22172l)\u2212 F1(W \u22172l\u22121)\u2225\u2225\u21131 + \u2225\u2225F1(W \u22172l\u22121)\u2212 F (W \u22172l\u22121)\u2225\u2225\u21131\n\u2264 2\u03b1+ \u2225\u2225F1(W \u22172l)\u2212 F1(W \u22172l\u22121)\u2225\u2225\u21131 .\nTherefore, it holds that\u2225\u2225F1(W \u22172l)\u2212 F1(W \u22172l\u22121)\u2225\u2225\u21131 \u2265 1\u2212 2\u03b1 = c1 > 0 which implies that\nc1 = \u2225\u2225F1(W \u22172l)\u2212 F1(W\u2217) + F1(W\u2217)\u2212 F1(W \u22172l\u22121)\u2225\u2225\u21131\n\u2264 \u2225\u2225F1(W \u22172l)\u2212 F1(W\u2217)\u2225\u2225\u21131 + \u2225\u2225F1(W\u2217)\u2212 F1(W \u22172l\u22121)\u2225\u2225\u21131\n\u2264 2max {\u2225\u2225F1(W \u22172l)\u2212F1(W\u2217)\u2225\u2225\u21131 ,\u2225\u2225F1(W\u2217)\u2212F1(W \u22172l\u22121)\u2225\u2225\u21131} =: 2r\u2217l .\nWe conclude that\nr\u2217l \u2265 c1 2 > 0. (18)\nFor l \u2208 N and l /\u2208 A, F1(W \u2217 2l) = F1(W\u2217)\nand F1(W \u2217 2l\u22121) = F1(W\u2217)\nare satisfied. Accordingly, we can use the same Turing machine T< 14 as in the proof of Theorem 2 for the input r \u2217 l in (18). The Turing machine T< 14 (r \u2217 l ) stops if and only if l /\u2208 A. Thus, we can construct a Turing machine as in the proof of Theorem 2 that decides for every l \u2208 N whether l \u2208 A or l /\u2208 A. This is, again, a contradiction to the initial assumption completing the proof of Theorem 4.\nFrom this we immediately obtain the following result.\nCorollary 2. Let F \u2208 Mopt(X ;Y) be an arbitrary function. For \u03b1 < 12 arbitrary, there exists no Turing machine T\u2217 such that for all W \u2208 CHc(X ;Y),\u2225\u2225F (W )\u2212 T\u2217(W )\u2225\u2225\u21131 \u2264 \u03b1 is true.\nProof: If such a function F \u2208 Mopt(X ;Y) would exist for which we can find a Turing machine T\u2217 with \u03b1\u0302 < 12 , then F1(W ) = T\u2217(W ), W \u2208 CHc(X ;Y), would be Banach-Mazur computable.\nAs a consequence, we can further conclude the following.\nCorollary 3. The approximation problem stated in Question 2 is not solvable.\nProof: Already for n = 2 this is not possible. Similarly as in Section IV, one can show that a choice\nof Borel-Turing computable starting points for iterative algorithms such as the Blahut-Arimoto algorithm, i.e., p0(W ) = G(W ), W \u2208 CHc(X ;Y), G Borel-Turing computable function, does not improve the approximation behavior according to Question 2."
        },
        {
            "heading": "VI. CONCLUSION",
            "text": "The channel capacity describes the maximum rate at which a source can be reliably transmitted. Capacity expressions are usually given by entropic quantities that are optimized over all possible input distributions. Evaluating such capacity expressions and finding corresponding optimal input distributions that maximize these capacity expressions is a common and important task in information and communication theory. Several algorithms including the Blahut-Arimoto algorithm have been proposed to algorithmically compute these quantities. In this work, we have shown that there exists no algorithm or Turing machine that takes a DMC as input and then computes an input distribution that maximizes the capacity. Although capacity-achieving input distributions have been found analytically for some specific DMCs, this does not immediately mean that capacity-achieving input distributions can be algorithmically computed by a Turing that takes a\n12\nDMC of interest as input. We have further shown that it is not even possible to algorithmically approximate this distribution. These results have implications for the Blahut-Arimoto algorithm. In particular, as we have noted, there is no stopping criterion for the computation of the input distribution, and our results imply that such a computable stopping criterion cannot exist, providing a negative answer to the open question of whether one does.\nFuture communication systems such as the 6th generation (6G) of mobile communication networks are being developed for very critical applications such as autonomous driving or mobile robots, but also for health care [42, 43]. Due to the particular challenges of security and privacy of these applications, 6G must fulfill strict conditions on trustworthiness [44], for which integrity is one of the essential conditions that needs to be satisfied. With the results of this work, it can be shown that the computation of optimal input distributions is never possible on digital computers under the condition of integrity. In addition to the technical requirement for integrity, algorithms must also fulfill legal requirements for many future applications. For example, algorithms for critical decision problems must already fulfill the legal requirement of algorithmic transparency2. With the results of this work, it can further be shown that the computation of optimal input distributions on digital computers is never possible under the requirement of algorithmic transparency."
        },
        {
            "heading": "ACKNOWLEDGMENT",
            "text": "Holger Boche thanks Rainer Moorfeld for discussions and hints on new computing technologies for future communication systems. He also thanks Gerhard Fettweis for introducing him to the large field of achieving trustworthiness in 6G.\nAPPENDIX"
        },
        {
            "heading": "A. Example of a Non-Computable Function",
            "text": "Here, we show that for x \u2208 [0, 1] \u2229 Rc the function\nf(t) = e\u2212x\nis not exactly computable on Turing machines, but only approximable.\nBy the remainder theorem of Lagrange, we get for x \u2208 [0, 1]:\nf(x) = n\u2211 l=0 (\u22121)l l! xl + 1 (n+ 1)! f (n+1)(\u03d1x)x n+1\nwith \u03d1x \u2208 [0, x] a suitable number. With this, we get\u2223\u2223\u2223f(x)\u2212 n\u2211 l=1 (\u22121)l l! xl \u2223\u2223\u2223 = 1 (n+ 1)! e\u2212\u03d1xxn+1 \u2264 1 (n+ 1)!\nand (n+ 1)! > 2n, n \u2265 2.\n2Algorithmic transparency requires all factors that determine the result of an algorithm to be visible to the legislator, operator, user, and other affected individuals.\nAssume now that we have a sequence (rn)n\u2208N of rational numbers with\n|x\u2212 rn| < 1\n2n\nso that\u2223\u2223\u2223f(x)\u2212 n\u2211 l=0 (\u22121)l l! (rn) l \u2223\u2223\u2223\n= \u2223\u2223\u2223f(x)\u2212 f(rn) + f(rn)\u2212 n\u2211\nl=0\n(\u22121)l l!\n(rn) l \u2223\u2223\u2223\n\u2264 |f(x)\u2212 f(rn)|+ \u2223\u2223\u2223f(rn)\u2212 n\u2211\nl=0\n(\u22121)l l!\n(rn) l \u2223\u2223\u2223\n< |f(x)\u2212 f(rn)|+ 1\n2n , n \u2265 2.\nNow, the mean value theorem implies that\n|f(x)\u2212 f(rn)| = |f \u2032(\u03bex,n)|\u00b7|x\u2212 rn|\nwith \u03bex,n \u2208 [x \u2212 rn, x + rn] being a suitable number. This yields\n|f(x)\u2212 f(rn)| \u2264 |x\u2212 rn| < 1\n2n .\nWith yn := \u2211n l=0 (\u22121)l l! (rn) l, we obtain\n|f(x)\u2212 yn| < 1\n2n +\n1\n2n =\n1\n2n\u22121 ,\ni.e., the algorithm\n(rn)n\u2208N \u2192 (yn)n\u2208N maps a representation of x into a representation of f(x). This algorithm converges effectively.\nFrom this calculation we immediately see how the function f can be approximated. Whenever f needs to be approximated in such a way that the error satisfies 12n , we use the polynomial as given above and compute it accordingly. For this, it is important to find suitable sequences of polynomials. Note that the polynomials in this sequence needs to be computable as well as the sequence itself needs to be a computable sequence, since otherwise, we are not able to evaluate the approximation process algorithmically. Note that this does not mean that every sequence of approximations of f is also a suitable sequence for our purpose."
        },
        {
            "heading": "B. Binary Entropy and Transcendental Numbers",
            "text": "For the following, we need Hilbert\u2019s Seventh Problem which is restated next for completeness.\nHilbert\u2019s Seventh Problem. Let a /\u2208 {0, 1} be an algebraic number (i.e., a root of a non-zero polynomial with integer coefficients) and let b be an irrational and algebraic number. Is ab always a transcendental number (i.e., not algebraic)?\nRemark 12. A positive answer to this question was then first given in 1934 by Gelfond [45] and subsequently refined in\n13\n1935 by Schneider [46]. Later this was generalized by Baker for which he was awarded a Fields Medal in 1970, cf. [47].\nWe further need the following observation.\nLemma 1. Let n \u2208 N and t \u2208 N be arbitrary. Then n and nt are divisible by the same prime numbers.\nProof: Let n = \u220fr\nl=1 pl be the unique prime factorization of n. Note that in factorization, certain prime factors may appear multiple times. Then, nt = \u220fr l=1(pl)\nt is a prime factorization of nt. As this factorization is unique, both n and nt must have the same prime factors.\nWe now prove the following result.\nTheorem 5. Let p \u2208 Q with p /\u2208 {0, 12 , 1}. Then, h2(p) is a transcendental number.\nProof: Let\nh2(p) = p log 1 p + (1\u2212 p) log 1\n1\u2212 p be the binary entropy, which can be equivalently be expressed as\n2h2(p) =\n( 1\np\n)p ( 1\n1\u2212 p\n)1\u2212p . (19)\nLet p \u2208 Q with p \u2208 (0, 1), p /\u2208 {0, 12 , 1} be arbitrary. Then, we can express p as p = nm , n < m, n,m \u2208 N, and assume without loss of generality that n and m are coprime. With this, we can write (\n1\np\n)p = (m n ) n m\nand conclude that the number ( 1p ) p is a root of the polynomial xm\u2212(mn )n and therewith also of the polynomial nnxm\u2212mn. Thus, ( 1p )\np is an algebraic number. Similarly, one can show that ( 11\u2212p )\n1\u2212p is an algebraic number so that 2h2(p) as in (19) is also an algebraic number.\nNow, we can use the Gelfond-Schneider theorem, i.e., the solution to Hilbert\u2019s Seventh Problem, cf. for example [47]. As 2h2(p) is an algebraic number, h2(p) must be either rational or transcendental. Since otherwise, if h2(p) would be algebraic and irrational, then 2h2(p) would be transcendental.\nNext, we want to show by contradiction that h2(p) cannot be rational. Since p \u2208 (0, 1), p \u0338= 12 , we have h2(p) \u2208 (0, 1). For this purpose, we assume that h2(p) is rational so that it can be expressed as h2(p) = uv with 0 < u < v, u, v \u2208 N, and u, v coprime without loss of generality. We further must have v > 1. This would imply that\n2 u v = (m n ) n m ( 1\n1\u2212 nm )1\u2212 nm = (m n ) n m ( m m\u2212 n )m\u2212n m\nso that\n2mu = (m n )nv ( m m\u2212 n )(m\u2212n)v or equivalently\n2mu(n)nv(m\u2212 n)(m\u2212n)v = (m)mv.\nNote that m\u2212n \u2265 1 and further nv \u2208 N, nv > 1, since v > 1. If n = 1, then\n2mu(m\u2212 1)(m\u22121)v = (m)mv. Lemma 1 and the uniqueness of the prime factorization would then imply that every prime factor of m\u2212 1 must be a prime factor m as well. However, this is not possible.\nIf n > 1, then Lemma 1 implies that every prime factor of n must also be a prime factor of m. However, this is not possible, since n and m are coprime. As a consequence, h2(p) cannot be a rational number. Finally, we conclude that h2(p) must be a transcendental number which completes the proof."
        }
    ],
    "title": "Algorithmic Computability and Approximability of Capacity-Achieving Input Distributions",
    "year": 2023
}