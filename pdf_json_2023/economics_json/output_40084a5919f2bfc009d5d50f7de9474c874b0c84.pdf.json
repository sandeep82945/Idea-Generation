{
    "abstractText": "Accurately forecasting crude oil prices is challenging due to market noise and non-stationarity. To address these challenges, we propose a novel forecasting framework that incorporates variational mode decomposition (VMD), time-series imaging, and bidirectional gated recurrent unit network (BGRU). Our approach eliminates additional assumptions and auxiliary data. The framework includes several stages. Firstly, the raw data are preprocessed through normalization, followed by decomposing multiple stationary sub-series throughVMD. Subsequently, three time-series imaging techniques, recurrence plot (RP), Gramian angular field (GAF), and Markov transition field (MTF), are employed respectively to transform the subseries into two-dimensional images. A convolutional neural network (CNN) is then used to extract features from these images. Finally, the extracted features are fed into BGRU for prediction, and the Adam optimizer is used to train models. Experimental evaluations are conducted using a dataset from the U.S. Energy Information Administration, consisting of weekly spot prices FOB of the Oklahoma Cushing WTI crude oil, spanning from June 19, 1998, to May 12, 2023. Results demonstrate that all three hybrid models constructed following our approach outperform benchmark methods. Specifically, our VMD-RP-BGRU model achieves the best forecasting performance with MAE=2.429, MSE=10.94, MAPE=2.94%, and R-squared=0.9418. It exhibits reductions of 21.64%, 23.15%, and 36.46% inMAE,MSE, andMAPE, respectively, compared to the seasonal autoregressive integrated moving average (SARIMA) model, and reductions of 21.18%, 22.70%, and 36.08% compared to the Holt-Winters exponential smoothing (HWES) model. Our study contributes to the advancement of crude oil price forecasting techniques and supports informed decision-making in the energy sector. INDEX TERMS Crude oil price forecasting, deep learning, variational mode decomposition, time-series imaging, bidirectional gated recurrent unit.",
    "authors": [
        {
            "affiliations": [],
            "name": "ZI-JIAN PENG"
        },
        {
            "affiliations": [],
            "name": "CHUAN ZHANG"
        },
        {
            "affiliations": [],
            "name": "Yu-xin Tian"
        }
    ],
    "id": "SP:06f8ac8d407a6fe0b7d66f0d3323a90b5e57c4c2",
    "references": [
        {
            "authors": [
                "IEA"
            ],
            "title": "Key World Energy Statistics 2021",
            "venue": "International Energy Agency, Paris, France, Sept. 10, 2021. [Online]. Available: https://www.iea.org/reports/key-world-energy-statistics-2021.",
            "year": 2021
        },
        {
            "authors": [
                "K. Joo",
                "J.H. Suh",
                "D. Lee",
                "K. Ahn"
            ],
            "title": "Impact of the global financial crisis on the crude oil market",
            "venue": "Energy Strategy Rev., vol. 30, p. 100516, Jul. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Bureau of Labor Statistics"
            ],
            "title": "The 2014 Plunge in Import Petroleum Prices: What Happened",
            "venue": "U.S. Department of Labor, Washington, DC, Rep. no. 9, vol. 4, May 2015. [Online]. Available: https://www.bls.gov/opub/btn/volume-4/pdf/the-2014-plunge-in-importpetroleum-prices-what-happened.pdf.",
            "year": 2015
        },
        {
            "authors": [
                "J. Yuan",
                "J. Li",
                "J. Hao"
            ],
            "title": "A dynamic clustering ensemble learning approach for crude oil price forecasting",
            "venue": "Eng Appl Artif Intell, vol. 123, p. 106408, Aug. 2023.",
            "year": 2023
        },
        {
            "authors": [
                "J. Guo",
                "Z. Zhao",
                "J. Sun",
                "S. Sun"
            ],
            "title": "Multi-perspective crude oil price forecasting with a new decomposition-ensemble framework",
            "venue": "Resour. Policy, vol. 77, p. 102737, Aug. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "Y. Guo",
                "F.Ma",
                "H. Li",
                "andX. Lai"
            ],
            "title": "Oil price volatility predictability based on global economic conditions",
            "venue": "Int. Rev. Financial Anal., vol. 82, p. 102195, Jul. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "B. S\u00e9vi"
            ],
            "title": "Forecasting the volatility of crude oil futures using intraday data",
            "venue": "Eur. J. Oper. Res., vol. 235, no. 3, pp. 643-659, Jun. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "R.J. Hyndman",
                "G. Athanasopoulos"
            ],
            "title": "Forecasting: principles and practice.Melbourne, Australia: OTexts, 2018",
            "year": 2018
        },
        {
            "authors": [
                "X.Y. Jiang"
            ],
            "title": "Effect of chromium on granule-based anammox processes",
            "venue": "Bioresour. Technol., vol. 260, pp. 1-8, Jul. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "Y. Baek",
                "H.Y. Kim"
            ],
            "title": "ModAugNet: A new forecasting framework for stock market index value with an overfitting prevention LSTMmodule and a prediction LSTM module",
            "venue": "Expert Syst. Appl., vol. 113, pp. 457-480, Dec. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "J. Cao",
                "Z. Li",
                "J. Li"
            ],
            "title": "Financial time series forecasting model based on CEEMDAN and LSTM",
            "venue": "Physica A, vol. 519, pp. 127-139, Apr. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "T. Fischer",
                "C. Krauss"
            ],
            "title": "Deep learning with long short-term memory networks for financial market predictions",
            "venue": "Eur. J. Oper. Res., vol. 270, no. 2, pp. 654-669, Oct. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "S. Borovkova",
                "I. Tsiamas"
            ],
            "title": "An ensemble of LSTM neural networks for high-frequency stock market classification",
            "venue": "J Forecast, vol. 38, no. 6, pp. 600-619, Mar. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "N. Jing",
                "Z. Wu",
                "H. Wang"
            ],
            "title": "A hybrid model integrating deep learning with investor sentiment analysis for stock price prediction",
            "venue": "Expert Syst. Appl., vol. 178, p. 115019, Sept. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "S.W. Lee andH.Y. Kim"
            ],
            "title": "Stockmarket forecastingwith super-high dimensional time-series data using ConvLSTM, trend sampling, and specialized data augmentation",
            "venue": "Expert Syst. Appl., vol. 161, p. 113704, Dec. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "T.B. Shahi",
                "A. Shrestha",
                "A. Neupane",
                "andW. Guo"
            ],
            "title": "Stock price forecasting with deep learning: A comparative study",
            "venue": "Mathematics, vol. 8, no. 9, p. 1441, Aug. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "X. Li",
                "P. Tang"
            ],
            "title": "Stock index prediction based on wavelet transform and FCD-MLGRU",
            "venue": "J Forecast, vol. 39, no. 8, pp. 1229-1237, Mar. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Xiang",
                "X.H. Zhuang"
            ],
            "title": "Application of ARIMAModel in Short-Term Prediction of International Crude Oil Price",
            "venue": "Adv Mat Res, vol. 798-799, pp. 979-982, Sept. 2013.",
            "year": 2013
        },
        {
            "authors": [
                "S.C. Hillmer",
                "G.C. Tiao"
            ],
            "title": "An ARIMA-Model-Based Approach to Seasonal Adjustment",
            "venue": "J Am Stat Assoc, vol. 77, no. 377, pp. 63-70, Mar. 1982.",
            "year": 1982
        },
        {
            "authors": [
                "C.-l. Zhao",
                "B. Wang"
            ],
            "title": "Forecasting Crude Oil Price with an Autoregressive IntegratedMovingAverage (ARIMA)Model",
            "venue": "inFuzzy Information& Engineering and Operations Research & Management, Berlin Heidelberg, 2014, pp. 275-286.",
            "year": 2014
        },
        {
            "authors": [
                "N.E. Huang"
            ],
            "title": "The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis",
            "venue": "Proc. R. Soc. Lond. A., vol. 454, no. 1971, pp. 903-995, Mar. 1998.",
            "year": 1971
        },
        {
            "authors": [
                "Z. Wu",
                "N.E. Huang"
            ],
            "title": "Ensemble empirical mode decomposition: A noise-assisted data analysis method",
            "venue": "Advances in Adaptive Data Analysis, vol. 1, no. 1, pp. 1-41, Jan. 2009.",
            "year": 2009
        },
        {
            "authors": [
                "F. Zhou",
                "Z. Huang",
                "C. Zhang"
            ],
            "title": "Carbon price forecasting based on CEEMDAN and LSTM",
            "venue": "Appl. Energy, vol. 311, p. 118601, Apr. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "M.E. Torres",
                "M.A. Colominas",
                "G. Schlotthauer",
                "P. Flandrin"
            ],
            "title": "A complete ensemble empirical mode decomposition with adaptive noise",
            "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Prague, Czech Republic, 2011, pp. 4144-4147, doi: 10.1109/ICASSP.2011.5947265.",
            "year": 2011
        },
        {
            "authors": [
                "J. Wang",
                "X. Li",
                "T. Hong",
                "S. Wang"
            ],
            "title": "A semi-heterogeneous approach to combining crude oil price forecasts",
            "venue": "Inform Sciences, vol. 460-461, pp. 279-292, Sept. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "T. Zhang",
                "Z. Tang",
                "J. Wu",
                "X. Du",
                "K. Chen"
            ],
            "title": "Multi-step-ahead crude oil price forecasting based on two-layer decomposition technique and extreme learningmachine optimized by the particle swarm optimization algorithm",
            "venue": "Energy, vol. 229, p. 120797, Aug. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "L. Yu",
                "W. Dai",
                "L. Tang"
            ],
            "title": "A novel decomposition ensemble model with extended extreme learning machine for crude oil price forecasting",
            "venue": "Eng Appl Artif Intell, vol. 47, pp. 110-121, Jan. 2016.",
            "year": 2016
        },
        {
            "authors": [
                "H. Abdollahi"
            ],
            "title": "A novel hybrid model for forecasting crude oil price based on time series decomposition",
            "venue": "Appl. Energy, vol. 267, p. 115035, Jun. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "Y. Huang",
                "Y. Deng"
            ],
            "title": "A new crude oil price forecasting model based on variational mode decomposition",
            "venue": "Knowl Based Syst, vol. 213, p. 106669, Feb. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "J. Sun",
                "P. Zhao",
                "S. Sun"
            ],
            "title": "A new secondary decompositionreconstruction-ensemble approach for crude oil price forecasting",
            "venue": "Resour. Policy, vol. 77, p. 102762, Aug. 2022.",
            "year": 2022
        },
        {
            "authors": [
                "S. Zhang",
                "J. Luo",
                "S.Wang",
                "F. Liu"
            ],
            "title": "Oil price forecasting: A hybrid GRU neural network based on decomposition-reconstruction methods",
            "venue": "Expert Syst. Appl., vol. 218, p. 119617, May 2023.",
            "year": 2023
        },
        {
            "authors": [
                "K. Zheng"
            ],
            "title": "A Multi-Scale Electricity Consumption Prediction Algorithm Based on Time-Frequency Variational Autoencoder",
            "venue": "IEEE Access, vol. 9, pp. 90937-90946, Apr. 2021.",
            "year": 2021
        },
        {
            "authors": [
                "K. Cho"
            ],
            "title": "Learning phrase representations using RNN encoderdecoder for statistical machine translation",
            "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar, 2014, pp. 1724-1734.",
            "year": 2014
        },
        {
            "authors": [
                "G.G. R",
                "A.S. Babu"
            ],
            "title": "Hybrid Deep Learning Model to Forecast Crude Oil Price",
            "venue": "International Conference on Inventive Computation Technologies, ICICT 2023, Lalitpur, Nepal, 2023, pp. 19-23.",
            "year": 2023
        },
        {
            "authors": [
                "J. Nasir",
                "M. Aamir",
                "Z.U. Haq",
                "S. Khan",
                "M.Y. Amin",
                "M. Naeem"
            ],
            "title": "A New Approach for Forecasting Crude Oil Prices Based on Stochastic and Deterministic Influences of LMD Using ARIMA and LSTMModels",
            "venue": "IEEE Access, vol. 11, pp. 14322-14339, Feb. 2023.",
            "year": 2023
        },
        {
            "authors": [
                "S. Borovkova",
                "I. Tsiamas"
            ],
            "title": "Text-based crude oil price forecasting: A deep learning approach",
            "venue": "Int J Forecast, vol. 35, no. 4, pp. 1548-1560, Oct. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "M. Li",
                "Z. Cheng",
                "W. Lin",
                "Y. Wei",
                "S. Wang"
            ],
            "title": "What can be learned from the historical trend of crude oil prices? An ensemble approach for crude oil price forecasting",
            "venue": "Energy Econ, vol. 123, p. 106736, Jul. 2023.",
            "year": 2023
        },
        {
            "authors": [
                "Q. Zhu",
                "F. Zhang",
                "S. Liu",
                "Y. Wu",
                "L. Wang"
            ],
            "title": "A hybrid VMD-BiGRU model for rubber futures time series forecasting",
            "venue": "Appl. Soft Comput., vol. 84, p. 105739, Nov. 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Y. Fang",
                "W. Wang",
                "P. Wu",
                "Y. Zhao"
            ],
            "title": "A sentiment-enhanced hybrid model for crude oil price forecasting",
            "venue": "Expert Syst. Appl., vol. 215, p. 119329, Apr. 2023.",
            "year": 2023
        },
        {
            "authors": [
                "J.-W. Bi",
                "H. Li",
                "Z.-P. Fan"
            ],
            "title": "Tourism demand forecasting with time series imaging: A deep learningmodel,\"Ann",
            "venue": "Tour. Res.,",
            "year": 2021
        },
        {
            "authors": [
                "G. Zhang",
                "J. Guo"
            ],
            "title": "A novel ensemble method for hourly residential electricity consumption forecasting by imaging time series",
            "venue": "Energy, vol. 203, p. 117858, Jul. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "R. Kadari",
                "Y. Zhang",
                "W. Zhang",
                "T. Liu"
            ],
            "title": "CCG supertagging via Bidirectional LSTM-CRF neural architecture",
            "venue": "Neurocomputing, vol. 283, pp. 31-37, Mar. 2018.",
            "year": 2018
        },
        {
            "authors": [
                "K. Dragomiretskiy",
                "D. Zosso"
            ],
            "title": "Variational mode decomposition",
            "venue": "IEEE Trans. Signal Process., vol. 62, no. 3, pp. 531-544, Nov. 2014.",
            "year": 2014
        },
        {
            "authors": [
                "X. Li",
                "Y. Kang",
                "F. Li"
            ],
            "title": "Forecasting with time series imaging",
            "venue": "Expert Syst. Appl., vol. 160, p. 113680, Dec. 2020.",
            "year": 2020
        },
        {
            "authors": [
                "J.P. Eckmann",
                "O. Oliffson Kamphorst",
                "D. Ruelle"
            ],
            "title": "Recurrence plots of dynamical systems",
            "venue": "EPL, vol. 4, no. 9, pp. 973-977, Nov. 1987.",
            "year": 1987
        },
        {
            "authors": [
                "Z. Wang",
                "T. Oates"
            ],
            "title": "Imaging time-series to improve classification and imputation",
            "venue": "Proceedings of the 24th International Conference on Artificial Intelligence (IJCAI\u201915), AAAI Press, 2015, pp. 3939-3945.",
            "year": 2015
        },
        {
            "authors": [
                "X. Glorot",
                "A. Bordes",
                "Y. Bengio"
            ],
            "title": "Deep sparse rectifier neural networks",
            "venue": "Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, JMLR Workshop and Conference Proceedings, 2011, pp. 315-323.",
            "year": 2011
        },
        {
            "authors": [
                "D.P. Kingma",
                "J.L. Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, 2015.",
            "year": 2015
        },
        {
            "authors": [
                "F.X. Diebold",
                "R.S. Mariano"
            ],
            "title": "Comparing Predictive Accuracy",
            "venue": "J Bus Econ Stat, vol. 13, no. 3, pp. 253-263, Jul. 1995.",
            "year": 1995
        },
        {
            "authors": [
                "E. Zhao",
                "P. Du",
                "S. Sun"
            ],
            "title": "Historical pattern recognition with trajectory similarity for daily tourist arrivals forecasting,\"Expert",
            "venue": "Syst. Appl.,",
            "year": 2022
        },
        {
            "authors": [
                "K. Ijaz",
                "Z. Hussain",
                "J. Ahmad",
                "S.F. Ali",
                "M. Adnan",
                "I. Khosa"
            ],
            "title": "A Novel Temporal Feature Selection Based LSTMModel for Electrical Short-Term Load Forecasting",
            "venue": "IEEE Access, vol. 10, pp. 82596-82613, Aug. 2023.",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "INDEX TERMS Crude oil price forecasting, deep learning, variational mode decomposition, time-series imaging, bidirectional gated recurrent unit.\nI. INTRODUCTION\nCRUDE oil is one of the essential energy sources formodern industrial production and transportation, often referred to as the \"lifeblood of industry.\" With the globalization of the economy and financial markets, fluctuations in crude oil prices impact global economic stability and development. According to the International Energy Agency (IEA), crude oil constituted 30.9% of the global total energy supply in 2019, establishing it as the largest primary energy source [1]. Fluctuations in crude oil prices can significantly affect global economic stability. For instance, the 2008 global financial crisis was exacerbated by the sharp increase in crude\noil prices, which reached a peak of $145.31 per barrel in June 2008 [2]. The surge in oil prices contributed to the economic downturn by reducing consumer spending and increasing production costs. Conversely, the drastic year-overyear decline of 31.9% in crude oil prices in 2014 imposed notable economic hardships on oil-exporting nations, thereby impeding their fiscal stability and prospects for development [3]. Therefore, accurate forecasting of crude oil prices is of significant importance for energy policy formulation, risk management, and investment decision-making [4], [5]. The main characteristics of crude oil price time series data are non-stationarity, non-linearity, and high volatility\nVOLUME 11, 2023 1\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\n[6]. Various unstable factors, including economic conditions, political events, and trader expectations, exert influence on oil prices [7]. All of these factors make accurate price prediction challenging and pose significant difficulties in forecasting. Traditional methodologies for time series analysis, such as moving average (MA), exponential smoothing (ES), and autoregressive integrated moving average (ARIMA) [8], have proven inadequate in achieving satisfactory predictions. With advancements in computer technology, deep learning methods have been successfully applied to forecasting crude oil price time series, particularly recurrent neural networks (RNN) [9], long short-term memory (LSTM) [10]\u2013 [15], and gated recurrent unit (GRU) [16], [17]. Leveraging their strong capabilities in handling substantial volumes of data and capturing non-linear relationships, deep learning models outperform their linear counterparts in predicting crude oil prices. However, the persistent non-stationarity exhibited by crude oil prices continues to negatively impact the predictive performance of deep learning models, indicating the need for further enhancement. Furthermore, historical time series encompass a multitude of implicit features, and recurrent neural network models face certain limitations in uncovering these latent features, thus necessitating the exploration of more effective methodologies.\nTo overcome these challenges and improve the accuracy of crude oil price forecasting, we propose a novel forecasting framework that combines variational mode decomposition (VMD), time series imaging, and deep learning. Our approach is entirely data-driven, without any assumption or additional search for auxiliary data potentially related to crude oil prices. Specifically, our framework consists of the following five steps: 1) Data preprocessing: The original data are standardized by division to reduce the influence of scale variance in the time series. 2) Decomposing subsequences by the VMD: The non-stationary time series is decomposed into simple, stationary intrinsic mode function (IMF) series with certain periodic patterns. 3) Time series image generation: We employ three time series imaging techniques, Recurrence Plot (RP), Gramian Angular Field (GAF), and Markov Transition Field (MTF), respectively, to transform the one-dimensional IMF series into two-dimensional images, which reveal more features of these series and facilitate subsequent processing by Convolutional Neural Network (CNN). 4) Image feature extraction using CNN: By leveraging the powerful computational vision capabilities of CNN, we extract and utilize the hidden features embedded in the time series, avoiding the need for manually collecting additional auxiliary data. 5) Forecasting through Bidirectional Gated Recurrent Unit Network (BGRU): We employ the BGRU module to extract information from both the forward and backward directions, train the model, and obtain the final prediction results.\nOur primary contributions can be summarized as follows: (1) The originality of this study lies in the proposal of three new hybrid forecasting models, namely VMD-RP-BGRU, VMD-GAF-BGRU, and VMD-MTF-BGRU, based on different time series imaging techniques. These models inte-\ngrate the advantages of VMD, time series imaging, CNN, and BGRU. We applied the proposed methods to publicly available West Texas Intermediate (WTI) crude oil price data to evaluate their performance. Comparative experimental results demonstrate that our proposed VMD-RP-BGRU model achieves the best prediction performance, followed by VMDMTF-BGRU and VMD-GAF-BGRU. Specifically, VMDGAF-BGRU, VMD-MTF-BGRU, and VMD-RP-BGRU exhibit a MAE reduction of 21.64%, 23.15%, and 36.46% compared to the SARIMA model, and 21.18%, 22.70%, and 36.08% compared to the HWES model, respectively. (2) We have, for the first time, employed the time series imaging technique to analyze the time series of crude oil prices. By transforming one-dimensional subseries into twodimensional image matrices, additional feature information embedded in the sequence is revealed, thereby enhancing the performance of crude oil price forecasting. Ablation experimental results demonstrate a significant improvement in the predictive performance of the crude oil price time series through the use of Recurrence Plot (RP) time series imaging. Specifically, after employing the RP time series imaging method, there was a reduction of 27.51% in MAE, 41.62% in MSE, and 24.29% in MAPE, while the coefficient of determination R2 increased by 4.61%. (3) Our study expands the research on crude oil price forecasting and enhances the theoretical framework of deep learning-based time series prediction methods, thereby contributing to the field. Moreover, our approach proves to be effective and holds the potential to provide valuable guidance to energy policy-makers, macroeconomic regulators, and investors. While our approach shows promising results, it is important to acknowledge its limitations. Currently, our methodology solely relies on univariate analysis and does not consider the influence of other significant factors or exogenous variables. However, to further enhance the accuracy of predictions, future research endeavors can explore the incorporation of additional variables, such as news media and search engine data. The subsequent sections of this paper are structured as follows. Section 2 provides an overview of the related work in crude oil price forecasting. Section 3 presents the methodology proposed in this study. Section 4 substantiates the effectiveness and superiority of our proposed approach by means of comparative analyses with existing methods and ablation experiments. The last section provides a summary and conclusion for the paper."
        },
        {
            "heading": "II. RELATED WORK",
            "text": "Developing an accurate prediction method to forecast future price fluctuations in the oil market has consistently been a focal point for investors. Traditional statistical techniques offer various models for time series analysis, such as the autoregressive moving average (ARMA) model [8] and the autoregressive integrated moving average (ARIMA) model ( [8], [18], [19]). For example, [20] applied the ARIMA tech-"
        },
        {
            "heading": "2 VOLUME 11, 2023",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nnique to forecast oil prices and observed reasonable predictions for the annual average oil prices worldwide. However, these statistical methods rely on assumptions of stationarity and linearity, rendering their performance inadequate when applied to non-stationary and chaotic forecasting of crude oil prices.\nTo address the non-stationarity, extreme irregularity, and multiscale variability of crude oil prices, an increasing number of studies have adopted a sequence decomposition approach. This approach decomposes the original time series data into several fixed components using various decomposition techniques, which often exhibit certain stationarity and regularity. The main decomposition methods include empirical mode decomposition (EMD) [21] and its variants [22]\u2013 [24], wavelet analysis [25], and VMD [26]. [27] utilized the ensemble empirical mode decomposition (EEMD) combinedwith extreme learningmachines (EELM) to predict spot prices of crude oil. Using a dataset of crude oil spot prices of West Texas Intermediate (WTI), their proposed EEMDEELM-ADD model demonstrated the highest prediction accuracy, which was statistically confirmed by the DieboldMariano (DM) test with a 90% confidence level. In another study, [28] constructed a hybrid model consisting of complete ensemble empirical mode decomposition (CEEMD), support vector machines (SVM), particle swarm optimization (PSO), and Markov-switching generalized autoregressive conditional heteroskedasticity to more effectively capture the nonlinearity and volatility of crude oil price time series. Using daily closing prices of WTI crude oil, their hybrid model achieved a MAE of 0.042, RMSE of 0.053, and MAPE of 0.057, outperforming SVM-PSO and MSGARCHmodels. [29] introduced a new forecasting approach for oil price prediction by combining VMD, LSTM networks, and a moving window strategy, known as the VMDLSTM-MWmodel. Using monthly WTI data, their proposed model exhibited significantly better MAPE compared to the VMD-GA-SVM model, EEMD-GA-SVM model, GA-SVM model, and ARIMA model, with relative improvements of 35.39%, 40.16%, 72.06%, and 67.23%, respectively. Additionally, [30] utilized an improved complete ensemble empirical mode decomposition with adaptive noise (ICEEMDAN) method to decompose the original crude oil futures price series into a set of subseries and reconstructed them into high-frequency, low-frequency, and trend components using permutation entropy (PE). Their proposed ICEEMDAN-PEEMD-PSR-CSSA-KELM model achieved significant reductions of 52%, 49.8%, and 44.8% inMAE,MAPE, and RMSE, respectively, in one-step ahead forecasting for Brent crude oil futures prices compared to the PSR-KELM model. Furthermore, [31] proposed two hybrid predictors based on RNN, employing VMD, sample entropy (SE), and GRUs for oil price prediction. Using theWTI dataset, their VMD-SE-GRU framework exhibited a RMSE of 0.6735, MAE of 0.4585, MAPE of 0.8059, and an R2 value of 0.9272.\nWith the development of artificial intelligence (AI), machine learning models are increasingly being used for time\nseries forecasting. Themainmachine learningmodels include LSTM ( [12], [29], [32]) and GRU ( [31], [33]). Compared to traditional statistical techniques, AI-based models do not require any assumptions about the data distribution. They possess good generalization and self-learning abilities, leading to a significant improvement in forecasting accuracy. For example, [34] proposed a hybrid method combining LSTM and GRU architectures for crude oil price forecasting and addressed challenges such as long-term dependencies, overfitting, and hyperparameter tuning. Experimental results using daily crude oil price data demonstrated that their hybrid model slightly outperforms the individual LSTM and GRU models. [35] proposed a new hybrid forecasting technique based on local mean decomposition (LMD), ARIMA and LSTM models to improve the accuracy of crude oil price forecasting. Experimental results using WTI crude oil price data showed that their LMD-SD-ARIMA-LSTMmodel achieves anMAEof 0.106 andMAPE of 1.124. [36] proposed a text-driven crude oil price forecasting method based on CNN and LSTM, which uses text information from various sources such as social media, news and expert comments to capture the impact of market sentiment and expectations on crude oil price fluctuations. Results indicated that the SVR model incorporating text and financial features outperforms the model using only financial features, with improvements of 6.67% and 2.5% in MAE and RMSE, respectively. [37] proposed a learning paradigm that combines the trajectory similarity (TS) method, VMD, and sample entropy (SE) to forecast nonlinear and highly volatile crude oil price series, and achieved better performance than benchmarks by using LSTM networks and ARIMA models. For the Brent dataset, theMAPE of their TSmodel was reduced by 45.66%, 59.55%, 55.12%, 44.08%, and 30.07% compared to Snaive, SVR, ELM, ANN, and LSTM, respectively. Unlike previous deep learning models that assumed unidirectional relationships in time series data, the BGRU method enhances model performance by extracting information from both forward and backward directions [38]. For example, [39] integrated news sentiment analysis, variational mode decomposition, attention mechanism, and BGRU for oil price forecasting, improving forecasting performance by capturing both qualitative and quantitative information. Experimental results using daily WTI crude oil futures price data demonstrated that their FinBERT-VMD-Att-BiGRU model achieves an RMSE of 0.0077 and MAE of 0.0049 for one-step ahead prediction. In recent years, there have been significant advancements in computer vision technologies, which are gradually finding applications in the field of forecasting. One emerging area of research involves utilizing deep learning architectures with imaging techniques for time series forecasting. However, the utilization of time series imaging methods in the domain of crude oil price forecasting remains relatively unexplored. Time series imaging has proven to be an effective approach for analyzing time-dependent data and has demonstrated its efficacy in various domains, including tourism demand forecasting [40], drought prediction [41], and residential\nVOLUME 11, 2023 3\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nelectricity consumption forecasting [42]. These studies have provided evidence of the ability of time series imaging to enhance prediction accuracy. Specifically, combining time series imaging with CNN can fully leverage the advantages of CNN in computer vision processing and enhance the accuracy of time series forecasting.\nIn view of this, this study takes into account the nonstationarity and complex variations of crude oil price fluctuations. By integrating VMD, time series imaging techniques, CNN, and BGRU, this study aims to fully leverage the strengths of VMD in non-stationary sequence decomposition, time series imaging in feature representation, CNN in image processing, and BGRU in sequence data handling. Through comparative experiments, the superiority of the proposed forecasting framework is demonstrated.\nIII. METHODOLOGY A. METHODOLOGICAL FRAMEWORK AND PRINCIPLE Fig. 1 illustrates the comprehensive framework of the methodology proposed in this research. The methodology comprises five components: 1) Data preprocessing; 2) Decomposing subsequences by the VMD; 3) Time series image generation; 4) Image feature extraction using CNN; 5) Forecasting through BGRU.\nIn the data preprocessing stage, the raw time series data are transformed into the required format for subsequent modeling using a normalization method, eliminating the prediction challenges caused by scale variance. Since crude oil prices exhibit continuous fluctuation and are non-stationary time series, the VMD component is used to decompose multiple subsequences used for forecasting the crude oil price in the next period. Each subsequence is decomposed into a set of IMF series that exhibit certain periodic patterns.\nIn the time series image generation module, the onedimensional IMF sequence is transformed into twodimensional image data using time series imaging techniques. This transformation is crucial for revealing the relationship between observations with different time lags in the IMF. It captures the temporal correlations and patterns of various components of crude oil prices series in response to environmental factors, which are helpful for forecasting future price changes.\nIn the next section, leveraging the powerful computer vision processing capability of CNN, features from each time series image are gradually extracted using convolutional kernels, capturing local feature information. Subsequently, the dimensionality of the results from the convolutional layers is reduced through pooling layers. This aims to retain essential information while reducing computational complexity. Additionally, it helps prevent overfitting and improves the model\u2019s generalization ability. Finally, the features extracted by the CNN module are transformed into the input format required by the BGRU network through fully connected layers.\nThe last module is the BGRU network, which consists of a two-layer GRU network that is trained simultaneously in both forward and backward directions along the time sequence.\nThe outputs from both directions are then concatenated and fed into an output layer. As proposed by [43], time series data are bidirectional, meaning that the current state reflects the past state and forms the basis for the future state. Therefore, BGRU is more advantageous in capturing the long-term correlations of time series observations as a whole. The CNNBGRU model is trained using the Adam optimizer with the objective of minimizing MSE to obtain the predictive model for forecasting future crude oil prices. In summary, in our proposed method, the strengths of VMD in non-stationary sequence decomposition, time series imaging in feature representation, CNN in image processing, and bidirectional GRU in sequence data handling are fully leveraged."
        },
        {
            "heading": "B. THE SPECIFIC PROCESS OF THE METHOD",
            "text": "The detailed expansion of the steps shown in Fig. 1 is described below."
        },
        {
            "heading": "1) Data preprocessing",
            "text": "To accurately forecast crude oil prices, our prediction model must capture both the global and local variations inherent in the time series data. The global variation primarily arises from scale (or level) variance, while the local variation is characterized by local nonlinear trends that encompass recurring patterns and temporary relationships. Deep learning models have strong nonlinear fitting capabilities and can effectively capture and model local variations in time series. However, they often encounter challenges when dealing with scale variance. By eliminating scale variation, deep learning models can fully utilize their nonlinear fitting capabilities, outputting improved forecasts. In this paper, we employ a division-based method known as scale normalization for preprocessing the raw data. Scale normalization involves dividing the current value by the previous value, as denoted by the equation:\nxt = yt yt\u22121 , (1)\nwhere yt represents the crude oil price at the current time, yt\u22121 represents the crude oil price at the previous time, and xt represents the normalized value of the time series at the current time. The normalized series of crude oil prices can be represented as a vector\nx = (x1, x2, \u00b7 \u00b7 \u00b7 , xt) . (2)\nWe forecast the future value xt+1 using multiple historical subsequences in x. Each subsequence is defined with a length referred to as the \"image size\" (denoted asM ). A subsequence used for predicting xt+1 can be represented as:\nst = (xt\u2212M+1, \u00b7 \u00b7 \u00b7 , xt\u22121, xt) . (3)"
        },
        {
            "heading": "2) Decomposing subsequences by VMD",
            "text": "Let f (t) represent an original sequence that undergoes decomposition using the VMD module, generating K decomposed signals, i.e., IMF series. VMD is an adaptive and fully"
        },
        {
            "heading": "4 VOLUME 11, 2023",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nnon-recursive method for mode variation and signal processing. This technique has the advantage of determining the number of mode decompositions. Its adaptability is demonstrated by determining the appropriate number of mode decompositions based on the specific situation of the given sequence. Subsequently, in the search and solving process, it can adaptively match the optimal center frequency and finite bandwidth for each mode and effectively separate the IMFs, thus obtaining the effective decomposition components of the given signal. For a detailed explanation of the principles of VMD, please refer to [44].\nLet {uk} = {u1, u2, . . . , uK} and {\u03c9k} = {\u03c91, \u03c92, . . . , \u03c9K} represent the k-th decomposed signal and the center frequency of the signal, respectively. \u03bbn denotes the noise tolerance in the n-th iteration calculation, which is used to satisfy the fidelity requirement of signal decomposition. u\u0302nk (\u03c9), f\u0302 (\u03c9) and \u03bb\u0302\nn (\u03c9) correspond to the Fourier transforms of unk (\u03c9), f (\u03c9) and \u03bb\nn (\u03c9) in the n-th iteration calculation, respectively. The main steps of VMD are as follows:\nStep 1. Let n = 0. Initialize {u\u03021k}, {\u03c91k }, \u03bb\u03021 and the max number of iterations N . Step 2. For each mode, update u\u0302nk and \u03c9 n k using the follow-\ning equations:\nu\u0302n+1k (\u03c9)= f\u0302 (\u03c9)\u2212\n\u2211 i<k u\u0302 n+1 i (\u03c9)\u2212 \u2211 i>k u\u0302 n i (\u03c9)+\u03bb\u0302 n(\u03c9)/2\n1 + 2\u03b1(\u03c9 \u2212 \u03c9nk ) 2 ,\n(4)\n\u03c9n+1k = \u222b\u221e 0 \u03c9 \u2223\u2223u\u0302n+1k (\u03c9)\u2223\u22232d\u03c9\u222b\u221e\n0 \u2223\u2223u\u0302n+1k (\u03c9)\u2223\u22232d\u03c9 . (5) Step 3. For each iteration, update \u03bbn by the following\nequation:\n\u03bb\u0302n+1(\u03c9) = \u03bb\u0302n(\u03c9) + \u03c4 [ f\u0302 (\u03c9)\u2212 \u2211 k u\u0302n+1k (\u03c9) ] . (6)\nStep 4. If \u2211\nk ( ||u\u0302n+1k \u2212 u\u0302nk ||22/||u\u0302nk ||22 ) < \u03b5 and n < N\nare not satisfied, return to Step 2; otherwise, complete the iteration and output the final {uk} and {\u03c9k}.\nVOLUME 11, 2023 5\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nIn this paper, K IMF series obtained from the decomposition of the subsequence st can be represented as:\nV (st ,K )=  ut,11 u t,1 2 \u00b7 \u00b7 \u00b7 u t,1 M ut,21 u t,2 2 \u00b7 \u00b7 \u00b7 u t,2 M ... ... . . . ...\nut,K1 u t,K 2 \u00b7 \u00b7 \u00b7 u t,K M\n=  vt,1 vt,2 ...\nvt,K  . (7)"
        },
        {
            "heading": "3) Time series image generation",
            "text": "The CNN model has demonstrated significant advantages in computer vision. However, when dealing with onedimensional IMF series, it becomes necessary to employ time series imaging techniques to convert the one-dimensional series into two-dimensional images. This conversion allows for the mapping of temporal correlations and patterns between each observation within the lag order to pixels in the resulting images. Consequently, CNNs are better equipped to recognize and learn these extracted features, facilitating improved performance in analysis tasks.\nThere are three commonly used time series imaging techniques: recurrence plot (RP) ( [45], [46]), Gramian angular field (GAF) [47], and Markov transition field (MTF) [47]. These techniques are capable of preserving the temporal and spatial relationships inherent in the time series data, as well as capturing essential characteristics such as periodicity and trend. By leveraging these transformation methods, we can effectively convert a complex time series analysis problem into a more manageable image classification problem. This conversion not only enhances the prediction accuracy but also improves computational efficiency [40].\nLet the vector X = (x1, x2, . . . , xn) denote the time series to be processed. The computational processes of these three techniques are as follows.\nRecurrence Plot (RP). RP technique is widely used to visualize the periodicity of trajectories in phase space, making it a valuable tool for analyzing the periodicity, non-stationarity, and chaos present in time series data. RP effectively captures the similarity and stability of the internal structure of time series, making it particularly suitable for analyzing short-term time series. The output values of each pixel in the original RP method are only 0 and 1. The process is as follows: First, the time-domain space of the time series is transformed into the phase space, where each point xi in the time domain is transformed into the corresponding state in the phase space:\n\u03c2i= ( xi, xi+\u03c4 , . . . , xi+(\u00b5\u22121)\u03c4 ) , i=1, 2, . . . , n\u2212(\u00b5\u22121)\u03c4, (8)\nwhere \u00b5 represents the dimension of the extracted trajectory, and \u03c4 denotes the time delay. Next, the distance (vector norm) between each pair of states is calculated, and threshold binarization is performed to obtain an n \u00d7 n recursive plot, where the calculation formula for each point in the image is:\ngRPi1,i2 = \u0398 (\u03b5\u2212 \u2016\u03c2i1 \u2212 \u03c2i2\u2016) , i1, i2 = 1, . . . , n, (9)\nwhere \u03b5 is the distance threshold that makes gRPi1,i2 \u2208 0, 1, and \u0398(\u00b7) represents the Heaviside function.\nGramian angular field (GAF). GAF technique utilizes the Gramian matrix and polar coordinate system to transform time series data into visual representations in the form of images. This encoding process enables the images to effectively capture the temporal correlation present within different time intervals. The calculation process for GAF is as follows: First, normalize X to the interval [\u22121, 1] to obtain X\u0303, where the formula for calculating the i-th element is:\nx\u0303i = 2xi \u2212max (X)\u2212min (X)\nmax (X)\u2212min (X) . (10)\nThen, X\u0303 is represented in polar coordinates based on the following formulas:{\n\u03d5i = arccos (x\u0303i) ri = iC , i = 1, 2, . . . , n, (11)\nwhere C is the constant factor used to regularize the span of the polar coordinates. Finally, the sequence represented in polar coordinates is transformed into a two-dimensional image of size n \u00d7 n, where the calculation formula for each point in the image is:\ngGAFi1,i2 = sin (\u03d5i1 \u2212 \u03d5i2) , i1, i2 = 1, 2, . . . , n. (12)\nThe resulting image effectively captures the temporal correlations within different time intervals.\nMarkov transition field (MTF). The fundamental concept behind the MTF technique is to convert time series data into image format using a Markov state transition matrix based on quantile bins. By preserving the temporal information within the sequence, the Markov transition probability captures the changes in the quantile bin to which the observed values belong. The calculation process for MTF is as follows: First, divideX into Q quantile bins to obtain B1,B2, . . . ,BQ. Then, calculate{\nwq1,q2 =P (xi\u22121\u2208bq1 |xi\u2208bq2)\u2211 q2 wq1,q2 = 1 ,\nq1, q2 = 1, 2, . . . ,Q, (13)\nto obtain a weighted adjacency matrix W = (wq1,q2)Q\u00d7Q. Finally, a two-dimensional image of size n \u00d7 n is obtained, where the value of each point in the image is:\ngMTFi1,i2 = wq1,q2 | (xi1 \u2208 Bq1 , xi2 \u2208 Bq2) , i1, i2 = 1, 2, . . . , n; q1, q2 = 1, 2, . . . ,Q. (14)\nBy employing time series imaging techniques, the IMF series from (7) can be transformed into images. Taking the k-th IMF series as an example, the expression is as follows:\nI# (vt,k)=  gt,k,#1,1 \u00b7 \u00b7 \u00b7 g t,k,# 1,m \u00b7 \u00b7 \u00b7 g t,k,# 1,M ... . . . ... . . . ... gt,k,#m,1 \u00b7 \u00b7 \u00b7 gt,k,#m,m \u00b7 \u00b7 \u00b7 g t,k,# m,M ... . . . ... . . .\n... gt,k,#M ,1 \u00b7 \u00b7 \u00b7 g t,k,# M ,m \u00b7 \u00b7 \u00b7 e t,k,# M ,M\n , (15)"
        },
        {
            "heading": "6 VOLUME 11, 2023",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nwhere # represents a time series imaging method, # \u2208 {RP,GAF ,MTF}.\nTo provide a more intuitive representation of these three types of images, we present typical examples of RP, GAF, and MTF images in Fig. 2. In these images, lighter regions correspond to higher values. It is apparent that applying the same method to different types of curves or employing different methods on the same curve leads to distinct images. In Case 1, the time series exhibits periodic trends, and the distribution of values in the three images clearly demonstrates periodicity. The regularity of value distribution is more pronounced in the GAF and RP images compared to the MTF image, and there is a certain level of complementarity between the GAF and RP images. In Case 2, the time series exhibits an increasing trendwith periodicity. The distribution of values in the RP image demonstrates a periodic increasing trend along the main diagonal axis, while the values in the GAF image cyclically increase from the bottom-left to the top-right. Conversely, the values in the MTF image exhibit a periodic decreasing trend along the main diagonal axis. In Case 3, the time series lacks any discernible pattern, and the corresponding distributions of values in the three types of images do not exhibit any regularity."
        },
        {
            "heading": "4) Image feature extraction using CNN",
            "text": "We utilize CNN to extract features from the time series images. The CNN model utilized in our approach consists of only one convolutional layer and one pooling layer. A single convolutional layer effectively detects features such as edges and shapes in the images, while multiple convolutional layers can introduce excessive complexity and redundancy, increasing computational costs and the risk of overfitting. A single pooling layer efficiently reduces the spatial dimensions of the feature maps while preserving the most prominent\nfeatures. This helps to reduce the number of parameters and computations in the network and prevents overfitting by providing a more abstract representation of the features. The use of multiple pooling layers may result in the loss of important information and excessive reduction in the resolution of the feature maps. Therefore, employing a single pooling layer is more appropriate for the current task. Let S# (vt,k) represent a submatrix of I# (vt,k) with a shape of f \u00d7 f , where f denotes the size of the filter matrix in the convolutional layer. We use grid search to determine the optimal value of the filter size f . Specifically, we have:\nS#(vt,k)f1,f2 =  gt,k,#f1,f2 \u00b7 \u00b7 \u00b7 g t,k,# f1,(f2+f\u22121) ... . . .\n... gt,k,#(f1+f\u22121),f2 \u00b7 \u00b7 \u00b7 g t,k,# (f1+f\u22121),(f2+f\u22121)  , f , f1, f2 \u2208 N+, f + f1, f + f2 6 M + 1. (16)\nThe feature extraction process by the convolution kernel weight matrix WCov \u2208 Rf\u00d7f (i.e., the filter) yields a feature ct,k,#f1,f2 , which is expressed as follows:\nct,k,#f1,f2 = \u03a6 [ WCov \u2217 S#(vt,k)f1,f2 + bCov ] , (17)\nwhere \u03a6 (\u00b7) is a nonlinear activation function, which is usually the rectified linear unit (ReLU) function defined as Relu(x) = max (x, 0). We use the ReLU activation function because it can increase the nonlinearity of the neural network, avoid the gradient vanishing problem that occurs when using sigmoid or tanh activation functions, and lower the computational cost of the neural network by only judging whether the input is greater than zero without performing exponential operations [48]. The asterisk symbol \u2217 denotes the convolution operation, and bCov represents the bias term\nVOLUME 11, 2023 7\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\ncorresponding to each layer. Through (17), the convolution feature matrix C# (vt,k) is calculated as follows:\nC# (vt,k)= ct,k,#1,1 \u00b7 \u00b7 \u00b7 c t,k,# 1,f2 \u00b7 \u00b7 \u00b7 c t,k,# 1,(M\u2212f+1) ... . . . ... . . . ... ct,k,#f1,1 \u00b7 \u00b7 \u00b7 c t,k,# f1,f2 \u00b7 \u00b7 \u00b7 c t,k,# f1,(M\u2212f+1) ... . . . ... . . .\n... ct,k,#(M\u2212f+1),1 \u00b7 \u00b7 \u00b7 c t,k,# (M\u2212f+1),f2 \u00b7 \u00b7 \u00b7 c t,k,# (M\u2212f+1),(M\u2212f+1)\n .\n(18)\nThen, we apply pooling operation to the convolution feature matrix to further reduce the dimensionality and extract salient features. Let the filter matrix size of the pooling layer be denoted as p \u00d7 p. The stride of the filter matrix in the pooling layer is given by s, and the size of the feature matrix after the pooling operation is D \u00d7 D. We can express this matrix as:\nP# (vt,k)=  zt,k,#1,1 \u00b7 \u00b7 \u00b7 z t,k,# 1,d2 \u00b7 \u00b7 \u00b7 z t,k,# 1,D ... . . . ... . . . ... zt,k,#d1,1 \u00b7 \u00b7 \u00b7 z t,k,# d1,d2 \u00b7 \u00b7 \u00b7 z t,k,# d1,D ... . . . ... . . .\n... zt,k,#D,1 \u00b7 \u00b7 \u00b7 z t,k,# D,d2 \u00b7 \u00b7 \u00b7 z t,k,# D,D\n . (19)\nTwo calculation methods exist for performing the pooling operation: average pooling and maximum pooling. The corresponding formulas are:\nzt,k,#d1,d2 = \u2211{ ct,k,#[1+(d1\u22121)s]:[p+(d1\u22121)s],[1+(d2\u22121)s]:[p+(d2\u22121)s] } /p2,\nd1, d2 = 1, 2, . . . ,D, and (20)\nzt,k,#d1,d2 = max { ct,k,#[1+(d1\u22121)s]:[p+(d1\u22121)s],[1+(d2\u22121)s]:[p+(d2\u22121)s] } ,\nd1, d2 = 1, 2, . . . ,D. (21)\nIn this paper, we implement the maximum pooling method. We use the maximum pooling method because it can reduce the dimensionality of images by extracting only the most salient features of the data, increase the translation invariance of the representation, lower the computational cost by reducing the number of parameters to learn, and prevent overfitting by providing an abstracted form of the representation. Flatten the obtained P# (vt,k), and then obtain a one-dimensional vector composed of D \u00d7 D elements: Z#t,k = ( zt,k,#1,1 , . . . , z t,k,# 1,D , . . . , z t,k,# D,1 , . . . , z t,k,# D,D ) . The onedimensional vectors obtained from above time series imaging and CNN processing for each IMF series are spliced together to form a fully connected layer. Hence, a new onedimensional vector composed of D \u00d7 D \u00d7 K elements is generated as follows:\nZ#t =(z t,1,# 1,1 , . . . , z t,1,# D,D , . . . , z t,2,# 1,1 , . . . ,\nzt,2,#D,D , . . . , z t,K ,# 1,1 , . . . , z t,K ,# D,D ). (22)"
        },
        {
            "heading": "5) Forecasting through BGRU",
            "text": "The number of subsequences used for training is defined as the \"Image Lag Period\" and denoted by J . The outputs of the fully connected layer in the previous step Z#t\u2212j+1, . . . ,Z # t\u22121,Z # t for j = 1, 2, . . . , J , are passed to a BGRU network [33], with a structure illustrated in Fig. 3(a), and a single cell of the network presented in Fig. 3(b). The network consists of three parts: a reset gate, an update gate, and a candidate hidden state. The computation formulas for each component in Fig. 3(b) are as follows:\nrt = \u03c3 (Wh,rht\u22121 + Wi,rIt + br) , (23)\nut = \u03c3 (Wh,uht\u22121 + Wi,uIt + bu) , (24)\nh\u0303t = tanh [Wr,c (rt \u2297 ht\u22121) + Wi,cIt + bc] , (25)\nht = (1\u2212 ut)\u2297 ht\u22121 + ut \u2297 h\u0303t , (26)\nwhere rt , ut , and h\u0303t represent the reset gate, update gate, and candidate hidden state, respectively. ht represents the hidden state. The symbol\u2297 denotes element-wisemultiplication.W represents the weight vectors for each component, and b represents the bias terms for each component. The function \u03c3 (x) = 1/[1 + exp(\u2212x)] is the sigmoid function, and tanh (x) = [exp(x) \u2212 exp(\u2212x)]/[exp(x) + exp(\u2212x)] is the hyperbolic tangent function. Moreover, the term (1\u2212 ut) \u2297 ht\u22121 determines the information to be retained in the previous hidden state, and ut \u2297 h\u0303t determines the information to be retained in the candidate hidden state. From Fig. 3(a), it can be observed that the BGRU connects the output state values of the hidden layer from the GRU in two different directions, and the expression is given by:\nHt = \u2212\u2192 h t \u2295 \u2190\u2212 h t , (27)\nwhere \u2212\u2192 h t and \u2190\u2212 h t represent the forward and backward states of the hidden layer in the GRU at the time t , the symbol \u2295 represents the concatenation operation, and Ht is the final output value of the BGRU. Finally, after passing through the fully connected layer, the output value can be obtained as:\nx\u0302t+1 = WxHt + bx , (28)\nwhere Wx and bx denote the weight and the bias term, respectively, of the final fully connected layer. Since the model is trained on normalized data, inverse normalization operation is required to obtain the forecasted value of the crude oil price at the next period, y\u0302t+1. The formula is given as:\ny\u0302t+1 = x\u0302t+1 \u00d7 yt , (29)\nwhere yt represents the actual crude oil price at the period t ."
        },
        {
            "heading": "8 VOLUME 11, 2023",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nC. TRAINING OF THE CNN-BGRU MODEL\nIn this study, the CNN-BGRU model is optimized using the Adam algorithm. The Adam algorithm is selected due to its faster convergence and superior learning performance when compared to other adaptive learning rate algorithms. Moreover, the Adam algorithm overcomes the limitations observed in alternative optimization techniques, such as unstable learning rates, slow convergence, and large fluctuations in the loss function resulting from high-variable parameter updates. For a comprehensive understanding of the Adam algorithm, we refer readers to the work of Kingma and Ba [49].\nWe employ grid search to determine an optimal initial learning rate, and use exponential decay to multiply the learning rate by 0.9 every 20 iterations. This approach accounts for the changes in the training process, as a fixed learning rate may not effectively adapt. As training progresses, a smaller learning rate becomes necessary to ensure convergence to a good local optimum and prevent oscillation. Exponential decay, a widely used method, allows the learning rate to decrease exponentially with the number of iterations, enabling smooth adaptation to the evolving training process.\nWe divide the training data into small batches of size 32 and calculate the loss function and gradient on each batch. The choice of this batch size balances model performance improvement and computational cost reduction. A smaller batch size can increase the generalization ability of themodel, avoid falling into local optima, and accelerates each iteration. Conversely, a larger batch size may cause the model to converge to sharp minima, which compromises generalization. By selecting 32 as the batch size, we satisfy the memory requirements of most CPUs and GPUs while maintaining a suitable balance.\nWe set a maximum number of iterations to 800, which is an empirical value that can achieve a balance between ensuring model convergence and avoiding overfitting. Insufficient\niterations may result in underfitting, where the model fails to fully capture the data\u2019s underlying features and patterns. Conversely, an excessive number of iterations may lead to overfitting, causing the model to struggle with adapting to new data. To address overfitting, we employ an early stopping strategy. If the validation set\u2019s loss function fails to improve for 40 consecutive iterations, we halt the training process. This adaptive approach dynamically adjusts the number of iterations based on the model\u2019s actual performance, preventing overfitting and unnecessary computations."
        },
        {
            "heading": "D. EVALUATION METRICS",
            "text": "To assess and compare the forecast performance of various models, this study employs four evaluation metrics to gauge the accuracy of the forecasts: absolute error (AEt ), mean absolute error (MAE), root mean square error (RMSE), mean absolute percentage error (MAPE), and determination coefficient R2. Smaller values of AEt , MAE, RMSE, and MAPE indicate better forecast accuracy, with predicted values being closer to actual values, and reflecting the high forecast performance of the model. Conversely, a larger value of the determination coefficient R2 suggests a better training result of the model. The calculation formulas for these metrics are provided below:\nAEt = |y\u0302t \u2212 yt | , (30)\nMAE = 1\nT T\u2211 t=1 |y\u0302t \u2212 yt |, (31)\nRMSE = \u221a\u221a\u221a\u221a 1 T T\u2211 t=1 (y\u0302t \u2212 yt)2, (32)\nVOLUME 11, 2023 9\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nMAPE = 1\nT T\u2211 t=1 \u2223\u2223\u2223\u2223 y\u0302t \u2212 ytyt \u2223\u2223\u2223\u2223, (33)\nR2 = 1\u2212 \u2211\n(y\u0302t \u2212 yt)2\u2211 (yt \u2212 y\u0304) , (34)\nwhere y\u0307t , yt and y\u0304 represent the forecasted value, the actual value, and the mean actual value, respectively.\nTo assess whether the proposed method exhibits superior forecasting accuracy compared to a benchmark model from a statistical perspective, we employ Diebold-Mariano (DM) test [50]. The null and alternative hypotheses for this test are formulated as follows:\nH0 : E [ L ( e1t )] = E [ L ( e2t )] , (35) H1 : E [ L ( e1t )] 6= E [ L ( e2t )] , (36)\nwhere L (\u00b7) is loss function of forecasting, e1t and e2t are the forecasting errors of the two models. The DM test is calculated by\nDM =\n1 T T\u2211 t=1 [ L ( e1t ) \u2212 L ( e2t )]\n\u221a S2/T\nS2, (37)\nwhere S2 is an estimator of the variance [ L ( e1t ) \u2212 L ( e2t )] . If DM < 0, the model 1 is superior to the model 2; otherwise, the model 2 is superior to the model 1.\nIV. EXPERIMENTS AND ANALYSIS A. DATA The time series data of international crude oil prices is obtained from the U.S. Energy Information Administration (EIA) website (https://www.eia.gov/dnav/pet/pet_pri_spt_s1 _w.htm). The dataset comprises weekly spot prices FOB of the Oklahoma Cushing WTI crude oil, spanning from June 19, 1998, to May 12, 2023. Table 1 presents the descriptive statistics of the dataset, which consists of 1300 data points with a mean of 59.89 and a variance of 27.48. The range of values spans from 3.32 to 142.52. Fig. 4 (a) illustrates the line graph of the crude oil price time series, while Fig. 4 (b) visualizes the normalized series calculated using (1).\nTABLE 1. Descriptive statistic.\nItem Value count 1300 mean 59.89 std 27.48 min 3.32 25% 36.73 50% 57.98 75% 80.77 max 142.52"
        },
        {
            "heading": "B. EXPERIMENTAL ENVIRONMENT AND EXPERIMENTAL DESIGN",
            "text": "The hardware environment for this experiment consists of an Intel Xeon Platinum 8255C @ 2.50GHz CPU with 12 cores, an NVIDIA GeForce RTX 3090 GPU, and an ubuntu20.04 systemwith 43GB ofmemory. The development environment includes Python 3.8, Cuda 11.2, and TensorFlow 2.9.0. The dataset from September 18, 1998, to March 8, 2019, containing 1069 weeks, is chosen as the training set for model training. The dataset from March 15, 2019, to June 11, 2021, containing 118 weeks, is selected as the validation set to determine the optimal hyperparameters. The dataset from June 18, 2021, toMay 12, 2023, containing 100weeks, is used as the testing set to evaluate the performance of the model. During training, the maximum number of training epochs is set to 800, batch size to 32, and the loss function to MSE."
        },
        {
            "heading": "C. SELECTION OF HYPERPARAMETERS",
            "text": "The proposed models involve several hyperparameters, including K , image size, image lag period, filter number, kernel size, GRU units, and initial learning rate. In this study, we utilize random grid search to determine the optimal hyperparameters by conducting multiple experiments and comparing the performance of the validation set. The selected hyperparameters for the proposed forecasting models are presented in Table 2."
        },
        {
            "heading": "D. RESULTS AND DISCUSSION",
            "text": "This section is divided into comparative experiments and ablation experiments."
        },
        {
            "heading": "1) Comparison with Existing Methods",
            "text": "The experiments conducted in this section compare the proposed method with the following benchmark models. MA: Moving Average model, ARIMA: Autoregressive Integrated Moving Average model, SARIMA: Seasonal Autoregressive Integrated Moving Average model, and HWES: Holt-Winters Exponential Smoothing model. \u2022 MA: The MA model is a widely employed technique\nfor smoothing time series data and reducing random fluctuations. It calculates the moving average based on past data to derive the forecasted value. \u2022 ARIMA: The ARIMA model is a general and flexible approach that can capture various patterns and structures in time series data. By integrating autoregression (AR) and differencing, the ARIMA model extends the capabilities of the MA model, enabling the elimination of seasonality and trends present in the data. \u2022 SARIMA: The SARIMA model is suitable for data that exhibits periodic or cyclical patterns over time. It is an extension of the ARIMA model that takes into account seasonal factors. \u2022 HWES: The HWES model is a popular and robust method that can handle data with both additive and multiplicative seasonality. By applying exponential smoothing to historical data, the HWES model generates a"
        },
        {
            "heading": "10 VOLUME 11, 2023",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nweighted average that effectively captures changes in trends.\nAccording to different time series imaging techniques used, we propose three models: VMD-GAF-BGRU, VMDMTF-BGRU, and VMD-RP-BGRU, based on our methodology. These models have the same components of VMD and deep learning, but differ in their utilization of GAF, MTF, and RP algorithms for generating time series images. The experimental results, highlighting the best-performing values in bold, are presented in Table 3. To facilitate an easier comparison between the models, we provide Fig. 5. From Table 3 and Fig. 5, the following can be observed:\nIn terms of MAE and MAPE metrics, the forecasting performance ranking is: VMD-RP-BGRU VMD-MTF-BGRU VMD-GAF-BGRU HWES SARIMA ARIMA MA. In terms of MSE and R2 metrics, the forecasting performance ranking is: VMD-RP-BGRU VMD-GAF-BGRU VMD-MTF-BGRU HWES SARIMA ARIMA\nMA. The symbol A B indicates that method A outperforms method B. In summary, based on any of the evaluation metrics, our proposed VMD-RP-BGRU model demonstrates the best predictive performance, followed by the VMD-MTFBGRU and VMD-GAF-BGRU models.\nThere are several possible reasons for the superior performance of our proposed method, which combines VMD, timeseries imaging, and BGRU: 1) The nonlinearity and complexity of crude oil price data can be effectively addressed by VMD, which decomposes the complex nonlinear signal into a set of basic mode functions representing different frequency oscillatory components in the signal. By decomposing the signal, local features and patterns can be better captured, thereby improving the representation capability of the signal. 2) Timeseries imaging leverages patterns and trends from historical data for prediction. By combining time-series imaging with VMD,modeling and prediction can be performed on the basic mode functions obtained from the decomposition, thereby\nVOLUME 11, 2023 11\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\ncapturing long-term dependencies and trends of the signal more accurately. 3) Bidirectional GRU utilizes both past and future context information, enabling a more comprehensive capture of the nonlinear relationships in the time series data. By applying bidirectional GRU to the prediction of the basic mode functions, it combines the local features obtained from the decomposition with the global dependencies, leading to improved prediction accuracy.\nHWES, SARIMA, ARIMA, and MA are commonly used methods in time series forecasting. The possible reasons for the differences in their forecasting performance are as follows: 1) HWES and SARIMA exhibit stronger modeling capabilities for trends and seasonality compared to ARIMA and MA. HWES, through exponential smoothing, effectively\ncaptures trend and seasonal changes in the data. It adapts the smoothing parameter adaptively, better accommodating trend and seasonal patterns in the data. In contrast, while SARIMA can handle seasonal data, its modeling capability may be limited when dealing with complex or irregular seasonal patterns. 2) HWES smoothes the data through exponential smoothing, eliminating some noise and reducing data volatility. This helps extract trend and seasonal components from the data, resulting in smoother prediction outcomes. In contrast, SARIMA requires differencing operations when dealing with noise and non-stationary data, and larger fluctuations or noise may affect its forecasting performance. ARIMA and MA are more suitable for modeling stationary time series, and their forecasting performance may be relatively poorer for non-"
        },
        {
            "heading": "12 VOLUME 11, 2023",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nTABLE 4. The DM test results of the comparative experimental results.\nDM Test DM value p-value Result VMD-GAF-BGRU v.s. MA -5.47 0.000\u2217\u2217\u2217 Accept H1, decline H0 VMD-GAF-BGRU v.s. ARIMA -2.83 0.005\u2217\u2217\u2217 Accept H1, decline H0 VMD-GAF-BGRU v.s. SARIMA -2.22 0.026\u2217\u2217 Accept H1, decline H0 VMD-GAF-BGRU v.s. HWES -2.40 0.016\u2217\u2217 Accept H1, decline H0 VMD-MTF-BGRU v.s. MA -5.12 0.000\u2217\u2217\u2217 Accept H1, decline H0 VMD-MTF-BGRU v.s. ARIMA -2.47 0.014\u2217\u2217 Accept H1, decline H0 VMD-MTF-BGRU v.s. SARIMA -1.91 0.057\u2217 Accept H0, decline H1 VMD-MTF-BGRU v.s. HWES -2.03 0.042\u2217\u2217 Accept H1, decline H0 VMD-RP-BGRU v.s. MA -4.35 0.000\u2217\u2217\u2217 Accept H1, decline H0 VMD-RP-BGRU v.s. ARIMA -3.20 0.001\u2217\u2217\u2217 Accept H1, decline H0 VMD-RP-BGRU v.s. SARIMA -2.76 0.006\u2217\u2217\u2217 Accept H1, decline H0 VMD-RP-BGRU v.s. HWES -2.74 0.006\u2217\u2217\u2217 Accept H1, decline H0 Note: The mark ***, **, and * indicate the 1%, 5% and 10% significance levels, respectively.\nstationary data. We calculate the absolute errors of each model at different points in the test set to facilitate statistical comparison. We present boxplots of the absolute errors for each benchmark, as shown in Fig. 6. The solid orange line on each box represents the median absolute error of the corresponding model\u2019s test points, while the dashed green line represents MAE. Further statistical analysis reveals the following findings:\nFirstly, VMD-GAF-BGRU, VMD-MTF-BGRU, and VMD-RP-BGRU achieve reductions in MAE of 21.64%, 23.15%, and 36.46%, respectively, compared to SARIMA. They also outperform HWES with reductions of 21.18%, 22.70%, and 36.08% in MAE, respectively. Moreover, these three models demonstrate superiority over SARIMA in 61%, 62%, and 65% of cases, and outperform HWES in 58%, 64%, and 65% of cases.\nSecondly, all three of our proposed forecasting models exhibit exceptional predictive performance. This is attributed to the effective utilization of VMD\u2019s advantages in handling non-linear and non-stationary signals, the integration of time series imaging and convolutional neural network feature extraction, and the ability of BGRU to capture local non-linear patterns in time series. Among the existing time series prediction methods, SARIMA and HWES perform relatively well. This may be attributed to their ability to capture both the scale variations and seasonal patterns in time series.\nTo evaluate the superiority of our methodology, we conduct DM tests to determine whether the forecasting accuracy of our proposed models is significantly superior to that of benchmarks [51]\u2013 [53]. Table 4 presents the results of the DM tests conducted on existing forecasting models. When the p-value is greater than or equal to 0.05, the null hypothesis is accepted (Accept H0, decline H1), indicating that the two models have similar performances. When the p-value is less than 0.05, the null hypothesis is rejected (Accept H1, decline H0), indicating that the two models have significantly different performances. It can be observed that, except for the \"VMD-MTF-BGRU v.s. SARIMA\" comparison, which does not meet the conditions to reject the null hypothesis (at a 10% confidence level), all other DM tests exhibit significance at the 1% or 5% level. These results can strongly indicate the\nsignificant superiority of our proposed methodology over existing methods in general. Thus, our findings underscore the effectiveness and advancement of our proposed methodology for forecasting crude oil prices."
        },
        {
            "heading": "2) Ablation experiments",
            "text": "To illustrate the contributions of each component of the proposed forecasting framework, we conduct ablation experiments by removing certain parts of the best-performing model, VMD-RP-BGRU. The constructed ablation experiment benchmarks are as follows:\n\u2022 VMD-RP-GRU: This model replaces the BGRU network in VMD-RP-BGRU with a unidirectional GRU network. \u2022 RP-BGRU: This model directly performs time series imaging without the VMD process, followed by CNN and BGRU networks to generate the predictions. \u2022 VMD-BGRU: This model decomposes the original subsequences using VMD intomultiple IMF series but skips the time series imaging step, directly inputting the IMF series into the BGRU network to generate the predictions. \u2022 VMD-RP: This model performsVMD, time series imaging, and CNN feature extraction operations, and then directly outputs the predictions through a fully connected layer. \u2022 This model omits the VMD process, time series imaging, and CNN feature extraction operations. Instead, it directly trains the BGRU network on the original subsequences to generate the predictions.\nTable 5 presents the comparison results of the ablation experiments, with the best-performing results highlighted in bold. Fig. 7 provides a more intuitive visualization of the predictive performance of different ablation benchmarks. Similarly, we have plotted the boxplot of the absolute errors of the ablation benchmarks at different points in the test set in Fig. 8 for a more in-depth analysis. From Table 5 and Fig. 7, it can be observed that removing any component of our method leads to a decrease in predictive performance. Through analysis of Fig. 8, the following findings are obtained: (1) The MAE, MSE, and MAPE of\nVOLUME 11, 2023 13\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nVMD-RP-BGRU are 27.51%, 41.62%, and 24.29% lower than those of VMD-BGRU, respectively, and the R2 of VMDRP-BGRU is 4.61% higher than that of VMD-BGRU. This indicates that the use of time series imaging (RP) significantly improves the predictive performance of crude oil price time series. (2) The MAE, MSE, and MAPE of VMD-RP-BGRU are 24.13%, 41.85%, and 20.43% lower than those of RPBGRU, respectively, and theR2 of RP-BGRU is 4.65% higher than that of VMD-BGRU. This indicates that the use of VMD also significantly improves the predictive performance of crude oil price time series. (3) The ablation benchmark without using VMD or RP time series imaging, i.e., BGRU, exhibits the worst predictive performance. (4) Introducing the GRU network, particularly the BGRU network, significantly improves the prediction performance. Specifically, using a\nGRU network reduces the MAE, MSE, and MAPE of the model\u2019s predictions by 8.66%, 20.09%, and 7.47%, respectively, with an R2 improvement of 2.22%. The adoption of BGRU network further reduces the MAE, MSE, and MAPE of the model compared to using the GRU network by 18.67%, 26.77%, and 15.8%, respectively, and increases the R2 by 2.31%.\nBased on Fig. 8 and further statistical analysis, we can observe that in terms of absolute value errors, VMD-RPBGRU outperforms BGRU, VMD-RP, VMD-BGRU, RPBGRU, and VMD-RP-GRU in 85%, 85%, 90%, 82%, and 82% of cases, respectively. This result further confirms the necessity and rationality of the different components constructed in our proposed methodology.\nIn summary, from the perspective of MAE and MAPE,"
        },
        {
            "heading": "14 VOLUME 11, 2023",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\nthe contribution of each component to improving predictive ability can be ranked as follows: time series imaging + CNN, BGRU, and VMD.While in terms ofMSE and R2, the rank is: VMD, time series imaging + CNN, and BGRU. These results may arise from the varying sensitivity of different evaluation metrics to the nature and biases of the predictions, leading to different performances of the components across different metrics. MAE and MAPE are absolute error metrics that are more sensitive to the differences between predicted values and true values.MSE andR2 are squared error metrics that are more sensitive to the deviations and goodness of fit between predicted values and true values. Specifically:\n- Time series imaging + CNN: By transforming time series data into images and applying CNN for feature extraction and modeling, the patterns and trends in the time series data can be better captured. This helps to reduce the absolute error between predicted values and true values, thus loweringMAE and MAPE.\n- BGRU: BGRU can capture the long-term dependencies and contextual information in time series data. By utilizing both past and future context, BGRU provides a more comprehensive data representation, improving the accuracy of predictions and reducing MAE and MAPE. However, BGRU may not perform as well as VMD and time series imaging + CNN in terms of goodness of fit, resulting in a comparatively inferior ranking in MSE and R2.\n- VMD: VMD decomposes the signal into a set of basic mode functions, extracting themain components of the signal. Although VMD performs well in capturing local features (for MSE andR2), it may be less sensitive to absolute error metrics such asMAE andMAPE, resulting in a lower ranking in these metrics.\nTable 6 presents the results of DM tests conducted on the forecast errors of ablation benchmarks in the test set. It can be observed that, except for the comparison between \"VMD-RPBGRU v.s. VMD-RP-GRU\" where the p-value does not meet the criteria for rejecting the null hypothesis, all other model comparisons exhibit statistically significant differences.\nV. CONCLUSION This paper proposes a novel approach for crude oil price forecasting based on VMD, time series imaging, and deep learning. Themain purpose is to address the limitations of traditional forecasting methods in dealing with non-stationary, non-linear, and highly volatile crude oil price time series data. The original data are preprocessed through normalization, and then VMD is used to decompose the subsequences\nused for prediction into multiple stationary IMF series. These IMF series are converted into two-dimensional images using three different time series imaging techniques: RP, GAF, and MTF. CNN is employed to extract features from the images, and BGRU is used for prediction. Experimental evaluations are conducted on publicly available crude oil price datasets, comparing the proposed method with commonly used forecasting methods such as SARIMA and HWSE. The results demonstrate significant advantages of our proposed approach, particularly the VMD-RP-BGRU model, which achieves superior forecasting performance across multiple evaluation metrics including MAE, MSE, MAPE, and R2. Specifically, our approach outperforms the benchmark methods, with the VMD-RP-BGRUmodel achieving the best forecasting performance, exhibiting MAE=2.429, MSE=10.94, MAPE=2.94%, and R2=0.9418. It showcases substantial improvements of 21.64%, 23.15%, and 36.46% in MAE, MSE, andMAPE, respectively, compared to the SARIMAmodel, as well as reductions of 21.18%, 22.70%, and 36.08% compared to the HWES model. The proposed approach offers several advantages and notable contributions that can be summarized in three key aspects: (1) The application of time series imaging techniques in crude oil price forecasting is introduced for the first time. By transforming one-dimensional series into twodimensional image matrices, the approach uncovers additional inherent feature information, thereby enhancing the accuracy of crude oil price forecasting. (2) Three novel hybrid models, namely VMD-RP-BGRU, VMD-GAF-BGRU, andVMD-MTF-BGRU, are proposed, incorporating different time series imaging methods. These models effectively combine the strengths of VMD, time series imaging, CNN, and BGRU. (3) This study contributes to the expansion of research in crude oil price prediction theory and enriches the repertoire of deep learning-based time series forecasting methods, thus contributing to theoretical advancements in the field. However, this study has limitations that can serve as directions for futurework. The proposed approach is univariate and does not consider other exogenous variables. Future research can incorporate several exogenous variables, such as news media and search engine data, to further enhance the accuracy of predictions. This study holds significant implications for various stakeholders including investors, crude oil producers, consumers, and policy-makers. For investors, accurate forecasts can inform investment decisions and risk management strategies. Crude oil producers can utilize reliable price forecasts to op-\nVOLUME 11, 2023 15\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\ntimize production plans and resource allocation. Consumers, such as industries heavily reliant on crude oil, can better anticipate price fluctuations and adjust their operations accordingly. Additionally, policy-makers can benefit from accurate forecasts when formulating energy policies, regulating market activities, and promoting economic stability. Overall, this study contributes to advancing the field of time series forecasting and offers valuable tools for decision-making in the energy sector.\nACKNOWLEDGMENT The authors would like to thank the editor, the associate editor, and the reviewers for their constructive comments, which have led to a dramatic improvement of the earlier version of this article.\nREFERENCES [1] IEA, \"Key World Energy Statistics 2021,\u2019\u2019 International Energy\nAgency, Paris, France, Sept. 10, 2021. [Online]. Available: https://www.iea.org/reports/key-world-energy-statistics-2021. [2] K. Joo, J. H. Suh, D. Lee, and K. Ahn, \"Impact of the global financial crisis on the crude oil market,\u2019\u2019 Energy Strategy Rev., vol. 30, p. 100516, Jul. 2020. [3] Bureau of Labor Statistics, \"The 2014 Plunge in Import Petroleum Prices: What Happened?,\u2019\u2019 U.S. Department of Labor, Washington, DC, Rep. no. 9, vol. 4, May 2015. [Online]. Available: https://www.bls.gov/opub/btn/volume-4/pdf/the-2014-plunge-in-importpetroleum-prices-what-happened.pdf. [4] J. Yuan, J. Li, and J. Hao, \"A dynamic clustering ensemble learning approach for crude oil price forecasting,\u2019\u2019 Eng Appl Artif Intell, vol. 123, p. 106408, Aug. 2023. [5] J. Guo, Z. Zhao, J. Sun, and S. Sun, \"Multi-perspective crude oil price forecasting with a new decomposition-ensemble framework,\u2019\u2019 Resour. Policy, vol. 77, p. 102737, Aug. 2022. [6] Y. Guo, F.Ma, H. Li, andX. Lai, \"Oil price volatility predictability based on global economic conditions,\u2019\u2019 Int. Rev. Financial Anal., vol. 82, p. 102195, Jul. 2022. [7] B. S\u00e9vi, \"Forecasting the volatility of crude oil futures using intraday data,\u2019\u2019 Eur. J. Oper. Res., vol. 235, no. 3, pp. 643-659, Jun. 2014. [8] R. J. Hyndman and G. Athanasopoulos, Forecasting: principles and practice.Melbourne, Australia: OTexts, 2018. [9] X. Y. Jiang et al., \"Effect of chromium on granule-based anammox processes,\u2019\u2019 Bioresour. Technol., vol. 260, pp. 1-8, Jul. 2018. [10] Y. Baek and H. Y. Kim, \"ModAugNet: A new forecasting framework for stock market index value with an overfitting prevention LSTMmodule and a prediction LSTM module,\u2019\u2019 Expert Syst. Appl., vol. 113, pp. 457-480, Dec. 2018. [11] J. Cao, Z. Li, and J. Li, \"Financial time series forecasting model based on CEEMDAN and LSTM,\" Physica A, vol. 519, pp. 127-139, Apr. 2019. [12] T. Fischer and C. Krauss, \"Deep learning with long short-term memory networks for financial market predictions,\" Eur. J. Oper. Res., vol. 270, no. 2, pp. 654-669, Oct. 2018. [13] S. Borovkova and I. Tsiamas, \"An ensemble of LSTM neural networks for high-frequency stock market classification,\" J Forecast, vol. 38, no. 6, pp. 600-619, Mar. 2019. [14] N. Jing, Z. Wu, and H. Wang, \"A hybrid model integrating deep learning with investor sentiment analysis for stock price prediction,\" Expert Syst. Appl., vol. 178, p. 115019, Sept. 2021. [15] S.W. Lee andH. Y. Kim, \"Stockmarket forecastingwith super-high dimensional time-series data using ConvLSTM, trend sampling, and specialized data augmentation,\" Expert Syst. Appl., vol. 161, p. 113704, Dec. 2020. [16] T. B. Shahi, A. Shrestha, A. Neupane, andW. Guo, \"Stock price forecasting with deep learning: A comparative study,\" Mathematics, vol. 8, no. 9, p. 1441, Aug. 2020. [17] X. Li and P. Tang, \"Stock index prediction based on wavelet transform and FCD-MLGRU,\" J Forecast, vol. 39, no. 8, pp. 1229-1237, Mar. 2020. [18] Y. Xiang and X. H. Zhuang, \"Application of ARIMAModel in Short-Term Prediction of International Crude Oil Price,\" Adv Mat Res, vol. 798-799, pp. 979-982, Sept. 2013.\n[19] S. C. Hillmer and G. C. Tiao, \"An ARIMA-Model-Based Approach to Seasonal Adjustment,\" J Am Stat Assoc, vol. 77, no. 377, pp. 63-70, Mar. 1982. [20] C.-l. Zhao and B. Wang, \"Forecasting Crude Oil Price with an Autoregressive IntegratedMovingAverage (ARIMA)Model,\" inFuzzy Information& Engineering and Operations Research & Management, Berlin Heidelberg, 2014, pp. 275-286. [21] N. E. Huang et al., \"The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis,\" Proc. R. Soc. Lond. A., vol. 454, no. 1971, pp. 903-995, Mar. 1998. [22] Z. Wu and N. E. Huang, \"Ensemble empirical mode decomposition: A noise-assisted data analysis method,\" Advances in Adaptive Data Analysis, vol. 1, no. 1, pp. 1-41, Jan. 2009. [23] F. Zhou, Z. Huang, and C. Zhang, \"Carbon price forecasting based on CEEMDAN and LSTM,\" Appl. Energy, vol. 311, p. 118601, Apr. 2022. [24] M. E. Torres, M. A. Colominas, G. Schlotthauer, and P. Flandrin, \"A complete ensemble empirical mode decomposition with adaptive noise,\" in IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Prague, Czech Republic, 2011, pp. 4144-4147, doi: 10.1109/ICASSP.2011.5947265. [25] J. Wang, X. Li, T. Hong, and S. Wang, \"A semi-heterogeneous approach to combining crude oil price forecasts,\" Inform Sciences, vol. 460-461, pp. 279-292, Sept. 2018. [26] T. Zhang, Z. Tang, J. Wu, X. Du, and K. Chen, \"Multi-step-ahead crude oil price forecasting based on two-layer decomposition technique and extreme learningmachine optimized by the particle swarm optimization algorithm,\" Energy, vol. 229, p. 120797, Aug. 2021. [27] L. Yu, W. Dai, and L. Tang, \"A novel decomposition ensemble model with extended extreme learning machine for crude oil price forecasting,\" Eng Appl Artif Intell, vol. 47, pp. 110-121, Jan. 2016. [28] H. Abdollahi, \"A novel hybrid model for forecasting crude oil price based on time series decomposition,\" Appl. Energy, vol. 267, p. 115035, Jun. 2020. [29] Y. Huang and Y. Deng, \"A new crude oil price forecasting model based on variational mode decomposition,\" Knowl Based Syst, vol. 213, p. 106669, Feb. 2021. [30] J. Sun, P. Zhao, and S. Sun, \"A new secondary decompositionreconstruction-ensemble approach for crude oil price forecasting,\" Resour. Policy, vol. 77, p. 102762, Aug. 2022. [31] S. Zhang, J. Luo, S.Wang, and F. Liu, \"Oil price forecasting: A hybrid GRU neural network based on decomposition-reconstruction methods,\" Expert Syst. Appl., vol. 218, p. 119617, May 2023. [32] K. Zheng et al., \"A Multi-Scale Electricity Consumption Prediction Algorithm Based on Time-Frequency Variational Autoencoder,\" IEEE Access, vol. 9, pp. 90937-90946, Apr. 2021. [33] K. Cho et al., \"Learning phrase representations using RNN encoderdecoder for statistical machine translation,\" in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar, 2014, pp. 1724-1734. [34] G. G. R and A. S. Babu, \"Hybrid Deep Learning Model to Forecast Crude Oil Price,\" in International Conference on Inventive Computation Technologies, ICICT 2023, Lalitpur, Nepal, 2023, pp. 19-23. [35] J. Nasir, M. Aamir, Z. U. Haq, S. Khan, M. Y. Amin, and M. Naeem, \"A New Approach for Forecasting Crude Oil Prices Based on Stochastic and Deterministic Influences of LMD Using ARIMA and LSTMModels,\" IEEE Access, vol. 11, pp. 14322-14339, Feb. 2023. [36] S. Borovkova and I. Tsiamas, \"Text-based crude oil price forecasting: A deep learning approach,\" Int J Forecast, vol. 35, no. 4, pp. 1548-1560, Oct. 2019. [37] M. Li, Z. Cheng, W. Lin, Y. Wei, and S. Wang, \"What can be learned from the historical trend of crude oil prices? An ensemble approach for crude oil price forecasting,\" Energy Econ, vol. 123, p. 106736, Jul. 2023. [38] Q. Zhu, F. Zhang, S. Liu, Y. Wu, and L. Wang, \"A hybrid VMD-BiGRU model for rubber futures time series forecasting,\" Appl. Soft Comput., vol. 84, p. 105739, Nov. 2019. [39] Y. Fang, W. Wang, P. Wu, and Y. Zhao, \"A sentiment-enhanced hybrid model for crude oil price forecasting,\" Expert Syst. Appl., vol. 215, p. 119329, Apr. 2023. [40] J.-W. Bi, H. Li, and Z.-P. Fan, \"Tourism demand forecasting with time series imaging: A deep learningmodel,\"Ann. Tour. Res., vol. 90, p. 103255, Sept. 2021. [41] W. Tian, J. Wu, H. Cui, and T. Hu, \"Drought Prediction Based on FeatureBased Transfer Learning and Time Series Imaging,\" IEEE Access, vol. 9, pp. 101454-101468, Jul. 2021."
        },
        {
            "heading": "16 VOLUME 11, 2023",
            "text": "This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nZ. J. Peng et al.: Crude Oil Price Time Series Forecasting: A Novel Approach\n[42] G. Zhang and J. Guo, \"A novel ensemble method for hourly residential electricity consumption forecasting by imaging time series,\" Energy, vol. 203, p. 117858, Jul. 2020. [43] R. Kadari, Y. Zhang, W. Zhang, and T. Liu, \"CCG supertagging via Bidirectional LSTM-CRF neural architecture,\" Neurocomputing, vol. 283, pp. 31-37, Mar. 2018. [44] K. Dragomiretskiy and D. Zosso, \"Variational mode decomposition,\" IEEE Trans. Signal Process., vol. 62, no. 3, pp. 531-544, Nov. 2014. [45] X. Li, Y. Kang, and F. Li, \"Forecasting with time series imaging,\" Expert Syst. Appl., vol. 160, p. 113680, Dec. 2020. [46] J. P. Eckmann, O. Oliffson Kamphorst, and D. Ruelle, \"Recurrence plots of dynamical systems,\" EPL, vol. 4, no. 9, pp. 973-977, Nov. 1987. [47] Z. Wang and T. Oates, \"Imaging time-series to improve classification and imputation,\" in Proceedings of the 24th International Conference on Artificial Intelligence (IJCAI\u201915), AAAI Press, 2015, pp. 3939-3945. [48] X. Glorot, A. Bordes, and Y. Bengio, \" Deep sparse rectifier neural networks,\" in Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, JMLR Workshop and Conference Proceedings, 2011, pp. 315-323. [49] D. P. Kingma and J. L. Ba, \"Adam: A method for stochastic optimization,\" in 3rd International Conference on Learning Representations, ICLR 2015, San Diego, 2015. [50] F. X. Diebold and R. S. Mariano, \"Comparing Predictive Accuracy,\" J Bus Econ Stat, vol. 13, no. 3, pp. 253-263, Jul. 1995. [51] E. Zhao, P. Du, and S. Sun, \"Historical pattern recognition with trajectory similarity for daily tourist arrivals forecasting,\"Expert Syst. Appl., vol. 203, p. 117427, Oct. 2022. [52] K. Ijaz, Z. Hussain, J. Ahmad, S. F. Ali, M. Adnan, and I. Khosa, \"A Novel Temporal Feature Selection Based LSTMModel for Electrical Short-Term Load Forecasting,\" IEEE Access, vol. 10, pp. 82596-82613, Aug. 2023. [53] T. Mutavhatsindi, C. Sigauke, and R. Mbuvha, \"Forecasting Hourly Global Horizontal Solar Irradiance in South Africa UsingMachine LearningModels,\" IEEE Access, vol. 8, pp. 198872-198885, Oct. 2020.\nZI-JIAN PENG is currently pursuing bachelor\u2019s degree in industrial engineering from Northeastern University, China. His research interests are forecasting, supply chain management, and revenue management.\nCHUAN ZHANG received the Ph.D. degree in control theory and control engineering fromNortheastern University (NEU), Shenyang, China, in 2002. He is currently a professor in School of Business Administration at Northeastern University (NEU), Shenyang, China. His current research interests include data-driven operations management, big data mining and forecasting, sustainable operations management, green supply chain management, and platform operations management.\nHe has published over 30 papers in leading journals including International Journal of Forecasting, Annals of Operations Research, Information Sciences, Journal of Cleaner Production and Expert Systems with Applications.\nYU-XIN TIAN is currently pursuing the doctor\u2019s degree in Management Science and Engineering from Northeastern University, China. His research interests are data-driven operational research, artificial Intelligence, machine learning, forecasting, sustainable operationsmanagement, and green supply chain management. He has published over 15 papers in leading journals including International Journal of Forecasting, Annals of Operations Research, Journal of Cleaner Production,\nand Expert Systems with Applications.\nVOLUME 11, 2023 17\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/"
        }
    ],
    "title": "Crude Oil Price Time Series Forecasting: A Novel Approach Based on Variational Mode Decomposition, Time-Series Imaging, and Deep Learning",
    "year": 2023
}