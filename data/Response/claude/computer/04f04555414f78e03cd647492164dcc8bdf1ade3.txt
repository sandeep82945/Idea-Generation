 Here are 5 possible future research ideas after reading this paper on argument mining:

1. Explore different attention mechanisms besides ArguAtten to model inter-dependencies between argument components. The self-attention mechanism helps capture relevance between components, but other attention variants could further improve relation modeling.

2. Incorporate syntactic features into the argument component representations. The current model relies primarily on semantic features from BERT embeddings. Adding syntactic features like part-of-speech tags or dependency parses could help the model better understand argument structure. 

3. Experiment with graph neural networks to explicitly model the full argument graph structure. Graph networks can directly operate on graph-structured data and may be well-suited for capturing both nodes (components) and edges (relations).

4. Apply the model to other argumentative domains beyond persuasive essays and legal texts. Testing the generalizability of the approach on domains like scientific writing, online debates, and social media conversations would be interesting.

5. Extend the model to handle dialogic argumentation with multiple perspectives. The current model focuses on monologic arguments from a single perspective. Enabling analysis of arguments from multiple sides could make the approach applicable to richer conversational data.