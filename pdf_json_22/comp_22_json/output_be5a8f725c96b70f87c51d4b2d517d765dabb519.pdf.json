{
    "authors": [
        {
            "affiliations": [],
            "name": "ITC"
        },
        {
            "affiliations": [],
            "name": "V. Jothi Prakash"
        },
        {
            "affiliations": [],
            "name": "N. K. Karthikeyan"
        }
    ],
    "id": "SP:6ce8e1507b27a0e4b0a61a1a67cb23e0a9720709",
    "references": [
        {
            "authors": [
                "K.K. Al-Barazanchi",
                "A.Q. Al-Neami",
                "A.H. Al-Timemy"
            ],
            "title": "Ensemble of Bagged Tree Classifier for the Diagnosis of Neuromuscular Disorders",
            "venue": "In Fourth International Conference on Advances in Biomedical Engineering (ICABME),",
            "year": 2017
        },
        {
            "authors": [
                "F. Ali",
                "S. El-Sappagh",
                "S.R. Islam",
                "D. Kwak",
                "A. Ali",
                "M. Imran",
                "K.S.A. Kwak"
            ],
            "title": "Smart Healthcare Monitoring System for Heart Disease Prediction Based on Ensemble Deep Learning and Feature Fusion",
            "venue": "Information Fusion,",
            "year": 2020
        },
        {
            "authors": [
                "R. Ani",
                "J. Jose",
                "M. Wilson",
                "O.S. Deepa"
            ],
            "title": "Modified Rotation Forest Ensemble Classifier for Medical Diagnosis in Decision Support Systems, Springer, 2018",
            "year": 2018
        },
        {
            "authors": [
                "S. Asadi",
                "S. Roshan",
                "M.W. Kattan"
            ],
            "title": "Random Forest Swarm Optimization-Based for Heart Diseases Diagnosis",
            "venue": "Journal of Biomedical Informatics,",
            "year": 2021
        },
        {
            "authors": [
                "R. Atallah",
                "A. Al-Mousa"
            ],
            "title": "Heart Disease Detection Using Machine Learning Majority Voting Ensemble Method",
            "venue": "In 2nd International Conference on New Trends in Computing Sciences (ICTCS),",
            "year": 2019
        },
        {
            "authors": [
                "A. Baccouche",
                "B. Garcia-Zapirain",
                "C. Castillo Olea",
                "A. Elmaghraby"
            ],
            "title": "Ensemble Deep Learning Models for Heart Disease Classification: A Case Study from Mexico, Information",
            "year": 2020
        },
        {
            "authors": [
                "S. Bashir",
                "U. Qamar",
                "F. Khan"
            ],
            "title": "BagMOOV: A Novel Ensemble for Heart Disease Prediction Bootstrap Aggregation with Multi-Objective Optimized Voting",
            "venue": "Australasian Physical & Engineering Sciences in Medicine,",
            "year": 2015
        },
        {
            "authors": [
                "S. Bashir",
                "U. Qamar",
                "F.H. Khan"
            ],
            "title": "A Multicriteria Weighted Vote-Based Classifier Ensemble for Heart Disease Prediction",
            "venue": "Computational Intelligence,",
            "year": 2015
        },
        {
            "authors": [
                "S. Bashir",
                "U. Qamar",
                "M. Younus Javed"
            ],
            "title": "An Ensemble Based Decision Support Framework for Intelligent Heart Disease Diagnosis",
            "venue": "International Conference on Information Society,",
            "year": 2014
        },
        {
            "authors": [
                "J.D. Beck",
                "K.L. Moss",
                "T. Morelli",
                "S. Offenbacher"
            ],
            "title": "Periodontal Profile Class Is Associated with Prevalent Diabetes, Coronary Heart Disease, Stroke, and Systemic Markers Of C-Reactive Protein and Interleukin-6",
            "venue": "Journal of Periodontology,",
            "year": 2018
        },
        {
            "authors": [
                "L. Brunese",
                "F. Mercaldo",
                "A. Reginelli",
                "A. Santone"
            ],
            "title": "An Ensemble Learning Approach for Brain Cancer Detection Exploiting Radiomic Features, Computer Methods and Programs",
            "venue": "in Biomedicine,",
            "year": 2020
        },
        {
            "authors": [
                "Y. Cao",
                "P. Li",
                "Y. Zhang"
            ],
            "title": "Parallel Processing Algorithm for Railway Signal Fault Diagnosis Data Based on Cloud Computing, Future Generation Computer Systems, 2018",
            "venue": "Information Technology and Control",
            "year": 2022
        },
        {
            "authors": [
                "Z. Chen",
                "M. Wu",
                "K. Gao",
                "J. Wu",
                "J. Ding",
                "Z. Zeng",
                "X. Li"
            ],
            "title": "A Novel Ensemble Deep Learning Approach for Sleep-Wake Detection Using Heart Rate Variability and Acceleration",
            "venue": "IEEE Transactions on Emerging Topics in Computational Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "K.J. Cios",
                "L.A. Kurgan"
            ],
            "title": "CLIP4: Hybrid Inductive Machine Learning Algorithm That Generates Inequality Rules",
            "venue": "Information Sciences,",
            "year": 2004
        },
        {
            "authors": [
                "A. Cord",
                "S. Chambon"
            ],
            "title": "Automatic Road Defect Detection by Textural Pattern Recognition Based on AdaBoost",
            "venue": "Computer-Aided Civil and Infrastructure Engineering,",
            "year": 2012
        },
        {
            "authors": [
                "G. Cumming"
            ],
            "title": "Replication and P Intervals: P Values Predict the Future Only Vaguely, But Confidence Intervals Do Much Better",
            "venue": "Perspectives on Psychological Science,",
            "year": 2008
        },
        {
            "authors": [
                "P. Geurts",
                "D. Ernst",
                "L. Wehenkel"
            ],
            "title": "Extremely Randomized Trees",
            "venue": "Machine Learning,",
            "year": 2006
        },
        {
            "authors": [
                "A.L. Goldberger",
                "L.A. Amaral",
                "L. Glass",
                "J.M. Hausdorff",
                "P.C. Ivanov",
                "R.G. Mark",
                "J.E. Mietus",
                "G.B. Moody",
                "C.K. Peng",
                "H.E. Stanley"
            ],
            "title": "PhysioBank, PhysioToolkit, and PhysioNet: Components of A New Research Resource for Complex",
            "venue": "Physiologic Signals. Circulation,",
            "year": 2000
        },
        {
            "authors": [
                "I. Guyon",
                "J. Weston",
                "S. Barnhill",
                "V. Vapnik"
            ],
            "title": "Gene Selection For Cancer Classification Using Support Vector Machines",
            "venue": "Machine Learning,",
            "year": 2002
        },
        {
            "authors": [
                "R. Hariharan",
                "I.S. Thaseen",
                "G.U. Devi"
            ],
            "title": "Performance Analysis of Single-And Ensemble-Based Classifiers for Intrusion Detection",
            "venue": "In Soft Computing for Problem Solving,",
            "year": 2019
        },
        {
            "authors": [
                "G. Hu",
                "C. Yin",
                "M. Wan",
                "Y. Zhang",
                "Y. Fang"
            ],
            "title": "Recognition of Diseased Pinus Trees in UAV Images Using Deep Learning and AdaBoost Classifier",
            "venue": "Biosystems Engineering,",
            "year": 2020
        },
        {
            "authors": [
                "C. Hung",
                "J.H. Chen"
            ],
            "title": "A Selective Ensemble Based on Expected Probabilities for Bankruptcy Prediction",
            "venue": "Expert Systems with Applications,",
            "year": 2009
        },
        {
            "authors": [
                "F. Jabeen",
                "M. Maqsood",
                "M.A. Ghazanfar",
                "F. Aadil",
                "S. Khan",
                "M.F. Khan",
                "I. Mehmood"
            ],
            "title": "An IoT Based Efficient Hybrid Recommender System for Cardiovascular Disease",
            "venue": "Peer-to-Peer Networking and Applications,",
            "year": 2019
        },
        {
            "authors": [
                "G. James",
                "D. Witten",
                "T. Hastie",
                "R. Tibshirani"
            ],
            "title": "An Introduction to Statistical Learning",
            "venue": "New York: Springer,",
            "year": 2013
        },
        {
            "authors": [
                "M.I. Jordan",
                "T.M. Mitchell"
            ],
            "title": "Machine learning: Trends, Perspectives",
            "venue": "And Prospects,",
            "year": 2015
        },
        {
            "authors": [
                "P. Kamal",
                "S. Ahuja"
            ],
            "title": "An Ensemble-Based Model for Prediction of Academic Performance of Students in Undergrad Professional Course",
            "venue": "Journal of Engineering, Design and Technology,",
            "year": 2019
        },
        {
            "authors": [
                "B. Kami\u0144ski",
                "M. Jakubczyk",
                "P. Szufel"
            ],
            "title": "A Framework for Sensitivity Analysis of Decision Trees",
            "venue": "Central European Journal of Operations Research,",
            "year": 2018
        },
        {
            "authors": [
                "Khairalla",
                "M.A",
                "X Ning",
                "N.T. Al-Jallad",
                "M.O. El-Faroug"
            ],
            "title": "Short-Term Forecasting for Energy Consumption Through Stacking Heterogeneous Ensemble Learning Model",
            "venue": "Energies, 2018,",
            "year": 2018
        },
        {
            "authors": [
                "S.B. Kotsiantis",
                "I. Zaharakis",
                "P. Pintelas"
            ],
            "title": "Supervised Machine Learning: A Review of Classification Techniques",
            "venue": "Emerging Artificial Intelligence Applications in Computer Engineering,",
            "year": 2007
        },
        {
            "authors": [
                "L.A. Kurgan",
                "K.J. Cios",
                "R. Tadeusiewicz",
                "M. Ogiela",
                "L.S. Goodenday"
            ],
            "title": "Knowledge Discovery Approach to Automated Cardiac SPECT Diagnosis",
            "venue": "Artificial Intelligence in Medicine,",
            "year": 2001
        },
        {
            "authors": [
                "D.C.B. Marak",
                "A. Halder",
                "A. Kumar"
            ],
            "title": "Semi-supervised Ensemble Learning for Efficient Cancer Sample Classification from miRNA Gene Expression Data",
            "venue": "New Generation Computing,",
            "year": 2021
        },
        {
            "authors": [
                "G.B. Moody",
                "R.G. Mark"
            ],
            "title": "The Impact of the MIT-BIH Arrhythmia Database",
            "venue": "IEEE Engineering in Medicine and Biology Magazine,",
            "year": 2001
        },
        {
            "authors": [
                "M. Muzammal",
                "R. Talat",
                "A.H. Sodhro",
                "S. Pirbhulal"
            ],
            "title": "A Multi-Sensor Data Fusion Enabled Ensemble Approach for Medical Data from Body Sensor Networks",
            "venue": "Information Technology and Control",
            "year": 2020
        },
        {
            "authors": [
                "A. Natekin",
                "A. Knoll"
            ],
            "title": "Gradient Boosting Machines, A Tutorial",
            "venue": "Frontiers in Neurorobotics,",
            "year": 2013
        },
        {
            "authors": [
                "M. Nilashi",
                "H. Ahmadi",
                "L. Shahmoradi",
                "O. Ibrahim",
                "E. Akbari"
            ],
            "title": "A Predictive Method for Hepatitis Disease Diagnosis Using Ensembles of Neuro-Fuzzy Technique",
            "venue": "Journal Of Infection and Public Health,",
            "year": 2019
        },
        {
            "authors": [
                "D. Panda",
                "R. Dash S"
            ],
            "title": "Predictive System: Comparison of Classification Techniques for Effective Prediction of Heart Disease",
            "venue": "Smart Intelligent Computing and Applications,",
            "year": 2020
        },
        {
            "authors": [
                "A. Pinto",
                "S. Pereira",
                "D. Rasteiro",
                "C.A. Silva"
            ],
            "title": "Hierarchical Brain Tumour Segmentation Using Extremely Randomized Trees",
            "venue": "Pattern Recognition,",
            "year": 2018
        },
        {
            "authors": [
                "P. P\u0142awiak",
                "U.R. Acharya"
            ],
            "title": "Novel Deep Genetic Ensemble of Classifiers for Arrhythmia Detection Using ECG signals",
            "venue": "Neural Computing and Applications,",
            "year": 2020
        },
        {
            "authors": [
                "N. Ponomareva",
                "S. Radpour",
                "G. Hendry",
                "S. Haykal",
                "T. Colthurst",
                "P. Mitrichev",
                "Grushetsky",
                "A. TF"
            ],
            "title": "Boosted Trees: A Scalable TensorFlow Based Framework for Gradient Boosting",
            "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,",
            "year": 2017
        },
        {
            "authors": [
                "V.J. Prakash",
                "N.K. Karthikeyan"
            ],
            "title": "Enhanced Evolutionary Feature Selection and Ensemble Method for Cardiovascular Disease Prediction",
            "venue": "Interdisciplinary Sciences: Computational Life Sciences,",
            "year": 2021
        },
        {
            "authors": [
                "P Probst",
                "MN Wright",
                "Boulesteix",
                "A.-L"
            ],
            "title": "Hyperparameters and Tuning Strategies for Random Forest. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 2019",
            "year": 2019
        },
        {
            "authors": [
                "A. Rath",
                "D. Mishra",
                "G. Panda",
                "S.C. Satapathy"
            ],
            "title": "Heart Disease Detection Using Deep Learning Methods from Imbalanced ECG Samples",
            "venue": "Biomedical Signal Processing and Control,",
            "year": 2021
        },
        {
            "authors": [
                "M. Rhanoui",
                "M. Mikram",
                "S. Yousfi",
                "S. Barzali"
            ],
            "title": "A CNN-BiLSTM Model for Document-Level Sentiment Analysis",
            "venue": "Machine Learning and Knowledge Extraction,",
            "year": 2019
        },
        {
            "authors": [
                "Ricco",
                "Eric"
            ],
            "title": "Heart Disease Dataset. [Online]. Available: http://eric.univ-lyon2.fr/%7Ericco/tanagra/fichiers/ heart_disease_male.xls [Accessed in 8 March 2021",
            "year": 2021
        },
        {
            "authors": [
                "L. Rokach"
            ],
            "title": "Ensemble-Based Classifiers",
            "venue": "Artificial Intelligence Review,",
            "year": 2010
        },
        {
            "authors": [
                "O. Sagi",
                "L. Rokach"
            ],
            "title": "Ensemble Learning: A Survey. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 2018",
            "year": 2018
        },
        {
            "authors": [
                "S.K. Sahu",
                "D.P. Mohapatra",
                "J.K. Rout",
                "K.S. Sahoo",
                "A.K. Luhach"
            ],
            "title": "An Ensemble-Based Scalable Approach for Intrusion Detection Using Big Data Framework",
            "venue": "Big Data,",
            "year": 2021
        },
        {
            "authors": [
                "L. Sapra",
                "J.K. Sandhu",
                "N. Goyal"
            ],
            "title": "Intelligent Method for Detection of Coronary Artery Disease with Ensemble Approach",
            "venue": "In Advances in Communication and Computational Technology,",
            "year": 2021
        },
        {
            "authors": [
                "U. Sidiq",
                "S.M. Aaqib"
            ],
            "title": "An Empirical Model for Thyroid Disease Diagnosis Using Data Mining Techniques",
            "venue": "In International Conference on Sustainable Communication Networks and Application,",
            "year": 2019
        },
        {
            "authors": [
                "Silva",
                "L.O.L. A",
                "M. Koga",
                "L.B.V. Boas",
                "C.E. Cugnasca",
                "A.H.R. Costa"
            ],
            "title": "Comparative Assessment of Feature Selection and Classification Techniques for Visual Inspection of Pot Plant Seedlings",
            "venue": "Computers And Electronics in Agriculture,",
            "year": 2013
        },
        {
            "authors": [
                "K. Siwek",
                "S. Osowski"
            ],
            "title": "Improving the Accuracy of Prediction of PM10 Pollution by The Wavelet Transformation and An Ensemble of Neural Predictors",
            "venue": "Engineering Applications of Artificial Intelligence,",
            "year": 2012
        },
        {
            "authors": [
                "O.M. Surakhi",
                "M.A. Zaidan",
                "S. Serhan",
                "I. Salah",
                "T. Hussein"
            ],
            "title": "An Optimal Stacked Ensemble Deep Learning Model for Predicting Time-Series Data Using a Genetic Algorithm-An Application for Aerosol Particle Number Concentrations",
            "venue": "https://doi",
            "year": 2020
        },
        {
            "authors": [
                "B.A. Tama",
                "S. Im",
                "S. Lee"
            ],
            "title": "Improving an Intelligent Detection System for Coronary Heart Disease Using a Two-Tier Classifier Ensemble",
            "venue": "BioMed Research International,",
            "year": 2020
        },
        {
            "authors": [
                "K.K. Tan",
                "N.Q.K. Le",
                "H.Y. Yeh",
                "M.C.H. Chua"
            ],
            "title": "Ensemble of Deep Recurrent Neural Networks for Identifying Enhancers Via Dinucleotide",
            "venue": "Physicochemical Properties. Cells,",
            "year": 2019
        },
        {
            "authors": [
                "S. Uslu"
            ],
            "title": "Optimization of Diesel Engine Operating Parameters Fueled with Palm Oil-Diesel Blend: Comparative Evaluation Between Response Surface Methodology (RSM) And Artificial Neural Network",
            "venue": "(ANN). Fuel,",
            "year": 2020
        },
        {
            "authors": [
                "S.J. Wang",
                "A. Mathew",
                "Y. Chen",
                "L.F. Xi",
                "L. Ma",
                "J. Lee"
            ],
            "title": "Empirical Analysis of Support Vector Machine Ensemble Classifiers",
            "venue": "Expert Systems with Applications,",
            "year": 2009
        },
        {
            "authors": [
                "Z. Wu",
                "L. Shi",
                "J. Li",
                "Q. Wang",
                "L. Sun",
                "Z. Wei",
                "J. Plaza",
                "A. Plaza"
            ],
            "title": "GPU Parallel Implementation of Spatially Adaptive Hyperspectral Image Classification",
            "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,",
            "year": 2017
        },
        {
            "authors": [
                "Q. Xie",
                "G. Cheng",
                "X. Xu",
                "Z. Zhao"
            ],
            "title": "Research Based on Stock Predicting Model of Neural Networks Ensemble Learning",
            "venue": "In MATEC Web of Conferences, EDP Sciences,",
            "year": 2018
        },
        {
            "authors": [
                "S. Xu"
            ],
            "title": "Bayesian Na\u00efve Bayes Classifiers to Text Classification",
            "venue": "Journal of Information Science,",
            "year": 2018
        },
        {
            "authors": [
                "I. Yekkala",
                "S. Dixit"
            ],
            "title": "A Novel Approach for Heart Disease Prediction Using Genetic Algorithm and Ensemble Classification",
            "venue": "Proceedings of SAI Intelligent Systems Conference,",
            "year": 2021
        },
        {
            "authors": [
                "N. Zeng",
                "H. Qiu",
                "Z. Wang",
                "W. Liu",
                "H. Zhang",
                "Y. Li"
            ],
            "title": "A New Switching-Delayed-PSO-Based Optimized SVM Algorithm for Diagnosis of Alzheimer's Disease",
            "year": 2018
        },
        {
            "authors": [
                "X. Zhang",
                "S.T. Waller",
                "P. Jiang"
            ],
            "title": "An Ensemble Machine Learning\u2010Based Modeling Framework for Analysis of Traffic Crash Frequency",
            "venue": "Computer-Aided Civil and Infrastructure Engineering,",
            "year": 2019
        },
        {
            "authors": [
                "J. Zhao",
                "Q. Feng",
                "P. Wu",
                "R.A. Lupu",
                "R.A. Wilke",
                "Q.S. Wells",
                "J.C. Denny",
                "W.Q. Wei"
            ],
            "title": "Learning from Longitudinal Data in Electronic Health Record and Genetic Data to Improve Cardiovascular Event Prediction",
            "venue": "Scientific Reports,",
            "year": 2019
        },
        {
            "authors": [
                "Q. Zhenya",
                "Z. Zhang"
            ],
            "title": "A Hybrid Cost-Sensitive Ensemble for Heart Disease Prediction",
            "venue": "BMC Medical Informatics and Decision Making,",
            "year": 2021
        },
        {
            "authors": [
                "X. Zhou",
                "Y. Li",
                "W. Liang"
            ],
            "title": "CNN-RNN Based Intelligent Recommendation for Online Medical Pre-Diagnosis Support",
            "venue": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "Information Technology and Control 2022/1/51158\nDual-Layer Deep Ensemble Techniques for Classifying Heart Disease\nITC 1/51 Information Technology and Control Vol. 51 / No. 1 / 2022 pp. 158-179 DOI 10.5755/j01.itc.51.1.30083\nDual-Layer Deep Ensemble Techniques for Classifying Heart Disease\nReceived 2021/11/05 Accepted after revision 2022/01/25\nhttp://dx.doi.org/10.5755/j01.itc.51.1.30083\nHOW TO CITE: Prakash, V. J., Karthikeyan, N. K. (2022). Dual-Layer Deep Ensemble Techniques for Classifying Heart Disease. Information Technology and Control, 51(1), 158-179. https://doi.org/10.5755/j01.itc.51.1.30083\nCorresponding author: jothiprakashv@gmail.com\nV. Jothi Prakash Department of Information Technology; Karpagam College of Engineering; Coimbatore, Tamil Nadu, India; e-mail: jothiprakashv@gmail.com\nN. K. Karthikeyan Department of Information Technology; Coimbatore Institute of Technology; Coimbatore, Tamil Nadu, India; e-mail: karthikeyan.nk@cit.edu.in\nThe prevalence of heart disease is increasing at a rapid rate due to changes in food habits and lifestyle of people all over the world. Early prediction and diagnosis of this fatal disease is a highly excruciating task. Nowadays, the ensemble learning approaches are preferred owing to their effectiveness in performance when compared to the performance of a single classification algorithm. In this work, a Dual-Layer Stacking Ensemble (DLSE) technique and a Deep Heterogeneous Ensemble (DHE) technique to classify heart disease are proposed. The DLSE uses several heterogeneous classifiers to form an ensemble that is efficient as well as diverse. The proposed framework consists of two layers with the first layer consisting of three different base learning algorithms Na\u00efve Bayes (NB), Decision Tree (DT), and Support Vector Machine (SVM). The second layer comprises of three different classifiers, Extremely Randomized Trees (ERT), Ada Boost Classifier (ABC) and Random Forest (RF). The second layer utilizes the results from the first layer to provide a diverse input for the three classifiers. Finally, the outcomes are fed to the meta-classifier Gradient Boosted Trees (GBT) to generate the final prediction. The DHE uses three deep learning models Convolutional Neural Networks with Bidirectional Long Short-Term Memory (CNN BiLSTM), Artificial Neural Network (ANN) and Recurrent Neural Network (RNN) with RF, ERT and GBT as the meta-learners. The performance of the proposed methods is compared with traditional state-of-the-art classifiers as well as existing ensemble learning and deep learning methods. The experimental outcomes show that the proposed DLSE and DHE methods perform exceptionally in terms of accuracy, precision and recall measures. KEYWORDS: Deep Learning, Ensemble Techniques, Heart Disease, Machine Learning, Multiple Classifiers, Stacking Ensemble.\n159Information Technology and Control 2022/1/51\n1. Introduction The World Health Organization (WHO) has stated that nearly 31% of annual deaths occur because of heart disease [58]. The WHO has also estimated that more than 75% of those deaths occur in middle- and low-income countries [57]. This increase in heart disease is mainly based on the factors such as years of alcohol abuse, smoking, unhealthy food habits, stress, lack of physical activities etc. The changes in the environment such as increase in the level of air pollution, variations in the temperature also play a factor for prevalence of heart disease. It has been estimated that over 54 million people in India suffer from heart related ailments. The recent Coronavirus Disease 2019 (COVID-19) outbreak has raised concern over substantial increase in heart related ailments. The COVID-19 pandemic has increased the risk of severe infection in people with underlying heart disease or heart related problems. Therefore, there is a need for proper classification methodology not only for detecting heart disease but also for predicting the possibility of heart disease in future. Machine learning [25] has been used extensively by researchers to classify and predict heart disease. Recent technology advancements in parallel processing [12], Graphical Processing Unit (GPU) technology [60] have urged many researchers to utilize this power to process the data more effectively. Ensemble methods [46] are always known to be highly effective in solving classification problems and are the most preferred techniques in the recent days. Ensemble techniques [17] rely on a collection of classifiers rather than focusing on the performance of a single classifier. These approaches build a meta-model based on the results of several diverse classifiers. This meta-model is then used to provide the final prediction outcome for the problem. A wide variety of machine learning algorithms have been developed over the recent years for solving classification and regression problems in real world. Most of the algorithms often deal with increasing the accuracy of classification and prediction. Many researches were carried out in search of an algorithm that provides high accuracy. The ensemble approaches also fall into this category. Some of the ensemble techniques deal with model fusion, selection of the base learners dynamically, combination of same or different base learners, bagging, applying voting scheme, stacked generalization among others. In this modern era, deep learning models have been successfully applied for classification and prediction tasks as they automate the process of feature extraction using the hierarchical feature learning approach. 2. Related Work The ensemble approaches have proven to be more effective when compared to the performance of a single classifier. Some of the recent works in ensemble approaches are discussed in this section. Bashir et. al [7] discussed an ensemble approach using bagging for diagnosing heart disease. The approach used a multi-objective voting scheme for the final prediction result. Al-Barazanchi et. al [1] developed a bagging model for diagnosing neuromuscular disorders. The technique used a Decision Tree as the base learner and a voting mechanism was used to obtain the final prediction. Nilashi et. al [35] proposed an adaptive neuro-fuzzy ensemble model for predicting hepatitis disease. This model used a Self-Organizing Map (SOM) for clustering the data. The major drawback in this method is the computational time that is needed for diagnosing the disease. Atallah and Al-Mousa [5] developed an ensemble method using the majority voting scheme. Four classifiers were used and the predictions were combined using hard voting method. This approach is just a combination of four basic classifiers using voting scheme and the performance was limited. Ani et. al [3] proposed a rotation forest-based ensemble technique for disease diagnosis. This technique used RF as the base learner. A two-tier classification ensemble for detecting coronary heart disease was explored by Tama et. al [53]. This technique used RF, Gradient Boosting Machine (GBM) and Extreme Gradient Boosting Machine (XGBoost) as separate homogeneous ensembles. Yekkala and Dixit [63] designed a Genetic Algorithm (GA) based ensemble for classifying heart disease. This technique used GA for selecting the attributes for classification. But this model was validated on only a single dataset. Brunese et. al [11] provided an ensemble learning method for detecting brain cancer. This method\nInformation Technology and Control 2022/1/51160\nused a weighted soft voting technique for generating the prediction. A hybrid ensemble for detecting heart disease was designed by Zhenya and Zhang [67]. This ensemble used five heterogeneous classifiers and used Relief algorithm for dimensionality reduction. This method was tested using the statlog dataset from the UCI data repository. A swarm-based RF algorithm was contributed by Asadi et. al [4]. This technique used a multi-objective particle swarm optimization (MOPSO) combined with the RF algorithm for diagnosing heart disease. This research suggested the generation of diverse feature sets rather than the traditional bootstrapping of the samples. An intelligent ensemble method for detecting coronary artery disease was contributed by Sapra et. al [48]. This approach focused on the cost-effectiveness and rapid prediction of heart disease. Marak et. al [31] proposed a semi-supervised ensemble for cancer diagnosis from gene expression data. This method combined the merits of semi-supervised learning and ensemble learning. The model was validated on eight gene expression datasets. Baccouche et. al [6] proposed a deep learning ensemble model using Bidirectional Long Short-Term Memory (BiLSTM) and Bidirectional Gated Recurrent Unit (BiGRU) model with CNN for the prediction of heart disease. But this technique did not use the benchmark datasets to validate the proposed model. Ali et. al [2] proposed a deep learning-based ensemble model along with feature fusion for predicting heart disease. This approach used conditional probability and information gain for feature weight and feature elimination respectively. Rath et. al [42] developed a deep learning method for predicting heart disease from the imbalanced ECG samples. This method used Generative Adversarial Network (GAN) model for dealing with the imbalanced samples and used an ensemble of LSTM and GAN for classification. Chen et. al [13] designed a Local Feature based LSTM (LF-LSTM) and a deep learning ensemble for detecting heart rate variability and acceleration. Plawiak et. al [38] proposed a deep ensemble method using genetic algorithm for cardiac arrhythmia detection using ECG signals. This method fused normalization, hamming window, cross-validation for constructing the layers of deep ensemble. It can be seen from the related works that the ensemble learning can be either homogeneous or heterogeneous. The former will have a single base learning algorithm and the latter will have different base learning algorithms. The choice of the base learner is directly proportional to the effectiveness of the ensemble. This paves the way to carry out extensive research in the area of ensemble classification. Moreover, it can be seen that the deep ensemble models provide a higher performance by utilizing the merits of both ensemble and deep learning models. In this research, a dual layer stacking ensemble that uses three different base learning algorithms in each layer and a deep heterogeneous ensemble are proposed and are applied to diagnose heart disease. 3. The Proposed Ensemble Methodologies 3.1. Dual Layer Stacking Ensemble (DLSE) The proposed DLSE approach involves two layers of base learners and a final meta-learner to provide the final prediction. The Enhanced Evolutionary Feature Selection (EEFS) [40] algorithm is used to select the best feature set from the input training set. The best training set is then subjected to k-fold Cross Validation (CV) and is split into K disjoint subsets of equal size and one set from the K subsets is selected as the validation set. Once the K training sets are constructed the base learners in layer- 1 are trained and validated. We have used three classifiers NB, DT and SVM as the base learners in layer- 1. The prediction results of all the three classifiers are recorded and all the layer-1 predictions are then combined with the original training set and a new training set is given as input to layer-2 by combining the training set with the prediction matrix generated in layer-1. Layer-1 can be considered as the feature generator for layer-2. This new training set is again subjected to k-fold CV and it results in K disjoint subsets of same size. Once again one subset is chosen at random as the validation set. Now the base learners in layer-2 are trained and validated. In layer-2 we have chosen ensemble classifiers ERT, ABC and RF as base learning algorithms. The second layer uses ensemble classifiers instead of traditional classifiers because the en-\n161Information Technology and Control 2022/1/51\nsemble-based classifiers always provide a better performance than the traditional classifiers [20, 22, 45, 47]. All layer-2 predictions are then used to train the meta-classifier GBT. The meta-learner then provides the final prediction. The flow diagram of the proposed DLSE technique is shown in Figure 1.\nFigure 1 Flow diagram of the proposed DLSE Method\nis tournament with all the other parameters remaining in their default values. The solver for LDA is set as Singular Value Decomposition (SVD) and the remaining parameters are set with their default values. Table 1\nEEFS algorithm hyperparameters setting\nAlgorithm Hyperparameters Setting\nEEFS\npopulation_size = 50 max_generations = 100 crossover probability = 0.8 mutation probability = 0.1 solver = \u2018svd\u2019\nFigure 1\nFlow diagram of the proposed DLSE Method\nAlgorithm 1 Pseudocode of proposed DLSE\nAlgorithm Input:  1 2 t m n metaS= s ,s , \u2026\u2026 s ,K=10, C , C , C Output: Prediction result p\u0302\nInformation Technology and Control 2022/1/51162\nAlgorithm\nInput: { }1 2 t m n metaS= s ,s , \u2026\u2026 s ,K=10, C , C , C Output: Prediction result p\u0302\nBegin [ ]bestS s = apply EEFS algorithm on S to select the best features. Split [ ]bestS s into [ ] [ ]train testS s , S s\n[ ] [ ] yields k train traincross_validation(K,S s ) S s\u2192\n[ ] [ ] ( )r k valid trainS s S s , r=rand 1, K \u2190\n//Layer -1 for each i in mC : Train a base learner iC on [ ]ktrainS s\nBegin  bestS s = apply EEFS algorithm on S to select the best features. Split  b tS s into    train testS s , S s\n    yields k train traincross_validation(K,S s ) S s\n      r k valid trainS s S s , r=rand 1, K \n//Layer -1proposed for ach i in mC :\nTrain a base learner iC on  ktrainS s\n  i ' vS s  Apply iC on   validS s\nend for Construct the prediction matrix\n        k1 k2 km ' ' ' ' v v v vS s {S s , S s \u2026\u2026 S s }\n//Layer -2\n      yields ' k train v traincross_validation(k,S s S s ) S s \n      r ' k valid trainS s S s , r=rand 1, k  for each i in nC :\nTrain a base learner iC on  ktrainS s\n  i '' vS s  Apply iC on   ' validS s\nend for Construct the prediction matrix\n        k1 k2 km '' '' ' '' v v v vS s {S s , S' s \u2026\u2026 S s }\n//Meta-Classifier Train metaC based on   ''vS s //Testing phase for i=1 to m and j = 1 to n do: Apply testS [s] on layer-1 base learners to obtain prediction set\n    ' c 1 i 2 i m tS s C (s ),C (s ), \u2026\u2026 C (s )\nApply    'test cS s S s on layer-2 base learners to obtain prediction set\n    '' ' ' ' C 1 i 2 i n tS s C (s ),C (s ), \u2026\u2026 C (s )\nend for Apply meta C to perform classification on\n   ' ''c CS s S s Return the final prediction ip End\n3.1.2. Layer-1 Base Learners The first layer of the proposed DLSE method consists of three simple classifiers. Three state-of-the-art classifiers NB [62], DT [27] and SVM [19, 64] have been used as base learning algorithms in layer-1. The Nave Bayes classification algorithm is well-known\n[29]. It estimates the conditional probability of each class given the observation and chooses the class with the highest posterior probability as the correct answer [50, 59]. It is employed in layer-1 because it requires the least amount of storage space to hold the probabilities in both the training and classification stages, making it a good fit for the high-dimensional datasets utilized in our research. SVM is based on statistical learning theory, which has since been improved by a number of other researchers. In SVM, kernel functions are used to map training samples in high-dimensional space in a nonlinear way [56]. For mapping and optimizing the separation between data points, several kernel functions such as polynomial, Gaussian, and sigmoid are utilized. SVM's advantages, such as its success in high-dimensional spaces and flexibility in kernel function selection, have made it appealing for a variety of applications, including disease prediction, speech recognition, and text categorization. The DT classifier uses a tree-like graph and does not require any domain expertise. It creates conditional probabilities for research analysis and selects the optimal option for traversing from root to leaf, indicating distinct class separation [49]. It can be used in the medical industry to classify and forecast diseases. Moreover, the combination of NB, SVM and DT have proven to be very effective in classification [8, 9, 26]. Hence we have chosen the three classifiers for layer-1 of DLSE. The parameter setting for each of the algorithm is described in Table 2. Table 2 DLSE Layer-1 base learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nNB -\nDT\ncriterion = \u2018gain_ratio\u2019 max_depth = 10 min_split_size = 4 minimal_gain = 0.01\nSVM kernel=\u2019dot\u2019 max iterations =100000 convergence_epsilon = 0.001\nThe DT algorithm uses gain ratio as the criterion for selecting the attributes to split the tree and the maximum depth is set as 10 with the minimum split size being set as 4. The gain ratio RatioG measure is given by Equation (1),\n     Gain i Ratio i i I d ,S G d ,S = , (1) H d ,S\nwhere, id is the attribute in training set S .   ,iH d S is the entropy measure for the attribute id in the set .S  ,Gain iI d S is the information gain for the attribute id in the set S and is given by Equation (2),\nly i on [ ] validS s end for Construct the prediction matrix\n[ ] [ ] [ ] [ ]k1 k2 km ' ' ' ' v v v vS s {S s , S s \u2026\u2026 S s }\u2190\n//Layer -2\n[ ] [ ] [ ] yields ' k train v traincross_validation(k,S s S s ) S s\u222a \u2032\u2192\n[ ] [ ] ( )r ' k valid trainS s S s , r=rand 1, k \u2032\u2190 for each i in nC : Train a base learner iC on [ ]ktrainS s\u2032 [ ]\ni\n'' vS s \u2190 Apply iC on [ ] ' validS s\nend for Construct the prediction matrix\n[ ] [ ] [ ] [ ]k1 k2 km '' '' ' '' v v v vS s {S s , S' s \u2026\u2026 S s }\u2190\n//Meta-Classifier\nTrain metaC based on [ ]( )''vS s //Testing phase for i=1 to m and j = 1 to n do: Apply testS [s] on layer-1 base learners to obtain prediction set [ ] { } ' c 1 i 2 i m tS s C (s ),C (s ), \u2026\u2026 C (s )\u2190\nApply [ ] [ ]'test cS s S s\u222a on layer-2 base learners o obtain prediction set [ ] { } '' ' ' ' C 1 i 2 i n tS s C (s ),C (s ), \u2026\u2026 C (s )\u2190 end for Apply metaC to perform classification on [ ] [ ]' ''c CS s S s\u222a Return the final prediction\nBegin  bestS s = apply EEFS algorithm on S to select the best features. Split  bestS s into    train testS s , S s\n    yields k train traincross_validation(K,S s ) S s\n      r k valid trainS s S s , r=rand 1, K \n//Layer -1proposed for each i in mC :\nTrain a base learner iC on  ktrainS s\n  i ' vS s  Apply iC on   validS s\nend for Construct the prediction matrix\n        k1 k2 km ' ' ' ' v v v vS s {S s , S s \u2026\u2026 S s }\n//Layer -2\n      yields ' k train v traincross_validation(k,S s S s ) S s \n      r ' k valid trainS s S s , r=rand 1, k  for each i in nC :\nTrain a base learner iC on  ktrainS s\n  i '' vS s  Apply iC on   ' validS s\nend for Construct the prediction matrix\n        k1 k2 km '' '' ' '' v v v vS s {S s , S' s \u2026\u2026 S s }\n//Meta-Classifier Train metaC based on   ''vS s //Testing phase for i=1 to m and j = 1 to n do: Apply testS [s] on layer-1 base learners to obt in prediction set\n    ' c 1 i 2 i m tS s C (s ),C (s ), \u2026\u2026 C (s )\nApply    'test cS s S s on layer-2 base learners to obtain prediction set\n    '' ' ' ' C 1 i 2 i n tS s C (s ),C (s ), \u2026\u2026 C (s )\nend for Apply meta C to perform classifica ion on    ' ''c CS s S s Return the final predicti ip\nEnd\n3.1.2. Layer-1 Base Learners The first layer of the proposed DLSE method consists of thre simple classifiers. Three state-of-the-art classifiers NB [62], DT [27] and SVM [19, 64] have been used as base learning algorithms in layer-1. The Nave Bayes classification algorithm is well-known\n[29]. It estimates the conditional probability of each class given the observation and chooses the class with the highest posterior probability as the correct answer [50, 59]. It is employed in layer-1 because it requires the least amount of storage space to hold the probabilities in both the training and classification stages, making it a good fit for the high-dimensional datasets utilized in our research. SVM is based on statistical learning theory, which has since been improved by a number of other researchers. In SVM, kernel functions are used to map training samples in high-dimensional space in a nonlinear way [56]. For mapping and optimizing the separation between data points, several kernel functions such as polynomial, Gaussian, and sigmoid are utilized. SVM's advantages, such as its success in high-dimensional spaces and flexibility in kernel function selection, have made it appealing for a variety of applications, including disease prediction, speech recognition, and text categorization. The DT classifier uses a tree-like graph and does not require any domain expertise. It creates conditional probabilities for research analysis and selects the optimal option for traversing from root to leaf, indicating distinct class separation [49]. It can be used in the medical industry to classify and forecast diseases. Moreover, the combination of NB, SVM and DT have proven to be very effective in classification [8, 9, 26]. Hence we have chosen the three classifiers for layer-1 of DLSE. The parameter setting for each of the algorithm is described in Table 2. Table 2 DLSE Layer-1 base learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nNB -\nDT\ncriterion = \u2018gain_ratio\u2019 max_depth = 10 min_split_size = 4 minimal_gain = 0.01\nSVM kernel=\u2019dot\u2019 max iterations =100000 convergence_epsilon = 0.001\nThe DT algorithm uses ga n ratio as the criterion for selecting the attribut s to split the tree and the maximum depth is set as 10 with the minimum split size being set as 4. The gain ratio RatioG measure is given by Equation (1),\n     Gain i Ratio i i I d ,S G d ,S = , (1) H d ,S\nwhere, id is the attribute in training set S .   ,iH d S is the entropy measure for the attribute id in the set .S  ,Gain iI d S is the information gain for the attribute id in the set S and is given by Equation (2),\nEnd\nAlgorithm 1 Pseudocode of proposed DLSE The pseudocode of the proposed Dual-Layer Stacking Ensemble (DLSE) method is shown in Algorithm 1 and the working principle is discussed. The dataset { }1 2 tS= s ,s , \u2026\u2026 s along with the layer-1 base learners mC , the layer-2 base learners nC , and the meta-learner metaC are provided as the input. Feature selection is applied on the dataset S to extract only the useful and important features. The feature selection of the data is performed by the GA-LDA [40] algorithm. The GA-LDA algorithm selects the best features [ ]bestS s from the given input dataset S. The data is then split into training set [ ]trainS s and testing set [ ]testS s by applying the 80-20 rule. Then k-fold CV is applied. We have chosen the value of K=10 for validating the data. The CV yields K disjoint subsets [ ]ktrainS s with same size. The validation set [ ] validS s is chosen randomly from the training set [ ]ktrainS s . The training set [ ]ktrain S s is used for training the base learners mC in layer-1. After training the validation set [ ] validS s is applied on the layer-1 base learners to obtain the prediction result [ ]\ni\n' vS s and a prediction matrix\n[ ]'vS s is constructed by repeating the procedure K times. Then the results are fed to the second layer. The second layer combines the training set [ ] trainS s generated in layer-1 with the prediction matrix [ ]'vS s . This is done to ensure the learnings of layer-1 are propagated to layer-2. Again k-fold CV with K=10 is applied to form the new training set The\nCV yields another K disjoint subsets of same size [ ]ktrainS s .\u2032 The validation set [ ]'validS s is chosen randomly from the training set [ ]ktrainS s\u2032 . The training set [ ]ktrain S s\u2032 is used for training the base learners nC in layer-2. After training, the validation set [ ]'validS s is applied on the layer-2 base learners to obtain the prediction result [ ]\ni\n'' vS s and this step is repeated k times to con-\nstruct the prediction matrix [ ]''vS s . The meta-learner metaC is trained using the prediction matrix [ ]''vS s constructed from layer-2. In the testing-phase, the test data [ ]testS s is applied to each of the layer-1 and layer-2 base learners mC and nC and the prediction set [ ]'cS s and [ ]''CS s are constructed. Then the meta-learner is provided with the union of [ ]'cS s and [ ]''CS s to perform classification and the final prediction p\u0302 is returned.\n163Information Technology and Control 2022/1/51\n3.1.1. Feature Selection Using EEFS The dataset is feature selected using EEFS algorithm. EEFS is an evolutionary feature selection algorithm that utilizes the advantages of both GA and LDA. This algorithm treats each individual in a population as a binary string that encodes a feature subset. Therefore, for a dataset S of F features, it will be represented as an F-bit binary string. The '1' bits in the F-bit binary string correspond to the features that are selected and the '0' bits correspond to the features that are not selected. Table 1 shows the hyperparameters setting for EEFS algorithm.\nThe population size is set as 50 with maximum generations being assigned a value of 100. The crossover probability and mutation probability are set as 0.8 and 0.1 respectively. The selection scheme used is tournament with all the other parameters remaining in their default values. The solver for LDA is set as Singular Value Decomposition (SVD) and the remaining parameters are set with their default values.\n3.1.2. Layer-1 Base Learners The first layer of the proposed DLSE method consists of three simple classifiers. Three state-ofthe-art classifiers NB [62], DT [27] and SVM [19, 64] have been used as base learning algorithms in layer-1. The Nave Bayes classification algorithm is well-known [29]. It estimates the conditional probability of each class given the observation and chooses the class with the highest posterior probability as the correct answer [50, 59]. It is employed in layer-1 because it requires the least amount of storage space to hold the probabilities in both the training and classification stages, making it a good fit for the high-dimensional datasets utilized in our research. SVM is based on statistical learning\u00a0 theory, which has since been improved by a number of other researchers. In SVM, kernel functions are\nused to map training samples in high-dimensional space in a nonlinear way [56]. For mapping and optimizing the separation between data points, several kernel functions such as polynomial, Gaussian, and sigmoid are utilized. SVM's advantages, such as its success in high-dimensional spaces and flexibility in kernel function selection, have made it appealing for a variety of applications, including disease prediction, speech recognition, and text categorization. The DT classifier uses a tree-like graph and does not require any domain expertise. It creates conditional probabilities for research analysis and selects the optimal option for traversing from root to leaf, indicating distinct class separation [49]. It can be used in the medical industry to classify and forecast diseases. Moreover, the combination of NB, SVM and DT have proven to be very effective in classification [8, 9, 26]. Hence we have chosen the three classifiers for layer-1 of DLSE. The parameter setting for each of the algorithm is described in Table 2.\nThe DT algorithm uses gain ratio as the criterion for selecting the attributes to split the tree and the maximum depth is set as 10 with the minimum split size being set as 4. The gain ratio RatioG measure is given by Equation (1),\n( ) ( )( ) Gain i Ratio i i I d ,S G d ,S = , (1) H d ,S (1)\nwhere, id is the attribute in training set S . ( ) ,iH d S is the entropy measure for the attribute id in the set .S ( ),Gain iI d S is the information gain for the attribute id in the set S and is given by Equation (2),\nInformation Technology and Control 2022/1/51164\n   \n   i i,j i i,j\ni,j i\nGain i\nd =v d =v\nv dom d\nI d ,S = H y,S -\n\u03c3 S * H y,\u03c3 S , (2)\u02c6\nS\n\u02c6\n \nwhere, y\u0302 is the target attribute, i i,j d =v \u03c3 S\nS is the\nproportion of the number of elements in category i over the total number of records S and  ,\u02c6H y S is the entropy measure given by the Equation (3),\n   \nj j\nj\ny=c y=c 2\nc do \u02c6m y\n\u02c6 \u02c6\u03c3 S \u03c3 S )\u02c6 H y,S = - log (3\nS S \nThe SVM uses dot kernel with a maximum iteration of 100000 along with the convergence epsilon value 0.001. The rest of the parameters of all the base learners remain in their default values.\n3.1.3. Layer-2 Base Learners In layer-2 three ensemble classifiers ERT [37], ABC [21] and RF [41] are used as base learning algorithms. Two of the most popular averaging methods are RF and ERTs. Before looking for the best features and split spots, it goes through two independent randomized algorithms. To begin, RF randomly selects a fixed number from the training set, similar to bagging [24]. Each decision tree is then grown using a randomly selected subset of input features. RF lowers variance and avoids overfitting by combining the two randomized techniques. ERT is similar to RF. The bagging approach, on the other hand, is not employed when assigning training samples to each base learner. Instead, each base student is given the same set of training materials. Furthermore, the input feature and its splitting value are picked at random for the building of base learners, whereas RF looks for the highest discriminative thresholds. ABC allows predictors to be learned in a sequential manner. Iterative training is used to change weights for each observation and each base learner, lowering both variation and bias [15]. Moreover, the combination of these classifiers are proven to be effective [65] and hence we have chosen these three classifiers for layer-2 of DLSE. The parameter setting for the layer-2 base learners is shown in Table 3. The ERT classifier uses a random subset just like RF but the random thresholds are set for each candidate feature and the best among the random thresholds is selected as the splitting criteria. The ERT uses averaging to minimize over-fitting and to maximize accuracy. Table 3 DLSE Layer-2 base learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nERT\nn_estimators = 200 criterion = \u2018gini\u2019 max_depth = 10 min_samples_split=2\nABC base_estimator = \u2018Decision Tree\u2019 n_estimators = 200 learning_rate = 1\nRF\nn_estimators = 200\ncriterion = \u2018gini\u2019\nmax_depth = 10 min_samples_split=2\nThe ABC uses a decision tree as the base estimator with a learning rate of 1. All the learners are configured with 200 estimators and the other parameters remain with default values. The RF uses gini index as the criterion for split with a maximum depth of 10. The gini index IndexG is given by Equation (4),\nc 2\nIndex gg=1 G =1- D , (4)\nwhere, gD is the proportion of samples that belongs to the class c for a particular tree node.\n3.1.4. Meta-Learner The GBT [34, 39] classifier is used as the metalearner. The meta-learner is a regressor that allows optimization of least squares regression loss function cL . At each stage of the regressor a regression tree is fit based on the negative gradient of the loss function c L . The cL is given by Equation (5), the negative gradient of the loss function cL . The cL is given by Equation (5),\n     n\nc i c-1 i i i=1\nL = l p ,E e + T e , (5) \nwhere, c L is the loss for c th ensemble, ip is the prediction for input ie , c-1E corresponds to the previous ensemble. T corresponds to the estimators used in the ensemble. A newly constructed tree cT is fit accordingly to minimize the loss cL given by previous ensemble c-1E as shown in Equations (6)- (7).\nc CT T =arg min L . (6)\nBy using Equation (5), we can rewrite Equation (6) as,\n     n\nc i c-1 i iT i=1\nT = arg min l p ,E e + T e . (7) \nTable 4 DLSE meta-learner hyperparameters setting\n(2)\nwhere, y\u0302 is the target attribute,\n   \n   i i,j i i,j\ni,j i\nGain i\nd =v d =v\nv dom d\nI d ,S = H y,S -\n\u03c3 S * H y,\u03c3 S , (2)\u02c6\nS\n\u02c6\n \nwhere, y\u0302 is the target attribute, i i,j d =v \u03c3 S\nS is the\nproportion of the number of elements in category i over the total number of records S and  ,\u02c6H y S is the entropy measure given by the Equation (3),\n   \nj j\nj\ny=c y=c 2\nc do \u02c6m y\n\u02c6 \u02c6\u03c3 S \u03c3 S )\u02c6 H y,S = - log (3\nS S \nThe SVM uses dot kern l with a maximu iteration of 100000 along with t e convergence epsilon value 0.001. The rest of the parameters of all the base learners remain in their default values.\n3.1.3. Layer-2 Base Learners In layer-2 three ensemble classifiers ERT [37], ABC [21] and RF [41] are used as base learning algorithms. Two of the most popular averaging methods are RF and ERTs. Before looking for the best features and split spots, it goes through two independent randomized algorithms. To begin, RF randomly selects a fixed number from the training set, similar to bagging [24]. Each decision tree is then grown using a randomly selected subset of input features. RF lowers variance and avoids overfitting by combining the two randomized techniques. ERT is similar to RF. The bagging approach, on the other hand, is not employed when assigning training samples to each base learner. Instead, each base student is given same se of training materials. Furthermore, the i put feature and its splitting v lu are picked at random for the buildin of base learners, whereas RF looks for the highest discrimi ative thresholds. ABC allows predictors to be learned in a sequential manner. Iterative training is used to change weights for each observation and each base learner, lowering both variation and bias [15]. Moreover, the combination of these classifiers are proven to be effective [65] and hence we have chosen these three classifiers for layer-2 of DLSE. The parameter setting for the layer-2 base learners is shown in Table 3. The ERT classifier uses a random subset just like RF but the random thresholds are set for each candidate feature and the best among the random thresholds is selected as the splitting criteria. The ERT uses averaging to minimize over-fitting and to maximize accuracy. Table 3 DLSE Layer-2 base learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nERT\nn_estimators = 200 criterion = \u2018gini\u2019 max_depth = 10 min_samples_split=2\nABC base_estimator = \u2018Decision Tree\u2019 n_estimators = 200 learning_rate = 1\nRF\nn_estimators = 200\ncriterion = \u2018gini\u2019\nmax_depth = 10\nin_sa ples_split=2\nThe ABC uses a decision tr sti ator with a learning rate of . r ers are configured with 200 esti t e other parameters remain with def l F uses gini ndex as the criterion f r axi um depth of 10. The gini i Index i iven by Equation (4),\nc 2\nIndex gg=1 G =1- D , (4)\nwhere, gD is the proportion of samples that belongs to the class c for a particular tree node.\n3.1.4. Meta-Learner The GBT [34, 39] classifier is used as the metalearner. The meta-learner is a regressor that allows optimization of least squares regression loss function cL . At each stage of the regressor a regression tree is fit based on the negative gradient of the loss function c L . The cL is given by Equation (5), the negative gradient of the loss function cL . The cL is given by Equation (5),\n     n\nc i c-1 i i i=1\nL = l p ,E e + T e , (5) \nwhere, c L is the loss for c th ensemble, ip is the prediction for input ie , c-1E corresponds to the previous ens mble. T corresponds to the estimators used in the ensemble. A newly constructed tree cT is fit acc rdingly to minimize the loss cL given by previous ensemble c-1E as shown in Equations (6)- (7).\nc CT T =arg min L . (6)\nBy using Equation (5), we can rewrite Equation (6) as,\n     n\nc i c-1 i iT i=1\nT = arg min l p ,E e + T e . (7) \nTable 4 DLSE meta-learner hyperparameters setting\nis the pro-\nportion of the number of elements in category i over the total number of records S and ( ),\u02c6H y S is the entropy measure given by the Equation (3),\n   \n   i i,j i i,j\ni,j i\nGain i\nd =v d =v\nv dom d\nI d ,S = H y,S -\n\u03c3 S * H y,\u03c3 S , (2)\u02c6\nS\n\u02c6\n \nwhere, y\u0302 is the target attribute, i i,j d =v \u03c3 S\nS is the\nproportion of the number of elements in category i over the total number of ecords S and  ,\u02c6H y S is the entropy meas re given by the Equation (3),\n   \nj j\nj\ny=c y=c 2\nc do \u02c6m y\n\u02c6 \u02c6\u03c3 S \u03c3 S )\u02c6 H y,S = - log (3\nS S \nThe SVM uses dot kernel with a maximum iteration of 100000 along with the convergence epsilon value 0.001. The rest of the parameters of all the base learners remain in their default values.\n3.1.3. Layer-2 Base Learners In layer-2 three en mble classifiers ERT [37], ABC [21] and RF [41] are used as base learning algorithms. Two of the most popular averaging methods are RF and ERTs. Before looking for the best features and split spots, it goes through two independent randomized algorithms. To begin, RF randomly selects a fixed number from the training set, similar to bagging [24]. Each decision tree is then grown using a randomly selected subset of input features. RF lowers variance and voids overfitting by combining the t o randomized t chniqu s. ERT is similar to RF. The bagging approach, on the other hand, is not employed when assigning training samples to each base le rner. Instead, each base stude t is given the same set of training mater als. Furthermore, the input feature and its splitting v lue are picked at random for the building of base learners, whereas RF looks for t e highest discriminative thresholds. ABC allows predictors to be learned in a sequential manner. Iterative training is used to change weights for each observation and each base learner, lowering both variation and bias [15]. Moreover, the combination of these classifiers are proven to be effective [65] and hence we have chosen these three classifiers for layer-2 of DLSE. The parameter setting for the layer-2 base learners is shown in Table 3. The ERT classifier uses a random subset just like RF but the random thresholds are set for each candidate feature and the best among the random thresholds is selected as the splitting criteria. The ERT uses averaging to minimize over-fitting and to maximize accuracy. Table 3 DLSE Layer-2 base learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nERT\nn_estimators = 200 criterion = \u2018gini\u2019 max_depth = 10 min_samples_split=2\nABC base_esti ator = \u2018Decision Tree\u2019 n_estimators = 200 learning_rate = 1\nRF\nn_ stimators = 200\ncriterion = \u2018gini\u2019\nmax_depth = 10\nmin_sam les_split=2\nThe ABC uses a decision tree as the base estimator with a learning rate of 1. All the learners are configured with 200 estimators and the other parameters remain with default values. The RF uses gini index as the criterion for split with a maximum depth of 10. The gini i dex IndexG is given by Equa ion (4),\nc 2\nIndex gg=1 G =1- D , (4)\nwhere, gD is the proportion of samples that belongs to the class c for a particular tree node.\n3.1.4. Meta-Learner The GBT [34, 39] classifier is used as the metalearner. The meta-learner is a regressor that allows optimization of least squares regression loss function cL . At e ch stage of he regressor a regression tree s fit based on the negative g adi nt of th loss fu ction c L . The cL is given by Equation (5), the negative gradient of the loss function cL . The cL is given by Equat o (5),\n     n\nc i c-1 i i i=1\nL = l p ,E e + T e , (5) \nwhere, c L is the loss for c th ensemble, ip is the prediction for input ie , c-1E corresponds to the previous ensemble. T corresponds to the estimators used in the ensemble. A newly c structed tree cT is fit accordi gly to minimize the loss cL given by previous ensemble c-1E as shown in Equations (6)- (7).\nc CT T =arg min L . (6)\nBy using Equation (5), we can rewrite Equation (6) as,\n     n\nc i c-1 i iT i=1\nT = arg min l p ,E e + T e . 7 \nTable 4 DLSE meta-learner hyperparameters setting\n(3)\nThe SVM uses dot kernel with a maximum iteration of 100000 along with the convergence epsilon value 0.001. The rest of the par meters of all the base learners emain in their d fault values.\n3.1.3. Layer-2 Base Learners In layer-2 three ensemble classifiers ERT [37], ABC [21] and RF [41] are used as base lear ing algorithms. Two of the most popular averaging methods are RF and ERTs. \u00a0 Before looking for the best features and split spots, it goes through two independent ran omized algorithms. To begin, RF rand mly s lects a fixed numb r from the training set, similar t bagging [24]. E ch decision tree is he grown sing a randomly selected subset of input features. RF lowers variance and avoids overfitting by combining the two randomized techn ques. ERT is\u00a0 similar\u00a0 to RF. The bagging approach, on the other hand, is not employed when assigning training sa pl s o each base lear er. In tead, each base st dent s given the same s t of training mat ials. Fu the mor , the input feature and its splitting value are picked at random for the building of base learners, whereas RF looks for the highest discriminative thresholds. ABC\u00a0 allows predictors to be learned in a sequential manner. Iterative training is used to change weights for each observation and eac base learner, lowering both variation and bias [15]. Moreover, the combination of these cla sifiers are proven to be effectiv [65] and hence we h ve chosen these three classifiers for layer-2 of DLSE. The parameter s tting for th layer-2 base learn rs is shown in\nTable 3. The ERT classifier uses a random subset just like RF but the random thresholds are set for each candidate feature and the b st among the random thresholds is selected as the splitting criteria. The ERT uses averaging to minimize ov -fitting and to maximize accuracy.\nTable 3 DLSE Layer-2 base learner hyperparameters setting\nAlgorithm Hyperparameter Setting\nERT\nn_estimators = 200 criterion = \u2018gini\u2019 max_depth = 10 min_samples_split=2\nABC base_estimator = \u2018Decision Tree\u2019 n_estimators = 200 learning_rate = 1\nRF\nn_estimators = 00 criterion = \u2018gini\u2019 ma _depth = 10 min_samples_ plit=2\nThe ABC uses a decision tree as the base estimator with a learning rate of 1. All the learners are configured with 200 estimators and the other parameters remain with default values. The RF uses gini index as the criterion for split with a maxim m depth of 10. The gini index IndexG is given by Equation (4),\nc 2 Index gg=1\nG =1- D , (4)\u2211 (4) where, gD is the proportion of samples that belongs to the class c for a particular tree node.\n3.1.4. Meta-Learner The GBT [34, 39] classifier is used as the meta-learner. The meta-learner is a regressor that allows optimization of least squar s regression loss function cL . At each stage of the regressor a regression tree is fit based on the negative gradient of the loss function c L . The cL is given by Equation (5), the negative gradient of the loss function cL . The cL is given by Equation (5),\n( ) ( )( ) n\nc i c-1 i i i=1\nL = l p ,E e + T e , (5) \u2211 (5)\n165Information Technology and Control 2022/1/51\nwhere, cL is the loss for c th ensemble, ip is the prediction for input ie , c-1E corresponds to the previous ensemble. T corresponds to the estimators used in the ensemble. A newly constructed tree cT is fit accordingly to minimize the loss cL given by previous ensemble c-1E as shown in Equations (6)-(7).\nc CT T =arg min L . (6) (6)\nBy using Equation (5), we can rewrite Equation (6) as,\n( ) ( )( ) n\nc i c-1 i iT i=1\nT = arg min l p ,E e + T e . (7) \u2211 (7)\nTable 4 DLSE meta-learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nGBT\nn_estimators = 200 criterion = \u2018friedman_mse\u2019 max_depth = 10 learning_rate = 0.01\nThe parameter setting for the meta-learner is shown in Table 4. The number of estimators is set as 200 and the maximum depth is set to 10 with the learning rate of 0.01. The criterion for measuring the quality of the split used is the Friedman mean squared error fmse R and is given by Equation (8),\n( ) ( )( )21 2fmse 1 2 n *n R = * x 1 - x 2 (8), n + n (8)\nwhere, 1 2n ,n are the number of examples in each sub node and ( )x n corresponds to the mean output of the n th sub node. The final prediction\nBegin  bestS s = apply EEFS algorithm on S to select the best features. Split  bestS s into    train testS s , S s\n    yields k train traincross_validation(K,S s ) S s\n      r k valid trainS s S s , r=rand 1, K \n//Layer -1p oposed for each i in mC :\nTrain a base learner iC on  ktrainS s\n  i ' vS s  Apply iC on   validS s\nend for Construct the prediction matrix\n        k1 k2 km ' ' ' ' v v v vS s {S s , S s \u2026\u2026 S s }\n//Layer -2\n      yields ' k train v traincross_validation(k,S s S s ) S s \n      r ' k valid trainS s S s , r=rand 1, k  for each i in nC :\nTrain a base learner iC on  ktrainS s\n  i '' vS s  Apply iC on   ' validS s\nend for Construct the prediction matrix\n        k1 k2 km '' '' ' '' v v v vS s {S s , S' s \u2026\u2026 S s }\n//Meta-Classifier Train metaC based on   ''vS s //Testing phase fo i=1 to m and j = 1 to n do: Apply testS [s] on layer-1 base learners to obtain predicti n set\n    ' c 1 i 2 i m tS s C (s ),C (s ), \u2026\u2026 C (s )\nApply    'test cS s S s on layer-2 base learners to obtain prediction set\n    '' ' ' ' C 1 i 2 i n tS s C (s ),C (s ), \u2026\u2026 C (s )\nend for Apply meta C to perform classification on\n   ' ''c CS s S s Return the final predictio ip End\n3.1.2. Layer-1 Base Learners The first layer of the proposed DLSE method consists of three simple classifiers. Three state-of-the-art classifiers NB [62], DT [27] and SVM [19, 64] have been used as base learning algorithms in layer-1. The Nave Bayes classification algorithm is well-known\n[29]. It estimates the conditional probability of each class given the observation and chooses the class with the highest posterior probability as the correct answer [50, 59]. It is employed in layer-1 because it requires the least amount of storage space to hold the probabilities in both the training and classification stages, making it a good fit for the high-dimensional datasets utilized in our research. SVM is based on statistical learning theory, which has since been improved by a number of other researchers. In SVM, kernel functions are used to map training samples in high-dimensional space in a nonlinear way [56]. For mapping and optimizing the separation between data points, several kernel functions such as polynomial, Gaussian, and sigmoid are utilized. SVM's advantages, such as its success in high-dimensional spaces and flexibility in kernel function selection, have made it appealing for a variety of applications, including disease prediction, speech recognition, and text categorization. The DT classifier uses a tree-like graph and does not require any domain expertise. It creates conditional probabilities for research analysis and selects the optimal option for traversing from root to leaf, indicating distinct class separation [49]. It can be used in the medical industry to classify and forecast diseases. Moreover, the combination of NB, SVM and DT have proven to be very effective in classification [8, 9, 26]. Hence we have chosen the three classifiers for layer-1 of DLSE. The parameter setting for each of the algorithm is described in Table 2. Table 2 DLSE Layer-1 base learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nNB -\nDT\ncriterion = \u2018gain_ratio\u2019 max_depth = 10 min_split_size = 4 minimal_gain = 0.01\nSVM kernel=\u2019dot\u2019 max iterations =100000 convergence_epsilon = 0.001\nThe DT algorithm uses gain ratio as the criterion for selecting the attributes to split the tree and the maximum depth is set as 10 with the minimum split size being set as 4. The gain ratio RatioG measure is given by Equation (1),\n     Gain i Ratio i i I d ,S G d ,S = , (1) H d ,S\nwhere, id is the attribute in training set S .   ,iH d S is the entropy measure for the attribute id in the set .S  ,Gain iI d S is the information gain for the attribute id in the set S and is given by Equation (2),\nfor the given input ie is given by Equation (9),\nAlgorithm Hyperparameters Setting\nGBT\nn_estimators = 200 criterion = \u2018friedman_mse\u2019 max_depth = 10 learning_rate = 0.01\nThe parameter setting for the meta-learner is shown in Table 4. The nu ber of estimators is set as 200 and the maximum depth is set to 10 with the learning rate of 0.01. The criterion for measuring the quality of the split used is the Friedman mean squared error fmse R and is given by Equation (8),\n    21 2fmse 1 2 n *n R = * x 1 - x 2 (8), n + n\nwhere, 1 2n ,n are the number of examples in each sub node and  x n corresponds to the mean output of the n th sub node. The final prediction ip for the given input ie is given by Equation (9),\n     C\ni C i c i c=1\np = E e = T e , (9)\nwhere, C corresponds to the number of estimators n_estimators parameter nd cT are the estimator also called as weak learners. The meta-learner uses a fixed size of weak learners.\n3.2. Deep Heterogeneous Ensemble (DHE) The pseudocode of the proposed DHE algorithm is shown in Algorithm 2. The proposed DHE technique involves one layer of base learners and two layers of meta-learners to provide the final prediction. The first layer consists of three deep learning models CNN BiLSTM, ANN and RNN. The reason for selecting the base learners are deep learning models is from the fact that the deep learning models perform extremely well when the data and the feature sets are higher and also removes the need for manual feature extraction. The large dataset is split into training set Utrain and testing set Utest. The training set Utrain subjected to 10-fold CV to generate the K training sets Utraink . One training set is chosen at random as the validation set . Algorithm 2 Pseudocode of Deep Heterogeneous Ensemble (DHE)\nAlgorithm Input:  1 2 t m meta metaU= u ,u , \u2026\u2026 u ,K=10, B , L1 , L2 limx\nOutput: Prediction result r\u0302 Begin Split the dataset U into train testU , U\nyields\nk train traincross_validation(K,U ) U Randomly select a validation set kvalidU\nfor each j in mB :\nTrain the base learner jB on training set k trainU\nValidate the trained base learner jB using k validU\nRecord the predictions of predictions\nj pB B end for // Level-1 Meta-Learners for each l in metaL1 : Train the meta-learner lL1 based on the prediction matrix pB\nRecord the predictions of predictions\nl pL1 M end for // Level-2 Meta-Learner Train the meta-learner metaL2 based on the prediction matrix pM\nReturn the final prediction r\u0302 End\nThe base learners CNN BiLSTM, ANN and RNN re trained and validated using Utraink and respectively. The predicitons of each base learner is recorder to form the base learner prediction matrix Bp. This prediction matrix is then used to train the Level1 meta learners of DHE. The RF and ERT algorithms are chosen as the level-1 meta learners. These two level-1 meta-learners are trained using the base learner prediction matrix Bp. Then the second level predictions are stored to form the level-1 meta learners prediction matrix Mp. This matrix is then fed as the input to the level-2 meta learner GBT. The level-2 meta learner is trained based on the predictions from Level-1 meta learner and the final prediction r\u0302 is returned as the output. The process flow of DHE is shown in Figure 2. Figure 2 Flow diagram of the proposed DHE Method\n(9)\nwhere, C corresponds to the number of estimators n_ estimators parameter and cT are the estimators also called as weak learners. The meta-learner uses a fixed size of weak learners.\n3.2. Deep Heteroge eous Ensemble (DHE) The pseudocode of the pr p sed DHE algorithm is shown in Algorithm 2. The proposed DHE technique involves one layer of base learners and two layers of meta-learners to provide the final predictio . The first layer consists of three deep learning models CNN BiLSTM, ANN and RNN. The reason for selecting the base learners are deep learning models is from the fact that the deep learning models perform extremely well when the data and the feature sets are higher and also removes the need for manual feature extraction. The large dataset is split into training set Utrain and testing set Utest. The tra ning set Utrain subjected t 10-fold CV to generate the K training sets Utraink . One training set is chosen at random as the validation set .\nAlgorithm 2 Pseudocode of Deep Heterogeneous Ensemble (DHE)\nAlgorithm\nInput: { }1 2 t m meta metaU= u ,u , \u2026\u2026 u ,K=10, B , L1 , L2 limx\u2192\u221e Output: Prediction result r\u0302 Begin Split the dataset U into train testU , U\nyields\nk train traincross_validation(K,U ) U\u2192\nRandomly select a validation set kvalidU for each j in mB : rain the base learner jB on training s t k trainU\nValidate the trained base learner jB using kvalidU Record the predictions of predictions\nj pB B\u2192 end for // Level-1 Meta-Learners for each l in metaL1 : Train the meta-learner lL1 based on the prediction matrix pB Record the predictions of predictions\nl pL1 M\u2192 end for // Level-2 Meta-Learner Train the meta-learner metaL2 based on the pre iction matrix pM Return the final prediction r\u0302 End\nInformation Technology and Control 2022/1/51166\nThe base learners CNN BiLSTM, ANN and RNN are trained and validated using Utraink and respectively. The predicitons of each base learner is recorder to form the base learner prediction matrix Bp. This prediction matrix is then used to train the Level-1 meta learners of DHE. The RF and ERT algorithms are chosen as the level-1 meta learners. These two level-1 meta-learners are trained using the base learner prediction matrix Bp. Then the second level predictions are stored to form the level-1 meta learners prediction matrix Mp. This matrix is then fed as the input to the level-2 meta learner GBT. The level-2 meta learner is trained based on the predictions from Level-1 meta learner and the final prediction r\u0302 is returned as the output. The process flow of DHE is shown in Figure 2.\n3.2.1. Base Learners The data is trained using three base learners CNN BiLSTM [43], ANN [55] and RNN [68]. The CNN BiLSTM is a hybrid bidirectional LSTM and CNN architecture. The CNN BiLSTM comprises of 8 convolutional layers, 4 dropout layers, 4 dense layers, 3 max pooling layers and 1 normalisation layer. The ANN consists of 4 dense layers, 3 dropout layers and 1 normalisation layer. Finally the RNN comprises of 3 dense layers, 2 dropout layers and 1 normalisation layer. The proposed DHE method uses deep learning models as base learners and these base learners consist of a number of hyper parameters such as optimizer, learning rate, number of epochs and so on. Five hyper parameters are selected based on their effect on the performance of the deep learning models. The hyper parameters setting for all the base learners is shown in Table 5. In all the three models the activation function was selected as ReLU, the Rectified Linear Unit function. ReLU is one of the most widely used activation function which allows the deep learning models\nto be trained easily. The next important parameter\nis the number of epochs used to train the model. The epoch determine the number of times a training sample is selected in order to update the weights. This parameter will lead to over-fitting of the model on the training data set and hence needs to be optimised. The CNN BiLSTM model tend to be stable after 50 epochs and the ANN and RNN models were stable af-\n3.2.1. Base Learners The data is trained using three base learners CNN BiLSTM [43], ANN [55] and RNN [68]. The CNN BiLSTM is a hybrid bidirectional LSTM and CNN architecture. The CNN BiLSTM comprises of 8 convolutional layers, 4 dropout layers, 4 dense layers, 3 max pooling layers and 1 normalisation layer. The ANN consists of 4 dense layers, 3 dropout layers and 1 normalisation layer. Finally the RNN comprises of 3 dense layers, 2 dropout layers and 1 normalisation layer. The proposed DHE method uses deep learning models as base learners and these base learners consist of a number of hyper parameters such as optimizer, learning rate, number of epochs and so on. Five hyper parameters are selected based on their effect on the performance of the deep learning models. The hyper parameters setting for all the base learners is shown in Table 5. In all the three models the activation function was selected as ReLU, the Rectified Linear Unit function. ReLU is one of the most widely used activation function which allows the deep learning models to be trained easily. The next important parameter is the number of epochs used to train the model. The epoch determine the number of times a training sample is selected in order to update the weights. This parameter will lead to over-fitting of the model on the training data set and hence needs to be optimised. The CNN BiLSTM model tend to be stable after 50 epochs and the ANN and RNN models were stable after 60 epochs. Another parameter that helps to avoid over-fitting problem is the dropout rate. This parameter ensures the generalisation of the model. The dropout layer allows a fraction of input units to be dropped during training. It ranges between 0 and 1.\nTable 5\nDHE base learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nCNN BiLSTM\nactivation function = \u2019relu\u2019 dropout rate = 0.2 optimizer = \u2019Nadam\u2019 learning rate = 0.7 number of epochs = 50\nANN\nactivation function = \u2019relu\u2019 dropout\nrate = 0.2\noptimizer = \u2019Nadam\u2019\nlearning rate = 0.7 number of epochs = 60\nRNN\nactivation function = \u2019relu\u2019 dropout rate = 0.3 optimizer = \u2019Nadam\u2019 learning rate = 0.7 number of epochs = 60 recurrent dropout = 0.3\nIn all the three models the activation function was selected as ReLU, the Rectified Linear Unit function. ReLU is one of the most widely used activation function which allows the deep learning models to be trained easily. The next important parameter is the number of epochs used to train the model. The epoch determine the number of times a training sample is selected in order to update the weights. This parameter will lead to over-fitting of the model on the training data set and hence needs to be optimised. The CNN BiLSTM model tend to be stable after 50 epochs and the ANN and RNN models were stable after 60 epochs. Another parameter that helps to avoid overfitting problem is the dropout rate. This parameter ensures the generalisation of the model. The dropout layer allows a fraction of input units to be dropped during training. The CNN BiLSTM model and ANN model showed highest performance for the dropout rate of 0.2 and the RNN model showed better performance for dropout rate 0.3. In order to reduce the loss function of the deep learning models an optimizer is used. All the three models performed extremely well for the optmizer \u2019Nadam\u2019 which is an Adam optimizer with Nesterov momentum. Finally the learning rate is another parameter that determines the optimization weights of the optimization algorithm. The learning rate for \u2019Nadam\u2019 optimization algorithm was varied and all the three deep learning algorithms showed stable performance for the learning rate of 0.7.\n3.2.2. Level-1 and Level-2 Meta Learners The level-1 meta learners used in DHE are RF and ERT. Both RF and ERT are tree based ensemble classifiers. The RF fits a several number of decision trees on different sub-samples of data. This method uses averaging to avoid over-fitting of data. The ERT works similar to the RF but uses random samples. The hyper parameter settings for both the meta learners is shown in Table 6.\nTable 5 DHE base learner hyperparameters setting\nAlgorithm Hyperparameters Setting\nCNN BiLSTM activation function = \u2019relu\u2019 dropout rate = 0.2 optimizer = \u2019Nadam\u2019 learning rate = 0.7 number of epochs = 50\nANN\nactivation function = \u2019relu\u2019 dropout rate = 0.2 optimizer = \u2019Nadam\u2019 learning rate = 0.7 number of epochs = 60\nRNN\nactivation function = \u2019relu\u2019 dropout rate = 0.3 optimizer = \u2019Nadam\u2019 learning rate = 0.7 number of epochs = 60 recurrent dropout = 0.3\n167Information Technology and Control 2022/1/51\nter 60 epochs. Another parameter that helps to avoid over-fitting problem is the dropout rate. This parameter ensures the generalisation of the model. The dropout layer allows a fraction of input units to be dropped during training. It ranges between 0 and 1. In all the three models the activation function was selected as ReLU, the Rectified Linear Unit function. ReLU is one of the most widely used activation function which allows the deep learning models to be trained easily. The next important parameter is the number of epochs used to train the model. The epoch determine the number of times a training sample is selected in order to update the weights. This parameter will lead to over-fitting of the model on the training data set and hence needs to be optimised. The CNN BiLSTM model tend to be stable after 50 epochs and the ANN and RNN models were stable after 60 epochs. Another parameter that helps to avoid over-fitting problem is the dropout rate. This parameter ensures the generalisation of the model. The dropout layer allows a fraction of input units to be dropped during training. The CNN BiLSTM model and ANN model showed highest performance for the dropout rate of 0.2 and the RNN model showed better performance for dropout rate 0.3. In order to reduce the loss function of the deep learning models an optimizer is used. All the three models performed extremely well for the optmizer \u2019Nadam\u2019 which is an Adam optimizer with Nesterov momentum. Finally the learning rate is another parameter that determines the optimization weights of the optimization algorithm. The learning rate for \u2019Nadam\u2019 optimization algorithm was varied and all the three deep learning algorithms showed stable performance for the learning rate of 0.7.\n3.2.2. Level-1 and Level-2 Meta Learners The level-1 meta learners used in DHE are RF and ERT. Both RF and ERT are tree based ensemble classifiers. The RF fits a several number of decision trees on different sub-samples of data. This method uses averaging to avoid over-fitting of data. The ERT works similar to the RF but uses random samples. The hyper parameter settings for both the meta learners is shown in Table 6. The level-2 meta learner is a single meta estimator GBT. The GBT uses a regression tree based on a loss function shown in Equation (5). The parameter setting for GBT is shown in Table 7. 4. Performance Evaluation The experiment is performed using a computer with Intel Core i7 processor having 16 gigabytes of Random-Access Memory (RAM) with a clock speed of 2.71 GHz and an NVIDIA GEFORCE RTX 2070 GPU. Five datasets are used to evaluate the proposed DLSE method out of which three datasets are from the University of California, Irvine data repository, the fourth dataset is from the ricco data repository and the last dataset is taken from the National Health and Nutrition Examination Survey (NHANES) repository. The datasets used to evaluate the proposed DLSE method are described in Table 8. Since the proposed DHE uses deep learning models it is evaluated using three larger datasets with more number of features and data samples. The three datasets used to evaluate the proposed DHE are MIT-BIH Arrhythmia Dataset, The PTB Diagnostic ECG Dataset and Longitudinal EHR dataset. The datasets used to evaluate the proposed DHE method are described in Table 9. The performance of the model is evaluated using the traditional performance metrics precision, accuracy and recall. The efficiency of the proposed DLSE and DHE methods are measured using a confusion ma-\nTable 6 DHE Level-1 Meta Learners hyperparameters setting\nAlgorithm Hyperparameters Setting\nGBT\nn estimators = 300 criterion = \u2019friedman mse\u2019 max depth = 10 learning rate = 0.7\nInformation Technology and Control 2022/1/51168\ntrix. Here, nT represents the True Negative, pT corresponds to the True Positive, pF and nF represent the False Positive and False Negative values respectively. Based on these values the performance metrics are given by,\nTable 6 DHE Level-1 Meta Learners hyperparameters setting\nAlgorithm Hyperparameters Setting\nERT n estimators = 300 criterion = \u2019gini\u2019 max depth = 10 min samples split = 5\nRF n estimators = 300 criterion = \u2019gini\u2019 max depth = 10 min samples split = 5\nThe level-2 meta learner is a single meta estimator GBT. The GBT uses a regression tree based on a loss function shown in Equation (5). The parameter setting for GBT is shown in Table 7. Table 7 DHE Level-2 Meta Learners hyperparameters setting\nAlgorithm Hyperparameters Setting\nGBT n estimators = 300 criterion = \u2019friedman mse\u2019 max depth = 10 learning rate = 0.7\n4. Performance Evaluation The experiment is performed using a computer with Intel Core i7 processor having 16 gigabytes of Random-Access Memory (RAM) with a clock speed of 2.71 GHz and an NVIDIA GEFORCE RTX 2070 GPU. Five datasets are used to evaluate the proposed DLSE method out of which three datasets are from the University of California, Irvine data repository, the fourth dataset is from the ricco data repository and the last dataset is taken from the National Health and Nutrition Examination Survey (NHANES) repository. The datasets used to evaluate the proposed DLSE method are described in Table 8. Since the proposed DHE uses deep learning models it is evaluated using three larger datasets with more number of features and data samples. The three datasets used to evaluate the proposed DHE are MIT-BIH Arrhythmia Dataset, The PTB Diagnostic ECG Dataset and Longitudinal EHR dataset. The datasets used to evaluate the proposed DHE method are described in Table 9. The performance of the model is evaluated using the traditional performance metrics precision, accuracy and recall. The efficiency of the proposed DLSE and DHE methods are measured using a confusion matrix. Here, nT represents the True Negative, pT corresponds to the True Positive, pF and nF represent the False Positive and False Negative values respectively. Based on these values the performance\nmetrics are given by, Table 8\nDatasets used for evaluation of DLSE method\nDataset Name\nNo. of Instances No. of Attributes No. of Classes\nStatlog Dataset [36] 270 14 2 SPECTF Dataset [30] 267 45 2 SPECT Dataset [14] 267 23 2 Eric Heart Dataset [44] 209 8 2 NHANES coronary heart disease Dataset [10] 37709 51 2\nTable 9 Datasets used for evaluation of DHE method\nDataset Name\nNo. of Instances No. of Attributes No. of Classes\nMIT-BIH Arrhythmia Dataset [32]\n109446 188 5\nPTB Diagnostic ECG Dataset [18]\n14552 188 2\nEHR dataset [66] 109490 89 2\n  10n p n p n p\nT T Accuracy T T F F     \n  11p p p\nT Precision\nT F  \n  12p p n\nT Recall\nT F  \nThe proposed DLSE and DHE models are validated using k-fold cross validation. For this research the value of k is chosen as 10 making it 10-fold cross validation to estimate the performance of DLSE and DHE. The cross validation is applied on both the layers of DLSE.\n4.1. ANOVA statistics\n(10)\nTable 6 DHE Level-1 Meta Learners hyperparameters setting\nAlgorithm Hyperparameters Setting\nERT n estimators = 300 cri erion = \u2019gini\u2019 max depth = 10 min samples split = 5\nRF n e ti ators = 300 cri erion = \u2019gini\u2019 max depth = 10 min samples split = 5\nThe level-2 meta learner is a single meta estimator GBT. The GBT uses a regressio tree based on a l ss function shown in Equation (5). The parameter setting for GBT is shown in Table 7. Table 7 DHE Level-2 Meta Learners hyperparameters setting\nAlgorithm Hyperparameters Setting\nGBT n estimators = 300 criterion = \u2019friedman mse\u2019 max depth = 10 learning rate = 0.7\n4. Performance Evaluation The experiment is performed using a computer with Intel Core i7 processor havi 16 gigabytes of Random-Access M m y (RAM) with a clock speed of 2.71 GHz and an NVIDI GEFORCE RTX 2070 GPU. Five datasets are used to evaluate the proposed DLSE m thod out of which hr e datase s are from the Universi y of Californ a, Irvine d ta reposit ry, the fourth dataset is fr m the ricco data repository and the las dataset taken from the National He lth and Nutrition Examination Survey ( HANES) repository. The datasets used to evaluate the proposed DLSE method are described in Table 8. Since th proposed DHE uses ep learn g models it is evaluated using three larger datasets with more numb r of features and data samples. The three datasets used to evaluate the proposed DHE are MIT-BIH Arrhythmia Dataset, The PTB Diagnostic ECG Dataset and Longitudinal EHR dataset. The datasets used o evaluate the proposed DHE metho are described in T ble 9. The performance of the model is evaluated using the traditional performance metrics precision, accuracy nd rec ll. The efficiency of the proposed DLSE and DHE methods are measured using a confusion m trix. ere, nT represents the True Negative, pT\ncorresponds to the True Positive, pF and nF represent the False Positive and False Negative values respectively. Based on these values the performance\nmetrics are given by, Table 8 Datasets used for evaluation of DLSE method\nDataset N me\nNo. of Instances No. of Attributes No. of Classes\nStatlog Dataset [36] 270 14 2 SPECTF Dataset [30] 267 45 2 SPECT Dataset [14] 267 23 2 Eric Heart Dataset [44] 209 8 2 NHANES coronary heart disease Dataset [10] 37709 51 2\nTable 9 Datasets used for evaluation of DHE method\nDataset N me\nNo. of Instances No. of Attributes No. of Classes\nMIT-BIH Arrhythmia Dataset [32]\n109446 188 5\nPTB Diagnostic ECG Dataset [18]\n14552 188 2\nEHR dataset [66] 109490 89 2\n  10n p n p n p\nT T Accuracy T T F F     \n  11p p p\nT Precision\nT F  \n  12p p n\nT Recall\nT F  \nThe proposed DLSE and DHE models are validated using k-fol cross validation. F r this research the value of k is chosen as 10 making it 10-fold cross validation to estimate the performance of DLSE and DHE. The cross validation is applied on both the layers of DLSE.\n4.1. ANOVA statistics\n(11)\nTable 6 DHE Level-1 Meta Learners hyperparameters setting\nAlgorithm Hyperparameters Setting\nERT n estimators = 300 criterion = \u2019gini\u2019 max d p h = 10 min sa ples split = 5\nRF n esti ators = 300 criterio = \u2019gini\u2019 max d p h = 10 min sa ples split = 5\nThe level-2 meta learner is a single meta estimator GBT. The GBT uses a regression tree bas d on a loss function shown in Equatio (5). The paramet r setti g for T is shown i Table 7. Table 7 DHE Level-2 Meta Learners hyperparameters setting\nAlgorithm Hyperparameters Setting\nGBT n estimators = 300 criterion = \u2019friedman mse\u2019 max dep h = 10 learning rate = 0.7\n4. Performance Evaluation The experiment is performed using a computer with Intel Cor i7 proces or having 16 igabytes of Random-Access Memory (RAM) w th a clock sp ed of 2.71 GHz and an NVIDIA GEFORCE RTX 2070 GPU. Five dataset are used to evaluate the proposed DLSE method out of which thre datasets are from the University of California, Irv ne data reposi ory, the fourth dataset is from the ricco data r pository and the last dataset is taken fr the Nation l H alth and Nutrition Examination Surv y (NHANES) repository. The datasets used to evaluate the proposed DLSE method are de cribed in Table 8. Since the proposed DHE uses deep learning mode s i is evaluated using three larger dataset with more number of fea ures and data samples. Th three datasets used to evaluate th propos d DHE are MIT-BIH Arrhyth ia Da as t, The PTB Diagnostic ECG Dataset and Longitud nal EHR dataset. The data ets used to evalu te the proposed DHE method are described in Table 9. The performance of the model is evaluated using the traditional performance metrics precision, ccuracy and recall. The effi iency of the p oposed DLSE d DHE me hods ar measured using a confusi n matrix. Here, nT represents the Tr e Negative, pT corresponds to the True Positive, pF and nF represent the False Positive and False Negative values respectively. Bas d on the e alues the performance\nmetrics are given by, Table 8 Datasets used for evaluation of DLSE method\nDataset Name\nNo. of Instances No. of Attributes No. of Classes\nStatlog Dataset [36] 270 14 2 SPECTF Dataset [30] 267 45 2 SPECT Dataset [14] 267 23 2 Eric He rt Dataset [44] 209 8 2 NHANES coronary heart disease Datas t [10] 37709 51 2\nTable 9 Datasets used for evaluation of DHE method\nDataset Name\nNo. of Instances No. of Attributes No. of Classes\nMIT-BIH Arrhythmia Dataset [32]\n109446 188 5\nPTB Diagnostic ECG Dataset [18]\n14552 188 2\nEHR dataset [66] 109490 89 2\n  10n p n p n p\nT T Accuracy T T F F     \n  11p p p\nT Precision\nT F  \n  12p p n\nT Recall\nT F  \nThe proposed DLSE and DHE models are validated using k-fold cross validatio . For this r search the value of k is chosen a 10 maki g it 10-fold cross validation t estimate th performance of DLSE and DHE. The cross val dation is applied on both the layers of DLSE.\n4.1. ANOVA statistics\n(12)\nThe proposed DLSE and DHE models are validated using k-fold cross vali ation. For this research the value of k is chosen as 10 making it 10-fold cross validation to estimate the performance of DLSE and DHE. The cross validation is applied on both the layers of DLSE.\nTable 8 Datasets used for evaluation of DLSE method\nDataset Name No. of Instances No. of Attributes No. of Classes\nStatlog Dataset [36] 270 14 2\nF Dataset [30] 267 45 2\nSPECT Dataset [14] 267 23 2\nEric Heart Dataset [44] 209 8 2\nNHANES coronary heart disease Dataset [10] 37709 51 2\nTable 9 Datasets used for evaluation of DHE method\nDataset Name No. of Instances No. of Attributes No. of Classes\nMIT-BIH Arrhythmia Dataset [32] 109446 188 5\nPTB Diagnostic ECG Dataset [18] 14552 188 2\nEHR dataset [66] 109490 89 2\n4.1. ANOVA Statistics The statistical significance of the model is analysed by the ANalysis Of Variance (ANOVA) statistics. ANOVA Statistics is a statistical test that is used to determine the difference between group means and their variances, such as differences within and across groups. On the same data sets, the F -test is employed to measure the overall deviation pattern. The F-test results indicate which model best matches the supplied data set. The F-test, which is represented by the ANOVA F-test, is also used to determine whether the expected values of provided data sets differ from the values predicted by other classifiers. The value of F is roughly 1 if the null hypothesis is correct, but a large value of F causes the null hypothesis to be rejected. ANOVA condenses all of the data into a single number, F, and assigns a single p to the null hypothesis. The F-test statistics are calculated using the following formula: The statistical ignificance of the model is analy ed by the ANalysi Of Vari nce (ANOVA) statistics. ANOVA Statistics is a statistical test that is used to determine the difference between group means and their variances, such as differences within and across groups. On the same data sets, the F -test is employed to measure the overall deviation pattern. The F-test results indicate which model best matches the supplied data set. The F-test, which is represented by the ANOVA F-test, is also used to determine whether the expected values of provided data sets differ from the values predicted by other classifiers. The value of F is roughly 1 if the null hypothesis is correct, but a large value of F causes the null hypothesis to be rejected. ANOVA condenses all of the data into a single number, F, and assigns a single p to the null hypothesis. The F-test statistics are calculated using the following formula:\n  . 13 Between GroupVariabilityF Within GroupVariability   \nThe spread of a group of values/distribution is determined by its variability. There are two sorts of variability: between-group and within-group. The collaboration between the examples defines betweengroup variability, which is indicated by SS(BG) for sum of squares between groups. If the instances/samples have modest distances between them, the value of SS(BG) is small, and hence the grand mean is small. The differences within individual samples define within-group variability, which is expressed by SS(WG), which is the sum of squares within groups. Because each sample is considered independently, there is no interaction between them. In the context of healthcare data, a within group indicates a single group of persons from many groupings. It can be a group of healthy people (class= 0) or patients with cardiac disease (class= 1). Thus, in this context, within group will indicate variability of attribute values within a group of heart disease patients or variability of attribute values within a group of healthy people. Between groups, on the other hand, depict multiple kinds of people from a same medical data collection. As an example, patients from both classes, those with and without heart disease, will be represented in the between group. In ANOVA statistics, the SS, df, MS, F, Fcritical, and p-value are determined. The sum of squares (SS) is determined across groups using SS(BG) variability and within groups using SS(WG) variability using the formulas:\n     2 14SS BG n x X  \n   2 * , 15S fS WG d SD \nwhere x is the total values, X is the mean of values, SD is the standard deviation, and n is one of many sample sizes. The variable df stands for \"degree of freedom,\" which refers to the number of values in a data collection that are free to vary. Chi-square and hypothesis-testing statistics are widely employed with it. The degree(s) of freedom for the provided data set are used to determine the validity of the null\nhypothesis. Based on a number of variables and samples for the provided dataset, the degree of freedom can then be used to determine if a null hypothesis can be rejected. For both between-group and within-group comparisons, the df is calculated separately. The number of groups minus one equals the \"between-group\" degree of freedom, which is computed using the formula:\n  1 . 16fd m  The number of groups is denoted by the letter m. The number of groups multiplied by the number of instances within each group, minus one, equals the degree of freedom \"within-group.\" The following formula is used to compute it:\n    1 , 17fd m N  where N signifies the number of samples inside each group and m is the number of groupings. MS stands for mean square, and it is determined for the MS(BG) group and the MS(WG) group. By dividing the SS(BG) by its degrees of freedom, the MS(B) is determined. By dividing the SS(WG) by the degrees of freedom, the MS(WG) is determined. The Fcritical value is a function of the numerator degree of freedom, denominator degree of freedom, and significance level \u03b1=0.05. The null hypothesis for ANOVA asserts that all groups have the same average value of the dependent variable (mean). It is always preferable to have an F value that is bigger than the Fcritical value, since if this value is significant enough, we can reject the null hypothesis in favor of the assumption that the classifiers we are comparing truly differ. ANOVA has long been a popular method for reviewing and interpreting medical data in the medical field. The importance of experimental data can also be determined using the p-value. The likelihood of finding a mean difference between groups given that the null hypothesis is true is defined as the p-value. A lower p-value, for example, p < 0.05, denotes a strong presumption against the null hypothesis and more significant results. For hypothesis tests, the p-value is particularly useful for weighing the strength of the evidence. A significant p-value suggests that there is insufficient evidence to reject the null hypothesis, which can never be rejected. The sample findings are usually observed at a significant level (threshold value), which is usually 0.05. However, the bayesian inference approach [16] suggests that this range of values may be optimistic, and thus establishes a new range in which p < 0.001 denotes an algorithm's extreme significance level. By assuming that the null hypothesis is true, the p-value represents the chance of selecting a sample/value from a particular test dataset that is equal to or larger than observed test data sets. A p-value of 0.05 means that given the null hypothesis is true, there is only a 5% chance of drawing the sample being tested. The lower the p value, the more likely the null hypothesis will be rejected.\n5. Results and Discussion 5.1. Evaluation of the Proposed DLSE Method\n(13)\nThe spread of a group of values/distribution is determined by its variability. There are two sorts of variability: between-group and within-group. The collaboration between the examples defines between-group variability, which is indicated by SS(BG) for sum of squares between groups. If the insta ces/ samples have modest distances between them, the value of SS(BG) is small, and hence the grand mean is small. The differences within individual samples define within-group variability, which is expressed by SS(WG), whic is the sum of squares ithin groups. Because each sample is considered independently, there is no interaction between them. In the context of healthcare data, a within group indicates a single group of persons from many groupings. It can be a group of healthy people (class= 0) or patients with cardiac disease (class= 1). Th s, in this con ext, within group will indicate variability of attribute values within a group of heart disease patients or variability of attribute values within a group of healthy people. Between groups, on the other hand, depict multiple kinds of p ople from a same medical dat collection. As an example, patients from both classes, those with and without heart disease, will be represented in the between group. In ANOVA statistics, the SS, df, MS, F, Fcritical, and p-value are determined. The sum\n169Information Technology and Control 2022/1/51\nof squares (SS) is determined across groups using SS(BG) variability and within groups using SS(WG) variability using the formulas:\nThe statistical significance of the model is analysed by the ANalysis Of Variance (ANOVA) statistics. ANOVA Statistics is a statistical test that is used to determine the difference between group means and their variances, such as differences within and across groups. On the same data sets, the F -test is employed to measure the overall deviation pattern. The F-test results indicate which model best matches the supplied data set. The F-test, which is represented by the ANOVA F-test, is also used to determine whether the expected values of provided data sets differ from the values predicted by other classifiers. The value of F is roughly 1 if the null hypothesis is correct, but a large value of F causes the null hypothesis to be rejected. ANOVA condenses all of the data into a single number, F, and assigns a single p to the null hypothesis. The F-test statistics are calculated using the following formula:   . 13 Between GroupVariabilityF Within GroupVariability   \nThe spread of a group of values/distribution is determined by its variability. There are two sorts of variability: between-group and within-group. The collaboration between the examples defines betweengroup variability, which is indicated by SS(BG) for sum of squares between groups. If the instances/samples have modest distances between them, the value of SS(BG) is small, and hence the grand mean is small. The differences within individual samples define within-group variability, which is expressed by SS(WG), which is the sum of squares within groups. Because each sample is considered independently, there is no interaction between them. In the context of healthcare data, a within group indicates a single group of persons from many groupings. It can be a group of healthy people (class= 0) or patients with cardiac disease (class= 1). Thus, in this context, within group will indicate variability of attribute values within a group of heart disease patients or variability of attribute values within a group of healthy people. Between groups, on the other hand, depict multiple kinds of people from a same medical data collection. As an example, patients from both classes, those with and without heart disease, will be represented in the between group. In ANOVA statistics, the SS, df, MS, F, Fcritical, and p-value are determined. The sum of squares (SS) is determined across groups using SS(BG) variability and within groups using SS(WG) variability using the formulas:\n     2 14SS BG n x X  \n   2 * , 15S fS WG d SD \nwhere x is the total values, X is the mean of values, SD is the standard deviation, and n is one of many sample sizes. The variable df stands for \"degree of freedom,\" which refers to the number of values in a data collection that are free to vary. Chi-square and hypothesis-testing statistics are widely employed with it. The degree(s) of freedom for the provided data set are used to determine the validity of the null\nhypothesis. Based on a number of variables and samples for the provided dataset, the degree of freedom can then be used to determine if a null hypothesis can be rejected. For both between-group and within-group comparisons, the df is calculated separately. The number of groups minus one equals the \"between-group\" degree of freedom, which is computed using the formula:   1 . 16fd m  The number of groups is denoted by the letter m. The number of groups multiplied by the number of instances within each group, minus one, equals the degree of freedom \"within-group.\" The following formula is used to compute it:\n    1 , 17fd m N  where N signifies the number of samples inside each group and m is the number of groupings. MS stands for mean square, and it is determined for the MS(BG) group and the MS(WG) group. By dividing the SS(BG) by its degrees of freedom, the MS(B) is determined. By dividing the SS(WG) by the degrees of freedom, the MS(WG) is determined. The Fcritical value is a function of the numerator degree of freedom, denominator degree of freedom, and significance level \u03b1=0.05. The null hypothesis for ANOVA asserts that all groups have the same average value of the dependent variable (mean). It is always preferable to have an F value that is bigger than the Fcritical value, since if this value is significant enough, we can reject the null hypothesis in favor of the assumption that the classifiers we are comparing truly differ. ANOVA has long been a popular method for reviewing and interpreting medical data in the medical field. The importance of experimental data can also be determined using the p-value. The likelihood of finding a mean difference between groups given that the null hypothesis is true is defined as the p-value. A lower p-value, for example, p < 0.05, denotes a strong presumption against the null hypothesis and more significant results. For hypothesis tests, the p-value is particularly useful for weighing the strength of the evidence. A significant p-value suggests that there is insufficient evidence to reject the null hypothesis, which can never be rejected. The sample findings are usually observed at a significant level (threshold value), which is usually 0.05. However, the bayesian inference approach [16] suggests that this range of values may be optimistic, and thus establishes a new range in which p < 0.001 denotes an algorithm's extreme significance level. By assuming that the null hypothesis is true, the p-value represents the chance of selecting a sample/value from a particular test dataset that is equal to or larger than observed test data sets. A p-value of 0.05 means that given the null hypothesis is true, there is only a 5% chance of drawing the sample being tested. The lower the p value, the more likely the null hypothesis will be rejected.\n5. Results and Discussion 5.1. Evaluation of the Proposed DLSE Method\n(14)\nThe statistical significance of the model is analysed by the ANalysis Of Variance (ANOVA) statistics. ANOVA Statistics is a st tistical test that is used to determine the d fference between group mean and th ir variances, such as diff rences within and across groups. On the same data sets, the F -test is employed to measure overall deviation patt rn. The F-test results indicate which model bes matc s he supp ied data set. The F-test, which i represented by the ANOVA F-test, is also used to dete mine wh ther the expected values of pr vid data sets differ from the valu s predicted by other classifier . The value of F is roughly 1 if he null ypothe is is corr ct, but a large value of F causes the null hypothesis to be rejected. ANOVA condenses all of the data into a single number, F, and assign single p to the null hypothesis. The F-test stat stics are calculated using t e f llowing formula:   . 13 Between GroupVariabilityF Within GroupVariability   \nThe spread of a group of values/distribution is det rmin d by its variability. There are two sorts of variability: etween-group and within-group. The collaboration betw en the examples defines betweengroup variability, whic is indicated by SS(BG) for sum of squares between groups. If the instances/samples have modest distances between them, the value of SS(BG) is mall, d hence the grand mean is small. The differences within individual samples define within-group variability, which is expressed by SS(WG), which is the sum of squares within groups. Because ea sample is con idered independently, there is no interaction betwee th m. I the context of healthcare data, a within group indicates a single group of persons from many groupings. It ca b a group f healthy people (class= 0) r atients with cardiac diseas (class= 1). Thus, in this con ext, within g oup will indi ate variability of attribute values within a group of he t disease pa ients or variabil y of attrib te valu s within a group of healthy people. Between groups, on the other hand, depict multiple kinds of people fr m a same medical data collection. As an example, patients fr m both cl sses, th s w th and without heart dis ase, will be represented in the between group. In ANOVA statistics, the SS, df, MS, F, Fcritical, and p-value are determined. The um of squar s (SS) is determined across groups using SS(BG) variability and within group using SS(WG) variability using the formulas:\n     2 14SS BG n x X  \n   2 * , 15S fS WG d SD \nwhere x is the total values, X is the mean of values, SD is the s andard deviation, and n is o e of many sample sizes. The variable df stands for \"degree of freedom,\" which refers to the number of values in a data collection that are free to vary. Chi-square a d hypothesis- esting statistics are widely employed with it. The degre (s) of freedom for the provided data set are used to determine the validity of the null\nhypothesis. Based on a number of variables and samples for the pr vided dataset, the degree of freedom can n be us to determine if a null hypothesis can be rej cted. For bo h between-gro p and with n-group comparisons, the df is calculated separately. The number of groups minus one equals the \"between-gro p\" degree f freedom, which is comput d usin the formula:   1 . 16fd m  The number of groups is denoted by the letter m. The number of groups multiplied by number of i stances within each group, minus one, equals the degree of freedom \"within-group.\" The following formula is used to compu e it:\n    1 , 17fd m N  where N signifies the number of samples inside each group and m s the number of groupings. MS stands for mean square, and it is determined for the MS(BG) group and the MS(WG) group. By dividing the SS( ) by its degrees of freedom, the MS(B) s det rmined. B dividing the SS(WG) by the degrees of freedom, the MS(WG) is determined. The Fcritical valu is a function of the numerator degree of fre dom, de omi at r degree of fr ed m, and significance level \u03b1=0.05. The null hypoth sis for ANOVA asserts that all groups have the same average value of t e dependent variable (mean). It is always pref rable to have an F alue that is bigger th n the Fcritical value, sinc if this value is signif cant enoug , we can reject the null hypothesis in favor of th assumption that the classifiers we are comp ring truly differ. ANOVA has long b en a popular method for reviewing and interpreting medical data in the medical field. The importance of experimental data can also be determined using th p-value. The likelihood of finding a mean difference between groups g ven that the null hypothesis is true is defined as the p-value. A lower p-value, for example, p < 0.05, denotes a strong presumption against the null hypothesis and m re significant results. For ypothesis tes s, the p-value is particul rly u eful f weighing the trength of the evidence. A significant p-value suggests tha there is insuffici nt eviden e to reject the null hypothesis, which an never be r jected. The sample findings are usually observed at a significant lev l (threshold val e), which is usually 0.05. However, the bayesian infer nce approach [16] suggests that this range of values may be ptimistic, and thus establishes a new rang in which p < 0.001 enotes an algorithm's extreme significance level. By assuming that the null hypothesis is true, th p- alue represents the chance of selecting a sample/value from a articular test dataset that is equal to or larger than observed tes data sets. A p-value of 0.05 means that given the null hypothesi is true, there is only a 5% cha ce of drawing the sampl being te ted. The lower the p value, the more likely the null hypothesis will be rejected.\n5. Results and Discussion 5.1. Evaluation of the Proposed DLSE Method\n(15)\nwhere x is the total values, X is the mean of values, SD is the standard deviation, and n is one of many sample sizes. The variable df stands for \"degree of freedom,\" which refers to the number of values in a data collection that r fr t var . Chi-s hypoth-\n-testing s at stics are widely employ d with it. The degree(s) of freedom for the provided data set are used to determine the validity of the null hypothesis. Based on a number of variables and samples for the provided dataset, the degree of freedom can then be used to determine if a null hypothesis can be rejected. For both between-group and within-group comparisons, the df is calculated separately. The number of groups minus one equals the \"between-group\" degree of freedom, which is computed using the formula:\nThe statistical significance of the model is analysed by the ANalysis Of Variance (ANOVA) statistics. ANOVA Statistics is a statistical test that is used to determine the difference between group means and their variances, such as differences within and across groups. On the same data sets, the F -test is employed to measure the overall deviation pattern. The F-test results indicate which model best matches the supplied data set. The F-test, which is represented by the ANOVA F-test, is also used to determine whether the expected values of provided data sets differ from the values predicted by other classifiers. The value of F is roughly 1 if the null hypothesis is correct, but a large value of F causes the null hypothesis to be rejected. ANOVA condenses all of the data into a single number, F, and assigns a single p to the null hypothesis. The F-test statistics are calculated using the following formula:\n  . 13 Between GroupVariabilityF Within GroupVariability   \nThe spread of a group of values/distribution is determined by its variability. There are two sorts of variability: between-group and within-group. The collaboration between the examples defines betweengroup variability, which is indicated by SS(BG) for sum of squares between groups. If the instances/samples have modest distances between them, the value of SS(BG) is small, and hence the grand mean is small. The differences within individual samples define within-group variability, which is expressed by SS(WG), which is the sum of squares within groups. Because each sample is considered independently, there is no interaction between them. In the context of healthcare data, a within group indicates a single group of persons from many groupings. It can be a group of healthy people (class= 0) or patients with cardiac disease (class= 1). Thus, in this context, within group will indicate variability of attribute values within a group of heart disease patients or variability of attribute values within a group of healthy people. Between groups, on the other hand, depict multiple kinds of people from a same medical data collection. As an example, patients from both classes, those with and without heart disease, will be represented in the between group. In ANOVA statistics, the SS, df, MS, F, Fcritical, and p-value are determined. The sum of squares (SS) is determined across groups using SS(BG) variability and within groups using SS(WG) variability using the formulas:\n     2 14SS BG n x X  \n   2 * , 15S fS WG d SD \nwhere x is the total values, X is the mean of values, SD is the standard deviation, and n is one of many sample sizes. The variable df stands for \"degree of freedom,\" which refers to the number of values in a data collection that are free to vary. Chi-square and hypothesis-testing statistics are widely employed with it. The degree(s) of freedom for the provided data set are used to determine the validity of the null\nhypothesis. Based on a number of variables and samples for the provided dataset, the degree of freedom can then be used to determine if a null hypothesis can be rejected. For both between-group and within-group comparisons, the df is calculated separately. The number of groups minus one equals the \"between-group\" degree of freedom, which is computed using the formula:\n  1 . 16fd m  The number of groups is denoted by the letter m. The number of groups multiplied by the number of instances within each group, minus one, equals the degree of freedom \"within-group.\" The following formula is used to compute it:\n    1 , 17fd m N  where N signifies the number of samples inside each group and m is the number of groupings. MS stands for mean square, and it is determined for the MS(BG) group and the MS(WG) group. By dividing the SS(BG) by its degrees of freedom, the MS(B) is determined. By dividing the SS(WG) by the degrees of freedom, the MS(WG) is determined. The Fcritical value is a function of the numerator degree of freedom, denominator degree of freedom, and significance level \u03b1=0.05. The null hypothesis for ANOVA asserts that all groups have the same average value of the dependent variable (mean). It is always preferable to have an F value that is bigger than the Fcritical value, since if this value is significant enough, we can reject the null hypothesis in favor of the assumption that the classifiers we are comparing truly differ. ANOVA has long been a popular method for reviewing and interpreting medical data in the medical field. The importance of experimental data can also be determined using the p-value. The likelihood of finding a mean difference between groups given that the null hypothesis is true is defined as the p-value. A lower p-value, for example, p < 0.05, denotes a strong presumption against the null hypothesis and more significant results. For hypothesis tests, the p-value is particularly useful for weighing the strength of the evidence. A significant p-value suggests that there is insufficient evidence to reject the null hypothesis, which can never be rejected. The sample findings are usually observed at a significant level (threshold value), which is usually 0.05. However, the bayesian inference approach [16] suggests that this range of values may be optimistic, and thus establishes a new range in which p < 0.001 denotes an algorithm's extreme significance level. By assuming that the null hypothesis is true, the p-value represents the chance of selecting a sample/value from a particular test dataset that is equal to or larger than observed test data sets. A p-value of 0.05 means that given the null hypothesis is true, there is only a 5% chance of drawing the sample being tested. The lower the p value, the more likely the null hypothesis will be rejected.\n5. Results and Discussion 5.1. Evaluation of the Proposed DLSE Method\n(16)\nThe number of groups is denoted by the letter m. The number of groups multiplied by the number of instances within each group, minus one, equals the degree of freedom \"within-group.\" The following formula is used to compute it: The statistical significance of the model is analysed by the ANalysis Of Variance (ANOVA) statistics. ANOVA Statistics is a statistical test that is used to determine the difference between group means and their variances, such as differences within and across groups. On the same data sets, the F -test is employed to measure the overall deviation pattern. The F-test results indicate which model best matches the supplied data set. The F-test, which is represented by the ANOVA F-test, is also used to determine whether the expected values of provided data sets differ from the values predicted by other classifiers. The value of F is roughly 1 if the null hypothesis is correct, but a large value of F causes the null hypothesis to be rejected. ANOVA condenses all of the data into a single number, F, and assigns a single p to the null hypothesis. The F-test statistics are calculated using the following formula:\n  . 13 Between GroupVariabilityF Within GroupVariability   \nThe spread of a group of values/distribution is determined by its variability. There are two sorts of variability: between-group and within-group. The collaboration between the examples defines betweengroup variability, which is indicated by SS(BG) for su of squares between groups. If the instances/samples have modest distances between them, the value of SS(BG) is small, and hence the grand mean is small. The differences within individual samples define within-group variability, which is expressed by SS(WG), which is the sum of squares within groups. Because each sample is considered independently, there is no interaction between them. In the context of healthcare data, a within group indicates a single group of persons from many groupings. It can be a group of healthy people (class= 0) or patients with cardiac disease (class= 1). Thus, in this context, within group will indicate variability of attribute values within a group of heart disease patients or variability of attribute values within a group of healthy people. Between groups, on the other hand, depict multiple kinds of people from a same medical data collection. As an example, patients from both classes, those with and without heart disease, will be represented in the between group. In ANOVA statistics, the SS, df, MS, F, Fcritical, and p-value are determined. The sum of squares (SS) is determined across groups using SS(BG) variability and within groups using SS(WG) variability using the formulas:\n     2 14SS BG n x X  \n   2 * , 15S fS WG d SD \nwhere x is the total values, X is the mean of values, SD is the standard deviation, and n is one of many sample sizes. The variable df stands for \"degree of freedom,\" which refers to the number of values in a data collection that are free to vary. Chi-square and hypothesis-testing statistics are widely employed with it. The degree(s) of freedom for the provided data set are used to determine the validity of the null\nhypothesis. Base n a number of variables and samples for the provided dataset, the egree of freedom can then be used to determine if a null hypothesis can be rejected. For both between-group and within-group comparisons, the df is calculated separately. The number of groups minus one equals the \"between-group\" degree of freedom, which is computed using the formula:\n  1 . 16fd m  The number of groups is denoted by the letter m. The number of groups multiplied by the number of instances within each group, inus one, equals the degree of freedom \"within-group.\" The following formula is used to compute it:\n    1 , 17fd m N  where N signifies the number of samples inside each group and m is the number of groupings. MS stands for mean square, and it is determined for the MS(BG) group and the MS(WG) group. By dividing the SS(BG) by its degrees of freedom, the MS(B) is determined. By dividing the SS(WG) by the degrees of freedom, the MS(WG) is determined. The Fcritical value is a function of the numerator degree of freedom, denominator degree of freedom, and significance level \u03b1=0.05. The null hypothesis for ANOVA asserts that all groups have the same average value of the dependent variable (mean). It is always preferable to have an F value that is bigger than the Fcritical value, since if this value is significant enough, we can reject the null hypothesis in favor of the assumption that the classifiers we are comparing truly differ. ANOVA has long been a popular method for reviewing and interpreting medical data in the medical field. The importance of experimental data can also be determined using the p-value. The likelihood of finding a mean difference between groups given that the null hypothesis is true is defined as the p-value. A lower p-value, for example, p < 0.05, denotes a strong presumption against the null hypothesis and more significant results. For hypothesis tests, the p-value is particularly useful for weighing the strength of the evidence. A significant p-value suggests that there is insufficient evidence to reject the null hypothesis, which can never be rejected. The sample findings are usually observed at a significant level (threshold value), which is usually 0.05. However, the bayesian inference approach [16] suggests that this range of values may be optimistic, and thus establishes a new range in which p < 0.001 denotes an algorithm's extreme significance level. By assuming that the null hypothesis is true, the p-value represents the chance of selecting a sample/value from a particular test dataset that is equal to or larger than observed test data sets. A p-value of 0.05 means that given the null hypothesis is true, there is only a 5% chance of drawing the sample being tested. The lower the p value, the more likely the null hypothesis will be rejected.\n5 Results and Discussion 5.1. Evaluation of the Proposed DLSE Method\n(17)\nwhere N signifies the number of samples inside each group and m is the number of groupings. MS stands for mean square, and it is det rmined for the MS(BG) group and the MS(WG) group. By dividing the SS(BG) by its deg ees of fre dom, the MS(B) is determined. By dividing the SS(WG) by the degrees of freedom, the MS(WG) is determined. The Fcritical value is a function of the numerator degree of freedom, denominator degree of freedom, and significance l vel \u03b1=0.05. The nul hypothesis for ANOVA asserts that all groups have the same average value of he dependent variable ( ean). It is always preferable to have an F value that is bigger than the Fcritical value, since if this value is significant enough, we can reject the null hypothe-\nsis in favor of the assumption that the classifiers we are comparing truly differ. ANOVA as long been a popular method for reviewing and i terpre i g medical data in the medical field. The importance of experimental data can also be determined using the p-value. The likelihood of finding a mean difference between groups given that the null hypothesis is true is defin d as the p-value. A lower p-value, for example, p < 0.05, denotes a strong presumption against the null hypothesis and more significant results. For hypothesis tests, the p-value is particularly useful for weighing the strength of the evidence. A significant p-value suggests that there is i sufficient evidence to reject the null hypothesi , which can never be rejected. The sample findings are usually observed at a significant level (threshold value), which is usually 0.05. However, the bayesian inference approach [16] suggests that this range of values may be optimistic, and thus establishes a new range in which p < 0.001 denotes an algorithm's extreme significance level. By assuming that the null hypothesis is true, the p-value represents the chance of selecting a sample/value from a particular test dataset that is equal to or larger than observed test data sets. A p-value of 0.05 means that given the null hypothesis is true, there is only a 5% chance of drawing the sample being tested. The lower the p value, the more likely the null hypothesis will be rejected.\n5. Results and Discussion 5.1. Evaluation of the Proposed DLSE Method The proposed DLSE method is evaluated with traditional single classifiers and also with the existing ensemble techniques and the results are tabulated. We have also compared the DLSE method with a single layer ensemble method comprising of all the classifiers used in both layer-1 and layer-2 (NB, DT, SVM, LR, ERT, ABC and RF) of the proposed DLSE approach. In the proposed DLSE method, feature selection is applied on the dataset before applying the training set to layer-1. As mentioned before, the evolutionary feature selection algorithm EEFS is used for feature selection. The set of features selected using EEFS are shown in Table 10. The training set with selected features is then passed as input to the layer-1 of DLSE.\nInformation Technology and Control 2022/1/51170\n5.1.1. Evaluation with Single Classifiers The performance of DLSE approach with single classifiers is shown in Table 11. It can be seen that for the Statlog dataset the accuracy of the proposed DLSE method is 94.21% which is the highest among all the other classifiers. Though the accuracy of NB, SVM and LR for the Statlog dataset is over 80%, the DLSE method performs better than these approaches. DT shows poor performance with accuracy of 75.19%. The precision and recall measure of DLSE for Statlog dataset is 95.21% and 96.08% respectively and are higher than all the other classifiers. The accuracy of NB, DT, SVM and LR for SPECTF dataset is 72.23%, 76.49%, 82.54% and 85.09% respectively. For this dataset also the proposed DLSE technique has achieved the highest accuracy of 92.34%. The proposed method also achieves highest precision value of 91.43% and recall value of 92.12% for the SPECTF dataset. The accuracy of the proposed method is 89.80% for SPECT dataset. NB obtains the lowest accuracy of 47.98% for the SPECT dataset. The precision rate of the proposed method is 88.49% which is higher than the precision rates of NB (63.60%), DT (80.40%), SVM (69.38%) and LR (81.26%). The recall rate of the proposed technique is 81.99% for the SPECT dataset which is greater than the recall rates of NB (66.69%), DT (73.91%), SVM (78.92%) and LR (75.00%). The accuracy of NB, DT, SVM and LR for the Eric dataset is 78.02%, 76.57%, 78.98% and 78.98% respectively. For the Eric dataset also the proposed DLSE approach achieves the highest accuracy, precision and recall measures of 85.04%, 85.94% and 85.86% respectively. All the other approaches have precision and recall rates below 85%. The accuracy of the proposed method for NHANES dataset is 95.17%. This is the highest accuracy among the other approaches as the accuracy rate is almost 10% higher than the accuracy of NB (81.94%), DT (79.78%), SVM (85.80%) and LR (85.83%). The single classifiers have produced very poor precision and recall measures when compared to the proposed DLSE approach. The precision and recall rate of the proposed method is 89.66% and\n171Information Technology and Control 2022/1/51\n85.43% respectively. It can be seen that for all the datasets the proposed DLSE method outperforms all the single classifiers in terms of accuracy, precision and recall measures.\n5.1.2. Evaluation with Other Ensemble Techniques The results of the evaluation of the proposed DLSE method with the state-of-the-art ensemble techniques is shown in Table 12. We have compared the proposed method with Bagging ensemble with DT as the base learner, AdaBoost with DT as the base learner, RF and GBT methods. For the Statlog dataset, the accuracy of Bagging ensemble is 82.59%. AdaBoost and GBT both obtained an accuracy of 82.96% and RF achieved an accuracy of 80.74%. DLSE method achieved the highest accuracy of 94.21%. The precision and recall rates for Bagging ensemble is 83.28% and 82.25% respectively whereas for AdaBoost it is 84.00% and 82.67%, for RF it is 81.60% and 80.42% and for GBT it is 84.34% and 82.42%. DLSE obtained the highest precision rate of 95.21% and recall of 96.08%. The accuracy of the proposed DLSE method is 92.34% for the SPECTF dataset. This is the highest accuracy when compared to Bagging (72.51%), AdaBoost (72.23%), RF (85.93%) and GBT (83.61%). Though precision rates of Bagging, AdaBoost, RF and GBT are 74.01%, 74.15%, 84.15% and 80.40% respectively the proposed method obtained the precision rate of 91.43% which is almost 17% higher than Bagging and AdaBoost, 7% higher than RF and 11% higher than GBT. The recall measure of DLSE is 92.12% and all the other ensembles obtained less than 80% recall rate. For the SPECT dataset, Bagging produced the lowest accuracy of 56.17% followed by AdaBoost with 71.99%, GBT with 83.85% and RF with 85.36%. The proposed DLSE method produced the highest accuracy of 89.80%. The precision and recall rate of DLSE is 88.49% and 81.99% which is the highest among all the other ensembles. AdaBoost produced the lowest precision and recall value of 44.05% and 53.18% respectively. DLSE obtained an accuracy of 85.04% for the Eric heart dataset. The other ensemble approaches achieved less than 80% accuracy. The precision and recall value of DLSE is 85.94% and 85.86% which is\nInformation Technology and Control 2022/1/51172\nagain higher than all the other ensembles. Finally, for the NHANES dataset our proposed method achieved highest accuracy of 95.17% compared to Bagging (81.95%), AdaBoost (82.93%), RF (83.80%) and GBT (82.68%). The precision value of DLSE is 89.66% and all the other ensembles obtained a precision value less than 60%. The recall measure of DLSE is 85.43% which is again the highest value when compared to the rest of the ensembles as the recall value is 63.19% for Bagging, 57.86% for both AdaBoost and GBT and 49.99% for RF. In general, though the ensemble methods have better accuracy rates than that of the single classifiers, the proposed DLSE method outperforms them all in terms of accuracy, precision and recall.\n5.1.3. Evaluation of Single-Layer and Dual-Layer Classification We have also evaluated the proposed DLSE method with a single layered stacking ensemble using all the six base learners (NB, DT, SVM, LR, ERT, ABC and RF) with the meta-learner being GBT. The results are tabulated and are shown in Table 13. It can be seen that the DLSE method performs better than a single-layered ensemble of base learners in terms of all the performance metrics namely accuracy, precision and recall for all the datasets. The main advantage of using an ensemble of dual-layers is that it provides more flexibility than a single-layer ensemble. Since there are more\nthan one layer, we can use different classifiers in each layer resulting in a more refined classification. There is also a possibility for splitting an imbalanced classification problem in two relatively balanced problems. The dual-layer ensemble is also scalable for training and classifying hierarchically and can be applied to large medical datasets. The hierarchical classification always results in a better performance and quality classification than a simple flat structure. Moreover, the empirical evaluation shows that the dual-layered arrangement of classifiers outperforms the single-layered arrangement of classifiers.\n5.2. Evaluation of the Proposed DHE Method\nThe proposed DHE method is evaluated against other popular ensemble techniques such as Boosting, Bagging, Stacking and the results are tabulated. It can be seen from Table 14 that the proposed DHE method outperforms the state-of-the-art ensemble techniques in terms of accuracy, precision and recall measures. The accuracy of the proposed DHE method for the MIT-BIH dataset is 99.50% which is the highest when compared to Bagging (92.31%), AdaBoost (88.48%) and Stacking (90.72%). The precision and recall measure for the DHE is 98.41% and 98.27% respectively which is also higher than the other ensemble models under consideration. The proposed DHE\n173Information Technology and Control 2022/1/51\nmethod achieves the highest accuracy of 99.87% for the PTB Diagnostic ECG dataset. The other ensemble techniques achieved accuracy rates below 90%. The precision value of DHE for the PTB dataset is 99.31% outlasting Bagging (84.17%), AdaBoost (80.52%) and Stacking (82.76%) by a very large margin. The recall measure is also 99.01% for the proposed DHE model which is higher than all the other ensemble models in comparison. Finally, for the EHR dataset the Bagging, AdaBoost and Stacking ensembles achieved an accuracy of 81.45%, 84.79% and 88.72% respectively. For this dataset also the proposed DHE achieved the highest accuracy of 98.03%. The precision and recall values of DHE for EHR dataset is 96.03% and 96.13% respectively which is again higher than that of Bagging (79.92%, 79.65%), AdaBoost (80.17%, 79.18%) and Stacking (83.63%, 81.29%).\n5.3. Analysis of Statistical Significance The statistical significance of the proposed models is discussed in this section. For a 95% confidence interval, we determined the p-value. The results show that the p-value is significantly lower than the selected threshold of 0.05. It also rejects the null hypothesis, implying that the proposed ensemble classifier outperforms competing classifiers across all datasets. The SS, df, MS are determined and F, Fcritical and p-value are calculated and tabulated. Table 15 provide the findings of ANOVA statistics of DHE for MIT-BIH\nArrhythmia dataset, PTB Diagnostic ECG dataset and EHR Dataset. Table 16 provide the findings of ANOVA statistics of DLSE method for Statlog, SPECTF, SPECT, Eric and NHANES datasets. The suggested framework's results are statistically significant, according to ANOVA statistics. Table 15 and 16 present the ANOVA statistics of the proposed ensemble classifiers versus each individual classifier. Each individual classifier is compared to the proposed ensemble classifier, and \"between-groups\" and \"within-groups\" variables are calculated. The results show that F value is greater than Fcritical for all classifiers, indicating that the proposed ensemble classifiers perform well. Furthermore, each classifier's p-value is less than 0.001, indicating that the results for heart disease prediction are strongly significant.\n5.4. Evaluation of the Proposed Methods with Existing Approaches The proposed DLSE method was evaluated against the existing ensemble approaches in the literature and the results are tabulated. Table 17 shows the comparison of accuracy of the proposed DLSE method with existing approaches. It can be seen that the proposed DLSE method obtained the highest accuracy for all the datasets used in the research. The proposed DHE method was evaluated against the existing deep ensemble techniques and the results are presented in Table 18. It can be seen that the proposed DHE meth-\nInformation Technology and Control 2022/1/51174\n175Information Technology and Control 2022/1/51\nod has obtained the highest accuracy for all the three datasets considered in this research. Overall, the results clearly portray the effectiveness of both DLSE and DHE methods in diagnosing heart disease.\n6. Conclusion and Future Work Ensemble techniques are in existence for over a decade and have been used in the domain of machine learning for classification and prediction. These approaches play a significant part in medical diagnosis for prediction and classification of diseases. In this work, dual-layer deep ensemble techniques namely, DLSE and DHE for heart disease classification and prediction were proposed. The proposed DLSE model was applied to five heart disease datasets and the results were analyzed. The proposed method was compared with both traditional single classifiers NB, DT, SVM and LR and also with state-of-the-art ensemble methods Bagging, AdaBoost, RF and GBT. The empir-\nical analysis shows that the proposed DLSE method excels in terms of accuracy, precision and recall. Also, the proposed DLSE was compared with a single-layer stacking ensemble comprising of all the machine learning approaches used in layer-1 and layer-2 of DLSE and the results further prove that the proposed dual-layered ensemble approach has higher accuracy than the traditional machine learning methods. The proposed DLSE method achieved the highest accuracy of 94.21% for Statlog dataset, 92.34% for SPECTF dataset, 89.80% for SPECT dataset and 85.04% for the Eric heart dataset. The highest overall accuracy achieved using DLSE method is 95.17% for the NHANES dataset. This strengthens the fact that hierarchical classification always results in a better performance and classification quality than a simple flat structure. The proposed DHE method was compared with other ensemble techniques Bagging, AdaBoost and Stacking. The performance evaluation shows that the proposed DHE method outperforms all the other ensemble methods by achieving an accuracy rate of\nInformation Technology and Control 2022/1/51176\n99.50% for the MIT-BIH Arrhythmia dataset, 99.87% for the PTB Diagnostic ECG dataset and 98.03% for the EHR dataset respectively. It can also be seen that the proposed DHE method is well-suited for larger datasets with a greater number of features. This also manifests the fact that the proposed DHE utilizes the merits of both deep learning and ensemble techniques. Moreover, at a 95% confidence interval, the F value and p-value derived from ANOVA statistics suggest that the results are statistically significant for all data sets. A major limitation of the proposed approaches is the time taken for training. The training time was not taken into account in the experiment. Ensemble classifiers require more training time than individual classifiers. Overall, when compared to individual classifiers and earlier research, the suggested ensemble achieved much superior results, suggesting that it may be employed as a viable alternative tool in medical decision-making for heart disease detection. In future, the proposed DLSE and DHE methods can be applied in classification and prediction of different diseases such as cancer and diabetes. Measures to reduce the training time of DLSE and DHE by applying parallel processing can be investigated. Furthermore, increasing the number of layers in the proposed method and analyzing the performance can also be explored.\nReferences 1. Al-Barazanchi, K. K., Al-Neami, A. Q., Al-Timemy, A.\nH. Ensemble of Bagged Tree Classifier for the Diagnosis of Neuromuscular Disorders. In Fourth International Conference on Advances in Biomedical Engineering (ICABME), 2017, 1-4. https://doi.org/10.1109/ ICABME.2017.8167564\n2. Ali, F., El-Sappagh, S., Islam, S. R., Kwak, D., Ali, A., Imran, M., Kwak, K.S.A. Smart Healthcare Monitoring System for Heart Disease Prediction Based on Ensemble Deep Learning and Feature Fusion. Information Fusion, 2020, 63, 208-222. https://doi.org/10.1016/j. inffus.2020.06.008\n3. Ani, R., Jose, J., Wilson, M. and Deepa, O. S. Modified Rotation Forest Ensemble Classifier for Medical Diagnosis in Decision Support Systems, Springer, 2018. https://doi.org/10.1007/978-981-10-6875-1_14\n4. Asadi, S., Roshan, S., Kattan, M.W. Random Forest Swarm Optimization-Based for Heart Diseases Diagnosis. Journal of Biomedical Informatics, 2021.https:// doi.org/10.1016/j.jbi.2021.103690\n5. Atallah, R., Al-Mousa, A. Heart Disease Detection Using Machine Learning Majority Voting Ensemble Method. In 2nd International Conference on New Trends in Computing Sciences (ICTCS), 2019. https://doi. org/10.1109/ICTCS.2019.8923053\n6. Baccouche, A., Garcia-Zapirain, B., Castillo Olea, C., Elmaghraby, A. Ensemble Deep Learning Models for Heart Disease Classification: A Case Study from Mexico, Information, 2020, 11(4), 207. https://doi. org/10.3390/info11040207\n7. Bashir, S., Qamar, U., Khan, F. BagMOOV: A Novel Ensemble for Heart Disease Prediction Bootstrap Aggregation with Multi-Objective Optimized Voting. Australasian Physical & Engineering Sciences in Medicine, 2015, 38(2), 305-323. https://doi.org/10.1007/s13246015-0337-6\n8. Bashir, S., Qamar, U., Khan, F. H. A Multicriteria Weighted Vote-Based Classifier Ensemble for Heart Disease Prediction. Computational Intelligence, 2015. https:// doi.org/10.1111/coin.12070\n9. Bashir, S., Qamar, U., Younus Javed, M. An Ensemble Based Decision Support Framework for Intelligent Heart Disease Diagnosis. International Conference on Information Society, 2014. https://doi. org/10.1109/i-Society.2014.7009056\n10. Beck, J. D., Moss, K. L., Morelli, T. and Offenbacher, S. Periodontal Profile Class Is Associated with Prevalent Diabetes, Coronary Heart Disease, Stroke, and Systemic Markers Of C-Reactive Protein and Interleukin-6. Journal of Periodontology, 2018, 89(2), 157-165. https:// doi.org/10.1002/JPER.17-0426\n11. Brunese, L., Mercaldo, F., Reginelli, A., Santone, A. An Ensemble Learning Approach for Brain Cancer Detection Exploiting Radiomic Features, Computer Methods and Programs in Biomedicine, 2020. https://doi. org/10.1016/j.cmpb.2019.105134\n12. Cao, Y., Li, P., Zhang, Y. Parallel Processing Algorithm for Railway Signal Fault Diagnosis Data Based on Cloud Computing, Future Generation Computer Systems, 2018. https://doi.org/10.1016/j.future.2018.05.038\n177Information Technology and Control 2022/1/51\n13. Chen, Z., Wu, M., Gao, K., Wu, J., Ding, J., Zeng, Z., Li, X. A Novel Ensemble Deep Learning Approach for Sleep-Wake Detection Using Heart Rate Variability and Acceleration. IEEE Transactions on Emerging Topics in Computational Intelligence, 2020. https://doi. org/10.1109/TETCI.2020.2996943\n14. Cios, K.J., Kurgan, L. A. CLIP4: Hybrid Inductive Machine Learning Algorithm That Generates Inequality Rules. Information Sciences, 2004. https://doi. org/10.1016/j.ins.2003.03.015\n15. Cord, A., Chambon, S. Automatic Road Defect Detection by Textural Pattern Recognition Based on AdaBoost. Computer-Aided Civil and Infrastructure Engineering, 2012. https://doi.org/10.1111/j.1467-8667.2011.00736.x\n16. Cumming, G. Replication and P Intervals: P Values Predict the Future Only Vaguely, But Confidence Intervals Do Much Better. Perspectives on Psychological Science, 2008, 3(4), 286-300. https://doi.org/10.1111/j.17456924.2008.00079.x\n17. Geurts, P., Ernst, D., Wehenkel, L., Extremely Randomized Trees. Machine Learning, 2006, 63(1), 3-42. https://doi.org/10.1007/s10994-006-6226-1\n18. Goldberger, A. L., Amaral, L. A., Glass, L., Hausdorff, J. M., Ivanov, P. C., Mark, R. G., Mietus, J. E., Moody, G. B., Peng, C. K., Stanley, H. E. PhysioBank, PhysioToolkit, and PhysioNet: Components of A New Research Resource for Complex Physiologic Signals. Circulation, 2000, 101(23), e215-e220. https://doi.org/10.1161/01. CIR.101.23.e215\n19. Guyon, I., Weston, J., Barnhill, S., Vapnik, V. Gene Selection For Cancer Classification Using Support Vector Machines. Machine Learning, 2002. https://doi. org/10.1023/A:1012487302797\n20. Hariharan, R., Thaseen, I. S., Devi, G. U. Performance Analysis of Single-And Ensemble-Based Classifiers for Intrusion Detection. In Soft Computing for Problem Solving, Springer, 2019. https://doi.org/10.1007/978981-15-0184-5_65\n21. Hu, G., Yin, C., Wan, M., Zhang, Y., Fang, Y. Recognition of Diseased Pinus Trees in UAV Images Using Deep Learning and AdaBoost Classifier. Biosystems Engineering, 2020. https://doi.org/10.1016/j.biosystemseng.2020.03.021\n22. Hung, C., Chen, J. H. A Selective Ensemble Based on Expected Probabilities for Bankruptcy Prediction. Expert Systems with Applications, 2009. https://doi. org/10.1016/j.eswa.2008.06.068\n23. Jabeen, F., Maqsood, M., Ghazanfar, M. A., Aadil, F., Khan, S., Khan, M. F., Mehmood, I. An IoT Based Efficient Hybrid Recommender System for Cardiovascular Disease. Peer-to-Peer Networking and Applications, 2019, 12(5), 1263-1276. https://doi.org/10.1007/s12083019-00733-3\n24. James, G., Witten, D., Hastie, T., Tibshirani, R. An Introduction to Statistical Learning. New York: Springer, 2013. https://doi.org/10.1007/978-1-4614-7138-7\n25. Jordan, M. I., Mitchell, T. M. Machine learning: Trends, Perspectives, And Prospects, Science, 2015, 349(5), 255-260. https://doi.org/10.1126/science.aaa8415\n26. Kamal, P., Ahuja, S. An Ensemble-Based Model for Prediction of Academic Performance of Students in Undergrad Professional Course. Journal of Engineering, Design and Technology, 2019. https://doi.org/10.1108/ JEDT-11-2018-0204\n27. Kami\u0144ski, B., Jakubczyk, M., Szufel, P. A Framework for Sensitivity Analysis of Decision Trees. Central European Journal of Operations Research, 2018. https://doi. org/10.1007/s10100-017-0479-6\n28. Khairalla, M.A, Ning, X, Al-Jallad, N.T., El-Faroug, M.O. Short-Term Forecasting for Energy Consumption Through Stacking Heterogeneous Ensemble Learning Model. Energies, 2018, 11, 1605. https://doi. org/10.3390/en11061605\n29. Kotsiantis, S. B., Zaharakis, I., Pintelas, P. Supervised Machine Learning: A Review of Classification Techniques. Emerging Artificial Intelligence Applications in Computer Engineering, 2007, 160(1), 3-24.\n30. Kurgan, L. A., Cios, K. J., Tadeusiewicz, R., Ogiela, M., Goodenday, L. S. Knowledge Discovery Approach to Automated Cardiac SPECT Diagnosis. Artificial Intelligence in Medicine, 2001, 23(2), 149-169. https://doi. org/10.1016/S0933-3657(01)00082-3\n31. Marak, D. C. B., Halder, A., Kumar, A. Semi-supervised Ensemble Learning for Efficient Cancer Sample Classification from miRNA Gene Expression Data. New Generation Computing, 2021. https://doi.org/10.1007/ s00354-021-00123-5\n32. Moody, G. B., Mark, R. G. The Impact of the MIT-BIH Arrhythmia Database. IEEE Engineering in Medicine and Biology Magazine, 2001, 20(3), 45-50. https://doi. org/10.1109/51.932724\n33. Muzammal, M., Talat, R., Sodhro, A. H., Pirbhulal, S. A Multi-Sensor Data Fusion Enabled Ensemble Approach for Medical Data from Body Sensor Networks.\nInformation Technology and Control 2022/1/51178\nInformation Fusion, 2020, 53, 155-164. https://doi. org/10.1016/j.inffus.2019.06.021\n34. Natekin, A., Knoll, A. Gradient Boosting Machines, A Tutorial. Frontiers in Neurorobotics, 2013. https://doi. org/10.3389/fnbot.2013.00021\n35. Nilashi, M., Ahmadi, H., Shahmoradi, L., Ibrahim, O., Akbari, E. A Predictive Method for Hepatitis Disease Diagnosis Using Ensembles of Neuro-Fuzzy Technique. Journal Of Infection and Public Health, 2019, 12(1), 13- 20. https://doi.org/10.1016/j.jiph.2018.09.009\n36. Panda D., Dash S. R. Predictive System: Comparison of Classification Techniques for Effective Prediction of Heart Disease. In: Smart Intelligent Computing and Applications, 2020. https://doi.org/10.1007/978-98113-9282-5_19\n37. Pinto, A., Pereira, S., Rasteiro, D., Silva, C. A. Hierarchical Brain Tumour Segmentation Using Extremely Randomized Trees. Pattern Recognition, 2018. https://doi. org/10.1016/j.patcog.2018.05.006\n38. P\u0142awiak, P., Acharya, U. R. Novel Deep Genetic Ensemble of Classifiers for Arrhythmia Detection Using ECG signals. Neural Computing and Applications, 2020, 32(15), 11137-11161. https://doi.org/10.1007/s00521018-03980-2\n39. Ponomareva, N., Radpour, S., Hendry, G., Haykal, S., Colthurst, T., Mitrichev, P., Grushetsky, A. TF Boosted Trees: A Scalable TensorFlow Based Framework for Gradient Boosting. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, 2017. https://doi.org/10.1007/978-3-319-712734_44\n40. Prakash, V. J., Karthikeyan, N. K. Enhanced Evolutionary Feature Selection and Ensemble Method for Cardiovascular Disease Prediction. Interdisciplinary Sciences: Computational Life Sciences, 2021. https://doi. org/10.1007/s12539-021-00430-x\n41. Probst, P, Wright, MN, Boulesteix, A.-L. Hyperparameters and Tuning Strategies for Random Forest. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 2019. https://doi.org/10.1002/widm.1301\n42. Rath, A., Mishra, D., Panda, G., Satapathy, S. C. Heart Disease Detection Using Deep Learning Methods from Imbalanced ECG Samples. Biomedical Signal Processing and Control, 2021. https://doi.org/10.1016/j. bspc.2021.102820\n43. Rhanoui, M., Mikram, M., Yousfi, S., Barzali, S. A CNN-BiLSTM Model for Document-Level Sentiment Analysis. Machine Learning and Knowledge Ex-\ntraction, 2019, 1(3), 832-847. https://doi.org/10.3390/ make1030048\n44. Ricco, Eric Heart Disease Dataset. [Online]. Available: http://eric.univ-lyon2.fr/%7Ericco/tanagra/fichiers/ heart_disease_male.xls [Accessed in 8 March 2021].\n45. Rokach, L. Ensemble-Based Classifiers. Artificial Intelligence Review, 2010, 33(1), 1-39. https://doi. org/10.1007/s10462-009-9124-7\n46. Sagi, O., Rokach, L. Ensemble Learning: A Survey. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 2018. https://doi.org/10.1002/widm.1249\n47. Sahu, S. K., Mohapatra, D. P., Rout, J. K., Sahoo, K. S., Luhach, A. K. An Ensemble-Based Scalable Approach for Intrusion Detection Using Big Data Framework. Big Data, 2021, 9(4), 303-321. https://doi.org/10.1089/ big.2020.0201\n48. Sapra, L., Sandhu, J. K., Goyal, N. Intelligent Method for Detection of Coronary Artery Disease with Ensemble Approach. In Advances in Communication and Computational Technology, 2021. https://doi.org/10.1007/978981-15-5341-7_78\n49. Sidiq, U., Aaqib, S. M. An Empirical Model for Thyroid Disease Diagnosis Using Data Mining Techniques. In International Conference on Sustainable Communication Networks and Application, Springer, Cham, 2019. https://doi.org/10.1007/978-3-030-34515-0_61\n50. Silva, L. O. L. A., Koga, M., Boas, L. B. V., Cugnasca, C. E., Costa, A. H. R. Comparative Assessment of Feature Selection and Classification Techniques for Visual Inspection of Pot Plant Seedlings. Computers And Electronics in Agriculture, 2013.https://doi.org/10.1016/j. compag.2013.07.001\n51. Siwek, K., Osowski, S. Improving the Accuracy of Prediction of PM10 Pollution by The Wavelet Transformation and An Ensemble of Neural Predictors. Engineering Applications of Artificial Intelligence, 2012, 25(6), 1246-1258. https://doi.org/10.1016/j.engappai.2011.10.013\n52. Surakhi, O. M., Zaidan, M. A., Serhan, S., Salah, I., Hussein, T. An Optimal Stacked Ensemble Deep Learning Model for Predicting Time-Series Data Using a Genetic Algorithm-An Application for Aerosol Particle Number Concentrations. Computers, 9(4), 89, 2020. https://doi. org/10.3390/computers9040089\n53. Tama, B. A., Im, S., Lee, S. Improving an Intelligent Detection System for Coronary Heart Disease Using a Two-Tier Classifier Ensemble. BioMed Research International, 2020. https://doi.org/10.1155/2020/9816142\n179Information Technology and Control 2022/1/51\n54. Tan, K. K., Le, N. Q. K., Yeh, H. Y., Chua, M. C. H. Ensemble of Deep Recurrent Neural Networks for Identifying Enhancers Via Dinucleotide Physicochemical Properties. Cells, 2019, 8(7), 767. https://doi.org/10.3390/ cells8070767\n55. Uslu, S. Optimization of Diesel Engine Operating Parameters Fueled with Palm Oil-Diesel Blend: Comparative Evaluation Between Response Surface Methodology (RSM) And Artificial Neural Network (ANN). Fuel, 2020. https://doi.org/10.1016/j.fuel.2020.117990\n56. Wang, S. J., Mathew, A., Chen, Y., Xi, L. F., Ma, L., Lee, J. Empirical Analysis of Support Vector Machine Ensemble Classifiers. Expert Systems with Applications, 2009. https://doi.org/10.1016/j.eswa.2008.07.041\n57. WHO, Cardiovascular Diseases in India. [Online]. Available: https://www.who.int/india/health-topics/ cardiovascular-diseases [Accessed in 8 March 2021].\n58. WHO, Cardiovascular Diseases. [Online]. Available: https://www.who.int /health-topics/cardiovascular-diseases [Accessed in 8 March 2021].\n59. Wu, X., Kumar, V., Quinlan, J. R., Ghosh, J., Yang, Q., Motoda, H., McLachlan, G. J., Ng, A., Liu, B., Yu, P. S., Zhou, Z.-H., Steinbach, M., Hand, D. J., Steinberg, D. Top 10 Algorithms in Data Mining. Knowledge Information Systems, 2010.\n60. Wu, Z., Shi, L., Li, J., Wang, Q., Sun, L., Wei, Z., Plaza, J., Plaza, A. GPU Parallel Implementation of Spatially Adaptive Hyperspectral Image Classification. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2017, 11(4), 1131-1143. https://doi.org/10.1109/JSTARS.2017.2755639\n61. Xie, Q., Cheng, G., Xu, X., Zhao, Z. Research Based on Stock Predicting Model of Neural Networks Ensemble\nLearning. In MATEC Web of Conferences, EDP Sciences, 2018. https://doi.org/10.1051/matecconf/201823202029\n62. Xu, S. Bayesian Na\u00efve Bayes Classifiers to Text Classification. Journal of Information Science, 2018. https:// doi.org/10.1177/0165551516677946\n63. Yekkala, I., Dixit, S. A Novel Approach for Heart Disease Prediction Using Genetic Algorithm and Ensemble Classification. Proceedings of SAI Intelligent Systems Conference, 2021, 468-489. https://doi. org/10.1007/978-3-030-55187-2_36\n64. Zeng, N., Qiu, H., Wang, Z., Liu, W., Zhang, H., Li, Y. A New Switching-Delayed-PSO-Based Optimized SVM Algorithm for Diagnosis of Alzheimer's Disease. Neurocomputing, 2018. https://doi.org/10.1016/j.neucom.2018.09.001\n65. Zhang, X., Waller, S. T., Jiang, P. An Ensemble Machine Learning\u2010Based Modeling Framework for Analysis of Traffic Crash Frequency. Computer-Aided Civil and Infrastructure Engineering, 2019. https://doi.org/10.1111/ mice.12485\n66. Zhao, J., Feng, Q., Wu, P., Lupu, R. A., Wilke, R. A., Wells, Q. S., Denny, J. C., Wei, W. Q. Learning from Longitudinal Data in Electronic Health Record and Genetic Data to Improve Cardiovascular Event Prediction. Scientific Reports, 2019, 9(1), 1-10. https://doi.org/10.1038/ s41598-018-36745-x\n67. Zhenya, Q., Zhang, Z. A Hybrid Cost-Sensitive Ensemble for Heart Disease Prediction. BMC Medical Informatics and Decision Making, 2021, 21(1), 1-18. https:// doi.org/10.1186/s12911-021-01436-7\n68. Zhou, X., Li, Y., Liang, W. CNN-RNN Based Intelligent Recommendation for Online Medical Pre-Diagnosis Support. IEEE/ACM Transactions on Computational Biology and Bioinformatics, 2020. https://doi. org/10.1109/TCBB.2020.2994780\nThis article is an Open Access article distributed under the terms and conditions of the Creative Commons Attribution 4.0 (CC BY 4.0) License (http://creativecommons.org/licenses/by/4.0/)."
        }
    ],
    "title": "Dual-Layer Deep Ensemble Techniques for Classifying Heart Disease",
    "year": 2022
}